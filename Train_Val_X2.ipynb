{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Berita</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category_id</th>\n",
       "      <th>Word2Vec Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ayah', 'pinrang', 'tangkap', 'sandera', 'anc...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1796092838048935, 0.4170130491256714, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['duga', 'anak', 'bawa', 'orang', 'kenal', 'at...</td>\n",
       "      <td>orang asing</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.10238317400217056, 0.2470414936542511, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['dpa', 'laku', 'damping', 'korban', 'laku', '...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.35820725560188293, 0.20362965762615204, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['inara', 'rusli', 'bawa', 'kunci', 'bukti', '...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.16313651204109192, 0.26164698600769043, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['viral', 'video', 'bocah', 'ikat', 'tiang', '...</td>\n",
       "      <td>orang asing</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.2542842924594879, 0.24875245988368988, 0.26...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Berita        Label  \\\n",
       "0  ['ayah', 'pinrang', 'tangkap', 'sandera', 'anc...     keluarga   \n",
       "1  ['duga', 'anak', 'bawa', 'orang', 'kenal', 'at...  orang asing   \n",
       "2  ['dpa', 'laku', 'damping', 'korban', 'laku', '...        teman   \n",
       "3  ['inara', 'rusli', 'bawa', 'kunci', 'bukti', '...     keluarga   \n",
       "4  ['viral', 'video', 'bocah', 'ikat', 'tiang', '...  orang asing   \n",
       "\n",
       "   Category_id                                    Word2Vec Vector  \n",
       "0            0  [0.1796092838048935, 0.4170130491256714, -0.04...  \n",
       "1            4  [0.10238317400217056, 0.2470414936542511, 0.27...  \n",
       "2            3  [0.35820725560188293, 0.20362965762615204, 0.2...  \n",
       "3            0  [0.16313651204109192, 0.26164698600769043, 0.2...  \n",
       "4            4  [0.2542842924594879, 0.24875245988368988, 0.26...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = \"Data Splitting/with_val/Train_Data.csv\"\n",
    "train_df = pd.read_csv(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Berita</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category_id</th>\n",
       "      <th>Word2Vec Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['kali', 'anak', 'selebgram', 'aghnia', 'aniay...</td>\n",
       "      <td>pengasuh</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3540416359901428, 0.3076167106628418, 0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['heboh', 'anak', 'vincent', 'rompies', 'libat...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.28507089614868164, 0.20352721214294434, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['keras', 'sma', 'negeri', 'tasikmalaya', 'mas...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.277415931224823, 0.2662486135959625, 0.2400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['poin', 'kpai', 'kawal', 'bullying', 'geng', ...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.28439921140670776, 0.27106228470802307, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['duga', 'hamil', 'jual', 'anak', 'hasil', 'se...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4781922698020935, 0.3863716125488281, 0.245...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Berita     Label  Category_id  \\\n",
       "0  ['kali', 'anak', 'selebgram', 'aghnia', 'aniay...  pengasuh            1   \n",
       "1  ['heboh', 'anak', 'vincent', 'rompies', 'libat...     teman            3   \n",
       "2  ['keras', 'sma', 'negeri', 'tasikmalaya', 'mas...     teman            3   \n",
       "3  ['poin', 'kpai', 'kawal', 'bullying', 'geng', ...     teman            3   \n",
       "4  ['duga', 'hamil', 'jual', 'anak', 'hasil', 'se...  keluarga            0   \n",
       "\n",
       "                                     Word2Vec Vector  \n",
       "0  [0.3540416359901428, 0.3076167106628418, 0.085...  \n",
       "1  [0.28507089614868164, 0.20352721214294434, 0.1...  \n",
       "2  [0.277415931224823, 0.2662486135959625, 0.2400...  \n",
       "3  [0.28439921140670776, 0.27106228470802307, 0.3...  \n",
       "4  [0.4781922698020935, 0.3863716125488281, 0.245...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = \"Data Splitting/with_val/Val_Data.csv\"\n",
    "val_df = pd.read_csv(val_df)\n",
    "val_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing The Data for Neural Network Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the locations\n",
    "X_train = train_df['Word2Vec Vector']\n",
    "y_train = train_df['Category_id']\n",
    "X_val = val_df['Word2Vec Vector']\n",
    "y_val = val_df['Category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17960928  0.41701305 -0.04744937 ...  0.40574414  0.245582\n",
      "   0.08898055]\n",
      " [ 0.10238317  0.24704149  0.27464882 ...  0.08813259  0.30407691\n",
      "   0.43934801]\n",
      " [ 0.35820726  0.20362966  0.2630544  ...  0.2579141   0.35038081\n",
      "   0.36289123]\n",
      " ...\n",
      " [ 0.27806711  0.24155277  0.24423018 ...  0.28065443  0.53148139\n",
      "   0.43777528]\n",
      " [ 0.42479664  0.10447986 -0.03571824 ...  0.26021251  0.16793445\n",
      "   0.25592601]\n",
      " [ 0.35719058  0.26109946  0.15572512 ...  0.1309738   0.32690907\n",
      "   0.12616619]]\n",
      "[[ 0.35404164  0.30761671  0.08512706 ...  0.2467062   0.2330083\n",
      "   0.29866689]\n",
      " [ 0.2850709   0.20352721  0.14480667 ...  0.20088911  0.2974396\n",
      "   0.22488372]\n",
      " [ 0.27741593  0.26624861  0.24004306 ...  0.2734699   0.46699813\n",
      "   0.09709835]\n",
      " ...\n",
      " [ 0.34807277  0.34124702 -0.12281044 ...  0.40926725  0.36617047\n",
      "   0.1402137 ]\n",
      " [ 0.26805174  0.2869263   0.12354009 ...  0.36130354  0.19468924\n",
      "   0.23578319]\n",
      " [ 0.27741507  0.2287111  -0.0033286  ...  0.2329713   0.16494793\n",
      "   0.14489825]]\n"
     ]
    }
   ],
   "source": [
    "# Convert string to float\n",
    "X_train = np.array([list(map(float, row.strip(\"[]\").split(','))) for row in X_train])\n",
    "print(X_train)\n",
    "X_train = X_train.T\n",
    "\n",
    "X_val = np.array([list(map(float, row.strip(\"[]\").split(','))) for row in X_val])\n",
    "print(X_val)\n",
    "X_val = X_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17960928,  0.10238317,  0.35820726, ...,  0.27806711,\n",
       "         0.42479664,  0.35719058],\n",
       "       [ 0.41701305,  0.24704149,  0.20362966, ...,  0.24155277,\n",
       "         0.10447986,  0.26109946],\n",
       "       [-0.04744937,  0.27464882,  0.2630544 , ...,  0.24423018,\n",
       "        -0.03571824,  0.15572512],\n",
       "       ...,\n",
       "       [ 0.40574414,  0.08813259,  0.2579141 , ...,  0.28065443,\n",
       "         0.26021251,  0.1309738 ],\n",
       "       [ 0.245582  ,  0.30407691,  0.35038081, ...,  0.53148139,\n",
       "         0.16793445,  0.32690907],\n",
       "       [ 0.08898055,  0.43934801,  0.36289123, ...,  0.43777528,\n",
       "         0.25592601,  0.12616619]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35404164,  0.2850709 ,  0.27741593, ...,  0.34807277,\n",
       "         0.26805174,  0.27741507],\n",
       "       [ 0.30761671,  0.20352721,  0.26624861, ...,  0.34124702,\n",
       "         0.2869263 ,  0.2287111 ],\n",
       "       [ 0.08512706,  0.14480667,  0.24004306, ..., -0.12281044,\n",
       "         0.12354009, -0.0033286 ],\n",
       "       ...,\n",
       "       [ 0.2467062 ,  0.20088911,  0.2734699 , ...,  0.40926725,\n",
       "         0.36130354,  0.2329713 ],\n",
       "       [ 0.2330083 ,  0.2974396 ,  0.46699813, ...,  0.36617047,\n",
       "         0.19468924,  0.16494793],\n",
       "       [ 0.29866689,  0.22488372,  0.09709835, ...,  0.1402137 ,\n",
       "         0.23578319,  0.14489825]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_Train:  (100, 780)\n",
      "Shape y_Train:  (780,)\n",
      "Shape X_Val:  (100, 97)\n",
      "Shape y_Val:  (97,)\n"
     ]
    }
   ],
   "source": [
    "# Make it suitable for my Neural Network input\n",
    "print(\"Shape X_Train: \", X_train.shape)\n",
    "print(\"Shape y_Train: \", y_train.shape)\n",
    "print(\"Shape X_Val: \", X_val.shape)\n",
    "print(\"Shape y_Val: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Type: <class 'numpy.ndarray'>\n",
      "y_train Type: <class 'numpy.ndarray'>\n",
      "X_val Type: <class 'numpy.ndarray'>\n",
      "y_val Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Type:\", type(X_train))\n",
    "print(\"y_train Type:\", type(y_train))\n",
    "print(\"X_val Type:\", type(X_val))\n",
    "print(\"y_val Type:\", type(y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model X2 (Node Hidden Layer 1 = 10, Learning Rate = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_Network_Val import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"X2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.437052, Train Acc: 0.080769 | Val Loss: 0.427723, Val Acc: 0.103093\n",
      "Epoch 2 - Train Loss: 0.434326, Train Acc: 0.082051 | Val Loss: 0.425209, Val Acc: 0.103093\n",
      "Epoch 3 - Train Loss: 0.431698, Train Acc: 0.083333 | Val Loss: 0.422785, Val Acc: 0.113402\n",
      "Epoch 4 - Train Loss: 0.429163, Train Acc: 0.087179 | Val Loss: 0.420447, Val Acc: 0.113402\n",
      "Epoch 5 - Train Loss: 0.426717, Train Acc: 0.097436 | Val Loss: 0.418190, Val Acc: 0.123711\n",
      "Epoch 6 - Train Loss: 0.424355, Train Acc: 0.111538 | Val Loss: 0.416011, Val Acc: 0.134021\n",
      "Epoch 7 - Train Loss: 0.422073, Train Acc: 0.120513 | Val Loss: 0.413904, Val Acc: 0.123711\n",
      "Epoch 8 - Train Loss: 0.419865, Train Acc: 0.146154 | Val Loss: 0.411867, Val Acc: 0.123711\n",
      "Epoch 9 - Train Loss: 0.417729, Train Acc: 0.173077 | Val Loss: 0.409896, Val Acc: 0.144330\n",
      "Epoch 10 - Train Loss: 0.415661, Train Acc: 0.187179 | Val Loss: 0.407987, Val Acc: 0.164948\n",
      "Epoch 11 - Train Loss: 0.413657, Train Acc: 0.214103 | Val Loss: 0.406136, Val Acc: 0.195876\n",
      "Epoch 12 - Train Loss: 0.411714, Train Acc: 0.248718 | Val Loss: 0.404344, Val Acc: 0.237113\n",
      "Epoch 13 - Train Loss: 0.409830, Train Acc: 0.274359 | Val Loss: 0.402605, Val Acc: 0.268041\n",
      "Epoch 14 - Train Loss: 0.408001, Train Acc: 0.296154 | Val Loss: 0.400917, Val Acc: 0.298969\n",
      "Epoch 15 - Train Loss: 0.406225, Train Acc: 0.333333 | Val Loss: 0.399276, Val Acc: 0.329897\n",
      "Epoch 16 - Train Loss: 0.404498, Train Acc: 0.356410 | Val Loss: 0.397682, Val Acc: 0.371134\n",
      "Epoch 17 - Train Loss: 0.402820, Train Acc: 0.374359 | Val Loss: 0.396131, Val Acc: 0.360825\n",
      "Epoch 18 - Train Loss: 0.401187, Train Acc: 0.397436 | Val Loss: 0.394623, Val Acc: 0.371134\n",
      "Epoch 19 - Train Loss: 0.399598, Train Acc: 0.408974 | Val Loss: 0.393154, Val Acc: 0.371134\n",
      "Epoch 20 - Train Loss: 0.398049, Train Acc: 0.426923 | Val Loss: 0.391723, Val Acc: 0.381443\n",
      "Epoch 21 - Train Loss: 0.396543, Train Acc: 0.438462 | Val Loss: 0.390329, Val Acc: 0.381443\n",
      "Epoch 22 - Train Loss: 0.395076, Train Acc: 0.441026 | Val Loss: 0.388970, Val Acc: 0.381443\n",
      "Epoch 23 - Train Loss: 0.393645, Train Acc: 0.444872 | Val Loss: 0.387641, Val Acc: 0.391753\n",
      "Epoch 24 - Train Loss: 0.392249, Train Acc: 0.455128 | Val Loss: 0.386344, Val Acc: 0.402062\n",
      "Epoch 25 - Train Loss: 0.390886, Train Acc: 0.457692 | Val Loss: 0.385077, Val Acc: 0.402062\n",
      "Epoch 26 - Train Loss: 0.389556, Train Acc: 0.465385 | Val Loss: 0.383839, Val Acc: 0.402062\n",
      "Epoch 27 - Train Loss: 0.388256, Train Acc: 0.467949 | Val Loss: 0.382630, Val Acc: 0.422680\n",
      "Epoch 28 - Train Loss: 0.386987, Train Acc: 0.475641 | Val Loss: 0.381447, Val Acc: 0.422680\n",
      "Epoch 29 - Train Loss: 0.385745, Train Acc: 0.483333 | Val Loss: 0.380290, Val Acc: 0.422680\n",
      "Epoch 30 - Train Loss: 0.384531, Train Acc: 0.488462 | Val Loss: 0.379158, Val Acc: 0.422680\n",
      "Epoch 31 - Train Loss: 0.383342, Train Acc: 0.489744 | Val Loss: 0.378050, Val Acc: 0.422680\n",
      "Epoch 32 - Train Loss: 0.382180, Train Acc: 0.492308 | Val Loss: 0.376964, Val Acc: 0.443299\n",
      "Epoch 33 - Train Loss: 0.381042, Train Acc: 0.492308 | Val Loss: 0.375900, Val Acc: 0.443299\n",
      "Epoch 34 - Train Loss: 0.379925, Train Acc: 0.493590 | Val Loss: 0.374857, Val Acc: 0.443299\n",
      "Epoch 35 - Train Loss: 0.378832, Train Acc: 0.493590 | Val Loss: 0.373834, Val Acc: 0.432990\n",
      "Epoch 36 - Train Loss: 0.377761, Train Acc: 0.494872 | Val Loss: 0.372832, Val Acc: 0.443299\n",
      "Epoch 37 - Train Loss: 0.376711, Train Acc: 0.493590 | Val Loss: 0.371847, Val Acc: 0.443299\n",
      "Epoch 38 - Train Loss: 0.375680, Train Acc: 0.496154 | Val Loss: 0.370881, Val Acc: 0.443299\n",
      "Epoch 39 - Train Loss: 0.374668, Train Acc: 0.496154 | Val Loss: 0.369931, Val Acc: 0.443299\n",
      "Epoch 40 - Train Loss: 0.373674, Train Acc: 0.496154 | Val Loss: 0.368999, Val Acc: 0.443299\n",
      "Epoch 41 - Train Loss: 0.372701, Train Acc: 0.497436 | Val Loss: 0.368083, Val Acc: 0.443299\n",
      "Epoch 42 - Train Loss: 0.371745, Train Acc: 0.497436 | Val Loss: 0.367181, Val Acc: 0.443299\n",
      "Epoch 43 - Train Loss: 0.370806, Train Acc: 0.498718 | Val Loss: 0.366293, Val Acc: 0.443299\n",
      "Epoch 44 - Train Loss: 0.369883, Train Acc: 0.500000 | Val Loss: 0.365417, Val Acc: 0.443299\n",
      "Epoch 45 - Train Loss: 0.368972, Train Acc: 0.500000 | Val Loss: 0.364551, Val Acc: 0.453608\n",
      "Epoch 46 - Train Loss: 0.368078, Train Acc: 0.501282 | Val Loss: 0.363686, Val Acc: 0.463918\n",
      "Epoch 47 - Train Loss: 0.367199, Train Acc: 0.501282 | Val Loss: 0.362835, Val Acc: 0.463918\n",
      "Epoch 48 - Train Loss: 0.366335, Train Acc: 0.502564 | Val Loss: 0.362001, Val Acc: 0.463918\n",
      "Epoch 49 - Train Loss: 0.365483, Train Acc: 0.502564 | Val Loss: 0.361185, Val Acc: 0.463918\n",
      "Epoch 50 - Train Loss: 0.364643, Train Acc: 0.503846 | Val Loss: 0.360388, Val Acc: 0.463918\n",
      "Epoch 51 - Train Loss: 0.363820, Train Acc: 0.503846 | Val Loss: 0.359606, Val Acc: 0.463918\n",
      "Epoch 52 - Train Loss: 0.363005, Train Acc: 0.503846 | Val Loss: 0.358835, Val Acc: 0.463918\n",
      "Epoch 53 - Train Loss: 0.362205, Train Acc: 0.503846 | Val Loss: 0.358084, Val Acc: 0.474227\n",
      "Epoch 54 - Train Loss: 0.361416, Train Acc: 0.503846 | Val Loss: 0.357345, Val Acc: 0.474227\n",
      "Epoch 55 - Train Loss: 0.360640, Train Acc: 0.503846 | Val Loss: 0.356619, Val Acc: 0.474227\n",
      "Epoch 56 - Train Loss: 0.359877, Train Acc: 0.505128 | Val Loss: 0.355907, Val Acc: 0.474227\n",
      "Epoch 57 - Train Loss: 0.359125, Train Acc: 0.505128 | Val Loss: 0.355206, Val Acc: 0.474227\n",
      "Epoch 58 - Train Loss: 0.358382, Train Acc: 0.505128 | Val Loss: 0.354515, Val Acc: 0.474227\n",
      "Epoch 59 - Train Loss: 0.357651, Train Acc: 0.505128 | Val Loss: 0.353839, Val Acc: 0.474227\n",
      "Epoch 60 - Train Loss: 0.356934, Train Acc: 0.505128 | Val Loss: 0.353168, Val Acc: 0.474227\n",
      "Epoch 61 - Train Loss: 0.356228, Train Acc: 0.505128 | Val Loss: 0.352510, Val Acc: 0.474227\n",
      "Epoch 62 - Train Loss: 0.355533, Train Acc: 0.505128 | Val Loss: 0.351856, Val Acc: 0.474227\n",
      "Epoch 63 - Train Loss: 0.354853, Train Acc: 0.505128 | Val Loss: 0.351212, Val Acc: 0.474227\n",
      "Epoch 64 - Train Loss: 0.354187, Train Acc: 0.505128 | Val Loss: 0.350577, Val Acc: 0.474227\n",
      "Epoch 65 - Train Loss: 0.353535, Train Acc: 0.505128 | Val Loss: 0.349952, Val Acc: 0.474227\n",
      "Epoch 66 - Train Loss: 0.352895, Train Acc: 0.505128 | Val Loss: 0.349334, Val Acc: 0.474227\n",
      "Epoch 67 - Train Loss: 0.352262, Train Acc: 0.503846 | Val Loss: 0.348724, Val Acc: 0.474227\n",
      "Epoch 68 - Train Loss: 0.351640, Train Acc: 0.503846 | Val Loss: 0.348123, Val Acc: 0.474227\n",
      "Epoch 69 - Train Loss: 0.351026, Train Acc: 0.503846 | Val Loss: 0.347531, Val Acc: 0.474227\n",
      "Epoch 70 - Train Loss: 0.350420, Train Acc: 0.503846 | Val Loss: 0.346946, Val Acc: 0.474227\n",
      "Epoch 71 - Train Loss: 0.349822, Train Acc: 0.503846 | Val Loss: 0.346370, Val Acc: 0.474227\n",
      "Epoch 72 - Train Loss: 0.349234, Train Acc: 0.503846 | Val Loss: 0.345802, Val Acc: 0.474227\n",
      "Epoch 73 - Train Loss: 0.348656, Train Acc: 0.503846 | Val Loss: 0.345245, Val Acc: 0.474227\n",
      "Epoch 74 - Train Loss: 0.348088, Train Acc: 0.503846 | Val Loss: 0.344697, Val Acc: 0.474227\n",
      "Epoch 75 - Train Loss: 0.347529, Train Acc: 0.503846 | Val Loss: 0.344158, Val Acc: 0.474227\n",
      "Epoch 76 - Train Loss: 0.346976, Train Acc: 0.503846 | Val Loss: 0.343627, Val Acc: 0.474227\n",
      "Epoch 77 - Train Loss: 0.346430, Train Acc: 0.503846 | Val Loss: 0.343106, Val Acc: 0.474227\n",
      "Epoch 78 - Train Loss: 0.345890, Train Acc: 0.503846 | Val Loss: 0.342592, Val Acc: 0.474227\n",
      "Epoch 79 - Train Loss: 0.345358, Train Acc: 0.503846 | Val Loss: 0.342082, Val Acc: 0.474227\n",
      "Epoch 80 - Train Loss: 0.344832, Train Acc: 0.503846 | Val Loss: 0.341579, Val Acc: 0.474227\n",
      "Epoch 81 - Train Loss: 0.344311, Train Acc: 0.503846 | Val Loss: 0.341082, Val Acc: 0.474227\n",
      "Epoch 82 - Train Loss: 0.343796, Train Acc: 0.503846 | Val Loss: 0.340593, Val Acc: 0.474227\n",
      "Epoch 83 - Train Loss: 0.343287, Train Acc: 0.503846 | Val Loss: 0.340109, Val Acc: 0.474227\n",
      "Epoch 84 - Train Loss: 0.342783, Train Acc: 0.503846 | Val Loss: 0.339630, Val Acc: 0.474227\n",
      "Epoch 85 - Train Loss: 0.342286, Train Acc: 0.503846 | Val Loss: 0.339156, Val Acc: 0.474227\n",
      "Epoch 86 - Train Loss: 0.341795, Train Acc: 0.503846 | Val Loss: 0.338687, Val Acc: 0.474227\n",
      "Epoch 87 - Train Loss: 0.341310, Train Acc: 0.503846 | Val Loss: 0.338223, Val Acc: 0.474227\n",
      "Epoch 88 - Train Loss: 0.340830, Train Acc: 0.503846 | Val Loss: 0.337763, Val Acc: 0.474227\n",
      "Epoch 89 - Train Loss: 0.340354, Train Acc: 0.503846 | Val Loss: 0.337310, Val Acc: 0.474227\n",
      "Epoch 90 - Train Loss: 0.339883, Train Acc: 0.503846 | Val Loss: 0.336856, Val Acc: 0.474227\n",
      "Epoch 91 - Train Loss: 0.339416, Train Acc: 0.503846 | Val Loss: 0.336406, Val Acc: 0.474227\n",
      "Epoch 92 - Train Loss: 0.338952, Train Acc: 0.503846 | Val Loss: 0.335961, Val Acc: 0.474227\n",
      "Epoch 93 - Train Loss: 0.338492, Train Acc: 0.503846 | Val Loss: 0.335523, Val Acc: 0.474227\n",
      "Epoch 94 - Train Loss: 0.338037, Train Acc: 0.503846 | Val Loss: 0.335089, Val Acc: 0.474227\n",
      "Epoch 95 - Train Loss: 0.337585, Train Acc: 0.503846 | Val Loss: 0.334659, Val Acc: 0.474227\n",
      "Epoch 96 - Train Loss: 0.337138, Train Acc: 0.503846 | Val Loss: 0.334233, Val Acc: 0.474227\n",
      "Epoch 97 - Train Loss: 0.336695, Train Acc: 0.503846 | Val Loss: 0.333810, Val Acc: 0.474227\n",
      "Epoch 98 - Train Loss: 0.336255, Train Acc: 0.503846 | Val Loss: 0.333390, Val Acc: 0.474227\n",
      "Epoch 99 - Train Loss: 0.335818, Train Acc: 0.503846 | Val Loss: 0.332973, Val Acc: 0.474227\n",
      "Epoch 100 - Train Loss: 0.335383, Train Acc: 0.503846 | Val Loss: 0.332561, Val Acc: 0.474227\n",
      "Epoch 101 - Train Loss: 0.334952, Train Acc: 0.503846 | Val Loss: 0.332152, Val Acc: 0.474227\n",
      "Epoch 102 - Train Loss: 0.334525, Train Acc: 0.503846 | Val Loss: 0.331744, Val Acc: 0.474227\n",
      "Epoch 103 - Train Loss: 0.334101, Train Acc: 0.503846 | Val Loss: 0.331339, Val Acc: 0.474227\n",
      "Epoch 104 - Train Loss: 0.333681, Train Acc: 0.503846 | Val Loss: 0.330939, Val Acc: 0.474227\n",
      "Epoch 105 - Train Loss: 0.333264, Train Acc: 0.503846 | Val Loss: 0.330543, Val Acc: 0.474227\n",
      "Epoch 106 - Train Loss: 0.332851, Train Acc: 0.503846 | Val Loss: 0.330151, Val Acc: 0.474227\n",
      "Epoch 107 - Train Loss: 0.332441, Train Acc: 0.503846 | Val Loss: 0.329762, Val Acc: 0.474227\n",
      "Epoch 108 - Train Loss: 0.332034, Train Acc: 0.503846 | Val Loss: 0.329376, Val Acc: 0.474227\n",
      "Epoch 109 - Train Loss: 0.331630, Train Acc: 0.503846 | Val Loss: 0.328995, Val Acc: 0.474227\n",
      "Epoch 110 - Train Loss: 0.331231, Train Acc: 0.503846 | Val Loss: 0.328619, Val Acc: 0.474227\n",
      "Epoch 111 - Train Loss: 0.330835, Train Acc: 0.503846 | Val Loss: 0.328246, Val Acc: 0.474227\n",
      "Epoch 112 - Train Loss: 0.330441, Train Acc: 0.503846 | Val Loss: 0.327876, Val Acc: 0.474227\n",
      "Epoch 113 - Train Loss: 0.330050, Train Acc: 0.503846 | Val Loss: 0.327508, Val Acc: 0.474227\n",
      "Epoch 114 - Train Loss: 0.329662, Train Acc: 0.503846 | Val Loss: 0.327144, Val Acc: 0.474227\n",
      "Epoch 115 - Train Loss: 0.329276, Train Acc: 0.503846 | Val Loss: 0.326782, Val Acc: 0.474227\n",
      "Epoch 116 - Train Loss: 0.328894, Train Acc: 0.503846 | Val Loss: 0.326422, Val Acc: 0.474227\n",
      "Epoch 117 - Train Loss: 0.328513, Train Acc: 0.503846 | Val Loss: 0.326065, Val Acc: 0.474227\n",
      "Epoch 118 - Train Loss: 0.328135, Train Acc: 0.503846 | Val Loss: 0.325710, Val Acc: 0.474227\n",
      "Epoch 119 - Train Loss: 0.327758, Train Acc: 0.503846 | Val Loss: 0.325357, Val Acc: 0.474227\n",
      "Epoch 120 - Train Loss: 0.327384, Train Acc: 0.503846 | Val Loss: 0.325006, Val Acc: 0.474227\n",
      "Epoch 121 - Train Loss: 0.327012, Train Acc: 0.503846 | Val Loss: 0.324658, Val Acc: 0.474227\n",
      "Epoch 122 - Train Loss: 0.326642, Train Acc: 0.503846 | Val Loss: 0.324311, Val Acc: 0.474227\n",
      "Epoch 123 - Train Loss: 0.326274, Train Acc: 0.503846 | Val Loss: 0.323967, Val Acc: 0.474227\n",
      "Epoch 124 - Train Loss: 0.325908, Train Acc: 0.503846 | Val Loss: 0.323626, Val Acc: 0.474227\n",
      "Epoch 125 - Train Loss: 0.325545, Train Acc: 0.503846 | Val Loss: 0.323286, Val Acc: 0.474227\n",
      "Epoch 126 - Train Loss: 0.325184, Train Acc: 0.503846 | Val Loss: 0.322950, Val Acc: 0.474227\n",
      "Epoch 127 - Train Loss: 0.324825, Train Acc: 0.503846 | Val Loss: 0.322615, Val Acc: 0.474227\n",
      "Epoch 128 - Train Loss: 0.324467, Train Acc: 0.503846 | Val Loss: 0.322282, Val Acc: 0.474227\n",
      "Epoch 129 - Train Loss: 0.324112, Train Acc: 0.503846 | Val Loss: 0.321951, Val Acc: 0.474227\n",
      "Epoch 130 - Train Loss: 0.323758, Train Acc: 0.503846 | Val Loss: 0.321622, Val Acc: 0.474227\n",
      "Epoch 131 - Train Loss: 0.323406, Train Acc: 0.503846 | Val Loss: 0.321296, Val Acc: 0.474227\n",
      "Epoch 132 - Train Loss: 0.323057, Train Acc: 0.503846 | Val Loss: 0.320972, Val Acc: 0.474227\n",
      "Epoch 133 - Train Loss: 0.322709, Train Acc: 0.503846 | Val Loss: 0.320649, Val Acc: 0.474227\n",
      "Epoch 134 - Train Loss: 0.322363, Train Acc: 0.503846 | Val Loss: 0.320328, Val Acc: 0.474227\n",
      "Epoch 135 - Train Loss: 0.322019, Train Acc: 0.503846 | Val Loss: 0.320010, Val Acc: 0.474227\n",
      "Epoch 136 - Train Loss: 0.321676, Train Acc: 0.503846 | Val Loss: 0.319693, Val Acc: 0.474227\n",
      "Epoch 137 - Train Loss: 0.321336, Train Acc: 0.503846 | Val Loss: 0.319378, Val Acc: 0.474227\n",
      "Epoch 138 - Train Loss: 0.320997, Train Acc: 0.503846 | Val Loss: 0.319067, Val Acc: 0.474227\n",
      "Epoch 139 - Train Loss: 0.320660, Train Acc: 0.503846 | Val Loss: 0.318759, Val Acc: 0.474227\n",
      "Epoch 140 - Train Loss: 0.320325, Train Acc: 0.503846 | Val Loss: 0.318451, Val Acc: 0.474227\n",
      "Epoch 141 - Train Loss: 0.319991, Train Acc: 0.503846 | Val Loss: 0.318146, Val Acc: 0.474227\n",
      "Epoch 142 - Train Loss: 0.319660, Train Acc: 0.503846 | Val Loss: 0.317841, Val Acc: 0.474227\n",
      "Epoch 143 - Train Loss: 0.319329, Train Acc: 0.503846 | Val Loss: 0.317538, Val Acc: 0.474227\n",
      "Epoch 144 - Train Loss: 0.319000, Train Acc: 0.503846 | Val Loss: 0.317236, Val Acc: 0.474227\n",
      "Epoch 145 - Train Loss: 0.318673, Train Acc: 0.503846 | Val Loss: 0.316936, Val Acc: 0.474227\n",
      "Epoch 146 - Train Loss: 0.318347, Train Acc: 0.503846 | Val Loss: 0.316638, Val Acc: 0.474227\n",
      "Epoch 147 - Train Loss: 0.318023, Train Acc: 0.503846 | Val Loss: 0.316341, Val Acc: 0.474227\n",
      "Epoch 148 - Train Loss: 0.317701, Train Acc: 0.503846 | Val Loss: 0.316046, Val Acc: 0.474227\n",
      "Epoch 149 - Train Loss: 0.317380, Train Acc: 0.503846 | Val Loss: 0.315752, Val Acc: 0.474227\n",
      "Epoch 150 - Train Loss: 0.317062, Train Acc: 0.503846 | Val Loss: 0.315460, Val Acc: 0.474227\n",
      "Epoch 151 - Train Loss: 0.316744, Train Acc: 0.503846 | Val Loss: 0.315169, Val Acc: 0.474227\n",
      "Epoch 152 - Train Loss: 0.316428, Train Acc: 0.503846 | Val Loss: 0.314879, Val Acc: 0.474227\n",
      "Epoch 153 - Train Loss: 0.316113, Train Acc: 0.503846 | Val Loss: 0.314592, Val Acc: 0.474227\n",
      "Epoch 154 - Train Loss: 0.315800, Train Acc: 0.503846 | Val Loss: 0.314305, Val Acc: 0.474227\n",
      "Epoch 155 - Train Loss: 0.315489, Train Acc: 0.503846 | Val Loss: 0.314021, Val Acc: 0.474227\n",
      "Epoch 156 - Train Loss: 0.315179, Train Acc: 0.503846 | Val Loss: 0.313737, Val Acc: 0.474227\n",
      "Epoch 157 - Train Loss: 0.314870, Train Acc: 0.503846 | Val Loss: 0.313455, Val Acc: 0.474227\n",
      "Epoch 158 - Train Loss: 0.314563, Train Acc: 0.503846 | Val Loss: 0.313175, Val Acc: 0.474227\n",
      "Epoch 159 - Train Loss: 0.314256, Train Acc: 0.503846 | Val Loss: 0.312897, Val Acc: 0.474227\n",
      "Epoch 160 - Train Loss: 0.313952, Train Acc: 0.503846 | Val Loss: 0.312620, Val Acc: 0.474227\n",
      "Epoch 161 - Train Loss: 0.313648, Train Acc: 0.503846 | Val Loss: 0.312344, Val Acc: 0.474227\n",
      "Epoch 162 - Train Loss: 0.313346, Train Acc: 0.503846 | Val Loss: 0.312070, Val Acc: 0.474227\n",
      "Epoch 163 - Train Loss: 0.313044, Train Acc: 0.503846 | Val Loss: 0.311797, Val Acc: 0.474227\n",
      "Epoch 164 - Train Loss: 0.312744, Train Acc: 0.503846 | Val Loss: 0.311525, Val Acc: 0.474227\n",
      "Epoch 165 - Train Loss: 0.312446, Train Acc: 0.503846 | Val Loss: 0.311254, Val Acc: 0.474227\n",
      "Epoch 166 - Train Loss: 0.312148, Train Acc: 0.503846 | Val Loss: 0.310985, Val Acc: 0.474227\n",
      "Epoch 167 - Train Loss: 0.311851, Train Acc: 0.503846 | Val Loss: 0.310717, Val Acc: 0.474227\n",
      "Epoch 168 - Train Loss: 0.311556, Train Acc: 0.503846 | Val Loss: 0.310452, Val Acc: 0.474227\n",
      "Epoch 169 - Train Loss: 0.311262, Train Acc: 0.503846 | Val Loss: 0.310187, Val Acc: 0.474227\n",
      "Epoch 170 - Train Loss: 0.310969, Train Acc: 0.503846 | Val Loss: 0.309924, Val Acc: 0.474227\n",
      "Epoch 171 - Train Loss: 0.310677, Train Acc: 0.503846 | Val Loss: 0.309662, Val Acc: 0.474227\n",
      "Epoch 172 - Train Loss: 0.310386, Train Acc: 0.503846 | Val Loss: 0.309401, Val Acc: 0.474227\n",
      "Epoch 173 - Train Loss: 0.310096, Train Acc: 0.503846 | Val Loss: 0.309141, Val Acc: 0.474227\n",
      "Epoch 174 - Train Loss: 0.309808, Train Acc: 0.503846 | Val Loss: 0.308882, Val Acc: 0.474227\n",
      "Epoch 175 - Train Loss: 0.309520, Train Acc: 0.503846 | Val Loss: 0.308625, Val Acc: 0.474227\n",
      "Epoch 176 - Train Loss: 0.309233, Train Acc: 0.503846 | Val Loss: 0.308368, Val Acc: 0.474227\n",
      "Epoch 177 - Train Loss: 0.308947, Train Acc: 0.503846 | Val Loss: 0.308113, Val Acc: 0.474227\n",
      "Epoch 178 - Train Loss: 0.308663, Train Acc: 0.503846 | Val Loss: 0.307858, Val Acc: 0.474227\n",
      "Epoch 179 - Train Loss: 0.308379, Train Acc: 0.503846 | Val Loss: 0.307606, Val Acc: 0.474227\n",
      "Epoch 180 - Train Loss: 0.308097, Train Acc: 0.503846 | Val Loss: 0.307354, Val Acc: 0.474227\n",
      "Epoch 181 - Train Loss: 0.307816, Train Acc: 0.503846 | Val Loss: 0.307104, Val Acc: 0.474227\n",
      "Epoch 182 - Train Loss: 0.307536, Train Acc: 0.503846 | Val Loss: 0.306855, Val Acc: 0.474227\n",
      "Epoch 183 - Train Loss: 0.307258, Train Acc: 0.503846 | Val Loss: 0.306607, Val Acc: 0.474227\n",
      "Epoch 184 - Train Loss: 0.306981, Train Acc: 0.503846 | Val Loss: 0.306360, Val Acc: 0.474227\n",
      "Epoch 185 - Train Loss: 0.306705, Train Acc: 0.503846 | Val Loss: 0.306115, Val Acc: 0.474227\n",
      "Epoch 186 - Train Loss: 0.306430, Train Acc: 0.503846 | Val Loss: 0.305870, Val Acc: 0.474227\n",
      "Epoch 187 - Train Loss: 0.306156, Train Acc: 0.503846 | Val Loss: 0.305627, Val Acc: 0.474227\n",
      "Epoch 188 - Train Loss: 0.305883, Train Acc: 0.503846 | Val Loss: 0.305385, Val Acc: 0.474227\n",
      "Epoch 189 - Train Loss: 0.305611, Train Acc: 0.503846 | Val Loss: 0.305144, Val Acc: 0.474227\n",
      "Epoch 190 - Train Loss: 0.305340, Train Acc: 0.503846 | Val Loss: 0.304903, Val Acc: 0.474227\n",
      "Epoch 191 - Train Loss: 0.305070, Train Acc: 0.503846 | Val Loss: 0.304664, Val Acc: 0.474227\n",
      "Epoch 192 - Train Loss: 0.304801, Train Acc: 0.503846 | Val Loss: 0.304426, Val Acc: 0.474227\n",
      "Epoch 193 - Train Loss: 0.304533, Train Acc: 0.503846 | Val Loss: 0.304189, Val Acc: 0.474227\n",
      "Epoch 194 - Train Loss: 0.304265, Train Acc: 0.503846 | Val Loss: 0.303953, Val Acc: 0.474227\n",
      "Epoch 195 - Train Loss: 0.303999, Train Acc: 0.503846 | Val Loss: 0.303718, Val Acc: 0.474227\n",
      "Epoch 196 - Train Loss: 0.303734, Train Acc: 0.503846 | Val Loss: 0.303484, Val Acc: 0.474227\n",
      "Epoch 197 - Train Loss: 0.303469, Train Acc: 0.503846 | Val Loss: 0.303251, Val Acc: 0.474227\n",
      "Epoch 198 - Train Loss: 0.303206, Train Acc: 0.503846 | Val Loss: 0.303019, Val Acc: 0.474227\n",
      "Epoch 199 - Train Loss: 0.302944, Train Acc: 0.503846 | Val Loss: 0.302788, Val Acc: 0.474227\n",
      "Epoch 200 - Train Loss: 0.302682, Train Acc: 0.503846 | Val Loss: 0.302558, Val Acc: 0.474227\n",
      "Epoch 201 - Train Loss: 0.302422, Train Acc: 0.503846 | Val Loss: 0.302330, Val Acc: 0.474227\n",
      "Epoch 202 - Train Loss: 0.302162, Train Acc: 0.503846 | Val Loss: 0.302102, Val Acc: 0.474227\n",
      "Epoch 203 - Train Loss: 0.301904, Train Acc: 0.503846 | Val Loss: 0.301875, Val Acc: 0.474227\n",
      "Epoch 204 - Train Loss: 0.301646, Train Acc: 0.503846 | Val Loss: 0.301649, Val Acc: 0.474227\n",
      "Epoch 205 - Train Loss: 0.301390, Train Acc: 0.503846 | Val Loss: 0.301424, Val Acc: 0.474227\n",
      "Epoch 206 - Train Loss: 0.301134, Train Acc: 0.503846 | Val Loss: 0.301200, Val Acc: 0.474227\n",
      "Epoch 207 - Train Loss: 0.300879, Train Acc: 0.503846 | Val Loss: 0.300978, Val Acc: 0.474227\n",
      "Epoch 208 - Train Loss: 0.300625, Train Acc: 0.503846 | Val Loss: 0.300756, Val Acc: 0.474227\n",
      "Epoch 209 - Train Loss: 0.300372, Train Acc: 0.503846 | Val Loss: 0.300535, Val Acc: 0.474227\n",
      "Epoch 210 - Train Loss: 0.300120, Train Acc: 0.503846 | Val Loss: 0.300315, Val Acc: 0.474227\n",
      "Epoch 211 - Train Loss: 0.299868, Train Acc: 0.503846 | Val Loss: 0.300096, Val Acc: 0.474227\n",
      "Epoch 212 - Train Loss: 0.299618, Train Acc: 0.503846 | Val Loss: 0.299878, Val Acc: 0.474227\n",
      "Epoch 213 - Train Loss: 0.299368, Train Acc: 0.503846 | Val Loss: 0.299661, Val Acc: 0.474227\n",
      "Epoch 214 - Train Loss: 0.299120, Train Acc: 0.503846 | Val Loss: 0.299445, Val Acc: 0.474227\n",
      "Epoch 215 - Train Loss: 0.298872, Train Acc: 0.503846 | Val Loss: 0.299230, Val Acc: 0.474227\n",
      "Epoch 216 - Train Loss: 0.298625, Train Acc: 0.503846 | Val Loss: 0.299016, Val Acc: 0.474227\n",
      "Epoch 217 - Train Loss: 0.298379, Train Acc: 0.503846 | Val Loss: 0.298803, Val Acc: 0.474227\n",
      "Epoch 218 - Train Loss: 0.298134, Train Acc: 0.503846 | Val Loss: 0.298590, Val Acc: 0.474227\n",
      "Epoch 219 - Train Loss: 0.297890, Train Acc: 0.503846 | Val Loss: 0.298379, Val Acc: 0.474227\n",
      "Epoch 220 - Train Loss: 0.297646, Train Acc: 0.503846 | Val Loss: 0.298169, Val Acc: 0.474227\n",
      "Epoch 221 - Train Loss: 0.297404, Train Acc: 0.503846 | Val Loss: 0.297959, Val Acc: 0.474227\n",
      "Epoch 222 - Train Loss: 0.297162, Train Acc: 0.503846 | Val Loss: 0.297750, Val Acc: 0.474227\n",
      "Epoch 223 - Train Loss: 0.296922, Train Acc: 0.503846 | Val Loss: 0.297543, Val Acc: 0.474227\n",
      "Epoch 224 - Train Loss: 0.296682, Train Acc: 0.503846 | Val Loss: 0.297336, Val Acc: 0.474227\n",
      "Epoch 225 - Train Loss: 0.296443, Train Acc: 0.503846 | Val Loss: 0.297131, Val Acc: 0.474227\n",
      "Epoch 226 - Train Loss: 0.296205, Train Acc: 0.503846 | Val Loss: 0.296926, Val Acc: 0.474227\n",
      "Epoch 227 - Train Loss: 0.295968, Train Acc: 0.503846 | Val Loss: 0.296722, Val Acc: 0.474227\n",
      "Epoch 228 - Train Loss: 0.295732, Train Acc: 0.503846 | Val Loss: 0.296519, Val Acc: 0.474227\n",
      "Epoch 229 - Train Loss: 0.295497, Train Acc: 0.503846 | Val Loss: 0.296317, Val Acc: 0.474227\n",
      "Epoch 230 - Train Loss: 0.295262, Train Acc: 0.503846 | Val Loss: 0.296116, Val Acc: 0.474227\n",
      "Epoch 231 - Train Loss: 0.295028, Train Acc: 0.503846 | Val Loss: 0.295916, Val Acc: 0.474227\n",
      "Epoch 232 - Train Loss: 0.294795, Train Acc: 0.503846 | Val Loss: 0.295716, Val Acc: 0.474227\n",
      "Epoch 233 - Train Loss: 0.294563, Train Acc: 0.503846 | Val Loss: 0.295518, Val Acc: 0.474227\n",
      "Epoch 234 - Train Loss: 0.294332, Train Acc: 0.503846 | Val Loss: 0.295321, Val Acc: 0.474227\n",
      "Epoch 235 - Train Loss: 0.294102, Train Acc: 0.503846 | Val Loss: 0.295124, Val Acc: 0.474227\n",
      "Epoch 236 - Train Loss: 0.293873, Train Acc: 0.503846 | Val Loss: 0.294929, Val Acc: 0.474227\n",
      "Epoch 237 - Train Loss: 0.293645, Train Acc: 0.503846 | Val Loss: 0.294734, Val Acc: 0.474227\n",
      "Epoch 238 - Train Loss: 0.293417, Train Acc: 0.503846 | Val Loss: 0.294541, Val Acc: 0.474227\n",
      "Epoch 239 - Train Loss: 0.293191, Train Acc: 0.503846 | Val Loss: 0.294348, Val Acc: 0.474227\n",
      "Epoch 240 - Train Loss: 0.292965, Train Acc: 0.503846 | Val Loss: 0.294156, Val Acc: 0.474227\n",
      "Epoch 241 - Train Loss: 0.292740, Train Acc: 0.503846 | Val Loss: 0.293965, Val Acc: 0.474227\n",
      "Epoch 242 - Train Loss: 0.292516, Train Acc: 0.503846 | Val Loss: 0.293775, Val Acc: 0.474227\n",
      "Epoch 243 - Train Loss: 0.292293, Train Acc: 0.503846 | Val Loss: 0.293586, Val Acc: 0.474227\n",
      "Epoch 244 - Train Loss: 0.292071, Train Acc: 0.503846 | Val Loss: 0.293398, Val Acc: 0.474227\n",
      "Epoch 245 - Train Loss: 0.291850, Train Acc: 0.503846 | Val Loss: 0.293211, Val Acc: 0.474227\n",
      "Epoch 246 - Train Loss: 0.291630, Train Acc: 0.503846 | Val Loss: 0.293024, Val Acc: 0.474227\n",
      "Epoch 247 - Train Loss: 0.291410, Train Acc: 0.503846 | Val Loss: 0.292839, Val Acc: 0.474227\n",
      "Epoch 248 - Train Loss: 0.291192, Train Acc: 0.503846 | Val Loss: 0.292654, Val Acc: 0.474227\n",
      "Epoch 249 - Train Loss: 0.290974, Train Acc: 0.503846 | Val Loss: 0.292471, Val Acc: 0.474227\n",
      "Epoch 250 - Train Loss: 0.290757, Train Acc: 0.503846 | Val Loss: 0.292288, Val Acc: 0.474227\n",
      "Epoch 251 - Train Loss: 0.290541, Train Acc: 0.503846 | Val Loss: 0.292106, Val Acc: 0.474227\n",
      "Epoch 252 - Train Loss: 0.290326, Train Acc: 0.503846 | Val Loss: 0.291926, Val Acc: 0.474227\n",
      "Epoch 253 - Train Loss: 0.290112, Train Acc: 0.503846 | Val Loss: 0.291747, Val Acc: 0.474227\n",
      "Epoch 254 - Train Loss: 0.289899, Train Acc: 0.503846 | Val Loss: 0.291568, Val Acc: 0.474227\n",
      "Epoch 255 - Train Loss: 0.289687, Train Acc: 0.503846 | Val Loss: 0.291391, Val Acc: 0.474227\n",
      "Epoch 256 - Train Loss: 0.289476, Train Acc: 0.503846 | Val Loss: 0.291215, Val Acc: 0.474227\n",
      "Epoch 257 - Train Loss: 0.289266, Train Acc: 0.503846 | Val Loss: 0.291039, Val Acc: 0.474227\n",
      "Epoch 258 - Train Loss: 0.289057, Train Acc: 0.503846 | Val Loss: 0.290865, Val Acc: 0.474227\n",
      "Epoch 259 - Train Loss: 0.288848, Train Acc: 0.503846 | Val Loss: 0.290691, Val Acc: 0.474227\n",
      "Epoch 260 - Train Loss: 0.288641, Train Acc: 0.503846 | Val Loss: 0.290519, Val Acc: 0.474227\n",
      "Epoch 261 - Train Loss: 0.288434, Train Acc: 0.503846 | Val Loss: 0.290347, Val Acc: 0.474227\n",
      "Epoch 262 - Train Loss: 0.288229, Train Acc: 0.503846 | Val Loss: 0.290176, Val Acc: 0.474227\n",
      "Epoch 263 - Train Loss: 0.288024, Train Acc: 0.503846 | Val Loss: 0.290006, Val Acc: 0.474227\n",
      "Epoch 264 - Train Loss: 0.287820, Train Acc: 0.503846 | Val Loss: 0.289837, Val Acc: 0.474227\n",
      "Epoch 265 - Train Loss: 0.287617, Train Acc: 0.503846 | Val Loss: 0.289669, Val Acc: 0.474227\n",
      "Epoch 266 - Train Loss: 0.287415, Train Acc: 0.503846 | Val Loss: 0.289502, Val Acc: 0.474227\n",
      "Epoch 267 - Train Loss: 0.287214, Train Acc: 0.503846 | Val Loss: 0.289336, Val Acc: 0.474227\n",
      "Epoch 268 - Train Loss: 0.287014, Train Acc: 0.503846 | Val Loss: 0.289171, Val Acc: 0.474227\n",
      "Epoch 269 - Train Loss: 0.286815, Train Acc: 0.503846 | Val Loss: 0.289007, Val Acc: 0.474227\n",
      "Epoch 270 - Train Loss: 0.286617, Train Acc: 0.503846 | Val Loss: 0.288843, Val Acc: 0.474227\n",
      "Epoch 271 - Train Loss: 0.286419, Train Acc: 0.503846 | Val Loss: 0.288681, Val Acc: 0.474227\n",
      "Epoch 272 - Train Loss: 0.286223, Train Acc: 0.503846 | Val Loss: 0.288519, Val Acc: 0.474227\n",
      "Epoch 273 - Train Loss: 0.286027, Train Acc: 0.503846 | Val Loss: 0.288358, Val Acc: 0.474227\n",
      "Epoch 274 - Train Loss: 0.285833, Train Acc: 0.503846 | Val Loss: 0.288198, Val Acc: 0.474227\n",
      "Epoch 275 - Train Loss: 0.285639, Train Acc: 0.503846 | Val Loss: 0.288040, Val Acc: 0.474227\n",
      "Epoch 276 - Train Loss: 0.285446, Train Acc: 0.503846 | Val Loss: 0.287882, Val Acc: 0.474227\n",
      "Epoch 277 - Train Loss: 0.285254, Train Acc: 0.503846 | Val Loss: 0.287725, Val Acc: 0.474227\n",
      "Epoch 278 - Train Loss: 0.285064, Train Acc: 0.503846 | Val Loss: 0.287569, Val Acc: 0.474227\n",
      "Epoch 279 - Train Loss: 0.284874, Train Acc: 0.503846 | Val Loss: 0.287414, Val Acc: 0.474227\n",
      "Epoch 280 - Train Loss: 0.284685, Train Acc: 0.503846 | Val Loss: 0.287259, Val Acc: 0.474227\n",
      "Epoch 281 - Train Loss: 0.284497, Train Acc: 0.503846 | Val Loss: 0.287106, Val Acc: 0.474227\n",
      "Epoch 282 - Train Loss: 0.284310, Train Acc: 0.503846 | Val Loss: 0.286954, Val Acc: 0.474227\n",
      "Epoch 283 - Train Loss: 0.284124, Train Acc: 0.503846 | Val Loss: 0.286803, Val Acc: 0.474227\n",
      "Epoch 284 - Train Loss: 0.283938, Train Acc: 0.503846 | Val Loss: 0.286652, Val Acc: 0.474227\n",
      "Epoch 285 - Train Loss: 0.283754, Train Acc: 0.503846 | Val Loss: 0.286503, Val Acc: 0.474227\n",
      "Epoch 286 - Train Loss: 0.283571, Train Acc: 0.503846 | Val Loss: 0.286354, Val Acc: 0.474227\n",
      "Epoch 287 - Train Loss: 0.283389, Train Acc: 0.503846 | Val Loss: 0.286207, Val Acc: 0.474227\n",
      "Epoch 288 - Train Loss: 0.283207, Train Acc: 0.503846 | Val Loss: 0.286060, Val Acc: 0.474227\n",
      "Epoch 289 - Train Loss: 0.283027, Train Acc: 0.503846 | Val Loss: 0.285915, Val Acc: 0.474227\n",
      "Epoch 290 - Train Loss: 0.282848, Train Acc: 0.503846 | Val Loss: 0.285770, Val Acc: 0.474227\n",
      "Epoch 291 - Train Loss: 0.282669, Train Acc: 0.503846 | Val Loss: 0.285626, Val Acc: 0.474227\n",
      "Epoch 292 - Train Loss: 0.282492, Train Acc: 0.503846 | Val Loss: 0.285483, Val Acc: 0.474227\n",
      "Epoch 293 - Train Loss: 0.282315, Train Acc: 0.503846 | Val Loss: 0.285341, Val Acc: 0.474227\n",
      "Epoch 294 - Train Loss: 0.282140, Train Acc: 0.503846 | Val Loss: 0.285201, Val Acc: 0.474227\n",
      "Epoch 295 - Train Loss: 0.281965, Train Acc: 0.503846 | Val Loss: 0.285061, Val Acc: 0.474227\n",
      "Epoch 296 - Train Loss: 0.281792, Train Acc: 0.503846 | Val Loss: 0.284922, Val Acc: 0.474227\n",
      "Epoch 297 - Train Loss: 0.281619, Train Acc: 0.503846 | Val Loss: 0.284784, Val Acc: 0.474227\n",
      "Epoch 298 - Train Loss: 0.281447, Train Acc: 0.503846 | Val Loss: 0.284647, Val Acc: 0.474227\n",
      "Epoch 299 - Train Loss: 0.281277, Train Acc: 0.503846 | Val Loss: 0.284510, Val Acc: 0.474227\n",
      "Epoch 300 - Train Loss: 0.281107, Train Acc: 0.503846 | Val Loss: 0.284375, Val Acc: 0.474227\n",
      "Epoch 301 - Train Loss: 0.280938, Train Acc: 0.503846 | Val Loss: 0.284241, Val Acc: 0.474227\n",
      "Epoch 302 - Train Loss: 0.280770, Train Acc: 0.503846 | Val Loss: 0.284107, Val Acc: 0.474227\n",
      "Epoch 303 - Train Loss: 0.280603, Train Acc: 0.503846 | Val Loss: 0.283975, Val Acc: 0.474227\n",
      "Epoch 304 - Train Loss: 0.280438, Train Acc: 0.503846 | Val Loss: 0.283843, Val Acc: 0.474227\n",
      "Epoch 305 - Train Loss: 0.280273, Train Acc: 0.503846 | Val Loss: 0.283713, Val Acc: 0.474227\n",
      "Epoch 306 - Train Loss: 0.280109, Train Acc: 0.503846 | Val Loss: 0.283583, Val Acc: 0.474227\n",
      "Epoch 307 - Train Loss: 0.279946, Train Acc: 0.503846 | Val Loss: 0.283455, Val Acc: 0.474227\n",
      "Epoch 308 - Train Loss: 0.279784, Train Acc: 0.503846 | Val Loss: 0.283327, Val Acc: 0.474227\n",
      "Epoch 309 - Train Loss: 0.279623, Train Acc: 0.503846 | Val Loss: 0.283200, Val Acc: 0.474227\n",
      "Epoch 310 - Train Loss: 0.279463, Train Acc: 0.503846 | Val Loss: 0.283074, Val Acc: 0.474227\n",
      "Epoch 311 - Train Loss: 0.279304, Train Acc: 0.503846 | Val Loss: 0.282950, Val Acc: 0.474227\n",
      "Epoch 312 - Train Loss: 0.279146, Train Acc: 0.503846 | Val Loss: 0.282826, Val Acc: 0.474227\n",
      "Epoch 313 - Train Loss: 0.278989, Train Acc: 0.503846 | Val Loss: 0.282702, Val Acc: 0.474227\n",
      "Epoch 314 - Train Loss: 0.278833, Train Acc: 0.503846 | Val Loss: 0.282580, Val Acc: 0.474227\n",
      "Epoch 315 - Train Loss: 0.278678, Train Acc: 0.503846 | Val Loss: 0.282459, Val Acc: 0.474227\n",
      "Epoch 316 - Train Loss: 0.278524, Train Acc: 0.503846 | Val Loss: 0.282339, Val Acc: 0.474227\n",
      "Epoch 317 - Train Loss: 0.278371, Train Acc: 0.503846 | Val Loss: 0.282219, Val Acc: 0.474227\n",
      "Epoch 318 - Train Loss: 0.278219, Train Acc: 0.503846 | Val Loss: 0.282101, Val Acc: 0.474227\n",
      "Epoch 319 - Train Loss: 0.278068, Train Acc: 0.503846 | Val Loss: 0.281983, Val Acc: 0.474227\n",
      "Epoch 320 - Train Loss: 0.277918, Train Acc: 0.503846 | Val Loss: 0.281867, Val Acc: 0.474227\n",
      "Epoch 321 - Train Loss: 0.277768, Train Acc: 0.503846 | Val Loss: 0.281751, Val Acc: 0.474227\n",
      "Epoch 322 - Train Loss: 0.277620, Train Acc: 0.503846 | Val Loss: 0.281636, Val Acc: 0.474227\n",
      "Epoch 323 - Train Loss: 0.277473, Train Acc: 0.503846 | Val Loss: 0.281523, Val Acc: 0.474227\n",
      "Epoch 324 - Train Loss: 0.277327, Train Acc: 0.503846 | Val Loss: 0.281410, Val Acc: 0.474227\n",
      "Epoch 325 - Train Loss: 0.277182, Train Acc: 0.503846 | Val Loss: 0.281298, Val Acc: 0.474227\n",
      "Epoch 326 - Train Loss: 0.277037, Train Acc: 0.503846 | Val Loss: 0.281187, Val Acc: 0.474227\n",
      "Epoch 327 - Train Loss: 0.276894, Train Acc: 0.503846 | Val Loss: 0.281077, Val Acc: 0.474227\n",
      "Epoch 328 - Train Loss: 0.276752, Train Acc: 0.503846 | Val Loss: 0.280968, Val Acc: 0.474227\n",
      "Epoch 329 - Train Loss: 0.276610, Train Acc: 0.503846 | Val Loss: 0.280860, Val Acc: 0.474227\n",
      "Epoch 330 - Train Loss: 0.276470, Train Acc: 0.503846 | Val Loss: 0.280752, Val Acc: 0.474227\n",
      "Epoch 331 - Train Loss: 0.276331, Train Acc: 0.503846 | Val Loss: 0.280646, Val Acc: 0.474227\n",
      "Epoch 332 - Train Loss: 0.276192, Train Acc: 0.503846 | Val Loss: 0.280541, Val Acc: 0.474227\n",
      "Epoch 333 - Train Loss: 0.276055, Train Acc: 0.503846 | Val Loss: 0.280436, Val Acc: 0.474227\n",
      "Epoch 334 - Train Loss: 0.275919, Train Acc: 0.503846 | Val Loss: 0.280333, Val Acc: 0.474227\n",
      "Epoch 335 - Train Loss: 0.275783, Train Acc: 0.503846 | Val Loss: 0.280230, Val Acc: 0.474227\n",
      "Epoch 336 - Train Loss: 0.275649, Train Acc: 0.503846 | Val Loss: 0.280128, Val Acc: 0.474227\n",
      "Epoch 337 - Train Loss: 0.275515, Train Acc: 0.503846 | Val Loss: 0.280027, Val Acc: 0.474227\n",
      "Epoch 338 - Train Loss: 0.275382, Train Acc: 0.503846 | Val Loss: 0.279927, Val Acc: 0.474227\n",
      "Epoch 339 - Train Loss: 0.275251, Train Acc: 0.503846 | Val Loss: 0.279828, Val Acc: 0.474227\n",
      "Epoch 340 - Train Loss: 0.275120, Train Acc: 0.503846 | Val Loss: 0.279730, Val Acc: 0.474227\n",
      "Epoch 341 - Train Loss: 0.274990, Train Acc: 0.503846 | Val Loss: 0.279633, Val Acc: 0.474227\n",
      "Epoch 342 - Train Loss: 0.274862, Train Acc: 0.503846 | Val Loss: 0.279537, Val Acc: 0.474227\n",
      "Epoch 343 - Train Loss: 0.274734, Train Acc: 0.503846 | Val Loss: 0.279442, Val Acc: 0.474227\n",
      "Epoch 344 - Train Loss: 0.274607, Train Acc: 0.503846 | Val Loss: 0.279347, Val Acc: 0.474227\n",
      "Epoch 345 - Train Loss: 0.274481, Train Acc: 0.503846 | Val Loss: 0.279254, Val Acc: 0.474227\n",
      "Epoch 346 - Train Loss: 0.274356, Train Acc: 0.503846 | Val Loss: 0.279161, Val Acc: 0.474227\n",
      "Epoch 347 - Train Loss: 0.274232, Train Acc: 0.503846 | Val Loss: 0.279070, Val Acc: 0.474227\n",
      "Epoch 348 - Train Loss: 0.274109, Train Acc: 0.503846 | Val Loss: 0.278979, Val Acc: 0.474227\n",
      "Epoch 349 - Train Loss: 0.273987, Train Acc: 0.503846 | Val Loss: 0.278889, Val Acc: 0.474227\n",
      "Epoch 350 - Train Loss: 0.273866, Train Acc: 0.503846 | Val Loss: 0.278800, Val Acc: 0.474227\n",
      "Epoch 351 - Train Loss: 0.273746, Train Acc: 0.503846 | Val Loss: 0.278712, Val Acc: 0.474227\n",
      "Epoch 352 - Train Loss: 0.273627, Train Acc: 0.503846 | Val Loss: 0.278625, Val Acc: 0.474227\n",
      "Epoch 353 - Train Loss: 0.273509, Train Acc: 0.503846 | Val Loss: 0.278539, Val Acc: 0.474227\n",
      "Epoch 354 - Train Loss: 0.273391, Train Acc: 0.503846 | Val Loss: 0.278454, Val Acc: 0.474227\n",
      "Epoch 355 - Train Loss: 0.273275, Train Acc: 0.503846 | Val Loss: 0.278369, Val Acc: 0.474227\n",
      "Epoch 356 - Train Loss: 0.273159, Train Acc: 0.503846 | Val Loss: 0.278285, Val Acc: 0.474227\n",
      "Epoch 357 - Train Loss: 0.273045, Train Acc: 0.503846 | Val Loss: 0.278203, Val Acc: 0.474227\n",
      "Epoch 358 - Train Loss: 0.272931, Train Acc: 0.503846 | Val Loss: 0.278121, Val Acc: 0.474227\n",
      "Epoch 359 - Train Loss: 0.272818, Train Acc: 0.503846 | Val Loss: 0.278040, Val Acc: 0.474227\n",
      "Epoch 360 - Train Loss: 0.272707, Train Acc: 0.503846 | Val Loss: 0.277959, Val Acc: 0.474227\n",
      "Epoch 361 - Train Loss: 0.272596, Train Acc: 0.503846 | Val Loss: 0.277880, Val Acc: 0.474227\n",
      "Epoch 362 - Train Loss: 0.272486, Train Acc: 0.503846 | Val Loss: 0.277801, Val Acc: 0.474227\n",
      "Epoch 363 - Train Loss: 0.272377, Train Acc: 0.503846 | Val Loss: 0.277724, Val Acc: 0.474227\n",
      "Epoch 364 - Train Loss: 0.272268, Train Acc: 0.503846 | Val Loss: 0.277647, Val Acc: 0.474227\n",
      "Epoch 365 - Train Loss: 0.272161, Train Acc: 0.503846 | Val Loss: 0.277571, Val Acc: 0.474227\n",
      "Epoch 366 - Train Loss: 0.272055, Train Acc: 0.503846 | Val Loss: 0.277495, Val Acc: 0.474227\n",
      "Epoch 367 - Train Loss: 0.271950, Train Acc: 0.503846 | Val Loss: 0.277420, Val Acc: 0.474227\n",
      "Epoch 368 - Train Loss: 0.271845, Train Acc: 0.503846 | Val Loss: 0.277347, Val Acc: 0.474227\n",
      "Epoch 369 - Train Loss: 0.271741, Train Acc: 0.503846 | Val Loss: 0.277274, Val Acc: 0.474227\n",
      "Epoch 370 - Train Loss: 0.271639, Train Acc: 0.503846 | Val Loss: 0.277201, Val Acc: 0.474227\n",
      "Epoch 371 - Train Loss: 0.271537, Train Acc: 0.503846 | Val Loss: 0.277130, Val Acc: 0.474227\n",
      "Epoch 372 - Train Loss: 0.271436, Train Acc: 0.503846 | Val Loss: 0.277059, Val Acc: 0.474227\n",
      "Epoch 373 - Train Loss: 0.271336, Train Acc: 0.503846 | Val Loss: 0.276989, Val Acc: 0.474227\n",
      "Epoch 374 - Train Loss: 0.271237, Train Acc: 0.503846 | Val Loss: 0.276920, Val Acc: 0.474227\n",
      "Epoch 375 - Train Loss: 0.271138, Train Acc: 0.503846 | Val Loss: 0.276851, Val Acc: 0.474227\n",
      "Epoch 376 - Train Loss: 0.271041, Train Acc: 0.503846 | Val Loss: 0.276784, Val Acc: 0.474227\n",
      "Epoch 377 - Train Loss: 0.270944, Train Acc: 0.503846 | Val Loss: 0.276717, Val Acc: 0.474227\n",
      "Epoch 378 - Train Loss: 0.270849, Train Acc: 0.503846 | Val Loss: 0.276651, Val Acc: 0.474227\n",
      "Epoch 379 - Train Loss: 0.270754, Train Acc: 0.503846 | Val Loss: 0.276586, Val Acc: 0.474227\n",
      "Epoch 380 - Train Loss: 0.270660, Train Acc: 0.503846 | Val Loss: 0.276521, Val Acc: 0.474227\n",
      "Epoch 381 - Train Loss: 0.270567, Train Acc: 0.503846 | Val Loss: 0.276457, Val Acc: 0.474227\n",
      "Epoch 382 - Train Loss: 0.270474, Train Acc: 0.503846 | Val Loss: 0.276394, Val Acc: 0.474227\n",
      "Epoch 383 - Train Loss: 0.270383, Train Acc: 0.503846 | Val Loss: 0.276332, Val Acc: 0.474227\n",
      "Epoch 384 - Train Loss: 0.270292, Train Acc: 0.503846 | Val Loss: 0.276270, Val Acc: 0.474227\n",
      "Epoch 385 - Train Loss: 0.270202, Train Acc: 0.503846 | Val Loss: 0.276209, Val Acc: 0.474227\n",
      "Epoch 386 - Train Loss: 0.270113, Train Acc: 0.503846 | Val Loss: 0.276149, Val Acc: 0.474227\n",
      "Epoch 387 - Train Loss: 0.270025, Train Acc: 0.503846 | Val Loss: 0.276089, Val Acc: 0.474227\n",
      "Epoch 388 - Train Loss: 0.269938, Train Acc: 0.503846 | Val Loss: 0.276031, Val Acc: 0.474227\n",
      "Epoch 389 - Train Loss: 0.269852, Train Acc: 0.503846 | Val Loss: 0.275973, Val Acc: 0.474227\n",
      "Epoch 390 - Train Loss: 0.269766, Train Acc: 0.503846 | Val Loss: 0.275915, Val Acc: 0.474227\n",
      "Epoch 391 - Train Loss: 0.269681, Train Acc: 0.503846 | Val Loss: 0.275859, Val Acc: 0.474227\n",
      "Epoch 392 - Train Loss: 0.269597, Train Acc: 0.503846 | Val Loss: 0.275803, Val Acc: 0.474227\n",
      "Epoch 393 - Train Loss: 0.269513, Train Acc: 0.503846 | Val Loss: 0.275748, Val Acc: 0.474227\n",
      "Epoch 394 - Train Loss: 0.269431, Train Acc: 0.503846 | Val Loss: 0.275693, Val Acc: 0.474227\n",
      "Epoch 395 - Train Loss: 0.269349, Train Acc: 0.503846 | Val Loss: 0.275640, Val Acc: 0.474227\n",
      "Epoch 396 - Train Loss: 0.269268, Train Acc: 0.503846 | Val Loss: 0.275586, Val Acc: 0.474227\n",
      "Epoch 397 - Train Loss: 0.269188, Train Acc: 0.503846 | Val Loss: 0.275534, Val Acc: 0.474227\n",
      "Epoch 398 - Train Loss: 0.269108, Train Acc: 0.503846 | Val Loss: 0.275482, Val Acc: 0.474227\n",
      "Epoch 399 - Train Loss: 0.269030, Train Acc: 0.503846 | Val Loss: 0.275431, Val Acc: 0.474227\n",
      "Epoch 400 - Train Loss: 0.268952, Train Acc: 0.503846 | Val Loss: 0.275381, Val Acc: 0.474227\n",
      "Epoch 401 - Train Loss: 0.268874, Train Acc: 0.503846 | Val Loss: 0.275331, Val Acc: 0.474227\n",
      "Epoch 402 - Train Loss: 0.268798, Train Acc: 0.503846 | Val Loss: 0.275282, Val Acc: 0.474227\n",
      "Epoch 403 - Train Loss: 0.268722, Train Acc: 0.503846 | Val Loss: 0.275233, Val Acc: 0.474227\n",
      "Epoch 404 - Train Loss: 0.268647, Train Acc: 0.503846 | Val Loss: 0.275186, Val Acc: 0.474227\n",
      "Epoch 405 - Train Loss: 0.268572, Train Acc: 0.503846 | Val Loss: 0.275138, Val Acc: 0.474227\n",
      "Epoch 406 - Train Loss: 0.268499, Train Acc: 0.503846 | Val Loss: 0.275092, Val Acc: 0.474227\n",
      "Epoch 407 - Train Loss: 0.268426, Train Acc: 0.503846 | Val Loss: 0.275046, Val Acc: 0.474227\n",
      "Epoch 408 - Train Loss: 0.268354, Train Acc: 0.503846 | Val Loss: 0.275001, Val Acc: 0.474227\n",
      "Epoch 409 - Train Loss: 0.268282, Train Acc: 0.503846 | Val Loss: 0.274956, Val Acc: 0.474227\n",
      "Epoch 410 - Train Loss: 0.268211, Train Acc: 0.503846 | Val Loss: 0.274911, Val Acc: 0.474227\n",
      "Epoch 411 - Train Loss: 0.268141, Train Acc: 0.503846 | Val Loss: 0.274867, Val Acc: 0.474227\n",
      "Epoch 412 - Train Loss: 0.268071, Train Acc: 0.503846 | Val Loss: 0.274824, Val Acc: 0.474227\n",
      "Epoch 413 - Train Loss: 0.268002, Train Acc: 0.503846 | Val Loss: 0.274782, Val Acc: 0.474227\n",
      "Epoch 414 - Train Loss: 0.267934, Train Acc: 0.503846 | Val Loss: 0.274740, Val Acc: 0.474227\n",
      "Epoch 415 - Train Loss: 0.267866, Train Acc: 0.503846 | Val Loss: 0.274698, Val Acc: 0.474227\n",
      "Epoch 416 - Train Loss: 0.267799, Train Acc: 0.503846 | Val Loss: 0.274657, Val Acc: 0.474227\n",
      "Epoch 417 - Train Loss: 0.267733, Train Acc: 0.503846 | Val Loss: 0.274617, Val Acc: 0.474227\n",
      "Epoch 418 - Train Loss: 0.267668, Train Acc: 0.503846 | Val Loss: 0.274577, Val Acc: 0.474227\n",
      "Epoch 419 - Train Loss: 0.267603, Train Acc: 0.503846 | Val Loss: 0.274537, Val Acc: 0.474227\n",
      "Epoch 420 - Train Loss: 0.267538, Train Acc: 0.503846 | Val Loss: 0.274498, Val Acc: 0.474227\n",
      "Epoch 421 - Train Loss: 0.267475, Train Acc: 0.503846 | Val Loss: 0.274460, Val Acc: 0.474227\n",
      "Epoch 422 - Train Loss: 0.267412, Train Acc: 0.503846 | Val Loss: 0.274422, Val Acc: 0.474227\n",
      "Epoch 423 - Train Loss: 0.267350, Train Acc: 0.503846 | Val Loss: 0.274385, Val Acc: 0.474227\n",
      "Epoch 424 - Train Loss: 0.267288, Train Acc: 0.503846 | Val Loss: 0.274348, Val Acc: 0.474227\n",
      "Epoch 425 - Train Loss: 0.267227, Train Acc: 0.503846 | Val Loss: 0.274312, Val Acc: 0.474227\n",
      "Epoch 426 - Train Loss: 0.267166, Train Acc: 0.503846 | Val Loss: 0.274276, Val Acc: 0.474227\n",
      "Epoch 427 - Train Loss: 0.267106, Train Acc: 0.503846 | Val Loss: 0.274240, Val Acc: 0.474227\n",
      "Epoch 428 - Train Loss: 0.267047, Train Acc: 0.503846 | Val Loss: 0.274205, Val Acc: 0.474227\n",
      "Epoch 429 - Train Loss: 0.266988, Train Acc: 0.503846 | Val Loss: 0.274171, Val Acc: 0.474227\n",
      "Epoch 430 - Train Loss: 0.266930, Train Acc: 0.503846 | Val Loss: 0.274137, Val Acc: 0.474227\n",
      "Epoch 431 - Train Loss: 0.266872, Train Acc: 0.503846 | Val Loss: 0.274103, Val Acc: 0.474227\n",
      "Epoch 432 - Train Loss: 0.266815, Train Acc: 0.503846 | Val Loss: 0.274070, Val Acc: 0.474227\n",
      "Epoch 433 - Train Loss: 0.266759, Train Acc: 0.503846 | Val Loss: 0.274038, Val Acc: 0.474227\n",
      "Epoch 434 - Train Loss: 0.266703, Train Acc: 0.503846 | Val Loss: 0.274005, Val Acc: 0.474227\n",
      "Epoch 435 - Train Loss: 0.266647, Train Acc: 0.503846 | Val Loss: 0.273974, Val Acc: 0.474227\n",
      "Epoch 436 - Train Loss: 0.266592, Train Acc: 0.503846 | Val Loss: 0.273942, Val Acc: 0.474227\n",
      "Epoch 437 - Train Loss: 0.266537, Train Acc: 0.503846 | Val Loss: 0.273912, Val Acc: 0.474227\n",
      "Epoch 438 - Train Loss: 0.266483, Train Acc: 0.503846 | Val Loss: 0.273881, Val Acc: 0.474227\n",
      "Epoch 439 - Train Loss: 0.266429, Train Acc: 0.503846 | Val Loss: 0.273851, Val Acc: 0.474227\n",
      "Epoch 440 - Train Loss: 0.266376, Train Acc: 0.503846 | Val Loss: 0.273822, Val Acc: 0.474227\n",
      "Epoch 441 - Train Loss: 0.266324, Train Acc: 0.503846 | Val Loss: 0.273792, Val Acc: 0.474227\n",
      "Epoch 442 - Train Loss: 0.266272, Train Acc: 0.503846 | Val Loss: 0.273764, Val Acc: 0.474227\n",
      "Epoch 443 - Train Loss: 0.266220, Train Acc: 0.503846 | Val Loss: 0.273735, Val Acc: 0.474227\n",
      "Epoch 444 - Train Loss: 0.266170, Train Acc: 0.503846 | Val Loss: 0.273707, Val Acc: 0.474227\n",
      "Epoch 445 - Train Loss: 0.266119, Train Acc: 0.503846 | Val Loss: 0.273680, Val Acc: 0.474227\n",
      "Epoch 446 - Train Loss: 0.266070, Train Acc: 0.503846 | Val Loss: 0.273652, Val Acc: 0.474227\n",
      "Epoch 447 - Train Loss: 0.266020, Train Acc: 0.503846 | Val Loss: 0.273626, Val Acc: 0.474227\n",
      "Epoch 448 - Train Loss: 0.265971, Train Acc: 0.503846 | Val Loss: 0.273599, Val Acc: 0.474227\n",
      "Epoch 449 - Train Loss: 0.265923, Train Acc: 0.503846 | Val Loss: 0.273573, Val Acc: 0.474227\n",
      "Epoch 450 - Train Loss: 0.265875, Train Acc: 0.503846 | Val Loss: 0.273547, Val Acc: 0.474227\n",
      "Epoch 451 - Train Loss: 0.265828, Train Acc: 0.503846 | Val Loss: 0.273522, Val Acc: 0.474227\n",
      "Epoch 452 - Train Loss: 0.265781, Train Acc: 0.503846 | Val Loss: 0.273497, Val Acc: 0.474227\n",
      "Epoch 453 - Train Loss: 0.265734, Train Acc: 0.503846 | Val Loss: 0.273473, Val Acc: 0.474227\n",
      "Epoch 454 - Train Loss: 0.265688, Train Acc: 0.503846 | Val Loss: 0.273449, Val Acc: 0.474227\n",
      "Epoch 455 - Train Loss: 0.265643, Train Acc: 0.503846 | Val Loss: 0.273425, Val Acc: 0.474227\n",
      "Epoch 456 - Train Loss: 0.265598, Train Acc: 0.503846 | Val Loss: 0.273401, Val Acc: 0.474227\n",
      "Epoch 457 - Train Loss: 0.265553, Train Acc: 0.503846 | Val Loss: 0.273378, Val Acc: 0.474227\n",
      "Epoch 458 - Train Loss: 0.265509, Train Acc: 0.503846 | Val Loss: 0.273356, Val Acc: 0.474227\n",
      "Epoch 459 - Train Loss: 0.265465, Train Acc: 0.503846 | Val Loss: 0.273333, Val Acc: 0.474227\n",
      "Epoch 460 - Train Loss: 0.265422, Train Acc: 0.503846 | Val Loss: 0.273312, Val Acc: 0.474227\n",
      "Epoch 461 - Train Loss: 0.265379, Train Acc: 0.503846 | Val Loss: 0.273291, Val Acc: 0.474227\n",
      "Epoch 462 - Train Loss: 0.265337, Train Acc: 0.503846 | Val Loss: 0.273270, Val Acc: 0.474227\n",
      "Epoch 463 - Train Loss: 0.265295, Train Acc: 0.503846 | Val Loss: 0.273249, Val Acc: 0.474227\n",
      "Epoch 464 - Train Loss: 0.265253, Train Acc: 0.503846 | Val Loss: 0.273229, Val Acc: 0.474227\n",
      "Epoch 465 - Train Loss: 0.265212, Train Acc: 0.503846 | Val Loss: 0.273209, Val Acc: 0.474227\n",
      "Epoch 466 - Train Loss: 0.265171, Train Acc: 0.503846 | Val Loss: 0.273189, Val Acc: 0.474227\n",
      "Epoch 467 - Train Loss: 0.265131, Train Acc: 0.503846 | Val Loss: 0.273170, Val Acc: 0.474227\n",
      "Epoch 468 - Train Loss: 0.265091, Train Acc: 0.503846 | Val Loss: 0.273151, Val Acc: 0.474227\n",
      "Epoch 469 - Train Loss: 0.265051, Train Acc: 0.503846 | Val Loss: 0.273132, Val Acc: 0.474227\n",
      "Epoch 470 - Train Loss: 0.265012, Train Acc: 0.503846 | Val Loss: 0.273114, Val Acc: 0.474227\n",
      "Epoch 471 - Train Loss: 0.264973, Train Acc: 0.503846 | Val Loss: 0.273095, Val Acc: 0.474227\n",
      "Epoch 472 - Train Loss: 0.264935, Train Acc: 0.503846 | Val Loss: 0.273077, Val Acc: 0.474227\n",
      "Epoch 473 - Train Loss: 0.264897, Train Acc: 0.503846 | Val Loss: 0.273060, Val Acc: 0.474227\n",
      "Epoch 474 - Train Loss: 0.264860, Train Acc: 0.503846 | Val Loss: 0.273042, Val Acc: 0.474227\n",
      "Epoch 475 - Train Loss: 0.264822, Train Acc: 0.503846 | Val Loss: 0.273025, Val Acc: 0.474227\n",
      "Epoch 476 - Train Loss: 0.264786, Train Acc: 0.503846 | Val Loss: 0.273008, Val Acc: 0.474227\n",
      "Epoch 477 - Train Loss: 0.264749, Train Acc: 0.503846 | Val Loss: 0.272991, Val Acc: 0.474227\n",
      "Epoch 478 - Train Loss: 0.264713, Train Acc: 0.503846 | Val Loss: 0.272975, Val Acc: 0.474227\n",
      "Epoch 479 - Train Loss: 0.264677, Train Acc: 0.503846 | Val Loss: 0.272959, Val Acc: 0.474227\n",
      "Epoch 480 - Train Loss: 0.264642, Train Acc: 0.503846 | Val Loss: 0.272943, Val Acc: 0.474227\n",
      "Epoch 481 - Train Loss: 0.264607, Train Acc: 0.503846 | Val Loss: 0.272927, Val Acc: 0.474227\n",
      "Epoch 482 - Train Loss: 0.264572, Train Acc: 0.503846 | Val Loss: 0.272911, Val Acc: 0.474227\n",
      "Epoch 483 - Train Loss: 0.264537, Train Acc: 0.503846 | Val Loss: 0.272897, Val Acc: 0.474227\n",
      "Epoch 484 - Train Loss: 0.264503, Train Acc: 0.503846 | Val Loss: 0.272883, Val Acc: 0.474227\n",
      "Epoch 485 - Train Loss: 0.264469, Train Acc: 0.503846 | Val Loss: 0.272869, Val Acc: 0.474227\n",
      "Epoch 486 - Train Loss: 0.264435, Train Acc: 0.503846 | Val Loss: 0.272855, Val Acc: 0.474227\n",
      "Epoch 487 - Train Loss: 0.264402, Train Acc: 0.503846 | Val Loss: 0.272841, Val Acc: 0.474227\n",
      "Epoch 488 - Train Loss: 0.264369, Train Acc: 0.503846 | Val Loss: 0.272828, Val Acc: 0.474227\n",
      "Epoch 489 - Train Loss: 0.264336, Train Acc: 0.503846 | Val Loss: 0.272814, Val Acc: 0.474227\n",
      "Epoch 490 - Train Loss: 0.264304, Train Acc: 0.503846 | Val Loss: 0.272801, Val Acc: 0.474227\n",
      "Epoch 491 - Train Loss: 0.264271, Train Acc: 0.503846 | Val Loss: 0.272789, Val Acc: 0.474227\n",
      "Epoch 492 - Train Loss: 0.264239, Train Acc: 0.503846 | Val Loss: 0.272776, Val Acc: 0.474227\n",
      "Epoch 493 - Train Loss: 0.264208, Train Acc: 0.503846 | Val Loss: 0.272764, Val Acc: 0.474227\n",
      "Epoch 494 - Train Loss: 0.264176, Train Acc: 0.503846 | Val Loss: 0.272752, Val Acc: 0.474227\n",
      "Epoch 495 - Train Loss: 0.264145, Train Acc: 0.503846 | Val Loss: 0.272740, Val Acc: 0.474227\n",
      "Epoch 496 - Train Loss: 0.264114, Train Acc: 0.503846 | Val Loss: 0.272728, Val Acc: 0.474227\n",
      "Epoch 497 - Train Loss: 0.264083, Train Acc: 0.503846 | Val Loss: 0.272716, Val Acc: 0.474227\n",
      "Epoch 498 - Train Loss: 0.264053, Train Acc: 0.503846 | Val Loss: 0.272704, Val Acc: 0.474227\n",
      "Epoch 499 - Train Loss: 0.264023, Train Acc: 0.503846 | Val Loss: 0.272693, Val Acc: 0.474227\n",
      "Epoch 500 - Train Loss: 0.263993, Train Acc: 0.503846 | Val Loss: 0.272682, Val Acc: 0.474227\n",
      "Epoch 501 - Train Loss: 0.263963, Train Acc: 0.503846 | Val Loss: 0.272671, Val Acc: 0.474227\n",
      "Epoch 502 - Train Loss: 0.263934, Train Acc: 0.503846 | Val Loss: 0.272660, Val Acc: 0.474227\n",
      "Epoch 503 - Train Loss: 0.263905, Train Acc: 0.503846 | Val Loss: 0.272650, Val Acc: 0.474227\n",
      "Epoch 504 - Train Loss: 0.263876, Train Acc: 0.503846 | Val Loss: 0.272639, Val Acc: 0.474227\n",
      "Epoch 505 - Train Loss: 0.263847, Train Acc: 0.503846 | Val Loss: 0.272629, Val Acc: 0.474227\n",
      "Epoch 506 - Train Loss: 0.263818, Train Acc: 0.503846 | Val Loss: 0.272619, Val Acc: 0.474227\n",
      "Epoch 507 - Train Loss: 0.263790, Train Acc: 0.503846 | Val Loss: 0.272608, Val Acc: 0.474227\n",
      "Epoch 508 - Train Loss: 0.263762, Train Acc: 0.503846 | Val Loss: 0.272598, Val Acc: 0.474227\n",
      "Epoch 509 - Train Loss: 0.263734, Train Acc: 0.503846 | Val Loss: 0.272588, Val Acc: 0.474227\n",
      "Epoch 510 - Train Loss: 0.263707, Train Acc: 0.503846 | Val Loss: 0.272579, Val Acc: 0.474227\n",
      "Epoch 511 - Train Loss: 0.263680, Train Acc: 0.503846 | Val Loss: 0.272569, Val Acc: 0.474227\n",
      "Epoch 512 - Train Loss: 0.263653, Train Acc: 0.503846 | Val Loss: 0.272559, Val Acc: 0.474227\n",
      "Epoch 513 - Train Loss: 0.263627, Train Acc: 0.503846 | Val Loss: 0.272550, Val Acc: 0.474227\n",
      "Epoch 514 - Train Loss: 0.263601, Train Acc: 0.503846 | Val Loss: 0.272540, Val Acc: 0.474227\n",
      "Epoch 515 - Train Loss: 0.263575, Train Acc: 0.503846 | Val Loss: 0.272531, Val Acc: 0.474227\n",
      "Epoch 516 - Train Loss: 0.263549, Train Acc: 0.503846 | Val Loss: 0.272521, Val Acc: 0.474227\n",
      "Epoch 517 - Train Loss: 0.263524, Train Acc: 0.503846 | Val Loss: 0.272512, Val Acc: 0.474227\n",
      "Epoch 518 - Train Loss: 0.263499, Train Acc: 0.503846 | Val Loss: 0.272503, Val Acc: 0.474227\n",
      "Epoch 519 - Train Loss: 0.263474, Train Acc: 0.503846 | Val Loss: 0.272494, Val Acc: 0.474227\n",
      "Epoch 520 - Train Loss: 0.263450, Train Acc: 0.503846 | Val Loss: 0.272485, Val Acc: 0.474227\n",
      "Epoch 521 - Train Loss: 0.263425, Train Acc: 0.503846 | Val Loss: 0.272476, Val Acc: 0.474227\n",
      "Epoch 522 - Train Loss: 0.263401, Train Acc: 0.503846 | Val Loss: 0.272468, Val Acc: 0.474227\n",
      "Epoch 523 - Train Loss: 0.263377, Train Acc: 0.503846 | Val Loss: 0.272459, Val Acc: 0.474227\n",
      "Epoch 524 - Train Loss: 0.263353, Train Acc: 0.503846 | Val Loss: 0.272451, Val Acc: 0.474227\n",
      "Epoch 525 - Train Loss: 0.263330, Train Acc: 0.503846 | Val Loss: 0.272442, Val Acc: 0.474227\n",
      "Epoch 526 - Train Loss: 0.263307, Train Acc: 0.503846 | Val Loss: 0.272434, Val Acc: 0.474227\n",
      "Epoch 527 - Train Loss: 0.263284, Train Acc: 0.503846 | Val Loss: 0.272426, Val Acc: 0.474227\n",
      "Epoch 528 - Train Loss: 0.263261, Train Acc: 0.503846 | Val Loss: 0.272418, Val Acc: 0.474227\n",
      "Epoch 529 - Train Loss: 0.263238, Train Acc: 0.503846 | Val Loss: 0.272410, Val Acc: 0.474227\n",
      "Epoch 530 - Train Loss: 0.263216, Train Acc: 0.503846 | Val Loss: 0.272402, Val Acc: 0.474227\n",
      "Epoch 531 - Train Loss: 0.263193, Train Acc: 0.503846 | Val Loss: 0.272394, Val Acc: 0.474227\n",
      "Epoch 532 - Train Loss: 0.263171, Train Acc: 0.503846 | Val Loss: 0.272386, Val Acc: 0.474227\n",
      "Epoch 533 - Train Loss: 0.263149, Train Acc: 0.503846 | Val Loss: 0.272378, Val Acc: 0.474227\n",
      "Epoch 534 - Train Loss: 0.263127, Train Acc: 0.503846 | Val Loss: 0.272370, Val Acc: 0.474227\n",
      "Epoch 535 - Train Loss: 0.263106, Train Acc: 0.503846 | Val Loss: 0.272362, Val Acc: 0.474227\n",
      "Epoch 536 - Train Loss: 0.263084, Train Acc: 0.503846 | Val Loss: 0.272355, Val Acc: 0.474227\n",
      "Epoch 537 - Train Loss: 0.263063, Train Acc: 0.503846 | Val Loss: 0.272347, Val Acc: 0.474227\n",
      "Epoch 538 - Train Loss: 0.263041, Train Acc: 0.503846 | Val Loss: 0.272340, Val Acc: 0.474227\n",
      "Epoch 539 - Train Loss: 0.263020, Train Acc: 0.503846 | Val Loss: 0.272332, Val Acc: 0.474227\n",
      "Epoch 540 - Train Loss: 0.262999, Train Acc: 0.503846 | Val Loss: 0.272325, Val Acc: 0.474227\n",
      "Epoch 541 - Train Loss: 0.262979, Train Acc: 0.503846 | Val Loss: 0.272318, Val Acc: 0.474227\n",
      "Epoch 542 - Train Loss: 0.262958, Train Acc: 0.503846 | Val Loss: 0.272310, Val Acc: 0.474227\n",
      "Epoch 543 - Train Loss: 0.262937, Train Acc: 0.503846 | Val Loss: 0.272303, Val Acc: 0.474227\n",
      "Epoch 544 - Train Loss: 0.262917, Train Acc: 0.503846 | Val Loss: 0.272296, Val Acc: 0.474227\n",
      "Epoch 545 - Train Loss: 0.262897, Train Acc: 0.503846 | Val Loss: 0.272289, Val Acc: 0.474227\n",
      "Epoch 546 - Train Loss: 0.262876, Train Acc: 0.503846 | Val Loss: 0.272282, Val Acc: 0.474227\n",
      "Epoch 547 - Train Loss: 0.262856, Train Acc: 0.503846 | Val Loss: 0.272275, Val Acc: 0.474227\n",
      "Epoch 548 - Train Loss: 0.262837, Train Acc: 0.503846 | Val Loss: 0.272268, Val Acc: 0.474227\n",
      "Epoch 549 - Train Loss: 0.262817, Train Acc: 0.503846 | Val Loss: 0.272261, Val Acc: 0.474227\n",
      "Epoch 550 - Train Loss: 0.262797, Train Acc: 0.503846 | Val Loss: 0.272255, Val Acc: 0.474227\n",
      "Epoch 551 - Train Loss: 0.262778, Train Acc: 0.503846 | Val Loss: 0.272248, Val Acc: 0.474227\n",
      "Epoch 552 - Train Loss: 0.262758, Train Acc: 0.503846 | Val Loss: 0.272241, Val Acc: 0.474227\n",
      "Epoch 553 - Train Loss: 0.262739, Train Acc: 0.503846 | Val Loss: 0.272234, Val Acc: 0.474227\n",
      "Epoch 554 - Train Loss: 0.262720, Train Acc: 0.503846 | Val Loss: 0.272228, Val Acc: 0.474227\n",
      "Epoch 555 - Train Loss: 0.262701, Train Acc: 0.503846 | Val Loss: 0.272221, Val Acc: 0.474227\n",
      "Epoch 556 - Train Loss: 0.262682, Train Acc: 0.503846 | Val Loss: 0.272215, Val Acc: 0.474227\n",
      "Epoch 557 - Train Loss: 0.262663, Train Acc: 0.503846 | Val Loss: 0.272209, Val Acc: 0.474227\n",
      "Epoch 558 - Train Loss: 0.262645, Train Acc: 0.503846 | Val Loss: 0.272203, Val Acc: 0.474227\n",
      "Epoch 559 - Train Loss: 0.262626, Train Acc: 0.503846 | Val Loss: 0.272198, Val Acc: 0.474227\n",
      "Epoch 560 - Train Loss: 0.262608, Train Acc: 0.503846 | Val Loss: 0.272192, Val Acc: 0.474227\n",
      "Epoch 561 - Train Loss: 0.262590, Train Acc: 0.503846 | Val Loss: 0.272186, Val Acc: 0.474227\n",
      "Epoch 562 - Train Loss: 0.262572, Train Acc: 0.503846 | Val Loss: 0.272180, Val Acc: 0.474227\n",
      "Epoch 563 - Train Loss: 0.262553, Train Acc: 0.503846 | Val Loss: 0.272174, Val Acc: 0.474227\n",
      "Epoch 564 - Train Loss: 0.262535, Train Acc: 0.503846 | Val Loss: 0.272169, Val Acc: 0.474227\n",
      "Epoch 565 - Train Loss: 0.262518, Train Acc: 0.503846 | Val Loss: 0.272163, Val Acc: 0.474227\n",
      "Epoch 566 - Train Loss: 0.262500, Train Acc: 0.503846 | Val Loss: 0.272157, Val Acc: 0.474227\n",
      "Epoch 567 - Train Loss: 0.262482, Train Acc: 0.503846 | Val Loss: 0.272152, Val Acc: 0.474227\n",
      "Epoch 568 - Train Loss: 0.262464, Train Acc: 0.503846 | Val Loss: 0.272146, Val Acc: 0.474227\n",
      "Epoch 569 - Train Loss: 0.262447, Train Acc: 0.503846 | Val Loss: 0.272141, Val Acc: 0.474227\n",
      "Epoch 570 - Train Loss: 0.262430, Train Acc: 0.503846 | Val Loss: 0.272135, Val Acc: 0.474227\n",
      "Epoch 571 - Train Loss: 0.262412, Train Acc: 0.503846 | Val Loss: 0.272130, Val Acc: 0.474227\n",
      "Epoch 572 - Train Loss: 0.262395, Train Acc: 0.503846 | Val Loss: 0.272124, Val Acc: 0.474227\n",
      "Epoch 573 - Train Loss: 0.262378, Train Acc: 0.503846 | Val Loss: 0.272119, Val Acc: 0.474227\n",
      "Epoch 574 - Train Loss: 0.262360, Train Acc: 0.503846 | Val Loss: 0.272113, Val Acc: 0.474227\n",
      "Epoch 575 - Train Loss: 0.262343, Train Acc: 0.503846 | Val Loss: 0.272108, Val Acc: 0.474227\n",
      "Epoch 576 - Train Loss: 0.262326, Train Acc: 0.503846 | Val Loss: 0.272103, Val Acc: 0.474227\n",
      "Epoch 577 - Train Loss: 0.262309, Train Acc: 0.503846 | Val Loss: 0.272097, Val Acc: 0.474227\n",
      "Epoch 578 - Train Loss: 0.262292, Train Acc: 0.503846 | Val Loss: 0.272092, Val Acc: 0.474227\n",
      "Epoch 579 - Train Loss: 0.262275, Train Acc: 0.503846 | Val Loss: 0.272087, Val Acc: 0.474227\n",
      "Epoch 580 - Train Loss: 0.262259, Train Acc: 0.503846 | Val Loss: 0.272081, Val Acc: 0.474227\n",
      "Epoch 581 - Train Loss: 0.262242, Train Acc: 0.503846 | Val Loss: 0.272076, Val Acc: 0.474227\n",
      "Epoch 582 - Train Loss: 0.262225, Train Acc: 0.503846 | Val Loss: 0.272071, Val Acc: 0.474227\n",
      "Epoch 583 - Train Loss: 0.262209, Train Acc: 0.503846 | Val Loss: 0.272066, Val Acc: 0.474227\n",
      "Epoch 584 - Train Loss: 0.262192, Train Acc: 0.503846 | Val Loss: 0.272061, Val Acc: 0.474227\n",
      "Epoch 585 - Train Loss: 0.262175, Train Acc: 0.503846 | Val Loss: 0.272056, Val Acc: 0.474227\n",
      "Epoch 586 - Train Loss: 0.262159, Train Acc: 0.503846 | Val Loss: 0.272051, Val Acc: 0.474227\n",
      "Epoch 587 - Train Loss: 0.262142, Train Acc: 0.503846 | Val Loss: 0.272046, Val Acc: 0.474227\n",
      "Epoch 588 - Train Loss: 0.262126, Train Acc: 0.503846 | Val Loss: 0.272041, Val Acc: 0.474227\n",
      "Epoch 589 - Train Loss: 0.262110, Train Acc: 0.503846 | Val Loss: 0.272035, Val Acc: 0.474227\n",
      "Epoch 590 - Train Loss: 0.262094, Train Acc: 0.503846 | Val Loss: 0.272030, Val Acc: 0.474227\n",
      "Epoch 591 - Train Loss: 0.262077, Train Acc: 0.503846 | Val Loss: 0.272025, Val Acc: 0.474227\n",
      "Epoch 592 - Train Loss: 0.262061, Train Acc: 0.503846 | Val Loss: 0.272020, Val Acc: 0.474227\n",
      "Epoch 593 - Train Loss: 0.262045, Train Acc: 0.503846 | Val Loss: 0.272015, Val Acc: 0.474227\n",
      "Epoch 594 - Train Loss: 0.262030, Train Acc: 0.503846 | Val Loss: 0.272010, Val Acc: 0.474227\n",
      "Epoch 595 - Train Loss: 0.262014, Train Acc: 0.503846 | Val Loss: 0.272005, Val Acc: 0.474227\n",
      "Epoch 596 - Train Loss: 0.261998, Train Acc: 0.503846 | Val Loss: 0.272000, Val Acc: 0.474227\n",
      "Epoch 597 - Train Loss: 0.261983, Train Acc: 0.503846 | Val Loss: 0.271995, Val Acc: 0.474227\n",
      "Epoch 598 - Train Loss: 0.261967, Train Acc: 0.503846 | Val Loss: 0.271990, Val Acc: 0.474227\n",
      "Epoch 599 - Train Loss: 0.261952, Train Acc: 0.503846 | Val Loss: 0.271984, Val Acc: 0.474227\n",
      "Epoch 600 - Train Loss: 0.261937, Train Acc: 0.503846 | Val Loss: 0.271978, Val Acc: 0.474227\n",
      "Epoch 601 - Train Loss: 0.261921, Train Acc: 0.503846 | Val Loss: 0.271972, Val Acc: 0.474227\n",
      "Epoch 602 - Train Loss: 0.261906, Train Acc: 0.503846 | Val Loss: 0.271966, Val Acc: 0.474227\n",
      "Epoch 603 - Train Loss: 0.261891, Train Acc: 0.503846 | Val Loss: 0.271961, Val Acc: 0.474227\n",
      "Epoch 604 - Train Loss: 0.261876, Train Acc: 0.503846 | Val Loss: 0.271955, Val Acc: 0.474227\n",
      "Epoch 605 - Train Loss: 0.261861, Train Acc: 0.503846 | Val Loss: 0.271949, Val Acc: 0.474227\n",
      "Epoch 606 - Train Loss: 0.261846, Train Acc: 0.503846 | Val Loss: 0.271943, Val Acc: 0.474227\n",
      "Epoch 607 - Train Loss: 0.261831, Train Acc: 0.503846 | Val Loss: 0.271937, Val Acc: 0.474227\n",
      "Epoch 608 - Train Loss: 0.261816, Train Acc: 0.503846 | Val Loss: 0.271931, Val Acc: 0.474227\n",
      "Epoch 609 - Train Loss: 0.261801, Train Acc: 0.503846 | Val Loss: 0.271925, Val Acc: 0.474227\n",
      "Epoch 610 - Train Loss: 0.261786, Train Acc: 0.503846 | Val Loss: 0.271919, Val Acc: 0.474227\n",
      "Epoch 611 - Train Loss: 0.261772, Train Acc: 0.503846 | Val Loss: 0.271913, Val Acc: 0.474227\n",
      "Epoch 612 - Train Loss: 0.261757, Train Acc: 0.503846 | Val Loss: 0.271907, Val Acc: 0.474227\n",
      "Epoch 613 - Train Loss: 0.261743, Train Acc: 0.503846 | Val Loss: 0.271902, Val Acc: 0.474227\n",
      "Epoch 614 - Train Loss: 0.261728, Train Acc: 0.503846 | Val Loss: 0.271896, Val Acc: 0.474227\n",
      "Epoch 615 - Train Loss: 0.261714, Train Acc: 0.503846 | Val Loss: 0.271890, Val Acc: 0.474227\n",
      "Epoch 616 - Train Loss: 0.261700, Train Acc: 0.503846 | Val Loss: 0.271884, Val Acc: 0.474227\n",
      "Epoch 617 - Train Loss: 0.261685, Train Acc: 0.503846 | Val Loss: 0.271878, Val Acc: 0.474227\n",
      "Epoch 618 - Train Loss: 0.261671, Train Acc: 0.503846 | Val Loss: 0.271872, Val Acc: 0.474227\n",
      "Epoch 619 - Train Loss: 0.261657, Train Acc: 0.503846 | Val Loss: 0.271866, Val Acc: 0.474227\n",
      "Epoch 620 - Train Loss: 0.261642, Train Acc: 0.503846 | Val Loss: 0.271860, Val Acc: 0.474227\n",
      "Epoch 621 - Train Loss: 0.261628, Train Acc: 0.503846 | Val Loss: 0.271854, Val Acc: 0.474227\n",
      "Epoch 622 - Train Loss: 0.261614, Train Acc: 0.503846 | Val Loss: 0.271848, Val Acc: 0.474227\n",
      "Epoch 623 - Train Loss: 0.261600, Train Acc: 0.503846 | Val Loss: 0.271842, Val Acc: 0.474227\n",
      "Epoch 624 - Train Loss: 0.261586, Train Acc: 0.503846 | Val Loss: 0.271836, Val Acc: 0.474227\n",
      "Epoch 625 - Train Loss: 0.261572, Train Acc: 0.503846 | Val Loss: 0.271830, Val Acc: 0.474227\n",
      "Epoch 626 - Train Loss: 0.261558, Train Acc: 0.503846 | Val Loss: 0.271824, Val Acc: 0.474227\n",
      "Epoch 627 - Train Loss: 0.261544, Train Acc: 0.503846 | Val Loss: 0.271818, Val Acc: 0.474227\n",
      "Epoch 628 - Train Loss: 0.261530, Train Acc: 0.503846 | Val Loss: 0.271812, Val Acc: 0.474227\n",
      "Epoch 629 - Train Loss: 0.261516, Train Acc: 0.503846 | Val Loss: 0.271806, Val Acc: 0.474227\n",
      "Epoch 630 - Train Loss: 0.261502, Train Acc: 0.503846 | Val Loss: 0.271800, Val Acc: 0.474227\n",
      "Epoch 631 - Train Loss: 0.261488, Train Acc: 0.503846 | Val Loss: 0.271794, Val Acc: 0.474227\n",
      "Epoch 632 - Train Loss: 0.261475, Train Acc: 0.503846 | Val Loss: 0.271787, Val Acc: 0.474227\n",
      "Epoch 633 - Train Loss: 0.261461, Train Acc: 0.503846 | Val Loss: 0.271781, Val Acc: 0.474227\n",
      "Epoch 634 - Train Loss: 0.261447, Train Acc: 0.503846 | Val Loss: 0.271775, Val Acc: 0.474227\n",
      "Epoch 635 - Train Loss: 0.261433, Train Acc: 0.503846 | Val Loss: 0.271769, Val Acc: 0.474227\n",
      "Epoch 636 - Train Loss: 0.261420, Train Acc: 0.503846 | Val Loss: 0.271762, Val Acc: 0.474227\n",
      "Epoch 637 - Train Loss: 0.261406, Train Acc: 0.503846 | Val Loss: 0.271756, Val Acc: 0.474227\n",
      "Epoch 638 - Train Loss: 0.261393, Train Acc: 0.503846 | Val Loss: 0.271750, Val Acc: 0.474227\n",
      "Epoch 639 - Train Loss: 0.261379, Train Acc: 0.503846 | Val Loss: 0.271743, Val Acc: 0.474227\n",
      "Epoch 640 - Train Loss: 0.261365, Train Acc: 0.503846 | Val Loss: 0.271737, Val Acc: 0.474227\n",
      "Epoch 641 - Train Loss: 0.261352, Train Acc: 0.503846 | Val Loss: 0.271731, Val Acc: 0.474227\n",
      "Epoch 642 - Train Loss: 0.261338, Train Acc: 0.503846 | Val Loss: 0.271724, Val Acc: 0.474227\n",
      "Epoch 643 - Train Loss: 0.261325, Train Acc: 0.503846 | Val Loss: 0.271718, Val Acc: 0.474227\n",
      "Epoch 644 - Train Loss: 0.261311, Train Acc: 0.503846 | Val Loss: 0.271712, Val Acc: 0.474227\n",
      "Epoch 645 - Train Loss: 0.261298, Train Acc: 0.503846 | Val Loss: 0.271705, Val Acc: 0.474227\n",
      "Epoch 646 - Train Loss: 0.261284, Train Acc: 0.503846 | Val Loss: 0.271699, Val Acc: 0.474227\n",
      "Epoch 647 - Train Loss: 0.261271, Train Acc: 0.503846 | Val Loss: 0.271693, Val Acc: 0.474227\n",
      "Epoch 648 - Train Loss: 0.261257, Train Acc: 0.503846 | Val Loss: 0.271686, Val Acc: 0.474227\n",
      "Epoch 649 - Train Loss: 0.261244, Train Acc: 0.503846 | Val Loss: 0.271680, Val Acc: 0.474227\n",
      "Epoch 650 - Train Loss: 0.261230, Train Acc: 0.503846 | Val Loss: 0.271674, Val Acc: 0.474227\n",
      "Epoch 651 - Train Loss: 0.261217, Train Acc: 0.503846 | Val Loss: 0.271667, Val Acc: 0.474227\n",
      "Epoch 652 - Train Loss: 0.261203, Train Acc: 0.503846 | Val Loss: 0.271661, Val Acc: 0.474227\n",
      "Epoch 653 - Train Loss: 0.261190, Train Acc: 0.503846 | Val Loss: 0.271654, Val Acc: 0.474227\n",
      "Epoch 654 - Train Loss: 0.261176, Train Acc: 0.503846 | Val Loss: 0.271648, Val Acc: 0.474227\n",
      "Epoch 655 - Train Loss: 0.261163, Train Acc: 0.503846 | Val Loss: 0.271641, Val Acc: 0.474227\n",
      "Epoch 656 - Train Loss: 0.261150, Train Acc: 0.503846 | Val Loss: 0.271634, Val Acc: 0.474227\n",
      "Epoch 657 - Train Loss: 0.261136, Train Acc: 0.503846 | Val Loss: 0.271628, Val Acc: 0.474227\n",
      "Epoch 658 - Train Loss: 0.261123, Train Acc: 0.503846 | Val Loss: 0.271621, Val Acc: 0.474227\n",
      "Epoch 659 - Train Loss: 0.261109, Train Acc: 0.503846 | Val Loss: 0.271614, Val Acc: 0.474227\n",
      "Epoch 660 - Train Loss: 0.261096, Train Acc: 0.503846 | Val Loss: 0.271607, Val Acc: 0.474227\n",
      "Epoch 661 - Train Loss: 0.261083, Train Acc: 0.503846 | Val Loss: 0.271601, Val Acc: 0.474227\n",
      "Epoch 662 - Train Loss: 0.261069, Train Acc: 0.503846 | Val Loss: 0.271594, Val Acc: 0.474227\n",
      "Epoch 663 - Train Loss: 0.261056, Train Acc: 0.503846 | Val Loss: 0.271587, Val Acc: 0.474227\n",
      "Epoch 664 - Train Loss: 0.261043, Train Acc: 0.503846 | Val Loss: 0.271580, Val Acc: 0.474227\n",
      "Epoch 665 - Train Loss: 0.261029, Train Acc: 0.503846 | Val Loss: 0.271574, Val Acc: 0.474227\n",
      "Epoch 666 - Train Loss: 0.261016, Train Acc: 0.503846 | Val Loss: 0.271567, Val Acc: 0.474227\n",
      "Epoch 667 - Train Loss: 0.261003, Train Acc: 0.503846 | Val Loss: 0.271561, Val Acc: 0.474227\n",
      "Epoch 668 - Train Loss: 0.260990, Train Acc: 0.503846 | Val Loss: 0.271554, Val Acc: 0.474227\n",
      "Epoch 669 - Train Loss: 0.260977, Train Acc: 0.503846 | Val Loss: 0.271548, Val Acc: 0.474227\n",
      "Epoch 670 - Train Loss: 0.260964, Train Acc: 0.503846 | Val Loss: 0.271541, Val Acc: 0.474227\n",
      "Epoch 671 - Train Loss: 0.260951, Train Acc: 0.503846 | Val Loss: 0.271534, Val Acc: 0.474227\n",
      "Epoch 672 - Train Loss: 0.260937, Train Acc: 0.503846 | Val Loss: 0.271528, Val Acc: 0.474227\n",
      "Epoch 673 - Train Loss: 0.260924, Train Acc: 0.503846 | Val Loss: 0.271521, Val Acc: 0.474227\n",
      "Epoch 674 - Train Loss: 0.260911, Train Acc: 0.503846 | Val Loss: 0.271515, Val Acc: 0.474227\n",
      "Epoch 675 - Train Loss: 0.260898, Train Acc: 0.503846 | Val Loss: 0.271508, Val Acc: 0.474227\n",
      "Epoch 676 - Train Loss: 0.260885, Train Acc: 0.503846 | Val Loss: 0.271501, Val Acc: 0.474227\n",
      "Epoch 677 - Train Loss: 0.260872, Train Acc: 0.503846 | Val Loss: 0.271495, Val Acc: 0.474227\n",
      "Epoch 678 - Train Loss: 0.260859, Train Acc: 0.503846 | Val Loss: 0.271488, Val Acc: 0.474227\n",
      "Epoch 679 - Train Loss: 0.260846, Train Acc: 0.503846 | Val Loss: 0.271481, Val Acc: 0.474227\n",
      "Epoch 680 - Train Loss: 0.260833, Train Acc: 0.503846 | Val Loss: 0.271474, Val Acc: 0.474227\n",
      "Epoch 681 - Train Loss: 0.260819, Train Acc: 0.503846 | Val Loss: 0.271468, Val Acc: 0.474227\n",
      "Epoch 682 - Train Loss: 0.260807, Train Acc: 0.503846 | Val Loss: 0.271461, Val Acc: 0.474227\n",
      "Epoch 683 - Train Loss: 0.260794, Train Acc: 0.503846 | Val Loss: 0.271454, Val Acc: 0.474227\n",
      "Epoch 684 - Train Loss: 0.260781, Train Acc: 0.503846 | Val Loss: 0.271447, Val Acc: 0.474227\n",
      "Epoch 685 - Train Loss: 0.260768, Train Acc: 0.503846 | Val Loss: 0.271440, Val Acc: 0.474227\n",
      "Epoch 686 - Train Loss: 0.260755, Train Acc: 0.503846 | Val Loss: 0.271433, Val Acc: 0.474227\n",
      "Epoch 687 - Train Loss: 0.260742, Train Acc: 0.503846 | Val Loss: 0.271426, Val Acc: 0.474227\n",
      "Epoch 688 - Train Loss: 0.260729, Train Acc: 0.503846 | Val Loss: 0.271419, Val Acc: 0.474227\n",
      "Epoch 689 - Train Loss: 0.260716, Train Acc: 0.503846 | Val Loss: 0.271411, Val Acc: 0.474227\n",
      "Epoch 690 - Train Loss: 0.260703, Train Acc: 0.503846 | Val Loss: 0.271404, Val Acc: 0.474227\n",
      "Epoch 691 - Train Loss: 0.260690, Train Acc: 0.503846 | Val Loss: 0.271397, Val Acc: 0.474227\n",
      "Epoch 692 - Train Loss: 0.260678, Train Acc: 0.503846 | Val Loss: 0.271390, Val Acc: 0.474227\n",
      "Epoch 693 - Train Loss: 0.260665, Train Acc: 0.503846 | Val Loss: 0.271382, Val Acc: 0.474227\n",
      "Epoch 694 - Train Loss: 0.260652, Train Acc: 0.503846 | Val Loss: 0.271374, Val Acc: 0.474227\n",
      "Epoch 695 - Train Loss: 0.260638, Train Acc: 0.503846 | Val Loss: 0.271367, Val Acc: 0.474227\n",
      "Epoch 696 - Train Loss: 0.260625, Train Acc: 0.503846 | Val Loss: 0.271359, Val Acc: 0.474227\n",
      "Epoch 697 - Train Loss: 0.260612, Train Acc: 0.503846 | Val Loss: 0.271351, Val Acc: 0.474227\n",
      "Epoch 698 - Train Loss: 0.260599, Train Acc: 0.503846 | Val Loss: 0.271344, Val Acc: 0.474227\n",
      "Epoch 699 - Train Loss: 0.260586, Train Acc: 0.503846 | Val Loss: 0.271336, Val Acc: 0.474227\n",
      "Epoch 700 - Train Loss: 0.260573, Train Acc: 0.503846 | Val Loss: 0.271328, Val Acc: 0.474227\n",
      "Epoch 701 - Train Loss: 0.260560, Train Acc: 0.503846 | Val Loss: 0.271320, Val Acc: 0.474227\n",
      "Epoch 702 - Train Loss: 0.260546, Train Acc: 0.503846 | Val Loss: 0.271313, Val Acc: 0.474227\n",
      "Epoch 703 - Train Loss: 0.260533, Train Acc: 0.503846 | Val Loss: 0.271305, Val Acc: 0.474227\n",
      "Epoch 704 - Train Loss: 0.260520, Train Acc: 0.503846 | Val Loss: 0.271297, Val Acc: 0.474227\n",
      "Epoch 705 - Train Loss: 0.260507, Train Acc: 0.503846 | Val Loss: 0.271289, Val Acc: 0.474227\n",
      "Epoch 706 - Train Loss: 0.260493, Train Acc: 0.503846 | Val Loss: 0.271281, Val Acc: 0.474227\n",
      "Epoch 707 - Train Loss: 0.260480, Train Acc: 0.503846 | Val Loss: 0.271273, Val Acc: 0.474227\n",
      "Epoch 708 - Train Loss: 0.260467, Train Acc: 0.503846 | Val Loss: 0.271265, Val Acc: 0.474227\n",
      "Epoch 709 - Train Loss: 0.260453, Train Acc: 0.503846 | Val Loss: 0.271256, Val Acc: 0.474227\n",
      "Epoch 710 - Train Loss: 0.260440, Train Acc: 0.503846 | Val Loss: 0.271248, Val Acc: 0.474227\n",
      "Epoch 711 - Train Loss: 0.260426, Train Acc: 0.503846 | Val Loss: 0.271239, Val Acc: 0.474227\n",
      "Epoch 712 - Train Loss: 0.260413, Train Acc: 0.503846 | Val Loss: 0.271230, Val Acc: 0.474227\n",
      "Epoch 713 - Train Loss: 0.260399, Train Acc: 0.503846 | Val Loss: 0.271222, Val Acc: 0.474227\n",
      "Epoch 714 - Train Loss: 0.260386, Train Acc: 0.503846 | Val Loss: 0.271213, Val Acc: 0.474227\n",
      "Epoch 715 - Train Loss: 0.260372, Train Acc: 0.503846 | Val Loss: 0.271203, Val Acc: 0.474227\n",
      "Epoch 716 - Train Loss: 0.260358, Train Acc: 0.503846 | Val Loss: 0.271194, Val Acc: 0.474227\n",
      "Epoch 717 - Train Loss: 0.260345, Train Acc: 0.503846 | Val Loss: 0.271185, Val Acc: 0.474227\n",
      "Epoch 718 - Train Loss: 0.260331, Train Acc: 0.503846 | Val Loss: 0.271176, Val Acc: 0.474227\n",
      "Epoch 719 - Train Loss: 0.260318, Train Acc: 0.503846 | Val Loss: 0.271167, Val Acc: 0.474227\n",
      "Epoch 720 - Train Loss: 0.260304, Train Acc: 0.503846 | Val Loss: 0.271157, Val Acc: 0.474227\n",
      "Epoch 721 - Train Loss: 0.260290, Train Acc: 0.503846 | Val Loss: 0.271148, Val Acc: 0.474227\n",
      "Epoch 722 - Train Loss: 0.260277, Train Acc: 0.503846 | Val Loss: 0.271138, Val Acc: 0.474227\n",
      "Epoch 723 - Train Loss: 0.260263, Train Acc: 0.503846 | Val Loss: 0.271128, Val Acc: 0.474227\n",
      "Epoch 724 - Train Loss: 0.260249, Train Acc: 0.503846 | Val Loss: 0.271119, Val Acc: 0.474227\n",
      "Epoch 725 - Train Loss: 0.260235, Train Acc: 0.503846 | Val Loss: 0.271109, Val Acc: 0.474227\n",
      "Epoch 726 - Train Loss: 0.260221, Train Acc: 0.503846 | Val Loss: 0.271100, Val Acc: 0.474227\n",
      "Epoch 727 - Train Loss: 0.260207, Train Acc: 0.503846 | Val Loss: 0.271091, Val Acc: 0.474227\n",
      "Epoch 728 - Train Loss: 0.260193, Train Acc: 0.503846 | Val Loss: 0.271081, Val Acc: 0.474227\n",
      "Epoch 729 - Train Loss: 0.260179, Train Acc: 0.503846 | Val Loss: 0.271072, Val Acc: 0.474227\n",
      "Epoch 730 - Train Loss: 0.260165, Train Acc: 0.503846 | Val Loss: 0.271062, Val Acc: 0.474227\n",
      "Epoch 731 - Train Loss: 0.260151, Train Acc: 0.503846 | Val Loss: 0.271052, Val Acc: 0.474227\n",
      "Epoch 732 - Train Loss: 0.260137, Train Acc: 0.503846 | Val Loss: 0.271042, Val Acc: 0.474227\n",
      "Epoch 733 - Train Loss: 0.260123, Train Acc: 0.503846 | Val Loss: 0.271032, Val Acc: 0.474227\n",
      "Epoch 734 - Train Loss: 0.260110, Train Acc: 0.503846 | Val Loss: 0.271022, Val Acc: 0.474227\n",
      "Epoch 735 - Train Loss: 0.260096, Train Acc: 0.503846 | Val Loss: 0.271012, Val Acc: 0.474227\n",
      "Epoch 736 - Train Loss: 0.260083, Train Acc: 0.503846 | Val Loss: 0.271002, Val Acc: 0.474227\n",
      "Epoch 737 - Train Loss: 0.260069, Train Acc: 0.503846 | Val Loss: 0.270992, Val Acc: 0.474227\n",
      "Epoch 738 - Train Loss: 0.260056, Train Acc: 0.503846 | Val Loss: 0.270982, Val Acc: 0.474227\n",
      "Epoch 739 - Train Loss: 0.260042, Train Acc: 0.503846 | Val Loss: 0.270972, Val Acc: 0.474227\n",
      "Epoch 740 - Train Loss: 0.260029, Train Acc: 0.503846 | Val Loss: 0.270961, Val Acc: 0.474227\n",
      "Epoch 741 - Train Loss: 0.260016, Train Acc: 0.503846 | Val Loss: 0.270951, Val Acc: 0.474227\n",
      "Epoch 742 - Train Loss: 0.260002, Train Acc: 0.503846 | Val Loss: 0.270941, Val Acc: 0.474227\n",
      "Epoch 743 - Train Loss: 0.259989, Train Acc: 0.503846 | Val Loss: 0.270931, Val Acc: 0.474227\n",
      "Epoch 744 - Train Loss: 0.259976, Train Acc: 0.503846 | Val Loss: 0.270921, Val Acc: 0.474227\n",
      "Epoch 745 - Train Loss: 0.259962, Train Acc: 0.503846 | Val Loss: 0.270910, Val Acc: 0.474227\n",
      "Epoch 746 - Train Loss: 0.259949, Train Acc: 0.503846 | Val Loss: 0.270900, Val Acc: 0.474227\n",
      "Epoch 747 - Train Loss: 0.259936, Train Acc: 0.503846 | Val Loss: 0.270890, Val Acc: 0.474227\n",
      "Epoch 748 - Train Loss: 0.259922, Train Acc: 0.503846 | Val Loss: 0.270879, Val Acc: 0.474227\n",
      "Epoch 749 - Train Loss: 0.259909, Train Acc: 0.503846 | Val Loss: 0.270869, Val Acc: 0.474227\n",
      "Epoch 750 - Train Loss: 0.259895, Train Acc: 0.503846 | Val Loss: 0.270858, Val Acc: 0.474227\n",
      "Epoch 751 - Train Loss: 0.259881, Train Acc: 0.503846 | Val Loss: 0.270848, Val Acc: 0.474227\n",
      "Epoch 752 - Train Loss: 0.259868, Train Acc: 0.503846 | Val Loss: 0.270837, Val Acc: 0.474227\n",
      "Epoch 753 - Train Loss: 0.259854, Train Acc: 0.503846 | Val Loss: 0.270826, Val Acc: 0.474227\n",
      "Epoch 754 - Train Loss: 0.259840, Train Acc: 0.503846 | Val Loss: 0.270815, Val Acc: 0.474227\n",
      "Epoch 755 - Train Loss: 0.259827, Train Acc: 0.503846 | Val Loss: 0.270804, Val Acc: 0.474227\n",
      "Epoch 756 - Train Loss: 0.259813, Train Acc: 0.503846 | Val Loss: 0.270793, Val Acc: 0.474227\n",
      "Epoch 757 - Train Loss: 0.259799, Train Acc: 0.503846 | Val Loss: 0.270782, Val Acc: 0.474227\n",
      "Epoch 758 - Train Loss: 0.259785, Train Acc: 0.503846 | Val Loss: 0.270770, Val Acc: 0.474227\n",
      "Epoch 759 - Train Loss: 0.259772, Train Acc: 0.503846 | Val Loss: 0.270759, Val Acc: 0.474227\n",
      "Epoch 760 - Train Loss: 0.259758, Train Acc: 0.503846 | Val Loss: 0.270747, Val Acc: 0.474227\n",
      "Epoch 761 - Train Loss: 0.259744, Train Acc: 0.503846 | Val Loss: 0.270736, Val Acc: 0.474227\n",
      "Epoch 762 - Train Loss: 0.259730, Train Acc: 0.503846 | Val Loss: 0.270724, Val Acc: 0.474227\n",
      "Epoch 763 - Train Loss: 0.259716, Train Acc: 0.503846 | Val Loss: 0.270713, Val Acc: 0.474227\n",
      "Epoch 764 - Train Loss: 0.259702, Train Acc: 0.503846 | Val Loss: 0.270701, Val Acc: 0.474227\n",
      "Epoch 765 - Train Loss: 0.259688, Train Acc: 0.503846 | Val Loss: 0.270690, Val Acc: 0.474227\n",
      "Epoch 766 - Train Loss: 0.259674, Train Acc: 0.503846 | Val Loss: 0.270678, Val Acc: 0.474227\n",
      "Epoch 767 - Train Loss: 0.259660, Train Acc: 0.503846 | Val Loss: 0.270667, Val Acc: 0.474227\n",
      "Epoch 768 - Train Loss: 0.259647, Train Acc: 0.503846 | Val Loss: 0.270655, Val Acc: 0.474227\n",
      "Epoch 769 - Train Loss: 0.259634, Train Acc: 0.503846 | Val Loss: 0.270644, Val Acc: 0.474227\n",
      "Epoch 770 - Train Loss: 0.259620, Train Acc: 0.503846 | Val Loss: 0.270633, Val Acc: 0.474227\n",
      "Epoch 771 - Train Loss: 0.259607, Train Acc: 0.503846 | Val Loss: 0.270621, Val Acc: 0.474227\n",
      "Epoch 772 - Train Loss: 0.259593, Train Acc: 0.503846 | Val Loss: 0.270609, Val Acc: 0.474227\n",
      "Epoch 773 - Train Loss: 0.259580, Train Acc: 0.503846 | Val Loss: 0.270597, Val Acc: 0.474227\n",
      "Epoch 774 - Train Loss: 0.259566, Train Acc: 0.503846 | Val Loss: 0.270586, Val Acc: 0.474227\n",
      "Epoch 775 - Train Loss: 0.259552, Train Acc: 0.503846 | Val Loss: 0.270574, Val Acc: 0.474227\n",
      "Epoch 776 - Train Loss: 0.259539, Train Acc: 0.503846 | Val Loss: 0.270563, Val Acc: 0.474227\n",
      "Epoch 777 - Train Loss: 0.259526, Train Acc: 0.503846 | Val Loss: 0.270552, Val Acc: 0.474227\n",
      "Epoch 778 - Train Loss: 0.259512, Train Acc: 0.503846 | Val Loss: 0.270540, Val Acc: 0.474227\n",
      "Epoch 779 - Train Loss: 0.259499, Train Acc: 0.503846 | Val Loss: 0.270529, Val Acc: 0.474227\n",
      "Epoch 780 - Train Loss: 0.259485, Train Acc: 0.503846 | Val Loss: 0.270516, Val Acc: 0.474227\n",
      "Epoch 781 - Train Loss: 0.259471, Train Acc: 0.503846 | Val Loss: 0.270504, Val Acc: 0.474227\n",
      "Epoch 782 - Train Loss: 0.259458, Train Acc: 0.503846 | Val Loss: 0.270492, Val Acc: 0.474227\n",
      "Epoch 783 - Train Loss: 0.259444, Train Acc: 0.503846 | Val Loss: 0.270480, Val Acc: 0.474227\n",
      "Epoch 784 - Train Loss: 0.259431, Train Acc: 0.503846 | Val Loss: 0.270468, Val Acc: 0.474227\n",
      "Epoch 785 - Train Loss: 0.259417, Train Acc: 0.503846 | Val Loss: 0.270456, Val Acc: 0.474227\n",
      "Epoch 786 - Train Loss: 0.259403, Train Acc: 0.503846 | Val Loss: 0.270444, Val Acc: 0.474227\n",
      "Epoch 787 - Train Loss: 0.259390, Train Acc: 0.503846 | Val Loss: 0.270432, Val Acc: 0.474227\n",
      "Epoch 788 - Train Loss: 0.259376, Train Acc: 0.503846 | Val Loss: 0.270419, Val Acc: 0.474227\n",
      "Epoch 789 - Train Loss: 0.259362, Train Acc: 0.503846 | Val Loss: 0.270406, Val Acc: 0.474227\n",
      "Epoch 790 - Train Loss: 0.259348, Train Acc: 0.503846 | Val Loss: 0.270393, Val Acc: 0.474227\n",
      "Epoch 791 - Train Loss: 0.259334, Train Acc: 0.503846 | Val Loss: 0.270380, Val Acc: 0.474227\n",
      "Epoch 792 - Train Loss: 0.259320, Train Acc: 0.503846 | Val Loss: 0.270366, Val Acc: 0.474227\n",
      "Epoch 793 - Train Loss: 0.259306, Train Acc: 0.503846 | Val Loss: 0.270353, Val Acc: 0.474227\n",
      "Epoch 794 - Train Loss: 0.259292, Train Acc: 0.503846 | Val Loss: 0.270340, Val Acc: 0.474227\n",
      "Epoch 795 - Train Loss: 0.259278, Train Acc: 0.503846 | Val Loss: 0.270326, Val Acc: 0.474227\n",
      "Epoch 796 - Train Loss: 0.259264, Train Acc: 0.503846 | Val Loss: 0.270313, Val Acc: 0.474227\n",
      "Epoch 797 - Train Loss: 0.259250, Train Acc: 0.503846 | Val Loss: 0.270300, Val Acc: 0.474227\n",
      "Epoch 798 - Train Loss: 0.259236, Train Acc: 0.503846 | Val Loss: 0.270287, Val Acc: 0.474227\n",
      "Epoch 799 - Train Loss: 0.259223, Train Acc: 0.503846 | Val Loss: 0.270273, Val Acc: 0.474227\n",
      "Epoch 800 - Train Loss: 0.259209, Train Acc: 0.503846 | Val Loss: 0.270260, Val Acc: 0.474227\n",
      "Epoch 801 - Train Loss: 0.259195, Train Acc: 0.503846 | Val Loss: 0.270246, Val Acc: 0.474227\n",
      "Epoch 802 - Train Loss: 0.259181, Train Acc: 0.503846 | Val Loss: 0.270233, Val Acc: 0.474227\n",
      "Epoch 803 - Train Loss: 0.259167, Train Acc: 0.503846 | Val Loss: 0.270219, Val Acc: 0.474227\n",
      "Epoch 804 - Train Loss: 0.259153, Train Acc: 0.503846 | Val Loss: 0.270206, Val Acc: 0.474227\n",
      "Epoch 805 - Train Loss: 0.259140, Train Acc: 0.503846 | Val Loss: 0.270193, Val Acc: 0.474227\n",
      "Epoch 806 - Train Loss: 0.259126, Train Acc: 0.503846 | Val Loss: 0.270180, Val Acc: 0.474227\n",
      "Epoch 807 - Train Loss: 0.259113, Train Acc: 0.503846 | Val Loss: 0.270167, Val Acc: 0.474227\n",
      "Epoch 808 - Train Loss: 0.259099, Train Acc: 0.503846 | Val Loss: 0.270154, Val Acc: 0.474227\n",
      "Epoch 809 - Train Loss: 0.259086, Train Acc: 0.503846 | Val Loss: 0.270141, Val Acc: 0.474227\n",
      "Epoch 810 - Train Loss: 0.259072, Train Acc: 0.503846 | Val Loss: 0.270128, Val Acc: 0.474227\n",
      "Epoch 811 - Train Loss: 0.259058, Train Acc: 0.503846 | Val Loss: 0.270115, Val Acc: 0.474227\n",
      "Epoch 812 - Train Loss: 0.259045, Train Acc: 0.503846 | Val Loss: 0.270102, Val Acc: 0.474227\n",
      "Epoch 813 - Train Loss: 0.259031, Train Acc: 0.503846 | Val Loss: 0.270089, Val Acc: 0.474227\n",
      "Epoch 814 - Train Loss: 0.259018, Train Acc: 0.503846 | Val Loss: 0.270076, Val Acc: 0.474227\n",
      "Epoch 815 - Train Loss: 0.259004, Train Acc: 0.503846 | Val Loss: 0.270063, Val Acc: 0.474227\n",
      "Epoch 816 - Train Loss: 0.258991, Train Acc: 0.503846 | Val Loss: 0.270050, Val Acc: 0.474227\n",
      "Epoch 817 - Train Loss: 0.258977, Train Acc: 0.503846 | Val Loss: 0.270037, Val Acc: 0.474227\n",
      "Epoch 818 - Train Loss: 0.258963, Train Acc: 0.503846 | Val Loss: 0.270024, Val Acc: 0.474227\n",
      "Epoch 819 - Train Loss: 0.258950, Train Acc: 0.503846 | Val Loss: 0.270011, Val Acc: 0.474227\n",
      "Epoch 820 - Train Loss: 0.258936, Train Acc: 0.503846 | Val Loss: 0.269999, Val Acc: 0.474227\n",
      "Epoch 821 - Train Loss: 0.258923, Train Acc: 0.503846 | Val Loss: 0.269986, Val Acc: 0.474227\n",
      "Epoch 822 - Train Loss: 0.258909, Train Acc: 0.503846 | Val Loss: 0.269973, Val Acc: 0.474227\n",
      "Epoch 823 - Train Loss: 0.258895, Train Acc: 0.503846 | Val Loss: 0.269960, Val Acc: 0.474227\n",
      "Epoch 824 - Train Loss: 0.258882, Train Acc: 0.503846 | Val Loss: 0.269947, Val Acc: 0.474227\n",
      "Epoch 825 - Train Loss: 0.258868, Train Acc: 0.503846 | Val Loss: 0.269934, Val Acc: 0.474227\n",
      "Epoch 826 - Train Loss: 0.258854, Train Acc: 0.503846 | Val Loss: 0.269921, Val Acc: 0.474227\n",
      "Epoch 827 - Train Loss: 0.258841, Train Acc: 0.503846 | Val Loss: 0.269908, Val Acc: 0.474227\n",
      "Epoch 828 - Train Loss: 0.258827, Train Acc: 0.503846 | Val Loss: 0.269895, Val Acc: 0.474227\n",
      "Epoch 829 - Train Loss: 0.258813, Train Acc: 0.503846 | Val Loss: 0.269881, Val Acc: 0.474227\n",
      "Epoch 830 - Train Loss: 0.258799, Train Acc: 0.503846 | Val Loss: 0.269868, Val Acc: 0.474227\n",
      "Epoch 831 - Train Loss: 0.258785, Train Acc: 0.503846 | Val Loss: 0.269855, Val Acc: 0.474227\n",
      "Epoch 832 - Train Loss: 0.258771, Train Acc: 0.503846 | Val Loss: 0.269842, Val Acc: 0.474227\n",
      "Epoch 833 - Train Loss: 0.258758, Train Acc: 0.503846 | Val Loss: 0.269828, Val Acc: 0.474227\n",
      "Epoch 834 - Train Loss: 0.258744, Train Acc: 0.503846 | Val Loss: 0.269815, Val Acc: 0.474227\n",
      "Epoch 835 - Train Loss: 0.258730, Train Acc: 0.503846 | Val Loss: 0.269802, Val Acc: 0.474227\n",
      "Epoch 836 - Train Loss: 0.258716, Train Acc: 0.503846 | Val Loss: 0.269788, Val Acc: 0.474227\n",
      "Epoch 837 - Train Loss: 0.258702, Train Acc: 0.503846 | Val Loss: 0.269775, Val Acc: 0.474227\n",
      "Epoch 838 - Train Loss: 0.258688, Train Acc: 0.503846 | Val Loss: 0.269763, Val Acc: 0.474227\n",
      "Epoch 839 - Train Loss: 0.258675, Train Acc: 0.503846 | Val Loss: 0.269750, Val Acc: 0.474227\n",
      "Epoch 840 - Train Loss: 0.258661, Train Acc: 0.503846 | Val Loss: 0.269737, Val Acc: 0.474227\n",
      "Epoch 841 - Train Loss: 0.258647, Train Acc: 0.503846 | Val Loss: 0.269724, Val Acc: 0.474227\n",
      "Epoch 842 - Train Loss: 0.258633, Train Acc: 0.503846 | Val Loss: 0.269712, Val Acc: 0.474227\n",
      "Epoch 843 - Train Loss: 0.258619, Train Acc: 0.503846 | Val Loss: 0.269699, Val Acc: 0.474227\n",
      "Epoch 844 - Train Loss: 0.258606, Train Acc: 0.503846 | Val Loss: 0.269686, Val Acc: 0.474227\n",
      "Epoch 845 - Train Loss: 0.258592, Train Acc: 0.503846 | Val Loss: 0.269673, Val Acc: 0.474227\n",
      "Epoch 846 - Train Loss: 0.258578, Train Acc: 0.503846 | Val Loss: 0.269660, Val Acc: 0.474227\n",
      "Epoch 847 - Train Loss: 0.258564, Train Acc: 0.503846 | Val Loss: 0.269647, Val Acc: 0.474227\n",
      "Epoch 848 - Train Loss: 0.258550, Train Acc: 0.503846 | Val Loss: 0.269634, Val Acc: 0.474227\n",
      "Epoch 849 - Train Loss: 0.258536, Train Acc: 0.503846 | Val Loss: 0.269621, Val Acc: 0.474227\n",
      "Epoch 850 - Train Loss: 0.258522, Train Acc: 0.503846 | Val Loss: 0.269607, Val Acc: 0.474227\n",
      "Epoch 851 - Train Loss: 0.258508, Train Acc: 0.503846 | Val Loss: 0.269594, Val Acc: 0.474227\n",
      "Epoch 852 - Train Loss: 0.258494, Train Acc: 0.503846 | Val Loss: 0.269581, Val Acc: 0.474227\n",
      "Epoch 853 - Train Loss: 0.258480, Train Acc: 0.503846 | Val Loss: 0.269568, Val Acc: 0.474227\n",
      "Epoch 854 - Train Loss: 0.258466, Train Acc: 0.503846 | Val Loss: 0.269554, Val Acc: 0.474227\n",
      "Epoch 855 - Train Loss: 0.258452, Train Acc: 0.503846 | Val Loss: 0.269541, Val Acc: 0.474227\n",
      "Epoch 856 - Train Loss: 0.258438, Train Acc: 0.503846 | Val Loss: 0.269527, Val Acc: 0.474227\n",
      "Epoch 857 - Train Loss: 0.258424, Train Acc: 0.503846 | Val Loss: 0.269514, Val Acc: 0.474227\n",
      "Epoch 858 - Train Loss: 0.258409, Train Acc: 0.503846 | Val Loss: 0.269501, Val Acc: 0.474227\n",
      "Epoch 859 - Train Loss: 0.258395, Train Acc: 0.503846 | Val Loss: 0.269487, Val Acc: 0.474227\n",
      "Epoch 860 - Train Loss: 0.258381, Train Acc: 0.503846 | Val Loss: 0.269474, Val Acc: 0.474227\n",
      "Epoch 861 - Train Loss: 0.258367, Train Acc: 0.503846 | Val Loss: 0.269460, Val Acc: 0.474227\n",
      "Epoch 862 - Train Loss: 0.258353, Train Acc: 0.503846 | Val Loss: 0.269447, Val Acc: 0.474227\n",
      "Epoch 863 - Train Loss: 0.258339, Train Acc: 0.503846 | Val Loss: 0.269434, Val Acc: 0.474227\n",
      "Epoch 864 - Train Loss: 0.258325, Train Acc: 0.503846 | Val Loss: 0.269420, Val Acc: 0.474227\n",
      "Epoch 865 - Train Loss: 0.258311, Train Acc: 0.503846 | Val Loss: 0.269407, Val Acc: 0.474227\n",
      "Epoch 866 - Train Loss: 0.258297, Train Acc: 0.503846 | Val Loss: 0.269394, Val Acc: 0.474227\n",
      "Epoch 867 - Train Loss: 0.258283, Train Acc: 0.503846 | Val Loss: 0.269381, Val Acc: 0.474227\n",
      "Epoch 868 - Train Loss: 0.258270, Train Acc: 0.503846 | Val Loss: 0.269367, Val Acc: 0.474227\n",
      "Epoch 869 - Train Loss: 0.258256, Train Acc: 0.503846 | Val Loss: 0.269354, Val Acc: 0.474227\n",
      "Epoch 870 - Train Loss: 0.258242, Train Acc: 0.503846 | Val Loss: 0.269341, Val Acc: 0.474227\n",
      "Epoch 871 - Train Loss: 0.258228, Train Acc: 0.503846 | Val Loss: 0.269328, Val Acc: 0.474227\n",
      "Epoch 872 - Train Loss: 0.258215, Train Acc: 0.503846 | Val Loss: 0.269314, Val Acc: 0.474227\n",
      "Epoch 873 - Train Loss: 0.258201, Train Acc: 0.503846 | Val Loss: 0.269301, Val Acc: 0.474227\n",
      "Epoch 874 - Train Loss: 0.258187, Train Acc: 0.503846 | Val Loss: 0.269288, Val Acc: 0.474227\n",
      "Epoch 875 - Train Loss: 0.258173, Train Acc: 0.503846 | Val Loss: 0.269274, Val Acc: 0.474227\n",
      "Epoch 876 - Train Loss: 0.258160, Train Acc: 0.503846 | Val Loss: 0.269261, Val Acc: 0.474227\n",
      "Epoch 877 - Train Loss: 0.258146, Train Acc: 0.503846 | Val Loss: 0.269248, Val Acc: 0.474227\n",
      "Epoch 878 - Train Loss: 0.258132, Train Acc: 0.503846 | Val Loss: 0.269235, Val Acc: 0.474227\n",
      "Epoch 879 - Train Loss: 0.258119, Train Acc: 0.503846 | Val Loss: 0.269222, Val Acc: 0.474227\n",
      "Epoch 880 - Train Loss: 0.258105, Train Acc: 0.503846 | Val Loss: 0.269209, Val Acc: 0.474227\n",
      "Epoch 881 - Train Loss: 0.258092, Train Acc: 0.503846 | Val Loss: 0.269196, Val Acc: 0.474227\n",
      "Epoch 882 - Train Loss: 0.258078, Train Acc: 0.503846 | Val Loss: 0.269183, Val Acc: 0.474227\n",
      "Epoch 883 - Train Loss: 0.258064, Train Acc: 0.503846 | Val Loss: 0.269170, Val Acc: 0.474227\n",
      "Epoch 884 - Train Loss: 0.258050, Train Acc: 0.503846 | Val Loss: 0.269157, Val Acc: 0.474227\n",
      "Epoch 885 - Train Loss: 0.258037, Train Acc: 0.503846 | Val Loss: 0.269144, Val Acc: 0.474227\n",
      "Epoch 886 - Train Loss: 0.258023, Train Acc: 0.503846 | Val Loss: 0.269131, Val Acc: 0.474227\n",
      "Epoch 887 - Train Loss: 0.258009, Train Acc: 0.503846 | Val Loss: 0.269118, Val Acc: 0.474227\n",
      "Epoch 888 - Train Loss: 0.257995, Train Acc: 0.503846 | Val Loss: 0.269105, Val Acc: 0.474227\n",
      "Epoch 889 - Train Loss: 0.257981, Train Acc: 0.503846 | Val Loss: 0.269092, Val Acc: 0.474227\n",
      "Epoch 890 - Train Loss: 0.257967, Train Acc: 0.503846 | Val Loss: 0.269079, Val Acc: 0.474227\n",
      "Epoch 891 - Train Loss: 0.257953, Train Acc: 0.503846 | Val Loss: 0.269066, Val Acc: 0.474227\n",
      "Epoch 892 - Train Loss: 0.257939, Train Acc: 0.503846 | Val Loss: 0.269053, Val Acc: 0.474227\n",
      "Epoch 893 - Train Loss: 0.257925, Train Acc: 0.503846 | Val Loss: 0.269040, Val Acc: 0.474227\n",
      "Epoch 894 - Train Loss: 0.257911, Train Acc: 0.503846 | Val Loss: 0.269026, Val Acc: 0.474227\n",
      "Epoch 895 - Train Loss: 0.257897, Train Acc: 0.503846 | Val Loss: 0.269013, Val Acc: 0.474227\n",
      "Epoch 896 - Train Loss: 0.257883, Train Acc: 0.503846 | Val Loss: 0.269000, Val Acc: 0.474227\n",
      "Epoch 897 - Train Loss: 0.257868, Train Acc: 0.503846 | Val Loss: 0.268987, Val Acc: 0.474227\n",
      "Epoch 898 - Train Loss: 0.257854, Train Acc: 0.503846 | Val Loss: 0.268974, Val Acc: 0.474227\n",
      "Epoch 899 - Train Loss: 0.257840, Train Acc: 0.503846 | Val Loss: 0.268961, Val Acc: 0.474227\n",
      "Epoch 900 - Train Loss: 0.257826, Train Acc: 0.503846 | Val Loss: 0.268948, Val Acc: 0.474227\n",
      "Epoch 901 - Train Loss: 0.257812, Train Acc: 0.503846 | Val Loss: 0.268935, Val Acc: 0.474227\n",
      "Epoch 902 - Train Loss: 0.257798, Train Acc: 0.503846 | Val Loss: 0.268923, Val Acc: 0.474227\n",
      "Epoch 903 - Train Loss: 0.257783, Train Acc: 0.503846 | Val Loss: 0.268910, Val Acc: 0.474227\n",
      "Epoch 904 - Train Loss: 0.257769, Train Acc: 0.503846 | Val Loss: 0.268897, Val Acc: 0.474227\n",
      "Epoch 905 - Train Loss: 0.257755, Train Acc: 0.503846 | Val Loss: 0.268884, Val Acc: 0.474227\n",
      "Epoch 906 - Train Loss: 0.257741, Train Acc: 0.503846 | Val Loss: 0.268871, Val Acc: 0.474227\n",
      "Epoch 907 - Train Loss: 0.257726, Train Acc: 0.503846 | Val Loss: 0.268857, Val Acc: 0.474227\n",
      "Epoch 908 - Train Loss: 0.257712, Train Acc: 0.503846 | Val Loss: 0.268844, Val Acc: 0.474227\n",
      "Epoch 909 - Train Loss: 0.257698, Train Acc: 0.503846 | Val Loss: 0.268831, Val Acc: 0.474227\n",
      "Epoch 910 - Train Loss: 0.257683, Train Acc: 0.503846 | Val Loss: 0.268817, Val Acc: 0.474227\n",
      "Epoch 911 - Train Loss: 0.257669, Train Acc: 0.503846 | Val Loss: 0.268804, Val Acc: 0.474227\n",
      "Epoch 912 - Train Loss: 0.257655, Train Acc: 0.503846 | Val Loss: 0.268790, Val Acc: 0.474227\n",
      "Epoch 913 - Train Loss: 0.257640, Train Acc: 0.503846 | Val Loss: 0.268777, Val Acc: 0.474227\n",
      "Epoch 914 - Train Loss: 0.257626, Train Acc: 0.503846 | Val Loss: 0.268764, Val Acc: 0.474227\n",
      "Epoch 915 - Train Loss: 0.257611, Train Acc: 0.503846 | Val Loss: 0.268750, Val Acc: 0.474227\n",
      "Epoch 916 - Train Loss: 0.257597, Train Acc: 0.503846 | Val Loss: 0.268737, Val Acc: 0.474227\n",
      "Epoch 917 - Train Loss: 0.257582, Train Acc: 0.503846 | Val Loss: 0.268724, Val Acc: 0.474227\n",
      "Epoch 918 - Train Loss: 0.257568, Train Acc: 0.503846 | Val Loss: 0.268710, Val Acc: 0.474227\n",
      "Epoch 919 - Train Loss: 0.257554, Train Acc: 0.503846 | Val Loss: 0.268697, Val Acc: 0.474227\n",
      "Epoch 920 - Train Loss: 0.257540, Train Acc: 0.503846 | Val Loss: 0.268684, Val Acc: 0.474227\n",
      "Epoch 921 - Train Loss: 0.257525, Train Acc: 0.503846 | Val Loss: 0.268671, Val Acc: 0.474227\n",
      "Epoch 922 - Train Loss: 0.257511, Train Acc: 0.503846 | Val Loss: 0.268657, Val Acc: 0.474227\n",
      "Epoch 923 - Train Loss: 0.257497, Train Acc: 0.503846 | Val Loss: 0.268644, Val Acc: 0.474227\n",
      "Epoch 924 - Train Loss: 0.257482, Train Acc: 0.503846 | Val Loss: 0.268630, Val Acc: 0.474227\n",
      "Epoch 925 - Train Loss: 0.257468, Train Acc: 0.503846 | Val Loss: 0.268617, Val Acc: 0.474227\n",
      "Epoch 926 - Train Loss: 0.257454, Train Acc: 0.503846 | Val Loss: 0.268603, Val Acc: 0.474227\n",
      "Epoch 927 - Train Loss: 0.257440, Train Acc: 0.503846 | Val Loss: 0.268589, Val Acc: 0.474227\n",
      "Epoch 928 - Train Loss: 0.257425, Train Acc: 0.503846 | Val Loss: 0.268575, Val Acc: 0.474227\n",
      "Epoch 929 - Train Loss: 0.257411, Train Acc: 0.503846 | Val Loss: 0.268561, Val Acc: 0.474227\n",
      "Epoch 930 - Train Loss: 0.257397, Train Acc: 0.503846 | Val Loss: 0.268548, Val Acc: 0.474227\n",
      "Epoch 931 - Train Loss: 0.257383, Train Acc: 0.503846 | Val Loss: 0.268534, Val Acc: 0.474227\n",
      "Epoch 932 - Train Loss: 0.257368, Train Acc: 0.503846 | Val Loss: 0.268521, Val Acc: 0.474227\n",
      "Epoch 933 - Train Loss: 0.257354, Train Acc: 0.503846 | Val Loss: 0.268507, Val Acc: 0.474227\n",
      "Epoch 934 - Train Loss: 0.257340, Train Acc: 0.503846 | Val Loss: 0.268494, Val Acc: 0.474227\n",
      "Epoch 935 - Train Loss: 0.257326, Train Acc: 0.503846 | Val Loss: 0.268481, Val Acc: 0.474227\n",
      "Epoch 936 - Train Loss: 0.257312, Train Acc: 0.503846 | Val Loss: 0.268467, Val Acc: 0.474227\n",
      "Epoch 937 - Train Loss: 0.257298, Train Acc: 0.503846 | Val Loss: 0.268454, Val Acc: 0.474227\n",
      "Epoch 938 - Train Loss: 0.257284, Train Acc: 0.503846 | Val Loss: 0.268441, Val Acc: 0.474227\n",
      "Epoch 939 - Train Loss: 0.257270, Train Acc: 0.503846 | Val Loss: 0.268427, Val Acc: 0.474227\n",
      "Epoch 940 - Train Loss: 0.257255, Train Acc: 0.503846 | Val Loss: 0.268414, Val Acc: 0.474227\n",
      "Epoch 941 - Train Loss: 0.257241, Train Acc: 0.503846 | Val Loss: 0.268401, Val Acc: 0.474227\n",
      "Epoch 942 - Train Loss: 0.257227, Train Acc: 0.503846 | Val Loss: 0.268387, Val Acc: 0.474227\n",
      "Epoch 943 - Train Loss: 0.257213, Train Acc: 0.503846 | Val Loss: 0.268374, Val Acc: 0.474227\n",
      "Epoch 944 - Train Loss: 0.257199, Train Acc: 0.503846 | Val Loss: 0.268360, Val Acc: 0.474227\n",
      "Epoch 945 - Train Loss: 0.257185, Train Acc: 0.503846 | Val Loss: 0.268347, Val Acc: 0.474227\n",
      "Epoch 946 - Train Loss: 0.257171, Train Acc: 0.503846 | Val Loss: 0.268333, Val Acc: 0.474227\n",
      "Epoch 947 - Train Loss: 0.257157, Train Acc: 0.503846 | Val Loss: 0.268320, Val Acc: 0.474227\n",
      "Epoch 948 - Train Loss: 0.257143, Train Acc: 0.503846 | Val Loss: 0.268306, Val Acc: 0.474227\n",
      "Epoch 949 - Train Loss: 0.257129, Train Acc: 0.503846 | Val Loss: 0.268293, Val Acc: 0.474227\n",
      "Epoch 950 - Train Loss: 0.257115, Train Acc: 0.503846 | Val Loss: 0.268279, Val Acc: 0.474227\n",
      "Epoch 951 - Train Loss: 0.257100, Train Acc: 0.503846 | Val Loss: 0.268265, Val Acc: 0.474227\n",
      "Epoch 952 - Train Loss: 0.257086, Train Acc: 0.503846 | Val Loss: 0.268252, Val Acc: 0.474227\n",
      "Epoch 953 - Train Loss: 0.257073, Train Acc: 0.503846 | Val Loss: 0.268239, Val Acc: 0.474227\n",
      "Epoch 954 - Train Loss: 0.257059, Train Acc: 0.503846 | Val Loss: 0.268226, Val Acc: 0.474227\n",
      "Epoch 955 - Train Loss: 0.257045, Train Acc: 0.503846 | Val Loss: 0.268213, Val Acc: 0.474227\n",
      "Epoch 956 - Train Loss: 0.257031, Train Acc: 0.503846 | Val Loss: 0.268200, Val Acc: 0.474227\n",
      "Epoch 957 - Train Loss: 0.257017, Train Acc: 0.503846 | Val Loss: 0.268186, Val Acc: 0.474227\n",
      "Epoch 958 - Train Loss: 0.257003, Train Acc: 0.503846 | Val Loss: 0.268173, Val Acc: 0.474227\n",
      "Epoch 959 - Train Loss: 0.256989, Train Acc: 0.503846 | Val Loss: 0.268160, Val Acc: 0.474227\n",
      "Epoch 960 - Train Loss: 0.256975, Train Acc: 0.503846 | Val Loss: 0.268146, Val Acc: 0.474227\n",
      "Epoch 961 - Train Loss: 0.256961, Train Acc: 0.503846 | Val Loss: 0.268133, Val Acc: 0.474227\n",
      "Epoch 962 - Train Loss: 0.256947, Train Acc: 0.503846 | Val Loss: 0.268120, Val Acc: 0.474227\n",
      "Epoch 963 - Train Loss: 0.256933, Train Acc: 0.503846 | Val Loss: 0.268107, Val Acc: 0.474227\n",
      "Epoch 964 - Train Loss: 0.256918, Train Acc: 0.503846 | Val Loss: 0.268094, Val Acc: 0.474227\n",
      "Epoch 965 - Train Loss: 0.256904, Train Acc: 0.503846 | Val Loss: 0.268080, Val Acc: 0.474227\n",
      "Epoch 966 - Train Loss: 0.256890, Train Acc: 0.503846 | Val Loss: 0.268067, Val Acc: 0.474227\n",
      "Epoch 967 - Train Loss: 0.256876, Train Acc: 0.503846 | Val Loss: 0.268054, Val Acc: 0.474227\n",
      "Epoch 968 - Train Loss: 0.256862, Train Acc: 0.503846 | Val Loss: 0.268041, Val Acc: 0.474227\n",
      "Epoch 969 - Train Loss: 0.256848, Train Acc: 0.503846 | Val Loss: 0.268027, Val Acc: 0.474227\n",
      "Epoch 970 - Train Loss: 0.256834, Train Acc: 0.503846 | Val Loss: 0.268014, Val Acc: 0.474227\n",
      "Epoch 971 - Train Loss: 0.256819, Train Acc: 0.503846 | Val Loss: 0.268001, Val Acc: 0.474227\n",
      "Epoch 972 - Train Loss: 0.256805, Train Acc: 0.503846 | Val Loss: 0.267987, Val Acc: 0.474227\n",
      "Epoch 973 - Train Loss: 0.256791, Train Acc: 0.503846 | Val Loss: 0.267974, Val Acc: 0.474227\n",
      "Epoch 974 - Train Loss: 0.256777, Train Acc: 0.503846 | Val Loss: 0.267961, Val Acc: 0.474227\n",
      "Epoch 975 - Train Loss: 0.256763, Train Acc: 0.503846 | Val Loss: 0.267948, Val Acc: 0.474227\n",
      "Epoch 976 - Train Loss: 0.256749, Train Acc: 0.503846 | Val Loss: 0.267935, Val Acc: 0.474227\n",
      "Epoch 977 - Train Loss: 0.256735, Train Acc: 0.503846 | Val Loss: 0.267922, Val Acc: 0.474227\n",
      "Epoch 978 - Train Loss: 0.256721, Train Acc: 0.503846 | Val Loss: 0.267908, Val Acc: 0.474227\n",
      "Epoch 979 - Train Loss: 0.256707, Train Acc: 0.503846 | Val Loss: 0.267895, Val Acc: 0.474227\n",
      "Epoch 980 - Train Loss: 0.256693, Train Acc: 0.503846 | Val Loss: 0.267882, Val Acc: 0.474227\n",
      "Epoch 981 - Train Loss: 0.256678, Train Acc: 0.503846 | Val Loss: 0.267868, Val Acc: 0.474227\n",
      "Epoch 982 - Train Loss: 0.256664, Train Acc: 0.503846 | Val Loss: 0.267855, Val Acc: 0.474227\n",
      "Epoch 983 - Train Loss: 0.256650, Train Acc: 0.503846 | Val Loss: 0.267842, Val Acc: 0.474227\n",
      "Epoch 984 - Train Loss: 0.256636, Train Acc: 0.503846 | Val Loss: 0.267828, Val Acc: 0.474227\n",
      "Epoch 985 - Train Loss: 0.256622, Train Acc: 0.503846 | Val Loss: 0.267815, Val Acc: 0.474227\n",
      "Epoch 986 - Train Loss: 0.256608, Train Acc: 0.503846 | Val Loss: 0.267801, Val Acc: 0.474227\n",
      "Epoch 987 - Train Loss: 0.256594, Train Acc: 0.503846 | Val Loss: 0.267788, Val Acc: 0.474227\n",
      "Epoch 988 - Train Loss: 0.256579, Train Acc: 0.503846 | Val Loss: 0.267774, Val Acc: 0.474227\n",
      "Epoch 989 - Train Loss: 0.256565, Train Acc: 0.503846 | Val Loss: 0.267760, Val Acc: 0.474227\n",
      "Epoch 990 - Train Loss: 0.256551, Train Acc: 0.503846 | Val Loss: 0.267746, Val Acc: 0.474227\n",
      "Epoch 991 - Train Loss: 0.256537, Train Acc: 0.503846 | Val Loss: 0.267732, Val Acc: 0.474227\n",
      "Epoch 992 - Train Loss: 0.256522, Train Acc: 0.503846 | Val Loss: 0.267718, Val Acc: 0.474227\n",
      "Epoch 993 - Train Loss: 0.256508, Train Acc: 0.503846 | Val Loss: 0.267704, Val Acc: 0.474227\n",
      "Epoch 994 - Train Loss: 0.256493, Train Acc: 0.503846 | Val Loss: 0.267690, Val Acc: 0.474227\n",
      "Epoch 995 - Train Loss: 0.256479, Train Acc: 0.503846 | Val Loss: 0.267677, Val Acc: 0.474227\n",
      "Epoch 996 - Train Loss: 0.256465, Train Acc: 0.503846 | Val Loss: 0.267663, Val Acc: 0.474227\n",
      "Epoch 997 - Train Loss: 0.256450, Train Acc: 0.503846 | Val Loss: 0.267649, Val Acc: 0.474227\n",
      "Epoch 998 - Train Loss: 0.256436, Train Acc: 0.503846 | Val Loss: 0.267635, Val Acc: 0.474227\n",
      "Epoch 999 - Train Loss: 0.256422, Train Acc: 0.503846 | Val Loss: 0.267621, Val Acc: 0.474227\n",
      "Epoch 1000 - Train Loss: 0.256407, Train Acc: 0.503846 | Val Loss: 0.267607, Val Acc: 0.474227\n",
      "Epoch 1001 - Train Loss: 0.256393, Train Acc: 0.503846 | Val Loss: 0.267593, Val Acc: 0.474227\n",
      "Epoch 1002 - Train Loss: 0.256379, Train Acc: 0.503846 | Val Loss: 0.267579, Val Acc: 0.474227\n",
      "Epoch 1003 - Train Loss: 0.256364, Train Acc: 0.503846 | Val Loss: 0.267565, Val Acc: 0.474227\n",
      "Epoch 1004 - Train Loss: 0.256350, Train Acc: 0.503846 | Val Loss: 0.267550, Val Acc: 0.474227\n",
      "Epoch 1005 - Train Loss: 0.256336, Train Acc: 0.503846 | Val Loss: 0.267536, Val Acc: 0.474227\n",
      "Epoch 1006 - Train Loss: 0.256321, Train Acc: 0.503846 | Val Loss: 0.267521, Val Acc: 0.474227\n",
      "Epoch 1007 - Train Loss: 0.256307, Train Acc: 0.503846 | Val Loss: 0.267507, Val Acc: 0.474227\n",
      "Epoch 1008 - Train Loss: 0.256293, Train Acc: 0.503846 | Val Loss: 0.267492, Val Acc: 0.474227\n",
      "Epoch 1009 - Train Loss: 0.256278, Train Acc: 0.503846 | Val Loss: 0.267478, Val Acc: 0.474227\n",
      "Epoch 1010 - Train Loss: 0.256264, Train Acc: 0.503846 | Val Loss: 0.267464, Val Acc: 0.474227\n",
      "Epoch 1011 - Train Loss: 0.256250, Train Acc: 0.503846 | Val Loss: 0.267449, Val Acc: 0.474227\n",
      "Epoch 1012 - Train Loss: 0.256235, Train Acc: 0.503846 | Val Loss: 0.267435, Val Acc: 0.474227\n",
      "Epoch 1013 - Train Loss: 0.256221, Train Acc: 0.503846 | Val Loss: 0.267421, Val Acc: 0.474227\n",
      "Epoch 1014 - Train Loss: 0.256207, Train Acc: 0.503846 | Val Loss: 0.267407, Val Acc: 0.474227\n",
      "Epoch 1015 - Train Loss: 0.256193, Train Acc: 0.503846 | Val Loss: 0.267392, Val Acc: 0.474227\n",
      "Epoch 1016 - Train Loss: 0.256179, Train Acc: 0.503846 | Val Loss: 0.267378, Val Acc: 0.474227\n",
      "Epoch 1017 - Train Loss: 0.256164, Train Acc: 0.503846 | Val Loss: 0.267364, Val Acc: 0.474227\n",
      "Epoch 1018 - Train Loss: 0.256150, Train Acc: 0.503846 | Val Loss: 0.267350, Val Acc: 0.474227\n",
      "Epoch 1019 - Train Loss: 0.256136, Train Acc: 0.503846 | Val Loss: 0.267336, Val Acc: 0.474227\n",
      "Epoch 1020 - Train Loss: 0.256122, Train Acc: 0.503846 | Val Loss: 0.267321, Val Acc: 0.474227\n",
      "Epoch 1021 - Train Loss: 0.256107, Train Acc: 0.503846 | Val Loss: 0.267307, Val Acc: 0.474227\n",
      "Epoch 1022 - Train Loss: 0.256093, Train Acc: 0.503846 | Val Loss: 0.267293, Val Acc: 0.474227\n",
      "Epoch 1023 - Train Loss: 0.256079, Train Acc: 0.503846 | Val Loss: 0.267279, Val Acc: 0.474227\n",
      "Epoch 1024 - Train Loss: 0.256065, Train Acc: 0.503846 | Val Loss: 0.267265, Val Acc: 0.474227\n",
      "Epoch 1025 - Train Loss: 0.256050, Train Acc: 0.503846 | Val Loss: 0.267250, Val Acc: 0.474227\n",
      "Epoch 1026 - Train Loss: 0.256036, Train Acc: 0.503846 | Val Loss: 0.267236, Val Acc: 0.474227\n",
      "Epoch 1027 - Train Loss: 0.256022, Train Acc: 0.503846 | Val Loss: 0.267222, Val Acc: 0.474227\n",
      "Epoch 1028 - Train Loss: 0.256007, Train Acc: 0.503846 | Val Loss: 0.267208, Val Acc: 0.474227\n",
      "Epoch 1029 - Train Loss: 0.255993, Train Acc: 0.503846 | Val Loss: 0.267194, Val Acc: 0.474227\n",
      "Epoch 1030 - Train Loss: 0.255979, Train Acc: 0.503846 | Val Loss: 0.267180, Val Acc: 0.474227\n",
      "Epoch 1031 - Train Loss: 0.255964, Train Acc: 0.503846 | Val Loss: 0.267166, Val Acc: 0.474227\n",
      "Epoch 1032 - Train Loss: 0.255950, Train Acc: 0.503846 | Val Loss: 0.267152, Val Acc: 0.474227\n",
      "Epoch 1033 - Train Loss: 0.255936, Train Acc: 0.503846 | Val Loss: 0.267138, Val Acc: 0.474227\n",
      "Epoch 1034 - Train Loss: 0.255922, Train Acc: 0.503846 | Val Loss: 0.267124, Val Acc: 0.474227\n",
      "Epoch 1035 - Train Loss: 0.255907, Train Acc: 0.503846 | Val Loss: 0.267110, Val Acc: 0.474227\n",
      "Epoch 1036 - Train Loss: 0.255893, Train Acc: 0.503846 | Val Loss: 0.267096, Val Acc: 0.474227\n",
      "Epoch 1037 - Train Loss: 0.255879, Train Acc: 0.503846 | Val Loss: 0.267082, Val Acc: 0.474227\n",
      "Epoch 1038 - Train Loss: 0.255864, Train Acc: 0.503846 | Val Loss: 0.267068, Val Acc: 0.474227\n",
      "Epoch 1039 - Train Loss: 0.255850, Train Acc: 0.503846 | Val Loss: 0.267054, Val Acc: 0.474227\n",
      "Epoch 1040 - Train Loss: 0.255836, Train Acc: 0.503846 | Val Loss: 0.267040, Val Acc: 0.474227\n",
      "Epoch 1041 - Train Loss: 0.255821, Train Acc: 0.503846 | Val Loss: 0.267026, Val Acc: 0.474227\n",
      "Epoch 1042 - Train Loss: 0.255807, Train Acc: 0.503846 | Val Loss: 0.267012, Val Acc: 0.474227\n",
      "Epoch 1043 - Train Loss: 0.255793, Train Acc: 0.503846 | Val Loss: 0.266998, Val Acc: 0.474227\n",
      "Epoch 1044 - Train Loss: 0.255778, Train Acc: 0.503846 | Val Loss: 0.266984, Val Acc: 0.474227\n",
      "Epoch 1045 - Train Loss: 0.255764, Train Acc: 0.503846 | Val Loss: 0.266970, Val Acc: 0.474227\n",
      "Epoch 1046 - Train Loss: 0.255750, Train Acc: 0.503846 | Val Loss: 0.266955, Val Acc: 0.474227\n",
      "Epoch 1047 - Train Loss: 0.255735, Train Acc: 0.503846 | Val Loss: 0.266941, Val Acc: 0.474227\n",
      "Epoch 1048 - Train Loss: 0.255721, Train Acc: 0.503846 | Val Loss: 0.266927, Val Acc: 0.474227\n",
      "Epoch 1049 - Train Loss: 0.255706, Train Acc: 0.503846 | Val Loss: 0.266913, Val Acc: 0.474227\n",
      "Epoch 1050 - Train Loss: 0.255692, Train Acc: 0.503846 | Val Loss: 0.266899, Val Acc: 0.474227\n",
      "Epoch 1051 - Train Loss: 0.255677, Train Acc: 0.503846 | Val Loss: 0.266885, Val Acc: 0.474227\n",
      "Epoch 1052 - Train Loss: 0.255663, Train Acc: 0.503846 | Val Loss: 0.266870, Val Acc: 0.474227\n",
      "Epoch 1053 - Train Loss: 0.255649, Train Acc: 0.503846 | Val Loss: 0.266856, Val Acc: 0.474227\n",
      "Epoch 1054 - Train Loss: 0.255634, Train Acc: 0.503846 | Val Loss: 0.266842, Val Acc: 0.474227\n",
      "Epoch 1055 - Train Loss: 0.255620, Train Acc: 0.503846 | Val Loss: 0.266827, Val Acc: 0.474227\n",
      "Epoch 1056 - Train Loss: 0.255605, Train Acc: 0.503846 | Val Loss: 0.266813, Val Acc: 0.474227\n",
      "Epoch 1057 - Train Loss: 0.255591, Train Acc: 0.503846 | Val Loss: 0.266799, Val Acc: 0.474227\n",
      "Epoch 1058 - Train Loss: 0.255576, Train Acc: 0.503846 | Val Loss: 0.266785, Val Acc: 0.474227\n",
      "Epoch 1059 - Train Loss: 0.255562, Train Acc: 0.503846 | Val Loss: 0.266770, Val Acc: 0.474227\n",
      "Epoch 1060 - Train Loss: 0.255547, Train Acc: 0.503846 | Val Loss: 0.266756, Val Acc: 0.474227\n",
      "Epoch 1061 - Train Loss: 0.255533, Train Acc: 0.503846 | Val Loss: 0.266742, Val Acc: 0.474227\n",
      "Epoch 1062 - Train Loss: 0.255518, Train Acc: 0.503846 | Val Loss: 0.266728, Val Acc: 0.474227\n",
      "Epoch 1063 - Train Loss: 0.255504, Train Acc: 0.503846 | Val Loss: 0.266714, Val Acc: 0.474227\n",
      "Epoch 1064 - Train Loss: 0.255489, Train Acc: 0.503846 | Val Loss: 0.266699, Val Acc: 0.474227\n",
      "Epoch 1065 - Train Loss: 0.255475, Train Acc: 0.503846 | Val Loss: 0.266685, Val Acc: 0.474227\n",
      "Epoch 1066 - Train Loss: 0.255460, Train Acc: 0.503846 | Val Loss: 0.266671, Val Acc: 0.474227\n",
      "Epoch 1067 - Train Loss: 0.255446, Train Acc: 0.503846 | Val Loss: 0.266657, Val Acc: 0.474227\n",
      "Epoch 1068 - Train Loss: 0.255431, Train Acc: 0.503846 | Val Loss: 0.266642, Val Acc: 0.474227\n",
      "Epoch 1069 - Train Loss: 0.255417, Train Acc: 0.503846 | Val Loss: 0.266628, Val Acc: 0.474227\n",
      "Epoch 1070 - Train Loss: 0.255402, Train Acc: 0.503846 | Val Loss: 0.266613, Val Acc: 0.474227\n",
      "Epoch 1071 - Train Loss: 0.255387, Train Acc: 0.503846 | Val Loss: 0.266598, Val Acc: 0.474227\n",
      "Epoch 1072 - Train Loss: 0.255372, Train Acc: 0.503846 | Val Loss: 0.266583, Val Acc: 0.474227\n",
      "Epoch 1073 - Train Loss: 0.255358, Train Acc: 0.503846 | Val Loss: 0.266569, Val Acc: 0.474227\n",
      "Epoch 1074 - Train Loss: 0.255343, Train Acc: 0.503846 | Val Loss: 0.266554, Val Acc: 0.474227\n",
      "Epoch 1075 - Train Loss: 0.255328, Train Acc: 0.503846 | Val Loss: 0.266539, Val Acc: 0.474227\n",
      "Epoch 1076 - Train Loss: 0.255314, Train Acc: 0.503846 | Val Loss: 0.266525, Val Acc: 0.474227\n",
      "Epoch 1077 - Train Loss: 0.255299, Train Acc: 0.503846 | Val Loss: 0.266510, Val Acc: 0.474227\n",
      "Epoch 1078 - Train Loss: 0.255284, Train Acc: 0.503846 | Val Loss: 0.266495, Val Acc: 0.474227\n",
      "Epoch 1079 - Train Loss: 0.255269, Train Acc: 0.503846 | Val Loss: 0.266481, Val Acc: 0.474227\n",
      "Epoch 1080 - Train Loss: 0.255255, Train Acc: 0.503846 | Val Loss: 0.266466, Val Acc: 0.474227\n",
      "Epoch 1081 - Train Loss: 0.255240, Train Acc: 0.503846 | Val Loss: 0.266451, Val Acc: 0.474227\n",
      "Epoch 1082 - Train Loss: 0.255225, Train Acc: 0.503846 | Val Loss: 0.266437, Val Acc: 0.474227\n",
      "Epoch 1083 - Train Loss: 0.255211, Train Acc: 0.503846 | Val Loss: 0.266422, Val Acc: 0.474227\n",
      "Epoch 1084 - Train Loss: 0.255196, Train Acc: 0.503846 | Val Loss: 0.266408, Val Acc: 0.474227\n",
      "Epoch 1085 - Train Loss: 0.255181, Train Acc: 0.503846 | Val Loss: 0.266393, Val Acc: 0.474227\n",
      "Epoch 1086 - Train Loss: 0.255167, Train Acc: 0.503846 | Val Loss: 0.266378, Val Acc: 0.474227\n",
      "Epoch 1087 - Train Loss: 0.255152, Train Acc: 0.503846 | Val Loss: 0.266364, Val Acc: 0.474227\n",
      "Epoch 1088 - Train Loss: 0.255137, Train Acc: 0.503846 | Val Loss: 0.266349, Val Acc: 0.474227\n",
      "Epoch 1089 - Train Loss: 0.255123, Train Acc: 0.503846 | Val Loss: 0.266334, Val Acc: 0.474227\n",
      "Epoch 1090 - Train Loss: 0.255108, Train Acc: 0.503846 | Val Loss: 0.266319, Val Acc: 0.474227\n",
      "Epoch 1091 - Train Loss: 0.255093, Train Acc: 0.503846 | Val Loss: 0.266304, Val Acc: 0.474227\n",
      "Epoch 1092 - Train Loss: 0.255078, Train Acc: 0.503846 | Val Loss: 0.266289, Val Acc: 0.474227\n",
      "Epoch 1093 - Train Loss: 0.255064, Train Acc: 0.503846 | Val Loss: 0.266274, Val Acc: 0.474227\n",
      "Epoch 1094 - Train Loss: 0.255049, Train Acc: 0.503846 | Val Loss: 0.266260, Val Acc: 0.474227\n",
      "Epoch 1095 - Train Loss: 0.255034, Train Acc: 0.503846 | Val Loss: 0.266245, Val Acc: 0.474227\n",
      "Epoch 1096 - Train Loss: 0.255020, Train Acc: 0.503846 | Val Loss: 0.266231, Val Acc: 0.474227\n",
      "Epoch 1097 - Train Loss: 0.255005, Train Acc: 0.503846 | Val Loss: 0.266216, Val Acc: 0.474227\n",
      "Epoch 1098 - Train Loss: 0.254991, Train Acc: 0.503846 | Val Loss: 0.266202, Val Acc: 0.474227\n",
      "Epoch 1099 - Train Loss: 0.254976, Train Acc: 0.503846 | Val Loss: 0.266187, Val Acc: 0.474227\n",
      "Epoch 1100 - Train Loss: 0.254961, Train Acc: 0.503846 | Val Loss: 0.266172, Val Acc: 0.474227\n",
      "Epoch 1101 - Train Loss: 0.254947, Train Acc: 0.503846 | Val Loss: 0.266158, Val Acc: 0.474227\n",
      "Epoch 1102 - Train Loss: 0.254932, Train Acc: 0.503846 | Val Loss: 0.266143, Val Acc: 0.474227\n",
      "Epoch 1103 - Train Loss: 0.254917, Train Acc: 0.503846 | Val Loss: 0.266128, Val Acc: 0.474227\n",
      "Epoch 1104 - Train Loss: 0.254902, Train Acc: 0.503846 | Val Loss: 0.266113, Val Acc: 0.474227\n",
      "Epoch 1105 - Train Loss: 0.254888, Train Acc: 0.503846 | Val Loss: 0.266098, Val Acc: 0.474227\n",
      "Epoch 1106 - Train Loss: 0.254873, Train Acc: 0.503846 | Val Loss: 0.266083, Val Acc: 0.474227\n",
      "Epoch 1107 - Train Loss: 0.254858, Train Acc: 0.503846 | Val Loss: 0.266068, Val Acc: 0.474227\n",
      "Epoch 1108 - Train Loss: 0.254843, Train Acc: 0.503846 | Val Loss: 0.266053, Val Acc: 0.474227\n",
      "Epoch 1109 - Train Loss: 0.254828, Train Acc: 0.503846 | Val Loss: 0.266038, Val Acc: 0.474227\n",
      "Epoch 1110 - Train Loss: 0.254814, Train Acc: 0.503846 | Val Loss: 0.266023, Val Acc: 0.474227\n",
      "Epoch 1111 - Train Loss: 0.254799, Train Acc: 0.503846 | Val Loss: 0.266008, Val Acc: 0.474227\n",
      "Epoch 1112 - Train Loss: 0.254784, Train Acc: 0.503846 | Val Loss: 0.265993, Val Acc: 0.474227\n",
      "Epoch 1113 - Train Loss: 0.254769, Train Acc: 0.503846 | Val Loss: 0.265978, Val Acc: 0.474227\n",
      "Epoch 1114 - Train Loss: 0.254754, Train Acc: 0.503846 | Val Loss: 0.265963, Val Acc: 0.474227\n",
      "Epoch 1115 - Train Loss: 0.254739, Train Acc: 0.503846 | Val Loss: 0.265948, Val Acc: 0.474227\n",
      "Epoch 1116 - Train Loss: 0.254724, Train Acc: 0.503846 | Val Loss: 0.265933, Val Acc: 0.474227\n",
      "Epoch 1117 - Train Loss: 0.254709, Train Acc: 0.503846 | Val Loss: 0.265918, Val Acc: 0.474227\n",
      "Epoch 1118 - Train Loss: 0.254694, Train Acc: 0.503846 | Val Loss: 0.265902, Val Acc: 0.474227\n",
      "Epoch 1119 - Train Loss: 0.254679, Train Acc: 0.503846 | Val Loss: 0.265887, Val Acc: 0.474227\n",
      "Epoch 1120 - Train Loss: 0.254664, Train Acc: 0.503846 | Val Loss: 0.265871, Val Acc: 0.474227\n",
      "Epoch 1121 - Train Loss: 0.254649, Train Acc: 0.503846 | Val Loss: 0.265856, Val Acc: 0.474227\n",
      "Epoch 1122 - Train Loss: 0.254634, Train Acc: 0.503846 | Val Loss: 0.265840, Val Acc: 0.474227\n",
      "Epoch 1123 - Train Loss: 0.254619, Train Acc: 0.503846 | Val Loss: 0.265825, Val Acc: 0.474227\n",
      "Epoch 1124 - Train Loss: 0.254604, Train Acc: 0.503846 | Val Loss: 0.265810, Val Acc: 0.474227\n",
      "Epoch 1125 - Train Loss: 0.254589, Train Acc: 0.503846 | Val Loss: 0.265794, Val Acc: 0.474227\n",
      "Epoch 1126 - Train Loss: 0.254574, Train Acc: 0.503846 | Val Loss: 0.265779, Val Acc: 0.474227\n",
      "Epoch 1127 - Train Loss: 0.254559, Train Acc: 0.503846 | Val Loss: 0.265764, Val Acc: 0.474227\n",
      "Epoch 1128 - Train Loss: 0.254544, Train Acc: 0.503846 | Val Loss: 0.265749, Val Acc: 0.474227\n",
      "Epoch 1129 - Train Loss: 0.254528, Train Acc: 0.503846 | Val Loss: 0.265734, Val Acc: 0.474227\n",
      "Epoch 1130 - Train Loss: 0.254513, Train Acc: 0.503846 | Val Loss: 0.265719, Val Acc: 0.474227\n",
      "Epoch 1131 - Train Loss: 0.254498, Train Acc: 0.503846 | Val Loss: 0.265703, Val Acc: 0.474227\n",
      "Epoch 1132 - Train Loss: 0.254483, Train Acc: 0.503846 | Val Loss: 0.265688, Val Acc: 0.474227\n",
      "Epoch 1133 - Train Loss: 0.254468, Train Acc: 0.503846 | Val Loss: 0.265673, Val Acc: 0.474227\n",
      "Epoch 1134 - Train Loss: 0.254453, Train Acc: 0.503846 | Val Loss: 0.265657, Val Acc: 0.474227\n",
      "Epoch 1135 - Train Loss: 0.254438, Train Acc: 0.503846 | Val Loss: 0.265642, Val Acc: 0.474227\n",
      "Epoch 1136 - Train Loss: 0.254423, Train Acc: 0.503846 | Val Loss: 0.265627, Val Acc: 0.474227\n",
      "Epoch 1137 - Train Loss: 0.254408, Train Acc: 0.503846 | Val Loss: 0.265612, Val Acc: 0.474227\n",
      "Epoch 1138 - Train Loss: 0.254393, Train Acc: 0.503846 | Val Loss: 0.265597, Val Acc: 0.474227\n",
      "Epoch 1139 - Train Loss: 0.254378, Train Acc: 0.503846 | Val Loss: 0.265582, Val Acc: 0.474227\n",
      "Epoch 1140 - Train Loss: 0.254363, Train Acc: 0.503846 | Val Loss: 0.265567, Val Acc: 0.474227\n",
      "Epoch 1141 - Train Loss: 0.254348, Train Acc: 0.503846 | Val Loss: 0.265552, Val Acc: 0.474227\n",
      "Epoch 1142 - Train Loss: 0.254333, Train Acc: 0.503846 | Val Loss: 0.265537, Val Acc: 0.474227\n",
      "Epoch 1143 - Train Loss: 0.254317, Train Acc: 0.503846 | Val Loss: 0.265521, Val Acc: 0.474227\n",
      "Epoch 1144 - Train Loss: 0.254302, Train Acc: 0.503846 | Val Loss: 0.265506, Val Acc: 0.474227\n",
      "Epoch 1145 - Train Loss: 0.254287, Train Acc: 0.503846 | Val Loss: 0.265491, Val Acc: 0.474227\n",
      "Epoch 1146 - Train Loss: 0.254272, Train Acc: 0.503846 | Val Loss: 0.265476, Val Acc: 0.474227\n",
      "Epoch 1147 - Train Loss: 0.254257, Train Acc: 0.503846 | Val Loss: 0.265461, Val Acc: 0.474227\n",
      "Epoch 1148 - Train Loss: 0.254242, Train Acc: 0.503846 | Val Loss: 0.265446, Val Acc: 0.474227\n",
      "Epoch 1149 - Train Loss: 0.254227, Train Acc: 0.503846 | Val Loss: 0.265431, Val Acc: 0.474227\n",
      "Epoch 1150 - Train Loss: 0.254212, Train Acc: 0.503846 | Val Loss: 0.265416, Val Acc: 0.474227\n",
      "Epoch 1151 - Train Loss: 0.254197, Train Acc: 0.503846 | Val Loss: 0.265401, Val Acc: 0.474227\n",
      "Epoch 1152 - Train Loss: 0.254181, Train Acc: 0.503846 | Val Loss: 0.265385, Val Acc: 0.474227\n",
      "Epoch 1153 - Train Loss: 0.254166, Train Acc: 0.503846 | Val Loss: 0.265370, Val Acc: 0.474227\n",
      "Epoch 1154 - Train Loss: 0.254151, Train Acc: 0.503846 | Val Loss: 0.265355, Val Acc: 0.474227\n",
      "Epoch 1155 - Train Loss: 0.254136, Train Acc: 0.503846 | Val Loss: 0.265340, Val Acc: 0.474227\n",
      "Epoch 1156 - Train Loss: 0.254121, Train Acc: 0.503846 | Val Loss: 0.265325, Val Acc: 0.474227\n",
      "Epoch 1157 - Train Loss: 0.254106, Train Acc: 0.503846 | Val Loss: 0.265310, Val Acc: 0.474227\n",
      "Epoch 1158 - Train Loss: 0.254091, Train Acc: 0.503846 | Val Loss: 0.265295, Val Acc: 0.474227\n",
      "Epoch 1159 - Train Loss: 0.254075, Train Acc: 0.503846 | Val Loss: 0.265280, Val Acc: 0.474227\n",
      "Epoch 1160 - Train Loss: 0.254060, Train Acc: 0.503846 | Val Loss: 0.265265, Val Acc: 0.474227\n",
      "Epoch 1161 - Train Loss: 0.254045, Train Acc: 0.503846 | Val Loss: 0.265249, Val Acc: 0.474227\n",
      "Epoch 1162 - Train Loss: 0.254030, Train Acc: 0.503846 | Val Loss: 0.265234, Val Acc: 0.474227\n",
      "Epoch 1163 - Train Loss: 0.254015, Train Acc: 0.503846 | Val Loss: 0.265219, Val Acc: 0.474227\n",
      "Epoch 1164 - Train Loss: 0.254000, Train Acc: 0.503846 | Val Loss: 0.265204, Val Acc: 0.474227\n",
      "Epoch 1165 - Train Loss: 0.253984, Train Acc: 0.503846 | Val Loss: 0.265188, Val Acc: 0.474227\n",
      "Epoch 1166 - Train Loss: 0.253969, Train Acc: 0.503846 | Val Loss: 0.265173, Val Acc: 0.474227\n",
      "Epoch 1167 - Train Loss: 0.253954, Train Acc: 0.503846 | Val Loss: 0.265157, Val Acc: 0.474227\n",
      "Epoch 1168 - Train Loss: 0.253939, Train Acc: 0.503846 | Val Loss: 0.265142, Val Acc: 0.474227\n",
      "Epoch 1169 - Train Loss: 0.253923, Train Acc: 0.503846 | Val Loss: 0.265127, Val Acc: 0.474227\n",
      "Epoch 1170 - Train Loss: 0.253908, Train Acc: 0.503846 | Val Loss: 0.265112, Val Acc: 0.474227\n",
      "Epoch 1171 - Train Loss: 0.253893, Train Acc: 0.503846 | Val Loss: 0.265096, Val Acc: 0.474227\n",
      "Epoch 1172 - Train Loss: 0.253878, Train Acc: 0.503846 | Val Loss: 0.265081, Val Acc: 0.474227\n",
      "Epoch 1173 - Train Loss: 0.253862, Train Acc: 0.503846 | Val Loss: 0.265065, Val Acc: 0.474227\n",
      "Epoch 1174 - Train Loss: 0.253847, Train Acc: 0.503846 | Val Loss: 0.265050, Val Acc: 0.474227\n",
      "Epoch 1175 - Train Loss: 0.253831, Train Acc: 0.503846 | Val Loss: 0.265035, Val Acc: 0.474227\n",
      "Epoch 1176 - Train Loss: 0.253816, Train Acc: 0.503846 | Val Loss: 0.265019, Val Acc: 0.474227\n",
      "Epoch 1177 - Train Loss: 0.253801, Train Acc: 0.503846 | Val Loss: 0.265004, Val Acc: 0.474227\n",
      "Epoch 1178 - Train Loss: 0.253785, Train Acc: 0.503846 | Val Loss: 0.264988, Val Acc: 0.474227\n",
      "Epoch 1179 - Train Loss: 0.253770, Train Acc: 0.503846 | Val Loss: 0.264973, Val Acc: 0.474227\n",
      "Epoch 1180 - Train Loss: 0.253755, Train Acc: 0.503846 | Val Loss: 0.264958, Val Acc: 0.474227\n",
      "Epoch 1181 - Train Loss: 0.253739, Train Acc: 0.503846 | Val Loss: 0.264942, Val Acc: 0.474227\n",
      "Epoch 1182 - Train Loss: 0.253724, Train Acc: 0.503846 | Val Loss: 0.264927, Val Acc: 0.474227\n",
      "Epoch 1183 - Train Loss: 0.253709, Train Acc: 0.503846 | Val Loss: 0.264911, Val Acc: 0.474227\n",
      "Epoch 1184 - Train Loss: 0.253693, Train Acc: 0.503846 | Val Loss: 0.264896, Val Acc: 0.474227\n",
      "Epoch 1185 - Train Loss: 0.253678, Train Acc: 0.503846 | Val Loss: 0.264881, Val Acc: 0.474227\n",
      "Epoch 1186 - Train Loss: 0.253663, Train Acc: 0.503846 | Val Loss: 0.264865, Val Acc: 0.474227\n",
      "Epoch 1187 - Train Loss: 0.253647, Train Acc: 0.503846 | Val Loss: 0.264850, Val Acc: 0.474227\n",
      "Epoch 1188 - Train Loss: 0.253632, Train Acc: 0.503846 | Val Loss: 0.264835, Val Acc: 0.474227\n",
      "Epoch 1189 - Train Loss: 0.253617, Train Acc: 0.503846 | Val Loss: 0.264819, Val Acc: 0.474227\n",
      "Epoch 1190 - Train Loss: 0.253601, Train Acc: 0.503846 | Val Loss: 0.264804, Val Acc: 0.474227\n",
      "Epoch 1191 - Train Loss: 0.253586, Train Acc: 0.503846 | Val Loss: 0.264789, Val Acc: 0.474227\n",
      "Epoch 1192 - Train Loss: 0.253571, Train Acc: 0.503846 | Val Loss: 0.264774, Val Acc: 0.474227\n",
      "Epoch 1193 - Train Loss: 0.253555, Train Acc: 0.503846 | Val Loss: 0.264759, Val Acc: 0.474227\n",
      "Epoch 1194 - Train Loss: 0.253540, Train Acc: 0.503846 | Val Loss: 0.264744, Val Acc: 0.474227\n",
      "Epoch 1195 - Train Loss: 0.253525, Train Acc: 0.503846 | Val Loss: 0.264729, Val Acc: 0.474227\n",
      "Epoch 1196 - Train Loss: 0.253509, Train Acc: 0.503846 | Val Loss: 0.264714, Val Acc: 0.474227\n",
      "Epoch 1197 - Train Loss: 0.253494, Train Acc: 0.503846 | Val Loss: 0.264699, Val Acc: 0.474227\n",
      "Epoch 1198 - Train Loss: 0.253479, Train Acc: 0.503846 | Val Loss: 0.264684, Val Acc: 0.474227\n",
      "Epoch 1199 - Train Loss: 0.253463, Train Acc: 0.503846 | Val Loss: 0.264669, Val Acc: 0.474227\n",
      "Epoch 1200 - Train Loss: 0.253448, Train Acc: 0.503846 | Val Loss: 0.264654, Val Acc: 0.474227\n",
      "Epoch 1201 - Train Loss: 0.253433, Train Acc: 0.503846 | Val Loss: 0.264639, Val Acc: 0.474227\n",
      "Epoch 1202 - Train Loss: 0.253417, Train Acc: 0.503846 | Val Loss: 0.264624, Val Acc: 0.474227\n",
      "Epoch 1203 - Train Loss: 0.253402, Train Acc: 0.503846 | Val Loss: 0.264609, Val Acc: 0.474227\n",
      "Epoch 1204 - Train Loss: 0.253386, Train Acc: 0.503846 | Val Loss: 0.264594, Val Acc: 0.474227\n",
      "Epoch 1205 - Train Loss: 0.253371, Train Acc: 0.503846 | Val Loss: 0.264579, Val Acc: 0.474227\n",
      "Epoch 1206 - Train Loss: 0.253355, Train Acc: 0.503846 | Val Loss: 0.264564, Val Acc: 0.474227\n",
      "Epoch 1207 - Train Loss: 0.253340, Train Acc: 0.503846 | Val Loss: 0.264549, Val Acc: 0.474227\n",
      "Epoch 1208 - Train Loss: 0.253324, Train Acc: 0.503846 | Val Loss: 0.264534, Val Acc: 0.474227\n",
      "Epoch 1209 - Train Loss: 0.253309, Train Acc: 0.503846 | Val Loss: 0.264519, Val Acc: 0.474227\n",
      "Epoch 1210 - Train Loss: 0.253293, Train Acc: 0.503846 | Val Loss: 0.264504, Val Acc: 0.474227\n",
      "Epoch 1211 - Train Loss: 0.253278, Train Acc: 0.503846 | Val Loss: 0.264489, Val Acc: 0.474227\n",
      "Epoch 1212 - Train Loss: 0.253262, Train Acc: 0.503846 | Val Loss: 0.264474, Val Acc: 0.474227\n",
      "Epoch 1213 - Train Loss: 0.253247, Train Acc: 0.503846 | Val Loss: 0.264459, Val Acc: 0.474227\n",
      "Epoch 1214 - Train Loss: 0.253231, Train Acc: 0.503846 | Val Loss: 0.264444, Val Acc: 0.474227\n",
      "Epoch 1215 - Train Loss: 0.253216, Train Acc: 0.503846 | Val Loss: 0.264429, Val Acc: 0.474227\n",
      "Epoch 1216 - Train Loss: 0.253200, Train Acc: 0.503846 | Val Loss: 0.264414, Val Acc: 0.474227\n",
      "Epoch 1217 - Train Loss: 0.253184, Train Acc: 0.503846 | Val Loss: 0.264399, Val Acc: 0.474227\n",
      "Epoch 1218 - Train Loss: 0.253169, Train Acc: 0.503846 | Val Loss: 0.264383, Val Acc: 0.474227\n",
      "Epoch 1219 - Train Loss: 0.253153, Train Acc: 0.503846 | Val Loss: 0.264368, Val Acc: 0.474227\n",
      "Epoch 1220 - Train Loss: 0.253137, Train Acc: 0.503846 | Val Loss: 0.264353, Val Acc: 0.474227\n",
      "Epoch 1221 - Train Loss: 0.253122, Train Acc: 0.503846 | Val Loss: 0.264338, Val Acc: 0.474227\n",
      "Epoch 1222 - Train Loss: 0.253106, Train Acc: 0.503846 | Val Loss: 0.264323, Val Acc: 0.474227\n",
      "Epoch 1223 - Train Loss: 0.253091, Train Acc: 0.503846 | Val Loss: 0.264307, Val Acc: 0.474227\n",
      "Epoch 1224 - Train Loss: 0.253075, Train Acc: 0.503846 | Val Loss: 0.264292, Val Acc: 0.474227\n",
      "Epoch 1225 - Train Loss: 0.253059, Train Acc: 0.503846 | Val Loss: 0.264277, Val Acc: 0.474227\n",
      "Epoch 1226 - Train Loss: 0.253044, Train Acc: 0.503846 | Val Loss: 0.264262, Val Acc: 0.474227\n",
      "Epoch 1227 - Train Loss: 0.253028, Train Acc: 0.503846 | Val Loss: 0.264247, Val Acc: 0.474227\n",
      "Epoch 1228 - Train Loss: 0.253012, Train Acc: 0.503846 | Val Loss: 0.264232, Val Acc: 0.474227\n",
      "Epoch 1229 - Train Loss: 0.252997, Train Acc: 0.503846 | Val Loss: 0.264217, Val Acc: 0.474227\n",
      "Epoch 1230 - Train Loss: 0.252981, Train Acc: 0.503846 | Val Loss: 0.264202, Val Acc: 0.474227\n",
      "Epoch 1231 - Train Loss: 0.252965, Train Acc: 0.503846 | Val Loss: 0.264187, Val Acc: 0.474227\n",
      "Epoch 1232 - Train Loss: 0.252950, Train Acc: 0.503846 | Val Loss: 0.264172, Val Acc: 0.474227\n",
      "Epoch 1233 - Train Loss: 0.252934, Train Acc: 0.503846 | Val Loss: 0.264156, Val Acc: 0.474227\n",
      "Epoch 1234 - Train Loss: 0.252919, Train Acc: 0.503846 | Val Loss: 0.264141, Val Acc: 0.474227\n",
      "Epoch 1235 - Train Loss: 0.252903, Train Acc: 0.503846 | Val Loss: 0.264126, Val Acc: 0.474227\n",
      "Epoch 1236 - Train Loss: 0.252887, Train Acc: 0.503846 | Val Loss: 0.264111, Val Acc: 0.474227\n",
      "Epoch 1237 - Train Loss: 0.252872, Train Acc: 0.503846 | Val Loss: 0.264096, Val Acc: 0.474227\n",
      "Epoch 1238 - Train Loss: 0.252856, Train Acc: 0.503846 | Val Loss: 0.264081, Val Acc: 0.474227\n",
      "Epoch 1239 - Train Loss: 0.252840, Train Acc: 0.503846 | Val Loss: 0.264065, Val Acc: 0.474227\n",
      "Epoch 1240 - Train Loss: 0.252824, Train Acc: 0.503846 | Val Loss: 0.264050, Val Acc: 0.474227\n",
      "Epoch 1241 - Train Loss: 0.252809, Train Acc: 0.503846 | Val Loss: 0.264035, Val Acc: 0.474227\n",
      "Epoch 1242 - Train Loss: 0.252793, Train Acc: 0.503846 | Val Loss: 0.264020, Val Acc: 0.474227\n",
      "Epoch 1243 - Train Loss: 0.252777, Train Acc: 0.503846 | Val Loss: 0.264004, Val Acc: 0.474227\n",
      "Epoch 1244 - Train Loss: 0.252761, Train Acc: 0.503846 | Val Loss: 0.263989, Val Acc: 0.474227\n",
      "Epoch 1245 - Train Loss: 0.252746, Train Acc: 0.503846 | Val Loss: 0.263974, Val Acc: 0.474227\n",
      "Epoch 1246 - Train Loss: 0.252730, Train Acc: 0.503846 | Val Loss: 0.263958, Val Acc: 0.474227\n",
      "Epoch 1247 - Train Loss: 0.252714, Train Acc: 0.503846 | Val Loss: 0.263943, Val Acc: 0.474227\n",
      "Epoch 1248 - Train Loss: 0.252698, Train Acc: 0.503846 | Val Loss: 0.263928, Val Acc: 0.474227\n",
      "Epoch 1249 - Train Loss: 0.252683, Train Acc: 0.503846 | Val Loss: 0.263913, Val Acc: 0.474227\n",
      "Epoch 1250 - Train Loss: 0.252667, Train Acc: 0.503846 | Val Loss: 0.263897, Val Acc: 0.474227\n",
      "Epoch 1251 - Train Loss: 0.252651, Train Acc: 0.503846 | Val Loss: 0.263882, Val Acc: 0.474227\n",
      "Epoch 1252 - Train Loss: 0.252636, Train Acc: 0.503846 | Val Loss: 0.263867, Val Acc: 0.474227\n",
      "Epoch 1253 - Train Loss: 0.252620, Train Acc: 0.503846 | Val Loss: 0.263851, Val Acc: 0.474227\n",
      "Epoch 1254 - Train Loss: 0.252604, Train Acc: 0.503846 | Val Loss: 0.263836, Val Acc: 0.474227\n",
      "Epoch 1255 - Train Loss: 0.252588, Train Acc: 0.503846 | Val Loss: 0.263821, Val Acc: 0.474227\n",
      "Epoch 1256 - Train Loss: 0.252572, Train Acc: 0.503846 | Val Loss: 0.263805, Val Acc: 0.474227\n",
      "Epoch 1257 - Train Loss: 0.252556, Train Acc: 0.503846 | Val Loss: 0.263790, Val Acc: 0.474227\n",
      "Epoch 1258 - Train Loss: 0.252540, Train Acc: 0.503846 | Val Loss: 0.263774, Val Acc: 0.474227\n",
      "Epoch 1259 - Train Loss: 0.252525, Train Acc: 0.503846 | Val Loss: 0.263758, Val Acc: 0.474227\n",
      "Epoch 1260 - Train Loss: 0.252509, Train Acc: 0.503846 | Val Loss: 0.263742, Val Acc: 0.474227\n",
      "Epoch 1261 - Train Loss: 0.252493, Train Acc: 0.503846 | Val Loss: 0.263727, Val Acc: 0.474227\n",
      "Epoch 1262 - Train Loss: 0.252477, Train Acc: 0.503846 | Val Loss: 0.263711, Val Acc: 0.474227\n",
      "Epoch 1263 - Train Loss: 0.252461, Train Acc: 0.503846 | Val Loss: 0.263695, Val Acc: 0.474227\n",
      "Epoch 1264 - Train Loss: 0.252445, Train Acc: 0.503846 | Val Loss: 0.263679, Val Acc: 0.474227\n",
      "Epoch 1265 - Train Loss: 0.252429, Train Acc: 0.503846 | Val Loss: 0.263664, Val Acc: 0.474227\n",
      "Epoch 1266 - Train Loss: 0.252413, Train Acc: 0.503846 | Val Loss: 0.263648, Val Acc: 0.474227\n",
      "Epoch 1267 - Train Loss: 0.252397, Train Acc: 0.503846 | Val Loss: 0.263632, Val Acc: 0.474227\n",
      "Epoch 1268 - Train Loss: 0.252381, Train Acc: 0.503846 | Val Loss: 0.263617, Val Acc: 0.474227\n",
      "Epoch 1269 - Train Loss: 0.252365, Train Acc: 0.503846 | Val Loss: 0.263601, Val Acc: 0.474227\n",
      "Epoch 1270 - Train Loss: 0.252349, Train Acc: 0.503846 | Val Loss: 0.263586, Val Acc: 0.474227\n",
      "Epoch 1271 - Train Loss: 0.252333, Train Acc: 0.503846 | Val Loss: 0.263571, Val Acc: 0.474227\n",
      "Epoch 1272 - Train Loss: 0.252317, Train Acc: 0.503846 | Val Loss: 0.263555, Val Acc: 0.474227\n",
      "Epoch 1273 - Train Loss: 0.252301, Train Acc: 0.503846 | Val Loss: 0.263540, Val Acc: 0.474227\n",
      "Epoch 1274 - Train Loss: 0.252285, Train Acc: 0.503846 | Val Loss: 0.263524, Val Acc: 0.474227\n",
      "Epoch 1275 - Train Loss: 0.252270, Train Acc: 0.503846 | Val Loss: 0.263509, Val Acc: 0.474227\n",
      "Epoch 1276 - Train Loss: 0.252254, Train Acc: 0.503846 | Val Loss: 0.263493, Val Acc: 0.474227\n",
      "Epoch 1277 - Train Loss: 0.252238, Train Acc: 0.503846 | Val Loss: 0.263478, Val Acc: 0.474227\n",
      "Epoch 1278 - Train Loss: 0.252222, Train Acc: 0.503846 | Val Loss: 0.263462, Val Acc: 0.474227\n",
      "Epoch 1279 - Train Loss: 0.252206, Train Acc: 0.503846 | Val Loss: 0.263447, Val Acc: 0.474227\n",
      "Epoch 1280 - Train Loss: 0.252190, Train Acc: 0.503846 | Val Loss: 0.263431, Val Acc: 0.474227\n",
      "Epoch 1281 - Train Loss: 0.252174, Train Acc: 0.503846 | Val Loss: 0.263416, Val Acc: 0.474227\n",
      "Epoch 1282 - Train Loss: 0.252158, Train Acc: 0.503846 | Val Loss: 0.263400, Val Acc: 0.474227\n",
      "Epoch 1283 - Train Loss: 0.252142, Train Acc: 0.503846 | Val Loss: 0.263385, Val Acc: 0.474227\n",
      "Epoch 1284 - Train Loss: 0.252126, Train Acc: 0.503846 | Val Loss: 0.263369, Val Acc: 0.474227\n",
      "Epoch 1285 - Train Loss: 0.252110, Train Acc: 0.503846 | Val Loss: 0.263354, Val Acc: 0.474227\n",
      "Epoch 1286 - Train Loss: 0.252094, Train Acc: 0.503846 | Val Loss: 0.263338, Val Acc: 0.474227\n",
      "Epoch 1287 - Train Loss: 0.252078, Train Acc: 0.503846 | Val Loss: 0.263323, Val Acc: 0.474227\n",
      "Epoch 1288 - Train Loss: 0.252062, Train Acc: 0.503846 | Val Loss: 0.263307, Val Acc: 0.474227\n",
      "Epoch 1289 - Train Loss: 0.252046, Train Acc: 0.503846 | Val Loss: 0.263292, Val Acc: 0.474227\n",
      "Epoch 1290 - Train Loss: 0.252030, Train Acc: 0.503846 | Val Loss: 0.263276, Val Acc: 0.474227\n",
      "Epoch 1291 - Train Loss: 0.252014, Train Acc: 0.503846 | Val Loss: 0.263261, Val Acc: 0.474227\n",
      "Epoch 1292 - Train Loss: 0.251998, Train Acc: 0.503846 | Val Loss: 0.263246, Val Acc: 0.474227\n",
      "Epoch 1293 - Train Loss: 0.251982, Train Acc: 0.505128 | Val Loss: 0.263230, Val Acc: 0.474227\n",
      "Epoch 1294 - Train Loss: 0.251966, Train Acc: 0.505128 | Val Loss: 0.263215, Val Acc: 0.474227\n",
      "Epoch 1295 - Train Loss: 0.251950, Train Acc: 0.505128 | Val Loss: 0.263199, Val Acc: 0.474227\n",
      "Epoch 1296 - Train Loss: 0.251934, Train Acc: 0.505128 | Val Loss: 0.263184, Val Acc: 0.474227\n",
      "Epoch 1297 - Train Loss: 0.251918, Train Acc: 0.505128 | Val Loss: 0.263169, Val Acc: 0.474227\n",
      "Epoch 1298 - Train Loss: 0.251902, Train Acc: 0.505128 | Val Loss: 0.263153, Val Acc: 0.474227\n",
      "Epoch 1299 - Train Loss: 0.251886, Train Acc: 0.505128 | Val Loss: 0.263138, Val Acc: 0.474227\n",
      "Epoch 1300 - Train Loss: 0.251870, Train Acc: 0.505128 | Val Loss: 0.263122, Val Acc: 0.474227\n",
      "Epoch 1301 - Train Loss: 0.251854, Train Acc: 0.505128 | Val Loss: 0.263107, Val Acc: 0.474227\n",
      "Epoch 1302 - Train Loss: 0.251838, Train Acc: 0.505128 | Val Loss: 0.263092, Val Acc: 0.474227\n",
      "Epoch 1303 - Train Loss: 0.251822, Train Acc: 0.505128 | Val Loss: 0.263076, Val Acc: 0.474227\n",
      "Epoch 1304 - Train Loss: 0.251806, Train Acc: 0.505128 | Val Loss: 0.263061, Val Acc: 0.474227\n",
      "Epoch 1305 - Train Loss: 0.251790, Train Acc: 0.505128 | Val Loss: 0.263046, Val Acc: 0.474227\n",
      "Epoch 1306 - Train Loss: 0.251774, Train Acc: 0.505128 | Val Loss: 0.263030, Val Acc: 0.474227\n",
      "Epoch 1307 - Train Loss: 0.251758, Train Acc: 0.505128 | Val Loss: 0.263015, Val Acc: 0.474227\n",
      "Epoch 1308 - Train Loss: 0.251742, Train Acc: 0.505128 | Val Loss: 0.263000, Val Acc: 0.474227\n",
      "Epoch 1309 - Train Loss: 0.251726, Train Acc: 0.505128 | Val Loss: 0.262985, Val Acc: 0.474227\n",
      "Epoch 1310 - Train Loss: 0.251710, Train Acc: 0.505128 | Val Loss: 0.262970, Val Acc: 0.474227\n",
      "Epoch 1311 - Train Loss: 0.251694, Train Acc: 0.505128 | Val Loss: 0.262955, Val Acc: 0.474227\n",
      "Epoch 1312 - Train Loss: 0.251678, Train Acc: 0.505128 | Val Loss: 0.262939, Val Acc: 0.474227\n",
      "Epoch 1313 - Train Loss: 0.251662, Train Acc: 0.505128 | Val Loss: 0.262924, Val Acc: 0.474227\n",
      "Epoch 1314 - Train Loss: 0.251646, Train Acc: 0.505128 | Val Loss: 0.262909, Val Acc: 0.474227\n",
      "Epoch 1315 - Train Loss: 0.251630, Train Acc: 0.505128 | Val Loss: 0.262893, Val Acc: 0.474227\n",
      "Epoch 1316 - Train Loss: 0.251614, Train Acc: 0.505128 | Val Loss: 0.262878, Val Acc: 0.474227\n",
      "Epoch 1317 - Train Loss: 0.251598, Train Acc: 0.505128 | Val Loss: 0.262863, Val Acc: 0.474227\n",
      "Epoch 1318 - Train Loss: 0.251582, Train Acc: 0.505128 | Val Loss: 0.262848, Val Acc: 0.474227\n",
      "Epoch 1319 - Train Loss: 0.251566, Train Acc: 0.505128 | Val Loss: 0.262833, Val Acc: 0.474227\n",
      "Epoch 1320 - Train Loss: 0.251550, Train Acc: 0.505128 | Val Loss: 0.262818, Val Acc: 0.474227\n",
      "Epoch 1321 - Train Loss: 0.251534, Train Acc: 0.505128 | Val Loss: 0.262803, Val Acc: 0.474227\n",
      "Epoch 1322 - Train Loss: 0.251518, Train Acc: 0.505128 | Val Loss: 0.262787, Val Acc: 0.474227\n",
      "Epoch 1323 - Train Loss: 0.251502, Train Acc: 0.505128 | Val Loss: 0.262772, Val Acc: 0.474227\n",
      "Epoch 1324 - Train Loss: 0.251486, Train Acc: 0.505128 | Val Loss: 0.262757, Val Acc: 0.474227\n",
      "Epoch 1325 - Train Loss: 0.251469, Train Acc: 0.505128 | Val Loss: 0.262742, Val Acc: 0.474227\n",
      "Epoch 1326 - Train Loss: 0.251453, Train Acc: 0.505128 | Val Loss: 0.262726, Val Acc: 0.474227\n",
      "Epoch 1327 - Train Loss: 0.251437, Train Acc: 0.505128 | Val Loss: 0.262711, Val Acc: 0.474227\n",
      "Epoch 1328 - Train Loss: 0.251421, Train Acc: 0.505128 | Val Loss: 0.262696, Val Acc: 0.474227\n",
      "Epoch 1329 - Train Loss: 0.251405, Train Acc: 0.505128 | Val Loss: 0.262681, Val Acc: 0.474227\n",
      "Epoch 1330 - Train Loss: 0.251388, Train Acc: 0.505128 | Val Loss: 0.262665, Val Acc: 0.474227\n",
      "Epoch 1331 - Train Loss: 0.251372, Train Acc: 0.505128 | Val Loss: 0.262650, Val Acc: 0.474227\n",
      "Epoch 1332 - Train Loss: 0.251356, Train Acc: 0.505128 | Val Loss: 0.262635, Val Acc: 0.474227\n",
      "Epoch 1333 - Train Loss: 0.251340, Train Acc: 0.505128 | Val Loss: 0.262620, Val Acc: 0.474227\n",
      "Epoch 1334 - Train Loss: 0.251323, Train Acc: 0.505128 | Val Loss: 0.262604, Val Acc: 0.474227\n",
      "Epoch 1335 - Train Loss: 0.251307, Train Acc: 0.505128 | Val Loss: 0.262589, Val Acc: 0.474227\n",
      "Epoch 1336 - Train Loss: 0.251291, Train Acc: 0.505128 | Val Loss: 0.262574, Val Acc: 0.474227\n",
      "Epoch 1337 - Train Loss: 0.251275, Train Acc: 0.505128 | Val Loss: 0.262559, Val Acc: 0.474227\n",
      "Epoch 1338 - Train Loss: 0.251258, Train Acc: 0.505128 | Val Loss: 0.262543, Val Acc: 0.474227\n",
      "Epoch 1339 - Train Loss: 0.251242, Train Acc: 0.505128 | Val Loss: 0.262528, Val Acc: 0.474227\n",
      "Epoch 1340 - Train Loss: 0.251226, Train Acc: 0.505128 | Val Loss: 0.262513, Val Acc: 0.474227\n",
      "Epoch 1341 - Train Loss: 0.251210, Train Acc: 0.505128 | Val Loss: 0.262497, Val Acc: 0.474227\n",
      "Epoch 1342 - Train Loss: 0.251194, Train Acc: 0.505128 | Val Loss: 0.262482, Val Acc: 0.474227\n",
      "Epoch 1343 - Train Loss: 0.251177, Train Acc: 0.505128 | Val Loss: 0.262467, Val Acc: 0.474227\n",
      "Epoch 1344 - Train Loss: 0.251161, Train Acc: 0.505128 | Val Loss: 0.262451, Val Acc: 0.474227\n",
      "Epoch 1345 - Train Loss: 0.251145, Train Acc: 0.505128 | Val Loss: 0.262436, Val Acc: 0.474227\n",
      "Epoch 1346 - Train Loss: 0.251129, Train Acc: 0.505128 | Val Loss: 0.262421, Val Acc: 0.474227\n",
      "Epoch 1347 - Train Loss: 0.251112, Train Acc: 0.505128 | Val Loss: 0.262405, Val Acc: 0.474227\n",
      "Epoch 1348 - Train Loss: 0.251096, Train Acc: 0.505128 | Val Loss: 0.262390, Val Acc: 0.474227\n",
      "Epoch 1349 - Train Loss: 0.251080, Train Acc: 0.505128 | Val Loss: 0.262374, Val Acc: 0.474227\n",
      "Epoch 1350 - Train Loss: 0.251063, Train Acc: 0.505128 | Val Loss: 0.262359, Val Acc: 0.474227\n",
      "Epoch 1351 - Train Loss: 0.251047, Train Acc: 0.505128 | Val Loss: 0.262343, Val Acc: 0.474227\n",
      "Epoch 1352 - Train Loss: 0.251030, Train Acc: 0.505128 | Val Loss: 0.262328, Val Acc: 0.474227\n",
      "Epoch 1353 - Train Loss: 0.251014, Train Acc: 0.505128 | Val Loss: 0.262312, Val Acc: 0.474227\n",
      "Epoch 1354 - Train Loss: 0.250998, Train Acc: 0.505128 | Val Loss: 0.262297, Val Acc: 0.474227\n",
      "Epoch 1355 - Train Loss: 0.250981, Train Acc: 0.505128 | Val Loss: 0.262281, Val Acc: 0.474227\n",
      "Epoch 1356 - Train Loss: 0.250965, Train Acc: 0.505128 | Val Loss: 0.262266, Val Acc: 0.474227\n",
      "Epoch 1357 - Train Loss: 0.250948, Train Acc: 0.505128 | Val Loss: 0.262250, Val Acc: 0.474227\n",
      "Epoch 1358 - Train Loss: 0.250932, Train Acc: 0.505128 | Val Loss: 0.262235, Val Acc: 0.474227\n",
      "Epoch 1359 - Train Loss: 0.250915, Train Acc: 0.505128 | Val Loss: 0.262219, Val Acc: 0.474227\n",
      "Epoch 1360 - Train Loss: 0.250899, Train Acc: 0.505128 | Val Loss: 0.262203, Val Acc: 0.474227\n",
      "Epoch 1361 - Train Loss: 0.250882, Train Acc: 0.507692 | Val Loss: 0.262188, Val Acc: 0.474227\n",
      "Epoch 1362 - Train Loss: 0.250866, Train Acc: 0.507692 | Val Loss: 0.262172, Val Acc: 0.474227\n",
      "Epoch 1363 - Train Loss: 0.250849, Train Acc: 0.507692 | Val Loss: 0.262156, Val Acc: 0.474227\n",
      "Epoch 1364 - Train Loss: 0.250833, Train Acc: 0.507692 | Val Loss: 0.262141, Val Acc: 0.474227\n",
      "Epoch 1365 - Train Loss: 0.250816, Train Acc: 0.507692 | Val Loss: 0.262125, Val Acc: 0.474227\n",
      "Epoch 1366 - Train Loss: 0.250800, Train Acc: 0.507692 | Val Loss: 0.262109, Val Acc: 0.474227\n",
      "Epoch 1367 - Train Loss: 0.250783, Train Acc: 0.507692 | Val Loss: 0.262093, Val Acc: 0.474227\n",
      "Epoch 1368 - Train Loss: 0.250767, Train Acc: 0.507692 | Val Loss: 0.262078, Val Acc: 0.474227\n",
      "Epoch 1369 - Train Loss: 0.250750, Train Acc: 0.507692 | Val Loss: 0.262062, Val Acc: 0.474227\n",
      "Epoch 1370 - Train Loss: 0.250734, Train Acc: 0.507692 | Val Loss: 0.262046, Val Acc: 0.474227\n",
      "Epoch 1371 - Train Loss: 0.250717, Train Acc: 0.507692 | Val Loss: 0.262030, Val Acc: 0.474227\n",
      "Epoch 1372 - Train Loss: 0.250701, Train Acc: 0.507692 | Val Loss: 0.262015, Val Acc: 0.474227\n",
      "Epoch 1373 - Train Loss: 0.250684, Train Acc: 0.507692 | Val Loss: 0.261999, Val Acc: 0.474227\n",
      "Epoch 1374 - Train Loss: 0.250667, Train Acc: 0.507692 | Val Loss: 0.261983, Val Acc: 0.474227\n",
      "Epoch 1375 - Train Loss: 0.250651, Train Acc: 0.507692 | Val Loss: 0.261968, Val Acc: 0.474227\n",
      "Epoch 1376 - Train Loss: 0.250634, Train Acc: 0.507692 | Val Loss: 0.261952, Val Acc: 0.474227\n",
      "Epoch 1377 - Train Loss: 0.250618, Train Acc: 0.507692 | Val Loss: 0.261936, Val Acc: 0.474227\n",
      "Epoch 1378 - Train Loss: 0.250601, Train Acc: 0.507692 | Val Loss: 0.261920, Val Acc: 0.474227\n",
      "Epoch 1379 - Train Loss: 0.250585, Train Acc: 0.507692 | Val Loss: 0.261905, Val Acc: 0.474227\n",
      "Epoch 1380 - Train Loss: 0.250568, Train Acc: 0.507692 | Val Loss: 0.261889, Val Acc: 0.474227\n",
      "Epoch 1381 - Train Loss: 0.250551, Train Acc: 0.507692 | Val Loss: 0.261873, Val Acc: 0.474227\n",
      "Epoch 1382 - Train Loss: 0.250535, Train Acc: 0.507692 | Val Loss: 0.261857, Val Acc: 0.474227\n",
      "Epoch 1383 - Train Loss: 0.250518, Train Acc: 0.507692 | Val Loss: 0.261841, Val Acc: 0.474227\n",
      "Epoch 1384 - Train Loss: 0.250502, Train Acc: 0.507692 | Val Loss: 0.261825, Val Acc: 0.474227\n",
      "Epoch 1385 - Train Loss: 0.250485, Train Acc: 0.507692 | Val Loss: 0.261809, Val Acc: 0.474227\n",
      "Epoch 1386 - Train Loss: 0.250469, Train Acc: 0.507692 | Val Loss: 0.261793, Val Acc: 0.474227\n",
      "Epoch 1387 - Train Loss: 0.250452, Train Acc: 0.507692 | Val Loss: 0.261778, Val Acc: 0.474227\n",
      "Epoch 1388 - Train Loss: 0.250436, Train Acc: 0.508974 | Val Loss: 0.261762, Val Acc: 0.474227\n",
      "Epoch 1389 - Train Loss: 0.250419, Train Acc: 0.508974 | Val Loss: 0.261746, Val Acc: 0.474227\n",
      "Epoch 1390 - Train Loss: 0.250403, Train Acc: 0.508974 | Val Loss: 0.261730, Val Acc: 0.474227\n",
      "Epoch 1391 - Train Loss: 0.250386, Train Acc: 0.508974 | Val Loss: 0.261714, Val Acc: 0.474227\n",
      "Epoch 1392 - Train Loss: 0.250370, Train Acc: 0.508974 | Val Loss: 0.261698, Val Acc: 0.474227\n",
      "Epoch 1393 - Train Loss: 0.250353, Train Acc: 0.508974 | Val Loss: 0.261682, Val Acc: 0.474227\n",
      "Epoch 1394 - Train Loss: 0.250336, Train Acc: 0.508974 | Val Loss: 0.261667, Val Acc: 0.474227\n",
      "Epoch 1395 - Train Loss: 0.250320, Train Acc: 0.508974 | Val Loss: 0.261651, Val Acc: 0.474227\n",
      "Epoch 1396 - Train Loss: 0.250303, Train Acc: 0.508974 | Val Loss: 0.261635, Val Acc: 0.474227\n",
      "Epoch 1397 - Train Loss: 0.250287, Train Acc: 0.508974 | Val Loss: 0.261619, Val Acc: 0.474227\n",
      "Epoch 1398 - Train Loss: 0.250270, Train Acc: 0.508974 | Val Loss: 0.261603, Val Acc: 0.474227\n",
      "Epoch 1399 - Train Loss: 0.250254, Train Acc: 0.508974 | Val Loss: 0.261587, Val Acc: 0.474227\n",
      "Epoch 1400 - Train Loss: 0.250237, Train Acc: 0.508974 | Val Loss: 0.261572, Val Acc: 0.474227\n",
      "Epoch 1401 - Train Loss: 0.250221, Train Acc: 0.508974 | Val Loss: 0.261556, Val Acc: 0.474227\n",
      "Epoch 1402 - Train Loss: 0.250204, Train Acc: 0.508974 | Val Loss: 0.261540, Val Acc: 0.474227\n",
      "Epoch 1403 - Train Loss: 0.250187, Train Acc: 0.508974 | Val Loss: 0.261524, Val Acc: 0.474227\n",
      "Epoch 1404 - Train Loss: 0.250171, Train Acc: 0.508974 | Val Loss: 0.261508, Val Acc: 0.474227\n",
      "Epoch 1405 - Train Loss: 0.250154, Train Acc: 0.508974 | Val Loss: 0.261492, Val Acc: 0.474227\n",
      "Epoch 1406 - Train Loss: 0.250138, Train Acc: 0.508974 | Val Loss: 0.261477, Val Acc: 0.474227\n",
      "Epoch 1407 - Train Loss: 0.250121, Train Acc: 0.508974 | Val Loss: 0.261461, Val Acc: 0.474227\n",
      "Epoch 1408 - Train Loss: 0.250105, Train Acc: 0.508974 | Val Loss: 0.261445, Val Acc: 0.474227\n",
      "Epoch 1409 - Train Loss: 0.250088, Train Acc: 0.508974 | Val Loss: 0.261429, Val Acc: 0.474227\n",
      "Epoch 1410 - Train Loss: 0.250071, Train Acc: 0.508974 | Val Loss: 0.261413, Val Acc: 0.474227\n",
      "Epoch 1411 - Train Loss: 0.250055, Train Acc: 0.508974 | Val Loss: 0.261398, Val Acc: 0.474227\n",
      "Epoch 1412 - Train Loss: 0.250038, Train Acc: 0.508974 | Val Loss: 0.261382, Val Acc: 0.474227\n",
      "Epoch 1413 - Train Loss: 0.250022, Train Acc: 0.508974 | Val Loss: 0.261367, Val Acc: 0.474227\n",
      "Epoch 1414 - Train Loss: 0.250005, Train Acc: 0.508974 | Val Loss: 0.261351, Val Acc: 0.474227\n",
      "Epoch 1415 - Train Loss: 0.249988, Train Acc: 0.508974 | Val Loss: 0.261335, Val Acc: 0.474227\n",
      "Epoch 1416 - Train Loss: 0.249972, Train Acc: 0.508974 | Val Loss: 0.261320, Val Acc: 0.474227\n",
      "Epoch 1417 - Train Loss: 0.249955, Train Acc: 0.508974 | Val Loss: 0.261304, Val Acc: 0.474227\n",
      "Epoch 1418 - Train Loss: 0.249939, Train Acc: 0.508974 | Val Loss: 0.261288, Val Acc: 0.474227\n",
      "Epoch 1419 - Train Loss: 0.249922, Train Acc: 0.508974 | Val Loss: 0.261272, Val Acc: 0.474227\n",
      "Epoch 1420 - Train Loss: 0.249905, Train Acc: 0.508974 | Val Loss: 0.261257, Val Acc: 0.474227\n",
      "Epoch 1421 - Train Loss: 0.249889, Train Acc: 0.508974 | Val Loss: 0.261241, Val Acc: 0.474227\n",
      "Epoch 1422 - Train Loss: 0.249872, Train Acc: 0.508974 | Val Loss: 0.261225, Val Acc: 0.474227\n",
      "Epoch 1423 - Train Loss: 0.249855, Train Acc: 0.508974 | Val Loss: 0.261209, Val Acc: 0.474227\n",
      "Epoch 1424 - Train Loss: 0.249839, Train Acc: 0.508974 | Val Loss: 0.261194, Val Acc: 0.474227\n",
      "Epoch 1425 - Train Loss: 0.249822, Train Acc: 0.508974 | Val Loss: 0.261178, Val Acc: 0.474227\n",
      "Epoch 1426 - Train Loss: 0.249805, Train Acc: 0.508974 | Val Loss: 0.261162, Val Acc: 0.474227\n",
      "Epoch 1427 - Train Loss: 0.249789, Train Acc: 0.508974 | Val Loss: 0.261146, Val Acc: 0.474227\n",
      "Epoch 1428 - Train Loss: 0.249772, Train Acc: 0.508974 | Val Loss: 0.261131, Val Acc: 0.474227\n",
      "Epoch 1429 - Train Loss: 0.249755, Train Acc: 0.508974 | Val Loss: 0.261115, Val Acc: 0.474227\n",
      "Epoch 1430 - Train Loss: 0.249739, Train Acc: 0.508974 | Val Loss: 0.261100, Val Acc: 0.474227\n",
      "Epoch 1431 - Train Loss: 0.249722, Train Acc: 0.508974 | Val Loss: 0.261084, Val Acc: 0.474227\n",
      "Epoch 1432 - Train Loss: 0.249706, Train Acc: 0.508974 | Val Loss: 0.261069, Val Acc: 0.474227\n",
      "Epoch 1433 - Train Loss: 0.249689, Train Acc: 0.508974 | Val Loss: 0.261053, Val Acc: 0.474227\n",
      "Epoch 1434 - Train Loss: 0.249672, Train Acc: 0.508974 | Val Loss: 0.261037, Val Acc: 0.474227\n",
      "Epoch 1435 - Train Loss: 0.249656, Train Acc: 0.508974 | Val Loss: 0.261022, Val Acc: 0.474227\n",
      "Epoch 1436 - Train Loss: 0.249639, Train Acc: 0.508974 | Val Loss: 0.261006, Val Acc: 0.474227\n",
      "Epoch 1437 - Train Loss: 0.249622, Train Acc: 0.508974 | Val Loss: 0.260990, Val Acc: 0.474227\n",
      "Epoch 1438 - Train Loss: 0.249606, Train Acc: 0.508974 | Val Loss: 0.260974, Val Acc: 0.474227\n",
      "Epoch 1439 - Train Loss: 0.249589, Train Acc: 0.508974 | Val Loss: 0.260958, Val Acc: 0.474227\n",
      "Epoch 1440 - Train Loss: 0.249573, Train Acc: 0.508974 | Val Loss: 0.260942, Val Acc: 0.474227\n",
      "Epoch 1441 - Train Loss: 0.249556, Train Acc: 0.508974 | Val Loss: 0.260927, Val Acc: 0.474227\n",
      "Epoch 1442 - Train Loss: 0.249539, Train Acc: 0.508974 | Val Loss: 0.260911, Val Acc: 0.474227\n",
      "Epoch 1443 - Train Loss: 0.249523, Train Acc: 0.508974 | Val Loss: 0.260895, Val Acc: 0.474227\n",
      "Epoch 1444 - Train Loss: 0.249506, Train Acc: 0.508974 | Val Loss: 0.260879, Val Acc: 0.474227\n",
      "Epoch 1445 - Train Loss: 0.249489, Train Acc: 0.508974 | Val Loss: 0.260863, Val Acc: 0.474227\n",
      "Epoch 1446 - Train Loss: 0.249473, Train Acc: 0.508974 | Val Loss: 0.260847, Val Acc: 0.474227\n",
      "Epoch 1447 - Train Loss: 0.249456, Train Acc: 0.510256 | Val Loss: 0.260832, Val Acc: 0.474227\n",
      "Epoch 1448 - Train Loss: 0.249439, Train Acc: 0.510256 | Val Loss: 0.260816, Val Acc: 0.474227\n",
      "Epoch 1449 - Train Loss: 0.249423, Train Acc: 0.510256 | Val Loss: 0.260800, Val Acc: 0.474227\n",
      "Epoch 1450 - Train Loss: 0.249406, Train Acc: 0.510256 | Val Loss: 0.260784, Val Acc: 0.474227\n",
      "Epoch 1451 - Train Loss: 0.249389, Train Acc: 0.511538 | Val Loss: 0.260769, Val Acc: 0.474227\n",
      "Epoch 1452 - Train Loss: 0.249372, Train Acc: 0.511538 | Val Loss: 0.260753, Val Acc: 0.484536\n",
      "Epoch 1453 - Train Loss: 0.249356, Train Acc: 0.511538 | Val Loss: 0.260737, Val Acc: 0.484536\n",
      "Epoch 1454 - Train Loss: 0.249339, Train Acc: 0.511538 | Val Loss: 0.260721, Val Acc: 0.484536\n",
      "Epoch 1455 - Train Loss: 0.249322, Train Acc: 0.511538 | Val Loss: 0.260705, Val Acc: 0.484536\n",
      "Epoch 1456 - Train Loss: 0.249305, Train Acc: 0.511538 | Val Loss: 0.260689, Val Acc: 0.484536\n",
      "Epoch 1457 - Train Loss: 0.249289, Train Acc: 0.511538 | Val Loss: 0.260673, Val Acc: 0.484536\n",
      "Epoch 1458 - Train Loss: 0.249272, Train Acc: 0.511538 | Val Loss: 0.260657, Val Acc: 0.484536\n",
      "Epoch 1459 - Train Loss: 0.249255, Train Acc: 0.511538 | Val Loss: 0.260641, Val Acc: 0.484536\n",
      "Epoch 1460 - Train Loss: 0.249238, Train Acc: 0.511538 | Val Loss: 0.260625, Val Acc: 0.484536\n",
      "Epoch 1461 - Train Loss: 0.249222, Train Acc: 0.511538 | Val Loss: 0.260609, Val Acc: 0.484536\n",
      "Epoch 1462 - Train Loss: 0.249205, Train Acc: 0.511538 | Val Loss: 0.260593, Val Acc: 0.484536\n",
      "Epoch 1463 - Train Loss: 0.249188, Train Acc: 0.511538 | Val Loss: 0.260577, Val Acc: 0.484536\n",
      "Epoch 1464 - Train Loss: 0.249171, Train Acc: 0.511538 | Val Loss: 0.260561, Val Acc: 0.484536\n",
      "Epoch 1465 - Train Loss: 0.249154, Train Acc: 0.511538 | Val Loss: 0.260544, Val Acc: 0.484536\n",
      "Epoch 1466 - Train Loss: 0.249137, Train Acc: 0.511538 | Val Loss: 0.260528, Val Acc: 0.484536\n",
      "Epoch 1467 - Train Loss: 0.249120, Train Acc: 0.511538 | Val Loss: 0.260512, Val Acc: 0.484536\n",
      "Epoch 1468 - Train Loss: 0.249103, Train Acc: 0.511538 | Val Loss: 0.260495, Val Acc: 0.484536\n",
      "Epoch 1469 - Train Loss: 0.249086, Train Acc: 0.511538 | Val Loss: 0.260479, Val Acc: 0.484536\n",
      "Epoch 1470 - Train Loss: 0.249069, Train Acc: 0.511538 | Val Loss: 0.260462, Val Acc: 0.484536\n",
      "Epoch 1471 - Train Loss: 0.249052, Train Acc: 0.511538 | Val Loss: 0.260446, Val Acc: 0.484536\n",
      "Epoch 1472 - Train Loss: 0.249035, Train Acc: 0.511538 | Val Loss: 0.260430, Val Acc: 0.484536\n",
      "Epoch 1473 - Train Loss: 0.249018, Train Acc: 0.511538 | Val Loss: 0.260414, Val Acc: 0.484536\n",
      "Epoch 1474 - Train Loss: 0.249001, Train Acc: 0.511538 | Val Loss: 0.260398, Val Acc: 0.484536\n",
      "Epoch 1475 - Train Loss: 0.248985, Train Acc: 0.511538 | Val Loss: 0.260382, Val Acc: 0.484536\n",
      "Epoch 1476 - Train Loss: 0.248968, Train Acc: 0.511538 | Val Loss: 0.260366, Val Acc: 0.484536\n",
      "Epoch 1477 - Train Loss: 0.248951, Train Acc: 0.511538 | Val Loss: 0.260349, Val Acc: 0.484536\n",
      "Epoch 1478 - Train Loss: 0.248934, Train Acc: 0.511538 | Val Loss: 0.260333, Val Acc: 0.484536\n",
      "Epoch 1479 - Train Loss: 0.248917, Train Acc: 0.511538 | Val Loss: 0.260317, Val Acc: 0.484536\n",
      "Epoch 1480 - Train Loss: 0.248900, Train Acc: 0.511538 | Val Loss: 0.260301, Val Acc: 0.484536\n",
      "Epoch 1481 - Train Loss: 0.248883, Train Acc: 0.511538 | Val Loss: 0.260285, Val Acc: 0.484536\n",
      "Epoch 1482 - Train Loss: 0.248866, Train Acc: 0.511538 | Val Loss: 0.260269, Val Acc: 0.484536\n",
      "Epoch 1483 - Train Loss: 0.248849, Train Acc: 0.511538 | Val Loss: 0.260253, Val Acc: 0.484536\n",
      "Epoch 1484 - Train Loss: 0.248832, Train Acc: 0.511538 | Val Loss: 0.260237, Val Acc: 0.484536\n",
      "Epoch 1485 - Train Loss: 0.248815, Train Acc: 0.511538 | Val Loss: 0.260221, Val Acc: 0.484536\n",
      "Epoch 1486 - Train Loss: 0.248798, Train Acc: 0.511538 | Val Loss: 0.260204, Val Acc: 0.484536\n",
      "Epoch 1487 - Train Loss: 0.248781, Train Acc: 0.511538 | Val Loss: 0.260188, Val Acc: 0.484536\n",
      "Epoch 1488 - Train Loss: 0.248765, Train Acc: 0.511538 | Val Loss: 0.260172, Val Acc: 0.484536\n",
      "Epoch 1489 - Train Loss: 0.248748, Train Acc: 0.511538 | Val Loss: 0.260156, Val Acc: 0.484536\n",
      "Epoch 1490 - Train Loss: 0.248731, Train Acc: 0.511538 | Val Loss: 0.260140, Val Acc: 0.484536\n",
      "Epoch 1491 - Train Loss: 0.248714, Train Acc: 0.511538 | Val Loss: 0.260124, Val Acc: 0.484536\n",
      "Epoch 1492 - Train Loss: 0.248697, Train Acc: 0.511538 | Val Loss: 0.260108, Val Acc: 0.484536\n",
      "Epoch 1493 - Train Loss: 0.248680, Train Acc: 0.511538 | Val Loss: 0.260092, Val Acc: 0.484536\n",
      "Epoch 1494 - Train Loss: 0.248663, Train Acc: 0.511538 | Val Loss: 0.260076, Val Acc: 0.484536\n",
      "Epoch 1495 - Train Loss: 0.248646, Train Acc: 0.511538 | Val Loss: 0.260059, Val Acc: 0.484536\n",
      "Epoch 1496 - Train Loss: 0.248629, Train Acc: 0.511538 | Val Loss: 0.260043, Val Acc: 0.484536\n",
      "Epoch 1497 - Train Loss: 0.248612, Train Acc: 0.511538 | Val Loss: 0.260027, Val Acc: 0.484536\n",
      "Epoch 1498 - Train Loss: 0.248595, Train Acc: 0.511538 | Val Loss: 0.260011, Val Acc: 0.484536\n",
      "Epoch 1499 - Train Loss: 0.248578, Train Acc: 0.511538 | Val Loss: 0.259995, Val Acc: 0.484536\n",
      "Epoch 1500 - Train Loss: 0.248561, Train Acc: 0.511538 | Val Loss: 0.259978, Val Acc: 0.484536\n",
      "Epoch 1501 - Train Loss: 0.248543, Train Acc: 0.511538 | Val Loss: 0.259962, Val Acc: 0.484536\n",
      "Epoch 1502 - Train Loss: 0.248526, Train Acc: 0.511538 | Val Loss: 0.259946, Val Acc: 0.484536\n",
      "Epoch 1503 - Train Loss: 0.248509, Train Acc: 0.511538 | Val Loss: 0.259929, Val Acc: 0.484536\n",
      "Epoch 1504 - Train Loss: 0.248492, Train Acc: 0.511538 | Val Loss: 0.259913, Val Acc: 0.484536\n",
      "Epoch 1505 - Train Loss: 0.248475, Train Acc: 0.511538 | Val Loss: 0.259897, Val Acc: 0.484536\n",
      "Epoch 1506 - Train Loss: 0.248458, Train Acc: 0.511538 | Val Loss: 0.259881, Val Acc: 0.484536\n",
      "Epoch 1507 - Train Loss: 0.248441, Train Acc: 0.511538 | Val Loss: 0.259864, Val Acc: 0.484536\n",
      "Epoch 1508 - Train Loss: 0.248423, Train Acc: 0.511538 | Val Loss: 0.259848, Val Acc: 0.484536\n",
      "Epoch 1509 - Train Loss: 0.248406, Train Acc: 0.511538 | Val Loss: 0.259832, Val Acc: 0.484536\n",
      "Epoch 1510 - Train Loss: 0.248389, Train Acc: 0.511538 | Val Loss: 0.259815, Val Acc: 0.484536\n",
      "Epoch 1511 - Train Loss: 0.248372, Train Acc: 0.511538 | Val Loss: 0.259799, Val Acc: 0.484536\n",
      "Epoch 1512 - Train Loss: 0.248355, Train Acc: 0.511538 | Val Loss: 0.259783, Val Acc: 0.484536\n",
      "Epoch 1513 - Train Loss: 0.248337, Train Acc: 0.511538 | Val Loss: 0.259766, Val Acc: 0.484536\n",
      "Epoch 1514 - Train Loss: 0.248320, Train Acc: 0.511538 | Val Loss: 0.259750, Val Acc: 0.484536\n",
      "Epoch 1515 - Train Loss: 0.248303, Train Acc: 0.511538 | Val Loss: 0.259734, Val Acc: 0.484536\n",
      "Epoch 1516 - Train Loss: 0.248286, Train Acc: 0.511538 | Val Loss: 0.259717, Val Acc: 0.484536\n",
      "Epoch 1517 - Train Loss: 0.248269, Train Acc: 0.511538 | Val Loss: 0.259701, Val Acc: 0.484536\n",
      "Epoch 1518 - Train Loss: 0.248251, Train Acc: 0.511538 | Val Loss: 0.259685, Val Acc: 0.484536\n",
      "Epoch 1519 - Train Loss: 0.248234, Train Acc: 0.511538 | Val Loss: 0.259668, Val Acc: 0.484536\n",
      "Epoch 1520 - Train Loss: 0.248217, Train Acc: 0.511538 | Val Loss: 0.259652, Val Acc: 0.484536\n",
      "Epoch 1521 - Train Loss: 0.248200, Train Acc: 0.511538 | Val Loss: 0.259636, Val Acc: 0.484536\n",
      "Epoch 1522 - Train Loss: 0.248183, Train Acc: 0.511538 | Val Loss: 0.259619, Val Acc: 0.484536\n",
      "Epoch 1523 - Train Loss: 0.248165, Train Acc: 0.511538 | Val Loss: 0.259603, Val Acc: 0.484536\n",
      "Epoch 1524 - Train Loss: 0.248148, Train Acc: 0.511538 | Val Loss: 0.259586, Val Acc: 0.484536\n",
      "Epoch 1525 - Train Loss: 0.248131, Train Acc: 0.511538 | Val Loss: 0.259569, Val Acc: 0.484536\n",
      "Epoch 1526 - Train Loss: 0.248114, Train Acc: 0.511538 | Val Loss: 0.259552, Val Acc: 0.484536\n",
      "Epoch 1527 - Train Loss: 0.248096, Train Acc: 0.511538 | Val Loss: 0.259536, Val Acc: 0.484536\n",
      "Epoch 1528 - Train Loss: 0.248079, Train Acc: 0.511538 | Val Loss: 0.259519, Val Acc: 0.484536\n",
      "Epoch 1529 - Train Loss: 0.248062, Train Acc: 0.511538 | Val Loss: 0.259502, Val Acc: 0.484536\n",
      "Epoch 1530 - Train Loss: 0.248044, Train Acc: 0.511538 | Val Loss: 0.259485, Val Acc: 0.484536\n",
      "Epoch 1531 - Train Loss: 0.248027, Train Acc: 0.511538 | Val Loss: 0.259468, Val Acc: 0.484536\n",
      "Epoch 1532 - Train Loss: 0.248010, Train Acc: 0.511538 | Val Loss: 0.259451, Val Acc: 0.484536\n",
      "Epoch 1533 - Train Loss: 0.247992, Train Acc: 0.511538 | Val Loss: 0.259434, Val Acc: 0.484536\n",
      "Epoch 1534 - Train Loss: 0.247975, Train Acc: 0.511538 | Val Loss: 0.259417, Val Acc: 0.484536\n",
      "Epoch 1535 - Train Loss: 0.247958, Train Acc: 0.511538 | Val Loss: 0.259401, Val Acc: 0.484536\n",
      "Epoch 1536 - Train Loss: 0.247941, Train Acc: 0.511538 | Val Loss: 0.259384, Val Acc: 0.484536\n",
      "Epoch 1537 - Train Loss: 0.247923, Train Acc: 0.511538 | Val Loss: 0.259367, Val Acc: 0.484536\n",
      "Epoch 1538 - Train Loss: 0.247906, Train Acc: 0.511538 | Val Loss: 0.259350, Val Acc: 0.484536\n",
      "Epoch 1539 - Train Loss: 0.247889, Train Acc: 0.511538 | Val Loss: 0.259333, Val Acc: 0.484536\n",
      "Epoch 1540 - Train Loss: 0.247871, Train Acc: 0.511538 | Val Loss: 0.259316, Val Acc: 0.484536\n",
      "Epoch 1541 - Train Loss: 0.247854, Train Acc: 0.511538 | Val Loss: 0.259299, Val Acc: 0.484536\n",
      "Epoch 1542 - Train Loss: 0.247837, Train Acc: 0.511538 | Val Loss: 0.259283, Val Acc: 0.484536\n",
      "Epoch 1543 - Train Loss: 0.247819, Train Acc: 0.511538 | Val Loss: 0.259266, Val Acc: 0.484536\n",
      "Epoch 1544 - Train Loss: 0.247802, Train Acc: 0.511538 | Val Loss: 0.259249, Val Acc: 0.484536\n",
      "Epoch 1545 - Train Loss: 0.247785, Train Acc: 0.511538 | Val Loss: 0.259232, Val Acc: 0.484536\n",
      "Epoch 1546 - Train Loss: 0.247767, Train Acc: 0.511538 | Val Loss: 0.259215, Val Acc: 0.484536\n",
      "Epoch 1547 - Train Loss: 0.247750, Train Acc: 0.511538 | Val Loss: 0.259199, Val Acc: 0.484536\n",
      "Epoch 1548 - Train Loss: 0.247732, Train Acc: 0.511538 | Val Loss: 0.259182, Val Acc: 0.484536\n",
      "Epoch 1549 - Train Loss: 0.247715, Train Acc: 0.511538 | Val Loss: 0.259165, Val Acc: 0.484536\n",
      "Epoch 1550 - Train Loss: 0.247698, Train Acc: 0.511538 | Val Loss: 0.259148, Val Acc: 0.484536\n",
      "Epoch 1551 - Train Loss: 0.247680, Train Acc: 0.511538 | Val Loss: 0.259131, Val Acc: 0.484536\n",
      "Epoch 1552 - Train Loss: 0.247663, Train Acc: 0.511538 | Val Loss: 0.259114, Val Acc: 0.484536\n",
      "Epoch 1553 - Train Loss: 0.247645, Train Acc: 0.511538 | Val Loss: 0.259097, Val Acc: 0.484536\n",
      "Epoch 1554 - Train Loss: 0.247628, Train Acc: 0.511538 | Val Loss: 0.259080, Val Acc: 0.484536\n",
      "Epoch 1555 - Train Loss: 0.247610, Train Acc: 0.511538 | Val Loss: 0.259064, Val Acc: 0.484536\n",
      "Epoch 1556 - Train Loss: 0.247593, Train Acc: 0.511538 | Val Loss: 0.259047, Val Acc: 0.484536\n",
      "Epoch 1557 - Train Loss: 0.247576, Train Acc: 0.512821 | Val Loss: 0.259030, Val Acc: 0.484536\n",
      "Epoch 1558 - Train Loss: 0.247558, Train Acc: 0.512821 | Val Loss: 0.259013, Val Acc: 0.484536\n",
      "Epoch 1559 - Train Loss: 0.247541, Train Acc: 0.512821 | Val Loss: 0.258996, Val Acc: 0.484536\n",
      "Epoch 1560 - Train Loss: 0.247523, Train Acc: 0.512821 | Val Loss: 0.258979, Val Acc: 0.484536\n",
      "Epoch 1561 - Train Loss: 0.247506, Train Acc: 0.512821 | Val Loss: 0.258962, Val Acc: 0.484536\n",
      "Epoch 1562 - Train Loss: 0.247488, Train Acc: 0.512821 | Val Loss: 0.258946, Val Acc: 0.484536\n",
      "Epoch 1563 - Train Loss: 0.247471, Train Acc: 0.512821 | Val Loss: 0.258929, Val Acc: 0.484536\n",
      "Epoch 1564 - Train Loss: 0.247454, Train Acc: 0.512821 | Val Loss: 0.258912, Val Acc: 0.484536\n",
      "Epoch 1565 - Train Loss: 0.247436, Train Acc: 0.512821 | Val Loss: 0.258895, Val Acc: 0.484536\n",
      "Epoch 1566 - Train Loss: 0.247419, Train Acc: 0.512821 | Val Loss: 0.258878, Val Acc: 0.484536\n",
      "Epoch 1567 - Train Loss: 0.247401, Train Acc: 0.512821 | Val Loss: 0.258862, Val Acc: 0.484536\n",
      "Epoch 1568 - Train Loss: 0.247384, Train Acc: 0.512821 | Val Loss: 0.258845, Val Acc: 0.484536\n",
      "Epoch 1569 - Train Loss: 0.247366, Train Acc: 0.512821 | Val Loss: 0.258828, Val Acc: 0.484536\n",
      "Epoch 1570 - Train Loss: 0.247349, Train Acc: 0.512821 | Val Loss: 0.258811, Val Acc: 0.484536\n",
      "Epoch 1571 - Train Loss: 0.247331, Train Acc: 0.512821 | Val Loss: 0.258794, Val Acc: 0.484536\n",
      "Epoch 1572 - Train Loss: 0.247314, Train Acc: 0.512821 | Val Loss: 0.258777, Val Acc: 0.484536\n",
      "Epoch 1573 - Train Loss: 0.247296, Train Acc: 0.512821 | Val Loss: 0.258760, Val Acc: 0.484536\n",
      "Epoch 1574 - Train Loss: 0.247279, Train Acc: 0.512821 | Val Loss: 0.258743, Val Acc: 0.484536\n",
      "Epoch 1575 - Train Loss: 0.247261, Train Acc: 0.512821 | Val Loss: 0.258726, Val Acc: 0.484536\n",
      "Epoch 1576 - Train Loss: 0.247244, Train Acc: 0.512821 | Val Loss: 0.258710, Val Acc: 0.484536\n",
      "Epoch 1577 - Train Loss: 0.247226, Train Acc: 0.512821 | Val Loss: 0.258693, Val Acc: 0.484536\n",
      "Epoch 1578 - Train Loss: 0.247209, Train Acc: 0.512821 | Val Loss: 0.258676, Val Acc: 0.484536\n",
      "Epoch 1579 - Train Loss: 0.247191, Train Acc: 0.512821 | Val Loss: 0.258659, Val Acc: 0.484536\n",
      "Epoch 1580 - Train Loss: 0.247173, Train Acc: 0.512821 | Val Loss: 0.258642, Val Acc: 0.484536\n",
      "Epoch 1581 - Train Loss: 0.247156, Train Acc: 0.512821 | Val Loss: 0.258625, Val Acc: 0.484536\n",
      "Epoch 1582 - Train Loss: 0.247138, Train Acc: 0.512821 | Val Loss: 0.258608, Val Acc: 0.484536\n",
      "Epoch 1583 - Train Loss: 0.247121, Train Acc: 0.512821 | Val Loss: 0.258591, Val Acc: 0.484536\n",
      "Epoch 1584 - Train Loss: 0.247103, Train Acc: 0.512821 | Val Loss: 0.258574, Val Acc: 0.484536\n",
      "Epoch 1585 - Train Loss: 0.247086, Train Acc: 0.512821 | Val Loss: 0.258557, Val Acc: 0.484536\n",
      "Epoch 1586 - Train Loss: 0.247068, Train Acc: 0.512821 | Val Loss: 0.258540, Val Acc: 0.484536\n",
      "Epoch 1587 - Train Loss: 0.247051, Train Acc: 0.512821 | Val Loss: 0.258523, Val Acc: 0.484536\n",
      "Epoch 1588 - Train Loss: 0.247033, Train Acc: 0.512821 | Val Loss: 0.258507, Val Acc: 0.484536\n",
      "Epoch 1589 - Train Loss: 0.247015, Train Acc: 0.512821 | Val Loss: 0.258490, Val Acc: 0.484536\n",
      "Epoch 1590 - Train Loss: 0.246998, Train Acc: 0.512821 | Val Loss: 0.258473, Val Acc: 0.484536\n",
      "Epoch 1591 - Train Loss: 0.246980, Train Acc: 0.512821 | Val Loss: 0.258456, Val Acc: 0.484536\n",
      "Epoch 1592 - Train Loss: 0.246963, Train Acc: 0.512821 | Val Loss: 0.258439, Val Acc: 0.484536\n",
      "Epoch 1593 - Train Loss: 0.246945, Train Acc: 0.512821 | Val Loss: 0.258422, Val Acc: 0.484536\n",
      "Epoch 1594 - Train Loss: 0.246928, Train Acc: 0.512821 | Val Loss: 0.258405, Val Acc: 0.484536\n",
      "Epoch 1595 - Train Loss: 0.246910, Train Acc: 0.512821 | Val Loss: 0.258389, Val Acc: 0.484536\n",
      "Epoch 1596 - Train Loss: 0.246892, Train Acc: 0.512821 | Val Loss: 0.258372, Val Acc: 0.484536\n",
      "Epoch 1597 - Train Loss: 0.246875, Train Acc: 0.512821 | Val Loss: 0.258355, Val Acc: 0.484536\n",
      "Epoch 1598 - Train Loss: 0.246857, Train Acc: 0.512821 | Val Loss: 0.258338, Val Acc: 0.484536\n",
      "Epoch 1599 - Train Loss: 0.246839, Train Acc: 0.512821 | Val Loss: 0.258321, Val Acc: 0.484536\n",
      "Epoch 1600 - Train Loss: 0.246822, Train Acc: 0.512821 | Val Loss: 0.258305, Val Acc: 0.484536\n",
      "Epoch 1601 - Train Loss: 0.246804, Train Acc: 0.512821 | Val Loss: 0.258288, Val Acc: 0.484536\n",
      "Epoch 1602 - Train Loss: 0.246787, Train Acc: 0.512821 | Val Loss: 0.258271, Val Acc: 0.484536\n",
      "Epoch 1603 - Train Loss: 0.246769, Train Acc: 0.512821 | Val Loss: 0.258254, Val Acc: 0.484536\n",
      "Epoch 1604 - Train Loss: 0.246751, Train Acc: 0.512821 | Val Loss: 0.258237, Val Acc: 0.484536\n",
      "Epoch 1605 - Train Loss: 0.246734, Train Acc: 0.512821 | Val Loss: 0.258221, Val Acc: 0.484536\n",
      "Epoch 1606 - Train Loss: 0.246716, Train Acc: 0.512821 | Val Loss: 0.258204, Val Acc: 0.484536\n",
      "Epoch 1607 - Train Loss: 0.246698, Train Acc: 0.512821 | Val Loss: 0.258187, Val Acc: 0.484536\n",
      "Epoch 1608 - Train Loss: 0.246681, Train Acc: 0.514103 | Val Loss: 0.258170, Val Acc: 0.484536\n",
      "Epoch 1609 - Train Loss: 0.246663, Train Acc: 0.514103 | Val Loss: 0.258153, Val Acc: 0.484536\n",
      "Epoch 1610 - Train Loss: 0.246645, Train Acc: 0.514103 | Val Loss: 0.258137, Val Acc: 0.484536\n",
      "Epoch 1611 - Train Loss: 0.246628, Train Acc: 0.514103 | Val Loss: 0.258120, Val Acc: 0.484536\n",
      "Epoch 1612 - Train Loss: 0.246610, Train Acc: 0.514103 | Val Loss: 0.258103, Val Acc: 0.484536\n",
      "Epoch 1613 - Train Loss: 0.246593, Train Acc: 0.514103 | Val Loss: 0.258086, Val Acc: 0.484536\n",
      "Epoch 1614 - Train Loss: 0.246575, Train Acc: 0.514103 | Val Loss: 0.258070, Val Acc: 0.484536\n",
      "Epoch 1615 - Train Loss: 0.246557, Train Acc: 0.514103 | Val Loss: 0.258053, Val Acc: 0.484536\n",
      "Epoch 1616 - Train Loss: 0.246540, Train Acc: 0.514103 | Val Loss: 0.258036, Val Acc: 0.484536\n",
      "Epoch 1617 - Train Loss: 0.246522, Train Acc: 0.514103 | Val Loss: 0.258020, Val Acc: 0.484536\n",
      "Epoch 1618 - Train Loss: 0.246504, Train Acc: 0.514103 | Val Loss: 0.258003, Val Acc: 0.484536\n",
      "Epoch 1619 - Train Loss: 0.246487, Train Acc: 0.514103 | Val Loss: 0.257987, Val Acc: 0.484536\n",
      "Epoch 1620 - Train Loss: 0.246469, Train Acc: 0.514103 | Val Loss: 0.257970, Val Acc: 0.484536\n",
      "Epoch 1621 - Train Loss: 0.246451, Train Acc: 0.514103 | Val Loss: 0.257954, Val Acc: 0.484536\n",
      "Epoch 1622 - Train Loss: 0.246434, Train Acc: 0.514103 | Val Loss: 0.257937, Val Acc: 0.484536\n",
      "Epoch 1623 - Train Loss: 0.246416, Train Acc: 0.514103 | Val Loss: 0.257921, Val Acc: 0.484536\n",
      "Epoch 1624 - Train Loss: 0.246399, Train Acc: 0.514103 | Val Loss: 0.257904, Val Acc: 0.484536\n",
      "Epoch 1625 - Train Loss: 0.246381, Train Acc: 0.514103 | Val Loss: 0.257888, Val Acc: 0.494845\n",
      "Epoch 1626 - Train Loss: 0.246363, Train Acc: 0.514103 | Val Loss: 0.257871, Val Acc: 0.494845\n",
      "Epoch 1627 - Train Loss: 0.246346, Train Acc: 0.514103 | Val Loss: 0.257855, Val Acc: 0.494845\n",
      "Epoch 1628 - Train Loss: 0.246328, Train Acc: 0.514103 | Val Loss: 0.257838, Val Acc: 0.494845\n",
      "Epoch 1629 - Train Loss: 0.246311, Train Acc: 0.514103 | Val Loss: 0.257822, Val Acc: 0.494845\n",
      "Epoch 1630 - Train Loss: 0.246293, Train Acc: 0.514103 | Val Loss: 0.257806, Val Acc: 0.494845\n",
      "Epoch 1631 - Train Loss: 0.246275, Train Acc: 0.514103 | Val Loss: 0.257789, Val Acc: 0.494845\n",
      "Epoch 1632 - Train Loss: 0.246258, Train Acc: 0.514103 | Val Loss: 0.257773, Val Acc: 0.494845\n",
      "Epoch 1633 - Train Loss: 0.246240, Train Acc: 0.514103 | Val Loss: 0.257756, Val Acc: 0.494845\n",
      "Epoch 1634 - Train Loss: 0.246222, Train Acc: 0.514103 | Val Loss: 0.257740, Val Acc: 0.494845\n",
      "Epoch 1635 - Train Loss: 0.246205, Train Acc: 0.514103 | Val Loss: 0.257724, Val Acc: 0.494845\n",
      "Epoch 1636 - Train Loss: 0.246187, Train Acc: 0.514103 | Val Loss: 0.257707, Val Acc: 0.494845\n",
      "Epoch 1637 - Train Loss: 0.246170, Train Acc: 0.514103 | Val Loss: 0.257691, Val Acc: 0.494845\n",
      "Epoch 1638 - Train Loss: 0.246152, Train Acc: 0.515385 | Val Loss: 0.257675, Val Acc: 0.494845\n",
      "Epoch 1639 - Train Loss: 0.246134, Train Acc: 0.515385 | Val Loss: 0.257659, Val Acc: 0.494845\n",
      "Epoch 1640 - Train Loss: 0.246117, Train Acc: 0.515385 | Val Loss: 0.257642, Val Acc: 0.494845\n",
      "Epoch 1641 - Train Loss: 0.246099, Train Acc: 0.515385 | Val Loss: 0.257626, Val Acc: 0.494845\n",
      "Epoch 1642 - Train Loss: 0.246081, Train Acc: 0.515385 | Val Loss: 0.257609, Val Acc: 0.494845\n",
      "Epoch 1643 - Train Loss: 0.246064, Train Acc: 0.515385 | Val Loss: 0.257593, Val Acc: 0.494845\n",
      "Epoch 1644 - Train Loss: 0.246046, Train Acc: 0.517949 | Val Loss: 0.257577, Val Acc: 0.494845\n",
      "Epoch 1645 - Train Loss: 0.246028, Train Acc: 0.517949 | Val Loss: 0.257560, Val Acc: 0.494845\n",
      "Epoch 1646 - Train Loss: 0.246011, Train Acc: 0.517949 | Val Loss: 0.257544, Val Acc: 0.494845\n",
      "Epoch 1647 - Train Loss: 0.245993, Train Acc: 0.517949 | Val Loss: 0.257527, Val Acc: 0.494845\n",
      "Epoch 1648 - Train Loss: 0.245975, Train Acc: 0.517949 | Val Loss: 0.257511, Val Acc: 0.494845\n",
      "Epoch 1649 - Train Loss: 0.245958, Train Acc: 0.517949 | Val Loss: 0.257495, Val Acc: 0.494845\n",
      "Epoch 1650 - Train Loss: 0.245940, Train Acc: 0.517949 | Val Loss: 0.257478, Val Acc: 0.494845\n",
      "Epoch 1651 - Train Loss: 0.245922, Train Acc: 0.517949 | Val Loss: 0.257462, Val Acc: 0.494845\n",
      "Epoch 1652 - Train Loss: 0.245905, Train Acc: 0.517949 | Val Loss: 0.257445, Val Acc: 0.494845\n",
      "Epoch 1653 - Train Loss: 0.245887, Train Acc: 0.517949 | Val Loss: 0.257429, Val Acc: 0.494845\n",
      "Epoch 1654 - Train Loss: 0.245869, Train Acc: 0.517949 | Val Loss: 0.257412, Val Acc: 0.494845\n",
      "Epoch 1655 - Train Loss: 0.245851, Train Acc: 0.517949 | Val Loss: 0.257395, Val Acc: 0.494845\n",
      "Epoch 1656 - Train Loss: 0.245834, Train Acc: 0.517949 | Val Loss: 0.257379, Val Acc: 0.494845\n",
      "Epoch 1657 - Train Loss: 0.245816, Train Acc: 0.517949 | Val Loss: 0.257362, Val Acc: 0.494845\n",
      "Epoch 1658 - Train Loss: 0.245798, Train Acc: 0.517949 | Val Loss: 0.257346, Val Acc: 0.494845\n",
      "Epoch 1659 - Train Loss: 0.245781, Train Acc: 0.517949 | Val Loss: 0.257329, Val Acc: 0.494845\n",
      "Epoch 1660 - Train Loss: 0.245763, Train Acc: 0.517949 | Val Loss: 0.257313, Val Acc: 0.494845\n",
      "Epoch 1661 - Train Loss: 0.245745, Train Acc: 0.517949 | Val Loss: 0.257296, Val Acc: 0.494845\n",
      "Epoch 1662 - Train Loss: 0.245727, Train Acc: 0.517949 | Val Loss: 0.257280, Val Acc: 0.494845\n",
      "Epoch 1663 - Train Loss: 0.245710, Train Acc: 0.517949 | Val Loss: 0.257263, Val Acc: 0.494845\n",
      "Epoch 1664 - Train Loss: 0.245692, Train Acc: 0.517949 | Val Loss: 0.257247, Val Acc: 0.494845\n",
      "Epoch 1665 - Train Loss: 0.245674, Train Acc: 0.517949 | Val Loss: 0.257230, Val Acc: 0.494845\n",
      "Epoch 1666 - Train Loss: 0.245656, Train Acc: 0.517949 | Val Loss: 0.257213, Val Acc: 0.494845\n",
      "Epoch 1667 - Train Loss: 0.245639, Train Acc: 0.517949 | Val Loss: 0.257197, Val Acc: 0.494845\n",
      "Epoch 1668 - Train Loss: 0.245621, Train Acc: 0.517949 | Val Loss: 0.257180, Val Acc: 0.494845\n",
      "Epoch 1669 - Train Loss: 0.245603, Train Acc: 0.517949 | Val Loss: 0.257163, Val Acc: 0.494845\n",
      "Epoch 1670 - Train Loss: 0.245585, Train Acc: 0.517949 | Val Loss: 0.257147, Val Acc: 0.494845\n",
      "Epoch 1671 - Train Loss: 0.245568, Train Acc: 0.517949 | Val Loss: 0.257130, Val Acc: 0.494845\n",
      "Epoch 1672 - Train Loss: 0.245550, Train Acc: 0.517949 | Val Loss: 0.257113, Val Acc: 0.494845\n",
      "Epoch 1673 - Train Loss: 0.245532, Train Acc: 0.519231 | Val Loss: 0.257097, Val Acc: 0.494845\n",
      "Epoch 1674 - Train Loss: 0.245514, Train Acc: 0.519231 | Val Loss: 0.257080, Val Acc: 0.494845\n",
      "Epoch 1675 - Train Loss: 0.245497, Train Acc: 0.519231 | Val Loss: 0.257063, Val Acc: 0.494845\n",
      "Epoch 1676 - Train Loss: 0.245479, Train Acc: 0.519231 | Val Loss: 0.257046, Val Acc: 0.494845\n",
      "Epoch 1677 - Train Loss: 0.245461, Train Acc: 0.519231 | Val Loss: 0.257030, Val Acc: 0.494845\n",
      "Epoch 1678 - Train Loss: 0.245443, Train Acc: 0.519231 | Val Loss: 0.257013, Val Acc: 0.494845\n",
      "Epoch 1679 - Train Loss: 0.245426, Train Acc: 0.519231 | Val Loss: 0.256996, Val Acc: 0.494845\n",
      "Epoch 1680 - Train Loss: 0.245408, Train Acc: 0.519231 | Val Loss: 0.256980, Val Acc: 0.494845\n",
      "Epoch 1681 - Train Loss: 0.245390, Train Acc: 0.519231 | Val Loss: 0.256963, Val Acc: 0.494845\n",
      "Epoch 1682 - Train Loss: 0.245372, Train Acc: 0.519231 | Val Loss: 0.256946, Val Acc: 0.494845\n",
      "Epoch 1683 - Train Loss: 0.245355, Train Acc: 0.519231 | Val Loss: 0.256930, Val Acc: 0.494845\n",
      "Epoch 1684 - Train Loss: 0.245337, Train Acc: 0.519231 | Val Loss: 0.256913, Val Acc: 0.494845\n",
      "Epoch 1685 - Train Loss: 0.245319, Train Acc: 0.519231 | Val Loss: 0.256896, Val Acc: 0.494845\n",
      "Epoch 1686 - Train Loss: 0.245301, Train Acc: 0.519231 | Val Loss: 0.256880, Val Acc: 0.494845\n",
      "Epoch 1687 - Train Loss: 0.245284, Train Acc: 0.519231 | Val Loss: 0.256863, Val Acc: 0.494845\n",
      "Epoch 1688 - Train Loss: 0.245266, Train Acc: 0.519231 | Val Loss: 0.256846, Val Acc: 0.494845\n",
      "Epoch 1689 - Train Loss: 0.245248, Train Acc: 0.519231 | Val Loss: 0.256830, Val Acc: 0.494845\n",
      "Epoch 1690 - Train Loss: 0.245230, Train Acc: 0.519231 | Val Loss: 0.256813, Val Acc: 0.494845\n",
      "Epoch 1691 - Train Loss: 0.245213, Train Acc: 0.519231 | Val Loss: 0.256796, Val Acc: 0.494845\n",
      "Epoch 1692 - Train Loss: 0.245195, Train Acc: 0.519231 | Val Loss: 0.256779, Val Acc: 0.494845\n",
      "Epoch 1693 - Train Loss: 0.245177, Train Acc: 0.519231 | Val Loss: 0.256763, Val Acc: 0.494845\n",
      "Epoch 1694 - Train Loss: 0.245159, Train Acc: 0.519231 | Val Loss: 0.256746, Val Acc: 0.494845\n",
      "Epoch 1695 - Train Loss: 0.245141, Train Acc: 0.519231 | Val Loss: 0.256729, Val Acc: 0.494845\n",
      "Epoch 1696 - Train Loss: 0.245124, Train Acc: 0.519231 | Val Loss: 0.256712, Val Acc: 0.494845\n",
      "Epoch 1697 - Train Loss: 0.245106, Train Acc: 0.519231 | Val Loss: 0.256696, Val Acc: 0.494845\n",
      "Epoch 1698 - Train Loss: 0.245088, Train Acc: 0.519231 | Val Loss: 0.256679, Val Acc: 0.494845\n",
      "Epoch 1699 - Train Loss: 0.245070, Train Acc: 0.519231 | Val Loss: 0.256662, Val Acc: 0.494845\n",
      "Epoch 1700 - Train Loss: 0.245052, Train Acc: 0.519231 | Val Loss: 0.256645, Val Acc: 0.494845\n",
      "Epoch 1701 - Train Loss: 0.245035, Train Acc: 0.519231 | Val Loss: 0.256628, Val Acc: 0.494845\n",
      "Epoch 1702 - Train Loss: 0.245017, Train Acc: 0.519231 | Val Loss: 0.256612, Val Acc: 0.494845\n",
      "Epoch 1703 - Train Loss: 0.244999, Train Acc: 0.519231 | Val Loss: 0.256595, Val Acc: 0.494845\n",
      "Epoch 1704 - Train Loss: 0.244981, Train Acc: 0.519231 | Val Loss: 0.256578, Val Acc: 0.494845\n",
      "Epoch 1705 - Train Loss: 0.244963, Train Acc: 0.519231 | Val Loss: 0.256561, Val Acc: 0.494845\n",
      "Epoch 1706 - Train Loss: 0.244945, Train Acc: 0.519231 | Val Loss: 0.256545, Val Acc: 0.494845\n",
      "Epoch 1707 - Train Loss: 0.244928, Train Acc: 0.519231 | Val Loss: 0.256528, Val Acc: 0.494845\n",
      "Epoch 1708 - Train Loss: 0.244910, Train Acc: 0.519231 | Val Loss: 0.256511, Val Acc: 0.494845\n",
      "Epoch 1709 - Train Loss: 0.244892, Train Acc: 0.519231 | Val Loss: 0.256494, Val Acc: 0.494845\n",
      "Epoch 1710 - Train Loss: 0.244874, Train Acc: 0.519231 | Val Loss: 0.256477, Val Acc: 0.494845\n",
      "Epoch 1711 - Train Loss: 0.244856, Train Acc: 0.519231 | Val Loss: 0.256460, Val Acc: 0.494845\n",
      "Epoch 1712 - Train Loss: 0.244838, Train Acc: 0.519231 | Val Loss: 0.256443, Val Acc: 0.494845\n",
      "Epoch 1713 - Train Loss: 0.244820, Train Acc: 0.519231 | Val Loss: 0.256426, Val Acc: 0.494845\n",
      "Epoch 1714 - Train Loss: 0.244802, Train Acc: 0.519231 | Val Loss: 0.256409, Val Acc: 0.494845\n",
      "Epoch 1715 - Train Loss: 0.244784, Train Acc: 0.519231 | Val Loss: 0.256392, Val Acc: 0.494845\n",
      "Epoch 1716 - Train Loss: 0.244766, Train Acc: 0.519231 | Val Loss: 0.256375, Val Acc: 0.494845\n",
      "Epoch 1717 - Train Loss: 0.244748, Train Acc: 0.519231 | Val Loss: 0.256358, Val Acc: 0.494845\n",
      "Epoch 1718 - Train Loss: 0.244730, Train Acc: 0.519231 | Val Loss: 0.256341, Val Acc: 0.494845\n",
      "Epoch 1719 - Train Loss: 0.244712, Train Acc: 0.519231 | Val Loss: 0.256324, Val Acc: 0.494845\n",
      "Epoch 1720 - Train Loss: 0.244694, Train Acc: 0.519231 | Val Loss: 0.256307, Val Acc: 0.494845\n",
      "Epoch 1721 - Train Loss: 0.244676, Train Acc: 0.519231 | Val Loss: 0.256290, Val Acc: 0.494845\n",
      "Epoch 1722 - Train Loss: 0.244658, Train Acc: 0.519231 | Val Loss: 0.256273, Val Acc: 0.494845\n",
      "Epoch 1723 - Train Loss: 0.244640, Train Acc: 0.519231 | Val Loss: 0.256257, Val Acc: 0.494845\n",
      "Epoch 1724 - Train Loss: 0.244622, Train Acc: 0.519231 | Val Loss: 0.256240, Val Acc: 0.494845\n",
      "Epoch 1725 - Train Loss: 0.244604, Train Acc: 0.519231 | Val Loss: 0.256223, Val Acc: 0.494845\n",
      "Epoch 1726 - Train Loss: 0.244586, Train Acc: 0.519231 | Val Loss: 0.256206, Val Acc: 0.494845\n",
      "Epoch 1727 - Train Loss: 0.244568, Train Acc: 0.519231 | Val Loss: 0.256188, Val Acc: 0.494845\n",
      "Epoch 1728 - Train Loss: 0.244550, Train Acc: 0.519231 | Val Loss: 0.256171, Val Acc: 0.494845\n",
      "Epoch 1729 - Train Loss: 0.244532, Train Acc: 0.519231 | Val Loss: 0.256154, Val Acc: 0.494845\n",
      "Epoch 1730 - Train Loss: 0.244514, Train Acc: 0.519231 | Val Loss: 0.256137, Val Acc: 0.494845\n",
      "Epoch 1731 - Train Loss: 0.244496, Train Acc: 0.519231 | Val Loss: 0.256120, Val Acc: 0.494845\n",
      "Epoch 1732 - Train Loss: 0.244478, Train Acc: 0.519231 | Val Loss: 0.256103, Val Acc: 0.494845\n",
      "Epoch 1733 - Train Loss: 0.244460, Train Acc: 0.519231 | Val Loss: 0.256086, Val Acc: 0.494845\n",
      "Epoch 1734 - Train Loss: 0.244442, Train Acc: 0.519231 | Val Loss: 0.256068, Val Acc: 0.494845\n",
      "Epoch 1735 - Train Loss: 0.244424, Train Acc: 0.519231 | Val Loss: 0.256051, Val Acc: 0.494845\n",
      "Epoch 1736 - Train Loss: 0.244405, Train Acc: 0.519231 | Val Loss: 0.256034, Val Acc: 0.494845\n",
      "Epoch 1737 - Train Loss: 0.244387, Train Acc: 0.519231 | Val Loss: 0.256017, Val Acc: 0.494845\n",
      "Epoch 1738 - Train Loss: 0.244369, Train Acc: 0.519231 | Val Loss: 0.256000, Val Acc: 0.494845\n",
      "Epoch 1739 - Train Loss: 0.244351, Train Acc: 0.519231 | Val Loss: 0.255982, Val Acc: 0.494845\n",
      "Epoch 1740 - Train Loss: 0.244333, Train Acc: 0.519231 | Val Loss: 0.255965, Val Acc: 0.494845\n",
      "Epoch 1741 - Train Loss: 0.244315, Train Acc: 0.519231 | Val Loss: 0.255948, Val Acc: 0.494845\n",
      "Epoch 1742 - Train Loss: 0.244296, Train Acc: 0.519231 | Val Loss: 0.255931, Val Acc: 0.494845\n",
      "Epoch 1743 - Train Loss: 0.244278, Train Acc: 0.519231 | Val Loss: 0.255913, Val Acc: 0.494845\n",
      "Epoch 1744 - Train Loss: 0.244260, Train Acc: 0.519231 | Val Loss: 0.255896, Val Acc: 0.494845\n",
      "Epoch 1745 - Train Loss: 0.244242, Train Acc: 0.519231 | Val Loss: 0.255879, Val Acc: 0.494845\n",
      "Epoch 1746 - Train Loss: 0.244223, Train Acc: 0.519231 | Val Loss: 0.255861, Val Acc: 0.494845\n",
      "Epoch 1747 - Train Loss: 0.244205, Train Acc: 0.519231 | Val Loss: 0.255843, Val Acc: 0.494845\n",
      "Epoch 1748 - Train Loss: 0.244187, Train Acc: 0.519231 | Val Loss: 0.255825, Val Acc: 0.494845\n",
      "Epoch 1749 - Train Loss: 0.244168, Train Acc: 0.519231 | Val Loss: 0.255807, Val Acc: 0.494845\n",
      "Epoch 1750 - Train Loss: 0.244150, Train Acc: 0.519231 | Val Loss: 0.255789, Val Acc: 0.494845\n",
      "Epoch 1751 - Train Loss: 0.244132, Train Acc: 0.519231 | Val Loss: 0.255772, Val Acc: 0.494845\n",
      "Epoch 1752 - Train Loss: 0.244113, Train Acc: 0.519231 | Val Loss: 0.255754, Val Acc: 0.494845\n",
      "Epoch 1753 - Train Loss: 0.244095, Train Acc: 0.519231 | Val Loss: 0.255736, Val Acc: 0.494845\n",
      "Epoch 1754 - Train Loss: 0.244077, Train Acc: 0.519231 | Val Loss: 0.255718, Val Acc: 0.494845\n",
      "Epoch 1755 - Train Loss: 0.244059, Train Acc: 0.519231 | Val Loss: 0.255700, Val Acc: 0.494845\n",
      "Epoch 1756 - Train Loss: 0.244040, Train Acc: 0.519231 | Val Loss: 0.255682, Val Acc: 0.494845\n",
      "Epoch 1757 - Train Loss: 0.244022, Train Acc: 0.519231 | Val Loss: 0.255665, Val Acc: 0.494845\n",
      "Epoch 1758 - Train Loss: 0.244004, Train Acc: 0.519231 | Val Loss: 0.255647, Val Acc: 0.494845\n",
      "Epoch 1759 - Train Loss: 0.243985, Train Acc: 0.519231 | Val Loss: 0.255629, Val Acc: 0.494845\n",
      "Epoch 1760 - Train Loss: 0.243967, Train Acc: 0.519231 | Val Loss: 0.255611, Val Acc: 0.494845\n",
      "Epoch 1761 - Train Loss: 0.243949, Train Acc: 0.519231 | Val Loss: 0.255593, Val Acc: 0.494845\n",
      "Epoch 1762 - Train Loss: 0.243930, Train Acc: 0.519231 | Val Loss: 0.255575, Val Acc: 0.494845\n",
      "Epoch 1763 - Train Loss: 0.243912, Train Acc: 0.519231 | Val Loss: 0.255557, Val Acc: 0.494845\n",
      "Epoch 1764 - Train Loss: 0.243894, Train Acc: 0.519231 | Val Loss: 0.255539, Val Acc: 0.494845\n",
      "Epoch 1765 - Train Loss: 0.243876, Train Acc: 0.519231 | Val Loss: 0.255522, Val Acc: 0.494845\n",
      "Epoch 1766 - Train Loss: 0.243857, Train Acc: 0.519231 | Val Loss: 0.255504, Val Acc: 0.494845\n",
      "Epoch 1767 - Train Loss: 0.243839, Train Acc: 0.519231 | Val Loss: 0.255486, Val Acc: 0.494845\n",
      "Epoch 1768 - Train Loss: 0.243821, Train Acc: 0.519231 | Val Loss: 0.255468, Val Acc: 0.494845\n",
      "Epoch 1769 - Train Loss: 0.243802, Train Acc: 0.519231 | Val Loss: 0.255451, Val Acc: 0.494845\n",
      "Epoch 1770 - Train Loss: 0.243784, Train Acc: 0.519231 | Val Loss: 0.255433, Val Acc: 0.494845\n",
      "Epoch 1771 - Train Loss: 0.243766, Train Acc: 0.519231 | Val Loss: 0.255415, Val Acc: 0.494845\n",
      "Epoch 1772 - Train Loss: 0.243747, Train Acc: 0.519231 | Val Loss: 0.255397, Val Acc: 0.494845\n",
      "Epoch 1773 - Train Loss: 0.243729, Train Acc: 0.519231 | Val Loss: 0.255379, Val Acc: 0.494845\n",
      "Epoch 1774 - Train Loss: 0.243711, Train Acc: 0.519231 | Val Loss: 0.255362, Val Acc: 0.494845\n",
      "Epoch 1775 - Train Loss: 0.243693, Train Acc: 0.519231 | Val Loss: 0.255344, Val Acc: 0.494845\n",
      "Epoch 1776 - Train Loss: 0.243674, Train Acc: 0.519231 | Val Loss: 0.255326, Val Acc: 0.494845\n",
      "Epoch 1777 - Train Loss: 0.243656, Train Acc: 0.519231 | Val Loss: 0.255308, Val Acc: 0.494845\n",
      "Epoch 1778 - Train Loss: 0.243638, Train Acc: 0.519231 | Val Loss: 0.255291, Val Acc: 0.494845\n",
      "Epoch 1779 - Train Loss: 0.243619, Train Acc: 0.519231 | Val Loss: 0.255273, Val Acc: 0.494845\n",
      "Epoch 1780 - Train Loss: 0.243601, Train Acc: 0.519231 | Val Loss: 0.255255, Val Acc: 0.494845\n",
      "Epoch 1781 - Train Loss: 0.243583, Train Acc: 0.519231 | Val Loss: 0.255237, Val Acc: 0.494845\n",
      "Epoch 1782 - Train Loss: 0.243564, Train Acc: 0.519231 | Val Loss: 0.255220, Val Acc: 0.494845\n",
      "Epoch 1783 - Train Loss: 0.243546, Train Acc: 0.519231 | Val Loss: 0.255202, Val Acc: 0.494845\n",
      "Epoch 1784 - Train Loss: 0.243528, Train Acc: 0.519231 | Val Loss: 0.255184, Val Acc: 0.494845\n",
      "Epoch 1785 - Train Loss: 0.243509, Train Acc: 0.519231 | Val Loss: 0.255166, Val Acc: 0.494845\n",
      "Epoch 1786 - Train Loss: 0.243491, Train Acc: 0.519231 | Val Loss: 0.255149, Val Acc: 0.494845\n",
      "Epoch 1787 - Train Loss: 0.243473, Train Acc: 0.519231 | Val Loss: 0.255131, Val Acc: 0.494845\n",
      "Epoch 1788 - Train Loss: 0.243454, Train Acc: 0.519231 | Val Loss: 0.255113, Val Acc: 0.494845\n",
      "Epoch 1789 - Train Loss: 0.243436, Train Acc: 0.519231 | Val Loss: 0.255095, Val Acc: 0.494845\n",
      "Epoch 1790 - Train Loss: 0.243417, Train Acc: 0.520513 | Val Loss: 0.255077, Val Acc: 0.494845\n",
      "Epoch 1791 - Train Loss: 0.243399, Train Acc: 0.520513 | Val Loss: 0.255059, Val Acc: 0.494845\n",
      "Epoch 1792 - Train Loss: 0.243380, Train Acc: 0.520513 | Val Loss: 0.255041, Val Acc: 0.494845\n",
      "Epoch 1793 - Train Loss: 0.243362, Train Acc: 0.520513 | Val Loss: 0.255023, Val Acc: 0.494845\n",
      "Epoch 1794 - Train Loss: 0.243343, Train Acc: 0.520513 | Val Loss: 0.255004, Val Acc: 0.494845\n",
      "Epoch 1795 - Train Loss: 0.243325, Train Acc: 0.520513 | Val Loss: 0.254986, Val Acc: 0.494845\n",
      "Epoch 1796 - Train Loss: 0.243306, Train Acc: 0.520513 | Val Loss: 0.254968, Val Acc: 0.494845\n",
      "Epoch 1797 - Train Loss: 0.243288, Train Acc: 0.520513 | Val Loss: 0.254950, Val Acc: 0.494845\n",
      "Epoch 1798 - Train Loss: 0.243269, Train Acc: 0.520513 | Val Loss: 0.254932, Val Acc: 0.494845\n",
      "Epoch 1799 - Train Loss: 0.243250, Train Acc: 0.520513 | Val Loss: 0.254914, Val Acc: 0.494845\n",
      "Epoch 1800 - Train Loss: 0.243232, Train Acc: 0.520513 | Val Loss: 0.254896, Val Acc: 0.505155\n",
      "Epoch 1801 - Train Loss: 0.243213, Train Acc: 0.520513 | Val Loss: 0.254878, Val Acc: 0.505155\n",
      "Epoch 1802 - Train Loss: 0.243195, Train Acc: 0.520513 | Val Loss: 0.254860, Val Acc: 0.505155\n",
      "Epoch 1803 - Train Loss: 0.243176, Train Acc: 0.520513 | Val Loss: 0.254843, Val Acc: 0.505155\n",
      "Epoch 1804 - Train Loss: 0.243158, Train Acc: 0.520513 | Val Loss: 0.254825, Val Acc: 0.505155\n",
      "Epoch 1805 - Train Loss: 0.243139, Train Acc: 0.520513 | Val Loss: 0.254807, Val Acc: 0.505155\n",
      "Epoch 1806 - Train Loss: 0.243121, Train Acc: 0.520513 | Val Loss: 0.254789, Val Acc: 0.505155\n",
      "Epoch 1807 - Train Loss: 0.243102, Train Acc: 0.520513 | Val Loss: 0.254771, Val Acc: 0.505155\n",
      "Epoch 1808 - Train Loss: 0.243084, Train Acc: 0.521795 | Val Loss: 0.254753, Val Acc: 0.505155\n",
      "Epoch 1809 - Train Loss: 0.243065, Train Acc: 0.521795 | Val Loss: 0.254735, Val Acc: 0.505155\n",
      "Epoch 1810 - Train Loss: 0.243046, Train Acc: 0.521795 | Val Loss: 0.254718, Val Acc: 0.505155\n",
      "Epoch 1811 - Train Loss: 0.243028, Train Acc: 0.521795 | Val Loss: 0.254700, Val Acc: 0.505155\n",
      "Epoch 1812 - Train Loss: 0.243009, Train Acc: 0.521795 | Val Loss: 0.254682, Val Acc: 0.505155\n",
      "Epoch 1813 - Train Loss: 0.242991, Train Acc: 0.521795 | Val Loss: 0.254664, Val Acc: 0.505155\n",
      "Epoch 1814 - Train Loss: 0.242972, Train Acc: 0.523077 | Val Loss: 0.254646, Val Acc: 0.505155\n",
      "Epoch 1815 - Train Loss: 0.242953, Train Acc: 0.523077 | Val Loss: 0.254628, Val Acc: 0.505155\n",
      "Epoch 1816 - Train Loss: 0.242935, Train Acc: 0.523077 | Val Loss: 0.254610, Val Acc: 0.505155\n",
      "Epoch 1817 - Train Loss: 0.242916, Train Acc: 0.523077 | Val Loss: 0.254593, Val Acc: 0.505155\n",
      "Epoch 1818 - Train Loss: 0.242898, Train Acc: 0.523077 | Val Loss: 0.254575, Val Acc: 0.505155\n",
      "Epoch 1819 - Train Loss: 0.242879, Train Acc: 0.523077 | Val Loss: 0.254557, Val Acc: 0.505155\n",
      "Epoch 1820 - Train Loss: 0.242860, Train Acc: 0.523077 | Val Loss: 0.254539, Val Acc: 0.505155\n",
      "Epoch 1821 - Train Loss: 0.242842, Train Acc: 0.523077 | Val Loss: 0.254522, Val Acc: 0.505155\n",
      "Epoch 1822 - Train Loss: 0.242823, Train Acc: 0.523077 | Val Loss: 0.254504, Val Acc: 0.505155\n",
      "Epoch 1823 - Train Loss: 0.242805, Train Acc: 0.523077 | Val Loss: 0.254486, Val Acc: 0.505155\n",
      "Epoch 1824 - Train Loss: 0.242786, Train Acc: 0.523077 | Val Loss: 0.254469, Val Acc: 0.505155\n",
      "Epoch 1825 - Train Loss: 0.242767, Train Acc: 0.523077 | Val Loss: 0.254451, Val Acc: 0.505155\n",
      "Epoch 1826 - Train Loss: 0.242749, Train Acc: 0.523077 | Val Loss: 0.254433, Val Acc: 0.505155\n",
      "Epoch 1827 - Train Loss: 0.242730, Train Acc: 0.523077 | Val Loss: 0.254416, Val Acc: 0.505155\n",
      "Epoch 1828 - Train Loss: 0.242712, Train Acc: 0.523077 | Val Loss: 0.254398, Val Acc: 0.505155\n",
      "Epoch 1829 - Train Loss: 0.242693, Train Acc: 0.523077 | Val Loss: 0.254380, Val Acc: 0.505155\n",
      "Epoch 1830 - Train Loss: 0.242675, Train Acc: 0.523077 | Val Loss: 0.254363, Val Acc: 0.505155\n",
      "Epoch 1831 - Train Loss: 0.242656, Train Acc: 0.523077 | Val Loss: 0.254345, Val Acc: 0.505155\n",
      "Epoch 1832 - Train Loss: 0.242637, Train Acc: 0.523077 | Val Loss: 0.254328, Val Acc: 0.505155\n",
      "Epoch 1833 - Train Loss: 0.242619, Train Acc: 0.523077 | Val Loss: 0.254310, Val Acc: 0.505155\n",
      "Epoch 1834 - Train Loss: 0.242600, Train Acc: 0.523077 | Val Loss: 0.254292, Val Acc: 0.505155\n",
      "Epoch 1835 - Train Loss: 0.242582, Train Acc: 0.523077 | Val Loss: 0.254274, Val Acc: 0.505155\n",
      "Epoch 1836 - Train Loss: 0.242563, Train Acc: 0.523077 | Val Loss: 0.254257, Val Acc: 0.505155\n",
      "Epoch 1837 - Train Loss: 0.242544, Train Acc: 0.523077 | Val Loss: 0.254239, Val Acc: 0.505155\n",
      "Epoch 1838 - Train Loss: 0.242526, Train Acc: 0.523077 | Val Loss: 0.254221, Val Acc: 0.505155\n",
      "Epoch 1839 - Train Loss: 0.242507, Train Acc: 0.523077 | Val Loss: 0.254203, Val Acc: 0.505155\n",
      "Epoch 1840 - Train Loss: 0.242488, Train Acc: 0.523077 | Val Loss: 0.254185, Val Acc: 0.505155\n",
      "Epoch 1841 - Train Loss: 0.242470, Train Acc: 0.523077 | Val Loss: 0.254167, Val Acc: 0.505155\n",
      "Epoch 1842 - Train Loss: 0.242451, Train Acc: 0.523077 | Val Loss: 0.254149, Val Acc: 0.505155\n",
      "Epoch 1843 - Train Loss: 0.242432, Train Acc: 0.523077 | Val Loss: 0.254131, Val Acc: 0.505155\n",
      "Epoch 1844 - Train Loss: 0.242413, Train Acc: 0.523077 | Val Loss: 0.254114, Val Acc: 0.505155\n",
      "Epoch 1845 - Train Loss: 0.242395, Train Acc: 0.523077 | Val Loss: 0.254096, Val Acc: 0.505155\n",
      "Epoch 1846 - Train Loss: 0.242376, Train Acc: 0.524359 | Val Loss: 0.254078, Val Acc: 0.505155\n",
      "Epoch 1847 - Train Loss: 0.242357, Train Acc: 0.525641 | Val Loss: 0.254060, Val Acc: 0.505155\n",
      "Epoch 1848 - Train Loss: 0.242339, Train Acc: 0.525641 | Val Loss: 0.254042, Val Acc: 0.505155\n",
      "Epoch 1849 - Train Loss: 0.242320, Train Acc: 0.525641 | Val Loss: 0.254025, Val Acc: 0.505155\n",
      "Epoch 1850 - Train Loss: 0.242301, Train Acc: 0.525641 | Val Loss: 0.254007, Val Acc: 0.505155\n",
      "Epoch 1851 - Train Loss: 0.242282, Train Acc: 0.525641 | Val Loss: 0.253989, Val Acc: 0.505155\n",
      "Epoch 1852 - Train Loss: 0.242264, Train Acc: 0.525641 | Val Loss: 0.253971, Val Acc: 0.505155\n",
      "Epoch 1853 - Train Loss: 0.242245, Train Acc: 0.525641 | Val Loss: 0.253953, Val Acc: 0.505155\n",
      "Epoch 1854 - Train Loss: 0.242226, Train Acc: 0.525641 | Val Loss: 0.253935, Val Acc: 0.505155\n",
      "Epoch 1855 - Train Loss: 0.242208, Train Acc: 0.525641 | Val Loss: 0.253918, Val Acc: 0.505155\n",
      "Epoch 1856 - Train Loss: 0.242189, Train Acc: 0.525641 | Val Loss: 0.253900, Val Acc: 0.505155\n",
      "Epoch 1857 - Train Loss: 0.242170, Train Acc: 0.525641 | Val Loss: 0.253882, Val Acc: 0.505155\n",
      "Epoch 1858 - Train Loss: 0.242152, Train Acc: 0.525641 | Val Loss: 0.253864, Val Acc: 0.505155\n",
      "Epoch 1859 - Train Loss: 0.242133, Train Acc: 0.525641 | Val Loss: 0.253846, Val Acc: 0.505155\n",
      "Epoch 1860 - Train Loss: 0.242114, Train Acc: 0.525641 | Val Loss: 0.253829, Val Acc: 0.505155\n",
      "Epoch 1861 - Train Loss: 0.242095, Train Acc: 0.526923 | Val Loss: 0.253811, Val Acc: 0.505155\n",
      "Epoch 1862 - Train Loss: 0.242077, Train Acc: 0.526923 | Val Loss: 0.253793, Val Acc: 0.505155\n",
      "Epoch 1863 - Train Loss: 0.242058, Train Acc: 0.526923 | Val Loss: 0.253775, Val Acc: 0.505155\n",
      "Epoch 1864 - Train Loss: 0.242039, Train Acc: 0.526923 | Val Loss: 0.253757, Val Acc: 0.505155\n",
      "Epoch 1865 - Train Loss: 0.242020, Train Acc: 0.526923 | Val Loss: 0.253739, Val Acc: 0.505155\n",
      "Epoch 1866 - Train Loss: 0.242002, Train Acc: 0.526923 | Val Loss: 0.253721, Val Acc: 0.505155\n",
      "Epoch 1867 - Train Loss: 0.241983, Train Acc: 0.526923 | Val Loss: 0.253703, Val Acc: 0.505155\n",
      "Epoch 1868 - Train Loss: 0.241964, Train Acc: 0.526923 | Val Loss: 0.253686, Val Acc: 0.505155\n",
      "Epoch 1869 - Train Loss: 0.241945, Train Acc: 0.526923 | Val Loss: 0.253668, Val Acc: 0.505155\n",
      "Epoch 1870 - Train Loss: 0.241926, Train Acc: 0.526923 | Val Loss: 0.253650, Val Acc: 0.505155\n",
      "Epoch 1871 - Train Loss: 0.241908, Train Acc: 0.526923 | Val Loss: 0.253632, Val Acc: 0.505155\n",
      "Epoch 1872 - Train Loss: 0.241889, Train Acc: 0.526923 | Val Loss: 0.253614, Val Acc: 0.505155\n",
      "Epoch 1873 - Train Loss: 0.241870, Train Acc: 0.526923 | Val Loss: 0.253596, Val Acc: 0.505155\n",
      "Epoch 1874 - Train Loss: 0.241851, Train Acc: 0.526923 | Val Loss: 0.253578, Val Acc: 0.505155\n",
      "Epoch 1875 - Train Loss: 0.241832, Train Acc: 0.526923 | Val Loss: 0.253560, Val Acc: 0.505155\n",
      "Epoch 1876 - Train Loss: 0.241814, Train Acc: 0.526923 | Val Loss: 0.253543, Val Acc: 0.505155\n",
      "Epoch 1877 - Train Loss: 0.241795, Train Acc: 0.528205 | Val Loss: 0.253525, Val Acc: 0.505155\n",
      "Epoch 1878 - Train Loss: 0.241776, Train Acc: 0.528205 | Val Loss: 0.253507, Val Acc: 0.505155\n",
      "Epoch 1879 - Train Loss: 0.241757, Train Acc: 0.528205 | Val Loss: 0.253490, Val Acc: 0.505155\n",
      "Epoch 1880 - Train Loss: 0.241739, Train Acc: 0.528205 | Val Loss: 0.253472, Val Acc: 0.505155\n",
      "Epoch 1881 - Train Loss: 0.241720, Train Acc: 0.528205 | Val Loss: 0.253454, Val Acc: 0.505155\n",
      "Epoch 1882 - Train Loss: 0.241701, Train Acc: 0.528205 | Val Loss: 0.253437, Val Acc: 0.505155\n",
      "Epoch 1883 - Train Loss: 0.241683, Train Acc: 0.528205 | Val Loss: 0.253419, Val Acc: 0.505155\n",
      "Epoch 1884 - Train Loss: 0.241664, Train Acc: 0.528205 | Val Loss: 0.253402, Val Acc: 0.505155\n",
      "Epoch 1885 - Train Loss: 0.241645, Train Acc: 0.528205 | Val Loss: 0.253384, Val Acc: 0.505155\n",
      "Epoch 1886 - Train Loss: 0.241626, Train Acc: 0.528205 | Val Loss: 0.253366, Val Acc: 0.505155\n",
      "Epoch 1887 - Train Loss: 0.241608, Train Acc: 0.528205 | Val Loss: 0.253349, Val Acc: 0.505155\n",
      "Epoch 1888 - Train Loss: 0.241589, Train Acc: 0.528205 | Val Loss: 0.253331, Val Acc: 0.505155\n",
      "Epoch 1889 - Train Loss: 0.241570, Train Acc: 0.528205 | Val Loss: 0.253314, Val Acc: 0.505155\n",
      "Epoch 1890 - Train Loss: 0.241552, Train Acc: 0.528205 | Val Loss: 0.253296, Val Acc: 0.505155\n",
      "Epoch 1891 - Train Loss: 0.241533, Train Acc: 0.528205 | Val Loss: 0.253279, Val Acc: 0.505155\n",
      "Epoch 1892 - Train Loss: 0.241514, Train Acc: 0.528205 | Val Loss: 0.253261, Val Acc: 0.505155\n",
      "Epoch 1893 - Train Loss: 0.241496, Train Acc: 0.528205 | Val Loss: 0.253244, Val Acc: 0.505155\n",
      "Epoch 1894 - Train Loss: 0.241477, Train Acc: 0.528205 | Val Loss: 0.253226, Val Acc: 0.505155\n",
      "Epoch 1895 - Train Loss: 0.241458, Train Acc: 0.528205 | Val Loss: 0.253209, Val Acc: 0.505155\n",
      "Epoch 1896 - Train Loss: 0.241440, Train Acc: 0.528205 | Val Loss: 0.253191, Val Acc: 0.505155\n",
      "Epoch 1897 - Train Loss: 0.241421, Train Acc: 0.528205 | Val Loss: 0.253174, Val Acc: 0.505155\n",
      "Epoch 1898 - Train Loss: 0.241402, Train Acc: 0.528205 | Val Loss: 0.253156, Val Acc: 0.505155\n",
      "Epoch 1899 - Train Loss: 0.241383, Train Acc: 0.528205 | Val Loss: 0.253139, Val Acc: 0.505155\n",
      "Epoch 1900 - Train Loss: 0.241365, Train Acc: 0.528205 | Val Loss: 0.253121, Val Acc: 0.505155\n",
      "Epoch 1901 - Train Loss: 0.241346, Train Acc: 0.529487 | Val Loss: 0.253104, Val Acc: 0.505155\n",
      "Epoch 1902 - Train Loss: 0.241327, Train Acc: 0.529487 | Val Loss: 0.253086, Val Acc: 0.505155\n",
      "Epoch 1903 - Train Loss: 0.241309, Train Acc: 0.529487 | Val Loss: 0.253069, Val Acc: 0.505155\n",
      "Epoch 1904 - Train Loss: 0.241290, Train Acc: 0.529487 | Val Loss: 0.253051, Val Acc: 0.505155\n",
      "Epoch 1905 - Train Loss: 0.241271, Train Acc: 0.529487 | Val Loss: 0.253034, Val Acc: 0.505155\n",
      "Epoch 1906 - Train Loss: 0.241253, Train Acc: 0.529487 | Val Loss: 0.253016, Val Acc: 0.505155\n",
      "Epoch 1907 - Train Loss: 0.241234, Train Acc: 0.529487 | Val Loss: 0.252998, Val Acc: 0.505155\n",
      "Epoch 1908 - Train Loss: 0.241215, Train Acc: 0.529487 | Val Loss: 0.252981, Val Acc: 0.505155\n",
      "Epoch 1909 - Train Loss: 0.241197, Train Acc: 0.529487 | Val Loss: 0.252963, Val Acc: 0.505155\n",
      "Epoch 1910 - Train Loss: 0.241178, Train Acc: 0.529487 | Val Loss: 0.252945, Val Acc: 0.505155\n",
      "Epoch 1911 - Train Loss: 0.241159, Train Acc: 0.530769 | Val Loss: 0.252928, Val Acc: 0.505155\n",
      "Epoch 1912 - Train Loss: 0.241140, Train Acc: 0.530769 | Val Loss: 0.252910, Val Acc: 0.505155\n",
      "Epoch 1913 - Train Loss: 0.241122, Train Acc: 0.530769 | Val Loss: 0.252893, Val Acc: 0.505155\n",
      "Epoch 1914 - Train Loss: 0.241103, Train Acc: 0.530769 | Val Loss: 0.252875, Val Acc: 0.505155\n",
      "Epoch 1915 - Train Loss: 0.241084, Train Acc: 0.530769 | Val Loss: 0.252857, Val Acc: 0.505155\n",
      "Epoch 1916 - Train Loss: 0.241066, Train Acc: 0.530769 | Val Loss: 0.252840, Val Acc: 0.505155\n",
      "Epoch 1917 - Train Loss: 0.241047, Train Acc: 0.530769 | Val Loss: 0.252822, Val Acc: 0.505155\n",
      "Epoch 1918 - Train Loss: 0.241028, Train Acc: 0.530769 | Val Loss: 0.252804, Val Acc: 0.505155\n",
      "Epoch 1919 - Train Loss: 0.241009, Train Acc: 0.530769 | Val Loss: 0.252787, Val Acc: 0.505155\n",
      "Epoch 1920 - Train Loss: 0.240991, Train Acc: 0.530769 | Val Loss: 0.252769, Val Acc: 0.505155\n",
      "Epoch 1921 - Train Loss: 0.240972, Train Acc: 0.530769 | Val Loss: 0.252751, Val Acc: 0.505155\n",
      "Epoch 1922 - Train Loss: 0.240953, Train Acc: 0.530769 | Val Loss: 0.252734, Val Acc: 0.505155\n",
      "Epoch 1923 - Train Loss: 0.240934, Train Acc: 0.530769 | Val Loss: 0.252716, Val Acc: 0.505155\n",
      "Epoch 1924 - Train Loss: 0.240915, Train Acc: 0.530769 | Val Loss: 0.252698, Val Acc: 0.505155\n",
      "Epoch 1925 - Train Loss: 0.240897, Train Acc: 0.530769 | Val Loss: 0.252681, Val Acc: 0.505155\n",
      "Epoch 1926 - Train Loss: 0.240878, Train Acc: 0.530769 | Val Loss: 0.252663, Val Acc: 0.505155\n",
      "Epoch 1927 - Train Loss: 0.240859, Train Acc: 0.530769 | Val Loss: 0.252645, Val Acc: 0.505155\n",
      "Epoch 1928 - Train Loss: 0.240840, Train Acc: 0.530769 | Val Loss: 0.252627, Val Acc: 0.505155\n",
      "Epoch 1929 - Train Loss: 0.240821, Train Acc: 0.530769 | Val Loss: 0.252610, Val Acc: 0.505155\n",
      "Epoch 1930 - Train Loss: 0.240803, Train Acc: 0.530769 | Val Loss: 0.252592, Val Acc: 0.505155\n",
      "Epoch 1931 - Train Loss: 0.240784, Train Acc: 0.530769 | Val Loss: 0.252574, Val Acc: 0.505155\n",
      "Epoch 1932 - Train Loss: 0.240765, Train Acc: 0.530769 | Val Loss: 0.252556, Val Acc: 0.505155\n",
      "Epoch 1933 - Train Loss: 0.240746, Train Acc: 0.530769 | Val Loss: 0.252539, Val Acc: 0.505155\n",
      "Epoch 1934 - Train Loss: 0.240727, Train Acc: 0.530769 | Val Loss: 0.252521, Val Acc: 0.505155\n",
      "Epoch 1935 - Train Loss: 0.240708, Train Acc: 0.530769 | Val Loss: 0.252503, Val Acc: 0.505155\n",
      "Epoch 1936 - Train Loss: 0.240689, Train Acc: 0.530769 | Val Loss: 0.252485, Val Acc: 0.505155\n",
      "Epoch 1937 - Train Loss: 0.240670, Train Acc: 0.530769 | Val Loss: 0.252468, Val Acc: 0.505155\n",
      "Epoch 1938 - Train Loss: 0.240651, Train Acc: 0.530769 | Val Loss: 0.252449, Val Acc: 0.505155\n",
      "Epoch 1939 - Train Loss: 0.240632, Train Acc: 0.532051 | Val Loss: 0.252431, Val Acc: 0.505155\n",
      "Epoch 1940 - Train Loss: 0.240613, Train Acc: 0.532051 | Val Loss: 0.252413, Val Acc: 0.505155\n",
      "Epoch 1941 - Train Loss: 0.240594, Train Acc: 0.532051 | Val Loss: 0.252395, Val Acc: 0.505155\n",
      "Epoch 1942 - Train Loss: 0.240575, Train Acc: 0.533333 | Val Loss: 0.252377, Val Acc: 0.505155\n",
      "Epoch 1943 - Train Loss: 0.240556, Train Acc: 0.533333 | Val Loss: 0.252359, Val Acc: 0.505155\n",
      "Epoch 1944 - Train Loss: 0.240537, Train Acc: 0.533333 | Val Loss: 0.252341, Val Acc: 0.505155\n",
      "Epoch 1945 - Train Loss: 0.240518, Train Acc: 0.533333 | Val Loss: 0.252323, Val Acc: 0.505155\n",
      "Epoch 1946 - Train Loss: 0.240499, Train Acc: 0.533333 | Val Loss: 0.252305, Val Acc: 0.505155\n",
      "Epoch 1947 - Train Loss: 0.240480, Train Acc: 0.533333 | Val Loss: 0.252287, Val Acc: 0.505155\n",
      "Epoch 1948 - Train Loss: 0.240461, Train Acc: 0.533333 | Val Loss: 0.252269, Val Acc: 0.505155\n",
      "Epoch 1949 - Train Loss: 0.240442, Train Acc: 0.533333 | Val Loss: 0.252251, Val Acc: 0.505155\n",
      "Epoch 1950 - Train Loss: 0.240423, Train Acc: 0.533333 | Val Loss: 0.252232, Val Acc: 0.505155\n",
      "Epoch 1951 - Train Loss: 0.240404, Train Acc: 0.533333 | Val Loss: 0.252214, Val Acc: 0.505155\n",
      "Epoch 1952 - Train Loss: 0.240385, Train Acc: 0.533333 | Val Loss: 0.252196, Val Acc: 0.505155\n",
      "Epoch 1953 - Train Loss: 0.240366, Train Acc: 0.534615 | Val Loss: 0.252178, Val Acc: 0.505155\n",
      "Epoch 1954 - Train Loss: 0.240347, Train Acc: 0.534615 | Val Loss: 0.252160, Val Acc: 0.505155\n",
      "Epoch 1955 - Train Loss: 0.240328, Train Acc: 0.534615 | Val Loss: 0.252142, Val Acc: 0.505155\n",
      "Epoch 1956 - Train Loss: 0.240308, Train Acc: 0.534615 | Val Loss: 0.252124, Val Acc: 0.505155\n",
      "Epoch 1957 - Train Loss: 0.240289, Train Acc: 0.534615 | Val Loss: 0.252106, Val Acc: 0.505155\n",
      "Epoch 1958 - Train Loss: 0.240270, Train Acc: 0.534615 | Val Loss: 0.252088, Val Acc: 0.505155\n",
      "Epoch 1959 - Train Loss: 0.240251, Train Acc: 0.535897 | Val Loss: 0.252070, Val Acc: 0.505155\n",
      "Epoch 1960 - Train Loss: 0.240232, Train Acc: 0.535897 | Val Loss: 0.252052, Val Acc: 0.505155\n",
      "Epoch 1961 - Train Loss: 0.240213, Train Acc: 0.535897 | Val Loss: 0.252034, Val Acc: 0.505155\n",
      "Epoch 1962 - Train Loss: 0.240194, Train Acc: 0.535897 | Val Loss: 0.252016, Val Acc: 0.505155\n",
      "Epoch 1963 - Train Loss: 0.240175, Train Acc: 0.535897 | Val Loss: 0.251997, Val Acc: 0.505155\n",
      "Epoch 1964 - Train Loss: 0.240156, Train Acc: 0.535897 | Val Loss: 0.251979, Val Acc: 0.505155\n",
      "Epoch 1965 - Train Loss: 0.240137, Train Acc: 0.535897 | Val Loss: 0.251961, Val Acc: 0.505155\n",
      "Epoch 1966 - Train Loss: 0.240118, Train Acc: 0.535897 | Val Loss: 0.251943, Val Acc: 0.505155\n",
      "Epoch 1967 - Train Loss: 0.240098, Train Acc: 0.535897 | Val Loss: 0.251925, Val Acc: 0.505155\n",
      "Epoch 1968 - Train Loss: 0.240079, Train Acc: 0.535897 | Val Loss: 0.251907, Val Acc: 0.505155\n",
      "Epoch 1969 - Train Loss: 0.240060, Train Acc: 0.535897 | Val Loss: 0.251889, Val Acc: 0.505155\n",
      "Epoch 1970 - Train Loss: 0.240041, Train Acc: 0.535897 | Val Loss: 0.251871, Val Acc: 0.505155\n",
      "Epoch 1971 - Train Loss: 0.240022, Train Acc: 0.535897 | Val Loss: 0.251853, Val Acc: 0.505155\n",
      "Epoch 1972 - Train Loss: 0.240003, Train Acc: 0.535897 | Val Loss: 0.251835, Val Acc: 0.505155\n",
      "Epoch 1973 - Train Loss: 0.239984, Train Acc: 0.535897 | Val Loss: 0.251817, Val Acc: 0.505155\n",
      "Epoch 1974 - Train Loss: 0.239965, Train Acc: 0.535897 | Val Loss: 0.251799, Val Acc: 0.505155\n",
      "Epoch 1975 - Train Loss: 0.239946, Train Acc: 0.535897 | Val Loss: 0.251781, Val Acc: 0.505155\n",
      "Epoch 1976 - Train Loss: 0.239927, Train Acc: 0.537179 | Val Loss: 0.251764, Val Acc: 0.505155\n",
      "Epoch 1977 - Train Loss: 0.239908, Train Acc: 0.537179 | Val Loss: 0.251746, Val Acc: 0.505155\n",
      "Epoch 1978 - Train Loss: 0.239889, Train Acc: 0.537179 | Val Loss: 0.251728, Val Acc: 0.505155\n",
      "Epoch 1979 - Train Loss: 0.239870, Train Acc: 0.537179 | Val Loss: 0.251710, Val Acc: 0.505155\n",
      "Epoch 1980 - Train Loss: 0.239850, Train Acc: 0.537179 | Val Loss: 0.251692, Val Acc: 0.505155\n",
      "Epoch 1981 - Train Loss: 0.239831, Train Acc: 0.537179 | Val Loss: 0.251674, Val Acc: 0.505155\n",
      "Epoch 1982 - Train Loss: 0.239812, Train Acc: 0.537179 | Val Loss: 0.251656, Val Acc: 0.505155\n",
      "Epoch 1983 - Train Loss: 0.239793, Train Acc: 0.537179 | Val Loss: 0.251638, Val Acc: 0.505155\n",
      "Epoch 1984 - Train Loss: 0.239774, Train Acc: 0.537179 | Val Loss: 0.251620, Val Acc: 0.505155\n",
      "Epoch 1985 - Train Loss: 0.239755, Train Acc: 0.537179 | Val Loss: 0.251602, Val Acc: 0.505155\n",
      "Epoch 1986 - Train Loss: 0.239736, Train Acc: 0.537179 | Val Loss: 0.251584, Val Acc: 0.505155\n",
      "Epoch 1987 - Train Loss: 0.239717, Train Acc: 0.537179 | Val Loss: 0.251566, Val Acc: 0.505155\n",
      "Epoch 1988 - Train Loss: 0.239698, Train Acc: 0.537179 | Val Loss: 0.251548, Val Acc: 0.505155\n",
      "Epoch 1989 - Train Loss: 0.239679, Train Acc: 0.537179 | Val Loss: 0.251530, Val Acc: 0.505155\n",
      "Epoch 1990 - Train Loss: 0.239660, Train Acc: 0.537179 | Val Loss: 0.251512, Val Acc: 0.505155\n",
      "Epoch 1991 - Train Loss: 0.239641, Train Acc: 0.537179 | Val Loss: 0.251494, Val Acc: 0.505155\n",
      "Epoch 1992 - Train Loss: 0.239621, Train Acc: 0.537179 | Val Loss: 0.251476, Val Acc: 0.505155\n",
      "Epoch 1993 - Train Loss: 0.239602, Train Acc: 0.537179 | Val Loss: 0.251459, Val Acc: 0.505155\n",
      "Epoch 1994 - Train Loss: 0.239583, Train Acc: 0.537179 | Val Loss: 0.251441, Val Acc: 0.505155\n",
      "Epoch 1995 - Train Loss: 0.239564, Train Acc: 0.537179 | Val Loss: 0.251423, Val Acc: 0.505155\n",
      "Epoch 1996 - Train Loss: 0.239545, Train Acc: 0.537179 | Val Loss: 0.251405, Val Acc: 0.505155\n",
      "Epoch 1997 - Train Loss: 0.239526, Train Acc: 0.537179 | Val Loss: 0.251387, Val Acc: 0.505155\n",
      "Epoch 1998 - Train Loss: 0.239507, Train Acc: 0.537179 | Val Loss: 0.251369, Val Acc: 0.505155\n",
      "Epoch 1999 - Train Loss: 0.239488, Train Acc: 0.537179 | Val Loss: 0.251351, Val Acc: 0.505155\n",
      "Epoch 2000 - Train Loss: 0.239469, Train Acc: 0.537179 | Val Loss: 0.251333, Val Acc: 0.505155\n",
      "Epoch 2001 - Train Loss: 0.239450, Train Acc: 0.537179 | Val Loss: 0.251315, Val Acc: 0.505155\n",
      "Epoch 2002 - Train Loss: 0.239430, Train Acc: 0.537179 | Val Loss: 0.251297, Val Acc: 0.505155\n",
      "Epoch 2003 - Train Loss: 0.239411, Train Acc: 0.537179 | Val Loss: 0.251279, Val Acc: 0.505155\n",
      "Epoch 2004 - Train Loss: 0.239392, Train Acc: 0.537179 | Val Loss: 0.251261, Val Acc: 0.505155\n",
      "Epoch 2005 - Train Loss: 0.239373, Train Acc: 0.537179 | Val Loss: 0.251243, Val Acc: 0.505155\n",
      "Epoch 2006 - Train Loss: 0.239354, Train Acc: 0.537179 | Val Loss: 0.251225, Val Acc: 0.505155\n",
      "Epoch 2007 - Train Loss: 0.239335, Train Acc: 0.537179 | Val Loss: 0.251207, Val Acc: 0.505155\n",
      "Epoch 2008 - Train Loss: 0.239316, Train Acc: 0.537179 | Val Loss: 0.251189, Val Acc: 0.505155\n",
      "Epoch 2009 - Train Loss: 0.239297, Train Acc: 0.537179 | Val Loss: 0.251171, Val Acc: 0.505155\n",
      "Epoch 2010 - Train Loss: 0.239278, Train Acc: 0.537179 | Val Loss: 0.251153, Val Acc: 0.505155\n",
      "Epoch 2011 - Train Loss: 0.239258, Train Acc: 0.537179 | Val Loss: 0.251135, Val Acc: 0.505155\n",
      "Epoch 2012 - Train Loss: 0.239239, Train Acc: 0.537179 | Val Loss: 0.251117, Val Acc: 0.505155\n",
      "Epoch 2013 - Train Loss: 0.239220, Train Acc: 0.537179 | Val Loss: 0.251099, Val Acc: 0.505155\n",
      "Epoch 2014 - Train Loss: 0.239201, Train Acc: 0.537179 | Val Loss: 0.251081, Val Acc: 0.505155\n",
      "Epoch 2015 - Train Loss: 0.239182, Train Acc: 0.537179 | Val Loss: 0.251063, Val Acc: 0.505155\n",
      "Epoch 2016 - Train Loss: 0.239163, Train Acc: 0.537179 | Val Loss: 0.251045, Val Acc: 0.505155\n",
      "Epoch 2017 - Train Loss: 0.239143, Train Acc: 0.538462 | Val Loss: 0.251027, Val Acc: 0.505155\n",
      "Epoch 2018 - Train Loss: 0.239124, Train Acc: 0.538462 | Val Loss: 0.251009, Val Acc: 0.505155\n",
      "Epoch 2019 - Train Loss: 0.239105, Train Acc: 0.538462 | Val Loss: 0.250991, Val Acc: 0.505155\n",
      "Epoch 2020 - Train Loss: 0.239086, Train Acc: 0.538462 | Val Loss: 0.250973, Val Acc: 0.505155\n",
      "Epoch 2021 - Train Loss: 0.239067, Train Acc: 0.538462 | Val Loss: 0.250954, Val Acc: 0.505155\n",
      "Epoch 2022 - Train Loss: 0.239047, Train Acc: 0.538462 | Val Loss: 0.250936, Val Acc: 0.505155\n",
      "Epoch 2023 - Train Loss: 0.239028, Train Acc: 0.538462 | Val Loss: 0.250918, Val Acc: 0.505155\n",
      "Epoch 2024 - Train Loss: 0.239009, Train Acc: 0.538462 | Val Loss: 0.250900, Val Acc: 0.505155\n",
      "Epoch 2025 - Train Loss: 0.238990, Train Acc: 0.538462 | Val Loss: 0.250882, Val Acc: 0.505155\n",
      "Epoch 2026 - Train Loss: 0.238970, Train Acc: 0.538462 | Val Loss: 0.250864, Val Acc: 0.505155\n",
      "Epoch 2027 - Train Loss: 0.238951, Train Acc: 0.538462 | Val Loss: 0.250845, Val Acc: 0.505155\n",
      "Epoch 2028 - Train Loss: 0.238932, Train Acc: 0.538462 | Val Loss: 0.250827, Val Acc: 0.505155\n",
      "Epoch 2029 - Train Loss: 0.238912, Train Acc: 0.538462 | Val Loss: 0.250809, Val Acc: 0.505155\n",
      "Epoch 2030 - Train Loss: 0.238893, Train Acc: 0.538462 | Val Loss: 0.250791, Val Acc: 0.505155\n",
      "Epoch 2031 - Train Loss: 0.238874, Train Acc: 0.538462 | Val Loss: 0.250772, Val Acc: 0.505155\n",
      "Epoch 2032 - Train Loss: 0.238855, Train Acc: 0.538462 | Val Loss: 0.250753, Val Acc: 0.505155\n",
      "Epoch 2033 - Train Loss: 0.238835, Train Acc: 0.538462 | Val Loss: 0.250734, Val Acc: 0.505155\n",
      "Epoch 2034 - Train Loss: 0.238816, Train Acc: 0.538462 | Val Loss: 0.250715, Val Acc: 0.505155\n",
      "Epoch 2035 - Train Loss: 0.238797, Train Acc: 0.538462 | Val Loss: 0.250696, Val Acc: 0.505155\n",
      "Epoch 2036 - Train Loss: 0.238777, Train Acc: 0.538462 | Val Loss: 0.250678, Val Acc: 0.505155\n",
      "Epoch 2037 - Train Loss: 0.238758, Train Acc: 0.538462 | Val Loss: 0.250659, Val Acc: 0.505155\n",
      "Epoch 2038 - Train Loss: 0.238739, Train Acc: 0.538462 | Val Loss: 0.250640, Val Acc: 0.505155\n",
      "Epoch 2039 - Train Loss: 0.238719, Train Acc: 0.538462 | Val Loss: 0.250621, Val Acc: 0.505155\n",
      "Epoch 2040 - Train Loss: 0.238700, Train Acc: 0.538462 | Val Loss: 0.250601, Val Acc: 0.505155\n",
      "Epoch 2041 - Train Loss: 0.238680, Train Acc: 0.538462 | Val Loss: 0.250582, Val Acc: 0.505155\n",
      "Epoch 2042 - Train Loss: 0.238661, Train Acc: 0.538462 | Val Loss: 0.250563, Val Acc: 0.505155\n",
      "Epoch 2043 - Train Loss: 0.238641, Train Acc: 0.538462 | Val Loss: 0.250544, Val Acc: 0.505155\n",
      "Epoch 2044 - Train Loss: 0.238622, Train Acc: 0.538462 | Val Loss: 0.250525, Val Acc: 0.505155\n",
      "Epoch 2045 - Train Loss: 0.238602, Train Acc: 0.538462 | Val Loss: 0.250506, Val Acc: 0.505155\n",
      "Epoch 2046 - Train Loss: 0.238583, Train Acc: 0.538462 | Val Loss: 0.250487, Val Acc: 0.505155\n",
      "Epoch 2047 - Train Loss: 0.238563, Train Acc: 0.538462 | Val Loss: 0.250468, Val Acc: 0.505155\n",
      "Epoch 2048 - Train Loss: 0.238544, Train Acc: 0.538462 | Val Loss: 0.250449, Val Acc: 0.505155\n",
      "Epoch 2049 - Train Loss: 0.238524, Train Acc: 0.538462 | Val Loss: 0.250430, Val Acc: 0.505155\n",
      "Epoch 2050 - Train Loss: 0.238505, Train Acc: 0.538462 | Val Loss: 0.250411, Val Acc: 0.505155\n",
      "Epoch 2051 - Train Loss: 0.238485, Train Acc: 0.538462 | Val Loss: 0.250391, Val Acc: 0.505155\n",
      "Epoch 2052 - Train Loss: 0.238466, Train Acc: 0.538462 | Val Loss: 0.250372, Val Acc: 0.505155\n",
      "Epoch 2053 - Train Loss: 0.238446, Train Acc: 0.538462 | Val Loss: 0.250353, Val Acc: 0.505155\n",
      "Epoch 2054 - Train Loss: 0.238427, Train Acc: 0.538462 | Val Loss: 0.250334, Val Acc: 0.505155\n",
      "Epoch 2055 - Train Loss: 0.238407, Train Acc: 0.538462 | Val Loss: 0.250315, Val Acc: 0.505155\n",
      "Epoch 2056 - Train Loss: 0.238388, Train Acc: 0.538462 | Val Loss: 0.250296, Val Acc: 0.505155\n",
      "Epoch 2057 - Train Loss: 0.238368, Train Acc: 0.538462 | Val Loss: 0.250277, Val Acc: 0.505155\n",
      "Epoch 2058 - Train Loss: 0.238349, Train Acc: 0.538462 | Val Loss: 0.250258, Val Acc: 0.505155\n",
      "Epoch 2059 - Train Loss: 0.238329, Train Acc: 0.538462 | Val Loss: 0.250239, Val Acc: 0.505155\n",
      "Epoch 2060 - Train Loss: 0.238310, Train Acc: 0.538462 | Val Loss: 0.250221, Val Acc: 0.505155\n",
      "Epoch 2061 - Train Loss: 0.238290, Train Acc: 0.538462 | Val Loss: 0.250202, Val Acc: 0.505155\n",
      "Epoch 2062 - Train Loss: 0.238271, Train Acc: 0.538462 | Val Loss: 0.250183, Val Acc: 0.505155\n",
      "Epoch 2063 - Train Loss: 0.238251, Train Acc: 0.539744 | Val Loss: 0.250164, Val Acc: 0.505155\n",
      "Epoch 2064 - Train Loss: 0.238232, Train Acc: 0.539744 | Val Loss: 0.250145, Val Acc: 0.505155\n",
      "Epoch 2065 - Train Loss: 0.238212, Train Acc: 0.539744 | Val Loss: 0.250126, Val Acc: 0.505155\n",
      "Epoch 2066 - Train Loss: 0.238193, Train Acc: 0.539744 | Val Loss: 0.250107, Val Acc: 0.505155\n",
      "Epoch 2067 - Train Loss: 0.238173, Train Acc: 0.539744 | Val Loss: 0.250089, Val Acc: 0.505155\n",
      "Epoch 2068 - Train Loss: 0.238154, Train Acc: 0.539744 | Val Loss: 0.250070, Val Acc: 0.505155\n",
      "Epoch 2069 - Train Loss: 0.238134, Train Acc: 0.539744 | Val Loss: 0.250051, Val Acc: 0.505155\n",
      "Epoch 2070 - Train Loss: 0.238115, Train Acc: 0.539744 | Val Loss: 0.250032, Val Acc: 0.505155\n",
      "Epoch 2071 - Train Loss: 0.238095, Train Acc: 0.539744 | Val Loss: 0.250014, Val Acc: 0.505155\n",
      "Epoch 2072 - Train Loss: 0.238076, Train Acc: 0.541026 | Val Loss: 0.249995, Val Acc: 0.505155\n",
      "Epoch 2073 - Train Loss: 0.238056, Train Acc: 0.541026 | Val Loss: 0.249976, Val Acc: 0.505155\n",
      "Epoch 2074 - Train Loss: 0.238037, Train Acc: 0.541026 | Val Loss: 0.249957, Val Acc: 0.505155\n",
      "Epoch 2075 - Train Loss: 0.238017, Train Acc: 0.541026 | Val Loss: 0.249938, Val Acc: 0.505155\n",
      "Epoch 2076 - Train Loss: 0.237998, Train Acc: 0.541026 | Val Loss: 0.249919, Val Acc: 0.505155\n",
      "Epoch 2077 - Train Loss: 0.237978, Train Acc: 0.541026 | Val Loss: 0.249901, Val Acc: 0.505155\n",
      "Epoch 2078 - Train Loss: 0.237959, Train Acc: 0.541026 | Val Loss: 0.249882, Val Acc: 0.505155\n",
      "Epoch 2079 - Train Loss: 0.237939, Train Acc: 0.541026 | Val Loss: 0.249863, Val Acc: 0.505155\n",
      "Epoch 2080 - Train Loss: 0.237920, Train Acc: 0.541026 | Val Loss: 0.249844, Val Acc: 0.505155\n",
      "Epoch 2081 - Train Loss: 0.237900, Train Acc: 0.541026 | Val Loss: 0.249825, Val Acc: 0.505155\n",
      "Epoch 2082 - Train Loss: 0.237881, Train Acc: 0.542308 | Val Loss: 0.249807, Val Acc: 0.505155\n",
      "Epoch 2083 - Train Loss: 0.237861, Train Acc: 0.542308 | Val Loss: 0.249788, Val Acc: 0.505155\n",
      "Epoch 2084 - Train Loss: 0.237842, Train Acc: 0.542308 | Val Loss: 0.249769, Val Acc: 0.505155\n",
      "Epoch 2085 - Train Loss: 0.237822, Train Acc: 0.543590 | Val Loss: 0.249750, Val Acc: 0.505155\n",
      "Epoch 2086 - Train Loss: 0.237802, Train Acc: 0.543590 | Val Loss: 0.249731, Val Acc: 0.505155\n",
      "Epoch 2087 - Train Loss: 0.237783, Train Acc: 0.543590 | Val Loss: 0.249712, Val Acc: 0.505155\n",
      "Epoch 2088 - Train Loss: 0.237763, Train Acc: 0.543590 | Val Loss: 0.249693, Val Acc: 0.505155\n",
      "Epoch 2089 - Train Loss: 0.237743, Train Acc: 0.543590 | Val Loss: 0.249674, Val Acc: 0.505155\n",
      "Epoch 2090 - Train Loss: 0.237724, Train Acc: 0.543590 | Val Loss: 0.249655, Val Acc: 0.505155\n",
      "Epoch 2091 - Train Loss: 0.237704, Train Acc: 0.543590 | Val Loss: 0.249636, Val Acc: 0.505155\n",
      "Epoch 2092 - Train Loss: 0.237684, Train Acc: 0.543590 | Val Loss: 0.249617, Val Acc: 0.505155\n",
      "Epoch 2093 - Train Loss: 0.237664, Train Acc: 0.543590 | Val Loss: 0.249598, Val Acc: 0.505155\n",
      "Epoch 2094 - Train Loss: 0.237645, Train Acc: 0.543590 | Val Loss: 0.249579, Val Acc: 0.505155\n",
      "Epoch 2095 - Train Loss: 0.237625, Train Acc: 0.543590 | Val Loss: 0.249560, Val Acc: 0.505155\n",
      "Epoch 2096 - Train Loss: 0.237605, Train Acc: 0.543590 | Val Loss: 0.249541, Val Acc: 0.505155\n",
      "Epoch 2097 - Train Loss: 0.237586, Train Acc: 0.543590 | Val Loss: 0.249522, Val Acc: 0.505155\n",
      "Epoch 2098 - Train Loss: 0.237566, Train Acc: 0.543590 | Val Loss: 0.249503, Val Acc: 0.505155\n",
      "Epoch 2099 - Train Loss: 0.237546, Train Acc: 0.543590 | Val Loss: 0.249484, Val Acc: 0.505155\n",
      "Epoch 2100 - Train Loss: 0.237527, Train Acc: 0.543590 | Val Loss: 0.249465, Val Acc: 0.505155\n",
      "Epoch 2101 - Train Loss: 0.237507, Train Acc: 0.543590 | Val Loss: 0.249446, Val Acc: 0.505155\n",
      "Epoch 2102 - Train Loss: 0.237487, Train Acc: 0.543590 | Val Loss: 0.249427, Val Acc: 0.505155\n",
      "Epoch 2103 - Train Loss: 0.237468, Train Acc: 0.543590 | Val Loss: 0.249409, Val Acc: 0.505155\n",
      "Epoch 2104 - Train Loss: 0.237448, Train Acc: 0.543590 | Val Loss: 0.249390, Val Acc: 0.505155\n",
      "Epoch 2105 - Train Loss: 0.237428, Train Acc: 0.543590 | Val Loss: 0.249371, Val Acc: 0.505155\n",
      "Epoch 2106 - Train Loss: 0.237409, Train Acc: 0.543590 | Val Loss: 0.249352, Val Acc: 0.505155\n",
      "Epoch 2107 - Train Loss: 0.237389, Train Acc: 0.543590 | Val Loss: 0.249333, Val Acc: 0.505155\n",
      "Epoch 2108 - Train Loss: 0.237369, Train Acc: 0.543590 | Val Loss: 0.249314, Val Acc: 0.505155\n",
      "Epoch 2109 - Train Loss: 0.237350, Train Acc: 0.543590 | Val Loss: 0.249295, Val Acc: 0.505155\n",
      "Epoch 2110 - Train Loss: 0.237330, Train Acc: 0.543590 | Val Loss: 0.249276, Val Acc: 0.505155\n",
      "Epoch 2111 - Train Loss: 0.237310, Train Acc: 0.543590 | Val Loss: 0.249257, Val Acc: 0.505155\n",
      "Epoch 2112 - Train Loss: 0.237291, Train Acc: 0.543590 | Val Loss: 0.249239, Val Acc: 0.505155\n",
      "Epoch 2113 - Train Loss: 0.237271, Train Acc: 0.543590 | Val Loss: 0.249220, Val Acc: 0.505155\n",
      "Epoch 2114 - Train Loss: 0.237251, Train Acc: 0.543590 | Val Loss: 0.249201, Val Acc: 0.505155\n",
      "Epoch 2115 - Train Loss: 0.237232, Train Acc: 0.543590 | Val Loss: 0.249182, Val Acc: 0.505155\n",
      "Epoch 2116 - Train Loss: 0.237212, Train Acc: 0.543590 | Val Loss: 0.249163, Val Acc: 0.505155\n",
      "Epoch 2117 - Train Loss: 0.237192, Train Acc: 0.543590 | Val Loss: 0.249144, Val Acc: 0.505155\n",
      "Epoch 2118 - Train Loss: 0.237173, Train Acc: 0.543590 | Val Loss: 0.249126, Val Acc: 0.505155\n",
      "Epoch 2119 - Train Loss: 0.237153, Train Acc: 0.543590 | Val Loss: 0.249107, Val Acc: 0.505155\n",
      "Epoch 2120 - Train Loss: 0.237133, Train Acc: 0.543590 | Val Loss: 0.249088, Val Acc: 0.505155\n",
      "Epoch 2121 - Train Loss: 0.237114, Train Acc: 0.543590 | Val Loss: 0.249069, Val Acc: 0.505155\n",
      "Epoch 2122 - Train Loss: 0.237094, Train Acc: 0.543590 | Val Loss: 0.249051, Val Acc: 0.505155\n",
      "Epoch 2123 - Train Loss: 0.237075, Train Acc: 0.543590 | Val Loss: 0.249032, Val Acc: 0.505155\n",
      "Epoch 2124 - Train Loss: 0.237055, Train Acc: 0.543590 | Val Loss: 0.249013, Val Acc: 0.505155\n",
      "Epoch 2125 - Train Loss: 0.237035, Train Acc: 0.543590 | Val Loss: 0.248994, Val Acc: 0.505155\n",
      "Epoch 2126 - Train Loss: 0.237016, Train Acc: 0.543590 | Val Loss: 0.248976, Val Acc: 0.505155\n",
      "Epoch 2127 - Train Loss: 0.236996, Train Acc: 0.543590 | Val Loss: 0.248957, Val Acc: 0.505155\n",
      "Epoch 2128 - Train Loss: 0.236976, Train Acc: 0.544872 | Val Loss: 0.248938, Val Acc: 0.505155\n",
      "Epoch 2129 - Train Loss: 0.236957, Train Acc: 0.544872 | Val Loss: 0.248919, Val Acc: 0.505155\n",
      "Epoch 2130 - Train Loss: 0.236937, Train Acc: 0.544872 | Val Loss: 0.248900, Val Acc: 0.505155\n",
      "Epoch 2131 - Train Loss: 0.236917, Train Acc: 0.544872 | Val Loss: 0.248881, Val Acc: 0.505155\n",
      "Epoch 2132 - Train Loss: 0.236897, Train Acc: 0.544872 | Val Loss: 0.248863, Val Acc: 0.505155\n",
      "Epoch 2133 - Train Loss: 0.236878, Train Acc: 0.544872 | Val Loss: 0.248844, Val Acc: 0.505155\n",
      "Epoch 2134 - Train Loss: 0.236858, Train Acc: 0.544872 | Val Loss: 0.248825, Val Acc: 0.505155\n",
      "Epoch 2135 - Train Loss: 0.236838, Train Acc: 0.544872 | Val Loss: 0.248806, Val Acc: 0.505155\n",
      "Epoch 2136 - Train Loss: 0.236819, Train Acc: 0.544872 | Val Loss: 0.248787, Val Acc: 0.505155\n",
      "Epoch 2137 - Train Loss: 0.236799, Train Acc: 0.544872 | Val Loss: 0.248768, Val Acc: 0.505155\n",
      "Epoch 2138 - Train Loss: 0.236779, Train Acc: 0.544872 | Val Loss: 0.248750, Val Acc: 0.505155\n",
      "Epoch 2139 - Train Loss: 0.236760, Train Acc: 0.544872 | Val Loss: 0.248731, Val Acc: 0.505155\n",
      "Epoch 2140 - Train Loss: 0.236740, Train Acc: 0.544872 | Val Loss: 0.248712, Val Acc: 0.505155\n",
      "Epoch 2141 - Train Loss: 0.236720, Train Acc: 0.544872 | Val Loss: 0.248693, Val Acc: 0.505155\n",
      "Epoch 2142 - Train Loss: 0.236700, Train Acc: 0.544872 | Val Loss: 0.248675, Val Acc: 0.505155\n",
      "Epoch 2143 - Train Loss: 0.236681, Train Acc: 0.544872 | Val Loss: 0.248656, Val Acc: 0.505155\n",
      "Epoch 2144 - Train Loss: 0.236661, Train Acc: 0.544872 | Val Loss: 0.248637, Val Acc: 0.505155\n",
      "Epoch 2145 - Train Loss: 0.236641, Train Acc: 0.544872 | Val Loss: 0.248618, Val Acc: 0.505155\n",
      "Epoch 2146 - Train Loss: 0.236622, Train Acc: 0.544872 | Val Loss: 0.248600, Val Acc: 0.505155\n",
      "Epoch 2147 - Train Loss: 0.236602, Train Acc: 0.544872 | Val Loss: 0.248581, Val Acc: 0.505155\n",
      "Epoch 2148 - Train Loss: 0.236583, Train Acc: 0.544872 | Val Loss: 0.248562, Val Acc: 0.505155\n",
      "Epoch 2149 - Train Loss: 0.236563, Train Acc: 0.544872 | Val Loss: 0.248544, Val Acc: 0.505155\n",
      "Epoch 2150 - Train Loss: 0.236543, Train Acc: 0.544872 | Val Loss: 0.248525, Val Acc: 0.505155\n",
      "Epoch 2151 - Train Loss: 0.236524, Train Acc: 0.544872 | Val Loss: 0.248506, Val Acc: 0.505155\n",
      "Epoch 2152 - Train Loss: 0.236504, Train Acc: 0.544872 | Val Loss: 0.248487, Val Acc: 0.505155\n",
      "Epoch 2153 - Train Loss: 0.236484, Train Acc: 0.544872 | Val Loss: 0.248469, Val Acc: 0.505155\n",
      "Epoch 2154 - Train Loss: 0.236464, Train Acc: 0.544872 | Val Loss: 0.248450, Val Acc: 0.505155\n",
      "Epoch 2155 - Train Loss: 0.236445, Train Acc: 0.544872 | Val Loss: 0.248431, Val Acc: 0.505155\n",
      "Epoch 2156 - Train Loss: 0.236425, Train Acc: 0.544872 | Val Loss: 0.248412, Val Acc: 0.505155\n",
      "Epoch 2157 - Train Loss: 0.236405, Train Acc: 0.544872 | Val Loss: 0.248394, Val Acc: 0.505155\n",
      "Epoch 2158 - Train Loss: 0.236386, Train Acc: 0.544872 | Val Loss: 0.248375, Val Acc: 0.505155\n",
      "Epoch 2159 - Train Loss: 0.236366, Train Acc: 0.544872 | Val Loss: 0.248356, Val Acc: 0.505155\n",
      "Epoch 2160 - Train Loss: 0.236346, Train Acc: 0.544872 | Val Loss: 0.248338, Val Acc: 0.505155\n",
      "Epoch 2161 - Train Loss: 0.236327, Train Acc: 0.544872 | Val Loss: 0.248319, Val Acc: 0.505155\n",
      "Epoch 2162 - Train Loss: 0.236307, Train Acc: 0.544872 | Val Loss: 0.248301, Val Acc: 0.505155\n",
      "Epoch 2163 - Train Loss: 0.236287, Train Acc: 0.544872 | Val Loss: 0.248282, Val Acc: 0.505155\n",
      "Epoch 2164 - Train Loss: 0.236268, Train Acc: 0.544872 | Val Loss: 0.248263, Val Acc: 0.505155\n",
      "Epoch 2165 - Train Loss: 0.236248, Train Acc: 0.544872 | Val Loss: 0.248245, Val Acc: 0.505155\n",
      "Epoch 2166 - Train Loss: 0.236228, Train Acc: 0.544872 | Val Loss: 0.248226, Val Acc: 0.505155\n",
      "Epoch 2167 - Train Loss: 0.236209, Train Acc: 0.544872 | Val Loss: 0.248207, Val Acc: 0.505155\n",
      "Epoch 2168 - Train Loss: 0.236189, Train Acc: 0.544872 | Val Loss: 0.248189, Val Acc: 0.505155\n",
      "Epoch 2169 - Train Loss: 0.236169, Train Acc: 0.544872 | Val Loss: 0.248170, Val Acc: 0.505155\n",
      "Epoch 2170 - Train Loss: 0.236149, Train Acc: 0.544872 | Val Loss: 0.248152, Val Acc: 0.505155\n",
      "Epoch 2171 - Train Loss: 0.236130, Train Acc: 0.544872 | Val Loss: 0.248133, Val Acc: 0.505155\n",
      "Epoch 2172 - Train Loss: 0.236110, Train Acc: 0.544872 | Val Loss: 0.248114, Val Acc: 0.505155\n",
      "Epoch 2173 - Train Loss: 0.236090, Train Acc: 0.544872 | Val Loss: 0.248096, Val Acc: 0.505155\n",
      "Epoch 2174 - Train Loss: 0.236071, Train Acc: 0.544872 | Val Loss: 0.248077, Val Acc: 0.505155\n",
      "Epoch 2175 - Train Loss: 0.236051, Train Acc: 0.544872 | Val Loss: 0.248059, Val Acc: 0.505155\n",
      "Epoch 2176 - Train Loss: 0.236032, Train Acc: 0.544872 | Val Loss: 0.248040, Val Acc: 0.505155\n",
      "Epoch 2177 - Train Loss: 0.236012, Train Acc: 0.544872 | Val Loss: 0.248022, Val Acc: 0.505155\n",
      "Epoch 2178 - Train Loss: 0.235992, Train Acc: 0.544872 | Val Loss: 0.248003, Val Acc: 0.505155\n",
      "Epoch 2179 - Train Loss: 0.235973, Train Acc: 0.544872 | Val Loss: 0.247984, Val Acc: 0.505155\n",
      "Epoch 2180 - Train Loss: 0.235953, Train Acc: 0.544872 | Val Loss: 0.247966, Val Acc: 0.505155\n",
      "Epoch 2181 - Train Loss: 0.235933, Train Acc: 0.544872 | Val Loss: 0.247947, Val Acc: 0.505155\n",
      "Epoch 2182 - Train Loss: 0.235914, Train Acc: 0.544872 | Val Loss: 0.247929, Val Acc: 0.505155\n",
      "Epoch 2183 - Train Loss: 0.235894, Train Acc: 0.544872 | Val Loss: 0.247910, Val Acc: 0.505155\n",
      "Epoch 2184 - Train Loss: 0.235874, Train Acc: 0.544872 | Val Loss: 0.247892, Val Acc: 0.505155\n",
      "Epoch 2185 - Train Loss: 0.235855, Train Acc: 0.544872 | Val Loss: 0.247873, Val Acc: 0.505155\n",
      "Epoch 2186 - Train Loss: 0.235835, Train Acc: 0.544872 | Val Loss: 0.247854, Val Acc: 0.505155\n",
      "Epoch 2187 - Train Loss: 0.235815, Train Acc: 0.544872 | Val Loss: 0.247836, Val Acc: 0.505155\n",
      "Epoch 2188 - Train Loss: 0.235796, Train Acc: 0.544872 | Val Loss: 0.247817, Val Acc: 0.505155\n",
      "Epoch 2189 - Train Loss: 0.235776, Train Acc: 0.544872 | Val Loss: 0.247799, Val Acc: 0.505155\n",
      "Epoch 2190 - Train Loss: 0.235756, Train Acc: 0.544872 | Val Loss: 0.247780, Val Acc: 0.505155\n",
      "Epoch 2191 - Train Loss: 0.235737, Train Acc: 0.544872 | Val Loss: 0.247762, Val Acc: 0.505155\n",
      "Epoch 2192 - Train Loss: 0.235717, Train Acc: 0.544872 | Val Loss: 0.247743, Val Acc: 0.505155\n",
      "Epoch 2193 - Train Loss: 0.235697, Train Acc: 0.544872 | Val Loss: 0.247725, Val Acc: 0.505155\n",
      "Epoch 2194 - Train Loss: 0.235678, Train Acc: 0.544872 | Val Loss: 0.247706, Val Acc: 0.505155\n",
      "Epoch 2195 - Train Loss: 0.235658, Train Acc: 0.544872 | Val Loss: 0.247688, Val Acc: 0.505155\n",
      "Epoch 2196 - Train Loss: 0.235639, Train Acc: 0.544872 | Val Loss: 0.247669, Val Acc: 0.505155\n",
      "Epoch 2197 - Train Loss: 0.235619, Train Acc: 0.544872 | Val Loss: 0.247651, Val Acc: 0.505155\n",
      "Epoch 2198 - Train Loss: 0.235599, Train Acc: 0.544872 | Val Loss: 0.247632, Val Acc: 0.505155\n",
      "Epoch 2199 - Train Loss: 0.235580, Train Acc: 0.544872 | Val Loss: 0.247614, Val Acc: 0.505155\n",
      "Epoch 2200 - Train Loss: 0.235560, Train Acc: 0.544872 | Val Loss: 0.247595, Val Acc: 0.505155\n",
      "Epoch 2201 - Train Loss: 0.235541, Train Acc: 0.544872 | Val Loss: 0.247577, Val Acc: 0.505155\n",
      "Epoch 2202 - Train Loss: 0.235521, Train Acc: 0.544872 | Val Loss: 0.247558, Val Acc: 0.505155\n",
      "Epoch 2203 - Train Loss: 0.235501, Train Acc: 0.544872 | Val Loss: 0.247540, Val Acc: 0.505155\n",
      "Epoch 2204 - Train Loss: 0.235482, Train Acc: 0.544872 | Val Loss: 0.247521, Val Acc: 0.505155\n",
      "Epoch 2205 - Train Loss: 0.235462, Train Acc: 0.544872 | Val Loss: 0.247503, Val Acc: 0.505155\n",
      "Epoch 2206 - Train Loss: 0.235442, Train Acc: 0.544872 | Val Loss: 0.247484, Val Acc: 0.505155\n",
      "Epoch 2207 - Train Loss: 0.235423, Train Acc: 0.544872 | Val Loss: 0.247465, Val Acc: 0.505155\n",
      "Epoch 2208 - Train Loss: 0.235403, Train Acc: 0.544872 | Val Loss: 0.247447, Val Acc: 0.505155\n",
      "Epoch 2209 - Train Loss: 0.235384, Train Acc: 0.544872 | Val Loss: 0.247428, Val Acc: 0.505155\n",
      "Epoch 2210 - Train Loss: 0.235364, Train Acc: 0.544872 | Val Loss: 0.247410, Val Acc: 0.505155\n",
      "Epoch 2211 - Train Loss: 0.235344, Train Acc: 0.544872 | Val Loss: 0.247391, Val Acc: 0.505155\n",
      "Epoch 2212 - Train Loss: 0.235325, Train Acc: 0.546154 | Val Loss: 0.247373, Val Acc: 0.505155\n",
      "Epoch 2213 - Train Loss: 0.235305, Train Acc: 0.546154 | Val Loss: 0.247354, Val Acc: 0.505155\n",
      "Epoch 2214 - Train Loss: 0.235285, Train Acc: 0.546154 | Val Loss: 0.247336, Val Acc: 0.505155\n",
      "Epoch 2215 - Train Loss: 0.235266, Train Acc: 0.546154 | Val Loss: 0.247317, Val Acc: 0.505155\n",
      "Epoch 2216 - Train Loss: 0.235246, Train Acc: 0.546154 | Val Loss: 0.247299, Val Acc: 0.505155\n",
      "Epoch 2217 - Train Loss: 0.235227, Train Acc: 0.546154 | Val Loss: 0.247280, Val Acc: 0.505155\n",
      "Epoch 2218 - Train Loss: 0.235207, Train Acc: 0.546154 | Val Loss: 0.247262, Val Acc: 0.505155\n",
      "Epoch 2219 - Train Loss: 0.235187, Train Acc: 0.546154 | Val Loss: 0.247243, Val Acc: 0.505155\n",
      "Epoch 2220 - Train Loss: 0.235168, Train Acc: 0.546154 | Val Loss: 0.247225, Val Acc: 0.505155\n",
      "Epoch 2221 - Train Loss: 0.235148, Train Acc: 0.546154 | Val Loss: 0.247206, Val Acc: 0.505155\n",
      "Epoch 2222 - Train Loss: 0.235128, Train Acc: 0.546154 | Val Loss: 0.247187, Val Acc: 0.505155\n",
      "Epoch 2223 - Train Loss: 0.235109, Train Acc: 0.546154 | Val Loss: 0.247169, Val Acc: 0.505155\n",
      "Epoch 2224 - Train Loss: 0.235089, Train Acc: 0.546154 | Val Loss: 0.247150, Val Acc: 0.505155\n",
      "Epoch 2225 - Train Loss: 0.235069, Train Acc: 0.546154 | Val Loss: 0.247131, Val Acc: 0.505155\n",
      "Epoch 2226 - Train Loss: 0.235050, Train Acc: 0.546154 | Val Loss: 0.247112, Val Acc: 0.505155\n",
      "Epoch 2227 - Train Loss: 0.235030, Train Acc: 0.546154 | Val Loss: 0.247094, Val Acc: 0.505155\n",
      "Epoch 2228 - Train Loss: 0.235011, Train Acc: 0.546154 | Val Loss: 0.247075, Val Acc: 0.505155\n",
      "Epoch 2229 - Train Loss: 0.234991, Train Acc: 0.546154 | Val Loss: 0.247057, Val Acc: 0.505155\n",
      "Epoch 2230 - Train Loss: 0.234971, Train Acc: 0.546154 | Val Loss: 0.247038, Val Acc: 0.505155\n",
      "Epoch 2231 - Train Loss: 0.234952, Train Acc: 0.546154 | Val Loss: 0.247019, Val Acc: 0.505155\n",
      "Epoch 2232 - Train Loss: 0.234932, Train Acc: 0.546154 | Val Loss: 0.247000, Val Acc: 0.505155\n",
      "Epoch 2233 - Train Loss: 0.234912, Train Acc: 0.546154 | Val Loss: 0.246982, Val Acc: 0.505155\n",
      "Epoch 2234 - Train Loss: 0.234893, Train Acc: 0.546154 | Val Loss: 0.246963, Val Acc: 0.505155\n",
      "Epoch 2235 - Train Loss: 0.234873, Train Acc: 0.546154 | Val Loss: 0.246944, Val Acc: 0.505155\n",
      "Epoch 2236 - Train Loss: 0.234854, Train Acc: 0.546154 | Val Loss: 0.246925, Val Acc: 0.505155\n",
      "Epoch 2237 - Train Loss: 0.234834, Train Acc: 0.546154 | Val Loss: 0.246906, Val Acc: 0.505155\n",
      "Epoch 2238 - Train Loss: 0.234814, Train Acc: 0.546154 | Val Loss: 0.246888, Val Acc: 0.505155\n",
      "Epoch 2239 - Train Loss: 0.234795, Train Acc: 0.546154 | Val Loss: 0.246869, Val Acc: 0.505155\n",
      "Epoch 2240 - Train Loss: 0.234775, Train Acc: 0.546154 | Val Loss: 0.246850, Val Acc: 0.505155\n",
      "Epoch 2241 - Train Loss: 0.234755, Train Acc: 0.546154 | Val Loss: 0.246831, Val Acc: 0.505155\n",
      "Epoch 2242 - Train Loss: 0.234736, Train Acc: 0.546154 | Val Loss: 0.246812, Val Acc: 0.505155\n",
      "Epoch 2243 - Train Loss: 0.234716, Train Acc: 0.546154 | Val Loss: 0.246794, Val Acc: 0.505155\n",
      "Epoch 2244 - Train Loss: 0.234697, Train Acc: 0.546154 | Val Loss: 0.246775, Val Acc: 0.505155\n",
      "Epoch 2245 - Train Loss: 0.234677, Train Acc: 0.546154 | Val Loss: 0.246756, Val Acc: 0.505155\n",
      "Epoch 2246 - Train Loss: 0.234657, Train Acc: 0.546154 | Val Loss: 0.246737, Val Acc: 0.505155\n",
      "Epoch 2247 - Train Loss: 0.234638, Train Acc: 0.546154 | Val Loss: 0.246718, Val Acc: 0.505155\n",
      "Epoch 2248 - Train Loss: 0.234618, Train Acc: 0.546154 | Val Loss: 0.246700, Val Acc: 0.505155\n",
      "Epoch 2249 - Train Loss: 0.234599, Train Acc: 0.546154 | Val Loss: 0.246681, Val Acc: 0.505155\n",
      "Epoch 2250 - Train Loss: 0.234579, Train Acc: 0.546154 | Val Loss: 0.246662, Val Acc: 0.505155\n",
      "Epoch 2251 - Train Loss: 0.234559, Train Acc: 0.546154 | Val Loss: 0.246643, Val Acc: 0.505155\n",
      "Epoch 2252 - Train Loss: 0.234540, Train Acc: 0.547436 | Val Loss: 0.246624, Val Acc: 0.505155\n",
      "Epoch 2253 - Train Loss: 0.234520, Train Acc: 0.547436 | Val Loss: 0.246605, Val Acc: 0.505155\n",
      "Epoch 2254 - Train Loss: 0.234500, Train Acc: 0.547436 | Val Loss: 0.246587, Val Acc: 0.505155\n",
      "Epoch 2255 - Train Loss: 0.234481, Train Acc: 0.547436 | Val Loss: 0.246568, Val Acc: 0.505155\n",
      "Epoch 2256 - Train Loss: 0.234461, Train Acc: 0.547436 | Val Loss: 0.246549, Val Acc: 0.505155\n",
      "Epoch 2257 - Train Loss: 0.234442, Train Acc: 0.547436 | Val Loss: 0.246530, Val Acc: 0.505155\n",
      "Epoch 2258 - Train Loss: 0.234422, Train Acc: 0.547436 | Val Loss: 0.246511, Val Acc: 0.505155\n",
      "Epoch 2259 - Train Loss: 0.234402, Train Acc: 0.547436 | Val Loss: 0.246493, Val Acc: 0.505155\n",
      "Epoch 2260 - Train Loss: 0.234383, Train Acc: 0.547436 | Val Loss: 0.246474, Val Acc: 0.505155\n",
      "Epoch 2261 - Train Loss: 0.234363, Train Acc: 0.547436 | Val Loss: 0.246455, Val Acc: 0.505155\n",
      "Epoch 2262 - Train Loss: 0.234344, Train Acc: 0.547436 | Val Loss: 0.246436, Val Acc: 0.505155\n",
      "Epoch 2263 - Train Loss: 0.234324, Train Acc: 0.548718 | Val Loss: 0.246417, Val Acc: 0.505155\n",
      "Epoch 2264 - Train Loss: 0.234304, Train Acc: 0.548718 | Val Loss: 0.246398, Val Acc: 0.505155\n",
      "Epoch 2265 - Train Loss: 0.234285, Train Acc: 0.548718 | Val Loss: 0.246380, Val Acc: 0.505155\n",
      "Epoch 2266 - Train Loss: 0.234265, Train Acc: 0.548718 | Val Loss: 0.246361, Val Acc: 0.505155\n",
      "Epoch 2267 - Train Loss: 0.234245, Train Acc: 0.548718 | Val Loss: 0.246342, Val Acc: 0.505155\n",
      "Epoch 2268 - Train Loss: 0.234226, Train Acc: 0.548718 | Val Loss: 0.246323, Val Acc: 0.505155\n",
      "Epoch 2269 - Train Loss: 0.234206, Train Acc: 0.548718 | Val Loss: 0.246305, Val Acc: 0.505155\n",
      "Epoch 2270 - Train Loss: 0.234187, Train Acc: 0.548718 | Val Loss: 0.246286, Val Acc: 0.505155\n",
      "Epoch 2271 - Train Loss: 0.234167, Train Acc: 0.548718 | Val Loss: 0.246267, Val Acc: 0.505155\n",
      "Epoch 2272 - Train Loss: 0.234148, Train Acc: 0.548718 | Val Loss: 0.246248, Val Acc: 0.505155\n",
      "Epoch 2273 - Train Loss: 0.234128, Train Acc: 0.548718 | Val Loss: 0.246229, Val Acc: 0.505155\n",
      "Epoch 2274 - Train Loss: 0.234108, Train Acc: 0.548718 | Val Loss: 0.246211, Val Acc: 0.505155\n",
      "Epoch 2275 - Train Loss: 0.234089, Train Acc: 0.548718 | Val Loss: 0.246192, Val Acc: 0.505155\n",
      "Epoch 2276 - Train Loss: 0.234069, Train Acc: 0.550000 | Val Loss: 0.246173, Val Acc: 0.505155\n",
      "Epoch 2277 - Train Loss: 0.234050, Train Acc: 0.550000 | Val Loss: 0.246155, Val Acc: 0.505155\n",
      "Epoch 2278 - Train Loss: 0.234030, Train Acc: 0.550000 | Val Loss: 0.246136, Val Acc: 0.505155\n",
      "Epoch 2279 - Train Loss: 0.234010, Train Acc: 0.550000 | Val Loss: 0.246117, Val Acc: 0.505155\n",
      "Epoch 2280 - Train Loss: 0.233991, Train Acc: 0.550000 | Val Loss: 0.246099, Val Acc: 0.505155\n",
      "Epoch 2281 - Train Loss: 0.233971, Train Acc: 0.550000 | Val Loss: 0.246080, Val Acc: 0.505155\n",
      "Epoch 2282 - Train Loss: 0.233952, Train Acc: 0.550000 | Val Loss: 0.246061, Val Acc: 0.505155\n",
      "Epoch 2283 - Train Loss: 0.233932, Train Acc: 0.550000 | Val Loss: 0.246042, Val Acc: 0.505155\n",
      "Epoch 2284 - Train Loss: 0.233913, Train Acc: 0.550000 | Val Loss: 0.246024, Val Acc: 0.505155\n",
      "Epoch 2285 - Train Loss: 0.233893, Train Acc: 0.550000 | Val Loss: 0.246005, Val Acc: 0.505155\n",
      "Epoch 2286 - Train Loss: 0.233873, Train Acc: 0.550000 | Val Loss: 0.245986, Val Acc: 0.505155\n",
      "Epoch 2287 - Train Loss: 0.233854, Train Acc: 0.550000 | Val Loss: 0.245968, Val Acc: 0.505155\n",
      "Epoch 2288 - Train Loss: 0.233834, Train Acc: 0.550000 | Val Loss: 0.245949, Val Acc: 0.505155\n",
      "Epoch 2289 - Train Loss: 0.233815, Train Acc: 0.551282 | Val Loss: 0.245930, Val Acc: 0.505155\n",
      "Epoch 2290 - Train Loss: 0.233795, Train Acc: 0.551282 | Val Loss: 0.245911, Val Acc: 0.505155\n",
      "Epoch 2291 - Train Loss: 0.233775, Train Acc: 0.551282 | Val Loss: 0.245893, Val Acc: 0.505155\n",
      "Epoch 2292 - Train Loss: 0.233756, Train Acc: 0.551282 | Val Loss: 0.245874, Val Acc: 0.505155\n",
      "Epoch 2293 - Train Loss: 0.233736, Train Acc: 0.551282 | Val Loss: 0.245855, Val Acc: 0.505155\n",
      "Epoch 2294 - Train Loss: 0.233717, Train Acc: 0.551282 | Val Loss: 0.245836, Val Acc: 0.505155\n",
      "Epoch 2295 - Train Loss: 0.233697, Train Acc: 0.551282 | Val Loss: 0.245817, Val Acc: 0.505155\n",
      "Epoch 2296 - Train Loss: 0.233678, Train Acc: 0.551282 | Val Loss: 0.245799, Val Acc: 0.505155\n",
      "Epoch 2297 - Train Loss: 0.233658, Train Acc: 0.551282 | Val Loss: 0.245780, Val Acc: 0.505155\n",
      "Epoch 2298 - Train Loss: 0.233638, Train Acc: 0.551282 | Val Loss: 0.245761, Val Acc: 0.505155\n",
      "Epoch 2299 - Train Loss: 0.233619, Train Acc: 0.551282 | Val Loss: 0.245742, Val Acc: 0.505155\n",
      "Epoch 2300 - Train Loss: 0.233599, Train Acc: 0.551282 | Val Loss: 0.245724, Val Acc: 0.505155\n",
      "Epoch 2301 - Train Loss: 0.233580, Train Acc: 0.551282 | Val Loss: 0.245705, Val Acc: 0.505155\n",
      "Epoch 2302 - Train Loss: 0.233560, Train Acc: 0.551282 | Val Loss: 0.245686, Val Acc: 0.505155\n",
      "Epoch 2303 - Train Loss: 0.233540, Train Acc: 0.551282 | Val Loss: 0.245667, Val Acc: 0.505155\n",
      "Epoch 2304 - Train Loss: 0.233521, Train Acc: 0.551282 | Val Loss: 0.245648, Val Acc: 0.505155\n",
      "Epoch 2305 - Train Loss: 0.233501, Train Acc: 0.551282 | Val Loss: 0.245630, Val Acc: 0.505155\n",
      "Epoch 2306 - Train Loss: 0.233482, Train Acc: 0.551282 | Val Loss: 0.245611, Val Acc: 0.505155\n",
      "Epoch 2307 - Train Loss: 0.233462, Train Acc: 0.551282 | Val Loss: 0.245592, Val Acc: 0.505155\n",
      "Epoch 2308 - Train Loss: 0.233443, Train Acc: 0.551282 | Val Loss: 0.245573, Val Acc: 0.505155\n",
      "Epoch 2309 - Train Loss: 0.233423, Train Acc: 0.551282 | Val Loss: 0.245554, Val Acc: 0.505155\n",
      "Epoch 2310 - Train Loss: 0.233403, Train Acc: 0.551282 | Val Loss: 0.245536, Val Acc: 0.505155\n",
      "Epoch 2311 - Train Loss: 0.233384, Train Acc: 0.551282 | Val Loss: 0.245517, Val Acc: 0.505155\n",
      "Epoch 2312 - Train Loss: 0.233364, Train Acc: 0.551282 | Val Loss: 0.245498, Val Acc: 0.505155\n",
      "Epoch 2313 - Train Loss: 0.233345, Train Acc: 0.551282 | Val Loss: 0.245479, Val Acc: 0.505155\n",
      "Epoch 2314 - Train Loss: 0.233325, Train Acc: 0.551282 | Val Loss: 0.245460, Val Acc: 0.505155\n",
      "Epoch 2315 - Train Loss: 0.233305, Train Acc: 0.551282 | Val Loss: 0.245442, Val Acc: 0.505155\n",
      "Epoch 2316 - Train Loss: 0.233286, Train Acc: 0.551282 | Val Loss: 0.245423, Val Acc: 0.505155\n",
      "Epoch 2317 - Train Loss: 0.233266, Train Acc: 0.551282 | Val Loss: 0.245404, Val Acc: 0.505155\n",
      "Epoch 2318 - Train Loss: 0.233247, Train Acc: 0.551282 | Val Loss: 0.245385, Val Acc: 0.505155\n",
      "Epoch 2319 - Train Loss: 0.233227, Train Acc: 0.551282 | Val Loss: 0.245366, Val Acc: 0.505155\n",
      "Epoch 2320 - Train Loss: 0.233207, Train Acc: 0.553846 | Val Loss: 0.245347, Val Acc: 0.505155\n",
      "Epoch 2321 - Train Loss: 0.233188, Train Acc: 0.553846 | Val Loss: 0.245329, Val Acc: 0.505155\n",
      "Epoch 2322 - Train Loss: 0.233168, Train Acc: 0.553846 | Val Loss: 0.245310, Val Acc: 0.505155\n",
      "Epoch 2323 - Train Loss: 0.233149, Train Acc: 0.553846 | Val Loss: 0.245291, Val Acc: 0.505155\n",
      "Epoch 2324 - Train Loss: 0.233129, Train Acc: 0.553846 | Val Loss: 0.245272, Val Acc: 0.505155\n",
      "Epoch 2325 - Train Loss: 0.233110, Train Acc: 0.553846 | Val Loss: 0.245253, Val Acc: 0.505155\n",
      "Epoch 2326 - Train Loss: 0.233090, Train Acc: 0.553846 | Val Loss: 0.245234, Val Acc: 0.505155\n",
      "Epoch 2327 - Train Loss: 0.233070, Train Acc: 0.553846 | Val Loss: 0.245216, Val Acc: 0.505155\n",
      "Epoch 2328 - Train Loss: 0.233051, Train Acc: 0.553846 | Val Loss: 0.245197, Val Acc: 0.505155\n",
      "Epoch 2329 - Train Loss: 0.233031, Train Acc: 0.553846 | Val Loss: 0.245178, Val Acc: 0.505155\n",
      "Epoch 2330 - Train Loss: 0.233012, Train Acc: 0.553846 | Val Loss: 0.245159, Val Acc: 0.505155\n",
      "Epoch 2331 - Train Loss: 0.232992, Train Acc: 0.553846 | Val Loss: 0.245140, Val Acc: 0.505155\n",
      "Epoch 2332 - Train Loss: 0.232972, Train Acc: 0.553846 | Val Loss: 0.245121, Val Acc: 0.505155\n",
      "Epoch 2333 - Train Loss: 0.232953, Train Acc: 0.553846 | Val Loss: 0.245103, Val Acc: 0.505155\n",
      "Epoch 2334 - Train Loss: 0.232933, Train Acc: 0.553846 | Val Loss: 0.245084, Val Acc: 0.505155\n",
      "Epoch 2335 - Train Loss: 0.232914, Train Acc: 0.553846 | Val Loss: 0.245065, Val Acc: 0.505155\n",
      "Epoch 2336 - Train Loss: 0.232894, Train Acc: 0.553846 | Val Loss: 0.245046, Val Acc: 0.505155\n",
      "Epoch 2337 - Train Loss: 0.232875, Train Acc: 0.553846 | Val Loss: 0.245027, Val Acc: 0.505155\n",
      "Epoch 2338 - Train Loss: 0.232855, Train Acc: 0.553846 | Val Loss: 0.245008, Val Acc: 0.505155\n",
      "Epoch 2339 - Train Loss: 0.232835, Train Acc: 0.553846 | Val Loss: 0.244990, Val Acc: 0.505155\n",
      "Epoch 2340 - Train Loss: 0.232816, Train Acc: 0.553846 | Val Loss: 0.244971, Val Acc: 0.505155\n",
      "Epoch 2341 - Train Loss: 0.232796, Train Acc: 0.553846 | Val Loss: 0.244952, Val Acc: 0.505155\n",
      "Epoch 2342 - Train Loss: 0.232777, Train Acc: 0.553846 | Val Loss: 0.244933, Val Acc: 0.505155\n",
      "Epoch 2343 - Train Loss: 0.232757, Train Acc: 0.553846 | Val Loss: 0.244914, Val Acc: 0.505155\n",
      "Epoch 2344 - Train Loss: 0.232738, Train Acc: 0.553846 | Val Loss: 0.244896, Val Acc: 0.505155\n",
      "Epoch 2345 - Train Loss: 0.232718, Train Acc: 0.553846 | Val Loss: 0.244877, Val Acc: 0.505155\n",
      "Epoch 2346 - Train Loss: 0.232698, Train Acc: 0.553846 | Val Loss: 0.244858, Val Acc: 0.505155\n",
      "Epoch 2347 - Train Loss: 0.232679, Train Acc: 0.553846 | Val Loss: 0.244839, Val Acc: 0.505155\n",
      "Epoch 2348 - Train Loss: 0.232659, Train Acc: 0.553846 | Val Loss: 0.244820, Val Acc: 0.505155\n",
      "Epoch 2349 - Train Loss: 0.232640, Train Acc: 0.553846 | Val Loss: 0.244801, Val Acc: 0.505155\n",
      "Epoch 2350 - Train Loss: 0.232620, Train Acc: 0.553846 | Val Loss: 0.244783, Val Acc: 0.505155\n",
      "Epoch 2351 - Train Loss: 0.232600, Train Acc: 0.553846 | Val Loss: 0.244764, Val Acc: 0.505155\n",
      "Epoch 2352 - Train Loss: 0.232581, Train Acc: 0.553846 | Val Loss: 0.244745, Val Acc: 0.505155\n",
      "Epoch 2353 - Train Loss: 0.232561, Train Acc: 0.553846 | Val Loss: 0.244726, Val Acc: 0.505155\n",
      "Epoch 2354 - Train Loss: 0.232542, Train Acc: 0.553846 | Val Loss: 0.244707, Val Acc: 0.505155\n",
      "Epoch 2355 - Train Loss: 0.232522, Train Acc: 0.553846 | Val Loss: 0.244688, Val Acc: 0.505155\n",
      "Epoch 2356 - Train Loss: 0.232503, Train Acc: 0.553846 | Val Loss: 0.244670, Val Acc: 0.505155\n",
      "Epoch 2357 - Train Loss: 0.232483, Train Acc: 0.553846 | Val Loss: 0.244651, Val Acc: 0.505155\n",
      "Epoch 2358 - Train Loss: 0.232463, Train Acc: 0.553846 | Val Loss: 0.244632, Val Acc: 0.505155\n",
      "Epoch 2359 - Train Loss: 0.232444, Train Acc: 0.553846 | Val Loss: 0.244613, Val Acc: 0.505155\n",
      "Epoch 2360 - Train Loss: 0.232424, Train Acc: 0.553846 | Val Loss: 0.244594, Val Acc: 0.505155\n",
      "Epoch 2361 - Train Loss: 0.232405, Train Acc: 0.553846 | Val Loss: 0.244575, Val Acc: 0.505155\n",
      "Epoch 2362 - Train Loss: 0.232385, Train Acc: 0.553846 | Val Loss: 0.244557, Val Acc: 0.505155\n",
      "Epoch 2363 - Train Loss: 0.232365, Train Acc: 0.553846 | Val Loss: 0.244538, Val Acc: 0.505155\n",
      "Epoch 2364 - Train Loss: 0.232346, Train Acc: 0.553846 | Val Loss: 0.244519, Val Acc: 0.505155\n",
      "Epoch 2365 - Train Loss: 0.232326, Train Acc: 0.553846 | Val Loss: 0.244500, Val Acc: 0.505155\n",
      "Epoch 2366 - Train Loss: 0.232307, Train Acc: 0.553846 | Val Loss: 0.244481, Val Acc: 0.505155\n",
      "Epoch 2367 - Train Loss: 0.232287, Train Acc: 0.553846 | Val Loss: 0.244462, Val Acc: 0.505155\n",
      "Epoch 2368 - Train Loss: 0.232268, Train Acc: 0.553846 | Val Loss: 0.244443, Val Acc: 0.505155\n",
      "Epoch 2369 - Train Loss: 0.232248, Train Acc: 0.553846 | Val Loss: 0.244425, Val Acc: 0.505155\n",
      "Epoch 2370 - Train Loss: 0.232228, Train Acc: 0.553846 | Val Loss: 0.244406, Val Acc: 0.505155\n",
      "Epoch 2371 - Train Loss: 0.232209, Train Acc: 0.553846 | Val Loss: 0.244387, Val Acc: 0.505155\n",
      "Epoch 2372 - Train Loss: 0.232189, Train Acc: 0.553846 | Val Loss: 0.244368, Val Acc: 0.505155\n",
      "Epoch 2373 - Train Loss: 0.232170, Train Acc: 0.553846 | Val Loss: 0.244349, Val Acc: 0.505155\n",
      "Epoch 2374 - Train Loss: 0.232150, Train Acc: 0.553846 | Val Loss: 0.244330, Val Acc: 0.505155\n",
      "Epoch 2375 - Train Loss: 0.232131, Train Acc: 0.555128 | Val Loss: 0.244311, Val Acc: 0.505155\n",
      "Epoch 2376 - Train Loss: 0.232111, Train Acc: 0.555128 | Val Loss: 0.244293, Val Acc: 0.505155\n",
      "Epoch 2377 - Train Loss: 0.232091, Train Acc: 0.555128 | Val Loss: 0.244274, Val Acc: 0.505155\n",
      "Epoch 2378 - Train Loss: 0.232072, Train Acc: 0.555128 | Val Loss: 0.244255, Val Acc: 0.505155\n",
      "Epoch 2379 - Train Loss: 0.232052, Train Acc: 0.555128 | Val Loss: 0.244236, Val Acc: 0.505155\n",
      "Epoch 2380 - Train Loss: 0.232033, Train Acc: 0.555128 | Val Loss: 0.244217, Val Acc: 0.505155\n",
      "Epoch 2381 - Train Loss: 0.232013, Train Acc: 0.555128 | Val Loss: 0.244198, Val Acc: 0.505155\n",
      "Epoch 2382 - Train Loss: 0.231993, Train Acc: 0.555128 | Val Loss: 0.244179, Val Acc: 0.505155\n",
      "Epoch 2383 - Train Loss: 0.231974, Train Acc: 0.555128 | Val Loss: 0.244161, Val Acc: 0.505155\n",
      "Epoch 2384 - Train Loss: 0.231954, Train Acc: 0.555128 | Val Loss: 0.244142, Val Acc: 0.505155\n",
      "Epoch 2385 - Train Loss: 0.231935, Train Acc: 0.555128 | Val Loss: 0.244123, Val Acc: 0.505155\n",
      "Epoch 2386 - Train Loss: 0.231915, Train Acc: 0.555128 | Val Loss: 0.244104, Val Acc: 0.505155\n",
      "Epoch 2387 - Train Loss: 0.231896, Train Acc: 0.555128 | Val Loss: 0.244085, Val Acc: 0.505155\n",
      "Epoch 2388 - Train Loss: 0.231876, Train Acc: 0.555128 | Val Loss: 0.244066, Val Acc: 0.505155\n",
      "Epoch 2389 - Train Loss: 0.231856, Train Acc: 0.555128 | Val Loss: 0.244048, Val Acc: 0.505155\n",
      "Epoch 2390 - Train Loss: 0.231837, Train Acc: 0.555128 | Val Loss: 0.244029, Val Acc: 0.505155\n",
      "Epoch 2391 - Train Loss: 0.231817, Train Acc: 0.555128 | Val Loss: 0.244010, Val Acc: 0.505155\n",
      "Epoch 2392 - Train Loss: 0.231798, Train Acc: 0.555128 | Val Loss: 0.243991, Val Acc: 0.505155\n",
      "Epoch 2393 - Train Loss: 0.231778, Train Acc: 0.555128 | Val Loss: 0.243972, Val Acc: 0.505155\n",
      "Epoch 2394 - Train Loss: 0.231759, Train Acc: 0.555128 | Val Loss: 0.243953, Val Acc: 0.505155\n",
      "Epoch 2395 - Train Loss: 0.231739, Train Acc: 0.555128 | Val Loss: 0.243935, Val Acc: 0.505155\n",
      "Epoch 2396 - Train Loss: 0.231720, Train Acc: 0.555128 | Val Loss: 0.243916, Val Acc: 0.505155\n",
      "Epoch 2397 - Train Loss: 0.231700, Train Acc: 0.555128 | Val Loss: 0.243897, Val Acc: 0.505155\n",
      "Epoch 2398 - Train Loss: 0.231680, Train Acc: 0.555128 | Val Loss: 0.243878, Val Acc: 0.505155\n",
      "Epoch 2399 - Train Loss: 0.231661, Train Acc: 0.555128 | Val Loss: 0.243859, Val Acc: 0.505155\n",
      "Epoch 2400 - Train Loss: 0.231641, Train Acc: 0.555128 | Val Loss: 0.243840, Val Acc: 0.505155\n",
      "Epoch 2401 - Train Loss: 0.231622, Train Acc: 0.555128 | Val Loss: 0.243822, Val Acc: 0.505155\n",
      "Epoch 2402 - Train Loss: 0.231602, Train Acc: 0.555128 | Val Loss: 0.243803, Val Acc: 0.505155\n",
      "Epoch 2403 - Train Loss: 0.231583, Train Acc: 0.555128 | Val Loss: 0.243784, Val Acc: 0.505155\n",
      "Epoch 2404 - Train Loss: 0.231563, Train Acc: 0.555128 | Val Loss: 0.243765, Val Acc: 0.505155\n",
      "Epoch 2405 - Train Loss: 0.231544, Train Acc: 0.556410 | Val Loss: 0.243746, Val Acc: 0.505155\n",
      "Epoch 2406 - Train Loss: 0.231524, Train Acc: 0.556410 | Val Loss: 0.243727, Val Acc: 0.505155\n",
      "Epoch 2407 - Train Loss: 0.231504, Train Acc: 0.556410 | Val Loss: 0.243709, Val Acc: 0.505155\n",
      "Epoch 2408 - Train Loss: 0.231485, Train Acc: 0.556410 | Val Loss: 0.243690, Val Acc: 0.505155\n",
      "Epoch 2409 - Train Loss: 0.231465, Train Acc: 0.556410 | Val Loss: 0.243671, Val Acc: 0.505155\n",
      "Epoch 2410 - Train Loss: 0.231446, Train Acc: 0.556410 | Val Loss: 0.243652, Val Acc: 0.505155\n",
      "Epoch 2411 - Train Loss: 0.231426, Train Acc: 0.556410 | Val Loss: 0.243633, Val Acc: 0.505155\n",
      "Epoch 2412 - Train Loss: 0.231407, Train Acc: 0.556410 | Val Loss: 0.243614, Val Acc: 0.505155\n",
      "Epoch 2413 - Train Loss: 0.231387, Train Acc: 0.556410 | Val Loss: 0.243595, Val Acc: 0.505155\n",
      "Epoch 2414 - Train Loss: 0.231368, Train Acc: 0.556410 | Val Loss: 0.243577, Val Acc: 0.505155\n",
      "Epoch 2415 - Train Loss: 0.231348, Train Acc: 0.556410 | Val Loss: 0.243558, Val Acc: 0.505155\n",
      "Epoch 2416 - Train Loss: 0.231328, Train Acc: 0.556410 | Val Loss: 0.243539, Val Acc: 0.505155\n",
      "Epoch 2417 - Train Loss: 0.231309, Train Acc: 0.556410 | Val Loss: 0.243520, Val Acc: 0.505155\n",
      "Epoch 2418 - Train Loss: 0.231289, Train Acc: 0.556410 | Val Loss: 0.243501, Val Acc: 0.505155\n",
      "Epoch 2419 - Train Loss: 0.231270, Train Acc: 0.556410 | Val Loss: 0.243482, Val Acc: 0.505155\n",
      "Epoch 2420 - Train Loss: 0.231250, Train Acc: 0.556410 | Val Loss: 0.243463, Val Acc: 0.505155\n",
      "Epoch 2421 - Train Loss: 0.231231, Train Acc: 0.556410 | Val Loss: 0.243445, Val Acc: 0.505155\n",
      "Epoch 2422 - Train Loss: 0.231211, Train Acc: 0.556410 | Val Loss: 0.243426, Val Acc: 0.505155\n",
      "Epoch 2423 - Train Loss: 0.231192, Train Acc: 0.556410 | Val Loss: 0.243407, Val Acc: 0.505155\n",
      "Epoch 2424 - Train Loss: 0.231172, Train Acc: 0.556410 | Val Loss: 0.243388, Val Acc: 0.505155\n",
      "Epoch 2425 - Train Loss: 0.231152, Train Acc: 0.556410 | Val Loss: 0.243369, Val Acc: 0.505155\n",
      "Epoch 2426 - Train Loss: 0.231133, Train Acc: 0.556410 | Val Loss: 0.243350, Val Acc: 0.505155\n",
      "Epoch 2427 - Train Loss: 0.231113, Train Acc: 0.556410 | Val Loss: 0.243331, Val Acc: 0.505155\n",
      "Epoch 2428 - Train Loss: 0.231094, Train Acc: 0.557692 | Val Loss: 0.243312, Val Acc: 0.505155\n",
      "Epoch 2429 - Train Loss: 0.231074, Train Acc: 0.557692 | Val Loss: 0.243294, Val Acc: 0.505155\n",
      "Epoch 2430 - Train Loss: 0.231055, Train Acc: 0.557692 | Val Loss: 0.243275, Val Acc: 0.505155\n",
      "Epoch 2431 - Train Loss: 0.231035, Train Acc: 0.556410 | Val Loss: 0.243256, Val Acc: 0.505155\n",
      "Epoch 2432 - Train Loss: 0.231016, Train Acc: 0.556410 | Val Loss: 0.243237, Val Acc: 0.505155\n",
      "Epoch 2433 - Train Loss: 0.230996, Train Acc: 0.556410 | Val Loss: 0.243218, Val Acc: 0.505155\n",
      "Epoch 2434 - Train Loss: 0.230977, Train Acc: 0.556410 | Val Loss: 0.243199, Val Acc: 0.505155\n",
      "Epoch 2435 - Train Loss: 0.230957, Train Acc: 0.556410 | Val Loss: 0.243180, Val Acc: 0.505155\n",
      "Epoch 2436 - Train Loss: 0.230937, Train Acc: 0.557692 | Val Loss: 0.243161, Val Acc: 0.505155\n",
      "Epoch 2437 - Train Loss: 0.230918, Train Acc: 0.557692 | Val Loss: 0.243143, Val Acc: 0.505155\n",
      "Epoch 2438 - Train Loss: 0.230898, Train Acc: 0.557692 | Val Loss: 0.243124, Val Acc: 0.505155\n",
      "Epoch 2439 - Train Loss: 0.230879, Train Acc: 0.557692 | Val Loss: 0.243105, Val Acc: 0.505155\n",
      "Epoch 2440 - Train Loss: 0.230859, Train Acc: 0.557692 | Val Loss: 0.243086, Val Acc: 0.505155\n",
      "Epoch 2441 - Train Loss: 0.230840, Train Acc: 0.557692 | Val Loss: 0.243067, Val Acc: 0.505155\n",
      "Epoch 2442 - Train Loss: 0.230820, Train Acc: 0.557692 | Val Loss: 0.243048, Val Acc: 0.505155\n",
      "Epoch 2443 - Train Loss: 0.230801, Train Acc: 0.557692 | Val Loss: 0.243029, Val Acc: 0.505155\n",
      "Epoch 2444 - Train Loss: 0.230781, Train Acc: 0.557692 | Val Loss: 0.243011, Val Acc: 0.505155\n",
      "Epoch 2445 - Train Loss: 0.230761, Train Acc: 0.557692 | Val Loss: 0.242992, Val Acc: 0.515464\n",
      "Epoch 2446 - Train Loss: 0.230742, Train Acc: 0.557692 | Val Loss: 0.242973, Val Acc: 0.515464\n",
      "Epoch 2447 - Train Loss: 0.230722, Train Acc: 0.557692 | Val Loss: 0.242954, Val Acc: 0.515464\n",
      "Epoch 2448 - Train Loss: 0.230703, Train Acc: 0.557692 | Val Loss: 0.242935, Val Acc: 0.515464\n",
      "Epoch 2449 - Train Loss: 0.230683, Train Acc: 0.557692 | Val Loss: 0.242916, Val Acc: 0.515464\n",
      "Epoch 2450 - Train Loss: 0.230664, Train Acc: 0.557692 | Val Loss: 0.242897, Val Acc: 0.515464\n",
      "Epoch 2451 - Train Loss: 0.230644, Train Acc: 0.557692 | Val Loss: 0.242879, Val Acc: 0.515464\n",
      "Epoch 2452 - Train Loss: 0.230625, Train Acc: 0.557692 | Val Loss: 0.242860, Val Acc: 0.515464\n",
      "Epoch 2453 - Train Loss: 0.230605, Train Acc: 0.557692 | Val Loss: 0.242841, Val Acc: 0.515464\n",
      "Epoch 2454 - Train Loss: 0.230586, Train Acc: 0.557692 | Val Loss: 0.242822, Val Acc: 0.515464\n",
      "Epoch 2455 - Train Loss: 0.230566, Train Acc: 0.558974 | Val Loss: 0.242803, Val Acc: 0.515464\n",
      "Epoch 2456 - Train Loss: 0.230546, Train Acc: 0.558974 | Val Loss: 0.242784, Val Acc: 0.515464\n",
      "Epoch 2457 - Train Loss: 0.230527, Train Acc: 0.558974 | Val Loss: 0.242765, Val Acc: 0.515464\n",
      "Epoch 2458 - Train Loss: 0.230507, Train Acc: 0.558974 | Val Loss: 0.242746, Val Acc: 0.515464\n",
      "Epoch 2459 - Train Loss: 0.230488, Train Acc: 0.558974 | Val Loss: 0.242728, Val Acc: 0.515464\n",
      "Epoch 2460 - Train Loss: 0.230468, Train Acc: 0.558974 | Val Loss: 0.242709, Val Acc: 0.515464\n",
      "Epoch 2461 - Train Loss: 0.230449, Train Acc: 0.558974 | Val Loss: 0.242690, Val Acc: 0.515464\n",
      "Epoch 2462 - Train Loss: 0.230429, Train Acc: 0.558974 | Val Loss: 0.242671, Val Acc: 0.515464\n",
      "Epoch 2463 - Train Loss: 0.230410, Train Acc: 0.558974 | Val Loss: 0.242652, Val Acc: 0.515464\n",
      "Epoch 2464 - Train Loss: 0.230390, Train Acc: 0.558974 | Val Loss: 0.242634, Val Acc: 0.515464\n",
      "Epoch 2465 - Train Loss: 0.230371, Train Acc: 0.558974 | Val Loss: 0.242615, Val Acc: 0.515464\n",
      "Epoch 2466 - Train Loss: 0.230351, Train Acc: 0.558974 | Val Loss: 0.242596, Val Acc: 0.515464\n",
      "Epoch 2467 - Train Loss: 0.230332, Train Acc: 0.558974 | Val Loss: 0.242577, Val Acc: 0.515464\n",
      "Epoch 2468 - Train Loss: 0.230312, Train Acc: 0.558974 | Val Loss: 0.242558, Val Acc: 0.515464\n",
      "Epoch 2469 - Train Loss: 0.230293, Train Acc: 0.558974 | Val Loss: 0.242540, Val Acc: 0.515464\n",
      "Epoch 2470 - Train Loss: 0.230273, Train Acc: 0.558974 | Val Loss: 0.242521, Val Acc: 0.515464\n",
      "Epoch 2471 - Train Loss: 0.230254, Train Acc: 0.558974 | Val Loss: 0.242502, Val Acc: 0.515464\n",
      "Epoch 2472 - Train Loss: 0.230234, Train Acc: 0.558974 | Val Loss: 0.242483, Val Acc: 0.515464\n",
      "Epoch 2473 - Train Loss: 0.230215, Train Acc: 0.558974 | Val Loss: 0.242464, Val Acc: 0.515464\n",
      "Epoch 2474 - Train Loss: 0.230195, Train Acc: 0.558974 | Val Loss: 0.242446, Val Acc: 0.515464\n",
      "Epoch 2475 - Train Loss: 0.230176, Train Acc: 0.558974 | Val Loss: 0.242427, Val Acc: 0.515464\n",
      "Epoch 2476 - Train Loss: 0.230156, Train Acc: 0.558974 | Val Loss: 0.242408, Val Acc: 0.515464\n",
      "Epoch 2477 - Train Loss: 0.230137, Train Acc: 0.558974 | Val Loss: 0.242389, Val Acc: 0.515464\n",
      "Epoch 2478 - Train Loss: 0.230117, Train Acc: 0.558974 | Val Loss: 0.242371, Val Acc: 0.515464\n",
      "Epoch 2479 - Train Loss: 0.230098, Train Acc: 0.558974 | Val Loss: 0.242352, Val Acc: 0.515464\n",
      "Epoch 2480 - Train Loss: 0.230078, Train Acc: 0.558974 | Val Loss: 0.242333, Val Acc: 0.515464\n",
      "Epoch 2481 - Train Loss: 0.230059, Train Acc: 0.558974 | Val Loss: 0.242314, Val Acc: 0.515464\n",
      "Epoch 2482 - Train Loss: 0.230039, Train Acc: 0.560256 | Val Loss: 0.242296, Val Acc: 0.515464\n",
      "Epoch 2483 - Train Loss: 0.230020, Train Acc: 0.560256 | Val Loss: 0.242277, Val Acc: 0.515464\n",
      "Epoch 2484 - Train Loss: 0.230000, Train Acc: 0.560256 | Val Loss: 0.242258, Val Acc: 0.515464\n",
      "Epoch 2485 - Train Loss: 0.229981, Train Acc: 0.561538 | Val Loss: 0.242239, Val Acc: 0.515464\n",
      "Epoch 2486 - Train Loss: 0.229961, Train Acc: 0.561538 | Val Loss: 0.242221, Val Acc: 0.515464\n",
      "Epoch 2487 - Train Loss: 0.229942, Train Acc: 0.561538 | Val Loss: 0.242202, Val Acc: 0.515464\n",
      "Epoch 2488 - Train Loss: 0.229922, Train Acc: 0.561538 | Val Loss: 0.242183, Val Acc: 0.515464\n",
      "Epoch 2489 - Train Loss: 0.229903, Train Acc: 0.561538 | Val Loss: 0.242164, Val Acc: 0.515464\n",
      "Epoch 2490 - Train Loss: 0.229884, Train Acc: 0.561538 | Val Loss: 0.242146, Val Acc: 0.515464\n",
      "Epoch 2491 - Train Loss: 0.229864, Train Acc: 0.561538 | Val Loss: 0.242127, Val Acc: 0.515464\n",
      "Epoch 2492 - Train Loss: 0.229845, Train Acc: 0.561538 | Val Loss: 0.242108, Val Acc: 0.515464\n",
      "Epoch 2493 - Train Loss: 0.229825, Train Acc: 0.561538 | Val Loss: 0.242089, Val Acc: 0.515464\n",
      "Epoch 2494 - Train Loss: 0.229806, Train Acc: 0.561538 | Val Loss: 0.242070, Val Acc: 0.515464\n",
      "Epoch 2495 - Train Loss: 0.229786, Train Acc: 0.561538 | Val Loss: 0.242052, Val Acc: 0.515464\n",
      "Epoch 2496 - Train Loss: 0.229767, Train Acc: 0.561538 | Val Loss: 0.242033, Val Acc: 0.515464\n",
      "Epoch 2497 - Train Loss: 0.229747, Train Acc: 0.561538 | Val Loss: 0.242014, Val Acc: 0.515464\n",
      "Epoch 2498 - Train Loss: 0.229728, Train Acc: 0.561538 | Val Loss: 0.241995, Val Acc: 0.515464\n",
      "Epoch 2499 - Train Loss: 0.229708, Train Acc: 0.561538 | Val Loss: 0.241976, Val Acc: 0.515464\n",
      "Epoch 2500 - Train Loss: 0.229689, Train Acc: 0.561538 | Val Loss: 0.241957, Val Acc: 0.515464\n",
      "Epoch 2501 - Train Loss: 0.229669, Train Acc: 0.561538 | Val Loss: 0.241938, Val Acc: 0.515464\n",
      "Epoch 2502 - Train Loss: 0.229650, Train Acc: 0.561538 | Val Loss: 0.241920, Val Acc: 0.515464\n",
      "Epoch 2503 - Train Loss: 0.229630, Train Acc: 0.562821 | Val Loss: 0.241901, Val Acc: 0.515464\n",
      "Epoch 2504 - Train Loss: 0.229611, Train Acc: 0.562821 | Val Loss: 0.241882, Val Acc: 0.515464\n",
      "Epoch 2505 - Train Loss: 0.229591, Train Acc: 0.562821 | Val Loss: 0.241863, Val Acc: 0.515464\n",
      "Epoch 2506 - Train Loss: 0.229572, Train Acc: 0.562821 | Val Loss: 0.241844, Val Acc: 0.515464\n",
      "Epoch 2507 - Train Loss: 0.229552, Train Acc: 0.562821 | Val Loss: 0.241825, Val Acc: 0.515464\n",
      "Epoch 2508 - Train Loss: 0.229533, Train Acc: 0.562821 | Val Loss: 0.241806, Val Acc: 0.515464\n",
      "Epoch 2509 - Train Loss: 0.229513, Train Acc: 0.562821 | Val Loss: 0.241788, Val Acc: 0.515464\n",
      "Epoch 2510 - Train Loss: 0.229494, Train Acc: 0.562821 | Val Loss: 0.241769, Val Acc: 0.515464\n",
      "Epoch 2511 - Train Loss: 0.229474, Train Acc: 0.562821 | Val Loss: 0.241750, Val Acc: 0.515464\n",
      "Epoch 2512 - Train Loss: 0.229455, Train Acc: 0.562821 | Val Loss: 0.241731, Val Acc: 0.515464\n",
      "Epoch 2513 - Train Loss: 0.229435, Train Acc: 0.562821 | Val Loss: 0.241712, Val Acc: 0.515464\n",
      "Epoch 2514 - Train Loss: 0.229416, Train Acc: 0.562821 | Val Loss: 0.241693, Val Acc: 0.515464\n",
      "Epoch 2515 - Train Loss: 0.229397, Train Acc: 0.562821 | Val Loss: 0.241675, Val Acc: 0.515464\n",
      "Epoch 2516 - Train Loss: 0.229377, Train Acc: 0.562821 | Val Loss: 0.241656, Val Acc: 0.515464\n",
      "Epoch 2517 - Train Loss: 0.229358, Train Acc: 0.562821 | Val Loss: 0.241637, Val Acc: 0.515464\n",
      "Epoch 2518 - Train Loss: 0.229338, Train Acc: 0.562821 | Val Loss: 0.241618, Val Acc: 0.515464\n",
      "Epoch 2519 - Train Loss: 0.229319, Train Acc: 0.562821 | Val Loss: 0.241599, Val Acc: 0.515464\n",
      "Epoch 2520 - Train Loss: 0.229299, Train Acc: 0.562821 | Val Loss: 0.241580, Val Acc: 0.515464\n",
      "Epoch 2521 - Train Loss: 0.229280, Train Acc: 0.562821 | Val Loss: 0.241562, Val Acc: 0.515464\n",
      "Epoch 2522 - Train Loss: 0.229260, Train Acc: 0.562821 | Val Loss: 0.241543, Val Acc: 0.515464\n",
      "Epoch 2523 - Train Loss: 0.229241, Train Acc: 0.562821 | Val Loss: 0.241524, Val Acc: 0.515464\n",
      "Epoch 2524 - Train Loss: 0.229221, Train Acc: 0.562821 | Val Loss: 0.241505, Val Acc: 0.515464\n",
      "Epoch 2525 - Train Loss: 0.229202, Train Acc: 0.562821 | Val Loss: 0.241486, Val Acc: 0.515464\n",
      "Epoch 2526 - Train Loss: 0.229182, Train Acc: 0.562821 | Val Loss: 0.241467, Val Acc: 0.515464\n",
      "Epoch 2527 - Train Loss: 0.229163, Train Acc: 0.562821 | Val Loss: 0.241449, Val Acc: 0.515464\n",
      "Epoch 2528 - Train Loss: 0.229143, Train Acc: 0.562821 | Val Loss: 0.241430, Val Acc: 0.515464\n",
      "Epoch 2529 - Train Loss: 0.229124, Train Acc: 0.562821 | Val Loss: 0.241411, Val Acc: 0.515464\n",
      "Epoch 2530 - Train Loss: 0.229105, Train Acc: 0.562821 | Val Loss: 0.241392, Val Acc: 0.515464\n",
      "Epoch 2531 - Train Loss: 0.229085, Train Acc: 0.562821 | Val Loss: 0.241373, Val Acc: 0.515464\n",
      "Epoch 2532 - Train Loss: 0.229066, Train Acc: 0.562821 | Val Loss: 0.241354, Val Acc: 0.515464\n",
      "Epoch 2533 - Train Loss: 0.229046, Train Acc: 0.562821 | Val Loss: 0.241335, Val Acc: 0.515464\n",
      "Epoch 2534 - Train Loss: 0.229027, Train Acc: 0.562821 | Val Loss: 0.241317, Val Acc: 0.515464\n",
      "Epoch 2535 - Train Loss: 0.229007, Train Acc: 0.562821 | Val Loss: 0.241298, Val Acc: 0.515464\n",
      "Epoch 2536 - Train Loss: 0.228988, Train Acc: 0.562821 | Val Loss: 0.241279, Val Acc: 0.515464\n",
      "Epoch 2537 - Train Loss: 0.228968, Train Acc: 0.562821 | Val Loss: 0.241260, Val Acc: 0.515464\n",
      "Epoch 2538 - Train Loss: 0.228949, Train Acc: 0.562821 | Val Loss: 0.241241, Val Acc: 0.515464\n",
      "Epoch 2539 - Train Loss: 0.228929, Train Acc: 0.562821 | Val Loss: 0.241222, Val Acc: 0.515464\n",
      "Epoch 2540 - Train Loss: 0.228910, Train Acc: 0.562821 | Val Loss: 0.241204, Val Acc: 0.515464\n",
      "Epoch 2541 - Train Loss: 0.228891, Train Acc: 0.562821 | Val Loss: 0.241185, Val Acc: 0.515464\n",
      "Epoch 2542 - Train Loss: 0.228871, Train Acc: 0.562821 | Val Loss: 0.241166, Val Acc: 0.515464\n",
      "Epoch 2543 - Train Loss: 0.228852, Train Acc: 0.562821 | Val Loss: 0.241147, Val Acc: 0.515464\n",
      "Epoch 2544 - Train Loss: 0.228832, Train Acc: 0.562821 | Val Loss: 0.241128, Val Acc: 0.515464\n",
      "Epoch 2545 - Train Loss: 0.228813, Train Acc: 0.562821 | Val Loss: 0.241109, Val Acc: 0.515464\n",
      "Epoch 2546 - Train Loss: 0.228793, Train Acc: 0.562821 | Val Loss: 0.241090, Val Acc: 0.515464\n",
      "Epoch 2547 - Train Loss: 0.228774, Train Acc: 0.562821 | Val Loss: 0.241072, Val Acc: 0.515464\n",
      "Epoch 2548 - Train Loss: 0.228754, Train Acc: 0.564103 | Val Loss: 0.241053, Val Acc: 0.515464\n",
      "Epoch 2549 - Train Loss: 0.228735, Train Acc: 0.565385 | Val Loss: 0.241034, Val Acc: 0.515464\n",
      "Epoch 2550 - Train Loss: 0.228716, Train Acc: 0.565385 | Val Loss: 0.241015, Val Acc: 0.515464\n",
      "Epoch 2551 - Train Loss: 0.228696, Train Acc: 0.565385 | Val Loss: 0.240996, Val Acc: 0.515464\n",
      "Epoch 2552 - Train Loss: 0.228677, Train Acc: 0.565385 | Val Loss: 0.240977, Val Acc: 0.515464\n",
      "Epoch 2553 - Train Loss: 0.228657, Train Acc: 0.565385 | Val Loss: 0.240959, Val Acc: 0.515464\n",
      "Epoch 2554 - Train Loss: 0.228638, Train Acc: 0.565385 | Val Loss: 0.240940, Val Acc: 0.515464\n",
      "Epoch 2555 - Train Loss: 0.228618, Train Acc: 0.565385 | Val Loss: 0.240921, Val Acc: 0.515464\n",
      "Epoch 2556 - Train Loss: 0.228599, Train Acc: 0.565385 | Val Loss: 0.240902, Val Acc: 0.515464\n",
      "Epoch 2557 - Train Loss: 0.228579, Train Acc: 0.565385 | Val Loss: 0.240883, Val Acc: 0.515464\n",
      "Epoch 2558 - Train Loss: 0.228560, Train Acc: 0.565385 | Val Loss: 0.240864, Val Acc: 0.515464\n",
      "Epoch 2559 - Train Loss: 0.228541, Train Acc: 0.565385 | Val Loss: 0.240845, Val Acc: 0.515464\n",
      "Epoch 2560 - Train Loss: 0.228521, Train Acc: 0.565385 | Val Loss: 0.240827, Val Acc: 0.515464\n",
      "Epoch 2561 - Train Loss: 0.228502, Train Acc: 0.565385 | Val Loss: 0.240808, Val Acc: 0.515464\n",
      "Epoch 2562 - Train Loss: 0.228482, Train Acc: 0.565385 | Val Loss: 0.240789, Val Acc: 0.515464\n",
      "Epoch 2563 - Train Loss: 0.228463, Train Acc: 0.565385 | Val Loss: 0.240770, Val Acc: 0.515464\n",
      "Epoch 2564 - Train Loss: 0.228443, Train Acc: 0.565385 | Val Loss: 0.240751, Val Acc: 0.515464\n",
      "Epoch 2565 - Train Loss: 0.228424, Train Acc: 0.565385 | Val Loss: 0.240732, Val Acc: 0.515464\n",
      "Epoch 2566 - Train Loss: 0.228405, Train Acc: 0.565385 | Val Loss: 0.240713, Val Acc: 0.515464\n",
      "Epoch 2567 - Train Loss: 0.228385, Train Acc: 0.565385 | Val Loss: 0.240695, Val Acc: 0.515464\n",
      "Epoch 2568 - Train Loss: 0.228366, Train Acc: 0.565385 | Val Loss: 0.240676, Val Acc: 0.515464\n",
      "Epoch 2569 - Train Loss: 0.228346, Train Acc: 0.565385 | Val Loss: 0.240657, Val Acc: 0.515464\n",
      "Epoch 2570 - Train Loss: 0.228327, Train Acc: 0.565385 | Val Loss: 0.240638, Val Acc: 0.515464\n",
      "Epoch 2571 - Train Loss: 0.228307, Train Acc: 0.565385 | Val Loss: 0.240619, Val Acc: 0.515464\n",
      "Epoch 2572 - Train Loss: 0.228288, Train Acc: 0.565385 | Val Loss: 0.240600, Val Acc: 0.515464\n",
      "Epoch 2573 - Train Loss: 0.228269, Train Acc: 0.565385 | Val Loss: 0.240581, Val Acc: 0.515464\n",
      "Epoch 2574 - Train Loss: 0.228249, Train Acc: 0.565385 | Val Loss: 0.240563, Val Acc: 0.515464\n",
      "Epoch 2575 - Train Loss: 0.228230, Train Acc: 0.565385 | Val Loss: 0.240544, Val Acc: 0.515464\n",
      "Epoch 2576 - Train Loss: 0.228210, Train Acc: 0.565385 | Val Loss: 0.240525, Val Acc: 0.515464\n",
      "Epoch 2577 - Train Loss: 0.228191, Train Acc: 0.565385 | Val Loss: 0.240506, Val Acc: 0.515464\n",
      "Epoch 2578 - Train Loss: 0.228171, Train Acc: 0.566667 | Val Loss: 0.240487, Val Acc: 0.515464\n",
      "Epoch 2579 - Train Loss: 0.228152, Train Acc: 0.566667 | Val Loss: 0.240468, Val Acc: 0.515464\n",
      "Epoch 2580 - Train Loss: 0.228133, Train Acc: 0.566667 | Val Loss: 0.240449, Val Acc: 0.515464\n",
      "Epoch 2581 - Train Loss: 0.228113, Train Acc: 0.566667 | Val Loss: 0.240431, Val Acc: 0.515464\n",
      "Epoch 2582 - Train Loss: 0.228094, Train Acc: 0.566667 | Val Loss: 0.240412, Val Acc: 0.515464\n",
      "Epoch 2583 - Train Loss: 0.228074, Train Acc: 0.566667 | Val Loss: 0.240393, Val Acc: 0.515464\n",
      "Epoch 2584 - Train Loss: 0.228055, Train Acc: 0.566667 | Val Loss: 0.240374, Val Acc: 0.515464\n",
      "Epoch 2585 - Train Loss: 0.228035, Train Acc: 0.566667 | Val Loss: 0.240355, Val Acc: 0.515464\n",
      "Epoch 2586 - Train Loss: 0.228016, Train Acc: 0.566667 | Val Loss: 0.240336, Val Acc: 0.515464\n",
      "Epoch 2587 - Train Loss: 0.227997, Train Acc: 0.566667 | Val Loss: 0.240317, Val Acc: 0.515464\n",
      "Epoch 2588 - Train Loss: 0.227977, Train Acc: 0.566667 | Val Loss: 0.240299, Val Acc: 0.515464\n",
      "Epoch 2589 - Train Loss: 0.227958, Train Acc: 0.567949 | Val Loss: 0.240280, Val Acc: 0.515464\n",
      "Epoch 2590 - Train Loss: 0.227938, Train Acc: 0.567949 | Val Loss: 0.240261, Val Acc: 0.515464\n",
      "Epoch 2591 - Train Loss: 0.227919, Train Acc: 0.567949 | Val Loss: 0.240242, Val Acc: 0.515464\n",
      "Epoch 2592 - Train Loss: 0.227900, Train Acc: 0.567949 | Val Loss: 0.240223, Val Acc: 0.515464\n",
      "Epoch 2593 - Train Loss: 0.227880, Train Acc: 0.567949 | Val Loss: 0.240204, Val Acc: 0.515464\n",
      "Epoch 2594 - Train Loss: 0.227861, Train Acc: 0.567949 | Val Loss: 0.240185, Val Acc: 0.515464\n",
      "Epoch 2595 - Train Loss: 0.227841, Train Acc: 0.567949 | Val Loss: 0.240167, Val Acc: 0.525773\n",
      "Epoch 2596 - Train Loss: 0.227822, Train Acc: 0.567949 | Val Loss: 0.240148, Val Acc: 0.525773\n",
      "Epoch 2597 - Train Loss: 0.227803, Train Acc: 0.567949 | Val Loss: 0.240129, Val Acc: 0.525773\n",
      "Epoch 2598 - Train Loss: 0.227783, Train Acc: 0.567949 | Val Loss: 0.240110, Val Acc: 0.525773\n",
      "Epoch 2599 - Train Loss: 0.227764, Train Acc: 0.567949 | Val Loss: 0.240091, Val Acc: 0.525773\n",
      "Epoch 2600 - Train Loss: 0.227744, Train Acc: 0.567949 | Val Loss: 0.240072, Val Acc: 0.525773\n",
      "Epoch 2601 - Train Loss: 0.227725, Train Acc: 0.567949 | Val Loss: 0.240053, Val Acc: 0.525773\n",
      "Epoch 2602 - Train Loss: 0.227706, Train Acc: 0.567949 | Val Loss: 0.240034, Val Acc: 0.525773\n",
      "Epoch 2603 - Train Loss: 0.227686, Train Acc: 0.567949 | Val Loss: 0.240016, Val Acc: 0.525773\n",
      "Epoch 2604 - Train Loss: 0.227667, Train Acc: 0.567949 | Val Loss: 0.239997, Val Acc: 0.525773\n",
      "Epoch 2605 - Train Loss: 0.227647, Train Acc: 0.567949 | Val Loss: 0.239978, Val Acc: 0.525773\n",
      "Epoch 2606 - Train Loss: 0.227628, Train Acc: 0.567949 | Val Loss: 0.239959, Val Acc: 0.525773\n",
      "Epoch 2607 - Train Loss: 0.227609, Train Acc: 0.567949 | Val Loss: 0.239940, Val Acc: 0.525773\n",
      "Epoch 2608 - Train Loss: 0.227589, Train Acc: 0.567949 | Val Loss: 0.239922, Val Acc: 0.525773\n",
      "Epoch 2609 - Train Loss: 0.227570, Train Acc: 0.567949 | Val Loss: 0.239903, Val Acc: 0.525773\n",
      "Epoch 2610 - Train Loss: 0.227550, Train Acc: 0.567949 | Val Loss: 0.239884, Val Acc: 0.525773\n",
      "Epoch 2611 - Train Loss: 0.227531, Train Acc: 0.567949 | Val Loss: 0.239865, Val Acc: 0.525773\n",
      "Epoch 2612 - Train Loss: 0.227512, Train Acc: 0.567949 | Val Loss: 0.239847, Val Acc: 0.525773\n",
      "Epoch 2613 - Train Loss: 0.227492, Train Acc: 0.567949 | Val Loss: 0.239828, Val Acc: 0.525773\n",
      "Epoch 2614 - Train Loss: 0.227473, Train Acc: 0.567949 | Val Loss: 0.239809, Val Acc: 0.525773\n",
      "Epoch 2615 - Train Loss: 0.227454, Train Acc: 0.567949 | Val Loss: 0.239791, Val Acc: 0.525773\n",
      "Epoch 2616 - Train Loss: 0.227434, Train Acc: 0.569231 | Val Loss: 0.239772, Val Acc: 0.525773\n",
      "Epoch 2617 - Train Loss: 0.227415, Train Acc: 0.569231 | Val Loss: 0.239753, Val Acc: 0.525773\n",
      "Epoch 2618 - Train Loss: 0.227396, Train Acc: 0.569231 | Val Loss: 0.239734, Val Acc: 0.525773\n",
      "Epoch 2619 - Train Loss: 0.227376, Train Acc: 0.569231 | Val Loss: 0.239716, Val Acc: 0.525773\n",
      "Epoch 2620 - Train Loss: 0.227357, Train Acc: 0.569231 | Val Loss: 0.239697, Val Acc: 0.525773\n",
      "Epoch 2621 - Train Loss: 0.227337, Train Acc: 0.569231 | Val Loss: 0.239678, Val Acc: 0.525773\n",
      "Epoch 2622 - Train Loss: 0.227318, Train Acc: 0.569231 | Val Loss: 0.239659, Val Acc: 0.525773\n",
      "Epoch 2623 - Train Loss: 0.227299, Train Acc: 0.569231 | Val Loss: 0.239641, Val Acc: 0.525773\n",
      "Epoch 2624 - Train Loss: 0.227279, Train Acc: 0.569231 | Val Loss: 0.239622, Val Acc: 0.525773\n",
      "Epoch 2625 - Train Loss: 0.227260, Train Acc: 0.569231 | Val Loss: 0.239603, Val Acc: 0.525773\n",
      "Epoch 2626 - Train Loss: 0.227241, Train Acc: 0.569231 | Val Loss: 0.239584, Val Acc: 0.525773\n",
      "Epoch 2627 - Train Loss: 0.227221, Train Acc: 0.570513 | Val Loss: 0.239566, Val Acc: 0.525773\n",
      "Epoch 2628 - Train Loss: 0.227202, Train Acc: 0.570513 | Val Loss: 0.239547, Val Acc: 0.525773\n",
      "Epoch 2629 - Train Loss: 0.227183, Train Acc: 0.570513 | Val Loss: 0.239528, Val Acc: 0.525773\n",
      "Epoch 2630 - Train Loss: 0.227163, Train Acc: 0.570513 | Val Loss: 0.239509, Val Acc: 0.525773\n",
      "Epoch 2631 - Train Loss: 0.227144, Train Acc: 0.570513 | Val Loss: 0.239491, Val Acc: 0.525773\n",
      "Epoch 2632 - Train Loss: 0.227125, Train Acc: 0.570513 | Val Loss: 0.239472, Val Acc: 0.525773\n",
      "Epoch 2633 - Train Loss: 0.227105, Train Acc: 0.570513 | Val Loss: 0.239453, Val Acc: 0.525773\n",
      "Epoch 2634 - Train Loss: 0.227086, Train Acc: 0.570513 | Val Loss: 0.239434, Val Acc: 0.525773\n",
      "Epoch 2635 - Train Loss: 0.227066, Train Acc: 0.570513 | Val Loss: 0.239416, Val Acc: 0.525773\n",
      "Epoch 2636 - Train Loss: 0.227047, Train Acc: 0.570513 | Val Loss: 0.239397, Val Acc: 0.525773\n",
      "Epoch 2637 - Train Loss: 0.227028, Train Acc: 0.570513 | Val Loss: 0.239378, Val Acc: 0.525773\n",
      "Epoch 2638 - Train Loss: 0.227008, Train Acc: 0.570513 | Val Loss: 0.239359, Val Acc: 0.525773\n",
      "Epoch 2639 - Train Loss: 0.226989, Train Acc: 0.570513 | Val Loss: 0.239341, Val Acc: 0.525773\n",
      "Epoch 2640 - Train Loss: 0.226970, Train Acc: 0.570513 | Val Loss: 0.239322, Val Acc: 0.525773\n",
      "Epoch 2641 - Train Loss: 0.226950, Train Acc: 0.570513 | Val Loss: 0.239303, Val Acc: 0.525773\n",
      "Epoch 2642 - Train Loss: 0.226931, Train Acc: 0.570513 | Val Loss: 0.239284, Val Acc: 0.525773\n",
      "Epoch 2643 - Train Loss: 0.226912, Train Acc: 0.570513 | Val Loss: 0.239266, Val Acc: 0.525773\n",
      "Epoch 2644 - Train Loss: 0.226892, Train Acc: 0.570513 | Val Loss: 0.239247, Val Acc: 0.525773\n",
      "Epoch 2645 - Train Loss: 0.226873, Train Acc: 0.570513 | Val Loss: 0.239228, Val Acc: 0.525773\n",
      "Epoch 2646 - Train Loss: 0.226854, Train Acc: 0.570513 | Val Loss: 0.239209, Val Acc: 0.525773\n",
      "Epoch 2647 - Train Loss: 0.226834, Train Acc: 0.570513 | Val Loss: 0.239191, Val Acc: 0.525773\n",
      "Epoch 2648 - Train Loss: 0.226815, Train Acc: 0.570513 | Val Loss: 0.239172, Val Acc: 0.525773\n",
      "Epoch 2649 - Train Loss: 0.226796, Train Acc: 0.570513 | Val Loss: 0.239153, Val Acc: 0.525773\n",
      "Epoch 2650 - Train Loss: 0.226776, Train Acc: 0.571795 | Val Loss: 0.239134, Val Acc: 0.525773\n",
      "Epoch 2651 - Train Loss: 0.226757, Train Acc: 0.571795 | Val Loss: 0.239116, Val Acc: 0.525773\n",
      "Epoch 2652 - Train Loss: 0.226738, Train Acc: 0.571795 | Val Loss: 0.239097, Val Acc: 0.525773\n",
      "Epoch 2653 - Train Loss: 0.226718, Train Acc: 0.571795 | Val Loss: 0.239078, Val Acc: 0.525773\n",
      "Epoch 2654 - Train Loss: 0.226699, Train Acc: 0.571795 | Val Loss: 0.239060, Val Acc: 0.525773\n",
      "Epoch 2655 - Train Loss: 0.226680, Train Acc: 0.571795 | Val Loss: 0.239041, Val Acc: 0.525773\n",
      "Epoch 2656 - Train Loss: 0.226661, Train Acc: 0.571795 | Val Loss: 0.239022, Val Acc: 0.525773\n",
      "Epoch 2657 - Train Loss: 0.226641, Train Acc: 0.573077 | Val Loss: 0.239003, Val Acc: 0.525773\n",
      "Epoch 2658 - Train Loss: 0.226622, Train Acc: 0.573077 | Val Loss: 0.238985, Val Acc: 0.515464\n",
      "Epoch 2659 - Train Loss: 0.226603, Train Acc: 0.573077 | Val Loss: 0.238966, Val Acc: 0.515464\n",
      "Epoch 2660 - Train Loss: 0.226583, Train Acc: 0.573077 | Val Loss: 0.238947, Val Acc: 0.515464\n",
      "Epoch 2661 - Train Loss: 0.226564, Train Acc: 0.573077 | Val Loss: 0.238928, Val Acc: 0.515464\n",
      "Epoch 2662 - Train Loss: 0.226545, Train Acc: 0.573077 | Val Loss: 0.238910, Val Acc: 0.515464\n",
      "Epoch 2663 - Train Loss: 0.226525, Train Acc: 0.573077 | Val Loss: 0.238891, Val Acc: 0.515464\n",
      "Epoch 2664 - Train Loss: 0.226506, Train Acc: 0.573077 | Val Loss: 0.238872, Val Acc: 0.515464\n",
      "Epoch 2665 - Train Loss: 0.226487, Train Acc: 0.573077 | Val Loss: 0.238854, Val Acc: 0.515464\n",
      "Epoch 2666 - Train Loss: 0.226467, Train Acc: 0.573077 | Val Loss: 0.238835, Val Acc: 0.515464\n",
      "Epoch 2667 - Train Loss: 0.226448, Train Acc: 0.573077 | Val Loss: 0.238816, Val Acc: 0.515464\n",
      "Epoch 2668 - Train Loss: 0.226429, Train Acc: 0.573077 | Val Loss: 0.238797, Val Acc: 0.515464\n",
      "Epoch 2669 - Train Loss: 0.226410, Train Acc: 0.573077 | Val Loss: 0.238779, Val Acc: 0.515464\n",
      "Epoch 2670 - Train Loss: 0.226390, Train Acc: 0.573077 | Val Loss: 0.238760, Val Acc: 0.515464\n",
      "Epoch 2671 - Train Loss: 0.226371, Train Acc: 0.573077 | Val Loss: 0.238741, Val Acc: 0.515464\n",
      "Epoch 2672 - Train Loss: 0.226352, Train Acc: 0.573077 | Val Loss: 0.238722, Val Acc: 0.515464\n",
      "Epoch 2673 - Train Loss: 0.226332, Train Acc: 0.573077 | Val Loss: 0.238703, Val Acc: 0.515464\n",
      "Epoch 2674 - Train Loss: 0.226313, Train Acc: 0.573077 | Val Loss: 0.238685, Val Acc: 0.515464\n",
      "Epoch 2675 - Train Loss: 0.226294, Train Acc: 0.573077 | Val Loss: 0.238666, Val Acc: 0.515464\n",
      "Epoch 2676 - Train Loss: 0.226274, Train Acc: 0.573077 | Val Loss: 0.238647, Val Acc: 0.515464\n",
      "Epoch 2677 - Train Loss: 0.226255, Train Acc: 0.573077 | Val Loss: 0.238628, Val Acc: 0.515464\n",
      "Epoch 2678 - Train Loss: 0.226236, Train Acc: 0.573077 | Val Loss: 0.238609, Val Acc: 0.515464\n",
      "Epoch 2679 - Train Loss: 0.226216, Train Acc: 0.573077 | Val Loss: 0.238591, Val Acc: 0.515464\n",
      "Epoch 2680 - Train Loss: 0.226197, Train Acc: 0.573077 | Val Loss: 0.238572, Val Acc: 0.515464\n",
      "Epoch 2681 - Train Loss: 0.226178, Train Acc: 0.573077 | Val Loss: 0.238553, Val Acc: 0.515464\n",
      "Epoch 2682 - Train Loss: 0.226159, Train Acc: 0.573077 | Val Loss: 0.238534, Val Acc: 0.515464\n",
      "Epoch 2683 - Train Loss: 0.226139, Train Acc: 0.574359 | Val Loss: 0.238515, Val Acc: 0.515464\n",
      "Epoch 2684 - Train Loss: 0.226120, Train Acc: 0.574359 | Val Loss: 0.238497, Val Acc: 0.515464\n",
      "Epoch 2685 - Train Loss: 0.226101, Train Acc: 0.574359 | Val Loss: 0.238478, Val Acc: 0.515464\n",
      "Epoch 2686 - Train Loss: 0.226081, Train Acc: 0.574359 | Val Loss: 0.238459, Val Acc: 0.515464\n",
      "Epoch 2687 - Train Loss: 0.226062, Train Acc: 0.574359 | Val Loss: 0.238440, Val Acc: 0.515464\n",
      "Epoch 2688 - Train Loss: 0.226043, Train Acc: 0.574359 | Val Loss: 0.238421, Val Acc: 0.515464\n",
      "Epoch 2689 - Train Loss: 0.226023, Train Acc: 0.574359 | Val Loss: 0.238403, Val Acc: 0.515464\n",
      "Epoch 2690 - Train Loss: 0.226004, Train Acc: 0.574359 | Val Loss: 0.238384, Val Acc: 0.515464\n",
      "Epoch 2691 - Train Loss: 0.225985, Train Acc: 0.574359 | Val Loss: 0.238365, Val Acc: 0.515464\n",
      "Epoch 2692 - Train Loss: 0.225966, Train Acc: 0.574359 | Val Loss: 0.238346, Val Acc: 0.515464\n",
      "Epoch 2693 - Train Loss: 0.225946, Train Acc: 0.574359 | Val Loss: 0.238328, Val Acc: 0.515464\n",
      "Epoch 2694 - Train Loss: 0.225927, Train Acc: 0.574359 | Val Loss: 0.238309, Val Acc: 0.515464\n",
      "Epoch 2695 - Train Loss: 0.225908, Train Acc: 0.574359 | Val Loss: 0.238290, Val Acc: 0.515464\n",
      "Epoch 2696 - Train Loss: 0.225889, Train Acc: 0.574359 | Val Loss: 0.238271, Val Acc: 0.515464\n",
      "Epoch 2697 - Train Loss: 0.225869, Train Acc: 0.574359 | Val Loss: 0.238253, Val Acc: 0.515464\n",
      "Epoch 2698 - Train Loss: 0.225850, Train Acc: 0.574359 | Val Loss: 0.238234, Val Acc: 0.515464\n",
      "Epoch 2699 - Train Loss: 0.225831, Train Acc: 0.574359 | Val Loss: 0.238215, Val Acc: 0.515464\n",
      "Epoch 2700 - Train Loss: 0.225811, Train Acc: 0.574359 | Val Loss: 0.238196, Val Acc: 0.515464\n",
      "Epoch 2701 - Train Loss: 0.225792, Train Acc: 0.574359 | Val Loss: 0.238178, Val Acc: 0.515464\n",
      "Epoch 2702 - Train Loss: 0.225773, Train Acc: 0.574359 | Val Loss: 0.238159, Val Acc: 0.515464\n",
      "Epoch 2703 - Train Loss: 0.225754, Train Acc: 0.574359 | Val Loss: 0.238140, Val Acc: 0.515464\n",
      "Epoch 2704 - Train Loss: 0.225734, Train Acc: 0.575641 | Val Loss: 0.238121, Val Acc: 0.515464\n",
      "Epoch 2705 - Train Loss: 0.225715, Train Acc: 0.575641 | Val Loss: 0.238102, Val Acc: 0.515464\n",
      "Epoch 2706 - Train Loss: 0.225696, Train Acc: 0.575641 | Val Loss: 0.238084, Val Acc: 0.515464\n",
      "Epoch 2707 - Train Loss: 0.225677, Train Acc: 0.575641 | Val Loss: 0.238065, Val Acc: 0.515464\n",
      "Epoch 2708 - Train Loss: 0.225657, Train Acc: 0.575641 | Val Loss: 0.238046, Val Acc: 0.515464\n",
      "Epoch 2709 - Train Loss: 0.225638, Train Acc: 0.575641 | Val Loss: 0.238027, Val Acc: 0.515464\n",
      "Epoch 2710 - Train Loss: 0.225619, Train Acc: 0.575641 | Val Loss: 0.238009, Val Acc: 0.515464\n",
      "Epoch 2711 - Train Loss: 0.225600, Train Acc: 0.575641 | Val Loss: 0.237990, Val Acc: 0.515464\n",
      "Epoch 2712 - Train Loss: 0.225580, Train Acc: 0.575641 | Val Loss: 0.237971, Val Acc: 0.515464\n",
      "Epoch 2713 - Train Loss: 0.225561, Train Acc: 0.575641 | Val Loss: 0.237953, Val Acc: 0.515464\n",
      "Epoch 2714 - Train Loss: 0.225542, Train Acc: 0.575641 | Val Loss: 0.237934, Val Acc: 0.515464\n",
      "Epoch 2715 - Train Loss: 0.225523, Train Acc: 0.575641 | Val Loss: 0.237915, Val Acc: 0.515464\n",
      "Epoch 2716 - Train Loss: 0.225503, Train Acc: 0.575641 | Val Loss: 0.237896, Val Acc: 0.515464\n",
      "Epoch 2717 - Train Loss: 0.225484, Train Acc: 0.575641 | Val Loss: 0.237878, Val Acc: 0.515464\n",
      "Epoch 2718 - Train Loss: 0.225465, Train Acc: 0.575641 | Val Loss: 0.237859, Val Acc: 0.515464\n",
      "Epoch 2719 - Train Loss: 0.225446, Train Acc: 0.575641 | Val Loss: 0.237840, Val Acc: 0.515464\n",
      "Epoch 2720 - Train Loss: 0.225426, Train Acc: 0.575641 | Val Loss: 0.237821, Val Acc: 0.515464\n",
      "Epoch 2721 - Train Loss: 0.225407, Train Acc: 0.575641 | Val Loss: 0.237803, Val Acc: 0.515464\n",
      "Epoch 2722 - Train Loss: 0.225388, Train Acc: 0.575641 | Val Loss: 0.237784, Val Acc: 0.515464\n",
      "Epoch 2723 - Train Loss: 0.225369, Train Acc: 0.575641 | Val Loss: 0.237765, Val Acc: 0.515464\n",
      "Epoch 2724 - Train Loss: 0.225349, Train Acc: 0.575641 | Val Loss: 0.237747, Val Acc: 0.515464\n",
      "Epoch 2725 - Train Loss: 0.225330, Train Acc: 0.575641 | Val Loss: 0.237728, Val Acc: 0.515464\n",
      "Epoch 2726 - Train Loss: 0.225311, Train Acc: 0.575641 | Val Loss: 0.237709, Val Acc: 0.515464\n",
      "Epoch 2727 - Train Loss: 0.225292, Train Acc: 0.575641 | Val Loss: 0.237690, Val Acc: 0.515464\n",
      "Epoch 2728 - Train Loss: 0.225272, Train Acc: 0.575641 | Val Loss: 0.237672, Val Acc: 0.515464\n",
      "Epoch 2729 - Train Loss: 0.225253, Train Acc: 0.575641 | Val Loss: 0.237653, Val Acc: 0.515464\n",
      "Epoch 2730 - Train Loss: 0.225234, Train Acc: 0.575641 | Val Loss: 0.237634, Val Acc: 0.515464\n",
      "Epoch 2731 - Train Loss: 0.225215, Train Acc: 0.575641 | Val Loss: 0.237615, Val Acc: 0.515464\n",
      "Epoch 2732 - Train Loss: 0.225196, Train Acc: 0.575641 | Val Loss: 0.237597, Val Acc: 0.515464\n",
      "Epoch 2733 - Train Loss: 0.225176, Train Acc: 0.575641 | Val Loss: 0.237578, Val Acc: 0.515464\n",
      "Epoch 2734 - Train Loss: 0.225157, Train Acc: 0.575641 | Val Loss: 0.237559, Val Acc: 0.515464\n",
      "Epoch 2735 - Train Loss: 0.225138, Train Acc: 0.575641 | Val Loss: 0.237541, Val Acc: 0.515464\n",
      "Epoch 2736 - Train Loss: 0.225119, Train Acc: 0.575641 | Val Loss: 0.237522, Val Acc: 0.515464\n",
      "Epoch 2737 - Train Loss: 0.225099, Train Acc: 0.575641 | Val Loss: 0.237503, Val Acc: 0.515464\n",
      "Epoch 2738 - Train Loss: 0.225080, Train Acc: 0.575641 | Val Loss: 0.237484, Val Acc: 0.515464\n",
      "Epoch 2739 - Train Loss: 0.225061, Train Acc: 0.575641 | Val Loss: 0.237466, Val Acc: 0.515464\n",
      "Epoch 2740 - Train Loss: 0.225042, Train Acc: 0.575641 | Val Loss: 0.237447, Val Acc: 0.515464\n",
      "Epoch 2741 - Train Loss: 0.225023, Train Acc: 0.575641 | Val Loss: 0.237428, Val Acc: 0.515464\n",
      "Epoch 2742 - Train Loss: 0.225003, Train Acc: 0.575641 | Val Loss: 0.237410, Val Acc: 0.515464\n",
      "Epoch 2743 - Train Loss: 0.224984, Train Acc: 0.575641 | Val Loss: 0.237391, Val Acc: 0.515464\n",
      "Epoch 2744 - Train Loss: 0.224965, Train Acc: 0.575641 | Val Loss: 0.237372, Val Acc: 0.515464\n",
      "Epoch 2745 - Train Loss: 0.224946, Train Acc: 0.575641 | Val Loss: 0.237354, Val Acc: 0.515464\n",
      "Epoch 2746 - Train Loss: 0.224927, Train Acc: 0.575641 | Val Loss: 0.237335, Val Acc: 0.515464\n",
      "Epoch 2747 - Train Loss: 0.224907, Train Acc: 0.575641 | Val Loss: 0.237316, Val Acc: 0.515464\n",
      "Epoch 2748 - Train Loss: 0.224888, Train Acc: 0.575641 | Val Loss: 0.237298, Val Acc: 0.525773\n",
      "Epoch 2749 - Train Loss: 0.224869, Train Acc: 0.575641 | Val Loss: 0.237279, Val Acc: 0.525773\n",
      "Epoch 2750 - Train Loss: 0.224850, Train Acc: 0.575641 | Val Loss: 0.237260, Val Acc: 0.525773\n",
      "Epoch 2751 - Train Loss: 0.224831, Train Acc: 0.575641 | Val Loss: 0.237241, Val Acc: 0.525773\n",
      "Epoch 2752 - Train Loss: 0.224811, Train Acc: 0.575641 | Val Loss: 0.237223, Val Acc: 0.525773\n",
      "Epoch 2753 - Train Loss: 0.224792, Train Acc: 0.575641 | Val Loss: 0.237204, Val Acc: 0.525773\n",
      "Epoch 2754 - Train Loss: 0.224773, Train Acc: 0.575641 | Val Loss: 0.237185, Val Acc: 0.525773\n",
      "Epoch 2755 - Train Loss: 0.224754, Train Acc: 0.575641 | Val Loss: 0.237167, Val Acc: 0.525773\n",
      "Epoch 2756 - Train Loss: 0.224735, Train Acc: 0.575641 | Val Loss: 0.237148, Val Acc: 0.525773\n",
      "Epoch 2757 - Train Loss: 0.224715, Train Acc: 0.575641 | Val Loss: 0.237129, Val Acc: 0.525773\n",
      "Epoch 2758 - Train Loss: 0.224696, Train Acc: 0.576923 | Val Loss: 0.237111, Val Acc: 0.525773\n",
      "Epoch 2759 - Train Loss: 0.224677, Train Acc: 0.576923 | Val Loss: 0.237092, Val Acc: 0.525773\n",
      "Epoch 2760 - Train Loss: 0.224658, Train Acc: 0.576923 | Val Loss: 0.237073, Val Acc: 0.525773\n",
      "Epoch 2761 - Train Loss: 0.224639, Train Acc: 0.576923 | Val Loss: 0.237055, Val Acc: 0.525773\n",
      "Epoch 2762 - Train Loss: 0.224619, Train Acc: 0.576923 | Val Loss: 0.237036, Val Acc: 0.525773\n",
      "Epoch 2763 - Train Loss: 0.224600, Train Acc: 0.576923 | Val Loss: 0.237017, Val Acc: 0.525773\n",
      "Epoch 2764 - Train Loss: 0.224581, Train Acc: 0.576923 | Val Loss: 0.236998, Val Acc: 0.525773\n",
      "Epoch 2765 - Train Loss: 0.224562, Train Acc: 0.576923 | Val Loss: 0.236980, Val Acc: 0.525773\n",
      "Epoch 2766 - Train Loss: 0.224543, Train Acc: 0.576923 | Val Loss: 0.236961, Val Acc: 0.525773\n",
      "Epoch 2767 - Train Loss: 0.224524, Train Acc: 0.576923 | Val Loss: 0.236942, Val Acc: 0.525773\n",
      "Epoch 2768 - Train Loss: 0.224504, Train Acc: 0.576923 | Val Loss: 0.236924, Val Acc: 0.525773\n",
      "Epoch 2769 - Train Loss: 0.224485, Train Acc: 0.576923 | Val Loss: 0.236905, Val Acc: 0.525773\n",
      "Epoch 2770 - Train Loss: 0.224466, Train Acc: 0.576923 | Val Loss: 0.236886, Val Acc: 0.525773\n",
      "Epoch 2771 - Train Loss: 0.224447, Train Acc: 0.576923 | Val Loss: 0.236868, Val Acc: 0.525773\n",
      "Epoch 2772 - Train Loss: 0.224428, Train Acc: 0.576923 | Val Loss: 0.236849, Val Acc: 0.525773\n",
      "Epoch 2773 - Train Loss: 0.224409, Train Acc: 0.576923 | Val Loss: 0.236830, Val Acc: 0.525773\n",
      "Epoch 2774 - Train Loss: 0.224389, Train Acc: 0.576923 | Val Loss: 0.236812, Val Acc: 0.525773\n",
      "Epoch 2775 - Train Loss: 0.224370, Train Acc: 0.576923 | Val Loss: 0.236793, Val Acc: 0.525773\n",
      "Epoch 2776 - Train Loss: 0.224351, Train Acc: 0.576923 | Val Loss: 0.236774, Val Acc: 0.525773\n",
      "Epoch 2777 - Train Loss: 0.224332, Train Acc: 0.576923 | Val Loss: 0.236756, Val Acc: 0.525773\n",
      "Epoch 2778 - Train Loss: 0.224313, Train Acc: 0.576923 | Val Loss: 0.236737, Val Acc: 0.525773\n",
      "Epoch 2779 - Train Loss: 0.224294, Train Acc: 0.576923 | Val Loss: 0.236718, Val Acc: 0.525773\n",
      "Epoch 2780 - Train Loss: 0.224275, Train Acc: 0.576923 | Val Loss: 0.236700, Val Acc: 0.525773\n",
      "Epoch 2781 - Train Loss: 0.224255, Train Acc: 0.576923 | Val Loss: 0.236681, Val Acc: 0.525773\n",
      "Epoch 2782 - Train Loss: 0.224236, Train Acc: 0.576923 | Val Loss: 0.236662, Val Acc: 0.525773\n",
      "Epoch 2783 - Train Loss: 0.224217, Train Acc: 0.576923 | Val Loss: 0.236644, Val Acc: 0.525773\n",
      "Epoch 2784 - Train Loss: 0.224198, Train Acc: 0.576923 | Val Loss: 0.236625, Val Acc: 0.525773\n",
      "Epoch 2785 - Train Loss: 0.224179, Train Acc: 0.576923 | Val Loss: 0.236606, Val Acc: 0.525773\n",
      "Epoch 2786 - Train Loss: 0.224160, Train Acc: 0.578205 | Val Loss: 0.236588, Val Acc: 0.525773\n",
      "Epoch 2787 - Train Loss: 0.224141, Train Acc: 0.578205 | Val Loss: 0.236569, Val Acc: 0.525773\n",
      "Epoch 2788 - Train Loss: 0.224121, Train Acc: 0.578205 | Val Loss: 0.236550, Val Acc: 0.525773\n",
      "Epoch 2789 - Train Loss: 0.224102, Train Acc: 0.578205 | Val Loss: 0.236532, Val Acc: 0.525773\n",
      "Epoch 2790 - Train Loss: 0.224083, Train Acc: 0.578205 | Val Loss: 0.236513, Val Acc: 0.525773\n",
      "Epoch 2791 - Train Loss: 0.224064, Train Acc: 0.578205 | Val Loss: 0.236494, Val Acc: 0.525773\n",
      "Epoch 2792 - Train Loss: 0.224045, Train Acc: 0.578205 | Val Loss: 0.236476, Val Acc: 0.525773\n",
      "Epoch 2793 - Train Loss: 0.224026, Train Acc: 0.578205 | Val Loss: 0.236457, Val Acc: 0.525773\n",
      "Epoch 2794 - Train Loss: 0.224007, Train Acc: 0.578205 | Val Loss: 0.236438, Val Acc: 0.525773\n",
      "Epoch 2795 - Train Loss: 0.223988, Train Acc: 0.578205 | Val Loss: 0.236420, Val Acc: 0.525773\n",
      "Epoch 2796 - Train Loss: 0.223968, Train Acc: 0.578205 | Val Loss: 0.236401, Val Acc: 0.525773\n",
      "Epoch 2797 - Train Loss: 0.223949, Train Acc: 0.578205 | Val Loss: 0.236382, Val Acc: 0.525773\n",
      "Epoch 2798 - Train Loss: 0.223930, Train Acc: 0.578205 | Val Loss: 0.236364, Val Acc: 0.525773\n",
      "Epoch 2799 - Train Loss: 0.223911, Train Acc: 0.578205 | Val Loss: 0.236345, Val Acc: 0.525773\n",
      "Epoch 2800 - Train Loss: 0.223892, Train Acc: 0.578205 | Val Loss: 0.236326, Val Acc: 0.525773\n",
      "Epoch 2801 - Train Loss: 0.223873, Train Acc: 0.578205 | Val Loss: 0.236308, Val Acc: 0.525773\n",
      "Epoch 2802 - Train Loss: 0.223854, Train Acc: 0.578205 | Val Loss: 0.236289, Val Acc: 0.525773\n",
      "Epoch 2803 - Train Loss: 0.223835, Train Acc: 0.578205 | Val Loss: 0.236271, Val Acc: 0.525773\n",
      "Epoch 2804 - Train Loss: 0.223816, Train Acc: 0.578205 | Val Loss: 0.236252, Val Acc: 0.525773\n",
      "Epoch 2805 - Train Loss: 0.223797, Train Acc: 0.578205 | Val Loss: 0.236233, Val Acc: 0.525773\n",
      "Epoch 2806 - Train Loss: 0.223777, Train Acc: 0.578205 | Val Loss: 0.236215, Val Acc: 0.525773\n",
      "Epoch 2807 - Train Loss: 0.223758, Train Acc: 0.578205 | Val Loss: 0.236196, Val Acc: 0.525773\n",
      "Epoch 2808 - Train Loss: 0.223739, Train Acc: 0.578205 | Val Loss: 0.236177, Val Acc: 0.525773\n",
      "Epoch 2809 - Train Loss: 0.223720, Train Acc: 0.578205 | Val Loss: 0.236159, Val Acc: 0.525773\n",
      "Epoch 2810 - Train Loss: 0.223701, Train Acc: 0.578205 | Val Loss: 0.236140, Val Acc: 0.525773\n",
      "Epoch 2811 - Train Loss: 0.223682, Train Acc: 0.578205 | Val Loss: 0.236121, Val Acc: 0.525773\n",
      "Epoch 2812 - Train Loss: 0.223663, Train Acc: 0.578205 | Val Loss: 0.236103, Val Acc: 0.525773\n",
      "Epoch 2813 - Train Loss: 0.223644, Train Acc: 0.578205 | Val Loss: 0.236084, Val Acc: 0.525773\n",
      "Epoch 2814 - Train Loss: 0.223625, Train Acc: 0.578205 | Val Loss: 0.236065, Val Acc: 0.525773\n",
      "Epoch 2815 - Train Loss: 0.223606, Train Acc: 0.578205 | Val Loss: 0.236047, Val Acc: 0.525773\n",
      "Epoch 2816 - Train Loss: 0.223586, Train Acc: 0.578205 | Val Loss: 0.236028, Val Acc: 0.525773\n",
      "Epoch 2817 - Train Loss: 0.223567, Train Acc: 0.578205 | Val Loss: 0.236010, Val Acc: 0.525773\n",
      "Epoch 2818 - Train Loss: 0.223548, Train Acc: 0.579487 | Val Loss: 0.235991, Val Acc: 0.525773\n",
      "Epoch 2819 - Train Loss: 0.223529, Train Acc: 0.579487 | Val Loss: 0.235972, Val Acc: 0.525773\n",
      "Epoch 2820 - Train Loss: 0.223510, Train Acc: 0.579487 | Val Loss: 0.235954, Val Acc: 0.525773\n",
      "Epoch 2821 - Train Loss: 0.223491, Train Acc: 0.579487 | Val Loss: 0.235935, Val Acc: 0.525773\n",
      "Epoch 2822 - Train Loss: 0.223472, Train Acc: 0.579487 | Val Loss: 0.235916, Val Acc: 0.525773\n",
      "Epoch 2823 - Train Loss: 0.223453, Train Acc: 0.579487 | Val Loss: 0.235898, Val Acc: 0.525773\n",
      "Epoch 2824 - Train Loss: 0.223434, Train Acc: 0.579487 | Val Loss: 0.235879, Val Acc: 0.525773\n",
      "Epoch 2825 - Train Loss: 0.223415, Train Acc: 0.579487 | Val Loss: 0.235861, Val Acc: 0.525773\n",
      "Epoch 2826 - Train Loss: 0.223396, Train Acc: 0.579487 | Val Loss: 0.235842, Val Acc: 0.525773\n",
      "Epoch 2827 - Train Loss: 0.223377, Train Acc: 0.580769 | Val Loss: 0.235823, Val Acc: 0.525773\n",
      "Epoch 2828 - Train Loss: 0.223358, Train Acc: 0.580769 | Val Loss: 0.235805, Val Acc: 0.525773\n",
      "Epoch 2829 - Train Loss: 0.223339, Train Acc: 0.580769 | Val Loss: 0.235786, Val Acc: 0.525773\n",
      "Epoch 2830 - Train Loss: 0.223319, Train Acc: 0.580769 | Val Loss: 0.235767, Val Acc: 0.525773\n",
      "Epoch 2831 - Train Loss: 0.223300, Train Acc: 0.580769 | Val Loss: 0.235749, Val Acc: 0.525773\n",
      "Epoch 2832 - Train Loss: 0.223281, Train Acc: 0.580769 | Val Loss: 0.235730, Val Acc: 0.525773\n",
      "Epoch 2833 - Train Loss: 0.223262, Train Acc: 0.582051 | Val Loss: 0.235712, Val Acc: 0.525773\n",
      "Epoch 2834 - Train Loss: 0.223243, Train Acc: 0.582051 | Val Loss: 0.235693, Val Acc: 0.525773\n",
      "Epoch 2835 - Train Loss: 0.223224, Train Acc: 0.582051 | Val Loss: 0.235674, Val Acc: 0.525773\n",
      "Epoch 2836 - Train Loss: 0.223205, Train Acc: 0.582051 | Val Loss: 0.235656, Val Acc: 0.525773\n",
      "Epoch 2837 - Train Loss: 0.223186, Train Acc: 0.582051 | Val Loss: 0.235637, Val Acc: 0.525773\n",
      "Epoch 2838 - Train Loss: 0.223167, Train Acc: 0.582051 | Val Loss: 0.235618, Val Acc: 0.525773\n",
      "Epoch 2839 - Train Loss: 0.223148, Train Acc: 0.582051 | Val Loss: 0.235600, Val Acc: 0.525773\n",
      "Epoch 2840 - Train Loss: 0.223129, Train Acc: 0.582051 | Val Loss: 0.235581, Val Acc: 0.525773\n",
      "Epoch 2841 - Train Loss: 0.223110, Train Acc: 0.582051 | Val Loss: 0.235563, Val Acc: 0.525773\n",
      "Epoch 2842 - Train Loss: 0.223091, Train Acc: 0.582051 | Val Loss: 0.235544, Val Acc: 0.525773\n",
      "Epoch 2843 - Train Loss: 0.223072, Train Acc: 0.582051 | Val Loss: 0.235525, Val Acc: 0.525773\n",
      "Epoch 2844 - Train Loss: 0.223053, Train Acc: 0.582051 | Val Loss: 0.235507, Val Acc: 0.525773\n",
      "Epoch 2845 - Train Loss: 0.223034, Train Acc: 0.582051 | Val Loss: 0.235488, Val Acc: 0.525773\n",
      "Epoch 2846 - Train Loss: 0.223015, Train Acc: 0.582051 | Val Loss: 0.235470, Val Acc: 0.525773\n",
      "Epoch 2847 - Train Loss: 0.222996, Train Acc: 0.582051 | Val Loss: 0.235451, Val Acc: 0.525773\n",
      "Epoch 2848 - Train Loss: 0.222977, Train Acc: 0.582051 | Val Loss: 0.235433, Val Acc: 0.525773\n",
      "Epoch 2849 - Train Loss: 0.222958, Train Acc: 0.582051 | Val Loss: 0.235414, Val Acc: 0.525773\n",
      "Epoch 2850 - Train Loss: 0.222939, Train Acc: 0.582051 | Val Loss: 0.235396, Val Acc: 0.525773\n",
      "Epoch 2851 - Train Loss: 0.222920, Train Acc: 0.582051 | Val Loss: 0.235377, Val Acc: 0.525773\n",
      "Epoch 2852 - Train Loss: 0.222901, Train Acc: 0.582051 | Val Loss: 0.235359, Val Acc: 0.525773\n",
      "Epoch 2853 - Train Loss: 0.222882, Train Acc: 0.582051 | Val Loss: 0.235340, Val Acc: 0.525773\n",
      "Epoch 2854 - Train Loss: 0.222863, Train Acc: 0.582051 | Val Loss: 0.235322, Val Acc: 0.525773\n",
      "Epoch 2855 - Train Loss: 0.222844, Train Acc: 0.582051 | Val Loss: 0.235303, Val Acc: 0.525773\n",
      "Epoch 2856 - Train Loss: 0.222825, Train Acc: 0.582051 | Val Loss: 0.235285, Val Acc: 0.525773\n",
      "Epoch 2857 - Train Loss: 0.222806, Train Acc: 0.582051 | Val Loss: 0.235266, Val Acc: 0.525773\n",
      "Epoch 2858 - Train Loss: 0.222787, Train Acc: 0.582051 | Val Loss: 0.235248, Val Acc: 0.525773\n",
      "Epoch 2859 - Train Loss: 0.222768, Train Acc: 0.582051 | Val Loss: 0.235229, Val Acc: 0.525773\n",
      "Epoch 2860 - Train Loss: 0.222749, Train Acc: 0.582051 | Val Loss: 0.235211, Val Acc: 0.525773\n",
      "Epoch 2861 - Train Loss: 0.222730, Train Acc: 0.582051 | Val Loss: 0.235192, Val Acc: 0.525773\n",
      "Epoch 2862 - Train Loss: 0.222711, Train Acc: 0.582051 | Val Loss: 0.235174, Val Acc: 0.525773\n",
      "Epoch 2863 - Train Loss: 0.222692, Train Acc: 0.582051 | Val Loss: 0.235155, Val Acc: 0.525773\n",
      "Epoch 2864 - Train Loss: 0.222673, Train Acc: 0.582051 | Val Loss: 0.235137, Val Acc: 0.525773\n",
      "Epoch 2865 - Train Loss: 0.222654, Train Acc: 0.582051 | Val Loss: 0.235119, Val Acc: 0.525773\n",
      "Epoch 2866 - Train Loss: 0.222635, Train Acc: 0.582051 | Val Loss: 0.235100, Val Acc: 0.525773\n",
      "Epoch 2867 - Train Loss: 0.222616, Train Acc: 0.582051 | Val Loss: 0.235082, Val Acc: 0.525773\n",
      "Epoch 2868 - Train Loss: 0.222597, Train Acc: 0.582051 | Val Loss: 0.235063, Val Acc: 0.525773\n",
      "Epoch 2869 - Train Loss: 0.222578, Train Acc: 0.582051 | Val Loss: 0.235045, Val Acc: 0.525773\n",
      "Epoch 2870 - Train Loss: 0.222559, Train Acc: 0.582051 | Val Loss: 0.235026, Val Acc: 0.525773\n",
      "Epoch 2871 - Train Loss: 0.222540, Train Acc: 0.582051 | Val Loss: 0.235008, Val Acc: 0.525773\n",
      "Epoch 2872 - Train Loss: 0.222521, Train Acc: 0.582051 | Val Loss: 0.234989, Val Acc: 0.525773\n",
      "Epoch 2873 - Train Loss: 0.222502, Train Acc: 0.582051 | Val Loss: 0.234971, Val Acc: 0.525773\n",
      "Epoch 2874 - Train Loss: 0.222483, Train Acc: 0.582051 | Val Loss: 0.234952, Val Acc: 0.525773\n",
      "Epoch 2875 - Train Loss: 0.222464, Train Acc: 0.582051 | Val Loss: 0.234934, Val Acc: 0.525773\n",
      "Epoch 2876 - Train Loss: 0.222445, Train Acc: 0.583333 | Val Loss: 0.234915, Val Acc: 0.525773\n",
      "Epoch 2877 - Train Loss: 0.222426, Train Acc: 0.583333 | Val Loss: 0.234897, Val Acc: 0.525773\n",
      "Epoch 2878 - Train Loss: 0.222407, Train Acc: 0.583333 | Val Loss: 0.234878, Val Acc: 0.525773\n",
      "Epoch 2879 - Train Loss: 0.222388, Train Acc: 0.583333 | Val Loss: 0.234860, Val Acc: 0.525773\n",
      "Epoch 2880 - Train Loss: 0.222369, Train Acc: 0.583333 | Val Loss: 0.234841, Val Acc: 0.525773\n",
      "Epoch 2881 - Train Loss: 0.222350, Train Acc: 0.583333 | Val Loss: 0.234823, Val Acc: 0.525773\n",
      "Epoch 2882 - Train Loss: 0.222331, Train Acc: 0.583333 | Val Loss: 0.234804, Val Acc: 0.525773\n",
      "Epoch 2883 - Train Loss: 0.222312, Train Acc: 0.583333 | Val Loss: 0.234786, Val Acc: 0.525773\n",
      "Epoch 2884 - Train Loss: 0.222293, Train Acc: 0.583333 | Val Loss: 0.234767, Val Acc: 0.525773\n",
      "Epoch 2885 - Train Loss: 0.222274, Train Acc: 0.583333 | Val Loss: 0.234749, Val Acc: 0.525773\n",
      "Epoch 2886 - Train Loss: 0.222255, Train Acc: 0.583333 | Val Loss: 0.234730, Val Acc: 0.525773\n",
      "Epoch 2887 - Train Loss: 0.222236, Train Acc: 0.583333 | Val Loss: 0.234712, Val Acc: 0.525773\n",
      "Epoch 2888 - Train Loss: 0.222217, Train Acc: 0.583333 | Val Loss: 0.234693, Val Acc: 0.525773\n",
      "Epoch 2889 - Train Loss: 0.222198, Train Acc: 0.583333 | Val Loss: 0.234675, Val Acc: 0.525773\n",
      "Epoch 2890 - Train Loss: 0.222180, Train Acc: 0.583333 | Val Loss: 0.234656, Val Acc: 0.525773\n",
      "Epoch 2891 - Train Loss: 0.222161, Train Acc: 0.583333 | Val Loss: 0.234638, Val Acc: 0.525773\n",
      "Epoch 2892 - Train Loss: 0.222142, Train Acc: 0.583333 | Val Loss: 0.234619, Val Acc: 0.525773\n",
      "Epoch 2893 - Train Loss: 0.222123, Train Acc: 0.583333 | Val Loss: 0.234601, Val Acc: 0.525773\n",
      "Epoch 2894 - Train Loss: 0.222104, Train Acc: 0.583333 | Val Loss: 0.234582, Val Acc: 0.525773\n",
      "Epoch 2895 - Train Loss: 0.222085, Train Acc: 0.583333 | Val Loss: 0.234564, Val Acc: 0.525773\n",
      "Epoch 2896 - Train Loss: 0.222066, Train Acc: 0.583333 | Val Loss: 0.234546, Val Acc: 0.525773\n",
      "Epoch 2897 - Train Loss: 0.222047, Train Acc: 0.583333 | Val Loss: 0.234527, Val Acc: 0.525773\n",
      "Epoch 2898 - Train Loss: 0.222028, Train Acc: 0.583333 | Val Loss: 0.234509, Val Acc: 0.525773\n",
      "Epoch 2899 - Train Loss: 0.222009, Train Acc: 0.583333 | Val Loss: 0.234490, Val Acc: 0.525773\n",
      "Epoch 2900 - Train Loss: 0.221990, Train Acc: 0.583333 | Val Loss: 0.234472, Val Acc: 0.525773\n",
      "Epoch 2901 - Train Loss: 0.221971, Train Acc: 0.583333 | Val Loss: 0.234453, Val Acc: 0.525773\n",
      "Epoch 2902 - Train Loss: 0.221952, Train Acc: 0.583333 | Val Loss: 0.234435, Val Acc: 0.525773\n",
      "Epoch 2903 - Train Loss: 0.221934, Train Acc: 0.583333 | Val Loss: 0.234416, Val Acc: 0.525773\n",
      "Epoch 2904 - Train Loss: 0.221915, Train Acc: 0.583333 | Val Loss: 0.234398, Val Acc: 0.525773\n",
      "Epoch 2905 - Train Loss: 0.221896, Train Acc: 0.583333 | Val Loss: 0.234379, Val Acc: 0.525773\n",
      "Epoch 2906 - Train Loss: 0.221877, Train Acc: 0.583333 | Val Loss: 0.234361, Val Acc: 0.525773\n",
      "Epoch 2907 - Train Loss: 0.221858, Train Acc: 0.583333 | Val Loss: 0.234342, Val Acc: 0.525773\n",
      "Epoch 2908 - Train Loss: 0.221839, Train Acc: 0.583333 | Val Loss: 0.234324, Val Acc: 0.525773\n",
      "Epoch 2909 - Train Loss: 0.221820, Train Acc: 0.583333 | Val Loss: 0.234305, Val Acc: 0.525773\n",
      "Epoch 2910 - Train Loss: 0.221801, Train Acc: 0.583333 | Val Loss: 0.234287, Val Acc: 0.525773\n",
      "Epoch 2911 - Train Loss: 0.221782, Train Acc: 0.583333 | Val Loss: 0.234268, Val Acc: 0.525773\n",
      "Epoch 2912 - Train Loss: 0.221763, Train Acc: 0.583333 | Val Loss: 0.234250, Val Acc: 0.525773\n",
      "Epoch 2913 - Train Loss: 0.221744, Train Acc: 0.583333 | Val Loss: 0.234231, Val Acc: 0.525773\n",
      "Epoch 2914 - Train Loss: 0.221726, Train Acc: 0.583333 | Val Loss: 0.234213, Val Acc: 0.525773\n",
      "Epoch 2915 - Train Loss: 0.221707, Train Acc: 0.583333 | Val Loss: 0.234194, Val Acc: 0.525773\n",
      "Epoch 2916 - Train Loss: 0.221688, Train Acc: 0.583333 | Val Loss: 0.234176, Val Acc: 0.525773\n",
      "Epoch 2917 - Train Loss: 0.221669, Train Acc: 0.583333 | Val Loss: 0.234158, Val Acc: 0.525773\n",
      "Epoch 2918 - Train Loss: 0.221650, Train Acc: 0.583333 | Val Loss: 0.234139, Val Acc: 0.525773\n",
      "Epoch 2919 - Train Loss: 0.221631, Train Acc: 0.584615 | Val Loss: 0.234121, Val Acc: 0.525773\n",
      "Epoch 2920 - Train Loss: 0.221612, Train Acc: 0.584615 | Val Loss: 0.234102, Val Acc: 0.525773\n",
      "Epoch 2921 - Train Loss: 0.221593, Train Acc: 0.584615 | Val Loss: 0.234084, Val Acc: 0.525773\n",
      "Epoch 2922 - Train Loss: 0.221575, Train Acc: 0.584615 | Val Loss: 0.234065, Val Acc: 0.525773\n",
      "Epoch 2923 - Train Loss: 0.221556, Train Acc: 0.584615 | Val Loss: 0.234047, Val Acc: 0.525773\n",
      "Epoch 2924 - Train Loss: 0.221537, Train Acc: 0.584615 | Val Loss: 0.234028, Val Acc: 0.525773\n",
      "Epoch 2925 - Train Loss: 0.221518, Train Acc: 0.584615 | Val Loss: 0.234010, Val Acc: 0.525773\n",
      "Epoch 2926 - Train Loss: 0.221499, Train Acc: 0.584615 | Val Loss: 0.233991, Val Acc: 0.525773\n",
      "Epoch 2927 - Train Loss: 0.221480, Train Acc: 0.584615 | Val Loss: 0.233973, Val Acc: 0.525773\n",
      "Epoch 2928 - Train Loss: 0.221461, Train Acc: 0.584615 | Val Loss: 0.233954, Val Acc: 0.525773\n",
      "Epoch 2929 - Train Loss: 0.221442, Train Acc: 0.584615 | Val Loss: 0.233936, Val Acc: 0.525773\n",
      "Epoch 2930 - Train Loss: 0.221424, Train Acc: 0.584615 | Val Loss: 0.233918, Val Acc: 0.525773\n",
      "Epoch 2931 - Train Loss: 0.221405, Train Acc: 0.584615 | Val Loss: 0.233899, Val Acc: 0.525773\n",
      "Epoch 2932 - Train Loss: 0.221386, Train Acc: 0.584615 | Val Loss: 0.233881, Val Acc: 0.525773\n",
      "Epoch 2933 - Train Loss: 0.221367, Train Acc: 0.584615 | Val Loss: 0.233862, Val Acc: 0.525773\n",
      "Epoch 2934 - Train Loss: 0.221348, Train Acc: 0.584615 | Val Loss: 0.233844, Val Acc: 0.525773\n",
      "Epoch 2935 - Train Loss: 0.221329, Train Acc: 0.584615 | Val Loss: 0.233825, Val Acc: 0.525773\n",
      "Epoch 2936 - Train Loss: 0.221310, Train Acc: 0.584615 | Val Loss: 0.233807, Val Acc: 0.525773\n",
      "Epoch 2937 - Train Loss: 0.221292, Train Acc: 0.584615 | Val Loss: 0.233788, Val Acc: 0.525773\n",
      "Epoch 2938 - Train Loss: 0.221273, Train Acc: 0.584615 | Val Loss: 0.233770, Val Acc: 0.525773\n",
      "Epoch 2939 - Train Loss: 0.221254, Train Acc: 0.584615 | Val Loss: 0.233751, Val Acc: 0.525773\n",
      "Epoch 2940 - Train Loss: 0.221235, Train Acc: 0.584615 | Val Loss: 0.233733, Val Acc: 0.525773\n",
      "Epoch 2941 - Train Loss: 0.221216, Train Acc: 0.584615 | Val Loss: 0.233715, Val Acc: 0.525773\n",
      "Epoch 2942 - Train Loss: 0.221197, Train Acc: 0.584615 | Val Loss: 0.233696, Val Acc: 0.525773\n",
      "Epoch 2943 - Train Loss: 0.221179, Train Acc: 0.584615 | Val Loss: 0.233678, Val Acc: 0.525773\n",
      "Epoch 2944 - Train Loss: 0.221160, Train Acc: 0.584615 | Val Loss: 0.233659, Val Acc: 0.525773\n",
      "Epoch 2945 - Train Loss: 0.221141, Train Acc: 0.584615 | Val Loss: 0.233641, Val Acc: 0.525773\n",
      "Epoch 2946 - Train Loss: 0.221122, Train Acc: 0.584615 | Val Loss: 0.233622, Val Acc: 0.525773\n",
      "Epoch 2947 - Train Loss: 0.221103, Train Acc: 0.584615 | Val Loss: 0.233604, Val Acc: 0.525773\n",
      "Epoch 2948 - Train Loss: 0.221084, Train Acc: 0.584615 | Val Loss: 0.233585, Val Acc: 0.525773\n",
      "Epoch 2949 - Train Loss: 0.221066, Train Acc: 0.584615 | Val Loss: 0.233567, Val Acc: 0.525773\n",
      "Epoch 2950 - Train Loss: 0.221047, Train Acc: 0.584615 | Val Loss: 0.233549, Val Acc: 0.525773\n",
      "Epoch 2951 - Train Loss: 0.221028, Train Acc: 0.584615 | Val Loss: 0.233530, Val Acc: 0.525773\n",
      "Epoch 2952 - Train Loss: 0.221009, Train Acc: 0.584615 | Val Loss: 0.233512, Val Acc: 0.525773\n",
      "Epoch 2953 - Train Loss: 0.220990, Train Acc: 0.584615 | Val Loss: 0.233494, Val Acc: 0.525773\n",
      "Epoch 2954 - Train Loss: 0.220972, Train Acc: 0.584615 | Val Loss: 0.233475, Val Acc: 0.525773\n",
      "Epoch 2955 - Train Loss: 0.220953, Train Acc: 0.584615 | Val Loss: 0.233457, Val Acc: 0.525773\n",
      "Epoch 2956 - Train Loss: 0.220934, Train Acc: 0.584615 | Val Loss: 0.233439, Val Acc: 0.525773\n",
      "Epoch 2957 - Train Loss: 0.220915, Train Acc: 0.584615 | Val Loss: 0.233420, Val Acc: 0.525773\n",
      "Epoch 2958 - Train Loss: 0.220896, Train Acc: 0.584615 | Val Loss: 0.233402, Val Acc: 0.525773\n",
      "Epoch 2959 - Train Loss: 0.220878, Train Acc: 0.584615 | Val Loss: 0.233384, Val Acc: 0.525773\n",
      "Epoch 2960 - Train Loss: 0.220859, Train Acc: 0.584615 | Val Loss: 0.233366, Val Acc: 0.525773\n",
      "Epoch 2961 - Train Loss: 0.220840, Train Acc: 0.585897 | Val Loss: 0.233347, Val Acc: 0.525773\n",
      "Epoch 2962 - Train Loss: 0.220821, Train Acc: 0.585897 | Val Loss: 0.233329, Val Acc: 0.525773\n",
      "Epoch 2963 - Train Loss: 0.220803, Train Acc: 0.585897 | Val Loss: 0.233311, Val Acc: 0.525773\n",
      "Epoch 2964 - Train Loss: 0.220784, Train Acc: 0.585897 | Val Loss: 0.233292, Val Acc: 0.525773\n",
      "Epoch 2965 - Train Loss: 0.220765, Train Acc: 0.585897 | Val Loss: 0.233274, Val Acc: 0.525773\n",
      "Epoch 2966 - Train Loss: 0.220746, Train Acc: 0.585897 | Val Loss: 0.233256, Val Acc: 0.525773\n",
      "Epoch 2967 - Train Loss: 0.220728, Train Acc: 0.585897 | Val Loss: 0.233238, Val Acc: 0.525773\n",
      "Epoch 2968 - Train Loss: 0.220709, Train Acc: 0.585897 | Val Loss: 0.233219, Val Acc: 0.525773\n",
      "Epoch 2969 - Train Loss: 0.220690, Train Acc: 0.585897 | Val Loss: 0.233201, Val Acc: 0.525773\n",
      "Epoch 2970 - Train Loss: 0.220671, Train Acc: 0.585897 | Val Loss: 0.233183, Val Acc: 0.525773\n",
      "Epoch 2971 - Train Loss: 0.220653, Train Acc: 0.585897 | Val Loss: 0.233164, Val Acc: 0.525773\n",
      "Epoch 2972 - Train Loss: 0.220634, Train Acc: 0.585897 | Val Loss: 0.233146, Val Acc: 0.525773\n",
      "Epoch 2973 - Train Loss: 0.220615, Train Acc: 0.585897 | Val Loss: 0.233128, Val Acc: 0.525773\n",
      "Epoch 2974 - Train Loss: 0.220596, Train Acc: 0.585897 | Val Loss: 0.233109, Val Acc: 0.525773\n",
      "Epoch 2975 - Train Loss: 0.220578, Train Acc: 0.585897 | Val Loss: 0.233091, Val Acc: 0.525773\n",
      "Epoch 2976 - Train Loss: 0.220559, Train Acc: 0.585897 | Val Loss: 0.233073, Val Acc: 0.525773\n",
      "Epoch 2977 - Train Loss: 0.220540, Train Acc: 0.585897 | Val Loss: 0.233055, Val Acc: 0.525773\n",
      "Epoch 2978 - Train Loss: 0.220521, Train Acc: 0.585897 | Val Loss: 0.233036, Val Acc: 0.525773\n",
      "Epoch 2979 - Train Loss: 0.220503, Train Acc: 0.585897 | Val Loss: 0.233018, Val Acc: 0.525773\n",
      "Epoch 2980 - Train Loss: 0.220484, Train Acc: 0.585897 | Val Loss: 0.233000, Val Acc: 0.525773\n",
      "Epoch 2981 - Train Loss: 0.220465, Train Acc: 0.585897 | Val Loss: 0.232981, Val Acc: 0.525773\n",
      "Epoch 2982 - Train Loss: 0.220446, Train Acc: 0.585897 | Val Loss: 0.232963, Val Acc: 0.525773\n",
      "Epoch 2983 - Train Loss: 0.220428, Train Acc: 0.585897 | Val Loss: 0.232945, Val Acc: 0.525773\n",
      "Epoch 2984 - Train Loss: 0.220409, Train Acc: 0.585897 | Val Loss: 0.232926, Val Acc: 0.525773\n",
      "Epoch 2985 - Train Loss: 0.220390, Train Acc: 0.585897 | Val Loss: 0.232908, Val Acc: 0.525773\n",
      "Epoch 2986 - Train Loss: 0.220372, Train Acc: 0.585897 | Val Loss: 0.232890, Val Acc: 0.525773\n",
      "Epoch 2987 - Train Loss: 0.220353, Train Acc: 0.585897 | Val Loss: 0.232872, Val Acc: 0.525773\n",
      "Epoch 2988 - Train Loss: 0.220334, Train Acc: 0.585897 | Val Loss: 0.232853, Val Acc: 0.525773\n",
      "Epoch 2989 - Train Loss: 0.220315, Train Acc: 0.585897 | Val Loss: 0.232835, Val Acc: 0.525773\n",
      "Epoch 2990 - Train Loss: 0.220297, Train Acc: 0.585897 | Val Loss: 0.232817, Val Acc: 0.525773\n",
      "Epoch 2991 - Train Loss: 0.220278, Train Acc: 0.585897 | Val Loss: 0.232798, Val Acc: 0.525773\n",
      "Epoch 2992 - Train Loss: 0.220259, Train Acc: 0.585897 | Val Loss: 0.232780, Val Acc: 0.525773\n",
      "Epoch 2993 - Train Loss: 0.220241, Train Acc: 0.585897 | Val Loss: 0.232762, Val Acc: 0.525773\n",
      "Epoch 2994 - Train Loss: 0.220222, Train Acc: 0.585897 | Val Loss: 0.232743, Val Acc: 0.525773\n",
      "Epoch 2995 - Train Loss: 0.220203, Train Acc: 0.585897 | Val Loss: 0.232725, Val Acc: 0.525773\n",
      "Epoch 2996 - Train Loss: 0.220184, Train Acc: 0.585897 | Val Loss: 0.232707, Val Acc: 0.525773\n",
      "Epoch 2997 - Train Loss: 0.220166, Train Acc: 0.585897 | Val Loss: 0.232689, Val Acc: 0.525773\n",
      "Epoch 2998 - Train Loss: 0.220147, Train Acc: 0.585897 | Val Loss: 0.232670, Val Acc: 0.525773\n",
      "Epoch 2999 - Train Loss: 0.220128, Train Acc: 0.585897 | Val Loss: 0.232652, Val Acc: 0.525773\n",
      "Epoch 3000 - Train Loss: 0.220110, Train Acc: 0.585897 | Val Loss: 0.232634, Val Acc: 0.525773\n",
      "Epoch 3001 - Train Loss: 0.220091, Train Acc: 0.585897 | Val Loss: 0.232615, Val Acc: 0.525773\n",
      "Epoch 3002 - Train Loss: 0.220072, Train Acc: 0.585897 | Val Loss: 0.232597, Val Acc: 0.525773\n",
      "Epoch 3003 - Train Loss: 0.220054, Train Acc: 0.585897 | Val Loss: 0.232579, Val Acc: 0.525773\n",
      "Epoch 3004 - Train Loss: 0.220035, Train Acc: 0.585897 | Val Loss: 0.232561, Val Acc: 0.525773\n",
      "Epoch 3005 - Train Loss: 0.220016, Train Acc: 0.585897 | Val Loss: 0.232542, Val Acc: 0.525773\n",
      "Epoch 3006 - Train Loss: 0.219998, Train Acc: 0.585897 | Val Loss: 0.232524, Val Acc: 0.525773\n",
      "Epoch 3007 - Train Loss: 0.219979, Train Acc: 0.585897 | Val Loss: 0.232506, Val Acc: 0.525773\n",
      "Epoch 3008 - Train Loss: 0.219960, Train Acc: 0.585897 | Val Loss: 0.232488, Val Acc: 0.525773\n",
      "Epoch 3009 - Train Loss: 0.219942, Train Acc: 0.585897 | Val Loss: 0.232469, Val Acc: 0.525773\n",
      "Epoch 3010 - Train Loss: 0.219923, Train Acc: 0.585897 | Val Loss: 0.232451, Val Acc: 0.525773\n",
      "Epoch 3011 - Train Loss: 0.219904, Train Acc: 0.585897 | Val Loss: 0.232433, Val Acc: 0.525773\n",
      "Epoch 3012 - Train Loss: 0.219886, Train Acc: 0.585897 | Val Loss: 0.232415, Val Acc: 0.525773\n",
      "Epoch 3013 - Train Loss: 0.219867, Train Acc: 0.585897 | Val Loss: 0.232396, Val Acc: 0.525773\n",
      "Epoch 3014 - Train Loss: 0.219848, Train Acc: 0.585897 | Val Loss: 0.232378, Val Acc: 0.525773\n",
      "Epoch 3015 - Train Loss: 0.219830, Train Acc: 0.585897 | Val Loss: 0.232360, Val Acc: 0.525773\n",
      "Epoch 3016 - Train Loss: 0.219811, Train Acc: 0.585897 | Val Loss: 0.232341, Val Acc: 0.525773\n",
      "Epoch 3017 - Train Loss: 0.219792, Train Acc: 0.585897 | Val Loss: 0.232323, Val Acc: 0.525773\n",
      "Epoch 3018 - Train Loss: 0.219774, Train Acc: 0.585897 | Val Loss: 0.232305, Val Acc: 0.525773\n",
      "Epoch 3019 - Train Loss: 0.219755, Train Acc: 0.585897 | Val Loss: 0.232287, Val Acc: 0.525773\n",
      "Epoch 3020 - Train Loss: 0.219737, Train Acc: 0.585897 | Val Loss: 0.232268, Val Acc: 0.525773\n",
      "Epoch 3021 - Train Loss: 0.219718, Train Acc: 0.585897 | Val Loss: 0.232250, Val Acc: 0.525773\n",
      "Epoch 3022 - Train Loss: 0.219699, Train Acc: 0.585897 | Val Loss: 0.232232, Val Acc: 0.525773\n",
      "Epoch 3023 - Train Loss: 0.219681, Train Acc: 0.585897 | Val Loss: 0.232214, Val Acc: 0.525773\n",
      "Epoch 3024 - Train Loss: 0.219662, Train Acc: 0.585897 | Val Loss: 0.232195, Val Acc: 0.525773\n",
      "Epoch 3025 - Train Loss: 0.219643, Train Acc: 0.585897 | Val Loss: 0.232177, Val Acc: 0.525773\n",
      "Epoch 3026 - Train Loss: 0.219625, Train Acc: 0.585897 | Val Loss: 0.232159, Val Acc: 0.525773\n",
      "Epoch 3027 - Train Loss: 0.219606, Train Acc: 0.587179 | Val Loss: 0.232141, Val Acc: 0.525773\n",
      "Epoch 3028 - Train Loss: 0.219588, Train Acc: 0.587179 | Val Loss: 0.232122, Val Acc: 0.525773\n",
      "Epoch 3029 - Train Loss: 0.219569, Train Acc: 0.587179 | Val Loss: 0.232104, Val Acc: 0.525773\n",
      "Epoch 3030 - Train Loss: 0.219550, Train Acc: 0.587179 | Val Loss: 0.232086, Val Acc: 0.525773\n",
      "Epoch 3031 - Train Loss: 0.219532, Train Acc: 0.587179 | Val Loss: 0.232068, Val Acc: 0.525773\n",
      "Epoch 3032 - Train Loss: 0.219513, Train Acc: 0.587179 | Val Loss: 0.232049, Val Acc: 0.525773\n",
      "Epoch 3033 - Train Loss: 0.219494, Train Acc: 0.587179 | Val Loss: 0.232031, Val Acc: 0.525773\n",
      "Epoch 3034 - Train Loss: 0.219476, Train Acc: 0.587179 | Val Loss: 0.232013, Val Acc: 0.525773\n",
      "Epoch 3035 - Train Loss: 0.219457, Train Acc: 0.587179 | Val Loss: 0.231995, Val Acc: 0.525773\n",
      "Epoch 3036 - Train Loss: 0.219439, Train Acc: 0.587179 | Val Loss: 0.231976, Val Acc: 0.525773\n",
      "Epoch 3037 - Train Loss: 0.219420, Train Acc: 0.587179 | Val Loss: 0.231958, Val Acc: 0.525773\n",
      "Epoch 3038 - Train Loss: 0.219401, Train Acc: 0.587179 | Val Loss: 0.231940, Val Acc: 0.525773\n",
      "Epoch 3039 - Train Loss: 0.219383, Train Acc: 0.587179 | Val Loss: 0.231922, Val Acc: 0.525773\n",
      "Epoch 3040 - Train Loss: 0.219364, Train Acc: 0.587179 | Val Loss: 0.231903, Val Acc: 0.525773\n",
      "Epoch 3041 - Train Loss: 0.219346, Train Acc: 0.587179 | Val Loss: 0.231885, Val Acc: 0.525773\n",
      "Epoch 3042 - Train Loss: 0.219327, Train Acc: 0.587179 | Val Loss: 0.231867, Val Acc: 0.525773\n",
      "Epoch 3043 - Train Loss: 0.219308, Train Acc: 0.587179 | Val Loss: 0.231849, Val Acc: 0.525773\n",
      "Epoch 3044 - Train Loss: 0.219290, Train Acc: 0.587179 | Val Loss: 0.231831, Val Acc: 0.525773\n",
      "Epoch 3045 - Train Loss: 0.219271, Train Acc: 0.587179 | Val Loss: 0.231812, Val Acc: 0.525773\n",
      "Epoch 3046 - Train Loss: 0.219253, Train Acc: 0.587179 | Val Loss: 0.231794, Val Acc: 0.525773\n",
      "Epoch 3047 - Train Loss: 0.219234, Train Acc: 0.587179 | Val Loss: 0.231776, Val Acc: 0.525773\n",
      "Epoch 3048 - Train Loss: 0.219216, Train Acc: 0.587179 | Val Loss: 0.231758, Val Acc: 0.536082\n",
      "Epoch 3049 - Train Loss: 0.219197, Train Acc: 0.587179 | Val Loss: 0.231739, Val Acc: 0.536082\n",
      "Epoch 3050 - Train Loss: 0.219178, Train Acc: 0.587179 | Val Loss: 0.231721, Val Acc: 0.536082\n",
      "Epoch 3051 - Train Loss: 0.219160, Train Acc: 0.587179 | Val Loss: 0.231703, Val Acc: 0.536082\n",
      "Epoch 3052 - Train Loss: 0.219141, Train Acc: 0.587179 | Val Loss: 0.231685, Val Acc: 0.536082\n",
      "Epoch 3053 - Train Loss: 0.219123, Train Acc: 0.587179 | Val Loss: 0.231667, Val Acc: 0.536082\n",
      "Epoch 3054 - Train Loss: 0.219104, Train Acc: 0.587179 | Val Loss: 0.231648, Val Acc: 0.536082\n",
      "Epoch 3055 - Train Loss: 0.219086, Train Acc: 0.587179 | Val Loss: 0.231630, Val Acc: 0.536082\n",
      "Epoch 3056 - Train Loss: 0.219067, Train Acc: 0.587179 | Val Loss: 0.231612, Val Acc: 0.536082\n",
      "Epoch 3057 - Train Loss: 0.219049, Train Acc: 0.587179 | Val Loss: 0.231594, Val Acc: 0.536082\n",
      "Epoch 3058 - Train Loss: 0.219030, Train Acc: 0.587179 | Val Loss: 0.231575, Val Acc: 0.536082\n",
      "Epoch 3059 - Train Loss: 0.219011, Train Acc: 0.587179 | Val Loss: 0.231557, Val Acc: 0.536082\n",
      "Epoch 3060 - Train Loss: 0.218993, Train Acc: 0.587179 | Val Loss: 0.231539, Val Acc: 0.536082\n",
      "Epoch 3061 - Train Loss: 0.218974, Train Acc: 0.587179 | Val Loss: 0.231521, Val Acc: 0.536082\n",
      "Epoch 3062 - Train Loss: 0.218956, Train Acc: 0.587179 | Val Loss: 0.231503, Val Acc: 0.536082\n",
      "Epoch 3063 - Train Loss: 0.218937, Train Acc: 0.587179 | Val Loss: 0.231484, Val Acc: 0.536082\n",
      "Epoch 3064 - Train Loss: 0.218919, Train Acc: 0.587179 | Val Loss: 0.231466, Val Acc: 0.536082\n",
      "Epoch 3065 - Train Loss: 0.218900, Train Acc: 0.587179 | Val Loss: 0.231448, Val Acc: 0.536082\n",
      "Epoch 3066 - Train Loss: 0.218882, Train Acc: 0.587179 | Val Loss: 0.231430, Val Acc: 0.536082\n",
      "Epoch 3067 - Train Loss: 0.218863, Train Acc: 0.587179 | Val Loss: 0.231412, Val Acc: 0.536082\n",
      "Epoch 3068 - Train Loss: 0.218845, Train Acc: 0.587179 | Val Loss: 0.231393, Val Acc: 0.536082\n",
      "Epoch 3069 - Train Loss: 0.218826, Train Acc: 0.587179 | Val Loss: 0.231375, Val Acc: 0.536082\n",
      "Epoch 3070 - Train Loss: 0.218808, Train Acc: 0.587179 | Val Loss: 0.231357, Val Acc: 0.536082\n",
      "Epoch 3071 - Train Loss: 0.218789, Train Acc: 0.587179 | Val Loss: 0.231339, Val Acc: 0.536082\n",
      "Epoch 3072 - Train Loss: 0.218771, Train Acc: 0.587179 | Val Loss: 0.231321, Val Acc: 0.536082\n",
      "Epoch 3073 - Train Loss: 0.218752, Train Acc: 0.587179 | Val Loss: 0.231302, Val Acc: 0.536082\n",
      "Epoch 3074 - Train Loss: 0.218733, Train Acc: 0.587179 | Val Loss: 0.231284, Val Acc: 0.536082\n",
      "Epoch 3075 - Train Loss: 0.218715, Train Acc: 0.587179 | Val Loss: 0.231266, Val Acc: 0.536082\n",
      "Epoch 3076 - Train Loss: 0.218696, Train Acc: 0.587179 | Val Loss: 0.231248, Val Acc: 0.536082\n",
      "Epoch 3077 - Train Loss: 0.218678, Train Acc: 0.587179 | Val Loss: 0.231230, Val Acc: 0.536082\n",
      "Epoch 3078 - Train Loss: 0.218659, Train Acc: 0.587179 | Val Loss: 0.231211, Val Acc: 0.536082\n",
      "Epoch 3079 - Train Loss: 0.218641, Train Acc: 0.587179 | Val Loss: 0.231193, Val Acc: 0.536082\n",
      "Epoch 3080 - Train Loss: 0.218622, Train Acc: 0.587179 | Val Loss: 0.231175, Val Acc: 0.536082\n",
      "Epoch 3081 - Train Loss: 0.218604, Train Acc: 0.587179 | Val Loss: 0.231157, Val Acc: 0.536082\n",
      "Epoch 3082 - Train Loss: 0.218585, Train Acc: 0.587179 | Val Loss: 0.231139, Val Acc: 0.536082\n",
      "Epoch 3083 - Train Loss: 0.218567, Train Acc: 0.587179 | Val Loss: 0.231120, Val Acc: 0.536082\n",
      "Epoch 3084 - Train Loss: 0.218548, Train Acc: 0.587179 | Val Loss: 0.231102, Val Acc: 0.536082\n",
      "Epoch 3085 - Train Loss: 0.218530, Train Acc: 0.587179 | Val Loss: 0.231084, Val Acc: 0.536082\n",
      "Epoch 3086 - Train Loss: 0.218511, Train Acc: 0.587179 | Val Loss: 0.231066, Val Acc: 0.536082\n",
      "Epoch 3087 - Train Loss: 0.218493, Train Acc: 0.587179 | Val Loss: 0.231048, Val Acc: 0.536082\n",
      "Epoch 3088 - Train Loss: 0.218474, Train Acc: 0.587179 | Val Loss: 0.231030, Val Acc: 0.536082\n",
      "Epoch 3089 - Train Loss: 0.218456, Train Acc: 0.587179 | Val Loss: 0.231011, Val Acc: 0.536082\n",
      "Epoch 3090 - Train Loss: 0.218438, Train Acc: 0.587179 | Val Loss: 0.230993, Val Acc: 0.536082\n",
      "Epoch 3091 - Train Loss: 0.218419, Train Acc: 0.587179 | Val Loss: 0.230975, Val Acc: 0.536082\n",
      "Epoch 3092 - Train Loss: 0.218401, Train Acc: 0.587179 | Val Loss: 0.230957, Val Acc: 0.536082\n",
      "Epoch 3093 - Train Loss: 0.218382, Train Acc: 0.587179 | Val Loss: 0.230939, Val Acc: 0.536082\n",
      "Epoch 3094 - Train Loss: 0.218364, Train Acc: 0.587179 | Val Loss: 0.230920, Val Acc: 0.536082\n",
      "Epoch 3095 - Train Loss: 0.218345, Train Acc: 0.587179 | Val Loss: 0.230902, Val Acc: 0.536082\n",
      "Epoch 3096 - Train Loss: 0.218327, Train Acc: 0.587179 | Val Loss: 0.230884, Val Acc: 0.536082\n",
      "Epoch 3097 - Train Loss: 0.218308, Train Acc: 0.587179 | Val Loss: 0.230866, Val Acc: 0.536082\n",
      "Epoch 3098 - Train Loss: 0.218290, Train Acc: 0.587179 | Val Loss: 0.230848, Val Acc: 0.536082\n",
      "Epoch 3099 - Train Loss: 0.218271, Train Acc: 0.588462 | Val Loss: 0.230830, Val Acc: 0.536082\n",
      "Epoch 3100 - Train Loss: 0.218253, Train Acc: 0.588462 | Val Loss: 0.230811, Val Acc: 0.536082\n",
      "Epoch 3101 - Train Loss: 0.218234, Train Acc: 0.588462 | Val Loss: 0.230793, Val Acc: 0.536082\n",
      "Epoch 3102 - Train Loss: 0.218216, Train Acc: 0.588462 | Val Loss: 0.230775, Val Acc: 0.536082\n",
      "Epoch 3103 - Train Loss: 0.218197, Train Acc: 0.588462 | Val Loss: 0.230757, Val Acc: 0.536082\n",
      "Epoch 3104 - Train Loss: 0.218179, Train Acc: 0.588462 | Val Loss: 0.230739, Val Acc: 0.536082\n",
      "Epoch 3105 - Train Loss: 0.218161, Train Acc: 0.588462 | Val Loss: 0.230721, Val Acc: 0.536082\n",
      "Epoch 3106 - Train Loss: 0.218142, Train Acc: 0.588462 | Val Loss: 0.230703, Val Acc: 0.536082\n",
      "Epoch 3107 - Train Loss: 0.218124, Train Acc: 0.588462 | Val Loss: 0.230684, Val Acc: 0.536082\n",
      "Epoch 3108 - Train Loss: 0.218105, Train Acc: 0.588462 | Val Loss: 0.230666, Val Acc: 0.536082\n",
      "Epoch 3109 - Train Loss: 0.218087, Train Acc: 0.588462 | Val Loss: 0.230648, Val Acc: 0.536082\n",
      "Epoch 3110 - Train Loss: 0.218068, Train Acc: 0.588462 | Val Loss: 0.230630, Val Acc: 0.536082\n",
      "Epoch 3111 - Train Loss: 0.218050, Train Acc: 0.588462 | Val Loss: 0.230612, Val Acc: 0.536082\n",
      "Epoch 3112 - Train Loss: 0.218032, Train Acc: 0.588462 | Val Loss: 0.230594, Val Acc: 0.536082\n",
      "Epoch 3113 - Train Loss: 0.218013, Train Acc: 0.588462 | Val Loss: 0.230576, Val Acc: 0.536082\n",
      "Epoch 3114 - Train Loss: 0.217995, Train Acc: 0.588462 | Val Loss: 0.230557, Val Acc: 0.536082\n",
      "Epoch 3115 - Train Loss: 0.217976, Train Acc: 0.588462 | Val Loss: 0.230539, Val Acc: 0.536082\n",
      "Epoch 3116 - Train Loss: 0.217958, Train Acc: 0.588462 | Val Loss: 0.230521, Val Acc: 0.536082\n",
      "Epoch 3117 - Train Loss: 0.217939, Train Acc: 0.588462 | Val Loss: 0.230503, Val Acc: 0.536082\n",
      "Epoch 3118 - Train Loss: 0.217921, Train Acc: 0.588462 | Val Loss: 0.230485, Val Acc: 0.536082\n",
      "Epoch 3119 - Train Loss: 0.217903, Train Acc: 0.588462 | Val Loss: 0.230467, Val Acc: 0.536082\n",
      "Epoch 3120 - Train Loss: 0.217884, Train Acc: 0.588462 | Val Loss: 0.230449, Val Acc: 0.536082\n",
      "Epoch 3121 - Train Loss: 0.217866, Train Acc: 0.588462 | Val Loss: 0.230431, Val Acc: 0.536082\n",
      "Epoch 3122 - Train Loss: 0.217847, Train Acc: 0.588462 | Val Loss: 0.230412, Val Acc: 0.536082\n",
      "Epoch 3123 - Train Loss: 0.217829, Train Acc: 0.588462 | Val Loss: 0.230394, Val Acc: 0.536082\n",
      "Epoch 3124 - Train Loss: 0.217811, Train Acc: 0.588462 | Val Loss: 0.230376, Val Acc: 0.536082\n",
      "Epoch 3125 - Train Loss: 0.217792, Train Acc: 0.588462 | Val Loss: 0.230358, Val Acc: 0.536082\n",
      "Epoch 3126 - Train Loss: 0.217774, Train Acc: 0.588462 | Val Loss: 0.230340, Val Acc: 0.536082\n",
      "Epoch 3127 - Train Loss: 0.217755, Train Acc: 0.588462 | Val Loss: 0.230322, Val Acc: 0.536082\n",
      "Epoch 3128 - Train Loss: 0.217737, Train Acc: 0.588462 | Val Loss: 0.230304, Val Acc: 0.536082\n",
      "Epoch 3129 - Train Loss: 0.217719, Train Acc: 0.588462 | Val Loss: 0.230286, Val Acc: 0.536082\n",
      "Epoch 3130 - Train Loss: 0.217700, Train Acc: 0.588462 | Val Loss: 0.230268, Val Acc: 0.536082\n",
      "Epoch 3131 - Train Loss: 0.217682, Train Acc: 0.588462 | Val Loss: 0.230249, Val Acc: 0.536082\n",
      "Epoch 3132 - Train Loss: 0.217664, Train Acc: 0.588462 | Val Loss: 0.230231, Val Acc: 0.536082\n",
      "Epoch 3133 - Train Loss: 0.217645, Train Acc: 0.588462 | Val Loss: 0.230213, Val Acc: 0.536082\n",
      "Epoch 3134 - Train Loss: 0.217627, Train Acc: 0.588462 | Val Loss: 0.230195, Val Acc: 0.536082\n",
      "Epoch 3135 - Train Loss: 0.217608, Train Acc: 0.588462 | Val Loss: 0.230177, Val Acc: 0.536082\n",
      "Epoch 3136 - Train Loss: 0.217590, Train Acc: 0.588462 | Val Loss: 0.230159, Val Acc: 0.536082\n",
      "Epoch 3137 - Train Loss: 0.217572, Train Acc: 0.588462 | Val Loss: 0.230141, Val Acc: 0.536082\n",
      "Epoch 3138 - Train Loss: 0.217553, Train Acc: 0.588462 | Val Loss: 0.230123, Val Acc: 0.536082\n",
      "Epoch 3139 - Train Loss: 0.217535, Train Acc: 0.588462 | Val Loss: 0.230105, Val Acc: 0.536082\n",
      "Epoch 3140 - Train Loss: 0.217517, Train Acc: 0.588462 | Val Loss: 0.230086, Val Acc: 0.536082\n",
      "Epoch 3141 - Train Loss: 0.217498, Train Acc: 0.588462 | Val Loss: 0.230068, Val Acc: 0.536082\n",
      "Epoch 3142 - Train Loss: 0.217480, Train Acc: 0.588462 | Val Loss: 0.230050, Val Acc: 0.536082\n",
      "Epoch 3143 - Train Loss: 0.217462, Train Acc: 0.588462 | Val Loss: 0.230032, Val Acc: 0.536082\n",
      "Epoch 3144 - Train Loss: 0.217443, Train Acc: 0.589744 | Val Loss: 0.230014, Val Acc: 0.536082\n",
      "Epoch 3145 - Train Loss: 0.217425, Train Acc: 0.589744 | Val Loss: 0.229996, Val Acc: 0.536082\n",
      "Epoch 3146 - Train Loss: 0.217407, Train Acc: 0.589744 | Val Loss: 0.229978, Val Acc: 0.536082\n",
      "Epoch 3147 - Train Loss: 0.217388, Train Acc: 0.589744 | Val Loss: 0.229960, Val Acc: 0.536082\n",
      "Epoch 3148 - Train Loss: 0.217370, Train Acc: 0.589744 | Val Loss: 0.229942, Val Acc: 0.536082\n",
      "Epoch 3149 - Train Loss: 0.217352, Train Acc: 0.589744 | Val Loss: 0.229924, Val Acc: 0.536082\n",
      "Epoch 3150 - Train Loss: 0.217333, Train Acc: 0.589744 | Val Loss: 0.229905, Val Acc: 0.536082\n",
      "Epoch 3151 - Train Loss: 0.217315, Train Acc: 0.589744 | Val Loss: 0.229887, Val Acc: 0.536082\n",
      "Epoch 3152 - Train Loss: 0.217297, Train Acc: 0.589744 | Val Loss: 0.229869, Val Acc: 0.536082\n",
      "Epoch 3153 - Train Loss: 0.217278, Train Acc: 0.589744 | Val Loss: 0.229851, Val Acc: 0.536082\n",
      "Epoch 3154 - Train Loss: 0.217260, Train Acc: 0.589744 | Val Loss: 0.229833, Val Acc: 0.536082\n",
      "Epoch 3155 - Train Loss: 0.217242, Train Acc: 0.589744 | Val Loss: 0.229815, Val Acc: 0.536082\n",
      "Epoch 3156 - Train Loss: 0.217223, Train Acc: 0.589744 | Val Loss: 0.229797, Val Acc: 0.536082\n",
      "Epoch 3157 - Train Loss: 0.217205, Train Acc: 0.589744 | Val Loss: 0.229779, Val Acc: 0.536082\n",
      "Epoch 3158 - Train Loss: 0.217187, Train Acc: 0.589744 | Val Loss: 0.229761, Val Acc: 0.536082\n",
      "Epoch 3159 - Train Loss: 0.217168, Train Acc: 0.589744 | Val Loss: 0.229743, Val Acc: 0.536082\n",
      "Epoch 3160 - Train Loss: 0.217150, Train Acc: 0.589744 | Val Loss: 0.229725, Val Acc: 0.536082\n",
      "Epoch 3161 - Train Loss: 0.217132, Train Acc: 0.589744 | Val Loss: 0.229706, Val Acc: 0.536082\n",
      "Epoch 3162 - Train Loss: 0.217114, Train Acc: 0.589744 | Val Loss: 0.229688, Val Acc: 0.536082\n",
      "Epoch 3163 - Train Loss: 0.217095, Train Acc: 0.589744 | Val Loss: 0.229670, Val Acc: 0.536082\n",
      "Epoch 3164 - Train Loss: 0.217077, Train Acc: 0.589744 | Val Loss: 0.229652, Val Acc: 0.536082\n",
      "Epoch 3165 - Train Loss: 0.217059, Train Acc: 0.589744 | Val Loss: 0.229634, Val Acc: 0.536082\n",
      "Epoch 3166 - Train Loss: 0.217040, Train Acc: 0.589744 | Val Loss: 0.229616, Val Acc: 0.536082\n",
      "Epoch 3167 - Train Loss: 0.217022, Train Acc: 0.589744 | Val Loss: 0.229598, Val Acc: 0.536082\n",
      "Epoch 3168 - Train Loss: 0.217004, Train Acc: 0.589744 | Val Loss: 0.229580, Val Acc: 0.536082\n",
      "Epoch 3169 - Train Loss: 0.216986, Train Acc: 0.589744 | Val Loss: 0.229562, Val Acc: 0.536082\n",
      "Epoch 3170 - Train Loss: 0.216967, Train Acc: 0.589744 | Val Loss: 0.229544, Val Acc: 0.536082\n",
      "Epoch 3171 - Train Loss: 0.216949, Train Acc: 0.589744 | Val Loss: 0.229526, Val Acc: 0.536082\n",
      "Epoch 3172 - Train Loss: 0.216931, Train Acc: 0.589744 | Val Loss: 0.229508, Val Acc: 0.536082\n",
      "Epoch 3173 - Train Loss: 0.216912, Train Acc: 0.589744 | Val Loss: 0.229490, Val Acc: 0.536082\n",
      "Epoch 3174 - Train Loss: 0.216894, Train Acc: 0.589744 | Val Loss: 0.229472, Val Acc: 0.536082\n",
      "Epoch 3175 - Train Loss: 0.216876, Train Acc: 0.589744 | Val Loss: 0.229453, Val Acc: 0.536082\n",
      "Epoch 3176 - Train Loss: 0.216858, Train Acc: 0.589744 | Val Loss: 0.229435, Val Acc: 0.536082\n",
      "Epoch 3177 - Train Loss: 0.216839, Train Acc: 0.589744 | Val Loss: 0.229417, Val Acc: 0.536082\n",
      "Epoch 3178 - Train Loss: 0.216821, Train Acc: 0.589744 | Val Loss: 0.229399, Val Acc: 0.536082\n",
      "Epoch 3179 - Train Loss: 0.216803, Train Acc: 0.589744 | Val Loss: 0.229381, Val Acc: 0.536082\n",
      "Epoch 3180 - Train Loss: 0.216785, Train Acc: 0.589744 | Val Loss: 0.229363, Val Acc: 0.536082\n",
      "Epoch 3181 - Train Loss: 0.216766, Train Acc: 0.589744 | Val Loss: 0.229345, Val Acc: 0.536082\n",
      "Epoch 3182 - Train Loss: 0.216748, Train Acc: 0.589744 | Val Loss: 0.229327, Val Acc: 0.536082\n",
      "Epoch 3183 - Train Loss: 0.216730, Train Acc: 0.589744 | Val Loss: 0.229309, Val Acc: 0.536082\n",
      "Epoch 3184 - Train Loss: 0.216712, Train Acc: 0.589744 | Val Loss: 0.229291, Val Acc: 0.536082\n",
      "Epoch 3185 - Train Loss: 0.216693, Train Acc: 0.589744 | Val Loss: 0.229273, Val Acc: 0.536082\n",
      "Epoch 3186 - Train Loss: 0.216675, Train Acc: 0.589744 | Val Loss: 0.229255, Val Acc: 0.536082\n",
      "Epoch 3187 - Train Loss: 0.216657, Train Acc: 0.589744 | Val Loss: 0.229237, Val Acc: 0.536082\n",
      "Epoch 3188 - Train Loss: 0.216639, Train Acc: 0.589744 | Val Loss: 0.229219, Val Acc: 0.536082\n",
      "Epoch 3189 - Train Loss: 0.216620, Train Acc: 0.589744 | Val Loss: 0.229201, Val Acc: 0.536082\n",
      "Epoch 3190 - Train Loss: 0.216602, Train Acc: 0.589744 | Val Loss: 0.229183, Val Acc: 0.536082\n",
      "Epoch 3191 - Train Loss: 0.216584, Train Acc: 0.589744 | Val Loss: 0.229165, Val Acc: 0.536082\n",
      "Epoch 3192 - Train Loss: 0.216566, Train Acc: 0.589744 | Val Loss: 0.229147, Val Acc: 0.536082\n",
      "Epoch 3193 - Train Loss: 0.216548, Train Acc: 0.589744 | Val Loss: 0.229129, Val Acc: 0.536082\n",
      "Epoch 3194 - Train Loss: 0.216529, Train Acc: 0.591026 | Val Loss: 0.229111, Val Acc: 0.536082\n",
      "Epoch 3195 - Train Loss: 0.216511, Train Acc: 0.591026 | Val Loss: 0.229093, Val Acc: 0.536082\n",
      "Epoch 3196 - Train Loss: 0.216493, Train Acc: 0.591026 | Val Loss: 0.229074, Val Acc: 0.536082\n",
      "Epoch 3197 - Train Loss: 0.216475, Train Acc: 0.591026 | Val Loss: 0.229056, Val Acc: 0.536082\n",
      "Epoch 3198 - Train Loss: 0.216456, Train Acc: 0.591026 | Val Loss: 0.229038, Val Acc: 0.536082\n",
      "Epoch 3199 - Train Loss: 0.216438, Train Acc: 0.591026 | Val Loss: 0.229020, Val Acc: 0.536082\n",
      "Epoch 3200 - Train Loss: 0.216420, Train Acc: 0.591026 | Val Loss: 0.229002, Val Acc: 0.536082\n",
      "Epoch 3201 - Train Loss: 0.216402, Train Acc: 0.591026 | Val Loss: 0.228984, Val Acc: 0.536082\n",
      "Epoch 3202 - Train Loss: 0.216384, Train Acc: 0.591026 | Val Loss: 0.228966, Val Acc: 0.536082\n",
      "Epoch 3203 - Train Loss: 0.216365, Train Acc: 0.591026 | Val Loss: 0.228948, Val Acc: 0.536082\n",
      "Epoch 3204 - Train Loss: 0.216347, Train Acc: 0.591026 | Val Loss: 0.228930, Val Acc: 0.536082\n",
      "Epoch 3205 - Train Loss: 0.216329, Train Acc: 0.591026 | Val Loss: 0.228912, Val Acc: 0.536082\n",
      "Epoch 3206 - Train Loss: 0.216311, Train Acc: 0.591026 | Val Loss: 0.228894, Val Acc: 0.536082\n",
      "Epoch 3207 - Train Loss: 0.216293, Train Acc: 0.591026 | Val Loss: 0.228876, Val Acc: 0.536082\n",
      "Epoch 3208 - Train Loss: 0.216274, Train Acc: 0.591026 | Val Loss: 0.228858, Val Acc: 0.536082\n",
      "Epoch 3209 - Train Loss: 0.216256, Train Acc: 0.591026 | Val Loss: 0.228840, Val Acc: 0.536082\n",
      "Epoch 3210 - Train Loss: 0.216238, Train Acc: 0.591026 | Val Loss: 0.228822, Val Acc: 0.536082\n",
      "Epoch 3211 - Train Loss: 0.216220, Train Acc: 0.591026 | Val Loss: 0.228804, Val Acc: 0.536082\n",
      "Epoch 3212 - Train Loss: 0.216202, Train Acc: 0.591026 | Val Loss: 0.228786, Val Acc: 0.536082\n",
      "Epoch 3213 - Train Loss: 0.216184, Train Acc: 0.591026 | Val Loss: 0.228768, Val Acc: 0.546392\n",
      "Epoch 3214 - Train Loss: 0.216165, Train Acc: 0.591026 | Val Loss: 0.228750, Val Acc: 0.546392\n",
      "Epoch 3215 - Train Loss: 0.216147, Train Acc: 0.591026 | Val Loss: 0.228732, Val Acc: 0.546392\n",
      "Epoch 3216 - Train Loss: 0.216129, Train Acc: 0.591026 | Val Loss: 0.228714, Val Acc: 0.546392\n",
      "Epoch 3217 - Train Loss: 0.216111, Train Acc: 0.591026 | Val Loss: 0.228696, Val Acc: 0.546392\n",
      "Epoch 3218 - Train Loss: 0.216093, Train Acc: 0.591026 | Val Loss: 0.228678, Val Acc: 0.546392\n",
      "Epoch 3219 - Train Loss: 0.216075, Train Acc: 0.591026 | Val Loss: 0.228660, Val Acc: 0.546392\n",
      "Epoch 3220 - Train Loss: 0.216056, Train Acc: 0.591026 | Val Loss: 0.228642, Val Acc: 0.546392\n",
      "Epoch 3221 - Train Loss: 0.216038, Train Acc: 0.591026 | Val Loss: 0.228624, Val Acc: 0.546392\n",
      "Epoch 3222 - Train Loss: 0.216020, Train Acc: 0.591026 | Val Loss: 0.228606, Val Acc: 0.546392\n",
      "Epoch 3223 - Train Loss: 0.216002, Train Acc: 0.591026 | Val Loss: 0.228588, Val Acc: 0.546392\n",
      "Epoch 3224 - Train Loss: 0.215984, Train Acc: 0.591026 | Val Loss: 0.228570, Val Acc: 0.546392\n",
      "Epoch 3225 - Train Loss: 0.215966, Train Acc: 0.591026 | Val Loss: 0.228552, Val Acc: 0.546392\n",
      "Epoch 3226 - Train Loss: 0.215948, Train Acc: 0.591026 | Val Loss: 0.228534, Val Acc: 0.546392\n",
      "Epoch 3227 - Train Loss: 0.215929, Train Acc: 0.591026 | Val Loss: 0.228516, Val Acc: 0.546392\n",
      "Epoch 3228 - Train Loss: 0.215911, Train Acc: 0.591026 | Val Loss: 0.228498, Val Acc: 0.546392\n",
      "Epoch 3229 - Train Loss: 0.215893, Train Acc: 0.591026 | Val Loss: 0.228481, Val Acc: 0.546392\n",
      "Epoch 3230 - Train Loss: 0.215875, Train Acc: 0.591026 | Val Loss: 0.228463, Val Acc: 0.546392\n",
      "Epoch 3231 - Train Loss: 0.215857, Train Acc: 0.591026 | Val Loss: 0.228445, Val Acc: 0.546392\n",
      "Epoch 3232 - Train Loss: 0.215839, Train Acc: 0.591026 | Val Loss: 0.228427, Val Acc: 0.546392\n",
      "Epoch 3233 - Train Loss: 0.215821, Train Acc: 0.591026 | Val Loss: 0.228409, Val Acc: 0.546392\n",
      "Epoch 3234 - Train Loss: 0.215802, Train Acc: 0.591026 | Val Loss: 0.228391, Val Acc: 0.546392\n",
      "Epoch 3235 - Train Loss: 0.215784, Train Acc: 0.591026 | Val Loss: 0.228373, Val Acc: 0.546392\n",
      "Epoch 3236 - Train Loss: 0.215766, Train Acc: 0.591026 | Val Loss: 0.228355, Val Acc: 0.546392\n",
      "Epoch 3237 - Train Loss: 0.215748, Train Acc: 0.591026 | Val Loss: 0.228337, Val Acc: 0.546392\n",
      "Epoch 3238 - Train Loss: 0.215730, Train Acc: 0.591026 | Val Loss: 0.228319, Val Acc: 0.546392\n",
      "Epoch 3239 - Train Loss: 0.215712, Train Acc: 0.591026 | Val Loss: 0.228301, Val Acc: 0.546392\n",
      "Epoch 3240 - Train Loss: 0.215694, Train Acc: 0.591026 | Val Loss: 0.228283, Val Acc: 0.546392\n",
      "Epoch 3241 - Train Loss: 0.215676, Train Acc: 0.591026 | Val Loss: 0.228265, Val Acc: 0.546392\n",
      "Epoch 3242 - Train Loss: 0.215658, Train Acc: 0.591026 | Val Loss: 0.228247, Val Acc: 0.546392\n",
      "Epoch 3243 - Train Loss: 0.215640, Train Acc: 0.591026 | Val Loss: 0.228229, Val Acc: 0.546392\n",
      "Epoch 3244 - Train Loss: 0.215621, Train Acc: 0.591026 | Val Loss: 0.228211, Val Acc: 0.546392\n",
      "Epoch 3245 - Train Loss: 0.215603, Train Acc: 0.591026 | Val Loss: 0.228193, Val Acc: 0.546392\n",
      "Epoch 3246 - Train Loss: 0.215585, Train Acc: 0.591026 | Val Loss: 0.228175, Val Acc: 0.546392\n",
      "Epoch 3247 - Train Loss: 0.215567, Train Acc: 0.591026 | Val Loss: 0.228157, Val Acc: 0.546392\n",
      "Epoch 3248 - Train Loss: 0.215549, Train Acc: 0.591026 | Val Loss: 0.228139, Val Acc: 0.546392\n",
      "Epoch 3249 - Train Loss: 0.215531, Train Acc: 0.591026 | Val Loss: 0.228121, Val Acc: 0.546392\n",
      "Epoch 3250 - Train Loss: 0.215513, Train Acc: 0.591026 | Val Loss: 0.228104, Val Acc: 0.546392\n",
      "Epoch 3251 - Train Loss: 0.215495, Train Acc: 0.591026 | Val Loss: 0.228086, Val Acc: 0.546392\n",
      "Epoch 3252 - Train Loss: 0.215477, Train Acc: 0.591026 | Val Loss: 0.228068, Val Acc: 0.546392\n",
      "Epoch 3253 - Train Loss: 0.215459, Train Acc: 0.591026 | Val Loss: 0.228050, Val Acc: 0.546392\n",
      "Epoch 3254 - Train Loss: 0.215441, Train Acc: 0.591026 | Val Loss: 0.228032, Val Acc: 0.546392\n",
      "Epoch 3255 - Train Loss: 0.215423, Train Acc: 0.591026 | Val Loss: 0.228014, Val Acc: 0.546392\n",
      "Epoch 3256 - Train Loss: 0.215404, Train Acc: 0.591026 | Val Loss: 0.227997, Val Acc: 0.546392\n",
      "Epoch 3257 - Train Loss: 0.215386, Train Acc: 0.591026 | Val Loss: 0.227979, Val Acc: 0.546392\n",
      "Epoch 3258 - Train Loss: 0.215368, Train Acc: 0.591026 | Val Loss: 0.227961, Val Acc: 0.546392\n",
      "Epoch 3259 - Train Loss: 0.215350, Train Acc: 0.591026 | Val Loss: 0.227943, Val Acc: 0.546392\n",
      "Epoch 3260 - Train Loss: 0.215332, Train Acc: 0.591026 | Val Loss: 0.227925, Val Acc: 0.546392\n",
      "Epoch 3261 - Train Loss: 0.215314, Train Acc: 0.591026 | Val Loss: 0.227907, Val Acc: 0.546392\n",
      "Epoch 3262 - Train Loss: 0.215296, Train Acc: 0.591026 | Val Loss: 0.227890, Val Acc: 0.546392\n",
      "Epoch 3263 - Train Loss: 0.215278, Train Acc: 0.591026 | Val Loss: 0.227872, Val Acc: 0.546392\n",
      "Epoch 3264 - Train Loss: 0.215260, Train Acc: 0.592308 | Val Loss: 0.227854, Val Acc: 0.546392\n",
      "Epoch 3265 - Train Loss: 0.215242, Train Acc: 0.592308 | Val Loss: 0.227836, Val Acc: 0.556701\n",
      "Epoch 3266 - Train Loss: 0.215224, Train Acc: 0.592308 | Val Loss: 0.227818, Val Acc: 0.556701\n",
      "Epoch 3267 - Train Loss: 0.215206, Train Acc: 0.592308 | Val Loss: 0.227800, Val Acc: 0.556701\n",
      "Epoch 3268 - Train Loss: 0.215188, Train Acc: 0.592308 | Val Loss: 0.227782, Val Acc: 0.556701\n",
      "Epoch 3269 - Train Loss: 0.215170, Train Acc: 0.592308 | Val Loss: 0.227765, Val Acc: 0.556701\n",
      "Epoch 3270 - Train Loss: 0.215152, Train Acc: 0.592308 | Val Loss: 0.227747, Val Acc: 0.556701\n",
      "Epoch 3271 - Train Loss: 0.215134, Train Acc: 0.592308 | Val Loss: 0.227729, Val Acc: 0.556701\n",
      "Epoch 3272 - Train Loss: 0.215116, Train Acc: 0.592308 | Val Loss: 0.227711, Val Acc: 0.556701\n",
      "Epoch 3273 - Train Loss: 0.215098, Train Acc: 0.592308 | Val Loss: 0.227693, Val Acc: 0.556701\n",
      "Epoch 3274 - Train Loss: 0.215080, Train Acc: 0.592308 | Val Loss: 0.227675, Val Acc: 0.556701\n",
      "Epoch 3275 - Train Loss: 0.215062, Train Acc: 0.592308 | Val Loss: 0.227658, Val Acc: 0.556701\n",
      "Epoch 3276 - Train Loss: 0.215044, Train Acc: 0.592308 | Val Loss: 0.227640, Val Acc: 0.556701\n",
      "Epoch 3277 - Train Loss: 0.215026, Train Acc: 0.592308 | Val Loss: 0.227622, Val Acc: 0.556701\n",
      "Epoch 3278 - Train Loss: 0.215008, Train Acc: 0.592308 | Val Loss: 0.227604, Val Acc: 0.556701\n",
      "Epoch 3279 - Train Loss: 0.214990, Train Acc: 0.592308 | Val Loss: 0.227586, Val Acc: 0.556701\n",
      "Epoch 3280 - Train Loss: 0.214972, Train Acc: 0.592308 | Val Loss: 0.227568, Val Acc: 0.556701\n",
      "Epoch 3281 - Train Loss: 0.214954, Train Acc: 0.592308 | Val Loss: 0.227551, Val Acc: 0.556701\n",
      "Epoch 3282 - Train Loss: 0.214936, Train Acc: 0.592308 | Val Loss: 0.227533, Val Acc: 0.556701\n",
      "Epoch 3283 - Train Loss: 0.214918, Train Acc: 0.592308 | Val Loss: 0.227515, Val Acc: 0.556701\n",
      "Epoch 3284 - Train Loss: 0.214900, Train Acc: 0.592308 | Val Loss: 0.227497, Val Acc: 0.556701\n",
      "Epoch 3285 - Train Loss: 0.214882, Train Acc: 0.592308 | Val Loss: 0.227479, Val Acc: 0.556701\n",
      "Epoch 3286 - Train Loss: 0.214864, Train Acc: 0.592308 | Val Loss: 0.227462, Val Acc: 0.556701\n",
      "Epoch 3287 - Train Loss: 0.214846, Train Acc: 0.592308 | Val Loss: 0.227444, Val Acc: 0.556701\n",
      "Epoch 3288 - Train Loss: 0.214828, Train Acc: 0.592308 | Val Loss: 0.227426, Val Acc: 0.556701\n",
      "Epoch 3289 - Train Loss: 0.214810, Train Acc: 0.592308 | Val Loss: 0.227408, Val Acc: 0.556701\n",
      "Epoch 3290 - Train Loss: 0.214792, Train Acc: 0.593590 | Val Loss: 0.227390, Val Acc: 0.556701\n",
      "Epoch 3291 - Train Loss: 0.214774, Train Acc: 0.593590 | Val Loss: 0.227372, Val Acc: 0.556701\n",
      "Epoch 3292 - Train Loss: 0.214756, Train Acc: 0.593590 | Val Loss: 0.227355, Val Acc: 0.556701\n",
      "Epoch 3293 - Train Loss: 0.214738, Train Acc: 0.593590 | Val Loss: 0.227337, Val Acc: 0.556701\n",
      "Epoch 3294 - Train Loss: 0.214720, Train Acc: 0.593590 | Val Loss: 0.227319, Val Acc: 0.556701\n",
      "Epoch 3295 - Train Loss: 0.214702, Train Acc: 0.593590 | Val Loss: 0.227301, Val Acc: 0.556701\n",
      "Epoch 3296 - Train Loss: 0.214684, Train Acc: 0.593590 | Val Loss: 0.227283, Val Acc: 0.556701\n",
      "Epoch 3297 - Train Loss: 0.214666, Train Acc: 0.593590 | Val Loss: 0.227266, Val Acc: 0.556701\n",
      "Epoch 3298 - Train Loss: 0.214648, Train Acc: 0.593590 | Val Loss: 0.227248, Val Acc: 0.556701\n",
      "Epoch 3299 - Train Loss: 0.214630, Train Acc: 0.593590 | Val Loss: 0.227230, Val Acc: 0.556701\n",
      "Epoch 3300 - Train Loss: 0.214612, Train Acc: 0.593590 | Val Loss: 0.227212, Val Acc: 0.556701\n",
      "Epoch 3301 - Train Loss: 0.214594, Train Acc: 0.593590 | Val Loss: 0.227194, Val Acc: 0.556701\n",
      "Epoch 3302 - Train Loss: 0.214576, Train Acc: 0.593590 | Val Loss: 0.227177, Val Acc: 0.556701\n",
      "Epoch 3303 - Train Loss: 0.214558, Train Acc: 0.593590 | Val Loss: 0.227159, Val Acc: 0.556701\n",
      "Epoch 3304 - Train Loss: 0.214540, Train Acc: 0.593590 | Val Loss: 0.227141, Val Acc: 0.556701\n",
      "Epoch 3305 - Train Loss: 0.214522, Train Acc: 0.593590 | Val Loss: 0.227123, Val Acc: 0.556701\n",
      "Epoch 3306 - Train Loss: 0.214504, Train Acc: 0.593590 | Val Loss: 0.227105, Val Acc: 0.556701\n",
      "Epoch 3307 - Train Loss: 0.214486, Train Acc: 0.593590 | Val Loss: 0.227088, Val Acc: 0.556701\n",
      "Epoch 3308 - Train Loss: 0.214469, Train Acc: 0.593590 | Val Loss: 0.227070, Val Acc: 0.556701\n",
      "Epoch 3309 - Train Loss: 0.214451, Train Acc: 0.593590 | Val Loss: 0.227052, Val Acc: 0.556701\n",
      "Epoch 3310 - Train Loss: 0.214433, Train Acc: 0.593590 | Val Loss: 0.227034, Val Acc: 0.556701\n",
      "Epoch 3311 - Train Loss: 0.214415, Train Acc: 0.593590 | Val Loss: 0.227017, Val Acc: 0.556701\n",
      "Epoch 3312 - Train Loss: 0.214397, Train Acc: 0.593590 | Val Loss: 0.226999, Val Acc: 0.546392\n",
      "Epoch 3313 - Train Loss: 0.214379, Train Acc: 0.593590 | Val Loss: 0.226981, Val Acc: 0.546392\n",
      "Epoch 3314 - Train Loss: 0.214361, Train Acc: 0.593590 | Val Loss: 0.226963, Val Acc: 0.546392\n",
      "Epoch 3315 - Train Loss: 0.214343, Train Acc: 0.593590 | Val Loss: 0.226945, Val Acc: 0.546392\n",
      "Epoch 3316 - Train Loss: 0.214325, Train Acc: 0.593590 | Val Loss: 0.226928, Val Acc: 0.546392\n",
      "Epoch 3317 - Train Loss: 0.214307, Train Acc: 0.593590 | Val Loss: 0.226910, Val Acc: 0.546392\n",
      "Epoch 3318 - Train Loss: 0.214289, Train Acc: 0.593590 | Val Loss: 0.226892, Val Acc: 0.546392\n",
      "Epoch 3319 - Train Loss: 0.214271, Train Acc: 0.593590 | Val Loss: 0.226874, Val Acc: 0.546392\n",
      "Epoch 3320 - Train Loss: 0.214254, Train Acc: 0.593590 | Val Loss: 0.226857, Val Acc: 0.546392\n",
      "Epoch 3321 - Train Loss: 0.214236, Train Acc: 0.593590 | Val Loss: 0.226839, Val Acc: 0.546392\n",
      "Epoch 3322 - Train Loss: 0.214218, Train Acc: 0.593590 | Val Loss: 0.226821, Val Acc: 0.546392\n",
      "Epoch 3323 - Train Loss: 0.214200, Train Acc: 0.593590 | Val Loss: 0.226803, Val Acc: 0.546392\n",
      "Epoch 3324 - Train Loss: 0.214182, Train Acc: 0.593590 | Val Loss: 0.226786, Val Acc: 0.546392\n",
      "Epoch 3325 - Train Loss: 0.214164, Train Acc: 0.593590 | Val Loss: 0.226768, Val Acc: 0.546392\n",
      "Epoch 3326 - Train Loss: 0.214146, Train Acc: 0.594872 | Val Loss: 0.226750, Val Acc: 0.546392\n",
      "Epoch 3327 - Train Loss: 0.214128, Train Acc: 0.594872 | Val Loss: 0.226732, Val Acc: 0.546392\n",
      "Epoch 3328 - Train Loss: 0.214110, Train Acc: 0.594872 | Val Loss: 0.226715, Val Acc: 0.546392\n",
      "Epoch 3329 - Train Loss: 0.214092, Train Acc: 0.594872 | Val Loss: 0.226697, Val Acc: 0.546392\n",
      "Epoch 3330 - Train Loss: 0.214075, Train Acc: 0.594872 | Val Loss: 0.226679, Val Acc: 0.546392\n",
      "Epoch 3331 - Train Loss: 0.214057, Train Acc: 0.594872 | Val Loss: 0.226661, Val Acc: 0.546392\n",
      "Epoch 3332 - Train Loss: 0.214039, Train Acc: 0.594872 | Val Loss: 0.226644, Val Acc: 0.546392\n",
      "Epoch 3333 - Train Loss: 0.214021, Train Acc: 0.594872 | Val Loss: 0.226626, Val Acc: 0.546392\n",
      "Epoch 3334 - Train Loss: 0.214003, Train Acc: 0.594872 | Val Loss: 0.226608, Val Acc: 0.546392\n",
      "Epoch 3335 - Train Loss: 0.213985, Train Acc: 0.594872 | Val Loss: 0.226590, Val Acc: 0.546392\n",
      "Epoch 3336 - Train Loss: 0.213967, Train Acc: 0.594872 | Val Loss: 0.226573, Val Acc: 0.546392\n",
      "Epoch 3337 - Train Loss: 0.213950, Train Acc: 0.594872 | Val Loss: 0.226555, Val Acc: 0.546392\n",
      "Epoch 3338 - Train Loss: 0.213932, Train Acc: 0.594872 | Val Loss: 0.226537, Val Acc: 0.546392\n",
      "Epoch 3339 - Train Loss: 0.213914, Train Acc: 0.594872 | Val Loss: 0.226520, Val Acc: 0.546392\n",
      "Epoch 3340 - Train Loss: 0.213896, Train Acc: 0.594872 | Val Loss: 0.226502, Val Acc: 0.546392\n",
      "Epoch 3341 - Train Loss: 0.213878, Train Acc: 0.594872 | Val Loss: 0.226484, Val Acc: 0.546392\n",
      "Epoch 3342 - Train Loss: 0.213860, Train Acc: 0.594872 | Val Loss: 0.226466, Val Acc: 0.546392\n",
      "Epoch 3343 - Train Loss: 0.213842, Train Acc: 0.594872 | Val Loss: 0.226449, Val Acc: 0.546392\n",
      "Epoch 3344 - Train Loss: 0.213825, Train Acc: 0.596154 | Val Loss: 0.226431, Val Acc: 0.546392\n",
      "Epoch 3345 - Train Loss: 0.213807, Train Acc: 0.596154 | Val Loss: 0.226413, Val Acc: 0.546392\n",
      "Epoch 3346 - Train Loss: 0.213789, Train Acc: 0.596154 | Val Loss: 0.226396, Val Acc: 0.546392\n",
      "Epoch 3347 - Train Loss: 0.213771, Train Acc: 0.596154 | Val Loss: 0.226378, Val Acc: 0.546392\n",
      "Epoch 3348 - Train Loss: 0.213753, Train Acc: 0.596154 | Val Loss: 0.226360, Val Acc: 0.546392\n",
      "Epoch 3349 - Train Loss: 0.213735, Train Acc: 0.596154 | Val Loss: 0.226343, Val Acc: 0.546392\n",
      "Epoch 3350 - Train Loss: 0.213718, Train Acc: 0.596154 | Val Loss: 0.226325, Val Acc: 0.546392\n",
      "Epoch 3351 - Train Loss: 0.213700, Train Acc: 0.597436 | Val Loss: 0.226307, Val Acc: 0.546392\n",
      "Epoch 3352 - Train Loss: 0.213682, Train Acc: 0.597436 | Val Loss: 0.226289, Val Acc: 0.546392\n",
      "Epoch 3353 - Train Loss: 0.213664, Train Acc: 0.597436 | Val Loss: 0.226272, Val Acc: 0.546392\n",
      "Epoch 3354 - Train Loss: 0.213646, Train Acc: 0.597436 | Val Loss: 0.226254, Val Acc: 0.546392\n",
      "Epoch 3355 - Train Loss: 0.213629, Train Acc: 0.597436 | Val Loss: 0.226236, Val Acc: 0.546392\n",
      "Epoch 3356 - Train Loss: 0.213611, Train Acc: 0.597436 | Val Loss: 0.226219, Val Acc: 0.546392\n",
      "Epoch 3357 - Train Loss: 0.213593, Train Acc: 0.597436 | Val Loss: 0.226201, Val Acc: 0.546392\n",
      "Epoch 3358 - Train Loss: 0.213575, Train Acc: 0.597436 | Val Loss: 0.226183, Val Acc: 0.546392\n",
      "Epoch 3359 - Train Loss: 0.213557, Train Acc: 0.597436 | Val Loss: 0.226166, Val Acc: 0.546392\n",
      "Epoch 3360 - Train Loss: 0.213539, Train Acc: 0.597436 | Val Loss: 0.226148, Val Acc: 0.546392\n",
      "Epoch 3361 - Train Loss: 0.213522, Train Acc: 0.597436 | Val Loss: 0.226130, Val Acc: 0.546392\n",
      "Epoch 3362 - Train Loss: 0.213504, Train Acc: 0.597436 | Val Loss: 0.226113, Val Acc: 0.546392\n",
      "Epoch 3363 - Train Loss: 0.213486, Train Acc: 0.597436 | Val Loss: 0.226095, Val Acc: 0.546392\n",
      "Epoch 3364 - Train Loss: 0.213468, Train Acc: 0.597436 | Val Loss: 0.226077, Val Acc: 0.546392\n",
      "Epoch 3365 - Train Loss: 0.213450, Train Acc: 0.597436 | Val Loss: 0.226060, Val Acc: 0.546392\n",
      "Epoch 3366 - Train Loss: 0.213433, Train Acc: 0.597436 | Val Loss: 0.226042, Val Acc: 0.546392\n",
      "Epoch 3367 - Train Loss: 0.213415, Train Acc: 0.597436 | Val Loss: 0.226024, Val Acc: 0.546392\n",
      "Epoch 3368 - Train Loss: 0.213397, Train Acc: 0.597436 | Val Loss: 0.226007, Val Acc: 0.546392\n",
      "Epoch 3369 - Train Loss: 0.213379, Train Acc: 0.597436 | Val Loss: 0.225989, Val Acc: 0.546392\n",
      "Epoch 3370 - Train Loss: 0.213362, Train Acc: 0.597436 | Val Loss: 0.225971, Val Acc: 0.546392\n",
      "Epoch 3371 - Train Loss: 0.213344, Train Acc: 0.597436 | Val Loss: 0.225954, Val Acc: 0.546392\n",
      "Epoch 3372 - Train Loss: 0.213326, Train Acc: 0.597436 | Val Loss: 0.225936, Val Acc: 0.546392\n",
      "Epoch 3373 - Train Loss: 0.213308, Train Acc: 0.597436 | Val Loss: 0.225918, Val Acc: 0.546392\n",
      "Epoch 3374 - Train Loss: 0.213291, Train Acc: 0.597436 | Val Loss: 0.225901, Val Acc: 0.546392\n",
      "Epoch 3375 - Train Loss: 0.213273, Train Acc: 0.597436 | Val Loss: 0.225883, Val Acc: 0.546392\n",
      "Epoch 3376 - Train Loss: 0.213255, Train Acc: 0.597436 | Val Loss: 0.225865, Val Acc: 0.546392\n",
      "Epoch 3377 - Train Loss: 0.213237, Train Acc: 0.597436 | Val Loss: 0.225848, Val Acc: 0.546392\n",
      "Epoch 3378 - Train Loss: 0.213219, Train Acc: 0.597436 | Val Loss: 0.225830, Val Acc: 0.546392\n",
      "Epoch 3379 - Train Loss: 0.213202, Train Acc: 0.597436 | Val Loss: 0.225812, Val Acc: 0.546392\n",
      "Epoch 3380 - Train Loss: 0.213184, Train Acc: 0.597436 | Val Loss: 0.225795, Val Acc: 0.546392\n",
      "Epoch 3381 - Train Loss: 0.213166, Train Acc: 0.597436 | Val Loss: 0.225777, Val Acc: 0.546392\n",
      "Epoch 3382 - Train Loss: 0.213148, Train Acc: 0.597436 | Val Loss: 0.225759, Val Acc: 0.546392\n",
      "Epoch 3383 - Train Loss: 0.213131, Train Acc: 0.597436 | Val Loss: 0.225742, Val Acc: 0.546392\n",
      "Epoch 3384 - Train Loss: 0.213113, Train Acc: 0.597436 | Val Loss: 0.225724, Val Acc: 0.546392\n",
      "Epoch 3385 - Train Loss: 0.213095, Train Acc: 0.597436 | Val Loss: 0.225707, Val Acc: 0.546392\n",
      "Epoch 3386 - Train Loss: 0.213077, Train Acc: 0.597436 | Val Loss: 0.225689, Val Acc: 0.546392\n",
      "Epoch 3387 - Train Loss: 0.213060, Train Acc: 0.597436 | Val Loss: 0.225671, Val Acc: 0.546392\n",
      "Epoch 3388 - Train Loss: 0.213042, Train Acc: 0.597436 | Val Loss: 0.225654, Val Acc: 0.546392\n",
      "Epoch 3389 - Train Loss: 0.213024, Train Acc: 0.597436 | Val Loss: 0.225636, Val Acc: 0.546392\n",
      "Epoch 3390 - Train Loss: 0.213007, Train Acc: 0.597436 | Val Loss: 0.225618, Val Acc: 0.546392\n",
      "Epoch 3391 - Train Loss: 0.212989, Train Acc: 0.597436 | Val Loss: 0.225601, Val Acc: 0.546392\n",
      "Epoch 3392 - Train Loss: 0.212971, Train Acc: 0.597436 | Val Loss: 0.225583, Val Acc: 0.546392\n",
      "Epoch 3393 - Train Loss: 0.212953, Train Acc: 0.597436 | Val Loss: 0.225566, Val Acc: 0.546392\n",
      "Epoch 3394 - Train Loss: 0.212936, Train Acc: 0.597436 | Val Loss: 0.225548, Val Acc: 0.546392\n",
      "Epoch 3395 - Train Loss: 0.212918, Train Acc: 0.597436 | Val Loss: 0.225530, Val Acc: 0.546392\n",
      "Epoch 3396 - Train Loss: 0.212900, Train Acc: 0.597436 | Val Loss: 0.225513, Val Acc: 0.546392\n",
      "Epoch 3397 - Train Loss: 0.212883, Train Acc: 0.597436 | Val Loss: 0.225495, Val Acc: 0.546392\n",
      "Epoch 3398 - Train Loss: 0.212865, Train Acc: 0.597436 | Val Loss: 0.225477, Val Acc: 0.546392\n",
      "Epoch 3399 - Train Loss: 0.212847, Train Acc: 0.597436 | Val Loss: 0.225460, Val Acc: 0.546392\n",
      "Epoch 3400 - Train Loss: 0.212829, Train Acc: 0.597436 | Val Loss: 0.225442, Val Acc: 0.546392\n",
      "Epoch 3401 - Train Loss: 0.212812, Train Acc: 0.597436 | Val Loss: 0.225425, Val Acc: 0.546392\n",
      "Epoch 3402 - Train Loss: 0.212794, Train Acc: 0.597436 | Val Loss: 0.225407, Val Acc: 0.546392\n",
      "Epoch 3403 - Train Loss: 0.212776, Train Acc: 0.597436 | Val Loss: 0.225389, Val Acc: 0.546392\n",
      "Epoch 3404 - Train Loss: 0.212759, Train Acc: 0.597436 | Val Loss: 0.225372, Val Acc: 0.546392\n",
      "Epoch 3405 - Train Loss: 0.212741, Train Acc: 0.597436 | Val Loss: 0.225354, Val Acc: 0.546392\n",
      "Epoch 3406 - Train Loss: 0.212723, Train Acc: 0.597436 | Val Loss: 0.225337, Val Acc: 0.546392\n",
      "Epoch 3407 - Train Loss: 0.212706, Train Acc: 0.597436 | Val Loss: 0.225319, Val Acc: 0.546392\n",
      "Epoch 3408 - Train Loss: 0.212688, Train Acc: 0.597436 | Val Loss: 0.225302, Val Acc: 0.546392\n",
      "Epoch 3409 - Train Loss: 0.212670, Train Acc: 0.597436 | Val Loss: 0.225284, Val Acc: 0.546392\n",
      "Epoch 3410 - Train Loss: 0.212653, Train Acc: 0.597436 | Val Loss: 0.225267, Val Acc: 0.546392\n",
      "Epoch 3411 - Train Loss: 0.212635, Train Acc: 0.597436 | Val Loss: 0.225249, Val Acc: 0.546392\n",
      "Epoch 3412 - Train Loss: 0.212617, Train Acc: 0.597436 | Val Loss: 0.225232, Val Acc: 0.546392\n",
      "Epoch 3413 - Train Loss: 0.212600, Train Acc: 0.597436 | Val Loss: 0.225214, Val Acc: 0.546392\n",
      "Epoch 3414 - Train Loss: 0.212582, Train Acc: 0.597436 | Val Loss: 0.225197, Val Acc: 0.546392\n",
      "Epoch 3415 - Train Loss: 0.212564, Train Acc: 0.597436 | Val Loss: 0.225179, Val Acc: 0.546392\n",
      "Epoch 3416 - Train Loss: 0.212547, Train Acc: 0.597436 | Val Loss: 0.225162, Val Acc: 0.546392\n",
      "Epoch 3417 - Train Loss: 0.212529, Train Acc: 0.598718 | Val Loss: 0.225144, Val Acc: 0.546392\n",
      "Epoch 3418 - Train Loss: 0.212511, Train Acc: 0.598718 | Val Loss: 0.225127, Val Acc: 0.546392\n",
      "Epoch 3419 - Train Loss: 0.212494, Train Acc: 0.598718 | Val Loss: 0.225109, Val Acc: 0.546392\n",
      "Epoch 3420 - Train Loss: 0.212476, Train Acc: 0.598718 | Val Loss: 0.225092, Val Acc: 0.546392\n",
      "Epoch 3421 - Train Loss: 0.212458, Train Acc: 0.598718 | Val Loss: 0.225074, Val Acc: 0.546392\n",
      "Epoch 3422 - Train Loss: 0.212441, Train Acc: 0.598718 | Val Loss: 0.225057, Val Acc: 0.546392\n",
      "Epoch 3423 - Train Loss: 0.212423, Train Acc: 0.598718 | Val Loss: 0.225039, Val Acc: 0.546392\n",
      "Epoch 3424 - Train Loss: 0.212405, Train Acc: 0.598718 | Val Loss: 0.225022, Val Acc: 0.546392\n",
      "Epoch 3425 - Train Loss: 0.212388, Train Acc: 0.598718 | Val Loss: 0.225004, Val Acc: 0.546392\n",
      "Epoch 3426 - Train Loss: 0.212370, Train Acc: 0.598718 | Val Loss: 0.224987, Val Acc: 0.546392\n",
      "Epoch 3427 - Train Loss: 0.212353, Train Acc: 0.598718 | Val Loss: 0.224969, Val Acc: 0.546392\n",
      "Epoch 3428 - Train Loss: 0.212335, Train Acc: 0.598718 | Val Loss: 0.224952, Val Acc: 0.546392\n",
      "Epoch 3429 - Train Loss: 0.212317, Train Acc: 0.598718 | Val Loss: 0.224934, Val Acc: 0.546392\n",
      "Epoch 3430 - Train Loss: 0.212300, Train Acc: 0.598718 | Val Loss: 0.224917, Val Acc: 0.546392\n",
      "Epoch 3431 - Train Loss: 0.212282, Train Acc: 0.598718 | Val Loss: 0.224899, Val Acc: 0.546392\n",
      "Epoch 3432 - Train Loss: 0.212264, Train Acc: 0.598718 | Val Loss: 0.224881, Val Acc: 0.546392\n",
      "Epoch 3433 - Train Loss: 0.212247, Train Acc: 0.598718 | Val Loss: 0.224864, Val Acc: 0.546392\n",
      "Epoch 3434 - Train Loss: 0.212229, Train Acc: 0.598718 | Val Loss: 0.224846, Val Acc: 0.546392\n",
      "Epoch 3435 - Train Loss: 0.212212, Train Acc: 0.598718 | Val Loss: 0.224829, Val Acc: 0.546392\n",
      "Epoch 3436 - Train Loss: 0.212194, Train Acc: 0.598718 | Val Loss: 0.224811, Val Acc: 0.546392\n",
      "Epoch 3437 - Train Loss: 0.212176, Train Acc: 0.598718 | Val Loss: 0.224794, Val Acc: 0.546392\n",
      "Epoch 3438 - Train Loss: 0.212159, Train Acc: 0.598718 | Val Loss: 0.224776, Val Acc: 0.546392\n",
      "Epoch 3439 - Train Loss: 0.212141, Train Acc: 0.598718 | Val Loss: 0.224759, Val Acc: 0.546392\n",
      "Epoch 3440 - Train Loss: 0.212124, Train Acc: 0.598718 | Val Loss: 0.224741, Val Acc: 0.546392\n",
      "Epoch 3441 - Train Loss: 0.212106, Train Acc: 0.598718 | Val Loss: 0.224723, Val Acc: 0.546392\n",
      "Epoch 3442 - Train Loss: 0.212088, Train Acc: 0.598718 | Val Loss: 0.224706, Val Acc: 0.546392\n",
      "Epoch 3443 - Train Loss: 0.212071, Train Acc: 0.598718 | Val Loss: 0.224688, Val Acc: 0.546392\n",
      "Epoch 3444 - Train Loss: 0.212053, Train Acc: 0.598718 | Val Loss: 0.224671, Val Acc: 0.546392\n",
      "Epoch 3445 - Train Loss: 0.212036, Train Acc: 0.598718 | Val Loss: 0.224653, Val Acc: 0.546392\n",
      "Epoch 3446 - Train Loss: 0.212018, Train Acc: 0.598718 | Val Loss: 0.224636, Val Acc: 0.546392\n",
      "Epoch 3447 - Train Loss: 0.212000, Train Acc: 0.598718 | Val Loss: 0.224618, Val Acc: 0.546392\n",
      "Epoch 3448 - Train Loss: 0.211983, Train Acc: 0.598718 | Val Loss: 0.224601, Val Acc: 0.546392\n",
      "Epoch 3449 - Train Loss: 0.211965, Train Acc: 0.598718 | Val Loss: 0.224583, Val Acc: 0.546392\n",
      "Epoch 3450 - Train Loss: 0.211948, Train Acc: 0.598718 | Val Loss: 0.224566, Val Acc: 0.546392\n",
      "Epoch 3451 - Train Loss: 0.211930, Train Acc: 0.598718 | Val Loss: 0.224548, Val Acc: 0.546392\n",
      "Epoch 3452 - Train Loss: 0.211912, Train Acc: 0.598718 | Val Loss: 0.224531, Val Acc: 0.546392\n",
      "Epoch 3453 - Train Loss: 0.211895, Train Acc: 0.598718 | Val Loss: 0.224513, Val Acc: 0.546392\n",
      "Epoch 3454 - Train Loss: 0.211877, Train Acc: 0.598718 | Val Loss: 0.224496, Val Acc: 0.546392\n",
      "Epoch 3455 - Train Loss: 0.211860, Train Acc: 0.598718 | Val Loss: 0.224478, Val Acc: 0.546392\n",
      "Epoch 3456 - Train Loss: 0.211842, Train Acc: 0.598718 | Val Loss: 0.224461, Val Acc: 0.546392\n",
      "Epoch 3457 - Train Loss: 0.211825, Train Acc: 0.598718 | Val Loss: 0.224443, Val Acc: 0.546392\n",
      "Epoch 3458 - Train Loss: 0.211807, Train Acc: 0.598718 | Val Loss: 0.224426, Val Acc: 0.546392\n",
      "Epoch 3459 - Train Loss: 0.211789, Train Acc: 0.598718 | Val Loss: 0.224408, Val Acc: 0.546392\n",
      "Epoch 3460 - Train Loss: 0.211772, Train Acc: 0.598718 | Val Loss: 0.224391, Val Acc: 0.536082\n",
      "Epoch 3461 - Train Loss: 0.211754, Train Acc: 0.598718 | Val Loss: 0.224373, Val Acc: 0.536082\n",
      "Epoch 3462 - Train Loss: 0.211737, Train Acc: 0.598718 | Val Loss: 0.224356, Val Acc: 0.536082\n",
      "Epoch 3463 - Train Loss: 0.211719, Train Acc: 0.598718 | Val Loss: 0.224338, Val Acc: 0.536082\n",
      "Epoch 3464 - Train Loss: 0.211702, Train Acc: 0.598718 | Val Loss: 0.224321, Val Acc: 0.536082\n",
      "Epoch 3465 - Train Loss: 0.211684, Train Acc: 0.598718 | Val Loss: 0.224303, Val Acc: 0.536082\n",
      "Epoch 3466 - Train Loss: 0.211666, Train Acc: 0.598718 | Val Loss: 0.224286, Val Acc: 0.536082\n",
      "Epoch 3467 - Train Loss: 0.211649, Train Acc: 0.598718 | Val Loss: 0.224268, Val Acc: 0.536082\n",
      "Epoch 3468 - Train Loss: 0.211631, Train Acc: 0.598718 | Val Loss: 0.224251, Val Acc: 0.536082\n",
      "Epoch 3469 - Train Loss: 0.211614, Train Acc: 0.598718 | Val Loss: 0.224233, Val Acc: 0.536082\n",
      "Epoch 3470 - Train Loss: 0.211596, Train Acc: 0.598718 | Val Loss: 0.224216, Val Acc: 0.536082\n",
      "Epoch 3471 - Train Loss: 0.211579, Train Acc: 0.598718 | Val Loss: 0.224198, Val Acc: 0.536082\n",
      "Epoch 3472 - Train Loss: 0.211561, Train Acc: 0.598718 | Val Loss: 0.224181, Val Acc: 0.536082\n",
      "Epoch 3473 - Train Loss: 0.211544, Train Acc: 0.598718 | Val Loss: 0.224163, Val Acc: 0.536082\n",
      "Epoch 3474 - Train Loss: 0.211526, Train Acc: 0.598718 | Val Loss: 0.224146, Val Acc: 0.536082\n",
      "Epoch 3475 - Train Loss: 0.211509, Train Acc: 0.598718 | Val Loss: 0.224128, Val Acc: 0.536082\n",
      "Epoch 3476 - Train Loss: 0.211491, Train Acc: 0.598718 | Val Loss: 0.224111, Val Acc: 0.536082\n",
      "Epoch 3477 - Train Loss: 0.211474, Train Acc: 0.598718 | Val Loss: 0.224093, Val Acc: 0.536082\n",
      "Epoch 3478 - Train Loss: 0.211456, Train Acc: 0.598718 | Val Loss: 0.224076, Val Acc: 0.536082\n",
      "Epoch 3479 - Train Loss: 0.211438, Train Acc: 0.598718 | Val Loss: 0.224058, Val Acc: 0.536082\n",
      "Epoch 3480 - Train Loss: 0.211421, Train Acc: 0.598718 | Val Loss: 0.224041, Val Acc: 0.536082\n",
      "Epoch 3481 - Train Loss: 0.211403, Train Acc: 0.598718 | Val Loss: 0.224023, Val Acc: 0.536082\n",
      "Epoch 3482 - Train Loss: 0.211386, Train Acc: 0.598718 | Val Loss: 0.224006, Val Acc: 0.536082\n",
      "Epoch 3483 - Train Loss: 0.211368, Train Acc: 0.598718 | Val Loss: 0.223988, Val Acc: 0.536082\n",
      "Epoch 3484 - Train Loss: 0.211351, Train Acc: 0.598718 | Val Loss: 0.223971, Val Acc: 0.536082\n",
      "Epoch 3485 - Train Loss: 0.211333, Train Acc: 0.598718 | Val Loss: 0.223953, Val Acc: 0.536082\n",
      "Epoch 3486 - Train Loss: 0.211316, Train Acc: 0.598718 | Val Loss: 0.223936, Val Acc: 0.536082\n",
      "Epoch 3487 - Train Loss: 0.211298, Train Acc: 0.598718 | Val Loss: 0.223918, Val Acc: 0.536082\n",
      "Epoch 3488 - Train Loss: 0.211281, Train Acc: 0.598718 | Val Loss: 0.223901, Val Acc: 0.536082\n",
      "Epoch 3489 - Train Loss: 0.211263, Train Acc: 0.598718 | Val Loss: 0.223884, Val Acc: 0.536082\n",
      "Epoch 3490 - Train Loss: 0.211246, Train Acc: 0.598718 | Val Loss: 0.223866, Val Acc: 0.536082\n",
      "Epoch 3491 - Train Loss: 0.211228, Train Acc: 0.598718 | Val Loss: 0.223849, Val Acc: 0.536082\n",
      "Epoch 3492 - Train Loss: 0.211211, Train Acc: 0.598718 | Val Loss: 0.223831, Val Acc: 0.536082\n",
      "Epoch 3493 - Train Loss: 0.211193, Train Acc: 0.598718 | Val Loss: 0.223814, Val Acc: 0.536082\n",
      "Epoch 3494 - Train Loss: 0.211176, Train Acc: 0.598718 | Val Loss: 0.223796, Val Acc: 0.536082\n",
      "Epoch 3495 - Train Loss: 0.211159, Train Acc: 0.598718 | Val Loss: 0.223779, Val Acc: 0.536082\n",
      "Epoch 3496 - Train Loss: 0.211141, Train Acc: 0.598718 | Val Loss: 0.223762, Val Acc: 0.536082\n",
      "Epoch 3497 - Train Loss: 0.211124, Train Acc: 0.598718 | Val Loss: 0.223744, Val Acc: 0.536082\n",
      "Epoch 3498 - Train Loss: 0.211106, Train Acc: 0.598718 | Val Loss: 0.223727, Val Acc: 0.536082\n",
      "Epoch 3499 - Train Loss: 0.211089, Train Acc: 0.598718 | Val Loss: 0.223709, Val Acc: 0.536082\n",
      "Epoch 3500 - Train Loss: 0.211071, Train Acc: 0.598718 | Val Loss: 0.223692, Val Acc: 0.536082\n",
      "Epoch 3501 - Train Loss: 0.211054, Train Acc: 0.598718 | Val Loss: 0.223675, Val Acc: 0.536082\n",
      "Epoch 3502 - Train Loss: 0.211036, Train Acc: 0.598718 | Val Loss: 0.223657, Val Acc: 0.536082\n",
      "Epoch 3503 - Train Loss: 0.211019, Train Acc: 0.598718 | Val Loss: 0.223640, Val Acc: 0.536082\n",
      "Epoch 3504 - Train Loss: 0.211001, Train Acc: 0.598718 | Val Loss: 0.223622, Val Acc: 0.536082\n",
      "Epoch 3505 - Train Loss: 0.210984, Train Acc: 0.598718 | Val Loss: 0.223605, Val Acc: 0.536082\n",
      "Epoch 3506 - Train Loss: 0.210967, Train Acc: 0.598718 | Val Loss: 0.223588, Val Acc: 0.536082\n",
      "Epoch 3507 - Train Loss: 0.210949, Train Acc: 0.598718 | Val Loss: 0.223570, Val Acc: 0.536082\n",
      "Epoch 3508 - Train Loss: 0.210932, Train Acc: 0.598718 | Val Loss: 0.223553, Val Acc: 0.536082\n",
      "Epoch 3509 - Train Loss: 0.210914, Train Acc: 0.598718 | Val Loss: 0.223536, Val Acc: 0.536082\n",
      "Epoch 3510 - Train Loss: 0.210897, Train Acc: 0.598718 | Val Loss: 0.223518, Val Acc: 0.536082\n",
      "Epoch 3511 - Train Loss: 0.210879, Train Acc: 0.598718 | Val Loss: 0.223501, Val Acc: 0.536082\n",
      "Epoch 3512 - Train Loss: 0.210862, Train Acc: 0.598718 | Val Loss: 0.223483, Val Acc: 0.536082\n",
      "Epoch 3513 - Train Loss: 0.210845, Train Acc: 0.598718 | Val Loss: 0.223466, Val Acc: 0.536082\n",
      "Epoch 3514 - Train Loss: 0.210827, Train Acc: 0.598718 | Val Loss: 0.223449, Val Acc: 0.536082\n",
      "Epoch 3515 - Train Loss: 0.210810, Train Acc: 0.598718 | Val Loss: 0.223431, Val Acc: 0.536082\n",
      "Epoch 3516 - Train Loss: 0.210792, Train Acc: 0.598718 | Val Loss: 0.223414, Val Acc: 0.536082\n",
      "Epoch 3517 - Train Loss: 0.210775, Train Acc: 0.598718 | Val Loss: 0.223397, Val Acc: 0.536082\n",
      "Epoch 3518 - Train Loss: 0.210757, Train Acc: 0.598718 | Val Loss: 0.223379, Val Acc: 0.536082\n",
      "Epoch 3519 - Train Loss: 0.210740, Train Acc: 0.598718 | Val Loss: 0.223362, Val Acc: 0.536082\n",
      "Epoch 3520 - Train Loss: 0.210723, Train Acc: 0.598718 | Val Loss: 0.223345, Val Acc: 0.536082\n",
      "Epoch 3521 - Train Loss: 0.210705, Train Acc: 0.598718 | Val Loss: 0.223327, Val Acc: 0.536082\n",
      "Epoch 3522 - Train Loss: 0.210688, Train Acc: 0.598718 | Val Loss: 0.223310, Val Acc: 0.536082\n",
      "Epoch 3523 - Train Loss: 0.210671, Train Acc: 0.598718 | Val Loss: 0.223293, Val Acc: 0.536082\n",
      "Epoch 3524 - Train Loss: 0.210653, Train Acc: 0.598718 | Val Loss: 0.223275, Val Acc: 0.536082\n",
      "Epoch 3525 - Train Loss: 0.210636, Train Acc: 0.598718 | Val Loss: 0.223258, Val Acc: 0.536082\n",
      "Epoch 3526 - Train Loss: 0.210618, Train Acc: 0.598718 | Val Loss: 0.223240, Val Acc: 0.536082\n",
      "Epoch 3527 - Train Loss: 0.210601, Train Acc: 0.598718 | Val Loss: 0.223223, Val Acc: 0.536082\n",
      "Epoch 3528 - Train Loss: 0.210584, Train Acc: 0.598718 | Val Loss: 0.223206, Val Acc: 0.536082\n",
      "Epoch 3529 - Train Loss: 0.210566, Train Acc: 0.598718 | Val Loss: 0.223188, Val Acc: 0.536082\n",
      "Epoch 3530 - Train Loss: 0.210549, Train Acc: 0.598718 | Val Loss: 0.223171, Val Acc: 0.536082\n",
      "Epoch 3531 - Train Loss: 0.210532, Train Acc: 0.598718 | Val Loss: 0.223154, Val Acc: 0.536082\n",
      "Epoch 3532 - Train Loss: 0.210514, Train Acc: 0.598718 | Val Loss: 0.223137, Val Acc: 0.536082\n",
      "Epoch 3533 - Train Loss: 0.210497, Train Acc: 0.598718 | Val Loss: 0.223119, Val Acc: 0.536082\n",
      "Epoch 3534 - Train Loss: 0.210479, Train Acc: 0.598718 | Val Loss: 0.223102, Val Acc: 0.536082\n",
      "Epoch 3535 - Train Loss: 0.210462, Train Acc: 0.598718 | Val Loss: 0.223085, Val Acc: 0.536082\n",
      "Epoch 3536 - Train Loss: 0.210445, Train Acc: 0.598718 | Val Loss: 0.223067, Val Acc: 0.536082\n",
      "Epoch 3537 - Train Loss: 0.210427, Train Acc: 0.598718 | Val Loss: 0.223050, Val Acc: 0.536082\n",
      "Epoch 3538 - Train Loss: 0.210410, Train Acc: 0.598718 | Val Loss: 0.223033, Val Acc: 0.536082\n",
      "Epoch 3539 - Train Loss: 0.210393, Train Acc: 0.598718 | Val Loss: 0.223015, Val Acc: 0.536082\n",
      "Epoch 3540 - Train Loss: 0.210375, Train Acc: 0.598718 | Val Loss: 0.222998, Val Acc: 0.536082\n",
      "Epoch 3541 - Train Loss: 0.210358, Train Acc: 0.598718 | Val Loss: 0.222981, Val Acc: 0.536082\n",
      "Epoch 3542 - Train Loss: 0.210341, Train Acc: 0.598718 | Val Loss: 0.222963, Val Acc: 0.536082\n",
      "Epoch 3543 - Train Loss: 0.210323, Train Acc: 0.598718 | Val Loss: 0.222946, Val Acc: 0.536082\n",
      "Epoch 3544 - Train Loss: 0.210306, Train Acc: 0.598718 | Val Loss: 0.222929, Val Acc: 0.536082\n",
      "Epoch 3545 - Train Loss: 0.210289, Train Acc: 0.598718 | Val Loss: 0.222911, Val Acc: 0.536082\n",
      "Epoch 3546 - Train Loss: 0.210271, Train Acc: 0.598718 | Val Loss: 0.222894, Val Acc: 0.536082\n",
      "Epoch 3547 - Train Loss: 0.210254, Train Acc: 0.598718 | Val Loss: 0.222877, Val Acc: 0.536082\n",
      "Epoch 3548 - Train Loss: 0.210237, Train Acc: 0.598718 | Val Loss: 0.222860, Val Acc: 0.536082\n",
      "Epoch 3549 - Train Loss: 0.210219, Train Acc: 0.598718 | Val Loss: 0.222842, Val Acc: 0.536082\n",
      "Epoch 3550 - Train Loss: 0.210202, Train Acc: 0.600000 | Val Loss: 0.222825, Val Acc: 0.536082\n",
      "Epoch 3551 - Train Loss: 0.210185, Train Acc: 0.600000 | Val Loss: 0.222808, Val Acc: 0.536082\n",
      "Epoch 3552 - Train Loss: 0.210167, Train Acc: 0.600000 | Val Loss: 0.222790, Val Acc: 0.536082\n",
      "Epoch 3553 - Train Loss: 0.210150, Train Acc: 0.600000 | Val Loss: 0.222773, Val Acc: 0.536082\n",
      "Epoch 3554 - Train Loss: 0.210133, Train Acc: 0.600000 | Val Loss: 0.222756, Val Acc: 0.536082\n",
      "Epoch 3555 - Train Loss: 0.210115, Train Acc: 0.600000 | Val Loss: 0.222739, Val Acc: 0.536082\n",
      "Epoch 3556 - Train Loss: 0.210098, Train Acc: 0.600000 | Val Loss: 0.222721, Val Acc: 0.536082\n",
      "Epoch 3557 - Train Loss: 0.210081, Train Acc: 0.600000 | Val Loss: 0.222704, Val Acc: 0.536082\n",
      "Epoch 3558 - Train Loss: 0.210064, Train Acc: 0.600000 | Val Loss: 0.222687, Val Acc: 0.536082\n",
      "Epoch 3559 - Train Loss: 0.210046, Train Acc: 0.600000 | Val Loss: 0.222670, Val Acc: 0.536082\n",
      "Epoch 3560 - Train Loss: 0.210029, Train Acc: 0.600000 | Val Loss: 0.222652, Val Acc: 0.536082\n",
      "Epoch 3561 - Train Loss: 0.210012, Train Acc: 0.600000 | Val Loss: 0.222635, Val Acc: 0.536082\n",
      "Epoch 3562 - Train Loss: 0.209994, Train Acc: 0.600000 | Val Loss: 0.222618, Val Acc: 0.536082\n",
      "Epoch 3563 - Train Loss: 0.209977, Train Acc: 0.600000 | Val Loss: 0.222601, Val Acc: 0.536082\n",
      "Epoch 3564 - Train Loss: 0.209960, Train Acc: 0.600000 | Val Loss: 0.222583, Val Acc: 0.536082\n",
      "Epoch 3565 - Train Loss: 0.209942, Train Acc: 0.600000 | Val Loss: 0.222566, Val Acc: 0.536082\n",
      "Epoch 3566 - Train Loss: 0.209925, Train Acc: 0.600000 | Val Loss: 0.222549, Val Acc: 0.536082\n",
      "Epoch 3567 - Train Loss: 0.209908, Train Acc: 0.600000 | Val Loss: 0.222532, Val Acc: 0.536082\n",
      "Epoch 3568 - Train Loss: 0.209891, Train Acc: 0.600000 | Val Loss: 0.222514, Val Acc: 0.536082\n",
      "Epoch 3569 - Train Loss: 0.209873, Train Acc: 0.600000 | Val Loss: 0.222497, Val Acc: 0.536082\n",
      "Epoch 3570 - Train Loss: 0.209856, Train Acc: 0.600000 | Val Loss: 0.222480, Val Acc: 0.536082\n",
      "Epoch 3571 - Train Loss: 0.209839, Train Acc: 0.600000 | Val Loss: 0.222463, Val Acc: 0.536082\n",
      "Epoch 3572 - Train Loss: 0.209822, Train Acc: 0.600000 | Val Loss: 0.222445, Val Acc: 0.536082\n",
      "Epoch 3573 - Train Loss: 0.209804, Train Acc: 0.600000 | Val Loss: 0.222428, Val Acc: 0.536082\n",
      "Epoch 3574 - Train Loss: 0.209787, Train Acc: 0.600000 | Val Loss: 0.222411, Val Acc: 0.536082\n",
      "Epoch 3575 - Train Loss: 0.209770, Train Acc: 0.600000 | Val Loss: 0.222394, Val Acc: 0.536082\n",
      "Epoch 3576 - Train Loss: 0.209753, Train Acc: 0.600000 | Val Loss: 0.222376, Val Acc: 0.536082\n",
      "Epoch 3577 - Train Loss: 0.209735, Train Acc: 0.600000 | Val Loss: 0.222359, Val Acc: 0.536082\n",
      "Epoch 3578 - Train Loss: 0.209718, Train Acc: 0.600000 | Val Loss: 0.222342, Val Acc: 0.536082\n",
      "Epoch 3579 - Train Loss: 0.209701, Train Acc: 0.600000 | Val Loss: 0.222325, Val Acc: 0.536082\n",
      "Epoch 3580 - Train Loss: 0.209684, Train Acc: 0.600000 | Val Loss: 0.222308, Val Acc: 0.536082\n",
      "Epoch 3581 - Train Loss: 0.209666, Train Acc: 0.600000 | Val Loss: 0.222290, Val Acc: 0.536082\n",
      "Epoch 3582 - Train Loss: 0.209649, Train Acc: 0.600000 | Val Loss: 0.222273, Val Acc: 0.536082\n",
      "Epoch 3583 - Train Loss: 0.209632, Train Acc: 0.600000 | Val Loss: 0.222256, Val Acc: 0.536082\n",
      "Epoch 3584 - Train Loss: 0.209615, Train Acc: 0.600000 | Val Loss: 0.222239, Val Acc: 0.536082\n",
      "Epoch 3585 - Train Loss: 0.209597, Train Acc: 0.600000 | Val Loss: 0.222221, Val Acc: 0.536082\n",
      "Epoch 3586 - Train Loss: 0.209580, Train Acc: 0.600000 | Val Loss: 0.222204, Val Acc: 0.536082\n",
      "Epoch 3587 - Train Loss: 0.209563, Train Acc: 0.600000 | Val Loss: 0.222187, Val Acc: 0.536082\n",
      "Epoch 3588 - Train Loss: 0.209546, Train Acc: 0.600000 | Val Loss: 0.222170, Val Acc: 0.536082\n",
      "Epoch 3589 - Train Loss: 0.209528, Train Acc: 0.600000 | Val Loss: 0.222153, Val Acc: 0.536082\n",
      "Epoch 3590 - Train Loss: 0.209511, Train Acc: 0.600000 | Val Loss: 0.222136, Val Acc: 0.536082\n",
      "Epoch 3591 - Train Loss: 0.209494, Train Acc: 0.600000 | Val Loss: 0.222118, Val Acc: 0.536082\n",
      "Epoch 3592 - Train Loss: 0.209477, Train Acc: 0.600000 | Val Loss: 0.222101, Val Acc: 0.536082\n",
      "Epoch 3593 - Train Loss: 0.209460, Train Acc: 0.600000 | Val Loss: 0.222084, Val Acc: 0.536082\n",
      "Epoch 3594 - Train Loss: 0.209442, Train Acc: 0.600000 | Val Loss: 0.222067, Val Acc: 0.536082\n",
      "Epoch 3595 - Train Loss: 0.209425, Train Acc: 0.600000 | Val Loss: 0.222050, Val Acc: 0.536082\n",
      "Epoch 3596 - Train Loss: 0.209408, Train Acc: 0.598718 | Val Loss: 0.222033, Val Acc: 0.536082\n",
      "Epoch 3597 - Train Loss: 0.209391, Train Acc: 0.598718 | Val Loss: 0.222015, Val Acc: 0.536082\n",
      "Epoch 3598 - Train Loss: 0.209374, Train Acc: 0.598718 | Val Loss: 0.221998, Val Acc: 0.536082\n",
      "Epoch 3599 - Train Loss: 0.209356, Train Acc: 0.598718 | Val Loss: 0.221981, Val Acc: 0.536082\n",
      "Epoch 3600 - Train Loss: 0.209339, Train Acc: 0.598718 | Val Loss: 0.221964, Val Acc: 0.536082\n",
      "Epoch 3601 - Train Loss: 0.209322, Train Acc: 0.598718 | Val Loss: 0.221947, Val Acc: 0.536082\n",
      "Epoch 3602 - Train Loss: 0.209305, Train Acc: 0.598718 | Val Loss: 0.221930, Val Acc: 0.536082\n",
      "Epoch 3603 - Train Loss: 0.209288, Train Acc: 0.598718 | Val Loss: 0.221912, Val Acc: 0.536082\n",
      "Epoch 3604 - Train Loss: 0.209270, Train Acc: 0.598718 | Val Loss: 0.221895, Val Acc: 0.536082\n",
      "Epoch 3605 - Train Loss: 0.209253, Train Acc: 0.598718 | Val Loss: 0.221878, Val Acc: 0.536082\n",
      "Epoch 3606 - Train Loss: 0.209236, Train Acc: 0.598718 | Val Loss: 0.221861, Val Acc: 0.536082\n",
      "Epoch 3607 - Train Loss: 0.209219, Train Acc: 0.597436 | Val Loss: 0.221844, Val Acc: 0.536082\n",
      "Epoch 3608 - Train Loss: 0.209202, Train Acc: 0.597436 | Val Loss: 0.221827, Val Acc: 0.536082\n",
      "Epoch 3609 - Train Loss: 0.209185, Train Acc: 0.597436 | Val Loss: 0.221810, Val Acc: 0.536082\n",
      "Epoch 3610 - Train Loss: 0.209167, Train Acc: 0.597436 | Val Loss: 0.221792, Val Acc: 0.536082\n",
      "Epoch 3611 - Train Loss: 0.209150, Train Acc: 0.597436 | Val Loss: 0.221775, Val Acc: 0.536082\n",
      "Epoch 3612 - Train Loss: 0.209133, Train Acc: 0.597436 | Val Loss: 0.221758, Val Acc: 0.536082\n",
      "Epoch 3613 - Train Loss: 0.209116, Train Acc: 0.597436 | Val Loss: 0.221741, Val Acc: 0.536082\n",
      "Epoch 3614 - Train Loss: 0.209099, Train Acc: 0.596154 | Val Loss: 0.221724, Val Acc: 0.536082\n",
      "Epoch 3615 - Train Loss: 0.209082, Train Acc: 0.596154 | Val Loss: 0.221707, Val Acc: 0.536082\n",
      "Epoch 3616 - Train Loss: 0.209064, Train Acc: 0.596154 | Val Loss: 0.221690, Val Acc: 0.536082\n",
      "Epoch 3617 - Train Loss: 0.209047, Train Acc: 0.596154 | Val Loss: 0.221673, Val Acc: 0.536082\n",
      "Epoch 3618 - Train Loss: 0.209030, Train Acc: 0.596154 | Val Loss: 0.221655, Val Acc: 0.536082\n",
      "Epoch 3619 - Train Loss: 0.209013, Train Acc: 0.596154 | Val Loss: 0.221638, Val Acc: 0.536082\n",
      "Epoch 3620 - Train Loss: 0.208996, Train Acc: 0.596154 | Val Loss: 0.221621, Val Acc: 0.536082\n",
      "Epoch 3621 - Train Loss: 0.208979, Train Acc: 0.596154 | Val Loss: 0.221604, Val Acc: 0.536082\n",
      "Epoch 3622 - Train Loss: 0.208962, Train Acc: 0.596154 | Val Loss: 0.221587, Val Acc: 0.536082\n",
      "Epoch 3623 - Train Loss: 0.208944, Train Acc: 0.596154 | Val Loss: 0.221570, Val Acc: 0.536082\n",
      "Epoch 3624 - Train Loss: 0.208927, Train Acc: 0.596154 | Val Loss: 0.221553, Val Acc: 0.536082\n",
      "Epoch 3625 - Train Loss: 0.208910, Train Acc: 0.596154 | Val Loss: 0.221536, Val Acc: 0.536082\n",
      "Epoch 3626 - Train Loss: 0.208893, Train Acc: 0.596154 | Val Loss: 0.221519, Val Acc: 0.536082\n",
      "Epoch 3627 - Train Loss: 0.208876, Train Acc: 0.596154 | Val Loss: 0.221502, Val Acc: 0.536082\n",
      "Epoch 3628 - Train Loss: 0.208859, Train Acc: 0.596154 | Val Loss: 0.221484, Val Acc: 0.536082\n",
      "Epoch 3629 - Train Loss: 0.208842, Train Acc: 0.596154 | Val Loss: 0.221467, Val Acc: 0.536082\n",
      "Epoch 3630 - Train Loss: 0.208825, Train Acc: 0.596154 | Val Loss: 0.221450, Val Acc: 0.536082\n",
      "Epoch 3631 - Train Loss: 0.208807, Train Acc: 0.596154 | Val Loss: 0.221433, Val Acc: 0.536082\n",
      "Epoch 3632 - Train Loss: 0.208790, Train Acc: 0.596154 | Val Loss: 0.221416, Val Acc: 0.536082\n",
      "Epoch 3633 - Train Loss: 0.208773, Train Acc: 0.596154 | Val Loss: 0.221399, Val Acc: 0.536082\n",
      "Epoch 3634 - Train Loss: 0.208756, Train Acc: 0.596154 | Val Loss: 0.221382, Val Acc: 0.536082\n",
      "Epoch 3635 - Train Loss: 0.208739, Train Acc: 0.596154 | Val Loss: 0.221365, Val Acc: 0.536082\n",
      "Epoch 3636 - Train Loss: 0.208722, Train Acc: 0.596154 | Val Loss: 0.221348, Val Acc: 0.536082\n",
      "Epoch 3637 - Train Loss: 0.208705, Train Acc: 0.596154 | Val Loss: 0.221331, Val Acc: 0.536082\n",
      "Epoch 3638 - Train Loss: 0.208688, Train Acc: 0.596154 | Val Loss: 0.221314, Val Acc: 0.536082\n",
      "Epoch 3639 - Train Loss: 0.208671, Train Acc: 0.596154 | Val Loss: 0.221297, Val Acc: 0.536082\n",
      "Epoch 3640 - Train Loss: 0.208653, Train Acc: 0.596154 | Val Loss: 0.221279, Val Acc: 0.536082\n",
      "Epoch 3641 - Train Loss: 0.208636, Train Acc: 0.596154 | Val Loss: 0.221262, Val Acc: 0.536082\n",
      "Epoch 3642 - Train Loss: 0.208619, Train Acc: 0.596154 | Val Loss: 0.221245, Val Acc: 0.536082\n",
      "Epoch 3643 - Train Loss: 0.208602, Train Acc: 0.596154 | Val Loss: 0.221228, Val Acc: 0.536082\n",
      "Epoch 3644 - Train Loss: 0.208585, Train Acc: 0.596154 | Val Loss: 0.221211, Val Acc: 0.536082\n",
      "Epoch 3645 - Train Loss: 0.208568, Train Acc: 0.596154 | Val Loss: 0.221194, Val Acc: 0.536082\n",
      "Epoch 3646 - Train Loss: 0.208551, Train Acc: 0.596154 | Val Loss: 0.221177, Val Acc: 0.536082\n",
      "Epoch 3647 - Train Loss: 0.208534, Train Acc: 0.596154 | Val Loss: 0.221160, Val Acc: 0.536082\n",
      "Epoch 3648 - Train Loss: 0.208517, Train Acc: 0.596154 | Val Loss: 0.221143, Val Acc: 0.536082\n",
      "Epoch 3649 - Train Loss: 0.208500, Train Acc: 0.596154 | Val Loss: 0.221126, Val Acc: 0.536082\n",
      "Epoch 3650 - Train Loss: 0.208483, Train Acc: 0.596154 | Val Loss: 0.221109, Val Acc: 0.536082\n",
      "Epoch 3651 - Train Loss: 0.208466, Train Acc: 0.596154 | Val Loss: 0.221092, Val Acc: 0.536082\n",
      "Epoch 3652 - Train Loss: 0.208449, Train Acc: 0.596154 | Val Loss: 0.221075, Val Acc: 0.536082\n",
      "Epoch 3653 - Train Loss: 0.208431, Train Acc: 0.596154 | Val Loss: 0.221058, Val Acc: 0.536082\n",
      "Epoch 3654 - Train Loss: 0.208414, Train Acc: 0.596154 | Val Loss: 0.221041, Val Acc: 0.536082\n",
      "Epoch 3655 - Train Loss: 0.208397, Train Acc: 0.596154 | Val Loss: 0.221024, Val Acc: 0.536082\n",
      "Epoch 3656 - Train Loss: 0.208380, Train Acc: 0.596154 | Val Loss: 0.221007, Val Acc: 0.536082\n",
      "Epoch 3657 - Train Loss: 0.208363, Train Acc: 0.596154 | Val Loss: 0.220990, Val Acc: 0.536082\n",
      "Epoch 3658 - Train Loss: 0.208346, Train Acc: 0.596154 | Val Loss: 0.220973, Val Acc: 0.536082\n",
      "Epoch 3659 - Train Loss: 0.208329, Train Acc: 0.596154 | Val Loss: 0.220956, Val Acc: 0.536082\n",
      "Epoch 3660 - Train Loss: 0.208312, Train Acc: 0.596154 | Val Loss: 0.220938, Val Acc: 0.536082\n",
      "Epoch 3661 - Train Loss: 0.208295, Train Acc: 0.596154 | Val Loss: 0.220921, Val Acc: 0.536082\n",
      "Epoch 3662 - Train Loss: 0.208278, Train Acc: 0.596154 | Val Loss: 0.220904, Val Acc: 0.536082\n",
      "Epoch 3663 - Train Loss: 0.208261, Train Acc: 0.596154 | Val Loss: 0.220887, Val Acc: 0.536082\n",
      "Epoch 3664 - Train Loss: 0.208244, Train Acc: 0.596154 | Val Loss: 0.220870, Val Acc: 0.536082\n",
      "Epoch 3665 - Train Loss: 0.208227, Train Acc: 0.596154 | Val Loss: 0.220853, Val Acc: 0.536082\n",
      "Epoch 3666 - Train Loss: 0.208210, Train Acc: 0.596154 | Val Loss: 0.220836, Val Acc: 0.536082\n",
      "Epoch 3667 - Train Loss: 0.208193, Train Acc: 0.596154 | Val Loss: 0.220819, Val Acc: 0.536082\n",
      "Epoch 3668 - Train Loss: 0.208176, Train Acc: 0.596154 | Val Loss: 0.220802, Val Acc: 0.536082\n",
      "Epoch 3669 - Train Loss: 0.208159, Train Acc: 0.596154 | Val Loss: 0.220785, Val Acc: 0.536082\n",
      "Epoch 3670 - Train Loss: 0.208142, Train Acc: 0.596154 | Val Loss: 0.220768, Val Acc: 0.536082\n",
      "Epoch 3671 - Train Loss: 0.208125, Train Acc: 0.596154 | Val Loss: 0.220751, Val Acc: 0.536082\n",
      "Epoch 3672 - Train Loss: 0.208108, Train Acc: 0.596154 | Val Loss: 0.220734, Val Acc: 0.536082\n",
      "Epoch 3673 - Train Loss: 0.208091, Train Acc: 0.596154 | Val Loss: 0.220717, Val Acc: 0.536082\n",
      "Epoch 3674 - Train Loss: 0.208074, Train Acc: 0.596154 | Val Loss: 0.220700, Val Acc: 0.536082\n",
      "Epoch 3675 - Train Loss: 0.208057, Train Acc: 0.596154 | Val Loss: 0.220683, Val Acc: 0.536082\n",
      "Epoch 3676 - Train Loss: 0.208040, Train Acc: 0.596154 | Val Loss: 0.220666, Val Acc: 0.536082\n",
      "Epoch 3677 - Train Loss: 0.208023, Train Acc: 0.596154 | Val Loss: 0.220649, Val Acc: 0.536082\n",
      "Epoch 3678 - Train Loss: 0.208006, Train Acc: 0.596154 | Val Loss: 0.220632, Val Acc: 0.536082\n",
      "Epoch 3679 - Train Loss: 0.207989, Train Acc: 0.596154 | Val Loss: 0.220615, Val Acc: 0.536082\n",
      "Epoch 3680 - Train Loss: 0.207972, Train Acc: 0.596154 | Val Loss: 0.220598, Val Acc: 0.536082\n",
      "Epoch 3681 - Train Loss: 0.207955, Train Acc: 0.596154 | Val Loss: 0.220581, Val Acc: 0.536082\n",
      "Epoch 3682 - Train Loss: 0.207938, Train Acc: 0.597436 | Val Loss: 0.220564, Val Acc: 0.536082\n",
      "Epoch 3683 - Train Loss: 0.207921, Train Acc: 0.597436 | Val Loss: 0.220547, Val Acc: 0.536082\n",
      "Epoch 3684 - Train Loss: 0.207904, Train Acc: 0.597436 | Val Loss: 0.220530, Val Acc: 0.536082\n",
      "Epoch 3685 - Train Loss: 0.207887, Train Acc: 0.597436 | Val Loss: 0.220513, Val Acc: 0.536082\n",
      "Epoch 3686 - Train Loss: 0.207870, Train Acc: 0.597436 | Val Loss: 0.220496, Val Acc: 0.536082\n",
      "Epoch 3687 - Train Loss: 0.207853, Train Acc: 0.597436 | Val Loss: 0.220479, Val Acc: 0.536082\n",
      "Epoch 3688 - Train Loss: 0.207836, Train Acc: 0.597436 | Val Loss: 0.220462, Val Acc: 0.536082\n",
      "Epoch 3689 - Train Loss: 0.207819, Train Acc: 0.597436 | Val Loss: 0.220446, Val Acc: 0.536082\n",
      "Epoch 3690 - Train Loss: 0.207802, Train Acc: 0.597436 | Val Loss: 0.220429, Val Acc: 0.536082\n",
      "Epoch 3691 - Train Loss: 0.207785, Train Acc: 0.597436 | Val Loss: 0.220412, Val Acc: 0.536082\n",
      "Epoch 3692 - Train Loss: 0.207768, Train Acc: 0.597436 | Val Loss: 0.220395, Val Acc: 0.536082\n",
      "Epoch 3693 - Train Loss: 0.207751, Train Acc: 0.597436 | Val Loss: 0.220378, Val Acc: 0.536082\n",
      "Epoch 3694 - Train Loss: 0.207734, Train Acc: 0.597436 | Val Loss: 0.220361, Val Acc: 0.536082\n",
      "Epoch 3695 - Train Loss: 0.207717, Train Acc: 0.597436 | Val Loss: 0.220344, Val Acc: 0.536082\n",
      "Epoch 3696 - Train Loss: 0.207700, Train Acc: 0.597436 | Val Loss: 0.220327, Val Acc: 0.536082\n",
      "Epoch 3697 - Train Loss: 0.207683, Train Acc: 0.597436 | Val Loss: 0.220310, Val Acc: 0.536082\n",
      "Epoch 3698 - Train Loss: 0.207666, Train Acc: 0.597436 | Val Loss: 0.220293, Val Acc: 0.536082\n",
      "Epoch 3699 - Train Loss: 0.207649, Train Acc: 0.597436 | Val Loss: 0.220276, Val Acc: 0.536082\n",
      "Epoch 3700 - Train Loss: 0.207632, Train Acc: 0.597436 | Val Loss: 0.220259, Val Acc: 0.536082\n",
      "Epoch 3701 - Train Loss: 0.207615, Train Acc: 0.597436 | Val Loss: 0.220242, Val Acc: 0.536082\n",
      "Epoch 3702 - Train Loss: 0.207598, Train Acc: 0.597436 | Val Loss: 0.220225, Val Acc: 0.536082\n",
      "Epoch 3703 - Train Loss: 0.207581, Train Acc: 0.597436 | Val Loss: 0.220208, Val Acc: 0.536082\n",
      "Epoch 3704 - Train Loss: 0.207565, Train Acc: 0.597436 | Val Loss: 0.220191, Val Acc: 0.536082\n",
      "Epoch 3705 - Train Loss: 0.207548, Train Acc: 0.597436 | Val Loss: 0.220174, Val Acc: 0.536082\n",
      "Epoch 3706 - Train Loss: 0.207531, Train Acc: 0.597436 | Val Loss: 0.220157, Val Acc: 0.536082\n",
      "Epoch 3707 - Train Loss: 0.207514, Train Acc: 0.597436 | Val Loss: 0.220140, Val Acc: 0.536082\n",
      "Epoch 3708 - Train Loss: 0.207497, Train Acc: 0.597436 | Val Loss: 0.220123, Val Acc: 0.536082\n",
      "Epoch 3709 - Train Loss: 0.207480, Train Acc: 0.597436 | Val Loss: 0.220107, Val Acc: 0.536082\n",
      "Epoch 3710 - Train Loss: 0.207463, Train Acc: 0.597436 | Val Loss: 0.220090, Val Acc: 0.536082\n",
      "Epoch 3711 - Train Loss: 0.207446, Train Acc: 0.597436 | Val Loss: 0.220073, Val Acc: 0.536082\n",
      "Epoch 3712 - Train Loss: 0.207429, Train Acc: 0.597436 | Val Loss: 0.220056, Val Acc: 0.536082\n",
      "Epoch 3713 - Train Loss: 0.207412, Train Acc: 0.597436 | Val Loss: 0.220039, Val Acc: 0.536082\n",
      "Epoch 3714 - Train Loss: 0.207395, Train Acc: 0.597436 | Val Loss: 0.220022, Val Acc: 0.536082\n",
      "Epoch 3715 - Train Loss: 0.207378, Train Acc: 0.597436 | Val Loss: 0.220005, Val Acc: 0.536082\n",
      "Epoch 3716 - Train Loss: 0.207361, Train Acc: 0.597436 | Val Loss: 0.219988, Val Acc: 0.536082\n",
      "Epoch 3717 - Train Loss: 0.207345, Train Acc: 0.597436 | Val Loss: 0.219971, Val Acc: 0.536082\n",
      "Epoch 3718 - Train Loss: 0.207328, Train Acc: 0.597436 | Val Loss: 0.219954, Val Acc: 0.536082\n",
      "Epoch 3719 - Train Loss: 0.207311, Train Acc: 0.597436 | Val Loss: 0.219937, Val Acc: 0.536082\n",
      "Epoch 3720 - Train Loss: 0.207294, Train Acc: 0.597436 | Val Loss: 0.219920, Val Acc: 0.536082\n",
      "Epoch 3721 - Train Loss: 0.207277, Train Acc: 0.597436 | Val Loss: 0.219904, Val Acc: 0.536082\n",
      "Epoch 3722 - Train Loss: 0.207260, Train Acc: 0.597436 | Val Loss: 0.219887, Val Acc: 0.536082\n",
      "Epoch 3723 - Train Loss: 0.207243, Train Acc: 0.597436 | Val Loss: 0.219870, Val Acc: 0.536082\n",
      "Epoch 3724 - Train Loss: 0.207226, Train Acc: 0.597436 | Val Loss: 0.219853, Val Acc: 0.536082\n",
      "Epoch 3725 - Train Loss: 0.207209, Train Acc: 0.597436 | Val Loss: 0.219836, Val Acc: 0.536082\n",
      "Epoch 3726 - Train Loss: 0.207192, Train Acc: 0.597436 | Val Loss: 0.219819, Val Acc: 0.536082\n",
      "Epoch 3727 - Train Loss: 0.207176, Train Acc: 0.597436 | Val Loss: 0.219802, Val Acc: 0.536082\n",
      "Epoch 3728 - Train Loss: 0.207159, Train Acc: 0.597436 | Val Loss: 0.219785, Val Acc: 0.536082\n",
      "Epoch 3729 - Train Loss: 0.207142, Train Acc: 0.597436 | Val Loss: 0.219768, Val Acc: 0.536082\n",
      "Epoch 3730 - Train Loss: 0.207125, Train Acc: 0.597436 | Val Loss: 0.219751, Val Acc: 0.536082\n",
      "Epoch 3731 - Train Loss: 0.207108, Train Acc: 0.597436 | Val Loss: 0.219735, Val Acc: 0.536082\n",
      "Epoch 3732 - Train Loss: 0.207091, Train Acc: 0.597436 | Val Loss: 0.219718, Val Acc: 0.536082\n",
      "Epoch 3733 - Train Loss: 0.207074, Train Acc: 0.597436 | Val Loss: 0.219701, Val Acc: 0.536082\n",
      "Epoch 3734 - Train Loss: 0.207057, Train Acc: 0.597436 | Val Loss: 0.219684, Val Acc: 0.536082\n",
      "Epoch 3735 - Train Loss: 0.207041, Train Acc: 0.597436 | Val Loss: 0.219667, Val Acc: 0.536082\n",
      "Epoch 3736 - Train Loss: 0.207024, Train Acc: 0.597436 | Val Loss: 0.219650, Val Acc: 0.536082\n",
      "Epoch 3737 - Train Loss: 0.207007, Train Acc: 0.597436 | Val Loss: 0.219633, Val Acc: 0.536082\n",
      "Epoch 3738 - Train Loss: 0.206990, Train Acc: 0.597436 | Val Loss: 0.219616, Val Acc: 0.536082\n",
      "Epoch 3739 - Train Loss: 0.206973, Train Acc: 0.597436 | Val Loss: 0.219600, Val Acc: 0.536082\n",
      "Epoch 3740 - Train Loss: 0.206956, Train Acc: 0.597436 | Val Loss: 0.219583, Val Acc: 0.536082\n",
      "Epoch 3741 - Train Loss: 0.206940, Train Acc: 0.597436 | Val Loss: 0.219566, Val Acc: 0.536082\n",
      "Epoch 3742 - Train Loss: 0.206923, Train Acc: 0.597436 | Val Loss: 0.219549, Val Acc: 0.536082\n",
      "Epoch 3743 - Train Loss: 0.206906, Train Acc: 0.597436 | Val Loss: 0.219532, Val Acc: 0.536082\n",
      "Epoch 3744 - Train Loss: 0.206889, Train Acc: 0.597436 | Val Loss: 0.219515, Val Acc: 0.536082\n",
      "Epoch 3745 - Train Loss: 0.206872, Train Acc: 0.597436 | Val Loss: 0.219498, Val Acc: 0.536082\n",
      "Epoch 3746 - Train Loss: 0.206855, Train Acc: 0.597436 | Val Loss: 0.219482, Val Acc: 0.536082\n",
      "Epoch 3747 - Train Loss: 0.206838, Train Acc: 0.597436 | Val Loss: 0.219465, Val Acc: 0.536082\n",
      "Epoch 3748 - Train Loss: 0.206822, Train Acc: 0.597436 | Val Loss: 0.219448, Val Acc: 0.536082\n",
      "Epoch 3749 - Train Loss: 0.206805, Train Acc: 0.597436 | Val Loss: 0.219431, Val Acc: 0.536082\n",
      "Epoch 3750 - Train Loss: 0.206788, Train Acc: 0.597436 | Val Loss: 0.219414, Val Acc: 0.536082\n",
      "Epoch 3751 - Train Loss: 0.206771, Train Acc: 0.597436 | Val Loss: 0.219397, Val Acc: 0.536082\n",
      "Epoch 3752 - Train Loss: 0.206754, Train Acc: 0.597436 | Val Loss: 0.219381, Val Acc: 0.536082\n",
      "Epoch 3753 - Train Loss: 0.206738, Train Acc: 0.597436 | Val Loss: 0.219364, Val Acc: 0.536082\n",
      "Epoch 3754 - Train Loss: 0.206721, Train Acc: 0.597436 | Val Loss: 0.219347, Val Acc: 0.536082\n",
      "Epoch 3755 - Train Loss: 0.206704, Train Acc: 0.597436 | Val Loss: 0.219330, Val Acc: 0.536082\n",
      "Epoch 3756 - Train Loss: 0.206687, Train Acc: 0.597436 | Val Loss: 0.219313, Val Acc: 0.536082\n",
      "Epoch 3757 - Train Loss: 0.206670, Train Acc: 0.597436 | Val Loss: 0.219296, Val Acc: 0.536082\n",
      "Epoch 3758 - Train Loss: 0.206654, Train Acc: 0.597436 | Val Loss: 0.219280, Val Acc: 0.536082\n",
      "Epoch 3759 - Train Loss: 0.206637, Train Acc: 0.597436 | Val Loss: 0.219263, Val Acc: 0.536082\n",
      "Epoch 3760 - Train Loss: 0.206620, Train Acc: 0.597436 | Val Loss: 0.219246, Val Acc: 0.536082\n",
      "Epoch 3761 - Train Loss: 0.206603, Train Acc: 0.597436 | Val Loss: 0.219229, Val Acc: 0.536082\n",
      "Epoch 3762 - Train Loss: 0.206586, Train Acc: 0.597436 | Val Loss: 0.219212, Val Acc: 0.536082\n",
      "Epoch 3763 - Train Loss: 0.206570, Train Acc: 0.597436 | Val Loss: 0.219196, Val Acc: 0.536082\n",
      "Epoch 3764 - Train Loss: 0.206553, Train Acc: 0.597436 | Val Loss: 0.219179, Val Acc: 0.536082\n",
      "Epoch 3765 - Train Loss: 0.206536, Train Acc: 0.597436 | Val Loss: 0.219162, Val Acc: 0.536082\n",
      "Epoch 3766 - Train Loss: 0.206519, Train Acc: 0.596154 | Val Loss: 0.219145, Val Acc: 0.536082\n",
      "Epoch 3767 - Train Loss: 0.206502, Train Acc: 0.596154 | Val Loss: 0.219128, Val Acc: 0.536082\n",
      "Epoch 3768 - Train Loss: 0.206486, Train Acc: 0.596154 | Val Loss: 0.219112, Val Acc: 0.536082\n",
      "Epoch 3769 - Train Loss: 0.206469, Train Acc: 0.596154 | Val Loss: 0.219095, Val Acc: 0.536082\n",
      "Epoch 3770 - Train Loss: 0.206452, Train Acc: 0.596154 | Val Loss: 0.219078, Val Acc: 0.536082\n",
      "Epoch 3771 - Train Loss: 0.206435, Train Acc: 0.596154 | Val Loss: 0.219061, Val Acc: 0.536082\n",
      "Epoch 3772 - Train Loss: 0.206419, Train Acc: 0.596154 | Val Loss: 0.219044, Val Acc: 0.536082\n",
      "Epoch 3773 - Train Loss: 0.206402, Train Acc: 0.596154 | Val Loss: 0.219028, Val Acc: 0.536082\n",
      "Epoch 3774 - Train Loss: 0.206385, Train Acc: 0.596154 | Val Loss: 0.219011, Val Acc: 0.536082\n",
      "Epoch 3775 - Train Loss: 0.206368, Train Acc: 0.596154 | Val Loss: 0.218994, Val Acc: 0.536082\n",
      "Epoch 3776 - Train Loss: 0.206352, Train Acc: 0.596154 | Val Loss: 0.218977, Val Acc: 0.536082\n",
      "Epoch 3777 - Train Loss: 0.206335, Train Acc: 0.596154 | Val Loss: 0.218960, Val Acc: 0.536082\n",
      "Epoch 3778 - Train Loss: 0.206318, Train Acc: 0.596154 | Val Loss: 0.218944, Val Acc: 0.536082\n",
      "Epoch 3779 - Train Loss: 0.206301, Train Acc: 0.596154 | Val Loss: 0.218927, Val Acc: 0.536082\n",
      "Epoch 3780 - Train Loss: 0.206285, Train Acc: 0.596154 | Val Loss: 0.218910, Val Acc: 0.536082\n",
      "Epoch 3781 - Train Loss: 0.206268, Train Acc: 0.596154 | Val Loss: 0.218893, Val Acc: 0.536082\n",
      "Epoch 3782 - Train Loss: 0.206251, Train Acc: 0.596154 | Val Loss: 0.218876, Val Acc: 0.536082\n",
      "Epoch 3783 - Train Loss: 0.206234, Train Acc: 0.596154 | Val Loss: 0.218860, Val Acc: 0.536082\n",
      "Epoch 3784 - Train Loss: 0.206218, Train Acc: 0.596154 | Val Loss: 0.218843, Val Acc: 0.536082\n",
      "Epoch 3785 - Train Loss: 0.206201, Train Acc: 0.596154 | Val Loss: 0.218826, Val Acc: 0.536082\n",
      "Epoch 3786 - Train Loss: 0.206184, Train Acc: 0.597436 | Val Loss: 0.218809, Val Acc: 0.536082\n",
      "Epoch 3787 - Train Loss: 0.206167, Train Acc: 0.597436 | Val Loss: 0.218793, Val Acc: 0.536082\n",
      "Epoch 3788 - Train Loss: 0.206151, Train Acc: 0.597436 | Val Loss: 0.218776, Val Acc: 0.536082\n",
      "Epoch 3789 - Train Loss: 0.206134, Train Acc: 0.597436 | Val Loss: 0.218759, Val Acc: 0.536082\n",
      "Epoch 3790 - Train Loss: 0.206117, Train Acc: 0.597436 | Val Loss: 0.218742, Val Acc: 0.536082\n",
      "Epoch 3791 - Train Loss: 0.206101, Train Acc: 0.597436 | Val Loss: 0.218726, Val Acc: 0.536082\n",
      "Epoch 3792 - Train Loss: 0.206084, Train Acc: 0.597436 | Val Loss: 0.218709, Val Acc: 0.536082\n",
      "Epoch 3793 - Train Loss: 0.206067, Train Acc: 0.597436 | Val Loss: 0.218692, Val Acc: 0.536082\n",
      "Epoch 3794 - Train Loss: 0.206050, Train Acc: 0.597436 | Val Loss: 0.218675, Val Acc: 0.536082\n",
      "Epoch 3795 - Train Loss: 0.206034, Train Acc: 0.597436 | Val Loss: 0.218659, Val Acc: 0.536082\n",
      "Epoch 3796 - Train Loss: 0.206017, Train Acc: 0.597436 | Val Loss: 0.218642, Val Acc: 0.536082\n",
      "Epoch 3797 - Train Loss: 0.206000, Train Acc: 0.597436 | Val Loss: 0.218625, Val Acc: 0.536082\n",
      "Epoch 3798 - Train Loss: 0.205984, Train Acc: 0.597436 | Val Loss: 0.218608, Val Acc: 0.536082\n",
      "Epoch 3799 - Train Loss: 0.205967, Train Acc: 0.597436 | Val Loss: 0.218592, Val Acc: 0.536082\n",
      "Epoch 3800 - Train Loss: 0.205950, Train Acc: 0.597436 | Val Loss: 0.218575, Val Acc: 0.536082\n",
      "Epoch 3801 - Train Loss: 0.205933, Train Acc: 0.597436 | Val Loss: 0.218558, Val Acc: 0.536082\n",
      "Epoch 3802 - Train Loss: 0.205917, Train Acc: 0.597436 | Val Loss: 0.218541, Val Acc: 0.536082\n",
      "Epoch 3803 - Train Loss: 0.205900, Train Acc: 0.597436 | Val Loss: 0.218525, Val Acc: 0.536082\n",
      "Epoch 3804 - Train Loss: 0.205883, Train Acc: 0.597436 | Val Loss: 0.218508, Val Acc: 0.536082\n",
      "Epoch 3805 - Train Loss: 0.205867, Train Acc: 0.597436 | Val Loss: 0.218491, Val Acc: 0.536082\n",
      "Epoch 3806 - Train Loss: 0.205850, Train Acc: 0.597436 | Val Loss: 0.218475, Val Acc: 0.536082\n",
      "Epoch 3807 - Train Loss: 0.205833, Train Acc: 0.597436 | Val Loss: 0.218458, Val Acc: 0.536082\n",
      "Epoch 3808 - Train Loss: 0.205817, Train Acc: 0.597436 | Val Loss: 0.218441, Val Acc: 0.536082\n",
      "Epoch 3809 - Train Loss: 0.205800, Train Acc: 0.597436 | Val Loss: 0.218425, Val Acc: 0.536082\n",
      "Epoch 3810 - Train Loss: 0.205783, Train Acc: 0.597436 | Val Loss: 0.218408, Val Acc: 0.536082\n",
      "Epoch 3811 - Train Loss: 0.205767, Train Acc: 0.597436 | Val Loss: 0.218391, Val Acc: 0.536082\n",
      "Epoch 3812 - Train Loss: 0.205750, Train Acc: 0.597436 | Val Loss: 0.218375, Val Acc: 0.536082\n",
      "Epoch 3813 - Train Loss: 0.205733, Train Acc: 0.597436 | Val Loss: 0.218358, Val Acc: 0.536082\n",
      "Epoch 3814 - Train Loss: 0.205717, Train Acc: 0.597436 | Val Loss: 0.218341, Val Acc: 0.536082\n",
      "Epoch 3815 - Train Loss: 0.205700, Train Acc: 0.597436 | Val Loss: 0.218325, Val Acc: 0.536082\n",
      "Epoch 3816 - Train Loss: 0.205683, Train Acc: 0.597436 | Val Loss: 0.218308, Val Acc: 0.536082\n",
      "Epoch 3817 - Train Loss: 0.205667, Train Acc: 0.597436 | Val Loss: 0.218291, Val Acc: 0.536082\n",
      "Epoch 3818 - Train Loss: 0.205650, Train Acc: 0.597436 | Val Loss: 0.218275, Val Acc: 0.536082\n",
      "Epoch 3819 - Train Loss: 0.205634, Train Acc: 0.597436 | Val Loss: 0.218258, Val Acc: 0.536082\n",
      "Epoch 3820 - Train Loss: 0.205617, Train Acc: 0.597436 | Val Loss: 0.218241, Val Acc: 0.536082\n",
      "Epoch 3821 - Train Loss: 0.205600, Train Acc: 0.597436 | Val Loss: 0.218225, Val Acc: 0.536082\n",
      "Epoch 3822 - Train Loss: 0.205584, Train Acc: 0.597436 | Val Loss: 0.218208, Val Acc: 0.536082\n",
      "Epoch 3823 - Train Loss: 0.205567, Train Acc: 0.598718 | Val Loss: 0.218191, Val Acc: 0.536082\n",
      "Epoch 3824 - Train Loss: 0.205550, Train Acc: 0.598718 | Val Loss: 0.218175, Val Acc: 0.536082\n",
      "Epoch 3825 - Train Loss: 0.205534, Train Acc: 0.598718 | Val Loss: 0.218158, Val Acc: 0.536082\n",
      "Epoch 3826 - Train Loss: 0.205517, Train Acc: 0.598718 | Val Loss: 0.218141, Val Acc: 0.536082\n",
      "Epoch 3827 - Train Loss: 0.205501, Train Acc: 0.598718 | Val Loss: 0.218125, Val Acc: 0.536082\n",
      "Epoch 3828 - Train Loss: 0.205484, Train Acc: 0.598718 | Val Loss: 0.218108, Val Acc: 0.536082\n",
      "Epoch 3829 - Train Loss: 0.205467, Train Acc: 0.598718 | Val Loss: 0.218091, Val Acc: 0.536082\n",
      "Epoch 3830 - Train Loss: 0.205451, Train Acc: 0.598718 | Val Loss: 0.218075, Val Acc: 0.536082\n",
      "Epoch 3831 - Train Loss: 0.205434, Train Acc: 0.598718 | Val Loss: 0.218058, Val Acc: 0.536082\n",
      "Epoch 3832 - Train Loss: 0.205417, Train Acc: 0.598718 | Val Loss: 0.218041, Val Acc: 0.536082\n",
      "Epoch 3833 - Train Loss: 0.205401, Train Acc: 0.598718 | Val Loss: 0.218025, Val Acc: 0.536082\n",
      "Epoch 3834 - Train Loss: 0.205384, Train Acc: 0.598718 | Val Loss: 0.218008, Val Acc: 0.536082\n",
      "Epoch 3835 - Train Loss: 0.205368, Train Acc: 0.600000 | Val Loss: 0.217991, Val Acc: 0.536082\n",
      "Epoch 3836 - Train Loss: 0.205351, Train Acc: 0.600000 | Val Loss: 0.217975, Val Acc: 0.536082\n",
      "Epoch 3837 - Train Loss: 0.205334, Train Acc: 0.600000 | Val Loss: 0.217958, Val Acc: 0.536082\n",
      "Epoch 3838 - Train Loss: 0.205318, Train Acc: 0.600000 | Val Loss: 0.217942, Val Acc: 0.536082\n",
      "Epoch 3839 - Train Loss: 0.205301, Train Acc: 0.600000 | Val Loss: 0.217925, Val Acc: 0.536082\n",
      "Epoch 3840 - Train Loss: 0.205285, Train Acc: 0.600000 | Val Loss: 0.217908, Val Acc: 0.536082\n",
      "Epoch 3841 - Train Loss: 0.205268, Train Acc: 0.600000 | Val Loss: 0.217892, Val Acc: 0.536082\n",
      "Epoch 3842 - Train Loss: 0.205251, Train Acc: 0.600000 | Val Loss: 0.217875, Val Acc: 0.536082\n",
      "Epoch 3843 - Train Loss: 0.205235, Train Acc: 0.600000 | Val Loss: 0.217858, Val Acc: 0.536082\n",
      "Epoch 3844 - Train Loss: 0.205218, Train Acc: 0.600000 | Val Loss: 0.217842, Val Acc: 0.536082\n",
      "Epoch 3845 - Train Loss: 0.205202, Train Acc: 0.600000 | Val Loss: 0.217825, Val Acc: 0.536082\n",
      "Epoch 3846 - Train Loss: 0.205185, Train Acc: 0.600000 | Val Loss: 0.217809, Val Acc: 0.536082\n",
      "Epoch 3847 - Train Loss: 0.205169, Train Acc: 0.600000 | Val Loss: 0.217792, Val Acc: 0.536082\n",
      "Epoch 3848 - Train Loss: 0.205152, Train Acc: 0.600000 | Val Loss: 0.217775, Val Acc: 0.536082\n",
      "Epoch 3849 - Train Loss: 0.205135, Train Acc: 0.600000 | Val Loss: 0.217759, Val Acc: 0.536082\n",
      "Epoch 3850 - Train Loss: 0.205119, Train Acc: 0.600000 | Val Loss: 0.217742, Val Acc: 0.536082\n",
      "Epoch 3851 - Train Loss: 0.205102, Train Acc: 0.600000 | Val Loss: 0.217726, Val Acc: 0.536082\n",
      "Epoch 3852 - Train Loss: 0.205086, Train Acc: 0.600000 | Val Loss: 0.217709, Val Acc: 0.536082\n",
      "Epoch 3853 - Train Loss: 0.205069, Train Acc: 0.600000 | Val Loss: 0.217692, Val Acc: 0.536082\n",
      "Epoch 3854 - Train Loss: 0.205053, Train Acc: 0.600000 | Val Loss: 0.217676, Val Acc: 0.536082\n",
      "Epoch 3855 - Train Loss: 0.205036, Train Acc: 0.600000 | Val Loss: 0.217659, Val Acc: 0.536082\n",
      "Epoch 3856 - Train Loss: 0.205020, Train Acc: 0.600000 | Val Loss: 0.217643, Val Acc: 0.536082\n",
      "Epoch 3857 - Train Loss: 0.205003, Train Acc: 0.600000 | Val Loss: 0.217626, Val Acc: 0.536082\n",
      "Epoch 3858 - Train Loss: 0.204986, Train Acc: 0.600000 | Val Loss: 0.217609, Val Acc: 0.536082\n",
      "Epoch 3859 - Train Loss: 0.204970, Train Acc: 0.600000 | Val Loss: 0.217593, Val Acc: 0.536082\n",
      "Epoch 3860 - Train Loss: 0.204953, Train Acc: 0.600000 | Val Loss: 0.217576, Val Acc: 0.536082\n",
      "Epoch 3861 - Train Loss: 0.204937, Train Acc: 0.600000 | Val Loss: 0.217560, Val Acc: 0.536082\n",
      "Epoch 3862 - Train Loss: 0.204920, Train Acc: 0.600000 | Val Loss: 0.217543, Val Acc: 0.536082\n",
      "Epoch 3863 - Train Loss: 0.204904, Train Acc: 0.600000 | Val Loss: 0.217527, Val Acc: 0.536082\n",
      "Epoch 3864 - Train Loss: 0.204887, Train Acc: 0.600000 | Val Loss: 0.217510, Val Acc: 0.536082\n",
      "Epoch 3865 - Train Loss: 0.204871, Train Acc: 0.600000 | Val Loss: 0.217493, Val Acc: 0.536082\n",
      "Epoch 3866 - Train Loss: 0.204854, Train Acc: 0.600000 | Val Loss: 0.217477, Val Acc: 0.536082\n",
      "Epoch 3867 - Train Loss: 0.204838, Train Acc: 0.600000 | Val Loss: 0.217460, Val Acc: 0.536082\n",
      "Epoch 3868 - Train Loss: 0.204821, Train Acc: 0.600000 | Val Loss: 0.217444, Val Acc: 0.536082\n",
      "Epoch 3869 - Train Loss: 0.204805, Train Acc: 0.600000 | Val Loss: 0.217427, Val Acc: 0.536082\n",
      "Epoch 3870 - Train Loss: 0.204788, Train Acc: 0.600000 | Val Loss: 0.217411, Val Acc: 0.536082\n",
      "Epoch 3871 - Train Loss: 0.204771, Train Acc: 0.600000 | Val Loss: 0.217394, Val Acc: 0.536082\n",
      "Epoch 3872 - Train Loss: 0.204755, Train Acc: 0.600000 | Val Loss: 0.217377, Val Acc: 0.536082\n",
      "Epoch 3873 - Train Loss: 0.204738, Train Acc: 0.600000 | Val Loss: 0.217361, Val Acc: 0.536082\n",
      "Epoch 3874 - Train Loss: 0.204722, Train Acc: 0.600000 | Val Loss: 0.217344, Val Acc: 0.536082\n",
      "Epoch 3875 - Train Loss: 0.204705, Train Acc: 0.600000 | Val Loss: 0.217328, Val Acc: 0.536082\n",
      "Epoch 3876 - Train Loss: 0.204689, Train Acc: 0.600000 | Val Loss: 0.217311, Val Acc: 0.536082\n",
      "Epoch 3877 - Train Loss: 0.204672, Train Acc: 0.600000 | Val Loss: 0.217295, Val Acc: 0.536082\n",
      "Epoch 3878 - Train Loss: 0.204656, Train Acc: 0.600000 | Val Loss: 0.217278, Val Acc: 0.536082\n",
      "Epoch 3879 - Train Loss: 0.204639, Train Acc: 0.600000 | Val Loss: 0.217262, Val Acc: 0.536082\n",
      "Epoch 3880 - Train Loss: 0.204623, Train Acc: 0.600000 | Val Loss: 0.217245, Val Acc: 0.536082\n",
      "Epoch 3881 - Train Loss: 0.204606, Train Acc: 0.600000 | Val Loss: 0.217229, Val Acc: 0.536082\n",
      "Epoch 3882 - Train Loss: 0.204590, Train Acc: 0.600000 | Val Loss: 0.217212, Val Acc: 0.536082\n",
      "Epoch 3883 - Train Loss: 0.204573, Train Acc: 0.600000 | Val Loss: 0.217195, Val Acc: 0.536082\n",
      "Epoch 3884 - Train Loss: 0.204557, Train Acc: 0.600000 | Val Loss: 0.217179, Val Acc: 0.536082\n",
      "Epoch 3885 - Train Loss: 0.204540, Train Acc: 0.600000 | Val Loss: 0.217162, Val Acc: 0.536082\n",
      "Epoch 3886 - Train Loss: 0.204524, Train Acc: 0.600000 | Val Loss: 0.217146, Val Acc: 0.536082\n",
      "Epoch 3887 - Train Loss: 0.204508, Train Acc: 0.600000 | Val Loss: 0.217129, Val Acc: 0.536082\n",
      "Epoch 3888 - Train Loss: 0.204491, Train Acc: 0.600000 | Val Loss: 0.217113, Val Acc: 0.536082\n",
      "Epoch 3889 - Train Loss: 0.204475, Train Acc: 0.600000 | Val Loss: 0.217096, Val Acc: 0.536082\n",
      "Epoch 3890 - Train Loss: 0.204458, Train Acc: 0.600000 | Val Loss: 0.217080, Val Acc: 0.536082\n",
      "Epoch 3891 - Train Loss: 0.204442, Train Acc: 0.600000 | Val Loss: 0.217063, Val Acc: 0.536082\n",
      "Epoch 3892 - Train Loss: 0.204425, Train Acc: 0.601282 | Val Loss: 0.217047, Val Acc: 0.536082\n",
      "Epoch 3893 - Train Loss: 0.204409, Train Acc: 0.601282 | Val Loss: 0.217030, Val Acc: 0.536082\n",
      "Epoch 3894 - Train Loss: 0.204392, Train Acc: 0.601282 | Val Loss: 0.217014, Val Acc: 0.536082\n",
      "Epoch 3895 - Train Loss: 0.204376, Train Acc: 0.601282 | Val Loss: 0.216997, Val Acc: 0.536082\n",
      "Epoch 3896 - Train Loss: 0.204359, Train Acc: 0.601282 | Val Loss: 0.216981, Val Acc: 0.536082\n",
      "Epoch 3897 - Train Loss: 0.204343, Train Acc: 0.601282 | Val Loss: 0.216964, Val Acc: 0.536082\n",
      "Epoch 3898 - Train Loss: 0.204326, Train Acc: 0.601282 | Val Loss: 0.216948, Val Acc: 0.536082\n",
      "Epoch 3899 - Train Loss: 0.204310, Train Acc: 0.601282 | Val Loss: 0.216931, Val Acc: 0.536082\n",
      "Epoch 3900 - Train Loss: 0.204294, Train Acc: 0.601282 | Val Loss: 0.216915, Val Acc: 0.536082\n",
      "Epoch 3901 - Train Loss: 0.204277, Train Acc: 0.601282 | Val Loss: 0.216898, Val Acc: 0.536082\n",
      "Epoch 3902 - Train Loss: 0.204261, Train Acc: 0.601282 | Val Loss: 0.216882, Val Acc: 0.536082\n",
      "Epoch 3903 - Train Loss: 0.204244, Train Acc: 0.601282 | Val Loss: 0.216865, Val Acc: 0.536082\n",
      "Epoch 3904 - Train Loss: 0.204228, Train Acc: 0.601282 | Val Loss: 0.216849, Val Acc: 0.536082\n",
      "Epoch 3905 - Train Loss: 0.204211, Train Acc: 0.601282 | Val Loss: 0.216832, Val Acc: 0.536082\n",
      "Epoch 3906 - Train Loss: 0.204195, Train Acc: 0.601282 | Val Loss: 0.216816, Val Acc: 0.536082\n",
      "Epoch 3907 - Train Loss: 0.204178, Train Acc: 0.601282 | Val Loss: 0.216799, Val Acc: 0.536082\n",
      "Epoch 3908 - Train Loss: 0.204162, Train Acc: 0.601282 | Val Loss: 0.216783, Val Acc: 0.536082\n",
      "Epoch 3909 - Train Loss: 0.204146, Train Acc: 0.601282 | Val Loss: 0.216766, Val Acc: 0.536082\n",
      "Epoch 3910 - Train Loss: 0.204129, Train Acc: 0.601282 | Val Loss: 0.216750, Val Acc: 0.536082\n",
      "Epoch 3911 - Train Loss: 0.204113, Train Acc: 0.601282 | Val Loss: 0.216733, Val Acc: 0.536082\n",
      "Epoch 3912 - Train Loss: 0.204096, Train Acc: 0.602564 | Val Loss: 0.216717, Val Acc: 0.536082\n",
      "Epoch 3913 - Train Loss: 0.204080, Train Acc: 0.602564 | Val Loss: 0.216700, Val Acc: 0.536082\n",
      "Epoch 3914 - Train Loss: 0.204063, Train Acc: 0.602564 | Val Loss: 0.216684, Val Acc: 0.536082\n",
      "Epoch 3915 - Train Loss: 0.204047, Train Acc: 0.602564 | Val Loss: 0.216668, Val Acc: 0.536082\n",
      "Epoch 3916 - Train Loss: 0.204031, Train Acc: 0.602564 | Val Loss: 0.216651, Val Acc: 0.536082\n",
      "Epoch 3917 - Train Loss: 0.204014, Train Acc: 0.603846 | Val Loss: 0.216635, Val Acc: 0.536082\n",
      "Epoch 3918 - Train Loss: 0.203998, Train Acc: 0.603846 | Val Loss: 0.216618, Val Acc: 0.536082\n",
      "Epoch 3919 - Train Loss: 0.203981, Train Acc: 0.603846 | Val Loss: 0.216602, Val Acc: 0.536082\n",
      "Epoch 3920 - Train Loss: 0.203965, Train Acc: 0.603846 | Val Loss: 0.216585, Val Acc: 0.536082\n",
      "Epoch 3921 - Train Loss: 0.203949, Train Acc: 0.603846 | Val Loss: 0.216569, Val Acc: 0.536082\n",
      "Epoch 3922 - Train Loss: 0.203932, Train Acc: 0.603846 | Val Loss: 0.216552, Val Acc: 0.536082\n",
      "Epoch 3923 - Train Loss: 0.203916, Train Acc: 0.603846 | Val Loss: 0.216536, Val Acc: 0.536082\n",
      "Epoch 3924 - Train Loss: 0.203899, Train Acc: 0.603846 | Val Loss: 0.216520, Val Acc: 0.536082\n",
      "Epoch 3925 - Train Loss: 0.203883, Train Acc: 0.603846 | Val Loss: 0.216503, Val Acc: 0.536082\n",
      "Epoch 3926 - Train Loss: 0.203867, Train Acc: 0.603846 | Val Loss: 0.216487, Val Acc: 0.536082\n",
      "Epoch 3927 - Train Loss: 0.203850, Train Acc: 0.605128 | Val Loss: 0.216471, Val Acc: 0.536082\n",
      "Epoch 3928 - Train Loss: 0.203834, Train Acc: 0.605128 | Val Loss: 0.216454, Val Acc: 0.536082\n",
      "Epoch 3929 - Train Loss: 0.203817, Train Acc: 0.605128 | Val Loss: 0.216438, Val Acc: 0.536082\n",
      "Epoch 3930 - Train Loss: 0.203801, Train Acc: 0.605128 | Val Loss: 0.216422, Val Acc: 0.536082\n",
      "Epoch 3931 - Train Loss: 0.203785, Train Acc: 0.603846 | Val Loss: 0.216405, Val Acc: 0.536082\n",
      "Epoch 3932 - Train Loss: 0.203768, Train Acc: 0.603846 | Val Loss: 0.216389, Val Acc: 0.536082\n",
      "Epoch 3933 - Train Loss: 0.203752, Train Acc: 0.603846 | Val Loss: 0.216373, Val Acc: 0.536082\n",
      "Epoch 3934 - Train Loss: 0.203736, Train Acc: 0.603846 | Val Loss: 0.216356, Val Acc: 0.536082\n",
      "Epoch 3935 - Train Loss: 0.203719, Train Acc: 0.603846 | Val Loss: 0.216340, Val Acc: 0.536082\n",
      "Epoch 3936 - Train Loss: 0.203703, Train Acc: 0.603846 | Val Loss: 0.216323, Val Acc: 0.536082\n",
      "Epoch 3937 - Train Loss: 0.203687, Train Acc: 0.603846 | Val Loss: 0.216307, Val Acc: 0.536082\n",
      "Epoch 3938 - Train Loss: 0.203670, Train Acc: 0.603846 | Val Loss: 0.216291, Val Acc: 0.536082\n",
      "Epoch 3939 - Train Loss: 0.203654, Train Acc: 0.603846 | Val Loss: 0.216274, Val Acc: 0.536082\n",
      "Epoch 3940 - Train Loss: 0.203637, Train Acc: 0.603846 | Val Loss: 0.216258, Val Acc: 0.536082\n",
      "Epoch 3941 - Train Loss: 0.203621, Train Acc: 0.603846 | Val Loss: 0.216242, Val Acc: 0.536082\n",
      "Epoch 3942 - Train Loss: 0.203605, Train Acc: 0.603846 | Val Loss: 0.216225, Val Acc: 0.536082\n",
      "Epoch 3943 - Train Loss: 0.203588, Train Acc: 0.603846 | Val Loss: 0.216209, Val Acc: 0.536082\n",
      "Epoch 3944 - Train Loss: 0.203572, Train Acc: 0.603846 | Val Loss: 0.216192, Val Acc: 0.536082\n",
      "Epoch 3945 - Train Loss: 0.203556, Train Acc: 0.603846 | Val Loss: 0.216176, Val Acc: 0.536082\n",
      "Epoch 3946 - Train Loss: 0.203539, Train Acc: 0.605128 | Val Loss: 0.216160, Val Acc: 0.536082\n",
      "Epoch 3947 - Train Loss: 0.203523, Train Acc: 0.605128 | Val Loss: 0.216143, Val Acc: 0.536082\n",
      "Epoch 3948 - Train Loss: 0.203507, Train Acc: 0.605128 | Val Loss: 0.216127, Val Acc: 0.536082\n",
      "Epoch 3949 - Train Loss: 0.203490, Train Acc: 0.605128 | Val Loss: 0.216110, Val Acc: 0.536082\n",
      "Epoch 3950 - Train Loss: 0.203474, Train Acc: 0.605128 | Val Loss: 0.216094, Val Acc: 0.536082\n",
      "Epoch 3951 - Train Loss: 0.203458, Train Acc: 0.605128 | Val Loss: 0.216078, Val Acc: 0.536082\n",
      "Epoch 3952 - Train Loss: 0.203441, Train Acc: 0.605128 | Val Loss: 0.216061, Val Acc: 0.536082\n",
      "Epoch 3953 - Train Loss: 0.203425, Train Acc: 0.605128 | Val Loss: 0.216045, Val Acc: 0.536082\n",
      "Epoch 3954 - Train Loss: 0.203409, Train Acc: 0.605128 | Val Loss: 0.216029, Val Acc: 0.536082\n",
      "Epoch 3955 - Train Loss: 0.203392, Train Acc: 0.605128 | Val Loss: 0.216012, Val Acc: 0.536082\n",
      "Epoch 3956 - Train Loss: 0.203376, Train Acc: 0.605128 | Val Loss: 0.215996, Val Acc: 0.536082\n",
      "Epoch 3957 - Train Loss: 0.203360, Train Acc: 0.605128 | Val Loss: 0.215979, Val Acc: 0.536082\n",
      "Epoch 3958 - Train Loss: 0.203343, Train Acc: 0.605128 | Val Loss: 0.215963, Val Acc: 0.536082\n",
      "Epoch 3959 - Train Loss: 0.203327, Train Acc: 0.605128 | Val Loss: 0.215947, Val Acc: 0.536082\n",
      "Epoch 3960 - Train Loss: 0.203311, Train Acc: 0.605128 | Val Loss: 0.215930, Val Acc: 0.536082\n",
      "Epoch 3961 - Train Loss: 0.203295, Train Acc: 0.605128 | Val Loss: 0.215914, Val Acc: 0.536082\n",
      "Epoch 3962 - Train Loss: 0.203278, Train Acc: 0.605128 | Val Loss: 0.215898, Val Acc: 0.536082\n",
      "Epoch 3963 - Train Loss: 0.203262, Train Acc: 0.605128 | Val Loss: 0.215881, Val Acc: 0.536082\n",
      "Epoch 3964 - Train Loss: 0.203246, Train Acc: 0.605128 | Val Loss: 0.215865, Val Acc: 0.536082\n",
      "Epoch 3965 - Train Loss: 0.203229, Train Acc: 0.605128 | Val Loss: 0.215848, Val Acc: 0.536082\n",
      "Epoch 3966 - Train Loss: 0.203213, Train Acc: 0.605128 | Val Loss: 0.215832, Val Acc: 0.536082\n",
      "Epoch 3967 - Train Loss: 0.203197, Train Acc: 0.605128 | Val Loss: 0.215816, Val Acc: 0.536082\n",
      "Epoch 3968 - Train Loss: 0.203180, Train Acc: 0.605128 | Val Loss: 0.215799, Val Acc: 0.536082\n",
      "Epoch 3969 - Train Loss: 0.203164, Train Acc: 0.605128 | Val Loss: 0.215783, Val Acc: 0.536082\n",
      "Epoch 3970 - Train Loss: 0.203148, Train Acc: 0.605128 | Val Loss: 0.215767, Val Acc: 0.536082\n",
      "Epoch 3971 - Train Loss: 0.203132, Train Acc: 0.605128 | Val Loss: 0.215750, Val Acc: 0.536082\n",
      "Epoch 3972 - Train Loss: 0.203115, Train Acc: 0.605128 | Val Loss: 0.215734, Val Acc: 0.536082\n",
      "Epoch 3973 - Train Loss: 0.203099, Train Acc: 0.605128 | Val Loss: 0.215718, Val Acc: 0.536082\n",
      "Epoch 3974 - Train Loss: 0.203083, Train Acc: 0.605128 | Val Loss: 0.215701, Val Acc: 0.536082\n",
      "Epoch 3975 - Train Loss: 0.203066, Train Acc: 0.605128 | Val Loss: 0.215685, Val Acc: 0.536082\n",
      "Epoch 3976 - Train Loss: 0.203050, Train Acc: 0.605128 | Val Loss: 0.215669, Val Acc: 0.536082\n",
      "Epoch 3977 - Train Loss: 0.203034, Train Acc: 0.605128 | Val Loss: 0.215652, Val Acc: 0.536082\n",
      "Epoch 3978 - Train Loss: 0.203018, Train Acc: 0.605128 | Val Loss: 0.215636, Val Acc: 0.536082\n",
      "Epoch 3979 - Train Loss: 0.203001, Train Acc: 0.605128 | Val Loss: 0.215620, Val Acc: 0.536082\n",
      "Epoch 3980 - Train Loss: 0.202985, Train Acc: 0.605128 | Val Loss: 0.215603, Val Acc: 0.536082\n",
      "Epoch 3981 - Train Loss: 0.202969, Train Acc: 0.605128 | Val Loss: 0.215587, Val Acc: 0.536082\n",
      "Epoch 3982 - Train Loss: 0.202953, Train Acc: 0.605128 | Val Loss: 0.215571, Val Acc: 0.536082\n",
      "Epoch 3983 - Train Loss: 0.202936, Train Acc: 0.605128 | Val Loss: 0.215554, Val Acc: 0.536082\n",
      "Epoch 3984 - Train Loss: 0.202920, Train Acc: 0.605128 | Val Loss: 0.215538, Val Acc: 0.536082\n",
      "Epoch 3985 - Train Loss: 0.202904, Train Acc: 0.605128 | Val Loss: 0.215522, Val Acc: 0.536082\n",
      "Epoch 3986 - Train Loss: 0.202888, Train Acc: 0.605128 | Val Loss: 0.215505, Val Acc: 0.536082\n",
      "Epoch 3987 - Train Loss: 0.202871, Train Acc: 0.605128 | Val Loss: 0.215489, Val Acc: 0.536082\n",
      "Epoch 3988 - Train Loss: 0.202855, Train Acc: 0.605128 | Val Loss: 0.215473, Val Acc: 0.536082\n",
      "Epoch 3989 - Train Loss: 0.202839, Train Acc: 0.605128 | Val Loss: 0.215456, Val Acc: 0.536082\n",
      "Epoch 3990 - Train Loss: 0.202823, Train Acc: 0.605128 | Val Loss: 0.215440, Val Acc: 0.536082\n",
      "Epoch 3991 - Train Loss: 0.202806, Train Acc: 0.605128 | Val Loss: 0.215424, Val Acc: 0.536082\n",
      "Epoch 3992 - Train Loss: 0.202790, Train Acc: 0.605128 | Val Loss: 0.215407, Val Acc: 0.536082\n",
      "Epoch 3993 - Train Loss: 0.202774, Train Acc: 0.605128 | Val Loss: 0.215391, Val Acc: 0.536082\n",
      "Epoch 3994 - Train Loss: 0.202758, Train Acc: 0.605128 | Val Loss: 0.215375, Val Acc: 0.536082\n",
      "Epoch 3995 - Train Loss: 0.202741, Train Acc: 0.605128 | Val Loss: 0.215358, Val Acc: 0.536082\n",
      "Epoch 3996 - Train Loss: 0.202725, Train Acc: 0.605128 | Val Loss: 0.215342, Val Acc: 0.536082\n",
      "Epoch 3997 - Train Loss: 0.202709, Train Acc: 0.605128 | Val Loss: 0.215326, Val Acc: 0.536082\n",
      "Epoch 3998 - Train Loss: 0.202693, Train Acc: 0.605128 | Val Loss: 0.215309, Val Acc: 0.536082\n",
      "Epoch 3999 - Train Loss: 0.202677, Train Acc: 0.605128 | Val Loss: 0.215293, Val Acc: 0.536082\n",
      "Epoch 4000 - Train Loss: 0.202660, Train Acc: 0.605128 | Val Loss: 0.215277, Val Acc: 0.536082\n",
      "Epoch 4001 - Train Loss: 0.202644, Train Acc: 0.605128 | Val Loss: 0.215260, Val Acc: 0.536082\n",
      "Epoch 4002 - Train Loss: 0.202628, Train Acc: 0.605128 | Val Loss: 0.215244, Val Acc: 0.536082\n",
      "Epoch 4003 - Train Loss: 0.202612, Train Acc: 0.605128 | Val Loss: 0.215228, Val Acc: 0.536082\n",
      "Epoch 4004 - Train Loss: 0.202595, Train Acc: 0.605128 | Val Loss: 0.215212, Val Acc: 0.536082\n",
      "Epoch 4005 - Train Loss: 0.202579, Train Acc: 0.605128 | Val Loss: 0.215195, Val Acc: 0.536082\n",
      "Epoch 4006 - Train Loss: 0.202563, Train Acc: 0.605128 | Val Loss: 0.215179, Val Acc: 0.536082\n",
      "Epoch 4007 - Train Loss: 0.202547, Train Acc: 0.605128 | Val Loss: 0.215163, Val Acc: 0.536082\n",
      "Epoch 4008 - Train Loss: 0.202531, Train Acc: 0.605128 | Val Loss: 0.215146, Val Acc: 0.536082\n",
      "Epoch 4009 - Train Loss: 0.202514, Train Acc: 0.605128 | Val Loss: 0.215130, Val Acc: 0.536082\n",
      "Epoch 4010 - Train Loss: 0.202498, Train Acc: 0.605128 | Val Loss: 0.215114, Val Acc: 0.536082\n",
      "Epoch 4011 - Train Loss: 0.202482, Train Acc: 0.605128 | Val Loss: 0.215097, Val Acc: 0.536082\n",
      "Epoch 4012 - Train Loss: 0.202466, Train Acc: 0.605128 | Val Loss: 0.215081, Val Acc: 0.536082\n",
      "Epoch 4013 - Train Loss: 0.202450, Train Acc: 0.605128 | Val Loss: 0.215065, Val Acc: 0.536082\n",
      "Epoch 4014 - Train Loss: 0.202433, Train Acc: 0.605128 | Val Loss: 0.215048, Val Acc: 0.536082\n",
      "Epoch 4015 - Train Loss: 0.202417, Train Acc: 0.605128 | Val Loss: 0.215032, Val Acc: 0.536082\n",
      "Epoch 4016 - Train Loss: 0.202401, Train Acc: 0.605128 | Val Loss: 0.215016, Val Acc: 0.536082\n",
      "Epoch 4017 - Train Loss: 0.202385, Train Acc: 0.605128 | Val Loss: 0.214999, Val Acc: 0.536082\n",
      "Epoch 4018 - Train Loss: 0.202369, Train Acc: 0.605128 | Val Loss: 0.214983, Val Acc: 0.536082\n",
      "Epoch 4019 - Train Loss: 0.202352, Train Acc: 0.605128 | Val Loss: 0.214967, Val Acc: 0.536082\n",
      "Epoch 4020 - Train Loss: 0.202336, Train Acc: 0.605128 | Val Loss: 0.214951, Val Acc: 0.536082\n",
      "Epoch 4021 - Train Loss: 0.202320, Train Acc: 0.605128 | Val Loss: 0.214934, Val Acc: 0.536082\n",
      "Epoch 4022 - Train Loss: 0.202304, Train Acc: 0.605128 | Val Loss: 0.214918, Val Acc: 0.536082\n",
      "Epoch 4023 - Train Loss: 0.202288, Train Acc: 0.605128 | Val Loss: 0.214902, Val Acc: 0.536082\n",
      "Epoch 4024 - Train Loss: 0.202272, Train Acc: 0.605128 | Val Loss: 0.214885, Val Acc: 0.536082\n",
      "Epoch 4025 - Train Loss: 0.202255, Train Acc: 0.605128 | Val Loss: 0.214869, Val Acc: 0.536082\n",
      "Epoch 4026 - Train Loss: 0.202239, Train Acc: 0.605128 | Val Loss: 0.214853, Val Acc: 0.536082\n",
      "Epoch 4027 - Train Loss: 0.202223, Train Acc: 0.605128 | Val Loss: 0.214837, Val Acc: 0.536082\n",
      "Epoch 4028 - Train Loss: 0.202207, Train Acc: 0.605128 | Val Loss: 0.214820, Val Acc: 0.536082\n",
      "Epoch 4029 - Train Loss: 0.202191, Train Acc: 0.605128 | Val Loss: 0.214804, Val Acc: 0.536082\n",
      "Epoch 4030 - Train Loss: 0.202175, Train Acc: 0.605128 | Val Loss: 0.214788, Val Acc: 0.536082\n",
      "Epoch 4031 - Train Loss: 0.202158, Train Acc: 0.605128 | Val Loss: 0.214772, Val Acc: 0.536082\n",
      "Epoch 4032 - Train Loss: 0.202142, Train Acc: 0.605128 | Val Loss: 0.214755, Val Acc: 0.536082\n",
      "Epoch 4033 - Train Loss: 0.202126, Train Acc: 0.605128 | Val Loss: 0.214739, Val Acc: 0.536082\n",
      "Epoch 4034 - Train Loss: 0.202110, Train Acc: 0.605128 | Val Loss: 0.214723, Val Acc: 0.536082\n",
      "Epoch 4035 - Train Loss: 0.202094, Train Acc: 0.605128 | Val Loss: 0.214706, Val Acc: 0.536082\n",
      "Epoch 4036 - Train Loss: 0.202078, Train Acc: 0.605128 | Val Loss: 0.214690, Val Acc: 0.536082\n",
      "Epoch 4037 - Train Loss: 0.202062, Train Acc: 0.605128 | Val Loss: 0.214674, Val Acc: 0.536082\n",
      "Epoch 4038 - Train Loss: 0.202045, Train Acc: 0.605128 | Val Loss: 0.214658, Val Acc: 0.536082\n",
      "Epoch 4039 - Train Loss: 0.202029, Train Acc: 0.605128 | Val Loss: 0.214641, Val Acc: 0.536082\n",
      "Epoch 4040 - Train Loss: 0.202013, Train Acc: 0.605128 | Val Loss: 0.214625, Val Acc: 0.536082\n",
      "Epoch 4041 - Train Loss: 0.201997, Train Acc: 0.605128 | Val Loss: 0.214609, Val Acc: 0.536082\n",
      "Epoch 4042 - Train Loss: 0.201981, Train Acc: 0.605128 | Val Loss: 0.214593, Val Acc: 0.536082\n",
      "Epoch 4043 - Train Loss: 0.201965, Train Acc: 0.605128 | Val Loss: 0.214576, Val Acc: 0.536082\n",
      "Epoch 4044 - Train Loss: 0.201949, Train Acc: 0.605128 | Val Loss: 0.214560, Val Acc: 0.536082\n",
      "Epoch 4045 - Train Loss: 0.201933, Train Acc: 0.605128 | Val Loss: 0.214544, Val Acc: 0.536082\n",
      "Epoch 4046 - Train Loss: 0.201916, Train Acc: 0.605128 | Val Loss: 0.214528, Val Acc: 0.536082\n",
      "Epoch 4047 - Train Loss: 0.201900, Train Acc: 0.605128 | Val Loss: 0.214512, Val Acc: 0.536082\n",
      "Epoch 4048 - Train Loss: 0.201884, Train Acc: 0.605128 | Val Loss: 0.214495, Val Acc: 0.536082\n",
      "Epoch 4049 - Train Loss: 0.201868, Train Acc: 0.605128 | Val Loss: 0.214479, Val Acc: 0.536082\n",
      "Epoch 4050 - Train Loss: 0.201852, Train Acc: 0.605128 | Val Loss: 0.214463, Val Acc: 0.536082\n",
      "Epoch 4051 - Train Loss: 0.201836, Train Acc: 0.605128 | Val Loss: 0.214447, Val Acc: 0.536082\n",
      "Epoch 4052 - Train Loss: 0.201820, Train Acc: 0.605128 | Val Loss: 0.214430, Val Acc: 0.536082\n",
      "Epoch 4053 - Train Loss: 0.201804, Train Acc: 0.605128 | Val Loss: 0.214414, Val Acc: 0.536082\n",
      "Epoch 4054 - Train Loss: 0.201787, Train Acc: 0.605128 | Val Loss: 0.214398, Val Acc: 0.536082\n",
      "Epoch 4055 - Train Loss: 0.201771, Train Acc: 0.605128 | Val Loss: 0.214382, Val Acc: 0.536082\n",
      "Epoch 4056 - Train Loss: 0.201755, Train Acc: 0.605128 | Val Loss: 0.214366, Val Acc: 0.536082\n",
      "Epoch 4057 - Train Loss: 0.201739, Train Acc: 0.605128 | Val Loss: 0.214349, Val Acc: 0.536082\n",
      "Epoch 4058 - Train Loss: 0.201723, Train Acc: 0.605128 | Val Loss: 0.214333, Val Acc: 0.536082\n",
      "Epoch 4059 - Train Loss: 0.201707, Train Acc: 0.605128 | Val Loss: 0.214317, Val Acc: 0.536082\n",
      "Epoch 4060 - Train Loss: 0.201691, Train Acc: 0.605128 | Val Loss: 0.214301, Val Acc: 0.536082\n",
      "Epoch 4061 - Train Loss: 0.201675, Train Acc: 0.605128 | Val Loss: 0.214285, Val Acc: 0.536082\n",
      "Epoch 4062 - Train Loss: 0.201659, Train Acc: 0.605128 | Val Loss: 0.214268, Val Acc: 0.536082\n",
      "Epoch 4063 - Train Loss: 0.201643, Train Acc: 0.605128 | Val Loss: 0.214252, Val Acc: 0.536082\n",
      "Epoch 4064 - Train Loss: 0.201627, Train Acc: 0.605128 | Val Loss: 0.214236, Val Acc: 0.536082\n",
      "Epoch 4065 - Train Loss: 0.201610, Train Acc: 0.605128 | Val Loss: 0.214220, Val Acc: 0.536082\n",
      "Epoch 4066 - Train Loss: 0.201594, Train Acc: 0.605128 | Val Loss: 0.214204, Val Acc: 0.536082\n",
      "Epoch 4067 - Train Loss: 0.201578, Train Acc: 0.605128 | Val Loss: 0.214187, Val Acc: 0.536082\n",
      "Epoch 4068 - Train Loss: 0.201562, Train Acc: 0.605128 | Val Loss: 0.214171, Val Acc: 0.536082\n",
      "Epoch 4069 - Train Loss: 0.201546, Train Acc: 0.605128 | Val Loss: 0.214155, Val Acc: 0.536082\n",
      "Epoch 4070 - Train Loss: 0.201530, Train Acc: 0.605128 | Val Loss: 0.214139, Val Acc: 0.536082\n",
      "Epoch 4071 - Train Loss: 0.201514, Train Acc: 0.605128 | Val Loss: 0.214123, Val Acc: 0.536082\n",
      "Epoch 4072 - Train Loss: 0.201498, Train Acc: 0.605128 | Val Loss: 0.214106, Val Acc: 0.536082\n",
      "Epoch 4073 - Train Loss: 0.201482, Train Acc: 0.605128 | Val Loss: 0.214090, Val Acc: 0.536082\n",
      "Epoch 4074 - Train Loss: 0.201466, Train Acc: 0.605128 | Val Loss: 0.214074, Val Acc: 0.536082\n",
      "Epoch 4075 - Train Loss: 0.201450, Train Acc: 0.605128 | Val Loss: 0.214058, Val Acc: 0.536082\n",
      "Epoch 4076 - Train Loss: 0.201434, Train Acc: 0.605128 | Val Loss: 0.214042, Val Acc: 0.536082\n",
      "Epoch 4077 - Train Loss: 0.201418, Train Acc: 0.605128 | Val Loss: 0.214026, Val Acc: 0.536082\n",
      "Epoch 4078 - Train Loss: 0.201402, Train Acc: 0.605128 | Val Loss: 0.214009, Val Acc: 0.536082\n",
      "Epoch 4079 - Train Loss: 0.201386, Train Acc: 0.605128 | Val Loss: 0.213993, Val Acc: 0.536082\n",
      "Epoch 4080 - Train Loss: 0.201370, Train Acc: 0.605128 | Val Loss: 0.213977, Val Acc: 0.536082\n",
      "Epoch 4081 - Train Loss: 0.201354, Train Acc: 0.605128 | Val Loss: 0.213961, Val Acc: 0.536082\n",
      "Epoch 4082 - Train Loss: 0.201337, Train Acc: 0.605128 | Val Loss: 0.213945, Val Acc: 0.536082\n",
      "Epoch 4083 - Train Loss: 0.201321, Train Acc: 0.605128 | Val Loss: 0.213929, Val Acc: 0.536082\n",
      "Epoch 4084 - Train Loss: 0.201305, Train Acc: 0.605128 | Val Loss: 0.213913, Val Acc: 0.536082\n",
      "Epoch 4085 - Train Loss: 0.201289, Train Acc: 0.605128 | Val Loss: 0.213896, Val Acc: 0.536082\n",
      "Epoch 4086 - Train Loss: 0.201273, Train Acc: 0.605128 | Val Loss: 0.213880, Val Acc: 0.536082\n",
      "Epoch 4087 - Train Loss: 0.201257, Train Acc: 0.605128 | Val Loss: 0.213864, Val Acc: 0.536082\n",
      "Epoch 4088 - Train Loss: 0.201241, Train Acc: 0.605128 | Val Loss: 0.213848, Val Acc: 0.536082\n",
      "Epoch 4089 - Train Loss: 0.201225, Train Acc: 0.605128 | Val Loss: 0.213832, Val Acc: 0.536082\n",
      "Epoch 4090 - Train Loss: 0.201209, Train Acc: 0.605128 | Val Loss: 0.213816, Val Acc: 0.536082\n",
      "Epoch 4091 - Train Loss: 0.201193, Train Acc: 0.605128 | Val Loss: 0.213800, Val Acc: 0.536082\n",
      "Epoch 4092 - Train Loss: 0.201177, Train Acc: 0.605128 | Val Loss: 0.213784, Val Acc: 0.536082\n",
      "Epoch 4093 - Train Loss: 0.201161, Train Acc: 0.605128 | Val Loss: 0.213768, Val Acc: 0.536082\n",
      "Epoch 4094 - Train Loss: 0.201145, Train Acc: 0.605128 | Val Loss: 0.213751, Val Acc: 0.536082\n",
      "Epoch 4095 - Train Loss: 0.201129, Train Acc: 0.605128 | Val Loss: 0.213735, Val Acc: 0.536082\n",
      "Epoch 4096 - Train Loss: 0.201113, Train Acc: 0.605128 | Val Loss: 0.213719, Val Acc: 0.536082\n",
      "Epoch 4097 - Train Loss: 0.201097, Train Acc: 0.605128 | Val Loss: 0.213703, Val Acc: 0.536082\n",
      "Epoch 4098 - Train Loss: 0.201081, Train Acc: 0.605128 | Val Loss: 0.213687, Val Acc: 0.536082\n",
      "Epoch 4099 - Train Loss: 0.201065, Train Acc: 0.605128 | Val Loss: 0.213671, Val Acc: 0.536082\n",
      "Epoch 4100 - Train Loss: 0.201049, Train Acc: 0.605128 | Val Loss: 0.213655, Val Acc: 0.536082\n",
      "Epoch 4101 - Train Loss: 0.201033, Train Acc: 0.605128 | Val Loss: 0.213639, Val Acc: 0.536082\n",
      "Epoch 4102 - Train Loss: 0.201017, Train Acc: 0.605128 | Val Loss: 0.213623, Val Acc: 0.536082\n",
      "Epoch 4103 - Train Loss: 0.201001, Train Acc: 0.605128 | Val Loss: 0.213607, Val Acc: 0.536082\n",
      "Epoch 4104 - Train Loss: 0.200985, Train Acc: 0.605128 | Val Loss: 0.213590, Val Acc: 0.536082\n",
      "Epoch 4105 - Train Loss: 0.200969, Train Acc: 0.605128 | Val Loss: 0.213574, Val Acc: 0.536082\n",
      "Epoch 4106 - Train Loss: 0.200953, Train Acc: 0.605128 | Val Loss: 0.213558, Val Acc: 0.536082\n",
      "Epoch 4107 - Train Loss: 0.200937, Train Acc: 0.605128 | Val Loss: 0.213542, Val Acc: 0.536082\n",
      "Epoch 4108 - Train Loss: 0.200921, Train Acc: 0.605128 | Val Loss: 0.213526, Val Acc: 0.536082\n",
      "Epoch 4109 - Train Loss: 0.200905, Train Acc: 0.605128 | Val Loss: 0.213510, Val Acc: 0.536082\n",
      "Epoch 4110 - Train Loss: 0.200889, Train Acc: 0.605128 | Val Loss: 0.213494, Val Acc: 0.536082\n",
      "Epoch 4111 - Train Loss: 0.200873, Train Acc: 0.605128 | Val Loss: 0.213478, Val Acc: 0.536082\n",
      "Epoch 4112 - Train Loss: 0.200857, Train Acc: 0.605128 | Val Loss: 0.213462, Val Acc: 0.536082\n",
      "Epoch 4113 - Train Loss: 0.200841, Train Acc: 0.605128 | Val Loss: 0.213446, Val Acc: 0.536082\n",
      "Epoch 4114 - Train Loss: 0.200825, Train Acc: 0.605128 | Val Loss: 0.213430, Val Acc: 0.536082\n",
      "Epoch 4115 - Train Loss: 0.200809, Train Acc: 0.605128 | Val Loss: 0.213414, Val Acc: 0.536082\n",
      "Epoch 4116 - Train Loss: 0.200794, Train Acc: 0.605128 | Val Loss: 0.213398, Val Acc: 0.536082\n",
      "Epoch 4117 - Train Loss: 0.200778, Train Acc: 0.605128 | Val Loss: 0.213382, Val Acc: 0.536082\n",
      "Epoch 4118 - Train Loss: 0.200762, Train Acc: 0.605128 | Val Loss: 0.213365, Val Acc: 0.536082\n",
      "Epoch 4119 - Train Loss: 0.200746, Train Acc: 0.605128 | Val Loss: 0.213349, Val Acc: 0.536082\n",
      "Epoch 4120 - Train Loss: 0.200730, Train Acc: 0.605128 | Val Loss: 0.213333, Val Acc: 0.536082\n",
      "Epoch 4121 - Train Loss: 0.200714, Train Acc: 0.605128 | Val Loss: 0.213317, Val Acc: 0.536082\n",
      "Epoch 4122 - Train Loss: 0.200698, Train Acc: 0.605128 | Val Loss: 0.213301, Val Acc: 0.536082\n",
      "Epoch 4123 - Train Loss: 0.200682, Train Acc: 0.605128 | Val Loss: 0.213285, Val Acc: 0.536082\n",
      "Epoch 4124 - Train Loss: 0.200666, Train Acc: 0.605128 | Val Loss: 0.213269, Val Acc: 0.536082\n",
      "Epoch 4125 - Train Loss: 0.200650, Train Acc: 0.605128 | Val Loss: 0.213253, Val Acc: 0.536082\n",
      "Epoch 4126 - Train Loss: 0.200634, Train Acc: 0.605128 | Val Loss: 0.213237, Val Acc: 0.536082\n",
      "Epoch 4127 - Train Loss: 0.200618, Train Acc: 0.605128 | Val Loss: 0.213221, Val Acc: 0.536082\n",
      "Epoch 4128 - Train Loss: 0.200602, Train Acc: 0.605128 | Val Loss: 0.213205, Val Acc: 0.536082\n",
      "Epoch 4129 - Train Loss: 0.200586, Train Acc: 0.605128 | Val Loss: 0.213189, Val Acc: 0.536082\n",
      "Epoch 4130 - Train Loss: 0.200570, Train Acc: 0.605128 | Val Loss: 0.213173, Val Acc: 0.536082\n",
      "Epoch 4131 - Train Loss: 0.200554, Train Acc: 0.605128 | Val Loss: 0.213157, Val Acc: 0.536082\n",
      "Epoch 4132 - Train Loss: 0.200538, Train Acc: 0.605128 | Val Loss: 0.213141, Val Acc: 0.536082\n",
      "Epoch 4133 - Train Loss: 0.200522, Train Acc: 0.605128 | Val Loss: 0.213125, Val Acc: 0.536082\n",
      "Epoch 4134 - Train Loss: 0.200507, Train Acc: 0.605128 | Val Loss: 0.213109, Val Acc: 0.536082\n",
      "Epoch 4135 - Train Loss: 0.200491, Train Acc: 0.605128 | Val Loss: 0.213093, Val Acc: 0.536082\n",
      "Epoch 4136 - Train Loss: 0.200475, Train Acc: 0.605128 | Val Loss: 0.213077, Val Acc: 0.536082\n",
      "Epoch 4137 - Train Loss: 0.200459, Train Acc: 0.605128 | Val Loss: 0.213061, Val Acc: 0.536082\n",
      "Epoch 4138 - Train Loss: 0.200443, Train Acc: 0.606410 | Val Loss: 0.213045, Val Acc: 0.536082\n",
      "Epoch 4139 - Train Loss: 0.200427, Train Acc: 0.606410 | Val Loss: 0.213029, Val Acc: 0.536082\n",
      "Epoch 4140 - Train Loss: 0.200411, Train Acc: 0.606410 | Val Loss: 0.213013, Val Acc: 0.536082\n",
      "Epoch 4141 - Train Loss: 0.200395, Train Acc: 0.606410 | Val Loss: 0.212997, Val Acc: 0.536082\n",
      "Epoch 4142 - Train Loss: 0.200379, Train Acc: 0.606410 | Val Loss: 0.212981, Val Acc: 0.536082\n",
      "Epoch 4143 - Train Loss: 0.200363, Train Acc: 0.606410 | Val Loss: 0.212965, Val Acc: 0.536082\n",
      "Epoch 4144 - Train Loss: 0.200347, Train Acc: 0.606410 | Val Loss: 0.212949, Val Acc: 0.536082\n",
      "Epoch 4145 - Train Loss: 0.200332, Train Acc: 0.606410 | Val Loss: 0.212933, Val Acc: 0.536082\n",
      "Epoch 4146 - Train Loss: 0.200316, Train Acc: 0.606410 | Val Loss: 0.212917, Val Acc: 0.536082\n",
      "Epoch 4147 - Train Loss: 0.200300, Train Acc: 0.606410 | Val Loss: 0.212901, Val Acc: 0.536082\n",
      "Epoch 4148 - Train Loss: 0.200284, Train Acc: 0.606410 | Val Loss: 0.212885, Val Acc: 0.536082\n",
      "Epoch 4149 - Train Loss: 0.200268, Train Acc: 0.606410 | Val Loss: 0.212869, Val Acc: 0.536082\n",
      "Epoch 4150 - Train Loss: 0.200252, Train Acc: 0.606410 | Val Loss: 0.212853, Val Acc: 0.536082\n",
      "Epoch 4151 - Train Loss: 0.200236, Train Acc: 0.606410 | Val Loss: 0.212837, Val Acc: 0.536082\n",
      "Epoch 4152 - Train Loss: 0.200220, Train Acc: 0.606410 | Val Loss: 0.212821, Val Acc: 0.536082\n",
      "Epoch 4153 - Train Loss: 0.200204, Train Acc: 0.606410 | Val Loss: 0.212805, Val Acc: 0.536082\n",
      "Epoch 4154 - Train Loss: 0.200189, Train Acc: 0.606410 | Val Loss: 0.212789, Val Acc: 0.536082\n",
      "Epoch 4155 - Train Loss: 0.200173, Train Acc: 0.606410 | Val Loss: 0.212773, Val Acc: 0.536082\n",
      "Epoch 4156 - Train Loss: 0.200157, Train Acc: 0.606410 | Val Loss: 0.212757, Val Acc: 0.536082\n",
      "Epoch 4157 - Train Loss: 0.200141, Train Acc: 0.606410 | Val Loss: 0.212741, Val Acc: 0.536082\n",
      "Epoch 4158 - Train Loss: 0.200125, Train Acc: 0.606410 | Val Loss: 0.212725, Val Acc: 0.536082\n",
      "Epoch 4159 - Train Loss: 0.200109, Train Acc: 0.606410 | Val Loss: 0.212709, Val Acc: 0.536082\n",
      "Epoch 4160 - Train Loss: 0.200093, Train Acc: 0.606410 | Val Loss: 0.212693, Val Acc: 0.536082\n",
      "Epoch 4161 - Train Loss: 0.200077, Train Acc: 0.606410 | Val Loss: 0.212677, Val Acc: 0.536082\n",
      "Epoch 4162 - Train Loss: 0.200062, Train Acc: 0.606410 | Val Loss: 0.212661, Val Acc: 0.536082\n",
      "Epoch 4163 - Train Loss: 0.200046, Train Acc: 0.606410 | Val Loss: 0.212645, Val Acc: 0.536082\n",
      "Epoch 4164 - Train Loss: 0.200030, Train Acc: 0.606410 | Val Loss: 0.212629, Val Acc: 0.536082\n",
      "Epoch 4165 - Train Loss: 0.200014, Train Acc: 0.606410 | Val Loss: 0.212613, Val Acc: 0.536082\n",
      "Epoch 4166 - Train Loss: 0.199998, Train Acc: 0.606410 | Val Loss: 0.212597, Val Acc: 0.536082\n",
      "Epoch 4167 - Train Loss: 0.199982, Train Acc: 0.606410 | Val Loss: 0.212581, Val Acc: 0.536082\n",
      "Epoch 4168 - Train Loss: 0.199966, Train Acc: 0.606410 | Val Loss: 0.212565, Val Acc: 0.536082\n",
      "Epoch 4169 - Train Loss: 0.199951, Train Acc: 0.606410 | Val Loss: 0.212549, Val Acc: 0.536082\n",
      "Epoch 4170 - Train Loss: 0.199935, Train Acc: 0.606410 | Val Loss: 0.212533, Val Acc: 0.536082\n",
      "Epoch 4171 - Train Loss: 0.199919, Train Acc: 0.606410 | Val Loss: 0.212517, Val Acc: 0.536082\n",
      "Epoch 4172 - Train Loss: 0.199903, Train Acc: 0.606410 | Val Loss: 0.212501, Val Acc: 0.536082\n",
      "Epoch 4173 - Train Loss: 0.199887, Train Acc: 0.606410 | Val Loss: 0.212485, Val Acc: 0.536082\n",
      "Epoch 4174 - Train Loss: 0.199871, Train Acc: 0.606410 | Val Loss: 0.212469, Val Acc: 0.536082\n",
      "Epoch 4175 - Train Loss: 0.199856, Train Acc: 0.606410 | Val Loss: 0.212454, Val Acc: 0.536082\n",
      "Epoch 4176 - Train Loss: 0.199840, Train Acc: 0.606410 | Val Loss: 0.212438, Val Acc: 0.536082\n",
      "Epoch 4177 - Train Loss: 0.199824, Train Acc: 0.606410 | Val Loss: 0.212422, Val Acc: 0.536082\n",
      "Epoch 4178 - Train Loss: 0.199808, Train Acc: 0.606410 | Val Loss: 0.212406, Val Acc: 0.536082\n",
      "Epoch 4179 - Train Loss: 0.199792, Train Acc: 0.606410 | Val Loss: 0.212390, Val Acc: 0.536082\n",
      "Epoch 4180 - Train Loss: 0.199776, Train Acc: 0.606410 | Val Loss: 0.212374, Val Acc: 0.536082\n",
      "Epoch 4181 - Train Loss: 0.199761, Train Acc: 0.606410 | Val Loss: 0.212358, Val Acc: 0.536082\n",
      "Epoch 4182 - Train Loss: 0.199745, Train Acc: 0.606410 | Val Loss: 0.212342, Val Acc: 0.536082\n",
      "Epoch 4183 - Train Loss: 0.199729, Train Acc: 0.606410 | Val Loss: 0.212326, Val Acc: 0.536082\n",
      "Epoch 4184 - Train Loss: 0.199713, Train Acc: 0.606410 | Val Loss: 0.212310, Val Acc: 0.536082\n",
      "Epoch 4185 - Train Loss: 0.199697, Train Acc: 0.606410 | Val Loss: 0.212294, Val Acc: 0.536082\n",
      "Epoch 4186 - Train Loss: 0.199681, Train Acc: 0.606410 | Val Loss: 0.212278, Val Acc: 0.536082\n",
      "Epoch 4187 - Train Loss: 0.199666, Train Acc: 0.606410 | Val Loss: 0.212262, Val Acc: 0.536082\n",
      "Epoch 4188 - Train Loss: 0.199650, Train Acc: 0.606410 | Val Loss: 0.212246, Val Acc: 0.536082\n",
      "Epoch 4189 - Train Loss: 0.199634, Train Acc: 0.606410 | Val Loss: 0.212231, Val Acc: 0.536082\n",
      "Epoch 4190 - Train Loss: 0.199618, Train Acc: 0.606410 | Val Loss: 0.212215, Val Acc: 0.536082\n",
      "Epoch 4191 - Train Loss: 0.199602, Train Acc: 0.606410 | Val Loss: 0.212199, Val Acc: 0.536082\n",
      "Epoch 4192 - Train Loss: 0.199587, Train Acc: 0.606410 | Val Loss: 0.212183, Val Acc: 0.536082\n",
      "Epoch 4193 - Train Loss: 0.199571, Train Acc: 0.606410 | Val Loss: 0.212167, Val Acc: 0.536082\n",
      "Epoch 4194 - Train Loss: 0.199555, Train Acc: 0.606410 | Val Loss: 0.212151, Val Acc: 0.536082\n",
      "Epoch 4195 - Train Loss: 0.199539, Train Acc: 0.606410 | Val Loss: 0.212135, Val Acc: 0.536082\n",
      "Epoch 4196 - Train Loss: 0.199523, Train Acc: 0.606410 | Val Loss: 0.212119, Val Acc: 0.536082\n",
      "Epoch 4197 - Train Loss: 0.199508, Train Acc: 0.606410 | Val Loss: 0.212103, Val Acc: 0.536082\n",
      "Epoch 4198 - Train Loss: 0.199492, Train Acc: 0.606410 | Val Loss: 0.212087, Val Acc: 0.536082\n",
      "Epoch 4199 - Train Loss: 0.199476, Train Acc: 0.606410 | Val Loss: 0.212072, Val Acc: 0.536082\n",
      "Epoch 4200 - Train Loss: 0.199460, Train Acc: 0.606410 | Val Loss: 0.212056, Val Acc: 0.536082\n",
      "Epoch 4201 - Train Loss: 0.199444, Train Acc: 0.606410 | Val Loss: 0.212040, Val Acc: 0.536082\n",
      "Epoch 4202 - Train Loss: 0.199429, Train Acc: 0.606410 | Val Loss: 0.212024, Val Acc: 0.536082\n",
      "Epoch 4203 - Train Loss: 0.199413, Train Acc: 0.606410 | Val Loss: 0.212008, Val Acc: 0.536082\n",
      "Epoch 4204 - Train Loss: 0.199397, Train Acc: 0.606410 | Val Loss: 0.211992, Val Acc: 0.536082\n",
      "Epoch 4205 - Train Loss: 0.199381, Train Acc: 0.606410 | Val Loss: 0.211976, Val Acc: 0.536082\n",
      "Epoch 4206 - Train Loss: 0.199366, Train Acc: 0.606410 | Val Loss: 0.211960, Val Acc: 0.536082\n",
      "Epoch 4207 - Train Loss: 0.199350, Train Acc: 0.606410 | Val Loss: 0.211945, Val Acc: 0.536082\n",
      "Epoch 4208 - Train Loss: 0.199334, Train Acc: 0.606410 | Val Loss: 0.211929, Val Acc: 0.536082\n",
      "Epoch 4209 - Train Loss: 0.199318, Train Acc: 0.606410 | Val Loss: 0.211913, Val Acc: 0.536082\n",
      "Epoch 4210 - Train Loss: 0.199303, Train Acc: 0.606410 | Val Loss: 0.211897, Val Acc: 0.536082\n",
      "Epoch 4211 - Train Loss: 0.199287, Train Acc: 0.606410 | Val Loss: 0.211881, Val Acc: 0.536082\n",
      "Epoch 4212 - Train Loss: 0.199271, Train Acc: 0.606410 | Val Loss: 0.211865, Val Acc: 0.536082\n",
      "Epoch 4213 - Train Loss: 0.199255, Train Acc: 0.606410 | Val Loss: 0.211849, Val Acc: 0.536082\n",
      "Epoch 4214 - Train Loss: 0.199239, Train Acc: 0.606410 | Val Loss: 0.211833, Val Acc: 0.536082\n",
      "Epoch 4215 - Train Loss: 0.199224, Train Acc: 0.606410 | Val Loss: 0.211818, Val Acc: 0.536082\n",
      "Epoch 4216 - Train Loss: 0.199208, Train Acc: 0.606410 | Val Loss: 0.211802, Val Acc: 0.536082\n",
      "Epoch 4217 - Train Loss: 0.199192, Train Acc: 0.606410 | Val Loss: 0.211786, Val Acc: 0.536082\n",
      "Epoch 4218 - Train Loss: 0.199176, Train Acc: 0.606410 | Val Loss: 0.211770, Val Acc: 0.536082\n",
      "Epoch 4219 - Train Loss: 0.199161, Train Acc: 0.606410 | Val Loss: 0.211754, Val Acc: 0.536082\n",
      "Epoch 4220 - Train Loss: 0.199145, Train Acc: 0.606410 | Val Loss: 0.211738, Val Acc: 0.536082\n",
      "Epoch 4221 - Train Loss: 0.199129, Train Acc: 0.606410 | Val Loss: 0.211722, Val Acc: 0.536082\n",
      "Epoch 4222 - Train Loss: 0.199113, Train Acc: 0.606410 | Val Loss: 0.211707, Val Acc: 0.536082\n",
      "Epoch 4223 - Train Loss: 0.199098, Train Acc: 0.606410 | Val Loss: 0.211691, Val Acc: 0.536082\n",
      "Epoch 4224 - Train Loss: 0.199082, Train Acc: 0.606410 | Val Loss: 0.211675, Val Acc: 0.536082\n",
      "Epoch 4225 - Train Loss: 0.199066, Train Acc: 0.606410 | Val Loss: 0.211659, Val Acc: 0.536082\n",
      "Epoch 4226 - Train Loss: 0.199051, Train Acc: 0.606410 | Val Loss: 0.211643, Val Acc: 0.536082\n",
      "Epoch 4227 - Train Loss: 0.199035, Train Acc: 0.606410 | Val Loss: 0.211627, Val Acc: 0.536082\n",
      "Epoch 4228 - Train Loss: 0.199019, Train Acc: 0.606410 | Val Loss: 0.211612, Val Acc: 0.536082\n",
      "Epoch 4229 - Train Loss: 0.199003, Train Acc: 0.606410 | Val Loss: 0.211596, Val Acc: 0.536082\n",
      "Epoch 4230 - Train Loss: 0.198988, Train Acc: 0.606410 | Val Loss: 0.211580, Val Acc: 0.536082\n",
      "Epoch 4231 - Train Loss: 0.198972, Train Acc: 0.606410 | Val Loss: 0.211564, Val Acc: 0.536082\n",
      "Epoch 4232 - Train Loss: 0.198956, Train Acc: 0.606410 | Val Loss: 0.211548, Val Acc: 0.536082\n",
      "Epoch 4233 - Train Loss: 0.198940, Train Acc: 0.606410 | Val Loss: 0.211532, Val Acc: 0.536082\n",
      "Epoch 4234 - Train Loss: 0.198925, Train Acc: 0.606410 | Val Loss: 0.211517, Val Acc: 0.536082\n",
      "Epoch 4235 - Train Loss: 0.198909, Train Acc: 0.606410 | Val Loss: 0.211501, Val Acc: 0.536082\n",
      "Epoch 4236 - Train Loss: 0.198893, Train Acc: 0.606410 | Val Loss: 0.211485, Val Acc: 0.536082\n",
      "Epoch 4237 - Train Loss: 0.198878, Train Acc: 0.606410 | Val Loss: 0.211469, Val Acc: 0.536082\n",
      "Epoch 4238 - Train Loss: 0.198862, Train Acc: 0.606410 | Val Loss: 0.211453, Val Acc: 0.536082\n",
      "Epoch 4239 - Train Loss: 0.198846, Train Acc: 0.606410 | Val Loss: 0.211438, Val Acc: 0.536082\n",
      "Epoch 4240 - Train Loss: 0.198830, Train Acc: 0.606410 | Val Loss: 0.211422, Val Acc: 0.536082\n",
      "Epoch 4241 - Train Loss: 0.198815, Train Acc: 0.606410 | Val Loss: 0.211406, Val Acc: 0.536082\n",
      "Epoch 4242 - Train Loss: 0.198799, Train Acc: 0.606410 | Val Loss: 0.211390, Val Acc: 0.536082\n",
      "Epoch 4243 - Train Loss: 0.198783, Train Acc: 0.606410 | Val Loss: 0.211374, Val Acc: 0.536082\n",
      "Epoch 4244 - Train Loss: 0.198768, Train Acc: 0.606410 | Val Loss: 0.211359, Val Acc: 0.536082\n",
      "Epoch 4245 - Train Loss: 0.198752, Train Acc: 0.606410 | Val Loss: 0.211343, Val Acc: 0.536082\n",
      "Epoch 4246 - Train Loss: 0.198736, Train Acc: 0.606410 | Val Loss: 0.211327, Val Acc: 0.536082\n",
      "Epoch 4247 - Train Loss: 0.198721, Train Acc: 0.606410 | Val Loss: 0.211311, Val Acc: 0.536082\n",
      "Epoch 4248 - Train Loss: 0.198705, Train Acc: 0.606410 | Val Loss: 0.211295, Val Acc: 0.536082\n",
      "Epoch 4249 - Train Loss: 0.198689, Train Acc: 0.606410 | Val Loss: 0.211279, Val Acc: 0.536082\n",
      "Epoch 4250 - Train Loss: 0.198674, Train Acc: 0.606410 | Val Loss: 0.211264, Val Acc: 0.536082\n",
      "Epoch 4251 - Train Loss: 0.198658, Train Acc: 0.606410 | Val Loss: 0.211248, Val Acc: 0.536082\n",
      "Epoch 4252 - Train Loss: 0.198642, Train Acc: 0.606410 | Val Loss: 0.211232, Val Acc: 0.536082\n",
      "Epoch 4253 - Train Loss: 0.198626, Train Acc: 0.606410 | Val Loss: 0.211216, Val Acc: 0.536082\n",
      "Epoch 4254 - Train Loss: 0.198611, Train Acc: 0.606410 | Val Loss: 0.211201, Val Acc: 0.536082\n",
      "Epoch 4255 - Train Loss: 0.198595, Train Acc: 0.606410 | Val Loss: 0.211185, Val Acc: 0.536082\n",
      "Epoch 4256 - Train Loss: 0.198579, Train Acc: 0.606410 | Val Loss: 0.211169, Val Acc: 0.536082\n",
      "Epoch 4257 - Train Loss: 0.198564, Train Acc: 0.606410 | Val Loss: 0.211153, Val Acc: 0.536082\n",
      "Epoch 4258 - Train Loss: 0.198548, Train Acc: 0.606410 | Val Loss: 0.211137, Val Acc: 0.536082\n",
      "Epoch 4259 - Train Loss: 0.198532, Train Acc: 0.606410 | Val Loss: 0.211122, Val Acc: 0.536082\n",
      "Epoch 4260 - Train Loss: 0.198517, Train Acc: 0.606410 | Val Loss: 0.211106, Val Acc: 0.536082\n",
      "Epoch 4261 - Train Loss: 0.198501, Train Acc: 0.606410 | Val Loss: 0.211090, Val Acc: 0.536082\n",
      "Epoch 4262 - Train Loss: 0.198485, Train Acc: 0.606410 | Val Loss: 0.211074, Val Acc: 0.536082\n",
      "Epoch 4263 - Train Loss: 0.198470, Train Acc: 0.606410 | Val Loss: 0.211058, Val Acc: 0.536082\n",
      "Epoch 4264 - Train Loss: 0.198454, Train Acc: 0.606410 | Val Loss: 0.211043, Val Acc: 0.536082\n",
      "Epoch 4265 - Train Loss: 0.198438, Train Acc: 0.606410 | Val Loss: 0.211027, Val Acc: 0.536082\n",
      "Epoch 4266 - Train Loss: 0.198423, Train Acc: 0.606410 | Val Loss: 0.211011, Val Acc: 0.536082\n",
      "Epoch 4267 - Train Loss: 0.198407, Train Acc: 0.606410 | Val Loss: 0.210995, Val Acc: 0.536082\n",
      "Epoch 4268 - Train Loss: 0.198392, Train Acc: 0.606410 | Val Loss: 0.210980, Val Acc: 0.536082\n",
      "Epoch 4269 - Train Loss: 0.198376, Train Acc: 0.606410 | Val Loss: 0.210964, Val Acc: 0.536082\n",
      "Epoch 4270 - Train Loss: 0.198360, Train Acc: 0.606410 | Val Loss: 0.210948, Val Acc: 0.536082\n",
      "Epoch 4271 - Train Loss: 0.198345, Train Acc: 0.606410 | Val Loss: 0.210932, Val Acc: 0.536082\n",
      "Epoch 4272 - Train Loss: 0.198329, Train Acc: 0.607692 | Val Loss: 0.210917, Val Acc: 0.536082\n",
      "Epoch 4273 - Train Loss: 0.198313, Train Acc: 0.607692 | Val Loss: 0.210901, Val Acc: 0.536082\n",
      "Epoch 4274 - Train Loss: 0.198298, Train Acc: 0.607692 | Val Loss: 0.210885, Val Acc: 0.536082\n",
      "Epoch 4275 - Train Loss: 0.198282, Train Acc: 0.607692 | Val Loss: 0.210869, Val Acc: 0.536082\n",
      "Epoch 4276 - Train Loss: 0.198266, Train Acc: 0.607692 | Val Loss: 0.210854, Val Acc: 0.536082\n",
      "Epoch 4277 - Train Loss: 0.198251, Train Acc: 0.607692 | Val Loss: 0.210838, Val Acc: 0.536082\n",
      "Epoch 4278 - Train Loss: 0.198235, Train Acc: 0.607692 | Val Loss: 0.210822, Val Acc: 0.536082\n",
      "Epoch 4279 - Train Loss: 0.198220, Train Acc: 0.607692 | Val Loss: 0.210806, Val Acc: 0.536082\n",
      "Epoch 4280 - Train Loss: 0.198204, Train Acc: 0.607692 | Val Loss: 0.210791, Val Acc: 0.536082\n",
      "Epoch 4281 - Train Loss: 0.198188, Train Acc: 0.607692 | Val Loss: 0.210775, Val Acc: 0.536082\n",
      "Epoch 4282 - Train Loss: 0.198173, Train Acc: 0.607692 | Val Loss: 0.210759, Val Acc: 0.536082\n",
      "Epoch 4283 - Train Loss: 0.198157, Train Acc: 0.607692 | Val Loss: 0.210743, Val Acc: 0.536082\n",
      "Epoch 4284 - Train Loss: 0.198141, Train Acc: 0.607692 | Val Loss: 0.210728, Val Acc: 0.536082\n",
      "Epoch 4285 - Train Loss: 0.198126, Train Acc: 0.607692 | Val Loss: 0.210712, Val Acc: 0.536082\n",
      "Epoch 4286 - Train Loss: 0.198110, Train Acc: 0.607692 | Val Loss: 0.210696, Val Acc: 0.536082\n",
      "Epoch 4287 - Train Loss: 0.198095, Train Acc: 0.607692 | Val Loss: 0.210680, Val Acc: 0.536082\n",
      "Epoch 4288 - Train Loss: 0.198079, Train Acc: 0.607692 | Val Loss: 0.210665, Val Acc: 0.536082\n",
      "Epoch 4289 - Train Loss: 0.198063, Train Acc: 0.608974 | Val Loss: 0.210649, Val Acc: 0.536082\n",
      "Epoch 4290 - Train Loss: 0.198048, Train Acc: 0.608974 | Val Loss: 0.210633, Val Acc: 0.536082\n",
      "Epoch 4291 - Train Loss: 0.198032, Train Acc: 0.607692 | Val Loss: 0.210618, Val Acc: 0.536082\n",
      "Epoch 4292 - Train Loss: 0.198017, Train Acc: 0.607692 | Val Loss: 0.210602, Val Acc: 0.536082\n",
      "Epoch 4293 - Train Loss: 0.198001, Train Acc: 0.607692 | Val Loss: 0.210586, Val Acc: 0.536082\n",
      "Epoch 4294 - Train Loss: 0.197985, Train Acc: 0.607692 | Val Loss: 0.210570, Val Acc: 0.536082\n",
      "Epoch 4295 - Train Loss: 0.197970, Train Acc: 0.607692 | Val Loss: 0.210555, Val Acc: 0.536082\n",
      "Epoch 4296 - Train Loss: 0.197954, Train Acc: 0.607692 | Val Loss: 0.210539, Val Acc: 0.536082\n",
      "Epoch 4297 - Train Loss: 0.197939, Train Acc: 0.607692 | Val Loss: 0.210523, Val Acc: 0.536082\n",
      "Epoch 4298 - Train Loss: 0.197923, Train Acc: 0.607692 | Val Loss: 0.210508, Val Acc: 0.536082\n",
      "Epoch 4299 - Train Loss: 0.197907, Train Acc: 0.607692 | Val Loss: 0.210492, Val Acc: 0.536082\n",
      "Epoch 4300 - Train Loss: 0.197892, Train Acc: 0.607692 | Val Loss: 0.210476, Val Acc: 0.536082\n",
      "Epoch 4301 - Train Loss: 0.197876, Train Acc: 0.607692 | Val Loss: 0.210461, Val Acc: 0.536082\n",
      "Epoch 4302 - Train Loss: 0.197861, Train Acc: 0.607692 | Val Loss: 0.210445, Val Acc: 0.536082\n",
      "Epoch 4303 - Train Loss: 0.197845, Train Acc: 0.607692 | Val Loss: 0.210429, Val Acc: 0.536082\n",
      "Epoch 4304 - Train Loss: 0.197829, Train Acc: 0.607692 | Val Loss: 0.210414, Val Acc: 0.536082\n",
      "Epoch 4305 - Train Loss: 0.197814, Train Acc: 0.607692 | Val Loss: 0.210398, Val Acc: 0.536082\n",
      "Epoch 4306 - Train Loss: 0.197798, Train Acc: 0.607692 | Val Loss: 0.210382, Val Acc: 0.536082\n",
      "Epoch 4307 - Train Loss: 0.197783, Train Acc: 0.607692 | Val Loss: 0.210366, Val Acc: 0.536082\n",
      "Epoch 4308 - Train Loss: 0.197767, Train Acc: 0.607692 | Val Loss: 0.210351, Val Acc: 0.536082\n",
      "Epoch 4309 - Train Loss: 0.197752, Train Acc: 0.607692 | Val Loss: 0.210335, Val Acc: 0.536082\n",
      "Epoch 4310 - Train Loss: 0.197736, Train Acc: 0.607692 | Val Loss: 0.210319, Val Acc: 0.536082\n",
      "Epoch 4311 - Train Loss: 0.197720, Train Acc: 0.607692 | Val Loss: 0.210304, Val Acc: 0.536082\n",
      "Epoch 4312 - Train Loss: 0.197705, Train Acc: 0.607692 | Val Loss: 0.210288, Val Acc: 0.536082\n",
      "Epoch 4313 - Train Loss: 0.197689, Train Acc: 0.607692 | Val Loss: 0.210272, Val Acc: 0.536082\n",
      "Epoch 4314 - Train Loss: 0.197674, Train Acc: 0.607692 | Val Loss: 0.210257, Val Acc: 0.536082\n",
      "Epoch 4315 - Train Loss: 0.197658, Train Acc: 0.607692 | Val Loss: 0.210241, Val Acc: 0.536082\n",
      "Epoch 4316 - Train Loss: 0.197643, Train Acc: 0.607692 | Val Loss: 0.210225, Val Acc: 0.536082\n",
      "Epoch 4317 - Train Loss: 0.197627, Train Acc: 0.607692 | Val Loss: 0.210210, Val Acc: 0.536082\n",
      "Epoch 4318 - Train Loss: 0.197612, Train Acc: 0.607692 | Val Loss: 0.210194, Val Acc: 0.536082\n",
      "Epoch 4319 - Train Loss: 0.197596, Train Acc: 0.607692 | Val Loss: 0.210178, Val Acc: 0.536082\n",
      "Epoch 4320 - Train Loss: 0.197580, Train Acc: 0.607692 | Val Loss: 0.210163, Val Acc: 0.536082\n",
      "Epoch 4321 - Train Loss: 0.197565, Train Acc: 0.608974 | Val Loss: 0.210147, Val Acc: 0.536082\n",
      "Epoch 4322 - Train Loss: 0.197549, Train Acc: 0.608974 | Val Loss: 0.210132, Val Acc: 0.536082\n",
      "Epoch 4323 - Train Loss: 0.197534, Train Acc: 0.608974 | Val Loss: 0.210116, Val Acc: 0.536082\n",
      "Epoch 4324 - Train Loss: 0.197518, Train Acc: 0.608974 | Val Loss: 0.210100, Val Acc: 0.536082\n",
      "Epoch 4325 - Train Loss: 0.197503, Train Acc: 0.610256 | Val Loss: 0.210085, Val Acc: 0.536082\n",
      "Epoch 4326 - Train Loss: 0.197487, Train Acc: 0.610256 | Val Loss: 0.210069, Val Acc: 0.536082\n",
      "Epoch 4327 - Train Loss: 0.197472, Train Acc: 0.610256 | Val Loss: 0.210053, Val Acc: 0.536082\n",
      "Epoch 4328 - Train Loss: 0.197456, Train Acc: 0.610256 | Val Loss: 0.210038, Val Acc: 0.536082\n",
      "Epoch 4329 - Train Loss: 0.197441, Train Acc: 0.610256 | Val Loss: 0.210022, Val Acc: 0.536082\n",
      "Epoch 4330 - Train Loss: 0.197425, Train Acc: 0.610256 | Val Loss: 0.210006, Val Acc: 0.536082\n",
      "Epoch 4331 - Train Loss: 0.197410, Train Acc: 0.610256 | Val Loss: 0.209991, Val Acc: 0.536082\n",
      "Epoch 4332 - Train Loss: 0.197394, Train Acc: 0.610256 | Val Loss: 0.209975, Val Acc: 0.536082\n",
      "Epoch 4333 - Train Loss: 0.197379, Train Acc: 0.610256 | Val Loss: 0.209960, Val Acc: 0.536082\n",
      "Epoch 4334 - Train Loss: 0.197363, Train Acc: 0.610256 | Val Loss: 0.209944, Val Acc: 0.536082\n",
      "Epoch 4335 - Train Loss: 0.197348, Train Acc: 0.610256 | Val Loss: 0.209928, Val Acc: 0.536082\n",
      "Epoch 4336 - Train Loss: 0.197332, Train Acc: 0.610256 | Val Loss: 0.209913, Val Acc: 0.536082\n",
      "Epoch 4337 - Train Loss: 0.197316, Train Acc: 0.610256 | Val Loss: 0.209897, Val Acc: 0.536082\n",
      "Epoch 4338 - Train Loss: 0.197301, Train Acc: 0.610256 | Val Loss: 0.209881, Val Acc: 0.536082\n",
      "Epoch 4339 - Train Loss: 0.197285, Train Acc: 0.610256 | Val Loss: 0.209866, Val Acc: 0.536082\n",
      "Epoch 4340 - Train Loss: 0.197270, Train Acc: 0.610256 | Val Loss: 0.209850, Val Acc: 0.536082\n",
      "Epoch 4341 - Train Loss: 0.197254, Train Acc: 0.610256 | Val Loss: 0.209835, Val Acc: 0.536082\n",
      "Epoch 4342 - Train Loss: 0.197239, Train Acc: 0.610256 | Val Loss: 0.209819, Val Acc: 0.536082\n",
      "Epoch 4343 - Train Loss: 0.197223, Train Acc: 0.610256 | Val Loss: 0.209803, Val Acc: 0.536082\n",
      "Epoch 4344 - Train Loss: 0.197208, Train Acc: 0.610256 | Val Loss: 0.209788, Val Acc: 0.536082\n",
      "Epoch 4345 - Train Loss: 0.197192, Train Acc: 0.610256 | Val Loss: 0.209772, Val Acc: 0.536082\n",
      "Epoch 4346 - Train Loss: 0.197177, Train Acc: 0.610256 | Val Loss: 0.209757, Val Acc: 0.536082\n",
      "Epoch 4347 - Train Loss: 0.197161, Train Acc: 0.610256 | Val Loss: 0.209741, Val Acc: 0.536082\n",
      "Epoch 4348 - Train Loss: 0.197146, Train Acc: 0.610256 | Val Loss: 0.209725, Val Acc: 0.536082\n",
      "Epoch 4349 - Train Loss: 0.197130, Train Acc: 0.610256 | Val Loss: 0.209710, Val Acc: 0.536082\n",
      "Epoch 4350 - Train Loss: 0.197115, Train Acc: 0.610256 | Val Loss: 0.209694, Val Acc: 0.536082\n",
      "Epoch 4351 - Train Loss: 0.197099, Train Acc: 0.610256 | Val Loss: 0.209679, Val Acc: 0.536082\n",
      "Epoch 4352 - Train Loss: 0.197084, Train Acc: 0.610256 | Val Loss: 0.209663, Val Acc: 0.536082\n",
      "Epoch 4353 - Train Loss: 0.197069, Train Acc: 0.610256 | Val Loss: 0.209647, Val Acc: 0.536082\n",
      "Epoch 4354 - Train Loss: 0.197053, Train Acc: 0.610256 | Val Loss: 0.209632, Val Acc: 0.536082\n",
      "Epoch 4355 - Train Loss: 0.197038, Train Acc: 0.610256 | Val Loss: 0.209616, Val Acc: 0.536082\n",
      "Epoch 4356 - Train Loss: 0.197022, Train Acc: 0.610256 | Val Loss: 0.209601, Val Acc: 0.536082\n",
      "Epoch 4357 - Train Loss: 0.197007, Train Acc: 0.610256 | Val Loss: 0.209585, Val Acc: 0.536082\n",
      "Epoch 4358 - Train Loss: 0.196991, Train Acc: 0.610256 | Val Loss: 0.209570, Val Acc: 0.536082\n",
      "Epoch 4359 - Train Loss: 0.196976, Train Acc: 0.610256 | Val Loss: 0.209554, Val Acc: 0.536082\n",
      "Epoch 4360 - Train Loss: 0.196960, Train Acc: 0.610256 | Val Loss: 0.209538, Val Acc: 0.536082\n",
      "Epoch 4361 - Train Loss: 0.196945, Train Acc: 0.610256 | Val Loss: 0.209523, Val Acc: 0.536082\n",
      "Epoch 4362 - Train Loss: 0.196929, Train Acc: 0.610256 | Val Loss: 0.209507, Val Acc: 0.536082\n",
      "Epoch 4363 - Train Loss: 0.196914, Train Acc: 0.610256 | Val Loss: 0.209492, Val Acc: 0.536082\n",
      "Epoch 4364 - Train Loss: 0.196898, Train Acc: 0.610256 | Val Loss: 0.209476, Val Acc: 0.536082\n",
      "Epoch 4365 - Train Loss: 0.196883, Train Acc: 0.610256 | Val Loss: 0.209461, Val Acc: 0.536082\n",
      "Epoch 4366 - Train Loss: 0.196867, Train Acc: 0.610256 | Val Loss: 0.209445, Val Acc: 0.536082\n",
      "Epoch 4367 - Train Loss: 0.196852, Train Acc: 0.610256 | Val Loss: 0.209429, Val Acc: 0.536082\n",
      "Epoch 4368 - Train Loss: 0.196836, Train Acc: 0.610256 | Val Loss: 0.209414, Val Acc: 0.536082\n",
      "Epoch 4369 - Train Loss: 0.196821, Train Acc: 0.610256 | Val Loss: 0.209398, Val Acc: 0.536082\n",
      "Epoch 4370 - Train Loss: 0.196806, Train Acc: 0.610256 | Val Loss: 0.209383, Val Acc: 0.536082\n",
      "Epoch 4371 - Train Loss: 0.196790, Train Acc: 0.610256 | Val Loss: 0.209367, Val Acc: 0.536082\n",
      "Epoch 4372 - Train Loss: 0.196775, Train Acc: 0.610256 | Val Loss: 0.209352, Val Acc: 0.536082\n",
      "Epoch 4373 - Train Loss: 0.196759, Train Acc: 0.610256 | Val Loss: 0.209336, Val Acc: 0.536082\n",
      "Epoch 4374 - Train Loss: 0.196744, Train Acc: 0.610256 | Val Loss: 0.209321, Val Acc: 0.536082\n",
      "Epoch 4375 - Train Loss: 0.196728, Train Acc: 0.610256 | Val Loss: 0.209305, Val Acc: 0.536082\n",
      "Epoch 4376 - Train Loss: 0.196713, Train Acc: 0.610256 | Val Loss: 0.209290, Val Acc: 0.536082\n",
      "Epoch 4377 - Train Loss: 0.196697, Train Acc: 0.610256 | Val Loss: 0.209274, Val Acc: 0.536082\n",
      "Epoch 4378 - Train Loss: 0.196682, Train Acc: 0.610256 | Val Loss: 0.209259, Val Acc: 0.536082\n",
      "Epoch 4379 - Train Loss: 0.196667, Train Acc: 0.611538 | Val Loss: 0.209243, Val Acc: 0.536082\n",
      "Epoch 4380 - Train Loss: 0.196651, Train Acc: 0.611538 | Val Loss: 0.209227, Val Acc: 0.536082\n",
      "Epoch 4381 - Train Loss: 0.196636, Train Acc: 0.611538 | Val Loss: 0.209212, Val Acc: 0.536082\n",
      "Epoch 4382 - Train Loss: 0.196620, Train Acc: 0.611538 | Val Loss: 0.209196, Val Acc: 0.536082\n",
      "Epoch 4383 - Train Loss: 0.196605, Train Acc: 0.611538 | Val Loss: 0.209181, Val Acc: 0.536082\n",
      "Epoch 4384 - Train Loss: 0.196589, Train Acc: 0.611538 | Val Loss: 0.209165, Val Acc: 0.536082\n",
      "Epoch 4385 - Train Loss: 0.196574, Train Acc: 0.611538 | Val Loss: 0.209150, Val Acc: 0.536082\n",
      "Epoch 4386 - Train Loss: 0.196559, Train Acc: 0.611538 | Val Loss: 0.209134, Val Acc: 0.536082\n",
      "Epoch 4387 - Train Loss: 0.196543, Train Acc: 0.611538 | Val Loss: 0.209119, Val Acc: 0.536082\n",
      "Epoch 4388 - Train Loss: 0.196528, Train Acc: 0.611538 | Val Loss: 0.209103, Val Acc: 0.536082\n",
      "Epoch 4389 - Train Loss: 0.196512, Train Acc: 0.611538 | Val Loss: 0.209088, Val Acc: 0.536082\n",
      "Epoch 4390 - Train Loss: 0.196497, Train Acc: 0.611538 | Val Loss: 0.209072, Val Acc: 0.536082\n",
      "Epoch 4391 - Train Loss: 0.196482, Train Acc: 0.611538 | Val Loss: 0.209057, Val Acc: 0.536082\n",
      "Epoch 4392 - Train Loss: 0.196466, Train Acc: 0.611538 | Val Loss: 0.209041, Val Acc: 0.536082\n",
      "Epoch 4393 - Train Loss: 0.196451, Train Acc: 0.611538 | Val Loss: 0.209026, Val Acc: 0.536082\n",
      "Epoch 4394 - Train Loss: 0.196435, Train Acc: 0.611538 | Val Loss: 0.209010, Val Acc: 0.536082\n",
      "Epoch 4395 - Train Loss: 0.196420, Train Acc: 0.611538 | Val Loss: 0.208995, Val Acc: 0.536082\n",
      "Epoch 4396 - Train Loss: 0.196405, Train Acc: 0.611538 | Val Loss: 0.208979, Val Acc: 0.536082\n",
      "Epoch 4397 - Train Loss: 0.196389, Train Acc: 0.611538 | Val Loss: 0.208964, Val Acc: 0.536082\n",
      "Epoch 4398 - Train Loss: 0.196374, Train Acc: 0.611538 | Val Loss: 0.208948, Val Acc: 0.536082\n",
      "Epoch 4399 - Train Loss: 0.196358, Train Acc: 0.611538 | Val Loss: 0.208933, Val Acc: 0.536082\n",
      "Epoch 4400 - Train Loss: 0.196343, Train Acc: 0.611538 | Val Loss: 0.208917, Val Acc: 0.536082\n",
      "Epoch 4401 - Train Loss: 0.196328, Train Acc: 0.611538 | Val Loss: 0.208902, Val Acc: 0.536082\n",
      "Epoch 4402 - Train Loss: 0.196312, Train Acc: 0.611538 | Val Loss: 0.208886, Val Acc: 0.536082\n",
      "Epoch 4403 - Train Loss: 0.196297, Train Acc: 0.611538 | Val Loss: 0.208871, Val Acc: 0.536082\n",
      "Epoch 4404 - Train Loss: 0.196281, Train Acc: 0.611538 | Val Loss: 0.208855, Val Acc: 0.536082\n",
      "Epoch 4405 - Train Loss: 0.196266, Train Acc: 0.611538 | Val Loss: 0.208840, Val Acc: 0.536082\n",
      "Epoch 4406 - Train Loss: 0.196251, Train Acc: 0.611538 | Val Loss: 0.208824, Val Acc: 0.536082\n",
      "Epoch 4407 - Train Loss: 0.196235, Train Acc: 0.611538 | Val Loss: 0.208809, Val Acc: 0.536082\n",
      "Epoch 4408 - Train Loss: 0.196220, Train Acc: 0.611538 | Val Loss: 0.208794, Val Acc: 0.536082\n",
      "Epoch 4409 - Train Loss: 0.196205, Train Acc: 0.611538 | Val Loss: 0.208778, Val Acc: 0.536082\n",
      "Epoch 4410 - Train Loss: 0.196189, Train Acc: 0.611538 | Val Loss: 0.208763, Val Acc: 0.536082\n",
      "Epoch 4411 - Train Loss: 0.196174, Train Acc: 0.610256 | Val Loss: 0.208747, Val Acc: 0.536082\n",
      "Epoch 4412 - Train Loss: 0.196158, Train Acc: 0.610256 | Val Loss: 0.208732, Val Acc: 0.536082\n",
      "Epoch 4413 - Train Loss: 0.196143, Train Acc: 0.610256 | Val Loss: 0.208716, Val Acc: 0.536082\n",
      "Epoch 4414 - Train Loss: 0.196128, Train Acc: 0.610256 | Val Loss: 0.208701, Val Acc: 0.536082\n",
      "Epoch 4415 - Train Loss: 0.196112, Train Acc: 0.610256 | Val Loss: 0.208685, Val Acc: 0.536082\n",
      "Epoch 4416 - Train Loss: 0.196097, Train Acc: 0.608974 | Val Loss: 0.208670, Val Acc: 0.536082\n",
      "Epoch 4417 - Train Loss: 0.196082, Train Acc: 0.608974 | Val Loss: 0.208654, Val Acc: 0.536082\n",
      "Epoch 4418 - Train Loss: 0.196066, Train Acc: 0.608974 | Val Loss: 0.208639, Val Acc: 0.536082\n",
      "Epoch 4419 - Train Loss: 0.196051, Train Acc: 0.608974 | Val Loss: 0.208623, Val Acc: 0.536082\n",
      "Epoch 4420 - Train Loss: 0.196035, Train Acc: 0.608974 | Val Loss: 0.208608, Val Acc: 0.536082\n",
      "Epoch 4421 - Train Loss: 0.196020, Train Acc: 0.608974 | Val Loss: 0.208593, Val Acc: 0.536082\n",
      "Epoch 4422 - Train Loss: 0.196005, Train Acc: 0.608974 | Val Loss: 0.208577, Val Acc: 0.536082\n",
      "Epoch 4423 - Train Loss: 0.195989, Train Acc: 0.608974 | Val Loss: 0.208562, Val Acc: 0.536082\n",
      "Epoch 4424 - Train Loss: 0.195974, Train Acc: 0.608974 | Val Loss: 0.208546, Val Acc: 0.536082\n",
      "Epoch 4425 - Train Loss: 0.195959, Train Acc: 0.608974 | Val Loss: 0.208531, Val Acc: 0.536082\n",
      "Epoch 4426 - Train Loss: 0.195943, Train Acc: 0.608974 | Val Loss: 0.208515, Val Acc: 0.536082\n",
      "Epoch 4427 - Train Loss: 0.195928, Train Acc: 0.608974 | Val Loss: 0.208500, Val Acc: 0.536082\n",
      "Epoch 4428 - Train Loss: 0.195913, Train Acc: 0.608974 | Val Loss: 0.208485, Val Acc: 0.536082\n",
      "Epoch 4429 - Train Loss: 0.195897, Train Acc: 0.608974 | Val Loss: 0.208469, Val Acc: 0.536082\n",
      "Epoch 4430 - Train Loss: 0.195882, Train Acc: 0.608974 | Val Loss: 0.208454, Val Acc: 0.536082\n",
      "Epoch 4431 - Train Loss: 0.195867, Train Acc: 0.608974 | Val Loss: 0.208438, Val Acc: 0.536082\n",
      "Epoch 4432 - Train Loss: 0.195851, Train Acc: 0.608974 | Val Loss: 0.208423, Val Acc: 0.536082\n",
      "Epoch 4433 - Train Loss: 0.195836, Train Acc: 0.608974 | Val Loss: 0.208408, Val Acc: 0.536082\n",
      "Epoch 4434 - Train Loss: 0.195821, Train Acc: 0.608974 | Val Loss: 0.208392, Val Acc: 0.536082\n",
      "Epoch 4435 - Train Loss: 0.195805, Train Acc: 0.608974 | Val Loss: 0.208377, Val Acc: 0.536082\n",
      "Epoch 4436 - Train Loss: 0.195790, Train Acc: 0.608974 | Val Loss: 0.208361, Val Acc: 0.536082\n",
      "Epoch 4437 - Train Loss: 0.195775, Train Acc: 0.608974 | Val Loss: 0.208346, Val Acc: 0.536082\n",
      "Epoch 4438 - Train Loss: 0.195759, Train Acc: 0.608974 | Val Loss: 0.208331, Val Acc: 0.536082\n",
      "Epoch 4439 - Train Loss: 0.195744, Train Acc: 0.608974 | Val Loss: 0.208315, Val Acc: 0.536082\n",
      "Epoch 4440 - Train Loss: 0.195729, Train Acc: 0.608974 | Val Loss: 0.208300, Val Acc: 0.536082\n",
      "Epoch 4441 - Train Loss: 0.195713, Train Acc: 0.608974 | Val Loss: 0.208284, Val Acc: 0.536082\n",
      "Epoch 4442 - Train Loss: 0.195698, Train Acc: 0.608974 | Val Loss: 0.208269, Val Acc: 0.536082\n",
      "Epoch 4443 - Train Loss: 0.195683, Train Acc: 0.608974 | Val Loss: 0.208254, Val Acc: 0.536082\n",
      "Epoch 4444 - Train Loss: 0.195667, Train Acc: 0.608974 | Val Loss: 0.208238, Val Acc: 0.536082\n",
      "Epoch 4445 - Train Loss: 0.195652, Train Acc: 0.608974 | Val Loss: 0.208223, Val Acc: 0.536082\n",
      "Epoch 4446 - Train Loss: 0.195637, Train Acc: 0.608974 | Val Loss: 0.208208, Val Acc: 0.536082\n",
      "Epoch 4447 - Train Loss: 0.195622, Train Acc: 0.608974 | Val Loss: 0.208192, Val Acc: 0.536082\n",
      "Epoch 4448 - Train Loss: 0.195606, Train Acc: 0.608974 | Val Loss: 0.208177, Val Acc: 0.536082\n",
      "Epoch 4449 - Train Loss: 0.195591, Train Acc: 0.610256 | Val Loss: 0.208161, Val Acc: 0.536082\n",
      "Epoch 4450 - Train Loss: 0.195576, Train Acc: 0.610256 | Val Loss: 0.208146, Val Acc: 0.536082\n",
      "Epoch 4451 - Train Loss: 0.195560, Train Acc: 0.610256 | Val Loss: 0.208131, Val Acc: 0.536082\n",
      "Epoch 4452 - Train Loss: 0.195545, Train Acc: 0.610256 | Val Loss: 0.208115, Val Acc: 0.536082\n",
      "Epoch 4453 - Train Loss: 0.195530, Train Acc: 0.610256 | Val Loss: 0.208100, Val Acc: 0.536082\n",
      "Epoch 4454 - Train Loss: 0.195514, Train Acc: 0.610256 | Val Loss: 0.208085, Val Acc: 0.536082\n",
      "Epoch 4455 - Train Loss: 0.195499, Train Acc: 0.610256 | Val Loss: 0.208069, Val Acc: 0.536082\n",
      "Epoch 4456 - Train Loss: 0.195484, Train Acc: 0.610256 | Val Loss: 0.208054, Val Acc: 0.536082\n",
      "Epoch 4457 - Train Loss: 0.195469, Train Acc: 0.610256 | Val Loss: 0.208039, Val Acc: 0.536082\n",
      "Epoch 4458 - Train Loss: 0.195453, Train Acc: 0.610256 | Val Loss: 0.208023, Val Acc: 0.536082\n",
      "Epoch 4459 - Train Loss: 0.195438, Train Acc: 0.610256 | Val Loss: 0.208008, Val Acc: 0.536082\n",
      "Epoch 4460 - Train Loss: 0.195423, Train Acc: 0.610256 | Val Loss: 0.207993, Val Acc: 0.536082\n",
      "Epoch 4461 - Train Loss: 0.195407, Train Acc: 0.610256 | Val Loss: 0.207977, Val Acc: 0.536082\n",
      "Epoch 4462 - Train Loss: 0.195392, Train Acc: 0.610256 | Val Loss: 0.207962, Val Acc: 0.536082\n",
      "Epoch 4463 - Train Loss: 0.195377, Train Acc: 0.610256 | Val Loss: 0.207946, Val Acc: 0.536082\n",
      "Epoch 4464 - Train Loss: 0.195362, Train Acc: 0.610256 | Val Loss: 0.207931, Val Acc: 0.536082\n",
      "Epoch 4465 - Train Loss: 0.195346, Train Acc: 0.610256 | Val Loss: 0.207916, Val Acc: 0.536082\n",
      "Epoch 4466 - Train Loss: 0.195331, Train Acc: 0.610256 | Val Loss: 0.207901, Val Acc: 0.536082\n",
      "Epoch 4467 - Train Loss: 0.195316, Train Acc: 0.610256 | Val Loss: 0.207885, Val Acc: 0.536082\n",
      "Epoch 4468 - Train Loss: 0.195300, Train Acc: 0.610256 | Val Loss: 0.207870, Val Acc: 0.536082\n",
      "Epoch 4469 - Train Loss: 0.195285, Train Acc: 0.610256 | Val Loss: 0.207855, Val Acc: 0.536082\n",
      "Epoch 4470 - Train Loss: 0.195270, Train Acc: 0.610256 | Val Loss: 0.207839, Val Acc: 0.536082\n",
      "Epoch 4471 - Train Loss: 0.195255, Train Acc: 0.610256 | Val Loss: 0.207824, Val Acc: 0.536082\n",
      "Epoch 4472 - Train Loss: 0.195239, Train Acc: 0.610256 | Val Loss: 0.207809, Val Acc: 0.536082\n",
      "Epoch 4473 - Train Loss: 0.195224, Train Acc: 0.610256 | Val Loss: 0.207793, Val Acc: 0.536082\n",
      "Epoch 4474 - Train Loss: 0.195209, Train Acc: 0.610256 | Val Loss: 0.207778, Val Acc: 0.536082\n",
      "Epoch 4475 - Train Loss: 0.195194, Train Acc: 0.610256 | Val Loss: 0.207763, Val Acc: 0.536082\n",
      "Epoch 4476 - Train Loss: 0.195178, Train Acc: 0.610256 | Val Loss: 0.207747, Val Acc: 0.536082\n",
      "Epoch 4477 - Train Loss: 0.195163, Train Acc: 0.610256 | Val Loss: 0.207732, Val Acc: 0.536082\n",
      "Epoch 4478 - Train Loss: 0.195148, Train Acc: 0.610256 | Val Loss: 0.207717, Val Acc: 0.536082\n",
      "Epoch 4479 - Train Loss: 0.195133, Train Acc: 0.610256 | Val Loss: 0.207702, Val Acc: 0.536082\n",
      "Epoch 4480 - Train Loss: 0.195117, Train Acc: 0.610256 | Val Loss: 0.207686, Val Acc: 0.536082\n",
      "Epoch 4481 - Train Loss: 0.195102, Train Acc: 0.610256 | Val Loss: 0.207671, Val Acc: 0.536082\n",
      "Epoch 4482 - Train Loss: 0.195087, Train Acc: 0.610256 | Val Loss: 0.207656, Val Acc: 0.536082\n",
      "Epoch 4483 - Train Loss: 0.195072, Train Acc: 0.610256 | Val Loss: 0.207640, Val Acc: 0.536082\n",
      "Epoch 4484 - Train Loss: 0.195056, Train Acc: 0.610256 | Val Loss: 0.207625, Val Acc: 0.536082\n",
      "Epoch 4485 - Train Loss: 0.195041, Train Acc: 0.610256 | Val Loss: 0.207610, Val Acc: 0.536082\n",
      "Epoch 4486 - Train Loss: 0.195026, Train Acc: 0.610256 | Val Loss: 0.207595, Val Acc: 0.536082\n",
      "Epoch 4487 - Train Loss: 0.195011, Train Acc: 0.610256 | Val Loss: 0.207579, Val Acc: 0.536082\n",
      "Epoch 4488 - Train Loss: 0.194995, Train Acc: 0.610256 | Val Loss: 0.207564, Val Acc: 0.536082\n",
      "Epoch 4489 - Train Loss: 0.194980, Train Acc: 0.610256 | Val Loss: 0.207549, Val Acc: 0.536082\n",
      "Epoch 4490 - Train Loss: 0.194965, Train Acc: 0.610256 | Val Loss: 0.207533, Val Acc: 0.536082\n",
      "Epoch 4491 - Train Loss: 0.194950, Train Acc: 0.610256 | Val Loss: 0.207518, Val Acc: 0.536082\n",
      "Epoch 4492 - Train Loss: 0.194934, Train Acc: 0.610256 | Val Loss: 0.207503, Val Acc: 0.536082\n",
      "Epoch 4493 - Train Loss: 0.194919, Train Acc: 0.610256 | Val Loss: 0.207488, Val Acc: 0.536082\n",
      "Epoch 4494 - Train Loss: 0.194904, Train Acc: 0.610256 | Val Loss: 0.207472, Val Acc: 0.536082\n",
      "Epoch 4495 - Train Loss: 0.194889, Train Acc: 0.610256 | Val Loss: 0.207457, Val Acc: 0.536082\n",
      "Epoch 4496 - Train Loss: 0.194874, Train Acc: 0.610256 | Val Loss: 0.207442, Val Acc: 0.536082\n",
      "Epoch 4497 - Train Loss: 0.194858, Train Acc: 0.610256 | Val Loss: 0.207426, Val Acc: 0.536082\n",
      "Epoch 4498 - Train Loss: 0.194843, Train Acc: 0.610256 | Val Loss: 0.207411, Val Acc: 0.536082\n",
      "Epoch 4499 - Train Loss: 0.194828, Train Acc: 0.610256 | Val Loss: 0.207396, Val Acc: 0.536082\n",
      "Epoch 4500 - Train Loss: 0.194813, Train Acc: 0.610256 | Val Loss: 0.207381, Val Acc: 0.536082\n",
      "Epoch 4501 - Train Loss: 0.194797, Train Acc: 0.610256 | Val Loss: 0.207365, Val Acc: 0.536082\n",
      "Epoch 4502 - Train Loss: 0.194782, Train Acc: 0.610256 | Val Loss: 0.207350, Val Acc: 0.536082\n",
      "Epoch 4503 - Train Loss: 0.194767, Train Acc: 0.610256 | Val Loss: 0.207335, Val Acc: 0.536082\n",
      "Epoch 4504 - Train Loss: 0.194752, Train Acc: 0.610256 | Val Loss: 0.207320, Val Acc: 0.536082\n",
      "Epoch 4505 - Train Loss: 0.194737, Train Acc: 0.610256 | Val Loss: 0.207304, Val Acc: 0.536082\n",
      "Epoch 4506 - Train Loss: 0.194721, Train Acc: 0.610256 | Val Loss: 0.207289, Val Acc: 0.536082\n",
      "Epoch 4507 - Train Loss: 0.194706, Train Acc: 0.610256 | Val Loss: 0.207274, Val Acc: 0.536082\n",
      "Epoch 4508 - Train Loss: 0.194691, Train Acc: 0.610256 | Val Loss: 0.207259, Val Acc: 0.536082\n",
      "Epoch 4509 - Train Loss: 0.194676, Train Acc: 0.610256 | Val Loss: 0.207243, Val Acc: 0.536082\n",
      "Epoch 4510 - Train Loss: 0.194661, Train Acc: 0.610256 | Val Loss: 0.207228, Val Acc: 0.536082\n",
      "Epoch 4511 - Train Loss: 0.194645, Train Acc: 0.610256 | Val Loss: 0.207213, Val Acc: 0.536082\n",
      "Epoch 4512 - Train Loss: 0.194630, Train Acc: 0.610256 | Val Loss: 0.207198, Val Acc: 0.536082\n",
      "Epoch 4513 - Train Loss: 0.194615, Train Acc: 0.610256 | Val Loss: 0.207182, Val Acc: 0.536082\n",
      "Epoch 4514 - Train Loss: 0.194600, Train Acc: 0.610256 | Val Loss: 0.207167, Val Acc: 0.536082\n",
      "Epoch 4515 - Train Loss: 0.194585, Train Acc: 0.610256 | Val Loss: 0.207152, Val Acc: 0.536082\n",
      "Epoch 4516 - Train Loss: 0.194570, Train Acc: 0.610256 | Val Loss: 0.207137, Val Acc: 0.536082\n",
      "Epoch 4517 - Train Loss: 0.194554, Train Acc: 0.610256 | Val Loss: 0.207121, Val Acc: 0.536082\n",
      "Epoch 4518 - Train Loss: 0.194539, Train Acc: 0.610256 | Val Loss: 0.207106, Val Acc: 0.536082\n",
      "Epoch 4519 - Train Loss: 0.194524, Train Acc: 0.610256 | Val Loss: 0.207091, Val Acc: 0.536082\n",
      "Epoch 4520 - Train Loss: 0.194509, Train Acc: 0.610256 | Val Loss: 0.207076, Val Acc: 0.536082\n",
      "Epoch 4521 - Train Loss: 0.194494, Train Acc: 0.610256 | Val Loss: 0.207061, Val Acc: 0.536082\n",
      "Epoch 4522 - Train Loss: 0.194478, Train Acc: 0.610256 | Val Loss: 0.207045, Val Acc: 0.536082\n",
      "Epoch 4523 - Train Loss: 0.194463, Train Acc: 0.610256 | Val Loss: 0.207030, Val Acc: 0.536082\n",
      "Epoch 4524 - Train Loss: 0.194448, Train Acc: 0.610256 | Val Loss: 0.207015, Val Acc: 0.536082\n",
      "Epoch 4525 - Train Loss: 0.194433, Train Acc: 0.610256 | Val Loss: 0.207000, Val Acc: 0.536082\n",
      "Epoch 4526 - Train Loss: 0.194418, Train Acc: 0.610256 | Val Loss: 0.206984, Val Acc: 0.536082\n",
      "Epoch 4527 - Train Loss: 0.194403, Train Acc: 0.610256 | Val Loss: 0.206969, Val Acc: 0.536082\n",
      "Epoch 4528 - Train Loss: 0.194387, Train Acc: 0.610256 | Val Loss: 0.206954, Val Acc: 0.536082\n",
      "Epoch 4529 - Train Loss: 0.194372, Train Acc: 0.610256 | Val Loss: 0.206939, Val Acc: 0.536082\n",
      "Epoch 4530 - Train Loss: 0.194357, Train Acc: 0.610256 | Val Loss: 0.206924, Val Acc: 0.536082\n",
      "Epoch 4531 - Train Loss: 0.194342, Train Acc: 0.610256 | Val Loss: 0.206908, Val Acc: 0.536082\n",
      "Epoch 4532 - Train Loss: 0.194327, Train Acc: 0.610256 | Val Loss: 0.206893, Val Acc: 0.536082\n",
      "Epoch 4533 - Train Loss: 0.194312, Train Acc: 0.610256 | Val Loss: 0.206878, Val Acc: 0.536082\n",
      "Epoch 4534 - Train Loss: 0.194296, Train Acc: 0.610256 | Val Loss: 0.206863, Val Acc: 0.536082\n",
      "Epoch 4535 - Train Loss: 0.194281, Train Acc: 0.610256 | Val Loss: 0.206848, Val Acc: 0.536082\n",
      "Epoch 4536 - Train Loss: 0.194266, Train Acc: 0.610256 | Val Loss: 0.206832, Val Acc: 0.536082\n",
      "Epoch 4537 - Train Loss: 0.194251, Train Acc: 0.610256 | Val Loss: 0.206817, Val Acc: 0.536082\n",
      "Epoch 4538 - Train Loss: 0.194236, Train Acc: 0.610256 | Val Loss: 0.206802, Val Acc: 0.536082\n",
      "Epoch 4539 - Train Loss: 0.194221, Train Acc: 0.610256 | Val Loss: 0.206787, Val Acc: 0.536082\n",
      "Epoch 4540 - Train Loss: 0.194206, Train Acc: 0.610256 | Val Loss: 0.206772, Val Acc: 0.536082\n",
      "Epoch 4541 - Train Loss: 0.194190, Train Acc: 0.610256 | Val Loss: 0.206756, Val Acc: 0.536082\n",
      "Epoch 4542 - Train Loss: 0.194175, Train Acc: 0.610256 | Val Loss: 0.206741, Val Acc: 0.536082\n",
      "Epoch 4543 - Train Loss: 0.194160, Train Acc: 0.610256 | Val Loss: 0.206726, Val Acc: 0.536082\n",
      "Epoch 4544 - Train Loss: 0.194145, Train Acc: 0.610256 | Val Loss: 0.206711, Val Acc: 0.536082\n",
      "Epoch 4545 - Train Loss: 0.194130, Train Acc: 0.610256 | Val Loss: 0.206696, Val Acc: 0.536082\n",
      "Epoch 4546 - Train Loss: 0.194115, Train Acc: 0.610256 | Val Loss: 0.206681, Val Acc: 0.536082\n",
      "Epoch 4547 - Train Loss: 0.194100, Train Acc: 0.610256 | Val Loss: 0.206665, Val Acc: 0.536082\n",
      "Epoch 4548 - Train Loss: 0.194084, Train Acc: 0.610256 | Val Loss: 0.206650, Val Acc: 0.536082\n",
      "Epoch 4549 - Train Loss: 0.194069, Train Acc: 0.610256 | Val Loss: 0.206635, Val Acc: 0.536082\n",
      "Epoch 4550 - Train Loss: 0.194054, Train Acc: 0.610256 | Val Loss: 0.206620, Val Acc: 0.536082\n",
      "Epoch 4551 - Train Loss: 0.194039, Train Acc: 0.610256 | Val Loss: 0.206605, Val Acc: 0.536082\n",
      "Epoch 4552 - Train Loss: 0.194024, Train Acc: 0.610256 | Val Loss: 0.206589, Val Acc: 0.536082\n",
      "Epoch 4553 - Train Loss: 0.194009, Train Acc: 0.610256 | Val Loss: 0.206574, Val Acc: 0.536082\n",
      "Epoch 4554 - Train Loss: 0.193994, Train Acc: 0.610256 | Val Loss: 0.206559, Val Acc: 0.536082\n",
      "Epoch 4555 - Train Loss: 0.193979, Train Acc: 0.610256 | Val Loss: 0.206544, Val Acc: 0.536082\n",
      "Epoch 4556 - Train Loss: 0.193963, Train Acc: 0.610256 | Val Loss: 0.206529, Val Acc: 0.536082\n",
      "Epoch 4557 - Train Loss: 0.193948, Train Acc: 0.610256 | Val Loss: 0.206514, Val Acc: 0.536082\n",
      "Epoch 4558 - Train Loss: 0.193933, Train Acc: 0.610256 | Val Loss: 0.206499, Val Acc: 0.536082\n",
      "Epoch 4559 - Train Loss: 0.193918, Train Acc: 0.610256 | Val Loss: 0.206483, Val Acc: 0.536082\n",
      "Epoch 4560 - Train Loss: 0.193903, Train Acc: 0.610256 | Val Loss: 0.206468, Val Acc: 0.536082\n",
      "Epoch 4561 - Train Loss: 0.193888, Train Acc: 0.610256 | Val Loss: 0.206453, Val Acc: 0.536082\n",
      "Epoch 4562 - Train Loss: 0.193873, Train Acc: 0.610256 | Val Loss: 0.206438, Val Acc: 0.536082\n",
      "Epoch 4563 - Train Loss: 0.193858, Train Acc: 0.610256 | Val Loss: 0.206423, Val Acc: 0.536082\n",
      "Epoch 4564 - Train Loss: 0.193843, Train Acc: 0.610256 | Val Loss: 0.206408, Val Acc: 0.536082\n",
      "Epoch 4565 - Train Loss: 0.193828, Train Acc: 0.610256 | Val Loss: 0.206392, Val Acc: 0.536082\n",
      "Epoch 4566 - Train Loss: 0.193812, Train Acc: 0.610256 | Val Loss: 0.206377, Val Acc: 0.536082\n",
      "Epoch 4567 - Train Loss: 0.193797, Train Acc: 0.610256 | Val Loss: 0.206362, Val Acc: 0.536082\n",
      "Epoch 4568 - Train Loss: 0.193782, Train Acc: 0.610256 | Val Loss: 0.206347, Val Acc: 0.536082\n",
      "Epoch 4569 - Train Loss: 0.193767, Train Acc: 0.610256 | Val Loss: 0.206332, Val Acc: 0.536082\n",
      "Epoch 4570 - Train Loss: 0.193752, Train Acc: 0.610256 | Val Loss: 0.206317, Val Acc: 0.536082\n",
      "Epoch 4571 - Train Loss: 0.193737, Train Acc: 0.610256 | Val Loss: 0.206302, Val Acc: 0.536082\n",
      "Epoch 4572 - Train Loss: 0.193722, Train Acc: 0.610256 | Val Loss: 0.206286, Val Acc: 0.536082\n",
      "Epoch 4573 - Train Loss: 0.193707, Train Acc: 0.610256 | Val Loss: 0.206271, Val Acc: 0.536082\n",
      "Epoch 4574 - Train Loss: 0.193692, Train Acc: 0.610256 | Val Loss: 0.206256, Val Acc: 0.536082\n",
      "Epoch 4575 - Train Loss: 0.193677, Train Acc: 0.610256 | Val Loss: 0.206241, Val Acc: 0.536082\n",
      "Epoch 4576 - Train Loss: 0.193662, Train Acc: 0.610256 | Val Loss: 0.206226, Val Acc: 0.536082\n",
      "Epoch 4577 - Train Loss: 0.193646, Train Acc: 0.610256 | Val Loss: 0.206211, Val Acc: 0.536082\n",
      "Epoch 4578 - Train Loss: 0.193631, Train Acc: 0.610256 | Val Loss: 0.206196, Val Acc: 0.536082\n",
      "Epoch 4579 - Train Loss: 0.193616, Train Acc: 0.610256 | Val Loss: 0.206181, Val Acc: 0.536082\n",
      "Epoch 4580 - Train Loss: 0.193601, Train Acc: 0.610256 | Val Loss: 0.206166, Val Acc: 0.536082\n",
      "Epoch 4581 - Train Loss: 0.193586, Train Acc: 0.610256 | Val Loss: 0.206150, Val Acc: 0.536082\n",
      "Epoch 4582 - Train Loss: 0.193571, Train Acc: 0.610256 | Val Loss: 0.206135, Val Acc: 0.536082\n",
      "Epoch 4583 - Train Loss: 0.193556, Train Acc: 0.610256 | Val Loss: 0.206120, Val Acc: 0.536082\n",
      "Epoch 4584 - Train Loss: 0.193541, Train Acc: 0.610256 | Val Loss: 0.206105, Val Acc: 0.536082\n",
      "Epoch 4585 - Train Loss: 0.193526, Train Acc: 0.610256 | Val Loss: 0.206090, Val Acc: 0.536082\n",
      "Epoch 4586 - Train Loss: 0.193511, Train Acc: 0.610256 | Val Loss: 0.206075, Val Acc: 0.536082\n",
      "Epoch 4587 - Train Loss: 0.193496, Train Acc: 0.610256 | Val Loss: 0.206060, Val Acc: 0.536082\n",
      "Epoch 4588 - Train Loss: 0.193481, Train Acc: 0.610256 | Val Loss: 0.206045, Val Acc: 0.536082\n",
      "Epoch 4589 - Train Loss: 0.193466, Train Acc: 0.610256 | Val Loss: 0.206030, Val Acc: 0.536082\n",
      "Epoch 4590 - Train Loss: 0.193451, Train Acc: 0.610256 | Val Loss: 0.206014, Val Acc: 0.536082\n",
      "Epoch 4591 - Train Loss: 0.193435, Train Acc: 0.610256 | Val Loss: 0.205999, Val Acc: 0.536082\n",
      "Epoch 4592 - Train Loss: 0.193420, Train Acc: 0.610256 | Val Loss: 0.205984, Val Acc: 0.536082\n",
      "Epoch 4593 - Train Loss: 0.193405, Train Acc: 0.610256 | Val Loss: 0.205969, Val Acc: 0.536082\n",
      "Epoch 4594 - Train Loss: 0.193390, Train Acc: 0.610256 | Val Loss: 0.205954, Val Acc: 0.536082\n",
      "Epoch 4595 - Train Loss: 0.193375, Train Acc: 0.610256 | Val Loss: 0.205939, Val Acc: 0.536082\n",
      "Epoch 4596 - Train Loss: 0.193360, Train Acc: 0.610256 | Val Loss: 0.205924, Val Acc: 0.536082\n",
      "Epoch 4597 - Train Loss: 0.193345, Train Acc: 0.610256 | Val Loss: 0.205909, Val Acc: 0.536082\n",
      "Epoch 4598 - Train Loss: 0.193330, Train Acc: 0.610256 | Val Loss: 0.205894, Val Acc: 0.536082\n",
      "Epoch 4599 - Train Loss: 0.193315, Train Acc: 0.610256 | Val Loss: 0.205879, Val Acc: 0.536082\n",
      "Epoch 4600 - Train Loss: 0.193300, Train Acc: 0.610256 | Val Loss: 0.205864, Val Acc: 0.536082\n",
      "Epoch 4601 - Train Loss: 0.193285, Train Acc: 0.610256 | Val Loss: 0.205848, Val Acc: 0.536082\n",
      "Epoch 4602 - Train Loss: 0.193270, Train Acc: 0.610256 | Val Loss: 0.205833, Val Acc: 0.536082\n",
      "Epoch 4603 - Train Loss: 0.193255, Train Acc: 0.610256 | Val Loss: 0.205818, Val Acc: 0.536082\n",
      "Epoch 4604 - Train Loss: 0.193240, Train Acc: 0.610256 | Val Loss: 0.205803, Val Acc: 0.536082\n",
      "Epoch 4605 - Train Loss: 0.193225, Train Acc: 0.610256 | Val Loss: 0.205788, Val Acc: 0.536082\n",
      "Epoch 4606 - Train Loss: 0.193210, Train Acc: 0.610256 | Val Loss: 0.205773, Val Acc: 0.536082\n",
      "Epoch 4607 - Train Loss: 0.193195, Train Acc: 0.610256 | Val Loss: 0.205758, Val Acc: 0.536082\n",
      "Epoch 4608 - Train Loss: 0.193180, Train Acc: 0.610256 | Val Loss: 0.205743, Val Acc: 0.536082\n",
      "Epoch 4609 - Train Loss: 0.193165, Train Acc: 0.610256 | Val Loss: 0.205728, Val Acc: 0.536082\n",
      "Epoch 4610 - Train Loss: 0.193150, Train Acc: 0.610256 | Val Loss: 0.205713, Val Acc: 0.536082\n",
      "Epoch 4611 - Train Loss: 0.193135, Train Acc: 0.610256 | Val Loss: 0.205698, Val Acc: 0.536082\n",
      "Epoch 4612 - Train Loss: 0.193120, Train Acc: 0.610256 | Val Loss: 0.205683, Val Acc: 0.536082\n",
      "Epoch 4613 - Train Loss: 0.193105, Train Acc: 0.610256 | Val Loss: 0.205668, Val Acc: 0.536082\n",
      "Epoch 4614 - Train Loss: 0.193090, Train Acc: 0.610256 | Val Loss: 0.205653, Val Acc: 0.536082\n",
      "Epoch 4615 - Train Loss: 0.193075, Train Acc: 0.610256 | Val Loss: 0.205638, Val Acc: 0.536082\n",
      "Epoch 4616 - Train Loss: 0.193060, Train Acc: 0.610256 | Val Loss: 0.205623, Val Acc: 0.536082\n",
      "Epoch 4617 - Train Loss: 0.193045, Train Acc: 0.610256 | Val Loss: 0.205607, Val Acc: 0.536082\n",
      "Epoch 4618 - Train Loss: 0.193030, Train Acc: 0.610256 | Val Loss: 0.205592, Val Acc: 0.536082\n",
      "Epoch 4619 - Train Loss: 0.193015, Train Acc: 0.610256 | Val Loss: 0.205577, Val Acc: 0.536082\n",
      "Epoch 4620 - Train Loss: 0.193000, Train Acc: 0.610256 | Val Loss: 0.205562, Val Acc: 0.536082\n",
      "Epoch 4621 - Train Loss: 0.192985, Train Acc: 0.610256 | Val Loss: 0.205547, Val Acc: 0.536082\n",
      "Epoch 4622 - Train Loss: 0.192970, Train Acc: 0.610256 | Val Loss: 0.205532, Val Acc: 0.536082\n",
      "Epoch 4623 - Train Loss: 0.192955, Train Acc: 0.610256 | Val Loss: 0.205517, Val Acc: 0.536082\n",
      "Epoch 4624 - Train Loss: 0.192940, Train Acc: 0.610256 | Val Loss: 0.205502, Val Acc: 0.536082\n",
      "Epoch 4625 - Train Loss: 0.192925, Train Acc: 0.610256 | Val Loss: 0.205487, Val Acc: 0.536082\n",
      "Epoch 4626 - Train Loss: 0.192910, Train Acc: 0.610256 | Val Loss: 0.205472, Val Acc: 0.536082\n",
      "Epoch 4627 - Train Loss: 0.192895, Train Acc: 0.610256 | Val Loss: 0.205457, Val Acc: 0.536082\n",
      "Epoch 4628 - Train Loss: 0.192880, Train Acc: 0.610256 | Val Loss: 0.205442, Val Acc: 0.536082\n",
      "Epoch 4629 - Train Loss: 0.192865, Train Acc: 0.610256 | Val Loss: 0.205427, Val Acc: 0.536082\n",
      "Epoch 4630 - Train Loss: 0.192850, Train Acc: 0.610256 | Val Loss: 0.205412, Val Acc: 0.536082\n",
      "Epoch 4631 - Train Loss: 0.192835, Train Acc: 0.610256 | Val Loss: 0.205397, Val Acc: 0.536082\n",
      "Epoch 4632 - Train Loss: 0.192820, Train Acc: 0.610256 | Val Loss: 0.205382, Val Acc: 0.536082\n",
      "Epoch 4633 - Train Loss: 0.192805, Train Acc: 0.610256 | Val Loss: 0.205367, Val Acc: 0.536082\n",
      "Epoch 4634 - Train Loss: 0.192790, Train Acc: 0.610256 | Val Loss: 0.205352, Val Acc: 0.536082\n",
      "Epoch 4635 - Train Loss: 0.192775, Train Acc: 0.610256 | Val Loss: 0.205337, Val Acc: 0.536082\n",
      "Epoch 4636 - Train Loss: 0.192760, Train Acc: 0.610256 | Val Loss: 0.205322, Val Acc: 0.536082\n",
      "Epoch 4637 - Train Loss: 0.192745, Train Acc: 0.610256 | Val Loss: 0.205307, Val Acc: 0.536082\n",
      "Epoch 4638 - Train Loss: 0.192730, Train Acc: 0.610256 | Val Loss: 0.205292, Val Acc: 0.536082\n",
      "Epoch 4639 - Train Loss: 0.192715, Train Acc: 0.610256 | Val Loss: 0.205277, Val Acc: 0.536082\n",
      "Epoch 4640 - Train Loss: 0.192700, Train Acc: 0.610256 | Val Loss: 0.205262, Val Acc: 0.536082\n",
      "Epoch 4641 - Train Loss: 0.192685, Train Acc: 0.610256 | Val Loss: 0.205247, Val Acc: 0.536082\n",
      "Epoch 4642 - Train Loss: 0.192670, Train Acc: 0.610256 | Val Loss: 0.205232, Val Acc: 0.536082\n",
      "Epoch 4643 - Train Loss: 0.192655, Train Acc: 0.610256 | Val Loss: 0.205217, Val Acc: 0.536082\n",
      "Epoch 4644 - Train Loss: 0.192640, Train Acc: 0.610256 | Val Loss: 0.205202, Val Acc: 0.536082\n",
      "Epoch 4645 - Train Loss: 0.192625, Train Acc: 0.610256 | Val Loss: 0.205187, Val Acc: 0.536082\n",
      "Epoch 4646 - Train Loss: 0.192610, Train Acc: 0.611538 | Val Loss: 0.205172, Val Acc: 0.536082\n",
      "Epoch 4647 - Train Loss: 0.192595, Train Acc: 0.611538 | Val Loss: 0.205157, Val Acc: 0.536082\n",
      "Epoch 4648 - Train Loss: 0.192580, Train Acc: 0.611538 | Val Loss: 0.205142, Val Acc: 0.536082\n",
      "Epoch 4649 - Train Loss: 0.192565, Train Acc: 0.611538 | Val Loss: 0.205127, Val Acc: 0.536082\n",
      "Epoch 4650 - Train Loss: 0.192550, Train Acc: 0.611538 | Val Loss: 0.205112, Val Acc: 0.536082\n",
      "Epoch 4651 - Train Loss: 0.192535, Train Acc: 0.611538 | Val Loss: 0.205097, Val Acc: 0.536082\n",
      "Epoch 4652 - Train Loss: 0.192520, Train Acc: 0.611538 | Val Loss: 0.205082, Val Acc: 0.536082\n",
      "Epoch 4653 - Train Loss: 0.192505, Train Acc: 0.611538 | Val Loss: 0.205067, Val Acc: 0.536082\n",
      "Epoch 4654 - Train Loss: 0.192490, Train Acc: 0.611538 | Val Loss: 0.205052, Val Acc: 0.536082\n",
      "Epoch 4655 - Train Loss: 0.192475, Train Acc: 0.611538 | Val Loss: 0.205037, Val Acc: 0.536082\n",
      "Epoch 4656 - Train Loss: 0.192460, Train Acc: 0.611538 | Val Loss: 0.205022, Val Acc: 0.536082\n",
      "Epoch 4657 - Train Loss: 0.192445, Train Acc: 0.611538 | Val Loss: 0.205007, Val Acc: 0.536082\n",
      "Epoch 4658 - Train Loss: 0.192430, Train Acc: 0.611538 | Val Loss: 0.204992, Val Acc: 0.536082\n",
      "Epoch 4659 - Train Loss: 0.192416, Train Acc: 0.611538 | Val Loss: 0.204977, Val Acc: 0.536082\n",
      "Epoch 4660 - Train Loss: 0.192401, Train Acc: 0.611538 | Val Loss: 0.204962, Val Acc: 0.536082\n",
      "Epoch 4661 - Train Loss: 0.192386, Train Acc: 0.611538 | Val Loss: 0.204947, Val Acc: 0.536082\n",
      "Epoch 4662 - Train Loss: 0.192371, Train Acc: 0.611538 | Val Loss: 0.204932, Val Acc: 0.536082\n",
      "Epoch 4663 - Train Loss: 0.192356, Train Acc: 0.611538 | Val Loss: 0.204917, Val Acc: 0.536082\n",
      "Epoch 4664 - Train Loss: 0.192341, Train Acc: 0.611538 | Val Loss: 0.204902, Val Acc: 0.536082\n",
      "Epoch 4665 - Train Loss: 0.192326, Train Acc: 0.611538 | Val Loss: 0.204887, Val Acc: 0.536082\n",
      "Epoch 4666 - Train Loss: 0.192311, Train Acc: 0.611538 | Val Loss: 0.204872, Val Acc: 0.536082\n",
      "Epoch 4667 - Train Loss: 0.192296, Train Acc: 0.611538 | Val Loss: 0.204857, Val Acc: 0.536082\n",
      "Epoch 4668 - Train Loss: 0.192281, Train Acc: 0.611538 | Val Loss: 0.204842, Val Acc: 0.536082\n",
      "Epoch 4669 - Train Loss: 0.192266, Train Acc: 0.611538 | Val Loss: 0.204827, Val Acc: 0.536082\n",
      "Epoch 4670 - Train Loss: 0.192251, Train Acc: 0.611538 | Val Loss: 0.204812, Val Acc: 0.536082\n",
      "Epoch 4671 - Train Loss: 0.192236, Train Acc: 0.611538 | Val Loss: 0.204797, Val Acc: 0.536082\n",
      "Epoch 4672 - Train Loss: 0.192222, Train Acc: 0.611538 | Val Loss: 0.204782, Val Acc: 0.536082\n",
      "Epoch 4673 - Train Loss: 0.192207, Train Acc: 0.611538 | Val Loss: 0.204767, Val Acc: 0.536082\n",
      "Epoch 4674 - Train Loss: 0.192192, Train Acc: 0.611538 | Val Loss: 0.204752, Val Acc: 0.536082\n",
      "Epoch 4675 - Train Loss: 0.192177, Train Acc: 0.611538 | Val Loss: 0.204737, Val Acc: 0.536082\n",
      "Epoch 4676 - Train Loss: 0.192162, Train Acc: 0.612821 | Val Loss: 0.204722, Val Acc: 0.536082\n",
      "Epoch 4677 - Train Loss: 0.192147, Train Acc: 0.612821 | Val Loss: 0.204707, Val Acc: 0.536082\n",
      "Epoch 4678 - Train Loss: 0.192132, Train Acc: 0.612821 | Val Loss: 0.204692, Val Acc: 0.536082\n",
      "Epoch 4679 - Train Loss: 0.192117, Train Acc: 0.612821 | Val Loss: 0.204677, Val Acc: 0.536082\n",
      "Epoch 4680 - Train Loss: 0.192102, Train Acc: 0.612821 | Val Loss: 0.204662, Val Acc: 0.536082\n",
      "Epoch 4681 - Train Loss: 0.192087, Train Acc: 0.612821 | Val Loss: 0.204647, Val Acc: 0.536082\n",
      "Epoch 4682 - Train Loss: 0.192072, Train Acc: 0.612821 | Val Loss: 0.204632, Val Acc: 0.536082\n",
      "Epoch 4683 - Train Loss: 0.192058, Train Acc: 0.612821 | Val Loss: 0.204617, Val Acc: 0.536082\n",
      "Epoch 4684 - Train Loss: 0.192043, Train Acc: 0.612821 | Val Loss: 0.204602, Val Acc: 0.536082\n",
      "Epoch 4685 - Train Loss: 0.192028, Train Acc: 0.612821 | Val Loss: 0.204587, Val Acc: 0.536082\n",
      "Epoch 4686 - Train Loss: 0.192013, Train Acc: 0.612821 | Val Loss: 0.204572, Val Acc: 0.536082\n",
      "Epoch 4687 - Train Loss: 0.191998, Train Acc: 0.612821 | Val Loss: 0.204557, Val Acc: 0.536082\n",
      "Epoch 4688 - Train Loss: 0.191983, Train Acc: 0.612821 | Val Loss: 0.204542, Val Acc: 0.536082\n",
      "Epoch 4689 - Train Loss: 0.191968, Train Acc: 0.612821 | Val Loss: 0.204527, Val Acc: 0.536082\n",
      "Epoch 4690 - Train Loss: 0.191953, Train Acc: 0.612821 | Val Loss: 0.204512, Val Acc: 0.536082\n",
      "Epoch 4691 - Train Loss: 0.191938, Train Acc: 0.612821 | Val Loss: 0.204497, Val Acc: 0.536082\n",
      "Epoch 4692 - Train Loss: 0.191924, Train Acc: 0.612821 | Val Loss: 0.204482, Val Acc: 0.536082\n",
      "Epoch 4693 - Train Loss: 0.191909, Train Acc: 0.612821 | Val Loss: 0.204467, Val Acc: 0.536082\n",
      "Epoch 4694 - Train Loss: 0.191894, Train Acc: 0.612821 | Val Loss: 0.204452, Val Acc: 0.536082\n",
      "Epoch 4695 - Train Loss: 0.191879, Train Acc: 0.612821 | Val Loss: 0.204436, Val Acc: 0.536082\n",
      "Epoch 4696 - Train Loss: 0.191864, Train Acc: 0.612821 | Val Loss: 0.204421, Val Acc: 0.536082\n",
      "Epoch 4697 - Train Loss: 0.191849, Train Acc: 0.612821 | Val Loss: 0.204406, Val Acc: 0.536082\n",
      "Epoch 4698 - Train Loss: 0.191834, Train Acc: 0.612821 | Val Loss: 0.204391, Val Acc: 0.536082\n",
      "Epoch 4699 - Train Loss: 0.191819, Train Acc: 0.612821 | Val Loss: 0.204376, Val Acc: 0.536082\n",
      "Epoch 4700 - Train Loss: 0.191805, Train Acc: 0.612821 | Val Loss: 0.204361, Val Acc: 0.536082\n",
      "Epoch 4701 - Train Loss: 0.191790, Train Acc: 0.612821 | Val Loss: 0.204346, Val Acc: 0.536082\n",
      "Epoch 4702 - Train Loss: 0.191775, Train Acc: 0.612821 | Val Loss: 0.204331, Val Acc: 0.536082\n",
      "Epoch 4703 - Train Loss: 0.191760, Train Acc: 0.612821 | Val Loss: 0.204316, Val Acc: 0.536082\n",
      "Epoch 4704 - Train Loss: 0.191745, Train Acc: 0.612821 | Val Loss: 0.204301, Val Acc: 0.536082\n",
      "Epoch 4705 - Train Loss: 0.191730, Train Acc: 0.612821 | Val Loss: 0.204286, Val Acc: 0.536082\n",
      "Epoch 4706 - Train Loss: 0.191715, Train Acc: 0.612821 | Val Loss: 0.204271, Val Acc: 0.536082\n",
      "Epoch 4707 - Train Loss: 0.191701, Train Acc: 0.612821 | Val Loss: 0.204256, Val Acc: 0.536082\n",
      "Epoch 4708 - Train Loss: 0.191686, Train Acc: 0.612821 | Val Loss: 0.204241, Val Acc: 0.536082\n",
      "Epoch 4709 - Train Loss: 0.191671, Train Acc: 0.612821 | Val Loss: 0.204226, Val Acc: 0.536082\n",
      "Epoch 4710 - Train Loss: 0.191656, Train Acc: 0.614103 | Val Loss: 0.204211, Val Acc: 0.536082\n",
      "Epoch 4711 - Train Loss: 0.191641, Train Acc: 0.614103 | Val Loss: 0.204196, Val Acc: 0.536082\n",
      "Epoch 4712 - Train Loss: 0.191626, Train Acc: 0.614103 | Val Loss: 0.204181, Val Acc: 0.536082\n",
      "Epoch 4713 - Train Loss: 0.191611, Train Acc: 0.614103 | Val Loss: 0.204166, Val Acc: 0.536082\n",
      "Epoch 4714 - Train Loss: 0.191597, Train Acc: 0.614103 | Val Loss: 0.204151, Val Acc: 0.536082\n",
      "Epoch 4715 - Train Loss: 0.191582, Train Acc: 0.614103 | Val Loss: 0.204136, Val Acc: 0.536082\n",
      "Epoch 4716 - Train Loss: 0.191567, Train Acc: 0.614103 | Val Loss: 0.204121, Val Acc: 0.536082\n",
      "Epoch 4717 - Train Loss: 0.191552, Train Acc: 0.614103 | Val Loss: 0.204106, Val Acc: 0.536082\n",
      "Epoch 4718 - Train Loss: 0.191537, Train Acc: 0.614103 | Val Loss: 0.204091, Val Acc: 0.536082\n",
      "Epoch 4719 - Train Loss: 0.191522, Train Acc: 0.614103 | Val Loss: 0.204076, Val Acc: 0.536082\n",
      "Epoch 4720 - Train Loss: 0.191508, Train Acc: 0.615385 | Val Loss: 0.204061, Val Acc: 0.536082\n",
      "Epoch 4721 - Train Loss: 0.191493, Train Acc: 0.616667 | Val Loss: 0.204046, Val Acc: 0.536082\n",
      "Epoch 4722 - Train Loss: 0.191478, Train Acc: 0.616667 | Val Loss: 0.204031, Val Acc: 0.536082\n",
      "Epoch 4723 - Train Loss: 0.191463, Train Acc: 0.616667 | Val Loss: 0.204016, Val Acc: 0.536082\n",
      "Epoch 4724 - Train Loss: 0.191448, Train Acc: 0.616667 | Val Loss: 0.204001, Val Acc: 0.536082\n",
      "Epoch 4725 - Train Loss: 0.191433, Train Acc: 0.616667 | Val Loss: 0.203986, Val Acc: 0.536082\n",
      "Epoch 4726 - Train Loss: 0.191419, Train Acc: 0.616667 | Val Loss: 0.203971, Val Acc: 0.536082\n",
      "Epoch 4727 - Train Loss: 0.191404, Train Acc: 0.616667 | Val Loss: 0.203957, Val Acc: 0.536082\n",
      "Epoch 4728 - Train Loss: 0.191389, Train Acc: 0.616667 | Val Loss: 0.203942, Val Acc: 0.536082\n",
      "Epoch 4729 - Train Loss: 0.191374, Train Acc: 0.616667 | Val Loss: 0.203927, Val Acc: 0.536082\n",
      "Epoch 4730 - Train Loss: 0.191359, Train Acc: 0.616667 | Val Loss: 0.203912, Val Acc: 0.536082\n",
      "Epoch 4731 - Train Loss: 0.191345, Train Acc: 0.616667 | Val Loss: 0.203897, Val Acc: 0.536082\n",
      "Epoch 4732 - Train Loss: 0.191330, Train Acc: 0.616667 | Val Loss: 0.203882, Val Acc: 0.536082\n",
      "Epoch 4733 - Train Loss: 0.191315, Train Acc: 0.616667 | Val Loss: 0.203867, Val Acc: 0.536082\n",
      "Epoch 4734 - Train Loss: 0.191300, Train Acc: 0.616667 | Val Loss: 0.203852, Val Acc: 0.536082\n",
      "Epoch 4735 - Train Loss: 0.191285, Train Acc: 0.616667 | Val Loss: 0.203837, Val Acc: 0.536082\n",
      "Epoch 4736 - Train Loss: 0.191270, Train Acc: 0.616667 | Val Loss: 0.203822, Val Acc: 0.536082\n",
      "Epoch 4737 - Train Loss: 0.191256, Train Acc: 0.616667 | Val Loss: 0.203807, Val Acc: 0.536082\n",
      "Epoch 4738 - Train Loss: 0.191241, Train Acc: 0.616667 | Val Loss: 0.203792, Val Acc: 0.536082\n",
      "Epoch 4739 - Train Loss: 0.191226, Train Acc: 0.616667 | Val Loss: 0.203777, Val Acc: 0.536082\n",
      "Epoch 4740 - Train Loss: 0.191211, Train Acc: 0.616667 | Val Loss: 0.203762, Val Acc: 0.536082\n",
      "Epoch 4741 - Train Loss: 0.191196, Train Acc: 0.616667 | Val Loss: 0.203747, Val Acc: 0.536082\n",
      "Epoch 4742 - Train Loss: 0.191182, Train Acc: 0.616667 | Val Loss: 0.203732, Val Acc: 0.536082\n",
      "Epoch 4743 - Train Loss: 0.191167, Train Acc: 0.617949 | Val Loss: 0.203717, Val Acc: 0.536082\n",
      "Epoch 4744 - Train Loss: 0.191152, Train Acc: 0.617949 | Val Loss: 0.203702, Val Acc: 0.536082\n",
      "Epoch 4745 - Train Loss: 0.191137, Train Acc: 0.617949 | Val Loss: 0.203687, Val Acc: 0.536082\n",
      "Epoch 4746 - Train Loss: 0.191122, Train Acc: 0.617949 | Val Loss: 0.203673, Val Acc: 0.536082\n",
      "Epoch 4747 - Train Loss: 0.191108, Train Acc: 0.617949 | Val Loss: 0.203658, Val Acc: 0.536082\n",
      "Epoch 4748 - Train Loss: 0.191093, Train Acc: 0.617949 | Val Loss: 0.203643, Val Acc: 0.536082\n",
      "Epoch 4749 - Train Loss: 0.191078, Train Acc: 0.617949 | Val Loss: 0.203628, Val Acc: 0.536082\n",
      "Epoch 4750 - Train Loss: 0.191063, Train Acc: 0.617949 | Val Loss: 0.203613, Val Acc: 0.536082\n",
      "Epoch 4751 - Train Loss: 0.191048, Train Acc: 0.617949 | Val Loss: 0.203598, Val Acc: 0.536082\n",
      "Epoch 4752 - Train Loss: 0.191034, Train Acc: 0.617949 | Val Loss: 0.203583, Val Acc: 0.536082\n",
      "Epoch 4753 - Train Loss: 0.191019, Train Acc: 0.617949 | Val Loss: 0.203568, Val Acc: 0.536082\n",
      "Epoch 4754 - Train Loss: 0.191004, Train Acc: 0.617949 | Val Loss: 0.203553, Val Acc: 0.536082\n",
      "Epoch 4755 - Train Loss: 0.190989, Train Acc: 0.617949 | Val Loss: 0.203538, Val Acc: 0.536082\n",
      "Epoch 4756 - Train Loss: 0.190975, Train Acc: 0.617949 | Val Loss: 0.203523, Val Acc: 0.536082\n",
      "Epoch 4757 - Train Loss: 0.190960, Train Acc: 0.617949 | Val Loss: 0.203508, Val Acc: 0.536082\n",
      "Epoch 4758 - Train Loss: 0.190945, Train Acc: 0.617949 | Val Loss: 0.203494, Val Acc: 0.536082\n",
      "Epoch 4759 - Train Loss: 0.190930, Train Acc: 0.617949 | Val Loss: 0.203479, Val Acc: 0.536082\n",
      "Epoch 4760 - Train Loss: 0.190915, Train Acc: 0.617949 | Val Loss: 0.203464, Val Acc: 0.536082\n",
      "Epoch 4761 - Train Loss: 0.190901, Train Acc: 0.617949 | Val Loss: 0.203449, Val Acc: 0.536082\n",
      "Epoch 4762 - Train Loss: 0.190886, Train Acc: 0.617949 | Val Loss: 0.203434, Val Acc: 0.536082\n",
      "Epoch 4763 - Train Loss: 0.190871, Train Acc: 0.617949 | Val Loss: 0.203419, Val Acc: 0.536082\n",
      "Epoch 4764 - Train Loss: 0.190856, Train Acc: 0.617949 | Val Loss: 0.203404, Val Acc: 0.536082\n",
      "Epoch 4765 - Train Loss: 0.190842, Train Acc: 0.617949 | Val Loss: 0.203389, Val Acc: 0.536082\n",
      "Epoch 4766 - Train Loss: 0.190827, Train Acc: 0.617949 | Val Loss: 0.203374, Val Acc: 0.536082\n",
      "Epoch 4767 - Train Loss: 0.190812, Train Acc: 0.617949 | Val Loss: 0.203359, Val Acc: 0.536082\n",
      "Epoch 4768 - Train Loss: 0.190797, Train Acc: 0.617949 | Val Loss: 0.203345, Val Acc: 0.536082\n",
      "Epoch 4769 - Train Loss: 0.190783, Train Acc: 0.617949 | Val Loss: 0.203330, Val Acc: 0.536082\n",
      "Epoch 4770 - Train Loss: 0.190768, Train Acc: 0.617949 | Val Loss: 0.203315, Val Acc: 0.536082\n",
      "Epoch 4771 - Train Loss: 0.190753, Train Acc: 0.617949 | Val Loss: 0.203300, Val Acc: 0.536082\n",
      "Epoch 4772 - Train Loss: 0.190738, Train Acc: 0.617949 | Val Loss: 0.203285, Val Acc: 0.536082\n",
      "Epoch 4773 - Train Loss: 0.190724, Train Acc: 0.617949 | Val Loss: 0.203270, Val Acc: 0.536082\n",
      "Epoch 4774 - Train Loss: 0.190709, Train Acc: 0.617949 | Val Loss: 0.203255, Val Acc: 0.536082\n",
      "Epoch 4775 - Train Loss: 0.190694, Train Acc: 0.617949 | Val Loss: 0.203240, Val Acc: 0.536082\n",
      "Epoch 4776 - Train Loss: 0.190679, Train Acc: 0.617949 | Val Loss: 0.203226, Val Acc: 0.536082\n",
      "Epoch 4777 - Train Loss: 0.190665, Train Acc: 0.617949 | Val Loss: 0.203211, Val Acc: 0.536082\n",
      "Epoch 4778 - Train Loss: 0.190650, Train Acc: 0.617949 | Val Loss: 0.203196, Val Acc: 0.536082\n",
      "Epoch 4779 - Train Loss: 0.190635, Train Acc: 0.617949 | Val Loss: 0.203181, Val Acc: 0.536082\n",
      "Epoch 4780 - Train Loss: 0.190620, Train Acc: 0.617949 | Val Loss: 0.203166, Val Acc: 0.536082\n",
      "Epoch 4781 - Train Loss: 0.190606, Train Acc: 0.617949 | Val Loss: 0.203151, Val Acc: 0.536082\n",
      "Epoch 4782 - Train Loss: 0.190591, Train Acc: 0.617949 | Val Loss: 0.203136, Val Acc: 0.536082\n",
      "Epoch 4783 - Train Loss: 0.190576, Train Acc: 0.617949 | Val Loss: 0.203122, Val Acc: 0.536082\n",
      "Epoch 4784 - Train Loss: 0.190561, Train Acc: 0.617949 | Val Loss: 0.203107, Val Acc: 0.536082\n",
      "Epoch 4785 - Train Loss: 0.190547, Train Acc: 0.617949 | Val Loss: 0.203092, Val Acc: 0.536082\n",
      "Epoch 4786 - Train Loss: 0.190532, Train Acc: 0.617949 | Val Loss: 0.203077, Val Acc: 0.536082\n",
      "Epoch 4787 - Train Loss: 0.190517, Train Acc: 0.617949 | Val Loss: 0.203062, Val Acc: 0.536082\n",
      "Epoch 4788 - Train Loss: 0.190502, Train Acc: 0.617949 | Val Loss: 0.203047, Val Acc: 0.536082\n",
      "Epoch 4789 - Train Loss: 0.190488, Train Acc: 0.617949 | Val Loss: 0.203032, Val Acc: 0.536082\n",
      "Epoch 4790 - Train Loss: 0.190473, Train Acc: 0.617949 | Val Loss: 0.203018, Val Acc: 0.536082\n",
      "Epoch 4791 - Train Loss: 0.190458, Train Acc: 0.617949 | Val Loss: 0.203003, Val Acc: 0.536082\n",
      "Epoch 4792 - Train Loss: 0.190444, Train Acc: 0.617949 | Val Loss: 0.202988, Val Acc: 0.536082\n",
      "Epoch 4793 - Train Loss: 0.190429, Train Acc: 0.617949 | Val Loss: 0.202973, Val Acc: 0.536082\n",
      "Epoch 4794 - Train Loss: 0.190414, Train Acc: 0.617949 | Val Loss: 0.202958, Val Acc: 0.536082\n",
      "Epoch 4795 - Train Loss: 0.190399, Train Acc: 0.617949 | Val Loss: 0.202943, Val Acc: 0.536082\n",
      "Epoch 4796 - Train Loss: 0.190385, Train Acc: 0.617949 | Val Loss: 0.202929, Val Acc: 0.536082\n",
      "Epoch 4797 - Train Loss: 0.190370, Train Acc: 0.617949 | Val Loss: 0.202914, Val Acc: 0.536082\n",
      "Epoch 4798 - Train Loss: 0.190355, Train Acc: 0.617949 | Val Loss: 0.202899, Val Acc: 0.536082\n",
      "Epoch 4799 - Train Loss: 0.190341, Train Acc: 0.617949 | Val Loss: 0.202884, Val Acc: 0.536082\n",
      "Epoch 4800 - Train Loss: 0.190326, Train Acc: 0.617949 | Val Loss: 0.202869, Val Acc: 0.536082\n",
      "Epoch 4801 - Train Loss: 0.190311, Train Acc: 0.617949 | Val Loss: 0.202854, Val Acc: 0.536082\n",
      "Epoch 4802 - Train Loss: 0.190296, Train Acc: 0.617949 | Val Loss: 0.202840, Val Acc: 0.536082\n",
      "Epoch 4803 - Train Loss: 0.190282, Train Acc: 0.617949 | Val Loss: 0.202825, Val Acc: 0.536082\n",
      "Epoch 4804 - Train Loss: 0.190267, Train Acc: 0.617949 | Val Loss: 0.202810, Val Acc: 0.536082\n",
      "Epoch 4805 - Train Loss: 0.190252, Train Acc: 0.617949 | Val Loss: 0.202795, Val Acc: 0.536082\n",
      "Epoch 4806 - Train Loss: 0.190238, Train Acc: 0.617949 | Val Loss: 0.202780, Val Acc: 0.536082\n",
      "Epoch 4807 - Train Loss: 0.190223, Train Acc: 0.617949 | Val Loss: 0.202765, Val Acc: 0.536082\n",
      "Epoch 4808 - Train Loss: 0.190208, Train Acc: 0.617949 | Val Loss: 0.202751, Val Acc: 0.536082\n",
      "Epoch 4809 - Train Loss: 0.190194, Train Acc: 0.617949 | Val Loss: 0.202736, Val Acc: 0.536082\n",
      "Epoch 4810 - Train Loss: 0.190179, Train Acc: 0.617949 | Val Loss: 0.202721, Val Acc: 0.536082\n",
      "Epoch 4811 - Train Loss: 0.190164, Train Acc: 0.617949 | Val Loss: 0.202706, Val Acc: 0.536082\n",
      "Epoch 4812 - Train Loss: 0.190149, Train Acc: 0.617949 | Val Loss: 0.202691, Val Acc: 0.536082\n",
      "Epoch 4813 - Train Loss: 0.190135, Train Acc: 0.617949 | Val Loss: 0.202676, Val Acc: 0.536082\n",
      "Epoch 4814 - Train Loss: 0.190120, Train Acc: 0.617949 | Val Loss: 0.202662, Val Acc: 0.536082\n",
      "Epoch 4815 - Train Loss: 0.190105, Train Acc: 0.617949 | Val Loss: 0.202647, Val Acc: 0.536082\n",
      "Epoch 4816 - Train Loss: 0.190091, Train Acc: 0.617949 | Val Loss: 0.202632, Val Acc: 0.536082\n",
      "Epoch 4817 - Train Loss: 0.190076, Train Acc: 0.617949 | Val Loss: 0.202617, Val Acc: 0.536082\n",
      "Epoch 4818 - Train Loss: 0.190061, Train Acc: 0.617949 | Val Loss: 0.202602, Val Acc: 0.536082\n",
      "Epoch 4819 - Train Loss: 0.190047, Train Acc: 0.617949 | Val Loss: 0.202588, Val Acc: 0.536082\n",
      "Epoch 4820 - Train Loss: 0.190032, Train Acc: 0.617949 | Val Loss: 0.202573, Val Acc: 0.536082\n",
      "Epoch 4821 - Train Loss: 0.190017, Train Acc: 0.617949 | Val Loss: 0.202558, Val Acc: 0.536082\n",
      "Epoch 4822 - Train Loss: 0.190003, Train Acc: 0.617949 | Val Loss: 0.202543, Val Acc: 0.536082\n",
      "Epoch 4823 - Train Loss: 0.189988, Train Acc: 0.617949 | Val Loss: 0.202528, Val Acc: 0.536082\n",
      "Epoch 4824 - Train Loss: 0.189973, Train Acc: 0.617949 | Val Loss: 0.202513, Val Acc: 0.536082\n",
      "Epoch 4825 - Train Loss: 0.189959, Train Acc: 0.617949 | Val Loss: 0.202499, Val Acc: 0.536082\n",
      "Epoch 4826 - Train Loss: 0.189944, Train Acc: 0.617949 | Val Loss: 0.202484, Val Acc: 0.536082\n",
      "Epoch 4827 - Train Loss: 0.189929, Train Acc: 0.617949 | Val Loss: 0.202469, Val Acc: 0.536082\n",
      "Epoch 4828 - Train Loss: 0.189914, Train Acc: 0.617949 | Val Loss: 0.202454, Val Acc: 0.536082\n",
      "Epoch 4829 - Train Loss: 0.189900, Train Acc: 0.617949 | Val Loss: 0.202439, Val Acc: 0.536082\n",
      "Epoch 4830 - Train Loss: 0.189885, Train Acc: 0.617949 | Val Loss: 0.202424, Val Acc: 0.536082\n",
      "Epoch 4831 - Train Loss: 0.189870, Train Acc: 0.617949 | Val Loss: 0.202409, Val Acc: 0.536082\n",
      "Epoch 4832 - Train Loss: 0.189856, Train Acc: 0.617949 | Val Loss: 0.202395, Val Acc: 0.536082\n",
      "Epoch 4833 - Train Loss: 0.189841, Train Acc: 0.617949 | Val Loss: 0.202380, Val Acc: 0.536082\n",
      "Epoch 4834 - Train Loss: 0.189826, Train Acc: 0.617949 | Val Loss: 0.202365, Val Acc: 0.536082\n",
      "Epoch 4835 - Train Loss: 0.189812, Train Acc: 0.617949 | Val Loss: 0.202350, Val Acc: 0.536082\n",
      "Epoch 4836 - Train Loss: 0.189797, Train Acc: 0.617949 | Val Loss: 0.202335, Val Acc: 0.536082\n",
      "Epoch 4837 - Train Loss: 0.189782, Train Acc: 0.617949 | Val Loss: 0.202320, Val Acc: 0.536082\n",
      "Epoch 4838 - Train Loss: 0.189768, Train Acc: 0.617949 | Val Loss: 0.202305, Val Acc: 0.536082\n",
      "Epoch 4839 - Train Loss: 0.189753, Train Acc: 0.617949 | Val Loss: 0.202291, Val Acc: 0.536082\n",
      "Epoch 4840 - Train Loss: 0.189738, Train Acc: 0.617949 | Val Loss: 0.202276, Val Acc: 0.536082\n",
      "Epoch 4841 - Train Loss: 0.189724, Train Acc: 0.617949 | Val Loss: 0.202261, Val Acc: 0.536082\n",
      "Epoch 4842 - Train Loss: 0.189709, Train Acc: 0.617949 | Val Loss: 0.202246, Val Acc: 0.536082\n",
      "Epoch 4843 - Train Loss: 0.189694, Train Acc: 0.617949 | Val Loss: 0.202231, Val Acc: 0.546392\n",
      "Epoch 4844 - Train Loss: 0.189680, Train Acc: 0.617949 | Val Loss: 0.202216, Val Acc: 0.546392\n",
      "Epoch 4845 - Train Loss: 0.189665, Train Acc: 0.617949 | Val Loss: 0.202202, Val Acc: 0.546392\n",
      "Epoch 4846 - Train Loss: 0.189650, Train Acc: 0.617949 | Val Loss: 0.202187, Val Acc: 0.546392\n",
      "Epoch 4847 - Train Loss: 0.189636, Train Acc: 0.617949 | Val Loss: 0.202172, Val Acc: 0.546392\n",
      "Epoch 4848 - Train Loss: 0.189621, Train Acc: 0.617949 | Val Loss: 0.202157, Val Acc: 0.546392\n",
      "Epoch 4849 - Train Loss: 0.189606, Train Acc: 0.617949 | Val Loss: 0.202142, Val Acc: 0.546392\n",
      "Epoch 4850 - Train Loss: 0.189592, Train Acc: 0.617949 | Val Loss: 0.202127, Val Acc: 0.546392\n",
      "Epoch 4851 - Train Loss: 0.189577, Train Acc: 0.617949 | Val Loss: 0.202113, Val Acc: 0.546392\n",
      "Epoch 4852 - Train Loss: 0.189562, Train Acc: 0.617949 | Val Loss: 0.202098, Val Acc: 0.546392\n",
      "Epoch 4853 - Train Loss: 0.189548, Train Acc: 0.617949 | Val Loss: 0.202083, Val Acc: 0.546392\n",
      "Epoch 4854 - Train Loss: 0.189533, Train Acc: 0.617949 | Val Loss: 0.202068, Val Acc: 0.546392\n",
      "Epoch 4855 - Train Loss: 0.189518, Train Acc: 0.617949 | Val Loss: 0.202053, Val Acc: 0.546392\n",
      "Epoch 4856 - Train Loss: 0.189504, Train Acc: 0.617949 | Val Loss: 0.202039, Val Acc: 0.546392\n",
      "Epoch 4857 - Train Loss: 0.189489, Train Acc: 0.617949 | Val Loss: 0.202024, Val Acc: 0.546392\n",
      "Epoch 4858 - Train Loss: 0.189475, Train Acc: 0.617949 | Val Loss: 0.202009, Val Acc: 0.546392\n",
      "Epoch 4859 - Train Loss: 0.189460, Train Acc: 0.617949 | Val Loss: 0.201994, Val Acc: 0.546392\n",
      "Epoch 4860 - Train Loss: 0.189445, Train Acc: 0.617949 | Val Loss: 0.201979, Val Acc: 0.546392\n",
      "Epoch 4861 - Train Loss: 0.189431, Train Acc: 0.617949 | Val Loss: 0.201965, Val Acc: 0.546392\n",
      "Epoch 4862 - Train Loss: 0.189416, Train Acc: 0.617949 | Val Loss: 0.201950, Val Acc: 0.546392\n",
      "Epoch 4863 - Train Loss: 0.189401, Train Acc: 0.617949 | Val Loss: 0.201935, Val Acc: 0.546392\n",
      "Epoch 4864 - Train Loss: 0.189387, Train Acc: 0.617949 | Val Loss: 0.201920, Val Acc: 0.546392\n",
      "Epoch 4865 - Train Loss: 0.189372, Train Acc: 0.617949 | Val Loss: 0.201905, Val Acc: 0.546392\n",
      "Epoch 4866 - Train Loss: 0.189357, Train Acc: 0.617949 | Val Loss: 0.201891, Val Acc: 0.546392\n",
      "Epoch 4867 - Train Loss: 0.189343, Train Acc: 0.617949 | Val Loss: 0.201876, Val Acc: 0.546392\n",
      "Epoch 4868 - Train Loss: 0.189328, Train Acc: 0.617949 | Val Loss: 0.201861, Val Acc: 0.546392\n",
      "Epoch 4869 - Train Loss: 0.189314, Train Acc: 0.617949 | Val Loss: 0.201846, Val Acc: 0.546392\n",
      "Epoch 4870 - Train Loss: 0.189299, Train Acc: 0.617949 | Val Loss: 0.201832, Val Acc: 0.546392\n",
      "Epoch 4871 - Train Loss: 0.189284, Train Acc: 0.617949 | Val Loss: 0.201817, Val Acc: 0.546392\n",
      "Epoch 4872 - Train Loss: 0.189270, Train Acc: 0.617949 | Val Loss: 0.201802, Val Acc: 0.546392\n",
      "Epoch 4873 - Train Loss: 0.189255, Train Acc: 0.617949 | Val Loss: 0.201787, Val Acc: 0.546392\n",
      "Epoch 4874 - Train Loss: 0.189241, Train Acc: 0.617949 | Val Loss: 0.201773, Val Acc: 0.546392\n",
      "Epoch 4875 - Train Loss: 0.189226, Train Acc: 0.617949 | Val Loss: 0.201758, Val Acc: 0.546392\n",
      "Epoch 4876 - Train Loss: 0.189211, Train Acc: 0.617949 | Val Loss: 0.201743, Val Acc: 0.546392\n",
      "Epoch 4877 - Train Loss: 0.189197, Train Acc: 0.617949 | Val Loss: 0.201728, Val Acc: 0.546392\n",
      "Epoch 4878 - Train Loss: 0.189182, Train Acc: 0.617949 | Val Loss: 0.201714, Val Acc: 0.546392\n",
      "Epoch 4879 - Train Loss: 0.189167, Train Acc: 0.617949 | Val Loss: 0.201699, Val Acc: 0.546392\n",
      "Epoch 4880 - Train Loss: 0.189153, Train Acc: 0.617949 | Val Loss: 0.201684, Val Acc: 0.546392\n",
      "Epoch 4881 - Train Loss: 0.189138, Train Acc: 0.617949 | Val Loss: 0.201669, Val Acc: 0.546392\n",
      "Epoch 4882 - Train Loss: 0.189124, Train Acc: 0.617949 | Val Loss: 0.201655, Val Acc: 0.546392\n",
      "Epoch 4883 - Train Loss: 0.189109, Train Acc: 0.617949 | Val Loss: 0.201640, Val Acc: 0.546392\n",
      "Epoch 4884 - Train Loss: 0.189094, Train Acc: 0.617949 | Val Loss: 0.201625, Val Acc: 0.546392\n",
      "Epoch 4885 - Train Loss: 0.189080, Train Acc: 0.617949 | Val Loss: 0.201610, Val Acc: 0.546392\n",
      "Epoch 4886 - Train Loss: 0.189065, Train Acc: 0.617949 | Val Loss: 0.201596, Val Acc: 0.546392\n",
      "Epoch 4887 - Train Loss: 0.189051, Train Acc: 0.617949 | Val Loss: 0.201581, Val Acc: 0.546392\n",
      "Epoch 4888 - Train Loss: 0.189036, Train Acc: 0.617949 | Val Loss: 0.201566, Val Acc: 0.546392\n",
      "Epoch 4889 - Train Loss: 0.189021, Train Acc: 0.617949 | Val Loss: 0.201551, Val Acc: 0.546392\n",
      "Epoch 4890 - Train Loss: 0.189007, Train Acc: 0.617949 | Val Loss: 0.201537, Val Acc: 0.546392\n",
      "Epoch 4891 - Train Loss: 0.188992, Train Acc: 0.619231 | Val Loss: 0.201522, Val Acc: 0.546392\n",
      "Epoch 4892 - Train Loss: 0.188978, Train Acc: 0.619231 | Val Loss: 0.201507, Val Acc: 0.546392\n",
      "Epoch 4893 - Train Loss: 0.188963, Train Acc: 0.619231 | Val Loss: 0.201493, Val Acc: 0.546392\n",
      "Epoch 4894 - Train Loss: 0.188948, Train Acc: 0.619231 | Val Loss: 0.201478, Val Acc: 0.546392\n",
      "Epoch 4895 - Train Loss: 0.188934, Train Acc: 0.619231 | Val Loss: 0.201463, Val Acc: 0.546392\n",
      "Epoch 4896 - Train Loss: 0.188919, Train Acc: 0.619231 | Val Loss: 0.201448, Val Acc: 0.546392\n",
      "Epoch 4897 - Train Loss: 0.188905, Train Acc: 0.619231 | Val Loss: 0.201434, Val Acc: 0.546392\n",
      "Epoch 4898 - Train Loss: 0.188890, Train Acc: 0.619231 | Val Loss: 0.201419, Val Acc: 0.546392\n",
      "Epoch 4899 - Train Loss: 0.188876, Train Acc: 0.619231 | Val Loss: 0.201404, Val Acc: 0.546392\n",
      "Epoch 4900 - Train Loss: 0.188861, Train Acc: 0.619231 | Val Loss: 0.201390, Val Acc: 0.546392\n",
      "Epoch 4901 - Train Loss: 0.188846, Train Acc: 0.619231 | Val Loss: 0.201375, Val Acc: 0.546392\n",
      "Epoch 4902 - Train Loss: 0.188832, Train Acc: 0.619231 | Val Loss: 0.201360, Val Acc: 0.546392\n",
      "Epoch 4903 - Train Loss: 0.188817, Train Acc: 0.619231 | Val Loss: 0.201346, Val Acc: 0.546392\n",
      "Epoch 4904 - Train Loss: 0.188803, Train Acc: 0.619231 | Val Loss: 0.201331, Val Acc: 0.546392\n",
      "Epoch 4905 - Train Loss: 0.188788, Train Acc: 0.619231 | Val Loss: 0.201316, Val Acc: 0.546392\n",
      "Epoch 4906 - Train Loss: 0.188774, Train Acc: 0.619231 | Val Loss: 0.201302, Val Acc: 0.546392\n",
      "Epoch 4907 - Train Loss: 0.188759, Train Acc: 0.619231 | Val Loss: 0.201287, Val Acc: 0.546392\n",
      "Epoch 4908 - Train Loss: 0.188744, Train Acc: 0.619231 | Val Loss: 0.201272, Val Acc: 0.546392\n",
      "Epoch 4909 - Train Loss: 0.188730, Train Acc: 0.619231 | Val Loss: 0.201257, Val Acc: 0.546392\n",
      "Epoch 4910 - Train Loss: 0.188715, Train Acc: 0.619231 | Val Loss: 0.201243, Val Acc: 0.546392\n",
      "Epoch 4911 - Train Loss: 0.188701, Train Acc: 0.619231 | Val Loss: 0.201228, Val Acc: 0.546392\n",
      "Epoch 4912 - Train Loss: 0.188686, Train Acc: 0.619231 | Val Loss: 0.201213, Val Acc: 0.546392\n",
      "Epoch 4913 - Train Loss: 0.188672, Train Acc: 0.619231 | Val Loss: 0.201199, Val Acc: 0.546392\n",
      "Epoch 4914 - Train Loss: 0.188657, Train Acc: 0.619231 | Val Loss: 0.201184, Val Acc: 0.546392\n",
      "Epoch 4915 - Train Loss: 0.188642, Train Acc: 0.619231 | Val Loss: 0.201169, Val Acc: 0.546392\n",
      "Epoch 4916 - Train Loss: 0.188628, Train Acc: 0.620513 | Val Loss: 0.201155, Val Acc: 0.546392\n",
      "Epoch 4917 - Train Loss: 0.188613, Train Acc: 0.620513 | Val Loss: 0.201140, Val Acc: 0.546392\n",
      "Epoch 4918 - Train Loss: 0.188599, Train Acc: 0.620513 | Val Loss: 0.201125, Val Acc: 0.546392\n",
      "Epoch 4919 - Train Loss: 0.188584, Train Acc: 0.620513 | Val Loss: 0.201111, Val Acc: 0.546392\n",
      "Epoch 4920 - Train Loss: 0.188570, Train Acc: 0.621795 | Val Loss: 0.201096, Val Acc: 0.546392\n",
      "Epoch 4921 - Train Loss: 0.188555, Train Acc: 0.621795 | Val Loss: 0.201081, Val Acc: 0.546392\n",
      "Epoch 4922 - Train Loss: 0.188541, Train Acc: 0.621795 | Val Loss: 0.201067, Val Acc: 0.546392\n",
      "Epoch 4923 - Train Loss: 0.188526, Train Acc: 0.621795 | Val Loss: 0.201052, Val Acc: 0.546392\n",
      "Epoch 4924 - Train Loss: 0.188512, Train Acc: 0.621795 | Val Loss: 0.201038, Val Acc: 0.546392\n",
      "Epoch 4925 - Train Loss: 0.188497, Train Acc: 0.621795 | Val Loss: 0.201023, Val Acc: 0.546392\n",
      "Epoch 4926 - Train Loss: 0.188482, Train Acc: 0.621795 | Val Loss: 0.201008, Val Acc: 0.546392\n",
      "Epoch 4927 - Train Loss: 0.188468, Train Acc: 0.621795 | Val Loss: 0.200994, Val Acc: 0.546392\n",
      "Epoch 4928 - Train Loss: 0.188453, Train Acc: 0.621795 | Val Loss: 0.200979, Val Acc: 0.546392\n",
      "Epoch 4929 - Train Loss: 0.188439, Train Acc: 0.621795 | Val Loss: 0.200964, Val Acc: 0.546392\n",
      "Epoch 4930 - Train Loss: 0.188424, Train Acc: 0.621795 | Val Loss: 0.200950, Val Acc: 0.546392\n",
      "Epoch 4931 - Train Loss: 0.188410, Train Acc: 0.621795 | Val Loss: 0.200935, Val Acc: 0.546392\n",
      "Epoch 4932 - Train Loss: 0.188395, Train Acc: 0.621795 | Val Loss: 0.200921, Val Acc: 0.546392\n",
      "Epoch 4933 - Train Loss: 0.188381, Train Acc: 0.621795 | Val Loss: 0.200906, Val Acc: 0.546392\n",
      "Epoch 4934 - Train Loss: 0.188366, Train Acc: 0.621795 | Val Loss: 0.200891, Val Acc: 0.546392\n",
      "Epoch 4935 - Train Loss: 0.188352, Train Acc: 0.621795 | Val Loss: 0.200877, Val Acc: 0.546392\n",
      "Epoch 4936 - Train Loss: 0.188337, Train Acc: 0.621795 | Val Loss: 0.200862, Val Acc: 0.546392\n",
      "Epoch 4937 - Train Loss: 0.188323, Train Acc: 0.621795 | Val Loss: 0.200848, Val Acc: 0.546392\n",
      "Epoch 4938 - Train Loss: 0.188308, Train Acc: 0.621795 | Val Loss: 0.200833, Val Acc: 0.546392\n",
      "Epoch 4939 - Train Loss: 0.188294, Train Acc: 0.621795 | Val Loss: 0.200818, Val Acc: 0.546392\n",
      "Epoch 4940 - Train Loss: 0.188279, Train Acc: 0.621795 | Val Loss: 0.200804, Val Acc: 0.546392\n",
      "Epoch 4941 - Train Loss: 0.188265, Train Acc: 0.621795 | Val Loss: 0.200789, Val Acc: 0.546392\n",
      "Epoch 4942 - Train Loss: 0.188250, Train Acc: 0.621795 | Val Loss: 0.200775, Val Acc: 0.546392\n",
      "Epoch 4943 - Train Loss: 0.188236, Train Acc: 0.621795 | Val Loss: 0.200760, Val Acc: 0.546392\n",
      "Epoch 4944 - Train Loss: 0.188221, Train Acc: 0.621795 | Val Loss: 0.200746, Val Acc: 0.546392\n",
      "Epoch 4945 - Train Loss: 0.188207, Train Acc: 0.621795 | Val Loss: 0.200731, Val Acc: 0.546392\n",
      "Epoch 4946 - Train Loss: 0.188192, Train Acc: 0.621795 | Val Loss: 0.200716, Val Acc: 0.546392\n",
      "Epoch 4947 - Train Loss: 0.188178, Train Acc: 0.621795 | Val Loss: 0.200702, Val Acc: 0.546392\n",
      "Epoch 4948 - Train Loss: 0.188163, Train Acc: 0.621795 | Val Loss: 0.200687, Val Acc: 0.546392\n",
      "Epoch 4949 - Train Loss: 0.188149, Train Acc: 0.621795 | Val Loss: 0.200673, Val Acc: 0.546392\n",
      "Epoch 4950 - Train Loss: 0.188134, Train Acc: 0.621795 | Val Loss: 0.200658, Val Acc: 0.546392\n",
      "Epoch 4951 - Train Loss: 0.188120, Train Acc: 0.621795 | Val Loss: 0.200644, Val Acc: 0.546392\n",
      "Epoch 4952 - Train Loss: 0.188105, Train Acc: 0.621795 | Val Loss: 0.200629, Val Acc: 0.546392\n",
      "Epoch 4953 - Train Loss: 0.188091, Train Acc: 0.621795 | Val Loss: 0.200614, Val Acc: 0.546392\n",
      "Epoch 4954 - Train Loss: 0.188076, Train Acc: 0.621795 | Val Loss: 0.200600, Val Acc: 0.546392\n",
      "Epoch 4955 - Train Loss: 0.188062, Train Acc: 0.621795 | Val Loss: 0.200585, Val Acc: 0.546392\n",
      "Epoch 4956 - Train Loss: 0.188047, Train Acc: 0.621795 | Val Loss: 0.200571, Val Acc: 0.546392\n",
      "Epoch 4957 - Train Loss: 0.188033, Train Acc: 0.623077 | Val Loss: 0.200556, Val Acc: 0.546392\n",
      "Epoch 4958 - Train Loss: 0.188018, Train Acc: 0.623077 | Val Loss: 0.200542, Val Acc: 0.546392\n",
      "Epoch 4959 - Train Loss: 0.188004, Train Acc: 0.623077 | Val Loss: 0.200527, Val Acc: 0.546392\n",
      "Epoch 4960 - Train Loss: 0.187989, Train Acc: 0.623077 | Val Loss: 0.200512, Val Acc: 0.546392\n",
      "Epoch 4961 - Train Loss: 0.187975, Train Acc: 0.623077 | Val Loss: 0.200498, Val Acc: 0.546392\n",
      "Epoch 4962 - Train Loss: 0.187960, Train Acc: 0.623077 | Val Loss: 0.200483, Val Acc: 0.546392\n",
      "Epoch 4963 - Train Loss: 0.187946, Train Acc: 0.623077 | Val Loss: 0.200469, Val Acc: 0.546392\n",
      "Epoch 4964 - Train Loss: 0.187931, Train Acc: 0.623077 | Val Loss: 0.200454, Val Acc: 0.546392\n",
      "Epoch 4965 - Train Loss: 0.187917, Train Acc: 0.623077 | Val Loss: 0.200440, Val Acc: 0.546392\n",
      "Epoch 4966 - Train Loss: 0.187902, Train Acc: 0.623077 | Val Loss: 0.200425, Val Acc: 0.546392\n",
      "Epoch 4967 - Train Loss: 0.187888, Train Acc: 0.623077 | Val Loss: 0.200411, Val Acc: 0.546392\n",
      "Epoch 4968 - Train Loss: 0.187874, Train Acc: 0.623077 | Val Loss: 0.200396, Val Acc: 0.546392\n",
      "Epoch 4969 - Train Loss: 0.187859, Train Acc: 0.623077 | Val Loss: 0.200382, Val Acc: 0.546392\n",
      "Epoch 4970 - Train Loss: 0.187845, Train Acc: 0.623077 | Val Loss: 0.200367, Val Acc: 0.546392\n",
      "Epoch 4971 - Train Loss: 0.187830, Train Acc: 0.623077 | Val Loss: 0.200353, Val Acc: 0.546392\n",
      "Epoch 4972 - Train Loss: 0.187816, Train Acc: 0.623077 | Val Loss: 0.200338, Val Acc: 0.546392\n",
      "Epoch 4973 - Train Loss: 0.187801, Train Acc: 0.624359 | Val Loss: 0.200323, Val Acc: 0.546392\n",
      "Epoch 4974 - Train Loss: 0.187787, Train Acc: 0.624359 | Val Loss: 0.200309, Val Acc: 0.546392\n",
      "Epoch 4975 - Train Loss: 0.187772, Train Acc: 0.624359 | Val Loss: 0.200294, Val Acc: 0.546392\n",
      "Epoch 4976 - Train Loss: 0.187758, Train Acc: 0.624359 | Val Loss: 0.200280, Val Acc: 0.546392\n",
      "Epoch 4977 - Train Loss: 0.187743, Train Acc: 0.624359 | Val Loss: 0.200265, Val Acc: 0.546392\n",
      "Epoch 4978 - Train Loss: 0.187729, Train Acc: 0.624359 | Val Loss: 0.200251, Val Acc: 0.546392\n",
      "Epoch 4979 - Train Loss: 0.187714, Train Acc: 0.624359 | Val Loss: 0.200236, Val Acc: 0.546392\n",
      "Epoch 4980 - Train Loss: 0.187700, Train Acc: 0.624359 | Val Loss: 0.200222, Val Acc: 0.546392\n",
      "Epoch 4981 - Train Loss: 0.187686, Train Acc: 0.624359 | Val Loss: 0.200207, Val Acc: 0.546392\n",
      "Epoch 4982 - Train Loss: 0.187671, Train Acc: 0.624359 | Val Loss: 0.200193, Val Acc: 0.546392\n",
      "Epoch 4983 - Train Loss: 0.187657, Train Acc: 0.624359 | Val Loss: 0.200178, Val Acc: 0.546392\n",
      "Epoch 4984 - Train Loss: 0.187642, Train Acc: 0.624359 | Val Loss: 0.200164, Val Acc: 0.546392\n",
      "Epoch 4985 - Train Loss: 0.187628, Train Acc: 0.624359 | Val Loss: 0.200149, Val Acc: 0.546392\n",
      "Epoch 4986 - Train Loss: 0.187613, Train Acc: 0.624359 | Val Loss: 0.200135, Val Acc: 0.546392\n",
      "Epoch 4987 - Train Loss: 0.187599, Train Acc: 0.624359 | Val Loss: 0.200120, Val Acc: 0.546392\n",
      "Epoch 4988 - Train Loss: 0.187584, Train Acc: 0.624359 | Val Loss: 0.200106, Val Acc: 0.546392\n",
      "Epoch 4989 - Train Loss: 0.187570, Train Acc: 0.624359 | Val Loss: 0.200091, Val Acc: 0.546392\n",
      "Epoch 4990 - Train Loss: 0.187556, Train Acc: 0.624359 | Val Loss: 0.200077, Val Acc: 0.546392\n",
      "Epoch 4991 - Train Loss: 0.187541, Train Acc: 0.624359 | Val Loss: 0.200062, Val Acc: 0.546392\n",
      "Epoch 4992 - Train Loss: 0.187527, Train Acc: 0.624359 | Val Loss: 0.200048, Val Acc: 0.546392\n",
      "Epoch 4993 - Train Loss: 0.187512, Train Acc: 0.624359 | Val Loss: 0.200033, Val Acc: 0.546392\n",
      "Epoch 4994 - Train Loss: 0.187498, Train Acc: 0.624359 | Val Loss: 0.200019, Val Acc: 0.546392\n",
      "Epoch 4995 - Train Loss: 0.187483, Train Acc: 0.624359 | Val Loss: 0.200004, Val Acc: 0.546392\n",
      "Epoch 4996 - Train Loss: 0.187469, Train Acc: 0.624359 | Val Loss: 0.199990, Val Acc: 0.546392\n",
      "Epoch 4997 - Train Loss: 0.187455, Train Acc: 0.624359 | Val Loss: 0.199975, Val Acc: 0.546392\n",
      "Epoch 4998 - Train Loss: 0.187440, Train Acc: 0.624359 | Val Loss: 0.199961, Val Acc: 0.546392\n",
      "Epoch 4999 - Train Loss: 0.187426, Train Acc: 0.624359 | Val Loss: 0.199946, Val Acc: 0.546392\n",
      "Epoch 5000 - Train Loss: 0.187411, Train Acc: 0.624359 | Val Loss: 0.199932, Val Acc: 0.546392\n",
      "Epoch 5001 - Train Loss: 0.187397, Train Acc: 0.624359 | Val Loss: 0.199917, Val Acc: 0.546392\n",
      "Epoch 5002 - Train Loss: 0.187382, Train Acc: 0.624359 | Val Loss: 0.199903, Val Acc: 0.546392\n",
      "Epoch 5003 - Train Loss: 0.187368, Train Acc: 0.624359 | Val Loss: 0.199888, Val Acc: 0.546392\n",
      "Epoch 5004 - Train Loss: 0.187354, Train Acc: 0.624359 | Val Loss: 0.199874, Val Acc: 0.546392\n",
      "Epoch 5005 - Train Loss: 0.187339, Train Acc: 0.624359 | Val Loss: 0.199860, Val Acc: 0.546392\n",
      "Epoch 5006 - Train Loss: 0.187325, Train Acc: 0.624359 | Val Loss: 0.199845, Val Acc: 0.546392\n",
      "Epoch 5007 - Train Loss: 0.187310, Train Acc: 0.624359 | Val Loss: 0.199831, Val Acc: 0.546392\n",
      "Epoch 5008 - Train Loss: 0.187296, Train Acc: 0.624359 | Val Loss: 0.199816, Val Acc: 0.546392\n",
      "Epoch 5009 - Train Loss: 0.187281, Train Acc: 0.624359 | Val Loss: 0.199802, Val Acc: 0.546392\n",
      "Epoch 5010 - Train Loss: 0.187267, Train Acc: 0.624359 | Val Loss: 0.199787, Val Acc: 0.546392\n",
      "Epoch 5011 - Train Loss: 0.187253, Train Acc: 0.624359 | Val Loss: 0.199773, Val Acc: 0.546392\n",
      "Epoch 5012 - Train Loss: 0.187238, Train Acc: 0.624359 | Val Loss: 0.199758, Val Acc: 0.546392\n",
      "Epoch 5013 - Train Loss: 0.187224, Train Acc: 0.624359 | Val Loss: 0.199744, Val Acc: 0.546392\n",
      "Epoch 5014 - Train Loss: 0.187209, Train Acc: 0.624359 | Val Loss: 0.199729, Val Acc: 0.546392\n",
      "Epoch 5015 - Train Loss: 0.187195, Train Acc: 0.624359 | Val Loss: 0.199715, Val Acc: 0.546392\n",
      "Epoch 5016 - Train Loss: 0.187181, Train Acc: 0.624359 | Val Loss: 0.199700, Val Acc: 0.546392\n",
      "Epoch 5017 - Train Loss: 0.187166, Train Acc: 0.624359 | Val Loss: 0.199686, Val Acc: 0.546392\n",
      "Epoch 5018 - Train Loss: 0.187152, Train Acc: 0.624359 | Val Loss: 0.199672, Val Acc: 0.546392\n",
      "Epoch 5019 - Train Loss: 0.187137, Train Acc: 0.625641 | Val Loss: 0.199657, Val Acc: 0.546392\n",
      "Epoch 5020 - Train Loss: 0.187123, Train Acc: 0.625641 | Val Loss: 0.199643, Val Acc: 0.546392\n",
      "Epoch 5021 - Train Loss: 0.187109, Train Acc: 0.625641 | Val Loss: 0.199628, Val Acc: 0.546392\n",
      "Epoch 5022 - Train Loss: 0.187094, Train Acc: 0.625641 | Val Loss: 0.199614, Val Acc: 0.546392\n",
      "Epoch 5023 - Train Loss: 0.187080, Train Acc: 0.625641 | Val Loss: 0.199599, Val Acc: 0.546392\n",
      "Epoch 5024 - Train Loss: 0.187065, Train Acc: 0.625641 | Val Loss: 0.199585, Val Acc: 0.546392\n",
      "Epoch 5025 - Train Loss: 0.187051, Train Acc: 0.625641 | Val Loss: 0.199571, Val Acc: 0.546392\n",
      "Epoch 5026 - Train Loss: 0.187037, Train Acc: 0.625641 | Val Loss: 0.199556, Val Acc: 0.546392\n",
      "Epoch 5027 - Train Loss: 0.187022, Train Acc: 0.625641 | Val Loss: 0.199542, Val Acc: 0.546392\n",
      "Epoch 5028 - Train Loss: 0.187008, Train Acc: 0.625641 | Val Loss: 0.199527, Val Acc: 0.546392\n",
      "Epoch 5029 - Train Loss: 0.186994, Train Acc: 0.625641 | Val Loss: 0.199513, Val Acc: 0.546392\n",
      "Epoch 5030 - Train Loss: 0.186979, Train Acc: 0.625641 | Val Loss: 0.199498, Val Acc: 0.546392\n",
      "Epoch 5031 - Train Loss: 0.186965, Train Acc: 0.625641 | Val Loss: 0.199484, Val Acc: 0.546392\n",
      "Epoch 5032 - Train Loss: 0.186950, Train Acc: 0.625641 | Val Loss: 0.199470, Val Acc: 0.546392\n",
      "Epoch 5033 - Train Loss: 0.186936, Train Acc: 0.625641 | Val Loss: 0.199455, Val Acc: 0.546392\n",
      "Epoch 5034 - Train Loss: 0.186922, Train Acc: 0.625641 | Val Loss: 0.199441, Val Acc: 0.546392\n",
      "Epoch 5035 - Train Loss: 0.186907, Train Acc: 0.625641 | Val Loss: 0.199426, Val Acc: 0.546392\n",
      "Epoch 5036 - Train Loss: 0.186893, Train Acc: 0.625641 | Val Loss: 0.199412, Val Acc: 0.546392\n",
      "Epoch 5037 - Train Loss: 0.186878, Train Acc: 0.625641 | Val Loss: 0.199397, Val Acc: 0.546392\n",
      "Epoch 5038 - Train Loss: 0.186864, Train Acc: 0.625641 | Val Loss: 0.199383, Val Acc: 0.546392\n",
      "Epoch 5039 - Train Loss: 0.186850, Train Acc: 0.625641 | Val Loss: 0.199369, Val Acc: 0.546392\n",
      "Epoch 5040 - Train Loss: 0.186835, Train Acc: 0.625641 | Val Loss: 0.199354, Val Acc: 0.546392\n",
      "Epoch 5041 - Train Loss: 0.186821, Train Acc: 0.625641 | Val Loss: 0.199340, Val Acc: 0.546392\n",
      "Epoch 5042 - Train Loss: 0.186807, Train Acc: 0.625641 | Val Loss: 0.199325, Val Acc: 0.546392\n",
      "Epoch 5043 - Train Loss: 0.186792, Train Acc: 0.625641 | Val Loss: 0.199311, Val Acc: 0.546392\n",
      "Epoch 5044 - Train Loss: 0.186778, Train Acc: 0.625641 | Val Loss: 0.199297, Val Acc: 0.546392\n",
      "Epoch 5045 - Train Loss: 0.186764, Train Acc: 0.625641 | Val Loss: 0.199282, Val Acc: 0.546392\n",
      "Epoch 5046 - Train Loss: 0.186749, Train Acc: 0.625641 | Val Loss: 0.199268, Val Acc: 0.546392\n",
      "Epoch 5047 - Train Loss: 0.186735, Train Acc: 0.625641 | Val Loss: 0.199253, Val Acc: 0.546392\n",
      "Epoch 5048 - Train Loss: 0.186720, Train Acc: 0.625641 | Val Loss: 0.199239, Val Acc: 0.546392\n",
      "Epoch 5049 - Train Loss: 0.186706, Train Acc: 0.625641 | Val Loss: 0.199225, Val Acc: 0.546392\n",
      "Epoch 5050 - Train Loss: 0.186692, Train Acc: 0.625641 | Val Loss: 0.199210, Val Acc: 0.546392\n",
      "Epoch 5051 - Train Loss: 0.186677, Train Acc: 0.625641 | Val Loss: 0.199196, Val Acc: 0.546392\n",
      "Epoch 5052 - Train Loss: 0.186663, Train Acc: 0.625641 | Val Loss: 0.199181, Val Acc: 0.546392\n",
      "Epoch 5053 - Train Loss: 0.186649, Train Acc: 0.625641 | Val Loss: 0.199167, Val Acc: 0.546392\n",
      "Epoch 5054 - Train Loss: 0.186634, Train Acc: 0.625641 | Val Loss: 0.199153, Val Acc: 0.546392\n",
      "Epoch 5055 - Train Loss: 0.186620, Train Acc: 0.625641 | Val Loss: 0.199138, Val Acc: 0.546392\n",
      "Epoch 5056 - Train Loss: 0.186606, Train Acc: 0.625641 | Val Loss: 0.199124, Val Acc: 0.546392\n",
      "Epoch 5057 - Train Loss: 0.186591, Train Acc: 0.625641 | Val Loss: 0.199109, Val Acc: 0.546392\n",
      "Epoch 5058 - Train Loss: 0.186577, Train Acc: 0.625641 | Val Loss: 0.199095, Val Acc: 0.546392\n",
      "Epoch 5059 - Train Loss: 0.186563, Train Acc: 0.625641 | Val Loss: 0.199081, Val Acc: 0.546392\n",
      "Epoch 5060 - Train Loss: 0.186548, Train Acc: 0.625641 | Val Loss: 0.199066, Val Acc: 0.546392\n",
      "Epoch 5061 - Train Loss: 0.186534, Train Acc: 0.625641 | Val Loss: 0.199052, Val Acc: 0.546392\n",
      "Epoch 5062 - Train Loss: 0.186520, Train Acc: 0.625641 | Val Loss: 0.199038, Val Acc: 0.546392\n",
      "Epoch 5063 - Train Loss: 0.186505, Train Acc: 0.625641 | Val Loss: 0.199023, Val Acc: 0.546392\n",
      "Epoch 5064 - Train Loss: 0.186491, Train Acc: 0.625641 | Val Loss: 0.199009, Val Acc: 0.546392\n",
      "Epoch 5065 - Train Loss: 0.186477, Train Acc: 0.625641 | Val Loss: 0.198995, Val Acc: 0.546392\n",
      "Epoch 5066 - Train Loss: 0.186462, Train Acc: 0.625641 | Val Loss: 0.198980, Val Acc: 0.546392\n",
      "Epoch 5067 - Train Loss: 0.186448, Train Acc: 0.625641 | Val Loss: 0.198966, Val Acc: 0.546392\n",
      "Epoch 5068 - Train Loss: 0.186434, Train Acc: 0.625641 | Val Loss: 0.198951, Val Acc: 0.546392\n",
      "Epoch 5069 - Train Loss: 0.186419, Train Acc: 0.625641 | Val Loss: 0.198937, Val Acc: 0.546392\n",
      "Epoch 5070 - Train Loss: 0.186405, Train Acc: 0.625641 | Val Loss: 0.198923, Val Acc: 0.546392\n",
      "Epoch 5071 - Train Loss: 0.186391, Train Acc: 0.625641 | Val Loss: 0.198908, Val Acc: 0.546392\n",
      "Epoch 5072 - Train Loss: 0.186376, Train Acc: 0.625641 | Val Loss: 0.198894, Val Acc: 0.546392\n",
      "Epoch 5073 - Train Loss: 0.186362, Train Acc: 0.625641 | Val Loss: 0.198880, Val Acc: 0.546392\n",
      "Epoch 5074 - Train Loss: 0.186348, Train Acc: 0.625641 | Val Loss: 0.198865, Val Acc: 0.546392\n",
      "Epoch 5075 - Train Loss: 0.186333, Train Acc: 0.625641 | Val Loss: 0.198851, Val Acc: 0.546392\n",
      "Epoch 5076 - Train Loss: 0.186319, Train Acc: 0.625641 | Val Loss: 0.198837, Val Acc: 0.546392\n",
      "Epoch 5077 - Train Loss: 0.186305, Train Acc: 0.625641 | Val Loss: 0.198822, Val Acc: 0.546392\n",
      "Epoch 5078 - Train Loss: 0.186290, Train Acc: 0.625641 | Val Loss: 0.198808, Val Acc: 0.546392\n",
      "Epoch 5079 - Train Loss: 0.186276, Train Acc: 0.625641 | Val Loss: 0.198794, Val Acc: 0.546392\n",
      "Epoch 5080 - Train Loss: 0.186262, Train Acc: 0.625641 | Val Loss: 0.198779, Val Acc: 0.546392\n",
      "Epoch 5081 - Train Loss: 0.186247, Train Acc: 0.625641 | Val Loss: 0.198765, Val Acc: 0.546392\n",
      "Epoch 5082 - Train Loss: 0.186233, Train Acc: 0.625641 | Val Loss: 0.198751, Val Acc: 0.546392\n",
      "Epoch 5083 - Train Loss: 0.186219, Train Acc: 0.625641 | Val Loss: 0.198736, Val Acc: 0.546392\n",
      "Epoch 5084 - Train Loss: 0.186204, Train Acc: 0.625641 | Val Loss: 0.198722, Val Acc: 0.546392\n",
      "Epoch 5085 - Train Loss: 0.186190, Train Acc: 0.625641 | Val Loss: 0.198708, Val Acc: 0.546392\n",
      "Epoch 5086 - Train Loss: 0.186176, Train Acc: 0.625641 | Val Loss: 0.198693, Val Acc: 0.546392\n",
      "Epoch 5087 - Train Loss: 0.186161, Train Acc: 0.625641 | Val Loss: 0.198679, Val Acc: 0.546392\n",
      "Epoch 5088 - Train Loss: 0.186147, Train Acc: 0.625641 | Val Loss: 0.198665, Val Acc: 0.546392\n",
      "Epoch 5089 - Train Loss: 0.186133, Train Acc: 0.625641 | Val Loss: 0.198650, Val Acc: 0.546392\n",
      "Epoch 5090 - Train Loss: 0.186119, Train Acc: 0.625641 | Val Loss: 0.198636, Val Acc: 0.546392\n",
      "Epoch 5091 - Train Loss: 0.186104, Train Acc: 0.625641 | Val Loss: 0.198622, Val Acc: 0.546392\n",
      "Epoch 5092 - Train Loss: 0.186090, Train Acc: 0.625641 | Val Loss: 0.198607, Val Acc: 0.546392\n",
      "Epoch 5093 - Train Loss: 0.186076, Train Acc: 0.625641 | Val Loss: 0.198593, Val Acc: 0.546392\n",
      "Epoch 5094 - Train Loss: 0.186061, Train Acc: 0.625641 | Val Loss: 0.198579, Val Acc: 0.546392\n",
      "Epoch 5095 - Train Loss: 0.186047, Train Acc: 0.625641 | Val Loss: 0.198564, Val Acc: 0.546392\n",
      "Epoch 5096 - Train Loss: 0.186033, Train Acc: 0.625641 | Val Loss: 0.198550, Val Acc: 0.546392\n",
      "Epoch 5097 - Train Loss: 0.186018, Train Acc: 0.625641 | Val Loss: 0.198536, Val Acc: 0.546392\n",
      "Epoch 5098 - Train Loss: 0.186004, Train Acc: 0.625641 | Val Loss: 0.198521, Val Acc: 0.546392\n",
      "Epoch 5099 - Train Loss: 0.185990, Train Acc: 0.625641 | Val Loss: 0.198507, Val Acc: 0.546392\n",
      "Epoch 5100 - Train Loss: 0.185976, Train Acc: 0.625641 | Val Loss: 0.198493, Val Acc: 0.546392\n",
      "Epoch 5101 - Train Loss: 0.185961, Train Acc: 0.625641 | Val Loss: 0.198478, Val Acc: 0.546392\n",
      "Epoch 5102 - Train Loss: 0.185947, Train Acc: 0.625641 | Val Loss: 0.198464, Val Acc: 0.546392\n",
      "Epoch 5103 - Train Loss: 0.185933, Train Acc: 0.625641 | Val Loss: 0.198450, Val Acc: 0.546392\n",
      "Epoch 5104 - Train Loss: 0.185918, Train Acc: 0.625641 | Val Loss: 0.198436, Val Acc: 0.546392\n",
      "Epoch 5105 - Train Loss: 0.185904, Train Acc: 0.625641 | Val Loss: 0.198421, Val Acc: 0.546392\n",
      "Epoch 5106 - Train Loss: 0.185890, Train Acc: 0.625641 | Val Loss: 0.198407, Val Acc: 0.546392\n",
      "Epoch 5107 - Train Loss: 0.185876, Train Acc: 0.625641 | Val Loss: 0.198393, Val Acc: 0.546392\n",
      "Epoch 5108 - Train Loss: 0.185861, Train Acc: 0.625641 | Val Loss: 0.198378, Val Acc: 0.546392\n",
      "Epoch 5109 - Train Loss: 0.185847, Train Acc: 0.625641 | Val Loss: 0.198364, Val Acc: 0.546392\n",
      "Epoch 5110 - Train Loss: 0.185833, Train Acc: 0.625641 | Val Loss: 0.198350, Val Acc: 0.546392\n",
      "Epoch 5111 - Train Loss: 0.185818, Train Acc: 0.625641 | Val Loss: 0.198335, Val Acc: 0.546392\n",
      "Epoch 5112 - Train Loss: 0.185804, Train Acc: 0.625641 | Val Loss: 0.198321, Val Acc: 0.546392\n",
      "Epoch 5113 - Train Loss: 0.185790, Train Acc: 0.625641 | Val Loss: 0.198307, Val Acc: 0.546392\n",
      "Epoch 5114 - Train Loss: 0.185776, Train Acc: 0.625641 | Val Loss: 0.198293, Val Acc: 0.546392\n",
      "Epoch 5115 - Train Loss: 0.185761, Train Acc: 0.625641 | Val Loss: 0.198278, Val Acc: 0.546392\n",
      "Epoch 5116 - Train Loss: 0.185747, Train Acc: 0.626923 | Val Loss: 0.198264, Val Acc: 0.546392\n",
      "Epoch 5117 - Train Loss: 0.185733, Train Acc: 0.626923 | Val Loss: 0.198250, Val Acc: 0.546392\n",
      "Epoch 5118 - Train Loss: 0.185719, Train Acc: 0.626923 | Val Loss: 0.198235, Val Acc: 0.546392\n",
      "Epoch 5119 - Train Loss: 0.185704, Train Acc: 0.626923 | Val Loss: 0.198221, Val Acc: 0.546392\n",
      "Epoch 5120 - Train Loss: 0.185690, Train Acc: 0.626923 | Val Loss: 0.198207, Val Acc: 0.546392\n",
      "Epoch 5121 - Train Loss: 0.185676, Train Acc: 0.626923 | Val Loss: 0.198193, Val Acc: 0.546392\n",
      "Epoch 5122 - Train Loss: 0.185661, Train Acc: 0.626923 | Val Loss: 0.198178, Val Acc: 0.546392\n",
      "Epoch 5123 - Train Loss: 0.185647, Train Acc: 0.626923 | Val Loss: 0.198164, Val Acc: 0.546392\n",
      "Epoch 5124 - Train Loss: 0.185633, Train Acc: 0.626923 | Val Loss: 0.198150, Val Acc: 0.546392\n",
      "Epoch 5125 - Train Loss: 0.185619, Train Acc: 0.626923 | Val Loss: 0.198136, Val Acc: 0.546392\n",
      "Epoch 5126 - Train Loss: 0.185604, Train Acc: 0.626923 | Val Loss: 0.198121, Val Acc: 0.546392\n",
      "Epoch 5127 - Train Loss: 0.185590, Train Acc: 0.626923 | Val Loss: 0.198107, Val Acc: 0.546392\n",
      "Epoch 5128 - Train Loss: 0.185576, Train Acc: 0.626923 | Val Loss: 0.198093, Val Acc: 0.546392\n",
      "Epoch 5129 - Train Loss: 0.185562, Train Acc: 0.626923 | Val Loss: 0.198078, Val Acc: 0.546392\n",
      "Epoch 5130 - Train Loss: 0.185547, Train Acc: 0.626923 | Val Loss: 0.198064, Val Acc: 0.546392\n",
      "Epoch 5131 - Train Loss: 0.185533, Train Acc: 0.626923 | Val Loss: 0.198050, Val Acc: 0.546392\n",
      "Epoch 5132 - Train Loss: 0.185519, Train Acc: 0.626923 | Val Loss: 0.198036, Val Acc: 0.546392\n",
      "Epoch 5133 - Train Loss: 0.185505, Train Acc: 0.626923 | Val Loss: 0.198021, Val Acc: 0.546392\n",
      "Epoch 5134 - Train Loss: 0.185490, Train Acc: 0.626923 | Val Loss: 0.198007, Val Acc: 0.546392\n",
      "Epoch 5135 - Train Loss: 0.185476, Train Acc: 0.626923 | Val Loss: 0.197993, Val Acc: 0.546392\n",
      "Epoch 5136 - Train Loss: 0.185462, Train Acc: 0.626923 | Val Loss: 0.197979, Val Acc: 0.546392\n",
      "Epoch 5137 - Train Loss: 0.185448, Train Acc: 0.626923 | Val Loss: 0.197964, Val Acc: 0.546392\n",
      "Epoch 5138 - Train Loss: 0.185433, Train Acc: 0.626923 | Val Loss: 0.197950, Val Acc: 0.546392\n",
      "Epoch 5139 - Train Loss: 0.185419, Train Acc: 0.626923 | Val Loss: 0.197936, Val Acc: 0.546392\n",
      "Epoch 5140 - Train Loss: 0.185405, Train Acc: 0.628205 | Val Loss: 0.197922, Val Acc: 0.546392\n",
      "Epoch 5141 - Train Loss: 0.185391, Train Acc: 0.628205 | Val Loss: 0.197907, Val Acc: 0.546392\n",
      "Epoch 5142 - Train Loss: 0.185377, Train Acc: 0.628205 | Val Loss: 0.197893, Val Acc: 0.546392\n",
      "Epoch 5143 - Train Loss: 0.185362, Train Acc: 0.628205 | Val Loss: 0.197879, Val Acc: 0.546392\n",
      "Epoch 5144 - Train Loss: 0.185348, Train Acc: 0.628205 | Val Loss: 0.197865, Val Acc: 0.546392\n",
      "Epoch 5145 - Train Loss: 0.185334, Train Acc: 0.628205 | Val Loss: 0.197851, Val Acc: 0.546392\n",
      "Epoch 5146 - Train Loss: 0.185320, Train Acc: 0.628205 | Val Loss: 0.197836, Val Acc: 0.546392\n",
      "Epoch 5147 - Train Loss: 0.185305, Train Acc: 0.628205 | Val Loss: 0.197822, Val Acc: 0.546392\n",
      "Epoch 5148 - Train Loss: 0.185291, Train Acc: 0.628205 | Val Loss: 0.197808, Val Acc: 0.546392\n",
      "Epoch 5149 - Train Loss: 0.185277, Train Acc: 0.628205 | Val Loss: 0.197794, Val Acc: 0.546392\n",
      "Epoch 5150 - Train Loss: 0.185263, Train Acc: 0.628205 | Val Loss: 0.197780, Val Acc: 0.546392\n",
      "Epoch 5151 - Train Loss: 0.185249, Train Acc: 0.628205 | Val Loss: 0.197766, Val Acc: 0.546392\n",
      "Epoch 5152 - Train Loss: 0.185234, Train Acc: 0.628205 | Val Loss: 0.197752, Val Acc: 0.546392\n",
      "Epoch 5153 - Train Loss: 0.185220, Train Acc: 0.628205 | Val Loss: 0.197738, Val Acc: 0.556701\n",
      "Epoch 5154 - Train Loss: 0.185206, Train Acc: 0.628205 | Val Loss: 0.197724, Val Acc: 0.556701\n",
      "Epoch 5155 - Train Loss: 0.185192, Train Acc: 0.628205 | Val Loss: 0.197710, Val Acc: 0.556701\n",
      "Epoch 5156 - Train Loss: 0.185177, Train Acc: 0.628205 | Val Loss: 0.197695, Val Acc: 0.556701\n",
      "Epoch 5157 - Train Loss: 0.185163, Train Acc: 0.628205 | Val Loss: 0.197681, Val Acc: 0.556701\n",
      "Epoch 5158 - Train Loss: 0.185149, Train Acc: 0.628205 | Val Loss: 0.197667, Val Acc: 0.556701\n",
      "Epoch 5159 - Train Loss: 0.185135, Train Acc: 0.628205 | Val Loss: 0.197653, Val Acc: 0.556701\n",
      "Epoch 5160 - Train Loss: 0.185121, Train Acc: 0.628205 | Val Loss: 0.197639, Val Acc: 0.556701\n",
      "Epoch 5161 - Train Loss: 0.185106, Train Acc: 0.628205 | Val Loss: 0.197625, Val Acc: 0.556701\n",
      "Epoch 5162 - Train Loss: 0.185092, Train Acc: 0.628205 | Val Loss: 0.197611, Val Acc: 0.556701\n",
      "Epoch 5163 - Train Loss: 0.185078, Train Acc: 0.628205 | Val Loss: 0.197597, Val Acc: 0.556701\n",
      "Epoch 5164 - Train Loss: 0.185064, Train Acc: 0.628205 | Val Loss: 0.197583, Val Acc: 0.556701\n",
      "Epoch 5165 - Train Loss: 0.185050, Train Acc: 0.628205 | Val Loss: 0.197568, Val Acc: 0.556701\n",
      "Epoch 5166 - Train Loss: 0.185036, Train Acc: 0.628205 | Val Loss: 0.197554, Val Acc: 0.556701\n",
      "Epoch 5167 - Train Loss: 0.185021, Train Acc: 0.628205 | Val Loss: 0.197540, Val Acc: 0.556701\n",
      "Epoch 5168 - Train Loss: 0.185007, Train Acc: 0.628205 | Val Loss: 0.197526, Val Acc: 0.556701\n",
      "Epoch 5169 - Train Loss: 0.184993, Train Acc: 0.628205 | Val Loss: 0.197512, Val Acc: 0.556701\n",
      "Epoch 5170 - Train Loss: 0.184979, Train Acc: 0.628205 | Val Loss: 0.197498, Val Acc: 0.556701\n",
      "Epoch 5171 - Train Loss: 0.184965, Train Acc: 0.628205 | Val Loss: 0.197484, Val Acc: 0.556701\n",
      "Epoch 5172 - Train Loss: 0.184950, Train Acc: 0.628205 | Val Loss: 0.197470, Val Acc: 0.556701\n",
      "Epoch 5173 - Train Loss: 0.184936, Train Acc: 0.628205 | Val Loss: 0.197456, Val Acc: 0.556701\n",
      "Epoch 5174 - Train Loss: 0.184922, Train Acc: 0.628205 | Val Loss: 0.197441, Val Acc: 0.556701\n",
      "Epoch 5175 - Train Loss: 0.184908, Train Acc: 0.628205 | Val Loss: 0.197427, Val Acc: 0.556701\n",
      "Epoch 5176 - Train Loss: 0.184894, Train Acc: 0.628205 | Val Loss: 0.197413, Val Acc: 0.556701\n",
      "Epoch 5177 - Train Loss: 0.184879, Train Acc: 0.628205 | Val Loss: 0.197399, Val Acc: 0.556701\n",
      "Epoch 5178 - Train Loss: 0.184865, Train Acc: 0.628205 | Val Loss: 0.197385, Val Acc: 0.556701\n",
      "Epoch 5179 - Train Loss: 0.184851, Train Acc: 0.628205 | Val Loss: 0.197371, Val Acc: 0.556701\n",
      "Epoch 5180 - Train Loss: 0.184837, Train Acc: 0.628205 | Val Loss: 0.197357, Val Acc: 0.556701\n",
      "Epoch 5181 - Train Loss: 0.184823, Train Acc: 0.628205 | Val Loss: 0.197343, Val Acc: 0.556701\n",
      "Epoch 5182 - Train Loss: 0.184809, Train Acc: 0.628205 | Val Loss: 0.197329, Val Acc: 0.556701\n",
      "Epoch 5183 - Train Loss: 0.184794, Train Acc: 0.628205 | Val Loss: 0.197315, Val Acc: 0.556701\n",
      "Epoch 5184 - Train Loss: 0.184780, Train Acc: 0.628205 | Val Loss: 0.197300, Val Acc: 0.556701\n",
      "Epoch 5185 - Train Loss: 0.184766, Train Acc: 0.628205 | Val Loss: 0.197286, Val Acc: 0.556701\n",
      "Epoch 5186 - Train Loss: 0.184752, Train Acc: 0.628205 | Val Loss: 0.197272, Val Acc: 0.556701\n",
      "Epoch 5187 - Train Loss: 0.184738, Train Acc: 0.628205 | Val Loss: 0.197258, Val Acc: 0.556701\n",
      "Epoch 5188 - Train Loss: 0.184724, Train Acc: 0.628205 | Val Loss: 0.197244, Val Acc: 0.556701\n",
      "Epoch 5189 - Train Loss: 0.184709, Train Acc: 0.628205 | Val Loss: 0.197230, Val Acc: 0.556701\n",
      "Epoch 5190 - Train Loss: 0.184695, Train Acc: 0.628205 | Val Loss: 0.197216, Val Acc: 0.556701\n",
      "Epoch 5191 - Train Loss: 0.184681, Train Acc: 0.628205 | Val Loss: 0.197202, Val Acc: 0.556701\n",
      "Epoch 5192 - Train Loss: 0.184667, Train Acc: 0.628205 | Val Loss: 0.197188, Val Acc: 0.556701\n",
      "Epoch 5193 - Train Loss: 0.184653, Train Acc: 0.628205 | Val Loss: 0.197174, Val Acc: 0.556701\n",
      "Epoch 5194 - Train Loss: 0.184639, Train Acc: 0.628205 | Val Loss: 0.197159, Val Acc: 0.556701\n",
      "Epoch 5195 - Train Loss: 0.184625, Train Acc: 0.628205 | Val Loss: 0.197145, Val Acc: 0.556701\n",
      "Epoch 5196 - Train Loss: 0.184610, Train Acc: 0.628205 | Val Loss: 0.197131, Val Acc: 0.556701\n",
      "Epoch 5197 - Train Loss: 0.184596, Train Acc: 0.628205 | Val Loss: 0.197117, Val Acc: 0.556701\n",
      "Epoch 5198 - Train Loss: 0.184582, Train Acc: 0.628205 | Val Loss: 0.197103, Val Acc: 0.556701\n",
      "Epoch 5199 - Train Loss: 0.184568, Train Acc: 0.628205 | Val Loss: 0.197089, Val Acc: 0.556701\n",
      "Epoch 5200 - Train Loss: 0.184554, Train Acc: 0.628205 | Val Loss: 0.197075, Val Acc: 0.556701\n",
      "Epoch 5201 - Train Loss: 0.184540, Train Acc: 0.628205 | Val Loss: 0.197061, Val Acc: 0.556701\n",
      "Epoch 5202 - Train Loss: 0.184525, Train Acc: 0.628205 | Val Loss: 0.197047, Val Acc: 0.556701\n",
      "Epoch 5203 - Train Loss: 0.184511, Train Acc: 0.629487 | Val Loss: 0.197033, Val Acc: 0.556701\n",
      "Epoch 5204 - Train Loss: 0.184497, Train Acc: 0.629487 | Val Loss: 0.197019, Val Acc: 0.556701\n",
      "Epoch 5205 - Train Loss: 0.184483, Train Acc: 0.629487 | Val Loss: 0.197004, Val Acc: 0.556701\n",
      "Epoch 5206 - Train Loss: 0.184469, Train Acc: 0.629487 | Val Loss: 0.196990, Val Acc: 0.556701\n",
      "Epoch 5207 - Train Loss: 0.184455, Train Acc: 0.629487 | Val Loss: 0.196976, Val Acc: 0.556701\n",
      "Epoch 5208 - Train Loss: 0.184441, Train Acc: 0.629487 | Val Loss: 0.196963, Val Acc: 0.556701\n",
      "Epoch 5209 - Train Loss: 0.184427, Train Acc: 0.629487 | Val Loss: 0.196949, Val Acc: 0.556701\n",
      "Epoch 5210 - Train Loss: 0.184412, Train Acc: 0.629487 | Val Loss: 0.196935, Val Acc: 0.556701\n",
      "Epoch 5211 - Train Loss: 0.184398, Train Acc: 0.629487 | Val Loss: 0.196921, Val Acc: 0.556701\n",
      "Epoch 5212 - Train Loss: 0.184384, Train Acc: 0.629487 | Val Loss: 0.196907, Val Acc: 0.567010\n",
      "Epoch 5213 - Train Loss: 0.184370, Train Acc: 0.629487 | Val Loss: 0.196893, Val Acc: 0.567010\n",
      "Epoch 5214 - Train Loss: 0.184356, Train Acc: 0.629487 | Val Loss: 0.196879, Val Acc: 0.567010\n",
      "Epoch 5215 - Train Loss: 0.184342, Train Acc: 0.629487 | Val Loss: 0.196865, Val Acc: 0.567010\n",
      "Epoch 5216 - Train Loss: 0.184328, Train Acc: 0.629487 | Val Loss: 0.196851, Val Acc: 0.567010\n",
      "Epoch 5217 - Train Loss: 0.184314, Train Acc: 0.629487 | Val Loss: 0.196837, Val Acc: 0.567010\n",
      "Epoch 5218 - Train Loss: 0.184300, Train Acc: 0.629487 | Val Loss: 0.196823, Val Acc: 0.567010\n",
      "Epoch 5219 - Train Loss: 0.184285, Train Acc: 0.629487 | Val Loss: 0.196809, Val Acc: 0.567010\n",
      "Epoch 5220 - Train Loss: 0.184271, Train Acc: 0.629487 | Val Loss: 0.196795, Val Acc: 0.567010\n",
      "Epoch 5221 - Train Loss: 0.184257, Train Acc: 0.629487 | Val Loss: 0.196781, Val Acc: 0.567010\n",
      "Epoch 5222 - Train Loss: 0.184243, Train Acc: 0.629487 | Val Loss: 0.196767, Val Acc: 0.567010\n",
      "Epoch 5223 - Train Loss: 0.184229, Train Acc: 0.629487 | Val Loss: 0.196753, Val Acc: 0.567010\n",
      "Epoch 5224 - Train Loss: 0.184215, Train Acc: 0.629487 | Val Loss: 0.196739, Val Acc: 0.567010\n",
      "Epoch 5225 - Train Loss: 0.184201, Train Acc: 0.629487 | Val Loss: 0.196725, Val Acc: 0.567010\n",
      "Epoch 5226 - Train Loss: 0.184187, Train Acc: 0.629487 | Val Loss: 0.196711, Val Acc: 0.567010\n",
      "Epoch 5227 - Train Loss: 0.184173, Train Acc: 0.629487 | Val Loss: 0.196697, Val Acc: 0.567010\n",
      "Epoch 5228 - Train Loss: 0.184159, Train Acc: 0.629487 | Val Loss: 0.196683, Val Acc: 0.567010\n",
      "Epoch 5229 - Train Loss: 0.184145, Train Acc: 0.629487 | Val Loss: 0.196669, Val Acc: 0.567010\n",
      "Epoch 5230 - Train Loss: 0.184130, Train Acc: 0.629487 | Val Loss: 0.196655, Val Acc: 0.567010\n",
      "Epoch 5231 - Train Loss: 0.184116, Train Acc: 0.629487 | Val Loss: 0.196641, Val Acc: 0.567010\n",
      "Epoch 5232 - Train Loss: 0.184102, Train Acc: 0.629487 | Val Loss: 0.196627, Val Acc: 0.567010\n",
      "Epoch 5233 - Train Loss: 0.184088, Train Acc: 0.629487 | Val Loss: 0.196613, Val Acc: 0.567010\n",
      "Epoch 5234 - Train Loss: 0.184074, Train Acc: 0.629487 | Val Loss: 0.196599, Val Acc: 0.567010\n",
      "Epoch 5235 - Train Loss: 0.184060, Train Acc: 0.629487 | Val Loss: 0.196585, Val Acc: 0.567010\n",
      "Epoch 5236 - Train Loss: 0.184046, Train Acc: 0.629487 | Val Loss: 0.196571, Val Acc: 0.567010\n",
      "Epoch 5237 - Train Loss: 0.184032, Train Acc: 0.630769 | Val Loss: 0.196557, Val Acc: 0.567010\n",
      "Epoch 5238 - Train Loss: 0.184018, Train Acc: 0.630769 | Val Loss: 0.196543, Val Acc: 0.567010\n",
      "Epoch 5239 - Train Loss: 0.184004, Train Acc: 0.630769 | Val Loss: 0.196529, Val Acc: 0.567010\n",
      "Epoch 5240 - Train Loss: 0.183990, Train Acc: 0.630769 | Val Loss: 0.196515, Val Acc: 0.567010\n",
      "Epoch 5241 - Train Loss: 0.183976, Train Acc: 0.630769 | Val Loss: 0.196501, Val Acc: 0.567010\n",
      "Epoch 5242 - Train Loss: 0.183961, Train Acc: 0.630769 | Val Loss: 0.196487, Val Acc: 0.567010\n",
      "Epoch 5243 - Train Loss: 0.183947, Train Acc: 0.630769 | Val Loss: 0.196473, Val Acc: 0.567010\n",
      "Epoch 5244 - Train Loss: 0.183933, Train Acc: 0.630769 | Val Loss: 0.196459, Val Acc: 0.567010\n",
      "Epoch 5245 - Train Loss: 0.183919, Train Acc: 0.630769 | Val Loss: 0.196445, Val Acc: 0.567010\n",
      "Epoch 5246 - Train Loss: 0.183905, Train Acc: 0.630769 | Val Loss: 0.196431, Val Acc: 0.567010\n",
      "Epoch 5247 - Train Loss: 0.183891, Train Acc: 0.630769 | Val Loss: 0.196417, Val Acc: 0.567010\n",
      "Epoch 5248 - Train Loss: 0.183877, Train Acc: 0.630769 | Val Loss: 0.196403, Val Acc: 0.567010\n",
      "Epoch 5249 - Train Loss: 0.183863, Train Acc: 0.630769 | Val Loss: 0.196389, Val Acc: 0.567010\n",
      "Epoch 5250 - Train Loss: 0.183849, Train Acc: 0.630769 | Val Loss: 0.196375, Val Acc: 0.567010\n",
      "Epoch 5251 - Train Loss: 0.183835, Train Acc: 0.630769 | Val Loss: 0.196361, Val Acc: 0.567010\n",
      "Epoch 5252 - Train Loss: 0.183821, Train Acc: 0.630769 | Val Loss: 0.196347, Val Acc: 0.567010\n",
      "Epoch 5253 - Train Loss: 0.183807, Train Acc: 0.630769 | Val Loss: 0.196333, Val Acc: 0.567010\n",
      "Epoch 5254 - Train Loss: 0.183793, Train Acc: 0.630769 | Val Loss: 0.196319, Val Acc: 0.567010\n",
      "Epoch 5255 - Train Loss: 0.183779, Train Acc: 0.630769 | Val Loss: 0.196305, Val Acc: 0.567010\n",
      "Epoch 5256 - Train Loss: 0.183765, Train Acc: 0.630769 | Val Loss: 0.196291, Val Acc: 0.567010\n",
      "Epoch 5257 - Train Loss: 0.183751, Train Acc: 0.630769 | Val Loss: 0.196277, Val Acc: 0.567010\n",
      "Epoch 5258 - Train Loss: 0.183736, Train Acc: 0.630769 | Val Loss: 0.196263, Val Acc: 0.567010\n",
      "Epoch 5259 - Train Loss: 0.183722, Train Acc: 0.630769 | Val Loss: 0.196249, Val Acc: 0.567010\n",
      "Epoch 5260 - Train Loss: 0.183708, Train Acc: 0.630769 | Val Loss: 0.196235, Val Acc: 0.567010\n",
      "Epoch 5261 - Train Loss: 0.183694, Train Acc: 0.630769 | Val Loss: 0.196221, Val Acc: 0.567010\n",
      "Epoch 5262 - Train Loss: 0.183680, Train Acc: 0.630769 | Val Loss: 0.196207, Val Acc: 0.567010\n",
      "Epoch 5263 - Train Loss: 0.183666, Train Acc: 0.630769 | Val Loss: 0.196193, Val Acc: 0.567010\n",
      "Epoch 5264 - Train Loss: 0.183652, Train Acc: 0.630769 | Val Loss: 0.196179, Val Acc: 0.567010\n",
      "Epoch 5265 - Train Loss: 0.183638, Train Acc: 0.630769 | Val Loss: 0.196165, Val Acc: 0.567010\n",
      "Epoch 5266 - Train Loss: 0.183624, Train Acc: 0.630769 | Val Loss: 0.196152, Val Acc: 0.567010\n",
      "Epoch 5267 - Train Loss: 0.183610, Train Acc: 0.630769 | Val Loss: 0.196138, Val Acc: 0.567010\n",
      "Epoch 5268 - Train Loss: 0.183596, Train Acc: 0.630769 | Val Loss: 0.196124, Val Acc: 0.567010\n",
      "Epoch 5269 - Train Loss: 0.183582, Train Acc: 0.630769 | Val Loss: 0.196110, Val Acc: 0.567010\n",
      "Epoch 5270 - Train Loss: 0.183568, Train Acc: 0.630769 | Val Loss: 0.196096, Val Acc: 0.567010\n",
      "Epoch 5271 - Train Loss: 0.183554, Train Acc: 0.630769 | Val Loss: 0.196082, Val Acc: 0.567010\n",
      "Epoch 5272 - Train Loss: 0.183540, Train Acc: 0.630769 | Val Loss: 0.196068, Val Acc: 0.567010\n",
      "Epoch 5273 - Train Loss: 0.183526, Train Acc: 0.630769 | Val Loss: 0.196054, Val Acc: 0.567010\n",
      "Epoch 5274 - Train Loss: 0.183512, Train Acc: 0.630769 | Val Loss: 0.196040, Val Acc: 0.567010\n",
      "Epoch 5275 - Train Loss: 0.183498, Train Acc: 0.630769 | Val Loss: 0.196026, Val Acc: 0.567010\n",
      "Epoch 5276 - Train Loss: 0.183484, Train Acc: 0.630769 | Val Loss: 0.196012, Val Acc: 0.567010\n",
      "Epoch 5277 - Train Loss: 0.183470, Train Acc: 0.630769 | Val Loss: 0.195998, Val Acc: 0.567010\n",
      "Epoch 5278 - Train Loss: 0.183456, Train Acc: 0.630769 | Val Loss: 0.195984, Val Acc: 0.567010\n",
      "Epoch 5279 - Train Loss: 0.183442, Train Acc: 0.630769 | Val Loss: 0.195970, Val Acc: 0.567010\n",
      "Epoch 5280 - Train Loss: 0.183428, Train Acc: 0.630769 | Val Loss: 0.195956, Val Acc: 0.567010\n",
      "Epoch 5281 - Train Loss: 0.183414, Train Acc: 0.630769 | Val Loss: 0.195942, Val Acc: 0.567010\n",
      "Epoch 5282 - Train Loss: 0.183400, Train Acc: 0.630769 | Val Loss: 0.195928, Val Acc: 0.567010\n",
      "Epoch 5283 - Train Loss: 0.183386, Train Acc: 0.630769 | Val Loss: 0.195914, Val Acc: 0.567010\n",
      "Epoch 5284 - Train Loss: 0.183372, Train Acc: 0.630769 | Val Loss: 0.195900, Val Acc: 0.567010\n",
      "Epoch 5285 - Train Loss: 0.183357, Train Acc: 0.630769 | Val Loss: 0.195886, Val Acc: 0.567010\n",
      "Epoch 5286 - Train Loss: 0.183343, Train Acc: 0.630769 | Val Loss: 0.195872, Val Acc: 0.567010\n",
      "Epoch 5287 - Train Loss: 0.183329, Train Acc: 0.630769 | Val Loss: 0.195859, Val Acc: 0.567010\n",
      "Epoch 5288 - Train Loss: 0.183315, Train Acc: 0.630769 | Val Loss: 0.195845, Val Acc: 0.567010\n",
      "Epoch 5289 - Train Loss: 0.183301, Train Acc: 0.630769 | Val Loss: 0.195831, Val Acc: 0.567010\n",
      "Epoch 5290 - Train Loss: 0.183287, Train Acc: 0.630769 | Val Loss: 0.195817, Val Acc: 0.567010\n",
      "Epoch 5291 - Train Loss: 0.183273, Train Acc: 0.630769 | Val Loss: 0.195803, Val Acc: 0.567010\n",
      "Epoch 5292 - Train Loss: 0.183259, Train Acc: 0.630769 | Val Loss: 0.195789, Val Acc: 0.567010\n",
      "Epoch 5293 - Train Loss: 0.183245, Train Acc: 0.630769 | Val Loss: 0.195775, Val Acc: 0.567010\n",
      "Epoch 5294 - Train Loss: 0.183231, Train Acc: 0.630769 | Val Loss: 0.195761, Val Acc: 0.567010\n",
      "Epoch 5295 - Train Loss: 0.183217, Train Acc: 0.630769 | Val Loss: 0.195747, Val Acc: 0.567010\n",
      "Epoch 5296 - Train Loss: 0.183203, Train Acc: 0.630769 | Val Loss: 0.195733, Val Acc: 0.567010\n",
      "Epoch 5297 - Train Loss: 0.183189, Train Acc: 0.630769 | Val Loss: 0.195719, Val Acc: 0.567010\n",
      "Epoch 5298 - Train Loss: 0.183175, Train Acc: 0.630769 | Val Loss: 0.195705, Val Acc: 0.567010\n",
      "Epoch 5299 - Train Loss: 0.183161, Train Acc: 0.630769 | Val Loss: 0.195691, Val Acc: 0.567010\n",
      "Epoch 5300 - Train Loss: 0.183147, Train Acc: 0.630769 | Val Loss: 0.195677, Val Acc: 0.567010\n",
      "Epoch 5301 - Train Loss: 0.183133, Train Acc: 0.630769 | Val Loss: 0.195663, Val Acc: 0.567010\n",
      "Epoch 5302 - Train Loss: 0.183119, Train Acc: 0.630769 | Val Loss: 0.195650, Val Acc: 0.567010\n",
      "Epoch 5303 - Train Loss: 0.183105, Train Acc: 0.630769 | Val Loss: 0.195636, Val Acc: 0.567010\n",
      "Epoch 5304 - Train Loss: 0.183091, Train Acc: 0.630769 | Val Loss: 0.195622, Val Acc: 0.567010\n",
      "Epoch 5305 - Train Loss: 0.183077, Train Acc: 0.630769 | Val Loss: 0.195608, Val Acc: 0.567010\n",
      "Epoch 5306 - Train Loss: 0.183063, Train Acc: 0.630769 | Val Loss: 0.195594, Val Acc: 0.567010\n",
      "Epoch 5307 - Train Loss: 0.183049, Train Acc: 0.630769 | Val Loss: 0.195580, Val Acc: 0.567010\n",
      "Epoch 5308 - Train Loss: 0.183035, Train Acc: 0.630769 | Val Loss: 0.195566, Val Acc: 0.567010\n",
      "Epoch 5309 - Train Loss: 0.183021, Train Acc: 0.630769 | Val Loss: 0.195552, Val Acc: 0.567010\n",
      "Epoch 5310 - Train Loss: 0.183007, Train Acc: 0.630769 | Val Loss: 0.195538, Val Acc: 0.567010\n",
      "Epoch 5311 - Train Loss: 0.182993, Train Acc: 0.630769 | Val Loss: 0.195524, Val Acc: 0.567010\n",
      "Epoch 5312 - Train Loss: 0.182979, Train Acc: 0.630769 | Val Loss: 0.195510, Val Acc: 0.567010\n",
      "Epoch 5313 - Train Loss: 0.182965, Train Acc: 0.630769 | Val Loss: 0.195497, Val Acc: 0.567010\n",
      "Epoch 5314 - Train Loss: 0.182951, Train Acc: 0.630769 | Val Loss: 0.195483, Val Acc: 0.567010\n",
      "Epoch 5315 - Train Loss: 0.182937, Train Acc: 0.630769 | Val Loss: 0.195469, Val Acc: 0.567010\n",
      "Epoch 5316 - Train Loss: 0.182923, Train Acc: 0.630769 | Val Loss: 0.195455, Val Acc: 0.567010\n",
      "Epoch 5317 - Train Loss: 0.182909, Train Acc: 0.630769 | Val Loss: 0.195441, Val Acc: 0.567010\n",
      "Epoch 5318 - Train Loss: 0.182895, Train Acc: 0.630769 | Val Loss: 0.195427, Val Acc: 0.567010\n",
      "Epoch 5319 - Train Loss: 0.182881, Train Acc: 0.630769 | Val Loss: 0.195413, Val Acc: 0.567010\n",
      "Epoch 5320 - Train Loss: 0.182867, Train Acc: 0.630769 | Val Loss: 0.195399, Val Acc: 0.567010\n",
      "Epoch 5321 - Train Loss: 0.182853, Train Acc: 0.630769 | Val Loss: 0.195385, Val Acc: 0.567010\n",
      "Epoch 5322 - Train Loss: 0.182840, Train Acc: 0.630769 | Val Loss: 0.195371, Val Acc: 0.567010\n",
      "Epoch 5323 - Train Loss: 0.182826, Train Acc: 0.630769 | Val Loss: 0.195358, Val Acc: 0.567010\n",
      "Epoch 5324 - Train Loss: 0.182812, Train Acc: 0.630769 | Val Loss: 0.195344, Val Acc: 0.567010\n",
      "Epoch 5325 - Train Loss: 0.182798, Train Acc: 0.630769 | Val Loss: 0.195330, Val Acc: 0.567010\n",
      "Epoch 5326 - Train Loss: 0.182784, Train Acc: 0.630769 | Val Loss: 0.195316, Val Acc: 0.567010\n",
      "Epoch 5327 - Train Loss: 0.182770, Train Acc: 0.630769 | Val Loss: 0.195302, Val Acc: 0.567010\n",
      "Epoch 5328 - Train Loss: 0.182756, Train Acc: 0.630769 | Val Loss: 0.195288, Val Acc: 0.567010\n",
      "Epoch 5329 - Train Loss: 0.182742, Train Acc: 0.630769 | Val Loss: 0.195274, Val Acc: 0.567010\n",
      "Epoch 5330 - Train Loss: 0.182728, Train Acc: 0.630769 | Val Loss: 0.195260, Val Acc: 0.567010\n",
      "Epoch 5331 - Train Loss: 0.182714, Train Acc: 0.630769 | Val Loss: 0.195246, Val Acc: 0.567010\n",
      "Epoch 5332 - Train Loss: 0.182700, Train Acc: 0.630769 | Val Loss: 0.195233, Val Acc: 0.567010\n",
      "Epoch 5333 - Train Loss: 0.182686, Train Acc: 0.630769 | Val Loss: 0.195219, Val Acc: 0.567010\n",
      "Epoch 5334 - Train Loss: 0.182672, Train Acc: 0.630769 | Val Loss: 0.195205, Val Acc: 0.567010\n",
      "Epoch 5335 - Train Loss: 0.182658, Train Acc: 0.630769 | Val Loss: 0.195191, Val Acc: 0.567010\n",
      "Epoch 5336 - Train Loss: 0.182644, Train Acc: 0.630769 | Val Loss: 0.195177, Val Acc: 0.567010\n",
      "Epoch 5337 - Train Loss: 0.182630, Train Acc: 0.630769 | Val Loss: 0.195163, Val Acc: 0.567010\n",
      "Epoch 5338 - Train Loss: 0.182616, Train Acc: 0.630769 | Val Loss: 0.195149, Val Acc: 0.567010\n",
      "Epoch 5339 - Train Loss: 0.182602, Train Acc: 0.630769 | Val Loss: 0.195135, Val Acc: 0.567010\n",
      "Epoch 5340 - Train Loss: 0.182588, Train Acc: 0.630769 | Val Loss: 0.195122, Val Acc: 0.567010\n",
      "Epoch 5341 - Train Loss: 0.182574, Train Acc: 0.630769 | Val Loss: 0.195108, Val Acc: 0.567010\n",
      "Epoch 5342 - Train Loss: 0.182560, Train Acc: 0.630769 | Val Loss: 0.195094, Val Acc: 0.567010\n",
      "Epoch 5343 - Train Loss: 0.182546, Train Acc: 0.630769 | Val Loss: 0.195080, Val Acc: 0.567010\n",
      "Epoch 5344 - Train Loss: 0.182532, Train Acc: 0.630769 | Val Loss: 0.195066, Val Acc: 0.567010\n",
      "Epoch 5345 - Train Loss: 0.182518, Train Acc: 0.630769 | Val Loss: 0.195052, Val Acc: 0.567010\n",
      "Epoch 5346 - Train Loss: 0.182504, Train Acc: 0.630769 | Val Loss: 0.195038, Val Acc: 0.567010\n",
      "Epoch 5347 - Train Loss: 0.182490, Train Acc: 0.630769 | Val Loss: 0.195024, Val Acc: 0.567010\n",
      "Epoch 5348 - Train Loss: 0.182476, Train Acc: 0.630769 | Val Loss: 0.195011, Val Acc: 0.567010\n",
      "Epoch 5349 - Train Loss: 0.182463, Train Acc: 0.630769 | Val Loss: 0.194997, Val Acc: 0.567010\n",
      "Epoch 5350 - Train Loss: 0.182449, Train Acc: 0.630769 | Val Loss: 0.194983, Val Acc: 0.567010\n",
      "Epoch 5351 - Train Loss: 0.182435, Train Acc: 0.630769 | Val Loss: 0.194969, Val Acc: 0.567010\n",
      "Epoch 5352 - Train Loss: 0.182421, Train Acc: 0.630769 | Val Loss: 0.194955, Val Acc: 0.567010\n",
      "Epoch 5353 - Train Loss: 0.182407, Train Acc: 0.630769 | Val Loss: 0.194941, Val Acc: 0.567010\n",
      "Epoch 5354 - Train Loss: 0.182393, Train Acc: 0.630769 | Val Loss: 0.194927, Val Acc: 0.567010\n",
      "Epoch 5355 - Train Loss: 0.182379, Train Acc: 0.630769 | Val Loss: 0.194914, Val Acc: 0.567010\n",
      "Epoch 5356 - Train Loss: 0.182365, Train Acc: 0.630769 | Val Loss: 0.194900, Val Acc: 0.567010\n",
      "Epoch 5357 - Train Loss: 0.182351, Train Acc: 0.630769 | Val Loss: 0.194886, Val Acc: 0.567010\n",
      "Epoch 5358 - Train Loss: 0.182337, Train Acc: 0.630769 | Val Loss: 0.194872, Val Acc: 0.567010\n",
      "Epoch 5359 - Train Loss: 0.182323, Train Acc: 0.630769 | Val Loss: 0.194858, Val Acc: 0.567010\n",
      "Epoch 5360 - Train Loss: 0.182309, Train Acc: 0.630769 | Val Loss: 0.194844, Val Acc: 0.567010\n",
      "Epoch 5361 - Train Loss: 0.182295, Train Acc: 0.630769 | Val Loss: 0.194831, Val Acc: 0.567010\n",
      "Epoch 5362 - Train Loss: 0.182281, Train Acc: 0.630769 | Val Loss: 0.194817, Val Acc: 0.567010\n",
      "Epoch 5363 - Train Loss: 0.182267, Train Acc: 0.630769 | Val Loss: 0.194803, Val Acc: 0.567010\n",
      "Epoch 5364 - Train Loss: 0.182253, Train Acc: 0.630769 | Val Loss: 0.194789, Val Acc: 0.567010\n",
      "Epoch 5365 - Train Loss: 0.182240, Train Acc: 0.630769 | Val Loss: 0.194775, Val Acc: 0.567010\n",
      "Epoch 5366 - Train Loss: 0.182226, Train Acc: 0.630769 | Val Loss: 0.194761, Val Acc: 0.567010\n",
      "Epoch 5367 - Train Loss: 0.182212, Train Acc: 0.630769 | Val Loss: 0.194748, Val Acc: 0.567010\n",
      "Epoch 5368 - Train Loss: 0.182198, Train Acc: 0.630769 | Val Loss: 0.194734, Val Acc: 0.567010\n",
      "Epoch 5369 - Train Loss: 0.182184, Train Acc: 0.630769 | Val Loss: 0.194720, Val Acc: 0.567010\n",
      "Epoch 5370 - Train Loss: 0.182170, Train Acc: 0.630769 | Val Loss: 0.194706, Val Acc: 0.567010\n",
      "Epoch 5371 - Train Loss: 0.182156, Train Acc: 0.630769 | Val Loss: 0.194692, Val Acc: 0.567010\n",
      "Epoch 5372 - Train Loss: 0.182142, Train Acc: 0.630769 | Val Loss: 0.194678, Val Acc: 0.567010\n",
      "Epoch 5373 - Train Loss: 0.182128, Train Acc: 0.630769 | Val Loss: 0.194665, Val Acc: 0.567010\n",
      "Epoch 5374 - Train Loss: 0.182114, Train Acc: 0.630769 | Val Loss: 0.194651, Val Acc: 0.567010\n",
      "Epoch 5375 - Train Loss: 0.182100, Train Acc: 0.630769 | Val Loss: 0.194637, Val Acc: 0.567010\n",
      "Epoch 5376 - Train Loss: 0.182086, Train Acc: 0.630769 | Val Loss: 0.194623, Val Acc: 0.567010\n",
      "Epoch 5377 - Train Loss: 0.182072, Train Acc: 0.630769 | Val Loss: 0.194609, Val Acc: 0.567010\n",
      "Epoch 5378 - Train Loss: 0.182059, Train Acc: 0.630769 | Val Loss: 0.194595, Val Acc: 0.567010\n",
      "Epoch 5379 - Train Loss: 0.182045, Train Acc: 0.630769 | Val Loss: 0.194582, Val Acc: 0.567010\n",
      "Epoch 5380 - Train Loss: 0.182031, Train Acc: 0.632051 | Val Loss: 0.194568, Val Acc: 0.567010\n",
      "Epoch 5381 - Train Loss: 0.182017, Train Acc: 0.632051 | Val Loss: 0.194554, Val Acc: 0.567010\n",
      "Epoch 5382 - Train Loss: 0.182003, Train Acc: 0.632051 | Val Loss: 0.194540, Val Acc: 0.567010\n",
      "Epoch 5383 - Train Loss: 0.181989, Train Acc: 0.632051 | Val Loss: 0.194526, Val Acc: 0.567010\n",
      "Epoch 5384 - Train Loss: 0.181975, Train Acc: 0.632051 | Val Loss: 0.194513, Val Acc: 0.567010\n",
      "Epoch 5385 - Train Loss: 0.181961, Train Acc: 0.632051 | Val Loss: 0.194499, Val Acc: 0.567010\n",
      "Epoch 5386 - Train Loss: 0.181947, Train Acc: 0.632051 | Val Loss: 0.194485, Val Acc: 0.567010\n",
      "Epoch 5387 - Train Loss: 0.181933, Train Acc: 0.633333 | Val Loss: 0.194471, Val Acc: 0.567010\n",
      "Epoch 5388 - Train Loss: 0.181920, Train Acc: 0.633333 | Val Loss: 0.194457, Val Acc: 0.567010\n",
      "Epoch 5389 - Train Loss: 0.181906, Train Acc: 0.633333 | Val Loss: 0.194444, Val Acc: 0.567010\n",
      "Epoch 5390 - Train Loss: 0.181892, Train Acc: 0.633333 | Val Loss: 0.194430, Val Acc: 0.567010\n",
      "Epoch 5391 - Train Loss: 0.181878, Train Acc: 0.633333 | Val Loss: 0.194416, Val Acc: 0.567010\n",
      "Epoch 5392 - Train Loss: 0.181864, Train Acc: 0.633333 | Val Loss: 0.194402, Val Acc: 0.567010\n",
      "Epoch 5393 - Train Loss: 0.181850, Train Acc: 0.633333 | Val Loss: 0.194388, Val Acc: 0.567010\n",
      "Epoch 5394 - Train Loss: 0.181836, Train Acc: 0.634615 | Val Loss: 0.194375, Val Acc: 0.567010\n",
      "Epoch 5395 - Train Loss: 0.181822, Train Acc: 0.634615 | Val Loss: 0.194361, Val Acc: 0.567010\n",
      "Epoch 5396 - Train Loss: 0.181808, Train Acc: 0.634615 | Val Loss: 0.194347, Val Acc: 0.567010\n",
      "Epoch 5397 - Train Loss: 0.181794, Train Acc: 0.635897 | Val Loss: 0.194333, Val Acc: 0.567010\n",
      "Epoch 5398 - Train Loss: 0.181781, Train Acc: 0.635897 | Val Loss: 0.194320, Val Acc: 0.567010\n",
      "Epoch 5399 - Train Loss: 0.181767, Train Acc: 0.635897 | Val Loss: 0.194306, Val Acc: 0.567010\n",
      "Epoch 5400 - Train Loss: 0.181753, Train Acc: 0.635897 | Val Loss: 0.194292, Val Acc: 0.567010\n",
      "Epoch 5401 - Train Loss: 0.181739, Train Acc: 0.635897 | Val Loss: 0.194279, Val Acc: 0.567010\n",
      "Epoch 5402 - Train Loss: 0.181725, Train Acc: 0.635897 | Val Loss: 0.194265, Val Acc: 0.567010\n",
      "Epoch 5403 - Train Loss: 0.181711, Train Acc: 0.635897 | Val Loss: 0.194251, Val Acc: 0.567010\n",
      "Epoch 5404 - Train Loss: 0.181697, Train Acc: 0.635897 | Val Loss: 0.194237, Val Acc: 0.567010\n",
      "Epoch 5405 - Train Loss: 0.181683, Train Acc: 0.635897 | Val Loss: 0.194224, Val Acc: 0.567010\n",
      "Epoch 5406 - Train Loss: 0.181669, Train Acc: 0.635897 | Val Loss: 0.194210, Val Acc: 0.567010\n",
      "Epoch 5407 - Train Loss: 0.181656, Train Acc: 0.635897 | Val Loss: 0.194196, Val Acc: 0.567010\n",
      "Epoch 5408 - Train Loss: 0.181642, Train Acc: 0.635897 | Val Loss: 0.194183, Val Acc: 0.567010\n",
      "Epoch 5409 - Train Loss: 0.181628, Train Acc: 0.635897 | Val Loss: 0.194169, Val Acc: 0.567010\n",
      "Epoch 5410 - Train Loss: 0.181614, Train Acc: 0.635897 | Val Loss: 0.194155, Val Acc: 0.567010\n",
      "Epoch 5411 - Train Loss: 0.181600, Train Acc: 0.635897 | Val Loss: 0.194141, Val Acc: 0.567010\n",
      "Epoch 5412 - Train Loss: 0.181586, Train Acc: 0.635897 | Val Loss: 0.194128, Val Acc: 0.567010\n",
      "Epoch 5413 - Train Loss: 0.181572, Train Acc: 0.635897 | Val Loss: 0.194114, Val Acc: 0.567010\n",
      "Epoch 5414 - Train Loss: 0.181558, Train Acc: 0.635897 | Val Loss: 0.194100, Val Acc: 0.567010\n",
      "Epoch 5415 - Train Loss: 0.181545, Train Acc: 0.635897 | Val Loss: 0.194087, Val Acc: 0.567010\n",
      "Epoch 5416 - Train Loss: 0.181531, Train Acc: 0.635897 | Val Loss: 0.194073, Val Acc: 0.567010\n",
      "Epoch 5417 - Train Loss: 0.181517, Train Acc: 0.635897 | Val Loss: 0.194059, Val Acc: 0.567010\n",
      "Epoch 5418 - Train Loss: 0.181503, Train Acc: 0.635897 | Val Loss: 0.194045, Val Acc: 0.567010\n",
      "Epoch 5419 - Train Loss: 0.181489, Train Acc: 0.635897 | Val Loss: 0.194032, Val Acc: 0.567010\n",
      "Epoch 5420 - Train Loss: 0.181475, Train Acc: 0.635897 | Val Loss: 0.194018, Val Acc: 0.567010\n",
      "Epoch 5421 - Train Loss: 0.181461, Train Acc: 0.635897 | Val Loss: 0.194004, Val Acc: 0.567010\n",
      "Epoch 5422 - Train Loss: 0.181448, Train Acc: 0.635897 | Val Loss: 0.193991, Val Acc: 0.567010\n",
      "Epoch 5423 - Train Loss: 0.181434, Train Acc: 0.637179 | Val Loss: 0.193977, Val Acc: 0.567010\n",
      "Epoch 5424 - Train Loss: 0.181420, Train Acc: 0.637179 | Val Loss: 0.193963, Val Acc: 0.567010\n",
      "Epoch 5425 - Train Loss: 0.181406, Train Acc: 0.637179 | Val Loss: 0.193950, Val Acc: 0.567010\n",
      "Epoch 5426 - Train Loss: 0.181392, Train Acc: 0.638462 | Val Loss: 0.193936, Val Acc: 0.567010\n",
      "Epoch 5427 - Train Loss: 0.181378, Train Acc: 0.638462 | Val Loss: 0.193922, Val Acc: 0.567010\n",
      "Epoch 5428 - Train Loss: 0.181364, Train Acc: 0.638462 | Val Loss: 0.193908, Val Acc: 0.567010\n",
      "Epoch 5429 - Train Loss: 0.181351, Train Acc: 0.638462 | Val Loss: 0.193895, Val Acc: 0.567010\n",
      "Epoch 5430 - Train Loss: 0.181337, Train Acc: 0.638462 | Val Loss: 0.193881, Val Acc: 0.567010\n",
      "Epoch 5431 - Train Loss: 0.181323, Train Acc: 0.638462 | Val Loss: 0.193867, Val Acc: 0.567010\n",
      "Epoch 5432 - Train Loss: 0.181309, Train Acc: 0.638462 | Val Loss: 0.193854, Val Acc: 0.567010\n",
      "Epoch 5433 - Train Loss: 0.181295, Train Acc: 0.638462 | Val Loss: 0.193840, Val Acc: 0.567010\n",
      "Epoch 5434 - Train Loss: 0.181281, Train Acc: 0.638462 | Val Loss: 0.193826, Val Acc: 0.567010\n",
      "Epoch 5435 - Train Loss: 0.181267, Train Acc: 0.638462 | Val Loss: 0.193813, Val Acc: 0.567010\n",
      "Epoch 5436 - Train Loss: 0.181254, Train Acc: 0.638462 | Val Loss: 0.193799, Val Acc: 0.567010\n",
      "Epoch 5437 - Train Loss: 0.181240, Train Acc: 0.638462 | Val Loss: 0.193785, Val Acc: 0.567010\n",
      "Epoch 5438 - Train Loss: 0.181226, Train Acc: 0.638462 | Val Loss: 0.193771, Val Acc: 0.567010\n",
      "Epoch 5439 - Train Loss: 0.181212, Train Acc: 0.638462 | Val Loss: 0.193758, Val Acc: 0.567010\n",
      "Epoch 5440 - Train Loss: 0.181198, Train Acc: 0.638462 | Val Loss: 0.193744, Val Acc: 0.567010\n",
      "Epoch 5441 - Train Loss: 0.181184, Train Acc: 0.638462 | Val Loss: 0.193730, Val Acc: 0.567010\n",
      "Epoch 5442 - Train Loss: 0.181170, Train Acc: 0.638462 | Val Loss: 0.193717, Val Acc: 0.567010\n",
      "Epoch 5443 - Train Loss: 0.181157, Train Acc: 0.638462 | Val Loss: 0.193703, Val Acc: 0.567010\n",
      "Epoch 5444 - Train Loss: 0.181143, Train Acc: 0.638462 | Val Loss: 0.193689, Val Acc: 0.567010\n",
      "Epoch 5445 - Train Loss: 0.181129, Train Acc: 0.639744 | Val Loss: 0.193675, Val Acc: 0.567010\n",
      "Epoch 5446 - Train Loss: 0.181115, Train Acc: 0.639744 | Val Loss: 0.193662, Val Acc: 0.567010\n",
      "Epoch 5447 - Train Loss: 0.181101, Train Acc: 0.639744 | Val Loss: 0.193648, Val Acc: 0.567010\n",
      "Epoch 5448 - Train Loss: 0.181087, Train Acc: 0.639744 | Val Loss: 0.193634, Val Acc: 0.567010\n",
      "Epoch 5449 - Train Loss: 0.181074, Train Acc: 0.639744 | Val Loss: 0.193621, Val Acc: 0.567010\n",
      "Epoch 5450 - Train Loss: 0.181060, Train Acc: 0.639744 | Val Loss: 0.193607, Val Acc: 0.567010\n",
      "Epoch 5451 - Train Loss: 0.181046, Train Acc: 0.639744 | Val Loss: 0.193593, Val Acc: 0.567010\n",
      "Epoch 5452 - Train Loss: 0.181032, Train Acc: 0.639744 | Val Loss: 0.193579, Val Acc: 0.567010\n",
      "Epoch 5453 - Train Loss: 0.181018, Train Acc: 0.639744 | Val Loss: 0.193566, Val Acc: 0.567010\n",
      "Epoch 5454 - Train Loss: 0.181005, Train Acc: 0.639744 | Val Loss: 0.193552, Val Acc: 0.567010\n",
      "Epoch 5455 - Train Loss: 0.180991, Train Acc: 0.639744 | Val Loss: 0.193538, Val Acc: 0.567010\n",
      "Epoch 5456 - Train Loss: 0.180977, Train Acc: 0.639744 | Val Loss: 0.193525, Val Acc: 0.567010\n",
      "Epoch 5457 - Train Loss: 0.180963, Train Acc: 0.639744 | Val Loss: 0.193511, Val Acc: 0.556701\n",
      "Epoch 5458 - Train Loss: 0.180949, Train Acc: 0.639744 | Val Loss: 0.193497, Val Acc: 0.556701\n",
      "Epoch 5459 - Train Loss: 0.180935, Train Acc: 0.639744 | Val Loss: 0.193483, Val Acc: 0.556701\n",
      "Epoch 5460 - Train Loss: 0.180922, Train Acc: 0.639744 | Val Loss: 0.193470, Val Acc: 0.556701\n",
      "Epoch 5461 - Train Loss: 0.180908, Train Acc: 0.639744 | Val Loss: 0.193456, Val Acc: 0.556701\n",
      "Epoch 5462 - Train Loss: 0.180894, Train Acc: 0.638462 | Val Loss: 0.193442, Val Acc: 0.556701\n",
      "Epoch 5463 - Train Loss: 0.180880, Train Acc: 0.638462 | Val Loss: 0.193429, Val Acc: 0.556701\n",
      "Epoch 5464 - Train Loss: 0.180866, Train Acc: 0.638462 | Val Loss: 0.193415, Val Acc: 0.556701\n",
      "Epoch 5465 - Train Loss: 0.180853, Train Acc: 0.638462 | Val Loss: 0.193401, Val Acc: 0.556701\n",
      "Epoch 5466 - Train Loss: 0.180839, Train Acc: 0.638462 | Val Loss: 0.193387, Val Acc: 0.556701\n",
      "Epoch 5467 - Train Loss: 0.180825, Train Acc: 0.638462 | Val Loss: 0.193374, Val Acc: 0.556701\n",
      "Epoch 5468 - Train Loss: 0.180811, Train Acc: 0.638462 | Val Loss: 0.193360, Val Acc: 0.556701\n",
      "Epoch 5469 - Train Loss: 0.180797, Train Acc: 0.638462 | Val Loss: 0.193346, Val Acc: 0.556701\n",
      "Epoch 5470 - Train Loss: 0.180783, Train Acc: 0.638462 | Val Loss: 0.193333, Val Acc: 0.556701\n",
      "Epoch 5471 - Train Loss: 0.180770, Train Acc: 0.638462 | Val Loss: 0.193319, Val Acc: 0.556701\n",
      "Epoch 5472 - Train Loss: 0.180756, Train Acc: 0.638462 | Val Loss: 0.193305, Val Acc: 0.556701\n",
      "Epoch 5473 - Train Loss: 0.180742, Train Acc: 0.638462 | Val Loss: 0.193292, Val Acc: 0.556701\n",
      "Epoch 5474 - Train Loss: 0.180728, Train Acc: 0.638462 | Val Loss: 0.193278, Val Acc: 0.556701\n",
      "Epoch 5475 - Train Loss: 0.180714, Train Acc: 0.638462 | Val Loss: 0.193264, Val Acc: 0.556701\n",
      "Epoch 5476 - Train Loss: 0.180701, Train Acc: 0.638462 | Val Loss: 0.193251, Val Acc: 0.556701\n",
      "Epoch 5477 - Train Loss: 0.180687, Train Acc: 0.638462 | Val Loss: 0.193237, Val Acc: 0.556701\n",
      "Epoch 5478 - Train Loss: 0.180673, Train Acc: 0.638462 | Val Loss: 0.193223, Val Acc: 0.556701\n",
      "Epoch 5479 - Train Loss: 0.180659, Train Acc: 0.638462 | Val Loss: 0.193209, Val Acc: 0.556701\n",
      "Epoch 5480 - Train Loss: 0.180645, Train Acc: 0.638462 | Val Loss: 0.193196, Val Acc: 0.556701\n",
      "Epoch 5481 - Train Loss: 0.180632, Train Acc: 0.638462 | Val Loss: 0.193182, Val Acc: 0.556701\n",
      "Epoch 5482 - Train Loss: 0.180618, Train Acc: 0.638462 | Val Loss: 0.193168, Val Acc: 0.556701\n",
      "Epoch 5483 - Train Loss: 0.180604, Train Acc: 0.638462 | Val Loss: 0.193155, Val Acc: 0.556701\n",
      "Epoch 5484 - Train Loss: 0.180590, Train Acc: 0.637179 | Val Loss: 0.193141, Val Acc: 0.556701\n",
      "Epoch 5485 - Train Loss: 0.180577, Train Acc: 0.637179 | Val Loss: 0.193127, Val Acc: 0.556701\n",
      "Epoch 5486 - Train Loss: 0.180563, Train Acc: 0.637179 | Val Loss: 0.193114, Val Acc: 0.556701\n",
      "Epoch 5487 - Train Loss: 0.180549, Train Acc: 0.637179 | Val Loss: 0.193100, Val Acc: 0.556701\n",
      "Epoch 5488 - Train Loss: 0.180535, Train Acc: 0.637179 | Val Loss: 0.193086, Val Acc: 0.556701\n",
      "Epoch 5489 - Train Loss: 0.180521, Train Acc: 0.637179 | Val Loss: 0.193073, Val Acc: 0.556701\n",
      "Epoch 5490 - Train Loss: 0.180508, Train Acc: 0.637179 | Val Loss: 0.193059, Val Acc: 0.556701\n",
      "Epoch 5491 - Train Loss: 0.180494, Train Acc: 0.637179 | Val Loss: 0.193045, Val Acc: 0.556701\n",
      "Epoch 5492 - Train Loss: 0.180480, Train Acc: 0.637179 | Val Loss: 0.193032, Val Acc: 0.556701\n",
      "Epoch 5493 - Train Loss: 0.180466, Train Acc: 0.637179 | Val Loss: 0.193018, Val Acc: 0.556701\n",
      "Epoch 5494 - Train Loss: 0.180452, Train Acc: 0.637179 | Val Loss: 0.193004, Val Acc: 0.556701\n",
      "Epoch 5495 - Train Loss: 0.180439, Train Acc: 0.637179 | Val Loss: 0.192991, Val Acc: 0.556701\n",
      "Epoch 5496 - Train Loss: 0.180425, Train Acc: 0.637179 | Val Loss: 0.192977, Val Acc: 0.556701\n",
      "Epoch 5497 - Train Loss: 0.180411, Train Acc: 0.637179 | Val Loss: 0.192963, Val Acc: 0.556701\n",
      "Epoch 5498 - Train Loss: 0.180397, Train Acc: 0.637179 | Val Loss: 0.192950, Val Acc: 0.556701\n",
      "Epoch 5499 - Train Loss: 0.180384, Train Acc: 0.637179 | Val Loss: 0.192936, Val Acc: 0.556701\n",
      "Epoch 5500 - Train Loss: 0.180370, Train Acc: 0.637179 | Val Loss: 0.192922, Val Acc: 0.556701\n",
      "Epoch 5501 - Train Loss: 0.180356, Train Acc: 0.637179 | Val Loss: 0.192909, Val Acc: 0.556701\n",
      "Epoch 5502 - Train Loss: 0.180342, Train Acc: 0.637179 | Val Loss: 0.192895, Val Acc: 0.556701\n",
      "Epoch 5503 - Train Loss: 0.180328, Train Acc: 0.637179 | Val Loss: 0.192881, Val Acc: 0.556701\n",
      "Epoch 5504 - Train Loss: 0.180315, Train Acc: 0.637179 | Val Loss: 0.192868, Val Acc: 0.556701\n",
      "Epoch 5505 - Train Loss: 0.180301, Train Acc: 0.637179 | Val Loss: 0.192854, Val Acc: 0.556701\n",
      "Epoch 5506 - Train Loss: 0.180287, Train Acc: 0.637179 | Val Loss: 0.192841, Val Acc: 0.556701\n",
      "Epoch 5507 - Train Loss: 0.180273, Train Acc: 0.637179 | Val Loss: 0.192827, Val Acc: 0.556701\n",
      "Epoch 5508 - Train Loss: 0.180260, Train Acc: 0.637179 | Val Loss: 0.192813, Val Acc: 0.556701\n",
      "Epoch 5509 - Train Loss: 0.180246, Train Acc: 0.637179 | Val Loss: 0.192800, Val Acc: 0.556701\n",
      "Epoch 5510 - Train Loss: 0.180232, Train Acc: 0.637179 | Val Loss: 0.192786, Val Acc: 0.556701\n",
      "Epoch 5511 - Train Loss: 0.180218, Train Acc: 0.637179 | Val Loss: 0.192772, Val Acc: 0.556701\n",
      "Epoch 5512 - Train Loss: 0.180205, Train Acc: 0.637179 | Val Loss: 0.192759, Val Acc: 0.556701\n",
      "Epoch 5513 - Train Loss: 0.180191, Train Acc: 0.637179 | Val Loss: 0.192745, Val Acc: 0.556701\n",
      "Epoch 5514 - Train Loss: 0.180177, Train Acc: 0.637179 | Val Loss: 0.192731, Val Acc: 0.556701\n",
      "Epoch 5515 - Train Loss: 0.180163, Train Acc: 0.637179 | Val Loss: 0.192718, Val Acc: 0.556701\n",
      "Epoch 5516 - Train Loss: 0.180150, Train Acc: 0.637179 | Val Loss: 0.192704, Val Acc: 0.556701\n",
      "Epoch 5517 - Train Loss: 0.180136, Train Acc: 0.637179 | Val Loss: 0.192690, Val Acc: 0.556701\n",
      "Epoch 5518 - Train Loss: 0.180122, Train Acc: 0.637179 | Val Loss: 0.192677, Val Acc: 0.556701\n",
      "Epoch 5519 - Train Loss: 0.180108, Train Acc: 0.637179 | Val Loss: 0.192663, Val Acc: 0.556701\n",
      "Epoch 5520 - Train Loss: 0.180094, Train Acc: 0.637179 | Val Loss: 0.192650, Val Acc: 0.556701\n",
      "Epoch 5521 - Train Loss: 0.180081, Train Acc: 0.637179 | Val Loss: 0.192636, Val Acc: 0.556701\n",
      "Epoch 5522 - Train Loss: 0.180067, Train Acc: 0.637179 | Val Loss: 0.192622, Val Acc: 0.556701\n",
      "Epoch 5523 - Train Loss: 0.180053, Train Acc: 0.637179 | Val Loss: 0.192609, Val Acc: 0.556701\n",
      "Epoch 5524 - Train Loss: 0.180039, Train Acc: 0.637179 | Val Loss: 0.192595, Val Acc: 0.556701\n",
      "Epoch 5525 - Train Loss: 0.180026, Train Acc: 0.637179 | Val Loss: 0.192581, Val Acc: 0.556701\n",
      "Epoch 5526 - Train Loss: 0.180012, Train Acc: 0.638462 | Val Loss: 0.192568, Val Acc: 0.556701\n",
      "Epoch 5527 - Train Loss: 0.179998, Train Acc: 0.638462 | Val Loss: 0.192554, Val Acc: 0.556701\n",
      "Epoch 5528 - Train Loss: 0.179984, Train Acc: 0.638462 | Val Loss: 0.192540, Val Acc: 0.556701\n",
      "Epoch 5529 - Train Loss: 0.179971, Train Acc: 0.638462 | Val Loss: 0.192527, Val Acc: 0.556701\n",
      "Epoch 5530 - Train Loss: 0.179957, Train Acc: 0.638462 | Val Loss: 0.192513, Val Acc: 0.556701\n",
      "Epoch 5531 - Train Loss: 0.179943, Train Acc: 0.638462 | Val Loss: 0.192500, Val Acc: 0.556701\n",
      "Epoch 5532 - Train Loss: 0.179930, Train Acc: 0.638462 | Val Loss: 0.192486, Val Acc: 0.556701\n",
      "Epoch 5533 - Train Loss: 0.179916, Train Acc: 0.638462 | Val Loss: 0.192472, Val Acc: 0.556701\n",
      "Epoch 5534 - Train Loss: 0.179902, Train Acc: 0.638462 | Val Loss: 0.192459, Val Acc: 0.556701\n",
      "Epoch 5535 - Train Loss: 0.179888, Train Acc: 0.638462 | Val Loss: 0.192445, Val Acc: 0.556701\n",
      "Epoch 5536 - Train Loss: 0.179875, Train Acc: 0.638462 | Val Loss: 0.192431, Val Acc: 0.556701\n",
      "Epoch 5537 - Train Loss: 0.179861, Train Acc: 0.638462 | Val Loss: 0.192418, Val Acc: 0.556701\n",
      "Epoch 5538 - Train Loss: 0.179847, Train Acc: 0.638462 | Val Loss: 0.192404, Val Acc: 0.556701\n",
      "Epoch 5539 - Train Loss: 0.179833, Train Acc: 0.638462 | Val Loss: 0.192391, Val Acc: 0.556701\n",
      "Epoch 5540 - Train Loss: 0.179820, Train Acc: 0.638462 | Val Loss: 0.192377, Val Acc: 0.556701\n",
      "Epoch 5541 - Train Loss: 0.179806, Train Acc: 0.638462 | Val Loss: 0.192363, Val Acc: 0.556701\n",
      "Epoch 5542 - Train Loss: 0.179792, Train Acc: 0.638462 | Val Loss: 0.192350, Val Acc: 0.556701\n",
      "Epoch 5543 - Train Loss: 0.179778, Train Acc: 0.638462 | Val Loss: 0.192336, Val Acc: 0.556701\n",
      "Epoch 5544 - Train Loss: 0.179765, Train Acc: 0.638462 | Val Loss: 0.192322, Val Acc: 0.556701\n",
      "Epoch 5545 - Train Loss: 0.179751, Train Acc: 0.638462 | Val Loss: 0.192309, Val Acc: 0.556701\n",
      "Epoch 5546 - Train Loss: 0.179737, Train Acc: 0.638462 | Val Loss: 0.192295, Val Acc: 0.556701\n",
      "Epoch 5547 - Train Loss: 0.179723, Train Acc: 0.638462 | Val Loss: 0.192282, Val Acc: 0.556701\n",
      "Epoch 5548 - Train Loss: 0.179710, Train Acc: 0.638462 | Val Loss: 0.192268, Val Acc: 0.556701\n",
      "Epoch 5549 - Train Loss: 0.179696, Train Acc: 0.638462 | Val Loss: 0.192254, Val Acc: 0.556701\n",
      "Epoch 5550 - Train Loss: 0.179682, Train Acc: 0.638462 | Val Loss: 0.192241, Val Acc: 0.556701\n",
      "Epoch 5551 - Train Loss: 0.179669, Train Acc: 0.638462 | Val Loss: 0.192227, Val Acc: 0.556701\n",
      "Epoch 5552 - Train Loss: 0.179655, Train Acc: 0.638462 | Val Loss: 0.192214, Val Acc: 0.556701\n",
      "Epoch 5553 - Train Loss: 0.179641, Train Acc: 0.638462 | Val Loss: 0.192200, Val Acc: 0.556701\n",
      "Epoch 5554 - Train Loss: 0.179627, Train Acc: 0.638462 | Val Loss: 0.192186, Val Acc: 0.556701\n",
      "Epoch 5555 - Train Loss: 0.179614, Train Acc: 0.638462 | Val Loss: 0.192173, Val Acc: 0.556701\n",
      "Epoch 5556 - Train Loss: 0.179600, Train Acc: 0.638462 | Val Loss: 0.192159, Val Acc: 0.556701\n",
      "Epoch 5557 - Train Loss: 0.179586, Train Acc: 0.638462 | Val Loss: 0.192146, Val Acc: 0.556701\n",
      "Epoch 5558 - Train Loss: 0.179573, Train Acc: 0.638462 | Val Loss: 0.192132, Val Acc: 0.556701\n",
      "Epoch 5559 - Train Loss: 0.179559, Train Acc: 0.638462 | Val Loss: 0.192118, Val Acc: 0.556701\n",
      "Epoch 5560 - Train Loss: 0.179545, Train Acc: 0.639744 | Val Loss: 0.192105, Val Acc: 0.556701\n",
      "Epoch 5561 - Train Loss: 0.179531, Train Acc: 0.639744 | Val Loss: 0.192091, Val Acc: 0.556701\n",
      "Epoch 5562 - Train Loss: 0.179518, Train Acc: 0.639744 | Val Loss: 0.192078, Val Acc: 0.556701\n",
      "Epoch 5563 - Train Loss: 0.179504, Train Acc: 0.639744 | Val Loss: 0.192064, Val Acc: 0.556701\n",
      "Epoch 5564 - Train Loss: 0.179490, Train Acc: 0.639744 | Val Loss: 0.192051, Val Acc: 0.556701\n",
      "Epoch 5565 - Train Loss: 0.179477, Train Acc: 0.639744 | Val Loss: 0.192037, Val Acc: 0.556701\n",
      "Epoch 5566 - Train Loss: 0.179463, Train Acc: 0.639744 | Val Loss: 0.192023, Val Acc: 0.556701\n",
      "Epoch 5567 - Train Loss: 0.179449, Train Acc: 0.639744 | Val Loss: 0.192010, Val Acc: 0.556701\n",
      "Epoch 5568 - Train Loss: 0.179435, Train Acc: 0.641026 | Val Loss: 0.191996, Val Acc: 0.556701\n",
      "Epoch 5569 - Train Loss: 0.179422, Train Acc: 0.641026 | Val Loss: 0.191983, Val Acc: 0.556701\n",
      "Epoch 5570 - Train Loss: 0.179408, Train Acc: 0.641026 | Val Loss: 0.191969, Val Acc: 0.556701\n",
      "Epoch 5571 - Train Loss: 0.179394, Train Acc: 0.641026 | Val Loss: 0.191956, Val Acc: 0.556701\n",
      "Epoch 5572 - Train Loss: 0.179381, Train Acc: 0.641026 | Val Loss: 0.191942, Val Acc: 0.556701\n",
      "Epoch 5573 - Train Loss: 0.179367, Train Acc: 0.641026 | Val Loss: 0.191928, Val Acc: 0.556701\n",
      "Epoch 5574 - Train Loss: 0.179353, Train Acc: 0.641026 | Val Loss: 0.191915, Val Acc: 0.556701\n",
      "Epoch 5575 - Train Loss: 0.179340, Train Acc: 0.641026 | Val Loss: 0.191901, Val Acc: 0.556701\n",
      "Epoch 5576 - Train Loss: 0.179326, Train Acc: 0.641026 | Val Loss: 0.191888, Val Acc: 0.556701\n",
      "Epoch 5577 - Train Loss: 0.179312, Train Acc: 0.641026 | Val Loss: 0.191874, Val Acc: 0.556701\n",
      "Epoch 5578 - Train Loss: 0.179298, Train Acc: 0.641026 | Val Loss: 0.191861, Val Acc: 0.556701\n",
      "Epoch 5579 - Train Loss: 0.179285, Train Acc: 0.641026 | Val Loss: 0.191847, Val Acc: 0.556701\n",
      "Epoch 5580 - Train Loss: 0.179271, Train Acc: 0.641026 | Val Loss: 0.191833, Val Acc: 0.556701\n",
      "Epoch 5581 - Train Loss: 0.179257, Train Acc: 0.641026 | Val Loss: 0.191820, Val Acc: 0.556701\n",
      "Epoch 5582 - Train Loss: 0.179244, Train Acc: 0.641026 | Val Loss: 0.191806, Val Acc: 0.556701\n",
      "Epoch 5583 - Train Loss: 0.179230, Train Acc: 0.641026 | Val Loss: 0.191793, Val Acc: 0.556701\n",
      "Epoch 5584 - Train Loss: 0.179216, Train Acc: 0.641026 | Val Loss: 0.191779, Val Acc: 0.556701\n",
      "Epoch 5585 - Train Loss: 0.179203, Train Acc: 0.641026 | Val Loss: 0.191766, Val Acc: 0.556701\n",
      "Epoch 5586 - Train Loss: 0.179189, Train Acc: 0.641026 | Val Loss: 0.191752, Val Acc: 0.556701\n",
      "Epoch 5587 - Train Loss: 0.179175, Train Acc: 0.641026 | Val Loss: 0.191739, Val Acc: 0.556701\n",
      "Epoch 5588 - Train Loss: 0.179162, Train Acc: 0.641026 | Val Loss: 0.191725, Val Acc: 0.556701\n",
      "Epoch 5589 - Train Loss: 0.179148, Train Acc: 0.641026 | Val Loss: 0.191712, Val Acc: 0.556701\n",
      "Epoch 5590 - Train Loss: 0.179134, Train Acc: 0.641026 | Val Loss: 0.191698, Val Acc: 0.556701\n",
      "Epoch 5591 - Train Loss: 0.179121, Train Acc: 0.641026 | Val Loss: 0.191684, Val Acc: 0.556701\n",
      "Epoch 5592 - Train Loss: 0.179107, Train Acc: 0.641026 | Val Loss: 0.191671, Val Acc: 0.556701\n",
      "Epoch 5593 - Train Loss: 0.179093, Train Acc: 0.641026 | Val Loss: 0.191657, Val Acc: 0.556701\n",
      "Epoch 5594 - Train Loss: 0.179080, Train Acc: 0.639744 | Val Loss: 0.191644, Val Acc: 0.556701\n",
      "Epoch 5595 - Train Loss: 0.179066, Train Acc: 0.639744 | Val Loss: 0.191630, Val Acc: 0.556701\n",
      "Epoch 5596 - Train Loss: 0.179052, Train Acc: 0.639744 | Val Loss: 0.191617, Val Acc: 0.556701\n",
      "Epoch 5597 - Train Loss: 0.179039, Train Acc: 0.639744 | Val Loss: 0.191603, Val Acc: 0.556701\n",
      "Epoch 5598 - Train Loss: 0.179025, Train Acc: 0.639744 | Val Loss: 0.191590, Val Acc: 0.556701\n",
      "Epoch 5599 - Train Loss: 0.179011, Train Acc: 0.639744 | Val Loss: 0.191576, Val Acc: 0.556701\n",
      "Epoch 5600 - Train Loss: 0.178997, Train Acc: 0.641026 | Val Loss: 0.191563, Val Acc: 0.556701\n",
      "Epoch 5601 - Train Loss: 0.178984, Train Acc: 0.641026 | Val Loss: 0.191549, Val Acc: 0.556701\n",
      "Epoch 5602 - Train Loss: 0.178970, Train Acc: 0.641026 | Val Loss: 0.191536, Val Acc: 0.556701\n",
      "Epoch 5603 - Train Loss: 0.178956, Train Acc: 0.641026 | Val Loss: 0.191522, Val Acc: 0.556701\n",
      "Epoch 5604 - Train Loss: 0.178943, Train Acc: 0.641026 | Val Loss: 0.191509, Val Acc: 0.556701\n",
      "Epoch 5605 - Train Loss: 0.178929, Train Acc: 0.641026 | Val Loss: 0.191495, Val Acc: 0.556701\n",
      "Epoch 5606 - Train Loss: 0.178915, Train Acc: 0.641026 | Val Loss: 0.191482, Val Acc: 0.556701\n",
      "Epoch 5607 - Train Loss: 0.178902, Train Acc: 0.641026 | Val Loss: 0.191468, Val Acc: 0.556701\n",
      "Epoch 5608 - Train Loss: 0.178888, Train Acc: 0.641026 | Val Loss: 0.191455, Val Acc: 0.556701\n",
      "Epoch 5609 - Train Loss: 0.178875, Train Acc: 0.641026 | Val Loss: 0.191441, Val Acc: 0.556701\n",
      "Epoch 5610 - Train Loss: 0.178861, Train Acc: 0.641026 | Val Loss: 0.191428, Val Acc: 0.556701\n",
      "Epoch 5611 - Train Loss: 0.178847, Train Acc: 0.641026 | Val Loss: 0.191414, Val Acc: 0.556701\n",
      "Epoch 5612 - Train Loss: 0.178834, Train Acc: 0.641026 | Val Loss: 0.191401, Val Acc: 0.556701\n",
      "Epoch 5613 - Train Loss: 0.178820, Train Acc: 0.641026 | Val Loss: 0.191387, Val Acc: 0.556701\n",
      "Epoch 5614 - Train Loss: 0.178806, Train Acc: 0.642308 | Val Loss: 0.191374, Val Acc: 0.556701\n",
      "Epoch 5615 - Train Loss: 0.178793, Train Acc: 0.642308 | Val Loss: 0.191360, Val Acc: 0.556701\n",
      "Epoch 5616 - Train Loss: 0.178779, Train Acc: 0.642308 | Val Loss: 0.191347, Val Acc: 0.556701\n",
      "Epoch 5617 - Train Loss: 0.178765, Train Acc: 0.642308 | Val Loss: 0.191333, Val Acc: 0.556701\n",
      "Epoch 5618 - Train Loss: 0.178752, Train Acc: 0.642308 | Val Loss: 0.191320, Val Acc: 0.556701\n",
      "Epoch 5619 - Train Loss: 0.178738, Train Acc: 0.642308 | Val Loss: 0.191306, Val Acc: 0.556701\n",
      "Epoch 5620 - Train Loss: 0.178724, Train Acc: 0.642308 | Val Loss: 0.191293, Val Acc: 0.556701\n",
      "Epoch 5621 - Train Loss: 0.178711, Train Acc: 0.642308 | Val Loss: 0.191279, Val Acc: 0.556701\n",
      "Epoch 5622 - Train Loss: 0.178697, Train Acc: 0.642308 | Val Loss: 0.191266, Val Acc: 0.556701\n",
      "Epoch 5623 - Train Loss: 0.178683, Train Acc: 0.642308 | Val Loss: 0.191252, Val Acc: 0.556701\n",
      "Epoch 5624 - Train Loss: 0.178670, Train Acc: 0.642308 | Val Loss: 0.191239, Val Acc: 0.556701\n",
      "Epoch 5625 - Train Loss: 0.178656, Train Acc: 0.642308 | Val Loss: 0.191225, Val Acc: 0.556701\n",
      "Epoch 5626 - Train Loss: 0.178642, Train Acc: 0.642308 | Val Loss: 0.191212, Val Acc: 0.556701\n",
      "Epoch 5627 - Train Loss: 0.178629, Train Acc: 0.642308 | Val Loss: 0.191198, Val Acc: 0.556701\n",
      "Epoch 5628 - Train Loss: 0.178615, Train Acc: 0.642308 | Val Loss: 0.191185, Val Acc: 0.556701\n",
      "Epoch 5629 - Train Loss: 0.178601, Train Acc: 0.642308 | Val Loss: 0.191171, Val Acc: 0.556701\n",
      "Epoch 5630 - Train Loss: 0.178588, Train Acc: 0.643590 | Val Loss: 0.191158, Val Acc: 0.556701\n",
      "Epoch 5631 - Train Loss: 0.178574, Train Acc: 0.643590 | Val Loss: 0.191144, Val Acc: 0.556701\n",
      "Epoch 5632 - Train Loss: 0.178561, Train Acc: 0.643590 | Val Loss: 0.191131, Val Acc: 0.556701\n",
      "Epoch 5633 - Train Loss: 0.178547, Train Acc: 0.643590 | Val Loss: 0.191117, Val Acc: 0.556701\n",
      "Epoch 5634 - Train Loss: 0.178533, Train Acc: 0.643590 | Val Loss: 0.191104, Val Acc: 0.556701\n",
      "Epoch 5635 - Train Loss: 0.178520, Train Acc: 0.643590 | Val Loss: 0.191090, Val Acc: 0.556701\n",
      "Epoch 5636 - Train Loss: 0.178506, Train Acc: 0.643590 | Val Loss: 0.191077, Val Acc: 0.556701\n",
      "Epoch 5637 - Train Loss: 0.178492, Train Acc: 0.643590 | Val Loss: 0.191064, Val Acc: 0.556701\n",
      "Epoch 5638 - Train Loss: 0.178479, Train Acc: 0.643590 | Val Loss: 0.191050, Val Acc: 0.556701\n",
      "Epoch 5639 - Train Loss: 0.178465, Train Acc: 0.643590 | Val Loss: 0.191037, Val Acc: 0.556701\n",
      "Epoch 5640 - Train Loss: 0.178452, Train Acc: 0.643590 | Val Loss: 0.191023, Val Acc: 0.556701\n",
      "Epoch 5641 - Train Loss: 0.178438, Train Acc: 0.643590 | Val Loss: 0.191010, Val Acc: 0.556701\n",
      "Epoch 5642 - Train Loss: 0.178424, Train Acc: 0.643590 | Val Loss: 0.190996, Val Acc: 0.556701\n",
      "Epoch 5643 - Train Loss: 0.178411, Train Acc: 0.643590 | Val Loss: 0.190983, Val Acc: 0.556701\n",
      "Epoch 5644 - Train Loss: 0.178397, Train Acc: 0.643590 | Val Loss: 0.190969, Val Acc: 0.556701\n",
      "Epoch 5645 - Train Loss: 0.178383, Train Acc: 0.643590 | Val Loss: 0.190956, Val Acc: 0.556701\n",
      "Epoch 5646 - Train Loss: 0.178370, Train Acc: 0.643590 | Val Loss: 0.190942, Val Acc: 0.556701\n",
      "Epoch 5647 - Train Loss: 0.178356, Train Acc: 0.643590 | Val Loss: 0.190929, Val Acc: 0.556701\n",
      "Epoch 5648 - Train Loss: 0.178343, Train Acc: 0.643590 | Val Loss: 0.190916, Val Acc: 0.556701\n",
      "Epoch 5649 - Train Loss: 0.178329, Train Acc: 0.643590 | Val Loss: 0.190902, Val Acc: 0.556701\n",
      "Epoch 5650 - Train Loss: 0.178315, Train Acc: 0.643590 | Val Loss: 0.190889, Val Acc: 0.556701\n",
      "Epoch 5651 - Train Loss: 0.178302, Train Acc: 0.643590 | Val Loss: 0.190875, Val Acc: 0.556701\n",
      "Epoch 5652 - Train Loss: 0.178288, Train Acc: 0.643590 | Val Loss: 0.190862, Val Acc: 0.556701\n",
      "Epoch 5653 - Train Loss: 0.178274, Train Acc: 0.643590 | Val Loss: 0.190848, Val Acc: 0.556701\n",
      "Epoch 5654 - Train Loss: 0.178261, Train Acc: 0.643590 | Val Loss: 0.190835, Val Acc: 0.567010\n",
      "Epoch 5655 - Train Loss: 0.178247, Train Acc: 0.643590 | Val Loss: 0.190821, Val Acc: 0.567010\n",
      "Epoch 5656 - Train Loss: 0.178234, Train Acc: 0.643590 | Val Loss: 0.190808, Val Acc: 0.567010\n",
      "Epoch 5657 - Train Loss: 0.178220, Train Acc: 0.644872 | Val Loss: 0.190795, Val Acc: 0.567010\n",
      "Epoch 5658 - Train Loss: 0.178206, Train Acc: 0.644872 | Val Loss: 0.190781, Val Acc: 0.567010\n",
      "Epoch 5659 - Train Loss: 0.178193, Train Acc: 0.644872 | Val Loss: 0.190768, Val Acc: 0.567010\n",
      "Epoch 5660 - Train Loss: 0.178179, Train Acc: 0.644872 | Val Loss: 0.190754, Val Acc: 0.567010\n",
      "Epoch 5661 - Train Loss: 0.178166, Train Acc: 0.644872 | Val Loss: 0.190741, Val Acc: 0.567010\n",
      "Epoch 5662 - Train Loss: 0.178152, Train Acc: 0.644872 | Val Loss: 0.190727, Val Acc: 0.567010\n",
      "Epoch 5663 - Train Loss: 0.178138, Train Acc: 0.644872 | Val Loss: 0.190714, Val Acc: 0.567010\n",
      "Epoch 5664 - Train Loss: 0.178125, Train Acc: 0.644872 | Val Loss: 0.190701, Val Acc: 0.567010\n",
      "Epoch 5665 - Train Loss: 0.178111, Train Acc: 0.644872 | Val Loss: 0.190687, Val Acc: 0.567010\n",
      "Epoch 5666 - Train Loss: 0.178098, Train Acc: 0.644872 | Val Loss: 0.190674, Val Acc: 0.567010\n",
      "Epoch 5667 - Train Loss: 0.178084, Train Acc: 0.644872 | Val Loss: 0.190660, Val Acc: 0.567010\n",
      "Epoch 5668 - Train Loss: 0.178070, Train Acc: 0.644872 | Val Loss: 0.190647, Val Acc: 0.567010\n",
      "Epoch 5669 - Train Loss: 0.178057, Train Acc: 0.644872 | Val Loss: 0.190633, Val Acc: 0.567010\n",
      "Epoch 5670 - Train Loss: 0.178043, Train Acc: 0.644872 | Val Loss: 0.190620, Val Acc: 0.567010\n",
      "Epoch 5671 - Train Loss: 0.178030, Train Acc: 0.644872 | Val Loss: 0.190607, Val Acc: 0.567010\n",
      "Epoch 5672 - Train Loss: 0.178016, Train Acc: 0.644872 | Val Loss: 0.190593, Val Acc: 0.567010\n",
      "Epoch 5673 - Train Loss: 0.178002, Train Acc: 0.644872 | Val Loss: 0.190580, Val Acc: 0.567010\n",
      "Epoch 5674 - Train Loss: 0.177989, Train Acc: 0.644872 | Val Loss: 0.190566, Val Acc: 0.567010\n",
      "Epoch 5675 - Train Loss: 0.177975, Train Acc: 0.644872 | Val Loss: 0.190553, Val Acc: 0.567010\n",
      "Epoch 5676 - Train Loss: 0.177962, Train Acc: 0.644872 | Val Loss: 0.190540, Val Acc: 0.567010\n",
      "Epoch 5677 - Train Loss: 0.177948, Train Acc: 0.644872 | Val Loss: 0.190526, Val Acc: 0.567010\n",
      "Epoch 5678 - Train Loss: 0.177934, Train Acc: 0.646154 | Val Loss: 0.190513, Val Acc: 0.567010\n",
      "Epoch 5679 - Train Loss: 0.177921, Train Acc: 0.646154 | Val Loss: 0.190499, Val Acc: 0.567010\n",
      "Epoch 5680 - Train Loss: 0.177907, Train Acc: 0.646154 | Val Loss: 0.190486, Val Acc: 0.567010\n",
      "Epoch 5681 - Train Loss: 0.177894, Train Acc: 0.646154 | Val Loss: 0.190473, Val Acc: 0.567010\n",
      "Epoch 5682 - Train Loss: 0.177880, Train Acc: 0.646154 | Val Loss: 0.190459, Val Acc: 0.567010\n",
      "Epoch 5683 - Train Loss: 0.177866, Train Acc: 0.646154 | Val Loss: 0.190446, Val Acc: 0.567010\n",
      "Epoch 5684 - Train Loss: 0.177853, Train Acc: 0.646154 | Val Loss: 0.190432, Val Acc: 0.567010\n",
      "Epoch 5685 - Train Loss: 0.177839, Train Acc: 0.646154 | Val Loss: 0.190419, Val Acc: 0.567010\n",
      "Epoch 5686 - Train Loss: 0.177826, Train Acc: 0.646154 | Val Loss: 0.190406, Val Acc: 0.567010\n",
      "Epoch 5687 - Train Loss: 0.177812, Train Acc: 0.646154 | Val Loss: 0.190392, Val Acc: 0.567010\n",
      "Epoch 5688 - Train Loss: 0.177799, Train Acc: 0.646154 | Val Loss: 0.190379, Val Acc: 0.567010\n",
      "Epoch 5689 - Train Loss: 0.177785, Train Acc: 0.646154 | Val Loss: 0.190365, Val Acc: 0.567010\n",
      "Epoch 5690 - Train Loss: 0.177771, Train Acc: 0.646154 | Val Loss: 0.190352, Val Acc: 0.567010\n",
      "Epoch 5691 - Train Loss: 0.177758, Train Acc: 0.646154 | Val Loss: 0.190339, Val Acc: 0.577320\n",
      "Epoch 5692 - Train Loss: 0.177744, Train Acc: 0.646154 | Val Loss: 0.190325, Val Acc: 0.577320\n",
      "Epoch 5693 - Train Loss: 0.177731, Train Acc: 0.646154 | Val Loss: 0.190312, Val Acc: 0.577320\n",
      "Epoch 5694 - Train Loss: 0.177717, Train Acc: 0.646154 | Val Loss: 0.190298, Val Acc: 0.577320\n",
      "Epoch 5695 - Train Loss: 0.177704, Train Acc: 0.646154 | Val Loss: 0.190285, Val Acc: 0.577320\n",
      "Epoch 5696 - Train Loss: 0.177690, Train Acc: 0.646154 | Val Loss: 0.190272, Val Acc: 0.577320\n",
      "Epoch 5697 - Train Loss: 0.177676, Train Acc: 0.646154 | Val Loss: 0.190258, Val Acc: 0.577320\n",
      "Epoch 5698 - Train Loss: 0.177663, Train Acc: 0.646154 | Val Loss: 0.190245, Val Acc: 0.577320\n",
      "Epoch 5699 - Train Loss: 0.177649, Train Acc: 0.646154 | Val Loss: 0.190232, Val Acc: 0.577320\n",
      "Epoch 5700 - Train Loss: 0.177636, Train Acc: 0.646154 | Val Loss: 0.190218, Val Acc: 0.577320\n",
      "Epoch 5701 - Train Loss: 0.177622, Train Acc: 0.646154 | Val Loss: 0.190205, Val Acc: 0.577320\n",
      "Epoch 5702 - Train Loss: 0.177609, Train Acc: 0.647436 | Val Loss: 0.190191, Val Acc: 0.577320\n",
      "Epoch 5703 - Train Loss: 0.177595, Train Acc: 0.647436 | Val Loss: 0.190178, Val Acc: 0.577320\n",
      "Epoch 5704 - Train Loss: 0.177581, Train Acc: 0.647436 | Val Loss: 0.190165, Val Acc: 0.577320\n",
      "Epoch 5705 - Train Loss: 0.177568, Train Acc: 0.647436 | Val Loss: 0.190151, Val Acc: 0.577320\n",
      "Epoch 5706 - Train Loss: 0.177554, Train Acc: 0.647436 | Val Loss: 0.190138, Val Acc: 0.577320\n",
      "Epoch 5707 - Train Loss: 0.177541, Train Acc: 0.647436 | Val Loss: 0.190125, Val Acc: 0.577320\n",
      "Epoch 5708 - Train Loss: 0.177527, Train Acc: 0.647436 | Val Loss: 0.190111, Val Acc: 0.577320\n",
      "Epoch 5709 - Train Loss: 0.177514, Train Acc: 0.647436 | Val Loss: 0.190098, Val Acc: 0.577320\n",
      "Epoch 5710 - Train Loss: 0.177500, Train Acc: 0.647436 | Val Loss: 0.190085, Val Acc: 0.577320\n",
      "Epoch 5711 - Train Loss: 0.177486, Train Acc: 0.647436 | Val Loss: 0.190071, Val Acc: 0.577320\n",
      "Epoch 5712 - Train Loss: 0.177473, Train Acc: 0.647436 | Val Loss: 0.190058, Val Acc: 0.577320\n",
      "Epoch 5713 - Train Loss: 0.177459, Train Acc: 0.648718 | Val Loss: 0.190044, Val Acc: 0.577320\n",
      "Epoch 5714 - Train Loss: 0.177446, Train Acc: 0.648718 | Val Loss: 0.190031, Val Acc: 0.577320\n",
      "Epoch 5715 - Train Loss: 0.177432, Train Acc: 0.648718 | Val Loss: 0.190018, Val Acc: 0.577320\n",
      "Epoch 5716 - Train Loss: 0.177419, Train Acc: 0.648718 | Val Loss: 0.190004, Val Acc: 0.577320\n",
      "Epoch 5717 - Train Loss: 0.177405, Train Acc: 0.648718 | Val Loss: 0.189991, Val Acc: 0.577320\n",
      "Epoch 5718 - Train Loss: 0.177392, Train Acc: 0.648718 | Val Loss: 0.189978, Val Acc: 0.577320\n",
      "Epoch 5719 - Train Loss: 0.177378, Train Acc: 0.650000 | Val Loss: 0.189964, Val Acc: 0.577320\n",
      "Epoch 5720 - Train Loss: 0.177365, Train Acc: 0.650000 | Val Loss: 0.189951, Val Acc: 0.577320\n",
      "Epoch 5721 - Train Loss: 0.177351, Train Acc: 0.650000 | Val Loss: 0.189938, Val Acc: 0.577320\n",
      "Epoch 5722 - Train Loss: 0.177337, Train Acc: 0.650000 | Val Loss: 0.189924, Val Acc: 0.577320\n",
      "Epoch 5723 - Train Loss: 0.177324, Train Acc: 0.650000 | Val Loss: 0.189911, Val Acc: 0.577320\n",
      "Epoch 5724 - Train Loss: 0.177310, Train Acc: 0.650000 | Val Loss: 0.189898, Val Acc: 0.577320\n",
      "Epoch 5725 - Train Loss: 0.177297, Train Acc: 0.650000 | Val Loss: 0.189884, Val Acc: 0.577320\n",
      "Epoch 5726 - Train Loss: 0.177283, Train Acc: 0.650000 | Val Loss: 0.189871, Val Acc: 0.577320\n",
      "Epoch 5727 - Train Loss: 0.177270, Train Acc: 0.650000 | Val Loss: 0.189858, Val Acc: 0.577320\n",
      "Epoch 5728 - Train Loss: 0.177256, Train Acc: 0.650000 | Val Loss: 0.189844, Val Acc: 0.577320\n",
      "Epoch 5729 - Train Loss: 0.177243, Train Acc: 0.650000 | Val Loss: 0.189831, Val Acc: 0.577320\n",
      "Epoch 5730 - Train Loss: 0.177229, Train Acc: 0.650000 | Val Loss: 0.189818, Val Acc: 0.577320\n",
      "Epoch 5731 - Train Loss: 0.177216, Train Acc: 0.650000 | Val Loss: 0.189804, Val Acc: 0.577320\n",
      "Epoch 5732 - Train Loss: 0.177202, Train Acc: 0.650000 | Val Loss: 0.189791, Val Acc: 0.577320\n",
      "Epoch 5733 - Train Loss: 0.177188, Train Acc: 0.650000 | Val Loss: 0.189778, Val Acc: 0.577320\n",
      "Epoch 5734 - Train Loss: 0.177175, Train Acc: 0.650000 | Val Loss: 0.189764, Val Acc: 0.577320\n",
      "Epoch 5735 - Train Loss: 0.177161, Train Acc: 0.650000 | Val Loss: 0.189751, Val Acc: 0.577320\n",
      "Epoch 5736 - Train Loss: 0.177148, Train Acc: 0.650000 | Val Loss: 0.189738, Val Acc: 0.577320\n",
      "Epoch 5737 - Train Loss: 0.177134, Train Acc: 0.650000 | Val Loss: 0.189724, Val Acc: 0.577320\n",
      "Epoch 5738 - Train Loss: 0.177121, Train Acc: 0.650000 | Val Loss: 0.189711, Val Acc: 0.577320\n",
      "Epoch 5739 - Train Loss: 0.177107, Train Acc: 0.650000 | Val Loss: 0.189698, Val Acc: 0.577320\n",
      "Epoch 5740 - Train Loss: 0.177094, Train Acc: 0.650000 | Val Loss: 0.189684, Val Acc: 0.577320\n",
      "Epoch 5741 - Train Loss: 0.177080, Train Acc: 0.650000 | Val Loss: 0.189671, Val Acc: 0.577320\n",
      "Epoch 5742 - Train Loss: 0.177067, Train Acc: 0.650000 | Val Loss: 0.189658, Val Acc: 0.577320\n",
      "Epoch 5743 - Train Loss: 0.177053, Train Acc: 0.650000 | Val Loss: 0.189644, Val Acc: 0.577320\n",
      "Epoch 5744 - Train Loss: 0.177040, Train Acc: 0.650000 | Val Loss: 0.189631, Val Acc: 0.577320\n",
      "Epoch 5745 - Train Loss: 0.177026, Train Acc: 0.650000 | Val Loss: 0.189618, Val Acc: 0.577320\n",
      "Epoch 5746 - Train Loss: 0.177013, Train Acc: 0.650000 | Val Loss: 0.189604, Val Acc: 0.577320\n",
      "Epoch 5747 - Train Loss: 0.176999, Train Acc: 0.650000 | Val Loss: 0.189591, Val Acc: 0.577320\n",
      "Epoch 5748 - Train Loss: 0.176986, Train Acc: 0.650000 | Val Loss: 0.189578, Val Acc: 0.577320\n",
      "Epoch 5749 - Train Loss: 0.176972, Train Acc: 0.650000 | Val Loss: 0.189565, Val Acc: 0.577320\n",
      "Epoch 5750 - Train Loss: 0.176959, Train Acc: 0.650000 | Val Loss: 0.189551, Val Acc: 0.577320\n",
      "Epoch 5751 - Train Loss: 0.176945, Train Acc: 0.650000 | Val Loss: 0.189538, Val Acc: 0.577320\n",
      "Epoch 5752 - Train Loss: 0.176932, Train Acc: 0.650000 | Val Loss: 0.189525, Val Acc: 0.577320\n",
      "Epoch 5753 - Train Loss: 0.176918, Train Acc: 0.650000 | Val Loss: 0.189511, Val Acc: 0.577320\n",
      "Epoch 5754 - Train Loss: 0.176905, Train Acc: 0.650000 | Val Loss: 0.189498, Val Acc: 0.577320\n",
      "Epoch 5755 - Train Loss: 0.176891, Train Acc: 0.650000 | Val Loss: 0.189485, Val Acc: 0.577320\n",
      "Epoch 5756 - Train Loss: 0.176877, Train Acc: 0.650000 | Val Loss: 0.189471, Val Acc: 0.577320\n",
      "Epoch 5757 - Train Loss: 0.176864, Train Acc: 0.650000 | Val Loss: 0.189458, Val Acc: 0.577320\n",
      "Epoch 5758 - Train Loss: 0.176850, Train Acc: 0.650000 | Val Loss: 0.189445, Val Acc: 0.577320\n",
      "Epoch 5759 - Train Loss: 0.176837, Train Acc: 0.650000 | Val Loss: 0.189432, Val Acc: 0.577320\n",
      "Epoch 5760 - Train Loss: 0.176823, Train Acc: 0.650000 | Val Loss: 0.189418, Val Acc: 0.577320\n",
      "Epoch 5761 - Train Loss: 0.176810, Train Acc: 0.650000 | Val Loss: 0.189405, Val Acc: 0.577320\n",
      "Epoch 5762 - Train Loss: 0.176796, Train Acc: 0.650000 | Val Loss: 0.189392, Val Acc: 0.577320\n",
      "Epoch 5763 - Train Loss: 0.176783, Train Acc: 0.650000 | Val Loss: 0.189378, Val Acc: 0.577320\n",
      "Epoch 5764 - Train Loss: 0.176769, Train Acc: 0.650000 | Val Loss: 0.189365, Val Acc: 0.577320\n",
      "Epoch 5765 - Train Loss: 0.176756, Train Acc: 0.650000 | Val Loss: 0.189352, Val Acc: 0.577320\n",
      "Epoch 5766 - Train Loss: 0.176742, Train Acc: 0.650000 | Val Loss: 0.189339, Val Acc: 0.577320\n",
      "Epoch 5767 - Train Loss: 0.176729, Train Acc: 0.650000 | Val Loss: 0.189325, Val Acc: 0.577320\n",
      "Epoch 5768 - Train Loss: 0.176715, Train Acc: 0.650000 | Val Loss: 0.189312, Val Acc: 0.577320\n",
      "Epoch 5769 - Train Loss: 0.176702, Train Acc: 0.650000 | Val Loss: 0.189299, Val Acc: 0.577320\n",
      "Epoch 5770 - Train Loss: 0.176688, Train Acc: 0.650000 | Val Loss: 0.189285, Val Acc: 0.577320\n",
      "Epoch 5771 - Train Loss: 0.176675, Train Acc: 0.650000 | Val Loss: 0.189272, Val Acc: 0.577320\n",
      "Epoch 5772 - Train Loss: 0.176661, Train Acc: 0.650000 | Val Loss: 0.189259, Val Acc: 0.577320\n",
      "Epoch 5773 - Train Loss: 0.176648, Train Acc: 0.650000 | Val Loss: 0.189246, Val Acc: 0.577320\n",
      "Epoch 5774 - Train Loss: 0.176634, Train Acc: 0.650000 | Val Loss: 0.189232, Val Acc: 0.577320\n",
      "Epoch 5775 - Train Loss: 0.176621, Train Acc: 0.650000 | Val Loss: 0.189219, Val Acc: 0.577320\n",
      "Epoch 5776 - Train Loss: 0.176607, Train Acc: 0.650000 | Val Loss: 0.189206, Val Acc: 0.577320\n",
      "Epoch 5777 - Train Loss: 0.176594, Train Acc: 0.650000 | Val Loss: 0.189193, Val Acc: 0.577320\n",
      "Epoch 5778 - Train Loss: 0.176580, Train Acc: 0.650000 | Val Loss: 0.189179, Val Acc: 0.577320\n",
      "Epoch 5779 - Train Loss: 0.176567, Train Acc: 0.650000 | Val Loss: 0.189166, Val Acc: 0.577320\n",
      "Epoch 5780 - Train Loss: 0.176554, Train Acc: 0.650000 | Val Loss: 0.189153, Val Acc: 0.577320\n",
      "Epoch 5781 - Train Loss: 0.176540, Train Acc: 0.650000 | Val Loss: 0.189139, Val Acc: 0.577320\n",
      "Epoch 5782 - Train Loss: 0.176527, Train Acc: 0.650000 | Val Loss: 0.189126, Val Acc: 0.577320\n",
      "Epoch 5783 - Train Loss: 0.176513, Train Acc: 0.650000 | Val Loss: 0.189113, Val Acc: 0.577320\n",
      "Epoch 5784 - Train Loss: 0.176500, Train Acc: 0.650000 | Val Loss: 0.189100, Val Acc: 0.577320\n",
      "Epoch 5785 - Train Loss: 0.176486, Train Acc: 0.650000 | Val Loss: 0.189086, Val Acc: 0.577320\n",
      "Epoch 5786 - Train Loss: 0.176473, Train Acc: 0.650000 | Val Loss: 0.189073, Val Acc: 0.577320\n",
      "Epoch 5787 - Train Loss: 0.176459, Train Acc: 0.650000 | Val Loss: 0.189060, Val Acc: 0.577320\n",
      "Epoch 5788 - Train Loss: 0.176446, Train Acc: 0.650000 | Val Loss: 0.189047, Val Acc: 0.577320\n",
      "Epoch 5789 - Train Loss: 0.176432, Train Acc: 0.650000 | Val Loss: 0.189033, Val Acc: 0.577320\n",
      "Epoch 5790 - Train Loss: 0.176419, Train Acc: 0.650000 | Val Loss: 0.189020, Val Acc: 0.577320\n",
      "Epoch 5791 - Train Loss: 0.176405, Train Acc: 0.650000 | Val Loss: 0.189007, Val Acc: 0.577320\n",
      "Epoch 5792 - Train Loss: 0.176392, Train Acc: 0.650000 | Val Loss: 0.188994, Val Acc: 0.577320\n",
      "Epoch 5793 - Train Loss: 0.176378, Train Acc: 0.650000 | Val Loss: 0.188980, Val Acc: 0.577320\n",
      "Epoch 5794 - Train Loss: 0.176365, Train Acc: 0.650000 | Val Loss: 0.188967, Val Acc: 0.577320\n",
      "Epoch 5795 - Train Loss: 0.176351, Train Acc: 0.650000 | Val Loss: 0.188954, Val Acc: 0.577320\n",
      "Epoch 5796 - Train Loss: 0.176338, Train Acc: 0.650000 | Val Loss: 0.188941, Val Acc: 0.577320\n",
      "Epoch 5797 - Train Loss: 0.176324, Train Acc: 0.650000 | Val Loss: 0.188928, Val Acc: 0.577320\n",
      "Epoch 5798 - Train Loss: 0.176311, Train Acc: 0.650000 | Val Loss: 0.188914, Val Acc: 0.577320\n",
      "Epoch 5799 - Train Loss: 0.176297, Train Acc: 0.650000 | Val Loss: 0.188901, Val Acc: 0.577320\n",
      "Epoch 5800 - Train Loss: 0.176284, Train Acc: 0.650000 | Val Loss: 0.188888, Val Acc: 0.577320\n",
      "Epoch 5801 - Train Loss: 0.176271, Train Acc: 0.650000 | Val Loss: 0.188875, Val Acc: 0.577320\n",
      "Epoch 5802 - Train Loss: 0.176257, Train Acc: 0.650000 | Val Loss: 0.188862, Val Acc: 0.577320\n",
      "Epoch 5803 - Train Loss: 0.176244, Train Acc: 0.650000 | Val Loss: 0.188848, Val Acc: 0.577320\n",
      "Epoch 5804 - Train Loss: 0.176230, Train Acc: 0.650000 | Val Loss: 0.188835, Val Acc: 0.577320\n",
      "Epoch 5805 - Train Loss: 0.176217, Train Acc: 0.650000 | Val Loss: 0.188822, Val Acc: 0.577320\n",
      "Epoch 5806 - Train Loss: 0.176203, Train Acc: 0.650000 | Val Loss: 0.188809, Val Acc: 0.577320\n",
      "Epoch 5807 - Train Loss: 0.176190, Train Acc: 0.650000 | Val Loss: 0.188796, Val Acc: 0.577320\n",
      "Epoch 5808 - Train Loss: 0.176176, Train Acc: 0.650000 | Val Loss: 0.188782, Val Acc: 0.577320\n",
      "Epoch 5809 - Train Loss: 0.176163, Train Acc: 0.650000 | Val Loss: 0.188769, Val Acc: 0.577320\n",
      "Epoch 5810 - Train Loss: 0.176149, Train Acc: 0.650000 | Val Loss: 0.188756, Val Acc: 0.577320\n",
      "Epoch 5811 - Train Loss: 0.176136, Train Acc: 0.650000 | Val Loss: 0.188743, Val Acc: 0.577320\n",
      "Epoch 5812 - Train Loss: 0.176122, Train Acc: 0.651282 | Val Loss: 0.188730, Val Acc: 0.577320\n",
      "Epoch 5813 - Train Loss: 0.176109, Train Acc: 0.651282 | Val Loss: 0.188716, Val Acc: 0.577320\n",
      "Epoch 5814 - Train Loss: 0.176096, Train Acc: 0.651282 | Val Loss: 0.188703, Val Acc: 0.577320\n",
      "Epoch 5815 - Train Loss: 0.176082, Train Acc: 0.651282 | Val Loss: 0.188690, Val Acc: 0.577320\n",
      "Epoch 5816 - Train Loss: 0.176069, Train Acc: 0.651282 | Val Loss: 0.188677, Val Acc: 0.577320\n",
      "Epoch 5817 - Train Loss: 0.176055, Train Acc: 0.651282 | Val Loss: 0.188664, Val Acc: 0.577320\n",
      "Epoch 5818 - Train Loss: 0.176042, Train Acc: 0.651282 | Val Loss: 0.188651, Val Acc: 0.577320\n",
      "Epoch 5819 - Train Loss: 0.176028, Train Acc: 0.651282 | Val Loss: 0.188637, Val Acc: 0.577320\n",
      "Epoch 5820 - Train Loss: 0.176015, Train Acc: 0.651282 | Val Loss: 0.188624, Val Acc: 0.577320\n",
      "Epoch 5821 - Train Loss: 0.176001, Train Acc: 0.651282 | Val Loss: 0.188611, Val Acc: 0.577320\n",
      "Epoch 5822 - Train Loss: 0.175988, Train Acc: 0.651282 | Val Loss: 0.188598, Val Acc: 0.577320\n",
      "Epoch 5823 - Train Loss: 0.175975, Train Acc: 0.651282 | Val Loss: 0.188585, Val Acc: 0.577320\n",
      "Epoch 5824 - Train Loss: 0.175961, Train Acc: 0.651282 | Val Loss: 0.188571, Val Acc: 0.577320\n",
      "Epoch 5825 - Train Loss: 0.175948, Train Acc: 0.651282 | Val Loss: 0.188558, Val Acc: 0.577320\n",
      "Epoch 5826 - Train Loss: 0.175934, Train Acc: 0.651282 | Val Loss: 0.188545, Val Acc: 0.577320\n",
      "Epoch 5827 - Train Loss: 0.175921, Train Acc: 0.651282 | Val Loss: 0.188532, Val Acc: 0.577320\n",
      "Epoch 5828 - Train Loss: 0.175907, Train Acc: 0.651282 | Val Loss: 0.188519, Val Acc: 0.577320\n",
      "Epoch 5829 - Train Loss: 0.175894, Train Acc: 0.651282 | Val Loss: 0.188506, Val Acc: 0.577320\n",
      "Epoch 5830 - Train Loss: 0.175880, Train Acc: 0.651282 | Val Loss: 0.188492, Val Acc: 0.577320\n",
      "Epoch 5831 - Train Loss: 0.175867, Train Acc: 0.651282 | Val Loss: 0.188479, Val Acc: 0.577320\n",
      "Epoch 5832 - Train Loss: 0.175854, Train Acc: 0.651282 | Val Loss: 0.188466, Val Acc: 0.577320\n",
      "Epoch 5833 - Train Loss: 0.175840, Train Acc: 0.651282 | Val Loss: 0.188453, Val Acc: 0.577320\n",
      "Epoch 5834 - Train Loss: 0.175827, Train Acc: 0.651282 | Val Loss: 0.188440, Val Acc: 0.577320\n",
      "Epoch 5835 - Train Loss: 0.175813, Train Acc: 0.651282 | Val Loss: 0.188427, Val Acc: 0.577320\n",
      "Epoch 5836 - Train Loss: 0.175800, Train Acc: 0.651282 | Val Loss: 0.188414, Val Acc: 0.577320\n",
      "Epoch 5837 - Train Loss: 0.175786, Train Acc: 0.651282 | Val Loss: 0.188400, Val Acc: 0.577320\n",
      "Epoch 5838 - Train Loss: 0.175773, Train Acc: 0.651282 | Val Loss: 0.188387, Val Acc: 0.577320\n",
      "Epoch 5839 - Train Loss: 0.175760, Train Acc: 0.651282 | Val Loss: 0.188374, Val Acc: 0.577320\n",
      "Epoch 5840 - Train Loss: 0.175746, Train Acc: 0.651282 | Val Loss: 0.188361, Val Acc: 0.577320\n",
      "Epoch 5841 - Train Loss: 0.175733, Train Acc: 0.651282 | Val Loss: 0.188348, Val Acc: 0.577320\n",
      "Epoch 5842 - Train Loss: 0.175719, Train Acc: 0.651282 | Val Loss: 0.188335, Val Acc: 0.577320\n",
      "Epoch 5843 - Train Loss: 0.175706, Train Acc: 0.651282 | Val Loss: 0.188321, Val Acc: 0.577320\n",
      "Epoch 5844 - Train Loss: 0.175692, Train Acc: 0.651282 | Val Loss: 0.188308, Val Acc: 0.577320\n",
      "Epoch 5845 - Train Loss: 0.175679, Train Acc: 0.651282 | Val Loss: 0.188295, Val Acc: 0.577320\n",
      "Epoch 5846 - Train Loss: 0.175666, Train Acc: 0.651282 | Val Loss: 0.188282, Val Acc: 0.577320\n",
      "Epoch 5847 - Train Loss: 0.175652, Train Acc: 0.651282 | Val Loss: 0.188269, Val Acc: 0.577320\n",
      "Epoch 5848 - Train Loss: 0.175639, Train Acc: 0.651282 | Val Loss: 0.188256, Val Acc: 0.577320\n",
      "Epoch 5849 - Train Loss: 0.175625, Train Acc: 0.651282 | Val Loss: 0.188243, Val Acc: 0.577320\n",
      "Epoch 5850 - Train Loss: 0.175612, Train Acc: 0.651282 | Val Loss: 0.188229, Val Acc: 0.577320\n",
      "Epoch 5851 - Train Loss: 0.175598, Train Acc: 0.651282 | Val Loss: 0.188216, Val Acc: 0.577320\n",
      "Epoch 5852 - Train Loss: 0.175585, Train Acc: 0.651282 | Val Loss: 0.188203, Val Acc: 0.577320\n",
      "Epoch 5853 - Train Loss: 0.175572, Train Acc: 0.651282 | Val Loss: 0.188190, Val Acc: 0.577320\n",
      "Epoch 5854 - Train Loss: 0.175558, Train Acc: 0.651282 | Val Loss: 0.188177, Val Acc: 0.577320\n",
      "Epoch 5855 - Train Loss: 0.175545, Train Acc: 0.651282 | Val Loss: 0.188164, Val Acc: 0.577320\n",
      "Epoch 5856 - Train Loss: 0.175531, Train Acc: 0.651282 | Val Loss: 0.188151, Val Acc: 0.577320\n",
      "Epoch 5857 - Train Loss: 0.175518, Train Acc: 0.651282 | Val Loss: 0.188137, Val Acc: 0.577320\n",
      "Epoch 5858 - Train Loss: 0.175505, Train Acc: 0.651282 | Val Loss: 0.188124, Val Acc: 0.577320\n",
      "Epoch 5859 - Train Loss: 0.175491, Train Acc: 0.651282 | Val Loss: 0.188111, Val Acc: 0.577320\n",
      "Epoch 5860 - Train Loss: 0.175478, Train Acc: 0.651282 | Val Loss: 0.188098, Val Acc: 0.577320\n",
      "Epoch 5861 - Train Loss: 0.175464, Train Acc: 0.651282 | Val Loss: 0.188085, Val Acc: 0.577320\n",
      "Epoch 5862 - Train Loss: 0.175451, Train Acc: 0.651282 | Val Loss: 0.188072, Val Acc: 0.577320\n",
      "Epoch 5863 - Train Loss: 0.175438, Train Acc: 0.651282 | Val Loss: 0.188059, Val Acc: 0.577320\n",
      "Epoch 5864 - Train Loss: 0.175424, Train Acc: 0.651282 | Val Loss: 0.188046, Val Acc: 0.577320\n",
      "Epoch 5865 - Train Loss: 0.175411, Train Acc: 0.651282 | Val Loss: 0.188032, Val Acc: 0.577320\n",
      "Epoch 5866 - Train Loss: 0.175397, Train Acc: 0.651282 | Val Loss: 0.188019, Val Acc: 0.577320\n",
      "Epoch 5867 - Train Loss: 0.175384, Train Acc: 0.651282 | Val Loss: 0.188006, Val Acc: 0.577320\n",
      "Epoch 5868 - Train Loss: 0.175370, Train Acc: 0.651282 | Val Loss: 0.187993, Val Acc: 0.577320\n",
      "Epoch 5869 - Train Loss: 0.175357, Train Acc: 0.651282 | Val Loss: 0.187980, Val Acc: 0.577320\n",
      "Epoch 5870 - Train Loss: 0.175344, Train Acc: 0.651282 | Val Loss: 0.187967, Val Acc: 0.577320\n",
      "Epoch 5871 - Train Loss: 0.175330, Train Acc: 0.651282 | Val Loss: 0.187954, Val Acc: 0.577320\n",
      "Epoch 5872 - Train Loss: 0.175317, Train Acc: 0.651282 | Val Loss: 0.187941, Val Acc: 0.577320\n",
      "Epoch 5873 - Train Loss: 0.175304, Train Acc: 0.651282 | Val Loss: 0.187928, Val Acc: 0.577320\n",
      "Epoch 5874 - Train Loss: 0.175290, Train Acc: 0.651282 | Val Loss: 0.187914, Val Acc: 0.577320\n",
      "Epoch 5875 - Train Loss: 0.175277, Train Acc: 0.651282 | Val Loss: 0.187901, Val Acc: 0.577320\n",
      "Epoch 5876 - Train Loss: 0.175263, Train Acc: 0.651282 | Val Loss: 0.187888, Val Acc: 0.577320\n",
      "Epoch 5877 - Train Loss: 0.175250, Train Acc: 0.651282 | Val Loss: 0.187875, Val Acc: 0.577320\n",
      "Epoch 5878 - Train Loss: 0.175237, Train Acc: 0.651282 | Val Loss: 0.187862, Val Acc: 0.577320\n",
      "Epoch 5879 - Train Loss: 0.175223, Train Acc: 0.651282 | Val Loss: 0.187849, Val Acc: 0.577320\n",
      "Epoch 5880 - Train Loss: 0.175210, Train Acc: 0.651282 | Val Loss: 0.187836, Val Acc: 0.577320\n",
      "Epoch 5881 - Train Loss: 0.175196, Train Acc: 0.651282 | Val Loss: 0.187823, Val Acc: 0.577320\n",
      "Epoch 5882 - Train Loss: 0.175183, Train Acc: 0.651282 | Val Loss: 0.187810, Val Acc: 0.577320\n",
      "Epoch 5883 - Train Loss: 0.175170, Train Acc: 0.651282 | Val Loss: 0.187797, Val Acc: 0.577320\n",
      "Epoch 5884 - Train Loss: 0.175156, Train Acc: 0.651282 | Val Loss: 0.187783, Val Acc: 0.577320\n",
      "Epoch 5885 - Train Loss: 0.175143, Train Acc: 0.651282 | Val Loss: 0.187770, Val Acc: 0.577320\n",
      "Epoch 5886 - Train Loss: 0.175129, Train Acc: 0.651282 | Val Loss: 0.187757, Val Acc: 0.577320\n",
      "Epoch 5887 - Train Loss: 0.175116, Train Acc: 0.651282 | Val Loss: 0.187744, Val Acc: 0.577320\n",
      "Epoch 5888 - Train Loss: 0.175103, Train Acc: 0.651282 | Val Loss: 0.187731, Val Acc: 0.577320\n",
      "Epoch 5889 - Train Loss: 0.175089, Train Acc: 0.651282 | Val Loss: 0.187718, Val Acc: 0.577320\n",
      "Epoch 5890 - Train Loss: 0.175076, Train Acc: 0.651282 | Val Loss: 0.187705, Val Acc: 0.577320\n",
      "Epoch 5891 - Train Loss: 0.175063, Train Acc: 0.651282 | Val Loss: 0.187692, Val Acc: 0.577320\n",
      "Epoch 5892 - Train Loss: 0.175049, Train Acc: 0.651282 | Val Loss: 0.187679, Val Acc: 0.577320\n",
      "Epoch 5893 - Train Loss: 0.175036, Train Acc: 0.651282 | Val Loss: 0.187666, Val Acc: 0.577320\n",
      "Epoch 5894 - Train Loss: 0.175022, Train Acc: 0.651282 | Val Loss: 0.187653, Val Acc: 0.577320\n",
      "Epoch 5895 - Train Loss: 0.175009, Train Acc: 0.651282 | Val Loss: 0.187640, Val Acc: 0.577320\n",
      "Epoch 5896 - Train Loss: 0.174996, Train Acc: 0.651282 | Val Loss: 0.187626, Val Acc: 0.577320\n",
      "Epoch 5897 - Train Loss: 0.174982, Train Acc: 0.651282 | Val Loss: 0.187613, Val Acc: 0.577320\n",
      "Epoch 5898 - Train Loss: 0.174969, Train Acc: 0.652564 | Val Loss: 0.187600, Val Acc: 0.577320\n",
      "Epoch 5899 - Train Loss: 0.174956, Train Acc: 0.652564 | Val Loss: 0.187587, Val Acc: 0.577320\n",
      "Epoch 5900 - Train Loss: 0.174942, Train Acc: 0.652564 | Val Loss: 0.187574, Val Acc: 0.577320\n",
      "Epoch 5901 - Train Loss: 0.174929, Train Acc: 0.652564 | Val Loss: 0.187561, Val Acc: 0.577320\n",
      "Epoch 5902 - Train Loss: 0.174915, Train Acc: 0.652564 | Val Loss: 0.187548, Val Acc: 0.577320\n",
      "Epoch 5903 - Train Loss: 0.174902, Train Acc: 0.652564 | Val Loss: 0.187535, Val Acc: 0.577320\n",
      "Epoch 5904 - Train Loss: 0.174889, Train Acc: 0.652564 | Val Loss: 0.187522, Val Acc: 0.577320\n",
      "Epoch 5905 - Train Loss: 0.174875, Train Acc: 0.652564 | Val Loss: 0.187509, Val Acc: 0.577320\n",
      "Epoch 5906 - Train Loss: 0.174862, Train Acc: 0.652564 | Val Loss: 0.187496, Val Acc: 0.577320\n",
      "Epoch 5907 - Train Loss: 0.174849, Train Acc: 0.652564 | Val Loss: 0.187483, Val Acc: 0.577320\n",
      "Epoch 5908 - Train Loss: 0.174835, Train Acc: 0.652564 | Val Loss: 0.187470, Val Acc: 0.577320\n",
      "Epoch 5909 - Train Loss: 0.174822, Train Acc: 0.652564 | Val Loss: 0.187457, Val Acc: 0.577320\n",
      "Epoch 5910 - Train Loss: 0.174809, Train Acc: 0.652564 | Val Loss: 0.187443, Val Acc: 0.577320\n",
      "Epoch 5911 - Train Loss: 0.174795, Train Acc: 0.652564 | Val Loss: 0.187430, Val Acc: 0.577320\n",
      "Epoch 5912 - Train Loss: 0.174782, Train Acc: 0.652564 | Val Loss: 0.187417, Val Acc: 0.577320\n",
      "Epoch 5913 - Train Loss: 0.174768, Train Acc: 0.652564 | Val Loss: 0.187404, Val Acc: 0.577320\n",
      "Epoch 5914 - Train Loss: 0.174755, Train Acc: 0.652564 | Val Loss: 0.187391, Val Acc: 0.577320\n",
      "Epoch 5915 - Train Loss: 0.174742, Train Acc: 0.652564 | Val Loss: 0.187378, Val Acc: 0.577320\n",
      "Epoch 5916 - Train Loss: 0.174728, Train Acc: 0.652564 | Val Loss: 0.187365, Val Acc: 0.577320\n",
      "Epoch 5917 - Train Loss: 0.174715, Train Acc: 0.652564 | Val Loss: 0.187352, Val Acc: 0.577320\n",
      "Epoch 5918 - Train Loss: 0.174702, Train Acc: 0.652564 | Val Loss: 0.187339, Val Acc: 0.577320\n",
      "Epoch 5919 - Train Loss: 0.174688, Train Acc: 0.652564 | Val Loss: 0.187326, Val Acc: 0.577320\n",
      "Epoch 5920 - Train Loss: 0.174675, Train Acc: 0.652564 | Val Loss: 0.187313, Val Acc: 0.577320\n",
      "Epoch 5921 - Train Loss: 0.174662, Train Acc: 0.652564 | Val Loss: 0.187300, Val Acc: 0.577320\n",
      "Epoch 5922 - Train Loss: 0.174648, Train Acc: 0.652564 | Val Loss: 0.187287, Val Acc: 0.577320\n",
      "Epoch 5923 - Train Loss: 0.174635, Train Acc: 0.652564 | Val Loss: 0.187274, Val Acc: 0.577320\n",
      "Epoch 5924 - Train Loss: 0.174622, Train Acc: 0.652564 | Val Loss: 0.187261, Val Acc: 0.577320\n",
      "Epoch 5925 - Train Loss: 0.174608, Train Acc: 0.652564 | Val Loss: 0.187248, Val Acc: 0.577320\n",
      "Epoch 5926 - Train Loss: 0.174595, Train Acc: 0.652564 | Val Loss: 0.187235, Val Acc: 0.577320\n",
      "Epoch 5927 - Train Loss: 0.174582, Train Acc: 0.652564 | Val Loss: 0.187222, Val Acc: 0.577320\n",
      "Epoch 5928 - Train Loss: 0.174568, Train Acc: 0.652564 | Val Loss: 0.187209, Val Acc: 0.577320\n",
      "Epoch 5929 - Train Loss: 0.174555, Train Acc: 0.652564 | Val Loss: 0.187196, Val Acc: 0.577320\n",
      "Epoch 5930 - Train Loss: 0.174542, Train Acc: 0.652564 | Val Loss: 0.187183, Val Acc: 0.577320\n",
      "Epoch 5931 - Train Loss: 0.174528, Train Acc: 0.652564 | Val Loss: 0.187170, Val Acc: 0.577320\n",
      "Epoch 5932 - Train Loss: 0.174515, Train Acc: 0.652564 | Val Loss: 0.187157, Val Acc: 0.577320\n",
      "Epoch 5933 - Train Loss: 0.174502, Train Acc: 0.652564 | Val Loss: 0.187144, Val Acc: 0.577320\n",
      "Epoch 5934 - Train Loss: 0.174488, Train Acc: 0.652564 | Val Loss: 0.187130, Val Acc: 0.577320\n",
      "Epoch 5935 - Train Loss: 0.174475, Train Acc: 0.652564 | Val Loss: 0.187117, Val Acc: 0.577320\n",
      "Epoch 5936 - Train Loss: 0.174462, Train Acc: 0.652564 | Val Loss: 0.187104, Val Acc: 0.577320\n",
      "Epoch 5937 - Train Loss: 0.174448, Train Acc: 0.652564 | Val Loss: 0.187091, Val Acc: 0.577320\n",
      "Epoch 5938 - Train Loss: 0.174435, Train Acc: 0.652564 | Val Loss: 0.187078, Val Acc: 0.577320\n",
      "Epoch 5939 - Train Loss: 0.174422, Train Acc: 0.652564 | Val Loss: 0.187065, Val Acc: 0.577320\n",
      "Epoch 5940 - Train Loss: 0.174408, Train Acc: 0.652564 | Val Loss: 0.187052, Val Acc: 0.577320\n",
      "Epoch 5941 - Train Loss: 0.174395, Train Acc: 0.652564 | Val Loss: 0.187039, Val Acc: 0.577320\n",
      "Epoch 5942 - Train Loss: 0.174382, Train Acc: 0.652564 | Val Loss: 0.187026, Val Acc: 0.577320\n",
      "Epoch 5943 - Train Loss: 0.174368, Train Acc: 0.652564 | Val Loss: 0.187013, Val Acc: 0.577320\n",
      "Epoch 5944 - Train Loss: 0.174355, Train Acc: 0.652564 | Val Loss: 0.187000, Val Acc: 0.577320\n",
      "Epoch 5945 - Train Loss: 0.174342, Train Acc: 0.652564 | Val Loss: 0.186987, Val Acc: 0.577320\n",
      "Epoch 5946 - Train Loss: 0.174328, Train Acc: 0.652564 | Val Loss: 0.186974, Val Acc: 0.577320\n",
      "Epoch 5947 - Train Loss: 0.174315, Train Acc: 0.652564 | Val Loss: 0.186961, Val Acc: 0.577320\n",
      "Epoch 5948 - Train Loss: 0.174302, Train Acc: 0.652564 | Val Loss: 0.186948, Val Acc: 0.577320\n",
      "Epoch 5949 - Train Loss: 0.174288, Train Acc: 0.652564 | Val Loss: 0.186935, Val Acc: 0.577320\n",
      "Epoch 5950 - Train Loss: 0.174275, Train Acc: 0.652564 | Val Loss: 0.186922, Val Acc: 0.577320\n",
      "Epoch 5951 - Train Loss: 0.174262, Train Acc: 0.652564 | Val Loss: 0.186909, Val Acc: 0.577320\n",
      "Epoch 5952 - Train Loss: 0.174248, Train Acc: 0.652564 | Val Loss: 0.186896, Val Acc: 0.577320\n",
      "Epoch 5953 - Train Loss: 0.174235, Train Acc: 0.652564 | Val Loss: 0.186883, Val Acc: 0.577320\n",
      "Epoch 5954 - Train Loss: 0.174222, Train Acc: 0.652564 | Val Loss: 0.186870, Val Acc: 0.577320\n",
      "Epoch 5955 - Train Loss: 0.174208, Train Acc: 0.652564 | Val Loss: 0.186857, Val Acc: 0.577320\n",
      "Epoch 5956 - Train Loss: 0.174195, Train Acc: 0.652564 | Val Loss: 0.186844, Val Acc: 0.577320\n",
      "Epoch 5957 - Train Loss: 0.174182, Train Acc: 0.652564 | Val Loss: 0.186831, Val Acc: 0.577320\n",
      "Epoch 5958 - Train Loss: 0.174169, Train Acc: 0.652564 | Val Loss: 0.186817, Val Acc: 0.577320\n",
      "Epoch 5959 - Train Loss: 0.174155, Train Acc: 0.652564 | Val Loss: 0.186804, Val Acc: 0.577320\n",
      "Epoch 5960 - Train Loss: 0.174142, Train Acc: 0.652564 | Val Loss: 0.186791, Val Acc: 0.577320\n",
      "Epoch 5961 - Train Loss: 0.174129, Train Acc: 0.652564 | Val Loss: 0.186778, Val Acc: 0.577320\n",
      "Epoch 5962 - Train Loss: 0.174115, Train Acc: 0.652564 | Val Loss: 0.186765, Val Acc: 0.577320\n",
      "Epoch 5963 - Train Loss: 0.174102, Train Acc: 0.652564 | Val Loss: 0.186752, Val Acc: 0.577320\n",
      "Epoch 5964 - Train Loss: 0.174089, Train Acc: 0.652564 | Val Loss: 0.186739, Val Acc: 0.577320\n",
      "Epoch 5965 - Train Loss: 0.174075, Train Acc: 0.652564 | Val Loss: 0.186726, Val Acc: 0.577320\n",
      "Epoch 5966 - Train Loss: 0.174062, Train Acc: 0.652564 | Val Loss: 0.186713, Val Acc: 0.577320\n",
      "Epoch 5967 - Train Loss: 0.174049, Train Acc: 0.652564 | Val Loss: 0.186700, Val Acc: 0.577320\n",
      "Epoch 5968 - Train Loss: 0.174035, Train Acc: 0.652564 | Val Loss: 0.186687, Val Acc: 0.577320\n",
      "Epoch 5969 - Train Loss: 0.174022, Train Acc: 0.652564 | Val Loss: 0.186674, Val Acc: 0.577320\n",
      "Epoch 5970 - Train Loss: 0.174009, Train Acc: 0.652564 | Val Loss: 0.186661, Val Acc: 0.577320\n",
      "Epoch 5971 - Train Loss: 0.173996, Train Acc: 0.652564 | Val Loss: 0.186648, Val Acc: 0.577320\n",
      "Epoch 5972 - Train Loss: 0.173982, Train Acc: 0.652564 | Val Loss: 0.186635, Val Acc: 0.577320\n",
      "Epoch 5973 - Train Loss: 0.173969, Train Acc: 0.652564 | Val Loss: 0.186622, Val Acc: 0.577320\n",
      "Epoch 5974 - Train Loss: 0.173956, Train Acc: 0.652564 | Val Loss: 0.186609, Val Acc: 0.577320\n",
      "Epoch 5975 - Train Loss: 0.173942, Train Acc: 0.652564 | Val Loss: 0.186596, Val Acc: 0.577320\n",
      "Epoch 5976 - Train Loss: 0.173929, Train Acc: 0.652564 | Val Loss: 0.186583, Val Acc: 0.577320\n",
      "Epoch 5977 - Train Loss: 0.173916, Train Acc: 0.652564 | Val Loss: 0.186570, Val Acc: 0.577320\n",
      "Epoch 5978 - Train Loss: 0.173903, Train Acc: 0.652564 | Val Loss: 0.186557, Val Acc: 0.577320\n",
      "Epoch 5979 - Train Loss: 0.173889, Train Acc: 0.652564 | Val Loss: 0.186544, Val Acc: 0.577320\n",
      "Epoch 5980 - Train Loss: 0.173876, Train Acc: 0.652564 | Val Loss: 0.186531, Val Acc: 0.577320\n",
      "Epoch 5981 - Train Loss: 0.173863, Train Acc: 0.652564 | Val Loss: 0.186518, Val Acc: 0.577320\n",
      "Epoch 5982 - Train Loss: 0.173849, Train Acc: 0.653846 | Val Loss: 0.186505, Val Acc: 0.577320\n",
      "Epoch 5983 - Train Loss: 0.173836, Train Acc: 0.653846 | Val Loss: 0.186492, Val Acc: 0.577320\n",
      "Epoch 5984 - Train Loss: 0.173823, Train Acc: 0.655128 | Val Loss: 0.186479, Val Acc: 0.577320\n",
      "Epoch 5985 - Train Loss: 0.173810, Train Acc: 0.655128 | Val Loss: 0.186467, Val Acc: 0.577320\n",
      "Epoch 5986 - Train Loss: 0.173796, Train Acc: 0.655128 | Val Loss: 0.186454, Val Acc: 0.577320\n",
      "Epoch 5987 - Train Loss: 0.173783, Train Acc: 0.655128 | Val Loss: 0.186441, Val Acc: 0.577320\n",
      "Epoch 5988 - Train Loss: 0.173770, Train Acc: 0.655128 | Val Loss: 0.186428, Val Acc: 0.577320\n",
      "Epoch 5989 - Train Loss: 0.173756, Train Acc: 0.655128 | Val Loss: 0.186415, Val Acc: 0.577320\n",
      "Epoch 5990 - Train Loss: 0.173743, Train Acc: 0.655128 | Val Loss: 0.186402, Val Acc: 0.577320\n",
      "Epoch 5991 - Train Loss: 0.173730, Train Acc: 0.655128 | Val Loss: 0.186389, Val Acc: 0.577320\n",
      "Epoch 5992 - Train Loss: 0.173717, Train Acc: 0.655128 | Val Loss: 0.186376, Val Acc: 0.577320\n",
      "Epoch 5993 - Train Loss: 0.173703, Train Acc: 0.655128 | Val Loss: 0.186363, Val Acc: 0.577320\n",
      "Epoch 5994 - Train Loss: 0.173690, Train Acc: 0.655128 | Val Loss: 0.186350, Val Acc: 0.577320\n",
      "Epoch 5995 - Train Loss: 0.173677, Train Acc: 0.655128 | Val Loss: 0.186337, Val Acc: 0.577320\n",
      "Epoch 5996 - Train Loss: 0.173663, Train Acc: 0.655128 | Val Loss: 0.186324, Val Acc: 0.577320\n",
      "Epoch 5997 - Train Loss: 0.173650, Train Acc: 0.655128 | Val Loss: 0.186311, Val Acc: 0.577320\n",
      "Epoch 5998 - Train Loss: 0.173637, Train Acc: 0.656410 | Val Loss: 0.186298, Val Acc: 0.577320\n",
      "Epoch 5999 - Train Loss: 0.173624, Train Acc: 0.656410 | Val Loss: 0.186285, Val Acc: 0.577320\n",
      "Epoch 6000 - Train Loss: 0.173610, Train Acc: 0.656410 | Val Loss: 0.186272, Val Acc: 0.577320\n",
      "Epoch 6001 - Train Loss: 0.173597, Train Acc: 0.656410 | Val Loss: 0.186259, Val Acc: 0.577320\n",
      "Epoch 6002 - Train Loss: 0.173584, Train Acc: 0.656410 | Val Loss: 0.186246, Val Acc: 0.577320\n",
      "Epoch 6003 - Train Loss: 0.173571, Train Acc: 0.656410 | Val Loss: 0.186233, Val Acc: 0.577320\n",
      "Epoch 6004 - Train Loss: 0.173557, Train Acc: 0.656410 | Val Loss: 0.186220, Val Acc: 0.577320\n",
      "Epoch 6005 - Train Loss: 0.173544, Train Acc: 0.656410 | Val Loss: 0.186207, Val Acc: 0.577320\n",
      "Epoch 6006 - Train Loss: 0.173531, Train Acc: 0.656410 | Val Loss: 0.186194, Val Acc: 0.577320\n",
      "Epoch 6007 - Train Loss: 0.173518, Train Acc: 0.656410 | Val Loss: 0.186181, Val Acc: 0.577320\n",
      "Epoch 6008 - Train Loss: 0.173504, Train Acc: 0.656410 | Val Loss: 0.186168, Val Acc: 0.577320\n",
      "Epoch 6009 - Train Loss: 0.173491, Train Acc: 0.656410 | Val Loss: 0.186155, Val Acc: 0.577320\n",
      "Epoch 6010 - Train Loss: 0.173478, Train Acc: 0.657692 | Val Loss: 0.186142, Val Acc: 0.577320\n",
      "Epoch 6011 - Train Loss: 0.173464, Train Acc: 0.657692 | Val Loss: 0.186129, Val Acc: 0.577320\n",
      "Epoch 6012 - Train Loss: 0.173451, Train Acc: 0.658974 | Val Loss: 0.186116, Val Acc: 0.577320\n",
      "Epoch 6013 - Train Loss: 0.173438, Train Acc: 0.658974 | Val Loss: 0.186104, Val Acc: 0.577320\n",
      "Epoch 6014 - Train Loss: 0.173425, Train Acc: 0.658974 | Val Loss: 0.186091, Val Acc: 0.577320\n",
      "Epoch 6015 - Train Loss: 0.173411, Train Acc: 0.658974 | Val Loss: 0.186078, Val Acc: 0.577320\n",
      "Epoch 6016 - Train Loss: 0.173398, Train Acc: 0.658974 | Val Loss: 0.186065, Val Acc: 0.577320\n",
      "Epoch 6017 - Train Loss: 0.173385, Train Acc: 0.658974 | Val Loss: 0.186052, Val Acc: 0.577320\n",
      "Epoch 6018 - Train Loss: 0.173372, Train Acc: 0.658974 | Val Loss: 0.186039, Val Acc: 0.577320\n",
      "Epoch 6019 - Train Loss: 0.173358, Train Acc: 0.658974 | Val Loss: 0.186026, Val Acc: 0.577320\n",
      "Epoch 6020 - Train Loss: 0.173345, Train Acc: 0.658974 | Val Loss: 0.186013, Val Acc: 0.577320\n",
      "Epoch 6021 - Train Loss: 0.173332, Train Acc: 0.658974 | Val Loss: 0.186000, Val Acc: 0.577320\n",
      "Epoch 6022 - Train Loss: 0.173319, Train Acc: 0.658974 | Val Loss: 0.185987, Val Acc: 0.577320\n",
      "Epoch 6023 - Train Loss: 0.173305, Train Acc: 0.658974 | Val Loss: 0.185974, Val Acc: 0.577320\n",
      "Epoch 6024 - Train Loss: 0.173292, Train Acc: 0.658974 | Val Loss: 0.185961, Val Acc: 0.577320\n",
      "Epoch 6025 - Train Loss: 0.173279, Train Acc: 0.658974 | Val Loss: 0.185948, Val Acc: 0.577320\n",
      "Epoch 6026 - Train Loss: 0.173266, Train Acc: 0.658974 | Val Loss: 0.185935, Val Acc: 0.577320\n",
      "Epoch 6027 - Train Loss: 0.173253, Train Acc: 0.658974 | Val Loss: 0.185922, Val Acc: 0.577320\n",
      "Epoch 6028 - Train Loss: 0.173239, Train Acc: 0.658974 | Val Loss: 0.185909, Val Acc: 0.577320\n",
      "Epoch 6029 - Train Loss: 0.173226, Train Acc: 0.658974 | Val Loss: 0.185896, Val Acc: 0.577320\n",
      "Epoch 6030 - Train Loss: 0.173213, Train Acc: 0.658974 | Val Loss: 0.185883, Val Acc: 0.577320\n",
      "Epoch 6031 - Train Loss: 0.173200, Train Acc: 0.658974 | Val Loss: 0.185871, Val Acc: 0.577320\n",
      "Epoch 6032 - Train Loss: 0.173186, Train Acc: 0.658974 | Val Loss: 0.185858, Val Acc: 0.577320\n",
      "Epoch 6033 - Train Loss: 0.173173, Train Acc: 0.658974 | Val Loss: 0.185845, Val Acc: 0.577320\n",
      "Epoch 6034 - Train Loss: 0.173160, Train Acc: 0.658974 | Val Loss: 0.185832, Val Acc: 0.577320\n",
      "Epoch 6035 - Train Loss: 0.173147, Train Acc: 0.658974 | Val Loss: 0.185819, Val Acc: 0.577320\n",
      "Epoch 6036 - Train Loss: 0.173133, Train Acc: 0.658974 | Val Loss: 0.185806, Val Acc: 0.577320\n",
      "Epoch 6037 - Train Loss: 0.173120, Train Acc: 0.658974 | Val Loss: 0.185793, Val Acc: 0.577320\n",
      "Epoch 6038 - Train Loss: 0.173107, Train Acc: 0.658974 | Val Loss: 0.185780, Val Acc: 0.577320\n",
      "Epoch 6039 - Train Loss: 0.173094, Train Acc: 0.658974 | Val Loss: 0.185767, Val Acc: 0.577320\n",
      "Epoch 6040 - Train Loss: 0.173081, Train Acc: 0.658974 | Val Loss: 0.185755, Val Acc: 0.577320\n",
      "Epoch 6041 - Train Loss: 0.173067, Train Acc: 0.658974 | Val Loss: 0.185742, Val Acc: 0.577320\n",
      "Epoch 6042 - Train Loss: 0.173054, Train Acc: 0.658974 | Val Loss: 0.185729, Val Acc: 0.577320\n",
      "Epoch 6043 - Train Loss: 0.173041, Train Acc: 0.658974 | Val Loss: 0.185716, Val Acc: 0.577320\n",
      "Epoch 6044 - Train Loss: 0.173028, Train Acc: 0.658974 | Val Loss: 0.185703, Val Acc: 0.577320\n",
      "Epoch 6045 - Train Loss: 0.173014, Train Acc: 0.658974 | Val Loss: 0.185690, Val Acc: 0.577320\n",
      "Epoch 6046 - Train Loss: 0.173001, Train Acc: 0.658974 | Val Loss: 0.185677, Val Acc: 0.577320\n",
      "Epoch 6047 - Train Loss: 0.172988, Train Acc: 0.658974 | Val Loss: 0.185664, Val Acc: 0.577320\n",
      "Epoch 6048 - Train Loss: 0.172975, Train Acc: 0.658974 | Val Loss: 0.185652, Val Acc: 0.577320\n",
      "Epoch 6049 - Train Loss: 0.172962, Train Acc: 0.658974 | Val Loss: 0.185639, Val Acc: 0.577320\n",
      "Epoch 6050 - Train Loss: 0.172948, Train Acc: 0.658974 | Val Loss: 0.185626, Val Acc: 0.577320\n",
      "Epoch 6051 - Train Loss: 0.172935, Train Acc: 0.658974 | Val Loss: 0.185613, Val Acc: 0.577320\n",
      "Epoch 6052 - Train Loss: 0.172922, Train Acc: 0.658974 | Val Loss: 0.185600, Val Acc: 0.577320\n",
      "Epoch 6053 - Train Loss: 0.172909, Train Acc: 0.658974 | Val Loss: 0.185587, Val Acc: 0.577320\n",
      "Epoch 6054 - Train Loss: 0.172896, Train Acc: 0.658974 | Val Loss: 0.185574, Val Acc: 0.577320\n",
      "Epoch 6055 - Train Loss: 0.172882, Train Acc: 0.658974 | Val Loss: 0.185561, Val Acc: 0.577320\n",
      "Epoch 6056 - Train Loss: 0.172869, Train Acc: 0.658974 | Val Loss: 0.185549, Val Acc: 0.577320\n",
      "Epoch 6057 - Train Loss: 0.172856, Train Acc: 0.658974 | Val Loss: 0.185536, Val Acc: 0.577320\n",
      "Epoch 6058 - Train Loss: 0.172843, Train Acc: 0.658974 | Val Loss: 0.185523, Val Acc: 0.577320\n",
      "Epoch 6059 - Train Loss: 0.172830, Train Acc: 0.658974 | Val Loss: 0.185510, Val Acc: 0.577320\n",
      "Epoch 6060 - Train Loss: 0.172816, Train Acc: 0.658974 | Val Loss: 0.185497, Val Acc: 0.577320\n",
      "Epoch 6061 - Train Loss: 0.172803, Train Acc: 0.658974 | Val Loss: 0.185484, Val Acc: 0.577320\n",
      "Epoch 6062 - Train Loss: 0.172790, Train Acc: 0.658974 | Val Loss: 0.185471, Val Acc: 0.577320\n",
      "Epoch 6063 - Train Loss: 0.172777, Train Acc: 0.658974 | Val Loss: 0.185459, Val Acc: 0.577320\n",
      "Epoch 6064 - Train Loss: 0.172764, Train Acc: 0.658974 | Val Loss: 0.185446, Val Acc: 0.577320\n",
      "Epoch 6065 - Train Loss: 0.172750, Train Acc: 0.658974 | Val Loss: 0.185433, Val Acc: 0.577320\n",
      "Epoch 6066 - Train Loss: 0.172737, Train Acc: 0.658974 | Val Loss: 0.185420, Val Acc: 0.577320\n",
      "Epoch 6067 - Train Loss: 0.172724, Train Acc: 0.658974 | Val Loss: 0.185407, Val Acc: 0.577320\n",
      "Epoch 6068 - Train Loss: 0.172711, Train Acc: 0.658974 | Val Loss: 0.185394, Val Acc: 0.577320\n",
      "Epoch 6069 - Train Loss: 0.172698, Train Acc: 0.658974 | Val Loss: 0.185382, Val Acc: 0.577320\n",
      "Epoch 6070 - Train Loss: 0.172684, Train Acc: 0.658974 | Val Loss: 0.185369, Val Acc: 0.577320\n",
      "Epoch 6071 - Train Loss: 0.172671, Train Acc: 0.658974 | Val Loss: 0.185356, Val Acc: 0.577320\n",
      "Epoch 6072 - Train Loss: 0.172658, Train Acc: 0.658974 | Val Loss: 0.185343, Val Acc: 0.577320\n",
      "Epoch 6073 - Train Loss: 0.172645, Train Acc: 0.658974 | Val Loss: 0.185330, Val Acc: 0.577320\n",
      "Epoch 6074 - Train Loss: 0.172632, Train Acc: 0.658974 | Val Loss: 0.185317, Val Acc: 0.577320\n",
      "Epoch 6075 - Train Loss: 0.172618, Train Acc: 0.658974 | Val Loss: 0.185305, Val Acc: 0.577320\n",
      "Epoch 6076 - Train Loss: 0.172605, Train Acc: 0.658974 | Val Loss: 0.185292, Val Acc: 0.587629\n",
      "Epoch 6077 - Train Loss: 0.172592, Train Acc: 0.660256 | Val Loss: 0.185279, Val Acc: 0.587629\n",
      "Epoch 6078 - Train Loss: 0.172579, Train Acc: 0.660256 | Val Loss: 0.185266, Val Acc: 0.587629\n",
      "Epoch 6079 - Train Loss: 0.172566, Train Acc: 0.660256 | Val Loss: 0.185253, Val Acc: 0.587629\n",
      "Epoch 6080 - Train Loss: 0.172553, Train Acc: 0.660256 | Val Loss: 0.185240, Val Acc: 0.587629\n",
      "Epoch 6081 - Train Loss: 0.172539, Train Acc: 0.660256 | Val Loss: 0.185227, Val Acc: 0.587629\n",
      "Epoch 6082 - Train Loss: 0.172526, Train Acc: 0.660256 | Val Loss: 0.185215, Val Acc: 0.587629\n",
      "Epoch 6083 - Train Loss: 0.172513, Train Acc: 0.660256 | Val Loss: 0.185202, Val Acc: 0.587629\n",
      "Epoch 6084 - Train Loss: 0.172500, Train Acc: 0.660256 | Val Loss: 0.185189, Val Acc: 0.587629\n",
      "Epoch 6085 - Train Loss: 0.172487, Train Acc: 0.660256 | Val Loss: 0.185176, Val Acc: 0.587629\n",
      "Epoch 6086 - Train Loss: 0.172473, Train Acc: 0.660256 | Val Loss: 0.185163, Val Acc: 0.587629\n",
      "Epoch 6087 - Train Loss: 0.172460, Train Acc: 0.660256 | Val Loss: 0.185150, Val Acc: 0.587629\n",
      "Epoch 6088 - Train Loss: 0.172447, Train Acc: 0.660256 | Val Loss: 0.185137, Val Acc: 0.587629\n",
      "Epoch 6089 - Train Loss: 0.172434, Train Acc: 0.660256 | Val Loss: 0.185125, Val Acc: 0.587629\n",
      "Epoch 6090 - Train Loss: 0.172421, Train Acc: 0.660256 | Val Loss: 0.185112, Val Acc: 0.587629\n",
      "Epoch 6091 - Train Loss: 0.172408, Train Acc: 0.661538 | Val Loss: 0.185099, Val Acc: 0.587629\n",
      "Epoch 6092 - Train Loss: 0.172394, Train Acc: 0.661538 | Val Loss: 0.185086, Val Acc: 0.587629\n",
      "Epoch 6093 - Train Loss: 0.172381, Train Acc: 0.661538 | Val Loss: 0.185073, Val Acc: 0.587629\n",
      "Epoch 6094 - Train Loss: 0.172368, Train Acc: 0.661538 | Val Loss: 0.185060, Val Acc: 0.587629\n",
      "Epoch 6095 - Train Loss: 0.172355, Train Acc: 0.661538 | Val Loss: 0.185048, Val Acc: 0.587629\n",
      "Epoch 6096 - Train Loss: 0.172342, Train Acc: 0.661538 | Val Loss: 0.185035, Val Acc: 0.587629\n",
      "Epoch 6097 - Train Loss: 0.172329, Train Acc: 0.661538 | Val Loss: 0.185022, Val Acc: 0.587629\n",
      "Epoch 6098 - Train Loss: 0.172315, Train Acc: 0.661538 | Val Loss: 0.185009, Val Acc: 0.587629\n",
      "Epoch 6099 - Train Loss: 0.172302, Train Acc: 0.661538 | Val Loss: 0.184996, Val Acc: 0.587629\n",
      "Epoch 6100 - Train Loss: 0.172289, Train Acc: 0.661538 | Val Loss: 0.184983, Val Acc: 0.587629\n",
      "Epoch 6101 - Train Loss: 0.172276, Train Acc: 0.661538 | Val Loss: 0.184970, Val Acc: 0.587629\n",
      "Epoch 6102 - Train Loss: 0.172263, Train Acc: 0.661538 | Val Loss: 0.184958, Val Acc: 0.587629\n",
      "Epoch 6103 - Train Loss: 0.172250, Train Acc: 0.661538 | Val Loss: 0.184945, Val Acc: 0.587629\n",
      "Epoch 6104 - Train Loss: 0.172236, Train Acc: 0.661538 | Val Loss: 0.184932, Val Acc: 0.587629\n",
      "Epoch 6105 - Train Loss: 0.172223, Train Acc: 0.661538 | Val Loss: 0.184919, Val Acc: 0.587629\n",
      "Epoch 6106 - Train Loss: 0.172210, Train Acc: 0.661538 | Val Loss: 0.184906, Val Acc: 0.587629\n",
      "Epoch 6107 - Train Loss: 0.172197, Train Acc: 0.661538 | Val Loss: 0.184893, Val Acc: 0.587629\n",
      "Epoch 6108 - Train Loss: 0.172184, Train Acc: 0.661538 | Val Loss: 0.184881, Val Acc: 0.587629\n",
      "Epoch 6109 - Train Loss: 0.172171, Train Acc: 0.661538 | Val Loss: 0.184868, Val Acc: 0.587629\n",
      "Epoch 6110 - Train Loss: 0.172158, Train Acc: 0.661538 | Val Loss: 0.184855, Val Acc: 0.587629\n",
      "Epoch 6111 - Train Loss: 0.172144, Train Acc: 0.661538 | Val Loss: 0.184842, Val Acc: 0.587629\n",
      "Epoch 6112 - Train Loss: 0.172131, Train Acc: 0.661538 | Val Loss: 0.184829, Val Acc: 0.587629\n",
      "Epoch 6113 - Train Loss: 0.172118, Train Acc: 0.661538 | Val Loss: 0.184817, Val Acc: 0.587629\n",
      "Epoch 6114 - Train Loss: 0.172105, Train Acc: 0.661538 | Val Loss: 0.184804, Val Acc: 0.587629\n",
      "Epoch 6115 - Train Loss: 0.172092, Train Acc: 0.661538 | Val Loss: 0.184791, Val Acc: 0.587629\n",
      "Epoch 6116 - Train Loss: 0.172079, Train Acc: 0.661538 | Val Loss: 0.184778, Val Acc: 0.587629\n",
      "Epoch 6117 - Train Loss: 0.172065, Train Acc: 0.661538 | Val Loss: 0.184765, Val Acc: 0.587629\n",
      "Epoch 6118 - Train Loss: 0.172052, Train Acc: 0.661538 | Val Loss: 0.184752, Val Acc: 0.587629\n",
      "Epoch 6119 - Train Loss: 0.172039, Train Acc: 0.661538 | Val Loss: 0.184740, Val Acc: 0.587629\n",
      "Epoch 6120 - Train Loss: 0.172026, Train Acc: 0.661538 | Val Loss: 0.184727, Val Acc: 0.587629\n",
      "Epoch 6121 - Train Loss: 0.172013, Train Acc: 0.661538 | Val Loss: 0.184714, Val Acc: 0.587629\n",
      "Epoch 6122 - Train Loss: 0.172000, Train Acc: 0.661538 | Val Loss: 0.184701, Val Acc: 0.587629\n",
      "Epoch 6123 - Train Loss: 0.171987, Train Acc: 0.661538 | Val Loss: 0.184688, Val Acc: 0.587629\n",
      "Epoch 6124 - Train Loss: 0.171973, Train Acc: 0.661538 | Val Loss: 0.184676, Val Acc: 0.587629\n",
      "Epoch 6125 - Train Loss: 0.171960, Train Acc: 0.661538 | Val Loss: 0.184663, Val Acc: 0.587629\n",
      "Epoch 6126 - Train Loss: 0.171947, Train Acc: 0.661538 | Val Loss: 0.184650, Val Acc: 0.587629\n",
      "Epoch 6127 - Train Loss: 0.171934, Train Acc: 0.661538 | Val Loss: 0.184637, Val Acc: 0.587629\n",
      "Epoch 6128 - Train Loss: 0.171921, Train Acc: 0.661538 | Val Loss: 0.184624, Val Acc: 0.587629\n",
      "Epoch 6129 - Train Loss: 0.171908, Train Acc: 0.661538 | Val Loss: 0.184612, Val Acc: 0.587629\n",
      "Epoch 6130 - Train Loss: 0.171895, Train Acc: 0.661538 | Val Loss: 0.184599, Val Acc: 0.587629\n",
      "Epoch 6131 - Train Loss: 0.171881, Train Acc: 0.661538 | Val Loss: 0.184586, Val Acc: 0.587629\n",
      "Epoch 6132 - Train Loss: 0.171868, Train Acc: 0.661538 | Val Loss: 0.184573, Val Acc: 0.587629\n",
      "Epoch 6133 - Train Loss: 0.171855, Train Acc: 0.661538 | Val Loss: 0.184560, Val Acc: 0.587629\n",
      "Epoch 6134 - Train Loss: 0.171842, Train Acc: 0.661538 | Val Loss: 0.184548, Val Acc: 0.587629\n",
      "Epoch 6135 - Train Loss: 0.171829, Train Acc: 0.661538 | Val Loss: 0.184535, Val Acc: 0.587629\n",
      "Epoch 6136 - Train Loss: 0.171816, Train Acc: 0.661538 | Val Loss: 0.184522, Val Acc: 0.587629\n",
      "Epoch 6137 - Train Loss: 0.171803, Train Acc: 0.661538 | Val Loss: 0.184509, Val Acc: 0.587629\n",
      "Epoch 6138 - Train Loss: 0.171790, Train Acc: 0.661538 | Val Loss: 0.184496, Val Acc: 0.587629\n",
      "Epoch 6139 - Train Loss: 0.171776, Train Acc: 0.661538 | Val Loss: 0.184484, Val Acc: 0.587629\n",
      "Epoch 6140 - Train Loss: 0.171763, Train Acc: 0.661538 | Val Loss: 0.184471, Val Acc: 0.587629\n",
      "Epoch 6141 - Train Loss: 0.171750, Train Acc: 0.661538 | Val Loss: 0.184458, Val Acc: 0.587629\n",
      "Epoch 6142 - Train Loss: 0.171737, Train Acc: 0.661538 | Val Loss: 0.184445, Val Acc: 0.587629\n",
      "Epoch 6143 - Train Loss: 0.171724, Train Acc: 0.661538 | Val Loss: 0.184433, Val Acc: 0.587629\n",
      "Epoch 6144 - Train Loss: 0.171711, Train Acc: 0.661538 | Val Loss: 0.184420, Val Acc: 0.587629\n",
      "Epoch 6145 - Train Loss: 0.171698, Train Acc: 0.661538 | Val Loss: 0.184407, Val Acc: 0.587629\n",
      "Epoch 6146 - Train Loss: 0.171685, Train Acc: 0.661538 | Val Loss: 0.184394, Val Acc: 0.587629\n",
      "Epoch 6147 - Train Loss: 0.171671, Train Acc: 0.661538 | Val Loss: 0.184381, Val Acc: 0.587629\n",
      "Epoch 6148 - Train Loss: 0.171658, Train Acc: 0.661538 | Val Loss: 0.184369, Val Acc: 0.587629\n",
      "Epoch 6149 - Train Loss: 0.171645, Train Acc: 0.661538 | Val Loss: 0.184356, Val Acc: 0.587629\n",
      "Epoch 6150 - Train Loss: 0.171632, Train Acc: 0.661538 | Val Loss: 0.184343, Val Acc: 0.587629\n",
      "Epoch 6151 - Train Loss: 0.171619, Train Acc: 0.661538 | Val Loss: 0.184330, Val Acc: 0.587629\n",
      "Epoch 6152 - Train Loss: 0.171606, Train Acc: 0.661538 | Val Loss: 0.184318, Val Acc: 0.587629\n",
      "Epoch 6153 - Train Loss: 0.171593, Train Acc: 0.661538 | Val Loss: 0.184305, Val Acc: 0.587629\n",
      "Epoch 6154 - Train Loss: 0.171580, Train Acc: 0.661538 | Val Loss: 0.184292, Val Acc: 0.587629\n",
      "Epoch 6155 - Train Loss: 0.171567, Train Acc: 0.661538 | Val Loss: 0.184279, Val Acc: 0.587629\n",
      "Epoch 6156 - Train Loss: 0.171553, Train Acc: 0.661538 | Val Loss: 0.184267, Val Acc: 0.587629\n",
      "Epoch 6157 - Train Loss: 0.171540, Train Acc: 0.661538 | Val Loss: 0.184254, Val Acc: 0.587629\n",
      "Epoch 6158 - Train Loss: 0.171527, Train Acc: 0.661538 | Val Loss: 0.184241, Val Acc: 0.587629\n",
      "Epoch 6159 - Train Loss: 0.171514, Train Acc: 0.661538 | Val Loss: 0.184228, Val Acc: 0.587629\n",
      "Epoch 6160 - Train Loss: 0.171501, Train Acc: 0.661538 | Val Loss: 0.184216, Val Acc: 0.587629\n",
      "Epoch 6161 - Train Loss: 0.171488, Train Acc: 0.661538 | Val Loss: 0.184203, Val Acc: 0.587629\n",
      "Epoch 6162 - Train Loss: 0.171475, Train Acc: 0.661538 | Val Loss: 0.184190, Val Acc: 0.587629\n",
      "Epoch 6163 - Train Loss: 0.171462, Train Acc: 0.661538 | Val Loss: 0.184177, Val Acc: 0.587629\n",
      "Epoch 6164 - Train Loss: 0.171449, Train Acc: 0.661538 | Val Loss: 0.184165, Val Acc: 0.587629\n",
      "Epoch 6165 - Train Loss: 0.171436, Train Acc: 0.661538 | Val Loss: 0.184152, Val Acc: 0.587629\n",
      "Epoch 6166 - Train Loss: 0.171422, Train Acc: 0.661538 | Val Loss: 0.184139, Val Acc: 0.587629\n",
      "Epoch 6167 - Train Loss: 0.171409, Train Acc: 0.661538 | Val Loss: 0.184127, Val Acc: 0.587629\n",
      "Epoch 6168 - Train Loss: 0.171396, Train Acc: 0.661538 | Val Loss: 0.184114, Val Acc: 0.587629\n",
      "Epoch 6169 - Train Loss: 0.171383, Train Acc: 0.661538 | Val Loss: 0.184101, Val Acc: 0.587629\n",
      "Epoch 6170 - Train Loss: 0.171370, Train Acc: 0.662821 | Val Loss: 0.184089, Val Acc: 0.587629\n",
      "Epoch 6171 - Train Loss: 0.171357, Train Acc: 0.661538 | Val Loss: 0.184076, Val Acc: 0.587629\n",
      "Epoch 6172 - Train Loss: 0.171344, Train Acc: 0.661538 | Val Loss: 0.184063, Val Acc: 0.587629\n",
      "Epoch 6173 - Train Loss: 0.171331, Train Acc: 0.661538 | Val Loss: 0.184051, Val Acc: 0.587629\n",
      "Epoch 6174 - Train Loss: 0.171318, Train Acc: 0.661538 | Val Loss: 0.184038, Val Acc: 0.587629\n",
      "Epoch 6175 - Train Loss: 0.171305, Train Acc: 0.661538 | Val Loss: 0.184026, Val Acc: 0.587629\n",
      "Epoch 6176 - Train Loss: 0.171291, Train Acc: 0.661538 | Val Loss: 0.184013, Val Acc: 0.587629\n",
      "Epoch 6177 - Train Loss: 0.171278, Train Acc: 0.661538 | Val Loss: 0.184000, Val Acc: 0.587629\n",
      "Epoch 6178 - Train Loss: 0.171265, Train Acc: 0.661538 | Val Loss: 0.183988, Val Acc: 0.587629\n",
      "Epoch 6179 - Train Loss: 0.171252, Train Acc: 0.661538 | Val Loss: 0.183975, Val Acc: 0.587629\n",
      "Epoch 6180 - Train Loss: 0.171239, Train Acc: 0.661538 | Val Loss: 0.183962, Val Acc: 0.587629\n",
      "Epoch 6181 - Train Loss: 0.171226, Train Acc: 0.661538 | Val Loss: 0.183950, Val Acc: 0.587629\n",
      "Epoch 6182 - Train Loss: 0.171213, Train Acc: 0.661538 | Val Loss: 0.183937, Val Acc: 0.587629\n",
      "Epoch 6183 - Train Loss: 0.171200, Train Acc: 0.661538 | Val Loss: 0.183924, Val Acc: 0.587629\n",
      "Epoch 6184 - Train Loss: 0.171187, Train Acc: 0.661538 | Val Loss: 0.183912, Val Acc: 0.587629\n",
      "Epoch 6185 - Train Loss: 0.171174, Train Acc: 0.661538 | Val Loss: 0.183899, Val Acc: 0.587629\n",
      "Epoch 6186 - Train Loss: 0.171160, Train Acc: 0.661538 | Val Loss: 0.183886, Val Acc: 0.587629\n",
      "Epoch 6187 - Train Loss: 0.171147, Train Acc: 0.661538 | Val Loss: 0.183874, Val Acc: 0.587629\n",
      "Epoch 6188 - Train Loss: 0.171134, Train Acc: 0.661538 | Val Loss: 0.183861, Val Acc: 0.587629\n",
      "Epoch 6189 - Train Loss: 0.171121, Train Acc: 0.661538 | Val Loss: 0.183848, Val Acc: 0.587629\n",
      "Epoch 6190 - Train Loss: 0.171108, Train Acc: 0.661538 | Val Loss: 0.183836, Val Acc: 0.587629\n",
      "Epoch 6191 - Train Loss: 0.171095, Train Acc: 0.661538 | Val Loss: 0.183823, Val Acc: 0.587629\n",
      "Epoch 6192 - Train Loss: 0.171082, Train Acc: 0.661538 | Val Loss: 0.183810, Val Acc: 0.587629\n",
      "Epoch 6193 - Train Loss: 0.171069, Train Acc: 0.661538 | Val Loss: 0.183798, Val Acc: 0.597938\n",
      "Epoch 6194 - Train Loss: 0.171056, Train Acc: 0.661538 | Val Loss: 0.183785, Val Acc: 0.597938\n",
      "Epoch 6195 - Train Loss: 0.171043, Train Acc: 0.661538 | Val Loss: 0.183772, Val Acc: 0.597938\n",
      "Epoch 6196 - Train Loss: 0.171030, Train Acc: 0.661538 | Val Loss: 0.183759, Val Acc: 0.597938\n",
      "Epoch 6197 - Train Loss: 0.171016, Train Acc: 0.661538 | Val Loss: 0.183747, Val Acc: 0.597938\n",
      "Epoch 6198 - Train Loss: 0.171003, Train Acc: 0.661538 | Val Loss: 0.183734, Val Acc: 0.597938\n",
      "Epoch 6199 - Train Loss: 0.170990, Train Acc: 0.661538 | Val Loss: 0.183721, Val Acc: 0.597938\n",
      "Epoch 6200 - Train Loss: 0.170977, Train Acc: 0.661538 | Val Loss: 0.183709, Val Acc: 0.597938\n",
      "Epoch 6201 - Train Loss: 0.170964, Train Acc: 0.661538 | Val Loss: 0.183696, Val Acc: 0.597938\n",
      "Epoch 6202 - Train Loss: 0.170951, Train Acc: 0.661538 | Val Loss: 0.183683, Val Acc: 0.597938\n",
      "Epoch 6203 - Train Loss: 0.170938, Train Acc: 0.661538 | Val Loss: 0.183671, Val Acc: 0.597938\n",
      "Epoch 6204 - Train Loss: 0.170925, Train Acc: 0.661538 | Val Loss: 0.183658, Val Acc: 0.597938\n",
      "Epoch 6205 - Train Loss: 0.170912, Train Acc: 0.661538 | Val Loss: 0.183645, Val Acc: 0.597938\n",
      "Epoch 6206 - Train Loss: 0.170899, Train Acc: 0.661538 | Val Loss: 0.183633, Val Acc: 0.597938\n",
      "Epoch 6207 - Train Loss: 0.170886, Train Acc: 0.661538 | Val Loss: 0.183620, Val Acc: 0.597938\n",
      "Epoch 6208 - Train Loss: 0.170873, Train Acc: 0.661538 | Val Loss: 0.183607, Val Acc: 0.597938\n",
      "Epoch 6209 - Train Loss: 0.170860, Train Acc: 0.661538 | Val Loss: 0.183595, Val Acc: 0.597938\n",
      "Epoch 6210 - Train Loss: 0.170846, Train Acc: 0.661538 | Val Loss: 0.183582, Val Acc: 0.597938\n",
      "Epoch 6211 - Train Loss: 0.170833, Train Acc: 0.661538 | Val Loss: 0.183569, Val Acc: 0.597938\n",
      "Epoch 6212 - Train Loss: 0.170820, Train Acc: 0.661538 | Val Loss: 0.183557, Val Acc: 0.597938\n",
      "Epoch 6213 - Train Loss: 0.170807, Train Acc: 0.661538 | Val Loss: 0.183544, Val Acc: 0.597938\n",
      "Epoch 6214 - Train Loss: 0.170794, Train Acc: 0.661538 | Val Loss: 0.183531, Val Acc: 0.597938\n",
      "Epoch 6215 - Train Loss: 0.170781, Train Acc: 0.661538 | Val Loss: 0.183519, Val Acc: 0.597938\n",
      "Epoch 6216 - Train Loss: 0.170768, Train Acc: 0.661538 | Val Loss: 0.183506, Val Acc: 0.597938\n",
      "Epoch 6217 - Train Loss: 0.170755, Train Acc: 0.661538 | Val Loss: 0.183494, Val Acc: 0.597938\n",
      "Epoch 6218 - Train Loss: 0.170742, Train Acc: 0.661538 | Val Loss: 0.183481, Val Acc: 0.597938\n",
      "Epoch 6219 - Train Loss: 0.170729, Train Acc: 0.661538 | Val Loss: 0.183468, Val Acc: 0.597938\n",
      "Epoch 6220 - Train Loss: 0.170716, Train Acc: 0.661538 | Val Loss: 0.183456, Val Acc: 0.597938\n",
      "Epoch 6221 - Train Loss: 0.170703, Train Acc: 0.661538 | Val Loss: 0.183443, Val Acc: 0.597938\n",
      "Epoch 6222 - Train Loss: 0.170690, Train Acc: 0.661538 | Val Loss: 0.183431, Val Acc: 0.597938\n",
      "Epoch 6223 - Train Loss: 0.170677, Train Acc: 0.661538 | Val Loss: 0.183418, Val Acc: 0.597938\n",
      "Epoch 6224 - Train Loss: 0.170664, Train Acc: 0.661538 | Val Loss: 0.183406, Val Acc: 0.597938\n",
      "Epoch 6225 - Train Loss: 0.170651, Train Acc: 0.661538 | Val Loss: 0.183393, Val Acc: 0.597938\n",
      "Epoch 6226 - Train Loss: 0.170638, Train Acc: 0.661538 | Val Loss: 0.183380, Val Acc: 0.597938\n",
      "Epoch 6227 - Train Loss: 0.170624, Train Acc: 0.661538 | Val Loss: 0.183368, Val Acc: 0.597938\n",
      "Epoch 6228 - Train Loss: 0.170611, Train Acc: 0.661538 | Val Loss: 0.183355, Val Acc: 0.597938\n",
      "Epoch 6229 - Train Loss: 0.170598, Train Acc: 0.662821 | Val Loss: 0.183343, Val Acc: 0.597938\n",
      "Epoch 6230 - Train Loss: 0.170585, Train Acc: 0.662821 | Val Loss: 0.183330, Val Acc: 0.597938\n",
      "Epoch 6231 - Train Loss: 0.170572, Train Acc: 0.662821 | Val Loss: 0.183318, Val Acc: 0.597938\n",
      "Epoch 6232 - Train Loss: 0.170559, Train Acc: 0.662821 | Val Loss: 0.183305, Val Acc: 0.597938\n",
      "Epoch 6233 - Train Loss: 0.170546, Train Acc: 0.662821 | Val Loss: 0.183292, Val Acc: 0.597938\n",
      "Epoch 6234 - Train Loss: 0.170533, Train Acc: 0.662821 | Val Loss: 0.183280, Val Acc: 0.597938\n",
      "Epoch 6235 - Train Loss: 0.170520, Train Acc: 0.662821 | Val Loss: 0.183267, Val Acc: 0.597938\n",
      "Epoch 6236 - Train Loss: 0.170507, Train Acc: 0.662821 | Val Loss: 0.183255, Val Acc: 0.597938\n",
      "Epoch 6237 - Train Loss: 0.170494, Train Acc: 0.662821 | Val Loss: 0.183242, Val Acc: 0.597938\n",
      "Epoch 6238 - Train Loss: 0.170481, Train Acc: 0.662821 | Val Loss: 0.183230, Val Acc: 0.597938\n",
      "Epoch 6239 - Train Loss: 0.170468, Train Acc: 0.662821 | Val Loss: 0.183217, Val Acc: 0.597938\n",
      "Epoch 6240 - Train Loss: 0.170455, Train Acc: 0.662821 | Val Loss: 0.183204, Val Acc: 0.597938\n",
      "Epoch 6241 - Train Loss: 0.170442, Train Acc: 0.662821 | Val Loss: 0.183192, Val Acc: 0.597938\n",
      "Epoch 6242 - Train Loss: 0.170429, Train Acc: 0.662821 | Val Loss: 0.183179, Val Acc: 0.597938\n",
      "Epoch 6243 - Train Loss: 0.170416, Train Acc: 0.662821 | Val Loss: 0.183167, Val Acc: 0.597938\n",
      "Epoch 6244 - Train Loss: 0.170403, Train Acc: 0.662821 | Val Loss: 0.183154, Val Acc: 0.597938\n",
      "Epoch 6245 - Train Loss: 0.170390, Train Acc: 0.662821 | Val Loss: 0.183142, Val Acc: 0.597938\n",
      "Epoch 6246 - Train Loss: 0.170377, Train Acc: 0.662821 | Val Loss: 0.183129, Val Acc: 0.597938\n",
      "Epoch 6247 - Train Loss: 0.170364, Train Acc: 0.662821 | Val Loss: 0.183116, Val Acc: 0.597938\n",
      "Epoch 6248 - Train Loss: 0.170351, Train Acc: 0.662821 | Val Loss: 0.183104, Val Acc: 0.597938\n",
      "Epoch 6249 - Train Loss: 0.170338, Train Acc: 0.662821 | Val Loss: 0.183091, Val Acc: 0.597938\n",
      "Epoch 6250 - Train Loss: 0.170325, Train Acc: 0.662821 | Val Loss: 0.183079, Val Acc: 0.597938\n",
      "Epoch 6251 - Train Loss: 0.170312, Train Acc: 0.662821 | Val Loss: 0.183066, Val Acc: 0.597938\n",
      "Epoch 6252 - Train Loss: 0.170299, Train Acc: 0.662821 | Val Loss: 0.183054, Val Acc: 0.597938\n",
      "Epoch 6253 - Train Loss: 0.170285, Train Acc: 0.662821 | Val Loss: 0.183041, Val Acc: 0.597938\n",
      "Epoch 6254 - Train Loss: 0.170272, Train Acc: 0.662821 | Val Loss: 0.183028, Val Acc: 0.597938\n",
      "Epoch 6255 - Train Loss: 0.170259, Train Acc: 0.662821 | Val Loss: 0.183016, Val Acc: 0.597938\n",
      "Epoch 6256 - Train Loss: 0.170246, Train Acc: 0.662821 | Val Loss: 0.183003, Val Acc: 0.597938\n",
      "Epoch 6257 - Train Loss: 0.170233, Train Acc: 0.662821 | Val Loss: 0.182991, Val Acc: 0.597938\n",
      "Epoch 6258 - Train Loss: 0.170220, Train Acc: 0.662821 | Val Loss: 0.182978, Val Acc: 0.597938\n",
      "Epoch 6259 - Train Loss: 0.170207, Train Acc: 0.662821 | Val Loss: 0.182966, Val Acc: 0.597938\n",
      "Epoch 6260 - Train Loss: 0.170194, Train Acc: 0.662821 | Val Loss: 0.182953, Val Acc: 0.597938\n",
      "Epoch 6261 - Train Loss: 0.170181, Train Acc: 0.662821 | Val Loss: 0.182941, Val Acc: 0.597938\n",
      "Epoch 6262 - Train Loss: 0.170168, Train Acc: 0.662821 | Val Loss: 0.182928, Val Acc: 0.597938\n",
      "Epoch 6263 - Train Loss: 0.170155, Train Acc: 0.662821 | Val Loss: 0.182915, Val Acc: 0.597938\n",
      "Epoch 6264 - Train Loss: 0.170142, Train Acc: 0.662821 | Val Loss: 0.182903, Val Acc: 0.597938\n",
      "Epoch 6265 - Train Loss: 0.170129, Train Acc: 0.662821 | Val Loss: 0.182890, Val Acc: 0.597938\n",
      "Epoch 6266 - Train Loss: 0.170116, Train Acc: 0.662821 | Val Loss: 0.182878, Val Acc: 0.597938\n",
      "Epoch 6267 - Train Loss: 0.170103, Train Acc: 0.662821 | Val Loss: 0.182865, Val Acc: 0.597938\n",
      "Epoch 6268 - Train Loss: 0.170090, Train Acc: 0.662821 | Val Loss: 0.182853, Val Acc: 0.597938\n",
      "Epoch 6269 - Train Loss: 0.170077, Train Acc: 0.662821 | Val Loss: 0.182840, Val Acc: 0.597938\n",
      "Epoch 6270 - Train Loss: 0.170064, Train Acc: 0.662821 | Val Loss: 0.182828, Val Acc: 0.597938\n",
      "Epoch 6271 - Train Loss: 0.170051, Train Acc: 0.662821 | Val Loss: 0.182815, Val Acc: 0.597938\n",
      "Epoch 6272 - Train Loss: 0.170038, Train Acc: 0.662821 | Val Loss: 0.182803, Val Acc: 0.597938\n",
      "Epoch 6273 - Train Loss: 0.170025, Train Acc: 0.662821 | Val Loss: 0.182790, Val Acc: 0.597938\n",
      "Epoch 6274 - Train Loss: 0.170012, Train Acc: 0.662821 | Val Loss: 0.182778, Val Acc: 0.597938\n",
      "Epoch 6275 - Train Loss: 0.169999, Train Acc: 0.662821 | Val Loss: 0.182765, Val Acc: 0.597938\n",
      "Epoch 6276 - Train Loss: 0.169986, Train Acc: 0.662821 | Val Loss: 0.182753, Val Acc: 0.597938\n",
      "Epoch 6277 - Train Loss: 0.169973, Train Acc: 0.662821 | Val Loss: 0.182740, Val Acc: 0.597938\n",
      "Epoch 6278 - Train Loss: 0.169960, Train Acc: 0.662821 | Val Loss: 0.182728, Val Acc: 0.597938\n",
      "Epoch 6279 - Train Loss: 0.169947, Train Acc: 0.662821 | Val Loss: 0.182715, Val Acc: 0.597938\n",
      "Epoch 6280 - Train Loss: 0.169934, Train Acc: 0.662821 | Val Loss: 0.182703, Val Acc: 0.597938\n",
      "Epoch 6281 - Train Loss: 0.169921, Train Acc: 0.662821 | Val Loss: 0.182690, Val Acc: 0.597938\n",
      "Epoch 6282 - Train Loss: 0.169908, Train Acc: 0.662821 | Val Loss: 0.182678, Val Acc: 0.597938\n",
      "Epoch 6283 - Train Loss: 0.169895, Train Acc: 0.662821 | Val Loss: 0.182665, Val Acc: 0.597938\n",
      "Epoch 6284 - Train Loss: 0.169882, Train Acc: 0.662821 | Val Loss: 0.182653, Val Acc: 0.597938\n",
      "Epoch 6285 - Train Loss: 0.169869, Train Acc: 0.662821 | Val Loss: 0.182640, Val Acc: 0.597938\n",
      "Epoch 6286 - Train Loss: 0.169856, Train Acc: 0.662821 | Val Loss: 0.182628, Val Acc: 0.597938\n",
      "Epoch 6287 - Train Loss: 0.169843, Train Acc: 0.662821 | Val Loss: 0.182615, Val Acc: 0.597938\n",
      "Epoch 6288 - Train Loss: 0.169830, Train Acc: 0.662821 | Val Loss: 0.182603, Val Acc: 0.597938\n",
      "Epoch 6289 - Train Loss: 0.169817, Train Acc: 0.662821 | Val Loss: 0.182590, Val Acc: 0.597938\n",
      "Epoch 6290 - Train Loss: 0.169804, Train Acc: 0.662821 | Val Loss: 0.182578, Val Acc: 0.597938\n",
      "Epoch 6291 - Train Loss: 0.169791, Train Acc: 0.662821 | Val Loss: 0.182565, Val Acc: 0.597938\n",
      "Epoch 6292 - Train Loss: 0.169778, Train Acc: 0.662821 | Val Loss: 0.182552, Val Acc: 0.597938\n",
      "Epoch 6293 - Train Loss: 0.169765, Train Acc: 0.662821 | Val Loss: 0.182540, Val Acc: 0.597938\n",
      "Epoch 6294 - Train Loss: 0.169752, Train Acc: 0.662821 | Val Loss: 0.182527, Val Acc: 0.597938\n",
      "Epoch 6295 - Train Loss: 0.169739, Train Acc: 0.662821 | Val Loss: 0.182515, Val Acc: 0.597938\n",
      "Epoch 6296 - Train Loss: 0.169726, Train Acc: 0.662821 | Val Loss: 0.182502, Val Acc: 0.597938\n",
      "Epoch 6297 - Train Loss: 0.169713, Train Acc: 0.662821 | Val Loss: 0.182490, Val Acc: 0.597938\n",
      "Epoch 6298 - Train Loss: 0.169700, Train Acc: 0.662821 | Val Loss: 0.182477, Val Acc: 0.597938\n",
      "Epoch 6299 - Train Loss: 0.169687, Train Acc: 0.662821 | Val Loss: 0.182465, Val Acc: 0.597938\n",
      "Epoch 6300 - Train Loss: 0.169674, Train Acc: 0.662821 | Val Loss: 0.182453, Val Acc: 0.597938\n",
      "Epoch 6301 - Train Loss: 0.169661, Train Acc: 0.662821 | Val Loss: 0.182440, Val Acc: 0.597938\n",
      "Epoch 6302 - Train Loss: 0.169648, Train Acc: 0.662821 | Val Loss: 0.182428, Val Acc: 0.597938\n",
      "Epoch 6303 - Train Loss: 0.169635, Train Acc: 0.662821 | Val Loss: 0.182415, Val Acc: 0.597938\n",
      "Epoch 6304 - Train Loss: 0.169622, Train Acc: 0.662821 | Val Loss: 0.182403, Val Acc: 0.597938\n",
      "Epoch 6305 - Train Loss: 0.169609, Train Acc: 0.662821 | Val Loss: 0.182390, Val Acc: 0.597938\n",
      "Epoch 6306 - Train Loss: 0.169596, Train Acc: 0.662821 | Val Loss: 0.182378, Val Acc: 0.597938\n",
      "Epoch 6307 - Train Loss: 0.169583, Train Acc: 0.662821 | Val Loss: 0.182365, Val Acc: 0.597938\n",
      "Epoch 6308 - Train Loss: 0.169570, Train Acc: 0.662821 | Val Loss: 0.182353, Val Acc: 0.597938\n",
      "Epoch 6309 - Train Loss: 0.169557, Train Acc: 0.662821 | Val Loss: 0.182340, Val Acc: 0.597938\n",
      "Epoch 6310 - Train Loss: 0.169544, Train Acc: 0.662821 | Val Loss: 0.182328, Val Acc: 0.597938\n",
      "Epoch 6311 - Train Loss: 0.169532, Train Acc: 0.662821 | Val Loss: 0.182315, Val Acc: 0.597938\n",
      "Epoch 6312 - Train Loss: 0.169519, Train Acc: 0.662821 | Val Loss: 0.182303, Val Acc: 0.597938\n",
      "Epoch 6313 - Train Loss: 0.169506, Train Acc: 0.662821 | Val Loss: 0.182290, Val Acc: 0.597938\n",
      "Epoch 6314 - Train Loss: 0.169493, Train Acc: 0.662821 | Val Loss: 0.182278, Val Acc: 0.597938\n",
      "Epoch 6315 - Train Loss: 0.169480, Train Acc: 0.662821 | Val Loss: 0.182265, Val Acc: 0.597938\n",
      "Epoch 6316 - Train Loss: 0.169467, Train Acc: 0.662821 | Val Loss: 0.182253, Val Acc: 0.597938\n",
      "Epoch 6317 - Train Loss: 0.169454, Train Acc: 0.662821 | Val Loss: 0.182240, Val Acc: 0.597938\n",
      "Epoch 6318 - Train Loss: 0.169441, Train Acc: 0.662821 | Val Loss: 0.182228, Val Acc: 0.597938\n",
      "Epoch 6319 - Train Loss: 0.169428, Train Acc: 0.662821 | Val Loss: 0.182215, Val Acc: 0.597938\n",
      "Epoch 6320 - Train Loss: 0.169415, Train Acc: 0.662821 | Val Loss: 0.182203, Val Acc: 0.597938\n",
      "Epoch 6321 - Train Loss: 0.169402, Train Acc: 0.662821 | Val Loss: 0.182190, Val Acc: 0.597938\n",
      "Epoch 6322 - Train Loss: 0.169389, Train Acc: 0.662821 | Val Loss: 0.182178, Val Acc: 0.597938\n",
      "Epoch 6323 - Train Loss: 0.169376, Train Acc: 0.662821 | Val Loss: 0.182165, Val Acc: 0.597938\n",
      "Epoch 6324 - Train Loss: 0.169363, Train Acc: 0.662821 | Val Loss: 0.182153, Val Acc: 0.597938\n",
      "Epoch 6325 - Train Loss: 0.169350, Train Acc: 0.662821 | Val Loss: 0.182140, Val Acc: 0.597938\n",
      "Epoch 6326 - Train Loss: 0.169337, Train Acc: 0.662821 | Val Loss: 0.182128, Val Acc: 0.597938\n",
      "Epoch 6327 - Train Loss: 0.169324, Train Acc: 0.662821 | Val Loss: 0.182116, Val Acc: 0.597938\n",
      "Epoch 6328 - Train Loss: 0.169311, Train Acc: 0.662821 | Val Loss: 0.182103, Val Acc: 0.597938\n",
      "Epoch 6329 - Train Loss: 0.169298, Train Acc: 0.662821 | Val Loss: 0.182091, Val Acc: 0.597938\n",
      "Epoch 6330 - Train Loss: 0.169285, Train Acc: 0.662821 | Val Loss: 0.182078, Val Acc: 0.597938\n",
      "Epoch 6331 - Train Loss: 0.169272, Train Acc: 0.662821 | Val Loss: 0.182066, Val Acc: 0.597938\n",
      "Epoch 6332 - Train Loss: 0.169259, Train Acc: 0.662821 | Val Loss: 0.182053, Val Acc: 0.597938\n",
      "Epoch 6333 - Train Loss: 0.169246, Train Acc: 0.662821 | Val Loss: 0.182041, Val Acc: 0.597938\n",
      "Epoch 6334 - Train Loss: 0.169233, Train Acc: 0.662821 | Val Loss: 0.182028, Val Acc: 0.597938\n",
      "Epoch 6335 - Train Loss: 0.169220, Train Acc: 0.664103 | Val Loss: 0.182016, Val Acc: 0.597938\n",
      "Epoch 6336 - Train Loss: 0.169208, Train Acc: 0.664103 | Val Loss: 0.182003, Val Acc: 0.597938\n",
      "Epoch 6337 - Train Loss: 0.169195, Train Acc: 0.662821 | Val Loss: 0.181991, Val Acc: 0.597938\n",
      "Epoch 6338 - Train Loss: 0.169182, Train Acc: 0.662821 | Val Loss: 0.181978, Val Acc: 0.597938\n",
      "Epoch 6339 - Train Loss: 0.169169, Train Acc: 0.662821 | Val Loss: 0.181966, Val Acc: 0.597938\n",
      "Epoch 6340 - Train Loss: 0.169156, Train Acc: 0.662821 | Val Loss: 0.181954, Val Acc: 0.597938\n",
      "Epoch 6341 - Train Loss: 0.169143, Train Acc: 0.662821 | Val Loss: 0.181941, Val Acc: 0.597938\n",
      "Epoch 6342 - Train Loss: 0.169130, Train Acc: 0.662821 | Val Loss: 0.181929, Val Acc: 0.597938\n",
      "Epoch 6343 - Train Loss: 0.169117, Train Acc: 0.662821 | Val Loss: 0.181916, Val Acc: 0.597938\n",
      "Epoch 6344 - Train Loss: 0.169104, Train Acc: 0.662821 | Val Loss: 0.181904, Val Acc: 0.597938\n",
      "Epoch 6345 - Train Loss: 0.169091, Train Acc: 0.662821 | Val Loss: 0.181891, Val Acc: 0.597938\n",
      "Epoch 6346 - Train Loss: 0.169078, Train Acc: 0.662821 | Val Loss: 0.181879, Val Acc: 0.597938\n",
      "Epoch 6347 - Train Loss: 0.169065, Train Acc: 0.662821 | Val Loss: 0.181866, Val Acc: 0.597938\n",
      "Epoch 6348 - Train Loss: 0.169052, Train Acc: 0.662821 | Val Loss: 0.181854, Val Acc: 0.597938\n",
      "Epoch 6349 - Train Loss: 0.169039, Train Acc: 0.662821 | Val Loss: 0.181842, Val Acc: 0.597938\n",
      "Epoch 6350 - Train Loss: 0.169026, Train Acc: 0.662821 | Val Loss: 0.181829, Val Acc: 0.597938\n",
      "Epoch 6351 - Train Loss: 0.169013, Train Acc: 0.662821 | Val Loss: 0.181817, Val Acc: 0.597938\n",
      "Epoch 6352 - Train Loss: 0.169000, Train Acc: 0.662821 | Val Loss: 0.181804, Val Acc: 0.597938\n",
      "Epoch 6353 - Train Loss: 0.168988, Train Acc: 0.662821 | Val Loss: 0.181792, Val Acc: 0.597938\n",
      "Epoch 6354 - Train Loss: 0.168975, Train Acc: 0.662821 | Val Loss: 0.181779, Val Acc: 0.597938\n",
      "Epoch 6355 - Train Loss: 0.168962, Train Acc: 0.662821 | Val Loss: 0.181767, Val Acc: 0.597938\n",
      "Epoch 6356 - Train Loss: 0.168949, Train Acc: 0.662821 | Val Loss: 0.181755, Val Acc: 0.597938\n",
      "Epoch 6357 - Train Loss: 0.168936, Train Acc: 0.662821 | Val Loss: 0.181742, Val Acc: 0.597938\n",
      "Epoch 6358 - Train Loss: 0.168923, Train Acc: 0.662821 | Val Loss: 0.181730, Val Acc: 0.597938\n",
      "Epoch 6359 - Train Loss: 0.168910, Train Acc: 0.662821 | Val Loss: 0.181717, Val Acc: 0.597938\n",
      "Epoch 6360 - Train Loss: 0.168897, Train Acc: 0.662821 | Val Loss: 0.181705, Val Acc: 0.597938\n",
      "Epoch 6361 - Train Loss: 0.168884, Train Acc: 0.662821 | Val Loss: 0.181692, Val Acc: 0.597938\n",
      "Epoch 6362 - Train Loss: 0.168871, Train Acc: 0.662821 | Val Loss: 0.181680, Val Acc: 0.597938\n",
      "Epoch 6363 - Train Loss: 0.168858, Train Acc: 0.662821 | Val Loss: 0.181668, Val Acc: 0.597938\n",
      "Epoch 6364 - Train Loss: 0.168845, Train Acc: 0.662821 | Val Loss: 0.181655, Val Acc: 0.597938\n",
      "Epoch 6365 - Train Loss: 0.168832, Train Acc: 0.662821 | Val Loss: 0.181643, Val Acc: 0.597938\n",
      "Epoch 6366 - Train Loss: 0.168820, Train Acc: 0.662821 | Val Loss: 0.181630, Val Acc: 0.597938\n",
      "Epoch 6367 - Train Loss: 0.168807, Train Acc: 0.662821 | Val Loss: 0.181618, Val Acc: 0.597938\n",
      "Epoch 6368 - Train Loss: 0.168794, Train Acc: 0.662821 | Val Loss: 0.181605, Val Acc: 0.597938\n",
      "Epoch 6369 - Train Loss: 0.168781, Train Acc: 0.662821 | Val Loss: 0.181593, Val Acc: 0.597938\n",
      "Epoch 6370 - Train Loss: 0.168768, Train Acc: 0.664103 | Val Loss: 0.181581, Val Acc: 0.597938\n",
      "Epoch 6371 - Train Loss: 0.168755, Train Acc: 0.664103 | Val Loss: 0.181568, Val Acc: 0.597938\n",
      "Epoch 6372 - Train Loss: 0.168742, Train Acc: 0.664103 | Val Loss: 0.181556, Val Acc: 0.597938\n",
      "Epoch 6373 - Train Loss: 0.168729, Train Acc: 0.664103 | Val Loss: 0.181543, Val Acc: 0.597938\n",
      "Epoch 6374 - Train Loss: 0.168716, Train Acc: 0.664103 | Val Loss: 0.181531, Val Acc: 0.597938\n",
      "Epoch 6375 - Train Loss: 0.168703, Train Acc: 0.664103 | Val Loss: 0.181519, Val Acc: 0.597938\n",
      "Epoch 6376 - Train Loss: 0.168690, Train Acc: 0.664103 | Val Loss: 0.181506, Val Acc: 0.597938\n",
      "Epoch 6377 - Train Loss: 0.168677, Train Acc: 0.664103 | Val Loss: 0.181494, Val Acc: 0.597938\n",
      "Epoch 6378 - Train Loss: 0.168665, Train Acc: 0.664103 | Val Loss: 0.181481, Val Acc: 0.597938\n",
      "Epoch 6379 - Train Loss: 0.168652, Train Acc: 0.665385 | Val Loss: 0.181469, Val Acc: 0.597938\n",
      "Epoch 6380 - Train Loss: 0.168639, Train Acc: 0.665385 | Val Loss: 0.181456, Val Acc: 0.597938\n",
      "Epoch 6381 - Train Loss: 0.168626, Train Acc: 0.665385 | Val Loss: 0.181444, Val Acc: 0.597938\n",
      "Epoch 6382 - Train Loss: 0.168613, Train Acc: 0.665385 | Val Loss: 0.181432, Val Acc: 0.597938\n",
      "Epoch 6383 - Train Loss: 0.168600, Train Acc: 0.665385 | Val Loss: 0.181419, Val Acc: 0.597938\n",
      "Epoch 6384 - Train Loss: 0.168587, Train Acc: 0.665385 | Val Loss: 0.181407, Val Acc: 0.597938\n",
      "Epoch 6385 - Train Loss: 0.168574, Train Acc: 0.665385 | Val Loss: 0.181394, Val Acc: 0.597938\n",
      "Epoch 6386 - Train Loss: 0.168561, Train Acc: 0.665385 | Val Loss: 0.181382, Val Acc: 0.597938\n",
      "Epoch 6387 - Train Loss: 0.168548, Train Acc: 0.665385 | Val Loss: 0.181370, Val Acc: 0.597938\n",
      "Epoch 6388 - Train Loss: 0.168536, Train Acc: 0.665385 | Val Loss: 0.181357, Val Acc: 0.597938\n",
      "Epoch 6389 - Train Loss: 0.168523, Train Acc: 0.665385 | Val Loss: 0.181345, Val Acc: 0.597938\n",
      "Epoch 6390 - Train Loss: 0.168510, Train Acc: 0.665385 | Val Loss: 0.181332, Val Acc: 0.597938\n",
      "Epoch 6391 - Train Loss: 0.168497, Train Acc: 0.665385 | Val Loss: 0.181320, Val Acc: 0.597938\n",
      "Epoch 6392 - Train Loss: 0.168484, Train Acc: 0.665385 | Val Loss: 0.181308, Val Acc: 0.597938\n",
      "Epoch 6393 - Train Loss: 0.168471, Train Acc: 0.665385 | Val Loss: 0.181295, Val Acc: 0.597938\n",
      "Epoch 6394 - Train Loss: 0.168458, Train Acc: 0.665385 | Val Loss: 0.181283, Val Acc: 0.597938\n",
      "Epoch 6395 - Train Loss: 0.168445, Train Acc: 0.665385 | Val Loss: 0.181270, Val Acc: 0.597938\n",
      "Epoch 6396 - Train Loss: 0.168432, Train Acc: 0.665385 | Val Loss: 0.181258, Val Acc: 0.608247\n",
      "Epoch 6397 - Train Loss: 0.168420, Train Acc: 0.665385 | Val Loss: 0.181246, Val Acc: 0.608247\n",
      "Epoch 6398 - Train Loss: 0.168407, Train Acc: 0.665385 | Val Loss: 0.181233, Val Acc: 0.608247\n",
      "Epoch 6399 - Train Loss: 0.168394, Train Acc: 0.665385 | Val Loss: 0.181221, Val Acc: 0.608247\n",
      "Epoch 6400 - Train Loss: 0.168381, Train Acc: 0.665385 | Val Loss: 0.181209, Val Acc: 0.608247\n",
      "Epoch 6401 - Train Loss: 0.168368, Train Acc: 0.665385 | Val Loss: 0.181196, Val Acc: 0.608247\n",
      "Epoch 6402 - Train Loss: 0.168355, Train Acc: 0.665385 | Val Loss: 0.181184, Val Acc: 0.608247\n",
      "Epoch 6403 - Train Loss: 0.168342, Train Acc: 0.665385 | Val Loss: 0.181171, Val Acc: 0.608247\n",
      "Epoch 6404 - Train Loss: 0.168329, Train Acc: 0.665385 | Val Loss: 0.181159, Val Acc: 0.608247\n",
      "Epoch 6405 - Train Loss: 0.168316, Train Acc: 0.665385 | Val Loss: 0.181147, Val Acc: 0.608247\n",
      "Epoch 6406 - Train Loss: 0.168304, Train Acc: 0.665385 | Val Loss: 0.181134, Val Acc: 0.608247\n",
      "Epoch 6407 - Train Loss: 0.168291, Train Acc: 0.665385 | Val Loss: 0.181122, Val Acc: 0.608247\n",
      "Epoch 6408 - Train Loss: 0.168278, Train Acc: 0.665385 | Val Loss: 0.181110, Val Acc: 0.608247\n",
      "Epoch 6409 - Train Loss: 0.168265, Train Acc: 0.665385 | Val Loss: 0.181097, Val Acc: 0.608247\n",
      "Epoch 6410 - Train Loss: 0.168252, Train Acc: 0.665385 | Val Loss: 0.181085, Val Acc: 0.608247\n",
      "Epoch 6411 - Train Loss: 0.168239, Train Acc: 0.665385 | Val Loss: 0.181072, Val Acc: 0.608247\n",
      "Epoch 6412 - Train Loss: 0.168226, Train Acc: 0.665385 | Val Loss: 0.181060, Val Acc: 0.608247\n",
      "Epoch 6413 - Train Loss: 0.168213, Train Acc: 0.665385 | Val Loss: 0.181048, Val Acc: 0.608247\n",
      "Epoch 6414 - Train Loss: 0.168201, Train Acc: 0.665385 | Val Loss: 0.181035, Val Acc: 0.608247\n",
      "Epoch 6415 - Train Loss: 0.168188, Train Acc: 0.665385 | Val Loss: 0.181023, Val Acc: 0.608247\n",
      "Epoch 6416 - Train Loss: 0.168175, Train Acc: 0.666667 | Val Loss: 0.181011, Val Acc: 0.608247\n",
      "Epoch 6417 - Train Loss: 0.168162, Train Acc: 0.666667 | Val Loss: 0.180998, Val Acc: 0.608247\n",
      "Epoch 6418 - Train Loss: 0.168149, Train Acc: 0.666667 | Val Loss: 0.180986, Val Acc: 0.608247\n",
      "Epoch 6419 - Train Loss: 0.168136, Train Acc: 0.666667 | Val Loss: 0.180973, Val Acc: 0.608247\n",
      "Epoch 6420 - Train Loss: 0.168123, Train Acc: 0.666667 | Val Loss: 0.180961, Val Acc: 0.608247\n",
      "Epoch 6421 - Train Loss: 0.168110, Train Acc: 0.666667 | Val Loss: 0.180949, Val Acc: 0.608247\n",
      "Epoch 6422 - Train Loss: 0.168098, Train Acc: 0.666667 | Val Loss: 0.180936, Val Acc: 0.608247\n",
      "Epoch 6423 - Train Loss: 0.168085, Train Acc: 0.666667 | Val Loss: 0.180924, Val Acc: 0.608247\n",
      "Epoch 6424 - Train Loss: 0.168072, Train Acc: 0.666667 | Val Loss: 0.180912, Val Acc: 0.608247\n",
      "Epoch 6425 - Train Loss: 0.168059, Train Acc: 0.666667 | Val Loss: 0.180899, Val Acc: 0.608247\n",
      "Epoch 6426 - Train Loss: 0.168046, Train Acc: 0.666667 | Val Loss: 0.180887, Val Acc: 0.608247\n",
      "Epoch 6427 - Train Loss: 0.168033, Train Acc: 0.666667 | Val Loss: 0.180875, Val Acc: 0.608247\n",
      "Epoch 6428 - Train Loss: 0.168020, Train Acc: 0.666667 | Val Loss: 0.180862, Val Acc: 0.608247\n",
      "Epoch 6429 - Train Loss: 0.168008, Train Acc: 0.666667 | Val Loss: 0.180850, Val Acc: 0.608247\n",
      "Epoch 6430 - Train Loss: 0.167995, Train Acc: 0.666667 | Val Loss: 0.180838, Val Acc: 0.608247\n",
      "Epoch 6431 - Train Loss: 0.167982, Train Acc: 0.666667 | Val Loss: 0.180825, Val Acc: 0.608247\n",
      "Epoch 6432 - Train Loss: 0.167969, Train Acc: 0.666667 | Val Loss: 0.180813, Val Acc: 0.608247\n",
      "Epoch 6433 - Train Loss: 0.167956, Train Acc: 0.666667 | Val Loss: 0.180800, Val Acc: 0.608247\n",
      "Epoch 6434 - Train Loss: 0.167943, Train Acc: 0.666667 | Val Loss: 0.180788, Val Acc: 0.608247\n",
      "Epoch 6435 - Train Loss: 0.167930, Train Acc: 0.666667 | Val Loss: 0.180776, Val Acc: 0.608247\n",
      "Epoch 6436 - Train Loss: 0.167918, Train Acc: 0.666667 | Val Loss: 0.180763, Val Acc: 0.608247\n",
      "Epoch 6437 - Train Loss: 0.167905, Train Acc: 0.666667 | Val Loss: 0.180751, Val Acc: 0.608247\n",
      "Epoch 6438 - Train Loss: 0.167892, Train Acc: 0.666667 | Val Loss: 0.180739, Val Acc: 0.608247\n",
      "Epoch 6439 - Train Loss: 0.167879, Train Acc: 0.666667 | Val Loss: 0.180726, Val Acc: 0.608247\n",
      "Epoch 6440 - Train Loss: 0.167866, Train Acc: 0.666667 | Val Loss: 0.180714, Val Acc: 0.608247\n",
      "Epoch 6441 - Train Loss: 0.167853, Train Acc: 0.666667 | Val Loss: 0.180702, Val Acc: 0.608247\n",
      "Epoch 6442 - Train Loss: 0.167840, Train Acc: 0.666667 | Val Loss: 0.180689, Val Acc: 0.608247\n",
      "Epoch 6443 - Train Loss: 0.167828, Train Acc: 0.666667 | Val Loss: 0.180677, Val Acc: 0.608247\n",
      "Epoch 6444 - Train Loss: 0.167815, Train Acc: 0.666667 | Val Loss: 0.180665, Val Acc: 0.608247\n",
      "Epoch 6445 - Train Loss: 0.167802, Train Acc: 0.666667 | Val Loss: 0.180652, Val Acc: 0.608247\n",
      "Epoch 6446 - Train Loss: 0.167789, Train Acc: 0.666667 | Val Loss: 0.180640, Val Acc: 0.608247\n",
      "Epoch 6447 - Train Loss: 0.167776, Train Acc: 0.666667 | Val Loss: 0.180628, Val Acc: 0.608247\n",
      "Epoch 6448 - Train Loss: 0.167763, Train Acc: 0.666667 | Val Loss: 0.180615, Val Acc: 0.608247\n",
      "Epoch 6449 - Train Loss: 0.167751, Train Acc: 0.666667 | Val Loss: 0.180603, Val Acc: 0.608247\n",
      "Epoch 6450 - Train Loss: 0.167738, Train Acc: 0.666667 | Val Loss: 0.180591, Val Acc: 0.608247\n",
      "Epoch 6451 - Train Loss: 0.167725, Train Acc: 0.666667 | Val Loss: 0.180578, Val Acc: 0.608247\n",
      "Epoch 6452 - Train Loss: 0.167712, Train Acc: 0.666667 | Val Loss: 0.180566, Val Acc: 0.608247\n",
      "Epoch 6453 - Train Loss: 0.167699, Train Acc: 0.666667 | Val Loss: 0.180554, Val Acc: 0.608247\n",
      "Epoch 6454 - Train Loss: 0.167686, Train Acc: 0.666667 | Val Loss: 0.180541, Val Acc: 0.608247\n",
      "Epoch 6455 - Train Loss: 0.167673, Train Acc: 0.666667 | Val Loss: 0.180529, Val Acc: 0.608247\n",
      "Epoch 6456 - Train Loss: 0.167661, Train Acc: 0.666667 | Val Loss: 0.180517, Val Acc: 0.608247\n",
      "Epoch 6457 - Train Loss: 0.167648, Train Acc: 0.666667 | Val Loss: 0.180504, Val Acc: 0.608247\n",
      "Epoch 6458 - Train Loss: 0.167635, Train Acc: 0.666667 | Val Loss: 0.180492, Val Acc: 0.608247\n",
      "Epoch 6459 - Train Loss: 0.167622, Train Acc: 0.666667 | Val Loss: 0.180480, Val Acc: 0.608247\n",
      "Epoch 6460 - Train Loss: 0.167609, Train Acc: 0.666667 | Val Loss: 0.180467, Val Acc: 0.608247\n",
      "Epoch 6461 - Train Loss: 0.167596, Train Acc: 0.666667 | Val Loss: 0.180455, Val Acc: 0.608247\n",
      "Epoch 6462 - Train Loss: 0.167584, Train Acc: 0.666667 | Val Loss: 0.180443, Val Acc: 0.608247\n",
      "Epoch 6463 - Train Loss: 0.167571, Train Acc: 0.666667 | Val Loss: 0.180430, Val Acc: 0.608247\n",
      "Epoch 6464 - Train Loss: 0.167558, Train Acc: 0.666667 | Val Loss: 0.180418, Val Acc: 0.608247\n",
      "Epoch 6465 - Train Loss: 0.167545, Train Acc: 0.666667 | Val Loss: 0.180406, Val Acc: 0.608247\n",
      "Epoch 6466 - Train Loss: 0.167532, Train Acc: 0.666667 | Val Loss: 0.180393, Val Acc: 0.608247\n",
      "Epoch 6467 - Train Loss: 0.167520, Train Acc: 0.666667 | Val Loss: 0.180381, Val Acc: 0.608247\n",
      "Epoch 6468 - Train Loss: 0.167507, Train Acc: 0.666667 | Val Loss: 0.180369, Val Acc: 0.608247\n",
      "Epoch 6469 - Train Loss: 0.167494, Train Acc: 0.666667 | Val Loss: 0.180357, Val Acc: 0.608247\n",
      "Epoch 6470 - Train Loss: 0.167481, Train Acc: 0.666667 | Val Loss: 0.180344, Val Acc: 0.608247\n",
      "Epoch 6471 - Train Loss: 0.167468, Train Acc: 0.666667 | Val Loss: 0.180332, Val Acc: 0.608247\n",
      "Epoch 6472 - Train Loss: 0.167455, Train Acc: 0.666667 | Val Loss: 0.180320, Val Acc: 0.608247\n",
      "Epoch 6473 - Train Loss: 0.167443, Train Acc: 0.666667 | Val Loss: 0.180307, Val Acc: 0.608247\n",
      "Epoch 6474 - Train Loss: 0.167430, Train Acc: 0.666667 | Val Loss: 0.180295, Val Acc: 0.608247\n",
      "Epoch 6475 - Train Loss: 0.167417, Train Acc: 0.666667 | Val Loss: 0.180283, Val Acc: 0.608247\n",
      "Epoch 6476 - Train Loss: 0.167404, Train Acc: 0.666667 | Val Loss: 0.180270, Val Acc: 0.608247\n",
      "Epoch 6477 - Train Loss: 0.167391, Train Acc: 0.667949 | Val Loss: 0.180258, Val Acc: 0.608247\n",
      "Epoch 6478 - Train Loss: 0.167379, Train Acc: 0.667949 | Val Loss: 0.180246, Val Acc: 0.608247\n",
      "Epoch 6479 - Train Loss: 0.167366, Train Acc: 0.667949 | Val Loss: 0.180234, Val Acc: 0.608247\n",
      "Epoch 6480 - Train Loss: 0.167353, Train Acc: 0.667949 | Val Loss: 0.180221, Val Acc: 0.608247\n",
      "Epoch 6481 - Train Loss: 0.167340, Train Acc: 0.667949 | Val Loss: 0.180209, Val Acc: 0.608247\n",
      "Epoch 6482 - Train Loss: 0.167327, Train Acc: 0.669231 | Val Loss: 0.180197, Val Acc: 0.608247\n",
      "Epoch 6483 - Train Loss: 0.167314, Train Acc: 0.669231 | Val Loss: 0.180184, Val Acc: 0.608247\n",
      "Epoch 6484 - Train Loss: 0.167302, Train Acc: 0.669231 | Val Loss: 0.180172, Val Acc: 0.608247\n",
      "Epoch 6485 - Train Loss: 0.167289, Train Acc: 0.669231 | Val Loss: 0.180160, Val Acc: 0.608247\n",
      "Epoch 6486 - Train Loss: 0.167276, Train Acc: 0.669231 | Val Loss: 0.180148, Val Acc: 0.608247\n",
      "Epoch 6487 - Train Loss: 0.167263, Train Acc: 0.669231 | Val Loss: 0.180135, Val Acc: 0.608247\n",
      "Epoch 6488 - Train Loss: 0.167250, Train Acc: 0.669231 | Val Loss: 0.180123, Val Acc: 0.608247\n",
      "Epoch 6489 - Train Loss: 0.167238, Train Acc: 0.669231 | Val Loss: 0.180111, Val Acc: 0.608247\n",
      "Epoch 6490 - Train Loss: 0.167225, Train Acc: 0.669231 | Val Loss: 0.180098, Val Acc: 0.608247\n",
      "Epoch 6491 - Train Loss: 0.167212, Train Acc: 0.669231 | Val Loss: 0.180086, Val Acc: 0.608247\n",
      "Epoch 6492 - Train Loss: 0.167199, Train Acc: 0.669231 | Val Loss: 0.180074, Val Acc: 0.608247\n",
      "Epoch 6493 - Train Loss: 0.167186, Train Acc: 0.669231 | Val Loss: 0.180062, Val Acc: 0.608247\n",
      "Epoch 6494 - Train Loss: 0.167174, Train Acc: 0.669231 | Val Loss: 0.180049, Val Acc: 0.608247\n",
      "Epoch 6495 - Train Loss: 0.167161, Train Acc: 0.669231 | Val Loss: 0.180037, Val Acc: 0.608247\n",
      "Epoch 6496 - Train Loss: 0.167148, Train Acc: 0.669231 | Val Loss: 0.180025, Val Acc: 0.608247\n",
      "Epoch 6497 - Train Loss: 0.167135, Train Acc: 0.669231 | Val Loss: 0.180012, Val Acc: 0.608247\n",
      "Epoch 6498 - Train Loss: 0.167122, Train Acc: 0.669231 | Val Loss: 0.180000, Val Acc: 0.608247\n",
      "Epoch 6499 - Train Loss: 0.167110, Train Acc: 0.669231 | Val Loss: 0.179988, Val Acc: 0.608247\n",
      "Epoch 6500 - Train Loss: 0.167097, Train Acc: 0.669231 | Val Loss: 0.179976, Val Acc: 0.608247\n",
      "Epoch 6501 - Train Loss: 0.167084, Train Acc: 0.669231 | Val Loss: 0.179963, Val Acc: 0.608247\n",
      "Epoch 6502 - Train Loss: 0.167071, Train Acc: 0.669231 | Val Loss: 0.179951, Val Acc: 0.608247\n",
      "Epoch 6503 - Train Loss: 0.167058, Train Acc: 0.669231 | Val Loss: 0.179939, Val Acc: 0.608247\n",
      "Epoch 6504 - Train Loss: 0.167046, Train Acc: 0.669231 | Val Loss: 0.179927, Val Acc: 0.608247\n",
      "Epoch 6505 - Train Loss: 0.167033, Train Acc: 0.669231 | Val Loss: 0.179914, Val Acc: 0.608247\n",
      "Epoch 6506 - Train Loss: 0.167020, Train Acc: 0.669231 | Val Loss: 0.179902, Val Acc: 0.608247\n",
      "Epoch 6507 - Train Loss: 0.167007, Train Acc: 0.669231 | Val Loss: 0.179890, Val Acc: 0.618557\n",
      "Epoch 6508 - Train Loss: 0.166994, Train Acc: 0.669231 | Val Loss: 0.179878, Val Acc: 0.618557\n",
      "Epoch 6509 - Train Loss: 0.166982, Train Acc: 0.669231 | Val Loss: 0.179865, Val Acc: 0.618557\n",
      "Epoch 6510 - Train Loss: 0.166969, Train Acc: 0.669231 | Val Loss: 0.179853, Val Acc: 0.618557\n",
      "Epoch 6511 - Train Loss: 0.166956, Train Acc: 0.669231 | Val Loss: 0.179841, Val Acc: 0.618557\n",
      "Epoch 6512 - Train Loss: 0.166943, Train Acc: 0.669231 | Val Loss: 0.179829, Val Acc: 0.618557\n",
      "Epoch 6513 - Train Loss: 0.166931, Train Acc: 0.669231 | Val Loss: 0.179816, Val Acc: 0.618557\n",
      "Epoch 6514 - Train Loss: 0.166918, Train Acc: 0.669231 | Val Loss: 0.179804, Val Acc: 0.618557\n",
      "Epoch 6515 - Train Loss: 0.166905, Train Acc: 0.669231 | Val Loss: 0.179792, Val Acc: 0.618557\n",
      "Epoch 6516 - Train Loss: 0.166892, Train Acc: 0.669231 | Val Loss: 0.179780, Val Acc: 0.618557\n",
      "Epoch 6517 - Train Loss: 0.166879, Train Acc: 0.669231 | Val Loss: 0.179767, Val Acc: 0.618557\n",
      "Epoch 6518 - Train Loss: 0.166867, Train Acc: 0.669231 | Val Loss: 0.179755, Val Acc: 0.618557\n",
      "Epoch 6519 - Train Loss: 0.166854, Train Acc: 0.669231 | Val Loss: 0.179743, Val Acc: 0.618557\n",
      "Epoch 6520 - Train Loss: 0.166841, Train Acc: 0.669231 | Val Loss: 0.179731, Val Acc: 0.618557\n",
      "Epoch 6521 - Train Loss: 0.166828, Train Acc: 0.669231 | Val Loss: 0.179718, Val Acc: 0.618557\n",
      "Epoch 6522 - Train Loss: 0.166815, Train Acc: 0.669231 | Val Loss: 0.179706, Val Acc: 0.618557\n",
      "Epoch 6523 - Train Loss: 0.166803, Train Acc: 0.669231 | Val Loss: 0.179694, Val Acc: 0.618557\n",
      "Epoch 6524 - Train Loss: 0.166790, Train Acc: 0.669231 | Val Loss: 0.179682, Val Acc: 0.618557\n",
      "Epoch 6525 - Train Loss: 0.166777, Train Acc: 0.669231 | Val Loss: 0.179669, Val Acc: 0.618557\n",
      "Epoch 6526 - Train Loss: 0.166764, Train Acc: 0.669231 | Val Loss: 0.179657, Val Acc: 0.618557\n",
      "Epoch 6527 - Train Loss: 0.166752, Train Acc: 0.669231 | Val Loss: 0.179645, Val Acc: 0.618557\n",
      "Epoch 6528 - Train Loss: 0.166739, Train Acc: 0.669231 | Val Loss: 0.179633, Val Acc: 0.618557\n",
      "Epoch 6529 - Train Loss: 0.166726, Train Acc: 0.669231 | Val Loss: 0.179620, Val Acc: 0.618557\n",
      "Epoch 6530 - Train Loss: 0.166713, Train Acc: 0.669231 | Val Loss: 0.179608, Val Acc: 0.618557\n",
      "Epoch 6531 - Train Loss: 0.166701, Train Acc: 0.669231 | Val Loss: 0.179596, Val Acc: 0.618557\n",
      "Epoch 6532 - Train Loss: 0.166688, Train Acc: 0.669231 | Val Loss: 0.179584, Val Acc: 0.618557\n",
      "Epoch 6533 - Train Loss: 0.166675, Train Acc: 0.669231 | Val Loss: 0.179571, Val Acc: 0.618557\n",
      "Epoch 6534 - Train Loss: 0.166662, Train Acc: 0.669231 | Val Loss: 0.179559, Val Acc: 0.618557\n",
      "Epoch 6535 - Train Loss: 0.166649, Train Acc: 0.669231 | Val Loss: 0.179547, Val Acc: 0.618557\n",
      "Epoch 6536 - Train Loss: 0.166637, Train Acc: 0.669231 | Val Loss: 0.179535, Val Acc: 0.618557\n",
      "Epoch 6537 - Train Loss: 0.166624, Train Acc: 0.669231 | Val Loss: 0.179522, Val Acc: 0.618557\n",
      "Epoch 6538 - Train Loss: 0.166611, Train Acc: 0.669231 | Val Loss: 0.179510, Val Acc: 0.618557\n",
      "Epoch 6539 - Train Loss: 0.166598, Train Acc: 0.669231 | Val Loss: 0.179498, Val Acc: 0.618557\n",
      "Epoch 6540 - Train Loss: 0.166586, Train Acc: 0.669231 | Val Loss: 0.179486, Val Acc: 0.618557\n",
      "Epoch 6541 - Train Loss: 0.166573, Train Acc: 0.669231 | Val Loss: 0.179474, Val Acc: 0.618557\n",
      "Epoch 6542 - Train Loss: 0.166560, Train Acc: 0.669231 | Val Loss: 0.179461, Val Acc: 0.618557\n",
      "Epoch 6543 - Train Loss: 0.166547, Train Acc: 0.669231 | Val Loss: 0.179449, Val Acc: 0.618557\n",
      "Epoch 6544 - Train Loss: 0.166535, Train Acc: 0.669231 | Val Loss: 0.179437, Val Acc: 0.618557\n",
      "Epoch 6545 - Train Loss: 0.166522, Train Acc: 0.669231 | Val Loss: 0.179425, Val Acc: 0.618557\n",
      "Epoch 6546 - Train Loss: 0.166509, Train Acc: 0.669231 | Val Loss: 0.179412, Val Acc: 0.618557\n",
      "Epoch 6547 - Train Loss: 0.166496, Train Acc: 0.669231 | Val Loss: 0.179400, Val Acc: 0.618557\n",
      "Epoch 6548 - Train Loss: 0.166484, Train Acc: 0.669231 | Val Loss: 0.179388, Val Acc: 0.618557\n",
      "Epoch 6549 - Train Loss: 0.166471, Train Acc: 0.669231 | Val Loss: 0.179376, Val Acc: 0.618557\n",
      "Epoch 6550 - Train Loss: 0.166458, Train Acc: 0.669231 | Val Loss: 0.179364, Val Acc: 0.618557\n",
      "Epoch 6551 - Train Loss: 0.166445, Train Acc: 0.669231 | Val Loss: 0.179351, Val Acc: 0.618557\n",
      "Epoch 6552 - Train Loss: 0.166433, Train Acc: 0.669231 | Val Loss: 0.179339, Val Acc: 0.618557\n",
      "Epoch 6553 - Train Loss: 0.166420, Train Acc: 0.669231 | Val Loss: 0.179327, Val Acc: 0.618557\n",
      "Epoch 6554 - Train Loss: 0.166407, Train Acc: 0.669231 | Val Loss: 0.179315, Val Acc: 0.618557\n",
      "Epoch 6555 - Train Loss: 0.166394, Train Acc: 0.669231 | Val Loss: 0.179303, Val Acc: 0.618557\n",
      "Epoch 6556 - Train Loss: 0.166382, Train Acc: 0.669231 | Val Loss: 0.179290, Val Acc: 0.618557\n",
      "Epoch 6557 - Train Loss: 0.166369, Train Acc: 0.669231 | Val Loss: 0.179278, Val Acc: 0.618557\n",
      "Epoch 6558 - Train Loss: 0.166356, Train Acc: 0.669231 | Val Loss: 0.179266, Val Acc: 0.618557\n",
      "Epoch 6559 - Train Loss: 0.166343, Train Acc: 0.669231 | Val Loss: 0.179254, Val Acc: 0.618557\n",
      "Epoch 6560 - Train Loss: 0.166331, Train Acc: 0.669231 | Val Loss: 0.179242, Val Acc: 0.618557\n",
      "Epoch 6561 - Train Loss: 0.166318, Train Acc: 0.669231 | Val Loss: 0.179229, Val Acc: 0.618557\n",
      "Epoch 6562 - Train Loss: 0.166305, Train Acc: 0.669231 | Val Loss: 0.179217, Val Acc: 0.618557\n",
      "Epoch 6563 - Train Loss: 0.166292, Train Acc: 0.669231 | Val Loss: 0.179205, Val Acc: 0.618557\n",
      "Epoch 6564 - Train Loss: 0.166280, Train Acc: 0.669231 | Val Loss: 0.179193, Val Acc: 0.618557\n",
      "Epoch 6565 - Train Loss: 0.166267, Train Acc: 0.669231 | Val Loss: 0.179181, Val Acc: 0.618557\n",
      "Epoch 6566 - Train Loss: 0.166254, Train Acc: 0.669231 | Val Loss: 0.179168, Val Acc: 0.618557\n",
      "Epoch 6567 - Train Loss: 0.166241, Train Acc: 0.669231 | Val Loss: 0.179156, Val Acc: 0.618557\n",
      "Epoch 6568 - Train Loss: 0.166229, Train Acc: 0.669231 | Val Loss: 0.179144, Val Acc: 0.618557\n",
      "Epoch 6569 - Train Loss: 0.166216, Train Acc: 0.669231 | Val Loss: 0.179132, Val Acc: 0.618557\n",
      "Epoch 6570 - Train Loss: 0.166203, Train Acc: 0.669231 | Val Loss: 0.179120, Val Acc: 0.618557\n",
      "Epoch 6571 - Train Loss: 0.166190, Train Acc: 0.669231 | Val Loss: 0.179108, Val Acc: 0.618557\n",
      "Epoch 6572 - Train Loss: 0.166178, Train Acc: 0.669231 | Val Loss: 0.179095, Val Acc: 0.618557\n",
      "Epoch 6573 - Train Loss: 0.166165, Train Acc: 0.669231 | Val Loss: 0.179083, Val Acc: 0.618557\n",
      "Epoch 6574 - Train Loss: 0.166152, Train Acc: 0.669231 | Val Loss: 0.179071, Val Acc: 0.618557\n",
      "Epoch 6575 - Train Loss: 0.166140, Train Acc: 0.669231 | Val Loss: 0.179059, Val Acc: 0.618557\n",
      "Epoch 6576 - Train Loss: 0.166127, Train Acc: 0.669231 | Val Loss: 0.179047, Val Acc: 0.618557\n",
      "Epoch 6577 - Train Loss: 0.166114, Train Acc: 0.669231 | Val Loss: 0.179035, Val Acc: 0.618557\n",
      "Epoch 6578 - Train Loss: 0.166101, Train Acc: 0.669231 | Val Loss: 0.179022, Val Acc: 0.618557\n",
      "Epoch 6579 - Train Loss: 0.166089, Train Acc: 0.669231 | Val Loss: 0.179010, Val Acc: 0.618557\n",
      "Epoch 6580 - Train Loss: 0.166076, Train Acc: 0.670513 | Val Loss: 0.178998, Val Acc: 0.618557\n",
      "Epoch 6581 - Train Loss: 0.166063, Train Acc: 0.670513 | Val Loss: 0.178986, Val Acc: 0.618557\n",
      "Epoch 6582 - Train Loss: 0.166050, Train Acc: 0.670513 | Val Loss: 0.178974, Val Acc: 0.618557\n",
      "Epoch 6583 - Train Loss: 0.166038, Train Acc: 0.670513 | Val Loss: 0.178962, Val Acc: 0.618557\n",
      "Epoch 6584 - Train Loss: 0.166025, Train Acc: 0.670513 | Val Loss: 0.178949, Val Acc: 0.618557\n",
      "Epoch 6585 - Train Loss: 0.166012, Train Acc: 0.670513 | Val Loss: 0.178937, Val Acc: 0.618557\n",
      "Epoch 6586 - Train Loss: 0.166000, Train Acc: 0.670513 | Val Loss: 0.178925, Val Acc: 0.618557\n",
      "Epoch 6587 - Train Loss: 0.165987, Train Acc: 0.670513 | Val Loss: 0.178913, Val Acc: 0.618557\n",
      "Epoch 6588 - Train Loss: 0.165974, Train Acc: 0.670513 | Val Loss: 0.178901, Val Acc: 0.618557\n",
      "Epoch 6589 - Train Loss: 0.165961, Train Acc: 0.670513 | Val Loss: 0.178888, Val Acc: 0.618557\n",
      "Epoch 6590 - Train Loss: 0.165949, Train Acc: 0.671795 | Val Loss: 0.178876, Val Acc: 0.618557\n",
      "Epoch 6591 - Train Loss: 0.165936, Train Acc: 0.671795 | Val Loss: 0.178864, Val Acc: 0.618557\n",
      "Epoch 6592 - Train Loss: 0.165923, Train Acc: 0.671795 | Val Loss: 0.178852, Val Acc: 0.628866\n",
      "Epoch 6593 - Train Loss: 0.165911, Train Acc: 0.671795 | Val Loss: 0.178840, Val Acc: 0.628866\n",
      "Epoch 6594 - Train Loss: 0.165898, Train Acc: 0.671795 | Val Loss: 0.178827, Val Acc: 0.628866\n",
      "Epoch 6595 - Train Loss: 0.165885, Train Acc: 0.671795 | Val Loss: 0.178815, Val Acc: 0.628866\n",
      "Epoch 6596 - Train Loss: 0.165872, Train Acc: 0.671795 | Val Loss: 0.178803, Val Acc: 0.628866\n",
      "Epoch 6597 - Train Loss: 0.165860, Train Acc: 0.671795 | Val Loss: 0.178791, Val Acc: 0.628866\n",
      "Epoch 6598 - Train Loss: 0.165847, Train Acc: 0.671795 | Val Loss: 0.178779, Val Acc: 0.628866\n",
      "Epoch 6599 - Train Loss: 0.165834, Train Acc: 0.671795 | Val Loss: 0.178767, Val Acc: 0.628866\n",
      "Epoch 6600 - Train Loss: 0.165822, Train Acc: 0.671795 | Val Loss: 0.178754, Val Acc: 0.628866\n",
      "Epoch 6601 - Train Loss: 0.165809, Train Acc: 0.671795 | Val Loss: 0.178742, Val Acc: 0.628866\n",
      "Epoch 6602 - Train Loss: 0.165796, Train Acc: 0.671795 | Val Loss: 0.178730, Val Acc: 0.628866\n",
      "Epoch 6603 - Train Loss: 0.165784, Train Acc: 0.671795 | Val Loss: 0.178718, Val Acc: 0.628866\n",
      "Epoch 6604 - Train Loss: 0.165771, Train Acc: 0.671795 | Val Loss: 0.178706, Val Acc: 0.628866\n",
      "Epoch 6605 - Train Loss: 0.165758, Train Acc: 0.671795 | Val Loss: 0.178694, Val Acc: 0.628866\n",
      "Epoch 6606 - Train Loss: 0.165745, Train Acc: 0.671795 | Val Loss: 0.178681, Val Acc: 0.628866\n",
      "Epoch 6607 - Train Loss: 0.165733, Train Acc: 0.671795 | Val Loss: 0.178669, Val Acc: 0.628866\n",
      "Epoch 6608 - Train Loss: 0.165720, Train Acc: 0.671795 | Val Loss: 0.178657, Val Acc: 0.628866\n",
      "Epoch 6609 - Train Loss: 0.165707, Train Acc: 0.671795 | Val Loss: 0.178645, Val Acc: 0.628866\n",
      "Epoch 6610 - Train Loss: 0.165695, Train Acc: 0.671795 | Val Loss: 0.178633, Val Acc: 0.628866\n",
      "Epoch 6611 - Train Loss: 0.165682, Train Acc: 0.671795 | Val Loss: 0.178621, Val Acc: 0.628866\n",
      "Epoch 6612 - Train Loss: 0.165669, Train Acc: 0.671795 | Val Loss: 0.178609, Val Acc: 0.628866\n",
      "Epoch 6613 - Train Loss: 0.165657, Train Acc: 0.671795 | Val Loss: 0.178596, Val Acc: 0.628866\n",
      "Epoch 6614 - Train Loss: 0.165644, Train Acc: 0.671795 | Val Loss: 0.178584, Val Acc: 0.628866\n",
      "Epoch 6615 - Train Loss: 0.165631, Train Acc: 0.671795 | Val Loss: 0.178572, Val Acc: 0.628866\n",
      "Epoch 6616 - Train Loss: 0.165619, Train Acc: 0.671795 | Val Loss: 0.178560, Val Acc: 0.628866\n",
      "Epoch 6617 - Train Loss: 0.165606, Train Acc: 0.671795 | Val Loss: 0.178548, Val Acc: 0.628866\n",
      "Epoch 6618 - Train Loss: 0.165593, Train Acc: 0.671795 | Val Loss: 0.178536, Val Acc: 0.628866\n",
      "Epoch 6619 - Train Loss: 0.165580, Train Acc: 0.671795 | Val Loss: 0.178524, Val Acc: 0.628866\n",
      "Epoch 6620 - Train Loss: 0.165568, Train Acc: 0.671795 | Val Loss: 0.178512, Val Acc: 0.628866\n",
      "Epoch 6621 - Train Loss: 0.165555, Train Acc: 0.671795 | Val Loss: 0.178500, Val Acc: 0.628866\n",
      "Epoch 6622 - Train Loss: 0.165542, Train Acc: 0.673077 | Val Loss: 0.178488, Val Acc: 0.628866\n",
      "Epoch 6623 - Train Loss: 0.165530, Train Acc: 0.673077 | Val Loss: 0.178476, Val Acc: 0.628866\n",
      "Epoch 6624 - Train Loss: 0.165517, Train Acc: 0.673077 | Val Loss: 0.178463, Val Acc: 0.628866\n",
      "Epoch 6625 - Train Loss: 0.165504, Train Acc: 0.673077 | Val Loss: 0.178451, Val Acc: 0.628866\n",
      "Epoch 6626 - Train Loss: 0.165492, Train Acc: 0.673077 | Val Loss: 0.178439, Val Acc: 0.628866\n",
      "Epoch 6627 - Train Loss: 0.165479, Train Acc: 0.673077 | Val Loss: 0.178427, Val Acc: 0.628866\n",
      "Epoch 6628 - Train Loss: 0.165466, Train Acc: 0.673077 | Val Loss: 0.178415, Val Acc: 0.628866\n",
      "Epoch 6629 - Train Loss: 0.165454, Train Acc: 0.673077 | Val Loss: 0.178403, Val Acc: 0.628866\n",
      "Epoch 6630 - Train Loss: 0.165441, Train Acc: 0.673077 | Val Loss: 0.178391, Val Acc: 0.628866\n",
      "Epoch 6631 - Train Loss: 0.165428, Train Acc: 0.673077 | Val Loss: 0.178379, Val Acc: 0.628866\n",
      "Epoch 6632 - Train Loss: 0.165416, Train Acc: 0.673077 | Val Loss: 0.178367, Val Acc: 0.628866\n",
      "Epoch 6633 - Train Loss: 0.165403, Train Acc: 0.673077 | Val Loss: 0.178355, Val Acc: 0.628866\n",
      "Epoch 6634 - Train Loss: 0.165390, Train Acc: 0.673077 | Val Loss: 0.178343, Val Acc: 0.628866\n",
      "Epoch 6635 - Train Loss: 0.165378, Train Acc: 0.673077 | Val Loss: 0.178331, Val Acc: 0.628866\n",
      "Epoch 6636 - Train Loss: 0.165365, Train Acc: 0.673077 | Val Loss: 0.178318, Val Acc: 0.628866\n",
      "Epoch 6637 - Train Loss: 0.165352, Train Acc: 0.673077 | Val Loss: 0.178306, Val Acc: 0.628866\n",
      "Epoch 6638 - Train Loss: 0.165340, Train Acc: 0.674359 | Val Loss: 0.178294, Val Acc: 0.628866\n",
      "Epoch 6639 - Train Loss: 0.165327, Train Acc: 0.674359 | Val Loss: 0.178282, Val Acc: 0.628866\n",
      "Epoch 6640 - Train Loss: 0.165314, Train Acc: 0.674359 | Val Loss: 0.178270, Val Acc: 0.628866\n",
      "Epoch 6641 - Train Loss: 0.165302, Train Acc: 0.674359 | Val Loss: 0.178258, Val Acc: 0.628866\n",
      "Epoch 6642 - Train Loss: 0.165289, Train Acc: 0.674359 | Val Loss: 0.178246, Val Acc: 0.628866\n",
      "Epoch 6643 - Train Loss: 0.165276, Train Acc: 0.674359 | Val Loss: 0.178234, Val Acc: 0.628866\n",
      "Epoch 6644 - Train Loss: 0.165264, Train Acc: 0.674359 | Val Loss: 0.178222, Val Acc: 0.628866\n",
      "Epoch 6645 - Train Loss: 0.165251, Train Acc: 0.674359 | Val Loss: 0.178210, Val Acc: 0.628866\n",
      "Epoch 6646 - Train Loss: 0.165238, Train Acc: 0.674359 | Val Loss: 0.178198, Val Acc: 0.628866\n",
      "Epoch 6647 - Train Loss: 0.165226, Train Acc: 0.674359 | Val Loss: 0.178186, Val Acc: 0.628866\n",
      "Epoch 6648 - Train Loss: 0.165213, Train Acc: 0.674359 | Val Loss: 0.178173, Val Acc: 0.628866\n",
      "Epoch 6649 - Train Loss: 0.165200, Train Acc: 0.674359 | Val Loss: 0.178161, Val Acc: 0.628866\n",
      "Epoch 6650 - Train Loss: 0.165188, Train Acc: 0.674359 | Val Loss: 0.178149, Val Acc: 0.628866\n",
      "Epoch 6651 - Train Loss: 0.165175, Train Acc: 0.674359 | Val Loss: 0.178137, Val Acc: 0.628866\n",
      "Epoch 6652 - Train Loss: 0.165162, Train Acc: 0.674359 | Val Loss: 0.178125, Val Acc: 0.628866\n",
      "Epoch 6653 - Train Loss: 0.165150, Train Acc: 0.674359 | Val Loss: 0.178113, Val Acc: 0.628866\n",
      "Epoch 6654 - Train Loss: 0.165137, Train Acc: 0.674359 | Val Loss: 0.178101, Val Acc: 0.628866\n",
      "Epoch 6655 - Train Loss: 0.165125, Train Acc: 0.674359 | Val Loss: 0.178089, Val Acc: 0.628866\n",
      "Epoch 6656 - Train Loss: 0.165112, Train Acc: 0.673077 | Val Loss: 0.178077, Val Acc: 0.628866\n",
      "Epoch 6657 - Train Loss: 0.165099, Train Acc: 0.674359 | Val Loss: 0.178065, Val Acc: 0.628866\n",
      "Epoch 6658 - Train Loss: 0.165087, Train Acc: 0.674359 | Val Loss: 0.178053, Val Acc: 0.628866\n",
      "Epoch 6659 - Train Loss: 0.165074, Train Acc: 0.674359 | Val Loss: 0.178041, Val Acc: 0.628866\n",
      "Epoch 6660 - Train Loss: 0.165061, Train Acc: 0.673077 | Val Loss: 0.178029, Val Acc: 0.628866\n",
      "Epoch 6661 - Train Loss: 0.165049, Train Acc: 0.673077 | Val Loss: 0.178017, Val Acc: 0.628866\n",
      "Epoch 6662 - Train Loss: 0.165036, Train Acc: 0.673077 | Val Loss: 0.178005, Val Acc: 0.628866\n",
      "Epoch 6663 - Train Loss: 0.165023, Train Acc: 0.673077 | Val Loss: 0.177992, Val Acc: 0.628866\n",
      "Epoch 6664 - Train Loss: 0.165011, Train Acc: 0.673077 | Val Loss: 0.177980, Val Acc: 0.628866\n",
      "Epoch 6665 - Train Loss: 0.164998, Train Acc: 0.673077 | Val Loss: 0.177968, Val Acc: 0.628866\n",
      "Epoch 6666 - Train Loss: 0.164985, Train Acc: 0.673077 | Val Loss: 0.177956, Val Acc: 0.628866\n",
      "Epoch 6667 - Train Loss: 0.164973, Train Acc: 0.673077 | Val Loss: 0.177944, Val Acc: 0.628866\n",
      "Epoch 6668 - Train Loss: 0.164960, Train Acc: 0.673077 | Val Loss: 0.177932, Val Acc: 0.628866\n",
      "Epoch 6669 - Train Loss: 0.164948, Train Acc: 0.673077 | Val Loss: 0.177920, Val Acc: 0.628866\n",
      "Epoch 6670 - Train Loss: 0.164935, Train Acc: 0.673077 | Val Loss: 0.177908, Val Acc: 0.628866\n",
      "Epoch 6671 - Train Loss: 0.164922, Train Acc: 0.673077 | Val Loss: 0.177896, Val Acc: 0.628866\n",
      "Epoch 6672 - Train Loss: 0.164910, Train Acc: 0.673077 | Val Loss: 0.177884, Val Acc: 0.628866\n",
      "Epoch 6673 - Train Loss: 0.164897, Train Acc: 0.673077 | Val Loss: 0.177872, Val Acc: 0.628866\n",
      "Epoch 6674 - Train Loss: 0.164884, Train Acc: 0.673077 | Val Loss: 0.177860, Val Acc: 0.628866\n",
      "Epoch 6675 - Train Loss: 0.164872, Train Acc: 0.673077 | Val Loss: 0.177848, Val Acc: 0.628866\n",
      "Epoch 6676 - Train Loss: 0.164859, Train Acc: 0.673077 | Val Loss: 0.177836, Val Acc: 0.628866\n",
      "Epoch 6677 - Train Loss: 0.164847, Train Acc: 0.673077 | Val Loss: 0.177824, Val Acc: 0.628866\n",
      "Epoch 6678 - Train Loss: 0.164834, Train Acc: 0.673077 | Val Loss: 0.177812, Val Acc: 0.628866\n",
      "Epoch 6679 - Train Loss: 0.164821, Train Acc: 0.673077 | Val Loss: 0.177800, Val Acc: 0.628866\n",
      "Epoch 6680 - Train Loss: 0.164809, Train Acc: 0.673077 | Val Loss: 0.177788, Val Acc: 0.628866\n",
      "Epoch 6681 - Train Loss: 0.164796, Train Acc: 0.673077 | Val Loss: 0.177776, Val Acc: 0.628866\n",
      "Epoch 6682 - Train Loss: 0.164783, Train Acc: 0.673077 | Val Loss: 0.177764, Val Acc: 0.628866\n",
      "Epoch 6683 - Train Loss: 0.164771, Train Acc: 0.673077 | Val Loss: 0.177752, Val Acc: 0.628866\n",
      "Epoch 6684 - Train Loss: 0.164758, Train Acc: 0.673077 | Val Loss: 0.177740, Val Acc: 0.628866\n",
      "Epoch 6685 - Train Loss: 0.164746, Train Acc: 0.673077 | Val Loss: 0.177728, Val Acc: 0.628866\n",
      "Epoch 6686 - Train Loss: 0.164733, Train Acc: 0.673077 | Val Loss: 0.177716, Val Acc: 0.628866\n",
      "Epoch 6687 - Train Loss: 0.164720, Train Acc: 0.673077 | Val Loss: 0.177703, Val Acc: 0.628866\n",
      "Epoch 6688 - Train Loss: 0.164708, Train Acc: 0.673077 | Val Loss: 0.177691, Val Acc: 0.628866\n",
      "Epoch 6689 - Train Loss: 0.164695, Train Acc: 0.673077 | Val Loss: 0.177679, Val Acc: 0.628866\n",
      "Epoch 6690 - Train Loss: 0.164682, Train Acc: 0.673077 | Val Loss: 0.177667, Val Acc: 0.628866\n",
      "Epoch 6691 - Train Loss: 0.164670, Train Acc: 0.673077 | Val Loss: 0.177655, Val Acc: 0.628866\n",
      "Epoch 6692 - Train Loss: 0.164657, Train Acc: 0.673077 | Val Loss: 0.177643, Val Acc: 0.628866\n",
      "Epoch 6693 - Train Loss: 0.164645, Train Acc: 0.673077 | Val Loss: 0.177631, Val Acc: 0.628866\n",
      "Epoch 6694 - Train Loss: 0.164632, Train Acc: 0.673077 | Val Loss: 0.177619, Val Acc: 0.628866\n",
      "Epoch 6695 - Train Loss: 0.164619, Train Acc: 0.673077 | Val Loss: 0.177607, Val Acc: 0.628866\n",
      "Epoch 6696 - Train Loss: 0.164607, Train Acc: 0.673077 | Val Loss: 0.177595, Val Acc: 0.628866\n",
      "Epoch 6697 - Train Loss: 0.164594, Train Acc: 0.673077 | Val Loss: 0.177583, Val Acc: 0.628866\n",
      "Epoch 6698 - Train Loss: 0.164582, Train Acc: 0.673077 | Val Loss: 0.177571, Val Acc: 0.628866\n",
      "Epoch 6699 - Train Loss: 0.164569, Train Acc: 0.673077 | Val Loss: 0.177559, Val Acc: 0.628866\n",
      "Epoch 6700 - Train Loss: 0.164556, Train Acc: 0.673077 | Val Loss: 0.177547, Val Acc: 0.628866\n",
      "Epoch 6701 - Train Loss: 0.164544, Train Acc: 0.673077 | Val Loss: 0.177535, Val Acc: 0.628866\n",
      "Epoch 6702 - Train Loss: 0.164531, Train Acc: 0.673077 | Val Loss: 0.177523, Val Acc: 0.628866\n",
      "Epoch 6703 - Train Loss: 0.164519, Train Acc: 0.674359 | Val Loss: 0.177511, Val Acc: 0.628866\n",
      "Epoch 6704 - Train Loss: 0.164506, Train Acc: 0.674359 | Val Loss: 0.177499, Val Acc: 0.628866\n",
      "Epoch 6705 - Train Loss: 0.164493, Train Acc: 0.674359 | Val Loss: 0.177487, Val Acc: 0.628866\n",
      "Epoch 6706 - Train Loss: 0.164481, Train Acc: 0.674359 | Val Loss: 0.177475, Val Acc: 0.628866\n",
      "Epoch 6707 - Train Loss: 0.164468, Train Acc: 0.674359 | Val Loss: 0.177463, Val Acc: 0.628866\n",
      "Epoch 6708 - Train Loss: 0.164456, Train Acc: 0.674359 | Val Loss: 0.177451, Val Acc: 0.628866\n",
      "Epoch 6709 - Train Loss: 0.164443, Train Acc: 0.674359 | Val Loss: 0.177439, Val Acc: 0.628866\n",
      "Epoch 6710 - Train Loss: 0.164430, Train Acc: 0.674359 | Val Loss: 0.177427, Val Acc: 0.628866\n",
      "Epoch 6711 - Train Loss: 0.164418, Train Acc: 0.674359 | Val Loss: 0.177415, Val Acc: 0.628866\n",
      "Epoch 6712 - Train Loss: 0.164405, Train Acc: 0.674359 | Val Loss: 0.177403, Val Acc: 0.628866\n",
      "Epoch 6713 - Train Loss: 0.164393, Train Acc: 0.674359 | Val Loss: 0.177391, Val Acc: 0.628866\n",
      "Epoch 6714 - Train Loss: 0.164380, Train Acc: 0.675641 | Val Loss: 0.177379, Val Acc: 0.628866\n",
      "Epoch 6715 - Train Loss: 0.164367, Train Acc: 0.675641 | Val Loss: 0.177367, Val Acc: 0.628866\n",
      "Epoch 6716 - Train Loss: 0.164355, Train Acc: 0.675641 | Val Loss: 0.177355, Val Acc: 0.628866\n",
      "Epoch 6717 - Train Loss: 0.164342, Train Acc: 0.675641 | Val Loss: 0.177343, Val Acc: 0.628866\n",
      "Epoch 6718 - Train Loss: 0.164330, Train Acc: 0.675641 | Val Loss: 0.177331, Val Acc: 0.628866\n",
      "Epoch 6719 - Train Loss: 0.164317, Train Acc: 0.675641 | Val Loss: 0.177319, Val Acc: 0.628866\n",
      "Epoch 6720 - Train Loss: 0.164304, Train Acc: 0.675641 | Val Loss: 0.177307, Val Acc: 0.628866\n",
      "Epoch 6721 - Train Loss: 0.164292, Train Acc: 0.675641 | Val Loss: 0.177295, Val Acc: 0.628866\n",
      "Epoch 6722 - Train Loss: 0.164279, Train Acc: 0.675641 | Val Loss: 0.177283, Val Acc: 0.628866\n",
      "Epoch 6723 - Train Loss: 0.164267, Train Acc: 0.675641 | Val Loss: 0.177271, Val Acc: 0.628866\n",
      "Epoch 6724 - Train Loss: 0.164254, Train Acc: 0.675641 | Val Loss: 0.177259, Val Acc: 0.628866\n",
      "Epoch 6725 - Train Loss: 0.164242, Train Acc: 0.675641 | Val Loss: 0.177247, Val Acc: 0.628866\n",
      "Epoch 6726 - Train Loss: 0.164229, Train Acc: 0.675641 | Val Loss: 0.177235, Val Acc: 0.628866\n",
      "Epoch 6727 - Train Loss: 0.164216, Train Acc: 0.675641 | Val Loss: 0.177223, Val Acc: 0.628866\n",
      "Epoch 6728 - Train Loss: 0.164204, Train Acc: 0.675641 | Val Loss: 0.177212, Val Acc: 0.628866\n",
      "Epoch 6729 - Train Loss: 0.164191, Train Acc: 0.675641 | Val Loss: 0.177200, Val Acc: 0.628866\n",
      "Epoch 6730 - Train Loss: 0.164179, Train Acc: 0.675641 | Val Loss: 0.177188, Val Acc: 0.628866\n",
      "Epoch 6731 - Train Loss: 0.164166, Train Acc: 0.675641 | Val Loss: 0.177176, Val Acc: 0.628866\n",
      "Epoch 6732 - Train Loss: 0.164153, Train Acc: 0.675641 | Val Loss: 0.177164, Val Acc: 0.628866\n",
      "Epoch 6733 - Train Loss: 0.164141, Train Acc: 0.675641 | Val Loss: 0.177152, Val Acc: 0.628866\n",
      "Epoch 6734 - Train Loss: 0.164128, Train Acc: 0.675641 | Val Loss: 0.177140, Val Acc: 0.628866\n",
      "Epoch 6735 - Train Loss: 0.164116, Train Acc: 0.675641 | Val Loss: 0.177128, Val Acc: 0.628866\n",
      "Epoch 6736 - Train Loss: 0.164103, Train Acc: 0.675641 | Val Loss: 0.177116, Val Acc: 0.628866\n",
      "Epoch 6737 - Train Loss: 0.164091, Train Acc: 0.675641 | Val Loss: 0.177104, Val Acc: 0.628866\n",
      "Epoch 6738 - Train Loss: 0.164078, Train Acc: 0.675641 | Val Loss: 0.177092, Val Acc: 0.628866\n",
      "Epoch 6739 - Train Loss: 0.164066, Train Acc: 0.675641 | Val Loss: 0.177080, Val Acc: 0.628866\n",
      "Epoch 6740 - Train Loss: 0.164053, Train Acc: 0.675641 | Val Loss: 0.177068, Val Acc: 0.628866\n",
      "Epoch 6741 - Train Loss: 0.164040, Train Acc: 0.675641 | Val Loss: 0.177056, Val Acc: 0.628866\n",
      "Epoch 6742 - Train Loss: 0.164028, Train Acc: 0.675641 | Val Loss: 0.177044, Val Acc: 0.628866\n",
      "Epoch 6743 - Train Loss: 0.164015, Train Acc: 0.675641 | Val Loss: 0.177032, Val Acc: 0.628866\n",
      "Epoch 6744 - Train Loss: 0.164003, Train Acc: 0.675641 | Val Loss: 0.177020, Val Acc: 0.628866\n",
      "Epoch 6745 - Train Loss: 0.163990, Train Acc: 0.675641 | Val Loss: 0.177008, Val Acc: 0.628866\n",
      "Epoch 6746 - Train Loss: 0.163978, Train Acc: 0.675641 | Val Loss: 0.176996, Val Acc: 0.628866\n",
      "Epoch 6747 - Train Loss: 0.163965, Train Acc: 0.675641 | Val Loss: 0.176984, Val Acc: 0.628866\n",
      "Epoch 6748 - Train Loss: 0.163952, Train Acc: 0.676923 | Val Loss: 0.176972, Val Acc: 0.628866\n",
      "Epoch 6749 - Train Loss: 0.163940, Train Acc: 0.676923 | Val Loss: 0.176960, Val Acc: 0.628866\n",
      "Epoch 6750 - Train Loss: 0.163927, Train Acc: 0.676923 | Val Loss: 0.176948, Val Acc: 0.628866\n",
      "Epoch 6751 - Train Loss: 0.163915, Train Acc: 0.676923 | Val Loss: 0.176936, Val Acc: 0.628866\n",
      "Epoch 6752 - Train Loss: 0.163902, Train Acc: 0.676923 | Val Loss: 0.176925, Val Acc: 0.628866\n",
      "Epoch 6753 - Train Loss: 0.163890, Train Acc: 0.676923 | Val Loss: 0.176913, Val Acc: 0.628866\n",
      "Epoch 6754 - Train Loss: 0.163877, Train Acc: 0.676923 | Val Loss: 0.176901, Val Acc: 0.628866\n",
      "Epoch 6755 - Train Loss: 0.163865, Train Acc: 0.676923 | Val Loss: 0.176889, Val Acc: 0.628866\n",
      "Epoch 6756 - Train Loss: 0.163852, Train Acc: 0.676923 | Val Loss: 0.176877, Val Acc: 0.628866\n",
      "Epoch 6757 - Train Loss: 0.163839, Train Acc: 0.676923 | Val Loss: 0.176865, Val Acc: 0.628866\n",
      "Epoch 6758 - Train Loss: 0.163827, Train Acc: 0.676923 | Val Loss: 0.176853, Val Acc: 0.628866\n",
      "Epoch 6759 - Train Loss: 0.163814, Train Acc: 0.676923 | Val Loss: 0.176841, Val Acc: 0.628866\n",
      "Epoch 6760 - Train Loss: 0.163802, Train Acc: 0.678205 | Val Loss: 0.176829, Val Acc: 0.628866\n",
      "Epoch 6761 - Train Loss: 0.163789, Train Acc: 0.678205 | Val Loss: 0.176817, Val Acc: 0.628866\n",
      "Epoch 6762 - Train Loss: 0.163777, Train Acc: 0.678205 | Val Loss: 0.176805, Val Acc: 0.628866\n",
      "Epoch 6763 - Train Loss: 0.163764, Train Acc: 0.678205 | Val Loss: 0.176793, Val Acc: 0.628866\n",
      "Epoch 6764 - Train Loss: 0.163752, Train Acc: 0.678205 | Val Loss: 0.176781, Val Acc: 0.628866\n",
      "Epoch 6765 - Train Loss: 0.163739, Train Acc: 0.678205 | Val Loss: 0.176769, Val Acc: 0.628866\n",
      "Epoch 6766 - Train Loss: 0.163727, Train Acc: 0.678205 | Val Loss: 0.176757, Val Acc: 0.628866\n",
      "Epoch 6767 - Train Loss: 0.163714, Train Acc: 0.678205 | Val Loss: 0.176746, Val Acc: 0.628866\n",
      "Epoch 6768 - Train Loss: 0.163701, Train Acc: 0.678205 | Val Loss: 0.176734, Val Acc: 0.628866\n",
      "Epoch 6769 - Train Loss: 0.163689, Train Acc: 0.678205 | Val Loss: 0.176722, Val Acc: 0.628866\n",
      "Epoch 6770 - Train Loss: 0.163676, Train Acc: 0.678205 | Val Loss: 0.176710, Val Acc: 0.628866\n",
      "Epoch 6771 - Train Loss: 0.163664, Train Acc: 0.678205 | Val Loss: 0.176698, Val Acc: 0.628866\n",
      "Epoch 6772 - Train Loss: 0.163651, Train Acc: 0.678205 | Val Loss: 0.176686, Val Acc: 0.628866\n",
      "Epoch 6773 - Train Loss: 0.163639, Train Acc: 0.678205 | Val Loss: 0.176674, Val Acc: 0.628866\n",
      "Epoch 6774 - Train Loss: 0.163626, Train Acc: 0.678205 | Val Loss: 0.176662, Val Acc: 0.628866\n",
      "Epoch 6775 - Train Loss: 0.163614, Train Acc: 0.678205 | Val Loss: 0.176650, Val Acc: 0.628866\n",
      "Epoch 6776 - Train Loss: 0.163601, Train Acc: 0.678205 | Val Loss: 0.176638, Val Acc: 0.628866\n",
      "Epoch 6777 - Train Loss: 0.163589, Train Acc: 0.678205 | Val Loss: 0.176626, Val Acc: 0.628866\n",
      "Epoch 6778 - Train Loss: 0.163576, Train Acc: 0.676923 | Val Loss: 0.176614, Val Acc: 0.628866\n",
      "Epoch 6779 - Train Loss: 0.163564, Train Acc: 0.676923 | Val Loss: 0.176603, Val Acc: 0.628866\n",
      "Epoch 6780 - Train Loss: 0.163551, Train Acc: 0.676923 | Val Loss: 0.176591, Val Acc: 0.628866\n",
      "Epoch 6781 - Train Loss: 0.163539, Train Acc: 0.676923 | Val Loss: 0.176579, Val Acc: 0.628866\n",
      "Epoch 6782 - Train Loss: 0.163526, Train Acc: 0.676923 | Val Loss: 0.176567, Val Acc: 0.628866\n",
      "Epoch 6783 - Train Loss: 0.163513, Train Acc: 0.678205 | Val Loss: 0.176555, Val Acc: 0.628866\n",
      "Epoch 6784 - Train Loss: 0.163501, Train Acc: 0.678205 | Val Loss: 0.176543, Val Acc: 0.628866\n",
      "Epoch 6785 - Train Loss: 0.163488, Train Acc: 0.678205 | Val Loss: 0.176531, Val Acc: 0.628866\n",
      "Epoch 6786 - Train Loss: 0.163476, Train Acc: 0.678205 | Val Loss: 0.176519, Val Acc: 0.628866\n",
      "Epoch 6787 - Train Loss: 0.163463, Train Acc: 0.678205 | Val Loss: 0.176507, Val Acc: 0.628866\n",
      "Epoch 6788 - Train Loss: 0.163451, Train Acc: 0.678205 | Val Loss: 0.176495, Val Acc: 0.628866\n",
      "Epoch 6789 - Train Loss: 0.163438, Train Acc: 0.678205 | Val Loss: 0.176483, Val Acc: 0.628866\n",
      "Epoch 6790 - Train Loss: 0.163426, Train Acc: 0.678205 | Val Loss: 0.176472, Val Acc: 0.628866\n",
      "Epoch 6791 - Train Loss: 0.163413, Train Acc: 0.679487 | Val Loss: 0.176460, Val Acc: 0.628866\n",
      "Epoch 6792 - Train Loss: 0.163401, Train Acc: 0.679487 | Val Loss: 0.176448, Val Acc: 0.628866\n",
      "Epoch 6793 - Train Loss: 0.163388, Train Acc: 0.680769 | Val Loss: 0.176436, Val Acc: 0.628866\n",
      "Epoch 6794 - Train Loss: 0.163376, Train Acc: 0.680769 | Val Loss: 0.176424, Val Acc: 0.628866\n",
      "Epoch 6795 - Train Loss: 0.163363, Train Acc: 0.680769 | Val Loss: 0.176412, Val Acc: 0.628866\n",
      "Epoch 6796 - Train Loss: 0.163351, Train Acc: 0.680769 | Val Loss: 0.176400, Val Acc: 0.628866\n",
      "Epoch 6797 - Train Loss: 0.163338, Train Acc: 0.679487 | Val Loss: 0.176388, Val Acc: 0.628866\n",
      "Epoch 6798 - Train Loss: 0.163326, Train Acc: 0.679487 | Val Loss: 0.176376, Val Acc: 0.628866\n",
      "Epoch 6799 - Train Loss: 0.163313, Train Acc: 0.679487 | Val Loss: 0.176365, Val Acc: 0.628866\n",
      "Epoch 6800 - Train Loss: 0.163301, Train Acc: 0.679487 | Val Loss: 0.176353, Val Acc: 0.628866\n",
      "Epoch 6801 - Train Loss: 0.163288, Train Acc: 0.679487 | Val Loss: 0.176341, Val Acc: 0.628866\n",
      "Epoch 6802 - Train Loss: 0.163276, Train Acc: 0.679487 | Val Loss: 0.176329, Val Acc: 0.628866\n",
      "Epoch 6803 - Train Loss: 0.163263, Train Acc: 0.679487 | Val Loss: 0.176317, Val Acc: 0.628866\n",
      "Epoch 6804 - Train Loss: 0.163251, Train Acc: 0.679487 | Val Loss: 0.176305, Val Acc: 0.628866\n",
      "Epoch 6805 - Train Loss: 0.163238, Train Acc: 0.679487 | Val Loss: 0.176293, Val Acc: 0.628866\n",
      "Epoch 6806 - Train Loss: 0.163226, Train Acc: 0.679487 | Val Loss: 0.176281, Val Acc: 0.628866\n",
      "Epoch 6807 - Train Loss: 0.163213, Train Acc: 0.679487 | Val Loss: 0.176270, Val Acc: 0.628866\n",
      "Epoch 6808 - Train Loss: 0.163201, Train Acc: 0.679487 | Val Loss: 0.176258, Val Acc: 0.628866\n",
      "Epoch 6809 - Train Loss: 0.163188, Train Acc: 0.679487 | Val Loss: 0.176246, Val Acc: 0.628866\n",
      "Epoch 6810 - Train Loss: 0.163176, Train Acc: 0.679487 | Val Loss: 0.176234, Val Acc: 0.628866\n",
      "Epoch 6811 - Train Loss: 0.163163, Train Acc: 0.679487 | Val Loss: 0.176222, Val Acc: 0.628866\n",
      "Epoch 6812 - Train Loss: 0.163151, Train Acc: 0.679487 | Val Loss: 0.176210, Val Acc: 0.628866\n",
      "Epoch 6813 - Train Loss: 0.163138, Train Acc: 0.679487 | Val Loss: 0.176198, Val Acc: 0.628866\n",
      "Epoch 6814 - Train Loss: 0.163126, Train Acc: 0.679487 | Val Loss: 0.176186, Val Acc: 0.628866\n",
      "Epoch 6815 - Train Loss: 0.163113, Train Acc: 0.679487 | Val Loss: 0.176175, Val Acc: 0.628866\n",
      "Epoch 6816 - Train Loss: 0.163101, Train Acc: 0.679487 | Val Loss: 0.176163, Val Acc: 0.628866\n",
      "Epoch 6817 - Train Loss: 0.163088, Train Acc: 0.679487 | Val Loss: 0.176151, Val Acc: 0.628866\n",
      "Epoch 6818 - Train Loss: 0.163076, Train Acc: 0.679487 | Val Loss: 0.176139, Val Acc: 0.628866\n",
      "Epoch 6819 - Train Loss: 0.163063, Train Acc: 0.679487 | Val Loss: 0.176127, Val Acc: 0.628866\n",
      "Epoch 6820 - Train Loss: 0.163051, Train Acc: 0.679487 | Val Loss: 0.176115, Val Acc: 0.628866\n",
      "Epoch 6821 - Train Loss: 0.163038, Train Acc: 0.679487 | Val Loss: 0.176103, Val Acc: 0.628866\n",
      "Epoch 6822 - Train Loss: 0.163026, Train Acc: 0.679487 | Val Loss: 0.176092, Val Acc: 0.628866\n",
      "Epoch 6823 - Train Loss: 0.163013, Train Acc: 0.679487 | Val Loss: 0.176080, Val Acc: 0.628866\n",
      "Epoch 6824 - Train Loss: 0.163001, Train Acc: 0.679487 | Val Loss: 0.176068, Val Acc: 0.628866\n",
      "Epoch 6825 - Train Loss: 0.162988, Train Acc: 0.679487 | Val Loss: 0.176056, Val Acc: 0.628866\n",
      "Epoch 6826 - Train Loss: 0.162976, Train Acc: 0.679487 | Val Loss: 0.176044, Val Acc: 0.628866\n",
      "Epoch 6827 - Train Loss: 0.162963, Train Acc: 0.679487 | Val Loss: 0.176032, Val Acc: 0.628866\n",
      "Epoch 6828 - Train Loss: 0.162951, Train Acc: 0.679487 | Val Loss: 0.176020, Val Acc: 0.628866\n",
      "Epoch 6829 - Train Loss: 0.162938, Train Acc: 0.679487 | Val Loss: 0.176009, Val Acc: 0.628866\n",
      "Epoch 6830 - Train Loss: 0.162926, Train Acc: 0.679487 | Val Loss: 0.175997, Val Acc: 0.628866\n",
      "Epoch 6831 - Train Loss: 0.162913, Train Acc: 0.679487 | Val Loss: 0.175985, Val Acc: 0.628866\n",
      "Epoch 6832 - Train Loss: 0.162901, Train Acc: 0.679487 | Val Loss: 0.175973, Val Acc: 0.628866\n",
      "Epoch 6833 - Train Loss: 0.162888, Train Acc: 0.679487 | Val Loss: 0.175961, Val Acc: 0.628866\n",
      "Epoch 6834 - Train Loss: 0.162876, Train Acc: 0.680769 | Val Loss: 0.175949, Val Acc: 0.628866\n",
      "Epoch 6835 - Train Loss: 0.162863, Train Acc: 0.680769 | Val Loss: 0.175938, Val Acc: 0.628866\n",
      "Epoch 6836 - Train Loss: 0.162851, Train Acc: 0.680769 | Val Loss: 0.175926, Val Acc: 0.628866\n",
      "Epoch 6837 - Train Loss: 0.162839, Train Acc: 0.680769 | Val Loss: 0.175914, Val Acc: 0.628866\n",
      "Epoch 6838 - Train Loss: 0.162826, Train Acc: 0.680769 | Val Loss: 0.175902, Val Acc: 0.628866\n",
      "Epoch 6839 - Train Loss: 0.162814, Train Acc: 0.680769 | Val Loss: 0.175890, Val Acc: 0.628866\n",
      "Epoch 6840 - Train Loss: 0.162801, Train Acc: 0.680769 | Val Loss: 0.175878, Val Acc: 0.628866\n",
      "Epoch 6841 - Train Loss: 0.162789, Train Acc: 0.680769 | Val Loss: 0.175867, Val Acc: 0.628866\n",
      "Epoch 6842 - Train Loss: 0.162776, Train Acc: 0.680769 | Val Loss: 0.175855, Val Acc: 0.628866\n",
      "Epoch 6843 - Train Loss: 0.162764, Train Acc: 0.680769 | Val Loss: 0.175843, Val Acc: 0.628866\n",
      "Epoch 6844 - Train Loss: 0.162751, Train Acc: 0.682051 | Val Loss: 0.175831, Val Acc: 0.628866\n",
      "Epoch 6845 - Train Loss: 0.162739, Train Acc: 0.682051 | Val Loss: 0.175819, Val Acc: 0.628866\n",
      "Epoch 6846 - Train Loss: 0.162726, Train Acc: 0.682051 | Val Loss: 0.175807, Val Acc: 0.628866\n",
      "Epoch 6847 - Train Loss: 0.162714, Train Acc: 0.682051 | Val Loss: 0.175796, Val Acc: 0.628866\n",
      "Epoch 6848 - Train Loss: 0.162701, Train Acc: 0.682051 | Val Loss: 0.175784, Val Acc: 0.628866\n",
      "Epoch 6849 - Train Loss: 0.162689, Train Acc: 0.682051 | Val Loss: 0.175772, Val Acc: 0.628866\n",
      "Epoch 6850 - Train Loss: 0.162677, Train Acc: 0.682051 | Val Loss: 0.175761, Val Acc: 0.628866\n",
      "Epoch 6851 - Train Loss: 0.162664, Train Acc: 0.682051 | Val Loss: 0.175749, Val Acc: 0.628866\n",
      "Epoch 6852 - Train Loss: 0.162652, Train Acc: 0.682051 | Val Loss: 0.175738, Val Acc: 0.628866\n",
      "Epoch 6853 - Train Loss: 0.162639, Train Acc: 0.682051 | Val Loss: 0.175726, Val Acc: 0.628866\n",
      "Epoch 6854 - Train Loss: 0.162627, Train Acc: 0.682051 | Val Loss: 0.175714, Val Acc: 0.628866\n",
      "Epoch 6855 - Train Loss: 0.162614, Train Acc: 0.682051 | Val Loss: 0.175703, Val Acc: 0.628866\n",
      "Epoch 6856 - Train Loss: 0.162602, Train Acc: 0.682051 | Val Loss: 0.175691, Val Acc: 0.628866\n",
      "Epoch 6857 - Train Loss: 0.162589, Train Acc: 0.682051 | Val Loss: 0.175679, Val Acc: 0.628866\n",
      "Epoch 6858 - Train Loss: 0.162577, Train Acc: 0.682051 | Val Loss: 0.175668, Val Acc: 0.628866\n",
      "Epoch 6859 - Train Loss: 0.162565, Train Acc: 0.682051 | Val Loss: 0.175656, Val Acc: 0.628866\n",
      "Epoch 6860 - Train Loss: 0.162552, Train Acc: 0.682051 | Val Loss: 0.175644, Val Acc: 0.628866\n",
      "Epoch 6861 - Train Loss: 0.162540, Train Acc: 0.682051 | Val Loss: 0.175633, Val Acc: 0.628866\n",
      "Epoch 6862 - Train Loss: 0.162527, Train Acc: 0.682051 | Val Loss: 0.175621, Val Acc: 0.628866\n",
      "Epoch 6863 - Train Loss: 0.162515, Train Acc: 0.682051 | Val Loss: 0.175609, Val Acc: 0.628866\n",
      "Epoch 6864 - Train Loss: 0.162502, Train Acc: 0.682051 | Val Loss: 0.175598, Val Acc: 0.628866\n",
      "Epoch 6865 - Train Loss: 0.162490, Train Acc: 0.682051 | Val Loss: 0.175586, Val Acc: 0.628866\n",
      "Epoch 6866 - Train Loss: 0.162478, Train Acc: 0.682051 | Val Loss: 0.175574, Val Acc: 0.628866\n",
      "Epoch 6867 - Train Loss: 0.162465, Train Acc: 0.682051 | Val Loss: 0.175563, Val Acc: 0.628866\n",
      "Epoch 6868 - Train Loss: 0.162453, Train Acc: 0.683333 | Val Loss: 0.175551, Val Acc: 0.628866\n",
      "Epoch 6869 - Train Loss: 0.162440, Train Acc: 0.683333 | Val Loss: 0.175539, Val Acc: 0.628866\n",
      "Epoch 6870 - Train Loss: 0.162428, Train Acc: 0.683333 | Val Loss: 0.175528, Val Acc: 0.628866\n",
      "Epoch 6871 - Train Loss: 0.162415, Train Acc: 0.683333 | Val Loss: 0.175516, Val Acc: 0.628866\n",
      "Epoch 6872 - Train Loss: 0.162403, Train Acc: 0.683333 | Val Loss: 0.175504, Val Acc: 0.628866\n",
      "Epoch 6873 - Train Loss: 0.162391, Train Acc: 0.683333 | Val Loss: 0.175493, Val Acc: 0.628866\n",
      "Epoch 6874 - Train Loss: 0.162378, Train Acc: 0.683333 | Val Loss: 0.175481, Val Acc: 0.628866\n",
      "Epoch 6875 - Train Loss: 0.162366, Train Acc: 0.683333 | Val Loss: 0.175469, Val Acc: 0.628866\n",
      "Epoch 6876 - Train Loss: 0.162353, Train Acc: 0.683333 | Val Loss: 0.175458, Val Acc: 0.628866\n",
      "Epoch 6877 - Train Loss: 0.162341, Train Acc: 0.683333 | Val Loss: 0.175446, Val Acc: 0.628866\n",
      "Epoch 6878 - Train Loss: 0.162329, Train Acc: 0.683333 | Val Loss: 0.175434, Val Acc: 0.628866\n",
      "Epoch 6879 - Train Loss: 0.162316, Train Acc: 0.683333 | Val Loss: 0.175423, Val Acc: 0.628866\n",
      "Epoch 6880 - Train Loss: 0.162304, Train Acc: 0.683333 | Val Loss: 0.175411, Val Acc: 0.628866\n",
      "Epoch 6881 - Train Loss: 0.162291, Train Acc: 0.683333 | Val Loss: 0.175399, Val Acc: 0.628866\n",
      "Epoch 6882 - Train Loss: 0.162279, Train Acc: 0.683333 | Val Loss: 0.175388, Val Acc: 0.628866\n",
      "Epoch 6883 - Train Loss: 0.162266, Train Acc: 0.683333 | Val Loss: 0.175376, Val Acc: 0.628866\n",
      "Epoch 6884 - Train Loss: 0.162254, Train Acc: 0.683333 | Val Loss: 0.175364, Val Acc: 0.628866\n",
      "Epoch 6885 - Train Loss: 0.162242, Train Acc: 0.683333 | Val Loss: 0.175353, Val Acc: 0.628866\n",
      "Epoch 6886 - Train Loss: 0.162229, Train Acc: 0.683333 | Val Loss: 0.175341, Val Acc: 0.628866\n",
      "Epoch 6887 - Train Loss: 0.162217, Train Acc: 0.684615 | Val Loss: 0.175329, Val Acc: 0.628866\n",
      "Epoch 6888 - Train Loss: 0.162204, Train Acc: 0.684615 | Val Loss: 0.175318, Val Acc: 0.628866\n",
      "Epoch 6889 - Train Loss: 0.162192, Train Acc: 0.684615 | Val Loss: 0.175306, Val Acc: 0.628866\n",
      "Epoch 6890 - Train Loss: 0.162180, Train Acc: 0.684615 | Val Loss: 0.175294, Val Acc: 0.628866\n",
      "Epoch 6891 - Train Loss: 0.162167, Train Acc: 0.685897 | Val Loss: 0.175283, Val Acc: 0.628866\n",
      "Epoch 6892 - Train Loss: 0.162155, Train Acc: 0.685897 | Val Loss: 0.175271, Val Acc: 0.628866\n",
      "Epoch 6893 - Train Loss: 0.162142, Train Acc: 0.685897 | Val Loss: 0.175259, Val Acc: 0.628866\n",
      "Epoch 6894 - Train Loss: 0.162130, Train Acc: 0.687179 | Val Loss: 0.175248, Val Acc: 0.628866\n",
      "Epoch 6895 - Train Loss: 0.162118, Train Acc: 0.687179 | Val Loss: 0.175236, Val Acc: 0.628866\n",
      "Epoch 6896 - Train Loss: 0.162105, Train Acc: 0.687179 | Val Loss: 0.175224, Val Acc: 0.628866\n",
      "Epoch 6897 - Train Loss: 0.162093, Train Acc: 0.687179 | Val Loss: 0.175213, Val Acc: 0.628866\n",
      "Epoch 6898 - Train Loss: 0.162080, Train Acc: 0.687179 | Val Loss: 0.175201, Val Acc: 0.628866\n",
      "Epoch 6899 - Train Loss: 0.162068, Train Acc: 0.687179 | Val Loss: 0.175189, Val Acc: 0.628866\n",
      "Epoch 6900 - Train Loss: 0.162056, Train Acc: 0.687179 | Val Loss: 0.175178, Val Acc: 0.628866\n",
      "Epoch 6901 - Train Loss: 0.162043, Train Acc: 0.687179 | Val Loss: 0.175166, Val Acc: 0.628866\n",
      "Epoch 6902 - Train Loss: 0.162031, Train Acc: 0.687179 | Val Loss: 0.175154, Val Acc: 0.628866\n",
      "Epoch 6903 - Train Loss: 0.162018, Train Acc: 0.687179 | Val Loss: 0.175143, Val Acc: 0.628866\n",
      "Epoch 6904 - Train Loss: 0.162006, Train Acc: 0.687179 | Val Loss: 0.175131, Val Acc: 0.628866\n",
      "Epoch 6905 - Train Loss: 0.161994, Train Acc: 0.687179 | Val Loss: 0.175119, Val Acc: 0.628866\n",
      "Epoch 6906 - Train Loss: 0.161981, Train Acc: 0.687179 | Val Loss: 0.175108, Val Acc: 0.628866\n",
      "Epoch 6907 - Train Loss: 0.161969, Train Acc: 0.687179 | Val Loss: 0.175096, Val Acc: 0.628866\n",
      "Epoch 6908 - Train Loss: 0.161957, Train Acc: 0.687179 | Val Loss: 0.175084, Val Acc: 0.628866\n",
      "Epoch 6909 - Train Loss: 0.161944, Train Acc: 0.687179 | Val Loss: 0.175073, Val Acc: 0.628866\n",
      "Epoch 6910 - Train Loss: 0.161932, Train Acc: 0.687179 | Val Loss: 0.175061, Val Acc: 0.628866\n",
      "Epoch 6911 - Train Loss: 0.161919, Train Acc: 0.687179 | Val Loss: 0.175049, Val Acc: 0.628866\n",
      "Epoch 6912 - Train Loss: 0.161907, Train Acc: 0.687179 | Val Loss: 0.175038, Val Acc: 0.628866\n",
      "Epoch 6913 - Train Loss: 0.161895, Train Acc: 0.687179 | Val Loss: 0.175026, Val Acc: 0.628866\n",
      "Epoch 6914 - Train Loss: 0.161882, Train Acc: 0.687179 | Val Loss: 0.175014, Val Acc: 0.628866\n",
      "Epoch 6915 - Train Loss: 0.161870, Train Acc: 0.687179 | Val Loss: 0.175003, Val Acc: 0.639175\n",
      "Epoch 6916 - Train Loss: 0.161858, Train Acc: 0.687179 | Val Loss: 0.174991, Val Acc: 0.639175\n",
      "Epoch 6917 - Train Loss: 0.161845, Train Acc: 0.687179 | Val Loss: 0.174979, Val Acc: 0.639175\n",
      "Epoch 6918 - Train Loss: 0.161833, Train Acc: 0.688462 | Val Loss: 0.174968, Val Acc: 0.639175\n",
      "Epoch 6919 - Train Loss: 0.161820, Train Acc: 0.688462 | Val Loss: 0.174956, Val Acc: 0.639175\n",
      "Epoch 6920 - Train Loss: 0.161808, Train Acc: 0.688462 | Val Loss: 0.174944, Val Acc: 0.639175\n",
      "Epoch 6921 - Train Loss: 0.161796, Train Acc: 0.688462 | Val Loss: 0.174933, Val Acc: 0.639175\n",
      "Epoch 6922 - Train Loss: 0.161783, Train Acc: 0.688462 | Val Loss: 0.174921, Val Acc: 0.639175\n",
      "Epoch 6923 - Train Loss: 0.161771, Train Acc: 0.688462 | Val Loss: 0.174909, Val Acc: 0.639175\n",
      "Epoch 6924 - Train Loss: 0.161759, Train Acc: 0.688462 | Val Loss: 0.174898, Val Acc: 0.639175\n",
      "Epoch 6925 - Train Loss: 0.161746, Train Acc: 0.689744 | Val Loss: 0.174886, Val Acc: 0.639175\n",
      "Epoch 6926 - Train Loss: 0.161734, Train Acc: 0.689744 | Val Loss: 0.174874, Val Acc: 0.639175\n",
      "Epoch 6927 - Train Loss: 0.161721, Train Acc: 0.689744 | Val Loss: 0.174863, Val Acc: 0.639175\n",
      "Epoch 6928 - Train Loss: 0.161709, Train Acc: 0.689744 | Val Loss: 0.174851, Val Acc: 0.639175\n",
      "Epoch 6929 - Train Loss: 0.161697, Train Acc: 0.689744 | Val Loss: 0.174840, Val Acc: 0.639175\n",
      "Epoch 6930 - Train Loss: 0.161684, Train Acc: 0.689744 | Val Loss: 0.174828, Val Acc: 0.639175\n",
      "Epoch 6931 - Train Loss: 0.161672, Train Acc: 0.689744 | Val Loss: 0.174816, Val Acc: 0.639175\n",
      "Epoch 6932 - Train Loss: 0.161660, Train Acc: 0.689744 | Val Loss: 0.174805, Val Acc: 0.639175\n",
      "Epoch 6933 - Train Loss: 0.161647, Train Acc: 0.689744 | Val Loss: 0.174793, Val Acc: 0.639175\n",
      "Epoch 6934 - Train Loss: 0.161635, Train Acc: 0.689744 | Val Loss: 0.174781, Val Acc: 0.639175\n",
      "Epoch 6935 - Train Loss: 0.161623, Train Acc: 0.689744 | Val Loss: 0.174770, Val Acc: 0.639175\n",
      "Epoch 6936 - Train Loss: 0.161610, Train Acc: 0.689744 | Val Loss: 0.174758, Val Acc: 0.639175\n",
      "Epoch 6937 - Train Loss: 0.161598, Train Acc: 0.689744 | Val Loss: 0.174746, Val Acc: 0.639175\n",
      "Epoch 6938 - Train Loss: 0.161585, Train Acc: 0.689744 | Val Loss: 0.174735, Val Acc: 0.639175\n",
      "Epoch 6939 - Train Loss: 0.161573, Train Acc: 0.689744 | Val Loss: 0.174723, Val Acc: 0.639175\n",
      "Epoch 6940 - Train Loss: 0.161561, Train Acc: 0.689744 | Val Loss: 0.174711, Val Acc: 0.639175\n",
      "Epoch 6941 - Train Loss: 0.161548, Train Acc: 0.689744 | Val Loss: 0.174700, Val Acc: 0.639175\n",
      "Epoch 6942 - Train Loss: 0.161536, Train Acc: 0.689744 | Val Loss: 0.174688, Val Acc: 0.639175\n",
      "Epoch 6943 - Train Loss: 0.161524, Train Acc: 0.689744 | Val Loss: 0.174677, Val Acc: 0.639175\n",
      "Epoch 6944 - Train Loss: 0.161511, Train Acc: 0.689744 | Val Loss: 0.174665, Val Acc: 0.639175\n",
      "Epoch 6945 - Train Loss: 0.161499, Train Acc: 0.689744 | Val Loss: 0.174653, Val Acc: 0.639175\n",
      "Epoch 6946 - Train Loss: 0.161487, Train Acc: 0.689744 | Val Loss: 0.174642, Val Acc: 0.639175\n",
      "Epoch 6947 - Train Loss: 0.161474, Train Acc: 0.689744 | Val Loss: 0.174630, Val Acc: 0.639175\n",
      "Epoch 6948 - Train Loss: 0.161462, Train Acc: 0.689744 | Val Loss: 0.174618, Val Acc: 0.639175\n",
      "Epoch 6949 - Train Loss: 0.161450, Train Acc: 0.689744 | Val Loss: 0.174607, Val Acc: 0.639175\n",
      "Epoch 6950 - Train Loss: 0.161437, Train Acc: 0.691026 | Val Loss: 0.174595, Val Acc: 0.639175\n",
      "Epoch 6951 - Train Loss: 0.161425, Train Acc: 0.691026 | Val Loss: 0.174583, Val Acc: 0.639175\n",
      "Epoch 6952 - Train Loss: 0.161413, Train Acc: 0.691026 | Val Loss: 0.174572, Val Acc: 0.639175\n",
      "Epoch 6953 - Train Loss: 0.161400, Train Acc: 0.691026 | Val Loss: 0.174560, Val Acc: 0.639175\n",
      "Epoch 6954 - Train Loss: 0.161388, Train Acc: 0.691026 | Val Loss: 0.174549, Val Acc: 0.639175\n",
      "Epoch 6955 - Train Loss: 0.161376, Train Acc: 0.691026 | Val Loss: 0.174537, Val Acc: 0.639175\n",
      "Epoch 6956 - Train Loss: 0.161363, Train Acc: 0.691026 | Val Loss: 0.174525, Val Acc: 0.639175\n",
      "Epoch 6957 - Train Loss: 0.161351, Train Acc: 0.691026 | Val Loss: 0.174514, Val Acc: 0.639175\n",
      "Epoch 6958 - Train Loss: 0.161339, Train Acc: 0.691026 | Val Loss: 0.174502, Val Acc: 0.639175\n",
      "Epoch 6959 - Train Loss: 0.161326, Train Acc: 0.692308 | Val Loss: 0.174490, Val Acc: 0.639175\n",
      "Epoch 6960 - Train Loss: 0.161314, Train Acc: 0.692308 | Val Loss: 0.174479, Val Acc: 0.639175\n",
      "Epoch 6961 - Train Loss: 0.161302, Train Acc: 0.692308 | Val Loss: 0.174467, Val Acc: 0.639175\n",
      "Epoch 6962 - Train Loss: 0.161289, Train Acc: 0.692308 | Val Loss: 0.174456, Val Acc: 0.639175\n",
      "Epoch 6963 - Train Loss: 0.161277, Train Acc: 0.692308 | Val Loss: 0.174444, Val Acc: 0.639175\n",
      "Epoch 6964 - Train Loss: 0.161265, Train Acc: 0.692308 | Val Loss: 0.174432, Val Acc: 0.639175\n",
      "Epoch 6965 - Train Loss: 0.161252, Train Acc: 0.692308 | Val Loss: 0.174421, Val Acc: 0.639175\n",
      "Epoch 6966 - Train Loss: 0.161240, Train Acc: 0.692308 | Val Loss: 0.174409, Val Acc: 0.639175\n",
      "Epoch 6967 - Train Loss: 0.161228, Train Acc: 0.692308 | Val Loss: 0.174397, Val Acc: 0.639175\n",
      "Epoch 6968 - Train Loss: 0.161215, Train Acc: 0.692308 | Val Loss: 0.174386, Val Acc: 0.639175\n",
      "Epoch 6969 - Train Loss: 0.161203, Train Acc: 0.692308 | Val Loss: 0.174374, Val Acc: 0.639175\n",
      "Epoch 6970 - Train Loss: 0.161191, Train Acc: 0.692308 | Val Loss: 0.174363, Val Acc: 0.639175\n",
      "Epoch 6971 - Train Loss: 0.161178, Train Acc: 0.692308 | Val Loss: 0.174351, Val Acc: 0.639175\n",
      "Epoch 6972 - Train Loss: 0.161166, Train Acc: 0.692308 | Val Loss: 0.174339, Val Acc: 0.639175\n",
      "Epoch 6973 - Train Loss: 0.161154, Train Acc: 0.692308 | Val Loss: 0.174328, Val Acc: 0.639175\n",
      "Epoch 6974 - Train Loss: 0.161141, Train Acc: 0.692308 | Val Loss: 0.174316, Val Acc: 0.639175\n",
      "Epoch 6975 - Train Loss: 0.161129, Train Acc: 0.692308 | Val Loss: 0.174305, Val Acc: 0.639175\n",
      "Epoch 6976 - Train Loss: 0.161117, Train Acc: 0.692308 | Val Loss: 0.174293, Val Acc: 0.639175\n",
      "Epoch 6977 - Train Loss: 0.161104, Train Acc: 0.692308 | Val Loss: 0.174281, Val Acc: 0.639175\n",
      "Epoch 6978 - Train Loss: 0.161092, Train Acc: 0.692308 | Val Loss: 0.174270, Val Acc: 0.639175\n",
      "Epoch 6979 - Train Loss: 0.161080, Train Acc: 0.692308 | Val Loss: 0.174258, Val Acc: 0.639175\n",
      "Epoch 6980 - Train Loss: 0.161067, Train Acc: 0.692308 | Val Loss: 0.174247, Val Acc: 0.639175\n",
      "Epoch 6981 - Train Loss: 0.161055, Train Acc: 0.692308 | Val Loss: 0.174235, Val Acc: 0.639175\n",
      "Epoch 6982 - Train Loss: 0.161043, Train Acc: 0.692308 | Val Loss: 0.174223, Val Acc: 0.639175\n",
      "Epoch 6983 - Train Loss: 0.161031, Train Acc: 0.692308 | Val Loss: 0.174212, Val Acc: 0.639175\n",
      "Epoch 6984 - Train Loss: 0.161018, Train Acc: 0.692308 | Val Loss: 0.174200, Val Acc: 0.639175\n",
      "Epoch 6985 - Train Loss: 0.161006, Train Acc: 0.692308 | Val Loss: 0.174189, Val Acc: 0.639175\n",
      "Epoch 6986 - Train Loss: 0.160994, Train Acc: 0.692308 | Val Loss: 0.174177, Val Acc: 0.639175\n",
      "Epoch 6987 - Train Loss: 0.160981, Train Acc: 0.692308 | Val Loss: 0.174165, Val Acc: 0.639175\n",
      "Epoch 6988 - Train Loss: 0.160969, Train Acc: 0.692308 | Val Loss: 0.174154, Val Acc: 0.639175\n",
      "Epoch 6989 - Train Loss: 0.160957, Train Acc: 0.692308 | Val Loss: 0.174142, Val Acc: 0.639175\n",
      "Epoch 6990 - Train Loss: 0.160944, Train Acc: 0.692308 | Val Loss: 0.174131, Val Acc: 0.639175\n",
      "Epoch 6991 - Train Loss: 0.160932, Train Acc: 0.692308 | Val Loss: 0.174119, Val Acc: 0.639175\n",
      "Epoch 6992 - Train Loss: 0.160920, Train Acc: 0.692308 | Val Loss: 0.174107, Val Acc: 0.639175\n",
      "Epoch 6993 - Train Loss: 0.160907, Train Acc: 0.692308 | Val Loss: 0.174096, Val Acc: 0.639175\n",
      "Epoch 6994 - Train Loss: 0.160895, Train Acc: 0.692308 | Val Loss: 0.174084, Val Acc: 0.639175\n",
      "Epoch 6995 - Train Loss: 0.160883, Train Acc: 0.693590 | Val Loss: 0.174073, Val Acc: 0.639175\n",
      "Epoch 6996 - Train Loss: 0.160871, Train Acc: 0.693590 | Val Loss: 0.174061, Val Acc: 0.639175\n",
      "Epoch 6997 - Train Loss: 0.160858, Train Acc: 0.693590 | Val Loss: 0.174050, Val Acc: 0.639175\n",
      "Epoch 6998 - Train Loss: 0.160846, Train Acc: 0.693590 | Val Loss: 0.174038, Val Acc: 0.639175\n",
      "Epoch 6999 - Train Loss: 0.160834, Train Acc: 0.693590 | Val Loss: 0.174026, Val Acc: 0.639175\n",
      "Epoch 7000 - Train Loss: 0.160821, Train Acc: 0.693590 | Val Loss: 0.174015, Val Acc: 0.639175\n",
      "Epoch 7001 - Train Loss: 0.160809, Train Acc: 0.693590 | Val Loss: 0.174003, Val Acc: 0.639175\n",
      "Epoch 7002 - Train Loss: 0.160797, Train Acc: 0.693590 | Val Loss: 0.173992, Val Acc: 0.639175\n",
      "Epoch 7003 - Train Loss: 0.160785, Train Acc: 0.693590 | Val Loss: 0.173980, Val Acc: 0.639175\n",
      "Epoch 7004 - Train Loss: 0.160772, Train Acc: 0.693590 | Val Loss: 0.173969, Val Acc: 0.639175\n",
      "Epoch 7005 - Train Loss: 0.160760, Train Acc: 0.693590 | Val Loss: 0.173957, Val Acc: 0.639175\n",
      "Epoch 7006 - Train Loss: 0.160748, Train Acc: 0.693590 | Val Loss: 0.173946, Val Acc: 0.639175\n",
      "Epoch 7007 - Train Loss: 0.160735, Train Acc: 0.693590 | Val Loss: 0.173934, Val Acc: 0.639175\n",
      "Epoch 7008 - Train Loss: 0.160723, Train Acc: 0.693590 | Val Loss: 0.173923, Val Acc: 0.639175\n",
      "Epoch 7009 - Train Loss: 0.160711, Train Acc: 0.693590 | Val Loss: 0.173911, Val Acc: 0.639175\n",
      "Epoch 7010 - Train Loss: 0.160699, Train Acc: 0.693590 | Val Loss: 0.173900, Val Acc: 0.639175\n",
      "Epoch 7011 - Train Loss: 0.160686, Train Acc: 0.693590 | Val Loss: 0.173888, Val Acc: 0.639175\n",
      "Epoch 7012 - Train Loss: 0.160674, Train Acc: 0.693590 | Val Loss: 0.173877, Val Acc: 0.639175\n",
      "Epoch 7013 - Train Loss: 0.160662, Train Acc: 0.693590 | Val Loss: 0.173865, Val Acc: 0.639175\n",
      "Epoch 7014 - Train Loss: 0.160649, Train Acc: 0.693590 | Val Loss: 0.173854, Val Acc: 0.639175\n",
      "Epoch 7015 - Train Loss: 0.160637, Train Acc: 0.693590 | Val Loss: 0.173843, Val Acc: 0.639175\n",
      "Epoch 7016 - Train Loss: 0.160625, Train Acc: 0.693590 | Val Loss: 0.173831, Val Acc: 0.639175\n",
      "Epoch 7017 - Train Loss: 0.160613, Train Acc: 0.693590 | Val Loss: 0.173820, Val Acc: 0.639175\n",
      "Epoch 7018 - Train Loss: 0.160600, Train Acc: 0.693590 | Val Loss: 0.173808, Val Acc: 0.639175\n",
      "Epoch 7019 - Train Loss: 0.160588, Train Acc: 0.693590 | Val Loss: 0.173797, Val Acc: 0.639175\n",
      "Epoch 7020 - Train Loss: 0.160576, Train Acc: 0.693590 | Val Loss: 0.173785, Val Acc: 0.639175\n",
      "Epoch 7021 - Train Loss: 0.160563, Train Acc: 0.693590 | Val Loss: 0.173774, Val Acc: 0.639175\n",
      "Epoch 7022 - Train Loss: 0.160551, Train Acc: 0.693590 | Val Loss: 0.173762, Val Acc: 0.639175\n",
      "Epoch 7023 - Train Loss: 0.160539, Train Acc: 0.693590 | Val Loss: 0.173751, Val Acc: 0.639175\n",
      "Epoch 7024 - Train Loss: 0.160527, Train Acc: 0.693590 | Val Loss: 0.173739, Val Acc: 0.639175\n",
      "Epoch 7025 - Train Loss: 0.160514, Train Acc: 0.693590 | Val Loss: 0.173728, Val Acc: 0.639175\n",
      "Epoch 7026 - Train Loss: 0.160502, Train Acc: 0.693590 | Val Loss: 0.173717, Val Acc: 0.639175\n",
      "Epoch 7027 - Train Loss: 0.160490, Train Acc: 0.693590 | Val Loss: 0.173705, Val Acc: 0.639175\n",
      "Epoch 7028 - Train Loss: 0.160478, Train Acc: 0.693590 | Val Loss: 0.173694, Val Acc: 0.639175\n",
      "Epoch 7029 - Train Loss: 0.160465, Train Acc: 0.693590 | Val Loss: 0.173682, Val Acc: 0.639175\n",
      "Epoch 7030 - Train Loss: 0.160453, Train Acc: 0.693590 | Val Loss: 0.173671, Val Acc: 0.639175\n",
      "Epoch 7031 - Train Loss: 0.160441, Train Acc: 0.693590 | Val Loss: 0.173659, Val Acc: 0.639175\n",
      "Epoch 7032 - Train Loss: 0.160429, Train Acc: 0.693590 | Val Loss: 0.173648, Val Acc: 0.639175\n",
      "Epoch 7033 - Train Loss: 0.160416, Train Acc: 0.693590 | Val Loss: 0.173636, Val Acc: 0.639175\n",
      "Epoch 7034 - Train Loss: 0.160404, Train Acc: 0.693590 | Val Loss: 0.173625, Val Acc: 0.639175\n",
      "Epoch 7035 - Train Loss: 0.160392, Train Acc: 0.693590 | Val Loss: 0.173613, Val Acc: 0.639175\n",
      "Epoch 7036 - Train Loss: 0.160380, Train Acc: 0.693590 | Val Loss: 0.173602, Val Acc: 0.639175\n",
      "Epoch 7037 - Train Loss: 0.160367, Train Acc: 0.693590 | Val Loss: 0.173591, Val Acc: 0.639175\n",
      "Epoch 7038 - Train Loss: 0.160355, Train Acc: 0.693590 | Val Loss: 0.173579, Val Acc: 0.639175\n",
      "Epoch 7039 - Train Loss: 0.160343, Train Acc: 0.693590 | Val Loss: 0.173568, Val Acc: 0.639175\n",
      "Epoch 7040 - Train Loss: 0.160331, Train Acc: 0.693590 | Val Loss: 0.173556, Val Acc: 0.639175\n",
      "Epoch 7041 - Train Loss: 0.160318, Train Acc: 0.693590 | Val Loss: 0.173545, Val Acc: 0.649485\n",
      "Epoch 7042 - Train Loss: 0.160306, Train Acc: 0.693590 | Val Loss: 0.173533, Val Acc: 0.649485\n",
      "Epoch 7043 - Train Loss: 0.160294, Train Acc: 0.693590 | Val Loss: 0.173522, Val Acc: 0.649485\n",
      "Epoch 7044 - Train Loss: 0.160282, Train Acc: 0.693590 | Val Loss: 0.173510, Val Acc: 0.649485\n",
      "Epoch 7045 - Train Loss: 0.160269, Train Acc: 0.693590 | Val Loss: 0.173499, Val Acc: 0.649485\n",
      "Epoch 7046 - Train Loss: 0.160257, Train Acc: 0.693590 | Val Loss: 0.173487, Val Acc: 0.649485\n",
      "Epoch 7047 - Train Loss: 0.160245, Train Acc: 0.693590 | Val Loss: 0.173476, Val Acc: 0.649485\n",
      "Epoch 7048 - Train Loss: 0.160233, Train Acc: 0.693590 | Val Loss: 0.173464, Val Acc: 0.649485\n",
      "Epoch 7049 - Train Loss: 0.160220, Train Acc: 0.693590 | Val Loss: 0.173453, Val Acc: 0.649485\n",
      "Epoch 7050 - Train Loss: 0.160208, Train Acc: 0.693590 | Val Loss: 0.173442, Val Acc: 0.649485\n",
      "Epoch 7051 - Train Loss: 0.160196, Train Acc: 0.693590 | Val Loss: 0.173430, Val Acc: 0.649485\n",
      "Epoch 7052 - Train Loss: 0.160184, Train Acc: 0.694872 | Val Loss: 0.173419, Val Acc: 0.649485\n",
      "Epoch 7053 - Train Loss: 0.160171, Train Acc: 0.694872 | Val Loss: 0.173407, Val Acc: 0.649485\n",
      "Epoch 7054 - Train Loss: 0.160159, Train Acc: 0.694872 | Val Loss: 0.173396, Val Acc: 0.649485\n",
      "Epoch 7055 - Train Loss: 0.160147, Train Acc: 0.694872 | Val Loss: 0.173384, Val Acc: 0.649485\n",
      "Epoch 7056 - Train Loss: 0.160135, Train Acc: 0.694872 | Val Loss: 0.173373, Val Acc: 0.649485\n",
      "Epoch 7057 - Train Loss: 0.160122, Train Acc: 0.694872 | Val Loss: 0.173361, Val Acc: 0.649485\n",
      "Epoch 7058 - Train Loss: 0.160110, Train Acc: 0.694872 | Val Loss: 0.173350, Val Acc: 0.649485\n",
      "Epoch 7059 - Train Loss: 0.160098, Train Acc: 0.694872 | Val Loss: 0.173338, Val Acc: 0.649485\n",
      "Epoch 7060 - Train Loss: 0.160086, Train Acc: 0.694872 | Val Loss: 0.173327, Val Acc: 0.649485\n",
      "Epoch 7061 - Train Loss: 0.160074, Train Acc: 0.694872 | Val Loss: 0.173315, Val Acc: 0.649485\n",
      "Epoch 7062 - Train Loss: 0.160061, Train Acc: 0.694872 | Val Loss: 0.173304, Val Acc: 0.649485\n",
      "Epoch 7063 - Train Loss: 0.160049, Train Acc: 0.694872 | Val Loss: 0.173292, Val Acc: 0.649485\n",
      "Epoch 7064 - Train Loss: 0.160037, Train Acc: 0.694872 | Val Loss: 0.173281, Val Acc: 0.649485\n",
      "Epoch 7065 - Train Loss: 0.160025, Train Acc: 0.696154 | Val Loss: 0.173269, Val Acc: 0.639175\n",
      "Epoch 7066 - Train Loss: 0.160012, Train Acc: 0.696154 | Val Loss: 0.173258, Val Acc: 0.639175\n",
      "Epoch 7067 - Train Loss: 0.160000, Train Acc: 0.696154 | Val Loss: 0.173246, Val Acc: 0.639175\n",
      "Epoch 7068 - Train Loss: 0.159988, Train Acc: 0.696154 | Val Loss: 0.173235, Val Acc: 0.639175\n",
      "Epoch 7069 - Train Loss: 0.159976, Train Acc: 0.696154 | Val Loss: 0.173224, Val Acc: 0.639175\n",
      "Epoch 7070 - Train Loss: 0.159963, Train Acc: 0.697436 | Val Loss: 0.173212, Val Acc: 0.639175\n",
      "Epoch 7071 - Train Loss: 0.159951, Train Acc: 0.697436 | Val Loss: 0.173201, Val Acc: 0.639175\n",
      "Epoch 7072 - Train Loss: 0.159939, Train Acc: 0.697436 | Val Loss: 0.173189, Val Acc: 0.639175\n",
      "Epoch 7073 - Train Loss: 0.159927, Train Acc: 0.697436 | Val Loss: 0.173177, Val Acc: 0.639175\n",
      "Epoch 7074 - Train Loss: 0.159915, Train Acc: 0.697436 | Val Loss: 0.173166, Val Acc: 0.639175\n",
      "Epoch 7075 - Train Loss: 0.159902, Train Acc: 0.697436 | Val Loss: 0.173154, Val Acc: 0.639175\n",
      "Epoch 7076 - Train Loss: 0.159890, Train Acc: 0.697436 | Val Loss: 0.173143, Val Acc: 0.639175\n",
      "Epoch 7077 - Train Loss: 0.159878, Train Acc: 0.697436 | Val Loss: 0.173131, Val Acc: 0.639175\n",
      "Epoch 7078 - Train Loss: 0.159866, Train Acc: 0.697436 | Val Loss: 0.173120, Val Acc: 0.639175\n",
      "Epoch 7079 - Train Loss: 0.159854, Train Acc: 0.697436 | Val Loss: 0.173108, Val Acc: 0.639175\n",
      "Epoch 7080 - Train Loss: 0.159841, Train Acc: 0.697436 | Val Loss: 0.173097, Val Acc: 0.639175\n",
      "Epoch 7081 - Train Loss: 0.159829, Train Acc: 0.697436 | Val Loss: 0.173085, Val Acc: 0.639175\n",
      "Epoch 7082 - Train Loss: 0.159817, Train Acc: 0.697436 | Val Loss: 0.173073, Val Acc: 0.639175\n",
      "Epoch 7083 - Train Loss: 0.159805, Train Acc: 0.697436 | Val Loss: 0.173062, Val Acc: 0.639175\n",
      "Epoch 7084 - Train Loss: 0.159793, Train Acc: 0.697436 | Val Loss: 0.173050, Val Acc: 0.639175\n",
      "Epoch 7085 - Train Loss: 0.159780, Train Acc: 0.697436 | Val Loss: 0.173039, Val Acc: 0.639175\n",
      "Epoch 7086 - Train Loss: 0.159768, Train Acc: 0.697436 | Val Loss: 0.173027, Val Acc: 0.639175\n",
      "Epoch 7087 - Train Loss: 0.159756, Train Acc: 0.697436 | Val Loss: 0.173016, Val Acc: 0.639175\n",
      "Epoch 7088 - Train Loss: 0.159744, Train Acc: 0.697436 | Val Loss: 0.173004, Val Acc: 0.639175\n",
      "Epoch 7089 - Train Loss: 0.159732, Train Acc: 0.697436 | Val Loss: 0.172993, Val Acc: 0.639175\n",
      "Epoch 7090 - Train Loss: 0.159719, Train Acc: 0.697436 | Val Loss: 0.172981, Val Acc: 0.639175\n",
      "Epoch 7091 - Train Loss: 0.159707, Train Acc: 0.697436 | Val Loss: 0.172970, Val Acc: 0.639175\n",
      "Epoch 7092 - Train Loss: 0.159695, Train Acc: 0.697436 | Val Loss: 0.172958, Val Acc: 0.639175\n",
      "Epoch 7093 - Train Loss: 0.159683, Train Acc: 0.697436 | Val Loss: 0.172947, Val Acc: 0.639175\n",
      "Epoch 7094 - Train Loss: 0.159671, Train Acc: 0.697436 | Val Loss: 0.172935, Val Acc: 0.639175\n",
      "Epoch 7095 - Train Loss: 0.159658, Train Acc: 0.697436 | Val Loss: 0.172924, Val Acc: 0.639175\n",
      "Epoch 7096 - Train Loss: 0.159646, Train Acc: 0.697436 | Val Loss: 0.172912, Val Acc: 0.639175\n",
      "Epoch 7097 - Train Loss: 0.159634, Train Acc: 0.697436 | Val Loss: 0.172901, Val Acc: 0.639175\n",
      "Epoch 7098 - Train Loss: 0.159622, Train Acc: 0.697436 | Val Loss: 0.172889, Val Acc: 0.639175\n",
      "Epoch 7099 - Train Loss: 0.159610, Train Acc: 0.697436 | Val Loss: 0.172878, Val Acc: 0.639175\n",
      "Epoch 7100 - Train Loss: 0.159597, Train Acc: 0.697436 | Val Loss: 0.172866, Val Acc: 0.639175\n",
      "Epoch 7101 - Train Loss: 0.159585, Train Acc: 0.697436 | Val Loss: 0.172855, Val Acc: 0.639175\n",
      "Epoch 7102 - Train Loss: 0.159573, Train Acc: 0.697436 | Val Loss: 0.172843, Val Acc: 0.639175\n",
      "Epoch 7103 - Train Loss: 0.159561, Train Acc: 0.697436 | Val Loss: 0.172832, Val Acc: 0.639175\n",
      "Epoch 7104 - Train Loss: 0.159549, Train Acc: 0.697436 | Val Loss: 0.172820, Val Acc: 0.639175\n",
      "Epoch 7105 - Train Loss: 0.159536, Train Acc: 0.697436 | Val Loss: 0.172809, Val Acc: 0.639175\n",
      "Epoch 7106 - Train Loss: 0.159524, Train Acc: 0.697436 | Val Loss: 0.172797, Val Acc: 0.639175\n",
      "Epoch 7107 - Train Loss: 0.159512, Train Acc: 0.697436 | Val Loss: 0.172786, Val Acc: 0.639175\n",
      "Epoch 7108 - Train Loss: 0.159500, Train Acc: 0.697436 | Val Loss: 0.172774, Val Acc: 0.639175\n",
      "Epoch 7109 - Train Loss: 0.159488, Train Acc: 0.697436 | Val Loss: 0.172763, Val Acc: 0.639175\n",
      "Epoch 7110 - Train Loss: 0.159476, Train Acc: 0.697436 | Val Loss: 0.172751, Val Acc: 0.639175\n",
      "Epoch 7111 - Train Loss: 0.159463, Train Acc: 0.697436 | Val Loss: 0.172740, Val Acc: 0.639175\n",
      "Epoch 7112 - Train Loss: 0.159451, Train Acc: 0.697436 | Val Loss: 0.172728, Val Acc: 0.639175\n",
      "Epoch 7113 - Train Loss: 0.159439, Train Acc: 0.697436 | Val Loss: 0.172717, Val Acc: 0.639175\n",
      "Epoch 7114 - Train Loss: 0.159427, Train Acc: 0.697436 | Val Loss: 0.172705, Val Acc: 0.639175\n",
      "Epoch 7115 - Train Loss: 0.159415, Train Acc: 0.697436 | Val Loss: 0.172694, Val Acc: 0.639175\n",
      "Epoch 7116 - Train Loss: 0.159403, Train Acc: 0.697436 | Val Loss: 0.172682, Val Acc: 0.639175\n",
      "Epoch 7117 - Train Loss: 0.159390, Train Acc: 0.697436 | Val Loss: 0.172671, Val Acc: 0.639175\n",
      "Epoch 7118 - Train Loss: 0.159378, Train Acc: 0.697436 | Val Loss: 0.172660, Val Acc: 0.639175\n",
      "Epoch 7119 - Train Loss: 0.159366, Train Acc: 0.697436 | Val Loss: 0.172648, Val Acc: 0.639175\n",
      "Epoch 7120 - Train Loss: 0.159354, Train Acc: 0.697436 | Val Loss: 0.172637, Val Acc: 0.639175\n",
      "Epoch 7121 - Train Loss: 0.159342, Train Acc: 0.697436 | Val Loss: 0.172625, Val Acc: 0.639175\n",
      "Epoch 7122 - Train Loss: 0.159330, Train Acc: 0.697436 | Val Loss: 0.172614, Val Acc: 0.639175\n",
      "Epoch 7123 - Train Loss: 0.159317, Train Acc: 0.697436 | Val Loss: 0.172602, Val Acc: 0.639175\n",
      "Epoch 7124 - Train Loss: 0.159305, Train Acc: 0.697436 | Val Loss: 0.172591, Val Acc: 0.639175\n",
      "Epoch 7125 - Train Loss: 0.159293, Train Acc: 0.697436 | Val Loss: 0.172579, Val Acc: 0.639175\n",
      "Epoch 7126 - Train Loss: 0.159281, Train Acc: 0.697436 | Val Loss: 0.172568, Val Acc: 0.639175\n",
      "Epoch 7127 - Train Loss: 0.159269, Train Acc: 0.697436 | Val Loss: 0.172556, Val Acc: 0.639175\n",
      "Epoch 7128 - Train Loss: 0.159257, Train Acc: 0.697436 | Val Loss: 0.172545, Val Acc: 0.639175\n",
      "Epoch 7129 - Train Loss: 0.159244, Train Acc: 0.697436 | Val Loss: 0.172534, Val Acc: 0.639175\n",
      "Epoch 7130 - Train Loss: 0.159232, Train Acc: 0.697436 | Val Loss: 0.172522, Val Acc: 0.639175\n",
      "Epoch 7131 - Train Loss: 0.159220, Train Acc: 0.697436 | Val Loss: 0.172511, Val Acc: 0.639175\n",
      "Epoch 7132 - Train Loss: 0.159208, Train Acc: 0.697436 | Val Loss: 0.172499, Val Acc: 0.639175\n",
      "Epoch 7133 - Train Loss: 0.159196, Train Acc: 0.697436 | Val Loss: 0.172488, Val Acc: 0.639175\n",
      "Epoch 7134 - Train Loss: 0.159184, Train Acc: 0.697436 | Val Loss: 0.172476, Val Acc: 0.639175\n",
      "Epoch 7135 - Train Loss: 0.159171, Train Acc: 0.697436 | Val Loss: 0.172465, Val Acc: 0.639175\n",
      "Epoch 7136 - Train Loss: 0.159159, Train Acc: 0.697436 | Val Loss: 0.172453, Val Acc: 0.639175\n",
      "Epoch 7137 - Train Loss: 0.159147, Train Acc: 0.697436 | Val Loss: 0.172442, Val Acc: 0.639175\n",
      "Epoch 7138 - Train Loss: 0.159135, Train Acc: 0.697436 | Val Loss: 0.172431, Val Acc: 0.639175\n",
      "Epoch 7139 - Train Loss: 0.159123, Train Acc: 0.697436 | Val Loss: 0.172419, Val Acc: 0.639175\n",
      "Epoch 7140 - Train Loss: 0.159111, Train Acc: 0.697436 | Val Loss: 0.172408, Val Acc: 0.639175\n",
      "Epoch 7141 - Train Loss: 0.159099, Train Acc: 0.697436 | Val Loss: 0.172396, Val Acc: 0.639175\n",
      "Epoch 7142 - Train Loss: 0.159086, Train Acc: 0.697436 | Val Loss: 0.172385, Val Acc: 0.639175\n",
      "Epoch 7143 - Train Loss: 0.159074, Train Acc: 0.697436 | Val Loss: 0.172373, Val Acc: 0.639175\n",
      "Epoch 7144 - Train Loss: 0.159062, Train Acc: 0.697436 | Val Loss: 0.172362, Val Acc: 0.639175\n",
      "Epoch 7145 - Train Loss: 0.159050, Train Acc: 0.697436 | Val Loss: 0.172351, Val Acc: 0.639175\n",
      "Epoch 7146 - Train Loss: 0.159038, Train Acc: 0.697436 | Val Loss: 0.172339, Val Acc: 0.639175\n",
      "Epoch 7147 - Train Loss: 0.159026, Train Acc: 0.697436 | Val Loss: 0.172328, Val Acc: 0.639175\n",
      "Epoch 7148 - Train Loss: 0.159014, Train Acc: 0.697436 | Val Loss: 0.172316, Val Acc: 0.639175\n",
      "Epoch 7149 - Train Loss: 0.159001, Train Acc: 0.697436 | Val Loss: 0.172305, Val Acc: 0.639175\n",
      "Epoch 7150 - Train Loss: 0.158989, Train Acc: 0.697436 | Val Loss: 0.172293, Val Acc: 0.639175\n",
      "Epoch 7151 - Train Loss: 0.158977, Train Acc: 0.697436 | Val Loss: 0.172282, Val Acc: 0.639175\n",
      "Epoch 7152 - Train Loss: 0.158965, Train Acc: 0.697436 | Val Loss: 0.172271, Val Acc: 0.639175\n",
      "Epoch 7153 - Train Loss: 0.158953, Train Acc: 0.697436 | Val Loss: 0.172259, Val Acc: 0.639175\n",
      "Epoch 7154 - Train Loss: 0.158941, Train Acc: 0.697436 | Val Loss: 0.172248, Val Acc: 0.639175\n",
      "Epoch 7155 - Train Loss: 0.158929, Train Acc: 0.697436 | Val Loss: 0.172236, Val Acc: 0.639175\n",
      "Epoch 7156 - Train Loss: 0.158917, Train Acc: 0.697436 | Val Loss: 0.172225, Val Acc: 0.639175\n",
      "Epoch 7157 - Train Loss: 0.158904, Train Acc: 0.697436 | Val Loss: 0.172214, Val Acc: 0.639175\n",
      "Epoch 7158 - Train Loss: 0.158892, Train Acc: 0.697436 | Val Loss: 0.172202, Val Acc: 0.639175\n",
      "Epoch 7159 - Train Loss: 0.158880, Train Acc: 0.697436 | Val Loss: 0.172191, Val Acc: 0.639175\n",
      "Epoch 7160 - Train Loss: 0.158868, Train Acc: 0.697436 | Val Loss: 0.172179, Val Acc: 0.639175\n",
      "Epoch 7161 - Train Loss: 0.158856, Train Acc: 0.697436 | Val Loss: 0.172168, Val Acc: 0.639175\n",
      "Epoch 7162 - Train Loss: 0.158844, Train Acc: 0.697436 | Val Loss: 0.172157, Val Acc: 0.639175\n",
      "Epoch 7163 - Train Loss: 0.158832, Train Acc: 0.697436 | Val Loss: 0.172145, Val Acc: 0.639175\n",
      "Epoch 7164 - Train Loss: 0.158820, Train Acc: 0.697436 | Val Loss: 0.172134, Val Acc: 0.639175\n",
      "Epoch 7165 - Train Loss: 0.158807, Train Acc: 0.697436 | Val Loss: 0.172122, Val Acc: 0.639175\n",
      "Epoch 7166 - Train Loss: 0.158795, Train Acc: 0.697436 | Val Loss: 0.172111, Val Acc: 0.639175\n",
      "Epoch 7167 - Train Loss: 0.158783, Train Acc: 0.697436 | Val Loss: 0.172100, Val Acc: 0.639175\n",
      "Epoch 7168 - Train Loss: 0.158771, Train Acc: 0.697436 | Val Loss: 0.172088, Val Acc: 0.639175\n",
      "Epoch 7169 - Train Loss: 0.158759, Train Acc: 0.697436 | Val Loss: 0.172077, Val Acc: 0.639175\n",
      "Epoch 7170 - Train Loss: 0.158747, Train Acc: 0.697436 | Val Loss: 0.172065, Val Acc: 0.639175\n",
      "Epoch 7171 - Train Loss: 0.158735, Train Acc: 0.697436 | Val Loss: 0.172054, Val Acc: 0.639175\n",
      "Epoch 7172 - Train Loss: 0.158723, Train Acc: 0.697436 | Val Loss: 0.172043, Val Acc: 0.639175\n",
      "Epoch 7173 - Train Loss: 0.158710, Train Acc: 0.697436 | Val Loss: 0.172031, Val Acc: 0.639175\n",
      "Epoch 7174 - Train Loss: 0.158698, Train Acc: 0.697436 | Val Loss: 0.172020, Val Acc: 0.639175\n",
      "Epoch 7175 - Train Loss: 0.158686, Train Acc: 0.697436 | Val Loss: 0.172009, Val Acc: 0.639175\n",
      "Epoch 7176 - Train Loss: 0.158674, Train Acc: 0.697436 | Val Loss: 0.171997, Val Acc: 0.639175\n",
      "Epoch 7177 - Train Loss: 0.158662, Train Acc: 0.697436 | Val Loss: 0.171986, Val Acc: 0.639175\n",
      "Epoch 7178 - Train Loss: 0.158650, Train Acc: 0.697436 | Val Loss: 0.171974, Val Acc: 0.639175\n",
      "Epoch 7179 - Train Loss: 0.158638, Train Acc: 0.697436 | Val Loss: 0.171963, Val Acc: 0.639175\n",
      "Epoch 7180 - Train Loss: 0.158626, Train Acc: 0.697436 | Val Loss: 0.171952, Val Acc: 0.639175\n",
      "Epoch 7181 - Train Loss: 0.158614, Train Acc: 0.697436 | Val Loss: 0.171940, Val Acc: 0.639175\n",
      "Epoch 7182 - Train Loss: 0.158602, Train Acc: 0.697436 | Val Loss: 0.171929, Val Acc: 0.639175\n",
      "Epoch 7183 - Train Loss: 0.158589, Train Acc: 0.697436 | Val Loss: 0.171917, Val Acc: 0.639175\n",
      "Epoch 7184 - Train Loss: 0.158577, Train Acc: 0.697436 | Val Loss: 0.171906, Val Acc: 0.639175\n",
      "Epoch 7185 - Train Loss: 0.158565, Train Acc: 0.697436 | Val Loss: 0.171895, Val Acc: 0.639175\n",
      "Epoch 7186 - Train Loss: 0.158553, Train Acc: 0.697436 | Val Loss: 0.171883, Val Acc: 0.639175\n",
      "Epoch 7187 - Train Loss: 0.158541, Train Acc: 0.697436 | Val Loss: 0.171872, Val Acc: 0.639175\n",
      "Epoch 7188 - Train Loss: 0.158529, Train Acc: 0.697436 | Val Loss: 0.171861, Val Acc: 0.639175\n",
      "Epoch 7189 - Train Loss: 0.158517, Train Acc: 0.697436 | Val Loss: 0.171849, Val Acc: 0.639175\n",
      "Epoch 7190 - Train Loss: 0.158505, Train Acc: 0.697436 | Val Loss: 0.171838, Val Acc: 0.639175\n",
      "Epoch 7191 - Train Loss: 0.158493, Train Acc: 0.697436 | Val Loss: 0.171827, Val Acc: 0.639175\n",
      "Epoch 7192 - Train Loss: 0.158481, Train Acc: 0.697436 | Val Loss: 0.171815, Val Acc: 0.639175\n",
      "Epoch 7193 - Train Loss: 0.158468, Train Acc: 0.697436 | Val Loss: 0.171804, Val Acc: 0.639175\n",
      "Epoch 7194 - Train Loss: 0.158456, Train Acc: 0.697436 | Val Loss: 0.171793, Val Acc: 0.639175\n",
      "Epoch 7195 - Train Loss: 0.158444, Train Acc: 0.697436 | Val Loss: 0.171781, Val Acc: 0.639175\n",
      "Epoch 7196 - Train Loss: 0.158432, Train Acc: 0.697436 | Val Loss: 0.171770, Val Acc: 0.639175\n",
      "Epoch 7197 - Train Loss: 0.158420, Train Acc: 0.697436 | Val Loss: 0.171758, Val Acc: 0.639175\n",
      "Epoch 7198 - Train Loss: 0.158408, Train Acc: 0.697436 | Val Loss: 0.171747, Val Acc: 0.639175\n",
      "Epoch 7199 - Train Loss: 0.158396, Train Acc: 0.698718 | Val Loss: 0.171736, Val Acc: 0.639175\n",
      "Epoch 7200 - Train Loss: 0.158384, Train Acc: 0.698718 | Val Loss: 0.171724, Val Acc: 0.639175\n",
      "Epoch 7201 - Train Loss: 0.158372, Train Acc: 0.698718 | Val Loss: 0.171713, Val Acc: 0.639175\n",
      "Epoch 7202 - Train Loss: 0.158360, Train Acc: 0.698718 | Val Loss: 0.171702, Val Acc: 0.639175\n",
      "Epoch 7203 - Train Loss: 0.158348, Train Acc: 0.698718 | Val Loss: 0.171690, Val Acc: 0.639175\n",
      "Epoch 7204 - Train Loss: 0.158336, Train Acc: 0.698718 | Val Loss: 0.171679, Val Acc: 0.639175\n",
      "Epoch 7205 - Train Loss: 0.158323, Train Acc: 0.698718 | Val Loss: 0.171668, Val Acc: 0.639175\n",
      "Epoch 7206 - Train Loss: 0.158311, Train Acc: 0.700000 | Val Loss: 0.171656, Val Acc: 0.639175\n",
      "Epoch 7207 - Train Loss: 0.158299, Train Acc: 0.700000 | Val Loss: 0.171645, Val Acc: 0.639175\n",
      "Epoch 7208 - Train Loss: 0.158287, Train Acc: 0.700000 | Val Loss: 0.171634, Val Acc: 0.639175\n",
      "Epoch 7209 - Train Loss: 0.158275, Train Acc: 0.700000 | Val Loss: 0.171622, Val Acc: 0.639175\n",
      "Epoch 7210 - Train Loss: 0.158263, Train Acc: 0.700000 | Val Loss: 0.171611, Val Acc: 0.639175\n",
      "Epoch 7211 - Train Loss: 0.158251, Train Acc: 0.700000 | Val Loss: 0.171600, Val Acc: 0.639175\n",
      "Epoch 7212 - Train Loss: 0.158239, Train Acc: 0.700000 | Val Loss: 0.171588, Val Acc: 0.639175\n",
      "Epoch 7213 - Train Loss: 0.158227, Train Acc: 0.700000 | Val Loss: 0.171577, Val Acc: 0.639175\n",
      "Epoch 7214 - Train Loss: 0.158215, Train Acc: 0.700000 | Val Loss: 0.171566, Val Acc: 0.639175\n",
      "Epoch 7215 - Train Loss: 0.158203, Train Acc: 0.700000 | Val Loss: 0.171554, Val Acc: 0.639175\n",
      "Epoch 7216 - Train Loss: 0.158191, Train Acc: 0.700000 | Val Loss: 0.171543, Val Acc: 0.639175\n",
      "Epoch 7217 - Train Loss: 0.158179, Train Acc: 0.700000 | Val Loss: 0.171532, Val Acc: 0.639175\n",
      "Epoch 7218 - Train Loss: 0.158167, Train Acc: 0.700000 | Val Loss: 0.171520, Val Acc: 0.639175\n",
      "Epoch 7219 - Train Loss: 0.158154, Train Acc: 0.700000 | Val Loss: 0.171509, Val Acc: 0.639175\n",
      "Epoch 7220 - Train Loss: 0.158142, Train Acc: 0.700000 | Val Loss: 0.171498, Val Acc: 0.639175\n",
      "Epoch 7221 - Train Loss: 0.158130, Train Acc: 0.700000 | Val Loss: 0.171486, Val Acc: 0.639175\n",
      "Epoch 7222 - Train Loss: 0.158118, Train Acc: 0.700000 | Val Loss: 0.171475, Val Acc: 0.639175\n",
      "Epoch 7223 - Train Loss: 0.158106, Train Acc: 0.700000 | Val Loss: 0.171464, Val Acc: 0.639175\n",
      "Epoch 7224 - Train Loss: 0.158094, Train Acc: 0.700000 | Val Loss: 0.171452, Val Acc: 0.639175\n",
      "Epoch 7225 - Train Loss: 0.158082, Train Acc: 0.700000 | Val Loss: 0.171441, Val Acc: 0.639175\n",
      "Epoch 7226 - Train Loss: 0.158070, Train Acc: 0.700000 | Val Loss: 0.171430, Val Acc: 0.639175\n",
      "Epoch 7227 - Train Loss: 0.158058, Train Acc: 0.700000 | Val Loss: 0.171419, Val Acc: 0.639175\n",
      "Epoch 7228 - Train Loss: 0.158046, Train Acc: 0.700000 | Val Loss: 0.171407, Val Acc: 0.639175\n",
      "Epoch 7229 - Train Loss: 0.158034, Train Acc: 0.700000 | Val Loss: 0.171396, Val Acc: 0.639175\n",
      "Epoch 7230 - Train Loss: 0.158022, Train Acc: 0.700000 | Val Loss: 0.171385, Val Acc: 0.639175\n",
      "Epoch 7231 - Train Loss: 0.158010, Train Acc: 0.700000 | Val Loss: 0.171373, Val Acc: 0.639175\n",
      "Epoch 7232 - Train Loss: 0.157998, Train Acc: 0.700000 | Val Loss: 0.171362, Val Acc: 0.639175\n",
      "Epoch 7233 - Train Loss: 0.157986, Train Acc: 0.700000 | Val Loss: 0.171351, Val Acc: 0.639175\n",
      "Epoch 7234 - Train Loss: 0.157974, Train Acc: 0.700000 | Val Loss: 0.171339, Val Acc: 0.639175\n",
      "Epoch 7235 - Train Loss: 0.157962, Train Acc: 0.700000 | Val Loss: 0.171328, Val Acc: 0.639175\n",
      "Epoch 7236 - Train Loss: 0.157950, Train Acc: 0.700000 | Val Loss: 0.171317, Val Acc: 0.639175\n",
      "Epoch 7237 - Train Loss: 0.157938, Train Acc: 0.700000 | Val Loss: 0.171305, Val Acc: 0.639175\n",
      "Epoch 7238 - Train Loss: 0.157925, Train Acc: 0.700000 | Val Loss: 0.171294, Val Acc: 0.639175\n",
      "Epoch 7239 - Train Loss: 0.157913, Train Acc: 0.700000 | Val Loss: 0.171283, Val Acc: 0.639175\n",
      "Epoch 7240 - Train Loss: 0.157901, Train Acc: 0.700000 | Val Loss: 0.171272, Val Acc: 0.639175\n",
      "Epoch 7241 - Train Loss: 0.157889, Train Acc: 0.700000 | Val Loss: 0.171260, Val Acc: 0.639175\n",
      "Epoch 7242 - Train Loss: 0.157877, Train Acc: 0.700000 | Val Loss: 0.171249, Val Acc: 0.639175\n",
      "Epoch 7243 - Train Loss: 0.157865, Train Acc: 0.700000 | Val Loss: 0.171238, Val Acc: 0.639175\n",
      "Epoch 7244 - Train Loss: 0.157853, Train Acc: 0.700000 | Val Loss: 0.171226, Val Acc: 0.639175\n",
      "Epoch 7245 - Train Loss: 0.157841, Train Acc: 0.700000 | Val Loss: 0.171215, Val Acc: 0.639175\n",
      "Epoch 7246 - Train Loss: 0.157829, Train Acc: 0.700000 | Val Loss: 0.171204, Val Acc: 0.639175\n",
      "Epoch 7247 - Train Loss: 0.157817, Train Acc: 0.700000 | Val Loss: 0.171193, Val Acc: 0.639175\n",
      "Epoch 7248 - Train Loss: 0.157805, Train Acc: 0.700000 | Val Loss: 0.171181, Val Acc: 0.639175\n",
      "Epoch 7249 - Train Loss: 0.157793, Train Acc: 0.700000 | Val Loss: 0.171170, Val Acc: 0.639175\n",
      "Epoch 7250 - Train Loss: 0.157781, Train Acc: 0.701282 | Val Loss: 0.171159, Val Acc: 0.639175\n",
      "Epoch 7251 - Train Loss: 0.157769, Train Acc: 0.701282 | Val Loss: 0.171147, Val Acc: 0.639175\n",
      "Epoch 7252 - Train Loss: 0.157757, Train Acc: 0.701282 | Val Loss: 0.171136, Val Acc: 0.639175\n",
      "Epoch 7253 - Train Loss: 0.157745, Train Acc: 0.701282 | Val Loss: 0.171125, Val Acc: 0.639175\n",
      "Epoch 7254 - Train Loss: 0.157733, Train Acc: 0.701282 | Val Loss: 0.171114, Val Acc: 0.639175\n",
      "Epoch 7255 - Train Loss: 0.157721, Train Acc: 0.701282 | Val Loss: 0.171102, Val Acc: 0.639175\n",
      "Epoch 7256 - Train Loss: 0.157709, Train Acc: 0.701282 | Val Loss: 0.171091, Val Acc: 0.639175\n",
      "Epoch 7257 - Train Loss: 0.157697, Train Acc: 0.701282 | Val Loss: 0.171080, Val Acc: 0.639175\n",
      "Epoch 7258 - Train Loss: 0.157685, Train Acc: 0.701282 | Val Loss: 0.171068, Val Acc: 0.639175\n",
      "Epoch 7259 - Train Loss: 0.157673, Train Acc: 0.702564 | Val Loss: 0.171057, Val Acc: 0.639175\n",
      "Epoch 7260 - Train Loss: 0.157661, Train Acc: 0.702564 | Val Loss: 0.171046, Val Acc: 0.639175\n",
      "Epoch 7261 - Train Loss: 0.157649, Train Acc: 0.702564 | Val Loss: 0.171035, Val Acc: 0.639175\n",
      "Epoch 7262 - Train Loss: 0.157637, Train Acc: 0.702564 | Val Loss: 0.171023, Val Acc: 0.639175\n",
      "Epoch 7263 - Train Loss: 0.157625, Train Acc: 0.702564 | Val Loss: 0.171012, Val Acc: 0.639175\n",
      "Epoch 7264 - Train Loss: 0.157613, Train Acc: 0.702564 | Val Loss: 0.171001, Val Acc: 0.639175\n",
      "Epoch 7265 - Train Loss: 0.157601, Train Acc: 0.702564 | Val Loss: 0.170990, Val Acc: 0.639175\n",
      "Epoch 7266 - Train Loss: 0.157589, Train Acc: 0.702564 | Val Loss: 0.170978, Val Acc: 0.639175\n",
      "Epoch 7267 - Train Loss: 0.157577, Train Acc: 0.702564 | Val Loss: 0.170967, Val Acc: 0.639175\n",
      "Epoch 7268 - Train Loss: 0.157565, Train Acc: 0.702564 | Val Loss: 0.170956, Val Acc: 0.639175\n",
      "Epoch 7269 - Train Loss: 0.157553, Train Acc: 0.702564 | Val Loss: 0.170945, Val Acc: 0.639175\n",
      "Epoch 7270 - Train Loss: 0.157541, Train Acc: 0.702564 | Val Loss: 0.170933, Val Acc: 0.639175\n",
      "Epoch 7271 - Train Loss: 0.157529, Train Acc: 0.702564 | Val Loss: 0.170922, Val Acc: 0.639175\n",
      "Epoch 7272 - Train Loss: 0.157517, Train Acc: 0.702564 | Val Loss: 0.170911, Val Acc: 0.639175\n",
      "Epoch 7273 - Train Loss: 0.157505, Train Acc: 0.702564 | Val Loss: 0.170900, Val Acc: 0.639175\n",
      "Epoch 7274 - Train Loss: 0.157493, Train Acc: 0.702564 | Val Loss: 0.170888, Val Acc: 0.639175\n",
      "Epoch 7275 - Train Loss: 0.157481, Train Acc: 0.702564 | Val Loss: 0.170877, Val Acc: 0.639175\n",
      "Epoch 7276 - Train Loss: 0.157469, Train Acc: 0.703846 | Val Loss: 0.170866, Val Acc: 0.639175\n",
      "Epoch 7277 - Train Loss: 0.157457, Train Acc: 0.703846 | Val Loss: 0.170855, Val Acc: 0.639175\n",
      "Epoch 7278 - Train Loss: 0.157445, Train Acc: 0.703846 | Val Loss: 0.170843, Val Acc: 0.639175\n",
      "Epoch 7279 - Train Loss: 0.157433, Train Acc: 0.703846 | Val Loss: 0.170832, Val Acc: 0.639175\n",
      "Epoch 7280 - Train Loss: 0.157421, Train Acc: 0.703846 | Val Loss: 0.170821, Val Acc: 0.639175\n",
      "Epoch 7281 - Train Loss: 0.157409, Train Acc: 0.706410 | Val Loss: 0.170810, Val Acc: 0.639175\n",
      "Epoch 7282 - Train Loss: 0.157397, Train Acc: 0.706410 | Val Loss: 0.170798, Val Acc: 0.639175\n",
      "Epoch 7283 - Train Loss: 0.157385, Train Acc: 0.707692 | Val Loss: 0.170787, Val Acc: 0.639175\n",
      "Epoch 7284 - Train Loss: 0.157373, Train Acc: 0.707692 | Val Loss: 0.170776, Val Acc: 0.639175\n",
      "Epoch 7285 - Train Loss: 0.157361, Train Acc: 0.707692 | Val Loss: 0.170765, Val Acc: 0.639175\n",
      "Epoch 7286 - Train Loss: 0.157349, Train Acc: 0.707692 | Val Loss: 0.170753, Val Acc: 0.639175\n",
      "Epoch 7287 - Train Loss: 0.157337, Train Acc: 0.707692 | Val Loss: 0.170742, Val Acc: 0.639175\n",
      "Epoch 7288 - Train Loss: 0.157325, Train Acc: 0.707692 | Val Loss: 0.170731, Val Acc: 0.639175\n",
      "Epoch 7289 - Train Loss: 0.157313, Train Acc: 0.707692 | Val Loss: 0.170720, Val Acc: 0.639175\n",
      "Epoch 7290 - Train Loss: 0.157301, Train Acc: 0.707692 | Val Loss: 0.170709, Val Acc: 0.639175\n",
      "Epoch 7291 - Train Loss: 0.157289, Train Acc: 0.707692 | Val Loss: 0.170697, Val Acc: 0.639175\n",
      "Epoch 7292 - Train Loss: 0.157277, Train Acc: 0.707692 | Val Loss: 0.170686, Val Acc: 0.639175\n",
      "Epoch 7293 - Train Loss: 0.157265, Train Acc: 0.707692 | Val Loss: 0.170675, Val Acc: 0.639175\n",
      "Epoch 7294 - Train Loss: 0.157253, Train Acc: 0.707692 | Val Loss: 0.170664, Val Acc: 0.639175\n",
      "Epoch 7295 - Train Loss: 0.157241, Train Acc: 0.707692 | Val Loss: 0.170652, Val Acc: 0.639175\n",
      "Epoch 7296 - Train Loss: 0.157229, Train Acc: 0.707692 | Val Loss: 0.170641, Val Acc: 0.639175\n",
      "Epoch 7297 - Train Loss: 0.157217, Train Acc: 0.707692 | Val Loss: 0.170630, Val Acc: 0.639175\n",
      "Epoch 7298 - Train Loss: 0.157205, Train Acc: 0.707692 | Val Loss: 0.170619, Val Acc: 0.639175\n",
      "Epoch 7299 - Train Loss: 0.157193, Train Acc: 0.707692 | Val Loss: 0.170608, Val Acc: 0.639175\n",
      "Epoch 7300 - Train Loss: 0.157181, Train Acc: 0.707692 | Val Loss: 0.170596, Val Acc: 0.639175\n",
      "Epoch 7301 - Train Loss: 0.157169, Train Acc: 0.707692 | Val Loss: 0.170585, Val Acc: 0.639175\n",
      "Epoch 7302 - Train Loss: 0.157157, Train Acc: 0.707692 | Val Loss: 0.170574, Val Acc: 0.639175\n",
      "Epoch 7303 - Train Loss: 0.157145, Train Acc: 0.707692 | Val Loss: 0.170563, Val Acc: 0.639175\n",
      "Epoch 7304 - Train Loss: 0.157133, Train Acc: 0.707692 | Val Loss: 0.170551, Val Acc: 0.639175\n",
      "Epoch 7305 - Train Loss: 0.157121, Train Acc: 0.707692 | Val Loss: 0.170540, Val Acc: 0.639175\n",
      "Epoch 7306 - Train Loss: 0.157109, Train Acc: 0.707692 | Val Loss: 0.170529, Val Acc: 0.639175\n",
      "Epoch 7307 - Train Loss: 0.157097, Train Acc: 0.707692 | Val Loss: 0.170518, Val Acc: 0.639175\n",
      "Epoch 7308 - Train Loss: 0.157085, Train Acc: 0.707692 | Val Loss: 0.170507, Val Acc: 0.639175\n",
      "Epoch 7309 - Train Loss: 0.157073, Train Acc: 0.706410 | Val Loss: 0.170495, Val Acc: 0.639175\n",
      "Epoch 7310 - Train Loss: 0.157061, Train Acc: 0.706410 | Val Loss: 0.170484, Val Acc: 0.639175\n",
      "Epoch 7311 - Train Loss: 0.157049, Train Acc: 0.706410 | Val Loss: 0.170473, Val Acc: 0.639175\n",
      "Epoch 7312 - Train Loss: 0.157037, Train Acc: 0.706410 | Val Loss: 0.170462, Val Acc: 0.639175\n",
      "Epoch 7313 - Train Loss: 0.157025, Train Acc: 0.706410 | Val Loss: 0.170451, Val Acc: 0.639175\n",
      "Epoch 7314 - Train Loss: 0.157013, Train Acc: 0.706410 | Val Loss: 0.170439, Val Acc: 0.639175\n",
      "Epoch 7315 - Train Loss: 0.157001, Train Acc: 0.706410 | Val Loss: 0.170428, Val Acc: 0.639175\n",
      "Epoch 7316 - Train Loss: 0.156989, Train Acc: 0.706410 | Val Loss: 0.170417, Val Acc: 0.639175\n",
      "Epoch 7317 - Train Loss: 0.156977, Train Acc: 0.706410 | Val Loss: 0.170406, Val Acc: 0.639175\n",
      "Epoch 7318 - Train Loss: 0.156965, Train Acc: 0.706410 | Val Loss: 0.170395, Val Acc: 0.639175\n",
      "Epoch 7319 - Train Loss: 0.156953, Train Acc: 0.706410 | Val Loss: 0.170383, Val Acc: 0.639175\n",
      "Epoch 7320 - Train Loss: 0.156942, Train Acc: 0.706410 | Val Loss: 0.170372, Val Acc: 0.639175\n",
      "Epoch 7321 - Train Loss: 0.156930, Train Acc: 0.706410 | Val Loss: 0.170361, Val Acc: 0.639175\n",
      "Epoch 7322 - Train Loss: 0.156918, Train Acc: 0.706410 | Val Loss: 0.170350, Val Acc: 0.639175\n",
      "Epoch 7323 - Train Loss: 0.156906, Train Acc: 0.706410 | Val Loss: 0.170339, Val Acc: 0.639175\n",
      "Epoch 7324 - Train Loss: 0.156894, Train Acc: 0.706410 | Val Loss: 0.170328, Val Acc: 0.639175\n",
      "Epoch 7325 - Train Loss: 0.156882, Train Acc: 0.706410 | Val Loss: 0.170316, Val Acc: 0.639175\n",
      "Epoch 7326 - Train Loss: 0.156870, Train Acc: 0.706410 | Val Loss: 0.170305, Val Acc: 0.639175\n",
      "Epoch 7327 - Train Loss: 0.156858, Train Acc: 0.707692 | Val Loss: 0.170294, Val Acc: 0.639175\n",
      "Epoch 7328 - Train Loss: 0.156846, Train Acc: 0.707692 | Val Loss: 0.170283, Val Acc: 0.639175\n",
      "Epoch 7329 - Train Loss: 0.156834, Train Acc: 0.707692 | Val Loss: 0.170272, Val Acc: 0.639175\n",
      "Epoch 7330 - Train Loss: 0.156822, Train Acc: 0.707692 | Val Loss: 0.170260, Val Acc: 0.639175\n",
      "Epoch 7331 - Train Loss: 0.156810, Train Acc: 0.707692 | Val Loss: 0.170249, Val Acc: 0.639175\n",
      "Epoch 7332 - Train Loss: 0.156798, Train Acc: 0.707692 | Val Loss: 0.170238, Val Acc: 0.639175\n",
      "Epoch 7333 - Train Loss: 0.156786, Train Acc: 0.707692 | Val Loss: 0.170227, Val Acc: 0.639175\n",
      "Epoch 7334 - Train Loss: 0.156774, Train Acc: 0.707692 | Val Loss: 0.170216, Val Acc: 0.639175\n",
      "Epoch 7335 - Train Loss: 0.156762, Train Acc: 0.707692 | Val Loss: 0.170205, Val Acc: 0.639175\n",
      "Epoch 7336 - Train Loss: 0.156750, Train Acc: 0.707692 | Val Loss: 0.170193, Val Acc: 0.639175\n",
      "Epoch 7337 - Train Loss: 0.156738, Train Acc: 0.707692 | Val Loss: 0.170182, Val Acc: 0.649485\n",
      "Epoch 7338 - Train Loss: 0.156726, Train Acc: 0.707692 | Val Loss: 0.170171, Val Acc: 0.649485\n",
      "Epoch 7339 - Train Loss: 0.156715, Train Acc: 0.707692 | Val Loss: 0.170160, Val Acc: 0.649485\n",
      "Epoch 7340 - Train Loss: 0.156703, Train Acc: 0.707692 | Val Loss: 0.170149, Val Acc: 0.649485\n",
      "Epoch 7341 - Train Loss: 0.156691, Train Acc: 0.707692 | Val Loss: 0.170138, Val Acc: 0.649485\n",
      "Epoch 7342 - Train Loss: 0.156679, Train Acc: 0.707692 | Val Loss: 0.170126, Val Acc: 0.649485\n",
      "Epoch 7343 - Train Loss: 0.156667, Train Acc: 0.707692 | Val Loss: 0.170115, Val Acc: 0.649485\n",
      "Epoch 7344 - Train Loss: 0.156655, Train Acc: 0.707692 | Val Loss: 0.170104, Val Acc: 0.649485\n",
      "Epoch 7345 - Train Loss: 0.156643, Train Acc: 0.707692 | Val Loss: 0.170093, Val Acc: 0.649485\n",
      "Epoch 7346 - Train Loss: 0.156631, Train Acc: 0.707692 | Val Loss: 0.170082, Val Acc: 0.649485\n",
      "Epoch 7347 - Train Loss: 0.156619, Train Acc: 0.707692 | Val Loss: 0.170071, Val Acc: 0.649485\n",
      "Epoch 7348 - Train Loss: 0.156607, Train Acc: 0.707692 | Val Loss: 0.170060, Val Acc: 0.649485\n",
      "Epoch 7349 - Train Loss: 0.156595, Train Acc: 0.707692 | Val Loss: 0.170048, Val Acc: 0.649485\n",
      "Epoch 7350 - Train Loss: 0.156583, Train Acc: 0.707692 | Val Loss: 0.170037, Val Acc: 0.649485\n",
      "Epoch 7351 - Train Loss: 0.156571, Train Acc: 0.707692 | Val Loss: 0.170026, Val Acc: 0.649485\n",
      "Epoch 7352 - Train Loss: 0.156560, Train Acc: 0.707692 | Val Loss: 0.170015, Val Acc: 0.649485\n",
      "Epoch 7353 - Train Loss: 0.156548, Train Acc: 0.708974 | Val Loss: 0.170004, Val Acc: 0.649485\n",
      "Epoch 7354 - Train Loss: 0.156536, Train Acc: 0.708974 | Val Loss: 0.169993, Val Acc: 0.649485\n",
      "Epoch 7355 - Train Loss: 0.156524, Train Acc: 0.708974 | Val Loss: 0.169982, Val Acc: 0.649485\n",
      "Epoch 7356 - Train Loss: 0.156512, Train Acc: 0.708974 | Val Loss: 0.169971, Val Acc: 0.649485\n",
      "Epoch 7357 - Train Loss: 0.156500, Train Acc: 0.708974 | Val Loss: 0.169959, Val Acc: 0.649485\n",
      "Epoch 7358 - Train Loss: 0.156488, Train Acc: 0.708974 | Val Loss: 0.169948, Val Acc: 0.649485\n",
      "Epoch 7359 - Train Loss: 0.156476, Train Acc: 0.708974 | Val Loss: 0.169937, Val Acc: 0.649485\n",
      "Epoch 7360 - Train Loss: 0.156464, Train Acc: 0.708974 | Val Loss: 0.169926, Val Acc: 0.649485\n",
      "Epoch 7361 - Train Loss: 0.156452, Train Acc: 0.708974 | Val Loss: 0.169915, Val Acc: 0.649485\n",
      "Epoch 7362 - Train Loss: 0.156440, Train Acc: 0.708974 | Val Loss: 0.169904, Val Acc: 0.649485\n",
      "Epoch 7363 - Train Loss: 0.156428, Train Acc: 0.708974 | Val Loss: 0.169893, Val Acc: 0.649485\n",
      "Epoch 7364 - Train Loss: 0.156417, Train Acc: 0.708974 | Val Loss: 0.169882, Val Acc: 0.649485\n",
      "Epoch 7365 - Train Loss: 0.156405, Train Acc: 0.708974 | Val Loss: 0.169871, Val Acc: 0.649485\n",
      "Epoch 7366 - Train Loss: 0.156393, Train Acc: 0.708974 | Val Loss: 0.169859, Val Acc: 0.649485\n",
      "Epoch 7367 - Train Loss: 0.156381, Train Acc: 0.708974 | Val Loss: 0.169848, Val Acc: 0.649485\n",
      "Epoch 7368 - Train Loss: 0.156369, Train Acc: 0.708974 | Val Loss: 0.169837, Val Acc: 0.649485\n",
      "Epoch 7369 - Train Loss: 0.156357, Train Acc: 0.708974 | Val Loss: 0.169826, Val Acc: 0.649485\n",
      "Epoch 7370 - Train Loss: 0.156345, Train Acc: 0.708974 | Val Loss: 0.169815, Val Acc: 0.649485\n",
      "Epoch 7371 - Train Loss: 0.156333, Train Acc: 0.708974 | Val Loss: 0.169804, Val Acc: 0.649485\n",
      "Epoch 7372 - Train Loss: 0.156321, Train Acc: 0.708974 | Val Loss: 0.169793, Val Acc: 0.649485\n",
      "Epoch 7373 - Train Loss: 0.156309, Train Acc: 0.708974 | Val Loss: 0.169782, Val Acc: 0.649485\n",
      "Epoch 7374 - Train Loss: 0.156298, Train Acc: 0.708974 | Val Loss: 0.169771, Val Acc: 0.649485\n",
      "Epoch 7375 - Train Loss: 0.156286, Train Acc: 0.708974 | Val Loss: 0.169760, Val Acc: 0.649485\n",
      "Epoch 7376 - Train Loss: 0.156274, Train Acc: 0.708974 | Val Loss: 0.169748, Val Acc: 0.649485\n",
      "Epoch 7377 - Train Loss: 0.156262, Train Acc: 0.708974 | Val Loss: 0.169737, Val Acc: 0.649485\n",
      "Epoch 7378 - Train Loss: 0.156250, Train Acc: 0.708974 | Val Loss: 0.169726, Val Acc: 0.649485\n",
      "Epoch 7379 - Train Loss: 0.156238, Train Acc: 0.708974 | Val Loss: 0.169715, Val Acc: 0.649485\n",
      "Epoch 7380 - Train Loss: 0.156226, Train Acc: 0.710256 | Val Loss: 0.169704, Val Acc: 0.649485\n",
      "Epoch 7381 - Train Loss: 0.156214, Train Acc: 0.710256 | Val Loss: 0.169693, Val Acc: 0.649485\n",
      "Epoch 7382 - Train Loss: 0.156202, Train Acc: 0.710256 | Val Loss: 0.169682, Val Acc: 0.649485\n",
      "Epoch 7383 - Train Loss: 0.156191, Train Acc: 0.710256 | Val Loss: 0.169671, Val Acc: 0.649485\n",
      "Epoch 7384 - Train Loss: 0.156179, Train Acc: 0.710256 | Val Loss: 0.169660, Val Acc: 0.649485\n",
      "Epoch 7385 - Train Loss: 0.156167, Train Acc: 0.710256 | Val Loss: 0.169648, Val Acc: 0.649485\n",
      "Epoch 7386 - Train Loss: 0.156155, Train Acc: 0.710256 | Val Loss: 0.169637, Val Acc: 0.649485\n",
      "Epoch 7387 - Train Loss: 0.156143, Train Acc: 0.710256 | Val Loss: 0.169626, Val Acc: 0.649485\n",
      "Epoch 7388 - Train Loss: 0.156131, Train Acc: 0.711538 | Val Loss: 0.169615, Val Acc: 0.649485\n",
      "Epoch 7389 - Train Loss: 0.156119, Train Acc: 0.711538 | Val Loss: 0.169604, Val Acc: 0.649485\n",
      "Epoch 7390 - Train Loss: 0.156107, Train Acc: 0.711538 | Val Loss: 0.169593, Val Acc: 0.649485\n",
      "Epoch 7391 - Train Loss: 0.156095, Train Acc: 0.711538 | Val Loss: 0.169582, Val Acc: 0.649485\n",
      "Epoch 7392 - Train Loss: 0.156084, Train Acc: 0.711538 | Val Loss: 0.169571, Val Acc: 0.649485\n",
      "Epoch 7393 - Train Loss: 0.156072, Train Acc: 0.711538 | Val Loss: 0.169560, Val Acc: 0.649485\n",
      "Epoch 7394 - Train Loss: 0.156060, Train Acc: 0.711538 | Val Loss: 0.169548, Val Acc: 0.649485\n",
      "Epoch 7395 - Train Loss: 0.156048, Train Acc: 0.711538 | Val Loss: 0.169537, Val Acc: 0.649485\n",
      "Epoch 7396 - Train Loss: 0.156036, Train Acc: 0.711538 | Val Loss: 0.169526, Val Acc: 0.649485\n",
      "Epoch 7397 - Train Loss: 0.156024, Train Acc: 0.711538 | Val Loss: 0.169515, Val Acc: 0.649485\n",
      "Epoch 7398 - Train Loss: 0.156012, Train Acc: 0.711538 | Val Loss: 0.169504, Val Acc: 0.649485\n",
      "Epoch 7399 - Train Loss: 0.156000, Train Acc: 0.711538 | Val Loss: 0.169493, Val Acc: 0.649485\n",
      "Epoch 7400 - Train Loss: 0.155989, Train Acc: 0.711538 | Val Loss: 0.169482, Val Acc: 0.649485\n",
      "Epoch 7401 - Train Loss: 0.155977, Train Acc: 0.711538 | Val Loss: 0.169471, Val Acc: 0.649485\n",
      "Epoch 7402 - Train Loss: 0.155965, Train Acc: 0.711538 | Val Loss: 0.169460, Val Acc: 0.649485\n",
      "Epoch 7403 - Train Loss: 0.155953, Train Acc: 0.711538 | Val Loss: 0.169449, Val Acc: 0.649485\n",
      "Epoch 7404 - Train Loss: 0.155941, Train Acc: 0.711538 | Val Loss: 0.169437, Val Acc: 0.649485\n",
      "Epoch 7405 - Train Loss: 0.155929, Train Acc: 0.711538 | Val Loss: 0.169426, Val Acc: 0.649485\n",
      "Epoch 7406 - Train Loss: 0.155917, Train Acc: 0.711538 | Val Loss: 0.169415, Val Acc: 0.649485\n",
      "Epoch 7407 - Train Loss: 0.155906, Train Acc: 0.711538 | Val Loss: 0.169404, Val Acc: 0.649485\n",
      "Epoch 7408 - Train Loss: 0.155894, Train Acc: 0.711538 | Val Loss: 0.169393, Val Acc: 0.649485\n",
      "Epoch 7409 - Train Loss: 0.155882, Train Acc: 0.711538 | Val Loss: 0.169382, Val Acc: 0.649485\n",
      "Epoch 7410 - Train Loss: 0.155870, Train Acc: 0.711538 | Val Loss: 0.169371, Val Acc: 0.649485\n",
      "Epoch 7411 - Train Loss: 0.155858, Train Acc: 0.711538 | Val Loss: 0.169360, Val Acc: 0.649485\n",
      "Epoch 7412 - Train Loss: 0.155846, Train Acc: 0.711538 | Val Loss: 0.169349, Val Acc: 0.649485\n",
      "Epoch 7413 - Train Loss: 0.155834, Train Acc: 0.711538 | Val Loss: 0.169338, Val Acc: 0.649485\n",
      "Epoch 7414 - Train Loss: 0.155823, Train Acc: 0.711538 | Val Loss: 0.169327, Val Acc: 0.649485\n",
      "Epoch 7415 - Train Loss: 0.155811, Train Acc: 0.711538 | Val Loss: 0.169316, Val Acc: 0.649485\n",
      "Epoch 7416 - Train Loss: 0.155799, Train Acc: 0.711538 | Val Loss: 0.169304, Val Acc: 0.649485\n",
      "Epoch 7417 - Train Loss: 0.155787, Train Acc: 0.711538 | Val Loss: 0.169293, Val Acc: 0.649485\n",
      "Epoch 7418 - Train Loss: 0.155775, Train Acc: 0.711538 | Val Loss: 0.169282, Val Acc: 0.649485\n",
      "Epoch 7419 - Train Loss: 0.155763, Train Acc: 0.711538 | Val Loss: 0.169271, Val Acc: 0.649485\n",
      "Epoch 7420 - Train Loss: 0.155751, Train Acc: 0.711538 | Val Loss: 0.169260, Val Acc: 0.649485\n",
      "Epoch 7421 - Train Loss: 0.155740, Train Acc: 0.711538 | Val Loss: 0.169249, Val Acc: 0.649485\n",
      "Epoch 7422 - Train Loss: 0.155728, Train Acc: 0.711538 | Val Loss: 0.169238, Val Acc: 0.649485\n",
      "Epoch 7423 - Train Loss: 0.155716, Train Acc: 0.711538 | Val Loss: 0.169227, Val Acc: 0.649485\n",
      "Epoch 7424 - Train Loss: 0.155704, Train Acc: 0.711538 | Val Loss: 0.169216, Val Acc: 0.649485\n",
      "Epoch 7425 - Train Loss: 0.155692, Train Acc: 0.711538 | Val Loss: 0.169205, Val Acc: 0.649485\n",
      "Epoch 7426 - Train Loss: 0.155680, Train Acc: 0.711538 | Val Loss: 0.169194, Val Acc: 0.649485\n",
      "Epoch 7427 - Train Loss: 0.155669, Train Acc: 0.712821 | Val Loss: 0.169183, Val Acc: 0.649485\n",
      "Epoch 7428 - Train Loss: 0.155657, Train Acc: 0.712821 | Val Loss: 0.169172, Val Acc: 0.649485\n",
      "Epoch 7429 - Train Loss: 0.155645, Train Acc: 0.712821 | Val Loss: 0.169161, Val Acc: 0.649485\n",
      "Epoch 7430 - Train Loss: 0.155633, Train Acc: 0.712821 | Val Loss: 0.169150, Val Acc: 0.649485\n",
      "Epoch 7431 - Train Loss: 0.155621, Train Acc: 0.712821 | Val Loss: 0.169138, Val Acc: 0.649485\n",
      "Epoch 7432 - Train Loss: 0.155609, Train Acc: 0.712821 | Val Loss: 0.169127, Val Acc: 0.649485\n",
      "Epoch 7433 - Train Loss: 0.155598, Train Acc: 0.712821 | Val Loss: 0.169116, Val Acc: 0.649485\n",
      "Epoch 7434 - Train Loss: 0.155586, Train Acc: 0.712821 | Val Loss: 0.169105, Val Acc: 0.649485\n",
      "Epoch 7435 - Train Loss: 0.155574, Train Acc: 0.712821 | Val Loss: 0.169094, Val Acc: 0.649485\n",
      "Epoch 7436 - Train Loss: 0.155562, Train Acc: 0.712821 | Val Loss: 0.169083, Val Acc: 0.649485\n",
      "Epoch 7437 - Train Loss: 0.155550, Train Acc: 0.712821 | Val Loss: 0.169072, Val Acc: 0.649485\n",
      "Epoch 7438 - Train Loss: 0.155538, Train Acc: 0.712821 | Val Loss: 0.169061, Val Acc: 0.649485\n",
      "Epoch 7439 - Train Loss: 0.155527, Train Acc: 0.712821 | Val Loss: 0.169050, Val Acc: 0.649485\n",
      "Epoch 7440 - Train Loss: 0.155515, Train Acc: 0.712821 | Val Loss: 0.169039, Val Acc: 0.649485\n",
      "Epoch 7441 - Train Loss: 0.155503, Train Acc: 0.712821 | Val Loss: 0.169028, Val Acc: 0.649485\n",
      "Epoch 7442 - Train Loss: 0.155491, Train Acc: 0.712821 | Val Loss: 0.169017, Val Acc: 0.649485\n",
      "Epoch 7443 - Train Loss: 0.155479, Train Acc: 0.712821 | Val Loss: 0.169006, Val Acc: 0.649485\n",
      "Epoch 7444 - Train Loss: 0.155467, Train Acc: 0.712821 | Val Loss: 0.168995, Val Acc: 0.649485\n",
      "Epoch 7445 - Train Loss: 0.155456, Train Acc: 0.712821 | Val Loss: 0.168984, Val Acc: 0.649485\n",
      "Epoch 7446 - Train Loss: 0.155444, Train Acc: 0.712821 | Val Loss: 0.168973, Val Acc: 0.649485\n",
      "Epoch 7447 - Train Loss: 0.155432, Train Acc: 0.712821 | Val Loss: 0.168962, Val Acc: 0.649485\n",
      "Epoch 7448 - Train Loss: 0.155420, Train Acc: 0.712821 | Val Loss: 0.168951, Val Acc: 0.649485\n",
      "Epoch 7449 - Train Loss: 0.155408, Train Acc: 0.712821 | Val Loss: 0.168940, Val Acc: 0.649485\n",
      "Epoch 7450 - Train Loss: 0.155397, Train Acc: 0.712821 | Val Loss: 0.168929, Val Acc: 0.649485\n",
      "Epoch 7451 - Train Loss: 0.155385, Train Acc: 0.712821 | Val Loss: 0.168918, Val Acc: 0.649485\n",
      "Epoch 7452 - Train Loss: 0.155373, Train Acc: 0.712821 | Val Loss: 0.168907, Val Acc: 0.649485\n",
      "Epoch 7453 - Train Loss: 0.155361, Train Acc: 0.712821 | Val Loss: 0.168896, Val Acc: 0.649485\n",
      "Epoch 7454 - Train Loss: 0.155349, Train Acc: 0.712821 | Val Loss: 0.168885, Val Acc: 0.649485\n",
      "Epoch 7455 - Train Loss: 0.155337, Train Acc: 0.712821 | Val Loss: 0.168874, Val Acc: 0.649485\n",
      "Epoch 7456 - Train Loss: 0.155326, Train Acc: 0.712821 | Val Loss: 0.168863, Val Acc: 0.649485\n",
      "Epoch 7457 - Train Loss: 0.155314, Train Acc: 0.712821 | Val Loss: 0.168852, Val Acc: 0.649485\n",
      "Epoch 7458 - Train Loss: 0.155302, Train Acc: 0.712821 | Val Loss: 0.168841, Val Acc: 0.649485\n",
      "Epoch 7459 - Train Loss: 0.155290, Train Acc: 0.712821 | Val Loss: 0.168830, Val Acc: 0.649485\n",
      "Epoch 7460 - Train Loss: 0.155278, Train Acc: 0.712821 | Val Loss: 0.168819, Val Acc: 0.649485\n",
      "Epoch 7461 - Train Loss: 0.155267, Train Acc: 0.712821 | Val Loss: 0.168807, Val Acc: 0.649485\n",
      "Epoch 7462 - Train Loss: 0.155255, Train Acc: 0.712821 | Val Loss: 0.168796, Val Acc: 0.649485\n",
      "Epoch 7463 - Train Loss: 0.155243, Train Acc: 0.712821 | Val Loss: 0.168785, Val Acc: 0.649485\n",
      "Epoch 7464 - Train Loss: 0.155231, Train Acc: 0.712821 | Val Loss: 0.168774, Val Acc: 0.649485\n",
      "Epoch 7465 - Train Loss: 0.155219, Train Acc: 0.712821 | Val Loss: 0.168763, Val Acc: 0.649485\n",
      "Epoch 7466 - Train Loss: 0.155208, Train Acc: 0.712821 | Val Loss: 0.168752, Val Acc: 0.649485\n",
      "Epoch 7467 - Train Loss: 0.155196, Train Acc: 0.712821 | Val Loss: 0.168741, Val Acc: 0.649485\n",
      "Epoch 7468 - Train Loss: 0.155184, Train Acc: 0.712821 | Val Loss: 0.168730, Val Acc: 0.649485\n",
      "Epoch 7469 - Train Loss: 0.155172, Train Acc: 0.712821 | Val Loss: 0.168719, Val Acc: 0.649485\n",
      "Epoch 7470 - Train Loss: 0.155160, Train Acc: 0.712821 | Val Loss: 0.168708, Val Acc: 0.649485\n",
      "Epoch 7471 - Train Loss: 0.155149, Train Acc: 0.712821 | Val Loss: 0.168697, Val Acc: 0.649485\n",
      "Epoch 7472 - Train Loss: 0.155137, Train Acc: 0.712821 | Val Loss: 0.168686, Val Acc: 0.649485\n",
      "Epoch 7473 - Train Loss: 0.155125, Train Acc: 0.712821 | Val Loss: 0.168675, Val Acc: 0.649485\n",
      "Epoch 7474 - Train Loss: 0.155113, Train Acc: 0.712821 | Val Loss: 0.168664, Val Acc: 0.649485\n",
      "Epoch 7475 - Train Loss: 0.155102, Train Acc: 0.712821 | Val Loss: 0.168653, Val Acc: 0.649485\n",
      "Epoch 7476 - Train Loss: 0.155090, Train Acc: 0.712821 | Val Loss: 0.168642, Val Acc: 0.649485\n",
      "Epoch 7477 - Train Loss: 0.155078, Train Acc: 0.712821 | Val Loss: 0.168632, Val Acc: 0.649485\n",
      "Epoch 7478 - Train Loss: 0.155066, Train Acc: 0.712821 | Val Loss: 0.168621, Val Acc: 0.649485\n",
      "Epoch 7479 - Train Loss: 0.155054, Train Acc: 0.712821 | Val Loss: 0.168610, Val Acc: 0.649485\n",
      "Epoch 7480 - Train Loss: 0.155043, Train Acc: 0.712821 | Val Loss: 0.168599, Val Acc: 0.649485\n",
      "Epoch 7481 - Train Loss: 0.155031, Train Acc: 0.712821 | Val Loss: 0.168588, Val Acc: 0.649485\n",
      "Epoch 7482 - Train Loss: 0.155019, Train Acc: 0.712821 | Val Loss: 0.168577, Val Acc: 0.649485\n",
      "Epoch 7483 - Train Loss: 0.155007, Train Acc: 0.712821 | Val Loss: 0.168566, Val Acc: 0.649485\n",
      "Epoch 7484 - Train Loss: 0.154995, Train Acc: 0.712821 | Val Loss: 0.168555, Val Acc: 0.649485\n",
      "Epoch 7485 - Train Loss: 0.154984, Train Acc: 0.712821 | Val Loss: 0.168544, Val Acc: 0.649485\n",
      "Epoch 7486 - Train Loss: 0.154972, Train Acc: 0.712821 | Val Loss: 0.168533, Val Acc: 0.649485\n",
      "Epoch 7487 - Train Loss: 0.154960, Train Acc: 0.714103 | Val Loss: 0.168522, Val Acc: 0.649485\n",
      "Epoch 7488 - Train Loss: 0.154948, Train Acc: 0.714103 | Val Loss: 0.168511, Val Acc: 0.649485\n",
      "Epoch 7489 - Train Loss: 0.154937, Train Acc: 0.714103 | Val Loss: 0.168500, Val Acc: 0.649485\n",
      "Epoch 7490 - Train Loss: 0.154925, Train Acc: 0.714103 | Val Loss: 0.168489, Val Acc: 0.649485\n",
      "Epoch 7491 - Train Loss: 0.154913, Train Acc: 0.714103 | Val Loss: 0.168478, Val Acc: 0.649485\n",
      "Epoch 7492 - Train Loss: 0.154901, Train Acc: 0.714103 | Val Loss: 0.168468, Val Acc: 0.649485\n",
      "Epoch 7493 - Train Loss: 0.154890, Train Acc: 0.714103 | Val Loss: 0.168457, Val Acc: 0.649485\n",
      "Epoch 7494 - Train Loss: 0.154878, Train Acc: 0.714103 | Val Loss: 0.168446, Val Acc: 0.649485\n",
      "Epoch 7495 - Train Loss: 0.154866, Train Acc: 0.714103 | Val Loss: 0.168436, Val Acc: 0.649485\n",
      "Epoch 7496 - Train Loss: 0.154854, Train Acc: 0.714103 | Val Loss: 0.168425, Val Acc: 0.649485\n",
      "Epoch 7497 - Train Loss: 0.154843, Train Acc: 0.714103 | Val Loss: 0.168414, Val Acc: 0.649485\n",
      "Epoch 7498 - Train Loss: 0.154831, Train Acc: 0.714103 | Val Loss: 0.168403, Val Acc: 0.649485\n",
      "Epoch 7499 - Train Loss: 0.154819, Train Acc: 0.714103 | Val Loss: 0.168393, Val Acc: 0.649485\n",
      "Epoch 7500 - Train Loss: 0.154807, Train Acc: 0.714103 | Val Loss: 0.168382, Val Acc: 0.649485\n",
      "Epoch 7501 - Train Loss: 0.154796, Train Acc: 0.714103 | Val Loss: 0.168371, Val Acc: 0.649485\n",
      "Epoch 7502 - Train Loss: 0.154784, Train Acc: 0.714103 | Val Loss: 0.168360, Val Acc: 0.649485\n",
      "Epoch 7503 - Train Loss: 0.154772, Train Acc: 0.714103 | Val Loss: 0.168350, Val Acc: 0.649485\n",
      "Epoch 7504 - Train Loss: 0.154760, Train Acc: 0.714103 | Val Loss: 0.168339, Val Acc: 0.649485\n",
      "Epoch 7505 - Train Loss: 0.154749, Train Acc: 0.714103 | Val Loss: 0.168328, Val Acc: 0.649485\n",
      "Epoch 7506 - Train Loss: 0.154737, Train Acc: 0.714103 | Val Loss: 0.168317, Val Acc: 0.649485\n",
      "Epoch 7507 - Train Loss: 0.154725, Train Acc: 0.714103 | Val Loss: 0.168307, Val Acc: 0.649485\n",
      "Epoch 7508 - Train Loss: 0.154713, Train Acc: 0.714103 | Val Loss: 0.168296, Val Acc: 0.649485\n",
      "Epoch 7509 - Train Loss: 0.154702, Train Acc: 0.714103 | Val Loss: 0.168285, Val Acc: 0.649485\n",
      "Epoch 7510 - Train Loss: 0.154690, Train Acc: 0.714103 | Val Loss: 0.168274, Val Acc: 0.649485\n",
      "Epoch 7511 - Train Loss: 0.154678, Train Acc: 0.714103 | Val Loss: 0.168264, Val Acc: 0.649485\n",
      "Epoch 7512 - Train Loss: 0.154666, Train Acc: 0.714103 | Val Loss: 0.168253, Val Acc: 0.649485\n",
      "Epoch 7513 - Train Loss: 0.154655, Train Acc: 0.714103 | Val Loss: 0.168242, Val Acc: 0.649485\n",
      "Epoch 7514 - Train Loss: 0.154643, Train Acc: 0.714103 | Val Loss: 0.168231, Val Acc: 0.649485\n",
      "Epoch 7515 - Train Loss: 0.154631, Train Acc: 0.714103 | Val Loss: 0.168221, Val Acc: 0.649485\n",
      "Epoch 7516 - Train Loss: 0.154619, Train Acc: 0.714103 | Val Loss: 0.168210, Val Acc: 0.649485\n",
      "Epoch 7517 - Train Loss: 0.154608, Train Acc: 0.714103 | Val Loss: 0.168199, Val Acc: 0.649485\n",
      "Epoch 7518 - Train Loss: 0.154596, Train Acc: 0.714103 | Val Loss: 0.168188, Val Acc: 0.649485\n",
      "Epoch 7519 - Train Loss: 0.154584, Train Acc: 0.714103 | Val Loss: 0.168177, Val Acc: 0.649485\n",
      "Epoch 7520 - Train Loss: 0.154573, Train Acc: 0.714103 | Val Loss: 0.168167, Val Acc: 0.649485\n",
      "Epoch 7521 - Train Loss: 0.154561, Train Acc: 0.714103 | Val Loss: 0.168156, Val Acc: 0.649485\n",
      "Epoch 7522 - Train Loss: 0.154549, Train Acc: 0.714103 | Val Loss: 0.168145, Val Acc: 0.649485\n",
      "Epoch 7523 - Train Loss: 0.154537, Train Acc: 0.714103 | Val Loss: 0.168134, Val Acc: 0.649485\n",
      "Epoch 7524 - Train Loss: 0.154526, Train Acc: 0.715385 | Val Loss: 0.168124, Val Acc: 0.649485\n",
      "Epoch 7525 - Train Loss: 0.154514, Train Acc: 0.715385 | Val Loss: 0.168113, Val Acc: 0.649485\n",
      "Epoch 7526 - Train Loss: 0.154502, Train Acc: 0.715385 | Val Loss: 0.168102, Val Acc: 0.649485\n",
      "Epoch 7527 - Train Loss: 0.154491, Train Acc: 0.715385 | Val Loss: 0.168091, Val Acc: 0.649485\n",
      "Epoch 7528 - Train Loss: 0.154479, Train Acc: 0.715385 | Val Loss: 0.168080, Val Acc: 0.649485\n",
      "Epoch 7529 - Train Loss: 0.154467, Train Acc: 0.715385 | Val Loss: 0.168070, Val Acc: 0.649485\n",
      "Epoch 7530 - Train Loss: 0.154455, Train Acc: 0.715385 | Val Loss: 0.168059, Val Acc: 0.649485\n",
      "Epoch 7531 - Train Loss: 0.154444, Train Acc: 0.715385 | Val Loss: 0.168048, Val Acc: 0.649485\n",
      "Epoch 7532 - Train Loss: 0.154432, Train Acc: 0.715385 | Val Loss: 0.168037, Val Acc: 0.649485\n",
      "Epoch 7533 - Train Loss: 0.154420, Train Acc: 0.715385 | Val Loss: 0.168026, Val Acc: 0.649485\n",
      "Epoch 7534 - Train Loss: 0.154409, Train Acc: 0.715385 | Val Loss: 0.168016, Val Acc: 0.649485\n",
      "Epoch 7535 - Train Loss: 0.154397, Train Acc: 0.715385 | Val Loss: 0.168005, Val Acc: 0.649485\n",
      "Epoch 7536 - Train Loss: 0.154385, Train Acc: 0.715385 | Val Loss: 0.167994, Val Acc: 0.649485\n",
      "Epoch 7537 - Train Loss: 0.154373, Train Acc: 0.715385 | Val Loss: 0.167983, Val Acc: 0.649485\n",
      "Epoch 7538 - Train Loss: 0.154362, Train Acc: 0.715385 | Val Loss: 0.167973, Val Acc: 0.649485\n",
      "Epoch 7539 - Train Loss: 0.154350, Train Acc: 0.715385 | Val Loss: 0.167962, Val Acc: 0.649485\n",
      "Epoch 7540 - Train Loss: 0.154338, Train Acc: 0.716667 | Val Loss: 0.167951, Val Acc: 0.649485\n",
      "Epoch 7541 - Train Loss: 0.154327, Train Acc: 0.716667 | Val Loss: 0.167940, Val Acc: 0.649485\n",
      "Epoch 7542 - Train Loss: 0.154315, Train Acc: 0.716667 | Val Loss: 0.167929, Val Acc: 0.649485\n",
      "Epoch 7543 - Train Loss: 0.154303, Train Acc: 0.716667 | Val Loss: 0.167919, Val Acc: 0.649485\n",
      "Epoch 7544 - Train Loss: 0.154291, Train Acc: 0.716667 | Val Loss: 0.167908, Val Acc: 0.649485\n",
      "Epoch 7545 - Train Loss: 0.154280, Train Acc: 0.716667 | Val Loss: 0.167897, Val Acc: 0.649485\n",
      "Epoch 7546 - Train Loss: 0.154268, Train Acc: 0.716667 | Val Loss: 0.167886, Val Acc: 0.649485\n",
      "Epoch 7547 - Train Loss: 0.154256, Train Acc: 0.716667 | Val Loss: 0.167876, Val Acc: 0.649485\n",
      "Epoch 7548 - Train Loss: 0.154245, Train Acc: 0.716667 | Val Loss: 0.167865, Val Acc: 0.649485\n",
      "Epoch 7549 - Train Loss: 0.154233, Train Acc: 0.716667 | Val Loss: 0.167854, Val Acc: 0.649485\n",
      "Epoch 7550 - Train Loss: 0.154221, Train Acc: 0.716667 | Val Loss: 0.167843, Val Acc: 0.649485\n",
      "Epoch 7551 - Train Loss: 0.154210, Train Acc: 0.716667 | Val Loss: 0.167832, Val Acc: 0.649485\n",
      "Epoch 7552 - Train Loss: 0.154198, Train Acc: 0.716667 | Val Loss: 0.167822, Val Acc: 0.649485\n",
      "Epoch 7553 - Train Loss: 0.154186, Train Acc: 0.716667 | Val Loss: 0.167811, Val Acc: 0.649485\n",
      "Epoch 7554 - Train Loss: 0.154175, Train Acc: 0.716667 | Val Loss: 0.167800, Val Acc: 0.649485\n",
      "Epoch 7555 - Train Loss: 0.154163, Train Acc: 0.716667 | Val Loss: 0.167789, Val Acc: 0.649485\n",
      "Epoch 7556 - Train Loss: 0.154151, Train Acc: 0.716667 | Val Loss: 0.167779, Val Acc: 0.649485\n",
      "Epoch 7557 - Train Loss: 0.154139, Train Acc: 0.716667 | Val Loss: 0.167768, Val Acc: 0.649485\n",
      "Epoch 7558 - Train Loss: 0.154128, Train Acc: 0.716667 | Val Loss: 0.167757, Val Acc: 0.649485\n",
      "Epoch 7559 - Train Loss: 0.154116, Train Acc: 0.716667 | Val Loss: 0.167746, Val Acc: 0.649485\n",
      "Epoch 7560 - Train Loss: 0.154104, Train Acc: 0.716667 | Val Loss: 0.167735, Val Acc: 0.649485\n",
      "Epoch 7561 - Train Loss: 0.154093, Train Acc: 0.716667 | Val Loss: 0.167725, Val Acc: 0.649485\n",
      "Epoch 7562 - Train Loss: 0.154081, Train Acc: 0.716667 | Val Loss: 0.167714, Val Acc: 0.649485\n",
      "Epoch 7563 - Train Loss: 0.154069, Train Acc: 0.716667 | Val Loss: 0.167703, Val Acc: 0.649485\n",
      "Epoch 7564 - Train Loss: 0.154058, Train Acc: 0.716667 | Val Loss: 0.167692, Val Acc: 0.649485\n",
      "Epoch 7565 - Train Loss: 0.154046, Train Acc: 0.716667 | Val Loss: 0.167682, Val Acc: 0.649485\n",
      "Epoch 7566 - Train Loss: 0.154034, Train Acc: 0.716667 | Val Loss: 0.167671, Val Acc: 0.649485\n",
      "Epoch 7567 - Train Loss: 0.154023, Train Acc: 0.716667 | Val Loss: 0.167660, Val Acc: 0.649485\n",
      "Epoch 7568 - Train Loss: 0.154011, Train Acc: 0.716667 | Val Loss: 0.167649, Val Acc: 0.649485\n",
      "Epoch 7569 - Train Loss: 0.153999, Train Acc: 0.716667 | Val Loss: 0.167638, Val Acc: 0.649485\n",
      "Epoch 7570 - Train Loss: 0.153988, Train Acc: 0.716667 | Val Loss: 0.167628, Val Acc: 0.649485\n",
      "Epoch 7571 - Train Loss: 0.153976, Train Acc: 0.716667 | Val Loss: 0.167617, Val Acc: 0.649485\n",
      "Epoch 7572 - Train Loss: 0.153964, Train Acc: 0.716667 | Val Loss: 0.167606, Val Acc: 0.649485\n",
      "Epoch 7573 - Train Loss: 0.153953, Train Acc: 0.716667 | Val Loss: 0.167595, Val Acc: 0.649485\n",
      "Epoch 7574 - Train Loss: 0.153941, Train Acc: 0.716667 | Val Loss: 0.167585, Val Acc: 0.649485\n",
      "Epoch 7575 - Train Loss: 0.153929, Train Acc: 0.716667 | Val Loss: 0.167574, Val Acc: 0.649485\n",
      "Epoch 7576 - Train Loss: 0.153918, Train Acc: 0.716667 | Val Loss: 0.167563, Val Acc: 0.649485\n",
      "Epoch 7577 - Train Loss: 0.153906, Train Acc: 0.716667 | Val Loss: 0.167552, Val Acc: 0.649485\n",
      "Epoch 7578 - Train Loss: 0.153894, Train Acc: 0.716667 | Val Loss: 0.167542, Val Acc: 0.649485\n",
      "Epoch 7579 - Train Loss: 0.153883, Train Acc: 0.716667 | Val Loss: 0.167531, Val Acc: 0.649485\n",
      "Epoch 7580 - Train Loss: 0.153871, Train Acc: 0.716667 | Val Loss: 0.167520, Val Acc: 0.649485\n",
      "Epoch 7581 - Train Loss: 0.153859, Train Acc: 0.716667 | Val Loss: 0.167509, Val Acc: 0.649485\n",
      "Epoch 7582 - Train Loss: 0.153848, Train Acc: 0.716667 | Val Loss: 0.167499, Val Acc: 0.649485\n",
      "Epoch 7583 - Train Loss: 0.153836, Train Acc: 0.716667 | Val Loss: 0.167488, Val Acc: 0.649485\n",
      "Epoch 7584 - Train Loss: 0.153824, Train Acc: 0.716667 | Val Loss: 0.167477, Val Acc: 0.649485\n",
      "Epoch 7585 - Train Loss: 0.153813, Train Acc: 0.716667 | Val Loss: 0.167466, Val Acc: 0.649485\n",
      "Epoch 7586 - Train Loss: 0.153801, Train Acc: 0.716667 | Val Loss: 0.167456, Val Acc: 0.649485\n",
      "Epoch 7587 - Train Loss: 0.153790, Train Acc: 0.716667 | Val Loss: 0.167445, Val Acc: 0.649485\n",
      "Epoch 7588 - Train Loss: 0.153778, Train Acc: 0.716667 | Val Loss: 0.167434, Val Acc: 0.649485\n",
      "Epoch 7589 - Train Loss: 0.153766, Train Acc: 0.716667 | Val Loss: 0.167423, Val Acc: 0.649485\n",
      "Epoch 7590 - Train Loss: 0.153755, Train Acc: 0.716667 | Val Loss: 0.167413, Val Acc: 0.649485\n",
      "Epoch 7591 - Train Loss: 0.153743, Train Acc: 0.716667 | Val Loss: 0.167402, Val Acc: 0.649485\n",
      "Epoch 7592 - Train Loss: 0.153731, Train Acc: 0.716667 | Val Loss: 0.167391, Val Acc: 0.649485\n",
      "Epoch 7593 - Train Loss: 0.153720, Train Acc: 0.716667 | Val Loss: 0.167380, Val Acc: 0.649485\n",
      "Epoch 7594 - Train Loss: 0.153708, Train Acc: 0.716667 | Val Loss: 0.167370, Val Acc: 0.649485\n",
      "Epoch 7595 - Train Loss: 0.153696, Train Acc: 0.716667 | Val Loss: 0.167359, Val Acc: 0.649485\n",
      "Epoch 7596 - Train Loss: 0.153685, Train Acc: 0.716667 | Val Loss: 0.167348, Val Acc: 0.649485\n",
      "Epoch 7597 - Train Loss: 0.153673, Train Acc: 0.716667 | Val Loss: 0.167337, Val Acc: 0.649485\n",
      "Epoch 7598 - Train Loss: 0.153661, Train Acc: 0.717949 | Val Loss: 0.167327, Val Acc: 0.649485\n",
      "Epoch 7599 - Train Loss: 0.153650, Train Acc: 0.717949 | Val Loss: 0.167316, Val Acc: 0.649485\n",
      "Epoch 7600 - Train Loss: 0.153638, Train Acc: 0.717949 | Val Loss: 0.167305, Val Acc: 0.649485\n",
      "Epoch 7601 - Train Loss: 0.153627, Train Acc: 0.717949 | Val Loss: 0.167294, Val Acc: 0.649485\n",
      "Epoch 7602 - Train Loss: 0.153615, Train Acc: 0.717949 | Val Loss: 0.167284, Val Acc: 0.649485\n",
      "Epoch 7603 - Train Loss: 0.153603, Train Acc: 0.717949 | Val Loss: 0.167273, Val Acc: 0.649485\n",
      "Epoch 7604 - Train Loss: 0.153592, Train Acc: 0.717949 | Val Loss: 0.167262, Val Acc: 0.649485\n",
      "Epoch 7605 - Train Loss: 0.153580, Train Acc: 0.717949 | Val Loss: 0.167251, Val Acc: 0.649485\n",
      "Epoch 7606 - Train Loss: 0.153568, Train Acc: 0.717949 | Val Loss: 0.167241, Val Acc: 0.649485\n",
      "Epoch 7607 - Train Loss: 0.153557, Train Acc: 0.717949 | Val Loss: 0.167230, Val Acc: 0.649485\n",
      "Epoch 7608 - Train Loss: 0.153545, Train Acc: 0.717949 | Val Loss: 0.167219, Val Acc: 0.649485\n",
      "Epoch 7609 - Train Loss: 0.153534, Train Acc: 0.717949 | Val Loss: 0.167208, Val Acc: 0.649485\n",
      "Epoch 7610 - Train Loss: 0.153522, Train Acc: 0.717949 | Val Loss: 0.167198, Val Acc: 0.649485\n",
      "Epoch 7611 - Train Loss: 0.153510, Train Acc: 0.717949 | Val Loss: 0.167187, Val Acc: 0.649485\n",
      "Epoch 7612 - Train Loss: 0.153499, Train Acc: 0.717949 | Val Loss: 0.167176, Val Acc: 0.649485\n",
      "Epoch 7613 - Train Loss: 0.153487, Train Acc: 0.717949 | Val Loss: 0.167166, Val Acc: 0.649485\n",
      "Epoch 7614 - Train Loss: 0.153475, Train Acc: 0.717949 | Val Loss: 0.167155, Val Acc: 0.649485\n",
      "Epoch 7615 - Train Loss: 0.153464, Train Acc: 0.717949 | Val Loss: 0.167144, Val Acc: 0.649485\n",
      "Epoch 7616 - Train Loss: 0.153452, Train Acc: 0.717949 | Val Loss: 0.167133, Val Acc: 0.649485\n",
      "Epoch 7617 - Train Loss: 0.153441, Train Acc: 0.717949 | Val Loss: 0.167123, Val Acc: 0.649485\n",
      "Epoch 7618 - Train Loss: 0.153429, Train Acc: 0.717949 | Val Loss: 0.167112, Val Acc: 0.649485\n",
      "Epoch 7619 - Train Loss: 0.153417, Train Acc: 0.717949 | Val Loss: 0.167101, Val Acc: 0.649485\n",
      "Epoch 7620 - Train Loss: 0.153406, Train Acc: 0.719231 | Val Loss: 0.167090, Val Acc: 0.649485\n",
      "Epoch 7621 - Train Loss: 0.153394, Train Acc: 0.719231 | Val Loss: 0.167080, Val Acc: 0.649485\n",
      "Epoch 7622 - Train Loss: 0.153382, Train Acc: 0.719231 | Val Loss: 0.167069, Val Acc: 0.649485\n",
      "Epoch 7623 - Train Loss: 0.153371, Train Acc: 0.719231 | Val Loss: 0.167058, Val Acc: 0.649485\n",
      "Epoch 7624 - Train Loss: 0.153359, Train Acc: 0.719231 | Val Loss: 0.167048, Val Acc: 0.649485\n",
      "Epoch 7625 - Train Loss: 0.153348, Train Acc: 0.719231 | Val Loss: 0.167037, Val Acc: 0.649485\n",
      "Epoch 7626 - Train Loss: 0.153336, Train Acc: 0.719231 | Val Loss: 0.167026, Val Acc: 0.649485\n",
      "Epoch 7627 - Train Loss: 0.153324, Train Acc: 0.719231 | Val Loss: 0.167015, Val Acc: 0.649485\n",
      "Epoch 7628 - Train Loss: 0.153313, Train Acc: 0.719231 | Val Loss: 0.167005, Val Acc: 0.649485\n",
      "Epoch 7629 - Train Loss: 0.153301, Train Acc: 0.719231 | Val Loss: 0.166994, Val Acc: 0.649485\n",
      "Epoch 7630 - Train Loss: 0.153290, Train Acc: 0.719231 | Val Loss: 0.166983, Val Acc: 0.649485\n",
      "Epoch 7631 - Train Loss: 0.153278, Train Acc: 0.719231 | Val Loss: 0.166973, Val Acc: 0.649485\n",
      "Epoch 7632 - Train Loss: 0.153266, Train Acc: 0.719231 | Val Loss: 0.166962, Val Acc: 0.649485\n",
      "Epoch 7633 - Train Loss: 0.153255, Train Acc: 0.719231 | Val Loss: 0.166951, Val Acc: 0.649485\n",
      "Epoch 7634 - Train Loss: 0.153243, Train Acc: 0.719231 | Val Loss: 0.166940, Val Acc: 0.649485\n",
      "Epoch 7635 - Train Loss: 0.153232, Train Acc: 0.719231 | Val Loss: 0.166930, Val Acc: 0.649485\n",
      "Epoch 7636 - Train Loss: 0.153220, Train Acc: 0.719231 | Val Loss: 0.166919, Val Acc: 0.649485\n",
      "Epoch 7637 - Train Loss: 0.153208, Train Acc: 0.719231 | Val Loss: 0.166908, Val Acc: 0.649485\n",
      "Epoch 7638 - Train Loss: 0.153197, Train Acc: 0.719231 | Val Loss: 0.166898, Val Acc: 0.649485\n",
      "Epoch 7639 - Train Loss: 0.153185, Train Acc: 0.719231 | Val Loss: 0.166887, Val Acc: 0.649485\n",
      "Epoch 7640 - Train Loss: 0.153174, Train Acc: 0.719231 | Val Loss: 0.166876, Val Acc: 0.649485\n",
      "Epoch 7641 - Train Loss: 0.153162, Train Acc: 0.719231 | Val Loss: 0.166866, Val Acc: 0.649485\n",
      "Epoch 7642 - Train Loss: 0.153151, Train Acc: 0.719231 | Val Loss: 0.166855, Val Acc: 0.649485\n",
      "Epoch 7643 - Train Loss: 0.153139, Train Acc: 0.719231 | Val Loss: 0.166844, Val Acc: 0.649485\n",
      "Epoch 7644 - Train Loss: 0.153127, Train Acc: 0.719231 | Val Loss: 0.166834, Val Acc: 0.649485\n",
      "Epoch 7645 - Train Loss: 0.153116, Train Acc: 0.719231 | Val Loss: 0.166823, Val Acc: 0.649485\n",
      "Epoch 7646 - Train Loss: 0.153104, Train Acc: 0.719231 | Val Loss: 0.166812, Val Acc: 0.649485\n",
      "Epoch 7647 - Train Loss: 0.153093, Train Acc: 0.719231 | Val Loss: 0.166801, Val Acc: 0.649485\n",
      "Epoch 7648 - Train Loss: 0.153081, Train Acc: 0.719231 | Val Loss: 0.166791, Val Acc: 0.649485\n",
      "Epoch 7649 - Train Loss: 0.153069, Train Acc: 0.719231 | Val Loss: 0.166780, Val Acc: 0.649485\n",
      "Epoch 7650 - Train Loss: 0.153058, Train Acc: 0.719231 | Val Loss: 0.166769, Val Acc: 0.649485\n",
      "Epoch 7651 - Train Loss: 0.153046, Train Acc: 0.719231 | Val Loss: 0.166759, Val Acc: 0.649485\n",
      "Epoch 7652 - Train Loss: 0.153035, Train Acc: 0.719231 | Val Loss: 0.166748, Val Acc: 0.649485\n",
      "Epoch 7653 - Train Loss: 0.153023, Train Acc: 0.719231 | Val Loss: 0.166737, Val Acc: 0.649485\n",
      "Epoch 7654 - Train Loss: 0.153012, Train Acc: 0.719231 | Val Loss: 0.166727, Val Acc: 0.649485\n",
      "Epoch 7655 - Train Loss: 0.153000, Train Acc: 0.719231 | Val Loss: 0.166716, Val Acc: 0.649485\n",
      "Epoch 7656 - Train Loss: 0.152988, Train Acc: 0.719231 | Val Loss: 0.166705, Val Acc: 0.649485\n",
      "Epoch 7657 - Train Loss: 0.152977, Train Acc: 0.719231 | Val Loss: 0.166695, Val Acc: 0.649485\n",
      "Epoch 7658 - Train Loss: 0.152965, Train Acc: 0.719231 | Val Loss: 0.166684, Val Acc: 0.649485\n",
      "Epoch 7659 - Train Loss: 0.152954, Train Acc: 0.719231 | Val Loss: 0.166673, Val Acc: 0.649485\n",
      "Epoch 7660 - Train Loss: 0.152942, Train Acc: 0.719231 | Val Loss: 0.166663, Val Acc: 0.649485\n",
      "Epoch 7661 - Train Loss: 0.152931, Train Acc: 0.719231 | Val Loss: 0.166652, Val Acc: 0.649485\n",
      "Epoch 7662 - Train Loss: 0.152919, Train Acc: 0.719231 | Val Loss: 0.166641, Val Acc: 0.649485\n",
      "Epoch 7663 - Train Loss: 0.152908, Train Acc: 0.719231 | Val Loss: 0.166631, Val Acc: 0.649485\n",
      "Epoch 7664 - Train Loss: 0.152896, Train Acc: 0.719231 | Val Loss: 0.166620, Val Acc: 0.649485\n",
      "Epoch 7665 - Train Loss: 0.152884, Train Acc: 0.719231 | Val Loss: 0.166609, Val Acc: 0.649485\n",
      "Epoch 7666 - Train Loss: 0.152873, Train Acc: 0.719231 | Val Loss: 0.166599, Val Acc: 0.649485\n",
      "Epoch 7667 - Train Loss: 0.152861, Train Acc: 0.719231 | Val Loss: 0.166588, Val Acc: 0.649485\n",
      "Epoch 7668 - Train Loss: 0.152850, Train Acc: 0.719231 | Val Loss: 0.166577, Val Acc: 0.649485\n",
      "Epoch 7669 - Train Loss: 0.152838, Train Acc: 0.719231 | Val Loss: 0.166567, Val Acc: 0.649485\n",
      "Epoch 7670 - Train Loss: 0.152827, Train Acc: 0.719231 | Val Loss: 0.166556, Val Acc: 0.649485\n",
      "Epoch 7671 - Train Loss: 0.152815, Train Acc: 0.719231 | Val Loss: 0.166545, Val Acc: 0.649485\n",
      "Epoch 7672 - Train Loss: 0.152804, Train Acc: 0.719231 | Val Loss: 0.166535, Val Acc: 0.649485\n",
      "Epoch 7673 - Train Loss: 0.152792, Train Acc: 0.719231 | Val Loss: 0.166524, Val Acc: 0.649485\n",
      "Epoch 7674 - Train Loss: 0.152780, Train Acc: 0.719231 | Val Loss: 0.166513, Val Acc: 0.649485\n",
      "Epoch 7675 - Train Loss: 0.152769, Train Acc: 0.719231 | Val Loss: 0.166503, Val Acc: 0.649485\n",
      "Epoch 7676 - Train Loss: 0.152757, Train Acc: 0.719231 | Val Loss: 0.166492, Val Acc: 0.649485\n",
      "Epoch 7677 - Train Loss: 0.152746, Train Acc: 0.719231 | Val Loss: 0.166481, Val Acc: 0.649485\n",
      "Epoch 7678 - Train Loss: 0.152734, Train Acc: 0.719231 | Val Loss: 0.166471, Val Acc: 0.649485\n",
      "Epoch 7679 - Train Loss: 0.152723, Train Acc: 0.719231 | Val Loss: 0.166460, Val Acc: 0.649485\n",
      "Epoch 7680 - Train Loss: 0.152711, Train Acc: 0.719231 | Val Loss: 0.166449, Val Acc: 0.659794\n",
      "Epoch 7681 - Train Loss: 0.152700, Train Acc: 0.719231 | Val Loss: 0.166439, Val Acc: 0.659794\n",
      "Epoch 7682 - Train Loss: 0.152688, Train Acc: 0.719231 | Val Loss: 0.166428, Val Acc: 0.659794\n",
      "Epoch 7683 - Train Loss: 0.152677, Train Acc: 0.719231 | Val Loss: 0.166417, Val Acc: 0.659794\n",
      "Epoch 7684 - Train Loss: 0.152665, Train Acc: 0.719231 | Val Loss: 0.166407, Val Acc: 0.659794\n",
      "Epoch 7685 - Train Loss: 0.152653, Train Acc: 0.719231 | Val Loss: 0.166396, Val Acc: 0.659794\n",
      "Epoch 7686 - Train Loss: 0.152642, Train Acc: 0.719231 | Val Loss: 0.166385, Val Acc: 0.659794\n",
      "Epoch 7687 - Train Loss: 0.152630, Train Acc: 0.719231 | Val Loss: 0.166375, Val Acc: 0.659794\n",
      "Epoch 7688 - Train Loss: 0.152619, Train Acc: 0.719231 | Val Loss: 0.166364, Val Acc: 0.659794\n",
      "Epoch 7689 - Train Loss: 0.152607, Train Acc: 0.719231 | Val Loss: 0.166354, Val Acc: 0.659794\n",
      "Epoch 7690 - Train Loss: 0.152596, Train Acc: 0.719231 | Val Loss: 0.166343, Val Acc: 0.659794\n",
      "Epoch 7691 - Train Loss: 0.152584, Train Acc: 0.719231 | Val Loss: 0.166332, Val Acc: 0.659794\n",
      "Epoch 7692 - Train Loss: 0.152573, Train Acc: 0.719231 | Val Loss: 0.166322, Val Acc: 0.659794\n",
      "Epoch 7693 - Train Loss: 0.152561, Train Acc: 0.719231 | Val Loss: 0.166311, Val Acc: 0.659794\n",
      "Epoch 7694 - Train Loss: 0.152550, Train Acc: 0.719231 | Val Loss: 0.166300, Val Acc: 0.659794\n",
      "Epoch 7695 - Train Loss: 0.152538, Train Acc: 0.720513 | Val Loss: 0.166290, Val Acc: 0.659794\n",
      "Epoch 7696 - Train Loss: 0.152527, Train Acc: 0.720513 | Val Loss: 0.166279, Val Acc: 0.659794\n",
      "Epoch 7697 - Train Loss: 0.152515, Train Acc: 0.720513 | Val Loss: 0.166269, Val Acc: 0.659794\n",
      "Epoch 7698 - Train Loss: 0.152504, Train Acc: 0.720513 | Val Loss: 0.166258, Val Acc: 0.659794\n",
      "Epoch 7699 - Train Loss: 0.152492, Train Acc: 0.720513 | Val Loss: 0.166247, Val Acc: 0.659794\n",
      "Epoch 7700 - Train Loss: 0.152481, Train Acc: 0.720513 | Val Loss: 0.166237, Val Acc: 0.659794\n",
      "Epoch 7701 - Train Loss: 0.152469, Train Acc: 0.720513 | Val Loss: 0.166226, Val Acc: 0.659794\n",
      "Epoch 7702 - Train Loss: 0.152458, Train Acc: 0.720513 | Val Loss: 0.166215, Val Acc: 0.659794\n",
      "Epoch 7703 - Train Loss: 0.152446, Train Acc: 0.720513 | Val Loss: 0.166205, Val Acc: 0.659794\n",
      "Epoch 7704 - Train Loss: 0.152434, Train Acc: 0.720513 | Val Loss: 0.166194, Val Acc: 0.659794\n",
      "Epoch 7705 - Train Loss: 0.152423, Train Acc: 0.720513 | Val Loss: 0.166184, Val Acc: 0.659794\n",
      "Epoch 7706 - Train Loss: 0.152411, Train Acc: 0.720513 | Val Loss: 0.166173, Val Acc: 0.659794\n",
      "Epoch 7707 - Train Loss: 0.152400, Train Acc: 0.720513 | Val Loss: 0.166162, Val Acc: 0.659794\n",
      "Epoch 7708 - Train Loss: 0.152388, Train Acc: 0.720513 | Val Loss: 0.166152, Val Acc: 0.659794\n",
      "Epoch 7709 - Train Loss: 0.152377, Train Acc: 0.720513 | Val Loss: 0.166141, Val Acc: 0.659794\n",
      "Epoch 7710 - Train Loss: 0.152365, Train Acc: 0.720513 | Val Loss: 0.166130, Val Acc: 0.659794\n",
      "Epoch 7711 - Train Loss: 0.152354, Train Acc: 0.720513 | Val Loss: 0.166120, Val Acc: 0.659794\n",
      "Epoch 7712 - Train Loss: 0.152342, Train Acc: 0.720513 | Val Loss: 0.166109, Val Acc: 0.659794\n",
      "Epoch 7713 - Train Loss: 0.152331, Train Acc: 0.720513 | Val Loss: 0.166099, Val Acc: 0.659794\n",
      "Epoch 7714 - Train Loss: 0.152319, Train Acc: 0.720513 | Val Loss: 0.166088, Val Acc: 0.659794\n",
      "Epoch 7715 - Train Loss: 0.152308, Train Acc: 0.720513 | Val Loss: 0.166077, Val Acc: 0.659794\n",
      "Epoch 7716 - Train Loss: 0.152296, Train Acc: 0.720513 | Val Loss: 0.166067, Val Acc: 0.659794\n",
      "Epoch 7717 - Train Loss: 0.152285, Train Acc: 0.720513 | Val Loss: 0.166056, Val Acc: 0.659794\n",
      "Epoch 7718 - Train Loss: 0.152273, Train Acc: 0.720513 | Val Loss: 0.166046, Val Acc: 0.659794\n",
      "Epoch 7719 - Train Loss: 0.152262, Train Acc: 0.720513 | Val Loss: 0.166035, Val Acc: 0.659794\n",
      "Epoch 7720 - Train Loss: 0.152250, Train Acc: 0.720513 | Val Loss: 0.166024, Val Acc: 0.659794\n",
      "Epoch 7721 - Train Loss: 0.152239, Train Acc: 0.720513 | Val Loss: 0.166014, Val Acc: 0.659794\n",
      "Epoch 7722 - Train Loss: 0.152227, Train Acc: 0.720513 | Val Loss: 0.166003, Val Acc: 0.659794\n",
      "Epoch 7723 - Train Loss: 0.152216, Train Acc: 0.720513 | Val Loss: 0.165993, Val Acc: 0.659794\n",
      "Epoch 7724 - Train Loss: 0.152204, Train Acc: 0.720513 | Val Loss: 0.165982, Val Acc: 0.659794\n",
      "Epoch 7725 - Train Loss: 0.152193, Train Acc: 0.720513 | Val Loss: 0.165971, Val Acc: 0.659794\n",
      "Epoch 7726 - Train Loss: 0.152181, Train Acc: 0.720513 | Val Loss: 0.165961, Val Acc: 0.659794\n",
      "Epoch 7727 - Train Loss: 0.152170, Train Acc: 0.720513 | Val Loss: 0.165950, Val Acc: 0.659794\n",
      "Epoch 7728 - Train Loss: 0.152158, Train Acc: 0.720513 | Val Loss: 0.165940, Val Acc: 0.659794\n",
      "Epoch 7729 - Train Loss: 0.152147, Train Acc: 0.720513 | Val Loss: 0.165929, Val Acc: 0.659794\n",
      "Epoch 7730 - Train Loss: 0.152136, Train Acc: 0.720513 | Val Loss: 0.165919, Val Acc: 0.659794\n",
      "Epoch 7731 - Train Loss: 0.152124, Train Acc: 0.720513 | Val Loss: 0.165908, Val Acc: 0.659794\n",
      "Epoch 7732 - Train Loss: 0.152113, Train Acc: 0.720513 | Val Loss: 0.165897, Val Acc: 0.659794\n",
      "Epoch 7733 - Train Loss: 0.152101, Train Acc: 0.720513 | Val Loss: 0.165887, Val Acc: 0.659794\n",
      "Epoch 7734 - Train Loss: 0.152090, Train Acc: 0.720513 | Val Loss: 0.165876, Val Acc: 0.659794\n",
      "Epoch 7735 - Train Loss: 0.152078, Train Acc: 0.720513 | Val Loss: 0.165866, Val Acc: 0.659794\n",
      "Epoch 7736 - Train Loss: 0.152067, Train Acc: 0.720513 | Val Loss: 0.165855, Val Acc: 0.659794\n",
      "Epoch 7737 - Train Loss: 0.152055, Train Acc: 0.720513 | Val Loss: 0.165845, Val Acc: 0.659794\n",
      "Epoch 7738 - Train Loss: 0.152044, Train Acc: 0.720513 | Val Loss: 0.165834, Val Acc: 0.659794\n",
      "Epoch 7739 - Train Loss: 0.152032, Train Acc: 0.720513 | Val Loss: 0.165823, Val Acc: 0.659794\n",
      "Epoch 7740 - Train Loss: 0.152021, Train Acc: 0.720513 | Val Loss: 0.165813, Val Acc: 0.659794\n",
      "Epoch 7741 - Train Loss: 0.152009, Train Acc: 0.720513 | Val Loss: 0.165802, Val Acc: 0.659794\n",
      "Epoch 7742 - Train Loss: 0.151998, Train Acc: 0.720513 | Val Loss: 0.165792, Val Acc: 0.659794\n",
      "Epoch 7743 - Train Loss: 0.151986, Train Acc: 0.720513 | Val Loss: 0.165781, Val Acc: 0.659794\n",
      "Epoch 7744 - Train Loss: 0.151975, Train Acc: 0.720513 | Val Loss: 0.165771, Val Acc: 0.659794\n",
      "Epoch 7745 - Train Loss: 0.151963, Train Acc: 0.720513 | Val Loss: 0.165760, Val Acc: 0.659794\n",
      "Epoch 7746 - Train Loss: 0.151952, Train Acc: 0.720513 | Val Loss: 0.165749, Val Acc: 0.659794\n",
      "Epoch 7747 - Train Loss: 0.151940, Train Acc: 0.720513 | Val Loss: 0.165739, Val Acc: 0.659794\n",
      "Epoch 7748 - Train Loss: 0.151929, Train Acc: 0.720513 | Val Loss: 0.165728, Val Acc: 0.659794\n",
      "Epoch 7749 - Train Loss: 0.151918, Train Acc: 0.720513 | Val Loss: 0.165718, Val Acc: 0.659794\n",
      "Epoch 7750 - Train Loss: 0.151906, Train Acc: 0.720513 | Val Loss: 0.165707, Val Acc: 0.659794\n",
      "Epoch 7751 - Train Loss: 0.151895, Train Acc: 0.720513 | Val Loss: 0.165697, Val Acc: 0.659794\n",
      "Epoch 7752 - Train Loss: 0.151883, Train Acc: 0.720513 | Val Loss: 0.165686, Val Acc: 0.659794\n",
      "Epoch 7753 - Train Loss: 0.151872, Train Acc: 0.720513 | Val Loss: 0.165675, Val Acc: 0.659794\n",
      "Epoch 7754 - Train Loss: 0.151860, Train Acc: 0.720513 | Val Loss: 0.165665, Val Acc: 0.659794\n",
      "Epoch 7755 - Train Loss: 0.151849, Train Acc: 0.720513 | Val Loss: 0.165654, Val Acc: 0.659794\n",
      "Epoch 7756 - Train Loss: 0.151837, Train Acc: 0.720513 | Val Loss: 0.165644, Val Acc: 0.659794\n",
      "Epoch 7757 - Train Loss: 0.151826, Train Acc: 0.721795 | Val Loss: 0.165633, Val Acc: 0.659794\n",
      "Epoch 7758 - Train Loss: 0.151814, Train Acc: 0.721795 | Val Loss: 0.165623, Val Acc: 0.659794\n",
      "Epoch 7759 - Train Loss: 0.151803, Train Acc: 0.721795 | Val Loss: 0.165612, Val Acc: 0.659794\n",
      "Epoch 7760 - Train Loss: 0.151792, Train Acc: 0.721795 | Val Loss: 0.165602, Val Acc: 0.659794\n",
      "Epoch 7761 - Train Loss: 0.151780, Train Acc: 0.721795 | Val Loss: 0.165591, Val Acc: 0.659794\n",
      "Epoch 7762 - Train Loss: 0.151769, Train Acc: 0.721795 | Val Loss: 0.165581, Val Acc: 0.659794\n",
      "Epoch 7763 - Train Loss: 0.151757, Train Acc: 0.721795 | Val Loss: 0.165570, Val Acc: 0.659794\n",
      "Epoch 7764 - Train Loss: 0.151746, Train Acc: 0.721795 | Val Loss: 0.165559, Val Acc: 0.659794\n",
      "Epoch 7765 - Train Loss: 0.151734, Train Acc: 0.721795 | Val Loss: 0.165549, Val Acc: 0.659794\n",
      "Epoch 7766 - Train Loss: 0.151723, Train Acc: 0.721795 | Val Loss: 0.165538, Val Acc: 0.659794\n",
      "Epoch 7767 - Train Loss: 0.151711, Train Acc: 0.721795 | Val Loss: 0.165528, Val Acc: 0.659794\n",
      "Epoch 7768 - Train Loss: 0.151700, Train Acc: 0.721795 | Val Loss: 0.165517, Val Acc: 0.659794\n",
      "Epoch 7769 - Train Loss: 0.151689, Train Acc: 0.721795 | Val Loss: 0.165507, Val Acc: 0.659794\n",
      "Epoch 7770 - Train Loss: 0.151677, Train Acc: 0.721795 | Val Loss: 0.165496, Val Acc: 0.659794\n",
      "Epoch 7771 - Train Loss: 0.151666, Train Acc: 0.721795 | Val Loss: 0.165486, Val Acc: 0.659794\n",
      "Epoch 7772 - Train Loss: 0.151654, Train Acc: 0.721795 | Val Loss: 0.165475, Val Acc: 0.659794\n",
      "Epoch 7773 - Train Loss: 0.151643, Train Acc: 0.721795 | Val Loss: 0.165465, Val Acc: 0.659794\n",
      "Epoch 7774 - Train Loss: 0.151631, Train Acc: 0.721795 | Val Loss: 0.165454, Val Acc: 0.659794\n",
      "Epoch 7775 - Train Loss: 0.151620, Train Acc: 0.721795 | Val Loss: 0.165444, Val Acc: 0.659794\n",
      "Epoch 7776 - Train Loss: 0.151609, Train Acc: 0.721795 | Val Loss: 0.165433, Val Acc: 0.659794\n",
      "Epoch 7777 - Train Loss: 0.151597, Train Acc: 0.721795 | Val Loss: 0.165423, Val Acc: 0.659794\n",
      "Epoch 7778 - Train Loss: 0.151586, Train Acc: 0.721795 | Val Loss: 0.165412, Val Acc: 0.659794\n",
      "Epoch 7779 - Train Loss: 0.151574, Train Acc: 0.721795 | Val Loss: 0.165402, Val Acc: 0.659794\n",
      "Epoch 7780 - Train Loss: 0.151563, Train Acc: 0.721795 | Val Loss: 0.165391, Val Acc: 0.659794\n",
      "Epoch 7781 - Train Loss: 0.151551, Train Acc: 0.721795 | Val Loss: 0.165381, Val Acc: 0.659794\n",
      "Epoch 7782 - Train Loss: 0.151540, Train Acc: 0.721795 | Val Loss: 0.165370, Val Acc: 0.659794\n",
      "Epoch 7783 - Train Loss: 0.151529, Train Acc: 0.721795 | Val Loss: 0.165360, Val Acc: 0.659794\n",
      "Epoch 7784 - Train Loss: 0.151517, Train Acc: 0.721795 | Val Loss: 0.165349, Val Acc: 0.659794\n",
      "Epoch 7785 - Train Loss: 0.151506, Train Acc: 0.721795 | Val Loss: 0.165338, Val Acc: 0.659794\n",
      "Epoch 7786 - Train Loss: 0.151494, Train Acc: 0.721795 | Val Loss: 0.165328, Val Acc: 0.659794\n",
      "Epoch 7787 - Train Loss: 0.151483, Train Acc: 0.721795 | Val Loss: 0.165317, Val Acc: 0.659794\n",
      "Epoch 7788 - Train Loss: 0.151472, Train Acc: 0.721795 | Val Loss: 0.165307, Val Acc: 0.659794\n",
      "Epoch 7789 - Train Loss: 0.151460, Train Acc: 0.721795 | Val Loss: 0.165296, Val Acc: 0.659794\n",
      "Epoch 7790 - Train Loss: 0.151449, Train Acc: 0.721795 | Val Loss: 0.165286, Val Acc: 0.659794\n",
      "Epoch 7791 - Train Loss: 0.151437, Train Acc: 0.721795 | Val Loss: 0.165275, Val Acc: 0.659794\n",
      "Epoch 7792 - Train Loss: 0.151426, Train Acc: 0.721795 | Val Loss: 0.165265, Val Acc: 0.659794\n",
      "Epoch 7793 - Train Loss: 0.151414, Train Acc: 0.721795 | Val Loss: 0.165254, Val Acc: 0.659794\n",
      "Epoch 7794 - Train Loss: 0.151403, Train Acc: 0.721795 | Val Loss: 0.165244, Val Acc: 0.659794\n",
      "Epoch 7795 - Train Loss: 0.151392, Train Acc: 0.721795 | Val Loss: 0.165233, Val Acc: 0.659794\n",
      "Epoch 7796 - Train Loss: 0.151380, Train Acc: 0.721795 | Val Loss: 0.165223, Val Acc: 0.659794\n",
      "Epoch 7797 - Train Loss: 0.151369, Train Acc: 0.721795 | Val Loss: 0.165212, Val Acc: 0.659794\n",
      "Epoch 7798 - Train Loss: 0.151357, Train Acc: 0.721795 | Val Loss: 0.165202, Val Acc: 0.659794\n",
      "Epoch 7799 - Train Loss: 0.151346, Train Acc: 0.721795 | Val Loss: 0.165191, Val Acc: 0.659794\n",
      "Epoch 7800 - Train Loss: 0.151335, Train Acc: 0.721795 | Val Loss: 0.165181, Val Acc: 0.659794\n",
      "Epoch 7801 - Train Loss: 0.151323, Train Acc: 0.721795 | Val Loss: 0.165170, Val Acc: 0.659794\n",
      "Epoch 7802 - Train Loss: 0.151312, Train Acc: 0.721795 | Val Loss: 0.165160, Val Acc: 0.659794\n",
      "Epoch 7803 - Train Loss: 0.151300, Train Acc: 0.721795 | Val Loss: 0.165150, Val Acc: 0.659794\n",
      "Epoch 7804 - Train Loss: 0.151289, Train Acc: 0.721795 | Val Loss: 0.165139, Val Acc: 0.659794\n",
      "Epoch 7805 - Train Loss: 0.151278, Train Acc: 0.721795 | Val Loss: 0.165129, Val Acc: 0.659794\n",
      "Epoch 7806 - Train Loss: 0.151266, Train Acc: 0.721795 | Val Loss: 0.165118, Val Acc: 0.659794\n",
      "Epoch 7807 - Train Loss: 0.151255, Train Acc: 0.721795 | Val Loss: 0.165108, Val Acc: 0.659794\n",
      "Epoch 7808 - Train Loss: 0.151243, Train Acc: 0.721795 | Val Loss: 0.165097, Val Acc: 0.659794\n",
      "Epoch 7809 - Train Loss: 0.151232, Train Acc: 0.721795 | Val Loss: 0.165087, Val Acc: 0.659794\n",
      "Epoch 7810 - Train Loss: 0.151221, Train Acc: 0.721795 | Val Loss: 0.165076, Val Acc: 0.659794\n",
      "Epoch 7811 - Train Loss: 0.151209, Train Acc: 0.721795 | Val Loss: 0.165066, Val Acc: 0.659794\n",
      "Epoch 7812 - Train Loss: 0.151198, Train Acc: 0.721795 | Val Loss: 0.165055, Val Acc: 0.659794\n",
      "Epoch 7813 - Train Loss: 0.151187, Train Acc: 0.721795 | Val Loss: 0.165045, Val Acc: 0.659794\n",
      "Epoch 7814 - Train Loss: 0.151175, Train Acc: 0.721795 | Val Loss: 0.165035, Val Acc: 0.659794\n",
      "Epoch 7815 - Train Loss: 0.151164, Train Acc: 0.721795 | Val Loss: 0.165025, Val Acc: 0.659794\n",
      "Epoch 7816 - Train Loss: 0.151152, Train Acc: 0.721795 | Val Loss: 0.165014, Val Acc: 0.659794\n",
      "Epoch 7817 - Train Loss: 0.151141, Train Acc: 0.721795 | Val Loss: 0.165004, Val Acc: 0.659794\n",
      "Epoch 7818 - Train Loss: 0.151130, Train Acc: 0.721795 | Val Loss: 0.164994, Val Acc: 0.659794\n",
      "Epoch 7819 - Train Loss: 0.151118, Train Acc: 0.721795 | Val Loss: 0.164984, Val Acc: 0.659794\n",
      "Epoch 7820 - Train Loss: 0.151107, Train Acc: 0.721795 | Val Loss: 0.164973, Val Acc: 0.659794\n",
      "Epoch 7821 - Train Loss: 0.151096, Train Acc: 0.721795 | Val Loss: 0.164963, Val Acc: 0.659794\n",
      "Epoch 7822 - Train Loss: 0.151084, Train Acc: 0.723077 | Val Loss: 0.164953, Val Acc: 0.659794\n",
      "Epoch 7823 - Train Loss: 0.151073, Train Acc: 0.723077 | Val Loss: 0.164943, Val Acc: 0.659794\n",
      "Epoch 7824 - Train Loss: 0.151061, Train Acc: 0.723077 | Val Loss: 0.164932, Val Acc: 0.659794\n",
      "Epoch 7825 - Train Loss: 0.151050, Train Acc: 0.723077 | Val Loss: 0.164922, Val Acc: 0.659794\n",
      "Epoch 7826 - Train Loss: 0.151039, Train Acc: 0.723077 | Val Loss: 0.164912, Val Acc: 0.659794\n",
      "Epoch 7827 - Train Loss: 0.151027, Train Acc: 0.723077 | Val Loss: 0.164902, Val Acc: 0.659794\n",
      "Epoch 7828 - Train Loss: 0.151016, Train Acc: 0.723077 | Val Loss: 0.164891, Val Acc: 0.659794\n",
      "Epoch 7829 - Train Loss: 0.151005, Train Acc: 0.723077 | Val Loss: 0.164881, Val Acc: 0.659794\n",
      "Epoch 7830 - Train Loss: 0.150993, Train Acc: 0.723077 | Val Loss: 0.164871, Val Acc: 0.659794\n",
      "Epoch 7831 - Train Loss: 0.150982, Train Acc: 0.723077 | Val Loss: 0.164861, Val Acc: 0.659794\n",
      "Epoch 7832 - Train Loss: 0.150971, Train Acc: 0.723077 | Val Loss: 0.164850, Val Acc: 0.659794\n",
      "Epoch 7833 - Train Loss: 0.150959, Train Acc: 0.723077 | Val Loss: 0.164840, Val Acc: 0.659794\n",
      "Epoch 7834 - Train Loss: 0.150948, Train Acc: 0.723077 | Val Loss: 0.164830, Val Acc: 0.659794\n",
      "Epoch 7835 - Train Loss: 0.150937, Train Acc: 0.723077 | Val Loss: 0.164820, Val Acc: 0.659794\n",
      "Epoch 7836 - Train Loss: 0.150925, Train Acc: 0.723077 | Val Loss: 0.164809, Val Acc: 0.659794\n",
      "Epoch 7837 - Train Loss: 0.150914, Train Acc: 0.723077 | Val Loss: 0.164799, Val Acc: 0.659794\n",
      "Epoch 7838 - Train Loss: 0.150902, Train Acc: 0.723077 | Val Loss: 0.164789, Val Acc: 0.659794\n",
      "Epoch 7839 - Train Loss: 0.150891, Train Acc: 0.724359 | Val Loss: 0.164778, Val Acc: 0.659794\n",
      "Epoch 7840 - Train Loss: 0.150880, Train Acc: 0.724359 | Val Loss: 0.164768, Val Acc: 0.659794\n",
      "Epoch 7841 - Train Loss: 0.150868, Train Acc: 0.724359 | Val Loss: 0.164758, Val Acc: 0.659794\n",
      "Epoch 7842 - Train Loss: 0.150857, Train Acc: 0.724359 | Val Loss: 0.164747, Val Acc: 0.659794\n",
      "Epoch 7843 - Train Loss: 0.150846, Train Acc: 0.724359 | Val Loss: 0.164737, Val Acc: 0.659794\n",
      "Epoch 7844 - Train Loss: 0.150834, Train Acc: 0.724359 | Val Loss: 0.164727, Val Acc: 0.659794\n",
      "Epoch 7845 - Train Loss: 0.150823, Train Acc: 0.724359 | Val Loss: 0.164717, Val Acc: 0.659794\n",
      "Epoch 7846 - Train Loss: 0.150812, Train Acc: 0.724359 | Val Loss: 0.164706, Val Acc: 0.659794\n",
      "Epoch 7847 - Train Loss: 0.150800, Train Acc: 0.724359 | Val Loss: 0.164696, Val Acc: 0.659794\n",
      "Epoch 7848 - Train Loss: 0.150789, Train Acc: 0.724359 | Val Loss: 0.164686, Val Acc: 0.659794\n",
      "Epoch 7849 - Train Loss: 0.150778, Train Acc: 0.724359 | Val Loss: 0.164675, Val Acc: 0.659794\n",
      "Epoch 7850 - Train Loss: 0.150766, Train Acc: 0.724359 | Val Loss: 0.164665, Val Acc: 0.659794\n",
      "Epoch 7851 - Train Loss: 0.150755, Train Acc: 0.724359 | Val Loss: 0.164655, Val Acc: 0.659794\n",
      "Epoch 7852 - Train Loss: 0.150744, Train Acc: 0.724359 | Val Loss: 0.164645, Val Acc: 0.659794\n",
      "Epoch 7853 - Train Loss: 0.150732, Train Acc: 0.724359 | Val Loss: 0.164634, Val Acc: 0.659794\n",
      "Epoch 7854 - Train Loss: 0.150721, Train Acc: 0.723077 | Val Loss: 0.164624, Val Acc: 0.659794\n",
      "Epoch 7855 - Train Loss: 0.150710, Train Acc: 0.723077 | Val Loss: 0.164614, Val Acc: 0.659794\n",
      "Epoch 7856 - Train Loss: 0.150698, Train Acc: 0.723077 | Val Loss: 0.164603, Val Acc: 0.659794\n",
      "Epoch 7857 - Train Loss: 0.150687, Train Acc: 0.723077 | Val Loss: 0.164593, Val Acc: 0.670103\n",
      "Epoch 7858 - Train Loss: 0.150676, Train Acc: 0.723077 | Val Loss: 0.164583, Val Acc: 0.670103\n",
      "Epoch 7859 - Train Loss: 0.150664, Train Acc: 0.723077 | Val Loss: 0.164572, Val Acc: 0.670103\n",
      "Epoch 7860 - Train Loss: 0.150653, Train Acc: 0.723077 | Val Loss: 0.164562, Val Acc: 0.670103\n",
      "Epoch 7861 - Train Loss: 0.150642, Train Acc: 0.723077 | Val Loss: 0.164552, Val Acc: 0.670103\n",
      "Epoch 7862 - Train Loss: 0.150630, Train Acc: 0.723077 | Val Loss: 0.164541, Val Acc: 0.670103\n",
      "Epoch 7863 - Train Loss: 0.150619, Train Acc: 0.723077 | Val Loss: 0.164531, Val Acc: 0.670103\n",
      "Epoch 7864 - Train Loss: 0.150608, Train Acc: 0.723077 | Val Loss: 0.164521, Val Acc: 0.670103\n",
      "Epoch 7865 - Train Loss: 0.150596, Train Acc: 0.723077 | Val Loss: 0.164511, Val Acc: 0.670103\n",
      "Epoch 7866 - Train Loss: 0.150585, Train Acc: 0.723077 | Val Loss: 0.164500, Val Acc: 0.670103\n",
      "Epoch 7867 - Train Loss: 0.150574, Train Acc: 0.723077 | Val Loss: 0.164490, Val Acc: 0.670103\n",
      "Epoch 7868 - Train Loss: 0.150563, Train Acc: 0.723077 | Val Loss: 0.164480, Val Acc: 0.670103\n",
      "Epoch 7869 - Train Loss: 0.150551, Train Acc: 0.723077 | Val Loss: 0.164469, Val Acc: 0.670103\n",
      "Epoch 7870 - Train Loss: 0.150540, Train Acc: 0.723077 | Val Loss: 0.164459, Val Acc: 0.670103\n",
      "Epoch 7871 - Train Loss: 0.150529, Train Acc: 0.723077 | Val Loss: 0.164449, Val Acc: 0.670103\n",
      "Epoch 7872 - Train Loss: 0.150517, Train Acc: 0.723077 | Val Loss: 0.164438, Val Acc: 0.670103\n",
      "Epoch 7873 - Train Loss: 0.150506, Train Acc: 0.723077 | Val Loss: 0.164428, Val Acc: 0.670103\n",
      "Epoch 7874 - Train Loss: 0.150495, Train Acc: 0.723077 | Val Loss: 0.164418, Val Acc: 0.670103\n",
      "Epoch 7875 - Train Loss: 0.150483, Train Acc: 0.723077 | Val Loss: 0.164408, Val Acc: 0.670103\n",
      "Epoch 7876 - Train Loss: 0.150472, Train Acc: 0.723077 | Val Loss: 0.164397, Val Acc: 0.670103\n",
      "Epoch 7877 - Train Loss: 0.150461, Train Acc: 0.723077 | Val Loss: 0.164387, Val Acc: 0.670103\n",
      "Epoch 7878 - Train Loss: 0.150449, Train Acc: 0.723077 | Val Loss: 0.164377, Val Acc: 0.670103\n",
      "Epoch 7879 - Train Loss: 0.150438, Train Acc: 0.723077 | Val Loss: 0.164366, Val Acc: 0.670103\n",
      "Epoch 7880 - Train Loss: 0.150427, Train Acc: 0.723077 | Val Loss: 0.164356, Val Acc: 0.670103\n",
      "Epoch 7881 - Train Loss: 0.150416, Train Acc: 0.723077 | Val Loss: 0.164346, Val Acc: 0.670103\n",
      "Epoch 7882 - Train Loss: 0.150404, Train Acc: 0.723077 | Val Loss: 0.164335, Val Acc: 0.670103\n",
      "Epoch 7883 - Train Loss: 0.150393, Train Acc: 0.723077 | Val Loss: 0.164325, Val Acc: 0.670103\n",
      "Epoch 7884 - Train Loss: 0.150382, Train Acc: 0.723077 | Val Loss: 0.164315, Val Acc: 0.670103\n",
      "Epoch 7885 - Train Loss: 0.150370, Train Acc: 0.723077 | Val Loss: 0.164305, Val Acc: 0.670103\n",
      "Epoch 7886 - Train Loss: 0.150359, Train Acc: 0.723077 | Val Loss: 0.164294, Val Acc: 0.670103\n",
      "Epoch 7887 - Train Loss: 0.150348, Train Acc: 0.723077 | Val Loss: 0.164284, Val Acc: 0.670103\n",
      "Epoch 7888 - Train Loss: 0.150336, Train Acc: 0.723077 | Val Loss: 0.164274, Val Acc: 0.670103\n",
      "Epoch 7889 - Train Loss: 0.150325, Train Acc: 0.723077 | Val Loss: 0.164263, Val Acc: 0.670103\n",
      "Epoch 7890 - Train Loss: 0.150314, Train Acc: 0.723077 | Val Loss: 0.164253, Val Acc: 0.670103\n",
      "Epoch 7891 - Train Loss: 0.150303, Train Acc: 0.723077 | Val Loss: 0.164243, Val Acc: 0.670103\n",
      "Epoch 7892 - Train Loss: 0.150291, Train Acc: 0.723077 | Val Loss: 0.164232, Val Acc: 0.670103\n",
      "Epoch 7893 - Train Loss: 0.150280, Train Acc: 0.723077 | Val Loss: 0.164222, Val Acc: 0.670103\n",
      "Epoch 7894 - Train Loss: 0.150269, Train Acc: 0.723077 | Val Loss: 0.164212, Val Acc: 0.670103\n",
      "Epoch 7895 - Train Loss: 0.150257, Train Acc: 0.723077 | Val Loss: 0.164202, Val Acc: 0.670103\n",
      "Epoch 7896 - Train Loss: 0.150246, Train Acc: 0.723077 | Val Loss: 0.164191, Val Acc: 0.670103\n",
      "Epoch 7897 - Train Loss: 0.150235, Train Acc: 0.723077 | Val Loss: 0.164181, Val Acc: 0.670103\n",
      "Epoch 7898 - Train Loss: 0.150224, Train Acc: 0.723077 | Val Loss: 0.164171, Val Acc: 0.670103\n",
      "Epoch 7899 - Train Loss: 0.150212, Train Acc: 0.723077 | Val Loss: 0.164160, Val Acc: 0.670103\n",
      "Epoch 7900 - Train Loss: 0.150201, Train Acc: 0.724359 | Val Loss: 0.164150, Val Acc: 0.670103\n",
      "Epoch 7901 - Train Loss: 0.150190, Train Acc: 0.724359 | Val Loss: 0.164140, Val Acc: 0.670103\n",
      "Epoch 7902 - Train Loss: 0.150178, Train Acc: 0.724359 | Val Loss: 0.164130, Val Acc: 0.670103\n",
      "Epoch 7903 - Train Loss: 0.150167, Train Acc: 0.724359 | Val Loss: 0.164119, Val Acc: 0.670103\n",
      "Epoch 7904 - Train Loss: 0.150156, Train Acc: 0.724359 | Val Loss: 0.164109, Val Acc: 0.670103\n",
      "Epoch 7905 - Train Loss: 0.150145, Train Acc: 0.725641 | Val Loss: 0.164099, Val Acc: 0.670103\n",
      "Epoch 7906 - Train Loss: 0.150133, Train Acc: 0.725641 | Val Loss: 0.164089, Val Acc: 0.670103\n",
      "Epoch 7907 - Train Loss: 0.150122, Train Acc: 0.725641 | Val Loss: 0.164078, Val Acc: 0.670103\n",
      "Epoch 7908 - Train Loss: 0.150111, Train Acc: 0.725641 | Val Loss: 0.164068, Val Acc: 0.670103\n",
      "Epoch 7909 - Train Loss: 0.150100, Train Acc: 0.725641 | Val Loss: 0.164058, Val Acc: 0.670103\n",
      "Epoch 7910 - Train Loss: 0.150088, Train Acc: 0.725641 | Val Loss: 0.164047, Val Acc: 0.670103\n",
      "Epoch 7911 - Train Loss: 0.150077, Train Acc: 0.725641 | Val Loss: 0.164037, Val Acc: 0.670103\n",
      "Epoch 7912 - Train Loss: 0.150066, Train Acc: 0.725641 | Val Loss: 0.164027, Val Acc: 0.670103\n",
      "Epoch 7913 - Train Loss: 0.150055, Train Acc: 0.725641 | Val Loss: 0.164017, Val Acc: 0.670103\n",
      "Epoch 7914 - Train Loss: 0.150043, Train Acc: 0.725641 | Val Loss: 0.164006, Val Acc: 0.670103\n",
      "Epoch 7915 - Train Loss: 0.150032, Train Acc: 0.725641 | Val Loss: 0.163996, Val Acc: 0.670103\n",
      "Epoch 7916 - Train Loss: 0.150021, Train Acc: 0.725641 | Val Loss: 0.163986, Val Acc: 0.670103\n",
      "Epoch 7917 - Train Loss: 0.150010, Train Acc: 0.725641 | Val Loss: 0.163976, Val Acc: 0.670103\n",
      "Epoch 7918 - Train Loss: 0.149998, Train Acc: 0.725641 | Val Loss: 0.163965, Val Acc: 0.670103\n",
      "Epoch 7919 - Train Loss: 0.149987, Train Acc: 0.725641 | Val Loss: 0.163955, Val Acc: 0.670103\n",
      "Epoch 7920 - Train Loss: 0.149976, Train Acc: 0.725641 | Val Loss: 0.163945, Val Acc: 0.670103\n",
      "Epoch 7921 - Train Loss: 0.149965, Train Acc: 0.725641 | Val Loss: 0.163935, Val Acc: 0.670103\n",
      "Epoch 7922 - Train Loss: 0.149953, Train Acc: 0.725641 | Val Loss: 0.163924, Val Acc: 0.670103\n",
      "Epoch 7923 - Train Loss: 0.149942, Train Acc: 0.725641 | Val Loss: 0.163914, Val Acc: 0.670103\n",
      "Epoch 7924 - Train Loss: 0.149931, Train Acc: 0.726923 | Val Loss: 0.163904, Val Acc: 0.670103\n",
      "Epoch 7925 - Train Loss: 0.149920, Train Acc: 0.726923 | Val Loss: 0.163894, Val Acc: 0.670103\n",
      "Epoch 7926 - Train Loss: 0.149908, Train Acc: 0.726923 | Val Loss: 0.163883, Val Acc: 0.670103\n",
      "Epoch 7927 - Train Loss: 0.149897, Train Acc: 0.726923 | Val Loss: 0.163873, Val Acc: 0.670103\n",
      "Epoch 7928 - Train Loss: 0.149886, Train Acc: 0.726923 | Val Loss: 0.163863, Val Acc: 0.670103\n",
      "Epoch 7929 - Train Loss: 0.149875, Train Acc: 0.726923 | Val Loss: 0.163853, Val Acc: 0.670103\n",
      "Epoch 7930 - Train Loss: 0.149863, Train Acc: 0.726923 | Val Loss: 0.163842, Val Acc: 0.670103\n",
      "Epoch 7931 - Train Loss: 0.149852, Train Acc: 0.726923 | Val Loss: 0.163832, Val Acc: 0.670103\n",
      "Epoch 7932 - Train Loss: 0.149841, Train Acc: 0.726923 | Val Loss: 0.163822, Val Acc: 0.670103\n",
      "Epoch 7933 - Train Loss: 0.149830, Train Acc: 0.726923 | Val Loss: 0.163812, Val Acc: 0.670103\n",
      "Epoch 7934 - Train Loss: 0.149818, Train Acc: 0.726923 | Val Loss: 0.163801, Val Acc: 0.670103\n",
      "Epoch 7935 - Train Loss: 0.149807, Train Acc: 0.726923 | Val Loss: 0.163791, Val Acc: 0.670103\n",
      "Epoch 7936 - Train Loss: 0.149796, Train Acc: 0.726923 | Val Loss: 0.163781, Val Acc: 0.670103\n",
      "Epoch 7937 - Train Loss: 0.149785, Train Acc: 0.726923 | Val Loss: 0.163771, Val Acc: 0.670103\n",
      "Epoch 7938 - Train Loss: 0.149773, Train Acc: 0.726923 | Val Loss: 0.163760, Val Acc: 0.670103\n",
      "Epoch 7939 - Train Loss: 0.149762, Train Acc: 0.726923 | Val Loss: 0.163750, Val Acc: 0.670103\n",
      "Epoch 7940 - Train Loss: 0.149751, Train Acc: 0.726923 | Val Loss: 0.163740, Val Acc: 0.670103\n",
      "Epoch 7941 - Train Loss: 0.149740, Train Acc: 0.726923 | Val Loss: 0.163730, Val Acc: 0.670103\n",
      "Epoch 7942 - Train Loss: 0.149729, Train Acc: 0.726923 | Val Loss: 0.163720, Val Acc: 0.670103\n",
      "Epoch 7943 - Train Loss: 0.149717, Train Acc: 0.726923 | Val Loss: 0.163710, Val Acc: 0.670103\n",
      "Epoch 7944 - Train Loss: 0.149706, Train Acc: 0.726923 | Val Loss: 0.163700, Val Acc: 0.670103\n",
      "Epoch 7945 - Train Loss: 0.149695, Train Acc: 0.726923 | Val Loss: 0.163690, Val Acc: 0.670103\n",
      "Epoch 7946 - Train Loss: 0.149684, Train Acc: 0.726923 | Val Loss: 0.163679, Val Acc: 0.670103\n",
      "Epoch 7947 - Train Loss: 0.149672, Train Acc: 0.726923 | Val Loss: 0.163669, Val Acc: 0.670103\n",
      "Epoch 7948 - Train Loss: 0.149661, Train Acc: 0.726923 | Val Loss: 0.163659, Val Acc: 0.670103\n",
      "Epoch 7949 - Train Loss: 0.149650, Train Acc: 0.726923 | Val Loss: 0.163649, Val Acc: 0.670103\n",
      "Epoch 7950 - Train Loss: 0.149639, Train Acc: 0.726923 | Val Loss: 0.163639, Val Acc: 0.670103\n",
      "Epoch 7951 - Train Loss: 0.149628, Train Acc: 0.726923 | Val Loss: 0.163629, Val Acc: 0.670103\n",
      "Epoch 7952 - Train Loss: 0.149616, Train Acc: 0.726923 | Val Loss: 0.163619, Val Acc: 0.670103\n",
      "Epoch 7953 - Train Loss: 0.149605, Train Acc: 0.726923 | Val Loss: 0.163609, Val Acc: 0.670103\n",
      "Epoch 7954 - Train Loss: 0.149594, Train Acc: 0.726923 | Val Loss: 0.163599, Val Acc: 0.670103\n",
      "Epoch 7955 - Train Loss: 0.149583, Train Acc: 0.726923 | Val Loss: 0.163589, Val Acc: 0.670103\n",
      "Epoch 7956 - Train Loss: 0.149572, Train Acc: 0.726923 | Val Loss: 0.163578, Val Acc: 0.670103\n",
      "Epoch 7957 - Train Loss: 0.149560, Train Acc: 0.726923 | Val Loss: 0.163568, Val Acc: 0.670103\n",
      "Epoch 7958 - Train Loss: 0.149549, Train Acc: 0.726923 | Val Loss: 0.163558, Val Acc: 0.670103\n",
      "Epoch 7959 - Train Loss: 0.149538, Train Acc: 0.726923 | Val Loss: 0.163548, Val Acc: 0.670103\n",
      "Epoch 7960 - Train Loss: 0.149527, Train Acc: 0.726923 | Val Loss: 0.163538, Val Acc: 0.670103\n",
      "Epoch 7961 - Train Loss: 0.149516, Train Acc: 0.726923 | Val Loss: 0.163528, Val Acc: 0.670103\n",
      "Epoch 7962 - Train Loss: 0.149504, Train Acc: 0.726923 | Val Loss: 0.163518, Val Acc: 0.670103\n",
      "Epoch 7963 - Train Loss: 0.149493, Train Acc: 0.726923 | Val Loss: 0.163508, Val Acc: 0.670103\n",
      "Epoch 7964 - Train Loss: 0.149482, Train Acc: 0.726923 | Val Loss: 0.163498, Val Acc: 0.670103\n",
      "Epoch 7965 - Train Loss: 0.149471, Train Acc: 0.726923 | Val Loss: 0.163487, Val Acc: 0.670103\n",
      "Epoch 7966 - Train Loss: 0.149460, Train Acc: 0.726923 | Val Loss: 0.163477, Val Acc: 0.670103\n",
      "Epoch 7967 - Train Loss: 0.149448, Train Acc: 0.726923 | Val Loss: 0.163467, Val Acc: 0.670103\n",
      "Epoch 7968 - Train Loss: 0.149437, Train Acc: 0.726923 | Val Loss: 0.163457, Val Acc: 0.670103\n",
      "Epoch 7969 - Train Loss: 0.149426, Train Acc: 0.726923 | Val Loss: 0.163447, Val Acc: 0.670103\n",
      "Epoch 7970 - Train Loss: 0.149415, Train Acc: 0.728205 | Val Loss: 0.163437, Val Acc: 0.670103\n",
      "Epoch 7971 - Train Loss: 0.149404, Train Acc: 0.728205 | Val Loss: 0.163427, Val Acc: 0.670103\n",
      "Epoch 7972 - Train Loss: 0.149392, Train Acc: 0.728205 | Val Loss: 0.163416, Val Acc: 0.670103\n",
      "Epoch 7973 - Train Loss: 0.149381, Train Acc: 0.728205 | Val Loss: 0.163406, Val Acc: 0.670103\n",
      "Epoch 7974 - Train Loss: 0.149370, Train Acc: 0.728205 | Val Loss: 0.163396, Val Acc: 0.670103\n",
      "Epoch 7975 - Train Loss: 0.149359, Train Acc: 0.729487 | Val Loss: 0.163386, Val Acc: 0.670103\n",
      "Epoch 7976 - Train Loss: 0.149348, Train Acc: 0.729487 | Val Loss: 0.163375, Val Acc: 0.670103\n",
      "Epoch 7977 - Train Loss: 0.149337, Train Acc: 0.729487 | Val Loss: 0.163365, Val Acc: 0.670103\n",
      "Epoch 7978 - Train Loss: 0.149325, Train Acc: 0.729487 | Val Loss: 0.163355, Val Acc: 0.670103\n",
      "Epoch 7979 - Train Loss: 0.149314, Train Acc: 0.729487 | Val Loss: 0.163344, Val Acc: 0.670103\n",
      "Epoch 7980 - Train Loss: 0.149303, Train Acc: 0.729487 | Val Loss: 0.163334, Val Acc: 0.670103\n",
      "Epoch 7981 - Train Loss: 0.149292, Train Acc: 0.729487 | Val Loss: 0.163324, Val Acc: 0.670103\n",
      "Epoch 7982 - Train Loss: 0.149281, Train Acc: 0.729487 | Val Loss: 0.163314, Val Acc: 0.670103\n",
      "Epoch 7983 - Train Loss: 0.149270, Train Acc: 0.729487 | Val Loss: 0.163303, Val Acc: 0.670103\n",
      "Epoch 7984 - Train Loss: 0.149258, Train Acc: 0.729487 | Val Loss: 0.163293, Val Acc: 0.670103\n",
      "Epoch 7985 - Train Loss: 0.149247, Train Acc: 0.729487 | Val Loss: 0.163283, Val Acc: 0.670103\n",
      "Epoch 7986 - Train Loss: 0.149236, Train Acc: 0.729487 | Val Loss: 0.163273, Val Acc: 0.670103\n",
      "Epoch 7987 - Train Loss: 0.149225, Train Acc: 0.729487 | Val Loss: 0.163263, Val Acc: 0.670103\n",
      "Epoch 7988 - Train Loss: 0.149214, Train Acc: 0.729487 | Val Loss: 0.163252, Val Acc: 0.670103\n",
      "Epoch 7989 - Train Loss: 0.149203, Train Acc: 0.729487 | Val Loss: 0.163242, Val Acc: 0.670103\n",
      "Epoch 7990 - Train Loss: 0.149191, Train Acc: 0.729487 | Val Loss: 0.163232, Val Acc: 0.670103\n",
      "Epoch 7991 - Train Loss: 0.149180, Train Acc: 0.729487 | Val Loss: 0.163222, Val Acc: 0.670103\n",
      "Epoch 7992 - Train Loss: 0.149169, Train Acc: 0.729487 | Val Loss: 0.163211, Val Acc: 0.670103\n",
      "Epoch 7993 - Train Loss: 0.149158, Train Acc: 0.729487 | Val Loss: 0.163201, Val Acc: 0.670103\n",
      "Epoch 7994 - Train Loss: 0.149147, Train Acc: 0.729487 | Val Loss: 0.163191, Val Acc: 0.670103\n",
      "Epoch 7995 - Train Loss: 0.149136, Train Acc: 0.730769 | Val Loss: 0.163181, Val Acc: 0.670103\n",
      "Epoch 7996 - Train Loss: 0.149125, Train Acc: 0.730769 | Val Loss: 0.163171, Val Acc: 0.670103\n",
      "Epoch 7997 - Train Loss: 0.149113, Train Acc: 0.730769 | Val Loss: 0.163160, Val Acc: 0.670103\n",
      "Epoch 7998 - Train Loss: 0.149102, Train Acc: 0.730769 | Val Loss: 0.163150, Val Acc: 0.670103\n",
      "Epoch 7999 - Train Loss: 0.149091, Train Acc: 0.730769 | Val Loss: 0.163140, Val Acc: 0.670103\n",
      "Epoch 8000 - Train Loss: 0.149080, Train Acc: 0.730769 | Val Loss: 0.163130, Val Acc: 0.670103\n",
      "Epoch 8001 - Train Loss: 0.149069, Train Acc: 0.730769 | Val Loss: 0.163120, Val Acc: 0.670103\n",
      "Epoch 8002 - Train Loss: 0.149058, Train Acc: 0.730769 | Val Loss: 0.163109, Val Acc: 0.670103\n",
      "Epoch 8003 - Train Loss: 0.149046, Train Acc: 0.730769 | Val Loss: 0.163099, Val Acc: 0.670103\n",
      "Epoch 8004 - Train Loss: 0.149035, Train Acc: 0.730769 | Val Loss: 0.163089, Val Acc: 0.680412\n",
      "Epoch 8005 - Train Loss: 0.149024, Train Acc: 0.730769 | Val Loss: 0.163079, Val Acc: 0.680412\n",
      "Epoch 8006 - Train Loss: 0.149013, Train Acc: 0.730769 | Val Loss: 0.163069, Val Acc: 0.680412\n",
      "Epoch 8007 - Train Loss: 0.149002, Train Acc: 0.730769 | Val Loss: 0.163058, Val Acc: 0.680412\n",
      "Epoch 8008 - Train Loss: 0.148991, Train Acc: 0.729487 | Val Loss: 0.163048, Val Acc: 0.680412\n",
      "Epoch 8009 - Train Loss: 0.148980, Train Acc: 0.729487 | Val Loss: 0.163038, Val Acc: 0.680412\n",
      "Epoch 8010 - Train Loss: 0.148969, Train Acc: 0.729487 | Val Loss: 0.163028, Val Acc: 0.680412\n",
      "Epoch 8011 - Train Loss: 0.148957, Train Acc: 0.729487 | Val Loss: 0.163018, Val Acc: 0.680412\n",
      "Epoch 8012 - Train Loss: 0.148946, Train Acc: 0.729487 | Val Loss: 0.163008, Val Acc: 0.680412\n",
      "Epoch 8013 - Train Loss: 0.148935, Train Acc: 0.729487 | Val Loss: 0.162997, Val Acc: 0.680412\n",
      "Epoch 8014 - Train Loss: 0.148924, Train Acc: 0.730769 | Val Loss: 0.162987, Val Acc: 0.680412\n",
      "Epoch 8015 - Train Loss: 0.148913, Train Acc: 0.732051 | Val Loss: 0.162977, Val Acc: 0.680412\n",
      "Epoch 8016 - Train Loss: 0.148902, Train Acc: 0.732051 | Val Loss: 0.162967, Val Acc: 0.680412\n",
      "Epoch 8017 - Train Loss: 0.148891, Train Acc: 0.732051 | Val Loss: 0.162957, Val Acc: 0.680412\n",
      "Epoch 8018 - Train Loss: 0.148880, Train Acc: 0.732051 | Val Loss: 0.162947, Val Acc: 0.680412\n",
      "Epoch 8019 - Train Loss: 0.148868, Train Acc: 0.732051 | Val Loss: 0.162937, Val Acc: 0.680412\n",
      "Epoch 8020 - Train Loss: 0.148857, Train Acc: 0.732051 | Val Loss: 0.162926, Val Acc: 0.680412\n",
      "Epoch 8021 - Train Loss: 0.148846, Train Acc: 0.732051 | Val Loss: 0.162916, Val Acc: 0.680412\n",
      "Epoch 8022 - Train Loss: 0.148835, Train Acc: 0.732051 | Val Loss: 0.162906, Val Acc: 0.680412\n",
      "Epoch 8023 - Train Loss: 0.148824, Train Acc: 0.733333 | Val Loss: 0.162896, Val Acc: 0.680412\n",
      "Epoch 8024 - Train Loss: 0.148813, Train Acc: 0.733333 | Val Loss: 0.162886, Val Acc: 0.680412\n",
      "Epoch 8025 - Train Loss: 0.148802, Train Acc: 0.733333 | Val Loss: 0.162876, Val Acc: 0.680412\n",
      "Epoch 8026 - Train Loss: 0.148791, Train Acc: 0.733333 | Val Loss: 0.162866, Val Acc: 0.680412\n",
      "Epoch 8027 - Train Loss: 0.148779, Train Acc: 0.733333 | Val Loss: 0.162855, Val Acc: 0.680412\n",
      "Epoch 8028 - Train Loss: 0.148768, Train Acc: 0.733333 | Val Loss: 0.162845, Val Acc: 0.680412\n",
      "Epoch 8029 - Train Loss: 0.148757, Train Acc: 0.733333 | Val Loss: 0.162835, Val Acc: 0.680412\n",
      "Epoch 8030 - Train Loss: 0.148746, Train Acc: 0.733333 | Val Loss: 0.162825, Val Acc: 0.680412\n",
      "Epoch 8031 - Train Loss: 0.148735, Train Acc: 0.733333 | Val Loss: 0.162815, Val Acc: 0.680412\n",
      "Epoch 8032 - Train Loss: 0.148724, Train Acc: 0.733333 | Val Loss: 0.162805, Val Acc: 0.680412\n",
      "Epoch 8033 - Train Loss: 0.148713, Train Acc: 0.733333 | Val Loss: 0.162795, Val Acc: 0.680412\n",
      "Epoch 8034 - Train Loss: 0.148702, Train Acc: 0.733333 | Val Loss: 0.162784, Val Acc: 0.680412\n",
      "Epoch 8035 - Train Loss: 0.148691, Train Acc: 0.733333 | Val Loss: 0.162774, Val Acc: 0.680412\n",
      "Epoch 8036 - Train Loss: 0.148680, Train Acc: 0.733333 | Val Loss: 0.162764, Val Acc: 0.680412\n",
      "Epoch 8037 - Train Loss: 0.148668, Train Acc: 0.733333 | Val Loss: 0.162754, Val Acc: 0.680412\n",
      "Epoch 8038 - Train Loss: 0.148657, Train Acc: 0.733333 | Val Loss: 0.162744, Val Acc: 0.680412\n",
      "Epoch 8039 - Train Loss: 0.148646, Train Acc: 0.733333 | Val Loss: 0.162734, Val Acc: 0.680412\n",
      "Epoch 8040 - Train Loss: 0.148635, Train Acc: 0.733333 | Val Loss: 0.162724, Val Acc: 0.680412\n",
      "Epoch 8041 - Train Loss: 0.148624, Train Acc: 0.733333 | Val Loss: 0.162714, Val Acc: 0.680412\n",
      "Epoch 8042 - Train Loss: 0.148613, Train Acc: 0.733333 | Val Loss: 0.162703, Val Acc: 0.680412\n",
      "Epoch 8043 - Train Loss: 0.148602, Train Acc: 0.733333 | Val Loss: 0.162693, Val Acc: 0.680412\n",
      "Epoch 8044 - Train Loss: 0.148591, Train Acc: 0.733333 | Val Loss: 0.162683, Val Acc: 0.680412\n",
      "Epoch 8045 - Train Loss: 0.148580, Train Acc: 0.733333 | Val Loss: 0.162673, Val Acc: 0.680412\n",
      "Epoch 8046 - Train Loss: 0.148569, Train Acc: 0.733333 | Val Loss: 0.162663, Val Acc: 0.680412\n",
      "Epoch 8047 - Train Loss: 0.148558, Train Acc: 0.733333 | Val Loss: 0.162653, Val Acc: 0.680412\n",
      "Epoch 8048 - Train Loss: 0.148546, Train Acc: 0.733333 | Val Loss: 0.162643, Val Acc: 0.680412\n",
      "Epoch 8049 - Train Loss: 0.148535, Train Acc: 0.734615 | Val Loss: 0.162633, Val Acc: 0.680412\n",
      "Epoch 8050 - Train Loss: 0.148524, Train Acc: 0.734615 | Val Loss: 0.162622, Val Acc: 0.680412\n",
      "Epoch 8051 - Train Loss: 0.148513, Train Acc: 0.734615 | Val Loss: 0.162612, Val Acc: 0.680412\n",
      "Epoch 8052 - Train Loss: 0.148502, Train Acc: 0.734615 | Val Loss: 0.162602, Val Acc: 0.680412\n",
      "Epoch 8053 - Train Loss: 0.148491, Train Acc: 0.734615 | Val Loss: 0.162592, Val Acc: 0.680412\n",
      "Epoch 8054 - Train Loss: 0.148480, Train Acc: 0.734615 | Val Loss: 0.162582, Val Acc: 0.680412\n",
      "Epoch 8055 - Train Loss: 0.148469, Train Acc: 0.734615 | Val Loss: 0.162572, Val Acc: 0.680412\n",
      "Epoch 8056 - Train Loss: 0.148458, Train Acc: 0.734615 | Val Loss: 0.162562, Val Acc: 0.680412\n",
      "Epoch 8057 - Train Loss: 0.148447, Train Acc: 0.734615 | Val Loss: 0.162552, Val Acc: 0.680412\n",
      "Epoch 8058 - Train Loss: 0.148436, Train Acc: 0.734615 | Val Loss: 0.162542, Val Acc: 0.680412\n",
      "Epoch 8059 - Train Loss: 0.148425, Train Acc: 0.734615 | Val Loss: 0.162531, Val Acc: 0.680412\n",
      "Epoch 8060 - Train Loss: 0.148414, Train Acc: 0.734615 | Val Loss: 0.162521, Val Acc: 0.680412\n",
      "Epoch 8061 - Train Loss: 0.148402, Train Acc: 0.734615 | Val Loss: 0.162511, Val Acc: 0.680412\n",
      "Epoch 8062 - Train Loss: 0.148391, Train Acc: 0.734615 | Val Loss: 0.162501, Val Acc: 0.680412\n",
      "Epoch 8063 - Train Loss: 0.148380, Train Acc: 0.734615 | Val Loss: 0.162491, Val Acc: 0.680412\n",
      "Epoch 8064 - Train Loss: 0.148369, Train Acc: 0.734615 | Val Loss: 0.162481, Val Acc: 0.680412\n",
      "Epoch 8065 - Train Loss: 0.148358, Train Acc: 0.734615 | Val Loss: 0.162471, Val Acc: 0.680412\n",
      "Epoch 8066 - Train Loss: 0.148347, Train Acc: 0.734615 | Val Loss: 0.162461, Val Acc: 0.680412\n",
      "Epoch 8067 - Train Loss: 0.148336, Train Acc: 0.734615 | Val Loss: 0.162451, Val Acc: 0.680412\n",
      "Epoch 8068 - Train Loss: 0.148325, Train Acc: 0.734615 | Val Loss: 0.162441, Val Acc: 0.680412\n",
      "Epoch 8069 - Train Loss: 0.148314, Train Acc: 0.734615 | Val Loss: 0.162430, Val Acc: 0.680412\n",
      "Epoch 8070 - Train Loss: 0.148303, Train Acc: 0.734615 | Val Loss: 0.162420, Val Acc: 0.680412\n",
      "Epoch 8071 - Train Loss: 0.148292, Train Acc: 0.734615 | Val Loss: 0.162410, Val Acc: 0.680412\n",
      "Epoch 8072 - Train Loss: 0.148281, Train Acc: 0.734615 | Val Loss: 0.162400, Val Acc: 0.680412\n",
      "Epoch 8073 - Train Loss: 0.148270, Train Acc: 0.734615 | Val Loss: 0.162390, Val Acc: 0.680412\n",
      "Epoch 8074 - Train Loss: 0.148259, Train Acc: 0.734615 | Val Loss: 0.162380, Val Acc: 0.680412\n",
      "Epoch 8075 - Train Loss: 0.148248, Train Acc: 0.734615 | Val Loss: 0.162370, Val Acc: 0.680412\n",
      "Epoch 8076 - Train Loss: 0.148237, Train Acc: 0.734615 | Val Loss: 0.162360, Val Acc: 0.680412\n",
      "Epoch 8077 - Train Loss: 0.148226, Train Acc: 0.734615 | Val Loss: 0.162350, Val Acc: 0.680412\n",
      "Epoch 8078 - Train Loss: 0.148214, Train Acc: 0.734615 | Val Loss: 0.162340, Val Acc: 0.680412\n",
      "Epoch 8079 - Train Loss: 0.148203, Train Acc: 0.734615 | Val Loss: 0.162330, Val Acc: 0.680412\n",
      "Epoch 8080 - Train Loss: 0.148192, Train Acc: 0.734615 | Val Loss: 0.162319, Val Acc: 0.680412\n",
      "Epoch 8081 - Train Loss: 0.148181, Train Acc: 0.734615 | Val Loss: 0.162309, Val Acc: 0.680412\n",
      "Epoch 8082 - Train Loss: 0.148170, Train Acc: 0.734615 | Val Loss: 0.162299, Val Acc: 0.680412\n",
      "Epoch 8083 - Train Loss: 0.148159, Train Acc: 0.734615 | Val Loss: 0.162289, Val Acc: 0.680412\n",
      "Epoch 8084 - Train Loss: 0.148148, Train Acc: 0.734615 | Val Loss: 0.162279, Val Acc: 0.680412\n",
      "Epoch 8085 - Train Loss: 0.148137, Train Acc: 0.734615 | Val Loss: 0.162269, Val Acc: 0.680412\n",
      "Epoch 8086 - Train Loss: 0.148126, Train Acc: 0.734615 | Val Loss: 0.162259, Val Acc: 0.680412\n",
      "Epoch 8087 - Train Loss: 0.148115, Train Acc: 0.734615 | Val Loss: 0.162249, Val Acc: 0.680412\n",
      "Epoch 8088 - Train Loss: 0.148104, Train Acc: 0.734615 | Val Loss: 0.162239, Val Acc: 0.680412\n",
      "Epoch 8089 - Train Loss: 0.148093, Train Acc: 0.734615 | Val Loss: 0.162229, Val Acc: 0.680412\n",
      "Epoch 8090 - Train Loss: 0.148082, Train Acc: 0.734615 | Val Loss: 0.162219, Val Acc: 0.680412\n",
      "Epoch 8091 - Train Loss: 0.148071, Train Acc: 0.734615 | Val Loss: 0.162209, Val Acc: 0.680412\n",
      "Epoch 8092 - Train Loss: 0.148060, Train Acc: 0.734615 | Val Loss: 0.162199, Val Acc: 0.680412\n",
      "Epoch 8093 - Train Loss: 0.148049, Train Acc: 0.734615 | Val Loss: 0.162189, Val Acc: 0.680412\n",
      "Epoch 8094 - Train Loss: 0.148038, Train Acc: 0.734615 | Val Loss: 0.162178, Val Acc: 0.680412\n",
      "Epoch 8095 - Train Loss: 0.148027, Train Acc: 0.734615 | Val Loss: 0.162168, Val Acc: 0.680412\n",
      "Epoch 8096 - Train Loss: 0.148016, Train Acc: 0.734615 | Val Loss: 0.162158, Val Acc: 0.680412\n",
      "Epoch 8097 - Train Loss: 0.148005, Train Acc: 0.734615 | Val Loss: 0.162148, Val Acc: 0.680412\n",
      "Epoch 8098 - Train Loss: 0.147994, Train Acc: 0.734615 | Val Loss: 0.162138, Val Acc: 0.680412\n",
      "Epoch 8099 - Train Loss: 0.147983, Train Acc: 0.734615 | Val Loss: 0.162128, Val Acc: 0.680412\n",
      "Epoch 8100 - Train Loss: 0.147972, Train Acc: 0.734615 | Val Loss: 0.162118, Val Acc: 0.680412\n",
      "Epoch 8101 - Train Loss: 0.147961, Train Acc: 0.734615 | Val Loss: 0.162108, Val Acc: 0.680412\n",
      "Epoch 8102 - Train Loss: 0.147950, Train Acc: 0.734615 | Val Loss: 0.162098, Val Acc: 0.680412\n",
      "Epoch 8103 - Train Loss: 0.147939, Train Acc: 0.734615 | Val Loss: 0.162088, Val Acc: 0.680412\n",
      "Epoch 8104 - Train Loss: 0.147928, Train Acc: 0.734615 | Val Loss: 0.162078, Val Acc: 0.680412\n",
      "Epoch 8105 - Train Loss: 0.147917, Train Acc: 0.734615 | Val Loss: 0.162068, Val Acc: 0.680412\n",
      "Epoch 8106 - Train Loss: 0.147906, Train Acc: 0.734615 | Val Loss: 0.162058, Val Acc: 0.680412\n",
      "Epoch 8107 - Train Loss: 0.147895, Train Acc: 0.734615 | Val Loss: 0.162048, Val Acc: 0.680412\n",
      "Epoch 8108 - Train Loss: 0.147884, Train Acc: 0.734615 | Val Loss: 0.162038, Val Acc: 0.680412\n",
      "Epoch 8109 - Train Loss: 0.147873, Train Acc: 0.734615 | Val Loss: 0.162028, Val Acc: 0.680412\n",
      "Epoch 8110 - Train Loss: 0.147862, Train Acc: 0.734615 | Val Loss: 0.162018, Val Acc: 0.680412\n",
      "Epoch 8111 - Train Loss: 0.147851, Train Acc: 0.734615 | Val Loss: 0.162008, Val Acc: 0.680412\n",
      "Epoch 8112 - Train Loss: 0.147840, Train Acc: 0.734615 | Val Loss: 0.161998, Val Acc: 0.680412\n",
      "Epoch 8113 - Train Loss: 0.147829, Train Acc: 0.734615 | Val Loss: 0.161988, Val Acc: 0.680412\n",
      "Epoch 8114 - Train Loss: 0.147818, Train Acc: 0.734615 | Val Loss: 0.161977, Val Acc: 0.680412\n",
      "Epoch 8115 - Train Loss: 0.147807, Train Acc: 0.734615 | Val Loss: 0.161967, Val Acc: 0.680412\n",
      "Epoch 8116 - Train Loss: 0.147796, Train Acc: 0.734615 | Val Loss: 0.161957, Val Acc: 0.680412\n",
      "Epoch 8117 - Train Loss: 0.147785, Train Acc: 0.734615 | Val Loss: 0.161947, Val Acc: 0.680412\n",
      "Epoch 8118 - Train Loss: 0.147774, Train Acc: 0.734615 | Val Loss: 0.161937, Val Acc: 0.680412\n",
      "Epoch 8119 - Train Loss: 0.147763, Train Acc: 0.734615 | Val Loss: 0.161927, Val Acc: 0.680412\n",
      "Epoch 8120 - Train Loss: 0.147752, Train Acc: 0.734615 | Val Loss: 0.161917, Val Acc: 0.680412\n",
      "Epoch 8121 - Train Loss: 0.147741, Train Acc: 0.734615 | Val Loss: 0.161907, Val Acc: 0.680412\n",
      "Epoch 8122 - Train Loss: 0.147730, Train Acc: 0.734615 | Val Loss: 0.161897, Val Acc: 0.680412\n",
      "Epoch 8123 - Train Loss: 0.147719, Train Acc: 0.734615 | Val Loss: 0.161887, Val Acc: 0.680412\n",
      "Epoch 8124 - Train Loss: 0.147708, Train Acc: 0.734615 | Val Loss: 0.161877, Val Acc: 0.680412\n",
      "Epoch 8125 - Train Loss: 0.147697, Train Acc: 0.734615 | Val Loss: 0.161867, Val Acc: 0.680412\n",
      "Epoch 8126 - Train Loss: 0.147686, Train Acc: 0.734615 | Val Loss: 0.161857, Val Acc: 0.680412\n",
      "Epoch 8127 - Train Loss: 0.147675, Train Acc: 0.734615 | Val Loss: 0.161847, Val Acc: 0.680412\n",
      "Epoch 8128 - Train Loss: 0.147664, Train Acc: 0.734615 | Val Loss: 0.161837, Val Acc: 0.680412\n",
      "Epoch 8129 - Train Loss: 0.147653, Train Acc: 0.734615 | Val Loss: 0.161827, Val Acc: 0.680412\n",
      "Epoch 8130 - Train Loss: 0.147642, Train Acc: 0.734615 | Val Loss: 0.161817, Val Acc: 0.680412\n",
      "Epoch 8131 - Train Loss: 0.147631, Train Acc: 0.734615 | Val Loss: 0.161807, Val Acc: 0.680412\n",
      "Epoch 8132 - Train Loss: 0.147620, Train Acc: 0.734615 | Val Loss: 0.161797, Val Acc: 0.680412\n",
      "Epoch 8133 - Train Loss: 0.147609, Train Acc: 0.734615 | Val Loss: 0.161787, Val Acc: 0.680412\n",
      "Epoch 8134 - Train Loss: 0.147598, Train Acc: 0.734615 | Val Loss: 0.161777, Val Acc: 0.680412\n",
      "Epoch 8135 - Train Loss: 0.147587, Train Acc: 0.734615 | Val Loss: 0.161767, Val Acc: 0.680412\n",
      "Epoch 8136 - Train Loss: 0.147576, Train Acc: 0.734615 | Val Loss: 0.161757, Val Acc: 0.680412\n",
      "Epoch 8137 - Train Loss: 0.147565, Train Acc: 0.734615 | Val Loss: 0.161747, Val Acc: 0.680412\n",
      "Epoch 8138 - Train Loss: 0.147554, Train Acc: 0.734615 | Val Loss: 0.161737, Val Acc: 0.680412\n",
      "Epoch 8139 - Train Loss: 0.147543, Train Acc: 0.734615 | Val Loss: 0.161727, Val Acc: 0.680412\n",
      "Epoch 8140 - Train Loss: 0.147532, Train Acc: 0.734615 | Val Loss: 0.161717, Val Acc: 0.680412\n",
      "Epoch 8141 - Train Loss: 0.147521, Train Acc: 0.734615 | Val Loss: 0.161707, Val Acc: 0.680412\n",
      "Epoch 8142 - Train Loss: 0.147510, Train Acc: 0.734615 | Val Loss: 0.161697, Val Acc: 0.680412\n",
      "Epoch 8143 - Train Loss: 0.147499, Train Acc: 0.734615 | Val Loss: 0.161687, Val Acc: 0.680412\n",
      "Epoch 8144 - Train Loss: 0.147488, Train Acc: 0.734615 | Val Loss: 0.161677, Val Acc: 0.680412\n",
      "Epoch 8145 - Train Loss: 0.147477, Train Acc: 0.734615 | Val Loss: 0.161667, Val Acc: 0.680412\n",
      "Epoch 8146 - Train Loss: 0.147466, Train Acc: 0.734615 | Val Loss: 0.161657, Val Acc: 0.680412\n",
      "Epoch 8147 - Train Loss: 0.147455, Train Acc: 0.734615 | Val Loss: 0.161647, Val Acc: 0.680412\n",
      "Epoch 8148 - Train Loss: 0.147444, Train Acc: 0.734615 | Val Loss: 0.161637, Val Acc: 0.680412\n",
      "Epoch 8149 - Train Loss: 0.147433, Train Acc: 0.734615 | Val Loss: 0.161627, Val Acc: 0.680412\n",
      "Epoch 8150 - Train Loss: 0.147422, Train Acc: 0.734615 | Val Loss: 0.161617, Val Acc: 0.680412\n",
      "Epoch 8151 - Train Loss: 0.147412, Train Acc: 0.734615 | Val Loss: 0.161607, Val Acc: 0.680412\n",
      "Epoch 8152 - Train Loss: 0.147401, Train Acc: 0.734615 | Val Loss: 0.161597, Val Acc: 0.680412\n",
      "Epoch 8153 - Train Loss: 0.147390, Train Acc: 0.734615 | Val Loss: 0.161587, Val Acc: 0.680412\n",
      "Epoch 8154 - Train Loss: 0.147379, Train Acc: 0.734615 | Val Loss: 0.161577, Val Acc: 0.680412\n",
      "Epoch 8155 - Train Loss: 0.147368, Train Acc: 0.735897 | Val Loss: 0.161567, Val Acc: 0.680412\n",
      "Epoch 8156 - Train Loss: 0.147357, Train Acc: 0.735897 | Val Loss: 0.161557, Val Acc: 0.680412\n",
      "Epoch 8157 - Train Loss: 0.147346, Train Acc: 0.735897 | Val Loss: 0.161547, Val Acc: 0.680412\n",
      "Epoch 8158 - Train Loss: 0.147335, Train Acc: 0.735897 | Val Loss: 0.161537, Val Acc: 0.690722\n",
      "Epoch 8159 - Train Loss: 0.147324, Train Acc: 0.735897 | Val Loss: 0.161527, Val Acc: 0.690722\n",
      "Epoch 8160 - Train Loss: 0.147313, Train Acc: 0.735897 | Val Loss: 0.161517, Val Acc: 0.690722\n",
      "Epoch 8161 - Train Loss: 0.147302, Train Acc: 0.735897 | Val Loss: 0.161507, Val Acc: 0.690722\n",
      "Epoch 8162 - Train Loss: 0.147291, Train Acc: 0.735897 | Val Loss: 0.161497, Val Acc: 0.690722\n",
      "Epoch 8163 - Train Loss: 0.147280, Train Acc: 0.735897 | Val Loss: 0.161487, Val Acc: 0.690722\n",
      "Epoch 8164 - Train Loss: 0.147269, Train Acc: 0.735897 | Val Loss: 0.161477, Val Acc: 0.690722\n",
      "Epoch 8165 - Train Loss: 0.147258, Train Acc: 0.735897 | Val Loss: 0.161467, Val Acc: 0.690722\n",
      "Epoch 8166 - Train Loss: 0.147247, Train Acc: 0.735897 | Val Loss: 0.161457, Val Acc: 0.690722\n",
      "Epoch 8167 - Train Loss: 0.147236, Train Acc: 0.735897 | Val Loss: 0.161447, Val Acc: 0.690722\n",
      "Epoch 8168 - Train Loss: 0.147226, Train Acc: 0.735897 | Val Loss: 0.161437, Val Acc: 0.690722\n",
      "Epoch 8169 - Train Loss: 0.147215, Train Acc: 0.735897 | Val Loss: 0.161427, Val Acc: 0.690722\n",
      "Epoch 8170 - Train Loss: 0.147204, Train Acc: 0.735897 | Val Loss: 0.161417, Val Acc: 0.690722\n",
      "Epoch 8171 - Train Loss: 0.147193, Train Acc: 0.735897 | Val Loss: 0.161407, Val Acc: 0.690722\n",
      "Epoch 8172 - Train Loss: 0.147182, Train Acc: 0.735897 | Val Loss: 0.161397, Val Acc: 0.690722\n",
      "Epoch 8173 - Train Loss: 0.147171, Train Acc: 0.735897 | Val Loss: 0.161387, Val Acc: 0.690722\n",
      "Epoch 8174 - Train Loss: 0.147160, Train Acc: 0.735897 | Val Loss: 0.161377, Val Acc: 0.690722\n",
      "Epoch 8175 - Train Loss: 0.147149, Train Acc: 0.735897 | Val Loss: 0.161367, Val Acc: 0.690722\n",
      "Epoch 8176 - Train Loss: 0.147138, Train Acc: 0.735897 | Val Loss: 0.161357, Val Acc: 0.690722\n",
      "Epoch 8177 - Train Loss: 0.147127, Train Acc: 0.735897 | Val Loss: 0.161347, Val Acc: 0.690722\n",
      "Epoch 8178 - Train Loss: 0.147116, Train Acc: 0.735897 | Val Loss: 0.161337, Val Acc: 0.690722\n",
      "Epoch 8179 - Train Loss: 0.147105, Train Acc: 0.735897 | Val Loss: 0.161327, Val Acc: 0.690722\n",
      "Epoch 8180 - Train Loss: 0.147095, Train Acc: 0.735897 | Val Loss: 0.161317, Val Acc: 0.690722\n",
      "Epoch 8181 - Train Loss: 0.147084, Train Acc: 0.735897 | Val Loss: 0.161307, Val Acc: 0.690722\n",
      "Epoch 8182 - Train Loss: 0.147073, Train Acc: 0.735897 | Val Loss: 0.161297, Val Acc: 0.690722\n",
      "Epoch 8183 - Train Loss: 0.147062, Train Acc: 0.735897 | Val Loss: 0.161287, Val Acc: 0.690722\n",
      "Epoch 8184 - Train Loss: 0.147051, Train Acc: 0.735897 | Val Loss: 0.161277, Val Acc: 0.690722\n",
      "Epoch 8185 - Train Loss: 0.147040, Train Acc: 0.735897 | Val Loss: 0.161267, Val Acc: 0.690722\n",
      "Epoch 8186 - Train Loss: 0.147029, Train Acc: 0.735897 | Val Loss: 0.161257, Val Acc: 0.690722\n",
      "Epoch 8187 - Train Loss: 0.147018, Train Acc: 0.735897 | Val Loss: 0.161247, Val Acc: 0.690722\n",
      "Epoch 8188 - Train Loss: 0.147007, Train Acc: 0.735897 | Val Loss: 0.161237, Val Acc: 0.690722\n",
      "Epoch 8189 - Train Loss: 0.146996, Train Acc: 0.735897 | Val Loss: 0.161227, Val Acc: 0.690722\n",
      "Epoch 8190 - Train Loss: 0.146985, Train Acc: 0.735897 | Val Loss: 0.161217, Val Acc: 0.690722\n",
      "Epoch 8191 - Train Loss: 0.146975, Train Acc: 0.735897 | Val Loss: 0.161207, Val Acc: 0.690722\n",
      "Epoch 8192 - Train Loss: 0.146964, Train Acc: 0.735897 | Val Loss: 0.161197, Val Acc: 0.690722\n",
      "Epoch 8193 - Train Loss: 0.146953, Train Acc: 0.735897 | Val Loss: 0.161187, Val Acc: 0.690722\n",
      "Epoch 8194 - Train Loss: 0.146942, Train Acc: 0.735897 | Val Loss: 0.161177, Val Acc: 0.690722\n",
      "Epoch 8195 - Train Loss: 0.146931, Train Acc: 0.735897 | Val Loss: 0.161167, Val Acc: 0.690722\n",
      "Epoch 8196 - Train Loss: 0.146920, Train Acc: 0.735897 | Val Loss: 0.161158, Val Acc: 0.690722\n",
      "Epoch 8197 - Train Loss: 0.146909, Train Acc: 0.735897 | Val Loss: 0.161148, Val Acc: 0.690722\n",
      "Epoch 8198 - Train Loss: 0.146898, Train Acc: 0.735897 | Val Loss: 0.161138, Val Acc: 0.690722\n",
      "Epoch 8199 - Train Loss: 0.146887, Train Acc: 0.735897 | Val Loss: 0.161128, Val Acc: 0.690722\n",
      "Epoch 8200 - Train Loss: 0.146877, Train Acc: 0.735897 | Val Loss: 0.161118, Val Acc: 0.690722\n",
      "Epoch 8201 - Train Loss: 0.146866, Train Acc: 0.735897 | Val Loss: 0.161108, Val Acc: 0.690722\n",
      "Epoch 8202 - Train Loss: 0.146855, Train Acc: 0.735897 | Val Loss: 0.161098, Val Acc: 0.690722\n",
      "Epoch 8203 - Train Loss: 0.146844, Train Acc: 0.735897 | Val Loss: 0.161088, Val Acc: 0.690722\n",
      "Epoch 8204 - Train Loss: 0.146833, Train Acc: 0.735897 | Val Loss: 0.161078, Val Acc: 0.690722\n",
      "Epoch 8205 - Train Loss: 0.146822, Train Acc: 0.735897 | Val Loss: 0.161068, Val Acc: 0.690722\n",
      "Epoch 8206 - Train Loss: 0.146811, Train Acc: 0.735897 | Val Loss: 0.161058, Val Acc: 0.690722\n",
      "Epoch 8207 - Train Loss: 0.146800, Train Acc: 0.735897 | Val Loss: 0.161048, Val Acc: 0.690722\n",
      "Epoch 8208 - Train Loss: 0.146789, Train Acc: 0.735897 | Val Loss: 0.161038, Val Acc: 0.690722\n",
      "Epoch 8209 - Train Loss: 0.146779, Train Acc: 0.735897 | Val Loss: 0.161028, Val Acc: 0.690722\n",
      "Epoch 8210 - Train Loss: 0.146768, Train Acc: 0.735897 | Val Loss: 0.161019, Val Acc: 0.690722\n",
      "Epoch 8211 - Train Loss: 0.146757, Train Acc: 0.735897 | Val Loss: 0.161009, Val Acc: 0.690722\n",
      "Epoch 8212 - Train Loss: 0.146746, Train Acc: 0.735897 | Val Loss: 0.160999, Val Acc: 0.690722\n",
      "Epoch 8213 - Train Loss: 0.146735, Train Acc: 0.735897 | Val Loss: 0.160989, Val Acc: 0.690722\n",
      "Epoch 8214 - Train Loss: 0.146724, Train Acc: 0.735897 | Val Loss: 0.160979, Val Acc: 0.690722\n",
      "Epoch 8215 - Train Loss: 0.146713, Train Acc: 0.735897 | Val Loss: 0.160969, Val Acc: 0.690722\n",
      "Epoch 8216 - Train Loss: 0.146702, Train Acc: 0.735897 | Val Loss: 0.160959, Val Acc: 0.690722\n",
      "Epoch 8217 - Train Loss: 0.146692, Train Acc: 0.735897 | Val Loss: 0.160949, Val Acc: 0.690722\n",
      "Epoch 8218 - Train Loss: 0.146681, Train Acc: 0.735897 | Val Loss: 0.160939, Val Acc: 0.690722\n",
      "Epoch 8219 - Train Loss: 0.146670, Train Acc: 0.735897 | Val Loss: 0.160929, Val Acc: 0.690722\n",
      "Epoch 8220 - Train Loss: 0.146659, Train Acc: 0.735897 | Val Loss: 0.160919, Val Acc: 0.690722\n",
      "Epoch 8221 - Train Loss: 0.146648, Train Acc: 0.735897 | Val Loss: 0.160910, Val Acc: 0.690722\n",
      "Epoch 8222 - Train Loss: 0.146637, Train Acc: 0.735897 | Val Loss: 0.160900, Val Acc: 0.690722\n",
      "Epoch 8223 - Train Loss: 0.146626, Train Acc: 0.735897 | Val Loss: 0.160890, Val Acc: 0.690722\n",
      "Epoch 8224 - Train Loss: 0.146616, Train Acc: 0.735897 | Val Loss: 0.160880, Val Acc: 0.690722\n",
      "Epoch 8225 - Train Loss: 0.146605, Train Acc: 0.735897 | Val Loss: 0.160870, Val Acc: 0.690722\n",
      "Epoch 8226 - Train Loss: 0.146594, Train Acc: 0.735897 | Val Loss: 0.160860, Val Acc: 0.690722\n",
      "Epoch 8227 - Train Loss: 0.146583, Train Acc: 0.735897 | Val Loss: 0.160850, Val Acc: 0.690722\n",
      "Epoch 8228 - Train Loss: 0.146572, Train Acc: 0.735897 | Val Loss: 0.160840, Val Acc: 0.690722\n",
      "Epoch 8229 - Train Loss: 0.146561, Train Acc: 0.735897 | Val Loss: 0.160830, Val Acc: 0.690722\n",
      "Epoch 8230 - Train Loss: 0.146551, Train Acc: 0.735897 | Val Loss: 0.160821, Val Acc: 0.690722\n",
      "Epoch 8231 - Train Loss: 0.146540, Train Acc: 0.735897 | Val Loss: 0.160811, Val Acc: 0.690722\n",
      "Epoch 8232 - Train Loss: 0.146529, Train Acc: 0.735897 | Val Loss: 0.160801, Val Acc: 0.690722\n",
      "Epoch 8233 - Train Loss: 0.146518, Train Acc: 0.735897 | Val Loss: 0.160791, Val Acc: 0.690722\n",
      "Epoch 8234 - Train Loss: 0.146507, Train Acc: 0.735897 | Val Loss: 0.160781, Val Acc: 0.690722\n",
      "Epoch 8235 - Train Loss: 0.146496, Train Acc: 0.735897 | Val Loss: 0.160771, Val Acc: 0.690722\n",
      "Epoch 8236 - Train Loss: 0.146485, Train Acc: 0.735897 | Val Loss: 0.160761, Val Acc: 0.690722\n",
      "Epoch 8237 - Train Loss: 0.146475, Train Acc: 0.735897 | Val Loss: 0.160751, Val Acc: 0.690722\n",
      "Epoch 8238 - Train Loss: 0.146464, Train Acc: 0.735897 | Val Loss: 0.160741, Val Acc: 0.690722\n",
      "Epoch 8239 - Train Loss: 0.146453, Train Acc: 0.735897 | Val Loss: 0.160732, Val Acc: 0.690722\n",
      "Epoch 8240 - Train Loss: 0.146442, Train Acc: 0.735897 | Val Loss: 0.160722, Val Acc: 0.690722\n",
      "Epoch 8241 - Train Loss: 0.146431, Train Acc: 0.735897 | Val Loss: 0.160712, Val Acc: 0.690722\n",
      "Epoch 8242 - Train Loss: 0.146420, Train Acc: 0.735897 | Val Loss: 0.160702, Val Acc: 0.690722\n",
      "Epoch 8243 - Train Loss: 0.146410, Train Acc: 0.735897 | Val Loss: 0.160692, Val Acc: 0.690722\n",
      "Epoch 8244 - Train Loss: 0.146399, Train Acc: 0.735897 | Val Loss: 0.160682, Val Acc: 0.690722\n",
      "Epoch 8245 - Train Loss: 0.146388, Train Acc: 0.737179 | Val Loss: 0.160672, Val Acc: 0.690722\n",
      "Epoch 8246 - Train Loss: 0.146377, Train Acc: 0.737179 | Val Loss: 0.160663, Val Acc: 0.690722\n",
      "Epoch 8247 - Train Loss: 0.146366, Train Acc: 0.737179 | Val Loss: 0.160653, Val Acc: 0.690722\n",
      "Epoch 8248 - Train Loss: 0.146355, Train Acc: 0.737179 | Val Loss: 0.160643, Val Acc: 0.690722\n",
      "Epoch 8249 - Train Loss: 0.146345, Train Acc: 0.737179 | Val Loss: 0.160633, Val Acc: 0.690722\n",
      "Epoch 8250 - Train Loss: 0.146334, Train Acc: 0.737179 | Val Loss: 0.160623, Val Acc: 0.690722\n",
      "Epoch 8251 - Train Loss: 0.146323, Train Acc: 0.737179 | Val Loss: 0.160613, Val Acc: 0.690722\n",
      "Epoch 8252 - Train Loss: 0.146312, Train Acc: 0.737179 | Val Loss: 0.160603, Val Acc: 0.690722\n",
      "Epoch 8253 - Train Loss: 0.146301, Train Acc: 0.737179 | Val Loss: 0.160594, Val Acc: 0.690722\n",
      "Epoch 8254 - Train Loss: 0.146291, Train Acc: 0.737179 | Val Loss: 0.160584, Val Acc: 0.701031\n",
      "Epoch 8255 - Train Loss: 0.146280, Train Acc: 0.737179 | Val Loss: 0.160574, Val Acc: 0.701031\n",
      "Epoch 8256 - Train Loss: 0.146269, Train Acc: 0.737179 | Val Loss: 0.160564, Val Acc: 0.701031\n",
      "Epoch 8257 - Train Loss: 0.146258, Train Acc: 0.737179 | Val Loss: 0.160554, Val Acc: 0.701031\n",
      "Epoch 8258 - Train Loss: 0.146247, Train Acc: 0.737179 | Val Loss: 0.160544, Val Acc: 0.701031\n",
      "Epoch 8259 - Train Loss: 0.146236, Train Acc: 0.737179 | Val Loss: 0.160535, Val Acc: 0.701031\n",
      "Epoch 8260 - Train Loss: 0.146226, Train Acc: 0.737179 | Val Loss: 0.160525, Val Acc: 0.701031\n",
      "Epoch 8261 - Train Loss: 0.146215, Train Acc: 0.737179 | Val Loss: 0.160515, Val Acc: 0.701031\n",
      "Epoch 8262 - Train Loss: 0.146204, Train Acc: 0.737179 | Val Loss: 0.160505, Val Acc: 0.701031\n",
      "Epoch 8263 - Train Loss: 0.146193, Train Acc: 0.737179 | Val Loss: 0.160495, Val Acc: 0.701031\n",
      "Epoch 8264 - Train Loss: 0.146182, Train Acc: 0.737179 | Val Loss: 0.160486, Val Acc: 0.701031\n",
      "Epoch 8265 - Train Loss: 0.146172, Train Acc: 0.737179 | Val Loss: 0.160476, Val Acc: 0.701031\n",
      "Epoch 8266 - Train Loss: 0.146161, Train Acc: 0.737179 | Val Loss: 0.160466, Val Acc: 0.701031\n",
      "Epoch 8267 - Train Loss: 0.146150, Train Acc: 0.737179 | Val Loss: 0.160456, Val Acc: 0.701031\n",
      "Epoch 8268 - Train Loss: 0.146139, Train Acc: 0.737179 | Val Loss: 0.160446, Val Acc: 0.701031\n",
      "Epoch 8269 - Train Loss: 0.146128, Train Acc: 0.737179 | Val Loss: 0.160437, Val Acc: 0.701031\n",
      "Epoch 8270 - Train Loss: 0.146118, Train Acc: 0.737179 | Val Loss: 0.160427, Val Acc: 0.701031\n",
      "Epoch 8271 - Train Loss: 0.146107, Train Acc: 0.737179 | Val Loss: 0.160417, Val Acc: 0.701031\n",
      "Epoch 8272 - Train Loss: 0.146096, Train Acc: 0.737179 | Val Loss: 0.160407, Val Acc: 0.701031\n",
      "Epoch 8273 - Train Loss: 0.146085, Train Acc: 0.737179 | Val Loss: 0.160397, Val Acc: 0.701031\n",
      "Epoch 8274 - Train Loss: 0.146075, Train Acc: 0.737179 | Val Loss: 0.160388, Val Acc: 0.701031\n",
      "Epoch 8275 - Train Loss: 0.146064, Train Acc: 0.737179 | Val Loss: 0.160378, Val Acc: 0.701031\n",
      "Epoch 8276 - Train Loss: 0.146053, Train Acc: 0.737179 | Val Loss: 0.160368, Val Acc: 0.701031\n",
      "Epoch 8277 - Train Loss: 0.146042, Train Acc: 0.737179 | Val Loss: 0.160358, Val Acc: 0.701031\n",
      "Epoch 8278 - Train Loss: 0.146031, Train Acc: 0.737179 | Val Loss: 0.160348, Val Acc: 0.701031\n",
      "Epoch 8279 - Train Loss: 0.146021, Train Acc: 0.737179 | Val Loss: 0.160339, Val Acc: 0.701031\n",
      "Epoch 8280 - Train Loss: 0.146010, Train Acc: 0.737179 | Val Loss: 0.160329, Val Acc: 0.701031\n",
      "Epoch 8281 - Train Loss: 0.145999, Train Acc: 0.737179 | Val Loss: 0.160319, Val Acc: 0.701031\n",
      "Epoch 8282 - Train Loss: 0.145988, Train Acc: 0.738462 | Val Loss: 0.160309, Val Acc: 0.701031\n",
      "Epoch 8283 - Train Loss: 0.145978, Train Acc: 0.738462 | Val Loss: 0.160300, Val Acc: 0.701031\n",
      "Epoch 8284 - Train Loss: 0.145967, Train Acc: 0.738462 | Val Loss: 0.160290, Val Acc: 0.701031\n",
      "Epoch 8285 - Train Loss: 0.145956, Train Acc: 0.739744 | Val Loss: 0.160280, Val Acc: 0.701031\n",
      "Epoch 8286 - Train Loss: 0.145945, Train Acc: 0.739744 | Val Loss: 0.160270, Val Acc: 0.701031\n",
      "Epoch 8287 - Train Loss: 0.145934, Train Acc: 0.739744 | Val Loss: 0.160260, Val Acc: 0.701031\n",
      "Epoch 8288 - Train Loss: 0.145924, Train Acc: 0.739744 | Val Loss: 0.160251, Val Acc: 0.701031\n",
      "Epoch 8289 - Train Loss: 0.145913, Train Acc: 0.739744 | Val Loss: 0.160241, Val Acc: 0.701031\n",
      "Epoch 8290 - Train Loss: 0.145902, Train Acc: 0.739744 | Val Loss: 0.160231, Val Acc: 0.701031\n",
      "Epoch 8291 - Train Loss: 0.145891, Train Acc: 0.739744 | Val Loss: 0.160221, Val Acc: 0.701031\n",
      "Epoch 8292 - Train Loss: 0.145881, Train Acc: 0.739744 | Val Loss: 0.160211, Val Acc: 0.701031\n",
      "Epoch 8293 - Train Loss: 0.145870, Train Acc: 0.739744 | Val Loss: 0.160202, Val Acc: 0.701031\n",
      "Epoch 8294 - Train Loss: 0.145859, Train Acc: 0.739744 | Val Loss: 0.160192, Val Acc: 0.701031\n",
      "Epoch 8295 - Train Loss: 0.145848, Train Acc: 0.739744 | Val Loss: 0.160182, Val Acc: 0.701031\n",
      "Epoch 8296 - Train Loss: 0.145838, Train Acc: 0.739744 | Val Loss: 0.160172, Val Acc: 0.701031\n",
      "Epoch 8297 - Train Loss: 0.145827, Train Acc: 0.739744 | Val Loss: 0.160163, Val Acc: 0.701031\n",
      "Epoch 8298 - Train Loss: 0.145816, Train Acc: 0.739744 | Val Loss: 0.160153, Val Acc: 0.701031\n",
      "Epoch 8299 - Train Loss: 0.145805, Train Acc: 0.739744 | Val Loss: 0.160143, Val Acc: 0.711340\n",
      "Epoch 8300 - Train Loss: 0.145795, Train Acc: 0.739744 | Val Loss: 0.160133, Val Acc: 0.711340\n",
      "Epoch 8301 - Train Loss: 0.145784, Train Acc: 0.739744 | Val Loss: 0.160123, Val Acc: 0.711340\n",
      "Epoch 8302 - Train Loss: 0.145773, Train Acc: 0.739744 | Val Loss: 0.160114, Val Acc: 0.711340\n",
      "Epoch 8303 - Train Loss: 0.145762, Train Acc: 0.739744 | Val Loss: 0.160104, Val Acc: 0.711340\n",
      "Epoch 8304 - Train Loss: 0.145752, Train Acc: 0.739744 | Val Loss: 0.160094, Val Acc: 0.711340\n",
      "Epoch 8305 - Train Loss: 0.145741, Train Acc: 0.739744 | Val Loss: 0.160084, Val Acc: 0.711340\n",
      "Epoch 8306 - Train Loss: 0.145730, Train Acc: 0.739744 | Val Loss: 0.160075, Val Acc: 0.711340\n",
      "Epoch 8307 - Train Loss: 0.145719, Train Acc: 0.739744 | Val Loss: 0.160065, Val Acc: 0.711340\n",
      "Epoch 8308 - Train Loss: 0.145709, Train Acc: 0.739744 | Val Loss: 0.160055, Val Acc: 0.711340\n",
      "Epoch 8309 - Train Loss: 0.145698, Train Acc: 0.739744 | Val Loss: 0.160045, Val Acc: 0.711340\n",
      "Epoch 8310 - Train Loss: 0.145687, Train Acc: 0.739744 | Val Loss: 0.160036, Val Acc: 0.711340\n",
      "Epoch 8311 - Train Loss: 0.145676, Train Acc: 0.739744 | Val Loss: 0.160026, Val Acc: 0.711340\n",
      "Epoch 8312 - Train Loss: 0.145666, Train Acc: 0.739744 | Val Loss: 0.160016, Val Acc: 0.711340\n",
      "Epoch 8313 - Train Loss: 0.145655, Train Acc: 0.739744 | Val Loss: 0.160006, Val Acc: 0.711340\n",
      "Epoch 8314 - Train Loss: 0.145644, Train Acc: 0.739744 | Val Loss: 0.159997, Val Acc: 0.711340\n",
      "Epoch 8315 - Train Loss: 0.145633, Train Acc: 0.739744 | Val Loss: 0.159987, Val Acc: 0.711340\n",
      "Epoch 8316 - Train Loss: 0.145623, Train Acc: 0.739744 | Val Loss: 0.159977, Val Acc: 0.711340\n",
      "Epoch 8317 - Train Loss: 0.145612, Train Acc: 0.739744 | Val Loss: 0.159967, Val Acc: 0.711340\n",
      "Epoch 8318 - Train Loss: 0.145601, Train Acc: 0.739744 | Val Loss: 0.159958, Val Acc: 0.711340\n",
      "Epoch 8319 - Train Loss: 0.145590, Train Acc: 0.739744 | Val Loss: 0.159948, Val Acc: 0.711340\n",
      "Epoch 8320 - Train Loss: 0.145580, Train Acc: 0.739744 | Val Loss: 0.159938, Val Acc: 0.711340\n",
      "Epoch 8321 - Train Loss: 0.145569, Train Acc: 0.739744 | Val Loss: 0.159928, Val Acc: 0.711340\n",
      "Epoch 8322 - Train Loss: 0.145558, Train Acc: 0.739744 | Val Loss: 0.159919, Val Acc: 0.711340\n",
      "Epoch 8323 - Train Loss: 0.145548, Train Acc: 0.739744 | Val Loss: 0.159909, Val Acc: 0.711340\n",
      "Epoch 8324 - Train Loss: 0.145537, Train Acc: 0.741026 | Val Loss: 0.159899, Val Acc: 0.711340\n",
      "Epoch 8325 - Train Loss: 0.145526, Train Acc: 0.741026 | Val Loss: 0.159889, Val Acc: 0.711340\n",
      "Epoch 8326 - Train Loss: 0.145515, Train Acc: 0.742308 | Val Loss: 0.159880, Val Acc: 0.711340\n",
      "Epoch 8327 - Train Loss: 0.145505, Train Acc: 0.742308 | Val Loss: 0.159870, Val Acc: 0.711340\n",
      "Epoch 8328 - Train Loss: 0.145494, Train Acc: 0.742308 | Val Loss: 0.159860, Val Acc: 0.711340\n",
      "Epoch 8329 - Train Loss: 0.145483, Train Acc: 0.742308 | Val Loss: 0.159850, Val Acc: 0.711340\n",
      "Epoch 8330 - Train Loss: 0.145473, Train Acc: 0.742308 | Val Loss: 0.159841, Val Acc: 0.711340\n",
      "Epoch 8331 - Train Loss: 0.145462, Train Acc: 0.742308 | Val Loss: 0.159831, Val Acc: 0.711340\n",
      "Epoch 8332 - Train Loss: 0.145451, Train Acc: 0.742308 | Val Loss: 0.159821, Val Acc: 0.711340\n",
      "Epoch 8333 - Train Loss: 0.145440, Train Acc: 0.742308 | Val Loss: 0.159812, Val Acc: 0.711340\n",
      "Epoch 8334 - Train Loss: 0.145430, Train Acc: 0.742308 | Val Loss: 0.159802, Val Acc: 0.711340\n",
      "Epoch 8335 - Train Loss: 0.145419, Train Acc: 0.742308 | Val Loss: 0.159792, Val Acc: 0.711340\n",
      "Epoch 8336 - Train Loss: 0.145408, Train Acc: 0.742308 | Val Loss: 0.159782, Val Acc: 0.711340\n",
      "Epoch 8337 - Train Loss: 0.145398, Train Acc: 0.742308 | Val Loss: 0.159773, Val Acc: 0.711340\n",
      "Epoch 8338 - Train Loss: 0.145387, Train Acc: 0.742308 | Val Loss: 0.159763, Val Acc: 0.711340\n",
      "Epoch 8339 - Train Loss: 0.145376, Train Acc: 0.742308 | Val Loss: 0.159753, Val Acc: 0.711340\n",
      "Epoch 8340 - Train Loss: 0.145366, Train Acc: 0.742308 | Val Loss: 0.159744, Val Acc: 0.711340\n",
      "Epoch 8341 - Train Loss: 0.145355, Train Acc: 0.742308 | Val Loss: 0.159734, Val Acc: 0.711340\n",
      "Epoch 8342 - Train Loss: 0.145344, Train Acc: 0.742308 | Val Loss: 0.159724, Val Acc: 0.711340\n",
      "Epoch 8343 - Train Loss: 0.145333, Train Acc: 0.742308 | Val Loss: 0.159714, Val Acc: 0.711340\n",
      "Epoch 8344 - Train Loss: 0.145323, Train Acc: 0.742308 | Val Loss: 0.159705, Val Acc: 0.711340\n",
      "Epoch 8345 - Train Loss: 0.145312, Train Acc: 0.742308 | Val Loss: 0.159695, Val Acc: 0.721649\n",
      "Epoch 8346 - Train Loss: 0.145301, Train Acc: 0.742308 | Val Loss: 0.159685, Val Acc: 0.721649\n",
      "Epoch 8347 - Train Loss: 0.145291, Train Acc: 0.742308 | Val Loss: 0.159676, Val Acc: 0.721649\n",
      "Epoch 8348 - Train Loss: 0.145280, Train Acc: 0.742308 | Val Loss: 0.159666, Val Acc: 0.721649\n",
      "Epoch 8349 - Train Loss: 0.145269, Train Acc: 0.742308 | Val Loss: 0.159656, Val Acc: 0.721649\n",
      "Epoch 8350 - Train Loss: 0.145259, Train Acc: 0.742308 | Val Loss: 0.159647, Val Acc: 0.721649\n",
      "Epoch 8351 - Train Loss: 0.145248, Train Acc: 0.742308 | Val Loss: 0.159637, Val Acc: 0.721649\n",
      "Epoch 8352 - Train Loss: 0.145237, Train Acc: 0.742308 | Val Loss: 0.159627, Val Acc: 0.721649\n",
      "Epoch 8353 - Train Loss: 0.145227, Train Acc: 0.742308 | Val Loss: 0.159617, Val Acc: 0.721649\n",
      "Epoch 8354 - Train Loss: 0.145216, Train Acc: 0.742308 | Val Loss: 0.159608, Val Acc: 0.721649\n",
      "Epoch 8355 - Train Loss: 0.145205, Train Acc: 0.742308 | Val Loss: 0.159598, Val Acc: 0.721649\n",
      "Epoch 8356 - Train Loss: 0.145194, Train Acc: 0.742308 | Val Loss: 0.159588, Val Acc: 0.721649\n",
      "Epoch 8357 - Train Loss: 0.145184, Train Acc: 0.742308 | Val Loss: 0.159579, Val Acc: 0.721649\n",
      "Epoch 8358 - Train Loss: 0.145173, Train Acc: 0.742308 | Val Loss: 0.159569, Val Acc: 0.721649\n",
      "Epoch 8359 - Train Loss: 0.145162, Train Acc: 0.742308 | Val Loss: 0.159559, Val Acc: 0.721649\n",
      "Epoch 8360 - Train Loss: 0.145152, Train Acc: 0.742308 | Val Loss: 0.159550, Val Acc: 0.721649\n",
      "Epoch 8361 - Train Loss: 0.145141, Train Acc: 0.742308 | Val Loss: 0.159540, Val Acc: 0.721649\n",
      "Epoch 8362 - Train Loss: 0.145130, Train Acc: 0.742308 | Val Loss: 0.159530, Val Acc: 0.721649\n",
      "Epoch 8363 - Train Loss: 0.145120, Train Acc: 0.742308 | Val Loss: 0.159520, Val Acc: 0.721649\n",
      "Epoch 8364 - Train Loss: 0.145109, Train Acc: 0.742308 | Val Loss: 0.159511, Val Acc: 0.721649\n",
      "Epoch 8365 - Train Loss: 0.145098, Train Acc: 0.742308 | Val Loss: 0.159501, Val Acc: 0.721649\n",
      "Epoch 8366 - Train Loss: 0.145088, Train Acc: 0.742308 | Val Loss: 0.159491, Val Acc: 0.721649\n",
      "Epoch 8367 - Train Loss: 0.145077, Train Acc: 0.742308 | Val Loss: 0.159482, Val Acc: 0.721649\n",
      "Epoch 8368 - Train Loss: 0.145066, Train Acc: 0.742308 | Val Loss: 0.159472, Val Acc: 0.721649\n",
      "Epoch 8369 - Train Loss: 0.145056, Train Acc: 0.742308 | Val Loss: 0.159462, Val Acc: 0.721649\n",
      "Epoch 8370 - Train Loss: 0.145045, Train Acc: 0.742308 | Val Loss: 0.159453, Val Acc: 0.721649\n",
      "Epoch 8371 - Train Loss: 0.145034, Train Acc: 0.742308 | Val Loss: 0.159443, Val Acc: 0.721649\n",
      "Epoch 8372 - Train Loss: 0.145024, Train Acc: 0.742308 | Val Loss: 0.159433, Val Acc: 0.721649\n",
      "Epoch 8373 - Train Loss: 0.145013, Train Acc: 0.742308 | Val Loss: 0.159424, Val Acc: 0.721649\n",
      "Epoch 8374 - Train Loss: 0.145002, Train Acc: 0.742308 | Val Loss: 0.159414, Val Acc: 0.721649\n",
      "Epoch 8375 - Train Loss: 0.144992, Train Acc: 0.742308 | Val Loss: 0.159405, Val Acc: 0.721649\n",
      "Epoch 8376 - Train Loss: 0.144981, Train Acc: 0.742308 | Val Loss: 0.159395, Val Acc: 0.721649\n",
      "Epoch 8377 - Train Loss: 0.144971, Train Acc: 0.742308 | Val Loss: 0.159385, Val Acc: 0.721649\n",
      "Epoch 8378 - Train Loss: 0.144960, Train Acc: 0.742308 | Val Loss: 0.159376, Val Acc: 0.721649\n",
      "Epoch 8379 - Train Loss: 0.144949, Train Acc: 0.742308 | Val Loss: 0.159366, Val Acc: 0.721649\n",
      "Epoch 8380 - Train Loss: 0.144939, Train Acc: 0.742308 | Val Loss: 0.159356, Val Acc: 0.721649\n",
      "Epoch 8381 - Train Loss: 0.144928, Train Acc: 0.742308 | Val Loss: 0.159347, Val Acc: 0.721649\n",
      "Epoch 8382 - Train Loss: 0.144917, Train Acc: 0.742308 | Val Loss: 0.159337, Val Acc: 0.721649\n",
      "Epoch 8383 - Train Loss: 0.144907, Train Acc: 0.742308 | Val Loss: 0.159328, Val Acc: 0.721649\n",
      "Epoch 8384 - Train Loss: 0.144896, Train Acc: 0.742308 | Val Loss: 0.159318, Val Acc: 0.721649\n",
      "Epoch 8385 - Train Loss: 0.144885, Train Acc: 0.742308 | Val Loss: 0.159308, Val Acc: 0.721649\n",
      "Epoch 8386 - Train Loss: 0.144875, Train Acc: 0.742308 | Val Loss: 0.159299, Val Acc: 0.721649\n",
      "Epoch 8387 - Train Loss: 0.144864, Train Acc: 0.742308 | Val Loss: 0.159289, Val Acc: 0.721649\n",
      "Epoch 8388 - Train Loss: 0.144853, Train Acc: 0.742308 | Val Loss: 0.159279, Val Acc: 0.721649\n",
      "Epoch 8389 - Train Loss: 0.144843, Train Acc: 0.742308 | Val Loss: 0.159270, Val Acc: 0.721649\n",
      "Epoch 8390 - Train Loss: 0.144832, Train Acc: 0.742308 | Val Loss: 0.159260, Val Acc: 0.721649\n",
      "Epoch 8391 - Train Loss: 0.144822, Train Acc: 0.742308 | Val Loss: 0.159251, Val Acc: 0.721649\n",
      "Epoch 8392 - Train Loss: 0.144811, Train Acc: 0.742308 | Val Loss: 0.159241, Val Acc: 0.721649\n",
      "Epoch 8393 - Train Loss: 0.144800, Train Acc: 0.742308 | Val Loss: 0.159231, Val Acc: 0.721649\n",
      "Epoch 8394 - Train Loss: 0.144790, Train Acc: 0.742308 | Val Loss: 0.159222, Val Acc: 0.721649\n",
      "Epoch 8395 - Train Loss: 0.144779, Train Acc: 0.742308 | Val Loss: 0.159212, Val Acc: 0.721649\n",
      "Epoch 8396 - Train Loss: 0.144768, Train Acc: 0.742308 | Val Loss: 0.159202, Val Acc: 0.721649\n",
      "Epoch 8397 - Train Loss: 0.144758, Train Acc: 0.742308 | Val Loss: 0.159193, Val Acc: 0.721649\n",
      "Epoch 8398 - Train Loss: 0.144747, Train Acc: 0.742308 | Val Loss: 0.159183, Val Acc: 0.721649\n",
      "Epoch 8399 - Train Loss: 0.144737, Train Acc: 0.742308 | Val Loss: 0.159174, Val Acc: 0.721649\n",
      "Epoch 8400 - Train Loss: 0.144726, Train Acc: 0.742308 | Val Loss: 0.159164, Val Acc: 0.721649\n",
      "Epoch 8401 - Train Loss: 0.144715, Train Acc: 0.742308 | Val Loss: 0.159154, Val Acc: 0.721649\n",
      "Epoch 8402 - Train Loss: 0.144705, Train Acc: 0.742308 | Val Loss: 0.159145, Val Acc: 0.721649\n",
      "Epoch 8403 - Train Loss: 0.144694, Train Acc: 0.742308 | Val Loss: 0.159135, Val Acc: 0.721649\n",
      "Epoch 8404 - Train Loss: 0.144684, Train Acc: 0.742308 | Val Loss: 0.159125, Val Acc: 0.721649\n",
      "Epoch 8405 - Train Loss: 0.144673, Train Acc: 0.742308 | Val Loss: 0.159116, Val Acc: 0.721649\n",
      "Epoch 8406 - Train Loss: 0.144662, Train Acc: 0.742308 | Val Loss: 0.159106, Val Acc: 0.721649\n",
      "Epoch 8407 - Train Loss: 0.144652, Train Acc: 0.742308 | Val Loss: 0.159097, Val Acc: 0.721649\n",
      "Epoch 8408 - Train Loss: 0.144641, Train Acc: 0.742308 | Val Loss: 0.159087, Val Acc: 0.721649\n",
      "Epoch 8409 - Train Loss: 0.144630, Train Acc: 0.742308 | Val Loss: 0.159077, Val Acc: 0.721649\n",
      "Epoch 8410 - Train Loss: 0.144620, Train Acc: 0.742308 | Val Loss: 0.159068, Val Acc: 0.721649\n",
      "Epoch 8411 - Train Loss: 0.144609, Train Acc: 0.742308 | Val Loss: 0.159058, Val Acc: 0.721649\n",
      "Epoch 8412 - Train Loss: 0.144599, Train Acc: 0.742308 | Val Loss: 0.159049, Val Acc: 0.721649\n",
      "Epoch 8413 - Train Loss: 0.144588, Train Acc: 0.742308 | Val Loss: 0.159039, Val Acc: 0.721649\n",
      "Epoch 8414 - Train Loss: 0.144577, Train Acc: 0.742308 | Val Loss: 0.159029, Val Acc: 0.721649\n",
      "Epoch 8415 - Train Loss: 0.144567, Train Acc: 0.742308 | Val Loss: 0.159020, Val Acc: 0.721649\n",
      "Epoch 8416 - Train Loss: 0.144556, Train Acc: 0.742308 | Val Loss: 0.159010, Val Acc: 0.721649\n",
      "Epoch 8417 - Train Loss: 0.144546, Train Acc: 0.742308 | Val Loss: 0.159001, Val Acc: 0.721649\n",
      "Epoch 8418 - Train Loss: 0.144535, Train Acc: 0.742308 | Val Loss: 0.158991, Val Acc: 0.721649\n",
      "Epoch 8419 - Train Loss: 0.144525, Train Acc: 0.742308 | Val Loss: 0.158981, Val Acc: 0.721649\n",
      "Epoch 8420 - Train Loss: 0.144514, Train Acc: 0.742308 | Val Loss: 0.158972, Val Acc: 0.721649\n",
      "Epoch 8421 - Train Loss: 0.144503, Train Acc: 0.742308 | Val Loss: 0.158962, Val Acc: 0.721649\n",
      "Epoch 8422 - Train Loss: 0.144493, Train Acc: 0.742308 | Val Loss: 0.158953, Val Acc: 0.721649\n",
      "Epoch 8423 - Train Loss: 0.144482, Train Acc: 0.742308 | Val Loss: 0.158943, Val Acc: 0.721649\n",
      "Epoch 8424 - Train Loss: 0.144472, Train Acc: 0.742308 | Val Loss: 0.158934, Val Acc: 0.721649\n",
      "Epoch 8425 - Train Loss: 0.144461, Train Acc: 0.742308 | Val Loss: 0.158924, Val Acc: 0.721649\n",
      "Epoch 8426 - Train Loss: 0.144450, Train Acc: 0.742308 | Val Loss: 0.158914, Val Acc: 0.721649\n",
      "Epoch 8427 - Train Loss: 0.144440, Train Acc: 0.742308 | Val Loss: 0.158905, Val Acc: 0.721649\n",
      "Epoch 8428 - Train Loss: 0.144429, Train Acc: 0.742308 | Val Loss: 0.158895, Val Acc: 0.721649\n",
      "Epoch 8429 - Train Loss: 0.144419, Train Acc: 0.742308 | Val Loss: 0.158886, Val Acc: 0.721649\n",
      "Epoch 8430 - Train Loss: 0.144408, Train Acc: 0.742308 | Val Loss: 0.158876, Val Acc: 0.721649\n",
      "Epoch 8431 - Train Loss: 0.144398, Train Acc: 0.742308 | Val Loss: 0.158866, Val Acc: 0.721649\n",
      "Epoch 8432 - Train Loss: 0.144387, Train Acc: 0.742308 | Val Loss: 0.158857, Val Acc: 0.721649\n",
      "Epoch 8433 - Train Loss: 0.144376, Train Acc: 0.742308 | Val Loss: 0.158847, Val Acc: 0.721649\n",
      "Epoch 8434 - Train Loss: 0.144366, Train Acc: 0.742308 | Val Loss: 0.158838, Val Acc: 0.721649\n",
      "Epoch 8435 - Train Loss: 0.144355, Train Acc: 0.742308 | Val Loss: 0.158828, Val Acc: 0.721649\n",
      "Epoch 8436 - Train Loss: 0.144345, Train Acc: 0.742308 | Val Loss: 0.158818, Val Acc: 0.721649\n",
      "Epoch 8437 - Train Loss: 0.144334, Train Acc: 0.742308 | Val Loss: 0.158809, Val Acc: 0.721649\n",
      "Epoch 8438 - Train Loss: 0.144323, Train Acc: 0.742308 | Val Loss: 0.158799, Val Acc: 0.721649\n",
      "Epoch 8439 - Train Loss: 0.144313, Train Acc: 0.742308 | Val Loss: 0.158789, Val Acc: 0.721649\n",
      "Epoch 8440 - Train Loss: 0.144302, Train Acc: 0.742308 | Val Loss: 0.158779, Val Acc: 0.721649\n",
      "Epoch 8441 - Train Loss: 0.144292, Train Acc: 0.742308 | Val Loss: 0.158770, Val Acc: 0.721649\n",
      "Epoch 8442 - Train Loss: 0.144281, Train Acc: 0.742308 | Val Loss: 0.158760, Val Acc: 0.721649\n",
      "Epoch 8443 - Train Loss: 0.144270, Train Acc: 0.742308 | Val Loss: 0.158750, Val Acc: 0.721649\n",
      "Epoch 8444 - Train Loss: 0.144260, Train Acc: 0.742308 | Val Loss: 0.158741, Val Acc: 0.721649\n",
      "Epoch 8445 - Train Loss: 0.144249, Train Acc: 0.742308 | Val Loss: 0.158731, Val Acc: 0.721649\n",
      "Epoch 8446 - Train Loss: 0.144239, Train Acc: 0.742308 | Val Loss: 0.158721, Val Acc: 0.721649\n",
      "Epoch 8447 - Train Loss: 0.144228, Train Acc: 0.742308 | Val Loss: 0.158711, Val Acc: 0.721649\n",
      "Epoch 8448 - Train Loss: 0.144217, Train Acc: 0.742308 | Val Loss: 0.158702, Val Acc: 0.721649\n",
      "Epoch 8449 - Train Loss: 0.144207, Train Acc: 0.742308 | Val Loss: 0.158692, Val Acc: 0.721649\n",
      "Epoch 8450 - Train Loss: 0.144196, Train Acc: 0.742308 | Val Loss: 0.158682, Val Acc: 0.721649\n",
      "Epoch 8451 - Train Loss: 0.144186, Train Acc: 0.742308 | Val Loss: 0.158673, Val Acc: 0.721649\n",
      "Epoch 8452 - Train Loss: 0.144175, Train Acc: 0.742308 | Val Loss: 0.158663, Val Acc: 0.721649\n",
      "Epoch 8453 - Train Loss: 0.144164, Train Acc: 0.742308 | Val Loss: 0.158653, Val Acc: 0.721649\n",
      "Epoch 8454 - Train Loss: 0.144154, Train Acc: 0.742308 | Val Loss: 0.158643, Val Acc: 0.721649\n",
      "Epoch 8455 - Train Loss: 0.144143, Train Acc: 0.742308 | Val Loss: 0.158634, Val Acc: 0.721649\n",
      "Epoch 8456 - Train Loss: 0.144133, Train Acc: 0.742308 | Val Loss: 0.158624, Val Acc: 0.721649\n",
      "Epoch 8457 - Train Loss: 0.144122, Train Acc: 0.742308 | Val Loss: 0.158614, Val Acc: 0.721649\n",
      "Epoch 8458 - Train Loss: 0.144112, Train Acc: 0.742308 | Val Loss: 0.158605, Val Acc: 0.721649\n",
      "Epoch 8459 - Train Loss: 0.144101, Train Acc: 0.742308 | Val Loss: 0.158595, Val Acc: 0.721649\n",
      "Epoch 8460 - Train Loss: 0.144090, Train Acc: 0.742308 | Val Loss: 0.158585, Val Acc: 0.721649\n",
      "Epoch 8461 - Train Loss: 0.144080, Train Acc: 0.742308 | Val Loss: 0.158576, Val Acc: 0.721649\n",
      "Epoch 8462 - Train Loss: 0.144069, Train Acc: 0.742308 | Val Loss: 0.158566, Val Acc: 0.721649\n",
      "Epoch 8463 - Train Loss: 0.144059, Train Acc: 0.743590 | Val Loss: 0.158556, Val Acc: 0.721649\n",
      "Epoch 8464 - Train Loss: 0.144048, Train Acc: 0.743590 | Val Loss: 0.158547, Val Acc: 0.721649\n",
      "Epoch 8465 - Train Loss: 0.144038, Train Acc: 0.743590 | Val Loss: 0.158537, Val Acc: 0.721649\n",
      "Epoch 8466 - Train Loss: 0.144027, Train Acc: 0.743590 | Val Loss: 0.158527, Val Acc: 0.721649\n",
      "Epoch 8467 - Train Loss: 0.144016, Train Acc: 0.743590 | Val Loss: 0.158518, Val Acc: 0.721649\n",
      "Epoch 8468 - Train Loss: 0.144006, Train Acc: 0.743590 | Val Loss: 0.158508, Val Acc: 0.721649\n",
      "Epoch 8469 - Train Loss: 0.143995, Train Acc: 0.743590 | Val Loss: 0.158498, Val Acc: 0.721649\n",
      "Epoch 8470 - Train Loss: 0.143985, Train Acc: 0.743590 | Val Loss: 0.158489, Val Acc: 0.721649\n",
      "Epoch 8471 - Train Loss: 0.143974, Train Acc: 0.743590 | Val Loss: 0.158479, Val Acc: 0.721649\n",
      "Epoch 8472 - Train Loss: 0.143964, Train Acc: 0.743590 | Val Loss: 0.158469, Val Acc: 0.721649\n",
      "Epoch 8473 - Train Loss: 0.143953, Train Acc: 0.743590 | Val Loss: 0.158460, Val Acc: 0.721649\n",
      "Epoch 8474 - Train Loss: 0.143943, Train Acc: 0.743590 | Val Loss: 0.158450, Val Acc: 0.721649\n",
      "Epoch 8475 - Train Loss: 0.143932, Train Acc: 0.743590 | Val Loss: 0.158440, Val Acc: 0.721649\n",
      "Epoch 8476 - Train Loss: 0.143921, Train Acc: 0.743590 | Val Loss: 0.158431, Val Acc: 0.721649\n",
      "Epoch 8477 - Train Loss: 0.143911, Train Acc: 0.743590 | Val Loss: 0.158421, Val Acc: 0.721649\n",
      "Epoch 8478 - Train Loss: 0.143900, Train Acc: 0.743590 | Val Loss: 0.158412, Val Acc: 0.721649\n",
      "Epoch 8479 - Train Loss: 0.143890, Train Acc: 0.743590 | Val Loss: 0.158402, Val Acc: 0.721649\n",
      "Epoch 8480 - Train Loss: 0.143879, Train Acc: 0.743590 | Val Loss: 0.158392, Val Acc: 0.721649\n",
      "Epoch 8481 - Train Loss: 0.143869, Train Acc: 0.743590 | Val Loss: 0.158383, Val Acc: 0.721649\n",
      "Epoch 8482 - Train Loss: 0.143858, Train Acc: 0.743590 | Val Loss: 0.158373, Val Acc: 0.721649\n",
      "Epoch 8483 - Train Loss: 0.143848, Train Acc: 0.743590 | Val Loss: 0.158363, Val Acc: 0.721649\n",
      "Epoch 8484 - Train Loss: 0.143837, Train Acc: 0.743590 | Val Loss: 0.158354, Val Acc: 0.721649\n",
      "Epoch 8485 - Train Loss: 0.143827, Train Acc: 0.743590 | Val Loss: 0.158344, Val Acc: 0.721649\n",
      "Epoch 8486 - Train Loss: 0.143816, Train Acc: 0.743590 | Val Loss: 0.158335, Val Acc: 0.721649\n",
      "Epoch 8487 - Train Loss: 0.143805, Train Acc: 0.743590 | Val Loss: 0.158325, Val Acc: 0.731959\n",
      "Epoch 8488 - Train Loss: 0.143795, Train Acc: 0.743590 | Val Loss: 0.158315, Val Acc: 0.731959\n",
      "Epoch 8489 - Train Loss: 0.143784, Train Acc: 0.743590 | Val Loss: 0.158306, Val Acc: 0.731959\n",
      "Epoch 8490 - Train Loss: 0.143774, Train Acc: 0.743590 | Val Loss: 0.158296, Val Acc: 0.731959\n",
      "Epoch 8491 - Train Loss: 0.143763, Train Acc: 0.743590 | Val Loss: 0.158287, Val Acc: 0.731959\n",
      "Epoch 8492 - Train Loss: 0.143753, Train Acc: 0.743590 | Val Loss: 0.158277, Val Acc: 0.731959\n",
      "Epoch 8493 - Train Loss: 0.143742, Train Acc: 0.743590 | Val Loss: 0.158268, Val Acc: 0.742268\n",
      "Epoch 8494 - Train Loss: 0.143732, Train Acc: 0.742308 | Val Loss: 0.158258, Val Acc: 0.742268\n",
      "Epoch 8495 - Train Loss: 0.143721, Train Acc: 0.742308 | Val Loss: 0.158248, Val Acc: 0.742268\n",
      "Epoch 8496 - Train Loss: 0.143711, Train Acc: 0.742308 | Val Loss: 0.158239, Val Acc: 0.742268\n",
      "Epoch 8497 - Train Loss: 0.143700, Train Acc: 0.742308 | Val Loss: 0.158229, Val Acc: 0.742268\n",
      "Epoch 8498 - Train Loss: 0.143690, Train Acc: 0.742308 | Val Loss: 0.158220, Val Acc: 0.742268\n",
      "Epoch 8499 - Train Loss: 0.143679, Train Acc: 0.742308 | Val Loss: 0.158210, Val Acc: 0.742268\n",
      "Epoch 8500 - Train Loss: 0.143669, Train Acc: 0.742308 | Val Loss: 0.158201, Val Acc: 0.742268\n",
      "Epoch 8501 - Train Loss: 0.143658, Train Acc: 0.742308 | Val Loss: 0.158191, Val Acc: 0.742268\n",
      "Epoch 8502 - Train Loss: 0.143648, Train Acc: 0.742308 | Val Loss: 0.158182, Val Acc: 0.742268\n",
      "Epoch 8503 - Train Loss: 0.143637, Train Acc: 0.742308 | Val Loss: 0.158172, Val Acc: 0.742268\n",
      "Epoch 8504 - Train Loss: 0.143627, Train Acc: 0.742308 | Val Loss: 0.158163, Val Acc: 0.742268\n",
      "Epoch 8505 - Train Loss: 0.143616, Train Acc: 0.742308 | Val Loss: 0.158153, Val Acc: 0.742268\n",
      "Epoch 8506 - Train Loss: 0.143606, Train Acc: 0.742308 | Val Loss: 0.158143, Val Acc: 0.742268\n",
      "Epoch 8507 - Train Loss: 0.143595, Train Acc: 0.742308 | Val Loss: 0.158134, Val Acc: 0.742268\n",
      "Epoch 8508 - Train Loss: 0.143585, Train Acc: 0.742308 | Val Loss: 0.158124, Val Acc: 0.742268\n",
      "Epoch 8509 - Train Loss: 0.143574, Train Acc: 0.742308 | Val Loss: 0.158115, Val Acc: 0.742268\n",
      "Epoch 8510 - Train Loss: 0.143563, Train Acc: 0.742308 | Val Loss: 0.158105, Val Acc: 0.742268\n",
      "Epoch 8511 - Train Loss: 0.143553, Train Acc: 0.742308 | Val Loss: 0.158096, Val Acc: 0.742268\n",
      "Epoch 8512 - Train Loss: 0.143542, Train Acc: 0.743590 | Val Loss: 0.158086, Val Acc: 0.742268\n",
      "Epoch 8513 - Train Loss: 0.143532, Train Acc: 0.743590 | Val Loss: 0.158077, Val Acc: 0.742268\n",
      "Epoch 8514 - Train Loss: 0.143521, Train Acc: 0.743590 | Val Loss: 0.158067, Val Acc: 0.742268\n",
      "Epoch 8515 - Train Loss: 0.143511, Train Acc: 0.743590 | Val Loss: 0.158058, Val Acc: 0.742268\n",
      "Epoch 8516 - Train Loss: 0.143501, Train Acc: 0.743590 | Val Loss: 0.158048, Val Acc: 0.742268\n",
      "Epoch 8517 - Train Loss: 0.143490, Train Acc: 0.743590 | Val Loss: 0.158039, Val Acc: 0.742268\n",
      "Epoch 8518 - Train Loss: 0.143480, Train Acc: 0.743590 | Val Loss: 0.158029, Val Acc: 0.742268\n",
      "Epoch 8519 - Train Loss: 0.143469, Train Acc: 0.743590 | Val Loss: 0.158020, Val Acc: 0.742268\n",
      "Epoch 8520 - Train Loss: 0.143459, Train Acc: 0.743590 | Val Loss: 0.158010, Val Acc: 0.742268\n",
      "Epoch 8521 - Train Loss: 0.143448, Train Acc: 0.743590 | Val Loss: 0.158001, Val Acc: 0.742268\n",
      "Epoch 8522 - Train Loss: 0.143438, Train Acc: 0.743590 | Val Loss: 0.157991, Val Acc: 0.742268\n",
      "Epoch 8523 - Train Loss: 0.143427, Train Acc: 0.743590 | Val Loss: 0.157982, Val Acc: 0.742268\n",
      "Epoch 8524 - Train Loss: 0.143417, Train Acc: 0.743590 | Val Loss: 0.157972, Val Acc: 0.742268\n",
      "Epoch 8525 - Train Loss: 0.143406, Train Acc: 0.743590 | Val Loss: 0.157963, Val Acc: 0.742268\n",
      "Epoch 8526 - Train Loss: 0.143396, Train Acc: 0.743590 | Val Loss: 0.157953, Val Acc: 0.742268\n",
      "Epoch 8527 - Train Loss: 0.143385, Train Acc: 0.743590 | Val Loss: 0.157944, Val Acc: 0.742268\n",
      "Epoch 8528 - Train Loss: 0.143375, Train Acc: 0.743590 | Val Loss: 0.157935, Val Acc: 0.742268\n",
      "Epoch 8529 - Train Loss: 0.143364, Train Acc: 0.743590 | Val Loss: 0.157925, Val Acc: 0.742268\n",
      "Epoch 8530 - Train Loss: 0.143354, Train Acc: 0.743590 | Val Loss: 0.157916, Val Acc: 0.742268\n",
      "Epoch 8531 - Train Loss: 0.143343, Train Acc: 0.743590 | Val Loss: 0.157906, Val Acc: 0.742268\n",
      "Epoch 8532 - Train Loss: 0.143333, Train Acc: 0.743590 | Val Loss: 0.157897, Val Acc: 0.742268\n",
      "Epoch 8533 - Train Loss: 0.143322, Train Acc: 0.743590 | Val Loss: 0.157887, Val Acc: 0.742268\n",
      "Epoch 8534 - Train Loss: 0.143312, Train Acc: 0.743590 | Val Loss: 0.157878, Val Acc: 0.742268\n",
      "Epoch 8535 - Train Loss: 0.143301, Train Acc: 0.743590 | Val Loss: 0.157868, Val Acc: 0.742268\n",
      "Epoch 8536 - Train Loss: 0.143291, Train Acc: 0.743590 | Val Loss: 0.157859, Val Acc: 0.742268\n",
      "Epoch 8537 - Train Loss: 0.143280, Train Acc: 0.743590 | Val Loss: 0.157849, Val Acc: 0.742268\n",
      "Epoch 8538 - Train Loss: 0.143270, Train Acc: 0.743590 | Val Loss: 0.157840, Val Acc: 0.742268\n",
      "Epoch 8539 - Train Loss: 0.143260, Train Acc: 0.743590 | Val Loss: 0.157830, Val Acc: 0.742268\n",
      "Epoch 8540 - Train Loss: 0.143249, Train Acc: 0.743590 | Val Loss: 0.157821, Val Acc: 0.742268\n",
      "Epoch 8541 - Train Loss: 0.143239, Train Acc: 0.744872 | Val Loss: 0.157811, Val Acc: 0.742268\n",
      "Epoch 8542 - Train Loss: 0.143228, Train Acc: 0.744872 | Val Loss: 0.157802, Val Acc: 0.742268\n",
      "Epoch 8543 - Train Loss: 0.143218, Train Acc: 0.744872 | Val Loss: 0.157793, Val Acc: 0.742268\n",
      "Epoch 8544 - Train Loss: 0.143207, Train Acc: 0.744872 | Val Loss: 0.157784, Val Acc: 0.742268\n",
      "Epoch 8545 - Train Loss: 0.143197, Train Acc: 0.744872 | Val Loss: 0.157774, Val Acc: 0.742268\n",
      "Epoch 8546 - Train Loss: 0.143186, Train Acc: 0.746154 | Val Loss: 0.157765, Val Acc: 0.742268\n",
      "Epoch 8547 - Train Loss: 0.143176, Train Acc: 0.746154 | Val Loss: 0.157756, Val Acc: 0.742268\n",
      "Epoch 8548 - Train Loss: 0.143165, Train Acc: 0.746154 | Val Loss: 0.157747, Val Acc: 0.742268\n",
      "Epoch 8549 - Train Loss: 0.143155, Train Acc: 0.746154 | Val Loss: 0.157737, Val Acc: 0.742268\n",
      "Epoch 8550 - Train Loss: 0.143145, Train Acc: 0.746154 | Val Loss: 0.157728, Val Acc: 0.742268\n",
      "Epoch 8551 - Train Loss: 0.143134, Train Acc: 0.746154 | Val Loss: 0.157719, Val Acc: 0.742268\n",
      "Epoch 8552 - Train Loss: 0.143124, Train Acc: 0.746154 | Val Loss: 0.157710, Val Acc: 0.742268\n",
      "Epoch 8553 - Train Loss: 0.143113, Train Acc: 0.746154 | Val Loss: 0.157700, Val Acc: 0.742268\n",
      "Epoch 8554 - Train Loss: 0.143103, Train Acc: 0.747436 | Val Loss: 0.157691, Val Acc: 0.742268\n",
      "Epoch 8555 - Train Loss: 0.143092, Train Acc: 0.747436 | Val Loss: 0.157682, Val Acc: 0.742268\n",
      "Epoch 8556 - Train Loss: 0.143082, Train Acc: 0.747436 | Val Loss: 0.157672, Val Acc: 0.742268\n",
      "Epoch 8557 - Train Loss: 0.143071, Train Acc: 0.747436 | Val Loss: 0.157663, Val Acc: 0.742268\n",
      "Epoch 8558 - Train Loss: 0.143061, Train Acc: 0.747436 | Val Loss: 0.157654, Val Acc: 0.742268\n",
      "Epoch 8559 - Train Loss: 0.143051, Train Acc: 0.747436 | Val Loss: 0.157645, Val Acc: 0.742268\n",
      "Epoch 8560 - Train Loss: 0.143040, Train Acc: 0.747436 | Val Loss: 0.157635, Val Acc: 0.742268\n",
      "Epoch 8561 - Train Loss: 0.143030, Train Acc: 0.747436 | Val Loss: 0.157626, Val Acc: 0.742268\n",
      "Epoch 8562 - Train Loss: 0.143019, Train Acc: 0.747436 | Val Loss: 0.157617, Val Acc: 0.742268\n",
      "Epoch 8563 - Train Loss: 0.143009, Train Acc: 0.747436 | Val Loss: 0.157607, Val Acc: 0.742268\n",
      "Epoch 8564 - Train Loss: 0.142999, Train Acc: 0.747436 | Val Loss: 0.157598, Val Acc: 0.742268\n",
      "Epoch 8565 - Train Loss: 0.142988, Train Acc: 0.747436 | Val Loss: 0.157589, Val Acc: 0.742268\n",
      "Epoch 8566 - Train Loss: 0.142978, Train Acc: 0.747436 | Val Loss: 0.157579, Val Acc: 0.742268\n",
      "Epoch 8567 - Train Loss: 0.142967, Train Acc: 0.747436 | Val Loss: 0.157570, Val Acc: 0.742268\n",
      "Epoch 8568 - Train Loss: 0.142957, Train Acc: 0.747436 | Val Loss: 0.157561, Val Acc: 0.742268\n",
      "Epoch 8569 - Train Loss: 0.142946, Train Acc: 0.747436 | Val Loss: 0.157552, Val Acc: 0.742268\n",
      "Epoch 8570 - Train Loss: 0.142936, Train Acc: 0.747436 | Val Loss: 0.157542, Val Acc: 0.742268\n",
      "Epoch 8571 - Train Loss: 0.142926, Train Acc: 0.748718 | Val Loss: 0.157533, Val Acc: 0.742268\n",
      "Epoch 8572 - Train Loss: 0.142915, Train Acc: 0.748718 | Val Loss: 0.157524, Val Acc: 0.742268\n",
      "Epoch 8573 - Train Loss: 0.142905, Train Acc: 0.748718 | Val Loss: 0.157514, Val Acc: 0.742268\n",
      "Epoch 8574 - Train Loss: 0.142894, Train Acc: 0.748718 | Val Loss: 0.157505, Val Acc: 0.742268\n",
      "Epoch 8575 - Train Loss: 0.142884, Train Acc: 0.748718 | Val Loss: 0.157496, Val Acc: 0.742268\n",
      "Epoch 8576 - Train Loss: 0.142874, Train Acc: 0.748718 | Val Loss: 0.157487, Val Acc: 0.742268\n",
      "Epoch 8577 - Train Loss: 0.142863, Train Acc: 0.750000 | Val Loss: 0.157477, Val Acc: 0.742268\n",
      "Epoch 8578 - Train Loss: 0.142853, Train Acc: 0.750000 | Val Loss: 0.157468, Val Acc: 0.742268\n",
      "Epoch 8579 - Train Loss: 0.142842, Train Acc: 0.750000 | Val Loss: 0.157459, Val Acc: 0.742268\n",
      "Epoch 8580 - Train Loss: 0.142832, Train Acc: 0.750000 | Val Loss: 0.157449, Val Acc: 0.742268\n",
      "Epoch 8581 - Train Loss: 0.142822, Train Acc: 0.750000 | Val Loss: 0.157440, Val Acc: 0.742268\n",
      "Epoch 8582 - Train Loss: 0.142811, Train Acc: 0.750000 | Val Loss: 0.157431, Val Acc: 0.742268\n",
      "Epoch 8583 - Train Loss: 0.142801, Train Acc: 0.750000 | Val Loss: 0.157421, Val Acc: 0.742268\n",
      "Epoch 8584 - Train Loss: 0.142790, Train Acc: 0.750000 | Val Loss: 0.157412, Val Acc: 0.742268\n",
      "Epoch 8585 - Train Loss: 0.142780, Train Acc: 0.750000 | Val Loss: 0.157403, Val Acc: 0.742268\n",
      "Epoch 8586 - Train Loss: 0.142770, Train Acc: 0.750000 | Val Loss: 0.157394, Val Acc: 0.742268\n",
      "Epoch 8587 - Train Loss: 0.142759, Train Acc: 0.750000 | Val Loss: 0.157384, Val Acc: 0.742268\n",
      "Epoch 8588 - Train Loss: 0.142749, Train Acc: 0.750000 | Val Loss: 0.157375, Val Acc: 0.742268\n",
      "Epoch 8589 - Train Loss: 0.142738, Train Acc: 0.750000 | Val Loss: 0.157366, Val Acc: 0.742268\n",
      "Epoch 8590 - Train Loss: 0.142728, Train Acc: 0.750000 | Val Loss: 0.157357, Val Acc: 0.742268\n",
      "Epoch 8591 - Train Loss: 0.142718, Train Acc: 0.750000 | Val Loss: 0.157347, Val Acc: 0.742268\n",
      "Epoch 8592 - Train Loss: 0.142707, Train Acc: 0.750000 | Val Loss: 0.157338, Val Acc: 0.742268\n",
      "Epoch 8593 - Train Loss: 0.142697, Train Acc: 0.750000 | Val Loss: 0.157329, Val Acc: 0.742268\n",
      "Epoch 8594 - Train Loss: 0.142686, Train Acc: 0.750000 | Val Loss: 0.157320, Val Acc: 0.742268\n",
      "Epoch 8595 - Train Loss: 0.142676, Train Acc: 0.750000 | Val Loss: 0.157310, Val Acc: 0.742268\n",
      "Epoch 8596 - Train Loss: 0.142666, Train Acc: 0.750000 | Val Loss: 0.157301, Val Acc: 0.742268\n",
      "Epoch 8597 - Train Loss: 0.142655, Train Acc: 0.750000 | Val Loss: 0.157292, Val Acc: 0.742268\n",
      "Epoch 8598 - Train Loss: 0.142645, Train Acc: 0.750000 | Val Loss: 0.157283, Val Acc: 0.742268\n",
      "Epoch 8599 - Train Loss: 0.142635, Train Acc: 0.750000 | Val Loss: 0.157273, Val Acc: 0.742268\n",
      "Epoch 8600 - Train Loss: 0.142624, Train Acc: 0.750000 | Val Loss: 0.157264, Val Acc: 0.742268\n",
      "Epoch 8601 - Train Loss: 0.142614, Train Acc: 0.750000 | Val Loss: 0.157255, Val Acc: 0.742268\n",
      "Epoch 8602 - Train Loss: 0.142603, Train Acc: 0.750000 | Val Loss: 0.157246, Val Acc: 0.742268\n",
      "Epoch 8603 - Train Loss: 0.142593, Train Acc: 0.750000 | Val Loss: 0.157236, Val Acc: 0.742268\n",
      "Epoch 8604 - Train Loss: 0.142583, Train Acc: 0.750000 | Val Loss: 0.157227, Val Acc: 0.742268\n",
      "Epoch 8605 - Train Loss: 0.142572, Train Acc: 0.750000 | Val Loss: 0.157218, Val Acc: 0.742268\n",
      "Epoch 8606 - Train Loss: 0.142562, Train Acc: 0.750000 | Val Loss: 0.157209, Val Acc: 0.742268\n",
      "Epoch 8607 - Train Loss: 0.142552, Train Acc: 0.750000 | Val Loss: 0.157199, Val Acc: 0.742268\n",
      "Epoch 8608 - Train Loss: 0.142541, Train Acc: 0.750000 | Val Loss: 0.157190, Val Acc: 0.742268\n",
      "Epoch 8609 - Train Loss: 0.142531, Train Acc: 0.750000 | Val Loss: 0.157181, Val Acc: 0.742268\n",
      "Epoch 8610 - Train Loss: 0.142521, Train Acc: 0.750000 | Val Loss: 0.157172, Val Acc: 0.742268\n",
      "Epoch 8611 - Train Loss: 0.142510, Train Acc: 0.750000 | Val Loss: 0.157162, Val Acc: 0.742268\n",
      "Epoch 8612 - Train Loss: 0.142500, Train Acc: 0.750000 | Val Loss: 0.157153, Val Acc: 0.742268\n",
      "Epoch 8613 - Train Loss: 0.142490, Train Acc: 0.750000 | Val Loss: 0.157144, Val Acc: 0.742268\n",
      "Epoch 8614 - Train Loss: 0.142479, Train Acc: 0.750000 | Val Loss: 0.157135, Val Acc: 0.742268\n",
      "Epoch 8615 - Train Loss: 0.142469, Train Acc: 0.748718 | Val Loss: 0.157125, Val Acc: 0.742268\n",
      "Epoch 8616 - Train Loss: 0.142458, Train Acc: 0.748718 | Val Loss: 0.157116, Val Acc: 0.742268\n",
      "Epoch 8617 - Train Loss: 0.142448, Train Acc: 0.750000 | Val Loss: 0.157107, Val Acc: 0.742268\n",
      "Epoch 8618 - Train Loss: 0.142438, Train Acc: 0.750000 | Val Loss: 0.157098, Val Acc: 0.742268\n",
      "Epoch 8619 - Train Loss: 0.142427, Train Acc: 0.750000 | Val Loss: 0.157088, Val Acc: 0.742268\n",
      "Epoch 8620 - Train Loss: 0.142417, Train Acc: 0.750000 | Val Loss: 0.157079, Val Acc: 0.742268\n",
      "Epoch 8621 - Train Loss: 0.142407, Train Acc: 0.750000 | Val Loss: 0.157070, Val Acc: 0.742268\n",
      "Epoch 8622 - Train Loss: 0.142396, Train Acc: 0.750000 | Val Loss: 0.157061, Val Acc: 0.742268\n",
      "Epoch 8623 - Train Loss: 0.142386, Train Acc: 0.750000 | Val Loss: 0.157052, Val Acc: 0.742268\n",
      "Epoch 8624 - Train Loss: 0.142376, Train Acc: 0.750000 | Val Loss: 0.157042, Val Acc: 0.742268\n",
      "Epoch 8625 - Train Loss: 0.142365, Train Acc: 0.750000 | Val Loss: 0.157033, Val Acc: 0.742268\n",
      "Epoch 8626 - Train Loss: 0.142355, Train Acc: 0.750000 | Val Loss: 0.157024, Val Acc: 0.742268\n",
      "Epoch 8627 - Train Loss: 0.142345, Train Acc: 0.750000 | Val Loss: 0.157015, Val Acc: 0.742268\n",
      "Epoch 8628 - Train Loss: 0.142334, Train Acc: 0.750000 | Val Loss: 0.157005, Val Acc: 0.742268\n",
      "Epoch 8629 - Train Loss: 0.142324, Train Acc: 0.750000 | Val Loss: 0.156996, Val Acc: 0.742268\n",
      "Epoch 8630 - Train Loss: 0.142314, Train Acc: 0.750000 | Val Loss: 0.156987, Val Acc: 0.742268\n",
      "Epoch 8631 - Train Loss: 0.142303, Train Acc: 0.750000 | Val Loss: 0.156978, Val Acc: 0.742268\n",
      "Epoch 8632 - Train Loss: 0.142293, Train Acc: 0.750000 | Val Loss: 0.156969, Val Acc: 0.742268\n",
      "Epoch 8633 - Train Loss: 0.142283, Train Acc: 0.750000 | Val Loss: 0.156959, Val Acc: 0.742268\n",
      "Epoch 8634 - Train Loss: 0.142272, Train Acc: 0.750000 | Val Loss: 0.156950, Val Acc: 0.742268\n",
      "Epoch 8635 - Train Loss: 0.142262, Train Acc: 0.750000 | Val Loss: 0.156941, Val Acc: 0.742268\n",
      "Epoch 8636 - Train Loss: 0.142252, Train Acc: 0.750000 | Val Loss: 0.156932, Val Acc: 0.742268\n",
      "Epoch 8637 - Train Loss: 0.142241, Train Acc: 0.750000 | Val Loss: 0.156922, Val Acc: 0.742268\n",
      "Epoch 8638 - Train Loss: 0.142231, Train Acc: 0.750000 | Val Loss: 0.156913, Val Acc: 0.742268\n",
      "Epoch 8639 - Train Loss: 0.142221, Train Acc: 0.750000 | Val Loss: 0.156904, Val Acc: 0.742268\n",
      "Epoch 8640 - Train Loss: 0.142211, Train Acc: 0.750000 | Val Loss: 0.156895, Val Acc: 0.742268\n",
      "Epoch 8641 - Train Loss: 0.142200, Train Acc: 0.750000 | Val Loss: 0.156886, Val Acc: 0.742268\n",
      "Epoch 8642 - Train Loss: 0.142190, Train Acc: 0.750000 | Val Loss: 0.156876, Val Acc: 0.742268\n",
      "Epoch 8643 - Train Loss: 0.142180, Train Acc: 0.750000 | Val Loss: 0.156867, Val Acc: 0.742268\n",
      "Epoch 8644 - Train Loss: 0.142169, Train Acc: 0.750000 | Val Loss: 0.156858, Val Acc: 0.742268\n",
      "Epoch 8645 - Train Loss: 0.142159, Train Acc: 0.750000 | Val Loss: 0.156849, Val Acc: 0.742268\n",
      "Epoch 8646 - Train Loss: 0.142149, Train Acc: 0.750000 | Val Loss: 0.156839, Val Acc: 0.742268\n",
      "Epoch 8647 - Train Loss: 0.142138, Train Acc: 0.750000 | Val Loss: 0.156830, Val Acc: 0.742268\n",
      "Epoch 8648 - Train Loss: 0.142128, Train Acc: 0.750000 | Val Loss: 0.156821, Val Acc: 0.742268\n",
      "Epoch 8649 - Train Loss: 0.142118, Train Acc: 0.750000 | Val Loss: 0.156812, Val Acc: 0.742268\n",
      "Epoch 8650 - Train Loss: 0.142107, Train Acc: 0.750000 | Val Loss: 0.156803, Val Acc: 0.742268\n",
      "Epoch 8651 - Train Loss: 0.142097, Train Acc: 0.750000 | Val Loss: 0.156793, Val Acc: 0.742268\n",
      "Epoch 8652 - Train Loss: 0.142087, Train Acc: 0.750000 | Val Loss: 0.156784, Val Acc: 0.731959\n",
      "Epoch 8653 - Train Loss: 0.142077, Train Acc: 0.750000 | Val Loss: 0.156775, Val Acc: 0.731959\n",
      "Epoch 8654 - Train Loss: 0.142066, Train Acc: 0.750000 | Val Loss: 0.156766, Val Acc: 0.731959\n",
      "Epoch 8655 - Train Loss: 0.142056, Train Acc: 0.750000 | Val Loss: 0.156757, Val Acc: 0.731959\n",
      "Epoch 8656 - Train Loss: 0.142046, Train Acc: 0.750000 | Val Loss: 0.156747, Val Acc: 0.731959\n",
      "Epoch 8657 - Train Loss: 0.142035, Train Acc: 0.750000 | Val Loss: 0.156738, Val Acc: 0.731959\n",
      "Epoch 8658 - Train Loss: 0.142025, Train Acc: 0.750000 | Val Loss: 0.156729, Val Acc: 0.731959\n",
      "Epoch 8659 - Train Loss: 0.142015, Train Acc: 0.750000 | Val Loss: 0.156720, Val Acc: 0.731959\n",
      "Epoch 8660 - Train Loss: 0.142004, Train Acc: 0.750000 | Val Loss: 0.156711, Val Acc: 0.731959\n",
      "Epoch 8661 - Train Loss: 0.141994, Train Acc: 0.750000 | Val Loss: 0.156701, Val Acc: 0.731959\n",
      "Epoch 8662 - Train Loss: 0.141984, Train Acc: 0.750000 | Val Loss: 0.156692, Val Acc: 0.731959\n",
      "Epoch 8663 - Train Loss: 0.141974, Train Acc: 0.750000 | Val Loss: 0.156683, Val Acc: 0.731959\n",
      "Epoch 8664 - Train Loss: 0.141963, Train Acc: 0.750000 | Val Loss: 0.156674, Val Acc: 0.731959\n",
      "Epoch 8665 - Train Loss: 0.141953, Train Acc: 0.750000 | Val Loss: 0.156665, Val Acc: 0.731959\n",
      "Epoch 8666 - Train Loss: 0.141943, Train Acc: 0.750000 | Val Loss: 0.156655, Val Acc: 0.731959\n",
      "Epoch 8667 - Train Loss: 0.141932, Train Acc: 0.750000 | Val Loss: 0.156646, Val Acc: 0.731959\n",
      "Epoch 8668 - Train Loss: 0.141922, Train Acc: 0.750000 | Val Loss: 0.156637, Val Acc: 0.731959\n",
      "Epoch 8669 - Train Loss: 0.141912, Train Acc: 0.750000 | Val Loss: 0.156628, Val Acc: 0.731959\n",
      "Epoch 8670 - Train Loss: 0.141902, Train Acc: 0.750000 | Val Loss: 0.156619, Val Acc: 0.731959\n",
      "Epoch 8671 - Train Loss: 0.141891, Train Acc: 0.750000 | Val Loss: 0.156609, Val Acc: 0.731959\n",
      "Epoch 8672 - Train Loss: 0.141881, Train Acc: 0.750000 | Val Loss: 0.156600, Val Acc: 0.731959\n",
      "Epoch 8673 - Train Loss: 0.141871, Train Acc: 0.750000 | Val Loss: 0.156591, Val Acc: 0.731959\n",
      "Epoch 8674 - Train Loss: 0.141861, Train Acc: 0.750000 | Val Loss: 0.156582, Val Acc: 0.731959\n",
      "Epoch 8675 - Train Loss: 0.141850, Train Acc: 0.750000 | Val Loss: 0.156573, Val Acc: 0.731959\n",
      "Epoch 8676 - Train Loss: 0.141840, Train Acc: 0.750000 | Val Loss: 0.156564, Val Acc: 0.731959\n",
      "Epoch 8677 - Train Loss: 0.141830, Train Acc: 0.750000 | Val Loss: 0.156554, Val Acc: 0.731959\n",
      "Epoch 8678 - Train Loss: 0.141819, Train Acc: 0.750000 | Val Loss: 0.156545, Val Acc: 0.731959\n",
      "Epoch 8679 - Train Loss: 0.141809, Train Acc: 0.750000 | Val Loss: 0.156536, Val Acc: 0.731959\n",
      "Epoch 8680 - Train Loss: 0.141799, Train Acc: 0.750000 | Val Loss: 0.156527, Val Acc: 0.731959\n",
      "Epoch 8681 - Train Loss: 0.141789, Train Acc: 0.750000 | Val Loss: 0.156518, Val Acc: 0.731959\n",
      "Epoch 8682 - Train Loss: 0.141778, Train Acc: 0.750000 | Val Loss: 0.156508, Val Acc: 0.731959\n",
      "Epoch 8683 - Train Loss: 0.141768, Train Acc: 0.750000 | Val Loss: 0.156499, Val Acc: 0.731959\n",
      "Epoch 8684 - Train Loss: 0.141758, Train Acc: 0.750000 | Val Loss: 0.156490, Val Acc: 0.731959\n",
      "Epoch 8685 - Train Loss: 0.141748, Train Acc: 0.750000 | Val Loss: 0.156481, Val Acc: 0.731959\n",
      "Epoch 8686 - Train Loss: 0.141737, Train Acc: 0.750000 | Val Loss: 0.156472, Val Acc: 0.731959\n",
      "Epoch 8687 - Train Loss: 0.141727, Train Acc: 0.750000 | Val Loss: 0.156463, Val Acc: 0.731959\n",
      "Epoch 8688 - Train Loss: 0.141717, Train Acc: 0.750000 | Val Loss: 0.156453, Val Acc: 0.731959\n",
      "Epoch 8689 - Train Loss: 0.141707, Train Acc: 0.750000 | Val Loss: 0.156444, Val Acc: 0.731959\n",
      "Epoch 8690 - Train Loss: 0.141696, Train Acc: 0.750000 | Val Loss: 0.156435, Val Acc: 0.731959\n",
      "Epoch 8691 - Train Loss: 0.141686, Train Acc: 0.750000 | Val Loss: 0.156426, Val Acc: 0.731959\n",
      "Epoch 8692 - Train Loss: 0.141676, Train Acc: 0.750000 | Val Loss: 0.156417, Val Acc: 0.731959\n",
      "Epoch 8693 - Train Loss: 0.141666, Train Acc: 0.750000 | Val Loss: 0.156408, Val Acc: 0.731959\n",
      "Epoch 8694 - Train Loss: 0.141655, Train Acc: 0.750000 | Val Loss: 0.156398, Val Acc: 0.731959\n",
      "Epoch 8695 - Train Loss: 0.141645, Train Acc: 0.751282 | Val Loss: 0.156389, Val Acc: 0.731959\n",
      "Epoch 8696 - Train Loss: 0.141635, Train Acc: 0.751282 | Val Loss: 0.156380, Val Acc: 0.731959\n",
      "Epoch 8697 - Train Loss: 0.141625, Train Acc: 0.751282 | Val Loss: 0.156371, Val Acc: 0.731959\n",
      "Epoch 8698 - Train Loss: 0.141615, Train Acc: 0.751282 | Val Loss: 0.156362, Val Acc: 0.731959\n",
      "Epoch 8699 - Train Loss: 0.141604, Train Acc: 0.751282 | Val Loss: 0.156353, Val Acc: 0.731959\n",
      "Epoch 8700 - Train Loss: 0.141594, Train Acc: 0.751282 | Val Loss: 0.156344, Val Acc: 0.731959\n",
      "Epoch 8701 - Train Loss: 0.141584, Train Acc: 0.751282 | Val Loss: 0.156334, Val Acc: 0.731959\n",
      "Epoch 8702 - Train Loss: 0.141574, Train Acc: 0.751282 | Val Loss: 0.156325, Val Acc: 0.731959\n",
      "Epoch 8703 - Train Loss: 0.141563, Train Acc: 0.751282 | Val Loss: 0.156316, Val Acc: 0.731959\n",
      "Epoch 8704 - Train Loss: 0.141553, Train Acc: 0.751282 | Val Loss: 0.156307, Val Acc: 0.731959\n",
      "Epoch 8705 - Train Loss: 0.141543, Train Acc: 0.751282 | Val Loss: 0.156298, Val Acc: 0.731959\n",
      "Epoch 8706 - Train Loss: 0.141533, Train Acc: 0.751282 | Val Loss: 0.156289, Val Acc: 0.731959\n",
      "Epoch 8707 - Train Loss: 0.141522, Train Acc: 0.751282 | Val Loss: 0.156279, Val Acc: 0.731959\n",
      "Epoch 8708 - Train Loss: 0.141512, Train Acc: 0.751282 | Val Loss: 0.156270, Val Acc: 0.731959\n",
      "Epoch 8709 - Train Loss: 0.141502, Train Acc: 0.751282 | Val Loss: 0.156261, Val Acc: 0.731959\n",
      "Epoch 8710 - Train Loss: 0.141492, Train Acc: 0.751282 | Val Loss: 0.156252, Val Acc: 0.731959\n",
      "Epoch 8711 - Train Loss: 0.141482, Train Acc: 0.751282 | Val Loss: 0.156243, Val Acc: 0.731959\n",
      "Epoch 8712 - Train Loss: 0.141471, Train Acc: 0.751282 | Val Loss: 0.156234, Val Acc: 0.731959\n",
      "Epoch 8713 - Train Loss: 0.141461, Train Acc: 0.751282 | Val Loss: 0.156225, Val Acc: 0.731959\n",
      "Epoch 8714 - Train Loss: 0.141451, Train Acc: 0.751282 | Val Loss: 0.156216, Val Acc: 0.731959\n",
      "Epoch 8715 - Train Loss: 0.141441, Train Acc: 0.751282 | Val Loss: 0.156206, Val Acc: 0.731959\n",
      "Epoch 8716 - Train Loss: 0.141430, Train Acc: 0.751282 | Val Loss: 0.156197, Val Acc: 0.731959\n",
      "Epoch 8717 - Train Loss: 0.141420, Train Acc: 0.751282 | Val Loss: 0.156188, Val Acc: 0.731959\n",
      "Epoch 8718 - Train Loss: 0.141410, Train Acc: 0.751282 | Val Loss: 0.156179, Val Acc: 0.731959\n",
      "Epoch 8719 - Train Loss: 0.141400, Train Acc: 0.751282 | Val Loss: 0.156170, Val Acc: 0.731959\n",
      "Epoch 8720 - Train Loss: 0.141390, Train Acc: 0.751282 | Val Loss: 0.156161, Val Acc: 0.731959\n",
      "Epoch 8721 - Train Loss: 0.141379, Train Acc: 0.751282 | Val Loss: 0.156152, Val Acc: 0.731959\n",
      "Epoch 8722 - Train Loss: 0.141369, Train Acc: 0.751282 | Val Loss: 0.156142, Val Acc: 0.731959\n",
      "Epoch 8723 - Train Loss: 0.141359, Train Acc: 0.751282 | Val Loss: 0.156133, Val Acc: 0.731959\n",
      "Epoch 8724 - Train Loss: 0.141349, Train Acc: 0.751282 | Val Loss: 0.156124, Val Acc: 0.731959\n",
      "Epoch 8725 - Train Loss: 0.141339, Train Acc: 0.751282 | Val Loss: 0.156115, Val Acc: 0.731959\n",
      "Epoch 8726 - Train Loss: 0.141328, Train Acc: 0.751282 | Val Loss: 0.156106, Val Acc: 0.731959\n",
      "Epoch 8727 - Train Loss: 0.141318, Train Acc: 0.751282 | Val Loss: 0.156097, Val Acc: 0.731959\n",
      "Epoch 8728 - Train Loss: 0.141308, Train Acc: 0.751282 | Val Loss: 0.156088, Val Acc: 0.731959\n",
      "Epoch 8729 - Train Loss: 0.141298, Train Acc: 0.751282 | Val Loss: 0.156079, Val Acc: 0.731959\n",
      "Epoch 8730 - Train Loss: 0.141288, Train Acc: 0.751282 | Val Loss: 0.156070, Val Acc: 0.731959\n",
      "Epoch 8731 - Train Loss: 0.141277, Train Acc: 0.751282 | Val Loss: 0.156060, Val Acc: 0.731959\n",
      "Epoch 8732 - Train Loss: 0.141267, Train Acc: 0.751282 | Val Loss: 0.156051, Val Acc: 0.731959\n",
      "Epoch 8733 - Train Loss: 0.141257, Train Acc: 0.751282 | Val Loss: 0.156042, Val Acc: 0.731959\n",
      "Epoch 8734 - Train Loss: 0.141247, Train Acc: 0.751282 | Val Loss: 0.156033, Val Acc: 0.731959\n",
      "Epoch 8735 - Train Loss: 0.141237, Train Acc: 0.751282 | Val Loss: 0.156024, Val Acc: 0.731959\n",
      "Epoch 8736 - Train Loss: 0.141227, Train Acc: 0.751282 | Val Loss: 0.156015, Val Acc: 0.731959\n",
      "Epoch 8737 - Train Loss: 0.141216, Train Acc: 0.751282 | Val Loss: 0.156006, Val Acc: 0.731959\n",
      "Epoch 8738 - Train Loss: 0.141206, Train Acc: 0.751282 | Val Loss: 0.155997, Val Acc: 0.731959\n",
      "Epoch 8739 - Train Loss: 0.141196, Train Acc: 0.751282 | Val Loss: 0.155988, Val Acc: 0.731959\n",
      "Epoch 8740 - Train Loss: 0.141186, Train Acc: 0.751282 | Val Loss: 0.155978, Val Acc: 0.731959\n",
      "Epoch 8741 - Train Loss: 0.141176, Train Acc: 0.751282 | Val Loss: 0.155969, Val Acc: 0.731959\n",
      "Epoch 8742 - Train Loss: 0.141165, Train Acc: 0.752564 | Val Loss: 0.155960, Val Acc: 0.731959\n",
      "Epoch 8743 - Train Loss: 0.141155, Train Acc: 0.753846 | Val Loss: 0.155951, Val Acc: 0.731959\n",
      "Epoch 8744 - Train Loss: 0.141145, Train Acc: 0.753846 | Val Loss: 0.155942, Val Acc: 0.731959\n",
      "Epoch 8745 - Train Loss: 0.141135, Train Acc: 0.753846 | Val Loss: 0.155933, Val Acc: 0.731959\n",
      "Epoch 8746 - Train Loss: 0.141125, Train Acc: 0.753846 | Val Loss: 0.155924, Val Acc: 0.731959\n",
      "Epoch 8747 - Train Loss: 0.141115, Train Acc: 0.753846 | Val Loss: 0.155915, Val Acc: 0.731959\n",
      "Epoch 8748 - Train Loss: 0.141104, Train Acc: 0.753846 | Val Loss: 0.155906, Val Acc: 0.731959\n",
      "Epoch 8749 - Train Loss: 0.141094, Train Acc: 0.753846 | Val Loss: 0.155897, Val Acc: 0.731959\n",
      "Epoch 8750 - Train Loss: 0.141084, Train Acc: 0.755128 | Val Loss: 0.155888, Val Acc: 0.731959\n",
      "Epoch 8751 - Train Loss: 0.141074, Train Acc: 0.755128 | Val Loss: 0.155878, Val Acc: 0.731959\n",
      "Epoch 8752 - Train Loss: 0.141064, Train Acc: 0.755128 | Val Loss: 0.155869, Val Acc: 0.731959\n",
      "Epoch 8753 - Train Loss: 0.141054, Train Acc: 0.755128 | Val Loss: 0.155860, Val Acc: 0.731959\n",
      "Epoch 8754 - Train Loss: 0.141043, Train Acc: 0.755128 | Val Loss: 0.155851, Val Acc: 0.731959\n",
      "Epoch 8755 - Train Loss: 0.141033, Train Acc: 0.755128 | Val Loss: 0.155842, Val Acc: 0.731959\n",
      "Epoch 8756 - Train Loss: 0.141023, Train Acc: 0.755128 | Val Loss: 0.155833, Val Acc: 0.731959\n",
      "Epoch 8757 - Train Loss: 0.141013, Train Acc: 0.755128 | Val Loss: 0.155823, Val Acc: 0.731959\n",
      "Epoch 8758 - Train Loss: 0.141003, Train Acc: 0.755128 | Val Loss: 0.155814, Val Acc: 0.731959\n",
      "Epoch 8759 - Train Loss: 0.140993, Train Acc: 0.755128 | Val Loss: 0.155805, Val Acc: 0.731959\n",
      "Epoch 8760 - Train Loss: 0.140983, Train Acc: 0.755128 | Val Loss: 0.155796, Val Acc: 0.731959\n",
      "Epoch 8761 - Train Loss: 0.140972, Train Acc: 0.755128 | Val Loss: 0.155787, Val Acc: 0.731959\n",
      "Epoch 8762 - Train Loss: 0.140962, Train Acc: 0.755128 | Val Loss: 0.155778, Val Acc: 0.731959\n",
      "Epoch 8763 - Train Loss: 0.140952, Train Acc: 0.755128 | Val Loss: 0.155769, Val Acc: 0.731959\n",
      "Epoch 8764 - Train Loss: 0.140942, Train Acc: 0.755128 | Val Loss: 0.155760, Val Acc: 0.731959\n",
      "Epoch 8765 - Train Loss: 0.140932, Train Acc: 0.755128 | Val Loss: 0.155750, Val Acc: 0.731959\n",
      "Epoch 8766 - Train Loss: 0.140922, Train Acc: 0.755128 | Val Loss: 0.155741, Val Acc: 0.731959\n",
      "Epoch 8767 - Train Loss: 0.140912, Train Acc: 0.755128 | Val Loss: 0.155732, Val Acc: 0.731959\n",
      "Epoch 8768 - Train Loss: 0.140901, Train Acc: 0.755128 | Val Loss: 0.155723, Val Acc: 0.731959\n",
      "Epoch 8769 - Train Loss: 0.140891, Train Acc: 0.755128 | Val Loss: 0.155714, Val Acc: 0.731959\n",
      "Epoch 8770 - Train Loss: 0.140881, Train Acc: 0.755128 | Val Loss: 0.155705, Val Acc: 0.731959\n",
      "Epoch 8771 - Train Loss: 0.140871, Train Acc: 0.755128 | Val Loss: 0.155696, Val Acc: 0.731959\n",
      "Epoch 8772 - Train Loss: 0.140861, Train Acc: 0.755128 | Val Loss: 0.155687, Val Acc: 0.731959\n",
      "Epoch 8773 - Train Loss: 0.140851, Train Acc: 0.755128 | Val Loss: 0.155678, Val Acc: 0.731959\n",
      "Epoch 8774 - Train Loss: 0.140841, Train Acc: 0.755128 | Val Loss: 0.155668, Val Acc: 0.731959\n",
      "Epoch 8775 - Train Loss: 0.140830, Train Acc: 0.755128 | Val Loss: 0.155659, Val Acc: 0.731959\n",
      "Epoch 8776 - Train Loss: 0.140820, Train Acc: 0.755128 | Val Loss: 0.155650, Val Acc: 0.731959\n",
      "Epoch 8777 - Train Loss: 0.140810, Train Acc: 0.755128 | Val Loss: 0.155641, Val Acc: 0.731959\n",
      "Epoch 8778 - Train Loss: 0.140800, Train Acc: 0.755128 | Val Loss: 0.155632, Val Acc: 0.731959\n",
      "Epoch 8779 - Train Loss: 0.140790, Train Acc: 0.755128 | Val Loss: 0.155623, Val Acc: 0.731959\n",
      "Epoch 8780 - Train Loss: 0.140780, Train Acc: 0.755128 | Val Loss: 0.155614, Val Acc: 0.731959\n",
      "Epoch 8781 - Train Loss: 0.140770, Train Acc: 0.755128 | Val Loss: 0.155605, Val Acc: 0.731959\n",
      "Epoch 8782 - Train Loss: 0.140760, Train Acc: 0.755128 | Val Loss: 0.155596, Val Acc: 0.731959\n",
      "Epoch 8783 - Train Loss: 0.140750, Train Acc: 0.756410 | Val Loss: 0.155587, Val Acc: 0.731959\n",
      "Epoch 8784 - Train Loss: 0.140739, Train Acc: 0.756410 | Val Loss: 0.155578, Val Acc: 0.731959\n",
      "Epoch 8785 - Train Loss: 0.140729, Train Acc: 0.756410 | Val Loss: 0.155569, Val Acc: 0.731959\n",
      "Epoch 8786 - Train Loss: 0.140719, Train Acc: 0.756410 | Val Loss: 0.155559, Val Acc: 0.731959\n",
      "Epoch 8787 - Train Loss: 0.140709, Train Acc: 0.756410 | Val Loss: 0.155550, Val Acc: 0.731959\n",
      "Epoch 8788 - Train Loss: 0.140699, Train Acc: 0.756410 | Val Loss: 0.155541, Val Acc: 0.731959\n",
      "Epoch 8789 - Train Loss: 0.140689, Train Acc: 0.756410 | Val Loss: 0.155532, Val Acc: 0.731959\n",
      "Epoch 8790 - Train Loss: 0.140679, Train Acc: 0.757692 | Val Loss: 0.155523, Val Acc: 0.731959\n",
      "Epoch 8791 - Train Loss: 0.140669, Train Acc: 0.757692 | Val Loss: 0.155514, Val Acc: 0.731959\n",
      "Epoch 8792 - Train Loss: 0.140659, Train Acc: 0.757692 | Val Loss: 0.155505, Val Acc: 0.731959\n",
      "Epoch 8793 - Train Loss: 0.140648, Train Acc: 0.757692 | Val Loss: 0.155496, Val Acc: 0.731959\n",
      "Epoch 8794 - Train Loss: 0.140638, Train Acc: 0.757692 | Val Loss: 0.155487, Val Acc: 0.731959\n",
      "Epoch 8795 - Train Loss: 0.140628, Train Acc: 0.757692 | Val Loss: 0.155478, Val Acc: 0.731959\n",
      "Epoch 8796 - Train Loss: 0.140618, Train Acc: 0.757692 | Val Loss: 0.155469, Val Acc: 0.731959\n",
      "Epoch 8797 - Train Loss: 0.140608, Train Acc: 0.757692 | Val Loss: 0.155460, Val Acc: 0.731959\n",
      "Epoch 8798 - Train Loss: 0.140598, Train Acc: 0.757692 | Val Loss: 0.155451, Val Acc: 0.731959\n",
      "Epoch 8799 - Train Loss: 0.140588, Train Acc: 0.757692 | Val Loss: 0.155442, Val Acc: 0.731959\n",
      "Epoch 8800 - Train Loss: 0.140578, Train Acc: 0.757692 | Val Loss: 0.155433, Val Acc: 0.731959\n",
      "Epoch 8801 - Train Loss: 0.140568, Train Acc: 0.757692 | Val Loss: 0.155424, Val Acc: 0.731959\n",
      "Epoch 8802 - Train Loss: 0.140558, Train Acc: 0.757692 | Val Loss: 0.155415, Val Acc: 0.731959\n",
      "Epoch 8803 - Train Loss: 0.140547, Train Acc: 0.757692 | Val Loss: 0.155406, Val Acc: 0.731959\n",
      "Epoch 8804 - Train Loss: 0.140537, Train Acc: 0.757692 | Val Loss: 0.155397, Val Acc: 0.731959\n",
      "Epoch 8805 - Train Loss: 0.140527, Train Acc: 0.757692 | Val Loss: 0.155388, Val Acc: 0.731959\n",
      "Epoch 8806 - Train Loss: 0.140517, Train Acc: 0.757692 | Val Loss: 0.155378, Val Acc: 0.731959\n",
      "Epoch 8807 - Train Loss: 0.140507, Train Acc: 0.757692 | Val Loss: 0.155369, Val Acc: 0.731959\n",
      "Epoch 8808 - Train Loss: 0.140497, Train Acc: 0.757692 | Val Loss: 0.155360, Val Acc: 0.731959\n",
      "Epoch 8809 - Train Loss: 0.140487, Train Acc: 0.757692 | Val Loss: 0.155351, Val Acc: 0.731959\n",
      "Epoch 8810 - Train Loss: 0.140477, Train Acc: 0.757692 | Val Loss: 0.155342, Val Acc: 0.731959\n",
      "Epoch 8811 - Train Loss: 0.140467, Train Acc: 0.757692 | Val Loss: 0.155333, Val Acc: 0.731959\n",
      "Epoch 8812 - Train Loss: 0.140457, Train Acc: 0.757692 | Val Loss: 0.155324, Val Acc: 0.731959\n",
      "Epoch 8813 - Train Loss: 0.140447, Train Acc: 0.757692 | Val Loss: 0.155315, Val Acc: 0.731959\n",
      "Epoch 8814 - Train Loss: 0.140437, Train Acc: 0.757692 | Val Loss: 0.155306, Val Acc: 0.731959\n",
      "Epoch 8815 - Train Loss: 0.140427, Train Acc: 0.757692 | Val Loss: 0.155297, Val Acc: 0.731959\n",
      "Epoch 8816 - Train Loss: 0.140416, Train Acc: 0.757692 | Val Loss: 0.155288, Val Acc: 0.731959\n",
      "Epoch 8817 - Train Loss: 0.140406, Train Acc: 0.757692 | Val Loss: 0.155279, Val Acc: 0.731959\n",
      "Epoch 8818 - Train Loss: 0.140396, Train Acc: 0.757692 | Val Loss: 0.155270, Val Acc: 0.731959\n",
      "Epoch 8819 - Train Loss: 0.140386, Train Acc: 0.757692 | Val Loss: 0.155261, Val Acc: 0.731959\n",
      "Epoch 8820 - Train Loss: 0.140376, Train Acc: 0.757692 | Val Loss: 0.155252, Val Acc: 0.731959\n",
      "Epoch 8821 - Train Loss: 0.140366, Train Acc: 0.757692 | Val Loss: 0.155243, Val Acc: 0.731959\n",
      "Epoch 8822 - Train Loss: 0.140356, Train Acc: 0.757692 | Val Loss: 0.155234, Val Acc: 0.731959\n",
      "Epoch 8823 - Train Loss: 0.140346, Train Acc: 0.757692 | Val Loss: 0.155225, Val Acc: 0.731959\n",
      "Epoch 8824 - Train Loss: 0.140336, Train Acc: 0.757692 | Val Loss: 0.155216, Val Acc: 0.731959\n",
      "Epoch 8825 - Train Loss: 0.140326, Train Acc: 0.757692 | Val Loss: 0.155207, Val Acc: 0.731959\n",
      "Epoch 8826 - Train Loss: 0.140316, Train Acc: 0.757692 | Val Loss: 0.155198, Val Acc: 0.731959\n",
      "Epoch 8827 - Train Loss: 0.140306, Train Acc: 0.757692 | Val Loss: 0.155189, Val Acc: 0.731959\n",
      "Epoch 8828 - Train Loss: 0.140296, Train Acc: 0.757692 | Val Loss: 0.155180, Val Acc: 0.731959\n",
      "Epoch 8829 - Train Loss: 0.140286, Train Acc: 0.757692 | Val Loss: 0.155171, Val Acc: 0.731959\n",
      "Epoch 8830 - Train Loss: 0.140276, Train Acc: 0.757692 | Val Loss: 0.155162, Val Acc: 0.731959\n",
      "Epoch 8831 - Train Loss: 0.140266, Train Acc: 0.757692 | Val Loss: 0.155153, Val Acc: 0.731959\n",
      "Epoch 8832 - Train Loss: 0.140256, Train Acc: 0.757692 | Val Loss: 0.155144, Val Acc: 0.731959\n",
      "Epoch 8833 - Train Loss: 0.140245, Train Acc: 0.757692 | Val Loss: 0.155135, Val Acc: 0.731959\n",
      "Epoch 8834 - Train Loss: 0.140235, Train Acc: 0.757692 | Val Loss: 0.155126, Val Acc: 0.731959\n",
      "Epoch 8835 - Train Loss: 0.140225, Train Acc: 0.757692 | Val Loss: 0.155117, Val Acc: 0.731959\n",
      "Epoch 8836 - Train Loss: 0.140215, Train Acc: 0.757692 | Val Loss: 0.155108, Val Acc: 0.731959\n",
      "Epoch 8837 - Train Loss: 0.140205, Train Acc: 0.757692 | Val Loss: 0.155099, Val Acc: 0.731959\n",
      "Epoch 8838 - Train Loss: 0.140195, Train Acc: 0.757692 | Val Loss: 0.155090, Val Acc: 0.731959\n",
      "Epoch 8839 - Train Loss: 0.140185, Train Acc: 0.757692 | Val Loss: 0.155081, Val Acc: 0.731959\n",
      "Epoch 8840 - Train Loss: 0.140175, Train Acc: 0.757692 | Val Loss: 0.155072, Val Acc: 0.731959\n",
      "Epoch 8841 - Train Loss: 0.140165, Train Acc: 0.757692 | Val Loss: 0.155063, Val Acc: 0.731959\n",
      "Epoch 8842 - Train Loss: 0.140155, Train Acc: 0.757692 | Val Loss: 0.155054, Val Acc: 0.731959\n",
      "Epoch 8843 - Train Loss: 0.140145, Train Acc: 0.757692 | Val Loss: 0.155046, Val Acc: 0.731959\n",
      "Epoch 8844 - Train Loss: 0.140135, Train Acc: 0.757692 | Val Loss: 0.155037, Val Acc: 0.731959\n",
      "Epoch 8845 - Train Loss: 0.140125, Train Acc: 0.757692 | Val Loss: 0.155027, Val Acc: 0.731959\n",
      "Epoch 8846 - Train Loss: 0.140115, Train Acc: 0.757692 | Val Loss: 0.155018, Val Acc: 0.731959\n",
      "Epoch 8847 - Train Loss: 0.140105, Train Acc: 0.757692 | Val Loss: 0.155009, Val Acc: 0.731959\n",
      "Epoch 8848 - Train Loss: 0.140095, Train Acc: 0.757692 | Val Loss: 0.155000, Val Acc: 0.731959\n",
      "Epoch 8849 - Train Loss: 0.140085, Train Acc: 0.757692 | Val Loss: 0.154991, Val Acc: 0.731959\n",
      "Epoch 8850 - Train Loss: 0.140075, Train Acc: 0.757692 | Val Loss: 0.154982, Val Acc: 0.731959\n",
      "Epoch 8851 - Train Loss: 0.140065, Train Acc: 0.757692 | Val Loss: 0.154973, Val Acc: 0.731959\n",
      "Epoch 8852 - Train Loss: 0.140055, Train Acc: 0.757692 | Val Loss: 0.154964, Val Acc: 0.731959\n",
      "Epoch 8853 - Train Loss: 0.140045, Train Acc: 0.757692 | Val Loss: 0.154955, Val Acc: 0.731959\n",
      "Epoch 8854 - Train Loss: 0.140035, Train Acc: 0.757692 | Val Loss: 0.154946, Val Acc: 0.731959\n",
      "Epoch 8855 - Train Loss: 0.140025, Train Acc: 0.757692 | Val Loss: 0.154937, Val Acc: 0.731959\n",
      "Epoch 8856 - Train Loss: 0.140015, Train Acc: 0.757692 | Val Loss: 0.154928, Val Acc: 0.731959\n",
      "Epoch 8857 - Train Loss: 0.140005, Train Acc: 0.757692 | Val Loss: 0.154919, Val Acc: 0.731959\n",
      "Epoch 8858 - Train Loss: 0.139995, Train Acc: 0.757692 | Val Loss: 0.154911, Val Acc: 0.731959\n",
      "Epoch 8859 - Train Loss: 0.139985, Train Acc: 0.757692 | Val Loss: 0.154902, Val Acc: 0.731959\n",
      "Epoch 8860 - Train Loss: 0.139975, Train Acc: 0.758974 | Val Loss: 0.154893, Val Acc: 0.731959\n",
      "Epoch 8861 - Train Loss: 0.139965, Train Acc: 0.758974 | Val Loss: 0.154884, Val Acc: 0.731959\n",
      "Epoch 8862 - Train Loss: 0.139955, Train Acc: 0.758974 | Val Loss: 0.154875, Val Acc: 0.731959\n",
      "Epoch 8863 - Train Loss: 0.139945, Train Acc: 0.758974 | Val Loss: 0.154866, Val Acc: 0.731959\n",
      "Epoch 8864 - Train Loss: 0.139935, Train Acc: 0.758974 | Val Loss: 0.154857, Val Acc: 0.731959\n",
      "Epoch 8865 - Train Loss: 0.139925, Train Acc: 0.758974 | Val Loss: 0.154848, Val Acc: 0.731959\n",
      "Epoch 8866 - Train Loss: 0.139915, Train Acc: 0.758974 | Val Loss: 0.154839, Val Acc: 0.731959\n",
      "Epoch 8867 - Train Loss: 0.139905, Train Acc: 0.758974 | Val Loss: 0.154830, Val Acc: 0.731959\n",
      "Epoch 8868 - Train Loss: 0.139895, Train Acc: 0.758974 | Val Loss: 0.154821, Val Acc: 0.731959\n",
      "Epoch 8869 - Train Loss: 0.139885, Train Acc: 0.758974 | Val Loss: 0.154812, Val Acc: 0.731959\n",
      "Epoch 8870 - Train Loss: 0.139875, Train Acc: 0.758974 | Val Loss: 0.154803, Val Acc: 0.731959\n",
      "Epoch 8871 - Train Loss: 0.139865, Train Acc: 0.758974 | Val Loss: 0.154794, Val Acc: 0.731959\n",
      "Epoch 8872 - Train Loss: 0.139855, Train Acc: 0.758974 | Val Loss: 0.154785, Val Acc: 0.731959\n",
      "Epoch 8873 - Train Loss: 0.139845, Train Acc: 0.758974 | Val Loss: 0.154776, Val Acc: 0.731959\n",
      "Epoch 8874 - Train Loss: 0.139835, Train Acc: 0.758974 | Val Loss: 0.154767, Val Acc: 0.731959\n",
      "Epoch 8875 - Train Loss: 0.139825, Train Acc: 0.758974 | Val Loss: 0.154758, Val Acc: 0.731959\n",
      "Epoch 8876 - Train Loss: 0.139815, Train Acc: 0.758974 | Val Loss: 0.154749, Val Acc: 0.731959\n",
      "Epoch 8877 - Train Loss: 0.139805, Train Acc: 0.758974 | Val Loss: 0.154740, Val Acc: 0.731959\n",
      "Epoch 8878 - Train Loss: 0.139795, Train Acc: 0.758974 | Val Loss: 0.154731, Val Acc: 0.731959\n",
      "Epoch 8879 - Train Loss: 0.139785, Train Acc: 0.758974 | Val Loss: 0.154722, Val Acc: 0.731959\n",
      "Epoch 8880 - Train Loss: 0.139775, Train Acc: 0.758974 | Val Loss: 0.154714, Val Acc: 0.731959\n",
      "Epoch 8881 - Train Loss: 0.139765, Train Acc: 0.758974 | Val Loss: 0.154705, Val Acc: 0.731959\n",
      "Epoch 8882 - Train Loss: 0.139755, Train Acc: 0.760256 | Val Loss: 0.154696, Val Acc: 0.731959\n",
      "Epoch 8883 - Train Loss: 0.139745, Train Acc: 0.760256 | Val Loss: 0.154687, Val Acc: 0.731959\n",
      "Epoch 8884 - Train Loss: 0.139735, Train Acc: 0.760256 | Val Loss: 0.154678, Val Acc: 0.731959\n",
      "Epoch 8885 - Train Loss: 0.139725, Train Acc: 0.760256 | Val Loss: 0.154669, Val Acc: 0.731959\n",
      "Epoch 8886 - Train Loss: 0.139715, Train Acc: 0.760256 | Val Loss: 0.154660, Val Acc: 0.731959\n",
      "Epoch 8887 - Train Loss: 0.139705, Train Acc: 0.760256 | Val Loss: 0.154651, Val Acc: 0.731959\n",
      "Epoch 8888 - Train Loss: 0.139695, Train Acc: 0.760256 | Val Loss: 0.154642, Val Acc: 0.731959\n",
      "Epoch 8889 - Train Loss: 0.139685, Train Acc: 0.760256 | Val Loss: 0.154633, Val Acc: 0.731959\n",
      "Epoch 8890 - Train Loss: 0.139675, Train Acc: 0.760256 | Val Loss: 0.154624, Val Acc: 0.731959\n",
      "Epoch 8891 - Train Loss: 0.139665, Train Acc: 0.760256 | Val Loss: 0.154615, Val Acc: 0.731959\n",
      "Epoch 8892 - Train Loss: 0.139655, Train Acc: 0.760256 | Val Loss: 0.154607, Val Acc: 0.731959\n",
      "Epoch 8893 - Train Loss: 0.139645, Train Acc: 0.760256 | Val Loss: 0.154598, Val Acc: 0.731959\n",
      "Epoch 8894 - Train Loss: 0.139635, Train Acc: 0.760256 | Val Loss: 0.154589, Val Acc: 0.731959\n",
      "Epoch 8895 - Train Loss: 0.139625, Train Acc: 0.760256 | Val Loss: 0.154580, Val Acc: 0.731959\n",
      "Epoch 8896 - Train Loss: 0.139615, Train Acc: 0.760256 | Val Loss: 0.154571, Val Acc: 0.731959\n",
      "Epoch 8897 - Train Loss: 0.139605, Train Acc: 0.760256 | Val Loss: 0.154562, Val Acc: 0.731959\n",
      "Epoch 8898 - Train Loss: 0.139595, Train Acc: 0.760256 | Val Loss: 0.154553, Val Acc: 0.731959\n",
      "Epoch 8899 - Train Loss: 0.139585, Train Acc: 0.760256 | Val Loss: 0.154544, Val Acc: 0.731959\n",
      "Epoch 8900 - Train Loss: 0.139576, Train Acc: 0.760256 | Val Loss: 0.154535, Val Acc: 0.731959\n",
      "Epoch 8901 - Train Loss: 0.139566, Train Acc: 0.760256 | Val Loss: 0.154526, Val Acc: 0.731959\n",
      "Epoch 8902 - Train Loss: 0.139556, Train Acc: 0.760256 | Val Loss: 0.154518, Val Acc: 0.731959\n",
      "Epoch 8903 - Train Loss: 0.139546, Train Acc: 0.760256 | Val Loss: 0.154509, Val Acc: 0.731959\n",
      "Epoch 8904 - Train Loss: 0.139536, Train Acc: 0.760256 | Val Loss: 0.154500, Val Acc: 0.731959\n",
      "Epoch 8905 - Train Loss: 0.139526, Train Acc: 0.760256 | Val Loss: 0.154491, Val Acc: 0.731959\n",
      "Epoch 8906 - Train Loss: 0.139516, Train Acc: 0.760256 | Val Loss: 0.154482, Val Acc: 0.731959\n",
      "Epoch 8907 - Train Loss: 0.139506, Train Acc: 0.760256 | Val Loss: 0.154473, Val Acc: 0.731959\n",
      "Epoch 8908 - Train Loss: 0.139496, Train Acc: 0.760256 | Val Loss: 0.154464, Val Acc: 0.731959\n",
      "Epoch 8909 - Train Loss: 0.139486, Train Acc: 0.760256 | Val Loss: 0.154455, Val Acc: 0.731959\n",
      "Epoch 8910 - Train Loss: 0.139476, Train Acc: 0.760256 | Val Loss: 0.154446, Val Acc: 0.731959\n",
      "Epoch 8911 - Train Loss: 0.139466, Train Acc: 0.760256 | Val Loss: 0.154438, Val Acc: 0.731959\n",
      "Epoch 8912 - Train Loss: 0.139456, Train Acc: 0.760256 | Val Loss: 0.154429, Val Acc: 0.731959\n",
      "Epoch 8913 - Train Loss: 0.139446, Train Acc: 0.760256 | Val Loss: 0.154420, Val Acc: 0.731959\n",
      "Epoch 8914 - Train Loss: 0.139436, Train Acc: 0.760256 | Val Loss: 0.154411, Val Acc: 0.731959\n",
      "Epoch 8915 - Train Loss: 0.139426, Train Acc: 0.760256 | Val Loss: 0.154402, Val Acc: 0.731959\n",
      "Epoch 8916 - Train Loss: 0.139416, Train Acc: 0.760256 | Val Loss: 0.154393, Val Acc: 0.731959\n",
      "Epoch 8917 - Train Loss: 0.139407, Train Acc: 0.760256 | Val Loss: 0.154384, Val Acc: 0.731959\n",
      "Epoch 8918 - Train Loss: 0.139397, Train Acc: 0.760256 | Val Loss: 0.154376, Val Acc: 0.731959\n",
      "Epoch 8919 - Train Loss: 0.139387, Train Acc: 0.760256 | Val Loss: 0.154367, Val Acc: 0.731959\n",
      "Epoch 8920 - Train Loss: 0.139377, Train Acc: 0.760256 | Val Loss: 0.154358, Val Acc: 0.731959\n",
      "Epoch 8921 - Train Loss: 0.139367, Train Acc: 0.760256 | Val Loss: 0.154349, Val Acc: 0.731959\n",
      "Epoch 8922 - Train Loss: 0.139357, Train Acc: 0.760256 | Val Loss: 0.154340, Val Acc: 0.731959\n",
      "Epoch 8923 - Train Loss: 0.139347, Train Acc: 0.760256 | Val Loss: 0.154331, Val Acc: 0.731959\n",
      "Epoch 8924 - Train Loss: 0.139337, Train Acc: 0.760256 | Val Loss: 0.154322, Val Acc: 0.731959\n",
      "Epoch 8925 - Train Loss: 0.139327, Train Acc: 0.760256 | Val Loss: 0.154314, Val Acc: 0.731959\n",
      "Epoch 8926 - Train Loss: 0.139317, Train Acc: 0.760256 | Val Loss: 0.154305, Val Acc: 0.731959\n",
      "Epoch 8927 - Train Loss: 0.139307, Train Acc: 0.760256 | Val Loss: 0.154296, Val Acc: 0.731959\n",
      "Epoch 8928 - Train Loss: 0.139297, Train Acc: 0.760256 | Val Loss: 0.154287, Val Acc: 0.731959\n",
      "Epoch 8929 - Train Loss: 0.139287, Train Acc: 0.760256 | Val Loss: 0.154278, Val Acc: 0.731959\n",
      "Epoch 8930 - Train Loss: 0.139278, Train Acc: 0.760256 | Val Loss: 0.154269, Val Acc: 0.731959\n",
      "Epoch 8931 - Train Loss: 0.139268, Train Acc: 0.760256 | Val Loss: 0.154260, Val Acc: 0.731959\n",
      "Epoch 8932 - Train Loss: 0.139258, Train Acc: 0.760256 | Val Loss: 0.154252, Val Acc: 0.731959\n",
      "Epoch 8933 - Train Loss: 0.139248, Train Acc: 0.760256 | Val Loss: 0.154243, Val Acc: 0.731959\n",
      "Epoch 8934 - Train Loss: 0.139238, Train Acc: 0.760256 | Val Loss: 0.154234, Val Acc: 0.731959\n",
      "Epoch 8935 - Train Loss: 0.139228, Train Acc: 0.760256 | Val Loss: 0.154225, Val Acc: 0.731959\n",
      "Epoch 8936 - Train Loss: 0.139218, Train Acc: 0.760256 | Val Loss: 0.154216, Val Acc: 0.731959\n",
      "Epoch 8937 - Train Loss: 0.139208, Train Acc: 0.760256 | Val Loss: 0.154207, Val Acc: 0.731959\n",
      "Epoch 8938 - Train Loss: 0.139198, Train Acc: 0.760256 | Val Loss: 0.154199, Val Acc: 0.731959\n",
      "Epoch 8939 - Train Loss: 0.139188, Train Acc: 0.760256 | Val Loss: 0.154190, Val Acc: 0.731959\n",
      "Epoch 8940 - Train Loss: 0.139179, Train Acc: 0.760256 | Val Loss: 0.154181, Val Acc: 0.731959\n",
      "Epoch 8941 - Train Loss: 0.139169, Train Acc: 0.760256 | Val Loss: 0.154172, Val Acc: 0.731959\n",
      "Epoch 8942 - Train Loss: 0.139159, Train Acc: 0.760256 | Val Loss: 0.154163, Val Acc: 0.731959\n",
      "Epoch 8943 - Train Loss: 0.139149, Train Acc: 0.760256 | Val Loss: 0.154154, Val Acc: 0.742268\n",
      "Epoch 8944 - Train Loss: 0.139139, Train Acc: 0.760256 | Val Loss: 0.154146, Val Acc: 0.742268\n",
      "Epoch 8945 - Train Loss: 0.139129, Train Acc: 0.760256 | Val Loss: 0.154137, Val Acc: 0.742268\n",
      "Epoch 8946 - Train Loss: 0.139119, Train Acc: 0.760256 | Val Loss: 0.154128, Val Acc: 0.742268\n",
      "Epoch 8947 - Train Loss: 0.139109, Train Acc: 0.760256 | Val Loss: 0.154119, Val Acc: 0.742268\n",
      "Epoch 8948 - Train Loss: 0.139099, Train Acc: 0.760256 | Val Loss: 0.154110, Val Acc: 0.742268\n",
      "Epoch 8949 - Train Loss: 0.139090, Train Acc: 0.760256 | Val Loss: 0.154102, Val Acc: 0.742268\n",
      "Epoch 8950 - Train Loss: 0.139080, Train Acc: 0.760256 | Val Loss: 0.154093, Val Acc: 0.742268\n",
      "Epoch 8951 - Train Loss: 0.139070, Train Acc: 0.760256 | Val Loss: 0.154084, Val Acc: 0.742268\n",
      "Epoch 8952 - Train Loss: 0.139060, Train Acc: 0.760256 | Val Loss: 0.154075, Val Acc: 0.742268\n",
      "Epoch 8953 - Train Loss: 0.139050, Train Acc: 0.760256 | Val Loss: 0.154066, Val Acc: 0.742268\n",
      "Epoch 8954 - Train Loss: 0.139040, Train Acc: 0.760256 | Val Loss: 0.154058, Val Acc: 0.742268\n",
      "Epoch 8955 - Train Loss: 0.139030, Train Acc: 0.760256 | Val Loss: 0.154049, Val Acc: 0.742268\n",
      "Epoch 8956 - Train Loss: 0.139020, Train Acc: 0.760256 | Val Loss: 0.154040, Val Acc: 0.742268\n",
      "Epoch 8957 - Train Loss: 0.139010, Train Acc: 0.760256 | Val Loss: 0.154031, Val Acc: 0.742268\n",
      "Epoch 8958 - Train Loss: 0.139001, Train Acc: 0.760256 | Val Loss: 0.154022, Val Acc: 0.742268\n",
      "Epoch 8959 - Train Loss: 0.138991, Train Acc: 0.760256 | Val Loss: 0.154014, Val Acc: 0.742268\n",
      "Epoch 8960 - Train Loss: 0.138981, Train Acc: 0.760256 | Val Loss: 0.154005, Val Acc: 0.742268\n",
      "Epoch 8961 - Train Loss: 0.138971, Train Acc: 0.760256 | Val Loss: 0.153996, Val Acc: 0.742268\n",
      "Epoch 8962 - Train Loss: 0.138961, Train Acc: 0.760256 | Val Loss: 0.153987, Val Acc: 0.742268\n",
      "Epoch 8963 - Train Loss: 0.138951, Train Acc: 0.760256 | Val Loss: 0.153978, Val Acc: 0.742268\n",
      "Epoch 8964 - Train Loss: 0.138941, Train Acc: 0.760256 | Val Loss: 0.153970, Val Acc: 0.742268\n",
      "Epoch 8965 - Train Loss: 0.138932, Train Acc: 0.760256 | Val Loss: 0.153961, Val Acc: 0.742268\n",
      "Epoch 8966 - Train Loss: 0.138922, Train Acc: 0.760256 | Val Loss: 0.153952, Val Acc: 0.742268\n",
      "Epoch 8967 - Train Loss: 0.138912, Train Acc: 0.760256 | Val Loss: 0.153943, Val Acc: 0.742268\n",
      "Epoch 8968 - Train Loss: 0.138902, Train Acc: 0.760256 | Val Loss: 0.153934, Val Acc: 0.742268\n",
      "Epoch 8969 - Train Loss: 0.138892, Train Acc: 0.760256 | Val Loss: 0.153926, Val Acc: 0.742268\n",
      "Epoch 8970 - Train Loss: 0.138882, Train Acc: 0.760256 | Val Loss: 0.153917, Val Acc: 0.742268\n",
      "Epoch 8971 - Train Loss: 0.138872, Train Acc: 0.761538 | Val Loss: 0.153908, Val Acc: 0.742268\n",
      "Epoch 8972 - Train Loss: 0.138863, Train Acc: 0.761538 | Val Loss: 0.153899, Val Acc: 0.742268\n",
      "Epoch 8973 - Train Loss: 0.138853, Train Acc: 0.761538 | Val Loss: 0.153891, Val Acc: 0.742268\n",
      "Epoch 8974 - Train Loss: 0.138843, Train Acc: 0.761538 | Val Loss: 0.153882, Val Acc: 0.742268\n",
      "Epoch 8975 - Train Loss: 0.138833, Train Acc: 0.761538 | Val Loss: 0.153873, Val Acc: 0.742268\n",
      "Epoch 8976 - Train Loss: 0.138823, Train Acc: 0.761538 | Val Loss: 0.153864, Val Acc: 0.742268\n",
      "Epoch 8977 - Train Loss: 0.138813, Train Acc: 0.761538 | Val Loss: 0.153856, Val Acc: 0.742268\n",
      "Epoch 8978 - Train Loss: 0.138803, Train Acc: 0.761538 | Val Loss: 0.153847, Val Acc: 0.742268\n",
      "Epoch 8979 - Train Loss: 0.138794, Train Acc: 0.761538 | Val Loss: 0.153838, Val Acc: 0.742268\n",
      "Epoch 8980 - Train Loss: 0.138784, Train Acc: 0.761538 | Val Loss: 0.153829, Val Acc: 0.742268\n",
      "Epoch 8981 - Train Loss: 0.138774, Train Acc: 0.761538 | Val Loss: 0.153820, Val Acc: 0.742268\n",
      "Epoch 8982 - Train Loss: 0.138764, Train Acc: 0.761538 | Val Loss: 0.153812, Val Acc: 0.742268\n",
      "Epoch 8983 - Train Loss: 0.138754, Train Acc: 0.761538 | Val Loss: 0.153803, Val Acc: 0.742268\n",
      "Epoch 8984 - Train Loss: 0.138744, Train Acc: 0.761538 | Val Loss: 0.153794, Val Acc: 0.742268\n",
      "Epoch 8985 - Train Loss: 0.138735, Train Acc: 0.761538 | Val Loss: 0.153785, Val Acc: 0.742268\n",
      "Epoch 8986 - Train Loss: 0.138725, Train Acc: 0.761538 | Val Loss: 0.153777, Val Acc: 0.742268\n",
      "Epoch 8987 - Train Loss: 0.138715, Train Acc: 0.761538 | Val Loss: 0.153768, Val Acc: 0.742268\n",
      "Epoch 8988 - Train Loss: 0.138705, Train Acc: 0.761538 | Val Loss: 0.153759, Val Acc: 0.742268\n",
      "Epoch 8989 - Train Loss: 0.138695, Train Acc: 0.761538 | Val Loss: 0.153750, Val Acc: 0.742268\n",
      "Epoch 8990 - Train Loss: 0.138685, Train Acc: 0.761538 | Val Loss: 0.153742, Val Acc: 0.742268\n",
      "Epoch 8991 - Train Loss: 0.138676, Train Acc: 0.761538 | Val Loss: 0.153733, Val Acc: 0.742268\n",
      "Epoch 8992 - Train Loss: 0.138666, Train Acc: 0.761538 | Val Loss: 0.153724, Val Acc: 0.742268\n",
      "Epoch 8993 - Train Loss: 0.138656, Train Acc: 0.762821 | Val Loss: 0.153715, Val Acc: 0.742268\n",
      "Epoch 8994 - Train Loss: 0.138646, Train Acc: 0.762821 | Val Loss: 0.153707, Val Acc: 0.742268\n",
      "Epoch 8995 - Train Loss: 0.138636, Train Acc: 0.762821 | Val Loss: 0.153698, Val Acc: 0.742268\n",
      "Epoch 8996 - Train Loss: 0.138627, Train Acc: 0.762821 | Val Loss: 0.153689, Val Acc: 0.742268\n",
      "Epoch 8997 - Train Loss: 0.138617, Train Acc: 0.762821 | Val Loss: 0.153680, Val Acc: 0.742268\n",
      "Epoch 8998 - Train Loss: 0.138607, Train Acc: 0.762821 | Val Loss: 0.153672, Val Acc: 0.742268\n",
      "Epoch 8999 - Train Loss: 0.138597, Train Acc: 0.762821 | Val Loss: 0.153663, Val Acc: 0.742268\n",
      "Epoch 9000 - Train Loss: 0.138587, Train Acc: 0.762821 | Val Loss: 0.153654, Val Acc: 0.742268\n",
      "Epoch 9001 - Train Loss: 0.138577, Train Acc: 0.762821 | Val Loss: 0.153646, Val Acc: 0.742268\n",
      "Epoch 9002 - Train Loss: 0.138568, Train Acc: 0.762821 | Val Loss: 0.153637, Val Acc: 0.742268\n",
      "Epoch 9003 - Train Loss: 0.138558, Train Acc: 0.762821 | Val Loss: 0.153628, Val Acc: 0.742268\n",
      "Epoch 9004 - Train Loss: 0.138548, Train Acc: 0.762821 | Val Loss: 0.153619, Val Acc: 0.742268\n",
      "Epoch 9005 - Train Loss: 0.138538, Train Acc: 0.762821 | Val Loss: 0.153611, Val Acc: 0.742268\n",
      "Epoch 9006 - Train Loss: 0.138528, Train Acc: 0.762821 | Val Loss: 0.153602, Val Acc: 0.742268\n",
      "Epoch 9007 - Train Loss: 0.138519, Train Acc: 0.762821 | Val Loss: 0.153593, Val Acc: 0.742268\n",
      "Epoch 9008 - Train Loss: 0.138509, Train Acc: 0.762821 | Val Loss: 0.153584, Val Acc: 0.742268\n",
      "Epoch 9009 - Train Loss: 0.138499, Train Acc: 0.762821 | Val Loss: 0.153576, Val Acc: 0.742268\n",
      "Epoch 9010 - Train Loss: 0.138489, Train Acc: 0.762821 | Val Loss: 0.153567, Val Acc: 0.742268\n",
      "Epoch 9011 - Train Loss: 0.138479, Train Acc: 0.762821 | Val Loss: 0.153558, Val Acc: 0.742268\n",
      "Epoch 9012 - Train Loss: 0.138470, Train Acc: 0.762821 | Val Loss: 0.153550, Val Acc: 0.742268\n",
      "Epoch 9013 - Train Loss: 0.138460, Train Acc: 0.762821 | Val Loss: 0.153541, Val Acc: 0.742268\n",
      "Epoch 9014 - Train Loss: 0.138450, Train Acc: 0.762821 | Val Loss: 0.153532, Val Acc: 0.742268\n",
      "Epoch 9015 - Train Loss: 0.138440, Train Acc: 0.762821 | Val Loss: 0.153523, Val Acc: 0.742268\n",
      "Epoch 9016 - Train Loss: 0.138430, Train Acc: 0.762821 | Val Loss: 0.153515, Val Acc: 0.742268\n",
      "Epoch 9017 - Train Loss: 0.138421, Train Acc: 0.762821 | Val Loss: 0.153506, Val Acc: 0.742268\n",
      "Epoch 9018 - Train Loss: 0.138411, Train Acc: 0.762821 | Val Loss: 0.153497, Val Acc: 0.742268\n",
      "Epoch 9019 - Train Loss: 0.138401, Train Acc: 0.762821 | Val Loss: 0.153489, Val Acc: 0.742268\n",
      "Epoch 9020 - Train Loss: 0.138391, Train Acc: 0.765385 | Val Loss: 0.153480, Val Acc: 0.742268\n",
      "Epoch 9021 - Train Loss: 0.138382, Train Acc: 0.765385 | Val Loss: 0.153471, Val Acc: 0.742268\n",
      "Epoch 9022 - Train Loss: 0.138372, Train Acc: 0.765385 | Val Loss: 0.153463, Val Acc: 0.742268\n",
      "Epoch 9023 - Train Loss: 0.138362, Train Acc: 0.765385 | Val Loss: 0.153454, Val Acc: 0.742268\n",
      "Epoch 9024 - Train Loss: 0.138352, Train Acc: 0.765385 | Val Loss: 0.153445, Val Acc: 0.742268\n",
      "Epoch 9025 - Train Loss: 0.138342, Train Acc: 0.765385 | Val Loss: 0.153436, Val Acc: 0.742268\n",
      "Epoch 9026 - Train Loss: 0.138333, Train Acc: 0.765385 | Val Loss: 0.153428, Val Acc: 0.742268\n",
      "Epoch 9027 - Train Loss: 0.138323, Train Acc: 0.765385 | Val Loss: 0.153419, Val Acc: 0.742268\n",
      "Epoch 9028 - Train Loss: 0.138313, Train Acc: 0.765385 | Val Loss: 0.153410, Val Acc: 0.742268\n",
      "Epoch 9029 - Train Loss: 0.138303, Train Acc: 0.765385 | Val Loss: 0.153402, Val Acc: 0.742268\n",
      "Epoch 9030 - Train Loss: 0.138294, Train Acc: 0.765385 | Val Loss: 0.153393, Val Acc: 0.742268\n",
      "Epoch 9031 - Train Loss: 0.138284, Train Acc: 0.765385 | Val Loss: 0.153384, Val Acc: 0.742268\n",
      "Epoch 9032 - Train Loss: 0.138274, Train Acc: 0.766667 | Val Loss: 0.153376, Val Acc: 0.742268\n",
      "Epoch 9033 - Train Loss: 0.138264, Train Acc: 0.766667 | Val Loss: 0.153367, Val Acc: 0.742268\n",
      "Epoch 9034 - Train Loss: 0.138254, Train Acc: 0.766667 | Val Loss: 0.153358, Val Acc: 0.742268\n",
      "Epoch 9035 - Train Loss: 0.138245, Train Acc: 0.766667 | Val Loss: 0.153350, Val Acc: 0.742268\n",
      "Epoch 9036 - Train Loss: 0.138235, Train Acc: 0.766667 | Val Loss: 0.153341, Val Acc: 0.742268\n",
      "Epoch 9037 - Train Loss: 0.138225, Train Acc: 0.766667 | Val Loss: 0.153332, Val Acc: 0.742268\n",
      "Epoch 9038 - Train Loss: 0.138215, Train Acc: 0.766667 | Val Loss: 0.153324, Val Acc: 0.742268\n",
      "Epoch 9039 - Train Loss: 0.138206, Train Acc: 0.766667 | Val Loss: 0.153315, Val Acc: 0.742268\n",
      "Epoch 9040 - Train Loss: 0.138196, Train Acc: 0.766667 | Val Loss: 0.153306, Val Acc: 0.742268\n",
      "Epoch 9041 - Train Loss: 0.138186, Train Acc: 0.766667 | Val Loss: 0.153298, Val Acc: 0.742268\n",
      "Epoch 9042 - Train Loss: 0.138176, Train Acc: 0.766667 | Val Loss: 0.153289, Val Acc: 0.742268\n",
      "Epoch 9043 - Train Loss: 0.138167, Train Acc: 0.766667 | Val Loss: 0.153280, Val Acc: 0.742268\n",
      "Epoch 9044 - Train Loss: 0.138157, Train Acc: 0.766667 | Val Loss: 0.153272, Val Acc: 0.742268\n",
      "Epoch 9045 - Train Loss: 0.138147, Train Acc: 0.766667 | Val Loss: 0.153263, Val Acc: 0.742268\n",
      "Epoch 9046 - Train Loss: 0.138137, Train Acc: 0.766667 | Val Loss: 0.153254, Val Acc: 0.742268\n",
      "Epoch 9047 - Train Loss: 0.138128, Train Acc: 0.766667 | Val Loss: 0.153246, Val Acc: 0.742268\n",
      "Epoch 9048 - Train Loss: 0.138118, Train Acc: 0.766667 | Val Loss: 0.153237, Val Acc: 0.742268\n",
      "Epoch 9049 - Train Loss: 0.138108, Train Acc: 0.766667 | Val Loss: 0.153228, Val Acc: 0.742268\n",
      "Epoch 9050 - Train Loss: 0.138098, Train Acc: 0.766667 | Val Loss: 0.153220, Val Acc: 0.742268\n",
      "Epoch 9051 - Train Loss: 0.138089, Train Acc: 0.766667 | Val Loss: 0.153211, Val Acc: 0.742268\n",
      "Epoch 9052 - Train Loss: 0.138079, Train Acc: 0.766667 | Val Loss: 0.153202, Val Acc: 0.742268\n",
      "Epoch 9053 - Train Loss: 0.138069, Train Acc: 0.766667 | Val Loss: 0.153194, Val Acc: 0.742268\n",
      "Epoch 9054 - Train Loss: 0.138059, Train Acc: 0.766667 | Val Loss: 0.153185, Val Acc: 0.742268\n",
      "Epoch 9055 - Train Loss: 0.138050, Train Acc: 0.766667 | Val Loss: 0.153176, Val Acc: 0.742268\n",
      "Epoch 9056 - Train Loss: 0.138040, Train Acc: 0.766667 | Val Loss: 0.153168, Val Acc: 0.742268\n",
      "Epoch 9057 - Train Loss: 0.138030, Train Acc: 0.766667 | Val Loss: 0.153159, Val Acc: 0.742268\n",
      "Epoch 9058 - Train Loss: 0.138021, Train Acc: 0.766667 | Val Loss: 0.153150, Val Acc: 0.742268\n",
      "Epoch 9059 - Train Loss: 0.138011, Train Acc: 0.766667 | Val Loss: 0.153142, Val Acc: 0.742268\n",
      "Epoch 9060 - Train Loss: 0.138001, Train Acc: 0.766667 | Val Loss: 0.153133, Val Acc: 0.742268\n",
      "Epoch 9061 - Train Loss: 0.137991, Train Acc: 0.766667 | Val Loss: 0.153124, Val Acc: 0.742268\n",
      "Epoch 9062 - Train Loss: 0.137982, Train Acc: 0.766667 | Val Loss: 0.153116, Val Acc: 0.742268\n",
      "Epoch 9063 - Train Loss: 0.137972, Train Acc: 0.766667 | Val Loss: 0.153107, Val Acc: 0.742268\n",
      "Epoch 9064 - Train Loss: 0.137962, Train Acc: 0.767949 | Val Loss: 0.153099, Val Acc: 0.742268\n",
      "Epoch 9065 - Train Loss: 0.137952, Train Acc: 0.767949 | Val Loss: 0.153090, Val Acc: 0.742268\n",
      "Epoch 9066 - Train Loss: 0.137943, Train Acc: 0.769231 | Val Loss: 0.153081, Val Acc: 0.742268\n",
      "Epoch 9067 - Train Loss: 0.137933, Train Acc: 0.769231 | Val Loss: 0.153073, Val Acc: 0.742268\n",
      "Epoch 9068 - Train Loss: 0.137923, Train Acc: 0.769231 | Val Loss: 0.153064, Val Acc: 0.742268\n",
      "Epoch 9069 - Train Loss: 0.137914, Train Acc: 0.769231 | Val Loss: 0.153055, Val Acc: 0.742268\n",
      "Epoch 9070 - Train Loss: 0.137904, Train Acc: 0.769231 | Val Loss: 0.153047, Val Acc: 0.742268\n",
      "Epoch 9071 - Train Loss: 0.137894, Train Acc: 0.769231 | Val Loss: 0.153038, Val Acc: 0.742268\n",
      "Epoch 9072 - Train Loss: 0.137884, Train Acc: 0.769231 | Val Loss: 0.153030, Val Acc: 0.742268\n",
      "Epoch 9073 - Train Loss: 0.137875, Train Acc: 0.769231 | Val Loss: 0.153021, Val Acc: 0.742268\n",
      "Epoch 9074 - Train Loss: 0.137865, Train Acc: 0.769231 | Val Loss: 0.153012, Val Acc: 0.742268\n",
      "Epoch 9075 - Train Loss: 0.137855, Train Acc: 0.769231 | Val Loss: 0.153004, Val Acc: 0.742268\n",
      "Epoch 9076 - Train Loss: 0.137846, Train Acc: 0.769231 | Val Loss: 0.152995, Val Acc: 0.742268\n",
      "Epoch 9077 - Train Loss: 0.137836, Train Acc: 0.769231 | Val Loss: 0.152986, Val Acc: 0.742268\n",
      "Epoch 9078 - Train Loss: 0.137826, Train Acc: 0.769231 | Val Loss: 0.152978, Val Acc: 0.742268\n",
      "Epoch 9079 - Train Loss: 0.137817, Train Acc: 0.769231 | Val Loss: 0.152969, Val Acc: 0.742268\n",
      "Epoch 9080 - Train Loss: 0.137807, Train Acc: 0.769231 | Val Loss: 0.152961, Val Acc: 0.742268\n",
      "Epoch 9081 - Train Loss: 0.137797, Train Acc: 0.769231 | Val Loss: 0.152952, Val Acc: 0.742268\n",
      "Epoch 9082 - Train Loss: 0.137787, Train Acc: 0.769231 | Val Loss: 0.152943, Val Acc: 0.742268\n",
      "Epoch 9083 - Train Loss: 0.137778, Train Acc: 0.769231 | Val Loss: 0.152935, Val Acc: 0.742268\n",
      "Epoch 9084 - Train Loss: 0.137768, Train Acc: 0.769231 | Val Loss: 0.152926, Val Acc: 0.742268\n",
      "Epoch 9085 - Train Loss: 0.137758, Train Acc: 0.769231 | Val Loss: 0.152918, Val Acc: 0.742268\n",
      "Epoch 9086 - Train Loss: 0.137749, Train Acc: 0.769231 | Val Loss: 0.152909, Val Acc: 0.742268\n",
      "Epoch 9087 - Train Loss: 0.137739, Train Acc: 0.769231 | Val Loss: 0.152900, Val Acc: 0.742268\n",
      "Epoch 9088 - Train Loss: 0.137729, Train Acc: 0.769231 | Val Loss: 0.152892, Val Acc: 0.742268\n",
      "Epoch 9089 - Train Loss: 0.137720, Train Acc: 0.769231 | Val Loss: 0.152883, Val Acc: 0.742268\n",
      "Epoch 9090 - Train Loss: 0.137710, Train Acc: 0.769231 | Val Loss: 0.152875, Val Acc: 0.742268\n",
      "Epoch 9091 - Train Loss: 0.137700, Train Acc: 0.769231 | Val Loss: 0.152866, Val Acc: 0.742268\n",
      "Epoch 9092 - Train Loss: 0.137691, Train Acc: 0.769231 | Val Loss: 0.152857, Val Acc: 0.742268\n",
      "Epoch 9093 - Train Loss: 0.137681, Train Acc: 0.769231 | Val Loss: 0.152849, Val Acc: 0.742268\n",
      "Epoch 9094 - Train Loss: 0.137671, Train Acc: 0.769231 | Val Loss: 0.152840, Val Acc: 0.742268\n",
      "Epoch 9095 - Train Loss: 0.137662, Train Acc: 0.769231 | Val Loss: 0.152832, Val Acc: 0.742268\n",
      "Epoch 9096 - Train Loss: 0.137652, Train Acc: 0.769231 | Val Loss: 0.152823, Val Acc: 0.742268\n",
      "Epoch 9097 - Train Loss: 0.137642, Train Acc: 0.769231 | Val Loss: 0.152814, Val Acc: 0.742268\n",
      "Epoch 9098 - Train Loss: 0.137632, Train Acc: 0.769231 | Val Loss: 0.152806, Val Acc: 0.742268\n",
      "Epoch 9099 - Train Loss: 0.137623, Train Acc: 0.769231 | Val Loss: 0.152797, Val Acc: 0.742268\n",
      "Epoch 9100 - Train Loss: 0.137613, Train Acc: 0.769231 | Val Loss: 0.152789, Val Acc: 0.742268\n",
      "Epoch 9101 - Train Loss: 0.137603, Train Acc: 0.769231 | Val Loss: 0.152780, Val Acc: 0.742268\n",
      "Epoch 9102 - Train Loss: 0.137594, Train Acc: 0.769231 | Val Loss: 0.152772, Val Acc: 0.742268\n",
      "Epoch 9103 - Train Loss: 0.137584, Train Acc: 0.769231 | Val Loss: 0.152763, Val Acc: 0.742268\n",
      "Epoch 9104 - Train Loss: 0.137574, Train Acc: 0.769231 | Val Loss: 0.152754, Val Acc: 0.742268\n",
      "Epoch 9105 - Train Loss: 0.137565, Train Acc: 0.769231 | Val Loss: 0.152746, Val Acc: 0.742268\n",
      "Epoch 9106 - Train Loss: 0.137555, Train Acc: 0.769231 | Val Loss: 0.152737, Val Acc: 0.742268\n",
      "Epoch 9107 - Train Loss: 0.137545, Train Acc: 0.769231 | Val Loss: 0.152729, Val Acc: 0.742268\n",
      "Epoch 9108 - Train Loss: 0.137536, Train Acc: 0.769231 | Val Loss: 0.152720, Val Acc: 0.742268\n",
      "Epoch 9109 - Train Loss: 0.137526, Train Acc: 0.769231 | Val Loss: 0.152711, Val Acc: 0.742268\n",
      "Epoch 9110 - Train Loss: 0.137516, Train Acc: 0.769231 | Val Loss: 0.152703, Val Acc: 0.742268\n",
      "Epoch 9111 - Train Loss: 0.137507, Train Acc: 0.769231 | Val Loss: 0.152694, Val Acc: 0.742268\n",
      "Epoch 9112 - Train Loss: 0.137497, Train Acc: 0.769231 | Val Loss: 0.152686, Val Acc: 0.742268\n",
      "Epoch 9113 - Train Loss: 0.137488, Train Acc: 0.769231 | Val Loss: 0.152677, Val Acc: 0.742268\n",
      "Epoch 9114 - Train Loss: 0.137478, Train Acc: 0.769231 | Val Loss: 0.152669, Val Acc: 0.742268\n",
      "Epoch 9115 - Train Loss: 0.137468, Train Acc: 0.769231 | Val Loss: 0.152660, Val Acc: 0.742268\n",
      "Epoch 9116 - Train Loss: 0.137459, Train Acc: 0.769231 | Val Loss: 0.152652, Val Acc: 0.742268\n",
      "Epoch 9117 - Train Loss: 0.137449, Train Acc: 0.769231 | Val Loss: 0.152643, Val Acc: 0.742268\n",
      "Epoch 9118 - Train Loss: 0.137439, Train Acc: 0.769231 | Val Loss: 0.152634, Val Acc: 0.742268\n",
      "Epoch 9119 - Train Loss: 0.137430, Train Acc: 0.769231 | Val Loss: 0.152626, Val Acc: 0.742268\n",
      "Epoch 9120 - Train Loss: 0.137420, Train Acc: 0.769231 | Val Loss: 0.152617, Val Acc: 0.742268\n",
      "Epoch 9121 - Train Loss: 0.137410, Train Acc: 0.769231 | Val Loss: 0.152609, Val Acc: 0.742268\n",
      "Epoch 9122 - Train Loss: 0.137401, Train Acc: 0.769231 | Val Loss: 0.152600, Val Acc: 0.742268\n",
      "Epoch 9123 - Train Loss: 0.137391, Train Acc: 0.769231 | Val Loss: 0.152592, Val Acc: 0.742268\n",
      "Epoch 9124 - Train Loss: 0.137381, Train Acc: 0.769231 | Val Loss: 0.152583, Val Acc: 0.742268\n",
      "Epoch 9125 - Train Loss: 0.137372, Train Acc: 0.769231 | Val Loss: 0.152575, Val Acc: 0.742268\n",
      "Epoch 9126 - Train Loss: 0.137362, Train Acc: 0.769231 | Val Loss: 0.152566, Val Acc: 0.742268\n",
      "Epoch 9127 - Train Loss: 0.137353, Train Acc: 0.769231 | Val Loss: 0.152557, Val Acc: 0.742268\n",
      "Epoch 9128 - Train Loss: 0.137343, Train Acc: 0.769231 | Val Loss: 0.152549, Val Acc: 0.742268\n",
      "Epoch 9129 - Train Loss: 0.137333, Train Acc: 0.769231 | Val Loss: 0.152540, Val Acc: 0.742268\n",
      "Epoch 9130 - Train Loss: 0.137324, Train Acc: 0.769231 | Val Loss: 0.152532, Val Acc: 0.742268\n",
      "Epoch 9131 - Train Loss: 0.137314, Train Acc: 0.769231 | Val Loss: 0.152523, Val Acc: 0.742268\n",
      "Epoch 9132 - Train Loss: 0.137304, Train Acc: 0.769231 | Val Loss: 0.152515, Val Acc: 0.742268\n",
      "Epoch 9133 - Train Loss: 0.137295, Train Acc: 0.769231 | Val Loss: 0.152506, Val Acc: 0.742268\n",
      "Epoch 9134 - Train Loss: 0.137285, Train Acc: 0.769231 | Val Loss: 0.152498, Val Acc: 0.742268\n",
      "Epoch 9135 - Train Loss: 0.137276, Train Acc: 0.769231 | Val Loss: 0.152489, Val Acc: 0.742268\n",
      "Epoch 9136 - Train Loss: 0.137266, Train Acc: 0.769231 | Val Loss: 0.152481, Val Acc: 0.742268\n",
      "Epoch 9137 - Train Loss: 0.137256, Train Acc: 0.769231 | Val Loss: 0.152472, Val Acc: 0.742268\n",
      "Epoch 9138 - Train Loss: 0.137247, Train Acc: 0.769231 | Val Loss: 0.152464, Val Acc: 0.742268\n",
      "Epoch 9139 - Train Loss: 0.137237, Train Acc: 0.769231 | Val Loss: 0.152455, Val Acc: 0.742268\n",
      "Epoch 9140 - Train Loss: 0.137227, Train Acc: 0.769231 | Val Loss: 0.152447, Val Acc: 0.742268\n",
      "Epoch 9141 - Train Loss: 0.137218, Train Acc: 0.769231 | Val Loss: 0.152438, Val Acc: 0.742268\n",
      "Epoch 9142 - Train Loss: 0.137208, Train Acc: 0.769231 | Val Loss: 0.152430, Val Acc: 0.742268\n",
      "Epoch 9143 - Train Loss: 0.137199, Train Acc: 0.769231 | Val Loss: 0.152421, Val Acc: 0.742268\n",
      "Epoch 9144 - Train Loss: 0.137189, Train Acc: 0.769231 | Val Loss: 0.152413, Val Acc: 0.742268\n",
      "Epoch 9145 - Train Loss: 0.137179, Train Acc: 0.769231 | Val Loss: 0.152404, Val Acc: 0.742268\n",
      "Epoch 9146 - Train Loss: 0.137170, Train Acc: 0.769231 | Val Loss: 0.152396, Val Acc: 0.742268\n",
      "Epoch 9147 - Train Loss: 0.137160, Train Acc: 0.769231 | Val Loss: 0.152387, Val Acc: 0.742268\n",
      "Epoch 9148 - Train Loss: 0.137151, Train Acc: 0.769231 | Val Loss: 0.152379, Val Acc: 0.742268\n",
      "Epoch 9149 - Train Loss: 0.137141, Train Acc: 0.769231 | Val Loss: 0.152370, Val Acc: 0.742268\n",
      "Epoch 9150 - Train Loss: 0.137131, Train Acc: 0.769231 | Val Loss: 0.152362, Val Acc: 0.742268\n",
      "Epoch 9151 - Train Loss: 0.137122, Train Acc: 0.769231 | Val Loss: 0.152353, Val Acc: 0.742268\n",
      "Epoch 9152 - Train Loss: 0.137112, Train Acc: 0.769231 | Val Loss: 0.152345, Val Acc: 0.742268\n",
      "Epoch 9153 - Train Loss: 0.137103, Train Acc: 0.769231 | Val Loss: 0.152336, Val Acc: 0.742268\n",
      "Epoch 9154 - Train Loss: 0.137093, Train Acc: 0.769231 | Val Loss: 0.152328, Val Acc: 0.742268\n",
      "Epoch 9155 - Train Loss: 0.137083, Train Acc: 0.769231 | Val Loss: 0.152319, Val Acc: 0.742268\n",
      "Epoch 9156 - Train Loss: 0.137074, Train Acc: 0.769231 | Val Loss: 0.152311, Val Acc: 0.742268\n",
      "Epoch 9157 - Train Loss: 0.137064, Train Acc: 0.769231 | Val Loss: 0.152302, Val Acc: 0.742268\n",
      "Epoch 9158 - Train Loss: 0.137055, Train Acc: 0.769231 | Val Loss: 0.152294, Val Acc: 0.742268\n",
      "Epoch 9159 - Train Loss: 0.137045, Train Acc: 0.769231 | Val Loss: 0.152285, Val Acc: 0.742268\n",
      "Epoch 9160 - Train Loss: 0.137035, Train Acc: 0.769231 | Val Loss: 0.152277, Val Acc: 0.742268\n",
      "Epoch 9161 - Train Loss: 0.137026, Train Acc: 0.769231 | Val Loss: 0.152268, Val Acc: 0.742268\n",
      "Epoch 9162 - Train Loss: 0.137016, Train Acc: 0.769231 | Val Loss: 0.152260, Val Acc: 0.742268\n",
      "Epoch 9163 - Train Loss: 0.137007, Train Acc: 0.769231 | Val Loss: 0.152251, Val Acc: 0.742268\n",
      "Epoch 9164 - Train Loss: 0.136997, Train Acc: 0.769231 | Val Loss: 0.152243, Val Acc: 0.742268\n",
      "Epoch 9165 - Train Loss: 0.136988, Train Acc: 0.769231 | Val Loss: 0.152235, Val Acc: 0.742268\n",
      "Epoch 9166 - Train Loss: 0.136978, Train Acc: 0.769231 | Val Loss: 0.152226, Val Acc: 0.742268\n",
      "Epoch 9167 - Train Loss: 0.136968, Train Acc: 0.769231 | Val Loss: 0.152218, Val Acc: 0.742268\n",
      "Epoch 9168 - Train Loss: 0.136959, Train Acc: 0.769231 | Val Loss: 0.152209, Val Acc: 0.742268\n",
      "Epoch 9169 - Train Loss: 0.136949, Train Acc: 0.769231 | Val Loss: 0.152201, Val Acc: 0.742268\n",
      "Epoch 9170 - Train Loss: 0.136940, Train Acc: 0.769231 | Val Loss: 0.152192, Val Acc: 0.742268\n",
      "Epoch 9171 - Train Loss: 0.136930, Train Acc: 0.769231 | Val Loss: 0.152184, Val Acc: 0.742268\n",
      "Epoch 9172 - Train Loss: 0.136921, Train Acc: 0.769231 | Val Loss: 0.152175, Val Acc: 0.742268\n",
      "Epoch 9173 - Train Loss: 0.136911, Train Acc: 0.769231 | Val Loss: 0.152167, Val Acc: 0.742268\n",
      "Epoch 9174 - Train Loss: 0.136901, Train Acc: 0.769231 | Val Loss: 0.152158, Val Acc: 0.742268\n",
      "Epoch 9175 - Train Loss: 0.136892, Train Acc: 0.769231 | Val Loss: 0.152150, Val Acc: 0.742268\n",
      "Epoch 9176 - Train Loss: 0.136882, Train Acc: 0.769231 | Val Loss: 0.152142, Val Acc: 0.742268\n",
      "Epoch 9177 - Train Loss: 0.136873, Train Acc: 0.769231 | Val Loss: 0.152133, Val Acc: 0.742268\n",
      "Epoch 9178 - Train Loss: 0.136863, Train Acc: 0.769231 | Val Loss: 0.152125, Val Acc: 0.742268\n",
      "Epoch 9179 - Train Loss: 0.136854, Train Acc: 0.769231 | Val Loss: 0.152116, Val Acc: 0.742268\n",
      "Epoch 9180 - Train Loss: 0.136844, Train Acc: 0.769231 | Val Loss: 0.152108, Val Acc: 0.742268\n",
      "Epoch 9181 - Train Loss: 0.136834, Train Acc: 0.769231 | Val Loss: 0.152099, Val Acc: 0.742268\n",
      "Epoch 9182 - Train Loss: 0.136825, Train Acc: 0.769231 | Val Loss: 0.152091, Val Acc: 0.742268\n",
      "Epoch 9183 - Train Loss: 0.136815, Train Acc: 0.769231 | Val Loss: 0.152082, Val Acc: 0.742268\n",
      "Epoch 9184 - Train Loss: 0.136806, Train Acc: 0.769231 | Val Loss: 0.152074, Val Acc: 0.742268\n",
      "Epoch 9185 - Train Loss: 0.136796, Train Acc: 0.769231 | Val Loss: 0.152066, Val Acc: 0.742268\n",
      "Epoch 9186 - Train Loss: 0.136787, Train Acc: 0.769231 | Val Loss: 0.152057, Val Acc: 0.742268\n",
      "Epoch 9187 - Train Loss: 0.136777, Train Acc: 0.769231 | Val Loss: 0.152049, Val Acc: 0.742268\n",
      "Epoch 9188 - Train Loss: 0.136768, Train Acc: 0.769231 | Val Loss: 0.152040, Val Acc: 0.742268\n",
      "Epoch 9189 - Train Loss: 0.136758, Train Acc: 0.769231 | Val Loss: 0.152032, Val Acc: 0.742268\n",
      "Epoch 9190 - Train Loss: 0.136749, Train Acc: 0.769231 | Val Loss: 0.152023, Val Acc: 0.742268\n",
      "Epoch 9191 - Train Loss: 0.136739, Train Acc: 0.769231 | Val Loss: 0.152015, Val Acc: 0.742268\n",
      "Epoch 9192 - Train Loss: 0.136729, Train Acc: 0.769231 | Val Loss: 0.152007, Val Acc: 0.742268\n",
      "Epoch 9193 - Train Loss: 0.136720, Train Acc: 0.769231 | Val Loss: 0.151998, Val Acc: 0.742268\n",
      "Epoch 9194 - Train Loss: 0.136710, Train Acc: 0.769231 | Val Loss: 0.151990, Val Acc: 0.742268\n",
      "Epoch 9195 - Train Loss: 0.136701, Train Acc: 0.769231 | Val Loss: 0.151981, Val Acc: 0.742268\n",
      "Epoch 9196 - Train Loss: 0.136691, Train Acc: 0.769231 | Val Loss: 0.151973, Val Acc: 0.742268\n",
      "Epoch 9197 - Train Loss: 0.136682, Train Acc: 0.769231 | Val Loss: 0.151965, Val Acc: 0.742268\n",
      "Epoch 9198 - Train Loss: 0.136672, Train Acc: 0.769231 | Val Loss: 0.151956, Val Acc: 0.742268\n",
      "Epoch 9199 - Train Loss: 0.136663, Train Acc: 0.769231 | Val Loss: 0.151948, Val Acc: 0.742268\n",
      "Epoch 9200 - Train Loss: 0.136653, Train Acc: 0.769231 | Val Loss: 0.151939, Val Acc: 0.742268\n",
      "Epoch 9201 - Train Loss: 0.136644, Train Acc: 0.769231 | Val Loss: 0.151931, Val Acc: 0.742268\n",
      "Epoch 9202 - Train Loss: 0.136634, Train Acc: 0.769231 | Val Loss: 0.151922, Val Acc: 0.742268\n",
      "Epoch 9203 - Train Loss: 0.136625, Train Acc: 0.769231 | Val Loss: 0.151914, Val Acc: 0.742268\n",
      "Epoch 9204 - Train Loss: 0.136615, Train Acc: 0.769231 | Val Loss: 0.151906, Val Acc: 0.742268\n",
      "Epoch 9205 - Train Loss: 0.136606, Train Acc: 0.769231 | Val Loss: 0.151897, Val Acc: 0.742268\n",
      "Epoch 9206 - Train Loss: 0.136596, Train Acc: 0.769231 | Val Loss: 0.151889, Val Acc: 0.742268\n",
      "Epoch 9207 - Train Loss: 0.136587, Train Acc: 0.769231 | Val Loss: 0.151880, Val Acc: 0.742268\n",
      "Epoch 9208 - Train Loss: 0.136577, Train Acc: 0.769231 | Val Loss: 0.151872, Val Acc: 0.742268\n",
      "Epoch 9209 - Train Loss: 0.136568, Train Acc: 0.769231 | Val Loss: 0.151864, Val Acc: 0.742268\n",
      "Epoch 9210 - Train Loss: 0.136558, Train Acc: 0.769231 | Val Loss: 0.151855, Val Acc: 0.742268\n",
      "Epoch 9211 - Train Loss: 0.136548, Train Acc: 0.769231 | Val Loss: 0.151847, Val Acc: 0.742268\n",
      "Epoch 9212 - Train Loss: 0.136539, Train Acc: 0.769231 | Val Loss: 0.151838, Val Acc: 0.742268\n",
      "Epoch 9213 - Train Loss: 0.136529, Train Acc: 0.769231 | Val Loss: 0.151830, Val Acc: 0.742268\n",
      "Epoch 9214 - Train Loss: 0.136520, Train Acc: 0.769231 | Val Loss: 0.151822, Val Acc: 0.742268\n",
      "Epoch 9215 - Train Loss: 0.136510, Train Acc: 0.769231 | Val Loss: 0.151813, Val Acc: 0.742268\n",
      "Epoch 9216 - Train Loss: 0.136501, Train Acc: 0.769231 | Val Loss: 0.151805, Val Acc: 0.742268\n",
      "Epoch 9217 - Train Loss: 0.136491, Train Acc: 0.769231 | Val Loss: 0.151796, Val Acc: 0.742268\n",
      "Epoch 9218 - Train Loss: 0.136482, Train Acc: 0.769231 | Val Loss: 0.151788, Val Acc: 0.742268\n",
      "Epoch 9219 - Train Loss: 0.136472, Train Acc: 0.769231 | Val Loss: 0.151780, Val Acc: 0.742268\n",
      "Epoch 9220 - Train Loss: 0.136463, Train Acc: 0.769231 | Val Loss: 0.151771, Val Acc: 0.742268\n",
      "Epoch 9221 - Train Loss: 0.136453, Train Acc: 0.770513 | Val Loss: 0.151763, Val Acc: 0.742268\n",
      "Epoch 9222 - Train Loss: 0.136444, Train Acc: 0.770513 | Val Loss: 0.151754, Val Acc: 0.742268\n",
      "Epoch 9223 - Train Loss: 0.136434, Train Acc: 0.770513 | Val Loss: 0.151746, Val Acc: 0.742268\n",
      "Epoch 9224 - Train Loss: 0.136425, Train Acc: 0.770513 | Val Loss: 0.151738, Val Acc: 0.742268\n",
      "Epoch 9225 - Train Loss: 0.136415, Train Acc: 0.770513 | Val Loss: 0.151729, Val Acc: 0.742268\n",
      "Epoch 9226 - Train Loss: 0.136406, Train Acc: 0.770513 | Val Loss: 0.151721, Val Acc: 0.742268\n",
      "Epoch 9227 - Train Loss: 0.136396, Train Acc: 0.770513 | Val Loss: 0.151712, Val Acc: 0.742268\n",
      "Epoch 9228 - Train Loss: 0.136387, Train Acc: 0.770513 | Val Loss: 0.151704, Val Acc: 0.742268\n",
      "Epoch 9229 - Train Loss: 0.136377, Train Acc: 0.770513 | Val Loss: 0.151696, Val Acc: 0.742268\n",
      "Epoch 9230 - Train Loss: 0.136368, Train Acc: 0.770513 | Val Loss: 0.151687, Val Acc: 0.742268\n",
      "Epoch 9231 - Train Loss: 0.136359, Train Acc: 0.770513 | Val Loss: 0.151679, Val Acc: 0.742268\n",
      "Epoch 9232 - Train Loss: 0.136349, Train Acc: 0.770513 | Val Loss: 0.151671, Val Acc: 0.742268\n",
      "Epoch 9233 - Train Loss: 0.136340, Train Acc: 0.770513 | Val Loss: 0.151662, Val Acc: 0.742268\n",
      "Epoch 9234 - Train Loss: 0.136330, Train Acc: 0.770513 | Val Loss: 0.151654, Val Acc: 0.742268\n",
      "Epoch 9235 - Train Loss: 0.136321, Train Acc: 0.770513 | Val Loss: 0.151645, Val Acc: 0.742268\n",
      "Epoch 9236 - Train Loss: 0.136311, Train Acc: 0.770513 | Val Loss: 0.151637, Val Acc: 0.742268\n",
      "Epoch 9237 - Train Loss: 0.136302, Train Acc: 0.770513 | Val Loss: 0.151629, Val Acc: 0.742268\n",
      "Epoch 9238 - Train Loss: 0.136292, Train Acc: 0.770513 | Val Loss: 0.151620, Val Acc: 0.742268\n",
      "Epoch 9239 - Train Loss: 0.136283, Train Acc: 0.770513 | Val Loss: 0.151612, Val Acc: 0.742268\n",
      "Epoch 9240 - Train Loss: 0.136273, Train Acc: 0.770513 | Val Loss: 0.151603, Val Acc: 0.742268\n",
      "Epoch 9241 - Train Loss: 0.136264, Train Acc: 0.770513 | Val Loss: 0.151595, Val Acc: 0.742268\n",
      "Epoch 9242 - Train Loss: 0.136254, Train Acc: 0.770513 | Val Loss: 0.151587, Val Acc: 0.742268\n",
      "Epoch 9243 - Train Loss: 0.136245, Train Acc: 0.770513 | Val Loss: 0.151578, Val Acc: 0.742268\n",
      "Epoch 9244 - Train Loss: 0.136235, Train Acc: 0.770513 | Val Loss: 0.151570, Val Acc: 0.742268\n",
      "Epoch 9245 - Train Loss: 0.136226, Train Acc: 0.770513 | Val Loss: 0.151561, Val Acc: 0.742268\n",
      "Epoch 9246 - Train Loss: 0.136216, Train Acc: 0.770513 | Val Loss: 0.151553, Val Acc: 0.742268\n",
      "Epoch 9247 - Train Loss: 0.136207, Train Acc: 0.770513 | Val Loss: 0.151545, Val Acc: 0.742268\n",
      "Epoch 9248 - Train Loss: 0.136198, Train Acc: 0.770513 | Val Loss: 0.151536, Val Acc: 0.742268\n",
      "Epoch 9249 - Train Loss: 0.136188, Train Acc: 0.770513 | Val Loss: 0.151528, Val Acc: 0.742268\n",
      "Epoch 9250 - Train Loss: 0.136179, Train Acc: 0.770513 | Val Loss: 0.151519, Val Acc: 0.742268\n",
      "Epoch 9251 - Train Loss: 0.136169, Train Acc: 0.770513 | Val Loss: 0.151511, Val Acc: 0.742268\n",
      "Epoch 9252 - Train Loss: 0.136160, Train Acc: 0.771795 | Val Loss: 0.151503, Val Acc: 0.742268\n",
      "Epoch 9253 - Train Loss: 0.136150, Train Acc: 0.771795 | Val Loss: 0.151494, Val Acc: 0.742268\n",
      "Epoch 9254 - Train Loss: 0.136141, Train Acc: 0.771795 | Val Loss: 0.151486, Val Acc: 0.742268\n",
      "Epoch 9255 - Train Loss: 0.136131, Train Acc: 0.771795 | Val Loss: 0.151478, Val Acc: 0.742268\n",
      "Epoch 9256 - Train Loss: 0.136122, Train Acc: 0.771795 | Val Loss: 0.151469, Val Acc: 0.742268\n",
      "Epoch 9257 - Train Loss: 0.136112, Train Acc: 0.771795 | Val Loss: 0.151461, Val Acc: 0.742268\n",
      "Epoch 9258 - Train Loss: 0.136103, Train Acc: 0.771795 | Val Loss: 0.151452, Val Acc: 0.742268\n",
      "Epoch 9259 - Train Loss: 0.136094, Train Acc: 0.771795 | Val Loss: 0.151444, Val Acc: 0.742268\n",
      "Epoch 9260 - Train Loss: 0.136084, Train Acc: 0.771795 | Val Loss: 0.151436, Val Acc: 0.742268\n",
      "Epoch 9261 - Train Loss: 0.136075, Train Acc: 0.771795 | Val Loss: 0.151427, Val Acc: 0.742268\n",
      "Epoch 9262 - Train Loss: 0.136065, Train Acc: 0.771795 | Val Loss: 0.151419, Val Acc: 0.742268\n",
      "Epoch 9263 - Train Loss: 0.136056, Train Acc: 0.771795 | Val Loss: 0.151411, Val Acc: 0.742268\n",
      "Epoch 9264 - Train Loss: 0.136046, Train Acc: 0.771795 | Val Loss: 0.151402, Val Acc: 0.742268\n",
      "Epoch 9265 - Train Loss: 0.136037, Train Acc: 0.773077 | Val Loss: 0.151394, Val Acc: 0.742268\n",
      "Epoch 9266 - Train Loss: 0.136028, Train Acc: 0.773077 | Val Loss: 0.151386, Val Acc: 0.742268\n",
      "Epoch 9267 - Train Loss: 0.136018, Train Acc: 0.773077 | Val Loss: 0.151377, Val Acc: 0.742268\n",
      "Epoch 9268 - Train Loss: 0.136009, Train Acc: 0.773077 | Val Loss: 0.151369, Val Acc: 0.742268\n",
      "Epoch 9269 - Train Loss: 0.135999, Train Acc: 0.773077 | Val Loss: 0.151361, Val Acc: 0.742268\n",
      "Epoch 9270 - Train Loss: 0.135990, Train Acc: 0.773077 | Val Loss: 0.151352, Val Acc: 0.742268\n",
      "Epoch 9271 - Train Loss: 0.135980, Train Acc: 0.773077 | Val Loss: 0.151344, Val Acc: 0.742268\n",
      "Epoch 9272 - Train Loss: 0.135971, Train Acc: 0.773077 | Val Loss: 0.151336, Val Acc: 0.742268\n",
      "Epoch 9273 - Train Loss: 0.135962, Train Acc: 0.773077 | Val Loss: 0.151327, Val Acc: 0.742268\n",
      "Epoch 9274 - Train Loss: 0.135952, Train Acc: 0.773077 | Val Loss: 0.151319, Val Acc: 0.742268\n",
      "Epoch 9275 - Train Loss: 0.135943, Train Acc: 0.773077 | Val Loss: 0.151310, Val Acc: 0.742268\n",
      "Epoch 9276 - Train Loss: 0.135933, Train Acc: 0.773077 | Val Loss: 0.151302, Val Acc: 0.742268\n",
      "Epoch 9277 - Train Loss: 0.135924, Train Acc: 0.773077 | Val Loss: 0.151294, Val Acc: 0.742268\n",
      "Epoch 9278 - Train Loss: 0.135914, Train Acc: 0.773077 | Val Loss: 0.151286, Val Acc: 0.742268\n",
      "Epoch 9279 - Train Loss: 0.135905, Train Acc: 0.773077 | Val Loss: 0.151277, Val Acc: 0.742268\n",
      "Epoch 9280 - Train Loss: 0.135896, Train Acc: 0.773077 | Val Loss: 0.151269, Val Acc: 0.742268\n",
      "Epoch 9281 - Train Loss: 0.135886, Train Acc: 0.773077 | Val Loss: 0.151261, Val Acc: 0.742268\n",
      "Epoch 9282 - Train Loss: 0.135877, Train Acc: 0.773077 | Val Loss: 0.151252, Val Acc: 0.742268\n",
      "Epoch 9283 - Train Loss: 0.135867, Train Acc: 0.773077 | Val Loss: 0.151244, Val Acc: 0.742268\n",
      "Epoch 9284 - Train Loss: 0.135858, Train Acc: 0.773077 | Val Loss: 0.151236, Val Acc: 0.742268\n",
      "Epoch 9285 - Train Loss: 0.135849, Train Acc: 0.773077 | Val Loss: 0.151227, Val Acc: 0.742268\n",
      "Epoch 9286 - Train Loss: 0.135839, Train Acc: 0.773077 | Val Loss: 0.151219, Val Acc: 0.742268\n",
      "Epoch 9287 - Train Loss: 0.135830, Train Acc: 0.773077 | Val Loss: 0.151211, Val Acc: 0.742268\n",
      "Epoch 9288 - Train Loss: 0.135820, Train Acc: 0.773077 | Val Loss: 0.151202, Val Acc: 0.742268\n",
      "Epoch 9289 - Train Loss: 0.135811, Train Acc: 0.773077 | Val Loss: 0.151194, Val Acc: 0.742268\n",
      "Epoch 9290 - Train Loss: 0.135802, Train Acc: 0.773077 | Val Loss: 0.151186, Val Acc: 0.742268\n",
      "Epoch 9291 - Train Loss: 0.135792, Train Acc: 0.773077 | Val Loss: 0.151177, Val Acc: 0.742268\n",
      "Epoch 9292 - Train Loss: 0.135783, Train Acc: 0.773077 | Val Loss: 0.151169, Val Acc: 0.742268\n",
      "Epoch 9293 - Train Loss: 0.135773, Train Acc: 0.773077 | Val Loss: 0.151161, Val Acc: 0.742268\n",
      "Epoch 9294 - Train Loss: 0.135764, Train Acc: 0.773077 | Val Loss: 0.151152, Val Acc: 0.742268\n",
      "Epoch 9295 - Train Loss: 0.135755, Train Acc: 0.773077 | Val Loss: 0.151144, Val Acc: 0.742268\n",
      "Epoch 9296 - Train Loss: 0.135745, Train Acc: 0.773077 | Val Loss: 0.151136, Val Acc: 0.742268\n",
      "Epoch 9297 - Train Loss: 0.135736, Train Acc: 0.773077 | Val Loss: 0.151128, Val Acc: 0.742268\n",
      "Epoch 9298 - Train Loss: 0.135726, Train Acc: 0.773077 | Val Loss: 0.151119, Val Acc: 0.742268\n",
      "Epoch 9299 - Train Loss: 0.135717, Train Acc: 0.773077 | Val Loss: 0.151111, Val Acc: 0.742268\n",
      "Epoch 9300 - Train Loss: 0.135708, Train Acc: 0.773077 | Val Loss: 0.151103, Val Acc: 0.742268\n",
      "Epoch 9301 - Train Loss: 0.135698, Train Acc: 0.773077 | Val Loss: 0.151094, Val Acc: 0.742268\n",
      "Epoch 9302 - Train Loss: 0.135689, Train Acc: 0.773077 | Val Loss: 0.151086, Val Acc: 0.742268\n",
      "Epoch 9303 - Train Loss: 0.135680, Train Acc: 0.773077 | Val Loss: 0.151078, Val Acc: 0.742268\n",
      "Epoch 9304 - Train Loss: 0.135670, Train Acc: 0.773077 | Val Loss: 0.151070, Val Acc: 0.742268\n",
      "Epoch 9305 - Train Loss: 0.135661, Train Acc: 0.774359 | Val Loss: 0.151061, Val Acc: 0.742268\n",
      "Epoch 9306 - Train Loss: 0.135651, Train Acc: 0.774359 | Val Loss: 0.151053, Val Acc: 0.742268\n",
      "Epoch 9307 - Train Loss: 0.135642, Train Acc: 0.774359 | Val Loss: 0.151045, Val Acc: 0.742268\n",
      "Epoch 9308 - Train Loss: 0.135633, Train Acc: 0.774359 | Val Loss: 0.151036, Val Acc: 0.742268\n",
      "Epoch 9309 - Train Loss: 0.135623, Train Acc: 0.774359 | Val Loss: 0.151028, Val Acc: 0.742268\n",
      "Epoch 9310 - Train Loss: 0.135614, Train Acc: 0.774359 | Val Loss: 0.151020, Val Acc: 0.742268\n",
      "Epoch 9311 - Train Loss: 0.135605, Train Acc: 0.774359 | Val Loss: 0.151012, Val Acc: 0.742268\n",
      "Epoch 9312 - Train Loss: 0.135595, Train Acc: 0.774359 | Val Loss: 0.151003, Val Acc: 0.742268\n",
      "Epoch 9313 - Train Loss: 0.135586, Train Acc: 0.774359 | Val Loss: 0.150995, Val Acc: 0.742268\n",
      "Epoch 9314 - Train Loss: 0.135576, Train Acc: 0.774359 | Val Loss: 0.150987, Val Acc: 0.742268\n",
      "Epoch 9315 - Train Loss: 0.135567, Train Acc: 0.774359 | Val Loss: 0.150979, Val Acc: 0.742268\n",
      "Epoch 9316 - Train Loss: 0.135558, Train Acc: 0.774359 | Val Loss: 0.150970, Val Acc: 0.742268\n",
      "Epoch 9317 - Train Loss: 0.135548, Train Acc: 0.774359 | Val Loss: 0.150962, Val Acc: 0.742268\n",
      "Epoch 9318 - Train Loss: 0.135539, Train Acc: 0.774359 | Val Loss: 0.150954, Val Acc: 0.742268\n",
      "Epoch 9319 - Train Loss: 0.135530, Train Acc: 0.774359 | Val Loss: 0.150945, Val Acc: 0.742268\n",
      "Epoch 9320 - Train Loss: 0.135520, Train Acc: 0.774359 | Val Loss: 0.150937, Val Acc: 0.742268\n",
      "Epoch 9321 - Train Loss: 0.135511, Train Acc: 0.774359 | Val Loss: 0.150929, Val Acc: 0.742268\n",
      "Epoch 9322 - Train Loss: 0.135502, Train Acc: 0.774359 | Val Loss: 0.150921, Val Acc: 0.742268\n",
      "Epoch 9323 - Train Loss: 0.135492, Train Acc: 0.774359 | Val Loss: 0.150912, Val Acc: 0.742268\n",
      "Epoch 9324 - Train Loss: 0.135483, Train Acc: 0.774359 | Val Loss: 0.150904, Val Acc: 0.742268\n",
      "Epoch 9325 - Train Loss: 0.135474, Train Acc: 0.774359 | Val Loss: 0.150896, Val Acc: 0.742268\n",
      "Epoch 9326 - Train Loss: 0.135464, Train Acc: 0.774359 | Val Loss: 0.150888, Val Acc: 0.742268\n",
      "Epoch 9327 - Train Loss: 0.135455, Train Acc: 0.774359 | Val Loss: 0.150879, Val Acc: 0.742268\n",
      "Epoch 9328 - Train Loss: 0.135446, Train Acc: 0.774359 | Val Loss: 0.150871, Val Acc: 0.742268\n",
      "Epoch 9329 - Train Loss: 0.135436, Train Acc: 0.774359 | Val Loss: 0.150863, Val Acc: 0.742268\n",
      "Epoch 9330 - Train Loss: 0.135427, Train Acc: 0.774359 | Val Loss: 0.150855, Val Acc: 0.742268\n",
      "Epoch 9331 - Train Loss: 0.135417, Train Acc: 0.774359 | Val Loss: 0.150846, Val Acc: 0.742268\n",
      "Epoch 9332 - Train Loss: 0.135408, Train Acc: 0.774359 | Val Loss: 0.150838, Val Acc: 0.742268\n",
      "Epoch 9333 - Train Loss: 0.135399, Train Acc: 0.774359 | Val Loss: 0.150830, Val Acc: 0.742268\n",
      "Epoch 9334 - Train Loss: 0.135389, Train Acc: 0.774359 | Val Loss: 0.150822, Val Acc: 0.742268\n",
      "Epoch 9335 - Train Loss: 0.135380, Train Acc: 0.774359 | Val Loss: 0.150814, Val Acc: 0.742268\n",
      "Epoch 9336 - Train Loss: 0.135371, Train Acc: 0.774359 | Val Loss: 0.150805, Val Acc: 0.742268\n",
      "Epoch 9337 - Train Loss: 0.135361, Train Acc: 0.774359 | Val Loss: 0.150797, Val Acc: 0.742268\n",
      "Epoch 9338 - Train Loss: 0.135352, Train Acc: 0.774359 | Val Loss: 0.150789, Val Acc: 0.742268\n",
      "Epoch 9339 - Train Loss: 0.135343, Train Acc: 0.774359 | Val Loss: 0.150781, Val Acc: 0.742268\n",
      "Epoch 9340 - Train Loss: 0.135333, Train Acc: 0.774359 | Val Loss: 0.150772, Val Acc: 0.742268\n",
      "Epoch 9341 - Train Loss: 0.135324, Train Acc: 0.774359 | Val Loss: 0.150764, Val Acc: 0.742268\n",
      "Epoch 9342 - Train Loss: 0.135315, Train Acc: 0.774359 | Val Loss: 0.150756, Val Acc: 0.742268\n",
      "Epoch 9343 - Train Loss: 0.135306, Train Acc: 0.774359 | Val Loss: 0.150748, Val Acc: 0.742268\n",
      "Epoch 9344 - Train Loss: 0.135296, Train Acc: 0.774359 | Val Loss: 0.150739, Val Acc: 0.742268\n",
      "Epoch 9345 - Train Loss: 0.135287, Train Acc: 0.774359 | Val Loss: 0.150731, Val Acc: 0.742268\n",
      "Epoch 9346 - Train Loss: 0.135278, Train Acc: 0.774359 | Val Loss: 0.150723, Val Acc: 0.742268\n",
      "Epoch 9347 - Train Loss: 0.135268, Train Acc: 0.774359 | Val Loss: 0.150715, Val Acc: 0.742268\n",
      "Epoch 9348 - Train Loss: 0.135259, Train Acc: 0.774359 | Val Loss: 0.150707, Val Acc: 0.742268\n",
      "Epoch 9349 - Train Loss: 0.135250, Train Acc: 0.774359 | Val Loss: 0.150698, Val Acc: 0.742268\n",
      "Epoch 9350 - Train Loss: 0.135240, Train Acc: 0.774359 | Val Loss: 0.150690, Val Acc: 0.742268\n",
      "Epoch 9351 - Train Loss: 0.135231, Train Acc: 0.774359 | Val Loss: 0.150682, Val Acc: 0.742268\n",
      "Epoch 9352 - Train Loss: 0.135222, Train Acc: 0.774359 | Val Loss: 0.150674, Val Acc: 0.742268\n",
      "Epoch 9353 - Train Loss: 0.135212, Train Acc: 0.774359 | Val Loss: 0.150666, Val Acc: 0.742268\n",
      "Epoch 9354 - Train Loss: 0.135203, Train Acc: 0.774359 | Val Loss: 0.150657, Val Acc: 0.742268\n",
      "Epoch 9355 - Train Loss: 0.135194, Train Acc: 0.774359 | Val Loss: 0.150649, Val Acc: 0.742268\n",
      "Epoch 9356 - Train Loss: 0.135184, Train Acc: 0.774359 | Val Loss: 0.150641, Val Acc: 0.742268\n",
      "Epoch 9357 - Train Loss: 0.135175, Train Acc: 0.774359 | Val Loss: 0.150633, Val Acc: 0.742268\n",
      "Epoch 9358 - Train Loss: 0.135166, Train Acc: 0.774359 | Val Loss: 0.150625, Val Acc: 0.742268\n",
      "Epoch 9359 - Train Loss: 0.135157, Train Acc: 0.774359 | Val Loss: 0.150616, Val Acc: 0.742268\n",
      "Epoch 9360 - Train Loss: 0.135147, Train Acc: 0.774359 | Val Loss: 0.150608, Val Acc: 0.742268\n",
      "Epoch 9361 - Train Loss: 0.135138, Train Acc: 0.774359 | Val Loss: 0.150600, Val Acc: 0.742268\n",
      "Epoch 9362 - Train Loss: 0.135129, Train Acc: 0.774359 | Val Loss: 0.150592, Val Acc: 0.742268\n",
      "Epoch 9363 - Train Loss: 0.135119, Train Acc: 0.774359 | Val Loss: 0.150584, Val Acc: 0.742268\n",
      "Epoch 9364 - Train Loss: 0.135110, Train Acc: 0.774359 | Val Loss: 0.150575, Val Acc: 0.742268\n",
      "Epoch 9365 - Train Loss: 0.135101, Train Acc: 0.774359 | Val Loss: 0.150567, Val Acc: 0.742268\n",
      "Epoch 9366 - Train Loss: 0.135091, Train Acc: 0.774359 | Val Loss: 0.150559, Val Acc: 0.742268\n",
      "Epoch 9367 - Train Loss: 0.135082, Train Acc: 0.774359 | Val Loss: 0.150551, Val Acc: 0.742268\n",
      "Epoch 9368 - Train Loss: 0.135073, Train Acc: 0.774359 | Val Loss: 0.150543, Val Acc: 0.742268\n",
      "Epoch 9369 - Train Loss: 0.135064, Train Acc: 0.774359 | Val Loss: 0.150534, Val Acc: 0.742268\n",
      "Epoch 9370 - Train Loss: 0.135054, Train Acc: 0.774359 | Val Loss: 0.150526, Val Acc: 0.742268\n",
      "Epoch 9371 - Train Loss: 0.135045, Train Acc: 0.774359 | Val Loss: 0.150518, Val Acc: 0.742268\n",
      "Epoch 9372 - Train Loss: 0.135036, Train Acc: 0.774359 | Val Loss: 0.150510, Val Acc: 0.742268\n",
      "Epoch 9373 - Train Loss: 0.135026, Train Acc: 0.774359 | Val Loss: 0.150502, Val Acc: 0.742268\n",
      "Epoch 9374 - Train Loss: 0.135017, Train Acc: 0.774359 | Val Loss: 0.150494, Val Acc: 0.742268\n",
      "Epoch 9375 - Train Loss: 0.135008, Train Acc: 0.774359 | Val Loss: 0.150485, Val Acc: 0.742268\n",
      "Epoch 9376 - Train Loss: 0.134999, Train Acc: 0.774359 | Val Loss: 0.150477, Val Acc: 0.742268\n",
      "Epoch 9377 - Train Loss: 0.134989, Train Acc: 0.774359 | Val Loss: 0.150469, Val Acc: 0.742268\n",
      "Epoch 9378 - Train Loss: 0.134980, Train Acc: 0.774359 | Val Loss: 0.150461, Val Acc: 0.742268\n",
      "Epoch 9379 - Train Loss: 0.134971, Train Acc: 0.774359 | Val Loss: 0.150453, Val Acc: 0.742268\n",
      "Epoch 9380 - Train Loss: 0.134962, Train Acc: 0.774359 | Val Loss: 0.150445, Val Acc: 0.742268\n",
      "Epoch 9381 - Train Loss: 0.134952, Train Acc: 0.774359 | Val Loss: 0.150436, Val Acc: 0.742268\n",
      "Epoch 9382 - Train Loss: 0.134943, Train Acc: 0.774359 | Val Loss: 0.150428, Val Acc: 0.742268\n",
      "Epoch 9383 - Train Loss: 0.134934, Train Acc: 0.774359 | Val Loss: 0.150420, Val Acc: 0.742268\n",
      "Epoch 9384 - Train Loss: 0.134925, Train Acc: 0.774359 | Val Loss: 0.150412, Val Acc: 0.742268\n",
      "Epoch 9385 - Train Loss: 0.134915, Train Acc: 0.774359 | Val Loss: 0.150404, Val Acc: 0.742268\n",
      "Epoch 9386 - Train Loss: 0.134906, Train Acc: 0.774359 | Val Loss: 0.150396, Val Acc: 0.742268\n",
      "Epoch 9387 - Train Loss: 0.134897, Train Acc: 0.774359 | Val Loss: 0.150387, Val Acc: 0.742268\n",
      "Epoch 9388 - Train Loss: 0.134887, Train Acc: 0.774359 | Val Loss: 0.150379, Val Acc: 0.742268\n",
      "Epoch 9389 - Train Loss: 0.134878, Train Acc: 0.774359 | Val Loss: 0.150371, Val Acc: 0.742268\n",
      "Epoch 9390 - Train Loss: 0.134869, Train Acc: 0.774359 | Val Loss: 0.150363, Val Acc: 0.742268\n",
      "Epoch 9391 - Train Loss: 0.134860, Train Acc: 0.774359 | Val Loss: 0.150355, Val Acc: 0.742268\n",
      "Epoch 9392 - Train Loss: 0.134850, Train Acc: 0.774359 | Val Loss: 0.150347, Val Acc: 0.742268\n",
      "Epoch 9393 - Train Loss: 0.134841, Train Acc: 0.774359 | Val Loss: 0.150339, Val Acc: 0.742268\n",
      "Epoch 9394 - Train Loss: 0.134832, Train Acc: 0.774359 | Val Loss: 0.150330, Val Acc: 0.742268\n",
      "Epoch 9395 - Train Loss: 0.134823, Train Acc: 0.774359 | Val Loss: 0.150322, Val Acc: 0.742268\n",
      "Epoch 9396 - Train Loss: 0.134813, Train Acc: 0.774359 | Val Loss: 0.150314, Val Acc: 0.742268\n",
      "Epoch 9397 - Train Loss: 0.134804, Train Acc: 0.774359 | Val Loss: 0.150306, Val Acc: 0.742268\n",
      "Epoch 9398 - Train Loss: 0.134795, Train Acc: 0.774359 | Val Loss: 0.150298, Val Acc: 0.742268\n",
      "Epoch 9399 - Train Loss: 0.134786, Train Acc: 0.774359 | Val Loss: 0.150290, Val Acc: 0.742268\n",
      "Epoch 9400 - Train Loss: 0.134776, Train Acc: 0.774359 | Val Loss: 0.150282, Val Acc: 0.742268\n",
      "Epoch 9401 - Train Loss: 0.134767, Train Acc: 0.774359 | Val Loss: 0.150273, Val Acc: 0.742268\n",
      "Epoch 9402 - Train Loss: 0.134758, Train Acc: 0.774359 | Val Loss: 0.150265, Val Acc: 0.742268\n",
      "Epoch 9403 - Train Loss: 0.134749, Train Acc: 0.774359 | Val Loss: 0.150257, Val Acc: 0.742268\n",
      "Epoch 9404 - Train Loss: 0.134740, Train Acc: 0.774359 | Val Loss: 0.150249, Val Acc: 0.742268\n",
      "Epoch 9405 - Train Loss: 0.134730, Train Acc: 0.774359 | Val Loss: 0.150241, Val Acc: 0.742268\n",
      "Epoch 9406 - Train Loss: 0.134721, Train Acc: 0.774359 | Val Loss: 0.150233, Val Acc: 0.742268\n",
      "Epoch 9407 - Train Loss: 0.134712, Train Acc: 0.774359 | Val Loss: 0.150225, Val Acc: 0.742268\n",
      "Epoch 9408 - Train Loss: 0.134703, Train Acc: 0.774359 | Val Loss: 0.150216, Val Acc: 0.742268\n",
      "Epoch 9409 - Train Loss: 0.134693, Train Acc: 0.774359 | Val Loss: 0.150208, Val Acc: 0.742268\n",
      "Epoch 9410 - Train Loss: 0.134684, Train Acc: 0.774359 | Val Loss: 0.150200, Val Acc: 0.742268\n",
      "Epoch 9411 - Train Loss: 0.134675, Train Acc: 0.774359 | Val Loss: 0.150192, Val Acc: 0.742268\n",
      "Epoch 9412 - Train Loss: 0.134666, Train Acc: 0.774359 | Val Loss: 0.150184, Val Acc: 0.742268\n",
      "Epoch 9413 - Train Loss: 0.134656, Train Acc: 0.774359 | Val Loss: 0.150176, Val Acc: 0.742268\n",
      "Epoch 9414 - Train Loss: 0.134647, Train Acc: 0.774359 | Val Loss: 0.150168, Val Acc: 0.742268\n",
      "Epoch 9415 - Train Loss: 0.134638, Train Acc: 0.774359 | Val Loss: 0.150160, Val Acc: 0.742268\n",
      "Epoch 9416 - Train Loss: 0.134629, Train Acc: 0.774359 | Val Loss: 0.150152, Val Acc: 0.742268\n",
      "Epoch 9417 - Train Loss: 0.134620, Train Acc: 0.774359 | Val Loss: 0.150143, Val Acc: 0.742268\n",
      "Epoch 9418 - Train Loss: 0.134610, Train Acc: 0.773077 | Val Loss: 0.150135, Val Acc: 0.742268\n",
      "Epoch 9419 - Train Loss: 0.134601, Train Acc: 0.773077 | Val Loss: 0.150127, Val Acc: 0.742268\n",
      "Epoch 9420 - Train Loss: 0.134592, Train Acc: 0.773077 | Val Loss: 0.150119, Val Acc: 0.742268\n",
      "Epoch 9421 - Train Loss: 0.134583, Train Acc: 0.773077 | Val Loss: 0.150111, Val Acc: 0.742268\n",
      "Epoch 9422 - Train Loss: 0.134574, Train Acc: 0.773077 | Val Loss: 0.150103, Val Acc: 0.742268\n",
      "Epoch 9423 - Train Loss: 0.134564, Train Acc: 0.773077 | Val Loss: 0.150095, Val Acc: 0.742268\n",
      "Epoch 9424 - Train Loss: 0.134555, Train Acc: 0.773077 | Val Loss: 0.150087, Val Acc: 0.742268\n",
      "Epoch 9425 - Train Loss: 0.134546, Train Acc: 0.773077 | Val Loss: 0.150079, Val Acc: 0.742268\n",
      "Epoch 9426 - Train Loss: 0.134537, Train Acc: 0.773077 | Val Loss: 0.150071, Val Acc: 0.742268\n",
      "Epoch 9427 - Train Loss: 0.134527, Train Acc: 0.773077 | Val Loss: 0.150062, Val Acc: 0.742268\n",
      "Epoch 9428 - Train Loss: 0.134518, Train Acc: 0.773077 | Val Loss: 0.150054, Val Acc: 0.742268\n",
      "Epoch 9429 - Train Loss: 0.134509, Train Acc: 0.773077 | Val Loss: 0.150046, Val Acc: 0.742268\n",
      "Epoch 9430 - Train Loss: 0.134500, Train Acc: 0.773077 | Val Loss: 0.150038, Val Acc: 0.742268\n",
      "Epoch 9431 - Train Loss: 0.134491, Train Acc: 0.773077 | Val Loss: 0.150030, Val Acc: 0.742268\n",
      "Epoch 9432 - Train Loss: 0.134481, Train Acc: 0.773077 | Val Loss: 0.150022, Val Acc: 0.742268\n",
      "Epoch 9433 - Train Loss: 0.134472, Train Acc: 0.773077 | Val Loss: 0.150014, Val Acc: 0.742268\n",
      "Epoch 9434 - Train Loss: 0.134463, Train Acc: 0.773077 | Val Loss: 0.150006, Val Acc: 0.742268\n",
      "Epoch 9435 - Train Loss: 0.134454, Train Acc: 0.773077 | Val Loss: 0.149997, Val Acc: 0.742268\n",
      "Epoch 9436 - Train Loss: 0.134445, Train Acc: 0.773077 | Val Loss: 0.149989, Val Acc: 0.742268\n",
      "Epoch 9437 - Train Loss: 0.134436, Train Acc: 0.773077 | Val Loss: 0.149981, Val Acc: 0.742268\n",
      "Epoch 9438 - Train Loss: 0.134426, Train Acc: 0.773077 | Val Loss: 0.149973, Val Acc: 0.742268\n",
      "Epoch 9439 - Train Loss: 0.134417, Train Acc: 0.773077 | Val Loss: 0.149965, Val Acc: 0.742268\n",
      "Epoch 9440 - Train Loss: 0.134408, Train Acc: 0.773077 | Val Loss: 0.149957, Val Acc: 0.742268\n",
      "Epoch 9441 - Train Loss: 0.134399, Train Acc: 0.773077 | Val Loss: 0.149948, Val Acc: 0.742268\n",
      "Epoch 9442 - Train Loss: 0.134390, Train Acc: 0.773077 | Val Loss: 0.149940, Val Acc: 0.742268\n",
      "Epoch 9443 - Train Loss: 0.134380, Train Acc: 0.773077 | Val Loss: 0.149932, Val Acc: 0.742268\n",
      "Epoch 9444 - Train Loss: 0.134371, Train Acc: 0.773077 | Val Loss: 0.149924, Val Acc: 0.742268\n",
      "Epoch 9445 - Train Loss: 0.134362, Train Acc: 0.773077 | Val Loss: 0.149916, Val Acc: 0.742268\n",
      "Epoch 9446 - Train Loss: 0.134353, Train Acc: 0.773077 | Val Loss: 0.149908, Val Acc: 0.742268\n",
      "Epoch 9447 - Train Loss: 0.134344, Train Acc: 0.773077 | Val Loss: 0.149900, Val Acc: 0.742268\n",
      "Epoch 9448 - Train Loss: 0.134335, Train Acc: 0.773077 | Val Loss: 0.149892, Val Acc: 0.742268\n",
      "Epoch 9449 - Train Loss: 0.134325, Train Acc: 0.773077 | Val Loss: 0.149883, Val Acc: 0.742268\n",
      "Epoch 9450 - Train Loss: 0.134316, Train Acc: 0.773077 | Val Loss: 0.149875, Val Acc: 0.742268\n",
      "Epoch 9451 - Train Loss: 0.134307, Train Acc: 0.773077 | Val Loss: 0.149867, Val Acc: 0.742268\n",
      "Epoch 9452 - Train Loss: 0.134298, Train Acc: 0.773077 | Val Loss: 0.149859, Val Acc: 0.742268\n",
      "Epoch 9453 - Train Loss: 0.134289, Train Acc: 0.773077 | Val Loss: 0.149851, Val Acc: 0.742268\n",
      "Epoch 9454 - Train Loss: 0.134280, Train Acc: 0.773077 | Val Loss: 0.149843, Val Acc: 0.742268\n",
      "Epoch 9455 - Train Loss: 0.134270, Train Acc: 0.773077 | Val Loss: 0.149835, Val Acc: 0.742268\n",
      "Epoch 9456 - Train Loss: 0.134261, Train Acc: 0.773077 | Val Loss: 0.149827, Val Acc: 0.742268\n",
      "Epoch 9457 - Train Loss: 0.134252, Train Acc: 0.773077 | Val Loss: 0.149819, Val Acc: 0.742268\n",
      "Epoch 9458 - Train Loss: 0.134243, Train Acc: 0.773077 | Val Loss: 0.149811, Val Acc: 0.742268\n",
      "Epoch 9459 - Train Loss: 0.134234, Train Acc: 0.773077 | Val Loss: 0.149802, Val Acc: 0.742268\n",
      "Epoch 9460 - Train Loss: 0.134225, Train Acc: 0.773077 | Val Loss: 0.149794, Val Acc: 0.742268\n",
      "Epoch 9461 - Train Loss: 0.134215, Train Acc: 0.773077 | Val Loss: 0.149786, Val Acc: 0.742268\n",
      "Epoch 9462 - Train Loss: 0.134206, Train Acc: 0.773077 | Val Loss: 0.149778, Val Acc: 0.742268\n",
      "Epoch 9463 - Train Loss: 0.134197, Train Acc: 0.773077 | Val Loss: 0.149770, Val Acc: 0.742268\n",
      "Epoch 9464 - Train Loss: 0.134188, Train Acc: 0.773077 | Val Loss: 0.149762, Val Acc: 0.742268\n",
      "Epoch 9465 - Train Loss: 0.134179, Train Acc: 0.773077 | Val Loss: 0.149754, Val Acc: 0.742268\n",
      "Epoch 9466 - Train Loss: 0.134170, Train Acc: 0.773077 | Val Loss: 0.149746, Val Acc: 0.742268\n",
      "Epoch 9467 - Train Loss: 0.134161, Train Acc: 0.773077 | Val Loss: 0.149738, Val Acc: 0.742268\n",
      "Epoch 9468 - Train Loss: 0.134151, Train Acc: 0.773077 | Val Loss: 0.149730, Val Acc: 0.742268\n",
      "Epoch 9469 - Train Loss: 0.134142, Train Acc: 0.773077 | Val Loss: 0.149722, Val Acc: 0.742268\n",
      "Epoch 9470 - Train Loss: 0.134133, Train Acc: 0.773077 | Val Loss: 0.149714, Val Acc: 0.742268\n",
      "Epoch 9471 - Train Loss: 0.134124, Train Acc: 0.773077 | Val Loss: 0.149706, Val Acc: 0.742268\n",
      "Epoch 9472 - Train Loss: 0.134115, Train Acc: 0.773077 | Val Loss: 0.149698, Val Acc: 0.742268\n",
      "Epoch 9473 - Train Loss: 0.134106, Train Acc: 0.773077 | Val Loss: 0.149689, Val Acc: 0.742268\n",
      "Epoch 9474 - Train Loss: 0.134097, Train Acc: 0.773077 | Val Loss: 0.149681, Val Acc: 0.742268\n",
      "Epoch 9475 - Train Loss: 0.134087, Train Acc: 0.773077 | Val Loss: 0.149673, Val Acc: 0.742268\n",
      "Epoch 9476 - Train Loss: 0.134078, Train Acc: 0.773077 | Val Loss: 0.149665, Val Acc: 0.742268\n",
      "Epoch 9477 - Train Loss: 0.134069, Train Acc: 0.773077 | Val Loss: 0.149657, Val Acc: 0.742268\n",
      "Epoch 9478 - Train Loss: 0.134060, Train Acc: 0.773077 | Val Loss: 0.149649, Val Acc: 0.742268\n",
      "Epoch 9479 - Train Loss: 0.134051, Train Acc: 0.773077 | Val Loss: 0.149641, Val Acc: 0.742268\n",
      "Epoch 9480 - Train Loss: 0.134042, Train Acc: 0.773077 | Val Loss: 0.149633, Val Acc: 0.742268\n",
      "Epoch 9481 - Train Loss: 0.134033, Train Acc: 0.773077 | Val Loss: 0.149625, Val Acc: 0.742268\n",
      "Epoch 9482 - Train Loss: 0.134024, Train Acc: 0.773077 | Val Loss: 0.149617, Val Acc: 0.742268\n",
      "Epoch 9483 - Train Loss: 0.134014, Train Acc: 0.773077 | Val Loss: 0.149609, Val Acc: 0.742268\n",
      "Epoch 9484 - Train Loss: 0.134005, Train Acc: 0.773077 | Val Loss: 0.149601, Val Acc: 0.742268\n",
      "Epoch 9485 - Train Loss: 0.133996, Train Acc: 0.773077 | Val Loss: 0.149593, Val Acc: 0.742268\n",
      "Epoch 9486 - Train Loss: 0.133987, Train Acc: 0.773077 | Val Loss: 0.149585, Val Acc: 0.742268\n",
      "Epoch 9487 - Train Loss: 0.133978, Train Acc: 0.773077 | Val Loss: 0.149577, Val Acc: 0.742268\n",
      "Epoch 9488 - Train Loss: 0.133969, Train Acc: 0.773077 | Val Loss: 0.149569, Val Acc: 0.742268\n",
      "Epoch 9489 - Train Loss: 0.133960, Train Acc: 0.773077 | Val Loss: 0.149561, Val Acc: 0.742268\n",
      "Epoch 9490 - Train Loss: 0.133951, Train Acc: 0.773077 | Val Loss: 0.149553, Val Acc: 0.742268\n",
      "Epoch 9491 - Train Loss: 0.133942, Train Acc: 0.773077 | Val Loss: 0.149545, Val Acc: 0.742268\n",
      "Epoch 9492 - Train Loss: 0.133932, Train Acc: 0.773077 | Val Loss: 0.149537, Val Acc: 0.742268\n",
      "Epoch 9493 - Train Loss: 0.133923, Train Acc: 0.773077 | Val Loss: 0.149529, Val Acc: 0.742268\n",
      "Epoch 9494 - Train Loss: 0.133914, Train Acc: 0.773077 | Val Loss: 0.149521, Val Acc: 0.742268\n",
      "Epoch 9495 - Train Loss: 0.133905, Train Acc: 0.773077 | Val Loss: 0.149513, Val Acc: 0.742268\n",
      "Epoch 9496 - Train Loss: 0.133896, Train Acc: 0.773077 | Val Loss: 0.149505, Val Acc: 0.742268\n",
      "Epoch 9497 - Train Loss: 0.133887, Train Acc: 0.773077 | Val Loss: 0.149497, Val Acc: 0.742268\n",
      "Epoch 9498 - Train Loss: 0.133878, Train Acc: 0.773077 | Val Loss: 0.149489, Val Acc: 0.742268\n",
      "Epoch 9499 - Train Loss: 0.133869, Train Acc: 0.773077 | Val Loss: 0.149481, Val Acc: 0.742268\n",
      "Epoch 9500 - Train Loss: 0.133860, Train Acc: 0.773077 | Val Loss: 0.149473, Val Acc: 0.742268\n",
      "Epoch 9501 - Train Loss: 0.133851, Train Acc: 0.773077 | Val Loss: 0.149465, Val Acc: 0.742268\n",
      "Epoch 9502 - Train Loss: 0.133841, Train Acc: 0.773077 | Val Loss: 0.149457, Val Acc: 0.742268\n",
      "Epoch 9503 - Train Loss: 0.133832, Train Acc: 0.773077 | Val Loss: 0.149449, Val Acc: 0.742268\n",
      "Epoch 9504 - Train Loss: 0.133823, Train Acc: 0.773077 | Val Loss: 0.149441, Val Acc: 0.742268\n",
      "Epoch 9505 - Train Loss: 0.133814, Train Acc: 0.773077 | Val Loss: 0.149433, Val Acc: 0.742268\n",
      "Epoch 9506 - Train Loss: 0.133805, Train Acc: 0.773077 | Val Loss: 0.149425, Val Acc: 0.742268\n",
      "Epoch 9507 - Train Loss: 0.133796, Train Acc: 0.773077 | Val Loss: 0.149417, Val Acc: 0.742268\n",
      "Epoch 9508 - Train Loss: 0.133787, Train Acc: 0.773077 | Val Loss: 0.149409, Val Acc: 0.742268\n",
      "Epoch 9509 - Train Loss: 0.133778, Train Acc: 0.773077 | Val Loss: 0.149401, Val Acc: 0.742268\n",
      "Epoch 9510 - Train Loss: 0.133769, Train Acc: 0.773077 | Val Loss: 0.149393, Val Acc: 0.742268\n",
      "Epoch 9511 - Train Loss: 0.133760, Train Acc: 0.773077 | Val Loss: 0.149385, Val Acc: 0.742268\n",
      "Epoch 9512 - Train Loss: 0.133751, Train Acc: 0.773077 | Val Loss: 0.149377, Val Acc: 0.742268\n",
      "Epoch 9513 - Train Loss: 0.133741, Train Acc: 0.773077 | Val Loss: 0.149369, Val Acc: 0.742268\n",
      "Epoch 9514 - Train Loss: 0.133732, Train Acc: 0.773077 | Val Loss: 0.149361, Val Acc: 0.742268\n",
      "Epoch 9515 - Train Loss: 0.133723, Train Acc: 0.773077 | Val Loss: 0.149353, Val Acc: 0.742268\n",
      "Epoch 9516 - Train Loss: 0.133714, Train Acc: 0.773077 | Val Loss: 0.149345, Val Acc: 0.742268\n",
      "Epoch 9517 - Train Loss: 0.133705, Train Acc: 0.773077 | Val Loss: 0.149337, Val Acc: 0.742268\n",
      "Epoch 9518 - Train Loss: 0.133696, Train Acc: 0.773077 | Val Loss: 0.149329, Val Acc: 0.742268\n",
      "Epoch 9519 - Train Loss: 0.133687, Train Acc: 0.773077 | Val Loss: 0.149321, Val Acc: 0.742268\n",
      "Epoch 9520 - Train Loss: 0.133678, Train Acc: 0.773077 | Val Loss: 0.149313, Val Acc: 0.742268\n",
      "Epoch 9521 - Train Loss: 0.133669, Train Acc: 0.773077 | Val Loss: 0.149305, Val Acc: 0.742268\n",
      "Epoch 9522 - Train Loss: 0.133660, Train Acc: 0.773077 | Val Loss: 0.149297, Val Acc: 0.742268\n",
      "Epoch 9523 - Train Loss: 0.133651, Train Acc: 0.773077 | Val Loss: 0.149289, Val Acc: 0.742268\n",
      "Epoch 9524 - Train Loss: 0.133642, Train Acc: 0.773077 | Val Loss: 0.149281, Val Acc: 0.742268\n",
      "Epoch 9525 - Train Loss: 0.133633, Train Acc: 0.773077 | Val Loss: 0.149273, Val Acc: 0.742268\n",
      "Epoch 9526 - Train Loss: 0.133624, Train Acc: 0.773077 | Val Loss: 0.149265, Val Acc: 0.742268\n",
      "Epoch 9527 - Train Loss: 0.133615, Train Acc: 0.773077 | Val Loss: 0.149257, Val Acc: 0.742268\n",
      "Epoch 9528 - Train Loss: 0.133605, Train Acc: 0.773077 | Val Loss: 0.149249, Val Acc: 0.742268\n",
      "Epoch 9529 - Train Loss: 0.133596, Train Acc: 0.773077 | Val Loss: 0.149241, Val Acc: 0.742268\n",
      "Epoch 9530 - Train Loss: 0.133587, Train Acc: 0.773077 | Val Loss: 0.149233, Val Acc: 0.742268\n",
      "Epoch 9531 - Train Loss: 0.133578, Train Acc: 0.773077 | Val Loss: 0.149225, Val Acc: 0.742268\n",
      "Epoch 9532 - Train Loss: 0.133569, Train Acc: 0.773077 | Val Loss: 0.149218, Val Acc: 0.742268\n",
      "Epoch 9533 - Train Loss: 0.133560, Train Acc: 0.773077 | Val Loss: 0.149210, Val Acc: 0.742268\n",
      "Epoch 9534 - Train Loss: 0.133551, Train Acc: 0.773077 | Val Loss: 0.149202, Val Acc: 0.742268\n",
      "Epoch 9535 - Train Loss: 0.133542, Train Acc: 0.773077 | Val Loss: 0.149194, Val Acc: 0.742268\n",
      "Epoch 9536 - Train Loss: 0.133533, Train Acc: 0.773077 | Val Loss: 0.149186, Val Acc: 0.742268\n",
      "Epoch 9537 - Train Loss: 0.133524, Train Acc: 0.773077 | Val Loss: 0.149178, Val Acc: 0.742268\n",
      "Epoch 9538 - Train Loss: 0.133515, Train Acc: 0.773077 | Val Loss: 0.149170, Val Acc: 0.742268\n",
      "Epoch 9539 - Train Loss: 0.133506, Train Acc: 0.773077 | Val Loss: 0.149162, Val Acc: 0.742268\n",
      "Epoch 9540 - Train Loss: 0.133497, Train Acc: 0.773077 | Val Loss: 0.149154, Val Acc: 0.742268\n",
      "Epoch 9541 - Train Loss: 0.133488, Train Acc: 0.773077 | Val Loss: 0.149146, Val Acc: 0.742268\n",
      "Epoch 9542 - Train Loss: 0.133479, Train Acc: 0.773077 | Val Loss: 0.149138, Val Acc: 0.742268\n",
      "Epoch 9543 - Train Loss: 0.133470, Train Acc: 0.773077 | Val Loss: 0.149130, Val Acc: 0.742268\n",
      "Epoch 9544 - Train Loss: 0.133461, Train Acc: 0.773077 | Val Loss: 0.149122, Val Acc: 0.742268\n",
      "Epoch 9545 - Train Loss: 0.133452, Train Acc: 0.773077 | Val Loss: 0.149114, Val Acc: 0.742268\n",
      "Epoch 9546 - Train Loss: 0.133443, Train Acc: 0.773077 | Val Loss: 0.149106, Val Acc: 0.742268\n",
      "Epoch 9547 - Train Loss: 0.133434, Train Acc: 0.773077 | Val Loss: 0.149098, Val Acc: 0.742268\n",
      "Epoch 9548 - Train Loss: 0.133425, Train Acc: 0.773077 | Val Loss: 0.149091, Val Acc: 0.742268\n",
      "Epoch 9549 - Train Loss: 0.133416, Train Acc: 0.773077 | Val Loss: 0.149083, Val Acc: 0.742268\n",
      "Epoch 9550 - Train Loss: 0.133407, Train Acc: 0.773077 | Val Loss: 0.149075, Val Acc: 0.742268\n",
      "Epoch 9551 - Train Loss: 0.133398, Train Acc: 0.773077 | Val Loss: 0.149067, Val Acc: 0.742268\n",
      "Epoch 9552 - Train Loss: 0.133389, Train Acc: 0.773077 | Val Loss: 0.149059, Val Acc: 0.742268\n",
      "Epoch 9553 - Train Loss: 0.133379, Train Acc: 0.773077 | Val Loss: 0.149051, Val Acc: 0.742268\n",
      "Epoch 9554 - Train Loss: 0.133370, Train Acc: 0.773077 | Val Loss: 0.149043, Val Acc: 0.742268\n",
      "Epoch 9555 - Train Loss: 0.133361, Train Acc: 0.773077 | Val Loss: 0.149035, Val Acc: 0.742268\n",
      "Epoch 9556 - Train Loss: 0.133352, Train Acc: 0.773077 | Val Loss: 0.149027, Val Acc: 0.742268\n",
      "Epoch 9557 - Train Loss: 0.133343, Train Acc: 0.773077 | Val Loss: 0.149019, Val Acc: 0.742268\n",
      "Epoch 9558 - Train Loss: 0.133334, Train Acc: 0.773077 | Val Loss: 0.149011, Val Acc: 0.742268\n",
      "Epoch 9559 - Train Loss: 0.133325, Train Acc: 0.773077 | Val Loss: 0.149003, Val Acc: 0.742268\n",
      "Epoch 9560 - Train Loss: 0.133316, Train Acc: 0.773077 | Val Loss: 0.148996, Val Acc: 0.742268\n",
      "Epoch 9561 - Train Loss: 0.133307, Train Acc: 0.773077 | Val Loss: 0.148988, Val Acc: 0.742268\n",
      "Epoch 9562 - Train Loss: 0.133298, Train Acc: 0.773077 | Val Loss: 0.148980, Val Acc: 0.742268\n",
      "Epoch 9563 - Train Loss: 0.133289, Train Acc: 0.773077 | Val Loss: 0.148972, Val Acc: 0.742268\n",
      "Epoch 9564 - Train Loss: 0.133280, Train Acc: 0.773077 | Val Loss: 0.148964, Val Acc: 0.742268\n",
      "Epoch 9565 - Train Loss: 0.133271, Train Acc: 0.773077 | Val Loss: 0.148956, Val Acc: 0.742268\n",
      "Epoch 9566 - Train Loss: 0.133262, Train Acc: 0.773077 | Val Loss: 0.148948, Val Acc: 0.742268\n",
      "Epoch 9567 - Train Loss: 0.133253, Train Acc: 0.773077 | Val Loss: 0.148940, Val Acc: 0.742268\n",
      "Epoch 9568 - Train Loss: 0.133244, Train Acc: 0.773077 | Val Loss: 0.148932, Val Acc: 0.742268\n",
      "Epoch 9569 - Train Loss: 0.133235, Train Acc: 0.773077 | Val Loss: 0.148924, Val Acc: 0.742268\n",
      "Epoch 9570 - Train Loss: 0.133226, Train Acc: 0.773077 | Val Loss: 0.148917, Val Acc: 0.742268\n",
      "Epoch 9571 - Train Loss: 0.133217, Train Acc: 0.773077 | Val Loss: 0.148909, Val Acc: 0.742268\n",
      "Epoch 9572 - Train Loss: 0.133208, Train Acc: 0.773077 | Val Loss: 0.148901, Val Acc: 0.742268\n",
      "Epoch 9573 - Train Loss: 0.133199, Train Acc: 0.773077 | Val Loss: 0.148893, Val Acc: 0.742268\n",
      "Epoch 9574 - Train Loss: 0.133190, Train Acc: 0.773077 | Val Loss: 0.148885, Val Acc: 0.742268\n",
      "Epoch 9575 - Train Loss: 0.133181, Train Acc: 0.773077 | Val Loss: 0.148877, Val Acc: 0.742268\n",
      "Epoch 9576 - Train Loss: 0.133172, Train Acc: 0.773077 | Val Loss: 0.148869, Val Acc: 0.742268\n",
      "Epoch 9577 - Train Loss: 0.133163, Train Acc: 0.773077 | Val Loss: 0.148861, Val Acc: 0.742268\n",
      "Epoch 9578 - Train Loss: 0.133154, Train Acc: 0.773077 | Val Loss: 0.148854, Val Acc: 0.742268\n",
      "Epoch 9579 - Train Loss: 0.133145, Train Acc: 0.773077 | Val Loss: 0.148846, Val Acc: 0.742268\n",
      "Epoch 9580 - Train Loss: 0.133136, Train Acc: 0.773077 | Val Loss: 0.148838, Val Acc: 0.752577\n",
      "Epoch 9581 - Train Loss: 0.133127, Train Acc: 0.773077 | Val Loss: 0.148830, Val Acc: 0.752577\n",
      "Epoch 9582 - Train Loss: 0.133118, Train Acc: 0.773077 | Val Loss: 0.148822, Val Acc: 0.752577\n",
      "Epoch 9583 - Train Loss: 0.133109, Train Acc: 0.773077 | Val Loss: 0.148814, Val Acc: 0.752577\n",
      "Epoch 9584 - Train Loss: 0.133101, Train Acc: 0.773077 | Val Loss: 0.148806, Val Acc: 0.752577\n",
      "Epoch 9585 - Train Loss: 0.133092, Train Acc: 0.773077 | Val Loss: 0.148798, Val Acc: 0.752577\n",
      "Epoch 9586 - Train Loss: 0.133083, Train Acc: 0.773077 | Val Loss: 0.148791, Val Acc: 0.752577\n",
      "Epoch 9587 - Train Loss: 0.133074, Train Acc: 0.773077 | Val Loss: 0.148783, Val Acc: 0.752577\n",
      "Epoch 9588 - Train Loss: 0.133065, Train Acc: 0.773077 | Val Loss: 0.148775, Val Acc: 0.752577\n",
      "Epoch 9589 - Train Loss: 0.133056, Train Acc: 0.773077 | Val Loss: 0.148767, Val Acc: 0.752577\n",
      "Epoch 9590 - Train Loss: 0.133047, Train Acc: 0.773077 | Val Loss: 0.148759, Val Acc: 0.752577\n",
      "Epoch 9591 - Train Loss: 0.133038, Train Acc: 0.774359 | Val Loss: 0.148751, Val Acc: 0.752577\n",
      "Epoch 9592 - Train Loss: 0.133029, Train Acc: 0.774359 | Val Loss: 0.148743, Val Acc: 0.752577\n",
      "Epoch 9593 - Train Loss: 0.133020, Train Acc: 0.774359 | Val Loss: 0.148736, Val Acc: 0.752577\n",
      "Epoch 9594 - Train Loss: 0.133011, Train Acc: 0.774359 | Val Loss: 0.148728, Val Acc: 0.752577\n",
      "Epoch 9595 - Train Loss: 0.133002, Train Acc: 0.774359 | Val Loss: 0.148720, Val Acc: 0.752577\n",
      "Epoch 9596 - Train Loss: 0.132993, Train Acc: 0.774359 | Val Loss: 0.148712, Val Acc: 0.752577\n",
      "Epoch 9597 - Train Loss: 0.132984, Train Acc: 0.774359 | Val Loss: 0.148704, Val Acc: 0.752577\n",
      "Epoch 9598 - Train Loss: 0.132975, Train Acc: 0.774359 | Val Loss: 0.148696, Val Acc: 0.752577\n",
      "Epoch 9599 - Train Loss: 0.132966, Train Acc: 0.774359 | Val Loss: 0.148688, Val Acc: 0.752577\n",
      "Epoch 9600 - Train Loss: 0.132957, Train Acc: 0.774359 | Val Loss: 0.148681, Val Acc: 0.752577\n",
      "Epoch 9601 - Train Loss: 0.132948, Train Acc: 0.774359 | Val Loss: 0.148673, Val Acc: 0.752577\n",
      "Epoch 9602 - Train Loss: 0.132939, Train Acc: 0.774359 | Val Loss: 0.148665, Val Acc: 0.752577\n",
      "Epoch 9603 - Train Loss: 0.132930, Train Acc: 0.774359 | Val Loss: 0.148657, Val Acc: 0.752577\n",
      "Epoch 9604 - Train Loss: 0.132921, Train Acc: 0.774359 | Val Loss: 0.148649, Val Acc: 0.752577\n",
      "Epoch 9605 - Train Loss: 0.132912, Train Acc: 0.774359 | Val Loss: 0.148641, Val Acc: 0.752577\n",
      "Epoch 9606 - Train Loss: 0.132903, Train Acc: 0.774359 | Val Loss: 0.148634, Val Acc: 0.752577\n",
      "Epoch 9607 - Train Loss: 0.132894, Train Acc: 0.774359 | Val Loss: 0.148626, Val Acc: 0.752577\n",
      "Epoch 9608 - Train Loss: 0.132885, Train Acc: 0.774359 | Val Loss: 0.148618, Val Acc: 0.752577\n",
      "Epoch 9609 - Train Loss: 0.132877, Train Acc: 0.774359 | Val Loss: 0.148610, Val Acc: 0.752577\n",
      "Epoch 9610 - Train Loss: 0.132868, Train Acc: 0.774359 | Val Loss: 0.148602, Val Acc: 0.752577\n",
      "Epoch 9611 - Train Loss: 0.132859, Train Acc: 0.774359 | Val Loss: 0.148594, Val Acc: 0.752577\n",
      "Epoch 9612 - Train Loss: 0.132850, Train Acc: 0.774359 | Val Loss: 0.148587, Val Acc: 0.752577\n",
      "Epoch 9613 - Train Loss: 0.132841, Train Acc: 0.774359 | Val Loss: 0.148579, Val Acc: 0.752577\n",
      "Epoch 9614 - Train Loss: 0.132832, Train Acc: 0.774359 | Val Loss: 0.148571, Val Acc: 0.752577\n",
      "Epoch 9615 - Train Loss: 0.132823, Train Acc: 0.774359 | Val Loss: 0.148563, Val Acc: 0.752577\n",
      "Epoch 9616 - Train Loss: 0.132814, Train Acc: 0.774359 | Val Loss: 0.148555, Val Acc: 0.752577\n",
      "Epoch 9617 - Train Loss: 0.132805, Train Acc: 0.774359 | Val Loss: 0.148548, Val Acc: 0.752577\n",
      "Epoch 9618 - Train Loss: 0.132796, Train Acc: 0.774359 | Val Loss: 0.148540, Val Acc: 0.752577\n",
      "Epoch 9619 - Train Loss: 0.132787, Train Acc: 0.774359 | Val Loss: 0.148532, Val Acc: 0.752577\n",
      "Epoch 9620 - Train Loss: 0.132778, Train Acc: 0.774359 | Val Loss: 0.148524, Val Acc: 0.752577\n",
      "Epoch 9621 - Train Loss: 0.132769, Train Acc: 0.774359 | Val Loss: 0.148516, Val Acc: 0.752577\n",
      "Epoch 9622 - Train Loss: 0.132760, Train Acc: 0.774359 | Val Loss: 0.148508, Val Acc: 0.752577\n",
      "Epoch 9623 - Train Loss: 0.132751, Train Acc: 0.774359 | Val Loss: 0.148501, Val Acc: 0.752577\n",
      "Epoch 9624 - Train Loss: 0.132743, Train Acc: 0.774359 | Val Loss: 0.148493, Val Acc: 0.752577\n",
      "Epoch 9625 - Train Loss: 0.132734, Train Acc: 0.774359 | Val Loss: 0.148485, Val Acc: 0.752577\n",
      "Epoch 9626 - Train Loss: 0.132725, Train Acc: 0.774359 | Val Loss: 0.148478, Val Acc: 0.752577\n",
      "Epoch 9627 - Train Loss: 0.132716, Train Acc: 0.774359 | Val Loss: 0.148470, Val Acc: 0.752577\n",
      "Epoch 9628 - Train Loss: 0.132707, Train Acc: 0.774359 | Val Loss: 0.148462, Val Acc: 0.752577\n",
      "Epoch 9629 - Train Loss: 0.132698, Train Acc: 0.774359 | Val Loss: 0.148455, Val Acc: 0.752577\n",
      "Epoch 9630 - Train Loss: 0.132689, Train Acc: 0.774359 | Val Loss: 0.148447, Val Acc: 0.752577\n",
      "Epoch 9631 - Train Loss: 0.132680, Train Acc: 0.774359 | Val Loss: 0.148440, Val Acc: 0.752577\n",
      "Epoch 9632 - Train Loss: 0.132671, Train Acc: 0.774359 | Val Loss: 0.148432, Val Acc: 0.752577\n",
      "Epoch 9633 - Train Loss: 0.132662, Train Acc: 0.775641 | Val Loss: 0.148424, Val Acc: 0.752577\n",
      "Epoch 9634 - Train Loss: 0.132653, Train Acc: 0.775641 | Val Loss: 0.148417, Val Acc: 0.752577\n",
      "Epoch 9635 - Train Loss: 0.132645, Train Acc: 0.775641 | Val Loss: 0.148409, Val Acc: 0.752577\n",
      "Epoch 9636 - Train Loss: 0.132636, Train Acc: 0.775641 | Val Loss: 0.148401, Val Acc: 0.752577\n",
      "Epoch 9637 - Train Loss: 0.132627, Train Acc: 0.775641 | Val Loss: 0.148394, Val Acc: 0.752577\n",
      "Epoch 9638 - Train Loss: 0.132618, Train Acc: 0.775641 | Val Loss: 0.148386, Val Acc: 0.752577\n",
      "Epoch 9639 - Train Loss: 0.132609, Train Acc: 0.775641 | Val Loss: 0.148379, Val Acc: 0.752577\n",
      "Epoch 9640 - Train Loss: 0.132600, Train Acc: 0.775641 | Val Loss: 0.148371, Val Acc: 0.752577\n",
      "Epoch 9641 - Train Loss: 0.132591, Train Acc: 0.775641 | Val Loss: 0.148363, Val Acc: 0.752577\n",
      "Epoch 9642 - Train Loss: 0.132582, Train Acc: 0.775641 | Val Loss: 0.148356, Val Acc: 0.752577\n",
      "Epoch 9643 - Train Loss: 0.132573, Train Acc: 0.775641 | Val Loss: 0.148348, Val Acc: 0.752577\n",
      "Epoch 9644 - Train Loss: 0.132565, Train Acc: 0.775641 | Val Loss: 0.148340, Val Acc: 0.752577\n",
      "Epoch 9645 - Train Loss: 0.132556, Train Acc: 0.775641 | Val Loss: 0.148333, Val Acc: 0.752577\n",
      "Epoch 9646 - Train Loss: 0.132547, Train Acc: 0.775641 | Val Loss: 0.148325, Val Acc: 0.752577\n",
      "Epoch 9647 - Train Loss: 0.132538, Train Acc: 0.775641 | Val Loss: 0.148317, Val Acc: 0.752577\n",
      "Epoch 9648 - Train Loss: 0.132529, Train Acc: 0.775641 | Val Loss: 0.148310, Val Acc: 0.752577\n",
      "Epoch 9649 - Train Loss: 0.132520, Train Acc: 0.775641 | Val Loss: 0.148302, Val Acc: 0.752577\n",
      "Epoch 9650 - Train Loss: 0.132511, Train Acc: 0.775641 | Val Loss: 0.148294, Val Acc: 0.752577\n",
      "Epoch 9651 - Train Loss: 0.132502, Train Acc: 0.775641 | Val Loss: 0.148287, Val Acc: 0.752577\n",
      "Epoch 9652 - Train Loss: 0.132493, Train Acc: 0.775641 | Val Loss: 0.148279, Val Acc: 0.752577\n",
      "Epoch 9653 - Train Loss: 0.132485, Train Acc: 0.775641 | Val Loss: 0.148271, Val Acc: 0.752577\n",
      "Epoch 9654 - Train Loss: 0.132476, Train Acc: 0.775641 | Val Loss: 0.148264, Val Acc: 0.752577\n",
      "Epoch 9655 - Train Loss: 0.132467, Train Acc: 0.775641 | Val Loss: 0.148256, Val Acc: 0.752577\n",
      "Epoch 9656 - Train Loss: 0.132458, Train Acc: 0.775641 | Val Loss: 0.148248, Val Acc: 0.752577\n",
      "Epoch 9657 - Train Loss: 0.132449, Train Acc: 0.775641 | Val Loss: 0.148241, Val Acc: 0.752577\n",
      "Epoch 9658 - Train Loss: 0.132440, Train Acc: 0.775641 | Val Loss: 0.148233, Val Acc: 0.752577\n",
      "Epoch 9659 - Train Loss: 0.132431, Train Acc: 0.775641 | Val Loss: 0.148225, Val Acc: 0.752577\n",
      "Epoch 9660 - Train Loss: 0.132423, Train Acc: 0.775641 | Val Loss: 0.148217, Val Acc: 0.752577\n",
      "Epoch 9661 - Train Loss: 0.132414, Train Acc: 0.775641 | Val Loss: 0.148210, Val Acc: 0.752577\n",
      "Epoch 9662 - Train Loss: 0.132405, Train Acc: 0.775641 | Val Loss: 0.148202, Val Acc: 0.752577\n",
      "Epoch 9663 - Train Loss: 0.132396, Train Acc: 0.775641 | Val Loss: 0.148194, Val Acc: 0.752577\n",
      "Epoch 9664 - Train Loss: 0.132387, Train Acc: 0.775641 | Val Loss: 0.148187, Val Acc: 0.752577\n",
      "Epoch 9665 - Train Loss: 0.132378, Train Acc: 0.775641 | Val Loss: 0.148179, Val Acc: 0.752577\n",
      "Epoch 9666 - Train Loss: 0.132369, Train Acc: 0.775641 | Val Loss: 0.148171, Val Acc: 0.752577\n",
      "Epoch 9667 - Train Loss: 0.132361, Train Acc: 0.775641 | Val Loss: 0.148163, Val Acc: 0.752577\n",
      "Epoch 9668 - Train Loss: 0.132352, Train Acc: 0.775641 | Val Loss: 0.148156, Val Acc: 0.752577\n",
      "Epoch 9669 - Train Loss: 0.132343, Train Acc: 0.775641 | Val Loss: 0.148148, Val Acc: 0.752577\n",
      "Epoch 9670 - Train Loss: 0.132334, Train Acc: 0.775641 | Val Loss: 0.148140, Val Acc: 0.752577\n",
      "Epoch 9671 - Train Loss: 0.132325, Train Acc: 0.775641 | Val Loss: 0.148133, Val Acc: 0.752577\n",
      "Epoch 9672 - Train Loss: 0.132316, Train Acc: 0.775641 | Val Loss: 0.148125, Val Acc: 0.752577\n",
      "Epoch 9673 - Train Loss: 0.132307, Train Acc: 0.775641 | Val Loss: 0.148117, Val Acc: 0.752577\n",
      "Epoch 9674 - Train Loss: 0.132299, Train Acc: 0.775641 | Val Loss: 0.148109, Val Acc: 0.752577\n",
      "Epoch 9675 - Train Loss: 0.132290, Train Acc: 0.775641 | Val Loss: 0.148102, Val Acc: 0.752577\n",
      "Epoch 9676 - Train Loss: 0.132281, Train Acc: 0.775641 | Val Loss: 0.148094, Val Acc: 0.752577\n",
      "Epoch 9677 - Train Loss: 0.132272, Train Acc: 0.775641 | Val Loss: 0.148086, Val Acc: 0.752577\n",
      "Epoch 9678 - Train Loss: 0.132263, Train Acc: 0.775641 | Val Loss: 0.148079, Val Acc: 0.752577\n",
      "Epoch 9679 - Train Loss: 0.132254, Train Acc: 0.775641 | Val Loss: 0.148071, Val Acc: 0.752577\n",
      "Epoch 9680 - Train Loss: 0.132246, Train Acc: 0.775641 | Val Loss: 0.148063, Val Acc: 0.752577\n",
      "Epoch 9681 - Train Loss: 0.132237, Train Acc: 0.775641 | Val Loss: 0.148056, Val Acc: 0.752577\n",
      "Epoch 9682 - Train Loss: 0.132228, Train Acc: 0.775641 | Val Loss: 0.148048, Val Acc: 0.752577\n",
      "Epoch 9683 - Train Loss: 0.132219, Train Acc: 0.775641 | Val Loss: 0.148040, Val Acc: 0.752577\n",
      "Epoch 9684 - Train Loss: 0.132210, Train Acc: 0.775641 | Val Loss: 0.148033, Val Acc: 0.752577\n",
      "Epoch 9685 - Train Loss: 0.132201, Train Acc: 0.775641 | Val Loss: 0.148025, Val Acc: 0.752577\n",
      "Epoch 9686 - Train Loss: 0.132193, Train Acc: 0.775641 | Val Loss: 0.148017, Val Acc: 0.752577\n",
      "Epoch 9687 - Train Loss: 0.132184, Train Acc: 0.775641 | Val Loss: 0.148009, Val Acc: 0.752577\n",
      "Epoch 9688 - Train Loss: 0.132175, Train Acc: 0.775641 | Val Loss: 0.148002, Val Acc: 0.752577\n",
      "Epoch 9689 - Train Loss: 0.132166, Train Acc: 0.775641 | Val Loss: 0.147994, Val Acc: 0.752577\n",
      "Epoch 9690 - Train Loss: 0.132157, Train Acc: 0.775641 | Val Loss: 0.147986, Val Acc: 0.752577\n",
      "Epoch 9691 - Train Loss: 0.132148, Train Acc: 0.775641 | Val Loss: 0.147979, Val Acc: 0.752577\n",
      "Epoch 9692 - Train Loss: 0.132140, Train Acc: 0.775641 | Val Loss: 0.147971, Val Acc: 0.752577\n",
      "Epoch 9693 - Train Loss: 0.132131, Train Acc: 0.775641 | Val Loss: 0.147963, Val Acc: 0.752577\n",
      "Epoch 9694 - Train Loss: 0.132122, Train Acc: 0.775641 | Val Loss: 0.147956, Val Acc: 0.752577\n",
      "Epoch 9695 - Train Loss: 0.132113, Train Acc: 0.775641 | Val Loss: 0.147948, Val Acc: 0.752577\n",
      "Epoch 9696 - Train Loss: 0.132104, Train Acc: 0.775641 | Val Loss: 0.147940, Val Acc: 0.752577\n",
      "Epoch 9697 - Train Loss: 0.132096, Train Acc: 0.775641 | Val Loss: 0.147933, Val Acc: 0.752577\n",
      "Epoch 9698 - Train Loss: 0.132087, Train Acc: 0.775641 | Val Loss: 0.147925, Val Acc: 0.752577\n",
      "Epoch 9699 - Train Loss: 0.132078, Train Acc: 0.775641 | Val Loss: 0.147917, Val Acc: 0.752577\n",
      "Epoch 9700 - Train Loss: 0.132069, Train Acc: 0.775641 | Val Loss: 0.147910, Val Acc: 0.752577\n",
      "Epoch 9701 - Train Loss: 0.132060, Train Acc: 0.775641 | Val Loss: 0.147902, Val Acc: 0.752577\n",
      "Epoch 9702 - Train Loss: 0.132052, Train Acc: 0.775641 | Val Loss: 0.147894, Val Acc: 0.752577\n",
      "Epoch 9703 - Train Loss: 0.132043, Train Acc: 0.775641 | Val Loss: 0.147887, Val Acc: 0.752577\n",
      "Epoch 9704 - Train Loss: 0.132034, Train Acc: 0.775641 | Val Loss: 0.147879, Val Acc: 0.752577\n",
      "Epoch 9705 - Train Loss: 0.132025, Train Acc: 0.775641 | Val Loss: 0.147871, Val Acc: 0.752577\n",
      "Epoch 9706 - Train Loss: 0.132016, Train Acc: 0.775641 | Val Loss: 0.147864, Val Acc: 0.752577\n",
      "Epoch 9707 - Train Loss: 0.132008, Train Acc: 0.775641 | Val Loss: 0.147856, Val Acc: 0.752577\n",
      "Epoch 9708 - Train Loss: 0.131999, Train Acc: 0.775641 | Val Loss: 0.147848, Val Acc: 0.752577\n",
      "Epoch 9709 - Train Loss: 0.131990, Train Acc: 0.775641 | Val Loss: 0.147841, Val Acc: 0.752577\n",
      "Epoch 9710 - Train Loss: 0.131981, Train Acc: 0.775641 | Val Loss: 0.147833, Val Acc: 0.752577\n",
      "Epoch 9711 - Train Loss: 0.131972, Train Acc: 0.775641 | Val Loss: 0.147825, Val Acc: 0.752577\n",
      "Epoch 9712 - Train Loss: 0.131964, Train Acc: 0.775641 | Val Loss: 0.147818, Val Acc: 0.752577\n",
      "Epoch 9713 - Train Loss: 0.131955, Train Acc: 0.775641 | Val Loss: 0.147810, Val Acc: 0.752577\n",
      "Epoch 9714 - Train Loss: 0.131946, Train Acc: 0.775641 | Val Loss: 0.147802, Val Acc: 0.752577\n",
      "Epoch 9715 - Train Loss: 0.131937, Train Acc: 0.775641 | Val Loss: 0.147795, Val Acc: 0.752577\n",
      "Epoch 9716 - Train Loss: 0.131928, Train Acc: 0.775641 | Val Loss: 0.147787, Val Acc: 0.752577\n",
      "Epoch 9717 - Train Loss: 0.131920, Train Acc: 0.775641 | Val Loss: 0.147779, Val Acc: 0.752577\n",
      "Epoch 9718 - Train Loss: 0.131911, Train Acc: 0.775641 | Val Loss: 0.147772, Val Acc: 0.752577\n",
      "Epoch 9719 - Train Loss: 0.131902, Train Acc: 0.775641 | Val Loss: 0.147764, Val Acc: 0.752577\n",
      "Epoch 9720 - Train Loss: 0.131893, Train Acc: 0.775641 | Val Loss: 0.147756, Val Acc: 0.752577\n",
      "Epoch 9721 - Train Loss: 0.131885, Train Acc: 0.775641 | Val Loss: 0.147749, Val Acc: 0.752577\n",
      "Epoch 9722 - Train Loss: 0.131876, Train Acc: 0.775641 | Val Loss: 0.147741, Val Acc: 0.752577\n",
      "Epoch 9723 - Train Loss: 0.131867, Train Acc: 0.775641 | Val Loss: 0.147733, Val Acc: 0.752577\n",
      "Epoch 9724 - Train Loss: 0.131858, Train Acc: 0.775641 | Val Loss: 0.147726, Val Acc: 0.752577\n",
      "Epoch 9725 - Train Loss: 0.131849, Train Acc: 0.775641 | Val Loss: 0.147718, Val Acc: 0.752577\n",
      "Epoch 9726 - Train Loss: 0.131841, Train Acc: 0.775641 | Val Loss: 0.147711, Val Acc: 0.752577\n",
      "Epoch 9727 - Train Loss: 0.131832, Train Acc: 0.775641 | Val Loss: 0.147703, Val Acc: 0.752577\n",
      "Epoch 9728 - Train Loss: 0.131823, Train Acc: 0.775641 | Val Loss: 0.147695, Val Acc: 0.752577\n",
      "Epoch 9729 - Train Loss: 0.131814, Train Acc: 0.775641 | Val Loss: 0.147688, Val Acc: 0.752577\n",
      "Epoch 9730 - Train Loss: 0.131806, Train Acc: 0.775641 | Val Loss: 0.147680, Val Acc: 0.752577\n",
      "Epoch 9731 - Train Loss: 0.131797, Train Acc: 0.775641 | Val Loss: 0.147673, Val Acc: 0.752577\n",
      "Epoch 9732 - Train Loss: 0.131788, Train Acc: 0.775641 | Val Loss: 0.147665, Val Acc: 0.752577\n",
      "Epoch 9733 - Train Loss: 0.131779, Train Acc: 0.775641 | Val Loss: 0.147657, Val Acc: 0.752577\n",
      "Epoch 9734 - Train Loss: 0.131771, Train Acc: 0.775641 | Val Loss: 0.147650, Val Acc: 0.752577\n",
      "Epoch 9735 - Train Loss: 0.131762, Train Acc: 0.775641 | Val Loss: 0.147642, Val Acc: 0.752577\n",
      "Epoch 9736 - Train Loss: 0.131753, Train Acc: 0.775641 | Val Loss: 0.147635, Val Acc: 0.752577\n",
      "Epoch 9737 - Train Loss: 0.131744, Train Acc: 0.775641 | Val Loss: 0.147627, Val Acc: 0.752577\n",
      "Epoch 9738 - Train Loss: 0.131736, Train Acc: 0.775641 | Val Loss: 0.147619, Val Acc: 0.752577\n",
      "Epoch 9739 - Train Loss: 0.131727, Train Acc: 0.775641 | Val Loss: 0.147612, Val Acc: 0.752577\n",
      "Epoch 9740 - Train Loss: 0.131718, Train Acc: 0.775641 | Val Loss: 0.147604, Val Acc: 0.752577\n",
      "Epoch 9741 - Train Loss: 0.131709, Train Acc: 0.775641 | Val Loss: 0.147597, Val Acc: 0.752577\n",
      "Epoch 9742 - Train Loss: 0.131701, Train Acc: 0.775641 | Val Loss: 0.147589, Val Acc: 0.752577\n",
      "Epoch 9743 - Train Loss: 0.131692, Train Acc: 0.775641 | Val Loss: 0.147581, Val Acc: 0.752577\n",
      "Epoch 9744 - Train Loss: 0.131683, Train Acc: 0.775641 | Val Loss: 0.147574, Val Acc: 0.752577\n",
      "Epoch 9745 - Train Loss: 0.131674, Train Acc: 0.775641 | Val Loss: 0.147566, Val Acc: 0.752577\n",
      "Epoch 9746 - Train Loss: 0.131666, Train Acc: 0.775641 | Val Loss: 0.147559, Val Acc: 0.752577\n",
      "Epoch 9747 - Train Loss: 0.131657, Train Acc: 0.775641 | Val Loss: 0.147551, Val Acc: 0.752577\n",
      "Epoch 9748 - Train Loss: 0.131648, Train Acc: 0.776923 | Val Loss: 0.147543, Val Acc: 0.752577\n",
      "Epoch 9749 - Train Loss: 0.131639, Train Acc: 0.776923 | Val Loss: 0.147536, Val Acc: 0.752577\n",
      "Epoch 9750 - Train Loss: 0.131631, Train Acc: 0.776923 | Val Loss: 0.147528, Val Acc: 0.752577\n",
      "Epoch 9751 - Train Loss: 0.131622, Train Acc: 0.776923 | Val Loss: 0.147521, Val Acc: 0.752577\n",
      "Epoch 9752 - Train Loss: 0.131613, Train Acc: 0.776923 | Val Loss: 0.147513, Val Acc: 0.752577\n",
      "Epoch 9753 - Train Loss: 0.131604, Train Acc: 0.776923 | Val Loss: 0.147506, Val Acc: 0.752577\n",
      "Epoch 9754 - Train Loss: 0.131596, Train Acc: 0.776923 | Val Loss: 0.147498, Val Acc: 0.752577\n",
      "Epoch 9755 - Train Loss: 0.131587, Train Acc: 0.776923 | Val Loss: 0.147490, Val Acc: 0.752577\n",
      "Epoch 9756 - Train Loss: 0.131578, Train Acc: 0.776923 | Val Loss: 0.147483, Val Acc: 0.752577\n",
      "Epoch 9757 - Train Loss: 0.131570, Train Acc: 0.776923 | Val Loss: 0.147475, Val Acc: 0.752577\n",
      "Epoch 9758 - Train Loss: 0.131561, Train Acc: 0.776923 | Val Loss: 0.147468, Val Acc: 0.752577\n",
      "Epoch 9759 - Train Loss: 0.131552, Train Acc: 0.776923 | Val Loss: 0.147460, Val Acc: 0.752577\n",
      "Epoch 9760 - Train Loss: 0.131543, Train Acc: 0.776923 | Val Loss: 0.147453, Val Acc: 0.752577\n",
      "Epoch 9761 - Train Loss: 0.131535, Train Acc: 0.776923 | Val Loss: 0.147445, Val Acc: 0.752577\n",
      "Epoch 9762 - Train Loss: 0.131526, Train Acc: 0.776923 | Val Loss: 0.147437, Val Acc: 0.752577\n",
      "Epoch 9763 - Train Loss: 0.131517, Train Acc: 0.776923 | Val Loss: 0.147430, Val Acc: 0.752577\n",
      "Epoch 9764 - Train Loss: 0.131509, Train Acc: 0.776923 | Val Loss: 0.147422, Val Acc: 0.752577\n",
      "Epoch 9765 - Train Loss: 0.131500, Train Acc: 0.776923 | Val Loss: 0.147415, Val Acc: 0.752577\n",
      "Epoch 9766 - Train Loss: 0.131491, Train Acc: 0.776923 | Val Loss: 0.147407, Val Acc: 0.752577\n",
      "Epoch 9767 - Train Loss: 0.131482, Train Acc: 0.776923 | Val Loss: 0.147399, Val Acc: 0.752577\n",
      "Epoch 9768 - Train Loss: 0.131474, Train Acc: 0.776923 | Val Loss: 0.147392, Val Acc: 0.752577\n",
      "Epoch 9769 - Train Loss: 0.131465, Train Acc: 0.776923 | Val Loss: 0.147384, Val Acc: 0.752577\n",
      "Epoch 9770 - Train Loss: 0.131456, Train Acc: 0.776923 | Val Loss: 0.147377, Val Acc: 0.752577\n",
      "Epoch 9771 - Train Loss: 0.131448, Train Acc: 0.778205 | Val Loss: 0.147369, Val Acc: 0.752577\n",
      "Epoch 9772 - Train Loss: 0.131439, Train Acc: 0.778205 | Val Loss: 0.147362, Val Acc: 0.752577\n",
      "Epoch 9773 - Train Loss: 0.131430, Train Acc: 0.778205 | Val Loss: 0.147354, Val Acc: 0.752577\n",
      "Epoch 9774 - Train Loss: 0.131421, Train Acc: 0.778205 | Val Loss: 0.147347, Val Acc: 0.752577\n",
      "Epoch 9775 - Train Loss: 0.131413, Train Acc: 0.778205 | Val Loss: 0.147339, Val Acc: 0.752577\n",
      "Epoch 9776 - Train Loss: 0.131404, Train Acc: 0.778205 | Val Loss: 0.147332, Val Acc: 0.752577\n",
      "Epoch 9777 - Train Loss: 0.131395, Train Acc: 0.778205 | Val Loss: 0.147324, Val Acc: 0.752577\n",
      "Epoch 9778 - Train Loss: 0.131387, Train Acc: 0.778205 | Val Loss: 0.147317, Val Acc: 0.752577\n",
      "Epoch 9779 - Train Loss: 0.131378, Train Acc: 0.778205 | Val Loss: 0.147309, Val Acc: 0.752577\n",
      "Epoch 9780 - Train Loss: 0.131369, Train Acc: 0.778205 | Val Loss: 0.147301, Val Acc: 0.752577\n",
      "Epoch 9781 - Train Loss: 0.131361, Train Acc: 0.778205 | Val Loss: 0.147294, Val Acc: 0.752577\n",
      "Epoch 9782 - Train Loss: 0.131352, Train Acc: 0.778205 | Val Loss: 0.147286, Val Acc: 0.752577\n",
      "Epoch 9783 - Train Loss: 0.131343, Train Acc: 0.778205 | Val Loss: 0.147279, Val Acc: 0.752577\n",
      "Epoch 9784 - Train Loss: 0.131335, Train Acc: 0.778205 | Val Loss: 0.147271, Val Acc: 0.752577\n",
      "Epoch 9785 - Train Loss: 0.131326, Train Acc: 0.778205 | Val Loss: 0.147263, Val Acc: 0.752577\n",
      "Epoch 9786 - Train Loss: 0.131317, Train Acc: 0.778205 | Val Loss: 0.147256, Val Acc: 0.752577\n",
      "Epoch 9787 - Train Loss: 0.131309, Train Acc: 0.778205 | Val Loss: 0.147248, Val Acc: 0.752577\n",
      "Epoch 9788 - Train Loss: 0.131300, Train Acc: 0.778205 | Val Loss: 0.147241, Val Acc: 0.752577\n",
      "Epoch 9789 - Train Loss: 0.131291, Train Acc: 0.778205 | Val Loss: 0.147233, Val Acc: 0.752577\n",
      "Epoch 9790 - Train Loss: 0.131283, Train Acc: 0.779487 | Val Loss: 0.147226, Val Acc: 0.752577\n",
      "Epoch 9791 - Train Loss: 0.131274, Train Acc: 0.779487 | Val Loss: 0.147218, Val Acc: 0.752577\n",
      "Epoch 9792 - Train Loss: 0.131265, Train Acc: 0.779487 | Val Loss: 0.147210, Val Acc: 0.752577\n",
      "Epoch 9793 - Train Loss: 0.131257, Train Acc: 0.779487 | Val Loss: 0.147203, Val Acc: 0.752577\n",
      "Epoch 9794 - Train Loss: 0.131248, Train Acc: 0.779487 | Val Loss: 0.147195, Val Acc: 0.752577\n",
      "Epoch 9795 - Train Loss: 0.131239, Train Acc: 0.779487 | Val Loss: 0.147188, Val Acc: 0.752577\n",
      "Epoch 9796 - Train Loss: 0.131231, Train Acc: 0.779487 | Val Loss: 0.147180, Val Acc: 0.752577\n",
      "Epoch 9797 - Train Loss: 0.131222, Train Acc: 0.779487 | Val Loss: 0.147172, Val Acc: 0.752577\n",
      "Epoch 9798 - Train Loss: 0.131213, Train Acc: 0.779487 | Val Loss: 0.147165, Val Acc: 0.752577\n",
      "Epoch 9799 - Train Loss: 0.131205, Train Acc: 0.779487 | Val Loss: 0.147157, Val Acc: 0.752577\n",
      "Epoch 9800 - Train Loss: 0.131196, Train Acc: 0.779487 | Val Loss: 0.147149, Val Acc: 0.752577\n",
      "Epoch 9801 - Train Loss: 0.131187, Train Acc: 0.779487 | Val Loss: 0.147142, Val Acc: 0.752577\n",
      "Epoch 9802 - Train Loss: 0.131179, Train Acc: 0.779487 | Val Loss: 0.147134, Val Acc: 0.752577\n",
      "Epoch 9803 - Train Loss: 0.131170, Train Acc: 0.779487 | Val Loss: 0.147127, Val Acc: 0.752577\n",
      "Epoch 9804 - Train Loss: 0.131161, Train Acc: 0.779487 | Val Loss: 0.147119, Val Acc: 0.752577\n",
      "Epoch 9805 - Train Loss: 0.131153, Train Acc: 0.779487 | Val Loss: 0.147111, Val Acc: 0.752577\n",
      "Epoch 9806 - Train Loss: 0.131144, Train Acc: 0.779487 | Val Loss: 0.147104, Val Acc: 0.752577\n",
      "Epoch 9807 - Train Loss: 0.131135, Train Acc: 0.779487 | Val Loss: 0.147096, Val Acc: 0.752577\n",
      "Epoch 9808 - Train Loss: 0.131127, Train Acc: 0.779487 | Val Loss: 0.147088, Val Acc: 0.752577\n",
      "Epoch 9809 - Train Loss: 0.131118, Train Acc: 0.779487 | Val Loss: 0.147081, Val Acc: 0.752577\n",
      "Epoch 9810 - Train Loss: 0.131109, Train Acc: 0.779487 | Val Loss: 0.147073, Val Acc: 0.752577\n",
      "Epoch 9811 - Train Loss: 0.131101, Train Acc: 0.779487 | Val Loss: 0.147066, Val Acc: 0.752577\n",
      "Epoch 9812 - Train Loss: 0.131092, Train Acc: 0.779487 | Val Loss: 0.147058, Val Acc: 0.752577\n",
      "Epoch 9813 - Train Loss: 0.131083, Train Acc: 0.779487 | Val Loss: 0.147050, Val Acc: 0.752577\n",
      "Epoch 9814 - Train Loss: 0.131075, Train Acc: 0.779487 | Val Loss: 0.147043, Val Acc: 0.752577\n",
      "Epoch 9815 - Train Loss: 0.131066, Train Acc: 0.779487 | Val Loss: 0.147035, Val Acc: 0.752577\n",
      "Epoch 9816 - Train Loss: 0.131058, Train Acc: 0.779487 | Val Loss: 0.147028, Val Acc: 0.752577\n",
      "Epoch 9817 - Train Loss: 0.131049, Train Acc: 0.779487 | Val Loss: 0.147020, Val Acc: 0.752577\n",
      "Epoch 9818 - Train Loss: 0.131040, Train Acc: 0.779487 | Val Loss: 0.147013, Val Acc: 0.752577\n",
      "Epoch 9819 - Train Loss: 0.131032, Train Acc: 0.779487 | Val Loss: 0.147005, Val Acc: 0.752577\n",
      "Epoch 9820 - Train Loss: 0.131023, Train Acc: 0.779487 | Val Loss: 0.146997, Val Acc: 0.752577\n",
      "Epoch 9821 - Train Loss: 0.131014, Train Acc: 0.779487 | Val Loss: 0.146990, Val Acc: 0.752577\n",
      "Epoch 9822 - Train Loss: 0.131006, Train Acc: 0.779487 | Val Loss: 0.146982, Val Acc: 0.752577\n",
      "Epoch 9823 - Train Loss: 0.130997, Train Acc: 0.779487 | Val Loss: 0.146975, Val Acc: 0.752577\n",
      "Epoch 9824 - Train Loss: 0.130988, Train Acc: 0.779487 | Val Loss: 0.146967, Val Acc: 0.752577\n",
      "Epoch 9825 - Train Loss: 0.130980, Train Acc: 0.779487 | Val Loss: 0.146960, Val Acc: 0.752577\n",
      "Epoch 9826 - Train Loss: 0.130971, Train Acc: 0.779487 | Val Loss: 0.146952, Val Acc: 0.752577\n",
      "Epoch 9827 - Train Loss: 0.130963, Train Acc: 0.779487 | Val Loss: 0.146944, Val Acc: 0.752577\n",
      "Epoch 9828 - Train Loss: 0.130954, Train Acc: 0.779487 | Val Loss: 0.146937, Val Acc: 0.752577\n",
      "Epoch 9829 - Train Loss: 0.130945, Train Acc: 0.779487 | Val Loss: 0.146929, Val Acc: 0.752577\n",
      "Epoch 9830 - Train Loss: 0.130937, Train Acc: 0.779487 | Val Loss: 0.146922, Val Acc: 0.752577\n",
      "Epoch 9831 - Train Loss: 0.130928, Train Acc: 0.779487 | Val Loss: 0.146914, Val Acc: 0.752577\n",
      "Epoch 9832 - Train Loss: 0.130920, Train Acc: 0.779487 | Val Loss: 0.146907, Val Acc: 0.752577\n",
      "Epoch 9833 - Train Loss: 0.130911, Train Acc: 0.779487 | Val Loss: 0.146899, Val Acc: 0.752577\n",
      "Epoch 9834 - Train Loss: 0.130902, Train Acc: 0.779487 | Val Loss: 0.146892, Val Acc: 0.752577\n",
      "Epoch 9835 - Train Loss: 0.130894, Train Acc: 0.779487 | Val Loss: 0.146884, Val Acc: 0.752577\n",
      "Epoch 9836 - Train Loss: 0.130885, Train Acc: 0.779487 | Val Loss: 0.146877, Val Acc: 0.752577\n",
      "Epoch 9837 - Train Loss: 0.130876, Train Acc: 0.779487 | Val Loss: 0.146869, Val Acc: 0.752577\n",
      "Epoch 9838 - Train Loss: 0.130868, Train Acc: 0.779487 | Val Loss: 0.146861, Val Acc: 0.752577\n",
      "Epoch 9839 - Train Loss: 0.130859, Train Acc: 0.779487 | Val Loss: 0.146854, Val Acc: 0.752577\n",
      "Epoch 9840 - Train Loss: 0.130851, Train Acc: 0.779487 | Val Loss: 0.146846, Val Acc: 0.752577\n",
      "Epoch 9841 - Train Loss: 0.130842, Train Acc: 0.779487 | Val Loss: 0.146839, Val Acc: 0.752577\n",
      "Epoch 9842 - Train Loss: 0.130833, Train Acc: 0.779487 | Val Loss: 0.146831, Val Acc: 0.752577\n",
      "Epoch 9843 - Train Loss: 0.130825, Train Acc: 0.779487 | Val Loss: 0.146824, Val Acc: 0.752577\n",
      "Epoch 9844 - Train Loss: 0.130816, Train Acc: 0.779487 | Val Loss: 0.146816, Val Acc: 0.752577\n",
      "Epoch 9845 - Train Loss: 0.130808, Train Acc: 0.779487 | Val Loss: 0.146809, Val Acc: 0.752577\n",
      "Epoch 9846 - Train Loss: 0.130799, Train Acc: 0.780769 | Val Loss: 0.146801, Val Acc: 0.752577\n",
      "Epoch 9847 - Train Loss: 0.130790, Train Acc: 0.780769 | Val Loss: 0.146794, Val Acc: 0.752577\n",
      "Epoch 9848 - Train Loss: 0.130782, Train Acc: 0.780769 | Val Loss: 0.146786, Val Acc: 0.752577\n",
      "Epoch 9849 - Train Loss: 0.130773, Train Acc: 0.780769 | Val Loss: 0.146779, Val Acc: 0.752577\n",
      "Epoch 9850 - Train Loss: 0.130765, Train Acc: 0.780769 | Val Loss: 0.146771, Val Acc: 0.752577\n",
      "Epoch 9851 - Train Loss: 0.130756, Train Acc: 0.780769 | Val Loss: 0.146764, Val Acc: 0.752577\n",
      "Epoch 9852 - Train Loss: 0.130748, Train Acc: 0.780769 | Val Loss: 0.146756, Val Acc: 0.752577\n",
      "Epoch 9853 - Train Loss: 0.130739, Train Acc: 0.780769 | Val Loss: 0.146749, Val Acc: 0.752577\n",
      "Epoch 9854 - Train Loss: 0.130730, Train Acc: 0.780769 | Val Loss: 0.146741, Val Acc: 0.752577\n",
      "Epoch 9855 - Train Loss: 0.130722, Train Acc: 0.780769 | Val Loss: 0.146734, Val Acc: 0.752577\n",
      "Epoch 9856 - Train Loss: 0.130713, Train Acc: 0.780769 | Val Loss: 0.146726, Val Acc: 0.752577\n",
      "Epoch 9857 - Train Loss: 0.130705, Train Acc: 0.780769 | Val Loss: 0.146719, Val Acc: 0.752577\n",
      "Epoch 9858 - Train Loss: 0.130696, Train Acc: 0.780769 | Val Loss: 0.146711, Val Acc: 0.752577\n",
      "Epoch 9859 - Train Loss: 0.130687, Train Acc: 0.780769 | Val Loss: 0.146704, Val Acc: 0.752577\n",
      "Epoch 9860 - Train Loss: 0.130679, Train Acc: 0.780769 | Val Loss: 0.146696, Val Acc: 0.752577\n",
      "Epoch 9861 - Train Loss: 0.130670, Train Acc: 0.780769 | Val Loss: 0.146689, Val Acc: 0.752577\n",
      "Epoch 9862 - Train Loss: 0.130662, Train Acc: 0.780769 | Val Loss: 0.146681, Val Acc: 0.752577\n",
      "Epoch 9863 - Train Loss: 0.130653, Train Acc: 0.780769 | Val Loss: 0.146674, Val Acc: 0.752577\n",
      "Epoch 9864 - Train Loss: 0.130645, Train Acc: 0.780769 | Val Loss: 0.146666, Val Acc: 0.752577\n",
      "Epoch 9865 - Train Loss: 0.130636, Train Acc: 0.780769 | Val Loss: 0.146659, Val Acc: 0.752577\n",
      "Epoch 9866 - Train Loss: 0.130627, Train Acc: 0.780769 | Val Loss: 0.146651, Val Acc: 0.752577\n",
      "Epoch 9867 - Train Loss: 0.130619, Train Acc: 0.780769 | Val Loss: 0.146644, Val Acc: 0.752577\n",
      "Epoch 9868 - Train Loss: 0.130610, Train Acc: 0.780769 | Val Loss: 0.146636, Val Acc: 0.752577\n",
      "Epoch 9869 - Train Loss: 0.130602, Train Acc: 0.780769 | Val Loss: 0.146629, Val Acc: 0.752577\n",
      "Epoch 9870 - Train Loss: 0.130593, Train Acc: 0.780769 | Val Loss: 0.146621, Val Acc: 0.752577\n",
      "Epoch 9871 - Train Loss: 0.130585, Train Acc: 0.780769 | Val Loss: 0.146614, Val Acc: 0.752577\n",
      "Epoch 9872 - Train Loss: 0.130576, Train Acc: 0.780769 | Val Loss: 0.146607, Val Acc: 0.752577\n",
      "Epoch 9873 - Train Loss: 0.130568, Train Acc: 0.780769 | Val Loss: 0.146600, Val Acc: 0.752577\n",
      "Epoch 9874 - Train Loss: 0.130559, Train Acc: 0.780769 | Val Loss: 0.146593, Val Acc: 0.752577\n",
      "Epoch 9875 - Train Loss: 0.130550, Train Acc: 0.780769 | Val Loss: 0.146585, Val Acc: 0.752577\n",
      "Epoch 9876 - Train Loss: 0.130542, Train Acc: 0.780769 | Val Loss: 0.146578, Val Acc: 0.752577\n",
      "Epoch 9877 - Train Loss: 0.130533, Train Acc: 0.780769 | Val Loss: 0.146571, Val Acc: 0.752577\n",
      "Epoch 9878 - Train Loss: 0.130525, Train Acc: 0.780769 | Val Loss: 0.146564, Val Acc: 0.752577\n",
      "Epoch 9879 - Train Loss: 0.130516, Train Acc: 0.780769 | Val Loss: 0.146556, Val Acc: 0.752577\n",
      "Epoch 9880 - Train Loss: 0.130508, Train Acc: 0.780769 | Val Loss: 0.146549, Val Acc: 0.752577\n",
      "Epoch 9881 - Train Loss: 0.130499, Train Acc: 0.780769 | Val Loss: 0.146542, Val Acc: 0.752577\n",
      "Epoch 9882 - Train Loss: 0.130491, Train Acc: 0.780769 | Val Loss: 0.146535, Val Acc: 0.752577\n",
      "Epoch 9883 - Train Loss: 0.130482, Train Acc: 0.780769 | Val Loss: 0.146527, Val Acc: 0.752577\n",
      "Epoch 9884 - Train Loss: 0.130474, Train Acc: 0.780769 | Val Loss: 0.146520, Val Acc: 0.752577\n",
      "Epoch 9885 - Train Loss: 0.130465, Train Acc: 0.780769 | Val Loss: 0.146513, Val Acc: 0.752577\n",
      "Epoch 9886 - Train Loss: 0.130456, Train Acc: 0.780769 | Val Loss: 0.146505, Val Acc: 0.752577\n",
      "Epoch 9887 - Train Loss: 0.130448, Train Acc: 0.780769 | Val Loss: 0.146498, Val Acc: 0.752577\n",
      "Epoch 9888 - Train Loss: 0.130439, Train Acc: 0.780769 | Val Loss: 0.146491, Val Acc: 0.752577\n",
      "Epoch 9889 - Train Loss: 0.130431, Train Acc: 0.780769 | Val Loss: 0.146484, Val Acc: 0.752577\n",
      "Epoch 9890 - Train Loss: 0.130422, Train Acc: 0.780769 | Val Loss: 0.146476, Val Acc: 0.752577\n",
      "Epoch 9891 - Train Loss: 0.130414, Train Acc: 0.780769 | Val Loss: 0.146469, Val Acc: 0.752577\n",
      "Epoch 9892 - Train Loss: 0.130405, Train Acc: 0.780769 | Val Loss: 0.146462, Val Acc: 0.752577\n",
      "Epoch 9893 - Train Loss: 0.130397, Train Acc: 0.780769 | Val Loss: 0.146454, Val Acc: 0.752577\n",
      "Epoch 9894 - Train Loss: 0.130388, Train Acc: 0.780769 | Val Loss: 0.146447, Val Acc: 0.752577\n",
      "Epoch 9895 - Train Loss: 0.130380, Train Acc: 0.780769 | Val Loss: 0.146440, Val Acc: 0.752577\n",
      "Epoch 9896 - Train Loss: 0.130371, Train Acc: 0.780769 | Val Loss: 0.146433, Val Acc: 0.752577\n",
      "Epoch 9897 - Train Loss: 0.130363, Train Acc: 0.780769 | Val Loss: 0.146425, Val Acc: 0.752577\n",
      "Epoch 9898 - Train Loss: 0.130354, Train Acc: 0.780769 | Val Loss: 0.146418, Val Acc: 0.752577\n",
      "Epoch 9899 - Train Loss: 0.130346, Train Acc: 0.780769 | Val Loss: 0.146411, Val Acc: 0.752577\n",
      "Epoch 9900 - Train Loss: 0.130337, Train Acc: 0.780769 | Val Loss: 0.146403, Val Acc: 0.752577\n",
      "Epoch 9901 - Train Loss: 0.130329, Train Acc: 0.780769 | Val Loss: 0.146396, Val Acc: 0.752577\n",
      "Epoch 9902 - Train Loss: 0.130320, Train Acc: 0.780769 | Val Loss: 0.146389, Val Acc: 0.752577\n",
      "Epoch 9903 - Train Loss: 0.130312, Train Acc: 0.780769 | Val Loss: 0.146381, Val Acc: 0.752577\n",
      "Epoch 9904 - Train Loss: 0.130303, Train Acc: 0.780769 | Val Loss: 0.146374, Val Acc: 0.752577\n",
      "Epoch 9905 - Train Loss: 0.130295, Train Acc: 0.780769 | Val Loss: 0.146367, Val Acc: 0.752577\n",
      "Epoch 9906 - Train Loss: 0.130286, Train Acc: 0.780769 | Val Loss: 0.146359, Val Acc: 0.752577\n",
      "Epoch 9907 - Train Loss: 0.130278, Train Acc: 0.780769 | Val Loss: 0.146352, Val Acc: 0.752577\n",
      "Epoch 9908 - Train Loss: 0.130269, Train Acc: 0.780769 | Val Loss: 0.146345, Val Acc: 0.752577\n",
      "Epoch 9909 - Train Loss: 0.130261, Train Acc: 0.780769 | Val Loss: 0.146338, Val Acc: 0.752577\n",
      "Epoch 9910 - Train Loss: 0.130252, Train Acc: 0.780769 | Val Loss: 0.146330, Val Acc: 0.752577\n",
      "Epoch 9911 - Train Loss: 0.130244, Train Acc: 0.780769 | Val Loss: 0.146323, Val Acc: 0.752577\n",
      "Epoch 9912 - Train Loss: 0.130235, Train Acc: 0.780769 | Val Loss: 0.146316, Val Acc: 0.752577\n",
      "Epoch 9913 - Train Loss: 0.130227, Train Acc: 0.780769 | Val Loss: 0.146308, Val Acc: 0.752577\n",
      "Epoch 9914 - Train Loss: 0.130218, Train Acc: 0.780769 | Val Loss: 0.146301, Val Acc: 0.752577\n",
      "Epoch 9915 - Train Loss: 0.130210, Train Acc: 0.780769 | Val Loss: 0.146294, Val Acc: 0.752577\n",
      "Epoch 9916 - Train Loss: 0.130201, Train Acc: 0.780769 | Val Loss: 0.146286, Val Acc: 0.752577\n",
      "Epoch 9917 - Train Loss: 0.130193, Train Acc: 0.780769 | Val Loss: 0.146279, Val Acc: 0.752577\n",
      "Epoch 9918 - Train Loss: 0.130184, Train Acc: 0.780769 | Val Loss: 0.146272, Val Acc: 0.752577\n",
      "Epoch 9919 - Train Loss: 0.130176, Train Acc: 0.780769 | Val Loss: 0.146264, Val Acc: 0.752577\n",
      "Epoch 9920 - Train Loss: 0.130167, Train Acc: 0.780769 | Val Loss: 0.146257, Val Acc: 0.752577\n",
      "Epoch 9921 - Train Loss: 0.130159, Train Acc: 0.780769 | Val Loss: 0.146250, Val Acc: 0.752577\n",
      "Epoch 9922 - Train Loss: 0.130150, Train Acc: 0.780769 | Val Loss: 0.146242, Val Acc: 0.752577\n",
      "Epoch 9923 - Train Loss: 0.130142, Train Acc: 0.780769 | Val Loss: 0.146235, Val Acc: 0.752577\n",
      "Epoch 9924 - Train Loss: 0.130133, Train Acc: 0.780769 | Val Loss: 0.146228, Val Acc: 0.752577\n",
      "Epoch 9925 - Train Loss: 0.130125, Train Acc: 0.780769 | Val Loss: 0.146221, Val Acc: 0.752577\n",
      "Epoch 9926 - Train Loss: 0.130116, Train Acc: 0.780769 | Val Loss: 0.146213, Val Acc: 0.752577\n",
      "Epoch 9927 - Train Loss: 0.130108, Train Acc: 0.780769 | Val Loss: 0.146206, Val Acc: 0.752577\n",
      "Epoch 9928 - Train Loss: 0.130099, Train Acc: 0.780769 | Val Loss: 0.146199, Val Acc: 0.752577\n",
      "Epoch 9929 - Train Loss: 0.130091, Train Acc: 0.780769 | Val Loss: 0.146191, Val Acc: 0.752577\n",
      "Epoch 9930 - Train Loss: 0.130082, Train Acc: 0.780769 | Val Loss: 0.146184, Val Acc: 0.752577\n",
      "Epoch 9931 - Train Loss: 0.130074, Train Acc: 0.780769 | Val Loss: 0.146177, Val Acc: 0.752577\n",
      "Epoch 9932 - Train Loss: 0.130065, Train Acc: 0.782051 | Val Loss: 0.146169, Val Acc: 0.752577\n",
      "Epoch 9933 - Train Loss: 0.130057, Train Acc: 0.782051 | Val Loss: 0.146162, Val Acc: 0.752577\n",
      "Epoch 9934 - Train Loss: 0.130049, Train Acc: 0.782051 | Val Loss: 0.146155, Val Acc: 0.752577\n",
      "Epoch 9935 - Train Loss: 0.130040, Train Acc: 0.782051 | Val Loss: 0.146147, Val Acc: 0.752577\n",
      "Epoch 9936 - Train Loss: 0.130032, Train Acc: 0.782051 | Val Loss: 0.146140, Val Acc: 0.752577\n",
      "Epoch 9937 - Train Loss: 0.130023, Train Acc: 0.782051 | Val Loss: 0.146133, Val Acc: 0.752577\n",
      "Epoch 9938 - Train Loss: 0.130015, Train Acc: 0.782051 | Val Loss: 0.146126, Val Acc: 0.752577\n",
      "Epoch 9939 - Train Loss: 0.130006, Train Acc: 0.782051 | Val Loss: 0.146118, Val Acc: 0.752577\n",
      "Epoch 9940 - Train Loss: 0.129998, Train Acc: 0.782051 | Val Loss: 0.146111, Val Acc: 0.752577\n",
      "Epoch 9941 - Train Loss: 0.129989, Train Acc: 0.782051 | Val Loss: 0.146104, Val Acc: 0.752577\n",
      "Epoch 9942 - Train Loss: 0.129981, Train Acc: 0.782051 | Val Loss: 0.146096, Val Acc: 0.752577\n",
      "Epoch 9943 - Train Loss: 0.129972, Train Acc: 0.782051 | Val Loss: 0.146089, Val Acc: 0.752577\n",
      "Epoch 9944 - Train Loss: 0.129964, Train Acc: 0.782051 | Val Loss: 0.146082, Val Acc: 0.752577\n",
      "Epoch 9945 - Train Loss: 0.129955, Train Acc: 0.782051 | Val Loss: 0.146074, Val Acc: 0.752577\n",
      "Epoch 9946 - Train Loss: 0.129947, Train Acc: 0.782051 | Val Loss: 0.146067, Val Acc: 0.752577\n",
      "Epoch 9947 - Train Loss: 0.129939, Train Acc: 0.782051 | Val Loss: 0.146060, Val Acc: 0.752577\n",
      "Epoch 9948 - Train Loss: 0.129930, Train Acc: 0.782051 | Val Loss: 0.146053, Val Acc: 0.752577\n",
      "Epoch 9949 - Train Loss: 0.129922, Train Acc: 0.782051 | Val Loss: 0.146045, Val Acc: 0.752577\n",
      "Epoch 9950 - Train Loss: 0.129913, Train Acc: 0.782051 | Val Loss: 0.146038, Val Acc: 0.752577\n",
      "Epoch 9951 - Train Loss: 0.129905, Train Acc: 0.782051 | Val Loss: 0.146031, Val Acc: 0.752577\n",
      "Epoch 9952 - Train Loss: 0.129896, Train Acc: 0.782051 | Val Loss: 0.146023, Val Acc: 0.752577\n",
      "Epoch 9953 - Train Loss: 0.129888, Train Acc: 0.782051 | Val Loss: 0.146016, Val Acc: 0.752577\n",
      "Epoch 9954 - Train Loss: 0.129879, Train Acc: 0.782051 | Val Loss: 0.146009, Val Acc: 0.752577\n",
      "Epoch 9955 - Train Loss: 0.129871, Train Acc: 0.782051 | Val Loss: 0.146002, Val Acc: 0.752577\n",
      "Epoch 9956 - Train Loss: 0.129863, Train Acc: 0.782051 | Val Loss: 0.145994, Val Acc: 0.752577\n",
      "Epoch 9957 - Train Loss: 0.129854, Train Acc: 0.782051 | Val Loss: 0.145987, Val Acc: 0.752577\n",
      "Epoch 9958 - Train Loss: 0.129846, Train Acc: 0.782051 | Val Loss: 0.145980, Val Acc: 0.752577\n",
      "Epoch 9959 - Train Loss: 0.129837, Train Acc: 0.782051 | Val Loss: 0.145972, Val Acc: 0.752577\n",
      "Epoch 9960 - Train Loss: 0.129829, Train Acc: 0.782051 | Val Loss: 0.145965, Val Acc: 0.752577\n",
      "Epoch 9961 - Train Loss: 0.129820, Train Acc: 0.782051 | Val Loss: 0.145958, Val Acc: 0.752577\n",
      "Epoch 9962 - Train Loss: 0.129812, Train Acc: 0.782051 | Val Loss: 0.145951, Val Acc: 0.752577\n",
      "Epoch 9963 - Train Loss: 0.129804, Train Acc: 0.782051 | Val Loss: 0.145943, Val Acc: 0.752577\n",
      "Epoch 9964 - Train Loss: 0.129795, Train Acc: 0.782051 | Val Loss: 0.145936, Val Acc: 0.752577\n",
      "Epoch 9965 - Train Loss: 0.129787, Train Acc: 0.782051 | Val Loss: 0.145929, Val Acc: 0.752577\n",
      "Epoch 9966 - Train Loss: 0.129778, Train Acc: 0.782051 | Val Loss: 0.145921, Val Acc: 0.752577\n",
      "Epoch 9967 - Train Loss: 0.129770, Train Acc: 0.782051 | Val Loss: 0.145914, Val Acc: 0.752577\n",
      "Epoch 9968 - Train Loss: 0.129761, Train Acc: 0.782051 | Val Loss: 0.145907, Val Acc: 0.752577\n",
      "Epoch 9969 - Train Loss: 0.129753, Train Acc: 0.782051 | Val Loss: 0.145900, Val Acc: 0.752577\n",
      "Epoch 9970 - Train Loss: 0.129745, Train Acc: 0.782051 | Val Loss: 0.145892, Val Acc: 0.752577\n",
      "Epoch 9971 - Train Loss: 0.129736, Train Acc: 0.782051 | Val Loss: 0.145885, Val Acc: 0.752577\n",
      "Epoch 9972 - Train Loss: 0.129728, Train Acc: 0.782051 | Val Loss: 0.145878, Val Acc: 0.752577\n",
      "Epoch 9973 - Train Loss: 0.129719, Train Acc: 0.782051 | Val Loss: 0.145871, Val Acc: 0.752577\n",
      "Epoch 9974 - Train Loss: 0.129711, Train Acc: 0.782051 | Val Loss: 0.145863, Val Acc: 0.752577\n",
      "Epoch 9975 - Train Loss: 0.129703, Train Acc: 0.782051 | Val Loss: 0.145856, Val Acc: 0.752577\n",
      "Epoch 9976 - Train Loss: 0.129694, Train Acc: 0.782051 | Val Loss: 0.145849, Val Acc: 0.752577\n",
      "Epoch 9977 - Train Loss: 0.129686, Train Acc: 0.782051 | Val Loss: 0.145842, Val Acc: 0.752577\n",
      "Epoch 9978 - Train Loss: 0.129677, Train Acc: 0.782051 | Val Loss: 0.145834, Val Acc: 0.752577\n",
      "Epoch 9979 - Train Loss: 0.129669, Train Acc: 0.782051 | Val Loss: 0.145827, Val Acc: 0.752577\n",
      "Epoch 9980 - Train Loss: 0.129661, Train Acc: 0.782051 | Val Loss: 0.145820, Val Acc: 0.752577\n",
      "Epoch 9981 - Train Loss: 0.129652, Train Acc: 0.782051 | Val Loss: 0.145812, Val Acc: 0.752577\n",
      "Epoch 9982 - Train Loss: 0.129644, Train Acc: 0.782051 | Val Loss: 0.145805, Val Acc: 0.752577\n",
      "Epoch 9983 - Train Loss: 0.129635, Train Acc: 0.782051 | Val Loss: 0.145798, Val Acc: 0.752577\n",
      "Epoch 9984 - Train Loss: 0.129627, Train Acc: 0.782051 | Val Loss: 0.145791, Val Acc: 0.752577\n",
      "Epoch 9985 - Train Loss: 0.129619, Train Acc: 0.782051 | Val Loss: 0.145783, Val Acc: 0.752577\n",
      "Epoch 9986 - Train Loss: 0.129610, Train Acc: 0.782051 | Val Loss: 0.145776, Val Acc: 0.752577\n",
      "Epoch 9987 - Train Loss: 0.129602, Train Acc: 0.782051 | Val Loss: 0.145769, Val Acc: 0.752577\n",
      "Epoch 9988 - Train Loss: 0.129593, Train Acc: 0.782051 | Val Loss: 0.145762, Val Acc: 0.752577\n",
      "Epoch 9989 - Train Loss: 0.129585, Train Acc: 0.782051 | Val Loss: 0.145754, Val Acc: 0.752577\n",
      "Epoch 9990 - Train Loss: 0.129577, Train Acc: 0.782051 | Val Loss: 0.145747, Val Acc: 0.752577\n",
      "Epoch 9991 - Train Loss: 0.129568, Train Acc: 0.782051 | Val Loss: 0.145740, Val Acc: 0.752577\n",
      "Epoch 9992 - Train Loss: 0.129560, Train Acc: 0.782051 | Val Loss: 0.145733, Val Acc: 0.752577\n",
      "Epoch 9993 - Train Loss: 0.129551, Train Acc: 0.782051 | Val Loss: 0.145725, Val Acc: 0.752577\n",
      "Epoch 9994 - Train Loss: 0.129543, Train Acc: 0.782051 | Val Loss: 0.145718, Val Acc: 0.752577\n",
      "Epoch 9995 - Train Loss: 0.129535, Train Acc: 0.782051 | Val Loss: 0.145711, Val Acc: 0.752577\n",
      "Epoch 9996 - Train Loss: 0.129526, Train Acc: 0.782051 | Val Loss: 0.145704, Val Acc: 0.752577\n",
      "Epoch 9997 - Train Loss: 0.129518, Train Acc: 0.782051 | Val Loss: 0.145697, Val Acc: 0.752577\n",
      "Epoch 9998 - Train Loss: 0.129510, Train Acc: 0.782051 | Val Loss: 0.145689, Val Acc: 0.752577\n",
      "Epoch 9999 - Train Loss: 0.129501, Train Acc: 0.782051 | Val Loss: 0.145682, Val Acc: 0.752577\n",
      "Epoch 10000 - Train Loss: 0.129493, Train Acc: 0.782051 | Val Loss: 0.145675, Val Acc: 0.752577\n",
      "Epoch 10001 - Train Loss: 0.129484, Train Acc: 0.782051 | Val Loss: 0.145668, Val Acc: 0.752577\n",
      "Epoch 10002 - Train Loss: 0.129476, Train Acc: 0.782051 | Val Loss: 0.145660, Val Acc: 0.752577\n",
      "Epoch 10003 - Train Loss: 0.129468, Train Acc: 0.782051 | Val Loss: 0.145653, Val Acc: 0.752577\n",
      "Epoch 10004 - Train Loss: 0.129459, Train Acc: 0.782051 | Val Loss: 0.145646, Val Acc: 0.752577\n",
      "Epoch 10005 - Train Loss: 0.129451, Train Acc: 0.782051 | Val Loss: 0.145639, Val Acc: 0.752577\n",
      "Epoch 10006 - Train Loss: 0.129443, Train Acc: 0.782051 | Val Loss: 0.145631, Val Acc: 0.752577\n",
      "Epoch 10007 - Train Loss: 0.129434, Train Acc: 0.782051 | Val Loss: 0.145624, Val Acc: 0.752577\n",
      "Epoch 10008 - Train Loss: 0.129426, Train Acc: 0.782051 | Val Loss: 0.145617, Val Acc: 0.752577\n",
      "Epoch 10009 - Train Loss: 0.129417, Train Acc: 0.782051 | Val Loss: 0.145610, Val Acc: 0.752577\n",
      "Epoch 10010 - Train Loss: 0.129409, Train Acc: 0.782051 | Val Loss: 0.145603, Val Acc: 0.752577\n",
      "Epoch 10011 - Train Loss: 0.129401, Train Acc: 0.782051 | Val Loss: 0.145595, Val Acc: 0.752577\n",
      "Epoch 10012 - Train Loss: 0.129392, Train Acc: 0.782051 | Val Loss: 0.145588, Val Acc: 0.752577\n",
      "Epoch 10013 - Train Loss: 0.129384, Train Acc: 0.782051 | Val Loss: 0.145581, Val Acc: 0.752577\n",
      "Epoch 10014 - Train Loss: 0.129376, Train Acc: 0.782051 | Val Loss: 0.145574, Val Acc: 0.752577\n",
      "Epoch 10015 - Train Loss: 0.129367, Train Acc: 0.782051 | Val Loss: 0.145566, Val Acc: 0.752577\n",
      "Epoch 10016 - Train Loss: 0.129359, Train Acc: 0.782051 | Val Loss: 0.145559, Val Acc: 0.752577\n",
      "Epoch 10017 - Train Loss: 0.129351, Train Acc: 0.782051 | Val Loss: 0.145552, Val Acc: 0.752577\n",
      "Epoch 10018 - Train Loss: 0.129342, Train Acc: 0.782051 | Val Loss: 0.145545, Val Acc: 0.752577\n",
      "Epoch 10019 - Train Loss: 0.129334, Train Acc: 0.782051 | Val Loss: 0.145537, Val Acc: 0.752577\n",
      "Epoch 10020 - Train Loss: 0.129326, Train Acc: 0.782051 | Val Loss: 0.145530, Val Acc: 0.752577\n",
      "Epoch 10021 - Train Loss: 0.129317, Train Acc: 0.782051 | Val Loss: 0.145523, Val Acc: 0.752577\n",
      "Epoch 10022 - Train Loss: 0.129309, Train Acc: 0.782051 | Val Loss: 0.145516, Val Acc: 0.752577\n",
      "Epoch 10023 - Train Loss: 0.129300, Train Acc: 0.782051 | Val Loss: 0.145508, Val Acc: 0.752577\n",
      "Epoch 10024 - Train Loss: 0.129292, Train Acc: 0.782051 | Val Loss: 0.145501, Val Acc: 0.752577\n",
      "Epoch 10025 - Train Loss: 0.129284, Train Acc: 0.782051 | Val Loss: 0.145494, Val Acc: 0.752577\n",
      "Epoch 10026 - Train Loss: 0.129275, Train Acc: 0.782051 | Val Loss: 0.145487, Val Acc: 0.752577\n",
      "Epoch 10027 - Train Loss: 0.129267, Train Acc: 0.782051 | Val Loss: 0.145479, Val Acc: 0.752577\n",
      "Epoch 10028 - Train Loss: 0.129259, Train Acc: 0.782051 | Val Loss: 0.145472, Val Acc: 0.752577\n",
      "Epoch 10029 - Train Loss: 0.129250, Train Acc: 0.782051 | Val Loss: 0.145465, Val Acc: 0.752577\n",
      "Epoch 10030 - Train Loss: 0.129242, Train Acc: 0.782051 | Val Loss: 0.145457, Val Acc: 0.752577\n",
      "Epoch 10031 - Train Loss: 0.129234, Train Acc: 0.782051 | Val Loss: 0.145450, Val Acc: 0.752577\n",
      "Epoch 10032 - Train Loss: 0.129225, Train Acc: 0.782051 | Val Loss: 0.145443, Val Acc: 0.752577\n",
      "Epoch 10033 - Train Loss: 0.129217, Train Acc: 0.783333 | Val Loss: 0.145436, Val Acc: 0.752577\n",
      "Epoch 10034 - Train Loss: 0.129209, Train Acc: 0.783333 | Val Loss: 0.145428, Val Acc: 0.752577\n",
      "Epoch 10035 - Train Loss: 0.129200, Train Acc: 0.783333 | Val Loss: 0.145421, Val Acc: 0.752577\n",
      "Epoch 10036 - Train Loss: 0.129192, Train Acc: 0.783333 | Val Loss: 0.145414, Val Acc: 0.752577\n",
      "Epoch 10037 - Train Loss: 0.129184, Train Acc: 0.783333 | Val Loss: 0.145407, Val Acc: 0.752577\n",
      "Epoch 10038 - Train Loss: 0.129175, Train Acc: 0.783333 | Val Loss: 0.145399, Val Acc: 0.752577\n",
      "Epoch 10039 - Train Loss: 0.129167, Train Acc: 0.783333 | Val Loss: 0.145392, Val Acc: 0.752577\n",
      "Epoch 10040 - Train Loss: 0.129159, Train Acc: 0.783333 | Val Loss: 0.145385, Val Acc: 0.752577\n",
      "Epoch 10041 - Train Loss: 0.129150, Train Acc: 0.783333 | Val Loss: 0.145378, Val Acc: 0.752577\n",
      "Epoch 10042 - Train Loss: 0.129142, Train Acc: 0.783333 | Val Loss: 0.145371, Val Acc: 0.752577\n",
      "Epoch 10043 - Train Loss: 0.129134, Train Acc: 0.783333 | Val Loss: 0.145363, Val Acc: 0.752577\n",
      "Epoch 10044 - Train Loss: 0.129125, Train Acc: 0.783333 | Val Loss: 0.145356, Val Acc: 0.752577\n",
      "Epoch 10045 - Train Loss: 0.129117, Train Acc: 0.783333 | Val Loss: 0.145349, Val Acc: 0.752577\n",
      "Epoch 10046 - Train Loss: 0.129109, Train Acc: 0.783333 | Val Loss: 0.145342, Val Acc: 0.752577\n",
      "Epoch 10047 - Train Loss: 0.129100, Train Acc: 0.783333 | Val Loss: 0.145334, Val Acc: 0.752577\n",
      "Epoch 10048 - Train Loss: 0.129092, Train Acc: 0.783333 | Val Loss: 0.145327, Val Acc: 0.752577\n",
      "Epoch 10049 - Train Loss: 0.129084, Train Acc: 0.783333 | Val Loss: 0.145320, Val Acc: 0.752577\n",
      "Epoch 10050 - Train Loss: 0.129075, Train Acc: 0.783333 | Val Loss: 0.145313, Val Acc: 0.752577\n",
      "Epoch 10051 - Train Loss: 0.129067, Train Acc: 0.783333 | Val Loss: 0.145306, Val Acc: 0.752577\n",
      "Epoch 10052 - Train Loss: 0.129059, Train Acc: 0.783333 | Val Loss: 0.145298, Val Acc: 0.752577\n",
      "Epoch 10053 - Train Loss: 0.129051, Train Acc: 0.783333 | Val Loss: 0.145291, Val Acc: 0.752577\n",
      "Epoch 10054 - Train Loss: 0.129042, Train Acc: 0.783333 | Val Loss: 0.145284, Val Acc: 0.752577\n",
      "Epoch 10055 - Train Loss: 0.129034, Train Acc: 0.783333 | Val Loss: 0.145277, Val Acc: 0.752577\n",
      "Epoch 10056 - Train Loss: 0.129026, Train Acc: 0.783333 | Val Loss: 0.145269, Val Acc: 0.752577\n",
      "Epoch 10057 - Train Loss: 0.129017, Train Acc: 0.783333 | Val Loss: 0.145262, Val Acc: 0.752577\n",
      "Epoch 10058 - Train Loss: 0.129009, Train Acc: 0.783333 | Val Loss: 0.145255, Val Acc: 0.752577\n",
      "Epoch 10059 - Train Loss: 0.129001, Train Acc: 0.783333 | Val Loss: 0.145248, Val Acc: 0.752577\n",
      "Epoch 10060 - Train Loss: 0.128992, Train Acc: 0.783333 | Val Loss: 0.145241, Val Acc: 0.752577\n",
      "Epoch 10061 - Train Loss: 0.128984, Train Acc: 0.783333 | Val Loss: 0.145234, Val Acc: 0.752577\n",
      "Epoch 10062 - Train Loss: 0.128976, Train Acc: 0.783333 | Val Loss: 0.145226, Val Acc: 0.752577\n",
      "Epoch 10063 - Train Loss: 0.128968, Train Acc: 0.783333 | Val Loss: 0.145219, Val Acc: 0.752577\n",
      "Epoch 10064 - Train Loss: 0.128959, Train Acc: 0.783333 | Val Loss: 0.145212, Val Acc: 0.752577\n",
      "Epoch 10065 - Train Loss: 0.128951, Train Acc: 0.783333 | Val Loss: 0.145205, Val Acc: 0.752577\n",
      "Epoch 10066 - Train Loss: 0.128943, Train Acc: 0.783333 | Val Loss: 0.145198, Val Acc: 0.752577\n",
      "Epoch 10067 - Train Loss: 0.128934, Train Acc: 0.783333 | Val Loss: 0.145190, Val Acc: 0.752577\n",
      "Epoch 10068 - Train Loss: 0.128926, Train Acc: 0.783333 | Val Loss: 0.145183, Val Acc: 0.752577\n",
      "Epoch 10069 - Train Loss: 0.128918, Train Acc: 0.783333 | Val Loss: 0.145176, Val Acc: 0.752577\n",
      "Epoch 10070 - Train Loss: 0.128909, Train Acc: 0.783333 | Val Loss: 0.145169, Val Acc: 0.752577\n",
      "Epoch 10071 - Train Loss: 0.128901, Train Acc: 0.783333 | Val Loss: 0.145162, Val Acc: 0.752577\n",
      "Epoch 10072 - Train Loss: 0.128893, Train Acc: 0.783333 | Val Loss: 0.145155, Val Acc: 0.752577\n",
      "Epoch 10073 - Train Loss: 0.128885, Train Acc: 0.783333 | Val Loss: 0.145147, Val Acc: 0.752577\n",
      "Epoch 10074 - Train Loss: 0.128876, Train Acc: 0.783333 | Val Loss: 0.145140, Val Acc: 0.752577\n",
      "Epoch 10075 - Train Loss: 0.128868, Train Acc: 0.783333 | Val Loss: 0.145133, Val Acc: 0.752577\n",
      "Epoch 10076 - Train Loss: 0.128860, Train Acc: 0.783333 | Val Loss: 0.145126, Val Acc: 0.752577\n",
      "Epoch 10077 - Train Loss: 0.128852, Train Acc: 0.783333 | Val Loss: 0.145119, Val Acc: 0.752577\n",
      "Epoch 10078 - Train Loss: 0.128843, Train Acc: 0.783333 | Val Loss: 0.145112, Val Acc: 0.752577\n",
      "Epoch 10079 - Train Loss: 0.128835, Train Acc: 0.783333 | Val Loss: 0.145104, Val Acc: 0.752577\n",
      "Epoch 10080 - Train Loss: 0.128827, Train Acc: 0.783333 | Val Loss: 0.145097, Val Acc: 0.752577\n",
      "Epoch 10081 - Train Loss: 0.128818, Train Acc: 0.783333 | Val Loss: 0.145090, Val Acc: 0.752577\n",
      "Epoch 10082 - Train Loss: 0.128810, Train Acc: 0.783333 | Val Loss: 0.145083, Val Acc: 0.752577\n",
      "Epoch 10083 - Train Loss: 0.128802, Train Acc: 0.783333 | Val Loss: 0.145076, Val Acc: 0.752577\n",
      "Epoch 10084 - Train Loss: 0.128794, Train Acc: 0.783333 | Val Loss: 0.145069, Val Acc: 0.752577\n",
      "Epoch 10085 - Train Loss: 0.128785, Train Acc: 0.783333 | Val Loss: 0.145061, Val Acc: 0.752577\n",
      "Epoch 10086 - Train Loss: 0.128777, Train Acc: 0.783333 | Val Loss: 0.145054, Val Acc: 0.752577\n",
      "Epoch 10087 - Train Loss: 0.128769, Train Acc: 0.783333 | Val Loss: 0.145047, Val Acc: 0.752577\n",
      "Epoch 10088 - Train Loss: 0.128761, Train Acc: 0.783333 | Val Loss: 0.145040, Val Acc: 0.752577\n",
      "Epoch 10089 - Train Loss: 0.128752, Train Acc: 0.783333 | Val Loss: 0.145033, Val Acc: 0.752577\n",
      "Epoch 10090 - Train Loss: 0.128744, Train Acc: 0.783333 | Val Loss: 0.145026, Val Acc: 0.752577\n",
      "Epoch 10091 - Train Loss: 0.128736, Train Acc: 0.783333 | Val Loss: 0.145019, Val Acc: 0.752577\n",
      "Epoch 10092 - Train Loss: 0.128728, Train Acc: 0.783333 | Val Loss: 0.145012, Val Acc: 0.752577\n",
      "Epoch 10093 - Train Loss: 0.128719, Train Acc: 0.783333 | Val Loss: 0.145004, Val Acc: 0.752577\n",
      "Epoch 10094 - Train Loss: 0.128711, Train Acc: 0.783333 | Val Loss: 0.144997, Val Acc: 0.752577\n",
      "Epoch 10095 - Train Loss: 0.128703, Train Acc: 0.783333 | Val Loss: 0.144990, Val Acc: 0.752577\n",
      "Epoch 10096 - Train Loss: 0.128694, Train Acc: 0.783333 | Val Loss: 0.144983, Val Acc: 0.752577\n",
      "Epoch 10097 - Train Loss: 0.128686, Train Acc: 0.783333 | Val Loss: 0.144976, Val Acc: 0.752577\n",
      "Epoch 10098 - Train Loss: 0.128678, Train Acc: 0.783333 | Val Loss: 0.144969, Val Acc: 0.752577\n",
      "Epoch 10099 - Train Loss: 0.128670, Train Acc: 0.783333 | Val Loss: 0.144962, Val Acc: 0.752577\n",
      "Epoch 10100 - Train Loss: 0.128661, Train Acc: 0.783333 | Val Loss: 0.144955, Val Acc: 0.752577\n",
      "Epoch 10101 - Train Loss: 0.128653, Train Acc: 0.783333 | Val Loss: 0.144947, Val Acc: 0.752577\n",
      "Epoch 10102 - Train Loss: 0.128645, Train Acc: 0.783333 | Val Loss: 0.144940, Val Acc: 0.752577\n",
      "Epoch 10103 - Train Loss: 0.128637, Train Acc: 0.783333 | Val Loss: 0.144933, Val Acc: 0.752577\n",
      "Epoch 10104 - Train Loss: 0.128629, Train Acc: 0.783333 | Val Loss: 0.144926, Val Acc: 0.752577\n",
      "Epoch 10105 - Train Loss: 0.128620, Train Acc: 0.783333 | Val Loss: 0.144919, Val Acc: 0.752577\n",
      "Epoch 10106 - Train Loss: 0.128612, Train Acc: 0.783333 | Val Loss: 0.144912, Val Acc: 0.752577\n",
      "Epoch 10107 - Train Loss: 0.128604, Train Acc: 0.783333 | Val Loss: 0.144905, Val Acc: 0.752577\n",
      "Epoch 10108 - Train Loss: 0.128596, Train Acc: 0.783333 | Val Loss: 0.144898, Val Acc: 0.752577\n",
      "Epoch 10109 - Train Loss: 0.128587, Train Acc: 0.783333 | Val Loss: 0.144891, Val Acc: 0.752577\n",
      "Epoch 10110 - Train Loss: 0.128579, Train Acc: 0.783333 | Val Loss: 0.144883, Val Acc: 0.752577\n",
      "Epoch 10111 - Train Loss: 0.128571, Train Acc: 0.783333 | Val Loss: 0.144876, Val Acc: 0.752577\n",
      "Epoch 10112 - Train Loss: 0.128563, Train Acc: 0.783333 | Val Loss: 0.144869, Val Acc: 0.752577\n",
      "Epoch 10113 - Train Loss: 0.128554, Train Acc: 0.783333 | Val Loss: 0.144862, Val Acc: 0.752577\n",
      "Epoch 10114 - Train Loss: 0.128546, Train Acc: 0.783333 | Val Loss: 0.144855, Val Acc: 0.752577\n",
      "Epoch 10115 - Train Loss: 0.128538, Train Acc: 0.783333 | Val Loss: 0.144848, Val Acc: 0.752577\n",
      "Epoch 10116 - Train Loss: 0.128530, Train Acc: 0.783333 | Val Loss: 0.144841, Val Acc: 0.752577\n",
      "Epoch 10117 - Train Loss: 0.128522, Train Acc: 0.783333 | Val Loss: 0.144834, Val Acc: 0.752577\n",
      "Epoch 10118 - Train Loss: 0.128513, Train Acc: 0.783333 | Val Loss: 0.144827, Val Acc: 0.752577\n",
      "Epoch 10119 - Train Loss: 0.128505, Train Acc: 0.783333 | Val Loss: 0.144820, Val Acc: 0.752577\n",
      "Epoch 10120 - Train Loss: 0.128497, Train Acc: 0.783333 | Val Loss: 0.144813, Val Acc: 0.752577\n",
      "Epoch 10121 - Train Loss: 0.128489, Train Acc: 0.783333 | Val Loss: 0.144806, Val Acc: 0.752577\n",
      "Epoch 10122 - Train Loss: 0.128480, Train Acc: 0.783333 | Val Loss: 0.144799, Val Acc: 0.752577\n",
      "Epoch 10123 - Train Loss: 0.128472, Train Acc: 0.783333 | Val Loss: 0.144792, Val Acc: 0.752577\n",
      "Epoch 10124 - Train Loss: 0.128464, Train Acc: 0.784615 | Val Loss: 0.144784, Val Acc: 0.752577\n",
      "Epoch 10125 - Train Loss: 0.128456, Train Acc: 0.784615 | Val Loss: 0.144777, Val Acc: 0.752577\n",
      "Epoch 10126 - Train Loss: 0.128448, Train Acc: 0.784615 | Val Loss: 0.144770, Val Acc: 0.752577\n",
      "Epoch 10127 - Train Loss: 0.128439, Train Acc: 0.784615 | Val Loss: 0.144763, Val Acc: 0.752577\n",
      "Epoch 10128 - Train Loss: 0.128431, Train Acc: 0.784615 | Val Loss: 0.144756, Val Acc: 0.752577\n",
      "Epoch 10129 - Train Loss: 0.128423, Train Acc: 0.784615 | Val Loss: 0.144749, Val Acc: 0.752577\n",
      "Epoch 10130 - Train Loss: 0.128415, Train Acc: 0.783333 | Val Loss: 0.144742, Val Acc: 0.752577\n",
      "Epoch 10131 - Train Loss: 0.128407, Train Acc: 0.783333 | Val Loss: 0.144735, Val Acc: 0.752577\n",
      "Epoch 10132 - Train Loss: 0.128398, Train Acc: 0.783333 | Val Loss: 0.144728, Val Acc: 0.752577\n",
      "Epoch 10133 - Train Loss: 0.128390, Train Acc: 0.783333 | Val Loss: 0.144721, Val Acc: 0.752577\n",
      "Epoch 10134 - Train Loss: 0.128382, Train Acc: 0.783333 | Val Loss: 0.144714, Val Acc: 0.752577\n",
      "Epoch 10135 - Train Loss: 0.128374, Train Acc: 0.783333 | Val Loss: 0.144707, Val Acc: 0.752577\n",
      "Epoch 10136 - Train Loss: 0.128366, Train Acc: 0.783333 | Val Loss: 0.144700, Val Acc: 0.752577\n",
      "Epoch 10137 - Train Loss: 0.128357, Train Acc: 0.783333 | Val Loss: 0.144693, Val Acc: 0.752577\n",
      "Epoch 10138 - Train Loss: 0.128349, Train Acc: 0.783333 | Val Loss: 0.144686, Val Acc: 0.752577\n",
      "Epoch 10139 - Train Loss: 0.128341, Train Acc: 0.783333 | Val Loss: 0.144679, Val Acc: 0.752577\n",
      "Epoch 10140 - Train Loss: 0.128333, Train Acc: 0.783333 | Val Loss: 0.144671, Val Acc: 0.752577\n",
      "Epoch 10141 - Train Loss: 0.128325, Train Acc: 0.783333 | Val Loss: 0.144664, Val Acc: 0.752577\n",
      "Epoch 10142 - Train Loss: 0.128316, Train Acc: 0.784615 | Val Loss: 0.144657, Val Acc: 0.752577\n",
      "Epoch 10143 - Train Loss: 0.128308, Train Acc: 0.784615 | Val Loss: 0.144650, Val Acc: 0.752577\n",
      "Epoch 10144 - Train Loss: 0.128300, Train Acc: 0.784615 | Val Loss: 0.144643, Val Acc: 0.752577\n",
      "Epoch 10145 - Train Loss: 0.128292, Train Acc: 0.784615 | Val Loss: 0.144636, Val Acc: 0.752577\n",
      "Epoch 10146 - Train Loss: 0.128284, Train Acc: 0.784615 | Val Loss: 0.144629, Val Acc: 0.752577\n",
      "Epoch 10147 - Train Loss: 0.128276, Train Acc: 0.784615 | Val Loss: 0.144622, Val Acc: 0.752577\n",
      "Epoch 10148 - Train Loss: 0.128267, Train Acc: 0.784615 | Val Loss: 0.144615, Val Acc: 0.752577\n",
      "Epoch 10149 - Train Loss: 0.128259, Train Acc: 0.784615 | Val Loss: 0.144608, Val Acc: 0.752577\n",
      "Epoch 10150 - Train Loss: 0.128251, Train Acc: 0.784615 | Val Loss: 0.144601, Val Acc: 0.752577\n",
      "Epoch 10151 - Train Loss: 0.128243, Train Acc: 0.784615 | Val Loss: 0.144594, Val Acc: 0.752577\n",
      "Epoch 10152 - Train Loss: 0.128235, Train Acc: 0.784615 | Val Loss: 0.144587, Val Acc: 0.752577\n",
      "Epoch 10153 - Train Loss: 0.128226, Train Acc: 0.784615 | Val Loss: 0.144580, Val Acc: 0.752577\n",
      "Epoch 10154 - Train Loss: 0.128218, Train Acc: 0.784615 | Val Loss: 0.144573, Val Acc: 0.752577\n",
      "Epoch 10155 - Train Loss: 0.128210, Train Acc: 0.784615 | Val Loss: 0.144566, Val Acc: 0.752577\n",
      "Epoch 10156 - Train Loss: 0.128202, Train Acc: 0.784615 | Val Loss: 0.144559, Val Acc: 0.752577\n",
      "Epoch 10157 - Train Loss: 0.128194, Train Acc: 0.784615 | Val Loss: 0.144552, Val Acc: 0.752577\n",
      "Epoch 10158 - Train Loss: 0.128186, Train Acc: 0.784615 | Val Loss: 0.144545, Val Acc: 0.752577\n",
      "Epoch 10159 - Train Loss: 0.128177, Train Acc: 0.784615 | Val Loss: 0.144538, Val Acc: 0.752577\n",
      "Epoch 10160 - Train Loss: 0.128169, Train Acc: 0.784615 | Val Loss: 0.144531, Val Acc: 0.752577\n",
      "Epoch 10161 - Train Loss: 0.128161, Train Acc: 0.784615 | Val Loss: 0.144524, Val Acc: 0.752577\n",
      "Epoch 10162 - Train Loss: 0.128153, Train Acc: 0.784615 | Val Loss: 0.144517, Val Acc: 0.752577\n",
      "Epoch 10163 - Train Loss: 0.128145, Train Acc: 0.784615 | Val Loss: 0.144510, Val Acc: 0.752577\n",
      "Epoch 10164 - Train Loss: 0.128137, Train Acc: 0.784615 | Val Loss: 0.144503, Val Acc: 0.752577\n",
      "Epoch 10165 - Train Loss: 0.128129, Train Acc: 0.784615 | Val Loss: 0.144495, Val Acc: 0.752577\n",
      "Epoch 10166 - Train Loss: 0.128120, Train Acc: 0.784615 | Val Loss: 0.144488, Val Acc: 0.752577\n",
      "Epoch 10167 - Train Loss: 0.128112, Train Acc: 0.784615 | Val Loss: 0.144481, Val Acc: 0.752577\n",
      "Epoch 10168 - Train Loss: 0.128104, Train Acc: 0.784615 | Val Loss: 0.144474, Val Acc: 0.752577\n",
      "Epoch 10169 - Train Loss: 0.128096, Train Acc: 0.784615 | Val Loss: 0.144467, Val Acc: 0.752577\n",
      "Epoch 10170 - Train Loss: 0.128088, Train Acc: 0.784615 | Val Loss: 0.144460, Val Acc: 0.752577\n",
      "Epoch 10171 - Train Loss: 0.128080, Train Acc: 0.784615 | Val Loss: 0.144453, Val Acc: 0.752577\n",
      "Epoch 10172 - Train Loss: 0.128071, Train Acc: 0.784615 | Val Loss: 0.144446, Val Acc: 0.752577\n",
      "Epoch 10173 - Train Loss: 0.128063, Train Acc: 0.784615 | Val Loss: 0.144439, Val Acc: 0.752577\n",
      "Epoch 10174 - Train Loss: 0.128055, Train Acc: 0.785897 | Val Loss: 0.144432, Val Acc: 0.752577\n",
      "Epoch 10175 - Train Loss: 0.128047, Train Acc: 0.785897 | Val Loss: 0.144425, Val Acc: 0.752577\n",
      "Epoch 10176 - Train Loss: 0.128039, Train Acc: 0.785897 | Val Loss: 0.144418, Val Acc: 0.752577\n",
      "Epoch 10177 - Train Loss: 0.128031, Train Acc: 0.785897 | Val Loss: 0.144411, Val Acc: 0.752577\n",
      "Epoch 10178 - Train Loss: 0.128023, Train Acc: 0.785897 | Val Loss: 0.144404, Val Acc: 0.752577\n",
      "Epoch 10179 - Train Loss: 0.128014, Train Acc: 0.785897 | Val Loss: 0.144397, Val Acc: 0.752577\n",
      "Epoch 10180 - Train Loss: 0.128006, Train Acc: 0.785897 | Val Loss: 0.144390, Val Acc: 0.752577\n",
      "Epoch 10181 - Train Loss: 0.127998, Train Acc: 0.785897 | Val Loss: 0.144383, Val Acc: 0.752577\n",
      "Epoch 10182 - Train Loss: 0.127990, Train Acc: 0.785897 | Val Loss: 0.144376, Val Acc: 0.752577\n",
      "Epoch 10183 - Train Loss: 0.127982, Train Acc: 0.785897 | Val Loss: 0.144369, Val Acc: 0.752577\n",
      "Epoch 10184 - Train Loss: 0.127974, Train Acc: 0.785897 | Val Loss: 0.144362, Val Acc: 0.752577\n",
      "Epoch 10185 - Train Loss: 0.127966, Train Acc: 0.785897 | Val Loss: 0.144355, Val Acc: 0.752577\n",
      "Epoch 10186 - Train Loss: 0.127958, Train Acc: 0.785897 | Val Loss: 0.144348, Val Acc: 0.752577\n",
      "Epoch 10187 - Train Loss: 0.127949, Train Acc: 0.785897 | Val Loss: 0.144341, Val Acc: 0.752577\n",
      "Epoch 10188 - Train Loss: 0.127941, Train Acc: 0.785897 | Val Loss: 0.144334, Val Acc: 0.752577\n",
      "Epoch 10189 - Train Loss: 0.127933, Train Acc: 0.785897 | Val Loss: 0.144327, Val Acc: 0.752577\n",
      "Epoch 10190 - Train Loss: 0.127925, Train Acc: 0.785897 | Val Loss: 0.144320, Val Acc: 0.752577\n",
      "Epoch 10191 - Train Loss: 0.127917, Train Acc: 0.785897 | Val Loss: 0.144314, Val Acc: 0.752577\n",
      "Epoch 10192 - Train Loss: 0.127909, Train Acc: 0.785897 | Val Loss: 0.144307, Val Acc: 0.752577\n",
      "Epoch 10193 - Train Loss: 0.127901, Train Acc: 0.785897 | Val Loss: 0.144300, Val Acc: 0.752577\n",
      "Epoch 10194 - Train Loss: 0.127893, Train Acc: 0.785897 | Val Loss: 0.144293, Val Acc: 0.752577\n",
      "Epoch 10195 - Train Loss: 0.127884, Train Acc: 0.785897 | Val Loss: 0.144286, Val Acc: 0.752577\n",
      "Epoch 10196 - Train Loss: 0.127876, Train Acc: 0.785897 | Val Loss: 0.144279, Val Acc: 0.752577\n",
      "Epoch 10197 - Train Loss: 0.127868, Train Acc: 0.785897 | Val Loss: 0.144272, Val Acc: 0.752577\n",
      "Epoch 10198 - Train Loss: 0.127860, Train Acc: 0.785897 | Val Loss: 0.144265, Val Acc: 0.752577\n",
      "Epoch 10199 - Train Loss: 0.127852, Train Acc: 0.785897 | Val Loss: 0.144258, Val Acc: 0.752577\n",
      "Epoch 10200 - Train Loss: 0.127844, Train Acc: 0.785897 | Val Loss: 0.144251, Val Acc: 0.752577\n",
      "Epoch 10201 - Train Loss: 0.127836, Train Acc: 0.785897 | Val Loss: 0.144244, Val Acc: 0.752577\n",
      "Epoch 10202 - Train Loss: 0.127828, Train Acc: 0.785897 | Val Loss: 0.144237, Val Acc: 0.752577\n",
      "Epoch 10203 - Train Loss: 0.127820, Train Acc: 0.785897 | Val Loss: 0.144230, Val Acc: 0.752577\n",
      "Epoch 10204 - Train Loss: 0.127812, Train Acc: 0.785897 | Val Loss: 0.144223, Val Acc: 0.752577\n",
      "Epoch 10205 - Train Loss: 0.127803, Train Acc: 0.785897 | Val Loss: 0.144216, Val Acc: 0.752577\n",
      "Epoch 10206 - Train Loss: 0.127795, Train Acc: 0.785897 | Val Loss: 0.144209, Val Acc: 0.752577\n",
      "Epoch 10207 - Train Loss: 0.127787, Train Acc: 0.785897 | Val Loss: 0.144202, Val Acc: 0.752577\n",
      "Epoch 10208 - Train Loss: 0.127779, Train Acc: 0.785897 | Val Loss: 0.144195, Val Acc: 0.752577\n",
      "Epoch 10209 - Train Loss: 0.127771, Train Acc: 0.785897 | Val Loss: 0.144188, Val Acc: 0.752577\n",
      "Epoch 10210 - Train Loss: 0.127763, Train Acc: 0.785897 | Val Loss: 0.144181, Val Acc: 0.752577\n",
      "Epoch 10211 - Train Loss: 0.127755, Train Acc: 0.785897 | Val Loss: 0.144174, Val Acc: 0.752577\n",
      "Epoch 10212 - Train Loss: 0.127747, Train Acc: 0.785897 | Val Loss: 0.144167, Val Acc: 0.752577\n",
      "Epoch 10213 - Train Loss: 0.127739, Train Acc: 0.785897 | Val Loss: 0.144160, Val Acc: 0.752577\n",
      "Epoch 10214 - Train Loss: 0.127731, Train Acc: 0.785897 | Val Loss: 0.144153, Val Acc: 0.752577\n",
      "Epoch 10215 - Train Loss: 0.127722, Train Acc: 0.785897 | Val Loss: 0.144147, Val Acc: 0.752577\n",
      "Epoch 10216 - Train Loss: 0.127714, Train Acc: 0.785897 | Val Loss: 0.144140, Val Acc: 0.752577\n",
      "Epoch 10217 - Train Loss: 0.127706, Train Acc: 0.785897 | Val Loss: 0.144133, Val Acc: 0.752577\n",
      "Epoch 10218 - Train Loss: 0.127698, Train Acc: 0.785897 | Val Loss: 0.144126, Val Acc: 0.752577\n",
      "Epoch 10219 - Train Loss: 0.127690, Train Acc: 0.785897 | Val Loss: 0.144119, Val Acc: 0.752577\n",
      "Epoch 10220 - Train Loss: 0.127682, Train Acc: 0.785897 | Val Loss: 0.144112, Val Acc: 0.752577\n",
      "Epoch 10221 - Train Loss: 0.127674, Train Acc: 0.785897 | Val Loss: 0.144105, Val Acc: 0.752577\n",
      "Epoch 10222 - Train Loss: 0.127666, Train Acc: 0.785897 | Val Loss: 0.144098, Val Acc: 0.752577\n",
      "Epoch 10223 - Train Loss: 0.127658, Train Acc: 0.785897 | Val Loss: 0.144091, Val Acc: 0.752577\n",
      "Epoch 10224 - Train Loss: 0.127650, Train Acc: 0.785897 | Val Loss: 0.144084, Val Acc: 0.752577\n",
      "Epoch 10225 - Train Loss: 0.127642, Train Acc: 0.785897 | Val Loss: 0.144078, Val Acc: 0.752577\n",
      "Epoch 10226 - Train Loss: 0.127634, Train Acc: 0.785897 | Val Loss: 0.144071, Val Acc: 0.752577\n",
      "Epoch 10227 - Train Loss: 0.127626, Train Acc: 0.785897 | Val Loss: 0.144064, Val Acc: 0.752577\n",
      "Epoch 10228 - Train Loss: 0.127617, Train Acc: 0.785897 | Val Loss: 0.144057, Val Acc: 0.752577\n",
      "Epoch 10229 - Train Loss: 0.127609, Train Acc: 0.785897 | Val Loss: 0.144050, Val Acc: 0.752577\n",
      "Epoch 10230 - Train Loss: 0.127601, Train Acc: 0.785897 | Val Loss: 0.144043, Val Acc: 0.752577\n",
      "Epoch 10231 - Train Loss: 0.127593, Train Acc: 0.785897 | Val Loss: 0.144037, Val Acc: 0.752577\n",
      "Epoch 10232 - Train Loss: 0.127585, Train Acc: 0.785897 | Val Loss: 0.144030, Val Acc: 0.752577\n",
      "Epoch 10233 - Train Loss: 0.127577, Train Acc: 0.785897 | Val Loss: 0.144023, Val Acc: 0.752577\n",
      "Epoch 10234 - Train Loss: 0.127569, Train Acc: 0.785897 | Val Loss: 0.144016, Val Acc: 0.752577\n",
      "Epoch 10235 - Train Loss: 0.127561, Train Acc: 0.785897 | Val Loss: 0.144009, Val Acc: 0.752577\n",
      "Epoch 10236 - Train Loss: 0.127553, Train Acc: 0.785897 | Val Loss: 0.144002, Val Acc: 0.752577\n",
      "Epoch 10237 - Train Loss: 0.127545, Train Acc: 0.787179 | Val Loss: 0.143995, Val Acc: 0.752577\n",
      "Epoch 10238 - Train Loss: 0.127537, Train Acc: 0.787179 | Val Loss: 0.143989, Val Acc: 0.752577\n",
      "Epoch 10239 - Train Loss: 0.127529, Train Acc: 0.787179 | Val Loss: 0.143982, Val Acc: 0.752577\n",
      "Epoch 10240 - Train Loss: 0.127521, Train Acc: 0.787179 | Val Loss: 0.143975, Val Acc: 0.752577\n",
      "Epoch 10241 - Train Loss: 0.127513, Train Acc: 0.787179 | Val Loss: 0.143968, Val Acc: 0.752577\n",
      "Epoch 10242 - Train Loss: 0.127505, Train Acc: 0.787179 | Val Loss: 0.143961, Val Acc: 0.752577\n",
      "Epoch 10243 - Train Loss: 0.127497, Train Acc: 0.787179 | Val Loss: 0.143954, Val Acc: 0.752577\n",
      "Epoch 10244 - Train Loss: 0.127489, Train Acc: 0.787179 | Val Loss: 0.143947, Val Acc: 0.752577\n",
      "Epoch 10245 - Train Loss: 0.127481, Train Acc: 0.787179 | Val Loss: 0.143941, Val Acc: 0.752577\n",
      "Epoch 10246 - Train Loss: 0.127472, Train Acc: 0.787179 | Val Loss: 0.143934, Val Acc: 0.752577\n",
      "Epoch 10247 - Train Loss: 0.127464, Train Acc: 0.787179 | Val Loss: 0.143927, Val Acc: 0.752577\n",
      "Epoch 10248 - Train Loss: 0.127456, Train Acc: 0.787179 | Val Loss: 0.143920, Val Acc: 0.752577\n",
      "Epoch 10249 - Train Loss: 0.127448, Train Acc: 0.787179 | Val Loss: 0.143913, Val Acc: 0.752577\n",
      "Epoch 10250 - Train Loss: 0.127440, Train Acc: 0.787179 | Val Loss: 0.143906, Val Acc: 0.752577\n",
      "Epoch 10251 - Train Loss: 0.127432, Train Acc: 0.787179 | Val Loss: 0.143899, Val Acc: 0.752577\n",
      "Epoch 10252 - Train Loss: 0.127424, Train Acc: 0.785897 | Val Loss: 0.143893, Val Acc: 0.752577\n",
      "Epoch 10253 - Train Loss: 0.127416, Train Acc: 0.785897 | Val Loss: 0.143886, Val Acc: 0.752577\n",
      "Epoch 10254 - Train Loss: 0.127408, Train Acc: 0.785897 | Val Loss: 0.143879, Val Acc: 0.752577\n",
      "Epoch 10255 - Train Loss: 0.127400, Train Acc: 0.785897 | Val Loss: 0.143872, Val Acc: 0.752577\n",
      "Epoch 10256 - Train Loss: 0.127392, Train Acc: 0.785897 | Val Loss: 0.143865, Val Acc: 0.752577\n",
      "Epoch 10257 - Train Loss: 0.127384, Train Acc: 0.785897 | Val Loss: 0.143858, Val Acc: 0.752577\n",
      "Epoch 10258 - Train Loss: 0.127376, Train Acc: 0.785897 | Val Loss: 0.143852, Val Acc: 0.752577\n",
      "Epoch 10259 - Train Loss: 0.127368, Train Acc: 0.785897 | Val Loss: 0.143845, Val Acc: 0.752577\n",
      "Epoch 10260 - Train Loss: 0.127360, Train Acc: 0.785897 | Val Loss: 0.143838, Val Acc: 0.752577\n",
      "Epoch 10261 - Train Loss: 0.127352, Train Acc: 0.785897 | Val Loss: 0.143831, Val Acc: 0.752577\n",
      "Epoch 10262 - Train Loss: 0.127344, Train Acc: 0.785897 | Val Loss: 0.143824, Val Acc: 0.752577\n",
      "Epoch 10263 - Train Loss: 0.127336, Train Acc: 0.785897 | Val Loss: 0.143817, Val Acc: 0.752577\n",
      "Epoch 10264 - Train Loss: 0.127328, Train Acc: 0.785897 | Val Loss: 0.143810, Val Acc: 0.752577\n",
      "Epoch 10265 - Train Loss: 0.127320, Train Acc: 0.785897 | Val Loss: 0.143804, Val Acc: 0.752577\n",
      "Epoch 10266 - Train Loss: 0.127312, Train Acc: 0.785897 | Val Loss: 0.143797, Val Acc: 0.752577\n",
      "Epoch 10267 - Train Loss: 0.127304, Train Acc: 0.785897 | Val Loss: 0.143790, Val Acc: 0.752577\n",
      "Epoch 10268 - Train Loss: 0.127296, Train Acc: 0.785897 | Val Loss: 0.143783, Val Acc: 0.752577\n",
      "Epoch 10269 - Train Loss: 0.127288, Train Acc: 0.785897 | Val Loss: 0.143776, Val Acc: 0.752577\n",
      "Epoch 10270 - Train Loss: 0.127280, Train Acc: 0.785897 | Val Loss: 0.143769, Val Acc: 0.752577\n",
      "Epoch 10271 - Train Loss: 0.127272, Train Acc: 0.785897 | Val Loss: 0.143763, Val Acc: 0.752577\n",
      "Epoch 10272 - Train Loss: 0.127264, Train Acc: 0.785897 | Val Loss: 0.143756, Val Acc: 0.752577\n",
      "Epoch 10273 - Train Loss: 0.127256, Train Acc: 0.785897 | Val Loss: 0.143749, Val Acc: 0.752577\n",
      "Epoch 10274 - Train Loss: 0.127248, Train Acc: 0.785897 | Val Loss: 0.143742, Val Acc: 0.752577\n",
      "Epoch 10275 - Train Loss: 0.127240, Train Acc: 0.785897 | Val Loss: 0.143735, Val Acc: 0.752577\n",
      "Epoch 10276 - Train Loss: 0.127232, Train Acc: 0.785897 | Val Loss: 0.143728, Val Acc: 0.752577\n",
      "Epoch 10277 - Train Loss: 0.127224, Train Acc: 0.785897 | Val Loss: 0.143722, Val Acc: 0.752577\n",
      "Epoch 10278 - Train Loss: 0.127216, Train Acc: 0.785897 | Val Loss: 0.143715, Val Acc: 0.752577\n",
      "Epoch 10279 - Train Loss: 0.127208, Train Acc: 0.785897 | Val Loss: 0.143708, Val Acc: 0.752577\n",
      "Epoch 10280 - Train Loss: 0.127200, Train Acc: 0.785897 | Val Loss: 0.143701, Val Acc: 0.752577\n",
      "Epoch 10281 - Train Loss: 0.127192, Train Acc: 0.785897 | Val Loss: 0.143694, Val Acc: 0.752577\n",
      "Epoch 10282 - Train Loss: 0.127184, Train Acc: 0.785897 | Val Loss: 0.143687, Val Acc: 0.752577\n",
      "Epoch 10283 - Train Loss: 0.127176, Train Acc: 0.785897 | Val Loss: 0.143681, Val Acc: 0.752577\n",
      "Epoch 10284 - Train Loss: 0.127168, Train Acc: 0.785897 | Val Loss: 0.143674, Val Acc: 0.752577\n",
      "Epoch 10285 - Train Loss: 0.127160, Train Acc: 0.785897 | Val Loss: 0.143667, Val Acc: 0.752577\n",
      "Epoch 10286 - Train Loss: 0.127152, Train Acc: 0.785897 | Val Loss: 0.143660, Val Acc: 0.752577\n",
      "Epoch 10287 - Train Loss: 0.127144, Train Acc: 0.785897 | Val Loss: 0.143653, Val Acc: 0.752577\n",
      "Epoch 10288 - Train Loss: 0.127136, Train Acc: 0.785897 | Val Loss: 0.143646, Val Acc: 0.752577\n",
      "Epoch 10289 - Train Loss: 0.127128, Train Acc: 0.785897 | Val Loss: 0.143639, Val Acc: 0.752577\n",
      "Epoch 10290 - Train Loss: 0.127120, Train Acc: 0.785897 | Val Loss: 0.143633, Val Acc: 0.752577\n",
      "Epoch 10291 - Train Loss: 0.127112, Train Acc: 0.785897 | Val Loss: 0.143626, Val Acc: 0.752577\n",
      "Epoch 10292 - Train Loss: 0.127104, Train Acc: 0.785897 | Val Loss: 0.143619, Val Acc: 0.752577\n",
      "Epoch 10293 - Train Loss: 0.127096, Train Acc: 0.785897 | Val Loss: 0.143612, Val Acc: 0.752577\n",
      "Epoch 10294 - Train Loss: 0.127088, Train Acc: 0.785897 | Val Loss: 0.143605, Val Acc: 0.752577\n",
      "Epoch 10295 - Train Loss: 0.127080, Train Acc: 0.785897 | Val Loss: 0.143598, Val Acc: 0.752577\n",
      "Epoch 10296 - Train Loss: 0.127072, Train Acc: 0.785897 | Val Loss: 0.143592, Val Acc: 0.752577\n",
      "Epoch 10297 - Train Loss: 0.127064, Train Acc: 0.785897 | Val Loss: 0.143585, Val Acc: 0.752577\n",
      "Epoch 10298 - Train Loss: 0.127056, Train Acc: 0.785897 | Val Loss: 0.143578, Val Acc: 0.752577\n",
      "Epoch 10299 - Train Loss: 0.127048, Train Acc: 0.785897 | Val Loss: 0.143571, Val Acc: 0.752577\n",
      "Epoch 10300 - Train Loss: 0.127040, Train Acc: 0.785897 | Val Loss: 0.143564, Val Acc: 0.752577\n",
      "Epoch 10301 - Train Loss: 0.127032, Train Acc: 0.785897 | Val Loss: 0.143558, Val Acc: 0.752577\n",
      "Epoch 10302 - Train Loss: 0.127024, Train Acc: 0.785897 | Val Loss: 0.143551, Val Acc: 0.752577\n",
      "Epoch 10303 - Train Loss: 0.127016, Train Acc: 0.785897 | Val Loss: 0.143544, Val Acc: 0.752577\n",
      "Epoch 10304 - Train Loss: 0.127008, Train Acc: 0.785897 | Val Loss: 0.143537, Val Acc: 0.752577\n",
      "Epoch 10305 - Train Loss: 0.127000, Train Acc: 0.785897 | Val Loss: 0.143530, Val Acc: 0.752577\n",
      "Epoch 10306 - Train Loss: 0.126992, Train Acc: 0.785897 | Val Loss: 0.143523, Val Acc: 0.752577\n",
      "Epoch 10307 - Train Loss: 0.126984, Train Acc: 0.785897 | Val Loss: 0.143517, Val Acc: 0.752577\n",
      "Epoch 10308 - Train Loss: 0.126976, Train Acc: 0.785897 | Val Loss: 0.143510, Val Acc: 0.752577\n",
      "Epoch 10309 - Train Loss: 0.126968, Train Acc: 0.785897 | Val Loss: 0.143503, Val Acc: 0.752577\n",
      "Epoch 10310 - Train Loss: 0.126960, Train Acc: 0.785897 | Val Loss: 0.143496, Val Acc: 0.752577\n",
      "Epoch 10311 - Train Loss: 0.126953, Train Acc: 0.785897 | Val Loss: 0.143489, Val Acc: 0.752577\n",
      "Epoch 10312 - Train Loss: 0.126945, Train Acc: 0.785897 | Val Loss: 0.143483, Val Acc: 0.752577\n",
      "Epoch 10313 - Train Loss: 0.126937, Train Acc: 0.785897 | Val Loss: 0.143476, Val Acc: 0.752577\n",
      "Epoch 10314 - Train Loss: 0.126929, Train Acc: 0.785897 | Val Loss: 0.143469, Val Acc: 0.752577\n",
      "Epoch 10315 - Train Loss: 0.126921, Train Acc: 0.787179 | Val Loss: 0.143462, Val Acc: 0.752577\n",
      "Epoch 10316 - Train Loss: 0.126913, Train Acc: 0.787179 | Val Loss: 0.143455, Val Acc: 0.752577\n",
      "Epoch 10317 - Train Loss: 0.126905, Train Acc: 0.787179 | Val Loss: 0.143449, Val Acc: 0.752577\n",
      "Epoch 10318 - Train Loss: 0.126897, Train Acc: 0.787179 | Val Loss: 0.143442, Val Acc: 0.752577\n",
      "Epoch 10319 - Train Loss: 0.126889, Train Acc: 0.787179 | Val Loss: 0.143435, Val Acc: 0.752577\n",
      "Epoch 10320 - Train Loss: 0.126881, Train Acc: 0.787179 | Val Loss: 0.143428, Val Acc: 0.752577\n",
      "Epoch 10321 - Train Loss: 0.126873, Train Acc: 0.787179 | Val Loss: 0.143421, Val Acc: 0.752577\n",
      "Epoch 10322 - Train Loss: 0.126865, Train Acc: 0.787179 | Val Loss: 0.143415, Val Acc: 0.752577\n",
      "Epoch 10323 - Train Loss: 0.126857, Train Acc: 0.787179 | Val Loss: 0.143408, Val Acc: 0.752577\n",
      "Epoch 10324 - Train Loss: 0.126849, Train Acc: 0.787179 | Val Loss: 0.143401, Val Acc: 0.752577\n",
      "Epoch 10325 - Train Loss: 0.126841, Train Acc: 0.787179 | Val Loss: 0.143394, Val Acc: 0.752577\n",
      "Epoch 10326 - Train Loss: 0.126833, Train Acc: 0.787179 | Val Loss: 0.143388, Val Acc: 0.752577\n",
      "Epoch 10327 - Train Loss: 0.126825, Train Acc: 0.787179 | Val Loss: 0.143381, Val Acc: 0.752577\n",
      "Epoch 10328 - Train Loss: 0.126817, Train Acc: 0.787179 | Val Loss: 0.143374, Val Acc: 0.752577\n",
      "Epoch 10329 - Train Loss: 0.126810, Train Acc: 0.787179 | Val Loss: 0.143367, Val Acc: 0.752577\n",
      "Epoch 10330 - Train Loss: 0.126802, Train Acc: 0.787179 | Val Loss: 0.143360, Val Acc: 0.752577\n",
      "Epoch 10331 - Train Loss: 0.126794, Train Acc: 0.787179 | Val Loss: 0.143354, Val Acc: 0.752577\n",
      "Epoch 10332 - Train Loss: 0.126786, Train Acc: 0.787179 | Val Loss: 0.143347, Val Acc: 0.752577\n",
      "Epoch 10333 - Train Loss: 0.126778, Train Acc: 0.787179 | Val Loss: 0.143340, Val Acc: 0.752577\n",
      "Epoch 10334 - Train Loss: 0.126770, Train Acc: 0.787179 | Val Loss: 0.143333, Val Acc: 0.752577\n",
      "Epoch 10335 - Train Loss: 0.126762, Train Acc: 0.787179 | Val Loss: 0.143327, Val Acc: 0.752577\n",
      "Epoch 10336 - Train Loss: 0.126754, Train Acc: 0.787179 | Val Loss: 0.143320, Val Acc: 0.752577\n",
      "Epoch 10337 - Train Loss: 0.126746, Train Acc: 0.787179 | Val Loss: 0.143313, Val Acc: 0.752577\n",
      "Epoch 10338 - Train Loss: 0.126738, Train Acc: 0.787179 | Val Loss: 0.143306, Val Acc: 0.752577\n",
      "Epoch 10339 - Train Loss: 0.126730, Train Acc: 0.787179 | Val Loss: 0.143300, Val Acc: 0.752577\n",
      "Epoch 10340 - Train Loss: 0.126722, Train Acc: 0.787179 | Val Loss: 0.143293, Val Acc: 0.752577\n",
      "Epoch 10341 - Train Loss: 0.126714, Train Acc: 0.787179 | Val Loss: 0.143286, Val Acc: 0.752577\n",
      "Epoch 10342 - Train Loss: 0.126707, Train Acc: 0.787179 | Val Loss: 0.143279, Val Acc: 0.752577\n",
      "Epoch 10343 - Train Loss: 0.126699, Train Acc: 0.787179 | Val Loss: 0.143273, Val Acc: 0.752577\n",
      "Epoch 10344 - Train Loss: 0.126691, Train Acc: 0.787179 | Val Loss: 0.143266, Val Acc: 0.752577\n",
      "Epoch 10345 - Train Loss: 0.126683, Train Acc: 0.787179 | Val Loss: 0.143259, Val Acc: 0.752577\n",
      "Epoch 10346 - Train Loss: 0.126675, Train Acc: 0.787179 | Val Loss: 0.143252, Val Acc: 0.752577\n",
      "Epoch 10347 - Train Loss: 0.126667, Train Acc: 0.787179 | Val Loss: 0.143246, Val Acc: 0.752577\n",
      "Epoch 10348 - Train Loss: 0.126659, Train Acc: 0.787179 | Val Loss: 0.143239, Val Acc: 0.752577\n",
      "Epoch 10349 - Train Loss: 0.126651, Train Acc: 0.787179 | Val Loss: 0.143232, Val Acc: 0.752577\n",
      "Epoch 10350 - Train Loss: 0.126643, Train Acc: 0.787179 | Val Loss: 0.143225, Val Acc: 0.752577\n",
      "Epoch 10351 - Train Loss: 0.126635, Train Acc: 0.787179 | Val Loss: 0.143219, Val Acc: 0.752577\n",
      "Epoch 10352 - Train Loss: 0.126627, Train Acc: 0.787179 | Val Loss: 0.143212, Val Acc: 0.752577\n",
      "Epoch 10353 - Train Loss: 0.126620, Train Acc: 0.787179 | Val Loss: 0.143205, Val Acc: 0.752577\n",
      "Epoch 10354 - Train Loss: 0.126612, Train Acc: 0.787179 | Val Loss: 0.143198, Val Acc: 0.752577\n",
      "Epoch 10355 - Train Loss: 0.126604, Train Acc: 0.787179 | Val Loss: 0.143192, Val Acc: 0.752577\n",
      "Epoch 10356 - Train Loss: 0.126596, Train Acc: 0.787179 | Val Loss: 0.143185, Val Acc: 0.752577\n",
      "Epoch 10357 - Train Loss: 0.126588, Train Acc: 0.787179 | Val Loss: 0.143178, Val Acc: 0.752577\n",
      "Epoch 10358 - Train Loss: 0.126580, Train Acc: 0.787179 | Val Loss: 0.143171, Val Acc: 0.752577\n",
      "Epoch 10359 - Train Loss: 0.126572, Train Acc: 0.787179 | Val Loss: 0.143165, Val Acc: 0.752577\n",
      "Epoch 10360 - Train Loss: 0.126564, Train Acc: 0.787179 | Val Loss: 0.143158, Val Acc: 0.752577\n",
      "Epoch 10361 - Train Loss: 0.126556, Train Acc: 0.787179 | Val Loss: 0.143151, Val Acc: 0.752577\n",
      "Epoch 10362 - Train Loss: 0.126549, Train Acc: 0.787179 | Val Loss: 0.143144, Val Acc: 0.752577\n",
      "Epoch 10363 - Train Loss: 0.126541, Train Acc: 0.787179 | Val Loss: 0.143138, Val Acc: 0.752577\n",
      "Epoch 10364 - Train Loss: 0.126533, Train Acc: 0.787179 | Val Loss: 0.143131, Val Acc: 0.752577\n",
      "Epoch 10365 - Train Loss: 0.126525, Train Acc: 0.787179 | Val Loss: 0.143124, Val Acc: 0.752577\n",
      "Epoch 10366 - Train Loss: 0.126517, Train Acc: 0.787179 | Val Loss: 0.143118, Val Acc: 0.752577\n",
      "Epoch 10367 - Train Loss: 0.126509, Train Acc: 0.787179 | Val Loss: 0.143111, Val Acc: 0.752577\n",
      "Epoch 10368 - Train Loss: 0.126501, Train Acc: 0.787179 | Val Loss: 0.143104, Val Acc: 0.752577\n",
      "Epoch 10369 - Train Loss: 0.126493, Train Acc: 0.787179 | Val Loss: 0.143097, Val Acc: 0.752577\n",
      "Epoch 10370 - Train Loss: 0.126485, Train Acc: 0.787179 | Val Loss: 0.143091, Val Acc: 0.752577\n",
      "Epoch 10371 - Train Loss: 0.126478, Train Acc: 0.787179 | Val Loss: 0.143084, Val Acc: 0.752577\n",
      "Epoch 10372 - Train Loss: 0.126470, Train Acc: 0.787179 | Val Loss: 0.143077, Val Acc: 0.752577\n",
      "Epoch 10373 - Train Loss: 0.126462, Train Acc: 0.787179 | Val Loss: 0.143071, Val Acc: 0.752577\n",
      "Epoch 10374 - Train Loss: 0.126454, Train Acc: 0.787179 | Val Loss: 0.143064, Val Acc: 0.752577\n",
      "Epoch 10375 - Train Loss: 0.126446, Train Acc: 0.787179 | Val Loss: 0.143057, Val Acc: 0.752577\n",
      "Epoch 10376 - Train Loss: 0.126438, Train Acc: 0.787179 | Val Loss: 0.143050, Val Acc: 0.752577\n",
      "Epoch 10377 - Train Loss: 0.126430, Train Acc: 0.787179 | Val Loss: 0.143044, Val Acc: 0.752577\n",
      "Epoch 10378 - Train Loss: 0.126423, Train Acc: 0.787179 | Val Loss: 0.143037, Val Acc: 0.752577\n",
      "Epoch 10379 - Train Loss: 0.126415, Train Acc: 0.787179 | Val Loss: 0.143030, Val Acc: 0.752577\n",
      "Epoch 10380 - Train Loss: 0.126407, Train Acc: 0.787179 | Val Loss: 0.143024, Val Acc: 0.752577\n",
      "Epoch 10381 - Train Loss: 0.126399, Train Acc: 0.787179 | Val Loss: 0.143017, Val Acc: 0.752577\n",
      "Epoch 10382 - Train Loss: 0.126391, Train Acc: 0.787179 | Val Loss: 0.143010, Val Acc: 0.752577\n",
      "Epoch 10383 - Train Loss: 0.126383, Train Acc: 0.787179 | Val Loss: 0.143003, Val Acc: 0.752577\n",
      "Epoch 10384 - Train Loss: 0.126375, Train Acc: 0.787179 | Val Loss: 0.142997, Val Acc: 0.752577\n",
      "Epoch 10385 - Train Loss: 0.126367, Train Acc: 0.787179 | Val Loss: 0.142990, Val Acc: 0.752577\n",
      "Epoch 10386 - Train Loss: 0.126360, Train Acc: 0.787179 | Val Loss: 0.142983, Val Acc: 0.752577\n",
      "Epoch 10387 - Train Loss: 0.126352, Train Acc: 0.787179 | Val Loss: 0.142977, Val Acc: 0.752577\n",
      "Epoch 10388 - Train Loss: 0.126344, Train Acc: 0.787179 | Val Loss: 0.142970, Val Acc: 0.752577\n",
      "Epoch 10389 - Train Loss: 0.126336, Train Acc: 0.787179 | Val Loss: 0.142963, Val Acc: 0.752577\n",
      "Epoch 10390 - Train Loss: 0.126328, Train Acc: 0.787179 | Val Loss: 0.142957, Val Acc: 0.752577\n",
      "Epoch 10391 - Train Loss: 0.126320, Train Acc: 0.787179 | Val Loss: 0.142950, Val Acc: 0.752577\n",
      "Epoch 10392 - Train Loss: 0.126313, Train Acc: 0.787179 | Val Loss: 0.142943, Val Acc: 0.752577\n",
      "Epoch 10393 - Train Loss: 0.126305, Train Acc: 0.787179 | Val Loss: 0.142937, Val Acc: 0.752577\n",
      "Epoch 10394 - Train Loss: 0.126297, Train Acc: 0.787179 | Val Loss: 0.142930, Val Acc: 0.752577\n",
      "Epoch 10395 - Train Loss: 0.126289, Train Acc: 0.788462 | Val Loss: 0.142923, Val Acc: 0.752577\n",
      "Epoch 10396 - Train Loss: 0.126281, Train Acc: 0.788462 | Val Loss: 0.142916, Val Acc: 0.752577\n",
      "Epoch 10397 - Train Loss: 0.126273, Train Acc: 0.788462 | Val Loss: 0.142910, Val Acc: 0.752577\n",
      "Epoch 10398 - Train Loss: 0.126265, Train Acc: 0.788462 | Val Loss: 0.142903, Val Acc: 0.752577\n",
      "Epoch 10399 - Train Loss: 0.126258, Train Acc: 0.788462 | Val Loss: 0.142896, Val Acc: 0.752577\n",
      "Epoch 10400 - Train Loss: 0.126250, Train Acc: 0.788462 | Val Loss: 0.142890, Val Acc: 0.752577\n",
      "Epoch 10401 - Train Loss: 0.126242, Train Acc: 0.788462 | Val Loss: 0.142883, Val Acc: 0.752577\n",
      "Epoch 10402 - Train Loss: 0.126234, Train Acc: 0.788462 | Val Loss: 0.142876, Val Acc: 0.752577\n",
      "Epoch 10403 - Train Loss: 0.126226, Train Acc: 0.788462 | Val Loss: 0.142870, Val Acc: 0.752577\n",
      "Epoch 10404 - Train Loss: 0.126218, Train Acc: 0.788462 | Val Loss: 0.142863, Val Acc: 0.752577\n",
      "Epoch 10405 - Train Loss: 0.126211, Train Acc: 0.788462 | Val Loss: 0.142856, Val Acc: 0.752577\n",
      "Epoch 10406 - Train Loss: 0.126203, Train Acc: 0.788462 | Val Loss: 0.142850, Val Acc: 0.752577\n",
      "Epoch 10407 - Train Loss: 0.126195, Train Acc: 0.788462 | Val Loss: 0.142843, Val Acc: 0.752577\n",
      "Epoch 10408 - Train Loss: 0.126187, Train Acc: 0.788462 | Val Loss: 0.142836, Val Acc: 0.752577\n",
      "Epoch 10409 - Train Loss: 0.126179, Train Acc: 0.788462 | Val Loss: 0.142830, Val Acc: 0.752577\n",
      "Epoch 10410 - Train Loss: 0.126171, Train Acc: 0.788462 | Val Loss: 0.142823, Val Acc: 0.752577\n",
      "Epoch 10411 - Train Loss: 0.126164, Train Acc: 0.788462 | Val Loss: 0.142816, Val Acc: 0.752577\n",
      "Epoch 10412 - Train Loss: 0.126156, Train Acc: 0.788462 | Val Loss: 0.142810, Val Acc: 0.752577\n",
      "Epoch 10413 - Train Loss: 0.126148, Train Acc: 0.788462 | Val Loss: 0.142803, Val Acc: 0.752577\n",
      "Epoch 10414 - Train Loss: 0.126140, Train Acc: 0.788462 | Val Loss: 0.142796, Val Acc: 0.752577\n",
      "Epoch 10415 - Train Loss: 0.126132, Train Acc: 0.788462 | Val Loss: 0.142790, Val Acc: 0.752577\n",
      "Epoch 10416 - Train Loss: 0.126125, Train Acc: 0.788462 | Val Loss: 0.142783, Val Acc: 0.752577\n",
      "Epoch 10417 - Train Loss: 0.126117, Train Acc: 0.788462 | Val Loss: 0.142776, Val Acc: 0.752577\n",
      "Epoch 10418 - Train Loss: 0.126109, Train Acc: 0.788462 | Val Loss: 0.142770, Val Acc: 0.752577\n",
      "Epoch 10419 - Train Loss: 0.126101, Train Acc: 0.788462 | Val Loss: 0.142763, Val Acc: 0.752577\n",
      "Epoch 10420 - Train Loss: 0.126093, Train Acc: 0.788462 | Val Loss: 0.142757, Val Acc: 0.752577\n",
      "Epoch 10421 - Train Loss: 0.126085, Train Acc: 0.788462 | Val Loss: 0.142750, Val Acc: 0.752577\n",
      "Epoch 10422 - Train Loss: 0.126078, Train Acc: 0.788462 | Val Loss: 0.142743, Val Acc: 0.752577\n",
      "Epoch 10423 - Train Loss: 0.126070, Train Acc: 0.788462 | Val Loss: 0.142737, Val Acc: 0.752577\n",
      "Epoch 10424 - Train Loss: 0.126062, Train Acc: 0.788462 | Val Loss: 0.142730, Val Acc: 0.752577\n",
      "Epoch 10425 - Train Loss: 0.126054, Train Acc: 0.788462 | Val Loss: 0.142723, Val Acc: 0.752577\n",
      "Epoch 10426 - Train Loss: 0.126046, Train Acc: 0.788462 | Val Loss: 0.142717, Val Acc: 0.752577\n",
      "Epoch 10427 - Train Loss: 0.126039, Train Acc: 0.788462 | Val Loss: 0.142710, Val Acc: 0.752577\n",
      "Epoch 10428 - Train Loss: 0.126031, Train Acc: 0.788462 | Val Loss: 0.142703, Val Acc: 0.752577\n",
      "Epoch 10429 - Train Loss: 0.126023, Train Acc: 0.788462 | Val Loss: 0.142697, Val Acc: 0.752577\n",
      "Epoch 10430 - Train Loss: 0.126015, Train Acc: 0.788462 | Val Loss: 0.142690, Val Acc: 0.752577\n",
      "Epoch 10431 - Train Loss: 0.126007, Train Acc: 0.788462 | Val Loss: 0.142683, Val Acc: 0.752577\n",
      "Epoch 10432 - Train Loss: 0.126000, Train Acc: 0.788462 | Val Loss: 0.142677, Val Acc: 0.752577\n",
      "Epoch 10433 - Train Loss: 0.125992, Train Acc: 0.788462 | Val Loss: 0.142670, Val Acc: 0.752577\n",
      "Epoch 10434 - Train Loss: 0.125984, Train Acc: 0.788462 | Val Loss: 0.142664, Val Acc: 0.752577\n",
      "Epoch 10435 - Train Loss: 0.125976, Train Acc: 0.788462 | Val Loss: 0.142657, Val Acc: 0.752577\n",
      "Epoch 10436 - Train Loss: 0.125969, Train Acc: 0.788462 | Val Loss: 0.142650, Val Acc: 0.752577\n",
      "Epoch 10437 - Train Loss: 0.125961, Train Acc: 0.788462 | Val Loss: 0.142644, Val Acc: 0.752577\n",
      "Epoch 10438 - Train Loss: 0.125953, Train Acc: 0.788462 | Val Loss: 0.142637, Val Acc: 0.752577\n",
      "Epoch 10439 - Train Loss: 0.125945, Train Acc: 0.788462 | Val Loss: 0.142630, Val Acc: 0.752577\n",
      "Epoch 10440 - Train Loss: 0.125937, Train Acc: 0.788462 | Val Loss: 0.142624, Val Acc: 0.752577\n",
      "Epoch 10441 - Train Loss: 0.125930, Train Acc: 0.788462 | Val Loss: 0.142617, Val Acc: 0.752577\n",
      "Epoch 10442 - Train Loss: 0.125922, Train Acc: 0.788462 | Val Loss: 0.142611, Val Acc: 0.752577\n",
      "Epoch 10443 - Train Loss: 0.125914, Train Acc: 0.788462 | Val Loss: 0.142604, Val Acc: 0.752577\n",
      "Epoch 10444 - Train Loss: 0.125906, Train Acc: 0.788462 | Val Loss: 0.142597, Val Acc: 0.752577\n",
      "Epoch 10445 - Train Loss: 0.125898, Train Acc: 0.788462 | Val Loss: 0.142591, Val Acc: 0.752577\n",
      "Epoch 10446 - Train Loss: 0.125891, Train Acc: 0.788462 | Val Loss: 0.142584, Val Acc: 0.752577\n",
      "Epoch 10447 - Train Loss: 0.125883, Train Acc: 0.788462 | Val Loss: 0.142577, Val Acc: 0.752577\n",
      "Epoch 10448 - Train Loss: 0.125875, Train Acc: 0.788462 | Val Loss: 0.142571, Val Acc: 0.752577\n",
      "Epoch 10449 - Train Loss: 0.125867, Train Acc: 0.788462 | Val Loss: 0.142564, Val Acc: 0.752577\n",
      "Epoch 10450 - Train Loss: 0.125860, Train Acc: 0.788462 | Val Loss: 0.142558, Val Acc: 0.752577\n",
      "Epoch 10451 - Train Loss: 0.125852, Train Acc: 0.788462 | Val Loss: 0.142551, Val Acc: 0.752577\n",
      "Epoch 10452 - Train Loss: 0.125844, Train Acc: 0.788462 | Val Loss: 0.142544, Val Acc: 0.752577\n",
      "Epoch 10453 - Train Loss: 0.125836, Train Acc: 0.788462 | Val Loss: 0.142538, Val Acc: 0.752577\n",
      "Epoch 10454 - Train Loss: 0.125829, Train Acc: 0.788462 | Val Loss: 0.142531, Val Acc: 0.752577\n",
      "Epoch 10455 - Train Loss: 0.125821, Train Acc: 0.788462 | Val Loss: 0.142525, Val Acc: 0.752577\n",
      "Epoch 10456 - Train Loss: 0.125813, Train Acc: 0.788462 | Val Loss: 0.142518, Val Acc: 0.752577\n",
      "Epoch 10457 - Train Loss: 0.125805, Train Acc: 0.788462 | Val Loss: 0.142511, Val Acc: 0.752577\n",
      "Epoch 10458 - Train Loss: 0.125797, Train Acc: 0.788462 | Val Loss: 0.142505, Val Acc: 0.752577\n",
      "Epoch 10459 - Train Loss: 0.125790, Train Acc: 0.788462 | Val Loss: 0.142498, Val Acc: 0.752577\n",
      "Epoch 10460 - Train Loss: 0.125782, Train Acc: 0.788462 | Val Loss: 0.142492, Val Acc: 0.752577\n",
      "Epoch 10461 - Train Loss: 0.125774, Train Acc: 0.788462 | Val Loss: 0.142485, Val Acc: 0.752577\n",
      "Epoch 10462 - Train Loss: 0.125766, Train Acc: 0.788462 | Val Loss: 0.142478, Val Acc: 0.752577\n",
      "Epoch 10463 - Train Loss: 0.125759, Train Acc: 0.788462 | Val Loss: 0.142472, Val Acc: 0.752577\n",
      "Epoch 10464 - Train Loss: 0.125751, Train Acc: 0.788462 | Val Loss: 0.142465, Val Acc: 0.752577\n",
      "Epoch 10465 - Train Loss: 0.125743, Train Acc: 0.788462 | Val Loss: 0.142459, Val Acc: 0.752577\n",
      "Epoch 10466 - Train Loss: 0.125735, Train Acc: 0.788462 | Val Loss: 0.142452, Val Acc: 0.752577\n",
      "Epoch 10467 - Train Loss: 0.125728, Train Acc: 0.789744 | Val Loss: 0.142446, Val Acc: 0.752577\n",
      "Epoch 10468 - Train Loss: 0.125720, Train Acc: 0.789744 | Val Loss: 0.142439, Val Acc: 0.752577\n",
      "Epoch 10469 - Train Loss: 0.125712, Train Acc: 0.789744 | Val Loss: 0.142432, Val Acc: 0.752577\n",
      "Epoch 10470 - Train Loss: 0.125704, Train Acc: 0.789744 | Val Loss: 0.142426, Val Acc: 0.752577\n",
      "Epoch 10471 - Train Loss: 0.125697, Train Acc: 0.789744 | Val Loss: 0.142419, Val Acc: 0.752577\n",
      "Epoch 10472 - Train Loss: 0.125689, Train Acc: 0.789744 | Val Loss: 0.142413, Val Acc: 0.752577\n",
      "Epoch 10473 - Train Loss: 0.125681, Train Acc: 0.789744 | Val Loss: 0.142406, Val Acc: 0.752577\n",
      "Epoch 10474 - Train Loss: 0.125673, Train Acc: 0.789744 | Val Loss: 0.142399, Val Acc: 0.752577\n",
      "Epoch 10475 - Train Loss: 0.125666, Train Acc: 0.789744 | Val Loss: 0.142393, Val Acc: 0.752577\n",
      "Epoch 10476 - Train Loss: 0.125658, Train Acc: 0.789744 | Val Loss: 0.142386, Val Acc: 0.752577\n",
      "Epoch 10477 - Train Loss: 0.125650, Train Acc: 0.789744 | Val Loss: 0.142380, Val Acc: 0.752577\n",
      "Epoch 10478 - Train Loss: 0.125642, Train Acc: 0.789744 | Val Loss: 0.142373, Val Acc: 0.752577\n",
      "Epoch 10479 - Train Loss: 0.125635, Train Acc: 0.789744 | Val Loss: 0.142367, Val Acc: 0.752577\n",
      "Epoch 10480 - Train Loss: 0.125627, Train Acc: 0.789744 | Val Loss: 0.142360, Val Acc: 0.752577\n",
      "Epoch 10481 - Train Loss: 0.125619, Train Acc: 0.789744 | Val Loss: 0.142353, Val Acc: 0.752577\n",
      "Epoch 10482 - Train Loss: 0.125612, Train Acc: 0.789744 | Val Loss: 0.142347, Val Acc: 0.752577\n",
      "Epoch 10483 - Train Loss: 0.125604, Train Acc: 0.789744 | Val Loss: 0.142340, Val Acc: 0.752577\n",
      "Epoch 10484 - Train Loss: 0.125596, Train Acc: 0.789744 | Val Loss: 0.142334, Val Acc: 0.752577\n",
      "Epoch 10485 - Train Loss: 0.125588, Train Acc: 0.789744 | Val Loss: 0.142327, Val Acc: 0.752577\n",
      "Epoch 10486 - Train Loss: 0.125581, Train Acc: 0.789744 | Val Loss: 0.142321, Val Acc: 0.752577\n",
      "Epoch 10487 - Train Loss: 0.125573, Train Acc: 0.789744 | Val Loss: 0.142314, Val Acc: 0.752577\n",
      "Epoch 10488 - Train Loss: 0.125565, Train Acc: 0.789744 | Val Loss: 0.142308, Val Acc: 0.752577\n",
      "Epoch 10489 - Train Loss: 0.125557, Train Acc: 0.789744 | Val Loss: 0.142301, Val Acc: 0.752577\n",
      "Epoch 10490 - Train Loss: 0.125550, Train Acc: 0.789744 | Val Loss: 0.142294, Val Acc: 0.752577\n",
      "Epoch 10491 - Train Loss: 0.125542, Train Acc: 0.789744 | Val Loss: 0.142288, Val Acc: 0.752577\n",
      "Epoch 10492 - Train Loss: 0.125534, Train Acc: 0.789744 | Val Loss: 0.142281, Val Acc: 0.752577\n",
      "Epoch 10493 - Train Loss: 0.125527, Train Acc: 0.789744 | Val Loss: 0.142275, Val Acc: 0.752577\n",
      "Epoch 10494 - Train Loss: 0.125519, Train Acc: 0.789744 | Val Loss: 0.142268, Val Acc: 0.752577\n",
      "Epoch 10495 - Train Loss: 0.125511, Train Acc: 0.789744 | Val Loss: 0.142262, Val Acc: 0.752577\n",
      "Epoch 10496 - Train Loss: 0.125503, Train Acc: 0.789744 | Val Loss: 0.142255, Val Acc: 0.752577\n",
      "Epoch 10497 - Train Loss: 0.125496, Train Acc: 0.791026 | Val Loss: 0.142249, Val Acc: 0.752577\n",
      "Epoch 10498 - Train Loss: 0.125488, Train Acc: 0.791026 | Val Loss: 0.142242, Val Acc: 0.752577\n",
      "Epoch 10499 - Train Loss: 0.125480, Train Acc: 0.791026 | Val Loss: 0.142235, Val Acc: 0.752577\n",
      "Epoch 10500 - Train Loss: 0.125473, Train Acc: 0.791026 | Val Loss: 0.142229, Val Acc: 0.752577\n",
      "Epoch 10501 - Train Loss: 0.125465, Train Acc: 0.791026 | Val Loss: 0.142222, Val Acc: 0.752577\n",
      "Epoch 10502 - Train Loss: 0.125457, Train Acc: 0.791026 | Val Loss: 0.142216, Val Acc: 0.752577\n",
      "Epoch 10503 - Train Loss: 0.125450, Train Acc: 0.791026 | Val Loss: 0.142209, Val Acc: 0.752577\n",
      "Epoch 10504 - Train Loss: 0.125442, Train Acc: 0.791026 | Val Loss: 0.142203, Val Acc: 0.752577\n",
      "Epoch 10505 - Train Loss: 0.125434, Train Acc: 0.791026 | Val Loss: 0.142196, Val Acc: 0.752577\n",
      "Epoch 10506 - Train Loss: 0.125426, Train Acc: 0.791026 | Val Loss: 0.142190, Val Acc: 0.752577\n",
      "Epoch 10507 - Train Loss: 0.125419, Train Acc: 0.791026 | Val Loss: 0.142183, Val Acc: 0.752577\n",
      "Epoch 10508 - Train Loss: 0.125411, Train Acc: 0.791026 | Val Loss: 0.142177, Val Acc: 0.752577\n",
      "Epoch 10509 - Train Loss: 0.125403, Train Acc: 0.791026 | Val Loss: 0.142170, Val Acc: 0.752577\n",
      "Epoch 10510 - Train Loss: 0.125396, Train Acc: 0.791026 | Val Loss: 0.142164, Val Acc: 0.752577\n",
      "Epoch 10511 - Train Loss: 0.125388, Train Acc: 0.791026 | Val Loss: 0.142157, Val Acc: 0.752577\n",
      "Epoch 10512 - Train Loss: 0.125380, Train Acc: 0.791026 | Val Loss: 0.142151, Val Acc: 0.752577\n",
      "Epoch 10513 - Train Loss: 0.125373, Train Acc: 0.791026 | Val Loss: 0.142144, Val Acc: 0.752577\n",
      "Epoch 10514 - Train Loss: 0.125365, Train Acc: 0.791026 | Val Loss: 0.142138, Val Acc: 0.752577\n",
      "Epoch 10515 - Train Loss: 0.125357, Train Acc: 0.791026 | Val Loss: 0.142131, Val Acc: 0.752577\n",
      "Epoch 10516 - Train Loss: 0.125350, Train Acc: 0.791026 | Val Loss: 0.142124, Val Acc: 0.752577\n",
      "Epoch 10517 - Train Loss: 0.125342, Train Acc: 0.791026 | Val Loss: 0.142118, Val Acc: 0.752577\n",
      "Epoch 10518 - Train Loss: 0.125334, Train Acc: 0.791026 | Val Loss: 0.142111, Val Acc: 0.752577\n",
      "Epoch 10519 - Train Loss: 0.125326, Train Acc: 0.791026 | Val Loss: 0.142105, Val Acc: 0.752577\n",
      "Epoch 10520 - Train Loss: 0.125319, Train Acc: 0.791026 | Val Loss: 0.142098, Val Acc: 0.752577\n",
      "Epoch 10521 - Train Loss: 0.125311, Train Acc: 0.791026 | Val Loss: 0.142092, Val Acc: 0.752577\n",
      "Epoch 10522 - Train Loss: 0.125303, Train Acc: 0.791026 | Val Loss: 0.142085, Val Acc: 0.752577\n",
      "Epoch 10523 - Train Loss: 0.125296, Train Acc: 0.791026 | Val Loss: 0.142079, Val Acc: 0.752577\n",
      "Epoch 10524 - Train Loss: 0.125288, Train Acc: 0.791026 | Val Loss: 0.142072, Val Acc: 0.752577\n",
      "Epoch 10525 - Train Loss: 0.125280, Train Acc: 0.791026 | Val Loss: 0.142066, Val Acc: 0.752577\n",
      "Epoch 10526 - Train Loss: 0.125273, Train Acc: 0.791026 | Val Loss: 0.142059, Val Acc: 0.752577\n",
      "Epoch 10527 - Train Loss: 0.125265, Train Acc: 0.791026 | Val Loss: 0.142053, Val Acc: 0.752577\n",
      "Epoch 10528 - Train Loss: 0.125257, Train Acc: 0.791026 | Val Loss: 0.142046, Val Acc: 0.752577\n",
      "Epoch 10529 - Train Loss: 0.125250, Train Acc: 0.791026 | Val Loss: 0.142040, Val Acc: 0.752577\n",
      "Epoch 10530 - Train Loss: 0.125242, Train Acc: 0.791026 | Val Loss: 0.142033, Val Acc: 0.752577\n",
      "Epoch 10531 - Train Loss: 0.125234, Train Acc: 0.791026 | Val Loss: 0.142027, Val Acc: 0.752577\n",
      "Epoch 10532 - Train Loss: 0.125227, Train Acc: 0.791026 | Val Loss: 0.142020, Val Acc: 0.752577\n",
      "Epoch 10533 - Train Loss: 0.125219, Train Acc: 0.791026 | Val Loss: 0.142014, Val Acc: 0.752577\n",
      "Epoch 10534 - Train Loss: 0.125211, Train Acc: 0.791026 | Val Loss: 0.142007, Val Acc: 0.752577\n",
      "Epoch 10535 - Train Loss: 0.125204, Train Acc: 0.791026 | Val Loss: 0.142001, Val Acc: 0.752577\n",
      "Epoch 10536 - Train Loss: 0.125196, Train Acc: 0.791026 | Val Loss: 0.141994, Val Acc: 0.752577\n",
      "Epoch 10537 - Train Loss: 0.125188, Train Acc: 0.792308 | Val Loss: 0.141988, Val Acc: 0.752577\n",
      "Epoch 10538 - Train Loss: 0.125181, Train Acc: 0.792308 | Val Loss: 0.141981, Val Acc: 0.752577\n",
      "Epoch 10539 - Train Loss: 0.125173, Train Acc: 0.792308 | Val Loss: 0.141975, Val Acc: 0.752577\n",
      "Epoch 10540 - Train Loss: 0.125165, Train Acc: 0.792308 | Val Loss: 0.141968, Val Acc: 0.752577\n",
      "Epoch 10541 - Train Loss: 0.125158, Train Acc: 0.792308 | Val Loss: 0.141962, Val Acc: 0.752577\n",
      "Epoch 10542 - Train Loss: 0.125150, Train Acc: 0.792308 | Val Loss: 0.141955, Val Acc: 0.752577\n",
      "Epoch 10543 - Train Loss: 0.125143, Train Acc: 0.792308 | Val Loss: 0.141949, Val Acc: 0.752577\n",
      "Epoch 10544 - Train Loss: 0.125135, Train Acc: 0.792308 | Val Loss: 0.141942, Val Acc: 0.752577\n",
      "Epoch 10545 - Train Loss: 0.125127, Train Acc: 0.792308 | Val Loss: 0.141936, Val Acc: 0.752577\n",
      "Epoch 10546 - Train Loss: 0.125120, Train Acc: 0.792308 | Val Loss: 0.141930, Val Acc: 0.752577\n",
      "Epoch 10547 - Train Loss: 0.125112, Train Acc: 0.792308 | Val Loss: 0.141923, Val Acc: 0.752577\n",
      "Epoch 10548 - Train Loss: 0.125104, Train Acc: 0.792308 | Val Loss: 0.141917, Val Acc: 0.752577\n",
      "Epoch 10549 - Train Loss: 0.125097, Train Acc: 0.792308 | Val Loss: 0.141910, Val Acc: 0.752577\n",
      "Epoch 10550 - Train Loss: 0.125089, Train Acc: 0.792308 | Val Loss: 0.141904, Val Acc: 0.752577\n",
      "Epoch 10551 - Train Loss: 0.125081, Train Acc: 0.792308 | Val Loss: 0.141897, Val Acc: 0.752577\n",
      "Epoch 10552 - Train Loss: 0.125074, Train Acc: 0.792308 | Val Loss: 0.141891, Val Acc: 0.752577\n",
      "Epoch 10553 - Train Loss: 0.125066, Train Acc: 0.792308 | Val Loss: 0.141884, Val Acc: 0.752577\n",
      "Epoch 10554 - Train Loss: 0.125058, Train Acc: 0.792308 | Val Loss: 0.141878, Val Acc: 0.752577\n",
      "Epoch 10555 - Train Loss: 0.125051, Train Acc: 0.792308 | Val Loss: 0.141871, Val Acc: 0.752577\n",
      "Epoch 10556 - Train Loss: 0.125043, Train Acc: 0.792308 | Val Loss: 0.141865, Val Acc: 0.752577\n",
      "Epoch 10557 - Train Loss: 0.125036, Train Acc: 0.793590 | Val Loss: 0.141858, Val Acc: 0.752577\n",
      "Epoch 10558 - Train Loss: 0.125028, Train Acc: 0.793590 | Val Loss: 0.141852, Val Acc: 0.752577\n",
      "Epoch 10559 - Train Loss: 0.125020, Train Acc: 0.793590 | Val Loss: 0.141845, Val Acc: 0.752577\n",
      "Epoch 10560 - Train Loss: 0.125013, Train Acc: 0.793590 | Val Loss: 0.141839, Val Acc: 0.752577\n",
      "Epoch 10561 - Train Loss: 0.125005, Train Acc: 0.793590 | Val Loss: 0.141833, Val Acc: 0.752577\n",
      "Epoch 10562 - Train Loss: 0.124997, Train Acc: 0.793590 | Val Loss: 0.141826, Val Acc: 0.752577\n",
      "Epoch 10563 - Train Loss: 0.124990, Train Acc: 0.793590 | Val Loss: 0.141820, Val Acc: 0.752577\n",
      "Epoch 10564 - Train Loss: 0.124982, Train Acc: 0.793590 | Val Loss: 0.141813, Val Acc: 0.752577\n",
      "Epoch 10565 - Train Loss: 0.124975, Train Acc: 0.793590 | Val Loss: 0.141807, Val Acc: 0.752577\n",
      "Epoch 10566 - Train Loss: 0.124967, Train Acc: 0.793590 | Val Loss: 0.141800, Val Acc: 0.752577\n",
      "Epoch 10567 - Train Loss: 0.124959, Train Acc: 0.793590 | Val Loss: 0.141794, Val Acc: 0.752577\n",
      "Epoch 10568 - Train Loss: 0.124952, Train Acc: 0.793590 | Val Loss: 0.141787, Val Acc: 0.752577\n",
      "Epoch 10569 - Train Loss: 0.124944, Train Acc: 0.793590 | Val Loss: 0.141781, Val Acc: 0.752577\n",
      "Epoch 10570 - Train Loss: 0.124936, Train Acc: 0.793590 | Val Loss: 0.141774, Val Acc: 0.752577\n",
      "Epoch 10571 - Train Loss: 0.124929, Train Acc: 0.793590 | Val Loss: 0.141768, Val Acc: 0.752577\n",
      "Epoch 10572 - Train Loss: 0.124921, Train Acc: 0.793590 | Val Loss: 0.141762, Val Acc: 0.752577\n",
      "Epoch 10573 - Train Loss: 0.124914, Train Acc: 0.793590 | Val Loss: 0.141755, Val Acc: 0.752577\n",
      "Epoch 10574 - Train Loss: 0.124906, Train Acc: 0.793590 | Val Loss: 0.141749, Val Acc: 0.752577\n",
      "Epoch 10575 - Train Loss: 0.124898, Train Acc: 0.793590 | Val Loss: 0.141742, Val Acc: 0.752577\n",
      "Epoch 10576 - Train Loss: 0.124891, Train Acc: 0.793590 | Val Loss: 0.141736, Val Acc: 0.752577\n",
      "Epoch 10577 - Train Loss: 0.124883, Train Acc: 0.793590 | Val Loss: 0.141730, Val Acc: 0.752577\n",
      "Epoch 10578 - Train Loss: 0.124876, Train Acc: 0.793590 | Val Loss: 0.141723, Val Acc: 0.752577\n",
      "Epoch 10579 - Train Loss: 0.124868, Train Acc: 0.793590 | Val Loss: 0.141717, Val Acc: 0.752577\n",
      "Epoch 10580 - Train Loss: 0.124860, Train Acc: 0.793590 | Val Loss: 0.141710, Val Acc: 0.752577\n",
      "Epoch 10581 - Train Loss: 0.124853, Train Acc: 0.793590 | Val Loss: 0.141704, Val Acc: 0.752577\n",
      "Epoch 10582 - Train Loss: 0.124845, Train Acc: 0.793590 | Val Loss: 0.141697, Val Acc: 0.752577\n",
      "Epoch 10583 - Train Loss: 0.124838, Train Acc: 0.793590 | Val Loss: 0.141691, Val Acc: 0.752577\n",
      "Epoch 10584 - Train Loss: 0.124830, Train Acc: 0.793590 | Val Loss: 0.141685, Val Acc: 0.752577\n",
      "Epoch 10585 - Train Loss: 0.124822, Train Acc: 0.793590 | Val Loss: 0.141678, Val Acc: 0.752577\n",
      "Epoch 10586 - Train Loss: 0.124815, Train Acc: 0.793590 | Val Loss: 0.141672, Val Acc: 0.752577\n",
      "Epoch 10587 - Train Loss: 0.124807, Train Acc: 0.793590 | Val Loss: 0.141665, Val Acc: 0.752577\n",
      "Epoch 10588 - Train Loss: 0.124800, Train Acc: 0.793590 | Val Loss: 0.141659, Val Acc: 0.752577\n",
      "Epoch 10589 - Train Loss: 0.124792, Train Acc: 0.793590 | Val Loss: 0.141653, Val Acc: 0.752577\n",
      "Epoch 10590 - Train Loss: 0.124784, Train Acc: 0.793590 | Val Loss: 0.141646, Val Acc: 0.752577\n",
      "Epoch 10591 - Train Loss: 0.124777, Train Acc: 0.793590 | Val Loss: 0.141640, Val Acc: 0.752577\n",
      "Epoch 10592 - Train Loss: 0.124769, Train Acc: 0.793590 | Val Loss: 0.141633, Val Acc: 0.752577\n",
      "Epoch 10593 - Train Loss: 0.124762, Train Acc: 0.793590 | Val Loss: 0.141627, Val Acc: 0.752577\n",
      "Epoch 10594 - Train Loss: 0.124754, Train Acc: 0.793590 | Val Loss: 0.141621, Val Acc: 0.752577\n",
      "Epoch 10595 - Train Loss: 0.124747, Train Acc: 0.793590 | Val Loss: 0.141614, Val Acc: 0.752577\n",
      "Epoch 10596 - Train Loss: 0.124739, Train Acc: 0.793590 | Val Loss: 0.141608, Val Acc: 0.752577\n",
      "Epoch 10597 - Train Loss: 0.124731, Train Acc: 0.793590 | Val Loss: 0.141601, Val Acc: 0.752577\n",
      "Epoch 10598 - Train Loss: 0.124724, Train Acc: 0.793590 | Val Loss: 0.141595, Val Acc: 0.752577\n",
      "Epoch 10599 - Train Loss: 0.124716, Train Acc: 0.793590 | Val Loss: 0.141589, Val Acc: 0.752577\n",
      "Epoch 10600 - Train Loss: 0.124709, Train Acc: 0.793590 | Val Loss: 0.141582, Val Acc: 0.752577\n",
      "Epoch 10601 - Train Loss: 0.124701, Train Acc: 0.793590 | Val Loss: 0.141576, Val Acc: 0.752577\n",
      "Epoch 10602 - Train Loss: 0.124693, Train Acc: 0.793590 | Val Loss: 0.141569, Val Acc: 0.752577\n",
      "Epoch 10603 - Train Loss: 0.124686, Train Acc: 0.793590 | Val Loss: 0.141563, Val Acc: 0.752577\n",
      "Epoch 10604 - Train Loss: 0.124678, Train Acc: 0.793590 | Val Loss: 0.141557, Val Acc: 0.752577\n",
      "Epoch 10605 - Train Loss: 0.124671, Train Acc: 0.793590 | Val Loss: 0.141550, Val Acc: 0.752577\n",
      "Epoch 10606 - Train Loss: 0.124663, Train Acc: 0.793590 | Val Loss: 0.141544, Val Acc: 0.752577\n",
      "Epoch 10607 - Train Loss: 0.124656, Train Acc: 0.793590 | Val Loss: 0.141538, Val Acc: 0.752577\n",
      "Epoch 10608 - Train Loss: 0.124648, Train Acc: 0.793590 | Val Loss: 0.141531, Val Acc: 0.752577\n",
      "Epoch 10609 - Train Loss: 0.124641, Train Acc: 0.793590 | Val Loss: 0.141525, Val Acc: 0.752577\n",
      "Epoch 10610 - Train Loss: 0.124633, Train Acc: 0.793590 | Val Loss: 0.141518, Val Acc: 0.752577\n",
      "Epoch 10611 - Train Loss: 0.124625, Train Acc: 0.793590 | Val Loss: 0.141512, Val Acc: 0.752577\n",
      "Epoch 10612 - Train Loss: 0.124618, Train Acc: 0.793590 | Val Loss: 0.141506, Val Acc: 0.752577\n",
      "Epoch 10613 - Train Loss: 0.124610, Train Acc: 0.793590 | Val Loss: 0.141499, Val Acc: 0.752577\n",
      "Epoch 10614 - Train Loss: 0.124603, Train Acc: 0.793590 | Val Loss: 0.141493, Val Acc: 0.752577\n",
      "Epoch 10615 - Train Loss: 0.124595, Train Acc: 0.793590 | Val Loss: 0.141486, Val Acc: 0.752577\n",
      "Epoch 10616 - Train Loss: 0.124588, Train Acc: 0.793590 | Val Loss: 0.141480, Val Acc: 0.752577\n",
      "Epoch 10617 - Train Loss: 0.124580, Train Acc: 0.793590 | Val Loss: 0.141474, Val Acc: 0.752577\n",
      "Epoch 10618 - Train Loss: 0.124572, Train Acc: 0.793590 | Val Loss: 0.141467, Val Acc: 0.752577\n",
      "Epoch 10619 - Train Loss: 0.124565, Train Acc: 0.793590 | Val Loss: 0.141461, Val Acc: 0.752577\n",
      "Epoch 10620 - Train Loss: 0.124557, Train Acc: 0.793590 | Val Loss: 0.141455, Val Acc: 0.752577\n",
      "Epoch 10621 - Train Loss: 0.124550, Train Acc: 0.793590 | Val Loss: 0.141448, Val Acc: 0.752577\n",
      "Epoch 10622 - Train Loss: 0.124542, Train Acc: 0.793590 | Val Loss: 0.141442, Val Acc: 0.752577\n",
      "Epoch 10623 - Train Loss: 0.124535, Train Acc: 0.793590 | Val Loss: 0.141436, Val Acc: 0.752577\n",
      "Epoch 10624 - Train Loss: 0.124527, Train Acc: 0.793590 | Val Loss: 0.141429, Val Acc: 0.752577\n",
      "Epoch 10625 - Train Loss: 0.124520, Train Acc: 0.793590 | Val Loss: 0.141423, Val Acc: 0.752577\n",
      "Epoch 10626 - Train Loss: 0.124512, Train Acc: 0.793590 | Val Loss: 0.141416, Val Acc: 0.752577\n",
      "Epoch 10627 - Train Loss: 0.124505, Train Acc: 0.793590 | Val Loss: 0.141410, Val Acc: 0.752577\n",
      "Epoch 10628 - Train Loss: 0.124497, Train Acc: 0.793590 | Val Loss: 0.141404, Val Acc: 0.752577\n",
      "Epoch 10629 - Train Loss: 0.124490, Train Acc: 0.793590 | Val Loss: 0.141397, Val Acc: 0.752577\n",
      "Epoch 10630 - Train Loss: 0.124482, Train Acc: 0.793590 | Val Loss: 0.141391, Val Acc: 0.752577\n",
      "Epoch 10631 - Train Loss: 0.124474, Train Acc: 0.793590 | Val Loss: 0.141385, Val Acc: 0.752577\n",
      "Epoch 10632 - Train Loss: 0.124467, Train Acc: 0.793590 | Val Loss: 0.141378, Val Acc: 0.752577\n",
      "Epoch 10633 - Train Loss: 0.124459, Train Acc: 0.793590 | Val Loss: 0.141372, Val Acc: 0.752577\n",
      "Epoch 10634 - Train Loss: 0.124452, Train Acc: 0.793590 | Val Loss: 0.141366, Val Acc: 0.752577\n",
      "Epoch 10635 - Train Loss: 0.124444, Train Acc: 0.793590 | Val Loss: 0.141359, Val Acc: 0.752577\n",
      "Epoch 10636 - Train Loss: 0.124437, Train Acc: 0.793590 | Val Loss: 0.141353, Val Acc: 0.752577\n",
      "Epoch 10637 - Train Loss: 0.124429, Train Acc: 0.793590 | Val Loss: 0.141347, Val Acc: 0.752577\n",
      "Epoch 10638 - Train Loss: 0.124422, Train Acc: 0.793590 | Val Loss: 0.141340, Val Acc: 0.752577\n",
      "Epoch 10639 - Train Loss: 0.124414, Train Acc: 0.793590 | Val Loss: 0.141334, Val Acc: 0.752577\n",
      "Epoch 10640 - Train Loss: 0.124407, Train Acc: 0.793590 | Val Loss: 0.141327, Val Acc: 0.752577\n",
      "Epoch 10641 - Train Loss: 0.124399, Train Acc: 0.793590 | Val Loss: 0.141321, Val Acc: 0.752577\n",
      "Epoch 10642 - Train Loss: 0.124392, Train Acc: 0.793590 | Val Loss: 0.141315, Val Acc: 0.752577\n",
      "Epoch 10643 - Train Loss: 0.124384, Train Acc: 0.793590 | Val Loss: 0.141308, Val Acc: 0.752577\n",
      "Epoch 10644 - Train Loss: 0.124377, Train Acc: 0.793590 | Val Loss: 0.141302, Val Acc: 0.752577\n",
      "Epoch 10645 - Train Loss: 0.124369, Train Acc: 0.793590 | Val Loss: 0.141296, Val Acc: 0.752577\n",
      "Epoch 10646 - Train Loss: 0.124362, Train Acc: 0.793590 | Val Loss: 0.141289, Val Acc: 0.752577\n",
      "Epoch 10647 - Train Loss: 0.124354, Train Acc: 0.793590 | Val Loss: 0.141283, Val Acc: 0.752577\n",
      "Epoch 10648 - Train Loss: 0.124347, Train Acc: 0.793590 | Val Loss: 0.141277, Val Acc: 0.752577\n",
      "Epoch 10649 - Train Loss: 0.124339, Train Acc: 0.793590 | Val Loss: 0.141270, Val Acc: 0.752577\n",
      "Epoch 10650 - Train Loss: 0.124332, Train Acc: 0.793590 | Val Loss: 0.141264, Val Acc: 0.752577\n",
      "Epoch 10651 - Train Loss: 0.124324, Train Acc: 0.794872 | Val Loss: 0.141258, Val Acc: 0.752577\n",
      "Epoch 10652 - Train Loss: 0.124316, Train Acc: 0.794872 | Val Loss: 0.141251, Val Acc: 0.752577\n",
      "Epoch 10653 - Train Loss: 0.124309, Train Acc: 0.794872 | Val Loss: 0.141245, Val Acc: 0.752577\n",
      "Epoch 10654 - Train Loss: 0.124301, Train Acc: 0.794872 | Val Loss: 0.141239, Val Acc: 0.752577\n",
      "Epoch 10655 - Train Loss: 0.124294, Train Acc: 0.794872 | Val Loss: 0.141232, Val Acc: 0.752577\n",
      "Epoch 10656 - Train Loss: 0.124286, Train Acc: 0.794872 | Val Loss: 0.141226, Val Acc: 0.752577\n",
      "Epoch 10657 - Train Loss: 0.124279, Train Acc: 0.794872 | Val Loss: 0.141220, Val Acc: 0.752577\n",
      "Epoch 10658 - Train Loss: 0.124271, Train Acc: 0.794872 | Val Loss: 0.141213, Val Acc: 0.752577\n",
      "Epoch 10659 - Train Loss: 0.124264, Train Acc: 0.794872 | Val Loss: 0.141207, Val Acc: 0.752577\n",
      "Epoch 10660 - Train Loss: 0.124256, Train Acc: 0.794872 | Val Loss: 0.141201, Val Acc: 0.752577\n",
      "Epoch 10661 - Train Loss: 0.124249, Train Acc: 0.794872 | Val Loss: 0.141194, Val Acc: 0.752577\n",
      "Epoch 10662 - Train Loss: 0.124241, Train Acc: 0.794872 | Val Loss: 0.141188, Val Acc: 0.752577\n",
      "Epoch 10663 - Train Loss: 0.124234, Train Acc: 0.794872 | Val Loss: 0.141182, Val Acc: 0.752577\n",
      "Epoch 10664 - Train Loss: 0.124226, Train Acc: 0.794872 | Val Loss: 0.141176, Val Acc: 0.752577\n",
      "Epoch 10665 - Train Loss: 0.124219, Train Acc: 0.794872 | Val Loss: 0.141169, Val Acc: 0.752577\n",
      "Epoch 10666 - Train Loss: 0.124211, Train Acc: 0.794872 | Val Loss: 0.141163, Val Acc: 0.752577\n",
      "Epoch 10667 - Train Loss: 0.124204, Train Acc: 0.794872 | Val Loss: 0.141157, Val Acc: 0.752577\n",
      "Epoch 10668 - Train Loss: 0.124197, Train Acc: 0.794872 | Val Loss: 0.141150, Val Acc: 0.752577\n",
      "Epoch 10669 - Train Loss: 0.124189, Train Acc: 0.794872 | Val Loss: 0.141144, Val Acc: 0.752577\n",
      "Epoch 10670 - Train Loss: 0.124182, Train Acc: 0.794872 | Val Loss: 0.141138, Val Acc: 0.752577\n",
      "Epoch 10671 - Train Loss: 0.124174, Train Acc: 0.794872 | Val Loss: 0.141131, Val Acc: 0.752577\n",
      "Epoch 10672 - Train Loss: 0.124167, Train Acc: 0.794872 | Val Loss: 0.141125, Val Acc: 0.752577\n",
      "Epoch 10673 - Train Loss: 0.124159, Train Acc: 0.794872 | Val Loss: 0.141119, Val Acc: 0.752577\n",
      "Epoch 10674 - Train Loss: 0.124152, Train Acc: 0.794872 | Val Loss: 0.141112, Val Acc: 0.752577\n",
      "Epoch 10675 - Train Loss: 0.124144, Train Acc: 0.794872 | Val Loss: 0.141106, Val Acc: 0.752577\n",
      "Epoch 10676 - Train Loss: 0.124137, Train Acc: 0.794872 | Val Loss: 0.141100, Val Acc: 0.752577\n",
      "Epoch 10677 - Train Loss: 0.124129, Train Acc: 0.794872 | Val Loss: 0.141094, Val Acc: 0.752577\n",
      "Epoch 10678 - Train Loss: 0.124122, Train Acc: 0.794872 | Val Loss: 0.141087, Val Acc: 0.752577\n",
      "Epoch 10679 - Train Loss: 0.124114, Train Acc: 0.794872 | Val Loss: 0.141081, Val Acc: 0.752577\n",
      "Epoch 10680 - Train Loss: 0.124107, Train Acc: 0.794872 | Val Loss: 0.141075, Val Acc: 0.752577\n",
      "Epoch 10681 - Train Loss: 0.124099, Train Acc: 0.794872 | Val Loss: 0.141068, Val Acc: 0.752577\n",
      "Epoch 10682 - Train Loss: 0.124092, Train Acc: 0.794872 | Val Loss: 0.141062, Val Acc: 0.752577\n",
      "Epoch 10683 - Train Loss: 0.124084, Train Acc: 0.794872 | Val Loss: 0.141056, Val Acc: 0.752577\n",
      "Epoch 10684 - Train Loss: 0.124077, Train Acc: 0.794872 | Val Loss: 0.141049, Val Acc: 0.752577\n",
      "Epoch 10685 - Train Loss: 0.124069, Train Acc: 0.794872 | Val Loss: 0.141043, Val Acc: 0.752577\n",
      "Epoch 10686 - Train Loss: 0.124062, Train Acc: 0.794872 | Val Loss: 0.141037, Val Acc: 0.752577\n",
      "Epoch 10687 - Train Loss: 0.124054, Train Acc: 0.794872 | Val Loss: 0.141031, Val Acc: 0.752577\n",
      "Epoch 10688 - Train Loss: 0.124047, Train Acc: 0.794872 | Val Loss: 0.141024, Val Acc: 0.752577\n",
      "Epoch 10689 - Train Loss: 0.124040, Train Acc: 0.794872 | Val Loss: 0.141018, Val Acc: 0.752577\n",
      "Epoch 10690 - Train Loss: 0.124032, Train Acc: 0.794872 | Val Loss: 0.141012, Val Acc: 0.752577\n",
      "Epoch 10691 - Train Loss: 0.124025, Train Acc: 0.794872 | Val Loss: 0.141005, Val Acc: 0.752577\n",
      "Epoch 10692 - Train Loss: 0.124017, Train Acc: 0.794872 | Val Loss: 0.140999, Val Acc: 0.752577\n",
      "Epoch 10693 - Train Loss: 0.124010, Train Acc: 0.794872 | Val Loss: 0.140993, Val Acc: 0.752577\n",
      "Epoch 10694 - Train Loss: 0.124002, Train Acc: 0.794872 | Val Loss: 0.140987, Val Acc: 0.752577\n",
      "Epoch 10695 - Train Loss: 0.123995, Train Acc: 0.794872 | Val Loss: 0.140980, Val Acc: 0.752577\n",
      "Epoch 10696 - Train Loss: 0.123987, Train Acc: 0.794872 | Val Loss: 0.140974, Val Acc: 0.752577\n",
      "Epoch 10697 - Train Loss: 0.123980, Train Acc: 0.794872 | Val Loss: 0.140968, Val Acc: 0.752577\n",
      "Epoch 10698 - Train Loss: 0.123972, Train Acc: 0.794872 | Val Loss: 0.140962, Val Acc: 0.752577\n",
      "Epoch 10699 - Train Loss: 0.123965, Train Acc: 0.794872 | Val Loss: 0.140955, Val Acc: 0.752577\n",
      "Epoch 10700 - Train Loss: 0.123958, Train Acc: 0.794872 | Val Loss: 0.140949, Val Acc: 0.752577\n",
      "Epoch 10701 - Train Loss: 0.123950, Train Acc: 0.794872 | Val Loss: 0.140943, Val Acc: 0.752577\n",
      "Epoch 10702 - Train Loss: 0.123943, Train Acc: 0.794872 | Val Loss: 0.140936, Val Acc: 0.752577\n",
      "Epoch 10703 - Train Loss: 0.123935, Train Acc: 0.794872 | Val Loss: 0.140930, Val Acc: 0.752577\n",
      "Epoch 10704 - Train Loss: 0.123928, Train Acc: 0.794872 | Val Loss: 0.140924, Val Acc: 0.752577\n",
      "Epoch 10705 - Train Loss: 0.123920, Train Acc: 0.794872 | Val Loss: 0.140918, Val Acc: 0.752577\n",
      "Epoch 10706 - Train Loss: 0.123913, Train Acc: 0.794872 | Val Loss: 0.140911, Val Acc: 0.752577\n",
      "Epoch 10707 - Train Loss: 0.123905, Train Acc: 0.794872 | Val Loss: 0.140905, Val Acc: 0.752577\n",
      "Epoch 10708 - Train Loss: 0.123898, Train Acc: 0.794872 | Val Loss: 0.140899, Val Acc: 0.752577\n",
      "Epoch 10709 - Train Loss: 0.123891, Train Acc: 0.794872 | Val Loss: 0.140893, Val Acc: 0.752577\n",
      "Epoch 10710 - Train Loss: 0.123883, Train Acc: 0.794872 | Val Loss: 0.140886, Val Acc: 0.752577\n",
      "Epoch 10711 - Train Loss: 0.123876, Train Acc: 0.794872 | Val Loss: 0.140880, Val Acc: 0.752577\n",
      "Epoch 10712 - Train Loss: 0.123868, Train Acc: 0.794872 | Val Loss: 0.140874, Val Acc: 0.752577\n",
      "Epoch 10713 - Train Loss: 0.123861, Train Acc: 0.794872 | Val Loss: 0.140868, Val Acc: 0.752577\n",
      "Epoch 10714 - Train Loss: 0.123853, Train Acc: 0.794872 | Val Loss: 0.140861, Val Acc: 0.752577\n",
      "Epoch 10715 - Train Loss: 0.123846, Train Acc: 0.794872 | Val Loss: 0.140855, Val Acc: 0.752577\n",
      "Epoch 10716 - Train Loss: 0.123839, Train Acc: 0.794872 | Val Loss: 0.140849, Val Acc: 0.752577\n",
      "Epoch 10717 - Train Loss: 0.123831, Train Acc: 0.794872 | Val Loss: 0.140843, Val Acc: 0.752577\n",
      "Epoch 10718 - Train Loss: 0.123824, Train Acc: 0.794872 | Val Loss: 0.140836, Val Acc: 0.752577\n",
      "Epoch 10719 - Train Loss: 0.123816, Train Acc: 0.794872 | Val Loss: 0.140830, Val Acc: 0.752577\n",
      "Epoch 10720 - Train Loss: 0.123809, Train Acc: 0.794872 | Val Loss: 0.140824, Val Acc: 0.752577\n",
      "Epoch 10721 - Train Loss: 0.123801, Train Acc: 0.794872 | Val Loss: 0.140818, Val Acc: 0.752577\n",
      "Epoch 10722 - Train Loss: 0.123794, Train Acc: 0.794872 | Val Loss: 0.140811, Val Acc: 0.752577\n",
      "Epoch 10723 - Train Loss: 0.123787, Train Acc: 0.794872 | Val Loss: 0.140805, Val Acc: 0.752577\n",
      "Epoch 10724 - Train Loss: 0.123779, Train Acc: 0.794872 | Val Loss: 0.140799, Val Acc: 0.752577\n",
      "Epoch 10725 - Train Loss: 0.123772, Train Acc: 0.794872 | Val Loss: 0.140793, Val Acc: 0.752577\n",
      "Epoch 10726 - Train Loss: 0.123764, Train Acc: 0.794872 | Val Loss: 0.140786, Val Acc: 0.752577\n",
      "Epoch 10727 - Train Loss: 0.123757, Train Acc: 0.794872 | Val Loss: 0.140780, Val Acc: 0.752577\n",
      "Epoch 10728 - Train Loss: 0.123750, Train Acc: 0.794872 | Val Loss: 0.140774, Val Acc: 0.752577\n",
      "Epoch 10729 - Train Loss: 0.123742, Train Acc: 0.794872 | Val Loss: 0.140768, Val Acc: 0.752577\n",
      "Epoch 10730 - Train Loss: 0.123735, Train Acc: 0.794872 | Val Loss: 0.140761, Val Acc: 0.752577\n",
      "Epoch 10731 - Train Loss: 0.123727, Train Acc: 0.794872 | Val Loss: 0.140755, Val Acc: 0.752577\n",
      "Epoch 10732 - Train Loss: 0.123720, Train Acc: 0.794872 | Val Loss: 0.140749, Val Acc: 0.752577\n",
      "Epoch 10733 - Train Loss: 0.123713, Train Acc: 0.794872 | Val Loss: 0.140743, Val Acc: 0.752577\n",
      "Epoch 10734 - Train Loss: 0.123705, Train Acc: 0.794872 | Val Loss: 0.140736, Val Acc: 0.752577\n",
      "Epoch 10735 - Train Loss: 0.123698, Train Acc: 0.794872 | Val Loss: 0.140730, Val Acc: 0.752577\n",
      "Epoch 10736 - Train Loss: 0.123690, Train Acc: 0.794872 | Val Loss: 0.140724, Val Acc: 0.752577\n",
      "Epoch 10737 - Train Loss: 0.123683, Train Acc: 0.794872 | Val Loss: 0.140718, Val Acc: 0.752577\n",
      "Epoch 10738 - Train Loss: 0.123676, Train Acc: 0.794872 | Val Loss: 0.140712, Val Acc: 0.752577\n",
      "Epoch 10739 - Train Loss: 0.123668, Train Acc: 0.794872 | Val Loss: 0.140705, Val Acc: 0.752577\n",
      "Epoch 10740 - Train Loss: 0.123661, Train Acc: 0.794872 | Val Loss: 0.140699, Val Acc: 0.752577\n",
      "Epoch 10741 - Train Loss: 0.123653, Train Acc: 0.794872 | Val Loss: 0.140693, Val Acc: 0.752577\n",
      "Epoch 10742 - Train Loss: 0.123646, Train Acc: 0.794872 | Val Loss: 0.140687, Val Acc: 0.752577\n",
      "Epoch 10743 - Train Loss: 0.123639, Train Acc: 0.794872 | Val Loss: 0.140680, Val Acc: 0.752577\n",
      "Epoch 10744 - Train Loss: 0.123631, Train Acc: 0.794872 | Val Loss: 0.140674, Val Acc: 0.752577\n",
      "Epoch 10745 - Train Loss: 0.123624, Train Acc: 0.794872 | Val Loss: 0.140668, Val Acc: 0.752577\n",
      "Epoch 10746 - Train Loss: 0.123616, Train Acc: 0.794872 | Val Loss: 0.140662, Val Acc: 0.752577\n",
      "Epoch 10747 - Train Loss: 0.123609, Train Acc: 0.794872 | Val Loss: 0.140656, Val Acc: 0.752577\n",
      "Epoch 10748 - Train Loss: 0.123602, Train Acc: 0.794872 | Val Loss: 0.140649, Val Acc: 0.752577\n",
      "Epoch 10749 - Train Loss: 0.123594, Train Acc: 0.794872 | Val Loss: 0.140643, Val Acc: 0.752577\n",
      "Epoch 10750 - Train Loss: 0.123587, Train Acc: 0.794872 | Val Loss: 0.140637, Val Acc: 0.752577\n",
      "Epoch 10751 - Train Loss: 0.123579, Train Acc: 0.794872 | Val Loss: 0.140631, Val Acc: 0.752577\n",
      "Epoch 10752 - Train Loss: 0.123572, Train Acc: 0.794872 | Val Loss: 0.140625, Val Acc: 0.752577\n",
      "Epoch 10753 - Train Loss: 0.123565, Train Acc: 0.794872 | Val Loss: 0.140618, Val Acc: 0.752577\n",
      "Epoch 10754 - Train Loss: 0.123557, Train Acc: 0.794872 | Val Loss: 0.140612, Val Acc: 0.752577\n",
      "Epoch 10755 - Train Loss: 0.123550, Train Acc: 0.794872 | Val Loss: 0.140606, Val Acc: 0.752577\n",
      "Epoch 10756 - Train Loss: 0.123543, Train Acc: 0.794872 | Val Loss: 0.140600, Val Acc: 0.752577\n",
      "Epoch 10757 - Train Loss: 0.123535, Train Acc: 0.794872 | Val Loss: 0.140594, Val Acc: 0.752577\n",
      "Epoch 10758 - Train Loss: 0.123528, Train Acc: 0.794872 | Val Loss: 0.140587, Val Acc: 0.752577\n",
      "Epoch 10759 - Train Loss: 0.123520, Train Acc: 0.794872 | Val Loss: 0.140581, Val Acc: 0.752577\n",
      "Epoch 10760 - Train Loss: 0.123513, Train Acc: 0.794872 | Val Loss: 0.140575, Val Acc: 0.752577\n",
      "Epoch 10761 - Train Loss: 0.123506, Train Acc: 0.794872 | Val Loss: 0.140569, Val Acc: 0.752577\n",
      "Epoch 10762 - Train Loss: 0.123498, Train Acc: 0.794872 | Val Loss: 0.140563, Val Acc: 0.752577\n",
      "Epoch 10763 - Train Loss: 0.123491, Train Acc: 0.794872 | Val Loss: 0.140556, Val Acc: 0.752577\n",
      "Epoch 10764 - Train Loss: 0.123484, Train Acc: 0.794872 | Val Loss: 0.140550, Val Acc: 0.762887\n",
      "Epoch 10765 - Train Loss: 0.123476, Train Acc: 0.794872 | Val Loss: 0.140544, Val Acc: 0.762887\n",
      "Epoch 10766 - Train Loss: 0.123469, Train Acc: 0.794872 | Val Loss: 0.140538, Val Acc: 0.762887\n",
      "Epoch 10767 - Train Loss: 0.123461, Train Acc: 0.794872 | Val Loss: 0.140532, Val Acc: 0.762887\n",
      "Epoch 10768 - Train Loss: 0.123454, Train Acc: 0.794872 | Val Loss: 0.140525, Val Acc: 0.762887\n",
      "Epoch 10769 - Train Loss: 0.123447, Train Acc: 0.794872 | Val Loss: 0.140519, Val Acc: 0.762887\n",
      "Epoch 10770 - Train Loss: 0.123439, Train Acc: 0.794872 | Val Loss: 0.140513, Val Acc: 0.762887\n",
      "Epoch 10771 - Train Loss: 0.123432, Train Acc: 0.794872 | Val Loss: 0.140507, Val Acc: 0.762887\n",
      "Epoch 10772 - Train Loss: 0.123425, Train Acc: 0.794872 | Val Loss: 0.140501, Val Acc: 0.762887\n",
      "Epoch 10773 - Train Loss: 0.123417, Train Acc: 0.794872 | Val Loss: 0.140495, Val Acc: 0.762887\n",
      "Epoch 10774 - Train Loss: 0.123410, Train Acc: 0.794872 | Val Loss: 0.140488, Val Acc: 0.762887\n",
      "Epoch 10775 - Train Loss: 0.123403, Train Acc: 0.794872 | Val Loss: 0.140482, Val Acc: 0.762887\n",
      "Epoch 10776 - Train Loss: 0.123395, Train Acc: 0.794872 | Val Loss: 0.140476, Val Acc: 0.762887\n",
      "Epoch 10777 - Train Loss: 0.123388, Train Acc: 0.794872 | Val Loss: 0.140470, Val Acc: 0.762887\n",
      "Epoch 10778 - Train Loss: 0.123381, Train Acc: 0.794872 | Val Loss: 0.140464, Val Acc: 0.762887\n",
      "Epoch 10779 - Train Loss: 0.123373, Train Acc: 0.794872 | Val Loss: 0.140458, Val Acc: 0.762887\n",
      "Epoch 10780 - Train Loss: 0.123366, Train Acc: 0.794872 | Val Loss: 0.140451, Val Acc: 0.762887\n",
      "Epoch 10781 - Train Loss: 0.123359, Train Acc: 0.794872 | Val Loss: 0.140445, Val Acc: 0.762887\n",
      "Epoch 10782 - Train Loss: 0.123351, Train Acc: 0.794872 | Val Loss: 0.140439, Val Acc: 0.762887\n",
      "Epoch 10783 - Train Loss: 0.123344, Train Acc: 0.794872 | Val Loss: 0.140433, Val Acc: 0.762887\n",
      "Epoch 10784 - Train Loss: 0.123337, Train Acc: 0.794872 | Val Loss: 0.140427, Val Acc: 0.762887\n",
      "Epoch 10785 - Train Loss: 0.123329, Train Acc: 0.794872 | Val Loss: 0.140421, Val Acc: 0.762887\n",
      "Epoch 10786 - Train Loss: 0.123322, Train Acc: 0.794872 | Val Loss: 0.140414, Val Acc: 0.762887\n",
      "Epoch 10787 - Train Loss: 0.123314, Train Acc: 0.794872 | Val Loss: 0.140408, Val Acc: 0.762887\n",
      "Epoch 10788 - Train Loss: 0.123307, Train Acc: 0.794872 | Val Loss: 0.140402, Val Acc: 0.762887\n",
      "Epoch 10789 - Train Loss: 0.123300, Train Acc: 0.794872 | Val Loss: 0.140396, Val Acc: 0.762887\n",
      "Epoch 10790 - Train Loss: 0.123292, Train Acc: 0.794872 | Val Loss: 0.140390, Val Acc: 0.762887\n",
      "Epoch 10791 - Train Loss: 0.123285, Train Acc: 0.794872 | Val Loss: 0.140384, Val Acc: 0.762887\n",
      "Epoch 10792 - Train Loss: 0.123278, Train Acc: 0.794872 | Val Loss: 0.140377, Val Acc: 0.762887\n",
      "Epoch 10793 - Train Loss: 0.123270, Train Acc: 0.794872 | Val Loss: 0.140371, Val Acc: 0.762887\n",
      "Epoch 10794 - Train Loss: 0.123263, Train Acc: 0.794872 | Val Loss: 0.140365, Val Acc: 0.762887\n",
      "Epoch 10795 - Train Loss: 0.123256, Train Acc: 0.794872 | Val Loss: 0.140359, Val Acc: 0.762887\n",
      "Epoch 10796 - Train Loss: 0.123249, Train Acc: 0.794872 | Val Loss: 0.140353, Val Acc: 0.762887\n",
      "Epoch 10797 - Train Loss: 0.123241, Train Acc: 0.794872 | Val Loss: 0.140347, Val Acc: 0.762887\n",
      "Epoch 10798 - Train Loss: 0.123234, Train Acc: 0.794872 | Val Loss: 0.140341, Val Acc: 0.762887\n",
      "Epoch 10799 - Train Loss: 0.123227, Train Acc: 0.794872 | Val Loss: 0.140334, Val Acc: 0.762887\n",
      "Epoch 10800 - Train Loss: 0.123219, Train Acc: 0.794872 | Val Loss: 0.140328, Val Acc: 0.762887\n",
      "Epoch 10801 - Train Loss: 0.123212, Train Acc: 0.794872 | Val Loss: 0.140322, Val Acc: 0.762887\n",
      "Epoch 10802 - Train Loss: 0.123205, Train Acc: 0.794872 | Val Loss: 0.140316, Val Acc: 0.762887\n",
      "Epoch 10803 - Train Loss: 0.123197, Train Acc: 0.794872 | Val Loss: 0.140310, Val Acc: 0.762887\n",
      "Epoch 10804 - Train Loss: 0.123190, Train Acc: 0.794872 | Val Loss: 0.140304, Val Acc: 0.762887\n",
      "Epoch 10805 - Train Loss: 0.123183, Train Acc: 0.794872 | Val Loss: 0.140298, Val Acc: 0.762887\n",
      "Epoch 10806 - Train Loss: 0.123175, Train Acc: 0.796154 | Val Loss: 0.140291, Val Acc: 0.762887\n",
      "Epoch 10807 - Train Loss: 0.123168, Train Acc: 0.796154 | Val Loss: 0.140285, Val Acc: 0.762887\n",
      "Epoch 10808 - Train Loss: 0.123161, Train Acc: 0.796154 | Val Loss: 0.140279, Val Acc: 0.762887\n",
      "Epoch 10809 - Train Loss: 0.123153, Train Acc: 0.796154 | Val Loss: 0.140273, Val Acc: 0.762887\n",
      "Epoch 10810 - Train Loss: 0.123146, Train Acc: 0.796154 | Val Loss: 0.140267, Val Acc: 0.762887\n",
      "Epoch 10811 - Train Loss: 0.123139, Train Acc: 0.796154 | Val Loss: 0.140261, Val Acc: 0.762887\n",
      "Epoch 10812 - Train Loss: 0.123131, Train Acc: 0.796154 | Val Loss: 0.140255, Val Acc: 0.762887\n",
      "Epoch 10813 - Train Loss: 0.123124, Train Acc: 0.796154 | Val Loss: 0.140248, Val Acc: 0.762887\n",
      "Epoch 10814 - Train Loss: 0.123117, Train Acc: 0.796154 | Val Loss: 0.140242, Val Acc: 0.762887\n",
      "Epoch 10815 - Train Loss: 0.123110, Train Acc: 0.796154 | Val Loss: 0.140236, Val Acc: 0.762887\n",
      "Epoch 10816 - Train Loss: 0.123102, Train Acc: 0.796154 | Val Loss: 0.140230, Val Acc: 0.762887\n",
      "Epoch 10817 - Train Loss: 0.123095, Train Acc: 0.796154 | Val Loss: 0.140224, Val Acc: 0.762887\n",
      "Epoch 10818 - Train Loss: 0.123088, Train Acc: 0.796154 | Val Loss: 0.140218, Val Acc: 0.762887\n",
      "Epoch 10819 - Train Loss: 0.123080, Train Acc: 0.796154 | Val Loss: 0.140212, Val Acc: 0.762887\n",
      "Epoch 10820 - Train Loss: 0.123073, Train Acc: 0.796154 | Val Loss: 0.140206, Val Acc: 0.762887\n",
      "Epoch 10821 - Train Loss: 0.123066, Train Acc: 0.796154 | Val Loss: 0.140200, Val Acc: 0.762887\n",
      "Epoch 10822 - Train Loss: 0.123058, Train Acc: 0.796154 | Val Loss: 0.140193, Val Acc: 0.762887\n",
      "Epoch 10823 - Train Loss: 0.123051, Train Acc: 0.796154 | Val Loss: 0.140187, Val Acc: 0.762887\n",
      "Epoch 10824 - Train Loss: 0.123044, Train Acc: 0.796154 | Val Loss: 0.140181, Val Acc: 0.762887\n",
      "Epoch 10825 - Train Loss: 0.123037, Train Acc: 0.796154 | Val Loss: 0.140175, Val Acc: 0.762887\n",
      "Epoch 10826 - Train Loss: 0.123029, Train Acc: 0.796154 | Val Loss: 0.140169, Val Acc: 0.762887\n",
      "Epoch 10827 - Train Loss: 0.123022, Train Acc: 0.796154 | Val Loss: 0.140163, Val Acc: 0.762887\n",
      "Epoch 10828 - Train Loss: 0.123015, Train Acc: 0.796154 | Val Loss: 0.140157, Val Acc: 0.762887\n",
      "Epoch 10829 - Train Loss: 0.123007, Train Acc: 0.796154 | Val Loss: 0.140151, Val Acc: 0.762887\n",
      "Epoch 10830 - Train Loss: 0.123000, Train Acc: 0.796154 | Val Loss: 0.140145, Val Acc: 0.762887\n",
      "Epoch 10831 - Train Loss: 0.122993, Train Acc: 0.796154 | Val Loss: 0.140138, Val Acc: 0.762887\n",
      "Epoch 10832 - Train Loss: 0.122986, Train Acc: 0.796154 | Val Loss: 0.140132, Val Acc: 0.762887\n",
      "Epoch 10833 - Train Loss: 0.122978, Train Acc: 0.796154 | Val Loss: 0.140126, Val Acc: 0.762887\n",
      "Epoch 10834 - Train Loss: 0.122971, Train Acc: 0.796154 | Val Loss: 0.140120, Val Acc: 0.762887\n",
      "Epoch 10835 - Train Loss: 0.122964, Train Acc: 0.796154 | Val Loss: 0.140114, Val Acc: 0.762887\n",
      "Epoch 10836 - Train Loss: 0.122956, Train Acc: 0.796154 | Val Loss: 0.140108, Val Acc: 0.762887\n",
      "Epoch 10837 - Train Loss: 0.122949, Train Acc: 0.796154 | Val Loss: 0.140102, Val Acc: 0.762887\n",
      "Epoch 10838 - Train Loss: 0.122942, Train Acc: 0.796154 | Val Loss: 0.140096, Val Acc: 0.762887\n",
      "Epoch 10839 - Train Loss: 0.122935, Train Acc: 0.796154 | Val Loss: 0.140090, Val Acc: 0.762887\n",
      "Epoch 10840 - Train Loss: 0.122927, Train Acc: 0.796154 | Val Loss: 0.140084, Val Acc: 0.762887\n",
      "Epoch 10841 - Train Loss: 0.122920, Train Acc: 0.796154 | Val Loss: 0.140078, Val Acc: 0.762887\n",
      "Epoch 10842 - Train Loss: 0.122913, Train Acc: 0.796154 | Val Loss: 0.140071, Val Acc: 0.762887\n",
      "Epoch 10843 - Train Loss: 0.122906, Train Acc: 0.796154 | Val Loss: 0.140065, Val Acc: 0.762887\n",
      "Epoch 10844 - Train Loss: 0.122898, Train Acc: 0.796154 | Val Loss: 0.140059, Val Acc: 0.762887\n",
      "Epoch 10845 - Train Loss: 0.122891, Train Acc: 0.796154 | Val Loss: 0.140053, Val Acc: 0.762887\n",
      "Epoch 10846 - Train Loss: 0.122884, Train Acc: 0.796154 | Val Loss: 0.140047, Val Acc: 0.762887\n",
      "Epoch 10847 - Train Loss: 0.122877, Train Acc: 0.796154 | Val Loss: 0.140041, Val Acc: 0.762887\n",
      "Epoch 10848 - Train Loss: 0.122869, Train Acc: 0.796154 | Val Loss: 0.140035, Val Acc: 0.762887\n",
      "Epoch 10849 - Train Loss: 0.122862, Train Acc: 0.796154 | Val Loss: 0.140029, Val Acc: 0.762887\n",
      "Epoch 10850 - Train Loss: 0.122855, Train Acc: 0.796154 | Val Loss: 0.140023, Val Acc: 0.762887\n",
      "Epoch 10851 - Train Loss: 0.122847, Train Acc: 0.796154 | Val Loss: 0.140017, Val Acc: 0.762887\n",
      "Epoch 10852 - Train Loss: 0.122840, Train Acc: 0.796154 | Val Loss: 0.140011, Val Acc: 0.762887\n",
      "Epoch 10853 - Train Loss: 0.122833, Train Acc: 0.796154 | Val Loss: 0.140005, Val Acc: 0.762887\n",
      "Epoch 10854 - Train Loss: 0.122826, Train Acc: 0.796154 | Val Loss: 0.139998, Val Acc: 0.762887\n",
      "Epoch 10855 - Train Loss: 0.122818, Train Acc: 0.796154 | Val Loss: 0.139992, Val Acc: 0.762887\n",
      "Epoch 10856 - Train Loss: 0.122811, Train Acc: 0.796154 | Val Loss: 0.139986, Val Acc: 0.762887\n",
      "Epoch 10857 - Train Loss: 0.122804, Train Acc: 0.796154 | Val Loss: 0.139980, Val Acc: 0.762887\n",
      "Epoch 10858 - Train Loss: 0.122797, Train Acc: 0.796154 | Val Loss: 0.139974, Val Acc: 0.762887\n",
      "Epoch 10859 - Train Loss: 0.122789, Train Acc: 0.796154 | Val Loss: 0.139968, Val Acc: 0.762887\n",
      "Epoch 10860 - Train Loss: 0.122782, Train Acc: 0.796154 | Val Loss: 0.139962, Val Acc: 0.762887\n",
      "Epoch 10861 - Train Loss: 0.122775, Train Acc: 0.796154 | Val Loss: 0.139956, Val Acc: 0.762887\n",
      "Epoch 10862 - Train Loss: 0.122768, Train Acc: 0.796154 | Val Loss: 0.139950, Val Acc: 0.762887\n",
      "Epoch 10863 - Train Loss: 0.122761, Train Acc: 0.796154 | Val Loss: 0.139944, Val Acc: 0.762887\n",
      "Epoch 10864 - Train Loss: 0.122753, Train Acc: 0.796154 | Val Loss: 0.139938, Val Acc: 0.762887\n",
      "Epoch 10865 - Train Loss: 0.122746, Train Acc: 0.796154 | Val Loss: 0.139932, Val Acc: 0.762887\n",
      "Epoch 10866 - Train Loss: 0.122739, Train Acc: 0.796154 | Val Loss: 0.139926, Val Acc: 0.762887\n",
      "Epoch 10867 - Train Loss: 0.122732, Train Acc: 0.796154 | Val Loss: 0.139920, Val Acc: 0.762887\n",
      "Epoch 10868 - Train Loss: 0.122724, Train Acc: 0.796154 | Val Loss: 0.139913, Val Acc: 0.762887\n",
      "Epoch 10869 - Train Loss: 0.122717, Train Acc: 0.796154 | Val Loss: 0.139907, Val Acc: 0.762887\n",
      "Epoch 10870 - Train Loss: 0.122710, Train Acc: 0.796154 | Val Loss: 0.139901, Val Acc: 0.762887\n",
      "Epoch 10871 - Train Loss: 0.122703, Train Acc: 0.796154 | Val Loss: 0.139895, Val Acc: 0.762887\n",
      "Epoch 10872 - Train Loss: 0.122695, Train Acc: 0.796154 | Val Loss: 0.139889, Val Acc: 0.762887\n",
      "Epoch 10873 - Train Loss: 0.122688, Train Acc: 0.796154 | Val Loss: 0.139883, Val Acc: 0.762887\n",
      "Epoch 10874 - Train Loss: 0.122681, Train Acc: 0.796154 | Val Loss: 0.139877, Val Acc: 0.762887\n",
      "Epoch 10875 - Train Loss: 0.122674, Train Acc: 0.796154 | Val Loss: 0.139871, Val Acc: 0.762887\n",
      "Epoch 10876 - Train Loss: 0.122666, Train Acc: 0.796154 | Val Loss: 0.139865, Val Acc: 0.762887\n",
      "Epoch 10877 - Train Loss: 0.122659, Train Acc: 0.796154 | Val Loss: 0.139859, Val Acc: 0.762887\n",
      "Epoch 10878 - Train Loss: 0.122652, Train Acc: 0.796154 | Val Loss: 0.139853, Val Acc: 0.762887\n",
      "Epoch 10879 - Train Loss: 0.122645, Train Acc: 0.796154 | Val Loss: 0.139847, Val Acc: 0.762887\n",
      "Epoch 10880 - Train Loss: 0.122638, Train Acc: 0.796154 | Val Loss: 0.139841, Val Acc: 0.762887\n",
      "Epoch 10881 - Train Loss: 0.122630, Train Acc: 0.796154 | Val Loss: 0.139835, Val Acc: 0.762887\n",
      "Epoch 10882 - Train Loss: 0.122623, Train Acc: 0.796154 | Val Loss: 0.139829, Val Acc: 0.762887\n",
      "Epoch 10883 - Train Loss: 0.122616, Train Acc: 0.796154 | Val Loss: 0.139823, Val Acc: 0.762887\n",
      "Epoch 10884 - Train Loss: 0.122609, Train Acc: 0.796154 | Val Loss: 0.139817, Val Acc: 0.762887\n",
      "Epoch 10885 - Train Loss: 0.122601, Train Acc: 0.796154 | Val Loss: 0.139811, Val Acc: 0.762887\n",
      "Epoch 10886 - Train Loss: 0.122594, Train Acc: 0.796154 | Val Loss: 0.139805, Val Acc: 0.762887\n",
      "Epoch 10887 - Train Loss: 0.122587, Train Acc: 0.796154 | Val Loss: 0.139799, Val Acc: 0.762887\n",
      "Epoch 10888 - Train Loss: 0.122580, Train Acc: 0.796154 | Val Loss: 0.139793, Val Acc: 0.762887\n",
      "Epoch 10889 - Train Loss: 0.122573, Train Acc: 0.796154 | Val Loss: 0.139787, Val Acc: 0.762887\n",
      "Epoch 10890 - Train Loss: 0.122565, Train Acc: 0.796154 | Val Loss: 0.139781, Val Acc: 0.762887\n",
      "Epoch 10891 - Train Loss: 0.122558, Train Acc: 0.796154 | Val Loss: 0.139775, Val Acc: 0.762887\n",
      "Epoch 10892 - Train Loss: 0.122551, Train Acc: 0.796154 | Val Loss: 0.139769, Val Acc: 0.762887\n",
      "Epoch 10893 - Train Loss: 0.122544, Train Acc: 0.796154 | Val Loss: 0.139763, Val Acc: 0.762887\n",
      "Epoch 10894 - Train Loss: 0.122537, Train Acc: 0.796154 | Val Loss: 0.139757, Val Acc: 0.762887\n",
      "Epoch 10895 - Train Loss: 0.122529, Train Acc: 0.796154 | Val Loss: 0.139750, Val Acc: 0.762887\n",
      "Epoch 10896 - Train Loss: 0.122522, Train Acc: 0.796154 | Val Loss: 0.139744, Val Acc: 0.762887\n",
      "Epoch 10897 - Train Loss: 0.122515, Train Acc: 0.796154 | Val Loss: 0.139738, Val Acc: 0.762887\n",
      "Epoch 10898 - Train Loss: 0.122508, Train Acc: 0.796154 | Val Loss: 0.139732, Val Acc: 0.762887\n",
      "Epoch 10899 - Train Loss: 0.122501, Train Acc: 0.796154 | Val Loss: 0.139726, Val Acc: 0.762887\n",
      "Epoch 10900 - Train Loss: 0.122493, Train Acc: 0.796154 | Val Loss: 0.139720, Val Acc: 0.762887\n",
      "Epoch 10901 - Train Loss: 0.122486, Train Acc: 0.796154 | Val Loss: 0.139714, Val Acc: 0.762887\n",
      "Epoch 10902 - Train Loss: 0.122479, Train Acc: 0.796154 | Val Loss: 0.139708, Val Acc: 0.762887\n",
      "Epoch 10903 - Train Loss: 0.122472, Train Acc: 0.796154 | Val Loss: 0.139702, Val Acc: 0.762887\n",
      "Epoch 10904 - Train Loss: 0.122465, Train Acc: 0.796154 | Val Loss: 0.139696, Val Acc: 0.762887\n",
      "Epoch 10905 - Train Loss: 0.122457, Train Acc: 0.796154 | Val Loss: 0.139690, Val Acc: 0.762887\n",
      "Epoch 10906 - Train Loss: 0.122450, Train Acc: 0.796154 | Val Loss: 0.139684, Val Acc: 0.762887\n",
      "Epoch 10907 - Train Loss: 0.122443, Train Acc: 0.796154 | Val Loss: 0.139678, Val Acc: 0.762887\n",
      "Epoch 10908 - Train Loss: 0.122436, Train Acc: 0.796154 | Val Loss: 0.139672, Val Acc: 0.762887\n",
      "Epoch 10909 - Train Loss: 0.122429, Train Acc: 0.796154 | Val Loss: 0.139666, Val Acc: 0.762887\n",
      "Epoch 10910 - Train Loss: 0.122421, Train Acc: 0.796154 | Val Loss: 0.139660, Val Acc: 0.762887\n",
      "Epoch 10911 - Train Loss: 0.122414, Train Acc: 0.796154 | Val Loss: 0.139654, Val Acc: 0.762887\n",
      "Epoch 10912 - Train Loss: 0.122407, Train Acc: 0.796154 | Val Loss: 0.139648, Val Acc: 0.762887\n",
      "Epoch 10913 - Train Loss: 0.122400, Train Acc: 0.796154 | Val Loss: 0.139642, Val Acc: 0.762887\n",
      "Epoch 10914 - Train Loss: 0.122393, Train Acc: 0.796154 | Val Loss: 0.139636, Val Acc: 0.762887\n",
      "Epoch 10915 - Train Loss: 0.122386, Train Acc: 0.796154 | Val Loss: 0.139630, Val Acc: 0.762887\n",
      "Epoch 10916 - Train Loss: 0.122378, Train Acc: 0.796154 | Val Loss: 0.139624, Val Acc: 0.762887\n",
      "Epoch 10917 - Train Loss: 0.122371, Train Acc: 0.796154 | Val Loss: 0.139618, Val Acc: 0.762887\n",
      "Epoch 10918 - Train Loss: 0.122364, Train Acc: 0.796154 | Val Loss: 0.139612, Val Acc: 0.762887\n",
      "Epoch 10919 - Train Loss: 0.122357, Train Acc: 0.796154 | Val Loss: 0.139606, Val Acc: 0.762887\n",
      "Epoch 10920 - Train Loss: 0.122350, Train Acc: 0.796154 | Val Loss: 0.139600, Val Acc: 0.762887\n",
      "Epoch 10921 - Train Loss: 0.122343, Train Acc: 0.796154 | Val Loss: 0.139594, Val Acc: 0.762887\n",
      "Epoch 10922 - Train Loss: 0.122335, Train Acc: 0.796154 | Val Loss: 0.139588, Val Acc: 0.762887\n",
      "Epoch 10923 - Train Loss: 0.122328, Train Acc: 0.796154 | Val Loss: 0.139582, Val Acc: 0.762887\n",
      "Epoch 10924 - Train Loss: 0.122321, Train Acc: 0.796154 | Val Loss: 0.139576, Val Acc: 0.762887\n",
      "Epoch 10925 - Train Loss: 0.122314, Train Acc: 0.796154 | Val Loss: 0.139570, Val Acc: 0.762887\n",
      "Epoch 10926 - Train Loss: 0.122307, Train Acc: 0.796154 | Val Loss: 0.139564, Val Acc: 0.762887\n",
      "Epoch 10927 - Train Loss: 0.122300, Train Acc: 0.796154 | Val Loss: 0.139558, Val Acc: 0.762887\n",
      "Epoch 10928 - Train Loss: 0.122292, Train Acc: 0.796154 | Val Loss: 0.139552, Val Acc: 0.762887\n",
      "Epoch 10929 - Train Loss: 0.122285, Train Acc: 0.796154 | Val Loss: 0.139547, Val Acc: 0.762887\n",
      "Epoch 10930 - Train Loss: 0.122278, Train Acc: 0.796154 | Val Loss: 0.139541, Val Acc: 0.762887\n",
      "Epoch 10931 - Train Loss: 0.122271, Train Acc: 0.796154 | Val Loss: 0.139535, Val Acc: 0.762887\n",
      "Epoch 10932 - Train Loss: 0.122264, Train Acc: 0.796154 | Val Loss: 0.139529, Val Acc: 0.762887\n",
      "Epoch 10933 - Train Loss: 0.122257, Train Acc: 0.796154 | Val Loss: 0.139523, Val Acc: 0.762887\n",
      "Epoch 10934 - Train Loss: 0.122249, Train Acc: 0.796154 | Val Loss: 0.139517, Val Acc: 0.762887\n",
      "Epoch 10935 - Train Loss: 0.122242, Train Acc: 0.796154 | Val Loss: 0.139511, Val Acc: 0.762887\n",
      "Epoch 10936 - Train Loss: 0.122235, Train Acc: 0.796154 | Val Loss: 0.139505, Val Acc: 0.762887\n",
      "Epoch 10937 - Train Loss: 0.122228, Train Acc: 0.796154 | Val Loss: 0.139499, Val Acc: 0.762887\n",
      "Epoch 10938 - Train Loss: 0.122221, Train Acc: 0.796154 | Val Loss: 0.139493, Val Acc: 0.762887\n",
      "Epoch 10939 - Train Loss: 0.122214, Train Acc: 0.796154 | Val Loss: 0.139487, Val Acc: 0.762887\n",
      "Epoch 10940 - Train Loss: 0.122207, Train Acc: 0.796154 | Val Loss: 0.139481, Val Acc: 0.762887\n",
      "Epoch 10941 - Train Loss: 0.122199, Train Acc: 0.796154 | Val Loss: 0.139475, Val Acc: 0.762887\n",
      "Epoch 10942 - Train Loss: 0.122192, Train Acc: 0.796154 | Val Loss: 0.139469, Val Acc: 0.762887\n",
      "Epoch 10943 - Train Loss: 0.122185, Train Acc: 0.796154 | Val Loss: 0.139463, Val Acc: 0.762887\n",
      "Epoch 10944 - Train Loss: 0.122178, Train Acc: 0.796154 | Val Loss: 0.139457, Val Acc: 0.762887\n",
      "Epoch 10945 - Train Loss: 0.122171, Train Acc: 0.796154 | Val Loss: 0.139451, Val Acc: 0.762887\n",
      "Epoch 10946 - Train Loss: 0.122164, Train Acc: 0.796154 | Val Loss: 0.139445, Val Acc: 0.762887\n",
      "Epoch 10947 - Train Loss: 0.122157, Train Acc: 0.796154 | Val Loss: 0.139439, Val Acc: 0.762887\n",
      "Epoch 10948 - Train Loss: 0.122149, Train Acc: 0.796154 | Val Loss: 0.139433, Val Acc: 0.762887\n",
      "Epoch 10949 - Train Loss: 0.122142, Train Acc: 0.796154 | Val Loss: 0.139427, Val Acc: 0.762887\n",
      "Epoch 10950 - Train Loss: 0.122135, Train Acc: 0.796154 | Val Loss: 0.139421, Val Acc: 0.762887\n",
      "Epoch 10951 - Train Loss: 0.122128, Train Acc: 0.796154 | Val Loss: 0.139415, Val Acc: 0.762887\n",
      "Epoch 10952 - Train Loss: 0.122121, Train Acc: 0.796154 | Val Loss: 0.139409, Val Acc: 0.762887\n",
      "Epoch 10953 - Train Loss: 0.122114, Train Acc: 0.796154 | Val Loss: 0.139403, Val Acc: 0.762887\n",
      "Epoch 10954 - Train Loss: 0.122107, Train Acc: 0.796154 | Val Loss: 0.139397, Val Acc: 0.762887\n",
      "Epoch 10955 - Train Loss: 0.122099, Train Acc: 0.796154 | Val Loss: 0.139391, Val Acc: 0.762887\n",
      "Epoch 10956 - Train Loss: 0.122092, Train Acc: 0.797436 | Val Loss: 0.139386, Val Acc: 0.762887\n",
      "Epoch 10957 - Train Loss: 0.122085, Train Acc: 0.797436 | Val Loss: 0.139380, Val Acc: 0.762887\n",
      "Epoch 10958 - Train Loss: 0.122078, Train Acc: 0.797436 | Val Loss: 0.139374, Val Acc: 0.762887\n",
      "Epoch 10959 - Train Loss: 0.122071, Train Acc: 0.797436 | Val Loss: 0.139368, Val Acc: 0.762887\n",
      "Epoch 10960 - Train Loss: 0.122064, Train Acc: 0.797436 | Val Loss: 0.139362, Val Acc: 0.762887\n",
      "Epoch 10961 - Train Loss: 0.122057, Train Acc: 0.797436 | Val Loss: 0.139356, Val Acc: 0.762887\n",
      "Epoch 10962 - Train Loss: 0.122050, Train Acc: 0.797436 | Val Loss: 0.139350, Val Acc: 0.762887\n",
      "Epoch 10963 - Train Loss: 0.122042, Train Acc: 0.797436 | Val Loss: 0.139344, Val Acc: 0.762887\n",
      "Epoch 10964 - Train Loss: 0.122035, Train Acc: 0.797436 | Val Loss: 0.139338, Val Acc: 0.762887\n",
      "Epoch 10965 - Train Loss: 0.122028, Train Acc: 0.797436 | Val Loss: 0.139332, Val Acc: 0.762887\n",
      "Epoch 10966 - Train Loss: 0.122021, Train Acc: 0.797436 | Val Loss: 0.139326, Val Acc: 0.762887\n",
      "Epoch 10967 - Train Loss: 0.122014, Train Acc: 0.797436 | Val Loss: 0.139320, Val Acc: 0.762887\n",
      "Epoch 10968 - Train Loss: 0.122007, Train Acc: 0.797436 | Val Loss: 0.139314, Val Acc: 0.762887\n",
      "Epoch 10969 - Train Loss: 0.122000, Train Acc: 0.797436 | Val Loss: 0.139308, Val Acc: 0.762887\n",
      "Epoch 10970 - Train Loss: 0.121993, Train Acc: 0.797436 | Val Loss: 0.139302, Val Acc: 0.762887\n",
      "Epoch 10971 - Train Loss: 0.121986, Train Acc: 0.797436 | Val Loss: 0.139297, Val Acc: 0.762887\n",
      "Epoch 10972 - Train Loss: 0.121978, Train Acc: 0.797436 | Val Loss: 0.139291, Val Acc: 0.762887\n",
      "Epoch 10973 - Train Loss: 0.121971, Train Acc: 0.797436 | Val Loss: 0.139285, Val Acc: 0.762887\n",
      "Epoch 10974 - Train Loss: 0.121964, Train Acc: 0.797436 | Val Loss: 0.139279, Val Acc: 0.762887\n",
      "Epoch 10975 - Train Loss: 0.121957, Train Acc: 0.797436 | Val Loss: 0.139273, Val Acc: 0.762887\n",
      "Epoch 10976 - Train Loss: 0.121950, Train Acc: 0.797436 | Val Loss: 0.139267, Val Acc: 0.762887\n",
      "Epoch 10977 - Train Loss: 0.121943, Train Acc: 0.797436 | Val Loss: 0.139261, Val Acc: 0.762887\n",
      "Epoch 10978 - Train Loss: 0.121936, Train Acc: 0.797436 | Val Loss: 0.139255, Val Acc: 0.762887\n",
      "Epoch 10979 - Train Loss: 0.121929, Train Acc: 0.797436 | Val Loss: 0.139249, Val Acc: 0.762887\n",
      "Epoch 10980 - Train Loss: 0.121922, Train Acc: 0.797436 | Val Loss: 0.139243, Val Acc: 0.762887\n",
      "Epoch 10981 - Train Loss: 0.121915, Train Acc: 0.797436 | Val Loss: 0.139237, Val Acc: 0.762887\n",
      "Epoch 10982 - Train Loss: 0.121907, Train Acc: 0.797436 | Val Loss: 0.139231, Val Acc: 0.762887\n",
      "Epoch 10983 - Train Loss: 0.121900, Train Acc: 0.797436 | Val Loss: 0.139226, Val Acc: 0.762887\n",
      "Epoch 10984 - Train Loss: 0.121893, Train Acc: 0.797436 | Val Loss: 0.139220, Val Acc: 0.762887\n",
      "Epoch 10985 - Train Loss: 0.121886, Train Acc: 0.797436 | Val Loss: 0.139214, Val Acc: 0.762887\n",
      "Epoch 10986 - Train Loss: 0.121879, Train Acc: 0.797436 | Val Loss: 0.139208, Val Acc: 0.762887\n",
      "Epoch 10987 - Train Loss: 0.121872, Train Acc: 0.797436 | Val Loss: 0.139202, Val Acc: 0.762887\n",
      "Epoch 10988 - Train Loss: 0.121865, Train Acc: 0.797436 | Val Loss: 0.139196, Val Acc: 0.762887\n",
      "Epoch 10989 - Train Loss: 0.121858, Train Acc: 0.797436 | Val Loss: 0.139190, Val Acc: 0.762887\n",
      "Epoch 10990 - Train Loss: 0.121851, Train Acc: 0.797436 | Val Loss: 0.139184, Val Acc: 0.762887\n",
      "Epoch 10991 - Train Loss: 0.121844, Train Acc: 0.797436 | Val Loss: 0.139178, Val Acc: 0.762887\n",
      "Epoch 10992 - Train Loss: 0.121837, Train Acc: 0.797436 | Val Loss: 0.139172, Val Acc: 0.762887\n",
      "Epoch 10993 - Train Loss: 0.121829, Train Acc: 0.797436 | Val Loss: 0.139166, Val Acc: 0.762887\n",
      "Epoch 10994 - Train Loss: 0.121822, Train Acc: 0.797436 | Val Loss: 0.139161, Val Acc: 0.762887\n",
      "Epoch 10995 - Train Loss: 0.121815, Train Acc: 0.797436 | Val Loss: 0.139155, Val Acc: 0.762887\n",
      "Epoch 10996 - Train Loss: 0.121808, Train Acc: 0.798718 | Val Loss: 0.139149, Val Acc: 0.762887\n",
      "Epoch 10997 - Train Loss: 0.121801, Train Acc: 0.798718 | Val Loss: 0.139143, Val Acc: 0.762887\n",
      "Epoch 10998 - Train Loss: 0.121794, Train Acc: 0.798718 | Val Loss: 0.139137, Val Acc: 0.762887\n",
      "Epoch 10999 - Train Loss: 0.121787, Train Acc: 0.798718 | Val Loss: 0.139131, Val Acc: 0.762887\n",
      "Epoch 11000 - Train Loss: 0.121780, Train Acc: 0.798718 | Val Loss: 0.139125, Val Acc: 0.762887\n",
      "Epoch 11001 - Train Loss: 0.121773, Train Acc: 0.798718 | Val Loss: 0.139119, Val Acc: 0.762887\n",
      "Epoch 11002 - Train Loss: 0.121766, Train Acc: 0.798718 | Val Loss: 0.139113, Val Acc: 0.762887\n",
      "Epoch 11003 - Train Loss: 0.121759, Train Acc: 0.798718 | Val Loss: 0.139108, Val Acc: 0.762887\n",
      "Epoch 11004 - Train Loss: 0.121752, Train Acc: 0.798718 | Val Loss: 0.139102, Val Acc: 0.762887\n",
      "Epoch 11005 - Train Loss: 0.121745, Train Acc: 0.798718 | Val Loss: 0.139096, Val Acc: 0.762887\n",
      "Epoch 11006 - Train Loss: 0.121737, Train Acc: 0.798718 | Val Loss: 0.139090, Val Acc: 0.762887\n",
      "Epoch 11007 - Train Loss: 0.121730, Train Acc: 0.798718 | Val Loss: 0.139084, Val Acc: 0.762887\n",
      "Epoch 11008 - Train Loss: 0.121723, Train Acc: 0.798718 | Val Loss: 0.139078, Val Acc: 0.762887\n",
      "Epoch 11009 - Train Loss: 0.121716, Train Acc: 0.798718 | Val Loss: 0.139072, Val Acc: 0.762887\n",
      "Epoch 11010 - Train Loss: 0.121709, Train Acc: 0.798718 | Val Loss: 0.139066, Val Acc: 0.762887\n",
      "Epoch 11011 - Train Loss: 0.121702, Train Acc: 0.798718 | Val Loss: 0.139060, Val Acc: 0.762887\n",
      "Epoch 11012 - Train Loss: 0.121695, Train Acc: 0.798718 | Val Loss: 0.139054, Val Acc: 0.762887\n",
      "Epoch 11013 - Train Loss: 0.121688, Train Acc: 0.798718 | Val Loss: 0.139048, Val Acc: 0.762887\n",
      "Epoch 11014 - Train Loss: 0.121681, Train Acc: 0.798718 | Val Loss: 0.139042, Val Acc: 0.762887\n",
      "Epoch 11015 - Train Loss: 0.121674, Train Acc: 0.798718 | Val Loss: 0.139036, Val Acc: 0.762887\n",
      "Epoch 11016 - Train Loss: 0.121667, Train Acc: 0.798718 | Val Loss: 0.139031, Val Acc: 0.762887\n",
      "Epoch 11017 - Train Loss: 0.121660, Train Acc: 0.798718 | Val Loss: 0.139025, Val Acc: 0.762887\n",
      "Epoch 11018 - Train Loss: 0.121653, Train Acc: 0.798718 | Val Loss: 0.139019, Val Acc: 0.762887\n",
      "Epoch 11019 - Train Loss: 0.121646, Train Acc: 0.798718 | Val Loss: 0.139013, Val Acc: 0.762887\n",
      "Epoch 11020 - Train Loss: 0.121639, Train Acc: 0.798718 | Val Loss: 0.139007, Val Acc: 0.762887\n",
      "Epoch 11021 - Train Loss: 0.121632, Train Acc: 0.798718 | Val Loss: 0.139001, Val Acc: 0.762887\n",
      "Epoch 11022 - Train Loss: 0.121625, Train Acc: 0.798718 | Val Loss: 0.138995, Val Acc: 0.762887\n",
      "Epoch 11023 - Train Loss: 0.121618, Train Acc: 0.798718 | Val Loss: 0.138989, Val Acc: 0.762887\n",
      "Epoch 11024 - Train Loss: 0.121610, Train Acc: 0.798718 | Val Loss: 0.138983, Val Acc: 0.762887\n",
      "Epoch 11025 - Train Loss: 0.121603, Train Acc: 0.798718 | Val Loss: 0.138977, Val Acc: 0.762887\n",
      "Epoch 11026 - Train Loss: 0.121596, Train Acc: 0.798718 | Val Loss: 0.138972, Val Acc: 0.762887\n",
      "Epoch 11027 - Train Loss: 0.121589, Train Acc: 0.798718 | Val Loss: 0.138966, Val Acc: 0.762887\n",
      "Epoch 11028 - Train Loss: 0.121582, Train Acc: 0.798718 | Val Loss: 0.138960, Val Acc: 0.762887\n",
      "Epoch 11029 - Train Loss: 0.121575, Train Acc: 0.798718 | Val Loss: 0.138954, Val Acc: 0.762887\n",
      "Epoch 11030 - Train Loss: 0.121568, Train Acc: 0.798718 | Val Loss: 0.138948, Val Acc: 0.762887\n",
      "Epoch 11031 - Train Loss: 0.121561, Train Acc: 0.798718 | Val Loss: 0.138942, Val Acc: 0.762887\n",
      "Epoch 11032 - Train Loss: 0.121554, Train Acc: 0.798718 | Val Loss: 0.138936, Val Acc: 0.762887\n",
      "Epoch 11033 - Train Loss: 0.121547, Train Acc: 0.798718 | Val Loss: 0.138930, Val Acc: 0.762887\n",
      "Epoch 11034 - Train Loss: 0.121540, Train Acc: 0.798718 | Val Loss: 0.138925, Val Acc: 0.762887\n",
      "Epoch 11035 - Train Loss: 0.121533, Train Acc: 0.798718 | Val Loss: 0.138919, Val Acc: 0.762887\n",
      "Epoch 11036 - Train Loss: 0.121526, Train Acc: 0.798718 | Val Loss: 0.138913, Val Acc: 0.762887\n",
      "Epoch 11037 - Train Loss: 0.121519, Train Acc: 0.798718 | Val Loss: 0.138907, Val Acc: 0.762887\n",
      "Epoch 11038 - Train Loss: 0.121512, Train Acc: 0.798718 | Val Loss: 0.138901, Val Acc: 0.762887\n",
      "Epoch 11039 - Train Loss: 0.121505, Train Acc: 0.798718 | Val Loss: 0.138895, Val Acc: 0.762887\n",
      "Epoch 11040 - Train Loss: 0.121498, Train Acc: 0.798718 | Val Loss: 0.138889, Val Acc: 0.762887\n",
      "Epoch 11041 - Train Loss: 0.121491, Train Acc: 0.798718 | Val Loss: 0.138883, Val Acc: 0.762887\n",
      "Epoch 11042 - Train Loss: 0.121484, Train Acc: 0.798718 | Val Loss: 0.138878, Val Acc: 0.762887\n",
      "Epoch 11043 - Train Loss: 0.121477, Train Acc: 0.798718 | Val Loss: 0.138872, Val Acc: 0.762887\n",
      "Epoch 11044 - Train Loss: 0.121470, Train Acc: 0.798718 | Val Loss: 0.138866, Val Acc: 0.762887\n",
      "Epoch 11045 - Train Loss: 0.121463, Train Acc: 0.798718 | Val Loss: 0.138860, Val Acc: 0.762887\n",
      "Epoch 11046 - Train Loss: 0.121456, Train Acc: 0.798718 | Val Loss: 0.138854, Val Acc: 0.762887\n",
      "Epoch 11047 - Train Loss: 0.121449, Train Acc: 0.798718 | Val Loss: 0.138848, Val Acc: 0.762887\n",
      "Epoch 11048 - Train Loss: 0.121442, Train Acc: 0.798718 | Val Loss: 0.138842, Val Acc: 0.762887\n",
      "Epoch 11049 - Train Loss: 0.121435, Train Acc: 0.798718 | Val Loss: 0.138837, Val Acc: 0.762887\n",
      "Epoch 11050 - Train Loss: 0.121428, Train Acc: 0.798718 | Val Loss: 0.138831, Val Acc: 0.762887\n",
      "Epoch 11051 - Train Loss: 0.121421, Train Acc: 0.798718 | Val Loss: 0.138825, Val Acc: 0.762887\n",
      "Epoch 11052 - Train Loss: 0.121414, Train Acc: 0.798718 | Val Loss: 0.138819, Val Acc: 0.762887\n",
      "Epoch 11053 - Train Loss: 0.121407, Train Acc: 0.798718 | Val Loss: 0.138813, Val Acc: 0.762887\n",
      "Epoch 11054 - Train Loss: 0.121400, Train Acc: 0.798718 | Val Loss: 0.138807, Val Acc: 0.762887\n",
      "Epoch 11055 - Train Loss: 0.121393, Train Acc: 0.798718 | Val Loss: 0.138802, Val Acc: 0.762887\n",
      "Epoch 11056 - Train Loss: 0.121386, Train Acc: 0.798718 | Val Loss: 0.138796, Val Acc: 0.762887\n",
      "Epoch 11057 - Train Loss: 0.121379, Train Acc: 0.798718 | Val Loss: 0.138790, Val Acc: 0.762887\n",
      "Epoch 11058 - Train Loss: 0.121372, Train Acc: 0.798718 | Val Loss: 0.138784, Val Acc: 0.762887\n",
      "Epoch 11059 - Train Loss: 0.121365, Train Acc: 0.798718 | Val Loss: 0.138778, Val Acc: 0.762887\n",
      "Epoch 11060 - Train Loss: 0.121358, Train Acc: 0.798718 | Val Loss: 0.138772, Val Acc: 0.762887\n",
      "Epoch 11061 - Train Loss: 0.121351, Train Acc: 0.798718 | Val Loss: 0.138767, Val Acc: 0.762887\n",
      "Epoch 11062 - Train Loss: 0.121344, Train Acc: 0.798718 | Val Loss: 0.138761, Val Acc: 0.762887\n",
      "Epoch 11063 - Train Loss: 0.121337, Train Acc: 0.798718 | Val Loss: 0.138755, Val Acc: 0.762887\n",
      "Epoch 11064 - Train Loss: 0.121330, Train Acc: 0.798718 | Val Loss: 0.138749, Val Acc: 0.762887\n",
      "Epoch 11065 - Train Loss: 0.121323, Train Acc: 0.798718 | Val Loss: 0.138743, Val Acc: 0.762887\n",
      "Epoch 11066 - Train Loss: 0.121316, Train Acc: 0.798718 | Val Loss: 0.138738, Val Acc: 0.762887\n",
      "Epoch 11067 - Train Loss: 0.121309, Train Acc: 0.798718 | Val Loss: 0.138732, Val Acc: 0.762887\n",
      "Epoch 11068 - Train Loss: 0.121302, Train Acc: 0.798718 | Val Loss: 0.138726, Val Acc: 0.762887\n",
      "Epoch 11069 - Train Loss: 0.121295, Train Acc: 0.798718 | Val Loss: 0.138720, Val Acc: 0.762887\n",
      "Epoch 11070 - Train Loss: 0.121288, Train Acc: 0.798718 | Val Loss: 0.138714, Val Acc: 0.762887\n",
      "Epoch 11071 - Train Loss: 0.121281, Train Acc: 0.798718 | Val Loss: 0.138708, Val Acc: 0.762887\n",
      "Epoch 11072 - Train Loss: 0.121274, Train Acc: 0.798718 | Val Loss: 0.138703, Val Acc: 0.762887\n",
      "Epoch 11073 - Train Loss: 0.121267, Train Acc: 0.798718 | Val Loss: 0.138697, Val Acc: 0.762887\n",
      "Epoch 11074 - Train Loss: 0.121260, Train Acc: 0.798718 | Val Loss: 0.138691, Val Acc: 0.762887\n",
      "Epoch 11075 - Train Loss: 0.121253, Train Acc: 0.798718 | Val Loss: 0.138685, Val Acc: 0.762887\n",
      "Epoch 11076 - Train Loss: 0.121246, Train Acc: 0.798718 | Val Loss: 0.138679, Val Acc: 0.762887\n",
      "Epoch 11077 - Train Loss: 0.121239, Train Acc: 0.798718 | Val Loss: 0.138674, Val Acc: 0.762887\n",
      "Epoch 11078 - Train Loss: 0.121232, Train Acc: 0.798718 | Val Loss: 0.138668, Val Acc: 0.762887\n",
      "Epoch 11079 - Train Loss: 0.121225, Train Acc: 0.798718 | Val Loss: 0.138662, Val Acc: 0.762887\n",
      "Epoch 11080 - Train Loss: 0.121218, Train Acc: 0.798718 | Val Loss: 0.138656, Val Acc: 0.762887\n",
      "Epoch 11081 - Train Loss: 0.121211, Train Acc: 0.798718 | Val Loss: 0.138650, Val Acc: 0.762887\n",
      "Epoch 11082 - Train Loss: 0.121204, Train Acc: 0.798718 | Val Loss: 0.138645, Val Acc: 0.762887\n",
      "Epoch 11083 - Train Loss: 0.121197, Train Acc: 0.798718 | Val Loss: 0.138639, Val Acc: 0.762887\n",
      "Epoch 11084 - Train Loss: 0.121190, Train Acc: 0.798718 | Val Loss: 0.138633, Val Acc: 0.762887\n",
      "Epoch 11085 - Train Loss: 0.121183, Train Acc: 0.798718 | Val Loss: 0.138627, Val Acc: 0.762887\n",
      "Epoch 11086 - Train Loss: 0.121176, Train Acc: 0.798718 | Val Loss: 0.138621, Val Acc: 0.762887\n",
      "Epoch 11087 - Train Loss: 0.121169, Train Acc: 0.798718 | Val Loss: 0.138616, Val Acc: 0.762887\n",
      "Epoch 11088 - Train Loss: 0.121162, Train Acc: 0.798718 | Val Loss: 0.138610, Val Acc: 0.762887\n",
      "Epoch 11089 - Train Loss: 0.121155, Train Acc: 0.798718 | Val Loss: 0.138604, Val Acc: 0.762887\n",
      "Epoch 11090 - Train Loss: 0.121148, Train Acc: 0.798718 | Val Loss: 0.138598, Val Acc: 0.762887\n",
      "Epoch 11091 - Train Loss: 0.121141, Train Acc: 0.798718 | Val Loss: 0.138592, Val Acc: 0.762887\n",
      "Epoch 11092 - Train Loss: 0.121134, Train Acc: 0.798718 | Val Loss: 0.138587, Val Acc: 0.762887\n",
      "Epoch 11093 - Train Loss: 0.121127, Train Acc: 0.798718 | Val Loss: 0.138581, Val Acc: 0.762887\n",
      "Epoch 11094 - Train Loss: 0.121120, Train Acc: 0.798718 | Val Loss: 0.138575, Val Acc: 0.762887\n",
      "Epoch 11095 - Train Loss: 0.121113, Train Acc: 0.798718 | Val Loss: 0.138569, Val Acc: 0.762887\n",
      "Epoch 11096 - Train Loss: 0.121106, Train Acc: 0.798718 | Val Loss: 0.138564, Val Acc: 0.762887\n",
      "Epoch 11097 - Train Loss: 0.121099, Train Acc: 0.798718 | Val Loss: 0.138558, Val Acc: 0.762887\n",
      "Epoch 11098 - Train Loss: 0.121092, Train Acc: 0.798718 | Val Loss: 0.138552, Val Acc: 0.762887\n",
      "Epoch 11099 - Train Loss: 0.121085, Train Acc: 0.798718 | Val Loss: 0.138546, Val Acc: 0.762887\n",
      "Epoch 11100 - Train Loss: 0.121079, Train Acc: 0.798718 | Val Loss: 0.138540, Val Acc: 0.762887\n",
      "Epoch 11101 - Train Loss: 0.121072, Train Acc: 0.798718 | Val Loss: 0.138535, Val Acc: 0.762887\n",
      "Epoch 11102 - Train Loss: 0.121065, Train Acc: 0.798718 | Val Loss: 0.138529, Val Acc: 0.762887\n",
      "Epoch 11103 - Train Loss: 0.121058, Train Acc: 0.798718 | Val Loss: 0.138523, Val Acc: 0.762887\n",
      "Epoch 11104 - Train Loss: 0.121051, Train Acc: 0.798718 | Val Loss: 0.138517, Val Acc: 0.762887\n",
      "Epoch 11105 - Train Loss: 0.121044, Train Acc: 0.798718 | Val Loss: 0.138512, Val Acc: 0.762887\n",
      "Epoch 11106 - Train Loss: 0.121037, Train Acc: 0.798718 | Val Loss: 0.138506, Val Acc: 0.762887\n",
      "Epoch 11107 - Train Loss: 0.121030, Train Acc: 0.798718 | Val Loss: 0.138500, Val Acc: 0.762887\n",
      "Epoch 11108 - Train Loss: 0.121023, Train Acc: 0.798718 | Val Loss: 0.138494, Val Acc: 0.762887\n",
      "Epoch 11109 - Train Loss: 0.121016, Train Acc: 0.798718 | Val Loss: 0.138489, Val Acc: 0.762887\n",
      "Epoch 11110 - Train Loss: 0.121009, Train Acc: 0.798718 | Val Loss: 0.138483, Val Acc: 0.762887\n",
      "Epoch 11111 - Train Loss: 0.121002, Train Acc: 0.798718 | Val Loss: 0.138477, Val Acc: 0.762887\n",
      "Epoch 11112 - Train Loss: 0.120995, Train Acc: 0.798718 | Val Loss: 0.138471, Val Acc: 0.762887\n",
      "Epoch 11113 - Train Loss: 0.120988, Train Acc: 0.798718 | Val Loss: 0.138465, Val Acc: 0.762887\n",
      "Epoch 11114 - Train Loss: 0.120981, Train Acc: 0.798718 | Val Loss: 0.138460, Val Acc: 0.762887\n",
      "Epoch 11115 - Train Loss: 0.120974, Train Acc: 0.798718 | Val Loss: 0.138454, Val Acc: 0.762887\n",
      "Epoch 11116 - Train Loss: 0.120967, Train Acc: 0.798718 | Val Loss: 0.138448, Val Acc: 0.762887\n",
      "Epoch 11117 - Train Loss: 0.120960, Train Acc: 0.798718 | Val Loss: 0.138442, Val Acc: 0.762887\n",
      "Epoch 11118 - Train Loss: 0.120954, Train Acc: 0.798718 | Val Loss: 0.138437, Val Acc: 0.762887\n",
      "Epoch 11119 - Train Loss: 0.120947, Train Acc: 0.798718 | Val Loss: 0.138431, Val Acc: 0.762887\n",
      "Epoch 11120 - Train Loss: 0.120940, Train Acc: 0.798718 | Val Loss: 0.138425, Val Acc: 0.762887\n",
      "Epoch 11121 - Train Loss: 0.120933, Train Acc: 0.798718 | Val Loss: 0.138419, Val Acc: 0.762887\n",
      "Epoch 11122 - Train Loss: 0.120926, Train Acc: 0.798718 | Val Loss: 0.138414, Val Acc: 0.762887\n",
      "Epoch 11123 - Train Loss: 0.120919, Train Acc: 0.798718 | Val Loss: 0.138408, Val Acc: 0.762887\n",
      "Epoch 11124 - Train Loss: 0.120912, Train Acc: 0.798718 | Val Loss: 0.138402, Val Acc: 0.762887\n",
      "Epoch 11125 - Train Loss: 0.120905, Train Acc: 0.798718 | Val Loss: 0.138396, Val Acc: 0.762887\n",
      "Epoch 11126 - Train Loss: 0.120898, Train Acc: 0.798718 | Val Loss: 0.138391, Val Acc: 0.762887\n",
      "Epoch 11127 - Train Loss: 0.120891, Train Acc: 0.798718 | Val Loss: 0.138385, Val Acc: 0.762887\n",
      "Epoch 11128 - Train Loss: 0.120884, Train Acc: 0.798718 | Val Loss: 0.138379, Val Acc: 0.762887\n",
      "Epoch 11129 - Train Loss: 0.120877, Train Acc: 0.798718 | Val Loss: 0.138374, Val Acc: 0.762887\n",
      "Epoch 11130 - Train Loss: 0.120870, Train Acc: 0.798718 | Val Loss: 0.138368, Val Acc: 0.762887\n",
      "Epoch 11131 - Train Loss: 0.120863, Train Acc: 0.798718 | Val Loss: 0.138362, Val Acc: 0.762887\n",
      "Epoch 11132 - Train Loss: 0.120857, Train Acc: 0.798718 | Val Loss: 0.138356, Val Acc: 0.762887\n",
      "Epoch 11133 - Train Loss: 0.120850, Train Acc: 0.798718 | Val Loss: 0.138351, Val Acc: 0.762887\n",
      "Epoch 11134 - Train Loss: 0.120843, Train Acc: 0.798718 | Val Loss: 0.138345, Val Acc: 0.762887\n",
      "Epoch 11135 - Train Loss: 0.120836, Train Acc: 0.798718 | Val Loss: 0.138339, Val Acc: 0.762887\n",
      "Epoch 11136 - Train Loss: 0.120829, Train Acc: 0.798718 | Val Loss: 0.138333, Val Acc: 0.762887\n",
      "Epoch 11137 - Train Loss: 0.120822, Train Acc: 0.798718 | Val Loss: 0.138328, Val Acc: 0.762887\n",
      "Epoch 11138 - Train Loss: 0.120815, Train Acc: 0.798718 | Val Loss: 0.138322, Val Acc: 0.762887\n",
      "Epoch 11139 - Train Loss: 0.120808, Train Acc: 0.798718 | Val Loss: 0.138316, Val Acc: 0.762887\n",
      "Epoch 11140 - Train Loss: 0.120801, Train Acc: 0.798718 | Val Loss: 0.138311, Val Acc: 0.762887\n",
      "Epoch 11141 - Train Loss: 0.120794, Train Acc: 0.798718 | Val Loss: 0.138305, Val Acc: 0.762887\n",
      "Epoch 11142 - Train Loss: 0.120787, Train Acc: 0.798718 | Val Loss: 0.138299, Val Acc: 0.762887\n",
      "Epoch 11143 - Train Loss: 0.120781, Train Acc: 0.798718 | Val Loss: 0.138293, Val Acc: 0.762887\n",
      "Epoch 11144 - Train Loss: 0.120774, Train Acc: 0.798718 | Val Loss: 0.138288, Val Acc: 0.762887\n",
      "Epoch 11145 - Train Loss: 0.120767, Train Acc: 0.798718 | Val Loss: 0.138282, Val Acc: 0.762887\n",
      "Epoch 11146 - Train Loss: 0.120760, Train Acc: 0.798718 | Val Loss: 0.138276, Val Acc: 0.762887\n",
      "Epoch 11147 - Train Loss: 0.120753, Train Acc: 0.798718 | Val Loss: 0.138271, Val Acc: 0.762887\n",
      "Epoch 11148 - Train Loss: 0.120746, Train Acc: 0.798718 | Val Loss: 0.138265, Val Acc: 0.762887\n",
      "Epoch 11149 - Train Loss: 0.120739, Train Acc: 0.798718 | Val Loss: 0.138259, Val Acc: 0.762887\n",
      "Epoch 11150 - Train Loss: 0.120732, Train Acc: 0.798718 | Val Loss: 0.138253, Val Acc: 0.762887\n",
      "Epoch 11151 - Train Loss: 0.120725, Train Acc: 0.800000 | Val Loss: 0.138248, Val Acc: 0.762887\n",
      "Epoch 11152 - Train Loss: 0.120718, Train Acc: 0.800000 | Val Loss: 0.138242, Val Acc: 0.762887\n",
      "Epoch 11153 - Train Loss: 0.120712, Train Acc: 0.800000 | Val Loss: 0.138236, Val Acc: 0.762887\n",
      "Epoch 11154 - Train Loss: 0.120705, Train Acc: 0.800000 | Val Loss: 0.138231, Val Acc: 0.762887\n",
      "Epoch 11155 - Train Loss: 0.120698, Train Acc: 0.800000 | Val Loss: 0.138225, Val Acc: 0.762887\n",
      "Epoch 11156 - Train Loss: 0.120691, Train Acc: 0.800000 | Val Loss: 0.138219, Val Acc: 0.762887\n",
      "Epoch 11157 - Train Loss: 0.120684, Train Acc: 0.800000 | Val Loss: 0.138213, Val Acc: 0.762887\n",
      "Epoch 11158 - Train Loss: 0.120677, Train Acc: 0.800000 | Val Loss: 0.138208, Val Acc: 0.762887\n",
      "Epoch 11159 - Train Loss: 0.120670, Train Acc: 0.800000 | Val Loss: 0.138202, Val Acc: 0.762887\n",
      "Epoch 11160 - Train Loss: 0.120663, Train Acc: 0.800000 | Val Loss: 0.138196, Val Acc: 0.762887\n",
      "Epoch 11161 - Train Loss: 0.120656, Train Acc: 0.800000 | Val Loss: 0.138191, Val Acc: 0.762887\n",
      "Epoch 11162 - Train Loss: 0.120650, Train Acc: 0.800000 | Val Loss: 0.138185, Val Acc: 0.762887\n",
      "Epoch 11163 - Train Loss: 0.120643, Train Acc: 0.800000 | Val Loss: 0.138179, Val Acc: 0.762887\n",
      "Epoch 11164 - Train Loss: 0.120636, Train Acc: 0.800000 | Val Loss: 0.138174, Val Acc: 0.762887\n",
      "Epoch 11165 - Train Loss: 0.120629, Train Acc: 0.800000 | Val Loss: 0.138168, Val Acc: 0.762887\n",
      "Epoch 11166 - Train Loss: 0.120622, Train Acc: 0.800000 | Val Loss: 0.138162, Val Acc: 0.762887\n",
      "Epoch 11167 - Train Loss: 0.120615, Train Acc: 0.800000 | Val Loss: 0.138156, Val Acc: 0.762887\n",
      "Epoch 11168 - Train Loss: 0.120608, Train Acc: 0.800000 | Val Loss: 0.138151, Val Acc: 0.762887\n",
      "Epoch 11169 - Train Loss: 0.120601, Train Acc: 0.800000 | Val Loss: 0.138145, Val Acc: 0.762887\n",
      "Epoch 11170 - Train Loss: 0.120595, Train Acc: 0.800000 | Val Loss: 0.138139, Val Acc: 0.762887\n",
      "Epoch 11171 - Train Loss: 0.120588, Train Acc: 0.800000 | Val Loss: 0.138134, Val Acc: 0.762887\n",
      "Epoch 11172 - Train Loss: 0.120581, Train Acc: 0.800000 | Val Loss: 0.138128, Val Acc: 0.762887\n",
      "Epoch 11173 - Train Loss: 0.120574, Train Acc: 0.800000 | Val Loss: 0.138122, Val Acc: 0.762887\n",
      "Epoch 11174 - Train Loss: 0.120567, Train Acc: 0.800000 | Val Loss: 0.138117, Val Acc: 0.762887\n",
      "Epoch 11175 - Train Loss: 0.120560, Train Acc: 0.800000 | Val Loss: 0.138111, Val Acc: 0.762887\n",
      "Epoch 11176 - Train Loss: 0.120553, Train Acc: 0.800000 | Val Loss: 0.138105, Val Acc: 0.762887\n",
      "Epoch 11177 - Train Loss: 0.120547, Train Acc: 0.800000 | Val Loss: 0.138100, Val Acc: 0.762887\n",
      "Epoch 11178 - Train Loss: 0.120540, Train Acc: 0.800000 | Val Loss: 0.138094, Val Acc: 0.762887\n",
      "Epoch 11179 - Train Loss: 0.120533, Train Acc: 0.800000 | Val Loss: 0.138088, Val Acc: 0.762887\n",
      "Epoch 11180 - Train Loss: 0.120526, Train Acc: 0.800000 | Val Loss: 0.138083, Val Acc: 0.762887\n",
      "Epoch 11181 - Train Loss: 0.120519, Train Acc: 0.800000 | Val Loss: 0.138077, Val Acc: 0.762887\n",
      "Epoch 11182 - Train Loss: 0.120512, Train Acc: 0.800000 | Val Loss: 0.138071, Val Acc: 0.762887\n",
      "Epoch 11183 - Train Loss: 0.120505, Train Acc: 0.800000 | Val Loss: 0.138066, Val Acc: 0.762887\n",
      "Epoch 11184 - Train Loss: 0.120499, Train Acc: 0.801282 | Val Loss: 0.138060, Val Acc: 0.762887\n",
      "Epoch 11185 - Train Loss: 0.120492, Train Acc: 0.801282 | Val Loss: 0.138054, Val Acc: 0.762887\n",
      "Epoch 11186 - Train Loss: 0.120485, Train Acc: 0.801282 | Val Loss: 0.138049, Val Acc: 0.762887\n",
      "Epoch 11187 - Train Loss: 0.120478, Train Acc: 0.801282 | Val Loss: 0.138043, Val Acc: 0.762887\n",
      "Epoch 11188 - Train Loss: 0.120471, Train Acc: 0.801282 | Val Loss: 0.138037, Val Acc: 0.762887\n",
      "Epoch 11189 - Train Loss: 0.120464, Train Acc: 0.801282 | Val Loss: 0.138032, Val Acc: 0.762887\n",
      "Epoch 11190 - Train Loss: 0.120457, Train Acc: 0.801282 | Val Loss: 0.138026, Val Acc: 0.762887\n",
      "Epoch 11191 - Train Loss: 0.120451, Train Acc: 0.801282 | Val Loss: 0.138020, Val Acc: 0.762887\n",
      "Epoch 11192 - Train Loss: 0.120444, Train Acc: 0.801282 | Val Loss: 0.138015, Val Acc: 0.762887\n",
      "Epoch 11193 - Train Loss: 0.120437, Train Acc: 0.801282 | Val Loss: 0.138009, Val Acc: 0.762887\n",
      "Epoch 11194 - Train Loss: 0.120430, Train Acc: 0.801282 | Val Loss: 0.138003, Val Acc: 0.762887\n",
      "Epoch 11195 - Train Loss: 0.120423, Train Acc: 0.801282 | Val Loss: 0.137998, Val Acc: 0.762887\n",
      "Epoch 11196 - Train Loss: 0.120416, Train Acc: 0.801282 | Val Loss: 0.137992, Val Acc: 0.762887\n",
      "Epoch 11197 - Train Loss: 0.120410, Train Acc: 0.801282 | Val Loss: 0.137986, Val Acc: 0.762887\n",
      "Epoch 11198 - Train Loss: 0.120403, Train Acc: 0.801282 | Val Loss: 0.137981, Val Acc: 0.762887\n",
      "Epoch 11199 - Train Loss: 0.120396, Train Acc: 0.801282 | Val Loss: 0.137975, Val Acc: 0.762887\n",
      "Epoch 11200 - Train Loss: 0.120389, Train Acc: 0.801282 | Val Loss: 0.137969, Val Acc: 0.762887\n",
      "Epoch 11201 - Train Loss: 0.120382, Train Acc: 0.801282 | Val Loss: 0.137964, Val Acc: 0.762887\n",
      "Epoch 11202 - Train Loss: 0.120375, Train Acc: 0.801282 | Val Loss: 0.137958, Val Acc: 0.762887\n",
      "Epoch 11203 - Train Loss: 0.120368, Train Acc: 0.802564 | Val Loss: 0.137952, Val Acc: 0.762887\n",
      "Epoch 11204 - Train Loss: 0.120362, Train Acc: 0.802564 | Val Loss: 0.137947, Val Acc: 0.762887\n",
      "Epoch 11205 - Train Loss: 0.120355, Train Acc: 0.802564 | Val Loss: 0.137941, Val Acc: 0.762887\n",
      "Epoch 11206 - Train Loss: 0.120348, Train Acc: 0.802564 | Val Loss: 0.137936, Val Acc: 0.762887\n",
      "Epoch 11207 - Train Loss: 0.120341, Train Acc: 0.802564 | Val Loss: 0.137930, Val Acc: 0.762887\n",
      "Epoch 11208 - Train Loss: 0.120334, Train Acc: 0.802564 | Val Loss: 0.137924, Val Acc: 0.762887\n",
      "Epoch 11209 - Train Loss: 0.120328, Train Acc: 0.802564 | Val Loss: 0.137919, Val Acc: 0.762887\n",
      "Epoch 11210 - Train Loss: 0.120321, Train Acc: 0.802564 | Val Loss: 0.137913, Val Acc: 0.762887\n",
      "Epoch 11211 - Train Loss: 0.120314, Train Acc: 0.802564 | Val Loss: 0.137907, Val Acc: 0.762887\n",
      "Epoch 11212 - Train Loss: 0.120307, Train Acc: 0.802564 | Val Loss: 0.137902, Val Acc: 0.762887\n",
      "Epoch 11213 - Train Loss: 0.120300, Train Acc: 0.802564 | Val Loss: 0.137896, Val Acc: 0.762887\n",
      "Epoch 11214 - Train Loss: 0.120293, Train Acc: 0.802564 | Val Loss: 0.137890, Val Acc: 0.762887\n",
      "Epoch 11215 - Train Loss: 0.120287, Train Acc: 0.802564 | Val Loss: 0.137885, Val Acc: 0.762887\n",
      "Epoch 11216 - Train Loss: 0.120280, Train Acc: 0.802564 | Val Loss: 0.137879, Val Acc: 0.762887\n",
      "Epoch 11217 - Train Loss: 0.120273, Train Acc: 0.802564 | Val Loss: 0.137874, Val Acc: 0.762887\n",
      "Epoch 11218 - Train Loss: 0.120266, Train Acc: 0.802564 | Val Loss: 0.137868, Val Acc: 0.762887\n",
      "Epoch 11219 - Train Loss: 0.120259, Train Acc: 0.802564 | Val Loss: 0.137862, Val Acc: 0.762887\n",
      "Epoch 11220 - Train Loss: 0.120252, Train Acc: 0.802564 | Val Loss: 0.137857, Val Acc: 0.762887\n",
      "Epoch 11221 - Train Loss: 0.120246, Train Acc: 0.802564 | Val Loss: 0.137851, Val Acc: 0.762887\n",
      "Epoch 11222 - Train Loss: 0.120239, Train Acc: 0.802564 | Val Loss: 0.137845, Val Acc: 0.762887\n",
      "Epoch 11223 - Train Loss: 0.120232, Train Acc: 0.802564 | Val Loss: 0.137840, Val Acc: 0.762887\n",
      "Epoch 11224 - Train Loss: 0.120225, Train Acc: 0.802564 | Val Loss: 0.137834, Val Acc: 0.762887\n",
      "Epoch 11225 - Train Loss: 0.120218, Train Acc: 0.802564 | Val Loss: 0.137829, Val Acc: 0.762887\n",
      "Epoch 11226 - Train Loss: 0.120212, Train Acc: 0.802564 | Val Loss: 0.137823, Val Acc: 0.762887\n",
      "Epoch 11227 - Train Loss: 0.120205, Train Acc: 0.802564 | Val Loss: 0.137817, Val Acc: 0.762887\n",
      "Epoch 11228 - Train Loss: 0.120198, Train Acc: 0.802564 | Val Loss: 0.137812, Val Acc: 0.762887\n",
      "Epoch 11229 - Train Loss: 0.120191, Train Acc: 0.802564 | Val Loss: 0.137806, Val Acc: 0.762887\n",
      "Epoch 11230 - Train Loss: 0.120184, Train Acc: 0.802564 | Val Loss: 0.137800, Val Acc: 0.762887\n",
      "Epoch 11231 - Train Loss: 0.120178, Train Acc: 0.802564 | Val Loss: 0.137795, Val Acc: 0.762887\n",
      "Epoch 11232 - Train Loss: 0.120171, Train Acc: 0.802564 | Val Loss: 0.137789, Val Acc: 0.762887\n",
      "Epoch 11233 - Train Loss: 0.120164, Train Acc: 0.802564 | Val Loss: 0.137784, Val Acc: 0.762887\n",
      "Epoch 11234 - Train Loss: 0.120157, Train Acc: 0.802564 | Val Loss: 0.137778, Val Acc: 0.762887\n",
      "Epoch 11235 - Train Loss: 0.120150, Train Acc: 0.802564 | Val Loss: 0.137772, Val Acc: 0.762887\n",
      "Epoch 11236 - Train Loss: 0.120144, Train Acc: 0.802564 | Val Loss: 0.137767, Val Acc: 0.762887\n",
      "Epoch 11237 - Train Loss: 0.120137, Train Acc: 0.802564 | Val Loss: 0.137761, Val Acc: 0.762887\n",
      "Epoch 11238 - Train Loss: 0.120130, Train Acc: 0.802564 | Val Loss: 0.137756, Val Acc: 0.762887\n",
      "Epoch 11239 - Train Loss: 0.120123, Train Acc: 0.802564 | Val Loss: 0.137750, Val Acc: 0.762887\n",
      "Epoch 11240 - Train Loss: 0.120116, Train Acc: 0.802564 | Val Loss: 0.137744, Val Acc: 0.762887\n",
      "Epoch 11241 - Train Loss: 0.120110, Train Acc: 0.802564 | Val Loss: 0.137739, Val Acc: 0.762887\n",
      "Epoch 11242 - Train Loss: 0.120103, Train Acc: 0.802564 | Val Loss: 0.137733, Val Acc: 0.762887\n",
      "Epoch 11243 - Train Loss: 0.120096, Train Acc: 0.802564 | Val Loss: 0.137728, Val Acc: 0.762887\n",
      "Epoch 11244 - Train Loss: 0.120089, Train Acc: 0.802564 | Val Loss: 0.137722, Val Acc: 0.762887\n",
      "Epoch 11245 - Train Loss: 0.120083, Train Acc: 0.802564 | Val Loss: 0.137716, Val Acc: 0.762887\n",
      "Epoch 11246 - Train Loss: 0.120076, Train Acc: 0.802564 | Val Loss: 0.137711, Val Acc: 0.762887\n",
      "Epoch 11247 - Train Loss: 0.120069, Train Acc: 0.802564 | Val Loss: 0.137705, Val Acc: 0.762887\n",
      "Epoch 11248 - Train Loss: 0.120062, Train Acc: 0.802564 | Val Loss: 0.137700, Val Acc: 0.762887\n",
      "Epoch 11249 - Train Loss: 0.120055, Train Acc: 0.802564 | Val Loss: 0.137694, Val Acc: 0.762887\n",
      "Epoch 11250 - Train Loss: 0.120049, Train Acc: 0.802564 | Val Loss: 0.137689, Val Acc: 0.762887\n",
      "Epoch 11251 - Train Loss: 0.120042, Train Acc: 0.802564 | Val Loss: 0.137683, Val Acc: 0.762887\n",
      "Epoch 11252 - Train Loss: 0.120035, Train Acc: 0.802564 | Val Loss: 0.137677, Val Acc: 0.762887\n",
      "Epoch 11253 - Train Loss: 0.120028, Train Acc: 0.802564 | Val Loss: 0.137672, Val Acc: 0.762887\n",
      "Epoch 11254 - Train Loss: 0.120022, Train Acc: 0.802564 | Val Loss: 0.137666, Val Acc: 0.762887\n",
      "Epoch 11255 - Train Loss: 0.120015, Train Acc: 0.802564 | Val Loss: 0.137661, Val Acc: 0.762887\n",
      "Epoch 11256 - Train Loss: 0.120008, Train Acc: 0.802564 | Val Loss: 0.137655, Val Acc: 0.762887\n",
      "Epoch 11257 - Train Loss: 0.120001, Train Acc: 0.802564 | Val Loss: 0.137649, Val Acc: 0.762887\n",
      "Epoch 11258 - Train Loss: 0.119994, Train Acc: 0.803846 | Val Loss: 0.137644, Val Acc: 0.762887\n",
      "Epoch 11259 - Train Loss: 0.119988, Train Acc: 0.803846 | Val Loss: 0.137638, Val Acc: 0.762887\n",
      "Epoch 11260 - Train Loss: 0.119981, Train Acc: 0.803846 | Val Loss: 0.137633, Val Acc: 0.762887\n",
      "Epoch 11261 - Train Loss: 0.119974, Train Acc: 0.803846 | Val Loss: 0.137627, Val Acc: 0.762887\n",
      "Epoch 11262 - Train Loss: 0.119967, Train Acc: 0.803846 | Val Loss: 0.137622, Val Acc: 0.762887\n",
      "Epoch 11263 - Train Loss: 0.119961, Train Acc: 0.803846 | Val Loss: 0.137616, Val Acc: 0.762887\n",
      "Epoch 11264 - Train Loss: 0.119954, Train Acc: 0.803846 | Val Loss: 0.137610, Val Acc: 0.762887\n",
      "Epoch 11265 - Train Loss: 0.119947, Train Acc: 0.803846 | Val Loss: 0.137605, Val Acc: 0.762887\n",
      "Epoch 11266 - Train Loss: 0.119940, Train Acc: 0.803846 | Val Loss: 0.137599, Val Acc: 0.762887\n",
      "Epoch 11267 - Train Loss: 0.119934, Train Acc: 0.803846 | Val Loss: 0.137594, Val Acc: 0.762887\n",
      "Epoch 11268 - Train Loss: 0.119927, Train Acc: 0.803846 | Val Loss: 0.137588, Val Acc: 0.762887\n",
      "Epoch 11269 - Train Loss: 0.119920, Train Acc: 0.803846 | Val Loss: 0.137583, Val Acc: 0.762887\n",
      "Epoch 11270 - Train Loss: 0.119913, Train Acc: 0.803846 | Val Loss: 0.137577, Val Acc: 0.762887\n",
      "Epoch 11271 - Train Loss: 0.119907, Train Acc: 0.803846 | Val Loss: 0.137571, Val Acc: 0.762887\n",
      "Epoch 11272 - Train Loss: 0.119900, Train Acc: 0.803846 | Val Loss: 0.137566, Val Acc: 0.762887\n",
      "Epoch 11273 - Train Loss: 0.119893, Train Acc: 0.803846 | Val Loss: 0.137560, Val Acc: 0.762887\n",
      "Epoch 11274 - Train Loss: 0.119886, Train Acc: 0.803846 | Val Loss: 0.137555, Val Acc: 0.762887\n",
      "Epoch 11275 - Train Loss: 0.119880, Train Acc: 0.803846 | Val Loss: 0.137549, Val Acc: 0.762887\n",
      "Epoch 11276 - Train Loss: 0.119873, Train Acc: 0.803846 | Val Loss: 0.137544, Val Acc: 0.762887\n",
      "Epoch 11277 - Train Loss: 0.119866, Train Acc: 0.803846 | Val Loss: 0.137538, Val Acc: 0.762887\n",
      "Epoch 11278 - Train Loss: 0.119859, Train Acc: 0.803846 | Val Loss: 0.137532, Val Acc: 0.762887\n",
      "Epoch 11279 - Train Loss: 0.119853, Train Acc: 0.803846 | Val Loss: 0.137527, Val Acc: 0.762887\n",
      "Epoch 11280 - Train Loss: 0.119846, Train Acc: 0.803846 | Val Loss: 0.137521, Val Acc: 0.762887\n",
      "Epoch 11281 - Train Loss: 0.119839, Train Acc: 0.803846 | Val Loss: 0.137516, Val Acc: 0.762887\n",
      "Epoch 11282 - Train Loss: 0.119832, Train Acc: 0.803846 | Val Loss: 0.137510, Val Acc: 0.762887\n",
      "Epoch 11283 - Train Loss: 0.119826, Train Acc: 0.803846 | Val Loss: 0.137505, Val Acc: 0.762887\n",
      "Epoch 11284 - Train Loss: 0.119819, Train Acc: 0.803846 | Val Loss: 0.137499, Val Acc: 0.762887\n",
      "Epoch 11285 - Train Loss: 0.119812, Train Acc: 0.803846 | Val Loss: 0.137494, Val Acc: 0.762887\n",
      "Epoch 11286 - Train Loss: 0.119805, Train Acc: 0.803846 | Val Loss: 0.137488, Val Acc: 0.762887\n",
      "Epoch 11287 - Train Loss: 0.119799, Train Acc: 0.803846 | Val Loss: 0.137483, Val Acc: 0.762887\n",
      "Epoch 11288 - Train Loss: 0.119792, Train Acc: 0.803846 | Val Loss: 0.137477, Val Acc: 0.762887\n",
      "Epoch 11289 - Train Loss: 0.119785, Train Acc: 0.803846 | Val Loss: 0.137471, Val Acc: 0.762887\n",
      "Epoch 11290 - Train Loss: 0.119778, Train Acc: 0.803846 | Val Loss: 0.137466, Val Acc: 0.762887\n",
      "Epoch 11291 - Train Loss: 0.119772, Train Acc: 0.803846 | Val Loss: 0.137460, Val Acc: 0.762887\n",
      "Epoch 11292 - Train Loss: 0.119765, Train Acc: 0.803846 | Val Loss: 0.137455, Val Acc: 0.762887\n",
      "Epoch 11293 - Train Loss: 0.119758, Train Acc: 0.803846 | Val Loss: 0.137449, Val Acc: 0.762887\n",
      "Epoch 11294 - Train Loss: 0.119752, Train Acc: 0.803846 | Val Loss: 0.137444, Val Acc: 0.762887\n",
      "Epoch 11295 - Train Loss: 0.119745, Train Acc: 0.803846 | Val Loss: 0.137438, Val Acc: 0.762887\n",
      "Epoch 11296 - Train Loss: 0.119738, Train Acc: 0.803846 | Val Loss: 0.137433, Val Acc: 0.762887\n",
      "Epoch 11297 - Train Loss: 0.119731, Train Acc: 0.803846 | Val Loss: 0.137427, Val Acc: 0.762887\n",
      "Epoch 11298 - Train Loss: 0.119725, Train Acc: 0.803846 | Val Loss: 0.137422, Val Acc: 0.762887\n",
      "Epoch 11299 - Train Loss: 0.119718, Train Acc: 0.805128 | Val Loss: 0.137416, Val Acc: 0.762887\n",
      "Epoch 11300 - Train Loss: 0.119711, Train Acc: 0.805128 | Val Loss: 0.137411, Val Acc: 0.762887\n",
      "Epoch 11301 - Train Loss: 0.119704, Train Acc: 0.805128 | Val Loss: 0.137405, Val Acc: 0.762887\n",
      "Epoch 11302 - Train Loss: 0.119698, Train Acc: 0.805128 | Val Loss: 0.137400, Val Acc: 0.762887\n",
      "Epoch 11303 - Train Loss: 0.119691, Train Acc: 0.805128 | Val Loss: 0.137394, Val Acc: 0.762887\n",
      "Epoch 11304 - Train Loss: 0.119684, Train Acc: 0.805128 | Val Loss: 0.137388, Val Acc: 0.762887\n",
      "Epoch 11305 - Train Loss: 0.119678, Train Acc: 0.805128 | Val Loss: 0.137383, Val Acc: 0.762887\n",
      "Epoch 11306 - Train Loss: 0.119671, Train Acc: 0.805128 | Val Loss: 0.137377, Val Acc: 0.762887\n",
      "Epoch 11307 - Train Loss: 0.119664, Train Acc: 0.805128 | Val Loss: 0.137372, Val Acc: 0.762887\n",
      "Epoch 11308 - Train Loss: 0.119657, Train Acc: 0.805128 | Val Loss: 0.137366, Val Acc: 0.762887\n",
      "Epoch 11309 - Train Loss: 0.119651, Train Acc: 0.805128 | Val Loss: 0.137361, Val Acc: 0.762887\n",
      "Epoch 11310 - Train Loss: 0.119644, Train Acc: 0.805128 | Val Loss: 0.137355, Val Acc: 0.762887\n",
      "Epoch 11311 - Train Loss: 0.119637, Train Acc: 0.805128 | Val Loss: 0.137350, Val Acc: 0.762887\n",
      "Epoch 11312 - Train Loss: 0.119631, Train Acc: 0.805128 | Val Loss: 0.137344, Val Acc: 0.762887\n",
      "Epoch 11313 - Train Loss: 0.119624, Train Acc: 0.805128 | Val Loss: 0.137339, Val Acc: 0.762887\n",
      "Epoch 11314 - Train Loss: 0.119617, Train Acc: 0.805128 | Val Loss: 0.137333, Val Acc: 0.762887\n",
      "Epoch 11315 - Train Loss: 0.119611, Train Acc: 0.805128 | Val Loss: 0.137328, Val Acc: 0.762887\n",
      "Epoch 11316 - Train Loss: 0.119604, Train Acc: 0.805128 | Val Loss: 0.137322, Val Acc: 0.762887\n",
      "Epoch 11317 - Train Loss: 0.119597, Train Acc: 0.805128 | Val Loss: 0.137317, Val Acc: 0.762887\n",
      "Epoch 11318 - Train Loss: 0.119590, Train Acc: 0.805128 | Val Loss: 0.137311, Val Acc: 0.762887\n",
      "Epoch 11319 - Train Loss: 0.119584, Train Acc: 0.805128 | Val Loss: 0.137306, Val Acc: 0.762887\n",
      "Epoch 11320 - Train Loss: 0.119577, Train Acc: 0.805128 | Val Loss: 0.137300, Val Acc: 0.762887\n",
      "Epoch 11321 - Train Loss: 0.119570, Train Acc: 0.805128 | Val Loss: 0.137295, Val Acc: 0.762887\n",
      "Epoch 11322 - Train Loss: 0.119564, Train Acc: 0.805128 | Val Loss: 0.137289, Val Acc: 0.762887\n",
      "Epoch 11323 - Train Loss: 0.119557, Train Acc: 0.805128 | Val Loss: 0.137284, Val Acc: 0.762887\n",
      "Epoch 11324 - Train Loss: 0.119550, Train Acc: 0.805128 | Val Loss: 0.137278, Val Acc: 0.762887\n",
      "Epoch 11325 - Train Loss: 0.119544, Train Acc: 0.805128 | Val Loss: 0.137273, Val Acc: 0.762887\n",
      "Epoch 11326 - Train Loss: 0.119537, Train Acc: 0.805128 | Val Loss: 0.137267, Val Acc: 0.762887\n",
      "Epoch 11327 - Train Loss: 0.119530, Train Acc: 0.805128 | Val Loss: 0.137262, Val Acc: 0.762887\n",
      "Epoch 11328 - Train Loss: 0.119523, Train Acc: 0.805128 | Val Loss: 0.137256, Val Acc: 0.762887\n",
      "Epoch 11329 - Train Loss: 0.119517, Train Acc: 0.805128 | Val Loss: 0.137251, Val Acc: 0.762887\n",
      "Epoch 11330 - Train Loss: 0.119510, Train Acc: 0.805128 | Val Loss: 0.137245, Val Acc: 0.762887\n",
      "Epoch 11331 - Train Loss: 0.119503, Train Acc: 0.805128 | Val Loss: 0.137240, Val Acc: 0.762887\n",
      "Epoch 11332 - Train Loss: 0.119497, Train Acc: 0.805128 | Val Loss: 0.137234, Val Acc: 0.762887\n",
      "Epoch 11333 - Train Loss: 0.119490, Train Acc: 0.805128 | Val Loss: 0.137229, Val Acc: 0.762887\n",
      "Epoch 11334 - Train Loss: 0.119483, Train Acc: 0.805128 | Val Loss: 0.137223, Val Acc: 0.762887\n",
      "Epoch 11335 - Train Loss: 0.119477, Train Acc: 0.805128 | Val Loss: 0.137218, Val Acc: 0.762887\n",
      "Epoch 11336 - Train Loss: 0.119470, Train Acc: 0.805128 | Val Loss: 0.137212, Val Acc: 0.762887\n",
      "Epoch 11337 - Train Loss: 0.119463, Train Acc: 0.805128 | Val Loss: 0.137207, Val Acc: 0.762887\n",
      "Epoch 11338 - Train Loss: 0.119457, Train Acc: 0.805128 | Val Loss: 0.137201, Val Acc: 0.762887\n",
      "Epoch 11339 - Train Loss: 0.119450, Train Acc: 0.805128 | Val Loss: 0.137196, Val Acc: 0.762887\n",
      "Epoch 11340 - Train Loss: 0.119443, Train Acc: 0.805128 | Val Loss: 0.137190, Val Acc: 0.762887\n",
      "Epoch 11341 - Train Loss: 0.119437, Train Acc: 0.805128 | Val Loss: 0.137185, Val Acc: 0.762887\n",
      "Epoch 11342 - Train Loss: 0.119430, Train Acc: 0.805128 | Val Loss: 0.137179, Val Acc: 0.762887\n",
      "Epoch 11343 - Train Loss: 0.119423, Train Acc: 0.805128 | Val Loss: 0.137174, Val Acc: 0.762887\n",
      "Epoch 11344 - Train Loss: 0.119417, Train Acc: 0.805128 | Val Loss: 0.137168, Val Acc: 0.762887\n",
      "Epoch 11345 - Train Loss: 0.119410, Train Acc: 0.805128 | Val Loss: 0.137163, Val Acc: 0.762887\n",
      "Epoch 11346 - Train Loss: 0.119403, Train Acc: 0.805128 | Val Loss: 0.137158, Val Acc: 0.762887\n",
      "Epoch 11347 - Train Loss: 0.119397, Train Acc: 0.805128 | Val Loss: 0.137152, Val Acc: 0.762887\n",
      "Epoch 11348 - Train Loss: 0.119390, Train Acc: 0.805128 | Val Loss: 0.137147, Val Acc: 0.762887\n",
      "Epoch 11349 - Train Loss: 0.119383, Train Acc: 0.805128 | Val Loss: 0.137141, Val Acc: 0.762887\n",
      "Epoch 11350 - Train Loss: 0.119377, Train Acc: 0.805128 | Val Loss: 0.137136, Val Acc: 0.762887\n",
      "Epoch 11351 - Train Loss: 0.119370, Train Acc: 0.805128 | Val Loss: 0.137130, Val Acc: 0.762887\n",
      "Epoch 11352 - Train Loss: 0.119363, Train Acc: 0.805128 | Val Loss: 0.137125, Val Acc: 0.762887\n",
      "Epoch 11353 - Train Loss: 0.119357, Train Acc: 0.805128 | Val Loss: 0.137119, Val Acc: 0.762887\n",
      "Epoch 11354 - Train Loss: 0.119350, Train Acc: 0.805128 | Val Loss: 0.137114, Val Acc: 0.762887\n",
      "Epoch 11355 - Train Loss: 0.119343, Train Acc: 0.805128 | Val Loss: 0.137108, Val Acc: 0.762887\n",
      "Epoch 11356 - Train Loss: 0.119337, Train Acc: 0.805128 | Val Loss: 0.137103, Val Acc: 0.762887\n",
      "Epoch 11357 - Train Loss: 0.119330, Train Acc: 0.805128 | Val Loss: 0.137097, Val Acc: 0.762887\n",
      "Epoch 11358 - Train Loss: 0.119323, Train Acc: 0.805128 | Val Loss: 0.137092, Val Acc: 0.762887\n",
      "Epoch 11359 - Train Loss: 0.119317, Train Acc: 0.805128 | Val Loss: 0.137086, Val Acc: 0.762887\n",
      "Epoch 11360 - Train Loss: 0.119310, Train Acc: 0.805128 | Val Loss: 0.137081, Val Acc: 0.762887\n",
      "Epoch 11361 - Train Loss: 0.119303, Train Acc: 0.805128 | Val Loss: 0.137076, Val Acc: 0.762887\n",
      "Epoch 11362 - Train Loss: 0.119297, Train Acc: 0.805128 | Val Loss: 0.137070, Val Acc: 0.762887\n",
      "Epoch 11363 - Train Loss: 0.119290, Train Acc: 0.805128 | Val Loss: 0.137065, Val Acc: 0.762887\n",
      "Epoch 11364 - Train Loss: 0.119283, Train Acc: 0.805128 | Val Loss: 0.137059, Val Acc: 0.762887\n",
      "Epoch 11365 - Train Loss: 0.119277, Train Acc: 0.805128 | Val Loss: 0.137054, Val Acc: 0.762887\n",
      "Epoch 11366 - Train Loss: 0.119270, Train Acc: 0.805128 | Val Loss: 0.137048, Val Acc: 0.762887\n",
      "Epoch 11367 - Train Loss: 0.119264, Train Acc: 0.805128 | Val Loss: 0.137043, Val Acc: 0.762887\n",
      "Epoch 11368 - Train Loss: 0.119257, Train Acc: 0.805128 | Val Loss: 0.137037, Val Acc: 0.762887\n",
      "Epoch 11369 - Train Loss: 0.119250, Train Acc: 0.805128 | Val Loss: 0.137032, Val Acc: 0.762887\n",
      "Epoch 11370 - Train Loss: 0.119244, Train Acc: 0.806410 | Val Loss: 0.137026, Val Acc: 0.762887\n",
      "Epoch 11371 - Train Loss: 0.119237, Train Acc: 0.806410 | Val Loss: 0.137021, Val Acc: 0.762887\n",
      "Epoch 11372 - Train Loss: 0.119230, Train Acc: 0.806410 | Val Loss: 0.137016, Val Acc: 0.762887\n",
      "Epoch 11373 - Train Loss: 0.119224, Train Acc: 0.806410 | Val Loss: 0.137010, Val Acc: 0.762887\n",
      "Epoch 11374 - Train Loss: 0.119217, Train Acc: 0.806410 | Val Loss: 0.137005, Val Acc: 0.762887\n",
      "Epoch 11375 - Train Loss: 0.119210, Train Acc: 0.806410 | Val Loss: 0.136999, Val Acc: 0.762887\n",
      "Epoch 11376 - Train Loss: 0.119204, Train Acc: 0.806410 | Val Loss: 0.136994, Val Acc: 0.762887\n",
      "Epoch 11377 - Train Loss: 0.119197, Train Acc: 0.806410 | Val Loss: 0.136988, Val Acc: 0.762887\n",
      "Epoch 11378 - Train Loss: 0.119191, Train Acc: 0.806410 | Val Loss: 0.136983, Val Acc: 0.762887\n",
      "Epoch 11379 - Train Loss: 0.119184, Train Acc: 0.806410 | Val Loss: 0.136978, Val Acc: 0.762887\n",
      "Epoch 11380 - Train Loss: 0.119177, Train Acc: 0.806410 | Val Loss: 0.136972, Val Acc: 0.762887\n",
      "Epoch 11381 - Train Loss: 0.119171, Train Acc: 0.806410 | Val Loss: 0.136967, Val Acc: 0.762887\n",
      "Epoch 11382 - Train Loss: 0.119164, Train Acc: 0.806410 | Val Loss: 0.136961, Val Acc: 0.762887\n",
      "Epoch 11383 - Train Loss: 0.119157, Train Acc: 0.806410 | Val Loss: 0.136956, Val Acc: 0.762887\n",
      "Epoch 11384 - Train Loss: 0.119151, Train Acc: 0.806410 | Val Loss: 0.136950, Val Acc: 0.762887\n",
      "Epoch 11385 - Train Loss: 0.119144, Train Acc: 0.806410 | Val Loss: 0.136945, Val Acc: 0.762887\n",
      "Epoch 11386 - Train Loss: 0.119137, Train Acc: 0.806410 | Val Loss: 0.136939, Val Acc: 0.762887\n",
      "Epoch 11387 - Train Loss: 0.119131, Train Acc: 0.806410 | Val Loss: 0.136934, Val Acc: 0.762887\n",
      "Epoch 11388 - Train Loss: 0.119124, Train Acc: 0.806410 | Val Loss: 0.136929, Val Acc: 0.762887\n",
      "Epoch 11389 - Train Loss: 0.119118, Train Acc: 0.806410 | Val Loss: 0.136923, Val Acc: 0.762887\n",
      "Epoch 11390 - Train Loss: 0.119111, Train Acc: 0.806410 | Val Loss: 0.136918, Val Acc: 0.762887\n",
      "Epoch 11391 - Train Loss: 0.119104, Train Acc: 0.806410 | Val Loss: 0.136912, Val Acc: 0.762887\n",
      "Epoch 11392 - Train Loss: 0.119098, Train Acc: 0.806410 | Val Loss: 0.136907, Val Acc: 0.762887\n",
      "Epoch 11393 - Train Loss: 0.119091, Train Acc: 0.806410 | Val Loss: 0.136902, Val Acc: 0.762887\n",
      "Epoch 11394 - Train Loss: 0.119085, Train Acc: 0.806410 | Val Loss: 0.136896, Val Acc: 0.762887\n",
      "Epoch 11395 - Train Loss: 0.119078, Train Acc: 0.806410 | Val Loss: 0.136891, Val Acc: 0.762887\n",
      "Epoch 11396 - Train Loss: 0.119071, Train Acc: 0.806410 | Val Loss: 0.136885, Val Acc: 0.762887\n",
      "Epoch 11397 - Train Loss: 0.119065, Train Acc: 0.806410 | Val Loss: 0.136880, Val Acc: 0.762887\n",
      "Epoch 11398 - Train Loss: 0.119058, Train Acc: 0.806410 | Val Loss: 0.136874, Val Acc: 0.762887\n",
      "Epoch 11399 - Train Loss: 0.119052, Train Acc: 0.806410 | Val Loss: 0.136869, Val Acc: 0.762887\n",
      "Epoch 11400 - Train Loss: 0.119045, Train Acc: 0.806410 | Val Loss: 0.136864, Val Acc: 0.762887\n",
      "Epoch 11401 - Train Loss: 0.119038, Train Acc: 0.806410 | Val Loss: 0.136858, Val Acc: 0.762887\n",
      "Epoch 11402 - Train Loss: 0.119032, Train Acc: 0.806410 | Val Loss: 0.136853, Val Acc: 0.762887\n",
      "Epoch 11403 - Train Loss: 0.119025, Train Acc: 0.806410 | Val Loss: 0.136847, Val Acc: 0.762887\n",
      "Epoch 11404 - Train Loss: 0.119018, Train Acc: 0.806410 | Val Loss: 0.136842, Val Acc: 0.762887\n",
      "Epoch 11405 - Train Loss: 0.119012, Train Acc: 0.806410 | Val Loss: 0.136837, Val Acc: 0.762887\n",
      "Epoch 11406 - Train Loss: 0.119005, Train Acc: 0.806410 | Val Loss: 0.136831, Val Acc: 0.762887\n",
      "Epoch 11407 - Train Loss: 0.118999, Train Acc: 0.807692 | Val Loss: 0.136826, Val Acc: 0.762887\n",
      "Epoch 11408 - Train Loss: 0.118992, Train Acc: 0.807692 | Val Loss: 0.136820, Val Acc: 0.762887\n",
      "Epoch 11409 - Train Loss: 0.118985, Train Acc: 0.807692 | Val Loss: 0.136815, Val Acc: 0.762887\n",
      "Epoch 11410 - Train Loss: 0.118979, Train Acc: 0.807692 | Val Loss: 0.136810, Val Acc: 0.762887\n",
      "Epoch 11411 - Train Loss: 0.118972, Train Acc: 0.807692 | Val Loss: 0.136804, Val Acc: 0.762887\n",
      "Epoch 11412 - Train Loss: 0.118966, Train Acc: 0.807692 | Val Loss: 0.136799, Val Acc: 0.762887\n",
      "Epoch 11413 - Train Loss: 0.118959, Train Acc: 0.807692 | Val Loss: 0.136793, Val Acc: 0.762887\n",
      "Epoch 11414 - Train Loss: 0.118953, Train Acc: 0.807692 | Val Loss: 0.136788, Val Acc: 0.762887\n",
      "Epoch 11415 - Train Loss: 0.118946, Train Acc: 0.807692 | Val Loss: 0.136783, Val Acc: 0.762887\n",
      "Epoch 11416 - Train Loss: 0.118939, Train Acc: 0.807692 | Val Loss: 0.136777, Val Acc: 0.762887\n",
      "Epoch 11417 - Train Loss: 0.118933, Train Acc: 0.807692 | Val Loss: 0.136772, Val Acc: 0.762887\n",
      "Epoch 11418 - Train Loss: 0.118926, Train Acc: 0.807692 | Val Loss: 0.136766, Val Acc: 0.762887\n",
      "Epoch 11419 - Train Loss: 0.118920, Train Acc: 0.807692 | Val Loss: 0.136761, Val Acc: 0.762887\n",
      "Epoch 11420 - Train Loss: 0.118913, Train Acc: 0.807692 | Val Loss: 0.136756, Val Acc: 0.762887\n",
      "Epoch 11421 - Train Loss: 0.118906, Train Acc: 0.807692 | Val Loss: 0.136750, Val Acc: 0.762887\n",
      "Epoch 11422 - Train Loss: 0.118900, Train Acc: 0.807692 | Val Loss: 0.136745, Val Acc: 0.762887\n",
      "Epoch 11423 - Train Loss: 0.118893, Train Acc: 0.807692 | Val Loss: 0.136739, Val Acc: 0.762887\n",
      "Epoch 11424 - Train Loss: 0.118887, Train Acc: 0.807692 | Val Loss: 0.136734, Val Acc: 0.762887\n",
      "Epoch 11425 - Train Loss: 0.118880, Train Acc: 0.807692 | Val Loss: 0.136729, Val Acc: 0.762887\n",
      "Epoch 11426 - Train Loss: 0.118874, Train Acc: 0.807692 | Val Loss: 0.136723, Val Acc: 0.762887\n",
      "Epoch 11427 - Train Loss: 0.118867, Train Acc: 0.807692 | Val Loss: 0.136718, Val Acc: 0.762887\n",
      "Epoch 11428 - Train Loss: 0.118860, Train Acc: 0.807692 | Val Loss: 0.136713, Val Acc: 0.762887\n",
      "Epoch 11429 - Train Loss: 0.118854, Train Acc: 0.807692 | Val Loss: 0.136707, Val Acc: 0.762887\n",
      "Epoch 11430 - Train Loss: 0.118847, Train Acc: 0.807692 | Val Loss: 0.136702, Val Acc: 0.762887\n",
      "Epoch 11431 - Train Loss: 0.118841, Train Acc: 0.807692 | Val Loss: 0.136696, Val Acc: 0.762887\n",
      "Epoch 11432 - Train Loss: 0.118834, Train Acc: 0.807692 | Val Loss: 0.136691, Val Acc: 0.762887\n",
      "Epoch 11433 - Train Loss: 0.118828, Train Acc: 0.807692 | Val Loss: 0.136686, Val Acc: 0.762887\n",
      "Epoch 11434 - Train Loss: 0.118821, Train Acc: 0.807692 | Val Loss: 0.136680, Val Acc: 0.762887\n",
      "Epoch 11435 - Train Loss: 0.118814, Train Acc: 0.807692 | Val Loss: 0.136675, Val Acc: 0.762887\n",
      "Epoch 11436 - Train Loss: 0.118808, Train Acc: 0.807692 | Val Loss: 0.136670, Val Acc: 0.762887\n",
      "Epoch 11437 - Train Loss: 0.118801, Train Acc: 0.807692 | Val Loss: 0.136664, Val Acc: 0.762887\n",
      "Epoch 11438 - Train Loss: 0.118795, Train Acc: 0.807692 | Val Loss: 0.136659, Val Acc: 0.762887\n",
      "Epoch 11439 - Train Loss: 0.118788, Train Acc: 0.807692 | Val Loss: 0.136653, Val Acc: 0.762887\n",
      "Epoch 11440 - Train Loss: 0.118782, Train Acc: 0.807692 | Val Loss: 0.136648, Val Acc: 0.762887\n",
      "Epoch 11441 - Train Loss: 0.118775, Train Acc: 0.807692 | Val Loss: 0.136643, Val Acc: 0.762887\n",
      "Epoch 11442 - Train Loss: 0.118768, Train Acc: 0.807692 | Val Loss: 0.136637, Val Acc: 0.762887\n",
      "Epoch 11443 - Train Loss: 0.118762, Train Acc: 0.807692 | Val Loss: 0.136632, Val Acc: 0.762887\n",
      "Epoch 11444 - Train Loss: 0.118755, Train Acc: 0.807692 | Val Loss: 0.136627, Val Acc: 0.762887\n",
      "Epoch 11445 - Train Loss: 0.118749, Train Acc: 0.807692 | Val Loss: 0.136621, Val Acc: 0.762887\n",
      "Epoch 11446 - Train Loss: 0.118742, Train Acc: 0.807692 | Val Loss: 0.136616, Val Acc: 0.762887\n",
      "Epoch 11447 - Train Loss: 0.118736, Train Acc: 0.807692 | Val Loss: 0.136611, Val Acc: 0.762887\n",
      "Epoch 11448 - Train Loss: 0.118729, Train Acc: 0.808974 | Val Loss: 0.136605, Val Acc: 0.762887\n",
      "Epoch 11449 - Train Loss: 0.118723, Train Acc: 0.808974 | Val Loss: 0.136600, Val Acc: 0.762887\n",
      "Epoch 11450 - Train Loss: 0.118716, Train Acc: 0.808974 | Val Loss: 0.136595, Val Acc: 0.762887\n",
      "Epoch 11451 - Train Loss: 0.118709, Train Acc: 0.808974 | Val Loss: 0.136589, Val Acc: 0.762887\n",
      "Epoch 11452 - Train Loss: 0.118703, Train Acc: 0.808974 | Val Loss: 0.136584, Val Acc: 0.762887\n",
      "Epoch 11453 - Train Loss: 0.118696, Train Acc: 0.808974 | Val Loss: 0.136578, Val Acc: 0.762887\n",
      "Epoch 11454 - Train Loss: 0.118690, Train Acc: 0.808974 | Val Loss: 0.136573, Val Acc: 0.762887\n",
      "Epoch 11455 - Train Loss: 0.118683, Train Acc: 0.808974 | Val Loss: 0.136568, Val Acc: 0.762887\n",
      "Epoch 11456 - Train Loss: 0.118677, Train Acc: 0.808974 | Val Loss: 0.136562, Val Acc: 0.762887\n",
      "Epoch 11457 - Train Loss: 0.118670, Train Acc: 0.808974 | Val Loss: 0.136557, Val Acc: 0.762887\n",
      "Epoch 11458 - Train Loss: 0.118664, Train Acc: 0.808974 | Val Loss: 0.136552, Val Acc: 0.762887\n",
      "Epoch 11459 - Train Loss: 0.118657, Train Acc: 0.808974 | Val Loss: 0.136546, Val Acc: 0.762887\n",
      "Epoch 11460 - Train Loss: 0.118651, Train Acc: 0.808974 | Val Loss: 0.136541, Val Acc: 0.762887\n",
      "Epoch 11461 - Train Loss: 0.118644, Train Acc: 0.808974 | Val Loss: 0.136536, Val Acc: 0.762887\n",
      "Epoch 11462 - Train Loss: 0.118637, Train Acc: 0.808974 | Val Loss: 0.136530, Val Acc: 0.762887\n",
      "Epoch 11463 - Train Loss: 0.118631, Train Acc: 0.808974 | Val Loss: 0.136525, Val Acc: 0.762887\n",
      "Epoch 11464 - Train Loss: 0.118624, Train Acc: 0.808974 | Val Loss: 0.136520, Val Acc: 0.762887\n",
      "Epoch 11465 - Train Loss: 0.118618, Train Acc: 0.808974 | Val Loss: 0.136514, Val Acc: 0.762887\n",
      "Epoch 11466 - Train Loss: 0.118611, Train Acc: 0.808974 | Val Loss: 0.136509, Val Acc: 0.762887\n",
      "Epoch 11467 - Train Loss: 0.118605, Train Acc: 0.808974 | Val Loss: 0.136504, Val Acc: 0.762887\n",
      "Epoch 11468 - Train Loss: 0.118598, Train Acc: 0.808974 | Val Loss: 0.136498, Val Acc: 0.762887\n",
      "Epoch 11469 - Train Loss: 0.118592, Train Acc: 0.808974 | Val Loss: 0.136493, Val Acc: 0.762887\n",
      "Epoch 11470 - Train Loss: 0.118585, Train Acc: 0.808974 | Val Loss: 0.136488, Val Acc: 0.762887\n",
      "Epoch 11471 - Train Loss: 0.118579, Train Acc: 0.808974 | Val Loss: 0.136482, Val Acc: 0.762887\n",
      "Epoch 11472 - Train Loss: 0.118572, Train Acc: 0.808974 | Val Loss: 0.136477, Val Acc: 0.762887\n",
      "Epoch 11473 - Train Loss: 0.118566, Train Acc: 0.808974 | Val Loss: 0.136472, Val Acc: 0.762887\n",
      "Epoch 11474 - Train Loss: 0.118559, Train Acc: 0.808974 | Val Loss: 0.136466, Val Acc: 0.762887\n",
      "Epoch 11475 - Train Loss: 0.118553, Train Acc: 0.808974 | Val Loss: 0.136461, Val Acc: 0.762887\n",
      "Epoch 11476 - Train Loss: 0.118546, Train Acc: 0.808974 | Val Loss: 0.136456, Val Acc: 0.762887\n",
      "Epoch 11477 - Train Loss: 0.118540, Train Acc: 0.808974 | Val Loss: 0.136450, Val Acc: 0.762887\n",
      "Epoch 11478 - Train Loss: 0.118533, Train Acc: 0.808974 | Val Loss: 0.136445, Val Acc: 0.762887\n",
      "Epoch 11479 - Train Loss: 0.118527, Train Acc: 0.808974 | Val Loss: 0.136440, Val Acc: 0.762887\n",
      "Epoch 11480 - Train Loss: 0.118520, Train Acc: 0.808974 | Val Loss: 0.136435, Val Acc: 0.762887\n",
      "Epoch 11481 - Train Loss: 0.118514, Train Acc: 0.808974 | Val Loss: 0.136429, Val Acc: 0.762887\n",
      "Epoch 11482 - Train Loss: 0.118507, Train Acc: 0.808974 | Val Loss: 0.136424, Val Acc: 0.762887\n",
      "Epoch 11483 - Train Loss: 0.118501, Train Acc: 0.808974 | Val Loss: 0.136419, Val Acc: 0.762887\n",
      "Epoch 11484 - Train Loss: 0.118494, Train Acc: 0.808974 | Val Loss: 0.136413, Val Acc: 0.762887\n",
      "Epoch 11485 - Train Loss: 0.118487, Train Acc: 0.808974 | Val Loss: 0.136408, Val Acc: 0.762887\n",
      "Epoch 11486 - Train Loss: 0.118481, Train Acc: 0.808974 | Val Loss: 0.136403, Val Acc: 0.762887\n",
      "Epoch 11487 - Train Loss: 0.118474, Train Acc: 0.808974 | Val Loss: 0.136397, Val Acc: 0.762887\n",
      "Epoch 11488 - Train Loss: 0.118468, Train Acc: 0.808974 | Val Loss: 0.136392, Val Acc: 0.762887\n",
      "Epoch 11489 - Train Loss: 0.118461, Train Acc: 0.808974 | Val Loss: 0.136387, Val Acc: 0.762887\n",
      "Epoch 11490 - Train Loss: 0.118455, Train Acc: 0.808974 | Val Loss: 0.136381, Val Acc: 0.762887\n",
      "Epoch 11491 - Train Loss: 0.118448, Train Acc: 0.808974 | Val Loss: 0.136376, Val Acc: 0.762887\n",
      "Epoch 11492 - Train Loss: 0.118442, Train Acc: 0.808974 | Val Loss: 0.136371, Val Acc: 0.762887\n",
      "Epoch 11493 - Train Loss: 0.118435, Train Acc: 0.808974 | Val Loss: 0.136365, Val Acc: 0.762887\n",
      "Epoch 11494 - Train Loss: 0.118429, Train Acc: 0.808974 | Val Loss: 0.136360, Val Acc: 0.762887\n",
      "Epoch 11495 - Train Loss: 0.118422, Train Acc: 0.808974 | Val Loss: 0.136355, Val Acc: 0.762887\n",
      "Epoch 11496 - Train Loss: 0.118416, Train Acc: 0.808974 | Val Loss: 0.136349, Val Acc: 0.762887\n",
      "Epoch 11497 - Train Loss: 0.118409, Train Acc: 0.808974 | Val Loss: 0.136344, Val Acc: 0.762887\n",
      "Epoch 11498 - Train Loss: 0.118403, Train Acc: 0.808974 | Val Loss: 0.136339, Val Acc: 0.762887\n",
      "Epoch 11499 - Train Loss: 0.118396, Train Acc: 0.808974 | Val Loss: 0.136334, Val Acc: 0.762887\n",
      "Epoch 11500 - Train Loss: 0.118390, Train Acc: 0.808974 | Val Loss: 0.136328, Val Acc: 0.762887\n",
      "Epoch 11501 - Train Loss: 0.118383, Train Acc: 0.808974 | Val Loss: 0.136323, Val Acc: 0.762887\n",
      "Epoch 11502 - Train Loss: 0.118377, Train Acc: 0.808974 | Val Loss: 0.136318, Val Acc: 0.762887\n",
      "Epoch 11503 - Train Loss: 0.118371, Train Acc: 0.808974 | Val Loss: 0.136312, Val Acc: 0.762887\n",
      "Epoch 11504 - Train Loss: 0.118364, Train Acc: 0.808974 | Val Loss: 0.136307, Val Acc: 0.762887\n",
      "Epoch 11505 - Train Loss: 0.118358, Train Acc: 0.808974 | Val Loss: 0.136302, Val Acc: 0.762887\n",
      "Epoch 11506 - Train Loss: 0.118351, Train Acc: 0.808974 | Val Loss: 0.136297, Val Acc: 0.762887\n",
      "Epoch 11507 - Train Loss: 0.118345, Train Acc: 0.808974 | Val Loss: 0.136291, Val Acc: 0.762887\n",
      "Epoch 11508 - Train Loss: 0.118338, Train Acc: 0.808974 | Val Loss: 0.136286, Val Acc: 0.762887\n",
      "Epoch 11509 - Train Loss: 0.118332, Train Acc: 0.808974 | Val Loss: 0.136281, Val Acc: 0.762887\n",
      "Epoch 11510 - Train Loss: 0.118325, Train Acc: 0.808974 | Val Loss: 0.136275, Val Acc: 0.762887\n",
      "Epoch 11511 - Train Loss: 0.118319, Train Acc: 0.808974 | Val Loss: 0.136270, Val Acc: 0.762887\n",
      "Epoch 11512 - Train Loss: 0.118312, Train Acc: 0.808974 | Val Loss: 0.136265, Val Acc: 0.762887\n",
      "Epoch 11513 - Train Loss: 0.118306, Train Acc: 0.808974 | Val Loss: 0.136259, Val Acc: 0.762887\n",
      "Epoch 11514 - Train Loss: 0.118299, Train Acc: 0.808974 | Val Loss: 0.136254, Val Acc: 0.762887\n",
      "Epoch 11515 - Train Loss: 0.118293, Train Acc: 0.808974 | Val Loss: 0.136249, Val Acc: 0.762887\n",
      "Epoch 11516 - Train Loss: 0.118286, Train Acc: 0.808974 | Val Loss: 0.136244, Val Acc: 0.762887\n",
      "Epoch 11517 - Train Loss: 0.118280, Train Acc: 0.808974 | Val Loss: 0.136238, Val Acc: 0.762887\n",
      "Epoch 11518 - Train Loss: 0.118273, Train Acc: 0.808974 | Val Loss: 0.136233, Val Acc: 0.762887\n",
      "Epoch 11519 - Train Loss: 0.118267, Train Acc: 0.808974 | Val Loss: 0.136228, Val Acc: 0.762887\n",
      "Epoch 11520 - Train Loss: 0.118260, Train Acc: 0.808974 | Val Loss: 0.136223, Val Acc: 0.762887\n",
      "Epoch 11521 - Train Loss: 0.118254, Train Acc: 0.808974 | Val Loss: 0.136217, Val Acc: 0.762887\n",
      "Epoch 11522 - Train Loss: 0.118247, Train Acc: 0.808974 | Val Loss: 0.136212, Val Acc: 0.762887\n",
      "Epoch 11523 - Train Loss: 0.118241, Train Acc: 0.808974 | Val Loss: 0.136207, Val Acc: 0.762887\n",
      "Epoch 11524 - Train Loss: 0.118234, Train Acc: 0.808974 | Val Loss: 0.136201, Val Acc: 0.762887\n",
      "Epoch 11525 - Train Loss: 0.118228, Train Acc: 0.808974 | Val Loss: 0.136196, Val Acc: 0.762887\n",
      "Epoch 11526 - Train Loss: 0.118222, Train Acc: 0.808974 | Val Loss: 0.136191, Val Acc: 0.762887\n",
      "Epoch 11527 - Train Loss: 0.118215, Train Acc: 0.808974 | Val Loss: 0.136186, Val Acc: 0.762887\n",
      "Epoch 11528 - Train Loss: 0.118209, Train Acc: 0.808974 | Val Loss: 0.136180, Val Acc: 0.762887\n",
      "Epoch 11529 - Train Loss: 0.118202, Train Acc: 0.808974 | Val Loss: 0.136175, Val Acc: 0.762887\n",
      "Epoch 11530 - Train Loss: 0.118196, Train Acc: 0.808974 | Val Loss: 0.136170, Val Acc: 0.762887\n",
      "Epoch 11531 - Train Loss: 0.118189, Train Acc: 0.808974 | Val Loss: 0.136165, Val Acc: 0.762887\n",
      "Epoch 11532 - Train Loss: 0.118183, Train Acc: 0.808974 | Val Loss: 0.136159, Val Acc: 0.762887\n",
      "Epoch 11533 - Train Loss: 0.118176, Train Acc: 0.808974 | Val Loss: 0.136154, Val Acc: 0.762887\n",
      "Epoch 11534 - Train Loss: 0.118170, Train Acc: 0.808974 | Val Loss: 0.136149, Val Acc: 0.762887\n",
      "Epoch 11535 - Train Loss: 0.118163, Train Acc: 0.808974 | Val Loss: 0.136144, Val Acc: 0.762887\n",
      "Epoch 11536 - Train Loss: 0.118157, Train Acc: 0.808974 | Val Loss: 0.136138, Val Acc: 0.762887\n",
      "Epoch 11537 - Train Loss: 0.118151, Train Acc: 0.808974 | Val Loss: 0.136133, Val Acc: 0.762887\n",
      "Epoch 11538 - Train Loss: 0.118144, Train Acc: 0.808974 | Val Loss: 0.136128, Val Acc: 0.762887\n",
      "Epoch 11539 - Train Loss: 0.118138, Train Acc: 0.808974 | Val Loss: 0.136122, Val Acc: 0.762887\n",
      "Epoch 11540 - Train Loss: 0.118131, Train Acc: 0.808974 | Val Loss: 0.136117, Val Acc: 0.762887\n",
      "Epoch 11541 - Train Loss: 0.118125, Train Acc: 0.808974 | Val Loss: 0.136112, Val Acc: 0.762887\n",
      "Epoch 11542 - Train Loss: 0.118118, Train Acc: 0.808974 | Val Loss: 0.136107, Val Acc: 0.762887\n",
      "Epoch 11543 - Train Loss: 0.118112, Train Acc: 0.808974 | Val Loss: 0.136101, Val Acc: 0.762887\n",
      "Epoch 11544 - Train Loss: 0.118105, Train Acc: 0.808974 | Val Loss: 0.136096, Val Acc: 0.762887\n",
      "Epoch 11545 - Train Loss: 0.118099, Train Acc: 0.808974 | Val Loss: 0.136091, Val Acc: 0.762887\n",
      "Epoch 11546 - Train Loss: 0.118092, Train Acc: 0.808974 | Val Loss: 0.136086, Val Acc: 0.762887\n",
      "Epoch 11547 - Train Loss: 0.118086, Train Acc: 0.808974 | Val Loss: 0.136081, Val Acc: 0.762887\n",
      "Epoch 11548 - Train Loss: 0.118080, Train Acc: 0.808974 | Val Loss: 0.136075, Val Acc: 0.762887\n",
      "Epoch 11549 - Train Loss: 0.118073, Train Acc: 0.808974 | Val Loss: 0.136070, Val Acc: 0.762887\n",
      "Epoch 11550 - Train Loss: 0.118067, Train Acc: 0.808974 | Val Loss: 0.136065, Val Acc: 0.762887\n",
      "Epoch 11551 - Train Loss: 0.118060, Train Acc: 0.808974 | Val Loss: 0.136060, Val Acc: 0.762887\n",
      "Epoch 11552 - Train Loss: 0.118054, Train Acc: 0.808974 | Val Loss: 0.136054, Val Acc: 0.762887\n",
      "Epoch 11553 - Train Loss: 0.118047, Train Acc: 0.808974 | Val Loss: 0.136049, Val Acc: 0.762887\n",
      "Epoch 11554 - Train Loss: 0.118041, Train Acc: 0.808974 | Val Loss: 0.136044, Val Acc: 0.762887\n",
      "Epoch 11555 - Train Loss: 0.118035, Train Acc: 0.808974 | Val Loss: 0.136039, Val Acc: 0.762887\n",
      "Epoch 11556 - Train Loss: 0.118028, Train Acc: 0.808974 | Val Loss: 0.136033, Val Acc: 0.762887\n",
      "Epoch 11557 - Train Loss: 0.118022, Train Acc: 0.808974 | Val Loss: 0.136028, Val Acc: 0.762887\n",
      "Epoch 11558 - Train Loss: 0.118015, Train Acc: 0.808974 | Val Loss: 0.136023, Val Acc: 0.762887\n",
      "Epoch 11559 - Train Loss: 0.118009, Train Acc: 0.808974 | Val Loss: 0.136018, Val Acc: 0.762887\n",
      "Epoch 11560 - Train Loss: 0.118002, Train Acc: 0.808974 | Val Loss: 0.136012, Val Acc: 0.762887\n",
      "Epoch 11561 - Train Loss: 0.117996, Train Acc: 0.808974 | Val Loss: 0.136007, Val Acc: 0.762887\n",
      "Epoch 11562 - Train Loss: 0.117990, Train Acc: 0.808974 | Val Loss: 0.136002, Val Acc: 0.762887\n",
      "Epoch 11563 - Train Loss: 0.117983, Train Acc: 0.808974 | Val Loss: 0.135997, Val Acc: 0.762887\n",
      "Epoch 11564 - Train Loss: 0.117977, Train Acc: 0.808974 | Val Loss: 0.135992, Val Acc: 0.762887\n",
      "Epoch 11565 - Train Loss: 0.117970, Train Acc: 0.808974 | Val Loss: 0.135986, Val Acc: 0.762887\n",
      "Epoch 11566 - Train Loss: 0.117964, Train Acc: 0.808974 | Val Loss: 0.135981, Val Acc: 0.762887\n",
      "Epoch 11567 - Train Loss: 0.117957, Train Acc: 0.808974 | Val Loss: 0.135976, Val Acc: 0.762887\n",
      "Epoch 11568 - Train Loss: 0.117951, Train Acc: 0.808974 | Val Loss: 0.135971, Val Acc: 0.762887\n",
      "Epoch 11569 - Train Loss: 0.117945, Train Acc: 0.808974 | Val Loss: 0.135965, Val Acc: 0.762887\n",
      "Epoch 11570 - Train Loss: 0.117938, Train Acc: 0.808974 | Val Loss: 0.135960, Val Acc: 0.762887\n",
      "Epoch 11571 - Train Loss: 0.117932, Train Acc: 0.808974 | Val Loss: 0.135955, Val Acc: 0.762887\n",
      "Epoch 11572 - Train Loss: 0.117925, Train Acc: 0.808974 | Val Loss: 0.135950, Val Acc: 0.762887\n",
      "Epoch 11573 - Train Loss: 0.117919, Train Acc: 0.808974 | Val Loss: 0.135945, Val Acc: 0.762887\n",
      "Epoch 11574 - Train Loss: 0.117913, Train Acc: 0.808974 | Val Loss: 0.135939, Val Acc: 0.762887\n",
      "Epoch 11575 - Train Loss: 0.117906, Train Acc: 0.808974 | Val Loss: 0.135934, Val Acc: 0.762887\n",
      "Epoch 11576 - Train Loss: 0.117900, Train Acc: 0.808974 | Val Loss: 0.135929, Val Acc: 0.762887\n",
      "Epoch 11577 - Train Loss: 0.117893, Train Acc: 0.808974 | Val Loss: 0.135924, Val Acc: 0.762887\n",
      "Epoch 11578 - Train Loss: 0.117887, Train Acc: 0.808974 | Val Loss: 0.135919, Val Acc: 0.762887\n",
      "Epoch 11579 - Train Loss: 0.117881, Train Acc: 0.808974 | Val Loss: 0.135913, Val Acc: 0.762887\n",
      "Epoch 11580 - Train Loss: 0.117874, Train Acc: 0.808974 | Val Loss: 0.135908, Val Acc: 0.762887\n",
      "Epoch 11581 - Train Loss: 0.117868, Train Acc: 0.808974 | Val Loss: 0.135903, Val Acc: 0.762887\n",
      "Epoch 11582 - Train Loss: 0.117861, Train Acc: 0.808974 | Val Loss: 0.135898, Val Acc: 0.762887\n",
      "Epoch 11583 - Train Loss: 0.117855, Train Acc: 0.808974 | Val Loss: 0.135893, Val Acc: 0.762887\n",
      "Epoch 11584 - Train Loss: 0.117849, Train Acc: 0.808974 | Val Loss: 0.135887, Val Acc: 0.762887\n",
      "Epoch 11585 - Train Loss: 0.117842, Train Acc: 0.808974 | Val Loss: 0.135882, Val Acc: 0.762887\n",
      "Epoch 11586 - Train Loss: 0.117836, Train Acc: 0.808974 | Val Loss: 0.135877, Val Acc: 0.762887\n",
      "Epoch 11587 - Train Loss: 0.117829, Train Acc: 0.808974 | Val Loss: 0.135872, Val Acc: 0.762887\n",
      "Epoch 11588 - Train Loss: 0.117823, Train Acc: 0.808974 | Val Loss: 0.135867, Val Acc: 0.762887\n",
      "Epoch 11589 - Train Loss: 0.117817, Train Acc: 0.808974 | Val Loss: 0.135861, Val Acc: 0.762887\n",
      "Epoch 11590 - Train Loss: 0.117810, Train Acc: 0.808974 | Val Loss: 0.135856, Val Acc: 0.762887\n",
      "Epoch 11591 - Train Loss: 0.117804, Train Acc: 0.808974 | Val Loss: 0.135851, Val Acc: 0.762887\n",
      "Epoch 11592 - Train Loss: 0.117797, Train Acc: 0.808974 | Val Loss: 0.135846, Val Acc: 0.762887\n",
      "Epoch 11593 - Train Loss: 0.117791, Train Acc: 0.808974 | Val Loss: 0.135841, Val Acc: 0.762887\n",
      "Epoch 11594 - Train Loss: 0.117785, Train Acc: 0.808974 | Val Loss: 0.135836, Val Acc: 0.762887\n",
      "Epoch 11595 - Train Loss: 0.117778, Train Acc: 0.808974 | Val Loss: 0.135830, Val Acc: 0.762887\n",
      "Epoch 11596 - Train Loss: 0.117772, Train Acc: 0.808974 | Val Loss: 0.135825, Val Acc: 0.762887\n",
      "Epoch 11597 - Train Loss: 0.117765, Train Acc: 0.808974 | Val Loss: 0.135820, Val Acc: 0.762887\n",
      "Epoch 11598 - Train Loss: 0.117759, Train Acc: 0.808974 | Val Loss: 0.135815, Val Acc: 0.762887\n",
      "Epoch 11599 - Train Loss: 0.117753, Train Acc: 0.808974 | Val Loss: 0.135810, Val Acc: 0.762887\n",
      "Epoch 11600 - Train Loss: 0.117746, Train Acc: 0.808974 | Val Loss: 0.135804, Val Acc: 0.762887\n",
      "Epoch 11601 - Train Loss: 0.117740, Train Acc: 0.808974 | Val Loss: 0.135799, Val Acc: 0.762887\n",
      "Epoch 11602 - Train Loss: 0.117733, Train Acc: 0.808974 | Val Loss: 0.135794, Val Acc: 0.762887\n",
      "Epoch 11603 - Train Loss: 0.117727, Train Acc: 0.808974 | Val Loss: 0.135789, Val Acc: 0.762887\n",
      "Epoch 11604 - Train Loss: 0.117721, Train Acc: 0.808974 | Val Loss: 0.135784, Val Acc: 0.762887\n",
      "Epoch 11605 - Train Loss: 0.117714, Train Acc: 0.808974 | Val Loss: 0.135779, Val Acc: 0.762887\n",
      "Epoch 11606 - Train Loss: 0.117708, Train Acc: 0.808974 | Val Loss: 0.135773, Val Acc: 0.762887\n",
      "Epoch 11607 - Train Loss: 0.117702, Train Acc: 0.808974 | Val Loss: 0.135768, Val Acc: 0.762887\n",
      "Epoch 11608 - Train Loss: 0.117695, Train Acc: 0.808974 | Val Loss: 0.135763, Val Acc: 0.762887\n",
      "Epoch 11609 - Train Loss: 0.117689, Train Acc: 0.808974 | Val Loss: 0.135758, Val Acc: 0.762887\n",
      "Epoch 11610 - Train Loss: 0.117682, Train Acc: 0.808974 | Val Loss: 0.135753, Val Acc: 0.762887\n",
      "Epoch 11611 - Train Loss: 0.117676, Train Acc: 0.808974 | Val Loss: 0.135748, Val Acc: 0.762887\n",
      "Epoch 11612 - Train Loss: 0.117670, Train Acc: 0.808974 | Val Loss: 0.135743, Val Acc: 0.762887\n",
      "Epoch 11613 - Train Loss: 0.117663, Train Acc: 0.808974 | Val Loss: 0.135737, Val Acc: 0.762887\n",
      "Epoch 11614 - Train Loss: 0.117657, Train Acc: 0.808974 | Val Loss: 0.135732, Val Acc: 0.762887\n",
      "Epoch 11615 - Train Loss: 0.117651, Train Acc: 0.808974 | Val Loss: 0.135727, Val Acc: 0.762887\n",
      "Epoch 11616 - Train Loss: 0.117644, Train Acc: 0.808974 | Val Loss: 0.135722, Val Acc: 0.762887\n",
      "Epoch 11617 - Train Loss: 0.117638, Train Acc: 0.808974 | Val Loss: 0.135717, Val Acc: 0.762887\n",
      "Epoch 11618 - Train Loss: 0.117632, Train Acc: 0.808974 | Val Loss: 0.135712, Val Acc: 0.762887\n",
      "Epoch 11619 - Train Loss: 0.117625, Train Acc: 0.808974 | Val Loss: 0.135706, Val Acc: 0.762887\n",
      "Epoch 11620 - Train Loss: 0.117619, Train Acc: 0.808974 | Val Loss: 0.135701, Val Acc: 0.762887\n",
      "Epoch 11621 - Train Loss: 0.117612, Train Acc: 0.808974 | Val Loss: 0.135696, Val Acc: 0.762887\n",
      "Epoch 11622 - Train Loss: 0.117606, Train Acc: 0.808974 | Val Loss: 0.135691, Val Acc: 0.762887\n",
      "Epoch 11623 - Train Loss: 0.117600, Train Acc: 0.808974 | Val Loss: 0.135686, Val Acc: 0.762887\n",
      "Epoch 11624 - Train Loss: 0.117593, Train Acc: 0.808974 | Val Loss: 0.135681, Val Acc: 0.762887\n",
      "Epoch 11625 - Train Loss: 0.117587, Train Acc: 0.808974 | Val Loss: 0.135675, Val Acc: 0.762887\n",
      "Epoch 11626 - Train Loss: 0.117581, Train Acc: 0.808974 | Val Loss: 0.135670, Val Acc: 0.762887\n",
      "Epoch 11627 - Train Loss: 0.117574, Train Acc: 0.808974 | Val Loss: 0.135665, Val Acc: 0.762887\n",
      "Epoch 11628 - Train Loss: 0.117568, Train Acc: 0.808974 | Val Loss: 0.135660, Val Acc: 0.762887\n",
      "Epoch 11629 - Train Loss: 0.117562, Train Acc: 0.808974 | Val Loss: 0.135655, Val Acc: 0.762887\n",
      "Epoch 11630 - Train Loss: 0.117555, Train Acc: 0.808974 | Val Loss: 0.135650, Val Acc: 0.762887\n",
      "Epoch 11631 - Train Loss: 0.117549, Train Acc: 0.808974 | Val Loss: 0.135645, Val Acc: 0.762887\n",
      "Epoch 11632 - Train Loss: 0.117543, Train Acc: 0.808974 | Val Loss: 0.135639, Val Acc: 0.762887\n",
      "Epoch 11633 - Train Loss: 0.117536, Train Acc: 0.808974 | Val Loss: 0.135634, Val Acc: 0.762887\n",
      "Epoch 11634 - Train Loss: 0.117530, Train Acc: 0.808974 | Val Loss: 0.135629, Val Acc: 0.762887\n",
      "Epoch 11635 - Train Loss: 0.117524, Train Acc: 0.808974 | Val Loss: 0.135624, Val Acc: 0.762887\n",
      "Epoch 11636 - Train Loss: 0.117517, Train Acc: 0.808974 | Val Loss: 0.135619, Val Acc: 0.762887\n",
      "Epoch 11637 - Train Loss: 0.117511, Train Acc: 0.808974 | Val Loss: 0.135614, Val Acc: 0.762887\n",
      "Epoch 11638 - Train Loss: 0.117505, Train Acc: 0.808974 | Val Loss: 0.135609, Val Acc: 0.762887\n",
      "Epoch 11639 - Train Loss: 0.117498, Train Acc: 0.808974 | Val Loss: 0.135603, Val Acc: 0.762887\n",
      "Epoch 11640 - Train Loss: 0.117492, Train Acc: 0.808974 | Val Loss: 0.135598, Val Acc: 0.762887\n",
      "Epoch 11641 - Train Loss: 0.117485, Train Acc: 0.808974 | Val Loss: 0.135593, Val Acc: 0.762887\n",
      "Epoch 11642 - Train Loss: 0.117479, Train Acc: 0.808974 | Val Loss: 0.135588, Val Acc: 0.762887\n",
      "Epoch 11643 - Train Loss: 0.117473, Train Acc: 0.808974 | Val Loss: 0.135583, Val Acc: 0.762887\n",
      "Epoch 11644 - Train Loss: 0.117466, Train Acc: 0.808974 | Val Loss: 0.135578, Val Acc: 0.762887\n",
      "Epoch 11645 - Train Loss: 0.117460, Train Acc: 0.808974 | Val Loss: 0.135573, Val Acc: 0.762887\n",
      "Epoch 11646 - Train Loss: 0.117454, Train Acc: 0.808974 | Val Loss: 0.135568, Val Acc: 0.762887\n",
      "Epoch 11647 - Train Loss: 0.117447, Train Acc: 0.808974 | Val Loss: 0.135562, Val Acc: 0.762887\n",
      "Epoch 11648 - Train Loss: 0.117441, Train Acc: 0.808974 | Val Loss: 0.135557, Val Acc: 0.762887\n",
      "Epoch 11649 - Train Loss: 0.117435, Train Acc: 0.808974 | Val Loss: 0.135552, Val Acc: 0.762887\n",
      "Epoch 11650 - Train Loss: 0.117428, Train Acc: 0.808974 | Val Loss: 0.135547, Val Acc: 0.762887\n",
      "Epoch 11651 - Train Loss: 0.117422, Train Acc: 0.808974 | Val Loss: 0.135542, Val Acc: 0.762887\n",
      "Epoch 11652 - Train Loss: 0.117416, Train Acc: 0.808974 | Val Loss: 0.135537, Val Acc: 0.762887\n",
      "Epoch 11653 - Train Loss: 0.117410, Train Acc: 0.808974 | Val Loss: 0.135532, Val Acc: 0.762887\n",
      "Epoch 11654 - Train Loss: 0.117403, Train Acc: 0.808974 | Val Loss: 0.135527, Val Acc: 0.762887\n",
      "Epoch 11655 - Train Loss: 0.117397, Train Acc: 0.808974 | Val Loss: 0.135521, Val Acc: 0.762887\n",
      "Epoch 11656 - Train Loss: 0.117391, Train Acc: 0.808974 | Val Loss: 0.135516, Val Acc: 0.762887\n",
      "Epoch 11657 - Train Loss: 0.117384, Train Acc: 0.808974 | Val Loss: 0.135511, Val Acc: 0.762887\n",
      "Epoch 11658 - Train Loss: 0.117378, Train Acc: 0.808974 | Val Loss: 0.135506, Val Acc: 0.762887\n",
      "Epoch 11659 - Train Loss: 0.117372, Train Acc: 0.808974 | Val Loss: 0.135501, Val Acc: 0.762887\n",
      "Epoch 11660 - Train Loss: 0.117365, Train Acc: 0.808974 | Val Loss: 0.135496, Val Acc: 0.762887\n",
      "Epoch 11661 - Train Loss: 0.117359, Train Acc: 0.808974 | Val Loss: 0.135491, Val Acc: 0.762887\n",
      "Epoch 11662 - Train Loss: 0.117353, Train Acc: 0.808974 | Val Loss: 0.135486, Val Acc: 0.762887\n",
      "Epoch 11663 - Train Loss: 0.117346, Train Acc: 0.808974 | Val Loss: 0.135481, Val Acc: 0.762887\n",
      "Epoch 11664 - Train Loss: 0.117340, Train Acc: 0.808974 | Val Loss: 0.135475, Val Acc: 0.762887\n",
      "Epoch 11665 - Train Loss: 0.117334, Train Acc: 0.808974 | Val Loss: 0.135470, Val Acc: 0.762887\n",
      "Epoch 11666 - Train Loss: 0.117327, Train Acc: 0.808974 | Val Loss: 0.135465, Val Acc: 0.762887\n",
      "Epoch 11667 - Train Loss: 0.117321, Train Acc: 0.808974 | Val Loss: 0.135460, Val Acc: 0.762887\n",
      "Epoch 11668 - Train Loss: 0.117315, Train Acc: 0.808974 | Val Loss: 0.135455, Val Acc: 0.762887\n",
      "Epoch 11669 - Train Loss: 0.117308, Train Acc: 0.808974 | Val Loss: 0.135450, Val Acc: 0.762887\n",
      "Epoch 11670 - Train Loss: 0.117302, Train Acc: 0.808974 | Val Loss: 0.135445, Val Acc: 0.762887\n",
      "Epoch 11671 - Train Loss: 0.117296, Train Acc: 0.808974 | Val Loss: 0.135440, Val Acc: 0.762887\n",
      "Epoch 11672 - Train Loss: 0.117290, Train Acc: 0.808974 | Val Loss: 0.135435, Val Acc: 0.762887\n",
      "Epoch 11673 - Train Loss: 0.117283, Train Acc: 0.808974 | Val Loss: 0.135430, Val Acc: 0.762887\n",
      "Epoch 11674 - Train Loss: 0.117277, Train Acc: 0.808974 | Val Loss: 0.135424, Val Acc: 0.762887\n",
      "Epoch 11675 - Train Loss: 0.117271, Train Acc: 0.808974 | Val Loss: 0.135419, Val Acc: 0.762887\n",
      "Epoch 11676 - Train Loss: 0.117264, Train Acc: 0.810256 | Val Loss: 0.135414, Val Acc: 0.762887\n",
      "Epoch 11677 - Train Loss: 0.117258, Train Acc: 0.810256 | Val Loss: 0.135409, Val Acc: 0.762887\n",
      "Epoch 11678 - Train Loss: 0.117252, Train Acc: 0.810256 | Val Loss: 0.135404, Val Acc: 0.762887\n",
      "Epoch 11679 - Train Loss: 0.117245, Train Acc: 0.810256 | Val Loss: 0.135399, Val Acc: 0.762887\n",
      "Epoch 11680 - Train Loss: 0.117239, Train Acc: 0.811538 | Val Loss: 0.135394, Val Acc: 0.762887\n",
      "Epoch 11681 - Train Loss: 0.117233, Train Acc: 0.811538 | Val Loss: 0.135389, Val Acc: 0.762887\n",
      "Epoch 11682 - Train Loss: 0.117227, Train Acc: 0.811538 | Val Loss: 0.135384, Val Acc: 0.762887\n",
      "Epoch 11683 - Train Loss: 0.117220, Train Acc: 0.811538 | Val Loss: 0.135379, Val Acc: 0.762887\n",
      "Epoch 11684 - Train Loss: 0.117214, Train Acc: 0.811538 | Val Loss: 0.135373, Val Acc: 0.762887\n",
      "Epoch 11685 - Train Loss: 0.117208, Train Acc: 0.811538 | Val Loss: 0.135368, Val Acc: 0.762887\n",
      "Epoch 11686 - Train Loss: 0.117201, Train Acc: 0.811538 | Val Loss: 0.135363, Val Acc: 0.773196\n",
      "Epoch 11687 - Train Loss: 0.117195, Train Acc: 0.811538 | Val Loss: 0.135358, Val Acc: 0.773196\n",
      "Epoch 11688 - Train Loss: 0.117189, Train Acc: 0.811538 | Val Loss: 0.135353, Val Acc: 0.773196\n",
      "Epoch 11689 - Train Loss: 0.117182, Train Acc: 0.811538 | Val Loss: 0.135348, Val Acc: 0.773196\n",
      "Epoch 11690 - Train Loss: 0.117176, Train Acc: 0.811538 | Val Loss: 0.135343, Val Acc: 0.773196\n",
      "Epoch 11691 - Train Loss: 0.117170, Train Acc: 0.811538 | Val Loss: 0.135338, Val Acc: 0.773196\n",
      "Epoch 11692 - Train Loss: 0.117164, Train Acc: 0.811538 | Val Loss: 0.135333, Val Acc: 0.773196\n",
      "Epoch 11693 - Train Loss: 0.117157, Train Acc: 0.811538 | Val Loss: 0.135328, Val Acc: 0.773196\n",
      "Epoch 11694 - Train Loss: 0.117151, Train Acc: 0.811538 | Val Loss: 0.135323, Val Acc: 0.773196\n",
      "Epoch 11695 - Train Loss: 0.117145, Train Acc: 0.811538 | Val Loss: 0.135318, Val Acc: 0.773196\n",
      "Epoch 11696 - Train Loss: 0.117138, Train Acc: 0.811538 | Val Loss: 0.135313, Val Acc: 0.773196\n",
      "Epoch 11697 - Train Loss: 0.117132, Train Acc: 0.811538 | Val Loss: 0.135307, Val Acc: 0.773196\n",
      "Epoch 11698 - Train Loss: 0.117126, Train Acc: 0.811538 | Val Loss: 0.135302, Val Acc: 0.773196\n",
      "Epoch 11699 - Train Loss: 0.117120, Train Acc: 0.811538 | Val Loss: 0.135297, Val Acc: 0.773196\n",
      "Epoch 11700 - Train Loss: 0.117113, Train Acc: 0.811538 | Val Loss: 0.135292, Val Acc: 0.773196\n",
      "Epoch 11701 - Train Loss: 0.117107, Train Acc: 0.811538 | Val Loss: 0.135287, Val Acc: 0.773196\n",
      "Epoch 11702 - Train Loss: 0.117101, Train Acc: 0.811538 | Val Loss: 0.135282, Val Acc: 0.773196\n",
      "Epoch 11703 - Train Loss: 0.117095, Train Acc: 0.811538 | Val Loss: 0.135277, Val Acc: 0.773196\n",
      "Epoch 11704 - Train Loss: 0.117088, Train Acc: 0.811538 | Val Loss: 0.135272, Val Acc: 0.773196\n",
      "Epoch 11705 - Train Loss: 0.117082, Train Acc: 0.811538 | Val Loss: 0.135267, Val Acc: 0.773196\n",
      "Epoch 11706 - Train Loss: 0.117076, Train Acc: 0.811538 | Val Loss: 0.135262, Val Acc: 0.773196\n",
      "Epoch 11707 - Train Loss: 0.117069, Train Acc: 0.811538 | Val Loss: 0.135257, Val Acc: 0.773196\n",
      "Epoch 11708 - Train Loss: 0.117063, Train Acc: 0.811538 | Val Loss: 0.135252, Val Acc: 0.773196\n",
      "Epoch 11709 - Train Loss: 0.117057, Train Acc: 0.812821 | Val Loss: 0.135247, Val Acc: 0.773196\n",
      "Epoch 11710 - Train Loss: 0.117051, Train Acc: 0.812821 | Val Loss: 0.135242, Val Acc: 0.773196\n",
      "Epoch 11711 - Train Loss: 0.117044, Train Acc: 0.812821 | Val Loss: 0.135236, Val Acc: 0.773196\n",
      "Epoch 11712 - Train Loss: 0.117038, Train Acc: 0.812821 | Val Loss: 0.135231, Val Acc: 0.773196\n",
      "Epoch 11713 - Train Loss: 0.117032, Train Acc: 0.812821 | Val Loss: 0.135226, Val Acc: 0.773196\n",
      "Epoch 11714 - Train Loss: 0.117026, Train Acc: 0.812821 | Val Loss: 0.135221, Val Acc: 0.773196\n",
      "Epoch 11715 - Train Loss: 0.117019, Train Acc: 0.812821 | Val Loss: 0.135216, Val Acc: 0.773196\n",
      "Epoch 11716 - Train Loss: 0.117013, Train Acc: 0.812821 | Val Loss: 0.135211, Val Acc: 0.773196\n",
      "Epoch 11717 - Train Loss: 0.117007, Train Acc: 0.812821 | Val Loss: 0.135206, Val Acc: 0.773196\n",
      "Epoch 11718 - Train Loss: 0.117001, Train Acc: 0.812821 | Val Loss: 0.135201, Val Acc: 0.773196\n",
      "Epoch 11719 - Train Loss: 0.116994, Train Acc: 0.812821 | Val Loss: 0.135196, Val Acc: 0.773196\n",
      "Epoch 11720 - Train Loss: 0.116988, Train Acc: 0.812821 | Val Loss: 0.135191, Val Acc: 0.773196\n",
      "Epoch 11721 - Train Loss: 0.116982, Train Acc: 0.812821 | Val Loss: 0.135186, Val Acc: 0.773196\n",
      "Epoch 11722 - Train Loss: 0.116976, Train Acc: 0.812821 | Val Loss: 0.135181, Val Acc: 0.773196\n",
      "Epoch 11723 - Train Loss: 0.116969, Train Acc: 0.812821 | Val Loss: 0.135176, Val Acc: 0.773196\n",
      "Epoch 11724 - Train Loss: 0.116963, Train Acc: 0.812821 | Val Loss: 0.135171, Val Acc: 0.773196\n",
      "Epoch 11725 - Train Loss: 0.116957, Train Acc: 0.812821 | Val Loss: 0.135166, Val Acc: 0.773196\n",
      "Epoch 11726 - Train Loss: 0.116951, Train Acc: 0.812821 | Val Loss: 0.135161, Val Acc: 0.773196\n",
      "Epoch 11727 - Train Loss: 0.116944, Train Acc: 0.812821 | Val Loss: 0.135156, Val Acc: 0.773196\n",
      "Epoch 11728 - Train Loss: 0.116938, Train Acc: 0.812821 | Val Loss: 0.135151, Val Acc: 0.773196\n",
      "Epoch 11729 - Train Loss: 0.116932, Train Acc: 0.812821 | Val Loss: 0.135146, Val Acc: 0.773196\n",
      "Epoch 11730 - Train Loss: 0.116926, Train Acc: 0.812821 | Val Loss: 0.135141, Val Acc: 0.773196\n",
      "Epoch 11731 - Train Loss: 0.116919, Train Acc: 0.812821 | Val Loss: 0.135135, Val Acc: 0.773196\n",
      "Epoch 11732 - Train Loss: 0.116913, Train Acc: 0.812821 | Val Loss: 0.135130, Val Acc: 0.773196\n",
      "Epoch 11733 - Train Loss: 0.116907, Train Acc: 0.812821 | Val Loss: 0.135125, Val Acc: 0.773196\n",
      "Epoch 11734 - Train Loss: 0.116901, Train Acc: 0.812821 | Val Loss: 0.135120, Val Acc: 0.773196\n",
      "Epoch 11735 - Train Loss: 0.116894, Train Acc: 0.812821 | Val Loss: 0.135115, Val Acc: 0.773196\n",
      "Epoch 11736 - Train Loss: 0.116888, Train Acc: 0.812821 | Val Loss: 0.135110, Val Acc: 0.773196\n",
      "Epoch 11737 - Train Loss: 0.116882, Train Acc: 0.812821 | Val Loss: 0.135105, Val Acc: 0.773196\n",
      "Epoch 11738 - Train Loss: 0.116876, Train Acc: 0.812821 | Val Loss: 0.135100, Val Acc: 0.773196\n",
      "Epoch 11739 - Train Loss: 0.116869, Train Acc: 0.812821 | Val Loss: 0.135095, Val Acc: 0.773196\n",
      "Epoch 11740 - Train Loss: 0.116863, Train Acc: 0.812821 | Val Loss: 0.135090, Val Acc: 0.773196\n",
      "Epoch 11741 - Train Loss: 0.116857, Train Acc: 0.812821 | Val Loss: 0.135085, Val Acc: 0.773196\n",
      "Epoch 11742 - Train Loss: 0.116851, Train Acc: 0.812821 | Val Loss: 0.135080, Val Acc: 0.773196\n",
      "Epoch 11743 - Train Loss: 0.116845, Train Acc: 0.812821 | Val Loss: 0.135075, Val Acc: 0.773196\n",
      "Epoch 11744 - Train Loss: 0.116838, Train Acc: 0.812821 | Val Loss: 0.135070, Val Acc: 0.773196\n",
      "Epoch 11745 - Train Loss: 0.116832, Train Acc: 0.812821 | Val Loss: 0.135065, Val Acc: 0.773196\n",
      "Epoch 11746 - Train Loss: 0.116826, Train Acc: 0.812821 | Val Loss: 0.135060, Val Acc: 0.773196\n",
      "Epoch 11747 - Train Loss: 0.116820, Train Acc: 0.812821 | Val Loss: 0.135055, Val Acc: 0.773196\n",
      "Epoch 11748 - Train Loss: 0.116813, Train Acc: 0.812821 | Val Loss: 0.135050, Val Acc: 0.773196\n",
      "Epoch 11749 - Train Loss: 0.116807, Train Acc: 0.812821 | Val Loss: 0.135045, Val Acc: 0.773196\n",
      "Epoch 11750 - Train Loss: 0.116801, Train Acc: 0.812821 | Val Loss: 0.135040, Val Acc: 0.773196\n",
      "Epoch 11751 - Train Loss: 0.116795, Train Acc: 0.812821 | Val Loss: 0.135035, Val Acc: 0.773196\n",
      "Epoch 11752 - Train Loss: 0.116789, Train Acc: 0.812821 | Val Loss: 0.135030, Val Acc: 0.773196\n",
      "Epoch 11753 - Train Loss: 0.116782, Train Acc: 0.812821 | Val Loss: 0.135025, Val Acc: 0.773196\n",
      "Epoch 11754 - Train Loss: 0.116776, Train Acc: 0.812821 | Val Loss: 0.135020, Val Acc: 0.773196\n",
      "Epoch 11755 - Train Loss: 0.116770, Train Acc: 0.812821 | Val Loss: 0.135015, Val Acc: 0.773196\n",
      "Epoch 11756 - Train Loss: 0.116764, Train Acc: 0.812821 | Val Loss: 0.135010, Val Acc: 0.773196\n",
      "Epoch 11757 - Train Loss: 0.116757, Train Acc: 0.812821 | Val Loss: 0.135005, Val Acc: 0.773196\n",
      "Epoch 11758 - Train Loss: 0.116751, Train Acc: 0.812821 | Val Loss: 0.135000, Val Acc: 0.773196\n",
      "Epoch 11759 - Train Loss: 0.116745, Train Acc: 0.812821 | Val Loss: 0.134995, Val Acc: 0.773196\n",
      "Epoch 11760 - Train Loss: 0.116739, Train Acc: 0.812821 | Val Loss: 0.134990, Val Acc: 0.773196\n",
      "Epoch 11761 - Train Loss: 0.116733, Train Acc: 0.812821 | Val Loss: 0.134985, Val Acc: 0.773196\n",
      "Epoch 11762 - Train Loss: 0.116726, Train Acc: 0.812821 | Val Loss: 0.134980, Val Acc: 0.773196\n",
      "Epoch 11763 - Train Loss: 0.116720, Train Acc: 0.812821 | Val Loss: 0.134975, Val Acc: 0.773196\n",
      "Epoch 11764 - Train Loss: 0.116714, Train Acc: 0.812821 | Val Loss: 0.134970, Val Acc: 0.773196\n",
      "Epoch 11765 - Train Loss: 0.116708, Train Acc: 0.812821 | Val Loss: 0.134965, Val Acc: 0.773196\n",
      "Epoch 11766 - Train Loss: 0.116702, Train Acc: 0.812821 | Val Loss: 0.134960, Val Acc: 0.773196\n",
      "Epoch 11767 - Train Loss: 0.116695, Train Acc: 0.812821 | Val Loss: 0.134955, Val Acc: 0.773196\n",
      "Epoch 11768 - Train Loss: 0.116689, Train Acc: 0.812821 | Val Loss: 0.134950, Val Acc: 0.773196\n",
      "Epoch 11769 - Train Loss: 0.116683, Train Acc: 0.812821 | Val Loss: 0.134945, Val Acc: 0.773196\n",
      "Epoch 11770 - Train Loss: 0.116677, Train Acc: 0.812821 | Val Loss: 0.134940, Val Acc: 0.773196\n",
      "Epoch 11771 - Train Loss: 0.116671, Train Acc: 0.812821 | Val Loss: 0.134935, Val Acc: 0.773196\n",
      "Epoch 11772 - Train Loss: 0.116664, Train Acc: 0.812821 | Val Loss: 0.134930, Val Acc: 0.773196\n",
      "Epoch 11773 - Train Loss: 0.116658, Train Acc: 0.812821 | Val Loss: 0.134925, Val Acc: 0.773196\n",
      "Epoch 11774 - Train Loss: 0.116652, Train Acc: 0.812821 | Val Loss: 0.134920, Val Acc: 0.773196\n",
      "Epoch 11775 - Train Loss: 0.116646, Train Acc: 0.812821 | Val Loss: 0.134915, Val Acc: 0.773196\n",
      "Epoch 11776 - Train Loss: 0.116640, Train Acc: 0.812821 | Val Loss: 0.134910, Val Acc: 0.773196\n",
      "Epoch 11777 - Train Loss: 0.116633, Train Acc: 0.812821 | Val Loss: 0.134905, Val Acc: 0.773196\n",
      "Epoch 11778 - Train Loss: 0.116627, Train Acc: 0.812821 | Val Loss: 0.134900, Val Acc: 0.773196\n",
      "Epoch 11779 - Train Loss: 0.116621, Train Acc: 0.812821 | Val Loss: 0.134895, Val Acc: 0.773196\n",
      "Epoch 11780 - Train Loss: 0.116615, Train Acc: 0.812821 | Val Loss: 0.134890, Val Acc: 0.773196\n",
      "Epoch 11781 - Train Loss: 0.116609, Train Acc: 0.812821 | Val Loss: 0.134885, Val Acc: 0.773196\n",
      "Epoch 11782 - Train Loss: 0.116602, Train Acc: 0.812821 | Val Loss: 0.134880, Val Acc: 0.773196\n",
      "Epoch 11783 - Train Loss: 0.116596, Train Acc: 0.812821 | Val Loss: 0.134875, Val Acc: 0.773196\n",
      "Epoch 11784 - Train Loss: 0.116590, Train Acc: 0.812821 | Val Loss: 0.134870, Val Acc: 0.773196\n",
      "Epoch 11785 - Train Loss: 0.116584, Train Acc: 0.812821 | Val Loss: 0.134865, Val Acc: 0.773196\n",
      "Epoch 11786 - Train Loss: 0.116578, Train Acc: 0.812821 | Val Loss: 0.134860, Val Acc: 0.773196\n",
      "Epoch 11787 - Train Loss: 0.116571, Train Acc: 0.812821 | Val Loss: 0.134855, Val Acc: 0.773196\n",
      "Epoch 11788 - Train Loss: 0.116565, Train Acc: 0.812821 | Val Loss: 0.134850, Val Acc: 0.773196\n",
      "Epoch 11789 - Train Loss: 0.116559, Train Acc: 0.812821 | Val Loss: 0.134845, Val Acc: 0.773196\n",
      "Epoch 11790 - Train Loss: 0.116553, Train Acc: 0.812821 | Val Loss: 0.134840, Val Acc: 0.773196\n",
      "Epoch 11791 - Train Loss: 0.116547, Train Acc: 0.812821 | Val Loss: 0.134835, Val Acc: 0.773196\n",
      "Epoch 11792 - Train Loss: 0.116541, Train Acc: 0.812821 | Val Loss: 0.134830, Val Acc: 0.773196\n",
      "Epoch 11793 - Train Loss: 0.116534, Train Acc: 0.812821 | Val Loss: 0.134825, Val Acc: 0.773196\n",
      "Epoch 11794 - Train Loss: 0.116528, Train Acc: 0.812821 | Val Loss: 0.134820, Val Acc: 0.773196\n",
      "Epoch 11795 - Train Loss: 0.116522, Train Acc: 0.812821 | Val Loss: 0.134815, Val Acc: 0.773196\n",
      "Epoch 11796 - Train Loss: 0.116516, Train Acc: 0.812821 | Val Loss: 0.134810, Val Acc: 0.773196\n",
      "Epoch 11797 - Train Loss: 0.116510, Train Acc: 0.812821 | Val Loss: 0.134805, Val Acc: 0.773196\n",
      "Epoch 11798 - Train Loss: 0.116503, Train Acc: 0.812821 | Val Loss: 0.134800, Val Acc: 0.773196\n",
      "Epoch 11799 - Train Loss: 0.116497, Train Acc: 0.812821 | Val Loss: 0.134795, Val Acc: 0.773196\n",
      "Epoch 11800 - Train Loss: 0.116491, Train Acc: 0.812821 | Val Loss: 0.134790, Val Acc: 0.773196\n",
      "Epoch 11801 - Train Loss: 0.116485, Train Acc: 0.812821 | Val Loss: 0.134785, Val Acc: 0.773196\n",
      "Epoch 11802 - Train Loss: 0.116479, Train Acc: 0.812821 | Val Loss: 0.134780, Val Acc: 0.773196\n",
      "Epoch 11803 - Train Loss: 0.116473, Train Acc: 0.812821 | Val Loss: 0.134775, Val Acc: 0.773196\n",
      "Epoch 11804 - Train Loss: 0.116466, Train Acc: 0.812821 | Val Loss: 0.134771, Val Acc: 0.773196\n",
      "Epoch 11805 - Train Loss: 0.116460, Train Acc: 0.812821 | Val Loss: 0.134766, Val Acc: 0.773196\n",
      "Epoch 11806 - Train Loss: 0.116454, Train Acc: 0.812821 | Val Loss: 0.134761, Val Acc: 0.773196\n",
      "Epoch 11807 - Train Loss: 0.116448, Train Acc: 0.812821 | Val Loss: 0.134756, Val Acc: 0.773196\n",
      "Epoch 11808 - Train Loss: 0.116442, Train Acc: 0.812821 | Val Loss: 0.134751, Val Acc: 0.773196\n",
      "Epoch 11809 - Train Loss: 0.116436, Train Acc: 0.812821 | Val Loss: 0.134746, Val Acc: 0.773196\n",
      "Epoch 11810 - Train Loss: 0.116430, Train Acc: 0.812821 | Val Loss: 0.134741, Val Acc: 0.773196\n",
      "Epoch 11811 - Train Loss: 0.116423, Train Acc: 0.812821 | Val Loss: 0.134736, Val Acc: 0.773196\n",
      "Epoch 11812 - Train Loss: 0.116417, Train Acc: 0.812821 | Val Loss: 0.134731, Val Acc: 0.773196\n",
      "Epoch 11813 - Train Loss: 0.116411, Train Acc: 0.812821 | Val Loss: 0.134726, Val Acc: 0.773196\n",
      "Epoch 11814 - Train Loss: 0.116405, Train Acc: 0.812821 | Val Loss: 0.134721, Val Acc: 0.773196\n",
      "Epoch 11815 - Train Loss: 0.116399, Train Acc: 0.812821 | Val Loss: 0.134716, Val Acc: 0.773196\n",
      "Epoch 11816 - Train Loss: 0.116393, Train Acc: 0.812821 | Val Loss: 0.134711, Val Acc: 0.773196\n",
      "Epoch 11817 - Train Loss: 0.116386, Train Acc: 0.812821 | Val Loss: 0.134706, Val Acc: 0.773196\n",
      "Epoch 11818 - Train Loss: 0.116380, Train Acc: 0.812821 | Val Loss: 0.134701, Val Acc: 0.773196\n",
      "Epoch 11819 - Train Loss: 0.116374, Train Acc: 0.812821 | Val Loss: 0.134696, Val Acc: 0.773196\n",
      "Epoch 11820 - Train Loss: 0.116368, Train Acc: 0.812821 | Val Loss: 0.134691, Val Acc: 0.773196\n",
      "Epoch 11821 - Train Loss: 0.116362, Train Acc: 0.812821 | Val Loss: 0.134686, Val Acc: 0.773196\n",
      "Epoch 11822 - Train Loss: 0.116356, Train Acc: 0.812821 | Val Loss: 0.134681, Val Acc: 0.773196\n",
      "Epoch 11823 - Train Loss: 0.116350, Train Acc: 0.812821 | Val Loss: 0.134676, Val Acc: 0.773196\n",
      "Epoch 11824 - Train Loss: 0.116343, Train Acc: 0.812821 | Val Loss: 0.134671, Val Acc: 0.773196\n",
      "Epoch 11825 - Train Loss: 0.116337, Train Acc: 0.812821 | Val Loss: 0.134666, Val Acc: 0.773196\n",
      "Epoch 11826 - Train Loss: 0.116331, Train Acc: 0.812821 | Val Loss: 0.134661, Val Acc: 0.773196\n",
      "Epoch 11827 - Train Loss: 0.116325, Train Acc: 0.812821 | Val Loss: 0.134656, Val Acc: 0.773196\n",
      "Epoch 11828 - Train Loss: 0.116319, Train Acc: 0.812821 | Val Loss: 0.134651, Val Acc: 0.773196\n",
      "Epoch 11829 - Train Loss: 0.116313, Train Acc: 0.812821 | Val Loss: 0.134646, Val Acc: 0.773196\n",
      "Epoch 11830 - Train Loss: 0.116307, Train Acc: 0.812821 | Val Loss: 0.134641, Val Acc: 0.773196\n",
      "Epoch 11831 - Train Loss: 0.116300, Train Acc: 0.812821 | Val Loss: 0.134636, Val Acc: 0.773196\n",
      "Epoch 11832 - Train Loss: 0.116294, Train Acc: 0.812821 | Val Loss: 0.134631, Val Acc: 0.773196\n",
      "Epoch 11833 - Train Loss: 0.116288, Train Acc: 0.812821 | Val Loss: 0.134626, Val Acc: 0.773196\n",
      "Epoch 11834 - Train Loss: 0.116282, Train Acc: 0.812821 | Val Loss: 0.134621, Val Acc: 0.773196\n",
      "Epoch 11835 - Train Loss: 0.116276, Train Acc: 0.812821 | Val Loss: 0.134616, Val Acc: 0.773196\n",
      "Epoch 11836 - Train Loss: 0.116270, Train Acc: 0.812821 | Val Loss: 0.134611, Val Acc: 0.773196\n",
      "Epoch 11837 - Train Loss: 0.116264, Train Acc: 0.812821 | Val Loss: 0.134606, Val Acc: 0.773196\n",
      "Epoch 11838 - Train Loss: 0.116257, Train Acc: 0.812821 | Val Loss: 0.134601, Val Acc: 0.773196\n",
      "Epoch 11839 - Train Loss: 0.116251, Train Acc: 0.812821 | Val Loss: 0.134596, Val Acc: 0.773196\n",
      "Epoch 11840 - Train Loss: 0.116245, Train Acc: 0.812821 | Val Loss: 0.134591, Val Acc: 0.773196\n",
      "Epoch 11841 - Train Loss: 0.116239, Train Acc: 0.812821 | Val Loss: 0.134586, Val Acc: 0.773196\n",
      "Epoch 11842 - Train Loss: 0.116233, Train Acc: 0.812821 | Val Loss: 0.134581, Val Acc: 0.773196\n",
      "Epoch 11843 - Train Loss: 0.116227, Train Acc: 0.812821 | Val Loss: 0.134576, Val Acc: 0.773196\n",
      "Epoch 11844 - Train Loss: 0.116221, Train Acc: 0.812821 | Val Loss: 0.134571, Val Acc: 0.773196\n",
      "Epoch 11845 - Train Loss: 0.116215, Train Acc: 0.812821 | Val Loss: 0.134566, Val Acc: 0.773196\n",
      "Epoch 11846 - Train Loss: 0.116208, Train Acc: 0.812821 | Val Loss: 0.134562, Val Acc: 0.773196\n",
      "Epoch 11847 - Train Loss: 0.116202, Train Acc: 0.812821 | Val Loss: 0.134557, Val Acc: 0.773196\n",
      "Epoch 11848 - Train Loss: 0.116196, Train Acc: 0.812821 | Val Loss: 0.134552, Val Acc: 0.773196\n",
      "Epoch 11849 - Train Loss: 0.116190, Train Acc: 0.812821 | Val Loss: 0.134547, Val Acc: 0.773196\n",
      "Epoch 11850 - Train Loss: 0.116184, Train Acc: 0.812821 | Val Loss: 0.134542, Val Acc: 0.773196\n",
      "Epoch 11851 - Train Loss: 0.116178, Train Acc: 0.812821 | Val Loss: 0.134537, Val Acc: 0.773196\n",
      "Epoch 11852 - Train Loss: 0.116172, Train Acc: 0.812821 | Val Loss: 0.134532, Val Acc: 0.773196\n",
      "Epoch 11853 - Train Loss: 0.116166, Train Acc: 0.812821 | Val Loss: 0.134527, Val Acc: 0.773196\n",
      "Epoch 11854 - Train Loss: 0.116160, Train Acc: 0.812821 | Val Loss: 0.134522, Val Acc: 0.773196\n",
      "Epoch 11855 - Train Loss: 0.116153, Train Acc: 0.812821 | Val Loss: 0.134517, Val Acc: 0.773196\n",
      "Epoch 11856 - Train Loss: 0.116147, Train Acc: 0.812821 | Val Loss: 0.134512, Val Acc: 0.773196\n",
      "Epoch 11857 - Train Loss: 0.116141, Train Acc: 0.812821 | Val Loss: 0.134507, Val Acc: 0.773196\n",
      "Epoch 11858 - Train Loss: 0.116135, Train Acc: 0.812821 | Val Loss: 0.134502, Val Acc: 0.773196\n",
      "Epoch 11859 - Train Loss: 0.116129, Train Acc: 0.812821 | Val Loss: 0.134497, Val Acc: 0.773196\n",
      "Epoch 11860 - Train Loss: 0.116123, Train Acc: 0.812821 | Val Loss: 0.134492, Val Acc: 0.773196\n",
      "Epoch 11861 - Train Loss: 0.116117, Train Acc: 0.812821 | Val Loss: 0.134487, Val Acc: 0.773196\n",
      "Epoch 11862 - Train Loss: 0.116111, Train Acc: 0.812821 | Val Loss: 0.134483, Val Acc: 0.773196\n",
      "Epoch 11863 - Train Loss: 0.116105, Train Acc: 0.812821 | Val Loss: 0.134478, Val Acc: 0.773196\n",
      "Epoch 11864 - Train Loss: 0.116098, Train Acc: 0.812821 | Val Loss: 0.134473, Val Acc: 0.773196\n",
      "Epoch 11865 - Train Loss: 0.116092, Train Acc: 0.812821 | Val Loss: 0.134468, Val Acc: 0.773196\n",
      "Epoch 11866 - Train Loss: 0.116086, Train Acc: 0.812821 | Val Loss: 0.134463, Val Acc: 0.773196\n",
      "Epoch 11867 - Train Loss: 0.116080, Train Acc: 0.812821 | Val Loss: 0.134458, Val Acc: 0.773196\n",
      "Epoch 11868 - Train Loss: 0.116074, Train Acc: 0.812821 | Val Loss: 0.134453, Val Acc: 0.773196\n",
      "Epoch 11869 - Train Loss: 0.116068, Train Acc: 0.812821 | Val Loss: 0.134448, Val Acc: 0.773196\n",
      "Epoch 11870 - Train Loss: 0.116062, Train Acc: 0.812821 | Val Loss: 0.134443, Val Acc: 0.773196\n",
      "Epoch 11871 - Train Loss: 0.116056, Train Acc: 0.812821 | Val Loss: 0.134438, Val Acc: 0.773196\n",
      "Epoch 11872 - Train Loss: 0.116050, Train Acc: 0.812821 | Val Loss: 0.134433, Val Acc: 0.773196\n",
      "Epoch 11873 - Train Loss: 0.116044, Train Acc: 0.812821 | Val Loss: 0.134428, Val Acc: 0.773196\n",
      "Epoch 11874 - Train Loss: 0.116037, Train Acc: 0.812821 | Val Loss: 0.134424, Val Acc: 0.773196\n",
      "Epoch 11875 - Train Loss: 0.116031, Train Acc: 0.812821 | Val Loss: 0.134419, Val Acc: 0.773196\n",
      "Epoch 11876 - Train Loss: 0.116025, Train Acc: 0.812821 | Val Loss: 0.134414, Val Acc: 0.773196\n",
      "Epoch 11877 - Train Loss: 0.116019, Train Acc: 0.812821 | Val Loss: 0.134409, Val Acc: 0.773196\n",
      "Epoch 11878 - Train Loss: 0.116013, Train Acc: 0.812821 | Val Loss: 0.134404, Val Acc: 0.773196\n",
      "Epoch 11879 - Train Loss: 0.116007, Train Acc: 0.812821 | Val Loss: 0.134399, Val Acc: 0.773196\n",
      "Epoch 11880 - Train Loss: 0.116001, Train Acc: 0.812821 | Val Loss: 0.134394, Val Acc: 0.773196\n",
      "Epoch 11881 - Train Loss: 0.115995, Train Acc: 0.812821 | Val Loss: 0.134389, Val Acc: 0.773196\n",
      "Epoch 11882 - Train Loss: 0.115989, Train Acc: 0.812821 | Val Loss: 0.134384, Val Acc: 0.773196\n",
      "Epoch 11883 - Train Loss: 0.115983, Train Acc: 0.812821 | Val Loss: 0.134379, Val Acc: 0.773196\n",
      "Epoch 11884 - Train Loss: 0.115977, Train Acc: 0.812821 | Val Loss: 0.134375, Val Acc: 0.773196\n",
      "Epoch 11885 - Train Loss: 0.115971, Train Acc: 0.812821 | Val Loss: 0.134370, Val Acc: 0.773196\n",
      "Epoch 11886 - Train Loss: 0.115964, Train Acc: 0.812821 | Val Loss: 0.134365, Val Acc: 0.773196\n",
      "Epoch 11887 - Train Loss: 0.115958, Train Acc: 0.812821 | Val Loss: 0.134360, Val Acc: 0.773196\n",
      "Epoch 11888 - Train Loss: 0.115952, Train Acc: 0.812821 | Val Loss: 0.134355, Val Acc: 0.773196\n",
      "Epoch 11889 - Train Loss: 0.115946, Train Acc: 0.812821 | Val Loss: 0.134350, Val Acc: 0.773196\n",
      "Epoch 11890 - Train Loss: 0.115940, Train Acc: 0.812821 | Val Loss: 0.134345, Val Acc: 0.773196\n",
      "Epoch 11891 - Train Loss: 0.115934, Train Acc: 0.812821 | Val Loss: 0.134340, Val Acc: 0.773196\n",
      "Epoch 11892 - Train Loss: 0.115928, Train Acc: 0.812821 | Val Loss: 0.134335, Val Acc: 0.773196\n",
      "Epoch 11893 - Train Loss: 0.115922, Train Acc: 0.812821 | Val Loss: 0.134331, Val Acc: 0.773196\n",
      "Epoch 11894 - Train Loss: 0.115916, Train Acc: 0.812821 | Val Loss: 0.134326, Val Acc: 0.773196\n",
      "Epoch 11895 - Train Loss: 0.115910, Train Acc: 0.812821 | Val Loss: 0.134321, Val Acc: 0.773196\n",
      "Epoch 11896 - Train Loss: 0.115904, Train Acc: 0.812821 | Val Loss: 0.134316, Val Acc: 0.773196\n",
      "Epoch 11897 - Train Loss: 0.115898, Train Acc: 0.812821 | Val Loss: 0.134311, Val Acc: 0.773196\n",
      "Epoch 11898 - Train Loss: 0.115892, Train Acc: 0.812821 | Val Loss: 0.134306, Val Acc: 0.773196\n",
      "Epoch 11899 - Train Loss: 0.115886, Train Acc: 0.812821 | Val Loss: 0.134301, Val Acc: 0.773196\n",
      "Epoch 11900 - Train Loss: 0.115879, Train Acc: 0.812821 | Val Loss: 0.134296, Val Acc: 0.773196\n",
      "Epoch 11901 - Train Loss: 0.115873, Train Acc: 0.812821 | Val Loss: 0.134292, Val Acc: 0.773196\n",
      "Epoch 11902 - Train Loss: 0.115867, Train Acc: 0.812821 | Val Loss: 0.134287, Val Acc: 0.773196\n",
      "Epoch 11903 - Train Loss: 0.115861, Train Acc: 0.812821 | Val Loss: 0.134282, Val Acc: 0.773196\n",
      "Epoch 11904 - Train Loss: 0.115855, Train Acc: 0.812821 | Val Loss: 0.134277, Val Acc: 0.773196\n",
      "Epoch 11905 - Train Loss: 0.115849, Train Acc: 0.812821 | Val Loss: 0.134272, Val Acc: 0.773196\n",
      "Epoch 11906 - Train Loss: 0.115843, Train Acc: 0.812821 | Val Loss: 0.134267, Val Acc: 0.773196\n",
      "Epoch 11907 - Train Loss: 0.115837, Train Acc: 0.812821 | Val Loss: 0.134262, Val Acc: 0.773196\n",
      "Epoch 11908 - Train Loss: 0.115831, Train Acc: 0.812821 | Val Loss: 0.134257, Val Acc: 0.773196\n",
      "Epoch 11909 - Train Loss: 0.115825, Train Acc: 0.812821 | Val Loss: 0.134253, Val Acc: 0.773196\n",
      "Epoch 11910 - Train Loss: 0.115819, Train Acc: 0.812821 | Val Loss: 0.134248, Val Acc: 0.773196\n",
      "Epoch 11911 - Train Loss: 0.115813, Train Acc: 0.812821 | Val Loss: 0.134243, Val Acc: 0.773196\n",
      "Epoch 11912 - Train Loss: 0.115807, Train Acc: 0.812821 | Val Loss: 0.134238, Val Acc: 0.773196\n",
      "Epoch 11913 - Train Loss: 0.115801, Train Acc: 0.812821 | Val Loss: 0.134233, Val Acc: 0.773196\n",
      "Epoch 11914 - Train Loss: 0.115795, Train Acc: 0.812821 | Val Loss: 0.134228, Val Acc: 0.773196\n",
      "Epoch 11915 - Train Loss: 0.115789, Train Acc: 0.812821 | Val Loss: 0.134223, Val Acc: 0.773196\n",
      "Epoch 11916 - Train Loss: 0.115783, Train Acc: 0.812821 | Val Loss: 0.134219, Val Acc: 0.773196\n",
      "Epoch 11917 - Train Loss: 0.115776, Train Acc: 0.812821 | Val Loss: 0.134214, Val Acc: 0.773196\n",
      "Epoch 11918 - Train Loss: 0.115770, Train Acc: 0.812821 | Val Loss: 0.134209, Val Acc: 0.773196\n",
      "Epoch 11919 - Train Loss: 0.115764, Train Acc: 0.812821 | Val Loss: 0.134204, Val Acc: 0.773196\n",
      "Epoch 11920 - Train Loss: 0.115758, Train Acc: 0.812821 | Val Loss: 0.134199, Val Acc: 0.773196\n",
      "Epoch 11921 - Train Loss: 0.115752, Train Acc: 0.812821 | Val Loss: 0.134194, Val Acc: 0.773196\n",
      "Epoch 11922 - Train Loss: 0.115746, Train Acc: 0.812821 | Val Loss: 0.134189, Val Acc: 0.773196\n",
      "Epoch 11923 - Train Loss: 0.115740, Train Acc: 0.812821 | Val Loss: 0.134185, Val Acc: 0.773196\n",
      "Epoch 11924 - Train Loss: 0.115734, Train Acc: 0.812821 | Val Loss: 0.134180, Val Acc: 0.773196\n",
      "Epoch 11925 - Train Loss: 0.115728, Train Acc: 0.812821 | Val Loss: 0.134175, Val Acc: 0.773196\n",
      "Epoch 11926 - Train Loss: 0.115722, Train Acc: 0.812821 | Val Loss: 0.134170, Val Acc: 0.773196\n",
      "Epoch 11927 - Train Loss: 0.115716, Train Acc: 0.812821 | Val Loss: 0.134165, Val Acc: 0.773196\n",
      "Epoch 11928 - Train Loss: 0.115710, Train Acc: 0.812821 | Val Loss: 0.134160, Val Acc: 0.773196\n",
      "Epoch 11929 - Train Loss: 0.115704, Train Acc: 0.812821 | Val Loss: 0.134156, Val Acc: 0.773196\n",
      "Epoch 11930 - Train Loss: 0.115698, Train Acc: 0.812821 | Val Loss: 0.134151, Val Acc: 0.773196\n",
      "Epoch 11931 - Train Loss: 0.115692, Train Acc: 0.812821 | Val Loss: 0.134146, Val Acc: 0.773196\n",
      "Epoch 11932 - Train Loss: 0.115686, Train Acc: 0.812821 | Val Loss: 0.134141, Val Acc: 0.773196\n",
      "Epoch 11933 - Train Loss: 0.115680, Train Acc: 0.812821 | Val Loss: 0.134136, Val Acc: 0.773196\n",
      "Epoch 11934 - Train Loss: 0.115674, Train Acc: 0.812821 | Val Loss: 0.134131, Val Acc: 0.773196\n",
      "Epoch 11935 - Train Loss: 0.115668, Train Acc: 0.812821 | Val Loss: 0.134127, Val Acc: 0.773196\n",
      "Epoch 11936 - Train Loss: 0.115662, Train Acc: 0.812821 | Val Loss: 0.134122, Val Acc: 0.773196\n",
      "Epoch 11937 - Train Loss: 0.115656, Train Acc: 0.812821 | Val Loss: 0.134117, Val Acc: 0.773196\n",
      "Epoch 11938 - Train Loss: 0.115650, Train Acc: 0.812821 | Val Loss: 0.134112, Val Acc: 0.773196\n",
      "Epoch 11939 - Train Loss: 0.115644, Train Acc: 0.812821 | Val Loss: 0.134107, Val Acc: 0.773196\n",
      "Epoch 11940 - Train Loss: 0.115638, Train Acc: 0.812821 | Val Loss: 0.134102, Val Acc: 0.773196\n",
      "Epoch 11941 - Train Loss: 0.115632, Train Acc: 0.812821 | Val Loss: 0.134098, Val Acc: 0.773196\n",
      "Epoch 11942 - Train Loss: 0.115626, Train Acc: 0.812821 | Val Loss: 0.134093, Val Acc: 0.773196\n",
      "Epoch 11943 - Train Loss: 0.115620, Train Acc: 0.812821 | Val Loss: 0.134088, Val Acc: 0.773196\n",
      "Epoch 11944 - Train Loss: 0.115614, Train Acc: 0.812821 | Val Loss: 0.134083, Val Acc: 0.773196\n",
      "Epoch 11945 - Train Loss: 0.115608, Train Acc: 0.812821 | Val Loss: 0.134078, Val Acc: 0.773196\n",
      "Epoch 11946 - Train Loss: 0.115602, Train Acc: 0.812821 | Val Loss: 0.134073, Val Acc: 0.773196\n",
      "Epoch 11947 - Train Loss: 0.115595, Train Acc: 0.812821 | Val Loss: 0.134069, Val Acc: 0.773196\n",
      "Epoch 11948 - Train Loss: 0.115589, Train Acc: 0.812821 | Val Loss: 0.134064, Val Acc: 0.773196\n",
      "Epoch 11949 - Train Loss: 0.115583, Train Acc: 0.812821 | Val Loss: 0.134059, Val Acc: 0.773196\n",
      "Epoch 11950 - Train Loss: 0.115577, Train Acc: 0.812821 | Val Loss: 0.134054, Val Acc: 0.773196\n",
      "Epoch 11951 - Train Loss: 0.115571, Train Acc: 0.812821 | Val Loss: 0.134049, Val Acc: 0.773196\n",
      "Epoch 11952 - Train Loss: 0.115565, Train Acc: 0.812821 | Val Loss: 0.134045, Val Acc: 0.773196\n",
      "Epoch 11953 - Train Loss: 0.115559, Train Acc: 0.812821 | Val Loss: 0.134040, Val Acc: 0.773196\n",
      "Epoch 11954 - Train Loss: 0.115553, Train Acc: 0.812821 | Val Loss: 0.134035, Val Acc: 0.773196\n",
      "Epoch 11955 - Train Loss: 0.115547, Train Acc: 0.812821 | Val Loss: 0.134030, Val Acc: 0.773196\n",
      "Epoch 11956 - Train Loss: 0.115541, Train Acc: 0.812821 | Val Loss: 0.134025, Val Acc: 0.773196\n",
      "Epoch 11957 - Train Loss: 0.115535, Train Acc: 0.812821 | Val Loss: 0.134020, Val Acc: 0.773196\n",
      "Epoch 11958 - Train Loss: 0.115529, Train Acc: 0.812821 | Val Loss: 0.134016, Val Acc: 0.773196\n",
      "Epoch 11959 - Train Loss: 0.115523, Train Acc: 0.812821 | Val Loss: 0.134011, Val Acc: 0.773196\n",
      "Epoch 11960 - Train Loss: 0.115517, Train Acc: 0.812821 | Val Loss: 0.134006, Val Acc: 0.773196\n",
      "Epoch 11961 - Train Loss: 0.115511, Train Acc: 0.812821 | Val Loss: 0.134001, Val Acc: 0.773196\n",
      "Epoch 11962 - Train Loss: 0.115505, Train Acc: 0.812821 | Val Loss: 0.133996, Val Acc: 0.773196\n",
      "Epoch 11963 - Train Loss: 0.115499, Train Acc: 0.812821 | Val Loss: 0.133992, Val Acc: 0.773196\n",
      "Epoch 11964 - Train Loss: 0.115493, Train Acc: 0.812821 | Val Loss: 0.133987, Val Acc: 0.773196\n",
      "Epoch 11965 - Train Loss: 0.115487, Train Acc: 0.812821 | Val Loss: 0.133982, Val Acc: 0.773196\n",
      "Epoch 11966 - Train Loss: 0.115481, Train Acc: 0.812821 | Val Loss: 0.133977, Val Acc: 0.773196\n",
      "Epoch 11967 - Train Loss: 0.115475, Train Acc: 0.812821 | Val Loss: 0.133972, Val Acc: 0.773196\n",
      "Epoch 11968 - Train Loss: 0.115469, Train Acc: 0.812821 | Val Loss: 0.133968, Val Acc: 0.773196\n",
      "Epoch 11969 - Train Loss: 0.115463, Train Acc: 0.812821 | Val Loss: 0.133963, Val Acc: 0.773196\n",
      "Epoch 11970 - Train Loss: 0.115457, Train Acc: 0.812821 | Val Loss: 0.133958, Val Acc: 0.773196\n",
      "Epoch 11971 - Train Loss: 0.115451, Train Acc: 0.812821 | Val Loss: 0.133953, Val Acc: 0.773196\n",
      "Epoch 11972 - Train Loss: 0.115445, Train Acc: 0.812821 | Val Loss: 0.133948, Val Acc: 0.773196\n",
      "Epoch 11973 - Train Loss: 0.115439, Train Acc: 0.812821 | Val Loss: 0.133944, Val Acc: 0.773196\n",
      "Epoch 11974 - Train Loss: 0.115433, Train Acc: 0.812821 | Val Loss: 0.133939, Val Acc: 0.773196\n",
      "Epoch 11975 - Train Loss: 0.115427, Train Acc: 0.812821 | Val Loss: 0.133934, Val Acc: 0.773196\n",
      "Epoch 11976 - Train Loss: 0.115421, Train Acc: 0.812821 | Val Loss: 0.133929, Val Acc: 0.773196\n",
      "Epoch 11977 - Train Loss: 0.115415, Train Acc: 0.812821 | Val Loss: 0.133925, Val Acc: 0.773196\n",
      "Epoch 11978 - Train Loss: 0.115409, Train Acc: 0.812821 | Val Loss: 0.133920, Val Acc: 0.773196\n",
      "Epoch 11979 - Train Loss: 0.115403, Train Acc: 0.812821 | Val Loss: 0.133915, Val Acc: 0.773196\n",
      "Epoch 11980 - Train Loss: 0.115397, Train Acc: 0.812821 | Val Loss: 0.133910, Val Acc: 0.773196\n",
      "Epoch 11981 - Train Loss: 0.115391, Train Acc: 0.812821 | Val Loss: 0.133905, Val Acc: 0.773196\n",
      "Epoch 11982 - Train Loss: 0.115385, Train Acc: 0.812821 | Val Loss: 0.133901, Val Acc: 0.773196\n",
      "Epoch 11983 - Train Loss: 0.115380, Train Acc: 0.812821 | Val Loss: 0.133896, Val Acc: 0.773196\n",
      "Epoch 11984 - Train Loss: 0.115374, Train Acc: 0.812821 | Val Loss: 0.133891, Val Acc: 0.773196\n",
      "Epoch 11985 - Train Loss: 0.115368, Train Acc: 0.812821 | Val Loss: 0.133886, Val Acc: 0.773196\n",
      "Epoch 11986 - Train Loss: 0.115362, Train Acc: 0.812821 | Val Loss: 0.133881, Val Acc: 0.773196\n",
      "Epoch 11987 - Train Loss: 0.115356, Train Acc: 0.814103 | Val Loss: 0.133877, Val Acc: 0.773196\n",
      "Epoch 11988 - Train Loss: 0.115350, Train Acc: 0.814103 | Val Loss: 0.133872, Val Acc: 0.773196\n",
      "Epoch 11989 - Train Loss: 0.115344, Train Acc: 0.814103 | Val Loss: 0.133867, Val Acc: 0.773196\n",
      "Epoch 11990 - Train Loss: 0.115338, Train Acc: 0.815385 | Val Loss: 0.133862, Val Acc: 0.773196\n",
      "Epoch 11991 - Train Loss: 0.115332, Train Acc: 0.815385 | Val Loss: 0.133858, Val Acc: 0.773196\n",
      "Epoch 11992 - Train Loss: 0.115326, Train Acc: 0.815385 | Val Loss: 0.133853, Val Acc: 0.773196\n",
      "Epoch 11993 - Train Loss: 0.115320, Train Acc: 0.815385 | Val Loss: 0.133848, Val Acc: 0.773196\n",
      "Epoch 11994 - Train Loss: 0.115314, Train Acc: 0.815385 | Val Loss: 0.133843, Val Acc: 0.773196\n",
      "Epoch 11995 - Train Loss: 0.115308, Train Acc: 0.815385 | Val Loss: 0.133838, Val Acc: 0.773196\n",
      "Epoch 11996 - Train Loss: 0.115302, Train Acc: 0.815385 | Val Loss: 0.133834, Val Acc: 0.773196\n",
      "Epoch 11997 - Train Loss: 0.115296, Train Acc: 0.815385 | Val Loss: 0.133829, Val Acc: 0.773196\n",
      "Epoch 11998 - Train Loss: 0.115290, Train Acc: 0.815385 | Val Loss: 0.133824, Val Acc: 0.773196\n",
      "Epoch 11999 - Train Loss: 0.115284, Train Acc: 0.815385 | Val Loss: 0.133819, Val Acc: 0.773196\n",
      "Epoch 12000 - Train Loss: 0.115278, Train Acc: 0.815385 | Val Loss: 0.133815, Val Acc: 0.773196\n",
      "Epoch 12001 - Train Loss: 0.115272, Train Acc: 0.815385 | Val Loss: 0.133810, Val Acc: 0.773196\n",
      "Epoch 12002 - Train Loss: 0.115266, Train Acc: 0.815385 | Val Loss: 0.133805, Val Acc: 0.773196\n",
      "Epoch 12003 - Train Loss: 0.115260, Train Acc: 0.815385 | Val Loss: 0.133800, Val Acc: 0.773196\n",
      "Epoch 12004 - Train Loss: 0.115254, Train Acc: 0.815385 | Val Loss: 0.133796, Val Acc: 0.773196\n",
      "Epoch 12005 - Train Loss: 0.115248, Train Acc: 0.815385 | Val Loss: 0.133791, Val Acc: 0.773196\n",
      "Epoch 12006 - Train Loss: 0.115242, Train Acc: 0.815385 | Val Loss: 0.133786, Val Acc: 0.773196\n",
      "Epoch 12007 - Train Loss: 0.115236, Train Acc: 0.815385 | Val Loss: 0.133781, Val Acc: 0.773196\n",
      "Epoch 12008 - Train Loss: 0.115230, Train Acc: 0.815385 | Val Loss: 0.133777, Val Acc: 0.773196\n",
      "Epoch 12009 - Train Loss: 0.115224, Train Acc: 0.815385 | Val Loss: 0.133772, Val Acc: 0.773196\n",
      "Epoch 12010 - Train Loss: 0.115218, Train Acc: 0.815385 | Val Loss: 0.133767, Val Acc: 0.773196\n",
      "Epoch 12011 - Train Loss: 0.115212, Train Acc: 0.815385 | Val Loss: 0.133762, Val Acc: 0.773196\n",
      "Epoch 12012 - Train Loss: 0.115206, Train Acc: 0.815385 | Val Loss: 0.133758, Val Acc: 0.773196\n",
      "Epoch 12013 - Train Loss: 0.115201, Train Acc: 0.815385 | Val Loss: 0.133753, Val Acc: 0.773196\n",
      "Epoch 12014 - Train Loss: 0.115195, Train Acc: 0.815385 | Val Loss: 0.133748, Val Acc: 0.773196\n",
      "Epoch 12015 - Train Loss: 0.115189, Train Acc: 0.815385 | Val Loss: 0.133744, Val Acc: 0.773196\n",
      "Epoch 12016 - Train Loss: 0.115183, Train Acc: 0.815385 | Val Loss: 0.133739, Val Acc: 0.773196\n",
      "Epoch 12017 - Train Loss: 0.115177, Train Acc: 0.815385 | Val Loss: 0.133734, Val Acc: 0.773196\n",
      "Epoch 12018 - Train Loss: 0.115171, Train Acc: 0.815385 | Val Loss: 0.133729, Val Acc: 0.773196\n",
      "Epoch 12019 - Train Loss: 0.115165, Train Acc: 0.815385 | Val Loss: 0.133725, Val Acc: 0.773196\n",
      "Epoch 12020 - Train Loss: 0.115159, Train Acc: 0.815385 | Val Loss: 0.133720, Val Acc: 0.773196\n",
      "Epoch 12021 - Train Loss: 0.115153, Train Acc: 0.815385 | Val Loss: 0.133715, Val Acc: 0.773196\n",
      "Epoch 12022 - Train Loss: 0.115147, Train Acc: 0.816667 | Val Loss: 0.133710, Val Acc: 0.773196\n",
      "Epoch 12023 - Train Loss: 0.115141, Train Acc: 0.816667 | Val Loss: 0.133706, Val Acc: 0.773196\n",
      "Epoch 12024 - Train Loss: 0.115135, Train Acc: 0.816667 | Val Loss: 0.133701, Val Acc: 0.773196\n",
      "Epoch 12025 - Train Loss: 0.115129, Train Acc: 0.816667 | Val Loss: 0.133696, Val Acc: 0.773196\n",
      "Epoch 12026 - Train Loss: 0.115123, Train Acc: 0.816667 | Val Loss: 0.133691, Val Acc: 0.773196\n",
      "Epoch 12027 - Train Loss: 0.115117, Train Acc: 0.816667 | Val Loss: 0.133687, Val Acc: 0.773196\n",
      "Epoch 12028 - Train Loss: 0.115111, Train Acc: 0.816667 | Val Loss: 0.133682, Val Acc: 0.773196\n",
      "Epoch 12029 - Train Loss: 0.115105, Train Acc: 0.816667 | Val Loss: 0.133677, Val Acc: 0.773196\n",
      "Epoch 12030 - Train Loss: 0.115099, Train Acc: 0.816667 | Val Loss: 0.133672, Val Acc: 0.773196\n",
      "Epoch 12031 - Train Loss: 0.115094, Train Acc: 0.816667 | Val Loss: 0.133668, Val Acc: 0.773196\n",
      "Epoch 12032 - Train Loss: 0.115088, Train Acc: 0.816667 | Val Loss: 0.133663, Val Acc: 0.773196\n",
      "Epoch 12033 - Train Loss: 0.115082, Train Acc: 0.816667 | Val Loss: 0.133658, Val Acc: 0.773196\n",
      "Epoch 12034 - Train Loss: 0.115076, Train Acc: 0.816667 | Val Loss: 0.133653, Val Acc: 0.773196\n",
      "Epoch 12035 - Train Loss: 0.115070, Train Acc: 0.816667 | Val Loss: 0.133649, Val Acc: 0.773196\n",
      "Epoch 12036 - Train Loss: 0.115064, Train Acc: 0.816667 | Val Loss: 0.133644, Val Acc: 0.773196\n",
      "Epoch 12037 - Train Loss: 0.115058, Train Acc: 0.816667 | Val Loss: 0.133639, Val Acc: 0.773196\n",
      "Epoch 12038 - Train Loss: 0.115052, Train Acc: 0.816667 | Val Loss: 0.133635, Val Acc: 0.773196\n",
      "Epoch 12039 - Train Loss: 0.115046, Train Acc: 0.816667 | Val Loss: 0.133630, Val Acc: 0.773196\n",
      "Epoch 12040 - Train Loss: 0.115040, Train Acc: 0.816667 | Val Loss: 0.133625, Val Acc: 0.773196\n",
      "Epoch 12041 - Train Loss: 0.115034, Train Acc: 0.816667 | Val Loss: 0.133620, Val Acc: 0.773196\n",
      "Epoch 12042 - Train Loss: 0.115028, Train Acc: 0.816667 | Val Loss: 0.133616, Val Acc: 0.773196\n",
      "Epoch 12043 - Train Loss: 0.115022, Train Acc: 0.816667 | Val Loss: 0.133611, Val Acc: 0.773196\n",
      "Epoch 12044 - Train Loss: 0.115016, Train Acc: 0.816667 | Val Loss: 0.133606, Val Acc: 0.773196\n",
      "Epoch 12045 - Train Loss: 0.115011, Train Acc: 0.816667 | Val Loss: 0.133601, Val Acc: 0.773196\n",
      "Epoch 12046 - Train Loss: 0.115005, Train Acc: 0.816667 | Val Loss: 0.133597, Val Acc: 0.773196\n",
      "Epoch 12047 - Train Loss: 0.114999, Train Acc: 0.816667 | Val Loss: 0.133592, Val Acc: 0.773196\n",
      "Epoch 12048 - Train Loss: 0.114993, Train Acc: 0.816667 | Val Loss: 0.133587, Val Acc: 0.773196\n",
      "Epoch 12049 - Train Loss: 0.114987, Train Acc: 0.816667 | Val Loss: 0.133583, Val Acc: 0.773196\n",
      "Epoch 12050 - Train Loss: 0.114981, Train Acc: 0.816667 | Val Loss: 0.133578, Val Acc: 0.773196\n",
      "Epoch 12051 - Train Loss: 0.114975, Train Acc: 0.816667 | Val Loss: 0.133573, Val Acc: 0.773196\n",
      "Epoch 12052 - Train Loss: 0.114969, Train Acc: 0.816667 | Val Loss: 0.133568, Val Acc: 0.773196\n",
      "Epoch 12053 - Train Loss: 0.114963, Train Acc: 0.816667 | Val Loss: 0.133564, Val Acc: 0.773196\n",
      "Epoch 12054 - Train Loss: 0.114957, Train Acc: 0.816667 | Val Loss: 0.133559, Val Acc: 0.773196\n",
      "Epoch 12055 - Train Loss: 0.114951, Train Acc: 0.816667 | Val Loss: 0.133554, Val Acc: 0.773196\n",
      "Epoch 12056 - Train Loss: 0.114945, Train Acc: 0.816667 | Val Loss: 0.133550, Val Acc: 0.773196\n",
      "Epoch 12057 - Train Loss: 0.114940, Train Acc: 0.816667 | Val Loss: 0.133545, Val Acc: 0.773196\n",
      "Epoch 12058 - Train Loss: 0.114934, Train Acc: 0.816667 | Val Loss: 0.133540, Val Acc: 0.773196\n",
      "Epoch 12059 - Train Loss: 0.114928, Train Acc: 0.816667 | Val Loss: 0.133535, Val Acc: 0.773196\n",
      "Epoch 12060 - Train Loss: 0.114922, Train Acc: 0.816667 | Val Loss: 0.133531, Val Acc: 0.773196\n",
      "Epoch 12061 - Train Loss: 0.114916, Train Acc: 0.816667 | Val Loss: 0.133526, Val Acc: 0.773196\n",
      "Epoch 12062 - Train Loss: 0.114910, Train Acc: 0.816667 | Val Loss: 0.133521, Val Acc: 0.773196\n",
      "Epoch 12063 - Train Loss: 0.114904, Train Acc: 0.816667 | Val Loss: 0.133517, Val Acc: 0.773196\n",
      "Epoch 12064 - Train Loss: 0.114898, Train Acc: 0.816667 | Val Loss: 0.133512, Val Acc: 0.773196\n",
      "Epoch 12065 - Train Loss: 0.114892, Train Acc: 0.816667 | Val Loss: 0.133507, Val Acc: 0.773196\n",
      "Epoch 12066 - Train Loss: 0.114886, Train Acc: 0.816667 | Val Loss: 0.133502, Val Acc: 0.773196\n",
      "Epoch 12067 - Train Loss: 0.114880, Train Acc: 0.816667 | Val Loss: 0.133498, Val Acc: 0.773196\n",
      "Epoch 12068 - Train Loss: 0.114875, Train Acc: 0.816667 | Val Loss: 0.133493, Val Acc: 0.773196\n",
      "Epoch 12069 - Train Loss: 0.114869, Train Acc: 0.816667 | Val Loss: 0.133488, Val Acc: 0.773196\n",
      "Epoch 12070 - Train Loss: 0.114863, Train Acc: 0.816667 | Val Loss: 0.133484, Val Acc: 0.773196\n",
      "Epoch 12071 - Train Loss: 0.114857, Train Acc: 0.816667 | Val Loss: 0.133479, Val Acc: 0.773196\n",
      "Epoch 12072 - Train Loss: 0.114851, Train Acc: 0.816667 | Val Loss: 0.133474, Val Acc: 0.773196\n",
      "Epoch 12073 - Train Loss: 0.114845, Train Acc: 0.816667 | Val Loss: 0.133470, Val Acc: 0.773196\n",
      "Epoch 12074 - Train Loss: 0.114839, Train Acc: 0.816667 | Val Loss: 0.133465, Val Acc: 0.773196\n",
      "Epoch 12075 - Train Loss: 0.114833, Train Acc: 0.816667 | Val Loss: 0.133460, Val Acc: 0.773196\n",
      "Epoch 12076 - Train Loss: 0.114827, Train Acc: 0.816667 | Val Loss: 0.133456, Val Acc: 0.773196\n",
      "Epoch 12077 - Train Loss: 0.114822, Train Acc: 0.816667 | Val Loss: 0.133451, Val Acc: 0.773196\n",
      "Epoch 12078 - Train Loss: 0.114816, Train Acc: 0.816667 | Val Loss: 0.133446, Val Acc: 0.773196\n",
      "Epoch 12079 - Train Loss: 0.114810, Train Acc: 0.816667 | Val Loss: 0.133442, Val Acc: 0.773196\n",
      "Epoch 12080 - Train Loss: 0.114804, Train Acc: 0.816667 | Val Loss: 0.133437, Val Acc: 0.773196\n",
      "Epoch 12081 - Train Loss: 0.114798, Train Acc: 0.816667 | Val Loss: 0.133432, Val Acc: 0.773196\n",
      "Epoch 12082 - Train Loss: 0.114792, Train Acc: 0.816667 | Val Loss: 0.133427, Val Acc: 0.773196\n",
      "Epoch 12083 - Train Loss: 0.114786, Train Acc: 0.816667 | Val Loss: 0.133423, Val Acc: 0.773196\n",
      "Epoch 12084 - Train Loss: 0.114780, Train Acc: 0.816667 | Val Loss: 0.133418, Val Acc: 0.773196\n",
      "Epoch 12085 - Train Loss: 0.114774, Train Acc: 0.816667 | Val Loss: 0.133413, Val Acc: 0.773196\n",
      "Epoch 12086 - Train Loss: 0.114769, Train Acc: 0.816667 | Val Loss: 0.133409, Val Acc: 0.773196\n",
      "Epoch 12087 - Train Loss: 0.114763, Train Acc: 0.816667 | Val Loss: 0.133404, Val Acc: 0.773196\n",
      "Epoch 12088 - Train Loss: 0.114757, Train Acc: 0.816667 | Val Loss: 0.133399, Val Acc: 0.773196\n",
      "Epoch 12089 - Train Loss: 0.114751, Train Acc: 0.816667 | Val Loss: 0.133395, Val Acc: 0.773196\n",
      "Epoch 12090 - Train Loss: 0.114745, Train Acc: 0.816667 | Val Loss: 0.133390, Val Acc: 0.773196\n",
      "Epoch 12091 - Train Loss: 0.114739, Train Acc: 0.816667 | Val Loss: 0.133385, Val Acc: 0.773196\n",
      "Epoch 12092 - Train Loss: 0.114733, Train Acc: 0.816667 | Val Loss: 0.133381, Val Acc: 0.773196\n",
      "Epoch 12093 - Train Loss: 0.114727, Train Acc: 0.816667 | Val Loss: 0.133376, Val Acc: 0.773196\n",
      "Epoch 12094 - Train Loss: 0.114722, Train Acc: 0.816667 | Val Loss: 0.133371, Val Acc: 0.773196\n",
      "Epoch 12095 - Train Loss: 0.114716, Train Acc: 0.816667 | Val Loss: 0.133367, Val Acc: 0.773196\n",
      "Epoch 12096 - Train Loss: 0.114710, Train Acc: 0.816667 | Val Loss: 0.133362, Val Acc: 0.773196\n",
      "Epoch 12097 - Train Loss: 0.114704, Train Acc: 0.816667 | Val Loss: 0.133357, Val Acc: 0.773196\n",
      "Epoch 12098 - Train Loss: 0.114698, Train Acc: 0.816667 | Val Loss: 0.133353, Val Acc: 0.773196\n",
      "Epoch 12099 - Train Loss: 0.114692, Train Acc: 0.816667 | Val Loss: 0.133348, Val Acc: 0.773196\n",
      "Epoch 12100 - Train Loss: 0.114686, Train Acc: 0.816667 | Val Loss: 0.133343, Val Acc: 0.773196\n",
      "Epoch 12101 - Train Loss: 0.114680, Train Acc: 0.816667 | Val Loss: 0.133339, Val Acc: 0.773196\n",
      "Epoch 12102 - Train Loss: 0.114675, Train Acc: 0.816667 | Val Loss: 0.133334, Val Acc: 0.773196\n",
      "Epoch 12103 - Train Loss: 0.114669, Train Acc: 0.816667 | Val Loss: 0.133329, Val Acc: 0.773196\n",
      "Epoch 12104 - Train Loss: 0.114663, Train Acc: 0.816667 | Val Loss: 0.133325, Val Acc: 0.773196\n",
      "Epoch 12105 - Train Loss: 0.114657, Train Acc: 0.816667 | Val Loss: 0.133320, Val Acc: 0.773196\n",
      "Epoch 12106 - Train Loss: 0.114651, Train Acc: 0.816667 | Val Loss: 0.133315, Val Acc: 0.773196\n",
      "Epoch 12107 - Train Loss: 0.114645, Train Acc: 0.816667 | Val Loss: 0.133311, Val Acc: 0.773196\n",
      "Epoch 12108 - Train Loss: 0.114639, Train Acc: 0.816667 | Val Loss: 0.133306, Val Acc: 0.773196\n",
      "Epoch 12109 - Train Loss: 0.114634, Train Acc: 0.816667 | Val Loss: 0.133302, Val Acc: 0.773196\n",
      "Epoch 12110 - Train Loss: 0.114628, Train Acc: 0.816667 | Val Loss: 0.133297, Val Acc: 0.773196\n",
      "Epoch 12111 - Train Loss: 0.114622, Train Acc: 0.816667 | Val Loss: 0.133292, Val Acc: 0.773196\n",
      "Epoch 12112 - Train Loss: 0.114616, Train Acc: 0.816667 | Val Loss: 0.133288, Val Acc: 0.773196\n",
      "Epoch 12113 - Train Loss: 0.114610, Train Acc: 0.816667 | Val Loss: 0.133283, Val Acc: 0.773196\n",
      "Epoch 12114 - Train Loss: 0.114604, Train Acc: 0.816667 | Val Loss: 0.133278, Val Acc: 0.773196\n",
      "Epoch 12115 - Train Loss: 0.114598, Train Acc: 0.816667 | Val Loss: 0.133274, Val Acc: 0.773196\n",
      "Epoch 12116 - Train Loss: 0.114593, Train Acc: 0.816667 | Val Loss: 0.133269, Val Acc: 0.773196\n",
      "Epoch 12117 - Train Loss: 0.114587, Train Acc: 0.816667 | Val Loss: 0.133264, Val Acc: 0.773196\n",
      "Epoch 12118 - Train Loss: 0.114581, Train Acc: 0.816667 | Val Loss: 0.133260, Val Acc: 0.773196\n",
      "Epoch 12119 - Train Loss: 0.114575, Train Acc: 0.816667 | Val Loss: 0.133255, Val Acc: 0.773196\n",
      "Epoch 12120 - Train Loss: 0.114569, Train Acc: 0.816667 | Val Loss: 0.133250, Val Acc: 0.773196\n",
      "Epoch 12121 - Train Loss: 0.114563, Train Acc: 0.816667 | Val Loss: 0.133246, Val Acc: 0.773196\n",
      "Epoch 12122 - Train Loss: 0.114557, Train Acc: 0.816667 | Val Loss: 0.133241, Val Acc: 0.773196\n",
      "Epoch 12123 - Train Loss: 0.114552, Train Acc: 0.816667 | Val Loss: 0.133237, Val Acc: 0.773196\n",
      "Epoch 12124 - Train Loss: 0.114546, Train Acc: 0.816667 | Val Loss: 0.133232, Val Acc: 0.773196\n",
      "Epoch 12125 - Train Loss: 0.114540, Train Acc: 0.816667 | Val Loss: 0.133227, Val Acc: 0.773196\n",
      "Epoch 12126 - Train Loss: 0.114534, Train Acc: 0.816667 | Val Loss: 0.133223, Val Acc: 0.773196\n",
      "Epoch 12127 - Train Loss: 0.114528, Train Acc: 0.816667 | Val Loss: 0.133218, Val Acc: 0.773196\n",
      "Epoch 12128 - Train Loss: 0.114522, Train Acc: 0.816667 | Val Loss: 0.133213, Val Acc: 0.773196\n",
      "Epoch 12129 - Train Loss: 0.114517, Train Acc: 0.816667 | Val Loss: 0.133209, Val Acc: 0.773196\n",
      "Epoch 12130 - Train Loss: 0.114511, Train Acc: 0.816667 | Val Loss: 0.133204, Val Acc: 0.773196\n",
      "Epoch 12131 - Train Loss: 0.114505, Train Acc: 0.816667 | Val Loss: 0.133199, Val Acc: 0.773196\n",
      "Epoch 12132 - Train Loss: 0.114499, Train Acc: 0.816667 | Val Loss: 0.133195, Val Acc: 0.773196\n",
      "Epoch 12133 - Train Loss: 0.114493, Train Acc: 0.816667 | Val Loss: 0.133190, Val Acc: 0.773196\n",
      "Epoch 12134 - Train Loss: 0.114487, Train Acc: 0.816667 | Val Loss: 0.133186, Val Acc: 0.773196\n",
      "Epoch 12135 - Train Loss: 0.114482, Train Acc: 0.816667 | Val Loss: 0.133181, Val Acc: 0.773196\n",
      "Epoch 12136 - Train Loss: 0.114476, Train Acc: 0.816667 | Val Loss: 0.133176, Val Acc: 0.773196\n",
      "Epoch 12137 - Train Loss: 0.114470, Train Acc: 0.816667 | Val Loss: 0.133172, Val Acc: 0.773196\n",
      "Epoch 12138 - Train Loss: 0.114464, Train Acc: 0.816667 | Val Loss: 0.133167, Val Acc: 0.773196\n",
      "Epoch 12139 - Train Loss: 0.114458, Train Acc: 0.816667 | Val Loss: 0.133162, Val Acc: 0.773196\n",
      "Epoch 12140 - Train Loss: 0.114452, Train Acc: 0.816667 | Val Loss: 0.133158, Val Acc: 0.773196\n",
      "Epoch 12141 - Train Loss: 0.114447, Train Acc: 0.816667 | Val Loss: 0.133153, Val Acc: 0.773196\n",
      "Epoch 12142 - Train Loss: 0.114441, Train Acc: 0.816667 | Val Loss: 0.133149, Val Acc: 0.773196\n",
      "Epoch 12143 - Train Loss: 0.114435, Train Acc: 0.816667 | Val Loss: 0.133144, Val Acc: 0.773196\n",
      "Epoch 12144 - Train Loss: 0.114429, Train Acc: 0.816667 | Val Loss: 0.133139, Val Acc: 0.773196\n",
      "Epoch 12145 - Train Loss: 0.114423, Train Acc: 0.816667 | Val Loss: 0.133135, Val Acc: 0.773196\n",
      "Epoch 12146 - Train Loss: 0.114417, Train Acc: 0.816667 | Val Loss: 0.133130, Val Acc: 0.773196\n",
      "Epoch 12147 - Train Loss: 0.114412, Train Acc: 0.816667 | Val Loss: 0.133126, Val Acc: 0.773196\n",
      "Epoch 12148 - Train Loss: 0.114406, Train Acc: 0.816667 | Val Loss: 0.133121, Val Acc: 0.773196\n",
      "Epoch 12149 - Train Loss: 0.114400, Train Acc: 0.816667 | Val Loss: 0.133116, Val Acc: 0.773196\n",
      "Epoch 12150 - Train Loss: 0.114394, Train Acc: 0.816667 | Val Loss: 0.133112, Val Acc: 0.773196\n",
      "Epoch 12151 - Train Loss: 0.114388, Train Acc: 0.816667 | Val Loss: 0.133107, Val Acc: 0.773196\n",
      "Epoch 12152 - Train Loss: 0.114383, Train Acc: 0.816667 | Val Loss: 0.133103, Val Acc: 0.773196\n",
      "Epoch 12153 - Train Loss: 0.114377, Train Acc: 0.816667 | Val Loss: 0.133098, Val Acc: 0.773196\n",
      "Epoch 12154 - Train Loss: 0.114371, Train Acc: 0.816667 | Val Loss: 0.133093, Val Acc: 0.773196\n",
      "Epoch 12155 - Train Loss: 0.114365, Train Acc: 0.816667 | Val Loss: 0.133089, Val Acc: 0.773196\n",
      "Epoch 12156 - Train Loss: 0.114359, Train Acc: 0.816667 | Val Loss: 0.133084, Val Acc: 0.773196\n",
      "Epoch 12157 - Train Loss: 0.114353, Train Acc: 0.816667 | Val Loss: 0.133080, Val Acc: 0.773196\n",
      "Epoch 12158 - Train Loss: 0.114348, Train Acc: 0.816667 | Val Loss: 0.133075, Val Acc: 0.773196\n",
      "Epoch 12159 - Train Loss: 0.114342, Train Acc: 0.816667 | Val Loss: 0.133070, Val Acc: 0.773196\n",
      "Epoch 12160 - Train Loss: 0.114336, Train Acc: 0.816667 | Val Loss: 0.133066, Val Acc: 0.773196\n",
      "Epoch 12161 - Train Loss: 0.114330, Train Acc: 0.816667 | Val Loss: 0.133061, Val Acc: 0.773196\n",
      "Epoch 12162 - Train Loss: 0.114324, Train Acc: 0.816667 | Val Loss: 0.133057, Val Acc: 0.773196\n",
      "Epoch 12163 - Train Loss: 0.114319, Train Acc: 0.816667 | Val Loss: 0.133052, Val Acc: 0.773196\n",
      "Epoch 12164 - Train Loss: 0.114313, Train Acc: 0.816667 | Val Loss: 0.133047, Val Acc: 0.773196\n",
      "Epoch 12165 - Train Loss: 0.114307, Train Acc: 0.816667 | Val Loss: 0.133043, Val Acc: 0.773196\n",
      "Epoch 12166 - Train Loss: 0.114301, Train Acc: 0.816667 | Val Loss: 0.133038, Val Acc: 0.773196\n",
      "Epoch 12167 - Train Loss: 0.114295, Train Acc: 0.816667 | Val Loss: 0.133034, Val Acc: 0.773196\n",
      "Epoch 12168 - Train Loss: 0.114290, Train Acc: 0.816667 | Val Loss: 0.133029, Val Acc: 0.773196\n",
      "Epoch 12169 - Train Loss: 0.114284, Train Acc: 0.816667 | Val Loss: 0.133024, Val Acc: 0.773196\n",
      "Epoch 12170 - Train Loss: 0.114278, Train Acc: 0.816667 | Val Loss: 0.133020, Val Acc: 0.773196\n",
      "Epoch 12171 - Train Loss: 0.114272, Train Acc: 0.816667 | Val Loss: 0.133015, Val Acc: 0.773196\n",
      "Epoch 12172 - Train Loss: 0.114266, Train Acc: 0.816667 | Val Loss: 0.133011, Val Acc: 0.773196\n",
      "Epoch 12173 - Train Loss: 0.114261, Train Acc: 0.816667 | Val Loss: 0.133006, Val Acc: 0.773196\n",
      "Epoch 12174 - Train Loss: 0.114255, Train Acc: 0.816667 | Val Loss: 0.133001, Val Acc: 0.773196\n",
      "Epoch 12175 - Train Loss: 0.114249, Train Acc: 0.816667 | Val Loss: 0.132997, Val Acc: 0.773196\n",
      "Epoch 12176 - Train Loss: 0.114243, Train Acc: 0.816667 | Val Loss: 0.132992, Val Acc: 0.773196\n",
      "Epoch 12177 - Train Loss: 0.114237, Train Acc: 0.816667 | Val Loss: 0.132988, Val Acc: 0.773196\n",
      "Epoch 12178 - Train Loss: 0.114232, Train Acc: 0.816667 | Val Loss: 0.132983, Val Acc: 0.773196\n",
      "Epoch 12179 - Train Loss: 0.114226, Train Acc: 0.816667 | Val Loss: 0.132979, Val Acc: 0.773196\n",
      "Epoch 12180 - Train Loss: 0.114220, Train Acc: 0.816667 | Val Loss: 0.132974, Val Acc: 0.773196\n",
      "Epoch 12181 - Train Loss: 0.114214, Train Acc: 0.816667 | Val Loss: 0.132969, Val Acc: 0.773196\n",
      "Epoch 12182 - Train Loss: 0.114208, Train Acc: 0.816667 | Val Loss: 0.132965, Val Acc: 0.773196\n",
      "Epoch 12183 - Train Loss: 0.114203, Train Acc: 0.816667 | Val Loss: 0.132960, Val Acc: 0.773196\n",
      "Epoch 12184 - Train Loss: 0.114197, Train Acc: 0.816667 | Val Loss: 0.132956, Val Acc: 0.773196\n",
      "Epoch 12185 - Train Loss: 0.114191, Train Acc: 0.816667 | Val Loss: 0.132951, Val Acc: 0.773196\n",
      "Epoch 12186 - Train Loss: 0.114185, Train Acc: 0.816667 | Val Loss: 0.132947, Val Acc: 0.773196\n",
      "Epoch 12187 - Train Loss: 0.114179, Train Acc: 0.816667 | Val Loss: 0.132942, Val Acc: 0.773196\n",
      "Epoch 12188 - Train Loss: 0.114174, Train Acc: 0.816667 | Val Loss: 0.132937, Val Acc: 0.773196\n",
      "Epoch 12189 - Train Loss: 0.114168, Train Acc: 0.816667 | Val Loss: 0.132933, Val Acc: 0.773196\n",
      "Epoch 12190 - Train Loss: 0.114162, Train Acc: 0.816667 | Val Loss: 0.132928, Val Acc: 0.773196\n",
      "Epoch 12191 - Train Loss: 0.114156, Train Acc: 0.816667 | Val Loss: 0.132924, Val Acc: 0.773196\n",
      "Epoch 12192 - Train Loss: 0.114151, Train Acc: 0.816667 | Val Loss: 0.132919, Val Acc: 0.773196\n",
      "Epoch 12193 - Train Loss: 0.114145, Train Acc: 0.816667 | Val Loss: 0.132915, Val Acc: 0.773196\n",
      "Epoch 12194 - Train Loss: 0.114139, Train Acc: 0.816667 | Val Loss: 0.132910, Val Acc: 0.773196\n",
      "Epoch 12195 - Train Loss: 0.114133, Train Acc: 0.816667 | Val Loss: 0.132905, Val Acc: 0.773196\n",
      "Epoch 12196 - Train Loss: 0.114127, Train Acc: 0.816667 | Val Loss: 0.132901, Val Acc: 0.773196\n",
      "Epoch 12197 - Train Loss: 0.114122, Train Acc: 0.816667 | Val Loss: 0.132896, Val Acc: 0.773196\n",
      "Epoch 12198 - Train Loss: 0.114116, Train Acc: 0.816667 | Val Loss: 0.132892, Val Acc: 0.773196\n",
      "Epoch 12199 - Train Loss: 0.114110, Train Acc: 0.816667 | Val Loss: 0.132887, Val Acc: 0.773196\n",
      "Epoch 12200 - Train Loss: 0.114104, Train Acc: 0.816667 | Val Loss: 0.132883, Val Acc: 0.773196\n",
      "Epoch 12201 - Train Loss: 0.114099, Train Acc: 0.816667 | Val Loss: 0.132878, Val Acc: 0.773196\n",
      "Epoch 12202 - Train Loss: 0.114093, Train Acc: 0.816667 | Val Loss: 0.132873, Val Acc: 0.773196\n",
      "Epoch 12203 - Train Loss: 0.114087, Train Acc: 0.816667 | Val Loss: 0.132869, Val Acc: 0.773196\n",
      "Epoch 12204 - Train Loss: 0.114081, Train Acc: 0.816667 | Val Loss: 0.132864, Val Acc: 0.773196\n",
      "Epoch 12205 - Train Loss: 0.114076, Train Acc: 0.816667 | Val Loss: 0.132860, Val Acc: 0.773196\n",
      "Epoch 12206 - Train Loss: 0.114070, Train Acc: 0.816667 | Val Loss: 0.132855, Val Acc: 0.773196\n",
      "Epoch 12207 - Train Loss: 0.114064, Train Acc: 0.816667 | Val Loss: 0.132851, Val Acc: 0.773196\n",
      "Epoch 12208 - Train Loss: 0.114058, Train Acc: 0.816667 | Val Loss: 0.132846, Val Acc: 0.773196\n",
      "Epoch 12209 - Train Loss: 0.114052, Train Acc: 0.816667 | Val Loss: 0.132842, Val Acc: 0.773196\n",
      "Epoch 12210 - Train Loss: 0.114047, Train Acc: 0.816667 | Val Loss: 0.132837, Val Acc: 0.773196\n",
      "Epoch 12211 - Train Loss: 0.114041, Train Acc: 0.816667 | Val Loss: 0.132833, Val Acc: 0.773196\n",
      "Epoch 12212 - Train Loss: 0.114035, Train Acc: 0.816667 | Val Loss: 0.132828, Val Acc: 0.773196\n",
      "Epoch 12213 - Train Loss: 0.114029, Train Acc: 0.816667 | Val Loss: 0.132823, Val Acc: 0.773196\n",
      "Epoch 12214 - Train Loss: 0.114024, Train Acc: 0.816667 | Val Loss: 0.132819, Val Acc: 0.773196\n",
      "Epoch 12215 - Train Loss: 0.114018, Train Acc: 0.816667 | Val Loss: 0.132814, Val Acc: 0.773196\n",
      "Epoch 12216 - Train Loss: 0.114012, Train Acc: 0.816667 | Val Loss: 0.132810, Val Acc: 0.773196\n",
      "Epoch 12217 - Train Loss: 0.114006, Train Acc: 0.816667 | Val Loss: 0.132805, Val Acc: 0.773196\n",
      "Epoch 12218 - Train Loss: 0.114001, Train Acc: 0.816667 | Val Loss: 0.132801, Val Acc: 0.773196\n",
      "Epoch 12219 - Train Loss: 0.113995, Train Acc: 0.816667 | Val Loss: 0.132796, Val Acc: 0.773196\n",
      "Epoch 12220 - Train Loss: 0.113989, Train Acc: 0.816667 | Val Loss: 0.132792, Val Acc: 0.773196\n",
      "Epoch 12221 - Train Loss: 0.113983, Train Acc: 0.816667 | Val Loss: 0.132787, Val Acc: 0.773196\n",
      "Epoch 12222 - Train Loss: 0.113978, Train Acc: 0.816667 | Val Loss: 0.132783, Val Acc: 0.773196\n",
      "Epoch 12223 - Train Loss: 0.113972, Train Acc: 0.816667 | Val Loss: 0.132778, Val Acc: 0.773196\n",
      "Epoch 12224 - Train Loss: 0.113966, Train Acc: 0.816667 | Val Loss: 0.132773, Val Acc: 0.773196\n",
      "Epoch 12225 - Train Loss: 0.113960, Train Acc: 0.816667 | Val Loss: 0.132769, Val Acc: 0.773196\n",
      "Epoch 12226 - Train Loss: 0.113955, Train Acc: 0.816667 | Val Loss: 0.132764, Val Acc: 0.773196\n",
      "Epoch 12227 - Train Loss: 0.113949, Train Acc: 0.816667 | Val Loss: 0.132760, Val Acc: 0.773196\n",
      "Epoch 12228 - Train Loss: 0.113943, Train Acc: 0.816667 | Val Loss: 0.132755, Val Acc: 0.773196\n",
      "Epoch 12229 - Train Loss: 0.113937, Train Acc: 0.816667 | Val Loss: 0.132751, Val Acc: 0.773196\n",
      "Epoch 12230 - Train Loss: 0.113932, Train Acc: 0.816667 | Val Loss: 0.132746, Val Acc: 0.773196\n",
      "Epoch 12231 - Train Loss: 0.113926, Train Acc: 0.816667 | Val Loss: 0.132742, Val Acc: 0.773196\n",
      "Epoch 12232 - Train Loss: 0.113920, Train Acc: 0.816667 | Val Loss: 0.132737, Val Acc: 0.773196\n",
      "Epoch 12233 - Train Loss: 0.113914, Train Acc: 0.816667 | Val Loss: 0.132733, Val Acc: 0.773196\n",
      "Epoch 12234 - Train Loss: 0.113909, Train Acc: 0.816667 | Val Loss: 0.132728, Val Acc: 0.773196\n",
      "Epoch 12235 - Train Loss: 0.113903, Train Acc: 0.816667 | Val Loss: 0.132724, Val Acc: 0.773196\n",
      "Epoch 12236 - Train Loss: 0.113897, Train Acc: 0.816667 | Val Loss: 0.132719, Val Acc: 0.773196\n",
      "Epoch 12237 - Train Loss: 0.113892, Train Acc: 0.816667 | Val Loss: 0.132715, Val Acc: 0.773196\n",
      "Epoch 12238 - Train Loss: 0.113886, Train Acc: 0.816667 | Val Loss: 0.132710, Val Acc: 0.773196\n",
      "Epoch 12239 - Train Loss: 0.113880, Train Acc: 0.816667 | Val Loss: 0.132706, Val Acc: 0.773196\n",
      "Epoch 12240 - Train Loss: 0.113874, Train Acc: 0.816667 | Val Loss: 0.132701, Val Acc: 0.773196\n",
      "Epoch 12241 - Train Loss: 0.113869, Train Acc: 0.816667 | Val Loss: 0.132697, Val Acc: 0.773196\n",
      "Epoch 12242 - Train Loss: 0.113863, Train Acc: 0.816667 | Val Loss: 0.132692, Val Acc: 0.773196\n",
      "Epoch 12243 - Train Loss: 0.113857, Train Acc: 0.816667 | Val Loss: 0.132687, Val Acc: 0.773196\n",
      "Epoch 12244 - Train Loss: 0.113851, Train Acc: 0.816667 | Val Loss: 0.132683, Val Acc: 0.773196\n",
      "Epoch 12245 - Train Loss: 0.113846, Train Acc: 0.816667 | Val Loss: 0.132678, Val Acc: 0.773196\n",
      "Epoch 12246 - Train Loss: 0.113840, Train Acc: 0.816667 | Val Loss: 0.132674, Val Acc: 0.773196\n",
      "Epoch 12247 - Train Loss: 0.113834, Train Acc: 0.816667 | Val Loss: 0.132669, Val Acc: 0.773196\n",
      "Epoch 12248 - Train Loss: 0.113828, Train Acc: 0.817949 | Val Loss: 0.132665, Val Acc: 0.773196\n",
      "Epoch 12249 - Train Loss: 0.113823, Train Acc: 0.817949 | Val Loss: 0.132660, Val Acc: 0.773196\n",
      "Epoch 12250 - Train Loss: 0.113817, Train Acc: 0.817949 | Val Loss: 0.132656, Val Acc: 0.773196\n",
      "Epoch 12251 - Train Loss: 0.113811, Train Acc: 0.817949 | Val Loss: 0.132651, Val Acc: 0.773196\n",
      "Epoch 12252 - Train Loss: 0.113806, Train Acc: 0.817949 | Val Loss: 0.132647, Val Acc: 0.773196\n",
      "Epoch 12253 - Train Loss: 0.113800, Train Acc: 0.817949 | Val Loss: 0.132642, Val Acc: 0.773196\n",
      "Epoch 12254 - Train Loss: 0.113794, Train Acc: 0.817949 | Val Loss: 0.132638, Val Acc: 0.773196\n",
      "Epoch 12255 - Train Loss: 0.113788, Train Acc: 0.817949 | Val Loss: 0.132633, Val Acc: 0.773196\n",
      "Epoch 12256 - Train Loss: 0.113783, Train Acc: 0.817949 | Val Loss: 0.132629, Val Acc: 0.773196\n",
      "Epoch 12257 - Train Loss: 0.113777, Train Acc: 0.817949 | Val Loss: 0.132624, Val Acc: 0.773196\n",
      "Epoch 12258 - Train Loss: 0.113771, Train Acc: 0.817949 | Val Loss: 0.132620, Val Acc: 0.773196\n",
      "Epoch 12259 - Train Loss: 0.113766, Train Acc: 0.817949 | Val Loss: 0.132615, Val Acc: 0.773196\n",
      "Epoch 12260 - Train Loss: 0.113760, Train Acc: 0.817949 | Val Loss: 0.132611, Val Acc: 0.773196\n",
      "Epoch 12261 - Train Loss: 0.113754, Train Acc: 0.817949 | Val Loss: 0.132606, Val Acc: 0.773196\n",
      "Epoch 12262 - Train Loss: 0.113748, Train Acc: 0.817949 | Val Loss: 0.132602, Val Acc: 0.773196\n",
      "Epoch 12263 - Train Loss: 0.113743, Train Acc: 0.817949 | Val Loss: 0.132597, Val Acc: 0.773196\n",
      "Epoch 12264 - Train Loss: 0.113737, Train Acc: 0.817949 | Val Loss: 0.132593, Val Acc: 0.773196\n",
      "Epoch 12265 - Train Loss: 0.113731, Train Acc: 0.817949 | Val Loss: 0.132588, Val Acc: 0.773196\n",
      "Epoch 12266 - Train Loss: 0.113726, Train Acc: 0.817949 | Val Loss: 0.132584, Val Acc: 0.773196\n",
      "Epoch 12267 - Train Loss: 0.113720, Train Acc: 0.817949 | Val Loss: 0.132579, Val Acc: 0.773196\n",
      "Epoch 12268 - Train Loss: 0.113714, Train Acc: 0.817949 | Val Loss: 0.132575, Val Acc: 0.773196\n",
      "Epoch 12269 - Train Loss: 0.113708, Train Acc: 0.817949 | Val Loss: 0.132570, Val Acc: 0.773196\n",
      "Epoch 12270 - Train Loss: 0.113703, Train Acc: 0.817949 | Val Loss: 0.132566, Val Acc: 0.773196\n",
      "Epoch 12271 - Train Loss: 0.113697, Train Acc: 0.817949 | Val Loss: 0.132561, Val Acc: 0.773196\n",
      "Epoch 12272 - Train Loss: 0.113691, Train Acc: 0.817949 | Val Loss: 0.132557, Val Acc: 0.773196\n",
      "Epoch 12273 - Train Loss: 0.113686, Train Acc: 0.817949 | Val Loss: 0.132552, Val Acc: 0.773196\n",
      "Epoch 12274 - Train Loss: 0.113680, Train Acc: 0.817949 | Val Loss: 0.132548, Val Acc: 0.773196\n",
      "Epoch 12275 - Train Loss: 0.113674, Train Acc: 0.817949 | Val Loss: 0.132543, Val Acc: 0.773196\n",
      "Epoch 12276 - Train Loss: 0.113669, Train Acc: 0.817949 | Val Loss: 0.132539, Val Acc: 0.773196\n",
      "Epoch 12277 - Train Loss: 0.113663, Train Acc: 0.817949 | Val Loss: 0.132535, Val Acc: 0.773196\n",
      "Epoch 12278 - Train Loss: 0.113657, Train Acc: 0.817949 | Val Loss: 0.132530, Val Acc: 0.773196\n",
      "Epoch 12279 - Train Loss: 0.113651, Train Acc: 0.817949 | Val Loss: 0.132526, Val Acc: 0.773196\n",
      "Epoch 12280 - Train Loss: 0.113646, Train Acc: 0.817949 | Val Loss: 0.132521, Val Acc: 0.773196\n",
      "Epoch 12281 - Train Loss: 0.113640, Train Acc: 0.817949 | Val Loss: 0.132517, Val Acc: 0.773196\n",
      "Epoch 12282 - Train Loss: 0.113634, Train Acc: 0.817949 | Val Loss: 0.132512, Val Acc: 0.773196\n",
      "Epoch 12283 - Train Loss: 0.113629, Train Acc: 0.817949 | Val Loss: 0.132508, Val Acc: 0.773196\n",
      "Epoch 12284 - Train Loss: 0.113623, Train Acc: 0.817949 | Val Loss: 0.132503, Val Acc: 0.773196\n",
      "Epoch 12285 - Train Loss: 0.113617, Train Acc: 0.817949 | Val Loss: 0.132499, Val Acc: 0.773196\n",
      "Epoch 12286 - Train Loss: 0.113612, Train Acc: 0.817949 | Val Loss: 0.132494, Val Acc: 0.773196\n",
      "Epoch 12287 - Train Loss: 0.113606, Train Acc: 0.817949 | Val Loss: 0.132490, Val Acc: 0.773196\n",
      "Epoch 12288 - Train Loss: 0.113600, Train Acc: 0.817949 | Val Loss: 0.132485, Val Acc: 0.773196\n",
      "Epoch 12289 - Train Loss: 0.113595, Train Acc: 0.817949 | Val Loss: 0.132481, Val Acc: 0.773196\n",
      "Epoch 12290 - Train Loss: 0.113589, Train Acc: 0.817949 | Val Loss: 0.132476, Val Acc: 0.773196\n",
      "Epoch 12291 - Train Loss: 0.113583, Train Acc: 0.817949 | Val Loss: 0.132472, Val Acc: 0.773196\n",
      "Epoch 12292 - Train Loss: 0.113577, Train Acc: 0.817949 | Val Loss: 0.132467, Val Acc: 0.773196\n",
      "Epoch 12293 - Train Loss: 0.113572, Train Acc: 0.817949 | Val Loss: 0.132463, Val Acc: 0.773196\n",
      "Epoch 12294 - Train Loss: 0.113566, Train Acc: 0.817949 | Val Loss: 0.132458, Val Acc: 0.773196\n",
      "Epoch 12295 - Train Loss: 0.113560, Train Acc: 0.817949 | Val Loss: 0.132454, Val Acc: 0.773196\n",
      "Epoch 12296 - Train Loss: 0.113555, Train Acc: 0.817949 | Val Loss: 0.132450, Val Acc: 0.773196\n",
      "Epoch 12297 - Train Loss: 0.113549, Train Acc: 0.817949 | Val Loss: 0.132445, Val Acc: 0.773196\n",
      "Epoch 12298 - Train Loss: 0.113543, Train Acc: 0.817949 | Val Loss: 0.132441, Val Acc: 0.773196\n",
      "Epoch 12299 - Train Loss: 0.113538, Train Acc: 0.817949 | Val Loss: 0.132436, Val Acc: 0.773196\n",
      "Epoch 12300 - Train Loss: 0.113532, Train Acc: 0.817949 | Val Loss: 0.132432, Val Acc: 0.773196\n",
      "Epoch 12301 - Train Loss: 0.113526, Train Acc: 0.817949 | Val Loss: 0.132427, Val Acc: 0.773196\n",
      "Epoch 12302 - Train Loss: 0.113521, Train Acc: 0.817949 | Val Loss: 0.132423, Val Acc: 0.773196\n",
      "Epoch 12303 - Train Loss: 0.113515, Train Acc: 0.817949 | Val Loss: 0.132418, Val Acc: 0.773196\n",
      "Epoch 12304 - Train Loss: 0.113509, Train Acc: 0.817949 | Val Loss: 0.132414, Val Acc: 0.773196\n",
      "Epoch 12305 - Train Loss: 0.113504, Train Acc: 0.817949 | Val Loss: 0.132409, Val Acc: 0.773196\n",
      "Epoch 12306 - Train Loss: 0.113498, Train Acc: 0.817949 | Val Loss: 0.132405, Val Acc: 0.773196\n",
      "Epoch 12307 - Train Loss: 0.113492, Train Acc: 0.817949 | Val Loss: 0.132400, Val Acc: 0.773196\n",
      "Epoch 12308 - Train Loss: 0.113487, Train Acc: 0.817949 | Val Loss: 0.132396, Val Acc: 0.773196\n",
      "Epoch 12309 - Train Loss: 0.113481, Train Acc: 0.817949 | Val Loss: 0.132392, Val Acc: 0.773196\n",
      "Epoch 12310 - Train Loss: 0.113475, Train Acc: 0.817949 | Val Loss: 0.132387, Val Acc: 0.773196\n",
      "Epoch 12311 - Train Loss: 0.113470, Train Acc: 0.817949 | Val Loss: 0.132383, Val Acc: 0.773196\n",
      "Epoch 12312 - Train Loss: 0.113464, Train Acc: 0.817949 | Val Loss: 0.132378, Val Acc: 0.773196\n",
      "Epoch 12313 - Train Loss: 0.113458, Train Acc: 0.817949 | Val Loss: 0.132374, Val Acc: 0.773196\n",
      "Epoch 12314 - Train Loss: 0.113453, Train Acc: 0.817949 | Val Loss: 0.132369, Val Acc: 0.773196\n",
      "Epoch 12315 - Train Loss: 0.113447, Train Acc: 0.817949 | Val Loss: 0.132365, Val Acc: 0.773196\n",
      "Epoch 12316 - Train Loss: 0.113441, Train Acc: 0.817949 | Val Loss: 0.132360, Val Acc: 0.773196\n",
      "Epoch 12317 - Train Loss: 0.113436, Train Acc: 0.817949 | Val Loss: 0.132356, Val Acc: 0.773196\n",
      "Epoch 12318 - Train Loss: 0.113430, Train Acc: 0.817949 | Val Loss: 0.132352, Val Acc: 0.773196\n",
      "Epoch 12319 - Train Loss: 0.113424, Train Acc: 0.817949 | Val Loss: 0.132347, Val Acc: 0.773196\n",
      "Epoch 12320 - Train Loss: 0.113419, Train Acc: 0.817949 | Val Loss: 0.132343, Val Acc: 0.773196\n",
      "Epoch 12321 - Train Loss: 0.113413, Train Acc: 0.817949 | Val Loss: 0.132338, Val Acc: 0.773196\n",
      "Epoch 12322 - Train Loss: 0.113407, Train Acc: 0.817949 | Val Loss: 0.132334, Val Acc: 0.773196\n",
      "Epoch 12323 - Train Loss: 0.113402, Train Acc: 0.817949 | Val Loss: 0.132329, Val Acc: 0.773196\n",
      "Epoch 12324 - Train Loss: 0.113396, Train Acc: 0.817949 | Val Loss: 0.132325, Val Acc: 0.773196\n",
      "Epoch 12325 - Train Loss: 0.113390, Train Acc: 0.817949 | Val Loss: 0.132320, Val Acc: 0.773196\n",
      "Epoch 12326 - Train Loss: 0.113385, Train Acc: 0.817949 | Val Loss: 0.132316, Val Acc: 0.773196\n",
      "Epoch 12327 - Train Loss: 0.113379, Train Acc: 0.817949 | Val Loss: 0.132312, Val Acc: 0.773196\n",
      "Epoch 12328 - Train Loss: 0.113373, Train Acc: 0.817949 | Val Loss: 0.132307, Val Acc: 0.773196\n",
      "Epoch 12329 - Train Loss: 0.113368, Train Acc: 0.817949 | Val Loss: 0.132303, Val Acc: 0.773196\n",
      "Epoch 12330 - Train Loss: 0.113362, Train Acc: 0.817949 | Val Loss: 0.132298, Val Acc: 0.773196\n",
      "Epoch 12331 - Train Loss: 0.113357, Train Acc: 0.817949 | Val Loss: 0.132294, Val Acc: 0.773196\n",
      "Epoch 12332 - Train Loss: 0.113351, Train Acc: 0.817949 | Val Loss: 0.132289, Val Acc: 0.773196\n",
      "Epoch 12333 - Train Loss: 0.113345, Train Acc: 0.817949 | Val Loss: 0.132285, Val Acc: 0.773196\n",
      "Epoch 12334 - Train Loss: 0.113340, Train Acc: 0.817949 | Val Loss: 0.132281, Val Acc: 0.773196\n",
      "Epoch 12335 - Train Loss: 0.113334, Train Acc: 0.817949 | Val Loss: 0.132276, Val Acc: 0.773196\n",
      "Epoch 12336 - Train Loss: 0.113328, Train Acc: 0.817949 | Val Loss: 0.132272, Val Acc: 0.773196\n",
      "Epoch 12337 - Train Loss: 0.113323, Train Acc: 0.817949 | Val Loss: 0.132267, Val Acc: 0.773196\n",
      "Epoch 12338 - Train Loss: 0.113317, Train Acc: 0.817949 | Val Loss: 0.132263, Val Acc: 0.773196\n",
      "Epoch 12339 - Train Loss: 0.113311, Train Acc: 0.817949 | Val Loss: 0.132258, Val Acc: 0.773196\n",
      "Epoch 12340 - Train Loss: 0.113306, Train Acc: 0.817949 | Val Loss: 0.132254, Val Acc: 0.773196\n",
      "Epoch 12341 - Train Loss: 0.113300, Train Acc: 0.817949 | Val Loss: 0.132250, Val Acc: 0.773196\n",
      "Epoch 12342 - Train Loss: 0.113294, Train Acc: 0.817949 | Val Loss: 0.132245, Val Acc: 0.773196\n",
      "Epoch 12343 - Train Loss: 0.113289, Train Acc: 0.817949 | Val Loss: 0.132241, Val Acc: 0.773196\n",
      "Epoch 12344 - Train Loss: 0.113283, Train Acc: 0.817949 | Val Loss: 0.132236, Val Acc: 0.773196\n",
      "Epoch 12345 - Train Loss: 0.113278, Train Acc: 0.817949 | Val Loss: 0.132232, Val Acc: 0.773196\n",
      "Epoch 12346 - Train Loss: 0.113272, Train Acc: 0.817949 | Val Loss: 0.132228, Val Acc: 0.773196\n",
      "Epoch 12347 - Train Loss: 0.113266, Train Acc: 0.817949 | Val Loss: 0.132223, Val Acc: 0.773196\n",
      "Epoch 12348 - Train Loss: 0.113261, Train Acc: 0.817949 | Val Loss: 0.132219, Val Acc: 0.773196\n",
      "Epoch 12349 - Train Loss: 0.113255, Train Acc: 0.817949 | Val Loss: 0.132214, Val Acc: 0.773196\n",
      "Epoch 12350 - Train Loss: 0.113249, Train Acc: 0.817949 | Val Loss: 0.132210, Val Acc: 0.773196\n",
      "Epoch 12351 - Train Loss: 0.113244, Train Acc: 0.817949 | Val Loss: 0.132205, Val Acc: 0.773196\n",
      "Epoch 12352 - Train Loss: 0.113238, Train Acc: 0.817949 | Val Loss: 0.132201, Val Acc: 0.773196\n",
      "Epoch 12353 - Train Loss: 0.113233, Train Acc: 0.817949 | Val Loss: 0.132197, Val Acc: 0.773196\n",
      "Epoch 12354 - Train Loss: 0.113227, Train Acc: 0.817949 | Val Loss: 0.132192, Val Acc: 0.773196\n",
      "Epoch 12355 - Train Loss: 0.113221, Train Acc: 0.817949 | Val Loss: 0.132188, Val Acc: 0.773196\n",
      "Epoch 12356 - Train Loss: 0.113216, Train Acc: 0.817949 | Val Loss: 0.132183, Val Acc: 0.773196\n",
      "Epoch 12357 - Train Loss: 0.113210, Train Acc: 0.817949 | Val Loss: 0.132179, Val Acc: 0.773196\n",
      "Epoch 12358 - Train Loss: 0.113204, Train Acc: 0.817949 | Val Loss: 0.132175, Val Acc: 0.773196\n",
      "Epoch 12359 - Train Loss: 0.113199, Train Acc: 0.817949 | Val Loss: 0.132170, Val Acc: 0.773196\n",
      "Epoch 12360 - Train Loss: 0.113193, Train Acc: 0.817949 | Val Loss: 0.132166, Val Acc: 0.773196\n",
      "Epoch 12361 - Train Loss: 0.113188, Train Acc: 0.817949 | Val Loss: 0.132161, Val Acc: 0.773196\n",
      "Epoch 12362 - Train Loss: 0.113182, Train Acc: 0.817949 | Val Loss: 0.132157, Val Acc: 0.773196\n",
      "Epoch 12363 - Train Loss: 0.113176, Train Acc: 0.817949 | Val Loss: 0.132153, Val Acc: 0.773196\n",
      "Epoch 12364 - Train Loss: 0.113171, Train Acc: 0.817949 | Val Loss: 0.132148, Val Acc: 0.773196\n",
      "Epoch 12365 - Train Loss: 0.113165, Train Acc: 0.817949 | Val Loss: 0.132144, Val Acc: 0.773196\n",
      "Epoch 12366 - Train Loss: 0.113159, Train Acc: 0.817949 | Val Loss: 0.132139, Val Acc: 0.773196\n",
      "Epoch 12367 - Train Loss: 0.113154, Train Acc: 0.817949 | Val Loss: 0.132135, Val Acc: 0.773196\n",
      "Epoch 12368 - Train Loss: 0.113148, Train Acc: 0.817949 | Val Loss: 0.132131, Val Acc: 0.773196\n",
      "Epoch 12369 - Train Loss: 0.113143, Train Acc: 0.817949 | Val Loss: 0.132126, Val Acc: 0.773196\n",
      "Epoch 12370 - Train Loss: 0.113137, Train Acc: 0.817949 | Val Loss: 0.132122, Val Acc: 0.773196\n",
      "Epoch 12371 - Train Loss: 0.113131, Train Acc: 0.817949 | Val Loss: 0.132117, Val Acc: 0.773196\n",
      "Epoch 12372 - Train Loss: 0.113126, Train Acc: 0.817949 | Val Loss: 0.132113, Val Acc: 0.773196\n",
      "Epoch 12373 - Train Loss: 0.113120, Train Acc: 0.817949 | Val Loss: 0.132109, Val Acc: 0.773196\n",
      "Epoch 12374 - Train Loss: 0.113115, Train Acc: 0.817949 | Val Loss: 0.132104, Val Acc: 0.773196\n",
      "Epoch 12375 - Train Loss: 0.113109, Train Acc: 0.817949 | Val Loss: 0.132100, Val Acc: 0.773196\n",
      "Epoch 12376 - Train Loss: 0.113103, Train Acc: 0.817949 | Val Loss: 0.132095, Val Acc: 0.773196\n",
      "Epoch 12377 - Train Loss: 0.113098, Train Acc: 0.817949 | Val Loss: 0.132091, Val Acc: 0.773196\n",
      "Epoch 12378 - Train Loss: 0.113092, Train Acc: 0.817949 | Val Loss: 0.132087, Val Acc: 0.773196\n",
      "Epoch 12379 - Train Loss: 0.113087, Train Acc: 0.817949 | Val Loss: 0.132082, Val Acc: 0.773196\n",
      "Epoch 12380 - Train Loss: 0.113081, Train Acc: 0.817949 | Val Loss: 0.132078, Val Acc: 0.773196\n",
      "Epoch 12381 - Train Loss: 0.113075, Train Acc: 0.817949 | Val Loss: 0.132074, Val Acc: 0.773196\n",
      "Epoch 12382 - Train Loss: 0.113070, Train Acc: 0.817949 | Val Loss: 0.132069, Val Acc: 0.773196\n",
      "Epoch 12383 - Train Loss: 0.113064, Train Acc: 0.817949 | Val Loss: 0.132065, Val Acc: 0.773196\n",
      "Epoch 12384 - Train Loss: 0.113059, Train Acc: 0.817949 | Val Loss: 0.132060, Val Acc: 0.773196\n",
      "Epoch 12385 - Train Loss: 0.113053, Train Acc: 0.817949 | Val Loss: 0.132056, Val Acc: 0.773196\n",
      "Epoch 12386 - Train Loss: 0.113047, Train Acc: 0.817949 | Val Loss: 0.132052, Val Acc: 0.773196\n",
      "Epoch 12387 - Train Loss: 0.113042, Train Acc: 0.817949 | Val Loss: 0.132047, Val Acc: 0.773196\n",
      "Epoch 12388 - Train Loss: 0.113036, Train Acc: 0.817949 | Val Loss: 0.132043, Val Acc: 0.773196\n",
      "Epoch 12389 - Train Loss: 0.113031, Train Acc: 0.817949 | Val Loss: 0.132038, Val Acc: 0.773196\n",
      "Epoch 12390 - Train Loss: 0.113025, Train Acc: 0.817949 | Val Loss: 0.132034, Val Acc: 0.773196\n",
      "Epoch 12391 - Train Loss: 0.113019, Train Acc: 0.817949 | Val Loss: 0.132030, Val Acc: 0.773196\n",
      "Epoch 12392 - Train Loss: 0.113014, Train Acc: 0.817949 | Val Loss: 0.132025, Val Acc: 0.773196\n",
      "Epoch 12393 - Train Loss: 0.113008, Train Acc: 0.817949 | Val Loss: 0.132021, Val Acc: 0.773196\n",
      "Epoch 12394 - Train Loss: 0.113003, Train Acc: 0.817949 | Val Loss: 0.132017, Val Acc: 0.773196\n",
      "Epoch 12395 - Train Loss: 0.112997, Train Acc: 0.817949 | Val Loss: 0.132012, Val Acc: 0.773196\n",
      "Epoch 12396 - Train Loss: 0.112991, Train Acc: 0.817949 | Val Loss: 0.132008, Val Acc: 0.773196\n",
      "Epoch 12397 - Train Loss: 0.112986, Train Acc: 0.817949 | Val Loss: 0.132003, Val Acc: 0.773196\n",
      "Epoch 12398 - Train Loss: 0.112980, Train Acc: 0.817949 | Val Loss: 0.131999, Val Acc: 0.773196\n",
      "Epoch 12399 - Train Loss: 0.112975, Train Acc: 0.817949 | Val Loss: 0.131995, Val Acc: 0.773196\n",
      "Epoch 12400 - Train Loss: 0.112969, Train Acc: 0.817949 | Val Loss: 0.131990, Val Acc: 0.773196\n",
      "Epoch 12401 - Train Loss: 0.112963, Train Acc: 0.817949 | Val Loss: 0.131986, Val Acc: 0.773196\n",
      "Epoch 12402 - Train Loss: 0.112958, Train Acc: 0.817949 | Val Loss: 0.131982, Val Acc: 0.773196\n",
      "Epoch 12403 - Train Loss: 0.112952, Train Acc: 0.817949 | Val Loss: 0.131978, Val Acc: 0.773196\n",
      "Epoch 12404 - Train Loss: 0.112947, Train Acc: 0.817949 | Val Loss: 0.131974, Val Acc: 0.773196\n",
      "Epoch 12405 - Train Loss: 0.112941, Train Acc: 0.817949 | Val Loss: 0.131970, Val Acc: 0.773196\n",
      "Epoch 12406 - Train Loss: 0.112936, Train Acc: 0.817949 | Val Loss: 0.131966, Val Acc: 0.773196\n",
      "Epoch 12407 - Train Loss: 0.112930, Train Acc: 0.817949 | Val Loss: 0.131961, Val Acc: 0.773196\n",
      "Epoch 12408 - Train Loss: 0.112924, Train Acc: 0.817949 | Val Loss: 0.131957, Val Acc: 0.773196\n",
      "Epoch 12409 - Train Loss: 0.112919, Train Acc: 0.817949 | Val Loss: 0.131953, Val Acc: 0.773196\n",
      "Epoch 12410 - Train Loss: 0.112913, Train Acc: 0.817949 | Val Loss: 0.131949, Val Acc: 0.773196\n",
      "Epoch 12411 - Train Loss: 0.112908, Train Acc: 0.817949 | Val Loss: 0.131945, Val Acc: 0.773196\n",
      "Epoch 12412 - Train Loss: 0.112902, Train Acc: 0.817949 | Val Loss: 0.131940, Val Acc: 0.773196\n",
      "Epoch 12413 - Train Loss: 0.112897, Train Acc: 0.817949 | Val Loss: 0.131936, Val Acc: 0.773196\n",
      "Epoch 12414 - Train Loss: 0.112891, Train Acc: 0.817949 | Val Loss: 0.131932, Val Acc: 0.773196\n",
      "Epoch 12415 - Train Loss: 0.112885, Train Acc: 0.817949 | Val Loss: 0.131928, Val Acc: 0.773196\n",
      "Epoch 12416 - Train Loss: 0.112880, Train Acc: 0.817949 | Val Loss: 0.131924, Val Acc: 0.773196\n",
      "Epoch 12417 - Train Loss: 0.112874, Train Acc: 0.817949 | Val Loss: 0.131920, Val Acc: 0.773196\n",
      "Epoch 12418 - Train Loss: 0.112869, Train Acc: 0.817949 | Val Loss: 0.131916, Val Acc: 0.773196\n",
      "Epoch 12419 - Train Loss: 0.112863, Train Acc: 0.817949 | Val Loss: 0.131912, Val Acc: 0.773196\n",
      "Epoch 12420 - Train Loss: 0.112858, Train Acc: 0.817949 | Val Loss: 0.131907, Val Acc: 0.773196\n",
      "Epoch 12421 - Train Loss: 0.112852, Train Acc: 0.817949 | Val Loss: 0.131903, Val Acc: 0.773196\n",
      "Epoch 12422 - Train Loss: 0.112846, Train Acc: 0.817949 | Val Loss: 0.131899, Val Acc: 0.773196\n",
      "Epoch 12423 - Train Loss: 0.112841, Train Acc: 0.817949 | Val Loss: 0.131895, Val Acc: 0.773196\n",
      "Epoch 12424 - Train Loss: 0.112835, Train Acc: 0.817949 | Val Loss: 0.131890, Val Acc: 0.773196\n",
      "Epoch 12425 - Train Loss: 0.112830, Train Acc: 0.817949 | Val Loss: 0.131886, Val Acc: 0.773196\n",
      "Epoch 12426 - Train Loss: 0.112824, Train Acc: 0.817949 | Val Loss: 0.131882, Val Acc: 0.773196\n",
      "Epoch 12427 - Train Loss: 0.112819, Train Acc: 0.817949 | Val Loss: 0.131878, Val Acc: 0.773196\n",
      "Epoch 12428 - Train Loss: 0.112813, Train Acc: 0.817949 | Val Loss: 0.131874, Val Acc: 0.773196\n",
      "Epoch 12429 - Train Loss: 0.112808, Train Acc: 0.817949 | Val Loss: 0.131869, Val Acc: 0.773196\n",
      "Epoch 12430 - Train Loss: 0.112802, Train Acc: 0.817949 | Val Loss: 0.131865, Val Acc: 0.773196\n",
      "Epoch 12431 - Train Loss: 0.112796, Train Acc: 0.817949 | Val Loss: 0.131861, Val Acc: 0.773196\n",
      "Epoch 12432 - Train Loss: 0.112791, Train Acc: 0.817949 | Val Loss: 0.131857, Val Acc: 0.773196\n",
      "Epoch 12433 - Train Loss: 0.112785, Train Acc: 0.817949 | Val Loss: 0.131853, Val Acc: 0.773196\n",
      "Epoch 12434 - Train Loss: 0.112780, Train Acc: 0.817949 | Val Loss: 0.131849, Val Acc: 0.773196\n",
      "Epoch 12435 - Train Loss: 0.112774, Train Acc: 0.817949 | Val Loss: 0.131844, Val Acc: 0.773196\n",
      "Epoch 12436 - Train Loss: 0.112769, Train Acc: 0.817949 | Val Loss: 0.131840, Val Acc: 0.773196\n",
      "Epoch 12437 - Train Loss: 0.112763, Train Acc: 0.817949 | Val Loss: 0.131836, Val Acc: 0.773196\n",
      "Epoch 12438 - Train Loss: 0.112758, Train Acc: 0.817949 | Val Loss: 0.131832, Val Acc: 0.773196\n",
      "Epoch 12439 - Train Loss: 0.112752, Train Acc: 0.817949 | Val Loss: 0.131828, Val Acc: 0.773196\n",
      "Epoch 12440 - Train Loss: 0.112747, Train Acc: 0.817949 | Val Loss: 0.131823, Val Acc: 0.773196\n",
      "Epoch 12441 - Train Loss: 0.112741, Train Acc: 0.817949 | Val Loss: 0.131819, Val Acc: 0.773196\n",
      "Epoch 12442 - Train Loss: 0.112735, Train Acc: 0.817949 | Val Loss: 0.131815, Val Acc: 0.773196\n",
      "Epoch 12443 - Train Loss: 0.112730, Train Acc: 0.817949 | Val Loss: 0.131811, Val Acc: 0.773196\n",
      "Epoch 12444 - Train Loss: 0.112724, Train Acc: 0.817949 | Val Loss: 0.131806, Val Acc: 0.773196\n",
      "Epoch 12445 - Train Loss: 0.112719, Train Acc: 0.817949 | Val Loss: 0.131802, Val Acc: 0.773196\n",
      "Epoch 12446 - Train Loss: 0.112713, Train Acc: 0.817949 | Val Loss: 0.131798, Val Acc: 0.773196\n",
      "Epoch 12447 - Train Loss: 0.112708, Train Acc: 0.817949 | Val Loss: 0.131794, Val Acc: 0.773196\n",
      "Epoch 12448 - Train Loss: 0.112702, Train Acc: 0.817949 | Val Loss: 0.131790, Val Acc: 0.773196\n",
      "Epoch 12449 - Train Loss: 0.112697, Train Acc: 0.817949 | Val Loss: 0.131785, Val Acc: 0.773196\n",
      "Epoch 12450 - Train Loss: 0.112691, Train Acc: 0.817949 | Val Loss: 0.131781, Val Acc: 0.773196\n",
      "Epoch 12451 - Train Loss: 0.112686, Train Acc: 0.817949 | Val Loss: 0.131777, Val Acc: 0.773196\n",
      "Epoch 12452 - Train Loss: 0.112680, Train Acc: 0.817949 | Val Loss: 0.131773, Val Acc: 0.773196\n",
      "Epoch 12453 - Train Loss: 0.112674, Train Acc: 0.817949 | Val Loss: 0.131769, Val Acc: 0.773196\n",
      "Epoch 12454 - Train Loss: 0.112669, Train Acc: 0.817949 | Val Loss: 0.131764, Val Acc: 0.773196\n",
      "Epoch 12455 - Train Loss: 0.112663, Train Acc: 0.817949 | Val Loss: 0.131760, Val Acc: 0.773196\n",
      "Epoch 12456 - Train Loss: 0.112658, Train Acc: 0.817949 | Val Loss: 0.131756, Val Acc: 0.773196\n",
      "Epoch 12457 - Train Loss: 0.112652, Train Acc: 0.817949 | Val Loss: 0.131752, Val Acc: 0.773196\n",
      "Epoch 12458 - Train Loss: 0.112647, Train Acc: 0.817949 | Val Loss: 0.131747, Val Acc: 0.773196\n",
      "Epoch 12459 - Train Loss: 0.112641, Train Acc: 0.817949 | Val Loss: 0.131743, Val Acc: 0.773196\n",
      "Epoch 12460 - Train Loss: 0.112636, Train Acc: 0.817949 | Val Loss: 0.131739, Val Acc: 0.773196\n",
      "Epoch 12461 - Train Loss: 0.112630, Train Acc: 0.817949 | Val Loss: 0.131735, Val Acc: 0.773196\n",
      "Epoch 12462 - Train Loss: 0.112625, Train Acc: 0.817949 | Val Loss: 0.131731, Val Acc: 0.773196\n",
      "Epoch 12463 - Train Loss: 0.112619, Train Acc: 0.817949 | Val Loss: 0.131726, Val Acc: 0.773196\n",
      "Epoch 12464 - Train Loss: 0.112614, Train Acc: 0.817949 | Val Loss: 0.131722, Val Acc: 0.773196\n",
      "Epoch 12465 - Train Loss: 0.112608, Train Acc: 0.817949 | Val Loss: 0.131718, Val Acc: 0.773196\n",
      "Epoch 12466 - Train Loss: 0.112603, Train Acc: 0.817949 | Val Loss: 0.131714, Val Acc: 0.773196\n",
      "Epoch 12467 - Train Loss: 0.112597, Train Acc: 0.817949 | Val Loss: 0.131709, Val Acc: 0.773196\n",
      "Epoch 12468 - Train Loss: 0.112592, Train Acc: 0.817949 | Val Loss: 0.131705, Val Acc: 0.773196\n",
      "Epoch 12469 - Train Loss: 0.112586, Train Acc: 0.817949 | Val Loss: 0.131701, Val Acc: 0.773196\n",
      "Epoch 12470 - Train Loss: 0.112581, Train Acc: 0.817949 | Val Loss: 0.131697, Val Acc: 0.773196\n",
      "Epoch 12471 - Train Loss: 0.112575, Train Acc: 0.817949 | Val Loss: 0.131693, Val Acc: 0.773196\n",
      "Epoch 12472 - Train Loss: 0.112570, Train Acc: 0.817949 | Val Loss: 0.131688, Val Acc: 0.773196\n",
      "Epoch 12473 - Train Loss: 0.112564, Train Acc: 0.817949 | Val Loss: 0.131684, Val Acc: 0.773196\n",
      "Epoch 12474 - Train Loss: 0.112558, Train Acc: 0.817949 | Val Loss: 0.131680, Val Acc: 0.773196\n",
      "Epoch 12475 - Train Loss: 0.112553, Train Acc: 0.817949 | Val Loss: 0.131676, Val Acc: 0.773196\n",
      "Epoch 12476 - Train Loss: 0.112547, Train Acc: 0.817949 | Val Loss: 0.131672, Val Acc: 0.773196\n",
      "Epoch 12477 - Train Loss: 0.112542, Train Acc: 0.817949 | Val Loss: 0.131667, Val Acc: 0.773196\n",
      "Epoch 12478 - Train Loss: 0.112536, Train Acc: 0.817949 | Val Loss: 0.131663, Val Acc: 0.773196\n",
      "Epoch 12479 - Train Loss: 0.112531, Train Acc: 0.817949 | Val Loss: 0.131659, Val Acc: 0.773196\n",
      "Epoch 12480 - Train Loss: 0.112525, Train Acc: 0.819231 | Val Loss: 0.131655, Val Acc: 0.773196\n",
      "Epoch 12481 - Train Loss: 0.112520, Train Acc: 0.819231 | Val Loss: 0.131650, Val Acc: 0.773196\n",
      "Epoch 12482 - Train Loss: 0.112514, Train Acc: 0.819231 | Val Loss: 0.131646, Val Acc: 0.773196\n",
      "Epoch 12483 - Train Loss: 0.112509, Train Acc: 0.819231 | Val Loss: 0.131642, Val Acc: 0.773196\n",
      "Epoch 12484 - Train Loss: 0.112503, Train Acc: 0.819231 | Val Loss: 0.131638, Val Acc: 0.773196\n",
      "Epoch 12485 - Train Loss: 0.112498, Train Acc: 0.819231 | Val Loss: 0.131634, Val Acc: 0.773196\n",
      "Epoch 12486 - Train Loss: 0.112492, Train Acc: 0.819231 | Val Loss: 0.131629, Val Acc: 0.773196\n",
      "Epoch 12487 - Train Loss: 0.112487, Train Acc: 0.819231 | Val Loss: 0.131625, Val Acc: 0.773196\n",
      "Epoch 12488 - Train Loss: 0.112481, Train Acc: 0.819231 | Val Loss: 0.131621, Val Acc: 0.773196\n",
      "Epoch 12489 - Train Loss: 0.112476, Train Acc: 0.819231 | Val Loss: 0.131617, Val Acc: 0.773196\n",
      "Epoch 12490 - Train Loss: 0.112470, Train Acc: 0.819231 | Val Loss: 0.131612, Val Acc: 0.773196\n",
      "Epoch 12491 - Train Loss: 0.112465, Train Acc: 0.819231 | Val Loss: 0.131608, Val Acc: 0.773196\n",
      "Epoch 12492 - Train Loss: 0.112459, Train Acc: 0.819231 | Val Loss: 0.131604, Val Acc: 0.773196\n",
      "Epoch 12493 - Train Loss: 0.112454, Train Acc: 0.819231 | Val Loss: 0.131600, Val Acc: 0.773196\n",
      "Epoch 12494 - Train Loss: 0.112448, Train Acc: 0.819231 | Val Loss: 0.131596, Val Acc: 0.773196\n",
      "Epoch 12495 - Train Loss: 0.112443, Train Acc: 0.819231 | Val Loss: 0.131591, Val Acc: 0.773196\n",
      "Epoch 12496 - Train Loss: 0.112437, Train Acc: 0.819231 | Val Loss: 0.131587, Val Acc: 0.773196\n",
      "Epoch 12497 - Train Loss: 0.112432, Train Acc: 0.819231 | Val Loss: 0.131583, Val Acc: 0.773196\n",
      "Epoch 12498 - Train Loss: 0.112426, Train Acc: 0.819231 | Val Loss: 0.131579, Val Acc: 0.773196\n",
      "Epoch 12499 - Train Loss: 0.112421, Train Acc: 0.819231 | Val Loss: 0.131575, Val Acc: 0.773196\n",
      "Epoch 12500 - Train Loss: 0.112415, Train Acc: 0.819231 | Val Loss: 0.131570, Val Acc: 0.773196\n",
      "Epoch 12501 - Train Loss: 0.112410, Train Acc: 0.819231 | Val Loss: 0.131566, Val Acc: 0.773196\n",
      "Epoch 12502 - Train Loss: 0.112404, Train Acc: 0.819231 | Val Loss: 0.131562, Val Acc: 0.773196\n",
      "Epoch 12503 - Train Loss: 0.112399, Train Acc: 0.819231 | Val Loss: 0.131558, Val Acc: 0.773196\n",
      "Epoch 12504 - Train Loss: 0.112393, Train Acc: 0.819231 | Val Loss: 0.131554, Val Acc: 0.773196\n",
      "Epoch 12505 - Train Loss: 0.112388, Train Acc: 0.819231 | Val Loss: 0.131549, Val Acc: 0.773196\n",
      "Epoch 12506 - Train Loss: 0.112382, Train Acc: 0.819231 | Val Loss: 0.131545, Val Acc: 0.773196\n",
      "Epoch 12507 - Train Loss: 0.112377, Train Acc: 0.819231 | Val Loss: 0.131541, Val Acc: 0.773196\n",
      "Epoch 12508 - Train Loss: 0.112371, Train Acc: 0.819231 | Val Loss: 0.131537, Val Acc: 0.773196\n",
      "Epoch 12509 - Train Loss: 0.112366, Train Acc: 0.819231 | Val Loss: 0.131533, Val Acc: 0.773196\n",
      "Epoch 12510 - Train Loss: 0.112361, Train Acc: 0.819231 | Val Loss: 0.131528, Val Acc: 0.773196\n",
      "Epoch 12511 - Train Loss: 0.112355, Train Acc: 0.819231 | Val Loss: 0.131524, Val Acc: 0.773196\n",
      "Epoch 12512 - Train Loss: 0.112350, Train Acc: 0.819231 | Val Loss: 0.131520, Val Acc: 0.773196\n",
      "Epoch 12513 - Train Loss: 0.112344, Train Acc: 0.819231 | Val Loss: 0.131516, Val Acc: 0.773196\n",
      "Epoch 12514 - Train Loss: 0.112339, Train Acc: 0.819231 | Val Loss: 0.131512, Val Acc: 0.773196\n",
      "Epoch 12515 - Train Loss: 0.112333, Train Acc: 0.819231 | Val Loss: 0.131507, Val Acc: 0.773196\n",
      "Epoch 12516 - Train Loss: 0.112328, Train Acc: 0.819231 | Val Loss: 0.131503, Val Acc: 0.773196\n",
      "Epoch 12517 - Train Loss: 0.112322, Train Acc: 0.819231 | Val Loss: 0.131499, Val Acc: 0.773196\n",
      "Epoch 12518 - Train Loss: 0.112317, Train Acc: 0.819231 | Val Loss: 0.131495, Val Acc: 0.773196\n",
      "Epoch 12519 - Train Loss: 0.112311, Train Acc: 0.819231 | Val Loss: 0.131491, Val Acc: 0.773196\n",
      "Epoch 12520 - Train Loss: 0.112306, Train Acc: 0.819231 | Val Loss: 0.131486, Val Acc: 0.773196\n",
      "Epoch 12521 - Train Loss: 0.112300, Train Acc: 0.819231 | Val Loss: 0.131482, Val Acc: 0.773196\n",
      "Epoch 12522 - Train Loss: 0.112295, Train Acc: 0.819231 | Val Loss: 0.131478, Val Acc: 0.773196\n",
      "Epoch 12523 - Train Loss: 0.112289, Train Acc: 0.819231 | Val Loss: 0.131474, Val Acc: 0.773196\n",
      "Epoch 12524 - Train Loss: 0.112284, Train Acc: 0.819231 | Val Loss: 0.131470, Val Acc: 0.773196\n",
      "Epoch 12525 - Train Loss: 0.112278, Train Acc: 0.819231 | Val Loss: 0.131465, Val Acc: 0.773196\n",
      "Epoch 12526 - Train Loss: 0.112273, Train Acc: 0.819231 | Val Loss: 0.131461, Val Acc: 0.773196\n",
      "Epoch 12527 - Train Loss: 0.112267, Train Acc: 0.819231 | Val Loss: 0.131457, Val Acc: 0.773196\n",
      "Epoch 12528 - Train Loss: 0.112262, Train Acc: 0.819231 | Val Loss: 0.131453, Val Acc: 0.773196\n",
      "Epoch 12529 - Train Loss: 0.112257, Train Acc: 0.819231 | Val Loss: 0.131449, Val Acc: 0.773196\n",
      "Epoch 12530 - Train Loss: 0.112251, Train Acc: 0.819231 | Val Loss: 0.131444, Val Acc: 0.773196\n",
      "Epoch 12531 - Train Loss: 0.112246, Train Acc: 0.819231 | Val Loss: 0.131440, Val Acc: 0.773196\n",
      "Epoch 12532 - Train Loss: 0.112240, Train Acc: 0.819231 | Val Loss: 0.131436, Val Acc: 0.773196\n",
      "Epoch 12533 - Train Loss: 0.112235, Train Acc: 0.819231 | Val Loss: 0.131432, Val Acc: 0.773196\n",
      "Epoch 12534 - Train Loss: 0.112229, Train Acc: 0.819231 | Val Loss: 0.131428, Val Acc: 0.773196\n",
      "Epoch 12535 - Train Loss: 0.112224, Train Acc: 0.819231 | Val Loss: 0.131423, Val Acc: 0.773196\n",
      "Epoch 12536 - Train Loss: 0.112218, Train Acc: 0.819231 | Val Loss: 0.131419, Val Acc: 0.773196\n",
      "Epoch 12537 - Train Loss: 0.112213, Train Acc: 0.819231 | Val Loss: 0.131415, Val Acc: 0.773196\n",
      "Epoch 12538 - Train Loss: 0.112207, Train Acc: 0.819231 | Val Loss: 0.131411, Val Acc: 0.773196\n",
      "Epoch 12539 - Train Loss: 0.112202, Train Acc: 0.819231 | Val Loss: 0.131407, Val Acc: 0.773196\n",
      "Epoch 12540 - Train Loss: 0.112196, Train Acc: 0.819231 | Val Loss: 0.131403, Val Acc: 0.773196\n",
      "Epoch 12541 - Train Loss: 0.112191, Train Acc: 0.819231 | Val Loss: 0.131398, Val Acc: 0.773196\n",
      "Epoch 12542 - Train Loss: 0.112186, Train Acc: 0.819231 | Val Loss: 0.131394, Val Acc: 0.773196\n",
      "Epoch 12543 - Train Loss: 0.112180, Train Acc: 0.819231 | Val Loss: 0.131390, Val Acc: 0.773196\n",
      "Epoch 12544 - Train Loss: 0.112175, Train Acc: 0.819231 | Val Loss: 0.131386, Val Acc: 0.773196\n",
      "Epoch 12545 - Train Loss: 0.112169, Train Acc: 0.819231 | Val Loss: 0.131382, Val Acc: 0.773196\n",
      "Epoch 12546 - Train Loss: 0.112164, Train Acc: 0.819231 | Val Loss: 0.131377, Val Acc: 0.773196\n",
      "Epoch 12547 - Train Loss: 0.112158, Train Acc: 0.819231 | Val Loss: 0.131373, Val Acc: 0.773196\n",
      "Epoch 12548 - Train Loss: 0.112153, Train Acc: 0.819231 | Val Loss: 0.131369, Val Acc: 0.773196\n",
      "Epoch 12549 - Train Loss: 0.112147, Train Acc: 0.819231 | Val Loss: 0.131365, Val Acc: 0.773196\n",
      "Epoch 12550 - Train Loss: 0.112142, Train Acc: 0.819231 | Val Loss: 0.131361, Val Acc: 0.773196\n",
      "Epoch 12551 - Train Loss: 0.112136, Train Acc: 0.819231 | Val Loss: 0.131357, Val Acc: 0.773196\n",
      "Epoch 12552 - Train Loss: 0.112131, Train Acc: 0.819231 | Val Loss: 0.131352, Val Acc: 0.773196\n",
      "Epoch 12553 - Train Loss: 0.112126, Train Acc: 0.819231 | Val Loss: 0.131348, Val Acc: 0.773196\n",
      "Epoch 12554 - Train Loss: 0.112120, Train Acc: 0.819231 | Val Loss: 0.131344, Val Acc: 0.773196\n",
      "Epoch 12555 - Train Loss: 0.112115, Train Acc: 0.819231 | Val Loss: 0.131340, Val Acc: 0.773196\n",
      "Epoch 12556 - Train Loss: 0.112109, Train Acc: 0.819231 | Val Loss: 0.131336, Val Acc: 0.773196\n",
      "Epoch 12557 - Train Loss: 0.112104, Train Acc: 0.819231 | Val Loss: 0.131332, Val Acc: 0.773196\n",
      "Epoch 12558 - Train Loss: 0.112098, Train Acc: 0.819231 | Val Loss: 0.131327, Val Acc: 0.773196\n",
      "Epoch 12559 - Train Loss: 0.112093, Train Acc: 0.819231 | Val Loss: 0.131323, Val Acc: 0.773196\n",
      "Epoch 12560 - Train Loss: 0.112088, Train Acc: 0.819231 | Val Loss: 0.131319, Val Acc: 0.773196\n",
      "Epoch 12561 - Train Loss: 0.112082, Train Acc: 0.819231 | Val Loss: 0.131315, Val Acc: 0.773196\n",
      "Epoch 12562 - Train Loss: 0.112077, Train Acc: 0.819231 | Val Loss: 0.131311, Val Acc: 0.773196\n",
      "Epoch 12563 - Train Loss: 0.112071, Train Acc: 0.819231 | Val Loss: 0.131307, Val Acc: 0.773196\n",
      "Epoch 12564 - Train Loss: 0.112066, Train Acc: 0.819231 | Val Loss: 0.131302, Val Acc: 0.773196\n",
      "Epoch 12565 - Train Loss: 0.112060, Train Acc: 0.819231 | Val Loss: 0.131298, Val Acc: 0.773196\n",
      "Epoch 12566 - Train Loss: 0.112055, Train Acc: 0.819231 | Val Loss: 0.131294, Val Acc: 0.773196\n",
      "Epoch 12567 - Train Loss: 0.112049, Train Acc: 0.819231 | Val Loss: 0.131290, Val Acc: 0.773196\n",
      "Epoch 12568 - Train Loss: 0.112044, Train Acc: 0.819231 | Val Loss: 0.131286, Val Acc: 0.773196\n",
      "Epoch 12569 - Train Loss: 0.112039, Train Acc: 0.819231 | Val Loss: 0.131282, Val Acc: 0.773196\n",
      "Epoch 12570 - Train Loss: 0.112033, Train Acc: 0.819231 | Val Loss: 0.131277, Val Acc: 0.773196\n",
      "Epoch 12571 - Train Loss: 0.112028, Train Acc: 0.819231 | Val Loss: 0.131273, Val Acc: 0.773196\n",
      "Epoch 12572 - Train Loss: 0.112022, Train Acc: 0.819231 | Val Loss: 0.131269, Val Acc: 0.773196\n",
      "Epoch 12573 - Train Loss: 0.112017, Train Acc: 0.819231 | Val Loss: 0.131265, Val Acc: 0.773196\n",
      "Epoch 12574 - Train Loss: 0.112011, Train Acc: 0.819231 | Val Loss: 0.131261, Val Acc: 0.773196\n",
      "Epoch 12575 - Train Loss: 0.112006, Train Acc: 0.819231 | Val Loss: 0.131257, Val Acc: 0.773196\n",
      "Epoch 12576 - Train Loss: 0.112001, Train Acc: 0.819231 | Val Loss: 0.131253, Val Acc: 0.773196\n",
      "Epoch 12577 - Train Loss: 0.111995, Train Acc: 0.819231 | Val Loss: 0.131248, Val Acc: 0.773196\n",
      "Epoch 12578 - Train Loss: 0.111990, Train Acc: 0.819231 | Val Loss: 0.131244, Val Acc: 0.773196\n",
      "Epoch 12579 - Train Loss: 0.111984, Train Acc: 0.819231 | Val Loss: 0.131240, Val Acc: 0.773196\n",
      "Epoch 12580 - Train Loss: 0.111979, Train Acc: 0.819231 | Val Loss: 0.131236, Val Acc: 0.773196\n",
      "Epoch 12581 - Train Loss: 0.111974, Train Acc: 0.819231 | Val Loss: 0.131232, Val Acc: 0.773196\n",
      "Epoch 12582 - Train Loss: 0.111968, Train Acc: 0.819231 | Val Loss: 0.131228, Val Acc: 0.773196\n",
      "Epoch 12583 - Train Loss: 0.111963, Train Acc: 0.819231 | Val Loss: 0.131223, Val Acc: 0.773196\n",
      "Epoch 12584 - Train Loss: 0.111957, Train Acc: 0.819231 | Val Loss: 0.131219, Val Acc: 0.773196\n",
      "Epoch 12585 - Train Loss: 0.111952, Train Acc: 0.819231 | Val Loss: 0.131215, Val Acc: 0.773196\n",
      "Epoch 12586 - Train Loss: 0.111946, Train Acc: 0.819231 | Val Loss: 0.131211, Val Acc: 0.773196\n",
      "Epoch 12587 - Train Loss: 0.111941, Train Acc: 0.819231 | Val Loss: 0.131207, Val Acc: 0.773196\n",
      "Epoch 12588 - Train Loss: 0.111936, Train Acc: 0.819231 | Val Loss: 0.131203, Val Acc: 0.773196\n",
      "Epoch 12589 - Train Loss: 0.111930, Train Acc: 0.819231 | Val Loss: 0.131199, Val Acc: 0.773196\n",
      "Epoch 12590 - Train Loss: 0.111925, Train Acc: 0.819231 | Val Loss: 0.131194, Val Acc: 0.773196\n",
      "Epoch 12591 - Train Loss: 0.111919, Train Acc: 0.819231 | Val Loss: 0.131190, Val Acc: 0.773196\n",
      "Epoch 12592 - Train Loss: 0.111914, Train Acc: 0.819231 | Val Loss: 0.131186, Val Acc: 0.773196\n",
      "Epoch 12593 - Train Loss: 0.111909, Train Acc: 0.819231 | Val Loss: 0.131182, Val Acc: 0.773196\n",
      "Epoch 12594 - Train Loss: 0.111903, Train Acc: 0.819231 | Val Loss: 0.131178, Val Acc: 0.773196\n",
      "Epoch 12595 - Train Loss: 0.111898, Train Acc: 0.819231 | Val Loss: 0.131174, Val Acc: 0.773196\n",
      "Epoch 12596 - Train Loss: 0.111892, Train Acc: 0.819231 | Val Loss: 0.131170, Val Acc: 0.773196\n",
      "Epoch 12597 - Train Loss: 0.111887, Train Acc: 0.819231 | Val Loss: 0.131166, Val Acc: 0.773196\n",
      "Epoch 12598 - Train Loss: 0.111882, Train Acc: 0.819231 | Val Loss: 0.131161, Val Acc: 0.773196\n",
      "Epoch 12599 - Train Loss: 0.111876, Train Acc: 0.819231 | Val Loss: 0.131157, Val Acc: 0.773196\n",
      "Epoch 12600 - Train Loss: 0.111871, Train Acc: 0.819231 | Val Loss: 0.131153, Val Acc: 0.773196\n",
      "Epoch 12601 - Train Loss: 0.111865, Train Acc: 0.819231 | Val Loss: 0.131149, Val Acc: 0.773196\n",
      "Epoch 12602 - Train Loss: 0.111860, Train Acc: 0.819231 | Val Loss: 0.131145, Val Acc: 0.773196\n",
      "Epoch 12603 - Train Loss: 0.111854, Train Acc: 0.819231 | Val Loss: 0.131141, Val Acc: 0.773196\n",
      "Epoch 12604 - Train Loss: 0.111849, Train Acc: 0.819231 | Val Loss: 0.131137, Val Acc: 0.773196\n",
      "Epoch 12605 - Train Loss: 0.111844, Train Acc: 0.819231 | Val Loss: 0.131132, Val Acc: 0.773196\n",
      "Epoch 12606 - Train Loss: 0.111838, Train Acc: 0.819231 | Val Loss: 0.131128, Val Acc: 0.773196\n",
      "Epoch 12607 - Train Loss: 0.111833, Train Acc: 0.819231 | Val Loss: 0.131124, Val Acc: 0.773196\n",
      "Epoch 12608 - Train Loss: 0.111828, Train Acc: 0.819231 | Val Loss: 0.131120, Val Acc: 0.773196\n",
      "Epoch 12609 - Train Loss: 0.111822, Train Acc: 0.819231 | Val Loss: 0.131116, Val Acc: 0.773196\n",
      "Epoch 12610 - Train Loss: 0.111817, Train Acc: 0.819231 | Val Loss: 0.131112, Val Acc: 0.773196\n",
      "Epoch 12611 - Train Loss: 0.111811, Train Acc: 0.819231 | Val Loss: 0.131108, Val Acc: 0.773196\n",
      "Epoch 12612 - Train Loss: 0.111806, Train Acc: 0.819231 | Val Loss: 0.131104, Val Acc: 0.773196\n",
      "Epoch 12613 - Train Loss: 0.111801, Train Acc: 0.819231 | Val Loss: 0.131099, Val Acc: 0.773196\n",
      "Epoch 12614 - Train Loss: 0.111795, Train Acc: 0.819231 | Val Loss: 0.131095, Val Acc: 0.773196\n",
      "Epoch 12615 - Train Loss: 0.111790, Train Acc: 0.819231 | Val Loss: 0.131091, Val Acc: 0.773196\n",
      "Epoch 12616 - Train Loss: 0.111784, Train Acc: 0.819231 | Val Loss: 0.131087, Val Acc: 0.773196\n",
      "Epoch 12617 - Train Loss: 0.111779, Train Acc: 0.819231 | Val Loss: 0.131083, Val Acc: 0.773196\n",
      "Epoch 12618 - Train Loss: 0.111774, Train Acc: 0.819231 | Val Loss: 0.131079, Val Acc: 0.773196\n",
      "Epoch 12619 - Train Loss: 0.111768, Train Acc: 0.819231 | Val Loss: 0.131075, Val Acc: 0.773196\n",
      "Epoch 12620 - Train Loss: 0.111763, Train Acc: 0.819231 | Val Loss: 0.131071, Val Acc: 0.773196\n",
      "Epoch 12621 - Train Loss: 0.111757, Train Acc: 0.819231 | Val Loss: 0.131067, Val Acc: 0.773196\n",
      "Epoch 12622 - Train Loss: 0.111752, Train Acc: 0.819231 | Val Loss: 0.131062, Val Acc: 0.773196\n",
      "Epoch 12623 - Train Loss: 0.111747, Train Acc: 0.819231 | Val Loss: 0.131058, Val Acc: 0.773196\n",
      "Epoch 12624 - Train Loss: 0.111741, Train Acc: 0.819231 | Val Loss: 0.131054, Val Acc: 0.773196\n",
      "Epoch 12625 - Train Loss: 0.111736, Train Acc: 0.819231 | Val Loss: 0.131050, Val Acc: 0.773196\n",
      "Epoch 12626 - Train Loss: 0.111731, Train Acc: 0.819231 | Val Loss: 0.131046, Val Acc: 0.773196\n",
      "Epoch 12627 - Train Loss: 0.111725, Train Acc: 0.819231 | Val Loss: 0.131042, Val Acc: 0.773196\n",
      "Epoch 12628 - Train Loss: 0.111720, Train Acc: 0.819231 | Val Loss: 0.131038, Val Acc: 0.773196\n",
      "Epoch 12629 - Train Loss: 0.111714, Train Acc: 0.819231 | Val Loss: 0.131034, Val Acc: 0.773196\n",
      "Epoch 12630 - Train Loss: 0.111709, Train Acc: 0.819231 | Val Loss: 0.131030, Val Acc: 0.773196\n",
      "Epoch 12631 - Train Loss: 0.111704, Train Acc: 0.819231 | Val Loss: 0.131026, Val Acc: 0.773196\n",
      "Epoch 12632 - Train Loss: 0.111698, Train Acc: 0.819231 | Val Loss: 0.131021, Val Acc: 0.773196\n",
      "Epoch 12633 - Train Loss: 0.111693, Train Acc: 0.819231 | Val Loss: 0.131017, Val Acc: 0.773196\n",
      "Epoch 12634 - Train Loss: 0.111688, Train Acc: 0.819231 | Val Loss: 0.131013, Val Acc: 0.773196\n",
      "Epoch 12635 - Train Loss: 0.111682, Train Acc: 0.819231 | Val Loss: 0.131009, Val Acc: 0.773196\n",
      "Epoch 12636 - Train Loss: 0.111677, Train Acc: 0.819231 | Val Loss: 0.131005, Val Acc: 0.773196\n",
      "Epoch 12637 - Train Loss: 0.111671, Train Acc: 0.819231 | Val Loss: 0.131001, Val Acc: 0.773196\n",
      "Epoch 12638 - Train Loss: 0.111666, Train Acc: 0.819231 | Val Loss: 0.130997, Val Acc: 0.773196\n",
      "Epoch 12639 - Train Loss: 0.111661, Train Acc: 0.819231 | Val Loss: 0.130993, Val Acc: 0.773196\n",
      "Epoch 12640 - Train Loss: 0.111655, Train Acc: 0.820513 | Val Loss: 0.130989, Val Acc: 0.773196\n",
      "Epoch 12641 - Train Loss: 0.111650, Train Acc: 0.820513 | Val Loss: 0.130985, Val Acc: 0.773196\n",
      "Epoch 12642 - Train Loss: 0.111645, Train Acc: 0.820513 | Val Loss: 0.130981, Val Acc: 0.773196\n",
      "Epoch 12643 - Train Loss: 0.111639, Train Acc: 0.820513 | Val Loss: 0.130976, Val Acc: 0.773196\n",
      "Epoch 12644 - Train Loss: 0.111634, Train Acc: 0.820513 | Val Loss: 0.130972, Val Acc: 0.773196\n",
      "Epoch 12645 - Train Loss: 0.111628, Train Acc: 0.820513 | Val Loss: 0.130968, Val Acc: 0.773196\n",
      "Epoch 12646 - Train Loss: 0.111623, Train Acc: 0.820513 | Val Loss: 0.130964, Val Acc: 0.773196\n",
      "Epoch 12647 - Train Loss: 0.111618, Train Acc: 0.820513 | Val Loss: 0.130960, Val Acc: 0.773196\n",
      "Epoch 12648 - Train Loss: 0.111612, Train Acc: 0.820513 | Val Loss: 0.130956, Val Acc: 0.773196\n",
      "Epoch 12649 - Train Loss: 0.111607, Train Acc: 0.820513 | Val Loss: 0.130952, Val Acc: 0.773196\n",
      "Epoch 12650 - Train Loss: 0.111602, Train Acc: 0.820513 | Val Loss: 0.130948, Val Acc: 0.773196\n",
      "Epoch 12651 - Train Loss: 0.111596, Train Acc: 0.820513 | Val Loss: 0.130944, Val Acc: 0.773196\n",
      "Epoch 12652 - Train Loss: 0.111591, Train Acc: 0.820513 | Val Loss: 0.130940, Val Acc: 0.773196\n",
      "Epoch 12653 - Train Loss: 0.111586, Train Acc: 0.820513 | Val Loss: 0.130935, Val Acc: 0.773196\n",
      "Epoch 12654 - Train Loss: 0.111580, Train Acc: 0.820513 | Val Loss: 0.130931, Val Acc: 0.773196\n",
      "Epoch 12655 - Train Loss: 0.111575, Train Acc: 0.820513 | Val Loss: 0.130927, Val Acc: 0.773196\n",
      "Epoch 12656 - Train Loss: 0.111570, Train Acc: 0.820513 | Val Loss: 0.130923, Val Acc: 0.773196\n",
      "Epoch 12657 - Train Loss: 0.111564, Train Acc: 0.820513 | Val Loss: 0.130919, Val Acc: 0.773196\n",
      "Epoch 12658 - Train Loss: 0.111559, Train Acc: 0.820513 | Val Loss: 0.130915, Val Acc: 0.773196\n",
      "Epoch 12659 - Train Loss: 0.111553, Train Acc: 0.820513 | Val Loss: 0.130911, Val Acc: 0.773196\n",
      "Epoch 12660 - Train Loss: 0.111548, Train Acc: 0.820513 | Val Loss: 0.130907, Val Acc: 0.773196\n",
      "Epoch 12661 - Train Loss: 0.111543, Train Acc: 0.820513 | Val Loss: 0.130903, Val Acc: 0.773196\n",
      "Epoch 12662 - Train Loss: 0.111537, Train Acc: 0.820513 | Val Loss: 0.130899, Val Acc: 0.773196\n",
      "Epoch 12663 - Train Loss: 0.111532, Train Acc: 0.820513 | Val Loss: 0.130895, Val Acc: 0.773196\n",
      "Epoch 12664 - Train Loss: 0.111527, Train Acc: 0.820513 | Val Loss: 0.130890, Val Acc: 0.773196\n",
      "Epoch 12665 - Train Loss: 0.111521, Train Acc: 0.820513 | Val Loss: 0.130886, Val Acc: 0.773196\n",
      "Epoch 12666 - Train Loss: 0.111516, Train Acc: 0.820513 | Val Loss: 0.130882, Val Acc: 0.773196\n",
      "Epoch 12667 - Train Loss: 0.111511, Train Acc: 0.820513 | Val Loss: 0.130878, Val Acc: 0.773196\n",
      "Epoch 12668 - Train Loss: 0.111505, Train Acc: 0.820513 | Val Loss: 0.130874, Val Acc: 0.773196\n",
      "Epoch 12669 - Train Loss: 0.111500, Train Acc: 0.820513 | Val Loss: 0.130870, Val Acc: 0.773196\n",
      "Epoch 12670 - Train Loss: 0.111495, Train Acc: 0.820513 | Val Loss: 0.130866, Val Acc: 0.773196\n",
      "Epoch 12671 - Train Loss: 0.111489, Train Acc: 0.820513 | Val Loss: 0.130862, Val Acc: 0.773196\n",
      "Epoch 12672 - Train Loss: 0.111484, Train Acc: 0.820513 | Val Loss: 0.130858, Val Acc: 0.773196\n",
      "Epoch 12673 - Train Loss: 0.111479, Train Acc: 0.820513 | Val Loss: 0.130854, Val Acc: 0.773196\n",
      "Epoch 12674 - Train Loss: 0.111473, Train Acc: 0.820513 | Val Loss: 0.130850, Val Acc: 0.773196\n",
      "Epoch 12675 - Train Loss: 0.111468, Train Acc: 0.820513 | Val Loss: 0.130846, Val Acc: 0.773196\n",
      "Epoch 12676 - Train Loss: 0.111463, Train Acc: 0.820513 | Val Loss: 0.130842, Val Acc: 0.773196\n",
      "Epoch 12677 - Train Loss: 0.111457, Train Acc: 0.820513 | Val Loss: 0.130837, Val Acc: 0.773196\n",
      "Epoch 12678 - Train Loss: 0.111452, Train Acc: 0.820513 | Val Loss: 0.130833, Val Acc: 0.773196\n",
      "Epoch 12679 - Train Loss: 0.111447, Train Acc: 0.820513 | Val Loss: 0.130829, Val Acc: 0.773196\n",
      "Epoch 12680 - Train Loss: 0.111441, Train Acc: 0.820513 | Val Loss: 0.130825, Val Acc: 0.773196\n",
      "Epoch 12681 - Train Loss: 0.111436, Train Acc: 0.820513 | Val Loss: 0.130821, Val Acc: 0.773196\n",
      "Epoch 12682 - Train Loss: 0.111431, Train Acc: 0.820513 | Val Loss: 0.130817, Val Acc: 0.773196\n",
      "Epoch 12683 - Train Loss: 0.111425, Train Acc: 0.820513 | Val Loss: 0.130813, Val Acc: 0.773196\n",
      "Epoch 12684 - Train Loss: 0.111420, Train Acc: 0.820513 | Val Loss: 0.130809, Val Acc: 0.773196\n",
      "Epoch 12685 - Train Loss: 0.111415, Train Acc: 0.820513 | Val Loss: 0.130805, Val Acc: 0.773196\n",
      "Epoch 12686 - Train Loss: 0.111409, Train Acc: 0.820513 | Val Loss: 0.130801, Val Acc: 0.773196\n",
      "Epoch 12687 - Train Loss: 0.111404, Train Acc: 0.820513 | Val Loss: 0.130797, Val Acc: 0.773196\n",
      "Epoch 12688 - Train Loss: 0.111399, Train Acc: 0.820513 | Val Loss: 0.130793, Val Acc: 0.773196\n",
      "Epoch 12689 - Train Loss: 0.111393, Train Acc: 0.820513 | Val Loss: 0.130789, Val Acc: 0.773196\n",
      "Epoch 12690 - Train Loss: 0.111388, Train Acc: 0.820513 | Val Loss: 0.130785, Val Acc: 0.773196\n",
      "Epoch 12691 - Train Loss: 0.111383, Train Acc: 0.820513 | Val Loss: 0.130781, Val Acc: 0.773196\n",
      "Epoch 12692 - Train Loss: 0.111377, Train Acc: 0.820513 | Val Loss: 0.130777, Val Acc: 0.773196\n",
      "Epoch 12693 - Train Loss: 0.111372, Train Acc: 0.820513 | Val Loss: 0.130773, Val Acc: 0.773196\n",
      "Epoch 12694 - Train Loss: 0.111367, Train Acc: 0.820513 | Val Loss: 0.130769, Val Acc: 0.773196\n",
      "Epoch 12695 - Train Loss: 0.111361, Train Acc: 0.820513 | Val Loss: 0.130765, Val Acc: 0.773196\n",
      "Epoch 12696 - Train Loss: 0.111356, Train Acc: 0.820513 | Val Loss: 0.130760, Val Acc: 0.773196\n",
      "Epoch 12697 - Train Loss: 0.111351, Train Acc: 0.820513 | Val Loss: 0.130756, Val Acc: 0.773196\n",
      "Epoch 12698 - Train Loss: 0.111345, Train Acc: 0.820513 | Val Loss: 0.130752, Val Acc: 0.773196\n",
      "Epoch 12699 - Train Loss: 0.111340, Train Acc: 0.820513 | Val Loss: 0.130748, Val Acc: 0.773196\n",
      "Epoch 12700 - Train Loss: 0.111335, Train Acc: 0.820513 | Val Loss: 0.130744, Val Acc: 0.773196\n",
      "Epoch 12701 - Train Loss: 0.111330, Train Acc: 0.820513 | Val Loss: 0.130740, Val Acc: 0.773196\n",
      "Epoch 12702 - Train Loss: 0.111324, Train Acc: 0.820513 | Val Loss: 0.130736, Val Acc: 0.773196\n",
      "Epoch 12703 - Train Loss: 0.111319, Train Acc: 0.820513 | Val Loss: 0.130732, Val Acc: 0.773196\n",
      "Epoch 12704 - Train Loss: 0.111314, Train Acc: 0.820513 | Val Loss: 0.130728, Val Acc: 0.773196\n",
      "Epoch 12705 - Train Loss: 0.111308, Train Acc: 0.820513 | Val Loss: 0.130724, Val Acc: 0.773196\n",
      "Epoch 12706 - Train Loss: 0.111303, Train Acc: 0.820513 | Val Loss: 0.130720, Val Acc: 0.773196\n",
      "Epoch 12707 - Train Loss: 0.111298, Train Acc: 0.820513 | Val Loss: 0.130716, Val Acc: 0.773196\n",
      "Epoch 12708 - Train Loss: 0.111292, Train Acc: 0.820513 | Val Loss: 0.130712, Val Acc: 0.773196\n",
      "Epoch 12709 - Train Loss: 0.111287, Train Acc: 0.820513 | Val Loss: 0.130708, Val Acc: 0.773196\n",
      "Epoch 12710 - Train Loss: 0.111282, Train Acc: 0.820513 | Val Loss: 0.130704, Val Acc: 0.773196\n",
      "Epoch 12711 - Train Loss: 0.111276, Train Acc: 0.820513 | Val Loss: 0.130700, Val Acc: 0.773196\n",
      "Epoch 12712 - Train Loss: 0.111271, Train Acc: 0.820513 | Val Loss: 0.130696, Val Acc: 0.773196\n",
      "Epoch 12713 - Train Loss: 0.111266, Train Acc: 0.820513 | Val Loss: 0.130692, Val Acc: 0.773196\n",
      "Epoch 12714 - Train Loss: 0.111261, Train Acc: 0.820513 | Val Loss: 0.130688, Val Acc: 0.773196\n",
      "Epoch 12715 - Train Loss: 0.111255, Train Acc: 0.820513 | Val Loss: 0.130684, Val Acc: 0.773196\n",
      "Epoch 12716 - Train Loss: 0.111250, Train Acc: 0.820513 | Val Loss: 0.130680, Val Acc: 0.773196\n",
      "Epoch 12717 - Train Loss: 0.111245, Train Acc: 0.820513 | Val Loss: 0.130676, Val Acc: 0.773196\n",
      "Epoch 12718 - Train Loss: 0.111239, Train Acc: 0.820513 | Val Loss: 0.130672, Val Acc: 0.773196\n",
      "Epoch 12719 - Train Loss: 0.111234, Train Acc: 0.820513 | Val Loss: 0.130667, Val Acc: 0.773196\n",
      "Epoch 12720 - Train Loss: 0.111229, Train Acc: 0.820513 | Val Loss: 0.130663, Val Acc: 0.773196\n",
      "Epoch 12721 - Train Loss: 0.111223, Train Acc: 0.820513 | Val Loss: 0.130659, Val Acc: 0.773196\n",
      "Epoch 12722 - Train Loss: 0.111218, Train Acc: 0.820513 | Val Loss: 0.130655, Val Acc: 0.773196\n",
      "Epoch 12723 - Train Loss: 0.111213, Train Acc: 0.820513 | Val Loss: 0.130651, Val Acc: 0.773196\n",
      "Epoch 12724 - Train Loss: 0.111208, Train Acc: 0.820513 | Val Loss: 0.130647, Val Acc: 0.773196\n",
      "Epoch 12725 - Train Loss: 0.111202, Train Acc: 0.820513 | Val Loss: 0.130643, Val Acc: 0.773196\n",
      "Epoch 12726 - Train Loss: 0.111197, Train Acc: 0.820513 | Val Loss: 0.130639, Val Acc: 0.773196\n",
      "Epoch 12727 - Train Loss: 0.111192, Train Acc: 0.820513 | Val Loss: 0.130635, Val Acc: 0.773196\n",
      "Epoch 12728 - Train Loss: 0.111186, Train Acc: 0.820513 | Val Loss: 0.130631, Val Acc: 0.773196\n",
      "Epoch 12729 - Train Loss: 0.111181, Train Acc: 0.820513 | Val Loss: 0.130627, Val Acc: 0.773196\n",
      "Epoch 12730 - Train Loss: 0.111176, Train Acc: 0.820513 | Val Loss: 0.130623, Val Acc: 0.773196\n",
      "Epoch 12731 - Train Loss: 0.111170, Train Acc: 0.820513 | Val Loss: 0.130619, Val Acc: 0.773196\n",
      "Epoch 12732 - Train Loss: 0.111165, Train Acc: 0.820513 | Val Loss: 0.130615, Val Acc: 0.773196\n",
      "Epoch 12733 - Train Loss: 0.111160, Train Acc: 0.820513 | Val Loss: 0.130611, Val Acc: 0.773196\n",
      "Epoch 12734 - Train Loss: 0.111155, Train Acc: 0.820513 | Val Loss: 0.130607, Val Acc: 0.773196\n",
      "Epoch 12735 - Train Loss: 0.111149, Train Acc: 0.820513 | Val Loss: 0.130603, Val Acc: 0.773196\n",
      "Epoch 12736 - Train Loss: 0.111144, Train Acc: 0.820513 | Val Loss: 0.130599, Val Acc: 0.773196\n",
      "Epoch 12737 - Train Loss: 0.111139, Train Acc: 0.820513 | Val Loss: 0.130595, Val Acc: 0.773196\n",
      "Epoch 12738 - Train Loss: 0.111133, Train Acc: 0.820513 | Val Loss: 0.130591, Val Acc: 0.773196\n",
      "Epoch 12739 - Train Loss: 0.111128, Train Acc: 0.820513 | Val Loss: 0.130587, Val Acc: 0.773196\n",
      "Epoch 12740 - Train Loss: 0.111123, Train Acc: 0.820513 | Val Loss: 0.130583, Val Acc: 0.773196\n",
      "Epoch 12741 - Train Loss: 0.111118, Train Acc: 0.820513 | Val Loss: 0.130579, Val Acc: 0.773196\n",
      "Epoch 12742 - Train Loss: 0.111112, Train Acc: 0.820513 | Val Loss: 0.130575, Val Acc: 0.773196\n",
      "Epoch 12743 - Train Loss: 0.111107, Train Acc: 0.820513 | Val Loss: 0.130571, Val Acc: 0.773196\n",
      "Epoch 12744 - Train Loss: 0.111102, Train Acc: 0.820513 | Val Loss: 0.130567, Val Acc: 0.773196\n",
      "Epoch 12745 - Train Loss: 0.111097, Train Acc: 0.820513 | Val Loss: 0.130563, Val Acc: 0.773196\n",
      "Epoch 12746 - Train Loss: 0.111091, Train Acc: 0.820513 | Val Loss: 0.130559, Val Acc: 0.773196\n",
      "Epoch 12747 - Train Loss: 0.111086, Train Acc: 0.820513 | Val Loss: 0.130555, Val Acc: 0.773196\n",
      "Epoch 12748 - Train Loss: 0.111081, Train Acc: 0.820513 | Val Loss: 0.130551, Val Acc: 0.773196\n",
      "Epoch 12749 - Train Loss: 0.111075, Train Acc: 0.820513 | Val Loss: 0.130547, Val Acc: 0.773196\n",
      "Epoch 12750 - Train Loss: 0.111070, Train Acc: 0.820513 | Val Loss: 0.130543, Val Acc: 0.773196\n",
      "Epoch 12751 - Train Loss: 0.111065, Train Acc: 0.820513 | Val Loss: 0.130539, Val Acc: 0.773196\n",
      "Epoch 12752 - Train Loss: 0.111060, Train Acc: 0.820513 | Val Loss: 0.130535, Val Acc: 0.773196\n",
      "Epoch 12753 - Train Loss: 0.111054, Train Acc: 0.820513 | Val Loss: 0.130531, Val Acc: 0.773196\n",
      "Epoch 12754 - Train Loss: 0.111049, Train Acc: 0.820513 | Val Loss: 0.130527, Val Acc: 0.773196\n",
      "Epoch 12755 - Train Loss: 0.111044, Train Acc: 0.820513 | Val Loss: 0.130523, Val Acc: 0.773196\n",
      "Epoch 12756 - Train Loss: 0.111039, Train Acc: 0.820513 | Val Loss: 0.130519, Val Acc: 0.773196\n",
      "Epoch 12757 - Train Loss: 0.111033, Train Acc: 0.820513 | Val Loss: 0.130515, Val Acc: 0.773196\n",
      "Epoch 12758 - Train Loss: 0.111028, Train Acc: 0.820513 | Val Loss: 0.130511, Val Acc: 0.773196\n",
      "Epoch 12759 - Train Loss: 0.111023, Train Acc: 0.820513 | Val Loss: 0.130507, Val Acc: 0.773196\n",
      "Epoch 12760 - Train Loss: 0.111017, Train Acc: 0.820513 | Val Loss: 0.130503, Val Acc: 0.773196\n",
      "Epoch 12761 - Train Loss: 0.111012, Train Acc: 0.820513 | Val Loss: 0.130499, Val Acc: 0.773196\n",
      "Epoch 12762 - Train Loss: 0.111007, Train Acc: 0.820513 | Val Loss: 0.130495, Val Acc: 0.773196\n",
      "Epoch 12763 - Train Loss: 0.111002, Train Acc: 0.820513 | Val Loss: 0.130491, Val Acc: 0.773196\n",
      "Epoch 12764 - Train Loss: 0.110996, Train Acc: 0.820513 | Val Loss: 0.130487, Val Acc: 0.773196\n",
      "Epoch 12765 - Train Loss: 0.110991, Train Acc: 0.820513 | Val Loss: 0.130483, Val Acc: 0.773196\n",
      "Epoch 12766 - Train Loss: 0.110986, Train Acc: 0.820513 | Val Loss: 0.130479, Val Acc: 0.773196\n",
      "Epoch 12767 - Train Loss: 0.110981, Train Acc: 0.820513 | Val Loss: 0.130475, Val Acc: 0.773196\n",
      "Epoch 12768 - Train Loss: 0.110975, Train Acc: 0.820513 | Val Loss: 0.130471, Val Acc: 0.773196\n",
      "Epoch 12769 - Train Loss: 0.110970, Train Acc: 0.820513 | Val Loss: 0.130467, Val Acc: 0.773196\n",
      "Epoch 12770 - Train Loss: 0.110965, Train Acc: 0.820513 | Val Loss: 0.130463, Val Acc: 0.773196\n",
      "Epoch 12771 - Train Loss: 0.110960, Train Acc: 0.820513 | Val Loss: 0.130459, Val Acc: 0.773196\n",
      "Epoch 12772 - Train Loss: 0.110954, Train Acc: 0.820513 | Val Loss: 0.130455, Val Acc: 0.773196\n",
      "Epoch 12773 - Train Loss: 0.110949, Train Acc: 0.820513 | Val Loss: 0.130451, Val Acc: 0.773196\n",
      "Epoch 12774 - Train Loss: 0.110944, Train Acc: 0.820513 | Val Loss: 0.130447, Val Acc: 0.773196\n",
      "Epoch 12775 - Train Loss: 0.110939, Train Acc: 0.820513 | Val Loss: 0.130443, Val Acc: 0.773196\n",
      "Epoch 12776 - Train Loss: 0.110933, Train Acc: 0.820513 | Val Loss: 0.130439, Val Acc: 0.773196\n",
      "Epoch 12777 - Train Loss: 0.110928, Train Acc: 0.820513 | Val Loss: 0.130435, Val Acc: 0.773196\n",
      "Epoch 12778 - Train Loss: 0.110923, Train Acc: 0.820513 | Val Loss: 0.130431, Val Acc: 0.773196\n",
      "Epoch 12779 - Train Loss: 0.110918, Train Acc: 0.820513 | Val Loss: 0.130427, Val Acc: 0.773196\n",
      "Epoch 12780 - Train Loss: 0.110912, Train Acc: 0.820513 | Val Loss: 0.130423, Val Acc: 0.773196\n",
      "Epoch 12781 - Train Loss: 0.110907, Train Acc: 0.820513 | Val Loss: 0.130419, Val Acc: 0.773196\n",
      "Epoch 12782 - Train Loss: 0.110902, Train Acc: 0.820513 | Val Loss: 0.130415, Val Acc: 0.773196\n",
      "Epoch 12783 - Train Loss: 0.110897, Train Acc: 0.820513 | Val Loss: 0.130411, Val Acc: 0.773196\n",
      "Epoch 12784 - Train Loss: 0.110891, Train Acc: 0.820513 | Val Loss: 0.130407, Val Acc: 0.773196\n",
      "Epoch 12785 - Train Loss: 0.110886, Train Acc: 0.820513 | Val Loss: 0.130403, Val Acc: 0.773196\n",
      "Epoch 12786 - Train Loss: 0.110881, Train Acc: 0.820513 | Val Loss: 0.130399, Val Acc: 0.773196\n",
      "Epoch 12787 - Train Loss: 0.110876, Train Acc: 0.820513 | Val Loss: 0.130395, Val Acc: 0.773196\n",
      "Epoch 12788 - Train Loss: 0.110870, Train Acc: 0.820513 | Val Loss: 0.130391, Val Acc: 0.773196\n",
      "Epoch 12789 - Train Loss: 0.110865, Train Acc: 0.820513 | Val Loss: 0.130387, Val Acc: 0.773196\n",
      "Epoch 12790 - Train Loss: 0.110860, Train Acc: 0.820513 | Val Loss: 0.130383, Val Acc: 0.773196\n",
      "Epoch 12791 - Train Loss: 0.110855, Train Acc: 0.820513 | Val Loss: 0.130380, Val Acc: 0.773196\n",
      "Epoch 12792 - Train Loss: 0.110849, Train Acc: 0.820513 | Val Loss: 0.130376, Val Acc: 0.773196\n",
      "Epoch 12793 - Train Loss: 0.110844, Train Acc: 0.820513 | Val Loss: 0.130372, Val Acc: 0.773196\n",
      "Epoch 12794 - Train Loss: 0.110839, Train Acc: 0.820513 | Val Loss: 0.130368, Val Acc: 0.773196\n",
      "Epoch 12795 - Train Loss: 0.110834, Train Acc: 0.820513 | Val Loss: 0.130364, Val Acc: 0.773196\n",
      "Epoch 12796 - Train Loss: 0.110829, Train Acc: 0.820513 | Val Loss: 0.130360, Val Acc: 0.773196\n",
      "Epoch 12797 - Train Loss: 0.110823, Train Acc: 0.820513 | Val Loss: 0.130356, Val Acc: 0.773196\n",
      "Epoch 12798 - Train Loss: 0.110818, Train Acc: 0.820513 | Val Loss: 0.130352, Val Acc: 0.773196\n",
      "Epoch 12799 - Train Loss: 0.110813, Train Acc: 0.820513 | Val Loss: 0.130348, Val Acc: 0.773196\n",
      "Epoch 12800 - Train Loss: 0.110808, Train Acc: 0.820513 | Val Loss: 0.130344, Val Acc: 0.773196\n",
      "Epoch 12801 - Train Loss: 0.110802, Train Acc: 0.820513 | Val Loss: 0.130340, Val Acc: 0.773196\n",
      "Epoch 12802 - Train Loss: 0.110797, Train Acc: 0.820513 | Val Loss: 0.130336, Val Acc: 0.773196\n",
      "Epoch 12803 - Train Loss: 0.110792, Train Acc: 0.820513 | Val Loss: 0.130332, Val Acc: 0.773196\n",
      "Epoch 12804 - Train Loss: 0.110787, Train Acc: 0.820513 | Val Loss: 0.130328, Val Acc: 0.773196\n",
      "Epoch 12805 - Train Loss: 0.110781, Train Acc: 0.820513 | Val Loss: 0.130324, Val Acc: 0.773196\n",
      "Epoch 12806 - Train Loss: 0.110776, Train Acc: 0.820513 | Val Loss: 0.130320, Val Acc: 0.773196\n",
      "Epoch 12807 - Train Loss: 0.110771, Train Acc: 0.820513 | Val Loss: 0.130316, Val Acc: 0.773196\n",
      "Epoch 12808 - Train Loss: 0.110766, Train Acc: 0.820513 | Val Loss: 0.130312, Val Acc: 0.773196\n",
      "Epoch 12809 - Train Loss: 0.110761, Train Acc: 0.820513 | Val Loss: 0.130308, Val Acc: 0.773196\n",
      "Epoch 12810 - Train Loss: 0.110755, Train Acc: 0.820513 | Val Loss: 0.130304, Val Acc: 0.773196\n",
      "Epoch 12811 - Train Loss: 0.110750, Train Acc: 0.820513 | Val Loss: 0.130300, Val Acc: 0.773196\n",
      "Epoch 12812 - Train Loss: 0.110745, Train Acc: 0.820513 | Val Loss: 0.130296, Val Acc: 0.773196\n",
      "Epoch 12813 - Train Loss: 0.110740, Train Acc: 0.820513 | Val Loss: 0.130292, Val Acc: 0.773196\n",
      "Epoch 12814 - Train Loss: 0.110734, Train Acc: 0.820513 | Val Loss: 0.130289, Val Acc: 0.773196\n",
      "Epoch 12815 - Train Loss: 0.110729, Train Acc: 0.820513 | Val Loss: 0.130285, Val Acc: 0.773196\n",
      "Epoch 12816 - Train Loss: 0.110724, Train Acc: 0.820513 | Val Loss: 0.130281, Val Acc: 0.773196\n",
      "Epoch 12817 - Train Loss: 0.110719, Train Acc: 0.820513 | Val Loss: 0.130277, Val Acc: 0.773196\n",
      "Epoch 12818 - Train Loss: 0.110714, Train Acc: 0.820513 | Val Loss: 0.130273, Val Acc: 0.773196\n",
      "Epoch 12819 - Train Loss: 0.110708, Train Acc: 0.820513 | Val Loss: 0.130269, Val Acc: 0.773196\n",
      "Epoch 12820 - Train Loss: 0.110703, Train Acc: 0.820513 | Val Loss: 0.130265, Val Acc: 0.773196\n",
      "Epoch 12821 - Train Loss: 0.110698, Train Acc: 0.820513 | Val Loss: 0.130261, Val Acc: 0.773196\n",
      "Epoch 12822 - Train Loss: 0.110693, Train Acc: 0.820513 | Val Loss: 0.130257, Val Acc: 0.773196\n",
      "Epoch 12823 - Train Loss: 0.110688, Train Acc: 0.820513 | Val Loss: 0.130253, Val Acc: 0.773196\n",
      "Epoch 12824 - Train Loss: 0.110682, Train Acc: 0.820513 | Val Loss: 0.130249, Val Acc: 0.773196\n",
      "Epoch 12825 - Train Loss: 0.110677, Train Acc: 0.820513 | Val Loss: 0.130245, Val Acc: 0.773196\n",
      "Epoch 12826 - Train Loss: 0.110672, Train Acc: 0.820513 | Val Loss: 0.130241, Val Acc: 0.773196\n",
      "Epoch 12827 - Train Loss: 0.110667, Train Acc: 0.820513 | Val Loss: 0.130237, Val Acc: 0.773196\n",
      "Epoch 12828 - Train Loss: 0.110661, Train Acc: 0.820513 | Val Loss: 0.130233, Val Acc: 0.773196\n",
      "Epoch 12829 - Train Loss: 0.110656, Train Acc: 0.820513 | Val Loss: 0.130229, Val Acc: 0.773196\n",
      "Epoch 12830 - Train Loss: 0.110651, Train Acc: 0.820513 | Val Loss: 0.130225, Val Acc: 0.773196\n",
      "Epoch 12831 - Train Loss: 0.110646, Train Acc: 0.820513 | Val Loss: 0.130222, Val Acc: 0.773196\n",
      "Epoch 12832 - Train Loss: 0.110641, Train Acc: 0.820513 | Val Loss: 0.130218, Val Acc: 0.773196\n",
      "Epoch 12833 - Train Loss: 0.110635, Train Acc: 0.820513 | Val Loss: 0.130214, Val Acc: 0.773196\n",
      "Epoch 12834 - Train Loss: 0.110630, Train Acc: 0.820513 | Val Loss: 0.130210, Val Acc: 0.773196\n",
      "Epoch 12835 - Train Loss: 0.110625, Train Acc: 0.820513 | Val Loss: 0.130206, Val Acc: 0.773196\n",
      "Epoch 12836 - Train Loss: 0.110620, Train Acc: 0.820513 | Val Loss: 0.130202, Val Acc: 0.773196\n",
      "Epoch 12837 - Train Loss: 0.110615, Train Acc: 0.820513 | Val Loss: 0.130198, Val Acc: 0.773196\n",
      "Epoch 12838 - Train Loss: 0.110609, Train Acc: 0.820513 | Val Loss: 0.130194, Val Acc: 0.773196\n",
      "Epoch 12839 - Train Loss: 0.110604, Train Acc: 0.820513 | Val Loss: 0.130190, Val Acc: 0.773196\n",
      "Epoch 12840 - Train Loss: 0.110599, Train Acc: 0.821795 | Val Loss: 0.130186, Val Acc: 0.773196\n",
      "Epoch 12841 - Train Loss: 0.110594, Train Acc: 0.821795 | Val Loss: 0.130182, Val Acc: 0.773196\n",
      "Epoch 12842 - Train Loss: 0.110589, Train Acc: 0.821795 | Val Loss: 0.130178, Val Acc: 0.773196\n",
      "Epoch 12843 - Train Loss: 0.110583, Train Acc: 0.821795 | Val Loss: 0.130174, Val Acc: 0.773196\n",
      "Epoch 12844 - Train Loss: 0.110578, Train Acc: 0.821795 | Val Loss: 0.130170, Val Acc: 0.773196\n",
      "Epoch 12845 - Train Loss: 0.110573, Train Acc: 0.821795 | Val Loss: 0.130167, Val Acc: 0.773196\n",
      "Epoch 12846 - Train Loss: 0.110568, Train Acc: 0.821795 | Val Loss: 0.130163, Val Acc: 0.773196\n",
      "Epoch 12847 - Train Loss: 0.110563, Train Acc: 0.821795 | Val Loss: 0.130159, Val Acc: 0.773196\n",
      "Epoch 12848 - Train Loss: 0.110557, Train Acc: 0.821795 | Val Loss: 0.130155, Val Acc: 0.773196\n",
      "Epoch 12849 - Train Loss: 0.110552, Train Acc: 0.821795 | Val Loss: 0.130151, Val Acc: 0.773196\n",
      "Epoch 12850 - Train Loss: 0.110547, Train Acc: 0.821795 | Val Loss: 0.130147, Val Acc: 0.773196\n",
      "Epoch 12851 - Train Loss: 0.110542, Train Acc: 0.821795 | Val Loss: 0.130143, Val Acc: 0.773196\n",
      "Epoch 12852 - Train Loss: 0.110537, Train Acc: 0.821795 | Val Loss: 0.130139, Val Acc: 0.773196\n",
      "Epoch 12853 - Train Loss: 0.110532, Train Acc: 0.821795 | Val Loss: 0.130135, Val Acc: 0.773196\n",
      "Epoch 12854 - Train Loss: 0.110526, Train Acc: 0.821795 | Val Loss: 0.130131, Val Acc: 0.773196\n",
      "Epoch 12855 - Train Loss: 0.110521, Train Acc: 0.821795 | Val Loss: 0.130127, Val Acc: 0.773196\n",
      "Epoch 12856 - Train Loss: 0.110516, Train Acc: 0.821795 | Val Loss: 0.130123, Val Acc: 0.773196\n",
      "Epoch 12857 - Train Loss: 0.110511, Train Acc: 0.821795 | Val Loss: 0.130120, Val Acc: 0.773196\n",
      "Epoch 12858 - Train Loss: 0.110506, Train Acc: 0.821795 | Val Loss: 0.130116, Val Acc: 0.773196\n",
      "Epoch 12859 - Train Loss: 0.110500, Train Acc: 0.821795 | Val Loss: 0.130112, Val Acc: 0.773196\n",
      "Epoch 12860 - Train Loss: 0.110495, Train Acc: 0.821795 | Val Loss: 0.130108, Val Acc: 0.773196\n",
      "Epoch 12861 - Train Loss: 0.110490, Train Acc: 0.821795 | Val Loss: 0.130104, Val Acc: 0.773196\n",
      "Epoch 12862 - Train Loss: 0.110485, Train Acc: 0.821795 | Val Loss: 0.130100, Val Acc: 0.773196\n",
      "Epoch 12863 - Train Loss: 0.110480, Train Acc: 0.821795 | Val Loss: 0.130096, Val Acc: 0.773196\n",
      "Epoch 12864 - Train Loss: 0.110475, Train Acc: 0.821795 | Val Loss: 0.130092, Val Acc: 0.773196\n",
      "Epoch 12865 - Train Loss: 0.110469, Train Acc: 0.821795 | Val Loss: 0.130088, Val Acc: 0.773196\n",
      "Epoch 12866 - Train Loss: 0.110464, Train Acc: 0.821795 | Val Loss: 0.130084, Val Acc: 0.773196\n",
      "Epoch 12867 - Train Loss: 0.110459, Train Acc: 0.821795 | Val Loss: 0.130080, Val Acc: 0.773196\n",
      "Epoch 12868 - Train Loss: 0.110454, Train Acc: 0.821795 | Val Loss: 0.130077, Val Acc: 0.773196\n",
      "Epoch 12869 - Train Loss: 0.110449, Train Acc: 0.821795 | Val Loss: 0.130073, Val Acc: 0.773196\n",
      "Epoch 12870 - Train Loss: 0.110444, Train Acc: 0.821795 | Val Loss: 0.130069, Val Acc: 0.773196\n",
      "Epoch 12871 - Train Loss: 0.110438, Train Acc: 0.821795 | Val Loss: 0.130065, Val Acc: 0.773196\n",
      "Epoch 12872 - Train Loss: 0.110433, Train Acc: 0.821795 | Val Loss: 0.130061, Val Acc: 0.773196\n",
      "Epoch 12873 - Train Loss: 0.110428, Train Acc: 0.821795 | Val Loss: 0.130057, Val Acc: 0.773196\n",
      "Epoch 12874 - Train Loss: 0.110423, Train Acc: 0.821795 | Val Loss: 0.130053, Val Acc: 0.773196\n",
      "Epoch 12875 - Train Loss: 0.110418, Train Acc: 0.821795 | Val Loss: 0.130049, Val Acc: 0.773196\n",
      "Epoch 12876 - Train Loss: 0.110412, Train Acc: 0.821795 | Val Loss: 0.130045, Val Acc: 0.773196\n",
      "Epoch 12877 - Train Loss: 0.110407, Train Acc: 0.821795 | Val Loss: 0.130041, Val Acc: 0.773196\n",
      "Epoch 12878 - Train Loss: 0.110402, Train Acc: 0.821795 | Val Loss: 0.130038, Val Acc: 0.773196\n",
      "Epoch 12879 - Train Loss: 0.110397, Train Acc: 0.821795 | Val Loss: 0.130034, Val Acc: 0.773196\n",
      "Epoch 12880 - Train Loss: 0.110392, Train Acc: 0.821795 | Val Loss: 0.130030, Val Acc: 0.773196\n",
      "Epoch 12881 - Train Loss: 0.110387, Train Acc: 0.821795 | Val Loss: 0.130026, Val Acc: 0.773196\n",
      "Epoch 12882 - Train Loss: 0.110381, Train Acc: 0.821795 | Val Loss: 0.130022, Val Acc: 0.773196\n",
      "Epoch 12883 - Train Loss: 0.110376, Train Acc: 0.821795 | Val Loss: 0.130018, Val Acc: 0.773196\n",
      "Epoch 12884 - Train Loss: 0.110371, Train Acc: 0.821795 | Val Loss: 0.130014, Val Acc: 0.773196\n",
      "Epoch 12885 - Train Loss: 0.110366, Train Acc: 0.821795 | Val Loss: 0.130010, Val Acc: 0.773196\n",
      "Epoch 12886 - Train Loss: 0.110361, Train Acc: 0.821795 | Val Loss: 0.130006, Val Acc: 0.773196\n",
      "Epoch 12887 - Train Loss: 0.110356, Train Acc: 0.821795 | Val Loss: 0.130003, Val Acc: 0.773196\n",
      "Epoch 12888 - Train Loss: 0.110351, Train Acc: 0.821795 | Val Loss: 0.129999, Val Acc: 0.773196\n",
      "Epoch 12889 - Train Loss: 0.110345, Train Acc: 0.821795 | Val Loss: 0.129995, Val Acc: 0.773196\n",
      "Epoch 12890 - Train Loss: 0.110340, Train Acc: 0.821795 | Val Loss: 0.129991, Val Acc: 0.773196\n",
      "Epoch 12891 - Train Loss: 0.110335, Train Acc: 0.821795 | Val Loss: 0.129987, Val Acc: 0.773196\n",
      "Epoch 12892 - Train Loss: 0.110330, Train Acc: 0.821795 | Val Loss: 0.129983, Val Acc: 0.773196\n",
      "Epoch 12893 - Train Loss: 0.110325, Train Acc: 0.821795 | Val Loss: 0.129979, Val Acc: 0.773196\n",
      "Epoch 12894 - Train Loss: 0.110320, Train Acc: 0.821795 | Val Loss: 0.129975, Val Acc: 0.773196\n",
      "Epoch 12895 - Train Loss: 0.110314, Train Acc: 0.821795 | Val Loss: 0.129971, Val Acc: 0.773196\n",
      "Epoch 12896 - Train Loss: 0.110309, Train Acc: 0.821795 | Val Loss: 0.129968, Val Acc: 0.773196\n",
      "Epoch 12897 - Train Loss: 0.110304, Train Acc: 0.821795 | Val Loss: 0.129964, Val Acc: 0.773196\n",
      "Epoch 12898 - Train Loss: 0.110299, Train Acc: 0.821795 | Val Loss: 0.129960, Val Acc: 0.773196\n",
      "Epoch 12899 - Train Loss: 0.110294, Train Acc: 0.821795 | Val Loss: 0.129956, Val Acc: 0.773196\n",
      "Epoch 12900 - Train Loss: 0.110289, Train Acc: 0.821795 | Val Loss: 0.129952, Val Acc: 0.773196\n",
      "Epoch 12901 - Train Loss: 0.110284, Train Acc: 0.821795 | Val Loss: 0.129948, Val Acc: 0.773196\n",
      "Epoch 12902 - Train Loss: 0.110278, Train Acc: 0.821795 | Val Loss: 0.129944, Val Acc: 0.773196\n",
      "Epoch 12903 - Train Loss: 0.110273, Train Acc: 0.821795 | Val Loss: 0.129940, Val Acc: 0.773196\n",
      "Epoch 12904 - Train Loss: 0.110268, Train Acc: 0.821795 | Val Loss: 0.129937, Val Acc: 0.773196\n",
      "Epoch 12905 - Train Loss: 0.110263, Train Acc: 0.821795 | Val Loss: 0.129933, Val Acc: 0.773196\n",
      "Epoch 12906 - Train Loss: 0.110258, Train Acc: 0.821795 | Val Loss: 0.129929, Val Acc: 0.773196\n",
      "Epoch 12907 - Train Loss: 0.110253, Train Acc: 0.821795 | Val Loss: 0.129925, Val Acc: 0.773196\n",
      "Epoch 12908 - Train Loss: 0.110248, Train Acc: 0.821795 | Val Loss: 0.129921, Val Acc: 0.773196\n",
      "Epoch 12909 - Train Loss: 0.110242, Train Acc: 0.821795 | Val Loss: 0.129917, Val Acc: 0.773196\n",
      "Epoch 12910 - Train Loss: 0.110237, Train Acc: 0.821795 | Val Loss: 0.129913, Val Acc: 0.773196\n",
      "Epoch 12911 - Train Loss: 0.110232, Train Acc: 0.821795 | Val Loss: 0.129909, Val Acc: 0.773196\n",
      "Epoch 12912 - Train Loss: 0.110227, Train Acc: 0.821795 | Val Loss: 0.129906, Val Acc: 0.773196\n",
      "Epoch 12913 - Train Loss: 0.110222, Train Acc: 0.821795 | Val Loss: 0.129902, Val Acc: 0.773196\n",
      "Epoch 12914 - Train Loss: 0.110217, Train Acc: 0.821795 | Val Loss: 0.129898, Val Acc: 0.773196\n",
      "Epoch 12915 - Train Loss: 0.110212, Train Acc: 0.821795 | Val Loss: 0.129894, Val Acc: 0.773196\n",
      "Epoch 12916 - Train Loss: 0.110206, Train Acc: 0.821795 | Val Loss: 0.129890, Val Acc: 0.773196\n",
      "Epoch 12917 - Train Loss: 0.110201, Train Acc: 0.821795 | Val Loss: 0.129886, Val Acc: 0.773196\n",
      "Epoch 12918 - Train Loss: 0.110196, Train Acc: 0.821795 | Val Loss: 0.129882, Val Acc: 0.773196\n",
      "Epoch 12919 - Train Loss: 0.110191, Train Acc: 0.821795 | Val Loss: 0.129879, Val Acc: 0.773196\n",
      "Epoch 12920 - Train Loss: 0.110186, Train Acc: 0.821795 | Val Loss: 0.129875, Val Acc: 0.773196\n",
      "Epoch 12921 - Train Loss: 0.110181, Train Acc: 0.821795 | Val Loss: 0.129871, Val Acc: 0.773196\n",
      "Epoch 12922 - Train Loss: 0.110176, Train Acc: 0.821795 | Val Loss: 0.129867, Val Acc: 0.773196\n",
      "Epoch 12923 - Train Loss: 0.110171, Train Acc: 0.821795 | Val Loss: 0.129863, Val Acc: 0.773196\n",
      "Epoch 12924 - Train Loss: 0.110165, Train Acc: 0.823077 | Val Loss: 0.129859, Val Acc: 0.773196\n",
      "Epoch 12925 - Train Loss: 0.110160, Train Acc: 0.823077 | Val Loss: 0.129855, Val Acc: 0.773196\n",
      "Epoch 12926 - Train Loss: 0.110155, Train Acc: 0.823077 | Val Loss: 0.129852, Val Acc: 0.773196\n",
      "Epoch 12927 - Train Loss: 0.110150, Train Acc: 0.823077 | Val Loss: 0.129848, Val Acc: 0.773196\n",
      "Epoch 12928 - Train Loss: 0.110145, Train Acc: 0.823077 | Val Loss: 0.129844, Val Acc: 0.773196\n",
      "Epoch 12929 - Train Loss: 0.110140, Train Acc: 0.823077 | Val Loss: 0.129840, Val Acc: 0.773196\n",
      "Epoch 12930 - Train Loss: 0.110135, Train Acc: 0.823077 | Val Loss: 0.129836, Val Acc: 0.773196\n",
      "Epoch 12931 - Train Loss: 0.110129, Train Acc: 0.823077 | Val Loss: 0.129832, Val Acc: 0.773196\n",
      "Epoch 12932 - Train Loss: 0.110124, Train Acc: 0.823077 | Val Loss: 0.129828, Val Acc: 0.773196\n",
      "Epoch 12933 - Train Loss: 0.110119, Train Acc: 0.823077 | Val Loss: 0.129825, Val Acc: 0.773196\n",
      "Epoch 12934 - Train Loss: 0.110114, Train Acc: 0.823077 | Val Loss: 0.129821, Val Acc: 0.773196\n",
      "Epoch 12935 - Train Loss: 0.110109, Train Acc: 0.823077 | Val Loss: 0.129817, Val Acc: 0.773196\n",
      "Epoch 12936 - Train Loss: 0.110104, Train Acc: 0.823077 | Val Loss: 0.129813, Val Acc: 0.773196\n",
      "Epoch 12937 - Train Loss: 0.110099, Train Acc: 0.823077 | Val Loss: 0.129809, Val Acc: 0.773196\n",
      "Epoch 12938 - Train Loss: 0.110094, Train Acc: 0.823077 | Val Loss: 0.129805, Val Acc: 0.773196\n",
      "Epoch 12939 - Train Loss: 0.110089, Train Acc: 0.823077 | Val Loss: 0.129801, Val Acc: 0.773196\n",
      "Epoch 12940 - Train Loss: 0.110083, Train Acc: 0.823077 | Val Loss: 0.129798, Val Acc: 0.773196\n",
      "Epoch 12941 - Train Loss: 0.110078, Train Acc: 0.823077 | Val Loss: 0.129794, Val Acc: 0.773196\n",
      "Epoch 12942 - Train Loss: 0.110073, Train Acc: 0.823077 | Val Loss: 0.129790, Val Acc: 0.773196\n",
      "Epoch 12943 - Train Loss: 0.110068, Train Acc: 0.823077 | Val Loss: 0.129786, Val Acc: 0.773196\n",
      "Epoch 12944 - Train Loss: 0.110063, Train Acc: 0.823077 | Val Loss: 0.129782, Val Acc: 0.773196\n",
      "Epoch 12945 - Train Loss: 0.110058, Train Acc: 0.823077 | Val Loss: 0.129778, Val Acc: 0.773196\n",
      "Epoch 12946 - Train Loss: 0.110053, Train Acc: 0.823077 | Val Loss: 0.129775, Val Acc: 0.773196\n",
      "Epoch 12947 - Train Loss: 0.110048, Train Acc: 0.823077 | Val Loss: 0.129771, Val Acc: 0.773196\n",
      "Epoch 12948 - Train Loss: 0.110043, Train Acc: 0.823077 | Val Loss: 0.129767, Val Acc: 0.773196\n",
      "Epoch 12949 - Train Loss: 0.110037, Train Acc: 0.823077 | Val Loss: 0.129763, Val Acc: 0.773196\n",
      "Epoch 12950 - Train Loss: 0.110032, Train Acc: 0.823077 | Val Loss: 0.129759, Val Acc: 0.773196\n",
      "Epoch 12951 - Train Loss: 0.110027, Train Acc: 0.823077 | Val Loss: 0.129755, Val Acc: 0.773196\n",
      "Epoch 12952 - Train Loss: 0.110022, Train Acc: 0.823077 | Val Loss: 0.129752, Val Acc: 0.773196\n",
      "Epoch 12953 - Train Loss: 0.110017, Train Acc: 0.823077 | Val Loss: 0.129748, Val Acc: 0.773196\n",
      "Epoch 12954 - Train Loss: 0.110012, Train Acc: 0.823077 | Val Loss: 0.129744, Val Acc: 0.773196\n",
      "Epoch 12955 - Train Loss: 0.110007, Train Acc: 0.823077 | Val Loss: 0.129740, Val Acc: 0.773196\n",
      "Epoch 12956 - Train Loss: 0.110002, Train Acc: 0.823077 | Val Loss: 0.129736, Val Acc: 0.773196\n",
      "Epoch 12957 - Train Loss: 0.109997, Train Acc: 0.823077 | Val Loss: 0.129732, Val Acc: 0.773196\n",
      "Epoch 12958 - Train Loss: 0.109991, Train Acc: 0.823077 | Val Loss: 0.129729, Val Acc: 0.773196\n",
      "Epoch 12959 - Train Loss: 0.109986, Train Acc: 0.823077 | Val Loss: 0.129725, Val Acc: 0.773196\n",
      "Epoch 12960 - Train Loss: 0.109981, Train Acc: 0.823077 | Val Loss: 0.129721, Val Acc: 0.773196\n",
      "Epoch 12961 - Train Loss: 0.109976, Train Acc: 0.823077 | Val Loss: 0.129717, Val Acc: 0.773196\n",
      "Epoch 12962 - Train Loss: 0.109971, Train Acc: 0.823077 | Val Loss: 0.129713, Val Acc: 0.773196\n",
      "Epoch 12963 - Train Loss: 0.109966, Train Acc: 0.823077 | Val Loss: 0.129709, Val Acc: 0.773196\n",
      "Epoch 12964 - Train Loss: 0.109961, Train Acc: 0.823077 | Val Loss: 0.129706, Val Acc: 0.773196\n",
      "Epoch 12965 - Train Loss: 0.109956, Train Acc: 0.823077 | Val Loss: 0.129702, Val Acc: 0.773196\n",
      "Epoch 12966 - Train Loss: 0.109951, Train Acc: 0.823077 | Val Loss: 0.129698, Val Acc: 0.773196\n",
      "Epoch 12967 - Train Loss: 0.109946, Train Acc: 0.823077 | Val Loss: 0.129694, Val Acc: 0.773196\n",
      "Epoch 12968 - Train Loss: 0.109941, Train Acc: 0.823077 | Val Loss: 0.129690, Val Acc: 0.773196\n",
      "Epoch 12969 - Train Loss: 0.109935, Train Acc: 0.823077 | Val Loss: 0.129687, Val Acc: 0.773196\n",
      "Epoch 12970 - Train Loss: 0.109930, Train Acc: 0.823077 | Val Loss: 0.129683, Val Acc: 0.773196\n",
      "Epoch 12971 - Train Loss: 0.109925, Train Acc: 0.823077 | Val Loss: 0.129679, Val Acc: 0.773196\n",
      "Epoch 12972 - Train Loss: 0.109920, Train Acc: 0.823077 | Val Loss: 0.129675, Val Acc: 0.773196\n",
      "Epoch 12973 - Train Loss: 0.109915, Train Acc: 0.823077 | Val Loss: 0.129671, Val Acc: 0.773196\n",
      "Epoch 12974 - Train Loss: 0.109910, Train Acc: 0.823077 | Val Loss: 0.129667, Val Acc: 0.773196\n",
      "Epoch 12975 - Train Loss: 0.109905, Train Acc: 0.823077 | Val Loss: 0.129664, Val Acc: 0.773196\n",
      "Epoch 12976 - Train Loss: 0.109900, Train Acc: 0.823077 | Val Loss: 0.129660, Val Acc: 0.773196\n",
      "Epoch 12977 - Train Loss: 0.109895, Train Acc: 0.823077 | Val Loss: 0.129656, Val Acc: 0.773196\n",
      "Epoch 12978 - Train Loss: 0.109890, Train Acc: 0.823077 | Val Loss: 0.129652, Val Acc: 0.773196\n",
      "Epoch 12979 - Train Loss: 0.109885, Train Acc: 0.823077 | Val Loss: 0.129648, Val Acc: 0.773196\n",
      "Epoch 12980 - Train Loss: 0.109879, Train Acc: 0.823077 | Val Loss: 0.129645, Val Acc: 0.773196\n",
      "Epoch 12981 - Train Loss: 0.109874, Train Acc: 0.823077 | Val Loss: 0.129641, Val Acc: 0.773196\n",
      "Epoch 12982 - Train Loss: 0.109869, Train Acc: 0.823077 | Val Loss: 0.129637, Val Acc: 0.773196\n",
      "Epoch 12983 - Train Loss: 0.109864, Train Acc: 0.823077 | Val Loss: 0.129633, Val Acc: 0.773196\n",
      "Epoch 12984 - Train Loss: 0.109859, Train Acc: 0.823077 | Val Loss: 0.129629, Val Acc: 0.773196\n",
      "Epoch 12985 - Train Loss: 0.109854, Train Acc: 0.823077 | Val Loss: 0.129625, Val Acc: 0.773196\n",
      "Epoch 12986 - Train Loss: 0.109849, Train Acc: 0.823077 | Val Loss: 0.129622, Val Acc: 0.773196\n",
      "Epoch 12987 - Train Loss: 0.109844, Train Acc: 0.823077 | Val Loss: 0.129618, Val Acc: 0.773196\n",
      "Epoch 12988 - Train Loss: 0.109839, Train Acc: 0.823077 | Val Loss: 0.129614, Val Acc: 0.773196\n",
      "Epoch 12989 - Train Loss: 0.109834, Train Acc: 0.823077 | Val Loss: 0.129610, Val Acc: 0.773196\n",
      "Epoch 12990 - Train Loss: 0.109829, Train Acc: 0.823077 | Val Loss: 0.129606, Val Acc: 0.773196\n",
      "Epoch 12991 - Train Loss: 0.109824, Train Acc: 0.823077 | Val Loss: 0.129603, Val Acc: 0.773196\n",
      "Epoch 12992 - Train Loss: 0.109818, Train Acc: 0.821795 | Val Loss: 0.129599, Val Acc: 0.773196\n",
      "Epoch 12993 - Train Loss: 0.109813, Train Acc: 0.821795 | Val Loss: 0.129595, Val Acc: 0.773196\n",
      "Epoch 12994 - Train Loss: 0.109808, Train Acc: 0.821795 | Val Loss: 0.129591, Val Acc: 0.773196\n",
      "Epoch 12995 - Train Loss: 0.109803, Train Acc: 0.821795 | Val Loss: 0.129587, Val Acc: 0.773196\n",
      "Epoch 12996 - Train Loss: 0.109798, Train Acc: 0.821795 | Val Loss: 0.129584, Val Acc: 0.773196\n",
      "Epoch 12997 - Train Loss: 0.109793, Train Acc: 0.821795 | Val Loss: 0.129580, Val Acc: 0.773196\n",
      "Epoch 12998 - Train Loss: 0.109788, Train Acc: 0.821795 | Val Loss: 0.129576, Val Acc: 0.773196\n",
      "Epoch 12999 - Train Loss: 0.109783, Train Acc: 0.821795 | Val Loss: 0.129572, Val Acc: 0.773196\n",
      "Epoch 13000 - Train Loss: 0.109778, Train Acc: 0.821795 | Val Loss: 0.129568, Val Acc: 0.773196\n",
      "Epoch 13001 - Train Loss: 0.109773, Train Acc: 0.823077 | Val Loss: 0.129565, Val Acc: 0.773196\n",
      "Epoch 13002 - Train Loss: 0.109768, Train Acc: 0.823077 | Val Loss: 0.129561, Val Acc: 0.773196\n",
      "Epoch 13003 - Train Loss: 0.109763, Train Acc: 0.823077 | Val Loss: 0.129557, Val Acc: 0.773196\n",
      "Epoch 13004 - Train Loss: 0.109758, Train Acc: 0.823077 | Val Loss: 0.129553, Val Acc: 0.773196\n",
      "Epoch 13005 - Train Loss: 0.109753, Train Acc: 0.823077 | Val Loss: 0.129549, Val Acc: 0.773196\n",
      "Epoch 13006 - Train Loss: 0.109748, Train Acc: 0.823077 | Val Loss: 0.129546, Val Acc: 0.773196\n",
      "Epoch 13007 - Train Loss: 0.109742, Train Acc: 0.823077 | Val Loss: 0.129542, Val Acc: 0.773196\n",
      "Epoch 13008 - Train Loss: 0.109737, Train Acc: 0.823077 | Val Loss: 0.129538, Val Acc: 0.773196\n",
      "Epoch 13009 - Train Loss: 0.109732, Train Acc: 0.823077 | Val Loss: 0.129534, Val Acc: 0.773196\n",
      "Epoch 13010 - Train Loss: 0.109727, Train Acc: 0.823077 | Val Loss: 0.129531, Val Acc: 0.773196\n",
      "Epoch 13011 - Train Loss: 0.109722, Train Acc: 0.823077 | Val Loss: 0.129527, Val Acc: 0.773196\n",
      "Epoch 13012 - Train Loss: 0.109717, Train Acc: 0.823077 | Val Loss: 0.129523, Val Acc: 0.773196\n",
      "Epoch 13013 - Train Loss: 0.109712, Train Acc: 0.823077 | Val Loss: 0.129519, Val Acc: 0.773196\n",
      "Epoch 13014 - Train Loss: 0.109707, Train Acc: 0.823077 | Val Loss: 0.129515, Val Acc: 0.773196\n",
      "Epoch 13015 - Train Loss: 0.109702, Train Acc: 0.823077 | Val Loss: 0.129512, Val Acc: 0.773196\n",
      "Epoch 13016 - Train Loss: 0.109697, Train Acc: 0.823077 | Val Loss: 0.129508, Val Acc: 0.773196\n",
      "Epoch 13017 - Train Loss: 0.109692, Train Acc: 0.823077 | Val Loss: 0.129504, Val Acc: 0.773196\n",
      "Epoch 13018 - Train Loss: 0.109687, Train Acc: 0.823077 | Val Loss: 0.129500, Val Acc: 0.773196\n",
      "Epoch 13019 - Train Loss: 0.109682, Train Acc: 0.823077 | Val Loss: 0.129496, Val Acc: 0.773196\n",
      "Epoch 13020 - Train Loss: 0.109677, Train Acc: 0.823077 | Val Loss: 0.129493, Val Acc: 0.773196\n",
      "Epoch 13021 - Train Loss: 0.109672, Train Acc: 0.823077 | Val Loss: 0.129489, Val Acc: 0.773196\n",
      "Epoch 13022 - Train Loss: 0.109667, Train Acc: 0.823077 | Val Loss: 0.129485, Val Acc: 0.773196\n",
      "Epoch 13023 - Train Loss: 0.109662, Train Acc: 0.823077 | Val Loss: 0.129481, Val Acc: 0.773196\n",
      "Epoch 13024 - Train Loss: 0.109657, Train Acc: 0.823077 | Val Loss: 0.129478, Val Acc: 0.773196\n",
      "Epoch 13025 - Train Loss: 0.109651, Train Acc: 0.823077 | Val Loss: 0.129474, Val Acc: 0.773196\n",
      "Epoch 13026 - Train Loss: 0.109646, Train Acc: 0.823077 | Val Loss: 0.129470, Val Acc: 0.773196\n",
      "Epoch 13027 - Train Loss: 0.109641, Train Acc: 0.823077 | Val Loss: 0.129466, Val Acc: 0.773196\n",
      "Epoch 13028 - Train Loss: 0.109636, Train Acc: 0.823077 | Val Loss: 0.129462, Val Acc: 0.773196\n",
      "Epoch 13029 - Train Loss: 0.109631, Train Acc: 0.823077 | Val Loss: 0.129459, Val Acc: 0.773196\n",
      "Epoch 13030 - Train Loss: 0.109626, Train Acc: 0.823077 | Val Loss: 0.129455, Val Acc: 0.773196\n",
      "Epoch 13031 - Train Loss: 0.109621, Train Acc: 0.823077 | Val Loss: 0.129451, Val Acc: 0.773196\n",
      "Epoch 13032 - Train Loss: 0.109616, Train Acc: 0.823077 | Val Loss: 0.129447, Val Acc: 0.773196\n",
      "Epoch 13033 - Train Loss: 0.109611, Train Acc: 0.823077 | Val Loss: 0.129444, Val Acc: 0.773196\n",
      "Epoch 13034 - Train Loss: 0.109606, Train Acc: 0.823077 | Val Loss: 0.129440, Val Acc: 0.773196\n",
      "Epoch 13035 - Train Loss: 0.109601, Train Acc: 0.823077 | Val Loss: 0.129436, Val Acc: 0.773196\n",
      "Epoch 13036 - Train Loss: 0.109596, Train Acc: 0.823077 | Val Loss: 0.129432, Val Acc: 0.773196\n",
      "Epoch 13037 - Train Loss: 0.109591, Train Acc: 0.823077 | Val Loss: 0.129429, Val Acc: 0.773196\n",
      "Epoch 13038 - Train Loss: 0.109586, Train Acc: 0.823077 | Val Loss: 0.129425, Val Acc: 0.773196\n",
      "Epoch 13039 - Train Loss: 0.109581, Train Acc: 0.823077 | Val Loss: 0.129421, Val Acc: 0.773196\n",
      "Epoch 13040 - Train Loss: 0.109576, Train Acc: 0.823077 | Val Loss: 0.129417, Val Acc: 0.773196\n",
      "Epoch 13041 - Train Loss: 0.109571, Train Acc: 0.823077 | Val Loss: 0.129413, Val Acc: 0.773196\n",
      "Epoch 13042 - Train Loss: 0.109566, Train Acc: 0.823077 | Val Loss: 0.129410, Val Acc: 0.773196\n",
      "Epoch 13043 - Train Loss: 0.109561, Train Acc: 0.823077 | Val Loss: 0.129406, Val Acc: 0.773196\n",
      "Epoch 13044 - Train Loss: 0.109556, Train Acc: 0.823077 | Val Loss: 0.129402, Val Acc: 0.773196\n",
      "Epoch 13045 - Train Loss: 0.109551, Train Acc: 0.823077 | Val Loss: 0.129398, Val Acc: 0.773196\n",
      "Epoch 13046 - Train Loss: 0.109546, Train Acc: 0.823077 | Val Loss: 0.129395, Val Acc: 0.773196\n",
      "Epoch 13047 - Train Loss: 0.109541, Train Acc: 0.823077 | Val Loss: 0.129391, Val Acc: 0.773196\n",
      "Epoch 13048 - Train Loss: 0.109536, Train Acc: 0.823077 | Val Loss: 0.129387, Val Acc: 0.773196\n",
      "Epoch 13049 - Train Loss: 0.109531, Train Acc: 0.823077 | Val Loss: 0.129383, Val Acc: 0.773196\n",
      "Epoch 13050 - Train Loss: 0.109526, Train Acc: 0.823077 | Val Loss: 0.129380, Val Acc: 0.773196\n",
      "Epoch 13051 - Train Loss: 0.109521, Train Acc: 0.823077 | Val Loss: 0.129376, Val Acc: 0.773196\n",
      "Epoch 13052 - Train Loss: 0.109515, Train Acc: 0.823077 | Val Loss: 0.129372, Val Acc: 0.773196\n",
      "Epoch 13053 - Train Loss: 0.109510, Train Acc: 0.823077 | Val Loss: 0.129368, Val Acc: 0.773196\n",
      "Epoch 13054 - Train Loss: 0.109505, Train Acc: 0.823077 | Val Loss: 0.129365, Val Acc: 0.773196\n",
      "Epoch 13055 - Train Loss: 0.109500, Train Acc: 0.823077 | Val Loss: 0.129361, Val Acc: 0.773196\n",
      "Epoch 13056 - Train Loss: 0.109495, Train Acc: 0.823077 | Val Loss: 0.129357, Val Acc: 0.773196\n",
      "Epoch 13057 - Train Loss: 0.109490, Train Acc: 0.823077 | Val Loss: 0.129353, Val Acc: 0.773196\n",
      "Epoch 13058 - Train Loss: 0.109485, Train Acc: 0.823077 | Val Loss: 0.129350, Val Acc: 0.773196\n",
      "Epoch 13059 - Train Loss: 0.109480, Train Acc: 0.823077 | Val Loss: 0.129346, Val Acc: 0.773196\n",
      "Epoch 13060 - Train Loss: 0.109475, Train Acc: 0.823077 | Val Loss: 0.129342, Val Acc: 0.773196\n",
      "Epoch 13061 - Train Loss: 0.109470, Train Acc: 0.823077 | Val Loss: 0.129338, Val Acc: 0.773196\n",
      "Epoch 13062 - Train Loss: 0.109465, Train Acc: 0.823077 | Val Loss: 0.129335, Val Acc: 0.773196\n",
      "Epoch 13063 - Train Loss: 0.109460, Train Acc: 0.823077 | Val Loss: 0.129331, Val Acc: 0.773196\n",
      "Epoch 13064 - Train Loss: 0.109455, Train Acc: 0.823077 | Val Loss: 0.129327, Val Acc: 0.773196\n",
      "Epoch 13065 - Train Loss: 0.109450, Train Acc: 0.823077 | Val Loss: 0.129323, Val Acc: 0.773196\n",
      "Epoch 13066 - Train Loss: 0.109445, Train Acc: 0.823077 | Val Loss: 0.129320, Val Acc: 0.773196\n",
      "Epoch 13067 - Train Loss: 0.109440, Train Acc: 0.823077 | Val Loss: 0.129316, Val Acc: 0.773196\n",
      "Epoch 13068 - Train Loss: 0.109435, Train Acc: 0.823077 | Val Loss: 0.129312, Val Acc: 0.773196\n",
      "Epoch 13069 - Train Loss: 0.109430, Train Acc: 0.823077 | Val Loss: 0.129308, Val Acc: 0.773196\n",
      "Epoch 13070 - Train Loss: 0.109425, Train Acc: 0.823077 | Val Loss: 0.129305, Val Acc: 0.773196\n",
      "Epoch 13071 - Train Loss: 0.109420, Train Acc: 0.823077 | Val Loss: 0.129301, Val Acc: 0.773196\n",
      "Epoch 13072 - Train Loss: 0.109415, Train Acc: 0.823077 | Val Loss: 0.129297, Val Acc: 0.773196\n",
      "Epoch 13073 - Train Loss: 0.109410, Train Acc: 0.823077 | Val Loss: 0.129293, Val Acc: 0.773196\n",
      "Epoch 13074 - Train Loss: 0.109405, Train Acc: 0.823077 | Val Loss: 0.129290, Val Acc: 0.773196\n",
      "Epoch 13075 - Train Loss: 0.109400, Train Acc: 0.823077 | Val Loss: 0.129286, Val Acc: 0.773196\n",
      "Epoch 13076 - Train Loss: 0.109395, Train Acc: 0.823077 | Val Loss: 0.129282, Val Acc: 0.773196\n",
      "Epoch 13077 - Train Loss: 0.109390, Train Acc: 0.823077 | Val Loss: 0.129279, Val Acc: 0.773196\n",
      "Epoch 13078 - Train Loss: 0.109385, Train Acc: 0.823077 | Val Loss: 0.129275, Val Acc: 0.773196\n",
      "Epoch 13079 - Train Loss: 0.109380, Train Acc: 0.823077 | Val Loss: 0.129271, Val Acc: 0.773196\n",
      "Epoch 13080 - Train Loss: 0.109375, Train Acc: 0.823077 | Val Loss: 0.129267, Val Acc: 0.773196\n",
      "Epoch 13081 - Train Loss: 0.109370, Train Acc: 0.823077 | Val Loss: 0.129264, Val Acc: 0.773196\n",
      "Epoch 13082 - Train Loss: 0.109365, Train Acc: 0.823077 | Val Loss: 0.129260, Val Acc: 0.773196\n",
      "Epoch 13083 - Train Loss: 0.109360, Train Acc: 0.823077 | Val Loss: 0.129256, Val Acc: 0.773196\n",
      "Epoch 13084 - Train Loss: 0.109355, Train Acc: 0.823077 | Val Loss: 0.129252, Val Acc: 0.773196\n",
      "Epoch 13085 - Train Loss: 0.109350, Train Acc: 0.823077 | Val Loss: 0.129249, Val Acc: 0.773196\n",
      "Epoch 13086 - Train Loss: 0.109345, Train Acc: 0.823077 | Val Loss: 0.129245, Val Acc: 0.773196\n",
      "Epoch 13087 - Train Loss: 0.109340, Train Acc: 0.823077 | Val Loss: 0.129241, Val Acc: 0.773196\n",
      "Epoch 13088 - Train Loss: 0.109335, Train Acc: 0.823077 | Val Loss: 0.129237, Val Acc: 0.773196\n",
      "Epoch 13089 - Train Loss: 0.109330, Train Acc: 0.823077 | Val Loss: 0.129234, Val Acc: 0.773196\n",
      "Epoch 13090 - Train Loss: 0.109325, Train Acc: 0.823077 | Val Loss: 0.129230, Val Acc: 0.773196\n",
      "Epoch 13091 - Train Loss: 0.109320, Train Acc: 0.823077 | Val Loss: 0.129226, Val Acc: 0.773196\n",
      "Epoch 13092 - Train Loss: 0.109315, Train Acc: 0.823077 | Val Loss: 0.129223, Val Acc: 0.773196\n",
      "Epoch 13093 - Train Loss: 0.109310, Train Acc: 0.823077 | Val Loss: 0.129219, Val Acc: 0.773196\n",
      "Epoch 13094 - Train Loss: 0.109305, Train Acc: 0.823077 | Val Loss: 0.129215, Val Acc: 0.773196\n",
      "Epoch 13095 - Train Loss: 0.109300, Train Acc: 0.823077 | Val Loss: 0.129211, Val Acc: 0.773196\n",
      "Epoch 13096 - Train Loss: 0.109295, Train Acc: 0.823077 | Val Loss: 0.129208, Val Acc: 0.773196\n",
      "Epoch 13097 - Train Loss: 0.109290, Train Acc: 0.823077 | Val Loss: 0.129204, Val Acc: 0.773196\n",
      "Epoch 13098 - Train Loss: 0.109285, Train Acc: 0.823077 | Val Loss: 0.129200, Val Acc: 0.773196\n",
      "Epoch 13099 - Train Loss: 0.109280, Train Acc: 0.821795 | Val Loss: 0.129197, Val Acc: 0.773196\n",
      "Epoch 13100 - Train Loss: 0.109275, Train Acc: 0.821795 | Val Loss: 0.129193, Val Acc: 0.773196\n",
      "Epoch 13101 - Train Loss: 0.109270, Train Acc: 0.821795 | Val Loss: 0.129189, Val Acc: 0.773196\n",
      "Epoch 13102 - Train Loss: 0.109265, Train Acc: 0.821795 | Val Loss: 0.129185, Val Acc: 0.773196\n",
      "Epoch 13103 - Train Loss: 0.109260, Train Acc: 0.821795 | Val Loss: 0.129182, Val Acc: 0.773196\n",
      "Epoch 13104 - Train Loss: 0.109255, Train Acc: 0.821795 | Val Loss: 0.129178, Val Acc: 0.773196\n",
      "Epoch 13105 - Train Loss: 0.109250, Train Acc: 0.821795 | Val Loss: 0.129174, Val Acc: 0.773196\n",
      "Epoch 13106 - Train Loss: 0.109245, Train Acc: 0.821795 | Val Loss: 0.129171, Val Acc: 0.773196\n",
      "Epoch 13107 - Train Loss: 0.109240, Train Acc: 0.821795 | Val Loss: 0.129167, Val Acc: 0.773196\n",
      "Epoch 13108 - Train Loss: 0.109235, Train Acc: 0.821795 | Val Loss: 0.129163, Val Acc: 0.773196\n",
      "Epoch 13109 - Train Loss: 0.109230, Train Acc: 0.821795 | Val Loss: 0.129159, Val Acc: 0.773196\n",
      "Epoch 13110 - Train Loss: 0.109225, Train Acc: 0.821795 | Val Loss: 0.129156, Val Acc: 0.773196\n",
      "Epoch 13111 - Train Loss: 0.109220, Train Acc: 0.821795 | Val Loss: 0.129152, Val Acc: 0.773196\n",
      "Epoch 13112 - Train Loss: 0.109215, Train Acc: 0.821795 | Val Loss: 0.129148, Val Acc: 0.773196\n",
      "Epoch 13113 - Train Loss: 0.109210, Train Acc: 0.821795 | Val Loss: 0.129145, Val Acc: 0.773196\n",
      "Epoch 13114 - Train Loss: 0.109205, Train Acc: 0.821795 | Val Loss: 0.129141, Val Acc: 0.773196\n",
      "Epoch 13115 - Train Loss: 0.109200, Train Acc: 0.821795 | Val Loss: 0.129137, Val Acc: 0.773196\n",
      "Epoch 13116 - Train Loss: 0.109195, Train Acc: 0.821795 | Val Loss: 0.129133, Val Acc: 0.773196\n",
      "Epoch 13117 - Train Loss: 0.109190, Train Acc: 0.821795 | Val Loss: 0.129130, Val Acc: 0.773196\n",
      "Epoch 13118 - Train Loss: 0.109185, Train Acc: 0.821795 | Val Loss: 0.129126, Val Acc: 0.773196\n",
      "Epoch 13119 - Train Loss: 0.109180, Train Acc: 0.821795 | Val Loss: 0.129122, Val Acc: 0.773196\n",
      "Epoch 13120 - Train Loss: 0.109175, Train Acc: 0.821795 | Val Loss: 0.129119, Val Acc: 0.773196\n",
      "Epoch 13121 - Train Loss: 0.109171, Train Acc: 0.821795 | Val Loss: 0.129115, Val Acc: 0.773196\n",
      "Epoch 13122 - Train Loss: 0.109166, Train Acc: 0.821795 | Val Loss: 0.129111, Val Acc: 0.773196\n",
      "Epoch 13123 - Train Loss: 0.109161, Train Acc: 0.821795 | Val Loss: 0.129108, Val Acc: 0.773196\n",
      "Epoch 13124 - Train Loss: 0.109156, Train Acc: 0.821795 | Val Loss: 0.129104, Val Acc: 0.773196\n",
      "Epoch 13125 - Train Loss: 0.109151, Train Acc: 0.821795 | Val Loss: 0.129100, Val Acc: 0.773196\n",
      "Epoch 13126 - Train Loss: 0.109146, Train Acc: 0.821795 | Val Loss: 0.129096, Val Acc: 0.773196\n",
      "Epoch 13127 - Train Loss: 0.109141, Train Acc: 0.821795 | Val Loss: 0.129093, Val Acc: 0.773196\n",
      "Epoch 13128 - Train Loss: 0.109136, Train Acc: 0.821795 | Val Loss: 0.129089, Val Acc: 0.773196\n",
      "Epoch 13129 - Train Loss: 0.109131, Train Acc: 0.821795 | Val Loss: 0.129085, Val Acc: 0.773196\n",
      "Epoch 13130 - Train Loss: 0.109126, Train Acc: 0.821795 | Val Loss: 0.129082, Val Acc: 0.773196\n",
      "Epoch 13131 - Train Loss: 0.109121, Train Acc: 0.821795 | Val Loss: 0.129078, Val Acc: 0.773196\n",
      "Epoch 13132 - Train Loss: 0.109116, Train Acc: 0.821795 | Val Loss: 0.129074, Val Acc: 0.773196\n",
      "Epoch 13133 - Train Loss: 0.109111, Train Acc: 0.821795 | Val Loss: 0.129071, Val Acc: 0.773196\n",
      "Epoch 13134 - Train Loss: 0.109106, Train Acc: 0.821795 | Val Loss: 0.129067, Val Acc: 0.773196\n",
      "Epoch 13135 - Train Loss: 0.109101, Train Acc: 0.821795 | Val Loss: 0.129063, Val Acc: 0.773196\n",
      "Epoch 13136 - Train Loss: 0.109096, Train Acc: 0.821795 | Val Loss: 0.129060, Val Acc: 0.773196\n",
      "Epoch 13137 - Train Loss: 0.109091, Train Acc: 0.821795 | Val Loss: 0.129056, Val Acc: 0.773196\n",
      "Epoch 13138 - Train Loss: 0.109086, Train Acc: 0.821795 | Val Loss: 0.129052, Val Acc: 0.773196\n",
      "Epoch 13139 - Train Loss: 0.109081, Train Acc: 0.821795 | Val Loss: 0.129048, Val Acc: 0.773196\n",
      "Epoch 13140 - Train Loss: 0.109076, Train Acc: 0.821795 | Val Loss: 0.129045, Val Acc: 0.773196\n",
      "Epoch 13141 - Train Loss: 0.109071, Train Acc: 0.821795 | Val Loss: 0.129041, Val Acc: 0.773196\n",
      "Epoch 13142 - Train Loss: 0.109066, Train Acc: 0.821795 | Val Loss: 0.129037, Val Acc: 0.773196\n",
      "Epoch 13143 - Train Loss: 0.109061, Train Acc: 0.821795 | Val Loss: 0.129034, Val Acc: 0.773196\n",
      "Epoch 13144 - Train Loss: 0.109056, Train Acc: 0.821795 | Val Loss: 0.129030, Val Acc: 0.773196\n",
      "Epoch 13145 - Train Loss: 0.109051, Train Acc: 0.821795 | Val Loss: 0.129026, Val Acc: 0.773196\n",
      "Epoch 13146 - Train Loss: 0.109046, Train Acc: 0.821795 | Val Loss: 0.129023, Val Acc: 0.773196\n",
      "Epoch 13147 - Train Loss: 0.109041, Train Acc: 0.821795 | Val Loss: 0.129019, Val Acc: 0.773196\n",
      "Epoch 13148 - Train Loss: 0.109037, Train Acc: 0.821795 | Val Loss: 0.129015, Val Acc: 0.773196\n",
      "Epoch 13149 - Train Loss: 0.109032, Train Acc: 0.821795 | Val Loss: 0.129012, Val Acc: 0.773196\n",
      "Epoch 13150 - Train Loss: 0.109027, Train Acc: 0.821795 | Val Loss: 0.129008, Val Acc: 0.773196\n",
      "Epoch 13151 - Train Loss: 0.109022, Train Acc: 0.821795 | Val Loss: 0.129004, Val Acc: 0.773196\n",
      "Epoch 13152 - Train Loss: 0.109017, Train Acc: 0.821795 | Val Loss: 0.129001, Val Acc: 0.773196\n",
      "Epoch 13153 - Train Loss: 0.109012, Train Acc: 0.821795 | Val Loss: 0.128997, Val Acc: 0.773196\n",
      "Epoch 13154 - Train Loss: 0.109007, Train Acc: 0.821795 | Val Loss: 0.128993, Val Acc: 0.773196\n",
      "Epoch 13155 - Train Loss: 0.109002, Train Acc: 0.821795 | Val Loss: 0.128990, Val Acc: 0.773196\n",
      "Epoch 13156 - Train Loss: 0.108997, Train Acc: 0.821795 | Val Loss: 0.128986, Val Acc: 0.773196\n",
      "Epoch 13157 - Train Loss: 0.108992, Train Acc: 0.821795 | Val Loss: 0.128982, Val Acc: 0.773196\n",
      "Epoch 13158 - Train Loss: 0.108987, Train Acc: 0.821795 | Val Loss: 0.128979, Val Acc: 0.773196\n",
      "Epoch 13159 - Train Loss: 0.108982, Train Acc: 0.821795 | Val Loss: 0.128975, Val Acc: 0.773196\n",
      "Epoch 13160 - Train Loss: 0.108977, Train Acc: 0.821795 | Val Loss: 0.128971, Val Acc: 0.773196\n",
      "Epoch 13161 - Train Loss: 0.108972, Train Acc: 0.821795 | Val Loss: 0.128968, Val Acc: 0.773196\n",
      "Epoch 13162 - Train Loss: 0.108967, Train Acc: 0.821795 | Val Loss: 0.128964, Val Acc: 0.773196\n",
      "Epoch 13163 - Train Loss: 0.108962, Train Acc: 0.821795 | Val Loss: 0.128960, Val Acc: 0.773196\n",
      "Epoch 13164 - Train Loss: 0.108957, Train Acc: 0.821795 | Val Loss: 0.128957, Val Acc: 0.773196\n",
      "Epoch 13165 - Train Loss: 0.108952, Train Acc: 0.821795 | Val Loss: 0.128953, Val Acc: 0.773196\n",
      "Epoch 13166 - Train Loss: 0.108948, Train Acc: 0.821795 | Val Loss: 0.128949, Val Acc: 0.773196\n",
      "Epoch 13167 - Train Loss: 0.108943, Train Acc: 0.821795 | Val Loss: 0.128946, Val Acc: 0.773196\n",
      "Epoch 13168 - Train Loss: 0.108938, Train Acc: 0.821795 | Val Loss: 0.128942, Val Acc: 0.773196\n",
      "Epoch 13169 - Train Loss: 0.108933, Train Acc: 0.821795 | Val Loss: 0.128938, Val Acc: 0.773196\n",
      "Epoch 13170 - Train Loss: 0.108928, Train Acc: 0.821795 | Val Loss: 0.128935, Val Acc: 0.773196\n",
      "Epoch 13171 - Train Loss: 0.108923, Train Acc: 0.821795 | Val Loss: 0.128931, Val Acc: 0.773196\n",
      "Epoch 13172 - Train Loss: 0.108918, Train Acc: 0.821795 | Val Loss: 0.128927, Val Acc: 0.773196\n",
      "Epoch 13173 - Train Loss: 0.108913, Train Acc: 0.821795 | Val Loss: 0.128924, Val Acc: 0.773196\n",
      "Epoch 13174 - Train Loss: 0.108908, Train Acc: 0.821795 | Val Loss: 0.128920, Val Acc: 0.773196\n",
      "Epoch 13175 - Train Loss: 0.108903, Train Acc: 0.821795 | Val Loss: 0.128916, Val Acc: 0.773196\n",
      "Epoch 13176 - Train Loss: 0.108898, Train Acc: 0.821795 | Val Loss: 0.128913, Val Acc: 0.773196\n",
      "Epoch 13177 - Train Loss: 0.108893, Train Acc: 0.821795 | Val Loss: 0.128909, Val Acc: 0.773196\n",
      "Epoch 13178 - Train Loss: 0.108888, Train Acc: 0.821795 | Val Loss: 0.128905, Val Acc: 0.773196\n",
      "Epoch 13179 - Train Loss: 0.108883, Train Acc: 0.821795 | Val Loss: 0.128902, Val Acc: 0.773196\n",
      "Epoch 13180 - Train Loss: 0.108878, Train Acc: 0.821795 | Val Loss: 0.128898, Val Acc: 0.773196\n",
      "Epoch 13181 - Train Loss: 0.108874, Train Acc: 0.821795 | Val Loss: 0.128894, Val Acc: 0.773196\n",
      "Epoch 13182 - Train Loss: 0.108869, Train Acc: 0.821795 | Val Loss: 0.128891, Val Acc: 0.773196\n",
      "Epoch 13183 - Train Loss: 0.108864, Train Acc: 0.821795 | Val Loss: 0.128887, Val Acc: 0.773196\n",
      "Epoch 13184 - Train Loss: 0.108859, Train Acc: 0.821795 | Val Loss: 0.128883, Val Acc: 0.773196\n",
      "Epoch 13185 - Train Loss: 0.108854, Train Acc: 0.821795 | Val Loss: 0.128880, Val Acc: 0.773196\n",
      "Epoch 13186 - Train Loss: 0.108849, Train Acc: 0.821795 | Val Loss: 0.128876, Val Acc: 0.773196\n",
      "Epoch 13187 - Train Loss: 0.108844, Train Acc: 0.821795 | Val Loss: 0.128872, Val Acc: 0.773196\n",
      "Epoch 13188 - Train Loss: 0.108839, Train Acc: 0.821795 | Val Loss: 0.128869, Val Acc: 0.773196\n",
      "Epoch 13189 - Train Loss: 0.108834, Train Acc: 0.821795 | Val Loss: 0.128865, Val Acc: 0.773196\n",
      "Epoch 13190 - Train Loss: 0.108829, Train Acc: 0.821795 | Val Loss: 0.128861, Val Acc: 0.773196\n",
      "Epoch 13191 - Train Loss: 0.108824, Train Acc: 0.821795 | Val Loss: 0.128858, Val Acc: 0.773196\n",
      "Epoch 13192 - Train Loss: 0.108819, Train Acc: 0.821795 | Val Loss: 0.128854, Val Acc: 0.773196\n",
      "Epoch 13193 - Train Loss: 0.108814, Train Acc: 0.821795 | Val Loss: 0.128851, Val Acc: 0.773196\n",
      "Epoch 13194 - Train Loss: 0.108810, Train Acc: 0.821795 | Val Loss: 0.128847, Val Acc: 0.773196\n",
      "Epoch 13195 - Train Loss: 0.108805, Train Acc: 0.821795 | Val Loss: 0.128843, Val Acc: 0.773196\n",
      "Epoch 13196 - Train Loss: 0.108800, Train Acc: 0.821795 | Val Loss: 0.128840, Val Acc: 0.773196\n",
      "Epoch 13197 - Train Loss: 0.108795, Train Acc: 0.821795 | Val Loss: 0.128836, Val Acc: 0.773196\n",
      "Epoch 13198 - Train Loss: 0.108790, Train Acc: 0.821795 | Val Loss: 0.128832, Val Acc: 0.773196\n",
      "Epoch 13199 - Train Loss: 0.108785, Train Acc: 0.821795 | Val Loss: 0.128829, Val Acc: 0.773196\n",
      "Epoch 13200 - Train Loss: 0.108780, Train Acc: 0.821795 | Val Loss: 0.128825, Val Acc: 0.773196\n",
      "Epoch 13201 - Train Loss: 0.108775, Train Acc: 0.821795 | Val Loss: 0.128821, Val Acc: 0.773196\n",
      "Epoch 13202 - Train Loss: 0.108770, Train Acc: 0.821795 | Val Loss: 0.128818, Val Acc: 0.773196\n",
      "Epoch 13203 - Train Loss: 0.108765, Train Acc: 0.821795 | Val Loss: 0.128814, Val Acc: 0.773196\n",
      "Epoch 13204 - Train Loss: 0.108760, Train Acc: 0.821795 | Val Loss: 0.128810, Val Acc: 0.773196\n",
      "Epoch 13205 - Train Loss: 0.108756, Train Acc: 0.821795 | Val Loss: 0.128807, Val Acc: 0.773196\n",
      "Epoch 13206 - Train Loss: 0.108751, Train Acc: 0.821795 | Val Loss: 0.128803, Val Acc: 0.773196\n",
      "Epoch 13207 - Train Loss: 0.108746, Train Acc: 0.821795 | Val Loss: 0.128800, Val Acc: 0.773196\n",
      "Epoch 13208 - Train Loss: 0.108741, Train Acc: 0.821795 | Val Loss: 0.128796, Val Acc: 0.773196\n",
      "Epoch 13209 - Train Loss: 0.108736, Train Acc: 0.821795 | Val Loss: 0.128792, Val Acc: 0.773196\n",
      "Epoch 13210 - Train Loss: 0.108731, Train Acc: 0.821795 | Val Loss: 0.128789, Val Acc: 0.773196\n",
      "Epoch 13211 - Train Loss: 0.108726, Train Acc: 0.821795 | Val Loss: 0.128785, Val Acc: 0.773196\n",
      "Epoch 13212 - Train Loss: 0.108721, Train Acc: 0.821795 | Val Loss: 0.128781, Val Acc: 0.773196\n",
      "Epoch 13213 - Train Loss: 0.108716, Train Acc: 0.821795 | Val Loss: 0.128778, Val Acc: 0.773196\n",
      "Epoch 13214 - Train Loss: 0.108711, Train Acc: 0.821795 | Val Loss: 0.128774, Val Acc: 0.773196\n",
      "Epoch 13215 - Train Loss: 0.108706, Train Acc: 0.821795 | Val Loss: 0.128770, Val Acc: 0.773196\n",
      "Epoch 13216 - Train Loss: 0.108702, Train Acc: 0.821795 | Val Loss: 0.128767, Val Acc: 0.773196\n",
      "Epoch 13217 - Train Loss: 0.108697, Train Acc: 0.821795 | Val Loss: 0.128763, Val Acc: 0.773196\n",
      "Epoch 13218 - Train Loss: 0.108692, Train Acc: 0.821795 | Val Loss: 0.128760, Val Acc: 0.773196\n",
      "Epoch 13219 - Train Loss: 0.108687, Train Acc: 0.821795 | Val Loss: 0.128756, Val Acc: 0.773196\n",
      "Epoch 13220 - Train Loss: 0.108682, Train Acc: 0.821795 | Val Loss: 0.128752, Val Acc: 0.773196\n",
      "Epoch 13221 - Train Loss: 0.108677, Train Acc: 0.821795 | Val Loss: 0.128749, Val Acc: 0.773196\n",
      "Epoch 13222 - Train Loss: 0.108672, Train Acc: 0.821795 | Val Loss: 0.128745, Val Acc: 0.773196\n",
      "Epoch 13223 - Train Loss: 0.108667, Train Acc: 0.821795 | Val Loss: 0.128741, Val Acc: 0.773196\n",
      "Epoch 13224 - Train Loss: 0.108662, Train Acc: 0.821795 | Val Loss: 0.128738, Val Acc: 0.773196\n",
      "Epoch 13225 - Train Loss: 0.108658, Train Acc: 0.821795 | Val Loss: 0.128734, Val Acc: 0.773196\n",
      "Epoch 13226 - Train Loss: 0.108653, Train Acc: 0.821795 | Val Loss: 0.128731, Val Acc: 0.773196\n",
      "Epoch 13227 - Train Loss: 0.108648, Train Acc: 0.821795 | Val Loss: 0.128727, Val Acc: 0.773196\n",
      "Epoch 13228 - Train Loss: 0.108643, Train Acc: 0.821795 | Val Loss: 0.128723, Val Acc: 0.773196\n",
      "Epoch 13229 - Train Loss: 0.108638, Train Acc: 0.821795 | Val Loss: 0.128720, Val Acc: 0.773196\n",
      "Epoch 13230 - Train Loss: 0.108633, Train Acc: 0.821795 | Val Loss: 0.128716, Val Acc: 0.773196\n",
      "Epoch 13231 - Train Loss: 0.108628, Train Acc: 0.821795 | Val Loss: 0.128713, Val Acc: 0.773196\n",
      "Epoch 13232 - Train Loss: 0.108623, Train Acc: 0.821795 | Val Loss: 0.128709, Val Acc: 0.773196\n",
      "Epoch 13233 - Train Loss: 0.108618, Train Acc: 0.821795 | Val Loss: 0.128705, Val Acc: 0.773196\n",
      "Epoch 13234 - Train Loss: 0.108614, Train Acc: 0.821795 | Val Loss: 0.128702, Val Acc: 0.773196\n",
      "Epoch 13235 - Train Loss: 0.108609, Train Acc: 0.821795 | Val Loss: 0.128698, Val Acc: 0.773196\n",
      "Epoch 13236 - Train Loss: 0.108604, Train Acc: 0.823077 | Val Loss: 0.128694, Val Acc: 0.773196\n",
      "Epoch 13237 - Train Loss: 0.108599, Train Acc: 0.823077 | Val Loss: 0.128691, Val Acc: 0.773196\n",
      "Epoch 13238 - Train Loss: 0.108594, Train Acc: 0.823077 | Val Loss: 0.128687, Val Acc: 0.773196\n",
      "Epoch 13239 - Train Loss: 0.108589, Train Acc: 0.823077 | Val Loss: 0.128684, Val Acc: 0.773196\n",
      "Epoch 13240 - Train Loss: 0.108584, Train Acc: 0.823077 | Val Loss: 0.128680, Val Acc: 0.773196\n",
      "Epoch 13241 - Train Loss: 0.108579, Train Acc: 0.823077 | Val Loss: 0.128676, Val Acc: 0.773196\n",
      "Epoch 13242 - Train Loss: 0.108574, Train Acc: 0.823077 | Val Loss: 0.128673, Val Acc: 0.773196\n",
      "Epoch 13243 - Train Loss: 0.108570, Train Acc: 0.823077 | Val Loss: 0.128669, Val Acc: 0.773196\n",
      "Epoch 13244 - Train Loss: 0.108565, Train Acc: 0.823077 | Val Loss: 0.128666, Val Acc: 0.773196\n",
      "Epoch 13245 - Train Loss: 0.108560, Train Acc: 0.823077 | Val Loss: 0.128662, Val Acc: 0.773196\n",
      "Epoch 13246 - Train Loss: 0.108555, Train Acc: 0.823077 | Val Loss: 0.128658, Val Acc: 0.773196\n",
      "Epoch 13247 - Train Loss: 0.108550, Train Acc: 0.823077 | Val Loss: 0.128655, Val Acc: 0.773196\n",
      "Epoch 13248 - Train Loss: 0.108545, Train Acc: 0.823077 | Val Loss: 0.128651, Val Acc: 0.773196\n",
      "Epoch 13249 - Train Loss: 0.108540, Train Acc: 0.823077 | Val Loss: 0.128648, Val Acc: 0.773196\n",
      "Epoch 13250 - Train Loss: 0.108535, Train Acc: 0.823077 | Val Loss: 0.128644, Val Acc: 0.773196\n",
      "Epoch 13251 - Train Loss: 0.108531, Train Acc: 0.823077 | Val Loss: 0.128640, Val Acc: 0.773196\n",
      "Epoch 13252 - Train Loss: 0.108526, Train Acc: 0.823077 | Val Loss: 0.128637, Val Acc: 0.773196\n",
      "Epoch 13253 - Train Loss: 0.108521, Train Acc: 0.823077 | Val Loss: 0.128633, Val Acc: 0.773196\n",
      "Epoch 13254 - Train Loss: 0.108516, Train Acc: 0.823077 | Val Loss: 0.128630, Val Acc: 0.773196\n",
      "Epoch 13255 - Train Loss: 0.108511, Train Acc: 0.823077 | Val Loss: 0.128626, Val Acc: 0.773196\n",
      "Epoch 13256 - Train Loss: 0.108506, Train Acc: 0.823077 | Val Loss: 0.128622, Val Acc: 0.773196\n",
      "Epoch 13257 - Train Loss: 0.108501, Train Acc: 0.823077 | Val Loss: 0.128619, Val Acc: 0.773196\n",
      "Epoch 13258 - Train Loss: 0.108496, Train Acc: 0.823077 | Val Loss: 0.128615, Val Acc: 0.773196\n",
      "Epoch 13259 - Train Loss: 0.108492, Train Acc: 0.823077 | Val Loss: 0.128612, Val Acc: 0.773196\n",
      "Epoch 13260 - Train Loss: 0.108487, Train Acc: 0.823077 | Val Loss: 0.128608, Val Acc: 0.773196\n",
      "Epoch 13261 - Train Loss: 0.108482, Train Acc: 0.823077 | Val Loss: 0.128604, Val Acc: 0.773196\n",
      "Epoch 13262 - Train Loss: 0.108477, Train Acc: 0.823077 | Val Loss: 0.128601, Val Acc: 0.773196\n",
      "Epoch 13263 - Train Loss: 0.108472, Train Acc: 0.823077 | Val Loss: 0.128597, Val Acc: 0.773196\n",
      "Epoch 13264 - Train Loss: 0.108467, Train Acc: 0.823077 | Val Loss: 0.128594, Val Acc: 0.773196\n",
      "Epoch 13265 - Train Loss: 0.108462, Train Acc: 0.823077 | Val Loss: 0.128590, Val Acc: 0.773196\n",
      "Epoch 13266 - Train Loss: 0.108458, Train Acc: 0.823077 | Val Loss: 0.128586, Val Acc: 0.773196\n",
      "Epoch 13267 - Train Loss: 0.108453, Train Acc: 0.823077 | Val Loss: 0.128583, Val Acc: 0.773196\n",
      "Epoch 13268 - Train Loss: 0.108448, Train Acc: 0.823077 | Val Loss: 0.128579, Val Acc: 0.773196\n",
      "Epoch 13269 - Train Loss: 0.108443, Train Acc: 0.823077 | Val Loss: 0.128576, Val Acc: 0.773196\n",
      "Epoch 13270 - Train Loss: 0.108438, Train Acc: 0.823077 | Val Loss: 0.128572, Val Acc: 0.773196\n",
      "Epoch 13271 - Train Loss: 0.108433, Train Acc: 0.823077 | Val Loss: 0.128569, Val Acc: 0.773196\n",
      "Epoch 13272 - Train Loss: 0.108428, Train Acc: 0.823077 | Val Loss: 0.128565, Val Acc: 0.773196\n",
      "Epoch 13273 - Train Loss: 0.108424, Train Acc: 0.823077 | Val Loss: 0.128561, Val Acc: 0.773196\n",
      "Epoch 13274 - Train Loss: 0.108419, Train Acc: 0.823077 | Val Loss: 0.128558, Val Acc: 0.773196\n",
      "Epoch 13275 - Train Loss: 0.108414, Train Acc: 0.823077 | Val Loss: 0.128554, Val Acc: 0.773196\n",
      "Epoch 13276 - Train Loss: 0.108409, Train Acc: 0.823077 | Val Loss: 0.128551, Val Acc: 0.773196\n",
      "Epoch 13277 - Train Loss: 0.108404, Train Acc: 0.823077 | Val Loss: 0.128547, Val Acc: 0.773196\n",
      "Epoch 13278 - Train Loss: 0.108399, Train Acc: 0.823077 | Val Loss: 0.128543, Val Acc: 0.773196\n",
      "Epoch 13279 - Train Loss: 0.108394, Train Acc: 0.823077 | Val Loss: 0.128540, Val Acc: 0.773196\n",
      "Epoch 13280 - Train Loss: 0.108390, Train Acc: 0.823077 | Val Loss: 0.128536, Val Acc: 0.773196\n",
      "Epoch 13281 - Train Loss: 0.108385, Train Acc: 0.823077 | Val Loss: 0.128533, Val Acc: 0.773196\n",
      "Epoch 13282 - Train Loss: 0.108380, Train Acc: 0.823077 | Val Loss: 0.128529, Val Acc: 0.773196\n",
      "Epoch 13283 - Train Loss: 0.108375, Train Acc: 0.823077 | Val Loss: 0.128526, Val Acc: 0.773196\n",
      "Epoch 13284 - Train Loss: 0.108370, Train Acc: 0.823077 | Val Loss: 0.128522, Val Acc: 0.773196\n",
      "Epoch 13285 - Train Loss: 0.108365, Train Acc: 0.823077 | Val Loss: 0.128518, Val Acc: 0.773196\n",
      "Epoch 13286 - Train Loss: 0.108360, Train Acc: 0.823077 | Val Loss: 0.128515, Val Acc: 0.773196\n",
      "Epoch 13287 - Train Loss: 0.108356, Train Acc: 0.823077 | Val Loss: 0.128511, Val Acc: 0.773196\n",
      "Epoch 13288 - Train Loss: 0.108351, Train Acc: 0.823077 | Val Loss: 0.128508, Val Acc: 0.773196\n",
      "Epoch 13289 - Train Loss: 0.108346, Train Acc: 0.823077 | Val Loss: 0.128504, Val Acc: 0.773196\n",
      "Epoch 13290 - Train Loss: 0.108341, Train Acc: 0.823077 | Val Loss: 0.128501, Val Acc: 0.773196\n",
      "Epoch 13291 - Train Loss: 0.108336, Train Acc: 0.823077 | Val Loss: 0.128497, Val Acc: 0.773196\n",
      "Epoch 13292 - Train Loss: 0.108331, Train Acc: 0.823077 | Val Loss: 0.128493, Val Acc: 0.773196\n",
      "Epoch 13293 - Train Loss: 0.108327, Train Acc: 0.823077 | Val Loss: 0.128490, Val Acc: 0.773196\n",
      "Epoch 13294 - Train Loss: 0.108322, Train Acc: 0.823077 | Val Loss: 0.128486, Val Acc: 0.773196\n",
      "Epoch 13295 - Train Loss: 0.108317, Train Acc: 0.823077 | Val Loss: 0.128483, Val Acc: 0.773196\n",
      "Epoch 13296 - Train Loss: 0.108312, Train Acc: 0.823077 | Val Loss: 0.128479, Val Acc: 0.773196\n",
      "Epoch 13297 - Train Loss: 0.108307, Train Acc: 0.823077 | Val Loss: 0.128476, Val Acc: 0.773196\n",
      "Epoch 13298 - Train Loss: 0.108302, Train Acc: 0.823077 | Val Loss: 0.128472, Val Acc: 0.773196\n",
      "Epoch 13299 - Train Loss: 0.108297, Train Acc: 0.823077 | Val Loss: 0.128468, Val Acc: 0.773196\n",
      "Epoch 13300 - Train Loss: 0.108293, Train Acc: 0.823077 | Val Loss: 0.128465, Val Acc: 0.773196\n",
      "Epoch 13301 - Train Loss: 0.108288, Train Acc: 0.823077 | Val Loss: 0.128461, Val Acc: 0.773196\n",
      "Epoch 13302 - Train Loss: 0.108283, Train Acc: 0.823077 | Val Loss: 0.128458, Val Acc: 0.773196\n",
      "Epoch 13303 - Train Loss: 0.108278, Train Acc: 0.823077 | Val Loss: 0.128454, Val Acc: 0.773196\n",
      "Epoch 13304 - Train Loss: 0.108273, Train Acc: 0.823077 | Val Loss: 0.128451, Val Acc: 0.773196\n",
      "Epoch 13305 - Train Loss: 0.108268, Train Acc: 0.823077 | Val Loss: 0.128447, Val Acc: 0.773196\n",
      "Epoch 13306 - Train Loss: 0.108264, Train Acc: 0.823077 | Val Loss: 0.128443, Val Acc: 0.773196\n",
      "Epoch 13307 - Train Loss: 0.108259, Train Acc: 0.823077 | Val Loss: 0.128440, Val Acc: 0.773196\n",
      "Epoch 13308 - Train Loss: 0.108254, Train Acc: 0.823077 | Val Loss: 0.128436, Val Acc: 0.773196\n",
      "Epoch 13309 - Train Loss: 0.108249, Train Acc: 0.823077 | Val Loss: 0.128433, Val Acc: 0.773196\n",
      "Epoch 13310 - Train Loss: 0.108244, Train Acc: 0.823077 | Val Loss: 0.128429, Val Acc: 0.773196\n",
      "Epoch 13311 - Train Loss: 0.108239, Train Acc: 0.823077 | Val Loss: 0.128426, Val Acc: 0.773196\n",
      "Epoch 13312 - Train Loss: 0.108235, Train Acc: 0.823077 | Val Loss: 0.128422, Val Acc: 0.773196\n",
      "Epoch 13313 - Train Loss: 0.108230, Train Acc: 0.823077 | Val Loss: 0.128419, Val Acc: 0.773196\n",
      "Epoch 13314 - Train Loss: 0.108225, Train Acc: 0.823077 | Val Loss: 0.128415, Val Acc: 0.773196\n",
      "Epoch 13315 - Train Loss: 0.108220, Train Acc: 0.823077 | Val Loss: 0.128411, Val Acc: 0.773196\n",
      "Epoch 13316 - Train Loss: 0.108215, Train Acc: 0.823077 | Val Loss: 0.128408, Val Acc: 0.773196\n",
      "Epoch 13317 - Train Loss: 0.108211, Train Acc: 0.823077 | Val Loss: 0.128404, Val Acc: 0.773196\n",
      "Epoch 13318 - Train Loss: 0.108206, Train Acc: 0.823077 | Val Loss: 0.128401, Val Acc: 0.773196\n",
      "Epoch 13319 - Train Loss: 0.108201, Train Acc: 0.823077 | Val Loss: 0.128397, Val Acc: 0.773196\n",
      "Epoch 13320 - Train Loss: 0.108196, Train Acc: 0.823077 | Val Loss: 0.128394, Val Acc: 0.773196\n",
      "Epoch 13321 - Train Loss: 0.108191, Train Acc: 0.823077 | Val Loss: 0.128390, Val Acc: 0.773196\n",
      "Epoch 13322 - Train Loss: 0.108186, Train Acc: 0.823077 | Val Loss: 0.128387, Val Acc: 0.773196\n",
      "Epoch 13323 - Train Loss: 0.108182, Train Acc: 0.823077 | Val Loss: 0.128383, Val Acc: 0.773196\n",
      "Epoch 13324 - Train Loss: 0.108177, Train Acc: 0.823077 | Val Loss: 0.128379, Val Acc: 0.773196\n",
      "Epoch 13325 - Train Loss: 0.108172, Train Acc: 0.823077 | Val Loss: 0.128376, Val Acc: 0.773196\n",
      "Epoch 13326 - Train Loss: 0.108167, Train Acc: 0.823077 | Val Loss: 0.128372, Val Acc: 0.773196\n",
      "Epoch 13327 - Train Loss: 0.108162, Train Acc: 0.823077 | Val Loss: 0.128369, Val Acc: 0.773196\n",
      "Epoch 13328 - Train Loss: 0.108157, Train Acc: 0.823077 | Val Loss: 0.128365, Val Acc: 0.773196\n",
      "Epoch 13329 - Train Loss: 0.108153, Train Acc: 0.823077 | Val Loss: 0.128362, Val Acc: 0.773196\n",
      "Epoch 13330 - Train Loss: 0.108148, Train Acc: 0.823077 | Val Loss: 0.128358, Val Acc: 0.773196\n",
      "Epoch 13331 - Train Loss: 0.108143, Train Acc: 0.823077 | Val Loss: 0.128355, Val Acc: 0.773196\n",
      "Epoch 13332 - Train Loss: 0.108138, Train Acc: 0.823077 | Val Loss: 0.128351, Val Acc: 0.773196\n",
      "Epoch 13333 - Train Loss: 0.108133, Train Acc: 0.823077 | Val Loss: 0.128348, Val Acc: 0.773196\n",
      "Epoch 13334 - Train Loss: 0.108129, Train Acc: 0.823077 | Val Loss: 0.128344, Val Acc: 0.773196\n",
      "Epoch 13335 - Train Loss: 0.108124, Train Acc: 0.823077 | Val Loss: 0.128341, Val Acc: 0.773196\n",
      "Epoch 13336 - Train Loss: 0.108119, Train Acc: 0.823077 | Val Loss: 0.128337, Val Acc: 0.773196\n",
      "Epoch 13337 - Train Loss: 0.108114, Train Acc: 0.823077 | Val Loss: 0.128333, Val Acc: 0.773196\n",
      "Epoch 13338 - Train Loss: 0.108109, Train Acc: 0.823077 | Val Loss: 0.128330, Val Acc: 0.773196\n",
      "Epoch 13339 - Train Loss: 0.108105, Train Acc: 0.823077 | Val Loss: 0.128326, Val Acc: 0.773196\n",
      "Epoch 13340 - Train Loss: 0.108100, Train Acc: 0.823077 | Val Loss: 0.128323, Val Acc: 0.773196\n",
      "Epoch 13341 - Train Loss: 0.108095, Train Acc: 0.823077 | Val Loss: 0.128319, Val Acc: 0.773196\n",
      "Epoch 13342 - Train Loss: 0.108090, Train Acc: 0.823077 | Val Loss: 0.128316, Val Acc: 0.773196\n",
      "Epoch 13343 - Train Loss: 0.108085, Train Acc: 0.823077 | Val Loss: 0.128312, Val Acc: 0.773196\n",
      "Epoch 13344 - Train Loss: 0.108081, Train Acc: 0.823077 | Val Loss: 0.128309, Val Acc: 0.773196\n",
      "Epoch 13345 - Train Loss: 0.108076, Train Acc: 0.823077 | Val Loss: 0.128305, Val Acc: 0.773196\n",
      "Epoch 13346 - Train Loss: 0.108071, Train Acc: 0.823077 | Val Loss: 0.128302, Val Acc: 0.773196\n",
      "Epoch 13347 - Train Loss: 0.108066, Train Acc: 0.823077 | Val Loss: 0.128298, Val Acc: 0.773196\n",
      "Epoch 13348 - Train Loss: 0.108061, Train Acc: 0.823077 | Val Loss: 0.128295, Val Acc: 0.773196\n",
      "Epoch 13349 - Train Loss: 0.108057, Train Acc: 0.823077 | Val Loss: 0.128291, Val Acc: 0.773196\n",
      "Epoch 13350 - Train Loss: 0.108052, Train Acc: 0.823077 | Val Loss: 0.128288, Val Acc: 0.773196\n",
      "Epoch 13351 - Train Loss: 0.108047, Train Acc: 0.823077 | Val Loss: 0.128284, Val Acc: 0.773196\n",
      "Epoch 13352 - Train Loss: 0.108042, Train Acc: 0.823077 | Val Loss: 0.128280, Val Acc: 0.773196\n",
      "Epoch 13353 - Train Loss: 0.108037, Train Acc: 0.823077 | Val Loss: 0.128277, Val Acc: 0.773196\n",
      "Epoch 13354 - Train Loss: 0.108033, Train Acc: 0.823077 | Val Loss: 0.128273, Val Acc: 0.773196\n",
      "Epoch 13355 - Train Loss: 0.108028, Train Acc: 0.823077 | Val Loss: 0.128270, Val Acc: 0.773196\n",
      "Epoch 13356 - Train Loss: 0.108023, Train Acc: 0.823077 | Val Loss: 0.128266, Val Acc: 0.773196\n",
      "Epoch 13357 - Train Loss: 0.108018, Train Acc: 0.823077 | Val Loss: 0.128263, Val Acc: 0.773196\n",
      "Epoch 13358 - Train Loss: 0.108013, Train Acc: 0.823077 | Val Loss: 0.128259, Val Acc: 0.773196\n",
      "Epoch 13359 - Train Loss: 0.108009, Train Acc: 0.823077 | Val Loss: 0.128256, Val Acc: 0.773196\n",
      "Epoch 13360 - Train Loss: 0.108004, Train Acc: 0.823077 | Val Loss: 0.128252, Val Acc: 0.773196\n",
      "Epoch 13361 - Train Loss: 0.107999, Train Acc: 0.823077 | Val Loss: 0.128249, Val Acc: 0.773196\n",
      "Epoch 13362 - Train Loss: 0.107994, Train Acc: 0.823077 | Val Loss: 0.128245, Val Acc: 0.773196\n",
      "Epoch 13363 - Train Loss: 0.107989, Train Acc: 0.823077 | Val Loss: 0.128242, Val Acc: 0.773196\n",
      "Epoch 13364 - Train Loss: 0.107985, Train Acc: 0.823077 | Val Loss: 0.128238, Val Acc: 0.773196\n",
      "Epoch 13365 - Train Loss: 0.107980, Train Acc: 0.823077 | Val Loss: 0.128235, Val Acc: 0.773196\n",
      "Epoch 13366 - Train Loss: 0.107975, Train Acc: 0.823077 | Val Loss: 0.128231, Val Acc: 0.773196\n",
      "Epoch 13367 - Train Loss: 0.107970, Train Acc: 0.823077 | Val Loss: 0.128228, Val Acc: 0.773196\n",
      "Epoch 13368 - Train Loss: 0.107965, Train Acc: 0.823077 | Val Loss: 0.128224, Val Acc: 0.773196\n",
      "Epoch 13369 - Train Loss: 0.107961, Train Acc: 0.823077 | Val Loss: 0.128221, Val Acc: 0.773196\n",
      "Epoch 13370 - Train Loss: 0.107956, Train Acc: 0.823077 | Val Loss: 0.128217, Val Acc: 0.773196\n",
      "Epoch 13371 - Train Loss: 0.107951, Train Acc: 0.823077 | Val Loss: 0.128214, Val Acc: 0.773196\n",
      "Epoch 13372 - Train Loss: 0.107946, Train Acc: 0.823077 | Val Loss: 0.128210, Val Acc: 0.773196\n",
      "Epoch 13373 - Train Loss: 0.107942, Train Acc: 0.823077 | Val Loss: 0.128207, Val Acc: 0.773196\n",
      "Epoch 13374 - Train Loss: 0.107937, Train Acc: 0.823077 | Val Loss: 0.128203, Val Acc: 0.773196\n",
      "Epoch 13375 - Train Loss: 0.107932, Train Acc: 0.823077 | Val Loss: 0.128200, Val Acc: 0.773196\n",
      "Epoch 13376 - Train Loss: 0.107927, Train Acc: 0.823077 | Val Loss: 0.128196, Val Acc: 0.773196\n",
      "Epoch 13377 - Train Loss: 0.107922, Train Acc: 0.824359 | Val Loss: 0.128193, Val Acc: 0.773196\n",
      "Epoch 13378 - Train Loss: 0.107918, Train Acc: 0.824359 | Val Loss: 0.128189, Val Acc: 0.773196\n",
      "Epoch 13379 - Train Loss: 0.107913, Train Acc: 0.824359 | Val Loss: 0.128186, Val Acc: 0.773196\n",
      "Epoch 13380 - Train Loss: 0.107908, Train Acc: 0.824359 | Val Loss: 0.128182, Val Acc: 0.773196\n",
      "Epoch 13381 - Train Loss: 0.107903, Train Acc: 0.824359 | Val Loss: 0.128179, Val Acc: 0.773196\n",
      "Epoch 13382 - Train Loss: 0.107898, Train Acc: 0.824359 | Val Loss: 0.128175, Val Acc: 0.773196\n",
      "Epoch 13383 - Train Loss: 0.107894, Train Acc: 0.824359 | Val Loss: 0.128172, Val Acc: 0.773196\n",
      "Epoch 13384 - Train Loss: 0.107889, Train Acc: 0.824359 | Val Loss: 0.128168, Val Acc: 0.773196\n",
      "Epoch 13385 - Train Loss: 0.107884, Train Acc: 0.824359 | Val Loss: 0.128165, Val Acc: 0.773196\n",
      "Epoch 13386 - Train Loss: 0.107879, Train Acc: 0.824359 | Val Loss: 0.128161, Val Acc: 0.773196\n",
      "Epoch 13387 - Train Loss: 0.107875, Train Acc: 0.824359 | Val Loss: 0.128158, Val Acc: 0.773196\n",
      "Epoch 13388 - Train Loss: 0.107870, Train Acc: 0.824359 | Val Loss: 0.128154, Val Acc: 0.773196\n",
      "Epoch 13389 - Train Loss: 0.107865, Train Acc: 0.824359 | Val Loss: 0.128151, Val Acc: 0.773196\n",
      "Epoch 13390 - Train Loss: 0.107860, Train Acc: 0.824359 | Val Loss: 0.128147, Val Acc: 0.773196\n",
      "Epoch 13391 - Train Loss: 0.107856, Train Acc: 0.824359 | Val Loss: 0.128144, Val Acc: 0.773196\n",
      "Epoch 13392 - Train Loss: 0.107851, Train Acc: 0.824359 | Val Loss: 0.128140, Val Acc: 0.773196\n",
      "Epoch 13393 - Train Loss: 0.107846, Train Acc: 0.824359 | Val Loss: 0.128137, Val Acc: 0.773196\n",
      "Epoch 13394 - Train Loss: 0.107841, Train Acc: 0.824359 | Val Loss: 0.128133, Val Acc: 0.773196\n",
      "Epoch 13395 - Train Loss: 0.107836, Train Acc: 0.824359 | Val Loss: 0.128130, Val Acc: 0.773196\n",
      "Epoch 13396 - Train Loss: 0.107832, Train Acc: 0.824359 | Val Loss: 0.128126, Val Acc: 0.773196\n",
      "Epoch 13397 - Train Loss: 0.107827, Train Acc: 0.824359 | Val Loss: 0.128123, Val Acc: 0.773196\n",
      "Epoch 13398 - Train Loss: 0.107822, Train Acc: 0.824359 | Val Loss: 0.128119, Val Acc: 0.773196\n",
      "Epoch 13399 - Train Loss: 0.107817, Train Acc: 0.824359 | Val Loss: 0.128116, Val Acc: 0.773196\n",
      "Epoch 13400 - Train Loss: 0.107813, Train Acc: 0.824359 | Val Loss: 0.128112, Val Acc: 0.773196\n",
      "Epoch 13401 - Train Loss: 0.107808, Train Acc: 0.824359 | Val Loss: 0.128109, Val Acc: 0.773196\n",
      "Epoch 13402 - Train Loss: 0.107803, Train Acc: 0.824359 | Val Loss: 0.128105, Val Acc: 0.773196\n",
      "Epoch 13403 - Train Loss: 0.107798, Train Acc: 0.824359 | Val Loss: 0.128102, Val Acc: 0.773196\n",
      "Epoch 13404 - Train Loss: 0.107794, Train Acc: 0.824359 | Val Loss: 0.128098, Val Acc: 0.773196\n",
      "Epoch 13405 - Train Loss: 0.107789, Train Acc: 0.824359 | Val Loss: 0.128095, Val Acc: 0.773196\n",
      "Epoch 13406 - Train Loss: 0.107784, Train Acc: 0.824359 | Val Loss: 0.128091, Val Acc: 0.773196\n",
      "Epoch 13407 - Train Loss: 0.107779, Train Acc: 0.824359 | Val Loss: 0.128088, Val Acc: 0.773196\n",
      "Epoch 13408 - Train Loss: 0.107775, Train Acc: 0.824359 | Val Loss: 0.128084, Val Acc: 0.773196\n",
      "Epoch 13409 - Train Loss: 0.107770, Train Acc: 0.824359 | Val Loss: 0.128081, Val Acc: 0.773196\n",
      "Epoch 13410 - Train Loss: 0.107765, Train Acc: 0.824359 | Val Loss: 0.128077, Val Acc: 0.773196\n",
      "Epoch 13411 - Train Loss: 0.107760, Train Acc: 0.824359 | Val Loss: 0.128074, Val Acc: 0.773196\n",
      "Epoch 13412 - Train Loss: 0.107756, Train Acc: 0.824359 | Val Loss: 0.128070, Val Acc: 0.773196\n",
      "Epoch 13413 - Train Loss: 0.107751, Train Acc: 0.824359 | Val Loss: 0.128067, Val Acc: 0.773196\n",
      "Epoch 13414 - Train Loss: 0.107746, Train Acc: 0.824359 | Val Loss: 0.128063, Val Acc: 0.773196\n",
      "Epoch 13415 - Train Loss: 0.107741, Train Acc: 0.824359 | Val Loss: 0.128060, Val Acc: 0.773196\n",
      "Epoch 13416 - Train Loss: 0.107736, Train Acc: 0.824359 | Val Loss: 0.128056, Val Acc: 0.773196\n",
      "Epoch 13417 - Train Loss: 0.107732, Train Acc: 0.824359 | Val Loss: 0.128053, Val Acc: 0.773196\n",
      "Epoch 13418 - Train Loss: 0.107727, Train Acc: 0.824359 | Val Loss: 0.128049, Val Acc: 0.773196\n",
      "Epoch 13419 - Train Loss: 0.107722, Train Acc: 0.824359 | Val Loss: 0.128046, Val Acc: 0.773196\n",
      "Epoch 13420 - Train Loss: 0.107717, Train Acc: 0.824359 | Val Loss: 0.128042, Val Acc: 0.773196\n",
      "Epoch 13421 - Train Loss: 0.107713, Train Acc: 0.824359 | Val Loss: 0.128039, Val Acc: 0.773196\n",
      "Epoch 13422 - Train Loss: 0.107708, Train Acc: 0.824359 | Val Loss: 0.128035, Val Acc: 0.773196\n",
      "Epoch 13423 - Train Loss: 0.107703, Train Acc: 0.824359 | Val Loss: 0.128032, Val Acc: 0.773196\n",
      "Epoch 13424 - Train Loss: 0.107699, Train Acc: 0.824359 | Val Loss: 0.128029, Val Acc: 0.773196\n",
      "Epoch 13425 - Train Loss: 0.107694, Train Acc: 0.824359 | Val Loss: 0.128025, Val Acc: 0.773196\n",
      "Epoch 13426 - Train Loss: 0.107689, Train Acc: 0.824359 | Val Loss: 0.128022, Val Acc: 0.773196\n",
      "Epoch 13427 - Train Loss: 0.107684, Train Acc: 0.824359 | Val Loss: 0.128018, Val Acc: 0.773196\n",
      "Epoch 13428 - Train Loss: 0.107680, Train Acc: 0.824359 | Val Loss: 0.128015, Val Acc: 0.773196\n",
      "Epoch 13429 - Train Loss: 0.107675, Train Acc: 0.824359 | Val Loss: 0.128011, Val Acc: 0.773196\n",
      "Epoch 13430 - Train Loss: 0.107670, Train Acc: 0.824359 | Val Loss: 0.128008, Val Acc: 0.773196\n",
      "Epoch 13431 - Train Loss: 0.107665, Train Acc: 0.824359 | Val Loss: 0.128004, Val Acc: 0.773196\n",
      "Epoch 13432 - Train Loss: 0.107661, Train Acc: 0.824359 | Val Loss: 0.128001, Val Acc: 0.773196\n",
      "Epoch 13433 - Train Loss: 0.107656, Train Acc: 0.824359 | Val Loss: 0.127997, Val Acc: 0.773196\n",
      "Epoch 13434 - Train Loss: 0.107651, Train Acc: 0.824359 | Val Loss: 0.127994, Val Acc: 0.773196\n",
      "Epoch 13435 - Train Loss: 0.107646, Train Acc: 0.824359 | Val Loss: 0.127990, Val Acc: 0.773196\n",
      "Epoch 13436 - Train Loss: 0.107642, Train Acc: 0.824359 | Val Loss: 0.127987, Val Acc: 0.773196\n",
      "Epoch 13437 - Train Loss: 0.107637, Train Acc: 0.824359 | Val Loss: 0.127983, Val Acc: 0.773196\n",
      "Epoch 13438 - Train Loss: 0.107632, Train Acc: 0.824359 | Val Loss: 0.127980, Val Acc: 0.773196\n",
      "Epoch 13439 - Train Loss: 0.107627, Train Acc: 0.824359 | Val Loss: 0.127977, Val Acc: 0.773196\n",
      "Epoch 13440 - Train Loss: 0.107623, Train Acc: 0.824359 | Val Loss: 0.127973, Val Acc: 0.773196\n",
      "Epoch 13441 - Train Loss: 0.107618, Train Acc: 0.824359 | Val Loss: 0.127970, Val Acc: 0.773196\n",
      "Epoch 13442 - Train Loss: 0.107613, Train Acc: 0.824359 | Val Loss: 0.127966, Val Acc: 0.773196\n",
      "Epoch 13443 - Train Loss: 0.107608, Train Acc: 0.824359 | Val Loss: 0.127963, Val Acc: 0.773196\n",
      "Epoch 13444 - Train Loss: 0.107604, Train Acc: 0.824359 | Val Loss: 0.127959, Val Acc: 0.773196\n",
      "Epoch 13445 - Train Loss: 0.107599, Train Acc: 0.824359 | Val Loss: 0.127956, Val Acc: 0.773196\n",
      "Epoch 13446 - Train Loss: 0.107594, Train Acc: 0.824359 | Val Loss: 0.127952, Val Acc: 0.773196\n",
      "Epoch 13447 - Train Loss: 0.107590, Train Acc: 0.824359 | Val Loss: 0.127949, Val Acc: 0.773196\n",
      "Epoch 13448 - Train Loss: 0.107585, Train Acc: 0.824359 | Val Loss: 0.127945, Val Acc: 0.773196\n",
      "Epoch 13449 - Train Loss: 0.107580, Train Acc: 0.824359 | Val Loss: 0.127942, Val Acc: 0.773196\n",
      "Epoch 13450 - Train Loss: 0.107575, Train Acc: 0.824359 | Val Loss: 0.127938, Val Acc: 0.773196\n",
      "Epoch 13451 - Train Loss: 0.107571, Train Acc: 0.824359 | Val Loss: 0.127935, Val Acc: 0.773196\n",
      "Epoch 13452 - Train Loss: 0.107566, Train Acc: 0.824359 | Val Loss: 0.127932, Val Acc: 0.773196\n",
      "Epoch 13453 - Train Loss: 0.107561, Train Acc: 0.824359 | Val Loss: 0.127928, Val Acc: 0.773196\n",
      "Epoch 13454 - Train Loss: 0.107556, Train Acc: 0.824359 | Val Loss: 0.127925, Val Acc: 0.773196\n",
      "Epoch 13455 - Train Loss: 0.107552, Train Acc: 0.824359 | Val Loss: 0.127921, Val Acc: 0.773196\n",
      "Epoch 13456 - Train Loss: 0.107547, Train Acc: 0.824359 | Val Loss: 0.127918, Val Acc: 0.773196\n",
      "Epoch 13457 - Train Loss: 0.107542, Train Acc: 0.824359 | Val Loss: 0.127914, Val Acc: 0.773196\n",
      "Epoch 13458 - Train Loss: 0.107538, Train Acc: 0.824359 | Val Loss: 0.127911, Val Acc: 0.773196\n",
      "Epoch 13459 - Train Loss: 0.107533, Train Acc: 0.824359 | Val Loss: 0.127907, Val Acc: 0.773196\n",
      "Epoch 13460 - Train Loss: 0.107528, Train Acc: 0.824359 | Val Loss: 0.127904, Val Acc: 0.773196\n",
      "Epoch 13461 - Train Loss: 0.107523, Train Acc: 0.824359 | Val Loss: 0.127901, Val Acc: 0.773196\n",
      "Epoch 13462 - Train Loss: 0.107519, Train Acc: 0.824359 | Val Loss: 0.127897, Val Acc: 0.773196\n",
      "Epoch 13463 - Train Loss: 0.107514, Train Acc: 0.825641 | Val Loss: 0.127894, Val Acc: 0.773196\n",
      "Epoch 13464 - Train Loss: 0.107509, Train Acc: 0.825641 | Val Loss: 0.127890, Val Acc: 0.773196\n",
      "Epoch 13465 - Train Loss: 0.107505, Train Acc: 0.825641 | Val Loss: 0.127887, Val Acc: 0.773196\n",
      "Epoch 13466 - Train Loss: 0.107500, Train Acc: 0.825641 | Val Loss: 0.127883, Val Acc: 0.773196\n",
      "Epoch 13467 - Train Loss: 0.107495, Train Acc: 0.825641 | Val Loss: 0.127880, Val Acc: 0.773196\n",
      "Epoch 13468 - Train Loss: 0.107490, Train Acc: 0.825641 | Val Loss: 0.127876, Val Acc: 0.773196\n",
      "Epoch 13469 - Train Loss: 0.107486, Train Acc: 0.825641 | Val Loss: 0.127873, Val Acc: 0.773196\n",
      "Epoch 13470 - Train Loss: 0.107481, Train Acc: 0.825641 | Val Loss: 0.127870, Val Acc: 0.773196\n",
      "Epoch 13471 - Train Loss: 0.107476, Train Acc: 0.825641 | Val Loss: 0.127866, Val Acc: 0.773196\n",
      "Epoch 13472 - Train Loss: 0.107472, Train Acc: 0.825641 | Val Loss: 0.127863, Val Acc: 0.773196\n",
      "Epoch 13473 - Train Loss: 0.107467, Train Acc: 0.825641 | Val Loss: 0.127859, Val Acc: 0.773196\n",
      "Epoch 13474 - Train Loss: 0.107462, Train Acc: 0.825641 | Val Loss: 0.127856, Val Acc: 0.773196\n",
      "Epoch 13475 - Train Loss: 0.107457, Train Acc: 0.825641 | Val Loss: 0.127852, Val Acc: 0.773196\n",
      "Epoch 13476 - Train Loss: 0.107453, Train Acc: 0.825641 | Val Loss: 0.127849, Val Acc: 0.773196\n",
      "Epoch 13477 - Train Loss: 0.107448, Train Acc: 0.825641 | Val Loss: 0.127845, Val Acc: 0.773196\n",
      "Epoch 13478 - Train Loss: 0.107443, Train Acc: 0.825641 | Val Loss: 0.127842, Val Acc: 0.773196\n",
      "Epoch 13479 - Train Loss: 0.107439, Train Acc: 0.825641 | Val Loss: 0.127839, Val Acc: 0.773196\n",
      "Epoch 13480 - Train Loss: 0.107434, Train Acc: 0.825641 | Val Loss: 0.127835, Val Acc: 0.773196\n",
      "Epoch 13481 - Train Loss: 0.107429, Train Acc: 0.825641 | Val Loss: 0.127832, Val Acc: 0.773196\n",
      "Epoch 13482 - Train Loss: 0.107424, Train Acc: 0.825641 | Val Loss: 0.127828, Val Acc: 0.773196\n",
      "Epoch 13483 - Train Loss: 0.107420, Train Acc: 0.825641 | Val Loss: 0.127825, Val Acc: 0.773196\n",
      "Epoch 13484 - Train Loss: 0.107415, Train Acc: 0.825641 | Val Loss: 0.127821, Val Acc: 0.773196\n",
      "Epoch 13485 - Train Loss: 0.107410, Train Acc: 0.825641 | Val Loss: 0.127818, Val Acc: 0.773196\n",
      "Epoch 13486 - Train Loss: 0.107406, Train Acc: 0.825641 | Val Loss: 0.127815, Val Acc: 0.773196\n",
      "Epoch 13487 - Train Loss: 0.107401, Train Acc: 0.825641 | Val Loss: 0.127811, Val Acc: 0.773196\n",
      "Epoch 13488 - Train Loss: 0.107396, Train Acc: 0.825641 | Val Loss: 0.127808, Val Acc: 0.773196\n",
      "Epoch 13489 - Train Loss: 0.107392, Train Acc: 0.825641 | Val Loss: 0.127804, Val Acc: 0.773196\n",
      "Epoch 13490 - Train Loss: 0.107387, Train Acc: 0.825641 | Val Loss: 0.127801, Val Acc: 0.773196\n",
      "Epoch 13491 - Train Loss: 0.107382, Train Acc: 0.825641 | Val Loss: 0.127797, Val Acc: 0.773196\n",
      "Epoch 13492 - Train Loss: 0.107377, Train Acc: 0.825641 | Val Loss: 0.127794, Val Acc: 0.773196\n",
      "Epoch 13493 - Train Loss: 0.107373, Train Acc: 0.825641 | Val Loss: 0.127791, Val Acc: 0.773196\n",
      "Epoch 13494 - Train Loss: 0.107368, Train Acc: 0.825641 | Val Loss: 0.127787, Val Acc: 0.773196\n",
      "Epoch 13495 - Train Loss: 0.107363, Train Acc: 0.825641 | Val Loss: 0.127784, Val Acc: 0.773196\n",
      "Epoch 13496 - Train Loss: 0.107359, Train Acc: 0.825641 | Val Loss: 0.127780, Val Acc: 0.773196\n",
      "Epoch 13497 - Train Loss: 0.107354, Train Acc: 0.825641 | Val Loss: 0.127777, Val Acc: 0.773196\n",
      "Epoch 13498 - Train Loss: 0.107349, Train Acc: 0.825641 | Val Loss: 0.127773, Val Acc: 0.773196\n",
      "Epoch 13499 - Train Loss: 0.107345, Train Acc: 0.825641 | Val Loss: 0.127770, Val Acc: 0.773196\n",
      "Epoch 13500 - Train Loss: 0.107340, Train Acc: 0.825641 | Val Loss: 0.127767, Val Acc: 0.773196\n",
      "Epoch 13501 - Train Loss: 0.107335, Train Acc: 0.825641 | Val Loss: 0.127763, Val Acc: 0.773196\n",
      "Epoch 13502 - Train Loss: 0.107330, Train Acc: 0.825641 | Val Loss: 0.127760, Val Acc: 0.773196\n",
      "Epoch 13503 - Train Loss: 0.107326, Train Acc: 0.825641 | Val Loss: 0.127756, Val Acc: 0.773196\n",
      "Epoch 13504 - Train Loss: 0.107321, Train Acc: 0.825641 | Val Loss: 0.127753, Val Acc: 0.773196\n",
      "Epoch 13505 - Train Loss: 0.107316, Train Acc: 0.825641 | Val Loss: 0.127750, Val Acc: 0.773196\n",
      "Epoch 13506 - Train Loss: 0.107312, Train Acc: 0.825641 | Val Loss: 0.127746, Val Acc: 0.773196\n",
      "Epoch 13507 - Train Loss: 0.107307, Train Acc: 0.825641 | Val Loss: 0.127743, Val Acc: 0.773196\n",
      "Epoch 13508 - Train Loss: 0.107302, Train Acc: 0.825641 | Val Loss: 0.127739, Val Acc: 0.773196\n",
      "Epoch 13509 - Train Loss: 0.107298, Train Acc: 0.825641 | Val Loss: 0.127736, Val Acc: 0.773196\n",
      "Epoch 13510 - Train Loss: 0.107293, Train Acc: 0.825641 | Val Loss: 0.127732, Val Acc: 0.773196\n",
      "Epoch 13511 - Train Loss: 0.107288, Train Acc: 0.825641 | Val Loss: 0.127729, Val Acc: 0.773196\n",
      "Epoch 13512 - Train Loss: 0.107284, Train Acc: 0.825641 | Val Loss: 0.127726, Val Acc: 0.773196\n",
      "Epoch 13513 - Train Loss: 0.107279, Train Acc: 0.825641 | Val Loss: 0.127722, Val Acc: 0.773196\n",
      "Epoch 13514 - Train Loss: 0.107274, Train Acc: 0.825641 | Val Loss: 0.127719, Val Acc: 0.773196\n",
      "Epoch 13515 - Train Loss: 0.107270, Train Acc: 0.825641 | Val Loss: 0.127715, Val Acc: 0.773196\n",
      "Epoch 13516 - Train Loss: 0.107265, Train Acc: 0.825641 | Val Loss: 0.127712, Val Acc: 0.773196\n",
      "Epoch 13517 - Train Loss: 0.107260, Train Acc: 0.825641 | Val Loss: 0.127709, Val Acc: 0.773196\n",
      "Epoch 13518 - Train Loss: 0.107256, Train Acc: 0.825641 | Val Loss: 0.127705, Val Acc: 0.773196\n",
      "Epoch 13519 - Train Loss: 0.107251, Train Acc: 0.825641 | Val Loss: 0.127702, Val Acc: 0.773196\n",
      "Epoch 13520 - Train Loss: 0.107246, Train Acc: 0.825641 | Val Loss: 0.127698, Val Acc: 0.773196\n",
      "Epoch 13521 - Train Loss: 0.107241, Train Acc: 0.825641 | Val Loss: 0.127695, Val Acc: 0.773196\n",
      "Epoch 13522 - Train Loss: 0.107237, Train Acc: 0.825641 | Val Loss: 0.127692, Val Acc: 0.773196\n",
      "Epoch 13523 - Train Loss: 0.107232, Train Acc: 0.826923 | Val Loss: 0.127688, Val Acc: 0.773196\n",
      "Epoch 13524 - Train Loss: 0.107227, Train Acc: 0.826923 | Val Loss: 0.127685, Val Acc: 0.773196\n",
      "Epoch 13525 - Train Loss: 0.107223, Train Acc: 0.826923 | Val Loss: 0.127681, Val Acc: 0.773196\n",
      "Epoch 13526 - Train Loss: 0.107218, Train Acc: 0.826923 | Val Loss: 0.127678, Val Acc: 0.773196\n",
      "Epoch 13527 - Train Loss: 0.107213, Train Acc: 0.826923 | Val Loss: 0.127675, Val Acc: 0.773196\n",
      "Epoch 13528 - Train Loss: 0.107209, Train Acc: 0.826923 | Val Loss: 0.127671, Val Acc: 0.773196\n",
      "Epoch 13529 - Train Loss: 0.107204, Train Acc: 0.826923 | Val Loss: 0.127668, Val Acc: 0.773196\n",
      "Epoch 13530 - Train Loss: 0.107199, Train Acc: 0.826923 | Val Loss: 0.127664, Val Acc: 0.773196\n",
      "Epoch 13531 - Train Loss: 0.107195, Train Acc: 0.826923 | Val Loss: 0.127661, Val Acc: 0.773196\n",
      "Epoch 13532 - Train Loss: 0.107190, Train Acc: 0.826923 | Val Loss: 0.127658, Val Acc: 0.773196\n",
      "Epoch 13533 - Train Loss: 0.107185, Train Acc: 0.826923 | Val Loss: 0.127654, Val Acc: 0.773196\n",
      "Epoch 13534 - Train Loss: 0.107181, Train Acc: 0.826923 | Val Loss: 0.127651, Val Acc: 0.773196\n",
      "Epoch 13535 - Train Loss: 0.107176, Train Acc: 0.826923 | Val Loss: 0.127647, Val Acc: 0.773196\n",
      "Epoch 13536 - Train Loss: 0.107171, Train Acc: 0.826923 | Val Loss: 0.127644, Val Acc: 0.773196\n",
      "Epoch 13537 - Train Loss: 0.107167, Train Acc: 0.826923 | Val Loss: 0.127641, Val Acc: 0.773196\n",
      "Epoch 13538 - Train Loss: 0.107162, Train Acc: 0.826923 | Val Loss: 0.127637, Val Acc: 0.773196\n",
      "Epoch 13539 - Train Loss: 0.107157, Train Acc: 0.826923 | Val Loss: 0.127634, Val Acc: 0.773196\n",
      "Epoch 13540 - Train Loss: 0.107153, Train Acc: 0.826923 | Val Loss: 0.127630, Val Acc: 0.773196\n",
      "Epoch 13541 - Train Loss: 0.107148, Train Acc: 0.826923 | Val Loss: 0.127627, Val Acc: 0.773196\n",
      "Epoch 13542 - Train Loss: 0.107143, Train Acc: 0.826923 | Val Loss: 0.127624, Val Acc: 0.773196\n",
      "Epoch 13543 - Train Loss: 0.107139, Train Acc: 0.826923 | Val Loss: 0.127620, Val Acc: 0.773196\n",
      "Epoch 13544 - Train Loss: 0.107134, Train Acc: 0.826923 | Val Loss: 0.127617, Val Acc: 0.773196\n",
      "Epoch 13545 - Train Loss: 0.107129, Train Acc: 0.826923 | Val Loss: 0.127613, Val Acc: 0.773196\n",
      "Epoch 13546 - Train Loss: 0.107125, Train Acc: 0.826923 | Val Loss: 0.127610, Val Acc: 0.773196\n",
      "Epoch 13547 - Train Loss: 0.107120, Train Acc: 0.826923 | Val Loss: 0.127607, Val Acc: 0.773196\n",
      "Epoch 13548 - Train Loss: 0.107115, Train Acc: 0.826923 | Val Loss: 0.127603, Val Acc: 0.773196\n",
      "Epoch 13549 - Train Loss: 0.107111, Train Acc: 0.826923 | Val Loss: 0.127600, Val Acc: 0.773196\n",
      "Epoch 13550 - Train Loss: 0.107106, Train Acc: 0.826923 | Val Loss: 0.127596, Val Acc: 0.773196\n",
      "Epoch 13551 - Train Loss: 0.107101, Train Acc: 0.826923 | Val Loss: 0.127593, Val Acc: 0.773196\n",
      "Epoch 13552 - Train Loss: 0.107097, Train Acc: 0.826923 | Val Loss: 0.127590, Val Acc: 0.773196\n",
      "Epoch 13553 - Train Loss: 0.107092, Train Acc: 0.826923 | Val Loss: 0.127586, Val Acc: 0.773196\n",
      "Epoch 13554 - Train Loss: 0.107088, Train Acc: 0.826923 | Val Loss: 0.127583, Val Acc: 0.773196\n",
      "Epoch 13555 - Train Loss: 0.107083, Train Acc: 0.826923 | Val Loss: 0.127579, Val Acc: 0.773196\n",
      "Epoch 13556 - Train Loss: 0.107078, Train Acc: 0.826923 | Val Loss: 0.127576, Val Acc: 0.773196\n",
      "Epoch 13557 - Train Loss: 0.107074, Train Acc: 0.826923 | Val Loss: 0.127573, Val Acc: 0.773196\n",
      "Epoch 13558 - Train Loss: 0.107069, Train Acc: 0.826923 | Val Loss: 0.127569, Val Acc: 0.773196\n",
      "Epoch 13559 - Train Loss: 0.107064, Train Acc: 0.826923 | Val Loss: 0.127566, Val Acc: 0.773196\n",
      "Epoch 13560 - Train Loss: 0.107060, Train Acc: 0.826923 | Val Loss: 0.127562, Val Acc: 0.773196\n",
      "Epoch 13561 - Train Loss: 0.107055, Train Acc: 0.826923 | Val Loss: 0.127559, Val Acc: 0.773196\n",
      "Epoch 13562 - Train Loss: 0.107050, Train Acc: 0.826923 | Val Loss: 0.127556, Val Acc: 0.773196\n",
      "Epoch 13563 - Train Loss: 0.107046, Train Acc: 0.826923 | Val Loss: 0.127552, Val Acc: 0.773196\n",
      "Epoch 13564 - Train Loss: 0.107041, Train Acc: 0.826923 | Val Loss: 0.127549, Val Acc: 0.773196\n",
      "Epoch 13565 - Train Loss: 0.107036, Train Acc: 0.826923 | Val Loss: 0.127546, Val Acc: 0.773196\n",
      "Epoch 13566 - Train Loss: 0.107032, Train Acc: 0.826923 | Val Loss: 0.127542, Val Acc: 0.773196\n",
      "Epoch 13567 - Train Loss: 0.107027, Train Acc: 0.826923 | Val Loss: 0.127539, Val Acc: 0.773196\n",
      "Epoch 13568 - Train Loss: 0.107022, Train Acc: 0.826923 | Val Loss: 0.127535, Val Acc: 0.773196\n",
      "Epoch 13569 - Train Loss: 0.107018, Train Acc: 0.826923 | Val Loss: 0.127532, Val Acc: 0.773196\n",
      "Epoch 13570 - Train Loss: 0.107013, Train Acc: 0.826923 | Val Loss: 0.127529, Val Acc: 0.773196\n",
      "Epoch 13571 - Train Loss: 0.107008, Train Acc: 0.826923 | Val Loss: 0.127525, Val Acc: 0.773196\n",
      "Epoch 13572 - Train Loss: 0.107004, Train Acc: 0.826923 | Val Loss: 0.127522, Val Acc: 0.773196\n",
      "Epoch 13573 - Train Loss: 0.106999, Train Acc: 0.826923 | Val Loss: 0.127518, Val Acc: 0.773196\n",
      "Epoch 13574 - Train Loss: 0.106995, Train Acc: 0.826923 | Val Loss: 0.127515, Val Acc: 0.773196\n",
      "Epoch 13575 - Train Loss: 0.106990, Train Acc: 0.826923 | Val Loss: 0.127512, Val Acc: 0.773196\n",
      "Epoch 13576 - Train Loss: 0.106985, Train Acc: 0.826923 | Val Loss: 0.127508, Val Acc: 0.773196\n",
      "Epoch 13577 - Train Loss: 0.106981, Train Acc: 0.826923 | Val Loss: 0.127505, Val Acc: 0.773196\n",
      "Epoch 13578 - Train Loss: 0.106976, Train Acc: 0.826923 | Val Loss: 0.127502, Val Acc: 0.773196\n",
      "Epoch 13579 - Train Loss: 0.106971, Train Acc: 0.826923 | Val Loss: 0.127498, Val Acc: 0.773196\n",
      "Epoch 13580 - Train Loss: 0.106967, Train Acc: 0.826923 | Val Loss: 0.127495, Val Acc: 0.773196\n",
      "Epoch 13581 - Train Loss: 0.106962, Train Acc: 0.826923 | Val Loss: 0.127492, Val Acc: 0.773196\n",
      "Epoch 13582 - Train Loss: 0.106957, Train Acc: 0.826923 | Val Loss: 0.127488, Val Acc: 0.773196\n",
      "Epoch 13583 - Train Loss: 0.106953, Train Acc: 0.828205 | Val Loss: 0.127485, Val Acc: 0.773196\n",
      "Epoch 13584 - Train Loss: 0.106948, Train Acc: 0.828205 | Val Loss: 0.127481, Val Acc: 0.773196\n",
      "Epoch 13585 - Train Loss: 0.106944, Train Acc: 0.828205 | Val Loss: 0.127478, Val Acc: 0.773196\n",
      "Epoch 13586 - Train Loss: 0.106939, Train Acc: 0.828205 | Val Loss: 0.127475, Val Acc: 0.773196\n",
      "Epoch 13587 - Train Loss: 0.106934, Train Acc: 0.828205 | Val Loss: 0.127471, Val Acc: 0.773196\n",
      "Epoch 13588 - Train Loss: 0.106930, Train Acc: 0.828205 | Val Loss: 0.127468, Val Acc: 0.773196\n",
      "Epoch 13589 - Train Loss: 0.106925, Train Acc: 0.828205 | Val Loss: 0.127465, Val Acc: 0.773196\n",
      "Epoch 13590 - Train Loss: 0.106920, Train Acc: 0.828205 | Val Loss: 0.127461, Val Acc: 0.773196\n",
      "Epoch 13591 - Train Loss: 0.106916, Train Acc: 0.828205 | Val Loss: 0.127458, Val Acc: 0.773196\n",
      "Epoch 13592 - Train Loss: 0.106911, Train Acc: 0.828205 | Val Loss: 0.127455, Val Acc: 0.773196\n",
      "Epoch 13593 - Train Loss: 0.106907, Train Acc: 0.828205 | Val Loss: 0.127451, Val Acc: 0.773196\n",
      "Epoch 13594 - Train Loss: 0.106902, Train Acc: 0.828205 | Val Loss: 0.127448, Val Acc: 0.773196\n",
      "Epoch 13595 - Train Loss: 0.106897, Train Acc: 0.828205 | Val Loss: 0.127444, Val Acc: 0.773196\n",
      "Epoch 13596 - Train Loss: 0.106893, Train Acc: 0.828205 | Val Loss: 0.127441, Val Acc: 0.773196\n",
      "Epoch 13597 - Train Loss: 0.106888, Train Acc: 0.828205 | Val Loss: 0.127438, Val Acc: 0.773196\n",
      "Epoch 13598 - Train Loss: 0.106883, Train Acc: 0.828205 | Val Loss: 0.127434, Val Acc: 0.773196\n",
      "Epoch 13599 - Train Loss: 0.106879, Train Acc: 0.828205 | Val Loss: 0.127431, Val Acc: 0.773196\n",
      "Epoch 13600 - Train Loss: 0.106874, Train Acc: 0.828205 | Val Loss: 0.127428, Val Acc: 0.773196\n",
      "Epoch 13601 - Train Loss: 0.106870, Train Acc: 0.829487 | Val Loss: 0.127424, Val Acc: 0.773196\n",
      "Epoch 13602 - Train Loss: 0.106865, Train Acc: 0.829487 | Val Loss: 0.127421, Val Acc: 0.773196\n",
      "Epoch 13603 - Train Loss: 0.106860, Train Acc: 0.829487 | Val Loss: 0.127418, Val Acc: 0.773196\n",
      "Epoch 13604 - Train Loss: 0.106856, Train Acc: 0.829487 | Val Loss: 0.127414, Val Acc: 0.773196\n",
      "Epoch 13605 - Train Loss: 0.106851, Train Acc: 0.829487 | Val Loss: 0.127411, Val Acc: 0.773196\n",
      "Epoch 13606 - Train Loss: 0.106846, Train Acc: 0.829487 | Val Loss: 0.127408, Val Acc: 0.773196\n",
      "Epoch 13607 - Train Loss: 0.106842, Train Acc: 0.829487 | Val Loss: 0.127404, Val Acc: 0.773196\n",
      "Epoch 13608 - Train Loss: 0.106837, Train Acc: 0.829487 | Val Loss: 0.127401, Val Acc: 0.773196\n",
      "Epoch 13609 - Train Loss: 0.106833, Train Acc: 0.829487 | Val Loss: 0.127398, Val Acc: 0.773196\n",
      "Epoch 13610 - Train Loss: 0.106828, Train Acc: 0.829487 | Val Loss: 0.127394, Val Acc: 0.773196\n",
      "Epoch 13611 - Train Loss: 0.106823, Train Acc: 0.829487 | Val Loss: 0.127391, Val Acc: 0.773196\n",
      "Epoch 13612 - Train Loss: 0.106819, Train Acc: 0.829487 | Val Loss: 0.127387, Val Acc: 0.773196\n",
      "Epoch 13613 - Train Loss: 0.106814, Train Acc: 0.829487 | Val Loss: 0.127384, Val Acc: 0.773196\n",
      "Epoch 13614 - Train Loss: 0.106810, Train Acc: 0.829487 | Val Loss: 0.127381, Val Acc: 0.773196\n",
      "Epoch 13615 - Train Loss: 0.106805, Train Acc: 0.829487 | Val Loss: 0.127377, Val Acc: 0.773196\n",
      "Epoch 13616 - Train Loss: 0.106800, Train Acc: 0.829487 | Val Loss: 0.127374, Val Acc: 0.773196\n",
      "Epoch 13617 - Train Loss: 0.106796, Train Acc: 0.829487 | Val Loss: 0.127371, Val Acc: 0.773196\n",
      "Epoch 13618 - Train Loss: 0.106791, Train Acc: 0.829487 | Val Loss: 0.127367, Val Acc: 0.773196\n",
      "Epoch 13619 - Train Loss: 0.106786, Train Acc: 0.829487 | Val Loss: 0.127364, Val Acc: 0.773196\n",
      "Epoch 13620 - Train Loss: 0.106782, Train Acc: 0.829487 | Val Loss: 0.127361, Val Acc: 0.773196\n",
      "Epoch 13621 - Train Loss: 0.106777, Train Acc: 0.829487 | Val Loss: 0.127357, Val Acc: 0.773196\n",
      "Epoch 13622 - Train Loss: 0.106773, Train Acc: 0.829487 | Val Loss: 0.127354, Val Acc: 0.773196\n",
      "Epoch 13623 - Train Loss: 0.106768, Train Acc: 0.829487 | Val Loss: 0.127351, Val Acc: 0.773196\n",
      "Epoch 13624 - Train Loss: 0.106763, Train Acc: 0.829487 | Val Loss: 0.127347, Val Acc: 0.773196\n",
      "Epoch 13625 - Train Loss: 0.106759, Train Acc: 0.829487 | Val Loss: 0.127344, Val Acc: 0.773196\n",
      "Epoch 13626 - Train Loss: 0.106754, Train Acc: 0.829487 | Val Loss: 0.127341, Val Acc: 0.773196\n",
      "Epoch 13627 - Train Loss: 0.106750, Train Acc: 0.829487 | Val Loss: 0.127337, Val Acc: 0.773196\n",
      "Epoch 13628 - Train Loss: 0.106745, Train Acc: 0.829487 | Val Loss: 0.127334, Val Acc: 0.773196\n",
      "Epoch 13629 - Train Loss: 0.106740, Train Acc: 0.829487 | Val Loss: 0.127331, Val Acc: 0.773196\n",
      "Epoch 13630 - Train Loss: 0.106736, Train Acc: 0.829487 | Val Loss: 0.127327, Val Acc: 0.773196\n",
      "Epoch 13631 - Train Loss: 0.106731, Train Acc: 0.829487 | Val Loss: 0.127324, Val Acc: 0.773196\n",
      "Epoch 13632 - Train Loss: 0.106727, Train Acc: 0.829487 | Val Loss: 0.127321, Val Acc: 0.773196\n",
      "Epoch 13633 - Train Loss: 0.106722, Train Acc: 0.829487 | Val Loss: 0.127317, Val Acc: 0.773196\n",
      "Epoch 13634 - Train Loss: 0.106717, Train Acc: 0.829487 | Val Loss: 0.127314, Val Acc: 0.773196\n",
      "Epoch 13635 - Train Loss: 0.106713, Train Acc: 0.830769 | Val Loss: 0.127311, Val Acc: 0.773196\n",
      "Epoch 13636 - Train Loss: 0.106708, Train Acc: 0.830769 | Val Loss: 0.127307, Val Acc: 0.773196\n",
      "Epoch 13637 - Train Loss: 0.106704, Train Acc: 0.830769 | Val Loss: 0.127304, Val Acc: 0.773196\n",
      "Epoch 13638 - Train Loss: 0.106699, Train Acc: 0.830769 | Val Loss: 0.127301, Val Acc: 0.773196\n",
      "Epoch 13639 - Train Loss: 0.106694, Train Acc: 0.830769 | Val Loss: 0.127297, Val Acc: 0.773196\n",
      "Epoch 13640 - Train Loss: 0.106690, Train Acc: 0.830769 | Val Loss: 0.127294, Val Acc: 0.773196\n",
      "Epoch 13641 - Train Loss: 0.106685, Train Acc: 0.830769 | Val Loss: 0.127291, Val Acc: 0.773196\n",
      "Epoch 13642 - Train Loss: 0.106681, Train Acc: 0.830769 | Val Loss: 0.127287, Val Acc: 0.773196\n",
      "Epoch 13643 - Train Loss: 0.106676, Train Acc: 0.830769 | Val Loss: 0.127284, Val Acc: 0.773196\n",
      "Epoch 13644 - Train Loss: 0.106671, Train Acc: 0.830769 | Val Loss: 0.127281, Val Acc: 0.773196\n",
      "Epoch 13645 - Train Loss: 0.106667, Train Acc: 0.830769 | Val Loss: 0.127278, Val Acc: 0.773196\n",
      "Epoch 13646 - Train Loss: 0.106662, Train Acc: 0.830769 | Val Loss: 0.127274, Val Acc: 0.773196\n",
      "Epoch 13647 - Train Loss: 0.106658, Train Acc: 0.830769 | Val Loss: 0.127271, Val Acc: 0.773196\n",
      "Epoch 13648 - Train Loss: 0.106653, Train Acc: 0.830769 | Val Loss: 0.127268, Val Acc: 0.773196\n",
      "Epoch 13649 - Train Loss: 0.106649, Train Acc: 0.830769 | Val Loss: 0.127264, Val Acc: 0.773196\n",
      "Epoch 13650 - Train Loss: 0.106644, Train Acc: 0.830769 | Val Loss: 0.127261, Val Acc: 0.773196\n",
      "Epoch 13651 - Train Loss: 0.106639, Train Acc: 0.830769 | Val Loss: 0.127258, Val Acc: 0.773196\n",
      "Epoch 13652 - Train Loss: 0.106635, Train Acc: 0.830769 | Val Loss: 0.127254, Val Acc: 0.773196\n",
      "Epoch 13653 - Train Loss: 0.106630, Train Acc: 0.830769 | Val Loss: 0.127251, Val Acc: 0.773196\n",
      "Epoch 13654 - Train Loss: 0.106626, Train Acc: 0.830769 | Val Loss: 0.127248, Val Acc: 0.773196\n",
      "Epoch 13655 - Train Loss: 0.106621, Train Acc: 0.830769 | Val Loss: 0.127244, Val Acc: 0.773196\n",
      "Epoch 13656 - Train Loss: 0.106616, Train Acc: 0.830769 | Val Loss: 0.127241, Val Acc: 0.773196\n",
      "Epoch 13657 - Train Loss: 0.106612, Train Acc: 0.830769 | Val Loss: 0.127238, Val Acc: 0.773196\n",
      "Epoch 13658 - Train Loss: 0.106607, Train Acc: 0.830769 | Val Loss: 0.127234, Val Acc: 0.773196\n",
      "Epoch 13659 - Train Loss: 0.106603, Train Acc: 0.830769 | Val Loss: 0.127231, Val Acc: 0.773196\n",
      "Epoch 13660 - Train Loss: 0.106598, Train Acc: 0.830769 | Val Loss: 0.127228, Val Acc: 0.773196\n",
      "Epoch 13661 - Train Loss: 0.106594, Train Acc: 0.830769 | Val Loss: 0.127224, Val Acc: 0.773196\n",
      "Epoch 13662 - Train Loss: 0.106589, Train Acc: 0.830769 | Val Loss: 0.127221, Val Acc: 0.773196\n",
      "Epoch 13663 - Train Loss: 0.106584, Train Acc: 0.830769 | Val Loss: 0.127218, Val Acc: 0.773196\n",
      "Epoch 13664 - Train Loss: 0.106580, Train Acc: 0.830769 | Val Loss: 0.127215, Val Acc: 0.773196\n",
      "Epoch 13665 - Train Loss: 0.106575, Train Acc: 0.830769 | Val Loss: 0.127211, Val Acc: 0.773196\n",
      "Epoch 13666 - Train Loss: 0.106571, Train Acc: 0.830769 | Val Loss: 0.127208, Val Acc: 0.773196\n",
      "Epoch 13667 - Train Loss: 0.106566, Train Acc: 0.830769 | Val Loss: 0.127205, Val Acc: 0.773196\n",
      "Epoch 13668 - Train Loss: 0.106561, Train Acc: 0.830769 | Val Loss: 0.127201, Val Acc: 0.773196\n",
      "Epoch 13669 - Train Loss: 0.106557, Train Acc: 0.830769 | Val Loss: 0.127198, Val Acc: 0.773196\n",
      "Epoch 13670 - Train Loss: 0.106552, Train Acc: 0.830769 | Val Loss: 0.127195, Val Acc: 0.773196\n",
      "Epoch 13671 - Train Loss: 0.106548, Train Acc: 0.830769 | Val Loss: 0.127191, Val Acc: 0.773196\n",
      "Epoch 13672 - Train Loss: 0.106543, Train Acc: 0.830769 | Val Loss: 0.127188, Val Acc: 0.773196\n",
      "Epoch 13673 - Train Loss: 0.106539, Train Acc: 0.830769 | Val Loss: 0.127185, Val Acc: 0.773196\n",
      "Epoch 13674 - Train Loss: 0.106534, Train Acc: 0.830769 | Val Loss: 0.127182, Val Acc: 0.773196\n",
      "Epoch 13675 - Train Loss: 0.106529, Train Acc: 0.830769 | Val Loss: 0.127178, Val Acc: 0.773196\n",
      "Epoch 13676 - Train Loss: 0.106525, Train Acc: 0.830769 | Val Loss: 0.127175, Val Acc: 0.773196\n",
      "Epoch 13677 - Train Loss: 0.106520, Train Acc: 0.830769 | Val Loss: 0.127172, Val Acc: 0.773196\n",
      "Epoch 13678 - Train Loss: 0.106516, Train Acc: 0.830769 | Val Loss: 0.127168, Val Acc: 0.773196\n",
      "Epoch 13679 - Train Loss: 0.106511, Train Acc: 0.830769 | Val Loss: 0.127165, Val Acc: 0.773196\n",
      "Epoch 13680 - Train Loss: 0.106507, Train Acc: 0.830769 | Val Loss: 0.127162, Val Acc: 0.773196\n",
      "Epoch 13681 - Train Loss: 0.106502, Train Acc: 0.830769 | Val Loss: 0.127158, Val Acc: 0.773196\n",
      "Epoch 13682 - Train Loss: 0.106497, Train Acc: 0.830769 | Val Loss: 0.127155, Val Acc: 0.773196\n",
      "Epoch 13683 - Train Loss: 0.106493, Train Acc: 0.830769 | Val Loss: 0.127152, Val Acc: 0.773196\n",
      "Epoch 13684 - Train Loss: 0.106488, Train Acc: 0.830769 | Val Loss: 0.127149, Val Acc: 0.773196\n",
      "Epoch 13685 - Train Loss: 0.106484, Train Acc: 0.830769 | Val Loss: 0.127145, Val Acc: 0.773196\n",
      "Epoch 13686 - Train Loss: 0.106479, Train Acc: 0.830769 | Val Loss: 0.127142, Val Acc: 0.773196\n",
      "Epoch 13687 - Train Loss: 0.106475, Train Acc: 0.830769 | Val Loss: 0.127139, Val Acc: 0.773196\n",
      "Epoch 13688 - Train Loss: 0.106470, Train Acc: 0.830769 | Val Loss: 0.127135, Val Acc: 0.773196\n",
      "Epoch 13689 - Train Loss: 0.106466, Train Acc: 0.830769 | Val Loss: 0.127132, Val Acc: 0.773196\n",
      "Epoch 13690 - Train Loss: 0.106461, Train Acc: 0.830769 | Val Loss: 0.127129, Val Acc: 0.773196\n",
      "Epoch 13691 - Train Loss: 0.106456, Train Acc: 0.830769 | Val Loss: 0.127126, Val Acc: 0.773196\n",
      "Epoch 13692 - Train Loss: 0.106452, Train Acc: 0.830769 | Val Loss: 0.127122, Val Acc: 0.773196\n",
      "Epoch 13693 - Train Loss: 0.106447, Train Acc: 0.830769 | Val Loss: 0.127119, Val Acc: 0.773196\n",
      "Epoch 13694 - Train Loss: 0.106443, Train Acc: 0.830769 | Val Loss: 0.127116, Val Acc: 0.773196\n",
      "Epoch 13695 - Train Loss: 0.106438, Train Acc: 0.830769 | Val Loss: 0.127112, Val Acc: 0.773196\n",
      "Epoch 13696 - Train Loss: 0.106434, Train Acc: 0.830769 | Val Loss: 0.127109, Val Acc: 0.773196\n",
      "Epoch 13697 - Train Loss: 0.106429, Train Acc: 0.830769 | Val Loss: 0.127106, Val Acc: 0.773196\n",
      "Epoch 13698 - Train Loss: 0.106425, Train Acc: 0.830769 | Val Loss: 0.127103, Val Acc: 0.773196\n",
      "Epoch 13699 - Train Loss: 0.106420, Train Acc: 0.830769 | Val Loss: 0.127099, Val Acc: 0.773196\n",
      "Epoch 13700 - Train Loss: 0.106415, Train Acc: 0.830769 | Val Loss: 0.127096, Val Acc: 0.773196\n",
      "Epoch 13701 - Train Loss: 0.106411, Train Acc: 0.830769 | Val Loss: 0.127093, Val Acc: 0.773196\n",
      "Epoch 13702 - Train Loss: 0.106406, Train Acc: 0.830769 | Val Loss: 0.127089, Val Acc: 0.773196\n",
      "Epoch 13703 - Train Loss: 0.106402, Train Acc: 0.830769 | Val Loss: 0.127086, Val Acc: 0.773196\n",
      "Epoch 13704 - Train Loss: 0.106397, Train Acc: 0.830769 | Val Loss: 0.127083, Val Acc: 0.773196\n",
      "Epoch 13705 - Train Loss: 0.106393, Train Acc: 0.830769 | Val Loss: 0.127080, Val Acc: 0.773196\n",
      "Epoch 13706 - Train Loss: 0.106388, Train Acc: 0.830769 | Val Loss: 0.127076, Val Acc: 0.773196\n",
      "Epoch 13707 - Train Loss: 0.106384, Train Acc: 0.830769 | Val Loss: 0.127073, Val Acc: 0.773196\n",
      "Epoch 13708 - Train Loss: 0.106379, Train Acc: 0.830769 | Val Loss: 0.127070, Val Acc: 0.773196\n",
      "Epoch 13709 - Train Loss: 0.106374, Train Acc: 0.830769 | Val Loss: 0.127066, Val Acc: 0.773196\n",
      "Epoch 13710 - Train Loss: 0.106370, Train Acc: 0.830769 | Val Loss: 0.127063, Val Acc: 0.773196\n",
      "Epoch 13711 - Train Loss: 0.106365, Train Acc: 0.830769 | Val Loss: 0.127060, Val Acc: 0.773196\n",
      "Epoch 13712 - Train Loss: 0.106361, Train Acc: 0.830769 | Val Loss: 0.127057, Val Acc: 0.773196\n",
      "Epoch 13713 - Train Loss: 0.106356, Train Acc: 0.830769 | Val Loss: 0.127053, Val Acc: 0.773196\n",
      "Epoch 13714 - Train Loss: 0.106352, Train Acc: 0.830769 | Val Loss: 0.127050, Val Acc: 0.773196\n",
      "Epoch 13715 - Train Loss: 0.106347, Train Acc: 0.830769 | Val Loss: 0.127047, Val Acc: 0.773196\n",
      "Epoch 13716 - Train Loss: 0.106343, Train Acc: 0.830769 | Val Loss: 0.127044, Val Acc: 0.773196\n",
      "Epoch 13717 - Train Loss: 0.106338, Train Acc: 0.830769 | Val Loss: 0.127040, Val Acc: 0.773196\n",
      "Epoch 13718 - Train Loss: 0.106334, Train Acc: 0.830769 | Val Loss: 0.127037, Val Acc: 0.773196\n",
      "Epoch 13719 - Train Loss: 0.106329, Train Acc: 0.830769 | Val Loss: 0.127034, Val Acc: 0.773196\n",
      "Epoch 13720 - Train Loss: 0.106324, Train Acc: 0.830769 | Val Loss: 0.127030, Val Acc: 0.773196\n",
      "Epoch 13721 - Train Loss: 0.106320, Train Acc: 0.830769 | Val Loss: 0.127027, Val Acc: 0.773196\n",
      "Epoch 13722 - Train Loss: 0.106315, Train Acc: 0.830769 | Val Loss: 0.127024, Val Acc: 0.773196\n",
      "Epoch 13723 - Train Loss: 0.106311, Train Acc: 0.830769 | Val Loss: 0.127021, Val Acc: 0.773196\n",
      "Epoch 13724 - Train Loss: 0.106306, Train Acc: 0.830769 | Val Loss: 0.127017, Val Acc: 0.773196\n",
      "Epoch 13725 - Train Loss: 0.106302, Train Acc: 0.830769 | Val Loss: 0.127014, Val Acc: 0.773196\n",
      "Epoch 13726 - Train Loss: 0.106297, Train Acc: 0.830769 | Val Loss: 0.127011, Val Acc: 0.773196\n",
      "Epoch 13727 - Train Loss: 0.106293, Train Acc: 0.830769 | Val Loss: 0.127008, Val Acc: 0.773196\n",
      "Epoch 13728 - Train Loss: 0.106288, Train Acc: 0.830769 | Val Loss: 0.127004, Val Acc: 0.773196\n",
      "Epoch 13729 - Train Loss: 0.106284, Train Acc: 0.830769 | Val Loss: 0.127001, Val Acc: 0.773196\n",
      "Epoch 13730 - Train Loss: 0.106279, Train Acc: 0.830769 | Val Loss: 0.126998, Val Acc: 0.773196\n",
      "Epoch 13731 - Train Loss: 0.106275, Train Acc: 0.830769 | Val Loss: 0.126995, Val Acc: 0.773196\n",
      "Epoch 13732 - Train Loss: 0.106270, Train Acc: 0.830769 | Val Loss: 0.126991, Val Acc: 0.773196\n",
      "Epoch 13733 - Train Loss: 0.106266, Train Acc: 0.830769 | Val Loss: 0.126988, Val Acc: 0.773196\n",
      "Epoch 13734 - Train Loss: 0.106261, Train Acc: 0.830769 | Val Loss: 0.126985, Val Acc: 0.773196\n",
      "Epoch 13735 - Train Loss: 0.106256, Train Acc: 0.830769 | Val Loss: 0.126982, Val Acc: 0.773196\n",
      "Epoch 13736 - Train Loss: 0.106252, Train Acc: 0.830769 | Val Loss: 0.126978, Val Acc: 0.773196\n",
      "Epoch 13737 - Train Loss: 0.106247, Train Acc: 0.830769 | Val Loss: 0.126975, Val Acc: 0.773196\n",
      "Epoch 13738 - Train Loss: 0.106243, Train Acc: 0.830769 | Val Loss: 0.126972, Val Acc: 0.773196\n",
      "Epoch 13739 - Train Loss: 0.106238, Train Acc: 0.830769 | Val Loss: 0.126969, Val Acc: 0.773196\n",
      "Epoch 13740 - Train Loss: 0.106234, Train Acc: 0.830769 | Val Loss: 0.126965, Val Acc: 0.773196\n",
      "Epoch 13741 - Train Loss: 0.106229, Train Acc: 0.830769 | Val Loss: 0.126962, Val Acc: 0.773196\n",
      "Epoch 13742 - Train Loss: 0.106225, Train Acc: 0.830769 | Val Loss: 0.126959, Val Acc: 0.773196\n",
      "Epoch 13743 - Train Loss: 0.106220, Train Acc: 0.830769 | Val Loss: 0.126955, Val Acc: 0.773196\n",
      "Epoch 13744 - Train Loss: 0.106216, Train Acc: 0.830769 | Val Loss: 0.126952, Val Acc: 0.773196\n",
      "Epoch 13745 - Train Loss: 0.106211, Train Acc: 0.830769 | Val Loss: 0.126949, Val Acc: 0.773196\n",
      "Epoch 13746 - Train Loss: 0.106207, Train Acc: 0.830769 | Val Loss: 0.126946, Val Acc: 0.773196\n",
      "Epoch 13747 - Train Loss: 0.106202, Train Acc: 0.830769 | Val Loss: 0.126942, Val Acc: 0.773196\n",
      "Epoch 13748 - Train Loss: 0.106198, Train Acc: 0.830769 | Val Loss: 0.126939, Val Acc: 0.773196\n",
      "Epoch 13749 - Train Loss: 0.106193, Train Acc: 0.830769 | Val Loss: 0.126936, Val Acc: 0.773196\n",
      "Epoch 13750 - Train Loss: 0.106189, Train Acc: 0.832051 | Val Loss: 0.126933, Val Acc: 0.773196\n",
      "Epoch 13751 - Train Loss: 0.106184, Train Acc: 0.832051 | Val Loss: 0.126929, Val Acc: 0.773196\n",
      "Epoch 13752 - Train Loss: 0.106180, Train Acc: 0.832051 | Val Loss: 0.126926, Val Acc: 0.773196\n",
      "Epoch 13753 - Train Loss: 0.106175, Train Acc: 0.832051 | Val Loss: 0.126923, Val Acc: 0.773196\n",
      "Epoch 13754 - Train Loss: 0.106171, Train Acc: 0.832051 | Val Loss: 0.126919, Val Acc: 0.773196\n",
      "Epoch 13755 - Train Loss: 0.106166, Train Acc: 0.832051 | Val Loss: 0.126916, Val Acc: 0.773196\n",
      "Epoch 13756 - Train Loss: 0.106161, Train Acc: 0.832051 | Val Loss: 0.126913, Val Acc: 0.773196\n",
      "Epoch 13757 - Train Loss: 0.106157, Train Acc: 0.832051 | Val Loss: 0.126910, Val Acc: 0.773196\n",
      "Epoch 13758 - Train Loss: 0.106152, Train Acc: 0.832051 | Val Loss: 0.126906, Val Acc: 0.773196\n",
      "Epoch 13759 - Train Loss: 0.106148, Train Acc: 0.832051 | Val Loss: 0.126903, Val Acc: 0.773196\n",
      "Epoch 13760 - Train Loss: 0.106143, Train Acc: 0.832051 | Val Loss: 0.126900, Val Acc: 0.773196\n",
      "Epoch 13761 - Train Loss: 0.106139, Train Acc: 0.832051 | Val Loss: 0.126897, Val Acc: 0.773196\n",
      "Epoch 13762 - Train Loss: 0.106134, Train Acc: 0.832051 | Val Loss: 0.126893, Val Acc: 0.773196\n",
      "Epoch 13763 - Train Loss: 0.106130, Train Acc: 0.832051 | Val Loss: 0.126890, Val Acc: 0.773196\n",
      "Epoch 13764 - Train Loss: 0.106125, Train Acc: 0.832051 | Val Loss: 0.126887, Val Acc: 0.773196\n",
      "Epoch 13765 - Train Loss: 0.106121, Train Acc: 0.832051 | Val Loss: 0.126884, Val Acc: 0.773196\n",
      "Epoch 13766 - Train Loss: 0.106116, Train Acc: 0.832051 | Val Loss: 0.126880, Val Acc: 0.773196\n",
      "Epoch 13767 - Train Loss: 0.106112, Train Acc: 0.832051 | Val Loss: 0.126877, Val Acc: 0.773196\n",
      "Epoch 13768 - Train Loss: 0.106107, Train Acc: 0.832051 | Val Loss: 0.126874, Val Acc: 0.773196\n",
      "Epoch 13769 - Train Loss: 0.106103, Train Acc: 0.832051 | Val Loss: 0.126871, Val Acc: 0.773196\n",
      "Epoch 13770 - Train Loss: 0.106098, Train Acc: 0.832051 | Val Loss: 0.126867, Val Acc: 0.773196\n",
      "Epoch 13771 - Train Loss: 0.106094, Train Acc: 0.832051 | Val Loss: 0.126864, Val Acc: 0.773196\n",
      "Epoch 13772 - Train Loss: 0.106089, Train Acc: 0.832051 | Val Loss: 0.126861, Val Acc: 0.773196\n",
      "Epoch 13773 - Train Loss: 0.106085, Train Acc: 0.832051 | Val Loss: 0.126858, Val Acc: 0.773196\n",
      "Epoch 13774 - Train Loss: 0.106080, Train Acc: 0.832051 | Val Loss: 0.126854, Val Acc: 0.773196\n",
      "Epoch 13775 - Train Loss: 0.106076, Train Acc: 0.832051 | Val Loss: 0.126851, Val Acc: 0.773196\n",
      "Epoch 13776 - Train Loss: 0.106071, Train Acc: 0.832051 | Val Loss: 0.126848, Val Acc: 0.773196\n",
      "Epoch 13777 - Train Loss: 0.106067, Train Acc: 0.832051 | Val Loss: 0.126845, Val Acc: 0.773196\n",
      "Epoch 13778 - Train Loss: 0.106062, Train Acc: 0.832051 | Val Loss: 0.126842, Val Acc: 0.773196\n",
      "Epoch 13779 - Train Loss: 0.106058, Train Acc: 0.832051 | Val Loss: 0.126838, Val Acc: 0.773196\n",
      "Epoch 13780 - Train Loss: 0.106053, Train Acc: 0.832051 | Val Loss: 0.126835, Val Acc: 0.773196\n",
      "Epoch 13781 - Train Loss: 0.106049, Train Acc: 0.832051 | Val Loss: 0.126832, Val Acc: 0.773196\n",
      "Epoch 13782 - Train Loss: 0.106044, Train Acc: 0.832051 | Val Loss: 0.126829, Val Acc: 0.773196\n",
      "Epoch 13783 - Train Loss: 0.106040, Train Acc: 0.832051 | Val Loss: 0.126825, Val Acc: 0.773196\n",
      "Epoch 13784 - Train Loss: 0.106035, Train Acc: 0.832051 | Val Loss: 0.126822, Val Acc: 0.773196\n",
      "Epoch 13785 - Train Loss: 0.106031, Train Acc: 0.832051 | Val Loss: 0.126819, Val Acc: 0.773196\n",
      "Epoch 13786 - Train Loss: 0.106026, Train Acc: 0.832051 | Val Loss: 0.126816, Val Acc: 0.773196\n",
      "Epoch 13787 - Train Loss: 0.106022, Train Acc: 0.832051 | Val Loss: 0.126812, Val Acc: 0.773196\n",
      "Epoch 13788 - Train Loss: 0.106017, Train Acc: 0.832051 | Val Loss: 0.126809, Val Acc: 0.773196\n",
      "Epoch 13789 - Train Loss: 0.106013, Train Acc: 0.832051 | Val Loss: 0.126806, Val Acc: 0.773196\n",
      "Epoch 13790 - Train Loss: 0.106008, Train Acc: 0.832051 | Val Loss: 0.126803, Val Acc: 0.773196\n",
      "Epoch 13791 - Train Loss: 0.106004, Train Acc: 0.832051 | Val Loss: 0.126800, Val Acc: 0.773196\n",
      "Epoch 13792 - Train Loss: 0.105999, Train Acc: 0.832051 | Val Loss: 0.126796, Val Acc: 0.773196\n",
      "Epoch 13793 - Train Loss: 0.105995, Train Acc: 0.832051 | Val Loss: 0.126793, Val Acc: 0.773196\n",
      "Epoch 13794 - Train Loss: 0.105990, Train Acc: 0.832051 | Val Loss: 0.126790, Val Acc: 0.773196\n",
      "Epoch 13795 - Train Loss: 0.105986, Train Acc: 0.832051 | Val Loss: 0.126787, Val Acc: 0.773196\n",
      "Epoch 13796 - Train Loss: 0.105981, Train Acc: 0.832051 | Val Loss: 0.126783, Val Acc: 0.773196\n",
      "Epoch 13797 - Train Loss: 0.105977, Train Acc: 0.832051 | Val Loss: 0.126780, Val Acc: 0.773196\n",
      "Epoch 13798 - Train Loss: 0.105972, Train Acc: 0.832051 | Val Loss: 0.126777, Val Acc: 0.773196\n",
      "Epoch 13799 - Train Loss: 0.105968, Train Acc: 0.832051 | Val Loss: 0.126774, Val Acc: 0.773196\n",
      "Epoch 13800 - Train Loss: 0.105963, Train Acc: 0.832051 | Val Loss: 0.126771, Val Acc: 0.773196\n",
      "Epoch 13801 - Train Loss: 0.105959, Train Acc: 0.832051 | Val Loss: 0.126767, Val Acc: 0.773196\n",
      "Epoch 13802 - Train Loss: 0.105954, Train Acc: 0.832051 | Val Loss: 0.126764, Val Acc: 0.773196\n",
      "Epoch 13803 - Train Loss: 0.105950, Train Acc: 0.832051 | Val Loss: 0.126761, Val Acc: 0.773196\n",
      "Epoch 13804 - Train Loss: 0.105945, Train Acc: 0.832051 | Val Loss: 0.126758, Val Acc: 0.773196\n",
      "Epoch 13805 - Train Loss: 0.105941, Train Acc: 0.832051 | Val Loss: 0.126754, Val Acc: 0.773196\n",
      "Epoch 13806 - Train Loss: 0.105937, Train Acc: 0.832051 | Val Loss: 0.126751, Val Acc: 0.773196\n",
      "Epoch 13807 - Train Loss: 0.105932, Train Acc: 0.832051 | Val Loss: 0.126748, Val Acc: 0.773196\n",
      "Epoch 13808 - Train Loss: 0.105928, Train Acc: 0.832051 | Val Loss: 0.126745, Val Acc: 0.773196\n",
      "Epoch 13809 - Train Loss: 0.105923, Train Acc: 0.832051 | Val Loss: 0.126742, Val Acc: 0.773196\n",
      "Epoch 13810 - Train Loss: 0.105919, Train Acc: 0.832051 | Val Loss: 0.126738, Val Acc: 0.773196\n",
      "Epoch 13811 - Train Loss: 0.105914, Train Acc: 0.832051 | Val Loss: 0.126735, Val Acc: 0.773196\n",
      "Epoch 13812 - Train Loss: 0.105910, Train Acc: 0.832051 | Val Loss: 0.126732, Val Acc: 0.773196\n",
      "Epoch 13813 - Train Loss: 0.105905, Train Acc: 0.832051 | Val Loss: 0.126729, Val Acc: 0.773196\n",
      "Epoch 13814 - Train Loss: 0.105901, Train Acc: 0.832051 | Val Loss: 0.126726, Val Acc: 0.773196\n",
      "Epoch 13815 - Train Loss: 0.105896, Train Acc: 0.832051 | Val Loss: 0.126722, Val Acc: 0.773196\n",
      "Epoch 13816 - Train Loss: 0.105892, Train Acc: 0.832051 | Val Loss: 0.126719, Val Acc: 0.773196\n",
      "Epoch 13817 - Train Loss: 0.105887, Train Acc: 0.832051 | Val Loss: 0.126716, Val Acc: 0.773196\n",
      "Epoch 13818 - Train Loss: 0.105883, Train Acc: 0.832051 | Val Loss: 0.126713, Val Acc: 0.773196\n",
      "Epoch 13819 - Train Loss: 0.105878, Train Acc: 0.832051 | Val Loss: 0.126709, Val Acc: 0.773196\n",
      "Epoch 13820 - Train Loss: 0.105874, Train Acc: 0.832051 | Val Loss: 0.126706, Val Acc: 0.773196\n",
      "Epoch 13821 - Train Loss: 0.105869, Train Acc: 0.832051 | Val Loss: 0.126703, Val Acc: 0.773196\n",
      "Epoch 13822 - Train Loss: 0.105865, Train Acc: 0.832051 | Val Loss: 0.126700, Val Acc: 0.773196\n",
      "Epoch 13823 - Train Loss: 0.105860, Train Acc: 0.832051 | Val Loss: 0.126697, Val Acc: 0.773196\n",
      "Epoch 13824 - Train Loss: 0.105856, Train Acc: 0.832051 | Val Loss: 0.126693, Val Acc: 0.773196\n",
      "Epoch 13825 - Train Loss: 0.105851, Train Acc: 0.832051 | Val Loss: 0.126690, Val Acc: 0.773196\n",
      "Epoch 13826 - Train Loss: 0.105847, Train Acc: 0.832051 | Val Loss: 0.126687, Val Acc: 0.773196\n",
      "Epoch 13827 - Train Loss: 0.105843, Train Acc: 0.832051 | Val Loss: 0.126684, Val Acc: 0.773196\n",
      "Epoch 13828 - Train Loss: 0.105838, Train Acc: 0.832051 | Val Loss: 0.126681, Val Acc: 0.773196\n",
      "Epoch 13829 - Train Loss: 0.105834, Train Acc: 0.832051 | Val Loss: 0.126677, Val Acc: 0.773196\n",
      "Epoch 13830 - Train Loss: 0.105829, Train Acc: 0.832051 | Val Loss: 0.126674, Val Acc: 0.773196\n",
      "Epoch 13831 - Train Loss: 0.105825, Train Acc: 0.832051 | Val Loss: 0.126671, Val Acc: 0.773196\n",
      "Epoch 13832 - Train Loss: 0.105820, Train Acc: 0.832051 | Val Loss: 0.126668, Val Acc: 0.773196\n",
      "Epoch 13833 - Train Loss: 0.105816, Train Acc: 0.832051 | Val Loss: 0.126665, Val Acc: 0.773196\n",
      "Epoch 13834 - Train Loss: 0.105811, Train Acc: 0.832051 | Val Loss: 0.126661, Val Acc: 0.773196\n",
      "Epoch 13835 - Train Loss: 0.105807, Train Acc: 0.832051 | Val Loss: 0.126658, Val Acc: 0.773196\n",
      "Epoch 13836 - Train Loss: 0.105802, Train Acc: 0.832051 | Val Loss: 0.126655, Val Acc: 0.773196\n",
      "Epoch 13837 - Train Loss: 0.105798, Train Acc: 0.832051 | Val Loss: 0.126652, Val Acc: 0.773196\n",
      "Epoch 13838 - Train Loss: 0.105793, Train Acc: 0.832051 | Val Loss: 0.126649, Val Acc: 0.773196\n",
      "Epoch 13839 - Train Loss: 0.105789, Train Acc: 0.832051 | Val Loss: 0.126646, Val Acc: 0.773196\n",
      "Epoch 13840 - Train Loss: 0.105784, Train Acc: 0.832051 | Val Loss: 0.126642, Val Acc: 0.773196\n",
      "Epoch 13841 - Train Loss: 0.105780, Train Acc: 0.832051 | Val Loss: 0.126639, Val Acc: 0.773196\n",
      "Epoch 13842 - Train Loss: 0.105776, Train Acc: 0.832051 | Val Loss: 0.126636, Val Acc: 0.773196\n",
      "Epoch 13843 - Train Loss: 0.105771, Train Acc: 0.832051 | Val Loss: 0.126633, Val Acc: 0.773196\n",
      "Epoch 13844 - Train Loss: 0.105767, Train Acc: 0.832051 | Val Loss: 0.126630, Val Acc: 0.773196\n",
      "Epoch 13845 - Train Loss: 0.105762, Train Acc: 0.832051 | Val Loss: 0.126626, Val Acc: 0.773196\n",
      "Epoch 13846 - Train Loss: 0.105758, Train Acc: 0.832051 | Val Loss: 0.126623, Val Acc: 0.773196\n",
      "Epoch 13847 - Train Loss: 0.105753, Train Acc: 0.832051 | Val Loss: 0.126620, Val Acc: 0.773196\n",
      "Epoch 13848 - Train Loss: 0.105749, Train Acc: 0.832051 | Val Loss: 0.126617, Val Acc: 0.773196\n",
      "Epoch 13849 - Train Loss: 0.105744, Train Acc: 0.832051 | Val Loss: 0.126614, Val Acc: 0.773196\n",
      "Epoch 13850 - Train Loss: 0.105740, Train Acc: 0.832051 | Val Loss: 0.126610, Val Acc: 0.773196\n",
      "Epoch 13851 - Train Loss: 0.105735, Train Acc: 0.832051 | Val Loss: 0.126607, Val Acc: 0.773196\n",
      "Epoch 13852 - Train Loss: 0.105731, Train Acc: 0.832051 | Val Loss: 0.126604, Val Acc: 0.773196\n",
      "Epoch 13853 - Train Loss: 0.105727, Train Acc: 0.832051 | Val Loss: 0.126601, Val Acc: 0.773196\n",
      "Epoch 13854 - Train Loss: 0.105722, Train Acc: 0.832051 | Val Loss: 0.126598, Val Acc: 0.773196\n",
      "Epoch 13855 - Train Loss: 0.105718, Train Acc: 0.832051 | Val Loss: 0.126595, Val Acc: 0.773196\n",
      "Epoch 13856 - Train Loss: 0.105713, Train Acc: 0.832051 | Val Loss: 0.126591, Val Acc: 0.773196\n",
      "Epoch 13857 - Train Loss: 0.105709, Train Acc: 0.832051 | Val Loss: 0.126588, Val Acc: 0.773196\n",
      "Epoch 13858 - Train Loss: 0.105704, Train Acc: 0.832051 | Val Loss: 0.126585, Val Acc: 0.773196\n",
      "Epoch 13859 - Train Loss: 0.105700, Train Acc: 0.832051 | Val Loss: 0.126582, Val Acc: 0.773196\n",
      "Epoch 13860 - Train Loss: 0.105695, Train Acc: 0.832051 | Val Loss: 0.126579, Val Acc: 0.773196\n",
      "Epoch 13861 - Train Loss: 0.105691, Train Acc: 0.832051 | Val Loss: 0.126575, Val Acc: 0.773196\n",
      "Epoch 13862 - Train Loss: 0.105686, Train Acc: 0.832051 | Val Loss: 0.126572, Val Acc: 0.773196\n",
      "Epoch 13863 - Train Loss: 0.105682, Train Acc: 0.832051 | Val Loss: 0.126569, Val Acc: 0.773196\n",
      "Epoch 13864 - Train Loss: 0.105678, Train Acc: 0.832051 | Val Loss: 0.126566, Val Acc: 0.773196\n",
      "Epoch 13865 - Train Loss: 0.105673, Train Acc: 0.832051 | Val Loss: 0.126563, Val Acc: 0.773196\n",
      "Epoch 13866 - Train Loss: 0.105669, Train Acc: 0.832051 | Val Loss: 0.126560, Val Acc: 0.773196\n",
      "Epoch 13867 - Train Loss: 0.105664, Train Acc: 0.832051 | Val Loss: 0.126556, Val Acc: 0.773196\n",
      "Epoch 13868 - Train Loss: 0.105660, Train Acc: 0.832051 | Val Loss: 0.126553, Val Acc: 0.773196\n",
      "Epoch 13869 - Train Loss: 0.105655, Train Acc: 0.832051 | Val Loss: 0.126550, Val Acc: 0.773196\n",
      "Epoch 13870 - Train Loss: 0.105651, Train Acc: 0.832051 | Val Loss: 0.126547, Val Acc: 0.773196\n",
      "Epoch 13871 - Train Loss: 0.105646, Train Acc: 0.832051 | Val Loss: 0.126544, Val Acc: 0.773196\n",
      "Epoch 13872 - Train Loss: 0.105642, Train Acc: 0.832051 | Val Loss: 0.126541, Val Acc: 0.773196\n",
      "Epoch 13873 - Train Loss: 0.105638, Train Acc: 0.832051 | Val Loss: 0.126537, Val Acc: 0.773196\n",
      "Epoch 13874 - Train Loss: 0.105633, Train Acc: 0.832051 | Val Loss: 0.126534, Val Acc: 0.773196\n",
      "Epoch 13875 - Train Loss: 0.105629, Train Acc: 0.832051 | Val Loss: 0.126531, Val Acc: 0.773196\n",
      "Epoch 13876 - Train Loss: 0.105624, Train Acc: 0.832051 | Val Loss: 0.126528, Val Acc: 0.773196\n",
      "Epoch 13877 - Train Loss: 0.105620, Train Acc: 0.832051 | Val Loss: 0.126525, Val Acc: 0.773196\n",
      "Epoch 13878 - Train Loss: 0.105615, Train Acc: 0.832051 | Val Loss: 0.126521, Val Acc: 0.773196\n",
      "Epoch 13879 - Train Loss: 0.105611, Train Acc: 0.832051 | Val Loss: 0.126518, Val Acc: 0.773196\n",
      "Epoch 13880 - Train Loss: 0.105607, Train Acc: 0.832051 | Val Loss: 0.126515, Val Acc: 0.773196\n",
      "Epoch 13881 - Train Loss: 0.105602, Train Acc: 0.832051 | Val Loss: 0.126512, Val Acc: 0.773196\n",
      "Epoch 13882 - Train Loss: 0.105598, Train Acc: 0.832051 | Val Loss: 0.126509, Val Acc: 0.773196\n",
      "Epoch 13883 - Train Loss: 0.105593, Train Acc: 0.832051 | Val Loss: 0.126506, Val Acc: 0.773196\n",
      "Epoch 13884 - Train Loss: 0.105589, Train Acc: 0.832051 | Val Loss: 0.126503, Val Acc: 0.773196\n",
      "Epoch 13885 - Train Loss: 0.105584, Train Acc: 0.832051 | Val Loss: 0.126499, Val Acc: 0.773196\n",
      "Epoch 13886 - Train Loss: 0.105580, Train Acc: 0.832051 | Val Loss: 0.126496, Val Acc: 0.773196\n",
      "Epoch 13887 - Train Loss: 0.105576, Train Acc: 0.832051 | Val Loss: 0.126493, Val Acc: 0.773196\n",
      "Epoch 13888 - Train Loss: 0.105571, Train Acc: 0.832051 | Val Loss: 0.126490, Val Acc: 0.773196\n",
      "Epoch 13889 - Train Loss: 0.105567, Train Acc: 0.832051 | Val Loss: 0.126487, Val Acc: 0.773196\n",
      "Epoch 13890 - Train Loss: 0.105562, Train Acc: 0.832051 | Val Loss: 0.126484, Val Acc: 0.773196\n",
      "Epoch 13891 - Train Loss: 0.105558, Train Acc: 0.832051 | Val Loss: 0.126480, Val Acc: 0.773196\n",
      "Epoch 13892 - Train Loss: 0.105553, Train Acc: 0.832051 | Val Loss: 0.126477, Val Acc: 0.773196\n",
      "Epoch 13893 - Train Loss: 0.105549, Train Acc: 0.832051 | Val Loss: 0.126474, Val Acc: 0.773196\n",
      "Epoch 13894 - Train Loss: 0.105545, Train Acc: 0.832051 | Val Loss: 0.126471, Val Acc: 0.773196\n",
      "Epoch 13895 - Train Loss: 0.105540, Train Acc: 0.832051 | Val Loss: 0.126468, Val Acc: 0.773196\n",
      "Epoch 13896 - Train Loss: 0.105536, Train Acc: 0.832051 | Val Loss: 0.126465, Val Acc: 0.773196\n",
      "Epoch 13897 - Train Loss: 0.105531, Train Acc: 0.832051 | Val Loss: 0.126461, Val Acc: 0.773196\n",
      "Epoch 13898 - Train Loss: 0.105527, Train Acc: 0.832051 | Val Loss: 0.126458, Val Acc: 0.773196\n",
      "Epoch 13899 - Train Loss: 0.105522, Train Acc: 0.832051 | Val Loss: 0.126455, Val Acc: 0.773196\n",
      "Epoch 13900 - Train Loss: 0.105518, Train Acc: 0.832051 | Val Loss: 0.126452, Val Acc: 0.773196\n",
      "Epoch 13901 - Train Loss: 0.105514, Train Acc: 0.832051 | Val Loss: 0.126449, Val Acc: 0.773196\n",
      "Epoch 13902 - Train Loss: 0.105509, Train Acc: 0.832051 | Val Loss: 0.126446, Val Acc: 0.773196\n",
      "Epoch 13903 - Train Loss: 0.105505, Train Acc: 0.832051 | Val Loss: 0.126443, Val Acc: 0.773196\n",
      "Epoch 13904 - Train Loss: 0.105500, Train Acc: 0.832051 | Val Loss: 0.126439, Val Acc: 0.773196\n",
      "Epoch 13905 - Train Loss: 0.105496, Train Acc: 0.832051 | Val Loss: 0.126436, Val Acc: 0.773196\n",
      "Epoch 13906 - Train Loss: 0.105491, Train Acc: 0.832051 | Val Loss: 0.126433, Val Acc: 0.773196\n",
      "Epoch 13907 - Train Loss: 0.105487, Train Acc: 0.832051 | Val Loss: 0.126430, Val Acc: 0.773196\n",
      "Epoch 13908 - Train Loss: 0.105483, Train Acc: 0.832051 | Val Loss: 0.126427, Val Acc: 0.773196\n",
      "Epoch 13909 - Train Loss: 0.105478, Train Acc: 0.832051 | Val Loss: 0.126424, Val Acc: 0.773196\n",
      "Epoch 13910 - Train Loss: 0.105474, Train Acc: 0.832051 | Val Loss: 0.126420, Val Acc: 0.773196\n",
      "Epoch 13911 - Train Loss: 0.105469, Train Acc: 0.832051 | Val Loss: 0.126417, Val Acc: 0.773196\n",
      "Epoch 13912 - Train Loss: 0.105465, Train Acc: 0.832051 | Val Loss: 0.126414, Val Acc: 0.773196\n",
      "Epoch 13913 - Train Loss: 0.105461, Train Acc: 0.832051 | Val Loss: 0.126411, Val Acc: 0.773196\n",
      "Epoch 13914 - Train Loss: 0.105456, Train Acc: 0.832051 | Val Loss: 0.126408, Val Acc: 0.773196\n",
      "Epoch 13915 - Train Loss: 0.105452, Train Acc: 0.832051 | Val Loss: 0.126405, Val Acc: 0.773196\n",
      "Epoch 13916 - Train Loss: 0.105447, Train Acc: 0.832051 | Val Loss: 0.126402, Val Acc: 0.773196\n",
      "Epoch 13917 - Train Loss: 0.105443, Train Acc: 0.832051 | Val Loss: 0.126398, Val Acc: 0.773196\n",
      "Epoch 13918 - Train Loss: 0.105439, Train Acc: 0.832051 | Val Loss: 0.126395, Val Acc: 0.773196\n",
      "Epoch 13919 - Train Loss: 0.105434, Train Acc: 0.832051 | Val Loss: 0.126392, Val Acc: 0.773196\n",
      "Epoch 13920 - Train Loss: 0.105430, Train Acc: 0.832051 | Val Loss: 0.126389, Val Acc: 0.773196\n",
      "Epoch 13921 - Train Loss: 0.105425, Train Acc: 0.832051 | Val Loss: 0.126386, Val Acc: 0.773196\n",
      "Epoch 13922 - Train Loss: 0.105421, Train Acc: 0.832051 | Val Loss: 0.126383, Val Acc: 0.773196\n",
      "Epoch 13923 - Train Loss: 0.105416, Train Acc: 0.832051 | Val Loss: 0.126380, Val Acc: 0.773196\n",
      "Epoch 13924 - Train Loss: 0.105412, Train Acc: 0.832051 | Val Loss: 0.126377, Val Acc: 0.773196\n",
      "Epoch 13925 - Train Loss: 0.105408, Train Acc: 0.832051 | Val Loss: 0.126373, Val Acc: 0.773196\n",
      "Epoch 13926 - Train Loss: 0.105403, Train Acc: 0.832051 | Val Loss: 0.126370, Val Acc: 0.773196\n",
      "Epoch 13927 - Train Loss: 0.105399, Train Acc: 0.832051 | Val Loss: 0.126367, Val Acc: 0.773196\n",
      "Epoch 13928 - Train Loss: 0.105394, Train Acc: 0.832051 | Val Loss: 0.126364, Val Acc: 0.773196\n",
      "Epoch 13929 - Train Loss: 0.105390, Train Acc: 0.832051 | Val Loss: 0.126361, Val Acc: 0.773196\n",
      "Epoch 13930 - Train Loss: 0.105386, Train Acc: 0.832051 | Val Loss: 0.126358, Val Acc: 0.773196\n",
      "Epoch 13931 - Train Loss: 0.105381, Train Acc: 0.832051 | Val Loss: 0.126355, Val Acc: 0.773196\n",
      "Epoch 13932 - Train Loss: 0.105377, Train Acc: 0.832051 | Val Loss: 0.126351, Val Acc: 0.773196\n",
      "Epoch 13933 - Train Loss: 0.105372, Train Acc: 0.832051 | Val Loss: 0.126348, Val Acc: 0.773196\n",
      "Epoch 13934 - Train Loss: 0.105368, Train Acc: 0.832051 | Val Loss: 0.126345, Val Acc: 0.773196\n",
      "Epoch 13935 - Train Loss: 0.105364, Train Acc: 0.832051 | Val Loss: 0.126342, Val Acc: 0.773196\n",
      "Epoch 13936 - Train Loss: 0.105359, Train Acc: 0.832051 | Val Loss: 0.126339, Val Acc: 0.773196\n",
      "Epoch 13937 - Train Loss: 0.105355, Train Acc: 0.832051 | Val Loss: 0.126336, Val Acc: 0.773196\n",
      "Epoch 13938 - Train Loss: 0.105350, Train Acc: 0.832051 | Val Loss: 0.126333, Val Acc: 0.773196\n",
      "Epoch 13939 - Train Loss: 0.105346, Train Acc: 0.832051 | Val Loss: 0.126330, Val Acc: 0.773196\n",
      "Epoch 13940 - Train Loss: 0.105342, Train Acc: 0.832051 | Val Loss: 0.126326, Val Acc: 0.773196\n",
      "Epoch 13941 - Train Loss: 0.105337, Train Acc: 0.832051 | Val Loss: 0.126323, Val Acc: 0.773196\n",
      "Epoch 13942 - Train Loss: 0.105333, Train Acc: 0.832051 | Val Loss: 0.126320, Val Acc: 0.773196\n",
      "Epoch 13943 - Train Loss: 0.105328, Train Acc: 0.832051 | Val Loss: 0.126317, Val Acc: 0.773196\n",
      "Epoch 13944 - Train Loss: 0.105324, Train Acc: 0.832051 | Val Loss: 0.126314, Val Acc: 0.773196\n",
      "Epoch 13945 - Train Loss: 0.105320, Train Acc: 0.832051 | Val Loss: 0.126311, Val Acc: 0.773196\n",
      "Epoch 13946 - Train Loss: 0.105315, Train Acc: 0.832051 | Val Loss: 0.126308, Val Acc: 0.773196\n",
      "Epoch 13947 - Train Loss: 0.105311, Train Acc: 0.832051 | Val Loss: 0.126305, Val Acc: 0.773196\n",
      "Epoch 13948 - Train Loss: 0.105306, Train Acc: 0.832051 | Val Loss: 0.126301, Val Acc: 0.773196\n",
      "Epoch 13949 - Train Loss: 0.105302, Train Acc: 0.832051 | Val Loss: 0.126298, Val Acc: 0.773196\n",
      "Epoch 13950 - Train Loss: 0.105298, Train Acc: 0.832051 | Val Loss: 0.126295, Val Acc: 0.773196\n",
      "Epoch 13951 - Train Loss: 0.105293, Train Acc: 0.832051 | Val Loss: 0.126292, Val Acc: 0.773196\n",
      "Epoch 13952 - Train Loss: 0.105289, Train Acc: 0.832051 | Val Loss: 0.126289, Val Acc: 0.773196\n",
      "Epoch 13953 - Train Loss: 0.105285, Train Acc: 0.832051 | Val Loss: 0.126286, Val Acc: 0.773196\n",
      "Epoch 13954 - Train Loss: 0.105280, Train Acc: 0.832051 | Val Loss: 0.126283, Val Acc: 0.773196\n",
      "Epoch 13955 - Train Loss: 0.105276, Train Acc: 0.832051 | Val Loss: 0.126280, Val Acc: 0.773196\n",
      "Epoch 13956 - Train Loss: 0.105271, Train Acc: 0.832051 | Val Loss: 0.126276, Val Acc: 0.773196\n",
      "Epoch 13957 - Train Loss: 0.105267, Train Acc: 0.832051 | Val Loss: 0.126273, Val Acc: 0.773196\n",
      "Epoch 13958 - Train Loss: 0.105263, Train Acc: 0.832051 | Val Loss: 0.126270, Val Acc: 0.773196\n",
      "Epoch 13959 - Train Loss: 0.105258, Train Acc: 0.832051 | Val Loss: 0.126267, Val Acc: 0.773196\n",
      "Epoch 13960 - Train Loss: 0.105254, Train Acc: 0.832051 | Val Loss: 0.126264, Val Acc: 0.773196\n",
      "Epoch 13961 - Train Loss: 0.105249, Train Acc: 0.832051 | Val Loss: 0.126261, Val Acc: 0.773196\n",
      "Epoch 13962 - Train Loss: 0.105245, Train Acc: 0.832051 | Val Loss: 0.126258, Val Acc: 0.773196\n",
      "Epoch 13963 - Train Loss: 0.105241, Train Acc: 0.832051 | Val Loss: 0.126255, Val Acc: 0.773196\n",
      "Epoch 13964 - Train Loss: 0.105236, Train Acc: 0.832051 | Val Loss: 0.126252, Val Acc: 0.773196\n",
      "Epoch 13965 - Train Loss: 0.105232, Train Acc: 0.832051 | Val Loss: 0.126248, Val Acc: 0.773196\n",
      "Epoch 13966 - Train Loss: 0.105228, Train Acc: 0.832051 | Val Loss: 0.126245, Val Acc: 0.773196\n",
      "Epoch 13967 - Train Loss: 0.105223, Train Acc: 0.832051 | Val Loss: 0.126242, Val Acc: 0.773196\n",
      "Epoch 13968 - Train Loss: 0.105219, Train Acc: 0.832051 | Val Loss: 0.126239, Val Acc: 0.773196\n",
      "Epoch 13969 - Train Loss: 0.105214, Train Acc: 0.832051 | Val Loss: 0.126236, Val Acc: 0.773196\n",
      "Epoch 13970 - Train Loss: 0.105210, Train Acc: 0.832051 | Val Loss: 0.126233, Val Acc: 0.773196\n",
      "Epoch 13971 - Train Loss: 0.105206, Train Acc: 0.832051 | Val Loss: 0.126230, Val Acc: 0.773196\n",
      "Epoch 13972 - Train Loss: 0.105201, Train Acc: 0.832051 | Val Loss: 0.126227, Val Acc: 0.773196\n",
      "Epoch 13973 - Train Loss: 0.105197, Train Acc: 0.832051 | Val Loss: 0.126224, Val Acc: 0.773196\n",
      "Epoch 13974 - Train Loss: 0.105193, Train Acc: 0.832051 | Val Loss: 0.126220, Val Acc: 0.773196\n",
      "Epoch 13975 - Train Loss: 0.105188, Train Acc: 0.832051 | Val Loss: 0.126217, Val Acc: 0.773196\n",
      "Epoch 13976 - Train Loss: 0.105184, Train Acc: 0.832051 | Val Loss: 0.126214, Val Acc: 0.773196\n",
      "Epoch 13977 - Train Loss: 0.105179, Train Acc: 0.832051 | Val Loss: 0.126211, Val Acc: 0.773196\n",
      "Epoch 13978 - Train Loss: 0.105175, Train Acc: 0.832051 | Val Loss: 0.126208, Val Acc: 0.773196\n",
      "Epoch 13979 - Train Loss: 0.105171, Train Acc: 0.832051 | Val Loss: 0.126205, Val Acc: 0.773196\n",
      "Epoch 13980 - Train Loss: 0.105166, Train Acc: 0.832051 | Val Loss: 0.126202, Val Acc: 0.773196\n",
      "Epoch 13981 - Train Loss: 0.105162, Train Acc: 0.832051 | Val Loss: 0.126199, Val Acc: 0.773196\n",
      "Epoch 13982 - Train Loss: 0.105158, Train Acc: 0.832051 | Val Loss: 0.126196, Val Acc: 0.773196\n",
      "Epoch 13983 - Train Loss: 0.105153, Train Acc: 0.832051 | Val Loss: 0.126193, Val Acc: 0.773196\n",
      "Epoch 13984 - Train Loss: 0.105149, Train Acc: 0.832051 | Val Loss: 0.126189, Val Acc: 0.773196\n",
      "Epoch 13985 - Train Loss: 0.105144, Train Acc: 0.832051 | Val Loss: 0.126186, Val Acc: 0.773196\n",
      "Epoch 13986 - Train Loss: 0.105140, Train Acc: 0.832051 | Val Loss: 0.126183, Val Acc: 0.773196\n",
      "Epoch 13987 - Train Loss: 0.105136, Train Acc: 0.832051 | Val Loss: 0.126180, Val Acc: 0.773196\n",
      "Epoch 13988 - Train Loss: 0.105131, Train Acc: 0.832051 | Val Loss: 0.126177, Val Acc: 0.773196\n",
      "Epoch 13989 - Train Loss: 0.105127, Train Acc: 0.832051 | Val Loss: 0.126174, Val Acc: 0.773196\n",
      "Epoch 13990 - Train Loss: 0.105123, Train Acc: 0.832051 | Val Loss: 0.126171, Val Acc: 0.773196\n",
      "Epoch 13991 - Train Loss: 0.105118, Train Acc: 0.832051 | Val Loss: 0.126168, Val Acc: 0.773196\n",
      "Epoch 13992 - Train Loss: 0.105114, Train Acc: 0.832051 | Val Loss: 0.126165, Val Acc: 0.773196\n",
      "Epoch 13993 - Train Loss: 0.105110, Train Acc: 0.832051 | Val Loss: 0.126162, Val Acc: 0.773196\n",
      "Epoch 13994 - Train Loss: 0.105105, Train Acc: 0.832051 | Val Loss: 0.126158, Val Acc: 0.773196\n",
      "Epoch 13995 - Train Loss: 0.105101, Train Acc: 0.832051 | Val Loss: 0.126155, Val Acc: 0.773196\n",
      "Epoch 13996 - Train Loss: 0.105096, Train Acc: 0.832051 | Val Loss: 0.126152, Val Acc: 0.773196\n",
      "Epoch 13997 - Train Loss: 0.105092, Train Acc: 0.832051 | Val Loss: 0.126149, Val Acc: 0.773196\n",
      "Epoch 13998 - Train Loss: 0.105088, Train Acc: 0.832051 | Val Loss: 0.126146, Val Acc: 0.773196\n",
      "Epoch 13999 - Train Loss: 0.105083, Train Acc: 0.832051 | Val Loss: 0.126143, Val Acc: 0.773196\n",
      "Epoch 14000 - Train Loss: 0.105079, Train Acc: 0.832051 | Val Loss: 0.126140, Val Acc: 0.773196\n",
      "Epoch 14001 - Train Loss: 0.105075, Train Acc: 0.832051 | Val Loss: 0.126137, Val Acc: 0.773196\n",
      "Epoch 14002 - Train Loss: 0.105070, Train Acc: 0.832051 | Val Loss: 0.126134, Val Acc: 0.773196\n",
      "Epoch 14003 - Train Loss: 0.105066, Train Acc: 0.832051 | Val Loss: 0.126131, Val Acc: 0.773196\n",
      "Epoch 14004 - Train Loss: 0.105062, Train Acc: 0.832051 | Val Loss: 0.126128, Val Acc: 0.773196\n",
      "Epoch 14005 - Train Loss: 0.105057, Train Acc: 0.832051 | Val Loss: 0.126125, Val Acc: 0.773196\n",
      "Epoch 14006 - Train Loss: 0.105053, Train Acc: 0.832051 | Val Loss: 0.126121, Val Acc: 0.773196\n",
      "Epoch 14007 - Train Loss: 0.105049, Train Acc: 0.832051 | Val Loss: 0.126118, Val Acc: 0.773196\n",
      "Epoch 14008 - Train Loss: 0.105044, Train Acc: 0.832051 | Val Loss: 0.126115, Val Acc: 0.773196\n",
      "Epoch 14009 - Train Loss: 0.105040, Train Acc: 0.832051 | Val Loss: 0.126112, Val Acc: 0.773196\n",
      "Epoch 14010 - Train Loss: 0.105035, Train Acc: 0.832051 | Val Loss: 0.126109, Val Acc: 0.773196\n",
      "Epoch 14011 - Train Loss: 0.105031, Train Acc: 0.832051 | Val Loss: 0.126106, Val Acc: 0.773196\n",
      "Epoch 14012 - Train Loss: 0.105027, Train Acc: 0.832051 | Val Loss: 0.126103, Val Acc: 0.773196\n",
      "Epoch 14013 - Train Loss: 0.105022, Train Acc: 0.832051 | Val Loss: 0.126100, Val Acc: 0.773196\n",
      "Epoch 14014 - Train Loss: 0.105018, Train Acc: 0.832051 | Val Loss: 0.126097, Val Acc: 0.773196\n",
      "Epoch 14015 - Train Loss: 0.105014, Train Acc: 0.833333 | Val Loss: 0.126094, Val Acc: 0.773196\n",
      "Epoch 14016 - Train Loss: 0.105009, Train Acc: 0.833333 | Val Loss: 0.126091, Val Acc: 0.773196\n",
      "Epoch 14017 - Train Loss: 0.105005, Train Acc: 0.833333 | Val Loss: 0.126088, Val Acc: 0.773196\n",
      "Epoch 14018 - Train Loss: 0.105001, Train Acc: 0.833333 | Val Loss: 0.126084, Val Acc: 0.773196\n",
      "Epoch 14019 - Train Loss: 0.104996, Train Acc: 0.833333 | Val Loss: 0.126081, Val Acc: 0.773196\n",
      "Epoch 14020 - Train Loss: 0.104992, Train Acc: 0.833333 | Val Loss: 0.126078, Val Acc: 0.773196\n",
      "Epoch 14021 - Train Loss: 0.104988, Train Acc: 0.833333 | Val Loss: 0.126075, Val Acc: 0.773196\n",
      "Epoch 14022 - Train Loss: 0.104983, Train Acc: 0.833333 | Val Loss: 0.126072, Val Acc: 0.773196\n",
      "Epoch 14023 - Train Loss: 0.104979, Train Acc: 0.833333 | Val Loss: 0.126069, Val Acc: 0.773196\n",
      "Epoch 14024 - Train Loss: 0.104975, Train Acc: 0.833333 | Val Loss: 0.126066, Val Acc: 0.773196\n",
      "Epoch 14025 - Train Loss: 0.104970, Train Acc: 0.833333 | Val Loss: 0.126063, Val Acc: 0.773196\n",
      "Epoch 14026 - Train Loss: 0.104966, Train Acc: 0.833333 | Val Loss: 0.126060, Val Acc: 0.773196\n",
      "Epoch 14027 - Train Loss: 0.104962, Train Acc: 0.833333 | Val Loss: 0.126057, Val Acc: 0.773196\n",
      "Epoch 14028 - Train Loss: 0.104957, Train Acc: 0.833333 | Val Loss: 0.126054, Val Acc: 0.773196\n",
      "Epoch 14029 - Train Loss: 0.104953, Train Acc: 0.833333 | Val Loss: 0.126051, Val Acc: 0.773196\n",
      "Epoch 14030 - Train Loss: 0.104949, Train Acc: 0.833333 | Val Loss: 0.126048, Val Acc: 0.773196\n",
      "Epoch 14031 - Train Loss: 0.104944, Train Acc: 0.834615 | Val Loss: 0.126045, Val Acc: 0.773196\n",
      "Epoch 14032 - Train Loss: 0.104940, Train Acc: 0.834615 | Val Loss: 0.126041, Val Acc: 0.773196\n",
      "Epoch 14033 - Train Loss: 0.104936, Train Acc: 0.834615 | Val Loss: 0.126038, Val Acc: 0.773196\n",
      "Epoch 14034 - Train Loss: 0.104931, Train Acc: 0.834615 | Val Loss: 0.126035, Val Acc: 0.773196\n",
      "Epoch 14035 - Train Loss: 0.104927, Train Acc: 0.834615 | Val Loss: 0.126032, Val Acc: 0.773196\n",
      "Epoch 14036 - Train Loss: 0.104923, Train Acc: 0.834615 | Val Loss: 0.126029, Val Acc: 0.773196\n",
      "Epoch 14037 - Train Loss: 0.104918, Train Acc: 0.834615 | Val Loss: 0.126026, Val Acc: 0.773196\n",
      "Epoch 14038 - Train Loss: 0.104914, Train Acc: 0.834615 | Val Loss: 0.126023, Val Acc: 0.773196\n",
      "Epoch 14039 - Train Loss: 0.104910, Train Acc: 0.834615 | Val Loss: 0.126020, Val Acc: 0.773196\n",
      "Epoch 14040 - Train Loss: 0.104905, Train Acc: 0.834615 | Val Loss: 0.126017, Val Acc: 0.773196\n",
      "Epoch 14041 - Train Loss: 0.104901, Train Acc: 0.834615 | Val Loss: 0.126014, Val Acc: 0.773196\n",
      "Epoch 14042 - Train Loss: 0.104897, Train Acc: 0.834615 | Val Loss: 0.126011, Val Acc: 0.773196\n",
      "Epoch 14043 - Train Loss: 0.104892, Train Acc: 0.834615 | Val Loss: 0.126008, Val Acc: 0.773196\n",
      "Epoch 14044 - Train Loss: 0.104888, Train Acc: 0.834615 | Val Loss: 0.126005, Val Acc: 0.773196\n",
      "Epoch 14045 - Train Loss: 0.104884, Train Acc: 0.834615 | Val Loss: 0.126002, Val Acc: 0.773196\n",
      "Epoch 14046 - Train Loss: 0.104879, Train Acc: 0.834615 | Val Loss: 0.125999, Val Acc: 0.773196\n",
      "Epoch 14047 - Train Loss: 0.104875, Train Acc: 0.834615 | Val Loss: 0.125995, Val Acc: 0.773196\n",
      "Epoch 14048 - Train Loss: 0.104871, Train Acc: 0.834615 | Val Loss: 0.125992, Val Acc: 0.773196\n",
      "Epoch 14049 - Train Loss: 0.104866, Train Acc: 0.834615 | Val Loss: 0.125989, Val Acc: 0.773196\n",
      "Epoch 14050 - Train Loss: 0.104862, Train Acc: 0.834615 | Val Loss: 0.125986, Val Acc: 0.773196\n",
      "Epoch 14051 - Train Loss: 0.104858, Train Acc: 0.834615 | Val Loss: 0.125983, Val Acc: 0.773196\n",
      "Epoch 14052 - Train Loss: 0.104853, Train Acc: 0.834615 | Val Loss: 0.125980, Val Acc: 0.773196\n",
      "Epoch 14053 - Train Loss: 0.104849, Train Acc: 0.834615 | Val Loss: 0.125977, Val Acc: 0.773196\n",
      "Epoch 14054 - Train Loss: 0.104845, Train Acc: 0.834615 | Val Loss: 0.125974, Val Acc: 0.773196\n",
      "Epoch 14055 - Train Loss: 0.104840, Train Acc: 0.834615 | Val Loss: 0.125971, Val Acc: 0.773196\n",
      "Epoch 14056 - Train Loss: 0.104836, Train Acc: 0.834615 | Val Loss: 0.125968, Val Acc: 0.773196\n",
      "Epoch 14057 - Train Loss: 0.104832, Train Acc: 0.834615 | Val Loss: 0.125965, Val Acc: 0.773196\n",
      "Epoch 14058 - Train Loss: 0.104827, Train Acc: 0.834615 | Val Loss: 0.125962, Val Acc: 0.773196\n",
      "Epoch 14059 - Train Loss: 0.104823, Train Acc: 0.834615 | Val Loss: 0.125959, Val Acc: 0.773196\n",
      "Epoch 14060 - Train Loss: 0.104819, Train Acc: 0.834615 | Val Loss: 0.125956, Val Acc: 0.773196\n",
      "Epoch 14061 - Train Loss: 0.104814, Train Acc: 0.834615 | Val Loss: 0.125953, Val Acc: 0.773196\n",
      "Epoch 14062 - Train Loss: 0.104810, Train Acc: 0.834615 | Val Loss: 0.125950, Val Acc: 0.773196\n",
      "Epoch 14063 - Train Loss: 0.104806, Train Acc: 0.834615 | Val Loss: 0.125947, Val Acc: 0.773196\n",
      "Epoch 14064 - Train Loss: 0.104801, Train Acc: 0.834615 | Val Loss: 0.125944, Val Acc: 0.773196\n",
      "Epoch 14065 - Train Loss: 0.104797, Train Acc: 0.834615 | Val Loss: 0.125941, Val Acc: 0.773196\n",
      "Epoch 14066 - Train Loss: 0.104793, Train Acc: 0.834615 | Val Loss: 0.125937, Val Acc: 0.773196\n",
      "Epoch 14067 - Train Loss: 0.104788, Train Acc: 0.834615 | Val Loss: 0.125934, Val Acc: 0.773196\n",
      "Epoch 14068 - Train Loss: 0.104784, Train Acc: 0.834615 | Val Loss: 0.125931, Val Acc: 0.773196\n",
      "Epoch 14069 - Train Loss: 0.104780, Train Acc: 0.834615 | Val Loss: 0.125928, Val Acc: 0.773196\n",
      "Epoch 14070 - Train Loss: 0.104775, Train Acc: 0.834615 | Val Loss: 0.125925, Val Acc: 0.773196\n",
      "Epoch 14071 - Train Loss: 0.104771, Train Acc: 0.834615 | Val Loss: 0.125922, Val Acc: 0.773196\n",
      "Epoch 14072 - Train Loss: 0.104767, Train Acc: 0.834615 | Val Loss: 0.125919, Val Acc: 0.773196\n",
      "Epoch 14073 - Train Loss: 0.104763, Train Acc: 0.834615 | Val Loss: 0.125916, Val Acc: 0.773196\n",
      "Epoch 14074 - Train Loss: 0.104758, Train Acc: 0.834615 | Val Loss: 0.125913, Val Acc: 0.773196\n",
      "Epoch 14075 - Train Loss: 0.104754, Train Acc: 0.834615 | Val Loss: 0.125910, Val Acc: 0.773196\n",
      "Epoch 14076 - Train Loss: 0.104750, Train Acc: 0.834615 | Val Loss: 0.125907, Val Acc: 0.773196\n",
      "Epoch 14077 - Train Loss: 0.104745, Train Acc: 0.834615 | Val Loss: 0.125904, Val Acc: 0.773196\n",
      "Epoch 14078 - Train Loss: 0.104741, Train Acc: 0.834615 | Val Loss: 0.125901, Val Acc: 0.773196\n",
      "Epoch 14079 - Train Loss: 0.104737, Train Acc: 0.834615 | Val Loss: 0.125898, Val Acc: 0.773196\n",
      "Epoch 14080 - Train Loss: 0.104732, Train Acc: 0.834615 | Val Loss: 0.125895, Val Acc: 0.773196\n",
      "Epoch 14081 - Train Loss: 0.104728, Train Acc: 0.834615 | Val Loss: 0.125892, Val Acc: 0.773196\n",
      "Epoch 14082 - Train Loss: 0.104724, Train Acc: 0.834615 | Val Loss: 0.125889, Val Acc: 0.773196\n",
      "Epoch 14083 - Train Loss: 0.104719, Train Acc: 0.834615 | Val Loss: 0.125886, Val Acc: 0.773196\n",
      "Epoch 14084 - Train Loss: 0.104715, Train Acc: 0.834615 | Val Loss: 0.125883, Val Acc: 0.773196\n",
      "Epoch 14085 - Train Loss: 0.104711, Train Acc: 0.834615 | Val Loss: 0.125880, Val Acc: 0.773196\n",
      "Epoch 14086 - Train Loss: 0.104707, Train Acc: 0.834615 | Val Loss: 0.125877, Val Acc: 0.773196\n",
      "Epoch 14087 - Train Loss: 0.104702, Train Acc: 0.834615 | Val Loss: 0.125874, Val Acc: 0.773196\n",
      "Epoch 14088 - Train Loss: 0.104698, Train Acc: 0.834615 | Val Loss: 0.125871, Val Acc: 0.773196\n",
      "Epoch 14089 - Train Loss: 0.104694, Train Acc: 0.834615 | Val Loss: 0.125868, Val Acc: 0.773196\n",
      "Epoch 14090 - Train Loss: 0.104689, Train Acc: 0.834615 | Val Loss: 0.125865, Val Acc: 0.773196\n",
      "Epoch 14091 - Train Loss: 0.104685, Train Acc: 0.834615 | Val Loss: 0.125861, Val Acc: 0.773196\n",
      "Epoch 14092 - Train Loss: 0.104681, Train Acc: 0.834615 | Val Loss: 0.125858, Val Acc: 0.773196\n",
      "Epoch 14093 - Train Loss: 0.104676, Train Acc: 0.834615 | Val Loss: 0.125855, Val Acc: 0.773196\n",
      "Epoch 14094 - Train Loss: 0.104672, Train Acc: 0.834615 | Val Loss: 0.125852, Val Acc: 0.773196\n",
      "Epoch 14095 - Train Loss: 0.104668, Train Acc: 0.834615 | Val Loss: 0.125849, Val Acc: 0.773196\n",
      "Epoch 14096 - Train Loss: 0.104664, Train Acc: 0.834615 | Val Loss: 0.125846, Val Acc: 0.773196\n",
      "Epoch 14097 - Train Loss: 0.104659, Train Acc: 0.834615 | Val Loss: 0.125843, Val Acc: 0.773196\n",
      "Epoch 14098 - Train Loss: 0.104655, Train Acc: 0.834615 | Val Loss: 0.125840, Val Acc: 0.773196\n",
      "Epoch 14099 - Train Loss: 0.104651, Train Acc: 0.834615 | Val Loss: 0.125837, Val Acc: 0.773196\n",
      "Epoch 14100 - Train Loss: 0.104646, Train Acc: 0.834615 | Val Loss: 0.125834, Val Acc: 0.773196\n",
      "Epoch 14101 - Train Loss: 0.104642, Train Acc: 0.834615 | Val Loss: 0.125831, Val Acc: 0.773196\n",
      "Epoch 14102 - Train Loss: 0.104638, Train Acc: 0.834615 | Val Loss: 0.125828, Val Acc: 0.773196\n",
      "Epoch 14103 - Train Loss: 0.104633, Train Acc: 0.834615 | Val Loss: 0.125825, Val Acc: 0.773196\n",
      "Epoch 14104 - Train Loss: 0.104629, Train Acc: 0.834615 | Val Loss: 0.125822, Val Acc: 0.773196\n",
      "Epoch 14105 - Train Loss: 0.104625, Train Acc: 0.834615 | Val Loss: 0.125819, Val Acc: 0.773196\n",
      "Epoch 14106 - Train Loss: 0.104621, Train Acc: 0.834615 | Val Loss: 0.125816, Val Acc: 0.773196\n",
      "Epoch 14107 - Train Loss: 0.104616, Train Acc: 0.834615 | Val Loss: 0.125813, Val Acc: 0.773196\n",
      "Epoch 14108 - Train Loss: 0.104612, Train Acc: 0.834615 | Val Loss: 0.125810, Val Acc: 0.773196\n",
      "Epoch 14109 - Train Loss: 0.104608, Train Acc: 0.834615 | Val Loss: 0.125807, Val Acc: 0.773196\n",
      "Epoch 14110 - Train Loss: 0.104603, Train Acc: 0.834615 | Val Loss: 0.125804, Val Acc: 0.773196\n",
      "Epoch 14111 - Train Loss: 0.104599, Train Acc: 0.834615 | Val Loss: 0.125801, Val Acc: 0.773196\n",
      "Epoch 14112 - Train Loss: 0.104595, Train Acc: 0.834615 | Val Loss: 0.125798, Val Acc: 0.773196\n",
      "Epoch 14113 - Train Loss: 0.104591, Train Acc: 0.834615 | Val Loss: 0.125795, Val Acc: 0.773196\n",
      "Epoch 14114 - Train Loss: 0.104586, Train Acc: 0.834615 | Val Loss: 0.125792, Val Acc: 0.773196\n",
      "Epoch 14115 - Train Loss: 0.104582, Train Acc: 0.834615 | Val Loss: 0.125789, Val Acc: 0.773196\n",
      "Epoch 14116 - Train Loss: 0.104578, Train Acc: 0.834615 | Val Loss: 0.125786, Val Acc: 0.773196\n",
      "Epoch 14117 - Train Loss: 0.104573, Train Acc: 0.834615 | Val Loss: 0.125783, Val Acc: 0.773196\n",
      "Epoch 14118 - Train Loss: 0.104569, Train Acc: 0.834615 | Val Loss: 0.125780, Val Acc: 0.773196\n",
      "Epoch 14119 - Train Loss: 0.104565, Train Acc: 0.834615 | Val Loss: 0.125777, Val Acc: 0.773196\n",
      "Epoch 14120 - Train Loss: 0.104561, Train Acc: 0.834615 | Val Loss: 0.125774, Val Acc: 0.773196\n",
      "Epoch 14121 - Train Loss: 0.104556, Train Acc: 0.834615 | Val Loss: 0.125771, Val Acc: 0.773196\n",
      "Epoch 14122 - Train Loss: 0.104552, Train Acc: 0.834615 | Val Loss: 0.125768, Val Acc: 0.773196\n",
      "Epoch 14123 - Train Loss: 0.104548, Train Acc: 0.834615 | Val Loss: 0.125765, Val Acc: 0.773196\n",
      "Epoch 14124 - Train Loss: 0.104543, Train Acc: 0.834615 | Val Loss: 0.125762, Val Acc: 0.773196\n",
      "Epoch 14125 - Train Loss: 0.104539, Train Acc: 0.834615 | Val Loss: 0.125759, Val Acc: 0.773196\n",
      "Epoch 14126 - Train Loss: 0.104535, Train Acc: 0.834615 | Val Loss: 0.125756, Val Acc: 0.773196\n",
      "Epoch 14127 - Train Loss: 0.104531, Train Acc: 0.834615 | Val Loss: 0.125753, Val Acc: 0.773196\n",
      "Epoch 14128 - Train Loss: 0.104526, Train Acc: 0.834615 | Val Loss: 0.125750, Val Acc: 0.773196\n",
      "Epoch 14129 - Train Loss: 0.104522, Train Acc: 0.834615 | Val Loss: 0.125747, Val Acc: 0.773196\n",
      "Epoch 14130 - Train Loss: 0.104518, Train Acc: 0.834615 | Val Loss: 0.125744, Val Acc: 0.773196\n",
      "Epoch 14131 - Train Loss: 0.104513, Train Acc: 0.834615 | Val Loss: 0.125741, Val Acc: 0.773196\n",
      "Epoch 14132 - Train Loss: 0.104509, Train Acc: 0.834615 | Val Loss: 0.125738, Val Acc: 0.773196\n",
      "Epoch 14133 - Train Loss: 0.104505, Train Acc: 0.834615 | Val Loss: 0.125735, Val Acc: 0.773196\n",
      "Epoch 14134 - Train Loss: 0.104501, Train Acc: 0.834615 | Val Loss: 0.125732, Val Acc: 0.773196\n",
      "Epoch 14135 - Train Loss: 0.104496, Train Acc: 0.834615 | Val Loss: 0.125729, Val Acc: 0.773196\n",
      "Epoch 14136 - Train Loss: 0.104492, Train Acc: 0.834615 | Val Loss: 0.125726, Val Acc: 0.773196\n",
      "Epoch 14137 - Train Loss: 0.104488, Train Acc: 0.834615 | Val Loss: 0.125723, Val Acc: 0.773196\n",
      "Epoch 14138 - Train Loss: 0.104484, Train Acc: 0.834615 | Val Loss: 0.125720, Val Acc: 0.773196\n",
      "Epoch 14139 - Train Loss: 0.104479, Train Acc: 0.834615 | Val Loss: 0.125717, Val Acc: 0.773196\n",
      "Epoch 14140 - Train Loss: 0.104475, Train Acc: 0.834615 | Val Loss: 0.125714, Val Acc: 0.773196\n",
      "Epoch 14141 - Train Loss: 0.104471, Train Acc: 0.834615 | Val Loss: 0.125711, Val Acc: 0.773196\n",
      "Epoch 14142 - Train Loss: 0.104466, Train Acc: 0.834615 | Val Loss: 0.125708, Val Acc: 0.773196\n",
      "Epoch 14143 - Train Loss: 0.104462, Train Acc: 0.834615 | Val Loss: 0.125705, Val Acc: 0.773196\n",
      "Epoch 14144 - Train Loss: 0.104458, Train Acc: 0.834615 | Val Loss: 0.125702, Val Acc: 0.773196\n",
      "Epoch 14145 - Train Loss: 0.104454, Train Acc: 0.834615 | Val Loss: 0.125699, Val Acc: 0.773196\n",
      "Epoch 14146 - Train Loss: 0.104449, Train Acc: 0.834615 | Val Loss: 0.125696, Val Acc: 0.773196\n",
      "Epoch 14147 - Train Loss: 0.104445, Train Acc: 0.834615 | Val Loss: 0.125693, Val Acc: 0.773196\n",
      "Epoch 14148 - Train Loss: 0.104441, Train Acc: 0.834615 | Val Loss: 0.125690, Val Acc: 0.773196\n",
      "Epoch 14149 - Train Loss: 0.104437, Train Acc: 0.834615 | Val Loss: 0.125687, Val Acc: 0.773196\n",
      "Epoch 14150 - Train Loss: 0.104432, Train Acc: 0.834615 | Val Loss: 0.125684, Val Acc: 0.773196\n",
      "Epoch 14151 - Train Loss: 0.104428, Train Acc: 0.834615 | Val Loss: 0.125681, Val Acc: 0.773196\n",
      "Epoch 14152 - Train Loss: 0.104424, Train Acc: 0.834615 | Val Loss: 0.125678, Val Acc: 0.773196\n",
      "Epoch 14153 - Train Loss: 0.104420, Train Acc: 0.834615 | Val Loss: 0.125675, Val Acc: 0.773196\n",
      "Epoch 14154 - Train Loss: 0.104415, Train Acc: 0.834615 | Val Loss: 0.125672, Val Acc: 0.773196\n",
      "Epoch 14155 - Train Loss: 0.104411, Train Acc: 0.834615 | Val Loss: 0.125669, Val Acc: 0.773196\n",
      "Epoch 14156 - Train Loss: 0.104407, Train Acc: 0.834615 | Val Loss: 0.125666, Val Acc: 0.773196\n",
      "Epoch 14157 - Train Loss: 0.104402, Train Acc: 0.834615 | Val Loss: 0.125663, Val Acc: 0.773196\n",
      "Epoch 14158 - Train Loss: 0.104398, Train Acc: 0.834615 | Val Loss: 0.125660, Val Acc: 0.773196\n",
      "Epoch 14159 - Train Loss: 0.104394, Train Acc: 0.834615 | Val Loss: 0.125657, Val Acc: 0.773196\n",
      "Epoch 14160 - Train Loss: 0.104390, Train Acc: 0.834615 | Val Loss: 0.125654, Val Acc: 0.773196\n",
      "Epoch 14161 - Train Loss: 0.104385, Train Acc: 0.834615 | Val Loss: 0.125651, Val Acc: 0.773196\n",
      "Epoch 14162 - Train Loss: 0.104381, Train Acc: 0.834615 | Val Loss: 0.125648, Val Acc: 0.773196\n",
      "Epoch 14163 - Train Loss: 0.104377, Train Acc: 0.834615 | Val Loss: 0.125645, Val Acc: 0.773196\n",
      "Epoch 14164 - Train Loss: 0.104373, Train Acc: 0.834615 | Val Loss: 0.125642, Val Acc: 0.773196\n",
      "Epoch 14165 - Train Loss: 0.104368, Train Acc: 0.834615 | Val Loss: 0.125639, Val Acc: 0.773196\n",
      "Epoch 14166 - Train Loss: 0.104364, Train Acc: 0.834615 | Val Loss: 0.125636, Val Acc: 0.773196\n",
      "Epoch 14167 - Train Loss: 0.104360, Train Acc: 0.834615 | Val Loss: 0.125633, Val Acc: 0.773196\n",
      "Epoch 14168 - Train Loss: 0.104356, Train Acc: 0.834615 | Val Loss: 0.125630, Val Acc: 0.773196\n",
      "Epoch 14169 - Train Loss: 0.104351, Train Acc: 0.834615 | Val Loss: 0.125627, Val Acc: 0.773196\n",
      "Epoch 14170 - Train Loss: 0.104347, Train Acc: 0.834615 | Val Loss: 0.125624, Val Acc: 0.773196\n",
      "Epoch 14171 - Train Loss: 0.104343, Train Acc: 0.834615 | Val Loss: 0.125621, Val Acc: 0.773196\n",
      "Epoch 14172 - Train Loss: 0.104339, Train Acc: 0.834615 | Val Loss: 0.125618, Val Acc: 0.773196\n",
      "Epoch 14173 - Train Loss: 0.104334, Train Acc: 0.834615 | Val Loss: 0.125615, Val Acc: 0.773196\n",
      "Epoch 14174 - Train Loss: 0.104330, Train Acc: 0.834615 | Val Loss: 0.125612, Val Acc: 0.773196\n",
      "Epoch 14175 - Train Loss: 0.104326, Train Acc: 0.834615 | Val Loss: 0.125609, Val Acc: 0.773196\n",
      "Epoch 14176 - Train Loss: 0.104322, Train Acc: 0.834615 | Val Loss: 0.125606, Val Acc: 0.773196\n",
      "Epoch 14177 - Train Loss: 0.104317, Train Acc: 0.835897 | Val Loss: 0.125603, Val Acc: 0.773196\n",
      "Epoch 14178 - Train Loss: 0.104313, Train Acc: 0.835897 | Val Loss: 0.125600, Val Acc: 0.773196\n",
      "Epoch 14179 - Train Loss: 0.104309, Train Acc: 0.835897 | Val Loss: 0.125597, Val Acc: 0.773196\n",
      "Epoch 14180 - Train Loss: 0.104305, Train Acc: 0.835897 | Val Loss: 0.125594, Val Acc: 0.773196\n",
      "Epoch 14181 - Train Loss: 0.104300, Train Acc: 0.835897 | Val Loss: 0.125591, Val Acc: 0.773196\n",
      "Epoch 14182 - Train Loss: 0.104296, Train Acc: 0.835897 | Val Loss: 0.125588, Val Acc: 0.773196\n",
      "Epoch 14183 - Train Loss: 0.104292, Train Acc: 0.835897 | Val Loss: 0.125585, Val Acc: 0.773196\n",
      "Epoch 14184 - Train Loss: 0.104288, Train Acc: 0.835897 | Val Loss: 0.125582, Val Acc: 0.773196\n",
      "Epoch 14185 - Train Loss: 0.104283, Train Acc: 0.835897 | Val Loss: 0.125579, Val Acc: 0.773196\n",
      "Epoch 14186 - Train Loss: 0.104279, Train Acc: 0.835897 | Val Loss: 0.125576, Val Acc: 0.773196\n",
      "Epoch 14187 - Train Loss: 0.104275, Train Acc: 0.835897 | Val Loss: 0.125573, Val Acc: 0.773196\n",
      "Epoch 14188 - Train Loss: 0.104271, Train Acc: 0.835897 | Val Loss: 0.125570, Val Acc: 0.773196\n",
      "Epoch 14189 - Train Loss: 0.104266, Train Acc: 0.835897 | Val Loss: 0.125567, Val Acc: 0.773196\n",
      "Epoch 14190 - Train Loss: 0.104262, Train Acc: 0.835897 | Val Loss: 0.125564, Val Acc: 0.773196\n",
      "Epoch 14191 - Train Loss: 0.104258, Train Acc: 0.835897 | Val Loss: 0.125561, Val Acc: 0.773196\n",
      "Epoch 14192 - Train Loss: 0.104254, Train Acc: 0.835897 | Val Loss: 0.125558, Val Acc: 0.773196\n",
      "Epoch 14193 - Train Loss: 0.104249, Train Acc: 0.835897 | Val Loss: 0.125555, Val Acc: 0.773196\n",
      "Epoch 14194 - Train Loss: 0.104245, Train Acc: 0.835897 | Val Loss: 0.125552, Val Acc: 0.773196\n",
      "Epoch 14195 - Train Loss: 0.104241, Train Acc: 0.835897 | Val Loss: 0.125549, Val Acc: 0.773196\n",
      "Epoch 14196 - Train Loss: 0.104237, Train Acc: 0.835897 | Val Loss: 0.125546, Val Acc: 0.773196\n",
      "Epoch 14197 - Train Loss: 0.104232, Train Acc: 0.835897 | Val Loss: 0.125543, Val Acc: 0.773196\n",
      "Epoch 14198 - Train Loss: 0.104228, Train Acc: 0.835897 | Val Loss: 0.125541, Val Acc: 0.773196\n",
      "Epoch 14199 - Train Loss: 0.104224, Train Acc: 0.835897 | Val Loss: 0.125538, Val Acc: 0.773196\n",
      "Epoch 14200 - Train Loss: 0.104220, Train Acc: 0.835897 | Val Loss: 0.125535, Val Acc: 0.773196\n",
      "Epoch 14201 - Train Loss: 0.104216, Train Acc: 0.835897 | Val Loss: 0.125532, Val Acc: 0.773196\n",
      "Epoch 14202 - Train Loss: 0.104211, Train Acc: 0.835897 | Val Loss: 0.125529, Val Acc: 0.773196\n",
      "Epoch 14203 - Train Loss: 0.104207, Train Acc: 0.835897 | Val Loss: 0.125526, Val Acc: 0.773196\n",
      "Epoch 14204 - Train Loss: 0.104203, Train Acc: 0.835897 | Val Loss: 0.125523, Val Acc: 0.773196\n",
      "Epoch 14205 - Train Loss: 0.104199, Train Acc: 0.835897 | Val Loss: 0.125520, Val Acc: 0.773196\n",
      "Epoch 14206 - Train Loss: 0.104194, Train Acc: 0.835897 | Val Loss: 0.125517, Val Acc: 0.773196\n",
      "Epoch 14207 - Train Loss: 0.104190, Train Acc: 0.835897 | Val Loss: 0.125514, Val Acc: 0.773196\n",
      "Epoch 14208 - Train Loss: 0.104186, Train Acc: 0.837179 | Val Loss: 0.125511, Val Acc: 0.773196\n",
      "Epoch 14209 - Train Loss: 0.104182, Train Acc: 0.837179 | Val Loss: 0.125508, Val Acc: 0.773196\n",
      "Epoch 14210 - Train Loss: 0.104177, Train Acc: 0.837179 | Val Loss: 0.125505, Val Acc: 0.773196\n",
      "Epoch 14211 - Train Loss: 0.104173, Train Acc: 0.837179 | Val Loss: 0.125502, Val Acc: 0.773196\n",
      "Epoch 14212 - Train Loss: 0.104169, Train Acc: 0.837179 | Val Loss: 0.125499, Val Acc: 0.773196\n",
      "Epoch 14213 - Train Loss: 0.104165, Train Acc: 0.837179 | Val Loss: 0.125496, Val Acc: 0.773196\n",
      "Epoch 14214 - Train Loss: 0.104161, Train Acc: 0.837179 | Val Loss: 0.125493, Val Acc: 0.773196\n",
      "Epoch 14215 - Train Loss: 0.104156, Train Acc: 0.837179 | Val Loss: 0.125490, Val Acc: 0.773196\n",
      "Epoch 14216 - Train Loss: 0.104152, Train Acc: 0.837179 | Val Loss: 0.125487, Val Acc: 0.773196\n",
      "Epoch 14217 - Train Loss: 0.104148, Train Acc: 0.837179 | Val Loss: 0.125484, Val Acc: 0.773196\n",
      "Epoch 14218 - Train Loss: 0.104144, Train Acc: 0.837179 | Val Loss: 0.125481, Val Acc: 0.773196\n",
      "Epoch 14219 - Train Loss: 0.104139, Train Acc: 0.837179 | Val Loss: 0.125478, Val Acc: 0.773196\n",
      "Epoch 14220 - Train Loss: 0.104135, Train Acc: 0.837179 | Val Loss: 0.125475, Val Acc: 0.773196\n",
      "Epoch 14221 - Train Loss: 0.104131, Train Acc: 0.837179 | Val Loss: 0.125472, Val Acc: 0.773196\n",
      "Epoch 14222 - Train Loss: 0.104127, Train Acc: 0.837179 | Val Loss: 0.125469, Val Acc: 0.773196\n",
      "Epoch 14223 - Train Loss: 0.104123, Train Acc: 0.837179 | Val Loss: 0.125467, Val Acc: 0.773196\n",
      "Epoch 14224 - Train Loss: 0.104118, Train Acc: 0.837179 | Val Loss: 0.125464, Val Acc: 0.773196\n",
      "Epoch 14225 - Train Loss: 0.104114, Train Acc: 0.837179 | Val Loss: 0.125461, Val Acc: 0.773196\n",
      "Epoch 14226 - Train Loss: 0.104110, Train Acc: 0.837179 | Val Loss: 0.125458, Val Acc: 0.773196\n",
      "Epoch 14227 - Train Loss: 0.104106, Train Acc: 0.837179 | Val Loss: 0.125455, Val Acc: 0.773196\n",
      "Epoch 14228 - Train Loss: 0.104101, Train Acc: 0.837179 | Val Loss: 0.125452, Val Acc: 0.773196\n",
      "Epoch 14229 - Train Loss: 0.104097, Train Acc: 0.837179 | Val Loss: 0.125449, Val Acc: 0.773196\n",
      "Epoch 14230 - Train Loss: 0.104093, Train Acc: 0.837179 | Val Loss: 0.125446, Val Acc: 0.773196\n",
      "Epoch 14231 - Train Loss: 0.104089, Train Acc: 0.837179 | Val Loss: 0.125443, Val Acc: 0.773196\n",
      "Epoch 14232 - Train Loss: 0.104085, Train Acc: 0.837179 | Val Loss: 0.125440, Val Acc: 0.773196\n",
      "Epoch 14233 - Train Loss: 0.104080, Train Acc: 0.837179 | Val Loss: 0.125437, Val Acc: 0.773196\n",
      "Epoch 14234 - Train Loss: 0.104076, Train Acc: 0.837179 | Val Loss: 0.125434, Val Acc: 0.773196\n",
      "Epoch 14235 - Train Loss: 0.104072, Train Acc: 0.837179 | Val Loss: 0.125431, Val Acc: 0.773196\n",
      "Epoch 14236 - Train Loss: 0.104068, Train Acc: 0.837179 | Val Loss: 0.125428, Val Acc: 0.773196\n",
      "Epoch 14237 - Train Loss: 0.104063, Train Acc: 0.837179 | Val Loss: 0.125425, Val Acc: 0.773196\n",
      "Epoch 14238 - Train Loss: 0.104059, Train Acc: 0.837179 | Val Loss: 0.125422, Val Acc: 0.773196\n",
      "Epoch 14239 - Train Loss: 0.104055, Train Acc: 0.837179 | Val Loss: 0.125419, Val Acc: 0.773196\n",
      "Epoch 14240 - Train Loss: 0.104051, Train Acc: 0.837179 | Val Loss: 0.125416, Val Acc: 0.773196\n",
      "Epoch 14241 - Train Loss: 0.104047, Train Acc: 0.837179 | Val Loss: 0.125413, Val Acc: 0.773196\n",
      "Epoch 14242 - Train Loss: 0.104042, Train Acc: 0.837179 | Val Loss: 0.125411, Val Acc: 0.773196\n",
      "Epoch 14243 - Train Loss: 0.104038, Train Acc: 0.837179 | Val Loss: 0.125408, Val Acc: 0.773196\n",
      "Epoch 14244 - Train Loss: 0.104034, Train Acc: 0.837179 | Val Loss: 0.125405, Val Acc: 0.773196\n",
      "Epoch 14245 - Train Loss: 0.104030, Train Acc: 0.837179 | Val Loss: 0.125402, Val Acc: 0.773196\n",
      "Epoch 14246 - Train Loss: 0.104026, Train Acc: 0.837179 | Val Loss: 0.125399, Val Acc: 0.773196\n",
      "Epoch 14247 - Train Loss: 0.104021, Train Acc: 0.837179 | Val Loss: 0.125396, Val Acc: 0.773196\n",
      "Epoch 14248 - Train Loss: 0.104017, Train Acc: 0.837179 | Val Loss: 0.125393, Val Acc: 0.773196\n",
      "Epoch 14249 - Train Loss: 0.104013, Train Acc: 0.837179 | Val Loss: 0.125390, Val Acc: 0.773196\n",
      "Epoch 14250 - Train Loss: 0.104009, Train Acc: 0.837179 | Val Loss: 0.125387, Val Acc: 0.773196\n",
      "Epoch 14251 - Train Loss: 0.104005, Train Acc: 0.837179 | Val Loss: 0.125384, Val Acc: 0.773196\n",
      "Epoch 14252 - Train Loss: 0.104000, Train Acc: 0.837179 | Val Loss: 0.125381, Val Acc: 0.773196\n",
      "Epoch 14253 - Train Loss: 0.103996, Train Acc: 0.837179 | Val Loss: 0.125378, Val Acc: 0.773196\n",
      "Epoch 14254 - Train Loss: 0.103992, Train Acc: 0.837179 | Val Loss: 0.125375, Val Acc: 0.773196\n",
      "Epoch 14255 - Train Loss: 0.103988, Train Acc: 0.837179 | Val Loss: 0.125372, Val Acc: 0.773196\n",
      "Epoch 14256 - Train Loss: 0.103984, Train Acc: 0.837179 | Val Loss: 0.125369, Val Acc: 0.773196\n",
      "Epoch 14257 - Train Loss: 0.103979, Train Acc: 0.837179 | Val Loss: 0.125366, Val Acc: 0.773196\n",
      "Epoch 14258 - Train Loss: 0.103975, Train Acc: 0.837179 | Val Loss: 0.125364, Val Acc: 0.773196\n",
      "Epoch 14259 - Train Loss: 0.103971, Train Acc: 0.837179 | Val Loss: 0.125361, Val Acc: 0.773196\n",
      "Epoch 14260 - Train Loss: 0.103967, Train Acc: 0.837179 | Val Loss: 0.125358, Val Acc: 0.773196\n",
      "Epoch 14261 - Train Loss: 0.103963, Train Acc: 0.837179 | Val Loss: 0.125355, Val Acc: 0.773196\n",
      "Epoch 14262 - Train Loss: 0.103958, Train Acc: 0.837179 | Val Loss: 0.125352, Val Acc: 0.773196\n",
      "Epoch 14263 - Train Loss: 0.103954, Train Acc: 0.837179 | Val Loss: 0.125349, Val Acc: 0.773196\n",
      "Epoch 14264 - Train Loss: 0.103950, Train Acc: 0.837179 | Val Loss: 0.125346, Val Acc: 0.773196\n",
      "Epoch 14265 - Train Loss: 0.103946, Train Acc: 0.837179 | Val Loss: 0.125343, Val Acc: 0.773196\n",
      "Epoch 14266 - Train Loss: 0.103942, Train Acc: 0.837179 | Val Loss: 0.125340, Val Acc: 0.773196\n",
      "Epoch 14267 - Train Loss: 0.103937, Train Acc: 0.837179 | Val Loss: 0.125337, Val Acc: 0.773196\n",
      "Epoch 14268 - Train Loss: 0.103933, Train Acc: 0.837179 | Val Loss: 0.125334, Val Acc: 0.773196\n",
      "Epoch 14269 - Train Loss: 0.103929, Train Acc: 0.835897 | Val Loss: 0.125331, Val Acc: 0.773196\n",
      "Epoch 14270 - Train Loss: 0.103925, Train Acc: 0.835897 | Val Loss: 0.125328, Val Acc: 0.773196\n",
      "Epoch 14271 - Train Loss: 0.103921, Train Acc: 0.835897 | Val Loss: 0.125325, Val Acc: 0.773196\n",
      "Epoch 14272 - Train Loss: 0.103916, Train Acc: 0.835897 | Val Loss: 0.125323, Val Acc: 0.773196\n",
      "Epoch 14273 - Train Loss: 0.103912, Train Acc: 0.835897 | Val Loss: 0.125320, Val Acc: 0.773196\n",
      "Epoch 14274 - Train Loss: 0.103908, Train Acc: 0.835897 | Val Loss: 0.125317, Val Acc: 0.773196\n",
      "Epoch 14275 - Train Loss: 0.103904, Train Acc: 0.835897 | Val Loss: 0.125314, Val Acc: 0.773196\n",
      "Epoch 14276 - Train Loss: 0.103900, Train Acc: 0.835897 | Val Loss: 0.125311, Val Acc: 0.773196\n",
      "Epoch 14277 - Train Loss: 0.103895, Train Acc: 0.835897 | Val Loss: 0.125308, Val Acc: 0.773196\n",
      "Epoch 14278 - Train Loss: 0.103891, Train Acc: 0.835897 | Val Loss: 0.125305, Val Acc: 0.773196\n",
      "Epoch 14279 - Train Loss: 0.103887, Train Acc: 0.835897 | Val Loss: 0.125302, Val Acc: 0.773196\n",
      "Epoch 14280 - Train Loss: 0.103883, Train Acc: 0.835897 | Val Loss: 0.125299, Val Acc: 0.773196\n",
      "Epoch 14281 - Train Loss: 0.103879, Train Acc: 0.835897 | Val Loss: 0.125296, Val Acc: 0.773196\n",
      "Epoch 14282 - Train Loss: 0.103875, Train Acc: 0.835897 | Val Loss: 0.125293, Val Acc: 0.773196\n",
      "Epoch 14283 - Train Loss: 0.103870, Train Acc: 0.835897 | Val Loss: 0.125290, Val Acc: 0.773196\n",
      "Epoch 14284 - Train Loss: 0.103866, Train Acc: 0.835897 | Val Loss: 0.125288, Val Acc: 0.773196\n",
      "Epoch 14285 - Train Loss: 0.103862, Train Acc: 0.835897 | Val Loss: 0.125285, Val Acc: 0.773196\n",
      "Epoch 14286 - Train Loss: 0.103858, Train Acc: 0.835897 | Val Loss: 0.125282, Val Acc: 0.773196\n",
      "Epoch 14287 - Train Loss: 0.103854, Train Acc: 0.835897 | Val Loss: 0.125279, Val Acc: 0.773196\n",
      "Epoch 14288 - Train Loss: 0.103849, Train Acc: 0.835897 | Val Loss: 0.125276, Val Acc: 0.773196\n",
      "Epoch 14289 - Train Loss: 0.103845, Train Acc: 0.835897 | Val Loss: 0.125273, Val Acc: 0.773196\n",
      "Epoch 14290 - Train Loss: 0.103841, Train Acc: 0.835897 | Val Loss: 0.125270, Val Acc: 0.773196\n",
      "Epoch 14291 - Train Loss: 0.103837, Train Acc: 0.835897 | Val Loss: 0.125267, Val Acc: 0.773196\n",
      "Epoch 14292 - Train Loss: 0.103833, Train Acc: 0.835897 | Val Loss: 0.125264, Val Acc: 0.773196\n",
      "Epoch 14293 - Train Loss: 0.103828, Train Acc: 0.835897 | Val Loss: 0.125261, Val Acc: 0.773196\n",
      "Epoch 14294 - Train Loss: 0.103824, Train Acc: 0.835897 | Val Loss: 0.125258, Val Acc: 0.773196\n",
      "Epoch 14295 - Train Loss: 0.103820, Train Acc: 0.835897 | Val Loss: 0.125255, Val Acc: 0.773196\n",
      "Epoch 14296 - Train Loss: 0.103816, Train Acc: 0.835897 | Val Loss: 0.125253, Val Acc: 0.773196\n",
      "Epoch 14297 - Train Loss: 0.103812, Train Acc: 0.835897 | Val Loss: 0.125250, Val Acc: 0.773196\n",
      "Epoch 14298 - Train Loss: 0.103808, Train Acc: 0.835897 | Val Loss: 0.125247, Val Acc: 0.773196\n",
      "Epoch 14299 - Train Loss: 0.103803, Train Acc: 0.835897 | Val Loss: 0.125244, Val Acc: 0.773196\n",
      "Epoch 14300 - Train Loss: 0.103799, Train Acc: 0.835897 | Val Loss: 0.125241, Val Acc: 0.773196\n",
      "Epoch 14301 - Train Loss: 0.103795, Train Acc: 0.835897 | Val Loss: 0.125238, Val Acc: 0.773196\n",
      "Epoch 14302 - Train Loss: 0.103791, Train Acc: 0.835897 | Val Loss: 0.125235, Val Acc: 0.773196\n",
      "Epoch 14303 - Train Loss: 0.103787, Train Acc: 0.835897 | Val Loss: 0.125232, Val Acc: 0.773196\n",
      "Epoch 14304 - Train Loss: 0.103783, Train Acc: 0.835897 | Val Loss: 0.125229, Val Acc: 0.773196\n",
      "Epoch 14305 - Train Loss: 0.103778, Train Acc: 0.835897 | Val Loss: 0.125226, Val Acc: 0.773196\n",
      "Epoch 14306 - Train Loss: 0.103774, Train Acc: 0.835897 | Val Loss: 0.125224, Val Acc: 0.773196\n",
      "Epoch 14307 - Train Loss: 0.103770, Train Acc: 0.835897 | Val Loss: 0.125221, Val Acc: 0.773196\n",
      "Epoch 14308 - Train Loss: 0.103766, Train Acc: 0.835897 | Val Loss: 0.125218, Val Acc: 0.773196\n",
      "Epoch 14309 - Train Loss: 0.103762, Train Acc: 0.835897 | Val Loss: 0.125215, Val Acc: 0.773196\n",
      "Epoch 14310 - Train Loss: 0.103758, Train Acc: 0.835897 | Val Loss: 0.125212, Val Acc: 0.773196\n",
      "Epoch 14311 - Train Loss: 0.103753, Train Acc: 0.835897 | Val Loss: 0.125209, Val Acc: 0.773196\n",
      "Epoch 14312 - Train Loss: 0.103749, Train Acc: 0.835897 | Val Loss: 0.125206, Val Acc: 0.773196\n",
      "Epoch 14313 - Train Loss: 0.103745, Train Acc: 0.835897 | Val Loss: 0.125203, Val Acc: 0.773196\n",
      "Epoch 14314 - Train Loss: 0.103741, Train Acc: 0.835897 | Val Loss: 0.125200, Val Acc: 0.773196\n",
      "Epoch 14315 - Train Loss: 0.103737, Train Acc: 0.835897 | Val Loss: 0.125197, Val Acc: 0.773196\n",
      "Epoch 14316 - Train Loss: 0.103733, Train Acc: 0.835897 | Val Loss: 0.125195, Val Acc: 0.773196\n",
      "Epoch 14317 - Train Loss: 0.103728, Train Acc: 0.835897 | Val Loss: 0.125192, Val Acc: 0.773196\n",
      "Epoch 14318 - Train Loss: 0.103724, Train Acc: 0.835897 | Val Loss: 0.125189, Val Acc: 0.773196\n",
      "Epoch 14319 - Train Loss: 0.103720, Train Acc: 0.835897 | Val Loss: 0.125186, Val Acc: 0.773196\n",
      "Epoch 14320 - Train Loss: 0.103716, Train Acc: 0.835897 | Val Loss: 0.125183, Val Acc: 0.773196\n",
      "Epoch 14321 - Train Loss: 0.103712, Train Acc: 0.835897 | Val Loss: 0.125180, Val Acc: 0.773196\n",
      "Epoch 14322 - Train Loss: 0.103708, Train Acc: 0.835897 | Val Loss: 0.125177, Val Acc: 0.773196\n",
      "Epoch 14323 - Train Loss: 0.103703, Train Acc: 0.835897 | Val Loss: 0.125174, Val Acc: 0.773196\n",
      "Epoch 14324 - Train Loss: 0.103699, Train Acc: 0.835897 | Val Loss: 0.125171, Val Acc: 0.773196\n",
      "Epoch 14325 - Train Loss: 0.103695, Train Acc: 0.835897 | Val Loss: 0.125168, Val Acc: 0.773196\n",
      "Epoch 14326 - Train Loss: 0.103691, Train Acc: 0.835897 | Val Loss: 0.125166, Val Acc: 0.773196\n",
      "Epoch 14327 - Train Loss: 0.103687, Train Acc: 0.835897 | Val Loss: 0.125163, Val Acc: 0.773196\n",
      "Epoch 14328 - Train Loss: 0.103683, Train Acc: 0.835897 | Val Loss: 0.125160, Val Acc: 0.773196\n",
      "Epoch 14329 - Train Loss: 0.103678, Train Acc: 0.835897 | Val Loss: 0.125157, Val Acc: 0.773196\n",
      "Epoch 14330 - Train Loss: 0.103674, Train Acc: 0.835897 | Val Loss: 0.125154, Val Acc: 0.773196\n",
      "Epoch 14331 - Train Loss: 0.103670, Train Acc: 0.835897 | Val Loss: 0.125151, Val Acc: 0.773196\n",
      "Epoch 14332 - Train Loss: 0.103666, Train Acc: 0.835897 | Val Loss: 0.125148, Val Acc: 0.773196\n",
      "Epoch 14333 - Train Loss: 0.103662, Train Acc: 0.835897 | Val Loss: 0.125145, Val Acc: 0.773196\n",
      "Epoch 14334 - Train Loss: 0.103658, Train Acc: 0.835897 | Val Loss: 0.125142, Val Acc: 0.773196\n",
      "Epoch 14335 - Train Loss: 0.103653, Train Acc: 0.835897 | Val Loss: 0.125140, Val Acc: 0.773196\n",
      "Epoch 14336 - Train Loss: 0.103649, Train Acc: 0.835897 | Val Loss: 0.125137, Val Acc: 0.773196\n",
      "Epoch 14337 - Train Loss: 0.103645, Train Acc: 0.835897 | Val Loss: 0.125134, Val Acc: 0.773196\n",
      "Epoch 14338 - Train Loss: 0.103641, Train Acc: 0.835897 | Val Loss: 0.125131, Val Acc: 0.773196\n",
      "Epoch 14339 - Train Loss: 0.103637, Train Acc: 0.835897 | Val Loss: 0.125128, Val Acc: 0.773196\n",
      "Epoch 14340 - Train Loss: 0.103633, Train Acc: 0.835897 | Val Loss: 0.125125, Val Acc: 0.773196\n",
      "Epoch 14341 - Train Loss: 0.103629, Train Acc: 0.835897 | Val Loss: 0.125122, Val Acc: 0.773196\n",
      "Epoch 14342 - Train Loss: 0.103624, Train Acc: 0.835897 | Val Loss: 0.125119, Val Acc: 0.773196\n",
      "Epoch 14343 - Train Loss: 0.103620, Train Acc: 0.835897 | Val Loss: 0.125117, Val Acc: 0.773196\n",
      "Epoch 14344 - Train Loss: 0.103616, Train Acc: 0.835897 | Val Loss: 0.125114, Val Acc: 0.773196\n",
      "Epoch 14345 - Train Loss: 0.103612, Train Acc: 0.835897 | Val Loss: 0.125111, Val Acc: 0.773196\n",
      "Epoch 14346 - Train Loss: 0.103608, Train Acc: 0.835897 | Val Loss: 0.125108, Val Acc: 0.773196\n",
      "Epoch 14347 - Train Loss: 0.103604, Train Acc: 0.835897 | Val Loss: 0.125105, Val Acc: 0.773196\n",
      "Epoch 14348 - Train Loss: 0.103599, Train Acc: 0.835897 | Val Loss: 0.125102, Val Acc: 0.773196\n",
      "Epoch 14349 - Train Loss: 0.103595, Train Acc: 0.835897 | Val Loss: 0.125099, Val Acc: 0.773196\n",
      "Epoch 14350 - Train Loss: 0.103591, Train Acc: 0.835897 | Val Loss: 0.125096, Val Acc: 0.773196\n",
      "Epoch 14351 - Train Loss: 0.103587, Train Acc: 0.835897 | Val Loss: 0.125093, Val Acc: 0.773196\n",
      "Epoch 14352 - Train Loss: 0.103583, Train Acc: 0.835897 | Val Loss: 0.125091, Val Acc: 0.773196\n",
      "Epoch 14353 - Train Loss: 0.103579, Train Acc: 0.835897 | Val Loss: 0.125088, Val Acc: 0.773196\n",
      "Epoch 14354 - Train Loss: 0.103575, Train Acc: 0.835897 | Val Loss: 0.125085, Val Acc: 0.773196\n",
      "Epoch 14355 - Train Loss: 0.103570, Train Acc: 0.835897 | Val Loss: 0.125082, Val Acc: 0.773196\n",
      "Epoch 14356 - Train Loss: 0.103566, Train Acc: 0.835897 | Val Loss: 0.125079, Val Acc: 0.773196\n",
      "Epoch 14357 - Train Loss: 0.103562, Train Acc: 0.835897 | Val Loss: 0.125076, Val Acc: 0.773196\n",
      "Epoch 14358 - Train Loss: 0.103558, Train Acc: 0.835897 | Val Loss: 0.125073, Val Acc: 0.773196\n",
      "Epoch 14359 - Train Loss: 0.103554, Train Acc: 0.835897 | Val Loss: 0.125070, Val Acc: 0.773196\n",
      "Epoch 14360 - Train Loss: 0.103550, Train Acc: 0.835897 | Val Loss: 0.125068, Val Acc: 0.773196\n",
      "Epoch 14361 - Train Loss: 0.103546, Train Acc: 0.835897 | Val Loss: 0.125065, Val Acc: 0.773196\n",
      "Epoch 14362 - Train Loss: 0.103541, Train Acc: 0.835897 | Val Loss: 0.125062, Val Acc: 0.773196\n",
      "Epoch 14363 - Train Loss: 0.103537, Train Acc: 0.835897 | Val Loss: 0.125059, Val Acc: 0.773196\n",
      "Epoch 14364 - Train Loss: 0.103533, Train Acc: 0.835897 | Val Loss: 0.125056, Val Acc: 0.773196\n",
      "Epoch 14365 - Train Loss: 0.103529, Train Acc: 0.835897 | Val Loss: 0.125053, Val Acc: 0.773196\n",
      "Epoch 14366 - Train Loss: 0.103525, Train Acc: 0.835897 | Val Loss: 0.125050, Val Acc: 0.773196\n",
      "Epoch 14367 - Train Loss: 0.103521, Train Acc: 0.835897 | Val Loss: 0.125047, Val Acc: 0.773196\n",
      "Epoch 14368 - Train Loss: 0.103517, Train Acc: 0.835897 | Val Loss: 0.125044, Val Acc: 0.773196\n",
      "Epoch 14369 - Train Loss: 0.103513, Train Acc: 0.835897 | Val Loss: 0.125041, Val Acc: 0.773196\n",
      "Epoch 14370 - Train Loss: 0.103508, Train Acc: 0.835897 | Val Loss: 0.125038, Val Acc: 0.773196\n",
      "Epoch 14371 - Train Loss: 0.103504, Train Acc: 0.835897 | Val Loss: 0.125035, Val Acc: 0.773196\n",
      "Epoch 14372 - Train Loss: 0.103500, Train Acc: 0.835897 | Val Loss: 0.125032, Val Acc: 0.773196\n",
      "Epoch 14373 - Train Loss: 0.103496, Train Acc: 0.835897 | Val Loss: 0.125029, Val Acc: 0.773196\n",
      "Epoch 14374 - Train Loss: 0.103492, Train Acc: 0.835897 | Val Loss: 0.125026, Val Acc: 0.773196\n",
      "Epoch 14375 - Train Loss: 0.103488, Train Acc: 0.835897 | Val Loss: 0.125023, Val Acc: 0.773196\n",
      "Epoch 14376 - Train Loss: 0.103484, Train Acc: 0.835897 | Val Loss: 0.125020, Val Acc: 0.773196\n",
      "Epoch 14377 - Train Loss: 0.103479, Train Acc: 0.835897 | Val Loss: 0.125017, Val Acc: 0.773196\n",
      "Epoch 14378 - Train Loss: 0.103475, Train Acc: 0.835897 | Val Loss: 0.125015, Val Acc: 0.773196\n",
      "Epoch 14379 - Train Loss: 0.103471, Train Acc: 0.835897 | Val Loss: 0.125012, Val Acc: 0.773196\n",
      "Epoch 14380 - Train Loss: 0.103467, Train Acc: 0.835897 | Val Loss: 0.125009, Val Acc: 0.773196\n",
      "Epoch 14381 - Train Loss: 0.103463, Train Acc: 0.835897 | Val Loss: 0.125006, Val Acc: 0.773196\n",
      "Epoch 14382 - Train Loss: 0.103459, Train Acc: 0.835897 | Val Loss: 0.125003, Val Acc: 0.773196\n",
      "Epoch 14383 - Train Loss: 0.103455, Train Acc: 0.835897 | Val Loss: 0.125000, Val Acc: 0.773196\n",
      "Epoch 14384 - Train Loss: 0.103451, Train Acc: 0.835897 | Val Loss: 0.124997, Val Acc: 0.773196\n",
      "Epoch 14385 - Train Loss: 0.103446, Train Acc: 0.835897 | Val Loss: 0.124994, Val Acc: 0.773196\n",
      "Epoch 14386 - Train Loss: 0.103442, Train Acc: 0.835897 | Val Loss: 0.124991, Val Acc: 0.773196\n",
      "Epoch 14387 - Train Loss: 0.103438, Train Acc: 0.835897 | Val Loss: 0.124988, Val Acc: 0.773196\n",
      "Epoch 14388 - Train Loss: 0.103434, Train Acc: 0.835897 | Val Loss: 0.124985, Val Acc: 0.773196\n",
      "Epoch 14389 - Train Loss: 0.103430, Train Acc: 0.835897 | Val Loss: 0.124982, Val Acc: 0.773196\n",
      "Epoch 14390 - Train Loss: 0.103426, Train Acc: 0.835897 | Val Loss: 0.124980, Val Acc: 0.773196\n",
      "Epoch 14391 - Train Loss: 0.103422, Train Acc: 0.835897 | Val Loss: 0.124977, Val Acc: 0.773196\n",
      "Epoch 14392 - Train Loss: 0.103418, Train Acc: 0.835897 | Val Loss: 0.124974, Val Acc: 0.773196\n",
      "Epoch 14393 - Train Loss: 0.103413, Train Acc: 0.835897 | Val Loss: 0.124971, Val Acc: 0.773196\n",
      "Epoch 14394 - Train Loss: 0.103409, Train Acc: 0.835897 | Val Loss: 0.124968, Val Acc: 0.773196\n",
      "Epoch 14395 - Train Loss: 0.103405, Train Acc: 0.835897 | Val Loss: 0.124965, Val Acc: 0.773196\n",
      "Epoch 14396 - Train Loss: 0.103401, Train Acc: 0.835897 | Val Loss: 0.124962, Val Acc: 0.773196\n",
      "Epoch 14397 - Train Loss: 0.103397, Train Acc: 0.835897 | Val Loss: 0.124959, Val Acc: 0.773196\n",
      "Epoch 14398 - Train Loss: 0.103393, Train Acc: 0.835897 | Val Loss: 0.124956, Val Acc: 0.773196\n",
      "Epoch 14399 - Train Loss: 0.103389, Train Acc: 0.835897 | Val Loss: 0.124954, Val Acc: 0.773196\n",
      "Epoch 14400 - Train Loss: 0.103385, Train Acc: 0.835897 | Val Loss: 0.124951, Val Acc: 0.773196\n",
      "Epoch 14401 - Train Loss: 0.103381, Train Acc: 0.835897 | Val Loss: 0.124948, Val Acc: 0.773196\n",
      "Epoch 14402 - Train Loss: 0.103376, Train Acc: 0.835897 | Val Loss: 0.124945, Val Acc: 0.773196\n",
      "Epoch 14403 - Train Loss: 0.103372, Train Acc: 0.835897 | Val Loss: 0.124942, Val Acc: 0.773196\n",
      "Epoch 14404 - Train Loss: 0.103368, Train Acc: 0.835897 | Val Loss: 0.124939, Val Acc: 0.773196\n",
      "Epoch 14405 - Train Loss: 0.103364, Train Acc: 0.835897 | Val Loss: 0.124936, Val Acc: 0.773196\n",
      "Epoch 14406 - Train Loss: 0.103360, Train Acc: 0.835897 | Val Loss: 0.124933, Val Acc: 0.773196\n",
      "Epoch 14407 - Train Loss: 0.103356, Train Acc: 0.835897 | Val Loss: 0.124930, Val Acc: 0.773196\n",
      "Epoch 14408 - Train Loss: 0.103352, Train Acc: 0.835897 | Val Loss: 0.124928, Val Acc: 0.773196\n",
      "Epoch 14409 - Train Loss: 0.103348, Train Acc: 0.837179 | Val Loss: 0.124925, Val Acc: 0.773196\n",
      "Epoch 14410 - Train Loss: 0.103343, Train Acc: 0.837179 | Val Loss: 0.124922, Val Acc: 0.773196\n",
      "Epoch 14411 - Train Loss: 0.103339, Train Acc: 0.837179 | Val Loss: 0.124919, Val Acc: 0.773196\n",
      "Epoch 14412 - Train Loss: 0.103335, Train Acc: 0.837179 | Val Loss: 0.124916, Val Acc: 0.773196\n",
      "Epoch 14413 - Train Loss: 0.103331, Train Acc: 0.837179 | Val Loss: 0.124913, Val Acc: 0.773196\n",
      "Epoch 14414 - Train Loss: 0.103327, Train Acc: 0.837179 | Val Loss: 0.124910, Val Acc: 0.773196\n",
      "Epoch 14415 - Train Loss: 0.103323, Train Acc: 0.837179 | Val Loss: 0.124908, Val Acc: 0.773196\n",
      "Epoch 14416 - Train Loss: 0.103319, Train Acc: 0.837179 | Val Loss: 0.124905, Val Acc: 0.773196\n",
      "Epoch 14417 - Train Loss: 0.103315, Train Acc: 0.837179 | Val Loss: 0.124902, Val Acc: 0.773196\n",
      "Epoch 14418 - Train Loss: 0.103311, Train Acc: 0.837179 | Val Loss: 0.124899, Val Acc: 0.773196\n",
      "Epoch 14419 - Train Loss: 0.103307, Train Acc: 0.837179 | Val Loss: 0.124896, Val Acc: 0.773196\n",
      "Epoch 14420 - Train Loss: 0.103302, Train Acc: 0.837179 | Val Loss: 0.124893, Val Acc: 0.773196\n",
      "Epoch 14421 - Train Loss: 0.103298, Train Acc: 0.837179 | Val Loss: 0.124890, Val Acc: 0.773196\n",
      "Epoch 14422 - Train Loss: 0.103294, Train Acc: 0.837179 | Val Loss: 0.124887, Val Acc: 0.773196\n",
      "Epoch 14423 - Train Loss: 0.103290, Train Acc: 0.837179 | Val Loss: 0.124885, Val Acc: 0.773196\n",
      "Epoch 14424 - Train Loss: 0.103286, Train Acc: 0.837179 | Val Loss: 0.124882, Val Acc: 0.773196\n",
      "Epoch 14425 - Train Loss: 0.103282, Train Acc: 0.837179 | Val Loss: 0.124879, Val Acc: 0.773196\n",
      "Epoch 14426 - Train Loss: 0.103278, Train Acc: 0.837179 | Val Loss: 0.124876, Val Acc: 0.773196\n",
      "Epoch 14427 - Train Loss: 0.103274, Train Acc: 0.837179 | Val Loss: 0.124873, Val Acc: 0.773196\n",
      "Epoch 14428 - Train Loss: 0.103270, Train Acc: 0.837179 | Val Loss: 0.124870, Val Acc: 0.773196\n",
      "Epoch 14429 - Train Loss: 0.103265, Train Acc: 0.837179 | Val Loss: 0.124867, Val Acc: 0.773196\n",
      "Epoch 14430 - Train Loss: 0.103261, Train Acc: 0.837179 | Val Loss: 0.124865, Val Acc: 0.773196\n",
      "Epoch 14431 - Train Loss: 0.103257, Train Acc: 0.837179 | Val Loss: 0.124862, Val Acc: 0.773196\n",
      "Epoch 14432 - Train Loss: 0.103253, Train Acc: 0.837179 | Val Loss: 0.124859, Val Acc: 0.773196\n",
      "Epoch 14433 - Train Loss: 0.103249, Train Acc: 0.837179 | Val Loss: 0.124856, Val Acc: 0.773196\n",
      "Epoch 14434 - Train Loss: 0.103245, Train Acc: 0.837179 | Val Loss: 0.124853, Val Acc: 0.773196\n",
      "Epoch 14435 - Train Loss: 0.103241, Train Acc: 0.837179 | Val Loss: 0.124850, Val Acc: 0.773196\n",
      "Epoch 14436 - Train Loss: 0.103237, Train Acc: 0.837179 | Val Loss: 0.124848, Val Acc: 0.773196\n",
      "Epoch 14437 - Train Loss: 0.103233, Train Acc: 0.837179 | Val Loss: 0.124845, Val Acc: 0.773196\n",
      "Epoch 14438 - Train Loss: 0.103229, Train Acc: 0.837179 | Val Loss: 0.124842, Val Acc: 0.773196\n",
      "Epoch 14439 - Train Loss: 0.103225, Train Acc: 0.837179 | Val Loss: 0.124839, Val Acc: 0.773196\n",
      "Epoch 14440 - Train Loss: 0.103220, Train Acc: 0.837179 | Val Loss: 0.124836, Val Acc: 0.773196\n",
      "Epoch 14441 - Train Loss: 0.103216, Train Acc: 0.837179 | Val Loss: 0.124833, Val Acc: 0.773196\n",
      "Epoch 14442 - Train Loss: 0.103212, Train Acc: 0.837179 | Val Loss: 0.124830, Val Acc: 0.773196\n",
      "Epoch 14443 - Train Loss: 0.103208, Train Acc: 0.837179 | Val Loss: 0.124828, Val Acc: 0.773196\n",
      "Epoch 14444 - Train Loss: 0.103204, Train Acc: 0.837179 | Val Loss: 0.124825, Val Acc: 0.773196\n",
      "Epoch 14445 - Train Loss: 0.103200, Train Acc: 0.837179 | Val Loss: 0.124822, Val Acc: 0.773196\n",
      "Epoch 14446 - Train Loss: 0.103196, Train Acc: 0.837179 | Val Loss: 0.124819, Val Acc: 0.773196\n",
      "Epoch 14447 - Train Loss: 0.103192, Train Acc: 0.837179 | Val Loss: 0.124816, Val Acc: 0.773196\n",
      "Epoch 14448 - Train Loss: 0.103188, Train Acc: 0.837179 | Val Loss: 0.124813, Val Acc: 0.773196\n",
      "Epoch 14449 - Train Loss: 0.103184, Train Acc: 0.837179 | Val Loss: 0.124811, Val Acc: 0.773196\n",
      "Epoch 14450 - Train Loss: 0.103180, Train Acc: 0.837179 | Val Loss: 0.124808, Val Acc: 0.773196\n",
      "Epoch 14451 - Train Loss: 0.103175, Train Acc: 0.838462 | Val Loss: 0.124805, Val Acc: 0.773196\n",
      "Epoch 14452 - Train Loss: 0.103171, Train Acc: 0.838462 | Val Loss: 0.124802, Val Acc: 0.773196\n",
      "Epoch 14453 - Train Loss: 0.103167, Train Acc: 0.838462 | Val Loss: 0.124799, Val Acc: 0.773196\n",
      "Epoch 14454 - Train Loss: 0.103163, Train Acc: 0.838462 | Val Loss: 0.124796, Val Acc: 0.773196\n",
      "Epoch 14455 - Train Loss: 0.103159, Train Acc: 0.838462 | Val Loss: 0.124793, Val Acc: 0.773196\n",
      "Epoch 14456 - Train Loss: 0.103155, Train Acc: 0.838462 | Val Loss: 0.124791, Val Acc: 0.773196\n",
      "Epoch 14457 - Train Loss: 0.103151, Train Acc: 0.838462 | Val Loss: 0.124788, Val Acc: 0.773196\n",
      "Epoch 14458 - Train Loss: 0.103147, Train Acc: 0.838462 | Val Loss: 0.124785, Val Acc: 0.773196\n",
      "Epoch 14459 - Train Loss: 0.103143, Train Acc: 0.838462 | Val Loss: 0.124782, Val Acc: 0.773196\n",
      "Epoch 14460 - Train Loss: 0.103139, Train Acc: 0.838462 | Val Loss: 0.124779, Val Acc: 0.773196\n",
      "Epoch 14461 - Train Loss: 0.103135, Train Acc: 0.838462 | Val Loss: 0.124776, Val Acc: 0.773196\n",
      "Epoch 14462 - Train Loss: 0.103130, Train Acc: 0.838462 | Val Loss: 0.124774, Val Acc: 0.773196\n",
      "Epoch 14463 - Train Loss: 0.103126, Train Acc: 0.838462 | Val Loss: 0.124771, Val Acc: 0.773196\n",
      "Epoch 14464 - Train Loss: 0.103122, Train Acc: 0.838462 | Val Loss: 0.124768, Val Acc: 0.773196\n",
      "Epoch 14465 - Train Loss: 0.103118, Train Acc: 0.838462 | Val Loss: 0.124765, Val Acc: 0.773196\n",
      "Epoch 14466 - Train Loss: 0.103114, Train Acc: 0.838462 | Val Loss: 0.124762, Val Acc: 0.773196\n",
      "Epoch 14467 - Train Loss: 0.103110, Train Acc: 0.838462 | Val Loss: 0.124759, Val Acc: 0.773196\n",
      "Epoch 14468 - Train Loss: 0.103106, Train Acc: 0.838462 | Val Loss: 0.124756, Val Acc: 0.773196\n",
      "Epoch 14469 - Train Loss: 0.103102, Train Acc: 0.838462 | Val Loss: 0.124754, Val Acc: 0.773196\n",
      "Epoch 14470 - Train Loss: 0.103098, Train Acc: 0.838462 | Val Loss: 0.124751, Val Acc: 0.773196\n",
      "Epoch 14471 - Train Loss: 0.103094, Train Acc: 0.838462 | Val Loss: 0.124748, Val Acc: 0.773196\n",
      "Epoch 14472 - Train Loss: 0.103090, Train Acc: 0.838462 | Val Loss: 0.124745, Val Acc: 0.773196\n",
      "Epoch 14473 - Train Loss: 0.103086, Train Acc: 0.838462 | Val Loss: 0.124742, Val Acc: 0.773196\n",
      "Epoch 14474 - Train Loss: 0.103082, Train Acc: 0.838462 | Val Loss: 0.124739, Val Acc: 0.773196\n",
      "Epoch 14475 - Train Loss: 0.103077, Train Acc: 0.838462 | Val Loss: 0.124737, Val Acc: 0.773196\n",
      "Epoch 14476 - Train Loss: 0.103073, Train Acc: 0.838462 | Val Loss: 0.124734, Val Acc: 0.773196\n",
      "Epoch 14477 - Train Loss: 0.103069, Train Acc: 0.838462 | Val Loss: 0.124731, Val Acc: 0.773196\n",
      "Epoch 14478 - Train Loss: 0.103065, Train Acc: 0.838462 | Val Loss: 0.124728, Val Acc: 0.773196\n",
      "Epoch 14479 - Train Loss: 0.103061, Train Acc: 0.838462 | Val Loss: 0.124725, Val Acc: 0.773196\n",
      "Epoch 14480 - Train Loss: 0.103057, Train Acc: 0.838462 | Val Loss: 0.124722, Val Acc: 0.773196\n",
      "Epoch 14481 - Train Loss: 0.103053, Train Acc: 0.838462 | Val Loss: 0.124720, Val Acc: 0.773196\n",
      "Epoch 14482 - Train Loss: 0.103049, Train Acc: 0.838462 | Val Loss: 0.124717, Val Acc: 0.773196\n",
      "Epoch 14483 - Train Loss: 0.103045, Train Acc: 0.838462 | Val Loss: 0.124714, Val Acc: 0.773196\n",
      "Epoch 14484 - Train Loss: 0.103041, Train Acc: 0.838462 | Val Loss: 0.124711, Val Acc: 0.773196\n",
      "Epoch 14485 - Train Loss: 0.103037, Train Acc: 0.838462 | Val Loss: 0.124708, Val Acc: 0.773196\n",
      "Epoch 14486 - Train Loss: 0.103033, Train Acc: 0.838462 | Val Loss: 0.124706, Val Acc: 0.773196\n",
      "Epoch 14487 - Train Loss: 0.103029, Train Acc: 0.838462 | Val Loss: 0.124703, Val Acc: 0.773196\n",
      "Epoch 14488 - Train Loss: 0.103025, Train Acc: 0.838462 | Val Loss: 0.124700, Val Acc: 0.773196\n",
      "Epoch 14489 - Train Loss: 0.103021, Train Acc: 0.838462 | Val Loss: 0.124697, Val Acc: 0.773196\n",
      "Epoch 14490 - Train Loss: 0.103016, Train Acc: 0.838462 | Val Loss: 0.124694, Val Acc: 0.773196\n",
      "Epoch 14491 - Train Loss: 0.103012, Train Acc: 0.838462 | Val Loss: 0.124691, Val Acc: 0.773196\n",
      "Epoch 14492 - Train Loss: 0.103008, Train Acc: 0.838462 | Val Loss: 0.124689, Val Acc: 0.773196\n",
      "Epoch 14493 - Train Loss: 0.103004, Train Acc: 0.838462 | Val Loss: 0.124686, Val Acc: 0.773196\n",
      "Epoch 14494 - Train Loss: 0.103000, Train Acc: 0.838462 | Val Loss: 0.124683, Val Acc: 0.773196\n",
      "Epoch 14495 - Train Loss: 0.102996, Train Acc: 0.838462 | Val Loss: 0.124680, Val Acc: 0.773196\n",
      "Epoch 14496 - Train Loss: 0.102992, Train Acc: 0.838462 | Val Loss: 0.124677, Val Acc: 0.773196\n",
      "Epoch 14497 - Train Loss: 0.102988, Train Acc: 0.838462 | Val Loss: 0.124674, Val Acc: 0.773196\n",
      "Epoch 14498 - Train Loss: 0.102984, Train Acc: 0.838462 | Val Loss: 0.124672, Val Acc: 0.773196\n",
      "Epoch 14499 - Train Loss: 0.102980, Train Acc: 0.838462 | Val Loss: 0.124669, Val Acc: 0.773196\n",
      "Epoch 14500 - Train Loss: 0.102976, Train Acc: 0.838462 | Val Loss: 0.124666, Val Acc: 0.773196\n",
      "Epoch 14501 - Train Loss: 0.102972, Train Acc: 0.838462 | Val Loss: 0.124663, Val Acc: 0.773196\n",
      "Epoch 14502 - Train Loss: 0.102968, Train Acc: 0.839744 | Val Loss: 0.124660, Val Acc: 0.773196\n",
      "Epoch 14503 - Train Loss: 0.102964, Train Acc: 0.839744 | Val Loss: 0.124658, Val Acc: 0.773196\n",
      "Epoch 14504 - Train Loss: 0.102960, Train Acc: 0.839744 | Val Loss: 0.124655, Val Acc: 0.773196\n",
      "Epoch 14505 - Train Loss: 0.102956, Train Acc: 0.839744 | Val Loss: 0.124652, Val Acc: 0.773196\n",
      "Epoch 14506 - Train Loss: 0.102951, Train Acc: 0.839744 | Val Loss: 0.124649, Val Acc: 0.773196\n",
      "Epoch 14507 - Train Loss: 0.102947, Train Acc: 0.839744 | Val Loss: 0.124646, Val Acc: 0.773196\n",
      "Epoch 14508 - Train Loss: 0.102943, Train Acc: 0.839744 | Val Loss: 0.124644, Val Acc: 0.773196\n",
      "Epoch 14509 - Train Loss: 0.102939, Train Acc: 0.839744 | Val Loss: 0.124641, Val Acc: 0.773196\n",
      "Epoch 14510 - Train Loss: 0.102935, Train Acc: 0.839744 | Val Loss: 0.124638, Val Acc: 0.773196\n",
      "Epoch 14511 - Train Loss: 0.102931, Train Acc: 0.839744 | Val Loss: 0.124635, Val Acc: 0.773196\n",
      "Epoch 14512 - Train Loss: 0.102927, Train Acc: 0.839744 | Val Loss: 0.124632, Val Acc: 0.773196\n",
      "Epoch 14513 - Train Loss: 0.102923, Train Acc: 0.839744 | Val Loss: 0.124629, Val Acc: 0.773196\n",
      "Epoch 14514 - Train Loss: 0.102919, Train Acc: 0.839744 | Val Loss: 0.124627, Val Acc: 0.773196\n",
      "Epoch 14515 - Train Loss: 0.102915, Train Acc: 0.839744 | Val Loss: 0.124624, Val Acc: 0.773196\n",
      "Epoch 14516 - Train Loss: 0.102911, Train Acc: 0.839744 | Val Loss: 0.124621, Val Acc: 0.773196\n",
      "Epoch 14517 - Train Loss: 0.102907, Train Acc: 0.839744 | Val Loss: 0.124618, Val Acc: 0.773196\n",
      "Epoch 14518 - Train Loss: 0.102903, Train Acc: 0.839744 | Val Loss: 0.124615, Val Acc: 0.773196\n",
      "Epoch 14519 - Train Loss: 0.102899, Train Acc: 0.839744 | Val Loss: 0.124613, Val Acc: 0.773196\n",
      "Epoch 14520 - Train Loss: 0.102895, Train Acc: 0.839744 | Val Loss: 0.124610, Val Acc: 0.773196\n",
      "Epoch 14521 - Train Loss: 0.102891, Train Acc: 0.839744 | Val Loss: 0.124607, Val Acc: 0.773196\n",
      "Epoch 14522 - Train Loss: 0.102887, Train Acc: 0.839744 | Val Loss: 0.124604, Val Acc: 0.773196\n",
      "Epoch 14523 - Train Loss: 0.102883, Train Acc: 0.839744 | Val Loss: 0.124601, Val Acc: 0.773196\n",
      "Epoch 14524 - Train Loss: 0.102879, Train Acc: 0.839744 | Val Loss: 0.124599, Val Acc: 0.773196\n",
      "Epoch 14525 - Train Loss: 0.102874, Train Acc: 0.839744 | Val Loss: 0.124596, Val Acc: 0.773196\n",
      "Epoch 14526 - Train Loss: 0.102870, Train Acc: 0.839744 | Val Loss: 0.124593, Val Acc: 0.773196\n",
      "Epoch 14527 - Train Loss: 0.102866, Train Acc: 0.839744 | Val Loss: 0.124590, Val Acc: 0.773196\n",
      "Epoch 14528 - Train Loss: 0.102862, Train Acc: 0.839744 | Val Loss: 0.124587, Val Acc: 0.773196\n",
      "Epoch 14529 - Train Loss: 0.102858, Train Acc: 0.839744 | Val Loss: 0.124585, Val Acc: 0.773196\n",
      "Epoch 14530 - Train Loss: 0.102854, Train Acc: 0.839744 | Val Loss: 0.124582, Val Acc: 0.773196\n",
      "Epoch 14531 - Train Loss: 0.102850, Train Acc: 0.839744 | Val Loss: 0.124579, Val Acc: 0.773196\n",
      "Epoch 14532 - Train Loss: 0.102846, Train Acc: 0.839744 | Val Loss: 0.124576, Val Acc: 0.773196\n",
      "Epoch 14533 - Train Loss: 0.102842, Train Acc: 0.839744 | Val Loss: 0.124573, Val Acc: 0.773196\n",
      "Epoch 14534 - Train Loss: 0.102838, Train Acc: 0.839744 | Val Loss: 0.124571, Val Acc: 0.773196\n",
      "Epoch 14535 - Train Loss: 0.102834, Train Acc: 0.839744 | Val Loss: 0.124568, Val Acc: 0.773196\n",
      "Epoch 14536 - Train Loss: 0.102830, Train Acc: 0.839744 | Val Loss: 0.124565, Val Acc: 0.773196\n",
      "Epoch 14537 - Train Loss: 0.102826, Train Acc: 0.839744 | Val Loss: 0.124562, Val Acc: 0.773196\n",
      "Epoch 14538 - Train Loss: 0.102822, Train Acc: 0.839744 | Val Loss: 0.124559, Val Acc: 0.773196\n",
      "Epoch 14539 - Train Loss: 0.102818, Train Acc: 0.839744 | Val Loss: 0.124557, Val Acc: 0.773196\n",
      "Epoch 14540 - Train Loss: 0.102814, Train Acc: 0.839744 | Val Loss: 0.124554, Val Acc: 0.773196\n",
      "Epoch 14541 - Train Loss: 0.102810, Train Acc: 0.839744 | Val Loss: 0.124551, Val Acc: 0.773196\n",
      "Epoch 14542 - Train Loss: 0.102806, Train Acc: 0.839744 | Val Loss: 0.124548, Val Acc: 0.773196\n",
      "Epoch 14543 - Train Loss: 0.102802, Train Acc: 0.839744 | Val Loss: 0.124545, Val Acc: 0.773196\n",
      "Epoch 14544 - Train Loss: 0.102798, Train Acc: 0.839744 | Val Loss: 0.124543, Val Acc: 0.773196\n",
      "Epoch 14545 - Train Loss: 0.102794, Train Acc: 0.839744 | Val Loss: 0.124540, Val Acc: 0.773196\n",
      "Epoch 14546 - Train Loss: 0.102790, Train Acc: 0.839744 | Val Loss: 0.124537, Val Acc: 0.773196\n",
      "Epoch 14547 - Train Loss: 0.102786, Train Acc: 0.839744 | Val Loss: 0.124534, Val Acc: 0.773196\n",
      "Epoch 14548 - Train Loss: 0.102782, Train Acc: 0.839744 | Val Loss: 0.124532, Val Acc: 0.773196\n",
      "Epoch 14549 - Train Loss: 0.102778, Train Acc: 0.839744 | Val Loss: 0.124529, Val Acc: 0.773196\n",
      "Epoch 14550 - Train Loss: 0.102774, Train Acc: 0.839744 | Val Loss: 0.124526, Val Acc: 0.773196\n",
      "Epoch 14551 - Train Loss: 0.102769, Train Acc: 0.839744 | Val Loss: 0.124523, Val Acc: 0.773196\n",
      "Epoch 14552 - Train Loss: 0.102765, Train Acc: 0.839744 | Val Loss: 0.124520, Val Acc: 0.773196\n",
      "Epoch 14553 - Train Loss: 0.102761, Train Acc: 0.839744 | Val Loss: 0.124518, Val Acc: 0.773196\n",
      "Epoch 14554 - Train Loss: 0.102757, Train Acc: 0.839744 | Val Loss: 0.124515, Val Acc: 0.773196\n",
      "Epoch 14555 - Train Loss: 0.102753, Train Acc: 0.839744 | Val Loss: 0.124512, Val Acc: 0.773196\n",
      "Epoch 14556 - Train Loss: 0.102749, Train Acc: 0.839744 | Val Loss: 0.124509, Val Acc: 0.773196\n",
      "Epoch 14557 - Train Loss: 0.102745, Train Acc: 0.839744 | Val Loss: 0.124506, Val Acc: 0.773196\n",
      "Epoch 14558 - Train Loss: 0.102741, Train Acc: 0.839744 | Val Loss: 0.124504, Val Acc: 0.773196\n",
      "Epoch 14559 - Train Loss: 0.102737, Train Acc: 0.839744 | Val Loss: 0.124501, Val Acc: 0.773196\n",
      "Epoch 14560 - Train Loss: 0.102733, Train Acc: 0.839744 | Val Loss: 0.124498, Val Acc: 0.773196\n",
      "Epoch 14561 - Train Loss: 0.102729, Train Acc: 0.839744 | Val Loss: 0.124495, Val Acc: 0.773196\n",
      "Epoch 14562 - Train Loss: 0.102725, Train Acc: 0.839744 | Val Loss: 0.124493, Val Acc: 0.773196\n",
      "Epoch 14563 - Train Loss: 0.102721, Train Acc: 0.839744 | Val Loss: 0.124490, Val Acc: 0.773196\n",
      "Epoch 14564 - Train Loss: 0.102717, Train Acc: 0.839744 | Val Loss: 0.124487, Val Acc: 0.773196\n",
      "Epoch 14565 - Train Loss: 0.102713, Train Acc: 0.839744 | Val Loss: 0.124484, Val Acc: 0.773196\n",
      "Epoch 14566 - Train Loss: 0.102709, Train Acc: 0.839744 | Val Loss: 0.124481, Val Acc: 0.773196\n",
      "Epoch 14567 - Train Loss: 0.102705, Train Acc: 0.839744 | Val Loss: 0.124479, Val Acc: 0.773196\n",
      "Epoch 14568 - Train Loss: 0.102701, Train Acc: 0.839744 | Val Loss: 0.124476, Val Acc: 0.773196\n",
      "Epoch 14569 - Train Loss: 0.102697, Train Acc: 0.839744 | Val Loss: 0.124473, Val Acc: 0.773196\n",
      "Epoch 14570 - Train Loss: 0.102693, Train Acc: 0.839744 | Val Loss: 0.124470, Val Acc: 0.773196\n",
      "Epoch 14571 - Train Loss: 0.102689, Train Acc: 0.839744 | Val Loss: 0.124468, Val Acc: 0.773196\n",
      "Epoch 14572 - Train Loss: 0.102685, Train Acc: 0.839744 | Val Loss: 0.124465, Val Acc: 0.773196\n",
      "Epoch 14573 - Train Loss: 0.102681, Train Acc: 0.839744 | Val Loss: 0.124462, Val Acc: 0.773196\n",
      "Epoch 14574 - Train Loss: 0.102677, Train Acc: 0.839744 | Val Loss: 0.124459, Val Acc: 0.773196\n",
      "Epoch 14575 - Train Loss: 0.102673, Train Acc: 0.839744 | Val Loss: 0.124456, Val Acc: 0.773196\n",
      "Epoch 14576 - Train Loss: 0.102669, Train Acc: 0.839744 | Val Loss: 0.124454, Val Acc: 0.773196\n",
      "Epoch 14577 - Train Loss: 0.102665, Train Acc: 0.841026 | Val Loss: 0.124451, Val Acc: 0.773196\n",
      "Epoch 14578 - Train Loss: 0.102661, Train Acc: 0.841026 | Val Loss: 0.124448, Val Acc: 0.773196\n",
      "Epoch 14579 - Train Loss: 0.102657, Train Acc: 0.841026 | Val Loss: 0.124445, Val Acc: 0.773196\n",
      "Epoch 14580 - Train Loss: 0.102653, Train Acc: 0.841026 | Val Loss: 0.124443, Val Acc: 0.773196\n",
      "Epoch 14581 - Train Loss: 0.102649, Train Acc: 0.841026 | Val Loss: 0.124440, Val Acc: 0.773196\n",
      "Epoch 14582 - Train Loss: 0.102645, Train Acc: 0.841026 | Val Loss: 0.124437, Val Acc: 0.773196\n",
      "Epoch 14583 - Train Loss: 0.102641, Train Acc: 0.841026 | Val Loss: 0.124434, Val Acc: 0.773196\n",
      "Epoch 14584 - Train Loss: 0.102637, Train Acc: 0.841026 | Val Loss: 0.124431, Val Acc: 0.773196\n",
      "Epoch 14585 - Train Loss: 0.102633, Train Acc: 0.841026 | Val Loss: 0.124429, Val Acc: 0.773196\n",
      "Epoch 14586 - Train Loss: 0.102629, Train Acc: 0.841026 | Val Loss: 0.124426, Val Acc: 0.773196\n",
      "Epoch 14587 - Train Loss: 0.102625, Train Acc: 0.841026 | Val Loss: 0.124423, Val Acc: 0.773196\n",
      "Epoch 14588 - Train Loss: 0.102621, Train Acc: 0.841026 | Val Loss: 0.124420, Val Acc: 0.773196\n",
      "Epoch 14589 - Train Loss: 0.102617, Train Acc: 0.841026 | Val Loss: 0.124418, Val Acc: 0.773196\n",
      "Epoch 14590 - Train Loss: 0.102613, Train Acc: 0.841026 | Val Loss: 0.124415, Val Acc: 0.773196\n",
      "Epoch 14591 - Train Loss: 0.102609, Train Acc: 0.841026 | Val Loss: 0.124412, Val Acc: 0.773196\n",
      "Epoch 14592 - Train Loss: 0.102605, Train Acc: 0.841026 | Val Loss: 0.124409, Val Acc: 0.773196\n",
      "Epoch 14593 - Train Loss: 0.102601, Train Acc: 0.841026 | Val Loss: 0.124407, Val Acc: 0.773196\n",
      "Epoch 14594 - Train Loss: 0.102597, Train Acc: 0.841026 | Val Loss: 0.124404, Val Acc: 0.773196\n",
      "Epoch 14595 - Train Loss: 0.102593, Train Acc: 0.841026 | Val Loss: 0.124401, Val Acc: 0.773196\n",
      "Epoch 14596 - Train Loss: 0.102589, Train Acc: 0.841026 | Val Loss: 0.124398, Val Acc: 0.773196\n",
      "Epoch 14597 - Train Loss: 0.102585, Train Acc: 0.841026 | Val Loss: 0.124396, Val Acc: 0.773196\n",
      "Epoch 14598 - Train Loss: 0.102581, Train Acc: 0.841026 | Val Loss: 0.124393, Val Acc: 0.773196\n",
      "Epoch 14599 - Train Loss: 0.102577, Train Acc: 0.841026 | Val Loss: 0.124390, Val Acc: 0.773196\n",
      "Epoch 14600 - Train Loss: 0.102573, Train Acc: 0.841026 | Val Loss: 0.124387, Val Acc: 0.773196\n",
      "Epoch 14601 - Train Loss: 0.102569, Train Acc: 0.841026 | Val Loss: 0.124384, Val Acc: 0.773196\n",
      "Epoch 14602 - Train Loss: 0.102565, Train Acc: 0.841026 | Val Loss: 0.124382, Val Acc: 0.773196\n",
      "Epoch 14603 - Train Loss: 0.102561, Train Acc: 0.841026 | Val Loss: 0.124379, Val Acc: 0.773196\n",
      "Epoch 14604 - Train Loss: 0.102557, Train Acc: 0.841026 | Val Loss: 0.124376, Val Acc: 0.773196\n",
      "Epoch 14605 - Train Loss: 0.102553, Train Acc: 0.841026 | Val Loss: 0.124373, Val Acc: 0.773196\n",
      "Epoch 14606 - Train Loss: 0.102549, Train Acc: 0.841026 | Val Loss: 0.124371, Val Acc: 0.773196\n",
      "Epoch 14607 - Train Loss: 0.102545, Train Acc: 0.842308 | Val Loss: 0.124368, Val Acc: 0.773196\n",
      "Epoch 14608 - Train Loss: 0.102541, Train Acc: 0.842308 | Val Loss: 0.124365, Val Acc: 0.773196\n",
      "Epoch 14609 - Train Loss: 0.102537, Train Acc: 0.842308 | Val Loss: 0.124362, Val Acc: 0.773196\n",
      "Epoch 14610 - Train Loss: 0.102533, Train Acc: 0.842308 | Val Loss: 0.124360, Val Acc: 0.773196\n",
      "Epoch 14611 - Train Loss: 0.102529, Train Acc: 0.842308 | Val Loss: 0.124357, Val Acc: 0.773196\n",
      "Epoch 14612 - Train Loss: 0.102525, Train Acc: 0.842308 | Val Loss: 0.124354, Val Acc: 0.773196\n",
      "Epoch 14613 - Train Loss: 0.102521, Train Acc: 0.842308 | Val Loss: 0.124351, Val Acc: 0.773196\n",
      "Epoch 14614 - Train Loss: 0.102517, Train Acc: 0.842308 | Val Loss: 0.124349, Val Acc: 0.773196\n",
      "Epoch 14615 - Train Loss: 0.102513, Train Acc: 0.842308 | Val Loss: 0.124346, Val Acc: 0.773196\n",
      "Epoch 14616 - Train Loss: 0.102509, Train Acc: 0.842308 | Val Loss: 0.124343, Val Acc: 0.773196\n",
      "Epoch 14617 - Train Loss: 0.102505, Train Acc: 0.842308 | Val Loss: 0.124340, Val Acc: 0.773196\n",
      "Epoch 14618 - Train Loss: 0.102501, Train Acc: 0.842308 | Val Loss: 0.124338, Val Acc: 0.773196\n",
      "Epoch 14619 - Train Loss: 0.102497, Train Acc: 0.842308 | Val Loss: 0.124335, Val Acc: 0.773196\n",
      "Epoch 14620 - Train Loss: 0.102493, Train Acc: 0.842308 | Val Loss: 0.124332, Val Acc: 0.773196\n",
      "Epoch 14621 - Train Loss: 0.102489, Train Acc: 0.842308 | Val Loss: 0.124329, Val Acc: 0.773196\n",
      "Epoch 14622 - Train Loss: 0.102485, Train Acc: 0.842308 | Val Loss: 0.124327, Val Acc: 0.773196\n",
      "Epoch 14623 - Train Loss: 0.102481, Train Acc: 0.842308 | Val Loss: 0.124324, Val Acc: 0.773196\n",
      "Epoch 14624 - Train Loss: 0.102477, Train Acc: 0.842308 | Val Loss: 0.124321, Val Acc: 0.773196\n",
      "Epoch 14625 - Train Loss: 0.102473, Train Acc: 0.842308 | Val Loss: 0.124318, Val Acc: 0.773196\n",
      "Epoch 14626 - Train Loss: 0.102469, Train Acc: 0.842308 | Val Loss: 0.124316, Val Acc: 0.773196\n",
      "Epoch 14627 - Train Loss: 0.102465, Train Acc: 0.842308 | Val Loss: 0.124313, Val Acc: 0.773196\n",
      "Epoch 14628 - Train Loss: 0.102461, Train Acc: 0.842308 | Val Loss: 0.124310, Val Acc: 0.773196\n",
      "Epoch 14629 - Train Loss: 0.102457, Train Acc: 0.842308 | Val Loss: 0.124307, Val Acc: 0.773196\n",
      "Epoch 14630 - Train Loss: 0.102453, Train Acc: 0.842308 | Val Loss: 0.124305, Val Acc: 0.773196\n",
      "Epoch 14631 - Train Loss: 0.102449, Train Acc: 0.842308 | Val Loss: 0.124302, Val Acc: 0.773196\n",
      "Epoch 14632 - Train Loss: 0.102445, Train Acc: 0.842308 | Val Loss: 0.124299, Val Acc: 0.773196\n",
      "Epoch 14633 - Train Loss: 0.102441, Train Acc: 0.842308 | Val Loss: 0.124296, Val Acc: 0.773196\n",
      "Epoch 14634 - Train Loss: 0.102437, Train Acc: 0.842308 | Val Loss: 0.124294, Val Acc: 0.773196\n",
      "Epoch 14635 - Train Loss: 0.102433, Train Acc: 0.842308 | Val Loss: 0.124291, Val Acc: 0.773196\n",
      "Epoch 14636 - Train Loss: 0.102429, Train Acc: 0.842308 | Val Loss: 0.124288, Val Acc: 0.773196\n",
      "Epoch 14637 - Train Loss: 0.102425, Train Acc: 0.842308 | Val Loss: 0.124285, Val Acc: 0.773196\n",
      "Epoch 14638 - Train Loss: 0.102421, Train Acc: 0.842308 | Val Loss: 0.124283, Val Acc: 0.773196\n",
      "Epoch 14639 - Train Loss: 0.102417, Train Acc: 0.842308 | Val Loss: 0.124280, Val Acc: 0.773196\n",
      "Epoch 14640 - Train Loss: 0.102413, Train Acc: 0.842308 | Val Loss: 0.124277, Val Acc: 0.773196\n",
      "Epoch 14641 - Train Loss: 0.102409, Train Acc: 0.842308 | Val Loss: 0.124275, Val Acc: 0.773196\n",
      "Epoch 14642 - Train Loss: 0.102405, Train Acc: 0.842308 | Val Loss: 0.124272, Val Acc: 0.773196\n",
      "Epoch 14643 - Train Loss: 0.102401, Train Acc: 0.842308 | Val Loss: 0.124269, Val Acc: 0.773196\n",
      "Epoch 14644 - Train Loss: 0.102397, Train Acc: 0.842308 | Val Loss: 0.124266, Val Acc: 0.773196\n",
      "Epoch 14645 - Train Loss: 0.102393, Train Acc: 0.842308 | Val Loss: 0.124263, Val Acc: 0.773196\n",
      "Epoch 14646 - Train Loss: 0.102389, Train Acc: 0.842308 | Val Loss: 0.124261, Val Acc: 0.773196\n",
      "Epoch 14647 - Train Loss: 0.102385, Train Acc: 0.842308 | Val Loss: 0.124258, Val Acc: 0.773196\n",
      "Epoch 14648 - Train Loss: 0.102381, Train Acc: 0.842308 | Val Loss: 0.124255, Val Acc: 0.773196\n",
      "Epoch 14649 - Train Loss: 0.102377, Train Acc: 0.842308 | Val Loss: 0.124252, Val Acc: 0.773196\n",
      "Epoch 14650 - Train Loss: 0.102373, Train Acc: 0.842308 | Val Loss: 0.124250, Val Acc: 0.773196\n",
      "Epoch 14651 - Train Loss: 0.102369, Train Acc: 0.842308 | Val Loss: 0.124247, Val Acc: 0.773196\n",
      "Epoch 14652 - Train Loss: 0.102365, Train Acc: 0.842308 | Val Loss: 0.124244, Val Acc: 0.773196\n",
      "Epoch 14653 - Train Loss: 0.102361, Train Acc: 0.842308 | Val Loss: 0.124241, Val Acc: 0.773196\n",
      "Epoch 14654 - Train Loss: 0.102357, Train Acc: 0.842308 | Val Loss: 0.124239, Val Acc: 0.773196\n",
      "Epoch 14655 - Train Loss: 0.102353, Train Acc: 0.842308 | Val Loss: 0.124236, Val Acc: 0.773196\n",
      "Epoch 14656 - Train Loss: 0.102349, Train Acc: 0.842308 | Val Loss: 0.124233, Val Acc: 0.773196\n",
      "Epoch 14657 - Train Loss: 0.102345, Train Acc: 0.842308 | Val Loss: 0.124230, Val Acc: 0.773196\n",
      "Epoch 14658 - Train Loss: 0.102341, Train Acc: 0.842308 | Val Loss: 0.124228, Val Acc: 0.773196\n",
      "Epoch 14659 - Train Loss: 0.102337, Train Acc: 0.842308 | Val Loss: 0.124225, Val Acc: 0.773196\n",
      "Epoch 14660 - Train Loss: 0.102333, Train Acc: 0.842308 | Val Loss: 0.124222, Val Acc: 0.773196\n",
      "Epoch 14661 - Train Loss: 0.102329, Train Acc: 0.842308 | Val Loss: 0.124220, Val Acc: 0.773196\n",
      "Epoch 14662 - Train Loss: 0.102325, Train Acc: 0.842308 | Val Loss: 0.124217, Val Acc: 0.773196\n",
      "Epoch 14663 - Train Loss: 0.102321, Train Acc: 0.842308 | Val Loss: 0.124214, Val Acc: 0.773196\n",
      "Epoch 14664 - Train Loss: 0.102317, Train Acc: 0.842308 | Val Loss: 0.124211, Val Acc: 0.773196\n",
      "Epoch 14665 - Train Loss: 0.102313, Train Acc: 0.842308 | Val Loss: 0.124209, Val Acc: 0.773196\n",
      "Epoch 14666 - Train Loss: 0.102310, Train Acc: 0.842308 | Val Loss: 0.124206, Val Acc: 0.773196\n",
      "Epoch 14667 - Train Loss: 0.102306, Train Acc: 0.842308 | Val Loss: 0.124203, Val Acc: 0.773196\n",
      "Epoch 14668 - Train Loss: 0.102302, Train Acc: 0.842308 | Val Loss: 0.124200, Val Acc: 0.773196\n",
      "Epoch 14669 - Train Loss: 0.102298, Train Acc: 0.842308 | Val Loss: 0.124198, Val Acc: 0.773196\n",
      "Epoch 14670 - Train Loss: 0.102294, Train Acc: 0.842308 | Val Loss: 0.124195, Val Acc: 0.773196\n",
      "Epoch 14671 - Train Loss: 0.102290, Train Acc: 0.842308 | Val Loss: 0.124192, Val Acc: 0.773196\n",
      "Epoch 14672 - Train Loss: 0.102286, Train Acc: 0.842308 | Val Loss: 0.124189, Val Acc: 0.773196\n",
      "Epoch 14673 - Train Loss: 0.102282, Train Acc: 0.842308 | Val Loss: 0.124187, Val Acc: 0.773196\n",
      "Epoch 14674 - Train Loss: 0.102278, Train Acc: 0.842308 | Val Loss: 0.124184, Val Acc: 0.773196\n",
      "Epoch 14675 - Train Loss: 0.102274, Train Acc: 0.842308 | Val Loss: 0.124181, Val Acc: 0.773196\n",
      "Epoch 14676 - Train Loss: 0.102270, Train Acc: 0.842308 | Val Loss: 0.124179, Val Acc: 0.773196\n",
      "Epoch 14677 - Train Loss: 0.102266, Train Acc: 0.842308 | Val Loss: 0.124176, Val Acc: 0.773196\n",
      "Epoch 14678 - Train Loss: 0.102262, Train Acc: 0.842308 | Val Loss: 0.124173, Val Acc: 0.773196\n",
      "Epoch 14679 - Train Loss: 0.102258, Train Acc: 0.842308 | Val Loss: 0.124170, Val Acc: 0.773196\n",
      "Epoch 14680 - Train Loss: 0.102254, Train Acc: 0.842308 | Val Loss: 0.124168, Val Acc: 0.773196\n",
      "Epoch 14681 - Train Loss: 0.102250, Train Acc: 0.842308 | Val Loss: 0.124165, Val Acc: 0.773196\n",
      "Epoch 14682 - Train Loss: 0.102246, Train Acc: 0.842308 | Val Loss: 0.124162, Val Acc: 0.773196\n",
      "Epoch 14683 - Train Loss: 0.102242, Train Acc: 0.842308 | Val Loss: 0.124160, Val Acc: 0.773196\n",
      "Epoch 14684 - Train Loss: 0.102238, Train Acc: 0.842308 | Val Loss: 0.124157, Val Acc: 0.773196\n",
      "Epoch 14685 - Train Loss: 0.102234, Train Acc: 0.842308 | Val Loss: 0.124154, Val Acc: 0.773196\n",
      "Epoch 14686 - Train Loss: 0.102230, Train Acc: 0.842308 | Val Loss: 0.124151, Val Acc: 0.773196\n",
      "Epoch 14687 - Train Loss: 0.102226, Train Acc: 0.842308 | Val Loss: 0.124149, Val Acc: 0.773196\n",
      "Epoch 14688 - Train Loss: 0.102222, Train Acc: 0.842308 | Val Loss: 0.124146, Val Acc: 0.773196\n",
      "Epoch 14689 - Train Loss: 0.102218, Train Acc: 0.842308 | Val Loss: 0.124143, Val Acc: 0.773196\n",
      "Epoch 14690 - Train Loss: 0.102214, Train Acc: 0.842308 | Val Loss: 0.124141, Val Acc: 0.773196\n",
      "Epoch 14691 - Train Loss: 0.102210, Train Acc: 0.842308 | Val Loss: 0.124138, Val Acc: 0.773196\n",
      "Epoch 14692 - Train Loss: 0.102207, Train Acc: 0.842308 | Val Loss: 0.124135, Val Acc: 0.773196\n",
      "Epoch 14693 - Train Loss: 0.102203, Train Acc: 0.842308 | Val Loss: 0.124132, Val Acc: 0.773196\n",
      "Epoch 14694 - Train Loss: 0.102199, Train Acc: 0.842308 | Val Loss: 0.124130, Val Acc: 0.773196\n",
      "Epoch 14695 - Train Loss: 0.102195, Train Acc: 0.842308 | Val Loss: 0.124127, Val Acc: 0.773196\n",
      "Epoch 14696 - Train Loss: 0.102191, Train Acc: 0.842308 | Val Loss: 0.124124, Val Acc: 0.773196\n",
      "Epoch 14697 - Train Loss: 0.102187, Train Acc: 0.842308 | Val Loss: 0.124122, Val Acc: 0.773196\n",
      "Epoch 14698 - Train Loss: 0.102183, Train Acc: 0.842308 | Val Loss: 0.124119, Val Acc: 0.773196\n",
      "Epoch 14699 - Train Loss: 0.102179, Train Acc: 0.842308 | Val Loss: 0.124116, Val Acc: 0.773196\n",
      "Epoch 14700 - Train Loss: 0.102175, Train Acc: 0.842308 | Val Loss: 0.124113, Val Acc: 0.773196\n",
      "Epoch 14701 - Train Loss: 0.102171, Train Acc: 0.842308 | Val Loss: 0.124111, Val Acc: 0.773196\n",
      "Epoch 14702 - Train Loss: 0.102167, Train Acc: 0.842308 | Val Loss: 0.124108, Val Acc: 0.773196\n",
      "Epoch 14703 - Train Loss: 0.102163, Train Acc: 0.842308 | Val Loss: 0.124105, Val Acc: 0.773196\n",
      "Epoch 14704 - Train Loss: 0.102159, Train Acc: 0.842308 | Val Loss: 0.124103, Val Acc: 0.773196\n",
      "Epoch 14705 - Train Loss: 0.102155, Train Acc: 0.842308 | Val Loss: 0.124100, Val Acc: 0.773196\n",
      "Epoch 14706 - Train Loss: 0.102151, Train Acc: 0.842308 | Val Loss: 0.124097, Val Acc: 0.773196\n",
      "Epoch 14707 - Train Loss: 0.102147, Train Acc: 0.842308 | Val Loss: 0.124094, Val Acc: 0.773196\n",
      "Epoch 14708 - Train Loss: 0.102143, Train Acc: 0.842308 | Val Loss: 0.124092, Val Acc: 0.773196\n",
      "Epoch 14709 - Train Loss: 0.102139, Train Acc: 0.842308 | Val Loss: 0.124089, Val Acc: 0.773196\n",
      "Epoch 14710 - Train Loss: 0.102135, Train Acc: 0.842308 | Val Loss: 0.124086, Val Acc: 0.773196\n",
      "Epoch 14711 - Train Loss: 0.102131, Train Acc: 0.842308 | Val Loss: 0.124084, Val Acc: 0.773196\n",
      "Epoch 14712 - Train Loss: 0.102128, Train Acc: 0.842308 | Val Loss: 0.124081, Val Acc: 0.773196\n",
      "Epoch 14713 - Train Loss: 0.102124, Train Acc: 0.842308 | Val Loss: 0.124078, Val Acc: 0.773196\n",
      "Epoch 14714 - Train Loss: 0.102120, Train Acc: 0.842308 | Val Loss: 0.124076, Val Acc: 0.773196\n",
      "Epoch 14715 - Train Loss: 0.102116, Train Acc: 0.842308 | Val Loss: 0.124073, Val Acc: 0.773196\n",
      "Epoch 14716 - Train Loss: 0.102112, Train Acc: 0.842308 | Val Loss: 0.124070, Val Acc: 0.773196\n",
      "Epoch 14717 - Train Loss: 0.102108, Train Acc: 0.842308 | Val Loss: 0.124067, Val Acc: 0.773196\n",
      "Epoch 14718 - Train Loss: 0.102104, Train Acc: 0.842308 | Val Loss: 0.124065, Val Acc: 0.773196\n",
      "Epoch 14719 - Train Loss: 0.102100, Train Acc: 0.842308 | Val Loss: 0.124062, Val Acc: 0.773196\n",
      "Epoch 14720 - Train Loss: 0.102096, Train Acc: 0.842308 | Val Loss: 0.124059, Val Acc: 0.773196\n",
      "Epoch 14721 - Train Loss: 0.102092, Train Acc: 0.842308 | Val Loss: 0.124057, Val Acc: 0.773196\n",
      "Epoch 14722 - Train Loss: 0.102088, Train Acc: 0.842308 | Val Loss: 0.124054, Val Acc: 0.773196\n",
      "Epoch 14723 - Train Loss: 0.102084, Train Acc: 0.842308 | Val Loss: 0.124051, Val Acc: 0.773196\n",
      "Epoch 14724 - Train Loss: 0.102080, Train Acc: 0.842308 | Val Loss: 0.124049, Val Acc: 0.773196\n",
      "Epoch 14725 - Train Loss: 0.102076, Train Acc: 0.842308 | Val Loss: 0.124046, Val Acc: 0.773196\n",
      "Epoch 14726 - Train Loss: 0.102072, Train Acc: 0.842308 | Val Loss: 0.124043, Val Acc: 0.773196\n",
      "Epoch 14727 - Train Loss: 0.102068, Train Acc: 0.842308 | Val Loss: 0.124040, Val Acc: 0.773196\n",
      "Epoch 14728 - Train Loss: 0.102065, Train Acc: 0.842308 | Val Loss: 0.124038, Val Acc: 0.773196\n",
      "Epoch 14729 - Train Loss: 0.102061, Train Acc: 0.842308 | Val Loss: 0.124035, Val Acc: 0.773196\n",
      "Epoch 14730 - Train Loss: 0.102057, Train Acc: 0.842308 | Val Loss: 0.124032, Val Acc: 0.773196\n",
      "Epoch 14731 - Train Loss: 0.102053, Train Acc: 0.842308 | Val Loss: 0.124030, Val Acc: 0.773196\n",
      "Epoch 14732 - Train Loss: 0.102049, Train Acc: 0.842308 | Val Loss: 0.124027, Val Acc: 0.773196\n",
      "Epoch 14733 - Train Loss: 0.102045, Train Acc: 0.842308 | Val Loss: 0.124024, Val Acc: 0.773196\n",
      "Epoch 14734 - Train Loss: 0.102041, Train Acc: 0.842308 | Val Loss: 0.124022, Val Acc: 0.773196\n",
      "Epoch 14735 - Train Loss: 0.102037, Train Acc: 0.842308 | Val Loss: 0.124019, Val Acc: 0.773196\n",
      "Epoch 14736 - Train Loss: 0.102033, Train Acc: 0.842308 | Val Loss: 0.124016, Val Acc: 0.773196\n",
      "Epoch 14737 - Train Loss: 0.102029, Train Acc: 0.842308 | Val Loss: 0.124014, Val Acc: 0.773196\n",
      "Epoch 14738 - Train Loss: 0.102025, Train Acc: 0.842308 | Val Loss: 0.124011, Val Acc: 0.773196\n",
      "Epoch 14739 - Train Loss: 0.102021, Train Acc: 0.842308 | Val Loss: 0.124008, Val Acc: 0.773196\n",
      "Epoch 14740 - Train Loss: 0.102017, Train Acc: 0.842308 | Val Loss: 0.124006, Val Acc: 0.773196\n",
      "Epoch 14741 - Train Loss: 0.102013, Train Acc: 0.842308 | Val Loss: 0.124003, Val Acc: 0.773196\n",
      "Epoch 14742 - Train Loss: 0.102009, Train Acc: 0.842308 | Val Loss: 0.124000, Val Acc: 0.773196\n",
      "Epoch 14743 - Train Loss: 0.102006, Train Acc: 0.842308 | Val Loss: 0.123997, Val Acc: 0.773196\n",
      "Epoch 14744 - Train Loss: 0.102002, Train Acc: 0.842308 | Val Loss: 0.123995, Val Acc: 0.773196\n",
      "Epoch 14745 - Train Loss: 0.101998, Train Acc: 0.842308 | Val Loss: 0.123992, Val Acc: 0.773196\n",
      "Epoch 14746 - Train Loss: 0.101994, Train Acc: 0.842308 | Val Loss: 0.123989, Val Acc: 0.773196\n",
      "Epoch 14747 - Train Loss: 0.101990, Train Acc: 0.842308 | Val Loss: 0.123987, Val Acc: 0.773196\n",
      "Epoch 14748 - Train Loss: 0.101986, Train Acc: 0.842308 | Val Loss: 0.123984, Val Acc: 0.773196\n",
      "Epoch 14749 - Train Loss: 0.101982, Train Acc: 0.842308 | Val Loss: 0.123981, Val Acc: 0.773196\n",
      "Epoch 14750 - Train Loss: 0.101978, Train Acc: 0.842308 | Val Loss: 0.123979, Val Acc: 0.773196\n",
      "Epoch 14751 - Train Loss: 0.101974, Train Acc: 0.842308 | Val Loss: 0.123976, Val Acc: 0.773196\n",
      "Epoch 14752 - Train Loss: 0.101970, Train Acc: 0.842308 | Val Loss: 0.123973, Val Acc: 0.773196\n",
      "Epoch 14753 - Train Loss: 0.101966, Train Acc: 0.842308 | Val Loss: 0.123971, Val Acc: 0.773196\n",
      "Epoch 14754 - Train Loss: 0.101962, Train Acc: 0.842308 | Val Loss: 0.123968, Val Acc: 0.773196\n",
      "Epoch 14755 - Train Loss: 0.101958, Train Acc: 0.842308 | Val Loss: 0.123965, Val Acc: 0.773196\n",
      "Epoch 14756 - Train Loss: 0.101955, Train Acc: 0.842308 | Val Loss: 0.123963, Val Acc: 0.773196\n",
      "Epoch 14757 - Train Loss: 0.101951, Train Acc: 0.842308 | Val Loss: 0.123960, Val Acc: 0.773196\n",
      "Epoch 14758 - Train Loss: 0.101947, Train Acc: 0.842308 | Val Loss: 0.123957, Val Acc: 0.773196\n",
      "Epoch 14759 - Train Loss: 0.101943, Train Acc: 0.842308 | Val Loss: 0.123955, Val Acc: 0.773196\n",
      "Epoch 14760 - Train Loss: 0.101939, Train Acc: 0.842308 | Val Loss: 0.123952, Val Acc: 0.773196\n",
      "Epoch 14761 - Train Loss: 0.101935, Train Acc: 0.842308 | Val Loss: 0.123949, Val Acc: 0.773196\n",
      "Epoch 14762 - Train Loss: 0.101931, Train Acc: 0.842308 | Val Loss: 0.123947, Val Acc: 0.773196\n",
      "Epoch 14763 - Train Loss: 0.101927, Train Acc: 0.842308 | Val Loss: 0.123944, Val Acc: 0.773196\n",
      "Epoch 14764 - Train Loss: 0.101923, Train Acc: 0.842308 | Val Loss: 0.123941, Val Acc: 0.773196\n",
      "Epoch 14765 - Train Loss: 0.101919, Train Acc: 0.842308 | Val Loss: 0.123939, Val Acc: 0.773196\n",
      "Epoch 14766 - Train Loss: 0.101915, Train Acc: 0.842308 | Val Loss: 0.123936, Val Acc: 0.773196\n",
      "Epoch 14767 - Train Loss: 0.101911, Train Acc: 0.842308 | Val Loss: 0.123933, Val Acc: 0.773196\n",
      "Epoch 14768 - Train Loss: 0.101908, Train Acc: 0.842308 | Val Loss: 0.123931, Val Acc: 0.773196\n",
      "Epoch 14769 - Train Loss: 0.101904, Train Acc: 0.843590 | Val Loss: 0.123928, Val Acc: 0.773196\n",
      "Epoch 14770 - Train Loss: 0.101900, Train Acc: 0.843590 | Val Loss: 0.123925, Val Acc: 0.773196\n",
      "Epoch 14771 - Train Loss: 0.101896, Train Acc: 0.843590 | Val Loss: 0.123923, Val Acc: 0.773196\n",
      "Epoch 14772 - Train Loss: 0.101892, Train Acc: 0.843590 | Val Loss: 0.123920, Val Acc: 0.773196\n",
      "Epoch 14773 - Train Loss: 0.101888, Train Acc: 0.843590 | Val Loss: 0.123917, Val Acc: 0.773196\n",
      "Epoch 14774 - Train Loss: 0.101884, Train Acc: 0.843590 | Val Loss: 0.123915, Val Acc: 0.773196\n",
      "Epoch 14775 - Train Loss: 0.101880, Train Acc: 0.843590 | Val Loss: 0.123912, Val Acc: 0.773196\n",
      "Epoch 14776 - Train Loss: 0.101876, Train Acc: 0.843590 | Val Loss: 0.123909, Val Acc: 0.773196\n",
      "Epoch 14777 - Train Loss: 0.101872, Train Acc: 0.843590 | Val Loss: 0.123907, Val Acc: 0.773196\n",
      "Epoch 14778 - Train Loss: 0.101868, Train Acc: 0.843590 | Val Loss: 0.123904, Val Acc: 0.773196\n",
      "Epoch 14779 - Train Loss: 0.101865, Train Acc: 0.843590 | Val Loss: 0.123901, Val Acc: 0.773196\n",
      "Epoch 14780 - Train Loss: 0.101861, Train Acc: 0.843590 | Val Loss: 0.123899, Val Acc: 0.773196\n",
      "Epoch 14781 - Train Loss: 0.101857, Train Acc: 0.843590 | Val Loss: 0.123896, Val Acc: 0.773196\n",
      "Epoch 14782 - Train Loss: 0.101853, Train Acc: 0.843590 | Val Loss: 0.123893, Val Acc: 0.773196\n",
      "Epoch 14783 - Train Loss: 0.101849, Train Acc: 0.843590 | Val Loss: 0.123891, Val Acc: 0.773196\n",
      "Epoch 14784 - Train Loss: 0.101845, Train Acc: 0.843590 | Val Loss: 0.123888, Val Acc: 0.773196\n",
      "Epoch 14785 - Train Loss: 0.101841, Train Acc: 0.843590 | Val Loss: 0.123885, Val Acc: 0.773196\n",
      "Epoch 14786 - Train Loss: 0.101837, Train Acc: 0.843590 | Val Loss: 0.123883, Val Acc: 0.773196\n",
      "Epoch 14787 - Train Loss: 0.101833, Train Acc: 0.843590 | Val Loss: 0.123880, Val Acc: 0.773196\n",
      "Epoch 14788 - Train Loss: 0.101829, Train Acc: 0.843590 | Val Loss: 0.123877, Val Acc: 0.773196\n",
      "Epoch 14789 - Train Loss: 0.101825, Train Acc: 0.843590 | Val Loss: 0.123875, Val Acc: 0.773196\n",
      "Epoch 14790 - Train Loss: 0.101822, Train Acc: 0.843590 | Val Loss: 0.123872, Val Acc: 0.773196\n",
      "Epoch 14791 - Train Loss: 0.101818, Train Acc: 0.843590 | Val Loss: 0.123869, Val Acc: 0.773196\n",
      "Epoch 14792 - Train Loss: 0.101814, Train Acc: 0.843590 | Val Loss: 0.123867, Val Acc: 0.773196\n",
      "Epoch 14793 - Train Loss: 0.101810, Train Acc: 0.843590 | Val Loss: 0.123864, Val Acc: 0.773196\n",
      "Epoch 14794 - Train Loss: 0.101806, Train Acc: 0.843590 | Val Loss: 0.123861, Val Acc: 0.773196\n",
      "Epoch 14795 - Train Loss: 0.101802, Train Acc: 0.843590 | Val Loss: 0.123859, Val Acc: 0.773196\n",
      "Epoch 14796 - Train Loss: 0.101798, Train Acc: 0.843590 | Val Loss: 0.123856, Val Acc: 0.773196\n",
      "Epoch 14797 - Train Loss: 0.101794, Train Acc: 0.843590 | Val Loss: 0.123854, Val Acc: 0.773196\n",
      "Epoch 14798 - Train Loss: 0.101790, Train Acc: 0.843590 | Val Loss: 0.123851, Val Acc: 0.773196\n",
      "Epoch 14799 - Train Loss: 0.101787, Train Acc: 0.843590 | Val Loss: 0.123848, Val Acc: 0.773196\n",
      "Epoch 14800 - Train Loss: 0.101783, Train Acc: 0.843590 | Val Loss: 0.123846, Val Acc: 0.773196\n",
      "Epoch 14801 - Train Loss: 0.101779, Train Acc: 0.843590 | Val Loss: 0.123843, Val Acc: 0.773196\n",
      "Epoch 14802 - Train Loss: 0.101775, Train Acc: 0.843590 | Val Loss: 0.123840, Val Acc: 0.773196\n",
      "Epoch 14803 - Train Loss: 0.101771, Train Acc: 0.843590 | Val Loss: 0.123838, Val Acc: 0.773196\n",
      "Epoch 14804 - Train Loss: 0.101767, Train Acc: 0.843590 | Val Loss: 0.123835, Val Acc: 0.773196\n",
      "Epoch 14805 - Train Loss: 0.101763, Train Acc: 0.843590 | Val Loss: 0.123832, Val Acc: 0.773196\n",
      "Epoch 14806 - Train Loss: 0.101759, Train Acc: 0.843590 | Val Loss: 0.123830, Val Acc: 0.773196\n",
      "Epoch 14807 - Train Loss: 0.101755, Train Acc: 0.843590 | Val Loss: 0.123827, Val Acc: 0.773196\n",
      "Epoch 14808 - Train Loss: 0.101751, Train Acc: 0.843590 | Val Loss: 0.123824, Val Acc: 0.773196\n",
      "Epoch 14809 - Train Loss: 0.101748, Train Acc: 0.843590 | Val Loss: 0.123822, Val Acc: 0.773196\n",
      "Epoch 14810 - Train Loss: 0.101744, Train Acc: 0.843590 | Val Loss: 0.123819, Val Acc: 0.773196\n",
      "Epoch 14811 - Train Loss: 0.101740, Train Acc: 0.843590 | Val Loss: 0.123816, Val Acc: 0.773196\n",
      "Epoch 14812 - Train Loss: 0.101736, Train Acc: 0.843590 | Val Loss: 0.123814, Val Acc: 0.773196\n",
      "Epoch 14813 - Train Loss: 0.101732, Train Acc: 0.843590 | Val Loss: 0.123811, Val Acc: 0.773196\n",
      "Epoch 14814 - Train Loss: 0.101728, Train Acc: 0.843590 | Val Loss: 0.123808, Val Acc: 0.773196\n",
      "Epoch 14815 - Train Loss: 0.101724, Train Acc: 0.843590 | Val Loss: 0.123806, Val Acc: 0.773196\n",
      "Epoch 14816 - Train Loss: 0.101720, Train Acc: 0.843590 | Val Loss: 0.123803, Val Acc: 0.773196\n",
      "Epoch 14817 - Train Loss: 0.101716, Train Acc: 0.843590 | Val Loss: 0.123801, Val Acc: 0.773196\n",
      "Epoch 14818 - Train Loss: 0.101713, Train Acc: 0.843590 | Val Loss: 0.123798, Val Acc: 0.773196\n",
      "Epoch 14819 - Train Loss: 0.101709, Train Acc: 0.843590 | Val Loss: 0.123795, Val Acc: 0.773196\n",
      "Epoch 14820 - Train Loss: 0.101705, Train Acc: 0.843590 | Val Loss: 0.123793, Val Acc: 0.773196\n",
      "Epoch 14821 - Train Loss: 0.101701, Train Acc: 0.843590 | Val Loss: 0.123790, Val Acc: 0.773196\n",
      "Epoch 14822 - Train Loss: 0.101697, Train Acc: 0.843590 | Val Loss: 0.123787, Val Acc: 0.773196\n",
      "Epoch 14823 - Train Loss: 0.101693, Train Acc: 0.843590 | Val Loss: 0.123785, Val Acc: 0.773196\n",
      "Epoch 14824 - Train Loss: 0.101689, Train Acc: 0.843590 | Val Loss: 0.123782, Val Acc: 0.773196\n",
      "Epoch 14825 - Train Loss: 0.101685, Train Acc: 0.843590 | Val Loss: 0.123779, Val Acc: 0.773196\n",
      "Epoch 14826 - Train Loss: 0.101681, Train Acc: 0.843590 | Val Loss: 0.123777, Val Acc: 0.773196\n",
      "Epoch 14827 - Train Loss: 0.101678, Train Acc: 0.843590 | Val Loss: 0.123774, Val Acc: 0.773196\n",
      "Epoch 14828 - Train Loss: 0.101674, Train Acc: 0.843590 | Val Loss: 0.123771, Val Acc: 0.773196\n",
      "Epoch 14829 - Train Loss: 0.101670, Train Acc: 0.843590 | Val Loss: 0.123769, Val Acc: 0.773196\n",
      "Epoch 14830 - Train Loss: 0.101666, Train Acc: 0.843590 | Val Loss: 0.123766, Val Acc: 0.773196\n",
      "Epoch 14831 - Train Loss: 0.101662, Train Acc: 0.843590 | Val Loss: 0.123764, Val Acc: 0.773196\n",
      "Epoch 14832 - Train Loss: 0.101658, Train Acc: 0.843590 | Val Loss: 0.123761, Val Acc: 0.773196\n",
      "Epoch 14833 - Train Loss: 0.101654, Train Acc: 0.843590 | Val Loss: 0.123758, Val Acc: 0.773196\n",
      "Epoch 14834 - Train Loss: 0.101650, Train Acc: 0.843590 | Val Loss: 0.123756, Val Acc: 0.773196\n",
      "Epoch 14835 - Train Loss: 0.101647, Train Acc: 0.843590 | Val Loss: 0.123753, Val Acc: 0.773196\n",
      "Epoch 14836 - Train Loss: 0.101643, Train Acc: 0.843590 | Val Loss: 0.123750, Val Acc: 0.773196\n",
      "Epoch 14837 - Train Loss: 0.101639, Train Acc: 0.843590 | Val Loss: 0.123748, Val Acc: 0.773196\n",
      "Epoch 14838 - Train Loss: 0.101635, Train Acc: 0.843590 | Val Loss: 0.123745, Val Acc: 0.773196\n",
      "Epoch 14839 - Train Loss: 0.101631, Train Acc: 0.843590 | Val Loss: 0.123742, Val Acc: 0.773196\n",
      "Epoch 14840 - Train Loss: 0.101627, Train Acc: 0.843590 | Val Loss: 0.123740, Val Acc: 0.773196\n",
      "Epoch 14841 - Train Loss: 0.101623, Train Acc: 0.843590 | Val Loss: 0.123737, Val Acc: 0.773196\n",
      "Epoch 14842 - Train Loss: 0.101619, Train Acc: 0.843590 | Val Loss: 0.123735, Val Acc: 0.773196\n",
      "Epoch 14843 - Train Loss: 0.101616, Train Acc: 0.843590 | Val Loss: 0.123732, Val Acc: 0.773196\n",
      "Epoch 14844 - Train Loss: 0.101612, Train Acc: 0.843590 | Val Loss: 0.123729, Val Acc: 0.773196\n",
      "Epoch 14845 - Train Loss: 0.101608, Train Acc: 0.843590 | Val Loss: 0.123727, Val Acc: 0.773196\n",
      "Epoch 14846 - Train Loss: 0.101604, Train Acc: 0.843590 | Val Loss: 0.123724, Val Acc: 0.773196\n",
      "Epoch 14847 - Train Loss: 0.101600, Train Acc: 0.843590 | Val Loss: 0.123721, Val Acc: 0.773196\n",
      "Epoch 14848 - Train Loss: 0.101596, Train Acc: 0.843590 | Val Loss: 0.123719, Val Acc: 0.773196\n",
      "Epoch 14849 - Train Loss: 0.101592, Train Acc: 0.843590 | Val Loss: 0.123716, Val Acc: 0.773196\n",
      "Epoch 14850 - Train Loss: 0.101588, Train Acc: 0.843590 | Val Loss: 0.123714, Val Acc: 0.773196\n",
      "Epoch 14851 - Train Loss: 0.101585, Train Acc: 0.843590 | Val Loss: 0.123711, Val Acc: 0.773196\n",
      "Epoch 14852 - Train Loss: 0.101581, Train Acc: 0.843590 | Val Loss: 0.123708, Val Acc: 0.773196\n",
      "Epoch 14853 - Train Loss: 0.101577, Train Acc: 0.843590 | Val Loss: 0.123706, Val Acc: 0.773196\n",
      "Epoch 14854 - Train Loss: 0.101573, Train Acc: 0.843590 | Val Loss: 0.123703, Val Acc: 0.773196\n",
      "Epoch 14855 - Train Loss: 0.101569, Train Acc: 0.843590 | Val Loss: 0.123700, Val Acc: 0.773196\n",
      "Epoch 14856 - Train Loss: 0.101565, Train Acc: 0.843590 | Val Loss: 0.123698, Val Acc: 0.773196\n",
      "Epoch 14857 - Train Loss: 0.101561, Train Acc: 0.843590 | Val Loss: 0.123695, Val Acc: 0.773196\n",
      "Epoch 14858 - Train Loss: 0.101557, Train Acc: 0.843590 | Val Loss: 0.123693, Val Acc: 0.773196\n",
      "Epoch 14859 - Train Loss: 0.101554, Train Acc: 0.843590 | Val Loss: 0.123690, Val Acc: 0.773196\n",
      "Epoch 14860 - Train Loss: 0.101550, Train Acc: 0.843590 | Val Loss: 0.123687, Val Acc: 0.773196\n",
      "Epoch 14861 - Train Loss: 0.101546, Train Acc: 0.843590 | Val Loss: 0.123685, Val Acc: 0.773196\n",
      "Epoch 14862 - Train Loss: 0.101542, Train Acc: 0.843590 | Val Loss: 0.123682, Val Acc: 0.773196\n",
      "Epoch 14863 - Train Loss: 0.101538, Train Acc: 0.843590 | Val Loss: 0.123679, Val Acc: 0.773196\n",
      "Epoch 14864 - Train Loss: 0.101534, Train Acc: 0.843590 | Val Loss: 0.123677, Val Acc: 0.773196\n",
      "Epoch 14865 - Train Loss: 0.101530, Train Acc: 0.843590 | Val Loss: 0.123674, Val Acc: 0.773196\n",
      "Epoch 14866 - Train Loss: 0.101527, Train Acc: 0.843590 | Val Loss: 0.123672, Val Acc: 0.773196\n",
      "Epoch 14867 - Train Loss: 0.101523, Train Acc: 0.843590 | Val Loss: 0.123669, Val Acc: 0.773196\n",
      "Epoch 14868 - Train Loss: 0.101519, Train Acc: 0.843590 | Val Loss: 0.123666, Val Acc: 0.773196\n",
      "Epoch 14869 - Train Loss: 0.101515, Train Acc: 0.843590 | Val Loss: 0.123664, Val Acc: 0.773196\n",
      "Epoch 14870 - Train Loss: 0.101511, Train Acc: 0.843590 | Val Loss: 0.123661, Val Acc: 0.773196\n",
      "Epoch 14871 - Train Loss: 0.101507, Train Acc: 0.843590 | Val Loss: 0.123658, Val Acc: 0.773196\n",
      "Epoch 14872 - Train Loss: 0.101503, Train Acc: 0.843590 | Val Loss: 0.123656, Val Acc: 0.773196\n",
      "Epoch 14873 - Train Loss: 0.101500, Train Acc: 0.843590 | Val Loss: 0.123653, Val Acc: 0.773196\n",
      "Epoch 14874 - Train Loss: 0.101496, Train Acc: 0.843590 | Val Loss: 0.123651, Val Acc: 0.773196\n",
      "Epoch 14875 - Train Loss: 0.101492, Train Acc: 0.843590 | Val Loss: 0.123648, Val Acc: 0.773196\n",
      "Epoch 14876 - Train Loss: 0.101488, Train Acc: 0.843590 | Val Loss: 0.123645, Val Acc: 0.773196\n",
      "Epoch 14877 - Train Loss: 0.101484, Train Acc: 0.843590 | Val Loss: 0.123643, Val Acc: 0.773196\n",
      "Epoch 14878 - Train Loss: 0.101480, Train Acc: 0.843590 | Val Loss: 0.123640, Val Acc: 0.773196\n",
      "Epoch 14879 - Train Loss: 0.101476, Train Acc: 0.843590 | Val Loss: 0.123638, Val Acc: 0.773196\n",
      "Epoch 14880 - Train Loss: 0.101473, Train Acc: 0.843590 | Val Loss: 0.123635, Val Acc: 0.773196\n",
      "Epoch 14881 - Train Loss: 0.101469, Train Acc: 0.843590 | Val Loss: 0.123632, Val Acc: 0.773196\n",
      "Epoch 14882 - Train Loss: 0.101465, Train Acc: 0.843590 | Val Loss: 0.123630, Val Acc: 0.773196\n",
      "Epoch 14883 - Train Loss: 0.101461, Train Acc: 0.843590 | Val Loss: 0.123627, Val Acc: 0.773196\n",
      "Epoch 14884 - Train Loss: 0.101457, Train Acc: 0.843590 | Val Loss: 0.123625, Val Acc: 0.773196\n",
      "Epoch 14885 - Train Loss: 0.101453, Train Acc: 0.843590 | Val Loss: 0.123622, Val Acc: 0.773196\n",
      "Epoch 14886 - Train Loss: 0.101449, Train Acc: 0.843590 | Val Loss: 0.123619, Val Acc: 0.773196\n",
      "Epoch 14887 - Train Loss: 0.101446, Train Acc: 0.843590 | Val Loss: 0.123617, Val Acc: 0.773196\n",
      "Epoch 14888 - Train Loss: 0.101442, Train Acc: 0.843590 | Val Loss: 0.123614, Val Acc: 0.773196\n",
      "Epoch 14889 - Train Loss: 0.101438, Train Acc: 0.843590 | Val Loss: 0.123612, Val Acc: 0.773196\n",
      "Epoch 14890 - Train Loss: 0.101434, Train Acc: 0.843590 | Val Loss: 0.123609, Val Acc: 0.773196\n",
      "Epoch 14891 - Train Loss: 0.101430, Train Acc: 0.843590 | Val Loss: 0.123606, Val Acc: 0.773196\n",
      "Epoch 14892 - Train Loss: 0.101426, Train Acc: 0.843590 | Val Loss: 0.123604, Val Acc: 0.773196\n",
      "Epoch 14893 - Train Loss: 0.101422, Train Acc: 0.843590 | Val Loss: 0.123601, Val Acc: 0.773196\n",
      "Epoch 14894 - Train Loss: 0.101419, Train Acc: 0.843590 | Val Loss: 0.123598, Val Acc: 0.773196\n",
      "Epoch 14895 - Train Loss: 0.101415, Train Acc: 0.843590 | Val Loss: 0.123596, Val Acc: 0.773196\n",
      "Epoch 14896 - Train Loss: 0.101411, Train Acc: 0.843590 | Val Loss: 0.123593, Val Acc: 0.773196\n",
      "Epoch 14897 - Train Loss: 0.101407, Train Acc: 0.843590 | Val Loss: 0.123591, Val Acc: 0.773196\n",
      "Epoch 14898 - Train Loss: 0.101403, Train Acc: 0.843590 | Val Loss: 0.123588, Val Acc: 0.773196\n",
      "Epoch 14899 - Train Loss: 0.101399, Train Acc: 0.843590 | Val Loss: 0.123585, Val Acc: 0.773196\n",
      "Epoch 14900 - Train Loss: 0.101396, Train Acc: 0.843590 | Val Loss: 0.123583, Val Acc: 0.773196\n",
      "Epoch 14901 - Train Loss: 0.101392, Train Acc: 0.843590 | Val Loss: 0.123580, Val Acc: 0.773196\n",
      "Epoch 14902 - Train Loss: 0.101388, Train Acc: 0.843590 | Val Loss: 0.123578, Val Acc: 0.773196\n",
      "Epoch 14903 - Train Loss: 0.101384, Train Acc: 0.843590 | Val Loss: 0.123575, Val Acc: 0.773196\n",
      "Epoch 14904 - Train Loss: 0.101380, Train Acc: 0.843590 | Val Loss: 0.123572, Val Acc: 0.773196\n",
      "Epoch 14905 - Train Loss: 0.101376, Train Acc: 0.843590 | Val Loss: 0.123570, Val Acc: 0.773196\n",
      "Epoch 14906 - Train Loss: 0.101372, Train Acc: 0.843590 | Val Loss: 0.123567, Val Acc: 0.773196\n",
      "Epoch 14907 - Train Loss: 0.101369, Train Acc: 0.843590 | Val Loss: 0.123565, Val Acc: 0.773196\n",
      "Epoch 14908 - Train Loss: 0.101365, Train Acc: 0.843590 | Val Loss: 0.123562, Val Acc: 0.773196\n",
      "Epoch 14909 - Train Loss: 0.101361, Train Acc: 0.843590 | Val Loss: 0.123559, Val Acc: 0.773196\n",
      "Epoch 14910 - Train Loss: 0.101357, Train Acc: 0.843590 | Val Loss: 0.123557, Val Acc: 0.773196\n",
      "Epoch 14911 - Train Loss: 0.101353, Train Acc: 0.843590 | Val Loss: 0.123554, Val Acc: 0.773196\n",
      "Epoch 14912 - Train Loss: 0.101349, Train Acc: 0.843590 | Val Loss: 0.123552, Val Acc: 0.773196\n",
      "Epoch 14913 - Train Loss: 0.101346, Train Acc: 0.843590 | Val Loss: 0.123549, Val Acc: 0.773196\n",
      "Epoch 14914 - Train Loss: 0.101342, Train Acc: 0.843590 | Val Loss: 0.123546, Val Acc: 0.773196\n",
      "Epoch 14915 - Train Loss: 0.101338, Train Acc: 0.843590 | Val Loss: 0.123544, Val Acc: 0.773196\n",
      "Epoch 14916 - Train Loss: 0.101334, Train Acc: 0.843590 | Val Loss: 0.123541, Val Acc: 0.773196\n",
      "Epoch 14917 - Train Loss: 0.101330, Train Acc: 0.843590 | Val Loss: 0.123539, Val Acc: 0.773196\n",
      "Epoch 14918 - Train Loss: 0.101326, Train Acc: 0.843590 | Val Loss: 0.123536, Val Acc: 0.773196\n",
      "Epoch 14919 - Train Loss: 0.101323, Train Acc: 0.843590 | Val Loss: 0.123534, Val Acc: 0.773196\n",
      "Epoch 14920 - Train Loss: 0.101319, Train Acc: 0.843590 | Val Loss: 0.123531, Val Acc: 0.773196\n",
      "Epoch 14921 - Train Loss: 0.101315, Train Acc: 0.843590 | Val Loss: 0.123528, Val Acc: 0.773196\n",
      "Epoch 14922 - Train Loss: 0.101311, Train Acc: 0.843590 | Val Loss: 0.123526, Val Acc: 0.773196\n",
      "Epoch 14923 - Train Loss: 0.101307, Train Acc: 0.843590 | Val Loss: 0.123523, Val Acc: 0.773196\n",
      "Epoch 14924 - Train Loss: 0.101303, Train Acc: 0.843590 | Val Loss: 0.123521, Val Acc: 0.773196\n",
      "Epoch 14925 - Train Loss: 0.101300, Train Acc: 0.843590 | Val Loss: 0.123518, Val Acc: 0.773196\n",
      "Epoch 14926 - Train Loss: 0.101296, Train Acc: 0.843590 | Val Loss: 0.123515, Val Acc: 0.773196\n",
      "Epoch 14927 - Train Loss: 0.101292, Train Acc: 0.843590 | Val Loss: 0.123513, Val Acc: 0.773196\n",
      "Epoch 14928 - Train Loss: 0.101288, Train Acc: 0.843590 | Val Loss: 0.123510, Val Acc: 0.773196\n",
      "Epoch 14929 - Train Loss: 0.101284, Train Acc: 0.843590 | Val Loss: 0.123508, Val Acc: 0.773196\n",
      "Epoch 14930 - Train Loss: 0.101280, Train Acc: 0.843590 | Val Loss: 0.123505, Val Acc: 0.773196\n",
      "Epoch 14931 - Train Loss: 0.101277, Train Acc: 0.843590 | Val Loss: 0.123502, Val Acc: 0.773196\n",
      "Epoch 14932 - Train Loss: 0.101273, Train Acc: 0.843590 | Val Loss: 0.123500, Val Acc: 0.773196\n",
      "Epoch 14933 - Train Loss: 0.101269, Train Acc: 0.843590 | Val Loss: 0.123497, Val Acc: 0.773196\n",
      "Epoch 14934 - Train Loss: 0.101265, Train Acc: 0.843590 | Val Loss: 0.123495, Val Acc: 0.773196\n",
      "Epoch 14935 - Train Loss: 0.101261, Train Acc: 0.843590 | Val Loss: 0.123492, Val Acc: 0.773196\n",
      "Epoch 14936 - Train Loss: 0.101257, Train Acc: 0.843590 | Val Loss: 0.123490, Val Acc: 0.773196\n",
      "Epoch 14937 - Train Loss: 0.101254, Train Acc: 0.843590 | Val Loss: 0.123487, Val Acc: 0.773196\n",
      "Epoch 14938 - Train Loss: 0.101250, Train Acc: 0.843590 | Val Loss: 0.123484, Val Acc: 0.773196\n",
      "Epoch 14939 - Train Loss: 0.101246, Train Acc: 0.843590 | Val Loss: 0.123482, Val Acc: 0.773196\n",
      "Epoch 14940 - Train Loss: 0.101242, Train Acc: 0.843590 | Val Loss: 0.123479, Val Acc: 0.773196\n",
      "Epoch 14941 - Train Loss: 0.101238, Train Acc: 0.843590 | Val Loss: 0.123477, Val Acc: 0.773196\n",
      "Epoch 14942 - Train Loss: 0.101234, Train Acc: 0.843590 | Val Loss: 0.123474, Val Acc: 0.773196\n",
      "Epoch 14943 - Train Loss: 0.101231, Train Acc: 0.843590 | Val Loss: 0.123471, Val Acc: 0.773196\n",
      "Epoch 14944 - Train Loss: 0.101227, Train Acc: 0.843590 | Val Loss: 0.123469, Val Acc: 0.773196\n",
      "Epoch 14945 - Train Loss: 0.101223, Train Acc: 0.843590 | Val Loss: 0.123466, Val Acc: 0.773196\n",
      "Epoch 14946 - Train Loss: 0.101219, Train Acc: 0.843590 | Val Loss: 0.123464, Val Acc: 0.773196\n",
      "Epoch 14947 - Train Loss: 0.101215, Train Acc: 0.843590 | Val Loss: 0.123461, Val Acc: 0.773196\n",
      "Epoch 14948 - Train Loss: 0.101212, Train Acc: 0.843590 | Val Loss: 0.123459, Val Acc: 0.773196\n",
      "Epoch 14949 - Train Loss: 0.101208, Train Acc: 0.843590 | Val Loss: 0.123456, Val Acc: 0.773196\n",
      "Epoch 14950 - Train Loss: 0.101204, Train Acc: 0.844872 | Val Loss: 0.123453, Val Acc: 0.773196\n",
      "Epoch 14951 - Train Loss: 0.101200, Train Acc: 0.844872 | Val Loss: 0.123451, Val Acc: 0.773196\n",
      "Epoch 14952 - Train Loss: 0.101196, Train Acc: 0.844872 | Val Loss: 0.123448, Val Acc: 0.773196\n",
      "Epoch 14953 - Train Loss: 0.101192, Train Acc: 0.844872 | Val Loss: 0.123446, Val Acc: 0.773196\n",
      "Epoch 14954 - Train Loss: 0.101189, Train Acc: 0.844872 | Val Loss: 0.123443, Val Acc: 0.773196\n",
      "Epoch 14955 - Train Loss: 0.101185, Train Acc: 0.844872 | Val Loss: 0.123441, Val Acc: 0.773196\n",
      "Epoch 14956 - Train Loss: 0.101181, Train Acc: 0.844872 | Val Loss: 0.123438, Val Acc: 0.773196\n",
      "Epoch 14957 - Train Loss: 0.101177, Train Acc: 0.844872 | Val Loss: 0.123435, Val Acc: 0.773196\n",
      "Epoch 14958 - Train Loss: 0.101173, Train Acc: 0.844872 | Val Loss: 0.123433, Val Acc: 0.773196\n",
      "Epoch 14959 - Train Loss: 0.101170, Train Acc: 0.844872 | Val Loss: 0.123430, Val Acc: 0.773196\n",
      "Epoch 14960 - Train Loss: 0.101166, Train Acc: 0.844872 | Val Loss: 0.123428, Val Acc: 0.773196\n",
      "Epoch 14961 - Train Loss: 0.101162, Train Acc: 0.844872 | Val Loss: 0.123425, Val Acc: 0.773196\n",
      "Epoch 14962 - Train Loss: 0.101158, Train Acc: 0.844872 | Val Loss: 0.123423, Val Acc: 0.773196\n",
      "Epoch 14963 - Train Loss: 0.101154, Train Acc: 0.844872 | Val Loss: 0.123420, Val Acc: 0.773196\n",
      "Epoch 14964 - Train Loss: 0.101150, Train Acc: 0.844872 | Val Loss: 0.123417, Val Acc: 0.773196\n",
      "Epoch 14965 - Train Loss: 0.101147, Train Acc: 0.844872 | Val Loss: 0.123415, Val Acc: 0.773196\n",
      "Epoch 14966 - Train Loss: 0.101143, Train Acc: 0.844872 | Val Loss: 0.123412, Val Acc: 0.773196\n",
      "Epoch 14967 - Train Loss: 0.101139, Train Acc: 0.844872 | Val Loss: 0.123410, Val Acc: 0.773196\n",
      "Epoch 14968 - Train Loss: 0.101135, Train Acc: 0.844872 | Val Loss: 0.123407, Val Acc: 0.773196\n",
      "Epoch 14969 - Train Loss: 0.101131, Train Acc: 0.844872 | Val Loss: 0.123405, Val Acc: 0.773196\n",
      "Epoch 14970 - Train Loss: 0.101128, Train Acc: 0.844872 | Val Loss: 0.123402, Val Acc: 0.773196\n",
      "Epoch 14971 - Train Loss: 0.101124, Train Acc: 0.844872 | Val Loss: 0.123399, Val Acc: 0.773196\n",
      "Epoch 14972 - Train Loss: 0.101120, Train Acc: 0.844872 | Val Loss: 0.123397, Val Acc: 0.773196\n",
      "Epoch 14973 - Train Loss: 0.101116, Train Acc: 0.844872 | Val Loss: 0.123394, Val Acc: 0.773196\n",
      "Epoch 14974 - Train Loss: 0.101112, Train Acc: 0.844872 | Val Loss: 0.123392, Val Acc: 0.773196\n",
      "Epoch 14975 - Train Loss: 0.101109, Train Acc: 0.844872 | Val Loss: 0.123389, Val Acc: 0.773196\n",
      "Epoch 14976 - Train Loss: 0.101105, Train Acc: 0.844872 | Val Loss: 0.123387, Val Acc: 0.773196\n",
      "Epoch 14977 - Train Loss: 0.101101, Train Acc: 0.844872 | Val Loss: 0.123384, Val Acc: 0.773196\n",
      "Epoch 14978 - Train Loss: 0.101097, Train Acc: 0.844872 | Val Loss: 0.123382, Val Acc: 0.773196\n",
      "Epoch 14979 - Train Loss: 0.101093, Train Acc: 0.844872 | Val Loss: 0.123379, Val Acc: 0.773196\n",
      "Epoch 14980 - Train Loss: 0.101090, Train Acc: 0.844872 | Val Loss: 0.123376, Val Acc: 0.773196\n",
      "Epoch 14981 - Train Loss: 0.101086, Train Acc: 0.844872 | Val Loss: 0.123374, Val Acc: 0.773196\n",
      "Epoch 14982 - Train Loss: 0.101082, Train Acc: 0.844872 | Val Loss: 0.123371, Val Acc: 0.773196\n",
      "Epoch 14983 - Train Loss: 0.101078, Train Acc: 0.844872 | Val Loss: 0.123369, Val Acc: 0.773196\n",
      "Epoch 14984 - Train Loss: 0.101074, Train Acc: 0.844872 | Val Loss: 0.123366, Val Acc: 0.773196\n",
      "Epoch 14985 - Train Loss: 0.101071, Train Acc: 0.844872 | Val Loss: 0.123364, Val Acc: 0.773196\n",
      "Epoch 14986 - Train Loss: 0.101067, Train Acc: 0.844872 | Val Loss: 0.123361, Val Acc: 0.773196\n",
      "Epoch 14987 - Train Loss: 0.101063, Train Acc: 0.844872 | Val Loss: 0.123359, Val Acc: 0.773196\n",
      "Epoch 14988 - Train Loss: 0.101059, Train Acc: 0.844872 | Val Loss: 0.123356, Val Acc: 0.773196\n",
      "Epoch 14989 - Train Loss: 0.101055, Train Acc: 0.844872 | Val Loss: 0.123353, Val Acc: 0.773196\n",
      "Epoch 14990 - Train Loss: 0.101052, Train Acc: 0.844872 | Val Loss: 0.123351, Val Acc: 0.773196\n",
      "Epoch 14991 - Train Loss: 0.101048, Train Acc: 0.844872 | Val Loss: 0.123348, Val Acc: 0.773196\n",
      "Epoch 14992 - Train Loss: 0.101044, Train Acc: 0.844872 | Val Loss: 0.123346, Val Acc: 0.773196\n",
      "Epoch 14993 - Train Loss: 0.101040, Train Acc: 0.844872 | Val Loss: 0.123343, Val Acc: 0.773196\n",
      "Epoch 14994 - Train Loss: 0.101036, Train Acc: 0.844872 | Val Loss: 0.123341, Val Acc: 0.773196\n",
      "Epoch 14995 - Train Loss: 0.101033, Train Acc: 0.844872 | Val Loss: 0.123338, Val Acc: 0.773196\n",
      "Epoch 14996 - Train Loss: 0.101029, Train Acc: 0.844872 | Val Loss: 0.123335, Val Acc: 0.773196\n",
      "Epoch 14997 - Train Loss: 0.101025, Train Acc: 0.844872 | Val Loss: 0.123333, Val Acc: 0.773196\n",
      "Epoch 14998 - Train Loss: 0.101021, Train Acc: 0.844872 | Val Loss: 0.123330, Val Acc: 0.773196\n",
      "Epoch 14999 - Train Loss: 0.101017, Train Acc: 0.844872 | Val Loss: 0.123328, Val Acc: 0.773196\n",
      "Epoch 15000 - Train Loss: 0.101014, Train Acc: 0.844872 | Val Loss: 0.123325, Val Acc: 0.773196\n",
      "Epoch 15001 - Train Loss: 0.101010, Train Acc: 0.844872 | Val Loss: 0.123323, Val Acc: 0.773196\n",
      "Epoch 15002 - Train Loss: 0.101006, Train Acc: 0.844872 | Val Loss: 0.123320, Val Acc: 0.773196\n",
      "Epoch 15003 - Train Loss: 0.101002, Train Acc: 0.844872 | Val Loss: 0.123317, Val Acc: 0.773196\n",
      "Epoch 15004 - Train Loss: 0.100998, Train Acc: 0.844872 | Val Loss: 0.123315, Val Acc: 0.773196\n",
      "Epoch 15005 - Train Loss: 0.100995, Train Acc: 0.844872 | Val Loss: 0.123312, Val Acc: 0.773196\n",
      "Epoch 15006 - Train Loss: 0.100991, Train Acc: 0.844872 | Val Loss: 0.123310, Val Acc: 0.773196\n",
      "Epoch 15007 - Train Loss: 0.100987, Train Acc: 0.844872 | Val Loss: 0.123307, Val Acc: 0.773196\n",
      "Epoch 15008 - Train Loss: 0.100983, Train Acc: 0.844872 | Val Loss: 0.123305, Val Acc: 0.773196\n",
      "Epoch 15009 - Train Loss: 0.100979, Train Acc: 0.844872 | Val Loss: 0.123302, Val Acc: 0.773196\n",
      "Epoch 15010 - Train Loss: 0.100976, Train Acc: 0.844872 | Val Loss: 0.123300, Val Acc: 0.773196\n",
      "Epoch 15011 - Train Loss: 0.100972, Train Acc: 0.844872 | Val Loss: 0.123297, Val Acc: 0.773196\n",
      "Epoch 15012 - Train Loss: 0.100968, Train Acc: 0.844872 | Val Loss: 0.123294, Val Acc: 0.773196\n",
      "Epoch 15013 - Train Loss: 0.100964, Train Acc: 0.844872 | Val Loss: 0.123292, Val Acc: 0.773196\n",
      "Epoch 15014 - Train Loss: 0.100961, Train Acc: 0.844872 | Val Loss: 0.123289, Val Acc: 0.773196\n",
      "Epoch 15015 - Train Loss: 0.100957, Train Acc: 0.844872 | Val Loss: 0.123287, Val Acc: 0.773196\n",
      "Epoch 15016 - Train Loss: 0.100953, Train Acc: 0.844872 | Val Loss: 0.123284, Val Acc: 0.773196\n",
      "Epoch 15017 - Train Loss: 0.100949, Train Acc: 0.844872 | Val Loss: 0.123282, Val Acc: 0.773196\n",
      "Epoch 15018 - Train Loss: 0.100945, Train Acc: 0.844872 | Val Loss: 0.123279, Val Acc: 0.773196\n",
      "Epoch 15019 - Train Loss: 0.100942, Train Acc: 0.844872 | Val Loss: 0.123277, Val Acc: 0.773196\n",
      "Epoch 15020 - Train Loss: 0.100938, Train Acc: 0.844872 | Val Loss: 0.123274, Val Acc: 0.773196\n",
      "Epoch 15021 - Train Loss: 0.100934, Train Acc: 0.844872 | Val Loss: 0.123272, Val Acc: 0.773196\n",
      "Epoch 15022 - Train Loss: 0.100930, Train Acc: 0.844872 | Val Loss: 0.123269, Val Acc: 0.773196\n",
      "Epoch 15023 - Train Loss: 0.100926, Train Acc: 0.844872 | Val Loss: 0.123266, Val Acc: 0.773196\n",
      "Epoch 15024 - Train Loss: 0.100923, Train Acc: 0.844872 | Val Loss: 0.123264, Val Acc: 0.773196\n",
      "Epoch 15025 - Train Loss: 0.100919, Train Acc: 0.844872 | Val Loss: 0.123261, Val Acc: 0.773196\n",
      "Epoch 15026 - Train Loss: 0.100915, Train Acc: 0.844872 | Val Loss: 0.123259, Val Acc: 0.773196\n",
      "Epoch 15027 - Train Loss: 0.100911, Train Acc: 0.844872 | Val Loss: 0.123256, Val Acc: 0.773196\n",
      "Epoch 15028 - Train Loss: 0.100908, Train Acc: 0.844872 | Val Loss: 0.123254, Val Acc: 0.773196\n",
      "Epoch 15029 - Train Loss: 0.100904, Train Acc: 0.844872 | Val Loss: 0.123251, Val Acc: 0.773196\n",
      "Epoch 15030 - Train Loss: 0.100900, Train Acc: 0.844872 | Val Loss: 0.123249, Val Acc: 0.773196\n",
      "Epoch 15031 - Train Loss: 0.100896, Train Acc: 0.844872 | Val Loss: 0.123246, Val Acc: 0.773196\n",
      "Epoch 15032 - Train Loss: 0.100892, Train Acc: 0.844872 | Val Loss: 0.123244, Val Acc: 0.773196\n",
      "Epoch 15033 - Train Loss: 0.100889, Train Acc: 0.844872 | Val Loss: 0.123241, Val Acc: 0.773196\n",
      "Epoch 15034 - Train Loss: 0.100885, Train Acc: 0.844872 | Val Loss: 0.123238, Val Acc: 0.773196\n",
      "Epoch 15035 - Train Loss: 0.100881, Train Acc: 0.844872 | Val Loss: 0.123236, Val Acc: 0.773196\n",
      "Epoch 15036 - Train Loss: 0.100877, Train Acc: 0.844872 | Val Loss: 0.123233, Val Acc: 0.773196\n",
      "Epoch 15037 - Train Loss: 0.100874, Train Acc: 0.844872 | Val Loss: 0.123231, Val Acc: 0.773196\n",
      "Epoch 15038 - Train Loss: 0.100870, Train Acc: 0.844872 | Val Loss: 0.123228, Val Acc: 0.773196\n",
      "Epoch 15039 - Train Loss: 0.100866, Train Acc: 0.844872 | Val Loss: 0.123226, Val Acc: 0.773196\n",
      "Epoch 15040 - Train Loss: 0.100862, Train Acc: 0.844872 | Val Loss: 0.123223, Val Acc: 0.773196\n",
      "Epoch 15041 - Train Loss: 0.100858, Train Acc: 0.844872 | Val Loss: 0.123221, Val Acc: 0.773196\n",
      "Epoch 15042 - Train Loss: 0.100855, Train Acc: 0.844872 | Val Loss: 0.123218, Val Acc: 0.773196\n",
      "Epoch 15043 - Train Loss: 0.100851, Train Acc: 0.844872 | Val Loss: 0.123216, Val Acc: 0.773196\n",
      "Epoch 15044 - Train Loss: 0.100847, Train Acc: 0.844872 | Val Loss: 0.123213, Val Acc: 0.773196\n",
      "Epoch 15045 - Train Loss: 0.100843, Train Acc: 0.844872 | Val Loss: 0.123211, Val Acc: 0.773196\n",
      "Epoch 15046 - Train Loss: 0.100840, Train Acc: 0.844872 | Val Loss: 0.123208, Val Acc: 0.773196\n",
      "Epoch 15047 - Train Loss: 0.100836, Train Acc: 0.844872 | Val Loss: 0.123206, Val Acc: 0.773196\n",
      "Epoch 15048 - Train Loss: 0.100832, Train Acc: 0.844872 | Val Loss: 0.123203, Val Acc: 0.773196\n",
      "Epoch 15049 - Train Loss: 0.100828, Train Acc: 0.844872 | Val Loss: 0.123200, Val Acc: 0.773196\n",
      "Epoch 15050 - Train Loss: 0.100825, Train Acc: 0.846154 | Val Loss: 0.123198, Val Acc: 0.773196\n",
      "Epoch 15051 - Train Loss: 0.100821, Train Acc: 0.846154 | Val Loss: 0.123195, Val Acc: 0.773196\n",
      "Epoch 15052 - Train Loss: 0.100817, Train Acc: 0.846154 | Val Loss: 0.123193, Val Acc: 0.773196\n",
      "Epoch 15053 - Train Loss: 0.100813, Train Acc: 0.846154 | Val Loss: 0.123190, Val Acc: 0.773196\n",
      "Epoch 15054 - Train Loss: 0.100809, Train Acc: 0.846154 | Val Loss: 0.123188, Val Acc: 0.773196\n",
      "Epoch 15055 - Train Loss: 0.100806, Train Acc: 0.846154 | Val Loss: 0.123185, Val Acc: 0.773196\n",
      "Epoch 15056 - Train Loss: 0.100802, Train Acc: 0.846154 | Val Loss: 0.123183, Val Acc: 0.773196\n",
      "Epoch 15057 - Train Loss: 0.100798, Train Acc: 0.846154 | Val Loss: 0.123180, Val Acc: 0.773196\n",
      "Epoch 15058 - Train Loss: 0.100794, Train Acc: 0.846154 | Val Loss: 0.123178, Val Acc: 0.773196\n",
      "Epoch 15059 - Train Loss: 0.100791, Train Acc: 0.846154 | Val Loss: 0.123175, Val Acc: 0.773196\n",
      "Epoch 15060 - Train Loss: 0.100787, Train Acc: 0.846154 | Val Loss: 0.123173, Val Acc: 0.773196\n",
      "Epoch 15061 - Train Loss: 0.100783, Train Acc: 0.846154 | Val Loss: 0.123170, Val Acc: 0.773196\n",
      "Epoch 15062 - Train Loss: 0.100779, Train Acc: 0.846154 | Val Loss: 0.123168, Val Acc: 0.773196\n",
      "Epoch 15063 - Train Loss: 0.100776, Train Acc: 0.846154 | Val Loss: 0.123165, Val Acc: 0.773196\n",
      "Epoch 15064 - Train Loss: 0.100772, Train Acc: 0.846154 | Val Loss: 0.123163, Val Acc: 0.773196\n",
      "Epoch 15065 - Train Loss: 0.100768, Train Acc: 0.846154 | Val Loss: 0.123160, Val Acc: 0.773196\n",
      "Epoch 15066 - Train Loss: 0.100764, Train Acc: 0.846154 | Val Loss: 0.123158, Val Acc: 0.773196\n",
      "Epoch 15067 - Train Loss: 0.100760, Train Acc: 0.846154 | Val Loss: 0.123155, Val Acc: 0.773196\n",
      "Epoch 15068 - Train Loss: 0.100757, Train Acc: 0.846154 | Val Loss: 0.123153, Val Acc: 0.773196\n",
      "Epoch 15069 - Train Loss: 0.100753, Train Acc: 0.846154 | Val Loss: 0.123150, Val Acc: 0.773196\n",
      "Epoch 15070 - Train Loss: 0.100749, Train Acc: 0.846154 | Val Loss: 0.123147, Val Acc: 0.773196\n",
      "Epoch 15071 - Train Loss: 0.100745, Train Acc: 0.846154 | Val Loss: 0.123145, Val Acc: 0.773196\n",
      "Epoch 15072 - Train Loss: 0.100742, Train Acc: 0.846154 | Val Loss: 0.123142, Val Acc: 0.773196\n",
      "Epoch 15073 - Train Loss: 0.100738, Train Acc: 0.846154 | Val Loss: 0.123140, Val Acc: 0.773196\n",
      "Epoch 15074 - Train Loss: 0.100734, Train Acc: 0.846154 | Val Loss: 0.123137, Val Acc: 0.773196\n",
      "Epoch 15075 - Train Loss: 0.100730, Train Acc: 0.846154 | Val Loss: 0.123135, Val Acc: 0.773196\n",
      "Epoch 15076 - Train Loss: 0.100727, Train Acc: 0.846154 | Val Loss: 0.123132, Val Acc: 0.773196\n",
      "Epoch 15077 - Train Loss: 0.100723, Train Acc: 0.846154 | Val Loss: 0.123130, Val Acc: 0.773196\n",
      "Epoch 15078 - Train Loss: 0.100719, Train Acc: 0.846154 | Val Loss: 0.123127, Val Acc: 0.773196\n",
      "Epoch 15079 - Train Loss: 0.100715, Train Acc: 0.846154 | Val Loss: 0.123125, Val Acc: 0.773196\n",
      "Epoch 15080 - Train Loss: 0.100712, Train Acc: 0.846154 | Val Loss: 0.123122, Val Acc: 0.773196\n",
      "Epoch 15081 - Train Loss: 0.100708, Train Acc: 0.846154 | Val Loss: 0.123120, Val Acc: 0.773196\n",
      "Epoch 15082 - Train Loss: 0.100704, Train Acc: 0.846154 | Val Loss: 0.123117, Val Acc: 0.773196\n",
      "Epoch 15083 - Train Loss: 0.100700, Train Acc: 0.846154 | Val Loss: 0.123115, Val Acc: 0.773196\n",
      "Epoch 15084 - Train Loss: 0.100697, Train Acc: 0.846154 | Val Loss: 0.123112, Val Acc: 0.773196\n",
      "Epoch 15085 - Train Loss: 0.100693, Train Acc: 0.846154 | Val Loss: 0.123110, Val Acc: 0.773196\n",
      "Epoch 15086 - Train Loss: 0.100689, Train Acc: 0.846154 | Val Loss: 0.123107, Val Acc: 0.773196\n",
      "Epoch 15087 - Train Loss: 0.100685, Train Acc: 0.846154 | Val Loss: 0.123105, Val Acc: 0.773196\n",
      "Epoch 15088 - Train Loss: 0.100682, Train Acc: 0.846154 | Val Loss: 0.123102, Val Acc: 0.773196\n",
      "Epoch 15089 - Train Loss: 0.100678, Train Acc: 0.846154 | Val Loss: 0.123100, Val Acc: 0.773196\n",
      "Epoch 15090 - Train Loss: 0.100674, Train Acc: 0.846154 | Val Loss: 0.123097, Val Acc: 0.773196\n",
      "Epoch 15091 - Train Loss: 0.100670, Train Acc: 0.846154 | Val Loss: 0.123095, Val Acc: 0.773196\n",
      "Epoch 15092 - Train Loss: 0.100667, Train Acc: 0.846154 | Val Loss: 0.123092, Val Acc: 0.773196\n",
      "Epoch 15093 - Train Loss: 0.100663, Train Acc: 0.846154 | Val Loss: 0.123090, Val Acc: 0.773196\n",
      "Epoch 15094 - Train Loss: 0.100659, Train Acc: 0.846154 | Val Loss: 0.123087, Val Acc: 0.773196\n",
      "Epoch 15095 - Train Loss: 0.100655, Train Acc: 0.846154 | Val Loss: 0.123085, Val Acc: 0.773196\n",
      "Epoch 15096 - Train Loss: 0.100652, Train Acc: 0.846154 | Val Loss: 0.123082, Val Acc: 0.773196\n",
      "Epoch 15097 - Train Loss: 0.100648, Train Acc: 0.846154 | Val Loss: 0.123080, Val Acc: 0.773196\n",
      "Epoch 15098 - Train Loss: 0.100644, Train Acc: 0.846154 | Val Loss: 0.123077, Val Acc: 0.773196\n",
      "Epoch 15099 - Train Loss: 0.100640, Train Acc: 0.846154 | Val Loss: 0.123075, Val Acc: 0.773196\n",
      "Epoch 15100 - Train Loss: 0.100637, Train Acc: 0.846154 | Val Loss: 0.123072, Val Acc: 0.773196\n",
      "Epoch 15101 - Train Loss: 0.100633, Train Acc: 0.846154 | Val Loss: 0.123070, Val Acc: 0.773196\n",
      "Epoch 15102 - Train Loss: 0.100629, Train Acc: 0.846154 | Val Loss: 0.123067, Val Acc: 0.773196\n",
      "Epoch 15103 - Train Loss: 0.100625, Train Acc: 0.846154 | Val Loss: 0.123065, Val Acc: 0.773196\n",
      "Epoch 15104 - Train Loss: 0.100622, Train Acc: 0.846154 | Val Loss: 0.123062, Val Acc: 0.773196\n",
      "Epoch 15105 - Train Loss: 0.100618, Train Acc: 0.846154 | Val Loss: 0.123060, Val Acc: 0.773196\n",
      "Epoch 15106 - Train Loss: 0.100614, Train Acc: 0.846154 | Val Loss: 0.123057, Val Acc: 0.773196\n",
      "Epoch 15107 - Train Loss: 0.100610, Train Acc: 0.846154 | Val Loss: 0.123055, Val Acc: 0.773196\n",
      "Epoch 15108 - Train Loss: 0.100607, Train Acc: 0.846154 | Val Loss: 0.123052, Val Acc: 0.773196\n",
      "Epoch 15109 - Train Loss: 0.100603, Train Acc: 0.846154 | Val Loss: 0.123050, Val Acc: 0.773196\n",
      "Epoch 15110 - Train Loss: 0.100599, Train Acc: 0.846154 | Val Loss: 0.123047, Val Acc: 0.773196\n",
      "Epoch 15111 - Train Loss: 0.100595, Train Acc: 0.846154 | Val Loss: 0.123045, Val Acc: 0.773196\n",
      "Epoch 15112 - Train Loss: 0.100592, Train Acc: 0.846154 | Val Loss: 0.123042, Val Acc: 0.773196\n",
      "Epoch 15113 - Train Loss: 0.100588, Train Acc: 0.846154 | Val Loss: 0.123040, Val Acc: 0.773196\n",
      "Epoch 15114 - Train Loss: 0.100584, Train Acc: 0.846154 | Val Loss: 0.123037, Val Acc: 0.773196\n",
      "Epoch 15115 - Train Loss: 0.100581, Train Acc: 0.846154 | Val Loss: 0.123035, Val Acc: 0.773196\n",
      "Epoch 15116 - Train Loss: 0.100577, Train Acc: 0.846154 | Val Loss: 0.123032, Val Acc: 0.773196\n",
      "Epoch 15117 - Train Loss: 0.100573, Train Acc: 0.846154 | Val Loss: 0.123030, Val Acc: 0.773196\n",
      "Epoch 15118 - Train Loss: 0.100569, Train Acc: 0.846154 | Val Loss: 0.123027, Val Acc: 0.773196\n",
      "Epoch 15119 - Train Loss: 0.100566, Train Acc: 0.846154 | Val Loss: 0.123025, Val Acc: 0.773196\n",
      "Epoch 15120 - Train Loss: 0.100562, Train Acc: 0.846154 | Val Loss: 0.123022, Val Acc: 0.773196\n",
      "Epoch 15121 - Train Loss: 0.100558, Train Acc: 0.846154 | Val Loss: 0.123020, Val Acc: 0.773196\n",
      "Epoch 15122 - Train Loss: 0.100554, Train Acc: 0.846154 | Val Loss: 0.123017, Val Acc: 0.773196\n",
      "Epoch 15123 - Train Loss: 0.100551, Train Acc: 0.846154 | Val Loss: 0.123015, Val Acc: 0.773196\n",
      "Epoch 15124 - Train Loss: 0.100547, Train Acc: 0.846154 | Val Loss: 0.123012, Val Acc: 0.773196\n",
      "Epoch 15125 - Train Loss: 0.100543, Train Acc: 0.846154 | Val Loss: 0.123010, Val Acc: 0.773196\n",
      "Epoch 15126 - Train Loss: 0.100539, Train Acc: 0.846154 | Val Loss: 0.123007, Val Acc: 0.773196\n",
      "Epoch 15127 - Train Loss: 0.100536, Train Acc: 0.846154 | Val Loss: 0.123005, Val Acc: 0.773196\n",
      "Epoch 15128 - Train Loss: 0.100532, Train Acc: 0.846154 | Val Loss: 0.123002, Val Acc: 0.773196\n",
      "Epoch 15129 - Train Loss: 0.100528, Train Acc: 0.846154 | Val Loss: 0.123000, Val Acc: 0.773196\n",
      "Epoch 15130 - Train Loss: 0.100525, Train Acc: 0.846154 | Val Loss: 0.122997, Val Acc: 0.773196\n",
      "Epoch 15131 - Train Loss: 0.100521, Train Acc: 0.846154 | Val Loss: 0.122995, Val Acc: 0.773196\n",
      "Epoch 15132 - Train Loss: 0.100517, Train Acc: 0.846154 | Val Loss: 0.122992, Val Acc: 0.773196\n",
      "Epoch 15133 - Train Loss: 0.100513, Train Acc: 0.846154 | Val Loss: 0.122990, Val Acc: 0.773196\n",
      "Epoch 15134 - Train Loss: 0.100510, Train Acc: 0.846154 | Val Loss: 0.122987, Val Acc: 0.773196\n",
      "Epoch 15135 - Train Loss: 0.100506, Train Acc: 0.846154 | Val Loss: 0.122985, Val Acc: 0.773196\n",
      "Epoch 15136 - Train Loss: 0.100502, Train Acc: 0.846154 | Val Loss: 0.122982, Val Acc: 0.773196\n",
      "Epoch 15137 - Train Loss: 0.100498, Train Acc: 0.846154 | Val Loss: 0.122980, Val Acc: 0.773196\n",
      "Epoch 15138 - Train Loss: 0.100495, Train Acc: 0.846154 | Val Loss: 0.122977, Val Acc: 0.773196\n",
      "Epoch 15139 - Train Loss: 0.100491, Train Acc: 0.846154 | Val Loss: 0.122975, Val Acc: 0.773196\n",
      "Epoch 15140 - Train Loss: 0.100487, Train Acc: 0.846154 | Val Loss: 0.122973, Val Acc: 0.773196\n",
      "Epoch 15141 - Train Loss: 0.100484, Train Acc: 0.846154 | Val Loss: 0.122970, Val Acc: 0.773196\n",
      "Epoch 15142 - Train Loss: 0.100480, Train Acc: 0.846154 | Val Loss: 0.122968, Val Acc: 0.773196\n",
      "Epoch 15143 - Train Loss: 0.100476, Train Acc: 0.846154 | Val Loss: 0.122965, Val Acc: 0.773196\n",
      "Epoch 15144 - Train Loss: 0.100472, Train Acc: 0.846154 | Val Loss: 0.122963, Val Acc: 0.773196\n",
      "Epoch 15145 - Train Loss: 0.100469, Train Acc: 0.846154 | Val Loss: 0.122960, Val Acc: 0.773196\n",
      "Epoch 15146 - Train Loss: 0.100465, Train Acc: 0.846154 | Val Loss: 0.122958, Val Acc: 0.773196\n",
      "Epoch 15147 - Train Loss: 0.100461, Train Acc: 0.846154 | Val Loss: 0.122955, Val Acc: 0.773196\n",
      "Epoch 15148 - Train Loss: 0.100457, Train Acc: 0.846154 | Val Loss: 0.122953, Val Acc: 0.773196\n",
      "Epoch 15149 - Train Loss: 0.100454, Train Acc: 0.846154 | Val Loss: 0.122950, Val Acc: 0.773196\n",
      "Epoch 15150 - Train Loss: 0.100450, Train Acc: 0.846154 | Val Loss: 0.122948, Val Acc: 0.773196\n",
      "Epoch 15151 - Train Loss: 0.100446, Train Acc: 0.846154 | Val Loss: 0.122945, Val Acc: 0.773196\n",
      "Epoch 15152 - Train Loss: 0.100443, Train Acc: 0.846154 | Val Loss: 0.122943, Val Acc: 0.773196\n",
      "Epoch 15153 - Train Loss: 0.100439, Train Acc: 0.846154 | Val Loss: 0.122940, Val Acc: 0.773196\n",
      "Epoch 15154 - Train Loss: 0.100435, Train Acc: 0.846154 | Val Loss: 0.122938, Val Acc: 0.773196\n",
      "Epoch 15155 - Train Loss: 0.100431, Train Acc: 0.846154 | Val Loss: 0.122935, Val Acc: 0.773196\n",
      "Epoch 15156 - Train Loss: 0.100428, Train Acc: 0.846154 | Val Loss: 0.122933, Val Acc: 0.773196\n",
      "Epoch 15157 - Train Loss: 0.100424, Train Acc: 0.846154 | Val Loss: 0.122930, Val Acc: 0.773196\n",
      "Epoch 15158 - Train Loss: 0.100420, Train Acc: 0.846154 | Val Loss: 0.122928, Val Acc: 0.773196\n",
      "Epoch 15159 - Train Loss: 0.100417, Train Acc: 0.846154 | Val Loss: 0.122925, Val Acc: 0.773196\n",
      "Epoch 15160 - Train Loss: 0.100413, Train Acc: 0.846154 | Val Loss: 0.122923, Val Acc: 0.773196\n",
      "Epoch 15161 - Train Loss: 0.100409, Train Acc: 0.846154 | Val Loss: 0.122920, Val Acc: 0.773196\n",
      "Epoch 15162 - Train Loss: 0.100405, Train Acc: 0.846154 | Val Loss: 0.122918, Val Acc: 0.773196\n",
      "Epoch 15163 - Train Loss: 0.100402, Train Acc: 0.846154 | Val Loss: 0.122916, Val Acc: 0.773196\n",
      "Epoch 15164 - Train Loss: 0.100398, Train Acc: 0.846154 | Val Loss: 0.122913, Val Acc: 0.773196\n",
      "Epoch 15165 - Train Loss: 0.100394, Train Acc: 0.846154 | Val Loss: 0.122911, Val Acc: 0.773196\n",
      "Epoch 15166 - Train Loss: 0.100391, Train Acc: 0.846154 | Val Loss: 0.122908, Val Acc: 0.773196\n",
      "Epoch 15167 - Train Loss: 0.100387, Train Acc: 0.846154 | Val Loss: 0.122906, Val Acc: 0.773196\n",
      "Epoch 15168 - Train Loss: 0.100383, Train Acc: 0.846154 | Val Loss: 0.122903, Val Acc: 0.773196\n",
      "Epoch 15169 - Train Loss: 0.100379, Train Acc: 0.846154 | Val Loss: 0.122901, Val Acc: 0.773196\n",
      "Epoch 15170 - Train Loss: 0.100376, Train Acc: 0.846154 | Val Loss: 0.122898, Val Acc: 0.773196\n",
      "Epoch 15171 - Train Loss: 0.100372, Train Acc: 0.846154 | Val Loss: 0.122896, Val Acc: 0.773196\n",
      "Epoch 15172 - Train Loss: 0.100368, Train Acc: 0.846154 | Val Loss: 0.122893, Val Acc: 0.773196\n",
      "Epoch 15173 - Train Loss: 0.100365, Train Acc: 0.846154 | Val Loss: 0.122891, Val Acc: 0.773196\n",
      "Epoch 15174 - Train Loss: 0.100361, Train Acc: 0.846154 | Val Loss: 0.122888, Val Acc: 0.773196\n",
      "Epoch 15175 - Train Loss: 0.100357, Train Acc: 0.846154 | Val Loss: 0.122886, Val Acc: 0.773196\n",
      "Epoch 15176 - Train Loss: 0.100353, Train Acc: 0.846154 | Val Loss: 0.122883, Val Acc: 0.773196\n",
      "Epoch 15177 - Train Loss: 0.100350, Train Acc: 0.846154 | Val Loss: 0.122881, Val Acc: 0.773196\n",
      "Epoch 15178 - Train Loss: 0.100346, Train Acc: 0.846154 | Val Loss: 0.122879, Val Acc: 0.773196\n",
      "Epoch 15179 - Train Loss: 0.100342, Train Acc: 0.846154 | Val Loss: 0.122876, Val Acc: 0.773196\n",
      "Epoch 15180 - Train Loss: 0.100339, Train Acc: 0.846154 | Val Loss: 0.122874, Val Acc: 0.773196\n",
      "Epoch 15181 - Train Loss: 0.100335, Train Acc: 0.846154 | Val Loss: 0.122871, Val Acc: 0.773196\n",
      "Epoch 15182 - Train Loss: 0.100331, Train Acc: 0.846154 | Val Loss: 0.122869, Val Acc: 0.773196\n",
      "Epoch 15183 - Train Loss: 0.100328, Train Acc: 0.846154 | Val Loss: 0.122866, Val Acc: 0.773196\n",
      "Epoch 15184 - Train Loss: 0.100324, Train Acc: 0.846154 | Val Loss: 0.122864, Val Acc: 0.773196\n",
      "Epoch 15185 - Train Loss: 0.100320, Train Acc: 0.846154 | Val Loss: 0.122861, Val Acc: 0.773196\n",
      "Epoch 15186 - Train Loss: 0.100316, Train Acc: 0.846154 | Val Loss: 0.122859, Val Acc: 0.773196\n",
      "Epoch 15187 - Train Loss: 0.100313, Train Acc: 0.846154 | Val Loss: 0.122856, Val Acc: 0.773196\n",
      "Epoch 15188 - Train Loss: 0.100309, Train Acc: 0.846154 | Val Loss: 0.122854, Val Acc: 0.773196\n",
      "Epoch 15189 - Train Loss: 0.100305, Train Acc: 0.846154 | Val Loss: 0.122851, Val Acc: 0.773196\n",
      "Epoch 15190 - Train Loss: 0.100302, Train Acc: 0.846154 | Val Loss: 0.122849, Val Acc: 0.773196\n",
      "Epoch 15191 - Train Loss: 0.100298, Train Acc: 0.846154 | Val Loss: 0.122847, Val Acc: 0.773196\n",
      "Epoch 15192 - Train Loss: 0.100294, Train Acc: 0.846154 | Val Loss: 0.122844, Val Acc: 0.773196\n",
      "Epoch 15193 - Train Loss: 0.100291, Train Acc: 0.846154 | Val Loss: 0.122842, Val Acc: 0.773196\n",
      "Epoch 15194 - Train Loss: 0.100287, Train Acc: 0.846154 | Val Loss: 0.122839, Val Acc: 0.773196\n",
      "Epoch 15195 - Train Loss: 0.100283, Train Acc: 0.846154 | Val Loss: 0.122837, Val Acc: 0.773196\n",
      "Epoch 15196 - Train Loss: 0.100279, Train Acc: 0.846154 | Val Loss: 0.122834, Val Acc: 0.773196\n",
      "Epoch 15197 - Train Loss: 0.100276, Train Acc: 0.846154 | Val Loss: 0.122832, Val Acc: 0.773196\n",
      "Epoch 15198 - Train Loss: 0.100272, Train Acc: 0.846154 | Val Loss: 0.122829, Val Acc: 0.773196\n",
      "Epoch 15199 - Train Loss: 0.100268, Train Acc: 0.846154 | Val Loss: 0.122827, Val Acc: 0.773196\n",
      "Epoch 15200 - Train Loss: 0.100265, Train Acc: 0.846154 | Val Loss: 0.122824, Val Acc: 0.773196\n",
      "Epoch 15201 - Train Loss: 0.100261, Train Acc: 0.846154 | Val Loss: 0.122822, Val Acc: 0.773196\n",
      "Epoch 15202 - Train Loss: 0.100257, Train Acc: 0.846154 | Val Loss: 0.122820, Val Acc: 0.773196\n",
      "Epoch 15203 - Train Loss: 0.100254, Train Acc: 0.846154 | Val Loss: 0.122817, Val Acc: 0.773196\n",
      "Epoch 15204 - Train Loss: 0.100250, Train Acc: 0.846154 | Val Loss: 0.122815, Val Acc: 0.773196\n",
      "Epoch 15205 - Train Loss: 0.100246, Train Acc: 0.846154 | Val Loss: 0.122812, Val Acc: 0.773196\n",
      "Epoch 15206 - Train Loss: 0.100242, Train Acc: 0.846154 | Val Loss: 0.122810, Val Acc: 0.773196\n",
      "Epoch 15207 - Train Loss: 0.100239, Train Acc: 0.846154 | Val Loss: 0.122807, Val Acc: 0.773196\n",
      "Epoch 15208 - Train Loss: 0.100235, Train Acc: 0.846154 | Val Loss: 0.122805, Val Acc: 0.773196\n",
      "Epoch 15209 - Train Loss: 0.100231, Train Acc: 0.846154 | Val Loss: 0.122802, Val Acc: 0.773196\n",
      "Epoch 15210 - Train Loss: 0.100228, Train Acc: 0.846154 | Val Loss: 0.122800, Val Acc: 0.773196\n",
      "Epoch 15211 - Train Loss: 0.100224, Train Acc: 0.846154 | Val Loss: 0.122797, Val Acc: 0.773196\n",
      "Epoch 15212 - Train Loss: 0.100220, Train Acc: 0.846154 | Val Loss: 0.122795, Val Acc: 0.773196\n",
      "Epoch 15213 - Train Loss: 0.100217, Train Acc: 0.846154 | Val Loss: 0.122793, Val Acc: 0.773196\n",
      "Epoch 15214 - Train Loss: 0.100213, Train Acc: 0.846154 | Val Loss: 0.122790, Val Acc: 0.773196\n",
      "Epoch 15215 - Train Loss: 0.100209, Train Acc: 0.846154 | Val Loss: 0.122788, Val Acc: 0.773196\n",
      "Epoch 15216 - Train Loss: 0.100206, Train Acc: 0.846154 | Val Loss: 0.122785, Val Acc: 0.773196\n",
      "Epoch 15217 - Train Loss: 0.100202, Train Acc: 0.846154 | Val Loss: 0.122783, Val Acc: 0.773196\n",
      "Epoch 15218 - Train Loss: 0.100198, Train Acc: 0.846154 | Val Loss: 0.122780, Val Acc: 0.773196\n",
      "Epoch 15219 - Train Loss: 0.100194, Train Acc: 0.846154 | Val Loss: 0.122778, Val Acc: 0.773196\n",
      "Epoch 15220 - Train Loss: 0.100191, Train Acc: 0.846154 | Val Loss: 0.122775, Val Acc: 0.773196\n",
      "Epoch 15221 - Train Loss: 0.100187, Train Acc: 0.846154 | Val Loss: 0.122773, Val Acc: 0.773196\n",
      "Epoch 15222 - Train Loss: 0.100183, Train Acc: 0.846154 | Val Loss: 0.122771, Val Acc: 0.773196\n",
      "Epoch 15223 - Train Loss: 0.100180, Train Acc: 0.846154 | Val Loss: 0.122768, Val Acc: 0.773196\n",
      "Epoch 15224 - Train Loss: 0.100176, Train Acc: 0.846154 | Val Loss: 0.122766, Val Acc: 0.773196\n",
      "Epoch 15225 - Train Loss: 0.100172, Train Acc: 0.846154 | Val Loss: 0.122763, Val Acc: 0.773196\n",
      "Epoch 15226 - Train Loss: 0.100169, Train Acc: 0.846154 | Val Loss: 0.122761, Val Acc: 0.773196\n",
      "Epoch 15227 - Train Loss: 0.100165, Train Acc: 0.846154 | Val Loss: 0.122758, Val Acc: 0.773196\n",
      "Epoch 15228 - Train Loss: 0.100161, Train Acc: 0.846154 | Val Loss: 0.122756, Val Acc: 0.773196\n",
      "Epoch 15229 - Train Loss: 0.100158, Train Acc: 0.846154 | Val Loss: 0.122753, Val Acc: 0.773196\n",
      "Epoch 15230 - Train Loss: 0.100154, Train Acc: 0.846154 | Val Loss: 0.122751, Val Acc: 0.773196\n",
      "Epoch 15231 - Train Loss: 0.100150, Train Acc: 0.846154 | Val Loss: 0.122749, Val Acc: 0.773196\n",
      "Epoch 15232 - Train Loss: 0.100147, Train Acc: 0.846154 | Val Loss: 0.122746, Val Acc: 0.773196\n",
      "Epoch 15233 - Train Loss: 0.100143, Train Acc: 0.846154 | Val Loss: 0.122744, Val Acc: 0.773196\n",
      "Epoch 15234 - Train Loss: 0.100139, Train Acc: 0.846154 | Val Loss: 0.122741, Val Acc: 0.773196\n",
      "Epoch 15235 - Train Loss: 0.100136, Train Acc: 0.846154 | Val Loss: 0.122739, Val Acc: 0.773196\n",
      "Epoch 15236 - Train Loss: 0.100132, Train Acc: 0.846154 | Val Loss: 0.122736, Val Acc: 0.773196\n",
      "Epoch 15237 - Train Loss: 0.100128, Train Acc: 0.846154 | Val Loss: 0.122734, Val Acc: 0.773196\n",
      "Epoch 15238 - Train Loss: 0.100125, Train Acc: 0.846154 | Val Loss: 0.122732, Val Acc: 0.773196\n",
      "Epoch 15239 - Train Loss: 0.100121, Train Acc: 0.846154 | Val Loss: 0.122729, Val Acc: 0.773196\n",
      "Epoch 15240 - Train Loss: 0.100117, Train Acc: 0.846154 | Val Loss: 0.122727, Val Acc: 0.773196\n",
      "Epoch 15241 - Train Loss: 0.100113, Train Acc: 0.846154 | Val Loss: 0.122724, Val Acc: 0.773196\n",
      "Epoch 15242 - Train Loss: 0.100110, Train Acc: 0.846154 | Val Loss: 0.122722, Val Acc: 0.773196\n",
      "Epoch 15243 - Train Loss: 0.100106, Train Acc: 0.846154 | Val Loss: 0.122719, Val Acc: 0.773196\n",
      "Epoch 15244 - Train Loss: 0.100102, Train Acc: 0.846154 | Val Loss: 0.122717, Val Acc: 0.773196\n",
      "Epoch 15245 - Train Loss: 0.100099, Train Acc: 0.846154 | Val Loss: 0.122714, Val Acc: 0.773196\n",
      "Epoch 15246 - Train Loss: 0.100095, Train Acc: 0.846154 | Val Loss: 0.122712, Val Acc: 0.773196\n",
      "Epoch 15247 - Train Loss: 0.100091, Train Acc: 0.846154 | Val Loss: 0.122710, Val Acc: 0.773196\n",
      "Epoch 15248 - Train Loss: 0.100088, Train Acc: 0.846154 | Val Loss: 0.122707, Val Acc: 0.773196\n",
      "Epoch 15249 - Train Loss: 0.100084, Train Acc: 0.847436 | Val Loss: 0.122705, Val Acc: 0.773196\n",
      "Epoch 15250 - Train Loss: 0.100080, Train Acc: 0.847436 | Val Loss: 0.122702, Val Acc: 0.773196\n",
      "Epoch 15251 - Train Loss: 0.100077, Train Acc: 0.847436 | Val Loss: 0.122700, Val Acc: 0.773196\n",
      "Epoch 15252 - Train Loss: 0.100073, Train Acc: 0.847436 | Val Loss: 0.122697, Val Acc: 0.773196\n",
      "Epoch 15253 - Train Loss: 0.100069, Train Acc: 0.847436 | Val Loss: 0.122695, Val Acc: 0.773196\n",
      "Epoch 15254 - Train Loss: 0.100066, Train Acc: 0.847436 | Val Loss: 0.122693, Val Acc: 0.773196\n",
      "Epoch 15255 - Train Loss: 0.100062, Train Acc: 0.847436 | Val Loss: 0.122690, Val Acc: 0.773196\n",
      "Epoch 15256 - Train Loss: 0.100058, Train Acc: 0.847436 | Val Loss: 0.122688, Val Acc: 0.773196\n",
      "Epoch 15257 - Train Loss: 0.100055, Train Acc: 0.847436 | Val Loss: 0.122685, Val Acc: 0.773196\n",
      "Epoch 15258 - Train Loss: 0.100051, Train Acc: 0.847436 | Val Loss: 0.122683, Val Acc: 0.773196\n",
      "Epoch 15259 - Train Loss: 0.100047, Train Acc: 0.847436 | Val Loss: 0.122680, Val Acc: 0.773196\n",
      "Epoch 15260 - Train Loss: 0.100044, Train Acc: 0.847436 | Val Loss: 0.122678, Val Acc: 0.773196\n",
      "Epoch 15261 - Train Loss: 0.100040, Train Acc: 0.847436 | Val Loss: 0.122676, Val Acc: 0.773196\n",
      "Epoch 15262 - Train Loss: 0.100036, Train Acc: 0.847436 | Val Loss: 0.122673, Val Acc: 0.773196\n",
      "Epoch 15263 - Train Loss: 0.100033, Train Acc: 0.847436 | Val Loss: 0.122671, Val Acc: 0.773196\n",
      "Epoch 15264 - Train Loss: 0.100029, Train Acc: 0.847436 | Val Loss: 0.122668, Val Acc: 0.773196\n",
      "Epoch 15265 - Train Loss: 0.100025, Train Acc: 0.847436 | Val Loss: 0.122666, Val Acc: 0.773196\n",
      "Epoch 15266 - Train Loss: 0.100022, Train Acc: 0.847436 | Val Loss: 0.122663, Val Acc: 0.773196\n",
      "Epoch 15267 - Train Loss: 0.100018, Train Acc: 0.847436 | Val Loss: 0.122661, Val Acc: 0.773196\n",
      "Epoch 15268 - Train Loss: 0.100014, Train Acc: 0.847436 | Val Loss: 0.122659, Val Acc: 0.773196\n",
      "Epoch 15269 - Train Loss: 0.100011, Train Acc: 0.847436 | Val Loss: 0.122656, Val Acc: 0.773196\n",
      "Epoch 15270 - Train Loss: 0.100007, Train Acc: 0.847436 | Val Loss: 0.122654, Val Acc: 0.773196\n",
      "Epoch 15271 - Train Loss: 0.100003, Train Acc: 0.847436 | Val Loss: 0.122651, Val Acc: 0.773196\n",
      "Epoch 15272 - Train Loss: 0.100000, Train Acc: 0.847436 | Val Loss: 0.122649, Val Acc: 0.773196\n",
      "Epoch 15273 - Train Loss: 0.099996, Train Acc: 0.847436 | Val Loss: 0.122647, Val Acc: 0.773196\n",
      "Epoch 15274 - Train Loss: 0.099992, Train Acc: 0.847436 | Val Loss: 0.122644, Val Acc: 0.773196\n",
      "Epoch 15275 - Train Loss: 0.099989, Train Acc: 0.847436 | Val Loss: 0.122642, Val Acc: 0.773196\n",
      "Epoch 15276 - Train Loss: 0.099985, Train Acc: 0.847436 | Val Loss: 0.122639, Val Acc: 0.773196\n",
      "Epoch 15277 - Train Loss: 0.099981, Train Acc: 0.847436 | Val Loss: 0.122637, Val Acc: 0.773196\n",
      "Epoch 15278 - Train Loss: 0.099978, Train Acc: 0.847436 | Val Loss: 0.122634, Val Acc: 0.773196\n",
      "Epoch 15279 - Train Loss: 0.099974, Train Acc: 0.847436 | Val Loss: 0.122632, Val Acc: 0.773196\n",
      "Epoch 15280 - Train Loss: 0.099970, Train Acc: 0.847436 | Val Loss: 0.122630, Val Acc: 0.773196\n",
      "Epoch 15281 - Train Loss: 0.099967, Train Acc: 0.847436 | Val Loss: 0.122627, Val Acc: 0.773196\n",
      "Epoch 15282 - Train Loss: 0.099963, Train Acc: 0.847436 | Val Loss: 0.122625, Val Acc: 0.773196\n",
      "Epoch 15283 - Train Loss: 0.099959, Train Acc: 0.847436 | Val Loss: 0.122622, Val Acc: 0.773196\n",
      "Epoch 15284 - Train Loss: 0.099956, Train Acc: 0.847436 | Val Loss: 0.122620, Val Acc: 0.773196\n",
      "Epoch 15285 - Train Loss: 0.099952, Train Acc: 0.847436 | Val Loss: 0.122618, Val Acc: 0.773196\n",
      "Epoch 15286 - Train Loss: 0.099948, Train Acc: 0.847436 | Val Loss: 0.122615, Val Acc: 0.773196\n",
      "Epoch 15287 - Train Loss: 0.099945, Train Acc: 0.847436 | Val Loss: 0.122613, Val Acc: 0.773196\n",
      "Epoch 15288 - Train Loss: 0.099941, Train Acc: 0.847436 | Val Loss: 0.122610, Val Acc: 0.773196\n",
      "Epoch 15289 - Train Loss: 0.099938, Train Acc: 0.847436 | Val Loss: 0.122608, Val Acc: 0.773196\n",
      "Epoch 15290 - Train Loss: 0.099934, Train Acc: 0.847436 | Val Loss: 0.122605, Val Acc: 0.773196\n",
      "Epoch 15291 - Train Loss: 0.099930, Train Acc: 0.847436 | Val Loss: 0.122603, Val Acc: 0.773196\n",
      "Epoch 15292 - Train Loss: 0.099927, Train Acc: 0.847436 | Val Loss: 0.122601, Val Acc: 0.773196\n",
      "Epoch 15293 - Train Loss: 0.099923, Train Acc: 0.847436 | Val Loss: 0.122598, Val Acc: 0.773196\n",
      "Epoch 15294 - Train Loss: 0.099919, Train Acc: 0.847436 | Val Loss: 0.122596, Val Acc: 0.773196\n",
      "Epoch 15295 - Train Loss: 0.099916, Train Acc: 0.847436 | Val Loss: 0.122593, Val Acc: 0.773196\n",
      "Epoch 15296 - Train Loss: 0.099912, Train Acc: 0.847436 | Val Loss: 0.122591, Val Acc: 0.773196\n",
      "Epoch 15297 - Train Loss: 0.099908, Train Acc: 0.847436 | Val Loss: 0.122589, Val Acc: 0.773196\n",
      "Epoch 15298 - Train Loss: 0.099905, Train Acc: 0.847436 | Val Loss: 0.122586, Val Acc: 0.773196\n",
      "Epoch 15299 - Train Loss: 0.099901, Train Acc: 0.847436 | Val Loss: 0.122584, Val Acc: 0.773196\n",
      "Epoch 15300 - Train Loss: 0.099897, Train Acc: 0.847436 | Val Loss: 0.122581, Val Acc: 0.773196\n",
      "Epoch 15301 - Train Loss: 0.099894, Train Acc: 0.847436 | Val Loss: 0.122579, Val Acc: 0.773196\n",
      "Epoch 15302 - Train Loss: 0.099890, Train Acc: 0.847436 | Val Loss: 0.122577, Val Acc: 0.773196\n",
      "Epoch 15303 - Train Loss: 0.099886, Train Acc: 0.847436 | Val Loss: 0.122574, Val Acc: 0.773196\n",
      "Epoch 15304 - Train Loss: 0.099883, Train Acc: 0.847436 | Val Loss: 0.122572, Val Acc: 0.773196\n",
      "Epoch 15305 - Train Loss: 0.099879, Train Acc: 0.847436 | Val Loss: 0.122569, Val Acc: 0.773196\n",
      "Epoch 15306 - Train Loss: 0.099875, Train Acc: 0.847436 | Val Loss: 0.122567, Val Acc: 0.773196\n",
      "Epoch 15307 - Train Loss: 0.099872, Train Acc: 0.847436 | Val Loss: 0.122565, Val Acc: 0.773196\n",
      "Epoch 15308 - Train Loss: 0.099868, Train Acc: 0.847436 | Val Loss: 0.122562, Val Acc: 0.773196\n",
      "Epoch 15309 - Train Loss: 0.099865, Train Acc: 0.847436 | Val Loss: 0.122560, Val Acc: 0.773196\n",
      "Epoch 15310 - Train Loss: 0.099861, Train Acc: 0.847436 | Val Loss: 0.122557, Val Acc: 0.773196\n",
      "Epoch 15311 - Train Loss: 0.099857, Train Acc: 0.847436 | Val Loss: 0.122555, Val Acc: 0.773196\n",
      "Epoch 15312 - Train Loss: 0.099854, Train Acc: 0.847436 | Val Loss: 0.122553, Val Acc: 0.773196\n",
      "Epoch 15313 - Train Loss: 0.099850, Train Acc: 0.847436 | Val Loss: 0.122550, Val Acc: 0.773196\n",
      "Epoch 15314 - Train Loss: 0.099846, Train Acc: 0.847436 | Val Loss: 0.122548, Val Acc: 0.773196\n",
      "Epoch 15315 - Train Loss: 0.099843, Train Acc: 0.847436 | Val Loss: 0.122545, Val Acc: 0.773196\n",
      "Epoch 15316 - Train Loss: 0.099839, Train Acc: 0.847436 | Val Loss: 0.122543, Val Acc: 0.773196\n",
      "Epoch 15317 - Train Loss: 0.099835, Train Acc: 0.847436 | Val Loss: 0.122541, Val Acc: 0.773196\n",
      "Epoch 15318 - Train Loss: 0.099832, Train Acc: 0.847436 | Val Loss: 0.122538, Val Acc: 0.773196\n",
      "Epoch 15319 - Train Loss: 0.099828, Train Acc: 0.847436 | Val Loss: 0.122536, Val Acc: 0.773196\n",
      "Epoch 15320 - Train Loss: 0.099824, Train Acc: 0.847436 | Val Loss: 0.122533, Val Acc: 0.773196\n",
      "Epoch 15321 - Train Loss: 0.099821, Train Acc: 0.847436 | Val Loss: 0.122531, Val Acc: 0.773196\n",
      "Epoch 15322 - Train Loss: 0.099817, Train Acc: 0.847436 | Val Loss: 0.122529, Val Acc: 0.773196\n",
      "Epoch 15323 - Train Loss: 0.099814, Train Acc: 0.847436 | Val Loss: 0.122526, Val Acc: 0.773196\n",
      "Epoch 15324 - Train Loss: 0.099810, Train Acc: 0.847436 | Val Loss: 0.122524, Val Acc: 0.773196\n",
      "Epoch 15325 - Train Loss: 0.099806, Train Acc: 0.847436 | Val Loss: 0.122521, Val Acc: 0.773196\n",
      "Epoch 15326 - Train Loss: 0.099803, Train Acc: 0.847436 | Val Loss: 0.122519, Val Acc: 0.773196\n",
      "Epoch 15327 - Train Loss: 0.099799, Train Acc: 0.847436 | Val Loss: 0.122517, Val Acc: 0.773196\n",
      "Epoch 15328 - Train Loss: 0.099795, Train Acc: 0.847436 | Val Loss: 0.122514, Val Acc: 0.773196\n",
      "Epoch 15329 - Train Loss: 0.099792, Train Acc: 0.847436 | Val Loss: 0.122512, Val Acc: 0.773196\n",
      "Epoch 15330 - Train Loss: 0.099788, Train Acc: 0.847436 | Val Loss: 0.122509, Val Acc: 0.773196\n",
      "Epoch 15331 - Train Loss: 0.099784, Train Acc: 0.847436 | Val Loss: 0.122507, Val Acc: 0.773196\n",
      "Epoch 15332 - Train Loss: 0.099781, Train Acc: 0.847436 | Val Loss: 0.122505, Val Acc: 0.773196\n",
      "Epoch 15333 - Train Loss: 0.099777, Train Acc: 0.847436 | Val Loss: 0.122502, Val Acc: 0.773196\n",
      "Epoch 15334 - Train Loss: 0.099774, Train Acc: 0.847436 | Val Loss: 0.122500, Val Acc: 0.773196\n",
      "Epoch 15335 - Train Loss: 0.099770, Train Acc: 0.847436 | Val Loss: 0.122497, Val Acc: 0.773196\n",
      "Epoch 15336 - Train Loss: 0.099766, Train Acc: 0.847436 | Val Loss: 0.122495, Val Acc: 0.773196\n",
      "Epoch 15337 - Train Loss: 0.099763, Train Acc: 0.847436 | Val Loss: 0.122493, Val Acc: 0.773196\n",
      "Epoch 15338 - Train Loss: 0.099759, Train Acc: 0.847436 | Val Loss: 0.122490, Val Acc: 0.773196\n",
      "Epoch 15339 - Train Loss: 0.099755, Train Acc: 0.847436 | Val Loss: 0.122488, Val Acc: 0.773196\n",
      "Epoch 15340 - Train Loss: 0.099752, Train Acc: 0.847436 | Val Loss: 0.122485, Val Acc: 0.773196\n",
      "Epoch 15341 - Train Loss: 0.099748, Train Acc: 0.847436 | Val Loss: 0.122483, Val Acc: 0.773196\n",
      "Epoch 15342 - Train Loss: 0.099745, Train Acc: 0.847436 | Val Loss: 0.122481, Val Acc: 0.773196\n",
      "Epoch 15343 - Train Loss: 0.099741, Train Acc: 0.847436 | Val Loss: 0.122478, Val Acc: 0.773196\n",
      "Epoch 15344 - Train Loss: 0.099737, Train Acc: 0.847436 | Val Loss: 0.122476, Val Acc: 0.773196\n",
      "Epoch 15345 - Train Loss: 0.099734, Train Acc: 0.847436 | Val Loss: 0.122474, Val Acc: 0.773196\n",
      "Epoch 15346 - Train Loss: 0.099730, Train Acc: 0.847436 | Val Loss: 0.122471, Val Acc: 0.773196\n",
      "Epoch 15347 - Train Loss: 0.099726, Train Acc: 0.847436 | Val Loss: 0.122469, Val Acc: 0.773196\n",
      "Epoch 15348 - Train Loss: 0.099723, Train Acc: 0.847436 | Val Loss: 0.122466, Val Acc: 0.773196\n",
      "Epoch 15349 - Train Loss: 0.099719, Train Acc: 0.847436 | Val Loss: 0.122464, Val Acc: 0.773196\n",
      "Epoch 15350 - Train Loss: 0.099715, Train Acc: 0.847436 | Val Loss: 0.122462, Val Acc: 0.773196\n",
      "Epoch 15351 - Train Loss: 0.099712, Train Acc: 0.847436 | Val Loss: 0.122459, Val Acc: 0.773196\n",
      "Epoch 15352 - Train Loss: 0.099708, Train Acc: 0.847436 | Val Loss: 0.122457, Val Acc: 0.773196\n",
      "Epoch 15353 - Train Loss: 0.099705, Train Acc: 0.847436 | Val Loss: 0.122454, Val Acc: 0.773196\n",
      "Epoch 15354 - Train Loss: 0.099701, Train Acc: 0.847436 | Val Loss: 0.122452, Val Acc: 0.773196\n",
      "Epoch 15355 - Train Loss: 0.099697, Train Acc: 0.847436 | Val Loss: 0.122450, Val Acc: 0.773196\n",
      "Epoch 15356 - Train Loss: 0.099694, Train Acc: 0.847436 | Val Loss: 0.122447, Val Acc: 0.773196\n",
      "Epoch 15357 - Train Loss: 0.099690, Train Acc: 0.847436 | Val Loss: 0.122445, Val Acc: 0.773196\n",
      "Epoch 15358 - Train Loss: 0.099686, Train Acc: 0.847436 | Val Loss: 0.122443, Val Acc: 0.773196\n",
      "Epoch 15359 - Train Loss: 0.099683, Train Acc: 0.847436 | Val Loss: 0.122440, Val Acc: 0.773196\n",
      "Epoch 15360 - Train Loss: 0.099679, Train Acc: 0.847436 | Val Loss: 0.122438, Val Acc: 0.773196\n",
      "Epoch 15361 - Train Loss: 0.099676, Train Acc: 0.847436 | Val Loss: 0.122435, Val Acc: 0.773196\n",
      "Epoch 15362 - Train Loss: 0.099672, Train Acc: 0.847436 | Val Loss: 0.122433, Val Acc: 0.773196\n",
      "Epoch 15363 - Train Loss: 0.099668, Train Acc: 0.847436 | Val Loss: 0.122431, Val Acc: 0.773196\n",
      "Epoch 15364 - Train Loss: 0.099665, Train Acc: 0.847436 | Val Loss: 0.122428, Val Acc: 0.773196\n",
      "Epoch 15365 - Train Loss: 0.099661, Train Acc: 0.847436 | Val Loss: 0.122426, Val Acc: 0.773196\n",
      "Epoch 15366 - Train Loss: 0.099658, Train Acc: 0.847436 | Val Loss: 0.122424, Val Acc: 0.773196\n",
      "Epoch 15367 - Train Loss: 0.099654, Train Acc: 0.847436 | Val Loss: 0.122421, Val Acc: 0.773196\n",
      "Epoch 15368 - Train Loss: 0.099650, Train Acc: 0.847436 | Val Loss: 0.122419, Val Acc: 0.773196\n",
      "Epoch 15369 - Train Loss: 0.099647, Train Acc: 0.847436 | Val Loss: 0.122416, Val Acc: 0.773196\n",
      "Epoch 15370 - Train Loss: 0.099643, Train Acc: 0.847436 | Val Loss: 0.122414, Val Acc: 0.773196\n",
      "Epoch 15371 - Train Loss: 0.099639, Train Acc: 0.847436 | Val Loss: 0.122412, Val Acc: 0.773196\n",
      "Epoch 15372 - Train Loss: 0.099636, Train Acc: 0.847436 | Val Loss: 0.122409, Val Acc: 0.773196\n",
      "Epoch 15373 - Train Loss: 0.099632, Train Acc: 0.847436 | Val Loss: 0.122407, Val Acc: 0.773196\n",
      "Epoch 15374 - Train Loss: 0.099629, Train Acc: 0.847436 | Val Loss: 0.122405, Val Acc: 0.773196\n",
      "Epoch 15375 - Train Loss: 0.099625, Train Acc: 0.847436 | Val Loss: 0.122402, Val Acc: 0.773196\n",
      "Epoch 15376 - Train Loss: 0.099621, Train Acc: 0.847436 | Val Loss: 0.122400, Val Acc: 0.773196\n",
      "Epoch 15377 - Train Loss: 0.099618, Train Acc: 0.847436 | Val Loss: 0.122397, Val Acc: 0.773196\n",
      "Epoch 15378 - Train Loss: 0.099614, Train Acc: 0.847436 | Val Loss: 0.122395, Val Acc: 0.773196\n",
      "Epoch 15379 - Train Loss: 0.099611, Train Acc: 0.847436 | Val Loss: 0.122393, Val Acc: 0.773196\n",
      "Epoch 15380 - Train Loss: 0.099607, Train Acc: 0.847436 | Val Loss: 0.122390, Val Acc: 0.773196\n",
      "Epoch 15381 - Train Loss: 0.099603, Train Acc: 0.847436 | Val Loss: 0.122388, Val Acc: 0.773196\n",
      "Epoch 15382 - Train Loss: 0.099600, Train Acc: 0.847436 | Val Loss: 0.122386, Val Acc: 0.773196\n",
      "Epoch 15383 - Train Loss: 0.099596, Train Acc: 0.847436 | Val Loss: 0.122383, Val Acc: 0.773196\n",
      "Epoch 15384 - Train Loss: 0.099592, Train Acc: 0.847436 | Val Loss: 0.122381, Val Acc: 0.773196\n",
      "Epoch 15385 - Train Loss: 0.099589, Train Acc: 0.847436 | Val Loss: 0.122378, Val Acc: 0.773196\n",
      "Epoch 15386 - Train Loss: 0.099585, Train Acc: 0.847436 | Val Loss: 0.122376, Val Acc: 0.773196\n",
      "Epoch 15387 - Train Loss: 0.099582, Train Acc: 0.847436 | Val Loss: 0.122374, Val Acc: 0.773196\n",
      "Epoch 15388 - Train Loss: 0.099578, Train Acc: 0.847436 | Val Loss: 0.122371, Val Acc: 0.773196\n",
      "Epoch 15389 - Train Loss: 0.099574, Train Acc: 0.847436 | Val Loss: 0.122369, Val Acc: 0.773196\n",
      "Epoch 15390 - Train Loss: 0.099571, Train Acc: 0.847436 | Val Loss: 0.122367, Val Acc: 0.773196\n",
      "Epoch 15391 - Train Loss: 0.099567, Train Acc: 0.847436 | Val Loss: 0.122364, Val Acc: 0.773196\n",
      "Epoch 15392 - Train Loss: 0.099564, Train Acc: 0.847436 | Val Loss: 0.122362, Val Acc: 0.773196\n",
      "Epoch 15393 - Train Loss: 0.099560, Train Acc: 0.847436 | Val Loss: 0.122360, Val Acc: 0.773196\n",
      "Epoch 15394 - Train Loss: 0.099556, Train Acc: 0.847436 | Val Loss: 0.122357, Val Acc: 0.773196\n",
      "Epoch 15395 - Train Loss: 0.099553, Train Acc: 0.847436 | Val Loss: 0.122355, Val Acc: 0.773196\n",
      "Epoch 15396 - Train Loss: 0.099549, Train Acc: 0.847436 | Val Loss: 0.122352, Val Acc: 0.773196\n",
      "Epoch 15397 - Train Loss: 0.099546, Train Acc: 0.847436 | Val Loss: 0.122350, Val Acc: 0.773196\n",
      "Epoch 15398 - Train Loss: 0.099542, Train Acc: 0.847436 | Val Loss: 0.122348, Val Acc: 0.773196\n",
      "Epoch 15399 - Train Loss: 0.099538, Train Acc: 0.847436 | Val Loss: 0.122345, Val Acc: 0.773196\n",
      "Epoch 15400 - Train Loss: 0.099535, Train Acc: 0.847436 | Val Loss: 0.122343, Val Acc: 0.773196\n",
      "Epoch 15401 - Train Loss: 0.099531, Train Acc: 0.847436 | Val Loss: 0.122341, Val Acc: 0.773196\n",
      "Epoch 15402 - Train Loss: 0.099528, Train Acc: 0.847436 | Val Loss: 0.122338, Val Acc: 0.773196\n",
      "Epoch 15403 - Train Loss: 0.099524, Train Acc: 0.847436 | Val Loss: 0.122336, Val Acc: 0.773196\n",
      "Epoch 15404 - Train Loss: 0.099520, Train Acc: 0.847436 | Val Loss: 0.122334, Val Acc: 0.773196\n",
      "Epoch 15405 - Train Loss: 0.099517, Train Acc: 0.847436 | Val Loss: 0.122331, Val Acc: 0.773196\n",
      "Epoch 15406 - Train Loss: 0.099513, Train Acc: 0.847436 | Val Loss: 0.122329, Val Acc: 0.773196\n",
      "Epoch 15407 - Train Loss: 0.099510, Train Acc: 0.847436 | Val Loss: 0.122326, Val Acc: 0.773196\n",
      "Epoch 15408 - Train Loss: 0.099506, Train Acc: 0.847436 | Val Loss: 0.122324, Val Acc: 0.773196\n",
      "Epoch 15409 - Train Loss: 0.099502, Train Acc: 0.847436 | Val Loss: 0.122322, Val Acc: 0.773196\n",
      "Epoch 15410 - Train Loss: 0.099499, Train Acc: 0.847436 | Val Loss: 0.122319, Val Acc: 0.773196\n",
      "Epoch 15411 - Train Loss: 0.099495, Train Acc: 0.847436 | Val Loss: 0.122317, Val Acc: 0.773196\n",
      "Epoch 15412 - Train Loss: 0.099492, Train Acc: 0.847436 | Val Loss: 0.122315, Val Acc: 0.773196\n",
      "Epoch 15413 - Train Loss: 0.099488, Train Acc: 0.847436 | Val Loss: 0.122312, Val Acc: 0.773196\n",
      "Epoch 15414 - Train Loss: 0.099484, Train Acc: 0.847436 | Val Loss: 0.122310, Val Acc: 0.773196\n",
      "Epoch 15415 - Train Loss: 0.099481, Train Acc: 0.847436 | Val Loss: 0.122308, Val Acc: 0.773196\n",
      "Epoch 15416 - Train Loss: 0.099477, Train Acc: 0.847436 | Val Loss: 0.122305, Val Acc: 0.773196\n",
      "Epoch 15417 - Train Loss: 0.099474, Train Acc: 0.847436 | Val Loss: 0.122303, Val Acc: 0.773196\n",
      "Epoch 15418 - Train Loss: 0.099470, Train Acc: 0.847436 | Val Loss: 0.122301, Val Acc: 0.773196\n",
      "Epoch 15419 - Train Loss: 0.099466, Train Acc: 0.847436 | Val Loss: 0.122298, Val Acc: 0.773196\n",
      "Epoch 15420 - Train Loss: 0.099463, Train Acc: 0.847436 | Val Loss: 0.122296, Val Acc: 0.773196\n",
      "Epoch 15421 - Train Loss: 0.099459, Train Acc: 0.847436 | Val Loss: 0.122293, Val Acc: 0.773196\n",
      "Epoch 15422 - Train Loss: 0.099456, Train Acc: 0.847436 | Val Loss: 0.122291, Val Acc: 0.773196\n",
      "Epoch 15423 - Train Loss: 0.099452, Train Acc: 0.847436 | Val Loss: 0.122289, Val Acc: 0.773196\n",
      "Epoch 15424 - Train Loss: 0.099448, Train Acc: 0.847436 | Val Loss: 0.122286, Val Acc: 0.773196\n",
      "Epoch 15425 - Train Loss: 0.099445, Train Acc: 0.847436 | Val Loss: 0.122284, Val Acc: 0.773196\n",
      "Epoch 15426 - Train Loss: 0.099441, Train Acc: 0.847436 | Val Loss: 0.122282, Val Acc: 0.773196\n",
      "Epoch 15427 - Train Loss: 0.099438, Train Acc: 0.847436 | Val Loss: 0.122279, Val Acc: 0.773196\n",
      "Epoch 15428 - Train Loss: 0.099434, Train Acc: 0.847436 | Val Loss: 0.122277, Val Acc: 0.773196\n",
      "Epoch 15429 - Train Loss: 0.099430, Train Acc: 0.847436 | Val Loss: 0.122275, Val Acc: 0.773196\n",
      "Epoch 15430 - Train Loss: 0.099427, Train Acc: 0.847436 | Val Loss: 0.122272, Val Acc: 0.773196\n",
      "Epoch 15431 - Train Loss: 0.099423, Train Acc: 0.847436 | Val Loss: 0.122270, Val Acc: 0.773196\n",
      "Epoch 15432 - Train Loss: 0.099420, Train Acc: 0.847436 | Val Loss: 0.122268, Val Acc: 0.773196\n",
      "Epoch 15433 - Train Loss: 0.099416, Train Acc: 0.847436 | Val Loss: 0.122265, Val Acc: 0.773196\n",
      "Epoch 15434 - Train Loss: 0.099413, Train Acc: 0.847436 | Val Loss: 0.122263, Val Acc: 0.773196\n",
      "Epoch 15435 - Train Loss: 0.099409, Train Acc: 0.847436 | Val Loss: 0.122261, Val Acc: 0.773196\n",
      "Epoch 15436 - Train Loss: 0.099405, Train Acc: 0.847436 | Val Loss: 0.122258, Val Acc: 0.773196\n",
      "Epoch 15437 - Train Loss: 0.099402, Train Acc: 0.847436 | Val Loss: 0.122256, Val Acc: 0.773196\n",
      "Epoch 15438 - Train Loss: 0.099398, Train Acc: 0.847436 | Val Loss: 0.122254, Val Acc: 0.773196\n",
      "Epoch 15439 - Train Loss: 0.099395, Train Acc: 0.847436 | Val Loss: 0.122251, Val Acc: 0.773196\n",
      "Epoch 15440 - Train Loss: 0.099391, Train Acc: 0.847436 | Val Loss: 0.122249, Val Acc: 0.773196\n",
      "Epoch 15441 - Train Loss: 0.099387, Train Acc: 0.847436 | Val Loss: 0.122247, Val Acc: 0.773196\n",
      "Epoch 15442 - Train Loss: 0.099384, Train Acc: 0.847436 | Val Loss: 0.122244, Val Acc: 0.773196\n",
      "Epoch 15443 - Train Loss: 0.099380, Train Acc: 0.847436 | Val Loss: 0.122242, Val Acc: 0.773196\n",
      "Epoch 15444 - Train Loss: 0.099377, Train Acc: 0.847436 | Val Loss: 0.122239, Val Acc: 0.773196\n",
      "Epoch 15445 - Train Loss: 0.099373, Train Acc: 0.847436 | Val Loss: 0.122237, Val Acc: 0.773196\n",
      "Epoch 15446 - Train Loss: 0.099370, Train Acc: 0.847436 | Val Loss: 0.122235, Val Acc: 0.773196\n",
      "Epoch 15447 - Train Loss: 0.099366, Train Acc: 0.847436 | Val Loss: 0.122232, Val Acc: 0.773196\n",
      "Epoch 15448 - Train Loss: 0.099362, Train Acc: 0.847436 | Val Loss: 0.122230, Val Acc: 0.773196\n",
      "Epoch 15449 - Train Loss: 0.099359, Train Acc: 0.847436 | Val Loss: 0.122228, Val Acc: 0.773196\n",
      "Epoch 15450 - Train Loss: 0.099355, Train Acc: 0.847436 | Val Loss: 0.122225, Val Acc: 0.773196\n",
      "Epoch 15451 - Train Loss: 0.099352, Train Acc: 0.847436 | Val Loss: 0.122223, Val Acc: 0.773196\n",
      "Epoch 15452 - Train Loss: 0.099348, Train Acc: 0.847436 | Val Loss: 0.122221, Val Acc: 0.773196\n",
      "Epoch 15453 - Train Loss: 0.099344, Train Acc: 0.847436 | Val Loss: 0.122218, Val Acc: 0.773196\n",
      "Epoch 15454 - Train Loss: 0.099341, Train Acc: 0.847436 | Val Loss: 0.122216, Val Acc: 0.773196\n",
      "Epoch 15455 - Train Loss: 0.099337, Train Acc: 0.847436 | Val Loss: 0.122214, Val Acc: 0.773196\n",
      "Epoch 15456 - Train Loss: 0.099334, Train Acc: 0.847436 | Val Loss: 0.122211, Val Acc: 0.773196\n",
      "Epoch 15457 - Train Loss: 0.099330, Train Acc: 0.847436 | Val Loss: 0.122209, Val Acc: 0.773196\n",
      "Epoch 15458 - Train Loss: 0.099327, Train Acc: 0.847436 | Val Loss: 0.122207, Val Acc: 0.773196\n",
      "Epoch 15459 - Train Loss: 0.099323, Train Acc: 0.847436 | Val Loss: 0.122204, Val Acc: 0.773196\n",
      "Epoch 15460 - Train Loss: 0.099319, Train Acc: 0.847436 | Val Loss: 0.122202, Val Acc: 0.773196\n",
      "Epoch 15461 - Train Loss: 0.099316, Train Acc: 0.847436 | Val Loss: 0.122200, Val Acc: 0.773196\n",
      "Epoch 15462 - Train Loss: 0.099312, Train Acc: 0.847436 | Val Loss: 0.122197, Val Acc: 0.773196\n",
      "Epoch 15463 - Train Loss: 0.099309, Train Acc: 0.847436 | Val Loss: 0.122195, Val Acc: 0.773196\n",
      "Epoch 15464 - Train Loss: 0.099305, Train Acc: 0.847436 | Val Loss: 0.122193, Val Acc: 0.773196\n",
      "Epoch 15465 - Train Loss: 0.099302, Train Acc: 0.847436 | Val Loss: 0.122190, Val Acc: 0.773196\n",
      "Epoch 15466 - Train Loss: 0.099298, Train Acc: 0.847436 | Val Loss: 0.122188, Val Acc: 0.773196\n",
      "Epoch 15467 - Train Loss: 0.099294, Train Acc: 0.847436 | Val Loss: 0.122186, Val Acc: 0.773196\n",
      "Epoch 15468 - Train Loss: 0.099291, Train Acc: 0.847436 | Val Loss: 0.122183, Val Acc: 0.773196\n",
      "Epoch 15469 - Train Loss: 0.099287, Train Acc: 0.847436 | Val Loss: 0.122181, Val Acc: 0.773196\n",
      "Epoch 15470 - Train Loss: 0.099284, Train Acc: 0.847436 | Val Loss: 0.122179, Val Acc: 0.773196\n",
      "Epoch 15471 - Train Loss: 0.099280, Train Acc: 0.847436 | Val Loss: 0.122176, Val Acc: 0.773196\n",
      "Epoch 15472 - Train Loss: 0.099277, Train Acc: 0.847436 | Val Loss: 0.122174, Val Acc: 0.773196\n",
      "Epoch 15473 - Train Loss: 0.099273, Train Acc: 0.847436 | Val Loss: 0.122172, Val Acc: 0.773196\n",
      "Epoch 15474 - Train Loss: 0.099269, Train Acc: 0.847436 | Val Loss: 0.122169, Val Acc: 0.773196\n",
      "Epoch 15475 - Train Loss: 0.099266, Train Acc: 0.847436 | Val Loss: 0.122167, Val Acc: 0.773196\n",
      "Epoch 15476 - Train Loss: 0.099262, Train Acc: 0.847436 | Val Loss: 0.122165, Val Acc: 0.773196\n",
      "Epoch 15477 - Train Loss: 0.099259, Train Acc: 0.847436 | Val Loss: 0.122162, Val Acc: 0.773196\n",
      "Epoch 15478 - Train Loss: 0.099255, Train Acc: 0.847436 | Val Loss: 0.122160, Val Acc: 0.773196\n",
      "Epoch 15479 - Train Loss: 0.099252, Train Acc: 0.847436 | Val Loss: 0.122158, Val Acc: 0.773196\n",
      "Epoch 15480 - Train Loss: 0.099248, Train Acc: 0.847436 | Val Loss: 0.122155, Val Acc: 0.773196\n",
      "Epoch 15481 - Train Loss: 0.099244, Train Acc: 0.847436 | Val Loss: 0.122153, Val Acc: 0.773196\n",
      "Epoch 15482 - Train Loss: 0.099241, Train Acc: 0.847436 | Val Loss: 0.122151, Val Acc: 0.773196\n",
      "Epoch 15483 - Train Loss: 0.099237, Train Acc: 0.847436 | Val Loss: 0.122149, Val Acc: 0.773196\n",
      "Epoch 15484 - Train Loss: 0.099234, Train Acc: 0.847436 | Val Loss: 0.122146, Val Acc: 0.773196\n",
      "Epoch 15485 - Train Loss: 0.099230, Train Acc: 0.847436 | Val Loss: 0.122144, Val Acc: 0.773196\n",
      "Epoch 15486 - Train Loss: 0.099227, Train Acc: 0.847436 | Val Loss: 0.122142, Val Acc: 0.773196\n",
      "Epoch 15487 - Train Loss: 0.099223, Train Acc: 0.847436 | Val Loss: 0.122139, Val Acc: 0.773196\n",
      "Epoch 15488 - Train Loss: 0.099219, Train Acc: 0.847436 | Val Loss: 0.122137, Val Acc: 0.773196\n",
      "Epoch 15489 - Train Loss: 0.099216, Train Acc: 0.847436 | Val Loss: 0.122135, Val Acc: 0.773196\n",
      "Epoch 15490 - Train Loss: 0.099212, Train Acc: 0.847436 | Val Loss: 0.122132, Val Acc: 0.773196\n",
      "Epoch 15491 - Train Loss: 0.099209, Train Acc: 0.847436 | Val Loss: 0.122130, Val Acc: 0.773196\n",
      "Epoch 15492 - Train Loss: 0.099205, Train Acc: 0.847436 | Val Loss: 0.122128, Val Acc: 0.773196\n",
      "Epoch 15493 - Train Loss: 0.099202, Train Acc: 0.847436 | Val Loss: 0.122125, Val Acc: 0.773196\n",
      "Epoch 15494 - Train Loss: 0.099198, Train Acc: 0.847436 | Val Loss: 0.122123, Val Acc: 0.773196\n",
      "Epoch 15495 - Train Loss: 0.099195, Train Acc: 0.847436 | Val Loss: 0.122121, Val Acc: 0.773196\n",
      "Epoch 15496 - Train Loss: 0.099191, Train Acc: 0.847436 | Val Loss: 0.122118, Val Acc: 0.773196\n",
      "Epoch 15497 - Train Loss: 0.099187, Train Acc: 0.847436 | Val Loss: 0.122116, Val Acc: 0.773196\n",
      "Epoch 15498 - Train Loss: 0.099184, Train Acc: 0.847436 | Val Loss: 0.122114, Val Acc: 0.773196\n",
      "Epoch 15499 - Train Loss: 0.099180, Train Acc: 0.847436 | Val Loss: 0.122111, Val Acc: 0.773196\n",
      "Epoch 15500 - Train Loss: 0.099177, Train Acc: 0.847436 | Val Loss: 0.122109, Val Acc: 0.773196\n",
      "Epoch 15501 - Train Loss: 0.099173, Train Acc: 0.847436 | Val Loss: 0.122107, Val Acc: 0.773196\n",
      "Epoch 15502 - Train Loss: 0.099170, Train Acc: 0.847436 | Val Loss: 0.122104, Val Acc: 0.773196\n",
      "Epoch 15503 - Train Loss: 0.099166, Train Acc: 0.847436 | Val Loss: 0.122102, Val Acc: 0.773196\n",
      "Epoch 15504 - Train Loss: 0.099163, Train Acc: 0.847436 | Val Loss: 0.122100, Val Acc: 0.773196\n",
      "Epoch 15505 - Train Loss: 0.099159, Train Acc: 0.847436 | Val Loss: 0.122097, Val Acc: 0.773196\n",
      "Epoch 15506 - Train Loss: 0.099155, Train Acc: 0.847436 | Val Loss: 0.122095, Val Acc: 0.773196\n",
      "Epoch 15507 - Train Loss: 0.099152, Train Acc: 0.847436 | Val Loss: 0.122093, Val Acc: 0.773196\n",
      "Epoch 15508 - Train Loss: 0.099148, Train Acc: 0.847436 | Val Loss: 0.122091, Val Acc: 0.773196\n",
      "Epoch 15509 - Train Loss: 0.099145, Train Acc: 0.847436 | Val Loss: 0.122088, Val Acc: 0.773196\n",
      "Epoch 15510 - Train Loss: 0.099141, Train Acc: 0.847436 | Val Loss: 0.122086, Val Acc: 0.773196\n",
      "Epoch 15511 - Train Loss: 0.099138, Train Acc: 0.847436 | Val Loss: 0.122084, Val Acc: 0.773196\n",
      "Epoch 15512 - Train Loss: 0.099134, Train Acc: 0.847436 | Val Loss: 0.122081, Val Acc: 0.773196\n",
      "Epoch 15513 - Train Loss: 0.099131, Train Acc: 0.847436 | Val Loss: 0.122079, Val Acc: 0.773196\n",
      "Epoch 15514 - Train Loss: 0.099127, Train Acc: 0.847436 | Val Loss: 0.122077, Val Acc: 0.773196\n",
      "Epoch 15515 - Train Loss: 0.099123, Train Acc: 0.847436 | Val Loss: 0.122074, Val Acc: 0.773196\n",
      "Epoch 15516 - Train Loss: 0.099120, Train Acc: 0.847436 | Val Loss: 0.122072, Val Acc: 0.773196\n",
      "Epoch 15517 - Train Loss: 0.099116, Train Acc: 0.847436 | Val Loss: 0.122070, Val Acc: 0.773196\n",
      "Epoch 15518 - Train Loss: 0.099113, Train Acc: 0.847436 | Val Loss: 0.122067, Val Acc: 0.773196\n",
      "Epoch 15519 - Train Loss: 0.099109, Train Acc: 0.847436 | Val Loss: 0.122065, Val Acc: 0.773196\n",
      "Epoch 15520 - Train Loss: 0.099106, Train Acc: 0.847436 | Val Loss: 0.122063, Val Acc: 0.773196\n",
      "Epoch 15521 - Train Loss: 0.099102, Train Acc: 0.847436 | Val Loss: 0.122060, Val Acc: 0.773196\n",
      "Epoch 15522 - Train Loss: 0.099099, Train Acc: 0.847436 | Val Loss: 0.122058, Val Acc: 0.773196\n",
      "Epoch 15523 - Train Loss: 0.099095, Train Acc: 0.847436 | Val Loss: 0.122056, Val Acc: 0.773196\n",
      "Epoch 15524 - Train Loss: 0.099091, Train Acc: 0.847436 | Val Loss: 0.122054, Val Acc: 0.773196\n",
      "Epoch 15525 - Train Loss: 0.099088, Train Acc: 0.847436 | Val Loss: 0.122051, Val Acc: 0.773196\n",
      "Epoch 15526 - Train Loss: 0.099084, Train Acc: 0.847436 | Val Loss: 0.122049, Val Acc: 0.773196\n",
      "Epoch 15527 - Train Loss: 0.099081, Train Acc: 0.847436 | Val Loss: 0.122047, Val Acc: 0.773196\n",
      "Epoch 15528 - Train Loss: 0.099077, Train Acc: 0.847436 | Val Loss: 0.122044, Val Acc: 0.773196\n",
      "Epoch 15529 - Train Loss: 0.099074, Train Acc: 0.847436 | Val Loss: 0.122042, Val Acc: 0.773196\n",
      "Epoch 15530 - Train Loss: 0.099070, Train Acc: 0.847436 | Val Loss: 0.122040, Val Acc: 0.773196\n",
      "Epoch 15531 - Train Loss: 0.099067, Train Acc: 0.847436 | Val Loss: 0.122037, Val Acc: 0.773196\n",
      "Epoch 15532 - Train Loss: 0.099063, Train Acc: 0.847436 | Val Loss: 0.122035, Val Acc: 0.773196\n",
      "Epoch 15533 - Train Loss: 0.099060, Train Acc: 0.847436 | Val Loss: 0.122033, Val Acc: 0.773196\n",
      "Epoch 15534 - Train Loss: 0.099056, Train Acc: 0.847436 | Val Loss: 0.122031, Val Acc: 0.773196\n",
      "Epoch 15535 - Train Loss: 0.099052, Train Acc: 0.847436 | Val Loss: 0.122028, Val Acc: 0.773196\n",
      "Epoch 15536 - Train Loss: 0.099049, Train Acc: 0.847436 | Val Loss: 0.122026, Val Acc: 0.773196\n",
      "Epoch 15537 - Train Loss: 0.099045, Train Acc: 0.847436 | Val Loss: 0.122024, Val Acc: 0.773196\n",
      "Epoch 15538 - Train Loss: 0.099042, Train Acc: 0.847436 | Val Loss: 0.122021, Val Acc: 0.773196\n",
      "Epoch 15539 - Train Loss: 0.099038, Train Acc: 0.847436 | Val Loss: 0.122019, Val Acc: 0.773196\n",
      "Epoch 15540 - Train Loss: 0.099035, Train Acc: 0.847436 | Val Loss: 0.122017, Val Acc: 0.773196\n",
      "Epoch 15541 - Train Loss: 0.099031, Train Acc: 0.847436 | Val Loss: 0.122014, Val Acc: 0.773196\n",
      "Epoch 15542 - Train Loss: 0.099028, Train Acc: 0.847436 | Val Loss: 0.122012, Val Acc: 0.773196\n",
      "Epoch 15543 - Train Loss: 0.099024, Train Acc: 0.847436 | Val Loss: 0.122010, Val Acc: 0.773196\n",
      "Epoch 15544 - Train Loss: 0.099021, Train Acc: 0.847436 | Val Loss: 0.122008, Val Acc: 0.773196\n",
      "Epoch 15545 - Train Loss: 0.099017, Train Acc: 0.847436 | Val Loss: 0.122005, Val Acc: 0.773196\n",
      "Epoch 15546 - Train Loss: 0.099014, Train Acc: 0.847436 | Val Loss: 0.122003, Val Acc: 0.773196\n",
      "Epoch 15547 - Train Loss: 0.099010, Train Acc: 0.847436 | Val Loss: 0.122001, Val Acc: 0.773196\n",
      "Epoch 15548 - Train Loss: 0.099006, Train Acc: 0.847436 | Val Loss: 0.121998, Val Acc: 0.773196\n",
      "Epoch 15549 - Train Loss: 0.099003, Train Acc: 0.847436 | Val Loss: 0.121996, Val Acc: 0.773196\n",
      "Epoch 15550 - Train Loss: 0.098999, Train Acc: 0.847436 | Val Loss: 0.121994, Val Acc: 0.773196\n",
      "Epoch 15551 - Train Loss: 0.098996, Train Acc: 0.847436 | Val Loss: 0.121991, Val Acc: 0.773196\n",
      "Epoch 15552 - Train Loss: 0.098992, Train Acc: 0.847436 | Val Loss: 0.121989, Val Acc: 0.773196\n",
      "Epoch 15553 - Train Loss: 0.098989, Train Acc: 0.847436 | Val Loss: 0.121987, Val Acc: 0.773196\n",
      "Epoch 15554 - Train Loss: 0.098985, Train Acc: 0.847436 | Val Loss: 0.121985, Val Acc: 0.773196\n",
      "Epoch 15555 - Train Loss: 0.098982, Train Acc: 0.847436 | Val Loss: 0.121982, Val Acc: 0.773196\n",
      "Epoch 15556 - Train Loss: 0.098978, Train Acc: 0.847436 | Val Loss: 0.121980, Val Acc: 0.773196\n",
      "Epoch 15557 - Train Loss: 0.098975, Train Acc: 0.847436 | Val Loss: 0.121978, Val Acc: 0.773196\n",
      "Epoch 15558 - Train Loss: 0.098971, Train Acc: 0.847436 | Val Loss: 0.121975, Val Acc: 0.773196\n",
      "Epoch 15559 - Train Loss: 0.098968, Train Acc: 0.847436 | Val Loss: 0.121973, Val Acc: 0.773196\n",
      "Epoch 15560 - Train Loss: 0.098964, Train Acc: 0.847436 | Val Loss: 0.121971, Val Acc: 0.773196\n",
      "Epoch 15561 - Train Loss: 0.098961, Train Acc: 0.847436 | Val Loss: 0.121969, Val Acc: 0.773196\n",
      "Epoch 15562 - Train Loss: 0.098957, Train Acc: 0.847436 | Val Loss: 0.121966, Val Acc: 0.773196\n",
      "Epoch 15563 - Train Loss: 0.098953, Train Acc: 0.847436 | Val Loss: 0.121964, Val Acc: 0.773196\n",
      "Epoch 15564 - Train Loss: 0.098950, Train Acc: 0.847436 | Val Loss: 0.121962, Val Acc: 0.773196\n",
      "Epoch 15565 - Train Loss: 0.098946, Train Acc: 0.847436 | Val Loss: 0.121959, Val Acc: 0.773196\n",
      "Epoch 15566 - Train Loss: 0.098943, Train Acc: 0.847436 | Val Loss: 0.121957, Val Acc: 0.773196\n",
      "Epoch 15567 - Train Loss: 0.098939, Train Acc: 0.847436 | Val Loss: 0.121955, Val Acc: 0.773196\n",
      "Epoch 15568 - Train Loss: 0.098936, Train Acc: 0.847436 | Val Loss: 0.121953, Val Acc: 0.773196\n",
      "Epoch 15569 - Train Loss: 0.098932, Train Acc: 0.847436 | Val Loss: 0.121950, Val Acc: 0.773196\n",
      "Epoch 15570 - Train Loss: 0.098929, Train Acc: 0.847436 | Val Loss: 0.121948, Val Acc: 0.773196\n",
      "Epoch 15571 - Train Loss: 0.098925, Train Acc: 0.847436 | Val Loss: 0.121946, Val Acc: 0.773196\n",
      "Epoch 15572 - Train Loss: 0.098922, Train Acc: 0.847436 | Val Loss: 0.121943, Val Acc: 0.773196\n",
      "Epoch 15573 - Train Loss: 0.098918, Train Acc: 0.847436 | Val Loss: 0.121941, Val Acc: 0.773196\n",
      "Epoch 15574 - Train Loss: 0.098915, Train Acc: 0.847436 | Val Loss: 0.121939, Val Acc: 0.773196\n",
      "Epoch 15575 - Train Loss: 0.098911, Train Acc: 0.847436 | Val Loss: 0.121937, Val Acc: 0.773196\n",
      "Epoch 15576 - Train Loss: 0.098908, Train Acc: 0.847436 | Val Loss: 0.121934, Val Acc: 0.773196\n",
      "Epoch 15577 - Train Loss: 0.098904, Train Acc: 0.847436 | Val Loss: 0.121932, Val Acc: 0.773196\n",
      "Epoch 15578 - Train Loss: 0.098901, Train Acc: 0.847436 | Val Loss: 0.121930, Val Acc: 0.773196\n",
      "Epoch 15579 - Train Loss: 0.098897, Train Acc: 0.847436 | Val Loss: 0.121927, Val Acc: 0.773196\n",
      "Epoch 15580 - Train Loss: 0.098894, Train Acc: 0.847436 | Val Loss: 0.121925, Val Acc: 0.773196\n",
      "Epoch 15581 - Train Loss: 0.098890, Train Acc: 0.847436 | Val Loss: 0.121923, Val Acc: 0.773196\n",
      "Epoch 15582 - Train Loss: 0.098886, Train Acc: 0.847436 | Val Loss: 0.121921, Val Acc: 0.773196\n",
      "Epoch 15583 - Train Loss: 0.098883, Train Acc: 0.847436 | Val Loss: 0.121918, Val Acc: 0.773196\n",
      "Epoch 15584 - Train Loss: 0.098879, Train Acc: 0.847436 | Val Loss: 0.121916, Val Acc: 0.773196\n",
      "Epoch 15585 - Train Loss: 0.098876, Train Acc: 0.847436 | Val Loss: 0.121914, Val Acc: 0.773196\n",
      "Epoch 15586 - Train Loss: 0.098872, Train Acc: 0.847436 | Val Loss: 0.121911, Val Acc: 0.773196\n",
      "Epoch 15587 - Train Loss: 0.098869, Train Acc: 0.847436 | Val Loss: 0.121909, Val Acc: 0.773196\n",
      "Epoch 15588 - Train Loss: 0.098865, Train Acc: 0.847436 | Val Loss: 0.121907, Val Acc: 0.773196\n",
      "Epoch 15589 - Train Loss: 0.098862, Train Acc: 0.847436 | Val Loss: 0.121905, Val Acc: 0.773196\n",
      "Epoch 15590 - Train Loss: 0.098858, Train Acc: 0.847436 | Val Loss: 0.121902, Val Acc: 0.773196\n",
      "Epoch 15591 - Train Loss: 0.098855, Train Acc: 0.847436 | Val Loss: 0.121900, Val Acc: 0.773196\n",
      "Epoch 15592 - Train Loss: 0.098851, Train Acc: 0.847436 | Val Loss: 0.121898, Val Acc: 0.773196\n",
      "Epoch 15593 - Train Loss: 0.098848, Train Acc: 0.847436 | Val Loss: 0.121895, Val Acc: 0.773196\n",
      "Epoch 15594 - Train Loss: 0.098844, Train Acc: 0.847436 | Val Loss: 0.121893, Val Acc: 0.773196\n",
      "Epoch 15595 - Train Loss: 0.098841, Train Acc: 0.847436 | Val Loss: 0.121891, Val Acc: 0.773196\n",
      "Epoch 15596 - Train Loss: 0.098837, Train Acc: 0.847436 | Val Loss: 0.121889, Val Acc: 0.773196\n",
      "Epoch 15597 - Train Loss: 0.098834, Train Acc: 0.847436 | Val Loss: 0.121886, Val Acc: 0.773196\n",
      "Epoch 15598 - Train Loss: 0.098830, Train Acc: 0.847436 | Val Loss: 0.121884, Val Acc: 0.773196\n",
      "Epoch 15599 - Train Loss: 0.098827, Train Acc: 0.847436 | Val Loss: 0.121882, Val Acc: 0.773196\n",
      "Epoch 15600 - Train Loss: 0.098823, Train Acc: 0.847436 | Val Loss: 0.121880, Val Acc: 0.773196\n",
      "Epoch 15601 - Train Loss: 0.098820, Train Acc: 0.847436 | Val Loss: 0.121877, Val Acc: 0.773196\n",
      "Epoch 15602 - Train Loss: 0.098816, Train Acc: 0.847436 | Val Loss: 0.121875, Val Acc: 0.773196\n",
      "Epoch 15603 - Train Loss: 0.098813, Train Acc: 0.847436 | Val Loss: 0.121873, Val Acc: 0.773196\n",
      "Epoch 15604 - Train Loss: 0.098809, Train Acc: 0.847436 | Val Loss: 0.121870, Val Acc: 0.773196\n",
      "Epoch 15605 - Train Loss: 0.098806, Train Acc: 0.847436 | Val Loss: 0.121868, Val Acc: 0.773196\n",
      "Epoch 15606 - Train Loss: 0.098802, Train Acc: 0.847436 | Val Loss: 0.121866, Val Acc: 0.773196\n",
      "Epoch 15607 - Train Loss: 0.098799, Train Acc: 0.847436 | Val Loss: 0.121864, Val Acc: 0.773196\n",
      "Epoch 15608 - Train Loss: 0.098795, Train Acc: 0.847436 | Val Loss: 0.121861, Val Acc: 0.773196\n",
      "Epoch 15609 - Train Loss: 0.098792, Train Acc: 0.847436 | Val Loss: 0.121859, Val Acc: 0.773196\n",
      "Epoch 15610 - Train Loss: 0.098788, Train Acc: 0.847436 | Val Loss: 0.121857, Val Acc: 0.773196\n",
      "Epoch 15611 - Train Loss: 0.098785, Train Acc: 0.847436 | Val Loss: 0.121855, Val Acc: 0.773196\n",
      "Epoch 15612 - Train Loss: 0.098781, Train Acc: 0.847436 | Val Loss: 0.121852, Val Acc: 0.773196\n",
      "Epoch 15613 - Train Loss: 0.098778, Train Acc: 0.847436 | Val Loss: 0.121850, Val Acc: 0.773196\n",
      "Epoch 15614 - Train Loss: 0.098774, Train Acc: 0.847436 | Val Loss: 0.121848, Val Acc: 0.773196\n",
      "Epoch 15615 - Train Loss: 0.098771, Train Acc: 0.847436 | Val Loss: 0.121846, Val Acc: 0.773196\n",
      "Epoch 15616 - Train Loss: 0.098767, Train Acc: 0.847436 | Val Loss: 0.121843, Val Acc: 0.773196\n",
      "Epoch 15617 - Train Loss: 0.098763, Train Acc: 0.847436 | Val Loss: 0.121841, Val Acc: 0.773196\n",
      "Epoch 15618 - Train Loss: 0.098760, Train Acc: 0.847436 | Val Loss: 0.121839, Val Acc: 0.773196\n",
      "Epoch 15619 - Train Loss: 0.098756, Train Acc: 0.847436 | Val Loss: 0.121836, Val Acc: 0.773196\n",
      "Epoch 15620 - Train Loss: 0.098753, Train Acc: 0.847436 | Val Loss: 0.121834, Val Acc: 0.773196\n",
      "Epoch 15621 - Train Loss: 0.098749, Train Acc: 0.847436 | Val Loss: 0.121832, Val Acc: 0.773196\n",
      "Epoch 15622 - Train Loss: 0.098746, Train Acc: 0.847436 | Val Loss: 0.121830, Val Acc: 0.773196\n",
      "Epoch 15623 - Train Loss: 0.098742, Train Acc: 0.847436 | Val Loss: 0.121827, Val Acc: 0.773196\n",
      "Epoch 15624 - Train Loss: 0.098739, Train Acc: 0.847436 | Val Loss: 0.121825, Val Acc: 0.773196\n",
      "Epoch 15625 - Train Loss: 0.098735, Train Acc: 0.847436 | Val Loss: 0.121823, Val Acc: 0.773196\n",
      "Epoch 15626 - Train Loss: 0.098732, Train Acc: 0.847436 | Val Loss: 0.121821, Val Acc: 0.773196\n",
      "Epoch 15627 - Train Loss: 0.098728, Train Acc: 0.847436 | Val Loss: 0.121818, Val Acc: 0.773196\n",
      "Epoch 15628 - Train Loss: 0.098725, Train Acc: 0.847436 | Val Loss: 0.121816, Val Acc: 0.773196\n",
      "Epoch 15629 - Train Loss: 0.098721, Train Acc: 0.847436 | Val Loss: 0.121814, Val Acc: 0.773196\n",
      "Epoch 15630 - Train Loss: 0.098718, Train Acc: 0.847436 | Val Loss: 0.121812, Val Acc: 0.773196\n",
      "Epoch 15631 - Train Loss: 0.098714, Train Acc: 0.847436 | Val Loss: 0.121809, Val Acc: 0.773196\n",
      "Epoch 15632 - Train Loss: 0.098711, Train Acc: 0.847436 | Val Loss: 0.121807, Val Acc: 0.773196\n",
      "Epoch 15633 - Train Loss: 0.098707, Train Acc: 0.847436 | Val Loss: 0.121805, Val Acc: 0.773196\n",
      "Epoch 15634 - Train Loss: 0.098704, Train Acc: 0.847436 | Val Loss: 0.121803, Val Acc: 0.773196\n",
      "Epoch 15635 - Train Loss: 0.098700, Train Acc: 0.847436 | Val Loss: 0.121800, Val Acc: 0.773196\n",
      "Epoch 15636 - Train Loss: 0.098697, Train Acc: 0.847436 | Val Loss: 0.121798, Val Acc: 0.773196\n",
      "Epoch 15637 - Train Loss: 0.098693, Train Acc: 0.847436 | Val Loss: 0.121796, Val Acc: 0.773196\n",
      "Epoch 15638 - Train Loss: 0.098690, Train Acc: 0.847436 | Val Loss: 0.121794, Val Acc: 0.773196\n",
      "Epoch 15639 - Train Loss: 0.098686, Train Acc: 0.847436 | Val Loss: 0.121791, Val Acc: 0.773196\n",
      "Epoch 15640 - Train Loss: 0.098683, Train Acc: 0.847436 | Val Loss: 0.121789, Val Acc: 0.773196\n",
      "Epoch 15641 - Train Loss: 0.098679, Train Acc: 0.847436 | Val Loss: 0.121787, Val Acc: 0.773196\n",
      "Epoch 15642 - Train Loss: 0.098676, Train Acc: 0.847436 | Val Loss: 0.121784, Val Acc: 0.773196\n",
      "Epoch 15643 - Train Loss: 0.098672, Train Acc: 0.847436 | Val Loss: 0.121782, Val Acc: 0.773196\n",
      "Epoch 15644 - Train Loss: 0.098669, Train Acc: 0.847436 | Val Loss: 0.121780, Val Acc: 0.773196\n",
      "Epoch 15645 - Train Loss: 0.098665, Train Acc: 0.847436 | Val Loss: 0.121778, Val Acc: 0.773196\n",
      "Epoch 15646 - Train Loss: 0.098662, Train Acc: 0.847436 | Val Loss: 0.121775, Val Acc: 0.773196\n",
      "Epoch 15647 - Train Loss: 0.098659, Train Acc: 0.847436 | Val Loss: 0.121773, Val Acc: 0.773196\n",
      "Epoch 15648 - Train Loss: 0.098655, Train Acc: 0.847436 | Val Loss: 0.121771, Val Acc: 0.773196\n",
      "Epoch 15649 - Train Loss: 0.098652, Train Acc: 0.847436 | Val Loss: 0.121769, Val Acc: 0.773196\n",
      "Epoch 15650 - Train Loss: 0.098648, Train Acc: 0.847436 | Val Loss: 0.121766, Val Acc: 0.773196\n",
      "Epoch 15651 - Train Loss: 0.098645, Train Acc: 0.847436 | Val Loss: 0.121764, Val Acc: 0.773196\n",
      "Epoch 15652 - Train Loss: 0.098641, Train Acc: 0.847436 | Val Loss: 0.121762, Val Acc: 0.773196\n",
      "Epoch 15653 - Train Loss: 0.098638, Train Acc: 0.847436 | Val Loss: 0.121760, Val Acc: 0.773196\n",
      "Epoch 15654 - Train Loss: 0.098634, Train Acc: 0.847436 | Val Loss: 0.121757, Val Acc: 0.773196\n",
      "Epoch 15655 - Train Loss: 0.098631, Train Acc: 0.847436 | Val Loss: 0.121755, Val Acc: 0.773196\n",
      "Epoch 15656 - Train Loss: 0.098627, Train Acc: 0.847436 | Val Loss: 0.121753, Val Acc: 0.773196\n",
      "Epoch 15657 - Train Loss: 0.098624, Train Acc: 0.847436 | Val Loss: 0.121751, Val Acc: 0.773196\n",
      "Epoch 15658 - Train Loss: 0.098620, Train Acc: 0.847436 | Val Loss: 0.121748, Val Acc: 0.773196\n",
      "Epoch 15659 - Train Loss: 0.098617, Train Acc: 0.847436 | Val Loss: 0.121746, Val Acc: 0.773196\n",
      "Epoch 15660 - Train Loss: 0.098613, Train Acc: 0.847436 | Val Loss: 0.121744, Val Acc: 0.773196\n",
      "Epoch 15661 - Train Loss: 0.098610, Train Acc: 0.847436 | Val Loss: 0.121742, Val Acc: 0.773196\n",
      "Epoch 15662 - Train Loss: 0.098606, Train Acc: 0.847436 | Val Loss: 0.121739, Val Acc: 0.773196\n",
      "Epoch 15663 - Train Loss: 0.098603, Train Acc: 0.847436 | Val Loss: 0.121737, Val Acc: 0.773196\n",
      "Epoch 15664 - Train Loss: 0.098599, Train Acc: 0.847436 | Val Loss: 0.121735, Val Acc: 0.773196\n",
      "Epoch 15665 - Train Loss: 0.098596, Train Acc: 0.847436 | Val Loss: 0.121733, Val Acc: 0.773196\n",
      "Epoch 15666 - Train Loss: 0.098592, Train Acc: 0.847436 | Val Loss: 0.121730, Val Acc: 0.773196\n",
      "Epoch 15667 - Train Loss: 0.098589, Train Acc: 0.847436 | Val Loss: 0.121728, Val Acc: 0.773196\n",
      "Epoch 15668 - Train Loss: 0.098585, Train Acc: 0.847436 | Val Loss: 0.121726, Val Acc: 0.773196\n",
      "Epoch 15669 - Train Loss: 0.098582, Train Acc: 0.847436 | Val Loss: 0.121724, Val Acc: 0.773196\n",
      "Epoch 15670 - Train Loss: 0.098578, Train Acc: 0.847436 | Val Loss: 0.121722, Val Acc: 0.773196\n",
      "Epoch 15671 - Train Loss: 0.098575, Train Acc: 0.847436 | Val Loss: 0.121719, Val Acc: 0.773196\n",
      "Epoch 15672 - Train Loss: 0.098571, Train Acc: 0.847436 | Val Loss: 0.121717, Val Acc: 0.773196\n",
      "Epoch 15673 - Train Loss: 0.098568, Train Acc: 0.847436 | Val Loss: 0.121715, Val Acc: 0.773196\n",
      "Epoch 15674 - Train Loss: 0.098564, Train Acc: 0.847436 | Val Loss: 0.121713, Val Acc: 0.773196\n",
      "Epoch 15675 - Train Loss: 0.098561, Train Acc: 0.847436 | Val Loss: 0.121710, Val Acc: 0.773196\n",
      "Epoch 15676 - Train Loss: 0.098557, Train Acc: 0.847436 | Val Loss: 0.121708, Val Acc: 0.773196\n",
      "Epoch 15677 - Train Loss: 0.098554, Train Acc: 0.847436 | Val Loss: 0.121706, Val Acc: 0.773196\n",
      "Epoch 15678 - Train Loss: 0.098550, Train Acc: 0.847436 | Val Loss: 0.121704, Val Acc: 0.773196\n",
      "Epoch 15679 - Train Loss: 0.098547, Train Acc: 0.847436 | Val Loss: 0.121701, Val Acc: 0.773196\n",
      "Epoch 15680 - Train Loss: 0.098543, Train Acc: 0.847436 | Val Loss: 0.121699, Val Acc: 0.773196\n",
      "Epoch 15681 - Train Loss: 0.098540, Train Acc: 0.847436 | Val Loss: 0.121697, Val Acc: 0.773196\n",
      "Epoch 15682 - Train Loss: 0.098537, Train Acc: 0.847436 | Val Loss: 0.121695, Val Acc: 0.773196\n",
      "Epoch 15683 - Train Loss: 0.098533, Train Acc: 0.847436 | Val Loss: 0.121692, Val Acc: 0.773196\n",
      "Epoch 15684 - Train Loss: 0.098530, Train Acc: 0.847436 | Val Loss: 0.121690, Val Acc: 0.773196\n",
      "Epoch 15685 - Train Loss: 0.098526, Train Acc: 0.847436 | Val Loss: 0.121688, Val Acc: 0.773196\n",
      "Epoch 15686 - Train Loss: 0.098523, Train Acc: 0.847436 | Val Loss: 0.121686, Val Acc: 0.773196\n",
      "Epoch 15687 - Train Loss: 0.098519, Train Acc: 0.847436 | Val Loss: 0.121683, Val Acc: 0.773196\n",
      "Epoch 15688 - Train Loss: 0.098516, Train Acc: 0.847436 | Val Loss: 0.121681, Val Acc: 0.773196\n",
      "Epoch 15689 - Train Loss: 0.098512, Train Acc: 0.847436 | Val Loss: 0.121679, Val Acc: 0.773196\n",
      "Epoch 15690 - Train Loss: 0.098509, Train Acc: 0.847436 | Val Loss: 0.121677, Val Acc: 0.773196\n",
      "Epoch 15691 - Train Loss: 0.098505, Train Acc: 0.847436 | Val Loss: 0.121675, Val Acc: 0.773196\n",
      "Epoch 15692 - Train Loss: 0.098502, Train Acc: 0.847436 | Val Loss: 0.121672, Val Acc: 0.773196\n",
      "Epoch 15693 - Train Loss: 0.098498, Train Acc: 0.847436 | Val Loss: 0.121670, Val Acc: 0.773196\n",
      "Epoch 15694 - Train Loss: 0.098495, Train Acc: 0.847436 | Val Loss: 0.121668, Val Acc: 0.773196\n",
      "Epoch 15695 - Train Loss: 0.098491, Train Acc: 0.847436 | Val Loss: 0.121666, Val Acc: 0.773196\n",
      "Epoch 15696 - Train Loss: 0.098488, Train Acc: 0.847436 | Val Loss: 0.121663, Val Acc: 0.773196\n",
      "Epoch 15697 - Train Loss: 0.098484, Train Acc: 0.847436 | Val Loss: 0.121661, Val Acc: 0.773196\n",
      "Epoch 15698 - Train Loss: 0.098481, Train Acc: 0.847436 | Val Loss: 0.121659, Val Acc: 0.773196\n",
      "Epoch 15699 - Train Loss: 0.098477, Train Acc: 0.847436 | Val Loss: 0.121657, Val Acc: 0.773196\n",
      "Epoch 15700 - Train Loss: 0.098474, Train Acc: 0.847436 | Val Loss: 0.121654, Val Acc: 0.773196\n",
      "Epoch 15701 - Train Loss: 0.098470, Train Acc: 0.847436 | Val Loss: 0.121652, Val Acc: 0.773196\n",
      "Epoch 15702 - Train Loss: 0.098467, Train Acc: 0.847436 | Val Loss: 0.121650, Val Acc: 0.773196\n",
      "Epoch 15703 - Train Loss: 0.098464, Train Acc: 0.847436 | Val Loss: 0.121648, Val Acc: 0.773196\n",
      "Epoch 15704 - Train Loss: 0.098460, Train Acc: 0.847436 | Val Loss: 0.121646, Val Acc: 0.773196\n",
      "Epoch 15705 - Train Loss: 0.098457, Train Acc: 0.847436 | Val Loss: 0.121643, Val Acc: 0.773196\n",
      "Epoch 15706 - Train Loss: 0.098453, Train Acc: 0.847436 | Val Loss: 0.121641, Val Acc: 0.773196\n",
      "Epoch 15707 - Train Loss: 0.098450, Train Acc: 0.847436 | Val Loss: 0.121639, Val Acc: 0.773196\n",
      "Epoch 15708 - Train Loss: 0.098446, Train Acc: 0.847436 | Val Loss: 0.121637, Val Acc: 0.773196\n",
      "Epoch 15709 - Train Loss: 0.098443, Train Acc: 0.847436 | Val Loss: 0.121634, Val Acc: 0.773196\n",
      "Epoch 15710 - Train Loss: 0.098439, Train Acc: 0.847436 | Val Loss: 0.121632, Val Acc: 0.773196\n",
      "Epoch 15711 - Train Loss: 0.098436, Train Acc: 0.847436 | Val Loss: 0.121630, Val Acc: 0.773196\n",
      "Epoch 15712 - Train Loss: 0.098432, Train Acc: 0.847436 | Val Loss: 0.121628, Val Acc: 0.773196\n",
      "Epoch 15713 - Train Loss: 0.098429, Train Acc: 0.847436 | Val Loss: 0.121625, Val Acc: 0.773196\n",
      "Epoch 15714 - Train Loss: 0.098425, Train Acc: 0.847436 | Val Loss: 0.121623, Val Acc: 0.773196\n",
      "Epoch 15715 - Train Loss: 0.098422, Train Acc: 0.847436 | Val Loss: 0.121621, Val Acc: 0.773196\n",
      "Epoch 15716 - Train Loss: 0.098418, Train Acc: 0.847436 | Val Loss: 0.121619, Val Acc: 0.773196\n",
      "Epoch 15717 - Train Loss: 0.098415, Train Acc: 0.847436 | Val Loss: 0.121617, Val Acc: 0.773196\n",
      "Epoch 15718 - Train Loss: 0.098412, Train Acc: 0.847436 | Val Loss: 0.121614, Val Acc: 0.773196\n",
      "Epoch 15719 - Train Loss: 0.098408, Train Acc: 0.847436 | Val Loss: 0.121612, Val Acc: 0.773196\n",
      "Epoch 15720 - Train Loss: 0.098405, Train Acc: 0.847436 | Val Loss: 0.121610, Val Acc: 0.773196\n",
      "Epoch 15721 - Train Loss: 0.098401, Train Acc: 0.847436 | Val Loss: 0.121608, Val Acc: 0.773196\n",
      "Epoch 15722 - Train Loss: 0.098398, Train Acc: 0.847436 | Val Loss: 0.121605, Val Acc: 0.773196\n",
      "Epoch 15723 - Train Loss: 0.098394, Train Acc: 0.847436 | Val Loss: 0.121603, Val Acc: 0.773196\n",
      "Epoch 15724 - Train Loss: 0.098391, Train Acc: 0.847436 | Val Loss: 0.121601, Val Acc: 0.773196\n",
      "Epoch 15725 - Train Loss: 0.098387, Train Acc: 0.847436 | Val Loss: 0.121599, Val Acc: 0.773196\n",
      "Epoch 15726 - Train Loss: 0.098384, Train Acc: 0.847436 | Val Loss: 0.121597, Val Acc: 0.773196\n",
      "Epoch 15727 - Train Loss: 0.098380, Train Acc: 0.847436 | Val Loss: 0.121594, Val Acc: 0.773196\n",
      "Epoch 15728 - Train Loss: 0.098377, Train Acc: 0.847436 | Val Loss: 0.121592, Val Acc: 0.773196\n",
      "Epoch 15729 - Train Loss: 0.098374, Train Acc: 0.847436 | Val Loss: 0.121590, Val Acc: 0.773196\n",
      "Epoch 15730 - Train Loss: 0.098370, Train Acc: 0.847436 | Val Loss: 0.121588, Val Acc: 0.773196\n",
      "Epoch 15731 - Train Loss: 0.098367, Train Acc: 0.847436 | Val Loss: 0.121585, Val Acc: 0.773196\n",
      "Epoch 15732 - Train Loss: 0.098363, Train Acc: 0.847436 | Val Loss: 0.121583, Val Acc: 0.773196\n",
      "Epoch 15733 - Train Loss: 0.098360, Train Acc: 0.847436 | Val Loss: 0.121581, Val Acc: 0.773196\n",
      "Epoch 15734 - Train Loss: 0.098356, Train Acc: 0.847436 | Val Loss: 0.121579, Val Acc: 0.773196\n",
      "Epoch 15735 - Train Loss: 0.098353, Train Acc: 0.847436 | Val Loss: 0.121577, Val Acc: 0.773196\n",
      "Epoch 15736 - Train Loss: 0.098349, Train Acc: 0.847436 | Val Loss: 0.121574, Val Acc: 0.773196\n",
      "Epoch 15737 - Train Loss: 0.098346, Train Acc: 0.847436 | Val Loss: 0.121572, Val Acc: 0.773196\n",
      "Epoch 15738 - Train Loss: 0.098342, Train Acc: 0.847436 | Val Loss: 0.121570, Val Acc: 0.773196\n",
      "Epoch 15739 - Train Loss: 0.098339, Train Acc: 0.847436 | Val Loss: 0.121568, Val Acc: 0.773196\n",
      "Epoch 15740 - Train Loss: 0.098335, Train Acc: 0.847436 | Val Loss: 0.121566, Val Acc: 0.773196\n",
      "Epoch 15741 - Train Loss: 0.098332, Train Acc: 0.847436 | Val Loss: 0.121563, Val Acc: 0.773196\n",
      "Epoch 15742 - Train Loss: 0.098329, Train Acc: 0.847436 | Val Loss: 0.121561, Val Acc: 0.773196\n",
      "Epoch 15743 - Train Loss: 0.098325, Train Acc: 0.847436 | Val Loss: 0.121559, Val Acc: 0.773196\n",
      "Epoch 15744 - Train Loss: 0.098322, Train Acc: 0.847436 | Val Loss: 0.121557, Val Acc: 0.773196\n",
      "Epoch 15745 - Train Loss: 0.098318, Train Acc: 0.847436 | Val Loss: 0.121555, Val Acc: 0.773196\n",
      "Epoch 15746 - Train Loss: 0.098315, Train Acc: 0.847436 | Val Loss: 0.121552, Val Acc: 0.773196\n",
      "Epoch 15747 - Train Loss: 0.098311, Train Acc: 0.847436 | Val Loss: 0.121550, Val Acc: 0.773196\n",
      "Epoch 15748 - Train Loss: 0.098308, Train Acc: 0.847436 | Val Loss: 0.121548, Val Acc: 0.773196\n",
      "Epoch 15749 - Train Loss: 0.098304, Train Acc: 0.847436 | Val Loss: 0.121546, Val Acc: 0.773196\n",
      "Epoch 15750 - Train Loss: 0.098301, Train Acc: 0.847436 | Val Loss: 0.121543, Val Acc: 0.773196\n",
      "Epoch 15751 - Train Loss: 0.098298, Train Acc: 0.847436 | Val Loss: 0.121541, Val Acc: 0.773196\n",
      "Epoch 15752 - Train Loss: 0.098294, Train Acc: 0.847436 | Val Loss: 0.121539, Val Acc: 0.773196\n",
      "Epoch 15753 - Train Loss: 0.098291, Train Acc: 0.847436 | Val Loss: 0.121537, Val Acc: 0.773196\n",
      "Epoch 15754 - Train Loss: 0.098287, Train Acc: 0.847436 | Val Loss: 0.121535, Val Acc: 0.773196\n",
      "Epoch 15755 - Train Loss: 0.098284, Train Acc: 0.847436 | Val Loss: 0.121532, Val Acc: 0.773196\n",
      "Epoch 15756 - Train Loss: 0.098280, Train Acc: 0.847436 | Val Loss: 0.121530, Val Acc: 0.773196\n",
      "Epoch 15757 - Train Loss: 0.098277, Train Acc: 0.847436 | Val Loss: 0.121528, Val Acc: 0.773196\n",
      "Epoch 15758 - Train Loss: 0.098273, Train Acc: 0.847436 | Val Loss: 0.121526, Val Acc: 0.773196\n",
      "Epoch 15759 - Train Loss: 0.098270, Train Acc: 0.847436 | Val Loss: 0.121524, Val Acc: 0.773196\n",
      "Epoch 15760 - Train Loss: 0.098267, Train Acc: 0.847436 | Val Loss: 0.121521, Val Acc: 0.773196\n",
      "Epoch 15761 - Train Loss: 0.098263, Train Acc: 0.847436 | Val Loss: 0.121519, Val Acc: 0.773196\n",
      "Epoch 15762 - Train Loss: 0.098260, Train Acc: 0.847436 | Val Loss: 0.121517, Val Acc: 0.773196\n",
      "Epoch 15763 - Train Loss: 0.098256, Train Acc: 0.847436 | Val Loss: 0.121515, Val Acc: 0.773196\n",
      "Epoch 15764 - Train Loss: 0.098253, Train Acc: 0.847436 | Val Loss: 0.121513, Val Acc: 0.773196\n",
      "Epoch 15765 - Train Loss: 0.098249, Train Acc: 0.847436 | Val Loss: 0.121510, Val Acc: 0.773196\n",
      "Epoch 15766 - Train Loss: 0.098246, Train Acc: 0.847436 | Val Loss: 0.121508, Val Acc: 0.773196\n",
      "Epoch 15767 - Train Loss: 0.098242, Train Acc: 0.847436 | Val Loss: 0.121506, Val Acc: 0.773196\n",
      "Epoch 15768 - Train Loss: 0.098239, Train Acc: 0.847436 | Val Loss: 0.121504, Val Acc: 0.773196\n",
      "Epoch 15769 - Train Loss: 0.098236, Train Acc: 0.847436 | Val Loss: 0.121502, Val Acc: 0.773196\n",
      "Epoch 15770 - Train Loss: 0.098232, Train Acc: 0.847436 | Val Loss: 0.121499, Val Acc: 0.773196\n",
      "Epoch 15771 - Train Loss: 0.098229, Train Acc: 0.847436 | Val Loss: 0.121497, Val Acc: 0.773196\n",
      "Epoch 15772 - Train Loss: 0.098225, Train Acc: 0.847436 | Val Loss: 0.121495, Val Acc: 0.773196\n",
      "Epoch 15773 - Train Loss: 0.098222, Train Acc: 0.847436 | Val Loss: 0.121493, Val Acc: 0.773196\n",
      "Epoch 15774 - Train Loss: 0.098218, Train Acc: 0.847436 | Val Loss: 0.121491, Val Acc: 0.773196\n",
      "Epoch 15775 - Train Loss: 0.098215, Train Acc: 0.847436 | Val Loss: 0.121488, Val Acc: 0.773196\n",
      "Epoch 15776 - Train Loss: 0.098211, Train Acc: 0.847436 | Val Loss: 0.121486, Val Acc: 0.773196\n",
      "Epoch 15777 - Train Loss: 0.098208, Train Acc: 0.847436 | Val Loss: 0.121484, Val Acc: 0.773196\n",
      "Epoch 15778 - Train Loss: 0.098205, Train Acc: 0.847436 | Val Loss: 0.121482, Val Acc: 0.773196\n",
      "Epoch 15779 - Train Loss: 0.098201, Train Acc: 0.847436 | Val Loss: 0.121480, Val Acc: 0.773196\n",
      "Epoch 15780 - Train Loss: 0.098198, Train Acc: 0.847436 | Val Loss: 0.121477, Val Acc: 0.773196\n",
      "Epoch 15781 - Train Loss: 0.098194, Train Acc: 0.847436 | Val Loss: 0.121475, Val Acc: 0.773196\n",
      "Epoch 15782 - Train Loss: 0.098191, Train Acc: 0.847436 | Val Loss: 0.121473, Val Acc: 0.773196\n",
      "Epoch 15783 - Train Loss: 0.098187, Train Acc: 0.847436 | Val Loss: 0.121471, Val Acc: 0.773196\n",
      "Epoch 15784 - Train Loss: 0.098184, Train Acc: 0.847436 | Val Loss: 0.121469, Val Acc: 0.773196\n",
      "Epoch 15785 - Train Loss: 0.098181, Train Acc: 0.847436 | Val Loss: 0.121466, Val Acc: 0.773196\n",
      "Epoch 15786 - Train Loss: 0.098177, Train Acc: 0.847436 | Val Loss: 0.121464, Val Acc: 0.773196\n",
      "Epoch 15787 - Train Loss: 0.098174, Train Acc: 0.847436 | Val Loss: 0.121462, Val Acc: 0.773196\n",
      "Epoch 15788 - Train Loss: 0.098170, Train Acc: 0.847436 | Val Loss: 0.121460, Val Acc: 0.773196\n",
      "Epoch 15789 - Train Loss: 0.098167, Train Acc: 0.847436 | Val Loss: 0.121458, Val Acc: 0.773196\n",
      "Epoch 15790 - Train Loss: 0.098163, Train Acc: 0.847436 | Val Loss: 0.121455, Val Acc: 0.773196\n",
      "Epoch 15791 - Train Loss: 0.098160, Train Acc: 0.847436 | Val Loss: 0.121453, Val Acc: 0.773196\n",
      "Epoch 15792 - Train Loss: 0.098156, Train Acc: 0.847436 | Val Loss: 0.121451, Val Acc: 0.762887\n",
      "Epoch 15793 - Train Loss: 0.098153, Train Acc: 0.847436 | Val Loss: 0.121449, Val Acc: 0.762887\n",
      "Epoch 15794 - Train Loss: 0.098150, Train Acc: 0.847436 | Val Loss: 0.121447, Val Acc: 0.762887\n",
      "Epoch 15795 - Train Loss: 0.098146, Train Acc: 0.847436 | Val Loss: 0.121444, Val Acc: 0.762887\n",
      "Epoch 15796 - Train Loss: 0.098143, Train Acc: 0.847436 | Val Loss: 0.121442, Val Acc: 0.762887\n",
      "Epoch 15797 - Train Loss: 0.098139, Train Acc: 0.847436 | Val Loss: 0.121440, Val Acc: 0.762887\n",
      "Epoch 15798 - Train Loss: 0.098136, Train Acc: 0.847436 | Val Loss: 0.121438, Val Acc: 0.762887\n",
      "Epoch 15799 - Train Loss: 0.098132, Train Acc: 0.847436 | Val Loss: 0.121436, Val Acc: 0.762887\n",
      "Epoch 15800 - Train Loss: 0.098129, Train Acc: 0.847436 | Val Loss: 0.121434, Val Acc: 0.762887\n",
      "Epoch 15801 - Train Loss: 0.098126, Train Acc: 0.847436 | Val Loss: 0.121431, Val Acc: 0.762887\n",
      "Epoch 15802 - Train Loss: 0.098122, Train Acc: 0.847436 | Val Loss: 0.121429, Val Acc: 0.762887\n",
      "Epoch 15803 - Train Loss: 0.098119, Train Acc: 0.847436 | Val Loss: 0.121427, Val Acc: 0.762887\n",
      "Epoch 15804 - Train Loss: 0.098115, Train Acc: 0.847436 | Val Loss: 0.121425, Val Acc: 0.762887\n",
      "Epoch 15805 - Train Loss: 0.098112, Train Acc: 0.847436 | Val Loss: 0.121423, Val Acc: 0.762887\n",
      "Epoch 15806 - Train Loss: 0.098108, Train Acc: 0.847436 | Val Loss: 0.121420, Val Acc: 0.762887\n",
      "Epoch 15807 - Train Loss: 0.098105, Train Acc: 0.847436 | Val Loss: 0.121418, Val Acc: 0.762887\n",
      "Epoch 15808 - Train Loss: 0.098102, Train Acc: 0.847436 | Val Loss: 0.121416, Val Acc: 0.762887\n",
      "Epoch 15809 - Train Loss: 0.098098, Train Acc: 0.847436 | Val Loss: 0.121414, Val Acc: 0.762887\n",
      "Epoch 15810 - Train Loss: 0.098095, Train Acc: 0.847436 | Val Loss: 0.121412, Val Acc: 0.762887\n",
      "Epoch 15811 - Train Loss: 0.098091, Train Acc: 0.847436 | Val Loss: 0.121409, Val Acc: 0.762887\n",
      "Epoch 15812 - Train Loss: 0.098088, Train Acc: 0.847436 | Val Loss: 0.121407, Val Acc: 0.762887\n",
      "Epoch 15813 - Train Loss: 0.098085, Train Acc: 0.847436 | Val Loss: 0.121405, Val Acc: 0.762887\n",
      "Epoch 15814 - Train Loss: 0.098081, Train Acc: 0.847436 | Val Loss: 0.121403, Val Acc: 0.762887\n",
      "Epoch 15815 - Train Loss: 0.098078, Train Acc: 0.847436 | Val Loss: 0.121401, Val Acc: 0.762887\n",
      "Epoch 15816 - Train Loss: 0.098074, Train Acc: 0.847436 | Val Loss: 0.121399, Val Acc: 0.762887\n",
      "Epoch 15817 - Train Loss: 0.098071, Train Acc: 0.847436 | Val Loss: 0.121396, Val Acc: 0.762887\n",
      "Epoch 15818 - Train Loss: 0.098067, Train Acc: 0.847436 | Val Loss: 0.121394, Val Acc: 0.762887\n",
      "Epoch 15819 - Train Loss: 0.098064, Train Acc: 0.847436 | Val Loss: 0.121392, Val Acc: 0.762887\n",
      "Epoch 15820 - Train Loss: 0.098061, Train Acc: 0.847436 | Val Loss: 0.121390, Val Acc: 0.762887\n",
      "Epoch 15821 - Train Loss: 0.098057, Train Acc: 0.847436 | Val Loss: 0.121388, Val Acc: 0.762887\n",
      "Epoch 15822 - Train Loss: 0.098054, Train Acc: 0.847436 | Val Loss: 0.121385, Val Acc: 0.762887\n",
      "Epoch 15823 - Train Loss: 0.098050, Train Acc: 0.847436 | Val Loss: 0.121383, Val Acc: 0.762887\n",
      "Epoch 15824 - Train Loss: 0.098047, Train Acc: 0.847436 | Val Loss: 0.121381, Val Acc: 0.762887\n",
      "Epoch 15825 - Train Loss: 0.098043, Train Acc: 0.847436 | Val Loss: 0.121379, Val Acc: 0.762887\n",
      "Epoch 15826 - Train Loss: 0.098040, Train Acc: 0.847436 | Val Loss: 0.121377, Val Acc: 0.762887\n",
      "Epoch 15827 - Train Loss: 0.098037, Train Acc: 0.847436 | Val Loss: 0.121375, Val Acc: 0.762887\n",
      "Epoch 15828 - Train Loss: 0.098033, Train Acc: 0.847436 | Val Loss: 0.121372, Val Acc: 0.762887\n",
      "Epoch 15829 - Train Loss: 0.098030, Train Acc: 0.847436 | Val Loss: 0.121370, Val Acc: 0.762887\n",
      "Epoch 15830 - Train Loss: 0.098026, Train Acc: 0.847436 | Val Loss: 0.121368, Val Acc: 0.762887\n",
      "Epoch 15831 - Train Loss: 0.098023, Train Acc: 0.847436 | Val Loss: 0.121366, Val Acc: 0.762887\n",
      "Epoch 15832 - Train Loss: 0.098020, Train Acc: 0.847436 | Val Loss: 0.121364, Val Acc: 0.762887\n",
      "Epoch 15833 - Train Loss: 0.098016, Train Acc: 0.847436 | Val Loss: 0.121362, Val Acc: 0.762887\n",
      "Epoch 15834 - Train Loss: 0.098013, Train Acc: 0.847436 | Val Loss: 0.121359, Val Acc: 0.762887\n",
      "Epoch 15835 - Train Loss: 0.098009, Train Acc: 0.847436 | Val Loss: 0.121357, Val Acc: 0.762887\n",
      "Epoch 15836 - Train Loss: 0.098006, Train Acc: 0.847436 | Val Loss: 0.121355, Val Acc: 0.762887\n",
      "Epoch 15837 - Train Loss: 0.098002, Train Acc: 0.847436 | Val Loss: 0.121353, Val Acc: 0.773196\n",
      "Epoch 15838 - Train Loss: 0.097999, Train Acc: 0.847436 | Val Loss: 0.121351, Val Acc: 0.773196\n",
      "Epoch 15839 - Train Loss: 0.097996, Train Acc: 0.847436 | Val Loss: 0.121348, Val Acc: 0.773196\n",
      "Epoch 15840 - Train Loss: 0.097992, Train Acc: 0.847436 | Val Loss: 0.121346, Val Acc: 0.773196\n",
      "Epoch 15841 - Train Loss: 0.097989, Train Acc: 0.847436 | Val Loss: 0.121344, Val Acc: 0.773196\n",
      "Epoch 15842 - Train Loss: 0.097985, Train Acc: 0.847436 | Val Loss: 0.121342, Val Acc: 0.773196\n",
      "Epoch 15843 - Train Loss: 0.097982, Train Acc: 0.847436 | Val Loss: 0.121340, Val Acc: 0.773196\n",
      "Epoch 15844 - Train Loss: 0.097979, Train Acc: 0.847436 | Val Loss: 0.121338, Val Acc: 0.773196\n",
      "Epoch 15845 - Train Loss: 0.097975, Train Acc: 0.847436 | Val Loss: 0.121335, Val Acc: 0.773196\n",
      "Epoch 15846 - Train Loss: 0.097972, Train Acc: 0.847436 | Val Loss: 0.121333, Val Acc: 0.773196\n",
      "Epoch 15847 - Train Loss: 0.097968, Train Acc: 0.847436 | Val Loss: 0.121331, Val Acc: 0.773196\n",
      "Epoch 15848 - Train Loss: 0.097965, Train Acc: 0.847436 | Val Loss: 0.121329, Val Acc: 0.773196\n",
      "Epoch 15849 - Train Loss: 0.097962, Train Acc: 0.847436 | Val Loss: 0.121327, Val Acc: 0.773196\n",
      "Epoch 15850 - Train Loss: 0.097958, Train Acc: 0.847436 | Val Loss: 0.121325, Val Acc: 0.773196\n",
      "Epoch 15851 - Train Loss: 0.097955, Train Acc: 0.847436 | Val Loss: 0.121322, Val Acc: 0.773196\n",
      "Epoch 15852 - Train Loss: 0.097951, Train Acc: 0.847436 | Val Loss: 0.121320, Val Acc: 0.773196\n",
      "Epoch 15853 - Train Loss: 0.097948, Train Acc: 0.847436 | Val Loss: 0.121318, Val Acc: 0.773196\n",
      "Epoch 15854 - Train Loss: 0.097945, Train Acc: 0.847436 | Val Loss: 0.121316, Val Acc: 0.773196\n",
      "Epoch 15855 - Train Loss: 0.097941, Train Acc: 0.847436 | Val Loss: 0.121314, Val Acc: 0.773196\n",
      "Epoch 15856 - Train Loss: 0.097938, Train Acc: 0.847436 | Val Loss: 0.121312, Val Acc: 0.773196\n",
      "Epoch 15857 - Train Loss: 0.097934, Train Acc: 0.847436 | Val Loss: 0.121309, Val Acc: 0.773196\n",
      "Epoch 15858 - Train Loss: 0.097931, Train Acc: 0.847436 | Val Loss: 0.121307, Val Acc: 0.773196\n",
      "Epoch 15859 - Train Loss: 0.097928, Train Acc: 0.847436 | Val Loss: 0.121305, Val Acc: 0.773196\n",
      "Epoch 15860 - Train Loss: 0.097924, Train Acc: 0.847436 | Val Loss: 0.121303, Val Acc: 0.773196\n",
      "Epoch 15861 - Train Loss: 0.097921, Train Acc: 0.847436 | Val Loss: 0.121301, Val Acc: 0.773196\n",
      "Epoch 15862 - Train Loss: 0.097917, Train Acc: 0.847436 | Val Loss: 0.121299, Val Acc: 0.773196\n",
      "Epoch 15863 - Train Loss: 0.097914, Train Acc: 0.847436 | Val Loss: 0.121296, Val Acc: 0.773196\n",
      "Epoch 15864 - Train Loss: 0.097910, Train Acc: 0.847436 | Val Loss: 0.121294, Val Acc: 0.773196\n",
      "Epoch 15865 - Train Loss: 0.097907, Train Acc: 0.847436 | Val Loss: 0.121292, Val Acc: 0.773196\n",
      "Epoch 15866 - Train Loss: 0.097904, Train Acc: 0.847436 | Val Loss: 0.121290, Val Acc: 0.773196\n",
      "Epoch 15867 - Train Loss: 0.097900, Train Acc: 0.847436 | Val Loss: 0.121288, Val Acc: 0.773196\n",
      "Epoch 15868 - Train Loss: 0.097897, Train Acc: 0.847436 | Val Loss: 0.121286, Val Acc: 0.773196\n",
      "Epoch 15869 - Train Loss: 0.097893, Train Acc: 0.847436 | Val Loss: 0.121284, Val Acc: 0.773196\n",
      "Epoch 15870 - Train Loss: 0.097890, Train Acc: 0.847436 | Val Loss: 0.121281, Val Acc: 0.773196\n",
      "Epoch 15871 - Train Loss: 0.097887, Train Acc: 0.847436 | Val Loss: 0.121279, Val Acc: 0.773196\n",
      "Epoch 15872 - Train Loss: 0.097883, Train Acc: 0.847436 | Val Loss: 0.121277, Val Acc: 0.773196\n",
      "Epoch 15873 - Train Loss: 0.097880, Train Acc: 0.847436 | Val Loss: 0.121275, Val Acc: 0.773196\n",
      "Epoch 15874 - Train Loss: 0.097876, Train Acc: 0.847436 | Val Loss: 0.121273, Val Acc: 0.773196\n",
      "Epoch 15875 - Train Loss: 0.097873, Train Acc: 0.847436 | Val Loss: 0.121271, Val Acc: 0.773196\n",
      "Epoch 15876 - Train Loss: 0.097870, Train Acc: 0.847436 | Val Loss: 0.121268, Val Acc: 0.773196\n",
      "Epoch 15877 - Train Loss: 0.097866, Train Acc: 0.847436 | Val Loss: 0.121266, Val Acc: 0.773196\n",
      "Epoch 15878 - Train Loss: 0.097863, Train Acc: 0.847436 | Val Loss: 0.121264, Val Acc: 0.773196\n",
      "Epoch 15879 - Train Loss: 0.097860, Train Acc: 0.847436 | Val Loss: 0.121262, Val Acc: 0.773196\n",
      "Epoch 15880 - Train Loss: 0.097856, Train Acc: 0.847436 | Val Loss: 0.121260, Val Acc: 0.773196\n",
      "Epoch 15881 - Train Loss: 0.097853, Train Acc: 0.847436 | Val Loss: 0.121258, Val Acc: 0.773196\n",
      "Epoch 15882 - Train Loss: 0.097849, Train Acc: 0.847436 | Val Loss: 0.121255, Val Acc: 0.773196\n",
      "Epoch 15883 - Train Loss: 0.097846, Train Acc: 0.847436 | Val Loss: 0.121253, Val Acc: 0.773196\n",
      "Epoch 15884 - Train Loss: 0.097843, Train Acc: 0.847436 | Val Loss: 0.121251, Val Acc: 0.773196\n",
      "Epoch 15885 - Train Loss: 0.097839, Train Acc: 0.847436 | Val Loss: 0.121249, Val Acc: 0.773196\n",
      "Epoch 15886 - Train Loss: 0.097836, Train Acc: 0.847436 | Val Loss: 0.121247, Val Acc: 0.773196\n",
      "Epoch 15887 - Train Loss: 0.097832, Train Acc: 0.847436 | Val Loss: 0.121245, Val Acc: 0.773196\n",
      "Epoch 15888 - Train Loss: 0.097829, Train Acc: 0.847436 | Val Loss: 0.121243, Val Acc: 0.773196\n",
      "Epoch 15889 - Train Loss: 0.097826, Train Acc: 0.847436 | Val Loss: 0.121240, Val Acc: 0.773196\n",
      "Epoch 15890 - Train Loss: 0.097822, Train Acc: 0.847436 | Val Loss: 0.121238, Val Acc: 0.773196\n",
      "Epoch 15891 - Train Loss: 0.097819, Train Acc: 0.847436 | Val Loss: 0.121236, Val Acc: 0.773196\n",
      "Epoch 15892 - Train Loss: 0.097815, Train Acc: 0.847436 | Val Loss: 0.121234, Val Acc: 0.773196\n",
      "Epoch 15893 - Train Loss: 0.097812, Train Acc: 0.847436 | Val Loss: 0.121232, Val Acc: 0.773196\n",
      "Epoch 15894 - Train Loss: 0.097809, Train Acc: 0.847436 | Val Loss: 0.121230, Val Acc: 0.773196\n",
      "Epoch 15895 - Train Loss: 0.097805, Train Acc: 0.847436 | Val Loss: 0.121227, Val Acc: 0.773196\n",
      "Epoch 15896 - Train Loss: 0.097802, Train Acc: 0.847436 | Val Loss: 0.121225, Val Acc: 0.773196\n",
      "Epoch 15897 - Train Loss: 0.097798, Train Acc: 0.847436 | Val Loss: 0.121223, Val Acc: 0.773196\n",
      "Epoch 15898 - Train Loss: 0.097795, Train Acc: 0.847436 | Val Loss: 0.121221, Val Acc: 0.773196\n",
      "Epoch 15899 - Train Loss: 0.097792, Train Acc: 0.847436 | Val Loss: 0.121219, Val Acc: 0.773196\n",
      "Epoch 15900 - Train Loss: 0.097788, Train Acc: 0.847436 | Val Loss: 0.121217, Val Acc: 0.773196\n",
      "Epoch 15901 - Train Loss: 0.097785, Train Acc: 0.847436 | Val Loss: 0.121215, Val Acc: 0.773196\n",
      "Epoch 15902 - Train Loss: 0.097782, Train Acc: 0.847436 | Val Loss: 0.121212, Val Acc: 0.773196\n",
      "Epoch 15903 - Train Loss: 0.097778, Train Acc: 0.847436 | Val Loss: 0.121210, Val Acc: 0.773196\n",
      "Epoch 15904 - Train Loss: 0.097775, Train Acc: 0.847436 | Val Loss: 0.121208, Val Acc: 0.773196\n",
      "Epoch 15905 - Train Loss: 0.097771, Train Acc: 0.847436 | Val Loss: 0.121206, Val Acc: 0.773196\n",
      "Epoch 15906 - Train Loss: 0.097768, Train Acc: 0.847436 | Val Loss: 0.121204, Val Acc: 0.773196\n",
      "Epoch 15907 - Train Loss: 0.097765, Train Acc: 0.847436 | Val Loss: 0.121202, Val Acc: 0.773196\n",
      "Epoch 15908 - Train Loss: 0.097761, Train Acc: 0.847436 | Val Loss: 0.121200, Val Acc: 0.773196\n",
      "Epoch 15909 - Train Loss: 0.097758, Train Acc: 0.847436 | Val Loss: 0.121197, Val Acc: 0.773196\n",
      "Epoch 15910 - Train Loss: 0.097754, Train Acc: 0.847436 | Val Loss: 0.121195, Val Acc: 0.773196\n",
      "Epoch 15911 - Train Loss: 0.097751, Train Acc: 0.847436 | Val Loss: 0.121193, Val Acc: 0.773196\n",
      "Epoch 15912 - Train Loss: 0.097748, Train Acc: 0.847436 | Val Loss: 0.121191, Val Acc: 0.773196\n",
      "Epoch 15913 - Train Loss: 0.097744, Train Acc: 0.847436 | Val Loss: 0.121189, Val Acc: 0.773196\n",
      "Epoch 15914 - Train Loss: 0.097741, Train Acc: 0.847436 | Val Loss: 0.121187, Val Acc: 0.773196\n",
      "Epoch 15915 - Train Loss: 0.097738, Train Acc: 0.847436 | Val Loss: 0.121185, Val Acc: 0.773196\n",
      "Epoch 15916 - Train Loss: 0.097734, Train Acc: 0.847436 | Val Loss: 0.121182, Val Acc: 0.773196\n",
      "Epoch 15917 - Train Loss: 0.097731, Train Acc: 0.847436 | Val Loss: 0.121180, Val Acc: 0.773196\n",
      "Epoch 15918 - Train Loss: 0.097727, Train Acc: 0.847436 | Val Loss: 0.121178, Val Acc: 0.773196\n",
      "Epoch 15919 - Train Loss: 0.097724, Train Acc: 0.847436 | Val Loss: 0.121176, Val Acc: 0.773196\n",
      "Epoch 15920 - Train Loss: 0.097721, Train Acc: 0.847436 | Val Loss: 0.121174, Val Acc: 0.773196\n",
      "Epoch 15921 - Train Loss: 0.097717, Train Acc: 0.847436 | Val Loss: 0.121172, Val Acc: 0.773196\n",
      "Epoch 15922 - Train Loss: 0.097714, Train Acc: 0.847436 | Val Loss: 0.121170, Val Acc: 0.773196\n",
      "Epoch 15923 - Train Loss: 0.097711, Train Acc: 0.847436 | Val Loss: 0.121167, Val Acc: 0.773196\n",
      "Epoch 15924 - Train Loss: 0.097707, Train Acc: 0.847436 | Val Loss: 0.121165, Val Acc: 0.773196\n",
      "Epoch 15925 - Train Loss: 0.097704, Train Acc: 0.847436 | Val Loss: 0.121163, Val Acc: 0.773196\n",
      "Epoch 15926 - Train Loss: 0.097700, Train Acc: 0.847436 | Val Loss: 0.121161, Val Acc: 0.773196\n",
      "Epoch 15927 - Train Loss: 0.097697, Train Acc: 0.847436 | Val Loss: 0.121159, Val Acc: 0.773196\n",
      "Epoch 15928 - Train Loss: 0.097694, Train Acc: 0.847436 | Val Loss: 0.121157, Val Acc: 0.773196\n",
      "Epoch 15929 - Train Loss: 0.097690, Train Acc: 0.847436 | Val Loss: 0.121155, Val Acc: 0.773196\n",
      "Epoch 15930 - Train Loss: 0.097687, Train Acc: 0.847436 | Val Loss: 0.121153, Val Acc: 0.773196\n",
      "Epoch 15931 - Train Loss: 0.097684, Train Acc: 0.847436 | Val Loss: 0.121150, Val Acc: 0.773196\n",
      "Epoch 15932 - Train Loss: 0.097680, Train Acc: 0.847436 | Val Loss: 0.121148, Val Acc: 0.773196\n",
      "Epoch 15933 - Train Loss: 0.097677, Train Acc: 0.847436 | Val Loss: 0.121146, Val Acc: 0.773196\n",
      "Epoch 15934 - Train Loss: 0.097673, Train Acc: 0.847436 | Val Loss: 0.121144, Val Acc: 0.773196\n",
      "Epoch 15935 - Train Loss: 0.097670, Train Acc: 0.847436 | Val Loss: 0.121142, Val Acc: 0.773196\n",
      "Epoch 15936 - Train Loss: 0.097667, Train Acc: 0.847436 | Val Loss: 0.121140, Val Acc: 0.773196\n",
      "Epoch 15937 - Train Loss: 0.097663, Train Acc: 0.847436 | Val Loss: 0.121138, Val Acc: 0.773196\n",
      "Epoch 15938 - Train Loss: 0.097660, Train Acc: 0.847436 | Val Loss: 0.121135, Val Acc: 0.773196\n",
      "Epoch 15939 - Train Loss: 0.097657, Train Acc: 0.847436 | Val Loss: 0.121133, Val Acc: 0.773196\n",
      "Epoch 15940 - Train Loss: 0.097653, Train Acc: 0.847436 | Val Loss: 0.121131, Val Acc: 0.773196\n",
      "Epoch 15941 - Train Loss: 0.097650, Train Acc: 0.847436 | Val Loss: 0.121129, Val Acc: 0.773196\n",
      "Epoch 15942 - Train Loss: 0.097646, Train Acc: 0.847436 | Val Loss: 0.121127, Val Acc: 0.773196\n",
      "Epoch 15943 - Train Loss: 0.097643, Train Acc: 0.847436 | Val Loss: 0.121125, Val Acc: 0.773196\n",
      "Epoch 15944 - Train Loss: 0.097640, Train Acc: 0.847436 | Val Loss: 0.121123, Val Acc: 0.773196\n",
      "Epoch 15945 - Train Loss: 0.097636, Train Acc: 0.847436 | Val Loss: 0.121121, Val Acc: 0.773196\n",
      "Epoch 15946 - Train Loss: 0.097633, Train Acc: 0.847436 | Val Loss: 0.121118, Val Acc: 0.773196\n",
      "Epoch 15947 - Train Loss: 0.097630, Train Acc: 0.847436 | Val Loss: 0.121116, Val Acc: 0.773196\n",
      "Epoch 15948 - Train Loss: 0.097626, Train Acc: 0.847436 | Val Loss: 0.121114, Val Acc: 0.773196\n",
      "Epoch 15949 - Train Loss: 0.097623, Train Acc: 0.847436 | Val Loss: 0.121112, Val Acc: 0.773196\n",
      "Epoch 15950 - Train Loss: 0.097619, Train Acc: 0.847436 | Val Loss: 0.121110, Val Acc: 0.773196\n",
      "Epoch 15951 - Train Loss: 0.097616, Train Acc: 0.847436 | Val Loss: 0.121108, Val Acc: 0.773196\n",
      "Epoch 15952 - Train Loss: 0.097613, Train Acc: 0.847436 | Val Loss: 0.121106, Val Acc: 0.773196\n",
      "Epoch 15953 - Train Loss: 0.097609, Train Acc: 0.847436 | Val Loss: 0.121104, Val Acc: 0.773196\n",
      "Epoch 15954 - Train Loss: 0.097606, Train Acc: 0.847436 | Val Loss: 0.121101, Val Acc: 0.773196\n",
      "Epoch 15955 - Train Loss: 0.097603, Train Acc: 0.847436 | Val Loss: 0.121099, Val Acc: 0.773196\n",
      "Epoch 15956 - Train Loss: 0.097599, Train Acc: 0.847436 | Val Loss: 0.121097, Val Acc: 0.773196\n",
      "Epoch 15957 - Train Loss: 0.097596, Train Acc: 0.847436 | Val Loss: 0.121095, Val Acc: 0.773196\n",
      "Epoch 15958 - Train Loss: 0.097593, Train Acc: 0.847436 | Val Loss: 0.121093, Val Acc: 0.773196\n",
      "Epoch 15959 - Train Loss: 0.097589, Train Acc: 0.847436 | Val Loss: 0.121091, Val Acc: 0.773196\n",
      "Epoch 15960 - Train Loss: 0.097586, Train Acc: 0.847436 | Val Loss: 0.121089, Val Acc: 0.773196\n",
      "Epoch 15961 - Train Loss: 0.097582, Train Acc: 0.847436 | Val Loss: 0.121087, Val Acc: 0.773196\n",
      "Epoch 15962 - Train Loss: 0.097579, Train Acc: 0.847436 | Val Loss: 0.121084, Val Acc: 0.773196\n",
      "Epoch 15963 - Train Loss: 0.097576, Train Acc: 0.847436 | Val Loss: 0.121082, Val Acc: 0.773196\n",
      "Epoch 15964 - Train Loss: 0.097572, Train Acc: 0.847436 | Val Loss: 0.121080, Val Acc: 0.773196\n",
      "Epoch 15965 - Train Loss: 0.097569, Train Acc: 0.847436 | Val Loss: 0.121078, Val Acc: 0.773196\n",
      "Epoch 15966 - Train Loss: 0.097566, Train Acc: 0.847436 | Val Loss: 0.121076, Val Acc: 0.773196\n",
      "Epoch 15967 - Train Loss: 0.097562, Train Acc: 0.847436 | Val Loss: 0.121074, Val Acc: 0.773196\n",
      "Epoch 15968 - Train Loss: 0.097559, Train Acc: 0.847436 | Val Loss: 0.121072, Val Acc: 0.773196\n",
      "Epoch 15969 - Train Loss: 0.097556, Train Acc: 0.847436 | Val Loss: 0.121070, Val Acc: 0.773196\n",
      "Epoch 15970 - Train Loss: 0.097552, Train Acc: 0.847436 | Val Loss: 0.121067, Val Acc: 0.773196\n",
      "Epoch 15971 - Train Loss: 0.097549, Train Acc: 0.847436 | Val Loss: 0.121065, Val Acc: 0.773196\n",
      "Epoch 15972 - Train Loss: 0.097546, Train Acc: 0.847436 | Val Loss: 0.121063, Val Acc: 0.773196\n",
      "Epoch 15973 - Train Loss: 0.097542, Train Acc: 0.847436 | Val Loss: 0.121061, Val Acc: 0.773196\n",
      "Epoch 15974 - Train Loss: 0.097539, Train Acc: 0.847436 | Val Loss: 0.121059, Val Acc: 0.773196\n",
      "Epoch 15975 - Train Loss: 0.097535, Train Acc: 0.847436 | Val Loss: 0.121057, Val Acc: 0.773196\n",
      "Epoch 15976 - Train Loss: 0.097532, Train Acc: 0.847436 | Val Loss: 0.121055, Val Acc: 0.773196\n",
      "Epoch 15977 - Train Loss: 0.097529, Train Acc: 0.847436 | Val Loss: 0.121053, Val Acc: 0.773196\n",
      "Epoch 15978 - Train Loss: 0.097525, Train Acc: 0.847436 | Val Loss: 0.121050, Val Acc: 0.773196\n",
      "Epoch 15979 - Train Loss: 0.097522, Train Acc: 0.847436 | Val Loss: 0.121048, Val Acc: 0.773196\n",
      "Epoch 15980 - Train Loss: 0.097519, Train Acc: 0.847436 | Val Loss: 0.121046, Val Acc: 0.773196\n",
      "Epoch 15981 - Train Loss: 0.097515, Train Acc: 0.847436 | Val Loss: 0.121044, Val Acc: 0.773196\n",
      "Epoch 15982 - Train Loss: 0.097512, Train Acc: 0.847436 | Val Loss: 0.121042, Val Acc: 0.773196\n",
      "Epoch 15983 - Train Loss: 0.097509, Train Acc: 0.847436 | Val Loss: 0.121040, Val Acc: 0.773196\n",
      "Epoch 15984 - Train Loss: 0.097505, Train Acc: 0.847436 | Val Loss: 0.121038, Val Acc: 0.773196\n",
      "Epoch 15985 - Train Loss: 0.097502, Train Acc: 0.847436 | Val Loss: 0.121036, Val Acc: 0.773196\n",
      "Epoch 15986 - Train Loss: 0.097499, Train Acc: 0.847436 | Val Loss: 0.121034, Val Acc: 0.773196\n",
      "Epoch 15987 - Train Loss: 0.097495, Train Acc: 0.847436 | Val Loss: 0.121031, Val Acc: 0.773196\n",
      "Epoch 15988 - Train Loss: 0.097492, Train Acc: 0.847436 | Val Loss: 0.121029, Val Acc: 0.773196\n",
      "Epoch 15989 - Train Loss: 0.097488, Train Acc: 0.847436 | Val Loss: 0.121027, Val Acc: 0.773196\n",
      "Epoch 15990 - Train Loss: 0.097485, Train Acc: 0.847436 | Val Loss: 0.121025, Val Acc: 0.773196\n",
      "Epoch 15991 - Train Loss: 0.097482, Train Acc: 0.847436 | Val Loss: 0.121023, Val Acc: 0.773196\n",
      "Epoch 15992 - Train Loss: 0.097478, Train Acc: 0.847436 | Val Loss: 0.121021, Val Acc: 0.773196\n",
      "Epoch 15993 - Train Loss: 0.097475, Train Acc: 0.847436 | Val Loss: 0.121019, Val Acc: 0.773196\n",
      "Epoch 15994 - Train Loss: 0.097472, Train Acc: 0.847436 | Val Loss: 0.121017, Val Acc: 0.773196\n",
      "Epoch 15995 - Train Loss: 0.097468, Train Acc: 0.847436 | Val Loss: 0.121015, Val Acc: 0.773196\n",
      "Epoch 15996 - Train Loss: 0.097465, Train Acc: 0.847436 | Val Loss: 0.121012, Val Acc: 0.773196\n",
      "Epoch 15997 - Train Loss: 0.097462, Train Acc: 0.847436 | Val Loss: 0.121010, Val Acc: 0.773196\n",
      "Epoch 15998 - Train Loss: 0.097458, Train Acc: 0.847436 | Val Loss: 0.121008, Val Acc: 0.773196\n",
      "Epoch 15999 - Train Loss: 0.097455, Train Acc: 0.847436 | Val Loss: 0.121006, Val Acc: 0.773196\n",
      "Epoch 16000 - Train Loss: 0.097452, Train Acc: 0.847436 | Val Loss: 0.121004, Val Acc: 0.773196\n",
      "Epoch 16001 - Train Loss: 0.097448, Train Acc: 0.847436 | Val Loss: 0.121002, Val Acc: 0.773196\n",
      "Epoch 16002 - Train Loss: 0.097445, Train Acc: 0.847436 | Val Loss: 0.121000, Val Acc: 0.773196\n",
      "Epoch 16003 - Train Loss: 0.097442, Train Acc: 0.847436 | Val Loss: 0.120998, Val Acc: 0.773196\n",
      "Epoch 16004 - Train Loss: 0.097438, Train Acc: 0.847436 | Val Loss: 0.120996, Val Acc: 0.773196\n",
      "Epoch 16005 - Train Loss: 0.097435, Train Acc: 0.847436 | Val Loss: 0.120993, Val Acc: 0.773196\n",
      "Epoch 16006 - Train Loss: 0.097432, Train Acc: 0.847436 | Val Loss: 0.120991, Val Acc: 0.773196\n",
      "Epoch 16007 - Train Loss: 0.097428, Train Acc: 0.847436 | Val Loss: 0.120989, Val Acc: 0.773196\n",
      "Epoch 16008 - Train Loss: 0.097425, Train Acc: 0.847436 | Val Loss: 0.120987, Val Acc: 0.773196\n",
      "Epoch 16009 - Train Loss: 0.097422, Train Acc: 0.847436 | Val Loss: 0.120985, Val Acc: 0.773196\n",
      "Epoch 16010 - Train Loss: 0.097418, Train Acc: 0.847436 | Val Loss: 0.120983, Val Acc: 0.773196\n",
      "Epoch 16011 - Train Loss: 0.097415, Train Acc: 0.847436 | Val Loss: 0.120981, Val Acc: 0.773196\n",
      "Epoch 16012 - Train Loss: 0.097412, Train Acc: 0.847436 | Val Loss: 0.120979, Val Acc: 0.773196\n",
      "Epoch 16013 - Train Loss: 0.097408, Train Acc: 0.847436 | Val Loss: 0.120977, Val Acc: 0.773196\n",
      "Epoch 16014 - Train Loss: 0.097405, Train Acc: 0.847436 | Val Loss: 0.120975, Val Acc: 0.773196\n",
      "Epoch 16015 - Train Loss: 0.097401, Train Acc: 0.847436 | Val Loss: 0.120972, Val Acc: 0.773196\n",
      "Epoch 16016 - Train Loss: 0.097398, Train Acc: 0.847436 | Val Loss: 0.120970, Val Acc: 0.773196\n",
      "Epoch 16017 - Train Loss: 0.097395, Train Acc: 0.847436 | Val Loss: 0.120968, Val Acc: 0.773196\n",
      "Epoch 16018 - Train Loss: 0.097391, Train Acc: 0.847436 | Val Loss: 0.120966, Val Acc: 0.773196\n",
      "Epoch 16019 - Train Loss: 0.097388, Train Acc: 0.847436 | Val Loss: 0.120964, Val Acc: 0.773196\n",
      "Epoch 16020 - Train Loss: 0.097385, Train Acc: 0.847436 | Val Loss: 0.120962, Val Acc: 0.773196\n",
      "Epoch 16021 - Train Loss: 0.097381, Train Acc: 0.847436 | Val Loss: 0.120960, Val Acc: 0.773196\n",
      "Epoch 16022 - Train Loss: 0.097378, Train Acc: 0.847436 | Val Loss: 0.120958, Val Acc: 0.773196\n",
      "Epoch 16023 - Train Loss: 0.097375, Train Acc: 0.847436 | Val Loss: 0.120956, Val Acc: 0.773196\n",
      "Epoch 16024 - Train Loss: 0.097371, Train Acc: 0.847436 | Val Loss: 0.120954, Val Acc: 0.773196\n",
      "Epoch 16025 - Train Loss: 0.097368, Train Acc: 0.847436 | Val Loss: 0.120951, Val Acc: 0.773196\n",
      "Epoch 16026 - Train Loss: 0.097365, Train Acc: 0.847436 | Val Loss: 0.120949, Val Acc: 0.773196\n",
      "Epoch 16027 - Train Loss: 0.097361, Train Acc: 0.847436 | Val Loss: 0.120947, Val Acc: 0.773196\n",
      "Epoch 16028 - Train Loss: 0.097358, Train Acc: 0.847436 | Val Loss: 0.120945, Val Acc: 0.773196\n",
      "Epoch 16029 - Train Loss: 0.097355, Train Acc: 0.847436 | Val Loss: 0.120943, Val Acc: 0.773196\n",
      "Epoch 16030 - Train Loss: 0.097351, Train Acc: 0.847436 | Val Loss: 0.120941, Val Acc: 0.773196\n",
      "Epoch 16031 - Train Loss: 0.097348, Train Acc: 0.847436 | Val Loss: 0.120939, Val Acc: 0.773196\n",
      "Epoch 16032 - Train Loss: 0.097345, Train Acc: 0.847436 | Val Loss: 0.120937, Val Acc: 0.773196\n",
      "Epoch 16033 - Train Loss: 0.097341, Train Acc: 0.847436 | Val Loss: 0.120935, Val Acc: 0.773196\n",
      "Epoch 16034 - Train Loss: 0.097338, Train Acc: 0.847436 | Val Loss: 0.120933, Val Acc: 0.773196\n",
      "Epoch 16035 - Train Loss: 0.097335, Train Acc: 0.847436 | Val Loss: 0.120931, Val Acc: 0.773196\n",
      "Epoch 16036 - Train Loss: 0.097331, Train Acc: 0.847436 | Val Loss: 0.120928, Val Acc: 0.773196\n",
      "Epoch 16037 - Train Loss: 0.097328, Train Acc: 0.847436 | Val Loss: 0.120926, Val Acc: 0.773196\n",
      "Epoch 16038 - Train Loss: 0.097325, Train Acc: 0.847436 | Val Loss: 0.120924, Val Acc: 0.773196\n",
      "Epoch 16039 - Train Loss: 0.097321, Train Acc: 0.847436 | Val Loss: 0.120922, Val Acc: 0.773196\n",
      "Epoch 16040 - Train Loss: 0.097318, Train Acc: 0.847436 | Val Loss: 0.120920, Val Acc: 0.773196\n",
      "Epoch 16041 - Train Loss: 0.097315, Train Acc: 0.847436 | Val Loss: 0.120918, Val Acc: 0.773196\n",
      "Epoch 16042 - Train Loss: 0.097311, Train Acc: 0.847436 | Val Loss: 0.120916, Val Acc: 0.773196\n",
      "Epoch 16043 - Train Loss: 0.097308, Train Acc: 0.847436 | Val Loss: 0.120914, Val Acc: 0.773196\n",
      "Epoch 16044 - Train Loss: 0.097305, Train Acc: 0.847436 | Val Loss: 0.120912, Val Acc: 0.773196\n",
      "Epoch 16045 - Train Loss: 0.097301, Train Acc: 0.847436 | Val Loss: 0.120910, Val Acc: 0.773196\n",
      "Epoch 16046 - Train Loss: 0.097298, Train Acc: 0.847436 | Val Loss: 0.120908, Val Acc: 0.773196\n",
      "Epoch 16047 - Train Loss: 0.097295, Train Acc: 0.847436 | Val Loss: 0.120905, Val Acc: 0.773196\n",
      "Epoch 16048 - Train Loss: 0.097291, Train Acc: 0.847436 | Val Loss: 0.120903, Val Acc: 0.773196\n",
      "Epoch 16049 - Train Loss: 0.097288, Train Acc: 0.847436 | Val Loss: 0.120901, Val Acc: 0.773196\n",
      "Epoch 16050 - Train Loss: 0.097285, Train Acc: 0.847436 | Val Loss: 0.120899, Val Acc: 0.773196\n",
      "Epoch 16051 - Train Loss: 0.097282, Train Acc: 0.847436 | Val Loss: 0.120897, Val Acc: 0.773196\n",
      "Epoch 16052 - Train Loss: 0.097278, Train Acc: 0.847436 | Val Loss: 0.120895, Val Acc: 0.773196\n",
      "Epoch 16053 - Train Loss: 0.097275, Train Acc: 0.847436 | Val Loss: 0.120893, Val Acc: 0.773196\n",
      "Epoch 16054 - Train Loss: 0.097272, Train Acc: 0.847436 | Val Loss: 0.120891, Val Acc: 0.773196\n",
      "Epoch 16055 - Train Loss: 0.097268, Train Acc: 0.847436 | Val Loss: 0.120889, Val Acc: 0.773196\n",
      "Epoch 16056 - Train Loss: 0.097265, Train Acc: 0.847436 | Val Loss: 0.120887, Val Acc: 0.773196\n",
      "Epoch 16057 - Train Loss: 0.097262, Train Acc: 0.847436 | Val Loss: 0.120885, Val Acc: 0.773196\n",
      "Epoch 16058 - Train Loss: 0.097258, Train Acc: 0.847436 | Val Loss: 0.120882, Val Acc: 0.773196\n",
      "Epoch 16059 - Train Loss: 0.097255, Train Acc: 0.847436 | Val Loss: 0.120880, Val Acc: 0.773196\n",
      "Epoch 16060 - Train Loss: 0.097252, Train Acc: 0.847436 | Val Loss: 0.120878, Val Acc: 0.773196\n",
      "Epoch 16061 - Train Loss: 0.097248, Train Acc: 0.847436 | Val Loss: 0.120876, Val Acc: 0.773196\n",
      "Epoch 16062 - Train Loss: 0.097245, Train Acc: 0.847436 | Val Loss: 0.120874, Val Acc: 0.773196\n",
      "Epoch 16063 - Train Loss: 0.097242, Train Acc: 0.847436 | Val Loss: 0.120872, Val Acc: 0.773196\n",
      "Epoch 16064 - Train Loss: 0.097238, Train Acc: 0.847436 | Val Loss: 0.120870, Val Acc: 0.773196\n",
      "Epoch 16065 - Train Loss: 0.097235, Train Acc: 0.847436 | Val Loss: 0.120868, Val Acc: 0.773196\n",
      "Epoch 16066 - Train Loss: 0.097232, Train Acc: 0.847436 | Val Loss: 0.120866, Val Acc: 0.773196\n",
      "Epoch 16067 - Train Loss: 0.097228, Train Acc: 0.847436 | Val Loss: 0.120864, Val Acc: 0.773196\n",
      "Epoch 16068 - Train Loss: 0.097225, Train Acc: 0.847436 | Val Loss: 0.120862, Val Acc: 0.773196\n",
      "Epoch 16069 - Train Loss: 0.097222, Train Acc: 0.847436 | Val Loss: 0.120860, Val Acc: 0.773196\n",
      "Epoch 16070 - Train Loss: 0.097218, Train Acc: 0.847436 | Val Loss: 0.120857, Val Acc: 0.773196\n",
      "Epoch 16071 - Train Loss: 0.097215, Train Acc: 0.847436 | Val Loss: 0.120855, Val Acc: 0.773196\n",
      "Epoch 16072 - Train Loss: 0.097212, Train Acc: 0.847436 | Val Loss: 0.120853, Val Acc: 0.773196\n",
      "Epoch 16073 - Train Loss: 0.097208, Train Acc: 0.847436 | Val Loss: 0.120851, Val Acc: 0.773196\n",
      "Epoch 16074 - Train Loss: 0.097205, Train Acc: 0.847436 | Val Loss: 0.120849, Val Acc: 0.773196\n",
      "Epoch 16075 - Train Loss: 0.097202, Train Acc: 0.847436 | Val Loss: 0.120847, Val Acc: 0.773196\n",
      "Epoch 16076 - Train Loss: 0.097198, Train Acc: 0.847436 | Val Loss: 0.120845, Val Acc: 0.773196\n",
      "Epoch 16077 - Train Loss: 0.097195, Train Acc: 0.847436 | Val Loss: 0.120843, Val Acc: 0.773196\n",
      "Epoch 16078 - Train Loss: 0.097192, Train Acc: 0.847436 | Val Loss: 0.120841, Val Acc: 0.773196\n",
      "Epoch 16079 - Train Loss: 0.097189, Train Acc: 0.847436 | Val Loss: 0.120839, Val Acc: 0.773196\n",
      "Epoch 16080 - Train Loss: 0.097185, Train Acc: 0.847436 | Val Loss: 0.120837, Val Acc: 0.773196\n",
      "Epoch 16081 - Train Loss: 0.097182, Train Acc: 0.848718 | Val Loss: 0.120835, Val Acc: 0.773196\n",
      "Epoch 16082 - Train Loss: 0.097179, Train Acc: 0.848718 | Val Loss: 0.120833, Val Acc: 0.773196\n",
      "Epoch 16083 - Train Loss: 0.097175, Train Acc: 0.848718 | Val Loss: 0.120830, Val Acc: 0.773196\n",
      "Epoch 16084 - Train Loss: 0.097172, Train Acc: 0.848718 | Val Loss: 0.120828, Val Acc: 0.773196\n",
      "Epoch 16085 - Train Loss: 0.097169, Train Acc: 0.848718 | Val Loss: 0.120826, Val Acc: 0.773196\n",
      "Epoch 16086 - Train Loss: 0.097165, Train Acc: 0.848718 | Val Loss: 0.120824, Val Acc: 0.773196\n",
      "Epoch 16087 - Train Loss: 0.097162, Train Acc: 0.848718 | Val Loss: 0.120822, Val Acc: 0.773196\n",
      "Epoch 16088 - Train Loss: 0.097159, Train Acc: 0.848718 | Val Loss: 0.120820, Val Acc: 0.773196\n",
      "Epoch 16089 - Train Loss: 0.097155, Train Acc: 0.848718 | Val Loss: 0.120818, Val Acc: 0.773196\n",
      "Epoch 16090 - Train Loss: 0.097152, Train Acc: 0.848718 | Val Loss: 0.120816, Val Acc: 0.773196\n",
      "Epoch 16091 - Train Loss: 0.097149, Train Acc: 0.848718 | Val Loss: 0.120814, Val Acc: 0.773196\n",
      "Epoch 16092 - Train Loss: 0.097145, Train Acc: 0.848718 | Val Loss: 0.120812, Val Acc: 0.773196\n",
      "Epoch 16093 - Train Loss: 0.097142, Train Acc: 0.848718 | Val Loss: 0.120810, Val Acc: 0.773196\n",
      "Epoch 16094 - Train Loss: 0.097139, Train Acc: 0.848718 | Val Loss: 0.120808, Val Acc: 0.773196\n",
      "Epoch 16095 - Train Loss: 0.097136, Train Acc: 0.848718 | Val Loss: 0.120806, Val Acc: 0.773196\n",
      "Epoch 16096 - Train Loss: 0.097132, Train Acc: 0.848718 | Val Loss: 0.120804, Val Acc: 0.773196\n",
      "Epoch 16097 - Train Loss: 0.097129, Train Acc: 0.848718 | Val Loss: 0.120801, Val Acc: 0.773196\n",
      "Epoch 16098 - Train Loss: 0.097126, Train Acc: 0.848718 | Val Loss: 0.120799, Val Acc: 0.773196\n",
      "Epoch 16099 - Train Loss: 0.097122, Train Acc: 0.848718 | Val Loss: 0.120797, Val Acc: 0.773196\n",
      "Epoch 16100 - Train Loss: 0.097119, Train Acc: 0.848718 | Val Loss: 0.120795, Val Acc: 0.773196\n",
      "Epoch 16101 - Train Loss: 0.097116, Train Acc: 0.848718 | Val Loss: 0.120793, Val Acc: 0.773196\n",
      "Epoch 16102 - Train Loss: 0.097112, Train Acc: 0.848718 | Val Loss: 0.120791, Val Acc: 0.773196\n",
      "Epoch 16103 - Train Loss: 0.097109, Train Acc: 0.848718 | Val Loss: 0.120789, Val Acc: 0.773196\n",
      "Epoch 16104 - Train Loss: 0.097106, Train Acc: 0.848718 | Val Loss: 0.120787, Val Acc: 0.773196\n",
      "Epoch 16105 - Train Loss: 0.097102, Train Acc: 0.848718 | Val Loss: 0.120785, Val Acc: 0.773196\n",
      "Epoch 16106 - Train Loss: 0.097099, Train Acc: 0.848718 | Val Loss: 0.120783, Val Acc: 0.773196\n",
      "Epoch 16107 - Train Loss: 0.097096, Train Acc: 0.848718 | Val Loss: 0.120781, Val Acc: 0.773196\n",
      "Epoch 16108 - Train Loss: 0.097093, Train Acc: 0.848718 | Val Loss: 0.120779, Val Acc: 0.773196\n",
      "Epoch 16109 - Train Loss: 0.097089, Train Acc: 0.848718 | Val Loss: 0.120777, Val Acc: 0.773196\n",
      "Epoch 16110 - Train Loss: 0.097086, Train Acc: 0.848718 | Val Loss: 0.120775, Val Acc: 0.773196\n",
      "Epoch 16111 - Train Loss: 0.097083, Train Acc: 0.848718 | Val Loss: 0.120773, Val Acc: 0.773196\n",
      "Epoch 16112 - Train Loss: 0.097079, Train Acc: 0.848718 | Val Loss: 0.120770, Val Acc: 0.773196\n",
      "Epoch 16113 - Train Loss: 0.097076, Train Acc: 0.848718 | Val Loss: 0.120768, Val Acc: 0.773196\n",
      "Epoch 16114 - Train Loss: 0.097073, Train Acc: 0.848718 | Val Loss: 0.120766, Val Acc: 0.773196\n",
      "Epoch 16115 - Train Loss: 0.097069, Train Acc: 0.848718 | Val Loss: 0.120764, Val Acc: 0.773196\n",
      "Epoch 16116 - Train Loss: 0.097066, Train Acc: 0.848718 | Val Loss: 0.120762, Val Acc: 0.773196\n",
      "Epoch 16117 - Train Loss: 0.097063, Train Acc: 0.848718 | Val Loss: 0.120760, Val Acc: 0.773196\n",
      "Epoch 16118 - Train Loss: 0.097060, Train Acc: 0.848718 | Val Loss: 0.120758, Val Acc: 0.773196\n",
      "Epoch 16119 - Train Loss: 0.097056, Train Acc: 0.848718 | Val Loss: 0.120756, Val Acc: 0.773196\n",
      "Epoch 16120 - Train Loss: 0.097053, Train Acc: 0.848718 | Val Loss: 0.120754, Val Acc: 0.773196\n",
      "Epoch 16121 - Train Loss: 0.097050, Train Acc: 0.848718 | Val Loss: 0.120752, Val Acc: 0.773196\n",
      "Epoch 16122 - Train Loss: 0.097046, Train Acc: 0.848718 | Val Loss: 0.120750, Val Acc: 0.773196\n",
      "Epoch 16123 - Train Loss: 0.097043, Train Acc: 0.848718 | Val Loss: 0.120748, Val Acc: 0.773196\n",
      "Epoch 16124 - Train Loss: 0.097040, Train Acc: 0.848718 | Val Loss: 0.120746, Val Acc: 0.773196\n",
      "Epoch 16125 - Train Loss: 0.097036, Train Acc: 0.848718 | Val Loss: 0.120744, Val Acc: 0.773196\n",
      "Epoch 16126 - Train Loss: 0.097033, Train Acc: 0.848718 | Val Loss: 0.120742, Val Acc: 0.773196\n",
      "Epoch 16127 - Train Loss: 0.097030, Train Acc: 0.848718 | Val Loss: 0.120740, Val Acc: 0.773196\n",
      "Epoch 16128 - Train Loss: 0.097027, Train Acc: 0.848718 | Val Loss: 0.120737, Val Acc: 0.773196\n",
      "Epoch 16129 - Train Loss: 0.097023, Train Acc: 0.848718 | Val Loss: 0.120735, Val Acc: 0.773196\n",
      "Epoch 16130 - Train Loss: 0.097020, Train Acc: 0.848718 | Val Loss: 0.120733, Val Acc: 0.773196\n",
      "Epoch 16131 - Train Loss: 0.097017, Train Acc: 0.848718 | Val Loss: 0.120731, Val Acc: 0.773196\n",
      "Epoch 16132 - Train Loss: 0.097013, Train Acc: 0.848718 | Val Loss: 0.120729, Val Acc: 0.773196\n",
      "Epoch 16133 - Train Loss: 0.097010, Train Acc: 0.848718 | Val Loss: 0.120727, Val Acc: 0.773196\n",
      "Epoch 16134 - Train Loss: 0.097007, Train Acc: 0.848718 | Val Loss: 0.120725, Val Acc: 0.773196\n",
      "Epoch 16135 - Train Loss: 0.097004, Train Acc: 0.848718 | Val Loss: 0.120723, Val Acc: 0.773196\n",
      "Epoch 16136 - Train Loss: 0.097000, Train Acc: 0.848718 | Val Loss: 0.120721, Val Acc: 0.773196\n",
      "Epoch 16137 - Train Loss: 0.096997, Train Acc: 0.848718 | Val Loss: 0.120719, Val Acc: 0.773196\n",
      "Epoch 16138 - Train Loss: 0.096994, Train Acc: 0.848718 | Val Loss: 0.120717, Val Acc: 0.773196\n",
      "Epoch 16139 - Train Loss: 0.096990, Train Acc: 0.848718 | Val Loss: 0.120715, Val Acc: 0.773196\n",
      "Epoch 16140 - Train Loss: 0.096987, Train Acc: 0.848718 | Val Loss: 0.120713, Val Acc: 0.773196\n",
      "Epoch 16141 - Train Loss: 0.096984, Train Acc: 0.848718 | Val Loss: 0.120711, Val Acc: 0.773196\n",
      "Epoch 16142 - Train Loss: 0.096980, Train Acc: 0.848718 | Val Loss: 0.120709, Val Acc: 0.773196\n",
      "Epoch 16143 - Train Loss: 0.096977, Train Acc: 0.848718 | Val Loss: 0.120707, Val Acc: 0.773196\n",
      "Epoch 16144 - Train Loss: 0.096974, Train Acc: 0.848718 | Val Loss: 0.120705, Val Acc: 0.773196\n",
      "Epoch 16145 - Train Loss: 0.096971, Train Acc: 0.848718 | Val Loss: 0.120703, Val Acc: 0.773196\n",
      "Epoch 16146 - Train Loss: 0.096967, Train Acc: 0.848718 | Val Loss: 0.120701, Val Acc: 0.773196\n",
      "Epoch 16147 - Train Loss: 0.096964, Train Acc: 0.848718 | Val Loss: 0.120698, Val Acc: 0.773196\n",
      "Epoch 16148 - Train Loss: 0.096961, Train Acc: 0.848718 | Val Loss: 0.120696, Val Acc: 0.773196\n",
      "Epoch 16149 - Train Loss: 0.096957, Train Acc: 0.848718 | Val Loss: 0.120694, Val Acc: 0.773196\n",
      "Epoch 16150 - Train Loss: 0.096954, Train Acc: 0.848718 | Val Loss: 0.120692, Val Acc: 0.773196\n",
      "Epoch 16151 - Train Loss: 0.096951, Train Acc: 0.848718 | Val Loss: 0.120690, Val Acc: 0.773196\n",
      "Epoch 16152 - Train Loss: 0.096948, Train Acc: 0.848718 | Val Loss: 0.120688, Val Acc: 0.773196\n",
      "Epoch 16153 - Train Loss: 0.096944, Train Acc: 0.848718 | Val Loss: 0.120686, Val Acc: 0.773196\n",
      "Epoch 16154 - Train Loss: 0.096941, Train Acc: 0.848718 | Val Loss: 0.120684, Val Acc: 0.773196\n",
      "Epoch 16155 - Train Loss: 0.096938, Train Acc: 0.848718 | Val Loss: 0.120682, Val Acc: 0.773196\n",
      "Epoch 16156 - Train Loss: 0.096934, Train Acc: 0.848718 | Val Loss: 0.120680, Val Acc: 0.773196\n",
      "Epoch 16157 - Train Loss: 0.096931, Train Acc: 0.848718 | Val Loss: 0.120678, Val Acc: 0.773196\n",
      "Epoch 16158 - Train Loss: 0.096928, Train Acc: 0.848718 | Val Loss: 0.120676, Val Acc: 0.773196\n",
      "Epoch 16159 - Train Loss: 0.096925, Train Acc: 0.848718 | Val Loss: 0.120674, Val Acc: 0.773196\n",
      "Epoch 16160 - Train Loss: 0.096921, Train Acc: 0.848718 | Val Loss: 0.120672, Val Acc: 0.773196\n",
      "Epoch 16161 - Train Loss: 0.096918, Train Acc: 0.848718 | Val Loss: 0.120670, Val Acc: 0.773196\n",
      "Epoch 16162 - Train Loss: 0.096915, Train Acc: 0.848718 | Val Loss: 0.120668, Val Acc: 0.773196\n",
      "Epoch 16163 - Train Loss: 0.096911, Train Acc: 0.848718 | Val Loss: 0.120666, Val Acc: 0.773196\n",
      "Epoch 16164 - Train Loss: 0.096908, Train Acc: 0.848718 | Val Loss: 0.120664, Val Acc: 0.773196\n",
      "Epoch 16165 - Train Loss: 0.096905, Train Acc: 0.848718 | Val Loss: 0.120662, Val Acc: 0.773196\n",
      "Epoch 16166 - Train Loss: 0.096902, Train Acc: 0.848718 | Val Loss: 0.120660, Val Acc: 0.773196\n",
      "Epoch 16167 - Train Loss: 0.096898, Train Acc: 0.848718 | Val Loss: 0.120658, Val Acc: 0.773196\n",
      "Epoch 16168 - Train Loss: 0.096895, Train Acc: 0.848718 | Val Loss: 0.120656, Val Acc: 0.773196\n",
      "Epoch 16169 - Train Loss: 0.096892, Train Acc: 0.848718 | Val Loss: 0.120654, Val Acc: 0.773196\n",
      "Epoch 16170 - Train Loss: 0.096888, Train Acc: 0.848718 | Val Loss: 0.120651, Val Acc: 0.773196\n",
      "Epoch 16171 - Train Loss: 0.096885, Train Acc: 0.848718 | Val Loss: 0.120649, Val Acc: 0.773196\n",
      "Epoch 16172 - Train Loss: 0.096882, Train Acc: 0.848718 | Val Loss: 0.120647, Val Acc: 0.773196\n",
      "Epoch 16173 - Train Loss: 0.096879, Train Acc: 0.848718 | Val Loss: 0.120645, Val Acc: 0.773196\n",
      "Epoch 16174 - Train Loss: 0.096875, Train Acc: 0.848718 | Val Loss: 0.120643, Val Acc: 0.773196\n",
      "Epoch 16175 - Train Loss: 0.096872, Train Acc: 0.848718 | Val Loss: 0.120641, Val Acc: 0.773196\n",
      "Epoch 16176 - Train Loss: 0.096869, Train Acc: 0.848718 | Val Loss: 0.120639, Val Acc: 0.773196\n",
      "Epoch 16177 - Train Loss: 0.096866, Train Acc: 0.848718 | Val Loss: 0.120637, Val Acc: 0.773196\n",
      "Epoch 16178 - Train Loss: 0.096862, Train Acc: 0.848718 | Val Loss: 0.120635, Val Acc: 0.773196\n",
      "Epoch 16179 - Train Loss: 0.096859, Train Acc: 0.848718 | Val Loss: 0.120633, Val Acc: 0.773196\n",
      "Epoch 16180 - Train Loss: 0.096856, Train Acc: 0.848718 | Val Loss: 0.120631, Val Acc: 0.773196\n",
      "Epoch 16181 - Train Loss: 0.096852, Train Acc: 0.848718 | Val Loss: 0.120629, Val Acc: 0.773196\n",
      "Epoch 16182 - Train Loss: 0.096849, Train Acc: 0.848718 | Val Loss: 0.120627, Val Acc: 0.773196\n",
      "Epoch 16183 - Train Loss: 0.096846, Train Acc: 0.848718 | Val Loss: 0.120625, Val Acc: 0.773196\n",
      "Epoch 16184 - Train Loss: 0.096843, Train Acc: 0.848718 | Val Loss: 0.120623, Val Acc: 0.773196\n",
      "Epoch 16185 - Train Loss: 0.096839, Train Acc: 0.848718 | Val Loss: 0.120621, Val Acc: 0.773196\n",
      "Epoch 16186 - Train Loss: 0.096836, Train Acc: 0.848718 | Val Loss: 0.120619, Val Acc: 0.773196\n",
      "Epoch 16187 - Train Loss: 0.096833, Train Acc: 0.848718 | Val Loss: 0.120617, Val Acc: 0.773196\n",
      "Epoch 16188 - Train Loss: 0.096830, Train Acc: 0.848718 | Val Loss: 0.120615, Val Acc: 0.773196\n",
      "Epoch 16189 - Train Loss: 0.096826, Train Acc: 0.848718 | Val Loss: 0.120613, Val Acc: 0.773196\n",
      "Epoch 16190 - Train Loss: 0.096823, Train Acc: 0.848718 | Val Loss: 0.120611, Val Acc: 0.773196\n",
      "Epoch 16191 - Train Loss: 0.096820, Train Acc: 0.848718 | Val Loss: 0.120609, Val Acc: 0.773196\n",
      "Epoch 16192 - Train Loss: 0.096816, Train Acc: 0.848718 | Val Loss: 0.120607, Val Acc: 0.773196\n",
      "Epoch 16193 - Train Loss: 0.096813, Train Acc: 0.848718 | Val Loss: 0.120605, Val Acc: 0.773196\n",
      "Epoch 16194 - Train Loss: 0.096810, Train Acc: 0.848718 | Val Loss: 0.120603, Val Acc: 0.773196\n",
      "Epoch 16195 - Train Loss: 0.096807, Train Acc: 0.848718 | Val Loss: 0.120601, Val Acc: 0.773196\n",
      "Epoch 16196 - Train Loss: 0.096803, Train Acc: 0.848718 | Val Loss: 0.120599, Val Acc: 0.773196\n",
      "Epoch 16197 - Train Loss: 0.096800, Train Acc: 0.848718 | Val Loss: 0.120597, Val Acc: 0.773196\n",
      "Epoch 16198 - Train Loss: 0.096797, Train Acc: 0.848718 | Val Loss: 0.120595, Val Acc: 0.773196\n",
      "Epoch 16199 - Train Loss: 0.096794, Train Acc: 0.848718 | Val Loss: 0.120593, Val Acc: 0.773196\n",
      "Epoch 16200 - Train Loss: 0.096790, Train Acc: 0.848718 | Val Loss: 0.120591, Val Acc: 0.773196\n",
      "Epoch 16201 - Train Loss: 0.096787, Train Acc: 0.848718 | Val Loss: 0.120589, Val Acc: 0.773196\n",
      "Epoch 16202 - Train Loss: 0.096784, Train Acc: 0.848718 | Val Loss: 0.120587, Val Acc: 0.773196\n",
      "Epoch 16203 - Train Loss: 0.096780, Train Acc: 0.848718 | Val Loss: 0.120585, Val Acc: 0.773196\n",
      "Epoch 16204 - Train Loss: 0.096777, Train Acc: 0.848718 | Val Loss: 0.120583, Val Acc: 0.773196\n",
      "Epoch 16205 - Train Loss: 0.096774, Train Acc: 0.848718 | Val Loss: 0.120581, Val Acc: 0.773196\n",
      "Epoch 16206 - Train Loss: 0.096771, Train Acc: 0.848718 | Val Loss: 0.120579, Val Acc: 0.773196\n",
      "Epoch 16207 - Train Loss: 0.096767, Train Acc: 0.848718 | Val Loss: 0.120577, Val Acc: 0.773196\n",
      "Epoch 16208 - Train Loss: 0.096764, Train Acc: 0.848718 | Val Loss: 0.120575, Val Acc: 0.773196\n",
      "Epoch 16209 - Train Loss: 0.096761, Train Acc: 0.848718 | Val Loss: 0.120573, Val Acc: 0.773196\n",
      "Epoch 16210 - Train Loss: 0.096758, Train Acc: 0.848718 | Val Loss: 0.120571, Val Acc: 0.773196\n",
      "Epoch 16211 - Train Loss: 0.096754, Train Acc: 0.848718 | Val Loss: 0.120569, Val Acc: 0.773196\n",
      "Epoch 16212 - Train Loss: 0.096751, Train Acc: 0.848718 | Val Loss: 0.120567, Val Acc: 0.773196\n",
      "Epoch 16213 - Train Loss: 0.096748, Train Acc: 0.848718 | Val Loss: 0.120565, Val Acc: 0.773196\n",
      "Epoch 16214 - Train Loss: 0.096745, Train Acc: 0.848718 | Val Loss: 0.120563, Val Acc: 0.773196\n",
      "Epoch 16215 - Train Loss: 0.096741, Train Acc: 0.848718 | Val Loss: 0.120561, Val Acc: 0.773196\n",
      "Epoch 16216 - Train Loss: 0.096738, Train Acc: 0.848718 | Val Loss: 0.120559, Val Acc: 0.773196\n",
      "Epoch 16217 - Train Loss: 0.096735, Train Acc: 0.848718 | Val Loss: 0.120557, Val Acc: 0.773196\n",
      "Epoch 16218 - Train Loss: 0.096732, Train Acc: 0.848718 | Val Loss: 0.120555, Val Acc: 0.773196\n",
      "Epoch 16219 - Train Loss: 0.096728, Train Acc: 0.848718 | Val Loss: 0.120553, Val Acc: 0.773196\n",
      "Epoch 16220 - Train Loss: 0.096725, Train Acc: 0.848718 | Val Loss: 0.120551, Val Acc: 0.773196\n",
      "Epoch 16221 - Train Loss: 0.096722, Train Acc: 0.848718 | Val Loss: 0.120549, Val Acc: 0.773196\n",
      "Epoch 16222 - Train Loss: 0.096718, Train Acc: 0.848718 | Val Loss: 0.120547, Val Acc: 0.773196\n",
      "Epoch 16223 - Train Loss: 0.096715, Train Acc: 0.848718 | Val Loss: 0.120545, Val Acc: 0.773196\n",
      "Epoch 16224 - Train Loss: 0.096712, Train Acc: 0.848718 | Val Loss: 0.120543, Val Acc: 0.773196\n",
      "Epoch 16225 - Train Loss: 0.096709, Train Acc: 0.848718 | Val Loss: 0.120541, Val Acc: 0.773196\n",
      "Epoch 16226 - Train Loss: 0.096705, Train Acc: 0.848718 | Val Loss: 0.120539, Val Acc: 0.773196\n",
      "Epoch 16227 - Train Loss: 0.096702, Train Acc: 0.848718 | Val Loss: 0.120537, Val Acc: 0.773196\n",
      "Epoch 16228 - Train Loss: 0.096699, Train Acc: 0.848718 | Val Loss: 0.120535, Val Acc: 0.773196\n",
      "Epoch 16229 - Train Loss: 0.096696, Train Acc: 0.848718 | Val Loss: 0.120533, Val Acc: 0.773196\n",
      "Epoch 16230 - Train Loss: 0.096692, Train Acc: 0.848718 | Val Loss: 0.120531, Val Acc: 0.773196\n",
      "Epoch 16231 - Train Loss: 0.096689, Train Acc: 0.848718 | Val Loss: 0.120528, Val Acc: 0.773196\n",
      "Epoch 16232 - Train Loss: 0.096686, Train Acc: 0.848718 | Val Loss: 0.120526, Val Acc: 0.773196\n",
      "Epoch 16233 - Train Loss: 0.096683, Train Acc: 0.848718 | Val Loss: 0.120524, Val Acc: 0.773196\n",
      "Epoch 16234 - Train Loss: 0.096679, Train Acc: 0.848718 | Val Loss: 0.120522, Val Acc: 0.773196\n",
      "Epoch 16235 - Train Loss: 0.096676, Train Acc: 0.848718 | Val Loss: 0.120520, Val Acc: 0.773196\n",
      "Epoch 16236 - Train Loss: 0.096673, Train Acc: 0.848718 | Val Loss: 0.120518, Val Acc: 0.773196\n",
      "Epoch 16237 - Train Loss: 0.096670, Train Acc: 0.848718 | Val Loss: 0.120516, Val Acc: 0.773196\n",
      "Epoch 16238 - Train Loss: 0.096666, Train Acc: 0.848718 | Val Loss: 0.120514, Val Acc: 0.773196\n",
      "Epoch 16239 - Train Loss: 0.096663, Train Acc: 0.848718 | Val Loss: 0.120512, Val Acc: 0.773196\n",
      "Epoch 16240 - Train Loss: 0.096660, Train Acc: 0.848718 | Val Loss: 0.120510, Val Acc: 0.773196\n",
      "Epoch 16241 - Train Loss: 0.096657, Train Acc: 0.848718 | Val Loss: 0.120508, Val Acc: 0.773196\n",
      "Epoch 16242 - Train Loss: 0.096653, Train Acc: 0.848718 | Val Loss: 0.120506, Val Acc: 0.773196\n",
      "Epoch 16243 - Train Loss: 0.096650, Train Acc: 0.848718 | Val Loss: 0.120504, Val Acc: 0.773196\n",
      "Epoch 16244 - Train Loss: 0.096647, Train Acc: 0.848718 | Val Loss: 0.120502, Val Acc: 0.773196\n",
      "Epoch 16245 - Train Loss: 0.096644, Train Acc: 0.848718 | Val Loss: 0.120500, Val Acc: 0.773196\n",
      "Epoch 16246 - Train Loss: 0.096640, Train Acc: 0.848718 | Val Loss: 0.120498, Val Acc: 0.773196\n",
      "Epoch 16247 - Train Loss: 0.096637, Train Acc: 0.848718 | Val Loss: 0.120496, Val Acc: 0.773196\n",
      "Epoch 16248 - Train Loss: 0.096634, Train Acc: 0.848718 | Val Loss: 0.120494, Val Acc: 0.773196\n",
      "Epoch 16249 - Train Loss: 0.096631, Train Acc: 0.848718 | Val Loss: 0.120492, Val Acc: 0.773196\n",
      "Epoch 16250 - Train Loss: 0.096627, Train Acc: 0.848718 | Val Loss: 0.120490, Val Acc: 0.773196\n",
      "Epoch 16251 - Train Loss: 0.096624, Train Acc: 0.848718 | Val Loss: 0.120488, Val Acc: 0.773196\n",
      "Epoch 16252 - Train Loss: 0.096621, Train Acc: 0.848718 | Val Loss: 0.120486, Val Acc: 0.773196\n",
      "Epoch 16253 - Train Loss: 0.096618, Train Acc: 0.848718 | Val Loss: 0.120484, Val Acc: 0.773196\n",
      "Epoch 16254 - Train Loss: 0.096614, Train Acc: 0.848718 | Val Loss: 0.120482, Val Acc: 0.773196\n",
      "Epoch 16255 - Train Loss: 0.096611, Train Acc: 0.848718 | Val Loss: 0.120480, Val Acc: 0.773196\n",
      "Epoch 16256 - Train Loss: 0.096608, Train Acc: 0.848718 | Val Loss: 0.120478, Val Acc: 0.773196\n",
      "Epoch 16257 - Train Loss: 0.096605, Train Acc: 0.848718 | Val Loss: 0.120476, Val Acc: 0.773196\n",
      "Epoch 16258 - Train Loss: 0.096601, Train Acc: 0.848718 | Val Loss: 0.120474, Val Acc: 0.773196\n",
      "Epoch 16259 - Train Loss: 0.096598, Train Acc: 0.848718 | Val Loss: 0.120472, Val Acc: 0.773196\n",
      "Epoch 16260 - Train Loss: 0.096595, Train Acc: 0.848718 | Val Loss: 0.120470, Val Acc: 0.773196\n",
      "Epoch 16261 - Train Loss: 0.096592, Train Acc: 0.848718 | Val Loss: 0.120468, Val Acc: 0.773196\n",
      "Epoch 16262 - Train Loss: 0.096588, Train Acc: 0.848718 | Val Loss: 0.120466, Val Acc: 0.773196\n",
      "Epoch 16263 - Train Loss: 0.096585, Train Acc: 0.848718 | Val Loss: 0.120464, Val Acc: 0.773196\n",
      "Epoch 16264 - Train Loss: 0.096582, Train Acc: 0.848718 | Val Loss: 0.120462, Val Acc: 0.773196\n",
      "Epoch 16265 - Train Loss: 0.096579, Train Acc: 0.848718 | Val Loss: 0.120461, Val Acc: 0.773196\n",
      "Epoch 16266 - Train Loss: 0.096575, Train Acc: 0.848718 | Val Loss: 0.120459, Val Acc: 0.773196\n",
      "Epoch 16267 - Train Loss: 0.096572, Train Acc: 0.848718 | Val Loss: 0.120457, Val Acc: 0.773196\n",
      "Epoch 16268 - Train Loss: 0.096569, Train Acc: 0.848718 | Val Loss: 0.120455, Val Acc: 0.773196\n",
      "Epoch 16269 - Train Loss: 0.096566, Train Acc: 0.848718 | Val Loss: 0.120453, Val Acc: 0.773196\n",
      "Epoch 16270 - Train Loss: 0.096562, Train Acc: 0.848718 | Val Loss: 0.120451, Val Acc: 0.773196\n",
      "Epoch 16271 - Train Loss: 0.096559, Train Acc: 0.848718 | Val Loss: 0.120449, Val Acc: 0.773196\n",
      "Epoch 16272 - Train Loss: 0.096556, Train Acc: 0.848718 | Val Loss: 0.120447, Val Acc: 0.773196\n",
      "Epoch 16273 - Train Loss: 0.096553, Train Acc: 0.848718 | Val Loss: 0.120445, Val Acc: 0.773196\n",
      "Epoch 16274 - Train Loss: 0.096550, Train Acc: 0.848718 | Val Loss: 0.120443, Val Acc: 0.773196\n",
      "Epoch 16275 - Train Loss: 0.096546, Train Acc: 0.848718 | Val Loss: 0.120441, Val Acc: 0.773196\n",
      "Epoch 16276 - Train Loss: 0.096543, Train Acc: 0.848718 | Val Loss: 0.120439, Val Acc: 0.773196\n",
      "Epoch 16277 - Train Loss: 0.096540, Train Acc: 0.848718 | Val Loss: 0.120437, Val Acc: 0.773196\n",
      "Epoch 16278 - Train Loss: 0.096537, Train Acc: 0.848718 | Val Loss: 0.120435, Val Acc: 0.773196\n",
      "Epoch 16279 - Train Loss: 0.096533, Train Acc: 0.848718 | Val Loss: 0.120433, Val Acc: 0.773196\n",
      "Epoch 16280 - Train Loss: 0.096530, Train Acc: 0.848718 | Val Loss: 0.120431, Val Acc: 0.773196\n",
      "Epoch 16281 - Train Loss: 0.096527, Train Acc: 0.848718 | Val Loss: 0.120429, Val Acc: 0.773196\n",
      "Epoch 16282 - Train Loss: 0.096524, Train Acc: 0.848718 | Val Loss: 0.120427, Val Acc: 0.773196\n",
      "Epoch 16283 - Train Loss: 0.096520, Train Acc: 0.848718 | Val Loss: 0.120425, Val Acc: 0.773196\n",
      "Epoch 16284 - Train Loss: 0.096517, Train Acc: 0.848718 | Val Loss: 0.120423, Val Acc: 0.773196\n",
      "Epoch 16285 - Train Loss: 0.096514, Train Acc: 0.848718 | Val Loss: 0.120421, Val Acc: 0.773196\n",
      "Epoch 16286 - Train Loss: 0.096511, Train Acc: 0.848718 | Val Loss: 0.120419, Val Acc: 0.773196\n",
      "Epoch 16287 - Train Loss: 0.096507, Train Acc: 0.848718 | Val Loss: 0.120417, Val Acc: 0.773196\n",
      "Epoch 16288 - Train Loss: 0.096504, Train Acc: 0.848718 | Val Loss: 0.120415, Val Acc: 0.773196\n",
      "Epoch 16289 - Train Loss: 0.096501, Train Acc: 0.848718 | Val Loss: 0.120413, Val Acc: 0.773196\n",
      "Epoch 16290 - Train Loss: 0.096498, Train Acc: 0.848718 | Val Loss: 0.120411, Val Acc: 0.773196\n",
      "Epoch 16291 - Train Loss: 0.096495, Train Acc: 0.848718 | Val Loss: 0.120409, Val Acc: 0.773196\n",
      "Epoch 16292 - Train Loss: 0.096491, Train Acc: 0.848718 | Val Loss: 0.120407, Val Acc: 0.773196\n",
      "Epoch 16293 - Train Loss: 0.096488, Train Acc: 0.848718 | Val Loss: 0.120405, Val Acc: 0.773196\n",
      "Epoch 16294 - Train Loss: 0.096485, Train Acc: 0.848718 | Val Loss: 0.120403, Val Acc: 0.773196\n",
      "Epoch 16295 - Train Loss: 0.096482, Train Acc: 0.848718 | Val Loss: 0.120401, Val Acc: 0.773196\n",
      "Epoch 16296 - Train Loss: 0.096478, Train Acc: 0.848718 | Val Loss: 0.120399, Val Acc: 0.773196\n",
      "Epoch 16297 - Train Loss: 0.096475, Train Acc: 0.848718 | Val Loss: 0.120397, Val Acc: 0.773196\n",
      "Epoch 16298 - Train Loss: 0.096472, Train Acc: 0.848718 | Val Loss: 0.120395, Val Acc: 0.773196\n",
      "Epoch 16299 - Train Loss: 0.096469, Train Acc: 0.848718 | Val Loss: 0.120393, Val Acc: 0.773196\n",
      "Epoch 16300 - Train Loss: 0.096465, Train Acc: 0.848718 | Val Loss: 0.120391, Val Acc: 0.773196\n",
      "Epoch 16301 - Train Loss: 0.096462, Train Acc: 0.848718 | Val Loss: 0.120389, Val Acc: 0.773196\n",
      "Epoch 16302 - Train Loss: 0.096459, Train Acc: 0.848718 | Val Loss: 0.120387, Val Acc: 0.773196\n",
      "Epoch 16303 - Train Loss: 0.096456, Train Acc: 0.848718 | Val Loss: 0.120385, Val Acc: 0.773196\n",
      "Epoch 16304 - Train Loss: 0.096453, Train Acc: 0.848718 | Val Loss: 0.120383, Val Acc: 0.773196\n",
      "Epoch 16305 - Train Loss: 0.096449, Train Acc: 0.848718 | Val Loss: 0.120381, Val Acc: 0.773196\n",
      "Epoch 16306 - Train Loss: 0.096446, Train Acc: 0.848718 | Val Loss: 0.120379, Val Acc: 0.773196\n",
      "Epoch 16307 - Train Loss: 0.096443, Train Acc: 0.848718 | Val Loss: 0.120377, Val Acc: 0.773196\n",
      "Epoch 16308 - Train Loss: 0.096440, Train Acc: 0.848718 | Val Loss: 0.120375, Val Acc: 0.773196\n",
      "Epoch 16309 - Train Loss: 0.096436, Train Acc: 0.848718 | Val Loss: 0.120373, Val Acc: 0.773196\n",
      "Epoch 16310 - Train Loss: 0.096433, Train Acc: 0.848718 | Val Loss: 0.120371, Val Acc: 0.773196\n",
      "Epoch 16311 - Train Loss: 0.096430, Train Acc: 0.848718 | Val Loss: 0.120369, Val Acc: 0.773196\n",
      "Epoch 16312 - Train Loss: 0.096427, Train Acc: 0.848718 | Val Loss: 0.120367, Val Acc: 0.773196\n",
      "Epoch 16313 - Train Loss: 0.096423, Train Acc: 0.848718 | Val Loss: 0.120365, Val Acc: 0.773196\n",
      "Epoch 16314 - Train Loss: 0.096420, Train Acc: 0.848718 | Val Loss: 0.120363, Val Acc: 0.773196\n",
      "Epoch 16315 - Train Loss: 0.096417, Train Acc: 0.848718 | Val Loss: 0.120361, Val Acc: 0.773196\n",
      "Epoch 16316 - Train Loss: 0.096414, Train Acc: 0.848718 | Val Loss: 0.120359, Val Acc: 0.773196\n",
      "Epoch 16317 - Train Loss: 0.096411, Train Acc: 0.848718 | Val Loss: 0.120357, Val Acc: 0.773196\n",
      "Epoch 16318 - Train Loss: 0.096407, Train Acc: 0.848718 | Val Loss: 0.120355, Val Acc: 0.773196\n",
      "Epoch 16319 - Train Loss: 0.096404, Train Acc: 0.848718 | Val Loss: 0.120353, Val Acc: 0.773196\n",
      "Epoch 16320 - Train Loss: 0.096401, Train Acc: 0.848718 | Val Loss: 0.120351, Val Acc: 0.773196\n",
      "Epoch 16321 - Train Loss: 0.096398, Train Acc: 0.848718 | Val Loss: 0.120349, Val Acc: 0.773196\n",
      "Epoch 16322 - Train Loss: 0.096394, Train Acc: 0.848718 | Val Loss: 0.120347, Val Acc: 0.773196\n",
      "Epoch 16323 - Train Loss: 0.096391, Train Acc: 0.848718 | Val Loss: 0.120345, Val Acc: 0.773196\n",
      "Epoch 16324 - Train Loss: 0.096388, Train Acc: 0.848718 | Val Loss: 0.120344, Val Acc: 0.773196\n",
      "Epoch 16325 - Train Loss: 0.096385, Train Acc: 0.848718 | Val Loss: 0.120342, Val Acc: 0.773196\n",
      "Epoch 16326 - Train Loss: 0.096382, Train Acc: 0.848718 | Val Loss: 0.120340, Val Acc: 0.773196\n",
      "Epoch 16327 - Train Loss: 0.096378, Train Acc: 0.848718 | Val Loss: 0.120338, Val Acc: 0.773196\n",
      "Epoch 16328 - Train Loss: 0.096375, Train Acc: 0.848718 | Val Loss: 0.120336, Val Acc: 0.773196\n",
      "Epoch 16329 - Train Loss: 0.096372, Train Acc: 0.848718 | Val Loss: 0.120334, Val Acc: 0.773196\n",
      "Epoch 16330 - Train Loss: 0.096369, Train Acc: 0.848718 | Val Loss: 0.120332, Val Acc: 0.773196\n",
      "Epoch 16331 - Train Loss: 0.096365, Train Acc: 0.848718 | Val Loss: 0.120330, Val Acc: 0.773196\n",
      "Epoch 16332 - Train Loss: 0.096362, Train Acc: 0.848718 | Val Loss: 0.120328, Val Acc: 0.773196\n",
      "Epoch 16333 - Train Loss: 0.096359, Train Acc: 0.848718 | Val Loss: 0.120326, Val Acc: 0.773196\n",
      "Epoch 16334 - Train Loss: 0.096356, Train Acc: 0.850000 | Val Loss: 0.120324, Val Acc: 0.773196\n",
      "Epoch 16335 - Train Loss: 0.096353, Train Acc: 0.850000 | Val Loss: 0.120322, Val Acc: 0.773196\n",
      "Epoch 16336 - Train Loss: 0.096349, Train Acc: 0.850000 | Val Loss: 0.120320, Val Acc: 0.773196\n",
      "Epoch 16337 - Train Loss: 0.096346, Train Acc: 0.850000 | Val Loss: 0.120318, Val Acc: 0.773196\n",
      "Epoch 16338 - Train Loss: 0.096343, Train Acc: 0.850000 | Val Loss: 0.120316, Val Acc: 0.773196\n",
      "Epoch 16339 - Train Loss: 0.096340, Train Acc: 0.850000 | Val Loss: 0.120314, Val Acc: 0.773196\n",
      "Epoch 16340 - Train Loss: 0.096337, Train Acc: 0.850000 | Val Loss: 0.120312, Val Acc: 0.773196\n",
      "Epoch 16341 - Train Loss: 0.096333, Train Acc: 0.850000 | Val Loss: 0.120310, Val Acc: 0.773196\n",
      "Epoch 16342 - Train Loss: 0.096330, Train Acc: 0.850000 | Val Loss: 0.120308, Val Acc: 0.773196\n",
      "Epoch 16343 - Train Loss: 0.096327, Train Acc: 0.850000 | Val Loss: 0.120306, Val Acc: 0.773196\n",
      "Epoch 16344 - Train Loss: 0.096324, Train Acc: 0.850000 | Val Loss: 0.120304, Val Acc: 0.773196\n",
      "Epoch 16345 - Train Loss: 0.096320, Train Acc: 0.850000 | Val Loss: 0.120302, Val Acc: 0.773196\n",
      "Epoch 16346 - Train Loss: 0.096317, Train Acc: 0.850000 | Val Loss: 0.120300, Val Acc: 0.773196\n",
      "Epoch 16347 - Train Loss: 0.096314, Train Acc: 0.850000 | Val Loss: 0.120298, Val Acc: 0.773196\n",
      "Epoch 16348 - Train Loss: 0.096311, Train Acc: 0.850000 | Val Loss: 0.120296, Val Acc: 0.773196\n",
      "Epoch 16349 - Train Loss: 0.096308, Train Acc: 0.850000 | Val Loss: 0.120294, Val Acc: 0.773196\n",
      "Epoch 16350 - Train Loss: 0.096304, Train Acc: 0.850000 | Val Loss: 0.120292, Val Acc: 0.773196\n",
      "Epoch 16351 - Train Loss: 0.096301, Train Acc: 0.850000 | Val Loss: 0.120290, Val Acc: 0.773196\n",
      "Epoch 16352 - Train Loss: 0.096298, Train Acc: 0.850000 | Val Loss: 0.120288, Val Acc: 0.773196\n",
      "Epoch 16353 - Train Loss: 0.096295, Train Acc: 0.850000 | Val Loss: 0.120286, Val Acc: 0.773196\n",
      "Epoch 16354 - Train Loss: 0.096292, Train Acc: 0.850000 | Val Loss: 0.120284, Val Acc: 0.773196\n",
      "Epoch 16355 - Train Loss: 0.096288, Train Acc: 0.850000 | Val Loss: 0.120282, Val Acc: 0.773196\n",
      "Epoch 16356 - Train Loss: 0.096285, Train Acc: 0.850000 | Val Loss: 0.120281, Val Acc: 0.773196\n",
      "Epoch 16357 - Train Loss: 0.096282, Train Acc: 0.850000 | Val Loss: 0.120279, Val Acc: 0.773196\n",
      "Epoch 16358 - Train Loss: 0.096279, Train Acc: 0.850000 | Val Loss: 0.120277, Val Acc: 0.773196\n",
      "Epoch 16359 - Train Loss: 0.096276, Train Acc: 0.850000 | Val Loss: 0.120275, Val Acc: 0.773196\n",
      "Epoch 16360 - Train Loss: 0.096272, Train Acc: 0.850000 | Val Loss: 0.120273, Val Acc: 0.773196\n",
      "Epoch 16361 - Train Loss: 0.096269, Train Acc: 0.850000 | Val Loss: 0.120271, Val Acc: 0.773196\n",
      "Epoch 16362 - Train Loss: 0.096266, Train Acc: 0.850000 | Val Loss: 0.120269, Val Acc: 0.773196\n",
      "Epoch 16363 - Train Loss: 0.096263, Train Acc: 0.850000 | Val Loss: 0.120267, Val Acc: 0.773196\n",
      "Epoch 16364 - Train Loss: 0.096260, Train Acc: 0.850000 | Val Loss: 0.120265, Val Acc: 0.773196\n",
      "Epoch 16365 - Train Loss: 0.096256, Train Acc: 0.850000 | Val Loss: 0.120263, Val Acc: 0.773196\n",
      "Epoch 16366 - Train Loss: 0.096253, Train Acc: 0.850000 | Val Loss: 0.120261, Val Acc: 0.773196\n",
      "Epoch 16367 - Train Loss: 0.096250, Train Acc: 0.850000 | Val Loss: 0.120259, Val Acc: 0.773196\n",
      "Epoch 16368 - Train Loss: 0.096247, Train Acc: 0.850000 | Val Loss: 0.120257, Val Acc: 0.773196\n",
      "Epoch 16369 - Train Loss: 0.096243, Train Acc: 0.850000 | Val Loss: 0.120255, Val Acc: 0.773196\n",
      "Epoch 16370 - Train Loss: 0.096240, Train Acc: 0.850000 | Val Loss: 0.120253, Val Acc: 0.773196\n",
      "Epoch 16371 - Train Loss: 0.096237, Train Acc: 0.850000 | Val Loss: 0.120251, Val Acc: 0.773196\n",
      "Epoch 16372 - Train Loss: 0.096234, Train Acc: 0.850000 | Val Loss: 0.120249, Val Acc: 0.773196\n",
      "Epoch 16373 - Train Loss: 0.096231, Train Acc: 0.850000 | Val Loss: 0.120247, Val Acc: 0.773196\n",
      "Epoch 16374 - Train Loss: 0.096227, Train Acc: 0.850000 | Val Loss: 0.120245, Val Acc: 0.773196\n",
      "Epoch 16375 - Train Loss: 0.096224, Train Acc: 0.850000 | Val Loss: 0.120243, Val Acc: 0.773196\n",
      "Epoch 16376 - Train Loss: 0.096221, Train Acc: 0.850000 | Val Loss: 0.120241, Val Acc: 0.773196\n",
      "Epoch 16377 - Train Loss: 0.096218, Train Acc: 0.850000 | Val Loss: 0.120239, Val Acc: 0.773196\n",
      "Epoch 16378 - Train Loss: 0.096215, Train Acc: 0.850000 | Val Loss: 0.120237, Val Acc: 0.773196\n",
      "Epoch 16379 - Train Loss: 0.096211, Train Acc: 0.850000 | Val Loss: 0.120235, Val Acc: 0.773196\n",
      "Epoch 16380 - Train Loss: 0.096208, Train Acc: 0.850000 | Val Loss: 0.120234, Val Acc: 0.773196\n",
      "Epoch 16381 - Train Loss: 0.096205, Train Acc: 0.850000 | Val Loss: 0.120232, Val Acc: 0.773196\n",
      "Epoch 16382 - Train Loss: 0.096202, Train Acc: 0.850000 | Val Loss: 0.120230, Val Acc: 0.773196\n",
      "Epoch 16383 - Train Loss: 0.096199, Train Acc: 0.850000 | Val Loss: 0.120228, Val Acc: 0.773196\n",
      "Epoch 16384 - Train Loss: 0.096195, Train Acc: 0.850000 | Val Loss: 0.120226, Val Acc: 0.773196\n",
      "Epoch 16385 - Train Loss: 0.096192, Train Acc: 0.850000 | Val Loss: 0.120224, Val Acc: 0.773196\n",
      "Epoch 16386 - Train Loss: 0.096189, Train Acc: 0.850000 | Val Loss: 0.120222, Val Acc: 0.773196\n",
      "Epoch 16387 - Train Loss: 0.096186, Train Acc: 0.850000 | Val Loss: 0.120220, Val Acc: 0.773196\n",
      "Epoch 16388 - Train Loss: 0.096183, Train Acc: 0.850000 | Val Loss: 0.120218, Val Acc: 0.773196\n",
      "Epoch 16389 - Train Loss: 0.096179, Train Acc: 0.850000 | Val Loss: 0.120216, Val Acc: 0.773196\n",
      "Epoch 16390 - Train Loss: 0.096176, Train Acc: 0.850000 | Val Loss: 0.120214, Val Acc: 0.773196\n",
      "Epoch 16391 - Train Loss: 0.096173, Train Acc: 0.850000 | Val Loss: 0.120212, Val Acc: 0.773196\n",
      "Epoch 16392 - Train Loss: 0.096170, Train Acc: 0.850000 | Val Loss: 0.120210, Val Acc: 0.773196\n",
      "Epoch 16393 - Train Loss: 0.096167, Train Acc: 0.850000 | Val Loss: 0.120208, Val Acc: 0.773196\n",
      "Epoch 16394 - Train Loss: 0.096164, Train Acc: 0.850000 | Val Loss: 0.120206, Val Acc: 0.773196\n",
      "Epoch 16395 - Train Loss: 0.096160, Train Acc: 0.850000 | Val Loss: 0.120204, Val Acc: 0.773196\n",
      "Epoch 16396 - Train Loss: 0.096157, Train Acc: 0.850000 | Val Loss: 0.120202, Val Acc: 0.773196\n",
      "Epoch 16397 - Train Loss: 0.096154, Train Acc: 0.850000 | Val Loss: 0.120200, Val Acc: 0.773196\n",
      "Epoch 16398 - Train Loss: 0.096151, Train Acc: 0.850000 | Val Loss: 0.120198, Val Acc: 0.773196\n",
      "Epoch 16399 - Train Loss: 0.096148, Train Acc: 0.850000 | Val Loss: 0.120196, Val Acc: 0.773196\n",
      "Epoch 16400 - Train Loss: 0.096144, Train Acc: 0.850000 | Val Loss: 0.120195, Val Acc: 0.773196\n",
      "Epoch 16401 - Train Loss: 0.096141, Train Acc: 0.850000 | Val Loss: 0.120193, Val Acc: 0.773196\n",
      "Epoch 16402 - Train Loss: 0.096138, Train Acc: 0.850000 | Val Loss: 0.120191, Val Acc: 0.773196\n",
      "Epoch 16403 - Train Loss: 0.096135, Train Acc: 0.850000 | Val Loss: 0.120189, Val Acc: 0.773196\n",
      "Epoch 16404 - Train Loss: 0.096132, Train Acc: 0.850000 | Val Loss: 0.120187, Val Acc: 0.773196\n",
      "Epoch 16405 - Train Loss: 0.096128, Train Acc: 0.850000 | Val Loss: 0.120185, Val Acc: 0.773196\n",
      "Epoch 16406 - Train Loss: 0.096125, Train Acc: 0.850000 | Val Loss: 0.120183, Val Acc: 0.773196\n",
      "Epoch 16407 - Train Loss: 0.096122, Train Acc: 0.850000 | Val Loss: 0.120181, Val Acc: 0.773196\n",
      "Epoch 16408 - Train Loss: 0.096119, Train Acc: 0.850000 | Val Loss: 0.120179, Val Acc: 0.773196\n",
      "Epoch 16409 - Train Loss: 0.096116, Train Acc: 0.850000 | Val Loss: 0.120177, Val Acc: 0.773196\n",
      "Epoch 16410 - Train Loss: 0.096112, Train Acc: 0.850000 | Val Loss: 0.120175, Val Acc: 0.773196\n",
      "Epoch 16411 - Train Loss: 0.096109, Train Acc: 0.850000 | Val Loss: 0.120173, Val Acc: 0.773196\n",
      "Epoch 16412 - Train Loss: 0.096106, Train Acc: 0.850000 | Val Loss: 0.120171, Val Acc: 0.773196\n",
      "Epoch 16413 - Train Loss: 0.096103, Train Acc: 0.850000 | Val Loss: 0.120169, Val Acc: 0.773196\n",
      "Epoch 16414 - Train Loss: 0.096100, Train Acc: 0.850000 | Val Loss: 0.120167, Val Acc: 0.773196\n",
      "Epoch 16415 - Train Loss: 0.096097, Train Acc: 0.850000 | Val Loss: 0.120165, Val Acc: 0.773196\n",
      "Epoch 16416 - Train Loss: 0.096093, Train Acc: 0.850000 | Val Loss: 0.120163, Val Acc: 0.773196\n",
      "Epoch 16417 - Train Loss: 0.096090, Train Acc: 0.850000 | Val Loss: 0.120161, Val Acc: 0.773196\n",
      "Epoch 16418 - Train Loss: 0.096087, Train Acc: 0.850000 | Val Loss: 0.120160, Val Acc: 0.773196\n",
      "Epoch 16419 - Train Loss: 0.096084, Train Acc: 0.850000 | Val Loss: 0.120158, Val Acc: 0.773196\n",
      "Epoch 16420 - Train Loss: 0.096081, Train Acc: 0.850000 | Val Loss: 0.120156, Val Acc: 0.773196\n",
      "Epoch 16421 - Train Loss: 0.096077, Train Acc: 0.850000 | Val Loss: 0.120154, Val Acc: 0.773196\n",
      "Epoch 16422 - Train Loss: 0.096074, Train Acc: 0.850000 | Val Loss: 0.120152, Val Acc: 0.773196\n",
      "Epoch 16423 - Train Loss: 0.096071, Train Acc: 0.850000 | Val Loss: 0.120150, Val Acc: 0.773196\n",
      "Epoch 16424 - Train Loss: 0.096068, Train Acc: 0.850000 | Val Loss: 0.120148, Val Acc: 0.773196\n",
      "Epoch 16425 - Train Loss: 0.096065, Train Acc: 0.850000 | Val Loss: 0.120146, Val Acc: 0.773196\n",
      "Epoch 16426 - Train Loss: 0.096061, Train Acc: 0.850000 | Val Loss: 0.120144, Val Acc: 0.773196\n",
      "Epoch 16427 - Train Loss: 0.096058, Train Acc: 0.850000 | Val Loss: 0.120142, Val Acc: 0.773196\n",
      "Epoch 16428 - Train Loss: 0.096055, Train Acc: 0.850000 | Val Loss: 0.120140, Val Acc: 0.773196\n",
      "Epoch 16429 - Train Loss: 0.096052, Train Acc: 0.850000 | Val Loss: 0.120138, Val Acc: 0.773196\n",
      "Epoch 16430 - Train Loss: 0.096049, Train Acc: 0.850000 | Val Loss: 0.120136, Val Acc: 0.773196\n",
      "Epoch 16431 - Train Loss: 0.096046, Train Acc: 0.850000 | Val Loss: 0.120134, Val Acc: 0.773196\n",
      "Epoch 16432 - Train Loss: 0.096042, Train Acc: 0.850000 | Val Loss: 0.120132, Val Acc: 0.773196\n",
      "Epoch 16433 - Train Loss: 0.096039, Train Acc: 0.850000 | Val Loss: 0.120130, Val Acc: 0.773196\n",
      "Epoch 16434 - Train Loss: 0.096036, Train Acc: 0.850000 | Val Loss: 0.120129, Val Acc: 0.773196\n",
      "Epoch 16435 - Train Loss: 0.096033, Train Acc: 0.850000 | Val Loss: 0.120127, Val Acc: 0.773196\n",
      "Epoch 16436 - Train Loss: 0.096030, Train Acc: 0.850000 | Val Loss: 0.120125, Val Acc: 0.773196\n",
      "Epoch 16437 - Train Loss: 0.096026, Train Acc: 0.850000 | Val Loss: 0.120123, Val Acc: 0.773196\n",
      "Epoch 16438 - Train Loss: 0.096023, Train Acc: 0.850000 | Val Loss: 0.120121, Val Acc: 0.773196\n",
      "Epoch 16439 - Train Loss: 0.096020, Train Acc: 0.850000 | Val Loss: 0.120119, Val Acc: 0.773196\n",
      "Epoch 16440 - Train Loss: 0.096017, Train Acc: 0.850000 | Val Loss: 0.120117, Val Acc: 0.773196\n",
      "Epoch 16441 - Train Loss: 0.096014, Train Acc: 0.850000 | Val Loss: 0.120115, Val Acc: 0.773196\n",
      "Epoch 16442 - Train Loss: 0.096011, Train Acc: 0.850000 | Val Loss: 0.120113, Val Acc: 0.773196\n",
      "Epoch 16443 - Train Loss: 0.096007, Train Acc: 0.850000 | Val Loss: 0.120111, Val Acc: 0.773196\n",
      "Epoch 16444 - Train Loss: 0.096004, Train Acc: 0.850000 | Val Loss: 0.120109, Val Acc: 0.773196\n",
      "Epoch 16445 - Train Loss: 0.096001, Train Acc: 0.850000 | Val Loss: 0.120107, Val Acc: 0.773196\n",
      "Epoch 16446 - Train Loss: 0.095998, Train Acc: 0.850000 | Val Loss: 0.120105, Val Acc: 0.773196\n",
      "Epoch 16447 - Train Loss: 0.095995, Train Acc: 0.850000 | Val Loss: 0.120103, Val Acc: 0.773196\n",
      "Epoch 16448 - Train Loss: 0.095992, Train Acc: 0.850000 | Val Loss: 0.120101, Val Acc: 0.773196\n",
      "Epoch 16449 - Train Loss: 0.095988, Train Acc: 0.850000 | Val Loss: 0.120100, Val Acc: 0.773196\n",
      "Epoch 16450 - Train Loss: 0.095985, Train Acc: 0.850000 | Val Loss: 0.120098, Val Acc: 0.773196\n",
      "Epoch 16451 - Train Loss: 0.095982, Train Acc: 0.850000 | Val Loss: 0.120096, Val Acc: 0.773196\n",
      "Epoch 16452 - Train Loss: 0.095979, Train Acc: 0.850000 | Val Loss: 0.120094, Val Acc: 0.773196\n",
      "Epoch 16453 - Train Loss: 0.095976, Train Acc: 0.850000 | Val Loss: 0.120092, Val Acc: 0.773196\n",
      "Epoch 16454 - Train Loss: 0.095973, Train Acc: 0.850000 | Val Loss: 0.120090, Val Acc: 0.773196\n",
      "Epoch 16455 - Train Loss: 0.095969, Train Acc: 0.850000 | Val Loss: 0.120088, Val Acc: 0.773196\n",
      "Epoch 16456 - Train Loss: 0.095966, Train Acc: 0.850000 | Val Loss: 0.120086, Val Acc: 0.773196\n",
      "Epoch 16457 - Train Loss: 0.095963, Train Acc: 0.850000 | Val Loss: 0.120084, Val Acc: 0.773196\n",
      "Epoch 16458 - Train Loss: 0.095960, Train Acc: 0.850000 | Val Loss: 0.120082, Val Acc: 0.773196\n",
      "Epoch 16459 - Train Loss: 0.095957, Train Acc: 0.850000 | Val Loss: 0.120080, Val Acc: 0.773196\n",
      "Epoch 16460 - Train Loss: 0.095953, Train Acc: 0.850000 | Val Loss: 0.120078, Val Acc: 0.773196\n",
      "Epoch 16461 - Train Loss: 0.095950, Train Acc: 0.850000 | Val Loss: 0.120076, Val Acc: 0.773196\n",
      "Epoch 16462 - Train Loss: 0.095947, Train Acc: 0.850000 | Val Loss: 0.120074, Val Acc: 0.773196\n",
      "Epoch 16463 - Train Loss: 0.095944, Train Acc: 0.850000 | Val Loss: 0.120073, Val Acc: 0.773196\n",
      "Epoch 16464 - Train Loss: 0.095941, Train Acc: 0.850000 | Val Loss: 0.120071, Val Acc: 0.773196\n",
      "Epoch 16465 - Train Loss: 0.095938, Train Acc: 0.850000 | Val Loss: 0.120069, Val Acc: 0.773196\n",
      "Epoch 16466 - Train Loss: 0.095934, Train Acc: 0.850000 | Val Loss: 0.120067, Val Acc: 0.773196\n",
      "Epoch 16467 - Train Loss: 0.095931, Train Acc: 0.850000 | Val Loss: 0.120065, Val Acc: 0.773196\n",
      "Epoch 16468 - Train Loss: 0.095928, Train Acc: 0.850000 | Val Loss: 0.120063, Val Acc: 0.773196\n",
      "Epoch 16469 - Train Loss: 0.095925, Train Acc: 0.850000 | Val Loss: 0.120061, Val Acc: 0.773196\n",
      "Epoch 16470 - Train Loss: 0.095922, Train Acc: 0.850000 | Val Loss: 0.120059, Val Acc: 0.773196\n",
      "Epoch 16471 - Train Loss: 0.095919, Train Acc: 0.850000 | Val Loss: 0.120057, Val Acc: 0.773196\n",
      "Epoch 16472 - Train Loss: 0.095915, Train Acc: 0.850000 | Val Loss: 0.120055, Val Acc: 0.773196\n",
      "Epoch 16473 - Train Loss: 0.095912, Train Acc: 0.850000 | Val Loss: 0.120053, Val Acc: 0.773196\n",
      "Epoch 16474 - Train Loss: 0.095909, Train Acc: 0.850000 | Val Loss: 0.120051, Val Acc: 0.773196\n",
      "Epoch 16475 - Train Loss: 0.095906, Train Acc: 0.850000 | Val Loss: 0.120049, Val Acc: 0.773196\n",
      "Epoch 16476 - Train Loss: 0.095903, Train Acc: 0.850000 | Val Loss: 0.120048, Val Acc: 0.773196\n",
      "Epoch 16477 - Train Loss: 0.095900, Train Acc: 0.850000 | Val Loss: 0.120046, Val Acc: 0.773196\n",
      "Epoch 16478 - Train Loss: 0.095896, Train Acc: 0.850000 | Val Loss: 0.120044, Val Acc: 0.773196\n",
      "Epoch 16479 - Train Loss: 0.095893, Train Acc: 0.850000 | Val Loss: 0.120042, Val Acc: 0.773196\n",
      "Epoch 16480 - Train Loss: 0.095890, Train Acc: 0.850000 | Val Loss: 0.120040, Val Acc: 0.773196\n",
      "Epoch 16481 - Train Loss: 0.095887, Train Acc: 0.850000 | Val Loss: 0.120038, Val Acc: 0.773196\n",
      "Epoch 16482 - Train Loss: 0.095884, Train Acc: 0.850000 | Val Loss: 0.120036, Val Acc: 0.773196\n",
      "Epoch 16483 - Train Loss: 0.095881, Train Acc: 0.850000 | Val Loss: 0.120034, Val Acc: 0.773196\n",
      "Epoch 16484 - Train Loss: 0.095878, Train Acc: 0.850000 | Val Loss: 0.120032, Val Acc: 0.773196\n",
      "Epoch 16485 - Train Loss: 0.095874, Train Acc: 0.850000 | Val Loss: 0.120030, Val Acc: 0.773196\n",
      "Epoch 16486 - Train Loss: 0.095871, Train Acc: 0.850000 | Val Loss: 0.120028, Val Acc: 0.773196\n",
      "Epoch 16487 - Train Loss: 0.095868, Train Acc: 0.850000 | Val Loss: 0.120026, Val Acc: 0.773196\n",
      "Epoch 16488 - Train Loss: 0.095865, Train Acc: 0.850000 | Val Loss: 0.120025, Val Acc: 0.773196\n",
      "Epoch 16489 - Train Loss: 0.095862, Train Acc: 0.850000 | Val Loss: 0.120023, Val Acc: 0.773196\n",
      "Epoch 16490 - Train Loss: 0.095859, Train Acc: 0.850000 | Val Loss: 0.120021, Val Acc: 0.773196\n",
      "Epoch 16491 - Train Loss: 0.095855, Train Acc: 0.850000 | Val Loss: 0.120019, Val Acc: 0.773196\n",
      "Epoch 16492 - Train Loss: 0.095852, Train Acc: 0.850000 | Val Loss: 0.120017, Val Acc: 0.773196\n",
      "Epoch 16493 - Train Loss: 0.095849, Train Acc: 0.850000 | Val Loss: 0.120015, Val Acc: 0.773196\n",
      "Epoch 16494 - Train Loss: 0.095846, Train Acc: 0.850000 | Val Loss: 0.120013, Val Acc: 0.773196\n",
      "Epoch 16495 - Train Loss: 0.095843, Train Acc: 0.850000 | Val Loss: 0.120011, Val Acc: 0.773196\n",
      "Epoch 16496 - Train Loss: 0.095840, Train Acc: 0.850000 | Val Loss: 0.120009, Val Acc: 0.773196\n",
      "Epoch 16497 - Train Loss: 0.095836, Train Acc: 0.850000 | Val Loss: 0.120007, Val Acc: 0.773196\n",
      "Epoch 16498 - Train Loss: 0.095833, Train Acc: 0.850000 | Val Loss: 0.120005, Val Acc: 0.773196\n",
      "Epoch 16499 - Train Loss: 0.095830, Train Acc: 0.850000 | Val Loss: 0.120003, Val Acc: 0.773196\n",
      "Epoch 16500 - Train Loss: 0.095827, Train Acc: 0.850000 | Val Loss: 0.120002, Val Acc: 0.773196\n",
      "Epoch 16501 - Train Loss: 0.095824, Train Acc: 0.850000 | Val Loss: 0.120000, Val Acc: 0.773196\n",
      "Epoch 16502 - Train Loss: 0.095821, Train Acc: 0.850000 | Val Loss: 0.119998, Val Acc: 0.773196\n",
      "Epoch 16503 - Train Loss: 0.095818, Train Acc: 0.850000 | Val Loss: 0.119996, Val Acc: 0.773196\n",
      "Epoch 16504 - Train Loss: 0.095814, Train Acc: 0.850000 | Val Loss: 0.119994, Val Acc: 0.773196\n",
      "Epoch 16505 - Train Loss: 0.095811, Train Acc: 0.850000 | Val Loss: 0.119992, Val Acc: 0.773196\n",
      "Epoch 16506 - Train Loss: 0.095808, Train Acc: 0.850000 | Val Loss: 0.119990, Val Acc: 0.773196\n",
      "Epoch 16507 - Train Loss: 0.095805, Train Acc: 0.850000 | Val Loss: 0.119988, Val Acc: 0.773196\n",
      "Epoch 16508 - Train Loss: 0.095802, Train Acc: 0.850000 | Val Loss: 0.119986, Val Acc: 0.773196\n",
      "Epoch 16509 - Train Loss: 0.095799, Train Acc: 0.850000 | Val Loss: 0.119984, Val Acc: 0.773196\n",
      "Epoch 16510 - Train Loss: 0.095795, Train Acc: 0.850000 | Val Loss: 0.119982, Val Acc: 0.773196\n",
      "Epoch 16511 - Train Loss: 0.095792, Train Acc: 0.850000 | Val Loss: 0.119981, Val Acc: 0.773196\n",
      "Epoch 16512 - Train Loss: 0.095789, Train Acc: 0.850000 | Val Loss: 0.119979, Val Acc: 0.773196\n",
      "Epoch 16513 - Train Loss: 0.095786, Train Acc: 0.850000 | Val Loss: 0.119977, Val Acc: 0.773196\n",
      "Epoch 16514 - Train Loss: 0.095783, Train Acc: 0.850000 | Val Loss: 0.119975, Val Acc: 0.773196\n",
      "Epoch 16515 - Train Loss: 0.095780, Train Acc: 0.850000 | Val Loss: 0.119973, Val Acc: 0.773196\n",
      "Epoch 16516 - Train Loss: 0.095777, Train Acc: 0.850000 | Val Loss: 0.119971, Val Acc: 0.773196\n",
      "Epoch 16517 - Train Loss: 0.095773, Train Acc: 0.850000 | Val Loss: 0.119969, Val Acc: 0.773196\n",
      "Epoch 16518 - Train Loss: 0.095770, Train Acc: 0.850000 | Val Loss: 0.119967, Val Acc: 0.773196\n",
      "Epoch 16519 - Train Loss: 0.095767, Train Acc: 0.850000 | Val Loss: 0.119965, Val Acc: 0.773196\n",
      "Epoch 16520 - Train Loss: 0.095764, Train Acc: 0.850000 | Val Loss: 0.119963, Val Acc: 0.773196\n",
      "Epoch 16521 - Train Loss: 0.095761, Train Acc: 0.850000 | Val Loss: 0.119962, Val Acc: 0.773196\n",
      "Epoch 16522 - Train Loss: 0.095758, Train Acc: 0.850000 | Val Loss: 0.119960, Val Acc: 0.773196\n",
      "Epoch 16523 - Train Loss: 0.095754, Train Acc: 0.850000 | Val Loss: 0.119958, Val Acc: 0.773196\n",
      "Epoch 16524 - Train Loss: 0.095751, Train Acc: 0.850000 | Val Loss: 0.119956, Val Acc: 0.773196\n",
      "Epoch 16525 - Train Loss: 0.095748, Train Acc: 0.850000 | Val Loss: 0.119954, Val Acc: 0.773196\n",
      "Epoch 16526 - Train Loss: 0.095745, Train Acc: 0.850000 | Val Loss: 0.119952, Val Acc: 0.773196\n",
      "Epoch 16527 - Train Loss: 0.095742, Train Acc: 0.850000 | Val Loss: 0.119950, Val Acc: 0.773196\n",
      "Epoch 16528 - Train Loss: 0.095739, Train Acc: 0.850000 | Val Loss: 0.119948, Val Acc: 0.773196\n",
      "Epoch 16529 - Train Loss: 0.095736, Train Acc: 0.850000 | Val Loss: 0.119946, Val Acc: 0.773196\n",
      "Epoch 16530 - Train Loss: 0.095732, Train Acc: 0.850000 | Val Loss: 0.119944, Val Acc: 0.773196\n",
      "Epoch 16531 - Train Loss: 0.095729, Train Acc: 0.850000 | Val Loss: 0.119942, Val Acc: 0.773196\n",
      "Epoch 16532 - Train Loss: 0.095726, Train Acc: 0.850000 | Val Loss: 0.119941, Val Acc: 0.773196\n",
      "Epoch 16533 - Train Loss: 0.095723, Train Acc: 0.850000 | Val Loss: 0.119939, Val Acc: 0.773196\n",
      "Epoch 16534 - Train Loss: 0.095720, Train Acc: 0.850000 | Val Loss: 0.119937, Val Acc: 0.773196\n",
      "Epoch 16535 - Train Loss: 0.095717, Train Acc: 0.850000 | Val Loss: 0.119935, Val Acc: 0.773196\n",
      "Epoch 16536 - Train Loss: 0.095714, Train Acc: 0.850000 | Val Loss: 0.119933, Val Acc: 0.773196\n",
      "Epoch 16537 - Train Loss: 0.095710, Train Acc: 0.850000 | Val Loss: 0.119931, Val Acc: 0.773196\n",
      "Epoch 16538 - Train Loss: 0.095707, Train Acc: 0.850000 | Val Loss: 0.119929, Val Acc: 0.773196\n",
      "Epoch 16539 - Train Loss: 0.095704, Train Acc: 0.850000 | Val Loss: 0.119927, Val Acc: 0.773196\n",
      "Epoch 16540 - Train Loss: 0.095701, Train Acc: 0.850000 | Val Loss: 0.119925, Val Acc: 0.773196\n",
      "Epoch 16541 - Train Loss: 0.095698, Train Acc: 0.850000 | Val Loss: 0.119924, Val Acc: 0.773196\n",
      "Epoch 16542 - Train Loss: 0.095695, Train Acc: 0.850000 | Val Loss: 0.119922, Val Acc: 0.773196\n",
      "Epoch 16543 - Train Loss: 0.095692, Train Acc: 0.850000 | Val Loss: 0.119920, Val Acc: 0.773196\n",
      "Epoch 16544 - Train Loss: 0.095688, Train Acc: 0.850000 | Val Loss: 0.119918, Val Acc: 0.773196\n",
      "Epoch 16545 - Train Loss: 0.095685, Train Acc: 0.850000 | Val Loss: 0.119916, Val Acc: 0.773196\n",
      "Epoch 16546 - Train Loss: 0.095682, Train Acc: 0.850000 | Val Loss: 0.119914, Val Acc: 0.773196\n",
      "Epoch 16547 - Train Loss: 0.095679, Train Acc: 0.850000 | Val Loss: 0.119912, Val Acc: 0.773196\n",
      "Epoch 16548 - Train Loss: 0.095676, Train Acc: 0.850000 | Val Loss: 0.119910, Val Acc: 0.773196\n",
      "Epoch 16549 - Train Loss: 0.095673, Train Acc: 0.850000 | Val Loss: 0.119908, Val Acc: 0.773196\n",
      "Epoch 16550 - Train Loss: 0.095670, Train Acc: 0.850000 | Val Loss: 0.119906, Val Acc: 0.773196\n",
      "Epoch 16551 - Train Loss: 0.095666, Train Acc: 0.850000 | Val Loss: 0.119905, Val Acc: 0.773196\n",
      "Epoch 16552 - Train Loss: 0.095663, Train Acc: 0.850000 | Val Loss: 0.119903, Val Acc: 0.773196\n",
      "Epoch 16553 - Train Loss: 0.095660, Train Acc: 0.850000 | Val Loss: 0.119901, Val Acc: 0.773196\n",
      "Epoch 16554 - Train Loss: 0.095657, Train Acc: 0.850000 | Val Loss: 0.119899, Val Acc: 0.773196\n",
      "Epoch 16555 - Train Loss: 0.095654, Train Acc: 0.850000 | Val Loss: 0.119897, Val Acc: 0.773196\n",
      "Epoch 16556 - Train Loss: 0.095651, Train Acc: 0.850000 | Val Loss: 0.119895, Val Acc: 0.773196\n",
      "Epoch 16557 - Train Loss: 0.095648, Train Acc: 0.850000 | Val Loss: 0.119893, Val Acc: 0.773196\n",
      "Epoch 16558 - Train Loss: 0.095645, Train Acc: 0.850000 | Val Loss: 0.119891, Val Acc: 0.773196\n",
      "Epoch 16559 - Train Loss: 0.095641, Train Acc: 0.850000 | Val Loss: 0.119889, Val Acc: 0.773196\n",
      "Epoch 16560 - Train Loss: 0.095638, Train Acc: 0.850000 | Val Loss: 0.119888, Val Acc: 0.773196\n",
      "Epoch 16561 - Train Loss: 0.095635, Train Acc: 0.850000 | Val Loss: 0.119886, Val Acc: 0.773196\n",
      "Epoch 16562 - Train Loss: 0.095632, Train Acc: 0.850000 | Val Loss: 0.119884, Val Acc: 0.773196\n",
      "Epoch 16563 - Train Loss: 0.095629, Train Acc: 0.850000 | Val Loss: 0.119882, Val Acc: 0.773196\n",
      "Epoch 16564 - Train Loss: 0.095626, Train Acc: 0.850000 | Val Loss: 0.119880, Val Acc: 0.773196\n",
      "Epoch 16565 - Train Loss: 0.095623, Train Acc: 0.850000 | Val Loss: 0.119878, Val Acc: 0.773196\n",
      "Epoch 16566 - Train Loss: 0.095619, Train Acc: 0.850000 | Val Loss: 0.119876, Val Acc: 0.773196\n",
      "Epoch 16567 - Train Loss: 0.095616, Train Acc: 0.850000 | Val Loss: 0.119874, Val Acc: 0.773196\n",
      "Epoch 16568 - Train Loss: 0.095613, Train Acc: 0.850000 | Val Loss: 0.119872, Val Acc: 0.773196\n",
      "Epoch 16569 - Train Loss: 0.095610, Train Acc: 0.850000 | Val Loss: 0.119871, Val Acc: 0.773196\n",
      "Epoch 16570 - Train Loss: 0.095607, Train Acc: 0.850000 | Val Loss: 0.119869, Val Acc: 0.773196\n",
      "Epoch 16571 - Train Loss: 0.095604, Train Acc: 0.850000 | Val Loss: 0.119867, Val Acc: 0.773196\n",
      "Epoch 16572 - Train Loss: 0.095601, Train Acc: 0.850000 | Val Loss: 0.119865, Val Acc: 0.773196\n",
      "Epoch 16573 - Train Loss: 0.095598, Train Acc: 0.850000 | Val Loss: 0.119863, Val Acc: 0.773196\n",
      "Epoch 16574 - Train Loss: 0.095594, Train Acc: 0.850000 | Val Loss: 0.119861, Val Acc: 0.773196\n",
      "Epoch 16575 - Train Loss: 0.095591, Train Acc: 0.850000 | Val Loss: 0.119859, Val Acc: 0.773196\n",
      "Epoch 16576 - Train Loss: 0.095588, Train Acc: 0.850000 | Val Loss: 0.119857, Val Acc: 0.773196\n",
      "Epoch 16577 - Train Loss: 0.095585, Train Acc: 0.850000 | Val Loss: 0.119855, Val Acc: 0.773196\n",
      "Epoch 16578 - Train Loss: 0.095582, Train Acc: 0.850000 | Val Loss: 0.119854, Val Acc: 0.773196\n",
      "Epoch 16579 - Train Loss: 0.095579, Train Acc: 0.850000 | Val Loss: 0.119852, Val Acc: 0.773196\n",
      "Epoch 16580 - Train Loss: 0.095576, Train Acc: 0.850000 | Val Loss: 0.119850, Val Acc: 0.773196\n",
      "Epoch 16581 - Train Loss: 0.095573, Train Acc: 0.850000 | Val Loss: 0.119848, Val Acc: 0.773196\n",
      "Epoch 16582 - Train Loss: 0.095569, Train Acc: 0.850000 | Val Loss: 0.119846, Val Acc: 0.773196\n",
      "Epoch 16583 - Train Loss: 0.095566, Train Acc: 0.850000 | Val Loss: 0.119844, Val Acc: 0.773196\n",
      "Epoch 16584 - Train Loss: 0.095563, Train Acc: 0.850000 | Val Loss: 0.119842, Val Acc: 0.773196\n",
      "Epoch 16585 - Train Loss: 0.095560, Train Acc: 0.850000 | Val Loss: 0.119840, Val Acc: 0.773196\n",
      "Epoch 16586 - Train Loss: 0.095557, Train Acc: 0.850000 | Val Loss: 0.119838, Val Acc: 0.773196\n",
      "Epoch 16587 - Train Loss: 0.095554, Train Acc: 0.850000 | Val Loss: 0.119837, Val Acc: 0.773196\n",
      "Epoch 16588 - Train Loss: 0.095551, Train Acc: 0.850000 | Val Loss: 0.119835, Val Acc: 0.773196\n",
      "Epoch 16589 - Train Loss: 0.095548, Train Acc: 0.850000 | Val Loss: 0.119833, Val Acc: 0.773196\n",
      "Epoch 16590 - Train Loss: 0.095544, Train Acc: 0.850000 | Val Loss: 0.119831, Val Acc: 0.773196\n",
      "Epoch 16591 - Train Loss: 0.095541, Train Acc: 0.850000 | Val Loss: 0.119829, Val Acc: 0.773196\n",
      "Epoch 16592 - Train Loss: 0.095538, Train Acc: 0.850000 | Val Loss: 0.119827, Val Acc: 0.773196\n",
      "Epoch 16593 - Train Loss: 0.095535, Train Acc: 0.850000 | Val Loss: 0.119825, Val Acc: 0.773196\n",
      "Epoch 16594 - Train Loss: 0.095532, Train Acc: 0.850000 | Val Loss: 0.119823, Val Acc: 0.773196\n",
      "Epoch 16595 - Train Loss: 0.095529, Train Acc: 0.850000 | Val Loss: 0.119822, Val Acc: 0.773196\n",
      "Epoch 16596 - Train Loss: 0.095526, Train Acc: 0.850000 | Val Loss: 0.119820, Val Acc: 0.773196\n",
      "Epoch 16597 - Train Loss: 0.095523, Train Acc: 0.850000 | Val Loss: 0.119818, Val Acc: 0.773196\n",
      "Epoch 16598 - Train Loss: 0.095519, Train Acc: 0.850000 | Val Loss: 0.119816, Val Acc: 0.773196\n",
      "Epoch 16599 - Train Loss: 0.095516, Train Acc: 0.850000 | Val Loss: 0.119814, Val Acc: 0.773196\n",
      "Epoch 16600 - Train Loss: 0.095513, Train Acc: 0.850000 | Val Loss: 0.119812, Val Acc: 0.773196\n",
      "Epoch 16601 - Train Loss: 0.095510, Train Acc: 0.850000 | Val Loss: 0.119810, Val Acc: 0.773196\n",
      "Epoch 16602 - Train Loss: 0.095507, Train Acc: 0.850000 | Val Loss: 0.119808, Val Acc: 0.773196\n",
      "Epoch 16603 - Train Loss: 0.095504, Train Acc: 0.850000 | Val Loss: 0.119807, Val Acc: 0.773196\n",
      "Epoch 16604 - Train Loss: 0.095501, Train Acc: 0.850000 | Val Loss: 0.119805, Val Acc: 0.773196\n",
      "Epoch 16605 - Train Loss: 0.095498, Train Acc: 0.850000 | Val Loss: 0.119803, Val Acc: 0.773196\n",
      "Epoch 16606 - Train Loss: 0.095494, Train Acc: 0.850000 | Val Loss: 0.119801, Val Acc: 0.773196\n",
      "Epoch 16607 - Train Loss: 0.095491, Train Acc: 0.850000 | Val Loss: 0.119799, Val Acc: 0.773196\n",
      "Epoch 16608 - Train Loss: 0.095488, Train Acc: 0.850000 | Val Loss: 0.119797, Val Acc: 0.773196\n",
      "Epoch 16609 - Train Loss: 0.095485, Train Acc: 0.850000 | Val Loss: 0.119795, Val Acc: 0.773196\n",
      "Epoch 16610 - Train Loss: 0.095482, Train Acc: 0.850000 | Val Loss: 0.119793, Val Acc: 0.773196\n",
      "Epoch 16611 - Train Loss: 0.095479, Train Acc: 0.850000 | Val Loss: 0.119792, Val Acc: 0.773196\n",
      "Epoch 16612 - Train Loss: 0.095476, Train Acc: 0.850000 | Val Loss: 0.119790, Val Acc: 0.773196\n",
      "Epoch 16613 - Train Loss: 0.095473, Train Acc: 0.850000 | Val Loss: 0.119788, Val Acc: 0.773196\n",
      "Epoch 16614 - Train Loss: 0.095470, Train Acc: 0.850000 | Val Loss: 0.119786, Val Acc: 0.773196\n",
      "Epoch 16615 - Train Loss: 0.095466, Train Acc: 0.850000 | Val Loss: 0.119784, Val Acc: 0.773196\n",
      "Epoch 16616 - Train Loss: 0.095463, Train Acc: 0.850000 | Val Loss: 0.119782, Val Acc: 0.773196\n",
      "Epoch 16617 - Train Loss: 0.095460, Train Acc: 0.850000 | Val Loss: 0.119780, Val Acc: 0.773196\n",
      "Epoch 16618 - Train Loss: 0.095457, Train Acc: 0.850000 | Val Loss: 0.119778, Val Acc: 0.773196\n",
      "Epoch 16619 - Train Loss: 0.095454, Train Acc: 0.850000 | Val Loss: 0.119777, Val Acc: 0.773196\n",
      "Epoch 16620 - Train Loss: 0.095451, Train Acc: 0.850000 | Val Loss: 0.119775, Val Acc: 0.773196\n",
      "Epoch 16621 - Train Loss: 0.095448, Train Acc: 0.850000 | Val Loss: 0.119773, Val Acc: 0.773196\n",
      "Epoch 16622 - Train Loss: 0.095445, Train Acc: 0.850000 | Val Loss: 0.119771, Val Acc: 0.773196\n",
      "Epoch 16623 - Train Loss: 0.095442, Train Acc: 0.850000 | Val Loss: 0.119769, Val Acc: 0.773196\n",
      "Epoch 16624 - Train Loss: 0.095438, Train Acc: 0.850000 | Val Loss: 0.119767, Val Acc: 0.773196\n",
      "Epoch 16625 - Train Loss: 0.095435, Train Acc: 0.850000 | Val Loss: 0.119765, Val Acc: 0.773196\n",
      "Epoch 16626 - Train Loss: 0.095432, Train Acc: 0.850000 | Val Loss: 0.119764, Val Acc: 0.773196\n",
      "Epoch 16627 - Train Loss: 0.095429, Train Acc: 0.850000 | Val Loss: 0.119762, Val Acc: 0.773196\n",
      "Epoch 16628 - Train Loss: 0.095426, Train Acc: 0.850000 | Val Loss: 0.119760, Val Acc: 0.773196\n",
      "Epoch 16629 - Train Loss: 0.095423, Train Acc: 0.850000 | Val Loss: 0.119758, Val Acc: 0.773196\n",
      "Epoch 16630 - Train Loss: 0.095420, Train Acc: 0.850000 | Val Loss: 0.119756, Val Acc: 0.773196\n",
      "Epoch 16631 - Train Loss: 0.095417, Train Acc: 0.850000 | Val Loss: 0.119754, Val Acc: 0.773196\n",
      "Epoch 16632 - Train Loss: 0.095414, Train Acc: 0.850000 | Val Loss: 0.119752, Val Acc: 0.773196\n",
      "Epoch 16633 - Train Loss: 0.095410, Train Acc: 0.850000 | Val Loss: 0.119750, Val Acc: 0.773196\n",
      "Epoch 16634 - Train Loss: 0.095407, Train Acc: 0.850000 | Val Loss: 0.119749, Val Acc: 0.773196\n",
      "Epoch 16635 - Train Loss: 0.095404, Train Acc: 0.850000 | Val Loss: 0.119747, Val Acc: 0.773196\n",
      "Epoch 16636 - Train Loss: 0.095401, Train Acc: 0.850000 | Val Loss: 0.119745, Val Acc: 0.773196\n",
      "Epoch 16637 - Train Loss: 0.095398, Train Acc: 0.850000 | Val Loss: 0.119743, Val Acc: 0.773196\n",
      "Epoch 16638 - Train Loss: 0.095395, Train Acc: 0.850000 | Val Loss: 0.119741, Val Acc: 0.773196\n",
      "Epoch 16639 - Train Loss: 0.095392, Train Acc: 0.850000 | Val Loss: 0.119739, Val Acc: 0.773196\n",
      "Epoch 16640 - Train Loss: 0.095389, Train Acc: 0.850000 | Val Loss: 0.119737, Val Acc: 0.773196\n",
      "Epoch 16641 - Train Loss: 0.095386, Train Acc: 0.850000 | Val Loss: 0.119736, Val Acc: 0.773196\n",
      "Epoch 16642 - Train Loss: 0.095382, Train Acc: 0.850000 | Val Loss: 0.119734, Val Acc: 0.773196\n",
      "Epoch 16643 - Train Loss: 0.095379, Train Acc: 0.850000 | Val Loss: 0.119732, Val Acc: 0.773196\n",
      "Epoch 16644 - Train Loss: 0.095376, Train Acc: 0.850000 | Val Loss: 0.119730, Val Acc: 0.773196\n",
      "Epoch 16645 - Train Loss: 0.095373, Train Acc: 0.850000 | Val Loss: 0.119728, Val Acc: 0.773196\n",
      "Epoch 16646 - Train Loss: 0.095370, Train Acc: 0.850000 | Val Loss: 0.119726, Val Acc: 0.773196\n",
      "Epoch 16647 - Train Loss: 0.095367, Train Acc: 0.850000 | Val Loss: 0.119724, Val Acc: 0.773196\n",
      "Epoch 16648 - Train Loss: 0.095364, Train Acc: 0.850000 | Val Loss: 0.119723, Val Acc: 0.773196\n",
      "Epoch 16649 - Train Loss: 0.095361, Train Acc: 0.850000 | Val Loss: 0.119721, Val Acc: 0.773196\n",
      "Epoch 16650 - Train Loss: 0.095358, Train Acc: 0.850000 | Val Loss: 0.119719, Val Acc: 0.773196\n",
      "Epoch 16651 - Train Loss: 0.095355, Train Acc: 0.850000 | Val Loss: 0.119717, Val Acc: 0.773196\n",
      "Epoch 16652 - Train Loss: 0.095351, Train Acc: 0.850000 | Val Loss: 0.119715, Val Acc: 0.773196\n",
      "Epoch 16653 - Train Loss: 0.095348, Train Acc: 0.850000 | Val Loss: 0.119713, Val Acc: 0.773196\n",
      "Epoch 16654 - Train Loss: 0.095345, Train Acc: 0.850000 | Val Loss: 0.119711, Val Acc: 0.773196\n",
      "Epoch 16655 - Train Loss: 0.095342, Train Acc: 0.850000 | Val Loss: 0.119709, Val Acc: 0.773196\n",
      "Epoch 16656 - Train Loss: 0.095339, Train Acc: 0.850000 | Val Loss: 0.119708, Val Acc: 0.773196\n",
      "Epoch 16657 - Train Loss: 0.095336, Train Acc: 0.850000 | Val Loss: 0.119706, Val Acc: 0.773196\n",
      "Epoch 16658 - Train Loss: 0.095333, Train Acc: 0.850000 | Val Loss: 0.119704, Val Acc: 0.773196\n",
      "Epoch 16659 - Train Loss: 0.095330, Train Acc: 0.850000 | Val Loss: 0.119702, Val Acc: 0.773196\n",
      "Epoch 16660 - Train Loss: 0.095327, Train Acc: 0.850000 | Val Loss: 0.119700, Val Acc: 0.773196\n",
      "Epoch 16661 - Train Loss: 0.095324, Train Acc: 0.850000 | Val Loss: 0.119698, Val Acc: 0.773196\n",
      "Epoch 16662 - Train Loss: 0.095320, Train Acc: 0.850000 | Val Loss: 0.119697, Val Acc: 0.773196\n",
      "Epoch 16663 - Train Loss: 0.095317, Train Acc: 0.850000 | Val Loss: 0.119695, Val Acc: 0.773196\n",
      "Epoch 16664 - Train Loss: 0.095314, Train Acc: 0.850000 | Val Loss: 0.119693, Val Acc: 0.773196\n",
      "Epoch 16665 - Train Loss: 0.095311, Train Acc: 0.850000 | Val Loss: 0.119691, Val Acc: 0.773196\n",
      "Epoch 16666 - Train Loss: 0.095308, Train Acc: 0.850000 | Val Loss: 0.119689, Val Acc: 0.773196\n",
      "Epoch 16667 - Train Loss: 0.095305, Train Acc: 0.850000 | Val Loss: 0.119687, Val Acc: 0.773196\n",
      "Epoch 16668 - Train Loss: 0.095302, Train Acc: 0.850000 | Val Loss: 0.119685, Val Acc: 0.773196\n",
      "Epoch 16669 - Train Loss: 0.095299, Train Acc: 0.850000 | Val Loss: 0.119684, Val Acc: 0.773196\n",
      "Epoch 16670 - Train Loss: 0.095296, Train Acc: 0.850000 | Val Loss: 0.119682, Val Acc: 0.773196\n",
      "Epoch 16671 - Train Loss: 0.095293, Train Acc: 0.850000 | Val Loss: 0.119680, Val Acc: 0.773196\n",
      "Epoch 16672 - Train Loss: 0.095289, Train Acc: 0.850000 | Val Loss: 0.119678, Val Acc: 0.773196\n",
      "Epoch 16673 - Train Loss: 0.095286, Train Acc: 0.850000 | Val Loss: 0.119676, Val Acc: 0.773196\n",
      "Epoch 16674 - Train Loss: 0.095283, Train Acc: 0.850000 | Val Loss: 0.119674, Val Acc: 0.773196\n",
      "Epoch 16675 - Train Loss: 0.095280, Train Acc: 0.850000 | Val Loss: 0.119672, Val Acc: 0.773196\n",
      "Epoch 16676 - Train Loss: 0.095277, Train Acc: 0.850000 | Val Loss: 0.119671, Val Acc: 0.773196\n",
      "Epoch 16677 - Train Loss: 0.095274, Train Acc: 0.850000 | Val Loss: 0.119669, Val Acc: 0.773196\n",
      "Epoch 16678 - Train Loss: 0.095271, Train Acc: 0.850000 | Val Loss: 0.119667, Val Acc: 0.773196\n",
      "Epoch 16679 - Train Loss: 0.095268, Train Acc: 0.850000 | Val Loss: 0.119665, Val Acc: 0.773196\n",
      "Epoch 16680 - Train Loss: 0.095265, Train Acc: 0.850000 | Val Loss: 0.119663, Val Acc: 0.773196\n",
      "Epoch 16681 - Train Loss: 0.095262, Train Acc: 0.850000 | Val Loss: 0.119661, Val Acc: 0.773196\n",
      "Epoch 16682 - Train Loss: 0.095259, Train Acc: 0.850000 | Val Loss: 0.119659, Val Acc: 0.773196\n",
      "Epoch 16683 - Train Loss: 0.095255, Train Acc: 0.850000 | Val Loss: 0.119658, Val Acc: 0.773196\n",
      "Epoch 16684 - Train Loss: 0.095252, Train Acc: 0.850000 | Val Loss: 0.119656, Val Acc: 0.773196\n",
      "Epoch 16685 - Train Loss: 0.095249, Train Acc: 0.850000 | Val Loss: 0.119654, Val Acc: 0.773196\n",
      "Epoch 16686 - Train Loss: 0.095246, Train Acc: 0.850000 | Val Loss: 0.119652, Val Acc: 0.773196\n",
      "Epoch 16687 - Train Loss: 0.095243, Train Acc: 0.850000 | Val Loss: 0.119650, Val Acc: 0.773196\n",
      "Epoch 16688 - Train Loss: 0.095240, Train Acc: 0.850000 | Val Loss: 0.119648, Val Acc: 0.773196\n",
      "Epoch 16689 - Train Loss: 0.095237, Train Acc: 0.850000 | Val Loss: 0.119647, Val Acc: 0.773196\n",
      "Epoch 16690 - Train Loss: 0.095234, Train Acc: 0.850000 | Val Loss: 0.119645, Val Acc: 0.773196\n",
      "Epoch 16691 - Train Loss: 0.095231, Train Acc: 0.850000 | Val Loss: 0.119643, Val Acc: 0.773196\n",
      "Epoch 16692 - Train Loss: 0.095228, Train Acc: 0.850000 | Val Loss: 0.119641, Val Acc: 0.773196\n",
      "Epoch 16693 - Train Loss: 0.095225, Train Acc: 0.850000 | Val Loss: 0.119639, Val Acc: 0.773196\n",
      "Epoch 16694 - Train Loss: 0.095221, Train Acc: 0.850000 | Val Loss: 0.119637, Val Acc: 0.773196\n",
      "Epoch 16695 - Train Loss: 0.095218, Train Acc: 0.850000 | Val Loss: 0.119635, Val Acc: 0.773196\n",
      "Epoch 16696 - Train Loss: 0.095215, Train Acc: 0.850000 | Val Loss: 0.119634, Val Acc: 0.773196\n",
      "Epoch 16697 - Train Loss: 0.095212, Train Acc: 0.850000 | Val Loss: 0.119632, Val Acc: 0.773196\n",
      "Epoch 16698 - Train Loss: 0.095209, Train Acc: 0.850000 | Val Loss: 0.119630, Val Acc: 0.773196\n",
      "Epoch 16699 - Train Loss: 0.095206, Train Acc: 0.850000 | Val Loss: 0.119628, Val Acc: 0.773196\n",
      "Epoch 16700 - Train Loss: 0.095203, Train Acc: 0.850000 | Val Loss: 0.119626, Val Acc: 0.773196\n",
      "Epoch 16701 - Train Loss: 0.095200, Train Acc: 0.850000 | Val Loss: 0.119624, Val Acc: 0.773196\n",
      "Epoch 16702 - Train Loss: 0.095197, Train Acc: 0.850000 | Val Loss: 0.119623, Val Acc: 0.773196\n",
      "Epoch 16703 - Train Loss: 0.095194, Train Acc: 0.850000 | Val Loss: 0.119621, Val Acc: 0.773196\n",
      "Epoch 16704 - Train Loss: 0.095191, Train Acc: 0.850000 | Val Loss: 0.119619, Val Acc: 0.773196\n",
      "Epoch 16705 - Train Loss: 0.095188, Train Acc: 0.850000 | Val Loss: 0.119617, Val Acc: 0.773196\n",
      "Epoch 16706 - Train Loss: 0.095184, Train Acc: 0.850000 | Val Loss: 0.119615, Val Acc: 0.773196\n",
      "Epoch 16707 - Train Loss: 0.095181, Train Acc: 0.850000 | Val Loss: 0.119613, Val Acc: 0.773196\n",
      "Epoch 16708 - Train Loss: 0.095178, Train Acc: 0.850000 | Val Loss: 0.119612, Val Acc: 0.773196\n",
      "Epoch 16709 - Train Loss: 0.095175, Train Acc: 0.850000 | Val Loss: 0.119610, Val Acc: 0.773196\n",
      "Epoch 16710 - Train Loss: 0.095172, Train Acc: 0.850000 | Val Loss: 0.119608, Val Acc: 0.773196\n",
      "Epoch 16711 - Train Loss: 0.095169, Train Acc: 0.850000 | Val Loss: 0.119606, Val Acc: 0.773196\n",
      "Epoch 16712 - Train Loss: 0.095166, Train Acc: 0.850000 | Val Loss: 0.119604, Val Acc: 0.773196\n",
      "Epoch 16713 - Train Loss: 0.095163, Train Acc: 0.850000 | Val Loss: 0.119602, Val Acc: 0.773196\n",
      "Epoch 16714 - Train Loss: 0.095160, Train Acc: 0.850000 | Val Loss: 0.119600, Val Acc: 0.773196\n",
      "Epoch 16715 - Train Loss: 0.095157, Train Acc: 0.850000 | Val Loss: 0.119599, Val Acc: 0.773196\n",
      "Epoch 16716 - Train Loss: 0.095154, Train Acc: 0.850000 | Val Loss: 0.119597, Val Acc: 0.773196\n",
      "Epoch 16717 - Train Loss: 0.095151, Train Acc: 0.850000 | Val Loss: 0.119595, Val Acc: 0.773196\n",
      "Epoch 16718 - Train Loss: 0.095147, Train Acc: 0.850000 | Val Loss: 0.119593, Val Acc: 0.773196\n",
      "Epoch 16719 - Train Loss: 0.095144, Train Acc: 0.850000 | Val Loss: 0.119591, Val Acc: 0.773196\n",
      "Epoch 16720 - Train Loss: 0.095141, Train Acc: 0.850000 | Val Loss: 0.119589, Val Acc: 0.773196\n",
      "Epoch 16721 - Train Loss: 0.095138, Train Acc: 0.850000 | Val Loss: 0.119588, Val Acc: 0.773196\n",
      "Epoch 16722 - Train Loss: 0.095135, Train Acc: 0.850000 | Val Loss: 0.119586, Val Acc: 0.773196\n",
      "Epoch 16723 - Train Loss: 0.095132, Train Acc: 0.850000 | Val Loss: 0.119584, Val Acc: 0.773196\n",
      "Epoch 16724 - Train Loss: 0.095129, Train Acc: 0.850000 | Val Loss: 0.119582, Val Acc: 0.773196\n",
      "Epoch 16725 - Train Loss: 0.095126, Train Acc: 0.850000 | Val Loss: 0.119580, Val Acc: 0.773196\n",
      "Epoch 16726 - Train Loss: 0.095123, Train Acc: 0.850000 | Val Loss: 0.119578, Val Acc: 0.773196\n",
      "Epoch 16727 - Train Loss: 0.095120, Train Acc: 0.850000 | Val Loss: 0.119577, Val Acc: 0.773196\n",
      "Epoch 16728 - Train Loss: 0.095117, Train Acc: 0.850000 | Val Loss: 0.119575, Val Acc: 0.773196\n",
      "Epoch 16729 - Train Loss: 0.095114, Train Acc: 0.850000 | Val Loss: 0.119573, Val Acc: 0.773196\n",
      "Epoch 16730 - Train Loss: 0.095111, Train Acc: 0.850000 | Val Loss: 0.119571, Val Acc: 0.773196\n",
      "Epoch 16731 - Train Loss: 0.095107, Train Acc: 0.850000 | Val Loss: 0.119569, Val Acc: 0.773196\n",
      "Epoch 16732 - Train Loss: 0.095104, Train Acc: 0.850000 | Val Loss: 0.119567, Val Acc: 0.773196\n",
      "Epoch 16733 - Train Loss: 0.095101, Train Acc: 0.850000 | Val Loss: 0.119566, Val Acc: 0.773196\n",
      "Epoch 16734 - Train Loss: 0.095098, Train Acc: 0.850000 | Val Loss: 0.119564, Val Acc: 0.773196\n",
      "Epoch 16735 - Train Loss: 0.095095, Train Acc: 0.850000 | Val Loss: 0.119562, Val Acc: 0.773196\n",
      "Epoch 16736 - Train Loss: 0.095092, Train Acc: 0.850000 | Val Loss: 0.119560, Val Acc: 0.773196\n",
      "Epoch 16737 - Train Loss: 0.095089, Train Acc: 0.850000 | Val Loss: 0.119558, Val Acc: 0.773196\n",
      "Epoch 16738 - Train Loss: 0.095086, Train Acc: 0.850000 | Val Loss: 0.119556, Val Acc: 0.773196\n",
      "Epoch 16739 - Train Loss: 0.095083, Train Acc: 0.850000 | Val Loss: 0.119555, Val Acc: 0.773196\n",
      "Epoch 16740 - Train Loss: 0.095080, Train Acc: 0.850000 | Val Loss: 0.119553, Val Acc: 0.773196\n",
      "Epoch 16741 - Train Loss: 0.095077, Train Acc: 0.850000 | Val Loss: 0.119551, Val Acc: 0.773196\n",
      "Epoch 16742 - Train Loss: 0.095074, Train Acc: 0.850000 | Val Loss: 0.119549, Val Acc: 0.773196\n",
      "Epoch 16743 - Train Loss: 0.095071, Train Acc: 0.850000 | Val Loss: 0.119547, Val Acc: 0.773196\n",
      "Epoch 16744 - Train Loss: 0.095068, Train Acc: 0.850000 | Val Loss: 0.119545, Val Acc: 0.773196\n",
      "Epoch 16745 - Train Loss: 0.095064, Train Acc: 0.850000 | Val Loss: 0.119544, Val Acc: 0.773196\n",
      "Epoch 16746 - Train Loss: 0.095061, Train Acc: 0.850000 | Val Loss: 0.119542, Val Acc: 0.773196\n",
      "Epoch 16747 - Train Loss: 0.095058, Train Acc: 0.850000 | Val Loss: 0.119540, Val Acc: 0.773196\n",
      "Epoch 16748 - Train Loss: 0.095055, Train Acc: 0.850000 | Val Loss: 0.119538, Val Acc: 0.773196\n",
      "Epoch 16749 - Train Loss: 0.095052, Train Acc: 0.850000 | Val Loss: 0.119536, Val Acc: 0.773196\n",
      "Epoch 16750 - Train Loss: 0.095049, Train Acc: 0.850000 | Val Loss: 0.119535, Val Acc: 0.773196\n",
      "Epoch 16751 - Train Loss: 0.095046, Train Acc: 0.850000 | Val Loss: 0.119533, Val Acc: 0.773196\n",
      "Epoch 16752 - Train Loss: 0.095043, Train Acc: 0.850000 | Val Loss: 0.119531, Val Acc: 0.773196\n",
      "Epoch 16753 - Train Loss: 0.095040, Train Acc: 0.850000 | Val Loss: 0.119529, Val Acc: 0.773196\n",
      "Epoch 16754 - Train Loss: 0.095037, Train Acc: 0.850000 | Val Loss: 0.119527, Val Acc: 0.773196\n",
      "Epoch 16755 - Train Loss: 0.095034, Train Acc: 0.850000 | Val Loss: 0.119525, Val Acc: 0.773196\n",
      "Epoch 16756 - Train Loss: 0.095031, Train Acc: 0.850000 | Val Loss: 0.119524, Val Acc: 0.773196\n",
      "Epoch 16757 - Train Loss: 0.095028, Train Acc: 0.850000 | Val Loss: 0.119522, Val Acc: 0.773196\n",
      "Epoch 16758 - Train Loss: 0.095025, Train Acc: 0.850000 | Val Loss: 0.119520, Val Acc: 0.773196\n",
      "Epoch 16759 - Train Loss: 0.095022, Train Acc: 0.850000 | Val Loss: 0.119518, Val Acc: 0.773196\n",
      "Epoch 16760 - Train Loss: 0.095018, Train Acc: 0.850000 | Val Loss: 0.119516, Val Acc: 0.773196\n",
      "Epoch 16761 - Train Loss: 0.095015, Train Acc: 0.850000 | Val Loss: 0.119514, Val Acc: 0.773196\n",
      "Epoch 16762 - Train Loss: 0.095012, Train Acc: 0.850000 | Val Loss: 0.119513, Val Acc: 0.773196\n",
      "Epoch 16763 - Train Loss: 0.095009, Train Acc: 0.850000 | Val Loss: 0.119511, Val Acc: 0.773196\n",
      "Epoch 16764 - Train Loss: 0.095006, Train Acc: 0.850000 | Val Loss: 0.119509, Val Acc: 0.773196\n",
      "Epoch 16765 - Train Loss: 0.095003, Train Acc: 0.850000 | Val Loss: 0.119507, Val Acc: 0.773196\n",
      "Epoch 16766 - Train Loss: 0.095000, Train Acc: 0.850000 | Val Loss: 0.119505, Val Acc: 0.773196\n",
      "Epoch 16767 - Train Loss: 0.094997, Train Acc: 0.851282 | Val Loss: 0.119504, Val Acc: 0.773196\n",
      "Epoch 16768 - Train Loss: 0.094994, Train Acc: 0.851282 | Val Loss: 0.119502, Val Acc: 0.773196\n",
      "Epoch 16769 - Train Loss: 0.094991, Train Acc: 0.851282 | Val Loss: 0.119500, Val Acc: 0.773196\n",
      "Epoch 16770 - Train Loss: 0.094988, Train Acc: 0.851282 | Val Loss: 0.119498, Val Acc: 0.773196\n",
      "Epoch 16771 - Train Loss: 0.094985, Train Acc: 0.851282 | Val Loss: 0.119496, Val Acc: 0.773196\n",
      "Epoch 16772 - Train Loss: 0.094982, Train Acc: 0.851282 | Val Loss: 0.119494, Val Acc: 0.773196\n",
      "Epoch 16773 - Train Loss: 0.094979, Train Acc: 0.851282 | Val Loss: 0.119493, Val Acc: 0.773196\n",
      "Epoch 16774 - Train Loss: 0.094976, Train Acc: 0.851282 | Val Loss: 0.119491, Val Acc: 0.773196\n",
      "Epoch 16775 - Train Loss: 0.094973, Train Acc: 0.851282 | Val Loss: 0.119489, Val Acc: 0.773196\n",
      "Epoch 16776 - Train Loss: 0.094969, Train Acc: 0.851282 | Val Loss: 0.119487, Val Acc: 0.773196\n",
      "Epoch 16777 - Train Loss: 0.094966, Train Acc: 0.851282 | Val Loss: 0.119485, Val Acc: 0.773196\n",
      "Epoch 16778 - Train Loss: 0.094963, Train Acc: 0.851282 | Val Loss: 0.119484, Val Acc: 0.773196\n",
      "Epoch 16779 - Train Loss: 0.094960, Train Acc: 0.851282 | Val Loss: 0.119482, Val Acc: 0.773196\n",
      "Epoch 16780 - Train Loss: 0.094957, Train Acc: 0.851282 | Val Loss: 0.119480, Val Acc: 0.773196\n",
      "Epoch 16781 - Train Loss: 0.094954, Train Acc: 0.851282 | Val Loss: 0.119478, Val Acc: 0.773196\n",
      "Epoch 16782 - Train Loss: 0.094951, Train Acc: 0.851282 | Val Loss: 0.119476, Val Acc: 0.773196\n",
      "Epoch 16783 - Train Loss: 0.094948, Train Acc: 0.851282 | Val Loss: 0.119474, Val Acc: 0.773196\n",
      "Epoch 16784 - Train Loss: 0.094945, Train Acc: 0.851282 | Val Loss: 0.119473, Val Acc: 0.773196\n",
      "Epoch 16785 - Train Loss: 0.094942, Train Acc: 0.851282 | Val Loss: 0.119471, Val Acc: 0.773196\n",
      "Epoch 16786 - Train Loss: 0.094939, Train Acc: 0.851282 | Val Loss: 0.119469, Val Acc: 0.773196\n",
      "Epoch 16787 - Train Loss: 0.094936, Train Acc: 0.851282 | Val Loss: 0.119467, Val Acc: 0.773196\n",
      "Epoch 16788 - Train Loss: 0.094933, Train Acc: 0.851282 | Val Loss: 0.119465, Val Acc: 0.773196\n",
      "Epoch 16789 - Train Loss: 0.094930, Train Acc: 0.851282 | Val Loss: 0.119464, Val Acc: 0.773196\n",
      "Epoch 16790 - Train Loss: 0.094927, Train Acc: 0.851282 | Val Loss: 0.119462, Val Acc: 0.773196\n",
      "Epoch 16791 - Train Loss: 0.094924, Train Acc: 0.851282 | Val Loss: 0.119460, Val Acc: 0.773196\n",
      "Epoch 16792 - Train Loss: 0.094921, Train Acc: 0.851282 | Val Loss: 0.119458, Val Acc: 0.773196\n",
      "Epoch 16793 - Train Loss: 0.094917, Train Acc: 0.851282 | Val Loss: 0.119456, Val Acc: 0.773196\n",
      "Epoch 16794 - Train Loss: 0.094914, Train Acc: 0.851282 | Val Loss: 0.119455, Val Acc: 0.773196\n",
      "Epoch 16795 - Train Loss: 0.094911, Train Acc: 0.851282 | Val Loss: 0.119453, Val Acc: 0.773196\n",
      "Epoch 16796 - Train Loss: 0.094908, Train Acc: 0.851282 | Val Loss: 0.119451, Val Acc: 0.773196\n",
      "Epoch 16797 - Train Loss: 0.094905, Train Acc: 0.851282 | Val Loss: 0.119449, Val Acc: 0.773196\n",
      "Epoch 16798 - Train Loss: 0.094902, Train Acc: 0.851282 | Val Loss: 0.119447, Val Acc: 0.773196\n",
      "Epoch 16799 - Train Loss: 0.094899, Train Acc: 0.851282 | Val Loss: 0.119445, Val Acc: 0.773196\n",
      "Epoch 16800 - Train Loss: 0.094896, Train Acc: 0.851282 | Val Loss: 0.119444, Val Acc: 0.773196\n",
      "Epoch 16801 - Train Loss: 0.094893, Train Acc: 0.851282 | Val Loss: 0.119442, Val Acc: 0.773196\n",
      "Epoch 16802 - Train Loss: 0.094890, Train Acc: 0.851282 | Val Loss: 0.119440, Val Acc: 0.773196\n",
      "Epoch 16803 - Train Loss: 0.094887, Train Acc: 0.851282 | Val Loss: 0.119438, Val Acc: 0.773196\n",
      "Epoch 16804 - Train Loss: 0.094884, Train Acc: 0.851282 | Val Loss: 0.119436, Val Acc: 0.773196\n",
      "Epoch 16805 - Train Loss: 0.094881, Train Acc: 0.851282 | Val Loss: 0.119435, Val Acc: 0.773196\n",
      "Epoch 16806 - Train Loss: 0.094878, Train Acc: 0.851282 | Val Loss: 0.119433, Val Acc: 0.773196\n",
      "Epoch 16807 - Train Loss: 0.094875, Train Acc: 0.851282 | Val Loss: 0.119431, Val Acc: 0.773196\n",
      "Epoch 16808 - Train Loss: 0.094872, Train Acc: 0.851282 | Val Loss: 0.119429, Val Acc: 0.773196\n",
      "Epoch 16809 - Train Loss: 0.094869, Train Acc: 0.851282 | Val Loss: 0.119427, Val Acc: 0.773196\n",
      "Epoch 16810 - Train Loss: 0.094866, Train Acc: 0.851282 | Val Loss: 0.119426, Val Acc: 0.773196\n",
      "Epoch 16811 - Train Loss: 0.094863, Train Acc: 0.851282 | Val Loss: 0.119424, Val Acc: 0.773196\n",
      "Epoch 16812 - Train Loss: 0.094860, Train Acc: 0.851282 | Val Loss: 0.119422, Val Acc: 0.773196\n",
      "Epoch 16813 - Train Loss: 0.094856, Train Acc: 0.851282 | Val Loss: 0.119420, Val Acc: 0.773196\n",
      "Epoch 16814 - Train Loss: 0.094853, Train Acc: 0.851282 | Val Loss: 0.119418, Val Acc: 0.773196\n",
      "Epoch 16815 - Train Loss: 0.094850, Train Acc: 0.851282 | Val Loss: 0.119417, Val Acc: 0.773196\n",
      "Epoch 16816 - Train Loss: 0.094847, Train Acc: 0.851282 | Val Loss: 0.119415, Val Acc: 0.773196\n",
      "Epoch 16817 - Train Loss: 0.094844, Train Acc: 0.851282 | Val Loss: 0.119413, Val Acc: 0.773196\n",
      "Epoch 16818 - Train Loss: 0.094841, Train Acc: 0.851282 | Val Loss: 0.119411, Val Acc: 0.773196\n",
      "Epoch 16819 - Train Loss: 0.094838, Train Acc: 0.851282 | Val Loss: 0.119409, Val Acc: 0.773196\n",
      "Epoch 16820 - Train Loss: 0.094835, Train Acc: 0.851282 | Val Loss: 0.119408, Val Acc: 0.773196\n",
      "Epoch 16821 - Train Loss: 0.094832, Train Acc: 0.851282 | Val Loss: 0.119406, Val Acc: 0.773196\n",
      "Epoch 16822 - Train Loss: 0.094829, Train Acc: 0.851282 | Val Loss: 0.119404, Val Acc: 0.773196\n",
      "Epoch 16823 - Train Loss: 0.094826, Train Acc: 0.851282 | Val Loss: 0.119402, Val Acc: 0.773196\n",
      "Epoch 16824 - Train Loss: 0.094823, Train Acc: 0.851282 | Val Loss: 0.119400, Val Acc: 0.773196\n",
      "Epoch 16825 - Train Loss: 0.094820, Train Acc: 0.851282 | Val Loss: 0.119399, Val Acc: 0.773196\n",
      "Epoch 16826 - Train Loss: 0.094817, Train Acc: 0.851282 | Val Loss: 0.119397, Val Acc: 0.773196\n",
      "Epoch 16827 - Train Loss: 0.094814, Train Acc: 0.851282 | Val Loss: 0.119395, Val Acc: 0.773196\n",
      "Epoch 16828 - Train Loss: 0.094811, Train Acc: 0.851282 | Val Loss: 0.119393, Val Acc: 0.773196\n",
      "Epoch 16829 - Train Loss: 0.094808, Train Acc: 0.851282 | Val Loss: 0.119391, Val Acc: 0.773196\n",
      "Epoch 16830 - Train Loss: 0.094805, Train Acc: 0.851282 | Val Loss: 0.119390, Val Acc: 0.773196\n",
      "Epoch 16831 - Train Loss: 0.094802, Train Acc: 0.851282 | Val Loss: 0.119388, Val Acc: 0.773196\n",
      "Epoch 16832 - Train Loss: 0.094799, Train Acc: 0.851282 | Val Loss: 0.119386, Val Acc: 0.773196\n",
      "Epoch 16833 - Train Loss: 0.094796, Train Acc: 0.851282 | Val Loss: 0.119384, Val Acc: 0.773196\n",
      "Epoch 16834 - Train Loss: 0.094793, Train Acc: 0.851282 | Val Loss: 0.119382, Val Acc: 0.773196\n",
      "Epoch 16835 - Train Loss: 0.094790, Train Acc: 0.851282 | Val Loss: 0.119381, Val Acc: 0.773196\n",
      "Epoch 16836 - Train Loss: 0.094787, Train Acc: 0.851282 | Val Loss: 0.119379, Val Acc: 0.773196\n",
      "Epoch 16837 - Train Loss: 0.094783, Train Acc: 0.851282 | Val Loss: 0.119377, Val Acc: 0.773196\n",
      "Epoch 16838 - Train Loss: 0.094780, Train Acc: 0.851282 | Val Loss: 0.119375, Val Acc: 0.773196\n",
      "Epoch 16839 - Train Loss: 0.094777, Train Acc: 0.851282 | Val Loss: 0.119373, Val Acc: 0.773196\n",
      "Epoch 16840 - Train Loss: 0.094774, Train Acc: 0.851282 | Val Loss: 0.119372, Val Acc: 0.773196\n",
      "Epoch 16841 - Train Loss: 0.094771, Train Acc: 0.851282 | Val Loss: 0.119370, Val Acc: 0.773196\n",
      "Epoch 16842 - Train Loss: 0.094768, Train Acc: 0.851282 | Val Loss: 0.119368, Val Acc: 0.773196\n",
      "Epoch 16843 - Train Loss: 0.094765, Train Acc: 0.851282 | Val Loss: 0.119366, Val Acc: 0.773196\n",
      "Epoch 16844 - Train Loss: 0.094762, Train Acc: 0.851282 | Val Loss: 0.119364, Val Acc: 0.773196\n",
      "Epoch 16845 - Train Loss: 0.094759, Train Acc: 0.851282 | Val Loss: 0.119363, Val Acc: 0.773196\n",
      "Epoch 16846 - Train Loss: 0.094756, Train Acc: 0.851282 | Val Loss: 0.119361, Val Acc: 0.773196\n",
      "Epoch 16847 - Train Loss: 0.094753, Train Acc: 0.851282 | Val Loss: 0.119359, Val Acc: 0.773196\n",
      "Epoch 16848 - Train Loss: 0.094750, Train Acc: 0.851282 | Val Loss: 0.119357, Val Acc: 0.773196\n",
      "Epoch 16849 - Train Loss: 0.094747, Train Acc: 0.851282 | Val Loss: 0.119355, Val Acc: 0.773196\n",
      "Epoch 16850 - Train Loss: 0.094744, Train Acc: 0.851282 | Val Loss: 0.119354, Val Acc: 0.773196\n",
      "Epoch 16851 - Train Loss: 0.094741, Train Acc: 0.851282 | Val Loss: 0.119352, Val Acc: 0.773196\n",
      "Epoch 16852 - Train Loss: 0.094738, Train Acc: 0.851282 | Val Loss: 0.119350, Val Acc: 0.773196\n",
      "Epoch 16853 - Train Loss: 0.094735, Train Acc: 0.851282 | Val Loss: 0.119348, Val Acc: 0.773196\n",
      "Epoch 16854 - Train Loss: 0.094732, Train Acc: 0.851282 | Val Loss: 0.119346, Val Acc: 0.773196\n",
      "Epoch 16855 - Train Loss: 0.094729, Train Acc: 0.851282 | Val Loss: 0.119345, Val Acc: 0.773196\n",
      "Epoch 16856 - Train Loss: 0.094726, Train Acc: 0.851282 | Val Loss: 0.119343, Val Acc: 0.773196\n",
      "Epoch 16857 - Train Loss: 0.094723, Train Acc: 0.851282 | Val Loss: 0.119341, Val Acc: 0.773196\n",
      "Epoch 16858 - Train Loss: 0.094720, Train Acc: 0.851282 | Val Loss: 0.119339, Val Acc: 0.773196\n",
      "Epoch 16859 - Train Loss: 0.094717, Train Acc: 0.851282 | Val Loss: 0.119337, Val Acc: 0.773196\n",
      "Epoch 16860 - Train Loss: 0.094714, Train Acc: 0.851282 | Val Loss: 0.119336, Val Acc: 0.773196\n",
      "Epoch 16861 - Train Loss: 0.094711, Train Acc: 0.851282 | Val Loss: 0.119334, Val Acc: 0.773196\n",
      "Epoch 16862 - Train Loss: 0.094708, Train Acc: 0.851282 | Val Loss: 0.119332, Val Acc: 0.773196\n",
      "Epoch 16863 - Train Loss: 0.094705, Train Acc: 0.851282 | Val Loss: 0.119330, Val Acc: 0.773196\n",
      "Epoch 16864 - Train Loss: 0.094702, Train Acc: 0.851282 | Val Loss: 0.119329, Val Acc: 0.773196\n",
      "Epoch 16865 - Train Loss: 0.094699, Train Acc: 0.851282 | Val Loss: 0.119327, Val Acc: 0.773196\n",
      "Epoch 16866 - Train Loss: 0.094696, Train Acc: 0.851282 | Val Loss: 0.119325, Val Acc: 0.773196\n",
      "Epoch 16867 - Train Loss: 0.094692, Train Acc: 0.851282 | Val Loss: 0.119323, Val Acc: 0.773196\n",
      "Epoch 16868 - Train Loss: 0.094689, Train Acc: 0.851282 | Val Loss: 0.119321, Val Acc: 0.773196\n",
      "Epoch 16869 - Train Loss: 0.094686, Train Acc: 0.851282 | Val Loss: 0.119320, Val Acc: 0.773196\n",
      "Epoch 16870 - Train Loss: 0.094683, Train Acc: 0.851282 | Val Loss: 0.119318, Val Acc: 0.773196\n",
      "Epoch 16871 - Train Loss: 0.094680, Train Acc: 0.851282 | Val Loss: 0.119316, Val Acc: 0.773196\n",
      "Epoch 16872 - Train Loss: 0.094677, Train Acc: 0.851282 | Val Loss: 0.119314, Val Acc: 0.773196\n",
      "Epoch 16873 - Train Loss: 0.094674, Train Acc: 0.851282 | Val Loss: 0.119312, Val Acc: 0.773196\n",
      "Epoch 16874 - Train Loss: 0.094671, Train Acc: 0.851282 | Val Loss: 0.119311, Val Acc: 0.773196\n",
      "Epoch 16875 - Train Loss: 0.094668, Train Acc: 0.851282 | Val Loss: 0.119309, Val Acc: 0.773196\n",
      "Epoch 16876 - Train Loss: 0.094665, Train Acc: 0.851282 | Val Loss: 0.119307, Val Acc: 0.773196\n",
      "Epoch 16877 - Train Loss: 0.094662, Train Acc: 0.851282 | Val Loss: 0.119305, Val Acc: 0.773196\n",
      "Epoch 16878 - Train Loss: 0.094659, Train Acc: 0.851282 | Val Loss: 0.119304, Val Acc: 0.773196\n",
      "Epoch 16879 - Train Loss: 0.094656, Train Acc: 0.851282 | Val Loss: 0.119302, Val Acc: 0.773196\n",
      "Epoch 16880 - Train Loss: 0.094653, Train Acc: 0.851282 | Val Loss: 0.119300, Val Acc: 0.773196\n",
      "Epoch 16881 - Train Loss: 0.094650, Train Acc: 0.851282 | Val Loss: 0.119298, Val Acc: 0.773196\n",
      "Epoch 16882 - Train Loss: 0.094647, Train Acc: 0.851282 | Val Loss: 0.119296, Val Acc: 0.773196\n",
      "Epoch 16883 - Train Loss: 0.094644, Train Acc: 0.851282 | Val Loss: 0.119295, Val Acc: 0.773196\n",
      "Epoch 16884 - Train Loss: 0.094641, Train Acc: 0.851282 | Val Loss: 0.119293, Val Acc: 0.773196\n",
      "Epoch 16885 - Train Loss: 0.094638, Train Acc: 0.851282 | Val Loss: 0.119291, Val Acc: 0.773196\n",
      "Epoch 16886 - Train Loss: 0.094635, Train Acc: 0.851282 | Val Loss: 0.119289, Val Acc: 0.773196\n",
      "Epoch 16887 - Train Loss: 0.094632, Train Acc: 0.851282 | Val Loss: 0.119288, Val Acc: 0.773196\n",
      "Epoch 16888 - Train Loss: 0.094629, Train Acc: 0.851282 | Val Loss: 0.119286, Val Acc: 0.773196\n",
      "Epoch 16889 - Train Loss: 0.094626, Train Acc: 0.851282 | Val Loss: 0.119284, Val Acc: 0.773196\n",
      "Epoch 16890 - Train Loss: 0.094623, Train Acc: 0.851282 | Val Loss: 0.119282, Val Acc: 0.773196\n",
      "Epoch 16891 - Train Loss: 0.094620, Train Acc: 0.851282 | Val Loss: 0.119280, Val Acc: 0.773196\n",
      "Epoch 16892 - Train Loss: 0.094617, Train Acc: 0.851282 | Val Loss: 0.119279, Val Acc: 0.773196\n",
      "Epoch 16893 - Train Loss: 0.094614, Train Acc: 0.851282 | Val Loss: 0.119277, Val Acc: 0.773196\n",
      "Epoch 16894 - Train Loss: 0.094611, Train Acc: 0.851282 | Val Loss: 0.119275, Val Acc: 0.773196\n",
      "Epoch 16895 - Train Loss: 0.094608, Train Acc: 0.851282 | Val Loss: 0.119273, Val Acc: 0.773196\n",
      "Epoch 16896 - Train Loss: 0.094605, Train Acc: 0.851282 | Val Loss: 0.119271, Val Acc: 0.773196\n",
      "Epoch 16897 - Train Loss: 0.094602, Train Acc: 0.851282 | Val Loss: 0.119270, Val Acc: 0.773196\n",
      "Epoch 16898 - Train Loss: 0.094599, Train Acc: 0.851282 | Val Loss: 0.119268, Val Acc: 0.773196\n",
      "Epoch 16899 - Train Loss: 0.094596, Train Acc: 0.851282 | Val Loss: 0.119266, Val Acc: 0.773196\n",
      "Epoch 16900 - Train Loss: 0.094593, Train Acc: 0.851282 | Val Loss: 0.119264, Val Acc: 0.773196\n",
      "Epoch 16901 - Train Loss: 0.094590, Train Acc: 0.851282 | Val Loss: 0.119263, Val Acc: 0.773196\n",
      "Epoch 16902 - Train Loss: 0.094587, Train Acc: 0.851282 | Val Loss: 0.119261, Val Acc: 0.773196\n",
      "Epoch 16903 - Train Loss: 0.094584, Train Acc: 0.851282 | Val Loss: 0.119259, Val Acc: 0.773196\n",
      "Epoch 16904 - Train Loss: 0.094581, Train Acc: 0.851282 | Val Loss: 0.119257, Val Acc: 0.773196\n",
      "Epoch 16905 - Train Loss: 0.094578, Train Acc: 0.851282 | Val Loss: 0.119256, Val Acc: 0.773196\n",
      "Epoch 16906 - Train Loss: 0.094575, Train Acc: 0.851282 | Val Loss: 0.119254, Val Acc: 0.773196\n",
      "Epoch 16907 - Train Loss: 0.094572, Train Acc: 0.851282 | Val Loss: 0.119252, Val Acc: 0.773196\n",
      "Epoch 16908 - Train Loss: 0.094569, Train Acc: 0.851282 | Val Loss: 0.119250, Val Acc: 0.773196\n",
      "Epoch 16909 - Train Loss: 0.094566, Train Acc: 0.851282 | Val Loss: 0.119248, Val Acc: 0.773196\n",
      "Epoch 16910 - Train Loss: 0.094563, Train Acc: 0.851282 | Val Loss: 0.119247, Val Acc: 0.773196\n",
      "Epoch 16911 - Train Loss: 0.094560, Train Acc: 0.851282 | Val Loss: 0.119245, Val Acc: 0.773196\n",
      "Epoch 16912 - Train Loss: 0.094557, Train Acc: 0.851282 | Val Loss: 0.119243, Val Acc: 0.773196\n",
      "Epoch 16913 - Train Loss: 0.094554, Train Acc: 0.851282 | Val Loss: 0.119241, Val Acc: 0.773196\n",
      "Epoch 16914 - Train Loss: 0.094551, Train Acc: 0.851282 | Val Loss: 0.119240, Val Acc: 0.773196\n",
      "Epoch 16915 - Train Loss: 0.094547, Train Acc: 0.851282 | Val Loss: 0.119238, Val Acc: 0.773196\n",
      "Epoch 16916 - Train Loss: 0.094544, Train Acc: 0.851282 | Val Loss: 0.119236, Val Acc: 0.773196\n",
      "Epoch 16917 - Train Loss: 0.094541, Train Acc: 0.851282 | Val Loss: 0.119234, Val Acc: 0.773196\n",
      "Epoch 16918 - Train Loss: 0.094538, Train Acc: 0.851282 | Val Loss: 0.119232, Val Acc: 0.773196\n",
      "Epoch 16919 - Train Loss: 0.094535, Train Acc: 0.851282 | Val Loss: 0.119231, Val Acc: 0.773196\n",
      "Epoch 16920 - Train Loss: 0.094532, Train Acc: 0.851282 | Val Loss: 0.119229, Val Acc: 0.773196\n",
      "Epoch 16921 - Train Loss: 0.094529, Train Acc: 0.851282 | Val Loss: 0.119227, Val Acc: 0.773196\n",
      "Epoch 16922 - Train Loss: 0.094526, Train Acc: 0.851282 | Val Loss: 0.119225, Val Acc: 0.773196\n",
      "Epoch 16923 - Train Loss: 0.094523, Train Acc: 0.851282 | Val Loss: 0.119224, Val Acc: 0.773196\n",
      "Epoch 16924 - Train Loss: 0.094520, Train Acc: 0.851282 | Val Loss: 0.119222, Val Acc: 0.773196\n",
      "Epoch 16925 - Train Loss: 0.094517, Train Acc: 0.851282 | Val Loss: 0.119220, Val Acc: 0.773196\n",
      "Epoch 16926 - Train Loss: 0.094514, Train Acc: 0.851282 | Val Loss: 0.119218, Val Acc: 0.773196\n",
      "Epoch 16927 - Train Loss: 0.094511, Train Acc: 0.851282 | Val Loss: 0.119217, Val Acc: 0.773196\n",
      "Epoch 16928 - Train Loss: 0.094508, Train Acc: 0.851282 | Val Loss: 0.119215, Val Acc: 0.773196\n",
      "Epoch 16929 - Train Loss: 0.094505, Train Acc: 0.851282 | Val Loss: 0.119213, Val Acc: 0.773196\n",
      "Epoch 16930 - Train Loss: 0.094502, Train Acc: 0.851282 | Val Loss: 0.119211, Val Acc: 0.773196\n",
      "Epoch 16931 - Train Loss: 0.094499, Train Acc: 0.851282 | Val Loss: 0.119209, Val Acc: 0.773196\n",
      "Epoch 16932 - Train Loss: 0.094496, Train Acc: 0.851282 | Val Loss: 0.119208, Val Acc: 0.773196\n",
      "Epoch 16933 - Train Loss: 0.094493, Train Acc: 0.851282 | Val Loss: 0.119206, Val Acc: 0.773196\n",
      "Epoch 16934 - Train Loss: 0.094490, Train Acc: 0.851282 | Val Loss: 0.119204, Val Acc: 0.773196\n",
      "Epoch 16935 - Train Loss: 0.094487, Train Acc: 0.851282 | Val Loss: 0.119202, Val Acc: 0.773196\n",
      "Epoch 16936 - Train Loss: 0.094484, Train Acc: 0.851282 | Val Loss: 0.119201, Val Acc: 0.773196\n",
      "Epoch 16937 - Train Loss: 0.094481, Train Acc: 0.851282 | Val Loss: 0.119199, Val Acc: 0.773196\n",
      "Epoch 16938 - Train Loss: 0.094478, Train Acc: 0.851282 | Val Loss: 0.119197, Val Acc: 0.773196\n",
      "Epoch 16939 - Train Loss: 0.094475, Train Acc: 0.851282 | Val Loss: 0.119195, Val Acc: 0.773196\n",
      "Epoch 16940 - Train Loss: 0.094472, Train Acc: 0.851282 | Val Loss: 0.119194, Val Acc: 0.773196\n",
      "Epoch 16941 - Train Loss: 0.094469, Train Acc: 0.851282 | Val Loss: 0.119192, Val Acc: 0.773196\n",
      "Epoch 16942 - Train Loss: 0.094466, Train Acc: 0.851282 | Val Loss: 0.119190, Val Acc: 0.773196\n",
      "Epoch 16943 - Train Loss: 0.094463, Train Acc: 0.851282 | Val Loss: 0.119188, Val Acc: 0.773196\n",
      "Epoch 16944 - Train Loss: 0.094460, Train Acc: 0.851282 | Val Loss: 0.119187, Val Acc: 0.773196\n",
      "Epoch 16945 - Train Loss: 0.094457, Train Acc: 0.851282 | Val Loss: 0.119185, Val Acc: 0.773196\n",
      "Epoch 16946 - Train Loss: 0.094454, Train Acc: 0.851282 | Val Loss: 0.119183, Val Acc: 0.773196\n",
      "Epoch 16947 - Train Loss: 0.094451, Train Acc: 0.851282 | Val Loss: 0.119181, Val Acc: 0.773196\n",
      "Epoch 16948 - Train Loss: 0.094448, Train Acc: 0.851282 | Val Loss: 0.119179, Val Acc: 0.773196\n",
      "Epoch 16949 - Train Loss: 0.094445, Train Acc: 0.851282 | Val Loss: 0.119178, Val Acc: 0.773196\n",
      "Epoch 16950 - Train Loss: 0.094442, Train Acc: 0.851282 | Val Loss: 0.119176, Val Acc: 0.773196\n",
      "Epoch 16951 - Train Loss: 0.094439, Train Acc: 0.851282 | Val Loss: 0.119174, Val Acc: 0.773196\n",
      "Epoch 16952 - Train Loss: 0.094436, Train Acc: 0.851282 | Val Loss: 0.119172, Val Acc: 0.773196\n",
      "Epoch 16953 - Train Loss: 0.094433, Train Acc: 0.851282 | Val Loss: 0.119171, Val Acc: 0.773196\n",
      "Epoch 16954 - Train Loss: 0.094430, Train Acc: 0.851282 | Val Loss: 0.119169, Val Acc: 0.773196\n",
      "Epoch 16955 - Train Loss: 0.094427, Train Acc: 0.851282 | Val Loss: 0.119167, Val Acc: 0.773196\n",
      "Epoch 16956 - Train Loss: 0.094424, Train Acc: 0.851282 | Val Loss: 0.119165, Val Acc: 0.773196\n",
      "Epoch 16957 - Train Loss: 0.094421, Train Acc: 0.851282 | Val Loss: 0.119164, Val Acc: 0.773196\n",
      "Epoch 16958 - Train Loss: 0.094418, Train Acc: 0.851282 | Val Loss: 0.119162, Val Acc: 0.773196\n",
      "Epoch 16959 - Train Loss: 0.094415, Train Acc: 0.851282 | Val Loss: 0.119160, Val Acc: 0.773196\n",
      "Epoch 16960 - Train Loss: 0.094412, Train Acc: 0.851282 | Val Loss: 0.119158, Val Acc: 0.773196\n",
      "Epoch 16961 - Train Loss: 0.094409, Train Acc: 0.851282 | Val Loss: 0.119157, Val Acc: 0.773196\n",
      "Epoch 16962 - Train Loss: 0.094406, Train Acc: 0.851282 | Val Loss: 0.119155, Val Acc: 0.773196\n",
      "Epoch 16963 - Train Loss: 0.094403, Train Acc: 0.851282 | Val Loss: 0.119153, Val Acc: 0.773196\n",
      "Epoch 16964 - Train Loss: 0.094400, Train Acc: 0.851282 | Val Loss: 0.119151, Val Acc: 0.773196\n",
      "Epoch 16965 - Train Loss: 0.094397, Train Acc: 0.851282 | Val Loss: 0.119150, Val Acc: 0.773196\n",
      "Epoch 16966 - Train Loss: 0.094394, Train Acc: 0.851282 | Val Loss: 0.119148, Val Acc: 0.773196\n",
      "Epoch 16967 - Train Loss: 0.094391, Train Acc: 0.851282 | Val Loss: 0.119146, Val Acc: 0.773196\n",
      "Epoch 16968 - Train Loss: 0.094388, Train Acc: 0.851282 | Val Loss: 0.119144, Val Acc: 0.773196\n",
      "Epoch 16969 - Train Loss: 0.094385, Train Acc: 0.851282 | Val Loss: 0.119143, Val Acc: 0.773196\n",
      "Epoch 16970 - Train Loss: 0.094382, Train Acc: 0.851282 | Val Loss: 0.119141, Val Acc: 0.773196\n",
      "Epoch 16971 - Train Loss: 0.094379, Train Acc: 0.851282 | Val Loss: 0.119139, Val Acc: 0.773196\n",
      "Epoch 16972 - Train Loss: 0.094376, Train Acc: 0.851282 | Val Loss: 0.119137, Val Acc: 0.773196\n",
      "Epoch 16973 - Train Loss: 0.094373, Train Acc: 0.851282 | Val Loss: 0.119136, Val Acc: 0.773196\n",
      "Epoch 16974 - Train Loss: 0.094370, Train Acc: 0.851282 | Val Loss: 0.119134, Val Acc: 0.773196\n",
      "Epoch 16975 - Train Loss: 0.094367, Train Acc: 0.851282 | Val Loss: 0.119132, Val Acc: 0.773196\n",
      "Epoch 16976 - Train Loss: 0.094364, Train Acc: 0.851282 | Val Loss: 0.119130, Val Acc: 0.773196\n",
      "Epoch 16977 - Train Loss: 0.094361, Train Acc: 0.851282 | Val Loss: 0.119129, Val Acc: 0.773196\n",
      "Epoch 16978 - Train Loss: 0.094358, Train Acc: 0.851282 | Val Loss: 0.119127, Val Acc: 0.773196\n",
      "Epoch 16979 - Train Loss: 0.094355, Train Acc: 0.851282 | Val Loss: 0.119125, Val Acc: 0.773196\n",
      "Epoch 16980 - Train Loss: 0.094352, Train Acc: 0.851282 | Val Loss: 0.119123, Val Acc: 0.773196\n",
      "Epoch 16981 - Train Loss: 0.094349, Train Acc: 0.851282 | Val Loss: 0.119122, Val Acc: 0.773196\n",
      "Epoch 16982 - Train Loss: 0.094346, Train Acc: 0.851282 | Val Loss: 0.119120, Val Acc: 0.773196\n",
      "Epoch 16983 - Train Loss: 0.094343, Train Acc: 0.851282 | Val Loss: 0.119118, Val Acc: 0.773196\n",
      "Epoch 16984 - Train Loss: 0.094340, Train Acc: 0.851282 | Val Loss: 0.119116, Val Acc: 0.773196\n",
      "Epoch 16985 - Train Loss: 0.094337, Train Acc: 0.851282 | Val Loss: 0.119115, Val Acc: 0.773196\n",
      "Epoch 16986 - Train Loss: 0.094334, Train Acc: 0.851282 | Val Loss: 0.119113, Val Acc: 0.773196\n",
      "Epoch 16987 - Train Loss: 0.094331, Train Acc: 0.851282 | Val Loss: 0.119111, Val Acc: 0.773196\n",
      "Epoch 16988 - Train Loss: 0.094328, Train Acc: 0.851282 | Val Loss: 0.119109, Val Acc: 0.773196\n",
      "Epoch 16989 - Train Loss: 0.094325, Train Acc: 0.851282 | Val Loss: 0.119108, Val Acc: 0.773196\n",
      "Epoch 16990 - Train Loss: 0.094322, Train Acc: 0.851282 | Val Loss: 0.119106, Val Acc: 0.773196\n",
      "Epoch 16991 - Train Loss: 0.094320, Train Acc: 0.851282 | Val Loss: 0.119104, Val Acc: 0.773196\n",
      "Epoch 16992 - Train Loss: 0.094317, Train Acc: 0.851282 | Val Loss: 0.119102, Val Acc: 0.773196\n",
      "Epoch 16993 - Train Loss: 0.094314, Train Acc: 0.851282 | Val Loss: 0.119101, Val Acc: 0.773196\n",
      "Epoch 16994 - Train Loss: 0.094311, Train Acc: 0.851282 | Val Loss: 0.119099, Val Acc: 0.773196\n",
      "Epoch 16995 - Train Loss: 0.094308, Train Acc: 0.851282 | Val Loss: 0.119097, Val Acc: 0.773196\n",
      "Epoch 16996 - Train Loss: 0.094305, Train Acc: 0.851282 | Val Loss: 0.119095, Val Acc: 0.773196\n",
      "Epoch 16997 - Train Loss: 0.094302, Train Acc: 0.851282 | Val Loss: 0.119094, Val Acc: 0.773196\n",
      "Epoch 16998 - Train Loss: 0.094299, Train Acc: 0.851282 | Val Loss: 0.119092, Val Acc: 0.773196\n",
      "Epoch 16999 - Train Loss: 0.094296, Train Acc: 0.851282 | Val Loss: 0.119090, Val Acc: 0.773196\n",
      "Epoch 17000 - Train Loss: 0.094293, Train Acc: 0.851282 | Val Loss: 0.119088, Val Acc: 0.773196\n",
      "Epoch 17001 - Train Loss: 0.094290, Train Acc: 0.851282 | Val Loss: 0.119087, Val Acc: 0.773196\n",
      "Epoch 17002 - Train Loss: 0.094287, Train Acc: 0.851282 | Val Loss: 0.119085, Val Acc: 0.773196\n",
      "Epoch 17003 - Train Loss: 0.094284, Train Acc: 0.851282 | Val Loss: 0.119083, Val Acc: 0.773196\n",
      "Epoch 17004 - Train Loss: 0.094281, Train Acc: 0.851282 | Val Loss: 0.119081, Val Acc: 0.773196\n",
      "Epoch 17005 - Train Loss: 0.094278, Train Acc: 0.851282 | Val Loss: 0.119080, Val Acc: 0.773196\n",
      "Epoch 17006 - Train Loss: 0.094275, Train Acc: 0.851282 | Val Loss: 0.119078, Val Acc: 0.773196\n",
      "Epoch 17007 - Train Loss: 0.094272, Train Acc: 0.851282 | Val Loss: 0.119076, Val Acc: 0.773196\n",
      "Epoch 17008 - Train Loss: 0.094269, Train Acc: 0.851282 | Val Loss: 0.119074, Val Acc: 0.773196\n",
      "Epoch 17009 - Train Loss: 0.094266, Train Acc: 0.851282 | Val Loss: 0.119073, Val Acc: 0.773196\n",
      "Epoch 17010 - Train Loss: 0.094263, Train Acc: 0.851282 | Val Loss: 0.119071, Val Acc: 0.773196\n",
      "Epoch 17011 - Train Loss: 0.094260, Train Acc: 0.851282 | Val Loss: 0.119069, Val Acc: 0.773196\n",
      "Epoch 17012 - Train Loss: 0.094257, Train Acc: 0.851282 | Val Loss: 0.119067, Val Acc: 0.773196\n",
      "Epoch 17013 - Train Loss: 0.094254, Train Acc: 0.851282 | Val Loss: 0.119066, Val Acc: 0.773196\n",
      "Epoch 17014 - Train Loss: 0.094251, Train Acc: 0.851282 | Val Loss: 0.119064, Val Acc: 0.773196\n",
      "Epoch 17015 - Train Loss: 0.094248, Train Acc: 0.851282 | Val Loss: 0.119062, Val Acc: 0.773196\n",
      "Epoch 17016 - Train Loss: 0.094245, Train Acc: 0.851282 | Val Loss: 0.119060, Val Acc: 0.773196\n",
      "Epoch 17017 - Train Loss: 0.094242, Train Acc: 0.851282 | Val Loss: 0.119059, Val Acc: 0.773196\n",
      "Epoch 17018 - Train Loss: 0.094239, Train Acc: 0.851282 | Val Loss: 0.119057, Val Acc: 0.773196\n",
      "Epoch 17019 - Train Loss: 0.094236, Train Acc: 0.851282 | Val Loss: 0.119055, Val Acc: 0.773196\n",
      "Epoch 17020 - Train Loss: 0.094233, Train Acc: 0.851282 | Val Loss: 0.119053, Val Acc: 0.773196\n",
      "Epoch 17021 - Train Loss: 0.094230, Train Acc: 0.851282 | Val Loss: 0.119052, Val Acc: 0.773196\n",
      "Epoch 17022 - Train Loss: 0.094227, Train Acc: 0.851282 | Val Loss: 0.119050, Val Acc: 0.773196\n",
      "Epoch 17023 - Train Loss: 0.094224, Train Acc: 0.851282 | Val Loss: 0.119048, Val Acc: 0.773196\n",
      "Epoch 17024 - Train Loss: 0.094221, Train Acc: 0.851282 | Val Loss: 0.119047, Val Acc: 0.773196\n",
      "Epoch 17025 - Train Loss: 0.094218, Train Acc: 0.851282 | Val Loss: 0.119045, Val Acc: 0.773196\n",
      "Epoch 17026 - Train Loss: 0.094215, Train Acc: 0.851282 | Val Loss: 0.119043, Val Acc: 0.773196\n",
      "Epoch 17027 - Train Loss: 0.094212, Train Acc: 0.851282 | Val Loss: 0.119041, Val Acc: 0.773196\n",
      "Epoch 17028 - Train Loss: 0.094209, Train Acc: 0.851282 | Val Loss: 0.119040, Val Acc: 0.773196\n",
      "Epoch 17029 - Train Loss: 0.094206, Train Acc: 0.851282 | Val Loss: 0.119038, Val Acc: 0.773196\n",
      "Epoch 17030 - Train Loss: 0.094203, Train Acc: 0.851282 | Val Loss: 0.119036, Val Acc: 0.773196\n",
      "Epoch 17031 - Train Loss: 0.094200, Train Acc: 0.851282 | Val Loss: 0.119034, Val Acc: 0.773196\n",
      "Epoch 17032 - Train Loss: 0.094197, Train Acc: 0.851282 | Val Loss: 0.119033, Val Acc: 0.773196\n",
      "Epoch 17033 - Train Loss: 0.094194, Train Acc: 0.851282 | Val Loss: 0.119031, Val Acc: 0.773196\n",
      "Epoch 17034 - Train Loss: 0.094191, Train Acc: 0.851282 | Val Loss: 0.119029, Val Acc: 0.773196\n",
      "Epoch 17035 - Train Loss: 0.094188, Train Acc: 0.851282 | Val Loss: 0.119027, Val Acc: 0.773196\n",
      "Epoch 17036 - Train Loss: 0.094185, Train Acc: 0.851282 | Val Loss: 0.119026, Val Acc: 0.773196\n",
      "Epoch 17037 - Train Loss: 0.094182, Train Acc: 0.851282 | Val Loss: 0.119024, Val Acc: 0.773196\n",
      "Epoch 17038 - Train Loss: 0.094179, Train Acc: 0.851282 | Val Loss: 0.119022, Val Acc: 0.773196\n",
      "Epoch 17039 - Train Loss: 0.094176, Train Acc: 0.851282 | Val Loss: 0.119021, Val Acc: 0.773196\n",
      "Epoch 17040 - Train Loss: 0.094174, Train Acc: 0.851282 | Val Loss: 0.119019, Val Acc: 0.773196\n",
      "Epoch 17041 - Train Loss: 0.094171, Train Acc: 0.851282 | Val Loss: 0.119017, Val Acc: 0.773196\n",
      "Epoch 17042 - Train Loss: 0.094168, Train Acc: 0.851282 | Val Loss: 0.119015, Val Acc: 0.773196\n",
      "Epoch 17043 - Train Loss: 0.094165, Train Acc: 0.851282 | Val Loss: 0.119014, Val Acc: 0.773196\n",
      "Epoch 17044 - Train Loss: 0.094162, Train Acc: 0.851282 | Val Loss: 0.119012, Val Acc: 0.773196\n",
      "Epoch 17045 - Train Loss: 0.094159, Train Acc: 0.851282 | Val Loss: 0.119010, Val Acc: 0.773196\n",
      "Epoch 17046 - Train Loss: 0.094156, Train Acc: 0.851282 | Val Loss: 0.119008, Val Acc: 0.773196\n",
      "Epoch 17047 - Train Loss: 0.094153, Train Acc: 0.851282 | Val Loss: 0.119007, Val Acc: 0.773196\n",
      "Epoch 17048 - Train Loss: 0.094150, Train Acc: 0.851282 | Val Loss: 0.119005, Val Acc: 0.773196\n",
      "Epoch 17049 - Train Loss: 0.094147, Train Acc: 0.851282 | Val Loss: 0.119003, Val Acc: 0.773196\n",
      "Epoch 17050 - Train Loss: 0.094144, Train Acc: 0.851282 | Val Loss: 0.119001, Val Acc: 0.773196\n",
      "Epoch 17051 - Train Loss: 0.094141, Train Acc: 0.851282 | Val Loss: 0.119000, Val Acc: 0.773196\n",
      "Epoch 17052 - Train Loss: 0.094138, Train Acc: 0.851282 | Val Loss: 0.118998, Val Acc: 0.773196\n",
      "Epoch 17053 - Train Loss: 0.094135, Train Acc: 0.851282 | Val Loss: 0.118996, Val Acc: 0.773196\n",
      "Epoch 17054 - Train Loss: 0.094132, Train Acc: 0.851282 | Val Loss: 0.118995, Val Acc: 0.773196\n",
      "Epoch 17055 - Train Loss: 0.094129, Train Acc: 0.851282 | Val Loss: 0.118993, Val Acc: 0.773196\n",
      "Epoch 17056 - Train Loss: 0.094126, Train Acc: 0.851282 | Val Loss: 0.118991, Val Acc: 0.773196\n",
      "Epoch 17057 - Train Loss: 0.094123, Train Acc: 0.851282 | Val Loss: 0.118989, Val Acc: 0.773196\n",
      "Epoch 17058 - Train Loss: 0.094120, Train Acc: 0.851282 | Val Loss: 0.118988, Val Acc: 0.773196\n",
      "Epoch 17059 - Train Loss: 0.094117, Train Acc: 0.851282 | Val Loss: 0.118986, Val Acc: 0.773196\n",
      "Epoch 17060 - Train Loss: 0.094114, Train Acc: 0.851282 | Val Loss: 0.118984, Val Acc: 0.773196\n",
      "Epoch 17061 - Train Loss: 0.094111, Train Acc: 0.851282 | Val Loss: 0.118982, Val Acc: 0.773196\n",
      "Epoch 17062 - Train Loss: 0.094108, Train Acc: 0.851282 | Val Loss: 0.118981, Val Acc: 0.773196\n",
      "Epoch 17063 - Train Loss: 0.094105, Train Acc: 0.851282 | Val Loss: 0.118979, Val Acc: 0.773196\n",
      "Epoch 17064 - Train Loss: 0.094102, Train Acc: 0.851282 | Val Loss: 0.118977, Val Acc: 0.773196\n",
      "Epoch 17065 - Train Loss: 0.094099, Train Acc: 0.851282 | Val Loss: 0.118976, Val Acc: 0.773196\n",
      "Epoch 17066 - Train Loss: 0.094096, Train Acc: 0.851282 | Val Loss: 0.118974, Val Acc: 0.773196\n",
      "Epoch 17067 - Train Loss: 0.094093, Train Acc: 0.851282 | Val Loss: 0.118972, Val Acc: 0.773196\n",
      "Epoch 17068 - Train Loss: 0.094090, Train Acc: 0.851282 | Val Loss: 0.118970, Val Acc: 0.773196\n",
      "Epoch 17069 - Train Loss: 0.094087, Train Acc: 0.851282 | Val Loss: 0.118969, Val Acc: 0.773196\n",
      "Epoch 17070 - Train Loss: 0.094085, Train Acc: 0.851282 | Val Loss: 0.118967, Val Acc: 0.773196\n",
      "Epoch 17071 - Train Loss: 0.094082, Train Acc: 0.851282 | Val Loss: 0.118965, Val Acc: 0.773196\n",
      "Epoch 17072 - Train Loss: 0.094079, Train Acc: 0.851282 | Val Loss: 0.118963, Val Acc: 0.773196\n",
      "Epoch 17073 - Train Loss: 0.094076, Train Acc: 0.851282 | Val Loss: 0.118962, Val Acc: 0.773196\n",
      "Epoch 17074 - Train Loss: 0.094073, Train Acc: 0.851282 | Val Loss: 0.118960, Val Acc: 0.773196\n",
      "Epoch 17075 - Train Loss: 0.094070, Train Acc: 0.851282 | Val Loss: 0.118958, Val Acc: 0.773196\n",
      "Epoch 17076 - Train Loss: 0.094067, Train Acc: 0.851282 | Val Loss: 0.118957, Val Acc: 0.773196\n",
      "Epoch 17077 - Train Loss: 0.094064, Train Acc: 0.851282 | Val Loss: 0.118955, Val Acc: 0.773196\n",
      "Epoch 17078 - Train Loss: 0.094061, Train Acc: 0.851282 | Val Loss: 0.118953, Val Acc: 0.773196\n",
      "Epoch 17079 - Train Loss: 0.094058, Train Acc: 0.851282 | Val Loss: 0.118951, Val Acc: 0.773196\n",
      "Epoch 17080 - Train Loss: 0.094055, Train Acc: 0.851282 | Val Loss: 0.118950, Val Acc: 0.773196\n",
      "Epoch 17081 - Train Loss: 0.094052, Train Acc: 0.851282 | Val Loss: 0.118948, Val Acc: 0.773196\n",
      "Epoch 17082 - Train Loss: 0.094049, Train Acc: 0.851282 | Val Loss: 0.118946, Val Acc: 0.773196\n",
      "Epoch 17083 - Train Loss: 0.094046, Train Acc: 0.851282 | Val Loss: 0.118945, Val Acc: 0.773196\n",
      "Epoch 17084 - Train Loss: 0.094043, Train Acc: 0.851282 | Val Loss: 0.118943, Val Acc: 0.773196\n",
      "Epoch 17085 - Train Loss: 0.094040, Train Acc: 0.851282 | Val Loss: 0.118941, Val Acc: 0.773196\n",
      "Epoch 17086 - Train Loss: 0.094037, Train Acc: 0.851282 | Val Loss: 0.118939, Val Acc: 0.773196\n",
      "Epoch 17087 - Train Loss: 0.094034, Train Acc: 0.851282 | Val Loss: 0.118938, Val Acc: 0.773196\n",
      "Epoch 17088 - Train Loss: 0.094031, Train Acc: 0.851282 | Val Loss: 0.118936, Val Acc: 0.773196\n",
      "Epoch 17089 - Train Loss: 0.094028, Train Acc: 0.851282 | Val Loss: 0.118934, Val Acc: 0.773196\n",
      "Epoch 17090 - Train Loss: 0.094025, Train Acc: 0.851282 | Val Loss: 0.118933, Val Acc: 0.773196\n",
      "Epoch 17091 - Train Loss: 0.094022, Train Acc: 0.851282 | Val Loss: 0.118931, Val Acc: 0.773196\n",
      "Epoch 17092 - Train Loss: 0.094019, Train Acc: 0.851282 | Val Loss: 0.118929, Val Acc: 0.773196\n",
      "Epoch 17093 - Train Loss: 0.094016, Train Acc: 0.851282 | Val Loss: 0.118927, Val Acc: 0.773196\n",
      "Epoch 17094 - Train Loss: 0.094014, Train Acc: 0.851282 | Val Loss: 0.118926, Val Acc: 0.773196\n",
      "Epoch 17095 - Train Loss: 0.094011, Train Acc: 0.851282 | Val Loss: 0.118924, Val Acc: 0.773196\n",
      "Epoch 17096 - Train Loss: 0.094008, Train Acc: 0.851282 | Val Loss: 0.118922, Val Acc: 0.773196\n",
      "Epoch 17097 - Train Loss: 0.094005, Train Acc: 0.851282 | Val Loss: 0.118921, Val Acc: 0.773196\n",
      "Epoch 17098 - Train Loss: 0.094002, Train Acc: 0.851282 | Val Loss: 0.118919, Val Acc: 0.773196\n",
      "Epoch 17099 - Train Loss: 0.093999, Train Acc: 0.851282 | Val Loss: 0.118917, Val Acc: 0.773196\n",
      "Epoch 17100 - Train Loss: 0.093996, Train Acc: 0.851282 | Val Loss: 0.118915, Val Acc: 0.773196\n",
      "Epoch 17101 - Train Loss: 0.093993, Train Acc: 0.851282 | Val Loss: 0.118914, Val Acc: 0.773196\n",
      "Epoch 17102 - Train Loss: 0.093990, Train Acc: 0.851282 | Val Loss: 0.118912, Val Acc: 0.773196\n",
      "Epoch 17103 - Train Loss: 0.093987, Train Acc: 0.851282 | Val Loss: 0.118910, Val Acc: 0.773196\n",
      "Epoch 17104 - Train Loss: 0.093984, Train Acc: 0.851282 | Val Loss: 0.118909, Val Acc: 0.773196\n",
      "Epoch 17105 - Train Loss: 0.093981, Train Acc: 0.851282 | Val Loss: 0.118907, Val Acc: 0.773196\n",
      "Epoch 17106 - Train Loss: 0.093978, Train Acc: 0.851282 | Val Loss: 0.118905, Val Acc: 0.773196\n",
      "Epoch 17107 - Train Loss: 0.093975, Train Acc: 0.851282 | Val Loss: 0.118903, Val Acc: 0.773196\n",
      "Epoch 17108 - Train Loss: 0.093972, Train Acc: 0.851282 | Val Loss: 0.118902, Val Acc: 0.773196\n",
      "Epoch 17109 - Train Loss: 0.093969, Train Acc: 0.851282 | Val Loss: 0.118900, Val Acc: 0.773196\n",
      "Epoch 17110 - Train Loss: 0.093966, Train Acc: 0.851282 | Val Loss: 0.118898, Val Acc: 0.773196\n",
      "Epoch 17111 - Train Loss: 0.093963, Train Acc: 0.851282 | Val Loss: 0.118897, Val Acc: 0.773196\n",
      "Epoch 17112 - Train Loss: 0.093960, Train Acc: 0.851282 | Val Loss: 0.118895, Val Acc: 0.773196\n",
      "Epoch 17113 - Train Loss: 0.093957, Train Acc: 0.851282 | Val Loss: 0.118893, Val Acc: 0.773196\n",
      "Epoch 17114 - Train Loss: 0.093954, Train Acc: 0.851282 | Val Loss: 0.118891, Val Acc: 0.773196\n",
      "Epoch 17115 - Train Loss: 0.093952, Train Acc: 0.851282 | Val Loss: 0.118890, Val Acc: 0.773196\n",
      "Epoch 17116 - Train Loss: 0.093949, Train Acc: 0.851282 | Val Loss: 0.118888, Val Acc: 0.773196\n",
      "Epoch 17117 - Train Loss: 0.093946, Train Acc: 0.851282 | Val Loss: 0.118886, Val Acc: 0.773196\n",
      "Epoch 17118 - Train Loss: 0.093943, Train Acc: 0.851282 | Val Loss: 0.118885, Val Acc: 0.773196\n",
      "Epoch 17119 - Train Loss: 0.093940, Train Acc: 0.851282 | Val Loss: 0.118883, Val Acc: 0.773196\n",
      "Epoch 17120 - Train Loss: 0.093937, Train Acc: 0.851282 | Val Loss: 0.118881, Val Acc: 0.773196\n",
      "Epoch 17121 - Train Loss: 0.093934, Train Acc: 0.851282 | Val Loss: 0.118879, Val Acc: 0.773196\n",
      "Epoch 17122 - Train Loss: 0.093931, Train Acc: 0.851282 | Val Loss: 0.118878, Val Acc: 0.773196\n",
      "Epoch 17123 - Train Loss: 0.093928, Train Acc: 0.851282 | Val Loss: 0.118876, Val Acc: 0.773196\n",
      "Epoch 17124 - Train Loss: 0.093925, Train Acc: 0.851282 | Val Loss: 0.118874, Val Acc: 0.773196\n",
      "Epoch 17125 - Train Loss: 0.093922, Train Acc: 0.851282 | Val Loss: 0.118873, Val Acc: 0.773196\n",
      "Epoch 17126 - Train Loss: 0.093919, Train Acc: 0.851282 | Val Loss: 0.118871, Val Acc: 0.773196\n",
      "Epoch 17127 - Train Loss: 0.093916, Train Acc: 0.851282 | Val Loss: 0.118869, Val Acc: 0.773196\n",
      "Epoch 17128 - Train Loss: 0.093913, Train Acc: 0.851282 | Val Loss: 0.118868, Val Acc: 0.773196\n",
      "Epoch 17129 - Train Loss: 0.093910, Train Acc: 0.851282 | Val Loss: 0.118866, Val Acc: 0.773196\n",
      "Epoch 17130 - Train Loss: 0.093907, Train Acc: 0.851282 | Val Loss: 0.118864, Val Acc: 0.773196\n",
      "Epoch 17131 - Train Loss: 0.093904, Train Acc: 0.851282 | Val Loss: 0.118862, Val Acc: 0.773196\n",
      "Epoch 17132 - Train Loss: 0.093901, Train Acc: 0.851282 | Val Loss: 0.118861, Val Acc: 0.773196\n",
      "Epoch 17133 - Train Loss: 0.093899, Train Acc: 0.851282 | Val Loss: 0.118859, Val Acc: 0.773196\n",
      "Epoch 17134 - Train Loss: 0.093896, Train Acc: 0.851282 | Val Loss: 0.118857, Val Acc: 0.773196\n",
      "Epoch 17135 - Train Loss: 0.093893, Train Acc: 0.851282 | Val Loss: 0.118856, Val Acc: 0.773196\n",
      "Epoch 17136 - Train Loss: 0.093890, Train Acc: 0.851282 | Val Loss: 0.118854, Val Acc: 0.773196\n",
      "Epoch 17137 - Train Loss: 0.093887, Train Acc: 0.851282 | Val Loss: 0.118852, Val Acc: 0.773196\n",
      "Epoch 17138 - Train Loss: 0.093884, Train Acc: 0.851282 | Val Loss: 0.118850, Val Acc: 0.773196\n",
      "Epoch 17139 - Train Loss: 0.093881, Train Acc: 0.851282 | Val Loss: 0.118849, Val Acc: 0.773196\n",
      "Epoch 17140 - Train Loss: 0.093878, Train Acc: 0.851282 | Val Loss: 0.118847, Val Acc: 0.773196\n",
      "Epoch 17141 - Train Loss: 0.093875, Train Acc: 0.851282 | Val Loss: 0.118845, Val Acc: 0.773196\n",
      "Epoch 17142 - Train Loss: 0.093872, Train Acc: 0.851282 | Val Loss: 0.118844, Val Acc: 0.773196\n",
      "Epoch 17143 - Train Loss: 0.093869, Train Acc: 0.851282 | Val Loss: 0.118842, Val Acc: 0.773196\n",
      "Epoch 17144 - Train Loss: 0.093866, Train Acc: 0.851282 | Val Loss: 0.118840, Val Acc: 0.773196\n",
      "Epoch 17145 - Train Loss: 0.093863, Train Acc: 0.852564 | Val Loss: 0.118839, Val Acc: 0.773196\n",
      "Epoch 17146 - Train Loss: 0.093860, Train Acc: 0.852564 | Val Loss: 0.118837, Val Acc: 0.773196\n",
      "Epoch 17147 - Train Loss: 0.093857, Train Acc: 0.852564 | Val Loss: 0.118835, Val Acc: 0.773196\n",
      "Epoch 17148 - Train Loss: 0.093854, Train Acc: 0.852564 | Val Loss: 0.118833, Val Acc: 0.773196\n",
      "Epoch 17149 - Train Loss: 0.093852, Train Acc: 0.852564 | Val Loss: 0.118832, Val Acc: 0.773196\n",
      "Epoch 17150 - Train Loss: 0.093849, Train Acc: 0.852564 | Val Loss: 0.118830, Val Acc: 0.773196\n",
      "Epoch 17151 - Train Loss: 0.093846, Train Acc: 0.852564 | Val Loss: 0.118828, Val Acc: 0.773196\n",
      "Epoch 17152 - Train Loss: 0.093843, Train Acc: 0.852564 | Val Loss: 0.118827, Val Acc: 0.773196\n",
      "Epoch 17153 - Train Loss: 0.093840, Train Acc: 0.852564 | Val Loss: 0.118825, Val Acc: 0.773196\n",
      "Epoch 17154 - Train Loss: 0.093837, Train Acc: 0.852564 | Val Loss: 0.118823, Val Acc: 0.773196\n",
      "Epoch 17155 - Train Loss: 0.093834, Train Acc: 0.852564 | Val Loss: 0.118822, Val Acc: 0.773196\n",
      "Epoch 17156 - Train Loss: 0.093831, Train Acc: 0.852564 | Val Loss: 0.118820, Val Acc: 0.773196\n",
      "Epoch 17157 - Train Loss: 0.093828, Train Acc: 0.852564 | Val Loss: 0.118818, Val Acc: 0.773196\n",
      "Epoch 17158 - Train Loss: 0.093825, Train Acc: 0.852564 | Val Loss: 0.118817, Val Acc: 0.773196\n",
      "Epoch 17159 - Train Loss: 0.093822, Train Acc: 0.852564 | Val Loss: 0.118815, Val Acc: 0.773196\n",
      "Epoch 17160 - Train Loss: 0.093819, Train Acc: 0.852564 | Val Loss: 0.118813, Val Acc: 0.773196\n",
      "Epoch 17161 - Train Loss: 0.093816, Train Acc: 0.852564 | Val Loss: 0.118811, Val Acc: 0.773196\n",
      "Epoch 17162 - Train Loss: 0.093813, Train Acc: 0.852564 | Val Loss: 0.118810, Val Acc: 0.773196\n",
      "Epoch 17163 - Train Loss: 0.093810, Train Acc: 0.852564 | Val Loss: 0.118808, Val Acc: 0.773196\n",
      "Epoch 17164 - Train Loss: 0.093807, Train Acc: 0.852564 | Val Loss: 0.118806, Val Acc: 0.773196\n",
      "Epoch 17165 - Train Loss: 0.093805, Train Acc: 0.852564 | Val Loss: 0.118805, Val Acc: 0.773196\n",
      "Epoch 17166 - Train Loss: 0.093802, Train Acc: 0.852564 | Val Loss: 0.118803, Val Acc: 0.773196\n",
      "Epoch 17167 - Train Loss: 0.093799, Train Acc: 0.852564 | Val Loss: 0.118801, Val Acc: 0.773196\n",
      "Epoch 17168 - Train Loss: 0.093796, Train Acc: 0.852564 | Val Loss: 0.118800, Val Acc: 0.773196\n",
      "Epoch 17169 - Train Loss: 0.093793, Train Acc: 0.852564 | Val Loss: 0.118798, Val Acc: 0.773196\n",
      "Epoch 17170 - Train Loss: 0.093790, Train Acc: 0.852564 | Val Loss: 0.118796, Val Acc: 0.773196\n",
      "Epoch 17171 - Train Loss: 0.093787, Train Acc: 0.852564 | Val Loss: 0.118794, Val Acc: 0.773196\n",
      "Epoch 17172 - Train Loss: 0.093784, Train Acc: 0.852564 | Val Loss: 0.118793, Val Acc: 0.773196\n",
      "Epoch 17173 - Train Loss: 0.093781, Train Acc: 0.852564 | Val Loss: 0.118791, Val Acc: 0.773196\n",
      "Epoch 17174 - Train Loss: 0.093778, Train Acc: 0.852564 | Val Loss: 0.118789, Val Acc: 0.773196\n",
      "Epoch 17175 - Train Loss: 0.093775, Train Acc: 0.852564 | Val Loss: 0.118788, Val Acc: 0.773196\n",
      "Epoch 17176 - Train Loss: 0.093772, Train Acc: 0.852564 | Val Loss: 0.118786, Val Acc: 0.773196\n",
      "Epoch 17177 - Train Loss: 0.093769, Train Acc: 0.852564 | Val Loss: 0.118784, Val Acc: 0.773196\n",
      "Epoch 17178 - Train Loss: 0.093766, Train Acc: 0.852564 | Val Loss: 0.118783, Val Acc: 0.773196\n",
      "Epoch 17179 - Train Loss: 0.093764, Train Acc: 0.852564 | Val Loss: 0.118781, Val Acc: 0.773196\n",
      "Epoch 17180 - Train Loss: 0.093761, Train Acc: 0.852564 | Val Loss: 0.118779, Val Acc: 0.773196\n",
      "Epoch 17181 - Train Loss: 0.093758, Train Acc: 0.852564 | Val Loss: 0.118778, Val Acc: 0.773196\n",
      "Epoch 17182 - Train Loss: 0.093755, Train Acc: 0.852564 | Val Loss: 0.118776, Val Acc: 0.773196\n",
      "Epoch 17183 - Train Loss: 0.093752, Train Acc: 0.852564 | Val Loss: 0.118774, Val Acc: 0.773196\n",
      "Epoch 17184 - Train Loss: 0.093749, Train Acc: 0.852564 | Val Loss: 0.118773, Val Acc: 0.773196\n",
      "Epoch 17185 - Train Loss: 0.093746, Train Acc: 0.852564 | Val Loss: 0.118771, Val Acc: 0.773196\n",
      "Epoch 17186 - Train Loss: 0.093743, Train Acc: 0.852564 | Val Loss: 0.118769, Val Acc: 0.773196\n",
      "Epoch 17187 - Train Loss: 0.093740, Train Acc: 0.852564 | Val Loss: 0.118767, Val Acc: 0.773196\n",
      "Epoch 17188 - Train Loss: 0.093737, Train Acc: 0.852564 | Val Loss: 0.118766, Val Acc: 0.773196\n",
      "Epoch 17189 - Train Loss: 0.093734, Train Acc: 0.852564 | Val Loss: 0.118764, Val Acc: 0.773196\n",
      "Epoch 17190 - Train Loss: 0.093731, Train Acc: 0.852564 | Val Loss: 0.118762, Val Acc: 0.773196\n",
      "Epoch 17191 - Train Loss: 0.093728, Train Acc: 0.852564 | Val Loss: 0.118761, Val Acc: 0.773196\n",
      "Epoch 17192 - Train Loss: 0.093726, Train Acc: 0.852564 | Val Loss: 0.118759, Val Acc: 0.773196\n",
      "Epoch 17193 - Train Loss: 0.093723, Train Acc: 0.852564 | Val Loss: 0.118757, Val Acc: 0.773196\n",
      "Epoch 17194 - Train Loss: 0.093720, Train Acc: 0.852564 | Val Loss: 0.118756, Val Acc: 0.773196\n",
      "Epoch 17195 - Train Loss: 0.093717, Train Acc: 0.852564 | Val Loss: 0.118754, Val Acc: 0.773196\n",
      "Epoch 17196 - Train Loss: 0.093714, Train Acc: 0.852564 | Val Loss: 0.118752, Val Acc: 0.773196\n",
      "Epoch 17197 - Train Loss: 0.093711, Train Acc: 0.852564 | Val Loss: 0.118751, Val Acc: 0.773196\n",
      "Epoch 17198 - Train Loss: 0.093708, Train Acc: 0.852564 | Val Loss: 0.118749, Val Acc: 0.773196\n",
      "Epoch 17199 - Train Loss: 0.093705, Train Acc: 0.852564 | Val Loss: 0.118747, Val Acc: 0.773196\n",
      "Epoch 17200 - Train Loss: 0.093702, Train Acc: 0.852564 | Val Loss: 0.118746, Val Acc: 0.773196\n",
      "Epoch 17201 - Train Loss: 0.093699, Train Acc: 0.852564 | Val Loss: 0.118744, Val Acc: 0.773196\n",
      "Epoch 17202 - Train Loss: 0.093696, Train Acc: 0.852564 | Val Loss: 0.118742, Val Acc: 0.773196\n",
      "Epoch 17203 - Train Loss: 0.093693, Train Acc: 0.852564 | Val Loss: 0.118740, Val Acc: 0.773196\n",
      "Epoch 17204 - Train Loss: 0.093690, Train Acc: 0.852564 | Val Loss: 0.118739, Val Acc: 0.773196\n",
      "Epoch 17205 - Train Loss: 0.093688, Train Acc: 0.852564 | Val Loss: 0.118737, Val Acc: 0.773196\n",
      "Epoch 17206 - Train Loss: 0.093685, Train Acc: 0.852564 | Val Loss: 0.118735, Val Acc: 0.773196\n",
      "Epoch 17207 - Train Loss: 0.093682, Train Acc: 0.852564 | Val Loss: 0.118734, Val Acc: 0.773196\n",
      "Epoch 17208 - Train Loss: 0.093679, Train Acc: 0.852564 | Val Loss: 0.118732, Val Acc: 0.773196\n",
      "Epoch 17209 - Train Loss: 0.093676, Train Acc: 0.852564 | Val Loss: 0.118730, Val Acc: 0.773196\n",
      "Epoch 17210 - Train Loss: 0.093673, Train Acc: 0.852564 | Val Loss: 0.118729, Val Acc: 0.773196\n",
      "Epoch 17211 - Train Loss: 0.093670, Train Acc: 0.852564 | Val Loss: 0.118727, Val Acc: 0.773196\n",
      "Epoch 17212 - Train Loss: 0.093667, Train Acc: 0.852564 | Val Loss: 0.118725, Val Acc: 0.773196\n",
      "Epoch 17213 - Train Loss: 0.093664, Train Acc: 0.852564 | Val Loss: 0.118724, Val Acc: 0.773196\n",
      "Epoch 17214 - Train Loss: 0.093661, Train Acc: 0.852564 | Val Loss: 0.118722, Val Acc: 0.773196\n",
      "Epoch 17215 - Train Loss: 0.093658, Train Acc: 0.852564 | Val Loss: 0.118720, Val Acc: 0.773196\n",
      "Epoch 17216 - Train Loss: 0.093655, Train Acc: 0.852564 | Val Loss: 0.118719, Val Acc: 0.773196\n",
      "Epoch 17217 - Train Loss: 0.093653, Train Acc: 0.852564 | Val Loss: 0.118717, Val Acc: 0.773196\n",
      "Epoch 17218 - Train Loss: 0.093650, Train Acc: 0.852564 | Val Loss: 0.118715, Val Acc: 0.773196\n",
      "Epoch 17219 - Train Loss: 0.093647, Train Acc: 0.852564 | Val Loss: 0.118714, Val Acc: 0.773196\n",
      "Epoch 17220 - Train Loss: 0.093644, Train Acc: 0.852564 | Val Loss: 0.118712, Val Acc: 0.773196\n",
      "Epoch 17221 - Train Loss: 0.093641, Train Acc: 0.852564 | Val Loss: 0.118710, Val Acc: 0.773196\n",
      "Epoch 17222 - Train Loss: 0.093638, Train Acc: 0.852564 | Val Loss: 0.118709, Val Acc: 0.773196\n",
      "Epoch 17223 - Train Loss: 0.093635, Train Acc: 0.852564 | Val Loss: 0.118707, Val Acc: 0.773196\n",
      "Epoch 17224 - Train Loss: 0.093632, Train Acc: 0.852564 | Val Loss: 0.118705, Val Acc: 0.773196\n",
      "Epoch 17225 - Train Loss: 0.093629, Train Acc: 0.852564 | Val Loss: 0.118704, Val Acc: 0.773196\n",
      "Epoch 17226 - Train Loss: 0.093626, Train Acc: 0.852564 | Val Loss: 0.118702, Val Acc: 0.773196\n",
      "Epoch 17227 - Train Loss: 0.093623, Train Acc: 0.852564 | Val Loss: 0.118700, Val Acc: 0.773196\n",
      "Epoch 17228 - Train Loss: 0.093620, Train Acc: 0.852564 | Val Loss: 0.118699, Val Acc: 0.773196\n",
      "Epoch 17229 - Train Loss: 0.093618, Train Acc: 0.852564 | Val Loss: 0.118697, Val Acc: 0.773196\n",
      "Epoch 17230 - Train Loss: 0.093615, Train Acc: 0.852564 | Val Loss: 0.118695, Val Acc: 0.773196\n",
      "Epoch 17231 - Train Loss: 0.093612, Train Acc: 0.852564 | Val Loss: 0.118693, Val Acc: 0.773196\n",
      "Epoch 17232 - Train Loss: 0.093609, Train Acc: 0.852564 | Val Loss: 0.118692, Val Acc: 0.773196\n",
      "Epoch 17233 - Train Loss: 0.093606, Train Acc: 0.852564 | Val Loss: 0.118690, Val Acc: 0.773196\n",
      "Epoch 17234 - Train Loss: 0.093603, Train Acc: 0.852564 | Val Loss: 0.118688, Val Acc: 0.773196\n",
      "Epoch 17235 - Train Loss: 0.093600, Train Acc: 0.852564 | Val Loss: 0.118687, Val Acc: 0.773196\n",
      "Epoch 17236 - Train Loss: 0.093597, Train Acc: 0.852564 | Val Loss: 0.118685, Val Acc: 0.773196\n",
      "Epoch 17237 - Train Loss: 0.093594, Train Acc: 0.852564 | Val Loss: 0.118683, Val Acc: 0.773196\n",
      "Epoch 17238 - Train Loss: 0.093591, Train Acc: 0.852564 | Val Loss: 0.118682, Val Acc: 0.773196\n",
      "Epoch 17239 - Train Loss: 0.093588, Train Acc: 0.852564 | Val Loss: 0.118680, Val Acc: 0.773196\n",
      "Epoch 17240 - Train Loss: 0.093586, Train Acc: 0.852564 | Val Loss: 0.118678, Val Acc: 0.773196\n",
      "Epoch 17241 - Train Loss: 0.093583, Train Acc: 0.852564 | Val Loss: 0.118677, Val Acc: 0.773196\n",
      "Epoch 17242 - Train Loss: 0.093580, Train Acc: 0.852564 | Val Loss: 0.118675, Val Acc: 0.773196\n",
      "Epoch 17243 - Train Loss: 0.093577, Train Acc: 0.852564 | Val Loss: 0.118673, Val Acc: 0.773196\n",
      "Epoch 17244 - Train Loss: 0.093574, Train Acc: 0.852564 | Val Loss: 0.118672, Val Acc: 0.773196\n",
      "Epoch 17245 - Train Loss: 0.093571, Train Acc: 0.852564 | Val Loss: 0.118670, Val Acc: 0.773196\n",
      "Epoch 17246 - Train Loss: 0.093568, Train Acc: 0.852564 | Val Loss: 0.118668, Val Acc: 0.773196\n",
      "Epoch 17247 - Train Loss: 0.093565, Train Acc: 0.852564 | Val Loss: 0.118667, Val Acc: 0.773196\n",
      "Epoch 17248 - Train Loss: 0.093562, Train Acc: 0.852564 | Val Loss: 0.118665, Val Acc: 0.773196\n",
      "Epoch 17249 - Train Loss: 0.093559, Train Acc: 0.852564 | Val Loss: 0.118663, Val Acc: 0.773196\n",
      "Epoch 17250 - Train Loss: 0.093556, Train Acc: 0.852564 | Val Loss: 0.118662, Val Acc: 0.773196\n",
      "Epoch 17251 - Train Loss: 0.093554, Train Acc: 0.852564 | Val Loss: 0.118660, Val Acc: 0.773196\n",
      "Epoch 17252 - Train Loss: 0.093551, Train Acc: 0.852564 | Val Loss: 0.118658, Val Acc: 0.773196\n",
      "Epoch 17253 - Train Loss: 0.093548, Train Acc: 0.852564 | Val Loss: 0.118657, Val Acc: 0.773196\n",
      "Epoch 17254 - Train Loss: 0.093545, Train Acc: 0.852564 | Val Loss: 0.118655, Val Acc: 0.773196\n",
      "Epoch 17255 - Train Loss: 0.093542, Train Acc: 0.852564 | Val Loss: 0.118653, Val Acc: 0.773196\n",
      "Epoch 17256 - Train Loss: 0.093539, Train Acc: 0.852564 | Val Loss: 0.118652, Val Acc: 0.773196\n",
      "Epoch 17257 - Train Loss: 0.093536, Train Acc: 0.852564 | Val Loss: 0.118650, Val Acc: 0.773196\n",
      "Epoch 17258 - Train Loss: 0.093533, Train Acc: 0.852564 | Val Loss: 0.118648, Val Acc: 0.773196\n",
      "Epoch 17259 - Train Loss: 0.093530, Train Acc: 0.852564 | Val Loss: 0.118647, Val Acc: 0.773196\n",
      "Epoch 17260 - Train Loss: 0.093527, Train Acc: 0.852564 | Val Loss: 0.118645, Val Acc: 0.773196\n",
      "Epoch 17261 - Train Loss: 0.093525, Train Acc: 0.852564 | Val Loss: 0.118643, Val Acc: 0.773196\n",
      "Epoch 17262 - Train Loss: 0.093522, Train Acc: 0.852564 | Val Loss: 0.118642, Val Acc: 0.773196\n",
      "Epoch 17263 - Train Loss: 0.093519, Train Acc: 0.852564 | Val Loss: 0.118640, Val Acc: 0.773196\n",
      "Epoch 17264 - Train Loss: 0.093516, Train Acc: 0.852564 | Val Loss: 0.118638, Val Acc: 0.773196\n",
      "Epoch 17265 - Train Loss: 0.093513, Train Acc: 0.852564 | Val Loss: 0.118637, Val Acc: 0.773196\n",
      "Epoch 17266 - Train Loss: 0.093510, Train Acc: 0.852564 | Val Loss: 0.118635, Val Acc: 0.773196\n",
      "Epoch 17267 - Train Loss: 0.093507, Train Acc: 0.852564 | Val Loss: 0.118633, Val Acc: 0.773196\n",
      "Epoch 17268 - Train Loss: 0.093504, Train Acc: 0.852564 | Val Loss: 0.118632, Val Acc: 0.773196\n",
      "Epoch 17269 - Train Loss: 0.093501, Train Acc: 0.852564 | Val Loss: 0.118630, Val Acc: 0.773196\n",
      "Epoch 17270 - Train Loss: 0.093498, Train Acc: 0.852564 | Val Loss: 0.118628, Val Acc: 0.773196\n",
      "Epoch 17271 - Train Loss: 0.093496, Train Acc: 0.852564 | Val Loss: 0.118627, Val Acc: 0.773196\n",
      "Epoch 17272 - Train Loss: 0.093493, Train Acc: 0.852564 | Val Loss: 0.118625, Val Acc: 0.773196\n",
      "Epoch 17273 - Train Loss: 0.093490, Train Acc: 0.852564 | Val Loss: 0.118623, Val Acc: 0.773196\n",
      "Epoch 17274 - Train Loss: 0.093487, Train Acc: 0.852564 | Val Loss: 0.118622, Val Acc: 0.773196\n",
      "Epoch 17275 - Train Loss: 0.093484, Train Acc: 0.852564 | Val Loss: 0.118620, Val Acc: 0.773196\n",
      "Epoch 17276 - Train Loss: 0.093481, Train Acc: 0.852564 | Val Loss: 0.118618, Val Acc: 0.773196\n",
      "Epoch 17277 - Train Loss: 0.093478, Train Acc: 0.852564 | Val Loss: 0.118617, Val Acc: 0.773196\n",
      "Epoch 17278 - Train Loss: 0.093475, Train Acc: 0.852564 | Val Loss: 0.118615, Val Acc: 0.773196\n",
      "Epoch 17279 - Train Loss: 0.093472, Train Acc: 0.852564 | Val Loss: 0.118613, Val Acc: 0.773196\n",
      "Epoch 17280 - Train Loss: 0.093469, Train Acc: 0.852564 | Val Loss: 0.118612, Val Acc: 0.773196\n",
      "Epoch 17281 - Train Loss: 0.093467, Train Acc: 0.852564 | Val Loss: 0.118610, Val Acc: 0.773196\n",
      "Epoch 17282 - Train Loss: 0.093464, Train Acc: 0.852564 | Val Loss: 0.118609, Val Acc: 0.773196\n",
      "Epoch 17283 - Train Loss: 0.093461, Train Acc: 0.852564 | Val Loss: 0.118607, Val Acc: 0.773196\n",
      "Epoch 17284 - Train Loss: 0.093458, Train Acc: 0.852564 | Val Loss: 0.118605, Val Acc: 0.773196\n",
      "Epoch 17285 - Train Loss: 0.093455, Train Acc: 0.852564 | Val Loss: 0.118604, Val Acc: 0.773196\n",
      "Epoch 17286 - Train Loss: 0.093452, Train Acc: 0.852564 | Val Loss: 0.118602, Val Acc: 0.773196\n",
      "Epoch 17287 - Train Loss: 0.093449, Train Acc: 0.852564 | Val Loss: 0.118600, Val Acc: 0.773196\n",
      "Epoch 17288 - Train Loss: 0.093446, Train Acc: 0.852564 | Val Loss: 0.118599, Val Acc: 0.773196\n",
      "Epoch 17289 - Train Loss: 0.093443, Train Acc: 0.852564 | Val Loss: 0.118597, Val Acc: 0.773196\n",
      "Epoch 17290 - Train Loss: 0.093441, Train Acc: 0.852564 | Val Loss: 0.118595, Val Acc: 0.773196\n",
      "Epoch 17291 - Train Loss: 0.093438, Train Acc: 0.852564 | Val Loss: 0.118594, Val Acc: 0.773196\n",
      "Epoch 17292 - Train Loss: 0.093435, Train Acc: 0.852564 | Val Loss: 0.118592, Val Acc: 0.773196\n",
      "Epoch 17293 - Train Loss: 0.093432, Train Acc: 0.852564 | Val Loss: 0.118590, Val Acc: 0.773196\n",
      "Epoch 17294 - Train Loss: 0.093429, Train Acc: 0.852564 | Val Loss: 0.118589, Val Acc: 0.773196\n",
      "Epoch 17295 - Train Loss: 0.093426, Train Acc: 0.852564 | Val Loss: 0.118587, Val Acc: 0.773196\n",
      "Epoch 17296 - Train Loss: 0.093423, Train Acc: 0.852564 | Val Loss: 0.118585, Val Acc: 0.773196\n",
      "Epoch 17297 - Train Loss: 0.093420, Train Acc: 0.852564 | Val Loss: 0.118584, Val Acc: 0.773196\n",
      "Epoch 17298 - Train Loss: 0.093417, Train Acc: 0.852564 | Val Loss: 0.118582, Val Acc: 0.773196\n",
      "Epoch 17299 - Train Loss: 0.093415, Train Acc: 0.852564 | Val Loss: 0.118580, Val Acc: 0.773196\n",
      "Epoch 17300 - Train Loss: 0.093412, Train Acc: 0.852564 | Val Loss: 0.118579, Val Acc: 0.773196\n",
      "Epoch 17301 - Train Loss: 0.093409, Train Acc: 0.852564 | Val Loss: 0.118577, Val Acc: 0.773196\n",
      "Epoch 17302 - Train Loss: 0.093406, Train Acc: 0.852564 | Val Loss: 0.118575, Val Acc: 0.773196\n",
      "Epoch 17303 - Train Loss: 0.093403, Train Acc: 0.852564 | Val Loss: 0.118574, Val Acc: 0.773196\n",
      "Epoch 17304 - Train Loss: 0.093400, Train Acc: 0.852564 | Val Loss: 0.118572, Val Acc: 0.773196\n",
      "Epoch 17305 - Train Loss: 0.093397, Train Acc: 0.852564 | Val Loss: 0.118570, Val Acc: 0.773196\n",
      "Epoch 17306 - Train Loss: 0.093394, Train Acc: 0.852564 | Val Loss: 0.118569, Val Acc: 0.773196\n",
      "Epoch 17307 - Train Loss: 0.093391, Train Acc: 0.852564 | Val Loss: 0.118567, Val Acc: 0.773196\n",
      "Epoch 17308 - Train Loss: 0.093389, Train Acc: 0.852564 | Val Loss: 0.118565, Val Acc: 0.773196\n",
      "Epoch 17309 - Train Loss: 0.093386, Train Acc: 0.852564 | Val Loss: 0.118564, Val Acc: 0.773196\n",
      "Epoch 17310 - Train Loss: 0.093383, Train Acc: 0.852564 | Val Loss: 0.118562, Val Acc: 0.773196\n",
      "Epoch 17311 - Train Loss: 0.093380, Train Acc: 0.852564 | Val Loss: 0.118560, Val Acc: 0.773196\n",
      "Epoch 17312 - Train Loss: 0.093377, Train Acc: 0.852564 | Val Loss: 0.118559, Val Acc: 0.773196\n",
      "Epoch 17313 - Train Loss: 0.093374, Train Acc: 0.852564 | Val Loss: 0.118557, Val Acc: 0.773196\n",
      "Epoch 17314 - Train Loss: 0.093371, Train Acc: 0.852564 | Val Loss: 0.118556, Val Acc: 0.773196\n",
      "Epoch 17315 - Train Loss: 0.093368, Train Acc: 0.852564 | Val Loss: 0.118554, Val Acc: 0.773196\n",
      "Epoch 17316 - Train Loss: 0.093365, Train Acc: 0.852564 | Val Loss: 0.118552, Val Acc: 0.773196\n",
      "Epoch 17317 - Train Loss: 0.093363, Train Acc: 0.852564 | Val Loss: 0.118551, Val Acc: 0.773196\n",
      "Epoch 17318 - Train Loss: 0.093360, Train Acc: 0.852564 | Val Loss: 0.118549, Val Acc: 0.773196\n",
      "Epoch 17319 - Train Loss: 0.093357, Train Acc: 0.852564 | Val Loss: 0.118547, Val Acc: 0.773196\n",
      "Epoch 17320 - Train Loss: 0.093354, Train Acc: 0.852564 | Val Loss: 0.118546, Val Acc: 0.773196\n",
      "Epoch 17321 - Train Loss: 0.093351, Train Acc: 0.852564 | Val Loss: 0.118544, Val Acc: 0.773196\n",
      "Epoch 17322 - Train Loss: 0.093348, Train Acc: 0.852564 | Val Loss: 0.118542, Val Acc: 0.773196\n",
      "Epoch 17323 - Train Loss: 0.093345, Train Acc: 0.852564 | Val Loss: 0.118541, Val Acc: 0.773196\n",
      "Epoch 17324 - Train Loss: 0.093342, Train Acc: 0.852564 | Val Loss: 0.118539, Val Acc: 0.773196\n",
      "Epoch 17325 - Train Loss: 0.093339, Train Acc: 0.852564 | Val Loss: 0.118537, Val Acc: 0.773196\n",
      "Epoch 17326 - Train Loss: 0.093337, Train Acc: 0.853846 | Val Loss: 0.118536, Val Acc: 0.773196\n",
      "Epoch 17327 - Train Loss: 0.093334, Train Acc: 0.853846 | Val Loss: 0.118534, Val Acc: 0.773196\n",
      "Epoch 17328 - Train Loss: 0.093331, Train Acc: 0.853846 | Val Loss: 0.118532, Val Acc: 0.773196\n",
      "Epoch 17329 - Train Loss: 0.093328, Train Acc: 0.853846 | Val Loss: 0.118531, Val Acc: 0.773196\n",
      "Epoch 17330 - Train Loss: 0.093325, Train Acc: 0.853846 | Val Loss: 0.118529, Val Acc: 0.773196\n",
      "Epoch 17331 - Train Loss: 0.093322, Train Acc: 0.853846 | Val Loss: 0.118528, Val Acc: 0.773196\n",
      "Epoch 17332 - Train Loss: 0.093319, Train Acc: 0.853846 | Val Loss: 0.118526, Val Acc: 0.773196\n",
      "Epoch 17333 - Train Loss: 0.093316, Train Acc: 0.853846 | Val Loss: 0.118524, Val Acc: 0.773196\n",
      "Epoch 17334 - Train Loss: 0.093314, Train Acc: 0.853846 | Val Loss: 0.118523, Val Acc: 0.773196\n",
      "Epoch 17335 - Train Loss: 0.093311, Train Acc: 0.853846 | Val Loss: 0.118521, Val Acc: 0.773196\n",
      "Epoch 17336 - Train Loss: 0.093308, Train Acc: 0.853846 | Val Loss: 0.118519, Val Acc: 0.773196\n",
      "Epoch 17337 - Train Loss: 0.093305, Train Acc: 0.853846 | Val Loss: 0.118518, Val Acc: 0.773196\n",
      "Epoch 17338 - Train Loss: 0.093302, Train Acc: 0.853846 | Val Loss: 0.118516, Val Acc: 0.773196\n",
      "Epoch 17339 - Train Loss: 0.093299, Train Acc: 0.853846 | Val Loss: 0.118514, Val Acc: 0.773196\n",
      "Epoch 17340 - Train Loss: 0.093296, Train Acc: 0.853846 | Val Loss: 0.118513, Val Acc: 0.773196\n",
      "Epoch 17341 - Train Loss: 0.093293, Train Acc: 0.853846 | Val Loss: 0.118511, Val Acc: 0.773196\n",
      "Epoch 17342 - Train Loss: 0.093291, Train Acc: 0.853846 | Val Loss: 0.118509, Val Acc: 0.773196\n",
      "Epoch 17343 - Train Loss: 0.093288, Train Acc: 0.853846 | Val Loss: 0.118508, Val Acc: 0.773196\n",
      "Epoch 17344 - Train Loss: 0.093285, Train Acc: 0.853846 | Val Loss: 0.118506, Val Acc: 0.773196\n",
      "Epoch 17345 - Train Loss: 0.093282, Train Acc: 0.855128 | Val Loss: 0.118505, Val Acc: 0.773196\n",
      "Epoch 17346 - Train Loss: 0.093279, Train Acc: 0.855128 | Val Loss: 0.118503, Val Acc: 0.773196\n",
      "Epoch 17347 - Train Loss: 0.093276, Train Acc: 0.855128 | Val Loss: 0.118501, Val Acc: 0.773196\n",
      "Epoch 17348 - Train Loss: 0.093273, Train Acc: 0.855128 | Val Loss: 0.118500, Val Acc: 0.773196\n",
      "Epoch 17349 - Train Loss: 0.093270, Train Acc: 0.855128 | Val Loss: 0.118498, Val Acc: 0.773196\n",
      "Epoch 17350 - Train Loss: 0.093268, Train Acc: 0.855128 | Val Loss: 0.118496, Val Acc: 0.773196\n",
      "Epoch 17351 - Train Loss: 0.093265, Train Acc: 0.855128 | Val Loss: 0.118495, Val Acc: 0.773196\n",
      "Epoch 17352 - Train Loss: 0.093262, Train Acc: 0.855128 | Val Loss: 0.118493, Val Acc: 0.773196\n",
      "Epoch 17353 - Train Loss: 0.093259, Train Acc: 0.855128 | Val Loss: 0.118491, Val Acc: 0.773196\n",
      "Epoch 17354 - Train Loss: 0.093256, Train Acc: 0.855128 | Val Loss: 0.118490, Val Acc: 0.773196\n",
      "Epoch 17355 - Train Loss: 0.093253, Train Acc: 0.855128 | Val Loss: 0.118488, Val Acc: 0.773196\n",
      "Epoch 17356 - Train Loss: 0.093250, Train Acc: 0.855128 | Val Loss: 0.118486, Val Acc: 0.773196\n",
      "Epoch 17357 - Train Loss: 0.093247, Train Acc: 0.855128 | Val Loss: 0.118485, Val Acc: 0.773196\n",
      "Epoch 17358 - Train Loss: 0.093245, Train Acc: 0.855128 | Val Loss: 0.118483, Val Acc: 0.773196\n",
      "Epoch 17359 - Train Loss: 0.093242, Train Acc: 0.855128 | Val Loss: 0.118482, Val Acc: 0.773196\n",
      "Epoch 17360 - Train Loss: 0.093239, Train Acc: 0.855128 | Val Loss: 0.118480, Val Acc: 0.773196\n",
      "Epoch 17361 - Train Loss: 0.093236, Train Acc: 0.855128 | Val Loss: 0.118478, Val Acc: 0.773196\n",
      "Epoch 17362 - Train Loss: 0.093233, Train Acc: 0.855128 | Val Loss: 0.118477, Val Acc: 0.773196\n",
      "Epoch 17363 - Train Loss: 0.093230, Train Acc: 0.855128 | Val Loss: 0.118475, Val Acc: 0.773196\n",
      "Epoch 17364 - Train Loss: 0.093227, Train Acc: 0.855128 | Val Loss: 0.118473, Val Acc: 0.773196\n",
      "Epoch 17365 - Train Loss: 0.093224, Train Acc: 0.855128 | Val Loss: 0.118472, Val Acc: 0.773196\n",
      "Epoch 17366 - Train Loss: 0.093222, Train Acc: 0.855128 | Val Loss: 0.118470, Val Acc: 0.773196\n",
      "Epoch 17367 - Train Loss: 0.093219, Train Acc: 0.855128 | Val Loss: 0.118468, Val Acc: 0.773196\n",
      "Epoch 17368 - Train Loss: 0.093216, Train Acc: 0.855128 | Val Loss: 0.118467, Val Acc: 0.773196\n",
      "Epoch 17369 - Train Loss: 0.093213, Train Acc: 0.855128 | Val Loss: 0.118465, Val Acc: 0.773196\n",
      "Epoch 17370 - Train Loss: 0.093210, Train Acc: 0.855128 | Val Loss: 0.118464, Val Acc: 0.773196\n",
      "Epoch 17371 - Train Loss: 0.093207, Train Acc: 0.855128 | Val Loss: 0.118462, Val Acc: 0.773196\n",
      "Epoch 17372 - Train Loss: 0.093204, Train Acc: 0.855128 | Val Loss: 0.118460, Val Acc: 0.773196\n",
      "Epoch 17373 - Train Loss: 0.093202, Train Acc: 0.855128 | Val Loss: 0.118459, Val Acc: 0.773196\n",
      "Epoch 17374 - Train Loss: 0.093199, Train Acc: 0.855128 | Val Loss: 0.118457, Val Acc: 0.773196\n",
      "Epoch 17375 - Train Loss: 0.093196, Train Acc: 0.855128 | Val Loss: 0.118455, Val Acc: 0.773196\n",
      "Epoch 17376 - Train Loss: 0.093193, Train Acc: 0.855128 | Val Loss: 0.118454, Val Acc: 0.773196\n",
      "Epoch 17377 - Train Loss: 0.093190, Train Acc: 0.855128 | Val Loss: 0.118452, Val Acc: 0.773196\n",
      "Epoch 17378 - Train Loss: 0.093187, Train Acc: 0.855128 | Val Loss: 0.118450, Val Acc: 0.773196\n",
      "Epoch 17379 - Train Loss: 0.093184, Train Acc: 0.855128 | Val Loss: 0.118449, Val Acc: 0.773196\n",
      "Epoch 17380 - Train Loss: 0.093181, Train Acc: 0.855128 | Val Loss: 0.118447, Val Acc: 0.773196\n",
      "Epoch 17381 - Train Loss: 0.093179, Train Acc: 0.855128 | Val Loss: 0.118446, Val Acc: 0.773196\n",
      "Epoch 17382 - Train Loss: 0.093176, Train Acc: 0.855128 | Val Loss: 0.118444, Val Acc: 0.773196\n",
      "Epoch 17383 - Train Loss: 0.093173, Train Acc: 0.855128 | Val Loss: 0.118442, Val Acc: 0.773196\n",
      "Epoch 17384 - Train Loss: 0.093170, Train Acc: 0.855128 | Val Loss: 0.118441, Val Acc: 0.773196\n",
      "Epoch 17385 - Train Loss: 0.093167, Train Acc: 0.855128 | Val Loss: 0.118439, Val Acc: 0.773196\n",
      "Epoch 17386 - Train Loss: 0.093164, Train Acc: 0.855128 | Val Loss: 0.118437, Val Acc: 0.773196\n",
      "Epoch 17387 - Train Loss: 0.093161, Train Acc: 0.855128 | Val Loss: 0.118436, Val Acc: 0.773196\n",
      "Epoch 17388 - Train Loss: 0.093159, Train Acc: 0.855128 | Val Loss: 0.118434, Val Acc: 0.773196\n",
      "Epoch 17389 - Train Loss: 0.093156, Train Acc: 0.855128 | Val Loss: 0.118432, Val Acc: 0.773196\n",
      "Epoch 17390 - Train Loss: 0.093153, Train Acc: 0.855128 | Val Loss: 0.118431, Val Acc: 0.773196\n",
      "Epoch 17391 - Train Loss: 0.093150, Train Acc: 0.855128 | Val Loss: 0.118429, Val Acc: 0.773196\n",
      "Epoch 17392 - Train Loss: 0.093147, Train Acc: 0.855128 | Val Loss: 0.118428, Val Acc: 0.773196\n",
      "Epoch 17393 - Train Loss: 0.093144, Train Acc: 0.855128 | Val Loss: 0.118426, Val Acc: 0.773196\n",
      "Epoch 17394 - Train Loss: 0.093141, Train Acc: 0.855128 | Val Loss: 0.118424, Val Acc: 0.773196\n",
      "Epoch 17395 - Train Loss: 0.093139, Train Acc: 0.855128 | Val Loss: 0.118423, Val Acc: 0.773196\n",
      "Epoch 17396 - Train Loss: 0.093136, Train Acc: 0.855128 | Val Loss: 0.118421, Val Acc: 0.773196\n",
      "Epoch 17397 - Train Loss: 0.093133, Train Acc: 0.855128 | Val Loss: 0.118419, Val Acc: 0.773196\n",
      "Epoch 17398 - Train Loss: 0.093130, Train Acc: 0.855128 | Val Loss: 0.118418, Val Acc: 0.773196\n",
      "Epoch 17399 - Train Loss: 0.093127, Train Acc: 0.855128 | Val Loss: 0.118416, Val Acc: 0.773196\n",
      "Epoch 17400 - Train Loss: 0.093124, Train Acc: 0.855128 | Val Loss: 0.118415, Val Acc: 0.773196\n",
      "Epoch 17401 - Train Loss: 0.093121, Train Acc: 0.855128 | Val Loss: 0.118413, Val Acc: 0.773196\n",
      "Epoch 17402 - Train Loss: 0.093119, Train Acc: 0.855128 | Val Loss: 0.118411, Val Acc: 0.773196\n",
      "Epoch 17403 - Train Loss: 0.093116, Train Acc: 0.855128 | Val Loss: 0.118410, Val Acc: 0.773196\n",
      "Epoch 17404 - Train Loss: 0.093113, Train Acc: 0.855128 | Val Loss: 0.118408, Val Acc: 0.773196\n",
      "Epoch 17405 - Train Loss: 0.093110, Train Acc: 0.855128 | Val Loss: 0.118406, Val Acc: 0.773196\n",
      "Epoch 17406 - Train Loss: 0.093107, Train Acc: 0.855128 | Val Loss: 0.118405, Val Acc: 0.773196\n",
      "Epoch 17407 - Train Loss: 0.093104, Train Acc: 0.855128 | Val Loss: 0.118403, Val Acc: 0.773196\n",
      "Epoch 17408 - Train Loss: 0.093101, Train Acc: 0.855128 | Val Loss: 0.118402, Val Acc: 0.773196\n",
      "Epoch 17409 - Train Loss: 0.093099, Train Acc: 0.855128 | Val Loss: 0.118400, Val Acc: 0.773196\n",
      "Epoch 17410 - Train Loss: 0.093096, Train Acc: 0.855128 | Val Loss: 0.118398, Val Acc: 0.773196\n",
      "Epoch 17411 - Train Loss: 0.093093, Train Acc: 0.855128 | Val Loss: 0.118397, Val Acc: 0.773196\n",
      "Epoch 17412 - Train Loss: 0.093090, Train Acc: 0.855128 | Val Loss: 0.118395, Val Acc: 0.773196\n",
      "Epoch 17413 - Train Loss: 0.093087, Train Acc: 0.855128 | Val Loss: 0.118393, Val Acc: 0.773196\n",
      "Epoch 17414 - Train Loss: 0.093084, Train Acc: 0.855128 | Val Loss: 0.118392, Val Acc: 0.773196\n",
      "Epoch 17415 - Train Loss: 0.093081, Train Acc: 0.855128 | Val Loss: 0.118390, Val Acc: 0.773196\n",
      "Epoch 17416 - Train Loss: 0.093079, Train Acc: 0.855128 | Val Loss: 0.118389, Val Acc: 0.773196\n",
      "Epoch 17417 - Train Loss: 0.093076, Train Acc: 0.855128 | Val Loss: 0.118387, Val Acc: 0.773196\n",
      "Epoch 17418 - Train Loss: 0.093073, Train Acc: 0.855128 | Val Loss: 0.118385, Val Acc: 0.773196\n",
      "Epoch 17419 - Train Loss: 0.093070, Train Acc: 0.855128 | Val Loss: 0.118384, Val Acc: 0.773196\n",
      "Epoch 17420 - Train Loss: 0.093067, Train Acc: 0.855128 | Val Loss: 0.118382, Val Acc: 0.773196\n",
      "Epoch 17421 - Train Loss: 0.093064, Train Acc: 0.855128 | Val Loss: 0.118380, Val Acc: 0.773196\n",
      "Epoch 17422 - Train Loss: 0.093061, Train Acc: 0.855128 | Val Loss: 0.118379, Val Acc: 0.773196\n",
      "Epoch 17423 - Train Loss: 0.093059, Train Acc: 0.855128 | Val Loss: 0.118377, Val Acc: 0.773196\n",
      "Epoch 17424 - Train Loss: 0.093056, Train Acc: 0.855128 | Val Loss: 0.118376, Val Acc: 0.773196\n",
      "Epoch 17425 - Train Loss: 0.093053, Train Acc: 0.855128 | Val Loss: 0.118374, Val Acc: 0.773196\n",
      "Epoch 17426 - Train Loss: 0.093050, Train Acc: 0.855128 | Val Loss: 0.118372, Val Acc: 0.773196\n",
      "Epoch 17427 - Train Loss: 0.093047, Train Acc: 0.855128 | Val Loss: 0.118371, Val Acc: 0.773196\n",
      "Epoch 17428 - Train Loss: 0.093044, Train Acc: 0.855128 | Val Loss: 0.118369, Val Acc: 0.773196\n",
      "Epoch 17429 - Train Loss: 0.093041, Train Acc: 0.855128 | Val Loss: 0.118367, Val Acc: 0.773196\n",
      "Epoch 17430 - Train Loss: 0.093039, Train Acc: 0.855128 | Val Loss: 0.118366, Val Acc: 0.773196\n",
      "Epoch 17431 - Train Loss: 0.093036, Train Acc: 0.856410 | Val Loss: 0.118364, Val Acc: 0.773196\n",
      "Epoch 17432 - Train Loss: 0.093033, Train Acc: 0.856410 | Val Loss: 0.118363, Val Acc: 0.773196\n",
      "Epoch 17433 - Train Loss: 0.093030, Train Acc: 0.856410 | Val Loss: 0.118361, Val Acc: 0.773196\n",
      "Epoch 17434 - Train Loss: 0.093027, Train Acc: 0.856410 | Val Loss: 0.118359, Val Acc: 0.773196\n",
      "Epoch 17435 - Train Loss: 0.093024, Train Acc: 0.856410 | Val Loss: 0.118358, Val Acc: 0.773196\n",
      "Epoch 17436 - Train Loss: 0.093022, Train Acc: 0.856410 | Val Loss: 0.118356, Val Acc: 0.773196\n",
      "Epoch 17437 - Train Loss: 0.093019, Train Acc: 0.856410 | Val Loss: 0.118355, Val Acc: 0.773196\n",
      "Epoch 17438 - Train Loss: 0.093016, Train Acc: 0.856410 | Val Loss: 0.118353, Val Acc: 0.773196\n",
      "Epoch 17439 - Train Loss: 0.093013, Train Acc: 0.856410 | Val Loss: 0.118351, Val Acc: 0.773196\n",
      "Epoch 17440 - Train Loss: 0.093010, Train Acc: 0.856410 | Val Loss: 0.118350, Val Acc: 0.773196\n",
      "Epoch 17441 - Train Loss: 0.093007, Train Acc: 0.856410 | Val Loss: 0.118348, Val Acc: 0.773196\n",
      "Epoch 17442 - Train Loss: 0.093004, Train Acc: 0.856410 | Val Loss: 0.118346, Val Acc: 0.773196\n",
      "Epoch 17443 - Train Loss: 0.093002, Train Acc: 0.856410 | Val Loss: 0.118345, Val Acc: 0.773196\n",
      "Epoch 17444 - Train Loss: 0.092999, Train Acc: 0.856410 | Val Loss: 0.118343, Val Acc: 0.773196\n",
      "Epoch 17445 - Train Loss: 0.092996, Train Acc: 0.856410 | Val Loss: 0.118342, Val Acc: 0.773196\n",
      "Epoch 17446 - Train Loss: 0.092993, Train Acc: 0.856410 | Val Loss: 0.118340, Val Acc: 0.773196\n",
      "Epoch 17447 - Train Loss: 0.092990, Train Acc: 0.856410 | Val Loss: 0.118338, Val Acc: 0.773196\n",
      "Epoch 17448 - Train Loss: 0.092987, Train Acc: 0.856410 | Val Loss: 0.118337, Val Acc: 0.773196\n",
      "Epoch 17449 - Train Loss: 0.092985, Train Acc: 0.856410 | Val Loss: 0.118335, Val Acc: 0.773196\n",
      "Epoch 17450 - Train Loss: 0.092982, Train Acc: 0.856410 | Val Loss: 0.118334, Val Acc: 0.773196\n",
      "Epoch 17451 - Train Loss: 0.092979, Train Acc: 0.856410 | Val Loss: 0.118332, Val Acc: 0.773196\n",
      "Epoch 17452 - Train Loss: 0.092976, Train Acc: 0.856410 | Val Loss: 0.118330, Val Acc: 0.773196\n",
      "Epoch 17453 - Train Loss: 0.092973, Train Acc: 0.856410 | Val Loss: 0.118329, Val Acc: 0.773196\n",
      "Epoch 17454 - Train Loss: 0.092970, Train Acc: 0.856410 | Val Loss: 0.118327, Val Acc: 0.773196\n",
      "Epoch 17455 - Train Loss: 0.092967, Train Acc: 0.856410 | Val Loss: 0.118325, Val Acc: 0.773196\n",
      "Epoch 17456 - Train Loss: 0.092965, Train Acc: 0.856410 | Val Loss: 0.118324, Val Acc: 0.773196\n",
      "Epoch 17457 - Train Loss: 0.092962, Train Acc: 0.856410 | Val Loss: 0.118322, Val Acc: 0.773196\n",
      "Epoch 17458 - Train Loss: 0.092959, Train Acc: 0.856410 | Val Loss: 0.118321, Val Acc: 0.773196\n",
      "Epoch 17459 - Train Loss: 0.092956, Train Acc: 0.856410 | Val Loss: 0.118319, Val Acc: 0.773196\n",
      "Epoch 17460 - Train Loss: 0.092953, Train Acc: 0.856410 | Val Loss: 0.118317, Val Acc: 0.773196\n",
      "Epoch 17461 - Train Loss: 0.092950, Train Acc: 0.856410 | Val Loss: 0.118316, Val Acc: 0.773196\n",
      "Epoch 17462 - Train Loss: 0.092948, Train Acc: 0.856410 | Val Loss: 0.118314, Val Acc: 0.773196\n",
      "Epoch 17463 - Train Loss: 0.092945, Train Acc: 0.856410 | Val Loss: 0.118313, Val Acc: 0.773196\n",
      "Epoch 17464 - Train Loss: 0.092942, Train Acc: 0.856410 | Val Loss: 0.118311, Val Acc: 0.773196\n",
      "Epoch 17465 - Train Loss: 0.092939, Train Acc: 0.856410 | Val Loss: 0.118309, Val Acc: 0.773196\n",
      "Epoch 17466 - Train Loss: 0.092936, Train Acc: 0.856410 | Val Loss: 0.118308, Val Acc: 0.773196\n",
      "Epoch 17467 - Train Loss: 0.092933, Train Acc: 0.856410 | Val Loss: 0.118306, Val Acc: 0.773196\n",
      "Epoch 17468 - Train Loss: 0.092931, Train Acc: 0.856410 | Val Loss: 0.118304, Val Acc: 0.773196\n",
      "Epoch 17469 - Train Loss: 0.092928, Train Acc: 0.856410 | Val Loss: 0.118303, Val Acc: 0.773196\n",
      "Epoch 17470 - Train Loss: 0.092925, Train Acc: 0.856410 | Val Loss: 0.118301, Val Acc: 0.773196\n",
      "Epoch 17471 - Train Loss: 0.092922, Train Acc: 0.856410 | Val Loss: 0.118300, Val Acc: 0.773196\n",
      "Epoch 17472 - Train Loss: 0.092919, Train Acc: 0.856410 | Val Loss: 0.118298, Val Acc: 0.773196\n",
      "Epoch 17473 - Train Loss: 0.092916, Train Acc: 0.856410 | Val Loss: 0.118296, Val Acc: 0.773196\n",
      "Epoch 17474 - Train Loss: 0.092914, Train Acc: 0.856410 | Val Loss: 0.118295, Val Acc: 0.773196\n",
      "Epoch 17475 - Train Loss: 0.092911, Train Acc: 0.856410 | Val Loss: 0.118293, Val Acc: 0.773196\n",
      "Epoch 17476 - Train Loss: 0.092908, Train Acc: 0.856410 | Val Loss: 0.118292, Val Acc: 0.773196\n",
      "Epoch 17477 - Train Loss: 0.092905, Train Acc: 0.856410 | Val Loss: 0.118290, Val Acc: 0.773196\n",
      "Epoch 17478 - Train Loss: 0.092902, Train Acc: 0.856410 | Val Loss: 0.118288, Val Acc: 0.773196\n",
      "Epoch 17479 - Train Loss: 0.092899, Train Acc: 0.856410 | Val Loss: 0.118287, Val Acc: 0.773196\n",
      "Epoch 17480 - Train Loss: 0.092896, Train Acc: 0.856410 | Val Loss: 0.118285, Val Acc: 0.773196\n",
      "Epoch 17481 - Train Loss: 0.092894, Train Acc: 0.856410 | Val Loss: 0.118284, Val Acc: 0.773196\n",
      "Epoch 17482 - Train Loss: 0.092891, Train Acc: 0.856410 | Val Loss: 0.118282, Val Acc: 0.773196\n",
      "Epoch 17483 - Train Loss: 0.092888, Train Acc: 0.856410 | Val Loss: 0.118280, Val Acc: 0.773196\n",
      "Epoch 17484 - Train Loss: 0.092885, Train Acc: 0.856410 | Val Loss: 0.118279, Val Acc: 0.773196\n",
      "Epoch 17485 - Train Loss: 0.092882, Train Acc: 0.856410 | Val Loss: 0.118277, Val Acc: 0.773196\n",
      "Epoch 17486 - Train Loss: 0.092879, Train Acc: 0.856410 | Val Loss: 0.118276, Val Acc: 0.773196\n",
      "Epoch 17487 - Train Loss: 0.092877, Train Acc: 0.856410 | Val Loss: 0.118274, Val Acc: 0.773196\n",
      "Epoch 17488 - Train Loss: 0.092874, Train Acc: 0.856410 | Val Loss: 0.118272, Val Acc: 0.773196\n",
      "Epoch 17489 - Train Loss: 0.092871, Train Acc: 0.856410 | Val Loss: 0.118271, Val Acc: 0.773196\n",
      "Epoch 17490 - Train Loss: 0.092868, Train Acc: 0.856410 | Val Loss: 0.118269, Val Acc: 0.773196\n",
      "Epoch 17491 - Train Loss: 0.092865, Train Acc: 0.856410 | Val Loss: 0.118268, Val Acc: 0.773196\n",
      "Epoch 17492 - Train Loss: 0.092863, Train Acc: 0.856410 | Val Loss: 0.118266, Val Acc: 0.773196\n",
      "Epoch 17493 - Train Loss: 0.092860, Train Acc: 0.856410 | Val Loss: 0.118264, Val Acc: 0.773196\n",
      "Epoch 17494 - Train Loss: 0.092857, Train Acc: 0.856410 | Val Loss: 0.118263, Val Acc: 0.773196\n",
      "Epoch 17495 - Train Loss: 0.092854, Train Acc: 0.856410 | Val Loss: 0.118261, Val Acc: 0.773196\n",
      "Epoch 17496 - Train Loss: 0.092851, Train Acc: 0.856410 | Val Loss: 0.118260, Val Acc: 0.773196\n",
      "Epoch 17497 - Train Loss: 0.092848, Train Acc: 0.856410 | Val Loss: 0.118258, Val Acc: 0.773196\n",
      "Epoch 17498 - Train Loss: 0.092846, Train Acc: 0.856410 | Val Loss: 0.118256, Val Acc: 0.773196\n",
      "Epoch 17499 - Train Loss: 0.092843, Train Acc: 0.856410 | Val Loss: 0.118255, Val Acc: 0.773196\n",
      "Epoch 17500 - Train Loss: 0.092840, Train Acc: 0.856410 | Val Loss: 0.118253, Val Acc: 0.773196\n",
      "Epoch 17501 - Train Loss: 0.092837, Train Acc: 0.856410 | Val Loss: 0.118252, Val Acc: 0.773196\n",
      "Epoch 17502 - Train Loss: 0.092834, Train Acc: 0.856410 | Val Loss: 0.118250, Val Acc: 0.773196\n",
      "Epoch 17503 - Train Loss: 0.092831, Train Acc: 0.856410 | Val Loss: 0.118248, Val Acc: 0.773196\n",
      "Epoch 17504 - Train Loss: 0.092829, Train Acc: 0.856410 | Val Loss: 0.118247, Val Acc: 0.773196\n",
      "Epoch 17505 - Train Loss: 0.092826, Train Acc: 0.856410 | Val Loss: 0.118245, Val Acc: 0.773196\n",
      "Epoch 17506 - Train Loss: 0.092823, Train Acc: 0.856410 | Val Loss: 0.118244, Val Acc: 0.773196\n",
      "Epoch 17507 - Train Loss: 0.092820, Train Acc: 0.856410 | Val Loss: 0.118242, Val Acc: 0.773196\n",
      "Epoch 17508 - Train Loss: 0.092817, Train Acc: 0.856410 | Val Loss: 0.118240, Val Acc: 0.773196\n",
      "Epoch 17509 - Train Loss: 0.092814, Train Acc: 0.856410 | Val Loss: 0.118239, Val Acc: 0.773196\n",
      "Epoch 17510 - Train Loss: 0.092812, Train Acc: 0.856410 | Val Loss: 0.118237, Val Acc: 0.773196\n",
      "Epoch 17511 - Train Loss: 0.092809, Train Acc: 0.856410 | Val Loss: 0.118236, Val Acc: 0.773196\n",
      "Epoch 17512 - Train Loss: 0.092806, Train Acc: 0.856410 | Val Loss: 0.118234, Val Acc: 0.773196\n",
      "Epoch 17513 - Train Loss: 0.092803, Train Acc: 0.856410 | Val Loss: 0.118232, Val Acc: 0.773196\n",
      "Epoch 17514 - Train Loss: 0.092800, Train Acc: 0.856410 | Val Loss: 0.118231, Val Acc: 0.773196\n",
      "Epoch 17515 - Train Loss: 0.092797, Train Acc: 0.856410 | Val Loss: 0.118229, Val Acc: 0.773196\n",
      "Epoch 17516 - Train Loss: 0.092795, Train Acc: 0.856410 | Val Loss: 0.118228, Val Acc: 0.773196\n",
      "Epoch 17517 - Train Loss: 0.092792, Train Acc: 0.856410 | Val Loss: 0.118226, Val Acc: 0.773196\n",
      "Epoch 17518 - Train Loss: 0.092789, Train Acc: 0.856410 | Val Loss: 0.118224, Val Acc: 0.773196\n",
      "Epoch 17519 - Train Loss: 0.092786, Train Acc: 0.856410 | Val Loss: 0.118223, Val Acc: 0.773196\n",
      "Epoch 17520 - Train Loss: 0.092783, Train Acc: 0.856410 | Val Loss: 0.118221, Val Acc: 0.773196\n",
      "Epoch 17521 - Train Loss: 0.092781, Train Acc: 0.856410 | Val Loss: 0.118220, Val Acc: 0.773196\n",
      "Epoch 17522 - Train Loss: 0.092778, Train Acc: 0.856410 | Val Loss: 0.118218, Val Acc: 0.773196\n",
      "Epoch 17523 - Train Loss: 0.092775, Train Acc: 0.856410 | Val Loss: 0.118216, Val Acc: 0.773196\n",
      "Epoch 17524 - Train Loss: 0.092772, Train Acc: 0.856410 | Val Loss: 0.118215, Val Acc: 0.773196\n",
      "Epoch 17525 - Train Loss: 0.092769, Train Acc: 0.856410 | Val Loss: 0.118213, Val Acc: 0.773196\n",
      "Epoch 17526 - Train Loss: 0.092766, Train Acc: 0.856410 | Val Loss: 0.118212, Val Acc: 0.773196\n",
      "Epoch 17527 - Train Loss: 0.092764, Train Acc: 0.856410 | Val Loss: 0.118210, Val Acc: 0.773196\n",
      "Epoch 17528 - Train Loss: 0.092761, Train Acc: 0.856410 | Val Loss: 0.118208, Val Acc: 0.773196\n",
      "Epoch 17529 - Train Loss: 0.092758, Train Acc: 0.856410 | Val Loss: 0.118207, Val Acc: 0.773196\n",
      "Epoch 17530 - Train Loss: 0.092755, Train Acc: 0.856410 | Val Loss: 0.118205, Val Acc: 0.773196\n",
      "Epoch 17531 - Train Loss: 0.092752, Train Acc: 0.856410 | Val Loss: 0.118204, Val Acc: 0.773196\n",
      "Epoch 17532 - Train Loss: 0.092749, Train Acc: 0.856410 | Val Loss: 0.118202, Val Acc: 0.773196\n",
      "Epoch 17533 - Train Loss: 0.092747, Train Acc: 0.856410 | Val Loss: 0.118201, Val Acc: 0.773196\n",
      "Epoch 17534 - Train Loss: 0.092744, Train Acc: 0.856410 | Val Loss: 0.118199, Val Acc: 0.773196\n",
      "Epoch 17535 - Train Loss: 0.092741, Train Acc: 0.856410 | Val Loss: 0.118197, Val Acc: 0.773196\n",
      "Epoch 17536 - Train Loss: 0.092738, Train Acc: 0.856410 | Val Loss: 0.118196, Val Acc: 0.773196\n",
      "Epoch 17537 - Train Loss: 0.092735, Train Acc: 0.856410 | Val Loss: 0.118194, Val Acc: 0.773196\n",
      "Epoch 17538 - Train Loss: 0.092733, Train Acc: 0.856410 | Val Loss: 0.118193, Val Acc: 0.773196\n",
      "Epoch 17539 - Train Loss: 0.092730, Train Acc: 0.856410 | Val Loss: 0.118191, Val Acc: 0.773196\n",
      "Epoch 17540 - Train Loss: 0.092727, Train Acc: 0.856410 | Val Loss: 0.118189, Val Acc: 0.773196\n",
      "Epoch 17541 - Train Loss: 0.092724, Train Acc: 0.856410 | Val Loss: 0.118188, Val Acc: 0.773196\n",
      "Epoch 17542 - Train Loss: 0.092721, Train Acc: 0.856410 | Val Loss: 0.118186, Val Acc: 0.773196\n",
      "Epoch 17543 - Train Loss: 0.092718, Train Acc: 0.856410 | Val Loss: 0.118185, Val Acc: 0.773196\n",
      "Epoch 17544 - Train Loss: 0.092716, Train Acc: 0.856410 | Val Loss: 0.118183, Val Acc: 0.773196\n",
      "Epoch 17545 - Train Loss: 0.092713, Train Acc: 0.856410 | Val Loss: 0.118181, Val Acc: 0.773196\n",
      "Epoch 17546 - Train Loss: 0.092710, Train Acc: 0.856410 | Val Loss: 0.118180, Val Acc: 0.773196\n",
      "Epoch 17547 - Train Loss: 0.092707, Train Acc: 0.856410 | Val Loss: 0.118178, Val Acc: 0.773196\n",
      "Epoch 17548 - Train Loss: 0.092704, Train Acc: 0.856410 | Val Loss: 0.118177, Val Acc: 0.773196\n",
      "Epoch 17549 - Train Loss: 0.092702, Train Acc: 0.856410 | Val Loss: 0.118175, Val Acc: 0.773196\n",
      "Epoch 17550 - Train Loss: 0.092699, Train Acc: 0.856410 | Val Loss: 0.118174, Val Acc: 0.773196\n",
      "Epoch 17551 - Train Loss: 0.092696, Train Acc: 0.856410 | Val Loss: 0.118172, Val Acc: 0.773196\n",
      "Epoch 17552 - Train Loss: 0.092693, Train Acc: 0.856410 | Val Loss: 0.118170, Val Acc: 0.773196\n",
      "Epoch 17553 - Train Loss: 0.092690, Train Acc: 0.856410 | Val Loss: 0.118169, Val Acc: 0.773196\n",
      "Epoch 17554 - Train Loss: 0.092688, Train Acc: 0.856410 | Val Loss: 0.118167, Val Acc: 0.773196\n",
      "Epoch 17555 - Train Loss: 0.092685, Train Acc: 0.856410 | Val Loss: 0.118166, Val Acc: 0.773196\n",
      "Epoch 17556 - Train Loss: 0.092682, Train Acc: 0.856410 | Val Loss: 0.118164, Val Acc: 0.773196\n",
      "Epoch 17557 - Train Loss: 0.092679, Train Acc: 0.856410 | Val Loss: 0.118162, Val Acc: 0.773196\n",
      "Epoch 17558 - Train Loss: 0.092676, Train Acc: 0.856410 | Val Loss: 0.118161, Val Acc: 0.773196\n",
      "Epoch 17559 - Train Loss: 0.092673, Train Acc: 0.856410 | Val Loss: 0.118159, Val Acc: 0.773196\n",
      "Epoch 17560 - Train Loss: 0.092671, Train Acc: 0.856410 | Val Loss: 0.118158, Val Acc: 0.773196\n",
      "Epoch 17561 - Train Loss: 0.092668, Train Acc: 0.856410 | Val Loss: 0.118156, Val Acc: 0.773196\n",
      "Epoch 17562 - Train Loss: 0.092665, Train Acc: 0.856410 | Val Loss: 0.118154, Val Acc: 0.773196\n",
      "Epoch 17563 - Train Loss: 0.092662, Train Acc: 0.856410 | Val Loss: 0.118153, Val Acc: 0.773196\n",
      "Epoch 17564 - Train Loss: 0.092659, Train Acc: 0.856410 | Val Loss: 0.118151, Val Acc: 0.773196\n",
      "Epoch 17565 - Train Loss: 0.092657, Train Acc: 0.856410 | Val Loss: 0.118150, Val Acc: 0.773196\n",
      "Epoch 17566 - Train Loss: 0.092654, Train Acc: 0.856410 | Val Loss: 0.118148, Val Acc: 0.773196\n",
      "Epoch 17567 - Train Loss: 0.092651, Train Acc: 0.856410 | Val Loss: 0.118147, Val Acc: 0.773196\n",
      "Epoch 17568 - Train Loss: 0.092648, Train Acc: 0.856410 | Val Loss: 0.118145, Val Acc: 0.773196\n",
      "Epoch 17569 - Train Loss: 0.092645, Train Acc: 0.856410 | Val Loss: 0.118143, Val Acc: 0.773196\n",
      "Epoch 17570 - Train Loss: 0.092643, Train Acc: 0.856410 | Val Loss: 0.118142, Val Acc: 0.773196\n",
      "Epoch 17571 - Train Loss: 0.092640, Train Acc: 0.856410 | Val Loss: 0.118140, Val Acc: 0.773196\n",
      "Epoch 17572 - Train Loss: 0.092637, Train Acc: 0.856410 | Val Loss: 0.118139, Val Acc: 0.773196\n",
      "Epoch 17573 - Train Loss: 0.092634, Train Acc: 0.856410 | Val Loss: 0.118137, Val Acc: 0.773196\n",
      "Epoch 17574 - Train Loss: 0.092631, Train Acc: 0.856410 | Val Loss: 0.118136, Val Acc: 0.773196\n",
      "Epoch 17575 - Train Loss: 0.092629, Train Acc: 0.856410 | Val Loss: 0.118134, Val Acc: 0.773196\n",
      "Epoch 17576 - Train Loss: 0.092626, Train Acc: 0.856410 | Val Loss: 0.118132, Val Acc: 0.773196\n",
      "Epoch 17577 - Train Loss: 0.092623, Train Acc: 0.856410 | Val Loss: 0.118131, Val Acc: 0.773196\n",
      "Epoch 17578 - Train Loss: 0.092620, Train Acc: 0.856410 | Val Loss: 0.118129, Val Acc: 0.773196\n",
      "Epoch 17579 - Train Loss: 0.092617, Train Acc: 0.856410 | Val Loss: 0.118128, Val Acc: 0.773196\n",
      "Epoch 17580 - Train Loss: 0.092614, Train Acc: 0.856410 | Val Loss: 0.118126, Val Acc: 0.773196\n",
      "Epoch 17581 - Train Loss: 0.092612, Train Acc: 0.856410 | Val Loss: 0.118124, Val Acc: 0.773196\n",
      "Epoch 17582 - Train Loss: 0.092609, Train Acc: 0.856410 | Val Loss: 0.118123, Val Acc: 0.773196\n",
      "Epoch 17583 - Train Loss: 0.092606, Train Acc: 0.856410 | Val Loss: 0.118121, Val Acc: 0.773196\n",
      "Epoch 17584 - Train Loss: 0.092603, Train Acc: 0.856410 | Val Loss: 0.118120, Val Acc: 0.773196\n",
      "Epoch 17585 - Train Loss: 0.092600, Train Acc: 0.856410 | Val Loss: 0.118118, Val Acc: 0.773196\n",
      "Epoch 17586 - Train Loss: 0.092598, Train Acc: 0.856410 | Val Loss: 0.118117, Val Acc: 0.773196\n",
      "Epoch 17587 - Train Loss: 0.092595, Train Acc: 0.856410 | Val Loss: 0.118115, Val Acc: 0.773196\n",
      "Epoch 17588 - Train Loss: 0.092592, Train Acc: 0.856410 | Val Loss: 0.118113, Val Acc: 0.773196\n",
      "Epoch 17589 - Train Loss: 0.092589, Train Acc: 0.856410 | Val Loss: 0.118112, Val Acc: 0.773196\n",
      "Epoch 17590 - Train Loss: 0.092586, Train Acc: 0.856410 | Val Loss: 0.118110, Val Acc: 0.773196\n",
      "Epoch 17591 - Train Loss: 0.092584, Train Acc: 0.856410 | Val Loss: 0.118109, Val Acc: 0.773196\n",
      "Epoch 17592 - Train Loss: 0.092581, Train Acc: 0.856410 | Val Loss: 0.118107, Val Acc: 0.773196\n",
      "Epoch 17593 - Train Loss: 0.092578, Train Acc: 0.856410 | Val Loss: 0.118106, Val Acc: 0.773196\n",
      "Epoch 17594 - Train Loss: 0.092575, Train Acc: 0.856410 | Val Loss: 0.118104, Val Acc: 0.773196\n",
      "Epoch 17595 - Train Loss: 0.092572, Train Acc: 0.856410 | Val Loss: 0.118102, Val Acc: 0.773196\n",
      "Epoch 17596 - Train Loss: 0.092570, Train Acc: 0.856410 | Val Loss: 0.118101, Val Acc: 0.773196\n",
      "Epoch 17597 - Train Loss: 0.092567, Train Acc: 0.856410 | Val Loss: 0.118099, Val Acc: 0.773196\n",
      "Epoch 17598 - Train Loss: 0.092564, Train Acc: 0.856410 | Val Loss: 0.118098, Val Acc: 0.773196\n",
      "Epoch 17599 - Train Loss: 0.092561, Train Acc: 0.856410 | Val Loss: 0.118096, Val Acc: 0.773196\n",
      "Epoch 17600 - Train Loss: 0.092558, Train Acc: 0.856410 | Val Loss: 0.118095, Val Acc: 0.773196\n",
      "Epoch 17601 - Train Loss: 0.092556, Train Acc: 0.856410 | Val Loss: 0.118093, Val Acc: 0.773196\n",
      "Epoch 17602 - Train Loss: 0.092553, Train Acc: 0.856410 | Val Loss: 0.118091, Val Acc: 0.773196\n",
      "Epoch 17603 - Train Loss: 0.092550, Train Acc: 0.856410 | Val Loss: 0.118090, Val Acc: 0.773196\n",
      "Epoch 17604 - Train Loss: 0.092547, Train Acc: 0.856410 | Val Loss: 0.118088, Val Acc: 0.773196\n",
      "Epoch 17605 - Train Loss: 0.092544, Train Acc: 0.856410 | Val Loss: 0.118087, Val Acc: 0.773196\n",
      "Epoch 17606 - Train Loss: 0.092542, Train Acc: 0.856410 | Val Loss: 0.118085, Val Acc: 0.773196\n",
      "Epoch 17607 - Train Loss: 0.092539, Train Acc: 0.856410 | Val Loss: 0.118084, Val Acc: 0.773196\n",
      "Epoch 17608 - Train Loss: 0.092536, Train Acc: 0.856410 | Val Loss: 0.118082, Val Acc: 0.773196\n",
      "Epoch 17609 - Train Loss: 0.092533, Train Acc: 0.856410 | Val Loss: 0.118080, Val Acc: 0.773196\n",
      "Epoch 17610 - Train Loss: 0.092530, Train Acc: 0.856410 | Val Loss: 0.118079, Val Acc: 0.773196\n",
      "Epoch 17611 - Train Loss: 0.092528, Train Acc: 0.856410 | Val Loss: 0.118077, Val Acc: 0.773196\n",
      "Epoch 17612 - Train Loss: 0.092525, Train Acc: 0.856410 | Val Loss: 0.118076, Val Acc: 0.773196\n",
      "Epoch 17613 - Train Loss: 0.092522, Train Acc: 0.856410 | Val Loss: 0.118074, Val Acc: 0.773196\n",
      "Epoch 17614 - Train Loss: 0.092519, Train Acc: 0.856410 | Val Loss: 0.118073, Val Acc: 0.773196\n",
      "Epoch 17615 - Train Loss: 0.092516, Train Acc: 0.856410 | Val Loss: 0.118071, Val Acc: 0.773196\n",
      "Epoch 17616 - Train Loss: 0.092514, Train Acc: 0.856410 | Val Loss: 0.118069, Val Acc: 0.773196\n",
      "Epoch 17617 - Train Loss: 0.092511, Train Acc: 0.856410 | Val Loss: 0.118068, Val Acc: 0.773196\n",
      "Epoch 17618 - Train Loss: 0.092508, Train Acc: 0.856410 | Val Loss: 0.118066, Val Acc: 0.773196\n",
      "Epoch 17619 - Train Loss: 0.092505, Train Acc: 0.856410 | Val Loss: 0.118065, Val Acc: 0.773196\n",
      "Epoch 17620 - Train Loss: 0.092502, Train Acc: 0.856410 | Val Loss: 0.118063, Val Acc: 0.773196\n",
      "Epoch 17621 - Train Loss: 0.092500, Train Acc: 0.856410 | Val Loss: 0.118062, Val Acc: 0.773196\n",
      "Epoch 17622 - Train Loss: 0.092497, Train Acc: 0.856410 | Val Loss: 0.118060, Val Acc: 0.773196\n",
      "Epoch 17623 - Train Loss: 0.092494, Train Acc: 0.856410 | Val Loss: 0.118058, Val Acc: 0.773196\n",
      "Epoch 17624 - Train Loss: 0.092491, Train Acc: 0.856410 | Val Loss: 0.118057, Val Acc: 0.773196\n",
      "Epoch 17625 - Train Loss: 0.092489, Train Acc: 0.856410 | Val Loss: 0.118055, Val Acc: 0.773196\n",
      "Epoch 17626 - Train Loss: 0.092486, Train Acc: 0.856410 | Val Loss: 0.118054, Val Acc: 0.773196\n",
      "Epoch 17627 - Train Loss: 0.092483, Train Acc: 0.856410 | Val Loss: 0.118052, Val Acc: 0.773196\n",
      "Epoch 17628 - Train Loss: 0.092480, Train Acc: 0.856410 | Val Loss: 0.118051, Val Acc: 0.773196\n",
      "Epoch 17629 - Train Loss: 0.092477, Train Acc: 0.856410 | Val Loss: 0.118049, Val Acc: 0.773196\n",
      "Epoch 17630 - Train Loss: 0.092475, Train Acc: 0.856410 | Val Loss: 0.118048, Val Acc: 0.773196\n",
      "Epoch 17631 - Train Loss: 0.092472, Train Acc: 0.856410 | Val Loss: 0.118046, Val Acc: 0.773196\n",
      "Epoch 17632 - Train Loss: 0.092469, Train Acc: 0.856410 | Val Loss: 0.118044, Val Acc: 0.773196\n",
      "Epoch 17633 - Train Loss: 0.092466, Train Acc: 0.856410 | Val Loss: 0.118043, Val Acc: 0.773196\n",
      "Epoch 17634 - Train Loss: 0.092463, Train Acc: 0.856410 | Val Loss: 0.118041, Val Acc: 0.773196\n",
      "Epoch 17635 - Train Loss: 0.092461, Train Acc: 0.856410 | Val Loss: 0.118040, Val Acc: 0.773196\n",
      "Epoch 17636 - Train Loss: 0.092458, Train Acc: 0.856410 | Val Loss: 0.118038, Val Acc: 0.773196\n",
      "Epoch 17637 - Train Loss: 0.092455, Train Acc: 0.856410 | Val Loss: 0.118037, Val Acc: 0.773196\n",
      "Epoch 17638 - Train Loss: 0.092452, Train Acc: 0.856410 | Val Loss: 0.118035, Val Acc: 0.773196\n",
      "Epoch 17639 - Train Loss: 0.092449, Train Acc: 0.856410 | Val Loss: 0.118033, Val Acc: 0.773196\n",
      "Epoch 17640 - Train Loss: 0.092447, Train Acc: 0.856410 | Val Loss: 0.118032, Val Acc: 0.773196\n",
      "Epoch 17641 - Train Loss: 0.092444, Train Acc: 0.856410 | Val Loss: 0.118030, Val Acc: 0.773196\n",
      "Epoch 17642 - Train Loss: 0.092441, Train Acc: 0.856410 | Val Loss: 0.118029, Val Acc: 0.773196\n",
      "Epoch 17643 - Train Loss: 0.092438, Train Acc: 0.856410 | Val Loss: 0.118027, Val Acc: 0.773196\n",
      "Epoch 17644 - Train Loss: 0.092436, Train Acc: 0.856410 | Val Loss: 0.118026, Val Acc: 0.773196\n",
      "Epoch 17645 - Train Loss: 0.092433, Train Acc: 0.856410 | Val Loss: 0.118024, Val Acc: 0.773196\n",
      "Epoch 17646 - Train Loss: 0.092430, Train Acc: 0.856410 | Val Loss: 0.118023, Val Acc: 0.773196\n",
      "Epoch 17647 - Train Loss: 0.092427, Train Acc: 0.856410 | Val Loss: 0.118021, Val Acc: 0.773196\n",
      "Epoch 17648 - Train Loss: 0.092424, Train Acc: 0.856410 | Val Loss: 0.118019, Val Acc: 0.773196\n",
      "Epoch 17649 - Train Loss: 0.092422, Train Acc: 0.856410 | Val Loss: 0.118018, Val Acc: 0.773196\n",
      "Epoch 17650 - Train Loss: 0.092419, Train Acc: 0.856410 | Val Loss: 0.118016, Val Acc: 0.773196\n",
      "Epoch 17651 - Train Loss: 0.092416, Train Acc: 0.856410 | Val Loss: 0.118015, Val Acc: 0.773196\n",
      "Epoch 17652 - Train Loss: 0.092413, Train Acc: 0.856410 | Val Loss: 0.118013, Val Acc: 0.773196\n",
      "Epoch 17653 - Train Loss: 0.092410, Train Acc: 0.856410 | Val Loss: 0.118012, Val Acc: 0.773196\n",
      "Epoch 17654 - Train Loss: 0.092408, Train Acc: 0.856410 | Val Loss: 0.118010, Val Acc: 0.773196\n",
      "Epoch 17655 - Train Loss: 0.092405, Train Acc: 0.856410 | Val Loss: 0.118009, Val Acc: 0.773196\n",
      "Epoch 17656 - Train Loss: 0.092402, Train Acc: 0.856410 | Val Loss: 0.118007, Val Acc: 0.773196\n",
      "Epoch 17657 - Train Loss: 0.092399, Train Acc: 0.856410 | Val Loss: 0.118005, Val Acc: 0.773196\n",
      "Epoch 17658 - Train Loss: 0.092397, Train Acc: 0.856410 | Val Loss: 0.118004, Val Acc: 0.773196\n",
      "Epoch 17659 - Train Loss: 0.092394, Train Acc: 0.856410 | Val Loss: 0.118002, Val Acc: 0.773196\n",
      "Epoch 17660 - Train Loss: 0.092391, Train Acc: 0.856410 | Val Loss: 0.118001, Val Acc: 0.773196\n",
      "Epoch 17661 - Train Loss: 0.092388, Train Acc: 0.856410 | Val Loss: 0.117999, Val Acc: 0.773196\n",
      "Epoch 17662 - Train Loss: 0.092385, Train Acc: 0.856410 | Val Loss: 0.117998, Val Acc: 0.773196\n",
      "Epoch 17663 - Train Loss: 0.092383, Train Acc: 0.856410 | Val Loss: 0.117996, Val Acc: 0.773196\n",
      "Epoch 17664 - Train Loss: 0.092380, Train Acc: 0.856410 | Val Loss: 0.117995, Val Acc: 0.773196\n",
      "Epoch 17665 - Train Loss: 0.092377, Train Acc: 0.856410 | Val Loss: 0.117993, Val Acc: 0.773196\n",
      "Epoch 17666 - Train Loss: 0.092374, Train Acc: 0.856410 | Val Loss: 0.117991, Val Acc: 0.773196\n",
      "Epoch 17667 - Train Loss: 0.092371, Train Acc: 0.856410 | Val Loss: 0.117990, Val Acc: 0.773196\n",
      "Epoch 17668 - Train Loss: 0.092369, Train Acc: 0.856410 | Val Loss: 0.117988, Val Acc: 0.773196\n",
      "Epoch 17669 - Train Loss: 0.092366, Train Acc: 0.856410 | Val Loss: 0.117987, Val Acc: 0.773196\n",
      "Epoch 17670 - Train Loss: 0.092363, Train Acc: 0.856410 | Val Loss: 0.117985, Val Acc: 0.773196\n",
      "Epoch 17671 - Train Loss: 0.092360, Train Acc: 0.856410 | Val Loss: 0.117984, Val Acc: 0.773196\n",
      "Epoch 17672 - Train Loss: 0.092358, Train Acc: 0.856410 | Val Loss: 0.117982, Val Acc: 0.773196\n",
      "Epoch 17673 - Train Loss: 0.092355, Train Acc: 0.856410 | Val Loss: 0.117981, Val Acc: 0.773196\n",
      "Epoch 17674 - Train Loss: 0.092352, Train Acc: 0.856410 | Val Loss: 0.117979, Val Acc: 0.773196\n",
      "Epoch 17675 - Train Loss: 0.092349, Train Acc: 0.856410 | Val Loss: 0.117977, Val Acc: 0.773196\n",
      "Epoch 17676 - Train Loss: 0.092346, Train Acc: 0.856410 | Val Loss: 0.117976, Val Acc: 0.773196\n",
      "Epoch 17677 - Train Loss: 0.092344, Train Acc: 0.856410 | Val Loss: 0.117974, Val Acc: 0.773196\n",
      "Epoch 17678 - Train Loss: 0.092341, Train Acc: 0.856410 | Val Loss: 0.117973, Val Acc: 0.773196\n",
      "Epoch 17679 - Train Loss: 0.092338, Train Acc: 0.856410 | Val Loss: 0.117971, Val Acc: 0.773196\n",
      "Epoch 17680 - Train Loss: 0.092335, Train Acc: 0.856410 | Val Loss: 0.117970, Val Acc: 0.773196\n",
      "Epoch 17681 - Train Loss: 0.092333, Train Acc: 0.856410 | Val Loss: 0.117968, Val Acc: 0.773196\n",
      "Epoch 17682 - Train Loss: 0.092330, Train Acc: 0.856410 | Val Loss: 0.117966, Val Acc: 0.773196\n",
      "Epoch 17683 - Train Loss: 0.092327, Train Acc: 0.856410 | Val Loss: 0.117965, Val Acc: 0.773196\n",
      "Epoch 17684 - Train Loss: 0.092324, Train Acc: 0.856410 | Val Loss: 0.117963, Val Acc: 0.773196\n",
      "Epoch 17685 - Train Loss: 0.092321, Train Acc: 0.856410 | Val Loss: 0.117962, Val Acc: 0.773196\n",
      "Epoch 17686 - Train Loss: 0.092319, Train Acc: 0.856410 | Val Loss: 0.117960, Val Acc: 0.773196\n",
      "Epoch 17687 - Train Loss: 0.092316, Train Acc: 0.856410 | Val Loss: 0.117959, Val Acc: 0.773196\n",
      "Epoch 17688 - Train Loss: 0.092313, Train Acc: 0.856410 | Val Loss: 0.117957, Val Acc: 0.773196\n",
      "Epoch 17689 - Train Loss: 0.092310, Train Acc: 0.856410 | Val Loss: 0.117956, Val Acc: 0.773196\n",
      "Epoch 17690 - Train Loss: 0.092308, Train Acc: 0.856410 | Val Loss: 0.117954, Val Acc: 0.773196\n",
      "Epoch 17691 - Train Loss: 0.092305, Train Acc: 0.856410 | Val Loss: 0.117952, Val Acc: 0.773196\n",
      "Epoch 17692 - Train Loss: 0.092302, Train Acc: 0.856410 | Val Loss: 0.117951, Val Acc: 0.773196\n",
      "Epoch 17693 - Train Loss: 0.092299, Train Acc: 0.856410 | Val Loss: 0.117949, Val Acc: 0.773196\n",
      "Epoch 17694 - Train Loss: 0.092297, Train Acc: 0.856410 | Val Loss: 0.117948, Val Acc: 0.773196\n",
      "Epoch 17695 - Train Loss: 0.092294, Train Acc: 0.856410 | Val Loss: 0.117946, Val Acc: 0.773196\n",
      "Epoch 17696 - Train Loss: 0.092291, Train Acc: 0.856410 | Val Loss: 0.117945, Val Acc: 0.773196\n",
      "Epoch 17697 - Train Loss: 0.092288, Train Acc: 0.856410 | Val Loss: 0.117943, Val Acc: 0.773196\n",
      "Epoch 17698 - Train Loss: 0.092285, Train Acc: 0.856410 | Val Loss: 0.117942, Val Acc: 0.773196\n",
      "Epoch 17699 - Train Loss: 0.092283, Train Acc: 0.856410 | Val Loss: 0.117940, Val Acc: 0.773196\n",
      "Epoch 17700 - Train Loss: 0.092280, Train Acc: 0.856410 | Val Loss: 0.117939, Val Acc: 0.773196\n",
      "Epoch 17701 - Train Loss: 0.092277, Train Acc: 0.856410 | Val Loss: 0.117937, Val Acc: 0.773196\n",
      "Epoch 17702 - Train Loss: 0.092274, Train Acc: 0.856410 | Val Loss: 0.117935, Val Acc: 0.773196\n",
      "Epoch 17703 - Train Loss: 0.092272, Train Acc: 0.856410 | Val Loss: 0.117934, Val Acc: 0.773196\n",
      "Epoch 17704 - Train Loss: 0.092269, Train Acc: 0.856410 | Val Loss: 0.117932, Val Acc: 0.773196\n",
      "Epoch 17705 - Train Loss: 0.092266, Train Acc: 0.856410 | Val Loss: 0.117931, Val Acc: 0.773196\n",
      "Epoch 17706 - Train Loss: 0.092263, Train Acc: 0.856410 | Val Loss: 0.117929, Val Acc: 0.773196\n",
      "Epoch 17707 - Train Loss: 0.092260, Train Acc: 0.856410 | Val Loss: 0.117928, Val Acc: 0.773196\n",
      "Epoch 17708 - Train Loss: 0.092258, Train Acc: 0.856410 | Val Loss: 0.117926, Val Acc: 0.773196\n",
      "Epoch 17709 - Train Loss: 0.092255, Train Acc: 0.856410 | Val Loss: 0.117925, Val Acc: 0.773196\n",
      "Epoch 17710 - Train Loss: 0.092252, Train Acc: 0.856410 | Val Loss: 0.117923, Val Acc: 0.773196\n",
      "Epoch 17711 - Train Loss: 0.092249, Train Acc: 0.856410 | Val Loss: 0.117922, Val Acc: 0.773196\n",
      "Epoch 17712 - Train Loss: 0.092247, Train Acc: 0.856410 | Val Loss: 0.117920, Val Acc: 0.773196\n",
      "Epoch 17713 - Train Loss: 0.092244, Train Acc: 0.856410 | Val Loss: 0.117918, Val Acc: 0.773196\n",
      "Epoch 17714 - Train Loss: 0.092241, Train Acc: 0.856410 | Val Loss: 0.117917, Val Acc: 0.773196\n",
      "Epoch 17715 - Train Loss: 0.092238, Train Acc: 0.856410 | Val Loss: 0.117915, Val Acc: 0.773196\n",
      "Epoch 17716 - Train Loss: 0.092236, Train Acc: 0.856410 | Val Loss: 0.117914, Val Acc: 0.773196\n",
      "Epoch 17717 - Train Loss: 0.092233, Train Acc: 0.856410 | Val Loss: 0.117912, Val Acc: 0.773196\n",
      "Epoch 17718 - Train Loss: 0.092230, Train Acc: 0.856410 | Val Loss: 0.117911, Val Acc: 0.773196\n",
      "Epoch 17719 - Train Loss: 0.092227, Train Acc: 0.856410 | Val Loss: 0.117909, Val Acc: 0.773196\n",
      "Epoch 17720 - Train Loss: 0.092225, Train Acc: 0.856410 | Val Loss: 0.117908, Val Acc: 0.773196\n",
      "Epoch 17721 - Train Loss: 0.092222, Train Acc: 0.856410 | Val Loss: 0.117906, Val Acc: 0.773196\n",
      "Epoch 17722 - Train Loss: 0.092219, Train Acc: 0.856410 | Val Loss: 0.117905, Val Acc: 0.773196\n",
      "Epoch 17723 - Train Loss: 0.092216, Train Acc: 0.856410 | Val Loss: 0.117903, Val Acc: 0.773196\n",
      "Epoch 17724 - Train Loss: 0.092213, Train Acc: 0.856410 | Val Loss: 0.117901, Val Acc: 0.773196\n",
      "Epoch 17725 - Train Loss: 0.092211, Train Acc: 0.856410 | Val Loss: 0.117900, Val Acc: 0.773196\n",
      "Epoch 17726 - Train Loss: 0.092208, Train Acc: 0.856410 | Val Loss: 0.117898, Val Acc: 0.773196\n",
      "Epoch 17727 - Train Loss: 0.092205, Train Acc: 0.856410 | Val Loss: 0.117897, Val Acc: 0.773196\n",
      "Epoch 17728 - Train Loss: 0.092202, Train Acc: 0.856410 | Val Loss: 0.117895, Val Acc: 0.773196\n",
      "Epoch 17729 - Train Loss: 0.092200, Train Acc: 0.856410 | Val Loss: 0.117894, Val Acc: 0.773196\n",
      "Epoch 17730 - Train Loss: 0.092197, Train Acc: 0.856410 | Val Loss: 0.117892, Val Acc: 0.773196\n",
      "Epoch 17731 - Train Loss: 0.092194, Train Acc: 0.856410 | Val Loss: 0.117891, Val Acc: 0.773196\n",
      "Epoch 17732 - Train Loss: 0.092191, Train Acc: 0.856410 | Val Loss: 0.117889, Val Acc: 0.773196\n",
      "Epoch 17733 - Train Loss: 0.092189, Train Acc: 0.856410 | Val Loss: 0.117888, Val Acc: 0.773196\n",
      "Epoch 17734 - Train Loss: 0.092186, Train Acc: 0.856410 | Val Loss: 0.117886, Val Acc: 0.773196\n",
      "Epoch 17735 - Train Loss: 0.092183, Train Acc: 0.856410 | Val Loss: 0.117885, Val Acc: 0.773196\n",
      "Epoch 17736 - Train Loss: 0.092180, Train Acc: 0.856410 | Val Loss: 0.117883, Val Acc: 0.773196\n",
      "Epoch 17737 - Train Loss: 0.092178, Train Acc: 0.856410 | Val Loss: 0.117882, Val Acc: 0.773196\n",
      "Epoch 17738 - Train Loss: 0.092175, Train Acc: 0.856410 | Val Loss: 0.117880, Val Acc: 0.773196\n",
      "Epoch 17739 - Train Loss: 0.092172, Train Acc: 0.856410 | Val Loss: 0.117878, Val Acc: 0.773196\n",
      "Epoch 17740 - Train Loss: 0.092169, Train Acc: 0.856410 | Val Loss: 0.117877, Val Acc: 0.773196\n",
      "Epoch 17741 - Train Loss: 0.092167, Train Acc: 0.856410 | Val Loss: 0.117875, Val Acc: 0.773196\n",
      "Epoch 17742 - Train Loss: 0.092164, Train Acc: 0.856410 | Val Loss: 0.117874, Val Acc: 0.773196\n",
      "Epoch 17743 - Train Loss: 0.092161, Train Acc: 0.856410 | Val Loss: 0.117872, Val Acc: 0.773196\n",
      "Epoch 17744 - Train Loss: 0.092158, Train Acc: 0.856410 | Val Loss: 0.117871, Val Acc: 0.773196\n",
      "Epoch 17745 - Train Loss: 0.092155, Train Acc: 0.856410 | Val Loss: 0.117869, Val Acc: 0.773196\n",
      "Epoch 17746 - Train Loss: 0.092153, Train Acc: 0.856410 | Val Loss: 0.117868, Val Acc: 0.773196\n",
      "Epoch 17747 - Train Loss: 0.092150, Train Acc: 0.856410 | Val Loss: 0.117866, Val Acc: 0.773196\n",
      "Epoch 17748 - Train Loss: 0.092147, Train Acc: 0.856410 | Val Loss: 0.117865, Val Acc: 0.773196\n",
      "Epoch 17749 - Train Loss: 0.092144, Train Acc: 0.856410 | Val Loss: 0.117863, Val Acc: 0.773196\n",
      "Epoch 17750 - Train Loss: 0.092142, Train Acc: 0.856410 | Val Loss: 0.117862, Val Acc: 0.773196\n",
      "Epoch 17751 - Train Loss: 0.092139, Train Acc: 0.856410 | Val Loss: 0.117860, Val Acc: 0.773196\n",
      "Epoch 17752 - Train Loss: 0.092136, Train Acc: 0.856410 | Val Loss: 0.117859, Val Acc: 0.773196\n",
      "Epoch 17753 - Train Loss: 0.092133, Train Acc: 0.856410 | Val Loss: 0.117857, Val Acc: 0.773196\n",
      "Epoch 17754 - Train Loss: 0.092131, Train Acc: 0.856410 | Val Loss: 0.117855, Val Acc: 0.773196\n",
      "Epoch 17755 - Train Loss: 0.092128, Train Acc: 0.856410 | Val Loss: 0.117854, Val Acc: 0.773196\n",
      "Epoch 17756 - Train Loss: 0.092125, Train Acc: 0.856410 | Val Loss: 0.117852, Val Acc: 0.773196\n",
      "Epoch 17757 - Train Loss: 0.092122, Train Acc: 0.856410 | Val Loss: 0.117851, Val Acc: 0.773196\n",
      "Epoch 17758 - Train Loss: 0.092120, Train Acc: 0.856410 | Val Loss: 0.117849, Val Acc: 0.773196\n",
      "Epoch 17759 - Train Loss: 0.092117, Train Acc: 0.856410 | Val Loss: 0.117848, Val Acc: 0.773196\n",
      "Epoch 17760 - Train Loss: 0.092114, Train Acc: 0.856410 | Val Loss: 0.117846, Val Acc: 0.773196\n",
      "Epoch 17761 - Train Loss: 0.092111, Train Acc: 0.856410 | Val Loss: 0.117845, Val Acc: 0.773196\n",
      "Epoch 17762 - Train Loss: 0.092109, Train Acc: 0.856410 | Val Loss: 0.117843, Val Acc: 0.773196\n",
      "Epoch 17763 - Train Loss: 0.092106, Train Acc: 0.856410 | Val Loss: 0.117842, Val Acc: 0.773196\n",
      "Epoch 17764 - Train Loss: 0.092103, Train Acc: 0.856410 | Val Loss: 0.117840, Val Acc: 0.773196\n",
      "Epoch 17765 - Train Loss: 0.092100, Train Acc: 0.856410 | Val Loss: 0.117839, Val Acc: 0.773196\n",
      "Epoch 17766 - Train Loss: 0.092098, Train Acc: 0.856410 | Val Loss: 0.117837, Val Acc: 0.773196\n",
      "Epoch 17767 - Train Loss: 0.092095, Train Acc: 0.856410 | Val Loss: 0.117836, Val Acc: 0.773196\n",
      "Epoch 17768 - Train Loss: 0.092092, Train Acc: 0.856410 | Val Loss: 0.117834, Val Acc: 0.773196\n",
      "Epoch 17769 - Train Loss: 0.092089, Train Acc: 0.856410 | Val Loss: 0.117833, Val Acc: 0.773196\n",
      "Epoch 17770 - Train Loss: 0.092087, Train Acc: 0.856410 | Val Loss: 0.117831, Val Acc: 0.773196\n",
      "Epoch 17771 - Train Loss: 0.092084, Train Acc: 0.856410 | Val Loss: 0.117830, Val Acc: 0.773196\n",
      "Epoch 17772 - Train Loss: 0.092081, Train Acc: 0.856410 | Val Loss: 0.117828, Val Acc: 0.773196\n",
      "Epoch 17773 - Train Loss: 0.092078, Train Acc: 0.856410 | Val Loss: 0.117826, Val Acc: 0.773196\n",
      "Epoch 17774 - Train Loss: 0.092076, Train Acc: 0.856410 | Val Loss: 0.117825, Val Acc: 0.773196\n",
      "Epoch 17775 - Train Loss: 0.092073, Train Acc: 0.856410 | Val Loss: 0.117823, Val Acc: 0.773196\n",
      "Epoch 17776 - Train Loss: 0.092070, Train Acc: 0.856410 | Val Loss: 0.117822, Val Acc: 0.773196\n",
      "Epoch 17777 - Train Loss: 0.092067, Train Acc: 0.856410 | Val Loss: 0.117820, Val Acc: 0.773196\n",
      "Epoch 17778 - Train Loss: 0.092065, Train Acc: 0.856410 | Val Loss: 0.117819, Val Acc: 0.773196\n",
      "Epoch 17779 - Train Loss: 0.092062, Train Acc: 0.856410 | Val Loss: 0.117817, Val Acc: 0.773196\n",
      "Epoch 17780 - Train Loss: 0.092059, Train Acc: 0.856410 | Val Loss: 0.117816, Val Acc: 0.773196\n",
      "Epoch 17781 - Train Loss: 0.092056, Train Acc: 0.856410 | Val Loss: 0.117814, Val Acc: 0.773196\n",
      "Epoch 17782 - Train Loss: 0.092054, Train Acc: 0.856410 | Val Loss: 0.117813, Val Acc: 0.773196\n",
      "Epoch 17783 - Train Loss: 0.092051, Train Acc: 0.856410 | Val Loss: 0.117811, Val Acc: 0.773196\n",
      "Epoch 17784 - Train Loss: 0.092048, Train Acc: 0.856410 | Val Loss: 0.117810, Val Acc: 0.773196\n",
      "Epoch 17785 - Train Loss: 0.092045, Train Acc: 0.856410 | Val Loss: 0.117808, Val Acc: 0.773196\n",
      "Epoch 17786 - Train Loss: 0.092043, Train Acc: 0.856410 | Val Loss: 0.117806, Val Acc: 0.773196\n",
      "Epoch 17787 - Train Loss: 0.092040, Train Acc: 0.856410 | Val Loss: 0.117805, Val Acc: 0.773196\n",
      "Epoch 17788 - Train Loss: 0.092037, Train Acc: 0.856410 | Val Loss: 0.117803, Val Acc: 0.773196\n",
      "Epoch 17789 - Train Loss: 0.092034, Train Acc: 0.856410 | Val Loss: 0.117802, Val Acc: 0.773196\n",
      "Epoch 17790 - Train Loss: 0.092032, Train Acc: 0.856410 | Val Loss: 0.117800, Val Acc: 0.773196\n",
      "Epoch 17791 - Train Loss: 0.092029, Train Acc: 0.856410 | Val Loss: 0.117799, Val Acc: 0.773196\n",
      "Epoch 17792 - Train Loss: 0.092026, Train Acc: 0.856410 | Val Loss: 0.117797, Val Acc: 0.773196\n",
      "Epoch 17793 - Train Loss: 0.092023, Train Acc: 0.856410 | Val Loss: 0.117796, Val Acc: 0.773196\n",
      "Epoch 17794 - Train Loss: 0.092021, Train Acc: 0.856410 | Val Loss: 0.117794, Val Acc: 0.773196\n",
      "Epoch 17795 - Train Loss: 0.092018, Train Acc: 0.856410 | Val Loss: 0.117793, Val Acc: 0.773196\n",
      "Epoch 17796 - Train Loss: 0.092015, Train Acc: 0.856410 | Val Loss: 0.117791, Val Acc: 0.773196\n",
      "Epoch 17797 - Train Loss: 0.092012, Train Acc: 0.856410 | Val Loss: 0.117790, Val Acc: 0.773196\n",
      "Epoch 17798 - Train Loss: 0.092010, Train Acc: 0.856410 | Val Loss: 0.117788, Val Acc: 0.773196\n",
      "Epoch 17799 - Train Loss: 0.092007, Train Acc: 0.856410 | Val Loss: 0.117787, Val Acc: 0.773196\n",
      "Epoch 17800 - Train Loss: 0.092004, Train Acc: 0.856410 | Val Loss: 0.117785, Val Acc: 0.773196\n",
      "Epoch 17801 - Train Loss: 0.092001, Train Acc: 0.856410 | Val Loss: 0.117784, Val Acc: 0.773196\n",
      "Epoch 17802 - Train Loss: 0.091999, Train Acc: 0.856410 | Val Loss: 0.117782, Val Acc: 0.773196\n",
      "Epoch 17803 - Train Loss: 0.091996, Train Acc: 0.856410 | Val Loss: 0.117780, Val Acc: 0.773196\n",
      "Epoch 17804 - Train Loss: 0.091993, Train Acc: 0.856410 | Val Loss: 0.117779, Val Acc: 0.773196\n",
      "Epoch 17805 - Train Loss: 0.091990, Train Acc: 0.856410 | Val Loss: 0.117777, Val Acc: 0.773196\n",
      "Epoch 17806 - Train Loss: 0.091988, Train Acc: 0.856410 | Val Loss: 0.117776, Val Acc: 0.773196\n",
      "Epoch 17807 - Train Loss: 0.091985, Train Acc: 0.856410 | Val Loss: 0.117774, Val Acc: 0.773196\n",
      "Epoch 17808 - Train Loss: 0.091982, Train Acc: 0.856410 | Val Loss: 0.117773, Val Acc: 0.773196\n",
      "Epoch 17809 - Train Loss: 0.091979, Train Acc: 0.856410 | Val Loss: 0.117771, Val Acc: 0.773196\n",
      "Epoch 17810 - Train Loss: 0.091977, Train Acc: 0.856410 | Val Loss: 0.117770, Val Acc: 0.773196\n",
      "Epoch 17811 - Train Loss: 0.091974, Train Acc: 0.856410 | Val Loss: 0.117768, Val Acc: 0.773196\n",
      "Epoch 17812 - Train Loss: 0.091971, Train Acc: 0.856410 | Val Loss: 0.117767, Val Acc: 0.773196\n",
      "Epoch 17813 - Train Loss: 0.091968, Train Acc: 0.856410 | Val Loss: 0.117765, Val Acc: 0.773196\n",
      "Epoch 17814 - Train Loss: 0.091966, Train Acc: 0.856410 | Val Loss: 0.117764, Val Acc: 0.773196\n",
      "Epoch 17815 - Train Loss: 0.091963, Train Acc: 0.856410 | Val Loss: 0.117762, Val Acc: 0.773196\n",
      "Epoch 17816 - Train Loss: 0.091960, Train Acc: 0.856410 | Val Loss: 0.117761, Val Acc: 0.773196\n",
      "Epoch 17817 - Train Loss: 0.091957, Train Acc: 0.856410 | Val Loss: 0.117759, Val Acc: 0.773196\n",
      "Epoch 17818 - Train Loss: 0.091955, Train Acc: 0.856410 | Val Loss: 0.117758, Val Acc: 0.773196\n",
      "Epoch 17819 - Train Loss: 0.091952, Train Acc: 0.856410 | Val Loss: 0.117756, Val Acc: 0.773196\n",
      "Epoch 17820 - Train Loss: 0.091949, Train Acc: 0.856410 | Val Loss: 0.117755, Val Acc: 0.773196\n",
      "Epoch 17821 - Train Loss: 0.091947, Train Acc: 0.856410 | Val Loss: 0.117753, Val Acc: 0.773196\n",
      "Epoch 17822 - Train Loss: 0.091944, Train Acc: 0.856410 | Val Loss: 0.117752, Val Acc: 0.773196\n",
      "Epoch 17823 - Train Loss: 0.091941, Train Acc: 0.856410 | Val Loss: 0.117750, Val Acc: 0.773196\n",
      "Epoch 17824 - Train Loss: 0.091938, Train Acc: 0.856410 | Val Loss: 0.117749, Val Acc: 0.773196\n",
      "Epoch 17825 - Train Loss: 0.091936, Train Acc: 0.856410 | Val Loss: 0.117747, Val Acc: 0.773196\n",
      "Epoch 17826 - Train Loss: 0.091933, Train Acc: 0.856410 | Val Loss: 0.117746, Val Acc: 0.773196\n",
      "Epoch 17827 - Train Loss: 0.091930, Train Acc: 0.856410 | Val Loss: 0.117744, Val Acc: 0.773196\n",
      "Epoch 17828 - Train Loss: 0.091927, Train Acc: 0.856410 | Val Loss: 0.117743, Val Acc: 0.773196\n",
      "Epoch 17829 - Train Loss: 0.091925, Train Acc: 0.856410 | Val Loss: 0.117741, Val Acc: 0.773196\n",
      "Epoch 17830 - Train Loss: 0.091922, Train Acc: 0.856410 | Val Loss: 0.117740, Val Acc: 0.773196\n",
      "Epoch 17831 - Train Loss: 0.091919, Train Acc: 0.856410 | Val Loss: 0.117738, Val Acc: 0.773196\n",
      "Epoch 17832 - Train Loss: 0.091916, Train Acc: 0.856410 | Val Loss: 0.117737, Val Acc: 0.773196\n",
      "Epoch 17833 - Train Loss: 0.091914, Train Acc: 0.856410 | Val Loss: 0.117735, Val Acc: 0.773196\n",
      "Epoch 17834 - Train Loss: 0.091911, Train Acc: 0.856410 | Val Loss: 0.117733, Val Acc: 0.773196\n",
      "Epoch 17835 - Train Loss: 0.091908, Train Acc: 0.856410 | Val Loss: 0.117732, Val Acc: 0.773196\n",
      "Epoch 17836 - Train Loss: 0.091905, Train Acc: 0.856410 | Val Loss: 0.117730, Val Acc: 0.773196\n",
      "Epoch 17837 - Train Loss: 0.091903, Train Acc: 0.856410 | Val Loss: 0.117729, Val Acc: 0.773196\n",
      "Epoch 17838 - Train Loss: 0.091900, Train Acc: 0.856410 | Val Loss: 0.117727, Val Acc: 0.773196\n",
      "Epoch 17839 - Train Loss: 0.091897, Train Acc: 0.856410 | Val Loss: 0.117726, Val Acc: 0.773196\n",
      "Epoch 17840 - Train Loss: 0.091895, Train Acc: 0.856410 | Val Loss: 0.117724, Val Acc: 0.773196\n",
      "Epoch 17841 - Train Loss: 0.091892, Train Acc: 0.856410 | Val Loss: 0.117723, Val Acc: 0.773196\n",
      "Epoch 17842 - Train Loss: 0.091889, Train Acc: 0.856410 | Val Loss: 0.117721, Val Acc: 0.773196\n",
      "Epoch 17843 - Train Loss: 0.091886, Train Acc: 0.856410 | Val Loss: 0.117720, Val Acc: 0.773196\n",
      "Epoch 17844 - Train Loss: 0.091884, Train Acc: 0.856410 | Val Loss: 0.117718, Val Acc: 0.773196\n",
      "Epoch 17845 - Train Loss: 0.091881, Train Acc: 0.856410 | Val Loss: 0.117717, Val Acc: 0.773196\n",
      "Epoch 17846 - Train Loss: 0.091878, Train Acc: 0.856410 | Val Loss: 0.117715, Val Acc: 0.773196\n",
      "Epoch 17847 - Train Loss: 0.091875, Train Acc: 0.856410 | Val Loss: 0.117714, Val Acc: 0.773196\n",
      "Epoch 17848 - Train Loss: 0.091873, Train Acc: 0.856410 | Val Loss: 0.117712, Val Acc: 0.773196\n",
      "Epoch 17849 - Train Loss: 0.091870, Train Acc: 0.856410 | Val Loss: 0.117711, Val Acc: 0.773196\n",
      "Epoch 17850 - Train Loss: 0.091867, Train Acc: 0.856410 | Val Loss: 0.117709, Val Acc: 0.773196\n",
      "Epoch 17851 - Train Loss: 0.091864, Train Acc: 0.856410 | Val Loss: 0.117708, Val Acc: 0.773196\n",
      "Epoch 17852 - Train Loss: 0.091862, Train Acc: 0.856410 | Val Loss: 0.117706, Val Acc: 0.773196\n",
      "Epoch 17853 - Train Loss: 0.091859, Train Acc: 0.856410 | Val Loss: 0.117705, Val Acc: 0.773196\n",
      "Epoch 17854 - Train Loss: 0.091856, Train Acc: 0.856410 | Val Loss: 0.117703, Val Acc: 0.773196\n",
      "Epoch 17855 - Train Loss: 0.091854, Train Acc: 0.856410 | Val Loss: 0.117702, Val Acc: 0.773196\n",
      "Epoch 17856 - Train Loss: 0.091851, Train Acc: 0.856410 | Val Loss: 0.117700, Val Acc: 0.773196\n",
      "Epoch 17857 - Train Loss: 0.091848, Train Acc: 0.856410 | Val Loss: 0.117699, Val Acc: 0.773196\n",
      "Epoch 17858 - Train Loss: 0.091845, Train Acc: 0.856410 | Val Loss: 0.117697, Val Acc: 0.773196\n",
      "Epoch 17859 - Train Loss: 0.091843, Train Acc: 0.856410 | Val Loss: 0.117696, Val Acc: 0.773196\n",
      "Epoch 17860 - Train Loss: 0.091840, Train Acc: 0.856410 | Val Loss: 0.117694, Val Acc: 0.773196\n",
      "Epoch 17861 - Train Loss: 0.091837, Train Acc: 0.856410 | Val Loss: 0.117693, Val Acc: 0.773196\n",
      "Epoch 17862 - Train Loss: 0.091834, Train Acc: 0.856410 | Val Loss: 0.117691, Val Acc: 0.773196\n",
      "Epoch 17863 - Train Loss: 0.091832, Train Acc: 0.856410 | Val Loss: 0.117690, Val Acc: 0.773196\n",
      "Epoch 17864 - Train Loss: 0.091829, Train Acc: 0.856410 | Val Loss: 0.117688, Val Acc: 0.773196\n",
      "Epoch 17865 - Train Loss: 0.091826, Train Acc: 0.856410 | Val Loss: 0.117687, Val Acc: 0.773196\n",
      "Epoch 17866 - Train Loss: 0.091824, Train Acc: 0.856410 | Val Loss: 0.117685, Val Acc: 0.773196\n",
      "Epoch 17867 - Train Loss: 0.091821, Train Acc: 0.856410 | Val Loss: 0.117684, Val Acc: 0.773196\n",
      "Epoch 17868 - Train Loss: 0.091818, Train Acc: 0.856410 | Val Loss: 0.117682, Val Acc: 0.773196\n",
      "Epoch 17869 - Train Loss: 0.091815, Train Acc: 0.856410 | Val Loss: 0.117681, Val Acc: 0.773196\n",
      "Epoch 17870 - Train Loss: 0.091813, Train Acc: 0.856410 | Val Loss: 0.117679, Val Acc: 0.773196\n",
      "Epoch 17871 - Train Loss: 0.091810, Train Acc: 0.856410 | Val Loss: 0.117678, Val Acc: 0.773196\n",
      "Epoch 17872 - Train Loss: 0.091807, Train Acc: 0.856410 | Val Loss: 0.117676, Val Acc: 0.773196\n",
      "Epoch 17873 - Train Loss: 0.091804, Train Acc: 0.856410 | Val Loss: 0.117675, Val Acc: 0.773196\n",
      "Epoch 17874 - Train Loss: 0.091802, Train Acc: 0.856410 | Val Loss: 0.117673, Val Acc: 0.773196\n",
      "Epoch 17875 - Train Loss: 0.091799, Train Acc: 0.856410 | Val Loss: 0.117672, Val Acc: 0.773196\n",
      "Epoch 17876 - Train Loss: 0.091796, Train Acc: 0.856410 | Val Loss: 0.117670, Val Acc: 0.773196\n",
      "Epoch 17877 - Train Loss: 0.091794, Train Acc: 0.856410 | Val Loss: 0.117669, Val Acc: 0.773196\n",
      "Epoch 17878 - Train Loss: 0.091791, Train Acc: 0.856410 | Val Loss: 0.117667, Val Acc: 0.773196\n",
      "Epoch 17879 - Train Loss: 0.091788, Train Acc: 0.856410 | Val Loss: 0.117666, Val Acc: 0.773196\n",
      "Epoch 17880 - Train Loss: 0.091785, Train Acc: 0.856410 | Val Loss: 0.117664, Val Acc: 0.773196\n",
      "Epoch 17881 - Train Loss: 0.091783, Train Acc: 0.856410 | Val Loss: 0.117663, Val Acc: 0.773196\n",
      "Epoch 17882 - Train Loss: 0.091780, Train Acc: 0.856410 | Val Loss: 0.117661, Val Acc: 0.773196\n",
      "Epoch 17883 - Train Loss: 0.091777, Train Acc: 0.856410 | Val Loss: 0.117660, Val Acc: 0.773196\n",
      "Epoch 17884 - Train Loss: 0.091775, Train Acc: 0.856410 | Val Loss: 0.117659, Val Acc: 0.773196\n",
      "Epoch 17885 - Train Loss: 0.091772, Train Acc: 0.856410 | Val Loss: 0.117657, Val Acc: 0.773196\n",
      "Epoch 17886 - Train Loss: 0.091769, Train Acc: 0.856410 | Val Loss: 0.117656, Val Acc: 0.773196\n",
      "Epoch 17887 - Train Loss: 0.091766, Train Acc: 0.856410 | Val Loss: 0.117654, Val Acc: 0.773196\n",
      "Epoch 17888 - Train Loss: 0.091764, Train Acc: 0.856410 | Val Loss: 0.117653, Val Acc: 0.773196\n",
      "Epoch 17889 - Train Loss: 0.091761, Train Acc: 0.856410 | Val Loss: 0.117651, Val Acc: 0.773196\n",
      "Epoch 17890 - Train Loss: 0.091758, Train Acc: 0.856410 | Val Loss: 0.117650, Val Acc: 0.773196\n",
      "Epoch 17891 - Train Loss: 0.091755, Train Acc: 0.856410 | Val Loss: 0.117648, Val Acc: 0.773196\n",
      "Epoch 17892 - Train Loss: 0.091753, Train Acc: 0.856410 | Val Loss: 0.117647, Val Acc: 0.773196\n",
      "Epoch 17893 - Train Loss: 0.091750, Train Acc: 0.856410 | Val Loss: 0.117645, Val Acc: 0.773196\n",
      "Epoch 17894 - Train Loss: 0.091747, Train Acc: 0.856410 | Val Loss: 0.117644, Val Acc: 0.773196\n",
      "Epoch 17895 - Train Loss: 0.091745, Train Acc: 0.856410 | Val Loss: 0.117642, Val Acc: 0.773196\n",
      "Epoch 17896 - Train Loss: 0.091742, Train Acc: 0.856410 | Val Loss: 0.117641, Val Acc: 0.773196\n",
      "Epoch 17897 - Train Loss: 0.091739, Train Acc: 0.856410 | Val Loss: 0.117639, Val Acc: 0.773196\n",
      "Epoch 17898 - Train Loss: 0.091736, Train Acc: 0.856410 | Val Loss: 0.117638, Val Acc: 0.773196\n",
      "Epoch 17899 - Train Loss: 0.091734, Train Acc: 0.856410 | Val Loss: 0.117636, Val Acc: 0.773196\n",
      "Epoch 17900 - Train Loss: 0.091731, Train Acc: 0.856410 | Val Loss: 0.117635, Val Acc: 0.773196\n",
      "Epoch 17901 - Train Loss: 0.091728, Train Acc: 0.856410 | Val Loss: 0.117633, Val Acc: 0.773196\n",
      "Epoch 17902 - Train Loss: 0.091726, Train Acc: 0.856410 | Val Loss: 0.117632, Val Acc: 0.773196\n",
      "Epoch 17903 - Train Loss: 0.091723, Train Acc: 0.856410 | Val Loss: 0.117630, Val Acc: 0.773196\n",
      "Epoch 17904 - Train Loss: 0.091720, Train Acc: 0.856410 | Val Loss: 0.117629, Val Acc: 0.773196\n",
      "Epoch 17905 - Train Loss: 0.091717, Train Acc: 0.856410 | Val Loss: 0.117627, Val Acc: 0.773196\n",
      "Epoch 17906 - Train Loss: 0.091715, Train Acc: 0.856410 | Val Loss: 0.117626, Val Acc: 0.773196\n",
      "Epoch 17907 - Train Loss: 0.091712, Train Acc: 0.856410 | Val Loss: 0.117624, Val Acc: 0.773196\n",
      "Epoch 17908 - Train Loss: 0.091709, Train Acc: 0.856410 | Val Loss: 0.117623, Val Acc: 0.773196\n",
      "Epoch 17909 - Train Loss: 0.091707, Train Acc: 0.856410 | Val Loss: 0.117621, Val Acc: 0.773196\n",
      "Epoch 17910 - Train Loss: 0.091704, Train Acc: 0.856410 | Val Loss: 0.117620, Val Acc: 0.773196\n",
      "Epoch 17911 - Train Loss: 0.091701, Train Acc: 0.856410 | Val Loss: 0.117618, Val Acc: 0.773196\n",
      "Epoch 17912 - Train Loss: 0.091698, Train Acc: 0.856410 | Val Loss: 0.117617, Val Acc: 0.773196\n",
      "Epoch 17913 - Train Loss: 0.091696, Train Acc: 0.856410 | Val Loss: 0.117615, Val Acc: 0.773196\n",
      "Epoch 17914 - Train Loss: 0.091693, Train Acc: 0.856410 | Val Loss: 0.117614, Val Acc: 0.773196\n",
      "Epoch 17915 - Train Loss: 0.091690, Train Acc: 0.856410 | Val Loss: 0.117612, Val Acc: 0.773196\n",
      "Epoch 17916 - Train Loss: 0.091688, Train Acc: 0.856410 | Val Loss: 0.117611, Val Acc: 0.773196\n",
      "Epoch 17917 - Train Loss: 0.091685, Train Acc: 0.856410 | Val Loss: 0.117609, Val Acc: 0.773196\n",
      "Epoch 17918 - Train Loss: 0.091682, Train Acc: 0.856410 | Val Loss: 0.117608, Val Acc: 0.773196\n",
      "Epoch 17919 - Train Loss: 0.091679, Train Acc: 0.856410 | Val Loss: 0.117606, Val Acc: 0.773196\n",
      "Epoch 17920 - Train Loss: 0.091677, Train Acc: 0.856410 | Val Loss: 0.117605, Val Acc: 0.773196\n",
      "Epoch 17921 - Train Loss: 0.091674, Train Acc: 0.856410 | Val Loss: 0.117604, Val Acc: 0.773196\n",
      "Epoch 17922 - Train Loss: 0.091671, Train Acc: 0.856410 | Val Loss: 0.117602, Val Acc: 0.773196\n",
      "Epoch 17923 - Train Loss: 0.091669, Train Acc: 0.856410 | Val Loss: 0.117601, Val Acc: 0.773196\n",
      "Epoch 17924 - Train Loss: 0.091666, Train Acc: 0.856410 | Val Loss: 0.117599, Val Acc: 0.773196\n",
      "Epoch 17925 - Train Loss: 0.091663, Train Acc: 0.856410 | Val Loss: 0.117598, Val Acc: 0.773196\n",
      "Epoch 17926 - Train Loss: 0.091660, Train Acc: 0.856410 | Val Loss: 0.117596, Val Acc: 0.773196\n",
      "Epoch 17927 - Train Loss: 0.091658, Train Acc: 0.856410 | Val Loss: 0.117595, Val Acc: 0.773196\n",
      "Epoch 17928 - Train Loss: 0.091655, Train Acc: 0.856410 | Val Loss: 0.117593, Val Acc: 0.773196\n",
      "Epoch 17929 - Train Loss: 0.091652, Train Acc: 0.856410 | Val Loss: 0.117592, Val Acc: 0.773196\n",
      "Epoch 17930 - Train Loss: 0.091650, Train Acc: 0.856410 | Val Loss: 0.117590, Val Acc: 0.773196\n",
      "Epoch 17931 - Train Loss: 0.091647, Train Acc: 0.856410 | Val Loss: 0.117589, Val Acc: 0.773196\n",
      "Epoch 17932 - Train Loss: 0.091644, Train Acc: 0.856410 | Val Loss: 0.117587, Val Acc: 0.773196\n",
      "Epoch 17933 - Train Loss: 0.091641, Train Acc: 0.856410 | Val Loss: 0.117586, Val Acc: 0.773196\n",
      "Epoch 17934 - Train Loss: 0.091639, Train Acc: 0.856410 | Val Loss: 0.117584, Val Acc: 0.773196\n",
      "Epoch 17935 - Train Loss: 0.091636, Train Acc: 0.856410 | Val Loss: 0.117583, Val Acc: 0.773196\n",
      "Epoch 17936 - Train Loss: 0.091633, Train Acc: 0.856410 | Val Loss: 0.117581, Val Acc: 0.773196\n",
      "Epoch 17937 - Train Loss: 0.091631, Train Acc: 0.856410 | Val Loss: 0.117580, Val Acc: 0.773196\n",
      "Epoch 17938 - Train Loss: 0.091628, Train Acc: 0.856410 | Val Loss: 0.117578, Val Acc: 0.773196\n",
      "Epoch 17939 - Train Loss: 0.091625, Train Acc: 0.856410 | Val Loss: 0.117577, Val Acc: 0.773196\n",
      "Epoch 17940 - Train Loss: 0.091623, Train Acc: 0.856410 | Val Loss: 0.117575, Val Acc: 0.773196\n",
      "Epoch 17941 - Train Loss: 0.091620, Train Acc: 0.856410 | Val Loss: 0.117574, Val Acc: 0.773196\n",
      "Epoch 17942 - Train Loss: 0.091617, Train Acc: 0.856410 | Val Loss: 0.117572, Val Acc: 0.773196\n",
      "Epoch 17943 - Train Loss: 0.091614, Train Acc: 0.856410 | Val Loss: 0.117571, Val Acc: 0.773196\n",
      "Epoch 17944 - Train Loss: 0.091612, Train Acc: 0.856410 | Val Loss: 0.117570, Val Acc: 0.773196\n",
      "Epoch 17945 - Train Loss: 0.091609, Train Acc: 0.856410 | Val Loss: 0.117568, Val Acc: 0.773196\n",
      "Epoch 17946 - Train Loss: 0.091606, Train Acc: 0.856410 | Val Loss: 0.117567, Val Acc: 0.773196\n",
      "Epoch 17947 - Train Loss: 0.091604, Train Acc: 0.856410 | Val Loss: 0.117565, Val Acc: 0.773196\n",
      "Epoch 17948 - Train Loss: 0.091601, Train Acc: 0.856410 | Val Loss: 0.117564, Val Acc: 0.773196\n",
      "Epoch 17949 - Train Loss: 0.091598, Train Acc: 0.856410 | Val Loss: 0.117562, Val Acc: 0.773196\n",
      "Epoch 17950 - Train Loss: 0.091595, Train Acc: 0.856410 | Val Loss: 0.117561, Val Acc: 0.773196\n",
      "Epoch 17951 - Train Loss: 0.091593, Train Acc: 0.856410 | Val Loss: 0.117559, Val Acc: 0.773196\n",
      "Epoch 17952 - Train Loss: 0.091590, Train Acc: 0.856410 | Val Loss: 0.117558, Val Acc: 0.773196\n",
      "Epoch 17953 - Train Loss: 0.091587, Train Acc: 0.856410 | Val Loss: 0.117556, Val Acc: 0.773196\n",
      "Epoch 17954 - Train Loss: 0.091585, Train Acc: 0.856410 | Val Loss: 0.117555, Val Acc: 0.773196\n",
      "Epoch 17955 - Train Loss: 0.091582, Train Acc: 0.856410 | Val Loss: 0.117553, Val Acc: 0.773196\n",
      "Epoch 17956 - Train Loss: 0.091579, Train Acc: 0.856410 | Val Loss: 0.117552, Val Acc: 0.773196\n",
      "Epoch 17957 - Train Loss: 0.091577, Train Acc: 0.856410 | Val Loss: 0.117550, Val Acc: 0.773196\n",
      "Epoch 17958 - Train Loss: 0.091574, Train Acc: 0.856410 | Val Loss: 0.117549, Val Acc: 0.773196\n",
      "Epoch 17959 - Train Loss: 0.091571, Train Acc: 0.856410 | Val Loss: 0.117547, Val Acc: 0.773196\n",
      "Epoch 17960 - Train Loss: 0.091568, Train Acc: 0.856410 | Val Loss: 0.117546, Val Acc: 0.773196\n",
      "Epoch 17961 - Train Loss: 0.091566, Train Acc: 0.856410 | Val Loss: 0.117544, Val Acc: 0.773196\n",
      "Epoch 17962 - Train Loss: 0.091563, Train Acc: 0.856410 | Val Loss: 0.117543, Val Acc: 0.773196\n",
      "Epoch 17963 - Train Loss: 0.091560, Train Acc: 0.856410 | Val Loss: 0.117542, Val Acc: 0.773196\n",
      "Epoch 17964 - Train Loss: 0.091558, Train Acc: 0.856410 | Val Loss: 0.117540, Val Acc: 0.773196\n",
      "Epoch 17965 - Train Loss: 0.091555, Train Acc: 0.856410 | Val Loss: 0.117539, Val Acc: 0.773196\n",
      "Epoch 17966 - Train Loss: 0.091552, Train Acc: 0.856410 | Val Loss: 0.117537, Val Acc: 0.773196\n",
      "Epoch 17967 - Train Loss: 0.091550, Train Acc: 0.856410 | Val Loss: 0.117536, Val Acc: 0.773196\n",
      "Epoch 17968 - Train Loss: 0.091547, Train Acc: 0.856410 | Val Loss: 0.117534, Val Acc: 0.773196\n",
      "Epoch 17969 - Train Loss: 0.091544, Train Acc: 0.856410 | Val Loss: 0.117533, Val Acc: 0.773196\n",
      "Epoch 17970 - Train Loss: 0.091541, Train Acc: 0.856410 | Val Loss: 0.117531, Val Acc: 0.773196\n",
      "Epoch 17971 - Train Loss: 0.091539, Train Acc: 0.856410 | Val Loss: 0.117530, Val Acc: 0.773196\n",
      "Epoch 17972 - Train Loss: 0.091536, Train Acc: 0.856410 | Val Loss: 0.117528, Val Acc: 0.773196\n",
      "Epoch 17973 - Train Loss: 0.091533, Train Acc: 0.856410 | Val Loss: 0.117527, Val Acc: 0.773196\n",
      "Epoch 17974 - Train Loss: 0.091531, Train Acc: 0.856410 | Val Loss: 0.117525, Val Acc: 0.773196\n",
      "Epoch 17975 - Train Loss: 0.091528, Train Acc: 0.856410 | Val Loss: 0.117524, Val Acc: 0.773196\n",
      "Epoch 17976 - Train Loss: 0.091525, Train Acc: 0.856410 | Val Loss: 0.117522, Val Acc: 0.773196\n",
      "Epoch 17977 - Train Loss: 0.091523, Train Acc: 0.856410 | Val Loss: 0.117521, Val Acc: 0.773196\n",
      "Epoch 17978 - Train Loss: 0.091520, Train Acc: 0.856410 | Val Loss: 0.117519, Val Acc: 0.773196\n",
      "Epoch 17979 - Train Loss: 0.091517, Train Acc: 0.856410 | Val Loss: 0.117518, Val Acc: 0.773196\n",
      "Epoch 17980 - Train Loss: 0.091514, Train Acc: 0.856410 | Val Loss: 0.117517, Val Acc: 0.773196\n",
      "Epoch 17981 - Train Loss: 0.091512, Train Acc: 0.856410 | Val Loss: 0.117515, Val Acc: 0.773196\n",
      "Epoch 17982 - Train Loss: 0.091509, Train Acc: 0.856410 | Val Loss: 0.117514, Val Acc: 0.773196\n",
      "Epoch 17983 - Train Loss: 0.091506, Train Acc: 0.856410 | Val Loss: 0.117512, Val Acc: 0.773196\n",
      "Epoch 17984 - Train Loss: 0.091504, Train Acc: 0.856410 | Val Loss: 0.117511, Val Acc: 0.773196\n",
      "Epoch 17985 - Train Loss: 0.091501, Train Acc: 0.856410 | Val Loss: 0.117509, Val Acc: 0.773196\n",
      "Epoch 17986 - Train Loss: 0.091498, Train Acc: 0.856410 | Val Loss: 0.117508, Val Acc: 0.773196\n",
      "Epoch 17987 - Train Loss: 0.091496, Train Acc: 0.856410 | Val Loss: 0.117506, Val Acc: 0.773196\n",
      "Epoch 17988 - Train Loss: 0.091493, Train Acc: 0.856410 | Val Loss: 0.117505, Val Acc: 0.773196\n",
      "Epoch 17989 - Train Loss: 0.091490, Train Acc: 0.856410 | Val Loss: 0.117503, Val Acc: 0.773196\n",
      "Epoch 17990 - Train Loss: 0.091488, Train Acc: 0.856410 | Val Loss: 0.117502, Val Acc: 0.773196\n",
      "Epoch 17991 - Train Loss: 0.091485, Train Acc: 0.856410 | Val Loss: 0.117500, Val Acc: 0.773196\n",
      "Epoch 17992 - Train Loss: 0.091482, Train Acc: 0.856410 | Val Loss: 0.117499, Val Acc: 0.773196\n",
      "Epoch 17993 - Train Loss: 0.091479, Train Acc: 0.856410 | Val Loss: 0.117498, Val Acc: 0.773196\n",
      "Epoch 17994 - Train Loss: 0.091477, Train Acc: 0.856410 | Val Loss: 0.117496, Val Acc: 0.773196\n",
      "Epoch 17995 - Train Loss: 0.091474, Train Acc: 0.856410 | Val Loss: 0.117495, Val Acc: 0.773196\n",
      "Epoch 17996 - Train Loss: 0.091471, Train Acc: 0.856410 | Val Loss: 0.117493, Val Acc: 0.773196\n",
      "Epoch 17997 - Train Loss: 0.091469, Train Acc: 0.856410 | Val Loss: 0.117492, Val Acc: 0.773196\n",
      "Epoch 17998 - Train Loss: 0.091466, Train Acc: 0.856410 | Val Loss: 0.117490, Val Acc: 0.773196\n",
      "Epoch 17999 - Train Loss: 0.091463, Train Acc: 0.856410 | Val Loss: 0.117489, Val Acc: 0.773196\n",
      "Epoch 18000 - Train Loss: 0.091461, Train Acc: 0.856410 | Val Loss: 0.117487, Val Acc: 0.773196\n",
      "Epoch 18001 - Train Loss: 0.091458, Train Acc: 0.856410 | Val Loss: 0.117486, Val Acc: 0.773196\n",
      "Epoch 18002 - Train Loss: 0.091455, Train Acc: 0.856410 | Val Loss: 0.117484, Val Acc: 0.773196\n",
      "Epoch 18003 - Train Loss: 0.091453, Train Acc: 0.856410 | Val Loss: 0.117483, Val Acc: 0.773196\n",
      "Epoch 18004 - Train Loss: 0.091450, Train Acc: 0.856410 | Val Loss: 0.117481, Val Acc: 0.773196\n",
      "Epoch 18005 - Train Loss: 0.091447, Train Acc: 0.856410 | Val Loss: 0.117480, Val Acc: 0.773196\n",
      "Epoch 18006 - Train Loss: 0.091444, Train Acc: 0.856410 | Val Loss: 0.117479, Val Acc: 0.773196\n",
      "Epoch 18007 - Train Loss: 0.091442, Train Acc: 0.856410 | Val Loss: 0.117477, Val Acc: 0.773196\n",
      "Epoch 18008 - Train Loss: 0.091439, Train Acc: 0.856410 | Val Loss: 0.117476, Val Acc: 0.773196\n",
      "Epoch 18009 - Train Loss: 0.091436, Train Acc: 0.856410 | Val Loss: 0.117474, Val Acc: 0.773196\n",
      "Epoch 18010 - Train Loss: 0.091434, Train Acc: 0.856410 | Val Loss: 0.117473, Val Acc: 0.773196\n",
      "Epoch 18011 - Train Loss: 0.091431, Train Acc: 0.856410 | Val Loss: 0.117471, Val Acc: 0.773196\n",
      "Epoch 18012 - Train Loss: 0.091428, Train Acc: 0.856410 | Val Loss: 0.117470, Val Acc: 0.773196\n",
      "Epoch 18013 - Train Loss: 0.091426, Train Acc: 0.856410 | Val Loss: 0.117468, Val Acc: 0.773196\n",
      "Epoch 18014 - Train Loss: 0.091423, Train Acc: 0.856410 | Val Loss: 0.117467, Val Acc: 0.773196\n",
      "Epoch 18015 - Train Loss: 0.091420, Train Acc: 0.856410 | Val Loss: 0.117465, Val Acc: 0.773196\n",
      "Epoch 18016 - Train Loss: 0.091418, Train Acc: 0.856410 | Val Loss: 0.117464, Val Acc: 0.773196\n",
      "Epoch 18017 - Train Loss: 0.091415, Train Acc: 0.856410 | Val Loss: 0.117462, Val Acc: 0.773196\n",
      "Epoch 18018 - Train Loss: 0.091412, Train Acc: 0.856410 | Val Loss: 0.117461, Val Acc: 0.773196\n",
      "Epoch 18019 - Train Loss: 0.091410, Train Acc: 0.856410 | Val Loss: 0.117460, Val Acc: 0.773196\n",
      "Epoch 18020 - Train Loss: 0.091407, Train Acc: 0.856410 | Val Loss: 0.117458, Val Acc: 0.773196\n",
      "Epoch 18021 - Train Loss: 0.091404, Train Acc: 0.856410 | Val Loss: 0.117457, Val Acc: 0.773196\n",
      "Epoch 18022 - Train Loss: 0.091401, Train Acc: 0.856410 | Val Loss: 0.117455, Val Acc: 0.773196\n",
      "Epoch 18023 - Train Loss: 0.091399, Train Acc: 0.856410 | Val Loss: 0.117454, Val Acc: 0.773196\n",
      "Epoch 18024 - Train Loss: 0.091396, Train Acc: 0.856410 | Val Loss: 0.117452, Val Acc: 0.773196\n",
      "Epoch 18025 - Train Loss: 0.091393, Train Acc: 0.856410 | Val Loss: 0.117451, Val Acc: 0.773196\n",
      "Epoch 18026 - Train Loss: 0.091391, Train Acc: 0.856410 | Val Loss: 0.117449, Val Acc: 0.773196\n",
      "Epoch 18027 - Train Loss: 0.091388, Train Acc: 0.856410 | Val Loss: 0.117448, Val Acc: 0.773196\n",
      "Epoch 18028 - Train Loss: 0.091385, Train Acc: 0.856410 | Val Loss: 0.117447, Val Acc: 0.773196\n",
      "Epoch 18029 - Train Loss: 0.091383, Train Acc: 0.856410 | Val Loss: 0.117445, Val Acc: 0.773196\n",
      "Epoch 18030 - Train Loss: 0.091380, Train Acc: 0.856410 | Val Loss: 0.117444, Val Acc: 0.773196\n",
      "Epoch 18031 - Train Loss: 0.091377, Train Acc: 0.856410 | Val Loss: 0.117442, Val Acc: 0.773196\n",
      "Epoch 18032 - Train Loss: 0.091375, Train Acc: 0.856410 | Val Loss: 0.117441, Val Acc: 0.773196\n",
      "Epoch 18033 - Train Loss: 0.091372, Train Acc: 0.856410 | Val Loss: 0.117439, Val Acc: 0.773196\n",
      "Epoch 18034 - Train Loss: 0.091369, Train Acc: 0.856410 | Val Loss: 0.117438, Val Acc: 0.773196\n",
      "Epoch 18035 - Train Loss: 0.091367, Train Acc: 0.856410 | Val Loss: 0.117436, Val Acc: 0.773196\n",
      "Epoch 18036 - Train Loss: 0.091364, Train Acc: 0.856410 | Val Loss: 0.117435, Val Acc: 0.773196\n",
      "Epoch 18037 - Train Loss: 0.091361, Train Acc: 0.856410 | Val Loss: 0.117433, Val Acc: 0.773196\n",
      "Epoch 18038 - Train Loss: 0.091359, Train Acc: 0.856410 | Val Loss: 0.117432, Val Acc: 0.773196\n",
      "Epoch 18039 - Train Loss: 0.091356, Train Acc: 0.856410 | Val Loss: 0.117430, Val Acc: 0.773196\n",
      "Epoch 18040 - Train Loss: 0.091353, Train Acc: 0.856410 | Val Loss: 0.117429, Val Acc: 0.773196\n",
      "Epoch 18041 - Train Loss: 0.091350, Train Acc: 0.856410 | Val Loss: 0.117428, Val Acc: 0.773196\n",
      "Epoch 18042 - Train Loss: 0.091348, Train Acc: 0.856410 | Val Loss: 0.117426, Val Acc: 0.773196\n",
      "Epoch 18043 - Train Loss: 0.091345, Train Acc: 0.856410 | Val Loss: 0.117425, Val Acc: 0.773196\n",
      "Epoch 18044 - Train Loss: 0.091342, Train Acc: 0.856410 | Val Loss: 0.117423, Val Acc: 0.773196\n",
      "Epoch 18045 - Train Loss: 0.091340, Train Acc: 0.856410 | Val Loss: 0.117422, Val Acc: 0.773196\n",
      "Epoch 18046 - Train Loss: 0.091337, Train Acc: 0.856410 | Val Loss: 0.117420, Val Acc: 0.773196\n",
      "Epoch 18047 - Train Loss: 0.091334, Train Acc: 0.856410 | Val Loss: 0.117419, Val Acc: 0.773196\n",
      "Epoch 18048 - Train Loss: 0.091332, Train Acc: 0.856410 | Val Loss: 0.117417, Val Acc: 0.773196\n",
      "Epoch 18049 - Train Loss: 0.091329, Train Acc: 0.856410 | Val Loss: 0.117416, Val Acc: 0.773196\n",
      "Epoch 18050 - Train Loss: 0.091326, Train Acc: 0.856410 | Val Loss: 0.117414, Val Acc: 0.773196\n",
      "Epoch 18051 - Train Loss: 0.091324, Train Acc: 0.856410 | Val Loss: 0.117413, Val Acc: 0.773196\n",
      "Epoch 18052 - Train Loss: 0.091321, Train Acc: 0.856410 | Val Loss: 0.117412, Val Acc: 0.773196\n",
      "Epoch 18053 - Train Loss: 0.091318, Train Acc: 0.856410 | Val Loss: 0.117410, Val Acc: 0.773196\n",
      "Epoch 18054 - Train Loss: 0.091316, Train Acc: 0.856410 | Val Loss: 0.117409, Val Acc: 0.773196\n",
      "Epoch 18055 - Train Loss: 0.091313, Train Acc: 0.856410 | Val Loss: 0.117407, Val Acc: 0.773196\n",
      "Epoch 18056 - Train Loss: 0.091310, Train Acc: 0.856410 | Val Loss: 0.117406, Val Acc: 0.773196\n",
      "Epoch 18057 - Train Loss: 0.091308, Train Acc: 0.856410 | Val Loss: 0.117404, Val Acc: 0.773196\n",
      "Epoch 18058 - Train Loss: 0.091305, Train Acc: 0.856410 | Val Loss: 0.117403, Val Acc: 0.773196\n",
      "Epoch 18059 - Train Loss: 0.091302, Train Acc: 0.856410 | Val Loss: 0.117401, Val Acc: 0.773196\n",
      "Epoch 18060 - Train Loss: 0.091300, Train Acc: 0.856410 | Val Loss: 0.117400, Val Acc: 0.773196\n",
      "Epoch 18061 - Train Loss: 0.091297, Train Acc: 0.856410 | Val Loss: 0.117399, Val Acc: 0.773196\n",
      "Epoch 18062 - Train Loss: 0.091294, Train Acc: 0.856410 | Val Loss: 0.117397, Val Acc: 0.773196\n",
      "Epoch 18063 - Train Loss: 0.091292, Train Acc: 0.856410 | Val Loss: 0.117396, Val Acc: 0.773196\n",
      "Epoch 18064 - Train Loss: 0.091289, Train Acc: 0.856410 | Val Loss: 0.117394, Val Acc: 0.773196\n",
      "Epoch 18065 - Train Loss: 0.091286, Train Acc: 0.856410 | Val Loss: 0.117393, Val Acc: 0.773196\n",
      "Epoch 18066 - Train Loss: 0.091284, Train Acc: 0.856410 | Val Loss: 0.117391, Val Acc: 0.773196\n",
      "Epoch 18067 - Train Loss: 0.091281, Train Acc: 0.856410 | Val Loss: 0.117390, Val Acc: 0.773196\n",
      "Epoch 18068 - Train Loss: 0.091278, Train Acc: 0.856410 | Val Loss: 0.117388, Val Acc: 0.773196\n",
      "Epoch 18069 - Train Loss: 0.091275, Train Acc: 0.856410 | Val Loss: 0.117387, Val Acc: 0.773196\n",
      "Epoch 18070 - Train Loss: 0.091273, Train Acc: 0.856410 | Val Loss: 0.117385, Val Acc: 0.773196\n",
      "Epoch 18071 - Train Loss: 0.091270, Train Acc: 0.856410 | Val Loss: 0.117384, Val Acc: 0.773196\n",
      "Epoch 18072 - Train Loss: 0.091267, Train Acc: 0.856410 | Val Loss: 0.117383, Val Acc: 0.773196\n",
      "Epoch 18073 - Train Loss: 0.091265, Train Acc: 0.856410 | Val Loss: 0.117381, Val Acc: 0.773196\n",
      "Epoch 18074 - Train Loss: 0.091262, Train Acc: 0.856410 | Val Loss: 0.117380, Val Acc: 0.773196\n",
      "Epoch 18075 - Train Loss: 0.091259, Train Acc: 0.856410 | Val Loss: 0.117378, Val Acc: 0.773196\n",
      "Epoch 18076 - Train Loss: 0.091257, Train Acc: 0.856410 | Val Loss: 0.117377, Val Acc: 0.773196\n",
      "Epoch 18077 - Train Loss: 0.091254, Train Acc: 0.856410 | Val Loss: 0.117375, Val Acc: 0.773196\n",
      "Epoch 18078 - Train Loss: 0.091251, Train Acc: 0.856410 | Val Loss: 0.117374, Val Acc: 0.773196\n",
      "Epoch 18079 - Train Loss: 0.091249, Train Acc: 0.856410 | Val Loss: 0.117373, Val Acc: 0.773196\n",
      "Epoch 18080 - Train Loss: 0.091246, Train Acc: 0.856410 | Val Loss: 0.117371, Val Acc: 0.773196\n",
      "Epoch 18081 - Train Loss: 0.091243, Train Acc: 0.856410 | Val Loss: 0.117370, Val Acc: 0.773196\n",
      "Epoch 18082 - Train Loss: 0.091241, Train Acc: 0.856410 | Val Loss: 0.117368, Val Acc: 0.773196\n",
      "Epoch 18083 - Train Loss: 0.091238, Train Acc: 0.856410 | Val Loss: 0.117367, Val Acc: 0.773196\n",
      "Epoch 18084 - Train Loss: 0.091235, Train Acc: 0.856410 | Val Loss: 0.117365, Val Acc: 0.773196\n",
      "Epoch 18085 - Train Loss: 0.091233, Train Acc: 0.856410 | Val Loss: 0.117364, Val Acc: 0.773196\n",
      "Epoch 18086 - Train Loss: 0.091230, Train Acc: 0.856410 | Val Loss: 0.117362, Val Acc: 0.773196\n",
      "Epoch 18087 - Train Loss: 0.091227, Train Acc: 0.856410 | Val Loss: 0.117361, Val Acc: 0.773196\n",
      "Epoch 18088 - Train Loss: 0.091225, Train Acc: 0.856410 | Val Loss: 0.117360, Val Acc: 0.773196\n",
      "Epoch 18089 - Train Loss: 0.091222, Train Acc: 0.856410 | Val Loss: 0.117358, Val Acc: 0.773196\n",
      "Epoch 18090 - Train Loss: 0.091219, Train Acc: 0.856410 | Val Loss: 0.117357, Val Acc: 0.773196\n",
      "Epoch 18091 - Train Loss: 0.091217, Train Acc: 0.856410 | Val Loss: 0.117355, Val Acc: 0.773196\n",
      "Epoch 18092 - Train Loss: 0.091214, Train Acc: 0.856410 | Val Loss: 0.117354, Val Acc: 0.773196\n",
      "Epoch 18093 - Train Loss: 0.091211, Train Acc: 0.856410 | Val Loss: 0.117352, Val Acc: 0.773196\n",
      "Epoch 18094 - Train Loss: 0.091209, Train Acc: 0.856410 | Val Loss: 0.117351, Val Acc: 0.773196\n",
      "Epoch 18095 - Train Loss: 0.091206, Train Acc: 0.856410 | Val Loss: 0.117350, Val Acc: 0.773196\n",
      "Epoch 18096 - Train Loss: 0.091203, Train Acc: 0.856410 | Val Loss: 0.117348, Val Acc: 0.773196\n",
      "Epoch 18097 - Train Loss: 0.091201, Train Acc: 0.856410 | Val Loss: 0.117347, Val Acc: 0.773196\n",
      "Epoch 18098 - Train Loss: 0.091198, Train Acc: 0.856410 | Val Loss: 0.117345, Val Acc: 0.773196\n",
      "Epoch 18099 - Train Loss: 0.091195, Train Acc: 0.856410 | Val Loss: 0.117344, Val Acc: 0.773196\n",
      "Epoch 18100 - Train Loss: 0.091193, Train Acc: 0.856410 | Val Loss: 0.117342, Val Acc: 0.773196\n",
      "Epoch 18101 - Train Loss: 0.091190, Train Acc: 0.856410 | Val Loss: 0.117341, Val Acc: 0.773196\n",
      "Epoch 18102 - Train Loss: 0.091187, Train Acc: 0.856410 | Val Loss: 0.117340, Val Acc: 0.773196\n",
      "Epoch 18103 - Train Loss: 0.091185, Train Acc: 0.856410 | Val Loss: 0.117338, Val Acc: 0.773196\n",
      "Epoch 18104 - Train Loss: 0.091182, Train Acc: 0.856410 | Val Loss: 0.117337, Val Acc: 0.773196\n",
      "Epoch 18105 - Train Loss: 0.091179, Train Acc: 0.856410 | Val Loss: 0.117335, Val Acc: 0.773196\n",
      "Epoch 18106 - Train Loss: 0.091177, Train Acc: 0.856410 | Val Loss: 0.117334, Val Acc: 0.773196\n",
      "Epoch 18107 - Train Loss: 0.091174, Train Acc: 0.856410 | Val Loss: 0.117332, Val Acc: 0.773196\n",
      "Epoch 18108 - Train Loss: 0.091171, Train Acc: 0.856410 | Val Loss: 0.117331, Val Acc: 0.773196\n",
      "Epoch 18109 - Train Loss: 0.091169, Train Acc: 0.856410 | Val Loss: 0.117330, Val Acc: 0.773196\n",
      "Epoch 18110 - Train Loss: 0.091166, Train Acc: 0.856410 | Val Loss: 0.117328, Val Acc: 0.773196\n",
      "Epoch 18111 - Train Loss: 0.091163, Train Acc: 0.856410 | Val Loss: 0.117327, Val Acc: 0.773196\n",
      "Epoch 18112 - Train Loss: 0.091161, Train Acc: 0.856410 | Val Loss: 0.117325, Val Acc: 0.773196\n",
      "Epoch 18113 - Train Loss: 0.091158, Train Acc: 0.856410 | Val Loss: 0.117324, Val Acc: 0.773196\n",
      "Epoch 18114 - Train Loss: 0.091155, Train Acc: 0.856410 | Val Loss: 0.117322, Val Acc: 0.773196\n",
      "Epoch 18115 - Train Loss: 0.091153, Train Acc: 0.856410 | Val Loss: 0.117321, Val Acc: 0.773196\n",
      "Epoch 18116 - Train Loss: 0.091150, Train Acc: 0.856410 | Val Loss: 0.117320, Val Acc: 0.773196\n",
      "Epoch 18117 - Train Loss: 0.091147, Train Acc: 0.856410 | Val Loss: 0.117318, Val Acc: 0.773196\n",
      "Epoch 18118 - Train Loss: 0.091145, Train Acc: 0.856410 | Val Loss: 0.117317, Val Acc: 0.773196\n",
      "Epoch 18119 - Train Loss: 0.091142, Train Acc: 0.856410 | Val Loss: 0.117315, Val Acc: 0.773196\n",
      "Epoch 18120 - Train Loss: 0.091139, Train Acc: 0.856410 | Val Loss: 0.117314, Val Acc: 0.773196\n",
      "Epoch 18121 - Train Loss: 0.091137, Train Acc: 0.856410 | Val Loss: 0.117312, Val Acc: 0.773196\n",
      "Epoch 18122 - Train Loss: 0.091134, Train Acc: 0.856410 | Val Loss: 0.117311, Val Acc: 0.773196\n",
      "Epoch 18123 - Train Loss: 0.091131, Train Acc: 0.856410 | Val Loss: 0.117310, Val Acc: 0.773196\n",
      "Epoch 18124 - Train Loss: 0.091129, Train Acc: 0.856410 | Val Loss: 0.117308, Val Acc: 0.773196\n",
      "Epoch 18125 - Train Loss: 0.091126, Train Acc: 0.856410 | Val Loss: 0.117307, Val Acc: 0.773196\n",
      "Epoch 18126 - Train Loss: 0.091124, Train Acc: 0.856410 | Val Loss: 0.117305, Val Acc: 0.773196\n",
      "Epoch 18127 - Train Loss: 0.091121, Train Acc: 0.856410 | Val Loss: 0.117304, Val Acc: 0.773196\n",
      "Epoch 18128 - Train Loss: 0.091118, Train Acc: 0.856410 | Val Loss: 0.117302, Val Acc: 0.773196\n",
      "Epoch 18129 - Train Loss: 0.091116, Train Acc: 0.856410 | Val Loss: 0.117301, Val Acc: 0.773196\n",
      "Epoch 18130 - Train Loss: 0.091113, Train Acc: 0.856410 | Val Loss: 0.117300, Val Acc: 0.773196\n",
      "Epoch 18131 - Train Loss: 0.091110, Train Acc: 0.856410 | Val Loss: 0.117298, Val Acc: 0.773196\n",
      "Epoch 18132 - Train Loss: 0.091108, Train Acc: 0.856410 | Val Loss: 0.117297, Val Acc: 0.773196\n",
      "Epoch 18133 - Train Loss: 0.091105, Train Acc: 0.856410 | Val Loss: 0.117295, Val Acc: 0.773196\n",
      "Epoch 18134 - Train Loss: 0.091102, Train Acc: 0.856410 | Val Loss: 0.117294, Val Acc: 0.773196\n",
      "Epoch 18135 - Train Loss: 0.091100, Train Acc: 0.856410 | Val Loss: 0.117292, Val Acc: 0.773196\n",
      "Epoch 18136 - Train Loss: 0.091097, Train Acc: 0.856410 | Val Loss: 0.117291, Val Acc: 0.773196\n",
      "Epoch 18137 - Train Loss: 0.091094, Train Acc: 0.856410 | Val Loss: 0.117290, Val Acc: 0.773196\n",
      "Epoch 18138 - Train Loss: 0.091092, Train Acc: 0.856410 | Val Loss: 0.117288, Val Acc: 0.773196\n",
      "Epoch 18139 - Train Loss: 0.091089, Train Acc: 0.856410 | Val Loss: 0.117287, Val Acc: 0.773196\n",
      "Epoch 18140 - Train Loss: 0.091086, Train Acc: 0.856410 | Val Loss: 0.117285, Val Acc: 0.773196\n",
      "Epoch 18141 - Train Loss: 0.091084, Train Acc: 0.856410 | Val Loss: 0.117284, Val Acc: 0.773196\n",
      "Epoch 18142 - Train Loss: 0.091081, Train Acc: 0.856410 | Val Loss: 0.117283, Val Acc: 0.773196\n",
      "Epoch 18143 - Train Loss: 0.091078, Train Acc: 0.856410 | Val Loss: 0.117281, Val Acc: 0.773196\n",
      "Epoch 18144 - Train Loss: 0.091076, Train Acc: 0.856410 | Val Loss: 0.117280, Val Acc: 0.773196\n",
      "Epoch 18145 - Train Loss: 0.091073, Train Acc: 0.856410 | Val Loss: 0.117278, Val Acc: 0.773196\n",
      "Epoch 18146 - Train Loss: 0.091070, Train Acc: 0.856410 | Val Loss: 0.117277, Val Acc: 0.773196\n",
      "Epoch 18147 - Train Loss: 0.091068, Train Acc: 0.856410 | Val Loss: 0.117275, Val Acc: 0.773196\n",
      "Epoch 18148 - Train Loss: 0.091065, Train Acc: 0.856410 | Val Loss: 0.117274, Val Acc: 0.773196\n",
      "Epoch 18149 - Train Loss: 0.091062, Train Acc: 0.856410 | Val Loss: 0.117273, Val Acc: 0.773196\n",
      "Epoch 18150 - Train Loss: 0.091060, Train Acc: 0.856410 | Val Loss: 0.117271, Val Acc: 0.773196\n",
      "Epoch 18151 - Train Loss: 0.091057, Train Acc: 0.856410 | Val Loss: 0.117270, Val Acc: 0.773196\n",
      "Epoch 18152 - Train Loss: 0.091054, Train Acc: 0.856410 | Val Loss: 0.117268, Val Acc: 0.773196\n",
      "Epoch 18153 - Train Loss: 0.091052, Train Acc: 0.856410 | Val Loss: 0.117267, Val Acc: 0.773196\n",
      "Epoch 18154 - Train Loss: 0.091049, Train Acc: 0.856410 | Val Loss: 0.117265, Val Acc: 0.773196\n",
      "Epoch 18155 - Train Loss: 0.091047, Train Acc: 0.856410 | Val Loss: 0.117264, Val Acc: 0.773196\n",
      "Epoch 18156 - Train Loss: 0.091044, Train Acc: 0.856410 | Val Loss: 0.117263, Val Acc: 0.773196\n",
      "Epoch 18157 - Train Loss: 0.091041, Train Acc: 0.856410 | Val Loss: 0.117261, Val Acc: 0.773196\n",
      "Epoch 18158 - Train Loss: 0.091039, Train Acc: 0.856410 | Val Loss: 0.117260, Val Acc: 0.773196\n",
      "Epoch 18159 - Train Loss: 0.091036, Train Acc: 0.856410 | Val Loss: 0.117258, Val Acc: 0.773196\n",
      "Epoch 18160 - Train Loss: 0.091033, Train Acc: 0.856410 | Val Loss: 0.117257, Val Acc: 0.773196\n",
      "Epoch 18161 - Train Loss: 0.091031, Train Acc: 0.857692 | Val Loss: 0.117256, Val Acc: 0.773196\n",
      "Epoch 18162 - Train Loss: 0.091028, Train Acc: 0.857692 | Val Loss: 0.117254, Val Acc: 0.773196\n",
      "Epoch 18163 - Train Loss: 0.091025, Train Acc: 0.857692 | Val Loss: 0.117253, Val Acc: 0.773196\n",
      "Epoch 18164 - Train Loss: 0.091023, Train Acc: 0.857692 | Val Loss: 0.117251, Val Acc: 0.773196\n",
      "Epoch 18165 - Train Loss: 0.091020, Train Acc: 0.857692 | Val Loss: 0.117250, Val Acc: 0.773196\n",
      "Epoch 18166 - Train Loss: 0.091017, Train Acc: 0.857692 | Val Loss: 0.117248, Val Acc: 0.773196\n",
      "Epoch 18167 - Train Loss: 0.091015, Train Acc: 0.857692 | Val Loss: 0.117247, Val Acc: 0.773196\n",
      "Epoch 18168 - Train Loss: 0.091012, Train Acc: 0.857692 | Val Loss: 0.117246, Val Acc: 0.773196\n",
      "Epoch 18169 - Train Loss: 0.091009, Train Acc: 0.857692 | Val Loss: 0.117244, Val Acc: 0.773196\n",
      "Epoch 18170 - Train Loss: 0.091007, Train Acc: 0.857692 | Val Loss: 0.117243, Val Acc: 0.773196\n",
      "Epoch 18171 - Train Loss: 0.091004, Train Acc: 0.857692 | Val Loss: 0.117241, Val Acc: 0.773196\n",
      "Epoch 18172 - Train Loss: 0.091001, Train Acc: 0.857692 | Val Loss: 0.117240, Val Acc: 0.773196\n",
      "Epoch 18173 - Train Loss: 0.090999, Train Acc: 0.857692 | Val Loss: 0.117239, Val Acc: 0.773196\n",
      "Epoch 18174 - Train Loss: 0.090996, Train Acc: 0.857692 | Val Loss: 0.117237, Val Acc: 0.773196\n",
      "Epoch 18175 - Train Loss: 0.090994, Train Acc: 0.857692 | Val Loss: 0.117236, Val Acc: 0.773196\n",
      "Epoch 18176 - Train Loss: 0.090991, Train Acc: 0.857692 | Val Loss: 0.117234, Val Acc: 0.773196\n",
      "Epoch 18177 - Train Loss: 0.090988, Train Acc: 0.857692 | Val Loss: 0.117233, Val Acc: 0.773196\n",
      "Epoch 18178 - Train Loss: 0.090986, Train Acc: 0.857692 | Val Loss: 0.117231, Val Acc: 0.773196\n",
      "Epoch 18179 - Train Loss: 0.090983, Train Acc: 0.857692 | Val Loss: 0.117230, Val Acc: 0.773196\n",
      "Epoch 18180 - Train Loss: 0.090980, Train Acc: 0.857692 | Val Loss: 0.117229, Val Acc: 0.773196\n",
      "Epoch 18181 - Train Loss: 0.090978, Train Acc: 0.857692 | Val Loss: 0.117227, Val Acc: 0.773196\n",
      "Epoch 18182 - Train Loss: 0.090975, Train Acc: 0.857692 | Val Loss: 0.117226, Val Acc: 0.773196\n",
      "Epoch 18183 - Train Loss: 0.090972, Train Acc: 0.857692 | Val Loss: 0.117224, Val Acc: 0.773196\n",
      "Epoch 18184 - Train Loss: 0.090970, Train Acc: 0.857692 | Val Loss: 0.117223, Val Acc: 0.773196\n",
      "Epoch 18185 - Train Loss: 0.090967, Train Acc: 0.857692 | Val Loss: 0.117222, Val Acc: 0.773196\n",
      "Epoch 18186 - Train Loss: 0.090964, Train Acc: 0.857692 | Val Loss: 0.117220, Val Acc: 0.773196\n",
      "Epoch 18187 - Train Loss: 0.090962, Train Acc: 0.857692 | Val Loss: 0.117219, Val Acc: 0.773196\n",
      "Epoch 18188 - Train Loss: 0.090959, Train Acc: 0.857692 | Val Loss: 0.117217, Val Acc: 0.773196\n",
      "Epoch 18189 - Train Loss: 0.090957, Train Acc: 0.857692 | Val Loss: 0.117216, Val Acc: 0.773196\n",
      "Epoch 18190 - Train Loss: 0.090954, Train Acc: 0.857692 | Val Loss: 0.117215, Val Acc: 0.773196\n",
      "Epoch 18191 - Train Loss: 0.090951, Train Acc: 0.857692 | Val Loss: 0.117213, Val Acc: 0.773196\n",
      "Epoch 18192 - Train Loss: 0.090949, Train Acc: 0.857692 | Val Loss: 0.117212, Val Acc: 0.773196\n",
      "Epoch 18193 - Train Loss: 0.090946, Train Acc: 0.857692 | Val Loss: 0.117210, Val Acc: 0.773196\n",
      "Epoch 18194 - Train Loss: 0.090943, Train Acc: 0.857692 | Val Loss: 0.117209, Val Acc: 0.773196\n",
      "Epoch 18195 - Train Loss: 0.090941, Train Acc: 0.857692 | Val Loss: 0.117207, Val Acc: 0.773196\n",
      "Epoch 18196 - Train Loss: 0.090938, Train Acc: 0.857692 | Val Loss: 0.117206, Val Acc: 0.773196\n",
      "Epoch 18197 - Train Loss: 0.090935, Train Acc: 0.857692 | Val Loss: 0.117205, Val Acc: 0.773196\n",
      "Epoch 18198 - Train Loss: 0.090933, Train Acc: 0.857692 | Val Loss: 0.117203, Val Acc: 0.773196\n",
      "Epoch 18199 - Train Loss: 0.090930, Train Acc: 0.857692 | Val Loss: 0.117202, Val Acc: 0.773196\n",
      "Epoch 18200 - Train Loss: 0.090927, Train Acc: 0.857692 | Val Loss: 0.117200, Val Acc: 0.773196\n",
      "Epoch 18201 - Train Loss: 0.090925, Train Acc: 0.857692 | Val Loss: 0.117199, Val Acc: 0.773196\n",
      "Epoch 18202 - Train Loss: 0.090922, Train Acc: 0.857692 | Val Loss: 0.117198, Val Acc: 0.773196\n",
      "Epoch 18203 - Train Loss: 0.090920, Train Acc: 0.857692 | Val Loss: 0.117196, Val Acc: 0.773196\n",
      "Epoch 18204 - Train Loss: 0.090917, Train Acc: 0.857692 | Val Loss: 0.117195, Val Acc: 0.773196\n",
      "Epoch 18205 - Train Loss: 0.090914, Train Acc: 0.857692 | Val Loss: 0.117193, Val Acc: 0.773196\n",
      "Epoch 18206 - Train Loss: 0.090912, Train Acc: 0.857692 | Val Loss: 0.117192, Val Acc: 0.773196\n",
      "Epoch 18207 - Train Loss: 0.090909, Train Acc: 0.857692 | Val Loss: 0.117191, Val Acc: 0.773196\n",
      "Epoch 18208 - Train Loss: 0.090906, Train Acc: 0.857692 | Val Loss: 0.117189, Val Acc: 0.773196\n",
      "Epoch 18209 - Train Loss: 0.090904, Train Acc: 0.857692 | Val Loss: 0.117188, Val Acc: 0.773196\n",
      "Epoch 18210 - Train Loss: 0.090901, Train Acc: 0.857692 | Val Loss: 0.117186, Val Acc: 0.773196\n",
      "Epoch 18211 - Train Loss: 0.090898, Train Acc: 0.857692 | Val Loss: 0.117185, Val Acc: 0.773196\n",
      "Epoch 18212 - Train Loss: 0.090896, Train Acc: 0.857692 | Val Loss: 0.117184, Val Acc: 0.773196\n",
      "Epoch 18213 - Train Loss: 0.090893, Train Acc: 0.857692 | Val Loss: 0.117182, Val Acc: 0.773196\n",
      "Epoch 18214 - Train Loss: 0.090891, Train Acc: 0.857692 | Val Loss: 0.117181, Val Acc: 0.773196\n",
      "Epoch 18215 - Train Loss: 0.090888, Train Acc: 0.857692 | Val Loss: 0.117179, Val Acc: 0.773196\n",
      "Epoch 18216 - Train Loss: 0.090885, Train Acc: 0.857692 | Val Loss: 0.117178, Val Acc: 0.773196\n",
      "Epoch 18217 - Train Loss: 0.090883, Train Acc: 0.857692 | Val Loss: 0.117177, Val Acc: 0.773196\n",
      "Epoch 18218 - Train Loss: 0.090880, Train Acc: 0.857692 | Val Loss: 0.117175, Val Acc: 0.773196\n",
      "Epoch 18219 - Train Loss: 0.090877, Train Acc: 0.857692 | Val Loss: 0.117174, Val Acc: 0.773196\n",
      "Epoch 18220 - Train Loss: 0.090875, Train Acc: 0.857692 | Val Loss: 0.117172, Val Acc: 0.773196\n",
      "Epoch 18221 - Train Loss: 0.090872, Train Acc: 0.857692 | Val Loss: 0.117171, Val Acc: 0.773196\n",
      "Epoch 18222 - Train Loss: 0.090869, Train Acc: 0.857692 | Val Loss: 0.117170, Val Acc: 0.773196\n",
      "Epoch 18223 - Train Loss: 0.090867, Train Acc: 0.857692 | Val Loss: 0.117168, Val Acc: 0.773196\n",
      "Epoch 18224 - Train Loss: 0.090864, Train Acc: 0.857692 | Val Loss: 0.117167, Val Acc: 0.773196\n",
      "Epoch 18225 - Train Loss: 0.090862, Train Acc: 0.857692 | Val Loss: 0.117165, Val Acc: 0.773196\n",
      "Epoch 18226 - Train Loss: 0.090859, Train Acc: 0.857692 | Val Loss: 0.117164, Val Acc: 0.773196\n",
      "Epoch 18227 - Train Loss: 0.090856, Train Acc: 0.857692 | Val Loss: 0.117163, Val Acc: 0.773196\n",
      "Epoch 18228 - Train Loss: 0.090854, Train Acc: 0.857692 | Val Loss: 0.117161, Val Acc: 0.773196\n",
      "Epoch 18229 - Train Loss: 0.090851, Train Acc: 0.857692 | Val Loss: 0.117160, Val Acc: 0.773196\n",
      "Epoch 18230 - Train Loss: 0.090848, Train Acc: 0.857692 | Val Loss: 0.117158, Val Acc: 0.773196\n",
      "Epoch 18231 - Train Loss: 0.090846, Train Acc: 0.857692 | Val Loss: 0.117157, Val Acc: 0.773196\n",
      "Epoch 18232 - Train Loss: 0.090843, Train Acc: 0.857692 | Val Loss: 0.117156, Val Acc: 0.773196\n",
      "Epoch 18233 - Train Loss: 0.090841, Train Acc: 0.857692 | Val Loss: 0.117154, Val Acc: 0.773196\n",
      "Epoch 18234 - Train Loss: 0.090838, Train Acc: 0.857692 | Val Loss: 0.117153, Val Acc: 0.773196\n",
      "Epoch 18235 - Train Loss: 0.090835, Train Acc: 0.857692 | Val Loss: 0.117151, Val Acc: 0.773196\n",
      "Epoch 18236 - Train Loss: 0.090833, Train Acc: 0.857692 | Val Loss: 0.117150, Val Acc: 0.773196\n",
      "Epoch 18237 - Train Loss: 0.090830, Train Acc: 0.857692 | Val Loss: 0.117149, Val Acc: 0.773196\n",
      "Epoch 18238 - Train Loss: 0.090827, Train Acc: 0.857692 | Val Loss: 0.117147, Val Acc: 0.773196\n",
      "Epoch 18239 - Train Loss: 0.090825, Train Acc: 0.857692 | Val Loss: 0.117146, Val Acc: 0.773196\n",
      "Epoch 18240 - Train Loss: 0.090822, Train Acc: 0.857692 | Val Loss: 0.117144, Val Acc: 0.773196\n",
      "Epoch 18241 - Train Loss: 0.090820, Train Acc: 0.857692 | Val Loss: 0.117143, Val Acc: 0.773196\n",
      "Epoch 18242 - Train Loss: 0.090817, Train Acc: 0.857692 | Val Loss: 0.117142, Val Acc: 0.773196\n",
      "Epoch 18243 - Train Loss: 0.090814, Train Acc: 0.857692 | Val Loss: 0.117140, Val Acc: 0.773196\n",
      "Epoch 18244 - Train Loss: 0.090812, Train Acc: 0.857692 | Val Loss: 0.117139, Val Acc: 0.773196\n",
      "Epoch 18245 - Train Loss: 0.090809, Train Acc: 0.857692 | Val Loss: 0.117137, Val Acc: 0.773196\n",
      "Epoch 18246 - Train Loss: 0.090806, Train Acc: 0.857692 | Val Loss: 0.117136, Val Acc: 0.773196\n",
      "Epoch 18247 - Train Loss: 0.090804, Train Acc: 0.857692 | Val Loss: 0.117135, Val Acc: 0.773196\n",
      "Epoch 18248 - Train Loss: 0.090801, Train Acc: 0.857692 | Val Loss: 0.117133, Val Acc: 0.773196\n",
      "Epoch 18249 - Train Loss: 0.090798, Train Acc: 0.857692 | Val Loss: 0.117132, Val Acc: 0.773196\n",
      "Epoch 18250 - Train Loss: 0.090796, Train Acc: 0.857692 | Val Loss: 0.117131, Val Acc: 0.773196\n",
      "Epoch 18251 - Train Loss: 0.090793, Train Acc: 0.857692 | Val Loss: 0.117129, Val Acc: 0.773196\n",
      "Epoch 18252 - Train Loss: 0.090791, Train Acc: 0.857692 | Val Loss: 0.117128, Val Acc: 0.773196\n",
      "Epoch 18253 - Train Loss: 0.090788, Train Acc: 0.857692 | Val Loss: 0.117126, Val Acc: 0.773196\n",
      "Epoch 18254 - Train Loss: 0.090785, Train Acc: 0.857692 | Val Loss: 0.117125, Val Acc: 0.773196\n",
      "Epoch 18255 - Train Loss: 0.090783, Train Acc: 0.857692 | Val Loss: 0.117124, Val Acc: 0.773196\n",
      "Epoch 18256 - Train Loss: 0.090780, Train Acc: 0.857692 | Val Loss: 0.117122, Val Acc: 0.773196\n",
      "Epoch 18257 - Train Loss: 0.090777, Train Acc: 0.857692 | Val Loss: 0.117121, Val Acc: 0.773196\n",
      "Epoch 18258 - Train Loss: 0.090775, Train Acc: 0.857692 | Val Loss: 0.117119, Val Acc: 0.773196\n",
      "Epoch 18259 - Train Loss: 0.090772, Train Acc: 0.857692 | Val Loss: 0.117118, Val Acc: 0.773196\n",
      "Epoch 18260 - Train Loss: 0.090770, Train Acc: 0.857692 | Val Loss: 0.117117, Val Acc: 0.773196\n",
      "Epoch 18261 - Train Loss: 0.090767, Train Acc: 0.857692 | Val Loss: 0.117115, Val Acc: 0.773196\n",
      "Epoch 18262 - Train Loss: 0.090764, Train Acc: 0.857692 | Val Loss: 0.117114, Val Acc: 0.773196\n",
      "Epoch 18263 - Train Loss: 0.090762, Train Acc: 0.857692 | Val Loss: 0.117112, Val Acc: 0.773196\n",
      "Epoch 18264 - Train Loss: 0.090759, Train Acc: 0.857692 | Val Loss: 0.117111, Val Acc: 0.773196\n",
      "Epoch 18265 - Train Loss: 0.090757, Train Acc: 0.857692 | Val Loss: 0.117110, Val Acc: 0.773196\n",
      "Epoch 18266 - Train Loss: 0.090754, Train Acc: 0.857692 | Val Loss: 0.117108, Val Acc: 0.773196\n",
      "Epoch 18267 - Train Loss: 0.090751, Train Acc: 0.857692 | Val Loss: 0.117107, Val Acc: 0.773196\n",
      "Epoch 18268 - Train Loss: 0.090749, Train Acc: 0.857692 | Val Loss: 0.117105, Val Acc: 0.773196\n",
      "Epoch 18269 - Train Loss: 0.090746, Train Acc: 0.857692 | Val Loss: 0.117104, Val Acc: 0.773196\n",
      "Epoch 18270 - Train Loss: 0.090743, Train Acc: 0.857692 | Val Loss: 0.117103, Val Acc: 0.773196\n",
      "Epoch 18271 - Train Loss: 0.090741, Train Acc: 0.857692 | Val Loss: 0.117101, Val Acc: 0.773196\n",
      "Epoch 18272 - Train Loss: 0.090738, Train Acc: 0.857692 | Val Loss: 0.117100, Val Acc: 0.773196\n",
      "Epoch 18273 - Train Loss: 0.090736, Train Acc: 0.857692 | Val Loss: 0.117098, Val Acc: 0.773196\n",
      "Epoch 18274 - Train Loss: 0.090733, Train Acc: 0.857692 | Val Loss: 0.117097, Val Acc: 0.773196\n",
      "Epoch 18275 - Train Loss: 0.090730, Train Acc: 0.857692 | Val Loss: 0.117096, Val Acc: 0.773196\n",
      "Epoch 18276 - Train Loss: 0.090728, Train Acc: 0.857692 | Val Loss: 0.117094, Val Acc: 0.773196\n",
      "Epoch 18277 - Train Loss: 0.090725, Train Acc: 0.857692 | Val Loss: 0.117093, Val Acc: 0.773196\n",
      "Epoch 18278 - Train Loss: 0.090722, Train Acc: 0.857692 | Val Loss: 0.117091, Val Acc: 0.773196\n",
      "Epoch 18279 - Train Loss: 0.090720, Train Acc: 0.857692 | Val Loss: 0.117090, Val Acc: 0.773196\n",
      "Epoch 18280 - Train Loss: 0.090717, Train Acc: 0.857692 | Val Loss: 0.117089, Val Acc: 0.773196\n",
      "Epoch 18281 - Train Loss: 0.090715, Train Acc: 0.857692 | Val Loss: 0.117087, Val Acc: 0.773196\n",
      "Epoch 18282 - Train Loss: 0.090712, Train Acc: 0.857692 | Val Loss: 0.117086, Val Acc: 0.773196\n",
      "Epoch 18283 - Train Loss: 0.090709, Train Acc: 0.857692 | Val Loss: 0.117085, Val Acc: 0.773196\n",
      "Epoch 18284 - Train Loss: 0.090707, Train Acc: 0.857692 | Val Loss: 0.117083, Val Acc: 0.773196\n",
      "Epoch 18285 - Train Loss: 0.090704, Train Acc: 0.857692 | Val Loss: 0.117082, Val Acc: 0.773196\n",
      "Epoch 18286 - Train Loss: 0.090702, Train Acc: 0.857692 | Val Loss: 0.117080, Val Acc: 0.773196\n",
      "Epoch 18287 - Train Loss: 0.090699, Train Acc: 0.857692 | Val Loss: 0.117079, Val Acc: 0.773196\n",
      "Epoch 18288 - Train Loss: 0.090696, Train Acc: 0.857692 | Val Loss: 0.117078, Val Acc: 0.773196\n",
      "Epoch 18289 - Train Loss: 0.090694, Train Acc: 0.857692 | Val Loss: 0.117076, Val Acc: 0.773196\n",
      "Epoch 18290 - Train Loss: 0.090691, Train Acc: 0.857692 | Val Loss: 0.117075, Val Acc: 0.773196\n",
      "Epoch 18291 - Train Loss: 0.090688, Train Acc: 0.857692 | Val Loss: 0.117073, Val Acc: 0.773196\n",
      "Epoch 18292 - Train Loss: 0.090686, Train Acc: 0.857692 | Val Loss: 0.117072, Val Acc: 0.773196\n",
      "Epoch 18293 - Train Loss: 0.090683, Train Acc: 0.857692 | Val Loss: 0.117071, Val Acc: 0.773196\n",
      "Epoch 18294 - Train Loss: 0.090681, Train Acc: 0.857692 | Val Loss: 0.117069, Val Acc: 0.773196\n",
      "Epoch 18295 - Train Loss: 0.090678, Train Acc: 0.857692 | Val Loss: 0.117068, Val Acc: 0.773196\n",
      "Epoch 18296 - Train Loss: 0.090675, Train Acc: 0.857692 | Val Loss: 0.117066, Val Acc: 0.773196\n",
      "Epoch 18297 - Train Loss: 0.090673, Train Acc: 0.857692 | Val Loss: 0.117065, Val Acc: 0.773196\n",
      "Epoch 18298 - Train Loss: 0.090670, Train Acc: 0.857692 | Val Loss: 0.117064, Val Acc: 0.773196\n",
      "Epoch 18299 - Train Loss: 0.090668, Train Acc: 0.857692 | Val Loss: 0.117062, Val Acc: 0.773196\n",
      "Epoch 18300 - Train Loss: 0.090665, Train Acc: 0.857692 | Val Loss: 0.117061, Val Acc: 0.773196\n",
      "Epoch 18301 - Train Loss: 0.090662, Train Acc: 0.857692 | Val Loss: 0.117060, Val Acc: 0.773196\n",
      "Epoch 18302 - Train Loss: 0.090660, Train Acc: 0.857692 | Val Loss: 0.117058, Val Acc: 0.773196\n",
      "Epoch 18303 - Train Loss: 0.090657, Train Acc: 0.857692 | Val Loss: 0.117057, Val Acc: 0.773196\n",
      "Epoch 18304 - Train Loss: 0.090654, Train Acc: 0.857692 | Val Loss: 0.117055, Val Acc: 0.773196\n",
      "Epoch 18305 - Train Loss: 0.090652, Train Acc: 0.857692 | Val Loss: 0.117054, Val Acc: 0.773196\n",
      "Epoch 18306 - Train Loss: 0.090649, Train Acc: 0.857692 | Val Loss: 0.117053, Val Acc: 0.773196\n",
      "Epoch 18307 - Train Loss: 0.090647, Train Acc: 0.857692 | Val Loss: 0.117051, Val Acc: 0.773196\n",
      "Epoch 18308 - Train Loss: 0.090644, Train Acc: 0.857692 | Val Loss: 0.117050, Val Acc: 0.773196\n",
      "Epoch 18309 - Train Loss: 0.090641, Train Acc: 0.857692 | Val Loss: 0.117048, Val Acc: 0.773196\n",
      "Epoch 18310 - Train Loss: 0.090639, Train Acc: 0.857692 | Val Loss: 0.117047, Val Acc: 0.773196\n",
      "Epoch 18311 - Train Loss: 0.090636, Train Acc: 0.857692 | Val Loss: 0.117046, Val Acc: 0.773196\n",
      "Epoch 18312 - Train Loss: 0.090634, Train Acc: 0.857692 | Val Loss: 0.117044, Val Acc: 0.773196\n",
      "Epoch 18313 - Train Loss: 0.090631, Train Acc: 0.857692 | Val Loss: 0.117043, Val Acc: 0.773196\n",
      "Epoch 18314 - Train Loss: 0.090628, Train Acc: 0.857692 | Val Loss: 0.117042, Val Acc: 0.773196\n",
      "Epoch 18315 - Train Loss: 0.090626, Train Acc: 0.857692 | Val Loss: 0.117040, Val Acc: 0.773196\n",
      "Epoch 18316 - Train Loss: 0.090623, Train Acc: 0.857692 | Val Loss: 0.117039, Val Acc: 0.773196\n",
      "Epoch 18317 - Train Loss: 0.090621, Train Acc: 0.857692 | Val Loss: 0.117037, Val Acc: 0.773196\n",
      "Epoch 18318 - Train Loss: 0.090618, Train Acc: 0.857692 | Val Loss: 0.117036, Val Acc: 0.773196\n",
      "Epoch 18319 - Train Loss: 0.090615, Train Acc: 0.857692 | Val Loss: 0.117035, Val Acc: 0.773196\n",
      "Epoch 18320 - Train Loss: 0.090613, Train Acc: 0.857692 | Val Loss: 0.117033, Val Acc: 0.773196\n",
      "Epoch 18321 - Train Loss: 0.090610, Train Acc: 0.857692 | Val Loss: 0.117032, Val Acc: 0.773196\n",
      "Epoch 18322 - Train Loss: 0.090607, Train Acc: 0.857692 | Val Loss: 0.117030, Val Acc: 0.773196\n",
      "Epoch 18323 - Train Loss: 0.090605, Train Acc: 0.857692 | Val Loss: 0.117029, Val Acc: 0.773196\n",
      "Epoch 18324 - Train Loss: 0.090602, Train Acc: 0.857692 | Val Loss: 0.117028, Val Acc: 0.773196\n",
      "Epoch 18325 - Train Loss: 0.090600, Train Acc: 0.857692 | Val Loss: 0.117026, Val Acc: 0.773196\n",
      "Epoch 18326 - Train Loss: 0.090597, Train Acc: 0.857692 | Val Loss: 0.117025, Val Acc: 0.773196\n",
      "Epoch 18327 - Train Loss: 0.090594, Train Acc: 0.857692 | Val Loss: 0.117024, Val Acc: 0.773196\n",
      "Epoch 18328 - Train Loss: 0.090592, Train Acc: 0.857692 | Val Loss: 0.117022, Val Acc: 0.773196\n",
      "Epoch 18329 - Train Loss: 0.090589, Train Acc: 0.857692 | Val Loss: 0.117021, Val Acc: 0.773196\n",
      "Epoch 18330 - Train Loss: 0.090587, Train Acc: 0.857692 | Val Loss: 0.117019, Val Acc: 0.773196\n",
      "Epoch 18331 - Train Loss: 0.090584, Train Acc: 0.857692 | Val Loss: 0.117018, Val Acc: 0.773196\n",
      "Epoch 18332 - Train Loss: 0.090581, Train Acc: 0.857692 | Val Loss: 0.117017, Val Acc: 0.773196\n",
      "Epoch 18333 - Train Loss: 0.090579, Train Acc: 0.857692 | Val Loss: 0.117015, Val Acc: 0.773196\n",
      "Epoch 18334 - Train Loss: 0.090576, Train Acc: 0.857692 | Val Loss: 0.117014, Val Acc: 0.773196\n",
      "Epoch 18335 - Train Loss: 0.090574, Train Acc: 0.857692 | Val Loss: 0.117012, Val Acc: 0.773196\n",
      "Epoch 18336 - Train Loss: 0.090571, Train Acc: 0.857692 | Val Loss: 0.117011, Val Acc: 0.773196\n",
      "Epoch 18337 - Train Loss: 0.090568, Train Acc: 0.857692 | Val Loss: 0.117010, Val Acc: 0.773196\n",
      "Epoch 18338 - Train Loss: 0.090566, Train Acc: 0.857692 | Val Loss: 0.117008, Val Acc: 0.773196\n",
      "Epoch 18339 - Train Loss: 0.090563, Train Acc: 0.857692 | Val Loss: 0.117007, Val Acc: 0.773196\n",
      "Epoch 18340 - Train Loss: 0.090561, Train Acc: 0.857692 | Val Loss: 0.117006, Val Acc: 0.773196\n",
      "Epoch 18341 - Train Loss: 0.090558, Train Acc: 0.857692 | Val Loss: 0.117004, Val Acc: 0.773196\n",
      "Epoch 18342 - Train Loss: 0.090555, Train Acc: 0.857692 | Val Loss: 0.117003, Val Acc: 0.773196\n",
      "Epoch 18343 - Train Loss: 0.090553, Train Acc: 0.857692 | Val Loss: 0.117001, Val Acc: 0.773196\n",
      "Epoch 18344 - Train Loss: 0.090550, Train Acc: 0.857692 | Val Loss: 0.117000, Val Acc: 0.773196\n",
      "Epoch 18345 - Train Loss: 0.090548, Train Acc: 0.857692 | Val Loss: 0.116999, Val Acc: 0.773196\n",
      "Epoch 18346 - Train Loss: 0.090545, Train Acc: 0.857692 | Val Loss: 0.116997, Val Acc: 0.773196\n",
      "Epoch 18347 - Train Loss: 0.090542, Train Acc: 0.857692 | Val Loss: 0.116996, Val Acc: 0.773196\n",
      "Epoch 18348 - Train Loss: 0.090540, Train Acc: 0.857692 | Val Loss: 0.116995, Val Acc: 0.773196\n",
      "Epoch 18349 - Train Loss: 0.090537, Train Acc: 0.857692 | Val Loss: 0.116993, Val Acc: 0.773196\n",
      "Epoch 18350 - Train Loss: 0.090535, Train Acc: 0.857692 | Val Loss: 0.116992, Val Acc: 0.773196\n",
      "Epoch 18351 - Train Loss: 0.090532, Train Acc: 0.857692 | Val Loss: 0.116990, Val Acc: 0.773196\n",
      "Epoch 18352 - Train Loss: 0.090529, Train Acc: 0.857692 | Val Loss: 0.116989, Val Acc: 0.773196\n",
      "Epoch 18353 - Train Loss: 0.090527, Train Acc: 0.857692 | Val Loss: 0.116988, Val Acc: 0.773196\n",
      "Epoch 18354 - Train Loss: 0.090524, Train Acc: 0.857692 | Val Loss: 0.116986, Val Acc: 0.773196\n",
      "Epoch 18355 - Train Loss: 0.090522, Train Acc: 0.857692 | Val Loss: 0.116985, Val Acc: 0.773196\n",
      "Epoch 18356 - Train Loss: 0.090519, Train Acc: 0.857692 | Val Loss: 0.116984, Val Acc: 0.773196\n",
      "Epoch 18357 - Train Loss: 0.090516, Train Acc: 0.857692 | Val Loss: 0.116982, Val Acc: 0.773196\n",
      "Epoch 18358 - Train Loss: 0.090514, Train Acc: 0.857692 | Val Loss: 0.116981, Val Acc: 0.773196\n",
      "Epoch 18359 - Train Loss: 0.090511, Train Acc: 0.857692 | Val Loss: 0.116979, Val Acc: 0.773196\n",
      "Epoch 18360 - Train Loss: 0.090509, Train Acc: 0.857692 | Val Loss: 0.116978, Val Acc: 0.773196\n",
      "Epoch 18361 - Train Loss: 0.090506, Train Acc: 0.857692 | Val Loss: 0.116977, Val Acc: 0.773196\n",
      "Epoch 18362 - Train Loss: 0.090503, Train Acc: 0.857692 | Val Loss: 0.116975, Val Acc: 0.773196\n",
      "Epoch 18363 - Train Loss: 0.090501, Train Acc: 0.857692 | Val Loss: 0.116974, Val Acc: 0.773196\n",
      "Epoch 18364 - Train Loss: 0.090498, Train Acc: 0.857692 | Val Loss: 0.116973, Val Acc: 0.773196\n",
      "Epoch 18365 - Train Loss: 0.090496, Train Acc: 0.857692 | Val Loss: 0.116971, Val Acc: 0.773196\n",
      "Epoch 18366 - Train Loss: 0.090493, Train Acc: 0.857692 | Val Loss: 0.116970, Val Acc: 0.773196\n",
      "Epoch 18367 - Train Loss: 0.090490, Train Acc: 0.857692 | Val Loss: 0.116968, Val Acc: 0.773196\n",
      "Epoch 18368 - Train Loss: 0.090488, Train Acc: 0.857692 | Val Loss: 0.116967, Val Acc: 0.773196\n",
      "Epoch 18369 - Train Loss: 0.090485, Train Acc: 0.857692 | Val Loss: 0.116966, Val Acc: 0.773196\n",
      "Epoch 18370 - Train Loss: 0.090483, Train Acc: 0.857692 | Val Loss: 0.116964, Val Acc: 0.773196\n",
      "Epoch 18371 - Train Loss: 0.090480, Train Acc: 0.857692 | Val Loss: 0.116963, Val Acc: 0.773196\n",
      "Epoch 18372 - Train Loss: 0.090477, Train Acc: 0.857692 | Val Loss: 0.116962, Val Acc: 0.773196\n",
      "Epoch 18373 - Train Loss: 0.090475, Train Acc: 0.857692 | Val Loss: 0.116960, Val Acc: 0.773196\n",
      "Epoch 18374 - Train Loss: 0.090472, Train Acc: 0.857692 | Val Loss: 0.116959, Val Acc: 0.773196\n",
      "Epoch 18375 - Train Loss: 0.090470, Train Acc: 0.857692 | Val Loss: 0.116957, Val Acc: 0.773196\n",
      "Epoch 18376 - Train Loss: 0.090467, Train Acc: 0.857692 | Val Loss: 0.116956, Val Acc: 0.773196\n",
      "Epoch 18377 - Train Loss: 0.090464, Train Acc: 0.857692 | Val Loss: 0.116955, Val Acc: 0.773196\n",
      "Epoch 18378 - Train Loss: 0.090462, Train Acc: 0.857692 | Val Loss: 0.116953, Val Acc: 0.773196\n",
      "Epoch 18379 - Train Loss: 0.090459, Train Acc: 0.857692 | Val Loss: 0.116952, Val Acc: 0.773196\n",
      "Epoch 18380 - Train Loss: 0.090457, Train Acc: 0.857692 | Val Loss: 0.116951, Val Acc: 0.773196\n",
      "Epoch 18381 - Train Loss: 0.090454, Train Acc: 0.857692 | Val Loss: 0.116949, Val Acc: 0.773196\n",
      "Epoch 18382 - Train Loss: 0.090451, Train Acc: 0.857692 | Val Loss: 0.116948, Val Acc: 0.773196\n",
      "Epoch 18383 - Train Loss: 0.090449, Train Acc: 0.857692 | Val Loss: 0.116946, Val Acc: 0.773196\n",
      "Epoch 18384 - Train Loss: 0.090446, Train Acc: 0.857692 | Val Loss: 0.116945, Val Acc: 0.773196\n",
      "Epoch 18385 - Train Loss: 0.090444, Train Acc: 0.857692 | Val Loss: 0.116944, Val Acc: 0.773196\n",
      "Epoch 18386 - Train Loss: 0.090441, Train Acc: 0.857692 | Val Loss: 0.116942, Val Acc: 0.773196\n",
      "Epoch 18387 - Train Loss: 0.090439, Train Acc: 0.857692 | Val Loss: 0.116941, Val Acc: 0.773196\n",
      "Epoch 18388 - Train Loss: 0.090436, Train Acc: 0.857692 | Val Loss: 0.116940, Val Acc: 0.773196\n",
      "Epoch 18389 - Train Loss: 0.090433, Train Acc: 0.857692 | Val Loss: 0.116938, Val Acc: 0.773196\n",
      "Epoch 18390 - Train Loss: 0.090431, Train Acc: 0.857692 | Val Loss: 0.116937, Val Acc: 0.773196\n",
      "Epoch 18391 - Train Loss: 0.090428, Train Acc: 0.857692 | Val Loss: 0.116936, Val Acc: 0.773196\n",
      "Epoch 18392 - Train Loss: 0.090426, Train Acc: 0.857692 | Val Loss: 0.116934, Val Acc: 0.773196\n",
      "Epoch 18393 - Train Loss: 0.090423, Train Acc: 0.857692 | Val Loss: 0.116933, Val Acc: 0.773196\n",
      "Epoch 18394 - Train Loss: 0.090420, Train Acc: 0.857692 | Val Loss: 0.116931, Val Acc: 0.773196\n",
      "Epoch 18395 - Train Loss: 0.090418, Train Acc: 0.857692 | Val Loss: 0.116930, Val Acc: 0.773196\n",
      "Epoch 18396 - Train Loss: 0.090415, Train Acc: 0.857692 | Val Loss: 0.116929, Val Acc: 0.773196\n",
      "Epoch 18397 - Train Loss: 0.090413, Train Acc: 0.857692 | Val Loss: 0.116927, Val Acc: 0.773196\n",
      "Epoch 18398 - Train Loss: 0.090410, Train Acc: 0.857692 | Val Loss: 0.116926, Val Acc: 0.773196\n",
      "Epoch 18399 - Train Loss: 0.090407, Train Acc: 0.857692 | Val Loss: 0.116925, Val Acc: 0.773196\n",
      "Epoch 18400 - Train Loss: 0.090405, Train Acc: 0.857692 | Val Loss: 0.116923, Val Acc: 0.773196\n",
      "Epoch 18401 - Train Loss: 0.090402, Train Acc: 0.857692 | Val Loss: 0.116922, Val Acc: 0.773196\n",
      "Epoch 18402 - Train Loss: 0.090400, Train Acc: 0.857692 | Val Loss: 0.116921, Val Acc: 0.773196\n",
      "Epoch 18403 - Train Loss: 0.090397, Train Acc: 0.857692 | Val Loss: 0.116919, Val Acc: 0.773196\n",
      "Epoch 18404 - Train Loss: 0.090395, Train Acc: 0.857692 | Val Loss: 0.116918, Val Acc: 0.773196\n",
      "Epoch 18405 - Train Loss: 0.090392, Train Acc: 0.857692 | Val Loss: 0.116917, Val Acc: 0.773196\n",
      "Epoch 18406 - Train Loss: 0.090389, Train Acc: 0.857692 | Val Loss: 0.116915, Val Acc: 0.773196\n",
      "Epoch 18407 - Train Loss: 0.090387, Train Acc: 0.857692 | Val Loss: 0.116914, Val Acc: 0.773196\n",
      "Epoch 18408 - Train Loss: 0.090384, Train Acc: 0.857692 | Val Loss: 0.116912, Val Acc: 0.773196\n",
      "Epoch 18409 - Train Loss: 0.090382, Train Acc: 0.857692 | Val Loss: 0.116911, Val Acc: 0.773196\n",
      "Epoch 18410 - Train Loss: 0.090379, Train Acc: 0.857692 | Val Loss: 0.116910, Val Acc: 0.773196\n",
      "Epoch 18411 - Train Loss: 0.090376, Train Acc: 0.857692 | Val Loss: 0.116908, Val Acc: 0.773196\n",
      "Epoch 18412 - Train Loss: 0.090374, Train Acc: 0.857692 | Val Loss: 0.116907, Val Acc: 0.773196\n",
      "Epoch 18413 - Train Loss: 0.090371, Train Acc: 0.857692 | Val Loss: 0.116906, Val Acc: 0.773196\n",
      "Epoch 18414 - Train Loss: 0.090369, Train Acc: 0.857692 | Val Loss: 0.116904, Val Acc: 0.773196\n",
      "Epoch 18415 - Train Loss: 0.090366, Train Acc: 0.857692 | Val Loss: 0.116903, Val Acc: 0.773196\n",
      "Epoch 18416 - Train Loss: 0.090363, Train Acc: 0.857692 | Val Loss: 0.116902, Val Acc: 0.773196\n",
      "Epoch 18417 - Train Loss: 0.090361, Train Acc: 0.857692 | Val Loss: 0.116900, Val Acc: 0.773196\n",
      "Epoch 18418 - Train Loss: 0.090358, Train Acc: 0.857692 | Val Loss: 0.116899, Val Acc: 0.773196\n",
      "Epoch 18419 - Train Loss: 0.090356, Train Acc: 0.857692 | Val Loss: 0.116898, Val Acc: 0.773196\n",
      "Epoch 18420 - Train Loss: 0.090353, Train Acc: 0.857692 | Val Loss: 0.116896, Val Acc: 0.773196\n",
      "Epoch 18421 - Train Loss: 0.090351, Train Acc: 0.857692 | Val Loss: 0.116895, Val Acc: 0.773196\n",
      "Epoch 18422 - Train Loss: 0.090348, Train Acc: 0.857692 | Val Loss: 0.116893, Val Acc: 0.773196\n",
      "Epoch 18423 - Train Loss: 0.090345, Train Acc: 0.857692 | Val Loss: 0.116892, Val Acc: 0.773196\n",
      "Epoch 18424 - Train Loss: 0.090343, Train Acc: 0.857692 | Val Loss: 0.116891, Val Acc: 0.773196\n",
      "Epoch 18425 - Train Loss: 0.090340, Train Acc: 0.857692 | Val Loss: 0.116889, Val Acc: 0.773196\n",
      "Epoch 18426 - Train Loss: 0.090338, Train Acc: 0.857692 | Val Loss: 0.116888, Val Acc: 0.773196\n",
      "Epoch 18427 - Train Loss: 0.090335, Train Acc: 0.857692 | Val Loss: 0.116887, Val Acc: 0.773196\n",
      "Epoch 18428 - Train Loss: 0.090332, Train Acc: 0.857692 | Val Loss: 0.116885, Val Acc: 0.773196\n",
      "Epoch 18429 - Train Loss: 0.090330, Train Acc: 0.857692 | Val Loss: 0.116884, Val Acc: 0.773196\n",
      "Epoch 18430 - Train Loss: 0.090327, Train Acc: 0.857692 | Val Loss: 0.116883, Val Acc: 0.773196\n",
      "Epoch 18431 - Train Loss: 0.090325, Train Acc: 0.857692 | Val Loss: 0.116881, Val Acc: 0.773196\n",
      "Epoch 18432 - Train Loss: 0.090322, Train Acc: 0.857692 | Val Loss: 0.116880, Val Acc: 0.773196\n",
      "Epoch 18433 - Train Loss: 0.090320, Train Acc: 0.857692 | Val Loss: 0.116878, Val Acc: 0.773196\n",
      "Epoch 18434 - Train Loss: 0.090317, Train Acc: 0.857692 | Val Loss: 0.116877, Val Acc: 0.773196\n",
      "Epoch 18435 - Train Loss: 0.090314, Train Acc: 0.857692 | Val Loss: 0.116876, Val Acc: 0.773196\n",
      "Epoch 18436 - Train Loss: 0.090312, Train Acc: 0.857692 | Val Loss: 0.116874, Val Acc: 0.773196\n",
      "Epoch 18437 - Train Loss: 0.090309, Train Acc: 0.857692 | Val Loss: 0.116873, Val Acc: 0.773196\n",
      "Epoch 18438 - Train Loss: 0.090307, Train Acc: 0.857692 | Val Loss: 0.116872, Val Acc: 0.773196\n",
      "Epoch 18439 - Train Loss: 0.090304, Train Acc: 0.857692 | Val Loss: 0.116870, Val Acc: 0.773196\n",
      "Epoch 18440 - Train Loss: 0.090302, Train Acc: 0.857692 | Val Loss: 0.116869, Val Acc: 0.773196\n",
      "Epoch 18441 - Train Loss: 0.090299, Train Acc: 0.857692 | Val Loss: 0.116868, Val Acc: 0.773196\n",
      "Epoch 18442 - Train Loss: 0.090296, Train Acc: 0.857692 | Val Loss: 0.116866, Val Acc: 0.773196\n",
      "Epoch 18443 - Train Loss: 0.090294, Train Acc: 0.857692 | Val Loss: 0.116865, Val Acc: 0.773196\n",
      "Epoch 18444 - Train Loss: 0.090291, Train Acc: 0.857692 | Val Loss: 0.116864, Val Acc: 0.773196\n",
      "Epoch 18445 - Train Loss: 0.090289, Train Acc: 0.857692 | Val Loss: 0.116862, Val Acc: 0.773196\n",
      "Epoch 18446 - Train Loss: 0.090286, Train Acc: 0.857692 | Val Loss: 0.116861, Val Acc: 0.773196\n",
      "Epoch 18447 - Train Loss: 0.090284, Train Acc: 0.857692 | Val Loss: 0.116859, Val Acc: 0.773196\n",
      "Epoch 18448 - Train Loss: 0.090281, Train Acc: 0.857692 | Val Loss: 0.116858, Val Acc: 0.773196\n",
      "Epoch 18449 - Train Loss: 0.090278, Train Acc: 0.857692 | Val Loss: 0.116857, Val Acc: 0.773196\n",
      "Epoch 18450 - Train Loss: 0.090276, Train Acc: 0.857692 | Val Loss: 0.116855, Val Acc: 0.773196\n",
      "Epoch 18451 - Train Loss: 0.090273, Train Acc: 0.857692 | Val Loss: 0.116854, Val Acc: 0.773196\n",
      "Epoch 18452 - Train Loss: 0.090271, Train Acc: 0.857692 | Val Loss: 0.116853, Val Acc: 0.773196\n",
      "Epoch 18453 - Train Loss: 0.090268, Train Acc: 0.857692 | Val Loss: 0.116851, Val Acc: 0.773196\n",
      "Epoch 18454 - Train Loss: 0.090265, Train Acc: 0.857692 | Val Loss: 0.116850, Val Acc: 0.773196\n",
      "Epoch 18455 - Train Loss: 0.090263, Train Acc: 0.857692 | Val Loss: 0.116849, Val Acc: 0.773196\n",
      "Epoch 18456 - Train Loss: 0.090260, Train Acc: 0.857692 | Val Loss: 0.116847, Val Acc: 0.773196\n",
      "Epoch 18457 - Train Loss: 0.090258, Train Acc: 0.857692 | Val Loss: 0.116846, Val Acc: 0.773196\n",
      "Epoch 18458 - Train Loss: 0.090255, Train Acc: 0.857692 | Val Loss: 0.116845, Val Acc: 0.773196\n",
      "Epoch 18459 - Train Loss: 0.090253, Train Acc: 0.857692 | Val Loss: 0.116843, Val Acc: 0.773196\n",
      "Epoch 18460 - Train Loss: 0.090250, Train Acc: 0.857692 | Val Loss: 0.116842, Val Acc: 0.773196\n",
      "Epoch 18461 - Train Loss: 0.090247, Train Acc: 0.857692 | Val Loss: 0.116840, Val Acc: 0.773196\n",
      "Epoch 18462 - Train Loss: 0.090245, Train Acc: 0.857692 | Val Loss: 0.116839, Val Acc: 0.773196\n",
      "Epoch 18463 - Train Loss: 0.090242, Train Acc: 0.857692 | Val Loss: 0.116838, Val Acc: 0.773196\n",
      "Epoch 18464 - Train Loss: 0.090240, Train Acc: 0.857692 | Val Loss: 0.116836, Val Acc: 0.773196\n",
      "Epoch 18465 - Train Loss: 0.090237, Train Acc: 0.857692 | Val Loss: 0.116835, Val Acc: 0.773196\n",
      "Epoch 18466 - Train Loss: 0.090235, Train Acc: 0.857692 | Val Loss: 0.116834, Val Acc: 0.773196\n",
      "Epoch 18467 - Train Loss: 0.090232, Train Acc: 0.857692 | Val Loss: 0.116832, Val Acc: 0.773196\n",
      "Epoch 18468 - Train Loss: 0.090229, Train Acc: 0.857692 | Val Loss: 0.116831, Val Acc: 0.773196\n",
      "Epoch 18469 - Train Loss: 0.090227, Train Acc: 0.857692 | Val Loss: 0.116830, Val Acc: 0.773196\n",
      "Epoch 18470 - Train Loss: 0.090224, Train Acc: 0.857692 | Val Loss: 0.116828, Val Acc: 0.773196\n",
      "Epoch 18471 - Train Loss: 0.090222, Train Acc: 0.857692 | Val Loss: 0.116827, Val Acc: 0.773196\n",
      "Epoch 18472 - Train Loss: 0.090219, Train Acc: 0.857692 | Val Loss: 0.116826, Val Acc: 0.773196\n",
      "Epoch 18473 - Train Loss: 0.090217, Train Acc: 0.857692 | Val Loss: 0.116824, Val Acc: 0.773196\n",
      "Epoch 18474 - Train Loss: 0.090214, Train Acc: 0.857692 | Val Loss: 0.116823, Val Acc: 0.773196\n",
      "Epoch 18475 - Train Loss: 0.090211, Train Acc: 0.857692 | Val Loss: 0.116822, Val Acc: 0.773196\n",
      "Epoch 18476 - Train Loss: 0.090209, Train Acc: 0.857692 | Val Loss: 0.116820, Val Acc: 0.773196\n",
      "Epoch 18477 - Train Loss: 0.090206, Train Acc: 0.857692 | Val Loss: 0.116819, Val Acc: 0.773196\n",
      "Epoch 18478 - Train Loss: 0.090204, Train Acc: 0.857692 | Val Loss: 0.116818, Val Acc: 0.773196\n",
      "Epoch 18479 - Train Loss: 0.090201, Train Acc: 0.857692 | Val Loss: 0.116816, Val Acc: 0.773196\n",
      "Epoch 18480 - Train Loss: 0.090199, Train Acc: 0.857692 | Val Loss: 0.116815, Val Acc: 0.773196\n",
      "Epoch 18481 - Train Loss: 0.090196, Train Acc: 0.857692 | Val Loss: 0.116814, Val Acc: 0.773196\n",
      "Epoch 18482 - Train Loss: 0.090194, Train Acc: 0.857692 | Val Loss: 0.116813, Val Acc: 0.773196\n",
      "Epoch 18483 - Train Loss: 0.090191, Train Acc: 0.857692 | Val Loss: 0.116811, Val Acc: 0.773196\n",
      "Epoch 18484 - Train Loss: 0.090188, Train Acc: 0.857692 | Val Loss: 0.116810, Val Acc: 0.773196\n",
      "Epoch 18485 - Train Loss: 0.090186, Train Acc: 0.857692 | Val Loss: 0.116809, Val Acc: 0.773196\n",
      "Epoch 18486 - Train Loss: 0.090183, Train Acc: 0.857692 | Val Loss: 0.116808, Val Acc: 0.773196\n",
      "Epoch 18487 - Train Loss: 0.090181, Train Acc: 0.857692 | Val Loss: 0.116806, Val Acc: 0.773196\n",
      "Epoch 18488 - Train Loss: 0.090178, Train Acc: 0.857692 | Val Loss: 0.116805, Val Acc: 0.773196\n",
      "Epoch 18489 - Train Loss: 0.090176, Train Acc: 0.857692 | Val Loss: 0.116804, Val Acc: 0.773196\n",
      "Epoch 18490 - Train Loss: 0.090173, Train Acc: 0.857692 | Val Loss: 0.116803, Val Acc: 0.773196\n",
      "Epoch 18491 - Train Loss: 0.090170, Train Acc: 0.857692 | Val Loss: 0.116801, Val Acc: 0.773196\n",
      "Epoch 18492 - Train Loss: 0.090168, Train Acc: 0.857692 | Val Loss: 0.116800, Val Acc: 0.773196\n",
      "Epoch 18493 - Train Loss: 0.090165, Train Acc: 0.857692 | Val Loss: 0.116799, Val Acc: 0.773196\n",
      "Epoch 18494 - Train Loss: 0.090163, Train Acc: 0.857692 | Val Loss: 0.116797, Val Acc: 0.773196\n",
      "Epoch 18495 - Train Loss: 0.090160, Train Acc: 0.857692 | Val Loss: 0.116796, Val Acc: 0.773196\n",
      "Epoch 18496 - Train Loss: 0.090158, Train Acc: 0.857692 | Val Loss: 0.116795, Val Acc: 0.773196\n",
      "Epoch 18497 - Train Loss: 0.090155, Train Acc: 0.857692 | Val Loss: 0.116793, Val Acc: 0.773196\n",
      "Epoch 18498 - Train Loss: 0.090152, Train Acc: 0.857692 | Val Loss: 0.116792, Val Acc: 0.773196\n",
      "Epoch 18499 - Train Loss: 0.090150, Train Acc: 0.857692 | Val Loss: 0.116791, Val Acc: 0.773196\n",
      "Epoch 18500 - Train Loss: 0.090147, Train Acc: 0.857692 | Val Loss: 0.116790, Val Acc: 0.773196\n",
      "Epoch 18501 - Train Loss: 0.090145, Train Acc: 0.857692 | Val Loss: 0.116788, Val Acc: 0.773196\n",
      "Epoch 18502 - Train Loss: 0.090142, Train Acc: 0.857692 | Val Loss: 0.116787, Val Acc: 0.773196\n",
      "Epoch 18503 - Train Loss: 0.090140, Train Acc: 0.857692 | Val Loss: 0.116786, Val Acc: 0.773196\n",
      "Epoch 18504 - Train Loss: 0.090137, Train Acc: 0.857692 | Val Loss: 0.116784, Val Acc: 0.773196\n",
      "Epoch 18505 - Train Loss: 0.090135, Train Acc: 0.857692 | Val Loss: 0.116783, Val Acc: 0.773196\n",
      "Epoch 18506 - Train Loss: 0.090132, Train Acc: 0.857692 | Val Loss: 0.116782, Val Acc: 0.773196\n",
      "Epoch 18507 - Train Loss: 0.090129, Train Acc: 0.857692 | Val Loss: 0.116780, Val Acc: 0.773196\n",
      "Epoch 18508 - Train Loss: 0.090127, Train Acc: 0.857692 | Val Loss: 0.116779, Val Acc: 0.773196\n",
      "Epoch 18509 - Train Loss: 0.090124, Train Acc: 0.857692 | Val Loss: 0.116778, Val Acc: 0.773196\n",
      "Epoch 18510 - Train Loss: 0.090122, Train Acc: 0.857692 | Val Loss: 0.116776, Val Acc: 0.773196\n",
      "Epoch 18511 - Train Loss: 0.090119, Train Acc: 0.857692 | Val Loss: 0.116775, Val Acc: 0.773196\n",
      "Epoch 18512 - Train Loss: 0.090117, Train Acc: 0.857692 | Val Loss: 0.116774, Val Acc: 0.773196\n",
      "Epoch 18513 - Train Loss: 0.090114, Train Acc: 0.857692 | Val Loss: 0.116772, Val Acc: 0.773196\n",
      "Epoch 18514 - Train Loss: 0.090112, Train Acc: 0.857692 | Val Loss: 0.116771, Val Acc: 0.773196\n",
      "Epoch 18515 - Train Loss: 0.090109, Train Acc: 0.857692 | Val Loss: 0.116770, Val Acc: 0.773196\n",
      "Epoch 18516 - Train Loss: 0.090106, Train Acc: 0.857692 | Val Loss: 0.116769, Val Acc: 0.773196\n",
      "Epoch 18517 - Train Loss: 0.090104, Train Acc: 0.857692 | Val Loss: 0.116767, Val Acc: 0.773196\n",
      "Epoch 18518 - Train Loss: 0.090101, Train Acc: 0.857692 | Val Loss: 0.116766, Val Acc: 0.773196\n",
      "Epoch 18519 - Train Loss: 0.090099, Train Acc: 0.857692 | Val Loss: 0.116765, Val Acc: 0.773196\n",
      "Epoch 18520 - Train Loss: 0.090096, Train Acc: 0.857692 | Val Loss: 0.116763, Val Acc: 0.773196\n",
      "Epoch 18521 - Train Loss: 0.090094, Train Acc: 0.857692 | Val Loss: 0.116762, Val Acc: 0.773196\n",
      "Epoch 18522 - Train Loss: 0.090091, Train Acc: 0.857692 | Val Loss: 0.116761, Val Acc: 0.773196\n",
      "Epoch 18523 - Train Loss: 0.090088, Train Acc: 0.857692 | Val Loss: 0.116759, Val Acc: 0.773196\n",
      "Epoch 18524 - Train Loss: 0.090086, Train Acc: 0.857692 | Val Loss: 0.116758, Val Acc: 0.773196\n",
      "Epoch 18525 - Train Loss: 0.090083, Train Acc: 0.857692 | Val Loss: 0.116757, Val Acc: 0.773196\n",
      "Epoch 18526 - Train Loss: 0.090081, Train Acc: 0.857692 | Val Loss: 0.116755, Val Acc: 0.773196\n",
      "Epoch 18527 - Train Loss: 0.090078, Train Acc: 0.857692 | Val Loss: 0.116754, Val Acc: 0.773196\n",
      "Epoch 18528 - Train Loss: 0.090076, Train Acc: 0.857692 | Val Loss: 0.116753, Val Acc: 0.773196\n",
      "Epoch 18529 - Train Loss: 0.090073, Train Acc: 0.857692 | Val Loss: 0.116751, Val Acc: 0.773196\n",
      "Epoch 18530 - Train Loss: 0.090071, Train Acc: 0.857692 | Val Loss: 0.116750, Val Acc: 0.773196\n",
      "Epoch 18531 - Train Loss: 0.090068, Train Acc: 0.857692 | Val Loss: 0.116749, Val Acc: 0.773196\n",
      "Epoch 18532 - Train Loss: 0.090065, Train Acc: 0.857692 | Val Loss: 0.116747, Val Acc: 0.773196\n",
      "Epoch 18533 - Train Loss: 0.090063, Train Acc: 0.857692 | Val Loss: 0.116746, Val Acc: 0.773196\n",
      "Epoch 18534 - Train Loss: 0.090060, Train Acc: 0.857692 | Val Loss: 0.116745, Val Acc: 0.773196\n",
      "Epoch 18535 - Train Loss: 0.090058, Train Acc: 0.857692 | Val Loss: 0.116743, Val Acc: 0.773196\n",
      "Epoch 18536 - Train Loss: 0.090055, Train Acc: 0.857692 | Val Loss: 0.116742, Val Acc: 0.773196\n",
      "Epoch 18537 - Train Loss: 0.090053, Train Acc: 0.857692 | Val Loss: 0.116741, Val Acc: 0.773196\n",
      "Epoch 18538 - Train Loss: 0.090050, Train Acc: 0.857692 | Val Loss: 0.116739, Val Acc: 0.773196\n",
      "Epoch 18539 - Train Loss: 0.090048, Train Acc: 0.857692 | Val Loss: 0.116738, Val Acc: 0.773196\n",
      "Epoch 18540 - Train Loss: 0.090045, Train Acc: 0.857692 | Val Loss: 0.116737, Val Acc: 0.773196\n",
      "Epoch 18541 - Train Loss: 0.090043, Train Acc: 0.857692 | Val Loss: 0.116735, Val Acc: 0.773196\n",
      "Epoch 18542 - Train Loss: 0.090040, Train Acc: 0.857692 | Val Loss: 0.116734, Val Acc: 0.773196\n",
      "Epoch 18543 - Train Loss: 0.090037, Train Acc: 0.857692 | Val Loss: 0.116733, Val Acc: 0.773196\n",
      "Epoch 18544 - Train Loss: 0.090035, Train Acc: 0.857692 | Val Loss: 0.116731, Val Acc: 0.773196\n",
      "Epoch 18545 - Train Loss: 0.090032, Train Acc: 0.857692 | Val Loss: 0.116730, Val Acc: 0.773196\n",
      "Epoch 18546 - Train Loss: 0.090030, Train Acc: 0.857692 | Val Loss: 0.116729, Val Acc: 0.773196\n",
      "Epoch 18547 - Train Loss: 0.090027, Train Acc: 0.857692 | Val Loss: 0.116727, Val Acc: 0.773196\n",
      "Epoch 18548 - Train Loss: 0.090025, Train Acc: 0.857692 | Val Loss: 0.116726, Val Acc: 0.773196\n",
      "Epoch 18549 - Train Loss: 0.090022, Train Acc: 0.857692 | Val Loss: 0.116725, Val Acc: 0.773196\n",
      "Epoch 18550 - Train Loss: 0.090020, Train Acc: 0.857692 | Val Loss: 0.116723, Val Acc: 0.773196\n",
      "Epoch 18551 - Train Loss: 0.090017, Train Acc: 0.857692 | Val Loss: 0.116722, Val Acc: 0.773196\n",
      "Epoch 18552 - Train Loss: 0.090014, Train Acc: 0.857692 | Val Loss: 0.116721, Val Acc: 0.773196\n",
      "Epoch 18553 - Train Loss: 0.090012, Train Acc: 0.857692 | Val Loss: 0.116719, Val Acc: 0.773196\n",
      "Epoch 18554 - Train Loss: 0.090009, Train Acc: 0.857692 | Val Loss: 0.116718, Val Acc: 0.773196\n",
      "Epoch 18555 - Train Loss: 0.090007, Train Acc: 0.857692 | Val Loss: 0.116717, Val Acc: 0.773196\n",
      "Epoch 18556 - Train Loss: 0.090004, Train Acc: 0.857692 | Val Loss: 0.116715, Val Acc: 0.773196\n",
      "Epoch 18557 - Train Loss: 0.090002, Train Acc: 0.857692 | Val Loss: 0.116714, Val Acc: 0.773196\n",
      "Epoch 18558 - Train Loss: 0.089999, Train Acc: 0.857692 | Val Loss: 0.116713, Val Acc: 0.773196\n",
      "Epoch 18559 - Train Loss: 0.089997, Train Acc: 0.857692 | Val Loss: 0.116711, Val Acc: 0.773196\n",
      "Epoch 18560 - Train Loss: 0.089994, Train Acc: 0.857692 | Val Loss: 0.116710, Val Acc: 0.773196\n",
      "Epoch 18561 - Train Loss: 0.089992, Train Acc: 0.857692 | Val Loss: 0.116709, Val Acc: 0.773196\n",
      "Epoch 18562 - Train Loss: 0.089989, Train Acc: 0.857692 | Val Loss: 0.116708, Val Acc: 0.773196\n",
      "Epoch 18563 - Train Loss: 0.089986, Train Acc: 0.857692 | Val Loss: 0.116706, Val Acc: 0.773196\n",
      "Epoch 18564 - Train Loss: 0.089984, Train Acc: 0.857692 | Val Loss: 0.116705, Val Acc: 0.773196\n",
      "Epoch 18565 - Train Loss: 0.089981, Train Acc: 0.857692 | Val Loss: 0.116704, Val Acc: 0.773196\n",
      "Epoch 18566 - Train Loss: 0.089979, Train Acc: 0.857692 | Val Loss: 0.116702, Val Acc: 0.773196\n",
      "Epoch 18567 - Train Loss: 0.089976, Train Acc: 0.857692 | Val Loss: 0.116701, Val Acc: 0.773196\n",
      "Epoch 18568 - Train Loss: 0.089974, Train Acc: 0.857692 | Val Loss: 0.116700, Val Acc: 0.773196\n",
      "Epoch 18569 - Train Loss: 0.089971, Train Acc: 0.857692 | Val Loss: 0.116698, Val Acc: 0.773196\n",
      "Epoch 18570 - Train Loss: 0.089969, Train Acc: 0.857692 | Val Loss: 0.116697, Val Acc: 0.773196\n",
      "Epoch 18571 - Train Loss: 0.089966, Train Acc: 0.857692 | Val Loss: 0.116696, Val Acc: 0.773196\n",
      "Epoch 18572 - Train Loss: 0.089964, Train Acc: 0.857692 | Val Loss: 0.116694, Val Acc: 0.773196\n",
      "Epoch 18573 - Train Loss: 0.089961, Train Acc: 0.857692 | Val Loss: 0.116693, Val Acc: 0.773196\n",
      "Epoch 18574 - Train Loss: 0.089958, Train Acc: 0.857692 | Val Loss: 0.116692, Val Acc: 0.773196\n",
      "Epoch 18575 - Train Loss: 0.089956, Train Acc: 0.857692 | Val Loss: 0.116690, Val Acc: 0.773196\n",
      "Epoch 18576 - Train Loss: 0.089953, Train Acc: 0.857692 | Val Loss: 0.116689, Val Acc: 0.773196\n",
      "Epoch 18577 - Train Loss: 0.089951, Train Acc: 0.857692 | Val Loss: 0.116688, Val Acc: 0.773196\n",
      "Epoch 18578 - Train Loss: 0.089948, Train Acc: 0.857692 | Val Loss: 0.116686, Val Acc: 0.773196\n",
      "Epoch 18579 - Train Loss: 0.089946, Train Acc: 0.857692 | Val Loss: 0.116685, Val Acc: 0.773196\n",
      "Epoch 18580 - Train Loss: 0.089943, Train Acc: 0.857692 | Val Loss: 0.116684, Val Acc: 0.773196\n",
      "Epoch 18581 - Train Loss: 0.089941, Train Acc: 0.857692 | Val Loss: 0.116682, Val Acc: 0.773196\n",
      "Epoch 18582 - Train Loss: 0.089938, Train Acc: 0.857692 | Val Loss: 0.116681, Val Acc: 0.773196\n",
      "Epoch 18583 - Train Loss: 0.089936, Train Acc: 0.857692 | Val Loss: 0.116680, Val Acc: 0.773196\n",
      "Epoch 18584 - Train Loss: 0.089933, Train Acc: 0.857692 | Val Loss: 0.116678, Val Acc: 0.773196\n",
      "Epoch 18585 - Train Loss: 0.089930, Train Acc: 0.857692 | Val Loss: 0.116677, Val Acc: 0.773196\n",
      "Epoch 18586 - Train Loss: 0.089928, Train Acc: 0.857692 | Val Loss: 0.116676, Val Acc: 0.773196\n",
      "Epoch 18587 - Train Loss: 0.089925, Train Acc: 0.857692 | Val Loss: 0.116674, Val Acc: 0.773196\n",
      "Epoch 18588 - Train Loss: 0.089923, Train Acc: 0.857692 | Val Loss: 0.116673, Val Acc: 0.773196\n",
      "Epoch 18589 - Train Loss: 0.089920, Train Acc: 0.857692 | Val Loss: 0.116672, Val Acc: 0.773196\n",
      "Epoch 18590 - Train Loss: 0.089918, Train Acc: 0.857692 | Val Loss: 0.116670, Val Acc: 0.773196\n",
      "Epoch 18591 - Train Loss: 0.089915, Train Acc: 0.857692 | Val Loss: 0.116669, Val Acc: 0.773196\n",
      "Epoch 18592 - Train Loss: 0.089913, Train Acc: 0.857692 | Val Loss: 0.116668, Val Acc: 0.773196\n",
      "Epoch 18593 - Train Loss: 0.089910, Train Acc: 0.857692 | Val Loss: 0.116666, Val Acc: 0.773196\n",
      "Epoch 18594 - Train Loss: 0.089908, Train Acc: 0.857692 | Val Loss: 0.116665, Val Acc: 0.773196\n",
      "Epoch 18595 - Train Loss: 0.089905, Train Acc: 0.857692 | Val Loss: 0.116664, Val Acc: 0.773196\n",
      "Epoch 18596 - Train Loss: 0.089903, Train Acc: 0.857692 | Val Loss: 0.116662, Val Acc: 0.773196\n",
      "Epoch 18597 - Train Loss: 0.089900, Train Acc: 0.857692 | Val Loss: 0.116661, Val Acc: 0.773196\n",
      "Epoch 18598 - Train Loss: 0.089897, Train Acc: 0.857692 | Val Loss: 0.116660, Val Acc: 0.773196\n",
      "Epoch 18599 - Train Loss: 0.089895, Train Acc: 0.857692 | Val Loss: 0.116659, Val Acc: 0.773196\n",
      "Epoch 18600 - Train Loss: 0.089892, Train Acc: 0.857692 | Val Loss: 0.116657, Val Acc: 0.773196\n",
      "Epoch 18601 - Train Loss: 0.089890, Train Acc: 0.857692 | Val Loss: 0.116656, Val Acc: 0.773196\n",
      "Epoch 18602 - Train Loss: 0.089887, Train Acc: 0.857692 | Val Loss: 0.116655, Val Acc: 0.773196\n",
      "Epoch 18603 - Train Loss: 0.089885, Train Acc: 0.857692 | Val Loss: 0.116653, Val Acc: 0.773196\n",
      "Epoch 18604 - Train Loss: 0.089882, Train Acc: 0.857692 | Val Loss: 0.116652, Val Acc: 0.773196\n",
      "Epoch 18605 - Train Loss: 0.089880, Train Acc: 0.857692 | Val Loss: 0.116651, Val Acc: 0.773196\n",
      "Epoch 18606 - Train Loss: 0.089877, Train Acc: 0.857692 | Val Loss: 0.116649, Val Acc: 0.773196\n",
      "Epoch 18607 - Train Loss: 0.089875, Train Acc: 0.857692 | Val Loss: 0.116648, Val Acc: 0.773196\n",
      "Epoch 18608 - Train Loss: 0.089872, Train Acc: 0.857692 | Val Loss: 0.116647, Val Acc: 0.773196\n",
      "Epoch 18609 - Train Loss: 0.089870, Train Acc: 0.857692 | Val Loss: 0.116645, Val Acc: 0.773196\n",
      "Epoch 18610 - Train Loss: 0.089867, Train Acc: 0.857692 | Val Loss: 0.116644, Val Acc: 0.773196\n",
      "Epoch 18611 - Train Loss: 0.089864, Train Acc: 0.857692 | Val Loss: 0.116643, Val Acc: 0.773196\n",
      "Epoch 18612 - Train Loss: 0.089862, Train Acc: 0.857692 | Val Loss: 0.116641, Val Acc: 0.773196\n",
      "Epoch 18613 - Train Loss: 0.089859, Train Acc: 0.857692 | Val Loss: 0.116640, Val Acc: 0.773196\n",
      "Epoch 18614 - Train Loss: 0.089857, Train Acc: 0.857692 | Val Loss: 0.116639, Val Acc: 0.773196\n",
      "Epoch 18615 - Train Loss: 0.089854, Train Acc: 0.857692 | Val Loss: 0.116637, Val Acc: 0.773196\n",
      "Epoch 18616 - Train Loss: 0.089852, Train Acc: 0.857692 | Val Loss: 0.116636, Val Acc: 0.773196\n",
      "Epoch 18617 - Train Loss: 0.089849, Train Acc: 0.857692 | Val Loss: 0.116635, Val Acc: 0.773196\n",
      "Epoch 18618 - Train Loss: 0.089847, Train Acc: 0.857692 | Val Loss: 0.116633, Val Acc: 0.773196\n",
      "Epoch 18619 - Train Loss: 0.089844, Train Acc: 0.857692 | Val Loss: 0.116632, Val Acc: 0.773196\n",
      "Epoch 18620 - Train Loss: 0.089842, Train Acc: 0.857692 | Val Loss: 0.116631, Val Acc: 0.773196\n",
      "Epoch 18621 - Train Loss: 0.089839, Train Acc: 0.857692 | Val Loss: 0.116629, Val Acc: 0.773196\n",
      "Epoch 18622 - Train Loss: 0.089837, Train Acc: 0.857692 | Val Loss: 0.116628, Val Acc: 0.773196\n",
      "Epoch 18623 - Train Loss: 0.089834, Train Acc: 0.857692 | Val Loss: 0.116627, Val Acc: 0.773196\n",
      "Epoch 18624 - Train Loss: 0.089832, Train Acc: 0.857692 | Val Loss: 0.116626, Val Acc: 0.773196\n",
      "Epoch 18625 - Train Loss: 0.089829, Train Acc: 0.857692 | Val Loss: 0.116624, Val Acc: 0.773196\n",
      "Epoch 18626 - Train Loss: 0.089826, Train Acc: 0.857692 | Val Loss: 0.116623, Val Acc: 0.773196\n",
      "Epoch 18627 - Train Loss: 0.089824, Train Acc: 0.857692 | Val Loss: 0.116622, Val Acc: 0.773196\n",
      "Epoch 18628 - Train Loss: 0.089821, Train Acc: 0.857692 | Val Loss: 0.116620, Val Acc: 0.773196\n",
      "Epoch 18629 - Train Loss: 0.089819, Train Acc: 0.857692 | Val Loss: 0.116619, Val Acc: 0.773196\n",
      "Epoch 18630 - Train Loss: 0.089816, Train Acc: 0.857692 | Val Loss: 0.116618, Val Acc: 0.773196\n",
      "Epoch 18631 - Train Loss: 0.089814, Train Acc: 0.857692 | Val Loss: 0.116616, Val Acc: 0.773196\n",
      "Epoch 18632 - Train Loss: 0.089811, Train Acc: 0.857692 | Val Loss: 0.116615, Val Acc: 0.773196\n",
      "Epoch 18633 - Train Loss: 0.089809, Train Acc: 0.857692 | Val Loss: 0.116614, Val Acc: 0.773196\n",
      "Epoch 18634 - Train Loss: 0.089806, Train Acc: 0.857692 | Val Loss: 0.116612, Val Acc: 0.773196\n",
      "Epoch 18635 - Train Loss: 0.089804, Train Acc: 0.857692 | Val Loss: 0.116611, Val Acc: 0.773196\n",
      "Epoch 18636 - Train Loss: 0.089801, Train Acc: 0.857692 | Val Loss: 0.116610, Val Acc: 0.773196\n",
      "Epoch 18637 - Train Loss: 0.089799, Train Acc: 0.857692 | Val Loss: 0.116608, Val Acc: 0.773196\n",
      "Epoch 18638 - Train Loss: 0.089796, Train Acc: 0.857692 | Val Loss: 0.116607, Val Acc: 0.773196\n",
      "Epoch 18639 - Train Loss: 0.089794, Train Acc: 0.857692 | Val Loss: 0.116606, Val Acc: 0.773196\n",
      "Epoch 18640 - Train Loss: 0.089791, Train Acc: 0.857692 | Val Loss: 0.116605, Val Acc: 0.773196\n",
      "Epoch 18641 - Train Loss: 0.089789, Train Acc: 0.857692 | Val Loss: 0.116603, Val Acc: 0.773196\n",
      "Epoch 18642 - Train Loss: 0.089786, Train Acc: 0.857692 | Val Loss: 0.116602, Val Acc: 0.773196\n",
      "Epoch 18643 - Train Loss: 0.089783, Train Acc: 0.857692 | Val Loss: 0.116601, Val Acc: 0.773196\n",
      "Epoch 18644 - Train Loss: 0.089781, Train Acc: 0.857692 | Val Loss: 0.116599, Val Acc: 0.773196\n",
      "Epoch 18645 - Train Loss: 0.089778, Train Acc: 0.857692 | Val Loss: 0.116598, Val Acc: 0.773196\n",
      "Epoch 18646 - Train Loss: 0.089776, Train Acc: 0.857692 | Val Loss: 0.116597, Val Acc: 0.773196\n",
      "Epoch 18647 - Train Loss: 0.089773, Train Acc: 0.857692 | Val Loss: 0.116595, Val Acc: 0.773196\n",
      "Epoch 18648 - Train Loss: 0.089771, Train Acc: 0.857692 | Val Loss: 0.116594, Val Acc: 0.773196\n",
      "Epoch 18649 - Train Loss: 0.089768, Train Acc: 0.857692 | Val Loss: 0.116593, Val Acc: 0.773196\n",
      "Epoch 18650 - Train Loss: 0.089766, Train Acc: 0.857692 | Val Loss: 0.116591, Val Acc: 0.773196\n",
      "Epoch 18651 - Train Loss: 0.089763, Train Acc: 0.857692 | Val Loss: 0.116590, Val Acc: 0.773196\n",
      "Epoch 18652 - Train Loss: 0.089761, Train Acc: 0.857692 | Val Loss: 0.116589, Val Acc: 0.773196\n",
      "Epoch 18653 - Train Loss: 0.089758, Train Acc: 0.857692 | Val Loss: 0.116587, Val Acc: 0.773196\n",
      "Epoch 18654 - Train Loss: 0.089756, Train Acc: 0.857692 | Val Loss: 0.116586, Val Acc: 0.773196\n",
      "Epoch 18655 - Train Loss: 0.089753, Train Acc: 0.857692 | Val Loss: 0.116585, Val Acc: 0.773196\n",
      "Epoch 18656 - Train Loss: 0.089751, Train Acc: 0.857692 | Val Loss: 0.116584, Val Acc: 0.773196\n",
      "Epoch 18657 - Train Loss: 0.089748, Train Acc: 0.857692 | Val Loss: 0.116582, Val Acc: 0.773196\n",
      "Epoch 18658 - Train Loss: 0.089746, Train Acc: 0.857692 | Val Loss: 0.116581, Val Acc: 0.773196\n",
      "Epoch 18659 - Train Loss: 0.089743, Train Acc: 0.857692 | Val Loss: 0.116580, Val Acc: 0.773196\n",
      "Epoch 18660 - Train Loss: 0.089741, Train Acc: 0.857692 | Val Loss: 0.116578, Val Acc: 0.773196\n",
      "Epoch 18661 - Train Loss: 0.089738, Train Acc: 0.857692 | Val Loss: 0.116577, Val Acc: 0.773196\n",
      "Epoch 18662 - Train Loss: 0.089735, Train Acc: 0.857692 | Val Loss: 0.116576, Val Acc: 0.773196\n",
      "Epoch 18663 - Train Loss: 0.089733, Train Acc: 0.857692 | Val Loss: 0.116574, Val Acc: 0.773196\n",
      "Epoch 18664 - Train Loss: 0.089730, Train Acc: 0.857692 | Val Loss: 0.116573, Val Acc: 0.773196\n",
      "Epoch 18665 - Train Loss: 0.089728, Train Acc: 0.857692 | Val Loss: 0.116572, Val Acc: 0.773196\n",
      "Epoch 18666 - Train Loss: 0.089725, Train Acc: 0.857692 | Val Loss: 0.116570, Val Acc: 0.773196\n",
      "Epoch 18667 - Train Loss: 0.089723, Train Acc: 0.857692 | Val Loss: 0.116569, Val Acc: 0.773196\n",
      "Epoch 18668 - Train Loss: 0.089720, Train Acc: 0.857692 | Val Loss: 0.116568, Val Acc: 0.773196\n",
      "Epoch 18669 - Train Loss: 0.089718, Train Acc: 0.857692 | Val Loss: 0.116567, Val Acc: 0.773196\n",
      "Epoch 18670 - Train Loss: 0.089715, Train Acc: 0.857692 | Val Loss: 0.116565, Val Acc: 0.773196\n",
      "Epoch 18671 - Train Loss: 0.089713, Train Acc: 0.857692 | Val Loss: 0.116564, Val Acc: 0.773196\n",
      "Epoch 18672 - Train Loss: 0.089710, Train Acc: 0.857692 | Val Loss: 0.116563, Val Acc: 0.773196\n",
      "Epoch 18673 - Train Loss: 0.089708, Train Acc: 0.857692 | Val Loss: 0.116561, Val Acc: 0.773196\n",
      "Epoch 18674 - Train Loss: 0.089705, Train Acc: 0.857692 | Val Loss: 0.116560, Val Acc: 0.773196\n",
      "Epoch 18675 - Train Loss: 0.089703, Train Acc: 0.857692 | Val Loss: 0.116559, Val Acc: 0.773196\n",
      "Epoch 18676 - Train Loss: 0.089700, Train Acc: 0.857692 | Val Loss: 0.116557, Val Acc: 0.773196\n",
      "Epoch 18677 - Train Loss: 0.089698, Train Acc: 0.857692 | Val Loss: 0.116556, Val Acc: 0.773196\n",
      "Epoch 18678 - Train Loss: 0.089695, Train Acc: 0.857692 | Val Loss: 0.116555, Val Acc: 0.773196\n",
      "Epoch 18679 - Train Loss: 0.089693, Train Acc: 0.857692 | Val Loss: 0.116553, Val Acc: 0.773196\n",
      "Epoch 18680 - Train Loss: 0.089690, Train Acc: 0.857692 | Val Loss: 0.116552, Val Acc: 0.773196\n",
      "Epoch 18681 - Train Loss: 0.089688, Train Acc: 0.857692 | Val Loss: 0.116551, Val Acc: 0.773196\n",
      "Epoch 18682 - Train Loss: 0.089685, Train Acc: 0.857692 | Val Loss: 0.116550, Val Acc: 0.773196\n",
      "Epoch 18683 - Train Loss: 0.089683, Train Acc: 0.857692 | Val Loss: 0.116548, Val Acc: 0.773196\n",
      "Epoch 18684 - Train Loss: 0.089680, Train Acc: 0.857692 | Val Loss: 0.116547, Val Acc: 0.773196\n",
      "Epoch 18685 - Train Loss: 0.089678, Train Acc: 0.857692 | Val Loss: 0.116546, Val Acc: 0.773196\n",
      "Epoch 18686 - Train Loss: 0.089675, Train Acc: 0.857692 | Val Loss: 0.116544, Val Acc: 0.773196\n",
      "Epoch 18687 - Train Loss: 0.089672, Train Acc: 0.857692 | Val Loss: 0.116543, Val Acc: 0.773196\n",
      "Epoch 18688 - Train Loss: 0.089670, Train Acc: 0.857692 | Val Loss: 0.116542, Val Acc: 0.773196\n",
      "Epoch 18689 - Train Loss: 0.089667, Train Acc: 0.857692 | Val Loss: 0.116540, Val Acc: 0.773196\n",
      "Epoch 18690 - Train Loss: 0.089665, Train Acc: 0.857692 | Val Loss: 0.116539, Val Acc: 0.773196\n",
      "Epoch 18691 - Train Loss: 0.089662, Train Acc: 0.857692 | Val Loss: 0.116538, Val Acc: 0.773196\n",
      "Epoch 18692 - Train Loss: 0.089660, Train Acc: 0.857692 | Val Loss: 0.116537, Val Acc: 0.773196\n",
      "Epoch 18693 - Train Loss: 0.089657, Train Acc: 0.857692 | Val Loss: 0.116535, Val Acc: 0.773196\n",
      "Epoch 18694 - Train Loss: 0.089655, Train Acc: 0.857692 | Val Loss: 0.116534, Val Acc: 0.773196\n",
      "Epoch 18695 - Train Loss: 0.089652, Train Acc: 0.857692 | Val Loss: 0.116533, Val Acc: 0.773196\n",
      "Epoch 18696 - Train Loss: 0.089650, Train Acc: 0.857692 | Val Loss: 0.116531, Val Acc: 0.773196\n",
      "Epoch 18697 - Train Loss: 0.089647, Train Acc: 0.857692 | Val Loss: 0.116530, Val Acc: 0.773196\n",
      "Epoch 18698 - Train Loss: 0.089645, Train Acc: 0.858974 | Val Loss: 0.116529, Val Acc: 0.773196\n",
      "Epoch 18699 - Train Loss: 0.089642, Train Acc: 0.858974 | Val Loss: 0.116527, Val Acc: 0.773196\n",
      "Epoch 18700 - Train Loss: 0.089640, Train Acc: 0.858974 | Val Loss: 0.116526, Val Acc: 0.773196\n",
      "Epoch 18701 - Train Loss: 0.089637, Train Acc: 0.858974 | Val Loss: 0.116525, Val Acc: 0.773196\n",
      "Epoch 18702 - Train Loss: 0.089635, Train Acc: 0.858974 | Val Loss: 0.116523, Val Acc: 0.773196\n",
      "Epoch 18703 - Train Loss: 0.089632, Train Acc: 0.858974 | Val Loss: 0.116522, Val Acc: 0.773196\n",
      "Epoch 18704 - Train Loss: 0.089630, Train Acc: 0.858974 | Val Loss: 0.116521, Val Acc: 0.773196\n",
      "Epoch 18705 - Train Loss: 0.089627, Train Acc: 0.858974 | Val Loss: 0.116520, Val Acc: 0.773196\n",
      "Epoch 18706 - Train Loss: 0.089625, Train Acc: 0.858974 | Val Loss: 0.116518, Val Acc: 0.773196\n",
      "Epoch 18707 - Train Loss: 0.089622, Train Acc: 0.858974 | Val Loss: 0.116517, Val Acc: 0.773196\n",
      "Epoch 18708 - Train Loss: 0.089620, Train Acc: 0.858974 | Val Loss: 0.116516, Val Acc: 0.773196\n",
      "Epoch 18709 - Train Loss: 0.089617, Train Acc: 0.858974 | Val Loss: 0.116514, Val Acc: 0.773196\n",
      "Epoch 18710 - Train Loss: 0.089615, Train Acc: 0.858974 | Val Loss: 0.116513, Val Acc: 0.773196\n",
      "Epoch 18711 - Train Loss: 0.089612, Train Acc: 0.858974 | Val Loss: 0.116512, Val Acc: 0.773196\n",
      "Epoch 18712 - Train Loss: 0.089610, Train Acc: 0.858974 | Val Loss: 0.116510, Val Acc: 0.773196\n",
      "Epoch 18713 - Train Loss: 0.089607, Train Acc: 0.858974 | Val Loss: 0.116509, Val Acc: 0.773196\n",
      "Epoch 18714 - Train Loss: 0.089605, Train Acc: 0.858974 | Val Loss: 0.116508, Val Acc: 0.773196\n",
      "Epoch 18715 - Train Loss: 0.089602, Train Acc: 0.858974 | Val Loss: 0.116507, Val Acc: 0.773196\n",
      "Epoch 18716 - Train Loss: 0.089600, Train Acc: 0.858974 | Val Loss: 0.116505, Val Acc: 0.773196\n",
      "Epoch 18717 - Train Loss: 0.089597, Train Acc: 0.858974 | Val Loss: 0.116504, Val Acc: 0.773196\n",
      "Epoch 18718 - Train Loss: 0.089595, Train Acc: 0.858974 | Val Loss: 0.116503, Val Acc: 0.773196\n",
      "Epoch 18719 - Train Loss: 0.089592, Train Acc: 0.858974 | Val Loss: 0.116501, Val Acc: 0.773196\n",
      "Epoch 18720 - Train Loss: 0.089590, Train Acc: 0.860256 | Val Loss: 0.116500, Val Acc: 0.773196\n",
      "Epoch 18721 - Train Loss: 0.089587, Train Acc: 0.860256 | Val Loss: 0.116499, Val Acc: 0.773196\n",
      "Epoch 18722 - Train Loss: 0.089585, Train Acc: 0.860256 | Val Loss: 0.116498, Val Acc: 0.773196\n",
      "Epoch 18723 - Train Loss: 0.089582, Train Acc: 0.860256 | Val Loss: 0.116496, Val Acc: 0.773196\n",
      "Epoch 18724 - Train Loss: 0.089580, Train Acc: 0.860256 | Val Loss: 0.116495, Val Acc: 0.773196\n",
      "Epoch 18725 - Train Loss: 0.089577, Train Acc: 0.860256 | Val Loss: 0.116494, Val Acc: 0.773196\n",
      "Epoch 18726 - Train Loss: 0.089574, Train Acc: 0.860256 | Val Loss: 0.116492, Val Acc: 0.773196\n",
      "Epoch 18727 - Train Loss: 0.089572, Train Acc: 0.860256 | Val Loss: 0.116491, Val Acc: 0.773196\n",
      "Epoch 18728 - Train Loss: 0.089569, Train Acc: 0.860256 | Val Loss: 0.116490, Val Acc: 0.773196\n",
      "Epoch 18729 - Train Loss: 0.089567, Train Acc: 0.860256 | Val Loss: 0.116488, Val Acc: 0.773196\n",
      "Epoch 18730 - Train Loss: 0.089564, Train Acc: 0.860256 | Val Loss: 0.116487, Val Acc: 0.773196\n",
      "Epoch 18731 - Train Loss: 0.089562, Train Acc: 0.860256 | Val Loss: 0.116486, Val Acc: 0.773196\n",
      "Epoch 18732 - Train Loss: 0.089559, Train Acc: 0.860256 | Val Loss: 0.116485, Val Acc: 0.773196\n",
      "Epoch 18733 - Train Loss: 0.089557, Train Acc: 0.860256 | Val Loss: 0.116483, Val Acc: 0.773196\n",
      "Epoch 18734 - Train Loss: 0.089554, Train Acc: 0.860256 | Val Loss: 0.116482, Val Acc: 0.773196\n",
      "Epoch 18735 - Train Loss: 0.089552, Train Acc: 0.860256 | Val Loss: 0.116481, Val Acc: 0.773196\n",
      "Epoch 18736 - Train Loss: 0.089549, Train Acc: 0.860256 | Val Loss: 0.116479, Val Acc: 0.773196\n",
      "Epoch 18737 - Train Loss: 0.089547, Train Acc: 0.860256 | Val Loss: 0.116478, Val Acc: 0.773196\n",
      "Epoch 18738 - Train Loss: 0.089544, Train Acc: 0.860256 | Val Loss: 0.116477, Val Acc: 0.773196\n",
      "Epoch 18739 - Train Loss: 0.089542, Train Acc: 0.860256 | Val Loss: 0.116476, Val Acc: 0.773196\n",
      "Epoch 18740 - Train Loss: 0.089539, Train Acc: 0.860256 | Val Loss: 0.116474, Val Acc: 0.773196\n",
      "Epoch 18741 - Train Loss: 0.089537, Train Acc: 0.860256 | Val Loss: 0.116473, Val Acc: 0.773196\n",
      "Epoch 18742 - Train Loss: 0.089534, Train Acc: 0.860256 | Val Loss: 0.116472, Val Acc: 0.773196\n",
      "Epoch 18743 - Train Loss: 0.089532, Train Acc: 0.860256 | Val Loss: 0.116470, Val Acc: 0.773196\n",
      "Epoch 18744 - Train Loss: 0.089529, Train Acc: 0.860256 | Val Loss: 0.116469, Val Acc: 0.773196\n",
      "Epoch 18745 - Train Loss: 0.089527, Train Acc: 0.860256 | Val Loss: 0.116468, Val Acc: 0.773196\n",
      "Epoch 18746 - Train Loss: 0.089524, Train Acc: 0.861538 | Val Loss: 0.116466, Val Acc: 0.773196\n",
      "Epoch 18747 - Train Loss: 0.089522, Train Acc: 0.861538 | Val Loss: 0.116465, Val Acc: 0.773196\n",
      "Epoch 18748 - Train Loss: 0.089519, Train Acc: 0.861538 | Val Loss: 0.116464, Val Acc: 0.773196\n",
      "Epoch 18749 - Train Loss: 0.089517, Train Acc: 0.861538 | Val Loss: 0.116463, Val Acc: 0.773196\n",
      "Epoch 18750 - Train Loss: 0.089514, Train Acc: 0.861538 | Val Loss: 0.116461, Val Acc: 0.773196\n",
      "Epoch 18751 - Train Loss: 0.089512, Train Acc: 0.861538 | Val Loss: 0.116460, Val Acc: 0.773196\n",
      "Epoch 18752 - Train Loss: 0.089509, Train Acc: 0.861538 | Val Loss: 0.116459, Val Acc: 0.773196\n",
      "Epoch 18753 - Train Loss: 0.089507, Train Acc: 0.861538 | Val Loss: 0.116457, Val Acc: 0.773196\n",
      "Epoch 18754 - Train Loss: 0.089504, Train Acc: 0.861538 | Val Loss: 0.116456, Val Acc: 0.773196\n",
      "Epoch 18755 - Train Loss: 0.089502, Train Acc: 0.861538 | Val Loss: 0.116455, Val Acc: 0.773196\n",
      "Epoch 18756 - Train Loss: 0.089499, Train Acc: 0.861538 | Val Loss: 0.116454, Val Acc: 0.773196\n",
      "Epoch 18757 - Train Loss: 0.089497, Train Acc: 0.861538 | Val Loss: 0.116452, Val Acc: 0.773196\n",
      "Epoch 18758 - Train Loss: 0.089494, Train Acc: 0.861538 | Val Loss: 0.116451, Val Acc: 0.773196\n",
      "Epoch 18759 - Train Loss: 0.089492, Train Acc: 0.861538 | Val Loss: 0.116450, Val Acc: 0.773196\n",
      "Epoch 18760 - Train Loss: 0.089489, Train Acc: 0.861538 | Val Loss: 0.116448, Val Acc: 0.773196\n",
      "Epoch 18761 - Train Loss: 0.089487, Train Acc: 0.861538 | Val Loss: 0.116447, Val Acc: 0.773196\n",
      "Epoch 18762 - Train Loss: 0.089484, Train Acc: 0.861538 | Val Loss: 0.116446, Val Acc: 0.773196\n",
      "Epoch 18763 - Train Loss: 0.089482, Train Acc: 0.861538 | Val Loss: 0.116445, Val Acc: 0.773196\n",
      "Epoch 18764 - Train Loss: 0.089479, Train Acc: 0.861538 | Val Loss: 0.116443, Val Acc: 0.773196\n",
      "Epoch 18765 - Train Loss: 0.089477, Train Acc: 0.861538 | Val Loss: 0.116442, Val Acc: 0.773196\n",
      "Epoch 18766 - Train Loss: 0.089474, Train Acc: 0.861538 | Val Loss: 0.116441, Val Acc: 0.773196\n",
      "Epoch 18767 - Train Loss: 0.089472, Train Acc: 0.861538 | Val Loss: 0.116439, Val Acc: 0.773196\n",
      "Epoch 18768 - Train Loss: 0.089469, Train Acc: 0.861538 | Val Loss: 0.116438, Val Acc: 0.773196\n",
      "Epoch 18769 - Train Loss: 0.089467, Train Acc: 0.861538 | Val Loss: 0.116437, Val Acc: 0.773196\n",
      "Epoch 18770 - Train Loss: 0.089464, Train Acc: 0.861538 | Val Loss: 0.116436, Val Acc: 0.773196\n",
      "Epoch 18771 - Train Loss: 0.089462, Train Acc: 0.861538 | Val Loss: 0.116434, Val Acc: 0.773196\n",
      "Epoch 18772 - Train Loss: 0.089459, Train Acc: 0.861538 | Val Loss: 0.116433, Val Acc: 0.773196\n",
      "Epoch 18773 - Train Loss: 0.089457, Train Acc: 0.861538 | Val Loss: 0.116432, Val Acc: 0.773196\n",
      "Epoch 18774 - Train Loss: 0.089454, Train Acc: 0.861538 | Val Loss: 0.116430, Val Acc: 0.773196\n",
      "Epoch 18775 - Train Loss: 0.089452, Train Acc: 0.861538 | Val Loss: 0.116429, Val Acc: 0.773196\n",
      "Epoch 18776 - Train Loss: 0.089449, Train Acc: 0.861538 | Val Loss: 0.116428, Val Acc: 0.773196\n",
      "Epoch 18777 - Train Loss: 0.089447, Train Acc: 0.861538 | Val Loss: 0.116427, Val Acc: 0.773196\n",
      "Epoch 18778 - Train Loss: 0.089444, Train Acc: 0.861538 | Val Loss: 0.116425, Val Acc: 0.773196\n",
      "Epoch 18779 - Train Loss: 0.089442, Train Acc: 0.861538 | Val Loss: 0.116424, Val Acc: 0.773196\n",
      "Epoch 18780 - Train Loss: 0.089439, Train Acc: 0.861538 | Val Loss: 0.116423, Val Acc: 0.773196\n",
      "Epoch 18781 - Train Loss: 0.089437, Train Acc: 0.861538 | Val Loss: 0.116421, Val Acc: 0.773196\n",
      "Epoch 18782 - Train Loss: 0.089434, Train Acc: 0.861538 | Val Loss: 0.116420, Val Acc: 0.773196\n",
      "Epoch 18783 - Train Loss: 0.089432, Train Acc: 0.861538 | Val Loss: 0.116419, Val Acc: 0.773196\n",
      "Epoch 18784 - Train Loss: 0.089429, Train Acc: 0.861538 | Val Loss: 0.116418, Val Acc: 0.773196\n",
      "Epoch 18785 - Train Loss: 0.089427, Train Acc: 0.861538 | Val Loss: 0.116416, Val Acc: 0.773196\n",
      "Epoch 18786 - Train Loss: 0.089424, Train Acc: 0.861538 | Val Loss: 0.116415, Val Acc: 0.773196\n",
      "Epoch 18787 - Train Loss: 0.089422, Train Acc: 0.861538 | Val Loss: 0.116414, Val Acc: 0.773196\n",
      "Epoch 18788 - Train Loss: 0.089419, Train Acc: 0.861538 | Val Loss: 0.116412, Val Acc: 0.773196\n",
      "Epoch 18789 - Train Loss: 0.089417, Train Acc: 0.861538 | Val Loss: 0.116411, Val Acc: 0.773196\n",
      "Epoch 18790 - Train Loss: 0.089414, Train Acc: 0.861538 | Val Loss: 0.116410, Val Acc: 0.773196\n",
      "Epoch 18791 - Train Loss: 0.089412, Train Acc: 0.861538 | Val Loss: 0.116409, Val Acc: 0.773196\n",
      "Epoch 18792 - Train Loss: 0.089409, Train Acc: 0.861538 | Val Loss: 0.116407, Val Acc: 0.773196\n",
      "Epoch 18793 - Train Loss: 0.089407, Train Acc: 0.861538 | Val Loss: 0.116406, Val Acc: 0.773196\n",
      "Epoch 18794 - Train Loss: 0.089404, Train Acc: 0.861538 | Val Loss: 0.116405, Val Acc: 0.773196\n",
      "Epoch 18795 - Train Loss: 0.089402, Train Acc: 0.861538 | Val Loss: 0.116403, Val Acc: 0.773196\n",
      "Epoch 18796 - Train Loss: 0.089399, Train Acc: 0.861538 | Val Loss: 0.116402, Val Acc: 0.773196\n",
      "Epoch 18797 - Train Loss: 0.089397, Train Acc: 0.861538 | Val Loss: 0.116401, Val Acc: 0.773196\n",
      "Epoch 18798 - Train Loss: 0.089395, Train Acc: 0.861538 | Val Loss: 0.116400, Val Acc: 0.773196\n",
      "Epoch 18799 - Train Loss: 0.089392, Train Acc: 0.861538 | Val Loss: 0.116398, Val Acc: 0.773196\n",
      "Epoch 18800 - Train Loss: 0.089390, Train Acc: 0.861538 | Val Loss: 0.116397, Val Acc: 0.773196\n",
      "Epoch 18801 - Train Loss: 0.089387, Train Acc: 0.861538 | Val Loss: 0.116396, Val Acc: 0.773196\n",
      "Epoch 18802 - Train Loss: 0.089385, Train Acc: 0.861538 | Val Loss: 0.116395, Val Acc: 0.773196\n",
      "Epoch 18803 - Train Loss: 0.089382, Train Acc: 0.861538 | Val Loss: 0.116393, Val Acc: 0.773196\n",
      "Epoch 18804 - Train Loss: 0.089380, Train Acc: 0.861538 | Val Loss: 0.116392, Val Acc: 0.773196\n",
      "Epoch 18805 - Train Loss: 0.089377, Train Acc: 0.861538 | Val Loss: 0.116391, Val Acc: 0.773196\n",
      "Epoch 18806 - Train Loss: 0.089375, Train Acc: 0.861538 | Val Loss: 0.116389, Val Acc: 0.773196\n",
      "Epoch 18807 - Train Loss: 0.089372, Train Acc: 0.861538 | Val Loss: 0.116388, Val Acc: 0.773196\n",
      "Epoch 18808 - Train Loss: 0.089370, Train Acc: 0.861538 | Val Loss: 0.116387, Val Acc: 0.773196\n",
      "Epoch 18809 - Train Loss: 0.089367, Train Acc: 0.861538 | Val Loss: 0.116386, Val Acc: 0.773196\n",
      "Epoch 18810 - Train Loss: 0.089365, Train Acc: 0.861538 | Val Loss: 0.116384, Val Acc: 0.773196\n",
      "Epoch 18811 - Train Loss: 0.089362, Train Acc: 0.861538 | Val Loss: 0.116383, Val Acc: 0.773196\n",
      "Epoch 18812 - Train Loss: 0.089360, Train Acc: 0.861538 | Val Loss: 0.116382, Val Acc: 0.773196\n",
      "Epoch 18813 - Train Loss: 0.089357, Train Acc: 0.861538 | Val Loss: 0.116380, Val Acc: 0.773196\n",
      "Epoch 18814 - Train Loss: 0.089355, Train Acc: 0.861538 | Val Loss: 0.116379, Val Acc: 0.773196\n",
      "Epoch 18815 - Train Loss: 0.089352, Train Acc: 0.861538 | Val Loss: 0.116378, Val Acc: 0.773196\n",
      "Epoch 18816 - Train Loss: 0.089350, Train Acc: 0.861538 | Val Loss: 0.116377, Val Acc: 0.773196\n",
      "Epoch 18817 - Train Loss: 0.089347, Train Acc: 0.861538 | Val Loss: 0.116375, Val Acc: 0.773196\n",
      "Epoch 18818 - Train Loss: 0.089345, Train Acc: 0.861538 | Val Loss: 0.116374, Val Acc: 0.773196\n",
      "Epoch 18819 - Train Loss: 0.089342, Train Acc: 0.861538 | Val Loss: 0.116373, Val Acc: 0.773196\n",
      "Epoch 18820 - Train Loss: 0.089340, Train Acc: 0.861538 | Val Loss: 0.116372, Val Acc: 0.773196\n",
      "Epoch 18821 - Train Loss: 0.089337, Train Acc: 0.861538 | Val Loss: 0.116370, Val Acc: 0.773196\n",
      "Epoch 18822 - Train Loss: 0.089335, Train Acc: 0.861538 | Val Loss: 0.116369, Val Acc: 0.773196\n",
      "Epoch 18823 - Train Loss: 0.089332, Train Acc: 0.861538 | Val Loss: 0.116368, Val Acc: 0.773196\n",
      "Epoch 18824 - Train Loss: 0.089330, Train Acc: 0.861538 | Val Loss: 0.116366, Val Acc: 0.773196\n",
      "Epoch 18825 - Train Loss: 0.089327, Train Acc: 0.861538 | Val Loss: 0.116365, Val Acc: 0.773196\n",
      "Epoch 18826 - Train Loss: 0.089325, Train Acc: 0.861538 | Val Loss: 0.116364, Val Acc: 0.773196\n",
      "Epoch 18827 - Train Loss: 0.089322, Train Acc: 0.861538 | Val Loss: 0.116363, Val Acc: 0.773196\n",
      "Epoch 18828 - Train Loss: 0.089320, Train Acc: 0.861538 | Val Loss: 0.116361, Val Acc: 0.773196\n",
      "Epoch 18829 - Train Loss: 0.089317, Train Acc: 0.861538 | Val Loss: 0.116360, Val Acc: 0.773196\n",
      "Epoch 18830 - Train Loss: 0.089315, Train Acc: 0.861538 | Val Loss: 0.116359, Val Acc: 0.773196\n",
      "Epoch 18831 - Train Loss: 0.089312, Train Acc: 0.861538 | Val Loss: 0.116358, Val Acc: 0.773196\n",
      "Epoch 18832 - Train Loss: 0.089310, Train Acc: 0.861538 | Val Loss: 0.116356, Val Acc: 0.773196\n",
      "Epoch 18833 - Train Loss: 0.089307, Train Acc: 0.861538 | Val Loss: 0.116355, Val Acc: 0.773196\n",
      "Epoch 18834 - Train Loss: 0.089305, Train Acc: 0.861538 | Val Loss: 0.116354, Val Acc: 0.773196\n",
      "Epoch 18835 - Train Loss: 0.089302, Train Acc: 0.861538 | Val Loss: 0.116352, Val Acc: 0.773196\n",
      "Epoch 18836 - Train Loss: 0.089300, Train Acc: 0.861538 | Val Loss: 0.116351, Val Acc: 0.773196\n",
      "Epoch 18837 - Train Loss: 0.089298, Train Acc: 0.861538 | Val Loss: 0.116350, Val Acc: 0.773196\n",
      "Epoch 18838 - Train Loss: 0.089295, Train Acc: 0.861538 | Val Loss: 0.116349, Val Acc: 0.773196\n",
      "Epoch 18839 - Train Loss: 0.089293, Train Acc: 0.861538 | Val Loss: 0.116347, Val Acc: 0.773196\n",
      "Epoch 18840 - Train Loss: 0.089290, Train Acc: 0.861538 | Val Loss: 0.116346, Val Acc: 0.773196\n",
      "Epoch 18841 - Train Loss: 0.089288, Train Acc: 0.861538 | Val Loss: 0.116345, Val Acc: 0.773196\n",
      "Epoch 18842 - Train Loss: 0.089285, Train Acc: 0.861538 | Val Loss: 0.116344, Val Acc: 0.773196\n",
      "Epoch 18843 - Train Loss: 0.089283, Train Acc: 0.861538 | Val Loss: 0.116342, Val Acc: 0.773196\n",
      "Epoch 18844 - Train Loss: 0.089280, Train Acc: 0.861538 | Val Loss: 0.116341, Val Acc: 0.773196\n",
      "Epoch 18845 - Train Loss: 0.089278, Train Acc: 0.861538 | Val Loss: 0.116340, Val Acc: 0.773196\n",
      "Epoch 18846 - Train Loss: 0.089275, Train Acc: 0.861538 | Val Loss: 0.116338, Val Acc: 0.773196\n",
      "Epoch 18847 - Train Loss: 0.089273, Train Acc: 0.861538 | Val Loss: 0.116337, Val Acc: 0.773196\n",
      "Epoch 18848 - Train Loss: 0.089270, Train Acc: 0.861538 | Val Loss: 0.116336, Val Acc: 0.773196\n",
      "Epoch 18849 - Train Loss: 0.089268, Train Acc: 0.861538 | Val Loss: 0.116335, Val Acc: 0.773196\n",
      "Epoch 18850 - Train Loss: 0.089265, Train Acc: 0.861538 | Val Loss: 0.116333, Val Acc: 0.773196\n",
      "Epoch 18851 - Train Loss: 0.089263, Train Acc: 0.861538 | Val Loss: 0.116332, Val Acc: 0.773196\n",
      "Epoch 18852 - Train Loss: 0.089260, Train Acc: 0.861538 | Val Loss: 0.116331, Val Acc: 0.773196\n",
      "Epoch 18853 - Train Loss: 0.089258, Train Acc: 0.861538 | Val Loss: 0.116330, Val Acc: 0.773196\n",
      "Epoch 18854 - Train Loss: 0.089255, Train Acc: 0.861538 | Val Loss: 0.116328, Val Acc: 0.773196\n",
      "Epoch 18855 - Train Loss: 0.089253, Train Acc: 0.861538 | Val Loss: 0.116327, Val Acc: 0.773196\n",
      "Epoch 18856 - Train Loss: 0.089250, Train Acc: 0.861538 | Val Loss: 0.116326, Val Acc: 0.773196\n",
      "Epoch 18857 - Train Loss: 0.089248, Train Acc: 0.861538 | Val Loss: 0.116325, Val Acc: 0.773196\n",
      "Epoch 18858 - Train Loss: 0.089245, Train Acc: 0.861538 | Val Loss: 0.116323, Val Acc: 0.773196\n",
      "Epoch 18859 - Train Loss: 0.089243, Train Acc: 0.861538 | Val Loss: 0.116322, Val Acc: 0.773196\n",
      "Epoch 18860 - Train Loss: 0.089240, Train Acc: 0.861538 | Val Loss: 0.116321, Val Acc: 0.773196\n",
      "Epoch 18861 - Train Loss: 0.089238, Train Acc: 0.861538 | Val Loss: 0.116319, Val Acc: 0.773196\n",
      "Epoch 18862 - Train Loss: 0.089236, Train Acc: 0.861538 | Val Loss: 0.116318, Val Acc: 0.773196\n",
      "Epoch 18863 - Train Loss: 0.089233, Train Acc: 0.861538 | Val Loss: 0.116317, Val Acc: 0.773196\n",
      "Epoch 18864 - Train Loss: 0.089231, Train Acc: 0.861538 | Val Loss: 0.116316, Val Acc: 0.773196\n",
      "Epoch 18865 - Train Loss: 0.089228, Train Acc: 0.861538 | Val Loss: 0.116314, Val Acc: 0.773196\n",
      "Epoch 18866 - Train Loss: 0.089226, Train Acc: 0.861538 | Val Loss: 0.116313, Val Acc: 0.773196\n",
      "Epoch 18867 - Train Loss: 0.089223, Train Acc: 0.861538 | Val Loss: 0.116312, Val Acc: 0.773196\n",
      "Epoch 18868 - Train Loss: 0.089221, Train Acc: 0.861538 | Val Loss: 0.116311, Val Acc: 0.773196\n",
      "Epoch 18869 - Train Loss: 0.089218, Train Acc: 0.861538 | Val Loss: 0.116309, Val Acc: 0.773196\n",
      "Epoch 18870 - Train Loss: 0.089216, Train Acc: 0.861538 | Val Loss: 0.116308, Val Acc: 0.773196\n",
      "Epoch 18871 - Train Loss: 0.089213, Train Acc: 0.861538 | Val Loss: 0.116307, Val Acc: 0.773196\n",
      "Epoch 18872 - Train Loss: 0.089211, Train Acc: 0.861538 | Val Loss: 0.116306, Val Acc: 0.773196\n",
      "Epoch 18873 - Train Loss: 0.089208, Train Acc: 0.861538 | Val Loss: 0.116304, Val Acc: 0.773196\n",
      "Epoch 18874 - Train Loss: 0.089206, Train Acc: 0.861538 | Val Loss: 0.116303, Val Acc: 0.773196\n",
      "Epoch 18875 - Train Loss: 0.089203, Train Acc: 0.862821 | Val Loss: 0.116302, Val Acc: 0.773196\n",
      "Epoch 18876 - Train Loss: 0.089201, Train Acc: 0.862821 | Val Loss: 0.116300, Val Acc: 0.773196\n",
      "Epoch 18877 - Train Loss: 0.089198, Train Acc: 0.862821 | Val Loss: 0.116299, Val Acc: 0.773196\n",
      "Epoch 18878 - Train Loss: 0.089196, Train Acc: 0.862821 | Val Loss: 0.116298, Val Acc: 0.773196\n",
      "Epoch 18879 - Train Loss: 0.089193, Train Acc: 0.862821 | Val Loss: 0.116297, Val Acc: 0.773196\n",
      "Epoch 18880 - Train Loss: 0.089191, Train Acc: 0.862821 | Val Loss: 0.116295, Val Acc: 0.773196\n",
      "Epoch 18881 - Train Loss: 0.089189, Train Acc: 0.862821 | Val Loss: 0.116294, Val Acc: 0.773196\n",
      "Epoch 18882 - Train Loss: 0.089186, Train Acc: 0.862821 | Val Loss: 0.116293, Val Acc: 0.773196\n",
      "Epoch 18883 - Train Loss: 0.089184, Train Acc: 0.862821 | Val Loss: 0.116292, Val Acc: 0.773196\n",
      "Epoch 18884 - Train Loss: 0.089181, Train Acc: 0.862821 | Val Loss: 0.116290, Val Acc: 0.773196\n",
      "Epoch 18885 - Train Loss: 0.089179, Train Acc: 0.862821 | Val Loss: 0.116289, Val Acc: 0.773196\n",
      "Epoch 18886 - Train Loss: 0.089176, Train Acc: 0.862821 | Val Loss: 0.116288, Val Acc: 0.773196\n",
      "Epoch 18887 - Train Loss: 0.089174, Train Acc: 0.862821 | Val Loss: 0.116287, Val Acc: 0.773196\n",
      "Epoch 18888 - Train Loss: 0.089171, Train Acc: 0.862821 | Val Loss: 0.116285, Val Acc: 0.773196\n",
      "Epoch 18889 - Train Loss: 0.089169, Train Acc: 0.862821 | Val Loss: 0.116284, Val Acc: 0.773196\n",
      "Epoch 18890 - Train Loss: 0.089166, Train Acc: 0.862821 | Val Loss: 0.116283, Val Acc: 0.773196\n",
      "Epoch 18891 - Train Loss: 0.089164, Train Acc: 0.862821 | Val Loss: 0.116282, Val Acc: 0.773196\n",
      "Epoch 18892 - Train Loss: 0.089161, Train Acc: 0.862821 | Val Loss: 0.116280, Val Acc: 0.773196\n",
      "Epoch 18893 - Train Loss: 0.089159, Train Acc: 0.862821 | Val Loss: 0.116279, Val Acc: 0.773196\n",
      "Epoch 18894 - Train Loss: 0.089156, Train Acc: 0.862821 | Val Loss: 0.116278, Val Acc: 0.773196\n",
      "Epoch 18895 - Train Loss: 0.089154, Train Acc: 0.862821 | Val Loss: 0.116276, Val Acc: 0.773196\n",
      "Epoch 18896 - Train Loss: 0.089151, Train Acc: 0.862821 | Val Loss: 0.116275, Val Acc: 0.773196\n",
      "Epoch 18897 - Train Loss: 0.089149, Train Acc: 0.862821 | Val Loss: 0.116274, Val Acc: 0.773196\n",
      "Epoch 18898 - Train Loss: 0.089147, Train Acc: 0.862821 | Val Loss: 0.116273, Val Acc: 0.773196\n",
      "Epoch 18899 - Train Loss: 0.089144, Train Acc: 0.862821 | Val Loss: 0.116271, Val Acc: 0.773196\n",
      "Epoch 18900 - Train Loss: 0.089142, Train Acc: 0.862821 | Val Loss: 0.116270, Val Acc: 0.773196\n",
      "Epoch 18901 - Train Loss: 0.089139, Train Acc: 0.862821 | Val Loss: 0.116269, Val Acc: 0.773196\n",
      "Epoch 18902 - Train Loss: 0.089137, Train Acc: 0.862821 | Val Loss: 0.116268, Val Acc: 0.773196\n",
      "Epoch 18903 - Train Loss: 0.089134, Train Acc: 0.862821 | Val Loss: 0.116266, Val Acc: 0.773196\n",
      "Epoch 18904 - Train Loss: 0.089132, Train Acc: 0.862821 | Val Loss: 0.116265, Val Acc: 0.773196\n",
      "Epoch 18905 - Train Loss: 0.089129, Train Acc: 0.862821 | Val Loss: 0.116264, Val Acc: 0.773196\n",
      "Epoch 18906 - Train Loss: 0.089127, Train Acc: 0.862821 | Val Loss: 0.116263, Val Acc: 0.773196\n",
      "Epoch 18907 - Train Loss: 0.089124, Train Acc: 0.862821 | Val Loss: 0.116261, Val Acc: 0.773196\n",
      "Epoch 18908 - Train Loss: 0.089122, Train Acc: 0.862821 | Val Loss: 0.116260, Val Acc: 0.773196\n",
      "Epoch 18909 - Train Loss: 0.089119, Train Acc: 0.862821 | Val Loss: 0.116259, Val Acc: 0.773196\n",
      "Epoch 18910 - Train Loss: 0.089117, Train Acc: 0.862821 | Val Loss: 0.116258, Val Acc: 0.773196\n",
      "Epoch 18911 - Train Loss: 0.089114, Train Acc: 0.862821 | Val Loss: 0.116256, Val Acc: 0.773196\n",
      "Epoch 18912 - Train Loss: 0.089112, Train Acc: 0.862821 | Val Loss: 0.116255, Val Acc: 0.773196\n",
      "Epoch 18913 - Train Loss: 0.089110, Train Acc: 0.862821 | Val Loss: 0.116254, Val Acc: 0.773196\n",
      "Epoch 18914 - Train Loss: 0.089107, Train Acc: 0.862821 | Val Loss: 0.116253, Val Acc: 0.773196\n",
      "Epoch 18915 - Train Loss: 0.089105, Train Acc: 0.862821 | Val Loss: 0.116251, Val Acc: 0.773196\n",
      "Epoch 18916 - Train Loss: 0.089102, Train Acc: 0.862821 | Val Loss: 0.116250, Val Acc: 0.773196\n",
      "Epoch 18917 - Train Loss: 0.089100, Train Acc: 0.862821 | Val Loss: 0.116249, Val Acc: 0.773196\n",
      "Epoch 18918 - Train Loss: 0.089097, Train Acc: 0.862821 | Val Loss: 0.116248, Val Acc: 0.773196\n",
      "Epoch 18919 - Train Loss: 0.089095, Train Acc: 0.862821 | Val Loss: 0.116246, Val Acc: 0.773196\n",
      "Epoch 18920 - Train Loss: 0.089092, Train Acc: 0.862821 | Val Loss: 0.116245, Val Acc: 0.773196\n",
      "Epoch 18921 - Train Loss: 0.089090, Train Acc: 0.862821 | Val Loss: 0.116244, Val Acc: 0.773196\n",
      "Epoch 18922 - Train Loss: 0.089087, Train Acc: 0.862821 | Val Loss: 0.116243, Val Acc: 0.773196\n",
      "Epoch 18923 - Train Loss: 0.089085, Train Acc: 0.862821 | Val Loss: 0.116241, Val Acc: 0.773196\n",
      "Epoch 18924 - Train Loss: 0.089082, Train Acc: 0.862821 | Val Loss: 0.116240, Val Acc: 0.773196\n",
      "Epoch 18925 - Train Loss: 0.089080, Train Acc: 0.862821 | Val Loss: 0.116239, Val Acc: 0.773196\n",
      "Epoch 18926 - Train Loss: 0.089077, Train Acc: 0.862821 | Val Loss: 0.116238, Val Acc: 0.773196\n",
      "Epoch 18927 - Train Loss: 0.089075, Train Acc: 0.862821 | Val Loss: 0.116236, Val Acc: 0.773196\n",
      "Epoch 18928 - Train Loss: 0.089073, Train Acc: 0.862821 | Val Loss: 0.116235, Val Acc: 0.773196\n",
      "Epoch 18929 - Train Loss: 0.089070, Train Acc: 0.862821 | Val Loss: 0.116234, Val Acc: 0.773196\n",
      "Epoch 18930 - Train Loss: 0.089068, Train Acc: 0.862821 | Val Loss: 0.116233, Val Acc: 0.773196\n",
      "Epoch 18931 - Train Loss: 0.089065, Train Acc: 0.862821 | Val Loss: 0.116231, Val Acc: 0.773196\n",
      "Epoch 18932 - Train Loss: 0.089063, Train Acc: 0.862821 | Val Loss: 0.116230, Val Acc: 0.773196\n",
      "Epoch 18933 - Train Loss: 0.089060, Train Acc: 0.862821 | Val Loss: 0.116229, Val Acc: 0.773196\n",
      "Epoch 18934 - Train Loss: 0.089058, Train Acc: 0.862821 | Val Loss: 0.116228, Val Acc: 0.773196\n",
      "Epoch 18935 - Train Loss: 0.089055, Train Acc: 0.862821 | Val Loss: 0.116226, Val Acc: 0.773196\n",
      "Epoch 18936 - Train Loss: 0.089053, Train Acc: 0.862821 | Val Loss: 0.116225, Val Acc: 0.773196\n",
      "Epoch 18937 - Train Loss: 0.089050, Train Acc: 0.862821 | Val Loss: 0.116224, Val Acc: 0.773196\n",
      "Epoch 18938 - Train Loss: 0.089048, Train Acc: 0.862821 | Val Loss: 0.116223, Val Acc: 0.773196\n",
      "Epoch 18939 - Train Loss: 0.089045, Train Acc: 0.862821 | Val Loss: 0.116221, Val Acc: 0.773196\n",
      "Epoch 18940 - Train Loss: 0.089043, Train Acc: 0.862821 | Val Loss: 0.116220, Val Acc: 0.773196\n",
      "Epoch 18941 - Train Loss: 0.089041, Train Acc: 0.862821 | Val Loss: 0.116219, Val Acc: 0.773196\n",
      "Epoch 18942 - Train Loss: 0.089038, Train Acc: 0.862821 | Val Loss: 0.116218, Val Acc: 0.773196\n",
      "Epoch 18943 - Train Loss: 0.089036, Train Acc: 0.862821 | Val Loss: 0.116216, Val Acc: 0.773196\n",
      "Epoch 18944 - Train Loss: 0.089033, Train Acc: 0.862821 | Val Loss: 0.116215, Val Acc: 0.773196\n",
      "Epoch 18945 - Train Loss: 0.089031, Train Acc: 0.862821 | Val Loss: 0.116214, Val Acc: 0.773196\n",
      "Epoch 18946 - Train Loss: 0.089028, Train Acc: 0.862821 | Val Loss: 0.116213, Val Acc: 0.773196\n",
      "Epoch 18947 - Train Loss: 0.089026, Train Acc: 0.862821 | Val Loss: 0.116211, Val Acc: 0.773196\n",
      "Epoch 18948 - Train Loss: 0.089023, Train Acc: 0.862821 | Val Loss: 0.116210, Val Acc: 0.773196\n",
      "Epoch 18949 - Train Loss: 0.089021, Train Acc: 0.862821 | Val Loss: 0.116209, Val Acc: 0.773196\n",
      "Epoch 18950 - Train Loss: 0.089018, Train Acc: 0.862821 | Val Loss: 0.116208, Val Acc: 0.773196\n",
      "Epoch 18951 - Train Loss: 0.089016, Train Acc: 0.862821 | Val Loss: 0.116206, Val Acc: 0.773196\n",
      "Epoch 18952 - Train Loss: 0.089014, Train Acc: 0.862821 | Val Loss: 0.116205, Val Acc: 0.773196\n",
      "Epoch 18953 - Train Loss: 0.089011, Train Acc: 0.862821 | Val Loss: 0.116204, Val Acc: 0.773196\n",
      "Epoch 18954 - Train Loss: 0.089009, Train Acc: 0.862821 | Val Loss: 0.116203, Val Acc: 0.773196\n",
      "Epoch 18955 - Train Loss: 0.089006, Train Acc: 0.862821 | Val Loss: 0.116201, Val Acc: 0.773196\n",
      "Epoch 18956 - Train Loss: 0.089004, Train Acc: 0.862821 | Val Loss: 0.116200, Val Acc: 0.773196\n",
      "Epoch 18957 - Train Loss: 0.089001, Train Acc: 0.862821 | Val Loss: 0.116199, Val Acc: 0.773196\n",
      "Epoch 18958 - Train Loss: 0.088999, Train Acc: 0.862821 | Val Loss: 0.116198, Val Acc: 0.773196\n",
      "Epoch 18959 - Train Loss: 0.088996, Train Acc: 0.862821 | Val Loss: 0.116196, Val Acc: 0.773196\n",
      "Epoch 18960 - Train Loss: 0.088994, Train Acc: 0.862821 | Val Loss: 0.116195, Val Acc: 0.773196\n",
      "Epoch 18961 - Train Loss: 0.088991, Train Acc: 0.862821 | Val Loss: 0.116194, Val Acc: 0.773196\n",
      "Epoch 18962 - Train Loss: 0.088989, Train Acc: 0.862821 | Val Loss: 0.116193, Val Acc: 0.773196\n",
      "Epoch 18963 - Train Loss: 0.088987, Train Acc: 0.862821 | Val Loss: 0.116191, Val Acc: 0.773196\n",
      "Epoch 18964 - Train Loss: 0.088984, Train Acc: 0.862821 | Val Loss: 0.116190, Val Acc: 0.773196\n",
      "Epoch 18965 - Train Loss: 0.088982, Train Acc: 0.862821 | Val Loss: 0.116189, Val Acc: 0.773196\n",
      "Epoch 18966 - Train Loss: 0.088979, Train Acc: 0.862821 | Val Loss: 0.116188, Val Acc: 0.773196\n",
      "Epoch 18967 - Train Loss: 0.088977, Train Acc: 0.862821 | Val Loss: 0.116186, Val Acc: 0.773196\n",
      "Epoch 18968 - Train Loss: 0.088974, Train Acc: 0.862821 | Val Loss: 0.116185, Val Acc: 0.773196\n",
      "Epoch 18969 - Train Loss: 0.088972, Train Acc: 0.862821 | Val Loss: 0.116184, Val Acc: 0.773196\n",
      "Epoch 18970 - Train Loss: 0.088969, Train Acc: 0.862821 | Val Loss: 0.116183, Val Acc: 0.773196\n",
      "Epoch 18971 - Train Loss: 0.088967, Train Acc: 0.862821 | Val Loss: 0.116181, Val Acc: 0.773196\n",
      "Epoch 18972 - Train Loss: 0.088964, Train Acc: 0.862821 | Val Loss: 0.116180, Val Acc: 0.773196\n",
      "Epoch 18973 - Train Loss: 0.088962, Train Acc: 0.862821 | Val Loss: 0.116179, Val Acc: 0.773196\n",
      "Epoch 18974 - Train Loss: 0.088960, Train Acc: 0.862821 | Val Loss: 0.116178, Val Acc: 0.773196\n",
      "Epoch 18975 - Train Loss: 0.088957, Train Acc: 0.862821 | Val Loss: 0.116176, Val Acc: 0.773196\n",
      "Epoch 18976 - Train Loss: 0.088955, Train Acc: 0.862821 | Val Loss: 0.116175, Val Acc: 0.773196\n",
      "Epoch 18977 - Train Loss: 0.088952, Train Acc: 0.862821 | Val Loss: 0.116174, Val Acc: 0.773196\n",
      "Epoch 18978 - Train Loss: 0.088950, Train Acc: 0.862821 | Val Loss: 0.116173, Val Acc: 0.773196\n",
      "Epoch 18979 - Train Loss: 0.088947, Train Acc: 0.862821 | Val Loss: 0.116171, Val Acc: 0.773196\n",
      "Epoch 18980 - Train Loss: 0.088945, Train Acc: 0.862821 | Val Loss: 0.116170, Val Acc: 0.773196\n",
      "Epoch 18981 - Train Loss: 0.088942, Train Acc: 0.862821 | Val Loss: 0.116169, Val Acc: 0.773196\n",
      "Epoch 18982 - Train Loss: 0.088940, Train Acc: 0.862821 | Val Loss: 0.116168, Val Acc: 0.773196\n",
      "Epoch 18983 - Train Loss: 0.088937, Train Acc: 0.862821 | Val Loss: 0.116166, Val Acc: 0.773196\n",
      "Epoch 18984 - Train Loss: 0.088935, Train Acc: 0.862821 | Val Loss: 0.116165, Val Acc: 0.773196\n",
      "Epoch 18985 - Train Loss: 0.088933, Train Acc: 0.862821 | Val Loss: 0.116164, Val Acc: 0.773196\n",
      "Epoch 18986 - Train Loss: 0.088930, Train Acc: 0.862821 | Val Loss: 0.116163, Val Acc: 0.773196\n",
      "Epoch 18987 - Train Loss: 0.088928, Train Acc: 0.862821 | Val Loss: 0.116161, Val Acc: 0.773196\n",
      "Epoch 18988 - Train Loss: 0.088925, Train Acc: 0.862821 | Val Loss: 0.116160, Val Acc: 0.773196\n",
      "Epoch 18989 - Train Loss: 0.088923, Train Acc: 0.862821 | Val Loss: 0.116159, Val Acc: 0.773196\n",
      "Epoch 18990 - Train Loss: 0.088920, Train Acc: 0.862821 | Val Loss: 0.116158, Val Acc: 0.773196\n",
      "Epoch 18991 - Train Loss: 0.088918, Train Acc: 0.862821 | Val Loss: 0.116157, Val Acc: 0.773196\n",
      "Epoch 18992 - Train Loss: 0.088915, Train Acc: 0.862821 | Val Loss: 0.116155, Val Acc: 0.773196\n",
      "Epoch 18993 - Train Loss: 0.088913, Train Acc: 0.862821 | Val Loss: 0.116154, Val Acc: 0.773196\n",
      "Epoch 18994 - Train Loss: 0.088911, Train Acc: 0.862821 | Val Loss: 0.116153, Val Acc: 0.773196\n",
      "Epoch 18995 - Train Loss: 0.088908, Train Acc: 0.862821 | Val Loss: 0.116152, Val Acc: 0.773196\n",
      "Epoch 18996 - Train Loss: 0.088906, Train Acc: 0.862821 | Val Loss: 0.116150, Val Acc: 0.773196\n",
      "Epoch 18997 - Train Loss: 0.088903, Train Acc: 0.862821 | Val Loss: 0.116149, Val Acc: 0.773196\n",
      "Epoch 18998 - Train Loss: 0.088901, Train Acc: 0.862821 | Val Loss: 0.116148, Val Acc: 0.773196\n",
      "Epoch 18999 - Train Loss: 0.088898, Train Acc: 0.862821 | Val Loss: 0.116147, Val Acc: 0.773196\n",
      "Epoch 19000 - Train Loss: 0.088896, Train Acc: 0.862821 | Val Loss: 0.116145, Val Acc: 0.773196\n",
      "Epoch 19001 - Train Loss: 0.088893, Train Acc: 0.862821 | Val Loss: 0.116144, Val Acc: 0.773196\n",
      "Epoch 19002 - Train Loss: 0.088891, Train Acc: 0.862821 | Val Loss: 0.116143, Val Acc: 0.773196\n",
      "Epoch 19003 - Train Loss: 0.088889, Train Acc: 0.862821 | Val Loss: 0.116142, Val Acc: 0.773196\n",
      "Epoch 19004 - Train Loss: 0.088886, Train Acc: 0.862821 | Val Loss: 0.116140, Val Acc: 0.773196\n",
      "Epoch 19005 - Train Loss: 0.088884, Train Acc: 0.862821 | Val Loss: 0.116139, Val Acc: 0.773196\n",
      "Epoch 19006 - Train Loss: 0.088881, Train Acc: 0.862821 | Val Loss: 0.116138, Val Acc: 0.773196\n",
      "Epoch 19007 - Train Loss: 0.088879, Train Acc: 0.862821 | Val Loss: 0.116137, Val Acc: 0.773196\n",
      "Epoch 19008 - Train Loss: 0.088876, Train Acc: 0.862821 | Val Loss: 0.116135, Val Acc: 0.773196\n",
      "Epoch 19009 - Train Loss: 0.088874, Train Acc: 0.862821 | Val Loss: 0.116134, Val Acc: 0.773196\n",
      "Epoch 19010 - Train Loss: 0.088871, Train Acc: 0.862821 | Val Loss: 0.116133, Val Acc: 0.773196\n",
      "Epoch 19011 - Train Loss: 0.088869, Train Acc: 0.862821 | Val Loss: 0.116132, Val Acc: 0.773196\n",
      "Epoch 19012 - Train Loss: 0.088867, Train Acc: 0.862821 | Val Loss: 0.116131, Val Acc: 0.773196\n",
      "Epoch 19013 - Train Loss: 0.088864, Train Acc: 0.862821 | Val Loss: 0.116129, Val Acc: 0.773196\n",
      "Epoch 19014 - Train Loss: 0.088862, Train Acc: 0.862821 | Val Loss: 0.116128, Val Acc: 0.773196\n",
      "Epoch 19015 - Train Loss: 0.088859, Train Acc: 0.862821 | Val Loss: 0.116127, Val Acc: 0.773196\n",
      "Epoch 19016 - Train Loss: 0.088857, Train Acc: 0.862821 | Val Loss: 0.116126, Val Acc: 0.773196\n",
      "Epoch 19017 - Train Loss: 0.088854, Train Acc: 0.862821 | Val Loss: 0.116124, Val Acc: 0.773196\n",
      "Epoch 19018 - Train Loss: 0.088852, Train Acc: 0.862821 | Val Loss: 0.116123, Val Acc: 0.773196\n",
      "Epoch 19019 - Train Loss: 0.088849, Train Acc: 0.862821 | Val Loss: 0.116122, Val Acc: 0.773196\n",
      "Epoch 19020 - Train Loss: 0.088847, Train Acc: 0.862821 | Val Loss: 0.116121, Val Acc: 0.773196\n",
      "Epoch 19021 - Train Loss: 0.088845, Train Acc: 0.862821 | Val Loss: 0.116119, Val Acc: 0.773196\n",
      "Epoch 19022 - Train Loss: 0.088842, Train Acc: 0.862821 | Val Loss: 0.116118, Val Acc: 0.773196\n",
      "Epoch 19023 - Train Loss: 0.088840, Train Acc: 0.862821 | Val Loss: 0.116117, Val Acc: 0.773196\n",
      "Epoch 19024 - Train Loss: 0.088837, Train Acc: 0.862821 | Val Loss: 0.116116, Val Acc: 0.773196\n",
      "Epoch 19025 - Train Loss: 0.088835, Train Acc: 0.862821 | Val Loss: 0.116114, Val Acc: 0.773196\n",
      "Epoch 19026 - Train Loss: 0.088832, Train Acc: 0.862821 | Val Loss: 0.116113, Val Acc: 0.773196\n",
      "Epoch 19027 - Train Loss: 0.088830, Train Acc: 0.862821 | Val Loss: 0.116112, Val Acc: 0.773196\n",
      "Epoch 19028 - Train Loss: 0.088827, Train Acc: 0.862821 | Val Loss: 0.116111, Val Acc: 0.773196\n",
      "Epoch 19029 - Train Loss: 0.088825, Train Acc: 0.862821 | Val Loss: 0.116110, Val Acc: 0.773196\n",
      "Epoch 19030 - Train Loss: 0.088823, Train Acc: 0.862821 | Val Loss: 0.116108, Val Acc: 0.773196\n",
      "Epoch 19031 - Train Loss: 0.088820, Train Acc: 0.862821 | Val Loss: 0.116107, Val Acc: 0.773196\n",
      "Epoch 19032 - Train Loss: 0.088818, Train Acc: 0.862821 | Val Loss: 0.116106, Val Acc: 0.773196\n",
      "Epoch 19033 - Train Loss: 0.088815, Train Acc: 0.862821 | Val Loss: 0.116105, Val Acc: 0.773196\n",
      "Epoch 19034 - Train Loss: 0.088813, Train Acc: 0.862821 | Val Loss: 0.116103, Val Acc: 0.773196\n",
      "Epoch 19035 - Train Loss: 0.088810, Train Acc: 0.862821 | Val Loss: 0.116102, Val Acc: 0.773196\n",
      "Epoch 19036 - Train Loss: 0.088808, Train Acc: 0.862821 | Val Loss: 0.116101, Val Acc: 0.773196\n",
      "Epoch 19037 - Train Loss: 0.088806, Train Acc: 0.862821 | Val Loss: 0.116100, Val Acc: 0.773196\n",
      "Epoch 19038 - Train Loss: 0.088803, Train Acc: 0.862821 | Val Loss: 0.116098, Val Acc: 0.773196\n",
      "Epoch 19039 - Train Loss: 0.088801, Train Acc: 0.862821 | Val Loss: 0.116097, Val Acc: 0.773196\n",
      "Epoch 19040 - Train Loss: 0.088798, Train Acc: 0.862821 | Val Loss: 0.116096, Val Acc: 0.773196\n",
      "Epoch 19041 - Train Loss: 0.088796, Train Acc: 0.862821 | Val Loss: 0.116095, Val Acc: 0.773196\n",
      "Epoch 19042 - Train Loss: 0.088793, Train Acc: 0.862821 | Val Loss: 0.116094, Val Acc: 0.773196\n",
      "Epoch 19043 - Train Loss: 0.088791, Train Acc: 0.862821 | Val Loss: 0.116092, Val Acc: 0.773196\n",
      "Epoch 19044 - Train Loss: 0.088788, Train Acc: 0.862821 | Val Loss: 0.116091, Val Acc: 0.773196\n",
      "Epoch 19045 - Train Loss: 0.088786, Train Acc: 0.862821 | Val Loss: 0.116090, Val Acc: 0.773196\n",
      "Epoch 19046 - Train Loss: 0.088784, Train Acc: 0.862821 | Val Loss: 0.116089, Val Acc: 0.773196\n",
      "Epoch 19047 - Train Loss: 0.088781, Train Acc: 0.862821 | Val Loss: 0.116087, Val Acc: 0.773196\n",
      "Epoch 19048 - Train Loss: 0.088779, Train Acc: 0.862821 | Val Loss: 0.116086, Val Acc: 0.773196\n",
      "Epoch 19049 - Train Loss: 0.088776, Train Acc: 0.862821 | Val Loss: 0.116085, Val Acc: 0.773196\n",
      "Epoch 19050 - Train Loss: 0.088774, Train Acc: 0.862821 | Val Loss: 0.116084, Val Acc: 0.773196\n",
      "Epoch 19051 - Train Loss: 0.088771, Train Acc: 0.862821 | Val Loss: 0.116082, Val Acc: 0.773196\n",
      "Epoch 19052 - Train Loss: 0.088769, Train Acc: 0.862821 | Val Loss: 0.116081, Val Acc: 0.773196\n",
      "Epoch 19053 - Train Loss: 0.088767, Train Acc: 0.862821 | Val Loss: 0.116080, Val Acc: 0.773196\n",
      "Epoch 19054 - Train Loss: 0.088764, Train Acc: 0.862821 | Val Loss: 0.116079, Val Acc: 0.773196\n",
      "Epoch 19055 - Train Loss: 0.088762, Train Acc: 0.862821 | Val Loss: 0.116078, Val Acc: 0.773196\n",
      "Epoch 19056 - Train Loss: 0.088759, Train Acc: 0.862821 | Val Loss: 0.116076, Val Acc: 0.773196\n",
      "Epoch 19057 - Train Loss: 0.088757, Train Acc: 0.862821 | Val Loss: 0.116075, Val Acc: 0.773196\n",
      "Epoch 19058 - Train Loss: 0.088754, Train Acc: 0.862821 | Val Loss: 0.116074, Val Acc: 0.773196\n",
      "Epoch 19059 - Train Loss: 0.088752, Train Acc: 0.862821 | Val Loss: 0.116073, Val Acc: 0.773196\n",
      "Epoch 19060 - Train Loss: 0.088750, Train Acc: 0.862821 | Val Loss: 0.116071, Val Acc: 0.773196\n",
      "Epoch 19061 - Train Loss: 0.088747, Train Acc: 0.862821 | Val Loss: 0.116070, Val Acc: 0.773196\n",
      "Epoch 19062 - Train Loss: 0.088745, Train Acc: 0.862821 | Val Loss: 0.116069, Val Acc: 0.773196\n",
      "Epoch 19063 - Train Loss: 0.088742, Train Acc: 0.862821 | Val Loss: 0.116068, Val Acc: 0.773196\n",
      "Epoch 19064 - Train Loss: 0.088740, Train Acc: 0.862821 | Val Loss: 0.116067, Val Acc: 0.773196\n",
      "Epoch 19065 - Train Loss: 0.088737, Train Acc: 0.862821 | Val Loss: 0.116065, Val Acc: 0.773196\n",
      "Epoch 19066 - Train Loss: 0.088735, Train Acc: 0.862821 | Val Loss: 0.116064, Val Acc: 0.773196\n",
      "Epoch 19067 - Train Loss: 0.088733, Train Acc: 0.862821 | Val Loss: 0.116063, Val Acc: 0.773196\n",
      "Epoch 19068 - Train Loss: 0.088730, Train Acc: 0.862821 | Val Loss: 0.116062, Val Acc: 0.773196\n",
      "Epoch 19069 - Train Loss: 0.088728, Train Acc: 0.862821 | Val Loss: 0.116060, Val Acc: 0.773196\n",
      "Epoch 19070 - Train Loss: 0.088725, Train Acc: 0.862821 | Val Loss: 0.116059, Val Acc: 0.773196\n",
      "Epoch 19071 - Train Loss: 0.088723, Train Acc: 0.862821 | Val Loss: 0.116058, Val Acc: 0.773196\n",
      "Epoch 19072 - Train Loss: 0.088720, Train Acc: 0.862821 | Val Loss: 0.116057, Val Acc: 0.773196\n",
      "Epoch 19073 - Train Loss: 0.088718, Train Acc: 0.862821 | Val Loss: 0.116055, Val Acc: 0.773196\n",
      "Epoch 19074 - Train Loss: 0.088716, Train Acc: 0.862821 | Val Loss: 0.116054, Val Acc: 0.773196\n",
      "Epoch 19075 - Train Loss: 0.088713, Train Acc: 0.862821 | Val Loss: 0.116053, Val Acc: 0.773196\n",
      "Epoch 19076 - Train Loss: 0.088711, Train Acc: 0.862821 | Val Loss: 0.116052, Val Acc: 0.773196\n",
      "Epoch 19077 - Train Loss: 0.088708, Train Acc: 0.862821 | Val Loss: 0.116051, Val Acc: 0.773196\n",
      "Epoch 19078 - Train Loss: 0.088706, Train Acc: 0.862821 | Val Loss: 0.116049, Val Acc: 0.773196\n",
      "Epoch 19079 - Train Loss: 0.088703, Train Acc: 0.862821 | Val Loss: 0.116048, Val Acc: 0.773196\n",
      "Epoch 19080 - Train Loss: 0.088701, Train Acc: 0.862821 | Val Loss: 0.116047, Val Acc: 0.773196\n",
      "Epoch 19081 - Train Loss: 0.088699, Train Acc: 0.862821 | Val Loss: 0.116046, Val Acc: 0.773196\n",
      "Epoch 19082 - Train Loss: 0.088696, Train Acc: 0.862821 | Val Loss: 0.116044, Val Acc: 0.773196\n",
      "Epoch 19083 - Train Loss: 0.088694, Train Acc: 0.862821 | Val Loss: 0.116043, Val Acc: 0.773196\n",
      "Epoch 19084 - Train Loss: 0.088691, Train Acc: 0.862821 | Val Loss: 0.116042, Val Acc: 0.773196\n",
      "Epoch 19085 - Train Loss: 0.088689, Train Acc: 0.862821 | Val Loss: 0.116041, Val Acc: 0.773196\n",
      "Epoch 19086 - Train Loss: 0.088686, Train Acc: 0.862821 | Val Loss: 0.116040, Val Acc: 0.773196\n",
      "Epoch 19087 - Train Loss: 0.088684, Train Acc: 0.862821 | Val Loss: 0.116038, Val Acc: 0.773196\n",
      "Epoch 19088 - Train Loss: 0.088682, Train Acc: 0.862821 | Val Loss: 0.116037, Val Acc: 0.773196\n",
      "Epoch 19089 - Train Loss: 0.088679, Train Acc: 0.862821 | Val Loss: 0.116036, Val Acc: 0.773196\n",
      "Epoch 19090 - Train Loss: 0.088677, Train Acc: 0.862821 | Val Loss: 0.116035, Val Acc: 0.773196\n",
      "Epoch 19091 - Train Loss: 0.088674, Train Acc: 0.862821 | Val Loss: 0.116033, Val Acc: 0.773196\n",
      "Epoch 19092 - Train Loss: 0.088672, Train Acc: 0.862821 | Val Loss: 0.116032, Val Acc: 0.773196\n",
      "Epoch 19093 - Train Loss: 0.088669, Train Acc: 0.862821 | Val Loss: 0.116031, Val Acc: 0.773196\n",
      "Epoch 19094 - Train Loss: 0.088667, Train Acc: 0.862821 | Val Loss: 0.116030, Val Acc: 0.773196\n",
      "Epoch 19095 - Train Loss: 0.088665, Train Acc: 0.862821 | Val Loss: 0.116029, Val Acc: 0.773196\n",
      "Epoch 19096 - Train Loss: 0.088662, Train Acc: 0.862821 | Val Loss: 0.116027, Val Acc: 0.773196\n",
      "Epoch 19097 - Train Loss: 0.088660, Train Acc: 0.862821 | Val Loss: 0.116026, Val Acc: 0.773196\n",
      "Epoch 19098 - Train Loss: 0.088657, Train Acc: 0.862821 | Val Loss: 0.116025, Val Acc: 0.773196\n",
      "Epoch 19099 - Train Loss: 0.088655, Train Acc: 0.862821 | Val Loss: 0.116024, Val Acc: 0.773196\n",
      "Epoch 19100 - Train Loss: 0.088652, Train Acc: 0.862821 | Val Loss: 0.116022, Val Acc: 0.773196\n",
      "Epoch 19101 - Train Loss: 0.088650, Train Acc: 0.862821 | Val Loss: 0.116021, Val Acc: 0.773196\n",
      "Epoch 19102 - Train Loss: 0.088648, Train Acc: 0.862821 | Val Loss: 0.116020, Val Acc: 0.773196\n",
      "Epoch 19103 - Train Loss: 0.088645, Train Acc: 0.862821 | Val Loss: 0.116019, Val Acc: 0.773196\n",
      "Epoch 19104 - Train Loss: 0.088643, Train Acc: 0.862821 | Val Loss: 0.116018, Val Acc: 0.773196\n",
      "Epoch 19105 - Train Loss: 0.088640, Train Acc: 0.862821 | Val Loss: 0.116016, Val Acc: 0.773196\n",
      "Epoch 19106 - Train Loss: 0.088638, Train Acc: 0.862821 | Val Loss: 0.116015, Val Acc: 0.773196\n",
      "Epoch 19107 - Train Loss: 0.088635, Train Acc: 0.862821 | Val Loss: 0.116014, Val Acc: 0.773196\n",
      "Epoch 19108 - Train Loss: 0.088633, Train Acc: 0.862821 | Val Loss: 0.116013, Val Acc: 0.773196\n",
      "Epoch 19109 - Train Loss: 0.088631, Train Acc: 0.862821 | Val Loss: 0.116011, Val Acc: 0.773196\n",
      "Epoch 19110 - Train Loss: 0.088628, Train Acc: 0.862821 | Val Loss: 0.116010, Val Acc: 0.773196\n",
      "Epoch 19111 - Train Loss: 0.088626, Train Acc: 0.862821 | Val Loss: 0.116009, Val Acc: 0.773196\n",
      "Epoch 19112 - Train Loss: 0.088623, Train Acc: 0.862821 | Val Loss: 0.116008, Val Acc: 0.773196\n",
      "Epoch 19113 - Train Loss: 0.088621, Train Acc: 0.862821 | Val Loss: 0.116007, Val Acc: 0.773196\n",
      "Epoch 19114 - Train Loss: 0.088619, Train Acc: 0.862821 | Val Loss: 0.116005, Val Acc: 0.773196\n",
      "Epoch 19115 - Train Loss: 0.088616, Train Acc: 0.862821 | Val Loss: 0.116004, Val Acc: 0.773196\n",
      "Epoch 19116 - Train Loss: 0.088614, Train Acc: 0.862821 | Val Loss: 0.116003, Val Acc: 0.773196\n",
      "Epoch 19117 - Train Loss: 0.088611, Train Acc: 0.862821 | Val Loss: 0.116002, Val Acc: 0.773196\n",
      "Epoch 19118 - Train Loss: 0.088609, Train Acc: 0.862821 | Val Loss: 0.116001, Val Acc: 0.773196\n",
      "Epoch 19119 - Train Loss: 0.088606, Train Acc: 0.862821 | Val Loss: 0.115999, Val Acc: 0.773196\n",
      "Epoch 19120 - Train Loss: 0.088604, Train Acc: 0.862821 | Val Loss: 0.115998, Val Acc: 0.773196\n",
      "Epoch 19121 - Train Loss: 0.088602, Train Acc: 0.862821 | Val Loss: 0.115997, Val Acc: 0.773196\n",
      "Epoch 19122 - Train Loss: 0.088599, Train Acc: 0.862821 | Val Loss: 0.115996, Val Acc: 0.773196\n",
      "Epoch 19123 - Train Loss: 0.088597, Train Acc: 0.862821 | Val Loss: 0.115994, Val Acc: 0.773196\n",
      "Epoch 19124 - Train Loss: 0.088594, Train Acc: 0.862821 | Val Loss: 0.115993, Val Acc: 0.773196\n",
      "Epoch 19125 - Train Loss: 0.088592, Train Acc: 0.862821 | Val Loss: 0.115992, Val Acc: 0.773196\n",
      "Epoch 19126 - Train Loss: 0.088589, Train Acc: 0.862821 | Val Loss: 0.115991, Val Acc: 0.773196\n",
      "Epoch 19127 - Train Loss: 0.088587, Train Acc: 0.862821 | Val Loss: 0.115990, Val Acc: 0.773196\n",
      "Epoch 19128 - Train Loss: 0.088585, Train Acc: 0.862821 | Val Loss: 0.115988, Val Acc: 0.773196\n",
      "Epoch 19129 - Train Loss: 0.088582, Train Acc: 0.862821 | Val Loss: 0.115987, Val Acc: 0.773196\n",
      "Epoch 19130 - Train Loss: 0.088580, Train Acc: 0.862821 | Val Loss: 0.115986, Val Acc: 0.773196\n",
      "Epoch 19131 - Train Loss: 0.088577, Train Acc: 0.862821 | Val Loss: 0.115985, Val Acc: 0.773196\n",
      "Epoch 19132 - Train Loss: 0.088575, Train Acc: 0.862821 | Val Loss: 0.115984, Val Acc: 0.773196\n",
      "Epoch 19133 - Train Loss: 0.088573, Train Acc: 0.862821 | Val Loss: 0.115982, Val Acc: 0.773196\n",
      "Epoch 19134 - Train Loss: 0.088570, Train Acc: 0.862821 | Val Loss: 0.115981, Val Acc: 0.773196\n",
      "Epoch 19135 - Train Loss: 0.088568, Train Acc: 0.862821 | Val Loss: 0.115980, Val Acc: 0.773196\n",
      "Epoch 19136 - Train Loss: 0.088565, Train Acc: 0.862821 | Val Loss: 0.115979, Val Acc: 0.773196\n",
      "Epoch 19137 - Train Loss: 0.088563, Train Acc: 0.862821 | Val Loss: 0.115977, Val Acc: 0.773196\n",
      "Epoch 19138 - Train Loss: 0.088560, Train Acc: 0.862821 | Val Loss: 0.115976, Val Acc: 0.773196\n",
      "Epoch 19139 - Train Loss: 0.088558, Train Acc: 0.862821 | Val Loss: 0.115975, Val Acc: 0.773196\n",
      "Epoch 19140 - Train Loss: 0.088556, Train Acc: 0.862821 | Val Loss: 0.115974, Val Acc: 0.773196\n",
      "Epoch 19141 - Train Loss: 0.088553, Train Acc: 0.862821 | Val Loss: 0.115973, Val Acc: 0.773196\n",
      "Epoch 19142 - Train Loss: 0.088551, Train Acc: 0.862821 | Val Loss: 0.115971, Val Acc: 0.773196\n",
      "Epoch 19143 - Train Loss: 0.088548, Train Acc: 0.862821 | Val Loss: 0.115970, Val Acc: 0.773196\n",
      "Epoch 19144 - Train Loss: 0.088546, Train Acc: 0.862821 | Val Loss: 0.115969, Val Acc: 0.773196\n",
      "Epoch 19145 - Train Loss: 0.088544, Train Acc: 0.862821 | Val Loss: 0.115968, Val Acc: 0.773196\n",
      "Epoch 19146 - Train Loss: 0.088541, Train Acc: 0.862821 | Val Loss: 0.115967, Val Acc: 0.773196\n",
      "Epoch 19147 - Train Loss: 0.088539, Train Acc: 0.862821 | Val Loss: 0.115965, Val Acc: 0.773196\n",
      "Epoch 19148 - Train Loss: 0.088536, Train Acc: 0.862821 | Val Loss: 0.115964, Val Acc: 0.773196\n",
      "Epoch 19149 - Train Loss: 0.088534, Train Acc: 0.862821 | Val Loss: 0.115963, Val Acc: 0.773196\n",
      "Epoch 19150 - Train Loss: 0.088532, Train Acc: 0.862821 | Val Loss: 0.115962, Val Acc: 0.773196\n",
      "Epoch 19151 - Train Loss: 0.088529, Train Acc: 0.862821 | Val Loss: 0.115961, Val Acc: 0.773196\n",
      "Epoch 19152 - Train Loss: 0.088527, Train Acc: 0.862821 | Val Loss: 0.115959, Val Acc: 0.773196\n",
      "Epoch 19153 - Train Loss: 0.088524, Train Acc: 0.862821 | Val Loss: 0.115958, Val Acc: 0.773196\n",
      "Epoch 19154 - Train Loss: 0.088522, Train Acc: 0.862821 | Val Loss: 0.115957, Val Acc: 0.773196\n",
      "Epoch 19155 - Train Loss: 0.088519, Train Acc: 0.862821 | Val Loss: 0.115956, Val Acc: 0.773196\n",
      "Epoch 19156 - Train Loss: 0.088517, Train Acc: 0.862821 | Val Loss: 0.115954, Val Acc: 0.773196\n",
      "Epoch 19157 - Train Loss: 0.088515, Train Acc: 0.862821 | Val Loss: 0.115953, Val Acc: 0.773196\n",
      "Epoch 19158 - Train Loss: 0.088512, Train Acc: 0.862821 | Val Loss: 0.115952, Val Acc: 0.773196\n",
      "Epoch 19159 - Train Loss: 0.088510, Train Acc: 0.862821 | Val Loss: 0.115951, Val Acc: 0.773196\n",
      "Epoch 19160 - Train Loss: 0.088507, Train Acc: 0.862821 | Val Loss: 0.115950, Val Acc: 0.773196\n",
      "Epoch 19161 - Train Loss: 0.088505, Train Acc: 0.862821 | Val Loss: 0.115948, Val Acc: 0.773196\n",
      "Epoch 19162 - Train Loss: 0.088503, Train Acc: 0.862821 | Val Loss: 0.115947, Val Acc: 0.773196\n",
      "Epoch 19163 - Train Loss: 0.088500, Train Acc: 0.862821 | Val Loss: 0.115946, Val Acc: 0.773196\n",
      "Epoch 19164 - Train Loss: 0.088498, Train Acc: 0.862821 | Val Loss: 0.115945, Val Acc: 0.773196\n",
      "Epoch 19165 - Train Loss: 0.088495, Train Acc: 0.862821 | Val Loss: 0.115944, Val Acc: 0.773196\n",
      "Epoch 19166 - Train Loss: 0.088493, Train Acc: 0.862821 | Val Loss: 0.115942, Val Acc: 0.773196\n",
      "Epoch 19167 - Train Loss: 0.088491, Train Acc: 0.862821 | Val Loss: 0.115941, Val Acc: 0.773196\n",
      "Epoch 19168 - Train Loss: 0.088488, Train Acc: 0.862821 | Val Loss: 0.115940, Val Acc: 0.773196\n",
      "Epoch 19169 - Train Loss: 0.088486, Train Acc: 0.862821 | Val Loss: 0.115939, Val Acc: 0.773196\n",
      "Epoch 19170 - Train Loss: 0.088483, Train Acc: 0.862821 | Val Loss: 0.115938, Val Acc: 0.773196\n",
      "Epoch 19171 - Train Loss: 0.088481, Train Acc: 0.862821 | Val Loss: 0.115936, Val Acc: 0.773196\n",
      "Epoch 19172 - Train Loss: 0.088478, Train Acc: 0.862821 | Val Loss: 0.115935, Val Acc: 0.773196\n",
      "Epoch 19173 - Train Loss: 0.088476, Train Acc: 0.862821 | Val Loss: 0.115934, Val Acc: 0.773196\n",
      "Epoch 19174 - Train Loss: 0.088474, Train Acc: 0.862821 | Val Loss: 0.115933, Val Acc: 0.773196\n",
      "Epoch 19175 - Train Loss: 0.088471, Train Acc: 0.862821 | Val Loss: 0.115932, Val Acc: 0.773196\n",
      "Epoch 19176 - Train Loss: 0.088469, Train Acc: 0.862821 | Val Loss: 0.115930, Val Acc: 0.773196\n",
      "Epoch 19177 - Train Loss: 0.088466, Train Acc: 0.862821 | Val Loss: 0.115929, Val Acc: 0.773196\n",
      "Epoch 19178 - Train Loss: 0.088464, Train Acc: 0.862821 | Val Loss: 0.115928, Val Acc: 0.773196\n",
      "Epoch 19179 - Train Loss: 0.088462, Train Acc: 0.862821 | Val Loss: 0.115927, Val Acc: 0.773196\n",
      "Epoch 19180 - Train Loss: 0.088459, Train Acc: 0.862821 | Val Loss: 0.115926, Val Acc: 0.773196\n",
      "Epoch 19181 - Train Loss: 0.088457, Train Acc: 0.862821 | Val Loss: 0.115924, Val Acc: 0.773196\n",
      "Epoch 19182 - Train Loss: 0.088454, Train Acc: 0.862821 | Val Loss: 0.115923, Val Acc: 0.773196\n",
      "Epoch 19183 - Train Loss: 0.088452, Train Acc: 0.862821 | Val Loss: 0.115922, Val Acc: 0.773196\n",
      "Epoch 19184 - Train Loss: 0.088450, Train Acc: 0.862821 | Val Loss: 0.115921, Val Acc: 0.773196\n",
      "Epoch 19185 - Train Loss: 0.088447, Train Acc: 0.862821 | Val Loss: 0.115920, Val Acc: 0.773196\n",
      "Epoch 19186 - Train Loss: 0.088445, Train Acc: 0.862821 | Val Loss: 0.115918, Val Acc: 0.773196\n",
      "Epoch 19187 - Train Loss: 0.088442, Train Acc: 0.862821 | Val Loss: 0.115917, Val Acc: 0.773196\n",
      "Epoch 19188 - Train Loss: 0.088440, Train Acc: 0.862821 | Val Loss: 0.115916, Val Acc: 0.773196\n",
      "Epoch 19189 - Train Loss: 0.088438, Train Acc: 0.862821 | Val Loss: 0.115915, Val Acc: 0.773196\n",
      "Epoch 19190 - Train Loss: 0.088435, Train Acc: 0.862821 | Val Loss: 0.115914, Val Acc: 0.773196\n",
      "Epoch 19191 - Train Loss: 0.088433, Train Acc: 0.862821 | Val Loss: 0.115912, Val Acc: 0.773196\n",
      "Epoch 19192 - Train Loss: 0.088430, Train Acc: 0.862821 | Val Loss: 0.115911, Val Acc: 0.773196\n",
      "Epoch 19193 - Train Loss: 0.088428, Train Acc: 0.862821 | Val Loss: 0.115910, Val Acc: 0.773196\n",
      "Epoch 19194 - Train Loss: 0.088426, Train Acc: 0.862821 | Val Loss: 0.115909, Val Acc: 0.773196\n",
      "Epoch 19195 - Train Loss: 0.088423, Train Acc: 0.862821 | Val Loss: 0.115908, Val Acc: 0.773196\n",
      "Epoch 19196 - Train Loss: 0.088421, Train Acc: 0.862821 | Val Loss: 0.115906, Val Acc: 0.773196\n",
      "Epoch 19197 - Train Loss: 0.088418, Train Acc: 0.862821 | Val Loss: 0.115905, Val Acc: 0.773196\n",
      "Epoch 19198 - Train Loss: 0.088416, Train Acc: 0.862821 | Val Loss: 0.115904, Val Acc: 0.773196\n",
      "Epoch 19199 - Train Loss: 0.088414, Train Acc: 0.862821 | Val Loss: 0.115903, Val Acc: 0.773196\n",
      "Epoch 19200 - Train Loss: 0.088411, Train Acc: 0.862821 | Val Loss: 0.115902, Val Acc: 0.773196\n",
      "Epoch 19201 - Train Loss: 0.088409, Train Acc: 0.862821 | Val Loss: 0.115900, Val Acc: 0.773196\n",
      "Epoch 19202 - Train Loss: 0.088406, Train Acc: 0.862821 | Val Loss: 0.115899, Val Acc: 0.773196\n",
      "Epoch 19203 - Train Loss: 0.088404, Train Acc: 0.862821 | Val Loss: 0.115898, Val Acc: 0.773196\n",
      "Epoch 19204 - Train Loss: 0.088402, Train Acc: 0.862821 | Val Loss: 0.115897, Val Acc: 0.773196\n",
      "Epoch 19205 - Train Loss: 0.088399, Train Acc: 0.862821 | Val Loss: 0.115896, Val Acc: 0.773196\n",
      "Epoch 19206 - Train Loss: 0.088397, Train Acc: 0.862821 | Val Loss: 0.115894, Val Acc: 0.773196\n",
      "Epoch 19207 - Train Loss: 0.088394, Train Acc: 0.862821 | Val Loss: 0.115893, Val Acc: 0.773196\n",
      "Epoch 19208 - Train Loss: 0.088392, Train Acc: 0.862821 | Val Loss: 0.115892, Val Acc: 0.773196\n",
      "Epoch 19209 - Train Loss: 0.088390, Train Acc: 0.862821 | Val Loss: 0.115891, Val Acc: 0.773196\n",
      "Epoch 19210 - Train Loss: 0.088387, Train Acc: 0.862821 | Val Loss: 0.115890, Val Acc: 0.773196\n",
      "Epoch 19211 - Train Loss: 0.088385, Train Acc: 0.862821 | Val Loss: 0.115888, Val Acc: 0.773196\n",
      "Epoch 19212 - Train Loss: 0.088382, Train Acc: 0.862821 | Val Loss: 0.115887, Val Acc: 0.773196\n",
      "Epoch 19213 - Train Loss: 0.088380, Train Acc: 0.862821 | Val Loss: 0.115886, Val Acc: 0.773196\n",
      "Epoch 19214 - Train Loss: 0.088378, Train Acc: 0.862821 | Val Loss: 0.115885, Val Acc: 0.773196\n",
      "Epoch 19215 - Train Loss: 0.088375, Train Acc: 0.862821 | Val Loss: 0.115884, Val Acc: 0.773196\n",
      "Epoch 19216 - Train Loss: 0.088373, Train Acc: 0.862821 | Val Loss: 0.115882, Val Acc: 0.773196\n",
      "Epoch 19217 - Train Loss: 0.088370, Train Acc: 0.862821 | Val Loss: 0.115881, Val Acc: 0.773196\n",
      "Epoch 19218 - Train Loss: 0.088368, Train Acc: 0.862821 | Val Loss: 0.115880, Val Acc: 0.773196\n",
      "Epoch 19219 - Train Loss: 0.088366, Train Acc: 0.862821 | Val Loss: 0.115879, Val Acc: 0.773196\n",
      "Epoch 19220 - Train Loss: 0.088363, Train Acc: 0.862821 | Val Loss: 0.115878, Val Acc: 0.773196\n",
      "Epoch 19221 - Train Loss: 0.088361, Train Acc: 0.862821 | Val Loss: 0.115876, Val Acc: 0.773196\n",
      "Epoch 19222 - Train Loss: 0.088358, Train Acc: 0.862821 | Val Loss: 0.115875, Val Acc: 0.773196\n",
      "Epoch 19223 - Train Loss: 0.088356, Train Acc: 0.862821 | Val Loss: 0.115874, Val Acc: 0.773196\n",
      "Epoch 19224 - Train Loss: 0.088354, Train Acc: 0.862821 | Val Loss: 0.115873, Val Acc: 0.773196\n",
      "Epoch 19225 - Train Loss: 0.088351, Train Acc: 0.862821 | Val Loss: 0.115872, Val Acc: 0.773196\n",
      "Epoch 19226 - Train Loss: 0.088349, Train Acc: 0.862821 | Val Loss: 0.115870, Val Acc: 0.773196\n",
      "Epoch 19227 - Train Loss: 0.088346, Train Acc: 0.862821 | Val Loss: 0.115869, Val Acc: 0.773196\n",
      "Epoch 19228 - Train Loss: 0.088344, Train Acc: 0.862821 | Val Loss: 0.115868, Val Acc: 0.773196\n",
      "Epoch 19229 - Train Loss: 0.088342, Train Acc: 0.862821 | Val Loss: 0.115867, Val Acc: 0.773196\n",
      "Epoch 19230 - Train Loss: 0.088339, Train Acc: 0.862821 | Val Loss: 0.115866, Val Acc: 0.773196\n",
      "Epoch 19231 - Train Loss: 0.088337, Train Acc: 0.862821 | Val Loss: 0.115864, Val Acc: 0.773196\n",
      "Epoch 19232 - Train Loss: 0.088334, Train Acc: 0.862821 | Val Loss: 0.115863, Val Acc: 0.773196\n",
      "Epoch 19233 - Train Loss: 0.088332, Train Acc: 0.862821 | Val Loss: 0.115862, Val Acc: 0.773196\n",
      "Epoch 19234 - Train Loss: 0.088330, Train Acc: 0.862821 | Val Loss: 0.115861, Val Acc: 0.773196\n",
      "Epoch 19235 - Train Loss: 0.088327, Train Acc: 0.862821 | Val Loss: 0.115860, Val Acc: 0.773196\n",
      "Epoch 19236 - Train Loss: 0.088325, Train Acc: 0.862821 | Val Loss: 0.115859, Val Acc: 0.773196\n",
      "Epoch 19237 - Train Loss: 0.088322, Train Acc: 0.862821 | Val Loss: 0.115857, Val Acc: 0.773196\n",
      "Epoch 19238 - Train Loss: 0.088320, Train Acc: 0.862821 | Val Loss: 0.115856, Val Acc: 0.773196\n",
      "Epoch 19239 - Train Loss: 0.088318, Train Acc: 0.862821 | Val Loss: 0.115855, Val Acc: 0.773196\n",
      "Epoch 19240 - Train Loss: 0.088315, Train Acc: 0.862821 | Val Loss: 0.115854, Val Acc: 0.773196\n",
      "Epoch 19241 - Train Loss: 0.088313, Train Acc: 0.862821 | Val Loss: 0.115853, Val Acc: 0.773196\n",
      "Epoch 19242 - Train Loss: 0.088310, Train Acc: 0.862821 | Val Loss: 0.115851, Val Acc: 0.773196\n",
      "Epoch 19243 - Train Loss: 0.088308, Train Acc: 0.862821 | Val Loss: 0.115850, Val Acc: 0.773196\n",
      "Epoch 19244 - Train Loss: 0.088306, Train Acc: 0.862821 | Val Loss: 0.115849, Val Acc: 0.773196\n",
      "Epoch 19245 - Train Loss: 0.088303, Train Acc: 0.862821 | Val Loss: 0.115848, Val Acc: 0.773196\n",
      "Epoch 19246 - Train Loss: 0.088301, Train Acc: 0.862821 | Val Loss: 0.115847, Val Acc: 0.773196\n",
      "Epoch 19247 - Train Loss: 0.088298, Train Acc: 0.862821 | Val Loss: 0.115845, Val Acc: 0.773196\n",
      "Epoch 19248 - Train Loss: 0.088296, Train Acc: 0.862821 | Val Loss: 0.115844, Val Acc: 0.773196\n",
      "Epoch 19249 - Train Loss: 0.088294, Train Acc: 0.862821 | Val Loss: 0.115843, Val Acc: 0.773196\n",
      "Epoch 19250 - Train Loss: 0.088291, Train Acc: 0.862821 | Val Loss: 0.115842, Val Acc: 0.773196\n",
      "Epoch 19251 - Train Loss: 0.088289, Train Acc: 0.862821 | Val Loss: 0.115841, Val Acc: 0.773196\n",
      "Epoch 19252 - Train Loss: 0.088287, Train Acc: 0.862821 | Val Loss: 0.115839, Val Acc: 0.773196\n",
      "Epoch 19253 - Train Loss: 0.088284, Train Acc: 0.862821 | Val Loss: 0.115838, Val Acc: 0.773196\n",
      "Epoch 19254 - Train Loss: 0.088282, Train Acc: 0.862821 | Val Loss: 0.115837, Val Acc: 0.773196\n",
      "Epoch 19255 - Train Loss: 0.088279, Train Acc: 0.862821 | Val Loss: 0.115836, Val Acc: 0.773196\n",
      "Epoch 19256 - Train Loss: 0.088277, Train Acc: 0.862821 | Val Loss: 0.115835, Val Acc: 0.773196\n",
      "Epoch 19257 - Train Loss: 0.088275, Train Acc: 0.862821 | Val Loss: 0.115834, Val Acc: 0.773196\n",
      "Epoch 19258 - Train Loss: 0.088272, Train Acc: 0.862821 | Val Loss: 0.115832, Val Acc: 0.773196\n",
      "Epoch 19259 - Train Loss: 0.088270, Train Acc: 0.862821 | Val Loss: 0.115831, Val Acc: 0.773196\n",
      "Epoch 19260 - Train Loss: 0.088267, Train Acc: 0.862821 | Val Loss: 0.115830, Val Acc: 0.773196\n",
      "Epoch 19261 - Train Loss: 0.088265, Train Acc: 0.862821 | Val Loss: 0.115829, Val Acc: 0.773196\n",
      "Epoch 19262 - Train Loss: 0.088263, Train Acc: 0.862821 | Val Loss: 0.115828, Val Acc: 0.773196\n",
      "Epoch 19263 - Train Loss: 0.088260, Train Acc: 0.862821 | Val Loss: 0.115826, Val Acc: 0.773196\n",
      "Epoch 19264 - Train Loss: 0.088258, Train Acc: 0.862821 | Val Loss: 0.115825, Val Acc: 0.773196\n",
      "Epoch 19265 - Train Loss: 0.088255, Train Acc: 0.862821 | Val Loss: 0.115824, Val Acc: 0.773196\n",
      "Epoch 19266 - Train Loss: 0.088253, Train Acc: 0.862821 | Val Loss: 0.115823, Val Acc: 0.773196\n",
      "Epoch 19267 - Train Loss: 0.088251, Train Acc: 0.862821 | Val Loss: 0.115822, Val Acc: 0.773196\n",
      "Epoch 19268 - Train Loss: 0.088248, Train Acc: 0.862821 | Val Loss: 0.115821, Val Acc: 0.773196\n",
      "Epoch 19269 - Train Loss: 0.088246, Train Acc: 0.862821 | Val Loss: 0.115819, Val Acc: 0.773196\n",
      "Epoch 19270 - Train Loss: 0.088244, Train Acc: 0.862821 | Val Loss: 0.115818, Val Acc: 0.773196\n",
      "Epoch 19271 - Train Loss: 0.088241, Train Acc: 0.862821 | Val Loss: 0.115817, Val Acc: 0.773196\n",
      "Epoch 19272 - Train Loss: 0.088239, Train Acc: 0.862821 | Val Loss: 0.115816, Val Acc: 0.773196\n",
      "Epoch 19273 - Train Loss: 0.088236, Train Acc: 0.862821 | Val Loss: 0.115815, Val Acc: 0.773196\n",
      "Epoch 19274 - Train Loss: 0.088234, Train Acc: 0.862821 | Val Loss: 0.115813, Val Acc: 0.773196\n",
      "Epoch 19275 - Train Loss: 0.088232, Train Acc: 0.862821 | Val Loss: 0.115812, Val Acc: 0.773196\n",
      "Epoch 19276 - Train Loss: 0.088229, Train Acc: 0.862821 | Val Loss: 0.115811, Val Acc: 0.773196\n",
      "Epoch 19277 - Train Loss: 0.088227, Train Acc: 0.862821 | Val Loss: 0.115810, Val Acc: 0.773196\n",
      "Epoch 19278 - Train Loss: 0.088224, Train Acc: 0.862821 | Val Loss: 0.115809, Val Acc: 0.773196\n",
      "Epoch 19279 - Train Loss: 0.088222, Train Acc: 0.862821 | Val Loss: 0.115807, Val Acc: 0.773196\n",
      "Epoch 19280 - Train Loss: 0.088220, Train Acc: 0.862821 | Val Loss: 0.115806, Val Acc: 0.773196\n",
      "Epoch 19281 - Train Loss: 0.088217, Train Acc: 0.862821 | Val Loss: 0.115805, Val Acc: 0.773196\n",
      "Epoch 19282 - Train Loss: 0.088215, Train Acc: 0.862821 | Val Loss: 0.115804, Val Acc: 0.773196\n",
      "Epoch 19283 - Train Loss: 0.088213, Train Acc: 0.862821 | Val Loss: 0.115803, Val Acc: 0.773196\n",
      "Epoch 19284 - Train Loss: 0.088210, Train Acc: 0.862821 | Val Loss: 0.115802, Val Acc: 0.773196\n",
      "Epoch 19285 - Train Loss: 0.088208, Train Acc: 0.862821 | Val Loss: 0.115800, Val Acc: 0.773196\n",
      "Epoch 19286 - Train Loss: 0.088205, Train Acc: 0.862821 | Val Loss: 0.115799, Val Acc: 0.773196\n",
      "Epoch 19287 - Train Loss: 0.088203, Train Acc: 0.862821 | Val Loss: 0.115798, Val Acc: 0.773196\n",
      "Epoch 19288 - Train Loss: 0.088201, Train Acc: 0.862821 | Val Loss: 0.115797, Val Acc: 0.773196\n",
      "Epoch 19289 - Train Loss: 0.088198, Train Acc: 0.862821 | Val Loss: 0.115796, Val Acc: 0.773196\n",
      "Epoch 19290 - Train Loss: 0.088196, Train Acc: 0.862821 | Val Loss: 0.115794, Val Acc: 0.773196\n",
      "Epoch 19291 - Train Loss: 0.088193, Train Acc: 0.862821 | Val Loss: 0.115793, Val Acc: 0.773196\n",
      "Epoch 19292 - Train Loss: 0.088191, Train Acc: 0.862821 | Val Loss: 0.115792, Val Acc: 0.773196\n",
      "Epoch 19293 - Train Loss: 0.088189, Train Acc: 0.862821 | Val Loss: 0.115791, Val Acc: 0.773196\n",
      "Epoch 19294 - Train Loss: 0.088186, Train Acc: 0.862821 | Val Loss: 0.115790, Val Acc: 0.773196\n",
      "Epoch 19295 - Train Loss: 0.088184, Train Acc: 0.862821 | Val Loss: 0.115789, Val Acc: 0.773196\n",
      "Epoch 19296 - Train Loss: 0.088182, Train Acc: 0.862821 | Val Loss: 0.115787, Val Acc: 0.773196\n",
      "Epoch 19297 - Train Loss: 0.088179, Train Acc: 0.862821 | Val Loss: 0.115786, Val Acc: 0.773196\n",
      "Epoch 19298 - Train Loss: 0.088177, Train Acc: 0.862821 | Val Loss: 0.115785, Val Acc: 0.773196\n",
      "Epoch 19299 - Train Loss: 0.088174, Train Acc: 0.862821 | Val Loss: 0.115784, Val Acc: 0.773196\n",
      "Epoch 19300 - Train Loss: 0.088172, Train Acc: 0.862821 | Val Loss: 0.115783, Val Acc: 0.773196\n",
      "Epoch 19301 - Train Loss: 0.088170, Train Acc: 0.862821 | Val Loss: 0.115781, Val Acc: 0.773196\n",
      "Epoch 19302 - Train Loss: 0.088167, Train Acc: 0.862821 | Val Loss: 0.115780, Val Acc: 0.773196\n",
      "Epoch 19303 - Train Loss: 0.088165, Train Acc: 0.862821 | Val Loss: 0.115779, Val Acc: 0.773196\n",
      "Epoch 19304 - Train Loss: 0.088162, Train Acc: 0.862821 | Val Loss: 0.115778, Val Acc: 0.773196\n",
      "Epoch 19305 - Train Loss: 0.088160, Train Acc: 0.862821 | Val Loss: 0.115777, Val Acc: 0.773196\n",
      "Epoch 19306 - Train Loss: 0.088158, Train Acc: 0.862821 | Val Loss: 0.115776, Val Acc: 0.773196\n",
      "Epoch 19307 - Train Loss: 0.088155, Train Acc: 0.862821 | Val Loss: 0.115774, Val Acc: 0.773196\n",
      "Epoch 19308 - Train Loss: 0.088153, Train Acc: 0.862821 | Val Loss: 0.115773, Val Acc: 0.773196\n",
      "Epoch 19309 - Train Loss: 0.088151, Train Acc: 0.862821 | Val Loss: 0.115772, Val Acc: 0.773196\n",
      "Epoch 19310 - Train Loss: 0.088148, Train Acc: 0.862821 | Val Loss: 0.115771, Val Acc: 0.773196\n",
      "Epoch 19311 - Train Loss: 0.088146, Train Acc: 0.862821 | Val Loss: 0.115770, Val Acc: 0.773196\n",
      "Epoch 19312 - Train Loss: 0.088143, Train Acc: 0.862821 | Val Loss: 0.115769, Val Acc: 0.773196\n",
      "Epoch 19313 - Train Loss: 0.088141, Train Acc: 0.862821 | Val Loss: 0.115767, Val Acc: 0.773196\n",
      "Epoch 19314 - Train Loss: 0.088139, Train Acc: 0.862821 | Val Loss: 0.115766, Val Acc: 0.773196\n",
      "Epoch 19315 - Train Loss: 0.088136, Train Acc: 0.862821 | Val Loss: 0.115765, Val Acc: 0.773196\n",
      "Epoch 19316 - Train Loss: 0.088134, Train Acc: 0.862821 | Val Loss: 0.115764, Val Acc: 0.773196\n",
      "Epoch 19317 - Train Loss: 0.088132, Train Acc: 0.862821 | Val Loss: 0.115763, Val Acc: 0.773196\n",
      "Epoch 19318 - Train Loss: 0.088129, Train Acc: 0.862821 | Val Loss: 0.115761, Val Acc: 0.773196\n",
      "Epoch 19319 - Train Loss: 0.088127, Train Acc: 0.862821 | Val Loss: 0.115760, Val Acc: 0.773196\n",
      "Epoch 19320 - Train Loss: 0.088124, Train Acc: 0.862821 | Val Loss: 0.115759, Val Acc: 0.773196\n",
      "Epoch 19321 - Train Loss: 0.088122, Train Acc: 0.862821 | Val Loss: 0.115758, Val Acc: 0.773196\n",
      "Epoch 19322 - Train Loss: 0.088120, Train Acc: 0.862821 | Val Loss: 0.115757, Val Acc: 0.773196\n",
      "Epoch 19323 - Train Loss: 0.088117, Train Acc: 0.862821 | Val Loss: 0.115756, Val Acc: 0.773196\n",
      "Epoch 19324 - Train Loss: 0.088115, Train Acc: 0.862821 | Val Loss: 0.115754, Val Acc: 0.773196\n",
      "Epoch 19325 - Train Loss: 0.088113, Train Acc: 0.862821 | Val Loss: 0.115753, Val Acc: 0.773196\n",
      "Epoch 19326 - Train Loss: 0.088110, Train Acc: 0.862821 | Val Loss: 0.115752, Val Acc: 0.773196\n",
      "Epoch 19327 - Train Loss: 0.088108, Train Acc: 0.862821 | Val Loss: 0.115751, Val Acc: 0.773196\n",
      "Epoch 19328 - Train Loss: 0.088105, Train Acc: 0.862821 | Val Loss: 0.115750, Val Acc: 0.773196\n",
      "Epoch 19329 - Train Loss: 0.088103, Train Acc: 0.862821 | Val Loss: 0.115749, Val Acc: 0.773196\n",
      "Epoch 19330 - Train Loss: 0.088101, Train Acc: 0.862821 | Val Loss: 0.115747, Val Acc: 0.773196\n",
      "Epoch 19331 - Train Loss: 0.088098, Train Acc: 0.862821 | Val Loss: 0.115746, Val Acc: 0.773196\n",
      "Epoch 19332 - Train Loss: 0.088096, Train Acc: 0.862821 | Val Loss: 0.115745, Val Acc: 0.773196\n",
      "Epoch 19333 - Train Loss: 0.088094, Train Acc: 0.862821 | Val Loss: 0.115744, Val Acc: 0.773196\n",
      "Epoch 19334 - Train Loss: 0.088091, Train Acc: 0.862821 | Val Loss: 0.115743, Val Acc: 0.773196\n",
      "Epoch 19335 - Train Loss: 0.088089, Train Acc: 0.862821 | Val Loss: 0.115742, Val Acc: 0.773196\n",
      "Epoch 19336 - Train Loss: 0.088086, Train Acc: 0.862821 | Val Loss: 0.115740, Val Acc: 0.773196\n",
      "Epoch 19337 - Train Loss: 0.088084, Train Acc: 0.862821 | Val Loss: 0.115739, Val Acc: 0.773196\n",
      "Epoch 19338 - Train Loss: 0.088082, Train Acc: 0.862821 | Val Loss: 0.115738, Val Acc: 0.773196\n",
      "Epoch 19339 - Train Loss: 0.088079, Train Acc: 0.862821 | Val Loss: 0.115737, Val Acc: 0.773196\n",
      "Epoch 19340 - Train Loss: 0.088077, Train Acc: 0.862821 | Val Loss: 0.115736, Val Acc: 0.773196\n",
      "Epoch 19341 - Train Loss: 0.088075, Train Acc: 0.862821 | Val Loss: 0.115734, Val Acc: 0.773196\n",
      "Epoch 19342 - Train Loss: 0.088072, Train Acc: 0.862821 | Val Loss: 0.115733, Val Acc: 0.773196\n",
      "Epoch 19343 - Train Loss: 0.088070, Train Acc: 0.862821 | Val Loss: 0.115732, Val Acc: 0.773196\n",
      "Epoch 19344 - Train Loss: 0.088067, Train Acc: 0.862821 | Val Loss: 0.115731, Val Acc: 0.773196\n",
      "Epoch 19345 - Train Loss: 0.088065, Train Acc: 0.862821 | Val Loss: 0.115730, Val Acc: 0.773196\n",
      "Epoch 19346 - Train Loss: 0.088063, Train Acc: 0.862821 | Val Loss: 0.115729, Val Acc: 0.773196\n",
      "Epoch 19347 - Train Loss: 0.088060, Train Acc: 0.862821 | Val Loss: 0.115727, Val Acc: 0.773196\n",
      "Epoch 19348 - Train Loss: 0.088058, Train Acc: 0.862821 | Val Loss: 0.115726, Val Acc: 0.773196\n",
      "Epoch 19349 - Train Loss: 0.088056, Train Acc: 0.862821 | Val Loss: 0.115725, Val Acc: 0.773196\n",
      "Epoch 19350 - Train Loss: 0.088053, Train Acc: 0.862821 | Val Loss: 0.115724, Val Acc: 0.773196\n",
      "Epoch 19351 - Train Loss: 0.088051, Train Acc: 0.862821 | Val Loss: 0.115723, Val Acc: 0.773196\n",
      "Epoch 19352 - Train Loss: 0.088049, Train Acc: 0.862821 | Val Loss: 0.115722, Val Acc: 0.773196\n",
      "Epoch 19353 - Train Loss: 0.088046, Train Acc: 0.862821 | Val Loss: 0.115720, Val Acc: 0.773196\n",
      "Epoch 19354 - Train Loss: 0.088044, Train Acc: 0.862821 | Val Loss: 0.115719, Val Acc: 0.773196\n",
      "Epoch 19355 - Train Loss: 0.088041, Train Acc: 0.862821 | Val Loss: 0.115718, Val Acc: 0.773196\n",
      "Epoch 19356 - Train Loss: 0.088039, Train Acc: 0.862821 | Val Loss: 0.115717, Val Acc: 0.773196\n",
      "Epoch 19357 - Train Loss: 0.088037, Train Acc: 0.862821 | Val Loss: 0.115716, Val Acc: 0.773196\n",
      "Epoch 19358 - Train Loss: 0.088034, Train Acc: 0.862821 | Val Loss: 0.115715, Val Acc: 0.773196\n",
      "Epoch 19359 - Train Loss: 0.088032, Train Acc: 0.862821 | Val Loss: 0.115713, Val Acc: 0.773196\n",
      "Epoch 19360 - Train Loss: 0.088030, Train Acc: 0.861538 | Val Loss: 0.115712, Val Acc: 0.773196\n",
      "Epoch 19361 - Train Loss: 0.088027, Train Acc: 0.861538 | Val Loss: 0.115711, Val Acc: 0.773196\n",
      "Epoch 19362 - Train Loss: 0.088025, Train Acc: 0.861538 | Val Loss: 0.115710, Val Acc: 0.773196\n",
      "Epoch 19363 - Train Loss: 0.088022, Train Acc: 0.861538 | Val Loss: 0.115709, Val Acc: 0.773196\n",
      "Epoch 19364 - Train Loss: 0.088020, Train Acc: 0.861538 | Val Loss: 0.115708, Val Acc: 0.773196\n",
      "Epoch 19365 - Train Loss: 0.088018, Train Acc: 0.861538 | Val Loss: 0.115706, Val Acc: 0.773196\n",
      "Epoch 19366 - Train Loss: 0.088015, Train Acc: 0.861538 | Val Loss: 0.115705, Val Acc: 0.773196\n",
      "Epoch 19367 - Train Loss: 0.088013, Train Acc: 0.861538 | Val Loss: 0.115704, Val Acc: 0.773196\n",
      "Epoch 19368 - Train Loss: 0.088011, Train Acc: 0.861538 | Val Loss: 0.115703, Val Acc: 0.773196\n",
      "Epoch 19369 - Train Loss: 0.088008, Train Acc: 0.861538 | Val Loss: 0.115702, Val Acc: 0.773196\n",
      "Epoch 19370 - Train Loss: 0.088006, Train Acc: 0.861538 | Val Loss: 0.115701, Val Acc: 0.773196\n",
      "Epoch 19371 - Train Loss: 0.088004, Train Acc: 0.861538 | Val Loss: 0.115699, Val Acc: 0.773196\n",
      "Epoch 19372 - Train Loss: 0.088001, Train Acc: 0.861538 | Val Loss: 0.115698, Val Acc: 0.773196\n",
      "Epoch 19373 - Train Loss: 0.087999, Train Acc: 0.861538 | Val Loss: 0.115697, Val Acc: 0.773196\n",
      "Epoch 19374 - Train Loss: 0.087996, Train Acc: 0.861538 | Val Loss: 0.115696, Val Acc: 0.773196\n",
      "Epoch 19375 - Train Loss: 0.087994, Train Acc: 0.861538 | Val Loss: 0.115695, Val Acc: 0.773196\n",
      "Epoch 19376 - Train Loss: 0.087992, Train Acc: 0.861538 | Val Loss: 0.115694, Val Acc: 0.773196\n",
      "Epoch 19377 - Train Loss: 0.087989, Train Acc: 0.861538 | Val Loss: 0.115692, Val Acc: 0.773196\n",
      "Epoch 19378 - Train Loss: 0.087987, Train Acc: 0.861538 | Val Loss: 0.115691, Val Acc: 0.773196\n",
      "Epoch 19379 - Train Loss: 0.087985, Train Acc: 0.861538 | Val Loss: 0.115690, Val Acc: 0.773196\n",
      "Epoch 19380 - Train Loss: 0.087982, Train Acc: 0.861538 | Val Loss: 0.115689, Val Acc: 0.773196\n",
      "Epoch 19381 - Train Loss: 0.087980, Train Acc: 0.861538 | Val Loss: 0.115688, Val Acc: 0.773196\n",
      "Epoch 19382 - Train Loss: 0.087978, Train Acc: 0.861538 | Val Loss: 0.115687, Val Acc: 0.773196\n",
      "Epoch 19383 - Train Loss: 0.087975, Train Acc: 0.861538 | Val Loss: 0.115685, Val Acc: 0.773196\n",
      "Epoch 19384 - Train Loss: 0.087973, Train Acc: 0.861538 | Val Loss: 0.115684, Val Acc: 0.773196\n",
      "Epoch 19385 - Train Loss: 0.087970, Train Acc: 0.861538 | Val Loss: 0.115683, Val Acc: 0.773196\n",
      "Epoch 19386 - Train Loss: 0.087968, Train Acc: 0.861538 | Val Loss: 0.115682, Val Acc: 0.773196\n",
      "Epoch 19387 - Train Loss: 0.087966, Train Acc: 0.861538 | Val Loss: 0.115681, Val Acc: 0.773196\n",
      "Epoch 19388 - Train Loss: 0.087963, Train Acc: 0.861538 | Val Loss: 0.115680, Val Acc: 0.773196\n",
      "Epoch 19389 - Train Loss: 0.087961, Train Acc: 0.861538 | Val Loss: 0.115678, Val Acc: 0.773196\n",
      "Epoch 19390 - Train Loss: 0.087959, Train Acc: 0.861538 | Val Loss: 0.115677, Val Acc: 0.773196\n",
      "Epoch 19391 - Train Loss: 0.087956, Train Acc: 0.861538 | Val Loss: 0.115676, Val Acc: 0.773196\n",
      "Epoch 19392 - Train Loss: 0.087954, Train Acc: 0.861538 | Val Loss: 0.115675, Val Acc: 0.773196\n",
      "Epoch 19393 - Train Loss: 0.087952, Train Acc: 0.861538 | Val Loss: 0.115674, Val Acc: 0.773196\n",
      "Epoch 19394 - Train Loss: 0.087949, Train Acc: 0.861538 | Val Loss: 0.115673, Val Acc: 0.773196\n",
      "Epoch 19395 - Train Loss: 0.087947, Train Acc: 0.861538 | Val Loss: 0.115672, Val Acc: 0.773196\n",
      "Epoch 19396 - Train Loss: 0.087944, Train Acc: 0.861538 | Val Loss: 0.115670, Val Acc: 0.773196\n",
      "Epoch 19397 - Train Loss: 0.087942, Train Acc: 0.861538 | Val Loss: 0.115669, Val Acc: 0.773196\n",
      "Epoch 19398 - Train Loss: 0.087940, Train Acc: 0.861538 | Val Loss: 0.115668, Val Acc: 0.773196\n",
      "Epoch 19399 - Train Loss: 0.087937, Train Acc: 0.861538 | Val Loss: 0.115667, Val Acc: 0.773196\n",
      "Epoch 19400 - Train Loss: 0.087935, Train Acc: 0.861538 | Val Loss: 0.115666, Val Acc: 0.773196\n",
      "Epoch 19401 - Train Loss: 0.087933, Train Acc: 0.861538 | Val Loss: 0.115665, Val Acc: 0.773196\n",
      "Epoch 19402 - Train Loss: 0.087930, Train Acc: 0.861538 | Val Loss: 0.115663, Val Acc: 0.773196\n",
      "Epoch 19403 - Train Loss: 0.087928, Train Acc: 0.861538 | Val Loss: 0.115662, Val Acc: 0.773196\n",
      "Epoch 19404 - Train Loss: 0.087926, Train Acc: 0.861538 | Val Loss: 0.115661, Val Acc: 0.773196\n",
      "Epoch 19405 - Train Loss: 0.087923, Train Acc: 0.861538 | Val Loss: 0.115660, Val Acc: 0.773196\n",
      "Epoch 19406 - Train Loss: 0.087921, Train Acc: 0.861538 | Val Loss: 0.115659, Val Acc: 0.773196\n",
      "Epoch 19407 - Train Loss: 0.087918, Train Acc: 0.861538 | Val Loss: 0.115658, Val Acc: 0.773196\n",
      "Epoch 19408 - Train Loss: 0.087916, Train Acc: 0.861538 | Val Loss: 0.115656, Val Acc: 0.773196\n",
      "Epoch 19409 - Train Loss: 0.087914, Train Acc: 0.861538 | Val Loss: 0.115655, Val Acc: 0.773196\n",
      "Epoch 19410 - Train Loss: 0.087911, Train Acc: 0.861538 | Val Loss: 0.115654, Val Acc: 0.773196\n",
      "Epoch 19411 - Train Loss: 0.087909, Train Acc: 0.861538 | Val Loss: 0.115653, Val Acc: 0.773196\n",
      "Epoch 19412 - Train Loss: 0.087907, Train Acc: 0.861538 | Val Loss: 0.115652, Val Acc: 0.773196\n",
      "Epoch 19413 - Train Loss: 0.087904, Train Acc: 0.861538 | Val Loss: 0.115651, Val Acc: 0.773196\n",
      "Epoch 19414 - Train Loss: 0.087902, Train Acc: 0.861538 | Val Loss: 0.115649, Val Acc: 0.773196\n",
      "Epoch 19415 - Train Loss: 0.087900, Train Acc: 0.861538 | Val Loss: 0.115648, Val Acc: 0.773196\n",
      "Epoch 19416 - Train Loss: 0.087897, Train Acc: 0.861538 | Val Loss: 0.115647, Val Acc: 0.773196\n",
      "Epoch 19417 - Train Loss: 0.087895, Train Acc: 0.861538 | Val Loss: 0.115646, Val Acc: 0.773196\n",
      "Epoch 19418 - Train Loss: 0.087893, Train Acc: 0.861538 | Val Loss: 0.115645, Val Acc: 0.773196\n",
      "Epoch 19419 - Train Loss: 0.087890, Train Acc: 0.861538 | Val Loss: 0.115644, Val Acc: 0.773196\n",
      "Epoch 19420 - Train Loss: 0.087888, Train Acc: 0.861538 | Val Loss: 0.115643, Val Acc: 0.773196\n",
      "Epoch 19421 - Train Loss: 0.087885, Train Acc: 0.861538 | Val Loss: 0.115641, Val Acc: 0.773196\n",
      "Epoch 19422 - Train Loss: 0.087883, Train Acc: 0.861538 | Val Loss: 0.115640, Val Acc: 0.773196\n",
      "Epoch 19423 - Train Loss: 0.087881, Train Acc: 0.861538 | Val Loss: 0.115639, Val Acc: 0.773196\n",
      "Epoch 19424 - Train Loss: 0.087878, Train Acc: 0.861538 | Val Loss: 0.115638, Val Acc: 0.773196\n",
      "Epoch 19425 - Train Loss: 0.087876, Train Acc: 0.861538 | Val Loss: 0.115637, Val Acc: 0.773196\n",
      "Epoch 19426 - Train Loss: 0.087874, Train Acc: 0.861538 | Val Loss: 0.115636, Val Acc: 0.773196\n",
      "Epoch 19427 - Train Loss: 0.087871, Train Acc: 0.861538 | Val Loss: 0.115634, Val Acc: 0.773196\n",
      "Epoch 19428 - Train Loss: 0.087869, Train Acc: 0.861538 | Val Loss: 0.115633, Val Acc: 0.773196\n",
      "Epoch 19429 - Train Loss: 0.087867, Train Acc: 0.861538 | Val Loss: 0.115632, Val Acc: 0.773196\n",
      "Epoch 19430 - Train Loss: 0.087864, Train Acc: 0.861538 | Val Loss: 0.115631, Val Acc: 0.773196\n",
      "Epoch 19431 - Train Loss: 0.087862, Train Acc: 0.861538 | Val Loss: 0.115630, Val Acc: 0.773196\n",
      "Epoch 19432 - Train Loss: 0.087860, Train Acc: 0.861538 | Val Loss: 0.115629, Val Acc: 0.773196\n",
      "Epoch 19433 - Train Loss: 0.087857, Train Acc: 0.861538 | Val Loss: 0.115628, Val Acc: 0.773196\n",
      "Epoch 19434 - Train Loss: 0.087855, Train Acc: 0.861538 | Val Loss: 0.115626, Val Acc: 0.773196\n",
      "Epoch 19435 - Train Loss: 0.087853, Train Acc: 0.861538 | Val Loss: 0.115625, Val Acc: 0.773196\n",
      "Epoch 19436 - Train Loss: 0.087850, Train Acc: 0.861538 | Val Loss: 0.115624, Val Acc: 0.773196\n",
      "Epoch 19437 - Train Loss: 0.087848, Train Acc: 0.861538 | Val Loss: 0.115623, Val Acc: 0.773196\n",
      "Epoch 19438 - Train Loss: 0.087845, Train Acc: 0.861538 | Val Loss: 0.115622, Val Acc: 0.773196\n",
      "Epoch 19439 - Train Loss: 0.087843, Train Acc: 0.861538 | Val Loss: 0.115621, Val Acc: 0.773196\n",
      "Epoch 19440 - Train Loss: 0.087841, Train Acc: 0.861538 | Val Loss: 0.115619, Val Acc: 0.773196\n",
      "Epoch 19441 - Train Loss: 0.087838, Train Acc: 0.861538 | Val Loss: 0.115618, Val Acc: 0.773196\n",
      "Epoch 19442 - Train Loss: 0.087836, Train Acc: 0.861538 | Val Loss: 0.115617, Val Acc: 0.773196\n",
      "Epoch 19443 - Train Loss: 0.087834, Train Acc: 0.861538 | Val Loss: 0.115616, Val Acc: 0.773196\n",
      "Epoch 19444 - Train Loss: 0.087831, Train Acc: 0.861538 | Val Loss: 0.115615, Val Acc: 0.773196\n",
      "Epoch 19445 - Train Loss: 0.087829, Train Acc: 0.861538 | Val Loss: 0.115614, Val Acc: 0.773196\n",
      "Epoch 19446 - Train Loss: 0.087827, Train Acc: 0.861538 | Val Loss: 0.115613, Val Acc: 0.773196\n",
      "Epoch 19447 - Train Loss: 0.087824, Train Acc: 0.861538 | Val Loss: 0.115611, Val Acc: 0.773196\n",
      "Epoch 19448 - Train Loss: 0.087822, Train Acc: 0.861538 | Val Loss: 0.115610, Val Acc: 0.773196\n",
      "Epoch 19449 - Train Loss: 0.087820, Train Acc: 0.861538 | Val Loss: 0.115609, Val Acc: 0.773196\n",
      "Epoch 19450 - Train Loss: 0.087817, Train Acc: 0.861538 | Val Loss: 0.115608, Val Acc: 0.773196\n",
      "Epoch 19451 - Train Loss: 0.087815, Train Acc: 0.861538 | Val Loss: 0.115607, Val Acc: 0.773196\n",
      "Epoch 19452 - Train Loss: 0.087813, Train Acc: 0.861538 | Val Loss: 0.115606, Val Acc: 0.773196\n",
      "Epoch 19453 - Train Loss: 0.087810, Train Acc: 0.861538 | Val Loss: 0.115604, Val Acc: 0.773196\n",
      "Epoch 19454 - Train Loss: 0.087808, Train Acc: 0.861538 | Val Loss: 0.115603, Val Acc: 0.773196\n",
      "Epoch 19455 - Train Loss: 0.087806, Train Acc: 0.861538 | Val Loss: 0.115602, Val Acc: 0.773196\n",
      "Epoch 19456 - Train Loss: 0.087803, Train Acc: 0.861538 | Val Loss: 0.115601, Val Acc: 0.773196\n",
      "Epoch 19457 - Train Loss: 0.087801, Train Acc: 0.861538 | Val Loss: 0.115600, Val Acc: 0.773196\n",
      "Epoch 19458 - Train Loss: 0.087799, Train Acc: 0.861538 | Val Loss: 0.115599, Val Acc: 0.773196\n",
      "Epoch 19459 - Train Loss: 0.087796, Train Acc: 0.861538 | Val Loss: 0.115598, Val Acc: 0.773196\n",
      "Epoch 19460 - Train Loss: 0.087794, Train Acc: 0.861538 | Val Loss: 0.115596, Val Acc: 0.773196\n",
      "Epoch 19461 - Train Loss: 0.087791, Train Acc: 0.861538 | Val Loss: 0.115595, Val Acc: 0.773196\n",
      "Epoch 19462 - Train Loss: 0.087789, Train Acc: 0.861538 | Val Loss: 0.115594, Val Acc: 0.773196\n",
      "Epoch 19463 - Train Loss: 0.087787, Train Acc: 0.861538 | Val Loss: 0.115593, Val Acc: 0.773196\n",
      "Epoch 19464 - Train Loss: 0.087784, Train Acc: 0.861538 | Val Loss: 0.115592, Val Acc: 0.773196\n",
      "Epoch 19465 - Train Loss: 0.087782, Train Acc: 0.861538 | Val Loss: 0.115591, Val Acc: 0.773196\n",
      "Epoch 19466 - Train Loss: 0.087780, Train Acc: 0.861538 | Val Loss: 0.115590, Val Acc: 0.773196\n",
      "Epoch 19467 - Train Loss: 0.087777, Train Acc: 0.861538 | Val Loss: 0.115588, Val Acc: 0.773196\n",
      "Epoch 19468 - Train Loss: 0.087775, Train Acc: 0.861538 | Val Loss: 0.115587, Val Acc: 0.773196\n",
      "Epoch 19469 - Train Loss: 0.087773, Train Acc: 0.861538 | Val Loss: 0.115586, Val Acc: 0.773196\n",
      "Epoch 19470 - Train Loss: 0.087770, Train Acc: 0.861538 | Val Loss: 0.115585, Val Acc: 0.773196\n",
      "Epoch 19471 - Train Loss: 0.087768, Train Acc: 0.861538 | Val Loss: 0.115584, Val Acc: 0.773196\n",
      "Epoch 19472 - Train Loss: 0.087766, Train Acc: 0.861538 | Val Loss: 0.115583, Val Acc: 0.773196\n",
      "Epoch 19473 - Train Loss: 0.087763, Train Acc: 0.861538 | Val Loss: 0.115581, Val Acc: 0.773196\n",
      "Epoch 19474 - Train Loss: 0.087761, Train Acc: 0.861538 | Val Loss: 0.115580, Val Acc: 0.773196\n",
      "Epoch 19475 - Train Loss: 0.087759, Train Acc: 0.861538 | Val Loss: 0.115579, Val Acc: 0.773196\n",
      "Epoch 19476 - Train Loss: 0.087756, Train Acc: 0.861538 | Val Loss: 0.115578, Val Acc: 0.773196\n",
      "Epoch 19477 - Train Loss: 0.087754, Train Acc: 0.861538 | Val Loss: 0.115577, Val Acc: 0.773196\n",
      "Epoch 19478 - Train Loss: 0.087752, Train Acc: 0.861538 | Val Loss: 0.115576, Val Acc: 0.773196\n",
      "Epoch 19479 - Train Loss: 0.087749, Train Acc: 0.861538 | Val Loss: 0.115575, Val Acc: 0.773196\n",
      "Epoch 19480 - Train Loss: 0.087747, Train Acc: 0.861538 | Val Loss: 0.115573, Val Acc: 0.773196\n",
      "Epoch 19481 - Train Loss: 0.087745, Train Acc: 0.861538 | Val Loss: 0.115572, Val Acc: 0.773196\n",
      "Epoch 19482 - Train Loss: 0.087742, Train Acc: 0.861538 | Val Loss: 0.115571, Val Acc: 0.773196\n",
      "Epoch 19483 - Train Loss: 0.087740, Train Acc: 0.861538 | Val Loss: 0.115570, Val Acc: 0.773196\n",
      "Epoch 19484 - Train Loss: 0.087738, Train Acc: 0.861538 | Val Loss: 0.115569, Val Acc: 0.773196\n",
      "Epoch 19485 - Train Loss: 0.087735, Train Acc: 0.861538 | Val Loss: 0.115568, Val Acc: 0.773196\n",
      "Epoch 19486 - Train Loss: 0.087733, Train Acc: 0.861538 | Val Loss: 0.115567, Val Acc: 0.773196\n",
      "Epoch 19487 - Train Loss: 0.087731, Train Acc: 0.861538 | Val Loss: 0.115565, Val Acc: 0.773196\n",
      "Epoch 19488 - Train Loss: 0.087728, Train Acc: 0.861538 | Val Loss: 0.115564, Val Acc: 0.773196\n",
      "Epoch 19489 - Train Loss: 0.087726, Train Acc: 0.861538 | Val Loss: 0.115563, Val Acc: 0.773196\n",
      "Epoch 19490 - Train Loss: 0.087724, Train Acc: 0.861538 | Val Loss: 0.115562, Val Acc: 0.773196\n",
      "Epoch 19491 - Train Loss: 0.087721, Train Acc: 0.861538 | Val Loss: 0.115561, Val Acc: 0.773196\n",
      "Epoch 19492 - Train Loss: 0.087719, Train Acc: 0.861538 | Val Loss: 0.115560, Val Acc: 0.773196\n",
      "Epoch 19493 - Train Loss: 0.087716, Train Acc: 0.861538 | Val Loss: 0.115559, Val Acc: 0.773196\n",
      "Epoch 19494 - Train Loss: 0.087714, Train Acc: 0.861538 | Val Loss: 0.115557, Val Acc: 0.773196\n",
      "Epoch 19495 - Train Loss: 0.087712, Train Acc: 0.861538 | Val Loss: 0.115556, Val Acc: 0.773196\n",
      "Epoch 19496 - Train Loss: 0.087709, Train Acc: 0.861538 | Val Loss: 0.115555, Val Acc: 0.773196\n",
      "Epoch 19497 - Train Loss: 0.087707, Train Acc: 0.861538 | Val Loss: 0.115554, Val Acc: 0.773196\n",
      "Epoch 19498 - Train Loss: 0.087705, Train Acc: 0.861538 | Val Loss: 0.115553, Val Acc: 0.773196\n",
      "Epoch 19499 - Train Loss: 0.087702, Train Acc: 0.861538 | Val Loss: 0.115552, Val Acc: 0.773196\n",
      "Epoch 19500 - Train Loss: 0.087700, Train Acc: 0.861538 | Val Loss: 0.115550, Val Acc: 0.773196\n",
      "Epoch 19501 - Train Loss: 0.087698, Train Acc: 0.861538 | Val Loss: 0.115549, Val Acc: 0.773196\n",
      "Epoch 19502 - Train Loss: 0.087695, Train Acc: 0.861538 | Val Loss: 0.115548, Val Acc: 0.773196\n",
      "Epoch 19503 - Train Loss: 0.087693, Train Acc: 0.861538 | Val Loss: 0.115547, Val Acc: 0.773196\n",
      "Epoch 19504 - Train Loss: 0.087691, Train Acc: 0.861538 | Val Loss: 0.115546, Val Acc: 0.773196\n",
      "Epoch 19505 - Train Loss: 0.087688, Train Acc: 0.861538 | Val Loss: 0.115545, Val Acc: 0.773196\n",
      "Epoch 19506 - Train Loss: 0.087686, Train Acc: 0.861538 | Val Loss: 0.115544, Val Acc: 0.773196\n",
      "Epoch 19507 - Train Loss: 0.087684, Train Acc: 0.861538 | Val Loss: 0.115542, Val Acc: 0.773196\n",
      "Epoch 19508 - Train Loss: 0.087681, Train Acc: 0.861538 | Val Loss: 0.115541, Val Acc: 0.773196\n",
      "Epoch 19509 - Train Loss: 0.087679, Train Acc: 0.861538 | Val Loss: 0.115540, Val Acc: 0.773196\n",
      "Epoch 19510 - Train Loss: 0.087677, Train Acc: 0.861538 | Val Loss: 0.115539, Val Acc: 0.773196\n",
      "Epoch 19511 - Train Loss: 0.087674, Train Acc: 0.861538 | Val Loss: 0.115538, Val Acc: 0.773196\n",
      "Epoch 19512 - Train Loss: 0.087672, Train Acc: 0.861538 | Val Loss: 0.115537, Val Acc: 0.773196\n",
      "Epoch 19513 - Train Loss: 0.087670, Train Acc: 0.861538 | Val Loss: 0.115536, Val Acc: 0.773196\n",
      "Epoch 19514 - Train Loss: 0.087667, Train Acc: 0.861538 | Val Loss: 0.115534, Val Acc: 0.773196\n",
      "Epoch 19515 - Train Loss: 0.087665, Train Acc: 0.861538 | Val Loss: 0.115533, Val Acc: 0.773196\n",
      "Epoch 19516 - Train Loss: 0.087663, Train Acc: 0.861538 | Val Loss: 0.115532, Val Acc: 0.773196\n",
      "Epoch 19517 - Train Loss: 0.087660, Train Acc: 0.861538 | Val Loss: 0.115531, Val Acc: 0.773196\n",
      "Epoch 19518 - Train Loss: 0.087658, Train Acc: 0.861538 | Val Loss: 0.115530, Val Acc: 0.773196\n",
      "Epoch 19519 - Train Loss: 0.087656, Train Acc: 0.861538 | Val Loss: 0.115529, Val Acc: 0.773196\n",
      "Epoch 19520 - Train Loss: 0.087653, Train Acc: 0.861538 | Val Loss: 0.115528, Val Acc: 0.773196\n",
      "Epoch 19521 - Train Loss: 0.087651, Train Acc: 0.861538 | Val Loss: 0.115527, Val Acc: 0.773196\n",
      "Epoch 19522 - Train Loss: 0.087649, Train Acc: 0.861538 | Val Loss: 0.115525, Val Acc: 0.773196\n",
      "Epoch 19523 - Train Loss: 0.087646, Train Acc: 0.861538 | Val Loss: 0.115524, Val Acc: 0.773196\n",
      "Epoch 19524 - Train Loss: 0.087644, Train Acc: 0.861538 | Val Loss: 0.115523, Val Acc: 0.773196\n",
      "Epoch 19525 - Train Loss: 0.087642, Train Acc: 0.861538 | Val Loss: 0.115522, Val Acc: 0.773196\n",
      "Epoch 19526 - Train Loss: 0.087639, Train Acc: 0.861538 | Val Loss: 0.115521, Val Acc: 0.773196\n",
      "Epoch 19527 - Train Loss: 0.087637, Train Acc: 0.861538 | Val Loss: 0.115520, Val Acc: 0.773196\n",
      "Epoch 19528 - Train Loss: 0.087635, Train Acc: 0.861538 | Val Loss: 0.115519, Val Acc: 0.773196\n",
      "Epoch 19529 - Train Loss: 0.087632, Train Acc: 0.861538 | Val Loss: 0.115517, Val Acc: 0.773196\n",
      "Epoch 19530 - Train Loss: 0.087630, Train Acc: 0.861538 | Val Loss: 0.115516, Val Acc: 0.773196\n",
      "Epoch 19531 - Train Loss: 0.087628, Train Acc: 0.861538 | Val Loss: 0.115515, Val Acc: 0.773196\n",
      "Epoch 19532 - Train Loss: 0.087625, Train Acc: 0.861538 | Val Loss: 0.115514, Val Acc: 0.773196\n",
      "Epoch 19533 - Train Loss: 0.087623, Train Acc: 0.861538 | Val Loss: 0.115513, Val Acc: 0.773196\n",
      "Epoch 19534 - Train Loss: 0.087621, Train Acc: 0.861538 | Val Loss: 0.115512, Val Acc: 0.773196\n",
      "Epoch 19535 - Train Loss: 0.087618, Train Acc: 0.861538 | Val Loss: 0.115511, Val Acc: 0.773196\n",
      "Epoch 19536 - Train Loss: 0.087616, Train Acc: 0.861538 | Val Loss: 0.115509, Val Acc: 0.773196\n",
      "Epoch 19537 - Train Loss: 0.087614, Train Acc: 0.861538 | Val Loss: 0.115508, Val Acc: 0.773196\n",
      "Epoch 19538 - Train Loss: 0.087611, Train Acc: 0.861538 | Val Loss: 0.115507, Val Acc: 0.773196\n",
      "Epoch 19539 - Train Loss: 0.087609, Train Acc: 0.861538 | Val Loss: 0.115506, Val Acc: 0.773196\n",
      "Epoch 19540 - Train Loss: 0.087607, Train Acc: 0.861538 | Val Loss: 0.115505, Val Acc: 0.773196\n",
      "Epoch 19541 - Train Loss: 0.087604, Train Acc: 0.861538 | Val Loss: 0.115504, Val Acc: 0.773196\n",
      "Epoch 19542 - Train Loss: 0.087602, Train Acc: 0.861538 | Val Loss: 0.115503, Val Acc: 0.773196\n",
      "Epoch 19543 - Train Loss: 0.087600, Train Acc: 0.861538 | Val Loss: 0.115501, Val Acc: 0.773196\n",
      "Epoch 19544 - Train Loss: 0.087597, Train Acc: 0.861538 | Val Loss: 0.115500, Val Acc: 0.773196\n",
      "Epoch 19545 - Train Loss: 0.087595, Train Acc: 0.861538 | Val Loss: 0.115499, Val Acc: 0.773196\n",
      "Epoch 19546 - Train Loss: 0.087593, Train Acc: 0.861538 | Val Loss: 0.115498, Val Acc: 0.773196\n",
      "Epoch 19547 - Train Loss: 0.087590, Train Acc: 0.861538 | Val Loss: 0.115497, Val Acc: 0.773196\n",
      "Epoch 19548 - Train Loss: 0.087588, Train Acc: 0.861538 | Val Loss: 0.115496, Val Acc: 0.773196\n",
      "Epoch 19549 - Train Loss: 0.087586, Train Acc: 0.861538 | Val Loss: 0.115495, Val Acc: 0.773196\n",
      "Epoch 19550 - Train Loss: 0.087583, Train Acc: 0.861538 | Val Loss: 0.115493, Val Acc: 0.773196\n",
      "Epoch 19551 - Train Loss: 0.087581, Train Acc: 0.861538 | Val Loss: 0.115492, Val Acc: 0.773196\n",
      "Epoch 19552 - Train Loss: 0.087579, Train Acc: 0.861538 | Val Loss: 0.115491, Val Acc: 0.773196\n",
      "Epoch 19553 - Train Loss: 0.087576, Train Acc: 0.861538 | Val Loss: 0.115490, Val Acc: 0.773196\n",
      "Epoch 19554 - Train Loss: 0.087574, Train Acc: 0.861538 | Val Loss: 0.115489, Val Acc: 0.773196\n",
      "Epoch 19555 - Train Loss: 0.087572, Train Acc: 0.861538 | Val Loss: 0.115488, Val Acc: 0.773196\n",
      "Epoch 19556 - Train Loss: 0.087569, Train Acc: 0.861538 | Val Loss: 0.115487, Val Acc: 0.773196\n",
      "Epoch 19557 - Train Loss: 0.087567, Train Acc: 0.861538 | Val Loss: 0.115486, Val Acc: 0.773196\n",
      "Epoch 19558 - Train Loss: 0.087565, Train Acc: 0.861538 | Val Loss: 0.115484, Val Acc: 0.773196\n",
      "Epoch 19559 - Train Loss: 0.087562, Train Acc: 0.861538 | Val Loss: 0.115483, Val Acc: 0.773196\n",
      "Epoch 19560 - Train Loss: 0.087560, Train Acc: 0.861538 | Val Loss: 0.115482, Val Acc: 0.773196\n",
      "Epoch 19561 - Train Loss: 0.087558, Train Acc: 0.861538 | Val Loss: 0.115481, Val Acc: 0.773196\n",
      "Epoch 19562 - Train Loss: 0.087556, Train Acc: 0.861538 | Val Loss: 0.115480, Val Acc: 0.773196\n",
      "Epoch 19563 - Train Loss: 0.087553, Train Acc: 0.861538 | Val Loss: 0.115479, Val Acc: 0.773196\n",
      "Epoch 19564 - Train Loss: 0.087551, Train Acc: 0.861538 | Val Loss: 0.115478, Val Acc: 0.773196\n",
      "Epoch 19565 - Train Loss: 0.087549, Train Acc: 0.861538 | Val Loss: 0.115476, Val Acc: 0.773196\n",
      "Epoch 19566 - Train Loss: 0.087546, Train Acc: 0.861538 | Val Loss: 0.115475, Val Acc: 0.773196\n",
      "Epoch 19567 - Train Loss: 0.087544, Train Acc: 0.861538 | Val Loss: 0.115474, Val Acc: 0.773196\n",
      "Epoch 19568 - Train Loss: 0.087542, Train Acc: 0.861538 | Val Loss: 0.115473, Val Acc: 0.773196\n",
      "Epoch 19569 - Train Loss: 0.087539, Train Acc: 0.861538 | Val Loss: 0.115472, Val Acc: 0.773196\n",
      "Epoch 19570 - Train Loss: 0.087537, Train Acc: 0.861538 | Val Loss: 0.115471, Val Acc: 0.773196\n",
      "Epoch 19571 - Train Loss: 0.087535, Train Acc: 0.861538 | Val Loss: 0.115470, Val Acc: 0.773196\n",
      "Epoch 19572 - Train Loss: 0.087532, Train Acc: 0.861538 | Val Loss: 0.115469, Val Acc: 0.773196\n",
      "Epoch 19573 - Train Loss: 0.087530, Train Acc: 0.861538 | Val Loss: 0.115467, Val Acc: 0.773196\n",
      "Epoch 19574 - Train Loss: 0.087528, Train Acc: 0.861538 | Val Loss: 0.115466, Val Acc: 0.773196\n",
      "Epoch 19575 - Train Loss: 0.087525, Train Acc: 0.861538 | Val Loss: 0.115465, Val Acc: 0.773196\n",
      "Epoch 19576 - Train Loss: 0.087523, Train Acc: 0.861538 | Val Loss: 0.115464, Val Acc: 0.773196\n",
      "Epoch 19577 - Train Loss: 0.087521, Train Acc: 0.861538 | Val Loss: 0.115463, Val Acc: 0.773196\n",
      "Epoch 19578 - Train Loss: 0.087518, Train Acc: 0.861538 | Val Loss: 0.115462, Val Acc: 0.773196\n",
      "Epoch 19579 - Train Loss: 0.087516, Train Acc: 0.861538 | Val Loss: 0.115461, Val Acc: 0.773196\n",
      "Epoch 19580 - Train Loss: 0.087514, Train Acc: 0.861538 | Val Loss: 0.115460, Val Acc: 0.773196\n",
      "Epoch 19581 - Train Loss: 0.087511, Train Acc: 0.861538 | Val Loss: 0.115458, Val Acc: 0.773196\n",
      "Epoch 19582 - Train Loss: 0.087509, Train Acc: 0.861538 | Val Loss: 0.115457, Val Acc: 0.773196\n",
      "Epoch 19583 - Train Loss: 0.087507, Train Acc: 0.861538 | Val Loss: 0.115456, Val Acc: 0.773196\n",
      "Epoch 19584 - Train Loss: 0.087504, Train Acc: 0.861538 | Val Loss: 0.115455, Val Acc: 0.773196\n",
      "Epoch 19585 - Train Loss: 0.087502, Train Acc: 0.861538 | Val Loss: 0.115454, Val Acc: 0.773196\n",
      "Epoch 19586 - Train Loss: 0.087500, Train Acc: 0.862821 | Val Loss: 0.115453, Val Acc: 0.773196\n",
      "Epoch 19587 - Train Loss: 0.087497, Train Acc: 0.862821 | Val Loss: 0.115452, Val Acc: 0.773196\n",
      "Epoch 19588 - Train Loss: 0.087495, Train Acc: 0.862821 | Val Loss: 0.115450, Val Acc: 0.773196\n",
      "Epoch 19589 - Train Loss: 0.087493, Train Acc: 0.862821 | Val Loss: 0.115449, Val Acc: 0.773196\n",
      "Epoch 19590 - Train Loss: 0.087490, Train Acc: 0.862821 | Val Loss: 0.115448, Val Acc: 0.773196\n",
      "Epoch 19591 - Train Loss: 0.087488, Train Acc: 0.862821 | Val Loss: 0.115447, Val Acc: 0.773196\n",
      "Epoch 19592 - Train Loss: 0.087486, Train Acc: 0.862821 | Val Loss: 0.115446, Val Acc: 0.773196\n",
      "Epoch 19593 - Train Loss: 0.087484, Train Acc: 0.862821 | Val Loss: 0.115445, Val Acc: 0.773196\n",
      "Epoch 19594 - Train Loss: 0.087481, Train Acc: 0.862821 | Val Loss: 0.115444, Val Acc: 0.773196\n",
      "Epoch 19595 - Train Loss: 0.087479, Train Acc: 0.862821 | Val Loss: 0.115443, Val Acc: 0.773196\n",
      "Epoch 19596 - Train Loss: 0.087477, Train Acc: 0.862821 | Val Loss: 0.115441, Val Acc: 0.773196\n",
      "Epoch 19597 - Train Loss: 0.087474, Train Acc: 0.862821 | Val Loss: 0.115440, Val Acc: 0.773196\n",
      "Epoch 19598 - Train Loss: 0.087472, Train Acc: 0.862821 | Val Loss: 0.115439, Val Acc: 0.773196\n",
      "Epoch 19599 - Train Loss: 0.087470, Train Acc: 0.862821 | Val Loss: 0.115438, Val Acc: 0.773196\n",
      "Epoch 19600 - Train Loss: 0.087467, Train Acc: 0.862821 | Val Loss: 0.115437, Val Acc: 0.773196\n",
      "Epoch 19601 - Train Loss: 0.087465, Train Acc: 0.862821 | Val Loss: 0.115436, Val Acc: 0.773196\n",
      "Epoch 19602 - Train Loss: 0.087463, Train Acc: 0.862821 | Val Loss: 0.115435, Val Acc: 0.773196\n",
      "Epoch 19603 - Train Loss: 0.087460, Train Acc: 0.862821 | Val Loss: 0.115434, Val Acc: 0.773196\n",
      "Epoch 19604 - Train Loss: 0.087458, Train Acc: 0.862821 | Val Loss: 0.115432, Val Acc: 0.773196\n",
      "Epoch 19605 - Train Loss: 0.087456, Train Acc: 0.862821 | Val Loss: 0.115431, Val Acc: 0.773196\n",
      "Epoch 19606 - Train Loss: 0.087453, Train Acc: 0.862821 | Val Loss: 0.115430, Val Acc: 0.773196\n",
      "Epoch 19607 - Train Loss: 0.087451, Train Acc: 0.862821 | Val Loss: 0.115429, Val Acc: 0.773196\n",
      "Epoch 19608 - Train Loss: 0.087449, Train Acc: 0.862821 | Val Loss: 0.115428, Val Acc: 0.773196\n",
      "Epoch 19609 - Train Loss: 0.087446, Train Acc: 0.862821 | Val Loss: 0.115427, Val Acc: 0.773196\n",
      "Epoch 19610 - Train Loss: 0.087444, Train Acc: 0.862821 | Val Loss: 0.115426, Val Acc: 0.773196\n",
      "Epoch 19611 - Train Loss: 0.087442, Train Acc: 0.862821 | Val Loss: 0.115425, Val Acc: 0.773196\n",
      "Epoch 19612 - Train Loss: 0.087439, Train Acc: 0.862821 | Val Loss: 0.115423, Val Acc: 0.773196\n",
      "Epoch 19613 - Train Loss: 0.087437, Train Acc: 0.862821 | Val Loss: 0.115422, Val Acc: 0.773196\n",
      "Epoch 19614 - Train Loss: 0.087435, Train Acc: 0.862821 | Val Loss: 0.115421, Val Acc: 0.773196\n",
      "Epoch 19615 - Train Loss: 0.087433, Train Acc: 0.862821 | Val Loss: 0.115420, Val Acc: 0.773196\n",
      "Epoch 19616 - Train Loss: 0.087430, Train Acc: 0.862821 | Val Loss: 0.115419, Val Acc: 0.773196\n",
      "Epoch 19617 - Train Loss: 0.087428, Train Acc: 0.862821 | Val Loss: 0.115418, Val Acc: 0.773196\n",
      "Epoch 19618 - Train Loss: 0.087426, Train Acc: 0.862821 | Val Loss: 0.115417, Val Acc: 0.773196\n",
      "Epoch 19619 - Train Loss: 0.087423, Train Acc: 0.862821 | Val Loss: 0.115416, Val Acc: 0.773196\n",
      "Epoch 19620 - Train Loss: 0.087421, Train Acc: 0.862821 | Val Loss: 0.115414, Val Acc: 0.773196\n",
      "Epoch 19621 - Train Loss: 0.087419, Train Acc: 0.862821 | Val Loss: 0.115413, Val Acc: 0.773196\n",
      "Epoch 19622 - Train Loss: 0.087416, Train Acc: 0.862821 | Val Loss: 0.115412, Val Acc: 0.773196\n",
      "Epoch 19623 - Train Loss: 0.087414, Train Acc: 0.862821 | Val Loss: 0.115411, Val Acc: 0.773196\n",
      "Epoch 19624 - Train Loss: 0.087412, Train Acc: 0.862821 | Val Loss: 0.115410, Val Acc: 0.773196\n",
      "Epoch 19625 - Train Loss: 0.087409, Train Acc: 0.862821 | Val Loss: 0.115409, Val Acc: 0.773196\n",
      "Epoch 19626 - Train Loss: 0.087407, Train Acc: 0.862821 | Val Loss: 0.115408, Val Acc: 0.773196\n",
      "Epoch 19627 - Train Loss: 0.087405, Train Acc: 0.862821 | Val Loss: 0.115407, Val Acc: 0.773196\n",
      "Epoch 19628 - Train Loss: 0.087402, Train Acc: 0.862821 | Val Loss: 0.115405, Val Acc: 0.773196\n",
      "Epoch 19629 - Train Loss: 0.087400, Train Acc: 0.862821 | Val Loss: 0.115404, Val Acc: 0.773196\n",
      "Epoch 19630 - Train Loss: 0.087398, Train Acc: 0.862821 | Val Loss: 0.115403, Val Acc: 0.773196\n",
      "Epoch 19631 - Train Loss: 0.087395, Train Acc: 0.862821 | Val Loss: 0.115402, Val Acc: 0.773196\n",
      "Epoch 19632 - Train Loss: 0.087393, Train Acc: 0.862821 | Val Loss: 0.115401, Val Acc: 0.773196\n",
      "Epoch 19633 - Train Loss: 0.087391, Train Acc: 0.862821 | Val Loss: 0.115400, Val Acc: 0.773196\n",
      "Epoch 19634 - Train Loss: 0.087389, Train Acc: 0.862821 | Val Loss: 0.115399, Val Acc: 0.773196\n",
      "Epoch 19635 - Train Loss: 0.087386, Train Acc: 0.862821 | Val Loss: 0.115398, Val Acc: 0.773196\n",
      "Epoch 19636 - Train Loss: 0.087384, Train Acc: 0.862821 | Val Loss: 0.115397, Val Acc: 0.773196\n",
      "Epoch 19637 - Train Loss: 0.087382, Train Acc: 0.862821 | Val Loss: 0.115395, Val Acc: 0.773196\n",
      "Epoch 19638 - Train Loss: 0.087379, Train Acc: 0.862821 | Val Loss: 0.115394, Val Acc: 0.773196\n",
      "Epoch 19639 - Train Loss: 0.087377, Train Acc: 0.862821 | Val Loss: 0.115393, Val Acc: 0.773196\n",
      "Epoch 19640 - Train Loss: 0.087375, Train Acc: 0.862821 | Val Loss: 0.115392, Val Acc: 0.773196\n",
      "Epoch 19641 - Train Loss: 0.087372, Train Acc: 0.862821 | Val Loss: 0.115391, Val Acc: 0.773196\n",
      "Epoch 19642 - Train Loss: 0.087370, Train Acc: 0.862821 | Val Loss: 0.115390, Val Acc: 0.773196\n",
      "Epoch 19643 - Train Loss: 0.087368, Train Acc: 0.862821 | Val Loss: 0.115389, Val Acc: 0.773196\n",
      "Epoch 19644 - Train Loss: 0.087365, Train Acc: 0.862821 | Val Loss: 0.115388, Val Acc: 0.773196\n",
      "Epoch 19645 - Train Loss: 0.087363, Train Acc: 0.862821 | Val Loss: 0.115386, Val Acc: 0.773196\n",
      "Epoch 19646 - Train Loss: 0.087361, Train Acc: 0.862821 | Val Loss: 0.115385, Val Acc: 0.773196\n",
      "Epoch 19647 - Train Loss: 0.087359, Train Acc: 0.862821 | Val Loss: 0.115384, Val Acc: 0.773196\n",
      "Epoch 19648 - Train Loss: 0.087356, Train Acc: 0.862821 | Val Loss: 0.115383, Val Acc: 0.773196\n",
      "Epoch 19649 - Train Loss: 0.087354, Train Acc: 0.862821 | Val Loss: 0.115382, Val Acc: 0.773196\n",
      "Epoch 19650 - Train Loss: 0.087352, Train Acc: 0.862821 | Val Loss: 0.115381, Val Acc: 0.773196\n",
      "Epoch 19651 - Train Loss: 0.087349, Train Acc: 0.862821 | Val Loss: 0.115380, Val Acc: 0.773196\n",
      "Epoch 19652 - Train Loss: 0.087347, Train Acc: 0.862821 | Val Loss: 0.115379, Val Acc: 0.773196\n",
      "Epoch 19653 - Train Loss: 0.087345, Train Acc: 0.862821 | Val Loss: 0.115377, Val Acc: 0.773196\n",
      "Epoch 19654 - Train Loss: 0.087342, Train Acc: 0.862821 | Val Loss: 0.115376, Val Acc: 0.773196\n",
      "Epoch 19655 - Train Loss: 0.087340, Train Acc: 0.862821 | Val Loss: 0.115375, Val Acc: 0.773196\n",
      "Epoch 19656 - Train Loss: 0.087338, Train Acc: 0.862821 | Val Loss: 0.115374, Val Acc: 0.773196\n",
      "Epoch 19657 - Train Loss: 0.087335, Train Acc: 0.862821 | Val Loss: 0.115373, Val Acc: 0.773196\n",
      "Epoch 19658 - Train Loss: 0.087333, Train Acc: 0.862821 | Val Loss: 0.115372, Val Acc: 0.773196\n",
      "Epoch 19659 - Train Loss: 0.087331, Train Acc: 0.862821 | Val Loss: 0.115371, Val Acc: 0.773196\n",
      "Epoch 19660 - Train Loss: 0.087329, Train Acc: 0.862821 | Val Loss: 0.115370, Val Acc: 0.773196\n",
      "Epoch 19661 - Train Loss: 0.087326, Train Acc: 0.862821 | Val Loss: 0.115369, Val Acc: 0.773196\n",
      "Epoch 19662 - Train Loss: 0.087324, Train Acc: 0.862821 | Val Loss: 0.115367, Val Acc: 0.773196\n",
      "Epoch 19663 - Train Loss: 0.087322, Train Acc: 0.862821 | Val Loss: 0.115366, Val Acc: 0.773196\n",
      "Epoch 19664 - Train Loss: 0.087319, Train Acc: 0.862821 | Val Loss: 0.115365, Val Acc: 0.773196\n",
      "Epoch 19665 - Train Loss: 0.087317, Train Acc: 0.862821 | Val Loss: 0.115364, Val Acc: 0.773196\n",
      "Epoch 19666 - Train Loss: 0.087315, Train Acc: 0.862821 | Val Loss: 0.115363, Val Acc: 0.773196\n",
      "Epoch 19667 - Train Loss: 0.087312, Train Acc: 0.862821 | Val Loss: 0.115362, Val Acc: 0.773196\n",
      "Epoch 19668 - Train Loss: 0.087310, Train Acc: 0.862821 | Val Loss: 0.115361, Val Acc: 0.773196\n",
      "Epoch 19669 - Train Loss: 0.087308, Train Acc: 0.862821 | Val Loss: 0.115360, Val Acc: 0.773196\n",
      "Epoch 19670 - Train Loss: 0.087305, Train Acc: 0.862821 | Val Loss: 0.115359, Val Acc: 0.773196\n",
      "Epoch 19671 - Train Loss: 0.087303, Train Acc: 0.862821 | Val Loss: 0.115357, Val Acc: 0.773196\n",
      "Epoch 19672 - Train Loss: 0.087301, Train Acc: 0.862821 | Val Loss: 0.115356, Val Acc: 0.773196\n",
      "Epoch 19673 - Train Loss: 0.087299, Train Acc: 0.862821 | Val Loss: 0.115355, Val Acc: 0.773196\n",
      "Epoch 19674 - Train Loss: 0.087296, Train Acc: 0.862821 | Val Loss: 0.115354, Val Acc: 0.773196\n",
      "Epoch 19675 - Train Loss: 0.087294, Train Acc: 0.862821 | Val Loss: 0.115353, Val Acc: 0.773196\n",
      "Epoch 19676 - Train Loss: 0.087292, Train Acc: 0.862821 | Val Loss: 0.115352, Val Acc: 0.773196\n",
      "Epoch 19677 - Train Loss: 0.087289, Train Acc: 0.862821 | Val Loss: 0.115351, Val Acc: 0.773196\n",
      "Epoch 19678 - Train Loss: 0.087287, Train Acc: 0.862821 | Val Loss: 0.115350, Val Acc: 0.773196\n",
      "Epoch 19679 - Train Loss: 0.087285, Train Acc: 0.862821 | Val Loss: 0.115349, Val Acc: 0.773196\n",
      "Epoch 19680 - Train Loss: 0.087282, Train Acc: 0.862821 | Val Loss: 0.115347, Val Acc: 0.773196\n",
      "Epoch 19681 - Train Loss: 0.087280, Train Acc: 0.862821 | Val Loss: 0.115346, Val Acc: 0.773196\n",
      "Epoch 19682 - Train Loss: 0.087278, Train Acc: 0.862821 | Val Loss: 0.115345, Val Acc: 0.773196\n",
      "Epoch 19683 - Train Loss: 0.087276, Train Acc: 0.862821 | Val Loss: 0.115344, Val Acc: 0.773196\n",
      "Epoch 19684 - Train Loss: 0.087273, Train Acc: 0.862821 | Val Loss: 0.115343, Val Acc: 0.773196\n",
      "Epoch 19685 - Train Loss: 0.087271, Train Acc: 0.862821 | Val Loss: 0.115342, Val Acc: 0.773196\n",
      "Epoch 19686 - Train Loss: 0.087269, Train Acc: 0.862821 | Val Loss: 0.115341, Val Acc: 0.773196\n",
      "Epoch 19687 - Train Loss: 0.087266, Train Acc: 0.862821 | Val Loss: 0.115340, Val Acc: 0.773196\n",
      "Epoch 19688 - Train Loss: 0.087264, Train Acc: 0.862821 | Val Loss: 0.115338, Val Acc: 0.773196\n",
      "Epoch 19689 - Train Loss: 0.087262, Train Acc: 0.862821 | Val Loss: 0.115337, Val Acc: 0.773196\n",
      "Epoch 19690 - Train Loss: 0.087259, Train Acc: 0.862821 | Val Loss: 0.115336, Val Acc: 0.773196\n",
      "Epoch 19691 - Train Loss: 0.087257, Train Acc: 0.862821 | Val Loss: 0.115335, Val Acc: 0.773196\n",
      "Epoch 19692 - Train Loss: 0.087255, Train Acc: 0.862821 | Val Loss: 0.115334, Val Acc: 0.773196\n",
      "Epoch 19693 - Train Loss: 0.087253, Train Acc: 0.862821 | Val Loss: 0.115333, Val Acc: 0.773196\n",
      "Epoch 19694 - Train Loss: 0.087250, Train Acc: 0.862821 | Val Loss: 0.115332, Val Acc: 0.773196\n",
      "Epoch 19695 - Train Loss: 0.087248, Train Acc: 0.862821 | Val Loss: 0.115331, Val Acc: 0.773196\n",
      "Epoch 19696 - Train Loss: 0.087246, Train Acc: 0.862821 | Val Loss: 0.115330, Val Acc: 0.773196\n",
      "Epoch 19697 - Train Loss: 0.087243, Train Acc: 0.862821 | Val Loss: 0.115329, Val Acc: 0.773196\n",
      "Epoch 19698 - Train Loss: 0.087241, Train Acc: 0.862821 | Val Loss: 0.115327, Val Acc: 0.773196\n",
      "Epoch 19699 - Train Loss: 0.087239, Train Acc: 0.862821 | Val Loss: 0.115326, Val Acc: 0.773196\n",
      "Epoch 19700 - Train Loss: 0.087236, Train Acc: 0.862821 | Val Loss: 0.115325, Val Acc: 0.773196\n",
      "Epoch 19701 - Train Loss: 0.087234, Train Acc: 0.862821 | Val Loss: 0.115324, Val Acc: 0.773196\n",
      "Epoch 19702 - Train Loss: 0.087232, Train Acc: 0.862821 | Val Loss: 0.115323, Val Acc: 0.773196\n",
      "Epoch 19703 - Train Loss: 0.087230, Train Acc: 0.862821 | Val Loss: 0.115322, Val Acc: 0.773196\n",
      "Epoch 19704 - Train Loss: 0.087227, Train Acc: 0.862821 | Val Loss: 0.115321, Val Acc: 0.773196\n",
      "Epoch 19705 - Train Loss: 0.087225, Train Acc: 0.862821 | Val Loss: 0.115320, Val Acc: 0.773196\n",
      "Epoch 19706 - Train Loss: 0.087223, Train Acc: 0.862821 | Val Loss: 0.115319, Val Acc: 0.773196\n",
      "Epoch 19707 - Train Loss: 0.087220, Train Acc: 0.862821 | Val Loss: 0.115317, Val Acc: 0.773196\n",
      "Epoch 19708 - Train Loss: 0.087218, Train Acc: 0.862821 | Val Loss: 0.115316, Val Acc: 0.773196\n",
      "Epoch 19709 - Train Loss: 0.087216, Train Acc: 0.862821 | Val Loss: 0.115315, Val Acc: 0.773196\n",
      "Epoch 19710 - Train Loss: 0.087213, Train Acc: 0.862821 | Val Loss: 0.115314, Val Acc: 0.773196\n",
      "Epoch 19711 - Train Loss: 0.087211, Train Acc: 0.862821 | Val Loss: 0.115313, Val Acc: 0.773196\n",
      "Epoch 19712 - Train Loss: 0.087209, Train Acc: 0.862821 | Val Loss: 0.115312, Val Acc: 0.773196\n",
      "Epoch 19713 - Train Loss: 0.087207, Train Acc: 0.862821 | Val Loss: 0.115311, Val Acc: 0.773196\n",
      "Epoch 19714 - Train Loss: 0.087204, Train Acc: 0.862821 | Val Loss: 0.115310, Val Acc: 0.773196\n",
      "Epoch 19715 - Train Loss: 0.087202, Train Acc: 0.862821 | Val Loss: 0.115309, Val Acc: 0.773196\n",
      "Epoch 19716 - Train Loss: 0.087200, Train Acc: 0.862821 | Val Loss: 0.115307, Val Acc: 0.773196\n",
      "Epoch 19717 - Train Loss: 0.087197, Train Acc: 0.862821 | Val Loss: 0.115306, Val Acc: 0.773196\n",
      "Epoch 19718 - Train Loss: 0.087195, Train Acc: 0.862821 | Val Loss: 0.115305, Val Acc: 0.773196\n",
      "Epoch 19719 - Train Loss: 0.087193, Train Acc: 0.862821 | Val Loss: 0.115304, Val Acc: 0.773196\n",
      "Epoch 19720 - Train Loss: 0.087190, Train Acc: 0.862821 | Val Loss: 0.115303, Val Acc: 0.773196\n",
      "Epoch 19721 - Train Loss: 0.087188, Train Acc: 0.862821 | Val Loss: 0.115302, Val Acc: 0.773196\n",
      "Epoch 19722 - Train Loss: 0.087186, Train Acc: 0.862821 | Val Loss: 0.115301, Val Acc: 0.773196\n",
      "Epoch 19723 - Train Loss: 0.087184, Train Acc: 0.862821 | Val Loss: 0.115300, Val Acc: 0.773196\n",
      "Epoch 19724 - Train Loss: 0.087181, Train Acc: 0.862821 | Val Loss: 0.115299, Val Acc: 0.773196\n",
      "Epoch 19725 - Train Loss: 0.087179, Train Acc: 0.862821 | Val Loss: 0.115298, Val Acc: 0.773196\n",
      "Epoch 19726 - Train Loss: 0.087177, Train Acc: 0.862821 | Val Loss: 0.115296, Val Acc: 0.773196\n",
      "Epoch 19727 - Train Loss: 0.087174, Train Acc: 0.862821 | Val Loss: 0.115295, Val Acc: 0.773196\n",
      "Epoch 19728 - Train Loss: 0.087172, Train Acc: 0.862821 | Val Loss: 0.115294, Val Acc: 0.773196\n",
      "Epoch 19729 - Train Loss: 0.087170, Train Acc: 0.862821 | Val Loss: 0.115293, Val Acc: 0.773196\n",
      "Epoch 19730 - Train Loss: 0.087168, Train Acc: 0.862821 | Val Loss: 0.115292, Val Acc: 0.773196\n",
      "Epoch 19731 - Train Loss: 0.087165, Train Acc: 0.862821 | Val Loss: 0.115291, Val Acc: 0.773196\n",
      "Epoch 19732 - Train Loss: 0.087163, Train Acc: 0.862821 | Val Loss: 0.115290, Val Acc: 0.773196\n",
      "Epoch 19733 - Train Loss: 0.087161, Train Acc: 0.862821 | Val Loss: 0.115289, Val Acc: 0.773196\n",
      "Epoch 19734 - Train Loss: 0.087158, Train Acc: 0.862821 | Val Loss: 0.115288, Val Acc: 0.773196\n",
      "Epoch 19735 - Train Loss: 0.087156, Train Acc: 0.862821 | Val Loss: 0.115286, Val Acc: 0.773196\n",
      "Epoch 19736 - Train Loss: 0.087154, Train Acc: 0.862821 | Val Loss: 0.115285, Val Acc: 0.773196\n",
      "Epoch 19737 - Train Loss: 0.087152, Train Acc: 0.862821 | Val Loss: 0.115284, Val Acc: 0.773196\n",
      "Epoch 19738 - Train Loss: 0.087149, Train Acc: 0.862821 | Val Loss: 0.115283, Val Acc: 0.773196\n",
      "Epoch 19739 - Train Loss: 0.087147, Train Acc: 0.862821 | Val Loss: 0.115282, Val Acc: 0.773196\n",
      "Epoch 19740 - Train Loss: 0.087145, Train Acc: 0.862821 | Val Loss: 0.115281, Val Acc: 0.773196\n",
      "Epoch 19741 - Train Loss: 0.087142, Train Acc: 0.862821 | Val Loss: 0.115280, Val Acc: 0.773196\n",
      "Epoch 19742 - Train Loss: 0.087140, Train Acc: 0.862821 | Val Loss: 0.115279, Val Acc: 0.773196\n",
      "Epoch 19743 - Train Loss: 0.087138, Train Acc: 0.862821 | Val Loss: 0.115278, Val Acc: 0.773196\n",
      "Epoch 19744 - Train Loss: 0.087135, Train Acc: 0.862821 | Val Loss: 0.115277, Val Acc: 0.773196\n",
      "Epoch 19745 - Train Loss: 0.087133, Train Acc: 0.862821 | Val Loss: 0.115275, Val Acc: 0.773196\n",
      "Epoch 19746 - Train Loss: 0.087131, Train Acc: 0.862821 | Val Loss: 0.115274, Val Acc: 0.773196\n",
      "Epoch 19747 - Train Loss: 0.087129, Train Acc: 0.862821 | Val Loss: 0.115273, Val Acc: 0.773196\n",
      "Epoch 19748 - Train Loss: 0.087126, Train Acc: 0.862821 | Val Loss: 0.115272, Val Acc: 0.773196\n",
      "Epoch 19749 - Train Loss: 0.087124, Train Acc: 0.862821 | Val Loss: 0.115271, Val Acc: 0.773196\n",
      "Epoch 19750 - Train Loss: 0.087122, Train Acc: 0.862821 | Val Loss: 0.115270, Val Acc: 0.773196\n",
      "Epoch 19751 - Train Loss: 0.087119, Train Acc: 0.862821 | Val Loss: 0.115269, Val Acc: 0.773196\n",
      "Epoch 19752 - Train Loss: 0.087117, Train Acc: 0.862821 | Val Loss: 0.115268, Val Acc: 0.773196\n",
      "Epoch 19753 - Train Loss: 0.087115, Train Acc: 0.862821 | Val Loss: 0.115267, Val Acc: 0.773196\n",
      "Epoch 19754 - Train Loss: 0.087113, Train Acc: 0.862821 | Val Loss: 0.115266, Val Acc: 0.773196\n",
      "Epoch 19755 - Train Loss: 0.087110, Train Acc: 0.862821 | Val Loss: 0.115264, Val Acc: 0.773196\n",
      "Epoch 19756 - Train Loss: 0.087108, Train Acc: 0.862821 | Val Loss: 0.115263, Val Acc: 0.773196\n",
      "Epoch 19757 - Train Loss: 0.087106, Train Acc: 0.862821 | Val Loss: 0.115262, Val Acc: 0.773196\n",
      "Epoch 19758 - Train Loss: 0.087103, Train Acc: 0.862821 | Val Loss: 0.115261, Val Acc: 0.773196\n",
      "Epoch 19759 - Train Loss: 0.087101, Train Acc: 0.862821 | Val Loss: 0.115260, Val Acc: 0.773196\n",
      "Epoch 19760 - Train Loss: 0.087099, Train Acc: 0.862821 | Val Loss: 0.115259, Val Acc: 0.773196\n",
      "Epoch 19761 - Train Loss: 0.087097, Train Acc: 0.862821 | Val Loss: 0.115258, Val Acc: 0.773196\n",
      "Epoch 19762 - Train Loss: 0.087094, Train Acc: 0.862821 | Val Loss: 0.115257, Val Acc: 0.773196\n",
      "Epoch 19763 - Train Loss: 0.087092, Train Acc: 0.862821 | Val Loss: 0.115256, Val Acc: 0.773196\n",
      "Epoch 19764 - Train Loss: 0.087090, Train Acc: 0.862821 | Val Loss: 0.115255, Val Acc: 0.773196\n",
      "Epoch 19765 - Train Loss: 0.087087, Train Acc: 0.862821 | Val Loss: 0.115253, Val Acc: 0.773196\n",
      "Epoch 19766 - Train Loss: 0.087085, Train Acc: 0.862821 | Val Loss: 0.115252, Val Acc: 0.773196\n",
      "Epoch 19767 - Train Loss: 0.087083, Train Acc: 0.862821 | Val Loss: 0.115251, Val Acc: 0.773196\n",
      "Epoch 19768 - Train Loss: 0.087081, Train Acc: 0.862821 | Val Loss: 0.115250, Val Acc: 0.773196\n",
      "Epoch 19769 - Train Loss: 0.087078, Train Acc: 0.862821 | Val Loss: 0.115249, Val Acc: 0.773196\n",
      "Epoch 19770 - Train Loss: 0.087076, Train Acc: 0.862821 | Val Loss: 0.115248, Val Acc: 0.773196\n",
      "Epoch 19771 - Train Loss: 0.087074, Train Acc: 0.862821 | Val Loss: 0.115247, Val Acc: 0.773196\n",
      "Epoch 19772 - Train Loss: 0.087071, Train Acc: 0.862821 | Val Loss: 0.115246, Val Acc: 0.773196\n",
      "Epoch 19773 - Train Loss: 0.087069, Train Acc: 0.862821 | Val Loss: 0.115245, Val Acc: 0.773196\n",
      "Epoch 19774 - Train Loss: 0.087067, Train Acc: 0.862821 | Val Loss: 0.115244, Val Acc: 0.773196\n",
      "Epoch 19775 - Train Loss: 0.087065, Train Acc: 0.862821 | Val Loss: 0.115243, Val Acc: 0.773196\n",
      "Epoch 19776 - Train Loss: 0.087062, Train Acc: 0.862821 | Val Loss: 0.115241, Val Acc: 0.773196\n",
      "Epoch 19777 - Train Loss: 0.087060, Train Acc: 0.862821 | Val Loss: 0.115240, Val Acc: 0.773196\n",
      "Epoch 19778 - Train Loss: 0.087058, Train Acc: 0.862821 | Val Loss: 0.115239, Val Acc: 0.773196\n",
      "Epoch 19779 - Train Loss: 0.087055, Train Acc: 0.862821 | Val Loss: 0.115238, Val Acc: 0.773196\n",
      "Epoch 19780 - Train Loss: 0.087053, Train Acc: 0.862821 | Val Loss: 0.115237, Val Acc: 0.773196\n",
      "Epoch 19781 - Train Loss: 0.087051, Train Acc: 0.862821 | Val Loss: 0.115236, Val Acc: 0.773196\n",
      "Epoch 19782 - Train Loss: 0.087049, Train Acc: 0.862821 | Val Loss: 0.115235, Val Acc: 0.773196\n",
      "Epoch 19783 - Train Loss: 0.087046, Train Acc: 0.862821 | Val Loss: 0.115234, Val Acc: 0.773196\n",
      "Epoch 19784 - Train Loss: 0.087044, Train Acc: 0.862821 | Val Loss: 0.115233, Val Acc: 0.773196\n",
      "Epoch 19785 - Train Loss: 0.087042, Train Acc: 0.864103 | Val Loss: 0.115232, Val Acc: 0.773196\n",
      "Epoch 19786 - Train Loss: 0.087039, Train Acc: 0.864103 | Val Loss: 0.115230, Val Acc: 0.773196\n",
      "Epoch 19787 - Train Loss: 0.087037, Train Acc: 0.864103 | Val Loss: 0.115229, Val Acc: 0.773196\n",
      "Epoch 19788 - Train Loss: 0.087035, Train Acc: 0.864103 | Val Loss: 0.115228, Val Acc: 0.773196\n",
      "Epoch 19789 - Train Loss: 0.087033, Train Acc: 0.864103 | Val Loss: 0.115227, Val Acc: 0.773196\n",
      "Epoch 19790 - Train Loss: 0.087030, Train Acc: 0.864103 | Val Loss: 0.115226, Val Acc: 0.773196\n",
      "Epoch 19791 - Train Loss: 0.087028, Train Acc: 0.864103 | Val Loss: 0.115225, Val Acc: 0.773196\n",
      "Epoch 19792 - Train Loss: 0.087026, Train Acc: 0.864103 | Val Loss: 0.115224, Val Acc: 0.773196\n",
      "Epoch 19793 - Train Loss: 0.087024, Train Acc: 0.864103 | Val Loss: 0.115223, Val Acc: 0.773196\n",
      "Epoch 19794 - Train Loss: 0.087021, Train Acc: 0.864103 | Val Loss: 0.115222, Val Acc: 0.773196\n",
      "Epoch 19795 - Train Loss: 0.087019, Train Acc: 0.864103 | Val Loss: 0.115221, Val Acc: 0.773196\n",
      "Epoch 19796 - Train Loss: 0.087017, Train Acc: 0.864103 | Val Loss: 0.115220, Val Acc: 0.773196\n",
      "Epoch 19797 - Train Loss: 0.087014, Train Acc: 0.864103 | Val Loss: 0.115218, Val Acc: 0.773196\n",
      "Epoch 19798 - Train Loss: 0.087012, Train Acc: 0.864103 | Val Loss: 0.115217, Val Acc: 0.773196\n",
      "Epoch 19799 - Train Loss: 0.087010, Train Acc: 0.864103 | Val Loss: 0.115216, Val Acc: 0.773196\n",
      "Epoch 19800 - Train Loss: 0.087008, Train Acc: 0.864103 | Val Loss: 0.115215, Val Acc: 0.773196\n",
      "Epoch 19801 - Train Loss: 0.087005, Train Acc: 0.864103 | Val Loss: 0.115214, Val Acc: 0.773196\n",
      "Epoch 19802 - Train Loss: 0.087003, Train Acc: 0.864103 | Val Loss: 0.115213, Val Acc: 0.773196\n",
      "Epoch 19803 - Train Loss: 0.087001, Train Acc: 0.864103 | Val Loss: 0.115212, Val Acc: 0.773196\n",
      "Epoch 19804 - Train Loss: 0.086998, Train Acc: 0.864103 | Val Loss: 0.115211, Val Acc: 0.773196\n",
      "Epoch 19805 - Train Loss: 0.086996, Train Acc: 0.864103 | Val Loss: 0.115210, Val Acc: 0.773196\n",
      "Epoch 19806 - Train Loss: 0.086994, Train Acc: 0.864103 | Val Loss: 0.115209, Val Acc: 0.773196\n",
      "Epoch 19807 - Train Loss: 0.086992, Train Acc: 0.864103 | Val Loss: 0.115208, Val Acc: 0.773196\n",
      "Epoch 19808 - Train Loss: 0.086989, Train Acc: 0.864103 | Val Loss: 0.115206, Val Acc: 0.773196\n",
      "Epoch 19809 - Train Loss: 0.086987, Train Acc: 0.864103 | Val Loss: 0.115205, Val Acc: 0.773196\n",
      "Epoch 19810 - Train Loss: 0.086985, Train Acc: 0.864103 | Val Loss: 0.115204, Val Acc: 0.773196\n",
      "Epoch 19811 - Train Loss: 0.086982, Train Acc: 0.864103 | Val Loss: 0.115203, Val Acc: 0.773196\n",
      "Epoch 19812 - Train Loss: 0.086980, Train Acc: 0.864103 | Val Loss: 0.115202, Val Acc: 0.773196\n",
      "Epoch 19813 - Train Loss: 0.086978, Train Acc: 0.864103 | Val Loss: 0.115201, Val Acc: 0.773196\n",
      "Epoch 19814 - Train Loss: 0.086976, Train Acc: 0.864103 | Val Loss: 0.115200, Val Acc: 0.773196\n",
      "Epoch 19815 - Train Loss: 0.086973, Train Acc: 0.864103 | Val Loss: 0.115199, Val Acc: 0.773196\n",
      "Epoch 19816 - Train Loss: 0.086971, Train Acc: 0.864103 | Val Loss: 0.115198, Val Acc: 0.773196\n",
      "Epoch 19817 - Train Loss: 0.086969, Train Acc: 0.864103 | Val Loss: 0.115197, Val Acc: 0.773196\n",
      "Epoch 19818 - Train Loss: 0.086967, Train Acc: 0.864103 | Val Loss: 0.115196, Val Acc: 0.773196\n",
      "Epoch 19819 - Train Loss: 0.086964, Train Acc: 0.864103 | Val Loss: 0.115194, Val Acc: 0.773196\n",
      "Epoch 19820 - Train Loss: 0.086962, Train Acc: 0.864103 | Val Loss: 0.115193, Val Acc: 0.773196\n",
      "Epoch 19821 - Train Loss: 0.086960, Train Acc: 0.864103 | Val Loss: 0.115192, Val Acc: 0.773196\n",
      "Epoch 19822 - Train Loss: 0.086957, Train Acc: 0.864103 | Val Loss: 0.115191, Val Acc: 0.773196\n",
      "Epoch 19823 - Train Loss: 0.086955, Train Acc: 0.864103 | Val Loss: 0.115190, Val Acc: 0.773196\n",
      "Epoch 19824 - Train Loss: 0.086953, Train Acc: 0.864103 | Val Loss: 0.115189, Val Acc: 0.773196\n",
      "Epoch 19825 - Train Loss: 0.086951, Train Acc: 0.864103 | Val Loss: 0.115188, Val Acc: 0.773196\n",
      "Epoch 19826 - Train Loss: 0.086948, Train Acc: 0.864103 | Val Loss: 0.115187, Val Acc: 0.773196\n",
      "Epoch 19827 - Train Loss: 0.086946, Train Acc: 0.864103 | Val Loss: 0.115186, Val Acc: 0.773196\n",
      "Epoch 19828 - Train Loss: 0.086944, Train Acc: 0.864103 | Val Loss: 0.115185, Val Acc: 0.773196\n",
      "Epoch 19829 - Train Loss: 0.086942, Train Acc: 0.864103 | Val Loss: 0.115184, Val Acc: 0.773196\n",
      "Epoch 19830 - Train Loss: 0.086939, Train Acc: 0.864103 | Val Loss: 0.115183, Val Acc: 0.773196\n",
      "Epoch 19831 - Train Loss: 0.086937, Train Acc: 0.864103 | Val Loss: 0.115181, Val Acc: 0.773196\n",
      "Epoch 19832 - Train Loss: 0.086935, Train Acc: 0.864103 | Val Loss: 0.115180, Val Acc: 0.773196\n",
      "Epoch 19833 - Train Loss: 0.086932, Train Acc: 0.864103 | Val Loss: 0.115179, Val Acc: 0.773196\n",
      "Epoch 19834 - Train Loss: 0.086930, Train Acc: 0.864103 | Val Loss: 0.115178, Val Acc: 0.773196\n",
      "Epoch 19835 - Train Loss: 0.086928, Train Acc: 0.864103 | Val Loss: 0.115177, Val Acc: 0.773196\n",
      "Epoch 19836 - Train Loss: 0.086926, Train Acc: 0.864103 | Val Loss: 0.115176, Val Acc: 0.773196\n",
      "Epoch 19837 - Train Loss: 0.086923, Train Acc: 0.864103 | Val Loss: 0.115175, Val Acc: 0.773196\n",
      "Epoch 19838 - Train Loss: 0.086921, Train Acc: 0.864103 | Val Loss: 0.115174, Val Acc: 0.773196\n",
      "Epoch 19839 - Train Loss: 0.086919, Train Acc: 0.864103 | Val Loss: 0.115173, Val Acc: 0.773196\n",
      "Epoch 19840 - Train Loss: 0.086917, Train Acc: 0.864103 | Val Loss: 0.115172, Val Acc: 0.773196\n",
      "Epoch 19841 - Train Loss: 0.086914, Train Acc: 0.864103 | Val Loss: 0.115171, Val Acc: 0.773196\n",
      "Epoch 19842 - Train Loss: 0.086912, Train Acc: 0.864103 | Val Loss: 0.115170, Val Acc: 0.773196\n",
      "Epoch 19843 - Train Loss: 0.086910, Train Acc: 0.864103 | Val Loss: 0.115168, Val Acc: 0.773196\n",
      "Epoch 19844 - Train Loss: 0.086907, Train Acc: 0.864103 | Val Loss: 0.115167, Val Acc: 0.773196\n",
      "Epoch 19845 - Train Loss: 0.086905, Train Acc: 0.864103 | Val Loss: 0.115166, Val Acc: 0.773196\n",
      "Epoch 19846 - Train Loss: 0.086903, Train Acc: 0.864103 | Val Loss: 0.115165, Val Acc: 0.773196\n",
      "Epoch 19847 - Train Loss: 0.086901, Train Acc: 0.864103 | Val Loss: 0.115164, Val Acc: 0.773196\n",
      "Epoch 19848 - Train Loss: 0.086898, Train Acc: 0.864103 | Val Loss: 0.115163, Val Acc: 0.773196\n",
      "Epoch 19849 - Train Loss: 0.086896, Train Acc: 0.864103 | Val Loss: 0.115162, Val Acc: 0.773196\n",
      "Epoch 19850 - Train Loss: 0.086894, Train Acc: 0.864103 | Val Loss: 0.115161, Val Acc: 0.773196\n",
      "Epoch 19851 - Train Loss: 0.086892, Train Acc: 0.864103 | Val Loss: 0.115160, Val Acc: 0.773196\n",
      "Epoch 19852 - Train Loss: 0.086889, Train Acc: 0.864103 | Val Loss: 0.115159, Val Acc: 0.773196\n",
      "Epoch 19853 - Train Loss: 0.086887, Train Acc: 0.864103 | Val Loss: 0.115158, Val Acc: 0.773196\n",
      "Epoch 19854 - Train Loss: 0.086885, Train Acc: 0.864103 | Val Loss: 0.115157, Val Acc: 0.773196\n",
      "Epoch 19855 - Train Loss: 0.086882, Train Acc: 0.864103 | Val Loss: 0.115155, Val Acc: 0.773196\n",
      "Epoch 19856 - Train Loss: 0.086880, Train Acc: 0.864103 | Val Loss: 0.115154, Val Acc: 0.773196\n",
      "Epoch 19857 - Train Loss: 0.086878, Train Acc: 0.864103 | Val Loss: 0.115153, Val Acc: 0.773196\n",
      "Epoch 19858 - Train Loss: 0.086876, Train Acc: 0.864103 | Val Loss: 0.115152, Val Acc: 0.773196\n",
      "Epoch 19859 - Train Loss: 0.086873, Train Acc: 0.864103 | Val Loss: 0.115151, Val Acc: 0.773196\n",
      "Epoch 19860 - Train Loss: 0.086871, Train Acc: 0.864103 | Val Loss: 0.115150, Val Acc: 0.773196\n",
      "Epoch 19861 - Train Loss: 0.086869, Train Acc: 0.864103 | Val Loss: 0.115149, Val Acc: 0.773196\n",
      "Epoch 19862 - Train Loss: 0.086867, Train Acc: 0.864103 | Val Loss: 0.115148, Val Acc: 0.773196\n",
      "Epoch 19863 - Train Loss: 0.086864, Train Acc: 0.864103 | Val Loss: 0.115147, Val Acc: 0.773196\n",
      "Epoch 19864 - Train Loss: 0.086862, Train Acc: 0.864103 | Val Loss: 0.115146, Val Acc: 0.773196\n",
      "Epoch 19865 - Train Loss: 0.086860, Train Acc: 0.864103 | Val Loss: 0.115145, Val Acc: 0.773196\n",
      "Epoch 19866 - Train Loss: 0.086858, Train Acc: 0.864103 | Val Loss: 0.115144, Val Acc: 0.773196\n",
      "Epoch 19867 - Train Loss: 0.086855, Train Acc: 0.864103 | Val Loss: 0.115142, Val Acc: 0.773196\n",
      "Epoch 19868 - Train Loss: 0.086853, Train Acc: 0.864103 | Val Loss: 0.115141, Val Acc: 0.773196\n",
      "Epoch 19869 - Train Loss: 0.086851, Train Acc: 0.864103 | Val Loss: 0.115140, Val Acc: 0.773196\n",
      "Epoch 19870 - Train Loss: 0.086848, Train Acc: 0.864103 | Val Loss: 0.115139, Val Acc: 0.773196\n",
      "Epoch 19871 - Train Loss: 0.086846, Train Acc: 0.864103 | Val Loss: 0.115138, Val Acc: 0.773196\n",
      "Epoch 19872 - Train Loss: 0.086844, Train Acc: 0.864103 | Val Loss: 0.115137, Val Acc: 0.773196\n",
      "Epoch 19873 - Train Loss: 0.086842, Train Acc: 0.864103 | Val Loss: 0.115136, Val Acc: 0.773196\n",
      "Epoch 19874 - Train Loss: 0.086839, Train Acc: 0.864103 | Val Loss: 0.115135, Val Acc: 0.773196\n",
      "Epoch 19875 - Train Loss: 0.086837, Train Acc: 0.864103 | Val Loss: 0.115134, Val Acc: 0.773196\n",
      "Epoch 19876 - Train Loss: 0.086835, Train Acc: 0.864103 | Val Loss: 0.115133, Val Acc: 0.773196\n",
      "Epoch 19877 - Train Loss: 0.086833, Train Acc: 0.864103 | Val Loss: 0.115132, Val Acc: 0.773196\n",
      "Epoch 19878 - Train Loss: 0.086830, Train Acc: 0.864103 | Val Loss: 0.115131, Val Acc: 0.773196\n",
      "Epoch 19879 - Train Loss: 0.086828, Train Acc: 0.864103 | Val Loss: 0.115130, Val Acc: 0.773196\n",
      "Epoch 19880 - Train Loss: 0.086826, Train Acc: 0.865385 | Val Loss: 0.115128, Val Acc: 0.773196\n",
      "Epoch 19881 - Train Loss: 0.086824, Train Acc: 0.865385 | Val Loss: 0.115127, Val Acc: 0.773196\n",
      "Epoch 19882 - Train Loss: 0.086821, Train Acc: 0.865385 | Val Loss: 0.115126, Val Acc: 0.773196\n",
      "Epoch 19883 - Train Loss: 0.086819, Train Acc: 0.865385 | Val Loss: 0.115125, Val Acc: 0.773196\n",
      "Epoch 19884 - Train Loss: 0.086817, Train Acc: 0.865385 | Val Loss: 0.115124, Val Acc: 0.773196\n",
      "Epoch 19885 - Train Loss: 0.086815, Train Acc: 0.865385 | Val Loss: 0.115123, Val Acc: 0.773196\n",
      "Epoch 19886 - Train Loss: 0.086812, Train Acc: 0.865385 | Val Loss: 0.115122, Val Acc: 0.773196\n",
      "Epoch 19887 - Train Loss: 0.086810, Train Acc: 0.865385 | Val Loss: 0.115121, Val Acc: 0.773196\n",
      "Epoch 19888 - Train Loss: 0.086808, Train Acc: 0.865385 | Val Loss: 0.115120, Val Acc: 0.773196\n",
      "Epoch 19889 - Train Loss: 0.086805, Train Acc: 0.865385 | Val Loss: 0.115119, Val Acc: 0.773196\n",
      "Epoch 19890 - Train Loss: 0.086803, Train Acc: 0.865385 | Val Loss: 0.115118, Val Acc: 0.773196\n",
      "Epoch 19891 - Train Loss: 0.086801, Train Acc: 0.865385 | Val Loss: 0.115117, Val Acc: 0.773196\n",
      "Epoch 19892 - Train Loss: 0.086799, Train Acc: 0.865385 | Val Loss: 0.115116, Val Acc: 0.773196\n",
      "Epoch 19893 - Train Loss: 0.086796, Train Acc: 0.865385 | Val Loss: 0.115114, Val Acc: 0.773196\n",
      "Epoch 19894 - Train Loss: 0.086794, Train Acc: 0.865385 | Val Loss: 0.115113, Val Acc: 0.773196\n",
      "Epoch 19895 - Train Loss: 0.086792, Train Acc: 0.865385 | Val Loss: 0.115112, Val Acc: 0.773196\n",
      "Epoch 19896 - Train Loss: 0.086790, Train Acc: 0.865385 | Val Loss: 0.115111, Val Acc: 0.773196\n",
      "Epoch 19897 - Train Loss: 0.086787, Train Acc: 0.865385 | Val Loss: 0.115110, Val Acc: 0.773196\n",
      "Epoch 19898 - Train Loss: 0.086785, Train Acc: 0.865385 | Val Loss: 0.115109, Val Acc: 0.773196\n",
      "Epoch 19899 - Train Loss: 0.086783, Train Acc: 0.865385 | Val Loss: 0.115108, Val Acc: 0.773196\n",
      "Epoch 19900 - Train Loss: 0.086781, Train Acc: 0.865385 | Val Loss: 0.115107, Val Acc: 0.773196\n",
      "Epoch 19901 - Train Loss: 0.086778, Train Acc: 0.865385 | Val Loss: 0.115106, Val Acc: 0.773196\n",
      "Epoch 19902 - Train Loss: 0.086776, Train Acc: 0.865385 | Val Loss: 0.115105, Val Acc: 0.773196\n",
      "Epoch 19903 - Train Loss: 0.086774, Train Acc: 0.865385 | Val Loss: 0.115104, Val Acc: 0.773196\n",
      "Epoch 19904 - Train Loss: 0.086772, Train Acc: 0.865385 | Val Loss: 0.115103, Val Acc: 0.773196\n",
      "Epoch 19905 - Train Loss: 0.086769, Train Acc: 0.865385 | Val Loss: 0.115102, Val Acc: 0.773196\n",
      "Epoch 19906 - Train Loss: 0.086767, Train Acc: 0.865385 | Val Loss: 0.115100, Val Acc: 0.773196\n",
      "Epoch 19907 - Train Loss: 0.086765, Train Acc: 0.865385 | Val Loss: 0.115099, Val Acc: 0.773196\n",
      "Epoch 19908 - Train Loss: 0.086763, Train Acc: 0.865385 | Val Loss: 0.115098, Val Acc: 0.773196\n",
      "Epoch 19909 - Train Loss: 0.086760, Train Acc: 0.865385 | Val Loss: 0.115097, Val Acc: 0.773196\n",
      "Epoch 19910 - Train Loss: 0.086758, Train Acc: 0.865385 | Val Loss: 0.115096, Val Acc: 0.773196\n",
      "Epoch 19911 - Train Loss: 0.086756, Train Acc: 0.865385 | Val Loss: 0.115095, Val Acc: 0.773196\n",
      "Epoch 19912 - Train Loss: 0.086754, Train Acc: 0.865385 | Val Loss: 0.115094, Val Acc: 0.773196\n",
      "Epoch 19913 - Train Loss: 0.086751, Train Acc: 0.865385 | Val Loss: 0.115093, Val Acc: 0.773196\n",
      "Epoch 19914 - Train Loss: 0.086749, Train Acc: 0.865385 | Val Loss: 0.115092, Val Acc: 0.773196\n",
      "Epoch 19915 - Train Loss: 0.086747, Train Acc: 0.865385 | Val Loss: 0.115091, Val Acc: 0.773196\n",
      "Epoch 19916 - Train Loss: 0.086744, Train Acc: 0.865385 | Val Loss: 0.115090, Val Acc: 0.773196\n",
      "Epoch 19917 - Train Loss: 0.086742, Train Acc: 0.865385 | Val Loss: 0.115089, Val Acc: 0.773196\n",
      "Epoch 19918 - Train Loss: 0.086740, Train Acc: 0.865385 | Val Loss: 0.115088, Val Acc: 0.773196\n",
      "Epoch 19919 - Train Loss: 0.086738, Train Acc: 0.865385 | Val Loss: 0.115087, Val Acc: 0.773196\n",
      "Epoch 19920 - Train Loss: 0.086735, Train Acc: 0.865385 | Val Loss: 0.115085, Val Acc: 0.773196\n",
      "Epoch 19921 - Train Loss: 0.086733, Train Acc: 0.865385 | Val Loss: 0.115084, Val Acc: 0.773196\n",
      "Epoch 19922 - Train Loss: 0.086731, Train Acc: 0.865385 | Val Loss: 0.115083, Val Acc: 0.773196\n",
      "Epoch 19923 - Train Loss: 0.086729, Train Acc: 0.865385 | Val Loss: 0.115082, Val Acc: 0.773196\n",
      "Epoch 19924 - Train Loss: 0.086726, Train Acc: 0.865385 | Val Loss: 0.115081, Val Acc: 0.773196\n",
      "Epoch 19925 - Train Loss: 0.086724, Train Acc: 0.865385 | Val Loss: 0.115080, Val Acc: 0.773196\n",
      "Epoch 19926 - Train Loss: 0.086722, Train Acc: 0.865385 | Val Loss: 0.115079, Val Acc: 0.773196\n",
      "Epoch 19927 - Train Loss: 0.086720, Train Acc: 0.865385 | Val Loss: 0.115078, Val Acc: 0.773196\n",
      "Epoch 19928 - Train Loss: 0.086717, Train Acc: 0.865385 | Val Loss: 0.115077, Val Acc: 0.773196\n",
      "Epoch 19929 - Train Loss: 0.086715, Train Acc: 0.865385 | Val Loss: 0.115076, Val Acc: 0.773196\n",
      "Epoch 19930 - Train Loss: 0.086713, Train Acc: 0.865385 | Val Loss: 0.115075, Val Acc: 0.773196\n",
      "Epoch 19931 - Train Loss: 0.086711, Train Acc: 0.865385 | Val Loss: 0.115074, Val Acc: 0.773196\n",
      "Epoch 19932 - Train Loss: 0.086708, Train Acc: 0.865385 | Val Loss: 0.115073, Val Acc: 0.773196\n",
      "Epoch 19933 - Train Loss: 0.086706, Train Acc: 0.865385 | Val Loss: 0.115072, Val Acc: 0.773196\n",
      "Epoch 19934 - Train Loss: 0.086704, Train Acc: 0.865385 | Val Loss: 0.115070, Val Acc: 0.773196\n",
      "Epoch 19935 - Train Loss: 0.086702, Train Acc: 0.865385 | Val Loss: 0.115069, Val Acc: 0.773196\n",
      "Epoch 19936 - Train Loss: 0.086699, Train Acc: 0.865385 | Val Loss: 0.115068, Val Acc: 0.773196\n",
      "Epoch 19937 - Train Loss: 0.086697, Train Acc: 0.865385 | Val Loss: 0.115067, Val Acc: 0.773196\n",
      "Epoch 19938 - Train Loss: 0.086695, Train Acc: 0.865385 | Val Loss: 0.115066, Val Acc: 0.773196\n",
      "Epoch 19939 - Train Loss: 0.086693, Train Acc: 0.865385 | Val Loss: 0.115065, Val Acc: 0.773196\n",
      "Epoch 19940 - Train Loss: 0.086690, Train Acc: 0.865385 | Val Loss: 0.115064, Val Acc: 0.773196\n",
      "Epoch 19941 - Train Loss: 0.086688, Train Acc: 0.865385 | Val Loss: 0.115063, Val Acc: 0.773196\n",
      "Epoch 19942 - Train Loss: 0.086686, Train Acc: 0.865385 | Val Loss: 0.115062, Val Acc: 0.773196\n",
      "Epoch 19943 - Train Loss: 0.086684, Train Acc: 0.865385 | Val Loss: 0.115061, Val Acc: 0.773196\n",
      "Epoch 19944 - Train Loss: 0.086681, Train Acc: 0.865385 | Val Loss: 0.115060, Val Acc: 0.773196\n",
      "Epoch 19945 - Train Loss: 0.086679, Train Acc: 0.865385 | Val Loss: 0.115059, Val Acc: 0.773196\n",
      "Epoch 19946 - Train Loss: 0.086677, Train Acc: 0.865385 | Val Loss: 0.115058, Val Acc: 0.773196\n",
      "Epoch 19947 - Train Loss: 0.086675, Train Acc: 0.865385 | Val Loss: 0.115057, Val Acc: 0.773196\n",
      "Epoch 19948 - Train Loss: 0.086672, Train Acc: 0.865385 | Val Loss: 0.115056, Val Acc: 0.773196\n",
      "Epoch 19949 - Train Loss: 0.086670, Train Acc: 0.865385 | Val Loss: 0.115054, Val Acc: 0.773196\n",
      "Epoch 19950 - Train Loss: 0.086668, Train Acc: 0.865385 | Val Loss: 0.115053, Val Acc: 0.773196\n",
      "Epoch 19951 - Train Loss: 0.086666, Train Acc: 0.865385 | Val Loss: 0.115052, Val Acc: 0.773196\n",
      "Epoch 19952 - Train Loss: 0.086663, Train Acc: 0.865385 | Val Loss: 0.115051, Val Acc: 0.773196\n",
      "Epoch 19953 - Train Loss: 0.086661, Train Acc: 0.865385 | Val Loss: 0.115050, Val Acc: 0.773196\n",
      "Epoch 19954 - Train Loss: 0.086659, Train Acc: 0.865385 | Val Loss: 0.115049, Val Acc: 0.773196\n",
      "Epoch 19955 - Train Loss: 0.086657, Train Acc: 0.865385 | Val Loss: 0.115048, Val Acc: 0.773196\n",
      "Epoch 19956 - Train Loss: 0.086654, Train Acc: 0.865385 | Val Loss: 0.115047, Val Acc: 0.773196\n",
      "Epoch 19957 - Train Loss: 0.086652, Train Acc: 0.865385 | Val Loss: 0.115046, Val Acc: 0.773196\n",
      "Epoch 19958 - Train Loss: 0.086650, Train Acc: 0.865385 | Val Loss: 0.115045, Val Acc: 0.773196\n",
      "Epoch 19959 - Train Loss: 0.086648, Train Acc: 0.865385 | Val Loss: 0.115044, Val Acc: 0.773196\n",
      "Epoch 19960 - Train Loss: 0.086645, Train Acc: 0.865385 | Val Loss: 0.115043, Val Acc: 0.773196\n",
      "Epoch 19961 - Train Loss: 0.086643, Train Acc: 0.865385 | Val Loss: 0.115042, Val Acc: 0.773196\n",
      "Epoch 19962 - Train Loss: 0.086641, Train Acc: 0.865385 | Val Loss: 0.115041, Val Acc: 0.773196\n",
      "Epoch 19963 - Train Loss: 0.086639, Train Acc: 0.865385 | Val Loss: 0.115040, Val Acc: 0.773196\n",
      "Epoch 19964 - Train Loss: 0.086636, Train Acc: 0.865385 | Val Loss: 0.115039, Val Acc: 0.773196\n",
      "Epoch 19965 - Train Loss: 0.086634, Train Acc: 0.865385 | Val Loss: 0.115037, Val Acc: 0.773196\n",
      "Epoch 19966 - Train Loss: 0.086632, Train Acc: 0.865385 | Val Loss: 0.115036, Val Acc: 0.773196\n",
      "Epoch 19967 - Train Loss: 0.086630, Train Acc: 0.865385 | Val Loss: 0.115035, Val Acc: 0.773196\n",
      "Epoch 19968 - Train Loss: 0.086627, Train Acc: 0.865385 | Val Loss: 0.115034, Val Acc: 0.773196\n",
      "Epoch 19969 - Train Loss: 0.086625, Train Acc: 0.865385 | Val Loss: 0.115033, Val Acc: 0.773196\n",
      "Epoch 19970 - Train Loss: 0.086623, Train Acc: 0.865385 | Val Loss: 0.115032, Val Acc: 0.773196\n",
      "Epoch 19971 - Train Loss: 0.086621, Train Acc: 0.865385 | Val Loss: 0.115031, Val Acc: 0.773196\n",
      "Epoch 19972 - Train Loss: 0.086618, Train Acc: 0.865385 | Val Loss: 0.115030, Val Acc: 0.773196\n",
      "Epoch 19973 - Train Loss: 0.086616, Train Acc: 0.865385 | Val Loss: 0.115029, Val Acc: 0.773196\n",
      "Epoch 19974 - Train Loss: 0.086614, Train Acc: 0.865385 | Val Loss: 0.115028, Val Acc: 0.773196\n",
      "Epoch 19975 - Train Loss: 0.086612, Train Acc: 0.865385 | Val Loss: 0.115027, Val Acc: 0.773196\n",
      "Epoch 19976 - Train Loss: 0.086609, Train Acc: 0.865385 | Val Loss: 0.115026, Val Acc: 0.773196\n",
      "Epoch 19977 - Train Loss: 0.086607, Train Acc: 0.865385 | Val Loss: 0.115025, Val Acc: 0.773196\n",
      "Epoch 19978 - Train Loss: 0.086605, Train Acc: 0.865385 | Val Loss: 0.115024, Val Acc: 0.773196\n",
      "Epoch 19979 - Train Loss: 0.086603, Train Acc: 0.865385 | Val Loss: 0.115023, Val Acc: 0.773196\n",
      "Epoch 19980 - Train Loss: 0.086600, Train Acc: 0.865385 | Val Loss: 0.115022, Val Acc: 0.773196\n",
      "Epoch 19981 - Train Loss: 0.086598, Train Acc: 0.865385 | Val Loss: 0.115020, Val Acc: 0.773196\n",
      "Epoch 19982 - Train Loss: 0.086596, Train Acc: 0.865385 | Val Loss: 0.115019, Val Acc: 0.773196\n",
      "Epoch 19983 - Train Loss: 0.086594, Train Acc: 0.865385 | Val Loss: 0.115018, Val Acc: 0.773196\n",
      "Epoch 19984 - Train Loss: 0.086591, Train Acc: 0.865385 | Val Loss: 0.115017, Val Acc: 0.773196\n",
      "Epoch 19985 - Train Loss: 0.086589, Train Acc: 0.865385 | Val Loss: 0.115016, Val Acc: 0.773196\n",
      "Epoch 19986 - Train Loss: 0.086587, Train Acc: 0.865385 | Val Loss: 0.115015, Val Acc: 0.773196\n",
      "Epoch 19987 - Train Loss: 0.086585, Train Acc: 0.865385 | Val Loss: 0.115014, Val Acc: 0.773196\n",
      "Epoch 19988 - Train Loss: 0.086582, Train Acc: 0.865385 | Val Loss: 0.115013, Val Acc: 0.773196\n",
      "Epoch 19989 - Train Loss: 0.086580, Train Acc: 0.865385 | Val Loss: 0.115012, Val Acc: 0.773196\n",
      "Epoch 19990 - Train Loss: 0.086578, Train Acc: 0.865385 | Val Loss: 0.115011, Val Acc: 0.773196\n",
      "Epoch 19991 - Train Loss: 0.086576, Train Acc: 0.865385 | Val Loss: 0.115010, Val Acc: 0.773196\n",
      "Epoch 19992 - Train Loss: 0.086574, Train Acc: 0.865385 | Val Loss: 0.115009, Val Acc: 0.773196\n",
      "Epoch 19993 - Train Loss: 0.086571, Train Acc: 0.865385 | Val Loss: 0.115008, Val Acc: 0.773196\n",
      "Epoch 19994 - Train Loss: 0.086569, Train Acc: 0.865385 | Val Loss: 0.115007, Val Acc: 0.773196\n",
      "Epoch 19995 - Train Loss: 0.086567, Train Acc: 0.865385 | Val Loss: 0.115006, Val Acc: 0.773196\n",
      "Epoch 19996 - Train Loss: 0.086565, Train Acc: 0.865385 | Val Loss: 0.115005, Val Acc: 0.773196\n",
      "Epoch 19997 - Train Loss: 0.086562, Train Acc: 0.865385 | Val Loss: 0.115004, Val Acc: 0.773196\n",
      "Epoch 19998 - Train Loss: 0.086560, Train Acc: 0.865385 | Val Loss: 0.115002, Val Acc: 0.773196\n",
      "Epoch 19999 - Train Loss: 0.086558, Train Acc: 0.865385 | Val Loss: 0.115001, Val Acc: 0.773196\n",
      "Epoch 20000 - Train Loss: 0.086556, Train Acc: 0.865385 | Val Loss: 0.115000, Val Acc: 0.773196\n",
      "Epoch 20001 - Train Loss: 0.086553, Train Acc: 0.865385 | Val Loss: 0.114999, Val Acc: 0.773196\n",
      "Epoch 20002 - Train Loss: 0.086551, Train Acc: 0.865385 | Val Loss: 0.114998, Val Acc: 0.773196\n",
      "Epoch 20003 - Train Loss: 0.086549, Train Acc: 0.865385 | Val Loss: 0.114997, Val Acc: 0.773196\n",
      "Epoch 20004 - Train Loss: 0.086547, Train Acc: 0.865385 | Val Loss: 0.114996, Val Acc: 0.773196\n",
      "Epoch 20005 - Train Loss: 0.086544, Train Acc: 0.865385 | Val Loss: 0.114995, Val Acc: 0.773196\n",
      "Epoch 20006 - Train Loss: 0.086542, Train Acc: 0.865385 | Val Loss: 0.114994, Val Acc: 0.773196\n",
      "Epoch 20007 - Train Loss: 0.086540, Train Acc: 0.865385 | Val Loss: 0.114993, Val Acc: 0.773196\n",
      "Epoch 20008 - Train Loss: 0.086538, Train Acc: 0.865385 | Val Loss: 0.114992, Val Acc: 0.773196\n",
      "Epoch 20009 - Train Loss: 0.086535, Train Acc: 0.865385 | Val Loss: 0.114991, Val Acc: 0.773196\n",
      "Epoch 20010 - Train Loss: 0.086533, Train Acc: 0.865385 | Val Loss: 0.114990, Val Acc: 0.773196\n",
      "Epoch 20011 - Train Loss: 0.086531, Train Acc: 0.865385 | Val Loss: 0.114989, Val Acc: 0.773196\n",
      "Epoch 20012 - Train Loss: 0.086529, Train Acc: 0.865385 | Val Loss: 0.114988, Val Acc: 0.773196\n",
      "Epoch 20013 - Train Loss: 0.086526, Train Acc: 0.865385 | Val Loss: 0.114987, Val Acc: 0.773196\n",
      "Epoch 20014 - Train Loss: 0.086524, Train Acc: 0.865385 | Val Loss: 0.114986, Val Acc: 0.773196\n",
      "Epoch 20015 - Train Loss: 0.086522, Train Acc: 0.865385 | Val Loss: 0.114984, Val Acc: 0.773196\n",
      "Epoch 20016 - Train Loss: 0.086520, Train Acc: 0.865385 | Val Loss: 0.114983, Val Acc: 0.773196\n",
      "Epoch 20017 - Train Loss: 0.086518, Train Acc: 0.865385 | Val Loss: 0.114982, Val Acc: 0.773196\n",
      "Epoch 20018 - Train Loss: 0.086515, Train Acc: 0.865385 | Val Loss: 0.114981, Val Acc: 0.773196\n",
      "Epoch 20019 - Train Loss: 0.086513, Train Acc: 0.865385 | Val Loss: 0.114980, Val Acc: 0.773196\n",
      "Epoch 20020 - Train Loss: 0.086511, Train Acc: 0.865385 | Val Loss: 0.114979, Val Acc: 0.773196\n",
      "Epoch 20021 - Train Loss: 0.086509, Train Acc: 0.865385 | Val Loss: 0.114978, Val Acc: 0.773196\n",
      "Epoch 20022 - Train Loss: 0.086506, Train Acc: 0.865385 | Val Loss: 0.114977, Val Acc: 0.773196\n",
      "Epoch 20023 - Train Loss: 0.086504, Train Acc: 0.865385 | Val Loss: 0.114976, Val Acc: 0.773196\n",
      "Epoch 20024 - Train Loss: 0.086502, Train Acc: 0.865385 | Val Loss: 0.114975, Val Acc: 0.773196\n",
      "Epoch 20025 - Train Loss: 0.086500, Train Acc: 0.865385 | Val Loss: 0.114974, Val Acc: 0.773196\n",
      "Epoch 20026 - Train Loss: 0.086497, Train Acc: 0.865385 | Val Loss: 0.114973, Val Acc: 0.773196\n",
      "Epoch 20027 - Train Loss: 0.086495, Train Acc: 0.865385 | Val Loss: 0.114972, Val Acc: 0.773196\n",
      "Epoch 20028 - Train Loss: 0.086493, Train Acc: 0.865385 | Val Loss: 0.114971, Val Acc: 0.773196\n",
      "Epoch 20029 - Train Loss: 0.086491, Train Acc: 0.865385 | Val Loss: 0.114970, Val Acc: 0.773196\n",
      "Epoch 20030 - Train Loss: 0.086488, Train Acc: 0.865385 | Val Loss: 0.114969, Val Acc: 0.773196\n",
      "Epoch 20031 - Train Loss: 0.086486, Train Acc: 0.865385 | Val Loss: 0.114968, Val Acc: 0.773196\n",
      "Epoch 20032 - Train Loss: 0.086484, Train Acc: 0.865385 | Val Loss: 0.114967, Val Acc: 0.773196\n",
      "Epoch 20033 - Train Loss: 0.086482, Train Acc: 0.865385 | Val Loss: 0.114966, Val Acc: 0.773196\n",
      "Epoch 20034 - Train Loss: 0.086479, Train Acc: 0.865385 | Val Loss: 0.114964, Val Acc: 0.773196\n",
      "Epoch 20035 - Train Loss: 0.086477, Train Acc: 0.865385 | Val Loss: 0.114963, Val Acc: 0.773196\n",
      "Epoch 20036 - Train Loss: 0.086475, Train Acc: 0.865385 | Val Loss: 0.114962, Val Acc: 0.773196\n",
      "Epoch 20037 - Train Loss: 0.086473, Train Acc: 0.865385 | Val Loss: 0.114961, Val Acc: 0.773196\n",
      "Epoch 20038 - Train Loss: 0.086471, Train Acc: 0.865385 | Val Loss: 0.114960, Val Acc: 0.773196\n",
      "Epoch 20039 - Train Loss: 0.086468, Train Acc: 0.865385 | Val Loss: 0.114959, Val Acc: 0.773196\n",
      "Epoch 20040 - Train Loss: 0.086466, Train Acc: 0.865385 | Val Loss: 0.114958, Val Acc: 0.773196\n",
      "Epoch 20041 - Train Loss: 0.086464, Train Acc: 0.865385 | Val Loss: 0.114957, Val Acc: 0.773196\n",
      "Epoch 20042 - Train Loss: 0.086462, Train Acc: 0.865385 | Val Loss: 0.114956, Val Acc: 0.773196\n",
      "Epoch 20043 - Train Loss: 0.086459, Train Acc: 0.865385 | Val Loss: 0.114955, Val Acc: 0.773196\n",
      "Epoch 20044 - Train Loss: 0.086457, Train Acc: 0.865385 | Val Loss: 0.114954, Val Acc: 0.773196\n",
      "Epoch 20045 - Train Loss: 0.086455, Train Acc: 0.865385 | Val Loss: 0.114953, Val Acc: 0.773196\n",
      "Epoch 20046 - Train Loss: 0.086453, Train Acc: 0.865385 | Val Loss: 0.114952, Val Acc: 0.773196\n",
      "Epoch 20047 - Train Loss: 0.086450, Train Acc: 0.865385 | Val Loss: 0.114951, Val Acc: 0.773196\n",
      "Epoch 20048 - Train Loss: 0.086448, Train Acc: 0.865385 | Val Loss: 0.114950, Val Acc: 0.773196\n",
      "Epoch 20049 - Train Loss: 0.086446, Train Acc: 0.865385 | Val Loss: 0.114949, Val Acc: 0.773196\n",
      "Epoch 20050 - Train Loss: 0.086444, Train Acc: 0.865385 | Val Loss: 0.114948, Val Acc: 0.773196\n",
      "Epoch 20051 - Train Loss: 0.086442, Train Acc: 0.865385 | Val Loss: 0.114947, Val Acc: 0.773196\n",
      "Epoch 20052 - Train Loss: 0.086439, Train Acc: 0.865385 | Val Loss: 0.114946, Val Acc: 0.773196\n",
      "Epoch 20053 - Train Loss: 0.086437, Train Acc: 0.865385 | Val Loss: 0.114945, Val Acc: 0.773196\n",
      "Epoch 20054 - Train Loss: 0.086435, Train Acc: 0.865385 | Val Loss: 0.114943, Val Acc: 0.773196\n",
      "Epoch 20055 - Train Loss: 0.086433, Train Acc: 0.865385 | Val Loss: 0.114942, Val Acc: 0.773196\n",
      "Epoch 20056 - Train Loss: 0.086430, Train Acc: 0.865385 | Val Loss: 0.114941, Val Acc: 0.773196\n",
      "Epoch 20057 - Train Loss: 0.086428, Train Acc: 0.865385 | Val Loss: 0.114940, Val Acc: 0.773196\n",
      "Epoch 20058 - Train Loss: 0.086426, Train Acc: 0.865385 | Val Loss: 0.114939, Val Acc: 0.773196\n",
      "Epoch 20059 - Train Loss: 0.086424, Train Acc: 0.865385 | Val Loss: 0.114938, Val Acc: 0.773196\n",
      "Epoch 20060 - Train Loss: 0.086421, Train Acc: 0.865385 | Val Loss: 0.114937, Val Acc: 0.773196\n",
      "Epoch 20061 - Train Loss: 0.086419, Train Acc: 0.865385 | Val Loss: 0.114936, Val Acc: 0.773196\n",
      "Epoch 20062 - Train Loss: 0.086417, Train Acc: 0.865385 | Val Loss: 0.114935, Val Acc: 0.773196\n",
      "Epoch 20063 - Train Loss: 0.086415, Train Acc: 0.865385 | Val Loss: 0.114934, Val Acc: 0.773196\n",
      "Epoch 20064 - Train Loss: 0.086413, Train Acc: 0.865385 | Val Loss: 0.114933, Val Acc: 0.773196\n",
      "Epoch 20065 - Train Loss: 0.086410, Train Acc: 0.865385 | Val Loss: 0.114932, Val Acc: 0.773196\n",
      "Epoch 20066 - Train Loss: 0.086408, Train Acc: 0.865385 | Val Loss: 0.114931, Val Acc: 0.773196\n",
      "Epoch 20067 - Train Loss: 0.086406, Train Acc: 0.865385 | Val Loss: 0.114930, Val Acc: 0.773196\n",
      "Epoch 20068 - Train Loss: 0.086404, Train Acc: 0.865385 | Val Loss: 0.114929, Val Acc: 0.773196\n",
      "Epoch 20069 - Train Loss: 0.086401, Train Acc: 0.865385 | Val Loss: 0.114928, Val Acc: 0.773196\n",
      "Epoch 20070 - Train Loss: 0.086399, Train Acc: 0.865385 | Val Loss: 0.114927, Val Acc: 0.773196\n",
      "Epoch 20071 - Train Loss: 0.086397, Train Acc: 0.865385 | Val Loss: 0.114926, Val Acc: 0.773196\n",
      "Epoch 20072 - Train Loss: 0.086395, Train Acc: 0.865385 | Val Loss: 0.114925, Val Acc: 0.773196\n",
      "Epoch 20073 - Train Loss: 0.086392, Train Acc: 0.865385 | Val Loss: 0.114924, Val Acc: 0.773196\n",
      "Epoch 20074 - Train Loss: 0.086390, Train Acc: 0.865385 | Val Loss: 0.114923, Val Acc: 0.773196\n",
      "Epoch 20075 - Train Loss: 0.086388, Train Acc: 0.865385 | Val Loss: 0.114921, Val Acc: 0.773196\n",
      "Epoch 20076 - Train Loss: 0.086386, Train Acc: 0.865385 | Val Loss: 0.114920, Val Acc: 0.773196\n",
      "Epoch 20077 - Train Loss: 0.086384, Train Acc: 0.865385 | Val Loss: 0.114919, Val Acc: 0.773196\n",
      "Epoch 20078 - Train Loss: 0.086381, Train Acc: 0.865385 | Val Loss: 0.114918, Val Acc: 0.773196\n",
      "Epoch 20079 - Train Loss: 0.086379, Train Acc: 0.865385 | Val Loss: 0.114917, Val Acc: 0.773196\n",
      "Epoch 20080 - Train Loss: 0.086377, Train Acc: 0.865385 | Val Loss: 0.114916, Val Acc: 0.773196\n",
      "Epoch 20081 - Train Loss: 0.086375, Train Acc: 0.865385 | Val Loss: 0.114915, Val Acc: 0.773196\n",
      "Epoch 20082 - Train Loss: 0.086372, Train Acc: 0.865385 | Val Loss: 0.114914, Val Acc: 0.773196\n",
      "Epoch 20083 - Train Loss: 0.086370, Train Acc: 0.865385 | Val Loss: 0.114913, Val Acc: 0.773196\n",
      "Epoch 20084 - Train Loss: 0.086368, Train Acc: 0.865385 | Val Loss: 0.114912, Val Acc: 0.773196\n",
      "Epoch 20085 - Train Loss: 0.086366, Train Acc: 0.865385 | Val Loss: 0.114911, Val Acc: 0.773196\n",
      "Epoch 20086 - Train Loss: 0.086364, Train Acc: 0.865385 | Val Loss: 0.114910, Val Acc: 0.773196\n",
      "Epoch 20087 - Train Loss: 0.086361, Train Acc: 0.865385 | Val Loss: 0.114909, Val Acc: 0.773196\n",
      "Epoch 20088 - Train Loss: 0.086359, Train Acc: 0.865385 | Val Loss: 0.114908, Val Acc: 0.773196\n",
      "Epoch 20089 - Train Loss: 0.086357, Train Acc: 0.865385 | Val Loss: 0.114907, Val Acc: 0.773196\n",
      "Epoch 20090 - Train Loss: 0.086355, Train Acc: 0.865385 | Val Loss: 0.114906, Val Acc: 0.773196\n",
      "Epoch 20091 - Train Loss: 0.086352, Train Acc: 0.865385 | Val Loss: 0.114905, Val Acc: 0.773196\n",
      "Epoch 20092 - Train Loss: 0.086350, Train Acc: 0.865385 | Val Loss: 0.114904, Val Acc: 0.773196\n",
      "Epoch 20093 - Train Loss: 0.086348, Train Acc: 0.865385 | Val Loss: 0.114903, Val Acc: 0.773196\n",
      "Epoch 20094 - Train Loss: 0.086346, Train Acc: 0.865385 | Val Loss: 0.114902, Val Acc: 0.773196\n",
      "Epoch 20095 - Train Loss: 0.086344, Train Acc: 0.865385 | Val Loss: 0.114901, Val Acc: 0.773196\n",
      "Epoch 20096 - Train Loss: 0.086341, Train Acc: 0.865385 | Val Loss: 0.114900, Val Acc: 0.773196\n",
      "Epoch 20097 - Train Loss: 0.086339, Train Acc: 0.865385 | Val Loss: 0.114899, Val Acc: 0.773196\n",
      "Epoch 20098 - Train Loss: 0.086337, Train Acc: 0.865385 | Val Loss: 0.114898, Val Acc: 0.773196\n",
      "Epoch 20099 - Train Loss: 0.086335, Train Acc: 0.865385 | Val Loss: 0.114896, Val Acc: 0.773196\n",
      "Epoch 20100 - Train Loss: 0.086332, Train Acc: 0.865385 | Val Loss: 0.114895, Val Acc: 0.773196\n",
      "Epoch 20101 - Train Loss: 0.086330, Train Acc: 0.865385 | Val Loss: 0.114894, Val Acc: 0.773196\n",
      "Epoch 20102 - Train Loss: 0.086328, Train Acc: 0.865385 | Val Loss: 0.114893, Val Acc: 0.773196\n",
      "Epoch 20103 - Train Loss: 0.086326, Train Acc: 0.865385 | Val Loss: 0.114892, Val Acc: 0.773196\n",
      "Epoch 20104 - Train Loss: 0.086324, Train Acc: 0.865385 | Val Loss: 0.114891, Val Acc: 0.773196\n",
      "Epoch 20105 - Train Loss: 0.086321, Train Acc: 0.865385 | Val Loss: 0.114890, Val Acc: 0.773196\n",
      "Epoch 20106 - Train Loss: 0.086319, Train Acc: 0.865385 | Val Loss: 0.114889, Val Acc: 0.773196\n",
      "Epoch 20107 - Train Loss: 0.086317, Train Acc: 0.865385 | Val Loss: 0.114888, Val Acc: 0.773196\n",
      "Epoch 20108 - Train Loss: 0.086315, Train Acc: 0.865385 | Val Loss: 0.114887, Val Acc: 0.773196\n",
      "Epoch 20109 - Train Loss: 0.086312, Train Acc: 0.865385 | Val Loss: 0.114886, Val Acc: 0.773196\n",
      "Epoch 20110 - Train Loss: 0.086310, Train Acc: 0.865385 | Val Loss: 0.114885, Val Acc: 0.773196\n",
      "Epoch 20111 - Train Loss: 0.086308, Train Acc: 0.865385 | Val Loss: 0.114884, Val Acc: 0.773196\n",
      "Epoch 20112 - Train Loss: 0.086306, Train Acc: 0.865385 | Val Loss: 0.114883, Val Acc: 0.773196\n",
      "Epoch 20113 - Train Loss: 0.086304, Train Acc: 0.865385 | Val Loss: 0.114882, Val Acc: 0.773196\n",
      "Epoch 20114 - Train Loss: 0.086301, Train Acc: 0.865385 | Val Loss: 0.114881, Val Acc: 0.773196\n",
      "Epoch 20115 - Train Loss: 0.086299, Train Acc: 0.865385 | Val Loss: 0.114880, Val Acc: 0.773196\n",
      "Epoch 20116 - Train Loss: 0.086297, Train Acc: 0.865385 | Val Loss: 0.114879, Val Acc: 0.773196\n",
      "Epoch 20117 - Train Loss: 0.086295, Train Acc: 0.865385 | Val Loss: 0.114878, Val Acc: 0.773196\n",
      "Epoch 20118 - Train Loss: 0.086292, Train Acc: 0.865385 | Val Loss: 0.114877, Val Acc: 0.773196\n",
      "Epoch 20119 - Train Loss: 0.086290, Train Acc: 0.865385 | Val Loss: 0.114876, Val Acc: 0.773196\n",
      "Epoch 20120 - Train Loss: 0.086288, Train Acc: 0.865385 | Val Loss: 0.114875, Val Acc: 0.773196\n",
      "Epoch 20121 - Train Loss: 0.086286, Train Acc: 0.865385 | Val Loss: 0.114874, Val Acc: 0.773196\n",
      "Epoch 20122 - Train Loss: 0.086284, Train Acc: 0.865385 | Val Loss: 0.114873, Val Acc: 0.773196\n",
      "Epoch 20123 - Train Loss: 0.086281, Train Acc: 0.865385 | Val Loss: 0.114872, Val Acc: 0.773196\n",
      "Epoch 20124 - Train Loss: 0.086279, Train Acc: 0.865385 | Val Loss: 0.114870, Val Acc: 0.773196\n",
      "Epoch 20125 - Train Loss: 0.086277, Train Acc: 0.865385 | Val Loss: 0.114869, Val Acc: 0.773196\n",
      "Epoch 20126 - Train Loss: 0.086275, Train Acc: 0.865385 | Val Loss: 0.114868, Val Acc: 0.773196\n",
      "Epoch 20127 - Train Loss: 0.086272, Train Acc: 0.865385 | Val Loss: 0.114867, Val Acc: 0.773196\n",
      "Epoch 20128 - Train Loss: 0.086270, Train Acc: 0.865385 | Val Loss: 0.114866, Val Acc: 0.773196\n",
      "Epoch 20129 - Train Loss: 0.086268, Train Acc: 0.865385 | Val Loss: 0.114865, Val Acc: 0.773196\n",
      "Epoch 20130 - Train Loss: 0.086266, Train Acc: 0.865385 | Val Loss: 0.114864, Val Acc: 0.773196\n",
      "Epoch 20131 - Train Loss: 0.086264, Train Acc: 0.865385 | Val Loss: 0.114863, Val Acc: 0.773196\n",
      "Epoch 20132 - Train Loss: 0.086261, Train Acc: 0.865385 | Val Loss: 0.114862, Val Acc: 0.773196\n",
      "Epoch 20133 - Train Loss: 0.086259, Train Acc: 0.865385 | Val Loss: 0.114861, Val Acc: 0.773196\n",
      "Epoch 20134 - Train Loss: 0.086257, Train Acc: 0.865385 | Val Loss: 0.114860, Val Acc: 0.773196\n",
      "Epoch 20135 - Train Loss: 0.086255, Train Acc: 0.865385 | Val Loss: 0.114859, Val Acc: 0.773196\n",
      "Epoch 20136 - Train Loss: 0.086253, Train Acc: 0.865385 | Val Loss: 0.114858, Val Acc: 0.773196\n",
      "Epoch 20137 - Train Loss: 0.086250, Train Acc: 0.865385 | Val Loss: 0.114857, Val Acc: 0.773196\n",
      "Epoch 20138 - Train Loss: 0.086248, Train Acc: 0.865385 | Val Loss: 0.114856, Val Acc: 0.773196\n",
      "Epoch 20139 - Train Loss: 0.086246, Train Acc: 0.865385 | Val Loss: 0.114855, Val Acc: 0.773196\n",
      "Epoch 20140 - Train Loss: 0.086244, Train Acc: 0.865385 | Val Loss: 0.114854, Val Acc: 0.773196\n",
      "Epoch 20141 - Train Loss: 0.086241, Train Acc: 0.865385 | Val Loss: 0.114853, Val Acc: 0.773196\n",
      "Epoch 20142 - Train Loss: 0.086239, Train Acc: 0.865385 | Val Loss: 0.114852, Val Acc: 0.773196\n",
      "Epoch 20143 - Train Loss: 0.086237, Train Acc: 0.865385 | Val Loss: 0.114851, Val Acc: 0.773196\n",
      "Epoch 20144 - Train Loss: 0.086235, Train Acc: 0.865385 | Val Loss: 0.114850, Val Acc: 0.773196\n",
      "Epoch 20145 - Train Loss: 0.086233, Train Acc: 0.865385 | Val Loss: 0.114849, Val Acc: 0.773196\n",
      "Epoch 20146 - Train Loss: 0.086230, Train Acc: 0.865385 | Val Loss: 0.114848, Val Acc: 0.773196\n",
      "Epoch 20147 - Train Loss: 0.086228, Train Acc: 0.865385 | Val Loss: 0.114847, Val Acc: 0.773196\n",
      "Epoch 20148 - Train Loss: 0.086226, Train Acc: 0.865385 | Val Loss: 0.114846, Val Acc: 0.773196\n",
      "Epoch 20149 - Train Loss: 0.086224, Train Acc: 0.865385 | Val Loss: 0.114845, Val Acc: 0.773196\n",
      "Epoch 20150 - Train Loss: 0.086222, Train Acc: 0.865385 | Val Loss: 0.114844, Val Acc: 0.773196\n",
      "Epoch 20151 - Train Loss: 0.086219, Train Acc: 0.865385 | Val Loss: 0.114843, Val Acc: 0.773196\n",
      "Epoch 20152 - Train Loss: 0.086217, Train Acc: 0.865385 | Val Loss: 0.114841, Val Acc: 0.773196\n",
      "Epoch 20153 - Train Loss: 0.086215, Train Acc: 0.865385 | Val Loss: 0.114840, Val Acc: 0.773196\n",
      "Epoch 20154 - Train Loss: 0.086213, Train Acc: 0.865385 | Val Loss: 0.114839, Val Acc: 0.773196\n",
      "Epoch 20155 - Train Loss: 0.086210, Train Acc: 0.865385 | Val Loss: 0.114838, Val Acc: 0.773196\n",
      "Epoch 20156 - Train Loss: 0.086208, Train Acc: 0.865385 | Val Loss: 0.114837, Val Acc: 0.773196\n",
      "Epoch 20157 - Train Loss: 0.086206, Train Acc: 0.865385 | Val Loss: 0.114836, Val Acc: 0.773196\n",
      "Epoch 20158 - Train Loss: 0.086204, Train Acc: 0.865385 | Val Loss: 0.114835, Val Acc: 0.773196\n",
      "Epoch 20159 - Train Loss: 0.086202, Train Acc: 0.865385 | Val Loss: 0.114834, Val Acc: 0.773196\n",
      "Epoch 20160 - Train Loss: 0.086199, Train Acc: 0.865385 | Val Loss: 0.114833, Val Acc: 0.773196\n",
      "Epoch 20161 - Train Loss: 0.086197, Train Acc: 0.865385 | Val Loss: 0.114832, Val Acc: 0.773196\n",
      "Epoch 20162 - Train Loss: 0.086195, Train Acc: 0.865385 | Val Loss: 0.114831, Val Acc: 0.773196\n",
      "Epoch 20163 - Train Loss: 0.086193, Train Acc: 0.865385 | Val Loss: 0.114830, Val Acc: 0.773196\n",
      "Epoch 20164 - Train Loss: 0.086191, Train Acc: 0.865385 | Val Loss: 0.114829, Val Acc: 0.773196\n",
      "Epoch 20165 - Train Loss: 0.086188, Train Acc: 0.865385 | Val Loss: 0.114828, Val Acc: 0.773196\n",
      "Epoch 20166 - Train Loss: 0.086186, Train Acc: 0.865385 | Val Loss: 0.114827, Val Acc: 0.773196\n",
      "Epoch 20167 - Train Loss: 0.086184, Train Acc: 0.865385 | Val Loss: 0.114826, Val Acc: 0.773196\n",
      "Epoch 20168 - Train Loss: 0.086182, Train Acc: 0.865385 | Val Loss: 0.114825, Val Acc: 0.773196\n",
      "Epoch 20169 - Train Loss: 0.086180, Train Acc: 0.865385 | Val Loss: 0.114824, Val Acc: 0.773196\n",
      "Epoch 20170 - Train Loss: 0.086177, Train Acc: 0.865385 | Val Loss: 0.114823, Val Acc: 0.773196\n",
      "Epoch 20171 - Train Loss: 0.086175, Train Acc: 0.865385 | Val Loss: 0.114822, Val Acc: 0.773196\n",
      "Epoch 20172 - Train Loss: 0.086173, Train Acc: 0.865385 | Val Loss: 0.114821, Val Acc: 0.773196\n",
      "Epoch 20173 - Train Loss: 0.086171, Train Acc: 0.865385 | Val Loss: 0.114820, Val Acc: 0.773196\n",
      "Epoch 20174 - Train Loss: 0.086168, Train Acc: 0.865385 | Val Loss: 0.114819, Val Acc: 0.773196\n",
      "Epoch 20175 - Train Loss: 0.086166, Train Acc: 0.865385 | Val Loss: 0.114818, Val Acc: 0.773196\n",
      "Epoch 20176 - Train Loss: 0.086164, Train Acc: 0.865385 | Val Loss: 0.114817, Val Acc: 0.773196\n",
      "Epoch 20177 - Train Loss: 0.086162, Train Acc: 0.865385 | Val Loss: 0.114816, Val Acc: 0.773196\n",
      "Epoch 20178 - Train Loss: 0.086160, Train Acc: 0.866667 | Val Loss: 0.114815, Val Acc: 0.773196\n",
      "Epoch 20179 - Train Loss: 0.086157, Train Acc: 0.866667 | Val Loss: 0.114814, Val Acc: 0.773196\n",
      "Epoch 20180 - Train Loss: 0.086155, Train Acc: 0.866667 | Val Loss: 0.114813, Val Acc: 0.773196\n",
      "Epoch 20181 - Train Loss: 0.086153, Train Acc: 0.866667 | Val Loss: 0.114812, Val Acc: 0.773196\n",
      "Epoch 20182 - Train Loss: 0.086151, Train Acc: 0.866667 | Val Loss: 0.114811, Val Acc: 0.773196\n",
      "Epoch 20183 - Train Loss: 0.086149, Train Acc: 0.866667 | Val Loss: 0.114810, Val Acc: 0.773196\n",
      "Epoch 20184 - Train Loss: 0.086146, Train Acc: 0.866667 | Val Loss: 0.114809, Val Acc: 0.773196\n",
      "Epoch 20185 - Train Loss: 0.086144, Train Acc: 0.866667 | Val Loss: 0.114808, Val Acc: 0.773196\n",
      "Epoch 20186 - Train Loss: 0.086142, Train Acc: 0.866667 | Val Loss: 0.114806, Val Acc: 0.773196\n",
      "Epoch 20187 - Train Loss: 0.086140, Train Acc: 0.866667 | Val Loss: 0.114805, Val Acc: 0.773196\n",
      "Epoch 20188 - Train Loss: 0.086138, Train Acc: 0.866667 | Val Loss: 0.114804, Val Acc: 0.773196\n",
      "Epoch 20189 - Train Loss: 0.086135, Train Acc: 0.866667 | Val Loss: 0.114803, Val Acc: 0.773196\n",
      "Epoch 20190 - Train Loss: 0.086133, Train Acc: 0.866667 | Val Loss: 0.114802, Val Acc: 0.773196\n",
      "Epoch 20191 - Train Loss: 0.086131, Train Acc: 0.866667 | Val Loss: 0.114801, Val Acc: 0.773196\n",
      "Epoch 20192 - Train Loss: 0.086129, Train Acc: 0.866667 | Val Loss: 0.114800, Val Acc: 0.773196\n",
      "Epoch 20193 - Train Loss: 0.086127, Train Acc: 0.866667 | Val Loss: 0.114799, Val Acc: 0.773196\n",
      "Epoch 20194 - Train Loss: 0.086124, Train Acc: 0.866667 | Val Loss: 0.114798, Val Acc: 0.773196\n",
      "Epoch 20195 - Train Loss: 0.086122, Train Acc: 0.866667 | Val Loss: 0.114797, Val Acc: 0.773196\n",
      "Epoch 20196 - Train Loss: 0.086120, Train Acc: 0.866667 | Val Loss: 0.114796, Val Acc: 0.773196\n",
      "Epoch 20197 - Train Loss: 0.086118, Train Acc: 0.866667 | Val Loss: 0.114795, Val Acc: 0.773196\n",
      "Epoch 20198 - Train Loss: 0.086116, Train Acc: 0.866667 | Val Loss: 0.114794, Val Acc: 0.773196\n",
      "Epoch 20199 - Train Loss: 0.086113, Train Acc: 0.866667 | Val Loss: 0.114793, Val Acc: 0.773196\n",
      "Epoch 20200 - Train Loss: 0.086111, Train Acc: 0.866667 | Val Loss: 0.114792, Val Acc: 0.773196\n",
      "Epoch 20201 - Train Loss: 0.086109, Train Acc: 0.866667 | Val Loss: 0.114791, Val Acc: 0.773196\n",
      "Epoch 20202 - Train Loss: 0.086107, Train Acc: 0.866667 | Val Loss: 0.114790, Val Acc: 0.773196\n",
      "Epoch 20203 - Train Loss: 0.086105, Train Acc: 0.866667 | Val Loss: 0.114789, Val Acc: 0.773196\n",
      "Epoch 20204 - Train Loss: 0.086102, Train Acc: 0.866667 | Val Loss: 0.114788, Val Acc: 0.773196\n",
      "Epoch 20205 - Train Loss: 0.086100, Train Acc: 0.866667 | Val Loss: 0.114787, Val Acc: 0.773196\n",
      "Epoch 20206 - Train Loss: 0.086098, Train Acc: 0.866667 | Val Loss: 0.114786, Val Acc: 0.773196\n",
      "Epoch 20207 - Train Loss: 0.086096, Train Acc: 0.866667 | Val Loss: 0.114785, Val Acc: 0.773196\n",
      "Epoch 20208 - Train Loss: 0.086094, Train Acc: 0.866667 | Val Loss: 0.114784, Val Acc: 0.773196\n",
      "Epoch 20209 - Train Loss: 0.086091, Train Acc: 0.866667 | Val Loss: 0.114783, Val Acc: 0.773196\n",
      "Epoch 20210 - Train Loss: 0.086089, Train Acc: 0.866667 | Val Loss: 0.114782, Val Acc: 0.773196\n",
      "Epoch 20211 - Train Loss: 0.086087, Train Acc: 0.866667 | Val Loss: 0.114781, Val Acc: 0.773196\n",
      "Epoch 20212 - Train Loss: 0.086085, Train Acc: 0.866667 | Val Loss: 0.114780, Val Acc: 0.773196\n",
      "Epoch 20213 - Train Loss: 0.086082, Train Acc: 0.866667 | Val Loss: 0.114779, Val Acc: 0.773196\n",
      "Epoch 20214 - Train Loss: 0.086080, Train Acc: 0.866667 | Val Loss: 0.114778, Val Acc: 0.773196\n",
      "Epoch 20215 - Train Loss: 0.086078, Train Acc: 0.866667 | Val Loss: 0.114777, Val Acc: 0.773196\n",
      "Epoch 20216 - Train Loss: 0.086076, Train Acc: 0.866667 | Val Loss: 0.114776, Val Acc: 0.773196\n",
      "Epoch 20217 - Train Loss: 0.086074, Train Acc: 0.866667 | Val Loss: 0.114775, Val Acc: 0.773196\n",
      "Epoch 20218 - Train Loss: 0.086071, Train Acc: 0.866667 | Val Loss: 0.114774, Val Acc: 0.773196\n",
      "Epoch 20219 - Train Loss: 0.086069, Train Acc: 0.866667 | Val Loss: 0.114773, Val Acc: 0.773196\n",
      "Epoch 20220 - Train Loss: 0.086067, Train Acc: 0.866667 | Val Loss: 0.114772, Val Acc: 0.773196\n",
      "Epoch 20221 - Train Loss: 0.086065, Train Acc: 0.866667 | Val Loss: 0.114771, Val Acc: 0.773196\n",
      "Epoch 20222 - Train Loss: 0.086063, Train Acc: 0.866667 | Val Loss: 0.114770, Val Acc: 0.773196\n",
      "Epoch 20223 - Train Loss: 0.086060, Train Acc: 0.866667 | Val Loss: 0.114769, Val Acc: 0.773196\n",
      "Epoch 20224 - Train Loss: 0.086058, Train Acc: 0.866667 | Val Loss: 0.114767, Val Acc: 0.773196\n",
      "Epoch 20225 - Train Loss: 0.086056, Train Acc: 0.866667 | Val Loss: 0.114766, Val Acc: 0.773196\n",
      "Epoch 20226 - Train Loss: 0.086054, Train Acc: 0.866667 | Val Loss: 0.114765, Val Acc: 0.773196\n",
      "Epoch 20227 - Train Loss: 0.086052, Train Acc: 0.866667 | Val Loss: 0.114764, Val Acc: 0.773196\n",
      "Epoch 20228 - Train Loss: 0.086049, Train Acc: 0.866667 | Val Loss: 0.114763, Val Acc: 0.773196\n",
      "Epoch 20229 - Train Loss: 0.086047, Train Acc: 0.866667 | Val Loss: 0.114762, Val Acc: 0.773196\n",
      "Epoch 20230 - Train Loss: 0.086045, Train Acc: 0.866667 | Val Loss: 0.114761, Val Acc: 0.773196\n",
      "Epoch 20231 - Train Loss: 0.086043, Train Acc: 0.866667 | Val Loss: 0.114760, Val Acc: 0.773196\n",
      "Epoch 20232 - Train Loss: 0.086041, Train Acc: 0.866667 | Val Loss: 0.114759, Val Acc: 0.773196\n",
      "Epoch 20233 - Train Loss: 0.086039, Train Acc: 0.866667 | Val Loss: 0.114758, Val Acc: 0.773196\n",
      "Epoch 20234 - Train Loss: 0.086036, Train Acc: 0.866667 | Val Loss: 0.114757, Val Acc: 0.773196\n",
      "Epoch 20235 - Train Loss: 0.086034, Train Acc: 0.866667 | Val Loss: 0.114756, Val Acc: 0.773196\n",
      "Epoch 20236 - Train Loss: 0.086032, Train Acc: 0.866667 | Val Loss: 0.114755, Val Acc: 0.773196\n",
      "Epoch 20237 - Train Loss: 0.086030, Train Acc: 0.866667 | Val Loss: 0.114754, Val Acc: 0.773196\n",
      "Epoch 20238 - Train Loss: 0.086028, Train Acc: 0.866667 | Val Loss: 0.114753, Val Acc: 0.773196\n",
      "Epoch 20239 - Train Loss: 0.086025, Train Acc: 0.866667 | Val Loss: 0.114752, Val Acc: 0.773196\n",
      "Epoch 20240 - Train Loss: 0.086023, Train Acc: 0.866667 | Val Loss: 0.114751, Val Acc: 0.773196\n",
      "Epoch 20241 - Train Loss: 0.086021, Train Acc: 0.866667 | Val Loss: 0.114750, Val Acc: 0.773196\n",
      "Epoch 20242 - Train Loss: 0.086019, Train Acc: 0.866667 | Val Loss: 0.114749, Val Acc: 0.773196\n",
      "Epoch 20243 - Train Loss: 0.086017, Train Acc: 0.866667 | Val Loss: 0.114748, Val Acc: 0.773196\n",
      "Epoch 20244 - Train Loss: 0.086014, Train Acc: 0.866667 | Val Loss: 0.114747, Val Acc: 0.773196\n",
      "Epoch 20245 - Train Loss: 0.086012, Train Acc: 0.866667 | Val Loss: 0.114746, Val Acc: 0.773196\n",
      "Epoch 20246 - Train Loss: 0.086010, Train Acc: 0.866667 | Val Loss: 0.114745, Val Acc: 0.773196\n",
      "Epoch 20247 - Train Loss: 0.086008, Train Acc: 0.866667 | Val Loss: 0.114744, Val Acc: 0.773196\n",
      "Epoch 20248 - Train Loss: 0.086006, Train Acc: 0.866667 | Val Loss: 0.114743, Val Acc: 0.773196\n",
      "Epoch 20249 - Train Loss: 0.086003, Train Acc: 0.866667 | Val Loss: 0.114742, Val Acc: 0.773196\n",
      "Epoch 20250 - Train Loss: 0.086001, Train Acc: 0.866667 | Val Loss: 0.114741, Val Acc: 0.773196\n",
      "Epoch 20251 - Train Loss: 0.085999, Train Acc: 0.866667 | Val Loss: 0.114740, Val Acc: 0.773196\n",
      "Epoch 20252 - Train Loss: 0.085997, Train Acc: 0.867949 | Val Loss: 0.114739, Val Acc: 0.773196\n",
      "Epoch 20253 - Train Loss: 0.085995, Train Acc: 0.867949 | Val Loss: 0.114738, Val Acc: 0.773196\n",
      "Epoch 20254 - Train Loss: 0.085992, Train Acc: 0.867949 | Val Loss: 0.114737, Val Acc: 0.773196\n",
      "Epoch 20255 - Train Loss: 0.085990, Train Acc: 0.867949 | Val Loss: 0.114736, Val Acc: 0.773196\n",
      "Epoch 20256 - Train Loss: 0.085988, Train Acc: 0.867949 | Val Loss: 0.114735, Val Acc: 0.773196\n",
      "Epoch 20257 - Train Loss: 0.085986, Train Acc: 0.867949 | Val Loss: 0.114734, Val Acc: 0.773196\n",
      "Epoch 20258 - Train Loss: 0.085984, Train Acc: 0.867949 | Val Loss: 0.114733, Val Acc: 0.773196\n",
      "Epoch 20259 - Train Loss: 0.085981, Train Acc: 0.867949 | Val Loss: 0.114732, Val Acc: 0.773196\n",
      "Epoch 20260 - Train Loss: 0.085979, Train Acc: 0.867949 | Val Loss: 0.114731, Val Acc: 0.773196\n",
      "Epoch 20261 - Train Loss: 0.085977, Train Acc: 0.867949 | Val Loss: 0.114730, Val Acc: 0.773196\n",
      "Epoch 20262 - Train Loss: 0.085975, Train Acc: 0.867949 | Val Loss: 0.114729, Val Acc: 0.773196\n",
      "Epoch 20263 - Train Loss: 0.085973, Train Acc: 0.867949 | Val Loss: 0.114728, Val Acc: 0.773196\n",
      "Epoch 20264 - Train Loss: 0.085970, Train Acc: 0.867949 | Val Loss: 0.114727, Val Acc: 0.773196\n",
      "Epoch 20265 - Train Loss: 0.085968, Train Acc: 0.867949 | Val Loss: 0.114726, Val Acc: 0.773196\n",
      "Epoch 20266 - Train Loss: 0.085966, Train Acc: 0.867949 | Val Loss: 0.114725, Val Acc: 0.773196\n",
      "Epoch 20267 - Train Loss: 0.085964, Train Acc: 0.867949 | Val Loss: 0.114724, Val Acc: 0.773196\n",
      "Epoch 20268 - Train Loss: 0.085962, Train Acc: 0.867949 | Val Loss: 0.114723, Val Acc: 0.773196\n",
      "Epoch 20269 - Train Loss: 0.085960, Train Acc: 0.867949 | Val Loss: 0.114722, Val Acc: 0.773196\n",
      "Epoch 20270 - Train Loss: 0.085957, Train Acc: 0.867949 | Val Loss: 0.114721, Val Acc: 0.773196\n",
      "Epoch 20271 - Train Loss: 0.085955, Train Acc: 0.867949 | Val Loss: 0.114720, Val Acc: 0.773196\n",
      "Epoch 20272 - Train Loss: 0.085953, Train Acc: 0.867949 | Val Loss: 0.114719, Val Acc: 0.773196\n",
      "Epoch 20273 - Train Loss: 0.085951, Train Acc: 0.867949 | Val Loss: 0.114718, Val Acc: 0.773196\n",
      "Epoch 20274 - Train Loss: 0.085949, Train Acc: 0.867949 | Val Loss: 0.114717, Val Acc: 0.773196\n",
      "Epoch 20275 - Train Loss: 0.085946, Train Acc: 0.867949 | Val Loss: 0.114715, Val Acc: 0.773196\n",
      "Epoch 20276 - Train Loss: 0.085944, Train Acc: 0.867949 | Val Loss: 0.114714, Val Acc: 0.773196\n",
      "Epoch 20277 - Train Loss: 0.085942, Train Acc: 0.867949 | Val Loss: 0.114713, Val Acc: 0.773196\n",
      "Epoch 20278 - Train Loss: 0.085940, Train Acc: 0.867949 | Val Loss: 0.114712, Val Acc: 0.773196\n",
      "Epoch 20279 - Train Loss: 0.085938, Train Acc: 0.867949 | Val Loss: 0.114711, Val Acc: 0.773196\n",
      "Epoch 20280 - Train Loss: 0.085935, Train Acc: 0.867949 | Val Loss: 0.114710, Val Acc: 0.773196\n",
      "Epoch 20281 - Train Loss: 0.085933, Train Acc: 0.867949 | Val Loss: 0.114709, Val Acc: 0.773196\n",
      "Epoch 20282 - Train Loss: 0.085931, Train Acc: 0.867949 | Val Loss: 0.114708, Val Acc: 0.773196\n",
      "Epoch 20283 - Train Loss: 0.085929, Train Acc: 0.867949 | Val Loss: 0.114707, Val Acc: 0.773196\n",
      "Epoch 20284 - Train Loss: 0.085927, Train Acc: 0.867949 | Val Loss: 0.114706, Val Acc: 0.773196\n",
      "Epoch 20285 - Train Loss: 0.085924, Train Acc: 0.867949 | Val Loss: 0.114705, Val Acc: 0.773196\n",
      "Epoch 20286 - Train Loss: 0.085922, Train Acc: 0.867949 | Val Loss: 0.114704, Val Acc: 0.773196\n",
      "Epoch 20287 - Train Loss: 0.085920, Train Acc: 0.867949 | Val Loss: 0.114703, Val Acc: 0.773196\n",
      "Epoch 20288 - Train Loss: 0.085918, Train Acc: 0.867949 | Val Loss: 0.114702, Val Acc: 0.773196\n",
      "Epoch 20289 - Train Loss: 0.085916, Train Acc: 0.867949 | Val Loss: 0.114701, Val Acc: 0.773196\n",
      "Epoch 20290 - Train Loss: 0.085914, Train Acc: 0.867949 | Val Loss: 0.114700, Val Acc: 0.773196\n",
      "Epoch 20291 - Train Loss: 0.085911, Train Acc: 0.867949 | Val Loss: 0.114699, Val Acc: 0.773196\n",
      "Epoch 20292 - Train Loss: 0.085909, Train Acc: 0.867949 | Val Loss: 0.114698, Val Acc: 0.773196\n",
      "Epoch 20293 - Train Loss: 0.085907, Train Acc: 0.867949 | Val Loss: 0.114697, Val Acc: 0.773196\n",
      "Epoch 20294 - Train Loss: 0.085905, Train Acc: 0.867949 | Val Loss: 0.114696, Val Acc: 0.773196\n",
      "Epoch 20295 - Train Loss: 0.085903, Train Acc: 0.867949 | Val Loss: 0.114695, Val Acc: 0.773196\n",
      "Epoch 20296 - Train Loss: 0.085900, Train Acc: 0.867949 | Val Loss: 0.114694, Val Acc: 0.773196\n",
      "Epoch 20297 - Train Loss: 0.085898, Train Acc: 0.867949 | Val Loss: 0.114693, Val Acc: 0.773196\n",
      "Epoch 20298 - Train Loss: 0.085896, Train Acc: 0.867949 | Val Loss: 0.114692, Val Acc: 0.773196\n",
      "Epoch 20299 - Train Loss: 0.085894, Train Acc: 0.867949 | Val Loss: 0.114691, Val Acc: 0.773196\n",
      "Epoch 20300 - Train Loss: 0.085892, Train Acc: 0.867949 | Val Loss: 0.114690, Val Acc: 0.773196\n",
      "Epoch 20301 - Train Loss: 0.085889, Train Acc: 0.867949 | Val Loss: 0.114689, Val Acc: 0.773196\n",
      "Epoch 20302 - Train Loss: 0.085887, Train Acc: 0.867949 | Val Loss: 0.114688, Val Acc: 0.773196\n",
      "Epoch 20303 - Train Loss: 0.085885, Train Acc: 0.867949 | Val Loss: 0.114687, Val Acc: 0.773196\n",
      "Epoch 20304 - Train Loss: 0.085883, Train Acc: 0.867949 | Val Loss: 0.114686, Val Acc: 0.773196\n",
      "Epoch 20305 - Train Loss: 0.085881, Train Acc: 0.867949 | Val Loss: 0.114685, Val Acc: 0.773196\n",
      "Epoch 20306 - Train Loss: 0.085879, Train Acc: 0.867949 | Val Loss: 0.114684, Val Acc: 0.773196\n",
      "Epoch 20307 - Train Loss: 0.085876, Train Acc: 0.867949 | Val Loss: 0.114683, Val Acc: 0.773196\n",
      "Epoch 20308 - Train Loss: 0.085874, Train Acc: 0.867949 | Val Loss: 0.114682, Val Acc: 0.773196\n",
      "Epoch 20309 - Train Loss: 0.085872, Train Acc: 0.867949 | Val Loss: 0.114681, Val Acc: 0.773196\n",
      "Epoch 20310 - Train Loss: 0.085870, Train Acc: 0.867949 | Val Loss: 0.114680, Val Acc: 0.773196\n",
      "Epoch 20311 - Train Loss: 0.085868, Train Acc: 0.867949 | Val Loss: 0.114679, Val Acc: 0.773196\n",
      "Epoch 20312 - Train Loss: 0.085865, Train Acc: 0.867949 | Val Loss: 0.114678, Val Acc: 0.773196\n",
      "Epoch 20313 - Train Loss: 0.085863, Train Acc: 0.867949 | Val Loss: 0.114677, Val Acc: 0.773196\n",
      "Epoch 20314 - Train Loss: 0.085861, Train Acc: 0.867949 | Val Loss: 0.114676, Val Acc: 0.773196\n",
      "Epoch 20315 - Train Loss: 0.085859, Train Acc: 0.867949 | Val Loss: 0.114675, Val Acc: 0.773196\n",
      "Epoch 20316 - Train Loss: 0.085857, Train Acc: 0.867949 | Val Loss: 0.114674, Val Acc: 0.773196\n",
      "Epoch 20317 - Train Loss: 0.085855, Train Acc: 0.867949 | Val Loss: 0.114673, Val Acc: 0.773196\n",
      "Epoch 20318 - Train Loss: 0.085852, Train Acc: 0.867949 | Val Loss: 0.114672, Val Acc: 0.773196\n",
      "Epoch 20319 - Train Loss: 0.085850, Train Acc: 0.867949 | Val Loss: 0.114671, Val Acc: 0.773196\n",
      "Epoch 20320 - Train Loss: 0.085848, Train Acc: 0.867949 | Val Loss: 0.114670, Val Acc: 0.773196\n",
      "Epoch 20321 - Train Loss: 0.085846, Train Acc: 0.867949 | Val Loss: 0.114669, Val Acc: 0.773196\n",
      "Epoch 20322 - Train Loss: 0.085844, Train Acc: 0.867949 | Val Loss: 0.114668, Val Acc: 0.773196\n",
      "Epoch 20323 - Train Loss: 0.085841, Train Acc: 0.867949 | Val Loss: 0.114667, Val Acc: 0.773196\n",
      "Epoch 20324 - Train Loss: 0.085839, Train Acc: 0.867949 | Val Loss: 0.114666, Val Acc: 0.773196\n",
      "Epoch 20325 - Train Loss: 0.085837, Train Acc: 0.867949 | Val Loss: 0.114665, Val Acc: 0.773196\n",
      "Epoch 20326 - Train Loss: 0.085835, Train Acc: 0.867949 | Val Loss: 0.114664, Val Acc: 0.773196\n",
      "Epoch 20327 - Train Loss: 0.085833, Train Acc: 0.867949 | Val Loss: 0.114663, Val Acc: 0.773196\n",
      "Epoch 20328 - Train Loss: 0.085831, Train Acc: 0.867949 | Val Loss: 0.114662, Val Acc: 0.773196\n",
      "Epoch 20329 - Train Loss: 0.085828, Train Acc: 0.867949 | Val Loss: 0.114661, Val Acc: 0.773196\n",
      "Epoch 20330 - Train Loss: 0.085826, Train Acc: 0.867949 | Val Loss: 0.114660, Val Acc: 0.773196\n",
      "Epoch 20331 - Train Loss: 0.085824, Train Acc: 0.867949 | Val Loss: 0.114659, Val Acc: 0.773196\n",
      "Epoch 20332 - Train Loss: 0.085822, Train Acc: 0.867949 | Val Loss: 0.114658, Val Acc: 0.773196\n",
      "Epoch 20333 - Train Loss: 0.085820, Train Acc: 0.867949 | Val Loss: 0.114657, Val Acc: 0.773196\n",
      "Epoch 20334 - Train Loss: 0.085817, Train Acc: 0.867949 | Val Loss: 0.114656, Val Acc: 0.773196\n",
      "Epoch 20335 - Train Loss: 0.085815, Train Acc: 0.867949 | Val Loss: 0.114655, Val Acc: 0.773196\n",
      "Epoch 20336 - Train Loss: 0.085813, Train Acc: 0.867949 | Val Loss: 0.114654, Val Acc: 0.773196\n",
      "Epoch 20337 - Train Loss: 0.085811, Train Acc: 0.867949 | Val Loss: 0.114653, Val Acc: 0.773196\n",
      "Epoch 20338 - Train Loss: 0.085809, Train Acc: 0.867949 | Val Loss: 0.114652, Val Acc: 0.773196\n",
      "Epoch 20339 - Train Loss: 0.085807, Train Acc: 0.867949 | Val Loss: 0.114651, Val Acc: 0.773196\n",
      "Epoch 20340 - Train Loss: 0.085804, Train Acc: 0.867949 | Val Loss: 0.114650, Val Acc: 0.773196\n",
      "Epoch 20341 - Train Loss: 0.085802, Train Acc: 0.867949 | Val Loss: 0.114649, Val Acc: 0.773196\n",
      "Epoch 20342 - Train Loss: 0.085800, Train Acc: 0.867949 | Val Loss: 0.114648, Val Acc: 0.773196\n",
      "Epoch 20343 - Train Loss: 0.085798, Train Acc: 0.867949 | Val Loss: 0.114647, Val Acc: 0.773196\n",
      "Epoch 20344 - Train Loss: 0.085796, Train Acc: 0.867949 | Val Loss: 0.114646, Val Acc: 0.773196\n",
      "Epoch 20345 - Train Loss: 0.085793, Train Acc: 0.867949 | Val Loss: 0.114645, Val Acc: 0.773196\n",
      "Epoch 20346 - Train Loss: 0.085791, Train Acc: 0.867949 | Val Loss: 0.114644, Val Acc: 0.773196\n",
      "Epoch 20347 - Train Loss: 0.085789, Train Acc: 0.867949 | Val Loss: 0.114643, Val Acc: 0.773196\n",
      "Epoch 20348 - Train Loss: 0.085787, Train Acc: 0.867949 | Val Loss: 0.114642, Val Acc: 0.773196\n",
      "Epoch 20349 - Train Loss: 0.085785, Train Acc: 0.867949 | Val Loss: 0.114641, Val Acc: 0.773196\n",
      "Epoch 20350 - Train Loss: 0.085783, Train Acc: 0.867949 | Val Loss: 0.114640, Val Acc: 0.773196\n",
      "Epoch 20351 - Train Loss: 0.085780, Train Acc: 0.867949 | Val Loss: 0.114639, Val Acc: 0.773196\n",
      "Epoch 20352 - Train Loss: 0.085778, Train Acc: 0.867949 | Val Loss: 0.114638, Val Acc: 0.773196\n",
      "Epoch 20353 - Train Loss: 0.085776, Train Acc: 0.867949 | Val Loss: 0.114637, Val Acc: 0.773196\n",
      "Epoch 20354 - Train Loss: 0.085774, Train Acc: 0.867949 | Val Loss: 0.114636, Val Acc: 0.773196\n",
      "Epoch 20355 - Train Loss: 0.085772, Train Acc: 0.867949 | Val Loss: 0.114635, Val Acc: 0.773196\n",
      "Epoch 20356 - Train Loss: 0.085770, Train Acc: 0.867949 | Val Loss: 0.114634, Val Acc: 0.773196\n",
      "Epoch 20357 - Train Loss: 0.085767, Train Acc: 0.867949 | Val Loss: 0.114633, Val Acc: 0.773196\n",
      "Epoch 20358 - Train Loss: 0.085765, Train Acc: 0.867949 | Val Loss: 0.114632, Val Acc: 0.773196\n",
      "Epoch 20359 - Train Loss: 0.085763, Train Acc: 0.867949 | Val Loss: 0.114631, Val Acc: 0.773196\n",
      "Epoch 20360 - Train Loss: 0.085761, Train Acc: 0.867949 | Val Loss: 0.114630, Val Acc: 0.773196\n",
      "Epoch 20361 - Train Loss: 0.085759, Train Acc: 0.867949 | Val Loss: 0.114629, Val Acc: 0.773196\n",
      "Epoch 20362 - Train Loss: 0.085756, Train Acc: 0.867949 | Val Loss: 0.114628, Val Acc: 0.773196\n",
      "Epoch 20363 - Train Loss: 0.085754, Train Acc: 0.867949 | Val Loss: 0.114627, Val Acc: 0.773196\n",
      "Epoch 20364 - Train Loss: 0.085752, Train Acc: 0.867949 | Val Loss: 0.114626, Val Acc: 0.773196\n",
      "Epoch 20365 - Train Loss: 0.085750, Train Acc: 0.867949 | Val Loss: 0.114625, Val Acc: 0.773196\n",
      "Epoch 20366 - Train Loss: 0.085748, Train Acc: 0.867949 | Val Loss: 0.114624, Val Acc: 0.773196\n",
      "Epoch 20367 - Train Loss: 0.085746, Train Acc: 0.867949 | Val Loss: 0.114623, Val Acc: 0.773196\n",
      "Epoch 20368 - Train Loss: 0.085743, Train Acc: 0.867949 | Val Loss: 0.114622, Val Acc: 0.773196\n",
      "Epoch 20369 - Train Loss: 0.085741, Train Acc: 0.867949 | Val Loss: 0.114621, Val Acc: 0.773196\n",
      "Epoch 20370 - Train Loss: 0.085739, Train Acc: 0.867949 | Val Loss: 0.114620, Val Acc: 0.773196\n",
      "Epoch 20371 - Train Loss: 0.085737, Train Acc: 0.867949 | Val Loss: 0.114619, Val Acc: 0.773196\n",
      "Epoch 20372 - Train Loss: 0.085735, Train Acc: 0.867949 | Val Loss: 0.114618, Val Acc: 0.773196\n",
      "Epoch 20373 - Train Loss: 0.085733, Train Acc: 0.867949 | Val Loss: 0.114617, Val Acc: 0.773196\n",
      "Epoch 20374 - Train Loss: 0.085730, Train Acc: 0.867949 | Val Loss: 0.114616, Val Acc: 0.773196\n",
      "Epoch 20375 - Train Loss: 0.085728, Train Acc: 0.867949 | Val Loss: 0.114615, Val Acc: 0.773196\n",
      "Epoch 20376 - Train Loss: 0.085726, Train Acc: 0.867949 | Val Loss: 0.114614, Val Acc: 0.773196\n",
      "Epoch 20377 - Train Loss: 0.085724, Train Acc: 0.867949 | Val Loss: 0.114613, Val Acc: 0.773196\n",
      "Epoch 20378 - Train Loss: 0.085722, Train Acc: 0.867949 | Val Loss: 0.114612, Val Acc: 0.773196\n",
      "Epoch 20379 - Train Loss: 0.085720, Train Acc: 0.867949 | Val Loss: 0.114611, Val Acc: 0.773196\n",
      "Epoch 20380 - Train Loss: 0.085717, Train Acc: 0.867949 | Val Loss: 0.114610, Val Acc: 0.773196\n",
      "Epoch 20381 - Train Loss: 0.085715, Train Acc: 0.867949 | Val Loss: 0.114609, Val Acc: 0.773196\n",
      "Epoch 20382 - Train Loss: 0.085713, Train Acc: 0.867949 | Val Loss: 0.114608, Val Acc: 0.773196\n",
      "Epoch 20383 - Train Loss: 0.085711, Train Acc: 0.867949 | Val Loss: 0.114607, Val Acc: 0.773196\n",
      "Epoch 20384 - Train Loss: 0.085709, Train Acc: 0.867949 | Val Loss: 0.114606, Val Acc: 0.773196\n",
      "Epoch 20385 - Train Loss: 0.085707, Train Acc: 0.867949 | Val Loss: 0.114605, Val Acc: 0.773196\n",
      "Epoch 20386 - Train Loss: 0.085704, Train Acc: 0.867949 | Val Loss: 0.114604, Val Acc: 0.773196\n",
      "Epoch 20387 - Train Loss: 0.085702, Train Acc: 0.867949 | Val Loss: 0.114603, Val Acc: 0.773196\n",
      "Epoch 20388 - Train Loss: 0.085700, Train Acc: 0.867949 | Val Loss: 0.114602, Val Acc: 0.773196\n",
      "Epoch 20389 - Train Loss: 0.085698, Train Acc: 0.867949 | Val Loss: 0.114601, Val Acc: 0.773196\n",
      "Epoch 20390 - Train Loss: 0.085696, Train Acc: 0.867949 | Val Loss: 0.114600, Val Acc: 0.773196\n",
      "Epoch 20391 - Train Loss: 0.085694, Train Acc: 0.867949 | Val Loss: 0.114599, Val Acc: 0.773196\n",
      "Epoch 20392 - Train Loss: 0.085691, Train Acc: 0.867949 | Val Loss: 0.114598, Val Acc: 0.773196\n",
      "Epoch 20393 - Train Loss: 0.085689, Train Acc: 0.867949 | Val Loss: 0.114597, Val Acc: 0.773196\n",
      "Epoch 20394 - Train Loss: 0.085687, Train Acc: 0.867949 | Val Loss: 0.114596, Val Acc: 0.773196\n",
      "Epoch 20395 - Train Loss: 0.085685, Train Acc: 0.867949 | Val Loss: 0.114595, Val Acc: 0.773196\n",
      "Epoch 20396 - Train Loss: 0.085683, Train Acc: 0.867949 | Val Loss: 0.114594, Val Acc: 0.773196\n",
      "Epoch 20397 - Train Loss: 0.085680, Train Acc: 0.867949 | Val Loss: 0.114593, Val Acc: 0.773196\n",
      "Epoch 20398 - Train Loss: 0.085678, Train Acc: 0.867949 | Val Loss: 0.114592, Val Acc: 0.773196\n",
      "Epoch 20399 - Train Loss: 0.085676, Train Acc: 0.867949 | Val Loss: 0.114591, Val Acc: 0.773196\n",
      "Epoch 20400 - Train Loss: 0.085674, Train Acc: 0.867949 | Val Loss: 0.114590, Val Acc: 0.773196\n",
      "Epoch 20401 - Train Loss: 0.085672, Train Acc: 0.867949 | Val Loss: 0.114589, Val Acc: 0.773196\n",
      "Epoch 20402 - Train Loss: 0.085670, Train Acc: 0.867949 | Val Loss: 0.114588, Val Acc: 0.773196\n",
      "Epoch 20403 - Train Loss: 0.085667, Train Acc: 0.867949 | Val Loss: 0.114587, Val Acc: 0.773196\n",
      "Epoch 20404 - Train Loss: 0.085665, Train Acc: 0.867949 | Val Loss: 0.114586, Val Acc: 0.773196\n",
      "Epoch 20405 - Train Loss: 0.085663, Train Acc: 0.867949 | Val Loss: 0.114585, Val Acc: 0.773196\n",
      "Epoch 20406 - Train Loss: 0.085661, Train Acc: 0.867949 | Val Loss: 0.114584, Val Acc: 0.773196\n",
      "Epoch 20407 - Train Loss: 0.085659, Train Acc: 0.867949 | Val Loss: 0.114583, Val Acc: 0.773196\n",
      "Epoch 20408 - Train Loss: 0.085657, Train Acc: 0.867949 | Val Loss: 0.114582, Val Acc: 0.773196\n",
      "Epoch 20409 - Train Loss: 0.085654, Train Acc: 0.867949 | Val Loss: 0.114581, Val Acc: 0.773196\n",
      "Epoch 20410 - Train Loss: 0.085652, Train Acc: 0.867949 | Val Loss: 0.114580, Val Acc: 0.773196\n",
      "Epoch 20411 - Train Loss: 0.085650, Train Acc: 0.867949 | Val Loss: 0.114579, Val Acc: 0.773196\n",
      "Epoch 20412 - Train Loss: 0.085648, Train Acc: 0.867949 | Val Loss: 0.114578, Val Acc: 0.773196\n",
      "Epoch 20413 - Train Loss: 0.085646, Train Acc: 0.867949 | Val Loss: 0.114577, Val Acc: 0.773196\n",
      "Epoch 20414 - Train Loss: 0.085644, Train Acc: 0.867949 | Val Loss: 0.114576, Val Acc: 0.773196\n",
      "Epoch 20415 - Train Loss: 0.085641, Train Acc: 0.867949 | Val Loss: 0.114575, Val Acc: 0.773196\n",
      "Epoch 20416 - Train Loss: 0.085639, Train Acc: 0.867949 | Val Loss: 0.114574, Val Acc: 0.773196\n",
      "Epoch 20417 - Train Loss: 0.085637, Train Acc: 0.867949 | Val Loss: 0.114573, Val Acc: 0.773196\n",
      "Epoch 20418 - Train Loss: 0.085635, Train Acc: 0.867949 | Val Loss: 0.114572, Val Acc: 0.773196\n",
      "Epoch 20419 - Train Loss: 0.085633, Train Acc: 0.867949 | Val Loss: 0.114571, Val Acc: 0.773196\n",
      "Epoch 20420 - Train Loss: 0.085631, Train Acc: 0.867949 | Val Loss: 0.114570, Val Acc: 0.773196\n",
      "Epoch 20421 - Train Loss: 0.085629, Train Acc: 0.867949 | Val Loss: 0.114569, Val Acc: 0.773196\n",
      "Epoch 20422 - Train Loss: 0.085626, Train Acc: 0.867949 | Val Loss: 0.114568, Val Acc: 0.773196\n",
      "Epoch 20423 - Train Loss: 0.085624, Train Acc: 0.867949 | Val Loss: 0.114567, Val Acc: 0.773196\n",
      "Epoch 20424 - Train Loss: 0.085622, Train Acc: 0.867949 | Val Loss: 0.114566, Val Acc: 0.773196\n",
      "Epoch 20425 - Train Loss: 0.085620, Train Acc: 0.867949 | Val Loss: 0.114565, Val Acc: 0.773196\n",
      "Epoch 20426 - Train Loss: 0.085618, Train Acc: 0.867949 | Val Loss: 0.114564, Val Acc: 0.773196\n",
      "Epoch 20427 - Train Loss: 0.085616, Train Acc: 0.867949 | Val Loss: 0.114563, Val Acc: 0.773196\n",
      "Epoch 20428 - Train Loss: 0.085613, Train Acc: 0.867949 | Val Loss: 0.114562, Val Acc: 0.773196\n",
      "Epoch 20429 - Train Loss: 0.085611, Train Acc: 0.867949 | Val Loss: 0.114561, Val Acc: 0.773196\n",
      "Epoch 20430 - Train Loss: 0.085609, Train Acc: 0.867949 | Val Loss: 0.114560, Val Acc: 0.773196\n",
      "Epoch 20431 - Train Loss: 0.085607, Train Acc: 0.867949 | Val Loss: 0.114559, Val Acc: 0.773196\n",
      "Epoch 20432 - Train Loss: 0.085605, Train Acc: 0.867949 | Val Loss: 0.114558, Val Acc: 0.773196\n",
      "Epoch 20433 - Train Loss: 0.085603, Train Acc: 0.867949 | Val Loss: 0.114557, Val Acc: 0.773196\n",
      "Epoch 20434 - Train Loss: 0.085600, Train Acc: 0.867949 | Val Loss: 0.114556, Val Acc: 0.773196\n",
      "Epoch 20435 - Train Loss: 0.085598, Train Acc: 0.867949 | Val Loss: 0.114555, Val Acc: 0.773196\n",
      "Epoch 20436 - Train Loss: 0.085596, Train Acc: 0.867949 | Val Loss: 0.114554, Val Acc: 0.773196\n",
      "Epoch 20437 - Train Loss: 0.085594, Train Acc: 0.867949 | Val Loss: 0.114553, Val Acc: 0.773196\n",
      "Epoch 20438 - Train Loss: 0.085592, Train Acc: 0.867949 | Val Loss: 0.114552, Val Acc: 0.773196\n",
      "Epoch 20439 - Train Loss: 0.085590, Train Acc: 0.867949 | Val Loss: 0.114551, Val Acc: 0.773196\n",
      "Epoch 20440 - Train Loss: 0.085587, Train Acc: 0.867949 | Val Loss: 0.114550, Val Acc: 0.773196\n",
      "Epoch 20441 - Train Loss: 0.085585, Train Acc: 0.867949 | Val Loss: 0.114549, Val Acc: 0.773196\n",
      "Epoch 20442 - Train Loss: 0.085583, Train Acc: 0.867949 | Val Loss: 0.114548, Val Acc: 0.773196\n",
      "Epoch 20443 - Train Loss: 0.085581, Train Acc: 0.867949 | Val Loss: 0.114547, Val Acc: 0.773196\n",
      "Epoch 20444 - Train Loss: 0.085579, Train Acc: 0.867949 | Val Loss: 0.114546, Val Acc: 0.773196\n",
      "Epoch 20445 - Train Loss: 0.085577, Train Acc: 0.867949 | Val Loss: 0.114545, Val Acc: 0.773196\n",
      "Epoch 20446 - Train Loss: 0.085574, Train Acc: 0.867949 | Val Loss: 0.114544, Val Acc: 0.773196\n",
      "Epoch 20447 - Train Loss: 0.085572, Train Acc: 0.867949 | Val Loss: 0.114543, Val Acc: 0.773196\n",
      "Epoch 20448 - Train Loss: 0.085570, Train Acc: 0.867949 | Val Loss: 0.114542, Val Acc: 0.773196\n",
      "Epoch 20449 - Train Loss: 0.085568, Train Acc: 0.867949 | Val Loss: 0.114541, Val Acc: 0.773196\n",
      "Epoch 20450 - Train Loss: 0.085566, Train Acc: 0.867949 | Val Loss: 0.114540, Val Acc: 0.773196\n",
      "Epoch 20451 - Train Loss: 0.085564, Train Acc: 0.867949 | Val Loss: 0.114539, Val Acc: 0.773196\n",
      "Epoch 20452 - Train Loss: 0.085561, Train Acc: 0.867949 | Val Loss: 0.114538, Val Acc: 0.773196\n",
      "Epoch 20453 - Train Loss: 0.085559, Train Acc: 0.867949 | Val Loss: 0.114537, Val Acc: 0.773196\n",
      "Epoch 20454 - Train Loss: 0.085557, Train Acc: 0.867949 | Val Loss: 0.114536, Val Acc: 0.773196\n",
      "Epoch 20455 - Train Loss: 0.085555, Train Acc: 0.867949 | Val Loss: 0.114535, Val Acc: 0.773196\n",
      "Epoch 20456 - Train Loss: 0.085553, Train Acc: 0.867949 | Val Loss: 0.114534, Val Acc: 0.773196\n",
      "Epoch 20457 - Train Loss: 0.085551, Train Acc: 0.867949 | Val Loss: 0.114533, Val Acc: 0.773196\n",
      "Epoch 20458 - Train Loss: 0.085549, Train Acc: 0.867949 | Val Loss: 0.114532, Val Acc: 0.773196\n",
      "Epoch 20459 - Train Loss: 0.085546, Train Acc: 0.867949 | Val Loss: 0.114531, Val Acc: 0.773196\n",
      "Epoch 20460 - Train Loss: 0.085544, Train Acc: 0.867949 | Val Loss: 0.114530, Val Acc: 0.773196\n",
      "Epoch 20461 - Train Loss: 0.085542, Train Acc: 0.867949 | Val Loss: 0.114529, Val Acc: 0.773196\n",
      "Epoch 20462 - Train Loss: 0.085540, Train Acc: 0.867949 | Val Loss: 0.114528, Val Acc: 0.773196\n",
      "Epoch 20463 - Train Loss: 0.085538, Train Acc: 0.867949 | Val Loss: 0.114527, Val Acc: 0.773196\n",
      "Epoch 20464 - Train Loss: 0.085536, Train Acc: 0.867949 | Val Loss: 0.114526, Val Acc: 0.773196\n",
      "Epoch 20465 - Train Loss: 0.085533, Train Acc: 0.867949 | Val Loss: 0.114525, Val Acc: 0.773196\n",
      "Epoch 20466 - Train Loss: 0.085531, Train Acc: 0.867949 | Val Loss: 0.114524, Val Acc: 0.773196\n",
      "Epoch 20467 - Train Loss: 0.085529, Train Acc: 0.867949 | Val Loss: 0.114523, Val Acc: 0.773196\n",
      "Epoch 20468 - Train Loss: 0.085527, Train Acc: 0.867949 | Val Loss: 0.114522, Val Acc: 0.773196\n",
      "Epoch 20469 - Train Loss: 0.085525, Train Acc: 0.867949 | Val Loss: 0.114521, Val Acc: 0.773196\n",
      "Epoch 20470 - Train Loss: 0.085523, Train Acc: 0.867949 | Val Loss: 0.114520, Val Acc: 0.773196\n",
      "Epoch 20471 - Train Loss: 0.085521, Train Acc: 0.867949 | Val Loss: 0.114519, Val Acc: 0.773196\n",
      "Epoch 20472 - Train Loss: 0.085518, Train Acc: 0.867949 | Val Loss: 0.114518, Val Acc: 0.773196\n",
      "Epoch 20473 - Train Loss: 0.085516, Train Acc: 0.867949 | Val Loss: 0.114517, Val Acc: 0.773196\n",
      "Epoch 20474 - Train Loss: 0.085514, Train Acc: 0.867949 | Val Loss: 0.114517, Val Acc: 0.773196\n",
      "Epoch 20475 - Train Loss: 0.085512, Train Acc: 0.867949 | Val Loss: 0.114516, Val Acc: 0.773196\n",
      "Epoch 20476 - Train Loss: 0.085510, Train Acc: 0.867949 | Val Loss: 0.114515, Val Acc: 0.773196\n",
      "Epoch 20477 - Train Loss: 0.085508, Train Acc: 0.867949 | Val Loss: 0.114514, Val Acc: 0.773196\n",
      "Epoch 20478 - Train Loss: 0.085505, Train Acc: 0.867949 | Val Loss: 0.114513, Val Acc: 0.773196\n",
      "Epoch 20479 - Train Loss: 0.085503, Train Acc: 0.867949 | Val Loss: 0.114512, Val Acc: 0.773196\n",
      "Epoch 20480 - Train Loss: 0.085501, Train Acc: 0.867949 | Val Loss: 0.114511, Val Acc: 0.773196\n",
      "Epoch 20481 - Train Loss: 0.085499, Train Acc: 0.867949 | Val Loss: 0.114510, Val Acc: 0.773196\n",
      "Epoch 20482 - Train Loss: 0.085497, Train Acc: 0.867949 | Val Loss: 0.114509, Val Acc: 0.773196\n",
      "Epoch 20483 - Train Loss: 0.085495, Train Acc: 0.867949 | Val Loss: 0.114508, Val Acc: 0.773196\n",
      "Epoch 20484 - Train Loss: 0.085492, Train Acc: 0.867949 | Val Loss: 0.114507, Val Acc: 0.773196\n",
      "Epoch 20485 - Train Loss: 0.085490, Train Acc: 0.867949 | Val Loss: 0.114506, Val Acc: 0.773196\n",
      "Epoch 20486 - Train Loss: 0.085488, Train Acc: 0.867949 | Val Loss: 0.114505, Val Acc: 0.773196\n",
      "Epoch 20487 - Train Loss: 0.085486, Train Acc: 0.867949 | Val Loss: 0.114504, Val Acc: 0.773196\n",
      "Epoch 20488 - Train Loss: 0.085484, Train Acc: 0.867949 | Val Loss: 0.114503, Val Acc: 0.773196\n",
      "Epoch 20489 - Train Loss: 0.085482, Train Acc: 0.867949 | Val Loss: 0.114502, Val Acc: 0.773196\n",
      "Epoch 20490 - Train Loss: 0.085480, Train Acc: 0.867949 | Val Loss: 0.114501, Val Acc: 0.773196\n",
      "Epoch 20491 - Train Loss: 0.085477, Train Acc: 0.867949 | Val Loss: 0.114500, Val Acc: 0.773196\n",
      "Epoch 20492 - Train Loss: 0.085475, Train Acc: 0.867949 | Val Loss: 0.114499, Val Acc: 0.773196\n",
      "Epoch 20493 - Train Loss: 0.085473, Train Acc: 0.867949 | Val Loss: 0.114498, Val Acc: 0.773196\n",
      "Epoch 20494 - Train Loss: 0.085471, Train Acc: 0.867949 | Val Loss: 0.114497, Val Acc: 0.773196\n",
      "Epoch 20495 - Train Loss: 0.085469, Train Acc: 0.867949 | Val Loss: 0.114496, Val Acc: 0.773196\n",
      "Epoch 20496 - Train Loss: 0.085467, Train Acc: 0.867949 | Val Loss: 0.114495, Val Acc: 0.773196\n",
      "Epoch 20497 - Train Loss: 0.085465, Train Acc: 0.867949 | Val Loss: 0.114494, Val Acc: 0.773196\n",
      "Epoch 20498 - Train Loss: 0.085462, Train Acc: 0.867949 | Val Loss: 0.114493, Val Acc: 0.773196\n",
      "Epoch 20499 - Train Loss: 0.085460, Train Acc: 0.867949 | Val Loss: 0.114492, Val Acc: 0.773196\n",
      "Epoch 20500 - Train Loss: 0.085458, Train Acc: 0.867949 | Val Loss: 0.114491, Val Acc: 0.773196\n",
      "Epoch 20501 - Train Loss: 0.085456, Train Acc: 0.867949 | Val Loss: 0.114490, Val Acc: 0.773196\n",
      "Epoch 20502 - Train Loss: 0.085454, Train Acc: 0.867949 | Val Loss: 0.114489, Val Acc: 0.773196\n",
      "Epoch 20503 - Train Loss: 0.085452, Train Acc: 0.867949 | Val Loss: 0.114488, Val Acc: 0.773196\n",
      "Epoch 20504 - Train Loss: 0.085449, Train Acc: 0.867949 | Val Loss: 0.114487, Val Acc: 0.773196\n",
      "Epoch 20505 - Train Loss: 0.085447, Train Acc: 0.867949 | Val Loss: 0.114486, Val Acc: 0.773196\n",
      "Epoch 20506 - Train Loss: 0.085445, Train Acc: 0.867949 | Val Loss: 0.114485, Val Acc: 0.773196\n",
      "Epoch 20507 - Train Loss: 0.085443, Train Acc: 0.867949 | Val Loss: 0.114484, Val Acc: 0.773196\n",
      "Epoch 20508 - Train Loss: 0.085441, Train Acc: 0.867949 | Val Loss: 0.114483, Val Acc: 0.773196\n",
      "Epoch 20509 - Train Loss: 0.085439, Train Acc: 0.867949 | Val Loss: 0.114482, Val Acc: 0.773196\n",
      "Epoch 20510 - Train Loss: 0.085437, Train Acc: 0.867949 | Val Loss: 0.114481, Val Acc: 0.773196\n",
      "Epoch 20511 - Train Loss: 0.085434, Train Acc: 0.867949 | Val Loss: 0.114480, Val Acc: 0.773196\n",
      "Epoch 20512 - Train Loss: 0.085432, Train Acc: 0.867949 | Val Loss: 0.114479, Val Acc: 0.773196\n",
      "Epoch 20513 - Train Loss: 0.085430, Train Acc: 0.867949 | Val Loss: 0.114478, Val Acc: 0.773196\n",
      "Epoch 20514 - Train Loss: 0.085428, Train Acc: 0.867949 | Val Loss: 0.114477, Val Acc: 0.773196\n",
      "Epoch 20515 - Train Loss: 0.085426, Train Acc: 0.867949 | Val Loss: 0.114476, Val Acc: 0.773196\n",
      "Epoch 20516 - Train Loss: 0.085424, Train Acc: 0.867949 | Val Loss: 0.114475, Val Acc: 0.773196\n",
      "Epoch 20517 - Train Loss: 0.085422, Train Acc: 0.867949 | Val Loss: 0.114474, Val Acc: 0.773196\n",
      "Epoch 20518 - Train Loss: 0.085419, Train Acc: 0.867949 | Val Loss: 0.114473, Val Acc: 0.773196\n",
      "Epoch 20519 - Train Loss: 0.085417, Train Acc: 0.867949 | Val Loss: 0.114472, Val Acc: 0.773196\n",
      "Epoch 20520 - Train Loss: 0.085415, Train Acc: 0.867949 | Val Loss: 0.114471, Val Acc: 0.773196\n",
      "Epoch 20521 - Train Loss: 0.085413, Train Acc: 0.867949 | Val Loss: 0.114470, Val Acc: 0.773196\n",
      "Epoch 20522 - Train Loss: 0.085411, Train Acc: 0.867949 | Val Loss: 0.114469, Val Acc: 0.773196\n",
      "Epoch 20523 - Train Loss: 0.085409, Train Acc: 0.867949 | Val Loss: 0.114468, Val Acc: 0.773196\n",
      "Epoch 20524 - Train Loss: 0.085407, Train Acc: 0.867949 | Val Loss: 0.114467, Val Acc: 0.773196\n",
      "Epoch 20525 - Train Loss: 0.085404, Train Acc: 0.867949 | Val Loss: 0.114466, Val Acc: 0.773196\n",
      "Epoch 20526 - Train Loss: 0.085402, Train Acc: 0.867949 | Val Loss: 0.114466, Val Acc: 0.773196\n",
      "Epoch 20527 - Train Loss: 0.085400, Train Acc: 0.867949 | Val Loss: 0.114465, Val Acc: 0.773196\n",
      "Epoch 20528 - Train Loss: 0.085398, Train Acc: 0.867949 | Val Loss: 0.114464, Val Acc: 0.773196\n",
      "Epoch 20529 - Train Loss: 0.085396, Train Acc: 0.867949 | Val Loss: 0.114463, Val Acc: 0.773196\n",
      "Epoch 20530 - Train Loss: 0.085394, Train Acc: 0.867949 | Val Loss: 0.114462, Val Acc: 0.773196\n",
      "Epoch 20531 - Train Loss: 0.085391, Train Acc: 0.867949 | Val Loss: 0.114461, Val Acc: 0.773196\n",
      "Epoch 20532 - Train Loss: 0.085389, Train Acc: 0.867949 | Val Loss: 0.114460, Val Acc: 0.773196\n",
      "Epoch 20533 - Train Loss: 0.085387, Train Acc: 0.867949 | Val Loss: 0.114459, Val Acc: 0.773196\n",
      "Epoch 20534 - Train Loss: 0.085385, Train Acc: 0.867949 | Val Loss: 0.114458, Val Acc: 0.773196\n",
      "Epoch 20535 - Train Loss: 0.085383, Train Acc: 0.867949 | Val Loss: 0.114457, Val Acc: 0.773196\n",
      "Epoch 20536 - Train Loss: 0.085381, Train Acc: 0.867949 | Val Loss: 0.114456, Val Acc: 0.773196\n",
      "Epoch 20537 - Train Loss: 0.085379, Train Acc: 0.867949 | Val Loss: 0.114455, Val Acc: 0.773196\n",
      "Epoch 20538 - Train Loss: 0.085376, Train Acc: 0.867949 | Val Loss: 0.114454, Val Acc: 0.773196\n",
      "Epoch 20539 - Train Loss: 0.085374, Train Acc: 0.867949 | Val Loss: 0.114453, Val Acc: 0.773196\n",
      "Epoch 20540 - Train Loss: 0.085372, Train Acc: 0.867949 | Val Loss: 0.114452, Val Acc: 0.773196\n",
      "Epoch 20541 - Train Loss: 0.085370, Train Acc: 0.867949 | Val Loss: 0.114451, Val Acc: 0.773196\n",
      "Epoch 20542 - Train Loss: 0.085368, Train Acc: 0.867949 | Val Loss: 0.114450, Val Acc: 0.773196\n",
      "Epoch 20543 - Train Loss: 0.085366, Train Acc: 0.867949 | Val Loss: 0.114449, Val Acc: 0.773196\n",
      "Epoch 20544 - Train Loss: 0.085364, Train Acc: 0.867949 | Val Loss: 0.114448, Val Acc: 0.773196\n",
      "Epoch 20545 - Train Loss: 0.085361, Train Acc: 0.867949 | Val Loss: 0.114447, Val Acc: 0.773196\n",
      "Epoch 20546 - Train Loss: 0.085359, Train Acc: 0.867949 | Val Loss: 0.114446, Val Acc: 0.773196\n",
      "Epoch 20547 - Train Loss: 0.085357, Train Acc: 0.867949 | Val Loss: 0.114445, Val Acc: 0.773196\n",
      "Epoch 20548 - Train Loss: 0.085355, Train Acc: 0.867949 | Val Loss: 0.114444, Val Acc: 0.773196\n",
      "Epoch 20549 - Train Loss: 0.085353, Train Acc: 0.867949 | Val Loss: 0.114443, Val Acc: 0.773196\n",
      "Epoch 20550 - Train Loss: 0.085351, Train Acc: 0.867949 | Val Loss: 0.114442, Val Acc: 0.773196\n",
      "Epoch 20551 - Train Loss: 0.085349, Train Acc: 0.867949 | Val Loss: 0.114441, Val Acc: 0.773196\n",
      "Epoch 20552 - Train Loss: 0.085346, Train Acc: 0.867949 | Val Loss: 0.114440, Val Acc: 0.773196\n",
      "Epoch 20553 - Train Loss: 0.085344, Train Acc: 0.867949 | Val Loss: 0.114439, Val Acc: 0.773196\n",
      "Epoch 20554 - Train Loss: 0.085342, Train Acc: 0.867949 | Val Loss: 0.114438, Val Acc: 0.773196\n",
      "Epoch 20555 - Train Loss: 0.085340, Train Acc: 0.867949 | Val Loss: 0.114437, Val Acc: 0.773196\n",
      "Epoch 20556 - Train Loss: 0.085338, Train Acc: 0.867949 | Val Loss: 0.114436, Val Acc: 0.773196\n",
      "Epoch 20557 - Train Loss: 0.085336, Train Acc: 0.867949 | Val Loss: 0.114435, Val Acc: 0.773196\n",
      "Epoch 20558 - Train Loss: 0.085334, Train Acc: 0.867949 | Val Loss: 0.114434, Val Acc: 0.773196\n",
      "Epoch 20559 - Train Loss: 0.085331, Train Acc: 0.867949 | Val Loss: 0.114433, Val Acc: 0.773196\n",
      "Epoch 20560 - Train Loss: 0.085329, Train Acc: 0.867949 | Val Loss: 0.114432, Val Acc: 0.773196\n",
      "Epoch 20561 - Train Loss: 0.085327, Train Acc: 0.867949 | Val Loss: 0.114431, Val Acc: 0.773196\n",
      "Epoch 20562 - Train Loss: 0.085325, Train Acc: 0.867949 | Val Loss: 0.114430, Val Acc: 0.773196\n",
      "Epoch 20563 - Train Loss: 0.085323, Train Acc: 0.867949 | Val Loss: 0.114429, Val Acc: 0.773196\n",
      "Epoch 20564 - Train Loss: 0.085321, Train Acc: 0.867949 | Val Loss: 0.114429, Val Acc: 0.773196\n",
      "Epoch 20565 - Train Loss: 0.085319, Train Acc: 0.867949 | Val Loss: 0.114428, Val Acc: 0.773196\n",
      "Epoch 20566 - Train Loss: 0.085317, Train Acc: 0.867949 | Val Loss: 0.114427, Val Acc: 0.773196\n",
      "Epoch 20567 - Train Loss: 0.085314, Train Acc: 0.867949 | Val Loss: 0.114426, Val Acc: 0.773196\n",
      "Epoch 20568 - Train Loss: 0.085312, Train Acc: 0.867949 | Val Loss: 0.114425, Val Acc: 0.773196\n",
      "Epoch 20569 - Train Loss: 0.085310, Train Acc: 0.867949 | Val Loss: 0.114424, Val Acc: 0.773196\n",
      "Epoch 20570 - Train Loss: 0.085308, Train Acc: 0.867949 | Val Loss: 0.114423, Val Acc: 0.773196\n",
      "Epoch 20571 - Train Loss: 0.085306, Train Acc: 0.867949 | Val Loss: 0.114422, Val Acc: 0.773196\n",
      "Epoch 20572 - Train Loss: 0.085304, Train Acc: 0.867949 | Val Loss: 0.114421, Val Acc: 0.773196\n",
      "Epoch 20573 - Train Loss: 0.085302, Train Acc: 0.867949 | Val Loss: 0.114420, Val Acc: 0.773196\n",
      "Epoch 20574 - Train Loss: 0.085299, Train Acc: 0.867949 | Val Loss: 0.114419, Val Acc: 0.773196\n",
      "Epoch 20575 - Train Loss: 0.085297, Train Acc: 0.867949 | Val Loss: 0.114418, Val Acc: 0.773196\n",
      "Epoch 20576 - Train Loss: 0.085295, Train Acc: 0.867949 | Val Loss: 0.114417, Val Acc: 0.773196\n",
      "Epoch 20577 - Train Loss: 0.085293, Train Acc: 0.867949 | Val Loss: 0.114416, Val Acc: 0.773196\n",
      "Epoch 20578 - Train Loss: 0.085291, Train Acc: 0.867949 | Val Loss: 0.114415, Val Acc: 0.773196\n",
      "Epoch 20579 - Train Loss: 0.085289, Train Acc: 0.867949 | Val Loss: 0.114414, Val Acc: 0.773196\n",
      "Epoch 20580 - Train Loss: 0.085287, Train Acc: 0.867949 | Val Loss: 0.114413, Val Acc: 0.773196\n",
      "Epoch 20581 - Train Loss: 0.085284, Train Acc: 0.867949 | Val Loss: 0.114412, Val Acc: 0.773196\n",
      "Epoch 20582 - Train Loss: 0.085282, Train Acc: 0.867949 | Val Loss: 0.114411, Val Acc: 0.773196\n",
      "Epoch 20583 - Train Loss: 0.085280, Train Acc: 0.867949 | Val Loss: 0.114410, Val Acc: 0.773196\n",
      "Epoch 20584 - Train Loss: 0.085278, Train Acc: 0.867949 | Val Loss: 0.114409, Val Acc: 0.773196\n",
      "Epoch 20585 - Train Loss: 0.085276, Train Acc: 0.867949 | Val Loss: 0.114408, Val Acc: 0.773196\n",
      "Epoch 20586 - Train Loss: 0.085274, Train Acc: 0.867949 | Val Loss: 0.114407, Val Acc: 0.773196\n",
      "Epoch 20587 - Train Loss: 0.085272, Train Acc: 0.867949 | Val Loss: 0.114406, Val Acc: 0.773196\n",
      "Epoch 20588 - Train Loss: 0.085269, Train Acc: 0.867949 | Val Loss: 0.114405, Val Acc: 0.773196\n",
      "Epoch 20589 - Train Loss: 0.085267, Train Acc: 0.867949 | Val Loss: 0.114404, Val Acc: 0.773196\n",
      "Epoch 20590 - Train Loss: 0.085265, Train Acc: 0.867949 | Val Loss: 0.114403, Val Acc: 0.773196\n",
      "Epoch 20591 - Train Loss: 0.085263, Train Acc: 0.867949 | Val Loss: 0.114402, Val Acc: 0.773196\n",
      "Epoch 20592 - Train Loss: 0.085261, Train Acc: 0.867949 | Val Loss: 0.114401, Val Acc: 0.773196\n",
      "Epoch 20593 - Train Loss: 0.085259, Train Acc: 0.867949 | Val Loss: 0.114400, Val Acc: 0.773196\n",
      "Epoch 20594 - Train Loss: 0.085257, Train Acc: 0.867949 | Val Loss: 0.114399, Val Acc: 0.773196\n",
      "Epoch 20595 - Train Loss: 0.085255, Train Acc: 0.867949 | Val Loss: 0.114398, Val Acc: 0.773196\n",
      "Epoch 20596 - Train Loss: 0.085252, Train Acc: 0.867949 | Val Loss: 0.114398, Val Acc: 0.773196\n",
      "Epoch 20597 - Train Loss: 0.085250, Train Acc: 0.867949 | Val Loss: 0.114397, Val Acc: 0.773196\n",
      "Epoch 20598 - Train Loss: 0.085248, Train Acc: 0.867949 | Val Loss: 0.114396, Val Acc: 0.773196\n",
      "Epoch 20599 - Train Loss: 0.085246, Train Acc: 0.867949 | Val Loss: 0.114395, Val Acc: 0.773196\n",
      "Epoch 20600 - Train Loss: 0.085244, Train Acc: 0.867949 | Val Loss: 0.114394, Val Acc: 0.773196\n",
      "Epoch 20601 - Train Loss: 0.085242, Train Acc: 0.867949 | Val Loss: 0.114393, Val Acc: 0.773196\n",
      "Epoch 20602 - Train Loss: 0.085240, Train Acc: 0.867949 | Val Loss: 0.114392, Val Acc: 0.773196\n",
      "Epoch 20603 - Train Loss: 0.085237, Train Acc: 0.867949 | Val Loss: 0.114391, Val Acc: 0.773196\n",
      "Epoch 20604 - Train Loss: 0.085235, Train Acc: 0.867949 | Val Loss: 0.114390, Val Acc: 0.773196\n",
      "Epoch 20605 - Train Loss: 0.085233, Train Acc: 0.867949 | Val Loss: 0.114389, Val Acc: 0.773196\n",
      "Epoch 20606 - Train Loss: 0.085231, Train Acc: 0.867949 | Val Loss: 0.114388, Val Acc: 0.773196\n",
      "Epoch 20607 - Train Loss: 0.085229, Train Acc: 0.867949 | Val Loss: 0.114387, Val Acc: 0.773196\n",
      "Epoch 20608 - Train Loss: 0.085227, Train Acc: 0.867949 | Val Loss: 0.114386, Val Acc: 0.773196\n",
      "Epoch 20609 - Train Loss: 0.085225, Train Acc: 0.867949 | Val Loss: 0.114385, Val Acc: 0.773196\n",
      "Epoch 20610 - Train Loss: 0.085223, Train Acc: 0.867949 | Val Loss: 0.114384, Val Acc: 0.773196\n",
      "Epoch 20611 - Train Loss: 0.085220, Train Acc: 0.867949 | Val Loss: 0.114383, Val Acc: 0.773196\n",
      "Epoch 20612 - Train Loss: 0.085218, Train Acc: 0.867949 | Val Loss: 0.114382, Val Acc: 0.773196\n",
      "Epoch 20613 - Train Loss: 0.085216, Train Acc: 0.867949 | Val Loss: 0.114381, Val Acc: 0.773196\n",
      "Epoch 20614 - Train Loss: 0.085214, Train Acc: 0.867949 | Val Loss: 0.114380, Val Acc: 0.773196\n",
      "Epoch 20615 - Train Loss: 0.085212, Train Acc: 0.867949 | Val Loss: 0.114379, Val Acc: 0.773196\n",
      "Epoch 20616 - Train Loss: 0.085210, Train Acc: 0.867949 | Val Loss: 0.114378, Val Acc: 0.773196\n",
      "Epoch 20617 - Train Loss: 0.085208, Train Acc: 0.867949 | Val Loss: 0.114377, Val Acc: 0.773196\n",
      "Epoch 20618 - Train Loss: 0.085205, Train Acc: 0.867949 | Val Loss: 0.114376, Val Acc: 0.773196\n",
      "Epoch 20619 - Train Loss: 0.085203, Train Acc: 0.867949 | Val Loss: 0.114375, Val Acc: 0.773196\n",
      "Epoch 20620 - Train Loss: 0.085201, Train Acc: 0.867949 | Val Loss: 0.114374, Val Acc: 0.773196\n",
      "Epoch 20621 - Train Loss: 0.085199, Train Acc: 0.867949 | Val Loss: 0.114373, Val Acc: 0.773196\n",
      "Epoch 20622 - Train Loss: 0.085197, Train Acc: 0.867949 | Val Loss: 0.114372, Val Acc: 0.773196\n",
      "Epoch 20623 - Train Loss: 0.085195, Train Acc: 0.867949 | Val Loss: 0.114371, Val Acc: 0.773196\n",
      "Epoch 20624 - Train Loss: 0.085193, Train Acc: 0.867949 | Val Loss: 0.114371, Val Acc: 0.773196\n",
      "Epoch 20625 - Train Loss: 0.085191, Train Acc: 0.867949 | Val Loss: 0.114370, Val Acc: 0.773196\n",
      "Epoch 20626 - Train Loss: 0.085188, Train Acc: 0.867949 | Val Loss: 0.114369, Val Acc: 0.773196\n",
      "Epoch 20627 - Train Loss: 0.085186, Train Acc: 0.867949 | Val Loss: 0.114368, Val Acc: 0.773196\n",
      "Epoch 20628 - Train Loss: 0.085184, Train Acc: 0.867949 | Val Loss: 0.114367, Val Acc: 0.773196\n",
      "Epoch 20629 - Train Loss: 0.085182, Train Acc: 0.867949 | Val Loss: 0.114366, Val Acc: 0.773196\n",
      "Epoch 20630 - Train Loss: 0.085180, Train Acc: 0.867949 | Val Loss: 0.114365, Val Acc: 0.773196\n",
      "Epoch 20631 - Train Loss: 0.085178, Train Acc: 0.867949 | Val Loss: 0.114364, Val Acc: 0.773196\n",
      "Epoch 20632 - Train Loss: 0.085176, Train Acc: 0.867949 | Val Loss: 0.114363, Val Acc: 0.773196\n",
      "Epoch 20633 - Train Loss: 0.085174, Train Acc: 0.867949 | Val Loss: 0.114362, Val Acc: 0.773196\n",
      "Epoch 20634 - Train Loss: 0.085171, Train Acc: 0.867949 | Val Loss: 0.114361, Val Acc: 0.773196\n",
      "Epoch 20635 - Train Loss: 0.085169, Train Acc: 0.867949 | Val Loss: 0.114360, Val Acc: 0.773196\n",
      "Epoch 20636 - Train Loss: 0.085167, Train Acc: 0.867949 | Val Loss: 0.114359, Val Acc: 0.773196\n",
      "Epoch 20637 - Train Loss: 0.085165, Train Acc: 0.867949 | Val Loss: 0.114358, Val Acc: 0.773196\n",
      "Epoch 20638 - Train Loss: 0.085163, Train Acc: 0.867949 | Val Loss: 0.114357, Val Acc: 0.773196\n",
      "Epoch 20639 - Train Loss: 0.085161, Train Acc: 0.867949 | Val Loss: 0.114356, Val Acc: 0.773196\n",
      "Epoch 20640 - Train Loss: 0.085159, Train Acc: 0.867949 | Val Loss: 0.114355, Val Acc: 0.773196\n",
      "Epoch 20641 - Train Loss: 0.085157, Train Acc: 0.867949 | Val Loss: 0.114354, Val Acc: 0.773196\n",
      "Epoch 20642 - Train Loss: 0.085154, Train Acc: 0.867949 | Val Loss: 0.114353, Val Acc: 0.773196\n",
      "Epoch 20643 - Train Loss: 0.085152, Train Acc: 0.867949 | Val Loss: 0.114352, Val Acc: 0.773196\n",
      "Epoch 20644 - Train Loss: 0.085150, Train Acc: 0.867949 | Val Loss: 0.114351, Val Acc: 0.773196\n",
      "Epoch 20645 - Train Loss: 0.085148, Train Acc: 0.867949 | Val Loss: 0.114350, Val Acc: 0.773196\n",
      "Epoch 20646 - Train Loss: 0.085146, Train Acc: 0.867949 | Val Loss: 0.114349, Val Acc: 0.773196\n",
      "Epoch 20647 - Train Loss: 0.085144, Train Acc: 0.867949 | Val Loss: 0.114348, Val Acc: 0.773196\n",
      "Epoch 20648 - Train Loss: 0.085142, Train Acc: 0.867949 | Val Loss: 0.114347, Val Acc: 0.773196\n",
      "Epoch 20649 - Train Loss: 0.085140, Train Acc: 0.867949 | Val Loss: 0.114347, Val Acc: 0.773196\n",
      "Epoch 20650 - Train Loss: 0.085137, Train Acc: 0.867949 | Val Loss: 0.114346, Val Acc: 0.773196\n",
      "Epoch 20651 - Train Loss: 0.085135, Train Acc: 0.867949 | Val Loss: 0.114345, Val Acc: 0.773196\n",
      "Epoch 20652 - Train Loss: 0.085133, Train Acc: 0.867949 | Val Loss: 0.114344, Val Acc: 0.773196\n",
      "Epoch 20653 - Train Loss: 0.085131, Train Acc: 0.867949 | Val Loss: 0.114343, Val Acc: 0.773196\n",
      "Epoch 20654 - Train Loss: 0.085129, Train Acc: 0.867949 | Val Loss: 0.114342, Val Acc: 0.773196\n",
      "Epoch 20655 - Train Loss: 0.085127, Train Acc: 0.867949 | Val Loss: 0.114341, Val Acc: 0.773196\n",
      "Epoch 20656 - Train Loss: 0.085125, Train Acc: 0.867949 | Val Loss: 0.114340, Val Acc: 0.773196\n",
      "Epoch 20657 - Train Loss: 0.085123, Train Acc: 0.867949 | Val Loss: 0.114339, Val Acc: 0.773196\n",
      "Epoch 20658 - Train Loss: 0.085120, Train Acc: 0.867949 | Val Loss: 0.114338, Val Acc: 0.773196\n",
      "Epoch 20659 - Train Loss: 0.085118, Train Acc: 0.867949 | Val Loss: 0.114337, Val Acc: 0.773196\n",
      "Epoch 20660 - Train Loss: 0.085116, Train Acc: 0.867949 | Val Loss: 0.114336, Val Acc: 0.773196\n",
      "Epoch 20661 - Train Loss: 0.085114, Train Acc: 0.867949 | Val Loss: 0.114335, Val Acc: 0.773196\n",
      "Epoch 20662 - Train Loss: 0.085112, Train Acc: 0.867949 | Val Loss: 0.114334, Val Acc: 0.773196\n",
      "Epoch 20663 - Train Loss: 0.085110, Train Acc: 0.867949 | Val Loss: 0.114333, Val Acc: 0.773196\n",
      "Epoch 20664 - Train Loss: 0.085108, Train Acc: 0.867949 | Val Loss: 0.114332, Val Acc: 0.773196\n",
      "Epoch 20665 - Train Loss: 0.085106, Train Acc: 0.867949 | Val Loss: 0.114331, Val Acc: 0.773196\n",
      "Epoch 20666 - Train Loss: 0.085103, Train Acc: 0.867949 | Val Loss: 0.114330, Val Acc: 0.773196\n",
      "Epoch 20667 - Train Loss: 0.085101, Train Acc: 0.867949 | Val Loss: 0.114329, Val Acc: 0.773196\n",
      "Epoch 20668 - Train Loss: 0.085099, Train Acc: 0.867949 | Val Loss: 0.114328, Val Acc: 0.773196\n",
      "Epoch 20669 - Train Loss: 0.085097, Train Acc: 0.867949 | Val Loss: 0.114327, Val Acc: 0.773196\n",
      "Epoch 20670 - Train Loss: 0.085095, Train Acc: 0.867949 | Val Loss: 0.114326, Val Acc: 0.773196\n",
      "Epoch 20671 - Train Loss: 0.085093, Train Acc: 0.867949 | Val Loss: 0.114325, Val Acc: 0.773196\n",
      "Epoch 20672 - Train Loss: 0.085091, Train Acc: 0.867949 | Val Loss: 0.114325, Val Acc: 0.773196\n",
      "Epoch 20673 - Train Loss: 0.085089, Train Acc: 0.867949 | Val Loss: 0.114324, Val Acc: 0.773196\n",
      "Epoch 20674 - Train Loss: 0.085086, Train Acc: 0.867949 | Val Loss: 0.114323, Val Acc: 0.773196\n",
      "Epoch 20675 - Train Loss: 0.085084, Train Acc: 0.867949 | Val Loss: 0.114322, Val Acc: 0.773196\n",
      "Epoch 20676 - Train Loss: 0.085082, Train Acc: 0.867949 | Val Loss: 0.114321, Val Acc: 0.773196\n",
      "Epoch 20677 - Train Loss: 0.085080, Train Acc: 0.867949 | Val Loss: 0.114320, Val Acc: 0.773196\n",
      "Epoch 20678 - Train Loss: 0.085078, Train Acc: 0.867949 | Val Loss: 0.114319, Val Acc: 0.773196\n",
      "Epoch 20679 - Train Loss: 0.085076, Train Acc: 0.867949 | Val Loss: 0.114318, Val Acc: 0.773196\n",
      "Epoch 20680 - Train Loss: 0.085074, Train Acc: 0.867949 | Val Loss: 0.114317, Val Acc: 0.773196\n",
      "Epoch 20681 - Train Loss: 0.085072, Train Acc: 0.867949 | Val Loss: 0.114316, Val Acc: 0.773196\n",
      "Epoch 20682 - Train Loss: 0.085070, Train Acc: 0.867949 | Val Loss: 0.114315, Val Acc: 0.773196\n",
      "Epoch 20683 - Train Loss: 0.085067, Train Acc: 0.867949 | Val Loss: 0.114314, Val Acc: 0.773196\n",
      "Epoch 20684 - Train Loss: 0.085065, Train Acc: 0.867949 | Val Loss: 0.114313, Val Acc: 0.773196\n",
      "Epoch 20685 - Train Loss: 0.085063, Train Acc: 0.867949 | Val Loss: 0.114312, Val Acc: 0.773196\n",
      "Epoch 20686 - Train Loss: 0.085061, Train Acc: 0.867949 | Val Loss: 0.114311, Val Acc: 0.773196\n",
      "Epoch 20687 - Train Loss: 0.085059, Train Acc: 0.867949 | Val Loss: 0.114310, Val Acc: 0.773196\n",
      "Epoch 20688 - Train Loss: 0.085057, Train Acc: 0.867949 | Val Loss: 0.114309, Val Acc: 0.773196\n",
      "Epoch 20689 - Train Loss: 0.085055, Train Acc: 0.867949 | Val Loss: 0.114308, Val Acc: 0.773196\n",
      "Epoch 20690 - Train Loss: 0.085053, Train Acc: 0.867949 | Val Loss: 0.114307, Val Acc: 0.773196\n",
      "Epoch 20691 - Train Loss: 0.085050, Train Acc: 0.867949 | Val Loss: 0.114306, Val Acc: 0.773196\n",
      "Epoch 20692 - Train Loss: 0.085048, Train Acc: 0.867949 | Val Loss: 0.114305, Val Acc: 0.773196\n",
      "Epoch 20693 - Train Loss: 0.085046, Train Acc: 0.867949 | Val Loss: 0.114304, Val Acc: 0.773196\n",
      "Epoch 20694 - Train Loss: 0.085044, Train Acc: 0.867949 | Val Loss: 0.114304, Val Acc: 0.773196\n",
      "Epoch 20695 - Train Loss: 0.085042, Train Acc: 0.867949 | Val Loss: 0.114303, Val Acc: 0.773196\n",
      "Epoch 20696 - Train Loss: 0.085040, Train Acc: 0.867949 | Val Loss: 0.114302, Val Acc: 0.773196\n",
      "Epoch 20697 - Train Loss: 0.085038, Train Acc: 0.867949 | Val Loss: 0.114301, Val Acc: 0.773196\n",
      "Epoch 20698 - Train Loss: 0.085036, Train Acc: 0.867949 | Val Loss: 0.114300, Val Acc: 0.773196\n",
      "Epoch 20699 - Train Loss: 0.085033, Train Acc: 0.867949 | Val Loss: 0.114299, Val Acc: 0.773196\n",
      "Epoch 20700 - Train Loss: 0.085031, Train Acc: 0.867949 | Val Loss: 0.114298, Val Acc: 0.773196\n",
      "Epoch 20701 - Train Loss: 0.085029, Train Acc: 0.867949 | Val Loss: 0.114297, Val Acc: 0.773196\n",
      "Epoch 20702 - Train Loss: 0.085027, Train Acc: 0.867949 | Val Loss: 0.114296, Val Acc: 0.773196\n",
      "Epoch 20703 - Train Loss: 0.085025, Train Acc: 0.867949 | Val Loss: 0.114295, Val Acc: 0.773196\n",
      "Epoch 20704 - Train Loss: 0.085023, Train Acc: 0.867949 | Val Loss: 0.114294, Val Acc: 0.773196\n",
      "Epoch 20705 - Train Loss: 0.085021, Train Acc: 0.867949 | Val Loss: 0.114293, Val Acc: 0.773196\n",
      "Epoch 20706 - Train Loss: 0.085019, Train Acc: 0.867949 | Val Loss: 0.114292, Val Acc: 0.773196\n",
      "Epoch 20707 - Train Loss: 0.085017, Train Acc: 0.867949 | Val Loss: 0.114291, Val Acc: 0.773196\n",
      "Epoch 20708 - Train Loss: 0.085014, Train Acc: 0.867949 | Val Loss: 0.114290, Val Acc: 0.773196\n",
      "Epoch 20709 - Train Loss: 0.085012, Train Acc: 0.867949 | Val Loss: 0.114289, Val Acc: 0.773196\n",
      "Epoch 20710 - Train Loss: 0.085010, Train Acc: 0.867949 | Val Loss: 0.114288, Val Acc: 0.773196\n",
      "Epoch 20711 - Train Loss: 0.085008, Train Acc: 0.867949 | Val Loss: 0.114287, Val Acc: 0.773196\n",
      "Epoch 20712 - Train Loss: 0.085006, Train Acc: 0.867949 | Val Loss: 0.114286, Val Acc: 0.773196\n",
      "Epoch 20713 - Train Loss: 0.085004, Train Acc: 0.867949 | Val Loss: 0.114285, Val Acc: 0.773196\n",
      "Epoch 20714 - Train Loss: 0.085002, Train Acc: 0.867949 | Val Loss: 0.114285, Val Acc: 0.773196\n",
      "Epoch 20715 - Train Loss: 0.085000, Train Acc: 0.867949 | Val Loss: 0.114284, Val Acc: 0.773196\n",
      "Epoch 20716 - Train Loss: 0.084998, Train Acc: 0.867949 | Val Loss: 0.114283, Val Acc: 0.773196\n",
      "Epoch 20717 - Train Loss: 0.084995, Train Acc: 0.867949 | Val Loss: 0.114282, Val Acc: 0.773196\n",
      "Epoch 20718 - Train Loss: 0.084993, Train Acc: 0.867949 | Val Loss: 0.114281, Val Acc: 0.773196\n",
      "Epoch 20719 - Train Loss: 0.084991, Train Acc: 0.867949 | Val Loss: 0.114280, Val Acc: 0.773196\n",
      "Epoch 20720 - Train Loss: 0.084989, Train Acc: 0.867949 | Val Loss: 0.114279, Val Acc: 0.773196\n",
      "Epoch 20721 - Train Loss: 0.084987, Train Acc: 0.867949 | Val Loss: 0.114278, Val Acc: 0.773196\n",
      "Epoch 20722 - Train Loss: 0.084985, Train Acc: 0.867949 | Val Loss: 0.114277, Val Acc: 0.773196\n",
      "Epoch 20723 - Train Loss: 0.084983, Train Acc: 0.867949 | Val Loss: 0.114276, Val Acc: 0.773196\n",
      "Epoch 20724 - Train Loss: 0.084981, Train Acc: 0.867949 | Val Loss: 0.114275, Val Acc: 0.773196\n",
      "Epoch 20725 - Train Loss: 0.084979, Train Acc: 0.867949 | Val Loss: 0.114274, Val Acc: 0.773196\n",
      "Epoch 20726 - Train Loss: 0.084976, Train Acc: 0.867949 | Val Loss: 0.114273, Val Acc: 0.773196\n",
      "Epoch 20727 - Train Loss: 0.084974, Train Acc: 0.867949 | Val Loss: 0.114272, Val Acc: 0.773196\n",
      "Epoch 20728 - Train Loss: 0.084972, Train Acc: 0.867949 | Val Loss: 0.114271, Val Acc: 0.773196\n",
      "Epoch 20729 - Train Loss: 0.084970, Train Acc: 0.867949 | Val Loss: 0.114270, Val Acc: 0.773196\n",
      "Epoch 20730 - Train Loss: 0.084968, Train Acc: 0.867949 | Val Loss: 0.114269, Val Acc: 0.773196\n",
      "Epoch 20731 - Train Loss: 0.084966, Train Acc: 0.867949 | Val Loss: 0.114268, Val Acc: 0.773196\n",
      "Epoch 20732 - Train Loss: 0.084964, Train Acc: 0.867949 | Val Loss: 0.114267, Val Acc: 0.773196\n",
      "Epoch 20733 - Train Loss: 0.084962, Train Acc: 0.867949 | Val Loss: 0.114267, Val Acc: 0.773196\n",
      "Epoch 20734 - Train Loss: 0.084960, Train Acc: 0.867949 | Val Loss: 0.114266, Val Acc: 0.773196\n",
      "Epoch 20735 - Train Loss: 0.084957, Train Acc: 0.867949 | Val Loss: 0.114265, Val Acc: 0.773196\n",
      "Epoch 20736 - Train Loss: 0.084955, Train Acc: 0.867949 | Val Loss: 0.114264, Val Acc: 0.773196\n",
      "Epoch 20737 - Train Loss: 0.084953, Train Acc: 0.867949 | Val Loss: 0.114263, Val Acc: 0.773196\n",
      "Epoch 20738 - Train Loss: 0.084951, Train Acc: 0.867949 | Val Loss: 0.114262, Val Acc: 0.773196\n",
      "Epoch 20739 - Train Loss: 0.084949, Train Acc: 0.867949 | Val Loss: 0.114261, Val Acc: 0.773196\n",
      "Epoch 20740 - Train Loss: 0.084947, Train Acc: 0.867949 | Val Loss: 0.114260, Val Acc: 0.773196\n",
      "Epoch 20741 - Train Loss: 0.084945, Train Acc: 0.867949 | Val Loss: 0.114259, Val Acc: 0.773196\n",
      "Epoch 20742 - Train Loss: 0.084943, Train Acc: 0.867949 | Val Loss: 0.114258, Val Acc: 0.773196\n",
      "Epoch 20743 - Train Loss: 0.084941, Train Acc: 0.867949 | Val Loss: 0.114257, Val Acc: 0.773196\n",
      "Epoch 20744 - Train Loss: 0.084938, Train Acc: 0.867949 | Val Loss: 0.114256, Val Acc: 0.773196\n",
      "Epoch 20745 - Train Loss: 0.084936, Train Acc: 0.867949 | Val Loss: 0.114255, Val Acc: 0.773196\n",
      "Epoch 20746 - Train Loss: 0.084934, Train Acc: 0.867949 | Val Loss: 0.114254, Val Acc: 0.773196\n",
      "Epoch 20747 - Train Loss: 0.084932, Train Acc: 0.867949 | Val Loss: 0.114253, Val Acc: 0.773196\n",
      "Epoch 20748 - Train Loss: 0.084930, Train Acc: 0.867949 | Val Loss: 0.114252, Val Acc: 0.773196\n",
      "Epoch 20749 - Train Loss: 0.084928, Train Acc: 0.867949 | Val Loss: 0.114251, Val Acc: 0.773196\n",
      "Epoch 20750 - Train Loss: 0.084926, Train Acc: 0.867949 | Val Loss: 0.114250, Val Acc: 0.773196\n",
      "Epoch 20751 - Train Loss: 0.084924, Train Acc: 0.867949 | Val Loss: 0.114250, Val Acc: 0.773196\n",
      "Epoch 20752 - Train Loss: 0.084922, Train Acc: 0.867949 | Val Loss: 0.114249, Val Acc: 0.773196\n",
      "Epoch 20753 - Train Loss: 0.084919, Train Acc: 0.867949 | Val Loss: 0.114248, Val Acc: 0.773196\n",
      "Epoch 20754 - Train Loss: 0.084917, Train Acc: 0.867949 | Val Loss: 0.114247, Val Acc: 0.773196\n",
      "Epoch 20755 - Train Loss: 0.084915, Train Acc: 0.867949 | Val Loss: 0.114246, Val Acc: 0.773196\n",
      "Epoch 20756 - Train Loss: 0.084913, Train Acc: 0.867949 | Val Loss: 0.114245, Val Acc: 0.773196\n",
      "Epoch 20757 - Train Loss: 0.084911, Train Acc: 0.867949 | Val Loss: 0.114244, Val Acc: 0.773196\n",
      "Epoch 20758 - Train Loss: 0.084909, Train Acc: 0.867949 | Val Loss: 0.114243, Val Acc: 0.773196\n",
      "Epoch 20759 - Train Loss: 0.084907, Train Acc: 0.867949 | Val Loss: 0.114242, Val Acc: 0.773196\n",
      "Epoch 20760 - Train Loss: 0.084905, Train Acc: 0.867949 | Val Loss: 0.114241, Val Acc: 0.773196\n",
      "Epoch 20761 - Train Loss: 0.084903, Train Acc: 0.867949 | Val Loss: 0.114240, Val Acc: 0.773196\n",
      "Epoch 20762 - Train Loss: 0.084900, Train Acc: 0.867949 | Val Loss: 0.114239, Val Acc: 0.773196\n",
      "Epoch 20763 - Train Loss: 0.084898, Train Acc: 0.867949 | Val Loss: 0.114238, Val Acc: 0.773196\n",
      "Epoch 20764 - Train Loss: 0.084896, Train Acc: 0.867949 | Val Loss: 0.114237, Val Acc: 0.773196\n",
      "Epoch 20765 - Train Loss: 0.084894, Train Acc: 0.867949 | Val Loss: 0.114236, Val Acc: 0.773196\n",
      "Epoch 20766 - Train Loss: 0.084892, Train Acc: 0.867949 | Val Loss: 0.114235, Val Acc: 0.773196\n",
      "Epoch 20767 - Train Loss: 0.084890, Train Acc: 0.867949 | Val Loss: 0.114235, Val Acc: 0.773196\n",
      "Epoch 20768 - Train Loss: 0.084888, Train Acc: 0.867949 | Val Loss: 0.114234, Val Acc: 0.773196\n",
      "Epoch 20769 - Train Loss: 0.084886, Train Acc: 0.867949 | Val Loss: 0.114233, Val Acc: 0.773196\n",
      "Epoch 20770 - Train Loss: 0.084884, Train Acc: 0.867949 | Val Loss: 0.114232, Val Acc: 0.773196\n",
      "Epoch 20771 - Train Loss: 0.084882, Train Acc: 0.867949 | Val Loss: 0.114231, Val Acc: 0.773196\n",
      "Epoch 20772 - Train Loss: 0.084879, Train Acc: 0.867949 | Val Loss: 0.114230, Val Acc: 0.773196\n",
      "Epoch 20773 - Train Loss: 0.084877, Train Acc: 0.867949 | Val Loss: 0.114229, Val Acc: 0.773196\n",
      "Epoch 20774 - Train Loss: 0.084875, Train Acc: 0.867949 | Val Loss: 0.114228, Val Acc: 0.773196\n",
      "Epoch 20775 - Train Loss: 0.084873, Train Acc: 0.867949 | Val Loss: 0.114227, Val Acc: 0.773196\n",
      "Epoch 20776 - Train Loss: 0.084871, Train Acc: 0.867949 | Val Loss: 0.114226, Val Acc: 0.773196\n",
      "Epoch 20777 - Train Loss: 0.084869, Train Acc: 0.867949 | Val Loss: 0.114225, Val Acc: 0.773196\n",
      "Epoch 20778 - Train Loss: 0.084867, Train Acc: 0.867949 | Val Loss: 0.114224, Val Acc: 0.773196\n",
      "Epoch 20779 - Train Loss: 0.084865, Train Acc: 0.867949 | Val Loss: 0.114223, Val Acc: 0.773196\n",
      "Epoch 20780 - Train Loss: 0.084863, Train Acc: 0.867949 | Val Loss: 0.114222, Val Acc: 0.773196\n",
      "Epoch 20781 - Train Loss: 0.084860, Train Acc: 0.867949 | Val Loss: 0.114221, Val Acc: 0.773196\n",
      "Epoch 20782 - Train Loss: 0.084858, Train Acc: 0.867949 | Val Loss: 0.114220, Val Acc: 0.773196\n",
      "Epoch 20783 - Train Loss: 0.084856, Train Acc: 0.867949 | Val Loss: 0.114220, Val Acc: 0.773196\n",
      "Epoch 20784 - Train Loss: 0.084854, Train Acc: 0.867949 | Val Loss: 0.114219, Val Acc: 0.773196\n",
      "Epoch 20785 - Train Loss: 0.084852, Train Acc: 0.867949 | Val Loss: 0.114218, Val Acc: 0.773196\n",
      "Epoch 20786 - Train Loss: 0.084850, Train Acc: 0.867949 | Val Loss: 0.114217, Val Acc: 0.773196\n",
      "Epoch 20787 - Train Loss: 0.084848, Train Acc: 0.867949 | Val Loss: 0.114216, Val Acc: 0.773196\n",
      "Epoch 20788 - Train Loss: 0.084846, Train Acc: 0.867949 | Val Loss: 0.114215, Val Acc: 0.773196\n",
      "Epoch 20789 - Train Loss: 0.084844, Train Acc: 0.867949 | Val Loss: 0.114214, Val Acc: 0.773196\n",
      "Epoch 20790 - Train Loss: 0.084842, Train Acc: 0.867949 | Val Loss: 0.114213, Val Acc: 0.773196\n",
      "Epoch 20791 - Train Loss: 0.084839, Train Acc: 0.867949 | Val Loss: 0.114212, Val Acc: 0.773196\n",
      "Epoch 20792 - Train Loss: 0.084837, Train Acc: 0.867949 | Val Loss: 0.114211, Val Acc: 0.773196\n",
      "Epoch 20793 - Train Loss: 0.084835, Train Acc: 0.867949 | Val Loss: 0.114210, Val Acc: 0.773196\n",
      "Epoch 20794 - Train Loss: 0.084833, Train Acc: 0.867949 | Val Loss: 0.114209, Val Acc: 0.773196\n",
      "Epoch 20795 - Train Loss: 0.084831, Train Acc: 0.867949 | Val Loss: 0.114208, Val Acc: 0.773196\n",
      "Epoch 20796 - Train Loss: 0.084829, Train Acc: 0.867949 | Val Loss: 0.114207, Val Acc: 0.773196\n",
      "Epoch 20797 - Train Loss: 0.084827, Train Acc: 0.867949 | Val Loss: 0.114206, Val Acc: 0.773196\n",
      "Epoch 20798 - Train Loss: 0.084825, Train Acc: 0.867949 | Val Loss: 0.114205, Val Acc: 0.773196\n",
      "Epoch 20799 - Train Loss: 0.084823, Train Acc: 0.867949 | Val Loss: 0.114204, Val Acc: 0.773196\n",
      "Epoch 20800 - Train Loss: 0.084821, Train Acc: 0.867949 | Val Loss: 0.114203, Val Acc: 0.773196\n",
      "Epoch 20801 - Train Loss: 0.084818, Train Acc: 0.867949 | Val Loss: 0.114202, Val Acc: 0.773196\n",
      "Epoch 20802 - Train Loss: 0.084816, Train Acc: 0.867949 | Val Loss: 0.114202, Val Acc: 0.773196\n",
      "Epoch 20803 - Train Loss: 0.084814, Train Acc: 0.867949 | Val Loss: 0.114201, Val Acc: 0.773196\n",
      "Epoch 20804 - Train Loss: 0.084812, Train Acc: 0.867949 | Val Loss: 0.114200, Val Acc: 0.773196\n",
      "Epoch 20805 - Train Loss: 0.084810, Train Acc: 0.867949 | Val Loss: 0.114199, Val Acc: 0.773196\n",
      "Epoch 20806 - Train Loss: 0.084808, Train Acc: 0.867949 | Val Loss: 0.114198, Val Acc: 0.773196\n",
      "Epoch 20807 - Train Loss: 0.084806, Train Acc: 0.867949 | Val Loss: 0.114197, Val Acc: 0.773196\n",
      "Epoch 20808 - Train Loss: 0.084804, Train Acc: 0.867949 | Val Loss: 0.114196, Val Acc: 0.773196\n",
      "Epoch 20809 - Train Loss: 0.084802, Train Acc: 0.867949 | Val Loss: 0.114195, Val Acc: 0.773196\n",
      "Epoch 20810 - Train Loss: 0.084800, Train Acc: 0.867949 | Val Loss: 0.114194, Val Acc: 0.773196\n",
      "Epoch 20811 - Train Loss: 0.084797, Train Acc: 0.867949 | Val Loss: 0.114193, Val Acc: 0.773196\n",
      "Epoch 20812 - Train Loss: 0.084795, Train Acc: 0.867949 | Val Loss: 0.114192, Val Acc: 0.773196\n",
      "Epoch 20813 - Train Loss: 0.084793, Train Acc: 0.867949 | Val Loss: 0.114191, Val Acc: 0.773196\n",
      "Epoch 20814 - Train Loss: 0.084791, Train Acc: 0.867949 | Val Loss: 0.114190, Val Acc: 0.773196\n",
      "Epoch 20815 - Train Loss: 0.084789, Train Acc: 0.867949 | Val Loss: 0.114189, Val Acc: 0.773196\n",
      "Epoch 20816 - Train Loss: 0.084787, Train Acc: 0.867949 | Val Loss: 0.114188, Val Acc: 0.773196\n",
      "Epoch 20817 - Train Loss: 0.084785, Train Acc: 0.867949 | Val Loss: 0.114187, Val Acc: 0.773196\n",
      "Epoch 20818 - Train Loss: 0.084783, Train Acc: 0.867949 | Val Loss: 0.114186, Val Acc: 0.773196\n",
      "Epoch 20819 - Train Loss: 0.084781, Train Acc: 0.867949 | Val Loss: 0.114185, Val Acc: 0.773196\n",
      "Epoch 20820 - Train Loss: 0.084779, Train Acc: 0.867949 | Val Loss: 0.114185, Val Acc: 0.773196\n",
      "Epoch 20821 - Train Loss: 0.084777, Train Acc: 0.867949 | Val Loss: 0.114184, Val Acc: 0.773196\n",
      "Epoch 20822 - Train Loss: 0.084774, Train Acc: 0.867949 | Val Loss: 0.114183, Val Acc: 0.773196\n",
      "Epoch 20823 - Train Loss: 0.084772, Train Acc: 0.867949 | Val Loss: 0.114182, Val Acc: 0.773196\n",
      "Epoch 20824 - Train Loss: 0.084770, Train Acc: 0.867949 | Val Loss: 0.114181, Val Acc: 0.773196\n",
      "Epoch 20825 - Train Loss: 0.084768, Train Acc: 0.867949 | Val Loss: 0.114180, Val Acc: 0.773196\n",
      "Epoch 20826 - Train Loss: 0.084766, Train Acc: 0.867949 | Val Loss: 0.114179, Val Acc: 0.773196\n",
      "Epoch 20827 - Train Loss: 0.084764, Train Acc: 0.867949 | Val Loss: 0.114178, Val Acc: 0.773196\n",
      "Epoch 20828 - Train Loss: 0.084762, Train Acc: 0.867949 | Val Loss: 0.114177, Val Acc: 0.773196\n",
      "Epoch 20829 - Train Loss: 0.084760, Train Acc: 0.867949 | Val Loss: 0.114176, Val Acc: 0.773196\n",
      "Epoch 20830 - Train Loss: 0.084758, Train Acc: 0.867949 | Val Loss: 0.114175, Val Acc: 0.773196\n",
      "Epoch 20831 - Train Loss: 0.084756, Train Acc: 0.867949 | Val Loss: 0.114174, Val Acc: 0.773196\n",
      "Epoch 20832 - Train Loss: 0.084753, Train Acc: 0.867949 | Val Loss: 0.114173, Val Acc: 0.773196\n",
      "Epoch 20833 - Train Loss: 0.084751, Train Acc: 0.867949 | Val Loss: 0.114172, Val Acc: 0.773196\n",
      "Epoch 20834 - Train Loss: 0.084749, Train Acc: 0.867949 | Val Loss: 0.114171, Val Acc: 0.773196\n",
      "Epoch 20835 - Train Loss: 0.084747, Train Acc: 0.867949 | Val Loss: 0.114170, Val Acc: 0.773196\n",
      "Epoch 20836 - Train Loss: 0.084745, Train Acc: 0.867949 | Val Loss: 0.114169, Val Acc: 0.773196\n",
      "Epoch 20837 - Train Loss: 0.084743, Train Acc: 0.867949 | Val Loss: 0.114169, Val Acc: 0.773196\n",
      "Epoch 20838 - Train Loss: 0.084741, Train Acc: 0.867949 | Val Loss: 0.114168, Val Acc: 0.773196\n",
      "Epoch 20839 - Train Loss: 0.084739, Train Acc: 0.867949 | Val Loss: 0.114167, Val Acc: 0.773196\n",
      "Epoch 20840 - Train Loss: 0.084737, Train Acc: 0.867949 | Val Loss: 0.114166, Val Acc: 0.773196\n",
      "Epoch 20841 - Train Loss: 0.084735, Train Acc: 0.867949 | Val Loss: 0.114165, Val Acc: 0.773196\n",
      "Epoch 20842 - Train Loss: 0.084733, Train Acc: 0.867949 | Val Loss: 0.114164, Val Acc: 0.773196\n",
      "Epoch 20843 - Train Loss: 0.084730, Train Acc: 0.867949 | Val Loss: 0.114163, Val Acc: 0.773196\n",
      "Epoch 20844 - Train Loss: 0.084728, Train Acc: 0.867949 | Val Loss: 0.114162, Val Acc: 0.773196\n",
      "Epoch 20845 - Train Loss: 0.084726, Train Acc: 0.867949 | Val Loss: 0.114161, Val Acc: 0.773196\n",
      "Epoch 20846 - Train Loss: 0.084724, Train Acc: 0.867949 | Val Loss: 0.114160, Val Acc: 0.773196\n",
      "Epoch 20847 - Train Loss: 0.084722, Train Acc: 0.867949 | Val Loss: 0.114159, Val Acc: 0.773196\n",
      "Epoch 20848 - Train Loss: 0.084720, Train Acc: 0.867949 | Val Loss: 0.114158, Val Acc: 0.773196\n",
      "Epoch 20849 - Train Loss: 0.084718, Train Acc: 0.867949 | Val Loss: 0.114157, Val Acc: 0.773196\n",
      "Epoch 20850 - Train Loss: 0.084716, Train Acc: 0.867949 | Val Loss: 0.114156, Val Acc: 0.773196\n",
      "Epoch 20851 - Train Loss: 0.084714, Train Acc: 0.867949 | Val Loss: 0.114155, Val Acc: 0.773196\n",
      "Epoch 20852 - Train Loss: 0.084712, Train Acc: 0.867949 | Val Loss: 0.114154, Val Acc: 0.773196\n",
      "Epoch 20853 - Train Loss: 0.084710, Train Acc: 0.867949 | Val Loss: 0.114153, Val Acc: 0.773196\n",
      "Epoch 20854 - Train Loss: 0.084707, Train Acc: 0.867949 | Val Loss: 0.114153, Val Acc: 0.773196\n",
      "Epoch 20855 - Train Loss: 0.084705, Train Acc: 0.867949 | Val Loss: 0.114152, Val Acc: 0.773196\n",
      "Epoch 20856 - Train Loss: 0.084703, Train Acc: 0.867949 | Val Loss: 0.114151, Val Acc: 0.773196\n",
      "Epoch 20857 - Train Loss: 0.084701, Train Acc: 0.867949 | Val Loss: 0.114150, Val Acc: 0.773196\n",
      "Epoch 20858 - Train Loss: 0.084699, Train Acc: 0.867949 | Val Loss: 0.114149, Val Acc: 0.773196\n",
      "Epoch 20859 - Train Loss: 0.084697, Train Acc: 0.867949 | Val Loss: 0.114148, Val Acc: 0.773196\n",
      "Epoch 20860 - Train Loss: 0.084695, Train Acc: 0.867949 | Val Loss: 0.114147, Val Acc: 0.773196\n",
      "Epoch 20861 - Train Loss: 0.084693, Train Acc: 0.867949 | Val Loss: 0.114146, Val Acc: 0.773196\n",
      "Epoch 20862 - Train Loss: 0.084691, Train Acc: 0.867949 | Val Loss: 0.114145, Val Acc: 0.773196\n",
      "Epoch 20863 - Train Loss: 0.084689, Train Acc: 0.867949 | Val Loss: 0.114144, Val Acc: 0.773196\n",
      "Epoch 20864 - Train Loss: 0.084687, Train Acc: 0.867949 | Val Loss: 0.114143, Val Acc: 0.773196\n",
      "Epoch 20865 - Train Loss: 0.084684, Train Acc: 0.867949 | Val Loss: 0.114142, Val Acc: 0.773196\n",
      "Epoch 20866 - Train Loss: 0.084682, Train Acc: 0.867949 | Val Loss: 0.114141, Val Acc: 0.773196\n",
      "Epoch 20867 - Train Loss: 0.084680, Train Acc: 0.867949 | Val Loss: 0.114140, Val Acc: 0.773196\n",
      "Epoch 20868 - Train Loss: 0.084678, Train Acc: 0.867949 | Val Loss: 0.114139, Val Acc: 0.773196\n",
      "Epoch 20869 - Train Loss: 0.084676, Train Acc: 0.867949 | Val Loss: 0.114138, Val Acc: 0.773196\n",
      "Epoch 20870 - Train Loss: 0.084674, Train Acc: 0.867949 | Val Loss: 0.114138, Val Acc: 0.773196\n",
      "Epoch 20871 - Train Loss: 0.084672, Train Acc: 0.867949 | Val Loss: 0.114137, Val Acc: 0.773196\n",
      "Epoch 20872 - Train Loss: 0.084670, Train Acc: 0.867949 | Val Loss: 0.114136, Val Acc: 0.773196\n",
      "Epoch 20873 - Train Loss: 0.084668, Train Acc: 0.867949 | Val Loss: 0.114135, Val Acc: 0.773196\n",
      "Epoch 20874 - Train Loss: 0.084666, Train Acc: 0.867949 | Val Loss: 0.114134, Val Acc: 0.773196\n",
      "Epoch 20875 - Train Loss: 0.084664, Train Acc: 0.867949 | Val Loss: 0.114133, Val Acc: 0.773196\n",
      "Epoch 20876 - Train Loss: 0.084661, Train Acc: 0.867949 | Val Loss: 0.114132, Val Acc: 0.773196\n",
      "Epoch 20877 - Train Loss: 0.084659, Train Acc: 0.867949 | Val Loss: 0.114131, Val Acc: 0.773196\n",
      "Epoch 20878 - Train Loss: 0.084657, Train Acc: 0.867949 | Val Loss: 0.114130, Val Acc: 0.773196\n",
      "Epoch 20879 - Train Loss: 0.084655, Train Acc: 0.867949 | Val Loss: 0.114129, Val Acc: 0.773196\n",
      "Epoch 20880 - Train Loss: 0.084653, Train Acc: 0.867949 | Val Loss: 0.114128, Val Acc: 0.773196\n",
      "Epoch 20881 - Train Loss: 0.084651, Train Acc: 0.867949 | Val Loss: 0.114127, Val Acc: 0.773196\n",
      "Epoch 20882 - Train Loss: 0.084649, Train Acc: 0.867949 | Val Loss: 0.114126, Val Acc: 0.773196\n",
      "Epoch 20883 - Train Loss: 0.084647, Train Acc: 0.867949 | Val Loss: 0.114125, Val Acc: 0.773196\n",
      "Epoch 20884 - Train Loss: 0.084645, Train Acc: 0.867949 | Val Loss: 0.114124, Val Acc: 0.773196\n",
      "Epoch 20885 - Train Loss: 0.084643, Train Acc: 0.867949 | Val Loss: 0.114124, Val Acc: 0.773196\n",
      "Epoch 20886 - Train Loss: 0.084641, Train Acc: 0.867949 | Val Loss: 0.114123, Val Acc: 0.773196\n",
      "Epoch 20887 - Train Loss: 0.084639, Train Acc: 0.867949 | Val Loss: 0.114122, Val Acc: 0.773196\n",
      "Epoch 20888 - Train Loss: 0.084636, Train Acc: 0.867949 | Val Loss: 0.114121, Val Acc: 0.773196\n",
      "Epoch 20889 - Train Loss: 0.084634, Train Acc: 0.867949 | Val Loss: 0.114120, Val Acc: 0.773196\n",
      "Epoch 20890 - Train Loss: 0.084632, Train Acc: 0.867949 | Val Loss: 0.114119, Val Acc: 0.773196\n",
      "Epoch 20891 - Train Loss: 0.084630, Train Acc: 0.867949 | Val Loss: 0.114118, Val Acc: 0.773196\n",
      "Epoch 20892 - Train Loss: 0.084628, Train Acc: 0.867949 | Val Loss: 0.114117, Val Acc: 0.773196\n",
      "Epoch 20893 - Train Loss: 0.084626, Train Acc: 0.867949 | Val Loss: 0.114116, Val Acc: 0.773196\n",
      "Epoch 20894 - Train Loss: 0.084624, Train Acc: 0.867949 | Val Loss: 0.114115, Val Acc: 0.773196\n",
      "Epoch 20895 - Train Loss: 0.084622, Train Acc: 0.867949 | Val Loss: 0.114114, Val Acc: 0.773196\n",
      "Epoch 20896 - Train Loss: 0.084620, Train Acc: 0.867949 | Val Loss: 0.114113, Val Acc: 0.773196\n",
      "Epoch 20897 - Train Loss: 0.084618, Train Acc: 0.867949 | Val Loss: 0.114112, Val Acc: 0.773196\n",
      "Epoch 20898 - Train Loss: 0.084616, Train Acc: 0.867949 | Val Loss: 0.114111, Val Acc: 0.773196\n",
      "Epoch 20899 - Train Loss: 0.084613, Train Acc: 0.867949 | Val Loss: 0.114110, Val Acc: 0.773196\n",
      "Epoch 20900 - Train Loss: 0.084611, Train Acc: 0.867949 | Val Loss: 0.114110, Val Acc: 0.773196\n",
      "Epoch 20901 - Train Loss: 0.084609, Train Acc: 0.867949 | Val Loss: 0.114109, Val Acc: 0.773196\n",
      "Epoch 20902 - Train Loss: 0.084607, Train Acc: 0.867949 | Val Loss: 0.114108, Val Acc: 0.773196\n",
      "Epoch 20903 - Train Loss: 0.084605, Train Acc: 0.867949 | Val Loss: 0.114107, Val Acc: 0.773196\n",
      "Epoch 20904 - Train Loss: 0.084603, Train Acc: 0.867949 | Val Loss: 0.114106, Val Acc: 0.773196\n",
      "Epoch 20905 - Train Loss: 0.084601, Train Acc: 0.867949 | Val Loss: 0.114105, Val Acc: 0.773196\n",
      "Epoch 20906 - Train Loss: 0.084599, Train Acc: 0.867949 | Val Loss: 0.114104, Val Acc: 0.773196\n",
      "Epoch 20907 - Train Loss: 0.084597, Train Acc: 0.867949 | Val Loss: 0.114103, Val Acc: 0.773196\n",
      "Epoch 20908 - Train Loss: 0.084595, Train Acc: 0.867949 | Val Loss: 0.114102, Val Acc: 0.773196\n",
      "Epoch 20909 - Train Loss: 0.084593, Train Acc: 0.867949 | Val Loss: 0.114101, Val Acc: 0.773196\n",
      "Epoch 20910 - Train Loss: 0.084591, Train Acc: 0.867949 | Val Loss: 0.114100, Val Acc: 0.773196\n",
      "Epoch 20911 - Train Loss: 0.084588, Train Acc: 0.867949 | Val Loss: 0.114099, Val Acc: 0.773196\n",
      "Epoch 20912 - Train Loss: 0.084586, Train Acc: 0.867949 | Val Loss: 0.114098, Val Acc: 0.773196\n",
      "Epoch 20913 - Train Loss: 0.084584, Train Acc: 0.867949 | Val Loss: 0.114097, Val Acc: 0.773196\n",
      "Epoch 20914 - Train Loss: 0.084582, Train Acc: 0.867949 | Val Loss: 0.114096, Val Acc: 0.773196\n",
      "Epoch 20915 - Train Loss: 0.084580, Train Acc: 0.867949 | Val Loss: 0.114096, Val Acc: 0.773196\n",
      "Epoch 20916 - Train Loss: 0.084578, Train Acc: 0.867949 | Val Loss: 0.114095, Val Acc: 0.773196\n",
      "Epoch 20917 - Train Loss: 0.084576, Train Acc: 0.867949 | Val Loss: 0.114094, Val Acc: 0.773196\n",
      "Epoch 20918 - Train Loss: 0.084574, Train Acc: 0.867949 | Val Loss: 0.114093, Val Acc: 0.773196\n",
      "Epoch 20919 - Train Loss: 0.084572, Train Acc: 0.867949 | Val Loss: 0.114092, Val Acc: 0.773196\n",
      "Epoch 20920 - Train Loss: 0.084570, Train Acc: 0.867949 | Val Loss: 0.114091, Val Acc: 0.773196\n",
      "Epoch 20921 - Train Loss: 0.084568, Train Acc: 0.867949 | Val Loss: 0.114090, Val Acc: 0.773196\n",
      "Epoch 20922 - Train Loss: 0.084566, Train Acc: 0.867949 | Val Loss: 0.114089, Val Acc: 0.773196\n",
      "Epoch 20923 - Train Loss: 0.084564, Train Acc: 0.867949 | Val Loss: 0.114088, Val Acc: 0.773196\n",
      "Epoch 20924 - Train Loss: 0.084561, Train Acc: 0.867949 | Val Loss: 0.114087, Val Acc: 0.773196\n",
      "Epoch 20925 - Train Loss: 0.084559, Train Acc: 0.867949 | Val Loss: 0.114086, Val Acc: 0.773196\n",
      "Epoch 20926 - Train Loss: 0.084557, Train Acc: 0.867949 | Val Loss: 0.114085, Val Acc: 0.773196\n",
      "Epoch 20927 - Train Loss: 0.084555, Train Acc: 0.867949 | Val Loss: 0.114084, Val Acc: 0.773196\n",
      "Epoch 20928 - Train Loss: 0.084553, Train Acc: 0.867949 | Val Loss: 0.114083, Val Acc: 0.773196\n",
      "Epoch 20929 - Train Loss: 0.084551, Train Acc: 0.867949 | Val Loss: 0.114083, Val Acc: 0.773196\n",
      "Epoch 20930 - Train Loss: 0.084549, Train Acc: 0.867949 | Val Loss: 0.114082, Val Acc: 0.773196\n",
      "Epoch 20931 - Train Loss: 0.084547, Train Acc: 0.867949 | Val Loss: 0.114081, Val Acc: 0.773196\n",
      "Epoch 20932 - Train Loss: 0.084545, Train Acc: 0.867949 | Val Loss: 0.114080, Val Acc: 0.773196\n",
      "Epoch 20933 - Train Loss: 0.084543, Train Acc: 0.867949 | Val Loss: 0.114079, Val Acc: 0.773196\n",
      "Epoch 20934 - Train Loss: 0.084541, Train Acc: 0.867949 | Val Loss: 0.114078, Val Acc: 0.773196\n",
      "Epoch 20935 - Train Loss: 0.084539, Train Acc: 0.867949 | Val Loss: 0.114077, Val Acc: 0.773196\n",
      "Epoch 20936 - Train Loss: 0.084537, Train Acc: 0.867949 | Val Loss: 0.114076, Val Acc: 0.773196\n",
      "Epoch 20937 - Train Loss: 0.084534, Train Acc: 0.867949 | Val Loss: 0.114075, Val Acc: 0.773196\n",
      "Epoch 20938 - Train Loss: 0.084532, Train Acc: 0.867949 | Val Loss: 0.114074, Val Acc: 0.773196\n",
      "Epoch 20939 - Train Loss: 0.084530, Train Acc: 0.867949 | Val Loss: 0.114073, Val Acc: 0.773196\n",
      "Epoch 20940 - Train Loss: 0.084528, Train Acc: 0.867949 | Val Loss: 0.114072, Val Acc: 0.773196\n",
      "Epoch 20941 - Train Loss: 0.084526, Train Acc: 0.867949 | Val Loss: 0.114071, Val Acc: 0.773196\n",
      "Epoch 20942 - Train Loss: 0.084524, Train Acc: 0.867949 | Val Loss: 0.114070, Val Acc: 0.773196\n",
      "Epoch 20943 - Train Loss: 0.084522, Train Acc: 0.867949 | Val Loss: 0.114070, Val Acc: 0.773196\n",
      "Epoch 20944 - Train Loss: 0.084520, Train Acc: 0.867949 | Val Loss: 0.114069, Val Acc: 0.773196\n",
      "Epoch 20945 - Train Loss: 0.084518, Train Acc: 0.867949 | Val Loss: 0.114068, Val Acc: 0.773196\n",
      "Epoch 20946 - Train Loss: 0.084516, Train Acc: 0.867949 | Val Loss: 0.114067, Val Acc: 0.773196\n",
      "Epoch 20947 - Train Loss: 0.084514, Train Acc: 0.867949 | Val Loss: 0.114066, Val Acc: 0.773196\n",
      "Epoch 20948 - Train Loss: 0.084512, Train Acc: 0.867949 | Val Loss: 0.114065, Val Acc: 0.773196\n",
      "Epoch 20949 - Train Loss: 0.084510, Train Acc: 0.867949 | Val Loss: 0.114064, Val Acc: 0.773196\n",
      "Epoch 20950 - Train Loss: 0.084507, Train Acc: 0.867949 | Val Loss: 0.114063, Val Acc: 0.773196\n",
      "Epoch 20951 - Train Loss: 0.084505, Train Acc: 0.867949 | Val Loss: 0.114062, Val Acc: 0.773196\n",
      "Epoch 20952 - Train Loss: 0.084503, Train Acc: 0.867949 | Val Loss: 0.114061, Val Acc: 0.773196\n",
      "Epoch 20953 - Train Loss: 0.084501, Train Acc: 0.867949 | Val Loss: 0.114060, Val Acc: 0.773196\n",
      "Epoch 20954 - Train Loss: 0.084499, Train Acc: 0.867949 | Val Loss: 0.114059, Val Acc: 0.773196\n",
      "Epoch 20955 - Train Loss: 0.084497, Train Acc: 0.867949 | Val Loss: 0.114058, Val Acc: 0.773196\n",
      "Epoch 20956 - Train Loss: 0.084495, Train Acc: 0.867949 | Val Loss: 0.114058, Val Acc: 0.773196\n",
      "Epoch 20957 - Train Loss: 0.084493, Train Acc: 0.867949 | Val Loss: 0.114057, Val Acc: 0.773196\n",
      "Epoch 20958 - Train Loss: 0.084491, Train Acc: 0.867949 | Val Loss: 0.114056, Val Acc: 0.773196\n",
      "Epoch 20959 - Train Loss: 0.084489, Train Acc: 0.867949 | Val Loss: 0.114055, Val Acc: 0.773196\n",
      "Epoch 20960 - Train Loss: 0.084487, Train Acc: 0.867949 | Val Loss: 0.114054, Val Acc: 0.773196\n",
      "Epoch 20961 - Train Loss: 0.084485, Train Acc: 0.867949 | Val Loss: 0.114053, Val Acc: 0.773196\n",
      "Epoch 20962 - Train Loss: 0.084483, Train Acc: 0.867949 | Val Loss: 0.114052, Val Acc: 0.773196\n",
      "Epoch 20963 - Train Loss: 0.084480, Train Acc: 0.867949 | Val Loss: 0.114051, Val Acc: 0.773196\n",
      "Epoch 20964 - Train Loss: 0.084478, Train Acc: 0.867949 | Val Loss: 0.114050, Val Acc: 0.773196\n",
      "Epoch 20965 - Train Loss: 0.084476, Train Acc: 0.867949 | Val Loss: 0.114049, Val Acc: 0.773196\n",
      "Epoch 20966 - Train Loss: 0.084474, Train Acc: 0.867949 | Val Loss: 0.114048, Val Acc: 0.773196\n",
      "Epoch 20967 - Train Loss: 0.084472, Train Acc: 0.867949 | Val Loss: 0.114047, Val Acc: 0.773196\n",
      "Epoch 20968 - Train Loss: 0.084470, Train Acc: 0.867949 | Val Loss: 0.114046, Val Acc: 0.773196\n",
      "Epoch 20969 - Train Loss: 0.084468, Train Acc: 0.867949 | Val Loss: 0.114046, Val Acc: 0.773196\n",
      "Epoch 20970 - Train Loss: 0.084466, Train Acc: 0.867949 | Val Loss: 0.114045, Val Acc: 0.773196\n",
      "Epoch 20971 - Train Loss: 0.084464, Train Acc: 0.867949 | Val Loss: 0.114044, Val Acc: 0.773196\n",
      "Epoch 20972 - Train Loss: 0.084462, Train Acc: 0.867949 | Val Loss: 0.114043, Val Acc: 0.773196\n",
      "Epoch 20973 - Train Loss: 0.084460, Train Acc: 0.867949 | Val Loss: 0.114042, Val Acc: 0.773196\n",
      "Epoch 20974 - Train Loss: 0.084458, Train Acc: 0.867949 | Val Loss: 0.114041, Val Acc: 0.773196\n",
      "Epoch 20975 - Train Loss: 0.084456, Train Acc: 0.867949 | Val Loss: 0.114040, Val Acc: 0.773196\n",
      "Epoch 20976 - Train Loss: 0.084454, Train Acc: 0.867949 | Val Loss: 0.114039, Val Acc: 0.773196\n",
      "Epoch 20977 - Train Loss: 0.084451, Train Acc: 0.867949 | Val Loss: 0.114038, Val Acc: 0.773196\n",
      "Epoch 20978 - Train Loss: 0.084449, Train Acc: 0.867949 | Val Loss: 0.114037, Val Acc: 0.773196\n",
      "Epoch 20979 - Train Loss: 0.084447, Train Acc: 0.867949 | Val Loss: 0.114036, Val Acc: 0.773196\n",
      "Epoch 20980 - Train Loss: 0.084445, Train Acc: 0.867949 | Val Loss: 0.114035, Val Acc: 0.773196\n",
      "Epoch 20981 - Train Loss: 0.084443, Train Acc: 0.867949 | Val Loss: 0.114034, Val Acc: 0.773196\n",
      "Epoch 20982 - Train Loss: 0.084441, Train Acc: 0.867949 | Val Loss: 0.114034, Val Acc: 0.773196\n",
      "Epoch 20983 - Train Loss: 0.084439, Train Acc: 0.867949 | Val Loss: 0.114033, Val Acc: 0.773196\n",
      "Epoch 20984 - Train Loss: 0.084437, Train Acc: 0.867949 | Val Loss: 0.114032, Val Acc: 0.773196\n",
      "Epoch 20985 - Train Loss: 0.084435, Train Acc: 0.867949 | Val Loss: 0.114031, Val Acc: 0.773196\n",
      "Epoch 20986 - Train Loss: 0.084433, Train Acc: 0.867949 | Val Loss: 0.114030, Val Acc: 0.773196\n",
      "Epoch 20987 - Train Loss: 0.084431, Train Acc: 0.867949 | Val Loss: 0.114029, Val Acc: 0.773196\n",
      "Epoch 20988 - Train Loss: 0.084429, Train Acc: 0.867949 | Val Loss: 0.114028, Val Acc: 0.773196\n",
      "Epoch 20989 - Train Loss: 0.084427, Train Acc: 0.867949 | Val Loss: 0.114027, Val Acc: 0.773196\n",
      "Epoch 20990 - Train Loss: 0.084425, Train Acc: 0.867949 | Val Loss: 0.114026, Val Acc: 0.773196\n",
      "Epoch 20991 - Train Loss: 0.084422, Train Acc: 0.867949 | Val Loss: 0.114025, Val Acc: 0.773196\n",
      "Epoch 20992 - Train Loss: 0.084420, Train Acc: 0.867949 | Val Loss: 0.114024, Val Acc: 0.773196\n",
      "Epoch 20993 - Train Loss: 0.084418, Train Acc: 0.867949 | Val Loss: 0.114023, Val Acc: 0.773196\n",
      "Epoch 20994 - Train Loss: 0.084416, Train Acc: 0.867949 | Val Loss: 0.114023, Val Acc: 0.773196\n",
      "Epoch 20995 - Train Loss: 0.084414, Train Acc: 0.867949 | Val Loss: 0.114022, Val Acc: 0.773196\n",
      "Epoch 20996 - Train Loss: 0.084412, Train Acc: 0.867949 | Val Loss: 0.114021, Val Acc: 0.773196\n",
      "Epoch 20997 - Train Loss: 0.084410, Train Acc: 0.867949 | Val Loss: 0.114020, Val Acc: 0.773196\n",
      "Epoch 20998 - Train Loss: 0.084408, Train Acc: 0.867949 | Val Loss: 0.114019, Val Acc: 0.773196\n",
      "Epoch 20999 - Train Loss: 0.084406, Train Acc: 0.867949 | Val Loss: 0.114018, Val Acc: 0.773196\n",
      "Epoch 21000 - Train Loss: 0.084404, Train Acc: 0.867949 | Val Loss: 0.114017, Val Acc: 0.773196\n",
      "Epoch 21001 - Train Loss: 0.084402, Train Acc: 0.867949 | Val Loss: 0.114016, Val Acc: 0.773196\n",
      "Epoch 21002 - Train Loss: 0.084400, Train Acc: 0.867949 | Val Loss: 0.114015, Val Acc: 0.773196\n",
      "Epoch 21003 - Train Loss: 0.084398, Train Acc: 0.867949 | Val Loss: 0.114014, Val Acc: 0.773196\n",
      "Epoch 21004 - Train Loss: 0.084396, Train Acc: 0.867949 | Val Loss: 0.114013, Val Acc: 0.773196\n",
      "Epoch 21005 - Train Loss: 0.084394, Train Acc: 0.867949 | Val Loss: 0.114012, Val Acc: 0.773196\n",
      "Epoch 21006 - Train Loss: 0.084391, Train Acc: 0.867949 | Val Loss: 0.114012, Val Acc: 0.773196\n",
      "Epoch 21007 - Train Loss: 0.084389, Train Acc: 0.867949 | Val Loss: 0.114011, Val Acc: 0.773196\n",
      "Epoch 21008 - Train Loss: 0.084387, Train Acc: 0.867949 | Val Loss: 0.114010, Val Acc: 0.773196\n",
      "Epoch 21009 - Train Loss: 0.084385, Train Acc: 0.867949 | Val Loss: 0.114009, Val Acc: 0.773196\n",
      "Epoch 21010 - Train Loss: 0.084383, Train Acc: 0.867949 | Val Loss: 0.114008, Val Acc: 0.773196\n",
      "Epoch 21011 - Train Loss: 0.084381, Train Acc: 0.867949 | Val Loss: 0.114007, Val Acc: 0.773196\n",
      "Epoch 21012 - Train Loss: 0.084379, Train Acc: 0.867949 | Val Loss: 0.114006, Val Acc: 0.773196\n",
      "Epoch 21013 - Train Loss: 0.084377, Train Acc: 0.867949 | Val Loss: 0.114005, Val Acc: 0.773196\n",
      "Epoch 21014 - Train Loss: 0.084375, Train Acc: 0.867949 | Val Loss: 0.114004, Val Acc: 0.773196\n",
      "Epoch 21015 - Train Loss: 0.084373, Train Acc: 0.867949 | Val Loss: 0.114003, Val Acc: 0.773196\n",
      "Epoch 21016 - Train Loss: 0.084371, Train Acc: 0.867949 | Val Loss: 0.114002, Val Acc: 0.773196\n",
      "Epoch 21017 - Train Loss: 0.084369, Train Acc: 0.867949 | Val Loss: 0.114001, Val Acc: 0.773196\n",
      "Epoch 21018 - Train Loss: 0.084367, Train Acc: 0.869231 | Val Loss: 0.114001, Val Acc: 0.773196\n",
      "Epoch 21019 - Train Loss: 0.084365, Train Acc: 0.869231 | Val Loss: 0.114000, Val Acc: 0.773196\n",
      "Epoch 21020 - Train Loss: 0.084363, Train Acc: 0.869231 | Val Loss: 0.113999, Val Acc: 0.773196\n",
      "Epoch 21021 - Train Loss: 0.084360, Train Acc: 0.869231 | Val Loss: 0.113998, Val Acc: 0.773196\n",
      "Epoch 21022 - Train Loss: 0.084358, Train Acc: 0.869231 | Val Loss: 0.113997, Val Acc: 0.773196\n",
      "Epoch 21023 - Train Loss: 0.084356, Train Acc: 0.869231 | Val Loss: 0.113996, Val Acc: 0.773196\n",
      "Epoch 21024 - Train Loss: 0.084354, Train Acc: 0.869231 | Val Loss: 0.113995, Val Acc: 0.773196\n",
      "Epoch 21025 - Train Loss: 0.084352, Train Acc: 0.869231 | Val Loss: 0.113994, Val Acc: 0.773196\n",
      "Epoch 21026 - Train Loss: 0.084350, Train Acc: 0.869231 | Val Loss: 0.113993, Val Acc: 0.773196\n",
      "Epoch 21027 - Train Loss: 0.084348, Train Acc: 0.869231 | Val Loss: 0.113992, Val Acc: 0.773196\n",
      "Epoch 21028 - Train Loss: 0.084346, Train Acc: 0.869231 | Val Loss: 0.113991, Val Acc: 0.773196\n",
      "Epoch 21029 - Train Loss: 0.084344, Train Acc: 0.869231 | Val Loss: 0.113990, Val Acc: 0.773196\n",
      "Epoch 21030 - Train Loss: 0.084342, Train Acc: 0.869231 | Val Loss: 0.113990, Val Acc: 0.773196\n",
      "Epoch 21031 - Train Loss: 0.084340, Train Acc: 0.869231 | Val Loss: 0.113989, Val Acc: 0.773196\n",
      "Epoch 21032 - Train Loss: 0.084338, Train Acc: 0.869231 | Val Loss: 0.113988, Val Acc: 0.773196\n",
      "Epoch 21033 - Train Loss: 0.084336, Train Acc: 0.869231 | Val Loss: 0.113987, Val Acc: 0.773196\n",
      "Epoch 21034 - Train Loss: 0.084334, Train Acc: 0.869231 | Val Loss: 0.113986, Val Acc: 0.773196\n",
      "Epoch 21035 - Train Loss: 0.084332, Train Acc: 0.869231 | Val Loss: 0.113985, Val Acc: 0.773196\n",
      "Epoch 21036 - Train Loss: 0.084330, Train Acc: 0.869231 | Val Loss: 0.113984, Val Acc: 0.773196\n",
      "Epoch 21037 - Train Loss: 0.084327, Train Acc: 0.869231 | Val Loss: 0.113983, Val Acc: 0.773196\n",
      "Epoch 21038 - Train Loss: 0.084325, Train Acc: 0.869231 | Val Loss: 0.113982, Val Acc: 0.773196\n",
      "Epoch 21039 - Train Loss: 0.084323, Train Acc: 0.869231 | Val Loss: 0.113981, Val Acc: 0.773196\n",
      "Epoch 21040 - Train Loss: 0.084321, Train Acc: 0.869231 | Val Loss: 0.113980, Val Acc: 0.773196\n",
      "Epoch 21041 - Train Loss: 0.084319, Train Acc: 0.869231 | Val Loss: 0.113979, Val Acc: 0.773196\n",
      "Epoch 21042 - Train Loss: 0.084317, Train Acc: 0.869231 | Val Loss: 0.113979, Val Acc: 0.773196\n",
      "Epoch 21043 - Train Loss: 0.084315, Train Acc: 0.869231 | Val Loss: 0.113978, Val Acc: 0.773196\n",
      "Epoch 21044 - Train Loss: 0.084313, Train Acc: 0.869231 | Val Loss: 0.113977, Val Acc: 0.773196\n",
      "Epoch 21045 - Train Loss: 0.084311, Train Acc: 0.869231 | Val Loss: 0.113976, Val Acc: 0.773196\n",
      "Epoch 21046 - Train Loss: 0.084309, Train Acc: 0.869231 | Val Loss: 0.113975, Val Acc: 0.773196\n",
      "Epoch 21047 - Train Loss: 0.084307, Train Acc: 0.869231 | Val Loss: 0.113974, Val Acc: 0.773196\n",
      "Epoch 21048 - Train Loss: 0.084305, Train Acc: 0.869231 | Val Loss: 0.113973, Val Acc: 0.773196\n",
      "Epoch 21049 - Train Loss: 0.084303, Train Acc: 0.869231 | Val Loss: 0.113972, Val Acc: 0.773196\n",
      "Epoch 21050 - Train Loss: 0.084301, Train Acc: 0.869231 | Val Loss: 0.113971, Val Acc: 0.773196\n",
      "Epoch 21051 - Train Loss: 0.084299, Train Acc: 0.869231 | Val Loss: 0.113970, Val Acc: 0.773196\n",
      "Epoch 21052 - Train Loss: 0.084297, Train Acc: 0.869231 | Val Loss: 0.113969, Val Acc: 0.773196\n",
      "Epoch 21053 - Train Loss: 0.084295, Train Acc: 0.869231 | Val Loss: 0.113969, Val Acc: 0.773196\n",
      "Epoch 21054 - Train Loss: 0.084292, Train Acc: 0.869231 | Val Loss: 0.113968, Val Acc: 0.773196\n",
      "Epoch 21055 - Train Loss: 0.084290, Train Acc: 0.869231 | Val Loss: 0.113967, Val Acc: 0.773196\n",
      "Epoch 21056 - Train Loss: 0.084288, Train Acc: 0.869231 | Val Loss: 0.113966, Val Acc: 0.773196\n",
      "Epoch 21057 - Train Loss: 0.084286, Train Acc: 0.869231 | Val Loss: 0.113965, Val Acc: 0.773196\n",
      "Epoch 21058 - Train Loss: 0.084284, Train Acc: 0.869231 | Val Loss: 0.113964, Val Acc: 0.773196\n",
      "Epoch 21059 - Train Loss: 0.084282, Train Acc: 0.869231 | Val Loss: 0.113963, Val Acc: 0.773196\n",
      "Epoch 21060 - Train Loss: 0.084280, Train Acc: 0.869231 | Val Loss: 0.113962, Val Acc: 0.773196\n",
      "Epoch 21061 - Train Loss: 0.084278, Train Acc: 0.869231 | Val Loss: 0.113961, Val Acc: 0.773196\n",
      "Epoch 21062 - Train Loss: 0.084276, Train Acc: 0.869231 | Val Loss: 0.113960, Val Acc: 0.773196\n",
      "Epoch 21063 - Train Loss: 0.084274, Train Acc: 0.869231 | Val Loss: 0.113959, Val Acc: 0.773196\n",
      "Epoch 21064 - Train Loss: 0.084272, Train Acc: 0.869231 | Val Loss: 0.113959, Val Acc: 0.773196\n",
      "Epoch 21065 - Train Loss: 0.084270, Train Acc: 0.869231 | Val Loss: 0.113958, Val Acc: 0.773196\n",
      "Epoch 21066 - Train Loss: 0.084268, Train Acc: 0.869231 | Val Loss: 0.113957, Val Acc: 0.773196\n",
      "Epoch 21067 - Train Loss: 0.084266, Train Acc: 0.869231 | Val Loss: 0.113956, Val Acc: 0.773196\n",
      "Epoch 21068 - Train Loss: 0.084264, Train Acc: 0.869231 | Val Loss: 0.113955, Val Acc: 0.773196\n",
      "Epoch 21069 - Train Loss: 0.084262, Train Acc: 0.869231 | Val Loss: 0.113954, Val Acc: 0.773196\n",
      "Epoch 21070 - Train Loss: 0.084260, Train Acc: 0.869231 | Val Loss: 0.113953, Val Acc: 0.773196\n",
      "Epoch 21071 - Train Loss: 0.084257, Train Acc: 0.869231 | Val Loss: 0.113952, Val Acc: 0.773196\n",
      "Epoch 21072 - Train Loss: 0.084255, Train Acc: 0.869231 | Val Loss: 0.113951, Val Acc: 0.773196\n",
      "Epoch 21073 - Train Loss: 0.084253, Train Acc: 0.869231 | Val Loss: 0.113950, Val Acc: 0.773196\n",
      "Epoch 21074 - Train Loss: 0.084251, Train Acc: 0.869231 | Val Loss: 0.113949, Val Acc: 0.773196\n",
      "Epoch 21075 - Train Loss: 0.084249, Train Acc: 0.869231 | Val Loss: 0.113949, Val Acc: 0.773196\n",
      "Epoch 21076 - Train Loss: 0.084247, Train Acc: 0.869231 | Val Loss: 0.113948, Val Acc: 0.773196\n",
      "Epoch 21077 - Train Loss: 0.084245, Train Acc: 0.869231 | Val Loss: 0.113947, Val Acc: 0.773196\n",
      "Epoch 21078 - Train Loss: 0.084243, Train Acc: 0.869231 | Val Loss: 0.113946, Val Acc: 0.773196\n",
      "Epoch 21079 - Train Loss: 0.084241, Train Acc: 0.869231 | Val Loss: 0.113945, Val Acc: 0.773196\n",
      "Epoch 21080 - Train Loss: 0.084239, Train Acc: 0.869231 | Val Loss: 0.113944, Val Acc: 0.773196\n",
      "Epoch 21081 - Train Loss: 0.084237, Train Acc: 0.869231 | Val Loss: 0.113943, Val Acc: 0.773196\n",
      "Epoch 21082 - Train Loss: 0.084235, Train Acc: 0.869231 | Val Loss: 0.113942, Val Acc: 0.773196\n",
      "Epoch 21083 - Train Loss: 0.084233, Train Acc: 0.869231 | Val Loss: 0.113941, Val Acc: 0.773196\n",
      "Epoch 21084 - Train Loss: 0.084231, Train Acc: 0.869231 | Val Loss: 0.113940, Val Acc: 0.773196\n",
      "Epoch 21085 - Train Loss: 0.084229, Train Acc: 0.869231 | Val Loss: 0.113939, Val Acc: 0.773196\n",
      "Epoch 21086 - Train Loss: 0.084227, Train Acc: 0.869231 | Val Loss: 0.113939, Val Acc: 0.773196\n",
      "Epoch 21087 - Train Loss: 0.084225, Train Acc: 0.869231 | Val Loss: 0.113938, Val Acc: 0.773196\n",
      "Epoch 21088 - Train Loss: 0.084223, Train Acc: 0.869231 | Val Loss: 0.113937, Val Acc: 0.773196\n",
      "Epoch 21089 - Train Loss: 0.084220, Train Acc: 0.869231 | Val Loss: 0.113936, Val Acc: 0.773196\n",
      "Epoch 21090 - Train Loss: 0.084218, Train Acc: 0.869231 | Val Loss: 0.113935, Val Acc: 0.773196\n",
      "Epoch 21091 - Train Loss: 0.084216, Train Acc: 0.869231 | Val Loss: 0.113934, Val Acc: 0.773196\n",
      "Epoch 21092 - Train Loss: 0.084214, Train Acc: 0.869231 | Val Loss: 0.113933, Val Acc: 0.773196\n",
      "Epoch 21093 - Train Loss: 0.084212, Train Acc: 0.869231 | Val Loss: 0.113932, Val Acc: 0.773196\n",
      "Epoch 21094 - Train Loss: 0.084210, Train Acc: 0.869231 | Val Loss: 0.113931, Val Acc: 0.773196\n",
      "Epoch 21095 - Train Loss: 0.084208, Train Acc: 0.869231 | Val Loss: 0.113930, Val Acc: 0.773196\n",
      "Epoch 21096 - Train Loss: 0.084206, Train Acc: 0.869231 | Val Loss: 0.113930, Val Acc: 0.773196\n",
      "Epoch 21097 - Train Loss: 0.084204, Train Acc: 0.869231 | Val Loss: 0.113929, Val Acc: 0.773196\n",
      "Epoch 21098 - Train Loss: 0.084202, Train Acc: 0.869231 | Val Loss: 0.113928, Val Acc: 0.773196\n",
      "Epoch 21099 - Train Loss: 0.084200, Train Acc: 0.869231 | Val Loss: 0.113927, Val Acc: 0.773196\n",
      "Epoch 21100 - Train Loss: 0.084198, Train Acc: 0.869231 | Val Loss: 0.113926, Val Acc: 0.773196\n",
      "Epoch 21101 - Train Loss: 0.084196, Train Acc: 0.869231 | Val Loss: 0.113925, Val Acc: 0.773196\n",
      "Epoch 21102 - Train Loss: 0.084194, Train Acc: 0.869231 | Val Loss: 0.113924, Val Acc: 0.773196\n",
      "Epoch 21103 - Train Loss: 0.084192, Train Acc: 0.869231 | Val Loss: 0.113923, Val Acc: 0.773196\n",
      "Epoch 21104 - Train Loss: 0.084190, Train Acc: 0.869231 | Val Loss: 0.113922, Val Acc: 0.773196\n",
      "Epoch 21105 - Train Loss: 0.084188, Train Acc: 0.869231 | Val Loss: 0.113921, Val Acc: 0.773196\n",
      "Epoch 21106 - Train Loss: 0.084186, Train Acc: 0.869231 | Val Loss: 0.113920, Val Acc: 0.773196\n",
      "Epoch 21107 - Train Loss: 0.084184, Train Acc: 0.869231 | Val Loss: 0.113920, Val Acc: 0.773196\n",
      "Epoch 21108 - Train Loss: 0.084182, Train Acc: 0.869231 | Val Loss: 0.113919, Val Acc: 0.773196\n",
      "Epoch 21109 - Train Loss: 0.084179, Train Acc: 0.869231 | Val Loss: 0.113918, Val Acc: 0.773196\n",
      "Epoch 21110 - Train Loss: 0.084177, Train Acc: 0.869231 | Val Loss: 0.113917, Val Acc: 0.773196\n",
      "Epoch 21111 - Train Loss: 0.084175, Train Acc: 0.869231 | Val Loss: 0.113916, Val Acc: 0.773196\n",
      "Epoch 21112 - Train Loss: 0.084173, Train Acc: 0.869231 | Val Loss: 0.113915, Val Acc: 0.773196\n",
      "Epoch 21113 - Train Loss: 0.084171, Train Acc: 0.869231 | Val Loss: 0.113914, Val Acc: 0.773196\n",
      "Epoch 21114 - Train Loss: 0.084169, Train Acc: 0.869231 | Val Loss: 0.113913, Val Acc: 0.773196\n",
      "Epoch 21115 - Train Loss: 0.084167, Train Acc: 0.869231 | Val Loss: 0.113912, Val Acc: 0.773196\n",
      "Epoch 21116 - Train Loss: 0.084165, Train Acc: 0.869231 | Val Loss: 0.113911, Val Acc: 0.773196\n",
      "Epoch 21117 - Train Loss: 0.084163, Train Acc: 0.869231 | Val Loss: 0.113911, Val Acc: 0.773196\n",
      "Epoch 21118 - Train Loss: 0.084161, Train Acc: 0.869231 | Val Loss: 0.113910, Val Acc: 0.773196\n",
      "Epoch 21119 - Train Loss: 0.084159, Train Acc: 0.869231 | Val Loss: 0.113909, Val Acc: 0.773196\n",
      "Epoch 21120 - Train Loss: 0.084157, Train Acc: 0.869231 | Val Loss: 0.113908, Val Acc: 0.773196\n",
      "Epoch 21121 - Train Loss: 0.084155, Train Acc: 0.869231 | Val Loss: 0.113907, Val Acc: 0.773196\n",
      "Epoch 21122 - Train Loss: 0.084153, Train Acc: 0.869231 | Val Loss: 0.113906, Val Acc: 0.773196\n",
      "Epoch 21123 - Train Loss: 0.084151, Train Acc: 0.869231 | Val Loss: 0.113905, Val Acc: 0.773196\n",
      "Epoch 21124 - Train Loss: 0.084149, Train Acc: 0.870513 | Val Loss: 0.113904, Val Acc: 0.773196\n",
      "Epoch 21125 - Train Loss: 0.084147, Train Acc: 0.870513 | Val Loss: 0.113903, Val Acc: 0.773196\n",
      "Epoch 21126 - Train Loss: 0.084145, Train Acc: 0.870513 | Val Loss: 0.113902, Val Acc: 0.773196\n",
      "Epoch 21127 - Train Loss: 0.084143, Train Acc: 0.870513 | Val Loss: 0.113902, Val Acc: 0.773196\n",
      "Epoch 21128 - Train Loss: 0.084141, Train Acc: 0.870513 | Val Loss: 0.113901, Val Acc: 0.773196\n",
      "Epoch 21129 - Train Loss: 0.084138, Train Acc: 0.870513 | Val Loss: 0.113900, Val Acc: 0.773196\n",
      "Epoch 21130 - Train Loss: 0.084136, Train Acc: 0.870513 | Val Loss: 0.113899, Val Acc: 0.773196\n",
      "Epoch 21131 - Train Loss: 0.084134, Train Acc: 0.870513 | Val Loss: 0.113898, Val Acc: 0.773196\n",
      "Epoch 21132 - Train Loss: 0.084132, Train Acc: 0.870513 | Val Loss: 0.113897, Val Acc: 0.773196\n",
      "Epoch 21133 - Train Loss: 0.084130, Train Acc: 0.870513 | Val Loss: 0.113896, Val Acc: 0.773196\n",
      "Epoch 21134 - Train Loss: 0.084128, Train Acc: 0.870513 | Val Loss: 0.113895, Val Acc: 0.773196\n",
      "Epoch 21135 - Train Loss: 0.084126, Train Acc: 0.870513 | Val Loss: 0.113894, Val Acc: 0.773196\n",
      "Epoch 21136 - Train Loss: 0.084124, Train Acc: 0.870513 | Val Loss: 0.113893, Val Acc: 0.773196\n",
      "Epoch 21137 - Train Loss: 0.084122, Train Acc: 0.870513 | Val Loss: 0.113893, Val Acc: 0.773196\n",
      "Epoch 21138 - Train Loss: 0.084120, Train Acc: 0.870513 | Val Loss: 0.113892, Val Acc: 0.773196\n",
      "Epoch 21139 - Train Loss: 0.084118, Train Acc: 0.869231 | Val Loss: 0.113891, Val Acc: 0.773196\n",
      "Epoch 21140 - Train Loss: 0.084116, Train Acc: 0.869231 | Val Loss: 0.113890, Val Acc: 0.773196\n",
      "Epoch 21141 - Train Loss: 0.084114, Train Acc: 0.869231 | Val Loss: 0.113889, Val Acc: 0.773196\n",
      "Epoch 21142 - Train Loss: 0.084112, Train Acc: 0.869231 | Val Loss: 0.113888, Val Acc: 0.773196\n",
      "Epoch 21143 - Train Loss: 0.084110, Train Acc: 0.869231 | Val Loss: 0.113887, Val Acc: 0.773196\n",
      "Epoch 21144 - Train Loss: 0.084108, Train Acc: 0.869231 | Val Loss: 0.113886, Val Acc: 0.773196\n",
      "Epoch 21145 - Train Loss: 0.084106, Train Acc: 0.869231 | Val Loss: 0.113885, Val Acc: 0.773196\n",
      "Epoch 21146 - Train Loss: 0.084104, Train Acc: 0.869231 | Val Loss: 0.113884, Val Acc: 0.773196\n",
      "Epoch 21147 - Train Loss: 0.084102, Train Acc: 0.869231 | Val Loss: 0.113884, Val Acc: 0.773196\n",
      "Epoch 21148 - Train Loss: 0.084100, Train Acc: 0.869231 | Val Loss: 0.113883, Val Acc: 0.773196\n",
      "Epoch 21149 - Train Loss: 0.084098, Train Acc: 0.869231 | Val Loss: 0.113882, Val Acc: 0.773196\n",
      "Epoch 21150 - Train Loss: 0.084096, Train Acc: 0.869231 | Val Loss: 0.113881, Val Acc: 0.773196\n",
      "Epoch 21151 - Train Loss: 0.084093, Train Acc: 0.869231 | Val Loss: 0.113880, Val Acc: 0.773196\n",
      "Epoch 21152 - Train Loss: 0.084091, Train Acc: 0.869231 | Val Loss: 0.113879, Val Acc: 0.773196\n",
      "Epoch 21153 - Train Loss: 0.084089, Train Acc: 0.869231 | Val Loss: 0.113878, Val Acc: 0.773196\n",
      "Epoch 21154 - Train Loss: 0.084087, Train Acc: 0.869231 | Val Loss: 0.113877, Val Acc: 0.773196\n",
      "Epoch 21155 - Train Loss: 0.084085, Train Acc: 0.869231 | Val Loss: 0.113876, Val Acc: 0.773196\n",
      "Epoch 21156 - Train Loss: 0.084083, Train Acc: 0.869231 | Val Loss: 0.113875, Val Acc: 0.773196\n",
      "Epoch 21157 - Train Loss: 0.084081, Train Acc: 0.869231 | Val Loss: 0.113875, Val Acc: 0.773196\n",
      "Epoch 21158 - Train Loss: 0.084079, Train Acc: 0.869231 | Val Loss: 0.113874, Val Acc: 0.773196\n",
      "Epoch 21159 - Train Loss: 0.084077, Train Acc: 0.869231 | Val Loss: 0.113873, Val Acc: 0.773196\n",
      "Epoch 21160 - Train Loss: 0.084075, Train Acc: 0.869231 | Val Loss: 0.113872, Val Acc: 0.773196\n",
      "Epoch 21161 - Train Loss: 0.084073, Train Acc: 0.869231 | Val Loss: 0.113871, Val Acc: 0.773196\n",
      "Epoch 21162 - Train Loss: 0.084071, Train Acc: 0.869231 | Val Loss: 0.113870, Val Acc: 0.773196\n",
      "Epoch 21163 - Train Loss: 0.084069, Train Acc: 0.869231 | Val Loss: 0.113869, Val Acc: 0.773196\n",
      "Epoch 21164 - Train Loss: 0.084067, Train Acc: 0.869231 | Val Loss: 0.113868, Val Acc: 0.773196\n",
      "Epoch 21165 - Train Loss: 0.084065, Train Acc: 0.869231 | Val Loss: 0.113867, Val Acc: 0.773196\n",
      "Epoch 21166 - Train Loss: 0.084063, Train Acc: 0.869231 | Val Loss: 0.113866, Val Acc: 0.773196\n",
      "Epoch 21167 - Train Loss: 0.084061, Train Acc: 0.869231 | Val Loss: 0.113866, Val Acc: 0.773196\n",
      "Epoch 21168 - Train Loss: 0.084059, Train Acc: 0.869231 | Val Loss: 0.113865, Val Acc: 0.773196\n",
      "Epoch 21169 - Train Loss: 0.084057, Train Acc: 0.869231 | Val Loss: 0.113864, Val Acc: 0.773196\n",
      "Epoch 21170 - Train Loss: 0.084055, Train Acc: 0.869231 | Val Loss: 0.113863, Val Acc: 0.773196\n",
      "Epoch 21171 - Train Loss: 0.084053, Train Acc: 0.869231 | Val Loss: 0.113862, Val Acc: 0.773196\n",
      "Epoch 21172 - Train Loss: 0.084051, Train Acc: 0.869231 | Val Loss: 0.113861, Val Acc: 0.773196\n",
      "Epoch 21173 - Train Loss: 0.084049, Train Acc: 0.869231 | Val Loss: 0.113860, Val Acc: 0.773196\n",
      "Epoch 21174 - Train Loss: 0.084047, Train Acc: 0.869231 | Val Loss: 0.113859, Val Acc: 0.773196\n",
      "Epoch 21175 - Train Loss: 0.084044, Train Acc: 0.869231 | Val Loss: 0.113858, Val Acc: 0.773196\n",
      "Epoch 21176 - Train Loss: 0.084042, Train Acc: 0.869231 | Val Loss: 0.113858, Val Acc: 0.773196\n",
      "Epoch 21177 - Train Loss: 0.084040, Train Acc: 0.869231 | Val Loss: 0.113857, Val Acc: 0.773196\n",
      "Epoch 21178 - Train Loss: 0.084038, Train Acc: 0.869231 | Val Loss: 0.113856, Val Acc: 0.773196\n",
      "Epoch 21179 - Train Loss: 0.084036, Train Acc: 0.869231 | Val Loss: 0.113855, Val Acc: 0.773196\n",
      "Epoch 21180 - Train Loss: 0.084034, Train Acc: 0.869231 | Val Loss: 0.113854, Val Acc: 0.773196\n",
      "Epoch 21181 - Train Loss: 0.084032, Train Acc: 0.869231 | Val Loss: 0.113853, Val Acc: 0.773196\n",
      "Epoch 21182 - Train Loss: 0.084030, Train Acc: 0.869231 | Val Loss: 0.113852, Val Acc: 0.773196\n",
      "Epoch 21183 - Train Loss: 0.084028, Train Acc: 0.869231 | Val Loss: 0.113851, Val Acc: 0.773196\n",
      "Epoch 21184 - Train Loss: 0.084026, Train Acc: 0.869231 | Val Loss: 0.113850, Val Acc: 0.773196\n",
      "Epoch 21185 - Train Loss: 0.084024, Train Acc: 0.869231 | Val Loss: 0.113850, Val Acc: 0.773196\n",
      "Epoch 21186 - Train Loss: 0.084022, Train Acc: 0.869231 | Val Loss: 0.113849, Val Acc: 0.773196\n",
      "Epoch 21187 - Train Loss: 0.084020, Train Acc: 0.869231 | Val Loss: 0.113848, Val Acc: 0.773196\n",
      "Epoch 21188 - Train Loss: 0.084018, Train Acc: 0.869231 | Val Loss: 0.113847, Val Acc: 0.773196\n",
      "Epoch 21189 - Train Loss: 0.084016, Train Acc: 0.869231 | Val Loss: 0.113846, Val Acc: 0.773196\n",
      "Epoch 21190 - Train Loss: 0.084014, Train Acc: 0.869231 | Val Loss: 0.113845, Val Acc: 0.773196\n",
      "Epoch 21191 - Train Loss: 0.084012, Train Acc: 0.869231 | Val Loss: 0.113844, Val Acc: 0.773196\n",
      "Epoch 21192 - Train Loss: 0.084010, Train Acc: 0.869231 | Val Loss: 0.113843, Val Acc: 0.773196\n",
      "Epoch 21193 - Train Loss: 0.084008, Train Acc: 0.869231 | Val Loss: 0.113842, Val Acc: 0.773196\n",
      "Epoch 21194 - Train Loss: 0.084006, Train Acc: 0.869231 | Val Loss: 0.113841, Val Acc: 0.773196\n",
      "Epoch 21195 - Train Loss: 0.084004, Train Acc: 0.869231 | Val Loss: 0.113841, Val Acc: 0.773196\n",
      "Epoch 21196 - Train Loss: 0.084002, Train Acc: 0.869231 | Val Loss: 0.113840, Val Acc: 0.773196\n",
      "Epoch 21197 - Train Loss: 0.084000, Train Acc: 0.869231 | Val Loss: 0.113839, Val Acc: 0.773196\n",
      "Epoch 21198 - Train Loss: 0.083998, Train Acc: 0.869231 | Val Loss: 0.113838, Val Acc: 0.773196\n",
      "Epoch 21199 - Train Loss: 0.083996, Train Acc: 0.869231 | Val Loss: 0.113837, Val Acc: 0.773196\n",
      "Epoch 21200 - Train Loss: 0.083994, Train Acc: 0.869231 | Val Loss: 0.113836, Val Acc: 0.773196\n",
      "Epoch 21201 - Train Loss: 0.083992, Train Acc: 0.869231 | Val Loss: 0.113835, Val Acc: 0.773196\n",
      "Epoch 21202 - Train Loss: 0.083989, Train Acc: 0.869231 | Val Loss: 0.113834, Val Acc: 0.773196\n",
      "Epoch 21203 - Train Loss: 0.083987, Train Acc: 0.869231 | Val Loss: 0.113833, Val Acc: 0.773196\n",
      "Epoch 21204 - Train Loss: 0.083985, Train Acc: 0.869231 | Val Loss: 0.113833, Val Acc: 0.773196\n",
      "Epoch 21205 - Train Loss: 0.083983, Train Acc: 0.869231 | Val Loss: 0.113832, Val Acc: 0.773196\n",
      "Epoch 21206 - Train Loss: 0.083981, Train Acc: 0.869231 | Val Loss: 0.113831, Val Acc: 0.773196\n",
      "Epoch 21207 - Train Loss: 0.083979, Train Acc: 0.869231 | Val Loss: 0.113830, Val Acc: 0.773196\n",
      "Epoch 21208 - Train Loss: 0.083977, Train Acc: 0.869231 | Val Loss: 0.113829, Val Acc: 0.773196\n",
      "Epoch 21209 - Train Loss: 0.083975, Train Acc: 0.869231 | Val Loss: 0.113828, Val Acc: 0.773196\n",
      "Epoch 21210 - Train Loss: 0.083973, Train Acc: 0.869231 | Val Loss: 0.113827, Val Acc: 0.773196\n",
      "Epoch 21211 - Train Loss: 0.083971, Train Acc: 0.869231 | Val Loss: 0.113826, Val Acc: 0.773196\n",
      "Epoch 21212 - Train Loss: 0.083969, Train Acc: 0.869231 | Val Loss: 0.113825, Val Acc: 0.773196\n",
      "Epoch 21213 - Train Loss: 0.083967, Train Acc: 0.869231 | Val Loss: 0.113825, Val Acc: 0.773196\n",
      "Epoch 21214 - Train Loss: 0.083965, Train Acc: 0.869231 | Val Loss: 0.113824, Val Acc: 0.773196\n",
      "Epoch 21215 - Train Loss: 0.083963, Train Acc: 0.869231 | Val Loss: 0.113823, Val Acc: 0.773196\n",
      "Epoch 21216 - Train Loss: 0.083961, Train Acc: 0.869231 | Val Loss: 0.113822, Val Acc: 0.773196\n",
      "Epoch 21217 - Train Loss: 0.083959, Train Acc: 0.869231 | Val Loss: 0.113821, Val Acc: 0.773196\n",
      "Epoch 21218 - Train Loss: 0.083957, Train Acc: 0.869231 | Val Loss: 0.113820, Val Acc: 0.773196\n",
      "Epoch 21219 - Train Loss: 0.083955, Train Acc: 0.869231 | Val Loss: 0.113819, Val Acc: 0.773196\n",
      "Epoch 21220 - Train Loss: 0.083953, Train Acc: 0.869231 | Val Loss: 0.113818, Val Acc: 0.773196\n",
      "Epoch 21221 - Train Loss: 0.083951, Train Acc: 0.869231 | Val Loss: 0.113817, Val Acc: 0.773196\n",
      "Epoch 21222 - Train Loss: 0.083949, Train Acc: 0.869231 | Val Loss: 0.113817, Val Acc: 0.773196\n",
      "Epoch 21223 - Train Loss: 0.083947, Train Acc: 0.869231 | Val Loss: 0.113816, Val Acc: 0.773196\n",
      "Epoch 21224 - Train Loss: 0.083945, Train Acc: 0.869231 | Val Loss: 0.113815, Val Acc: 0.773196\n",
      "Epoch 21225 - Train Loss: 0.083943, Train Acc: 0.869231 | Val Loss: 0.113814, Val Acc: 0.773196\n",
      "Epoch 21226 - Train Loss: 0.083941, Train Acc: 0.869231 | Val Loss: 0.113813, Val Acc: 0.773196\n",
      "Epoch 21227 - Train Loss: 0.083939, Train Acc: 0.869231 | Val Loss: 0.113812, Val Acc: 0.773196\n",
      "Epoch 21228 - Train Loss: 0.083937, Train Acc: 0.869231 | Val Loss: 0.113811, Val Acc: 0.773196\n",
      "Epoch 21229 - Train Loss: 0.083935, Train Acc: 0.869231 | Val Loss: 0.113810, Val Acc: 0.773196\n",
      "Epoch 21230 - Train Loss: 0.083933, Train Acc: 0.869231 | Val Loss: 0.113809, Val Acc: 0.773196\n",
      "Epoch 21231 - Train Loss: 0.083931, Train Acc: 0.869231 | Val Loss: 0.113809, Val Acc: 0.773196\n",
      "Epoch 21232 - Train Loss: 0.083928, Train Acc: 0.869231 | Val Loss: 0.113808, Val Acc: 0.773196\n",
      "Epoch 21233 - Train Loss: 0.083926, Train Acc: 0.869231 | Val Loss: 0.113807, Val Acc: 0.773196\n",
      "Epoch 21234 - Train Loss: 0.083924, Train Acc: 0.869231 | Val Loss: 0.113806, Val Acc: 0.773196\n",
      "Epoch 21235 - Train Loss: 0.083922, Train Acc: 0.869231 | Val Loss: 0.113805, Val Acc: 0.773196\n",
      "Epoch 21236 - Train Loss: 0.083920, Train Acc: 0.869231 | Val Loss: 0.113804, Val Acc: 0.773196\n",
      "Epoch 21237 - Train Loss: 0.083918, Train Acc: 0.869231 | Val Loss: 0.113803, Val Acc: 0.773196\n",
      "Epoch 21238 - Train Loss: 0.083916, Train Acc: 0.869231 | Val Loss: 0.113802, Val Acc: 0.773196\n",
      "Epoch 21239 - Train Loss: 0.083914, Train Acc: 0.869231 | Val Loss: 0.113801, Val Acc: 0.773196\n",
      "Epoch 21240 - Train Loss: 0.083912, Train Acc: 0.869231 | Val Loss: 0.113801, Val Acc: 0.773196\n",
      "Epoch 21241 - Train Loss: 0.083910, Train Acc: 0.869231 | Val Loss: 0.113800, Val Acc: 0.773196\n",
      "Epoch 21242 - Train Loss: 0.083908, Train Acc: 0.869231 | Val Loss: 0.113799, Val Acc: 0.773196\n",
      "Epoch 21243 - Train Loss: 0.083906, Train Acc: 0.869231 | Val Loss: 0.113798, Val Acc: 0.773196\n",
      "Epoch 21244 - Train Loss: 0.083904, Train Acc: 0.869231 | Val Loss: 0.113797, Val Acc: 0.773196\n",
      "Epoch 21245 - Train Loss: 0.083902, Train Acc: 0.869231 | Val Loss: 0.113796, Val Acc: 0.773196\n",
      "Epoch 21246 - Train Loss: 0.083900, Train Acc: 0.869231 | Val Loss: 0.113795, Val Acc: 0.773196\n",
      "Epoch 21247 - Train Loss: 0.083898, Train Acc: 0.869231 | Val Loss: 0.113794, Val Acc: 0.773196\n",
      "Epoch 21248 - Train Loss: 0.083896, Train Acc: 0.869231 | Val Loss: 0.113794, Val Acc: 0.773196\n",
      "Epoch 21249 - Train Loss: 0.083894, Train Acc: 0.869231 | Val Loss: 0.113793, Val Acc: 0.773196\n",
      "Epoch 21250 - Train Loss: 0.083892, Train Acc: 0.869231 | Val Loss: 0.113792, Val Acc: 0.773196\n",
      "Epoch 21251 - Train Loss: 0.083890, Train Acc: 0.869231 | Val Loss: 0.113791, Val Acc: 0.773196\n",
      "Epoch 21252 - Train Loss: 0.083888, Train Acc: 0.869231 | Val Loss: 0.113790, Val Acc: 0.773196\n",
      "Epoch 21253 - Train Loss: 0.083886, Train Acc: 0.869231 | Val Loss: 0.113789, Val Acc: 0.773196\n",
      "Epoch 21254 - Train Loss: 0.083884, Train Acc: 0.869231 | Val Loss: 0.113788, Val Acc: 0.773196\n",
      "Epoch 21255 - Train Loss: 0.083882, Train Acc: 0.869231 | Val Loss: 0.113787, Val Acc: 0.773196\n",
      "Epoch 21256 - Train Loss: 0.083880, Train Acc: 0.869231 | Val Loss: 0.113786, Val Acc: 0.773196\n",
      "Epoch 21257 - Train Loss: 0.083878, Train Acc: 0.869231 | Val Loss: 0.113786, Val Acc: 0.773196\n",
      "Epoch 21258 - Train Loss: 0.083876, Train Acc: 0.869231 | Val Loss: 0.113785, Val Acc: 0.773196\n",
      "Epoch 21259 - Train Loss: 0.083874, Train Acc: 0.869231 | Val Loss: 0.113784, Val Acc: 0.773196\n",
      "Epoch 21260 - Train Loss: 0.083872, Train Acc: 0.869231 | Val Loss: 0.113783, Val Acc: 0.773196\n",
      "Epoch 21261 - Train Loss: 0.083870, Train Acc: 0.869231 | Val Loss: 0.113782, Val Acc: 0.773196\n",
      "Epoch 21262 - Train Loss: 0.083868, Train Acc: 0.869231 | Val Loss: 0.113781, Val Acc: 0.773196\n",
      "Epoch 21263 - Train Loss: 0.083866, Train Acc: 0.869231 | Val Loss: 0.113780, Val Acc: 0.773196\n",
      "Epoch 21264 - Train Loss: 0.083864, Train Acc: 0.869231 | Val Loss: 0.113779, Val Acc: 0.773196\n",
      "Epoch 21265 - Train Loss: 0.083862, Train Acc: 0.869231 | Val Loss: 0.113779, Val Acc: 0.773196\n",
      "Epoch 21266 - Train Loss: 0.083860, Train Acc: 0.869231 | Val Loss: 0.113778, Val Acc: 0.773196\n",
      "Epoch 21267 - Train Loss: 0.083857, Train Acc: 0.869231 | Val Loss: 0.113777, Val Acc: 0.773196\n",
      "Epoch 21268 - Train Loss: 0.083855, Train Acc: 0.869231 | Val Loss: 0.113776, Val Acc: 0.773196\n",
      "Epoch 21269 - Train Loss: 0.083853, Train Acc: 0.869231 | Val Loss: 0.113775, Val Acc: 0.773196\n",
      "Epoch 21270 - Train Loss: 0.083851, Train Acc: 0.869231 | Val Loss: 0.113774, Val Acc: 0.773196\n",
      "Epoch 21271 - Train Loss: 0.083849, Train Acc: 0.869231 | Val Loss: 0.113773, Val Acc: 0.773196\n",
      "Epoch 21272 - Train Loss: 0.083847, Train Acc: 0.869231 | Val Loss: 0.113772, Val Acc: 0.773196\n",
      "Epoch 21273 - Train Loss: 0.083845, Train Acc: 0.869231 | Val Loss: 0.113771, Val Acc: 0.773196\n",
      "Epoch 21274 - Train Loss: 0.083843, Train Acc: 0.869231 | Val Loss: 0.113771, Val Acc: 0.773196\n",
      "Epoch 21275 - Train Loss: 0.083841, Train Acc: 0.869231 | Val Loss: 0.113770, Val Acc: 0.773196\n",
      "Epoch 21276 - Train Loss: 0.083839, Train Acc: 0.869231 | Val Loss: 0.113769, Val Acc: 0.773196\n",
      "Epoch 21277 - Train Loss: 0.083837, Train Acc: 0.869231 | Val Loss: 0.113768, Val Acc: 0.773196\n",
      "Epoch 21278 - Train Loss: 0.083835, Train Acc: 0.869231 | Val Loss: 0.113767, Val Acc: 0.773196\n",
      "Epoch 21279 - Train Loss: 0.083833, Train Acc: 0.869231 | Val Loss: 0.113766, Val Acc: 0.773196\n",
      "Epoch 21280 - Train Loss: 0.083831, Train Acc: 0.869231 | Val Loss: 0.113765, Val Acc: 0.773196\n",
      "Epoch 21281 - Train Loss: 0.083829, Train Acc: 0.869231 | Val Loss: 0.113764, Val Acc: 0.773196\n",
      "Epoch 21282 - Train Loss: 0.083827, Train Acc: 0.869231 | Val Loss: 0.113764, Val Acc: 0.773196\n",
      "Epoch 21283 - Train Loss: 0.083825, Train Acc: 0.869231 | Val Loss: 0.113763, Val Acc: 0.773196\n",
      "Epoch 21284 - Train Loss: 0.083823, Train Acc: 0.869231 | Val Loss: 0.113762, Val Acc: 0.773196\n",
      "Epoch 21285 - Train Loss: 0.083821, Train Acc: 0.869231 | Val Loss: 0.113761, Val Acc: 0.773196\n",
      "Epoch 21286 - Train Loss: 0.083819, Train Acc: 0.869231 | Val Loss: 0.113760, Val Acc: 0.773196\n",
      "Epoch 21287 - Train Loss: 0.083817, Train Acc: 0.869231 | Val Loss: 0.113759, Val Acc: 0.773196\n",
      "Epoch 21288 - Train Loss: 0.083815, Train Acc: 0.869231 | Val Loss: 0.113758, Val Acc: 0.773196\n",
      "Epoch 21289 - Train Loss: 0.083813, Train Acc: 0.869231 | Val Loss: 0.113757, Val Acc: 0.773196\n",
      "Epoch 21290 - Train Loss: 0.083811, Train Acc: 0.869231 | Val Loss: 0.113756, Val Acc: 0.773196\n",
      "Epoch 21291 - Train Loss: 0.083809, Train Acc: 0.869231 | Val Loss: 0.113756, Val Acc: 0.773196\n",
      "Epoch 21292 - Train Loss: 0.083807, Train Acc: 0.869231 | Val Loss: 0.113755, Val Acc: 0.773196\n",
      "Epoch 21293 - Train Loss: 0.083805, Train Acc: 0.869231 | Val Loss: 0.113754, Val Acc: 0.773196\n",
      "Epoch 21294 - Train Loss: 0.083803, Train Acc: 0.869231 | Val Loss: 0.113753, Val Acc: 0.773196\n",
      "Epoch 21295 - Train Loss: 0.083801, Train Acc: 0.869231 | Val Loss: 0.113752, Val Acc: 0.773196\n",
      "Epoch 21296 - Train Loss: 0.083799, Train Acc: 0.869231 | Val Loss: 0.113751, Val Acc: 0.773196\n",
      "Epoch 21297 - Train Loss: 0.083797, Train Acc: 0.869231 | Val Loss: 0.113750, Val Acc: 0.773196\n",
      "Epoch 21298 - Train Loss: 0.083795, Train Acc: 0.869231 | Val Loss: 0.113749, Val Acc: 0.773196\n",
      "Epoch 21299 - Train Loss: 0.083793, Train Acc: 0.869231 | Val Loss: 0.113749, Val Acc: 0.773196\n",
      "Epoch 21300 - Train Loss: 0.083791, Train Acc: 0.869231 | Val Loss: 0.113748, Val Acc: 0.773196\n",
      "Epoch 21301 - Train Loss: 0.083789, Train Acc: 0.869231 | Val Loss: 0.113747, Val Acc: 0.773196\n",
      "Epoch 21302 - Train Loss: 0.083787, Train Acc: 0.869231 | Val Loss: 0.113746, Val Acc: 0.773196\n",
      "Epoch 21303 - Train Loss: 0.083785, Train Acc: 0.869231 | Val Loss: 0.113745, Val Acc: 0.773196\n",
      "Epoch 21304 - Train Loss: 0.083783, Train Acc: 0.869231 | Val Loss: 0.113744, Val Acc: 0.773196\n",
      "Epoch 21305 - Train Loss: 0.083781, Train Acc: 0.869231 | Val Loss: 0.113743, Val Acc: 0.773196\n",
      "Epoch 21306 - Train Loss: 0.083779, Train Acc: 0.869231 | Val Loss: 0.113742, Val Acc: 0.773196\n",
      "Epoch 21307 - Train Loss: 0.083777, Train Acc: 0.869231 | Val Loss: 0.113742, Val Acc: 0.773196\n",
      "Epoch 21308 - Train Loss: 0.083775, Train Acc: 0.869231 | Val Loss: 0.113741, Val Acc: 0.773196\n",
      "Epoch 21309 - Train Loss: 0.083773, Train Acc: 0.869231 | Val Loss: 0.113740, Val Acc: 0.773196\n",
      "Epoch 21310 - Train Loss: 0.083771, Train Acc: 0.869231 | Val Loss: 0.113739, Val Acc: 0.773196\n",
      "Epoch 21311 - Train Loss: 0.083769, Train Acc: 0.869231 | Val Loss: 0.113738, Val Acc: 0.773196\n",
      "Epoch 21312 - Train Loss: 0.083766, Train Acc: 0.869231 | Val Loss: 0.113737, Val Acc: 0.773196\n",
      "Epoch 21313 - Train Loss: 0.083764, Train Acc: 0.869231 | Val Loss: 0.113736, Val Acc: 0.773196\n",
      "Epoch 21314 - Train Loss: 0.083762, Train Acc: 0.869231 | Val Loss: 0.113735, Val Acc: 0.773196\n",
      "Epoch 21315 - Train Loss: 0.083760, Train Acc: 0.869231 | Val Loss: 0.113735, Val Acc: 0.773196\n",
      "Epoch 21316 - Train Loss: 0.083758, Train Acc: 0.869231 | Val Loss: 0.113734, Val Acc: 0.773196\n",
      "Epoch 21317 - Train Loss: 0.083756, Train Acc: 0.869231 | Val Loss: 0.113733, Val Acc: 0.773196\n",
      "Epoch 21318 - Train Loss: 0.083754, Train Acc: 0.869231 | Val Loss: 0.113732, Val Acc: 0.773196\n",
      "Epoch 21319 - Train Loss: 0.083752, Train Acc: 0.869231 | Val Loss: 0.113731, Val Acc: 0.773196\n",
      "Epoch 21320 - Train Loss: 0.083750, Train Acc: 0.869231 | Val Loss: 0.113730, Val Acc: 0.773196\n",
      "Epoch 21321 - Train Loss: 0.083748, Train Acc: 0.869231 | Val Loss: 0.113729, Val Acc: 0.773196\n",
      "Epoch 21322 - Train Loss: 0.083746, Train Acc: 0.869231 | Val Loss: 0.113728, Val Acc: 0.773196\n",
      "Epoch 21323 - Train Loss: 0.083744, Train Acc: 0.869231 | Val Loss: 0.113728, Val Acc: 0.773196\n",
      "Epoch 21324 - Train Loss: 0.083742, Train Acc: 0.869231 | Val Loss: 0.113727, Val Acc: 0.773196\n",
      "Epoch 21325 - Train Loss: 0.083740, Train Acc: 0.869231 | Val Loss: 0.113726, Val Acc: 0.773196\n",
      "Epoch 21326 - Train Loss: 0.083738, Train Acc: 0.869231 | Val Loss: 0.113725, Val Acc: 0.773196\n",
      "Epoch 21327 - Train Loss: 0.083736, Train Acc: 0.869231 | Val Loss: 0.113724, Val Acc: 0.773196\n",
      "Epoch 21328 - Train Loss: 0.083734, Train Acc: 0.869231 | Val Loss: 0.113723, Val Acc: 0.773196\n",
      "Epoch 21329 - Train Loss: 0.083732, Train Acc: 0.869231 | Val Loss: 0.113722, Val Acc: 0.773196\n",
      "Epoch 21330 - Train Loss: 0.083730, Train Acc: 0.869231 | Val Loss: 0.113721, Val Acc: 0.773196\n",
      "Epoch 21331 - Train Loss: 0.083728, Train Acc: 0.869231 | Val Loss: 0.113721, Val Acc: 0.773196\n",
      "Epoch 21332 - Train Loss: 0.083726, Train Acc: 0.869231 | Val Loss: 0.113720, Val Acc: 0.773196\n",
      "Epoch 21333 - Train Loss: 0.083724, Train Acc: 0.869231 | Val Loss: 0.113719, Val Acc: 0.773196\n",
      "Epoch 21334 - Train Loss: 0.083722, Train Acc: 0.869231 | Val Loss: 0.113718, Val Acc: 0.773196\n",
      "Epoch 21335 - Train Loss: 0.083720, Train Acc: 0.869231 | Val Loss: 0.113717, Val Acc: 0.773196\n",
      "Epoch 21336 - Train Loss: 0.083718, Train Acc: 0.869231 | Val Loss: 0.113716, Val Acc: 0.773196\n",
      "Epoch 21337 - Train Loss: 0.083716, Train Acc: 0.869231 | Val Loss: 0.113715, Val Acc: 0.773196\n",
      "Epoch 21338 - Train Loss: 0.083714, Train Acc: 0.869231 | Val Loss: 0.113714, Val Acc: 0.773196\n",
      "Epoch 21339 - Train Loss: 0.083712, Train Acc: 0.869231 | Val Loss: 0.113714, Val Acc: 0.773196\n",
      "Epoch 21340 - Train Loss: 0.083710, Train Acc: 0.869231 | Val Loss: 0.113713, Val Acc: 0.773196\n",
      "Epoch 21341 - Train Loss: 0.083708, Train Acc: 0.869231 | Val Loss: 0.113712, Val Acc: 0.773196\n",
      "Epoch 21342 - Train Loss: 0.083706, Train Acc: 0.869231 | Val Loss: 0.113711, Val Acc: 0.773196\n",
      "Epoch 21343 - Train Loss: 0.083704, Train Acc: 0.869231 | Val Loss: 0.113710, Val Acc: 0.773196\n",
      "Epoch 21344 - Train Loss: 0.083702, Train Acc: 0.869231 | Val Loss: 0.113709, Val Acc: 0.773196\n",
      "Epoch 21345 - Train Loss: 0.083700, Train Acc: 0.869231 | Val Loss: 0.113708, Val Acc: 0.773196\n",
      "Epoch 21346 - Train Loss: 0.083698, Train Acc: 0.869231 | Val Loss: 0.113707, Val Acc: 0.773196\n",
      "Epoch 21347 - Train Loss: 0.083696, Train Acc: 0.869231 | Val Loss: 0.113707, Val Acc: 0.773196\n",
      "Epoch 21348 - Train Loss: 0.083694, Train Acc: 0.869231 | Val Loss: 0.113706, Val Acc: 0.773196\n",
      "Epoch 21349 - Train Loss: 0.083692, Train Acc: 0.869231 | Val Loss: 0.113705, Val Acc: 0.773196\n",
      "Epoch 21350 - Train Loss: 0.083690, Train Acc: 0.869231 | Val Loss: 0.113704, Val Acc: 0.773196\n",
      "Epoch 21351 - Train Loss: 0.083688, Train Acc: 0.869231 | Val Loss: 0.113703, Val Acc: 0.773196\n",
      "Epoch 21352 - Train Loss: 0.083686, Train Acc: 0.869231 | Val Loss: 0.113702, Val Acc: 0.773196\n",
      "Epoch 21353 - Train Loss: 0.083684, Train Acc: 0.869231 | Val Loss: 0.113701, Val Acc: 0.773196\n",
      "Epoch 21354 - Train Loss: 0.083682, Train Acc: 0.869231 | Val Loss: 0.113701, Val Acc: 0.773196\n",
      "Epoch 21355 - Train Loss: 0.083680, Train Acc: 0.869231 | Val Loss: 0.113700, Val Acc: 0.773196\n",
      "Epoch 21356 - Train Loss: 0.083678, Train Acc: 0.869231 | Val Loss: 0.113699, Val Acc: 0.773196\n",
      "Epoch 21357 - Train Loss: 0.083676, Train Acc: 0.869231 | Val Loss: 0.113698, Val Acc: 0.773196\n",
      "Epoch 21358 - Train Loss: 0.083674, Train Acc: 0.869231 | Val Loss: 0.113697, Val Acc: 0.773196\n",
      "Epoch 21359 - Train Loss: 0.083672, Train Acc: 0.869231 | Val Loss: 0.113696, Val Acc: 0.773196\n",
      "Epoch 21360 - Train Loss: 0.083670, Train Acc: 0.869231 | Val Loss: 0.113695, Val Acc: 0.773196\n",
      "Epoch 21361 - Train Loss: 0.083668, Train Acc: 0.869231 | Val Loss: 0.113694, Val Acc: 0.773196\n",
      "Epoch 21362 - Train Loss: 0.083666, Train Acc: 0.869231 | Val Loss: 0.113694, Val Acc: 0.773196\n",
      "Epoch 21363 - Train Loss: 0.083664, Train Acc: 0.869231 | Val Loss: 0.113693, Val Acc: 0.773196\n",
      "Epoch 21364 - Train Loss: 0.083662, Train Acc: 0.869231 | Val Loss: 0.113692, Val Acc: 0.773196\n",
      "Epoch 21365 - Train Loss: 0.083660, Train Acc: 0.869231 | Val Loss: 0.113691, Val Acc: 0.773196\n",
      "Epoch 21366 - Train Loss: 0.083658, Train Acc: 0.869231 | Val Loss: 0.113690, Val Acc: 0.773196\n",
      "Epoch 21367 - Train Loss: 0.083656, Train Acc: 0.869231 | Val Loss: 0.113689, Val Acc: 0.773196\n",
      "Epoch 21368 - Train Loss: 0.083654, Train Acc: 0.869231 | Val Loss: 0.113688, Val Acc: 0.773196\n",
      "Epoch 21369 - Train Loss: 0.083652, Train Acc: 0.869231 | Val Loss: 0.113687, Val Acc: 0.773196\n",
      "Epoch 21370 - Train Loss: 0.083650, Train Acc: 0.869231 | Val Loss: 0.113687, Val Acc: 0.773196\n",
      "Epoch 21371 - Train Loss: 0.083648, Train Acc: 0.869231 | Val Loss: 0.113686, Val Acc: 0.773196\n",
      "Epoch 21372 - Train Loss: 0.083646, Train Acc: 0.869231 | Val Loss: 0.113685, Val Acc: 0.773196\n",
      "Epoch 21373 - Train Loss: 0.083644, Train Acc: 0.869231 | Val Loss: 0.113684, Val Acc: 0.773196\n",
      "Epoch 21374 - Train Loss: 0.083642, Train Acc: 0.869231 | Val Loss: 0.113683, Val Acc: 0.773196\n",
      "Epoch 21375 - Train Loss: 0.083640, Train Acc: 0.869231 | Val Loss: 0.113682, Val Acc: 0.773196\n",
      "Epoch 21376 - Train Loss: 0.083638, Train Acc: 0.869231 | Val Loss: 0.113681, Val Acc: 0.773196\n",
      "Epoch 21377 - Train Loss: 0.083636, Train Acc: 0.869231 | Val Loss: 0.113681, Val Acc: 0.773196\n",
      "Epoch 21378 - Train Loss: 0.083634, Train Acc: 0.869231 | Val Loss: 0.113680, Val Acc: 0.773196\n",
      "Epoch 21379 - Train Loss: 0.083632, Train Acc: 0.869231 | Val Loss: 0.113679, Val Acc: 0.773196\n",
      "Epoch 21380 - Train Loss: 0.083630, Train Acc: 0.869231 | Val Loss: 0.113678, Val Acc: 0.773196\n",
      "Epoch 21381 - Train Loss: 0.083628, Train Acc: 0.869231 | Val Loss: 0.113677, Val Acc: 0.773196\n",
      "Epoch 21382 - Train Loss: 0.083626, Train Acc: 0.869231 | Val Loss: 0.113676, Val Acc: 0.773196\n",
      "Epoch 21383 - Train Loss: 0.083624, Train Acc: 0.869231 | Val Loss: 0.113675, Val Acc: 0.773196\n",
      "Epoch 21384 - Train Loss: 0.083622, Train Acc: 0.869231 | Val Loss: 0.113674, Val Acc: 0.773196\n",
      "Epoch 21385 - Train Loss: 0.083620, Train Acc: 0.869231 | Val Loss: 0.113674, Val Acc: 0.773196\n",
      "Epoch 21386 - Train Loss: 0.083618, Train Acc: 0.869231 | Val Loss: 0.113673, Val Acc: 0.773196\n",
      "Epoch 21387 - Train Loss: 0.083616, Train Acc: 0.869231 | Val Loss: 0.113672, Val Acc: 0.773196\n",
      "Epoch 21388 - Train Loss: 0.083614, Train Acc: 0.869231 | Val Loss: 0.113671, Val Acc: 0.773196\n",
      "Epoch 21389 - Train Loss: 0.083612, Train Acc: 0.869231 | Val Loss: 0.113670, Val Acc: 0.773196\n",
      "Epoch 21390 - Train Loss: 0.083609, Train Acc: 0.869231 | Val Loss: 0.113669, Val Acc: 0.773196\n",
      "Epoch 21391 - Train Loss: 0.083607, Train Acc: 0.869231 | Val Loss: 0.113668, Val Acc: 0.773196\n",
      "Epoch 21392 - Train Loss: 0.083605, Train Acc: 0.869231 | Val Loss: 0.113668, Val Acc: 0.773196\n",
      "Epoch 21393 - Train Loss: 0.083603, Train Acc: 0.869231 | Val Loss: 0.113667, Val Acc: 0.773196\n",
      "Epoch 21394 - Train Loss: 0.083601, Train Acc: 0.869231 | Val Loss: 0.113666, Val Acc: 0.773196\n",
      "Epoch 21395 - Train Loss: 0.083599, Train Acc: 0.869231 | Val Loss: 0.113665, Val Acc: 0.773196\n",
      "Epoch 21396 - Train Loss: 0.083597, Train Acc: 0.869231 | Val Loss: 0.113664, Val Acc: 0.773196\n",
      "Epoch 21397 - Train Loss: 0.083595, Train Acc: 0.869231 | Val Loss: 0.113663, Val Acc: 0.773196\n",
      "Epoch 21398 - Train Loss: 0.083593, Train Acc: 0.869231 | Val Loss: 0.113662, Val Acc: 0.773196\n",
      "Epoch 21399 - Train Loss: 0.083591, Train Acc: 0.869231 | Val Loss: 0.113661, Val Acc: 0.773196\n",
      "Epoch 21400 - Train Loss: 0.083589, Train Acc: 0.869231 | Val Loss: 0.113661, Val Acc: 0.773196\n",
      "Epoch 21401 - Train Loss: 0.083587, Train Acc: 0.869231 | Val Loss: 0.113660, Val Acc: 0.773196\n",
      "Epoch 21402 - Train Loss: 0.083585, Train Acc: 0.869231 | Val Loss: 0.113659, Val Acc: 0.773196\n",
      "Epoch 21403 - Train Loss: 0.083583, Train Acc: 0.869231 | Val Loss: 0.113658, Val Acc: 0.773196\n",
      "Epoch 21404 - Train Loss: 0.083581, Train Acc: 0.869231 | Val Loss: 0.113657, Val Acc: 0.773196\n",
      "Epoch 21405 - Train Loss: 0.083579, Train Acc: 0.869231 | Val Loss: 0.113656, Val Acc: 0.773196\n",
      "Epoch 21406 - Train Loss: 0.083577, Train Acc: 0.869231 | Val Loss: 0.113655, Val Acc: 0.773196\n",
      "Epoch 21407 - Train Loss: 0.083575, Train Acc: 0.869231 | Val Loss: 0.113655, Val Acc: 0.773196\n",
      "Epoch 21408 - Train Loss: 0.083573, Train Acc: 0.869231 | Val Loss: 0.113654, Val Acc: 0.773196\n",
      "Epoch 21409 - Train Loss: 0.083571, Train Acc: 0.869231 | Val Loss: 0.113653, Val Acc: 0.773196\n",
      "Epoch 21410 - Train Loss: 0.083569, Train Acc: 0.869231 | Val Loss: 0.113652, Val Acc: 0.773196\n",
      "Epoch 21411 - Train Loss: 0.083567, Train Acc: 0.869231 | Val Loss: 0.113651, Val Acc: 0.773196\n",
      "Epoch 21412 - Train Loss: 0.083565, Train Acc: 0.869231 | Val Loss: 0.113650, Val Acc: 0.773196\n",
      "Epoch 21413 - Train Loss: 0.083563, Train Acc: 0.869231 | Val Loss: 0.113649, Val Acc: 0.773196\n",
      "Epoch 21414 - Train Loss: 0.083561, Train Acc: 0.869231 | Val Loss: 0.113649, Val Acc: 0.773196\n",
      "Epoch 21415 - Train Loss: 0.083559, Train Acc: 0.869231 | Val Loss: 0.113648, Val Acc: 0.773196\n",
      "Epoch 21416 - Train Loss: 0.083557, Train Acc: 0.869231 | Val Loss: 0.113647, Val Acc: 0.773196\n",
      "Epoch 21417 - Train Loss: 0.083555, Train Acc: 0.869231 | Val Loss: 0.113646, Val Acc: 0.773196\n",
      "Epoch 21418 - Train Loss: 0.083553, Train Acc: 0.869231 | Val Loss: 0.113645, Val Acc: 0.773196\n",
      "Epoch 21419 - Train Loss: 0.083551, Train Acc: 0.869231 | Val Loss: 0.113644, Val Acc: 0.773196\n",
      "Epoch 21420 - Train Loss: 0.083549, Train Acc: 0.869231 | Val Loss: 0.113643, Val Acc: 0.773196\n",
      "Epoch 21421 - Train Loss: 0.083547, Train Acc: 0.869231 | Val Loss: 0.113642, Val Acc: 0.773196\n",
      "Epoch 21422 - Train Loss: 0.083545, Train Acc: 0.869231 | Val Loss: 0.113642, Val Acc: 0.773196\n",
      "Epoch 21423 - Train Loss: 0.083543, Train Acc: 0.869231 | Val Loss: 0.113641, Val Acc: 0.773196\n",
      "Epoch 21424 - Train Loss: 0.083541, Train Acc: 0.869231 | Val Loss: 0.113640, Val Acc: 0.773196\n",
      "Epoch 21425 - Train Loss: 0.083539, Train Acc: 0.869231 | Val Loss: 0.113639, Val Acc: 0.773196\n",
      "Epoch 21426 - Train Loss: 0.083537, Train Acc: 0.869231 | Val Loss: 0.113638, Val Acc: 0.773196\n",
      "Epoch 21427 - Train Loss: 0.083535, Train Acc: 0.869231 | Val Loss: 0.113637, Val Acc: 0.773196\n",
      "Epoch 21428 - Train Loss: 0.083533, Train Acc: 0.869231 | Val Loss: 0.113636, Val Acc: 0.773196\n",
      "Epoch 21429 - Train Loss: 0.083531, Train Acc: 0.869231 | Val Loss: 0.113636, Val Acc: 0.773196\n",
      "Epoch 21430 - Train Loss: 0.083529, Train Acc: 0.869231 | Val Loss: 0.113635, Val Acc: 0.773196\n",
      "Epoch 21431 - Train Loss: 0.083527, Train Acc: 0.869231 | Val Loss: 0.113634, Val Acc: 0.773196\n",
      "Epoch 21432 - Train Loss: 0.083525, Train Acc: 0.869231 | Val Loss: 0.113633, Val Acc: 0.773196\n",
      "Epoch 21433 - Train Loss: 0.083523, Train Acc: 0.869231 | Val Loss: 0.113632, Val Acc: 0.773196\n",
      "Epoch 21434 - Train Loss: 0.083521, Train Acc: 0.869231 | Val Loss: 0.113631, Val Acc: 0.773196\n",
      "Epoch 21435 - Train Loss: 0.083519, Train Acc: 0.869231 | Val Loss: 0.113630, Val Acc: 0.773196\n",
      "Epoch 21436 - Train Loss: 0.083517, Train Acc: 0.869231 | Val Loss: 0.113630, Val Acc: 0.773196\n",
      "Epoch 21437 - Train Loss: 0.083515, Train Acc: 0.869231 | Val Loss: 0.113629, Val Acc: 0.773196\n",
      "Epoch 21438 - Train Loss: 0.083513, Train Acc: 0.869231 | Val Loss: 0.113628, Val Acc: 0.773196\n",
      "Epoch 21439 - Train Loss: 0.083511, Train Acc: 0.869231 | Val Loss: 0.113627, Val Acc: 0.773196\n",
      "Epoch 21440 - Train Loss: 0.083509, Train Acc: 0.869231 | Val Loss: 0.113626, Val Acc: 0.773196\n",
      "Epoch 21441 - Train Loss: 0.083507, Train Acc: 0.869231 | Val Loss: 0.113625, Val Acc: 0.773196\n",
      "Epoch 21442 - Train Loss: 0.083505, Train Acc: 0.869231 | Val Loss: 0.113624, Val Acc: 0.773196\n",
      "Epoch 21443 - Train Loss: 0.083503, Train Acc: 0.869231 | Val Loss: 0.113624, Val Acc: 0.773196\n",
      "Epoch 21444 - Train Loss: 0.083501, Train Acc: 0.869231 | Val Loss: 0.113623, Val Acc: 0.773196\n",
      "Epoch 21445 - Train Loss: 0.083499, Train Acc: 0.869231 | Val Loss: 0.113622, Val Acc: 0.773196\n",
      "Epoch 21446 - Train Loss: 0.083497, Train Acc: 0.869231 | Val Loss: 0.113621, Val Acc: 0.773196\n",
      "Epoch 21447 - Train Loss: 0.083495, Train Acc: 0.869231 | Val Loss: 0.113620, Val Acc: 0.773196\n",
      "Epoch 21448 - Train Loss: 0.083493, Train Acc: 0.869231 | Val Loss: 0.113619, Val Acc: 0.773196\n",
      "Epoch 21449 - Train Loss: 0.083491, Train Acc: 0.869231 | Val Loss: 0.113618, Val Acc: 0.773196\n",
      "Epoch 21450 - Train Loss: 0.083489, Train Acc: 0.869231 | Val Loss: 0.113618, Val Acc: 0.773196\n",
      "Epoch 21451 - Train Loss: 0.083487, Train Acc: 0.869231 | Val Loss: 0.113617, Val Acc: 0.773196\n",
      "Epoch 21452 - Train Loss: 0.083485, Train Acc: 0.869231 | Val Loss: 0.113616, Val Acc: 0.773196\n",
      "Epoch 21453 - Train Loss: 0.083483, Train Acc: 0.869231 | Val Loss: 0.113615, Val Acc: 0.773196\n",
      "Epoch 21454 - Train Loss: 0.083481, Train Acc: 0.869231 | Val Loss: 0.113614, Val Acc: 0.773196\n",
      "Epoch 21455 - Train Loss: 0.083479, Train Acc: 0.869231 | Val Loss: 0.113613, Val Acc: 0.773196\n",
      "Epoch 21456 - Train Loss: 0.083477, Train Acc: 0.869231 | Val Loss: 0.113612, Val Acc: 0.773196\n",
      "Epoch 21457 - Train Loss: 0.083475, Train Acc: 0.869231 | Val Loss: 0.113612, Val Acc: 0.773196\n",
      "Epoch 21458 - Train Loss: 0.083473, Train Acc: 0.869231 | Val Loss: 0.113611, Val Acc: 0.773196\n",
      "Epoch 21459 - Train Loss: 0.083471, Train Acc: 0.869231 | Val Loss: 0.113610, Val Acc: 0.773196\n",
      "Epoch 21460 - Train Loss: 0.083469, Train Acc: 0.869231 | Val Loss: 0.113609, Val Acc: 0.773196\n",
      "Epoch 21461 - Train Loss: 0.083467, Train Acc: 0.869231 | Val Loss: 0.113608, Val Acc: 0.773196\n",
      "Epoch 21462 - Train Loss: 0.083465, Train Acc: 0.869231 | Val Loss: 0.113607, Val Acc: 0.773196\n",
      "Epoch 21463 - Train Loss: 0.083463, Train Acc: 0.869231 | Val Loss: 0.113606, Val Acc: 0.773196\n",
      "Epoch 21464 - Train Loss: 0.083461, Train Acc: 0.869231 | Val Loss: 0.113606, Val Acc: 0.773196\n",
      "Epoch 21465 - Train Loss: 0.083459, Train Acc: 0.869231 | Val Loss: 0.113605, Val Acc: 0.773196\n",
      "Epoch 21466 - Train Loss: 0.083457, Train Acc: 0.869231 | Val Loss: 0.113604, Val Acc: 0.773196\n",
      "Epoch 21467 - Train Loss: 0.083455, Train Acc: 0.869231 | Val Loss: 0.113603, Val Acc: 0.773196\n",
      "Epoch 21468 - Train Loss: 0.083453, Train Acc: 0.869231 | Val Loss: 0.113602, Val Acc: 0.773196\n",
      "Epoch 21469 - Train Loss: 0.083451, Train Acc: 0.869231 | Val Loss: 0.113601, Val Acc: 0.773196\n",
      "Epoch 21470 - Train Loss: 0.083449, Train Acc: 0.869231 | Val Loss: 0.113600, Val Acc: 0.773196\n",
      "Epoch 21471 - Train Loss: 0.083447, Train Acc: 0.869231 | Val Loss: 0.113600, Val Acc: 0.773196\n",
      "Epoch 21472 - Train Loss: 0.083445, Train Acc: 0.869231 | Val Loss: 0.113599, Val Acc: 0.773196\n",
      "Epoch 21473 - Train Loss: 0.083443, Train Acc: 0.869231 | Val Loss: 0.113598, Val Acc: 0.773196\n",
      "Epoch 21474 - Train Loss: 0.083441, Train Acc: 0.869231 | Val Loss: 0.113597, Val Acc: 0.773196\n",
      "Epoch 21475 - Train Loss: 0.083439, Train Acc: 0.869231 | Val Loss: 0.113596, Val Acc: 0.773196\n",
      "Epoch 21476 - Train Loss: 0.083437, Train Acc: 0.869231 | Val Loss: 0.113595, Val Acc: 0.773196\n",
      "Epoch 21477 - Train Loss: 0.083435, Train Acc: 0.869231 | Val Loss: 0.113594, Val Acc: 0.773196\n",
      "Epoch 21478 - Train Loss: 0.083433, Train Acc: 0.869231 | Val Loss: 0.113594, Val Acc: 0.773196\n",
      "Epoch 21479 - Train Loss: 0.083431, Train Acc: 0.869231 | Val Loss: 0.113593, Val Acc: 0.773196\n",
      "Epoch 21480 - Train Loss: 0.083429, Train Acc: 0.869231 | Val Loss: 0.113592, Val Acc: 0.773196\n",
      "Epoch 21481 - Train Loss: 0.083427, Train Acc: 0.869231 | Val Loss: 0.113591, Val Acc: 0.773196\n",
      "Epoch 21482 - Train Loss: 0.083425, Train Acc: 0.869231 | Val Loss: 0.113590, Val Acc: 0.773196\n",
      "Epoch 21483 - Train Loss: 0.083424, Train Acc: 0.869231 | Val Loss: 0.113589, Val Acc: 0.773196\n",
      "Epoch 21484 - Train Loss: 0.083422, Train Acc: 0.869231 | Val Loss: 0.113588, Val Acc: 0.773196\n",
      "Epoch 21485 - Train Loss: 0.083420, Train Acc: 0.869231 | Val Loss: 0.113588, Val Acc: 0.773196\n",
      "Epoch 21486 - Train Loss: 0.083418, Train Acc: 0.869231 | Val Loss: 0.113587, Val Acc: 0.773196\n",
      "Epoch 21487 - Train Loss: 0.083416, Train Acc: 0.869231 | Val Loss: 0.113586, Val Acc: 0.773196\n",
      "Epoch 21488 - Train Loss: 0.083414, Train Acc: 0.869231 | Val Loss: 0.113585, Val Acc: 0.773196\n",
      "Epoch 21489 - Train Loss: 0.083412, Train Acc: 0.869231 | Val Loss: 0.113584, Val Acc: 0.773196\n",
      "Epoch 21490 - Train Loss: 0.083410, Train Acc: 0.869231 | Val Loss: 0.113583, Val Acc: 0.773196\n",
      "Epoch 21491 - Train Loss: 0.083408, Train Acc: 0.869231 | Val Loss: 0.113582, Val Acc: 0.773196\n",
      "Epoch 21492 - Train Loss: 0.083406, Train Acc: 0.869231 | Val Loss: 0.113582, Val Acc: 0.773196\n",
      "Epoch 21493 - Train Loss: 0.083404, Train Acc: 0.869231 | Val Loss: 0.113581, Val Acc: 0.773196\n",
      "Epoch 21494 - Train Loss: 0.083402, Train Acc: 0.869231 | Val Loss: 0.113580, Val Acc: 0.773196\n",
      "Epoch 21495 - Train Loss: 0.083400, Train Acc: 0.869231 | Val Loss: 0.113579, Val Acc: 0.773196\n",
      "Epoch 21496 - Train Loss: 0.083398, Train Acc: 0.869231 | Val Loss: 0.113578, Val Acc: 0.773196\n",
      "Epoch 21497 - Train Loss: 0.083396, Train Acc: 0.869231 | Val Loss: 0.113577, Val Acc: 0.773196\n",
      "Epoch 21498 - Train Loss: 0.083394, Train Acc: 0.869231 | Val Loss: 0.113576, Val Acc: 0.773196\n",
      "Epoch 21499 - Train Loss: 0.083392, Train Acc: 0.869231 | Val Loss: 0.113576, Val Acc: 0.773196\n",
      "Epoch 21500 - Train Loss: 0.083390, Train Acc: 0.869231 | Val Loss: 0.113575, Val Acc: 0.773196\n",
      "Epoch 21501 - Train Loss: 0.083388, Train Acc: 0.869231 | Val Loss: 0.113574, Val Acc: 0.773196\n",
      "Epoch 21502 - Train Loss: 0.083386, Train Acc: 0.869231 | Val Loss: 0.113573, Val Acc: 0.773196\n",
      "Epoch 21503 - Train Loss: 0.083384, Train Acc: 0.869231 | Val Loss: 0.113572, Val Acc: 0.773196\n",
      "Epoch 21504 - Train Loss: 0.083382, Train Acc: 0.869231 | Val Loss: 0.113571, Val Acc: 0.773196\n",
      "Epoch 21505 - Train Loss: 0.083380, Train Acc: 0.869231 | Val Loss: 0.113571, Val Acc: 0.773196\n",
      "Epoch 21506 - Train Loss: 0.083378, Train Acc: 0.869231 | Val Loss: 0.113570, Val Acc: 0.773196\n",
      "Epoch 21507 - Train Loss: 0.083376, Train Acc: 0.869231 | Val Loss: 0.113569, Val Acc: 0.773196\n",
      "Epoch 21508 - Train Loss: 0.083374, Train Acc: 0.869231 | Val Loss: 0.113568, Val Acc: 0.773196\n",
      "Epoch 21509 - Train Loss: 0.083372, Train Acc: 0.869231 | Val Loss: 0.113567, Val Acc: 0.773196\n",
      "Epoch 21510 - Train Loss: 0.083370, Train Acc: 0.869231 | Val Loss: 0.113566, Val Acc: 0.773196\n",
      "Epoch 21511 - Train Loss: 0.083368, Train Acc: 0.869231 | Val Loss: 0.113565, Val Acc: 0.773196\n",
      "Epoch 21512 - Train Loss: 0.083366, Train Acc: 0.869231 | Val Loss: 0.113565, Val Acc: 0.773196\n",
      "Epoch 21513 - Train Loss: 0.083364, Train Acc: 0.869231 | Val Loss: 0.113564, Val Acc: 0.773196\n",
      "Epoch 21514 - Train Loss: 0.083362, Train Acc: 0.869231 | Val Loss: 0.113563, Val Acc: 0.773196\n",
      "Epoch 21515 - Train Loss: 0.083360, Train Acc: 0.869231 | Val Loss: 0.113562, Val Acc: 0.773196\n",
      "Epoch 21516 - Train Loss: 0.083358, Train Acc: 0.869231 | Val Loss: 0.113561, Val Acc: 0.773196\n",
      "Epoch 21517 - Train Loss: 0.083356, Train Acc: 0.869231 | Val Loss: 0.113560, Val Acc: 0.773196\n",
      "Epoch 21518 - Train Loss: 0.083354, Train Acc: 0.869231 | Val Loss: 0.113559, Val Acc: 0.773196\n",
      "Epoch 21519 - Train Loss: 0.083352, Train Acc: 0.869231 | Val Loss: 0.113559, Val Acc: 0.773196\n",
      "Epoch 21520 - Train Loss: 0.083350, Train Acc: 0.869231 | Val Loss: 0.113558, Val Acc: 0.773196\n",
      "Epoch 21521 - Train Loss: 0.083348, Train Acc: 0.869231 | Val Loss: 0.113557, Val Acc: 0.773196\n",
      "Epoch 21522 - Train Loss: 0.083346, Train Acc: 0.869231 | Val Loss: 0.113556, Val Acc: 0.773196\n",
      "Epoch 21523 - Train Loss: 0.083344, Train Acc: 0.869231 | Val Loss: 0.113555, Val Acc: 0.773196\n",
      "Epoch 21524 - Train Loss: 0.083342, Train Acc: 0.869231 | Val Loss: 0.113554, Val Acc: 0.773196\n",
      "Epoch 21525 - Train Loss: 0.083340, Train Acc: 0.869231 | Val Loss: 0.113554, Val Acc: 0.773196\n",
      "Epoch 21526 - Train Loss: 0.083338, Train Acc: 0.869231 | Val Loss: 0.113553, Val Acc: 0.773196\n",
      "Epoch 21527 - Train Loss: 0.083336, Train Acc: 0.869231 | Val Loss: 0.113552, Val Acc: 0.773196\n",
      "Epoch 21528 - Train Loss: 0.083334, Train Acc: 0.869231 | Val Loss: 0.113551, Val Acc: 0.773196\n",
      "Epoch 21529 - Train Loss: 0.083332, Train Acc: 0.869231 | Val Loss: 0.113550, Val Acc: 0.773196\n",
      "Epoch 21530 - Train Loss: 0.083330, Train Acc: 0.869231 | Val Loss: 0.113549, Val Acc: 0.773196\n",
      "Epoch 21531 - Train Loss: 0.083328, Train Acc: 0.869231 | Val Loss: 0.113548, Val Acc: 0.773196\n",
      "Epoch 21532 - Train Loss: 0.083326, Train Acc: 0.869231 | Val Loss: 0.113548, Val Acc: 0.773196\n",
      "Epoch 21533 - Train Loss: 0.083324, Train Acc: 0.869231 | Val Loss: 0.113547, Val Acc: 0.773196\n",
      "Epoch 21534 - Train Loss: 0.083322, Train Acc: 0.869231 | Val Loss: 0.113546, Val Acc: 0.773196\n",
      "Epoch 21535 - Train Loss: 0.083320, Train Acc: 0.869231 | Val Loss: 0.113545, Val Acc: 0.773196\n",
      "Epoch 21536 - Train Loss: 0.083318, Train Acc: 0.869231 | Val Loss: 0.113544, Val Acc: 0.773196\n",
      "Epoch 21537 - Train Loss: 0.083316, Train Acc: 0.869231 | Val Loss: 0.113543, Val Acc: 0.773196\n",
      "Epoch 21538 - Train Loss: 0.083314, Train Acc: 0.869231 | Val Loss: 0.113542, Val Acc: 0.773196\n",
      "Epoch 21539 - Train Loss: 0.083312, Train Acc: 0.869231 | Val Loss: 0.113542, Val Acc: 0.773196\n",
      "Epoch 21540 - Train Loss: 0.083310, Train Acc: 0.869231 | Val Loss: 0.113541, Val Acc: 0.773196\n",
      "Epoch 21541 - Train Loss: 0.083308, Train Acc: 0.869231 | Val Loss: 0.113540, Val Acc: 0.773196\n",
      "Epoch 21542 - Train Loss: 0.083306, Train Acc: 0.869231 | Val Loss: 0.113539, Val Acc: 0.773196\n",
      "Epoch 21543 - Train Loss: 0.083304, Train Acc: 0.869231 | Val Loss: 0.113538, Val Acc: 0.773196\n",
      "Epoch 21544 - Train Loss: 0.083302, Train Acc: 0.869231 | Val Loss: 0.113537, Val Acc: 0.773196\n",
      "Epoch 21545 - Train Loss: 0.083300, Train Acc: 0.869231 | Val Loss: 0.113537, Val Acc: 0.773196\n",
      "Epoch 21546 - Train Loss: 0.083298, Train Acc: 0.869231 | Val Loss: 0.113536, Val Acc: 0.773196\n",
      "Epoch 21547 - Train Loss: 0.083296, Train Acc: 0.869231 | Val Loss: 0.113535, Val Acc: 0.773196\n",
      "Epoch 21548 - Train Loss: 0.083294, Train Acc: 0.869231 | Val Loss: 0.113534, Val Acc: 0.773196\n",
      "Epoch 21549 - Train Loss: 0.083292, Train Acc: 0.869231 | Val Loss: 0.113533, Val Acc: 0.773196\n",
      "Epoch 21550 - Train Loss: 0.083290, Train Acc: 0.869231 | Val Loss: 0.113532, Val Acc: 0.773196\n",
      "Epoch 21551 - Train Loss: 0.083288, Train Acc: 0.869231 | Val Loss: 0.113531, Val Acc: 0.773196\n",
      "Epoch 21552 - Train Loss: 0.083286, Train Acc: 0.869231 | Val Loss: 0.113531, Val Acc: 0.773196\n",
      "Epoch 21553 - Train Loss: 0.083284, Train Acc: 0.869231 | Val Loss: 0.113530, Val Acc: 0.773196\n",
      "Epoch 21554 - Train Loss: 0.083282, Train Acc: 0.869231 | Val Loss: 0.113529, Val Acc: 0.773196\n",
      "Epoch 21555 - Train Loss: 0.083280, Train Acc: 0.869231 | Val Loss: 0.113528, Val Acc: 0.773196\n",
      "Epoch 21556 - Train Loss: 0.083278, Train Acc: 0.869231 | Val Loss: 0.113527, Val Acc: 0.773196\n",
      "Epoch 21557 - Train Loss: 0.083276, Train Acc: 0.869231 | Val Loss: 0.113526, Val Acc: 0.773196\n",
      "Epoch 21558 - Train Loss: 0.083274, Train Acc: 0.869231 | Val Loss: 0.113526, Val Acc: 0.773196\n",
      "Epoch 21559 - Train Loss: 0.083272, Train Acc: 0.869231 | Val Loss: 0.113525, Val Acc: 0.773196\n",
      "Epoch 21560 - Train Loss: 0.083270, Train Acc: 0.869231 | Val Loss: 0.113524, Val Acc: 0.773196\n",
      "Epoch 21561 - Train Loss: 0.083268, Train Acc: 0.869231 | Val Loss: 0.113523, Val Acc: 0.773196\n",
      "Epoch 21562 - Train Loss: 0.083267, Train Acc: 0.869231 | Val Loss: 0.113522, Val Acc: 0.773196\n",
      "Epoch 21563 - Train Loss: 0.083265, Train Acc: 0.869231 | Val Loss: 0.113521, Val Acc: 0.773196\n",
      "Epoch 21564 - Train Loss: 0.083263, Train Acc: 0.869231 | Val Loss: 0.113521, Val Acc: 0.773196\n",
      "Epoch 21565 - Train Loss: 0.083261, Train Acc: 0.869231 | Val Loss: 0.113520, Val Acc: 0.773196\n",
      "Epoch 21566 - Train Loss: 0.083259, Train Acc: 0.869231 | Val Loss: 0.113519, Val Acc: 0.773196\n",
      "Epoch 21567 - Train Loss: 0.083257, Train Acc: 0.869231 | Val Loss: 0.113518, Val Acc: 0.773196\n",
      "Epoch 21568 - Train Loss: 0.083255, Train Acc: 0.869231 | Val Loss: 0.113517, Val Acc: 0.773196\n",
      "Epoch 21569 - Train Loss: 0.083253, Train Acc: 0.869231 | Val Loss: 0.113516, Val Acc: 0.773196\n",
      "Epoch 21570 - Train Loss: 0.083251, Train Acc: 0.869231 | Val Loss: 0.113515, Val Acc: 0.773196\n",
      "Epoch 21571 - Train Loss: 0.083249, Train Acc: 0.869231 | Val Loss: 0.113515, Val Acc: 0.773196\n",
      "Epoch 21572 - Train Loss: 0.083247, Train Acc: 0.869231 | Val Loss: 0.113514, Val Acc: 0.773196\n",
      "Epoch 21573 - Train Loss: 0.083245, Train Acc: 0.869231 | Val Loss: 0.113513, Val Acc: 0.773196\n",
      "Epoch 21574 - Train Loss: 0.083243, Train Acc: 0.869231 | Val Loss: 0.113512, Val Acc: 0.773196\n",
      "Epoch 21575 - Train Loss: 0.083241, Train Acc: 0.869231 | Val Loss: 0.113511, Val Acc: 0.773196\n",
      "Epoch 21576 - Train Loss: 0.083239, Train Acc: 0.869231 | Val Loss: 0.113510, Val Acc: 0.773196\n",
      "Epoch 21577 - Train Loss: 0.083237, Train Acc: 0.869231 | Val Loss: 0.113510, Val Acc: 0.773196\n",
      "Epoch 21578 - Train Loss: 0.083235, Train Acc: 0.869231 | Val Loss: 0.113509, Val Acc: 0.773196\n",
      "Epoch 21579 - Train Loss: 0.083233, Train Acc: 0.869231 | Val Loss: 0.113508, Val Acc: 0.773196\n",
      "Epoch 21580 - Train Loss: 0.083231, Train Acc: 0.869231 | Val Loss: 0.113507, Val Acc: 0.773196\n",
      "Epoch 21581 - Train Loss: 0.083229, Train Acc: 0.869231 | Val Loss: 0.113506, Val Acc: 0.773196\n",
      "Epoch 21582 - Train Loss: 0.083227, Train Acc: 0.869231 | Val Loss: 0.113505, Val Acc: 0.773196\n",
      "Epoch 21583 - Train Loss: 0.083225, Train Acc: 0.869231 | Val Loss: 0.113505, Val Acc: 0.773196\n",
      "Epoch 21584 - Train Loss: 0.083223, Train Acc: 0.869231 | Val Loss: 0.113504, Val Acc: 0.773196\n",
      "Epoch 21585 - Train Loss: 0.083221, Train Acc: 0.869231 | Val Loss: 0.113503, Val Acc: 0.773196\n",
      "Epoch 21586 - Train Loss: 0.083219, Train Acc: 0.869231 | Val Loss: 0.113502, Val Acc: 0.773196\n",
      "Epoch 21587 - Train Loss: 0.083217, Train Acc: 0.869231 | Val Loss: 0.113501, Val Acc: 0.773196\n",
      "Epoch 21588 - Train Loss: 0.083215, Train Acc: 0.869231 | Val Loss: 0.113500, Val Acc: 0.773196\n",
      "Epoch 21589 - Train Loss: 0.083213, Train Acc: 0.869231 | Val Loss: 0.113499, Val Acc: 0.773196\n",
      "Epoch 21590 - Train Loss: 0.083211, Train Acc: 0.869231 | Val Loss: 0.113499, Val Acc: 0.773196\n",
      "Epoch 21591 - Train Loss: 0.083209, Train Acc: 0.869231 | Val Loss: 0.113498, Val Acc: 0.773196\n",
      "Epoch 21592 - Train Loss: 0.083207, Train Acc: 0.869231 | Val Loss: 0.113497, Val Acc: 0.773196\n",
      "Epoch 21593 - Train Loss: 0.083205, Train Acc: 0.869231 | Val Loss: 0.113496, Val Acc: 0.773196\n",
      "Epoch 21594 - Train Loss: 0.083203, Train Acc: 0.869231 | Val Loss: 0.113495, Val Acc: 0.773196\n",
      "Epoch 21595 - Train Loss: 0.083201, Train Acc: 0.869231 | Val Loss: 0.113494, Val Acc: 0.773196\n",
      "Epoch 21596 - Train Loss: 0.083199, Train Acc: 0.869231 | Val Loss: 0.113494, Val Acc: 0.773196\n",
      "Epoch 21597 - Train Loss: 0.083197, Train Acc: 0.869231 | Val Loss: 0.113493, Val Acc: 0.773196\n",
      "Epoch 21598 - Train Loss: 0.083195, Train Acc: 0.869231 | Val Loss: 0.113492, Val Acc: 0.773196\n",
      "Epoch 21599 - Train Loss: 0.083193, Train Acc: 0.869231 | Val Loss: 0.113491, Val Acc: 0.773196\n",
      "Epoch 21600 - Train Loss: 0.083191, Train Acc: 0.869231 | Val Loss: 0.113490, Val Acc: 0.773196\n",
      "Epoch 21601 - Train Loss: 0.083189, Train Acc: 0.869231 | Val Loss: 0.113489, Val Acc: 0.773196\n",
      "Epoch 21602 - Train Loss: 0.083187, Train Acc: 0.869231 | Val Loss: 0.113489, Val Acc: 0.773196\n",
      "Epoch 21603 - Train Loss: 0.083185, Train Acc: 0.869231 | Val Loss: 0.113488, Val Acc: 0.773196\n",
      "Epoch 21604 - Train Loss: 0.083183, Train Acc: 0.869231 | Val Loss: 0.113487, Val Acc: 0.773196\n",
      "Epoch 21605 - Train Loss: 0.083181, Train Acc: 0.869231 | Val Loss: 0.113486, Val Acc: 0.773196\n",
      "Epoch 21606 - Train Loss: 0.083179, Train Acc: 0.869231 | Val Loss: 0.113485, Val Acc: 0.773196\n",
      "Epoch 21607 - Train Loss: 0.083178, Train Acc: 0.869231 | Val Loss: 0.113484, Val Acc: 0.773196\n",
      "Epoch 21608 - Train Loss: 0.083176, Train Acc: 0.869231 | Val Loss: 0.113484, Val Acc: 0.773196\n",
      "Epoch 21609 - Train Loss: 0.083174, Train Acc: 0.869231 | Val Loss: 0.113483, Val Acc: 0.773196\n",
      "Epoch 21610 - Train Loss: 0.083172, Train Acc: 0.869231 | Val Loss: 0.113482, Val Acc: 0.773196\n",
      "Epoch 21611 - Train Loss: 0.083170, Train Acc: 0.869231 | Val Loss: 0.113481, Val Acc: 0.773196\n",
      "Epoch 21612 - Train Loss: 0.083168, Train Acc: 0.869231 | Val Loss: 0.113480, Val Acc: 0.773196\n",
      "Epoch 21613 - Train Loss: 0.083166, Train Acc: 0.869231 | Val Loss: 0.113479, Val Acc: 0.773196\n",
      "Epoch 21614 - Train Loss: 0.083164, Train Acc: 0.869231 | Val Loss: 0.113478, Val Acc: 0.773196\n",
      "Epoch 21615 - Train Loss: 0.083162, Train Acc: 0.869231 | Val Loss: 0.113478, Val Acc: 0.773196\n",
      "Epoch 21616 - Train Loss: 0.083160, Train Acc: 0.869231 | Val Loss: 0.113477, Val Acc: 0.773196\n",
      "Epoch 21617 - Train Loss: 0.083158, Train Acc: 0.869231 | Val Loss: 0.113476, Val Acc: 0.773196\n",
      "Epoch 21618 - Train Loss: 0.083156, Train Acc: 0.869231 | Val Loss: 0.113475, Val Acc: 0.773196\n",
      "Epoch 21619 - Train Loss: 0.083154, Train Acc: 0.869231 | Val Loss: 0.113474, Val Acc: 0.773196\n",
      "Epoch 21620 - Train Loss: 0.083152, Train Acc: 0.869231 | Val Loss: 0.113473, Val Acc: 0.773196\n",
      "Epoch 21621 - Train Loss: 0.083150, Train Acc: 0.869231 | Val Loss: 0.113473, Val Acc: 0.773196\n",
      "Epoch 21622 - Train Loss: 0.083148, Train Acc: 0.869231 | Val Loss: 0.113472, Val Acc: 0.773196\n",
      "Epoch 21623 - Train Loss: 0.083146, Train Acc: 0.869231 | Val Loss: 0.113471, Val Acc: 0.773196\n",
      "Epoch 21624 - Train Loss: 0.083144, Train Acc: 0.869231 | Val Loss: 0.113470, Val Acc: 0.773196\n",
      "Epoch 21625 - Train Loss: 0.083142, Train Acc: 0.869231 | Val Loss: 0.113469, Val Acc: 0.773196\n",
      "Epoch 21626 - Train Loss: 0.083140, Train Acc: 0.869231 | Val Loss: 0.113468, Val Acc: 0.773196\n",
      "Epoch 21627 - Train Loss: 0.083138, Train Acc: 0.869231 | Val Loss: 0.113468, Val Acc: 0.773196\n",
      "Epoch 21628 - Train Loss: 0.083136, Train Acc: 0.869231 | Val Loss: 0.113467, Val Acc: 0.773196\n",
      "Epoch 21629 - Train Loss: 0.083134, Train Acc: 0.869231 | Val Loss: 0.113466, Val Acc: 0.773196\n",
      "Epoch 21630 - Train Loss: 0.083132, Train Acc: 0.869231 | Val Loss: 0.113465, Val Acc: 0.773196\n",
      "Epoch 21631 - Train Loss: 0.083130, Train Acc: 0.869231 | Val Loss: 0.113464, Val Acc: 0.773196\n",
      "Epoch 21632 - Train Loss: 0.083128, Train Acc: 0.869231 | Val Loss: 0.113463, Val Acc: 0.773196\n",
      "Epoch 21633 - Train Loss: 0.083126, Train Acc: 0.869231 | Val Loss: 0.113463, Val Acc: 0.773196\n",
      "Epoch 21634 - Train Loss: 0.083124, Train Acc: 0.869231 | Val Loss: 0.113462, Val Acc: 0.773196\n",
      "Epoch 21635 - Train Loss: 0.083122, Train Acc: 0.869231 | Val Loss: 0.113461, Val Acc: 0.773196\n",
      "Epoch 21636 - Train Loss: 0.083120, Train Acc: 0.869231 | Val Loss: 0.113460, Val Acc: 0.773196\n",
      "Epoch 21637 - Train Loss: 0.083118, Train Acc: 0.869231 | Val Loss: 0.113459, Val Acc: 0.773196\n",
      "Epoch 21638 - Train Loss: 0.083116, Train Acc: 0.869231 | Val Loss: 0.113458, Val Acc: 0.773196\n",
      "Epoch 21639 - Train Loss: 0.083114, Train Acc: 0.869231 | Val Loss: 0.113458, Val Acc: 0.773196\n",
      "Epoch 21640 - Train Loss: 0.083112, Train Acc: 0.869231 | Val Loss: 0.113457, Val Acc: 0.773196\n",
      "Epoch 21641 - Train Loss: 0.083110, Train Acc: 0.869231 | Val Loss: 0.113456, Val Acc: 0.773196\n",
      "Epoch 21642 - Train Loss: 0.083108, Train Acc: 0.869231 | Val Loss: 0.113455, Val Acc: 0.773196\n",
      "Epoch 21643 - Train Loss: 0.083107, Train Acc: 0.869231 | Val Loss: 0.113454, Val Acc: 0.773196\n",
      "Epoch 21644 - Train Loss: 0.083105, Train Acc: 0.869231 | Val Loss: 0.113453, Val Acc: 0.773196\n",
      "Epoch 21645 - Train Loss: 0.083103, Train Acc: 0.869231 | Val Loss: 0.113453, Val Acc: 0.773196\n",
      "Epoch 21646 - Train Loss: 0.083101, Train Acc: 0.869231 | Val Loss: 0.113452, Val Acc: 0.773196\n",
      "Epoch 21647 - Train Loss: 0.083099, Train Acc: 0.869231 | Val Loss: 0.113451, Val Acc: 0.773196\n",
      "Epoch 21648 - Train Loss: 0.083097, Train Acc: 0.869231 | Val Loss: 0.113450, Val Acc: 0.773196\n",
      "Epoch 21649 - Train Loss: 0.083095, Train Acc: 0.869231 | Val Loss: 0.113449, Val Acc: 0.773196\n",
      "Epoch 21650 - Train Loss: 0.083093, Train Acc: 0.869231 | Val Loss: 0.113448, Val Acc: 0.773196\n",
      "Epoch 21651 - Train Loss: 0.083091, Train Acc: 0.869231 | Val Loss: 0.113448, Val Acc: 0.773196\n",
      "Epoch 21652 - Train Loss: 0.083089, Train Acc: 0.869231 | Val Loss: 0.113447, Val Acc: 0.773196\n",
      "Epoch 21653 - Train Loss: 0.083087, Train Acc: 0.869231 | Val Loss: 0.113446, Val Acc: 0.773196\n",
      "Epoch 21654 - Train Loss: 0.083085, Train Acc: 0.869231 | Val Loss: 0.113445, Val Acc: 0.773196\n",
      "Epoch 21655 - Train Loss: 0.083083, Train Acc: 0.869231 | Val Loss: 0.113444, Val Acc: 0.773196\n",
      "Epoch 21656 - Train Loss: 0.083081, Train Acc: 0.869231 | Val Loss: 0.113443, Val Acc: 0.773196\n",
      "Epoch 21657 - Train Loss: 0.083079, Train Acc: 0.869231 | Val Loss: 0.113443, Val Acc: 0.773196\n",
      "Epoch 21658 - Train Loss: 0.083077, Train Acc: 0.869231 | Val Loss: 0.113442, Val Acc: 0.773196\n",
      "Epoch 21659 - Train Loss: 0.083075, Train Acc: 0.869231 | Val Loss: 0.113441, Val Acc: 0.773196\n",
      "Epoch 21660 - Train Loss: 0.083073, Train Acc: 0.869231 | Val Loss: 0.113440, Val Acc: 0.773196\n",
      "Epoch 21661 - Train Loss: 0.083071, Train Acc: 0.869231 | Val Loss: 0.113439, Val Acc: 0.773196\n",
      "Epoch 21662 - Train Loss: 0.083069, Train Acc: 0.869231 | Val Loss: 0.113438, Val Acc: 0.773196\n",
      "Epoch 21663 - Train Loss: 0.083067, Train Acc: 0.869231 | Val Loss: 0.113438, Val Acc: 0.773196\n",
      "Epoch 21664 - Train Loss: 0.083065, Train Acc: 0.869231 | Val Loss: 0.113437, Val Acc: 0.773196\n",
      "Epoch 21665 - Train Loss: 0.083063, Train Acc: 0.869231 | Val Loss: 0.113436, Val Acc: 0.773196\n",
      "Epoch 21666 - Train Loss: 0.083061, Train Acc: 0.869231 | Val Loss: 0.113435, Val Acc: 0.773196\n",
      "Epoch 21667 - Train Loss: 0.083059, Train Acc: 0.869231 | Val Loss: 0.113434, Val Acc: 0.773196\n",
      "Epoch 21668 - Train Loss: 0.083057, Train Acc: 0.869231 | Val Loss: 0.113433, Val Acc: 0.773196\n",
      "Epoch 21669 - Train Loss: 0.083055, Train Acc: 0.869231 | Val Loss: 0.113433, Val Acc: 0.773196\n",
      "Epoch 21670 - Train Loss: 0.083053, Train Acc: 0.869231 | Val Loss: 0.113432, Val Acc: 0.773196\n",
      "Epoch 21671 - Train Loss: 0.083051, Train Acc: 0.869231 | Val Loss: 0.113431, Val Acc: 0.773196\n",
      "Epoch 21672 - Train Loss: 0.083049, Train Acc: 0.869231 | Val Loss: 0.113430, Val Acc: 0.773196\n",
      "Epoch 21673 - Train Loss: 0.083047, Train Acc: 0.869231 | Val Loss: 0.113429, Val Acc: 0.773196\n",
      "Epoch 21674 - Train Loss: 0.083046, Train Acc: 0.869231 | Val Loss: 0.113428, Val Acc: 0.773196\n",
      "Epoch 21675 - Train Loss: 0.083044, Train Acc: 0.869231 | Val Loss: 0.113428, Val Acc: 0.773196\n",
      "Epoch 21676 - Train Loss: 0.083042, Train Acc: 0.869231 | Val Loss: 0.113427, Val Acc: 0.773196\n",
      "Epoch 21677 - Train Loss: 0.083040, Train Acc: 0.869231 | Val Loss: 0.113426, Val Acc: 0.773196\n",
      "Epoch 21678 - Train Loss: 0.083038, Train Acc: 0.869231 | Val Loss: 0.113425, Val Acc: 0.773196\n",
      "Epoch 21679 - Train Loss: 0.083036, Train Acc: 0.869231 | Val Loss: 0.113424, Val Acc: 0.773196\n",
      "Epoch 21680 - Train Loss: 0.083034, Train Acc: 0.869231 | Val Loss: 0.113423, Val Acc: 0.773196\n",
      "Epoch 21681 - Train Loss: 0.083032, Train Acc: 0.869231 | Val Loss: 0.113423, Val Acc: 0.773196\n",
      "Epoch 21682 - Train Loss: 0.083030, Train Acc: 0.869231 | Val Loss: 0.113422, Val Acc: 0.773196\n",
      "Epoch 21683 - Train Loss: 0.083028, Train Acc: 0.869231 | Val Loss: 0.113421, Val Acc: 0.773196\n",
      "Epoch 21684 - Train Loss: 0.083026, Train Acc: 0.869231 | Val Loss: 0.113420, Val Acc: 0.773196\n",
      "Epoch 21685 - Train Loss: 0.083024, Train Acc: 0.869231 | Val Loss: 0.113419, Val Acc: 0.773196\n",
      "Epoch 21686 - Train Loss: 0.083022, Train Acc: 0.869231 | Val Loss: 0.113419, Val Acc: 0.773196\n",
      "Epoch 21687 - Train Loss: 0.083020, Train Acc: 0.869231 | Val Loss: 0.113418, Val Acc: 0.773196\n",
      "Epoch 21688 - Train Loss: 0.083018, Train Acc: 0.869231 | Val Loss: 0.113417, Val Acc: 0.773196\n",
      "Epoch 21689 - Train Loss: 0.083016, Train Acc: 0.869231 | Val Loss: 0.113416, Val Acc: 0.773196\n",
      "Epoch 21690 - Train Loss: 0.083014, Train Acc: 0.869231 | Val Loss: 0.113415, Val Acc: 0.773196\n",
      "Epoch 21691 - Train Loss: 0.083012, Train Acc: 0.869231 | Val Loss: 0.113414, Val Acc: 0.773196\n",
      "Epoch 21692 - Train Loss: 0.083010, Train Acc: 0.869231 | Val Loss: 0.113414, Val Acc: 0.773196\n",
      "Epoch 21693 - Train Loss: 0.083008, Train Acc: 0.869231 | Val Loss: 0.113413, Val Acc: 0.773196\n",
      "Epoch 21694 - Train Loss: 0.083006, Train Acc: 0.869231 | Val Loss: 0.113412, Val Acc: 0.773196\n",
      "Epoch 21695 - Train Loss: 0.083004, Train Acc: 0.869231 | Val Loss: 0.113411, Val Acc: 0.773196\n",
      "Epoch 21696 - Train Loss: 0.083002, Train Acc: 0.869231 | Val Loss: 0.113410, Val Acc: 0.773196\n",
      "Epoch 21697 - Train Loss: 0.083000, Train Acc: 0.869231 | Val Loss: 0.113409, Val Acc: 0.773196\n",
      "Epoch 21698 - Train Loss: 0.082998, Train Acc: 0.869231 | Val Loss: 0.113409, Val Acc: 0.773196\n",
      "Epoch 21699 - Train Loss: 0.082996, Train Acc: 0.869231 | Val Loss: 0.113408, Val Acc: 0.773196\n",
      "Epoch 21700 - Train Loss: 0.082994, Train Acc: 0.869231 | Val Loss: 0.113407, Val Acc: 0.773196\n",
      "Epoch 21701 - Train Loss: 0.082993, Train Acc: 0.869231 | Val Loss: 0.113406, Val Acc: 0.773196\n",
      "Epoch 21702 - Train Loss: 0.082991, Train Acc: 0.869231 | Val Loss: 0.113405, Val Acc: 0.773196\n",
      "Epoch 21703 - Train Loss: 0.082989, Train Acc: 0.869231 | Val Loss: 0.113404, Val Acc: 0.773196\n",
      "Epoch 21704 - Train Loss: 0.082987, Train Acc: 0.869231 | Val Loss: 0.113404, Val Acc: 0.773196\n",
      "Epoch 21705 - Train Loss: 0.082985, Train Acc: 0.869231 | Val Loss: 0.113403, Val Acc: 0.773196\n",
      "Epoch 21706 - Train Loss: 0.082983, Train Acc: 0.869231 | Val Loss: 0.113402, Val Acc: 0.773196\n",
      "Epoch 21707 - Train Loss: 0.082981, Train Acc: 0.869231 | Val Loss: 0.113401, Val Acc: 0.773196\n",
      "Epoch 21708 - Train Loss: 0.082979, Train Acc: 0.869231 | Val Loss: 0.113400, Val Acc: 0.773196\n",
      "Epoch 21709 - Train Loss: 0.082977, Train Acc: 0.869231 | Val Loss: 0.113399, Val Acc: 0.773196\n",
      "Epoch 21710 - Train Loss: 0.082975, Train Acc: 0.869231 | Val Loss: 0.113399, Val Acc: 0.773196\n",
      "Epoch 21711 - Train Loss: 0.082973, Train Acc: 0.869231 | Val Loss: 0.113398, Val Acc: 0.773196\n",
      "Epoch 21712 - Train Loss: 0.082971, Train Acc: 0.869231 | Val Loss: 0.113397, Val Acc: 0.773196\n",
      "Epoch 21713 - Train Loss: 0.082969, Train Acc: 0.869231 | Val Loss: 0.113396, Val Acc: 0.773196\n",
      "Epoch 21714 - Train Loss: 0.082967, Train Acc: 0.869231 | Val Loss: 0.113395, Val Acc: 0.773196\n",
      "Epoch 21715 - Train Loss: 0.082965, Train Acc: 0.869231 | Val Loss: 0.113395, Val Acc: 0.773196\n",
      "Epoch 21716 - Train Loss: 0.082963, Train Acc: 0.869231 | Val Loss: 0.113394, Val Acc: 0.773196\n",
      "Epoch 21717 - Train Loss: 0.082961, Train Acc: 0.869231 | Val Loss: 0.113393, Val Acc: 0.773196\n",
      "Epoch 21718 - Train Loss: 0.082959, Train Acc: 0.869231 | Val Loss: 0.113392, Val Acc: 0.773196\n",
      "Epoch 21719 - Train Loss: 0.082957, Train Acc: 0.869231 | Val Loss: 0.113391, Val Acc: 0.773196\n",
      "Epoch 21720 - Train Loss: 0.082955, Train Acc: 0.869231 | Val Loss: 0.113390, Val Acc: 0.773196\n",
      "Epoch 21721 - Train Loss: 0.082953, Train Acc: 0.869231 | Val Loss: 0.113390, Val Acc: 0.773196\n",
      "Epoch 21722 - Train Loss: 0.082951, Train Acc: 0.869231 | Val Loss: 0.113389, Val Acc: 0.773196\n",
      "Epoch 21723 - Train Loss: 0.082949, Train Acc: 0.869231 | Val Loss: 0.113388, Val Acc: 0.773196\n",
      "Epoch 21724 - Train Loss: 0.082947, Train Acc: 0.869231 | Val Loss: 0.113387, Val Acc: 0.773196\n",
      "Epoch 21725 - Train Loss: 0.082945, Train Acc: 0.869231 | Val Loss: 0.113386, Val Acc: 0.773196\n",
      "Epoch 21726 - Train Loss: 0.082944, Train Acc: 0.869231 | Val Loss: 0.113385, Val Acc: 0.773196\n",
      "Epoch 21727 - Train Loss: 0.082942, Train Acc: 0.869231 | Val Loss: 0.113385, Val Acc: 0.773196\n",
      "Epoch 21728 - Train Loss: 0.082940, Train Acc: 0.869231 | Val Loss: 0.113384, Val Acc: 0.773196\n",
      "Epoch 21729 - Train Loss: 0.082938, Train Acc: 0.869231 | Val Loss: 0.113383, Val Acc: 0.773196\n",
      "Epoch 21730 - Train Loss: 0.082936, Train Acc: 0.869231 | Val Loss: 0.113382, Val Acc: 0.773196\n",
      "Epoch 21731 - Train Loss: 0.082934, Train Acc: 0.869231 | Val Loss: 0.113381, Val Acc: 0.773196\n",
      "Epoch 21732 - Train Loss: 0.082932, Train Acc: 0.869231 | Val Loss: 0.113381, Val Acc: 0.773196\n",
      "Epoch 21733 - Train Loss: 0.082930, Train Acc: 0.869231 | Val Loss: 0.113380, Val Acc: 0.773196\n",
      "Epoch 21734 - Train Loss: 0.082928, Train Acc: 0.869231 | Val Loss: 0.113379, Val Acc: 0.773196\n",
      "Epoch 21735 - Train Loss: 0.082926, Train Acc: 0.869231 | Val Loss: 0.113378, Val Acc: 0.773196\n",
      "Epoch 21736 - Train Loss: 0.082924, Train Acc: 0.869231 | Val Loss: 0.113377, Val Acc: 0.773196\n",
      "Epoch 21737 - Train Loss: 0.082922, Train Acc: 0.869231 | Val Loss: 0.113376, Val Acc: 0.773196\n",
      "Epoch 21738 - Train Loss: 0.082920, Train Acc: 0.869231 | Val Loss: 0.113376, Val Acc: 0.773196\n",
      "Epoch 21739 - Train Loss: 0.082918, Train Acc: 0.869231 | Val Loss: 0.113375, Val Acc: 0.773196\n",
      "Epoch 21740 - Train Loss: 0.082916, Train Acc: 0.869231 | Val Loss: 0.113374, Val Acc: 0.773196\n",
      "Epoch 21741 - Train Loss: 0.082914, Train Acc: 0.869231 | Val Loss: 0.113373, Val Acc: 0.773196\n",
      "Epoch 21742 - Train Loss: 0.082912, Train Acc: 0.869231 | Val Loss: 0.113372, Val Acc: 0.773196\n",
      "Epoch 21743 - Train Loss: 0.082910, Train Acc: 0.869231 | Val Loss: 0.113371, Val Acc: 0.773196\n",
      "Epoch 21744 - Train Loss: 0.082908, Train Acc: 0.869231 | Val Loss: 0.113371, Val Acc: 0.773196\n",
      "Epoch 21745 - Train Loss: 0.082906, Train Acc: 0.869231 | Val Loss: 0.113370, Val Acc: 0.773196\n",
      "Epoch 21746 - Train Loss: 0.082904, Train Acc: 0.869231 | Val Loss: 0.113369, Val Acc: 0.773196\n",
      "Epoch 21747 - Train Loss: 0.082902, Train Acc: 0.869231 | Val Loss: 0.113368, Val Acc: 0.773196\n",
      "Epoch 21748 - Train Loss: 0.082900, Train Acc: 0.869231 | Val Loss: 0.113367, Val Acc: 0.773196\n",
      "Epoch 21749 - Train Loss: 0.082899, Train Acc: 0.869231 | Val Loss: 0.113367, Val Acc: 0.773196\n",
      "Epoch 21750 - Train Loss: 0.082897, Train Acc: 0.869231 | Val Loss: 0.113366, Val Acc: 0.773196\n",
      "Epoch 21751 - Train Loss: 0.082895, Train Acc: 0.869231 | Val Loss: 0.113365, Val Acc: 0.773196\n",
      "Epoch 21752 - Train Loss: 0.082893, Train Acc: 0.869231 | Val Loss: 0.113364, Val Acc: 0.773196\n",
      "Epoch 21753 - Train Loss: 0.082891, Train Acc: 0.869231 | Val Loss: 0.113363, Val Acc: 0.773196\n",
      "Epoch 21754 - Train Loss: 0.082889, Train Acc: 0.869231 | Val Loss: 0.113362, Val Acc: 0.773196\n",
      "Epoch 21755 - Train Loss: 0.082887, Train Acc: 0.869231 | Val Loss: 0.113362, Val Acc: 0.773196\n",
      "Epoch 21756 - Train Loss: 0.082885, Train Acc: 0.869231 | Val Loss: 0.113361, Val Acc: 0.773196\n",
      "Epoch 21757 - Train Loss: 0.082883, Train Acc: 0.869231 | Val Loss: 0.113360, Val Acc: 0.773196\n",
      "Epoch 21758 - Train Loss: 0.082881, Train Acc: 0.869231 | Val Loss: 0.113359, Val Acc: 0.773196\n",
      "Epoch 21759 - Train Loss: 0.082879, Train Acc: 0.869231 | Val Loss: 0.113358, Val Acc: 0.773196\n",
      "Epoch 21760 - Train Loss: 0.082877, Train Acc: 0.869231 | Val Loss: 0.113358, Val Acc: 0.773196\n",
      "Epoch 21761 - Train Loss: 0.082875, Train Acc: 0.869231 | Val Loss: 0.113357, Val Acc: 0.773196\n",
      "Epoch 21762 - Train Loss: 0.082873, Train Acc: 0.869231 | Val Loss: 0.113356, Val Acc: 0.773196\n",
      "Epoch 21763 - Train Loss: 0.082871, Train Acc: 0.869231 | Val Loss: 0.113355, Val Acc: 0.773196\n",
      "Epoch 21764 - Train Loss: 0.082869, Train Acc: 0.869231 | Val Loss: 0.113354, Val Acc: 0.773196\n",
      "Epoch 21765 - Train Loss: 0.082867, Train Acc: 0.869231 | Val Loss: 0.113353, Val Acc: 0.773196\n",
      "Epoch 21766 - Train Loss: 0.082865, Train Acc: 0.869231 | Val Loss: 0.113353, Val Acc: 0.773196\n",
      "Epoch 21767 - Train Loss: 0.082863, Train Acc: 0.869231 | Val Loss: 0.113352, Val Acc: 0.773196\n",
      "Epoch 21768 - Train Loss: 0.082861, Train Acc: 0.869231 | Val Loss: 0.113351, Val Acc: 0.773196\n",
      "Epoch 21769 - Train Loss: 0.082859, Train Acc: 0.869231 | Val Loss: 0.113350, Val Acc: 0.773196\n",
      "Epoch 21770 - Train Loss: 0.082858, Train Acc: 0.869231 | Val Loss: 0.113349, Val Acc: 0.773196\n",
      "Epoch 21771 - Train Loss: 0.082856, Train Acc: 0.869231 | Val Loss: 0.113349, Val Acc: 0.773196\n",
      "Epoch 21772 - Train Loss: 0.082854, Train Acc: 0.869231 | Val Loss: 0.113348, Val Acc: 0.773196\n",
      "Epoch 21773 - Train Loss: 0.082852, Train Acc: 0.869231 | Val Loss: 0.113347, Val Acc: 0.773196\n",
      "Epoch 21774 - Train Loss: 0.082850, Train Acc: 0.869231 | Val Loss: 0.113346, Val Acc: 0.773196\n",
      "Epoch 21775 - Train Loss: 0.082848, Train Acc: 0.869231 | Val Loss: 0.113345, Val Acc: 0.773196\n",
      "Epoch 21776 - Train Loss: 0.082846, Train Acc: 0.869231 | Val Loss: 0.113344, Val Acc: 0.773196\n",
      "Epoch 21777 - Train Loss: 0.082844, Train Acc: 0.869231 | Val Loss: 0.113344, Val Acc: 0.773196\n",
      "Epoch 21778 - Train Loss: 0.082842, Train Acc: 0.869231 | Val Loss: 0.113343, Val Acc: 0.773196\n",
      "Epoch 21779 - Train Loss: 0.082840, Train Acc: 0.869231 | Val Loss: 0.113342, Val Acc: 0.773196\n",
      "Epoch 21780 - Train Loss: 0.082838, Train Acc: 0.869231 | Val Loss: 0.113341, Val Acc: 0.773196\n",
      "Epoch 21781 - Train Loss: 0.082836, Train Acc: 0.869231 | Val Loss: 0.113340, Val Acc: 0.773196\n",
      "Epoch 21782 - Train Loss: 0.082834, Train Acc: 0.869231 | Val Loss: 0.113340, Val Acc: 0.773196\n",
      "Epoch 21783 - Train Loss: 0.082832, Train Acc: 0.869231 | Val Loss: 0.113339, Val Acc: 0.773196\n",
      "Epoch 21784 - Train Loss: 0.082830, Train Acc: 0.869231 | Val Loss: 0.113338, Val Acc: 0.773196\n",
      "Epoch 21785 - Train Loss: 0.082828, Train Acc: 0.869231 | Val Loss: 0.113337, Val Acc: 0.773196\n",
      "Epoch 21786 - Train Loss: 0.082826, Train Acc: 0.869231 | Val Loss: 0.113336, Val Acc: 0.773196\n",
      "Epoch 21787 - Train Loss: 0.082824, Train Acc: 0.869231 | Val Loss: 0.113335, Val Acc: 0.773196\n",
      "Epoch 21788 - Train Loss: 0.082822, Train Acc: 0.869231 | Val Loss: 0.113335, Val Acc: 0.773196\n",
      "Epoch 21789 - Train Loss: 0.082820, Train Acc: 0.869231 | Val Loss: 0.113334, Val Acc: 0.773196\n",
      "Epoch 21790 - Train Loss: 0.082819, Train Acc: 0.869231 | Val Loss: 0.113333, Val Acc: 0.773196\n",
      "Epoch 21791 - Train Loss: 0.082817, Train Acc: 0.869231 | Val Loss: 0.113332, Val Acc: 0.773196\n",
      "Epoch 21792 - Train Loss: 0.082815, Train Acc: 0.869231 | Val Loss: 0.113331, Val Acc: 0.773196\n",
      "Epoch 21793 - Train Loss: 0.082813, Train Acc: 0.869231 | Val Loss: 0.113331, Val Acc: 0.773196\n",
      "Epoch 21794 - Train Loss: 0.082811, Train Acc: 0.869231 | Val Loss: 0.113330, Val Acc: 0.773196\n",
      "Epoch 21795 - Train Loss: 0.082809, Train Acc: 0.869231 | Val Loss: 0.113329, Val Acc: 0.773196\n",
      "Epoch 21796 - Train Loss: 0.082807, Train Acc: 0.869231 | Val Loss: 0.113328, Val Acc: 0.773196\n",
      "Epoch 21797 - Train Loss: 0.082805, Train Acc: 0.869231 | Val Loss: 0.113327, Val Acc: 0.773196\n",
      "Epoch 21798 - Train Loss: 0.082803, Train Acc: 0.869231 | Val Loss: 0.113326, Val Acc: 0.773196\n",
      "Epoch 21799 - Train Loss: 0.082801, Train Acc: 0.869231 | Val Loss: 0.113326, Val Acc: 0.773196\n",
      "Epoch 21800 - Train Loss: 0.082799, Train Acc: 0.869231 | Val Loss: 0.113325, Val Acc: 0.773196\n",
      "Epoch 21801 - Train Loss: 0.082797, Train Acc: 0.869231 | Val Loss: 0.113324, Val Acc: 0.773196\n",
      "Epoch 21802 - Train Loss: 0.082795, Train Acc: 0.869231 | Val Loss: 0.113323, Val Acc: 0.773196\n",
      "Epoch 21803 - Train Loss: 0.082793, Train Acc: 0.869231 | Val Loss: 0.113322, Val Acc: 0.773196\n",
      "Epoch 21804 - Train Loss: 0.082791, Train Acc: 0.869231 | Val Loss: 0.113322, Val Acc: 0.773196\n",
      "Epoch 21805 - Train Loss: 0.082789, Train Acc: 0.869231 | Val Loss: 0.113321, Val Acc: 0.773196\n",
      "Epoch 21806 - Train Loss: 0.082787, Train Acc: 0.869231 | Val Loss: 0.113320, Val Acc: 0.773196\n",
      "Epoch 21807 - Train Loss: 0.082785, Train Acc: 0.869231 | Val Loss: 0.113319, Val Acc: 0.773196\n",
      "Epoch 21808 - Train Loss: 0.082783, Train Acc: 0.869231 | Val Loss: 0.113318, Val Acc: 0.773196\n",
      "Epoch 21809 - Train Loss: 0.082782, Train Acc: 0.869231 | Val Loss: 0.113318, Val Acc: 0.773196\n",
      "Epoch 21810 - Train Loss: 0.082780, Train Acc: 0.869231 | Val Loss: 0.113317, Val Acc: 0.773196\n",
      "Epoch 21811 - Train Loss: 0.082778, Train Acc: 0.869231 | Val Loss: 0.113316, Val Acc: 0.773196\n",
      "Epoch 21812 - Train Loss: 0.082776, Train Acc: 0.869231 | Val Loss: 0.113315, Val Acc: 0.773196\n",
      "Epoch 21813 - Train Loss: 0.082774, Train Acc: 0.869231 | Val Loss: 0.113314, Val Acc: 0.773196\n",
      "Epoch 21814 - Train Loss: 0.082772, Train Acc: 0.869231 | Val Loss: 0.113313, Val Acc: 0.773196\n",
      "Epoch 21815 - Train Loss: 0.082770, Train Acc: 0.869231 | Val Loss: 0.113313, Val Acc: 0.773196\n",
      "Epoch 21816 - Train Loss: 0.082768, Train Acc: 0.869231 | Val Loss: 0.113312, Val Acc: 0.773196\n",
      "Epoch 21817 - Train Loss: 0.082766, Train Acc: 0.869231 | Val Loss: 0.113311, Val Acc: 0.773196\n",
      "Epoch 21818 - Train Loss: 0.082764, Train Acc: 0.869231 | Val Loss: 0.113310, Val Acc: 0.773196\n",
      "Epoch 21819 - Train Loss: 0.082762, Train Acc: 0.869231 | Val Loss: 0.113309, Val Acc: 0.773196\n",
      "Epoch 21820 - Train Loss: 0.082760, Train Acc: 0.869231 | Val Loss: 0.113309, Val Acc: 0.773196\n",
      "Epoch 21821 - Train Loss: 0.082758, Train Acc: 0.869231 | Val Loss: 0.113308, Val Acc: 0.773196\n",
      "Epoch 21822 - Train Loss: 0.082756, Train Acc: 0.869231 | Val Loss: 0.113307, Val Acc: 0.773196\n",
      "Epoch 21823 - Train Loss: 0.082754, Train Acc: 0.869231 | Val Loss: 0.113306, Val Acc: 0.773196\n",
      "Epoch 21824 - Train Loss: 0.082752, Train Acc: 0.869231 | Val Loss: 0.113305, Val Acc: 0.773196\n",
      "Epoch 21825 - Train Loss: 0.082750, Train Acc: 0.869231 | Val Loss: 0.113305, Val Acc: 0.773196\n",
      "Epoch 21826 - Train Loss: 0.082748, Train Acc: 0.869231 | Val Loss: 0.113304, Val Acc: 0.773196\n",
      "Epoch 21827 - Train Loss: 0.082747, Train Acc: 0.869231 | Val Loss: 0.113303, Val Acc: 0.773196\n",
      "Epoch 21828 - Train Loss: 0.082745, Train Acc: 0.869231 | Val Loss: 0.113302, Val Acc: 0.773196\n",
      "Epoch 21829 - Train Loss: 0.082743, Train Acc: 0.869231 | Val Loss: 0.113301, Val Acc: 0.773196\n",
      "Epoch 21830 - Train Loss: 0.082741, Train Acc: 0.869231 | Val Loss: 0.113300, Val Acc: 0.773196\n",
      "Epoch 21831 - Train Loss: 0.082739, Train Acc: 0.869231 | Val Loss: 0.113300, Val Acc: 0.773196\n",
      "Epoch 21832 - Train Loss: 0.082737, Train Acc: 0.869231 | Val Loss: 0.113299, Val Acc: 0.773196\n",
      "Epoch 21833 - Train Loss: 0.082735, Train Acc: 0.869231 | Val Loss: 0.113298, Val Acc: 0.773196\n",
      "Epoch 21834 - Train Loss: 0.082733, Train Acc: 0.869231 | Val Loss: 0.113297, Val Acc: 0.773196\n",
      "Epoch 21835 - Train Loss: 0.082731, Train Acc: 0.869231 | Val Loss: 0.113296, Val Acc: 0.773196\n",
      "Epoch 21836 - Train Loss: 0.082729, Train Acc: 0.869231 | Val Loss: 0.113296, Val Acc: 0.773196\n",
      "Epoch 21837 - Train Loss: 0.082727, Train Acc: 0.869231 | Val Loss: 0.113295, Val Acc: 0.773196\n",
      "Epoch 21838 - Train Loss: 0.082725, Train Acc: 0.869231 | Val Loss: 0.113294, Val Acc: 0.773196\n",
      "Epoch 21839 - Train Loss: 0.082723, Train Acc: 0.869231 | Val Loss: 0.113293, Val Acc: 0.773196\n",
      "Epoch 21840 - Train Loss: 0.082721, Train Acc: 0.869231 | Val Loss: 0.113292, Val Acc: 0.773196\n",
      "Epoch 21841 - Train Loss: 0.082719, Train Acc: 0.869231 | Val Loss: 0.113292, Val Acc: 0.773196\n",
      "Epoch 21842 - Train Loss: 0.082717, Train Acc: 0.869231 | Val Loss: 0.113291, Val Acc: 0.773196\n",
      "Epoch 21843 - Train Loss: 0.082715, Train Acc: 0.869231 | Val Loss: 0.113290, Val Acc: 0.773196\n",
      "Epoch 21844 - Train Loss: 0.082714, Train Acc: 0.869231 | Val Loss: 0.113289, Val Acc: 0.773196\n",
      "Epoch 21845 - Train Loss: 0.082712, Train Acc: 0.869231 | Val Loss: 0.113288, Val Acc: 0.773196\n",
      "Epoch 21846 - Train Loss: 0.082710, Train Acc: 0.869231 | Val Loss: 0.113287, Val Acc: 0.773196\n",
      "Epoch 21847 - Train Loss: 0.082708, Train Acc: 0.869231 | Val Loss: 0.113287, Val Acc: 0.773196\n",
      "Epoch 21848 - Train Loss: 0.082706, Train Acc: 0.869231 | Val Loss: 0.113286, Val Acc: 0.773196\n",
      "Epoch 21849 - Train Loss: 0.082704, Train Acc: 0.869231 | Val Loss: 0.113285, Val Acc: 0.773196\n",
      "Epoch 21850 - Train Loss: 0.082702, Train Acc: 0.869231 | Val Loss: 0.113284, Val Acc: 0.773196\n",
      "Epoch 21851 - Train Loss: 0.082700, Train Acc: 0.869231 | Val Loss: 0.113283, Val Acc: 0.773196\n",
      "Epoch 21852 - Train Loss: 0.082698, Train Acc: 0.869231 | Val Loss: 0.113283, Val Acc: 0.773196\n",
      "Epoch 21853 - Train Loss: 0.082696, Train Acc: 0.869231 | Val Loss: 0.113282, Val Acc: 0.773196\n",
      "Epoch 21854 - Train Loss: 0.082694, Train Acc: 0.869231 | Val Loss: 0.113281, Val Acc: 0.773196\n",
      "Epoch 21855 - Train Loss: 0.082692, Train Acc: 0.869231 | Val Loss: 0.113280, Val Acc: 0.773196\n",
      "Epoch 21856 - Train Loss: 0.082690, Train Acc: 0.869231 | Val Loss: 0.113279, Val Acc: 0.773196\n",
      "Epoch 21857 - Train Loss: 0.082688, Train Acc: 0.869231 | Val Loss: 0.113279, Val Acc: 0.773196\n",
      "Epoch 21858 - Train Loss: 0.082686, Train Acc: 0.869231 | Val Loss: 0.113278, Val Acc: 0.773196\n",
      "Epoch 21859 - Train Loss: 0.082684, Train Acc: 0.869231 | Val Loss: 0.113277, Val Acc: 0.773196\n",
      "Epoch 21860 - Train Loss: 0.082682, Train Acc: 0.869231 | Val Loss: 0.113276, Val Acc: 0.773196\n",
      "Epoch 21861 - Train Loss: 0.082681, Train Acc: 0.869231 | Val Loss: 0.113275, Val Acc: 0.773196\n",
      "Epoch 21862 - Train Loss: 0.082679, Train Acc: 0.869231 | Val Loss: 0.113275, Val Acc: 0.773196\n",
      "Epoch 21863 - Train Loss: 0.082677, Train Acc: 0.869231 | Val Loss: 0.113274, Val Acc: 0.773196\n",
      "Epoch 21864 - Train Loss: 0.082675, Train Acc: 0.869231 | Val Loss: 0.113273, Val Acc: 0.773196\n",
      "Epoch 21865 - Train Loss: 0.082673, Train Acc: 0.869231 | Val Loss: 0.113272, Val Acc: 0.773196\n",
      "Epoch 21866 - Train Loss: 0.082671, Train Acc: 0.869231 | Val Loss: 0.113271, Val Acc: 0.773196\n",
      "Epoch 21867 - Train Loss: 0.082669, Train Acc: 0.869231 | Val Loss: 0.113271, Val Acc: 0.773196\n",
      "Epoch 21868 - Train Loss: 0.082667, Train Acc: 0.869231 | Val Loss: 0.113270, Val Acc: 0.773196\n",
      "Epoch 21869 - Train Loss: 0.082665, Train Acc: 0.869231 | Val Loss: 0.113269, Val Acc: 0.773196\n",
      "Epoch 21870 - Train Loss: 0.082663, Train Acc: 0.869231 | Val Loss: 0.113268, Val Acc: 0.773196\n",
      "Epoch 21871 - Train Loss: 0.082661, Train Acc: 0.869231 | Val Loss: 0.113267, Val Acc: 0.773196\n",
      "Epoch 21872 - Train Loss: 0.082659, Train Acc: 0.869231 | Val Loss: 0.113266, Val Acc: 0.773196\n",
      "Epoch 21873 - Train Loss: 0.082657, Train Acc: 0.869231 | Val Loss: 0.113266, Val Acc: 0.773196\n",
      "Epoch 21874 - Train Loss: 0.082655, Train Acc: 0.869231 | Val Loss: 0.113265, Val Acc: 0.773196\n",
      "Epoch 21875 - Train Loss: 0.082653, Train Acc: 0.869231 | Val Loss: 0.113264, Val Acc: 0.773196\n",
      "Epoch 21876 - Train Loss: 0.082651, Train Acc: 0.869231 | Val Loss: 0.113263, Val Acc: 0.773196\n",
      "Epoch 21877 - Train Loss: 0.082650, Train Acc: 0.869231 | Val Loss: 0.113262, Val Acc: 0.773196\n",
      "Epoch 21878 - Train Loss: 0.082648, Train Acc: 0.869231 | Val Loss: 0.113262, Val Acc: 0.773196\n",
      "Epoch 21879 - Train Loss: 0.082646, Train Acc: 0.869231 | Val Loss: 0.113261, Val Acc: 0.773196\n",
      "Epoch 21880 - Train Loss: 0.082644, Train Acc: 0.869231 | Val Loss: 0.113260, Val Acc: 0.773196\n",
      "Epoch 21881 - Train Loss: 0.082642, Train Acc: 0.869231 | Val Loss: 0.113259, Val Acc: 0.773196\n",
      "Epoch 21882 - Train Loss: 0.082640, Train Acc: 0.869231 | Val Loss: 0.113258, Val Acc: 0.773196\n",
      "Epoch 21883 - Train Loss: 0.082638, Train Acc: 0.869231 | Val Loss: 0.113258, Val Acc: 0.773196\n",
      "Epoch 21884 - Train Loss: 0.082636, Train Acc: 0.869231 | Val Loss: 0.113257, Val Acc: 0.773196\n",
      "Epoch 21885 - Train Loss: 0.082634, Train Acc: 0.869231 | Val Loss: 0.113256, Val Acc: 0.773196\n",
      "Epoch 21886 - Train Loss: 0.082632, Train Acc: 0.869231 | Val Loss: 0.113255, Val Acc: 0.773196\n",
      "Epoch 21887 - Train Loss: 0.082630, Train Acc: 0.869231 | Val Loss: 0.113254, Val Acc: 0.773196\n",
      "Epoch 21888 - Train Loss: 0.082628, Train Acc: 0.869231 | Val Loss: 0.113254, Val Acc: 0.773196\n",
      "Epoch 21889 - Train Loss: 0.082626, Train Acc: 0.869231 | Val Loss: 0.113253, Val Acc: 0.773196\n",
      "Epoch 21890 - Train Loss: 0.082624, Train Acc: 0.869231 | Val Loss: 0.113252, Val Acc: 0.773196\n",
      "Epoch 21891 - Train Loss: 0.082622, Train Acc: 0.869231 | Val Loss: 0.113251, Val Acc: 0.773196\n",
      "Epoch 21892 - Train Loss: 0.082621, Train Acc: 0.869231 | Val Loss: 0.113250, Val Acc: 0.773196\n",
      "Epoch 21893 - Train Loss: 0.082619, Train Acc: 0.869231 | Val Loss: 0.113250, Val Acc: 0.773196\n",
      "Epoch 21894 - Train Loss: 0.082617, Train Acc: 0.869231 | Val Loss: 0.113249, Val Acc: 0.773196\n",
      "Epoch 21895 - Train Loss: 0.082615, Train Acc: 0.869231 | Val Loss: 0.113248, Val Acc: 0.773196\n",
      "Epoch 21896 - Train Loss: 0.082613, Train Acc: 0.869231 | Val Loss: 0.113247, Val Acc: 0.773196\n",
      "Epoch 21897 - Train Loss: 0.082611, Train Acc: 0.869231 | Val Loss: 0.113246, Val Acc: 0.773196\n",
      "Epoch 21898 - Train Loss: 0.082609, Train Acc: 0.869231 | Val Loss: 0.113246, Val Acc: 0.773196\n",
      "Epoch 21899 - Train Loss: 0.082607, Train Acc: 0.869231 | Val Loss: 0.113245, Val Acc: 0.773196\n",
      "Epoch 21900 - Train Loss: 0.082605, Train Acc: 0.869231 | Val Loss: 0.113244, Val Acc: 0.773196\n",
      "Epoch 21901 - Train Loss: 0.082603, Train Acc: 0.869231 | Val Loss: 0.113243, Val Acc: 0.773196\n",
      "Epoch 21902 - Train Loss: 0.082601, Train Acc: 0.869231 | Val Loss: 0.113242, Val Acc: 0.773196\n",
      "Epoch 21903 - Train Loss: 0.082599, Train Acc: 0.869231 | Val Loss: 0.113242, Val Acc: 0.773196\n",
      "Epoch 21904 - Train Loss: 0.082597, Train Acc: 0.869231 | Val Loss: 0.113241, Val Acc: 0.773196\n",
      "Epoch 21905 - Train Loss: 0.082595, Train Acc: 0.869231 | Val Loss: 0.113240, Val Acc: 0.773196\n",
      "Epoch 21906 - Train Loss: 0.082593, Train Acc: 0.869231 | Val Loss: 0.113239, Val Acc: 0.773196\n",
      "Epoch 21907 - Train Loss: 0.082592, Train Acc: 0.869231 | Val Loss: 0.113238, Val Acc: 0.773196\n",
      "Epoch 21908 - Train Loss: 0.082590, Train Acc: 0.869231 | Val Loss: 0.113238, Val Acc: 0.773196\n",
      "Epoch 21909 - Train Loss: 0.082588, Train Acc: 0.869231 | Val Loss: 0.113237, Val Acc: 0.773196\n",
      "Epoch 21910 - Train Loss: 0.082586, Train Acc: 0.869231 | Val Loss: 0.113236, Val Acc: 0.773196\n",
      "Epoch 21911 - Train Loss: 0.082584, Train Acc: 0.869231 | Val Loss: 0.113235, Val Acc: 0.773196\n",
      "Epoch 21912 - Train Loss: 0.082582, Train Acc: 0.869231 | Val Loss: 0.113234, Val Acc: 0.773196\n",
      "Epoch 21913 - Train Loss: 0.082580, Train Acc: 0.869231 | Val Loss: 0.113234, Val Acc: 0.773196\n",
      "Epoch 21914 - Train Loss: 0.082578, Train Acc: 0.869231 | Val Loss: 0.113233, Val Acc: 0.773196\n",
      "Epoch 21915 - Train Loss: 0.082576, Train Acc: 0.869231 | Val Loss: 0.113232, Val Acc: 0.773196\n",
      "Epoch 21916 - Train Loss: 0.082574, Train Acc: 0.869231 | Val Loss: 0.113231, Val Acc: 0.773196\n",
      "Epoch 21917 - Train Loss: 0.082572, Train Acc: 0.869231 | Val Loss: 0.113230, Val Acc: 0.773196\n",
      "Epoch 21918 - Train Loss: 0.082570, Train Acc: 0.869231 | Val Loss: 0.113230, Val Acc: 0.773196\n",
      "Epoch 21919 - Train Loss: 0.082568, Train Acc: 0.869231 | Val Loss: 0.113229, Val Acc: 0.773196\n",
      "Epoch 21920 - Train Loss: 0.082566, Train Acc: 0.869231 | Val Loss: 0.113228, Val Acc: 0.773196\n",
      "Epoch 21921 - Train Loss: 0.082564, Train Acc: 0.869231 | Val Loss: 0.113227, Val Acc: 0.773196\n",
      "Epoch 21922 - Train Loss: 0.082563, Train Acc: 0.869231 | Val Loss: 0.113226, Val Acc: 0.773196\n",
      "Epoch 21923 - Train Loss: 0.082561, Train Acc: 0.869231 | Val Loss: 0.113226, Val Acc: 0.773196\n",
      "Epoch 21924 - Train Loss: 0.082559, Train Acc: 0.869231 | Val Loss: 0.113225, Val Acc: 0.773196\n",
      "Epoch 21925 - Train Loss: 0.082557, Train Acc: 0.869231 | Val Loss: 0.113224, Val Acc: 0.773196\n",
      "Epoch 21926 - Train Loss: 0.082555, Train Acc: 0.869231 | Val Loss: 0.113223, Val Acc: 0.773196\n",
      "Epoch 21927 - Train Loss: 0.082553, Train Acc: 0.869231 | Val Loss: 0.113222, Val Acc: 0.773196\n",
      "Epoch 21928 - Train Loss: 0.082551, Train Acc: 0.869231 | Val Loss: 0.113222, Val Acc: 0.773196\n",
      "Epoch 21929 - Train Loss: 0.082549, Train Acc: 0.869231 | Val Loss: 0.113221, Val Acc: 0.773196\n",
      "Epoch 21930 - Train Loss: 0.082547, Train Acc: 0.869231 | Val Loss: 0.113220, Val Acc: 0.773196\n",
      "Epoch 21931 - Train Loss: 0.082545, Train Acc: 0.869231 | Val Loss: 0.113219, Val Acc: 0.773196\n",
      "Epoch 21932 - Train Loss: 0.082543, Train Acc: 0.869231 | Val Loss: 0.113218, Val Acc: 0.773196\n",
      "Epoch 21933 - Train Loss: 0.082541, Train Acc: 0.869231 | Val Loss: 0.113218, Val Acc: 0.773196\n",
      "Epoch 21934 - Train Loss: 0.082539, Train Acc: 0.869231 | Val Loss: 0.113217, Val Acc: 0.773196\n",
      "Epoch 21935 - Train Loss: 0.082537, Train Acc: 0.869231 | Val Loss: 0.113216, Val Acc: 0.773196\n",
      "Epoch 21936 - Train Loss: 0.082536, Train Acc: 0.869231 | Val Loss: 0.113215, Val Acc: 0.773196\n",
      "Epoch 21937 - Train Loss: 0.082534, Train Acc: 0.869231 | Val Loss: 0.113214, Val Acc: 0.773196\n",
      "Epoch 21938 - Train Loss: 0.082532, Train Acc: 0.869231 | Val Loss: 0.113214, Val Acc: 0.773196\n",
      "Epoch 21939 - Train Loss: 0.082530, Train Acc: 0.869231 | Val Loss: 0.113213, Val Acc: 0.773196\n",
      "Epoch 21940 - Train Loss: 0.082528, Train Acc: 0.869231 | Val Loss: 0.113212, Val Acc: 0.773196\n",
      "Epoch 21941 - Train Loss: 0.082526, Train Acc: 0.869231 | Val Loss: 0.113211, Val Acc: 0.773196\n",
      "Epoch 21942 - Train Loss: 0.082524, Train Acc: 0.869231 | Val Loss: 0.113210, Val Acc: 0.773196\n",
      "Epoch 21943 - Train Loss: 0.082522, Train Acc: 0.869231 | Val Loss: 0.113210, Val Acc: 0.773196\n",
      "Epoch 21944 - Train Loss: 0.082520, Train Acc: 0.870513 | Val Loss: 0.113209, Val Acc: 0.773196\n",
      "Epoch 21945 - Train Loss: 0.082518, Train Acc: 0.870513 | Val Loss: 0.113208, Val Acc: 0.773196\n",
      "Epoch 21946 - Train Loss: 0.082516, Train Acc: 0.870513 | Val Loss: 0.113207, Val Acc: 0.773196\n",
      "Epoch 21947 - Train Loss: 0.082514, Train Acc: 0.870513 | Val Loss: 0.113206, Val Acc: 0.773196\n",
      "Epoch 21948 - Train Loss: 0.082512, Train Acc: 0.870513 | Val Loss: 0.113206, Val Acc: 0.773196\n",
      "Epoch 21949 - Train Loss: 0.082511, Train Acc: 0.870513 | Val Loss: 0.113205, Val Acc: 0.773196\n",
      "Epoch 21950 - Train Loss: 0.082509, Train Acc: 0.870513 | Val Loss: 0.113204, Val Acc: 0.773196\n",
      "Epoch 21951 - Train Loss: 0.082507, Train Acc: 0.870513 | Val Loss: 0.113203, Val Acc: 0.773196\n",
      "Epoch 21952 - Train Loss: 0.082505, Train Acc: 0.870513 | Val Loss: 0.113202, Val Acc: 0.773196\n",
      "Epoch 21953 - Train Loss: 0.082503, Train Acc: 0.870513 | Val Loss: 0.113202, Val Acc: 0.773196\n",
      "Epoch 21954 - Train Loss: 0.082501, Train Acc: 0.870513 | Val Loss: 0.113201, Val Acc: 0.773196\n",
      "Epoch 21955 - Train Loss: 0.082499, Train Acc: 0.870513 | Val Loss: 0.113200, Val Acc: 0.773196\n",
      "Epoch 21956 - Train Loss: 0.082497, Train Acc: 0.870513 | Val Loss: 0.113199, Val Acc: 0.773196\n",
      "Epoch 21957 - Train Loss: 0.082495, Train Acc: 0.870513 | Val Loss: 0.113198, Val Acc: 0.773196\n",
      "Epoch 21958 - Train Loss: 0.082493, Train Acc: 0.870513 | Val Loss: 0.113198, Val Acc: 0.773196\n",
      "Epoch 21959 - Train Loss: 0.082491, Train Acc: 0.870513 | Val Loss: 0.113197, Val Acc: 0.773196\n",
      "Epoch 21960 - Train Loss: 0.082489, Train Acc: 0.870513 | Val Loss: 0.113196, Val Acc: 0.773196\n",
      "Epoch 21961 - Train Loss: 0.082487, Train Acc: 0.870513 | Val Loss: 0.113195, Val Acc: 0.773196\n",
      "Epoch 21962 - Train Loss: 0.082485, Train Acc: 0.870513 | Val Loss: 0.113194, Val Acc: 0.773196\n",
      "Epoch 21963 - Train Loss: 0.082484, Train Acc: 0.870513 | Val Loss: 0.113194, Val Acc: 0.773196\n",
      "Epoch 21964 - Train Loss: 0.082482, Train Acc: 0.870513 | Val Loss: 0.113193, Val Acc: 0.773196\n",
      "Epoch 21965 - Train Loss: 0.082480, Train Acc: 0.870513 | Val Loss: 0.113192, Val Acc: 0.773196\n",
      "Epoch 21966 - Train Loss: 0.082478, Train Acc: 0.870513 | Val Loss: 0.113191, Val Acc: 0.773196\n",
      "Epoch 21967 - Train Loss: 0.082476, Train Acc: 0.870513 | Val Loss: 0.113190, Val Acc: 0.773196\n",
      "Epoch 21968 - Train Loss: 0.082474, Train Acc: 0.870513 | Val Loss: 0.113190, Val Acc: 0.773196\n",
      "Epoch 21969 - Train Loss: 0.082472, Train Acc: 0.870513 | Val Loss: 0.113189, Val Acc: 0.773196\n",
      "Epoch 21970 - Train Loss: 0.082470, Train Acc: 0.870513 | Val Loss: 0.113188, Val Acc: 0.773196\n",
      "Epoch 21971 - Train Loss: 0.082468, Train Acc: 0.870513 | Val Loss: 0.113187, Val Acc: 0.773196\n",
      "Epoch 21972 - Train Loss: 0.082466, Train Acc: 0.870513 | Val Loss: 0.113186, Val Acc: 0.773196\n",
      "Epoch 21973 - Train Loss: 0.082464, Train Acc: 0.870513 | Val Loss: 0.113186, Val Acc: 0.773196\n",
      "Epoch 21974 - Train Loss: 0.082462, Train Acc: 0.870513 | Val Loss: 0.113185, Val Acc: 0.773196\n",
      "Epoch 21975 - Train Loss: 0.082460, Train Acc: 0.870513 | Val Loss: 0.113184, Val Acc: 0.773196\n",
      "Epoch 21976 - Train Loss: 0.082459, Train Acc: 0.870513 | Val Loss: 0.113183, Val Acc: 0.773196\n",
      "Epoch 21977 - Train Loss: 0.082457, Train Acc: 0.870513 | Val Loss: 0.113182, Val Acc: 0.773196\n",
      "Epoch 21978 - Train Loss: 0.082455, Train Acc: 0.870513 | Val Loss: 0.113182, Val Acc: 0.773196\n",
      "Epoch 21979 - Train Loss: 0.082453, Train Acc: 0.870513 | Val Loss: 0.113181, Val Acc: 0.773196\n",
      "Epoch 21980 - Train Loss: 0.082451, Train Acc: 0.870513 | Val Loss: 0.113180, Val Acc: 0.773196\n",
      "Epoch 21981 - Train Loss: 0.082449, Train Acc: 0.870513 | Val Loss: 0.113179, Val Acc: 0.773196\n",
      "Epoch 21982 - Train Loss: 0.082447, Train Acc: 0.870513 | Val Loss: 0.113179, Val Acc: 0.773196\n",
      "Epoch 21983 - Train Loss: 0.082445, Train Acc: 0.870513 | Val Loss: 0.113178, Val Acc: 0.773196\n",
      "Epoch 21984 - Train Loss: 0.082443, Train Acc: 0.870513 | Val Loss: 0.113177, Val Acc: 0.773196\n",
      "Epoch 21985 - Train Loss: 0.082441, Train Acc: 0.870513 | Val Loss: 0.113176, Val Acc: 0.773196\n",
      "Epoch 21986 - Train Loss: 0.082439, Train Acc: 0.870513 | Val Loss: 0.113175, Val Acc: 0.773196\n",
      "Epoch 21987 - Train Loss: 0.082437, Train Acc: 0.870513 | Val Loss: 0.113175, Val Acc: 0.773196\n",
      "Epoch 21988 - Train Loss: 0.082435, Train Acc: 0.870513 | Val Loss: 0.113174, Val Acc: 0.773196\n",
      "Epoch 21989 - Train Loss: 0.082434, Train Acc: 0.870513 | Val Loss: 0.113173, Val Acc: 0.773196\n",
      "Epoch 21990 - Train Loss: 0.082432, Train Acc: 0.870513 | Val Loss: 0.113172, Val Acc: 0.773196\n",
      "Epoch 21991 - Train Loss: 0.082430, Train Acc: 0.870513 | Val Loss: 0.113171, Val Acc: 0.773196\n",
      "Epoch 21992 - Train Loss: 0.082428, Train Acc: 0.870513 | Val Loss: 0.113170, Val Acc: 0.773196\n",
      "Epoch 21993 - Train Loss: 0.082426, Train Acc: 0.870513 | Val Loss: 0.113170, Val Acc: 0.773196\n",
      "Epoch 21994 - Train Loss: 0.082424, Train Acc: 0.870513 | Val Loss: 0.113169, Val Acc: 0.773196\n",
      "Epoch 21995 - Train Loss: 0.082422, Train Acc: 0.870513 | Val Loss: 0.113168, Val Acc: 0.773196\n",
      "Epoch 21996 - Train Loss: 0.082420, Train Acc: 0.870513 | Val Loss: 0.113167, Val Acc: 0.773196\n",
      "Epoch 21997 - Train Loss: 0.082418, Train Acc: 0.870513 | Val Loss: 0.113166, Val Acc: 0.773196\n",
      "Epoch 21998 - Train Loss: 0.082416, Train Acc: 0.870513 | Val Loss: 0.113166, Val Acc: 0.773196\n",
      "Epoch 21999 - Train Loss: 0.082414, Train Acc: 0.870513 | Val Loss: 0.113165, Val Acc: 0.773196\n",
      "Epoch 22000 - Train Loss: 0.082412, Train Acc: 0.870513 | Val Loss: 0.113164, Val Acc: 0.773196\n",
      "Epoch 22001 - Train Loss: 0.082411, Train Acc: 0.870513 | Val Loss: 0.113163, Val Acc: 0.773196\n",
      "Epoch 22002 - Train Loss: 0.082409, Train Acc: 0.870513 | Val Loss: 0.113163, Val Acc: 0.773196\n",
      "Epoch 22003 - Train Loss: 0.082407, Train Acc: 0.870513 | Val Loss: 0.113162, Val Acc: 0.773196\n",
      "Epoch 22004 - Train Loss: 0.082405, Train Acc: 0.870513 | Val Loss: 0.113161, Val Acc: 0.773196\n",
      "Epoch 22005 - Train Loss: 0.082403, Train Acc: 0.870513 | Val Loss: 0.113160, Val Acc: 0.773196\n",
      "Epoch 22006 - Train Loss: 0.082401, Train Acc: 0.870513 | Val Loss: 0.113159, Val Acc: 0.773196\n",
      "Epoch 22007 - Train Loss: 0.082399, Train Acc: 0.870513 | Val Loss: 0.113159, Val Acc: 0.773196\n",
      "Epoch 22008 - Train Loss: 0.082397, Train Acc: 0.870513 | Val Loss: 0.113158, Val Acc: 0.773196\n",
      "Epoch 22009 - Train Loss: 0.082395, Train Acc: 0.870513 | Val Loss: 0.113157, Val Acc: 0.773196\n",
      "Epoch 22010 - Train Loss: 0.082393, Train Acc: 0.870513 | Val Loss: 0.113156, Val Acc: 0.773196\n",
      "Epoch 22011 - Train Loss: 0.082391, Train Acc: 0.870513 | Val Loss: 0.113155, Val Acc: 0.773196\n",
      "Epoch 22012 - Train Loss: 0.082389, Train Acc: 0.870513 | Val Loss: 0.113155, Val Acc: 0.773196\n",
      "Epoch 22013 - Train Loss: 0.082388, Train Acc: 0.870513 | Val Loss: 0.113154, Val Acc: 0.773196\n",
      "Epoch 22014 - Train Loss: 0.082386, Train Acc: 0.870513 | Val Loss: 0.113153, Val Acc: 0.773196\n",
      "Epoch 22015 - Train Loss: 0.082384, Train Acc: 0.870513 | Val Loss: 0.113152, Val Acc: 0.773196\n",
      "Epoch 22016 - Train Loss: 0.082382, Train Acc: 0.870513 | Val Loss: 0.113152, Val Acc: 0.773196\n",
      "Epoch 22017 - Train Loss: 0.082380, Train Acc: 0.870513 | Val Loss: 0.113151, Val Acc: 0.773196\n",
      "Epoch 22018 - Train Loss: 0.082378, Train Acc: 0.870513 | Val Loss: 0.113150, Val Acc: 0.773196\n",
      "Epoch 22019 - Train Loss: 0.082376, Train Acc: 0.870513 | Val Loss: 0.113149, Val Acc: 0.773196\n",
      "Epoch 22020 - Train Loss: 0.082374, Train Acc: 0.870513 | Val Loss: 0.113148, Val Acc: 0.773196\n",
      "Epoch 22021 - Train Loss: 0.082372, Train Acc: 0.870513 | Val Loss: 0.113148, Val Acc: 0.773196\n",
      "Epoch 22022 - Train Loss: 0.082370, Train Acc: 0.870513 | Val Loss: 0.113147, Val Acc: 0.773196\n",
      "Epoch 22023 - Train Loss: 0.082368, Train Acc: 0.870513 | Val Loss: 0.113146, Val Acc: 0.773196\n",
      "Epoch 22024 - Train Loss: 0.082366, Train Acc: 0.870513 | Val Loss: 0.113145, Val Acc: 0.773196\n",
      "Epoch 22025 - Train Loss: 0.082365, Train Acc: 0.870513 | Val Loss: 0.113144, Val Acc: 0.773196\n",
      "Epoch 22026 - Train Loss: 0.082363, Train Acc: 0.870513 | Val Loss: 0.113144, Val Acc: 0.773196\n",
      "Epoch 22027 - Train Loss: 0.082361, Train Acc: 0.870513 | Val Loss: 0.113143, Val Acc: 0.773196\n",
      "Epoch 22028 - Train Loss: 0.082359, Train Acc: 0.870513 | Val Loss: 0.113142, Val Acc: 0.773196\n",
      "Epoch 22029 - Train Loss: 0.082357, Train Acc: 0.870513 | Val Loss: 0.113141, Val Acc: 0.773196\n",
      "Epoch 22030 - Train Loss: 0.082355, Train Acc: 0.870513 | Val Loss: 0.113141, Val Acc: 0.773196\n",
      "Epoch 22031 - Train Loss: 0.082353, Train Acc: 0.870513 | Val Loss: 0.113140, Val Acc: 0.773196\n",
      "Epoch 22032 - Train Loss: 0.082351, Train Acc: 0.870513 | Val Loss: 0.113139, Val Acc: 0.773196\n",
      "Epoch 22033 - Train Loss: 0.082349, Train Acc: 0.870513 | Val Loss: 0.113138, Val Acc: 0.773196\n",
      "Epoch 22034 - Train Loss: 0.082347, Train Acc: 0.870513 | Val Loss: 0.113137, Val Acc: 0.773196\n",
      "Epoch 22035 - Train Loss: 0.082345, Train Acc: 0.870513 | Val Loss: 0.113137, Val Acc: 0.773196\n",
      "Epoch 22036 - Train Loss: 0.082344, Train Acc: 0.870513 | Val Loss: 0.113136, Val Acc: 0.773196\n",
      "Epoch 22037 - Train Loss: 0.082342, Train Acc: 0.870513 | Val Loss: 0.113135, Val Acc: 0.773196\n",
      "Epoch 22038 - Train Loss: 0.082340, Train Acc: 0.870513 | Val Loss: 0.113134, Val Acc: 0.773196\n",
      "Epoch 22039 - Train Loss: 0.082338, Train Acc: 0.870513 | Val Loss: 0.113133, Val Acc: 0.773196\n",
      "Epoch 22040 - Train Loss: 0.082336, Train Acc: 0.870513 | Val Loss: 0.113133, Val Acc: 0.773196\n",
      "Epoch 22041 - Train Loss: 0.082334, Train Acc: 0.870513 | Val Loss: 0.113132, Val Acc: 0.773196\n",
      "Epoch 22042 - Train Loss: 0.082332, Train Acc: 0.870513 | Val Loss: 0.113131, Val Acc: 0.773196\n",
      "Epoch 22043 - Train Loss: 0.082330, Train Acc: 0.870513 | Val Loss: 0.113130, Val Acc: 0.773196\n",
      "Epoch 22044 - Train Loss: 0.082328, Train Acc: 0.870513 | Val Loss: 0.113129, Val Acc: 0.773196\n",
      "Epoch 22045 - Train Loss: 0.082326, Train Acc: 0.870513 | Val Loss: 0.113129, Val Acc: 0.773196\n",
      "Epoch 22046 - Train Loss: 0.082324, Train Acc: 0.870513 | Val Loss: 0.113128, Val Acc: 0.773196\n",
      "Epoch 22047 - Train Loss: 0.082322, Train Acc: 0.870513 | Val Loss: 0.113127, Val Acc: 0.773196\n",
      "Epoch 22048 - Train Loss: 0.082321, Train Acc: 0.870513 | Val Loss: 0.113126, Val Acc: 0.773196\n",
      "Epoch 22049 - Train Loss: 0.082319, Train Acc: 0.870513 | Val Loss: 0.113125, Val Acc: 0.773196\n",
      "Epoch 22050 - Train Loss: 0.082317, Train Acc: 0.870513 | Val Loss: 0.113125, Val Acc: 0.773196\n",
      "Epoch 22051 - Train Loss: 0.082315, Train Acc: 0.870513 | Val Loss: 0.113124, Val Acc: 0.773196\n",
      "Epoch 22052 - Train Loss: 0.082313, Train Acc: 0.870513 | Val Loss: 0.113123, Val Acc: 0.773196\n",
      "Epoch 22053 - Train Loss: 0.082311, Train Acc: 0.870513 | Val Loss: 0.113122, Val Acc: 0.773196\n",
      "Epoch 22054 - Train Loss: 0.082309, Train Acc: 0.870513 | Val Loss: 0.113121, Val Acc: 0.773196\n",
      "Epoch 22055 - Train Loss: 0.082307, Train Acc: 0.870513 | Val Loss: 0.113121, Val Acc: 0.773196\n",
      "Epoch 22056 - Train Loss: 0.082305, Train Acc: 0.870513 | Val Loss: 0.113120, Val Acc: 0.773196\n",
      "Epoch 22057 - Train Loss: 0.082303, Train Acc: 0.870513 | Val Loss: 0.113119, Val Acc: 0.773196\n",
      "Epoch 22058 - Train Loss: 0.082301, Train Acc: 0.870513 | Val Loss: 0.113118, Val Acc: 0.773196\n",
      "Epoch 22059 - Train Loss: 0.082300, Train Acc: 0.870513 | Val Loss: 0.113118, Val Acc: 0.773196\n",
      "Epoch 22060 - Train Loss: 0.082298, Train Acc: 0.870513 | Val Loss: 0.113117, Val Acc: 0.773196\n",
      "Epoch 22061 - Train Loss: 0.082296, Train Acc: 0.870513 | Val Loss: 0.113116, Val Acc: 0.773196\n",
      "Epoch 22062 - Train Loss: 0.082294, Train Acc: 0.870513 | Val Loss: 0.113115, Val Acc: 0.773196\n",
      "Epoch 22063 - Train Loss: 0.082292, Train Acc: 0.870513 | Val Loss: 0.113114, Val Acc: 0.773196\n",
      "Epoch 22064 - Train Loss: 0.082290, Train Acc: 0.870513 | Val Loss: 0.113114, Val Acc: 0.773196\n",
      "Epoch 22065 - Train Loss: 0.082288, Train Acc: 0.870513 | Val Loss: 0.113113, Val Acc: 0.773196\n",
      "Epoch 22066 - Train Loss: 0.082286, Train Acc: 0.870513 | Val Loss: 0.113112, Val Acc: 0.773196\n",
      "Epoch 22067 - Train Loss: 0.082284, Train Acc: 0.870513 | Val Loss: 0.113111, Val Acc: 0.773196\n",
      "Epoch 22068 - Train Loss: 0.082282, Train Acc: 0.870513 | Val Loss: 0.113110, Val Acc: 0.773196\n",
      "Epoch 22069 - Train Loss: 0.082280, Train Acc: 0.870513 | Val Loss: 0.113110, Val Acc: 0.773196\n",
      "Epoch 22070 - Train Loss: 0.082279, Train Acc: 0.870513 | Val Loss: 0.113109, Val Acc: 0.773196\n",
      "Epoch 22071 - Train Loss: 0.082277, Train Acc: 0.870513 | Val Loss: 0.113108, Val Acc: 0.773196\n",
      "Epoch 22072 - Train Loss: 0.082275, Train Acc: 0.870513 | Val Loss: 0.113107, Val Acc: 0.773196\n",
      "Epoch 22073 - Train Loss: 0.082273, Train Acc: 0.870513 | Val Loss: 0.113106, Val Acc: 0.773196\n",
      "Epoch 22074 - Train Loss: 0.082271, Train Acc: 0.870513 | Val Loss: 0.113106, Val Acc: 0.773196\n",
      "Epoch 22075 - Train Loss: 0.082269, Train Acc: 0.870513 | Val Loss: 0.113105, Val Acc: 0.773196\n",
      "Epoch 22076 - Train Loss: 0.082267, Train Acc: 0.870513 | Val Loss: 0.113104, Val Acc: 0.773196\n",
      "Epoch 22077 - Train Loss: 0.082265, Train Acc: 0.870513 | Val Loss: 0.113103, Val Acc: 0.773196\n",
      "Epoch 22078 - Train Loss: 0.082263, Train Acc: 0.870513 | Val Loss: 0.113102, Val Acc: 0.773196\n",
      "Epoch 22079 - Train Loss: 0.082261, Train Acc: 0.870513 | Val Loss: 0.113102, Val Acc: 0.773196\n",
      "Epoch 22080 - Train Loss: 0.082260, Train Acc: 0.870513 | Val Loss: 0.113101, Val Acc: 0.773196\n",
      "Epoch 22081 - Train Loss: 0.082258, Train Acc: 0.870513 | Val Loss: 0.113100, Val Acc: 0.773196\n",
      "Epoch 22082 - Train Loss: 0.082256, Train Acc: 0.870513 | Val Loss: 0.113099, Val Acc: 0.773196\n",
      "Epoch 22083 - Train Loss: 0.082254, Train Acc: 0.870513 | Val Loss: 0.113098, Val Acc: 0.773196\n",
      "Epoch 22084 - Train Loss: 0.082252, Train Acc: 0.870513 | Val Loss: 0.113098, Val Acc: 0.773196\n",
      "Epoch 22085 - Train Loss: 0.082250, Train Acc: 0.870513 | Val Loss: 0.113097, Val Acc: 0.773196\n",
      "Epoch 22086 - Train Loss: 0.082248, Train Acc: 0.870513 | Val Loss: 0.113096, Val Acc: 0.773196\n",
      "Epoch 22087 - Train Loss: 0.082246, Train Acc: 0.870513 | Val Loss: 0.113095, Val Acc: 0.773196\n",
      "Epoch 22088 - Train Loss: 0.082244, Train Acc: 0.870513 | Val Loss: 0.113094, Val Acc: 0.773196\n",
      "Epoch 22089 - Train Loss: 0.082242, Train Acc: 0.870513 | Val Loss: 0.113094, Val Acc: 0.773196\n",
      "Epoch 22090 - Train Loss: 0.082240, Train Acc: 0.870513 | Val Loss: 0.113093, Val Acc: 0.773196\n",
      "Epoch 22091 - Train Loss: 0.082239, Train Acc: 0.870513 | Val Loss: 0.113092, Val Acc: 0.773196\n",
      "Epoch 22092 - Train Loss: 0.082237, Train Acc: 0.870513 | Val Loss: 0.113091, Val Acc: 0.773196\n",
      "Epoch 22093 - Train Loss: 0.082235, Train Acc: 0.870513 | Val Loss: 0.113090, Val Acc: 0.773196\n",
      "Epoch 22094 - Train Loss: 0.082233, Train Acc: 0.870513 | Val Loss: 0.113090, Val Acc: 0.773196\n",
      "Epoch 22095 - Train Loss: 0.082231, Train Acc: 0.870513 | Val Loss: 0.113089, Val Acc: 0.773196\n",
      "Epoch 22096 - Train Loss: 0.082229, Train Acc: 0.870513 | Val Loss: 0.113088, Val Acc: 0.773196\n",
      "Epoch 22097 - Train Loss: 0.082227, Train Acc: 0.870513 | Val Loss: 0.113087, Val Acc: 0.773196\n",
      "Epoch 22098 - Train Loss: 0.082225, Train Acc: 0.870513 | Val Loss: 0.113087, Val Acc: 0.773196\n",
      "Epoch 22099 - Train Loss: 0.082223, Train Acc: 0.870513 | Val Loss: 0.113086, Val Acc: 0.773196\n",
      "Epoch 22100 - Train Loss: 0.082221, Train Acc: 0.870513 | Val Loss: 0.113085, Val Acc: 0.773196\n",
      "Epoch 22101 - Train Loss: 0.082220, Train Acc: 0.870513 | Val Loss: 0.113084, Val Acc: 0.773196\n",
      "Epoch 22102 - Train Loss: 0.082218, Train Acc: 0.870513 | Val Loss: 0.113083, Val Acc: 0.773196\n",
      "Epoch 22103 - Train Loss: 0.082216, Train Acc: 0.870513 | Val Loss: 0.113083, Val Acc: 0.773196\n",
      "Epoch 22104 - Train Loss: 0.082214, Train Acc: 0.870513 | Val Loss: 0.113082, Val Acc: 0.773196\n",
      "Epoch 22105 - Train Loss: 0.082212, Train Acc: 0.870513 | Val Loss: 0.113081, Val Acc: 0.773196\n",
      "Epoch 22106 - Train Loss: 0.082210, Train Acc: 0.870513 | Val Loss: 0.113080, Val Acc: 0.773196\n",
      "Epoch 22107 - Train Loss: 0.082208, Train Acc: 0.870513 | Val Loss: 0.113079, Val Acc: 0.773196\n",
      "Epoch 22108 - Train Loss: 0.082206, Train Acc: 0.870513 | Val Loss: 0.113079, Val Acc: 0.773196\n",
      "Epoch 22109 - Train Loss: 0.082204, Train Acc: 0.870513 | Val Loss: 0.113078, Val Acc: 0.773196\n",
      "Epoch 22110 - Train Loss: 0.082202, Train Acc: 0.870513 | Val Loss: 0.113077, Val Acc: 0.773196\n",
      "Epoch 22111 - Train Loss: 0.082200, Train Acc: 0.870513 | Val Loss: 0.113076, Val Acc: 0.773196\n",
      "Epoch 22112 - Train Loss: 0.082199, Train Acc: 0.870513 | Val Loss: 0.113075, Val Acc: 0.773196\n",
      "Epoch 22113 - Train Loss: 0.082197, Train Acc: 0.870513 | Val Loss: 0.113075, Val Acc: 0.773196\n",
      "Epoch 22114 - Train Loss: 0.082195, Train Acc: 0.870513 | Val Loss: 0.113074, Val Acc: 0.773196\n",
      "Epoch 22115 - Train Loss: 0.082193, Train Acc: 0.870513 | Val Loss: 0.113073, Val Acc: 0.773196\n",
      "Epoch 22116 - Train Loss: 0.082191, Train Acc: 0.870513 | Val Loss: 0.113072, Val Acc: 0.773196\n",
      "Epoch 22117 - Train Loss: 0.082189, Train Acc: 0.870513 | Val Loss: 0.113071, Val Acc: 0.773196\n",
      "Epoch 22118 - Train Loss: 0.082187, Train Acc: 0.870513 | Val Loss: 0.113071, Val Acc: 0.773196\n",
      "Epoch 22119 - Train Loss: 0.082185, Train Acc: 0.870513 | Val Loss: 0.113070, Val Acc: 0.773196\n",
      "Epoch 22120 - Train Loss: 0.082183, Train Acc: 0.870513 | Val Loss: 0.113069, Val Acc: 0.773196\n",
      "Epoch 22121 - Train Loss: 0.082181, Train Acc: 0.870513 | Val Loss: 0.113068, Val Acc: 0.773196\n",
      "Epoch 22122 - Train Loss: 0.082180, Train Acc: 0.870513 | Val Loss: 0.113068, Val Acc: 0.773196\n",
      "Epoch 22123 - Train Loss: 0.082178, Train Acc: 0.870513 | Val Loss: 0.113067, Val Acc: 0.773196\n",
      "Epoch 22124 - Train Loss: 0.082176, Train Acc: 0.870513 | Val Loss: 0.113066, Val Acc: 0.773196\n",
      "Epoch 22125 - Train Loss: 0.082174, Train Acc: 0.870513 | Val Loss: 0.113065, Val Acc: 0.773196\n",
      "Epoch 22126 - Train Loss: 0.082172, Train Acc: 0.870513 | Val Loss: 0.113064, Val Acc: 0.773196\n",
      "Epoch 22127 - Train Loss: 0.082170, Train Acc: 0.870513 | Val Loss: 0.113064, Val Acc: 0.773196\n",
      "Epoch 22128 - Train Loss: 0.082168, Train Acc: 0.870513 | Val Loss: 0.113063, Val Acc: 0.773196\n",
      "Epoch 22129 - Train Loss: 0.082166, Train Acc: 0.870513 | Val Loss: 0.113062, Val Acc: 0.773196\n",
      "Epoch 22130 - Train Loss: 0.082164, Train Acc: 0.870513 | Val Loss: 0.113061, Val Acc: 0.773196\n",
      "Epoch 22131 - Train Loss: 0.082162, Train Acc: 0.870513 | Val Loss: 0.113060, Val Acc: 0.773196\n",
      "Epoch 22132 - Train Loss: 0.082161, Train Acc: 0.870513 | Val Loss: 0.113060, Val Acc: 0.773196\n",
      "Epoch 22133 - Train Loss: 0.082159, Train Acc: 0.870513 | Val Loss: 0.113059, Val Acc: 0.773196\n",
      "Epoch 22134 - Train Loss: 0.082157, Train Acc: 0.870513 | Val Loss: 0.113058, Val Acc: 0.773196\n",
      "Epoch 22135 - Train Loss: 0.082155, Train Acc: 0.870513 | Val Loss: 0.113057, Val Acc: 0.773196\n",
      "Epoch 22136 - Train Loss: 0.082153, Train Acc: 0.870513 | Val Loss: 0.113056, Val Acc: 0.773196\n",
      "Epoch 22137 - Train Loss: 0.082151, Train Acc: 0.870513 | Val Loss: 0.113056, Val Acc: 0.773196\n",
      "Epoch 22138 - Train Loss: 0.082149, Train Acc: 0.870513 | Val Loss: 0.113055, Val Acc: 0.773196\n",
      "Epoch 22139 - Train Loss: 0.082147, Train Acc: 0.870513 | Val Loss: 0.113054, Val Acc: 0.773196\n",
      "Epoch 22140 - Train Loss: 0.082145, Train Acc: 0.870513 | Val Loss: 0.113053, Val Acc: 0.773196\n",
      "Epoch 22141 - Train Loss: 0.082143, Train Acc: 0.870513 | Val Loss: 0.113053, Val Acc: 0.773196\n",
      "Epoch 22142 - Train Loss: 0.082142, Train Acc: 0.870513 | Val Loss: 0.113052, Val Acc: 0.773196\n",
      "Epoch 22143 - Train Loss: 0.082140, Train Acc: 0.870513 | Val Loss: 0.113051, Val Acc: 0.773196\n",
      "Epoch 22144 - Train Loss: 0.082138, Train Acc: 0.870513 | Val Loss: 0.113050, Val Acc: 0.773196\n",
      "Epoch 22145 - Train Loss: 0.082136, Train Acc: 0.870513 | Val Loss: 0.113049, Val Acc: 0.773196\n",
      "Epoch 22146 - Train Loss: 0.082134, Train Acc: 0.870513 | Val Loss: 0.113049, Val Acc: 0.773196\n",
      "Epoch 22147 - Train Loss: 0.082132, Train Acc: 0.870513 | Val Loss: 0.113048, Val Acc: 0.773196\n",
      "Epoch 22148 - Train Loss: 0.082130, Train Acc: 0.870513 | Val Loss: 0.113047, Val Acc: 0.773196\n",
      "Epoch 22149 - Train Loss: 0.082128, Train Acc: 0.870513 | Val Loss: 0.113046, Val Acc: 0.773196\n",
      "Epoch 22150 - Train Loss: 0.082126, Train Acc: 0.870513 | Val Loss: 0.113045, Val Acc: 0.773196\n",
      "Epoch 22151 - Train Loss: 0.082124, Train Acc: 0.870513 | Val Loss: 0.113045, Val Acc: 0.773196\n",
      "Epoch 22152 - Train Loss: 0.082123, Train Acc: 0.870513 | Val Loss: 0.113044, Val Acc: 0.773196\n",
      "Epoch 22153 - Train Loss: 0.082121, Train Acc: 0.870513 | Val Loss: 0.113043, Val Acc: 0.773196\n",
      "Epoch 22154 - Train Loss: 0.082119, Train Acc: 0.870513 | Val Loss: 0.113042, Val Acc: 0.773196\n",
      "Epoch 22155 - Train Loss: 0.082117, Train Acc: 0.870513 | Val Loss: 0.113041, Val Acc: 0.773196\n",
      "Epoch 22156 - Train Loss: 0.082115, Train Acc: 0.870513 | Val Loss: 0.113041, Val Acc: 0.773196\n",
      "Epoch 22157 - Train Loss: 0.082113, Train Acc: 0.870513 | Val Loss: 0.113040, Val Acc: 0.773196\n",
      "Epoch 22158 - Train Loss: 0.082111, Train Acc: 0.870513 | Val Loss: 0.113039, Val Acc: 0.773196\n",
      "Epoch 22159 - Train Loss: 0.082109, Train Acc: 0.870513 | Val Loss: 0.113038, Val Acc: 0.773196\n",
      "Epoch 22160 - Train Loss: 0.082107, Train Acc: 0.870513 | Val Loss: 0.113038, Val Acc: 0.773196\n",
      "Epoch 22161 - Train Loss: 0.082106, Train Acc: 0.870513 | Val Loss: 0.113037, Val Acc: 0.773196\n",
      "Epoch 22162 - Train Loss: 0.082104, Train Acc: 0.870513 | Val Loss: 0.113036, Val Acc: 0.773196\n",
      "Epoch 22163 - Train Loss: 0.082102, Train Acc: 0.870513 | Val Loss: 0.113035, Val Acc: 0.773196\n",
      "Epoch 22164 - Train Loss: 0.082100, Train Acc: 0.870513 | Val Loss: 0.113034, Val Acc: 0.773196\n",
      "Epoch 22165 - Train Loss: 0.082098, Train Acc: 0.870513 | Val Loss: 0.113034, Val Acc: 0.773196\n",
      "Epoch 22166 - Train Loss: 0.082096, Train Acc: 0.870513 | Val Loss: 0.113033, Val Acc: 0.773196\n",
      "Epoch 22167 - Train Loss: 0.082094, Train Acc: 0.870513 | Val Loss: 0.113032, Val Acc: 0.773196\n",
      "Epoch 22168 - Train Loss: 0.082092, Train Acc: 0.870513 | Val Loss: 0.113031, Val Acc: 0.773196\n",
      "Epoch 22169 - Train Loss: 0.082090, Train Acc: 0.870513 | Val Loss: 0.113030, Val Acc: 0.773196\n",
      "Epoch 22170 - Train Loss: 0.082088, Train Acc: 0.870513 | Val Loss: 0.113030, Val Acc: 0.773196\n",
      "Epoch 22171 - Train Loss: 0.082087, Train Acc: 0.870513 | Val Loss: 0.113029, Val Acc: 0.773196\n",
      "Epoch 22172 - Train Loss: 0.082085, Train Acc: 0.870513 | Val Loss: 0.113028, Val Acc: 0.773196\n",
      "Epoch 22173 - Train Loss: 0.082083, Train Acc: 0.870513 | Val Loss: 0.113027, Val Acc: 0.773196\n",
      "Epoch 22174 - Train Loss: 0.082081, Train Acc: 0.870513 | Val Loss: 0.113027, Val Acc: 0.773196\n",
      "Epoch 22175 - Train Loss: 0.082079, Train Acc: 0.870513 | Val Loss: 0.113026, Val Acc: 0.773196\n",
      "Epoch 22176 - Train Loss: 0.082077, Train Acc: 0.870513 | Val Loss: 0.113025, Val Acc: 0.773196\n",
      "Epoch 22177 - Train Loss: 0.082075, Train Acc: 0.870513 | Val Loss: 0.113024, Val Acc: 0.773196\n",
      "Epoch 22178 - Train Loss: 0.082073, Train Acc: 0.870513 | Val Loss: 0.113023, Val Acc: 0.773196\n",
      "Epoch 22179 - Train Loss: 0.082071, Train Acc: 0.870513 | Val Loss: 0.113023, Val Acc: 0.773196\n",
      "Epoch 22180 - Train Loss: 0.082070, Train Acc: 0.870513 | Val Loss: 0.113022, Val Acc: 0.773196\n",
      "Epoch 22181 - Train Loss: 0.082068, Train Acc: 0.870513 | Val Loss: 0.113021, Val Acc: 0.773196\n",
      "Epoch 22182 - Train Loss: 0.082066, Train Acc: 0.870513 | Val Loss: 0.113020, Val Acc: 0.773196\n",
      "Epoch 22183 - Train Loss: 0.082064, Train Acc: 0.870513 | Val Loss: 0.113019, Val Acc: 0.773196\n",
      "Epoch 22184 - Train Loss: 0.082062, Train Acc: 0.870513 | Val Loss: 0.113019, Val Acc: 0.773196\n",
      "Epoch 22185 - Train Loss: 0.082060, Train Acc: 0.870513 | Val Loss: 0.113018, Val Acc: 0.773196\n",
      "Epoch 22186 - Train Loss: 0.082058, Train Acc: 0.870513 | Val Loss: 0.113017, Val Acc: 0.773196\n",
      "Epoch 22187 - Train Loss: 0.082056, Train Acc: 0.870513 | Val Loss: 0.113016, Val Acc: 0.773196\n",
      "Epoch 22188 - Train Loss: 0.082054, Train Acc: 0.870513 | Val Loss: 0.113016, Val Acc: 0.773196\n",
      "Epoch 22189 - Train Loss: 0.082053, Train Acc: 0.870513 | Val Loss: 0.113015, Val Acc: 0.773196\n",
      "Epoch 22190 - Train Loss: 0.082051, Train Acc: 0.870513 | Val Loss: 0.113014, Val Acc: 0.773196\n",
      "Epoch 22191 - Train Loss: 0.082049, Train Acc: 0.870513 | Val Loss: 0.113013, Val Acc: 0.773196\n",
      "Epoch 22192 - Train Loss: 0.082047, Train Acc: 0.870513 | Val Loss: 0.113012, Val Acc: 0.773196\n",
      "Epoch 22193 - Train Loss: 0.082045, Train Acc: 0.870513 | Val Loss: 0.113012, Val Acc: 0.773196\n",
      "Epoch 22194 - Train Loss: 0.082043, Train Acc: 0.870513 | Val Loss: 0.113011, Val Acc: 0.773196\n",
      "Epoch 22195 - Train Loss: 0.082041, Train Acc: 0.871795 | Val Loss: 0.113010, Val Acc: 0.773196\n",
      "Epoch 22196 - Train Loss: 0.082039, Train Acc: 0.871795 | Val Loss: 0.113009, Val Acc: 0.773196\n",
      "Epoch 22197 - Train Loss: 0.082037, Train Acc: 0.871795 | Val Loss: 0.113008, Val Acc: 0.773196\n",
      "Epoch 22198 - Train Loss: 0.082035, Train Acc: 0.871795 | Val Loss: 0.113008, Val Acc: 0.773196\n",
      "Epoch 22199 - Train Loss: 0.082034, Train Acc: 0.871795 | Val Loss: 0.113007, Val Acc: 0.773196\n",
      "Epoch 22200 - Train Loss: 0.082032, Train Acc: 0.871795 | Val Loss: 0.113006, Val Acc: 0.773196\n",
      "Epoch 22201 - Train Loss: 0.082030, Train Acc: 0.871795 | Val Loss: 0.113005, Val Acc: 0.773196\n",
      "Epoch 22202 - Train Loss: 0.082028, Train Acc: 0.871795 | Val Loss: 0.113005, Val Acc: 0.773196\n",
      "Epoch 22203 - Train Loss: 0.082026, Train Acc: 0.871795 | Val Loss: 0.113004, Val Acc: 0.773196\n",
      "Epoch 22204 - Train Loss: 0.082024, Train Acc: 0.871795 | Val Loss: 0.113003, Val Acc: 0.773196\n",
      "Epoch 22205 - Train Loss: 0.082022, Train Acc: 0.871795 | Val Loss: 0.113002, Val Acc: 0.773196\n",
      "Epoch 22206 - Train Loss: 0.082020, Train Acc: 0.871795 | Val Loss: 0.113001, Val Acc: 0.773196\n",
      "Epoch 22207 - Train Loss: 0.082018, Train Acc: 0.871795 | Val Loss: 0.113001, Val Acc: 0.773196\n",
      "Epoch 22208 - Train Loss: 0.082017, Train Acc: 0.871795 | Val Loss: 0.113000, Val Acc: 0.773196\n",
      "Epoch 22209 - Train Loss: 0.082015, Train Acc: 0.871795 | Val Loss: 0.112999, Val Acc: 0.773196\n",
      "Epoch 22210 - Train Loss: 0.082013, Train Acc: 0.871795 | Val Loss: 0.112998, Val Acc: 0.773196\n",
      "Epoch 22211 - Train Loss: 0.082011, Train Acc: 0.871795 | Val Loss: 0.112998, Val Acc: 0.773196\n",
      "Epoch 22212 - Train Loss: 0.082009, Train Acc: 0.871795 | Val Loss: 0.112997, Val Acc: 0.773196\n",
      "Epoch 22213 - Train Loss: 0.082007, Train Acc: 0.871795 | Val Loss: 0.112996, Val Acc: 0.773196\n",
      "Epoch 22214 - Train Loss: 0.082005, Train Acc: 0.871795 | Val Loss: 0.112995, Val Acc: 0.773196\n",
      "Epoch 22215 - Train Loss: 0.082003, Train Acc: 0.871795 | Val Loss: 0.112994, Val Acc: 0.773196\n",
      "Epoch 22216 - Train Loss: 0.082001, Train Acc: 0.871795 | Val Loss: 0.112994, Val Acc: 0.773196\n",
      "Epoch 22217 - Train Loss: 0.082000, Train Acc: 0.871795 | Val Loss: 0.112993, Val Acc: 0.773196\n",
      "Epoch 22218 - Train Loss: 0.081998, Train Acc: 0.871795 | Val Loss: 0.112992, Val Acc: 0.773196\n",
      "Epoch 22219 - Train Loss: 0.081996, Train Acc: 0.871795 | Val Loss: 0.112991, Val Acc: 0.773196\n",
      "Epoch 22220 - Train Loss: 0.081994, Train Acc: 0.871795 | Val Loss: 0.112991, Val Acc: 0.773196\n",
      "Epoch 22221 - Train Loss: 0.081992, Train Acc: 0.871795 | Val Loss: 0.112990, Val Acc: 0.773196\n",
      "Epoch 22222 - Train Loss: 0.081990, Train Acc: 0.871795 | Val Loss: 0.112989, Val Acc: 0.773196\n",
      "Epoch 22223 - Train Loss: 0.081988, Train Acc: 0.871795 | Val Loss: 0.112988, Val Acc: 0.773196\n",
      "Epoch 22224 - Train Loss: 0.081986, Train Acc: 0.871795 | Val Loss: 0.112987, Val Acc: 0.773196\n",
      "Epoch 22225 - Train Loss: 0.081985, Train Acc: 0.871795 | Val Loss: 0.112987, Val Acc: 0.773196\n",
      "Epoch 22226 - Train Loss: 0.081983, Train Acc: 0.871795 | Val Loss: 0.112986, Val Acc: 0.773196\n",
      "Epoch 22227 - Train Loss: 0.081981, Train Acc: 0.871795 | Val Loss: 0.112985, Val Acc: 0.773196\n",
      "Epoch 22228 - Train Loss: 0.081979, Train Acc: 0.871795 | Val Loss: 0.112984, Val Acc: 0.773196\n",
      "Epoch 22229 - Train Loss: 0.081977, Train Acc: 0.871795 | Val Loss: 0.112984, Val Acc: 0.773196\n",
      "Epoch 22230 - Train Loss: 0.081975, Train Acc: 0.871795 | Val Loss: 0.112983, Val Acc: 0.773196\n",
      "Epoch 22231 - Train Loss: 0.081973, Train Acc: 0.871795 | Val Loss: 0.112982, Val Acc: 0.773196\n",
      "Epoch 22232 - Train Loss: 0.081971, Train Acc: 0.871795 | Val Loss: 0.112981, Val Acc: 0.773196\n",
      "Epoch 22233 - Train Loss: 0.081969, Train Acc: 0.871795 | Val Loss: 0.112980, Val Acc: 0.773196\n",
      "Epoch 22234 - Train Loss: 0.081968, Train Acc: 0.871795 | Val Loss: 0.112980, Val Acc: 0.773196\n",
      "Epoch 22235 - Train Loss: 0.081966, Train Acc: 0.871795 | Val Loss: 0.112979, Val Acc: 0.773196\n",
      "Epoch 22236 - Train Loss: 0.081964, Train Acc: 0.871795 | Val Loss: 0.112978, Val Acc: 0.773196\n",
      "Epoch 22237 - Train Loss: 0.081962, Train Acc: 0.871795 | Val Loss: 0.112977, Val Acc: 0.773196\n",
      "Epoch 22238 - Train Loss: 0.081960, Train Acc: 0.871795 | Val Loss: 0.112976, Val Acc: 0.773196\n",
      "Epoch 22239 - Train Loss: 0.081958, Train Acc: 0.871795 | Val Loss: 0.112976, Val Acc: 0.773196\n",
      "Epoch 22240 - Train Loss: 0.081956, Train Acc: 0.871795 | Val Loss: 0.112975, Val Acc: 0.773196\n",
      "Epoch 22241 - Train Loss: 0.081954, Train Acc: 0.871795 | Val Loss: 0.112974, Val Acc: 0.773196\n",
      "Epoch 22242 - Train Loss: 0.081952, Train Acc: 0.871795 | Val Loss: 0.112973, Val Acc: 0.773196\n",
      "Epoch 22243 - Train Loss: 0.081951, Train Acc: 0.871795 | Val Loss: 0.112973, Val Acc: 0.773196\n",
      "Epoch 22244 - Train Loss: 0.081949, Train Acc: 0.871795 | Val Loss: 0.112972, Val Acc: 0.773196\n",
      "Epoch 22245 - Train Loss: 0.081947, Train Acc: 0.871795 | Val Loss: 0.112971, Val Acc: 0.773196\n",
      "Epoch 22246 - Train Loss: 0.081945, Train Acc: 0.871795 | Val Loss: 0.112970, Val Acc: 0.773196\n",
      "Epoch 22247 - Train Loss: 0.081943, Train Acc: 0.871795 | Val Loss: 0.112969, Val Acc: 0.773196\n",
      "Epoch 22248 - Train Loss: 0.081941, Train Acc: 0.871795 | Val Loss: 0.112969, Val Acc: 0.773196\n",
      "Epoch 22249 - Train Loss: 0.081939, Train Acc: 0.871795 | Val Loss: 0.112968, Val Acc: 0.773196\n",
      "Epoch 22250 - Train Loss: 0.081937, Train Acc: 0.871795 | Val Loss: 0.112967, Val Acc: 0.773196\n",
      "Epoch 22251 - Train Loss: 0.081935, Train Acc: 0.871795 | Val Loss: 0.112966, Val Acc: 0.773196\n",
      "Epoch 22252 - Train Loss: 0.081934, Train Acc: 0.871795 | Val Loss: 0.112966, Val Acc: 0.773196\n",
      "Epoch 22253 - Train Loss: 0.081932, Train Acc: 0.871795 | Val Loss: 0.112965, Val Acc: 0.773196\n",
      "Epoch 22254 - Train Loss: 0.081930, Train Acc: 0.871795 | Val Loss: 0.112964, Val Acc: 0.773196\n",
      "Epoch 22255 - Train Loss: 0.081928, Train Acc: 0.871795 | Val Loss: 0.112963, Val Acc: 0.773196\n",
      "Epoch 22256 - Train Loss: 0.081926, Train Acc: 0.871795 | Val Loss: 0.112963, Val Acc: 0.773196\n",
      "Epoch 22257 - Train Loss: 0.081924, Train Acc: 0.871795 | Val Loss: 0.112962, Val Acc: 0.773196\n",
      "Epoch 22258 - Train Loss: 0.081922, Train Acc: 0.871795 | Val Loss: 0.112961, Val Acc: 0.773196\n",
      "Epoch 22259 - Train Loss: 0.081920, Train Acc: 0.871795 | Val Loss: 0.112960, Val Acc: 0.773196\n",
      "Epoch 22260 - Train Loss: 0.081919, Train Acc: 0.871795 | Val Loss: 0.112959, Val Acc: 0.773196\n",
      "Epoch 22261 - Train Loss: 0.081917, Train Acc: 0.871795 | Val Loss: 0.112959, Val Acc: 0.773196\n",
      "Epoch 22262 - Train Loss: 0.081915, Train Acc: 0.871795 | Val Loss: 0.112958, Val Acc: 0.773196\n",
      "Epoch 22263 - Train Loss: 0.081913, Train Acc: 0.871795 | Val Loss: 0.112957, Val Acc: 0.773196\n",
      "Epoch 22264 - Train Loss: 0.081911, Train Acc: 0.871795 | Val Loss: 0.112956, Val Acc: 0.773196\n",
      "Epoch 22265 - Train Loss: 0.081909, Train Acc: 0.871795 | Val Loss: 0.112956, Val Acc: 0.773196\n",
      "Epoch 22266 - Train Loss: 0.081907, Train Acc: 0.871795 | Val Loss: 0.112955, Val Acc: 0.773196\n",
      "Epoch 22267 - Train Loss: 0.081905, Train Acc: 0.871795 | Val Loss: 0.112954, Val Acc: 0.773196\n",
      "Epoch 22268 - Train Loss: 0.081903, Train Acc: 0.871795 | Val Loss: 0.112953, Val Acc: 0.773196\n",
      "Epoch 22269 - Train Loss: 0.081902, Train Acc: 0.871795 | Val Loss: 0.112952, Val Acc: 0.773196\n",
      "Epoch 22270 - Train Loss: 0.081900, Train Acc: 0.871795 | Val Loss: 0.112952, Val Acc: 0.773196\n",
      "Epoch 22271 - Train Loss: 0.081898, Train Acc: 0.871795 | Val Loss: 0.112951, Val Acc: 0.773196\n",
      "Epoch 22272 - Train Loss: 0.081896, Train Acc: 0.871795 | Val Loss: 0.112950, Val Acc: 0.773196\n",
      "Epoch 22273 - Train Loss: 0.081894, Train Acc: 0.871795 | Val Loss: 0.112949, Val Acc: 0.773196\n",
      "Epoch 22274 - Train Loss: 0.081892, Train Acc: 0.871795 | Val Loss: 0.112949, Val Acc: 0.773196\n",
      "Epoch 22275 - Train Loss: 0.081890, Train Acc: 0.871795 | Val Loss: 0.112948, Val Acc: 0.773196\n",
      "Epoch 22276 - Train Loss: 0.081888, Train Acc: 0.871795 | Val Loss: 0.112947, Val Acc: 0.773196\n",
      "Epoch 22277 - Train Loss: 0.081887, Train Acc: 0.871795 | Val Loss: 0.112946, Val Acc: 0.773196\n",
      "Epoch 22278 - Train Loss: 0.081885, Train Acc: 0.871795 | Val Loss: 0.112945, Val Acc: 0.773196\n",
      "Epoch 22279 - Train Loss: 0.081883, Train Acc: 0.871795 | Val Loss: 0.112945, Val Acc: 0.773196\n",
      "Epoch 22280 - Train Loss: 0.081881, Train Acc: 0.871795 | Val Loss: 0.112944, Val Acc: 0.773196\n",
      "Epoch 22281 - Train Loss: 0.081879, Train Acc: 0.871795 | Val Loss: 0.112943, Val Acc: 0.773196\n",
      "Epoch 22282 - Train Loss: 0.081877, Train Acc: 0.871795 | Val Loss: 0.112942, Val Acc: 0.773196\n",
      "Epoch 22283 - Train Loss: 0.081875, Train Acc: 0.871795 | Val Loss: 0.112942, Val Acc: 0.773196\n",
      "Epoch 22284 - Train Loss: 0.081873, Train Acc: 0.871795 | Val Loss: 0.112941, Val Acc: 0.773196\n",
      "Epoch 22285 - Train Loss: 0.081872, Train Acc: 0.871795 | Val Loss: 0.112940, Val Acc: 0.773196\n",
      "Epoch 22286 - Train Loss: 0.081870, Train Acc: 0.871795 | Val Loss: 0.112939, Val Acc: 0.773196\n",
      "Epoch 22287 - Train Loss: 0.081868, Train Acc: 0.871795 | Val Loss: 0.112939, Val Acc: 0.773196\n",
      "Epoch 22288 - Train Loss: 0.081866, Train Acc: 0.871795 | Val Loss: 0.112938, Val Acc: 0.773196\n",
      "Epoch 22289 - Train Loss: 0.081864, Train Acc: 0.871795 | Val Loss: 0.112937, Val Acc: 0.773196\n",
      "Epoch 22290 - Train Loss: 0.081862, Train Acc: 0.871795 | Val Loss: 0.112936, Val Acc: 0.773196\n",
      "Epoch 22291 - Train Loss: 0.081860, Train Acc: 0.871795 | Val Loss: 0.112935, Val Acc: 0.773196\n",
      "Epoch 22292 - Train Loss: 0.081858, Train Acc: 0.871795 | Val Loss: 0.112935, Val Acc: 0.773196\n",
      "Epoch 22293 - Train Loss: 0.081857, Train Acc: 0.871795 | Val Loss: 0.112934, Val Acc: 0.773196\n",
      "Epoch 22294 - Train Loss: 0.081855, Train Acc: 0.871795 | Val Loss: 0.112933, Val Acc: 0.773196\n",
      "Epoch 22295 - Train Loss: 0.081853, Train Acc: 0.871795 | Val Loss: 0.112932, Val Acc: 0.773196\n",
      "Epoch 22296 - Train Loss: 0.081851, Train Acc: 0.871795 | Val Loss: 0.112932, Val Acc: 0.773196\n",
      "Epoch 22297 - Train Loss: 0.081849, Train Acc: 0.871795 | Val Loss: 0.112931, Val Acc: 0.773196\n",
      "Epoch 22298 - Train Loss: 0.081847, Train Acc: 0.871795 | Val Loss: 0.112930, Val Acc: 0.773196\n",
      "Epoch 22299 - Train Loss: 0.081845, Train Acc: 0.871795 | Val Loss: 0.112929, Val Acc: 0.773196\n",
      "Epoch 22300 - Train Loss: 0.081843, Train Acc: 0.871795 | Val Loss: 0.112928, Val Acc: 0.773196\n",
      "Epoch 22301 - Train Loss: 0.081841, Train Acc: 0.871795 | Val Loss: 0.112928, Val Acc: 0.773196\n",
      "Epoch 22302 - Train Loss: 0.081840, Train Acc: 0.871795 | Val Loss: 0.112927, Val Acc: 0.773196\n",
      "Epoch 22303 - Train Loss: 0.081838, Train Acc: 0.871795 | Val Loss: 0.112926, Val Acc: 0.773196\n",
      "Epoch 22304 - Train Loss: 0.081836, Train Acc: 0.871795 | Val Loss: 0.112925, Val Acc: 0.773196\n",
      "Epoch 22305 - Train Loss: 0.081834, Train Acc: 0.871795 | Val Loss: 0.112925, Val Acc: 0.773196\n",
      "Epoch 22306 - Train Loss: 0.081832, Train Acc: 0.871795 | Val Loss: 0.112924, Val Acc: 0.773196\n",
      "Epoch 22307 - Train Loss: 0.081830, Train Acc: 0.871795 | Val Loss: 0.112923, Val Acc: 0.773196\n",
      "Epoch 22308 - Train Loss: 0.081828, Train Acc: 0.871795 | Val Loss: 0.112922, Val Acc: 0.773196\n",
      "Epoch 22309 - Train Loss: 0.081826, Train Acc: 0.871795 | Val Loss: 0.112922, Val Acc: 0.773196\n",
      "Epoch 22310 - Train Loss: 0.081825, Train Acc: 0.871795 | Val Loss: 0.112921, Val Acc: 0.773196\n",
      "Epoch 22311 - Train Loss: 0.081823, Train Acc: 0.871795 | Val Loss: 0.112920, Val Acc: 0.773196\n",
      "Epoch 22312 - Train Loss: 0.081821, Train Acc: 0.871795 | Val Loss: 0.112919, Val Acc: 0.773196\n",
      "Epoch 22313 - Train Loss: 0.081819, Train Acc: 0.871795 | Val Loss: 0.112918, Val Acc: 0.773196\n",
      "Epoch 22314 - Train Loss: 0.081817, Train Acc: 0.871795 | Val Loss: 0.112918, Val Acc: 0.773196\n",
      "Epoch 22315 - Train Loss: 0.081815, Train Acc: 0.871795 | Val Loss: 0.112917, Val Acc: 0.773196\n",
      "Epoch 22316 - Train Loss: 0.081813, Train Acc: 0.871795 | Val Loss: 0.112916, Val Acc: 0.773196\n",
      "Epoch 22317 - Train Loss: 0.081811, Train Acc: 0.871795 | Val Loss: 0.112915, Val Acc: 0.773196\n",
      "Epoch 22318 - Train Loss: 0.081810, Train Acc: 0.871795 | Val Loss: 0.112915, Val Acc: 0.773196\n",
      "Epoch 22319 - Train Loss: 0.081808, Train Acc: 0.871795 | Val Loss: 0.112914, Val Acc: 0.773196\n",
      "Epoch 22320 - Train Loss: 0.081806, Train Acc: 0.871795 | Val Loss: 0.112913, Val Acc: 0.773196\n",
      "Epoch 22321 - Train Loss: 0.081804, Train Acc: 0.871795 | Val Loss: 0.112912, Val Acc: 0.773196\n",
      "Epoch 22322 - Train Loss: 0.081802, Train Acc: 0.871795 | Val Loss: 0.112912, Val Acc: 0.773196\n",
      "Epoch 22323 - Train Loss: 0.081800, Train Acc: 0.871795 | Val Loss: 0.112911, Val Acc: 0.773196\n",
      "Epoch 22324 - Train Loss: 0.081798, Train Acc: 0.871795 | Val Loss: 0.112910, Val Acc: 0.773196\n",
      "Epoch 22325 - Train Loss: 0.081796, Train Acc: 0.871795 | Val Loss: 0.112909, Val Acc: 0.773196\n",
      "Epoch 22326 - Train Loss: 0.081795, Train Acc: 0.871795 | Val Loss: 0.112908, Val Acc: 0.773196\n",
      "Epoch 22327 - Train Loss: 0.081793, Train Acc: 0.871795 | Val Loss: 0.112908, Val Acc: 0.773196\n",
      "Epoch 22328 - Train Loss: 0.081791, Train Acc: 0.871795 | Val Loss: 0.112907, Val Acc: 0.773196\n",
      "Epoch 22329 - Train Loss: 0.081789, Train Acc: 0.871795 | Val Loss: 0.112906, Val Acc: 0.773196\n",
      "Epoch 22330 - Train Loss: 0.081787, Train Acc: 0.871795 | Val Loss: 0.112905, Val Acc: 0.773196\n",
      "Epoch 22331 - Train Loss: 0.081785, Train Acc: 0.871795 | Val Loss: 0.112905, Val Acc: 0.773196\n",
      "Epoch 22332 - Train Loss: 0.081783, Train Acc: 0.871795 | Val Loss: 0.112904, Val Acc: 0.773196\n",
      "Epoch 22333 - Train Loss: 0.081782, Train Acc: 0.871795 | Val Loss: 0.112903, Val Acc: 0.773196\n",
      "Epoch 22334 - Train Loss: 0.081780, Train Acc: 0.871795 | Val Loss: 0.112902, Val Acc: 0.773196\n",
      "Epoch 22335 - Train Loss: 0.081778, Train Acc: 0.871795 | Val Loss: 0.112902, Val Acc: 0.773196\n",
      "Epoch 22336 - Train Loss: 0.081776, Train Acc: 0.871795 | Val Loss: 0.112901, Val Acc: 0.773196\n",
      "Epoch 22337 - Train Loss: 0.081774, Train Acc: 0.871795 | Val Loss: 0.112900, Val Acc: 0.773196\n",
      "Epoch 22338 - Train Loss: 0.081772, Train Acc: 0.871795 | Val Loss: 0.112899, Val Acc: 0.773196\n",
      "Epoch 22339 - Train Loss: 0.081770, Train Acc: 0.871795 | Val Loss: 0.112898, Val Acc: 0.773196\n",
      "Epoch 22340 - Train Loss: 0.081768, Train Acc: 0.871795 | Val Loss: 0.112898, Val Acc: 0.773196\n",
      "Epoch 22341 - Train Loss: 0.081767, Train Acc: 0.871795 | Val Loss: 0.112897, Val Acc: 0.773196\n",
      "Epoch 22342 - Train Loss: 0.081765, Train Acc: 0.871795 | Val Loss: 0.112896, Val Acc: 0.773196\n",
      "Epoch 22343 - Train Loss: 0.081763, Train Acc: 0.871795 | Val Loss: 0.112895, Val Acc: 0.773196\n",
      "Epoch 22344 - Train Loss: 0.081761, Train Acc: 0.871795 | Val Loss: 0.112895, Val Acc: 0.773196\n",
      "Epoch 22345 - Train Loss: 0.081759, Train Acc: 0.871795 | Val Loss: 0.112894, Val Acc: 0.773196\n",
      "Epoch 22346 - Train Loss: 0.081757, Train Acc: 0.871795 | Val Loss: 0.112893, Val Acc: 0.773196\n",
      "Epoch 22347 - Train Loss: 0.081755, Train Acc: 0.871795 | Val Loss: 0.112892, Val Acc: 0.773196\n",
      "Epoch 22348 - Train Loss: 0.081753, Train Acc: 0.871795 | Val Loss: 0.112892, Val Acc: 0.773196\n",
      "Epoch 22349 - Train Loss: 0.081752, Train Acc: 0.871795 | Val Loss: 0.112891, Val Acc: 0.773196\n",
      "Epoch 22350 - Train Loss: 0.081750, Train Acc: 0.871795 | Val Loss: 0.112890, Val Acc: 0.773196\n",
      "Epoch 22351 - Train Loss: 0.081748, Train Acc: 0.871795 | Val Loss: 0.112889, Val Acc: 0.773196\n",
      "Epoch 22352 - Train Loss: 0.081746, Train Acc: 0.871795 | Val Loss: 0.112889, Val Acc: 0.773196\n",
      "Epoch 22353 - Train Loss: 0.081744, Train Acc: 0.871795 | Val Loss: 0.112888, Val Acc: 0.773196\n",
      "Epoch 22354 - Train Loss: 0.081742, Train Acc: 0.871795 | Val Loss: 0.112887, Val Acc: 0.773196\n",
      "Epoch 22355 - Train Loss: 0.081740, Train Acc: 0.871795 | Val Loss: 0.112886, Val Acc: 0.773196\n",
      "Epoch 22356 - Train Loss: 0.081738, Train Acc: 0.871795 | Val Loss: 0.112885, Val Acc: 0.773196\n",
      "Epoch 22357 - Train Loss: 0.081737, Train Acc: 0.871795 | Val Loss: 0.112885, Val Acc: 0.773196\n",
      "Epoch 22358 - Train Loss: 0.081735, Train Acc: 0.871795 | Val Loss: 0.112884, Val Acc: 0.773196\n",
      "Epoch 22359 - Train Loss: 0.081733, Train Acc: 0.871795 | Val Loss: 0.112883, Val Acc: 0.773196\n",
      "Epoch 22360 - Train Loss: 0.081731, Train Acc: 0.871795 | Val Loss: 0.112882, Val Acc: 0.773196\n",
      "Epoch 22361 - Train Loss: 0.081729, Train Acc: 0.871795 | Val Loss: 0.112882, Val Acc: 0.773196\n",
      "Epoch 22362 - Train Loss: 0.081727, Train Acc: 0.871795 | Val Loss: 0.112881, Val Acc: 0.773196\n",
      "Epoch 22363 - Train Loss: 0.081725, Train Acc: 0.871795 | Val Loss: 0.112880, Val Acc: 0.773196\n",
      "Epoch 22364 - Train Loss: 0.081724, Train Acc: 0.871795 | Val Loss: 0.112879, Val Acc: 0.773196\n",
      "Epoch 22365 - Train Loss: 0.081722, Train Acc: 0.871795 | Val Loss: 0.112879, Val Acc: 0.773196\n",
      "Epoch 22366 - Train Loss: 0.081720, Train Acc: 0.871795 | Val Loss: 0.112878, Val Acc: 0.773196\n",
      "Epoch 22367 - Train Loss: 0.081718, Train Acc: 0.871795 | Val Loss: 0.112877, Val Acc: 0.773196\n",
      "Epoch 22368 - Train Loss: 0.081716, Train Acc: 0.871795 | Val Loss: 0.112876, Val Acc: 0.773196\n",
      "Epoch 22369 - Train Loss: 0.081714, Train Acc: 0.871795 | Val Loss: 0.112876, Val Acc: 0.773196\n",
      "Epoch 22370 - Train Loss: 0.081712, Train Acc: 0.871795 | Val Loss: 0.112875, Val Acc: 0.773196\n",
      "Epoch 22371 - Train Loss: 0.081710, Train Acc: 0.871795 | Val Loss: 0.112874, Val Acc: 0.773196\n",
      "Epoch 22372 - Train Loss: 0.081709, Train Acc: 0.871795 | Val Loss: 0.112873, Val Acc: 0.773196\n",
      "Epoch 22373 - Train Loss: 0.081707, Train Acc: 0.871795 | Val Loss: 0.112872, Val Acc: 0.773196\n",
      "Epoch 22374 - Train Loss: 0.081705, Train Acc: 0.871795 | Val Loss: 0.112872, Val Acc: 0.773196\n",
      "Epoch 22375 - Train Loss: 0.081703, Train Acc: 0.871795 | Val Loss: 0.112871, Val Acc: 0.773196\n",
      "Epoch 22376 - Train Loss: 0.081701, Train Acc: 0.871795 | Val Loss: 0.112870, Val Acc: 0.773196\n",
      "Epoch 22377 - Train Loss: 0.081699, Train Acc: 0.871795 | Val Loss: 0.112869, Val Acc: 0.773196\n",
      "Epoch 22378 - Train Loss: 0.081697, Train Acc: 0.871795 | Val Loss: 0.112869, Val Acc: 0.773196\n",
      "Epoch 22379 - Train Loss: 0.081696, Train Acc: 0.871795 | Val Loss: 0.112868, Val Acc: 0.773196\n",
      "Epoch 22380 - Train Loss: 0.081694, Train Acc: 0.871795 | Val Loss: 0.112867, Val Acc: 0.773196\n",
      "Epoch 22381 - Train Loss: 0.081692, Train Acc: 0.871795 | Val Loss: 0.112866, Val Acc: 0.773196\n",
      "Epoch 22382 - Train Loss: 0.081690, Train Acc: 0.871795 | Val Loss: 0.112866, Val Acc: 0.773196\n",
      "Epoch 22383 - Train Loss: 0.081688, Train Acc: 0.871795 | Val Loss: 0.112865, Val Acc: 0.773196\n",
      "Epoch 22384 - Train Loss: 0.081686, Train Acc: 0.871795 | Val Loss: 0.112864, Val Acc: 0.773196\n",
      "Epoch 22385 - Train Loss: 0.081684, Train Acc: 0.871795 | Val Loss: 0.112863, Val Acc: 0.773196\n",
      "Epoch 22386 - Train Loss: 0.081682, Train Acc: 0.871795 | Val Loss: 0.112863, Val Acc: 0.773196\n",
      "Epoch 22387 - Train Loss: 0.081681, Train Acc: 0.871795 | Val Loss: 0.112862, Val Acc: 0.773196\n",
      "Epoch 22388 - Train Loss: 0.081679, Train Acc: 0.871795 | Val Loss: 0.112861, Val Acc: 0.773196\n",
      "Epoch 22389 - Train Loss: 0.081677, Train Acc: 0.871795 | Val Loss: 0.112860, Val Acc: 0.773196\n",
      "Epoch 22390 - Train Loss: 0.081675, Train Acc: 0.871795 | Val Loss: 0.112860, Val Acc: 0.773196\n",
      "Epoch 22391 - Train Loss: 0.081673, Train Acc: 0.871795 | Val Loss: 0.112859, Val Acc: 0.773196\n",
      "Epoch 22392 - Train Loss: 0.081671, Train Acc: 0.871795 | Val Loss: 0.112858, Val Acc: 0.773196\n",
      "Epoch 22393 - Train Loss: 0.081669, Train Acc: 0.871795 | Val Loss: 0.112857, Val Acc: 0.773196\n",
      "Epoch 22394 - Train Loss: 0.081668, Train Acc: 0.871795 | Val Loss: 0.112856, Val Acc: 0.773196\n",
      "Epoch 22395 - Train Loss: 0.081666, Train Acc: 0.871795 | Val Loss: 0.112856, Val Acc: 0.773196\n",
      "Epoch 22396 - Train Loss: 0.081664, Train Acc: 0.871795 | Val Loss: 0.112855, Val Acc: 0.773196\n",
      "Epoch 22397 - Train Loss: 0.081662, Train Acc: 0.871795 | Val Loss: 0.112854, Val Acc: 0.773196\n",
      "Epoch 22398 - Train Loss: 0.081660, Train Acc: 0.871795 | Val Loss: 0.112853, Val Acc: 0.773196\n",
      "Epoch 22399 - Train Loss: 0.081658, Train Acc: 0.871795 | Val Loss: 0.112853, Val Acc: 0.773196\n",
      "Epoch 22400 - Train Loss: 0.081656, Train Acc: 0.871795 | Val Loss: 0.112852, Val Acc: 0.773196\n",
      "Epoch 22401 - Train Loss: 0.081654, Train Acc: 0.871795 | Val Loss: 0.112851, Val Acc: 0.773196\n",
      "Epoch 22402 - Train Loss: 0.081653, Train Acc: 0.871795 | Val Loss: 0.112850, Val Acc: 0.773196\n",
      "Epoch 22403 - Train Loss: 0.081651, Train Acc: 0.871795 | Val Loss: 0.112850, Val Acc: 0.773196\n",
      "Epoch 22404 - Train Loss: 0.081649, Train Acc: 0.871795 | Val Loss: 0.112849, Val Acc: 0.773196\n",
      "Epoch 22405 - Train Loss: 0.081647, Train Acc: 0.871795 | Val Loss: 0.112848, Val Acc: 0.773196\n",
      "Epoch 22406 - Train Loss: 0.081645, Train Acc: 0.871795 | Val Loss: 0.112847, Val Acc: 0.773196\n",
      "Epoch 22407 - Train Loss: 0.081643, Train Acc: 0.871795 | Val Loss: 0.112847, Val Acc: 0.773196\n",
      "Epoch 22408 - Train Loss: 0.081641, Train Acc: 0.871795 | Val Loss: 0.112846, Val Acc: 0.773196\n",
      "Epoch 22409 - Train Loss: 0.081640, Train Acc: 0.871795 | Val Loss: 0.112845, Val Acc: 0.773196\n",
      "Epoch 22410 - Train Loss: 0.081638, Train Acc: 0.871795 | Val Loss: 0.112844, Val Acc: 0.773196\n",
      "Epoch 22411 - Train Loss: 0.081636, Train Acc: 0.871795 | Val Loss: 0.112844, Val Acc: 0.773196\n",
      "Epoch 22412 - Train Loss: 0.081634, Train Acc: 0.871795 | Val Loss: 0.112843, Val Acc: 0.773196\n",
      "Epoch 22413 - Train Loss: 0.081632, Train Acc: 0.871795 | Val Loss: 0.112842, Val Acc: 0.773196\n",
      "Epoch 22414 - Train Loss: 0.081630, Train Acc: 0.871795 | Val Loss: 0.112841, Val Acc: 0.773196\n",
      "Epoch 22415 - Train Loss: 0.081628, Train Acc: 0.871795 | Val Loss: 0.112841, Val Acc: 0.773196\n",
      "Epoch 22416 - Train Loss: 0.081627, Train Acc: 0.871795 | Val Loss: 0.112840, Val Acc: 0.773196\n",
      "Epoch 22417 - Train Loss: 0.081625, Train Acc: 0.871795 | Val Loss: 0.112839, Val Acc: 0.773196\n",
      "Epoch 22418 - Train Loss: 0.081623, Train Acc: 0.871795 | Val Loss: 0.112838, Val Acc: 0.773196\n",
      "Epoch 22419 - Train Loss: 0.081621, Train Acc: 0.871795 | Val Loss: 0.112838, Val Acc: 0.773196\n",
      "Epoch 22420 - Train Loss: 0.081619, Train Acc: 0.871795 | Val Loss: 0.112837, Val Acc: 0.773196\n",
      "Epoch 22421 - Train Loss: 0.081617, Train Acc: 0.871795 | Val Loss: 0.112836, Val Acc: 0.773196\n",
      "Epoch 22422 - Train Loss: 0.081615, Train Acc: 0.871795 | Val Loss: 0.112835, Val Acc: 0.773196\n",
      "Epoch 22423 - Train Loss: 0.081614, Train Acc: 0.871795 | Val Loss: 0.112834, Val Acc: 0.773196\n",
      "Epoch 22424 - Train Loss: 0.081612, Train Acc: 0.871795 | Val Loss: 0.112834, Val Acc: 0.773196\n",
      "Epoch 22425 - Train Loss: 0.081610, Train Acc: 0.871795 | Val Loss: 0.112833, Val Acc: 0.773196\n",
      "Epoch 22426 - Train Loss: 0.081608, Train Acc: 0.871795 | Val Loss: 0.112832, Val Acc: 0.773196\n",
      "Epoch 22427 - Train Loss: 0.081606, Train Acc: 0.871795 | Val Loss: 0.112831, Val Acc: 0.773196\n",
      "Epoch 22428 - Train Loss: 0.081604, Train Acc: 0.871795 | Val Loss: 0.112831, Val Acc: 0.773196\n",
      "Epoch 22429 - Train Loss: 0.081602, Train Acc: 0.871795 | Val Loss: 0.112830, Val Acc: 0.773196\n",
      "Epoch 22430 - Train Loss: 0.081600, Train Acc: 0.871795 | Val Loss: 0.112829, Val Acc: 0.773196\n",
      "Epoch 22431 - Train Loss: 0.081599, Train Acc: 0.871795 | Val Loss: 0.112828, Val Acc: 0.773196\n",
      "Epoch 22432 - Train Loss: 0.081597, Train Acc: 0.871795 | Val Loss: 0.112828, Val Acc: 0.773196\n",
      "Epoch 22433 - Train Loss: 0.081595, Train Acc: 0.871795 | Val Loss: 0.112827, Val Acc: 0.773196\n",
      "Epoch 22434 - Train Loss: 0.081593, Train Acc: 0.871795 | Val Loss: 0.112826, Val Acc: 0.773196\n",
      "Epoch 22435 - Train Loss: 0.081591, Train Acc: 0.871795 | Val Loss: 0.112825, Val Acc: 0.773196\n",
      "Epoch 22436 - Train Loss: 0.081589, Train Acc: 0.871795 | Val Loss: 0.112825, Val Acc: 0.773196\n",
      "Epoch 22437 - Train Loss: 0.081587, Train Acc: 0.871795 | Val Loss: 0.112824, Val Acc: 0.773196\n",
      "Epoch 22438 - Train Loss: 0.081586, Train Acc: 0.871795 | Val Loss: 0.112823, Val Acc: 0.773196\n",
      "Epoch 22439 - Train Loss: 0.081584, Train Acc: 0.871795 | Val Loss: 0.112822, Val Acc: 0.773196\n",
      "Epoch 22440 - Train Loss: 0.081582, Train Acc: 0.871795 | Val Loss: 0.112822, Val Acc: 0.773196\n",
      "Epoch 22441 - Train Loss: 0.081580, Train Acc: 0.871795 | Val Loss: 0.112821, Val Acc: 0.773196\n",
      "Epoch 22442 - Train Loss: 0.081578, Train Acc: 0.871795 | Val Loss: 0.112820, Val Acc: 0.773196\n",
      "Epoch 22443 - Train Loss: 0.081576, Train Acc: 0.871795 | Val Loss: 0.112819, Val Acc: 0.773196\n",
      "Epoch 22444 - Train Loss: 0.081574, Train Acc: 0.871795 | Val Loss: 0.112819, Val Acc: 0.773196\n",
      "Epoch 22445 - Train Loss: 0.081573, Train Acc: 0.871795 | Val Loss: 0.112818, Val Acc: 0.773196\n",
      "Epoch 22446 - Train Loss: 0.081571, Train Acc: 0.871795 | Val Loss: 0.112817, Val Acc: 0.773196\n",
      "Epoch 22447 - Train Loss: 0.081569, Train Acc: 0.871795 | Val Loss: 0.112816, Val Acc: 0.773196\n",
      "Epoch 22448 - Train Loss: 0.081567, Train Acc: 0.871795 | Val Loss: 0.112816, Val Acc: 0.773196\n",
      "Epoch 22449 - Train Loss: 0.081565, Train Acc: 0.871795 | Val Loss: 0.112815, Val Acc: 0.773196\n",
      "Epoch 22450 - Train Loss: 0.081563, Train Acc: 0.871795 | Val Loss: 0.112814, Val Acc: 0.773196\n",
      "Epoch 22451 - Train Loss: 0.081561, Train Acc: 0.871795 | Val Loss: 0.112813, Val Acc: 0.773196\n",
      "Epoch 22452 - Train Loss: 0.081560, Train Acc: 0.871795 | Val Loss: 0.112813, Val Acc: 0.773196\n",
      "Epoch 22453 - Train Loss: 0.081558, Train Acc: 0.871795 | Val Loss: 0.112812, Val Acc: 0.773196\n",
      "Epoch 22454 - Train Loss: 0.081556, Train Acc: 0.871795 | Val Loss: 0.112811, Val Acc: 0.773196\n",
      "Epoch 22455 - Train Loss: 0.081554, Train Acc: 0.871795 | Val Loss: 0.112810, Val Acc: 0.773196\n",
      "Epoch 22456 - Train Loss: 0.081552, Train Acc: 0.871795 | Val Loss: 0.112810, Val Acc: 0.773196\n",
      "Epoch 22457 - Train Loss: 0.081550, Train Acc: 0.871795 | Val Loss: 0.112809, Val Acc: 0.773196\n",
      "Epoch 22458 - Train Loss: 0.081548, Train Acc: 0.871795 | Val Loss: 0.112808, Val Acc: 0.773196\n",
      "Epoch 22459 - Train Loss: 0.081547, Train Acc: 0.871795 | Val Loss: 0.112807, Val Acc: 0.773196\n",
      "Epoch 22460 - Train Loss: 0.081545, Train Acc: 0.871795 | Val Loss: 0.112807, Val Acc: 0.773196\n",
      "Epoch 22461 - Train Loss: 0.081543, Train Acc: 0.871795 | Val Loss: 0.112806, Val Acc: 0.773196\n",
      "Epoch 22462 - Train Loss: 0.081541, Train Acc: 0.871795 | Val Loss: 0.112805, Val Acc: 0.773196\n",
      "Epoch 22463 - Train Loss: 0.081539, Train Acc: 0.871795 | Val Loss: 0.112804, Val Acc: 0.773196\n",
      "Epoch 22464 - Train Loss: 0.081537, Train Acc: 0.871795 | Val Loss: 0.112804, Val Acc: 0.773196\n",
      "Epoch 22465 - Train Loss: 0.081535, Train Acc: 0.871795 | Val Loss: 0.112803, Val Acc: 0.773196\n",
      "Epoch 22466 - Train Loss: 0.081534, Train Acc: 0.871795 | Val Loss: 0.112802, Val Acc: 0.773196\n",
      "Epoch 22467 - Train Loss: 0.081532, Train Acc: 0.871795 | Val Loss: 0.112801, Val Acc: 0.773196\n",
      "Epoch 22468 - Train Loss: 0.081530, Train Acc: 0.871795 | Val Loss: 0.112801, Val Acc: 0.773196\n",
      "Epoch 22469 - Train Loss: 0.081528, Train Acc: 0.871795 | Val Loss: 0.112800, Val Acc: 0.773196\n",
      "Epoch 22470 - Train Loss: 0.081526, Train Acc: 0.871795 | Val Loss: 0.112799, Val Acc: 0.773196\n",
      "Epoch 22471 - Train Loss: 0.081524, Train Acc: 0.871795 | Val Loss: 0.112798, Val Acc: 0.773196\n",
      "Epoch 22472 - Train Loss: 0.081522, Train Acc: 0.871795 | Val Loss: 0.112798, Val Acc: 0.773196\n",
      "Epoch 22473 - Train Loss: 0.081521, Train Acc: 0.871795 | Val Loss: 0.112797, Val Acc: 0.773196\n",
      "Epoch 22474 - Train Loss: 0.081519, Train Acc: 0.871795 | Val Loss: 0.112796, Val Acc: 0.773196\n",
      "Epoch 22475 - Train Loss: 0.081517, Train Acc: 0.871795 | Val Loss: 0.112795, Val Acc: 0.773196\n",
      "Epoch 22476 - Train Loss: 0.081515, Train Acc: 0.871795 | Val Loss: 0.112794, Val Acc: 0.773196\n",
      "Epoch 22477 - Train Loss: 0.081513, Train Acc: 0.871795 | Val Loss: 0.112794, Val Acc: 0.773196\n",
      "Epoch 22478 - Train Loss: 0.081511, Train Acc: 0.871795 | Val Loss: 0.112793, Val Acc: 0.773196\n",
      "Epoch 22479 - Train Loss: 0.081510, Train Acc: 0.871795 | Val Loss: 0.112792, Val Acc: 0.773196\n",
      "Epoch 22480 - Train Loss: 0.081508, Train Acc: 0.871795 | Val Loss: 0.112791, Val Acc: 0.773196\n",
      "Epoch 22481 - Train Loss: 0.081506, Train Acc: 0.871795 | Val Loss: 0.112791, Val Acc: 0.773196\n",
      "Epoch 22482 - Train Loss: 0.081504, Train Acc: 0.871795 | Val Loss: 0.112790, Val Acc: 0.773196\n",
      "Epoch 22483 - Train Loss: 0.081502, Train Acc: 0.871795 | Val Loss: 0.112789, Val Acc: 0.773196\n",
      "Epoch 22484 - Train Loss: 0.081500, Train Acc: 0.871795 | Val Loss: 0.112788, Val Acc: 0.773196\n",
      "Epoch 22485 - Train Loss: 0.081498, Train Acc: 0.871795 | Val Loss: 0.112788, Val Acc: 0.773196\n",
      "Epoch 22486 - Train Loss: 0.081497, Train Acc: 0.871795 | Val Loss: 0.112787, Val Acc: 0.773196\n",
      "Epoch 22487 - Train Loss: 0.081495, Train Acc: 0.871795 | Val Loss: 0.112786, Val Acc: 0.773196\n",
      "Epoch 22488 - Train Loss: 0.081493, Train Acc: 0.871795 | Val Loss: 0.112785, Val Acc: 0.773196\n",
      "Epoch 22489 - Train Loss: 0.081491, Train Acc: 0.871795 | Val Loss: 0.112785, Val Acc: 0.773196\n",
      "Epoch 22490 - Train Loss: 0.081489, Train Acc: 0.871795 | Val Loss: 0.112784, Val Acc: 0.773196\n",
      "Epoch 22491 - Train Loss: 0.081487, Train Acc: 0.871795 | Val Loss: 0.112783, Val Acc: 0.773196\n",
      "Epoch 22492 - Train Loss: 0.081485, Train Acc: 0.871795 | Val Loss: 0.112782, Val Acc: 0.773196\n",
      "Epoch 22493 - Train Loss: 0.081484, Train Acc: 0.871795 | Val Loss: 0.112782, Val Acc: 0.773196\n",
      "Epoch 22494 - Train Loss: 0.081482, Train Acc: 0.871795 | Val Loss: 0.112781, Val Acc: 0.773196\n",
      "Epoch 22495 - Train Loss: 0.081480, Train Acc: 0.871795 | Val Loss: 0.112780, Val Acc: 0.773196\n",
      "Epoch 22496 - Train Loss: 0.081478, Train Acc: 0.871795 | Val Loss: 0.112779, Val Acc: 0.773196\n",
      "Epoch 22497 - Train Loss: 0.081476, Train Acc: 0.871795 | Val Loss: 0.112779, Val Acc: 0.773196\n",
      "Epoch 22498 - Train Loss: 0.081474, Train Acc: 0.871795 | Val Loss: 0.112778, Val Acc: 0.773196\n",
      "Epoch 22499 - Train Loss: 0.081472, Train Acc: 0.871795 | Val Loss: 0.112777, Val Acc: 0.773196\n",
      "Epoch 22500 - Train Loss: 0.081471, Train Acc: 0.871795 | Val Loss: 0.112776, Val Acc: 0.773196\n",
      "Epoch 22501 - Train Loss: 0.081469, Train Acc: 0.871795 | Val Loss: 0.112776, Val Acc: 0.773196\n",
      "Epoch 22502 - Train Loss: 0.081467, Train Acc: 0.871795 | Val Loss: 0.112775, Val Acc: 0.773196\n",
      "Epoch 22503 - Train Loss: 0.081465, Train Acc: 0.871795 | Val Loss: 0.112774, Val Acc: 0.773196\n",
      "Epoch 22504 - Train Loss: 0.081463, Train Acc: 0.871795 | Val Loss: 0.112773, Val Acc: 0.773196\n",
      "Epoch 22505 - Train Loss: 0.081461, Train Acc: 0.871795 | Val Loss: 0.112773, Val Acc: 0.773196\n",
      "Epoch 22506 - Train Loss: 0.081460, Train Acc: 0.871795 | Val Loss: 0.112772, Val Acc: 0.773196\n",
      "Epoch 22507 - Train Loss: 0.081458, Train Acc: 0.871795 | Val Loss: 0.112771, Val Acc: 0.773196\n",
      "Epoch 22508 - Train Loss: 0.081456, Train Acc: 0.871795 | Val Loss: 0.112771, Val Acc: 0.773196\n",
      "Epoch 22509 - Train Loss: 0.081454, Train Acc: 0.871795 | Val Loss: 0.112770, Val Acc: 0.773196\n",
      "Epoch 22510 - Train Loss: 0.081452, Train Acc: 0.871795 | Val Loss: 0.112769, Val Acc: 0.773196\n",
      "Epoch 22511 - Train Loss: 0.081450, Train Acc: 0.871795 | Val Loss: 0.112768, Val Acc: 0.773196\n",
      "Epoch 22512 - Train Loss: 0.081448, Train Acc: 0.871795 | Val Loss: 0.112768, Val Acc: 0.773196\n",
      "Epoch 22513 - Train Loss: 0.081447, Train Acc: 0.871795 | Val Loss: 0.112767, Val Acc: 0.773196\n",
      "Epoch 22514 - Train Loss: 0.081445, Train Acc: 0.871795 | Val Loss: 0.112766, Val Acc: 0.773196\n",
      "Epoch 22515 - Train Loss: 0.081443, Train Acc: 0.871795 | Val Loss: 0.112765, Val Acc: 0.773196\n",
      "Epoch 22516 - Train Loss: 0.081441, Train Acc: 0.871795 | Val Loss: 0.112765, Val Acc: 0.773196\n",
      "Epoch 22517 - Train Loss: 0.081439, Train Acc: 0.871795 | Val Loss: 0.112764, Val Acc: 0.773196\n",
      "Epoch 22518 - Train Loss: 0.081437, Train Acc: 0.871795 | Val Loss: 0.112763, Val Acc: 0.773196\n",
      "Epoch 22519 - Train Loss: 0.081435, Train Acc: 0.871795 | Val Loss: 0.112762, Val Acc: 0.773196\n",
      "Epoch 22520 - Train Loss: 0.081434, Train Acc: 0.871795 | Val Loss: 0.112762, Val Acc: 0.773196\n",
      "Epoch 22521 - Train Loss: 0.081432, Train Acc: 0.871795 | Val Loss: 0.112761, Val Acc: 0.773196\n",
      "Epoch 22522 - Train Loss: 0.081430, Train Acc: 0.871795 | Val Loss: 0.112760, Val Acc: 0.773196\n",
      "Epoch 22523 - Train Loss: 0.081428, Train Acc: 0.871795 | Val Loss: 0.112759, Val Acc: 0.773196\n",
      "Epoch 22524 - Train Loss: 0.081426, Train Acc: 0.871795 | Val Loss: 0.112759, Val Acc: 0.773196\n",
      "Epoch 22525 - Train Loss: 0.081424, Train Acc: 0.871795 | Val Loss: 0.112758, Val Acc: 0.773196\n",
      "Epoch 22526 - Train Loss: 0.081423, Train Acc: 0.871795 | Val Loss: 0.112757, Val Acc: 0.773196\n",
      "Epoch 22527 - Train Loss: 0.081421, Train Acc: 0.871795 | Val Loss: 0.112756, Val Acc: 0.773196\n",
      "Epoch 22528 - Train Loss: 0.081419, Train Acc: 0.871795 | Val Loss: 0.112756, Val Acc: 0.773196\n",
      "Epoch 22529 - Train Loss: 0.081417, Train Acc: 0.871795 | Val Loss: 0.112755, Val Acc: 0.773196\n",
      "Epoch 22530 - Train Loss: 0.081415, Train Acc: 0.871795 | Val Loss: 0.112754, Val Acc: 0.773196\n",
      "Epoch 22531 - Train Loss: 0.081413, Train Acc: 0.871795 | Val Loss: 0.112753, Val Acc: 0.773196\n",
      "Epoch 22532 - Train Loss: 0.081411, Train Acc: 0.871795 | Val Loss: 0.112753, Val Acc: 0.773196\n",
      "Epoch 22533 - Train Loss: 0.081410, Train Acc: 0.871795 | Val Loss: 0.112752, Val Acc: 0.773196\n",
      "Epoch 22534 - Train Loss: 0.081408, Train Acc: 0.871795 | Val Loss: 0.112751, Val Acc: 0.773196\n",
      "Epoch 22535 - Train Loss: 0.081406, Train Acc: 0.871795 | Val Loss: 0.112750, Val Acc: 0.773196\n",
      "Epoch 22536 - Train Loss: 0.081404, Train Acc: 0.871795 | Val Loss: 0.112750, Val Acc: 0.773196\n",
      "Epoch 22537 - Train Loss: 0.081402, Train Acc: 0.871795 | Val Loss: 0.112749, Val Acc: 0.773196\n",
      "Epoch 22538 - Train Loss: 0.081400, Train Acc: 0.871795 | Val Loss: 0.112748, Val Acc: 0.773196\n",
      "Epoch 22539 - Train Loss: 0.081399, Train Acc: 0.871795 | Val Loss: 0.112747, Val Acc: 0.773196\n",
      "Epoch 22540 - Train Loss: 0.081397, Train Acc: 0.871795 | Val Loss: 0.112747, Val Acc: 0.773196\n",
      "Epoch 22541 - Train Loss: 0.081395, Train Acc: 0.871795 | Val Loss: 0.112746, Val Acc: 0.773196\n",
      "Epoch 22542 - Train Loss: 0.081393, Train Acc: 0.871795 | Val Loss: 0.112745, Val Acc: 0.773196\n",
      "Epoch 22543 - Train Loss: 0.081391, Train Acc: 0.871795 | Val Loss: 0.112744, Val Acc: 0.773196\n",
      "Epoch 22544 - Train Loss: 0.081389, Train Acc: 0.871795 | Val Loss: 0.112744, Val Acc: 0.773196\n",
      "Epoch 22545 - Train Loss: 0.081387, Train Acc: 0.871795 | Val Loss: 0.112743, Val Acc: 0.773196\n",
      "Epoch 22546 - Train Loss: 0.081386, Train Acc: 0.871795 | Val Loss: 0.112742, Val Acc: 0.773196\n",
      "Epoch 22547 - Train Loss: 0.081384, Train Acc: 0.871795 | Val Loss: 0.112741, Val Acc: 0.773196\n",
      "Epoch 22548 - Train Loss: 0.081382, Train Acc: 0.871795 | Val Loss: 0.112741, Val Acc: 0.773196\n",
      "Epoch 22549 - Train Loss: 0.081380, Train Acc: 0.871795 | Val Loss: 0.112740, Val Acc: 0.773196\n",
      "Epoch 22550 - Train Loss: 0.081378, Train Acc: 0.871795 | Val Loss: 0.112739, Val Acc: 0.773196\n",
      "Epoch 22551 - Train Loss: 0.081376, Train Acc: 0.871795 | Val Loss: 0.112738, Val Acc: 0.773196\n",
      "Epoch 22552 - Train Loss: 0.081375, Train Acc: 0.871795 | Val Loss: 0.112738, Val Acc: 0.773196\n",
      "Epoch 22553 - Train Loss: 0.081373, Train Acc: 0.871795 | Val Loss: 0.112737, Val Acc: 0.773196\n",
      "Epoch 22554 - Train Loss: 0.081371, Train Acc: 0.871795 | Val Loss: 0.112736, Val Acc: 0.773196\n",
      "Epoch 22555 - Train Loss: 0.081369, Train Acc: 0.871795 | Val Loss: 0.112735, Val Acc: 0.773196\n",
      "Epoch 22556 - Train Loss: 0.081367, Train Acc: 0.871795 | Val Loss: 0.112735, Val Acc: 0.773196\n",
      "Epoch 22557 - Train Loss: 0.081365, Train Acc: 0.871795 | Val Loss: 0.112734, Val Acc: 0.773196\n",
      "Epoch 22558 - Train Loss: 0.081363, Train Acc: 0.871795 | Val Loss: 0.112733, Val Acc: 0.773196\n",
      "Epoch 22559 - Train Loss: 0.081362, Train Acc: 0.871795 | Val Loss: 0.112732, Val Acc: 0.773196\n",
      "Epoch 22560 - Train Loss: 0.081360, Train Acc: 0.871795 | Val Loss: 0.112732, Val Acc: 0.773196\n",
      "Epoch 22561 - Train Loss: 0.081358, Train Acc: 0.871795 | Val Loss: 0.112731, Val Acc: 0.773196\n",
      "Epoch 22562 - Train Loss: 0.081356, Train Acc: 0.871795 | Val Loss: 0.112730, Val Acc: 0.773196\n",
      "Epoch 22563 - Train Loss: 0.081354, Train Acc: 0.871795 | Val Loss: 0.112730, Val Acc: 0.773196\n",
      "Epoch 22564 - Train Loss: 0.081352, Train Acc: 0.871795 | Val Loss: 0.112729, Val Acc: 0.773196\n",
      "Epoch 22565 - Train Loss: 0.081351, Train Acc: 0.871795 | Val Loss: 0.112728, Val Acc: 0.773196\n",
      "Epoch 22566 - Train Loss: 0.081349, Train Acc: 0.871795 | Val Loss: 0.112727, Val Acc: 0.773196\n",
      "Epoch 22567 - Train Loss: 0.081347, Train Acc: 0.871795 | Val Loss: 0.112727, Val Acc: 0.773196\n",
      "Epoch 22568 - Train Loss: 0.081345, Train Acc: 0.871795 | Val Loss: 0.112726, Val Acc: 0.773196\n",
      "Epoch 22569 - Train Loss: 0.081343, Train Acc: 0.871795 | Val Loss: 0.112725, Val Acc: 0.773196\n",
      "Epoch 22570 - Train Loss: 0.081341, Train Acc: 0.871795 | Val Loss: 0.112724, Val Acc: 0.773196\n",
      "Epoch 22571 - Train Loss: 0.081340, Train Acc: 0.871795 | Val Loss: 0.112724, Val Acc: 0.773196\n",
      "Epoch 22572 - Train Loss: 0.081338, Train Acc: 0.871795 | Val Loss: 0.112723, Val Acc: 0.773196\n",
      "Epoch 22573 - Train Loss: 0.081336, Train Acc: 0.871795 | Val Loss: 0.112722, Val Acc: 0.773196\n",
      "Epoch 22574 - Train Loss: 0.081334, Train Acc: 0.871795 | Val Loss: 0.112721, Val Acc: 0.773196\n",
      "Epoch 22575 - Train Loss: 0.081332, Train Acc: 0.871795 | Val Loss: 0.112721, Val Acc: 0.773196\n",
      "Epoch 22576 - Train Loss: 0.081330, Train Acc: 0.871795 | Val Loss: 0.112720, Val Acc: 0.773196\n",
      "Epoch 22577 - Train Loss: 0.081328, Train Acc: 0.871795 | Val Loss: 0.112719, Val Acc: 0.773196\n",
      "Epoch 22578 - Train Loss: 0.081327, Train Acc: 0.871795 | Val Loss: 0.112718, Val Acc: 0.773196\n",
      "Epoch 22579 - Train Loss: 0.081325, Train Acc: 0.871795 | Val Loss: 0.112718, Val Acc: 0.773196\n",
      "Epoch 22580 - Train Loss: 0.081323, Train Acc: 0.871795 | Val Loss: 0.112717, Val Acc: 0.773196\n",
      "Epoch 22581 - Train Loss: 0.081321, Train Acc: 0.871795 | Val Loss: 0.112716, Val Acc: 0.773196\n",
      "Epoch 22582 - Train Loss: 0.081319, Train Acc: 0.871795 | Val Loss: 0.112715, Val Acc: 0.773196\n",
      "Epoch 22583 - Train Loss: 0.081317, Train Acc: 0.871795 | Val Loss: 0.112715, Val Acc: 0.773196\n",
      "Epoch 22584 - Train Loss: 0.081316, Train Acc: 0.871795 | Val Loss: 0.112714, Val Acc: 0.773196\n",
      "Epoch 22585 - Train Loss: 0.081314, Train Acc: 0.871795 | Val Loss: 0.112713, Val Acc: 0.773196\n",
      "Epoch 22586 - Train Loss: 0.081312, Train Acc: 0.871795 | Val Loss: 0.112712, Val Acc: 0.773196\n",
      "Epoch 22587 - Train Loss: 0.081310, Train Acc: 0.871795 | Val Loss: 0.112712, Val Acc: 0.773196\n",
      "Epoch 22588 - Train Loss: 0.081308, Train Acc: 0.871795 | Val Loss: 0.112711, Val Acc: 0.773196\n",
      "Epoch 22589 - Train Loss: 0.081306, Train Acc: 0.871795 | Val Loss: 0.112710, Val Acc: 0.773196\n",
      "Epoch 22590 - Train Loss: 0.081305, Train Acc: 0.871795 | Val Loss: 0.112710, Val Acc: 0.773196\n",
      "Epoch 22591 - Train Loss: 0.081303, Train Acc: 0.871795 | Val Loss: 0.112709, Val Acc: 0.773196\n",
      "Epoch 22592 - Train Loss: 0.081301, Train Acc: 0.871795 | Val Loss: 0.112708, Val Acc: 0.773196\n",
      "Epoch 22593 - Train Loss: 0.081299, Train Acc: 0.871795 | Val Loss: 0.112707, Val Acc: 0.773196\n",
      "Epoch 22594 - Train Loss: 0.081297, Train Acc: 0.871795 | Val Loss: 0.112707, Val Acc: 0.773196\n",
      "Epoch 22595 - Train Loss: 0.081295, Train Acc: 0.871795 | Val Loss: 0.112706, Val Acc: 0.773196\n",
      "Epoch 22596 - Train Loss: 0.081294, Train Acc: 0.871795 | Val Loss: 0.112705, Val Acc: 0.773196\n",
      "Epoch 22597 - Train Loss: 0.081292, Train Acc: 0.871795 | Val Loss: 0.112704, Val Acc: 0.773196\n",
      "Epoch 22598 - Train Loss: 0.081290, Train Acc: 0.871795 | Val Loss: 0.112704, Val Acc: 0.773196\n",
      "Epoch 22599 - Train Loss: 0.081288, Train Acc: 0.871795 | Val Loss: 0.112703, Val Acc: 0.773196\n",
      "Epoch 22600 - Train Loss: 0.081286, Train Acc: 0.871795 | Val Loss: 0.112702, Val Acc: 0.773196\n",
      "Epoch 22601 - Train Loss: 0.081284, Train Acc: 0.871795 | Val Loss: 0.112701, Val Acc: 0.773196\n",
      "Epoch 22602 - Train Loss: 0.081283, Train Acc: 0.871795 | Val Loss: 0.112701, Val Acc: 0.773196\n",
      "Epoch 22603 - Train Loss: 0.081281, Train Acc: 0.871795 | Val Loss: 0.112700, Val Acc: 0.773196\n",
      "Epoch 22604 - Train Loss: 0.081279, Train Acc: 0.871795 | Val Loss: 0.112699, Val Acc: 0.773196\n",
      "Epoch 22605 - Train Loss: 0.081277, Train Acc: 0.871795 | Val Loss: 0.112698, Val Acc: 0.773196\n",
      "Epoch 22606 - Train Loss: 0.081275, Train Acc: 0.871795 | Val Loss: 0.112698, Val Acc: 0.773196\n",
      "Epoch 22607 - Train Loss: 0.081273, Train Acc: 0.871795 | Val Loss: 0.112697, Val Acc: 0.773196\n",
      "Epoch 22608 - Train Loss: 0.081271, Train Acc: 0.871795 | Val Loss: 0.112696, Val Acc: 0.773196\n",
      "Epoch 22609 - Train Loss: 0.081270, Train Acc: 0.871795 | Val Loss: 0.112695, Val Acc: 0.773196\n",
      "Epoch 22610 - Train Loss: 0.081268, Train Acc: 0.871795 | Val Loss: 0.112695, Val Acc: 0.773196\n",
      "Epoch 22611 - Train Loss: 0.081266, Train Acc: 0.871795 | Val Loss: 0.112694, Val Acc: 0.773196\n",
      "Epoch 22612 - Train Loss: 0.081264, Train Acc: 0.871795 | Val Loss: 0.112693, Val Acc: 0.773196\n",
      "Epoch 22613 - Train Loss: 0.081262, Train Acc: 0.871795 | Val Loss: 0.112693, Val Acc: 0.773196\n",
      "Epoch 22614 - Train Loss: 0.081260, Train Acc: 0.871795 | Val Loss: 0.112692, Val Acc: 0.773196\n",
      "Epoch 22615 - Train Loss: 0.081259, Train Acc: 0.871795 | Val Loss: 0.112691, Val Acc: 0.773196\n",
      "Epoch 22616 - Train Loss: 0.081257, Train Acc: 0.871795 | Val Loss: 0.112690, Val Acc: 0.773196\n",
      "Epoch 22617 - Train Loss: 0.081255, Train Acc: 0.871795 | Val Loss: 0.112690, Val Acc: 0.773196\n",
      "Epoch 22618 - Train Loss: 0.081253, Train Acc: 0.871795 | Val Loss: 0.112689, Val Acc: 0.773196\n",
      "Epoch 22619 - Train Loss: 0.081251, Train Acc: 0.871795 | Val Loss: 0.112688, Val Acc: 0.773196\n",
      "Epoch 22620 - Train Loss: 0.081249, Train Acc: 0.871795 | Val Loss: 0.112687, Val Acc: 0.773196\n",
      "Epoch 22621 - Train Loss: 0.081248, Train Acc: 0.871795 | Val Loss: 0.112687, Val Acc: 0.773196\n",
      "Epoch 22622 - Train Loss: 0.081246, Train Acc: 0.871795 | Val Loss: 0.112686, Val Acc: 0.773196\n",
      "Epoch 22623 - Train Loss: 0.081244, Train Acc: 0.871795 | Val Loss: 0.112685, Val Acc: 0.773196\n",
      "Epoch 22624 - Train Loss: 0.081242, Train Acc: 0.871795 | Val Loss: 0.112684, Val Acc: 0.773196\n",
      "Epoch 22625 - Train Loss: 0.081240, Train Acc: 0.871795 | Val Loss: 0.112684, Val Acc: 0.773196\n",
      "Epoch 22626 - Train Loss: 0.081238, Train Acc: 0.871795 | Val Loss: 0.112683, Val Acc: 0.773196\n",
      "Epoch 22627 - Train Loss: 0.081237, Train Acc: 0.871795 | Val Loss: 0.112682, Val Acc: 0.773196\n",
      "Epoch 22628 - Train Loss: 0.081235, Train Acc: 0.871795 | Val Loss: 0.112682, Val Acc: 0.773196\n",
      "Epoch 22629 - Train Loss: 0.081233, Train Acc: 0.871795 | Val Loss: 0.112681, Val Acc: 0.773196\n",
      "Epoch 22630 - Train Loss: 0.081231, Train Acc: 0.871795 | Val Loss: 0.112680, Val Acc: 0.773196\n",
      "Epoch 22631 - Train Loss: 0.081229, Train Acc: 0.871795 | Val Loss: 0.112679, Val Acc: 0.773196\n",
      "Epoch 22632 - Train Loss: 0.081227, Train Acc: 0.871795 | Val Loss: 0.112679, Val Acc: 0.773196\n",
      "Epoch 22633 - Train Loss: 0.081226, Train Acc: 0.871795 | Val Loss: 0.112678, Val Acc: 0.773196\n",
      "Epoch 22634 - Train Loss: 0.081224, Train Acc: 0.871795 | Val Loss: 0.112677, Val Acc: 0.773196\n",
      "Epoch 22635 - Train Loss: 0.081222, Train Acc: 0.871795 | Val Loss: 0.112676, Val Acc: 0.773196\n",
      "Epoch 22636 - Train Loss: 0.081220, Train Acc: 0.871795 | Val Loss: 0.112676, Val Acc: 0.773196\n",
      "Epoch 22637 - Train Loss: 0.081218, Train Acc: 0.871795 | Val Loss: 0.112675, Val Acc: 0.773196\n",
      "Epoch 22638 - Train Loss: 0.081216, Train Acc: 0.871795 | Val Loss: 0.112674, Val Acc: 0.773196\n",
      "Epoch 22639 - Train Loss: 0.081215, Train Acc: 0.871795 | Val Loss: 0.112673, Val Acc: 0.773196\n",
      "Epoch 22640 - Train Loss: 0.081213, Train Acc: 0.871795 | Val Loss: 0.112673, Val Acc: 0.773196\n",
      "Epoch 22641 - Train Loss: 0.081211, Train Acc: 0.871795 | Val Loss: 0.112672, Val Acc: 0.773196\n",
      "Epoch 22642 - Train Loss: 0.081209, Train Acc: 0.871795 | Val Loss: 0.112671, Val Acc: 0.773196\n",
      "Epoch 22643 - Train Loss: 0.081207, Train Acc: 0.871795 | Val Loss: 0.112670, Val Acc: 0.773196\n",
      "Epoch 22644 - Train Loss: 0.081205, Train Acc: 0.871795 | Val Loss: 0.112670, Val Acc: 0.773196\n",
      "Epoch 22645 - Train Loss: 0.081204, Train Acc: 0.871795 | Val Loss: 0.112669, Val Acc: 0.773196\n",
      "Epoch 22646 - Train Loss: 0.081202, Train Acc: 0.871795 | Val Loss: 0.112668, Val Acc: 0.773196\n",
      "Epoch 22647 - Train Loss: 0.081200, Train Acc: 0.871795 | Val Loss: 0.112668, Val Acc: 0.773196\n",
      "Epoch 22648 - Train Loss: 0.081198, Train Acc: 0.871795 | Val Loss: 0.112667, Val Acc: 0.773196\n",
      "Epoch 22649 - Train Loss: 0.081196, Train Acc: 0.871795 | Val Loss: 0.112666, Val Acc: 0.773196\n",
      "Epoch 22650 - Train Loss: 0.081194, Train Acc: 0.871795 | Val Loss: 0.112665, Val Acc: 0.773196\n",
      "Epoch 22651 - Train Loss: 0.081193, Train Acc: 0.871795 | Val Loss: 0.112665, Val Acc: 0.773196\n",
      "Epoch 22652 - Train Loss: 0.081191, Train Acc: 0.871795 | Val Loss: 0.112664, Val Acc: 0.773196\n",
      "Epoch 22653 - Train Loss: 0.081189, Train Acc: 0.871795 | Val Loss: 0.112663, Val Acc: 0.773196\n",
      "Epoch 22654 - Train Loss: 0.081187, Train Acc: 0.871795 | Val Loss: 0.112662, Val Acc: 0.773196\n",
      "Epoch 22655 - Train Loss: 0.081185, Train Acc: 0.871795 | Val Loss: 0.112662, Val Acc: 0.773196\n",
      "Epoch 22656 - Train Loss: 0.081183, Train Acc: 0.871795 | Val Loss: 0.112661, Val Acc: 0.773196\n",
      "Epoch 22657 - Train Loss: 0.081182, Train Acc: 0.871795 | Val Loss: 0.112660, Val Acc: 0.773196\n",
      "Epoch 22658 - Train Loss: 0.081180, Train Acc: 0.871795 | Val Loss: 0.112660, Val Acc: 0.773196\n",
      "Epoch 22659 - Train Loss: 0.081178, Train Acc: 0.871795 | Val Loss: 0.112659, Val Acc: 0.773196\n",
      "Epoch 22660 - Train Loss: 0.081176, Train Acc: 0.871795 | Val Loss: 0.112658, Val Acc: 0.773196\n",
      "Epoch 22661 - Train Loss: 0.081174, Train Acc: 0.871795 | Val Loss: 0.112657, Val Acc: 0.773196\n",
      "Epoch 22662 - Train Loss: 0.081172, Train Acc: 0.871795 | Val Loss: 0.112657, Val Acc: 0.773196\n",
      "Epoch 22663 - Train Loss: 0.081171, Train Acc: 0.871795 | Val Loss: 0.112656, Val Acc: 0.773196\n",
      "Epoch 22664 - Train Loss: 0.081169, Train Acc: 0.871795 | Val Loss: 0.112655, Val Acc: 0.773196\n",
      "Epoch 22665 - Train Loss: 0.081167, Train Acc: 0.871795 | Val Loss: 0.112654, Val Acc: 0.773196\n",
      "Epoch 22666 - Train Loss: 0.081165, Train Acc: 0.871795 | Val Loss: 0.112654, Val Acc: 0.773196\n",
      "Epoch 22667 - Train Loss: 0.081163, Train Acc: 0.871795 | Val Loss: 0.112653, Val Acc: 0.773196\n",
      "Epoch 22668 - Train Loss: 0.081161, Train Acc: 0.871795 | Val Loss: 0.112652, Val Acc: 0.773196\n",
      "Epoch 22669 - Train Loss: 0.081160, Train Acc: 0.871795 | Val Loss: 0.112651, Val Acc: 0.773196\n",
      "Epoch 22670 - Train Loss: 0.081158, Train Acc: 0.871795 | Val Loss: 0.112651, Val Acc: 0.773196\n",
      "Epoch 22671 - Train Loss: 0.081156, Train Acc: 0.871795 | Val Loss: 0.112650, Val Acc: 0.773196\n",
      "Epoch 22672 - Train Loss: 0.081154, Train Acc: 0.871795 | Val Loss: 0.112649, Val Acc: 0.773196\n",
      "Epoch 22673 - Train Loss: 0.081152, Train Acc: 0.871795 | Val Loss: 0.112649, Val Acc: 0.773196\n",
      "Epoch 22674 - Train Loss: 0.081151, Train Acc: 0.871795 | Val Loss: 0.112648, Val Acc: 0.773196\n",
      "Epoch 22675 - Train Loss: 0.081149, Train Acc: 0.871795 | Val Loss: 0.112647, Val Acc: 0.773196\n",
      "Epoch 22676 - Train Loss: 0.081147, Train Acc: 0.871795 | Val Loss: 0.112646, Val Acc: 0.773196\n",
      "Epoch 22677 - Train Loss: 0.081145, Train Acc: 0.871795 | Val Loss: 0.112646, Val Acc: 0.773196\n",
      "Epoch 22678 - Train Loss: 0.081143, Train Acc: 0.871795 | Val Loss: 0.112645, Val Acc: 0.773196\n",
      "Epoch 22679 - Train Loss: 0.081141, Train Acc: 0.871795 | Val Loss: 0.112644, Val Acc: 0.773196\n",
      "Epoch 22680 - Train Loss: 0.081140, Train Acc: 0.871795 | Val Loss: 0.112643, Val Acc: 0.773196\n",
      "Epoch 22681 - Train Loss: 0.081138, Train Acc: 0.871795 | Val Loss: 0.112643, Val Acc: 0.773196\n",
      "Epoch 22682 - Train Loss: 0.081136, Train Acc: 0.871795 | Val Loss: 0.112642, Val Acc: 0.773196\n",
      "Epoch 22683 - Train Loss: 0.081134, Train Acc: 0.871795 | Val Loss: 0.112641, Val Acc: 0.773196\n",
      "Epoch 22684 - Train Loss: 0.081132, Train Acc: 0.871795 | Val Loss: 0.112641, Val Acc: 0.773196\n",
      "Epoch 22685 - Train Loss: 0.081130, Train Acc: 0.871795 | Val Loss: 0.112640, Val Acc: 0.773196\n",
      "Epoch 22686 - Train Loss: 0.081129, Train Acc: 0.871795 | Val Loss: 0.112639, Val Acc: 0.773196\n",
      "Epoch 22687 - Train Loss: 0.081127, Train Acc: 0.871795 | Val Loss: 0.112638, Val Acc: 0.773196\n",
      "Epoch 22688 - Train Loss: 0.081125, Train Acc: 0.871795 | Val Loss: 0.112638, Val Acc: 0.773196\n",
      "Epoch 22689 - Train Loss: 0.081123, Train Acc: 0.871795 | Val Loss: 0.112637, Val Acc: 0.773196\n",
      "Epoch 22690 - Train Loss: 0.081121, Train Acc: 0.871795 | Val Loss: 0.112636, Val Acc: 0.773196\n",
      "Epoch 22691 - Train Loss: 0.081119, Train Acc: 0.871795 | Val Loss: 0.112635, Val Acc: 0.773196\n",
      "Epoch 22692 - Train Loss: 0.081118, Train Acc: 0.871795 | Val Loss: 0.112635, Val Acc: 0.773196\n",
      "Epoch 22693 - Train Loss: 0.081116, Train Acc: 0.871795 | Val Loss: 0.112634, Val Acc: 0.773196\n",
      "Epoch 22694 - Train Loss: 0.081114, Train Acc: 0.871795 | Val Loss: 0.112633, Val Acc: 0.773196\n",
      "Epoch 22695 - Train Loss: 0.081112, Train Acc: 0.871795 | Val Loss: 0.112632, Val Acc: 0.773196\n",
      "Epoch 22696 - Train Loss: 0.081110, Train Acc: 0.871795 | Val Loss: 0.112632, Val Acc: 0.773196\n",
      "Epoch 22697 - Train Loss: 0.081108, Train Acc: 0.871795 | Val Loss: 0.112631, Val Acc: 0.773196\n",
      "Epoch 22698 - Train Loss: 0.081107, Train Acc: 0.871795 | Val Loss: 0.112630, Val Acc: 0.773196\n",
      "Epoch 22699 - Train Loss: 0.081105, Train Acc: 0.871795 | Val Loss: 0.112630, Val Acc: 0.773196\n",
      "Epoch 22700 - Train Loss: 0.081103, Train Acc: 0.871795 | Val Loss: 0.112629, Val Acc: 0.773196\n",
      "Epoch 22701 - Train Loss: 0.081101, Train Acc: 0.871795 | Val Loss: 0.112628, Val Acc: 0.773196\n",
      "Epoch 22702 - Train Loss: 0.081099, Train Acc: 0.871795 | Val Loss: 0.112627, Val Acc: 0.773196\n",
      "Epoch 22703 - Train Loss: 0.081098, Train Acc: 0.871795 | Val Loss: 0.112627, Val Acc: 0.773196\n",
      "Epoch 22704 - Train Loss: 0.081096, Train Acc: 0.871795 | Val Loss: 0.112626, Val Acc: 0.773196\n",
      "Epoch 22705 - Train Loss: 0.081094, Train Acc: 0.871795 | Val Loss: 0.112625, Val Acc: 0.773196\n",
      "Epoch 22706 - Train Loss: 0.081092, Train Acc: 0.871795 | Val Loss: 0.112624, Val Acc: 0.773196\n",
      "Epoch 22707 - Train Loss: 0.081090, Train Acc: 0.871795 | Val Loss: 0.112624, Val Acc: 0.773196\n",
      "Epoch 22708 - Train Loss: 0.081088, Train Acc: 0.871795 | Val Loss: 0.112623, Val Acc: 0.773196\n",
      "Epoch 22709 - Train Loss: 0.081087, Train Acc: 0.871795 | Val Loss: 0.112622, Val Acc: 0.773196\n",
      "Epoch 22710 - Train Loss: 0.081085, Train Acc: 0.871795 | Val Loss: 0.112622, Val Acc: 0.773196\n",
      "Epoch 22711 - Train Loss: 0.081083, Train Acc: 0.871795 | Val Loss: 0.112621, Val Acc: 0.773196\n",
      "Epoch 22712 - Train Loss: 0.081081, Train Acc: 0.871795 | Val Loss: 0.112620, Val Acc: 0.773196\n",
      "Epoch 22713 - Train Loss: 0.081079, Train Acc: 0.871795 | Val Loss: 0.112619, Val Acc: 0.773196\n",
      "Epoch 22714 - Train Loss: 0.081077, Train Acc: 0.871795 | Val Loss: 0.112619, Val Acc: 0.773196\n",
      "Epoch 22715 - Train Loss: 0.081076, Train Acc: 0.871795 | Val Loss: 0.112618, Val Acc: 0.773196\n",
      "Epoch 22716 - Train Loss: 0.081074, Train Acc: 0.871795 | Val Loss: 0.112617, Val Acc: 0.773196\n",
      "Epoch 22717 - Train Loss: 0.081072, Train Acc: 0.871795 | Val Loss: 0.112617, Val Acc: 0.773196\n",
      "Epoch 22718 - Train Loss: 0.081070, Train Acc: 0.871795 | Val Loss: 0.112616, Val Acc: 0.773196\n",
      "Epoch 22719 - Train Loss: 0.081068, Train Acc: 0.871795 | Val Loss: 0.112615, Val Acc: 0.773196\n",
      "Epoch 22720 - Train Loss: 0.081067, Train Acc: 0.871795 | Val Loss: 0.112614, Val Acc: 0.773196\n",
      "Epoch 22721 - Train Loss: 0.081065, Train Acc: 0.871795 | Val Loss: 0.112614, Val Acc: 0.773196\n",
      "Epoch 22722 - Train Loss: 0.081063, Train Acc: 0.871795 | Val Loss: 0.112613, Val Acc: 0.773196\n",
      "Epoch 22723 - Train Loss: 0.081061, Train Acc: 0.871795 | Val Loss: 0.112612, Val Acc: 0.773196\n",
      "Epoch 22724 - Train Loss: 0.081059, Train Acc: 0.871795 | Val Loss: 0.112611, Val Acc: 0.773196\n",
      "Epoch 22725 - Train Loss: 0.081057, Train Acc: 0.871795 | Val Loss: 0.112611, Val Acc: 0.773196\n",
      "Epoch 22726 - Train Loss: 0.081056, Train Acc: 0.871795 | Val Loss: 0.112610, Val Acc: 0.773196\n",
      "Epoch 22727 - Train Loss: 0.081054, Train Acc: 0.871795 | Val Loss: 0.112609, Val Acc: 0.773196\n",
      "Epoch 22728 - Train Loss: 0.081052, Train Acc: 0.871795 | Val Loss: 0.112609, Val Acc: 0.773196\n",
      "Epoch 22729 - Train Loss: 0.081050, Train Acc: 0.871795 | Val Loss: 0.112608, Val Acc: 0.773196\n",
      "Epoch 22730 - Train Loss: 0.081048, Train Acc: 0.871795 | Val Loss: 0.112607, Val Acc: 0.773196\n",
      "Epoch 22731 - Train Loss: 0.081046, Train Acc: 0.871795 | Val Loss: 0.112606, Val Acc: 0.773196\n",
      "Epoch 22732 - Train Loss: 0.081045, Train Acc: 0.871795 | Val Loss: 0.112606, Val Acc: 0.773196\n",
      "Epoch 22733 - Train Loss: 0.081043, Train Acc: 0.871795 | Val Loss: 0.112605, Val Acc: 0.773196\n",
      "Epoch 22734 - Train Loss: 0.081041, Train Acc: 0.871795 | Val Loss: 0.112604, Val Acc: 0.773196\n",
      "Epoch 22735 - Train Loss: 0.081039, Train Acc: 0.871795 | Val Loss: 0.112603, Val Acc: 0.773196\n",
      "Epoch 22736 - Train Loss: 0.081037, Train Acc: 0.871795 | Val Loss: 0.112603, Val Acc: 0.773196\n",
      "Epoch 22737 - Train Loss: 0.081036, Train Acc: 0.871795 | Val Loss: 0.112602, Val Acc: 0.773196\n",
      "Epoch 22738 - Train Loss: 0.081034, Train Acc: 0.871795 | Val Loss: 0.112601, Val Acc: 0.773196\n",
      "Epoch 22739 - Train Loss: 0.081032, Train Acc: 0.871795 | Val Loss: 0.112601, Val Acc: 0.773196\n",
      "Epoch 22740 - Train Loss: 0.081030, Train Acc: 0.871795 | Val Loss: 0.112600, Val Acc: 0.773196\n",
      "Epoch 22741 - Train Loss: 0.081028, Train Acc: 0.871795 | Val Loss: 0.112599, Val Acc: 0.773196\n",
      "Epoch 22742 - Train Loss: 0.081026, Train Acc: 0.871795 | Val Loss: 0.112598, Val Acc: 0.773196\n",
      "Epoch 22743 - Train Loss: 0.081025, Train Acc: 0.871795 | Val Loss: 0.112598, Val Acc: 0.773196\n",
      "Epoch 22744 - Train Loss: 0.081023, Train Acc: 0.871795 | Val Loss: 0.112597, Val Acc: 0.773196\n",
      "Epoch 22745 - Train Loss: 0.081021, Train Acc: 0.871795 | Val Loss: 0.112596, Val Acc: 0.773196\n",
      "Epoch 22746 - Train Loss: 0.081019, Train Acc: 0.871795 | Val Loss: 0.112595, Val Acc: 0.773196\n",
      "Epoch 22747 - Train Loss: 0.081017, Train Acc: 0.871795 | Val Loss: 0.112595, Val Acc: 0.773196\n",
      "Epoch 22748 - Train Loss: 0.081016, Train Acc: 0.871795 | Val Loss: 0.112594, Val Acc: 0.773196\n",
      "Epoch 22749 - Train Loss: 0.081014, Train Acc: 0.871795 | Val Loss: 0.112593, Val Acc: 0.773196\n",
      "Epoch 22750 - Train Loss: 0.081012, Train Acc: 0.871795 | Val Loss: 0.112593, Val Acc: 0.773196\n",
      "Epoch 22751 - Train Loss: 0.081010, Train Acc: 0.871795 | Val Loss: 0.112592, Val Acc: 0.773196\n",
      "Epoch 22752 - Train Loss: 0.081008, Train Acc: 0.871795 | Val Loss: 0.112591, Val Acc: 0.773196\n",
      "Epoch 22753 - Train Loss: 0.081006, Train Acc: 0.871795 | Val Loss: 0.112590, Val Acc: 0.773196\n",
      "Epoch 22754 - Train Loss: 0.081005, Train Acc: 0.871795 | Val Loss: 0.112590, Val Acc: 0.773196\n",
      "Epoch 22755 - Train Loss: 0.081003, Train Acc: 0.871795 | Val Loss: 0.112589, Val Acc: 0.773196\n",
      "Epoch 22756 - Train Loss: 0.081001, Train Acc: 0.871795 | Val Loss: 0.112588, Val Acc: 0.773196\n",
      "Epoch 22757 - Train Loss: 0.080999, Train Acc: 0.871795 | Val Loss: 0.112588, Val Acc: 0.773196\n",
      "Epoch 22758 - Train Loss: 0.080997, Train Acc: 0.871795 | Val Loss: 0.112587, Val Acc: 0.773196\n",
      "Epoch 22759 - Train Loss: 0.080996, Train Acc: 0.871795 | Val Loss: 0.112586, Val Acc: 0.773196\n",
      "Epoch 22760 - Train Loss: 0.080994, Train Acc: 0.871795 | Val Loss: 0.112585, Val Acc: 0.773196\n",
      "Epoch 22761 - Train Loss: 0.080992, Train Acc: 0.871795 | Val Loss: 0.112585, Val Acc: 0.773196\n",
      "Epoch 22762 - Train Loss: 0.080990, Train Acc: 0.871795 | Val Loss: 0.112584, Val Acc: 0.773196\n",
      "Epoch 22763 - Train Loss: 0.080988, Train Acc: 0.871795 | Val Loss: 0.112583, Val Acc: 0.773196\n",
      "Epoch 22764 - Train Loss: 0.080986, Train Acc: 0.871795 | Val Loss: 0.112583, Val Acc: 0.773196\n",
      "Epoch 22765 - Train Loss: 0.080985, Train Acc: 0.871795 | Val Loss: 0.112582, Val Acc: 0.773196\n",
      "Epoch 22766 - Train Loss: 0.080983, Train Acc: 0.871795 | Val Loss: 0.112581, Val Acc: 0.773196\n",
      "Epoch 22767 - Train Loss: 0.080981, Train Acc: 0.871795 | Val Loss: 0.112580, Val Acc: 0.773196\n",
      "Epoch 22768 - Train Loss: 0.080979, Train Acc: 0.871795 | Val Loss: 0.112580, Val Acc: 0.773196\n",
      "Epoch 22769 - Train Loss: 0.080977, Train Acc: 0.871795 | Val Loss: 0.112579, Val Acc: 0.773196\n",
      "Epoch 22770 - Train Loss: 0.080976, Train Acc: 0.871795 | Val Loss: 0.112578, Val Acc: 0.773196\n",
      "Epoch 22771 - Train Loss: 0.080974, Train Acc: 0.871795 | Val Loss: 0.112577, Val Acc: 0.773196\n",
      "Epoch 22772 - Train Loss: 0.080972, Train Acc: 0.871795 | Val Loss: 0.112577, Val Acc: 0.773196\n",
      "Epoch 22773 - Train Loss: 0.080970, Train Acc: 0.871795 | Val Loss: 0.112576, Val Acc: 0.773196\n",
      "Epoch 22774 - Train Loss: 0.080968, Train Acc: 0.871795 | Val Loss: 0.112575, Val Acc: 0.773196\n",
      "Epoch 22775 - Train Loss: 0.080966, Train Acc: 0.871795 | Val Loss: 0.112575, Val Acc: 0.773196\n",
      "Epoch 22776 - Train Loss: 0.080965, Train Acc: 0.871795 | Val Loss: 0.112574, Val Acc: 0.773196\n",
      "Epoch 22777 - Train Loss: 0.080963, Train Acc: 0.871795 | Val Loss: 0.112573, Val Acc: 0.773196\n",
      "Epoch 22778 - Train Loss: 0.080961, Train Acc: 0.871795 | Val Loss: 0.112572, Val Acc: 0.773196\n",
      "Epoch 22779 - Train Loss: 0.080959, Train Acc: 0.871795 | Val Loss: 0.112572, Val Acc: 0.773196\n",
      "Epoch 22780 - Train Loss: 0.080957, Train Acc: 0.871795 | Val Loss: 0.112571, Val Acc: 0.773196\n",
      "Epoch 22781 - Train Loss: 0.080956, Train Acc: 0.871795 | Val Loss: 0.112570, Val Acc: 0.773196\n",
      "Epoch 22782 - Train Loss: 0.080954, Train Acc: 0.871795 | Val Loss: 0.112570, Val Acc: 0.773196\n",
      "Epoch 22783 - Train Loss: 0.080952, Train Acc: 0.871795 | Val Loss: 0.112569, Val Acc: 0.773196\n",
      "Epoch 22784 - Train Loss: 0.080950, Train Acc: 0.871795 | Val Loss: 0.112568, Val Acc: 0.773196\n",
      "Epoch 22785 - Train Loss: 0.080948, Train Acc: 0.871795 | Val Loss: 0.112567, Val Acc: 0.773196\n",
      "Epoch 22786 - Train Loss: 0.080946, Train Acc: 0.871795 | Val Loss: 0.112567, Val Acc: 0.773196\n",
      "Epoch 22787 - Train Loss: 0.080945, Train Acc: 0.871795 | Val Loss: 0.112566, Val Acc: 0.773196\n",
      "Epoch 22788 - Train Loss: 0.080943, Train Acc: 0.871795 | Val Loss: 0.112565, Val Acc: 0.773196\n",
      "Epoch 22789 - Train Loss: 0.080941, Train Acc: 0.871795 | Val Loss: 0.112565, Val Acc: 0.773196\n",
      "Epoch 22790 - Train Loss: 0.080939, Train Acc: 0.871795 | Val Loss: 0.112564, Val Acc: 0.773196\n",
      "Epoch 22791 - Train Loss: 0.080937, Train Acc: 0.871795 | Val Loss: 0.112563, Val Acc: 0.773196\n",
      "Epoch 22792 - Train Loss: 0.080936, Train Acc: 0.871795 | Val Loss: 0.112562, Val Acc: 0.773196\n",
      "Epoch 22793 - Train Loss: 0.080934, Train Acc: 0.871795 | Val Loss: 0.112562, Val Acc: 0.773196\n",
      "Epoch 22794 - Train Loss: 0.080932, Train Acc: 0.871795 | Val Loss: 0.112561, Val Acc: 0.773196\n",
      "Epoch 22795 - Train Loss: 0.080930, Train Acc: 0.871795 | Val Loss: 0.112560, Val Acc: 0.773196\n",
      "Epoch 22796 - Train Loss: 0.080928, Train Acc: 0.871795 | Val Loss: 0.112559, Val Acc: 0.773196\n",
      "Epoch 22797 - Train Loss: 0.080927, Train Acc: 0.871795 | Val Loss: 0.112559, Val Acc: 0.773196\n",
      "Epoch 22798 - Train Loss: 0.080925, Train Acc: 0.871795 | Val Loss: 0.112558, Val Acc: 0.773196\n",
      "Epoch 22799 - Train Loss: 0.080923, Train Acc: 0.871795 | Val Loss: 0.112557, Val Acc: 0.773196\n",
      "Epoch 22800 - Train Loss: 0.080921, Train Acc: 0.871795 | Val Loss: 0.112557, Val Acc: 0.773196\n",
      "Epoch 22801 - Train Loss: 0.080919, Train Acc: 0.871795 | Val Loss: 0.112556, Val Acc: 0.773196\n",
      "Epoch 22802 - Train Loss: 0.080917, Train Acc: 0.871795 | Val Loss: 0.112555, Val Acc: 0.773196\n",
      "Epoch 22803 - Train Loss: 0.080916, Train Acc: 0.871795 | Val Loss: 0.112554, Val Acc: 0.773196\n",
      "Epoch 22804 - Train Loss: 0.080914, Train Acc: 0.871795 | Val Loss: 0.112554, Val Acc: 0.773196\n",
      "Epoch 22805 - Train Loss: 0.080912, Train Acc: 0.871795 | Val Loss: 0.112553, Val Acc: 0.773196\n",
      "Epoch 22806 - Train Loss: 0.080910, Train Acc: 0.871795 | Val Loss: 0.112552, Val Acc: 0.773196\n",
      "Epoch 22807 - Train Loss: 0.080908, Train Acc: 0.871795 | Val Loss: 0.112552, Val Acc: 0.773196\n",
      "Epoch 22808 - Train Loss: 0.080907, Train Acc: 0.871795 | Val Loss: 0.112551, Val Acc: 0.773196\n",
      "Epoch 22809 - Train Loss: 0.080905, Train Acc: 0.871795 | Val Loss: 0.112550, Val Acc: 0.773196\n",
      "Epoch 22810 - Train Loss: 0.080903, Train Acc: 0.871795 | Val Loss: 0.112549, Val Acc: 0.773196\n",
      "Epoch 22811 - Train Loss: 0.080901, Train Acc: 0.871795 | Val Loss: 0.112549, Val Acc: 0.773196\n",
      "Epoch 22812 - Train Loss: 0.080899, Train Acc: 0.871795 | Val Loss: 0.112548, Val Acc: 0.773196\n",
      "Epoch 22813 - Train Loss: 0.080898, Train Acc: 0.871795 | Val Loss: 0.112547, Val Acc: 0.773196\n",
      "Epoch 22814 - Train Loss: 0.080896, Train Acc: 0.871795 | Val Loss: 0.112547, Val Acc: 0.773196\n",
      "Epoch 22815 - Train Loss: 0.080894, Train Acc: 0.871795 | Val Loss: 0.112546, Val Acc: 0.773196\n",
      "Epoch 22816 - Train Loss: 0.080892, Train Acc: 0.871795 | Val Loss: 0.112545, Val Acc: 0.773196\n",
      "Epoch 22817 - Train Loss: 0.080890, Train Acc: 0.871795 | Val Loss: 0.112544, Val Acc: 0.773196\n",
      "Epoch 22818 - Train Loss: 0.080888, Train Acc: 0.871795 | Val Loss: 0.112544, Val Acc: 0.773196\n",
      "Epoch 22819 - Train Loss: 0.080887, Train Acc: 0.871795 | Val Loss: 0.112543, Val Acc: 0.773196\n",
      "Epoch 22820 - Train Loss: 0.080885, Train Acc: 0.871795 | Val Loss: 0.112542, Val Acc: 0.773196\n",
      "Epoch 22821 - Train Loss: 0.080883, Train Acc: 0.871795 | Val Loss: 0.112542, Val Acc: 0.773196\n",
      "Epoch 22822 - Train Loss: 0.080881, Train Acc: 0.871795 | Val Loss: 0.112541, Val Acc: 0.773196\n",
      "Epoch 22823 - Train Loss: 0.080879, Train Acc: 0.871795 | Val Loss: 0.112540, Val Acc: 0.773196\n",
      "Epoch 22824 - Train Loss: 0.080878, Train Acc: 0.871795 | Val Loss: 0.112539, Val Acc: 0.773196\n",
      "Epoch 22825 - Train Loss: 0.080876, Train Acc: 0.871795 | Val Loss: 0.112539, Val Acc: 0.773196\n",
      "Epoch 22826 - Train Loss: 0.080874, Train Acc: 0.871795 | Val Loss: 0.112538, Val Acc: 0.773196\n",
      "Epoch 22827 - Train Loss: 0.080872, Train Acc: 0.871795 | Val Loss: 0.112537, Val Acc: 0.773196\n",
      "Epoch 22828 - Train Loss: 0.080870, Train Acc: 0.871795 | Val Loss: 0.112537, Val Acc: 0.773196\n",
      "Epoch 22829 - Train Loss: 0.080869, Train Acc: 0.871795 | Val Loss: 0.112536, Val Acc: 0.773196\n",
      "Epoch 22830 - Train Loss: 0.080867, Train Acc: 0.871795 | Val Loss: 0.112535, Val Acc: 0.773196\n",
      "Epoch 22831 - Train Loss: 0.080865, Train Acc: 0.871795 | Val Loss: 0.112534, Val Acc: 0.773196\n",
      "Epoch 22832 - Train Loss: 0.080863, Train Acc: 0.871795 | Val Loss: 0.112534, Val Acc: 0.773196\n",
      "Epoch 22833 - Train Loss: 0.080861, Train Acc: 0.871795 | Val Loss: 0.112533, Val Acc: 0.773196\n",
      "Epoch 22834 - Train Loss: 0.080860, Train Acc: 0.871795 | Val Loss: 0.112532, Val Acc: 0.773196\n",
      "Epoch 22835 - Train Loss: 0.080858, Train Acc: 0.871795 | Val Loss: 0.112532, Val Acc: 0.773196\n",
      "Epoch 22836 - Train Loss: 0.080856, Train Acc: 0.871795 | Val Loss: 0.112531, Val Acc: 0.773196\n",
      "Epoch 22837 - Train Loss: 0.080854, Train Acc: 0.871795 | Val Loss: 0.112530, Val Acc: 0.773196\n",
      "Epoch 22838 - Train Loss: 0.080852, Train Acc: 0.871795 | Val Loss: 0.112529, Val Acc: 0.773196\n",
      "Epoch 22839 - Train Loss: 0.080850, Train Acc: 0.871795 | Val Loss: 0.112529, Val Acc: 0.773196\n",
      "Epoch 22840 - Train Loss: 0.080849, Train Acc: 0.871795 | Val Loss: 0.112528, Val Acc: 0.773196\n",
      "Epoch 22841 - Train Loss: 0.080847, Train Acc: 0.871795 | Val Loss: 0.112527, Val Acc: 0.773196\n",
      "Epoch 22842 - Train Loss: 0.080845, Train Acc: 0.871795 | Val Loss: 0.112527, Val Acc: 0.773196\n",
      "Epoch 22843 - Train Loss: 0.080843, Train Acc: 0.871795 | Val Loss: 0.112526, Val Acc: 0.773196\n",
      "Epoch 22844 - Train Loss: 0.080841, Train Acc: 0.871795 | Val Loss: 0.112525, Val Acc: 0.773196\n",
      "Epoch 22845 - Train Loss: 0.080840, Train Acc: 0.871795 | Val Loss: 0.112524, Val Acc: 0.773196\n",
      "Epoch 22846 - Train Loss: 0.080838, Train Acc: 0.871795 | Val Loss: 0.112524, Val Acc: 0.773196\n",
      "Epoch 22847 - Train Loss: 0.080836, Train Acc: 0.871795 | Val Loss: 0.112523, Val Acc: 0.773196\n",
      "Epoch 22848 - Train Loss: 0.080834, Train Acc: 0.871795 | Val Loss: 0.112522, Val Acc: 0.773196\n",
      "Epoch 22849 - Train Loss: 0.080832, Train Acc: 0.871795 | Val Loss: 0.112522, Val Acc: 0.773196\n",
      "Epoch 22850 - Train Loss: 0.080831, Train Acc: 0.871795 | Val Loss: 0.112521, Val Acc: 0.773196\n",
      "Epoch 22851 - Train Loss: 0.080829, Train Acc: 0.871795 | Val Loss: 0.112520, Val Acc: 0.773196\n",
      "Epoch 22852 - Train Loss: 0.080827, Train Acc: 0.871795 | Val Loss: 0.112519, Val Acc: 0.773196\n",
      "Epoch 22853 - Train Loss: 0.080825, Train Acc: 0.871795 | Val Loss: 0.112519, Val Acc: 0.773196\n",
      "Epoch 22854 - Train Loss: 0.080823, Train Acc: 0.871795 | Val Loss: 0.112518, Val Acc: 0.773196\n",
      "Epoch 22855 - Train Loss: 0.080822, Train Acc: 0.871795 | Val Loss: 0.112517, Val Acc: 0.773196\n",
      "Epoch 22856 - Train Loss: 0.080820, Train Acc: 0.871795 | Val Loss: 0.112517, Val Acc: 0.773196\n",
      "Epoch 22857 - Train Loss: 0.080818, Train Acc: 0.871795 | Val Loss: 0.112516, Val Acc: 0.773196\n",
      "Epoch 22858 - Train Loss: 0.080816, Train Acc: 0.871795 | Val Loss: 0.112515, Val Acc: 0.773196\n",
      "Epoch 22859 - Train Loss: 0.080814, Train Acc: 0.871795 | Val Loss: 0.112514, Val Acc: 0.773196\n",
      "Epoch 22860 - Train Loss: 0.080813, Train Acc: 0.871795 | Val Loss: 0.112514, Val Acc: 0.773196\n",
      "Epoch 22861 - Train Loss: 0.080811, Train Acc: 0.871795 | Val Loss: 0.112513, Val Acc: 0.773196\n",
      "Epoch 22862 - Train Loss: 0.080809, Train Acc: 0.871795 | Val Loss: 0.112512, Val Acc: 0.773196\n",
      "Epoch 22863 - Train Loss: 0.080807, Train Acc: 0.871795 | Val Loss: 0.112512, Val Acc: 0.773196\n",
      "Epoch 22864 - Train Loss: 0.080805, Train Acc: 0.871795 | Val Loss: 0.112511, Val Acc: 0.773196\n",
      "Epoch 22865 - Train Loss: 0.080804, Train Acc: 0.871795 | Val Loss: 0.112510, Val Acc: 0.773196\n",
      "Epoch 22866 - Train Loss: 0.080802, Train Acc: 0.871795 | Val Loss: 0.112510, Val Acc: 0.773196\n",
      "Epoch 22867 - Train Loss: 0.080800, Train Acc: 0.871795 | Val Loss: 0.112509, Val Acc: 0.773196\n",
      "Epoch 22868 - Train Loss: 0.080798, Train Acc: 0.871795 | Val Loss: 0.112508, Val Acc: 0.773196\n",
      "Epoch 22869 - Train Loss: 0.080796, Train Acc: 0.871795 | Val Loss: 0.112507, Val Acc: 0.773196\n",
      "Epoch 22870 - Train Loss: 0.080794, Train Acc: 0.871795 | Val Loss: 0.112507, Val Acc: 0.773196\n",
      "Epoch 22871 - Train Loss: 0.080793, Train Acc: 0.871795 | Val Loss: 0.112506, Val Acc: 0.773196\n",
      "Epoch 22872 - Train Loss: 0.080791, Train Acc: 0.871795 | Val Loss: 0.112505, Val Acc: 0.773196\n",
      "Epoch 22873 - Train Loss: 0.080789, Train Acc: 0.871795 | Val Loss: 0.112505, Val Acc: 0.773196\n",
      "Epoch 22874 - Train Loss: 0.080787, Train Acc: 0.871795 | Val Loss: 0.112504, Val Acc: 0.773196\n",
      "Epoch 22875 - Train Loss: 0.080785, Train Acc: 0.871795 | Val Loss: 0.112503, Val Acc: 0.773196\n",
      "Epoch 22876 - Train Loss: 0.080784, Train Acc: 0.871795 | Val Loss: 0.112502, Val Acc: 0.773196\n",
      "Epoch 22877 - Train Loss: 0.080782, Train Acc: 0.871795 | Val Loss: 0.112502, Val Acc: 0.773196\n",
      "Epoch 22878 - Train Loss: 0.080780, Train Acc: 0.871795 | Val Loss: 0.112501, Val Acc: 0.773196\n",
      "Epoch 22879 - Train Loss: 0.080778, Train Acc: 0.871795 | Val Loss: 0.112500, Val Acc: 0.773196\n",
      "Epoch 22880 - Train Loss: 0.080776, Train Acc: 0.871795 | Val Loss: 0.112500, Val Acc: 0.773196\n",
      "Epoch 22881 - Train Loss: 0.080775, Train Acc: 0.871795 | Val Loss: 0.112499, Val Acc: 0.773196\n",
      "Epoch 22882 - Train Loss: 0.080773, Train Acc: 0.871795 | Val Loss: 0.112498, Val Acc: 0.773196\n",
      "Epoch 22883 - Train Loss: 0.080771, Train Acc: 0.871795 | Val Loss: 0.112497, Val Acc: 0.773196\n",
      "Epoch 22884 - Train Loss: 0.080769, Train Acc: 0.871795 | Val Loss: 0.112497, Val Acc: 0.773196\n",
      "Epoch 22885 - Train Loss: 0.080767, Train Acc: 0.871795 | Val Loss: 0.112496, Val Acc: 0.773196\n",
      "Epoch 22886 - Train Loss: 0.080766, Train Acc: 0.871795 | Val Loss: 0.112495, Val Acc: 0.773196\n",
      "Epoch 22887 - Train Loss: 0.080764, Train Acc: 0.871795 | Val Loss: 0.112495, Val Acc: 0.773196\n",
      "Epoch 22888 - Train Loss: 0.080762, Train Acc: 0.871795 | Val Loss: 0.112494, Val Acc: 0.773196\n",
      "Epoch 22889 - Train Loss: 0.080760, Train Acc: 0.871795 | Val Loss: 0.112493, Val Acc: 0.773196\n",
      "Epoch 22890 - Train Loss: 0.080758, Train Acc: 0.871795 | Val Loss: 0.112492, Val Acc: 0.773196\n",
      "Epoch 22891 - Train Loss: 0.080757, Train Acc: 0.871795 | Val Loss: 0.112492, Val Acc: 0.773196\n",
      "Epoch 22892 - Train Loss: 0.080755, Train Acc: 0.871795 | Val Loss: 0.112491, Val Acc: 0.773196\n",
      "Epoch 22893 - Train Loss: 0.080753, Train Acc: 0.871795 | Val Loss: 0.112490, Val Acc: 0.773196\n",
      "Epoch 22894 - Train Loss: 0.080751, Train Acc: 0.871795 | Val Loss: 0.112490, Val Acc: 0.773196\n",
      "Epoch 22895 - Train Loss: 0.080749, Train Acc: 0.871795 | Val Loss: 0.112489, Val Acc: 0.773196\n",
      "Epoch 22896 - Train Loss: 0.080748, Train Acc: 0.871795 | Val Loss: 0.112488, Val Acc: 0.773196\n",
      "Epoch 22897 - Train Loss: 0.080746, Train Acc: 0.871795 | Val Loss: 0.112488, Val Acc: 0.773196\n",
      "Epoch 22898 - Train Loss: 0.080744, Train Acc: 0.871795 | Val Loss: 0.112487, Val Acc: 0.773196\n",
      "Epoch 22899 - Train Loss: 0.080742, Train Acc: 0.871795 | Val Loss: 0.112486, Val Acc: 0.773196\n",
      "Epoch 22900 - Train Loss: 0.080740, Train Acc: 0.871795 | Val Loss: 0.112485, Val Acc: 0.773196\n",
      "Epoch 22901 - Train Loss: 0.080739, Train Acc: 0.871795 | Val Loss: 0.112485, Val Acc: 0.773196\n",
      "Epoch 22902 - Train Loss: 0.080737, Train Acc: 0.871795 | Val Loss: 0.112484, Val Acc: 0.773196\n",
      "Epoch 22903 - Train Loss: 0.080735, Train Acc: 0.871795 | Val Loss: 0.112483, Val Acc: 0.773196\n",
      "Epoch 22904 - Train Loss: 0.080733, Train Acc: 0.871795 | Val Loss: 0.112483, Val Acc: 0.773196\n",
      "Epoch 22905 - Train Loss: 0.080731, Train Acc: 0.871795 | Val Loss: 0.112482, Val Acc: 0.773196\n",
      "Epoch 22906 - Train Loss: 0.080730, Train Acc: 0.871795 | Val Loss: 0.112481, Val Acc: 0.773196\n",
      "Epoch 22907 - Train Loss: 0.080728, Train Acc: 0.871795 | Val Loss: 0.112480, Val Acc: 0.773196\n",
      "Epoch 22908 - Train Loss: 0.080726, Train Acc: 0.871795 | Val Loss: 0.112480, Val Acc: 0.773196\n",
      "Epoch 22909 - Train Loss: 0.080724, Train Acc: 0.871795 | Val Loss: 0.112479, Val Acc: 0.773196\n",
      "Epoch 22910 - Train Loss: 0.080722, Train Acc: 0.871795 | Val Loss: 0.112478, Val Acc: 0.773196\n",
      "Epoch 22911 - Train Loss: 0.080721, Train Acc: 0.871795 | Val Loss: 0.112478, Val Acc: 0.773196\n",
      "Epoch 22912 - Train Loss: 0.080719, Train Acc: 0.871795 | Val Loss: 0.112477, Val Acc: 0.773196\n",
      "Epoch 22913 - Train Loss: 0.080717, Train Acc: 0.871795 | Val Loss: 0.112476, Val Acc: 0.773196\n",
      "Epoch 22914 - Train Loss: 0.080715, Train Acc: 0.871795 | Val Loss: 0.112476, Val Acc: 0.773196\n",
      "Epoch 22915 - Train Loss: 0.080713, Train Acc: 0.871795 | Val Loss: 0.112475, Val Acc: 0.773196\n",
      "Epoch 22916 - Train Loss: 0.080712, Train Acc: 0.871795 | Val Loss: 0.112474, Val Acc: 0.773196\n",
      "Epoch 22917 - Train Loss: 0.080710, Train Acc: 0.871795 | Val Loss: 0.112473, Val Acc: 0.773196\n",
      "Epoch 22918 - Train Loss: 0.080708, Train Acc: 0.871795 | Val Loss: 0.112473, Val Acc: 0.773196\n",
      "Epoch 22919 - Train Loss: 0.080706, Train Acc: 0.871795 | Val Loss: 0.112472, Val Acc: 0.773196\n",
      "Epoch 22920 - Train Loss: 0.080704, Train Acc: 0.871795 | Val Loss: 0.112471, Val Acc: 0.773196\n",
      "Epoch 22921 - Train Loss: 0.080703, Train Acc: 0.871795 | Val Loss: 0.112471, Val Acc: 0.773196\n",
      "Epoch 22922 - Train Loss: 0.080701, Train Acc: 0.871795 | Val Loss: 0.112470, Val Acc: 0.773196\n",
      "Epoch 22923 - Train Loss: 0.080699, Train Acc: 0.871795 | Val Loss: 0.112469, Val Acc: 0.773196\n",
      "Epoch 22924 - Train Loss: 0.080697, Train Acc: 0.871795 | Val Loss: 0.112468, Val Acc: 0.773196\n",
      "Epoch 22925 - Train Loss: 0.080695, Train Acc: 0.871795 | Val Loss: 0.112468, Val Acc: 0.773196\n",
      "Epoch 22926 - Train Loss: 0.080694, Train Acc: 0.871795 | Val Loss: 0.112467, Val Acc: 0.773196\n",
      "Epoch 22927 - Train Loss: 0.080692, Train Acc: 0.871795 | Val Loss: 0.112466, Val Acc: 0.773196\n",
      "Epoch 22928 - Train Loss: 0.080690, Train Acc: 0.871795 | Val Loss: 0.112466, Val Acc: 0.773196\n",
      "Epoch 22929 - Train Loss: 0.080688, Train Acc: 0.871795 | Val Loss: 0.112465, Val Acc: 0.773196\n",
      "Epoch 22930 - Train Loss: 0.080686, Train Acc: 0.871795 | Val Loss: 0.112464, Val Acc: 0.773196\n",
      "Epoch 22931 - Train Loss: 0.080685, Train Acc: 0.871795 | Val Loss: 0.112464, Val Acc: 0.773196\n",
      "Epoch 22932 - Train Loss: 0.080683, Train Acc: 0.871795 | Val Loss: 0.112463, Val Acc: 0.773196\n",
      "Epoch 22933 - Train Loss: 0.080681, Train Acc: 0.871795 | Val Loss: 0.112462, Val Acc: 0.773196\n",
      "Epoch 22934 - Train Loss: 0.080679, Train Acc: 0.871795 | Val Loss: 0.112461, Val Acc: 0.773196\n",
      "Epoch 22935 - Train Loss: 0.080677, Train Acc: 0.871795 | Val Loss: 0.112461, Val Acc: 0.773196\n",
      "Epoch 22936 - Train Loss: 0.080676, Train Acc: 0.871795 | Val Loss: 0.112460, Val Acc: 0.773196\n",
      "Epoch 22937 - Train Loss: 0.080674, Train Acc: 0.871795 | Val Loss: 0.112459, Val Acc: 0.773196\n",
      "Epoch 22938 - Train Loss: 0.080672, Train Acc: 0.871795 | Val Loss: 0.112459, Val Acc: 0.773196\n",
      "Epoch 22939 - Train Loss: 0.080670, Train Acc: 0.871795 | Val Loss: 0.112458, Val Acc: 0.773196\n",
      "Epoch 22940 - Train Loss: 0.080668, Train Acc: 0.871795 | Val Loss: 0.112457, Val Acc: 0.773196\n",
      "Epoch 22941 - Train Loss: 0.080667, Train Acc: 0.871795 | Val Loss: 0.112457, Val Acc: 0.773196\n",
      "Epoch 22942 - Train Loss: 0.080665, Train Acc: 0.871795 | Val Loss: 0.112456, Val Acc: 0.773196\n",
      "Epoch 22943 - Train Loss: 0.080663, Train Acc: 0.871795 | Val Loss: 0.112455, Val Acc: 0.773196\n",
      "Epoch 22944 - Train Loss: 0.080661, Train Acc: 0.871795 | Val Loss: 0.112454, Val Acc: 0.773196\n",
      "Epoch 22945 - Train Loss: 0.080660, Train Acc: 0.871795 | Val Loss: 0.112454, Val Acc: 0.773196\n",
      "Epoch 22946 - Train Loss: 0.080658, Train Acc: 0.871795 | Val Loss: 0.112453, Val Acc: 0.773196\n",
      "Epoch 22947 - Train Loss: 0.080656, Train Acc: 0.871795 | Val Loss: 0.112452, Val Acc: 0.773196\n",
      "Epoch 22948 - Train Loss: 0.080654, Train Acc: 0.871795 | Val Loss: 0.112452, Val Acc: 0.773196\n",
      "Epoch 22949 - Train Loss: 0.080652, Train Acc: 0.871795 | Val Loss: 0.112451, Val Acc: 0.773196\n",
      "Epoch 22950 - Train Loss: 0.080651, Train Acc: 0.871795 | Val Loss: 0.112450, Val Acc: 0.773196\n",
      "Epoch 22951 - Train Loss: 0.080649, Train Acc: 0.871795 | Val Loss: 0.112450, Val Acc: 0.773196\n",
      "Epoch 22952 - Train Loss: 0.080647, Train Acc: 0.871795 | Val Loss: 0.112449, Val Acc: 0.773196\n",
      "Epoch 22953 - Train Loss: 0.080645, Train Acc: 0.871795 | Val Loss: 0.112448, Val Acc: 0.773196\n",
      "Epoch 22954 - Train Loss: 0.080643, Train Acc: 0.871795 | Val Loss: 0.112447, Val Acc: 0.773196\n",
      "Epoch 22955 - Train Loss: 0.080642, Train Acc: 0.871795 | Val Loss: 0.112447, Val Acc: 0.773196\n",
      "Epoch 22956 - Train Loss: 0.080640, Train Acc: 0.871795 | Val Loss: 0.112446, Val Acc: 0.773196\n",
      "Epoch 22957 - Train Loss: 0.080638, Train Acc: 0.871795 | Val Loss: 0.112445, Val Acc: 0.773196\n",
      "Epoch 22958 - Train Loss: 0.080636, Train Acc: 0.871795 | Val Loss: 0.112445, Val Acc: 0.773196\n",
      "Epoch 22959 - Train Loss: 0.080634, Train Acc: 0.871795 | Val Loss: 0.112444, Val Acc: 0.773196\n",
      "Epoch 22960 - Train Loss: 0.080633, Train Acc: 0.871795 | Val Loss: 0.112443, Val Acc: 0.773196\n",
      "Epoch 22961 - Train Loss: 0.080631, Train Acc: 0.871795 | Val Loss: 0.112442, Val Acc: 0.773196\n",
      "Epoch 22962 - Train Loss: 0.080629, Train Acc: 0.871795 | Val Loss: 0.112442, Val Acc: 0.773196\n",
      "Epoch 22963 - Train Loss: 0.080627, Train Acc: 0.871795 | Val Loss: 0.112441, Val Acc: 0.773196\n",
      "Epoch 22964 - Train Loss: 0.080625, Train Acc: 0.871795 | Val Loss: 0.112440, Val Acc: 0.773196\n",
      "Epoch 22965 - Train Loss: 0.080624, Train Acc: 0.871795 | Val Loss: 0.112440, Val Acc: 0.773196\n",
      "Epoch 22966 - Train Loss: 0.080622, Train Acc: 0.871795 | Val Loss: 0.112439, Val Acc: 0.773196\n",
      "Epoch 22967 - Train Loss: 0.080620, Train Acc: 0.871795 | Val Loss: 0.112438, Val Acc: 0.773196\n",
      "Epoch 22968 - Train Loss: 0.080618, Train Acc: 0.871795 | Val Loss: 0.112438, Val Acc: 0.773196\n",
      "Epoch 22969 - Train Loss: 0.080616, Train Acc: 0.871795 | Val Loss: 0.112437, Val Acc: 0.773196\n",
      "Epoch 22970 - Train Loss: 0.080615, Train Acc: 0.871795 | Val Loss: 0.112436, Val Acc: 0.773196\n",
      "Epoch 22971 - Train Loss: 0.080613, Train Acc: 0.871795 | Val Loss: 0.112435, Val Acc: 0.773196\n",
      "Epoch 22972 - Train Loss: 0.080611, Train Acc: 0.871795 | Val Loss: 0.112435, Val Acc: 0.773196\n",
      "Epoch 22973 - Train Loss: 0.080609, Train Acc: 0.871795 | Val Loss: 0.112434, Val Acc: 0.773196\n",
      "Epoch 22974 - Train Loss: 0.080607, Train Acc: 0.871795 | Val Loss: 0.112433, Val Acc: 0.773196\n",
      "Epoch 22975 - Train Loss: 0.080606, Train Acc: 0.871795 | Val Loss: 0.112433, Val Acc: 0.773196\n",
      "Epoch 22976 - Train Loss: 0.080604, Train Acc: 0.871795 | Val Loss: 0.112432, Val Acc: 0.773196\n",
      "Epoch 22977 - Train Loss: 0.080602, Train Acc: 0.871795 | Val Loss: 0.112431, Val Acc: 0.773196\n",
      "Epoch 22978 - Train Loss: 0.080600, Train Acc: 0.871795 | Val Loss: 0.112431, Val Acc: 0.773196\n",
      "Epoch 22979 - Train Loss: 0.080599, Train Acc: 0.871795 | Val Loss: 0.112430, Val Acc: 0.773196\n",
      "Epoch 22980 - Train Loss: 0.080597, Train Acc: 0.871795 | Val Loss: 0.112429, Val Acc: 0.773196\n",
      "Epoch 22981 - Train Loss: 0.080595, Train Acc: 0.871795 | Val Loss: 0.112429, Val Acc: 0.773196\n",
      "Epoch 22982 - Train Loss: 0.080593, Train Acc: 0.871795 | Val Loss: 0.112428, Val Acc: 0.773196\n",
      "Epoch 22983 - Train Loss: 0.080591, Train Acc: 0.871795 | Val Loss: 0.112427, Val Acc: 0.773196\n",
      "Epoch 22984 - Train Loss: 0.080590, Train Acc: 0.871795 | Val Loss: 0.112426, Val Acc: 0.773196\n",
      "Epoch 22985 - Train Loss: 0.080588, Train Acc: 0.871795 | Val Loss: 0.112426, Val Acc: 0.773196\n",
      "Epoch 22986 - Train Loss: 0.080586, Train Acc: 0.871795 | Val Loss: 0.112425, Val Acc: 0.773196\n",
      "Epoch 22987 - Train Loss: 0.080584, Train Acc: 0.871795 | Val Loss: 0.112424, Val Acc: 0.773196\n",
      "Epoch 22988 - Train Loss: 0.080582, Train Acc: 0.871795 | Val Loss: 0.112424, Val Acc: 0.773196\n",
      "Epoch 22989 - Train Loss: 0.080581, Train Acc: 0.871795 | Val Loss: 0.112423, Val Acc: 0.773196\n",
      "Epoch 22990 - Train Loss: 0.080579, Train Acc: 0.871795 | Val Loss: 0.112422, Val Acc: 0.773196\n",
      "Epoch 22991 - Train Loss: 0.080577, Train Acc: 0.871795 | Val Loss: 0.112422, Val Acc: 0.773196\n",
      "Epoch 22992 - Train Loss: 0.080575, Train Acc: 0.871795 | Val Loss: 0.112421, Val Acc: 0.773196\n",
      "Epoch 22993 - Train Loss: 0.080573, Train Acc: 0.871795 | Val Loss: 0.112420, Val Acc: 0.773196\n",
      "Epoch 22994 - Train Loss: 0.080572, Train Acc: 0.871795 | Val Loss: 0.112419, Val Acc: 0.773196\n",
      "Epoch 22995 - Train Loss: 0.080570, Train Acc: 0.871795 | Val Loss: 0.112419, Val Acc: 0.773196\n",
      "Epoch 22996 - Train Loss: 0.080568, Train Acc: 0.871795 | Val Loss: 0.112418, Val Acc: 0.773196\n",
      "Epoch 22997 - Train Loss: 0.080566, Train Acc: 0.871795 | Val Loss: 0.112417, Val Acc: 0.773196\n",
      "Epoch 22998 - Train Loss: 0.080565, Train Acc: 0.871795 | Val Loss: 0.112417, Val Acc: 0.773196\n",
      "Epoch 22999 - Train Loss: 0.080563, Train Acc: 0.871795 | Val Loss: 0.112416, Val Acc: 0.773196\n",
      "Epoch 23000 - Train Loss: 0.080561, Train Acc: 0.871795 | Val Loss: 0.112415, Val Acc: 0.773196\n",
      "Epoch 23001 - Train Loss: 0.080559, Train Acc: 0.871795 | Val Loss: 0.112415, Val Acc: 0.773196\n",
      "Epoch 23002 - Train Loss: 0.080557, Train Acc: 0.871795 | Val Loss: 0.112414, Val Acc: 0.773196\n",
      "Epoch 23003 - Train Loss: 0.080556, Train Acc: 0.871795 | Val Loss: 0.112413, Val Acc: 0.773196\n",
      "Epoch 23004 - Train Loss: 0.080554, Train Acc: 0.871795 | Val Loss: 0.112412, Val Acc: 0.773196\n",
      "Epoch 23005 - Train Loss: 0.080552, Train Acc: 0.871795 | Val Loss: 0.112412, Val Acc: 0.773196\n",
      "Epoch 23006 - Train Loss: 0.080550, Train Acc: 0.871795 | Val Loss: 0.112411, Val Acc: 0.773196\n",
      "Epoch 23007 - Train Loss: 0.080548, Train Acc: 0.871795 | Val Loss: 0.112410, Val Acc: 0.773196\n",
      "Epoch 23008 - Train Loss: 0.080547, Train Acc: 0.871795 | Val Loss: 0.112410, Val Acc: 0.773196\n",
      "Epoch 23009 - Train Loss: 0.080545, Train Acc: 0.871795 | Val Loss: 0.112409, Val Acc: 0.773196\n",
      "Epoch 23010 - Train Loss: 0.080543, Train Acc: 0.871795 | Val Loss: 0.112408, Val Acc: 0.773196\n",
      "Epoch 23011 - Train Loss: 0.080541, Train Acc: 0.871795 | Val Loss: 0.112408, Val Acc: 0.773196\n",
      "Epoch 23012 - Train Loss: 0.080539, Train Acc: 0.871795 | Val Loss: 0.112407, Val Acc: 0.773196\n",
      "Epoch 23013 - Train Loss: 0.080538, Train Acc: 0.871795 | Val Loss: 0.112406, Val Acc: 0.773196\n",
      "Epoch 23014 - Train Loss: 0.080536, Train Acc: 0.871795 | Val Loss: 0.112406, Val Acc: 0.773196\n",
      "Epoch 23015 - Train Loss: 0.080534, Train Acc: 0.871795 | Val Loss: 0.112405, Val Acc: 0.773196\n",
      "Epoch 23016 - Train Loss: 0.080532, Train Acc: 0.871795 | Val Loss: 0.112404, Val Acc: 0.773196\n",
      "Epoch 23017 - Train Loss: 0.080531, Train Acc: 0.871795 | Val Loss: 0.112403, Val Acc: 0.773196\n",
      "Epoch 23018 - Train Loss: 0.080529, Train Acc: 0.871795 | Val Loss: 0.112403, Val Acc: 0.773196\n",
      "Epoch 23019 - Train Loss: 0.080527, Train Acc: 0.871795 | Val Loss: 0.112402, Val Acc: 0.773196\n",
      "Epoch 23020 - Train Loss: 0.080525, Train Acc: 0.871795 | Val Loss: 0.112401, Val Acc: 0.773196\n",
      "Epoch 23021 - Train Loss: 0.080523, Train Acc: 0.871795 | Val Loss: 0.112401, Val Acc: 0.773196\n",
      "Epoch 23022 - Train Loss: 0.080522, Train Acc: 0.871795 | Val Loss: 0.112400, Val Acc: 0.773196\n",
      "Epoch 23023 - Train Loss: 0.080520, Train Acc: 0.871795 | Val Loss: 0.112399, Val Acc: 0.773196\n",
      "Epoch 23024 - Train Loss: 0.080518, Train Acc: 0.871795 | Val Loss: 0.112399, Val Acc: 0.773196\n",
      "Epoch 23025 - Train Loss: 0.080516, Train Acc: 0.871795 | Val Loss: 0.112398, Val Acc: 0.773196\n",
      "Epoch 23026 - Train Loss: 0.080514, Train Acc: 0.871795 | Val Loss: 0.112397, Val Acc: 0.773196\n",
      "Epoch 23027 - Train Loss: 0.080513, Train Acc: 0.871795 | Val Loss: 0.112396, Val Acc: 0.773196\n",
      "Epoch 23028 - Train Loss: 0.080511, Train Acc: 0.871795 | Val Loss: 0.112396, Val Acc: 0.773196\n",
      "Epoch 23029 - Train Loss: 0.080509, Train Acc: 0.871795 | Val Loss: 0.112395, Val Acc: 0.773196\n",
      "Epoch 23030 - Train Loss: 0.080507, Train Acc: 0.871795 | Val Loss: 0.112394, Val Acc: 0.773196\n",
      "Epoch 23031 - Train Loss: 0.080506, Train Acc: 0.871795 | Val Loss: 0.112394, Val Acc: 0.773196\n",
      "Epoch 23032 - Train Loss: 0.080504, Train Acc: 0.871795 | Val Loss: 0.112393, Val Acc: 0.773196\n",
      "Epoch 23033 - Train Loss: 0.080502, Train Acc: 0.871795 | Val Loss: 0.112392, Val Acc: 0.773196\n",
      "Epoch 23034 - Train Loss: 0.080500, Train Acc: 0.871795 | Val Loss: 0.112392, Val Acc: 0.773196\n",
      "Epoch 23035 - Train Loss: 0.080498, Train Acc: 0.871795 | Val Loss: 0.112391, Val Acc: 0.773196\n",
      "Epoch 23036 - Train Loss: 0.080497, Train Acc: 0.871795 | Val Loss: 0.112390, Val Acc: 0.773196\n",
      "Epoch 23037 - Train Loss: 0.080495, Train Acc: 0.871795 | Val Loss: 0.112390, Val Acc: 0.773196\n",
      "Epoch 23038 - Train Loss: 0.080493, Train Acc: 0.871795 | Val Loss: 0.112389, Val Acc: 0.773196\n",
      "Epoch 23039 - Train Loss: 0.080491, Train Acc: 0.871795 | Val Loss: 0.112388, Val Acc: 0.773196\n",
      "Epoch 23040 - Train Loss: 0.080489, Train Acc: 0.871795 | Val Loss: 0.112387, Val Acc: 0.773196\n",
      "Epoch 23041 - Train Loss: 0.080488, Train Acc: 0.871795 | Val Loss: 0.112387, Val Acc: 0.773196\n",
      "Epoch 23042 - Train Loss: 0.080486, Train Acc: 0.871795 | Val Loss: 0.112386, Val Acc: 0.773196\n",
      "Epoch 23043 - Train Loss: 0.080484, Train Acc: 0.871795 | Val Loss: 0.112385, Val Acc: 0.773196\n",
      "Epoch 23044 - Train Loss: 0.080482, Train Acc: 0.871795 | Val Loss: 0.112385, Val Acc: 0.773196\n",
      "Epoch 23045 - Train Loss: 0.080481, Train Acc: 0.871795 | Val Loss: 0.112384, Val Acc: 0.773196\n",
      "Epoch 23046 - Train Loss: 0.080479, Train Acc: 0.871795 | Val Loss: 0.112383, Val Acc: 0.773196\n",
      "Epoch 23047 - Train Loss: 0.080477, Train Acc: 0.871795 | Val Loss: 0.112383, Val Acc: 0.773196\n",
      "Epoch 23048 - Train Loss: 0.080475, Train Acc: 0.871795 | Val Loss: 0.112382, Val Acc: 0.773196\n",
      "Epoch 23049 - Train Loss: 0.080473, Train Acc: 0.871795 | Val Loss: 0.112381, Val Acc: 0.773196\n",
      "Epoch 23050 - Train Loss: 0.080472, Train Acc: 0.871795 | Val Loss: 0.112381, Val Acc: 0.773196\n",
      "Epoch 23051 - Train Loss: 0.080470, Train Acc: 0.871795 | Val Loss: 0.112380, Val Acc: 0.773196\n",
      "Epoch 23052 - Train Loss: 0.080468, Train Acc: 0.871795 | Val Loss: 0.112379, Val Acc: 0.773196\n",
      "Epoch 23053 - Train Loss: 0.080466, Train Acc: 0.871795 | Val Loss: 0.112378, Val Acc: 0.773196\n",
      "Epoch 23054 - Train Loss: 0.080465, Train Acc: 0.871795 | Val Loss: 0.112378, Val Acc: 0.773196\n",
      "Epoch 23055 - Train Loss: 0.080463, Train Acc: 0.871795 | Val Loss: 0.112377, Val Acc: 0.773196\n",
      "Epoch 23056 - Train Loss: 0.080461, Train Acc: 0.871795 | Val Loss: 0.112376, Val Acc: 0.773196\n",
      "Epoch 23057 - Train Loss: 0.080459, Train Acc: 0.871795 | Val Loss: 0.112376, Val Acc: 0.773196\n",
      "Epoch 23058 - Train Loss: 0.080457, Train Acc: 0.871795 | Val Loss: 0.112375, Val Acc: 0.773196\n",
      "Epoch 23059 - Train Loss: 0.080456, Train Acc: 0.871795 | Val Loss: 0.112374, Val Acc: 0.773196\n",
      "Epoch 23060 - Train Loss: 0.080454, Train Acc: 0.871795 | Val Loss: 0.112374, Val Acc: 0.773196\n",
      "Epoch 23061 - Train Loss: 0.080452, Train Acc: 0.871795 | Val Loss: 0.112373, Val Acc: 0.773196\n",
      "Epoch 23062 - Train Loss: 0.080450, Train Acc: 0.871795 | Val Loss: 0.112372, Val Acc: 0.773196\n",
      "Epoch 23063 - Train Loss: 0.080448, Train Acc: 0.871795 | Val Loss: 0.112372, Val Acc: 0.773196\n",
      "Epoch 23064 - Train Loss: 0.080447, Train Acc: 0.871795 | Val Loss: 0.112371, Val Acc: 0.773196\n",
      "Epoch 23065 - Train Loss: 0.080445, Train Acc: 0.871795 | Val Loss: 0.112370, Val Acc: 0.773196\n",
      "Epoch 23066 - Train Loss: 0.080443, Train Acc: 0.871795 | Val Loss: 0.112369, Val Acc: 0.773196\n",
      "Epoch 23067 - Train Loss: 0.080441, Train Acc: 0.871795 | Val Loss: 0.112369, Val Acc: 0.773196\n",
      "Epoch 23068 - Train Loss: 0.080440, Train Acc: 0.871795 | Val Loss: 0.112368, Val Acc: 0.773196\n",
      "Epoch 23069 - Train Loss: 0.080438, Train Acc: 0.871795 | Val Loss: 0.112367, Val Acc: 0.773196\n",
      "Epoch 23070 - Train Loss: 0.080436, Train Acc: 0.871795 | Val Loss: 0.112367, Val Acc: 0.773196\n",
      "Epoch 23071 - Train Loss: 0.080434, Train Acc: 0.871795 | Val Loss: 0.112366, Val Acc: 0.773196\n",
      "Epoch 23072 - Train Loss: 0.080432, Train Acc: 0.871795 | Val Loss: 0.112365, Val Acc: 0.773196\n",
      "Epoch 23073 - Train Loss: 0.080431, Train Acc: 0.871795 | Val Loss: 0.112365, Val Acc: 0.773196\n",
      "Epoch 23074 - Train Loss: 0.080429, Train Acc: 0.871795 | Val Loss: 0.112364, Val Acc: 0.773196\n",
      "Epoch 23075 - Train Loss: 0.080427, Train Acc: 0.871795 | Val Loss: 0.112363, Val Acc: 0.773196\n",
      "Epoch 23076 - Train Loss: 0.080425, Train Acc: 0.871795 | Val Loss: 0.112363, Val Acc: 0.773196\n",
      "Epoch 23077 - Train Loss: 0.080424, Train Acc: 0.871795 | Val Loss: 0.112362, Val Acc: 0.773196\n",
      "Epoch 23078 - Train Loss: 0.080422, Train Acc: 0.871795 | Val Loss: 0.112361, Val Acc: 0.773196\n",
      "Epoch 23079 - Train Loss: 0.080420, Train Acc: 0.871795 | Val Loss: 0.112361, Val Acc: 0.773196\n",
      "Epoch 23080 - Train Loss: 0.080418, Train Acc: 0.871795 | Val Loss: 0.112360, Val Acc: 0.773196\n",
      "Epoch 23081 - Train Loss: 0.080416, Train Acc: 0.871795 | Val Loss: 0.112359, Val Acc: 0.773196\n",
      "Epoch 23082 - Train Loss: 0.080415, Train Acc: 0.871795 | Val Loss: 0.112358, Val Acc: 0.773196\n",
      "Epoch 23083 - Train Loss: 0.080413, Train Acc: 0.871795 | Val Loss: 0.112358, Val Acc: 0.773196\n",
      "Epoch 23084 - Train Loss: 0.080411, Train Acc: 0.871795 | Val Loss: 0.112357, Val Acc: 0.773196\n",
      "Epoch 23085 - Train Loss: 0.080409, Train Acc: 0.871795 | Val Loss: 0.112356, Val Acc: 0.773196\n",
      "Epoch 23086 - Train Loss: 0.080408, Train Acc: 0.871795 | Val Loss: 0.112356, Val Acc: 0.773196\n",
      "Epoch 23087 - Train Loss: 0.080406, Train Acc: 0.871795 | Val Loss: 0.112355, Val Acc: 0.773196\n",
      "Epoch 23088 - Train Loss: 0.080404, Train Acc: 0.871795 | Val Loss: 0.112354, Val Acc: 0.773196\n",
      "Epoch 23089 - Train Loss: 0.080402, Train Acc: 0.871795 | Val Loss: 0.112354, Val Acc: 0.773196\n",
      "Epoch 23090 - Train Loss: 0.080400, Train Acc: 0.871795 | Val Loss: 0.112353, Val Acc: 0.773196\n",
      "Epoch 23091 - Train Loss: 0.080399, Train Acc: 0.871795 | Val Loss: 0.112352, Val Acc: 0.773196\n",
      "Epoch 23092 - Train Loss: 0.080397, Train Acc: 0.871795 | Val Loss: 0.112352, Val Acc: 0.773196\n",
      "Epoch 23093 - Train Loss: 0.080395, Train Acc: 0.871795 | Val Loss: 0.112351, Val Acc: 0.773196\n",
      "Epoch 23094 - Train Loss: 0.080393, Train Acc: 0.871795 | Val Loss: 0.112350, Val Acc: 0.773196\n",
      "Epoch 23095 - Train Loss: 0.080392, Train Acc: 0.871795 | Val Loss: 0.112350, Val Acc: 0.773196\n",
      "Epoch 23096 - Train Loss: 0.080390, Train Acc: 0.871795 | Val Loss: 0.112349, Val Acc: 0.773196\n",
      "Epoch 23097 - Train Loss: 0.080388, Train Acc: 0.871795 | Val Loss: 0.112348, Val Acc: 0.773196\n",
      "Epoch 23098 - Train Loss: 0.080386, Train Acc: 0.871795 | Val Loss: 0.112347, Val Acc: 0.773196\n",
      "Epoch 23099 - Train Loss: 0.080384, Train Acc: 0.871795 | Val Loss: 0.112347, Val Acc: 0.773196\n",
      "Epoch 23100 - Train Loss: 0.080383, Train Acc: 0.871795 | Val Loss: 0.112346, Val Acc: 0.773196\n",
      "Epoch 23101 - Train Loss: 0.080381, Train Acc: 0.871795 | Val Loss: 0.112345, Val Acc: 0.773196\n",
      "Epoch 23102 - Train Loss: 0.080379, Train Acc: 0.871795 | Val Loss: 0.112345, Val Acc: 0.773196\n",
      "Epoch 23103 - Train Loss: 0.080377, Train Acc: 0.871795 | Val Loss: 0.112344, Val Acc: 0.773196\n",
      "Epoch 23104 - Train Loss: 0.080376, Train Acc: 0.871795 | Val Loss: 0.112343, Val Acc: 0.773196\n",
      "Epoch 23105 - Train Loss: 0.080374, Train Acc: 0.871795 | Val Loss: 0.112343, Val Acc: 0.773196\n",
      "Epoch 23106 - Train Loss: 0.080372, Train Acc: 0.871795 | Val Loss: 0.112342, Val Acc: 0.773196\n",
      "Epoch 23107 - Train Loss: 0.080370, Train Acc: 0.871795 | Val Loss: 0.112341, Val Acc: 0.773196\n",
      "Epoch 23108 - Train Loss: 0.080368, Train Acc: 0.871795 | Val Loss: 0.112341, Val Acc: 0.773196\n",
      "Epoch 23109 - Train Loss: 0.080367, Train Acc: 0.871795 | Val Loss: 0.112340, Val Acc: 0.773196\n",
      "Epoch 23110 - Train Loss: 0.080365, Train Acc: 0.871795 | Val Loss: 0.112339, Val Acc: 0.773196\n",
      "Epoch 23111 - Train Loss: 0.080363, Train Acc: 0.871795 | Val Loss: 0.112339, Val Acc: 0.773196\n",
      "Epoch 23112 - Train Loss: 0.080361, Train Acc: 0.871795 | Val Loss: 0.112338, Val Acc: 0.773196\n",
      "Epoch 23113 - Train Loss: 0.080360, Train Acc: 0.871795 | Val Loss: 0.112337, Val Acc: 0.773196\n",
      "Epoch 23114 - Train Loss: 0.080358, Train Acc: 0.871795 | Val Loss: 0.112336, Val Acc: 0.773196\n",
      "Epoch 23115 - Train Loss: 0.080356, Train Acc: 0.871795 | Val Loss: 0.112336, Val Acc: 0.773196\n",
      "Epoch 23116 - Train Loss: 0.080354, Train Acc: 0.871795 | Val Loss: 0.112335, Val Acc: 0.773196\n",
      "Epoch 23117 - Train Loss: 0.080352, Train Acc: 0.871795 | Val Loss: 0.112334, Val Acc: 0.773196\n",
      "Epoch 23118 - Train Loss: 0.080351, Train Acc: 0.871795 | Val Loss: 0.112334, Val Acc: 0.773196\n",
      "Epoch 23119 - Train Loss: 0.080349, Train Acc: 0.871795 | Val Loss: 0.112333, Val Acc: 0.773196\n",
      "Epoch 23120 - Train Loss: 0.080347, Train Acc: 0.871795 | Val Loss: 0.112332, Val Acc: 0.773196\n",
      "Epoch 23121 - Train Loss: 0.080345, Train Acc: 0.871795 | Val Loss: 0.112332, Val Acc: 0.773196\n",
      "Epoch 23122 - Train Loss: 0.080344, Train Acc: 0.871795 | Val Loss: 0.112331, Val Acc: 0.773196\n",
      "Epoch 23123 - Train Loss: 0.080342, Train Acc: 0.871795 | Val Loss: 0.112330, Val Acc: 0.773196\n",
      "Epoch 23124 - Train Loss: 0.080340, Train Acc: 0.871795 | Val Loss: 0.112330, Val Acc: 0.773196\n",
      "Epoch 23125 - Train Loss: 0.080338, Train Acc: 0.871795 | Val Loss: 0.112329, Val Acc: 0.773196\n",
      "Epoch 23126 - Train Loss: 0.080337, Train Acc: 0.871795 | Val Loss: 0.112328, Val Acc: 0.773196\n",
      "Epoch 23127 - Train Loss: 0.080335, Train Acc: 0.871795 | Val Loss: 0.112328, Val Acc: 0.773196\n",
      "Epoch 23128 - Train Loss: 0.080333, Train Acc: 0.871795 | Val Loss: 0.112327, Val Acc: 0.773196\n",
      "Epoch 23129 - Train Loss: 0.080331, Train Acc: 0.871795 | Val Loss: 0.112326, Val Acc: 0.773196\n",
      "Epoch 23130 - Train Loss: 0.080329, Train Acc: 0.871795 | Val Loss: 0.112326, Val Acc: 0.773196\n",
      "Epoch 23131 - Train Loss: 0.080328, Train Acc: 0.871795 | Val Loss: 0.112325, Val Acc: 0.773196\n",
      "Epoch 23132 - Train Loss: 0.080326, Train Acc: 0.871795 | Val Loss: 0.112324, Val Acc: 0.773196\n",
      "Epoch 23133 - Train Loss: 0.080324, Train Acc: 0.871795 | Val Loss: 0.112323, Val Acc: 0.773196\n",
      "Epoch 23134 - Train Loss: 0.080322, Train Acc: 0.871795 | Val Loss: 0.112323, Val Acc: 0.773196\n",
      "Epoch 23135 - Train Loss: 0.080321, Train Acc: 0.871795 | Val Loss: 0.112322, Val Acc: 0.773196\n",
      "Epoch 23136 - Train Loss: 0.080319, Train Acc: 0.871795 | Val Loss: 0.112321, Val Acc: 0.773196\n",
      "Epoch 23137 - Train Loss: 0.080317, Train Acc: 0.871795 | Val Loss: 0.112321, Val Acc: 0.773196\n",
      "Epoch 23138 - Train Loss: 0.080315, Train Acc: 0.871795 | Val Loss: 0.112320, Val Acc: 0.773196\n",
      "Epoch 23139 - Train Loss: 0.080313, Train Acc: 0.871795 | Val Loss: 0.112319, Val Acc: 0.773196\n",
      "Epoch 23140 - Train Loss: 0.080312, Train Acc: 0.871795 | Val Loss: 0.112319, Val Acc: 0.773196\n",
      "Epoch 23141 - Train Loss: 0.080310, Train Acc: 0.871795 | Val Loss: 0.112318, Val Acc: 0.773196\n",
      "Epoch 23142 - Train Loss: 0.080308, Train Acc: 0.871795 | Val Loss: 0.112317, Val Acc: 0.773196\n",
      "Epoch 23143 - Train Loss: 0.080306, Train Acc: 0.871795 | Val Loss: 0.112317, Val Acc: 0.773196\n",
      "Epoch 23144 - Train Loss: 0.080305, Train Acc: 0.871795 | Val Loss: 0.112316, Val Acc: 0.773196\n",
      "Epoch 23145 - Train Loss: 0.080303, Train Acc: 0.871795 | Val Loss: 0.112315, Val Acc: 0.773196\n",
      "Epoch 23146 - Train Loss: 0.080301, Train Acc: 0.871795 | Val Loss: 0.112315, Val Acc: 0.773196\n",
      "Epoch 23147 - Train Loss: 0.080299, Train Acc: 0.871795 | Val Loss: 0.112314, Val Acc: 0.773196\n",
      "Epoch 23148 - Train Loss: 0.080298, Train Acc: 0.871795 | Val Loss: 0.112313, Val Acc: 0.773196\n",
      "Epoch 23149 - Train Loss: 0.080296, Train Acc: 0.871795 | Val Loss: 0.112313, Val Acc: 0.773196\n",
      "Epoch 23150 - Train Loss: 0.080294, Train Acc: 0.871795 | Val Loss: 0.112312, Val Acc: 0.773196\n",
      "Epoch 23151 - Train Loss: 0.080292, Train Acc: 0.871795 | Val Loss: 0.112311, Val Acc: 0.773196\n",
      "Epoch 23152 - Train Loss: 0.080290, Train Acc: 0.871795 | Val Loss: 0.112310, Val Acc: 0.773196\n",
      "Epoch 23153 - Train Loss: 0.080289, Train Acc: 0.871795 | Val Loss: 0.112310, Val Acc: 0.773196\n",
      "Epoch 23154 - Train Loss: 0.080287, Train Acc: 0.871795 | Val Loss: 0.112309, Val Acc: 0.773196\n",
      "Epoch 23155 - Train Loss: 0.080285, Train Acc: 0.871795 | Val Loss: 0.112308, Val Acc: 0.773196\n",
      "Epoch 23156 - Train Loss: 0.080283, Train Acc: 0.871795 | Val Loss: 0.112308, Val Acc: 0.773196\n",
      "Epoch 23157 - Train Loss: 0.080282, Train Acc: 0.871795 | Val Loss: 0.112307, Val Acc: 0.773196\n",
      "Epoch 23158 - Train Loss: 0.080280, Train Acc: 0.871795 | Val Loss: 0.112306, Val Acc: 0.773196\n",
      "Epoch 23159 - Train Loss: 0.080278, Train Acc: 0.871795 | Val Loss: 0.112306, Val Acc: 0.773196\n",
      "Epoch 23160 - Train Loss: 0.080276, Train Acc: 0.871795 | Val Loss: 0.112305, Val Acc: 0.773196\n",
      "Epoch 23161 - Train Loss: 0.080275, Train Acc: 0.871795 | Val Loss: 0.112304, Val Acc: 0.773196\n",
      "Epoch 23162 - Train Loss: 0.080273, Train Acc: 0.871795 | Val Loss: 0.112304, Val Acc: 0.773196\n",
      "Epoch 23163 - Train Loss: 0.080271, Train Acc: 0.871795 | Val Loss: 0.112303, Val Acc: 0.773196\n",
      "Epoch 23164 - Train Loss: 0.080269, Train Acc: 0.871795 | Val Loss: 0.112302, Val Acc: 0.773196\n",
      "Epoch 23165 - Train Loss: 0.080267, Train Acc: 0.871795 | Val Loss: 0.112302, Val Acc: 0.773196\n",
      "Epoch 23166 - Train Loss: 0.080266, Train Acc: 0.871795 | Val Loss: 0.112301, Val Acc: 0.773196\n",
      "Epoch 23167 - Train Loss: 0.080264, Train Acc: 0.871795 | Val Loss: 0.112300, Val Acc: 0.773196\n",
      "Epoch 23168 - Train Loss: 0.080262, Train Acc: 0.871795 | Val Loss: 0.112300, Val Acc: 0.773196\n",
      "Epoch 23169 - Train Loss: 0.080260, Train Acc: 0.871795 | Val Loss: 0.112299, Val Acc: 0.773196\n",
      "Epoch 23170 - Train Loss: 0.080259, Train Acc: 0.871795 | Val Loss: 0.112298, Val Acc: 0.773196\n",
      "Epoch 23171 - Train Loss: 0.080257, Train Acc: 0.871795 | Val Loss: 0.112298, Val Acc: 0.773196\n",
      "Epoch 23172 - Train Loss: 0.080255, Train Acc: 0.871795 | Val Loss: 0.112297, Val Acc: 0.773196\n",
      "Epoch 23173 - Train Loss: 0.080253, Train Acc: 0.871795 | Val Loss: 0.112296, Val Acc: 0.773196\n",
      "Epoch 23174 - Train Loss: 0.080252, Train Acc: 0.871795 | Val Loss: 0.112296, Val Acc: 0.773196\n",
      "Epoch 23175 - Train Loss: 0.080250, Train Acc: 0.871795 | Val Loss: 0.112295, Val Acc: 0.773196\n",
      "Epoch 23176 - Train Loss: 0.080248, Train Acc: 0.871795 | Val Loss: 0.112294, Val Acc: 0.773196\n",
      "Epoch 23177 - Train Loss: 0.080246, Train Acc: 0.871795 | Val Loss: 0.112293, Val Acc: 0.773196\n",
      "Epoch 23178 - Train Loss: 0.080244, Train Acc: 0.871795 | Val Loss: 0.112293, Val Acc: 0.773196\n",
      "Epoch 23179 - Train Loss: 0.080243, Train Acc: 0.871795 | Val Loss: 0.112292, Val Acc: 0.773196\n",
      "Epoch 23180 - Train Loss: 0.080241, Train Acc: 0.871795 | Val Loss: 0.112291, Val Acc: 0.773196\n",
      "Epoch 23181 - Train Loss: 0.080239, Train Acc: 0.871795 | Val Loss: 0.112291, Val Acc: 0.773196\n",
      "Epoch 23182 - Train Loss: 0.080237, Train Acc: 0.871795 | Val Loss: 0.112290, Val Acc: 0.773196\n",
      "Epoch 23183 - Train Loss: 0.080236, Train Acc: 0.871795 | Val Loss: 0.112289, Val Acc: 0.773196\n",
      "Epoch 23184 - Train Loss: 0.080234, Train Acc: 0.871795 | Val Loss: 0.112289, Val Acc: 0.773196\n",
      "Epoch 23185 - Train Loss: 0.080232, Train Acc: 0.871795 | Val Loss: 0.112288, Val Acc: 0.773196\n",
      "Epoch 23186 - Train Loss: 0.080230, Train Acc: 0.871795 | Val Loss: 0.112287, Val Acc: 0.773196\n",
      "Epoch 23187 - Train Loss: 0.080229, Train Acc: 0.871795 | Val Loss: 0.112287, Val Acc: 0.773196\n",
      "Epoch 23188 - Train Loss: 0.080227, Train Acc: 0.871795 | Val Loss: 0.112286, Val Acc: 0.773196\n",
      "Epoch 23189 - Train Loss: 0.080225, Train Acc: 0.871795 | Val Loss: 0.112285, Val Acc: 0.773196\n",
      "Epoch 23190 - Train Loss: 0.080223, Train Acc: 0.871795 | Val Loss: 0.112285, Val Acc: 0.773196\n",
      "Epoch 23191 - Train Loss: 0.080221, Train Acc: 0.871795 | Val Loss: 0.112284, Val Acc: 0.773196\n",
      "Epoch 23192 - Train Loss: 0.080220, Train Acc: 0.871795 | Val Loss: 0.112283, Val Acc: 0.773196\n",
      "Epoch 23193 - Train Loss: 0.080218, Train Acc: 0.871795 | Val Loss: 0.112283, Val Acc: 0.773196\n",
      "Epoch 23194 - Train Loss: 0.080216, Train Acc: 0.871795 | Val Loss: 0.112282, Val Acc: 0.773196\n",
      "Epoch 23195 - Train Loss: 0.080214, Train Acc: 0.871795 | Val Loss: 0.112281, Val Acc: 0.773196\n",
      "Epoch 23196 - Train Loss: 0.080213, Train Acc: 0.871795 | Val Loss: 0.112281, Val Acc: 0.773196\n",
      "Epoch 23197 - Train Loss: 0.080211, Train Acc: 0.871795 | Val Loss: 0.112280, Val Acc: 0.773196\n",
      "Epoch 23198 - Train Loss: 0.080209, Train Acc: 0.871795 | Val Loss: 0.112279, Val Acc: 0.773196\n",
      "Epoch 23199 - Train Loss: 0.080207, Train Acc: 0.871795 | Val Loss: 0.112279, Val Acc: 0.773196\n",
      "Epoch 23200 - Train Loss: 0.080206, Train Acc: 0.871795 | Val Loss: 0.112278, Val Acc: 0.773196\n",
      "Epoch 23201 - Train Loss: 0.080204, Train Acc: 0.871795 | Val Loss: 0.112277, Val Acc: 0.773196\n",
      "Epoch 23202 - Train Loss: 0.080202, Train Acc: 0.871795 | Val Loss: 0.112277, Val Acc: 0.773196\n",
      "Epoch 23203 - Train Loss: 0.080200, Train Acc: 0.871795 | Val Loss: 0.112276, Val Acc: 0.773196\n",
      "Epoch 23204 - Train Loss: 0.080199, Train Acc: 0.871795 | Val Loss: 0.112275, Val Acc: 0.773196\n",
      "Epoch 23205 - Train Loss: 0.080197, Train Acc: 0.871795 | Val Loss: 0.112275, Val Acc: 0.773196\n",
      "Epoch 23206 - Train Loss: 0.080195, Train Acc: 0.871795 | Val Loss: 0.112274, Val Acc: 0.773196\n",
      "Epoch 23207 - Train Loss: 0.080193, Train Acc: 0.871795 | Val Loss: 0.112273, Val Acc: 0.773196\n",
      "Epoch 23208 - Train Loss: 0.080191, Train Acc: 0.871795 | Val Loss: 0.112272, Val Acc: 0.773196\n",
      "Epoch 23209 - Train Loss: 0.080190, Train Acc: 0.871795 | Val Loss: 0.112272, Val Acc: 0.773196\n",
      "Epoch 23210 - Train Loss: 0.080188, Train Acc: 0.871795 | Val Loss: 0.112271, Val Acc: 0.773196\n",
      "Epoch 23211 - Train Loss: 0.080186, Train Acc: 0.871795 | Val Loss: 0.112270, Val Acc: 0.773196\n",
      "Epoch 23212 - Train Loss: 0.080184, Train Acc: 0.871795 | Val Loss: 0.112270, Val Acc: 0.773196\n",
      "Epoch 23213 - Train Loss: 0.080183, Train Acc: 0.871795 | Val Loss: 0.112269, Val Acc: 0.773196\n",
      "Epoch 23214 - Train Loss: 0.080181, Train Acc: 0.871795 | Val Loss: 0.112268, Val Acc: 0.773196\n",
      "Epoch 23215 - Train Loss: 0.080179, Train Acc: 0.871795 | Val Loss: 0.112268, Val Acc: 0.773196\n",
      "Epoch 23216 - Train Loss: 0.080177, Train Acc: 0.871795 | Val Loss: 0.112267, Val Acc: 0.773196\n",
      "Epoch 23217 - Train Loss: 0.080176, Train Acc: 0.871795 | Val Loss: 0.112266, Val Acc: 0.773196\n",
      "Epoch 23218 - Train Loss: 0.080174, Train Acc: 0.871795 | Val Loss: 0.112266, Val Acc: 0.773196\n",
      "Epoch 23219 - Train Loss: 0.080172, Train Acc: 0.871795 | Val Loss: 0.112265, Val Acc: 0.773196\n",
      "Epoch 23220 - Train Loss: 0.080170, Train Acc: 0.871795 | Val Loss: 0.112264, Val Acc: 0.773196\n",
      "Epoch 23221 - Train Loss: 0.080169, Train Acc: 0.871795 | Val Loss: 0.112264, Val Acc: 0.773196\n",
      "Epoch 23222 - Train Loss: 0.080167, Train Acc: 0.871795 | Val Loss: 0.112263, Val Acc: 0.773196\n",
      "Epoch 23223 - Train Loss: 0.080165, Train Acc: 0.871795 | Val Loss: 0.112262, Val Acc: 0.773196\n",
      "Epoch 23224 - Train Loss: 0.080163, Train Acc: 0.871795 | Val Loss: 0.112262, Val Acc: 0.773196\n",
      "Epoch 23225 - Train Loss: 0.080162, Train Acc: 0.871795 | Val Loss: 0.112261, Val Acc: 0.773196\n",
      "Epoch 23226 - Train Loss: 0.080160, Train Acc: 0.871795 | Val Loss: 0.112260, Val Acc: 0.773196\n",
      "Epoch 23227 - Train Loss: 0.080158, Train Acc: 0.871795 | Val Loss: 0.112260, Val Acc: 0.773196\n",
      "Epoch 23228 - Train Loss: 0.080156, Train Acc: 0.871795 | Val Loss: 0.112259, Val Acc: 0.773196\n",
      "Epoch 23229 - Train Loss: 0.080154, Train Acc: 0.871795 | Val Loss: 0.112258, Val Acc: 0.773196\n",
      "Epoch 23230 - Train Loss: 0.080153, Train Acc: 0.871795 | Val Loss: 0.112258, Val Acc: 0.773196\n",
      "Epoch 23231 - Train Loss: 0.080151, Train Acc: 0.871795 | Val Loss: 0.112257, Val Acc: 0.773196\n",
      "Epoch 23232 - Train Loss: 0.080149, Train Acc: 0.871795 | Val Loss: 0.112256, Val Acc: 0.773196\n",
      "Epoch 23233 - Train Loss: 0.080147, Train Acc: 0.871795 | Val Loss: 0.112256, Val Acc: 0.773196\n",
      "Epoch 23234 - Train Loss: 0.080146, Train Acc: 0.871795 | Val Loss: 0.112255, Val Acc: 0.773196\n",
      "Epoch 23235 - Train Loss: 0.080144, Train Acc: 0.871795 | Val Loss: 0.112254, Val Acc: 0.773196\n",
      "Epoch 23236 - Train Loss: 0.080142, Train Acc: 0.871795 | Val Loss: 0.112254, Val Acc: 0.773196\n",
      "Epoch 23237 - Train Loss: 0.080140, Train Acc: 0.871795 | Val Loss: 0.112253, Val Acc: 0.773196\n",
      "Epoch 23238 - Train Loss: 0.080139, Train Acc: 0.873077 | Val Loss: 0.112252, Val Acc: 0.773196\n",
      "Epoch 23239 - Train Loss: 0.080137, Train Acc: 0.873077 | Val Loss: 0.112252, Val Acc: 0.773196\n",
      "Epoch 23240 - Train Loss: 0.080135, Train Acc: 0.873077 | Val Loss: 0.112251, Val Acc: 0.773196\n",
      "Epoch 23241 - Train Loss: 0.080133, Train Acc: 0.873077 | Val Loss: 0.112250, Val Acc: 0.773196\n",
      "Epoch 23242 - Train Loss: 0.080132, Train Acc: 0.873077 | Val Loss: 0.112250, Val Acc: 0.773196\n",
      "Epoch 23243 - Train Loss: 0.080130, Train Acc: 0.873077 | Val Loss: 0.112249, Val Acc: 0.773196\n",
      "Epoch 23244 - Train Loss: 0.080128, Train Acc: 0.873077 | Val Loss: 0.112248, Val Acc: 0.773196\n",
      "Epoch 23245 - Train Loss: 0.080126, Train Acc: 0.873077 | Val Loss: 0.112248, Val Acc: 0.773196\n",
      "Epoch 23246 - Train Loss: 0.080125, Train Acc: 0.873077 | Val Loss: 0.112247, Val Acc: 0.773196\n",
      "Epoch 23247 - Train Loss: 0.080123, Train Acc: 0.873077 | Val Loss: 0.112246, Val Acc: 0.773196\n",
      "Epoch 23248 - Train Loss: 0.080121, Train Acc: 0.873077 | Val Loss: 0.112245, Val Acc: 0.773196\n",
      "Epoch 23249 - Train Loss: 0.080119, Train Acc: 0.873077 | Val Loss: 0.112245, Val Acc: 0.773196\n",
      "Epoch 23250 - Train Loss: 0.080118, Train Acc: 0.873077 | Val Loss: 0.112244, Val Acc: 0.773196\n",
      "Epoch 23251 - Train Loss: 0.080116, Train Acc: 0.873077 | Val Loss: 0.112243, Val Acc: 0.773196\n",
      "Epoch 23252 - Train Loss: 0.080114, Train Acc: 0.873077 | Val Loss: 0.112243, Val Acc: 0.773196\n",
      "Epoch 23253 - Train Loss: 0.080112, Train Acc: 0.873077 | Val Loss: 0.112242, Val Acc: 0.773196\n",
      "Epoch 23254 - Train Loss: 0.080110, Train Acc: 0.873077 | Val Loss: 0.112241, Val Acc: 0.773196\n",
      "Epoch 23255 - Train Loss: 0.080109, Train Acc: 0.873077 | Val Loss: 0.112241, Val Acc: 0.773196\n",
      "Epoch 23256 - Train Loss: 0.080107, Train Acc: 0.873077 | Val Loss: 0.112240, Val Acc: 0.773196\n",
      "Epoch 23257 - Train Loss: 0.080105, Train Acc: 0.873077 | Val Loss: 0.112239, Val Acc: 0.773196\n",
      "Epoch 23258 - Train Loss: 0.080103, Train Acc: 0.873077 | Val Loss: 0.112239, Val Acc: 0.773196\n",
      "Epoch 23259 - Train Loss: 0.080102, Train Acc: 0.873077 | Val Loss: 0.112238, Val Acc: 0.773196\n",
      "Epoch 23260 - Train Loss: 0.080100, Train Acc: 0.873077 | Val Loss: 0.112237, Val Acc: 0.773196\n",
      "Epoch 23261 - Train Loss: 0.080098, Train Acc: 0.873077 | Val Loss: 0.112237, Val Acc: 0.773196\n",
      "Epoch 23262 - Train Loss: 0.080096, Train Acc: 0.873077 | Val Loss: 0.112236, Val Acc: 0.773196\n",
      "Epoch 23263 - Train Loss: 0.080095, Train Acc: 0.873077 | Val Loss: 0.112235, Val Acc: 0.773196\n",
      "Epoch 23264 - Train Loss: 0.080093, Train Acc: 0.873077 | Val Loss: 0.112235, Val Acc: 0.773196\n",
      "Epoch 23265 - Train Loss: 0.080091, Train Acc: 0.873077 | Val Loss: 0.112234, Val Acc: 0.773196\n",
      "Epoch 23266 - Train Loss: 0.080089, Train Acc: 0.873077 | Val Loss: 0.112233, Val Acc: 0.773196\n",
      "Epoch 23267 - Train Loss: 0.080088, Train Acc: 0.873077 | Val Loss: 0.112233, Val Acc: 0.773196\n",
      "Epoch 23268 - Train Loss: 0.080086, Train Acc: 0.873077 | Val Loss: 0.112232, Val Acc: 0.773196\n",
      "Epoch 23269 - Train Loss: 0.080084, Train Acc: 0.873077 | Val Loss: 0.112231, Val Acc: 0.773196\n",
      "Epoch 23270 - Train Loss: 0.080082, Train Acc: 0.873077 | Val Loss: 0.112231, Val Acc: 0.773196\n",
      "Epoch 23271 - Train Loss: 0.080081, Train Acc: 0.873077 | Val Loss: 0.112230, Val Acc: 0.773196\n",
      "Epoch 23272 - Train Loss: 0.080079, Train Acc: 0.873077 | Val Loss: 0.112229, Val Acc: 0.773196\n",
      "Epoch 23273 - Train Loss: 0.080077, Train Acc: 0.873077 | Val Loss: 0.112229, Val Acc: 0.773196\n",
      "Epoch 23274 - Train Loss: 0.080075, Train Acc: 0.873077 | Val Loss: 0.112228, Val Acc: 0.773196\n",
      "Epoch 23275 - Train Loss: 0.080074, Train Acc: 0.873077 | Val Loss: 0.112227, Val Acc: 0.773196\n",
      "Epoch 23276 - Train Loss: 0.080072, Train Acc: 0.873077 | Val Loss: 0.112227, Val Acc: 0.773196\n",
      "Epoch 23277 - Train Loss: 0.080070, Train Acc: 0.873077 | Val Loss: 0.112226, Val Acc: 0.773196\n",
      "Epoch 23278 - Train Loss: 0.080068, Train Acc: 0.873077 | Val Loss: 0.112225, Val Acc: 0.773196\n",
      "Epoch 23279 - Train Loss: 0.080067, Train Acc: 0.873077 | Val Loss: 0.112225, Val Acc: 0.773196\n",
      "Epoch 23280 - Train Loss: 0.080065, Train Acc: 0.873077 | Val Loss: 0.112224, Val Acc: 0.773196\n",
      "Epoch 23281 - Train Loss: 0.080063, Train Acc: 0.873077 | Val Loss: 0.112223, Val Acc: 0.773196\n",
      "Epoch 23282 - Train Loss: 0.080061, Train Acc: 0.873077 | Val Loss: 0.112223, Val Acc: 0.773196\n",
      "Epoch 23283 - Train Loss: 0.080060, Train Acc: 0.873077 | Val Loss: 0.112222, Val Acc: 0.773196\n",
      "Epoch 23284 - Train Loss: 0.080058, Train Acc: 0.873077 | Val Loss: 0.112221, Val Acc: 0.773196\n",
      "Epoch 23285 - Train Loss: 0.080056, Train Acc: 0.873077 | Val Loss: 0.112221, Val Acc: 0.773196\n",
      "Epoch 23286 - Train Loss: 0.080054, Train Acc: 0.873077 | Val Loss: 0.112220, Val Acc: 0.773196\n",
      "Epoch 23287 - Train Loss: 0.080053, Train Acc: 0.873077 | Val Loss: 0.112219, Val Acc: 0.773196\n",
      "Epoch 23288 - Train Loss: 0.080051, Train Acc: 0.873077 | Val Loss: 0.112219, Val Acc: 0.773196\n",
      "Epoch 23289 - Train Loss: 0.080049, Train Acc: 0.873077 | Val Loss: 0.112218, Val Acc: 0.773196\n",
      "Epoch 23290 - Train Loss: 0.080047, Train Acc: 0.873077 | Val Loss: 0.112217, Val Acc: 0.773196\n",
      "Epoch 23291 - Train Loss: 0.080045, Train Acc: 0.873077 | Val Loss: 0.112217, Val Acc: 0.773196\n",
      "Epoch 23292 - Train Loss: 0.080044, Train Acc: 0.873077 | Val Loss: 0.112216, Val Acc: 0.773196\n",
      "Epoch 23293 - Train Loss: 0.080042, Train Acc: 0.873077 | Val Loss: 0.112215, Val Acc: 0.773196\n",
      "Epoch 23294 - Train Loss: 0.080040, Train Acc: 0.873077 | Val Loss: 0.112215, Val Acc: 0.773196\n",
      "Epoch 23295 - Train Loss: 0.080038, Train Acc: 0.873077 | Val Loss: 0.112214, Val Acc: 0.773196\n",
      "Epoch 23296 - Train Loss: 0.080037, Train Acc: 0.873077 | Val Loss: 0.112213, Val Acc: 0.773196\n",
      "Epoch 23297 - Train Loss: 0.080035, Train Acc: 0.873077 | Val Loss: 0.112213, Val Acc: 0.773196\n",
      "Epoch 23298 - Train Loss: 0.080033, Train Acc: 0.873077 | Val Loss: 0.112212, Val Acc: 0.773196\n",
      "Epoch 23299 - Train Loss: 0.080031, Train Acc: 0.873077 | Val Loss: 0.112211, Val Acc: 0.773196\n",
      "Epoch 23300 - Train Loss: 0.080030, Train Acc: 0.873077 | Val Loss: 0.112211, Val Acc: 0.773196\n",
      "Epoch 23301 - Train Loss: 0.080028, Train Acc: 0.873077 | Val Loss: 0.112210, Val Acc: 0.773196\n",
      "Epoch 23302 - Train Loss: 0.080026, Train Acc: 0.873077 | Val Loss: 0.112209, Val Acc: 0.773196\n",
      "Epoch 23303 - Train Loss: 0.080024, Train Acc: 0.873077 | Val Loss: 0.112209, Val Acc: 0.773196\n",
      "Epoch 23304 - Train Loss: 0.080023, Train Acc: 0.873077 | Val Loss: 0.112208, Val Acc: 0.773196\n",
      "Epoch 23305 - Train Loss: 0.080021, Train Acc: 0.873077 | Val Loss: 0.112207, Val Acc: 0.773196\n",
      "Epoch 23306 - Train Loss: 0.080019, Train Acc: 0.873077 | Val Loss: 0.112207, Val Acc: 0.773196\n",
      "Epoch 23307 - Train Loss: 0.080017, Train Acc: 0.873077 | Val Loss: 0.112206, Val Acc: 0.773196\n",
      "Epoch 23308 - Train Loss: 0.080016, Train Acc: 0.873077 | Val Loss: 0.112205, Val Acc: 0.773196\n",
      "Epoch 23309 - Train Loss: 0.080014, Train Acc: 0.873077 | Val Loss: 0.112205, Val Acc: 0.773196\n",
      "Epoch 23310 - Train Loss: 0.080012, Train Acc: 0.873077 | Val Loss: 0.112204, Val Acc: 0.773196\n",
      "Epoch 23311 - Train Loss: 0.080010, Train Acc: 0.873077 | Val Loss: 0.112203, Val Acc: 0.773196\n",
      "Epoch 23312 - Train Loss: 0.080009, Train Acc: 0.873077 | Val Loss: 0.112203, Val Acc: 0.773196\n",
      "Epoch 23313 - Train Loss: 0.080007, Train Acc: 0.873077 | Val Loss: 0.112202, Val Acc: 0.773196\n",
      "Epoch 23314 - Train Loss: 0.080005, Train Acc: 0.873077 | Val Loss: 0.112201, Val Acc: 0.773196\n",
      "Epoch 23315 - Train Loss: 0.080003, Train Acc: 0.873077 | Val Loss: 0.112201, Val Acc: 0.773196\n",
      "Epoch 23316 - Train Loss: 0.080002, Train Acc: 0.873077 | Val Loss: 0.112200, Val Acc: 0.773196\n",
      "Epoch 23317 - Train Loss: 0.080000, Train Acc: 0.873077 | Val Loss: 0.112199, Val Acc: 0.773196\n",
      "Epoch 23318 - Train Loss: 0.079998, Train Acc: 0.873077 | Val Loss: 0.112199, Val Acc: 0.773196\n",
      "Epoch 23319 - Train Loss: 0.079996, Train Acc: 0.873077 | Val Loss: 0.112198, Val Acc: 0.773196\n",
      "Epoch 23320 - Train Loss: 0.079995, Train Acc: 0.873077 | Val Loss: 0.112197, Val Acc: 0.773196\n",
      "Epoch 23321 - Train Loss: 0.079993, Train Acc: 0.873077 | Val Loss: 0.112197, Val Acc: 0.773196\n",
      "Epoch 23322 - Train Loss: 0.079991, Train Acc: 0.873077 | Val Loss: 0.112196, Val Acc: 0.773196\n",
      "Epoch 23323 - Train Loss: 0.079989, Train Acc: 0.873077 | Val Loss: 0.112195, Val Acc: 0.773196\n",
      "Epoch 23324 - Train Loss: 0.079988, Train Acc: 0.873077 | Val Loss: 0.112195, Val Acc: 0.773196\n",
      "Epoch 23325 - Train Loss: 0.079986, Train Acc: 0.873077 | Val Loss: 0.112194, Val Acc: 0.773196\n",
      "Epoch 23326 - Train Loss: 0.079984, Train Acc: 0.873077 | Val Loss: 0.112193, Val Acc: 0.773196\n",
      "Epoch 23327 - Train Loss: 0.079982, Train Acc: 0.873077 | Val Loss: 0.112193, Val Acc: 0.773196\n",
      "Epoch 23328 - Train Loss: 0.079981, Train Acc: 0.873077 | Val Loss: 0.112192, Val Acc: 0.773196\n",
      "Epoch 23329 - Train Loss: 0.079979, Train Acc: 0.873077 | Val Loss: 0.112191, Val Acc: 0.773196\n",
      "Epoch 23330 - Train Loss: 0.079977, Train Acc: 0.874359 | Val Loss: 0.112191, Val Acc: 0.773196\n",
      "Epoch 23331 - Train Loss: 0.079975, Train Acc: 0.874359 | Val Loss: 0.112190, Val Acc: 0.773196\n",
      "Epoch 23332 - Train Loss: 0.079974, Train Acc: 0.874359 | Val Loss: 0.112189, Val Acc: 0.773196\n",
      "Epoch 23333 - Train Loss: 0.079972, Train Acc: 0.874359 | Val Loss: 0.112189, Val Acc: 0.773196\n",
      "Epoch 23334 - Train Loss: 0.079970, Train Acc: 0.874359 | Val Loss: 0.112188, Val Acc: 0.773196\n",
      "Epoch 23335 - Train Loss: 0.079968, Train Acc: 0.874359 | Val Loss: 0.112187, Val Acc: 0.773196\n",
      "Epoch 23336 - Train Loss: 0.079967, Train Acc: 0.874359 | Val Loss: 0.112187, Val Acc: 0.773196\n",
      "Epoch 23337 - Train Loss: 0.079965, Train Acc: 0.874359 | Val Loss: 0.112186, Val Acc: 0.773196\n",
      "Epoch 23338 - Train Loss: 0.079963, Train Acc: 0.874359 | Val Loss: 0.112185, Val Acc: 0.773196\n",
      "Epoch 23339 - Train Loss: 0.079961, Train Acc: 0.874359 | Val Loss: 0.112185, Val Acc: 0.773196\n",
      "Epoch 23340 - Train Loss: 0.079960, Train Acc: 0.874359 | Val Loss: 0.112184, Val Acc: 0.773196\n",
      "Epoch 23341 - Train Loss: 0.079958, Train Acc: 0.874359 | Val Loss: 0.112183, Val Acc: 0.773196\n",
      "Epoch 23342 - Train Loss: 0.079956, Train Acc: 0.874359 | Val Loss: 0.112183, Val Acc: 0.773196\n",
      "Epoch 23343 - Train Loss: 0.079954, Train Acc: 0.874359 | Val Loss: 0.112182, Val Acc: 0.773196\n",
      "Epoch 23344 - Train Loss: 0.079953, Train Acc: 0.874359 | Val Loss: 0.112181, Val Acc: 0.773196\n",
      "Epoch 23345 - Train Loss: 0.079951, Train Acc: 0.874359 | Val Loss: 0.112181, Val Acc: 0.773196\n",
      "Epoch 23346 - Train Loss: 0.079949, Train Acc: 0.874359 | Val Loss: 0.112180, Val Acc: 0.773196\n",
      "Epoch 23347 - Train Loss: 0.079947, Train Acc: 0.874359 | Val Loss: 0.112179, Val Acc: 0.773196\n",
      "Epoch 23348 - Train Loss: 0.079946, Train Acc: 0.874359 | Val Loss: 0.112179, Val Acc: 0.773196\n",
      "Epoch 23349 - Train Loss: 0.079944, Train Acc: 0.874359 | Val Loss: 0.112178, Val Acc: 0.773196\n",
      "Epoch 23350 - Train Loss: 0.079942, Train Acc: 0.874359 | Val Loss: 0.112177, Val Acc: 0.773196\n",
      "Epoch 23351 - Train Loss: 0.079940, Train Acc: 0.874359 | Val Loss: 0.112177, Val Acc: 0.773196\n",
      "Epoch 23352 - Train Loss: 0.079939, Train Acc: 0.874359 | Val Loss: 0.112176, Val Acc: 0.773196\n",
      "Epoch 23353 - Train Loss: 0.079937, Train Acc: 0.874359 | Val Loss: 0.112175, Val Acc: 0.773196\n",
      "Epoch 23354 - Train Loss: 0.079935, Train Acc: 0.874359 | Val Loss: 0.112175, Val Acc: 0.773196\n",
      "Epoch 23355 - Train Loss: 0.079933, Train Acc: 0.874359 | Val Loss: 0.112174, Val Acc: 0.773196\n",
      "Epoch 23356 - Train Loss: 0.079932, Train Acc: 0.874359 | Val Loss: 0.112173, Val Acc: 0.773196\n",
      "Epoch 23357 - Train Loss: 0.079930, Train Acc: 0.874359 | Val Loss: 0.112173, Val Acc: 0.773196\n",
      "Epoch 23358 - Train Loss: 0.079928, Train Acc: 0.874359 | Val Loss: 0.112172, Val Acc: 0.773196\n",
      "Epoch 23359 - Train Loss: 0.079926, Train Acc: 0.874359 | Val Loss: 0.112171, Val Acc: 0.773196\n",
      "Epoch 23360 - Train Loss: 0.079925, Train Acc: 0.874359 | Val Loss: 0.112171, Val Acc: 0.773196\n",
      "Epoch 23361 - Train Loss: 0.079923, Train Acc: 0.874359 | Val Loss: 0.112170, Val Acc: 0.773196\n",
      "Epoch 23362 - Train Loss: 0.079921, Train Acc: 0.874359 | Val Loss: 0.112169, Val Acc: 0.773196\n",
      "Epoch 23363 - Train Loss: 0.079919, Train Acc: 0.874359 | Val Loss: 0.112169, Val Acc: 0.773196\n",
      "Epoch 23364 - Train Loss: 0.079918, Train Acc: 0.874359 | Val Loss: 0.112168, Val Acc: 0.773196\n",
      "Epoch 23365 - Train Loss: 0.079916, Train Acc: 0.874359 | Val Loss: 0.112167, Val Acc: 0.773196\n",
      "Epoch 23366 - Train Loss: 0.079914, Train Acc: 0.874359 | Val Loss: 0.112167, Val Acc: 0.773196\n",
      "Epoch 23367 - Train Loss: 0.079913, Train Acc: 0.874359 | Val Loss: 0.112166, Val Acc: 0.773196\n",
      "Epoch 23368 - Train Loss: 0.079911, Train Acc: 0.874359 | Val Loss: 0.112165, Val Acc: 0.773196\n",
      "Epoch 23369 - Train Loss: 0.079909, Train Acc: 0.874359 | Val Loss: 0.112165, Val Acc: 0.773196\n",
      "Epoch 23370 - Train Loss: 0.079907, Train Acc: 0.874359 | Val Loss: 0.112164, Val Acc: 0.773196\n",
      "Epoch 23371 - Train Loss: 0.079906, Train Acc: 0.874359 | Val Loss: 0.112163, Val Acc: 0.773196\n",
      "Epoch 23372 - Train Loss: 0.079904, Train Acc: 0.874359 | Val Loss: 0.112163, Val Acc: 0.773196\n",
      "Epoch 23373 - Train Loss: 0.079902, Train Acc: 0.874359 | Val Loss: 0.112162, Val Acc: 0.773196\n",
      "Epoch 23374 - Train Loss: 0.079900, Train Acc: 0.874359 | Val Loss: 0.112161, Val Acc: 0.773196\n",
      "Epoch 23375 - Train Loss: 0.079899, Train Acc: 0.874359 | Val Loss: 0.112161, Val Acc: 0.773196\n",
      "Epoch 23376 - Train Loss: 0.079897, Train Acc: 0.874359 | Val Loss: 0.112160, Val Acc: 0.773196\n",
      "Epoch 23377 - Train Loss: 0.079895, Train Acc: 0.874359 | Val Loss: 0.112159, Val Acc: 0.773196\n",
      "Epoch 23378 - Train Loss: 0.079893, Train Acc: 0.874359 | Val Loss: 0.112159, Val Acc: 0.773196\n",
      "Epoch 23379 - Train Loss: 0.079892, Train Acc: 0.874359 | Val Loss: 0.112158, Val Acc: 0.773196\n",
      "Epoch 23380 - Train Loss: 0.079890, Train Acc: 0.874359 | Val Loss: 0.112157, Val Acc: 0.773196\n",
      "Epoch 23381 - Train Loss: 0.079888, Train Acc: 0.874359 | Val Loss: 0.112157, Val Acc: 0.773196\n",
      "Epoch 23382 - Train Loss: 0.079886, Train Acc: 0.874359 | Val Loss: 0.112156, Val Acc: 0.773196\n",
      "Epoch 23383 - Train Loss: 0.079885, Train Acc: 0.874359 | Val Loss: 0.112155, Val Acc: 0.773196\n",
      "Epoch 23384 - Train Loss: 0.079883, Train Acc: 0.874359 | Val Loss: 0.112155, Val Acc: 0.773196\n",
      "Epoch 23385 - Train Loss: 0.079881, Train Acc: 0.874359 | Val Loss: 0.112154, Val Acc: 0.773196\n",
      "Epoch 23386 - Train Loss: 0.079879, Train Acc: 0.874359 | Val Loss: 0.112153, Val Acc: 0.773196\n",
      "Epoch 23387 - Train Loss: 0.079878, Train Acc: 0.874359 | Val Loss: 0.112153, Val Acc: 0.773196\n",
      "Epoch 23388 - Train Loss: 0.079876, Train Acc: 0.874359 | Val Loss: 0.112152, Val Acc: 0.773196\n",
      "Epoch 23389 - Train Loss: 0.079874, Train Acc: 0.874359 | Val Loss: 0.112151, Val Acc: 0.773196\n",
      "Epoch 23390 - Train Loss: 0.079872, Train Acc: 0.874359 | Val Loss: 0.112151, Val Acc: 0.773196\n",
      "Epoch 23391 - Train Loss: 0.079871, Train Acc: 0.874359 | Val Loss: 0.112150, Val Acc: 0.773196\n",
      "Epoch 23392 - Train Loss: 0.079869, Train Acc: 0.874359 | Val Loss: 0.112149, Val Acc: 0.773196\n",
      "Epoch 23393 - Train Loss: 0.079867, Train Acc: 0.874359 | Val Loss: 0.112149, Val Acc: 0.773196\n",
      "Epoch 23394 - Train Loss: 0.079865, Train Acc: 0.874359 | Val Loss: 0.112148, Val Acc: 0.773196\n",
      "Epoch 23395 - Train Loss: 0.079864, Train Acc: 0.874359 | Val Loss: 0.112148, Val Acc: 0.773196\n",
      "Epoch 23396 - Train Loss: 0.079862, Train Acc: 0.874359 | Val Loss: 0.112147, Val Acc: 0.773196\n",
      "Epoch 23397 - Train Loss: 0.079860, Train Acc: 0.874359 | Val Loss: 0.112146, Val Acc: 0.773196\n",
      "Epoch 23398 - Train Loss: 0.079858, Train Acc: 0.874359 | Val Loss: 0.112146, Val Acc: 0.773196\n",
      "Epoch 23399 - Train Loss: 0.079857, Train Acc: 0.874359 | Val Loss: 0.112145, Val Acc: 0.773196\n",
      "Epoch 23400 - Train Loss: 0.079855, Train Acc: 0.874359 | Val Loss: 0.112144, Val Acc: 0.773196\n",
      "Epoch 23401 - Train Loss: 0.079853, Train Acc: 0.874359 | Val Loss: 0.112144, Val Acc: 0.773196\n",
      "Epoch 23402 - Train Loss: 0.079851, Train Acc: 0.874359 | Val Loss: 0.112143, Val Acc: 0.773196\n",
      "Epoch 23403 - Train Loss: 0.079850, Train Acc: 0.874359 | Val Loss: 0.112142, Val Acc: 0.773196\n",
      "Epoch 23404 - Train Loss: 0.079848, Train Acc: 0.874359 | Val Loss: 0.112142, Val Acc: 0.773196\n",
      "Epoch 23405 - Train Loss: 0.079846, Train Acc: 0.874359 | Val Loss: 0.112141, Val Acc: 0.773196\n",
      "Epoch 23406 - Train Loss: 0.079845, Train Acc: 0.874359 | Val Loss: 0.112140, Val Acc: 0.773196\n",
      "Epoch 23407 - Train Loss: 0.079843, Train Acc: 0.874359 | Val Loss: 0.112140, Val Acc: 0.773196\n",
      "Epoch 23408 - Train Loss: 0.079841, Train Acc: 0.874359 | Val Loss: 0.112139, Val Acc: 0.773196\n",
      "Epoch 23409 - Train Loss: 0.079839, Train Acc: 0.874359 | Val Loss: 0.112138, Val Acc: 0.773196\n",
      "Epoch 23410 - Train Loss: 0.079838, Train Acc: 0.874359 | Val Loss: 0.112138, Val Acc: 0.773196\n",
      "Epoch 23411 - Train Loss: 0.079836, Train Acc: 0.874359 | Val Loss: 0.112137, Val Acc: 0.773196\n",
      "Epoch 23412 - Train Loss: 0.079834, Train Acc: 0.874359 | Val Loss: 0.112136, Val Acc: 0.773196\n",
      "Epoch 23413 - Train Loss: 0.079832, Train Acc: 0.874359 | Val Loss: 0.112136, Val Acc: 0.773196\n",
      "Epoch 23414 - Train Loss: 0.079831, Train Acc: 0.874359 | Val Loss: 0.112135, Val Acc: 0.773196\n",
      "Epoch 23415 - Train Loss: 0.079829, Train Acc: 0.874359 | Val Loss: 0.112134, Val Acc: 0.773196\n",
      "Epoch 23416 - Train Loss: 0.079827, Train Acc: 0.874359 | Val Loss: 0.112134, Val Acc: 0.773196\n",
      "Epoch 23417 - Train Loss: 0.079825, Train Acc: 0.874359 | Val Loss: 0.112133, Val Acc: 0.773196\n",
      "Epoch 23418 - Train Loss: 0.079824, Train Acc: 0.874359 | Val Loss: 0.112132, Val Acc: 0.773196\n",
      "Epoch 23419 - Train Loss: 0.079822, Train Acc: 0.874359 | Val Loss: 0.112132, Val Acc: 0.773196\n",
      "Epoch 23420 - Train Loss: 0.079820, Train Acc: 0.874359 | Val Loss: 0.112131, Val Acc: 0.773196\n",
      "Epoch 23421 - Train Loss: 0.079818, Train Acc: 0.874359 | Val Loss: 0.112130, Val Acc: 0.773196\n",
      "Epoch 23422 - Train Loss: 0.079817, Train Acc: 0.874359 | Val Loss: 0.112130, Val Acc: 0.773196\n",
      "Epoch 23423 - Train Loss: 0.079815, Train Acc: 0.874359 | Val Loss: 0.112129, Val Acc: 0.773196\n",
      "Epoch 23424 - Train Loss: 0.079813, Train Acc: 0.874359 | Val Loss: 0.112128, Val Acc: 0.773196\n",
      "Epoch 23425 - Train Loss: 0.079811, Train Acc: 0.874359 | Val Loss: 0.112128, Val Acc: 0.773196\n",
      "Epoch 23426 - Train Loss: 0.079810, Train Acc: 0.874359 | Val Loss: 0.112127, Val Acc: 0.773196\n",
      "Epoch 23427 - Train Loss: 0.079808, Train Acc: 0.874359 | Val Loss: 0.112126, Val Acc: 0.773196\n",
      "Epoch 23428 - Train Loss: 0.079806, Train Acc: 0.874359 | Val Loss: 0.112126, Val Acc: 0.773196\n",
      "Epoch 23429 - Train Loss: 0.079804, Train Acc: 0.874359 | Val Loss: 0.112125, Val Acc: 0.773196\n",
      "Epoch 23430 - Train Loss: 0.079803, Train Acc: 0.874359 | Val Loss: 0.112124, Val Acc: 0.773196\n",
      "Epoch 23431 - Train Loss: 0.079801, Train Acc: 0.874359 | Val Loss: 0.112124, Val Acc: 0.773196\n",
      "Epoch 23432 - Train Loss: 0.079799, Train Acc: 0.874359 | Val Loss: 0.112123, Val Acc: 0.773196\n",
      "Epoch 23433 - Train Loss: 0.079798, Train Acc: 0.874359 | Val Loss: 0.112123, Val Acc: 0.773196\n",
      "Epoch 23434 - Train Loss: 0.079796, Train Acc: 0.874359 | Val Loss: 0.112122, Val Acc: 0.773196\n",
      "Epoch 23435 - Train Loss: 0.079794, Train Acc: 0.874359 | Val Loss: 0.112121, Val Acc: 0.773196\n",
      "Epoch 23436 - Train Loss: 0.079792, Train Acc: 0.874359 | Val Loss: 0.112121, Val Acc: 0.773196\n",
      "Epoch 23437 - Train Loss: 0.079791, Train Acc: 0.874359 | Val Loss: 0.112120, Val Acc: 0.773196\n",
      "Epoch 23438 - Train Loss: 0.079789, Train Acc: 0.874359 | Val Loss: 0.112119, Val Acc: 0.773196\n",
      "Epoch 23439 - Train Loss: 0.079787, Train Acc: 0.874359 | Val Loss: 0.112119, Val Acc: 0.773196\n",
      "Epoch 23440 - Train Loss: 0.079785, Train Acc: 0.874359 | Val Loss: 0.112118, Val Acc: 0.773196\n",
      "Epoch 23441 - Train Loss: 0.079784, Train Acc: 0.874359 | Val Loss: 0.112117, Val Acc: 0.773196\n",
      "Epoch 23442 - Train Loss: 0.079782, Train Acc: 0.874359 | Val Loss: 0.112117, Val Acc: 0.773196\n",
      "Epoch 23443 - Train Loss: 0.079780, Train Acc: 0.874359 | Val Loss: 0.112116, Val Acc: 0.773196\n",
      "Epoch 23444 - Train Loss: 0.079778, Train Acc: 0.874359 | Val Loss: 0.112115, Val Acc: 0.773196\n",
      "Epoch 23445 - Train Loss: 0.079777, Train Acc: 0.874359 | Val Loss: 0.112115, Val Acc: 0.773196\n",
      "Epoch 23446 - Train Loss: 0.079775, Train Acc: 0.873077 | Val Loss: 0.112114, Val Acc: 0.773196\n",
      "Epoch 23447 - Train Loss: 0.079773, Train Acc: 0.873077 | Val Loss: 0.112113, Val Acc: 0.773196\n",
      "Epoch 23448 - Train Loss: 0.079771, Train Acc: 0.873077 | Val Loss: 0.112113, Val Acc: 0.773196\n",
      "Epoch 23449 - Train Loss: 0.079770, Train Acc: 0.873077 | Val Loss: 0.112112, Val Acc: 0.773196\n",
      "Epoch 23450 - Train Loss: 0.079768, Train Acc: 0.873077 | Val Loss: 0.112111, Val Acc: 0.773196\n",
      "Epoch 23451 - Train Loss: 0.079766, Train Acc: 0.873077 | Val Loss: 0.112111, Val Acc: 0.773196\n",
      "Epoch 23452 - Train Loss: 0.079765, Train Acc: 0.873077 | Val Loss: 0.112110, Val Acc: 0.773196\n",
      "Epoch 23453 - Train Loss: 0.079763, Train Acc: 0.873077 | Val Loss: 0.112109, Val Acc: 0.773196\n",
      "Epoch 23454 - Train Loss: 0.079761, Train Acc: 0.873077 | Val Loss: 0.112109, Val Acc: 0.773196\n",
      "Epoch 23455 - Train Loss: 0.079759, Train Acc: 0.873077 | Val Loss: 0.112108, Val Acc: 0.773196\n",
      "Epoch 23456 - Train Loss: 0.079758, Train Acc: 0.873077 | Val Loss: 0.112107, Val Acc: 0.773196\n",
      "Epoch 23457 - Train Loss: 0.079756, Train Acc: 0.873077 | Val Loss: 0.112107, Val Acc: 0.773196\n",
      "Epoch 23458 - Train Loss: 0.079754, Train Acc: 0.873077 | Val Loss: 0.112106, Val Acc: 0.773196\n",
      "Epoch 23459 - Train Loss: 0.079752, Train Acc: 0.873077 | Val Loss: 0.112105, Val Acc: 0.773196\n",
      "Epoch 23460 - Train Loss: 0.079751, Train Acc: 0.873077 | Val Loss: 0.112105, Val Acc: 0.773196\n",
      "Epoch 23461 - Train Loss: 0.079749, Train Acc: 0.873077 | Val Loss: 0.112104, Val Acc: 0.773196\n",
      "Epoch 23462 - Train Loss: 0.079747, Train Acc: 0.873077 | Val Loss: 0.112104, Val Acc: 0.773196\n",
      "Epoch 23463 - Train Loss: 0.079745, Train Acc: 0.873077 | Val Loss: 0.112103, Val Acc: 0.773196\n",
      "Epoch 23464 - Train Loss: 0.079744, Train Acc: 0.873077 | Val Loss: 0.112102, Val Acc: 0.773196\n",
      "Epoch 23465 - Train Loss: 0.079742, Train Acc: 0.873077 | Val Loss: 0.112102, Val Acc: 0.773196\n",
      "Epoch 23466 - Train Loss: 0.079740, Train Acc: 0.873077 | Val Loss: 0.112101, Val Acc: 0.773196\n",
      "Epoch 23467 - Train Loss: 0.079739, Train Acc: 0.873077 | Val Loss: 0.112100, Val Acc: 0.773196\n",
      "Epoch 23468 - Train Loss: 0.079737, Train Acc: 0.873077 | Val Loss: 0.112100, Val Acc: 0.773196\n",
      "Epoch 23469 - Train Loss: 0.079735, Train Acc: 0.873077 | Val Loss: 0.112099, Val Acc: 0.773196\n",
      "Epoch 23470 - Train Loss: 0.079733, Train Acc: 0.873077 | Val Loss: 0.112098, Val Acc: 0.773196\n",
      "Epoch 23471 - Train Loss: 0.079732, Train Acc: 0.873077 | Val Loss: 0.112098, Val Acc: 0.773196\n",
      "Epoch 23472 - Train Loss: 0.079730, Train Acc: 0.873077 | Val Loss: 0.112097, Val Acc: 0.773196\n",
      "Epoch 23473 - Train Loss: 0.079728, Train Acc: 0.873077 | Val Loss: 0.112096, Val Acc: 0.773196\n",
      "Epoch 23474 - Train Loss: 0.079726, Train Acc: 0.873077 | Val Loss: 0.112096, Val Acc: 0.773196\n",
      "Epoch 23475 - Train Loss: 0.079725, Train Acc: 0.873077 | Val Loss: 0.112095, Val Acc: 0.773196\n",
      "Epoch 23476 - Train Loss: 0.079723, Train Acc: 0.873077 | Val Loss: 0.112094, Val Acc: 0.773196\n",
      "Epoch 23477 - Train Loss: 0.079721, Train Acc: 0.873077 | Val Loss: 0.112094, Val Acc: 0.773196\n",
      "Epoch 23478 - Train Loss: 0.079719, Train Acc: 0.873077 | Val Loss: 0.112093, Val Acc: 0.773196\n",
      "Epoch 23479 - Train Loss: 0.079718, Train Acc: 0.873077 | Val Loss: 0.112092, Val Acc: 0.773196\n",
      "Epoch 23480 - Train Loss: 0.079716, Train Acc: 0.873077 | Val Loss: 0.112092, Val Acc: 0.773196\n",
      "Epoch 23481 - Train Loss: 0.079714, Train Acc: 0.873077 | Val Loss: 0.112091, Val Acc: 0.773196\n",
      "Epoch 23482 - Train Loss: 0.079713, Train Acc: 0.873077 | Val Loss: 0.112090, Val Acc: 0.773196\n",
      "Epoch 23483 - Train Loss: 0.079711, Train Acc: 0.873077 | Val Loss: 0.112090, Val Acc: 0.773196\n",
      "Epoch 23484 - Train Loss: 0.079709, Train Acc: 0.873077 | Val Loss: 0.112089, Val Acc: 0.773196\n",
      "Epoch 23485 - Train Loss: 0.079707, Train Acc: 0.873077 | Val Loss: 0.112089, Val Acc: 0.773196\n",
      "Epoch 23486 - Train Loss: 0.079706, Train Acc: 0.873077 | Val Loss: 0.112088, Val Acc: 0.773196\n",
      "Epoch 23487 - Train Loss: 0.079704, Train Acc: 0.873077 | Val Loss: 0.112087, Val Acc: 0.773196\n",
      "Epoch 23488 - Train Loss: 0.079702, Train Acc: 0.873077 | Val Loss: 0.112087, Val Acc: 0.773196\n",
      "Epoch 23489 - Train Loss: 0.079700, Train Acc: 0.873077 | Val Loss: 0.112086, Val Acc: 0.773196\n",
      "Epoch 23490 - Train Loss: 0.079699, Train Acc: 0.873077 | Val Loss: 0.112085, Val Acc: 0.773196\n",
      "Epoch 23491 - Train Loss: 0.079697, Train Acc: 0.873077 | Val Loss: 0.112085, Val Acc: 0.773196\n",
      "Epoch 23492 - Train Loss: 0.079695, Train Acc: 0.873077 | Val Loss: 0.112084, Val Acc: 0.773196\n",
      "Epoch 23493 - Train Loss: 0.079693, Train Acc: 0.873077 | Val Loss: 0.112083, Val Acc: 0.773196\n",
      "Epoch 23494 - Train Loss: 0.079692, Train Acc: 0.873077 | Val Loss: 0.112083, Val Acc: 0.773196\n",
      "Epoch 23495 - Train Loss: 0.079690, Train Acc: 0.873077 | Val Loss: 0.112082, Val Acc: 0.773196\n",
      "Epoch 23496 - Train Loss: 0.079688, Train Acc: 0.873077 | Val Loss: 0.112081, Val Acc: 0.773196\n",
      "Epoch 23497 - Train Loss: 0.079687, Train Acc: 0.873077 | Val Loss: 0.112081, Val Acc: 0.773196\n",
      "Epoch 23498 - Train Loss: 0.079685, Train Acc: 0.873077 | Val Loss: 0.112080, Val Acc: 0.773196\n",
      "Epoch 23499 - Train Loss: 0.079683, Train Acc: 0.873077 | Val Loss: 0.112079, Val Acc: 0.773196\n",
      "Epoch 23500 - Train Loss: 0.079681, Train Acc: 0.873077 | Val Loss: 0.112079, Val Acc: 0.773196\n",
      "Epoch 23501 - Train Loss: 0.079680, Train Acc: 0.873077 | Val Loss: 0.112078, Val Acc: 0.773196\n",
      "Epoch 23502 - Train Loss: 0.079678, Train Acc: 0.873077 | Val Loss: 0.112077, Val Acc: 0.773196\n",
      "Epoch 23503 - Train Loss: 0.079676, Train Acc: 0.873077 | Val Loss: 0.112077, Val Acc: 0.773196\n",
      "Epoch 23504 - Train Loss: 0.079674, Train Acc: 0.873077 | Val Loss: 0.112076, Val Acc: 0.773196\n",
      "Epoch 23505 - Train Loss: 0.079673, Train Acc: 0.873077 | Val Loss: 0.112076, Val Acc: 0.773196\n",
      "Epoch 23506 - Train Loss: 0.079671, Train Acc: 0.873077 | Val Loss: 0.112075, Val Acc: 0.773196\n",
      "Epoch 23507 - Train Loss: 0.079669, Train Acc: 0.873077 | Val Loss: 0.112074, Val Acc: 0.773196\n",
      "Epoch 23508 - Train Loss: 0.079668, Train Acc: 0.873077 | Val Loss: 0.112074, Val Acc: 0.773196\n",
      "Epoch 23509 - Train Loss: 0.079666, Train Acc: 0.873077 | Val Loss: 0.112073, Val Acc: 0.773196\n",
      "Epoch 23510 - Train Loss: 0.079664, Train Acc: 0.873077 | Val Loss: 0.112072, Val Acc: 0.773196\n",
      "Epoch 23511 - Train Loss: 0.079662, Train Acc: 0.873077 | Val Loss: 0.112072, Val Acc: 0.773196\n",
      "Epoch 23512 - Train Loss: 0.079661, Train Acc: 0.873077 | Val Loss: 0.112071, Val Acc: 0.773196\n",
      "Epoch 23513 - Train Loss: 0.079659, Train Acc: 0.873077 | Val Loss: 0.112070, Val Acc: 0.773196\n",
      "Epoch 23514 - Train Loss: 0.079657, Train Acc: 0.873077 | Val Loss: 0.112070, Val Acc: 0.773196\n",
      "Epoch 23515 - Train Loss: 0.079655, Train Acc: 0.873077 | Val Loss: 0.112069, Val Acc: 0.773196\n",
      "Epoch 23516 - Train Loss: 0.079654, Train Acc: 0.873077 | Val Loss: 0.112068, Val Acc: 0.773196\n",
      "Epoch 23517 - Train Loss: 0.079652, Train Acc: 0.873077 | Val Loss: 0.112068, Val Acc: 0.773196\n",
      "Epoch 23518 - Train Loss: 0.079650, Train Acc: 0.873077 | Val Loss: 0.112067, Val Acc: 0.773196\n",
      "Epoch 23519 - Train Loss: 0.079648, Train Acc: 0.873077 | Val Loss: 0.112066, Val Acc: 0.773196\n",
      "Epoch 23520 - Train Loss: 0.079647, Train Acc: 0.873077 | Val Loss: 0.112066, Val Acc: 0.773196\n",
      "Epoch 23521 - Train Loss: 0.079645, Train Acc: 0.873077 | Val Loss: 0.112065, Val Acc: 0.773196\n",
      "Epoch 23522 - Train Loss: 0.079643, Train Acc: 0.873077 | Val Loss: 0.112065, Val Acc: 0.773196\n",
      "Epoch 23523 - Train Loss: 0.079642, Train Acc: 0.873077 | Val Loss: 0.112064, Val Acc: 0.773196\n",
      "Epoch 23524 - Train Loss: 0.079640, Train Acc: 0.873077 | Val Loss: 0.112063, Val Acc: 0.773196\n",
      "Epoch 23525 - Train Loss: 0.079638, Train Acc: 0.873077 | Val Loss: 0.112063, Val Acc: 0.773196\n",
      "Epoch 23526 - Train Loss: 0.079636, Train Acc: 0.873077 | Val Loss: 0.112062, Val Acc: 0.773196\n",
      "Epoch 23527 - Train Loss: 0.079635, Train Acc: 0.873077 | Val Loss: 0.112061, Val Acc: 0.773196\n",
      "Epoch 23528 - Train Loss: 0.079633, Train Acc: 0.873077 | Val Loss: 0.112061, Val Acc: 0.773196\n",
      "Epoch 23529 - Train Loss: 0.079631, Train Acc: 0.873077 | Val Loss: 0.112060, Val Acc: 0.773196\n",
      "Epoch 23530 - Train Loss: 0.079629, Train Acc: 0.873077 | Val Loss: 0.112059, Val Acc: 0.773196\n",
      "Epoch 23531 - Train Loss: 0.079628, Train Acc: 0.873077 | Val Loss: 0.112059, Val Acc: 0.773196\n",
      "Epoch 23532 - Train Loss: 0.079626, Train Acc: 0.873077 | Val Loss: 0.112058, Val Acc: 0.773196\n",
      "Epoch 23533 - Train Loss: 0.079624, Train Acc: 0.873077 | Val Loss: 0.112057, Val Acc: 0.773196\n",
      "Epoch 23534 - Train Loss: 0.079623, Train Acc: 0.873077 | Val Loss: 0.112057, Val Acc: 0.773196\n",
      "Epoch 23535 - Train Loss: 0.079621, Train Acc: 0.873077 | Val Loss: 0.112056, Val Acc: 0.773196\n",
      "Epoch 23536 - Train Loss: 0.079619, Train Acc: 0.873077 | Val Loss: 0.112055, Val Acc: 0.773196\n",
      "Epoch 23537 - Train Loss: 0.079617, Train Acc: 0.873077 | Val Loss: 0.112055, Val Acc: 0.773196\n",
      "Epoch 23538 - Train Loss: 0.079616, Train Acc: 0.873077 | Val Loss: 0.112054, Val Acc: 0.773196\n",
      "Epoch 23539 - Train Loss: 0.079614, Train Acc: 0.873077 | Val Loss: 0.112054, Val Acc: 0.773196\n",
      "Epoch 23540 - Train Loss: 0.079612, Train Acc: 0.873077 | Val Loss: 0.112053, Val Acc: 0.773196\n",
      "Epoch 23541 - Train Loss: 0.079611, Train Acc: 0.873077 | Val Loss: 0.112052, Val Acc: 0.773196\n",
      "Epoch 23542 - Train Loss: 0.079609, Train Acc: 0.873077 | Val Loss: 0.112052, Val Acc: 0.773196\n",
      "Epoch 23543 - Train Loss: 0.079607, Train Acc: 0.873077 | Val Loss: 0.112051, Val Acc: 0.773196\n",
      "Epoch 23544 - Train Loss: 0.079605, Train Acc: 0.873077 | Val Loss: 0.112050, Val Acc: 0.773196\n",
      "Epoch 23545 - Train Loss: 0.079604, Train Acc: 0.873077 | Val Loss: 0.112050, Val Acc: 0.773196\n",
      "Epoch 23546 - Train Loss: 0.079602, Train Acc: 0.873077 | Val Loss: 0.112049, Val Acc: 0.773196\n",
      "Epoch 23547 - Train Loss: 0.079600, Train Acc: 0.873077 | Val Loss: 0.112048, Val Acc: 0.773196\n",
      "Epoch 23548 - Train Loss: 0.079598, Train Acc: 0.873077 | Val Loss: 0.112048, Val Acc: 0.773196\n",
      "Epoch 23549 - Train Loss: 0.079597, Train Acc: 0.873077 | Val Loss: 0.112047, Val Acc: 0.773196\n",
      "Epoch 23550 - Train Loss: 0.079595, Train Acc: 0.873077 | Val Loss: 0.112046, Val Acc: 0.773196\n",
      "Epoch 23551 - Train Loss: 0.079593, Train Acc: 0.873077 | Val Loss: 0.112046, Val Acc: 0.773196\n",
      "Epoch 23552 - Train Loss: 0.079592, Train Acc: 0.873077 | Val Loss: 0.112045, Val Acc: 0.773196\n",
      "Epoch 23553 - Train Loss: 0.079590, Train Acc: 0.873077 | Val Loss: 0.112044, Val Acc: 0.773196\n",
      "Epoch 23554 - Train Loss: 0.079588, Train Acc: 0.873077 | Val Loss: 0.112044, Val Acc: 0.773196\n",
      "Epoch 23555 - Train Loss: 0.079586, Train Acc: 0.873077 | Val Loss: 0.112043, Val Acc: 0.773196\n",
      "Epoch 23556 - Train Loss: 0.079585, Train Acc: 0.873077 | Val Loss: 0.112043, Val Acc: 0.773196\n",
      "Epoch 23557 - Train Loss: 0.079583, Train Acc: 0.873077 | Val Loss: 0.112042, Val Acc: 0.773196\n",
      "Epoch 23558 - Train Loss: 0.079581, Train Acc: 0.873077 | Val Loss: 0.112041, Val Acc: 0.773196\n",
      "Epoch 23559 - Train Loss: 0.079579, Train Acc: 0.873077 | Val Loss: 0.112041, Val Acc: 0.773196\n",
      "Epoch 23560 - Train Loss: 0.079578, Train Acc: 0.873077 | Val Loss: 0.112040, Val Acc: 0.773196\n",
      "Epoch 23561 - Train Loss: 0.079576, Train Acc: 0.873077 | Val Loss: 0.112039, Val Acc: 0.773196\n",
      "Epoch 23562 - Train Loss: 0.079574, Train Acc: 0.873077 | Val Loss: 0.112039, Val Acc: 0.773196\n",
      "Epoch 23563 - Train Loss: 0.079573, Train Acc: 0.873077 | Val Loss: 0.112038, Val Acc: 0.773196\n",
      "Epoch 23564 - Train Loss: 0.079571, Train Acc: 0.873077 | Val Loss: 0.112037, Val Acc: 0.773196\n",
      "Epoch 23565 - Train Loss: 0.079569, Train Acc: 0.873077 | Val Loss: 0.112037, Val Acc: 0.773196\n",
      "Epoch 23566 - Train Loss: 0.079567, Train Acc: 0.873077 | Val Loss: 0.112036, Val Acc: 0.773196\n",
      "Epoch 23567 - Train Loss: 0.079566, Train Acc: 0.873077 | Val Loss: 0.112035, Val Acc: 0.773196\n",
      "Epoch 23568 - Train Loss: 0.079564, Train Acc: 0.873077 | Val Loss: 0.112035, Val Acc: 0.773196\n",
      "Epoch 23569 - Train Loss: 0.079562, Train Acc: 0.873077 | Val Loss: 0.112034, Val Acc: 0.773196\n",
      "Epoch 23570 - Train Loss: 0.079560, Train Acc: 0.873077 | Val Loss: 0.112034, Val Acc: 0.773196\n",
      "Epoch 23571 - Train Loss: 0.079559, Train Acc: 0.873077 | Val Loss: 0.112033, Val Acc: 0.773196\n",
      "Epoch 23572 - Train Loss: 0.079557, Train Acc: 0.873077 | Val Loss: 0.112032, Val Acc: 0.773196\n",
      "Epoch 23573 - Train Loss: 0.079555, Train Acc: 0.873077 | Val Loss: 0.112032, Val Acc: 0.773196\n",
      "Epoch 23574 - Train Loss: 0.079554, Train Acc: 0.873077 | Val Loss: 0.112031, Val Acc: 0.773196\n",
      "Epoch 23575 - Train Loss: 0.079552, Train Acc: 0.873077 | Val Loss: 0.112030, Val Acc: 0.773196\n",
      "Epoch 23576 - Train Loss: 0.079550, Train Acc: 0.873077 | Val Loss: 0.112030, Val Acc: 0.773196\n",
      "Epoch 23577 - Train Loss: 0.079548, Train Acc: 0.873077 | Val Loss: 0.112029, Val Acc: 0.773196\n",
      "Epoch 23578 - Train Loss: 0.079547, Train Acc: 0.873077 | Val Loss: 0.112028, Val Acc: 0.773196\n",
      "Epoch 23579 - Train Loss: 0.079545, Train Acc: 0.873077 | Val Loss: 0.112028, Val Acc: 0.773196\n",
      "Epoch 23580 - Train Loss: 0.079543, Train Acc: 0.873077 | Val Loss: 0.112027, Val Acc: 0.773196\n",
      "Epoch 23581 - Train Loss: 0.079542, Train Acc: 0.873077 | Val Loss: 0.112026, Val Acc: 0.773196\n",
      "Epoch 23582 - Train Loss: 0.079540, Train Acc: 0.873077 | Val Loss: 0.112026, Val Acc: 0.773196\n",
      "Epoch 23583 - Train Loss: 0.079538, Train Acc: 0.873077 | Val Loss: 0.112025, Val Acc: 0.773196\n",
      "Epoch 23584 - Train Loss: 0.079536, Train Acc: 0.873077 | Val Loss: 0.112025, Val Acc: 0.773196\n",
      "Epoch 23585 - Train Loss: 0.079535, Train Acc: 0.873077 | Val Loss: 0.112024, Val Acc: 0.773196\n",
      "Epoch 23586 - Train Loss: 0.079533, Train Acc: 0.873077 | Val Loss: 0.112023, Val Acc: 0.773196\n",
      "Epoch 23587 - Train Loss: 0.079531, Train Acc: 0.873077 | Val Loss: 0.112023, Val Acc: 0.773196\n",
      "Epoch 23588 - Train Loss: 0.079530, Train Acc: 0.873077 | Val Loss: 0.112022, Val Acc: 0.773196\n",
      "Epoch 23589 - Train Loss: 0.079528, Train Acc: 0.873077 | Val Loss: 0.112021, Val Acc: 0.773196\n",
      "Epoch 23590 - Train Loss: 0.079526, Train Acc: 0.873077 | Val Loss: 0.112021, Val Acc: 0.773196\n",
      "Epoch 23591 - Train Loss: 0.079524, Train Acc: 0.873077 | Val Loss: 0.112020, Val Acc: 0.773196\n",
      "Epoch 23592 - Train Loss: 0.079523, Train Acc: 0.873077 | Val Loss: 0.112019, Val Acc: 0.773196\n",
      "Epoch 23593 - Train Loss: 0.079521, Train Acc: 0.873077 | Val Loss: 0.112019, Val Acc: 0.773196\n",
      "Epoch 23594 - Train Loss: 0.079519, Train Acc: 0.873077 | Val Loss: 0.112018, Val Acc: 0.773196\n",
      "Epoch 23595 - Train Loss: 0.079517, Train Acc: 0.873077 | Val Loss: 0.112017, Val Acc: 0.773196\n",
      "Epoch 23596 - Train Loss: 0.079516, Train Acc: 0.873077 | Val Loss: 0.112017, Val Acc: 0.773196\n",
      "Epoch 23597 - Train Loss: 0.079514, Train Acc: 0.873077 | Val Loss: 0.112016, Val Acc: 0.773196\n",
      "Epoch 23598 - Train Loss: 0.079512, Train Acc: 0.873077 | Val Loss: 0.112016, Val Acc: 0.773196\n",
      "Epoch 23599 - Train Loss: 0.079511, Train Acc: 0.873077 | Val Loss: 0.112015, Val Acc: 0.773196\n",
      "Epoch 23600 - Train Loss: 0.079509, Train Acc: 0.873077 | Val Loss: 0.112014, Val Acc: 0.773196\n",
      "Epoch 23601 - Train Loss: 0.079507, Train Acc: 0.873077 | Val Loss: 0.112014, Val Acc: 0.773196\n",
      "Epoch 23602 - Train Loss: 0.079505, Train Acc: 0.873077 | Val Loss: 0.112013, Val Acc: 0.773196\n",
      "Epoch 23603 - Train Loss: 0.079504, Train Acc: 0.873077 | Val Loss: 0.112012, Val Acc: 0.773196\n",
      "Epoch 23604 - Train Loss: 0.079502, Train Acc: 0.873077 | Val Loss: 0.112012, Val Acc: 0.773196\n",
      "Epoch 23605 - Train Loss: 0.079500, Train Acc: 0.873077 | Val Loss: 0.112011, Val Acc: 0.773196\n",
      "Epoch 23606 - Train Loss: 0.079499, Train Acc: 0.873077 | Val Loss: 0.112010, Val Acc: 0.773196\n",
      "Epoch 23607 - Train Loss: 0.079497, Train Acc: 0.873077 | Val Loss: 0.112010, Val Acc: 0.773196\n",
      "Epoch 23608 - Train Loss: 0.079495, Train Acc: 0.873077 | Val Loss: 0.112009, Val Acc: 0.773196\n",
      "Epoch 23609 - Train Loss: 0.079493, Train Acc: 0.873077 | Val Loss: 0.112009, Val Acc: 0.773196\n",
      "Epoch 23610 - Train Loss: 0.079492, Train Acc: 0.873077 | Val Loss: 0.112008, Val Acc: 0.773196\n",
      "Epoch 23611 - Train Loss: 0.079490, Train Acc: 0.873077 | Val Loss: 0.112007, Val Acc: 0.773196\n",
      "Epoch 23612 - Train Loss: 0.079488, Train Acc: 0.873077 | Val Loss: 0.112007, Val Acc: 0.773196\n",
      "Epoch 23613 - Train Loss: 0.079487, Train Acc: 0.873077 | Val Loss: 0.112006, Val Acc: 0.773196\n",
      "Epoch 23614 - Train Loss: 0.079485, Train Acc: 0.873077 | Val Loss: 0.112005, Val Acc: 0.773196\n",
      "Epoch 23615 - Train Loss: 0.079483, Train Acc: 0.873077 | Val Loss: 0.112005, Val Acc: 0.773196\n",
      "Epoch 23616 - Train Loss: 0.079481, Train Acc: 0.873077 | Val Loss: 0.112004, Val Acc: 0.773196\n",
      "Epoch 23617 - Train Loss: 0.079480, Train Acc: 0.873077 | Val Loss: 0.112003, Val Acc: 0.773196\n",
      "Epoch 23618 - Train Loss: 0.079478, Train Acc: 0.873077 | Val Loss: 0.112003, Val Acc: 0.773196\n",
      "Epoch 23619 - Train Loss: 0.079476, Train Acc: 0.873077 | Val Loss: 0.112002, Val Acc: 0.773196\n",
      "Epoch 23620 - Train Loss: 0.079475, Train Acc: 0.873077 | Val Loss: 0.112001, Val Acc: 0.773196\n",
      "Epoch 23621 - Train Loss: 0.079473, Train Acc: 0.873077 | Val Loss: 0.112001, Val Acc: 0.773196\n",
      "Epoch 23622 - Train Loss: 0.079471, Train Acc: 0.873077 | Val Loss: 0.112000, Val Acc: 0.773196\n",
      "Epoch 23623 - Train Loss: 0.079469, Train Acc: 0.873077 | Val Loss: 0.112000, Val Acc: 0.773196\n",
      "Epoch 23624 - Train Loss: 0.079468, Train Acc: 0.873077 | Val Loss: 0.111999, Val Acc: 0.773196\n",
      "Epoch 23625 - Train Loss: 0.079466, Train Acc: 0.873077 | Val Loss: 0.111998, Val Acc: 0.773196\n",
      "Epoch 23626 - Train Loss: 0.079464, Train Acc: 0.873077 | Val Loss: 0.111998, Val Acc: 0.773196\n",
      "Epoch 23627 - Train Loss: 0.079462, Train Acc: 0.873077 | Val Loss: 0.111997, Val Acc: 0.773196\n",
      "Epoch 23628 - Train Loss: 0.079461, Train Acc: 0.873077 | Val Loss: 0.111996, Val Acc: 0.773196\n",
      "Epoch 23629 - Train Loss: 0.079459, Train Acc: 0.873077 | Val Loss: 0.111996, Val Acc: 0.773196\n",
      "Epoch 23630 - Train Loss: 0.079457, Train Acc: 0.873077 | Val Loss: 0.111995, Val Acc: 0.773196\n",
      "Epoch 23631 - Train Loss: 0.079456, Train Acc: 0.873077 | Val Loss: 0.111994, Val Acc: 0.773196\n",
      "Epoch 23632 - Train Loss: 0.079454, Train Acc: 0.873077 | Val Loss: 0.111994, Val Acc: 0.773196\n",
      "Epoch 23633 - Train Loss: 0.079452, Train Acc: 0.873077 | Val Loss: 0.111993, Val Acc: 0.773196\n",
      "Epoch 23634 - Train Loss: 0.079450, Train Acc: 0.873077 | Val Loss: 0.111993, Val Acc: 0.773196\n",
      "Epoch 23635 - Train Loss: 0.079449, Train Acc: 0.873077 | Val Loss: 0.111992, Val Acc: 0.773196\n",
      "Epoch 23636 - Train Loss: 0.079447, Train Acc: 0.873077 | Val Loss: 0.111991, Val Acc: 0.773196\n",
      "Epoch 23637 - Train Loss: 0.079445, Train Acc: 0.873077 | Val Loss: 0.111991, Val Acc: 0.773196\n",
      "Epoch 23638 - Train Loss: 0.079444, Train Acc: 0.873077 | Val Loss: 0.111990, Val Acc: 0.773196\n",
      "Epoch 23639 - Train Loss: 0.079442, Train Acc: 0.873077 | Val Loss: 0.111989, Val Acc: 0.773196\n",
      "Epoch 23640 - Train Loss: 0.079440, Train Acc: 0.873077 | Val Loss: 0.111989, Val Acc: 0.773196\n",
      "Epoch 23641 - Train Loss: 0.079438, Train Acc: 0.873077 | Val Loss: 0.111988, Val Acc: 0.773196\n",
      "Epoch 23642 - Train Loss: 0.079437, Train Acc: 0.873077 | Val Loss: 0.111987, Val Acc: 0.773196\n",
      "Epoch 23643 - Train Loss: 0.079435, Train Acc: 0.873077 | Val Loss: 0.111987, Val Acc: 0.773196\n",
      "Epoch 23644 - Train Loss: 0.079433, Train Acc: 0.873077 | Val Loss: 0.111986, Val Acc: 0.773196\n",
      "Epoch 23645 - Train Loss: 0.079432, Train Acc: 0.873077 | Val Loss: 0.111986, Val Acc: 0.773196\n",
      "Epoch 23646 - Train Loss: 0.079430, Train Acc: 0.873077 | Val Loss: 0.111985, Val Acc: 0.773196\n",
      "Epoch 23647 - Train Loss: 0.079428, Train Acc: 0.873077 | Val Loss: 0.111984, Val Acc: 0.773196\n",
      "Epoch 23648 - Train Loss: 0.079426, Train Acc: 0.873077 | Val Loss: 0.111984, Val Acc: 0.773196\n",
      "Epoch 23649 - Train Loss: 0.079425, Train Acc: 0.873077 | Val Loss: 0.111983, Val Acc: 0.773196\n",
      "Epoch 23650 - Train Loss: 0.079423, Train Acc: 0.873077 | Val Loss: 0.111982, Val Acc: 0.773196\n",
      "Epoch 23651 - Train Loss: 0.079421, Train Acc: 0.873077 | Val Loss: 0.111982, Val Acc: 0.773196\n",
      "Epoch 23652 - Train Loss: 0.079420, Train Acc: 0.873077 | Val Loss: 0.111981, Val Acc: 0.773196\n",
      "Epoch 23653 - Train Loss: 0.079418, Train Acc: 0.873077 | Val Loss: 0.111980, Val Acc: 0.773196\n",
      "Epoch 23654 - Train Loss: 0.079416, Train Acc: 0.873077 | Val Loss: 0.111980, Val Acc: 0.773196\n",
      "Epoch 23655 - Train Loss: 0.079414, Train Acc: 0.873077 | Val Loss: 0.111979, Val Acc: 0.773196\n",
      "Epoch 23656 - Train Loss: 0.079413, Train Acc: 0.873077 | Val Loss: 0.111979, Val Acc: 0.773196\n",
      "Epoch 23657 - Train Loss: 0.079411, Train Acc: 0.873077 | Val Loss: 0.111978, Val Acc: 0.773196\n",
      "Epoch 23658 - Train Loss: 0.079409, Train Acc: 0.873077 | Val Loss: 0.111977, Val Acc: 0.773196\n",
      "Epoch 23659 - Train Loss: 0.079408, Train Acc: 0.873077 | Val Loss: 0.111977, Val Acc: 0.773196\n",
      "Epoch 23660 - Train Loss: 0.079406, Train Acc: 0.873077 | Val Loss: 0.111976, Val Acc: 0.773196\n",
      "Epoch 23661 - Train Loss: 0.079404, Train Acc: 0.873077 | Val Loss: 0.111975, Val Acc: 0.773196\n",
      "Epoch 23662 - Train Loss: 0.079402, Train Acc: 0.873077 | Val Loss: 0.111975, Val Acc: 0.773196\n",
      "Epoch 23663 - Train Loss: 0.079401, Train Acc: 0.873077 | Val Loss: 0.111974, Val Acc: 0.773196\n",
      "Epoch 23664 - Train Loss: 0.079399, Train Acc: 0.873077 | Val Loss: 0.111973, Val Acc: 0.773196\n",
      "Epoch 23665 - Train Loss: 0.079397, Train Acc: 0.873077 | Val Loss: 0.111973, Val Acc: 0.773196\n",
      "Epoch 23666 - Train Loss: 0.079396, Train Acc: 0.873077 | Val Loss: 0.111972, Val Acc: 0.773196\n",
      "Epoch 23667 - Train Loss: 0.079394, Train Acc: 0.873077 | Val Loss: 0.111972, Val Acc: 0.773196\n",
      "Epoch 23668 - Train Loss: 0.079392, Train Acc: 0.873077 | Val Loss: 0.111971, Val Acc: 0.773196\n",
      "Epoch 23669 - Train Loss: 0.079391, Train Acc: 0.873077 | Val Loss: 0.111970, Val Acc: 0.773196\n",
      "Epoch 23670 - Train Loss: 0.079389, Train Acc: 0.873077 | Val Loss: 0.111970, Val Acc: 0.773196\n",
      "Epoch 23671 - Train Loss: 0.079387, Train Acc: 0.873077 | Val Loss: 0.111969, Val Acc: 0.773196\n",
      "Epoch 23672 - Train Loss: 0.079385, Train Acc: 0.873077 | Val Loss: 0.111968, Val Acc: 0.773196\n",
      "Epoch 23673 - Train Loss: 0.079384, Train Acc: 0.873077 | Val Loss: 0.111968, Val Acc: 0.773196\n",
      "Epoch 23674 - Train Loss: 0.079382, Train Acc: 0.873077 | Val Loss: 0.111967, Val Acc: 0.773196\n",
      "Epoch 23675 - Train Loss: 0.079380, Train Acc: 0.873077 | Val Loss: 0.111967, Val Acc: 0.773196\n",
      "Epoch 23676 - Train Loss: 0.079379, Train Acc: 0.873077 | Val Loss: 0.111966, Val Acc: 0.773196\n",
      "Epoch 23677 - Train Loss: 0.079377, Train Acc: 0.873077 | Val Loss: 0.111965, Val Acc: 0.773196\n",
      "Epoch 23678 - Train Loss: 0.079375, Train Acc: 0.873077 | Val Loss: 0.111965, Val Acc: 0.773196\n",
      "Epoch 23679 - Train Loss: 0.079373, Train Acc: 0.873077 | Val Loss: 0.111964, Val Acc: 0.773196\n",
      "Epoch 23680 - Train Loss: 0.079372, Train Acc: 0.873077 | Val Loss: 0.111963, Val Acc: 0.773196\n",
      "Epoch 23681 - Train Loss: 0.079370, Train Acc: 0.873077 | Val Loss: 0.111963, Val Acc: 0.773196\n",
      "Epoch 23682 - Train Loss: 0.079368, Train Acc: 0.873077 | Val Loss: 0.111962, Val Acc: 0.773196\n",
      "Epoch 23683 - Train Loss: 0.079367, Train Acc: 0.873077 | Val Loss: 0.111961, Val Acc: 0.773196\n",
      "Epoch 23684 - Train Loss: 0.079365, Train Acc: 0.873077 | Val Loss: 0.111961, Val Acc: 0.773196\n",
      "Epoch 23685 - Train Loss: 0.079363, Train Acc: 0.873077 | Val Loss: 0.111960, Val Acc: 0.773196\n",
      "Epoch 23686 - Train Loss: 0.079361, Train Acc: 0.873077 | Val Loss: 0.111960, Val Acc: 0.773196\n",
      "Epoch 23687 - Train Loss: 0.079360, Train Acc: 0.873077 | Val Loss: 0.111959, Val Acc: 0.773196\n",
      "Epoch 23688 - Train Loss: 0.079358, Train Acc: 0.873077 | Val Loss: 0.111958, Val Acc: 0.773196\n",
      "Epoch 23689 - Train Loss: 0.079356, Train Acc: 0.873077 | Val Loss: 0.111958, Val Acc: 0.773196\n",
      "Epoch 23690 - Train Loss: 0.079355, Train Acc: 0.873077 | Val Loss: 0.111957, Val Acc: 0.773196\n",
      "Epoch 23691 - Train Loss: 0.079353, Train Acc: 0.873077 | Val Loss: 0.111956, Val Acc: 0.773196\n",
      "Epoch 23692 - Train Loss: 0.079351, Train Acc: 0.873077 | Val Loss: 0.111956, Val Acc: 0.773196\n",
      "Epoch 23693 - Train Loss: 0.079349, Train Acc: 0.873077 | Val Loss: 0.111955, Val Acc: 0.773196\n",
      "Epoch 23694 - Train Loss: 0.079348, Train Acc: 0.873077 | Val Loss: 0.111954, Val Acc: 0.773196\n",
      "Epoch 23695 - Train Loss: 0.079346, Train Acc: 0.873077 | Val Loss: 0.111954, Val Acc: 0.773196\n",
      "Epoch 23696 - Train Loss: 0.079344, Train Acc: 0.873077 | Val Loss: 0.111953, Val Acc: 0.773196\n",
      "Epoch 23697 - Train Loss: 0.079343, Train Acc: 0.873077 | Val Loss: 0.111953, Val Acc: 0.773196\n",
      "Epoch 23698 - Train Loss: 0.079341, Train Acc: 0.873077 | Val Loss: 0.111952, Val Acc: 0.773196\n",
      "Epoch 23699 - Train Loss: 0.079339, Train Acc: 0.873077 | Val Loss: 0.111951, Val Acc: 0.773196\n",
      "Epoch 23700 - Train Loss: 0.079337, Train Acc: 0.873077 | Val Loss: 0.111951, Val Acc: 0.773196\n",
      "Epoch 23701 - Train Loss: 0.079336, Train Acc: 0.873077 | Val Loss: 0.111950, Val Acc: 0.773196\n",
      "Epoch 23702 - Train Loss: 0.079334, Train Acc: 0.873077 | Val Loss: 0.111949, Val Acc: 0.773196\n",
      "Epoch 23703 - Train Loss: 0.079332, Train Acc: 0.873077 | Val Loss: 0.111949, Val Acc: 0.773196\n",
      "Epoch 23704 - Train Loss: 0.079331, Train Acc: 0.873077 | Val Loss: 0.111948, Val Acc: 0.773196\n",
      "Epoch 23705 - Train Loss: 0.079329, Train Acc: 0.873077 | Val Loss: 0.111948, Val Acc: 0.773196\n",
      "Epoch 23706 - Train Loss: 0.079327, Train Acc: 0.873077 | Val Loss: 0.111947, Val Acc: 0.773196\n",
      "Epoch 23707 - Train Loss: 0.079326, Train Acc: 0.873077 | Val Loss: 0.111946, Val Acc: 0.773196\n",
      "Epoch 23708 - Train Loss: 0.079324, Train Acc: 0.873077 | Val Loss: 0.111946, Val Acc: 0.773196\n",
      "Epoch 23709 - Train Loss: 0.079322, Train Acc: 0.873077 | Val Loss: 0.111945, Val Acc: 0.773196\n",
      "Epoch 23710 - Train Loss: 0.079320, Train Acc: 0.873077 | Val Loss: 0.111944, Val Acc: 0.773196\n",
      "Epoch 23711 - Train Loss: 0.079319, Train Acc: 0.873077 | Val Loss: 0.111944, Val Acc: 0.773196\n",
      "Epoch 23712 - Train Loss: 0.079317, Train Acc: 0.873077 | Val Loss: 0.111943, Val Acc: 0.773196\n",
      "Epoch 23713 - Train Loss: 0.079315, Train Acc: 0.873077 | Val Loss: 0.111942, Val Acc: 0.773196\n",
      "Epoch 23714 - Train Loss: 0.079314, Train Acc: 0.873077 | Val Loss: 0.111942, Val Acc: 0.773196\n",
      "Epoch 23715 - Train Loss: 0.079312, Train Acc: 0.873077 | Val Loss: 0.111941, Val Acc: 0.773196\n",
      "Epoch 23716 - Train Loss: 0.079310, Train Acc: 0.873077 | Val Loss: 0.111941, Val Acc: 0.773196\n",
      "Epoch 23717 - Train Loss: 0.079308, Train Acc: 0.873077 | Val Loss: 0.111940, Val Acc: 0.773196\n",
      "Epoch 23718 - Train Loss: 0.079307, Train Acc: 0.873077 | Val Loss: 0.111939, Val Acc: 0.773196\n",
      "Epoch 23719 - Train Loss: 0.079305, Train Acc: 0.873077 | Val Loss: 0.111939, Val Acc: 0.773196\n",
      "Epoch 23720 - Train Loss: 0.079303, Train Acc: 0.873077 | Val Loss: 0.111938, Val Acc: 0.773196\n",
      "Epoch 23721 - Train Loss: 0.079302, Train Acc: 0.873077 | Val Loss: 0.111937, Val Acc: 0.773196\n",
      "Epoch 23722 - Train Loss: 0.079300, Train Acc: 0.873077 | Val Loss: 0.111937, Val Acc: 0.773196\n",
      "Epoch 23723 - Train Loss: 0.079298, Train Acc: 0.873077 | Val Loss: 0.111936, Val Acc: 0.773196\n",
      "Epoch 23724 - Train Loss: 0.079297, Train Acc: 0.873077 | Val Loss: 0.111936, Val Acc: 0.773196\n",
      "Epoch 23725 - Train Loss: 0.079295, Train Acc: 0.873077 | Val Loss: 0.111935, Val Acc: 0.773196\n",
      "Epoch 23726 - Train Loss: 0.079293, Train Acc: 0.873077 | Val Loss: 0.111934, Val Acc: 0.773196\n",
      "Epoch 23727 - Train Loss: 0.079291, Train Acc: 0.873077 | Val Loss: 0.111934, Val Acc: 0.773196\n",
      "Epoch 23728 - Train Loss: 0.079290, Train Acc: 0.873077 | Val Loss: 0.111933, Val Acc: 0.773196\n",
      "Epoch 23729 - Train Loss: 0.079288, Train Acc: 0.873077 | Val Loss: 0.111932, Val Acc: 0.773196\n",
      "Epoch 23730 - Train Loss: 0.079286, Train Acc: 0.873077 | Val Loss: 0.111932, Val Acc: 0.773196\n",
      "Epoch 23731 - Train Loss: 0.079285, Train Acc: 0.873077 | Val Loss: 0.111931, Val Acc: 0.773196\n",
      "Epoch 23732 - Train Loss: 0.079283, Train Acc: 0.873077 | Val Loss: 0.111931, Val Acc: 0.773196\n",
      "Epoch 23733 - Train Loss: 0.079281, Train Acc: 0.873077 | Val Loss: 0.111930, Val Acc: 0.773196\n",
      "Epoch 23734 - Train Loss: 0.079279, Train Acc: 0.873077 | Val Loss: 0.111929, Val Acc: 0.773196\n",
      "Epoch 23735 - Train Loss: 0.079278, Train Acc: 0.873077 | Val Loss: 0.111929, Val Acc: 0.773196\n",
      "Epoch 23736 - Train Loss: 0.079276, Train Acc: 0.873077 | Val Loss: 0.111928, Val Acc: 0.773196\n",
      "Epoch 23737 - Train Loss: 0.079274, Train Acc: 0.873077 | Val Loss: 0.111927, Val Acc: 0.773196\n",
      "Epoch 23738 - Train Loss: 0.079273, Train Acc: 0.873077 | Val Loss: 0.111927, Val Acc: 0.773196\n",
      "Epoch 23739 - Train Loss: 0.079271, Train Acc: 0.873077 | Val Loss: 0.111926, Val Acc: 0.773196\n",
      "Epoch 23740 - Train Loss: 0.079269, Train Acc: 0.873077 | Val Loss: 0.111926, Val Acc: 0.773196\n",
      "Epoch 23741 - Train Loss: 0.079268, Train Acc: 0.873077 | Val Loss: 0.111925, Val Acc: 0.773196\n",
      "Epoch 23742 - Train Loss: 0.079266, Train Acc: 0.873077 | Val Loss: 0.111924, Val Acc: 0.773196\n",
      "Epoch 23743 - Train Loss: 0.079264, Train Acc: 0.873077 | Val Loss: 0.111924, Val Acc: 0.773196\n",
      "Epoch 23744 - Train Loss: 0.079262, Train Acc: 0.873077 | Val Loss: 0.111923, Val Acc: 0.773196\n",
      "Epoch 23745 - Train Loss: 0.079261, Train Acc: 0.873077 | Val Loss: 0.111922, Val Acc: 0.773196\n",
      "Epoch 23746 - Train Loss: 0.079259, Train Acc: 0.873077 | Val Loss: 0.111922, Val Acc: 0.773196\n",
      "Epoch 23747 - Train Loss: 0.079257, Train Acc: 0.873077 | Val Loss: 0.111921, Val Acc: 0.773196\n",
      "Epoch 23748 - Train Loss: 0.079256, Train Acc: 0.873077 | Val Loss: 0.111920, Val Acc: 0.773196\n",
      "Epoch 23749 - Train Loss: 0.079254, Train Acc: 0.873077 | Val Loss: 0.111920, Val Acc: 0.773196\n",
      "Epoch 23750 - Train Loss: 0.079252, Train Acc: 0.873077 | Val Loss: 0.111919, Val Acc: 0.773196\n",
      "Epoch 23751 - Train Loss: 0.079251, Train Acc: 0.873077 | Val Loss: 0.111919, Val Acc: 0.773196\n",
      "Epoch 23752 - Train Loss: 0.079249, Train Acc: 0.873077 | Val Loss: 0.111918, Val Acc: 0.773196\n",
      "Epoch 23753 - Train Loss: 0.079247, Train Acc: 0.873077 | Val Loss: 0.111917, Val Acc: 0.773196\n",
      "Epoch 23754 - Train Loss: 0.079245, Train Acc: 0.873077 | Val Loss: 0.111917, Val Acc: 0.773196\n",
      "Epoch 23755 - Train Loss: 0.079244, Train Acc: 0.873077 | Val Loss: 0.111916, Val Acc: 0.773196\n",
      "Epoch 23756 - Train Loss: 0.079242, Train Acc: 0.873077 | Val Loss: 0.111915, Val Acc: 0.773196\n",
      "Epoch 23757 - Train Loss: 0.079240, Train Acc: 0.873077 | Val Loss: 0.111915, Val Acc: 0.773196\n",
      "Epoch 23758 - Train Loss: 0.079239, Train Acc: 0.873077 | Val Loss: 0.111914, Val Acc: 0.773196\n",
      "Epoch 23759 - Train Loss: 0.079237, Train Acc: 0.873077 | Val Loss: 0.111914, Val Acc: 0.773196\n",
      "Epoch 23760 - Train Loss: 0.079235, Train Acc: 0.873077 | Val Loss: 0.111913, Val Acc: 0.773196\n",
      "Epoch 23761 - Train Loss: 0.079233, Train Acc: 0.873077 | Val Loss: 0.111912, Val Acc: 0.773196\n",
      "Epoch 23762 - Train Loss: 0.079232, Train Acc: 0.873077 | Val Loss: 0.111912, Val Acc: 0.773196\n",
      "Epoch 23763 - Train Loss: 0.079230, Train Acc: 0.873077 | Val Loss: 0.111911, Val Acc: 0.773196\n",
      "Epoch 23764 - Train Loss: 0.079228, Train Acc: 0.873077 | Val Loss: 0.111910, Val Acc: 0.773196\n",
      "Epoch 23765 - Train Loss: 0.079227, Train Acc: 0.873077 | Val Loss: 0.111910, Val Acc: 0.773196\n",
      "Epoch 23766 - Train Loss: 0.079225, Train Acc: 0.873077 | Val Loss: 0.111909, Val Acc: 0.773196\n",
      "Epoch 23767 - Train Loss: 0.079223, Train Acc: 0.873077 | Val Loss: 0.111909, Val Acc: 0.773196\n",
      "Epoch 23768 - Train Loss: 0.079222, Train Acc: 0.873077 | Val Loss: 0.111908, Val Acc: 0.773196\n",
      "Epoch 23769 - Train Loss: 0.079220, Train Acc: 0.873077 | Val Loss: 0.111907, Val Acc: 0.773196\n",
      "Epoch 23770 - Train Loss: 0.079218, Train Acc: 0.873077 | Val Loss: 0.111907, Val Acc: 0.773196\n",
      "Epoch 23771 - Train Loss: 0.079216, Train Acc: 0.873077 | Val Loss: 0.111906, Val Acc: 0.773196\n",
      "Epoch 23772 - Train Loss: 0.079215, Train Acc: 0.873077 | Val Loss: 0.111905, Val Acc: 0.773196\n",
      "Epoch 23773 - Train Loss: 0.079213, Train Acc: 0.873077 | Val Loss: 0.111905, Val Acc: 0.773196\n",
      "Epoch 23774 - Train Loss: 0.079211, Train Acc: 0.873077 | Val Loss: 0.111904, Val Acc: 0.773196\n",
      "Epoch 23775 - Train Loss: 0.079210, Train Acc: 0.873077 | Val Loss: 0.111904, Val Acc: 0.773196\n",
      "Epoch 23776 - Train Loss: 0.079208, Train Acc: 0.873077 | Val Loss: 0.111903, Val Acc: 0.773196\n",
      "Epoch 23777 - Train Loss: 0.079206, Train Acc: 0.873077 | Val Loss: 0.111902, Val Acc: 0.773196\n",
      "Epoch 23778 - Train Loss: 0.079205, Train Acc: 0.873077 | Val Loss: 0.111902, Val Acc: 0.773196\n",
      "Epoch 23779 - Train Loss: 0.079203, Train Acc: 0.873077 | Val Loss: 0.111901, Val Acc: 0.773196\n",
      "Epoch 23780 - Train Loss: 0.079201, Train Acc: 0.873077 | Val Loss: 0.111900, Val Acc: 0.773196\n",
      "Epoch 23781 - Train Loss: 0.079199, Train Acc: 0.873077 | Val Loss: 0.111900, Val Acc: 0.773196\n",
      "Epoch 23782 - Train Loss: 0.079198, Train Acc: 0.873077 | Val Loss: 0.111899, Val Acc: 0.773196\n",
      "Epoch 23783 - Train Loss: 0.079196, Train Acc: 0.873077 | Val Loss: 0.111899, Val Acc: 0.773196\n",
      "Epoch 23784 - Train Loss: 0.079194, Train Acc: 0.873077 | Val Loss: 0.111898, Val Acc: 0.773196\n",
      "Epoch 23785 - Train Loss: 0.079193, Train Acc: 0.873077 | Val Loss: 0.111897, Val Acc: 0.773196\n",
      "Epoch 23786 - Train Loss: 0.079191, Train Acc: 0.873077 | Val Loss: 0.111897, Val Acc: 0.773196\n",
      "Epoch 23787 - Train Loss: 0.079189, Train Acc: 0.873077 | Val Loss: 0.111896, Val Acc: 0.773196\n",
      "Epoch 23788 - Train Loss: 0.079188, Train Acc: 0.873077 | Val Loss: 0.111895, Val Acc: 0.773196\n",
      "Epoch 23789 - Train Loss: 0.079186, Train Acc: 0.873077 | Val Loss: 0.111895, Val Acc: 0.773196\n",
      "Epoch 23790 - Train Loss: 0.079184, Train Acc: 0.873077 | Val Loss: 0.111894, Val Acc: 0.773196\n",
      "Epoch 23791 - Train Loss: 0.079182, Train Acc: 0.873077 | Val Loss: 0.111894, Val Acc: 0.773196\n",
      "Epoch 23792 - Train Loss: 0.079181, Train Acc: 0.873077 | Val Loss: 0.111893, Val Acc: 0.773196\n",
      "Epoch 23793 - Train Loss: 0.079179, Train Acc: 0.873077 | Val Loss: 0.111892, Val Acc: 0.773196\n",
      "Epoch 23794 - Train Loss: 0.079177, Train Acc: 0.873077 | Val Loss: 0.111892, Val Acc: 0.773196\n",
      "Epoch 23795 - Train Loss: 0.079176, Train Acc: 0.873077 | Val Loss: 0.111891, Val Acc: 0.773196\n",
      "Epoch 23796 - Train Loss: 0.079174, Train Acc: 0.873077 | Val Loss: 0.111891, Val Acc: 0.773196\n",
      "Epoch 23797 - Train Loss: 0.079172, Train Acc: 0.873077 | Val Loss: 0.111890, Val Acc: 0.773196\n",
      "Epoch 23798 - Train Loss: 0.079171, Train Acc: 0.873077 | Val Loss: 0.111889, Val Acc: 0.773196\n",
      "Epoch 23799 - Train Loss: 0.079169, Train Acc: 0.873077 | Val Loss: 0.111889, Val Acc: 0.773196\n",
      "Epoch 23800 - Train Loss: 0.079167, Train Acc: 0.873077 | Val Loss: 0.111888, Val Acc: 0.773196\n",
      "Epoch 23801 - Train Loss: 0.079166, Train Acc: 0.873077 | Val Loss: 0.111887, Val Acc: 0.773196\n",
      "Epoch 23802 - Train Loss: 0.079164, Train Acc: 0.873077 | Val Loss: 0.111887, Val Acc: 0.773196\n",
      "Epoch 23803 - Train Loss: 0.079162, Train Acc: 0.873077 | Val Loss: 0.111886, Val Acc: 0.773196\n",
      "Epoch 23804 - Train Loss: 0.079160, Train Acc: 0.873077 | Val Loss: 0.111886, Val Acc: 0.773196\n",
      "Epoch 23805 - Train Loss: 0.079159, Train Acc: 0.873077 | Val Loss: 0.111885, Val Acc: 0.773196\n",
      "Epoch 23806 - Train Loss: 0.079157, Train Acc: 0.873077 | Val Loss: 0.111884, Val Acc: 0.773196\n",
      "Epoch 23807 - Train Loss: 0.079155, Train Acc: 0.873077 | Val Loss: 0.111884, Val Acc: 0.773196\n",
      "Epoch 23808 - Train Loss: 0.079154, Train Acc: 0.873077 | Val Loss: 0.111883, Val Acc: 0.773196\n",
      "Epoch 23809 - Train Loss: 0.079152, Train Acc: 0.873077 | Val Loss: 0.111882, Val Acc: 0.773196\n",
      "Epoch 23810 - Train Loss: 0.079150, Train Acc: 0.873077 | Val Loss: 0.111882, Val Acc: 0.773196\n",
      "Epoch 23811 - Train Loss: 0.079149, Train Acc: 0.873077 | Val Loss: 0.111881, Val Acc: 0.773196\n",
      "Epoch 23812 - Train Loss: 0.079147, Train Acc: 0.873077 | Val Loss: 0.111881, Val Acc: 0.773196\n",
      "Epoch 23813 - Train Loss: 0.079145, Train Acc: 0.873077 | Val Loss: 0.111880, Val Acc: 0.773196\n",
      "Epoch 23814 - Train Loss: 0.079143, Train Acc: 0.873077 | Val Loss: 0.111879, Val Acc: 0.773196\n",
      "Epoch 23815 - Train Loss: 0.079142, Train Acc: 0.873077 | Val Loss: 0.111879, Val Acc: 0.773196\n",
      "Epoch 23816 - Train Loss: 0.079140, Train Acc: 0.873077 | Val Loss: 0.111878, Val Acc: 0.773196\n",
      "Epoch 23817 - Train Loss: 0.079138, Train Acc: 0.873077 | Val Loss: 0.111877, Val Acc: 0.773196\n",
      "Epoch 23818 - Train Loss: 0.079137, Train Acc: 0.873077 | Val Loss: 0.111877, Val Acc: 0.773196\n",
      "Epoch 23819 - Train Loss: 0.079135, Train Acc: 0.873077 | Val Loss: 0.111876, Val Acc: 0.773196\n",
      "Epoch 23820 - Train Loss: 0.079133, Train Acc: 0.873077 | Val Loss: 0.111876, Val Acc: 0.773196\n",
      "Epoch 23821 - Train Loss: 0.079132, Train Acc: 0.873077 | Val Loss: 0.111875, Val Acc: 0.773196\n",
      "Epoch 23822 - Train Loss: 0.079130, Train Acc: 0.873077 | Val Loss: 0.111874, Val Acc: 0.773196\n",
      "Epoch 23823 - Train Loss: 0.079128, Train Acc: 0.873077 | Val Loss: 0.111874, Val Acc: 0.773196\n",
      "Epoch 23824 - Train Loss: 0.079127, Train Acc: 0.873077 | Val Loss: 0.111873, Val Acc: 0.773196\n",
      "Epoch 23825 - Train Loss: 0.079125, Train Acc: 0.873077 | Val Loss: 0.111872, Val Acc: 0.773196\n",
      "Epoch 23826 - Train Loss: 0.079123, Train Acc: 0.873077 | Val Loss: 0.111872, Val Acc: 0.773196\n",
      "Epoch 23827 - Train Loss: 0.079121, Train Acc: 0.873077 | Val Loss: 0.111871, Val Acc: 0.773196\n",
      "Epoch 23828 - Train Loss: 0.079120, Train Acc: 0.873077 | Val Loss: 0.111871, Val Acc: 0.773196\n",
      "Epoch 23829 - Train Loss: 0.079118, Train Acc: 0.873077 | Val Loss: 0.111870, Val Acc: 0.773196\n",
      "Epoch 23830 - Train Loss: 0.079116, Train Acc: 0.873077 | Val Loss: 0.111869, Val Acc: 0.773196\n",
      "Epoch 23831 - Train Loss: 0.079115, Train Acc: 0.873077 | Val Loss: 0.111869, Val Acc: 0.773196\n",
      "Epoch 23832 - Train Loss: 0.079113, Train Acc: 0.873077 | Val Loss: 0.111868, Val Acc: 0.773196\n",
      "Epoch 23833 - Train Loss: 0.079111, Train Acc: 0.873077 | Val Loss: 0.111868, Val Acc: 0.773196\n",
      "Epoch 23834 - Train Loss: 0.079110, Train Acc: 0.873077 | Val Loss: 0.111867, Val Acc: 0.773196\n",
      "Epoch 23835 - Train Loss: 0.079108, Train Acc: 0.873077 | Val Loss: 0.111866, Val Acc: 0.773196\n",
      "Epoch 23836 - Train Loss: 0.079106, Train Acc: 0.873077 | Val Loss: 0.111866, Val Acc: 0.773196\n",
      "Epoch 23837 - Train Loss: 0.079104, Train Acc: 0.873077 | Val Loss: 0.111865, Val Acc: 0.773196\n",
      "Epoch 23838 - Train Loss: 0.079103, Train Acc: 0.873077 | Val Loss: 0.111864, Val Acc: 0.773196\n",
      "Epoch 23839 - Train Loss: 0.079101, Train Acc: 0.873077 | Val Loss: 0.111864, Val Acc: 0.773196\n",
      "Epoch 23840 - Train Loss: 0.079099, Train Acc: 0.873077 | Val Loss: 0.111863, Val Acc: 0.773196\n",
      "Epoch 23841 - Train Loss: 0.079098, Train Acc: 0.873077 | Val Loss: 0.111863, Val Acc: 0.773196\n",
      "Epoch 23842 - Train Loss: 0.079096, Train Acc: 0.873077 | Val Loss: 0.111862, Val Acc: 0.773196\n",
      "Epoch 23843 - Train Loss: 0.079094, Train Acc: 0.873077 | Val Loss: 0.111861, Val Acc: 0.773196\n",
      "Epoch 23844 - Train Loss: 0.079093, Train Acc: 0.873077 | Val Loss: 0.111861, Val Acc: 0.773196\n",
      "Epoch 23845 - Train Loss: 0.079091, Train Acc: 0.873077 | Val Loss: 0.111860, Val Acc: 0.773196\n",
      "Epoch 23846 - Train Loss: 0.079089, Train Acc: 0.873077 | Val Loss: 0.111859, Val Acc: 0.773196\n",
      "Epoch 23847 - Train Loss: 0.079088, Train Acc: 0.873077 | Val Loss: 0.111859, Val Acc: 0.773196\n",
      "Epoch 23848 - Train Loss: 0.079086, Train Acc: 0.873077 | Val Loss: 0.111858, Val Acc: 0.773196\n",
      "Epoch 23849 - Train Loss: 0.079084, Train Acc: 0.873077 | Val Loss: 0.111858, Val Acc: 0.773196\n",
      "Epoch 23850 - Train Loss: 0.079082, Train Acc: 0.873077 | Val Loss: 0.111857, Val Acc: 0.773196\n",
      "Epoch 23851 - Train Loss: 0.079081, Train Acc: 0.873077 | Val Loss: 0.111856, Val Acc: 0.773196\n",
      "Epoch 23852 - Train Loss: 0.079079, Train Acc: 0.873077 | Val Loss: 0.111856, Val Acc: 0.773196\n",
      "Epoch 23853 - Train Loss: 0.079077, Train Acc: 0.873077 | Val Loss: 0.111855, Val Acc: 0.773196\n",
      "Epoch 23854 - Train Loss: 0.079076, Train Acc: 0.873077 | Val Loss: 0.111855, Val Acc: 0.773196\n",
      "Epoch 23855 - Train Loss: 0.079074, Train Acc: 0.873077 | Val Loss: 0.111854, Val Acc: 0.773196\n",
      "Epoch 23856 - Train Loss: 0.079072, Train Acc: 0.873077 | Val Loss: 0.111853, Val Acc: 0.773196\n",
      "Epoch 23857 - Train Loss: 0.079071, Train Acc: 0.873077 | Val Loss: 0.111853, Val Acc: 0.773196\n",
      "Epoch 23858 - Train Loss: 0.079069, Train Acc: 0.873077 | Val Loss: 0.111852, Val Acc: 0.773196\n",
      "Epoch 23859 - Train Loss: 0.079067, Train Acc: 0.873077 | Val Loss: 0.111851, Val Acc: 0.773196\n",
      "Epoch 23860 - Train Loss: 0.079066, Train Acc: 0.873077 | Val Loss: 0.111851, Val Acc: 0.773196\n",
      "Epoch 23861 - Train Loss: 0.079064, Train Acc: 0.873077 | Val Loss: 0.111850, Val Acc: 0.773196\n",
      "Epoch 23862 - Train Loss: 0.079062, Train Acc: 0.873077 | Val Loss: 0.111850, Val Acc: 0.773196\n",
      "Epoch 23863 - Train Loss: 0.079060, Train Acc: 0.873077 | Val Loss: 0.111849, Val Acc: 0.773196\n",
      "Epoch 23864 - Train Loss: 0.079059, Train Acc: 0.873077 | Val Loss: 0.111848, Val Acc: 0.773196\n",
      "Epoch 23865 - Train Loss: 0.079057, Train Acc: 0.873077 | Val Loss: 0.111848, Val Acc: 0.773196\n",
      "Epoch 23866 - Train Loss: 0.079055, Train Acc: 0.873077 | Val Loss: 0.111847, Val Acc: 0.773196\n",
      "Epoch 23867 - Train Loss: 0.079054, Train Acc: 0.873077 | Val Loss: 0.111846, Val Acc: 0.773196\n",
      "Epoch 23868 - Train Loss: 0.079052, Train Acc: 0.873077 | Val Loss: 0.111846, Val Acc: 0.773196\n",
      "Epoch 23869 - Train Loss: 0.079050, Train Acc: 0.873077 | Val Loss: 0.111845, Val Acc: 0.773196\n",
      "Epoch 23870 - Train Loss: 0.079049, Train Acc: 0.873077 | Val Loss: 0.111845, Val Acc: 0.773196\n",
      "Epoch 23871 - Train Loss: 0.079047, Train Acc: 0.873077 | Val Loss: 0.111844, Val Acc: 0.773196\n",
      "Epoch 23872 - Train Loss: 0.079045, Train Acc: 0.873077 | Val Loss: 0.111843, Val Acc: 0.773196\n",
      "Epoch 23873 - Train Loss: 0.079044, Train Acc: 0.873077 | Val Loss: 0.111843, Val Acc: 0.773196\n",
      "Epoch 23874 - Train Loss: 0.079042, Train Acc: 0.873077 | Val Loss: 0.111842, Val Acc: 0.773196\n",
      "Epoch 23875 - Train Loss: 0.079040, Train Acc: 0.873077 | Val Loss: 0.111842, Val Acc: 0.773196\n",
      "Epoch 23876 - Train Loss: 0.079039, Train Acc: 0.873077 | Val Loss: 0.111841, Val Acc: 0.773196\n",
      "Epoch 23877 - Train Loss: 0.079037, Train Acc: 0.873077 | Val Loss: 0.111840, Val Acc: 0.773196\n",
      "Epoch 23878 - Train Loss: 0.079035, Train Acc: 0.873077 | Val Loss: 0.111840, Val Acc: 0.773196\n",
      "Epoch 23879 - Train Loss: 0.079033, Train Acc: 0.873077 | Val Loss: 0.111839, Val Acc: 0.773196\n",
      "Epoch 23880 - Train Loss: 0.079032, Train Acc: 0.873077 | Val Loss: 0.111838, Val Acc: 0.773196\n",
      "Epoch 23881 - Train Loss: 0.079030, Train Acc: 0.873077 | Val Loss: 0.111838, Val Acc: 0.773196\n",
      "Epoch 23882 - Train Loss: 0.079028, Train Acc: 0.873077 | Val Loss: 0.111837, Val Acc: 0.773196\n",
      "Epoch 23883 - Train Loss: 0.079027, Train Acc: 0.873077 | Val Loss: 0.111837, Val Acc: 0.773196\n",
      "Epoch 23884 - Train Loss: 0.079025, Train Acc: 0.873077 | Val Loss: 0.111836, Val Acc: 0.773196\n",
      "Epoch 23885 - Train Loss: 0.079023, Train Acc: 0.873077 | Val Loss: 0.111835, Val Acc: 0.773196\n",
      "Epoch 23886 - Train Loss: 0.079022, Train Acc: 0.873077 | Val Loss: 0.111835, Val Acc: 0.773196\n",
      "Epoch 23887 - Train Loss: 0.079020, Train Acc: 0.873077 | Val Loss: 0.111834, Val Acc: 0.773196\n",
      "Epoch 23888 - Train Loss: 0.079018, Train Acc: 0.873077 | Val Loss: 0.111834, Val Acc: 0.773196\n",
      "Epoch 23889 - Train Loss: 0.079017, Train Acc: 0.873077 | Val Loss: 0.111833, Val Acc: 0.773196\n",
      "Epoch 23890 - Train Loss: 0.079015, Train Acc: 0.873077 | Val Loss: 0.111832, Val Acc: 0.773196\n",
      "Epoch 23891 - Train Loss: 0.079013, Train Acc: 0.873077 | Val Loss: 0.111832, Val Acc: 0.773196\n",
      "Epoch 23892 - Train Loss: 0.079012, Train Acc: 0.873077 | Val Loss: 0.111831, Val Acc: 0.773196\n",
      "Epoch 23893 - Train Loss: 0.079010, Train Acc: 0.873077 | Val Loss: 0.111830, Val Acc: 0.773196\n",
      "Epoch 23894 - Train Loss: 0.079008, Train Acc: 0.873077 | Val Loss: 0.111830, Val Acc: 0.773196\n",
      "Epoch 23895 - Train Loss: 0.079006, Train Acc: 0.873077 | Val Loss: 0.111829, Val Acc: 0.773196\n",
      "Epoch 23896 - Train Loss: 0.079005, Train Acc: 0.873077 | Val Loss: 0.111829, Val Acc: 0.773196\n",
      "Epoch 23897 - Train Loss: 0.079003, Train Acc: 0.873077 | Val Loss: 0.111828, Val Acc: 0.773196\n",
      "Epoch 23898 - Train Loss: 0.079001, Train Acc: 0.873077 | Val Loss: 0.111827, Val Acc: 0.773196\n",
      "Epoch 23899 - Train Loss: 0.079000, Train Acc: 0.873077 | Val Loss: 0.111827, Val Acc: 0.773196\n",
      "Epoch 23900 - Train Loss: 0.078998, Train Acc: 0.873077 | Val Loss: 0.111826, Val Acc: 0.773196\n",
      "Epoch 23901 - Train Loss: 0.078996, Train Acc: 0.873077 | Val Loss: 0.111826, Val Acc: 0.773196\n",
      "Epoch 23902 - Train Loss: 0.078995, Train Acc: 0.873077 | Val Loss: 0.111825, Val Acc: 0.773196\n",
      "Epoch 23903 - Train Loss: 0.078993, Train Acc: 0.873077 | Val Loss: 0.111824, Val Acc: 0.773196\n",
      "Epoch 23904 - Train Loss: 0.078991, Train Acc: 0.873077 | Val Loss: 0.111824, Val Acc: 0.773196\n",
      "Epoch 23905 - Train Loss: 0.078990, Train Acc: 0.873077 | Val Loss: 0.111823, Val Acc: 0.773196\n",
      "Epoch 23906 - Train Loss: 0.078988, Train Acc: 0.873077 | Val Loss: 0.111823, Val Acc: 0.773196\n",
      "Epoch 23907 - Train Loss: 0.078986, Train Acc: 0.873077 | Val Loss: 0.111822, Val Acc: 0.773196\n",
      "Epoch 23908 - Train Loss: 0.078985, Train Acc: 0.873077 | Val Loss: 0.111821, Val Acc: 0.773196\n",
      "Epoch 23909 - Train Loss: 0.078983, Train Acc: 0.873077 | Val Loss: 0.111821, Val Acc: 0.773196\n",
      "Epoch 23910 - Train Loss: 0.078981, Train Acc: 0.873077 | Val Loss: 0.111820, Val Acc: 0.773196\n",
      "Epoch 23911 - Train Loss: 0.078979, Train Acc: 0.873077 | Val Loss: 0.111820, Val Acc: 0.773196\n",
      "Epoch 23912 - Train Loss: 0.078978, Train Acc: 0.873077 | Val Loss: 0.111819, Val Acc: 0.773196\n",
      "Epoch 23913 - Train Loss: 0.078976, Train Acc: 0.873077 | Val Loss: 0.111818, Val Acc: 0.773196\n",
      "Epoch 23914 - Train Loss: 0.078974, Train Acc: 0.873077 | Val Loss: 0.111818, Val Acc: 0.773196\n",
      "Epoch 23915 - Train Loss: 0.078973, Train Acc: 0.873077 | Val Loss: 0.111817, Val Acc: 0.773196\n",
      "Epoch 23916 - Train Loss: 0.078971, Train Acc: 0.873077 | Val Loss: 0.111816, Val Acc: 0.773196\n",
      "Epoch 23917 - Train Loss: 0.078969, Train Acc: 0.873077 | Val Loss: 0.111816, Val Acc: 0.773196\n",
      "Epoch 23918 - Train Loss: 0.078968, Train Acc: 0.873077 | Val Loss: 0.111815, Val Acc: 0.773196\n",
      "Epoch 23919 - Train Loss: 0.078966, Train Acc: 0.873077 | Val Loss: 0.111815, Val Acc: 0.773196\n",
      "Epoch 23920 - Train Loss: 0.078964, Train Acc: 0.873077 | Val Loss: 0.111814, Val Acc: 0.773196\n",
      "Epoch 23921 - Train Loss: 0.078963, Train Acc: 0.873077 | Val Loss: 0.111813, Val Acc: 0.773196\n",
      "Epoch 23922 - Train Loss: 0.078961, Train Acc: 0.873077 | Val Loss: 0.111813, Val Acc: 0.773196\n",
      "Epoch 23923 - Train Loss: 0.078959, Train Acc: 0.873077 | Val Loss: 0.111812, Val Acc: 0.773196\n",
      "Epoch 23924 - Train Loss: 0.078958, Train Acc: 0.873077 | Val Loss: 0.111812, Val Acc: 0.773196\n",
      "Epoch 23925 - Train Loss: 0.078956, Train Acc: 0.873077 | Val Loss: 0.111811, Val Acc: 0.773196\n",
      "Epoch 23926 - Train Loss: 0.078954, Train Acc: 0.873077 | Val Loss: 0.111810, Val Acc: 0.773196\n",
      "Epoch 23927 - Train Loss: 0.078953, Train Acc: 0.873077 | Val Loss: 0.111810, Val Acc: 0.773196\n",
      "Epoch 23928 - Train Loss: 0.078951, Train Acc: 0.874359 | Val Loss: 0.111809, Val Acc: 0.773196\n",
      "Epoch 23929 - Train Loss: 0.078949, Train Acc: 0.874359 | Val Loss: 0.111809, Val Acc: 0.773196\n",
      "Epoch 23930 - Train Loss: 0.078947, Train Acc: 0.874359 | Val Loss: 0.111808, Val Acc: 0.773196\n",
      "Epoch 23931 - Train Loss: 0.078946, Train Acc: 0.874359 | Val Loss: 0.111807, Val Acc: 0.773196\n",
      "Epoch 23932 - Train Loss: 0.078944, Train Acc: 0.874359 | Val Loss: 0.111807, Val Acc: 0.773196\n",
      "Epoch 23933 - Train Loss: 0.078942, Train Acc: 0.874359 | Val Loss: 0.111806, Val Acc: 0.773196\n",
      "Epoch 23934 - Train Loss: 0.078941, Train Acc: 0.874359 | Val Loss: 0.111805, Val Acc: 0.773196\n",
      "Epoch 23935 - Train Loss: 0.078939, Train Acc: 0.874359 | Val Loss: 0.111805, Val Acc: 0.773196\n",
      "Epoch 23936 - Train Loss: 0.078937, Train Acc: 0.874359 | Val Loss: 0.111804, Val Acc: 0.773196\n",
      "Epoch 23937 - Train Loss: 0.078936, Train Acc: 0.874359 | Val Loss: 0.111804, Val Acc: 0.773196\n",
      "Epoch 23938 - Train Loss: 0.078934, Train Acc: 0.874359 | Val Loss: 0.111803, Val Acc: 0.773196\n",
      "Epoch 23939 - Train Loss: 0.078932, Train Acc: 0.874359 | Val Loss: 0.111802, Val Acc: 0.773196\n",
      "Epoch 23940 - Train Loss: 0.078931, Train Acc: 0.874359 | Val Loss: 0.111802, Val Acc: 0.773196\n",
      "Epoch 23941 - Train Loss: 0.078929, Train Acc: 0.874359 | Val Loss: 0.111801, Val Acc: 0.773196\n",
      "Epoch 23942 - Train Loss: 0.078927, Train Acc: 0.874359 | Val Loss: 0.111801, Val Acc: 0.773196\n",
      "Epoch 23943 - Train Loss: 0.078926, Train Acc: 0.874359 | Val Loss: 0.111800, Val Acc: 0.773196\n",
      "Epoch 23944 - Train Loss: 0.078924, Train Acc: 0.874359 | Val Loss: 0.111799, Val Acc: 0.773196\n",
      "Epoch 23945 - Train Loss: 0.078922, Train Acc: 0.874359 | Val Loss: 0.111799, Val Acc: 0.773196\n",
      "Epoch 23946 - Train Loss: 0.078921, Train Acc: 0.874359 | Val Loss: 0.111798, Val Acc: 0.773196\n",
      "Epoch 23947 - Train Loss: 0.078919, Train Acc: 0.874359 | Val Loss: 0.111798, Val Acc: 0.773196\n",
      "Epoch 23948 - Train Loss: 0.078917, Train Acc: 0.874359 | Val Loss: 0.111797, Val Acc: 0.773196\n",
      "Epoch 23949 - Train Loss: 0.078915, Train Acc: 0.874359 | Val Loss: 0.111796, Val Acc: 0.773196\n",
      "Epoch 23950 - Train Loss: 0.078914, Train Acc: 0.874359 | Val Loss: 0.111796, Val Acc: 0.773196\n",
      "Epoch 23951 - Train Loss: 0.078912, Train Acc: 0.874359 | Val Loss: 0.111795, Val Acc: 0.773196\n",
      "Epoch 23952 - Train Loss: 0.078910, Train Acc: 0.874359 | Val Loss: 0.111794, Val Acc: 0.773196\n",
      "Epoch 23953 - Train Loss: 0.078909, Train Acc: 0.874359 | Val Loss: 0.111794, Val Acc: 0.773196\n",
      "Epoch 23954 - Train Loss: 0.078907, Train Acc: 0.874359 | Val Loss: 0.111793, Val Acc: 0.773196\n",
      "Epoch 23955 - Train Loss: 0.078905, Train Acc: 0.874359 | Val Loss: 0.111793, Val Acc: 0.773196\n",
      "Epoch 23956 - Train Loss: 0.078904, Train Acc: 0.874359 | Val Loss: 0.111792, Val Acc: 0.773196\n",
      "Epoch 23957 - Train Loss: 0.078902, Train Acc: 0.874359 | Val Loss: 0.111791, Val Acc: 0.773196\n",
      "Epoch 23958 - Train Loss: 0.078900, Train Acc: 0.874359 | Val Loss: 0.111791, Val Acc: 0.773196\n",
      "Epoch 23959 - Train Loss: 0.078899, Train Acc: 0.874359 | Val Loss: 0.111790, Val Acc: 0.773196\n",
      "Epoch 23960 - Train Loss: 0.078897, Train Acc: 0.874359 | Val Loss: 0.111790, Val Acc: 0.773196\n",
      "Epoch 23961 - Train Loss: 0.078895, Train Acc: 0.874359 | Val Loss: 0.111789, Val Acc: 0.773196\n",
      "Epoch 23962 - Train Loss: 0.078894, Train Acc: 0.874359 | Val Loss: 0.111788, Val Acc: 0.773196\n",
      "Epoch 23963 - Train Loss: 0.078892, Train Acc: 0.874359 | Val Loss: 0.111788, Val Acc: 0.773196\n",
      "Epoch 23964 - Train Loss: 0.078890, Train Acc: 0.874359 | Val Loss: 0.111787, Val Acc: 0.773196\n",
      "Epoch 23965 - Train Loss: 0.078889, Train Acc: 0.874359 | Val Loss: 0.111787, Val Acc: 0.773196\n",
      "Epoch 23966 - Train Loss: 0.078887, Train Acc: 0.874359 | Val Loss: 0.111786, Val Acc: 0.773196\n",
      "Epoch 23967 - Train Loss: 0.078885, Train Acc: 0.874359 | Val Loss: 0.111785, Val Acc: 0.773196\n",
      "Epoch 23968 - Train Loss: 0.078884, Train Acc: 0.874359 | Val Loss: 0.111785, Val Acc: 0.773196\n",
      "Epoch 23969 - Train Loss: 0.078882, Train Acc: 0.874359 | Val Loss: 0.111784, Val Acc: 0.773196\n",
      "Epoch 23970 - Train Loss: 0.078880, Train Acc: 0.874359 | Val Loss: 0.111784, Val Acc: 0.773196\n",
      "Epoch 23971 - Train Loss: 0.078879, Train Acc: 0.874359 | Val Loss: 0.111783, Val Acc: 0.773196\n",
      "Epoch 23972 - Train Loss: 0.078877, Train Acc: 0.874359 | Val Loss: 0.111782, Val Acc: 0.773196\n",
      "Epoch 23973 - Train Loss: 0.078875, Train Acc: 0.874359 | Val Loss: 0.111782, Val Acc: 0.773196\n",
      "Epoch 23974 - Train Loss: 0.078873, Train Acc: 0.874359 | Val Loss: 0.111781, Val Acc: 0.773196\n",
      "Epoch 23975 - Train Loss: 0.078872, Train Acc: 0.874359 | Val Loss: 0.111780, Val Acc: 0.773196\n",
      "Epoch 23976 - Train Loss: 0.078870, Train Acc: 0.874359 | Val Loss: 0.111780, Val Acc: 0.773196\n",
      "Epoch 23977 - Train Loss: 0.078868, Train Acc: 0.874359 | Val Loss: 0.111779, Val Acc: 0.773196\n",
      "Epoch 23978 - Train Loss: 0.078867, Train Acc: 0.874359 | Val Loss: 0.111779, Val Acc: 0.773196\n",
      "Epoch 23979 - Train Loss: 0.078865, Train Acc: 0.874359 | Val Loss: 0.111778, Val Acc: 0.773196\n",
      "Epoch 23980 - Train Loss: 0.078863, Train Acc: 0.874359 | Val Loss: 0.111777, Val Acc: 0.773196\n",
      "Epoch 23981 - Train Loss: 0.078862, Train Acc: 0.874359 | Val Loss: 0.111777, Val Acc: 0.773196\n",
      "Epoch 23982 - Train Loss: 0.078860, Train Acc: 0.874359 | Val Loss: 0.111776, Val Acc: 0.773196\n",
      "Epoch 23983 - Train Loss: 0.078858, Train Acc: 0.874359 | Val Loss: 0.111776, Val Acc: 0.773196\n",
      "Epoch 23984 - Train Loss: 0.078857, Train Acc: 0.874359 | Val Loss: 0.111775, Val Acc: 0.773196\n",
      "Epoch 23985 - Train Loss: 0.078855, Train Acc: 0.874359 | Val Loss: 0.111774, Val Acc: 0.773196\n",
      "Epoch 23986 - Train Loss: 0.078853, Train Acc: 0.874359 | Val Loss: 0.111774, Val Acc: 0.773196\n",
      "Epoch 23987 - Train Loss: 0.078852, Train Acc: 0.874359 | Val Loss: 0.111773, Val Acc: 0.773196\n",
      "Epoch 23988 - Train Loss: 0.078850, Train Acc: 0.874359 | Val Loss: 0.111773, Val Acc: 0.773196\n",
      "Epoch 23989 - Train Loss: 0.078848, Train Acc: 0.874359 | Val Loss: 0.111772, Val Acc: 0.773196\n",
      "Epoch 23990 - Train Loss: 0.078847, Train Acc: 0.874359 | Val Loss: 0.111771, Val Acc: 0.773196\n",
      "Epoch 23991 - Train Loss: 0.078845, Train Acc: 0.874359 | Val Loss: 0.111771, Val Acc: 0.773196\n",
      "Epoch 23992 - Train Loss: 0.078843, Train Acc: 0.874359 | Val Loss: 0.111770, Val Acc: 0.773196\n",
      "Epoch 23993 - Train Loss: 0.078842, Train Acc: 0.874359 | Val Loss: 0.111770, Val Acc: 0.773196\n",
      "Epoch 23994 - Train Loss: 0.078840, Train Acc: 0.874359 | Val Loss: 0.111769, Val Acc: 0.773196\n",
      "Epoch 23995 - Train Loss: 0.078838, Train Acc: 0.874359 | Val Loss: 0.111768, Val Acc: 0.773196\n",
      "Epoch 23996 - Train Loss: 0.078837, Train Acc: 0.874359 | Val Loss: 0.111768, Val Acc: 0.773196\n",
      "Epoch 23997 - Train Loss: 0.078835, Train Acc: 0.874359 | Val Loss: 0.111767, Val Acc: 0.773196\n",
      "Epoch 23998 - Train Loss: 0.078833, Train Acc: 0.874359 | Val Loss: 0.111767, Val Acc: 0.773196\n",
      "Epoch 23999 - Train Loss: 0.078832, Train Acc: 0.874359 | Val Loss: 0.111766, Val Acc: 0.773196\n",
      "Epoch 24000 - Train Loss: 0.078830, Train Acc: 0.874359 | Val Loss: 0.111765, Val Acc: 0.773196\n",
      "Epoch 24001 - Train Loss: 0.078828, Train Acc: 0.874359 | Val Loss: 0.111765, Val Acc: 0.773196\n",
      "Epoch 24002 - Train Loss: 0.078827, Train Acc: 0.874359 | Val Loss: 0.111764, Val Acc: 0.773196\n",
      "Epoch 24003 - Train Loss: 0.078825, Train Acc: 0.874359 | Val Loss: 0.111763, Val Acc: 0.773196\n",
      "Epoch 24004 - Train Loss: 0.078823, Train Acc: 0.874359 | Val Loss: 0.111763, Val Acc: 0.773196\n",
      "Epoch 24005 - Train Loss: 0.078821, Train Acc: 0.874359 | Val Loss: 0.111762, Val Acc: 0.773196\n",
      "Epoch 24006 - Train Loss: 0.078820, Train Acc: 0.874359 | Val Loss: 0.111762, Val Acc: 0.773196\n",
      "Epoch 24007 - Train Loss: 0.078818, Train Acc: 0.874359 | Val Loss: 0.111761, Val Acc: 0.773196\n",
      "Epoch 24008 - Train Loss: 0.078816, Train Acc: 0.874359 | Val Loss: 0.111760, Val Acc: 0.773196\n",
      "Epoch 24009 - Train Loss: 0.078815, Train Acc: 0.874359 | Val Loss: 0.111760, Val Acc: 0.773196\n",
      "Epoch 24010 - Train Loss: 0.078813, Train Acc: 0.874359 | Val Loss: 0.111759, Val Acc: 0.773196\n",
      "Epoch 24011 - Train Loss: 0.078811, Train Acc: 0.874359 | Val Loss: 0.111759, Val Acc: 0.773196\n",
      "Epoch 24012 - Train Loss: 0.078810, Train Acc: 0.874359 | Val Loss: 0.111758, Val Acc: 0.773196\n",
      "Epoch 24013 - Train Loss: 0.078808, Train Acc: 0.874359 | Val Loss: 0.111757, Val Acc: 0.773196\n",
      "Epoch 24014 - Train Loss: 0.078806, Train Acc: 0.874359 | Val Loss: 0.111757, Val Acc: 0.773196\n",
      "Epoch 24015 - Train Loss: 0.078805, Train Acc: 0.874359 | Val Loss: 0.111756, Val Acc: 0.773196\n",
      "Epoch 24016 - Train Loss: 0.078803, Train Acc: 0.874359 | Val Loss: 0.111756, Val Acc: 0.773196\n",
      "Epoch 24017 - Train Loss: 0.078801, Train Acc: 0.874359 | Val Loss: 0.111755, Val Acc: 0.773196\n",
      "Epoch 24018 - Train Loss: 0.078800, Train Acc: 0.874359 | Val Loss: 0.111754, Val Acc: 0.773196\n",
      "Epoch 24019 - Train Loss: 0.078798, Train Acc: 0.874359 | Val Loss: 0.111754, Val Acc: 0.773196\n",
      "Epoch 24020 - Train Loss: 0.078796, Train Acc: 0.874359 | Val Loss: 0.111753, Val Acc: 0.773196\n",
      "Epoch 24021 - Train Loss: 0.078795, Train Acc: 0.874359 | Val Loss: 0.111753, Val Acc: 0.773196\n",
      "Epoch 24022 - Train Loss: 0.078793, Train Acc: 0.874359 | Val Loss: 0.111752, Val Acc: 0.773196\n",
      "Epoch 24023 - Train Loss: 0.078791, Train Acc: 0.874359 | Val Loss: 0.111751, Val Acc: 0.773196\n",
      "Epoch 24024 - Train Loss: 0.078790, Train Acc: 0.874359 | Val Loss: 0.111751, Val Acc: 0.773196\n",
      "Epoch 24025 - Train Loss: 0.078788, Train Acc: 0.874359 | Val Loss: 0.111750, Val Acc: 0.773196\n",
      "Epoch 24026 - Train Loss: 0.078786, Train Acc: 0.874359 | Val Loss: 0.111750, Val Acc: 0.773196\n",
      "Epoch 24027 - Train Loss: 0.078785, Train Acc: 0.874359 | Val Loss: 0.111749, Val Acc: 0.773196\n",
      "Epoch 24028 - Train Loss: 0.078783, Train Acc: 0.874359 | Val Loss: 0.111748, Val Acc: 0.773196\n",
      "Epoch 24029 - Train Loss: 0.078781, Train Acc: 0.874359 | Val Loss: 0.111748, Val Acc: 0.773196\n",
      "Epoch 24030 - Train Loss: 0.078780, Train Acc: 0.874359 | Val Loss: 0.111747, Val Acc: 0.773196\n",
      "Epoch 24031 - Train Loss: 0.078778, Train Acc: 0.874359 | Val Loss: 0.111747, Val Acc: 0.773196\n",
      "Epoch 24032 - Train Loss: 0.078776, Train Acc: 0.874359 | Val Loss: 0.111746, Val Acc: 0.773196\n",
      "Epoch 24033 - Train Loss: 0.078775, Train Acc: 0.874359 | Val Loss: 0.111745, Val Acc: 0.773196\n",
      "Epoch 24034 - Train Loss: 0.078773, Train Acc: 0.874359 | Val Loss: 0.111745, Val Acc: 0.773196\n",
      "Epoch 24035 - Train Loss: 0.078771, Train Acc: 0.874359 | Val Loss: 0.111744, Val Acc: 0.773196\n",
      "Epoch 24036 - Train Loss: 0.078770, Train Acc: 0.874359 | Val Loss: 0.111744, Val Acc: 0.773196\n",
      "Epoch 24037 - Train Loss: 0.078768, Train Acc: 0.874359 | Val Loss: 0.111743, Val Acc: 0.773196\n",
      "Epoch 24038 - Train Loss: 0.078766, Train Acc: 0.874359 | Val Loss: 0.111742, Val Acc: 0.773196\n",
      "Epoch 24039 - Train Loss: 0.078765, Train Acc: 0.874359 | Val Loss: 0.111742, Val Acc: 0.773196\n",
      "Epoch 24040 - Train Loss: 0.078763, Train Acc: 0.874359 | Val Loss: 0.111741, Val Acc: 0.773196\n",
      "Epoch 24041 - Train Loss: 0.078761, Train Acc: 0.874359 | Val Loss: 0.111741, Val Acc: 0.773196\n",
      "Epoch 24042 - Train Loss: 0.078760, Train Acc: 0.874359 | Val Loss: 0.111740, Val Acc: 0.773196\n",
      "Epoch 24043 - Train Loss: 0.078758, Train Acc: 0.874359 | Val Loss: 0.111739, Val Acc: 0.773196\n",
      "Epoch 24044 - Train Loss: 0.078756, Train Acc: 0.874359 | Val Loss: 0.111739, Val Acc: 0.773196\n",
      "Epoch 24045 - Train Loss: 0.078755, Train Acc: 0.874359 | Val Loss: 0.111738, Val Acc: 0.773196\n",
      "Epoch 24046 - Train Loss: 0.078753, Train Acc: 0.874359 | Val Loss: 0.111738, Val Acc: 0.773196\n",
      "Epoch 24047 - Train Loss: 0.078751, Train Acc: 0.874359 | Val Loss: 0.111737, Val Acc: 0.773196\n",
      "Epoch 24048 - Train Loss: 0.078750, Train Acc: 0.874359 | Val Loss: 0.111736, Val Acc: 0.773196\n",
      "Epoch 24049 - Train Loss: 0.078748, Train Acc: 0.874359 | Val Loss: 0.111736, Val Acc: 0.773196\n",
      "Epoch 24050 - Train Loss: 0.078746, Train Acc: 0.874359 | Val Loss: 0.111735, Val Acc: 0.773196\n",
      "Epoch 24051 - Train Loss: 0.078745, Train Acc: 0.874359 | Val Loss: 0.111735, Val Acc: 0.773196\n",
      "Epoch 24052 - Train Loss: 0.078743, Train Acc: 0.874359 | Val Loss: 0.111734, Val Acc: 0.773196\n",
      "Epoch 24053 - Train Loss: 0.078741, Train Acc: 0.874359 | Val Loss: 0.111733, Val Acc: 0.773196\n",
      "Epoch 24054 - Train Loss: 0.078740, Train Acc: 0.874359 | Val Loss: 0.111733, Val Acc: 0.773196\n",
      "Epoch 24055 - Train Loss: 0.078738, Train Acc: 0.874359 | Val Loss: 0.111732, Val Acc: 0.773196\n",
      "Epoch 24056 - Train Loss: 0.078736, Train Acc: 0.874359 | Val Loss: 0.111732, Val Acc: 0.773196\n",
      "Epoch 24057 - Train Loss: 0.078734, Train Acc: 0.874359 | Val Loss: 0.111731, Val Acc: 0.773196\n",
      "Epoch 24058 - Train Loss: 0.078733, Train Acc: 0.874359 | Val Loss: 0.111730, Val Acc: 0.773196\n",
      "Epoch 24059 - Train Loss: 0.078731, Train Acc: 0.874359 | Val Loss: 0.111730, Val Acc: 0.773196\n",
      "Epoch 24060 - Train Loss: 0.078729, Train Acc: 0.874359 | Val Loss: 0.111729, Val Acc: 0.773196\n",
      "Epoch 24061 - Train Loss: 0.078728, Train Acc: 0.874359 | Val Loss: 0.111729, Val Acc: 0.773196\n",
      "Epoch 24062 - Train Loss: 0.078726, Train Acc: 0.874359 | Val Loss: 0.111728, Val Acc: 0.773196\n",
      "Epoch 24063 - Train Loss: 0.078724, Train Acc: 0.874359 | Val Loss: 0.111727, Val Acc: 0.773196\n",
      "Epoch 24064 - Train Loss: 0.078723, Train Acc: 0.874359 | Val Loss: 0.111727, Val Acc: 0.773196\n",
      "Epoch 24065 - Train Loss: 0.078721, Train Acc: 0.874359 | Val Loss: 0.111726, Val Acc: 0.773196\n",
      "Epoch 24066 - Train Loss: 0.078719, Train Acc: 0.874359 | Val Loss: 0.111726, Val Acc: 0.773196\n",
      "Epoch 24067 - Train Loss: 0.078718, Train Acc: 0.874359 | Val Loss: 0.111725, Val Acc: 0.773196\n",
      "Epoch 24068 - Train Loss: 0.078716, Train Acc: 0.874359 | Val Loss: 0.111724, Val Acc: 0.773196\n",
      "Epoch 24069 - Train Loss: 0.078714, Train Acc: 0.874359 | Val Loss: 0.111724, Val Acc: 0.773196\n",
      "Epoch 24070 - Train Loss: 0.078713, Train Acc: 0.874359 | Val Loss: 0.111723, Val Acc: 0.773196\n",
      "Epoch 24071 - Train Loss: 0.078711, Train Acc: 0.874359 | Val Loss: 0.111723, Val Acc: 0.773196\n",
      "Epoch 24072 - Train Loss: 0.078709, Train Acc: 0.874359 | Val Loss: 0.111722, Val Acc: 0.773196\n",
      "Epoch 24073 - Train Loss: 0.078708, Train Acc: 0.874359 | Val Loss: 0.111721, Val Acc: 0.773196\n",
      "Epoch 24074 - Train Loss: 0.078706, Train Acc: 0.874359 | Val Loss: 0.111721, Val Acc: 0.773196\n",
      "Epoch 24075 - Train Loss: 0.078704, Train Acc: 0.874359 | Val Loss: 0.111720, Val Acc: 0.773196\n",
      "Epoch 24076 - Train Loss: 0.078703, Train Acc: 0.874359 | Val Loss: 0.111720, Val Acc: 0.773196\n",
      "Epoch 24077 - Train Loss: 0.078701, Train Acc: 0.874359 | Val Loss: 0.111719, Val Acc: 0.773196\n",
      "Epoch 24078 - Train Loss: 0.078699, Train Acc: 0.874359 | Val Loss: 0.111718, Val Acc: 0.773196\n",
      "Epoch 24079 - Train Loss: 0.078698, Train Acc: 0.874359 | Val Loss: 0.111718, Val Acc: 0.773196\n",
      "Epoch 24080 - Train Loss: 0.078696, Train Acc: 0.874359 | Val Loss: 0.111717, Val Acc: 0.773196\n",
      "Epoch 24081 - Train Loss: 0.078694, Train Acc: 0.874359 | Val Loss: 0.111717, Val Acc: 0.773196\n",
      "Epoch 24082 - Train Loss: 0.078693, Train Acc: 0.874359 | Val Loss: 0.111716, Val Acc: 0.773196\n",
      "Epoch 24083 - Train Loss: 0.078691, Train Acc: 0.874359 | Val Loss: 0.111715, Val Acc: 0.773196\n",
      "Epoch 24084 - Train Loss: 0.078689, Train Acc: 0.874359 | Val Loss: 0.111715, Val Acc: 0.773196\n",
      "Epoch 24085 - Train Loss: 0.078688, Train Acc: 0.874359 | Val Loss: 0.111714, Val Acc: 0.773196\n",
      "Epoch 24086 - Train Loss: 0.078686, Train Acc: 0.874359 | Val Loss: 0.111714, Val Acc: 0.773196\n",
      "Epoch 24087 - Train Loss: 0.078684, Train Acc: 0.874359 | Val Loss: 0.111713, Val Acc: 0.773196\n",
      "Epoch 24088 - Train Loss: 0.078683, Train Acc: 0.874359 | Val Loss: 0.111712, Val Acc: 0.773196\n",
      "Epoch 24089 - Train Loss: 0.078681, Train Acc: 0.874359 | Val Loss: 0.111712, Val Acc: 0.773196\n",
      "Epoch 24090 - Train Loss: 0.078679, Train Acc: 0.874359 | Val Loss: 0.111711, Val Acc: 0.773196\n",
      "Epoch 24091 - Train Loss: 0.078678, Train Acc: 0.874359 | Val Loss: 0.111711, Val Acc: 0.773196\n",
      "Epoch 24092 - Train Loss: 0.078676, Train Acc: 0.874359 | Val Loss: 0.111710, Val Acc: 0.773196\n",
      "Epoch 24093 - Train Loss: 0.078674, Train Acc: 0.874359 | Val Loss: 0.111709, Val Acc: 0.773196\n",
      "Epoch 24094 - Train Loss: 0.078673, Train Acc: 0.874359 | Val Loss: 0.111709, Val Acc: 0.773196\n",
      "Epoch 24095 - Train Loss: 0.078671, Train Acc: 0.874359 | Val Loss: 0.111708, Val Acc: 0.773196\n",
      "Epoch 24096 - Train Loss: 0.078669, Train Acc: 0.874359 | Val Loss: 0.111708, Val Acc: 0.773196\n",
      "Epoch 24097 - Train Loss: 0.078668, Train Acc: 0.874359 | Val Loss: 0.111707, Val Acc: 0.773196\n",
      "Epoch 24098 - Train Loss: 0.078666, Train Acc: 0.874359 | Val Loss: 0.111706, Val Acc: 0.773196\n",
      "Epoch 24099 - Train Loss: 0.078664, Train Acc: 0.874359 | Val Loss: 0.111706, Val Acc: 0.773196\n",
      "Epoch 24100 - Train Loss: 0.078663, Train Acc: 0.874359 | Val Loss: 0.111705, Val Acc: 0.773196\n",
      "Epoch 24101 - Train Loss: 0.078661, Train Acc: 0.874359 | Val Loss: 0.111705, Val Acc: 0.773196\n",
      "Epoch 24102 - Train Loss: 0.078659, Train Acc: 0.874359 | Val Loss: 0.111704, Val Acc: 0.773196\n",
      "Epoch 24103 - Train Loss: 0.078658, Train Acc: 0.874359 | Val Loss: 0.111703, Val Acc: 0.773196\n",
      "Epoch 24104 - Train Loss: 0.078656, Train Acc: 0.874359 | Val Loss: 0.111703, Val Acc: 0.773196\n",
      "Epoch 24105 - Train Loss: 0.078654, Train Acc: 0.874359 | Val Loss: 0.111702, Val Acc: 0.773196\n",
      "Epoch 24106 - Train Loss: 0.078653, Train Acc: 0.874359 | Val Loss: 0.111702, Val Acc: 0.773196\n",
      "Epoch 24107 - Train Loss: 0.078651, Train Acc: 0.874359 | Val Loss: 0.111701, Val Acc: 0.773196\n",
      "Epoch 24108 - Train Loss: 0.078649, Train Acc: 0.874359 | Val Loss: 0.111700, Val Acc: 0.773196\n",
      "Epoch 24109 - Train Loss: 0.078648, Train Acc: 0.874359 | Val Loss: 0.111700, Val Acc: 0.773196\n",
      "Epoch 24110 - Train Loss: 0.078646, Train Acc: 0.874359 | Val Loss: 0.111699, Val Acc: 0.773196\n",
      "Epoch 24111 - Train Loss: 0.078644, Train Acc: 0.874359 | Val Loss: 0.111699, Val Acc: 0.773196\n",
      "Epoch 24112 - Train Loss: 0.078643, Train Acc: 0.874359 | Val Loss: 0.111698, Val Acc: 0.773196\n",
      "Epoch 24113 - Train Loss: 0.078641, Train Acc: 0.874359 | Val Loss: 0.111697, Val Acc: 0.773196\n",
      "Epoch 24114 - Train Loss: 0.078639, Train Acc: 0.874359 | Val Loss: 0.111697, Val Acc: 0.773196\n",
      "Epoch 24115 - Train Loss: 0.078638, Train Acc: 0.874359 | Val Loss: 0.111696, Val Acc: 0.773196\n",
      "Epoch 24116 - Train Loss: 0.078636, Train Acc: 0.874359 | Val Loss: 0.111696, Val Acc: 0.773196\n",
      "Epoch 24117 - Train Loss: 0.078634, Train Acc: 0.874359 | Val Loss: 0.111695, Val Acc: 0.773196\n",
      "Epoch 24118 - Train Loss: 0.078633, Train Acc: 0.874359 | Val Loss: 0.111694, Val Acc: 0.773196\n",
      "Epoch 24119 - Train Loss: 0.078631, Train Acc: 0.874359 | Val Loss: 0.111694, Val Acc: 0.773196\n",
      "Epoch 24120 - Train Loss: 0.078629, Train Acc: 0.874359 | Val Loss: 0.111693, Val Acc: 0.773196\n",
      "Epoch 24121 - Train Loss: 0.078628, Train Acc: 0.874359 | Val Loss: 0.111693, Val Acc: 0.773196\n",
      "Epoch 24122 - Train Loss: 0.078626, Train Acc: 0.874359 | Val Loss: 0.111692, Val Acc: 0.773196\n",
      "Epoch 24123 - Train Loss: 0.078624, Train Acc: 0.874359 | Val Loss: 0.111691, Val Acc: 0.773196\n",
      "Epoch 24124 - Train Loss: 0.078623, Train Acc: 0.874359 | Val Loss: 0.111691, Val Acc: 0.773196\n",
      "Epoch 24125 - Train Loss: 0.078621, Train Acc: 0.874359 | Val Loss: 0.111690, Val Acc: 0.773196\n",
      "Epoch 24126 - Train Loss: 0.078620, Train Acc: 0.874359 | Val Loss: 0.111690, Val Acc: 0.773196\n",
      "Epoch 24127 - Train Loss: 0.078618, Train Acc: 0.874359 | Val Loss: 0.111689, Val Acc: 0.773196\n",
      "Epoch 24128 - Train Loss: 0.078616, Train Acc: 0.874359 | Val Loss: 0.111688, Val Acc: 0.773196\n",
      "Epoch 24129 - Train Loss: 0.078615, Train Acc: 0.874359 | Val Loss: 0.111688, Val Acc: 0.773196\n",
      "Epoch 24130 - Train Loss: 0.078613, Train Acc: 0.874359 | Val Loss: 0.111687, Val Acc: 0.773196\n",
      "Epoch 24131 - Train Loss: 0.078611, Train Acc: 0.874359 | Val Loss: 0.111687, Val Acc: 0.773196\n",
      "Epoch 24132 - Train Loss: 0.078610, Train Acc: 0.874359 | Val Loss: 0.111686, Val Acc: 0.773196\n",
      "Epoch 24133 - Train Loss: 0.078608, Train Acc: 0.874359 | Val Loss: 0.111685, Val Acc: 0.773196\n",
      "Epoch 24134 - Train Loss: 0.078606, Train Acc: 0.874359 | Val Loss: 0.111685, Val Acc: 0.773196\n",
      "Epoch 24135 - Train Loss: 0.078605, Train Acc: 0.874359 | Val Loss: 0.111684, Val Acc: 0.773196\n",
      "Epoch 24136 - Train Loss: 0.078603, Train Acc: 0.874359 | Val Loss: 0.111684, Val Acc: 0.773196\n",
      "Epoch 24137 - Train Loss: 0.078601, Train Acc: 0.874359 | Val Loss: 0.111683, Val Acc: 0.773196\n",
      "Epoch 24138 - Train Loss: 0.078600, Train Acc: 0.874359 | Val Loss: 0.111683, Val Acc: 0.773196\n",
      "Epoch 24139 - Train Loss: 0.078598, Train Acc: 0.874359 | Val Loss: 0.111682, Val Acc: 0.773196\n",
      "Epoch 24140 - Train Loss: 0.078596, Train Acc: 0.874359 | Val Loss: 0.111681, Val Acc: 0.773196\n",
      "Epoch 24141 - Train Loss: 0.078595, Train Acc: 0.874359 | Val Loss: 0.111681, Val Acc: 0.773196\n",
      "Epoch 24142 - Train Loss: 0.078593, Train Acc: 0.874359 | Val Loss: 0.111680, Val Acc: 0.773196\n",
      "Epoch 24143 - Train Loss: 0.078591, Train Acc: 0.874359 | Val Loss: 0.111680, Val Acc: 0.773196\n",
      "Epoch 24144 - Train Loss: 0.078590, Train Acc: 0.874359 | Val Loss: 0.111679, Val Acc: 0.773196\n",
      "Epoch 24145 - Train Loss: 0.078588, Train Acc: 0.874359 | Val Loss: 0.111678, Val Acc: 0.773196\n",
      "Epoch 24146 - Train Loss: 0.078586, Train Acc: 0.874359 | Val Loss: 0.111678, Val Acc: 0.773196\n",
      "Epoch 24147 - Train Loss: 0.078585, Train Acc: 0.874359 | Val Loss: 0.111677, Val Acc: 0.773196\n",
      "Epoch 24148 - Train Loss: 0.078583, Train Acc: 0.874359 | Val Loss: 0.111677, Val Acc: 0.773196\n",
      "Epoch 24149 - Train Loss: 0.078581, Train Acc: 0.874359 | Val Loss: 0.111676, Val Acc: 0.773196\n",
      "Epoch 24150 - Train Loss: 0.078580, Train Acc: 0.874359 | Val Loss: 0.111675, Val Acc: 0.773196\n",
      "Epoch 24151 - Train Loss: 0.078578, Train Acc: 0.874359 | Val Loss: 0.111675, Val Acc: 0.773196\n",
      "Epoch 24152 - Train Loss: 0.078576, Train Acc: 0.874359 | Val Loss: 0.111674, Val Acc: 0.773196\n",
      "Epoch 24153 - Train Loss: 0.078575, Train Acc: 0.874359 | Val Loss: 0.111674, Val Acc: 0.773196\n",
      "Epoch 24154 - Train Loss: 0.078573, Train Acc: 0.874359 | Val Loss: 0.111673, Val Acc: 0.773196\n",
      "Epoch 24155 - Train Loss: 0.078571, Train Acc: 0.874359 | Val Loss: 0.111672, Val Acc: 0.773196\n",
      "Epoch 24156 - Train Loss: 0.078570, Train Acc: 0.874359 | Val Loss: 0.111672, Val Acc: 0.773196\n",
      "Epoch 24157 - Train Loss: 0.078568, Train Acc: 0.874359 | Val Loss: 0.111671, Val Acc: 0.773196\n",
      "Epoch 24158 - Train Loss: 0.078566, Train Acc: 0.874359 | Val Loss: 0.111671, Val Acc: 0.773196\n",
      "Epoch 24159 - Train Loss: 0.078565, Train Acc: 0.874359 | Val Loss: 0.111670, Val Acc: 0.773196\n",
      "Epoch 24160 - Train Loss: 0.078563, Train Acc: 0.874359 | Val Loss: 0.111669, Val Acc: 0.773196\n",
      "Epoch 24161 - Train Loss: 0.078561, Train Acc: 0.874359 | Val Loss: 0.111669, Val Acc: 0.773196\n",
      "Epoch 24162 - Train Loss: 0.078560, Train Acc: 0.874359 | Val Loss: 0.111668, Val Acc: 0.773196\n",
      "Epoch 24163 - Train Loss: 0.078558, Train Acc: 0.874359 | Val Loss: 0.111668, Val Acc: 0.773196\n",
      "Epoch 24164 - Train Loss: 0.078556, Train Acc: 0.874359 | Val Loss: 0.111667, Val Acc: 0.773196\n",
      "Epoch 24165 - Train Loss: 0.078555, Train Acc: 0.874359 | Val Loss: 0.111666, Val Acc: 0.773196\n",
      "Epoch 24166 - Train Loss: 0.078553, Train Acc: 0.874359 | Val Loss: 0.111666, Val Acc: 0.773196\n",
      "Epoch 24167 - Train Loss: 0.078551, Train Acc: 0.874359 | Val Loss: 0.111665, Val Acc: 0.773196\n",
      "Epoch 24168 - Train Loss: 0.078550, Train Acc: 0.874359 | Val Loss: 0.111665, Val Acc: 0.773196\n",
      "Epoch 24169 - Train Loss: 0.078548, Train Acc: 0.874359 | Val Loss: 0.111664, Val Acc: 0.773196\n",
      "Epoch 24170 - Train Loss: 0.078546, Train Acc: 0.874359 | Val Loss: 0.111664, Val Acc: 0.773196\n",
      "Epoch 24171 - Train Loss: 0.078545, Train Acc: 0.874359 | Val Loss: 0.111663, Val Acc: 0.773196\n",
      "Epoch 24172 - Train Loss: 0.078543, Train Acc: 0.874359 | Val Loss: 0.111662, Val Acc: 0.773196\n",
      "Epoch 24173 - Train Loss: 0.078541, Train Acc: 0.874359 | Val Loss: 0.111662, Val Acc: 0.773196\n",
      "Epoch 24174 - Train Loss: 0.078540, Train Acc: 0.874359 | Val Loss: 0.111661, Val Acc: 0.773196\n",
      "Epoch 24175 - Train Loss: 0.078538, Train Acc: 0.874359 | Val Loss: 0.111661, Val Acc: 0.773196\n",
      "Epoch 24176 - Train Loss: 0.078536, Train Acc: 0.874359 | Val Loss: 0.111660, Val Acc: 0.773196\n",
      "Epoch 24177 - Train Loss: 0.078535, Train Acc: 0.874359 | Val Loss: 0.111659, Val Acc: 0.773196\n",
      "Epoch 24178 - Train Loss: 0.078533, Train Acc: 0.874359 | Val Loss: 0.111659, Val Acc: 0.773196\n",
      "Epoch 24179 - Train Loss: 0.078532, Train Acc: 0.874359 | Val Loss: 0.111658, Val Acc: 0.773196\n",
      "Epoch 24180 - Train Loss: 0.078530, Train Acc: 0.874359 | Val Loss: 0.111658, Val Acc: 0.773196\n",
      "Epoch 24181 - Train Loss: 0.078528, Train Acc: 0.874359 | Val Loss: 0.111657, Val Acc: 0.773196\n",
      "Epoch 24182 - Train Loss: 0.078527, Train Acc: 0.874359 | Val Loss: 0.111656, Val Acc: 0.773196\n",
      "Epoch 24183 - Train Loss: 0.078525, Train Acc: 0.874359 | Val Loss: 0.111656, Val Acc: 0.773196\n",
      "Epoch 24184 - Train Loss: 0.078523, Train Acc: 0.874359 | Val Loss: 0.111655, Val Acc: 0.773196\n",
      "Epoch 24185 - Train Loss: 0.078522, Train Acc: 0.874359 | Val Loss: 0.111655, Val Acc: 0.773196\n",
      "Epoch 24186 - Train Loss: 0.078520, Train Acc: 0.874359 | Val Loss: 0.111654, Val Acc: 0.773196\n",
      "Epoch 24187 - Train Loss: 0.078518, Train Acc: 0.874359 | Val Loss: 0.111653, Val Acc: 0.773196\n",
      "Epoch 24188 - Train Loss: 0.078517, Train Acc: 0.874359 | Val Loss: 0.111653, Val Acc: 0.773196\n",
      "Epoch 24189 - Train Loss: 0.078515, Train Acc: 0.874359 | Val Loss: 0.111652, Val Acc: 0.773196\n",
      "Epoch 24190 - Train Loss: 0.078513, Train Acc: 0.874359 | Val Loss: 0.111652, Val Acc: 0.773196\n",
      "Epoch 24191 - Train Loss: 0.078512, Train Acc: 0.874359 | Val Loss: 0.111651, Val Acc: 0.773196\n",
      "Epoch 24192 - Train Loss: 0.078510, Train Acc: 0.874359 | Val Loss: 0.111651, Val Acc: 0.773196\n",
      "Epoch 24193 - Train Loss: 0.078508, Train Acc: 0.874359 | Val Loss: 0.111650, Val Acc: 0.773196\n",
      "Epoch 24194 - Train Loss: 0.078507, Train Acc: 0.874359 | Val Loss: 0.111649, Val Acc: 0.773196\n",
      "Epoch 24195 - Train Loss: 0.078505, Train Acc: 0.874359 | Val Loss: 0.111649, Val Acc: 0.773196\n",
      "Epoch 24196 - Train Loss: 0.078503, Train Acc: 0.874359 | Val Loss: 0.111648, Val Acc: 0.773196\n",
      "Epoch 24197 - Train Loss: 0.078502, Train Acc: 0.874359 | Val Loss: 0.111648, Val Acc: 0.773196\n",
      "Epoch 24198 - Train Loss: 0.078500, Train Acc: 0.874359 | Val Loss: 0.111647, Val Acc: 0.773196\n",
      "Epoch 24199 - Train Loss: 0.078498, Train Acc: 0.874359 | Val Loss: 0.111646, Val Acc: 0.773196\n",
      "Epoch 24200 - Train Loss: 0.078497, Train Acc: 0.874359 | Val Loss: 0.111646, Val Acc: 0.773196\n",
      "Epoch 24201 - Train Loss: 0.078495, Train Acc: 0.874359 | Val Loss: 0.111645, Val Acc: 0.773196\n",
      "Epoch 24202 - Train Loss: 0.078493, Train Acc: 0.874359 | Val Loss: 0.111645, Val Acc: 0.773196\n",
      "Epoch 24203 - Train Loss: 0.078492, Train Acc: 0.874359 | Val Loss: 0.111644, Val Acc: 0.773196\n",
      "Epoch 24204 - Train Loss: 0.078490, Train Acc: 0.874359 | Val Loss: 0.111643, Val Acc: 0.773196\n",
      "Epoch 24205 - Train Loss: 0.078488, Train Acc: 0.874359 | Val Loss: 0.111643, Val Acc: 0.773196\n",
      "Epoch 24206 - Train Loss: 0.078487, Train Acc: 0.874359 | Val Loss: 0.111642, Val Acc: 0.773196\n",
      "Epoch 24207 - Train Loss: 0.078485, Train Acc: 0.874359 | Val Loss: 0.111642, Val Acc: 0.773196\n",
      "Epoch 24208 - Train Loss: 0.078483, Train Acc: 0.874359 | Val Loss: 0.111641, Val Acc: 0.773196\n",
      "Epoch 24209 - Train Loss: 0.078482, Train Acc: 0.874359 | Val Loss: 0.111641, Val Acc: 0.773196\n",
      "Epoch 24210 - Train Loss: 0.078480, Train Acc: 0.874359 | Val Loss: 0.111640, Val Acc: 0.773196\n",
      "Epoch 24211 - Train Loss: 0.078479, Train Acc: 0.874359 | Val Loss: 0.111639, Val Acc: 0.773196\n",
      "Epoch 24212 - Train Loss: 0.078477, Train Acc: 0.874359 | Val Loss: 0.111639, Val Acc: 0.773196\n",
      "Epoch 24213 - Train Loss: 0.078475, Train Acc: 0.874359 | Val Loss: 0.111638, Val Acc: 0.773196\n",
      "Epoch 24214 - Train Loss: 0.078474, Train Acc: 0.874359 | Val Loss: 0.111638, Val Acc: 0.773196\n",
      "Epoch 24215 - Train Loss: 0.078472, Train Acc: 0.874359 | Val Loss: 0.111637, Val Acc: 0.773196\n",
      "Epoch 24216 - Train Loss: 0.078470, Train Acc: 0.874359 | Val Loss: 0.111636, Val Acc: 0.773196\n",
      "Epoch 24217 - Train Loss: 0.078469, Train Acc: 0.874359 | Val Loss: 0.111636, Val Acc: 0.773196\n",
      "Epoch 24218 - Train Loss: 0.078467, Train Acc: 0.874359 | Val Loss: 0.111635, Val Acc: 0.773196\n",
      "Epoch 24219 - Train Loss: 0.078465, Train Acc: 0.874359 | Val Loss: 0.111635, Val Acc: 0.773196\n",
      "Epoch 24220 - Train Loss: 0.078464, Train Acc: 0.874359 | Val Loss: 0.111634, Val Acc: 0.773196\n",
      "Epoch 24221 - Train Loss: 0.078462, Train Acc: 0.874359 | Val Loss: 0.111633, Val Acc: 0.773196\n",
      "Epoch 24222 - Train Loss: 0.078460, Train Acc: 0.874359 | Val Loss: 0.111633, Val Acc: 0.773196\n",
      "Epoch 24223 - Train Loss: 0.078459, Train Acc: 0.874359 | Val Loss: 0.111632, Val Acc: 0.773196\n",
      "Epoch 24224 - Train Loss: 0.078457, Train Acc: 0.874359 | Val Loss: 0.111632, Val Acc: 0.773196\n",
      "Epoch 24225 - Train Loss: 0.078455, Train Acc: 0.874359 | Val Loss: 0.111631, Val Acc: 0.773196\n",
      "Epoch 24226 - Train Loss: 0.078454, Train Acc: 0.874359 | Val Loss: 0.111631, Val Acc: 0.773196\n",
      "Epoch 24227 - Train Loss: 0.078452, Train Acc: 0.874359 | Val Loss: 0.111630, Val Acc: 0.773196\n",
      "Epoch 24228 - Train Loss: 0.078450, Train Acc: 0.874359 | Val Loss: 0.111629, Val Acc: 0.773196\n",
      "Epoch 24229 - Train Loss: 0.078449, Train Acc: 0.874359 | Val Loss: 0.111629, Val Acc: 0.773196\n",
      "Epoch 24230 - Train Loss: 0.078447, Train Acc: 0.874359 | Val Loss: 0.111628, Val Acc: 0.773196\n",
      "Epoch 24231 - Train Loss: 0.078445, Train Acc: 0.874359 | Val Loss: 0.111628, Val Acc: 0.773196\n",
      "Epoch 24232 - Train Loss: 0.078444, Train Acc: 0.874359 | Val Loss: 0.111627, Val Acc: 0.773196\n",
      "Epoch 24233 - Train Loss: 0.078442, Train Acc: 0.874359 | Val Loss: 0.111626, Val Acc: 0.773196\n",
      "Epoch 24234 - Train Loss: 0.078441, Train Acc: 0.874359 | Val Loss: 0.111626, Val Acc: 0.773196\n",
      "Epoch 24235 - Train Loss: 0.078439, Train Acc: 0.874359 | Val Loss: 0.111625, Val Acc: 0.773196\n",
      "Epoch 24236 - Train Loss: 0.078437, Train Acc: 0.874359 | Val Loss: 0.111625, Val Acc: 0.773196\n",
      "Epoch 24237 - Train Loss: 0.078436, Train Acc: 0.874359 | Val Loss: 0.111624, Val Acc: 0.773196\n",
      "Epoch 24238 - Train Loss: 0.078434, Train Acc: 0.874359 | Val Loss: 0.111624, Val Acc: 0.773196\n",
      "Epoch 24239 - Train Loss: 0.078432, Train Acc: 0.874359 | Val Loss: 0.111623, Val Acc: 0.773196\n",
      "Epoch 24240 - Train Loss: 0.078431, Train Acc: 0.874359 | Val Loss: 0.111622, Val Acc: 0.773196\n",
      "Epoch 24241 - Train Loss: 0.078429, Train Acc: 0.874359 | Val Loss: 0.111622, Val Acc: 0.773196\n",
      "Epoch 24242 - Train Loss: 0.078427, Train Acc: 0.874359 | Val Loss: 0.111621, Val Acc: 0.773196\n",
      "Epoch 24243 - Train Loss: 0.078426, Train Acc: 0.874359 | Val Loss: 0.111621, Val Acc: 0.773196\n",
      "Epoch 24244 - Train Loss: 0.078424, Train Acc: 0.874359 | Val Loss: 0.111620, Val Acc: 0.773196\n",
      "Epoch 24245 - Train Loss: 0.078422, Train Acc: 0.874359 | Val Loss: 0.111619, Val Acc: 0.773196\n",
      "Epoch 24246 - Train Loss: 0.078421, Train Acc: 0.874359 | Val Loss: 0.111619, Val Acc: 0.773196\n",
      "Epoch 24247 - Train Loss: 0.078419, Train Acc: 0.874359 | Val Loss: 0.111618, Val Acc: 0.773196\n",
      "Epoch 24248 - Train Loss: 0.078417, Train Acc: 0.874359 | Val Loss: 0.111618, Val Acc: 0.773196\n",
      "Epoch 24249 - Train Loss: 0.078416, Train Acc: 0.874359 | Val Loss: 0.111617, Val Acc: 0.773196\n",
      "Epoch 24250 - Train Loss: 0.078414, Train Acc: 0.874359 | Val Loss: 0.111617, Val Acc: 0.773196\n",
      "Epoch 24251 - Train Loss: 0.078412, Train Acc: 0.874359 | Val Loss: 0.111616, Val Acc: 0.773196\n",
      "Epoch 24252 - Train Loss: 0.078411, Train Acc: 0.874359 | Val Loss: 0.111615, Val Acc: 0.773196\n",
      "Epoch 24253 - Train Loss: 0.078409, Train Acc: 0.874359 | Val Loss: 0.111615, Val Acc: 0.773196\n",
      "Epoch 24254 - Train Loss: 0.078407, Train Acc: 0.874359 | Val Loss: 0.111614, Val Acc: 0.773196\n",
      "Epoch 24255 - Train Loss: 0.078406, Train Acc: 0.874359 | Val Loss: 0.111614, Val Acc: 0.773196\n",
      "Epoch 24256 - Train Loss: 0.078404, Train Acc: 0.874359 | Val Loss: 0.111613, Val Acc: 0.773196\n",
      "Epoch 24257 - Train Loss: 0.078403, Train Acc: 0.874359 | Val Loss: 0.111612, Val Acc: 0.773196\n",
      "Epoch 24258 - Train Loss: 0.078401, Train Acc: 0.874359 | Val Loss: 0.111612, Val Acc: 0.773196\n",
      "Epoch 24259 - Train Loss: 0.078399, Train Acc: 0.874359 | Val Loss: 0.111611, Val Acc: 0.773196\n",
      "Epoch 24260 - Train Loss: 0.078398, Train Acc: 0.874359 | Val Loss: 0.111611, Val Acc: 0.773196\n",
      "Epoch 24261 - Train Loss: 0.078396, Train Acc: 0.874359 | Val Loss: 0.111610, Val Acc: 0.773196\n",
      "Epoch 24262 - Train Loss: 0.078394, Train Acc: 0.874359 | Val Loss: 0.111609, Val Acc: 0.773196\n",
      "Epoch 24263 - Train Loss: 0.078393, Train Acc: 0.874359 | Val Loss: 0.111609, Val Acc: 0.773196\n",
      "Epoch 24264 - Train Loss: 0.078391, Train Acc: 0.874359 | Val Loss: 0.111608, Val Acc: 0.773196\n",
      "Epoch 24265 - Train Loss: 0.078389, Train Acc: 0.874359 | Val Loss: 0.111608, Val Acc: 0.773196\n",
      "Epoch 24266 - Train Loss: 0.078388, Train Acc: 0.874359 | Val Loss: 0.111607, Val Acc: 0.773196\n",
      "Epoch 24267 - Train Loss: 0.078386, Train Acc: 0.874359 | Val Loss: 0.111607, Val Acc: 0.773196\n",
      "Epoch 24268 - Train Loss: 0.078384, Train Acc: 0.874359 | Val Loss: 0.111606, Val Acc: 0.773196\n",
      "Epoch 24269 - Train Loss: 0.078383, Train Acc: 0.874359 | Val Loss: 0.111605, Val Acc: 0.773196\n",
      "Epoch 24270 - Train Loss: 0.078381, Train Acc: 0.874359 | Val Loss: 0.111605, Val Acc: 0.773196\n",
      "Epoch 24271 - Train Loss: 0.078379, Train Acc: 0.874359 | Val Loss: 0.111604, Val Acc: 0.773196\n",
      "Epoch 24272 - Train Loss: 0.078378, Train Acc: 0.874359 | Val Loss: 0.111604, Val Acc: 0.773196\n",
      "Epoch 24273 - Train Loss: 0.078376, Train Acc: 0.874359 | Val Loss: 0.111603, Val Acc: 0.773196\n",
      "Epoch 24274 - Train Loss: 0.078375, Train Acc: 0.874359 | Val Loss: 0.111602, Val Acc: 0.773196\n",
      "Epoch 24275 - Train Loss: 0.078373, Train Acc: 0.874359 | Val Loss: 0.111602, Val Acc: 0.773196\n",
      "Epoch 24276 - Train Loss: 0.078371, Train Acc: 0.874359 | Val Loss: 0.111601, Val Acc: 0.773196\n",
      "Epoch 24277 - Train Loss: 0.078370, Train Acc: 0.874359 | Val Loss: 0.111601, Val Acc: 0.773196\n",
      "Epoch 24278 - Train Loss: 0.078368, Train Acc: 0.874359 | Val Loss: 0.111600, Val Acc: 0.773196\n",
      "Epoch 24279 - Train Loss: 0.078366, Train Acc: 0.874359 | Val Loss: 0.111600, Val Acc: 0.773196\n",
      "Epoch 24280 - Train Loss: 0.078365, Train Acc: 0.874359 | Val Loss: 0.111599, Val Acc: 0.773196\n",
      "Epoch 24281 - Train Loss: 0.078363, Train Acc: 0.874359 | Val Loss: 0.111598, Val Acc: 0.773196\n",
      "Epoch 24282 - Train Loss: 0.078361, Train Acc: 0.874359 | Val Loss: 0.111598, Val Acc: 0.773196\n",
      "Epoch 24283 - Train Loss: 0.078360, Train Acc: 0.874359 | Val Loss: 0.111597, Val Acc: 0.773196\n",
      "Epoch 24284 - Train Loss: 0.078358, Train Acc: 0.874359 | Val Loss: 0.111597, Val Acc: 0.773196\n",
      "Epoch 24285 - Train Loss: 0.078356, Train Acc: 0.874359 | Val Loss: 0.111596, Val Acc: 0.773196\n",
      "Epoch 24286 - Train Loss: 0.078355, Train Acc: 0.874359 | Val Loss: 0.111596, Val Acc: 0.773196\n",
      "Epoch 24287 - Train Loss: 0.078353, Train Acc: 0.874359 | Val Loss: 0.111595, Val Acc: 0.773196\n",
      "Epoch 24288 - Train Loss: 0.078351, Train Acc: 0.874359 | Val Loss: 0.111594, Val Acc: 0.773196\n",
      "Epoch 24289 - Train Loss: 0.078350, Train Acc: 0.874359 | Val Loss: 0.111594, Val Acc: 0.773196\n",
      "Epoch 24290 - Train Loss: 0.078348, Train Acc: 0.874359 | Val Loss: 0.111593, Val Acc: 0.773196\n",
      "Epoch 24291 - Train Loss: 0.078347, Train Acc: 0.874359 | Val Loss: 0.111593, Val Acc: 0.773196\n",
      "Epoch 24292 - Train Loss: 0.078345, Train Acc: 0.874359 | Val Loss: 0.111592, Val Acc: 0.773196\n",
      "Epoch 24293 - Train Loss: 0.078343, Train Acc: 0.874359 | Val Loss: 0.111591, Val Acc: 0.773196\n",
      "Epoch 24294 - Train Loss: 0.078342, Train Acc: 0.874359 | Val Loss: 0.111591, Val Acc: 0.773196\n",
      "Epoch 24295 - Train Loss: 0.078340, Train Acc: 0.874359 | Val Loss: 0.111590, Val Acc: 0.773196\n",
      "Epoch 24296 - Train Loss: 0.078338, Train Acc: 0.874359 | Val Loss: 0.111590, Val Acc: 0.773196\n",
      "Epoch 24297 - Train Loss: 0.078337, Train Acc: 0.874359 | Val Loss: 0.111589, Val Acc: 0.773196\n",
      "Epoch 24298 - Train Loss: 0.078335, Train Acc: 0.874359 | Val Loss: 0.111589, Val Acc: 0.773196\n",
      "Epoch 24299 - Train Loss: 0.078333, Train Acc: 0.874359 | Val Loss: 0.111588, Val Acc: 0.773196\n",
      "Epoch 24300 - Train Loss: 0.078332, Train Acc: 0.874359 | Val Loss: 0.111587, Val Acc: 0.773196\n",
      "Epoch 24301 - Train Loss: 0.078330, Train Acc: 0.874359 | Val Loss: 0.111587, Val Acc: 0.773196\n",
      "Epoch 24302 - Train Loss: 0.078328, Train Acc: 0.874359 | Val Loss: 0.111586, Val Acc: 0.773196\n",
      "Epoch 24303 - Train Loss: 0.078327, Train Acc: 0.874359 | Val Loss: 0.111586, Val Acc: 0.773196\n",
      "Epoch 24304 - Train Loss: 0.078325, Train Acc: 0.874359 | Val Loss: 0.111585, Val Acc: 0.773196\n",
      "Epoch 24305 - Train Loss: 0.078323, Train Acc: 0.874359 | Val Loss: 0.111584, Val Acc: 0.773196\n",
      "Epoch 24306 - Train Loss: 0.078322, Train Acc: 0.874359 | Val Loss: 0.111584, Val Acc: 0.773196\n",
      "Epoch 24307 - Train Loss: 0.078320, Train Acc: 0.874359 | Val Loss: 0.111583, Val Acc: 0.773196\n",
      "Epoch 24308 - Train Loss: 0.078319, Train Acc: 0.874359 | Val Loss: 0.111583, Val Acc: 0.773196\n",
      "Epoch 24309 - Train Loss: 0.078317, Train Acc: 0.874359 | Val Loss: 0.111582, Val Acc: 0.773196\n",
      "Epoch 24310 - Train Loss: 0.078315, Train Acc: 0.874359 | Val Loss: 0.111582, Val Acc: 0.773196\n",
      "Epoch 24311 - Train Loss: 0.078314, Train Acc: 0.874359 | Val Loss: 0.111581, Val Acc: 0.773196\n",
      "Epoch 24312 - Train Loss: 0.078312, Train Acc: 0.874359 | Val Loss: 0.111580, Val Acc: 0.773196\n",
      "Epoch 24313 - Train Loss: 0.078310, Train Acc: 0.874359 | Val Loss: 0.111580, Val Acc: 0.773196\n",
      "Epoch 24314 - Train Loss: 0.078309, Train Acc: 0.874359 | Val Loss: 0.111579, Val Acc: 0.773196\n",
      "Epoch 24315 - Train Loss: 0.078307, Train Acc: 0.874359 | Val Loss: 0.111579, Val Acc: 0.773196\n",
      "Epoch 24316 - Train Loss: 0.078305, Train Acc: 0.874359 | Val Loss: 0.111578, Val Acc: 0.773196\n",
      "Epoch 24317 - Train Loss: 0.078304, Train Acc: 0.874359 | Val Loss: 0.111578, Val Acc: 0.773196\n",
      "Epoch 24318 - Train Loss: 0.078302, Train Acc: 0.874359 | Val Loss: 0.111577, Val Acc: 0.773196\n",
      "Epoch 24319 - Train Loss: 0.078300, Train Acc: 0.874359 | Val Loss: 0.111576, Val Acc: 0.773196\n",
      "Epoch 24320 - Train Loss: 0.078299, Train Acc: 0.874359 | Val Loss: 0.111576, Val Acc: 0.773196\n",
      "Epoch 24321 - Train Loss: 0.078297, Train Acc: 0.874359 | Val Loss: 0.111575, Val Acc: 0.773196\n",
      "Epoch 24322 - Train Loss: 0.078296, Train Acc: 0.874359 | Val Loss: 0.111575, Val Acc: 0.773196\n",
      "Epoch 24323 - Train Loss: 0.078294, Train Acc: 0.874359 | Val Loss: 0.111574, Val Acc: 0.773196\n",
      "Epoch 24324 - Train Loss: 0.078292, Train Acc: 0.874359 | Val Loss: 0.111573, Val Acc: 0.773196\n",
      "Epoch 24325 - Train Loss: 0.078291, Train Acc: 0.874359 | Val Loss: 0.111573, Val Acc: 0.773196\n",
      "Epoch 24326 - Train Loss: 0.078289, Train Acc: 0.874359 | Val Loss: 0.111572, Val Acc: 0.773196\n",
      "Epoch 24327 - Train Loss: 0.078287, Train Acc: 0.874359 | Val Loss: 0.111572, Val Acc: 0.773196\n",
      "Epoch 24328 - Train Loss: 0.078286, Train Acc: 0.874359 | Val Loss: 0.111571, Val Acc: 0.773196\n",
      "Epoch 24329 - Train Loss: 0.078284, Train Acc: 0.874359 | Val Loss: 0.111571, Val Acc: 0.773196\n",
      "Epoch 24330 - Train Loss: 0.078282, Train Acc: 0.874359 | Val Loss: 0.111570, Val Acc: 0.773196\n",
      "Epoch 24331 - Train Loss: 0.078281, Train Acc: 0.874359 | Val Loss: 0.111569, Val Acc: 0.773196\n",
      "Epoch 24332 - Train Loss: 0.078279, Train Acc: 0.874359 | Val Loss: 0.111569, Val Acc: 0.773196\n",
      "Epoch 24333 - Train Loss: 0.078277, Train Acc: 0.874359 | Val Loss: 0.111568, Val Acc: 0.773196\n",
      "Epoch 24334 - Train Loss: 0.078276, Train Acc: 0.874359 | Val Loss: 0.111568, Val Acc: 0.773196\n",
      "Epoch 24335 - Train Loss: 0.078274, Train Acc: 0.874359 | Val Loss: 0.111567, Val Acc: 0.773196\n",
      "Epoch 24336 - Train Loss: 0.078273, Train Acc: 0.874359 | Val Loss: 0.111567, Val Acc: 0.773196\n",
      "Epoch 24337 - Train Loss: 0.078271, Train Acc: 0.874359 | Val Loss: 0.111566, Val Acc: 0.773196\n",
      "Epoch 24338 - Train Loss: 0.078269, Train Acc: 0.874359 | Val Loss: 0.111565, Val Acc: 0.773196\n",
      "Epoch 24339 - Train Loss: 0.078268, Train Acc: 0.874359 | Val Loss: 0.111565, Val Acc: 0.773196\n",
      "Epoch 24340 - Train Loss: 0.078266, Train Acc: 0.874359 | Val Loss: 0.111564, Val Acc: 0.773196\n",
      "Epoch 24341 - Train Loss: 0.078264, Train Acc: 0.874359 | Val Loss: 0.111564, Val Acc: 0.773196\n",
      "Epoch 24342 - Train Loss: 0.078263, Train Acc: 0.874359 | Val Loss: 0.111563, Val Acc: 0.773196\n",
      "Epoch 24343 - Train Loss: 0.078261, Train Acc: 0.874359 | Val Loss: 0.111562, Val Acc: 0.773196\n",
      "Epoch 24344 - Train Loss: 0.078259, Train Acc: 0.874359 | Val Loss: 0.111562, Val Acc: 0.773196\n",
      "Epoch 24345 - Train Loss: 0.078258, Train Acc: 0.874359 | Val Loss: 0.111561, Val Acc: 0.773196\n",
      "Epoch 24346 - Train Loss: 0.078256, Train Acc: 0.874359 | Val Loss: 0.111561, Val Acc: 0.773196\n",
      "Epoch 24347 - Train Loss: 0.078254, Train Acc: 0.874359 | Val Loss: 0.111560, Val Acc: 0.773196\n",
      "Epoch 24348 - Train Loss: 0.078253, Train Acc: 0.874359 | Val Loss: 0.111560, Val Acc: 0.773196\n",
      "Epoch 24349 - Train Loss: 0.078251, Train Acc: 0.874359 | Val Loss: 0.111559, Val Acc: 0.773196\n",
      "Epoch 24350 - Train Loss: 0.078250, Train Acc: 0.874359 | Val Loss: 0.111558, Val Acc: 0.773196\n",
      "Epoch 24351 - Train Loss: 0.078248, Train Acc: 0.874359 | Val Loss: 0.111558, Val Acc: 0.773196\n",
      "Epoch 24352 - Train Loss: 0.078246, Train Acc: 0.874359 | Val Loss: 0.111557, Val Acc: 0.773196\n",
      "Epoch 24353 - Train Loss: 0.078245, Train Acc: 0.874359 | Val Loss: 0.111557, Val Acc: 0.773196\n",
      "Epoch 24354 - Train Loss: 0.078243, Train Acc: 0.874359 | Val Loss: 0.111556, Val Acc: 0.773196\n",
      "Epoch 24355 - Train Loss: 0.078241, Train Acc: 0.874359 | Val Loss: 0.111556, Val Acc: 0.773196\n",
      "Epoch 24356 - Train Loss: 0.078240, Train Acc: 0.874359 | Val Loss: 0.111555, Val Acc: 0.773196\n",
      "Epoch 24357 - Train Loss: 0.078238, Train Acc: 0.874359 | Val Loss: 0.111554, Val Acc: 0.773196\n",
      "Epoch 24358 - Train Loss: 0.078236, Train Acc: 0.874359 | Val Loss: 0.111554, Val Acc: 0.773196\n",
      "Epoch 24359 - Train Loss: 0.078235, Train Acc: 0.874359 | Val Loss: 0.111553, Val Acc: 0.773196\n",
      "Epoch 24360 - Train Loss: 0.078233, Train Acc: 0.874359 | Val Loss: 0.111553, Val Acc: 0.773196\n",
      "Epoch 24361 - Train Loss: 0.078232, Train Acc: 0.874359 | Val Loss: 0.111552, Val Acc: 0.773196\n",
      "Epoch 24362 - Train Loss: 0.078230, Train Acc: 0.874359 | Val Loss: 0.111552, Val Acc: 0.773196\n",
      "Epoch 24363 - Train Loss: 0.078228, Train Acc: 0.874359 | Val Loss: 0.111551, Val Acc: 0.773196\n",
      "Epoch 24364 - Train Loss: 0.078227, Train Acc: 0.874359 | Val Loss: 0.111550, Val Acc: 0.773196\n",
      "Epoch 24365 - Train Loss: 0.078225, Train Acc: 0.874359 | Val Loss: 0.111550, Val Acc: 0.773196\n",
      "Epoch 24366 - Train Loss: 0.078223, Train Acc: 0.874359 | Val Loss: 0.111549, Val Acc: 0.773196\n",
      "Epoch 24367 - Train Loss: 0.078222, Train Acc: 0.874359 | Val Loss: 0.111549, Val Acc: 0.773196\n",
      "Epoch 24368 - Train Loss: 0.078220, Train Acc: 0.874359 | Val Loss: 0.111548, Val Acc: 0.773196\n",
      "Epoch 24369 - Train Loss: 0.078218, Train Acc: 0.874359 | Val Loss: 0.111548, Val Acc: 0.773196\n",
      "Epoch 24370 - Train Loss: 0.078217, Train Acc: 0.874359 | Val Loss: 0.111547, Val Acc: 0.773196\n",
      "Epoch 24371 - Train Loss: 0.078215, Train Acc: 0.874359 | Val Loss: 0.111546, Val Acc: 0.773196\n",
      "Epoch 24372 - Train Loss: 0.078214, Train Acc: 0.874359 | Val Loss: 0.111546, Val Acc: 0.773196\n",
      "Epoch 24373 - Train Loss: 0.078212, Train Acc: 0.874359 | Val Loss: 0.111545, Val Acc: 0.773196\n",
      "Epoch 24374 - Train Loss: 0.078210, Train Acc: 0.874359 | Val Loss: 0.111545, Val Acc: 0.773196\n",
      "Epoch 24375 - Train Loss: 0.078209, Train Acc: 0.874359 | Val Loss: 0.111544, Val Acc: 0.773196\n",
      "Epoch 24376 - Train Loss: 0.078207, Train Acc: 0.874359 | Val Loss: 0.111544, Val Acc: 0.773196\n",
      "Epoch 24377 - Train Loss: 0.078205, Train Acc: 0.874359 | Val Loss: 0.111543, Val Acc: 0.773196\n",
      "Epoch 24378 - Train Loss: 0.078204, Train Acc: 0.874359 | Val Loss: 0.111542, Val Acc: 0.773196\n",
      "Epoch 24379 - Train Loss: 0.078202, Train Acc: 0.874359 | Val Loss: 0.111542, Val Acc: 0.773196\n",
      "Epoch 24380 - Train Loss: 0.078200, Train Acc: 0.874359 | Val Loss: 0.111541, Val Acc: 0.773196\n",
      "Epoch 24381 - Train Loss: 0.078199, Train Acc: 0.874359 | Val Loss: 0.111541, Val Acc: 0.773196\n",
      "Epoch 24382 - Train Loss: 0.078197, Train Acc: 0.874359 | Val Loss: 0.111540, Val Acc: 0.773196\n",
      "Epoch 24383 - Train Loss: 0.078195, Train Acc: 0.874359 | Val Loss: 0.111539, Val Acc: 0.773196\n",
      "Epoch 24384 - Train Loss: 0.078194, Train Acc: 0.874359 | Val Loss: 0.111539, Val Acc: 0.773196\n",
      "Epoch 24385 - Train Loss: 0.078192, Train Acc: 0.874359 | Val Loss: 0.111538, Val Acc: 0.773196\n",
      "Epoch 24386 - Train Loss: 0.078191, Train Acc: 0.874359 | Val Loss: 0.111538, Val Acc: 0.773196\n",
      "Epoch 24387 - Train Loss: 0.078189, Train Acc: 0.874359 | Val Loss: 0.111537, Val Acc: 0.773196\n",
      "Epoch 24388 - Train Loss: 0.078187, Train Acc: 0.874359 | Val Loss: 0.111537, Val Acc: 0.773196\n",
      "Epoch 24389 - Train Loss: 0.078186, Train Acc: 0.874359 | Val Loss: 0.111536, Val Acc: 0.773196\n",
      "Epoch 24390 - Train Loss: 0.078184, Train Acc: 0.874359 | Val Loss: 0.111535, Val Acc: 0.773196\n",
      "Epoch 24391 - Train Loss: 0.078182, Train Acc: 0.874359 | Val Loss: 0.111535, Val Acc: 0.773196\n",
      "Epoch 24392 - Train Loss: 0.078181, Train Acc: 0.874359 | Val Loss: 0.111534, Val Acc: 0.773196\n",
      "Epoch 24393 - Train Loss: 0.078179, Train Acc: 0.874359 | Val Loss: 0.111534, Val Acc: 0.773196\n",
      "Epoch 24394 - Train Loss: 0.078177, Train Acc: 0.874359 | Val Loss: 0.111533, Val Acc: 0.773196\n",
      "Epoch 24395 - Train Loss: 0.078176, Train Acc: 0.874359 | Val Loss: 0.111533, Val Acc: 0.773196\n",
      "Epoch 24396 - Train Loss: 0.078174, Train Acc: 0.874359 | Val Loss: 0.111532, Val Acc: 0.773196\n",
      "Epoch 24397 - Train Loss: 0.078173, Train Acc: 0.874359 | Val Loss: 0.111531, Val Acc: 0.773196\n",
      "Epoch 24398 - Train Loss: 0.078171, Train Acc: 0.874359 | Val Loss: 0.111531, Val Acc: 0.773196\n",
      "Epoch 24399 - Train Loss: 0.078169, Train Acc: 0.874359 | Val Loss: 0.111530, Val Acc: 0.773196\n",
      "Epoch 24400 - Train Loss: 0.078168, Train Acc: 0.874359 | Val Loss: 0.111530, Val Acc: 0.773196\n",
      "Epoch 24401 - Train Loss: 0.078166, Train Acc: 0.874359 | Val Loss: 0.111529, Val Acc: 0.773196\n",
      "Epoch 24402 - Train Loss: 0.078164, Train Acc: 0.874359 | Val Loss: 0.111529, Val Acc: 0.773196\n",
      "Epoch 24403 - Train Loss: 0.078163, Train Acc: 0.874359 | Val Loss: 0.111528, Val Acc: 0.773196\n",
      "Epoch 24404 - Train Loss: 0.078161, Train Acc: 0.874359 | Val Loss: 0.111527, Val Acc: 0.773196\n",
      "Epoch 24405 - Train Loss: 0.078160, Train Acc: 0.874359 | Val Loss: 0.111527, Val Acc: 0.773196\n",
      "Epoch 24406 - Train Loss: 0.078158, Train Acc: 0.874359 | Val Loss: 0.111526, Val Acc: 0.773196\n",
      "Epoch 24407 - Train Loss: 0.078156, Train Acc: 0.874359 | Val Loss: 0.111526, Val Acc: 0.773196\n",
      "Epoch 24408 - Train Loss: 0.078155, Train Acc: 0.874359 | Val Loss: 0.111525, Val Acc: 0.773196\n",
      "Epoch 24409 - Train Loss: 0.078153, Train Acc: 0.874359 | Val Loss: 0.111525, Val Acc: 0.773196\n",
      "Epoch 24410 - Train Loss: 0.078151, Train Acc: 0.874359 | Val Loss: 0.111524, Val Acc: 0.773196\n",
      "Epoch 24411 - Train Loss: 0.078150, Train Acc: 0.874359 | Val Loss: 0.111523, Val Acc: 0.773196\n",
      "Epoch 24412 - Train Loss: 0.078148, Train Acc: 0.874359 | Val Loss: 0.111523, Val Acc: 0.773196\n",
      "Epoch 24413 - Train Loss: 0.078146, Train Acc: 0.874359 | Val Loss: 0.111522, Val Acc: 0.773196\n",
      "Epoch 24414 - Train Loss: 0.078145, Train Acc: 0.874359 | Val Loss: 0.111522, Val Acc: 0.773196\n",
      "Epoch 24415 - Train Loss: 0.078143, Train Acc: 0.874359 | Val Loss: 0.111521, Val Acc: 0.773196\n",
      "Epoch 24416 - Train Loss: 0.078142, Train Acc: 0.874359 | Val Loss: 0.111521, Val Acc: 0.773196\n",
      "Epoch 24417 - Train Loss: 0.078140, Train Acc: 0.874359 | Val Loss: 0.111520, Val Acc: 0.773196\n",
      "Epoch 24418 - Train Loss: 0.078138, Train Acc: 0.874359 | Val Loss: 0.111519, Val Acc: 0.773196\n",
      "Epoch 24419 - Train Loss: 0.078137, Train Acc: 0.874359 | Val Loss: 0.111519, Val Acc: 0.773196\n",
      "Epoch 24420 - Train Loss: 0.078135, Train Acc: 0.874359 | Val Loss: 0.111518, Val Acc: 0.773196\n",
      "Epoch 24421 - Train Loss: 0.078133, Train Acc: 0.874359 | Val Loss: 0.111518, Val Acc: 0.773196\n",
      "Epoch 24422 - Train Loss: 0.078132, Train Acc: 0.874359 | Val Loss: 0.111517, Val Acc: 0.773196\n",
      "Epoch 24423 - Train Loss: 0.078130, Train Acc: 0.874359 | Val Loss: 0.111517, Val Acc: 0.773196\n",
      "Epoch 24424 - Train Loss: 0.078128, Train Acc: 0.874359 | Val Loss: 0.111516, Val Acc: 0.773196\n",
      "Epoch 24425 - Train Loss: 0.078127, Train Acc: 0.874359 | Val Loss: 0.111515, Val Acc: 0.773196\n",
      "Epoch 24426 - Train Loss: 0.078125, Train Acc: 0.874359 | Val Loss: 0.111515, Val Acc: 0.773196\n",
      "Epoch 24427 - Train Loss: 0.078124, Train Acc: 0.874359 | Val Loss: 0.111514, Val Acc: 0.773196\n",
      "Epoch 24428 - Train Loss: 0.078122, Train Acc: 0.874359 | Val Loss: 0.111514, Val Acc: 0.773196\n",
      "Epoch 24429 - Train Loss: 0.078120, Train Acc: 0.874359 | Val Loss: 0.111513, Val Acc: 0.773196\n",
      "Epoch 24430 - Train Loss: 0.078119, Train Acc: 0.874359 | Val Loss: 0.111513, Val Acc: 0.773196\n",
      "Epoch 24431 - Train Loss: 0.078117, Train Acc: 0.874359 | Val Loss: 0.111512, Val Acc: 0.773196\n",
      "Epoch 24432 - Train Loss: 0.078115, Train Acc: 0.874359 | Val Loss: 0.111511, Val Acc: 0.773196\n",
      "Epoch 24433 - Train Loss: 0.078114, Train Acc: 0.874359 | Val Loss: 0.111511, Val Acc: 0.773196\n",
      "Epoch 24434 - Train Loss: 0.078112, Train Acc: 0.874359 | Val Loss: 0.111510, Val Acc: 0.773196\n",
      "Epoch 24435 - Train Loss: 0.078111, Train Acc: 0.874359 | Val Loss: 0.111510, Val Acc: 0.773196\n",
      "Epoch 24436 - Train Loss: 0.078109, Train Acc: 0.874359 | Val Loss: 0.111509, Val Acc: 0.773196\n",
      "Epoch 24437 - Train Loss: 0.078107, Train Acc: 0.874359 | Val Loss: 0.111509, Val Acc: 0.773196\n",
      "Epoch 24438 - Train Loss: 0.078106, Train Acc: 0.874359 | Val Loss: 0.111508, Val Acc: 0.773196\n",
      "Epoch 24439 - Train Loss: 0.078104, Train Acc: 0.874359 | Val Loss: 0.111507, Val Acc: 0.773196\n",
      "Epoch 24440 - Train Loss: 0.078102, Train Acc: 0.874359 | Val Loss: 0.111507, Val Acc: 0.773196\n",
      "Epoch 24441 - Train Loss: 0.078101, Train Acc: 0.874359 | Val Loss: 0.111506, Val Acc: 0.773196\n",
      "Epoch 24442 - Train Loss: 0.078099, Train Acc: 0.874359 | Val Loss: 0.111506, Val Acc: 0.773196\n",
      "Epoch 24443 - Train Loss: 0.078097, Train Acc: 0.874359 | Val Loss: 0.111505, Val Acc: 0.773196\n",
      "Epoch 24444 - Train Loss: 0.078096, Train Acc: 0.874359 | Val Loss: 0.111505, Val Acc: 0.773196\n",
      "Epoch 24445 - Train Loss: 0.078094, Train Acc: 0.874359 | Val Loss: 0.111504, Val Acc: 0.773196\n",
      "Epoch 24446 - Train Loss: 0.078093, Train Acc: 0.874359 | Val Loss: 0.111504, Val Acc: 0.773196\n",
      "Epoch 24447 - Train Loss: 0.078091, Train Acc: 0.874359 | Val Loss: 0.111503, Val Acc: 0.773196\n",
      "Epoch 24448 - Train Loss: 0.078089, Train Acc: 0.874359 | Val Loss: 0.111502, Val Acc: 0.773196\n",
      "Epoch 24449 - Train Loss: 0.078088, Train Acc: 0.874359 | Val Loss: 0.111502, Val Acc: 0.773196\n",
      "Epoch 24450 - Train Loss: 0.078086, Train Acc: 0.874359 | Val Loss: 0.111501, Val Acc: 0.773196\n",
      "Epoch 24451 - Train Loss: 0.078084, Train Acc: 0.875641 | Val Loss: 0.111501, Val Acc: 0.773196\n",
      "Epoch 24452 - Train Loss: 0.078083, Train Acc: 0.875641 | Val Loss: 0.111500, Val Acc: 0.773196\n",
      "Epoch 24453 - Train Loss: 0.078081, Train Acc: 0.875641 | Val Loss: 0.111500, Val Acc: 0.773196\n",
      "Epoch 24454 - Train Loss: 0.078080, Train Acc: 0.875641 | Val Loss: 0.111499, Val Acc: 0.773196\n",
      "Epoch 24455 - Train Loss: 0.078078, Train Acc: 0.875641 | Val Loss: 0.111498, Val Acc: 0.773196\n",
      "Epoch 24456 - Train Loss: 0.078076, Train Acc: 0.875641 | Val Loss: 0.111498, Val Acc: 0.773196\n",
      "Epoch 24457 - Train Loss: 0.078075, Train Acc: 0.875641 | Val Loss: 0.111497, Val Acc: 0.773196\n",
      "Epoch 24458 - Train Loss: 0.078073, Train Acc: 0.875641 | Val Loss: 0.111497, Val Acc: 0.773196\n",
      "Epoch 24459 - Train Loss: 0.078071, Train Acc: 0.875641 | Val Loss: 0.111496, Val Acc: 0.773196\n",
      "Epoch 24460 - Train Loss: 0.078070, Train Acc: 0.875641 | Val Loss: 0.111496, Val Acc: 0.773196\n",
      "Epoch 24461 - Train Loss: 0.078068, Train Acc: 0.875641 | Val Loss: 0.111495, Val Acc: 0.773196\n",
      "Epoch 24462 - Train Loss: 0.078067, Train Acc: 0.875641 | Val Loss: 0.111494, Val Acc: 0.773196\n",
      "Epoch 24463 - Train Loss: 0.078065, Train Acc: 0.875641 | Val Loss: 0.111494, Val Acc: 0.773196\n",
      "Epoch 24464 - Train Loss: 0.078063, Train Acc: 0.875641 | Val Loss: 0.111493, Val Acc: 0.773196\n",
      "Epoch 24465 - Train Loss: 0.078062, Train Acc: 0.875641 | Val Loss: 0.111493, Val Acc: 0.773196\n",
      "Epoch 24466 - Train Loss: 0.078060, Train Acc: 0.875641 | Val Loss: 0.111492, Val Acc: 0.773196\n",
      "Epoch 24467 - Train Loss: 0.078058, Train Acc: 0.875641 | Val Loss: 0.111492, Val Acc: 0.773196\n",
      "Epoch 24468 - Train Loss: 0.078057, Train Acc: 0.875641 | Val Loss: 0.111491, Val Acc: 0.773196\n",
      "Epoch 24469 - Train Loss: 0.078055, Train Acc: 0.875641 | Val Loss: 0.111490, Val Acc: 0.773196\n",
      "Epoch 24470 - Train Loss: 0.078053, Train Acc: 0.875641 | Val Loss: 0.111490, Val Acc: 0.773196\n",
      "Epoch 24471 - Train Loss: 0.078052, Train Acc: 0.875641 | Val Loss: 0.111489, Val Acc: 0.773196\n",
      "Epoch 24472 - Train Loss: 0.078050, Train Acc: 0.875641 | Val Loss: 0.111489, Val Acc: 0.773196\n",
      "Epoch 24473 - Train Loss: 0.078049, Train Acc: 0.875641 | Val Loss: 0.111488, Val Acc: 0.773196\n",
      "Epoch 24474 - Train Loss: 0.078047, Train Acc: 0.875641 | Val Loss: 0.111488, Val Acc: 0.773196\n",
      "Epoch 24475 - Train Loss: 0.078045, Train Acc: 0.875641 | Val Loss: 0.111487, Val Acc: 0.773196\n",
      "Epoch 24476 - Train Loss: 0.078044, Train Acc: 0.875641 | Val Loss: 0.111487, Val Acc: 0.773196\n",
      "Epoch 24477 - Train Loss: 0.078042, Train Acc: 0.875641 | Val Loss: 0.111486, Val Acc: 0.773196\n",
      "Epoch 24478 - Train Loss: 0.078040, Train Acc: 0.875641 | Val Loss: 0.111485, Val Acc: 0.773196\n",
      "Epoch 24479 - Train Loss: 0.078039, Train Acc: 0.875641 | Val Loss: 0.111485, Val Acc: 0.773196\n",
      "Epoch 24480 - Train Loss: 0.078037, Train Acc: 0.875641 | Val Loss: 0.111484, Val Acc: 0.773196\n",
      "Epoch 24481 - Train Loss: 0.078036, Train Acc: 0.875641 | Val Loss: 0.111484, Val Acc: 0.773196\n",
      "Epoch 24482 - Train Loss: 0.078034, Train Acc: 0.875641 | Val Loss: 0.111483, Val Acc: 0.773196\n",
      "Epoch 24483 - Train Loss: 0.078032, Train Acc: 0.875641 | Val Loss: 0.111483, Val Acc: 0.773196\n",
      "Epoch 24484 - Train Loss: 0.078031, Train Acc: 0.875641 | Val Loss: 0.111482, Val Acc: 0.773196\n",
      "Epoch 24485 - Train Loss: 0.078029, Train Acc: 0.875641 | Val Loss: 0.111481, Val Acc: 0.773196\n",
      "Epoch 24486 - Train Loss: 0.078027, Train Acc: 0.875641 | Val Loss: 0.111481, Val Acc: 0.773196\n",
      "Epoch 24487 - Train Loss: 0.078026, Train Acc: 0.875641 | Val Loss: 0.111480, Val Acc: 0.773196\n",
      "Epoch 24488 - Train Loss: 0.078024, Train Acc: 0.875641 | Val Loss: 0.111480, Val Acc: 0.773196\n",
      "Epoch 24489 - Train Loss: 0.078023, Train Acc: 0.875641 | Val Loss: 0.111479, Val Acc: 0.773196\n",
      "Epoch 24490 - Train Loss: 0.078021, Train Acc: 0.875641 | Val Loss: 0.111479, Val Acc: 0.773196\n",
      "Epoch 24491 - Train Loss: 0.078019, Train Acc: 0.875641 | Val Loss: 0.111478, Val Acc: 0.773196\n",
      "Epoch 24492 - Train Loss: 0.078018, Train Acc: 0.875641 | Val Loss: 0.111477, Val Acc: 0.773196\n",
      "Epoch 24493 - Train Loss: 0.078016, Train Acc: 0.875641 | Val Loss: 0.111477, Val Acc: 0.773196\n",
      "Epoch 24494 - Train Loss: 0.078014, Train Acc: 0.875641 | Val Loss: 0.111476, Val Acc: 0.773196\n",
      "Epoch 24495 - Train Loss: 0.078013, Train Acc: 0.875641 | Val Loss: 0.111476, Val Acc: 0.773196\n",
      "Epoch 24496 - Train Loss: 0.078011, Train Acc: 0.875641 | Val Loss: 0.111475, Val Acc: 0.773196\n",
      "Epoch 24497 - Train Loss: 0.078010, Train Acc: 0.875641 | Val Loss: 0.111475, Val Acc: 0.773196\n",
      "Epoch 24498 - Train Loss: 0.078008, Train Acc: 0.875641 | Val Loss: 0.111474, Val Acc: 0.773196\n",
      "Epoch 24499 - Train Loss: 0.078006, Train Acc: 0.875641 | Val Loss: 0.111474, Val Acc: 0.773196\n",
      "Epoch 24500 - Train Loss: 0.078005, Train Acc: 0.875641 | Val Loss: 0.111473, Val Acc: 0.773196\n",
      "Epoch 24501 - Train Loss: 0.078003, Train Acc: 0.875641 | Val Loss: 0.111472, Val Acc: 0.773196\n",
      "Epoch 24502 - Train Loss: 0.078001, Train Acc: 0.875641 | Val Loss: 0.111472, Val Acc: 0.773196\n",
      "Epoch 24503 - Train Loss: 0.078000, Train Acc: 0.875641 | Val Loss: 0.111471, Val Acc: 0.773196\n",
      "Epoch 24504 - Train Loss: 0.077998, Train Acc: 0.875641 | Val Loss: 0.111471, Val Acc: 0.773196\n",
      "Epoch 24505 - Train Loss: 0.077997, Train Acc: 0.875641 | Val Loss: 0.111470, Val Acc: 0.773196\n",
      "Epoch 24506 - Train Loss: 0.077995, Train Acc: 0.875641 | Val Loss: 0.111470, Val Acc: 0.773196\n",
      "Epoch 24507 - Train Loss: 0.077993, Train Acc: 0.875641 | Val Loss: 0.111469, Val Acc: 0.773196\n",
      "Epoch 24508 - Train Loss: 0.077992, Train Acc: 0.875641 | Val Loss: 0.111468, Val Acc: 0.773196\n",
      "Epoch 24509 - Train Loss: 0.077990, Train Acc: 0.875641 | Val Loss: 0.111468, Val Acc: 0.773196\n",
      "Epoch 24510 - Train Loss: 0.077988, Train Acc: 0.875641 | Val Loss: 0.111467, Val Acc: 0.773196\n",
      "Epoch 24511 - Train Loss: 0.077987, Train Acc: 0.875641 | Val Loss: 0.111467, Val Acc: 0.773196\n",
      "Epoch 24512 - Train Loss: 0.077985, Train Acc: 0.875641 | Val Loss: 0.111466, Val Acc: 0.773196\n",
      "Epoch 24513 - Train Loss: 0.077984, Train Acc: 0.875641 | Val Loss: 0.111466, Val Acc: 0.773196\n",
      "Epoch 24514 - Train Loss: 0.077982, Train Acc: 0.875641 | Val Loss: 0.111465, Val Acc: 0.773196\n",
      "Epoch 24515 - Train Loss: 0.077980, Train Acc: 0.875641 | Val Loss: 0.111464, Val Acc: 0.773196\n",
      "Epoch 24516 - Train Loss: 0.077979, Train Acc: 0.875641 | Val Loss: 0.111464, Val Acc: 0.773196\n",
      "Epoch 24517 - Train Loss: 0.077977, Train Acc: 0.875641 | Val Loss: 0.111463, Val Acc: 0.773196\n",
      "Epoch 24518 - Train Loss: 0.077975, Train Acc: 0.875641 | Val Loss: 0.111463, Val Acc: 0.773196\n",
      "Epoch 24519 - Train Loss: 0.077974, Train Acc: 0.875641 | Val Loss: 0.111462, Val Acc: 0.773196\n",
      "Epoch 24520 - Train Loss: 0.077972, Train Acc: 0.875641 | Val Loss: 0.111462, Val Acc: 0.773196\n",
      "Epoch 24521 - Train Loss: 0.077971, Train Acc: 0.875641 | Val Loss: 0.111461, Val Acc: 0.773196\n",
      "Epoch 24522 - Train Loss: 0.077969, Train Acc: 0.875641 | Val Loss: 0.111461, Val Acc: 0.773196\n",
      "Epoch 24523 - Train Loss: 0.077967, Train Acc: 0.875641 | Val Loss: 0.111460, Val Acc: 0.773196\n",
      "Epoch 24524 - Train Loss: 0.077966, Train Acc: 0.875641 | Val Loss: 0.111459, Val Acc: 0.773196\n",
      "Epoch 24525 - Train Loss: 0.077964, Train Acc: 0.875641 | Val Loss: 0.111459, Val Acc: 0.773196\n",
      "Epoch 24526 - Train Loss: 0.077962, Train Acc: 0.875641 | Val Loss: 0.111458, Val Acc: 0.773196\n",
      "Epoch 24527 - Train Loss: 0.077961, Train Acc: 0.875641 | Val Loss: 0.111458, Val Acc: 0.773196\n",
      "Epoch 24528 - Train Loss: 0.077959, Train Acc: 0.875641 | Val Loss: 0.111457, Val Acc: 0.773196\n",
      "Epoch 24529 - Train Loss: 0.077958, Train Acc: 0.875641 | Val Loss: 0.111457, Val Acc: 0.773196\n",
      "Epoch 24530 - Train Loss: 0.077956, Train Acc: 0.875641 | Val Loss: 0.111456, Val Acc: 0.773196\n",
      "Epoch 24531 - Train Loss: 0.077954, Train Acc: 0.875641 | Val Loss: 0.111456, Val Acc: 0.773196\n",
      "Epoch 24532 - Train Loss: 0.077953, Train Acc: 0.875641 | Val Loss: 0.111455, Val Acc: 0.773196\n",
      "Epoch 24533 - Train Loss: 0.077951, Train Acc: 0.875641 | Val Loss: 0.111454, Val Acc: 0.773196\n",
      "Epoch 24534 - Train Loss: 0.077949, Train Acc: 0.875641 | Val Loss: 0.111454, Val Acc: 0.773196\n",
      "Epoch 24535 - Train Loss: 0.077948, Train Acc: 0.875641 | Val Loss: 0.111453, Val Acc: 0.773196\n",
      "Epoch 24536 - Train Loss: 0.077946, Train Acc: 0.875641 | Val Loss: 0.111453, Val Acc: 0.773196\n",
      "Epoch 24537 - Train Loss: 0.077945, Train Acc: 0.875641 | Val Loss: 0.111452, Val Acc: 0.773196\n",
      "Epoch 24538 - Train Loss: 0.077943, Train Acc: 0.875641 | Val Loss: 0.111452, Val Acc: 0.773196\n",
      "Epoch 24539 - Train Loss: 0.077941, Train Acc: 0.875641 | Val Loss: 0.111451, Val Acc: 0.773196\n",
      "Epoch 24540 - Train Loss: 0.077940, Train Acc: 0.875641 | Val Loss: 0.111450, Val Acc: 0.773196\n",
      "Epoch 24541 - Train Loss: 0.077938, Train Acc: 0.875641 | Val Loss: 0.111450, Val Acc: 0.773196\n",
      "Epoch 24542 - Train Loss: 0.077937, Train Acc: 0.875641 | Val Loss: 0.111449, Val Acc: 0.773196\n",
      "Epoch 24543 - Train Loss: 0.077935, Train Acc: 0.875641 | Val Loss: 0.111449, Val Acc: 0.773196\n",
      "Epoch 24544 - Train Loss: 0.077933, Train Acc: 0.875641 | Val Loss: 0.111448, Val Acc: 0.773196\n",
      "Epoch 24545 - Train Loss: 0.077932, Train Acc: 0.875641 | Val Loss: 0.111448, Val Acc: 0.773196\n",
      "Epoch 24546 - Train Loss: 0.077930, Train Acc: 0.875641 | Val Loss: 0.111447, Val Acc: 0.773196\n",
      "Epoch 24547 - Train Loss: 0.077928, Train Acc: 0.875641 | Val Loss: 0.111447, Val Acc: 0.773196\n",
      "Epoch 24548 - Train Loss: 0.077927, Train Acc: 0.875641 | Val Loss: 0.111446, Val Acc: 0.773196\n",
      "Epoch 24549 - Train Loss: 0.077925, Train Acc: 0.875641 | Val Loss: 0.111445, Val Acc: 0.773196\n",
      "Epoch 24550 - Train Loss: 0.077924, Train Acc: 0.875641 | Val Loss: 0.111445, Val Acc: 0.773196\n",
      "Epoch 24551 - Train Loss: 0.077922, Train Acc: 0.875641 | Val Loss: 0.111444, Val Acc: 0.773196\n",
      "Epoch 24552 - Train Loss: 0.077920, Train Acc: 0.875641 | Val Loss: 0.111444, Val Acc: 0.773196\n",
      "Epoch 24553 - Train Loss: 0.077919, Train Acc: 0.875641 | Val Loss: 0.111443, Val Acc: 0.773196\n",
      "Epoch 24554 - Train Loss: 0.077917, Train Acc: 0.875641 | Val Loss: 0.111443, Val Acc: 0.773196\n",
      "Epoch 24555 - Train Loss: 0.077915, Train Acc: 0.875641 | Val Loss: 0.111442, Val Acc: 0.773196\n",
      "Epoch 24556 - Train Loss: 0.077914, Train Acc: 0.875641 | Val Loss: 0.111441, Val Acc: 0.773196\n",
      "Epoch 24557 - Train Loss: 0.077912, Train Acc: 0.875641 | Val Loss: 0.111441, Val Acc: 0.773196\n",
      "Epoch 24558 - Train Loss: 0.077911, Train Acc: 0.875641 | Val Loss: 0.111440, Val Acc: 0.773196\n",
      "Epoch 24559 - Train Loss: 0.077909, Train Acc: 0.875641 | Val Loss: 0.111440, Val Acc: 0.773196\n",
      "Epoch 24560 - Train Loss: 0.077907, Train Acc: 0.875641 | Val Loss: 0.111439, Val Acc: 0.773196\n",
      "Epoch 24561 - Train Loss: 0.077906, Train Acc: 0.875641 | Val Loss: 0.111439, Val Acc: 0.773196\n",
      "Epoch 24562 - Train Loss: 0.077904, Train Acc: 0.875641 | Val Loss: 0.111438, Val Acc: 0.773196\n",
      "Epoch 24563 - Train Loss: 0.077902, Train Acc: 0.875641 | Val Loss: 0.111438, Val Acc: 0.773196\n",
      "Epoch 24564 - Train Loss: 0.077901, Train Acc: 0.875641 | Val Loss: 0.111437, Val Acc: 0.773196\n",
      "Epoch 24565 - Train Loss: 0.077899, Train Acc: 0.875641 | Val Loss: 0.111436, Val Acc: 0.773196\n",
      "Epoch 24566 - Train Loss: 0.077898, Train Acc: 0.875641 | Val Loss: 0.111436, Val Acc: 0.773196\n",
      "Epoch 24567 - Train Loss: 0.077896, Train Acc: 0.875641 | Val Loss: 0.111435, Val Acc: 0.773196\n",
      "Epoch 24568 - Train Loss: 0.077894, Train Acc: 0.875641 | Val Loss: 0.111435, Val Acc: 0.773196\n",
      "Epoch 24569 - Train Loss: 0.077893, Train Acc: 0.875641 | Val Loss: 0.111434, Val Acc: 0.773196\n",
      "Epoch 24570 - Train Loss: 0.077891, Train Acc: 0.875641 | Val Loss: 0.111434, Val Acc: 0.773196\n",
      "Epoch 24571 - Train Loss: 0.077890, Train Acc: 0.875641 | Val Loss: 0.111433, Val Acc: 0.773196\n",
      "Epoch 24572 - Train Loss: 0.077888, Train Acc: 0.875641 | Val Loss: 0.111433, Val Acc: 0.773196\n",
      "Epoch 24573 - Train Loss: 0.077886, Train Acc: 0.875641 | Val Loss: 0.111432, Val Acc: 0.773196\n",
      "Epoch 24574 - Train Loss: 0.077885, Train Acc: 0.875641 | Val Loss: 0.111431, Val Acc: 0.773196\n",
      "Epoch 24575 - Train Loss: 0.077883, Train Acc: 0.875641 | Val Loss: 0.111431, Val Acc: 0.773196\n",
      "Epoch 24576 - Train Loss: 0.077881, Train Acc: 0.875641 | Val Loss: 0.111430, Val Acc: 0.773196\n",
      "Epoch 24577 - Train Loss: 0.077880, Train Acc: 0.875641 | Val Loss: 0.111430, Val Acc: 0.773196\n",
      "Epoch 24578 - Train Loss: 0.077878, Train Acc: 0.875641 | Val Loss: 0.111429, Val Acc: 0.773196\n",
      "Epoch 24579 - Train Loss: 0.077877, Train Acc: 0.875641 | Val Loss: 0.111429, Val Acc: 0.773196\n",
      "Epoch 24580 - Train Loss: 0.077875, Train Acc: 0.875641 | Val Loss: 0.111428, Val Acc: 0.773196\n",
      "Epoch 24581 - Train Loss: 0.077873, Train Acc: 0.875641 | Val Loss: 0.111428, Val Acc: 0.773196\n",
      "Epoch 24582 - Train Loss: 0.077872, Train Acc: 0.875641 | Val Loss: 0.111427, Val Acc: 0.773196\n",
      "Epoch 24583 - Train Loss: 0.077870, Train Acc: 0.875641 | Val Loss: 0.111426, Val Acc: 0.773196\n",
      "Epoch 24584 - Train Loss: 0.077869, Train Acc: 0.875641 | Val Loss: 0.111426, Val Acc: 0.773196\n",
      "Epoch 24585 - Train Loss: 0.077867, Train Acc: 0.875641 | Val Loss: 0.111425, Val Acc: 0.773196\n",
      "Epoch 24586 - Train Loss: 0.077865, Train Acc: 0.875641 | Val Loss: 0.111425, Val Acc: 0.773196\n",
      "Epoch 24587 - Train Loss: 0.077864, Train Acc: 0.875641 | Val Loss: 0.111424, Val Acc: 0.773196\n",
      "Epoch 24588 - Train Loss: 0.077862, Train Acc: 0.875641 | Val Loss: 0.111424, Val Acc: 0.773196\n",
      "Epoch 24589 - Train Loss: 0.077860, Train Acc: 0.875641 | Val Loss: 0.111423, Val Acc: 0.773196\n",
      "Epoch 24590 - Train Loss: 0.077859, Train Acc: 0.875641 | Val Loss: 0.111423, Val Acc: 0.773196\n",
      "Epoch 24591 - Train Loss: 0.077857, Train Acc: 0.875641 | Val Loss: 0.111422, Val Acc: 0.773196\n",
      "Epoch 24592 - Train Loss: 0.077856, Train Acc: 0.875641 | Val Loss: 0.111421, Val Acc: 0.773196\n",
      "Epoch 24593 - Train Loss: 0.077854, Train Acc: 0.875641 | Val Loss: 0.111421, Val Acc: 0.773196\n",
      "Epoch 24594 - Train Loss: 0.077852, Train Acc: 0.875641 | Val Loss: 0.111420, Val Acc: 0.773196\n",
      "Epoch 24595 - Train Loss: 0.077851, Train Acc: 0.875641 | Val Loss: 0.111420, Val Acc: 0.773196\n",
      "Epoch 24596 - Train Loss: 0.077849, Train Acc: 0.875641 | Val Loss: 0.111419, Val Acc: 0.773196\n",
      "Epoch 24597 - Train Loss: 0.077848, Train Acc: 0.875641 | Val Loss: 0.111419, Val Acc: 0.773196\n",
      "Epoch 24598 - Train Loss: 0.077846, Train Acc: 0.875641 | Val Loss: 0.111418, Val Acc: 0.773196\n",
      "Epoch 24599 - Train Loss: 0.077844, Train Acc: 0.875641 | Val Loss: 0.111418, Val Acc: 0.773196\n",
      "Epoch 24600 - Train Loss: 0.077843, Train Acc: 0.875641 | Val Loss: 0.111417, Val Acc: 0.773196\n",
      "Epoch 24601 - Train Loss: 0.077841, Train Acc: 0.875641 | Val Loss: 0.111416, Val Acc: 0.773196\n",
      "Epoch 24602 - Train Loss: 0.077839, Train Acc: 0.875641 | Val Loss: 0.111416, Val Acc: 0.773196\n",
      "Epoch 24603 - Train Loss: 0.077838, Train Acc: 0.875641 | Val Loss: 0.111415, Val Acc: 0.773196\n",
      "Epoch 24604 - Train Loss: 0.077836, Train Acc: 0.875641 | Val Loss: 0.111415, Val Acc: 0.773196\n",
      "Epoch 24605 - Train Loss: 0.077835, Train Acc: 0.875641 | Val Loss: 0.111414, Val Acc: 0.773196\n",
      "Epoch 24606 - Train Loss: 0.077833, Train Acc: 0.875641 | Val Loss: 0.111414, Val Acc: 0.773196\n",
      "Epoch 24607 - Train Loss: 0.077831, Train Acc: 0.875641 | Val Loss: 0.111413, Val Acc: 0.773196\n",
      "Epoch 24608 - Train Loss: 0.077830, Train Acc: 0.875641 | Val Loss: 0.111413, Val Acc: 0.773196\n",
      "Epoch 24609 - Train Loss: 0.077828, Train Acc: 0.875641 | Val Loss: 0.111412, Val Acc: 0.773196\n",
      "Epoch 24610 - Train Loss: 0.077827, Train Acc: 0.875641 | Val Loss: 0.111411, Val Acc: 0.773196\n",
      "Epoch 24611 - Train Loss: 0.077825, Train Acc: 0.875641 | Val Loss: 0.111411, Val Acc: 0.773196\n",
      "Epoch 24612 - Train Loss: 0.077823, Train Acc: 0.875641 | Val Loss: 0.111410, Val Acc: 0.773196\n",
      "Epoch 24613 - Train Loss: 0.077822, Train Acc: 0.875641 | Val Loss: 0.111410, Val Acc: 0.773196\n",
      "Epoch 24614 - Train Loss: 0.077820, Train Acc: 0.875641 | Val Loss: 0.111409, Val Acc: 0.773196\n",
      "Epoch 24615 - Train Loss: 0.077818, Train Acc: 0.875641 | Val Loss: 0.111409, Val Acc: 0.773196\n",
      "Epoch 24616 - Train Loss: 0.077817, Train Acc: 0.875641 | Val Loss: 0.111408, Val Acc: 0.773196\n",
      "Epoch 24617 - Train Loss: 0.077815, Train Acc: 0.875641 | Val Loss: 0.111408, Val Acc: 0.773196\n",
      "Epoch 24618 - Train Loss: 0.077814, Train Acc: 0.875641 | Val Loss: 0.111407, Val Acc: 0.773196\n",
      "Epoch 24619 - Train Loss: 0.077812, Train Acc: 0.875641 | Val Loss: 0.111406, Val Acc: 0.773196\n",
      "Epoch 24620 - Train Loss: 0.077810, Train Acc: 0.875641 | Val Loss: 0.111406, Val Acc: 0.773196\n",
      "Epoch 24621 - Train Loss: 0.077809, Train Acc: 0.875641 | Val Loss: 0.111405, Val Acc: 0.773196\n",
      "Epoch 24622 - Train Loss: 0.077807, Train Acc: 0.875641 | Val Loss: 0.111405, Val Acc: 0.773196\n",
      "Epoch 24623 - Train Loss: 0.077806, Train Acc: 0.875641 | Val Loss: 0.111404, Val Acc: 0.773196\n",
      "Epoch 24624 - Train Loss: 0.077804, Train Acc: 0.875641 | Val Loss: 0.111404, Val Acc: 0.773196\n",
      "Epoch 24625 - Train Loss: 0.077802, Train Acc: 0.875641 | Val Loss: 0.111403, Val Acc: 0.773196\n",
      "Epoch 24626 - Train Loss: 0.077801, Train Acc: 0.875641 | Val Loss: 0.111403, Val Acc: 0.773196\n",
      "Epoch 24627 - Train Loss: 0.077799, Train Acc: 0.875641 | Val Loss: 0.111402, Val Acc: 0.773196\n",
      "Epoch 24628 - Train Loss: 0.077797, Train Acc: 0.875641 | Val Loss: 0.111401, Val Acc: 0.773196\n",
      "Epoch 24629 - Train Loss: 0.077796, Train Acc: 0.875641 | Val Loss: 0.111401, Val Acc: 0.773196\n",
      "Epoch 24630 - Train Loss: 0.077794, Train Acc: 0.875641 | Val Loss: 0.111400, Val Acc: 0.773196\n",
      "Epoch 24631 - Train Loss: 0.077793, Train Acc: 0.875641 | Val Loss: 0.111400, Val Acc: 0.773196\n",
      "Epoch 24632 - Train Loss: 0.077791, Train Acc: 0.875641 | Val Loss: 0.111399, Val Acc: 0.773196\n",
      "Epoch 24633 - Train Loss: 0.077789, Train Acc: 0.875641 | Val Loss: 0.111399, Val Acc: 0.773196\n",
      "Epoch 24634 - Train Loss: 0.077788, Train Acc: 0.875641 | Val Loss: 0.111398, Val Acc: 0.773196\n",
      "Epoch 24635 - Train Loss: 0.077786, Train Acc: 0.875641 | Val Loss: 0.111398, Val Acc: 0.773196\n",
      "Epoch 24636 - Train Loss: 0.077785, Train Acc: 0.875641 | Val Loss: 0.111397, Val Acc: 0.773196\n",
      "Epoch 24637 - Train Loss: 0.077783, Train Acc: 0.875641 | Val Loss: 0.111396, Val Acc: 0.773196\n",
      "Epoch 24638 - Train Loss: 0.077781, Train Acc: 0.875641 | Val Loss: 0.111396, Val Acc: 0.773196\n",
      "Epoch 24639 - Train Loss: 0.077780, Train Acc: 0.875641 | Val Loss: 0.111395, Val Acc: 0.773196\n",
      "Epoch 24640 - Train Loss: 0.077778, Train Acc: 0.875641 | Val Loss: 0.111395, Val Acc: 0.773196\n",
      "Epoch 24641 - Train Loss: 0.077777, Train Acc: 0.875641 | Val Loss: 0.111394, Val Acc: 0.773196\n",
      "Epoch 24642 - Train Loss: 0.077775, Train Acc: 0.875641 | Val Loss: 0.111394, Val Acc: 0.773196\n",
      "Epoch 24643 - Train Loss: 0.077773, Train Acc: 0.875641 | Val Loss: 0.111393, Val Acc: 0.773196\n",
      "Epoch 24644 - Train Loss: 0.077772, Train Acc: 0.875641 | Val Loss: 0.111393, Val Acc: 0.773196\n",
      "Epoch 24645 - Train Loss: 0.077770, Train Acc: 0.875641 | Val Loss: 0.111392, Val Acc: 0.773196\n",
      "Epoch 24646 - Train Loss: 0.077768, Train Acc: 0.875641 | Val Loss: 0.111391, Val Acc: 0.773196\n",
      "Epoch 24647 - Train Loss: 0.077767, Train Acc: 0.875641 | Val Loss: 0.111391, Val Acc: 0.773196\n",
      "Epoch 24648 - Train Loss: 0.077765, Train Acc: 0.875641 | Val Loss: 0.111390, Val Acc: 0.773196\n",
      "Epoch 24649 - Train Loss: 0.077764, Train Acc: 0.875641 | Val Loss: 0.111390, Val Acc: 0.773196\n",
      "Epoch 24650 - Train Loss: 0.077762, Train Acc: 0.875641 | Val Loss: 0.111389, Val Acc: 0.773196\n",
      "Epoch 24651 - Train Loss: 0.077760, Train Acc: 0.875641 | Val Loss: 0.111389, Val Acc: 0.773196\n",
      "Epoch 24652 - Train Loss: 0.077759, Train Acc: 0.875641 | Val Loss: 0.111388, Val Acc: 0.773196\n",
      "Epoch 24653 - Train Loss: 0.077757, Train Acc: 0.875641 | Val Loss: 0.111388, Val Acc: 0.773196\n",
      "Epoch 24654 - Train Loss: 0.077756, Train Acc: 0.875641 | Val Loss: 0.111387, Val Acc: 0.773196\n",
      "Epoch 24655 - Train Loss: 0.077754, Train Acc: 0.875641 | Val Loss: 0.111387, Val Acc: 0.773196\n",
      "Epoch 24656 - Train Loss: 0.077752, Train Acc: 0.875641 | Val Loss: 0.111386, Val Acc: 0.773196\n",
      "Epoch 24657 - Train Loss: 0.077751, Train Acc: 0.875641 | Val Loss: 0.111385, Val Acc: 0.773196\n",
      "Epoch 24658 - Train Loss: 0.077749, Train Acc: 0.875641 | Val Loss: 0.111385, Val Acc: 0.773196\n",
      "Epoch 24659 - Train Loss: 0.077748, Train Acc: 0.875641 | Val Loss: 0.111384, Val Acc: 0.773196\n",
      "Epoch 24660 - Train Loss: 0.077746, Train Acc: 0.875641 | Val Loss: 0.111384, Val Acc: 0.773196\n",
      "Epoch 24661 - Train Loss: 0.077744, Train Acc: 0.875641 | Val Loss: 0.111383, Val Acc: 0.773196\n",
      "Epoch 24662 - Train Loss: 0.077743, Train Acc: 0.875641 | Val Loss: 0.111383, Val Acc: 0.773196\n",
      "Epoch 24663 - Train Loss: 0.077741, Train Acc: 0.875641 | Val Loss: 0.111382, Val Acc: 0.773196\n",
      "Epoch 24664 - Train Loss: 0.077739, Train Acc: 0.875641 | Val Loss: 0.111382, Val Acc: 0.773196\n",
      "Epoch 24665 - Train Loss: 0.077738, Train Acc: 0.875641 | Val Loss: 0.111381, Val Acc: 0.773196\n",
      "Epoch 24666 - Train Loss: 0.077736, Train Acc: 0.875641 | Val Loss: 0.111380, Val Acc: 0.773196\n",
      "Epoch 24667 - Train Loss: 0.077735, Train Acc: 0.875641 | Val Loss: 0.111380, Val Acc: 0.773196\n",
      "Epoch 24668 - Train Loss: 0.077733, Train Acc: 0.875641 | Val Loss: 0.111379, Val Acc: 0.773196\n",
      "Epoch 24669 - Train Loss: 0.077731, Train Acc: 0.875641 | Val Loss: 0.111379, Val Acc: 0.773196\n",
      "Epoch 24670 - Train Loss: 0.077730, Train Acc: 0.875641 | Val Loss: 0.111378, Val Acc: 0.773196\n",
      "Epoch 24671 - Train Loss: 0.077728, Train Acc: 0.875641 | Val Loss: 0.111378, Val Acc: 0.773196\n",
      "Epoch 24672 - Train Loss: 0.077727, Train Acc: 0.875641 | Val Loss: 0.111377, Val Acc: 0.773196\n",
      "Epoch 24673 - Train Loss: 0.077725, Train Acc: 0.875641 | Val Loss: 0.111377, Val Acc: 0.773196\n",
      "Epoch 24674 - Train Loss: 0.077723, Train Acc: 0.875641 | Val Loss: 0.111376, Val Acc: 0.773196\n",
      "Epoch 24675 - Train Loss: 0.077722, Train Acc: 0.875641 | Val Loss: 0.111375, Val Acc: 0.773196\n",
      "Epoch 24676 - Train Loss: 0.077720, Train Acc: 0.875641 | Val Loss: 0.111375, Val Acc: 0.773196\n",
      "Epoch 24677 - Train Loss: 0.077719, Train Acc: 0.875641 | Val Loss: 0.111374, Val Acc: 0.773196\n",
      "Epoch 24678 - Train Loss: 0.077717, Train Acc: 0.875641 | Val Loss: 0.111374, Val Acc: 0.773196\n",
      "Epoch 24679 - Train Loss: 0.077715, Train Acc: 0.875641 | Val Loss: 0.111373, Val Acc: 0.773196\n",
      "Epoch 24680 - Train Loss: 0.077714, Train Acc: 0.875641 | Val Loss: 0.111373, Val Acc: 0.773196\n",
      "Epoch 24681 - Train Loss: 0.077712, Train Acc: 0.875641 | Val Loss: 0.111372, Val Acc: 0.773196\n",
      "Epoch 24682 - Train Loss: 0.077711, Train Acc: 0.875641 | Val Loss: 0.111372, Val Acc: 0.773196\n",
      "Epoch 24683 - Train Loss: 0.077709, Train Acc: 0.875641 | Val Loss: 0.111371, Val Acc: 0.773196\n",
      "Epoch 24684 - Train Loss: 0.077707, Train Acc: 0.875641 | Val Loss: 0.111371, Val Acc: 0.773196\n",
      "Epoch 24685 - Train Loss: 0.077706, Train Acc: 0.875641 | Val Loss: 0.111370, Val Acc: 0.773196\n",
      "Epoch 24686 - Train Loss: 0.077704, Train Acc: 0.875641 | Val Loss: 0.111369, Val Acc: 0.773196\n",
      "Epoch 24687 - Train Loss: 0.077702, Train Acc: 0.875641 | Val Loss: 0.111369, Val Acc: 0.773196\n",
      "Epoch 24688 - Train Loss: 0.077701, Train Acc: 0.875641 | Val Loss: 0.111368, Val Acc: 0.773196\n",
      "Epoch 24689 - Train Loss: 0.077699, Train Acc: 0.875641 | Val Loss: 0.111368, Val Acc: 0.773196\n",
      "Epoch 24690 - Train Loss: 0.077698, Train Acc: 0.875641 | Val Loss: 0.111367, Val Acc: 0.773196\n",
      "Epoch 24691 - Train Loss: 0.077696, Train Acc: 0.875641 | Val Loss: 0.111367, Val Acc: 0.773196\n",
      "Epoch 24692 - Train Loss: 0.077694, Train Acc: 0.875641 | Val Loss: 0.111366, Val Acc: 0.773196\n",
      "Epoch 24693 - Train Loss: 0.077693, Train Acc: 0.875641 | Val Loss: 0.111366, Val Acc: 0.773196\n",
      "Epoch 24694 - Train Loss: 0.077691, Train Acc: 0.875641 | Val Loss: 0.111365, Val Acc: 0.773196\n",
      "Epoch 24695 - Train Loss: 0.077690, Train Acc: 0.875641 | Val Loss: 0.111365, Val Acc: 0.773196\n",
      "Epoch 24696 - Train Loss: 0.077688, Train Acc: 0.875641 | Val Loss: 0.111364, Val Acc: 0.773196\n",
      "Epoch 24697 - Train Loss: 0.077686, Train Acc: 0.875641 | Val Loss: 0.111363, Val Acc: 0.773196\n",
      "Epoch 24698 - Train Loss: 0.077685, Train Acc: 0.875641 | Val Loss: 0.111363, Val Acc: 0.773196\n",
      "Epoch 24699 - Train Loss: 0.077683, Train Acc: 0.875641 | Val Loss: 0.111362, Val Acc: 0.773196\n",
      "Epoch 24700 - Train Loss: 0.077682, Train Acc: 0.875641 | Val Loss: 0.111362, Val Acc: 0.773196\n",
      "Epoch 24701 - Train Loss: 0.077680, Train Acc: 0.875641 | Val Loss: 0.111361, Val Acc: 0.773196\n",
      "Epoch 24702 - Train Loss: 0.077678, Train Acc: 0.875641 | Val Loss: 0.111361, Val Acc: 0.773196\n",
      "Epoch 24703 - Train Loss: 0.077677, Train Acc: 0.875641 | Val Loss: 0.111360, Val Acc: 0.773196\n",
      "Epoch 24704 - Train Loss: 0.077675, Train Acc: 0.875641 | Val Loss: 0.111360, Val Acc: 0.773196\n",
      "Epoch 24705 - Train Loss: 0.077674, Train Acc: 0.875641 | Val Loss: 0.111359, Val Acc: 0.773196\n",
      "Epoch 24706 - Train Loss: 0.077672, Train Acc: 0.875641 | Val Loss: 0.111358, Val Acc: 0.773196\n",
      "Epoch 24707 - Train Loss: 0.077670, Train Acc: 0.875641 | Val Loss: 0.111358, Val Acc: 0.773196\n",
      "Epoch 24708 - Train Loss: 0.077669, Train Acc: 0.875641 | Val Loss: 0.111357, Val Acc: 0.773196\n",
      "Epoch 24709 - Train Loss: 0.077667, Train Acc: 0.875641 | Val Loss: 0.111357, Val Acc: 0.773196\n",
      "Epoch 24710 - Train Loss: 0.077666, Train Acc: 0.875641 | Val Loss: 0.111356, Val Acc: 0.773196\n",
      "Epoch 24711 - Train Loss: 0.077664, Train Acc: 0.875641 | Val Loss: 0.111356, Val Acc: 0.773196\n",
      "Epoch 24712 - Train Loss: 0.077662, Train Acc: 0.875641 | Val Loss: 0.111355, Val Acc: 0.773196\n",
      "Epoch 24713 - Train Loss: 0.077661, Train Acc: 0.875641 | Val Loss: 0.111355, Val Acc: 0.773196\n",
      "Epoch 24714 - Train Loss: 0.077659, Train Acc: 0.875641 | Val Loss: 0.111354, Val Acc: 0.773196\n",
      "Epoch 24715 - Train Loss: 0.077658, Train Acc: 0.875641 | Val Loss: 0.111354, Val Acc: 0.773196\n",
      "Epoch 24716 - Train Loss: 0.077656, Train Acc: 0.875641 | Val Loss: 0.111353, Val Acc: 0.773196\n",
      "Epoch 24717 - Train Loss: 0.077654, Train Acc: 0.875641 | Val Loss: 0.111352, Val Acc: 0.773196\n",
      "Epoch 24718 - Train Loss: 0.077653, Train Acc: 0.875641 | Val Loss: 0.111352, Val Acc: 0.773196\n",
      "Epoch 24719 - Train Loss: 0.077651, Train Acc: 0.875641 | Val Loss: 0.111351, Val Acc: 0.773196\n",
      "Epoch 24720 - Train Loss: 0.077650, Train Acc: 0.875641 | Val Loss: 0.111351, Val Acc: 0.773196\n",
      "Epoch 24721 - Train Loss: 0.077648, Train Acc: 0.875641 | Val Loss: 0.111350, Val Acc: 0.773196\n",
      "Epoch 24722 - Train Loss: 0.077646, Train Acc: 0.875641 | Val Loss: 0.111350, Val Acc: 0.773196\n",
      "Epoch 24723 - Train Loss: 0.077645, Train Acc: 0.875641 | Val Loss: 0.111349, Val Acc: 0.773196\n",
      "Epoch 24724 - Train Loss: 0.077643, Train Acc: 0.875641 | Val Loss: 0.111348, Val Acc: 0.773196\n",
      "Epoch 24725 - Train Loss: 0.077642, Train Acc: 0.875641 | Val Loss: 0.111348, Val Acc: 0.773196\n",
      "Epoch 24726 - Train Loss: 0.077640, Train Acc: 0.875641 | Val Loss: 0.111347, Val Acc: 0.773196\n",
      "Epoch 24727 - Train Loss: 0.077638, Train Acc: 0.875641 | Val Loss: 0.111347, Val Acc: 0.773196\n",
      "Epoch 24728 - Train Loss: 0.077637, Train Acc: 0.875641 | Val Loss: 0.111346, Val Acc: 0.773196\n",
      "Epoch 24729 - Train Loss: 0.077635, Train Acc: 0.875641 | Val Loss: 0.111346, Val Acc: 0.773196\n",
      "Epoch 24730 - Train Loss: 0.077633, Train Acc: 0.875641 | Val Loss: 0.111345, Val Acc: 0.773196\n",
      "Epoch 24731 - Train Loss: 0.077632, Train Acc: 0.875641 | Val Loss: 0.111345, Val Acc: 0.773196\n",
      "Epoch 24732 - Train Loss: 0.077630, Train Acc: 0.875641 | Val Loss: 0.111344, Val Acc: 0.773196\n",
      "Epoch 24733 - Train Loss: 0.077629, Train Acc: 0.875641 | Val Loss: 0.111343, Val Acc: 0.773196\n",
      "Epoch 24734 - Train Loss: 0.077627, Train Acc: 0.875641 | Val Loss: 0.111343, Val Acc: 0.773196\n",
      "Epoch 24735 - Train Loss: 0.077625, Train Acc: 0.875641 | Val Loss: 0.111342, Val Acc: 0.773196\n",
      "Epoch 24736 - Train Loss: 0.077624, Train Acc: 0.875641 | Val Loss: 0.111342, Val Acc: 0.773196\n",
      "Epoch 24737 - Train Loss: 0.077622, Train Acc: 0.875641 | Val Loss: 0.111341, Val Acc: 0.773196\n",
      "Epoch 24738 - Train Loss: 0.077621, Train Acc: 0.875641 | Val Loss: 0.111341, Val Acc: 0.773196\n",
      "Epoch 24739 - Train Loss: 0.077619, Train Acc: 0.875641 | Val Loss: 0.111340, Val Acc: 0.773196\n",
      "Epoch 24740 - Train Loss: 0.077617, Train Acc: 0.875641 | Val Loss: 0.111339, Val Acc: 0.773196\n",
      "Epoch 24741 - Train Loss: 0.077616, Train Acc: 0.875641 | Val Loss: 0.111339, Val Acc: 0.773196\n",
      "Epoch 24742 - Train Loss: 0.077614, Train Acc: 0.875641 | Val Loss: 0.111338, Val Acc: 0.773196\n",
      "Epoch 24743 - Train Loss: 0.077613, Train Acc: 0.875641 | Val Loss: 0.111338, Val Acc: 0.773196\n",
      "Epoch 24744 - Train Loss: 0.077611, Train Acc: 0.875641 | Val Loss: 0.111337, Val Acc: 0.773196\n",
      "Epoch 24745 - Train Loss: 0.077609, Train Acc: 0.875641 | Val Loss: 0.111337, Val Acc: 0.773196\n",
      "Epoch 24746 - Train Loss: 0.077608, Train Acc: 0.875641 | Val Loss: 0.111336, Val Acc: 0.773196\n",
      "Epoch 24747 - Train Loss: 0.077606, Train Acc: 0.875641 | Val Loss: 0.111335, Val Acc: 0.773196\n",
      "Epoch 24748 - Train Loss: 0.077605, Train Acc: 0.875641 | Val Loss: 0.111335, Val Acc: 0.773196\n",
      "Epoch 24749 - Train Loss: 0.077603, Train Acc: 0.875641 | Val Loss: 0.111334, Val Acc: 0.773196\n",
      "Epoch 24750 - Train Loss: 0.077601, Train Acc: 0.875641 | Val Loss: 0.111334, Val Acc: 0.773196\n",
      "Epoch 24751 - Train Loss: 0.077600, Train Acc: 0.875641 | Val Loss: 0.111333, Val Acc: 0.773196\n",
      "Epoch 24752 - Train Loss: 0.077598, Train Acc: 0.875641 | Val Loss: 0.111333, Val Acc: 0.773196\n",
      "Epoch 24753 - Train Loss: 0.077597, Train Acc: 0.875641 | Val Loss: 0.111332, Val Acc: 0.773196\n",
      "Epoch 24754 - Train Loss: 0.077595, Train Acc: 0.875641 | Val Loss: 0.111332, Val Acc: 0.773196\n",
      "Epoch 24755 - Train Loss: 0.077593, Train Acc: 0.875641 | Val Loss: 0.111331, Val Acc: 0.773196\n",
      "Epoch 24756 - Train Loss: 0.077592, Train Acc: 0.875641 | Val Loss: 0.111330, Val Acc: 0.773196\n",
      "Epoch 24757 - Train Loss: 0.077590, Train Acc: 0.875641 | Val Loss: 0.111330, Val Acc: 0.773196\n",
      "Epoch 24758 - Train Loss: 0.077589, Train Acc: 0.875641 | Val Loss: 0.111329, Val Acc: 0.773196\n",
      "Epoch 24759 - Train Loss: 0.077587, Train Acc: 0.875641 | Val Loss: 0.111329, Val Acc: 0.773196\n",
      "Epoch 24760 - Train Loss: 0.077585, Train Acc: 0.875641 | Val Loss: 0.111328, Val Acc: 0.773196\n",
      "Epoch 24761 - Train Loss: 0.077584, Train Acc: 0.875641 | Val Loss: 0.111328, Val Acc: 0.773196\n",
      "Epoch 24762 - Train Loss: 0.077582, Train Acc: 0.875641 | Val Loss: 0.111327, Val Acc: 0.773196\n",
      "Epoch 24763 - Train Loss: 0.077581, Train Acc: 0.875641 | Val Loss: 0.111326, Val Acc: 0.773196\n",
      "Epoch 24764 - Train Loss: 0.077579, Train Acc: 0.875641 | Val Loss: 0.111326, Val Acc: 0.773196\n",
      "Epoch 24765 - Train Loss: 0.077577, Train Acc: 0.875641 | Val Loss: 0.111325, Val Acc: 0.773196\n",
      "Epoch 24766 - Train Loss: 0.077576, Train Acc: 0.875641 | Val Loss: 0.111325, Val Acc: 0.773196\n",
      "Epoch 24767 - Train Loss: 0.077574, Train Acc: 0.876923 | Val Loss: 0.111324, Val Acc: 0.773196\n",
      "Epoch 24768 - Train Loss: 0.077573, Train Acc: 0.876923 | Val Loss: 0.111324, Val Acc: 0.773196\n",
      "Epoch 24769 - Train Loss: 0.077571, Train Acc: 0.876923 | Val Loss: 0.111323, Val Acc: 0.773196\n",
      "Epoch 24770 - Train Loss: 0.077569, Train Acc: 0.876923 | Val Loss: 0.111323, Val Acc: 0.773196\n",
      "Epoch 24771 - Train Loss: 0.077568, Train Acc: 0.876923 | Val Loss: 0.111322, Val Acc: 0.773196\n",
      "Epoch 24772 - Train Loss: 0.077566, Train Acc: 0.876923 | Val Loss: 0.111321, Val Acc: 0.773196\n",
      "Epoch 24773 - Train Loss: 0.077565, Train Acc: 0.876923 | Val Loss: 0.111321, Val Acc: 0.773196\n",
      "Epoch 24774 - Train Loss: 0.077563, Train Acc: 0.876923 | Val Loss: 0.111320, Val Acc: 0.773196\n",
      "Epoch 24775 - Train Loss: 0.077561, Train Acc: 0.876923 | Val Loss: 0.111320, Val Acc: 0.773196\n",
      "Epoch 24776 - Train Loss: 0.077560, Train Acc: 0.876923 | Val Loss: 0.111319, Val Acc: 0.773196\n",
      "Epoch 24777 - Train Loss: 0.077558, Train Acc: 0.876923 | Val Loss: 0.111319, Val Acc: 0.773196\n",
      "Epoch 24778 - Train Loss: 0.077557, Train Acc: 0.876923 | Val Loss: 0.111318, Val Acc: 0.773196\n",
      "Epoch 24779 - Train Loss: 0.077555, Train Acc: 0.876923 | Val Loss: 0.111318, Val Acc: 0.773196\n",
      "Epoch 24780 - Train Loss: 0.077553, Train Acc: 0.876923 | Val Loss: 0.111317, Val Acc: 0.773196\n",
      "Epoch 24781 - Train Loss: 0.077552, Train Acc: 0.876923 | Val Loss: 0.111316, Val Acc: 0.773196\n",
      "Epoch 24782 - Train Loss: 0.077550, Train Acc: 0.876923 | Val Loss: 0.111316, Val Acc: 0.773196\n",
      "Epoch 24783 - Train Loss: 0.077549, Train Acc: 0.876923 | Val Loss: 0.111315, Val Acc: 0.773196\n",
      "Epoch 24784 - Train Loss: 0.077547, Train Acc: 0.876923 | Val Loss: 0.111315, Val Acc: 0.773196\n",
      "Epoch 24785 - Train Loss: 0.077545, Train Acc: 0.876923 | Val Loss: 0.111314, Val Acc: 0.773196\n",
      "Epoch 24786 - Train Loss: 0.077544, Train Acc: 0.876923 | Val Loss: 0.111314, Val Acc: 0.773196\n",
      "Epoch 24787 - Train Loss: 0.077542, Train Acc: 0.876923 | Val Loss: 0.111313, Val Acc: 0.773196\n",
      "Epoch 24788 - Train Loss: 0.077541, Train Acc: 0.876923 | Val Loss: 0.111312, Val Acc: 0.773196\n",
      "Epoch 24789 - Train Loss: 0.077539, Train Acc: 0.876923 | Val Loss: 0.111312, Val Acc: 0.773196\n",
      "Epoch 24790 - Train Loss: 0.077538, Train Acc: 0.876923 | Val Loss: 0.111311, Val Acc: 0.773196\n",
      "Epoch 24791 - Train Loss: 0.077536, Train Acc: 0.876923 | Val Loss: 0.111311, Val Acc: 0.773196\n",
      "Epoch 24792 - Train Loss: 0.077534, Train Acc: 0.876923 | Val Loss: 0.111310, Val Acc: 0.773196\n",
      "Epoch 24793 - Train Loss: 0.077533, Train Acc: 0.876923 | Val Loss: 0.111310, Val Acc: 0.773196\n",
      "Epoch 24794 - Train Loss: 0.077531, Train Acc: 0.876923 | Val Loss: 0.111309, Val Acc: 0.773196\n",
      "Epoch 24795 - Train Loss: 0.077530, Train Acc: 0.876923 | Val Loss: 0.111309, Val Acc: 0.773196\n",
      "Epoch 24796 - Train Loss: 0.077528, Train Acc: 0.876923 | Val Loss: 0.111308, Val Acc: 0.773196\n",
      "Epoch 24797 - Train Loss: 0.077526, Train Acc: 0.876923 | Val Loss: 0.111307, Val Acc: 0.773196\n",
      "Epoch 24798 - Train Loss: 0.077525, Train Acc: 0.876923 | Val Loss: 0.111307, Val Acc: 0.773196\n",
      "Epoch 24799 - Train Loss: 0.077523, Train Acc: 0.876923 | Val Loss: 0.111306, Val Acc: 0.773196\n",
      "Epoch 24800 - Train Loss: 0.077522, Train Acc: 0.876923 | Val Loss: 0.111306, Val Acc: 0.773196\n",
      "Epoch 24801 - Train Loss: 0.077520, Train Acc: 0.876923 | Val Loss: 0.111305, Val Acc: 0.773196\n",
      "Epoch 24802 - Train Loss: 0.077518, Train Acc: 0.876923 | Val Loss: 0.111305, Val Acc: 0.773196\n",
      "Epoch 24803 - Train Loss: 0.077517, Train Acc: 0.876923 | Val Loss: 0.111304, Val Acc: 0.773196\n",
      "Epoch 24804 - Train Loss: 0.077515, Train Acc: 0.876923 | Val Loss: 0.111304, Val Acc: 0.773196\n",
      "Epoch 24805 - Train Loss: 0.077514, Train Acc: 0.876923 | Val Loss: 0.111303, Val Acc: 0.773196\n",
      "Epoch 24806 - Train Loss: 0.077512, Train Acc: 0.876923 | Val Loss: 0.111302, Val Acc: 0.773196\n",
      "Epoch 24807 - Train Loss: 0.077510, Train Acc: 0.876923 | Val Loss: 0.111302, Val Acc: 0.773196\n",
      "Epoch 24808 - Train Loss: 0.077509, Train Acc: 0.876923 | Val Loss: 0.111301, Val Acc: 0.773196\n",
      "Epoch 24809 - Train Loss: 0.077507, Train Acc: 0.876923 | Val Loss: 0.111301, Val Acc: 0.773196\n",
      "Epoch 24810 - Train Loss: 0.077506, Train Acc: 0.876923 | Val Loss: 0.111300, Val Acc: 0.773196\n",
      "Epoch 24811 - Train Loss: 0.077504, Train Acc: 0.876923 | Val Loss: 0.111300, Val Acc: 0.773196\n",
      "Epoch 24812 - Train Loss: 0.077502, Train Acc: 0.876923 | Val Loss: 0.111299, Val Acc: 0.773196\n",
      "Epoch 24813 - Train Loss: 0.077501, Train Acc: 0.876923 | Val Loss: 0.111299, Val Acc: 0.773196\n",
      "Epoch 24814 - Train Loss: 0.077499, Train Acc: 0.876923 | Val Loss: 0.111298, Val Acc: 0.773196\n",
      "Epoch 24815 - Train Loss: 0.077498, Train Acc: 0.876923 | Val Loss: 0.111297, Val Acc: 0.773196\n",
      "Epoch 24816 - Train Loss: 0.077496, Train Acc: 0.876923 | Val Loss: 0.111297, Val Acc: 0.773196\n",
      "Epoch 24817 - Train Loss: 0.077494, Train Acc: 0.876923 | Val Loss: 0.111296, Val Acc: 0.773196\n",
      "Epoch 24818 - Train Loss: 0.077493, Train Acc: 0.876923 | Val Loss: 0.111296, Val Acc: 0.773196\n",
      "Epoch 24819 - Train Loss: 0.077491, Train Acc: 0.876923 | Val Loss: 0.111295, Val Acc: 0.773196\n",
      "Epoch 24820 - Train Loss: 0.077490, Train Acc: 0.876923 | Val Loss: 0.111295, Val Acc: 0.773196\n",
      "Epoch 24821 - Train Loss: 0.077488, Train Acc: 0.876923 | Val Loss: 0.111294, Val Acc: 0.773196\n",
      "Epoch 24822 - Train Loss: 0.077486, Train Acc: 0.876923 | Val Loss: 0.111293, Val Acc: 0.773196\n",
      "Epoch 24823 - Train Loss: 0.077485, Train Acc: 0.876923 | Val Loss: 0.111293, Val Acc: 0.773196\n",
      "Epoch 24824 - Train Loss: 0.077483, Train Acc: 0.876923 | Val Loss: 0.111292, Val Acc: 0.773196\n",
      "Epoch 24825 - Train Loss: 0.077482, Train Acc: 0.876923 | Val Loss: 0.111292, Val Acc: 0.773196\n",
      "Epoch 24826 - Train Loss: 0.077480, Train Acc: 0.876923 | Val Loss: 0.111291, Val Acc: 0.773196\n",
      "Epoch 24827 - Train Loss: 0.077478, Train Acc: 0.876923 | Val Loss: 0.111291, Val Acc: 0.773196\n",
      "Epoch 24828 - Train Loss: 0.077477, Train Acc: 0.876923 | Val Loss: 0.111290, Val Acc: 0.773196\n",
      "Epoch 24829 - Train Loss: 0.077475, Train Acc: 0.876923 | Val Loss: 0.111290, Val Acc: 0.773196\n",
      "Epoch 24830 - Train Loss: 0.077474, Train Acc: 0.876923 | Val Loss: 0.111289, Val Acc: 0.773196\n",
      "Epoch 24831 - Train Loss: 0.077472, Train Acc: 0.876923 | Val Loss: 0.111288, Val Acc: 0.773196\n",
      "Epoch 24832 - Train Loss: 0.077471, Train Acc: 0.876923 | Val Loss: 0.111288, Val Acc: 0.773196\n",
      "Epoch 24833 - Train Loss: 0.077469, Train Acc: 0.876923 | Val Loss: 0.111287, Val Acc: 0.773196\n",
      "Epoch 24834 - Train Loss: 0.077467, Train Acc: 0.876923 | Val Loss: 0.111287, Val Acc: 0.773196\n",
      "Epoch 24835 - Train Loss: 0.077466, Train Acc: 0.876923 | Val Loss: 0.111286, Val Acc: 0.773196\n",
      "Epoch 24836 - Train Loss: 0.077464, Train Acc: 0.876923 | Val Loss: 0.111286, Val Acc: 0.773196\n",
      "Epoch 24837 - Train Loss: 0.077463, Train Acc: 0.876923 | Val Loss: 0.111285, Val Acc: 0.773196\n",
      "Epoch 24838 - Train Loss: 0.077461, Train Acc: 0.876923 | Val Loss: 0.111285, Val Acc: 0.773196\n",
      "Epoch 24839 - Train Loss: 0.077459, Train Acc: 0.876923 | Val Loss: 0.111284, Val Acc: 0.773196\n",
      "Epoch 24840 - Train Loss: 0.077458, Train Acc: 0.876923 | Val Loss: 0.111283, Val Acc: 0.773196\n",
      "Epoch 24841 - Train Loss: 0.077456, Train Acc: 0.876923 | Val Loss: 0.111283, Val Acc: 0.773196\n",
      "Epoch 24842 - Train Loss: 0.077455, Train Acc: 0.876923 | Val Loss: 0.111282, Val Acc: 0.773196\n",
      "Epoch 24843 - Train Loss: 0.077453, Train Acc: 0.876923 | Val Loss: 0.111282, Val Acc: 0.773196\n",
      "Epoch 24844 - Train Loss: 0.077451, Train Acc: 0.876923 | Val Loss: 0.111281, Val Acc: 0.773196\n",
      "Epoch 24845 - Train Loss: 0.077450, Train Acc: 0.876923 | Val Loss: 0.111281, Val Acc: 0.773196\n",
      "Epoch 24846 - Train Loss: 0.077448, Train Acc: 0.876923 | Val Loss: 0.111280, Val Acc: 0.773196\n",
      "Epoch 24847 - Train Loss: 0.077447, Train Acc: 0.876923 | Val Loss: 0.111280, Val Acc: 0.773196\n",
      "Epoch 24848 - Train Loss: 0.077445, Train Acc: 0.876923 | Val Loss: 0.111279, Val Acc: 0.773196\n",
      "Epoch 24849 - Train Loss: 0.077443, Train Acc: 0.876923 | Val Loss: 0.111278, Val Acc: 0.773196\n",
      "Epoch 24850 - Train Loss: 0.077442, Train Acc: 0.876923 | Val Loss: 0.111278, Val Acc: 0.773196\n",
      "Epoch 24851 - Train Loss: 0.077440, Train Acc: 0.876923 | Val Loss: 0.111277, Val Acc: 0.773196\n",
      "Epoch 24852 - Train Loss: 0.077439, Train Acc: 0.876923 | Val Loss: 0.111277, Val Acc: 0.773196\n",
      "Epoch 24853 - Train Loss: 0.077437, Train Acc: 0.876923 | Val Loss: 0.111276, Val Acc: 0.773196\n",
      "Epoch 24854 - Train Loss: 0.077435, Train Acc: 0.876923 | Val Loss: 0.111276, Val Acc: 0.773196\n",
      "Epoch 24855 - Train Loss: 0.077434, Train Acc: 0.876923 | Val Loss: 0.111275, Val Acc: 0.773196\n",
      "Epoch 24856 - Train Loss: 0.077432, Train Acc: 0.876923 | Val Loss: 0.111275, Val Acc: 0.773196\n",
      "Epoch 24857 - Train Loss: 0.077431, Train Acc: 0.876923 | Val Loss: 0.111274, Val Acc: 0.773196\n",
      "Epoch 24858 - Train Loss: 0.077429, Train Acc: 0.876923 | Val Loss: 0.111273, Val Acc: 0.773196\n",
      "Epoch 24859 - Train Loss: 0.077428, Train Acc: 0.876923 | Val Loss: 0.111273, Val Acc: 0.773196\n",
      "Epoch 24860 - Train Loss: 0.077426, Train Acc: 0.876923 | Val Loss: 0.111272, Val Acc: 0.773196\n",
      "Epoch 24861 - Train Loss: 0.077424, Train Acc: 0.876923 | Val Loss: 0.111272, Val Acc: 0.773196\n",
      "Epoch 24862 - Train Loss: 0.077423, Train Acc: 0.876923 | Val Loss: 0.111271, Val Acc: 0.773196\n",
      "Epoch 24863 - Train Loss: 0.077421, Train Acc: 0.876923 | Val Loss: 0.111271, Val Acc: 0.773196\n",
      "Epoch 24864 - Train Loss: 0.077420, Train Acc: 0.876923 | Val Loss: 0.111270, Val Acc: 0.773196\n",
      "Epoch 24865 - Train Loss: 0.077418, Train Acc: 0.876923 | Val Loss: 0.111270, Val Acc: 0.773196\n",
      "Epoch 24866 - Train Loss: 0.077416, Train Acc: 0.876923 | Val Loss: 0.111269, Val Acc: 0.773196\n",
      "Epoch 24867 - Train Loss: 0.077415, Train Acc: 0.876923 | Val Loss: 0.111268, Val Acc: 0.773196\n",
      "Epoch 24868 - Train Loss: 0.077413, Train Acc: 0.876923 | Val Loss: 0.111268, Val Acc: 0.773196\n",
      "Epoch 24869 - Train Loss: 0.077412, Train Acc: 0.876923 | Val Loss: 0.111267, Val Acc: 0.773196\n",
      "Epoch 24870 - Train Loss: 0.077410, Train Acc: 0.876923 | Val Loss: 0.111267, Val Acc: 0.773196\n",
      "Epoch 24871 - Train Loss: 0.077408, Train Acc: 0.876923 | Val Loss: 0.111266, Val Acc: 0.773196\n",
      "Epoch 24872 - Train Loss: 0.077407, Train Acc: 0.876923 | Val Loss: 0.111266, Val Acc: 0.773196\n",
      "Epoch 24873 - Train Loss: 0.077405, Train Acc: 0.876923 | Val Loss: 0.111265, Val Acc: 0.773196\n",
      "Epoch 24874 - Train Loss: 0.077404, Train Acc: 0.876923 | Val Loss: 0.111265, Val Acc: 0.773196\n",
      "Epoch 24875 - Train Loss: 0.077402, Train Acc: 0.876923 | Val Loss: 0.111264, Val Acc: 0.773196\n",
      "Epoch 24876 - Train Loss: 0.077401, Train Acc: 0.876923 | Val Loss: 0.111263, Val Acc: 0.773196\n",
      "Epoch 24877 - Train Loss: 0.077399, Train Acc: 0.876923 | Val Loss: 0.111263, Val Acc: 0.773196\n",
      "Epoch 24878 - Train Loss: 0.077397, Train Acc: 0.876923 | Val Loss: 0.111262, Val Acc: 0.773196\n",
      "Epoch 24879 - Train Loss: 0.077396, Train Acc: 0.876923 | Val Loss: 0.111262, Val Acc: 0.773196\n",
      "Epoch 24880 - Train Loss: 0.077394, Train Acc: 0.876923 | Val Loss: 0.111261, Val Acc: 0.773196\n",
      "Epoch 24881 - Train Loss: 0.077393, Train Acc: 0.876923 | Val Loss: 0.111261, Val Acc: 0.773196\n",
      "Epoch 24882 - Train Loss: 0.077391, Train Acc: 0.876923 | Val Loss: 0.111260, Val Acc: 0.773196\n",
      "Epoch 24883 - Train Loss: 0.077389, Train Acc: 0.876923 | Val Loss: 0.111260, Val Acc: 0.773196\n",
      "Epoch 24884 - Train Loss: 0.077388, Train Acc: 0.876923 | Val Loss: 0.111259, Val Acc: 0.773196\n",
      "Epoch 24885 - Train Loss: 0.077386, Train Acc: 0.876923 | Val Loss: 0.111258, Val Acc: 0.773196\n",
      "Epoch 24886 - Train Loss: 0.077385, Train Acc: 0.876923 | Val Loss: 0.111258, Val Acc: 0.773196\n",
      "Epoch 24887 - Train Loss: 0.077383, Train Acc: 0.876923 | Val Loss: 0.111257, Val Acc: 0.773196\n",
      "Epoch 24888 - Train Loss: 0.077381, Train Acc: 0.876923 | Val Loss: 0.111257, Val Acc: 0.773196\n",
      "Epoch 24889 - Train Loss: 0.077380, Train Acc: 0.876923 | Val Loss: 0.111256, Val Acc: 0.773196\n",
      "Epoch 24890 - Train Loss: 0.077378, Train Acc: 0.876923 | Val Loss: 0.111256, Val Acc: 0.773196\n",
      "Epoch 24891 - Train Loss: 0.077377, Train Acc: 0.876923 | Val Loss: 0.111255, Val Acc: 0.773196\n",
      "Epoch 24892 - Train Loss: 0.077375, Train Acc: 0.876923 | Val Loss: 0.111255, Val Acc: 0.773196\n",
      "Epoch 24893 - Train Loss: 0.077374, Train Acc: 0.876923 | Val Loss: 0.111254, Val Acc: 0.773196\n",
      "Epoch 24894 - Train Loss: 0.077372, Train Acc: 0.876923 | Val Loss: 0.111253, Val Acc: 0.773196\n",
      "Epoch 24895 - Train Loss: 0.077370, Train Acc: 0.876923 | Val Loss: 0.111253, Val Acc: 0.773196\n",
      "Epoch 24896 - Train Loss: 0.077369, Train Acc: 0.876923 | Val Loss: 0.111252, Val Acc: 0.773196\n",
      "Epoch 24897 - Train Loss: 0.077367, Train Acc: 0.876923 | Val Loss: 0.111252, Val Acc: 0.773196\n",
      "Epoch 24898 - Train Loss: 0.077366, Train Acc: 0.876923 | Val Loss: 0.111251, Val Acc: 0.773196\n",
      "Epoch 24899 - Train Loss: 0.077364, Train Acc: 0.876923 | Val Loss: 0.111251, Val Acc: 0.773196\n",
      "Epoch 24900 - Train Loss: 0.077362, Train Acc: 0.876923 | Val Loss: 0.111250, Val Acc: 0.773196\n",
      "Epoch 24901 - Train Loss: 0.077361, Train Acc: 0.876923 | Val Loss: 0.111250, Val Acc: 0.773196\n",
      "Epoch 24902 - Train Loss: 0.077359, Train Acc: 0.876923 | Val Loss: 0.111249, Val Acc: 0.773196\n",
      "Epoch 24903 - Train Loss: 0.077358, Train Acc: 0.876923 | Val Loss: 0.111249, Val Acc: 0.773196\n",
      "Epoch 24904 - Train Loss: 0.077356, Train Acc: 0.876923 | Val Loss: 0.111248, Val Acc: 0.773196\n",
      "Epoch 24905 - Train Loss: 0.077354, Train Acc: 0.876923 | Val Loss: 0.111247, Val Acc: 0.773196\n",
      "Epoch 24906 - Train Loss: 0.077353, Train Acc: 0.876923 | Val Loss: 0.111247, Val Acc: 0.773196\n",
      "Epoch 24907 - Train Loss: 0.077351, Train Acc: 0.876923 | Val Loss: 0.111246, Val Acc: 0.773196\n",
      "Epoch 24908 - Train Loss: 0.077350, Train Acc: 0.876923 | Val Loss: 0.111246, Val Acc: 0.773196\n",
      "Epoch 24909 - Train Loss: 0.077348, Train Acc: 0.876923 | Val Loss: 0.111245, Val Acc: 0.773196\n",
      "Epoch 24910 - Train Loss: 0.077347, Train Acc: 0.876923 | Val Loss: 0.111245, Val Acc: 0.773196\n",
      "Epoch 24911 - Train Loss: 0.077345, Train Acc: 0.876923 | Val Loss: 0.111244, Val Acc: 0.773196\n",
      "Epoch 24912 - Train Loss: 0.077343, Train Acc: 0.876923 | Val Loss: 0.111244, Val Acc: 0.773196\n",
      "Epoch 24913 - Train Loss: 0.077342, Train Acc: 0.876923 | Val Loss: 0.111243, Val Acc: 0.773196\n",
      "Epoch 24914 - Train Loss: 0.077340, Train Acc: 0.876923 | Val Loss: 0.111242, Val Acc: 0.773196\n",
      "Epoch 24915 - Train Loss: 0.077339, Train Acc: 0.876923 | Val Loss: 0.111242, Val Acc: 0.773196\n",
      "Epoch 24916 - Train Loss: 0.077337, Train Acc: 0.876923 | Val Loss: 0.111241, Val Acc: 0.773196\n",
      "Epoch 24917 - Train Loss: 0.077335, Train Acc: 0.876923 | Val Loss: 0.111241, Val Acc: 0.773196\n",
      "Epoch 24918 - Train Loss: 0.077334, Train Acc: 0.876923 | Val Loss: 0.111240, Val Acc: 0.773196\n",
      "Epoch 24919 - Train Loss: 0.077332, Train Acc: 0.876923 | Val Loss: 0.111240, Val Acc: 0.773196\n",
      "Epoch 24920 - Train Loss: 0.077331, Train Acc: 0.876923 | Val Loss: 0.111239, Val Acc: 0.773196\n",
      "Epoch 24921 - Train Loss: 0.077329, Train Acc: 0.876923 | Val Loss: 0.111239, Val Acc: 0.773196\n",
      "Epoch 24922 - Train Loss: 0.077328, Train Acc: 0.876923 | Val Loss: 0.111238, Val Acc: 0.773196\n",
      "Epoch 24923 - Train Loss: 0.077326, Train Acc: 0.876923 | Val Loss: 0.111238, Val Acc: 0.773196\n",
      "Epoch 24924 - Train Loss: 0.077324, Train Acc: 0.876923 | Val Loss: 0.111237, Val Acc: 0.773196\n",
      "Epoch 24925 - Train Loss: 0.077323, Train Acc: 0.876923 | Val Loss: 0.111236, Val Acc: 0.773196\n",
      "Epoch 24926 - Train Loss: 0.077321, Train Acc: 0.876923 | Val Loss: 0.111236, Val Acc: 0.773196\n",
      "Epoch 24927 - Train Loss: 0.077320, Train Acc: 0.876923 | Val Loss: 0.111235, Val Acc: 0.773196\n",
      "Epoch 24928 - Train Loss: 0.077318, Train Acc: 0.876923 | Val Loss: 0.111235, Val Acc: 0.773196\n",
      "Epoch 24929 - Train Loss: 0.077316, Train Acc: 0.876923 | Val Loss: 0.111234, Val Acc: 0.773196\n",
      "Epoch 24930 - Train Loss: 0.077315, Train Acc: 0.876923 | Val Loss: 0.111234, Val Acc: 0.773196\n",
      "Epoch 24931 - Train Loss: 0.077313, Train Acc: 0.876923 | Val Loss: 0.111233, Val Acc: 0.773196\n",
      "Epoch 24932 - Train Loss: 0.077312, Train Acc: 0.876923 | Val Loss: 0.111233, Val Acc: 0.773196\n",
      "Epoch 24933 - Train Loss: 0.077310, Train Acc: 0.876923 | Val Loss: 0.111232, Val Acc: 0.773196\n",
      "Epoch 24934 - Train Loss: 0.077309, Train Acc: 0.876923 | Val Loss: 0.111231, Val Acc: 0.773196\n",
      "Epoch 24935 - Train Loss: 0.077307, Train Acc: 0.876923 | Val Loss: 0.111231, Val Acc: 0.773196\n",
      "Epoch 24936 - Train Loss: 0.077305, Train Acc: 0.876923 | Val Loss: 0.111230, Val Acc: 0.773196\n",
      "Epoch 24937 - Train Loss: 0.077304, Train Acc: 0.876923 | Val Loss: 0.111230, Val Acc: 0.773196\n",
      "Epoch 24938 - Train Loss: 0.077302, Train Acc: 0.876923 | Val Loss: 0.111229, Val Acc: 0.773196\n",
      "Epoch 24939 - Train Loss: 0.077301, Train Acc: 0.876923 | Val Loss: 0.111229, Val Acc: 0.773196\n",
      "Epoch 24940 - Train Loss: 0.077299, Train Acc: 0.876923 | Val Loss: 0.111228, Val Acc: 0.773196\n",
      "Epoch 24941 - Train Loss: 0.077297, Train Acc: 0.876923 | Val Loss: 0.111228, Val Acc: 0.773196\n",
      "Epoch 24942 - Train Loss: 0.077296, Train Acc: 0.876923 | Val Loss: 0.111227, Val Acc: 0.773196\n",
      "Epoch 24943 - Train Loss: 0.077294, Train Acc: 0.876923 | Val Loss: 0.111227, Val Acc: 0.773196\n",
      "Epoch 24944 - Train Loss: 0.077293, Train Acc: 0.876923 | Val Loss: 0.111226, Val Acc: 0.773196\n",
      "Epoch 24945 - Train Loss: 0.077291, Train Acc: 0.876923 | Val Loss: 0.111225, Val Acc: 0.773196\n",
      "Epoch 24946 - Train Loss: 0.077290, Train Acc: 0.876923 | Val Loss: 0.111225, Val Acc: 0.773196\n",
      "Epoch 24947 - Train Loss: 0.077288, Train Acc: 0.876923 | Val Loss: 0.111224, Val Acc: 0.773196\n",
      "Epoch 24948 - Train Loss: 0.077286, Train Acc: 0.876923 | Val Loss: 0.111224, Val Acc: 0.773196\n",
      "Epoch 24949 - Train Loss: 0.077285, Train Acc: 0.876923 | Val Loss: 0.111223, Val Acc: 0.773196\n",
      "Epoch 24950 - Train Loss: 0.077283, Train Acc: 0.876923 | Val Loss: 0.111223, Val Acc: 0.773196\n",
      "Epoch 24951 - Train Loss: 0.077282, Train Acc: 0.876923 | Val Loss: 0.111222, Val Acc: 0.773196\n",
      "Epoch 24952 - Train Loss: 0.077280, Train Acc: 0.876923 | Val Loss: 0.111222, Val Acc: 0.773196\n",
      "Epoch 24953 - Train Loss: 0.077278, Train Acc: 0.876923 | Val Loss: 0.111221, Val Acc: 0.773196\n",
      "Epoch 24954 - Train Loss: 0.077277, Train Acc: 0.876923 | Val Loss: 0.111221, Val Acc: 0.773196\n",
      "Epoch 24955 - Train Loss: 0.077275, Train Acc: 0.876923 | Val Loss: 0.111220, Val Acc: 0.773196\n",
      "Epoch 24956 - Train Loss: 0.077274, Train Acc: 0.876923 | Val Loss: 0.111219, Val Acc: 0.773196\n",
      "Epoch 24957 - Train Loss: 0.077272, Train Acc: 0.876923 | Val Loss: 0.111219, Val Acc: 0.773196\n",
      "Epoch 24958 - Train Loss: 0.077271, Train Acc: 0.876923 | Val Loss: 0.111218, Val Acc: 0.773196\n",
      "Epoch 24959 - Train Loss: 0.077269, Train Acc: 0.876923 | Val Loss: 0.111218, Val Acc: 0.773196\n",
      "Epoch 24960 - Train Loss: 0.077267, Train Acc: 0.876923 | Val Loss: 0.111217, Val Acc: 0.773196\n",
      "Epoch 24961 - Train Loss: 0.077266, Train Acc: 0.876923 | Val Loss: 0.111217, Val Acc: 0.773196\n",
      "Epoch 24962 - Train Loss: 0.077264, Train Acc: 0.876923 | Val Loss: 0.111216, Val Acc: 0.773196\n",
      "Epoch 24963 - Train Loss: 0.077263, Train Acc: 0.876923 | Val Loss: 0.111216, Val Acc: 0.773196\n",
      "Epoch 24964 - Train Loss: 0.077261, Train Acc: 0.876923 | Val Loss: 0.111215, Val Acc: 0.773196\n",
      "Epoch 24965 - Train Loss: 0.077259, Train Acc: 0.876923 | Val Loss: 0.111214, Val Acc: 0.773196\n",
      "Epoch 24966 - Train Loss: 0.077258, Train Acc: 0.876923 | Val Loss: 0.111214, Val Acc: 0.773196\n",
      "Epoch 24967 - Train Loss: 0.077256, Train Acc: 0.876923 | Val Loss: 0.111213, Val Acc: 0.773196\n",
      "Epoch 24968 - Train Loss: 0.077255, Train Acc: 0.876923 | Val Loss: 0.111213, Val Acc: 0.773196\n",
      "Epoch 24969 - Train Loss: 0.077253, Train Acc: 0.876923 | Val Loss: 0.111212, Val Acc: 0.773196\n",
      "Epoch 24970 - Train Loss: 0.077252, Train Acc: 0.876923 | Val Loss: 0.111212, Val Acc: 0.773196\n",
      "Epoch 24971 - Train Loss: 0.077250, Train Acc: 0.876923 | Val Loss: 0.111211, Val Acc: 0.773196\n",
      "Epoch 24972 - Train Loss: 0.077248, Train Acc: 0.876923 | Val Loss: 0.111211, Val Acc: 0.773196\n",
      "Epoch 24973 - Train Loss: 0.077247, Train Acc: 0.876923 | Val Loss: 0.111210, Val Acc: 0.773196\n",
      "Epoch 24974 - Train Loss: 0.077245, Train Acc: 0.876923 | Val Loss: 0.111210, Val Acc: 0.773196\n",
      "Epoch 24975 - Train Loss: 0.077244, Train Acc: 0.876923 | Val Loss: 0.111209, Val Acc: 0.773196\n",
      "Epoch 24976 - Train Loss: 0.077242, Train Acc: 0.876923 | Val Loss: 0.111208, Val Acc: 0.773196\n",
      "Epoch 24977 - Train Loss: 0.077241, Train Acc: 0.876923 | Val Loss: 0.111208, Val Acc: 0.773196\n",
      "Epoch 24978 - Train Loss: 0.077239, Train Acc: 0.876923 | Val Loss: 0.111207, Val Acc: 0.773196\n",
      "Epoch 24979 - Train Loss: 0.077237, Train Acc: 0.876923 | Val Loss: 0.111207, Val Acc: 0.773196\n",
      "Epoch 24980 - Train Loss: 0.077236, Train Acc: 0.876923 | Val Loss: 0.111206, Val Acc: 0.773196\n",
      "Epoch 24981 - Train Loss: 0.077234, Train Acc: 0.876923 | Val Loss: 0.111206, Val Acc: 0.773196\n",
      "Epoch 24982 - Train Loss: 0.077233, Train Acc: 0.876923 | Val Loss: 0.111205, Val Acc: 0.773196\n",
      "Epoch 24983 - Train Loss: 0.077231, Train Acc: 0.876923 | Val Loss: 0.111205, Val Acc: 0.773196\n",
      "Epoch 24984 - Train Loss: 0.077229, Train Acc: 0.876923 | Val Loss: 0.111204, Val Acc: 0.773196\n",
      "Epoch 24985 - Train Loss: 0.077228, Train Acc: 0.876923 | Val Loss: 0.111204, Val Acc: 0.773196\n",
      "Epoch 24986 - Train Loss: 0.077226, Train Acc: 0.876923 | Val Loss: 0.111203, Val Acc: 0.773196\n",
      "Epoch 24987 - Train Loss: 0.077225, Train Acc: 0.876923 | Val Loss: 0.111202, Val Acc: 0.773196\n",
      "Epoch 24988 - Train Loss: 0.077223, Train Acc: 0.876923 | Val Loss: 0.111202, Val Acc: 0.773196\n",
      "Epoch 24989 - Train Loss: 0.077222, Train Acc: 0.876923 | Val Loss: 0.111201, Val Acc: 0.773196\n",
      "Epoch 24990 - Train Loss: 0.077220, Train Acc: 0.876923 | Val Loss: 0.111201, Val Acc: 0.773196\n",
      "Epoch 24991 - Train Loss: 0.077218, Train Acc: 0.876923 | Val Loss: 0.111200, Val Acc: 0.773196\n",
      "Epoch 24992 - Train Loss: 0.077217, Train Acc: 0.876923 | Val Loss: 0.111200, Val Acc: 0.773196\n",
      "Epoch 24993 - Train Loss: 0.077215, Train Acc: 0.876923 | Val Loss: 0.111199, Val Acc: 0.773196\n",
      "Epoch 24994 - Train Loss: 0.077214, Train Acc: 0.876923 | Val Loss: 0.111199, Val Acc: 0.773196\n",
      "Epoch 24995 - Train Loss: 0.077212, Train Acc: 0.876923 | Val Loss: 0.111198, Val Acc: 0.773196\n",
      "Epoch 24996 - Train Loss: 0.077211, Train Acc: 0.876923 | Val Loss: 0.111198, Val Acc: 0.773196\n",
      "Epoch 24997 - Train Loss: 0.077209, Train Acc: 0.876923 | Val Loss: 0.111197, Val Acc: 0.773196\n",
      "Epoch 24998 - Train Loss: 0.077207, Train Acc: 0.876923 | Val Loss: 0.111197, Val Acc: 0.773196\n",
      "Epoch 24999 - Train Loss: 0.077206, Train Acc: 0.876923 | Val Loss: 0.111196, Val Acc: 0.773196\n",
      "Epoch 25000 - Train Loss: 0.077204, Train Acc: 0.876923 | Val Loss: 0.111195, Val Acc: 0.773196\n",
      "Epoch 25001 - Train Loss: 0.077203, Train Acc: 0.876923 | Val Loss: 0.111195, Val Acc: 0.773196\n",
      "Epoch 25002 - Train Loss: 0.077201, Train Acc: 0.876923 | Val Loss: 0.111194, Val Acc: 0.773196\n",
      "Epoch 25003 - Train Loss: 0.077200, Train Acc: 0.876923 | Val Loss: 0.111194, Val Acc: 0.773196\n",
      "Epoch 25004 - Train Loss: 0.077198, Train Acc: 0.876923 | Val Loss: 0.111193, Val Acc: 0.773196\n",
      "Epoch 25005 - Train Loss: 0.077196, Train Acc: 0.876923 | Val Loss: 0.111193, Val Acc: 0.773196\n",
      "Epoch 25006 - Train Loss: 0.077195, Train Acc: 0.876923 | Val Loss: 0.111192, Val Acc: 0.773196\n",
      "Epoch 25007 - Train Loss: 0.077193, Train Acc: 0.876923 | Val Loss: 0.111192, Val Acc: 0.773196\n",
      "Epoch 25008 - Train Loss: 0.077192, Train Acc: 0.876923 | Val Loss: 0.111191, Val Acc: 0.773196\n",
      "Epoch 25009 - Train Loss: 0.077190, Train Acc: 0.876923 | Val Loss: 0.111191, Val Acc: 0.773196\n",
      "Epoch 25010 - Train Loss: 0.077188, Train Acc: 0.876923 | Val Loss: 0.111190, Val Acc: 0.773196\n",
      "Epoch 25011 - Train Loss: 0.077187, Train Acc: 0.876923 | Val Loss: 0.111189, Val Acc: 0.773196\n",
      "Epoch 25012 - Train Loss: 0.077185, Train Acc: 0.876923 | Val Loss: 0.111189, Val Acc: 0.773196\n",
      "Epoch 25013 - Train Loss: 0.077184, Train Acc: 0.876923 | Val Loss: 0.111188, Val Acc: 0.773196\n",
      "Epoch 25014 - Train Loss: 0.077182, Train Acc: 0.876923 | Val Loss: 0.111188, Val Acc: 0.773196\n",
      "Epoch 25015 - Train Loss: 0.077181, Train Acc: 0.876923 | Val Loss: 0.111187, Val Acc: 0.773196\n",
      "Epoch 25016 - Train Loss: 0.077179, Train Acc: 0.876923 | Val Loss: 0.111187, Val Acc: 0.773196\n",
      "Epoch 25017 - Train Loss: 0.077177, Train Acc: 0.876923 | Val Loss: 0.111186, Val Acc: 0.773196\n",
      "Epoch 25018 - Train Loss: 0.077176, Train Acc: 0.876923 | Val Loss: 0.111186, Val Acc: 0.773196\n",
      "Epoch 25019 - Train Loss: 0.077174, Train Acc: 0.876923 | Val Loss: 0.111185, Val Acc: 0.773196\n",
      "Epoch 25020 - Train Loss: 0.077173, Train Acc: 0.876923 | Val Loss: 0.111185, Val Acc: 0.773196\n",
      "Epoch 25021 - Train Loss: 0.077171, Train Acc: 0.876923 | Val Loss: 0.111184, Val Acc: 0.773196\n",
      "Epoch 25022 - Train Loss: 0.077170, Train Acc: 0.876923 | Val Loss: 0.111183, Val Acc: 0.773196\n",
      "Epoch 25023 - Train Loss: 0.077168, Train Acc: 0.876923 | Val Loss: 0.111183, Val Acc: 0.773196\n",
      "Epoch 25024 - Train Loss: 0.077166, Train Acc: 0.876923 | Val Loss: 0.111182, Val Acc: 0.773196\n",
      "Epoch 25025 - Train Loss: 0.077165, Train Acc: 0.876923 | Val Loss: 0.111182, Val Acc: 0.773196\n",
      "Epoch 25026 - Train Loss: 0.077163, Train Acc: 0.876923 | Val Loss: 0.111181, Val Acc: 0.773196\n",
      "Epoch 25027 - Train Loss: 0.077162, Train Acc: 0.876923 | Val Loss: 0.111181, Val Acc: 0.773196\n",
      "Epoch 25028 - Train Loss: 0.077160, Train Acc: 0.876923 | Val Loss: 0.111180, Val Acc: 0.773196\n",
      "Epoch 25029 - Train Loss: 0.077159, Train Acc: 0.876923 | Val Loss: 0.111180, Val Acc: 0.773196\n",
      "Epoch 25030 - Train Loss: 0.077157, Train Acc: 0.876923 | Val Loss: 0.111179, Val Acc: 0.773196\n",
      "Epoch 25031 - Train Loss: 0.077155, Train Acc: 0.876923 | Val Loss: 0.111179, Val Acc: 0.773196\n",
      "Epoch 25032 - Train Loss: 0.077154, Train Acc: 0.876923 | Val Loss: 0.111178, Val Acc: 0.773196\n",
      "Epoch 25033 - Train Loss: 0.077152, Train Acc: 0.876923 | Val Loss: 0.111178, Val Acc: 0.773196\n",
      "Epoch 25034 - Train Loss: 0.077151, Train Acc: 0.876923 | Val Loss: 0.111177, Val Acc: 0.773196\n",
      "Epoch 25035 - Train Loss: 0.077149, Train Acc: 0.876923 | Val Loss: 0.111176, Val Acc: 0.773196\n",
      "Epoch 25036 - Train Loss: 0.077148, Train Acc: 0.876923 | Val Loss: 0.111176, Val Acc: 0.773196\n",
      "Epoch 25037 - Train Loss: 0.077146, Train Acc: 0.876923 | Val Loss: 0.111175, Val Acc: 0.773196\n",
      "Epoch 25038 - Train Loss: 0.077144, Train Acc: 0.876923 | Val Loss: 0.111175, Val Acc: 0.773196\n",
      "Epoch 25039 - Train Loss: 0.077143, Train Acc: 0.876923 | Val Loss: 0.111174, Val Acc: 0.773196\n",
      "Epoch 25040 - Train Loss: 0.077141, Train Acc: 0.876923 | Val Loss: 0.111174, Val Acc: 0.773196\n",
      "Epoch 25041 - Train Loss: 0.077140, Train Acc: 0.876923 | Val Loss: 0.111173, Val Acc: 0.773196\n",
      "Epoch 25042 - Train Loss: 0.077138, Train Acc: 0.876923 | Val Loss: 0.111173, Val Acc: 0.773196\n",
      "Epoch 25043 - Train Loss: 0.077137, Train Acc: 0.876923 | Val Loss: 0.111172, Val Acc: 0.773196\n",
      "Epoch 25044 - Train Loss: 0.077135, Train Acc: 0.876923 | Val Loss: 0.111172, Val Acc: 0.773196\n",
      "Epoch 25045 - Train Loss: 0.077133, Train Acc: 0.876923 | Val Loss: 0.111171, Val Acc: 0.773196\n",
      "Epoch 25046 - Train Loss: 0.077132, Train Acc: 0.876923 | Val Loss: 0.111170, Val Acc: 0.773196\n",
      "Epoch 25047 - Train Loss: 0.077130, Train Acc: 0.876923 | Val Loss: 0.111170, Val Acc: 0.773196\n",
      "Epoch 25048 - Train Loss: 0.077129, Train Acc: 0.876923 | Val Loss: 0.111169, Val Acc: 0.773196\n",
      "Epoch 25049 - Train Loss: 0.077127, Train Acc: 0.876923 | Val Loss: 0.111169, Val Acc: 0.773196\n",
      "Epoch 25050 - Train Loss: 0.077125, Train Acc: 0.876923 | Val Loss: 0.111168, Val Acc: 0.773196\n",
      "Epoch 25051 - Train Loss: 0.077124, Train Acc: 0.876923 | Val Loss: 0.111168, Val Acc: 0.773196\n",
      "Epoch 25052 - Train Loss: 0.077122, Train Acc: 0.876923 | Val Loss: 0.111167, Val Acc: 0.773196\n",
      "Epoch 25053 - Train Loss: 0.077121, Train Acc: 0.876923 | Val Loss: 0.111167, Val Acc: 0.773196\n",
      "Epoch 25054 - Train Loss: 0.077119, Train Acc: 0.876923 | Val Loss: 0.111166, Val Acc: 0.773196\n",
      "Epoch 25055 - Train Loss: 0.077118, Train Acc: 0.876923 | Val Loss: 0.111166, Val Acc: 0.773196\n",
      "Epoch 25056 - Train Loss: 0.077116, Train Acc: 0.876923 | Val Loss: 0.111165, Val Acc: 0.773196\n",
      "Epoch 25057 - Train Loss: 0.077114, Train Acc: 0.876923 | Val Loss: 0.111165, Val Acc: 0.773196\n",
      "Epoch 25058 - Train Loss: 0.077113, Train Acc: 0.876923 | Val Loss: 0.111164, Val Acc: 0.773196\n",
      "Epoch 25059 - Train Loss: 0.077111, Train Acc: 0.876923 | Val Loss: 0.111163, Val Acc: 0.773196\n",
      "Epoch 25060 - Train Loss: 0.077110, Train Acc: 0.876923 | Val Loss: 0.111163, Val Acc: 0.773196\n",
      "Epoch 25061 - Train Loss: 0.077108, Train Acc: 0.876923 | Val Loss: 0.111162, Val Acc: 0.773196\n",
      "Epoch 25062 - Train Loss: 0.077107, Train Acc: 0.876923 | Val Loss: 0.111162, Val Acc: 0.773196\n",
      "Epoch 25063 - Train Loss: 0.077105, Train Acc: 0.876923 | Val Loss: 0.111161, Val Acc: 0.773196\n",
      "Epoch 25064 - Train Loss: 0.077103, Train Acc: 0.876923 | Val Loss: 0.111161, Val Acc: 0.773196\n",
      "Epoch 25065 - Train Loss: 0.077102, Train Acc: 0.876923 | Val Loss: 0.111160, Val Acc: 0.773196\n",
      "Epoch 25066 - Train Loss: 0.077100, Train Acc: 0.876923 | Val Loss: 0.111160, Val Acc: 0.773196\n",
      "Epoch 25067 - Train Loss: 0.077099, Train Acc: 0.876923 | Val Loss: 0.111159, Val Acc: 0.773196\n",
      "Epoch 25068 - Train Loss: 0.077097, Train Acc: 0.876923 | Val Loss: 0.111159, Val Acc: 0.773196\n",
      "Epoch 25069 - Train Loss: 0.077096, Train Acc: 0.876923 | Val Loss: 0.111158, Val Acc: 0.773196\n",
      "Epoch 25070 - Train Loss: 0.077094, Train Acc: 0.876923 | Val Loss: 0.111158, Val Acc: 0.773196\n",
      "Epoch 25071 - Train Loss: 0.077092, Train Acc: 0.876923 | Val Loss: 0.111157, Val Acc: 0.773196\n",
      "Epoch 25072 - Train Loss: 0.077091, Train Acc: 0.876923 | Val Loss: 0.111156, Val Acc: 0.773196\n",
      "Epoch 25073 - Train Loss: 0.077089, Train Acc: 0.876923 | Val Loss: 0.111156, Val Acc: 0.773196\n",
      "Epoch 25074 - Train Loss: 0.077088, Train Acc: 0.876923 | Val Loss: 0.111155, Val Acc: 0.773196\n",
      "Epoch 25075 - Train Loss: 0.077086, Train Acc: 0.876923 | Val Loss: 0.111155, Val Acc: 0.773196\n",
      "Epoch 25076 - Train Loss: 0.077085, Train Acc: 0.876923 | Val Loss: 0.111154, Val Acc: 0.773196\n",
      "Epoch 25077 - Train Loss: 0.077083, Train Acc: 0.876923 | Val Loss: 0.111154, Val Acc: 0.773196\n",
      "Epoch 25078 - Train Loss: 0.077082, Train Acc: 0.876923 | Val Loss: 0.111153, Val Acc: 0.773196\n",
      "Epoch 25079 - Train Loss: 0.077080, Train Acc: 0.876923 | Val Loss: 0.111153, Val Acc: 0.773196\n",
      "Epoch 25080 - Train Loss: 0.077078, Train Acc: 0.876923 | Val Loss: 0.111152, Val Acc: 0.773196\n",
      "Epoch 25081 - Train Loss: 0.077077, Train Acc: 0.876923 | Val Loss: 0.111152, Val Acc: 0.773196\n",
      "Epoch 25082 - Train Loss: 0.077075, Train Acc: 0.876923 | Val Loss: 0.111151, Val Acc: 0.773196\n",
      "Epoch 25083 - Train Loss: 0.077074, Train Acc: 0.876923 | Val Loss: 0.111151, Val Acc: 0.773196\n",
      "Epoch 25084 - Train Loss: 0.077072, Train Acc: 0.876923 | Val Loss: 0.111150, Val Acc: 0.773196\n",
      "Epoch 25085 - Train Loss: 0.077071, Train Acc: 0.876923 | Val Loss: 0.111149, Val Acc: 0.773196\n",
      "Epoch 25086 - Train Loss: 0.077069, Train Acc: 0.876923 | Val Loss: 0.111149, Val Acc: 0.773196\n",
      "Epoch 25087 - Train Loss: 0.077067, Train Acc: 0.876923 | Val Loss: 0.111148, Val Acc: 0.773196\n",
      "Epoch 25088 - Train Loss: 0.077066, Train Acc: 0.876923 | Val Loss: 0.111148, Val Acc: 0.773196\n",
      "Epoch 25089 - Train Loss: 0.077064, Train Acc: 0.876923 | Val Loss: 0.111147, Val Acc: 0.773196\n",
      "Epoch 25090 - Train Loss: 0.077063, Train Acc: 0.876923 | Val Loss: 0.111147, Val Acc: 0.773196\n",
      "Epoch 25091 - Train Loss: 0.077061, Train Acc: 0.876923 | Val Loss: 0.111146, Val Acc: 0.773196\n",
      "Epoch 25092 - Train Loss: 0.077060, Train Acc: 0.876923 | Val Loss: 0.111146, Val Acc: 0.773196\n",
      "Epoch 25093 - Train Loss: 0.077058, Train Acc: 0.876923 | Val Loss: 0.111145, Val Acc: 0.773196\n",
      "Epoch 25094 - Train Loss: 0.077056, Train Acc: 0.876923 | Val Loss: 0.111145, Val Acc: 0.773196\n",
      "Epoch 25095 - Train Loss: 0.077055, Train Acc: 0.876923 | Val Loss: 0.111144, Val Acc: 0.773196\n",
      "Epoch 25096 - Train Loss: 0.077053, Train Acc: 0.876923 | Val Loss: 0.111144, Val Acc: 0.773196\n",
      "Epoch 25097 - Train Loss: 0.077052, Train Acc: 0.876923 | Val Loss: 0.111143, Val Acc: 0.773196\n",
      "Epoch 25098 - Train Loss: 0.077050, Train Acc: 0.876923 | Val Loss: 0.111142, Val Acc: 0.773196\n",
      "Epoch 25099 - Train Loss: 0.077049, Train Acc: 0.876923 | Val Loss: 0.111142, Val Acc: 0.773196\n",
      "Epoch 25100 - Train Loss: 0.077047, Train Acc: 0.876923 | Val Loss: 0.111141, Val Acc: 0.773196\n",
      "Epoch 25101 - Train Loss: 0.077045, Train Acc: 0.876923 | Val Loss: 0.111141, Val Acc: 0.773196\n",
      "Epoch 25102 - Train Loss: 0.077044, Train Acc: 0.876923 | Val Loss: 0.111140, Val Acc: 0.773196\n",
      "Epoch 25103 - Train Loss: 0.077042, Train Acc: 0.876923 | Val Loss: 0.111140, Val Acc: 0.773196\n",
      "Epoch 25104 - Train Loss: 0.077041, Train Acc: 0.876923 | Val Loss: 0.111139, Val Acc: 0.773196\n",
      "Epoch 25105 - Train Loss: 0.077039, Train Acc: 0.876923 | Val Loss: 0.111139, Val Acc: 0.773196\n",
      "Epoch 25106 - Train Loss: 0.077038, Train Acc: 0.876923 | Val Loss: 0.111138, Val Acc: 0.773196\n",
      "Epoch 25107 - Train Loss: 0.077036, Train Acc: 0.876923 | Val Loss: 0.111138, Val Acc: 0.773196\n",
      "Epoch 25108 - Train Loss: 0.077034, Train Acc: 0.876923 | Val Loss: 0.111137, Val Acc: 0.773196\n",
      "Epoch 25109 - Train Loss: 0.077033, Train Acc: 0.876923 | Val Loss: 0.111137, Val Acc: 0.773196\n",
      "Epoch 25110 - Train Loss: 0.077031, Train Acc: 0.876923 | Val Loss: 0.111136, Val Acc: 0.773196\n",
      "Epoch 25111 - Train Loss: 0.077030, Train Acc: 0.876923 | Val Loss: 0.111136, Val Acc: 0.773196\n",
      "Epoch 25112 - Train Loss: 0.077028, Train Acc: 0.876923 | Val Loss: 0.111135, Val Acc: 0.773196\n",
      "Epoch 25113 - Train Loss: 0.077027, Train Acc: 0.876923 | Val Loss: 0.111134, Val Acc: 0.773196\n",
      "Epoch 25114 - Train Loss: 0.077025, Train Acc: 0.876923 | Val Loss: 0.111134, Val Acc: 0.773196\n",
      "Epoch 25115 - Train Loss: 0.077023, Train Acc: 0.876923 | Val Loss: 0.111133, Val Acc: 0.773196\n",
      "Epoch 25116 - Train Loss: 0.077022, Train Acc: 0.876923 | Val Loss: 0.111133, Val Acc: 0.773196\n",
      "Epoch 25117 - Train Loss: 0.077020, Train Acc: 0.876923 | Val Loss: 0.111132, Val Acc: 0.773196\n",
      "Epoch 25118 - Train Loss: 0.077019, Train Acc: 0.876923 | Val Loss: 0.111132, Val Acc: 0.773196\n",
      "Epoch 25119 - Train Loss: 0.077017, Train Acc: 0.876923 | Val Loss: 0.111131, Val Acc: 0.773196\n",
      "Epoch 25120 - Train Loss: 0.077016, Train Acc: 0.876923 | Val Loss: 0.111131, Val Acc: 0.773196\n",
      "Epoch 25121 - Train Loss: 0.077014, Train Acc: 0.876923 | Val Loss: 0.111130, Val Acc: 0.773196\n",
      "Epoch 25122 - Train Loss: 0.077013, Train Acc: 0.876923 | Val Loss: 0.111130, Val Acc: 0.773196\n",
      "Epoch 25123 - Train Loss: 0.077011, Train Acc: 0.876923 | Val Loss: 0.111129, Val Acc: 0.773196\n",
      "Epoch 25124 - Train Loss: 0.077009, Train Acc: 0.876923 | Val Loss: 0.111129, Val Acc: 0.773196\n",
      "Epoch 25125 - Train Loss: 0.077008, Train Acc: 0.876923 | Val Loss: 0.111128, Val Acc: 0.773196\n",
      "Epoch 25126 - Train Loss: 0.077006, Train Acc: 0.876923 | Val Loss: 0.111127, Val Acc: 0.773196\n",
      "Epoch 25127 - Train Loss: 0.077005, Train Acc: 0.876923 | Val Loss: 0.111127, Val Acc: 0.773196\n",
      "Epoch 25128 - Train Loss: 0.077003, Train Acc: 0.876923 | Val Loss: 0.111126, Val Acc: 0.773196\n",
      "Epoch 25129 - Train Loss: 0.077002, Train Acc: 0.876923 | Val Loss: 0.111126, Val Acc: 0.773196\n",
      "Epoch 25130 - Train Loss: 0.077000, Train Acc: 0.876923 | Val Loss: 0.111125, Val Acc: 0.773196\n",
      "Epoch 25131 - Train Loss: 0.076998, Train Acc: 0.876923 | Val Loss: 0.111125, Val Acc: 0.773196\n",
      "Epoch 25132 - Train Loss: 0.076997, Train Acc: 0.876923 | Val Loss: 0.111124, Val Acc: 0.773196\n",
      "Epoch 25133 - Train Loss: 0.076995, Train Acc: 0.876923 | Val Loss: 0.111124, Val Acc: 0.773196\n",
      "Epoch 25134 - Train Loss: 0.076994, Train Acc: 0.876923 | Val Loss: 0.111123, Val Acc: 0.773196\n",
      "Epoch 25135 - Train Loss: 0.076992, Train Acc: 0.876923 | Val Loss: 0.111123, Val Acc: 0.773196\n",
      "Epoch 25136 - Train Loss: 0.076991, Train Acc: 0.876923 | Val Loss: 0.111122, Val Acc: 0.773196\n",
      "Epoch 25137 - Train Loss: 0.076989, Train Acc: 0.876923 | Val Loss: 0.111122, Val Acc: 0.773196\n",
      "Epoch 25138 - Train Loss: 0.076987, Train Acc: 0.876923 | Val Loss: 0.111121, Val Acc: 0.773196\n",
      "Epoch 25139 - Train Loss: 0.076986, Train Acc: 0.876923 | Val Loss: 0.111121, Val Acc: 0.773196\n",
      "Epoch 25140 - Train Loss: 0.076984, Train Acc: 0.876923 | Val Loss: 0.111120, Val Acc: 0.773196\n",
      "Epoch 25141 - Train Loss: 0.076983, Train Acc: 0.876923 | Val Loss: 0.111119, Val Acc: 0.773196\n",
      "Epoch 25142 - Train Loss: 0.076981, Train Acc: 0.876923 | Val Loss: 0.111119, Val Acc: 0.773196\n",
      "Epoch 25143 - Train Loss: 0.076980, Train Acc: 0.876923 | Val Loss: 0.111118, Val Acc: 0.773196\n",
      "Epoch 25144 - Train Loss: 0.076978, Train Acc: 0.876923 | Val Loss: 0.111118, Val Acc: 0.773196\n",
      "Epoch 25145 - Train Loss: 0.076977, Train Acc: 0.876923 | Val Loss: 0.111117, Val Acc: 0.773196\n",
      "Epoch 25146 - Train Loss: 0.076975, Train Acc: 0.876923 | Val Loss: 0.111117, Val Acc: 0.773196\n",
      "Epoch 25147 - Train Loss: 0.076973, Train Acc: 0.876923 | Val Loss: 0.111116, Val Acc: 0.773196\n",
      "Epoch 25148 - Train Loss: 0.076972, Train Acc: 0.876923 | Val Loss: 0.111116, Val Acc: 0.773196\n",
      "Epoch 25149 - Train Loss: 0.076970, Train Acc: 0.876923 | Val Loss: 0.111115, Val Acc: 0.773196\n",
      "Epoch 25150 - Train Loss: 0.076969, Train Acc: 0.876923 | Val Loss: 0.111115, Val Acc: 0.773196\n",
      "Epoch 25151 - Train Loss: 0.076967, Train Acc: 0.876923 | Val Loss: 0.111114, Val Acc: 0.773196\n",
      "Epoch 25152 - Train Loss: 0.076966, Train Acc: 0.876923 | Val Loss: 0.111114, Val Acc: 0.773196\n",
      "Epoch 25153 - Train Loss: 0.076964, Train Acc: 0.876923 | Val Loss: 0.111113, Val Acc: 0.773196\n",
      "Epoch 25154 - Train Loss: 0.076962, Train Acc: 0.876923 | Val Loss: 0.111113, Val Acc: 0.773196\n",
      "Epoch 25155 - Train Loss: 0.076961, Train Acc: 0.876923 | Val Loss: 0.111112, Val Acc: 0.773196\n",
      "Epoch 25156 - Train Loss: 0.076959, Train Acc: 0.876923 | Val Loss: 0.111111, Val Acc: 0.773196\n",
      "Epoch 25157 - Train Loss: 0.076958, Train Acc: 0.876923 | Val Loss: 0.111111, Val Acc: 0.773196\n",
      "Epoch 25158 - Train Loss: 0.076956, Train Acc: 0.876923 | Val Loss: 0.111110, Val Acc: 0.773196\n",
      "Epoch 25159 - Train Loss: 0.076955, Train Acc: 0.876923 | Val Loss: 0.111110, Val Acc: 0.773196\n",
      "Epoch 25160 - Train Loss: 0.076953, Train Acc: 0.876923 | Val Loss: 0.111109, Val Acc: 0.773196\n",
      "Epoch 25161 - Train Loss: 0.076952, Train Acc: 0.876923 | Val Loss: 0.111109, Val Acc: 0.773196\n",
      "Epoch 25162 - Train Loss: 0.076950, Train Acc: 0.876923 | Val Loss: 0.111108, Val Acc: 0.773196\n",
      "Epoch 25163 - Train Loss: 0.076948, Train Acc: 0.876923 | Val Loss: 0.111108, Val Acc: 0.773196\n",
      "Epoch 25164 - Train Loss: 0.076947, Train Acc: 0.876923 | Val Loss: 0.111107, Val Acc: 0.773196\n",
      "Epoch 25165 - Train Loss: 0.076945, Train Acc: 0.876923 | Val Loss: 0.111107, Val Acc: 0.773196\n",
      "Epoch 25166 - Train Loss: 0.076944, Train Acc: 0.876923 | Val Loss: 0.111106, Val Acc: 0.773196\n",
      "Epoch 25167 - Train Loss: 0.076942, Train Acc: 0.876923 | Val Loss: 0.111106, Val Acc: 0.773196\n",
      "Epoch 25168 - Train Loss: 0.076941, Train Acc: 0.876923 | Val Loss: 0.111105, Val Acc: 0.773196\n",
      "Epoch 25169 - Train Loss: 0.076939, Train Acc: 0.876923 | Val Loss: 0.111105, Val Acc: 0.773196\n",
      "Epoch 25170 - Train Loss: 0.076937, Train Acc: 0.876923 | Val Loss: 0.111104, Val Acc: 0.773196\n",
      "Epoch 25171 - Train Loss: 0.076936, Train Acc: 0.876923 | Val Loss: 0.111104, Val Acc: 0.773196\n",
      "Epoch 25172 - Train Loss: 0.076934, Train Acc: 0.876923 | Val Loss: 0.111103, Val Acc: 0.773196\n",
      "Epoch 25173 - Train Loss: 0.076933, Train Acc: 0.876923 | Val Loss: 0.111102, Val Acc: 0.773196\n",
      "Epoch 25174 - Train Loss: 0.076931, Train Acc: 0.876923 | Val Loss: 0.111102, Val Acc: 0.773196\n",
      "Epoch 25175 - Train Loss: 0.076930, Train Acc: 0.876923 | Val Loss: 0.111101, Val Acc: 0.773196\n",
      "Epoch 25176 - Train Loss: 0.076928, Train Acc: 0.876923 | Val Loss: 0.111101, Val Acc: 0.773196\n",
      "Epoch 25177 - Train Loss: 0.076927, Train Acc: 0.876923 | Val Loss: 0.111100, Val Acc: 0.773196\n",
      "Epoch 25178 - Train Loss: 0.076925, Train Acc: 0.876923 | Val Loss: 0.111100, Val Acc: 0.773196\n",
      "Epoch 25179 - Train Loss: 0.076923, Train Acc: 0.876923 | Val Loss: 0.111099, Val Acc: 0.773196\n",
      "Epoch 25180 - Train Loss: 0.076922, Train Acc: 0.876923 | Val Loss: 0.111099, Val Acc: 0.773196\n",
      "Epoch 25181 - Train Loss: 0.076920, Train Acc: 0.876923 | Val Loss: 0.111098, Val Acc: 0.773196\n",
      "Epoch 25182 - Train Loss: 0.076919, Train Acc: 0.876923 | Val Loss: 0.111098, Val Acc: 0.773196\n",
      "Epoch 25183 - Train Loss: 0.076917, Train Acc: 0.876923 | Val Loss: 0.111097, Val Acc: 0.773196\n",
      "Epoch 25184 - Train Loss: 0.076916, Train Acc: 0.876923 | Val Loss: 0.111097, Val Acc: 0.773196\n",
      "Epoch 25185 - Train Loss: 0.076914, Train Acc: 0.876923 | Val Loss: 0.111096, Val Acc: 0.773196\n",
      "Epoch 25186 - Train Loss: 0.076912, Train Acc: 0.876923 | Val Loss: 0.111096, Val Acc: 0.773196\n",
      "Epoch 25187 - Train Loss: 0.076911, Train Acc: 0.876923 | Val Loss: 0.111095, Val Acc: 0.773196\n",
      "Epoch 25188 - Train Loss: 0.076909, Train Acc: 0.876923 | Val Loss: 0.111094, Val Acc: 0.773196\n",
      "Epoch 25189 - Train Loss: 0.076908, Train Acc: 0.876923 | Val Loss: 0.111094, Val Acc: 0.773196\n",
      "Epoch 25190 - Train Loss: 0.076906, Train Acc: 0.876923 | Val Loss: 0.111093, Val Acc: 0.773196\n",
      "Epoch 25191 - Train Loss: 0.076905, Train Acc: 0.876923 | Val Loss: 0.111093, Val Acc: 0.773196\n",
      "Epoch 25192 - Train Loss: 0.076903, Train Acc: 0.876923 | Val Loss: 0.111092, Val Acc: 0.773196\n",
      "Epoch 25193 - Train Loss: 0.076902, Train Acc: 0.876923 | Val Loss: 0.111092, Val Acc: 0.773196\n",
      "Epoch 25194 - Train Loss: 0.076900, Train Acc: 0.876923 | Val Loss: 0.111091, Val Acc: 0.773196\n",
      "Epoch 25195 - Train Loss: 0.076898, Train Acc: 0.876923 | Val Loss: 0.111091, Val Acc: 0.773196\n",
      "Epoch 25196 - Train Loss: 0.076897, Train Acc: 0.876923 | Val Loss: 0.111090, Val Acc: 0.773196\n",
      "Epoch 25197 - Train Loss: 0.076895, Train Acc: 0.876923 | Val Loss: 0.111090, Val Acc: 0.773196\n",
      "Epoch 25198 - Train Loss: 0.076894, Train Acc: 0.876923 | Val Loss: 0.111089, Val Acc: 0.773196\n",
      "Epoch 25199 - Train Loss: 0.076892, Train Acc: 0.876923 | Val Loss: 0.111089, Val Acc: 0.773196\n",
      "Epoch 25200 - Train Loss: 0.076891, Train Acc: 0.876923 | Val Loss: 0.111088, Val Acc: 0.773196\n",
      "Epoch 25201 - Train Loss: 0.076889, Train Acc: 0.876923 | Val Loss: 0.111088, Val Acc: 0.773196\n",
      "Epoch 25202 - Train Loss: 0.076888, Train Acc: 0.876923 | Val Loss: 0.111087, Val Acc: 0.773196\n",
      "Epoch 25203 - Train Loss: 0.076886, Train Acc: 0.876923 | Val Loss: 0.111087, Val Acc: 0.773196\n",
      "Epoch 25204 - Train Loss: 0.076884, Train Acc: 0.876923 | Val Loss: 0.111086, Val Acc: 0.773196\n",
      "Epoch 25205 - Train Loss: 0.076883, Train Acc: 0.876923 | Val Loss: 0.111086, Val Acc: 0.773196\n",
      "Epoch 25206 - Train Loss: 0.076881, Train Acc: 0.876923 | Val Loss: 0.111085, Val Acc: 0.773196\n",
      "Epoch 25207 - Train Loss: 0.076880, Train Acc: 0.876923 | Val Loss: 0.111084, Val Acc: 0.773196\n",
      "Epoch 25208 - Train Loss: 0.076878, Train Acc: 0.876923 | Val Loss: 0.111084, Val Acc: 0.773196\n",
      "Epoch 25209 - Train Loss: 0.076877, Train Acc: 0.876923 | Val Loss: 0.111083, Val Acc: 0.773196\n",
      "Epoch 25210 - Train Loss: 0.076875, Train Acc: 0.876923 | Val Loss: 0.111083, Val Acc: 0.773196\n",
      "Epoch 25211 - Train Loss: 0.076874, Train Acc: 0.876923 | Val Loss: 0.111082, Val Acc: 0.773196\n",
      "Epoch 25212 - Train Loss: 0.076872, Train Acc: 0.876923 | Val Loss: 0.111082, Val Acc: 0.773196\n",
      "Epoch 25213 - Train Loss: 0.076870, Train Acc: 0.876923 | Val Loss: 0.111081, Val Acc: 0.773196\n",
      "Epoch 25214 - Train Loss: 0.076869, Train Acc: 0.876923 | Val Loss: 0.111081, Val Acc: 0.773196\n",
      "Epoch 25215 - Train Loss: 0.076867, Train Acc: 0.876923 | Val Loss: 0.111080, Val Acc: 0.773196\n",
      "Epoch 25216 - Train Loss: 0.076866, Train Acc: 0.876923 | Val Loss: 0.111080, Val Acc: 0.773196\n",
      "Epoch 25217 - Train Loss: 0.076864, Train Acc: 0.876923 | Val Loss: 0.111079, Val Acc: 0.773196\n",
      "Epoch 25218 - Train Loss: 0.076863, Train Acc: 0.876923 | Val Loss: 0.111079, Val Acc: 0.773196\n",
      "Epoch 25219 - Train Loss: 0.076861, Train Acc: 0.876923 | Val Loss: 0.111078, Val Acc: 0.773196\n",
      "Epoch 25220 - Train Loss: 0.076860, Train Acc: 0.876923 | Val Loss: 0.111078, Val Acc: 0.773196\n",
      "Epoch 25221 - Train Loss: 0.076858, Train Acc: 0.876923 | Val Loss: 0.111077, Val Acc: 0.773196\n",
      "Epoch 25222 - Train Loss: 0.076856, Train Acc: 0.876923 | Val Loss: 0.111077, Val Acc: 0.773196\n",
      "Epoch 25223 - Train Loss: 0.076855, Train Acc: 0.876923 | Val Loss: 0.111076, Val Acc: 0.773196\n",
      "Epoch 25224 - Train Loss: 0.076853, Train Acc: 0.876923 | Val Loss: 0.111075, Val Acc: 0.773196\n",
      "Epoch 25225 - Train Loss: 0.076852, Train Acc: 0.876923 | Val Loss: 0.111075, Val Acc: 0.773196\n",
      "Epoch 25226 - Train Loss: 0.076850, Train Acc: 0.876923 | Val Loss: 0.111074, Val Acc: 0.773196\n",
      "Epoch 25227 - Train Loss: 0.076849, Train Acc: 0.876923 | Val Loss: 0.111074, Val Acc: 0.773196\n",
      "Epoch 25228 - Train Loss: 0.076847, Train Acc: 0.876923 | Val Loss: 0.111073, Val Acc: 0.773196\n",
      "Epoch 25229 - Train Loss: 0.076846, Train Acc: 0.876923 | Val Loss: 0.111073, Val Acc: 0.773196\n",
      "Epoch 25230 - Train Loss: 0.076844, Train Acc: 0.876923 | Val Loss: 0.111072, Val Acc: 0.773196\n",
      "Epoch 25231 - Train Loss: 0.076842, Train Acc: 0.876923 | Val Loss: 0.111072, Val Acc: 0.773196\n",
      "Epoch 25232 - Train Loss: 0.076841, Train Acc: 0.876923 | Val Loss: 0.111071, Val Acc: 0.773196\n",
      "Epoch 25233 - Train Loss: 0.076839, Train Acc: 0.876923 | Val Loss: 0.111071, Val Acc: 0.773196\n",
      "Epoch 25234 - Train Loss: 0.076838, Train Acc: 0.876923 | Val Loss: 0.111070, Val Acc: 0.773196\n",
      "Epoch 25235 - Train Loss: 0.076836, Train Acc: 0.876923 | Val Loss: 0.111070, Val Acc: 0.773196\n",
      "Epoch 25236 - Train Loss: 0.076835, Train Acc: 0.876923 | Val Loss: 0.111069, Val Acc: 0.773196\n",
      "Epoch 25237 - Train Loss: 0.076833, Train Acc: 0.876923 | Val Loss: 0.111069, Val Acc: 0.773196\n",
      "Epoch 25238 - Train Loss: 0.076832, Train Acc: 0.876923 | Val Loss: 0.111068, Val Acc: 0.773196\n",
      "Epoch 25239 - Train Loss: 0.076830, Train Acc: 0.876923 | Val Loss: 0.111068, Val Acc: 0.773196\n",
      "Epoch 25240 - Train Loss: 0.076828, Train Acc: 0.876923 | Val Loss: 0.111067, Val Acc: 0.773196\n",
      "Epoch 25241 - Train Loss: 0.076827, Train Acc: 0.876923 | Val Loss: 0.111067, Val Acc: 0.773196\n",
      "Epoch 25242 - Train Loss: 0.076825, Train Acc: 0.876923 | Val Loss: 0.111066, Val Acc: 0.773196\n",
      "Epoch 25243 - Train Loss: 0.076824, Train Acc: 0.876923 | Val Loss: 0.111065, Val Acc: 0.773196\n",
      "Epoch 25244 - Train Loss: 0.076822, Train Acc: 0.876923 | Val Loss: 0.111065, Val Acc: 0.773196\n",
      "Epoch 25245 - Train Loss: 0.076821, Train Acc: 0.876923 | Val Loss: 0.111064, Val Acc: 0.773196\n",
      "Epoch 25246 - Train Loss: 0.076819, Train Acc: 0.878205 | Val Loss: 0.111064, Val Acc: 0.773196\n",
      "Epoch 25247 - Train Loss: 0.076818, Train Acc: 0.878205 | Val Loss: 0.111063, Val Acc: 0.773196\n",
      "Epoch 25248 - Train Loss: 0.076816, Train Acc: 0.878205 | Val Loss: 0.111063, Val Acc: 0.773196\n",
      "Epoch 25249 - Train Loss: 0.076814, Train Acc: 0.878205 | Val Loss: 0.111062, Val Acc: 0.773196\n",
      "Epoch 25250 - Train Loss: 0.076813, Train Acc: 0.878205 | Val Loss: 0.111062, Val Acc: 0.773196\n",
      "Epoch 25251 - Train Loss: 0.076811, Train Acc: 0.878205 | Val Loss: 0.111061, Val Acc: 0.773196\n",
      "Epoch 25252 - Train Loss: 0.076810, Train Acc: 0.878205 | Val Loss: 0.111061, Val Acc: 0.773196\n",
      "Epoch 25253 - Train Loss: 0.076808, Train Acc: 0.878205 | Val Loss: 0.111060, Val Acc: 0.773196\n",
      "Epoch 25254 - Train Loss: 0.076807, Train Acc: 0.878205 | Val Loss: 0.111060, Val Acc: 0.773196\n",
      "Epoch 25255 - Train Loss: 0.076805, Train Acc: 0.878205 | Val Loss: 0.111059, Val Acc: 0.773196\n",
      "Epoch 25256 - Train Loss: 0.076804, Train Acc: 0.878205 | Val Loss: 0.111059, Val Acc: 0.773196\n",
      "Epoch 25257 - Train Loss: 0.076802, Train Acc: 0.878205 | Val Loss: 0.111058, Val Acc: 0.773196\n",
      "Epoch 25258 - Train Loss: 0.076800, Train Acc: 0.878205 | Val Loss: 0.111058, Val Acc: 0.773196\n",
      "Epoch 25259 - Train Loss: 0.076799, Train Acc: 0.878205 | Val Loss: 0.111057, Val Acc: 0.773196\n",
      "Epoch 25260 - Train Loss: 0.076797, Train Acc: 0.878205 | Val Loss: 0.111057, Val Acc: 0.773196\n",
      "Epoch 25261 - Train Loss: 0.076796, Train Acc: 0.878205 | Val Loss: 0.111056, Val Acc: 0.773196\n",
      "Epoch 25262 - Train Loss: 0.076794, Train Acc: 0.878205 | Val Loss: 0.111055, Val Acc: 0.773196\n",
      "Epoch 25263 - Train Loss: 0.076793, Train Acc: 0.878205 | Val Loss: 0.111055, Val Acc: 0.773196\n",
      "Epoch 25264 - Train Loss: 0.076791, Train Acc: 0.878205 | Val Loss: 0.111054, Val Acc: 0.773196\n",
      "Epoch 25265 - Train Loss: 0.076790, Train Acc: 0.878205 | Val Loss: 0.111054, Val Acc: 0.773196\n",
      "Epoch 25266 - Train Loss: 0.076788, Train Acc: 0.878205 | Val Loss: 0.111053, Val Acc: 0.773196\n",
      "Epoch 25267 - Train Loss: 0.076786, Train Acc: 0.878205 | Val Loss: 0.111053, Val Acc: 0.773196\n",
      "Epoch 25268 - Train Loss: 0.076785, Train Acc: 0.878205 | Val Loss: 0.111052, Val Acc: 0.773196\n",
      "Epoch 25269 - Train Loss: 0.076783, Train Acc: 0.878205 | Val Loss: 0.111052, Val Acc: 0.773196\n",
      "Epoch 25270 - Train Loss: 0.076782, Train Acc: 0.878205 | Val Loss: 0.111051, Val Acc: 0.773196\n",
      "Epoch 25271 - Train Loss: 0.076780, Train Acc: 0.878205 | Val Loss: 0.111051, Val Acc: 0.773196\n",
      "Epoch 25272 - Train Loss: 0.076779, Train Acc: 0.878205 | Val Loss: 0.111050, Val Acc: 0.773196\n",
      "Epoch 25273 - Train Loss: 0.076777, Train Acc: 0.878205 | Val Loss: 0.111050, Val Acc: 0.773196\n",
      "Epoch 25274 - Train Loss: 0.076776, Train Acc: 0.878205 | Val Loss: 0.111049, Val Acc: 0.773196\n",
      "Epoch 25275 - Train Loss: 0.076774, Train Acc: 0.878205 | Val Loss: 0.111049, Val Acc: 0.773196\n",
      "Epoch 25276 - Train Loss: 0.076772, Train Acc: 0.878205 | Val Loss: 0.111048, Val Acc: 0.773196\n",
      "Epoch 25277 - Train Loss: 0.076771, Train Acc: 0.878205 | Val Loss: 0.111048, Val Acc: 0.773196\n",
      "Epoch 25278 - Train Loss: 0.076769, Train Acc: 0.878205 | Val Loss: 0.111047, Val Acc: 0.773196\n",
      "Epoch 25279 - Train Loss: 0.076768, Train Acc: 0.878205 | Val Loss: 0.111047, Val Acc: 0.773196\n",
      "Epoch 25280 - Train Loss: 0.076766, Train Acc: 0.878205 | Val Loss: 0.111046, Val Acc: 0.773196\n",
      "Epoch 25281 - Train Loss: 0.076765, Train Acc: 0.878205 | Val Loss: 0.111046, Val Acc: 0.773196\n",
      "Epoch 25282 - Train Loss: 0.076763, Train Acc: 0.878205 | Val Loss: 0.111045, Val Acc: 0.773196\n",
      "Epoch 25283 - Train Loss: 0.076762, Train Acc: 0.878205 | Val Loss: 0.111044, Val Acc: 0.773196\n",
      "Epoch 25284 - Train Loss: 0.076760, Train Acc: 0.878205 | Val Loss: 0.111044, Val Acc: 0.773196\n",
      "Epoch 25285 - Train Loss: 0.076759, Train Acc: 0.878205 | Val Loss: 0.111043, Val Acc: 0.773196\n",
      "Epoch 25286 - Train Loss: 0.076757, Train Acc: 0.878205 | Val Loss: 0.111043, Val Acc: 0.773196\n",
      "Epoch 25287 - Train Loss: 0.076755, Train Acc: 0.878205 | Val Loss: 0.111042, Val Acc: 0.773196\n",
      "Epoch 25288 - Train Loss: 0.076754, Train Acc: 0.878205 | Val Loss: 0.111042, Val Acc: 0.773196\n",
      "Epoch 25289 - Train Loss: 0.076752, Train Acc: 0.878205 | Val Loss: 0.111041, Val Acc: 0.773196\n",
      "Epoch 25290 - Train Loss: 0.076751, Train Acc: 0.878205 | Val Loss: 0.111041, Val Acc: 0.773196\n",
      "Epoch 25291 - Train Loss: 0.076749, Train Acc: 0.878205 | Val Loss: 0.111040, Val Acc: 0.773196\n",
      "Epoch 25292 - Train Loss: 0.076748, Train Acc: 0.878205 | Val Loss: 0.111040, Val Acc: 0.773196\n",
      "Epoch 25293 - Train Loss: 0.076746, Train Acc: 0.878205 | Val Loss: 0.111039, Val Acc: 0.773196\n",
      "Epoch 25294 - Train Loss: 0.076745, Train Acc: 0.878205 | Val Loss: 0.111039, Val Acc: 0.773196\n",
      "Epoch 25295 - Train Loss: 0.076743, Train Acc: 0.878205 | Val Loss: 0.111038, Val Acc: 0.773196\n",
      "Epoch 25296 - Train Loss: 0.076741, Train Acc: 0.878205 | Val Loss: 0.111038, Val Acc: 0.773196\n",
      "Epoch 25297 - Train Loss: 0.076740, Train Acc: 0.878205 | Val Loss: 0.111037, Val Acc: 0.773196\n",
      "Epoch 25298 - Train Loss: 0.076738, Train Acc: 0.878205 | Val Loss: 0.111037, Val Acc: 0.773196\n",
      "Epoch 25299 - Train Loss: 0.076737, Train Acc: 0.878205 | Val Loss: 0.111036, Val Acc: 0.773196\n",
      "Epoch 25300 - Train Loss: 0.076735, Train Acc: 0.878205 | Val Loss: 0.111036, Val Acc: 0.773196\n",
      "Epoch 25301 - Train Loss: 0.076734, Train Acc: 0.878205 | Val Loss: 0.111035, Val Acc: 0.773196\n",
      "Epoch 25302 - Train Loss: 0.076732, Train Acc: 0.878205 | Val Loss: 0.111035, Val Acc: 0.773196\n",
      "Epoch 25303 - Train Loss: 0.076731, Train Acc: 0.878205 | Val Loss: 0.111034, Val Acc: 0.773196\n",
      "Epoch 25304 - Train Loss: 0.076729, Train Acc: 0.878205 | Val Loss: 0.111034, Val Acc: 0.773196\n",
      "Epoch 25305 - Train Loss: 0.076728, Train Acc: 0.878205 | Val Loss: 0.111033, Val Acc: 0.773196\n",
      "Epoch 25306 - Train Loss: 0.076726, Train Acc: 0.878205 | Val Loss: 0.111032, Val Acc: 0.773196\n",
      "Epoch 25307 - Train Loss: 0.076724, Train Acc: 0.878205 | Val Loss: 0.111032, Val Acc: 0.773196\n",
      "Epoch 25308 - Train Loss: 0.076723, Train Acc: 0.878205 | Val Loss: 0.111031, Val Acc: 0.773196\n",
      "Epoch 25309 - Train Loss: 0.076721, Train Acc: 0.878205 | Val Loss: 0.111031, Val Acc: 0.773196\n",
      "Epoch 25310 - Train Loss: 0.076720, Train Acc: 0.878205 | Val Loss: 0.111030, Val Acc: 0.773196\n",
      "Epoch 25311 - Train Loss: 0.076718, Train Acc: 0.878205 | Val Loss: 0.111030, Val Acc: 0.773196\n",
      "Epoch 25312 - Train Loss: 0.076717, Train Acc: 0.878205 | Val Loss: 0.111029, Val Acc: 0.773196\n",
      "Epoch 25313 - Train Loss: 0.076715, Train Acc: 0.878205 | Val Loss: 0.111029, Val Acc: 0.773196\n",
      "Epoch 25314 - Train Loss: 0.076714, Train Acc: 0.878205 | Val Loss: 0.111028, Val Acc: 0.773196\n",
      "Epoch 25315 - Train Loss: 0.076712, Train Acc: 0.878205 | Val Loss: 0.111028, Val Acc: 0.773196\n",
      "Epoch 25316 - Train Loss: 0.076710, Train Acc: 0.878205 | Val Loss: 0.111027, Val Acc: 0.773196\n",
      "Epoch 25317 - Train Loss: 0.076709, Train Acc: 0.878205 | Val Loss: 0.111027, Val Acc: 0.773196\n",
      "Epoch 25318 - Train Loss: 0.076707, Train Acc: 0.878205 | Val Loss: 0.111026, Val Acc: 0.773196\n",
      "Epoch 25319 - Train Loss: 0.076706, Train Acc: 0.878205 | Val Loss: 0.111026, Val Acc: 0.773196\n",
      "Epoch 25320 - Train Loss: 0.076704, Train Acc: 0.878205 | Val Loss: 0.111025, Val Acc: 0.773196\n",
      "Epoch 25321 - Train Loss: 0.076703, Train Acc: 0.878205 | Val Loss: 0.111025, Val Acc: 0.773196\n",
      "Epoch 25322 - Train Loss: 0.076701, Train Acc: 0.878205 | Val Loss: 0.111024, Val Acc: 0.773196\n",
      "Epoch 25323 - Train Loss: 0.076700, Train Acc: 0.878205 | Val Loss: 0.111024, Val Acc: 0.773196\n",
      "Epoch 25324 - Train Loss: 0.076698, Train Acc: 0.878205 | Val Loss: 0.111023, Val Acc: 0.773196\n",
      "Epoch 25325 - Train Loss: 0.076697, Train Acc: 0.878205 | Val Loss: 0.111023, Val Acc: 0.773196\n",
      "Epoch 25326 - Train Loss: 0.076695, Train Acc: 0.878205 | Val Loss: 0.111022, Val Acc: 0.773196\n",
      "Epoch 25327 - Train Loss: 0.076693, Train Acc: 0.878205 | Val Loss: 0.111022, Val Acc: 0.773196\n",
      "Epoch 25328 - Train Loss: 0.076692, Train Acc: 0.878205 | Val Loss: 0.111021, Val Acc: 0.773196\n",
      "Epoch 25329 - Train Loss: 0.076690, Train Acc: 0.878205 | Val Loss: 0.111021, Val Acc: 0.773196\n",
      "Epoch 25330 - Train Loss: 0.076689, Train Acc: 0.878205 | Val Loss: 0.111020, Val Acc: 0.773196\n",
      "Epoch 25331 - Train Loss: 0.076687, Train Acc: 0.878205 | Val Loss: 0.111019, Val Acc: 0.773196\n",
      "Epoch 25332 - Train Loss: 0.076686, Train Acc: 0.878205 | Val Loss: 0.111019, Val Acc: 0.773196\n",
      "Epoch 25333 - Train Loss: 0.076684, Train Acc: 0.878205 | Val Loss: 0.111018, Val Acc: 0.773196\n",
      "Epoch 25334 - Train Loss: 0.076683, Train Acc: 0.878205 | Val Loss: 0.111018, Val Acc: 0.773196\n",
      "Epoch 25335 - Train Loss: 0.076681, Train Acc: 0.878205 | Val Loss: 0.111017, Val Acc: 0.773196\n",
      "Epoch 25336 - Train Loss: 0.076680, Train Acc: 0.878205 | Val Loss: 0.111017, Val Acc: 0.773196\n",
      "Epoch 25337 - Train Loss: 0.076678, Train Acc: 0.878205 | Val Loss: 0.111016, Val Acc: 0.773196\n",
      "Epoch 25338 - Train Loss: 0.076676, Train Acc: 0.878205 | Val Loss: 0.111016, Val Acc: 0.773196\n",
      "Epoch 25339 - Train Loss: 0.076675, Train Acc: 0.878205 | Val Loss: 0.111015, Val Acc: 0.773196\n",
      "Epoch 25340 - Train Loss: 0.076673, Train Acc: 0.878205 | Val Loss: 0.111015, Val Acc: 0.773196\n",
      "Epoch 25341 - Train Loss: 0.076672, Train Acc: 0.878205 | Val Loss: 0.111014, Val Acc: 0.773196\n",
      "Epoch 25342 - Train Loss: 0.076670, Train Acc: 0.878205 | Val Loss: 0.111014, Val Acc: 0.773196\n",
      "Epoch 25343 - Train Loss: 0.076669, Train Acc: 0.878205 | Val Loss: 0.111013, Val Acc: 0.773196\n",
      "Epoch 25344 - Train Loss: 0.076667, Train Acc: 0.878205 | Val Loss: 0.111013, Val Acc: 0.773196\n",
      "Epoch 25345 - Train Loss: 0.076666, Train Acc: 0.878205 | Val Loss: 0.111012, Val Acc: 0.773196\n",
      "Epoch 25346 - Train Loss: 0.076664, Train Acc: 0.878205 | Val Loss: 0.111012, Val Acc: 0.773196\n",
      "Epoch 25347 - Train Loss: 0.076663, Train Acc: 0.878205 | Val Loss: 0.111011, Val Acc: 0.773196\n",
      "Epoch 25348 - Train Loss: 0.076661, Train Acc: 0.878205 | Val Loss: 0.111011, Val Acc: 0.773196\n",
      "Epoch 25349 - Train Loss: 0.076659, Train Acc: 0.878205 | Val Loss: 0.111010, Val Acc: 0.773196\n",
      "Epoch 25350 - Train Loss: 0.076658, Train Acc: 0.878205 | Val Loss: 0.111010, Val Acc: 0.773196\n",
      "Epoch 25351 - Train Loss: 0.076656, Train Acc: 0.878205 | Val Loss: 0.111009, Val Acc: 0.773196\n",
      "Epoch 25352 - Train Loss: 0.076655, Train Acc: 0.878205 | Val Loss: 0.111009, Val Acc: 0.773196\n",
      "Epoch 25353 - Train Loss: 0.076653, Train Acc: 0.878205 | Val Loss: 0.111008, Val Acc: 0.773196\n",
      "Epoch 25354 - Train Loss: 0.076652, Train Acc: 0.878205 | Val Loss: 0.111008, Val Acc: 0.773196\n",
      "Epoch 25355 - Train Loss: 0.076650, Train Acc: 0.878205 | Val Loss: 0.111007, Val Acc: 0.773196\n",
      "Epoch 25356 - Train Loss: 0.076649, Train Acc: 0.878205 | Val Loss: 0.111007, Val Acc: 0.773196\n",
      "Epoch 25357 - Train Loss: 0.076647, Train Acc: 0.878205 | Val Loss: 0.111006, Val Acc: 0.773196\n",
      "Epoch 25358 - Train Loss: 0.076646, Train Acc: 0.878205 | Val Loss: 0.111005, Val Acc: 0.773196\n",
      "Epoch 25359 - Train Loss: 0.076644, Train Acc: 0.878205 | Val Loss: 0.111005, Val Acc: 0.773196\n",
      "Epoch 25360 - Train Loss: 0.076642, Train Acc: 0.878205 | Val Loss: 0.111004, Val Acc: 0.773196\n",
      "Epoch 25361 - Train Loss: 0.076641, Train Acc: 0.878205 | Val Loss: 0.111004, Val Acc: 0.773196\n",
      "Epoch 25362 - Train Loss: 0.076639, Train Acc: 0.878205 | Val Loss: 0.111003, Val Acc: 0.773196\n",
      "Epoch 25363 - Train Loss: 0.076638, Train Acc: 0.878205 | Val Loss: 0.111003, Val Acc: 0.773196\n",
      "Epoch 25364 - Train Loss: 0.076636, Train Acc: 0.878205 | Val Loss: 0.111002, Val Acc: 0.773196\n",
      "Epoch 25365 - Train Loss: 0.076635, Train Acc: 0.878205 | Val Loss: 0.111002, Val Acc: 0.773196\n",
      "Epoch 25366 - Train Loss: 0.076633, Train Acc: 0.878205 | Val Loss: 0.111001, Val Acc: 0.773196\n",
      "Epoch 25367 - Train Loss: 0.076632, Train Acc: 0.878205 | Val Loss: 0.111001, Val Acc: 0.773196\n",
      "Epoch 25368 - Train Loss: 0.076630, Train Acc: 0.878205 | Val Loss: 0.111000, Val Acc: 0.773196\n",
      "Epoch 25369 - Train Loss: 0.076629, Train Acc: 0.878205 | Val Loss: 0.111000, Val Acc: 0.773196\n",
      "Epoch 25370 - Train Loss: 0.076627, Train Acc: 0.878205 | Val Loss: 0.110999, Val Acc: 0.773196\n",
      "Epoch 25371 - Train Loss: 0.076625, Train Acc: 0.878205 | Val Loss: 0.110999, Val Acc: 0.773196\n",
      "Epoch 25372 - Train Loss: 0.076624, Train Acc: 0.878205 | Val Loss: 0.110998, Val Acc: 0.773196\n",
      "Epoch 25373 - Train Loss: 0.076622, Train Acc: 0.878205 | Val Loss: 0.110998, Val Acc: 0.773196\n",
      "Epoch 25374 - Train Loss: 0.076621, Train Acc: 0.878205 | Val Loss: 0.110997, Val Acc: 0.773196\n",
      "Epoch 25375 - Train Loss: 0.076619, Train Acc: 0.878205 | Val Loss: 0.110997, Val Acc: 0.773196\n",
      "Epoch 25376 - Train Loss: 0.076618, Train Acc: 0.878205 | Val Loss: 0.110996, Val Acc: 0.773196\n",
      "Epoch 25377 - Train Loss: 0.076616, Train Acc: 0.878205 | Val Loss: 0.110996, Val Acc: 0.773196\n",
      "Epoch 25378 - Train Loss: 0.076615, Train Acc: 0.878205 | Val Loss: 0.110995, Val Acc: 0.773196\n",
      "Epoch 25379 - Train Loss: 0.076613, Train Acc: 0.878205 | Val Loss: 0.110995, Val Acc: 0.773196\n",
      "Epoch 25380 - Train Loss: 0.076612, Train Acc: 0.878205 | Val Loss: 0.110994, Val Acc: 0.773196\n",
      "Epoch 25381 - Train Loss: 0.076610, Train Acc: 0.878205 | Val Loss: 0.110994, Val Acc: 0.773196\n",
      "Epoch 25382 - Train Loss: 0.076608, Train Acc: 0.878205 | Val Loss: 0.110993, Val Acc: 0.773196\n",
      "Epoch 25383 - Train Loss: 0.076607, Train Acc: 0.878205 | Val Loss: 0.110993, Val Acc: 0.773196\n",
      "Epoch 25384 - Train Loss: 0.076605, Train Acc: 0.878205 | Val Loss: 0.110992, Val Acc: 0.773196\n",
      "Epoch 25385 - Train Loss: 0.076604, Train Acc: 0.878205 | Val Loss: 0.110992, Val Acc: 0.773196\n",
      "Epoch 25386 - Train Loss: 0.076602, Train Acc: 0.878205 | Val Loss: 0.110991, Val Acc: 0.773196\n",
      "Epoch 25387 - Train Loss: 0.076601, Train Acc: 0.878205 | Val Loss: 0.110991, Val Acc: 0.773196\n",
      "Epoch 25388 - Train Loss: 0.076599, Train Acc: 0.878205 | Val Loss: 0.110990, Val Acc: 0.773196\n",
      "Epoch 25389 - Train Loss: 0.076598, Train Acc: 0.878205 | Val Loss: 0.110989, Val Acc: 0.773196\n",
      "Epoch 25390 - Train Loss: 0.076596, Train Acc: 0.878205 | Val Loss: 0.110989, Val Acc: 0.773196\n",
      "Epoch 25391 - Train Loss: 0.076595, Train Acc: 0.878205 | Val Loss: 0.110988, Val Acc: 0.773196\n",
      "Epoch 25392 - Train Loss: 0.076593, Train Acc: 0.878205 | Val Loss: 0.110988, Val Acc: 0.773196\n",
      "Epoch 25393 - Train Loss: 0.076592, Train Acc: 0.878205 | Val Loss: 0.110987, Val Acc: 0.773196\n",
      "Epoch 25394 - Train Loss: 0.076590, Train Acc: 0.878205 | Val Loss: 0.110987, Val Acc: 0.773196\n",
      "Epoch 25395 - Train Loss: 0.076588, Train Acc: 0.878205 | Val Loss: 0.110986, Val Acc: 0.773196\n",
      "Epoch 25396 - Train Loss: 0.076587, Train Acc: 0.878205 | Val Loss: 0.110986, Val Acc: 0.773196\n",
      "Epoch 25397 - Train Loss: 0.076585, Train Acc: 0.878205 | Val Loss: 0.110985, Val Acc: 0.773196\n",
      "Epoch 25398 - Train Loss: 0.076584, Train Acc: 0.878205 | Val Loss: 0.110985, Val Acc: 0.773196\n",
      "Epoch 25399 - Train Loss: 0.076582, Train Acc: 0.878205 | Val Loss: 0.110984, Val Acc: 0.773196\n",
      "Epoch 25400 - Train Loss: 0.076581, Train Acc: 0.878205 | Val Loss: 0.110984, Val Acc: 0.773196\n",
      "Epoch 25401 - Train Loss: 0.076579, Train Acc: 0.878205 | Val Loss: 0.110983, Val Acc: 0.773196\n",
      "Epoch 25402 - Train Loss: 0.076578, Train Acc: 0.878205 | Val Loss: 0.110983, Val Acc: 0.773196\n",
      "Epoch 25403 - Train Loss: 0.076576, Train Acc: 0.878205 | Val Loss: 0.110982, Val Acc: 0.773196\n",
      "Epoch 25404 - Train Loss: 0.076575, Train Acc: 0.878205 | Val Loss: 0.110982, Val Acc: 0.773196\n",
      "Epoch 25405 - Train Loss: 0.076573, Train Acc: 0.878205 | Val Loss: 0.110981, Val Acc: 0.773196\n",
      "Epoch 25406 - Train Loss: 0.076571, Train Acc: 0.878205 | Val Loss: 0.110981, Val Acc: 0.773196\n",
      "Epoch 25407 - Train Loss: 0.076570, Train Acc: 0.878205 | Val Loss: 0.110980, Val Acc: 0.773196\n",
      "Epoch 25408 - Train Loss: 0.076568, Train Acc: 0.878205 | Val Loss: 0.110980, Val Acc: 0.773196\n",
      "Epoch 25409 - Train Loss: 0.076567, Train Acc: 0.878205 | Val Loss: 0.110979, Val Acc: 0.773196\n",
      "Epoch 25410 - Train Loss: 0.076565, Train Acc: 0.878205 | Val Loss: 0.110979, Val Acc: 0.773196\n",
      "Epoch 25411 - Train Loss: 0.076564, Train Acc: 0.878205 | Val Loss: 0.110978, Val Acc: 0.773196\n",
      "Epoch 25412 - Train Loss: 0.076562, Train Acc: 0.878205 | Val Loss: 0.110978, Val Acc: 0.773196\n",
      "Epoch 25413 - Train Loss: 0.076561, Train Acc: 0.878205 | Val Loss: 0.110977, Val Acc: 0.773196\n",
      "Epoch 25414 - Train Loss: 0.076559, Train Acc: 0.878205 | Val Loss: 0.110977, Val Acc: 0.773196\n",
      "Epoch 25415 - Train Loss: 0.076558, Train Acc: 0.878205 | Val Loss: 0.110976, Val Acc: 0.773196\n",
      "Epoch 25416 - Train Loss: 0.076556, Train Acc: 0.878205 | Val Loss: 0.110976, Val Acc: 0.773196\n",
      "Epoch 25417 - Train Loss: 0.076555, Train Acc: 0.878205 | Val Loss: 0.110975, Val Acc: 0.773196\n",
      "Epoch 25418 - Train Loss: 0.076553, Train Acc: 0.878205 | Val Loss: 0.110975, Val Acc: 0.773196\n",
      "Epoch 25419 - Train Loss: 0.076551, Train Acc: 0.878205 | Val Loss: 0.110974, Val Acc: 0.773196\n",
      "Epoch 25420 - Train Loss: 0.076550, Train Acc: 0.878205 | Val Loss: 0.110974, Val Acc: 0.773196\n",
      "Epoch 25421 - Train Loss: 0.076548, Train Acc: 0.878205 | Val Loss: 0.110973, Val Acc: 0.773196\n",
      "Epoch 25422 - Train Loss: 0.076547, Train Acc: 0.878205 | Val Loss: 0.110973, Val Acc: 0.773196\n",
      "Epoch 25423 - Train Loss: 0.076545, Train Acc: 0.878205 | Val Loss: 0.110972, Val Acc: 0.773196\n",
      "Epoch 25424 - Train Loss: 0.076544, Train Acc: 0.878205 | Val Loss: 0.110971, Val Acc: 0.773196\n",
      "Epoch 25425 - Train Loss: 0.076542, Train Acc: 0.878205 | Val Loss: 0.110971, Val Acc: 0.773196\n",
      "Epoch 25426 - Train Loss: 0.076541, Train Acc: 0.878205 | Val Loss: 0.110970, Val Acc: 0.773196\n",
      "Epoch 25427 - Train Loss: 0.076539, Train Acc: 0.878205 | Val Loss: 0.110970, Val Acc: 0.773196\n",
      "Epoch 25428 - Train Loss: 0.076538, Train Acc: 0.878205 | Val Loss: 0.110969, Val Acc: 0.773196\n",
      "Epoch 25429 - Train Loss: 0.076536, Train Acc: 0.878205 | Val Loss: 0.110969, Val Acc: 0.773196\n",
      "Epoch 25430 - Train Loss: 0.076535, Train Acc: 0.878205 | Val Loss: 0.110968, Val Acc: 0.773196\n",
      "Epoch 25431 - Train Loss: 0.076533, Train Acc: 0.878205 | Val Loss: 0.110968, Val Acc: 0.773196\n",
      "Epoch 25432 - Train Loss: 0.076531, Train Acc: 0.878205 | Val Loss: 0.110967, Val Acc: 0.773196\n",
      "Epoch 25433 - Train Loss: 0.076530, Train Acc: 0.878205 | Val Loss: 0.110967, Val Acc: 0.773196\n",
      "Epoch 25434 - Train Loss: 0.076528, Train Acc: 0.878205 | Val Loss: 0.110966, Val Acc: 0.773196\n",
      "Epoch 25435 - Train Loss: 0.076527, Train Acc: 0.878205 | Val Loss: 0.110966, Val Acc: 0.773196\n",
      "Epoch 25436 - Train Loss: 0.076525, Train Acc: 0.878205 | Val Loss: 0.110965, Val Acc: 0.773196\n",
      "Epoch 25437 - Train Loss: 0.076524, Train Acc: 0.878205 | Val Loss: 0.110965, Val Acc: 0.773196\n",
      "Epoch 25438 - Train Loss: 0.076522, Train Acc: 0.878205 | Val Loss: 0.110964, Val Acc: 0.773196\n",
      "Epoch 25439 - Train Loss: 0.076521, Train Acc: 0.878205 | Val Loss: 0.110964, Val Acc: 0.773196\n",
      "Epoch 25440 - Train Loss: 0.076519, Train Acc: 0.878205 | Val Loss: 0.110963, Val Acc: 0.773196\n",
      "Epoch 25441 - Train Loss: 0.076518, Train Acc: 0.878205 | Val Loss: 0.110963, Val Acc: 0.773196\n",
      "Epoch 25442 - Train Loss: 0.076516, Train Acc: 0.878205 | Val Loss: 0.110962, Val Acc: 0.773196\n",
      "Epoch 25443 - Train Loss: 0.076515, Train Acc: 0.878205 | Val Loss: 0.110962, Val Acc: 0.773196\n",
      "Epoch 25444 - Train Loss: 0.076513, Train Acc: 0.878205 | Val Loss: 0.110961, Val Acc: 0.773196\n",
      "Epoch 25445 - Train Loss: 0.076511, Train Acc: 0.878205 | Val Loss: 0.110961, Val Acc: 0.773196\n",
      "Epoch 25446 - Train Loss: 0.076510, Train Acc: 0.878205 | Val Loss: 0.110960, Val Acc: 0.773196\n",
      "Epoch 25447 - Train Loss: 0.076508, Train Acc: 0.878205 | Val Loss: 0.110960, Val Acc: 0.773196\n",
      "Epoch 25448 - Train Loss: 0.076507, Train Acc: 0.878205 | Val Loss: 0.110959, Val Acc: 0.773196\n",
      "Epoch 25449 - Train Loss: 0.076505, Train Acc: 0.878205 | Val Loss: 0.110959, Val Acc: 0.773196\n",
      "Epoch 25450 - Train Loss: 0.076504, Train Acc: 0.878205 | Val Loss: 0.110958, Val Acc: 0.773196\n",
      "Epoch 25451 - Train Loss: 0.076502, Train Acc: 0.878205 | Val Loss: 0.110958, Val Acc: 0.773196\n",
      "Epoch 25452 - Train Loss: 0.076501, Train Acc: 0.878205 | Val Loss: 0.110957, Val Acc: 0.773196\n",
      "Epoch 25453 - Train Loss: 0.076499, Train Acc: 0.878205 | Val Loss: 0.110957, Val Acc: 0.773196\n",
      "Epoch 25454 - Train Loss: 0.076498, Train Acc: 0.878205 | Val Loss: 0.110956, Val Acc: 0.773196\n",
      "Epoch 25455 - Train Loss: 0.076496, Train Acc: 0.878205 | Val Loss: 0.110956, Val Acc: 0.773196\n",
      "Epoch 25456 - Train Loss: 0.076495, Train Acc: 0.878205 | Val Loss: 0.110955, Val Acc: 0.773196\n",
      "Epoch 25457 - Train Loss: 0.076493, Train Acc: 0.878205 | Val Loss: 0.110955, Val Acc: 0.773196\n",
      "Epoch 25458 - Train Loss: 0.076492, Train Acc: 0.878205 | Val Loss: 0.110954, Val Acc: 0.773196\n",
      "Epoch 25459 - Train Loss: 0.076490, Train Acc: 0.878205 | Val Loss: 0.110954, Val Acc: 0.773196\n",
      "Epoch 25460 - Train Loss: 0.076488, Train Acc: 0.878205 | Val Loss: 0.110953, Val Acc: 0.773196\n",
      "Epoch 25461 - Train Loss: 0.076487, Train Acc: 0.878205 | Val Loss: 0.110953, Val Acc: 0.773196\n",
      "Epoch 25462 - Train Loss: 0.076485, Train Acc: 0.878205 | Val Loss: 0.110952, Val Acc: 0.773196\n",
      "Epoch 25463 - Train Loss: 0.076484, Train Acc: 0.878205 | Val Loss: 0.110952, Val Acc: 0.773196\n",
      "Epoch 25464 - Train Loss: 0.076482, Train Acc: 0.878205 | Val Loss: 0.110951, Val Acc: 0.773196\n",
      "Epoch 25465 - Train Loss: 0.076481, Train Acc: 0.878205 | Val Loss: 0.110951, Val Acc: 0.773196\n",
      "Epoch 25466 - Train Loss: 0.076479, Train Acc: 0.878205 | Val Loss: 0.110950, Val Acc: 0.773196\n",
      "Epoch 25467 - Train Loss: 0.076478, Train Acc: 0.878205 | Val Loss: 0.110950, Val Acc: 0.773196\n",
      "Epoch 25468 - Train Loss: 0.076476, Train Acc: 0.878205 | Val Loss: 0.110949, Val Acc: 0.773196\n",
      "Epoch 25469 - Train Loss: 0.076475, Train Acc: 0.878205 | Val Loss: 0.110948, Val Acc: 0.773196\n",
      "Epoch 25470 - Train Loss: 0.076473, Train Acc: 0.878205 | Val Loss: 0.110948, Val Acc: 0.773196\n",
      "Epoch 25471 - Train Loss: 0.076472, Train Acc: 0.878205 | Val Loss: 0.110947, Val Acc: 0.773196\n",
      "Epoch 25472 - Train Loss: 0.076470, Train Acc: 0.878205 | Val Loss: 0.110947, Val Acc: 0.773196\n",
      "Epoch 25473 - Train Loss: 0.076469, Train Acc: 0.878205 | Val Loss: 0.110946, Val Acc: 0.773196\n",
      "Epoch 25474 - Train Loss: 0.076467, Train Acc: 0.878205 | Val Loss: 0.110946, Val Acc: 0.773196\n",
      "Epoch 25475 - Train Loss: 0.076465, Train Acc: 0.878205 | Val Loss: 0.110945, Val Acc: 0.773196\n",
      "Epoch 25476 - Train Loss: 0.076464, Train Acc: 0.878205 | Val Loss: 0.110945, Val Acc: 0.773196\n",
      "Epoch 25477 - Train Loss: 0.076462, Train Acc: 0.878205 | Val Loss: 0.110944, Val Acc: 0.773196\n",
      "Epoch 25478 - Train Loss: 0.076461, Train Acc: 0.878205 | Val Loss: 0.110944, Val Acc: 0.773196\n",
      "Epoch 25479 - Train Loss: 0.076459, Train Acc: 0.878205 | Val Loss: 0.110943, Val Acc: 0.773196\n",
      "Epoch 25480 - Train Loss: 0.076458, Train Acc: 0.878205 | Val Loss: 0.110943, Val Acc: 0.773196\n",
      "Epoch 25481 - Train Loss: 0.076456, Train Acc: 0.878205 | Val Loss: 0.110942, Val Acc: 0.773196\n",
      "Epoch 25482 - Train Loss: 0.076455, Train Acc: 0.878205 | Val Loss: 0.110942, Val Acc: 0.773196\n",
      "Epoch 25483 - Train Loss: 0.076453, Train Acc: 0.878205 | Val Loss: 0.110941, Val Acc: 0.773196\n",
      "Epoch 25484 - Train Loss: 0.076452, Train Acc: 0.878205 | Val Loss: 0.110941, Val Acc: 0.773196\n",
      "Epoch 25485 - Train Loss: 0.076450, Train Acc: 0.878205 | Val Loss: 0.110940, Val Acc: 0.773196\n",
      "Epoch 25486 - Train Loss: 0.076449, Train Acc: 0.878205 | Val Loss: 0.110940, Val Acc: 0.773196\n",
      "Epoch 25487 - Train Loss: 0.076447, Train Acc: 0.878205 | Val Loss: 0.110939, Val Acc: 0.773196\n",
      "Epoch 25488 - Train Loss: 0.076446, Train Acc: 0.878205 | Val Loss: 0.110939, Val Acc: 0.773196\n",
      "Epoch 25489 - Train Loss: 0.076444, Train Acc: 0.878205 | Val Loss: 0.110938, Val Acc: 0.773196\n",
      "Epoch 25490 - Train Loss: 0.076442, Train Acc: 0.878205 | Val Loss: 0.110938, Val Acc: 0.773196\n",
      "Epoch 25491 - Train Loss: 0.076441, Train Acc: 0.878205 | Val Loss: 0.110937, Val Acc: 0.773196\n",
      "Epoch 25492 - Train Loss: 0.076439, Train Acc: 0.878205 | Val Loss: 0.110937, Val Acc: 0.773196\n",
      "Epoch 25493 - Train Loss: 0.076438, Train Acc: 0.878205 | Val Loss: 0.110936, Val Acc: 0.773196\n",
      "Epoch 25494 - Train Loss: 0.076436, Train Acc: 0.878205 | Val Loss: 0.110936, Val Acc: 0.773196\n",
      "Epoch 25495 - Train Loss: 0.076435, Train Acc: 0.878205 | Val Loss: 0.110935, Val Acc: 0.773196\n",
      "Epoch 25496 - Train Loss: 0.076433, Train Acc: 0.878205 | Val Loss: 0.110935, Val Acc: 0.773196\n",
      "Epoch 25497 - Train Loss: 0.076432, Train Acc: 0.878205 | Val Loss: 0.110934, Val Acc: 0.773196\n",
      "Epoch 25498 - Train Loss: 0.076430, Train Acc: 0.878205 | Val Loss: 0.110934, Val Acc: 0.773196\n",
      "Epoch 25499 - Train Loss: 0.076429, Train Acc: 0.878205 | Val Loss: 0.110933, Val Acc: 0.773196\n",
      "Epoch 25500 - Train Loss: 0.076427, Train Acc: 0.878205 | Val Loss: 0.110933, Val Acc: 0.773196\n",
      "Epoch 25501 - Train Loss: 0.076426, Train Acc: 0.878205 | Val Loss: 0.110932, Val Acc: 0.773196\n",
      "Epoch 25502 - Train Loss: 0.076424, Train Acc: 0.878205 | Val Loss: 0.110932, Val Acc: 0.773196\n",
      "Epoch 25503 - Train Loss: 0.076423, Train Acc: 0.878205 | Val Loss: 0.110931, Val Acc: 0.773196\n",
      "Epoch 25504 - Train Loss: 0.076421, Train Acc: 0.878205 | Val Loss: 0.110931, Val Acc: 0.773196\n",
      "Epoch 25505 - Train Loss: 0.076419, Train Acc: 0.878205 | Val Loss: 0.110930, Val Acc: 0.773196\n",
      "Epoch 25506 - Train Loss: 0.076418, Train Acc: 0.878205 | Val Loss: 0.110930, Val Acc: 0.773196\n",
      "Epoch 25507 - Train Loss: 0.076416, Train Acc: 0.878205 | Val Loss: 0.110929, Val Acc: 0.773196\n",
      "Epoch 25508 - Train Loss: 0.076415, Train Acc: 0.878205 | Val Loss: 0.110929, Val Acc: 0.773196\n",
      "Epoch 25509 - Train Loss: 0.076413, Train Acc: 0.878205 | Val Loss: 0.110928, Val Acc: 0.773196\n",
      "Epoch 25510 - Train Loss: 0.076412, Train Acc: 0.878205 | Val Loss: 0.110928, Val Acc: 0.773196\n",
      "Epoch 25511 - Train Loss: 0.076410, Train Acc: 0.878205 | Val Loss: 0.110927, Val Acc: 0.773196\n",
      "Epoch 25512 - Train Loss: 0.076409, Train Acc: 0.878205 | Val Loss: 0.110927, Val Acc: 0.773196\n",
      "Epoch 25513 - Train Loss: 0.076407, Train Acc: 0.878205 | Val Loss: 0.110926, Val Acc: 0.773196\n",
      "Epoch 25514 - Train Loss: 0.076406, Train Acc: 0.878205 | Val Loss: 0.110926, Val Acc: 0.773196\n",
      "Epoch 25515 - Train Loss: 0.076404, Train Acc: 0.878205 | Val Loss: 0.110925, Val Acc: 0.773196\n",
      "Epoch 25516 - Train Loss: 0.076403, Train Acc: 0.878205 | Val Loss: 0.110925, Val Acc: 0.773196\n",
      "Epoch 25517 - Train Loss: 0.076401, Train Acc: 0.878205 | Val Loss: 0.110924, Val Acc: 0.773196\n",
      "Epoch 25518 - Train Loss: 0.076400, Train Acc: 0.878205 | Val Loss: 0.110924, Val Acc: 0.773196\n",
      "Epoch 25519 - Train Loss: 0.076398, Train Acc: 0.878205 | Val Loss: 0.110923, Val Acc: 0.773196\n",
      "Epoch 25520 - Train Loss: 0.076396, Train Acc: 0.878205 | Val Loss: 0.110923, Val Acc: 0.773196\n",
      "Epoch 25521 - Train Loss: 0.076395, Train Acc: 0.878205 | Val Loss: 0.110922, Val Acc: 0.773196\n",
      "Epoch 25522 - Train Loss: 0.076393, Train Acc: 0.878205 | Val Loss: 0.110922, Val Acc: 0.773196\n",
      "Epoch 25523 - Train Loss: 0.076392, Train Acc: 0.878205 | Val Loss: 0.110921, Val Acc: 0.773196\n",
      "Epoch 25524 - Train Loss: 0.076390, Train Acc: 0.878205 | Val Loss: 0.110921, Val Acc: 0.773196\n",
      "Epoch 25525 - Train Loss: 0.076389, Train Acc: 0.878205 | Val Loss: 0.110920, Val Acc: 0.773196\n",
      "Epoch 25526 - Train Loss: 0.076387, Train Acc: 0.878205 | Val Loss: 0.110920, Val Acc: 0.773196\n",
      "Epoch 25527 - Train Loss: 0.076386, Train Acc: 0.878205 | Val Loss: 0.110919, Val Acc: 0.773196\n",
      "Epoch 25528 - Train Loss: 0.076384, Train Acc: 0.878205 | Val Loss: 0.110919, Val Acc: 0.773196\n",
      "Epoch 25529 - Train Loss: 0.076383, Train Acc: 0.878205 | Val Loss: 0.110918, Val Acc: 0.773196\n",
      "Epoch 25530 - Train Loss: 0.076381, Train Acc: 0.878205 | Val Loss: 0.110918, Val Acc: 0.773196\n",
      "Epoch 25531 - Train Loss: 0.076380, Train Acc: 0.878205 | Val Loss: 0.110917, Val Acc: 0.773196\n",
      "Epoch 25532 - Train Loss: 0.076378, Train Acc: 0.878205 | Val Loss: 0.110917, Val Acc: 0.773196\n",
      "Epoch 25533 - Train Loss: 0.076377, Train Acc: 0.878205 | Val Loss: 0.110916, Val Acc: 0.773196\n",
      "Epoch 25534 - Train Loss: 0.076375, Train Acc: 0.878205 | Val Loss: 0.110916, Val Acc: 0.773196\n",
      "Epoch 25535 - Train Loss: 0.076374, Train Acc: 0.878205 | Val Loss: 0.110915, Val Acc: 0.773196\n",
      "Epoch 25536 - Train Loss: 0.076372, Train Acc: 0.878205 | Val Loss: 0.110915, Val Acc: 0.773196\n",
      "Epoch 25537 - Train Loss: 0.076370, Train Acc: 0.878205 | Val Loss: 0.110914, Val Acc: 0.773196\n",
      "Epoch 25538 - Train Loss: 0.076369, Train Acc: 0.878205 | Val Loss: 0.110913, Val Acc: 0.773196\n",
      "Epoch 25539 - Train Loss: 0.076367, Train Acc: 0.878205 | Val Loss: 0.110913, Val Acc: 0.773196\n",
      "Epoch 25540 - Train Loss: 0.076366, Train Acc: 0.878205 | Val Loss: 0.110912, Val Acc: 0.773196\n",
      "Epoch 25541 - Train Loss: 0.076364, Train Acc: 0.878205 | Val Loss: 0.110912, Val Acc: 0.773196\n",
      "Epoch 25542 - Train Loss: 0.076363, Train Acc: 0.878205 | Val Loss: 0.110911, Val Acc: 0.773196\n",
      "Epoch 25543 - Train Loss: 0.076361, Train Acc: 0.878205 | Val Loss: 0.110911, Val Acc: 0.773196\n",
      "Epoch 25544 - Train Loss: 0.076360, Train Acc: 0.878205 | Val Loss: 0.110910, Val Acc: 0.773196\n",
      "Epoch 25545 - Train Loss: 0.076358, Train Acc: 0.878205 | Val Loss: 0.110910, Val Acc: 0.773196\n",
      "Epoch 25546 - Train Loss: 0.076357, Train Acc: 0.878205 | Val Loss: 0.110909, Val Acc: 0.773196\n",
      "Epoch 25547 - Train Loss: 0.076355, Train Acc: 0.879487 | Val Loss: 0.110909, Val Acc: 0.773196\n",
      "Epoch 25548 - Train Loss: 0.076354, Train Acc: 0.879487 | Val Loss: 0.110908, Val Acc: 0.773196\n",
      "Epoch 25549 - Train Loss: 0.076352, Train Acc: 0.879487 | Val Loss: 0.110908, Val Acc: 0.773196\n",
      "Epoch 25550 - Train Loss: 0.076351, Train Acc: 0.879487 | Val Loss: 0.110907, Val Acc: 0.773196\n",
      "Epoch 25551 - Train Loss: 0.076349, Train Acc: 0.879487 | Val Loss: 0.110907, Val Acc: 0.773196\n",
      "Epoch 25552 - Train Loss: 0.076348, Train Acc: 0.879487 | Val Loss: 0.110906, Val Acc: 0.773196\n",
      "Epoch 25553 - Train Loss: 0.076346, Train Acc: 0.879487 | Val Loss: 0.110906, Val Acc: 0.773196\n",
      "Epoch 25554 - Train Loss: 0.076345, Train Acc: 0.879487 | Val Loss: 0.110905, Val Acc: 0.773196\n",
      "Epoch 25555 - Train Loss: 0.076343, Train Acc: 0.879487 | Val Loss: 0.110905, Val Acc: 0.773196\n",
      "Epoch 25556 - Train Loss: 0.076341, Train Acc: 0.879487 | Val Loss: 0.110904, Val Acc: 0.773196\n",
      "Epoch 25557 - Train Loss: 0.076340, Train Acc: 0.879487 | Val Loss: 0.110904, Val Acc: 0.773196\n",
      "Epoch 25558 - Train Loss: 0.076338, Train Acc: 0.879487 | Val Loss: 0.110903, Val Acc: 0.773196\n",
      "Epoch 25559 - Train Loss: 0.076337, Train Acc: 0.879487 | Val Loss: 0.110903, Val Acc: 0.773196\n",
      "Epoch 25560 - Train Loss: 0.076335, Train Acc: 0.879487 | Val Loss: 0.110902, Val Acc: 0.773196\n",
      "Epoch 25561 - Train Loss: 0.076334, Train Acc: 0.879487 | Val Loss: 0.110902, Val Acc: 0.773196\n",
      "Epoch 25562 - Train Loss: 0.076332, Train Acc: 0.879487 | Val Loss: 0.110901, Val Acc: 0.773196\n",
      "Epoch 25563 - Train Loss: 0.076331, Train Acc: 0.879487 | Val Loss: 0.110901, Val Acc: 0.773196\n",
      "Epoch 25564 - Train Loss: 0.076329, Train Acc: 0.879487 | Val Loss: 0.110900, Val Acc: 0.773196\n",
      "Epoch 25565 - Train Loss: 0.076328, Train Acc: 0.879487 | Val Loss: 0.110900, Val Acc: 0.773196\n",
      "Epoch 25566 - Train Loss: 0.076326, Train Acc: 0.879487 | Val Loss: 0.110899, Val Acc: 0.773196\n",
      "Epoch 25567 - Train Loss: 0.076325, Train Acc: 0.879487 | Val Loss: 0.110899, Val Acc: 0.773196\n",
      "Epoch 25568 - Train Loss: 0.076323, Train Acc: 0.879487 | Val Loss: 0.110898, Val Acc: 0.773196\n",
      "Epoch 25569 - Train Loss: 0.076322, Train Acc: 0.879487 | Val Loss: 0.110898, Val Acc: 0.773196\n",
      "Epoch 25570 - Train Loss: 0.076320, Train Acc: 0.879487 | Val Loss: 0.110897, Val Acc: 0.773196\n",
      "Epoch 25571 - Train Loss: 0.076319, Train Acc: 0.879487 | Val Loss: 0.110897, Val Acc: 0.773196\n",
      "Epoch 25572 - Train Loss: 0.076317, Train Acc: 0.879487 | Val Loss: 0.110896, Val Acc: 0.773196\n",
      "Epoch 25573 - Train Loss: 0.076316, Train Acc: 0.879487 | Val Loss: 0.110896, Val Acc: 0.773196\n",
      "Epoch 25574 - Train Loss: 0.076314, Train Acc: 0.879487 | Val Loss: 0.110895, Val Acc: 0.773196\n",
      "Epoch 25575 - Train Loss: 0.076312, Train Acc: 0.879487 | Val Loss: 0.110895, Val Acc: 0.773196\n",
      "Epoch 25576 - Train Loss: 0.076311, Train Acc: 0.879487 | Val Loss: 0.110894, Val Acc: 0.773196\n",
      "Epoch 25577 - Train Loss: 0.076309, Train Acc: 0.879487 | Val Loss: 0.110894, Val Acc: 0.773196\n",
      "Epoch 25578 - Train Loss: 0.076308, Train Acc: 0.879487 | Val Loss: 0.110893, Val Acc: 0.773196\n",
      "Epoch 25579 - Train Loss: 0.076306, Train Acc: 0.879487 | Val Loss: 0.110893, Val Acc: 0.773196\n",
      "Epoch 25580 - Train Loss: 0.076305, Train Acc: 0.879487 | Val Loss: 0.110892, Val Acc: 0.773196\n",
      "Epoch 25581 - Train Loss: 0.076303, Train Acc: 0.879487 | Val Loss: 0.110892, Val Acc: 0.773196\n",
      "Epoch 25582 - Train Loss: 0.076302, Train Acc: 0.879487 | Val Loss: 0.110891, Val Acc: 0.773196\n",
      "Epoch 25583 - Train Loss: 0.076300, Train Acc: 0.879487 | Val Loss: 0.110891, Val Acc: 0.773196\n",
      "Epoch 25584 - Train Loss: 0.076299, Train Acc: 0.879487 | Val Loss: 0.110890, Val Acc: 0.773196\n",
      "Epoch 25585 - Train Loss: 0.076297, Train Acc: 0.879487 | Val Loss: 0.110890, Val Acc: 0.773196\n",
      "Epoch 25586 - Train Loss: 0.076296, Train Acc: 0.879487 | Val Loss: 0.110889, Val Acc: 0.773196\n",
      "Epoch 25587 - Train Loss: 0.076294, Train Acc: 0.879487 | Val Loss: 0.110889, Val Acc: 0.773196\n",
      "Epoch 25588 - Train Loss: 0.076293, Train Acc: 0.879487 | Val Loss: 0.110888, Val Acc: 0.773196\n",
      "Epoch 25589 - Train Loss: 0.076291, Train Acc: 0.879487 | Val Loss: 0.110888, Val Acc: 0.773196\n",
      "Epoch 25590 - Train Loss: 0.076290, Train Acc: 0.879487 | Val Loss: 0.110887, Val Acc: 0.773196\n",
      "Epoch 25591 - Train Loss: 0.076288, Train Acc: 0.879487 | Val Loss: 0.110887, Val Acc: 0.773196\n",
      "Epoch 25592 - Train Loss: 0.076287, Train Acc: 0.879487 | Val Loss: 0.110886, Val Acc: 0.773196\n",
      "Epoch 25593 - Train Loss: 0.076285, Train Acc: 0.879487 | Val Loss: 0.110886, Val Acc: 0.773196\n",
      "Epoch 25594 - Train Loss: 0.076284, Train Acc: 0.879487 | Val Loss: 0.110885, Val Acc: 0.773196\n",
      "Epoch 25595 - Train Loss: 0.076282, Train Acc: 0.879487 | Val Loss: 0.110885, Val Acc: 0.773196\n",
      "Epoch 25596 - Train Loss: 0.076280, Train Acc: 0.879487 | Val Loss: 0.110884, Val Acc: 0.773196\n",
      "Epoch 25597 - Train Loss: 0.076279, Train Acc: 0.879487 | Val Loss: 0.110884, Val Acc: 0.773196\n",
      "Epoch 25598 - Train Loss: 0.076277, Train Acc: 0.879487 | Val Loss: 0.110883, Val Acc: 0.773196\n",
      "Epoch 25599 - Train Loss: 0.076276, Train Acc: 0.879487 | Val Loss: 0.110883, Val Acc: 0.773196\n",
      "Epoch 25600 - Train Loss: 0.076274, Train Acc: 0.879487 | Val Loss: 0.110882, Val Acc: 0.773196\n",
      "Epoch 25601 - Train Loss: 0.076273, Train Acc: 0.879487 | Val Loss: 0.110882, Val Acc: 0.773196\n",
      "Epoch 25602 - Train Loss: 0.076271, Train Acc: 0.879487 | Val Loss: 0.110881, Val Acc: 0.773196\n",
      "Epoch 25603 - Train Loss: 0.076270, Train Acc: 0.879487 | Val Loss: 0.110881, Val Acc: 0.773196\n",
      "Epoch 25604 - Train Loss: 0.076268, Train Acc: 0.879487 | Val Loss: 0.110880, Val Acc: 0.773196\n",
      "Epoch 25605 - Train Loss: 0.076267, Train Acc: 0.879487 | Val Loss: 0.110880, Val Acc: 0.773196\n",
      "Epoch 25606 - Train Loss: 0.076265, Train Acc: 0.879487 | Val Loss: 0.110879, Val Acc: 0.773196\n",
      "Epoch 25607 - Train Loss: 0.076264, Train Acc: 0.879487 | Val Loss: 0.110879, Val Acc: 0.773196\n",
      "Epoch 25608 - Train Loss: 0.076262, Train Acc: 0.879487 | Val Loss: 0.110878, Val Acc: 0.773196\n",
      "Epoch 25609 - Train Loss: 0.076261, Train Acc: 0.879487 | Val Loss: 0.110878, Val Acc: 0.773196\n",
      "Epoch 25610 - Train Loss: 0.076259, Train Acc: 0.879487 | Val Loss: 0.110877, Val Acc: 0.773196\n",
      "Epoch 25611 - Train Loss: 0.076258, Train Acc: 0.879487 | Val Loss: 0.110877, Val Acc: 0.773196\n",
      "Epoch 25612 - Train Loss: 0.076256, Train Acc: 0.879487 | Val Loss: 0.110876, Val Acc: 0.773196\n",
      "Epoch 25613 - Train Loss: 0.076255, Train Acc: 0.879487 | Val Loss: 0.110876, Val Acc: 0.773196\n",
      "Epoch 25614 - Train Loss: 0.076253, Train Acc: 0.879487 | Val Loss: 0.110875, Val Acc: 0.773196\n",
      "Epoch 25615 - Train Loss: 0.076252, Train Acc: 0.879487 | Val Loss: 0.110875, Val Acc: 0.773196\n",
      "Epoch 25616 - Train Loss: 0.076250, Train Acc: 0.879487 | Val Loss: 0.110874, Val Acc: 0.773196\n",
      "Epoch 25617 - Train Loss: 0.076248, Train Acc: 0.879487 | Val Loss: 0.110874, Val Acc: 0.773196\n",
      "Epoch 25618 - Train Loss: 0.076247, Train Acc: 0.879487 | Val Loss: 0.110873, Val Acc: 0.773196\n",
      "Epoch 25619 - Train Loss: 0.076245, Train Acc: 0.879487 | Val Loss: 0.110873, Val Acc: 0.773196\n",
      "Epoch 25620 - Train Loss: 0.076244, Train Acc: 0.879487 | Val Loss: 0.110872, Val Acc: 0.773196\n",
      "Epoch 25621 - Train Loss: 0.076242, Train Acc: 0.879487 | Val Loss: 0.110872, Val Acc: 0.773196\n",
      "Epoch 25622 - Train Loss: 0.076241, Train Acc: 0.879487 | Val Loss: 0.110871, Val Acc: 0.773196\n",
      "Epoch 25623 - Train Loss: 0.076239, Train Acc: 0.879487 | Val Loss: 0.110871, Val Acc: 0.773196\n",
      "Epoch 25624 - Train Loss: 0.076238, Train Acc: 0.879487 | Val Loss: 0.110870, Val Acc: 0.773196\n",
      "Epoch 25625 - Train Loss: 0.076236, Train Acc: 0.879487 | Val Loss: 0.110870, Val Acc: 0.773196\n",
      "Epoch 25626 - Train Loss: 0.076235, Train Acc: 0.879487 | Val Loss: 0.110869, Val Acc: 0.773196\n",
      "Epoch 25627 - Train Loss: 0.076233, Train Acc: 0.879487 | Val Loss: 0.110869, Val Acc: 0.773196\n",
      "Epoch 25628 - Train Loss: 0.076232, Train Acc: 0.879487 | Val Loss: 0.110868, Val Acc: 0.773196\n",
      "Epoch 25629 - Train Loss: 0.076230, Train Acc: 0.879487 | Val Loss: 0.110868, Val Acc: 0.773196\n",
      "Epoch 25630 - Train Loss: 0.076229, Train Acc: 0.879487 | Val Loss: 0.110867, Val Acc: 0.773196\n",
      "Epoch 25631 - Train Loss: 0.076227, Train Acc: 0.879487 | Val Loss: 0.110867, Val Acc: 0.773196\n",
      "Epoch 25632 - Train Loss: 0.076226, Train Acc: 0.879487 | Val Loss: 0.110866, Val Acc: 0.773196\n",
      "Epoch 25633 - Train Loss: 0.076224, Train Acc: 0.879487 | Val Loss: 0.110866, Val Acc: 0.773196\n",
      "Epoch 25634 - Train Loss: 0.076223, Train Acc: 0.879487 | Val Loss: 0.110865, Val Acc: 0.773196\n",
      "Epoch 25635 - Train Loss: 0.076221, Train Acc: 0.879487 | Val Loss: 0.110865, Val Acc: 0.773196\n",
      "Epoch 25636 - Train Loss: 0.076220, Train Acc: 0.879487 | Val Loss: 0.110864, Val Acc: 0.773196\n",
      "Epoch 25637 - Train Loss: 0.076218, Train Acc: 0.879487 | Val Loss: 0.110864, Val Acc: 0.773196\n",
      "Epoch 25638 - Train Loss: 0.076217, Train Acc: 0.879487 | Val Loss: 0.110863, Val Acc: 0.773196\n",
      "Epoch 25639 - Train Loss: 0.076215, Train Acc: 0.879487 | Val Loss: 0.110863, Val Acc: 0.773196\n",
      "Epoch 25640 - Train Loss: 0.076214, Train Acc: 0.879487 | Val Loss: 0.110862, Val Acc: 0.773196\n",
      "Epoch 25641 - Train Loss: 0.076212, Train Acc: 0.879487 | Val Loss: 0.110862, Val Acc: 0.773196\n",
      "Epoch 25642 - Train Loss: 0.076210, Train Acc: 0.879487 | Val Loss: 0.110861, Val Acc: 0.773196\n",
      "Epoch 25643 - Train Loss: 0.076209, Train Acc: 0.879487 | Val Loss: 0.110861, Val Acc: 0.773196\n",
      "Epoch 25644 - Train Loss: 0.076207, Train Acc: 0.879487 | Val Loss: 0.110860, Val Acc: 0.773196\n",
      "Epoch 25645 - Train Loss: 0.076206, Train Acc: 0.879487 | Val Loss: 0.110860, Val Acc: 0.773196\n",
      "Epoch 25646 - Train Loss: 0.076204, Train Acc: 0.879487 | Val Loss: 0.110859, Val Acc: 0.773196\n",
      "Epoch 25647 - Train Loss: 0.076203, Train Acc: 0.879487 | Val Loss: 0.110859, Val Acc: 0.773196\n",
      "Epoch 25648 - Train Loss: 0.076201, Train Acc: 0.879487 | Val Loss: 0.110858, Val Acc: 0.773196\n",
      "Epoch 25649 - Train Loss: 0.076200, Train Acc: 0.879487 | Val Loss: 0.110858, Val Acc: 0.773196\n",
      "Epoch 25650 - Train Loss: 0.076198, Train Acc: 0.879487 | Val Loss: 0.110857, Val Acc: 0.773196\n",
      "Epoch 25651 - Train Loss: 0.076197, Train Acc: 0.879487 | Val Loss: 0.110857, Val Acc: 0.773196\n",
      "Epoch 25652 - Train Loss: 0.076195, Train Acc: 0.879487 | Val Loss: 0.110856, Val Acc: 0.773196\n",
      "Epoch 25653 - Train Loss: 0.076194, Train Acc: 0.879487 | Val Loss: 0.110856, Val Acc: 0.773196\n",
      "Epoch 25654 - Train Loss: 0.076192, Train Acc: 0.879487 | Val Loss: 0.110855, Val Acc: 0.773196\n",
      "Epoch 25655 - Train Loss: 0.076191, Train Acc: 0.879487 | Val Loss: 0.110855, Val Acc: 0.773196\n",
      "Epoch 25656 - Train Loss: 0.076189, Train Acc: 0.879487 | Val Loss: 0.110854, Val Acc: 0.773196\n",
      "Epoch 25657 - Train Loss: 0.076188, Train Acc: 0.879487 | Val Loss: 0.110854, Val Acc: 0.773196\n",
      "Epoch 25658 - Train Loss: 0.076186, Train Acc: 0.879487 | Val Loss: 0.110853, Val Acc: 0.773196\n",
      "Epoch 25659 - Train Loss: 0.076185, Train Acc: 0.879487 | Val Loss: 0.110853, Val Acc: 0.773196\n",
      "Epoch 25660 - Train Loss: 0.076183, Train Acc: 0.879487 | Val Loss: 0.110852, Val Acc: 0.773196\n",
      "Epoch 25661 - Train Loss: 0.076182, Train Acc: 0.879487 | Val Loss: 0.110852, Val Acc: 0.773196\n",
      "Epoch 25662 - Train Loss: 0.076180, Train Acc: 0.879487 | Val Loss: 0.110851, Val Acc: 0.773196\n",
      "Epoch 25663 - Train Loss: 0.076179, Train Acc: 0.879487 | Val Loss: 0.110851, Val Acc: 0.773196\n",
      "Epoch 25664 - Train Loss: 0.076177, Train Acc: 0.879487 | Val Loss: 0.110850, Val Acc: 0.773196\n",
      "Epoch 25665 - Train Loss: 0.076176, Train Acc: 0.879487 | Val Loss: 0.110850, Val Acc: 0.773196\n",
      "Epoch 25666 - Train Loss: 0.076174, Train Acc: 0.879487 | Val Loss: 0.110849, Val Acc: 0.773196\n",
      "Epoch 25667 - Train Loss: 0.076173, Train Acc: 0.879487 | Val Loss: 0.110849, Val Acc: 0.773196\n",
      "Epoch 25668 - Train Loss: 0.076171, Train Acc: 0.879487 | Val Loss: 0.110848, Val Acc: 0.773196\n",
      "Epoch 25669 - Train Loss: 0.076169, Train Acc: 0.879487 | Val Loss: 0.110848, Val Acc: 0.773196\n",
      "Epoch 25670 - Train Loss: 0.076168, Train Acc: 0.879487 | Val Loss: 0.110847, Val Acc: 0.773196\n",
      "Epoch 25671 - Train Loss: 0.076166, Train Acc: 0.879487 | Val Loss: 0.110847, Val Acc: 0.773196\n",
      "Epoch 25672 - Train Loss: 0.076165, Train Acc: 0.879487 | Val Loss: 0.110847, Val Acc: 0.773196\n",
      "Epoch 25673 - Train Loss: 0.076163, Train Acc: 0.879487 | Val Loss: 0.110846, Val Acc: 0.773196\n",
      "Epoch 25674 - Train Loss: 0.076162, Train Acc: 0.879487 | Val Loss: 0.110846, Val Acc: 0.773196\n",
      "Epoch 25675 - Train Loss: 0.076160, Train Acc: 0.879487 | Val Loss: 0.110845, Val Acc: 0.773196\n",
      "Epoch 25676 - Train Loss: 0.076159, Train Acc: 0.879487 | Val Loss: 0.110845, Val Acc: 0.773196\n",
      "Epoch 25677 - Train Loss: 0.076157, Train Acc: 0.879487 | Val Loss: 0.110844, Val Acc: 0.773196\n",
      "Epoch 25678 - Train Loss: 0.076156, Train Acc: 0.879487 | Val Loss: 0.110844, Val Acc: 0.773196\n",
      "Epoch 25679 - Train Loss: 0.076154, Train Acc: 0.879487 | Val Loss: 0.110843, Val Acc: 0.773196\n",
      "Epoch 25680 - Train Loss: 0.076153, Train Acc: 0.879487 | Val Loss: 0.110843, Val Acc: 0.773196\n",
      "Epoch 25681 - Train Loss: 0.076151, Train Acc: 0.879487 | Val Loss: 0.110842, Val Acc: 0.773196\n",
      "Epoch 25682 - Train Loss: 0.076150, Train Acc: 0.879487 | Val Loss: 0.110842, Val Acc: 0.773196\n",
      "Epoch 25683 - Train Loss: 0.076148, Train Acc: 0.879487 | Val Loss: 0.110841, Val Acc: 0.773196\n",
      "Epoch 25684 - Train Loss: 0.076147, Train Acc: 0.879487 | Val Loss: 0.110841, Val Acc: 0.773196\n",
      "Epoch 25685 - Train Loss: 0.076145, Train Acc: 0.879487 | Val Loss: 0.110840, Val Acc: 0.773196\n",
      "Epoch 25686 - Train Loss: 0.076144, Train Acc: 0.879487 | Val Loss: 0.110840, Val Acc: 0.773196\n",
      "Epoch 25687 - Train Loss: 0.076142, Train Acc: 0.879487 | Val Loss: 0.110839, Val Acc: 0.773196\n",
      "Epoch 25688 - Train Loss: 0.076141, Train Acc: 0.879487 | Val Loss: 0.110839, Val Acc: 0.773196\n",
      "Epoch 25689 - Train Loss: 0.076139, Train Acc: 0.879487 | Val Loss: 0.110838, Val Acc: 0.773196\n",
      "Epoch 25690 - Train Loss: 0.076138, Train Acc: 0.879487 | Val Loss: 0.110838, Val Acc: 0.773196\n",
      "Epoch 25691 - Train Loss: 0.076136, Train Acc: 0.879487 | Val Loss: 0.110837, Val Acc: 0.773196\n",
      "Epoch 25692 - Train Loss: 0.076135, Train Acc: 0.879487 | Val Loss: 0.110837, Val Acc: 0.773196\n",
      "Epoch 25693 - Train Loss: 0.076133, Train Acc: 0.879487 | Val Loss: 0.110836, Val Acc: 0.773196\n",
      "Epoch 25694 - Train Loss: 0.076132, Train Acc: 0.879487 | Val Loss: 0.110836, Val Acc: 0.773196\n",
      "Epoch 25695 - Train Loss: 0.076130, Train Acc: 0.879487 | Val Loss: 0.110835, Val Acc: 0.773196\n",
      "Epoch 25696 - Train Loss: 0.076129, Train Acc: 0.879487 | Val Loss: 0.110835, Val Acc: 0.773196\n",
      "Epoch 25697 - Train Loss: 0.076127, Train Acc: 0.879487 | Val Loss: 0.110834, Val Acc: 0.773196\n",
      "Epoch 25698 - Train Loss: 0.076126, Train Acc: 0.879487 | Val Loss: 0.110834, Val Acc: 0.773196\n",
      "Epoch 25699 - Train Loss: 0.076124, Train Acc: 0.879487 | Val Loss: 0.110833, Val Acc: 0.773196\n",
      "Epoch 25700 - Train Loss: 0.076122, Train Acc: 0.879487 | Val Loss: 0.110833, Val Acc: 0.773196\n",
      "Epoch 25701 - Train Loss: 0.076121, Train Acc: 0.879487 | Val Loss: 0.110832, Val Acc: 0.773196\n",
      "Epoch 25702 - Train Loss: 0.076119, Train Acc: 0.879487 | Val Loss: 0.110832, Val Acc: 0.773196\n",
      "Epoch 25703 - Train Loss: 0.076118, Train Acc: 0.879487 | Val Loss: 0.110831, Val Acc: 0.773196\n",
      "Epoch 25704 - Train Loss: 0.076116, Train Acc: 0.879487 | Val Loss: 0.110831, Val Acc: 0.773196\n",
      "Epoch 25705 - Train Loss: 0.076115, Train Acc: 0.879487 | Val Loss: 0.110830, Val Acc: 0.773196\n",
      "Epoch 25706 - Train Loss: 0.076113, Train Acc: 0.879487 | Val Loss: 0.110830, Val Acc: 0.773196\n",
      "Epoch 25707 - Train Loss: 0.076112, Train Acc: 0.879487 | Val Loss: 0.110829, Val Acc: 0.773196\n",
      "Epoch 25708 - Train Loss: 0.076110, Train Acc: 0.879487 | Val Loss: 0.110829, Val Acc: 0.773196\n",
      "Epoch 25709 - Train Loss: 0.076109, Train Acc: 0.879487 | Val Loss: 0.110828, Val Acc: 0.773196\n",
      "Epoch 25710 - Train Loss: 0.076107, Train Acc: 0.879487 | Val Loss: 0.110828, Val Acc: 0.773196\n",
      "Epoch 25711 - Train Loss: 0.076106, Train Acc: 0.879487 | Val Loss: 0.110827, Val Acc: 0.773196\n",
      "Epoch 25712 - Train Loss: 0.076104, Train Acc: 0.879487 | Val Loss: 0.110827, Val Acc: 0.773196\n",
      "Epoch 25713 - Train Loss: 0.076103, Train Acc: 0.879487 | Val Loss: 0.110826, Val Acc: 0.773196\n",
      "Epoch 25714 - Train Loss: 0.076101, Train Acc: 0.879487 | Val Loss: 0.110826, Val Acc: 0.773196\n",
      "Epoch 25715 - Train Loss: 0.076100, Train Acc: 0.879487 | Val Loss: 0.110825, Val Acc: 0.773196\n",
      "Epoch 25716 - Train Loss: 0.076098, Train Acc: 0.879487 | Val Loss: 0.110825, Val Acc: 0.773196\n",
      "Epoch 25717 - Train Loss: 0.076097, Train Acc: 0.879487 | Val Loss: 0.110824, Val Acc: 0.773196\n",
      "Epoch 25718 - Train Loss: 0.076095, Train Acc: 0.879487 | Val Loss: 0.110824, Val Acc: 0.773196\n",
      "Epoch 25719 - Train Loss: 0.076094, Train Acc: 0.879487 | Val Loss: 0.110823, Val Acc: 0.773196\n",
      "Epoch 25720 - Train Loss: 0.076092, Train Acc: 0.879487 | Val Loss: 0.110823, Val Acc: 0.773196\n",
      "Epoch 25721 - Train Loss: 0.076091, Train Acc: 0.879487 | Val Loss: 0.110822, Val Acc: 0.773196\n",
      "Epoch 25722 - Train Loss: 0.076089, Train Acc: 0.879487 | Val Loss: 0.110822, Val Acc: 0.773196\n",
      "Epoch 25723 - Train Loss: 0.076088, Train Acc: 0.879487 | Val Loss: 0.110821, Val Acc: 0.773196\n",
      "Epoch 25724 - Train Loss: 0.076086, Train Acc: 0.879487 | Val Loss: 0.110821, Val Acc: 0.773196\n",
      "Epoch 25725 - Train Loss: 0.076085, Train Acc: 0.879487 | Val Loss: 0.110820, Val Acc: 0.773196\n",
      "Epoch 25726 - Train Loss: 0.076083, Train Acc: 0.879487 | Val Loss: 0.110820, Val Acc: 0.773196\n",
      "Epoch 25727 - Train Loss: 0.076082, Train Acc: 0.879487 | Val Loss: 0.110819, Val Acc: 0.773196\n",
      "Epoch 25728 - Train Loss: 0.076080, Train Acc: 0.879487 | Val Loss: 0.110819, Val Acc: 0.773196\n",
      "Epoch 25729 - Train Loss: 0.076079, Train Acc: 0.879487 | Val Loss: 0.110818, Val Acc: 0.773196\n",
      "Epoch 25730 - Train Loss: 0.076077, Train Acc: 0.879487 | Val Loss: 0.110818, Val Acc: 0.773196\n",
      "Epoch 25731 - Train Loss: 0.076076, Train Acc: 0.879487 | Val Loss: 0.110817, Val Acc: 0.773196\n",
      "Epoch 25732 - Train Loss: 0.076074, Train Acc: 0.879487 | Val Loss: 0.110817, Val Acc: 0.773196\n",
      "Epoch 25733 - Train Loss: 0.076073, Train Acc: 0.879487 | Val Loss: 0.110816, Val Acc: 0.773196\n",
      "Epoch 25734 - Train Loss: 0.076071, Train Acc: 0.879487 | Val Loss: 0.110816, Val Acc: 0.773196\n",
      "Epoch 25735 - Train Loss: 0.076070, Train Acc: 0.879487 | Val Loss: 0.110815, Val Acc: 0.773196\n",
      "Epoch 25736 - Train Loss: 0.076068, Train Acc: 0.879487 | Val Loss: 0.110815, Val Acc: 0.773196\n",
      "Epoch 25737 - Train Loss: 0.076067, Train Acc: 0.879487 | Val Loss: 0.110814, Val Acc: 0.773196\n",
      "Epoch 25738 - Train Loss: 0.076065, Train Acc: 0.879487 | Val Loss: 0.110814, Val Acc: 0.773196\n",
      "Epoch 25739 - Train Loss: 0.076063, Train Acc: 0.879487 | Val Loss: 0.110813, Val Acc: 0.773196\n",
      "Epoch 25740 - Train Loss: 0.076062, Train Acc: 0.879487 | Val Loss: 0.110813, Val Acc: 0.773196\n",
      "Epoch 25741 - Train Loss: 0.076060, Train Acc: 0.879487 | Val Loss: 0.110812, Val Acc: 0.773196\n",
      "Epoch 25742 - Train Loss: 0.076059, Train Acc: 0.879487 | Val Loss: 0.110812, Val Acc: 0.773196\n",
      "Epoch 25743 - Train Loss: 0.076057, Train Acc: 0.879487 | Val Loss: 0.110812, Val Acc: 0.773196\n",
      "Epoch 25744 - Train Loss: 0.076056, Train Acc: 0.879487 | Val Loss: 0.110811, Val Acc: 0.773196\n",
      "Epoch 25745 - Train Loss: 0.076054, Train Acc: 0.879487 | Val Loss: 0.110811, Val Acc: 0.773196\n",
      "Epoch 25746 - Train Loss: 0.076053, Train Acc: 0.879487 | Val Loss: 0.110810, Val Acc: 0.773196\n",
      "Epoch 25747 - Train Loss: 0.076051, Train Acc: 0.879487 | Val Loss: 0.110810, Val Acc: 0.773196\n",
      "Epoch 25748 - Train Loss: 0.076050, Train Acc: 0.879487 | Val Loss: 0.110809, Val Acc: 0.773196\n",
      "Epoch 25749 - Train Loss: 0.076048, Train Acc: 0.879487 | Val Loss: 0.110809, Val Acc: 0.773196\n",
      "Epoch 25750 - Train Loss: 0.076047, Train Acc: 0.879487 | Val Loss: 0.110808, Val Acc: 0.773196\n",
      "Epoch 25751 - Train Loss: 0.076045, Train Acc: 0.879487 | Val Loss: 0.110808, Val Acc: 0.773196\n",
      "Epoch 25752 - Train Loss: 0.076044, Train Acc: 0.879487 | Val Loss: 0.110807, Val Acc: 0.773196\n",
      "Epoch 25753 - Train Loss: 0.076042, Train Acc: 0.879487 | Val Loss: 0.110807, Val Acc: 0.773196\n",
      "Epoch 25754 - Train Loss: 0.076041, Train Acc: 0.879487 | Val Loss: 0.110806, Val Acc: 0.773196\n",
      "Epoch 25755 - Train Loss: 0.076039, Train Acc: 0.879487 | Val Loss: 0.110806, Val Acc: 0.773196\n",
      "Epoch 25756 - Train Loss: 0.076038, Train Acc: 0.879487 | Val Loss: 0.110805, Val Acc: 0.773196\n",
      "Epoch 25757 - Train Loss: 0.076036, Train Acc: 0.879487 | Val Loss: 0.110805, Val Acc: 0.773196\n",
      "Epoch 25758 - Train Loss: 0.076035, Train Acc: 0.879487 | Val Loss: 0.110804, Val Acc: 0.773196\n",
      "Epoch 25759 - Train Loss: 0.076033, Train Acc: 0.879487 | Val Loss: 0.110804, Val Acc: 0.773196\n",
      "Epoch 25760 - Train Loss: 0.076032, Train Acc: 0.879487 | Val Loss: 0.110803, Val Acc: 0.773196\n",
      "Epoch 25761 - Train Loss: 0.076030, Train Acc: 0.879487 | Val Loss: 0.110803, Val Acc: 0.773196\n",
      "Epoch 25762 - Train Loss: 0.076029, Train Acc: 0.879487 | Val Loss: 0.110802, Val Acc: 0.773196\n",
      "Epoch 25763 - Train Loss: 0.076027, Train Acc: 0.879487 | Val Loss: 0.110802, Val Acc: 0.773196\n",
      "Epoch 25764 - Train Loss: 0.076026, Train Acc: 0.879487 | Val Loss: 0.110801, Val Acc: 0.773196\n",
      "Epoch 25765 - Train Loss: 0.076024, Train Acc: 0.879487 | Val Loss: 0.110801, Val Acc: 0.773196\n",
      "Epoch 25766 - Train Loss: 0.076023, Train Acc: 0.879487 | Val Loss: 0.110800, Val Acc: 0.773196\n",
      "Epoch 25767 - Train Loss: 0.076021, Train Acc: 0.879487 | Val Loss: 0.110800, Val Acc: 0.773196\n",
      "Epoch 25768 - Train Loss: 0.076020, Train Acc: 0.879487 | Val Loss: 0.110799, Val Acc: 0.773196\n",
      "Epoch 25769 - Train Loss: 0.076018, Train Acc: 0.879487 | Val Loss: 0.110799, Val Acc: 0.773196\n",
      "Epoch 25770 - Train Loss: 0.076017, Train Acc: 0.879487 | Val Loss: 0.110798, Val Acc: 0.773196\n",
      "Epoch 25771 - Train Loss: 0.076015, Train Acc: 0.879487 | Val Loss: 0.110798, Val Acc: 0.773196\n",
      "Epoch 25772 - Train Loss: 0.076014, Train Acc: 0.879487 | Val Loss: 0.110797, Val Acc: 0.773196\n",
      "Epoch 25773 - Train Loss: 0.076012, Train Acc: 0.879487 | Val Loss: 0.110797, Val Acc: 0.773196\n",
      "Epoch 25774 - Train Loss: 0.076011, Train Acc: 0.879487 | Val Loss: 0.110796, Val Acc: 0.773196\n",
      "Epoch 25775 - Train Loss: 0.076009, Train Acc: 0.879487 | Val Loss: 0.110796, Val Acc: 0.773196\n",
      "Epoch 25776 - Train Loss: 0.076008, Train Acc: 0.879487 | Val Loss: 0.110795, Val Acc: 0.773196\n",
      "Epoch 25777 - Train Loss: 0.076006, Train Acc: 0.879487 | Val Loss: 0.110795, Val Acc: 0.773196\n",
      "Epoch 25778 - Train Loss: 0.076005, Train Acc: 0.879487 | Val Loss: 0.110794, Val Acc: 0.773196\n",
      "Epoch 25779 - Train Loss: 0.076003, Train Acc: 0.879487 | Val Loss: 0.110794, Val Acc: 0.773196\n",
      "Epoch 25780 - Train Loss: 0.076002, Train Acc: 0.879487 | Val Loss: 0.110793, Val Acc: 0.773196\n",
      "Epoch 25781 - Train Loss: 0.076000, Train Acc: 0.879487 | Val Loss: 0.110793, Val Acc: 0.773196\n",
      "Epoch 25782 - Train Loss: 0.075999, Train Acc: 0.879487 | Val Loss: 0.110792, Val Acc: 0.773196\n",
      "Epoch 25783 - Train Loss: 0.075997, Train Acc: 0.879487 | Val Loss: 0.110792, Val Acc: 0.773196\n",
      "Epoch 25784 - Train Loss: 0.075996, Train Acc: 0.879487 | Val Loss: 0.110791, Val Acc: 0.773196\n",
      "Epoch 25785 - Train Loss: 0.075994, Train Acc: 0.879487 | Val Loss: 0.110791, Val Acc: 0.773196\n",
      "Epoch 25786 - Train Loss: 0.075993, Train Acc: 0.879487 | Val Loss: 0.110790, Val Acc: 0.773196\n",
      "Epoch 25787 - Train Loss: 0.075991, Train Acc: 0.879487 | Val Loss: 0.110790, Val Acc: 0.773196\n",
      "Epoch 25788 - Train Loss: 0.075990, Train Acc: 0.879487 | Val Loss: 0.110790, Val Acc: 0.773196\n",
      "Epoch 25789 - Train Loss: 0.075988, Train Acc: 0.879487 | Val Loss: 0.110789, Val Acc: 0.773196\n",
      "Epoch 25790 - Train Loss: 0.075987, Train Acc: 0.879487 | Val Loss: 0.110789, Val Acc: 0.773196\n",
      "Epoch 25791 - Train Loss: 0.075985, Train Acc: 0.879487 | Val Loss: 0.110788, Val Acc: 0.773196\n",
      "Epoch 25792 - Train Loss: 0.075984, Train Acc: 0.879487 | Val Loss: 0.110788, Val Acc: 0.773196\n",
      "Epoch 25793 - Train Loss: 0.075982, Train Acc: 0.879487 | Val Loss: 0.110787, Val Acc: 0.773196\n",
      "Epoch 25794 - Train Loss: 0.075981, Train Acc: 0.879487 | Val Loss: 0.110787, Val Acc: 0.773196\n",
      "Epoch 25795 - Train Loss: 0.075979, Train Acc: 0.879487 | Val Loss: 0.110786, Val Acc: 0.773196\n",
      "Epoch 25796 - Train Loss: 0.075978, Train Acc: 0.879487 | Val Loss: 0.110786, Val Acc: 0.773196\n",
      "Epoch 25797 - Train Loss: 0.075976, Train Acc: 0.879487 | Val Loss: 0.110785, Val Acc: 0.773196\n",
      "Epoch 25798 - Train Loss: 0.075974, Train Acc: 0.879487 | Val Loss: 0.110785, Val Acc: 0.773196\n",
      "Epoch 25799 - Train Loss: 0.075973, Train Acc: 0.879487 | Val Loss: 0.110784, Val Acc: 0.773196\n",
      "Epoch 25800 - Train Loss: 0.075971, Train Acc: 0.879487 | Val Loss: 0.110784, Val Acc: 0.773196\n",
      "Epoch 25801 - Train Loss: 0.075970, Train Acc: 0.879487 | Val Loss: 0.110783, Val Acc: 0.773196\n",
      "Epoch 25802 - Train Loss: 0.075968, Train Acc: 0.880769 | Val Loss: 0.110783, Val Acc: 0.773196\n",
      "Epoch 25803 - Train Loss: 0.075967, Train Acc: 0.880769 | Val Loss: 0.110782, Val Acc: 0.773196\n",
      "Epoch 25804 - Train Loss: 0.075965, Train Acc: 0.880769 | Val Loss: 0.110782, Val Acc: 0.773196\n",
      "Epoch 25805 - Train Loss: 0.075964, Train Acc: 0.880769 | Val Loss: 0.110781, Val Acc: 0.773196\n",
      "Epoch 25806 - Train Loss: 0.075962, Train Acc: 0.880769 | Val Loss: 0.110781, Val Acc: 0.773196\n",
      "Epoch 25807 - Train Loss: 0.075961, Train Acc: 0.880769 | Val Loss: 0.110780, Val Acc: 0.773196\n",
      "Epoch 25808 - Train Loss: 0.075959, Train Acc: 0.880769 | Val Loss: 0.110780, Val Acc: 0.773196\n",
      "Epoch 25809 - Train Loss: 0.075958, Train Acc: 0.880769 | Val Loss: 0.110779, Val Acc: 0.773196\n",
      "Epoch 25810 - Train Loss: 0.075956, Train Acc: 0.880769 | Val Loss: 0.110779, Val Acc: 0.773196\n",
      "Epoch 25811 - Train Loss: 0.075955, Train Acc: 0.880769 | Val Loss: 0.110778, Val Acc: 0.773196\n",
      "Epoch 25812 - Train Loss: 0.075953, Train Acc: 0.880769 | Val Loss: 0.110778, Val Acc: 0.773196\n",
      "Epoch 25813 - Train Loss: 0.075952, Train Acc: 0.880769 | Val Loss: 0.110777, Val Acc: 0.773196\n",
      "Epoch 25814 - Train Loss: 0.075950, Train Acc: 0.880769 | Val Loss: 0.110777, Val Acc: 0.773196\n",
      "Epoch 25815 - Train Loss: 0.075949, Train Acc: 0.880769 | Val Loss: 0.110776, Val Acc: 0.773196\n",
      "Epoch 25816 - Train Loss: 0.075947, Train Acc: 0.880769 | Val Loss: 0.110776, Val Acc: 0.773196\n",
      "Epoch 25817 - Train Loss: 0.075946, Train Acc: 0.880769 | Val Loss: 0.110775, Val Acc: 0.773196\n",
      "Epoch 25818 - Train Loss: 0.075944, Train Acc: 0.880769 | Val Loss: 0.110775, Val Acc: 0.773196\n",
      "Epoch 25819 - Train Loss: 0.075943, Train Acc: 0.880769 | Val Loss: 0.110774, Val Acc: 0.773196\n",
      "Epoch 25820 - Train Loss: 0.075941, Train Acc: 0.880769 | Val Loss: 0.110774, Val Acc: 0.783505\n",
      "Epoch 25821 - Train Loss: 0.075940, Train Acc: 0.880769 | Val Loss: 0.110773, Val Acc: 0.783505\n",
      "Epoch 25822 - Train Loss: 0.075938, Train Acc: 0.880769 | Val Loss: 0.110773, Val Acc: 0.783505\n",
      "Epoch 25823 - Train Loss: 0.075937, Train Acc: 0.880769 | Val Loss: 0.110773, Val Acc: 0.783505\n",
      "Epoch 25824 - Train Loss: 0.075935, Train Acc: 0.880769 | Val Loss: 0.110772, Val Acc: 0.783505\n",
      "Epoch 25825 - Train Loss: 0.075934, Train Acc: 0.880769 | Val Loss: 0.110772, Val Acc: 0.783505\n",
      "Epoch 25826 - Train Loss: 0.075932, Train Acc: 0.880769 | Val Loss: 0.110771, Val Acc: 0.783505\n",
      "Epoch 25827 - Train Loss: 0.075931, Train Acc: 0.880769 | Val Loss: 0.110771, Val Acc: 0.783505\n",
      "Epoch 25828 - Train Loss: 0.075929, Train Acc: 0.880769 | Val Loss: 0.110770, Val Acc: 0.783505\n",
      "Epoch 25829 - Train Loss: 0.075928, Train Acc: 0.880769 | Val Loss: 0.110770, Val Acc: 0.783505\n",
      "Epoch 25830 - Train Loss: 0.075926, Train Acc: 0.880769 | Val Loss: 0.110769, Val Acc: 0.783505\n",
      "Epoch 25831 - Train Loss: 0.075925, Train Acc: 0.880769 | Val Loss: 0.110769, Val Acc: 0.783505\n",
      "Epoch 25832 - Train Loss: 0.075923, Train Acc: 0.880769 | Val Loss: 0.110768, Val Acc: 0.783505\n",
      "Epoch 25833 - Train Loss: 0.075922, Train Acc: 0.880769 | Val Loss: 0.110768, Val Acc: 0.783505\n",
      "Epoch 25834 - Train Loss: 0.075920, Train Acc: 0.880769 | Val Loss: 0.110767, Val Acc: 0.783505\n",
      "Epoch 25835 - Train Loss: 0.075919, Train Acc: 0.880769 | Val Loss: 0.110767, Val Acc: 0.783505\n",
      "Epoch 25836 - Train Loss: 0.075917, Train Acc: 0.880769 | Val Loss: 0.110766, Val Acc: 0.783505\n",
      "Epoch 25837 - Train Loss: 0.075916, Train Acc: 0.880769 | Val Loss: 0.110766, Val Acc: 0.783505\n",
      "Epoch 25838 - Train Loss: 0.075914, Train Acc: 0.880769 | Val Loss: 0.110765, Val Acc: 0.783505\n",
      "Epoch 25839 - Train Loss: 0.075913, Train Acc: 0.880769 | Val Loss: 0.110765, Val Acc: 0.783505\n",
      "Epoch 25840 - Train Loss: 0.075911, Train Acc: 0.880769 | Val Loss: 0.110764, Val Acc: 0.783505\n",
      "Epoch 25841 - Train Loss: 0.075910, Train Acc: 0.880769 | Val Loss: 0.110764, Val Acc: 0.783505\n",
      "Epoch 25842 - Train Loss: 0.075908, Train Acc: 0.880769 | Val Loss: 0.110763, Val Acc: 0.783505\n",
      "Epoch 25843 - Train Loss: 0.075907, Train Acc: 0.880769 | Val Loss: 0.110763, Val Acc: 0.783505\n",
      "Epoch 25844 - Train Loss: 0.075905, Train Acc: 0.880769 | Val Loss: 0.110762, Val Acc: 0.783505\n",
      "Epoch 25845 - Train Loss: 0.075904, Train Acc: 0.880769 | Val Loss: 0.110762, Val Acc: 0.783505\n",
      "Epoch 25846 - Train Loss: 0.075902, Train Acc: 0.880769 | Val Loss: 0.110761, Val Acc: 0.783505\n",
      "Epoch 25847 - Train Loss: 0.075901, Train Acc: 0.880769 | Val Loss: 0.110761, Val Acc: 0.783505\n",
      "Epoch 25848 - Train Loss: 0.075899, Train Acc: 0.880769 | Val Loss: 0.110760, Val Acc: 0.783505\n",
      "Epoch 25849 - Train Loss: 0.075898, Train Acc: 0.880769 | Val Loss: 0.110760, Val Acc: 0.783505\n",
      "Epoch 25850 - Train Loss: 0.075896, Train Acc: 0.880769 | Val Loss: 0.110759, Val Acc: 0.783505\n",
      "Epoch 25851 - Train Loss: 0.075895, Train Acc: 0.880769 | Val Loss: 0.110759, Val Acc: 0.783505\n",
      "Epoch 25852 - Train Loss: 0.075893, Train Acc: 0.880769 | Val Loss: 0.110758, Val Acc: 0.783505\n",
      "Epoch 25853 - Train Loss: 0.075892, Train Acc: 0.880769 | Val Loss: 0.110758, Val Acc: 0.783505\n",
      "Epoch 25854 - Train Loss: 0.075890, Train Acc: 0.880769 | Val Loss: 0.110758, Val Acc: 0.783505\n",
      "Epoch 25855 - Train Loss: 0.075889, Train Acc: 0.880769 | Val Loss: 0.110757, Val Acc: 0.783505\n",
      "Epoch 25856 - Train Loss: 0.075887, Train Acc: 0.880769 | Val Loss: 0.110757, Val Acc: 0.783505\n",
      "Epoch 25857 - Train Loss: 0.075886, Train Acc: 0.880769 | Val Loss: 0.110756, Val Acc: 0.783505\n",
      "Epoch 25858 - Train Loss: 0.075884, Train Acc: 0.880769 | Val Loss: 0.110756, Val Acc: 0.783505\n",
      "Epoch 25859 - Train Loss: 0.075883, Train Acc: 0.880769 | Val Loss: 0.110755, Val Acc: 0.783505\n",
      "Epoch 25860 - Train Loss: 0.075881, Train Acc: 0.880769 | Val Loss: 0.110755, Val Acc: 0.783505\n",
      "Epoch 25861 - Train Loss: 0.075880, Train Acc: 0.880769 | Val Loss: 0.110754, Val Acc: 0.783505\n",
      "Epoch 25862 - Train Loss: 0.075878, Train Acc: 0.880769 | Val Loss: 0.110754, Val Acc: 0.783505\n",
      "Epoch 25863 - Train Loss: 0.075877, Train Acc: 0.880769 | Val Loss: 0.110753, Val Acc: 0.783505\n",
      "Epoch 25864 - Train Loss: 0.075875, Train Acc: 0.880769 | Val Loss: 0.110753, Val Acc: 0.783505\n",
      "Epoch 25865 - Train Loss: 0.075874, Train Acc: 0.880769 | Val Loss: 0.110752, Val Acc: 0.783505\n",
      "Epoch 25866 - Train Loss: 0.075872, Train Acc: 0.880769 | Val Loss: 0.110752, Val Acc: 0.783505\n",
      "Epoch 25867 - Train Loss: 0.075871, Train Acc: 0.880769 | Val Loss: 0.110751, Val Acc: 0.783505\n",
      "Epoch 25868 - Train Loss: 0.075869, Train Acc: 0.880769 | Val Loss: 0.110751, Val Acc: 0.783505\n",
      "Epoch 25869 - Train Loss: 0.075868, Train Acc: 0.880769 | Val Loss: 0.110750, Val Acc: 0.783505\n",
      "Epoch 25870 - Train Loss: 0.075866, Train Acc: 0.880769 | Val Loss: 0.110750, Val Acc: 0.783505\n",
      "Epoch 25871 - Train Loss: 0.075865, Train Acc: 0.880769 | Val Loss: 0.110749, Val Acc: 0.783505\n",
      "Epoch 25872 - Train Loss: 0.075863, Train Acc: 0.880769 | Val Loss: 0.110749, Val Acc: 0.783505\n",
      "Epoch 25873 - Train Loss: 0.075862, Train Acc: 0.880769 | Val Loss: 0.110748, Val Acc: 0.783505\n",
      "Epoch 25874 - Train Loss: 0.075860, Train Acc: 0.880769 | Val Loss: 0.110748, Val Acc: 0.783505\n",
      "Epoch 25875 - Train Loss: 0.075859, Train Acc: 0.880769 | Val Loss: 0.110747, Val Acc: 0.783505\n",
      "Epoch 25876 - Train Loss: 0.075857, Train Acc: 0.880769 | Val Loss: 0.110747, Val Acc: 0.783505\n",
      "Epoch 25877 - Train Loss: 0.075856, Train Acc: 0.880769 | Val Loss: 0.110746, Val Acc: 0.783505\n",
      "Epoch 25878 - Train Loss: 0.075854, Train Acc: 0.880769 | Val Loss: 0.110746, Val Acc: 0.783505\n",
      "Epoch 25879 - Train Loss: 0.075853, Train Acc: 0.880769 | Val Loss: 0.110745, Val Acc: 0.783505\n",
      "Epoch 25880 - Train Loss: 0.075851, Train Acc: 0.880769 | Val Loss: 0.110745, Val Acc: 0.783505\n",
      "Epoch 25881 - Train Loss: 0.075850, Train Acc: 0.880769 | Val Loss: 0.110745, Val Acc: 0.783505\n",
      "Epoch 25882 - Train Loss: 0.075848, Train Acc: 0.880769 | Val Loss: 0.110744, Val Acc: 0.783505\n",
      "Epoch 25883 - Train Loss: 0.075847, Train Acc: 0.880769 | Val Loss: 0.110744, Val Acc: 0.783505\n",
      "Epoch 25884 - Train Loss: 0.075845, Train Acc: 0.880769 | Val Loss: 0.110743, Val Acc: 0.783505\n",
      "Epoch 25885 - Train Loss: 0.075844, Train Acc: 0.880769 | Val Loss: 0.110743, Val Acc: 0.783505\n",
      "Epoch 25886 - Train Loss: 0.075842, Train Acc: 0.880769 | Val Loss: 0.110742, Val Acc: 0.783505\n",
      "Epoch 25887 - Train Loss: 0.075841, Train Acc: 0.880769 | Val Loss: 0.110742, Val Acc: 0.783505\n",
      "Epoch 25888 - Train Loss: 0.075839, Train Acc: 0.880769 | Val Loss: 0.110741, Val Acc: 0.783505\n",
      "Epoch 25889 - Train Loss: 0.075838, Train Acc: 0.880769 | Val Loss: 0.110741, Val Acc: 0.783505\n",
      "Epoch 25890 - Train Loss: 0.075836, Train Acc: 0.880769 | Val Loss: 0.110740, Val Acc: 0.783505\n",
      "Epoch 25891 - Train Loss: 0.075835, Train Acc: 0.880769 | Val Loss: 0.110740, Val Acc: 0.783505\n",
      "Epoch 25892 - Train Loss: 0.075833, Train Acc: 0.880769 | Val Loss: 0.110739, Val Acc: 0.783505\n",
      "Epoch 25893 - Train Loss: 0.075832, Train Acc: 0.880769 | Val Loss: 0.110739, Val Acc: 0.783505\n",
      "Epoch 25894 - Train Loss: 0.075830, Train Acc: 0.880769 | Val Loss: 0.110738, Val Acc: 0.783505\n",
      "Epoch 25895 - Train Loss: 0.075829, Train Acc: 0.880769 | Val Loss: 0.110738, Val Acc: 0.783505\n",
      "Epoch 25896 - Train Loss: 0.075827, Train Acc: 0.880769 | Val Loss: 0.110737, Val Acc: 0.783505\n",
      "Epoch 25897 - Train Loss: 0.075826, Train Acc: 0.880769 | Val Loss: 0.110737, Val Acc: 0.783505\n",
      "Epoch 25898 - Train Loss: 0.075824, Train Acc: 0.880769 | Val Loss: 0.110736, Val Acc: 0.783505\n",
      "Epoch 25899 - Train Loss: 0.075823, Train Acc: 0.880769 | Val Loss: 0.110736, Val Acc: 0.783505\n",
      "Epoch 25900 - Train Loss: 0.075821, Train Acc: 0.880769 | Val Loss: 0.110735, Val Acc: 0.783505\n",
      "Epoch 25901 - Train Loss: 0.075820, Train Acc: 0.880769 | Val Loss: 0.110735, Val Acc: 0.783505\n",
      "Epoch 25902 - Train Loss: 0.075818, Train Acc: 0.880769 | Val Loss: 0.110734, Val Acc: 0.783505\n",
      "Epoch 25903 - Train Loss: 0.075817, Train Acc: 0.880769 | Val Loss: 0.110734, Val Acc: 0.783505\n",
      "Epoch 25904 - Train Loss: 0.075815, Train Acc: 0.880769 | Val Loss: 0.110733, Val Acc: 0.783505\n",
      "Epoch 25905 - Train Loss: 0.075814, Train Acc: 0.880769 | Val Loss: 0.110733, Val Acc: 0.783505\n",
      "Epoch 25906 - Train Loss: 0.075812, Train Acc: 0.880769 | Val Loss: 0.110733, Val Acc: 0.783505\n",
      "Epoch 25907 - Train Loss: 0.075811, Train Acc: 0.880769 | Val Loss: 0.110732, Val Acc: 0.783505\n",
      "Epoch 25908 - Train Loss: 0.075809, Train Acc: 0.880769 | Val Loss: 0.110732, Val Acc: 0.783505\n",
      "Epoch 25909 - Train Loss: 0.075808, Train Acc: 0.880769 | Val Loss: 0.110731, Val Acc: 0.783505\n",
      "Epoch 25910 - Train Loss: 0.075806, Train Acc: 0.880769 | Val Loss: 0.110731, Val Acc: 0.783505\n",
      "Epoch 25911 - Train Loss: 0.075805, Train Acc: 0.880769 | Val Loss: 0.110730, Val Acc: 0.783505\n",
      "Epoch 25912 - Train Loss: 0.075803, Train Acc: 0.880769 | Val Loss: 0.110730, Val Acc: 0.783505\n",
      "Epoch 25913 - Train Loss: 0.075802, Train Acc: 0.880769 | Val Loss: 0.110729, Val Acc: 0.783505\n",
      "Epoch 25914 - Train Loss: 0.075800, Train Acc: 0.880769 | Val Loss: 0.110729, Val Acc: 0.783505\n",
      "Epoch 25915 - Train Loss: 0.075799, Train Acc: 0.880769 | Val Loss: 0.110728, Val Acc: 0.783505\n",
      "Epoch 25916 - Train Loss: 0.075797, Train Acc: 0.880769 | Val Loss: 0.110728, Val Acc: 0.783505\n",
      "Epoch 25917 - Train Loss: 0.075796, Train Acc: 0.880769 | Val Loss: 0.110727, Val Acc: 0.783505\n",
      "Epoch 25918 - Train Loss: 0.075794, Train Acc: 0.880769 | Val Loss: 0.110727, Val Acc: 0.783505\n",
      "Epoch 25919 - Train Loss: 0.075793, Train Acc: 0.880769 | Val Loss: 0.110726, Val Acc: 0.783505\n",
      "Epoch 25920 - Train Loss: 0.075791, Train Acc: 0.880769 | Val Loss: 0.110726, Val Acc: 0.783505\n",
      "Epoch 25921 - Train Loss: 0.075790, Train Acc: 0.880769 | Val Loss: 0.110725, Val Acc: 0.783505\n",
      "Epoch 25922 - Train Loss: 0.075788, Train Acc: 0.880769 | Val Loss: 0.110725, Val Acc: 0.783505\n",
      "Epoch 25923 - Train Loss: 0.075787, Train Acc: 0.880769 | Val Loss: 0.110724, Val Acc: 0.783505\n",
      "Epoch 25924 - Train Loss: 0.075785, Train Acc: 0.880769 | Val Loss: 0.110724, Val Acc: 0.783505\n",
      "Epoch 25925 - Train Loss: 0.075784, Train Acc: 0.880769 | Val Loss: 0.110723, Val Acc: 0.783505\n",
      "Epoch 25926 - Train Loss: 0.075782, Train Acc: 0.880769 | Val Loss: 0.110723, Val Acc: 0.783505\n",
      "Epoch 25927 - Train Loss: 0.075781, Train Acc: 0.880769 | Val Loss: 0.110722, Val Acc: 0.783505\n",
      "Epoch 25928 - Train Loss: 0.075779, Train Acc: 0.880769 | Val Loss: 0.110722, Val Acc: 0.783505\n",
      "Epoch 25929 - Train Loss: 0.075778, Train Acc: 0.880769 | Val Loss: 0.110721, Val Acc: 0.783505\n",
      "Epoch 25930 - Train Loss: 0.075776, Train Acc: 0.880769 | Val Loss: 0.110721, Val Acc: 0.783505\n",
      "Epoch 25931 - Train Loss: 0.075775, Train Acc: 0.880769 | Val Loss: 0.110721, Val Acc: 0.783505\n",
      "Epoch 25932 - Train Loss: 0.075773, Train Acc: 0.880769 | Val Loss: 0.110720, Val Acc: 0.783505\n",
      "Epoch 25933 - Train Loss: 0.075772, Train Acc: 0.880769 | Val Loss: 0.110720, Val Acc: 0.783505\n",
      "Epoch 25934 - Train Loss: 0.075770, Train Acc: 0.880769 | Val Loss: 0.110719, Val Acc: 0.783505\n",
      "Epoch 25935 - Train Loss: 0.075769, Train Acc: 0.880769 | Val Loss: 0.110719, Val Acc: 0.783505\n",
      "Epoch 25936 - Train Loss: 0.075767, Train Acc: 0.880769 | Val Loss: 0.110718, Val Acc: 0.783505\n",
      "Epoch 25937 - Train Loss: 0.075766, Train Acc: 0.880769 | Val Loss: 0.110718, Val Acc: 0.783505\n",
      "Epoch 25938 - Train Loss: 0.075764, Train Acc: 0.880769 | Val Loss: 0.110717, Val Acc: 0.783505\n",
      "Epoch 25939 - Train Loss: 0.075763, Train Acc: 0.880769 | Val Loss: 0.110717, Val Acc: 0.783505\n",
      "Epoch 25940 - Train Loss: 0.075761, Train Acc: 0.880769 | Val Loss: 0.110716, Val Acc: 0.783505\n",
      "Epoch 25941 - Train Loss: 0.075760, Train Acc: 0.880769 | Val Loss: 0.110716, Val Acc: 0.783505\n",
      "Epoch 25942 - Train Loss: 0.075758, Train Acc: 0.880769 | Val Loss: 0.110715, Val Acc: 0.783505\n",
      "Epoch 25943 - Train Loss: 0.075757, Train Acc: 0.880769 | Val Loss: 0.110715, Val Acc: 0.783505\n",
      "Epoch 25944 - Train Loss: 0.075756, Train Acc: 0.880769 | Val Loss: 0.110714, Val Acc: 0.783505\n",
      "Epoch 25945 - Train Loss: 0.075754, Train Acc: 0.880769 | Val Loss: 0.110714, Val Acc: 0.783505\n",
      "Epoch 25946 - Train Loss: 0.075753, Train Acc: 0.880769 | Val Loss: 0.110713, Val Acc: 0.783505\n",
      "Epoch 25947 - Train Loss: 0.075751, Train Acc: 0.880769 | Val Loss: 0.110713, Val Acc: 0.783505\n",
      "Epoch 25948 - Train Loss: 0.075750, Train Acc: 0.880769 | Val Loss: 0.110712, Val Acc: 0.783505\n",
      "Epoch 25949 - Train Loss: 0.075748, Train Acc: 0.880769 | Val Loss: 0.110712, Val Acc: 0.783505\n",
      "Epoch 25950 - Train Loss: 0.075747, Train Acc: 0.880769 | Val Loss: 0.110711, Val Acc: 0.783505\n",
      "Epoch 25951 - Train Loss: 0.075745, Train Acc: 0.880769 | Val Loss: 0.110711, Val Acc: 0.783505\n",
      "Epoch 25952 - Train Loss: 0.075744, Train Acc: 0.880769 | Val Loss: 0.110711, Val Acc: 0.783505\n",
      "Epoch 25953 - Train Loss: 0.075742, Train Acc: 0.880769 | Val Loss: 0.110710, Val Acc: 0.783505\n",
      "Epoch 25954 - Train Loss: 0.075741, Train Acc: 0.880769 | Val Loss: 0.110710, Val Acc: 0.783505\n",
      "Epoch 25955 - Train Loss: 0.075739, Train Acc: 0.880769 | Val Loss: 0.110709, Val Acc: 0.783505\n",
      "Epoch 25956 - Train Loss: 0.075738, Train Acc: 0.880769 | Val Loss: 0.110709, Val Acc: 0.783505\n",
      "Epoch 25957 - Train Loss: 0.075736, Train Acc: 0.880769 | Val Loss: 0.110708, Val Acc: 0.783505\n",
      "Epoch 25958 - Train Loss: 0.075735, Train Acc: 0.880769 | Val Loss: 0.110708, Val Acc: 0.783505\n",
      "Epoch 25959 - Train Loss: 0.075733, Train Acc: 0.880769 | Val Loss: 0.110707, Val Acc: 0.783505\n",
      "Epoch 25960 - Train Loss: 0.075732, Train Acc: 0.880769 | Val Loss: 0.110707, Val Acc: 0.783505\n",
      "Epoch 25961 - Train Loss: 0.075730, Train Acc: 0.880769 | Val Loss: 0.110706, Val Acc: 0.783505\n",
      "Epoch 25962 - Train Loss: 0.075729, Train Acc: 0.880769 | Val Loss: 0.110706, Val Acc: 0.783505\n",
      "Epoch 25963 - Train Loss: 0.075727, Train Acc: 0.880769 | Val Loss: 0.110705, Val Acc: 0.783505\n",
      "Epoch 25964 - Train Loss: 0.075726, Train Acc: 0.880769 | Val Loss: 0.110705, Val Acc: 0.783505\n",
      "Epoch 25965 - Train Loss: 0.075724, Train Acc: 0.880769 | Val Loss: 0.110704, Val Acc: 0.783505\n",
      "Epoch 25966 - Train Loss: 0.075723, Train Acc: 0.880769 | Val Loss: 0.110704, Val Acc: 0.783505\n",
      "Epoch 25967 - Train Loss: 0.075721, Train Acc: 0.880769 | Val Loss: 0.110703, Val Acc: 0.783505\n",
      "Epoch 25968 - Train Loss: 0.075720, Train Acc: 0.880769 | Val Loss: 0.110703, Val Acc: 0.783505\n",
      "Epoch 25969 - Train Loss: 0.075718, Train Acc: 0.880769 | Val Loss: 0.110702, Val Acc: 0.783505\n",
      "Epoch 25970 - Train Loss: 0.075717, Train Acc: 0.880769 | Val Loss: 0.110702, Val Acc: 0.783505\n",
      "Epoch 25971 - Train Loss: 0.075715, Train Acc: 0.880769 | Val Loss: 0.110701, Val Acc: 0.783505\n",
      "Epoch 25972 - Train Loss: 0.075714, Train Acc: 0.880769 | Val Loss: 0.110701, Val Acc: 0.783505\n",
      "Epoch 25973 - Train Loss: 0.075712, Train Acc: 0.880769 | Val Loss: 0.110701, Val Acc: 0.783505\n",
      "Epoch 25974 - Train Loss: 0.075711, Train Acc: 0.880769 | Val Loss: 0.110700, Val Acc: 0.783505\n",
      "Epoch 25975 - Train Loss: 0.075709, Train Acc: 0.880769 | Val Loss: 0.110700, Val Acc: 0.783505\n",
      "Epoch 25976 - Train Loss: 0.075708, Train Acc: 0.880769 | Val Loss: 0.110699, Val Acc: 0.783505\n",
      "Epoch 25977 - Train Loss: 0.075706, Train Acc: 0.880769 | Val Loss: 0.110699, Val Acc: 0.783505\n",
      "Epoch 25978 - Train Loss: 0.075705, Train Acc: 0.880769 | Val Loss: 0.110698, Val Acc: 0.783505\n",
      "Epoch 25979 - Train Loss: 0.075703, Train Acc: 0.880769 | Val Loss: 0.110698, Val Acc: 0.783505\n",
      "Epoch 25980 - Train Loss: 0.075702, Train Acc: 0.880769 | Val Loss: 0.110697, Val Acc: 0.783505\n",
      "Epoch 25981 - Train Loss: 0.075700, Train Acc: 0.880769 | Val Loss: 0.110697, Val Acc: 0.783505\n",
      "Epoch 25982 - Train Loss: 0.075699, Train Acc: 0.880769 | Val Loss: 0.110696, Val Acc: 0.783505\n",
      "Epoch 25983 - Train Loss: 0.075697, Train Acc: 0.880769 | Val Loss: 0.110696, Val Acc: 0.783505\n",
      "Epoch 25984 - Train Loss: 0.075696, Train Acc: 0.880769 | Val Loss: 0.110695, Val Acc: 0.783505\n",
      "Epoch 25985 - Train Loss: 0.075694, Train Acc: 0.880769 | Val Loss: 0.110695, Val Acc: 0.783505\n",
      "Epoch 25986 - Train Loss: 0.075693, Train Acc: 0.880769 | Val Loss: 0.110694, Val Acc: 0.783505\n",
      "Epoch 25987 - Train Loss: 0.075691, Train Acc: 0.880769 | Val Loss: 0.110694, Val Acc: 0.783505\n",
      "Epoch 25988 - Train Loss: 0.075690, Train Acc: 0.880769 | Val Loss: 0.110693, Val Acc: 0.783505\n",
      "Epoch 25989 - Train Loss: 0.075688, Train Acc: 0.880769 | Val Loss: 0.110693, Val Acc: 0.783505\n",
      "Epoch 25990 - Train Loss: 0.075687, Train Acc: 0.880769 | Val Loss: 0.110692, Val Acc: 0.783505\n",
      "Epoch 25991 - Train Loss: 0.075685, Train Acc: 0.880769 | Val Loss: 0.110692, Val Acc: 0.783505\n",
      "Epoch 25992 - Train Loss: 0.075684, Train Acc: 0.880769 | Val Loss: 0.110692, Val Acc: 0.783505\n",
      "Epoch 25993 - Train Loss: 0.075682, Train Acc: 0.880769 | Val Loss: 0.110691, Val Acc: 0.783505\n",
      "Epoch 25994 - Train Loss: 0.075681, Train Acc: 0.880769 | Val Loss: 0.110691, Val Acc: 0.783505\n",
      "Epoch 25995 - Train Loss: 0.075679, Train Acc: 0.880769 | Val Loss: 0.110690, Val Acc: 0.783505\n",
      "Epoch 25996 - Train Loss: 0.075678, Train Acc: 0.880769 | Val Loss: 0.110690, Val Acc: 0.783505\n",
      "Epoch 25997 - Train Loss: 0.075676, Train Acc: 0.880769 | Val Loss: 0.110689, Val Acc: 0.783505\n",
      "Epoch 25998 - Train Loss: 0.075675, Train Acc: 0.880769 | Val Loss: 0.110689, Val Acc: 0.783505\n",
      "Epoch 25999 - Train Loss: 0.075673, Train Acc: 0.880769 | Val Loss: 0.110688, Val Acc: 0.783505\n",
      "Epoch 26000 - Train Loss: 0.075672, Train Acc: 0.880769 | Val Loss: 0.110688, Val Acc: 0.783505\n",
      "Epoch 26001 - Train Loss: 0.075670, Train Acc: 0.880769 | Val Loss: 0.110687, Val Acc: 0.783505\n",
      "Epoch 26002 - Train Loss: 0.075669, Train Acc: 0.880769 | Val Loss: 0.110687, Val Acc: 0.783505\n",
      "Epoch 26003 - Train Loss: 0.075668, Train Acc: 0.880769 | Val Loss: 0.110686, Val Acc: 0.783505\n",
      "Epoch 26004 - Train Loss: 0.075666, Train Acc: 0.880769 | Val Loss: 0.110686, Val Acc: 0.783505\n",
      "Epoch 26005 - Train Loss: 0.075665, Train Acc: 0.880769 | Val Loss: 0.110685, Val Acc: 0.783505\n",
      "Epoch 26006 - Train Loss: 0.075663, Train Acc: 0.880769 | Val Loss: 0.110685, Val Acc: 0.783505\n",
      "Epoch 26007 - Train Loss: 0.075662, Train Acc: 0.880769 | Val Loss: 0.110684, Val Acc: 0.783505\n",
      "Epoch 26008 - Train Loss: 0.075660, Train Acc: 0.880769 | Val Loss: 0.110684, Val Acc: 0.783505\n",
      "Epoch 26009 - Train Loss: 0.075659, Train Acc: 0.880769 | Val Loss: 0.110684, Val Acc: 0.783505\n",
      "Epoch 26010 - Train Loss: 0.075657, Train Acc: 0.880769 | Val Loss: 0.110683, Val Acc: 0.783505\n",
      "Epoch 26011 - Train Loss: 0.075656, Train Acc: 0.880769 | Val Loss: 0.110683, Val Acc: 0.783505\n",
      "Epoch 26012 - Train Loss: 0.075654, Train Acc: 0.880769 | Val Loss: 0.110682, Val Acc: 0.783505\n",
      "Epoch 26013 - Train Loss: 0.075653, Train Acc: 0.880769 | Val Loss: 0.110682, Val Acc: 0.783505\n",
      "Epoch 26014 - Train Loss: 0.075651, Train Acc: 0.880769 | Val Loss: 0.110681, Val Acc: 0.783505\n",
      "Epoch 26015 - Train Loss: 0.075650, Train Acc: 0.880769 | Val Loss: 0.110681, Val Acc: 0.783505\n",
      "Epoch 26016 - Train Loss: 0.075648, Train Acc: 0.880769 | Val Loss: 0.110680, Val Acc: 0.783505\n",
      "Epoch 26017 - Train Loss: 0.075647, Train Acc: 0.880769 | Val Loss: 0.110680, Val Acc: 0.783505\n",
      "Epoch 26018 - Train Loss: 0.075645, Train Acc: 0.880769 | Val Loss: 0.110679, Val Acc: 0.783505\n",
      "Epoch 26019 - Train Loss: 0.075644, Train Acc: 0.880769 | Val Loss: 0.110679, Val Acc: 0.783505\n",
      "Epoch 26020 - Train Loss: 0.075642, Train Acc: 0.880769 | Val Loss: 0.110678, Val Acc: 0.783505\n",
      "Epoch 26021 - Train Loss: 0.075641, Train Acc: 0.880769 | Val Loss: 0.110678, Val Acc: 0.783505\n",
      "Epoch 26022 - Train Loss: 0.075639, Train Acc: 0.880769 | Val Loss: 0.110677, Val Acc: 0.783505\n",
      "Epoch 26023 - Train Loss: 0.075638, Train Acc: 0.880769 | Val Loss: 0.110677, Val Acc: 0.783505\n",
      "Epoch 26024 - Train Loss: 0.075636, Train Acc: 0.880769 | Val Loss: 0.110676, Val Acc: 0.783505\n",
      "Epoch 26025 - Train Loss: 0.075635, Train Acc: 0.880769 | Val Loss: 0.110676, Val Acc: 0.783505\n",
      "Epoch 26026 - Train Loss: 0.075633, Train Acc: 0.880769 | Val Loss: 0.110675, Val Acc: 0.783505\n",
      "Epoch 26027 - Train Loss: 0.075632, Train Acc: 0.880769 | Val Loss: 0.110675, Val Acc: 0.783505\n",
      "Epoch 26028 - Train Loss: 0.075630, Train Acc: 0.880769 | Val Loss: 0.110675, Val Acc: 0.783505\n",
      "Epoch 26029 - Train Loss: 0.075629, Train Acc: 0.880769 | Val Loss: 0.110674, Val Acc: 0.783505\n",
      "Epoch 26030 - Train Loss: 0.075627, Train Acc: 0.880769 | Val Loss: 0.110674, Val Acc: 0.783505\n",
      "Epoch 26031 - Train Loss: 0.075626, Train Acc: 0.880769 | Val Loss: 0.110673, Val Acc: 0.783505\n",
      "Epoch 26032 - Train Loss: 0.075624, Train Acc: 0.880769 | Val Loss: 0.110673, Val Acc: 0.783505\n",
      "Epoch 26033 - Train Loss: 0.075623, Train Acc: 0.880769 | Val Loss: 0.110672, Val Acc: 0.783505\n",
      "Epoch 26034 - Train Loss: 0.075621, Train Acc: 0.880769 | Val Loss: 0.110672, Val Acc: 0.783505\n",
      "Epoch 26035 - Train Loss: 0.075620, Train Acc: 0.880769 | Val Loss: 0.110671, Val Acc: 0.783505\n",
      "Epoch 26036 - Train Loss: 0.075618, Train Acc: 0.880769 | Val Loss: 0.110671, Val Acc: 0.783505\n",
      "Epoch 26037 - Train Loss: 0.075617, Train Acc: 0.880769 | Val Loss: 0.110670, Val Acc: 0.783505\n",
      "Epoch 26038 - Train Loss: 0.075615, Train Acc: 0.880769 | Val Loss: 0.110670, Val Acc: 0.783505\n",
      "Epoch 26039 - Train Loss: 0.075614, Train Acc: 0.880769 | Val Loss: 0.110669, Val Acc: 0.783505\n",
      "Epoch 26040 - Train Loss: 0.075612, Train Acc: 0.880769 | Val Loss: 0.110669, Val Acc: 0.783505\n",
      "Epoch 26041 - Train Loss: 0.075611, Train Acc: 0.880769 | Val Loss: 0.110668, Val Acc: 0.783505\n",
      "Epoch 26042 - Train Loss: 0.075610, Train Acc: 0.880769 | Val Loss: 0.110668, Val Acc: 0.783505\n",
      "Epoch 26043 - Train Loss: 0.075608, Train Acc: 0.880769 | Val Loss: 0.110667, Val Acc: 0.783505\n",
      "Epoch 26044 - Train Loss: 0.075607, Train Acc: 0.880769 | Val Loss: 0.110667, Val Acc: 0.783505\n",
      "Epoch 26045 - Train Loss: 0.075605, Train Acc: 0.880769 | Val Loss: 0.110667, Val Acc: 0.783505\n",
      "Epoch 26046 - Train Loss: 0.075604, Train Acc: 0.880769 | Val Loss: 0.110666, Val Acc: 0.783505\n",
      "Epoch 26047 - Train Loss: 0.075602, Train Acc: 0.880769 | Val Loss: 0.110666, Val Acc: 0.783505\n",
      "Epoch 26048 - Train Loss: 0.075601, Train Acc: 0.880769 | Val Loss: 0.110665, Val Acc: 0.783505\n",
      "Epoch 26049 - Train Loss: 0.075599, Train Acc: 0.880769 | Val Loss: 0.110665, Val Acc: 0.783505\n",
      "Epoch 26050 - Train Loss: 0.075598, Train Acc: 0.880769 | Val Loss: 0.110664, Val Acc: 0.783505\n",
      "Epoch 26051 - Train Loss: 0.075596, Train Acc: 0.880769 | Val Loss: 0.110664, Val Acc: 0.783505\n",
      "Epoch 26052 - Train Loss: 0.075595, Train Acc: 0.880769 | Val Loss: 0.110663, Val Acc: 0.783505\n",
      "Epoch 26053 - Train Loss: 0.075593, Train Acc: 0.880769 | Val Loss: 0.110663, Val Acc: 0.783505\n",
      "Epoch 26054 - Train Loss: 0.075592, Train Acc: 0.880769 | Val Loss: 0.110662, Val Acc: 0.783505\n",
      "Epoch 26055 - Train Loss: 0.075590, Train Acc: 0.880769 | Val Loss: 0.110662, Val Acc: 0.783505\n",
      "Epoch 26056 - Train Loss: 0.075589, Train Acc: 0.880769 | Val Loss: 0.110661, Val Acc: 0.783505\n",
      "Epoch 26057 - Train Loss: 0.075587, Train Acc: 0.880769 | Val Loss: 0.110661, Val Acc: 0.783505\n",
      "Epoch 26058 - Train Loss: 0.075586, Train Acc: 0.880769 | Val Loss: 0.110660, Val Acc: 0.783505\n",
      "Epoch 26059 - Train Loss: 0.075584, Train Acc: 0.880769 | Val Loss: 0.110660, Val Acc: 0.783505\n",
      "Epoch 26060 - Train Loss: 0.075583, Train Acc: 0.880769 | Val Loss: 0.110660, Val Acc: 0.783505\n",
      "Epoch 26061 - Train Loss: 0.075581, Train Acc: 0.880769 | Val Loss: 0.110659, Val Acc: 0.783505\n",
      "Epoch 26062 - Train Loss: 0.075580, Train Acc: 0.880769 | Val Loss: 0.110659, Val Acc: 0.783505\n",
      "Epoch 26063 - Train Loss: 0.075578, Train Acc: 0.880769 | Val Loss: 0.110658, Val Acc: 0.783505\n",
      "Epoch 26064 - Train Loss: 0.075577, Train Acc: 0.880769 | Val Loss: 0.110658, Val Acc: 0.783505\n",
      "Epoch 26065 - Train Loss: 0.075575, Train Acc: 0.880769 | Val Loss: 0.110657, Val Acc: 0.783505\n",
      "Epoch 26066 - Train Loss: 0.075574, Train Acc: 0.880769 | Val Loss: 0.110657, Val Acc: 0.783505\n",
      "Epoch 26067 - Train Loss: 0.075572, Train Acc: 0.880769 | Val Loss: 0.110656, Val Acc: 0.783505\n",
      "Epoch 26068 - Train Loss: 0.075571, Train Acc: 0.880769 | Val Loss: 0.110656, Val Acc: 0.783505\n",
      "Epoch 26069 - Train Loss: 0.075569, Train Acc: 0.880769 | Val Loss: 0.110655, Val Acc: 0.783505\n",
      "Epoch 26070 - Train Loss: 0.075568, Train Acc: 0.880769 | Val Loss: 0.110655, Val Acc: 0.783505\n",
      "Epoch 26071 - Train Loss: 0.075566, Train Acc: 0.880769 | Val Loss: 0.110654, Val Acc: 0.783505\n",
      "Epoch 26072 - Train Loss: 0.075565, Train Acc: 0.880769 | Val Loss: 0.110654, Val Acc: 0.783505\n",
      "Epoch 26073 - Train Loss: 0.075564, Train Acc: 0.880769 | Val Loss: 0.110653, Val Acc: 0.783505\n",
      "Epoch 26074 - Train Loss: 0.075562, Train Acc: 0.880769 | Val Loss: 0.110653, Val Acc: 0.783505\n",
      "Epoch 26075 - Train Loss: 0.075561, Train Acc: 0.880769 | Val Loss: 0.110652, Val Acc: 0.783505\n",
      "Epoch 26076 - Train Loss: 0.075559, Train Acc: 0.880769 | Val Loss: 0.110652, Val Acc: 0.783505\n",
      "Epoch 26077 - Train Loss: 0.075558, Train Acc: 0.880769 | Val Loss: 0.110652, Val Acc: 0.783505\n",
      "Epoch 26078 - Train Loss: 0.075556, Train Acc: 0.880769 | Val Loss: 0.110651, Val Acc: 0.783505\n",
      "Epoch 26079 - Train Loss: 0.075555, Train Acc: 0.880769 | Val Loss: 0.110651, Val Acc: 0.783505\n",
      "Epoch 26080 - Train Loss: 0.075553, Train Acc: 0.880769 | Val Loss: 0.110650, Val Acc: 0.783505\n",
      "Epoch 26081 - Train Loss: 0.075552, Train Acc: 0.880769 | Val Loss: 0.110650, Val Acc: 0.783505\n",
      "Epoch 26082 - Train Loss: 0.075550, Train Acc: 0.880769 | Val Loss: 0.110649, Val Acc: 0.783505\n",
      "Epoch 26083 - Train Loss: 0.075549, Train Acc: 0.880769 | Val Loss: 0.110649, Val Acc: 0.783505\n",
      "Epoch 26084 - Train Loss: 0.075547, Train Acc: 0.880769 | Val Loss: 0.110648, Val Acc: 0.783505\n",
      "Epoch 26085 - Train Loss: 0.075546, Train Acc: 0.880769 | Val Loss: 0.110648, Val Acc: 0.783505\n",
      "Epoch 26086 - Train Loss: 0.075544, Train Acc: 0.880769 | Val Loss: 0.110647, Val Acc: 0.783505\n",
      "Epoch 26087 - Train Loss: 0.075543, Train Acc: 0.880769 | Val Loss: 0.110647, Val Acc: 0.783505\n",
      "Epoch 26088 - Train Loss: 0.075541, Train Acc: 0.880769 | Val Loss: 0.110646, Val Acc: 0.783505\n",
      "Epoch 26089 - Train Loss: 0.075540, Train Acc: 0.880769 | Val Loss: 0.110646, Val Acc: 0.783505\n",
      "Epoch 26090 - Train Loss: 0.075538, Train Acc: 0.880769 | Val Loss: 0.110645, Val Acc: 0.783505\n",
      "Epoch 26091 - Train Loss: 0.075537, Train Acc: 0.880769 | Val Loss: 0.110645, Val Acc: 0.783505\n",
      "Epoch 26092 - Train Loss: 0.075535, Train Acc: 0.880769 | Val Loss: 0.110645, Val Acc: 0.783505\n",
      "Epoch 26093 - Train Loss: 0.075534, Train Acc: 0.880769 | Val Loss: 0.110644, Val Acc: 0.783505\n",
      "Epoch 26094 - Train Loss: 0.075532, Train Acc: 0.880769 | Val Loss: 0.110644, Val Acc: 0.783505\n",
      "Epoch 26095 - Train Loss: 0.075531, Train Acc: 0.880769 | Val Loss: 0.110643, Val Acc: 0.783505\n",
      "Epoch 26096 - Train Loss: 0.075529, Train Acc: 0.880769 | Val Loss: 0.110643, Val Acc: 0.783505\n",
      "Epoch 26097 - Train Loss: 0.075528, Train Acc: 0.880769 | Val Loss: 0.110642, Val Acc: 0.783505\n",
      "Epoch 26098 - Train Loss: 0.075526, Train Acc: 0.880769 | Val Loss: 0.110642, Val Acc: 0.783505\n",
      "Epoch 26099 - Train Loss: 0.075525, Train Acc: 0.880769 | Val Loss: 0.110641, Val Acc: 0.783505\n",
      "Epoch 26100 - Train Loss: 0.075523, Train Acc: 0.880769 | Val Loss: 0.110641, Val Acc: 0.783505\n",
      "Epoch 26101 - Train Loss: 0.075522, Train Acc: 0.880769 | Val Loss: 0.110640, Val Acc: 0.783505\n",
      "Epoch 26102 - Train Loss: 0.075521, Train Acc: 0.880769 | Val Loss: 0.110640, Val Acc: 0.783505\n",
      "Epoch 26103 - Train Loss: 0.075519, Train Acc: 0.880769 | Val Loss: 0.110639, Val Acc: 0.783505\n",
      "Epoch 26104 - Train Loss: 0.075518, Train Acc: 0.880769 | Val Loss: 0.110639, Val Acc: 0.783505\n",
      "Epoch 26105 - Train Loss: 0.075516, Train Acc: 0.880769 | Val Loss: 0.110638, Val Acc: 0.783505\n",
      "Epoch 26106 - Train Loss: 0.075515, Train Acc: 0.880769 | Val Loss: 0.110638, Val Acc: 0.783505\n",
      "Epoch 26107 - Train Loss: 0.075513, Train Acc: 0.880769 | Val Loss: 0.110638, Val Acc: 0.783505\n",
      "Epoch 26108 - Train Loss: 0.075512, Train Acc: 0.880769 | Val Loss: 0.110637, Val Acc: 0.783505\n",
      "Epoch 26109 - Train Loss: 0.075510, Train Acc: 0.880769 | Val Loss: 0.110637, Val Acc: 0.783505\n",
      "Epoch 26110 - Train Loss: 0.075509, Train Acc: 0.880769 | Val Loss: 0.110636, Val Acc: 0.783505\n",
      "Epoch 26111 - Train Loss: 0.075507, Train Acc: 0.880769 | Val Loss: 0.110636, Val Acc: 0.783505\n",
      "Epoch 26112 - Train Loss: 0.075506, Train Acc: 0.880769 | Val Loss: 0.110635, Val Acc: 0.783505\n",
      "Epoch 26113 - Train Loss: 0.075504, Train Acc: 0.880769 | Val Loss: 0.110635, Val Acc: 0.783505\n",
      "Epoch 26114 - Train Loss: 0.075503, Train Acc: 0.880769 | Val Loss: 0.110634, Val Acc: 0.783505\n",
      "Epoch 26115 - Train Loss: 0.075501, Train Acc: 0.880769 | Val Loss: 0.110634, Val Acc: 0.783505\n",
      "Epoch 26116 - Train Loss: 0.075500, Train Acc: 0.880769 | Val Loss: 0.110633, Val Acc: 0.783505\n",
      "Epoch 26117 - Train Loss: 0.075498, Train Acc: 0.880769 | Val Loss: 0.110633, Val Acc: 0.783505\n",
      "Epoch 26118 - Train Loss: 0.075497, Train Acc: 0.880769 | Val Loss: 0.110632, Val Acc: 0.783505\n",
      "Epoch 26119 - Train Loss: 0.075495, Train Acc: 0.880769 | Val Loss: 0.110632, Val Acc: 0.783505\n",
      "Epoch 26120 - Train Loss: 0.075494, Train Acc: 0.880769 | Val Loss: 0.110631, Val Acc: 0.783505\n",
      "Epoch 26121 - Train Loss: 0.075492, Train Acc: 0.880769 | Val Loss: 0.110631, Val Acc: 0.783505\n",
      "Epoch 26122 - Train Loss: 0.075491, Train Acc: 0.880769 | Val Loss: 0.110631, Val Acc: 0.783505\n",
      "Epoch 26123 - Train Loss: 0.075489, Train Acc: 0.880769 | Val Loss: 0.110630, Val Acc: 0.783505\n",
      "Epoch 26124 - Train Loss: 0.075488, Train Acc: 0.880769 | Val Loss: 0.110630, Val Acc: 0.783505\n",
      "Epoch 26125 - Train Loss: 0.075486, Train Acc: 0.880769 | Val Loss: 0.110629, Val Acc: 0.783505\n",
      "Epoch 26126 - Train Loss: 0.075485, Train Acc: 0.880769 | Val Loss: 0.110629, Val Acc: 0.783505\n",
      "Epoch 26127 - Train Loss: 0.075484, Train Acc: 0.880769 | Val Loss: 0.110628, Val Acc: 0.783505\n",
      "Epoch 26128 - Train Loss: 0.075482, Train Acc: 0.880769 | Val Loss: 0.110628, Val Acc: 0.783505\n",
      "Epoch 26129 - Train Loss: 0.075481, Train Acc: 0.880769 | Val Loss: 0.110627, Val Acc: 0.783505\n",
      "Epoch 26130 - Train Loss: 0.075479, Train Acc: 0.880769 | Val Loss: 0.110627, Val Acc: 0.783505\n",
      "Epoch 26131 - Train Loss: 0.075478, Train Acc: 0.880769 | Val Loss: 0.110626, Val Acc: 0.783505\n",
      "Epoch 26132 - Train Loss: 0.075476, Train Acc: 0.880769 | Val Loss: 0.110626, Val Acc: 0.783505\n",
      "Epoch 26133 - Train Loss: 0.075475, Train Acc: 0.880769 | Val Loss: 0.110625, Val Acc: 0.783505\n",
      "Epoch 26134 - Train Loss: 0.075473, Train Acc: 0.880769 | Val Loss: 0.110625, Val Acc: 0.783505\n",
      "Epoch 26135 - Train Loss: 0.075472, Train Acc: 0.880769 | Val Loss: 0.110625, Val Acc: 0.783505\n",
      "Epoch 26136 - Train Loss: 0.075470, Train Acc: 0.880769 | Val Loss: 0.110624, Val Acc: 0.783505\n",
      "Epoch 26137 - Train Loss: 0.075469, Train Acc: 0.880769 | Val Loss: 0.110624, Val Acc: 0.783505\n",
      "Epoch 26138 - Train Loss: 0.075467, Train Acc: 0.880769 | Val Loss: 0.110623, Val Acc: 0.783505\n",
      "Epoch 26139 - Train Loss: 0.075466, Train Acc: 0.880769 | Val Loss: 0.110623, Val Acc: 0.783505\n",
      "Epoch 26140 - Train Loss: 0.075464, Train Acc: 0.880769 | Val Loss: 0.110622, Val Acc: 0.783505\n",
      "Epoch 26141 - Train Loss: 0.075463, Train Acc: 0.880769 | Val Loss: 0.110622, Val Acc: 0.783505\n",
      "Epoch 26142 - Train Loss: 0.075461, Train Acc: 0.880769 | Val Loss: 0.110621, Val Acc: 0.783505\n",
      "Epoch 26143 - Train Loss: 0.075460, Train Acc: 0.880769 | Val Loss: 0.110621, Val Acc: 0.783505\n",
      "Epoch 26144 - Train Loss: 0.075458, Train Acc: 0.880769 | Val Loss: 0.110620, Val Acc: 0.783505\n",
      "Epoch 26145 - Train Loss: 0.075457, Train Acc: 0.880769 | Val Loss: 0.110620, Val Acc: 0.783505\n",
      "Epoch 26146 - Train Loss: 0.075455, Train Acc: 0.880769 | Val Loss: 0.110619, Val Acc: 0.783505\n",
      "Epoch 26147 - Train Loss: 0.075454, Train Acc: 0.880769 | Val Loss: 0.110619, Val Acc: 0.783505\n",
      "Epoch 26148 - Train Loss: 0.075453, Train Acc: 0.880769 | Val Loss: 0.110619, Val Acc: 0.783505\n",
      "Epoch 26149 - Train Loss: 0.075451, Train Acc: 0.880769 | Val Loss: 0.110618, Val Acc: 0.783505\n",
      "Epoch 26150 - Train Loss: 0.075450, Train Acc: 0.880769 | Val Loss: 0.110618, Val Acc: 0.783505\n",
      "Epoch 26151 - Train Loss: 0.075448, Train Acc: 0.880769 | Val Loss: 0.110617, Val Acc: 0.783505\n",
      "Epoch 26152 - Train Loss: 0.075447, Train Acc: 0.880769 | Val Loss: 0.110617, Val Acc: 0.783505\n",
      "Epoch 26153 - Train Loss: 0.075445, Train Acc: 0.880769 | Val Loss: 0.110616, Val Acc: 0.783505\n",
      "Epoch 26154 - Train Loss: 0.075444, Train Acc: 0.880769 | Val Loss: 0.110616, Val Acc: 0.783505\n",
      "Epoch 26155 - Train Loss: 0.075442, Train Acc: 0.880769 | Val Loss: 0.110615, Val Acc: 0.783505\n",
      "Epoch 26156 - Train Loss: 0.075441, Train Acc: 0.880769 | Val Loss: 0.110615, Val Acc: 0.783505\n",
      "Epoch 26157 - Train Loss: 0.075439, Train Acc: 0.880769 | Val Loss: 0.110614, Val Acc: 0.783505\n",
      "Epoch 26158 - Train Loss: 0.075438, Train Acc: 0.880769 | Val Loss: 0.110614, Val Acc: 0.783505\n",
      "Epoch 26159 - Train Loss: 0.075436, Train Acc: 0.880769 | Val Loss: 0.110613, Val Acc: 0.783505\n",
      "Epoch 26160 - Train Loss: 0.075435, Train Acc: 0.880769 | Val Loss: 0.110613, Val Acc: 0.783505\n",
      "Epoch 26161 - Train Loss: 0.075433, Train Acc: 0.880769 | Val Loss: 0.110612, Val Acc: 0.783505\n",
      "Epoch 26162 - Train Loss: 0.075432, Train Acc: 0.880769 | Val Loss: 0.110612, Val Acc: 0.783505\n",
      "Epoch 26163 - Train Loss: 0.075430, Train Acc: 0.880769 | Val Loss: 0.110612, Val Acc: 0.783505\n",
      "Epoch 26164 - Train Loss: 0.075429, Train Acc: 0.880769 | Val Loss: 0.110611, Val Acc: 0.783505\n",
      "Epoch 26165 - Train Loss: 0.075427, Train Acc: 0.880769 | Val Loss: 0.110611, Val Acc: 0.783505\n",
      "Epoch 26166 - Train Loss: 0.075426, Train Acc: 0.880769 | Val Loss: 0.110610, Val Acc: 0.783505\n",
      "Epoch 26167 - Train Loss: 0.075424, Train Acc: 0.880769 | Val Loss: 0.110610, Val Acc: 0.783505\n",
      "Epoch 26168 - Train Loss: 0.075423, Train Acc: 0.880769 | Val Loss: 0.110609, Val Acc: 0.783505\n",
      "Epoch 26169 - Train Loss: 0.075422, Train Acc: 0.880769 | Val Loss: 0.110609, Val Acc: 0.783505\n",
      "Epoch 26170 - Train Loss: 0.075420, Train Acc: 0.880769 | Val Loss: 0.110608, Val Acc: 0.783505\n",
      "Epoch 26171 - Train Loss: 0.075419, Train Acc: 0.880769 | Val Loss: 0.110608, Val Acc: 0.783505\n",
      "Epoch 26172 - Train Loss: 0.075417, Train Acc: 0.880769 | Val Loss: 0.110607, Val Acc: 0.783505\n",
      "Epoch 26173 - Train Loss: 0.075416, Train Acc: 0.880769 | Val Loss: 0.110607, Val Acc: 0.783505\n",
      "Epoch 26174 - Train Loss: 0.075414, Train Acc: 0.880769 | Val Loss: 0.110606, Val Acc: 0.783505\n",
      "Epoch 26175 - Train Loss: 0.075413, Train Acc: 0.880769 | Val Loss: 0.110606, Val Acc: 0.783505\n",
      "Epoch 26176 - Train Loss: 0.075411, Train Acc: 0.880769 | Val Loss: 0.110606, Val Acc: 0.783505\n",
      "Epoch 26177 - Train Loss: 0.075410, Train Acc: 0.880769 | Val Loss: 0.110605, Val Acc: 0.783505\n",
      "Epoch 26178 - Train Loss: 0.075408, Train Acc: 0.880769 | Val Loss: 0.110605, Val Acc: 0.783505\n",
      "Epoch 26179 - Train Loss: 0.075407, Train Acc: 0.880769 | Val Loss: 0.110604, Val Acc: 0.783505\n",
      "Epoch 26180 - Train Loss: 0.075405, Train Acc: 0.880769 | Val Loss: 0.110604, Val Acc: 0.783505\n",
      "Epoch 26181 - Train Loss: 0.075404, Train Acc: 0.880769 | Val Loss: 0.110603, Val Acc: 0.783505\n",
      "Epoch 26182 - Train Loss: 0.075402, Train Acc: 0.880769 | Val Loss: 0.110603, Val Acc: 0.783505\n",
      "Epoch 26183 - Train Loss: 0.075401, Train Acc: 0.880769 | Val Loss: 0.110602, Val Acc: 0.783505\n",
      "Epoch 26184 - Train Loss: 0.075399, Train Acc: 0.880769 | Val Loss: 0.110602, Val Acc: 0.783505\n",
      "Epoch 26185 - Train Loss: 0.075398, Train Acc: 0.880769 | Val Loss: 0.110601, Val Acc: 0.783505\n",
      "Epoch 26186 - Train Loss: 0.075396, Train Acc: 0.880769 | Val Loss: 0.110601, Val Acc: 0.783505\n",
      "Epoch 26187 - Train Loss: 0.075395, Train Acc: 0.880769 | Val Loss: 0.110600, Val Acc: 0.783505\n",
      "Epoch 26188 - Train Loss: 0.075393, Train Acc: 0.880769 | Val Loss: 0.110600, Val Acc: 0.783505\n",
      "Epoch 26189 - Train Loss: 0.075392, Train Acc: 0.880769 | Val Loss: 0.110600, Val Acc: 0.783505\n",
      "Epoch 26190 - Train Loss: 0.075391, Train Acc: 0.880769 | Val Loss: 0.110599, Val Acc: 0.783505\n",
      "Epoch 26191 - Train Loss: 0.075389, Train Acc: 0.880769 | Val Loss: 0.110599, Val Acc: 0.783505\n",
      "Epoch 26192 - Train Loss: 0.075388, Train Acc: 0.880769 | Val Loss: 0.110598, Val Acc: 0.783505\n",
      "Epoch 26193 - Train Loss: 0.075386, Train Acc: 0.880769 | Val Loss: 0.110598, Val Acc: 0.783505\n",
      "Epoch 26194 - Train Loss: 0.075385, Train Acc: 0.880769 | Val Loss: 0.110597, Val Acc: 0.783505\n",
      "Epoch 26195 - Train Loss: 0.075383, Train Acc: 0.880769 | Val Loss: 0.110597, Val Acc: 0.783505\n",
      "Epoch 26196 - Train Loss: 0.075382, Train Acc: 0.880769 | Val Loss: 0.110596, Val Acc: 0.783505\n",
      "Epoch 26197 - Train Loss: 0.075380, Train Acc: 0.880769 | Val Loss: 0.110596, Val Acc: 0.783505\n",
      "Epoch 26198 - Train Loss: 0.075379, Train Acc: 0.880769 | Val Loss: 0.110595, Val Acc: 0.783505\n",
      "Epoch 26199 - Train Loss: 0.075377, Train Acc: 0.880769 | Val Loss: 0.110595, Val Acc: 0.783505\n",
      "Epoch 26200 - Train Loss: 0.075376, Train Acc: 0.880769 | Val Loss: 0.110595, Val Acc: 0.783505\n",
      "Epoch 26201 - Train Loss: 0.075374, Train Acc: 0.880769 | Val Loss: 0.110594, Val Acc: 0.783505\n",
      "Epoch 26202 - Train Loss: 0.075373, Train Acc: 0.880769 | Val Loss: 0.110594, Val Acc: 0.783505\n",
      "Epoch 26203 - Train Loss: 0.075371, Train Acc: 0.880769 | Val Loss: 0.110593, Val Acc: 0.783505\n",
      "Epoch 26204 - Train Loss: 0.075370, Train Acc: 0.880769 | Val Loss: 0.110593, Val Acc: 0.783505\n",
      "Epoch 26205 - Train Loss: 0.075368, Train Acc: 0.880769 | Val Loss: 0.110592, Val Acc: 0.783505\n",
      "Epoch 26206 - Train Loss: 0.075367, Train Acc: 0.880769 | Val Loss: 0.110592, Val Acc: 0.783505\n",
      "Epoch 26207 - Train Loss: 0.075366, Train Acc: 0.880769 | Val Loss: 0.110591, Val Acc: 0.783505\n",
      "Epoch 26208 - Train Loss: 0.075364, Train Acc: 0.880769 | Val Loss: 0.110591, Val Acc: 0.783505\n",
      "Epoch 26209 - Train Loss: 0.075363, Train Acc: 0.880769 | Val Loss: 0.110590, Val Acc: 0.783505\n",
      "Epoch 26210 - Train Loss: 0.075361, Train Acc: 0.880769 | Val Loss: 0.110590, Val Acc: 0.783505\n",
      "Epoch 26211 - Train Loss: 0.075360, Train Acc: 0.880769 | Val Loss: 0.110589, Val Acc: 0.783505\n",
      "Epoch 26212 - Train Loss: 0.075358, Train Acc: 0.880769 | Val Loss: 0.110589, Val Acc: 0.783505\n",
      "Epoch 26213 - Train Loss: 0.075357, Train Acc: 0.880769 | Val Loss: 0.110589, Val Acc: 0.783505\n",
      "Epoch 26214 - Train Loss: 0.075355, Train Acc: 0.880769 | Val Loss: 0.110588, Val Acc: 0.783505\n",
      "Epoch 26215 - Train Loss: 0.075354, Train Acc: 0.880769 | Val Loss: 0.110588, Val Acc: 0.783505\n",
      "Epoch 26216 - Train Loss: 0.075352, Train Acc: 0.880769 | Val Loss: 0.110587, Val Acc: 0.783505\n",
      "Epoch 26217 - Train Loss: 0.075351, Train Acc: 0.880769 | Val Loss: 0.110587, Val Acc: 0.783505\n",
      "Epoch 26218 - Train Loss: 0.075349, Train Acc: 0.880769 | Val Loss: 0.110586, Val Acc: 0.783505\n",
      "Epoch 26219 - Train Loss: 0.075348, Train Acc: 0.880769 | Val Loss: 0.110586, Val Acc: 0.783505\n",
      "Epoch 26220 - Train Loss: 0.075346, Train Acc: 0.880769 | Val Loss: 0.110585, Val Acc: 0.783505\n",
      "Epoch 26221 - Train Loss: 0.075345, Train Acc: 0.880769 | Val Loss: 0.110585, Val Acc: 0.783505\n",
      "Epoch 26222 - Train Loss: 0.075343, Train Acc: 0.880769 | Val Loss: 0.110584, Val Acc: 0.783505\n",
      "Epoch 26223 - Train Loss: 0.075342, Train Acc: 0.880769 | Val Loss: 0.110584, Val Acc: 0.783505\n",
      "Epoch 26224 - Train Loss: 0.075341, Train Acc: 0.880769 | Val Loss: 0.110584, Val Acc: 0.783505\n",
      "Epoch 26225 - Train Loss: 0.075339, Train Acc: 0.880769 | Val Loss: 0.110583, Val Acc: 0.783505\n",
      "Epoch 26226 - Train Loss: 0.075338, Train Acc: 0.880769 | Val Loss: 0.110583, Val Acc: 0.783505\n",
      "Epoch 26227 - Train Loss: 0.075336, Train Acc: 0.880769 | Val Loss: 0.110582, Val Acc: 0.783505\n",
      "Epoch 26228 - Train Loss: 0.075335, Train Acc: 0.880769 | Val Loss: 0.110582, Val Acc: 0.783505\n",
      "Epoch 26229 - Train Loss: 0.075333, Train Acc: 0.880769 | Val Loss: 0.110581, Val Acc: 0.783505\n",
      "Epoch 26230 - Train Loss: 0.075332, Train Acc: 0.880769 | Val Loss: 0.110581, Val Acc: 0.783505\n",
      "Epoch 26231 - Train Loss: 0.075330, Train Acc: 0.880769 | Val Loss: 0.110580, Val Acc: 0.783505\n",
      "Epoch 26232 - Train Loss: 0.075329, Train Acc: 0.880769 | Val Loss: 0.110580, Val Acc: 0.783505\n",
      "Epoch 26233 - Train Loss: 0.075327, Train Acc: 0.880769 | Val Loss: 0.110579, Val Acc: 0.783505\n",
      "Epoch 26234 - Train Loss: 0.075326, Train Acc: 0.880769 | Val Loss: 0.110579, Val Acc: 0.783505\n",
      "Epoch 26235 - Train Loss: 0.075324, Train Acc: 0.880769 | Val Loss: 0.110578, Val Acc: 0.783505\n",
      "Epoch 26236 - Train Loss: 0.075323, Train Acc: 0.880769 | Val Loss: 0.110578, Val Acc: 0.783505\n",
      "Epoch 26237 - Train Loss: 0.075321, Train Acc: 0.880769 | Val Loss: 0.110578, Val Acc: 0.783505\n",
      "Epoch 26238 - Train Loss: 0.075320, Train Acc: 0.880769 | Val Loss: 0.110577, Val Acc: 0.783505\n",
      "Epoch 26239 - Train Loss: 0.075318, Train Acc: 0.880769 | Val Loss: 0.110577, Val Acc: 0.783505\n",
      "Epoch 26240 - Train Loss: 0.075317, Train Acc: 0.880769 | Val Loss: 0.110576, Val Acc: 0.783505\n",
      "Epoch 26241 - Train Loss: 0.075316, Train Acc: 0.880769 | Val Loss: 0.110576, Val Acc: 0.783505\n",
      "Epoch 26242 - Train Loss: 0.075314, Train Acc: 0.880769 | Val Loss: 0.110575, Val Acc: 0.783505\n",
      "Epoch 26243 - Train Loss: 0.075313, Train Acc: 0.880769 | Val Loss: 0.110575, Val Acc: 0.783505\n",
      "Epoch 26244 - Train Loss: 0.075311, Train Acc: 0.880769 | Val Loss: 0.110574, Val Acc: 0.783505\n",
      "Epoch 26245 - Train Loss: 0.075310, Train Acc: 0.880769 | Val Loss: 0.110574, Val Acc: 0.783505\n",
      "Epoch 26246 - Train Loss: 0.075308, Train Acc: 0.880769 | Val Loss: 0.110573, Val Acc: 0.783505\n",
      "Epoch 26247 - Train Loss: 0.075307, Train Acc: 0.880769 | Val Loss: 0.110573, Val Acc: 0.783505\n",
      "Epoch 26248 - Train Loss: 0.075305, Train Acc: 0.880769 | Val Loss: 0.110573, Val Acc: 0.783505\n",
      "Epoch 26249 - Train Loss: 0.075304, Train Acc: 0.880769 | Val Loss: 0.110572, Val Acc: 0.783505\n",
      "Epoch 26250 - Train Loss: 0.075302, Train Acc: 0.880769 | Val Loss: 0.110572, Val Acc: 0.783505\n",
      "Epoch 26251 - Train Loss: 0.075301, Train Acc: 0.880769 | Val Loss: 0.110571, Val Acc: 0.783505\n",
      "Epoch 26252 - Train Loss: 0.075299, Train Acc: 0.880769 | Val Loss: 0.110571, Val Acc: 0.783505\n",
      "Epoch 26253 - Train Loss: 0.075298, Train Acc: 0.880769 | Val Loss: 0.110570, Val Acc: 0.783505\n",
      "Epoch 26254 - Train Loss: 0.075296, Train Acc: 0.880769 | Val Loss: 0.110570, Val Acc: 0.783505\n",
      "Epoch 26255 - Train Loss: 0.075295, Train Acc: 0.880769 | Val Loss: 0.110569, Val Acc: 0.783505\n",
      "Epoch 26256 - Train Loss: 0.075293, Train Acc: 0.880769 | Val Loss: 0.110569, Val Acc: 0.783505\n",
      "Epoch 26257 - Train Loss: 0.075292, Train Acc: 0.880769 | Val Loss: 0.110568, Val Acc: 0.783505\n",
      "Epoch 26258 - Train Loss: 0.075291, Train Acc: 0.880769 | Val Loss: 0.110568, Val Acc: 0.783505\n",
      "Epoch 26259 - Train Loss: 0.075289, Train Acc: 0.880769 | Val Loss: 0.110567, Val Acc: 0.783505\n",
      "Epoch 26260 - Train Loss: 0.075288, Train Acc: 0.880769 | Val Loss: 0.110567, Val Acc: 0.783505\n",
      "Epoch 26261 - Train Loss: 0.075286, Train Acc: 0.880769 | Val Loss: 0.110566, Val Acc: 0.783505\n",
      "Epoch 26262 - Train Loss: 0.075285, Train Acc: 0.880769 | Val Loss: 0.110566, Val Acc: 0.783505\n",
      "Epoch 26263 - Train Loss: 0.075283, Train Acc: 0.880769 | Val Loss: 0.110566, Val Acc: 0.783505\n",
      "Epoch 26264 - Train Loss: 0.075282, Train Acc: 0.880769 | Val Loss: 0.110565, Val Acc: 0.783505\n",
      "Epoch 26265 - Train Loss: 0.075280, Train Acc: 0.880769 | Val Loss: 0.110565, Val Acc: 0.783505\n",
      "Epoch 26266 - Train Loss: 0.075279, Train Acc: 0.880769 | Val Loss: 0.110564, Val Acc: 0.783505\n",
      "Epoch 26267 - Train Loss: 0.075277, Train Acc: 0.880769 | Val Loss: 0.110564, Val Acc: 0.783505\n",
      "Epoch 26268 - Train Loss: 0.075276, Train Acc: 0.880769 | Val Loss: 0.110563, Val Acc: 0.783505\n",
      "Epoch 26269 - Train Loss: 0.075274, Train Acc: 0.880769 | Val Loss: 0.110563, Val Acc: 0.783505\n",
      "Epoch 26270 - Train Loss: 0.075273, Train Acc: 0.880769 | Val Loss: 0.110562, Val Acc: 0.783505\n",
      "Epoch 26271 - Train Loss: 0.075271, Train Acc: 0.880769 | Val Loss: 0.110562, Val Acc: 0.783505\n",
      "Epoch 26272 - Train Loss: 0.075270, Train Acc: 0.880769 | Val Loss: 0.110561, Val Acc: 0.783505\n",
      "Epoch 26273 - Train Loss: 0.075269, Train Acc: 0.880769 | Val Loss: 0.110561, Val Acc: 0.783505\n",
      "Epoch 26274 - Train Loss: 0.075267, Train Acc: 0.880769 | Val Loss: 0.110560, Val Acc: 0.783505\n",
      "Epoch 26275 - Train Loss: 0.075266, Train Acc: 0.880769 | Val Loss: 0.110560, Val Acc: 0.783505\n",
      "Epoch 26276 - Train Loss: 0.075264, Train Acc: 0.880769 | Val Loss: 0.110560, Val Acc: 0.783505\n",
      "Epoch 26277 - Train Loss: 0.075263, Train Acc: 0.880769 | Val Loss: 0.110559, Val Acc: 0.783505\n",
      "Epoch 26278 - Train Loss: 0.075261, Train Acc: 0.880769 | Val Loss: 0.110559, Val Acc: 0.783505\n",
      "Epoch 26279 - Train Loss: 0.075260, Train Acc: 0.880769 | Val Loss: 0.110558, Val Acc: 0.783505\n",
      "Epoch 26280 - Train Loss: 0.075258, Train Acc: 0.880769 | Val Loss: 0.110558, Val Acc: 0.783505\n",
      "Epoch 26281 - Train Loss: 0.075257, Train Acc: 0.880769 | Val Loss: 0.110557, Val Acc: 0.783505\n",
      "Epoch 26282 - Train Loss: 0.075255, Train Acc: 0.880769 | Val Loss: 0.110557, Val Acc: 0.783505\n",
      "Epoch 26283 - Train Loss: 0.075254, Train Acc: 0.880769 | Val Loss: 0.110556, Val Acc: 0.783505\n",
      "Epoch 26284 - Train Loss: 0.075252, Train Acc: 0.880769 | Val Loss: 0.110556, Val Acc: 0.783505\n",
      "Epoch 26285 - Train Loss: 0.075251, Train Acc: 0.880769 | Val Loss: 0.110555, Val Acc: 0.783505\n",
      "Epoch 26286 - Train Loss: 0.075249, Train Acc: 0.880769 | Val Loss: 0.110555, Val Acc: 0.783505\n",
      "Epoch 26287 - Train Loss: 0.075248, Train Acc: 0.880769 | Val Loss: 0.110555, Val Acc: 0.783505\n",
      "Epoch 26288 - Train Loss: 0.075247, Train Acc: 0.880769 | Val Loss: 0.110554, Val Acc: 0.783505\n",
      "Epoch 26289 - Train Loss: 0.075245, Train Acc: 0.880769 | Val Loss: 0.110554, Val Acc: 0.783505\n",
      "Epoch 26290 - Train Loss: 0.075244, Train Acc: 0.880769 | Val Loss: 0.110553, Val Acc: 0.783505\n",
      "Epoch 26291 - Train Loss: 0.075242, Train Acc: 0.880769 | Val Loss: 0.110553, Val Acc: 0.783505\n",
      "Epoch 26292 - Train Loss: 0.075241, Train Acc: 0.880769 | Val Loss: 0.110552, Val Acc: 0.783505\n",
      "Epoch 26293 - Train Loss: 0.075239, Train Acc: 0.880769 | Val Loss: 0.110552, Val Acc: 0.783505\n",
      "Epoch 26294 - Train Loss: 0.075238, Train Acc: 0.880769 | Val Loss: 0.110551, Val Acc: 0.783505\n",
      "Epoch 26295 - Train Loss: 0.075236, Train Acc: 0.880769 | Val Loss: 0.110551, Val Acc: 0.783505\n",
      "Epoch 26296 - Train Loss: 0.075235, Train Acc: 0.880769 | Val Loss: 0.110550, Val Acc: 0.783505\n",
      "Epoch 26297 - Train Loss: 0.075233, Train Acc: 0.880769 | Val Loss: 0.110550, Val Acc: 0.783505\n",
      "Epoch 26298 - Train Loss: 0.075232, Train Acc: 0.880769 | Val Loss: 0.110549, Val Acc: 0.783505\n",
      "Epoch 26299 - Train Loss: 0.075230, Train Acc: 0.880769 | Val Loss: 0.110549, Val Acc: 0.783505\n",
      "Epoch 26300 - Train Loss: 0.075229, Train Acc: 0.880769 | Val Loss: 0.110549, Val Acc: 0.783505\n",
      "Epoch 26301 - Train Loss: 0.075227, Train Acc: 0.880769 | Val Loss: 0.110548, Val Acc: 0.783505\n",
      "Epoch 26302 - Train Loss: 0.075226, Train Acc: 0.880769 | Val Loss: 0.110548, Val Acc: 0.783505\n",
      "Epoch 26303 - Train Loss: 0.075225, Train Acc: 0.880769 | Val Loss: 0.110547, Val Acc: 0.783505\n",
      "Epoch 26304 - Train Loss: 0.075223, Train Acc: 0.880769 | Val Loss: 0.110547, Val Acc: 0.783505\n",
      "Epoch 26305 - Train Loss: 0.075222, Train Acc: 0.880769 | Val Loss: 0.110546, Val Acc: 0.783505\n",
      "Epoch 26306 - Train Loss: 0.075220, Train Acc: 0.880769 | Val Loss: 0.110546, Val Acc: 0.783505\n",
      "Epoch 26307 - Train Loss: 0.075219, Train Acc: 0.880769 | Val Loss: 0.110545, Val Acc: 0.783505\n",
      "Epoch 26308 - Train Loss: 0.075217, Train Acc: 0.880769 | Val Loss: 0.110545, Val Acc: 0.783505\n",
      "Epoch 26309 - Train Loss: 0.075216, Train Acc: 0.880769 | Val Loss: 0.110544, Val Acc: 0.783505\n",
      "Epoch 26310 - Train Loss: 0.075214, Train Acc: 0.880769 | Val Loss: 0.110544, Val Acc: 0.783505\n",
      "Epoch 26311 - Train Loss: 0.075213, Train Acc: 0.880769 | Val Loss: 0.110544, Val Acc: 0.783505\n",
      "Epoch 26312 - Train Loss: 0.075211, Train Acc: 0.880769 | Val Loss: 0.110543, Val Acc: 0.783505\n",
      "Epoch 26313 - Train Loss: 0.075210, Train Acc: 0.880769 | Val Loss: 0.110543, Val Acc: 0.783505\n",
      "Epoch 26314 - Train Loss: 0.075208, Train Acc: 0.880769 | Val Loss: 0.110542, Val Acc: 0.783505\n",
      "Epoch 26315 - Train Loss: 0.075207, Train Acc: 0.880769 | Val Loss: 0.110542, Val Acc: 0.783505\n",
      "Epoch 26316 - Train Loss: 0.075205, Train Acc: 0.880769 | Val Loss: 0.110541, Val Acc: 0.783505\n",
      "Epoch 26317 - Train Loss: 0.075204, Train Acc: 0.880769 | Val Loss: 0.110541, Val Acc: 0.783505\n",
      "Epoch 26318 - Train Loss: 0.075203, Train Acc: 0.880769 | Val Loss: 0.110540, Val Acc: 0.783505\n",
      "Epoch 26319 - Train Loss: 0.075201, Train Acc: 0.880769 | Val Loss: 0.110540, Val Acc: 0.783505\n",
      "Epoch 26320 - Train Loss: 0.075200, Train Acc: 0.880769 | Val Loss: 0.110539, Val Acc: 0.783505\n",
      "Epoch 26321 - Train Loss: 0.075198, Train Acc: 0.880769 | Val Loss: 0.110539, Val Acc: 0.783505\n",
      "Epoch 26322 - Train Loss: 0.075197, Train Acc: 0.880769 | Val Loss: 0.110539, Val Acc: 0.783505\n",
      "Epoch 26323 - Train Loss: 0.075195, Train Acc: 0.880769 | Val Loss: 0.110538, Val Acc: 0.783505\n",
      "Epoch 26324 - Train Loss: 0.075194, Train Acc: 0.880769 | Val Loss: 0.110538, Val Acc: 0.783505\n",
      "Epoch 26325 - Train Loss: 0.075192, Train Acc: 0.880769 | Val Loss: 0.110537, Val Acc: 0.783505\n",
      "Epoch 26326 - Train Loss: 0.075191, Train Acc: 0.880769 | Val Loss: 0.110537, Val Acc: 0.783505\n",
      "Epoch 26327 - Train Loss: 0.075189, Train Acc: 0.880769 | Val Loss: 0.110536, Val Acc: 0.783505\n",
      "Epoch 26328 - Train Loss: 0.075188, Train Acc: 0.880769 | Val Loss: 0.110536, Val Acc: 0.783505\n",
      "Epoch 26329 - Train Loss: 0.075186, Train Acc: 0.880769 | Val Loss: 0.110535, Val Acc: 0.783505\n",
      "Epoch 26330 - Train Loss: 0.075185, Train Acc: 0.880769 | Val Loss: 0.110535, Val Acc: 0.783505\n",
      "Epoch 26331 - Train Loss: 0.075184, Train Acc: 0.880769 | Val Loss: 0.110535, Val Acc: 0.783505\n",
      "Epoch 26332 - Train Loss: 0.075182, Train Acc: 0.880769 | Val Loss: 0.110534, Val Acc: 0.783505\n",
      "Epoch 26333 - Train Loss: 0.075181, Train Acc: 0.880769 | Val Loss: 0.110534, Val Acc: 0.783505\n",
      "Epoch 26334 - Train Loss: 0.075179, Train Acc: 0.880769 | Val Loss: 0.110533, Val Acc: 0.783505\n",
      "Epoch 26335 - Train Loss: 0.075178, Train Acc: 0.880769 | Val Loss: 0.110533, Val Acc: 0.783505\n",
      "Epoch 26336 - Train Loss: 0.075176, Train Acc: 0.880769 | Val Loss: 0.110532, Val Acc: 0.783505\n",
      "Epoch 26337 - Train Loss: 0.075175, Train Acc: 0.880769 | Val Loss: 0.110532, Val Acc: 0.783505\n",
      "Epoch 26338 - Train Loss: 0.075173, Train Acc: 0.880769 | Val Loss: 0.110531, Val Acc: 0.783505\n",
      "Epoch 26339 - Train Loss: 0.075172, Train Acc: 0.880769 | Val Loss: 0.110531, Val Acc: 0.783505\n",
      "Epoch 26340 - Train Loss: 0.075170, Train Acc: 0.880769 | Val Loss: 0.110530, Val Acc: 0.783505\n",
      "Epoch 26341 - Train Loss: 0.075169, Train Acc: 0.880769 | Val Loss: 0.110530, Val Acc: 0.783505\n",
      "Epoch 26342 - Train Loss: 0.075167, Train Acc: 0.880769 | Val Loss: 0.110530, Val Acc: 0.783505\n",
      "Epoch 26343 - Train Loss: 0.075166, Train Acc: 0.880769 | Val Loss: 0.110529, Val Acc: 0.783505\n",
      "Epoch 26344 - Train Loss: 0.075165, Train Acc: 0.880769 | Val Loss: 0.110529, Val Acc: 0.783505\n",
      "Epoch 26345 - Train Loss: 0.075163, Train Acc: 0.880769 | Val Loss: 0.110528, Val Acc: 0.783505\n",
      "Epoch 26346 - Train Loss: 0.075162, Train Acc: 0.880769 | Val Loss: 0.110528, Val Acc: 0.783505\n",
      "Epoch 26347 - Train Loss: 0.075160, Train Acc: 0.880769 | Val Loss: 0.110527, Val Acc: 0.783505\n",
      "Epoch 26348 - Train Loss: 0.075159, Train Acc: 0.880769 | Val Loss: 0.110527, Val Acc: 0.783505\n",
      "Epoch 26349 - Train Loss: 0.075157, Train Acc: 0.880769 | Val Loss: 0.110526, Val Acc: 0.783505\n",
      "Epoch 26350 - Train Loss: 0.075156, Train Acc: 0.880769 | Val Loss: 0.110526, Val Acc: 0.783505\n",
      "Epoch 26351 - Train Loss: 0.075154, Train Acc: 0.880769 | Val Loss: 0.110525, Val Acc: 0.783505\n",
      "Epoch 26352 - Train Loss: 0.075153, Train Acc: 0.880769 | Val Loss: 0.110525, Val Acc: 0.783505\n",
      "Epoch 26353 - Train Loss: 0.075151, Train Acc: 0.880769 | Val Loss: 0.110525, Val Acc: 0.783505\n",
      "Epoch 26354 - Train Loss: 0.075150, Train Acc: 0.880769 | Val Loss: 0.110524, Val Acc: 0.783505\n",
      "Epoch 26355 - Train Loss: 0.075148, Train Acc: 0.880769 | Val Loss: 0.110524, Val Acc: 0.783505\n",
      "Epoch 26356 - Train Loss: 0.075147, Train Acc: 0.880769 | Val Loss: 0.110523, Val Acc: 0.783505\n",
      "Epoch 26357 - Train Loss: 0.075146, Train Acc: 0.880769 | Val Loss: 0.110523, Val Acc: 0.783505\n",
      "Epoch 26358 - Train Loss: 0.075144, Train Acc: 0.880769 | Val Loss: 0.110522, Val Acc: 0.783505\n",
      "Epoch 26359 - Train Loss: 0.075143, Train Acc: 0.880769 | Val Loss: 0.110522, Val Acc: 0.783505\n",
      "Epoch 26360 - Train Loss: 0.075141, Train Acc: 0.880769 | Val Loss: 0.110521, Val Acc: 0.783505\n",
      "Epoch 26361 - Train Loss: 0.075140, Train Acc: 0.880769 | Val Loss: 0.110521, Val Acc: 0.783505\n",
      "Epoch 26362 - Train Loss: 0.075138, Train Acc: 0.880769 | Val Loss: 0.110521, Val Acc: 0.783505\n",
      "Epoch 26363 - Train Loss: 0.075137, Train Acc: 0.880769 | Val Loss: 0.110520, Val Acc: 0.783505\n",
      "Epoch 26364 - Train Loss: 0.075135, Train Acc: 0.880769 | Val Loss: 0.110520, Val Acc: 0.783505\n",
      "Epoch 26365 - Train Loss: 0.075134, Train Acc: 0.880769 | Val Loss: 0.110519, Val Acc: 0.783505\n",
      "Epoch 26366 - Train Loss: 0.075132, Train Acc: 0.880769 | Val Loss: 0.110519, Val Acc: 0.783505\n",
      "Epoch 26367 - Train Loss: 0.075131, Train Acc: 0.880769 | Val Loss: 0.110518, Val Acc: 0.783505\n",
      "Epoch 26368 - Train Loss: 0.075129, Train Acc: 0.880769 | Val Loss: 0.110518, Val Acc: 0.783505\n",
      "Epoch 26369 - Train Loss: 0.075128, Train Acc: 0.880769 | Val Loss: 0.110517, Val Acc: 0.783505\n",
      "Epoch 26370 - Train Loss: 0.075127, Train Acc: 0.880769 | Val Loss: 0.110517, Val Acc: 0.783505\n",
      "Epoch 26371 - Train Loss: 0.075125, Train Acc: 0.880769 | Val Loss: 0.110517, Val Acc: 0.783505\n",
      "Epoch 26372 - Train Loss: 0.075124, Train Acc: 0.880769 | Val Loss: 0.110516, Val Acc: 0.783505\n",
      "Epoch 26373 - Train Loss: 0.075122, Train Acc: 0.880769 | Val Loss: 0.110516, Val Acc: 0.783505\n",
      "Epoch 26374 - Train Loss: 0.075121, Train Acc: 0.880769 | Val Loss: 0.110515, Val Acc: 0.783505\n",
      "Epoch 26375 - Train Loss: 0.075119, Train Acc: 0.880769 | Val Loss: 0.110515, Val Acc: 0.783505\n",
      "Epoch 26376 - Train Loss: 0.075118, Train Acc: 0.880769 | Val Loss: 0.110514, Val Acc: 0.783505\n",
      "Epoch 26377 - Train Loss: 0.075116, Train Acc: 0.880769 | Val Loss: 0.110514, Val Acc: 0.783505\n",
      "Epoch 26378 - Train Loss: 0.075115, Train Acc: 0.880769 | Val Loss: 0.110513, Val Acc: 0.783505\n",
      "Epoch 26379 - Train Loss: 0.075113, Train Acc: 0.880769 | Val Loss: 0.110513, Val Acc: 0.783505\n",
      "Epoch 26380 - Train Loss: 0.075112, Train Acc: 0.880769 | Val Loss: 0.110512, Val Acc: 0.783505\n",
      "Epoch 26381 - Train Loss: 0.075111, Train Acc: 0.880769 | Val Loss: 0.110512, Val Acc: 0.783505\n",
      "Epoch 26382 - Train Loss: 0.075109, Train Acc: 0.880769 | Val Loss: 0.110512, Val Acc: 0.783505\n",
      "Epoch 26383 - Train Loss: 0.075108, Train Acc: 0.880769 | Val Loss: 0.110511, Val Acc: 0.783505\n",
      "Epoch 26384 - Train Loss: 0.075106, Train Acc: 0.880769 | Val Loss: 0.110511, Val Acc: 0.783505\n",
      "Epoch 26385 - Train Loss: 0.075105, Train Acc: 0.880769 | Val Loss: 0.110510, Val Acc: 0.783505\n",
      "Epoch 26386 - Train Loss: 0.075103, Train Acc: 0.880769 | Val Loss: 0.110510, Val Acc: 0.783505\n",
      "Epoch 26387 - Train Loss: 0.075102, Train Acc: 0.880769 | Val Loss: 0.110509, Val Acc: 0.783505\n",
      "Epoch 26388 - Train Loss: 0.075100, Train Acc: 0.880769 | Val Loss: 0.110509, Val Acc: 0.783505\n",
      "Epoch 26389 - Train Loss: 0.075099, Train Acc: 0.880769 | Val Loss: 0.110508, Val Acc: 0.783505\n",
      "Epoch 26390 - Train Loss: 0.075097, Train Acc: 0.880769 | Val Loss: 0.110508, Val Acc: 0.783505\n",
      "Epoch 26391 - Train Loss: 0.075096, Train Acc: 0.880769 | Val Loss: 0.110508, Val Acc: 0.783505\n",
      "Epoch 26392 - Train Loss: 0.075094, Train Acc: 0.880769 | Val Loss: 0.110507, Val Acc: 0.783505\n",
      "Epoch 26393 - Train Loss: 0.075093, Train Acc: 0.880769 | Val Loss: 0.110507, Val Acc: 0.783505\n",
      "Epoch 26394 - Train Loss: 0.075092, Train Acc: 0.880769 | Val Loss: 0.110506, Val Acc: 0.783505\n",
      "Epoch 26395 - Train Loss: 0.075090, Train Acc: 0.880769 | Val Loss: 0.110506, Val Acc: 0.783505\n",
      "Epoch 26396 - Train Loss: 0.075089, Train Acc: 0.880769 | Val Loss: 0.110505, Val Acc: 0.783505\n",
      "Epoch 26397 - Train Loss: 0.075087, Train Acc: 0.880769 | Val Loss: 0.110505, Val Acc: 0.783505\n",
      "Epoch 26398 - Train Loss: 0.075086, Train Acc: 0.880769 | Val Loss: 0.110504, Val Acc: 0.783505\n",
      "Epoch 26399 - Train Loss: 0.075084, Train Acc: 0.880769 | Val Loss: 0.110504, Val Acc: 0.783505\n",
      "Epoch 26400 - Train Loss: 0.075083, Train Acc: 0.880769 | Val Loss: 0.110504, Val Acc: 0.783505\n",
      "Epoch 26401 - Train Loss: 0.075081, Train Acc: 0.880769 | Val Loss: 0.110503, Val Acc: 0.783505\n",
      "Epoch 26402 - Train Loss: 0.075080, Train Acc: 0.880769 | Val Loss: 0.110503, Val Acc: 0.783505\n",
      "Epoch 26403 - Train Loss: 0.075078, Train Acc: 0.880769 | Val Loss: 0.110502, Val Acc: 0.783505\n",
      "Epoch 26404 - Train Loss: 0.075077, Train Acc: 0.880769 | Val Loss: 0.110502, Val Acc: 0.783505\n",
      "Epoch 26405 - Train Loss: 0.075076, Train Acc: 0.880769 | Val Loss: 0.110501, Val Acc: 0.783505\n",
      "Epoch 26406 - Train Loss: 0.075074, Train Acc: 0.880769 | Val Loss: 0.110501, Val Acc: 0.783505\n",
      "Epoch 26407 - Train Loss: 0.075073, Train Acc: 0.880769 | Val Loss: 0.110500, Val Acc: 0.783505\n",
      "Epoch 26408 - Train Loss: 0.075071, Train Acc: 0.880769 | Val Loss: 0.110500, Val Acc: 0.783505\n",
      "Epoch 26409 - Train Loss: 0.075070, Train Acc: 0.880769 | Val Loss: 0.110500, Val Acc: 0.783505\n",
      "Epoch 26410 - Train Loss: 0.075068, Train Acc: 0.880769 | Val Loss: 0.110499, Val Acc: 0.783505\n",
      "Epoch 26411 - Train Loss: 0.075067, Train Acc: 0.880769 | Val Loss: 0.110499, Val Acc: 0.783505\n",
      "Epoch 26412 - Train Loss: 0.075065, Train Acc: 0.880769 | Val Loss: 0.110498, Val Acc: 0.783505\n",
      "Epoch 26413 - Train Loss: 0.075064, Train Acc: 0.880769 | Val Loss: 0.110498, Val Acc: 0.783505\n",
      "Epoch 26414 - Train Loss: 0.075062, Train Acc: 0.880769 | Val Loss: 0.110497, Val Acc: 0.783505\n",
      "Epoch 26415 - Train Loss: 0.075061, Train Acc: 0.880769 | Val Loss: 0.110497, Val Acc: 0.783505\n",
      "Epoch 26416 - Train Loss: 0.075060, Train Acc: 0.880769 | Val Loss: 0.110496, Val Acc: 0.783505\n",
      "Epoch 26417 - Train Loss: 0.075058, Train Acc: 0.880769 | Val Loss: 0.110496, Val Acc: 0.783505\n",
      "Epoch 26418 - Train Loss: 0.075057, Train Acc: 0.880769 | Val Loss: 0.110496, Val Acc: 0.783505\n",
      "Epoch 26419 - Train Loss: 0.075055, Train Acc: 0.880769 | Val Loss: 0.110495, Val Acc: 0.783505\n",
      "Epoch 26420 - Train Loss: 0.075054, Train Acc: 0.880769 | Val Loss: 0.110495, Val Acc: 0.783505\n",
      "Epoch 26421 - Train Loss: 0.075052, Train Acc: 0.880769 | Val Loss: 0.110494, Val Acc: 0.783505\n",
      "Epoch 26422 - Train Loss: 0.075051, Train Acc: 0.880769 | Val Loss: 0.110494, Val Acc: 0.783505\n",
      "Epoch 26423 - Train Loss: 0.075049, Train Acc: 0.880769 | Val Loss: 0.110493, Val Acc: 0.783505\n",
      "Epoch 26424 - Train Loss: 0.075048, Train Acc: 0.880769 | Val Loss: 0.110493, Val Acc: 0.783505\n",
      "Epoch 26425 - Train Loss: 0.075046, Train Acc: 0.880769 | Val Loss: 0.110492, Val Acc: 0.783505\n",
      "Epoch 26426 - Train Loss: 0.075045, Train Acc: 0.880769 | Val Loss: 0.110492, Val Acc: 0.783505\n",
      "Epoch 26427 - Train Loss: 0.075044, Train Acc: 0.880769 | Val Loss: 0.110492, Val Acc: 0.783505\n",
      "Epoch 26428 - Train Loss: 0.075042, Train Acc: 0.880769 | Val Loss: 0.110491, Val Acc: 0.783505\n",
      "Epoch 26429 - Train Loss: 0.075041, Train Acc: 0.880769 | Val Loss: 0.110491, Val Acc: 0.783505\n",
      "Epoch 26430 - Train Loss: 0.075039, Train Acc: 0.880769 | Val Loss: 0.110490, Val Acc: 0.783505\n",
      "Epoch 26431 - Train Loss: 0.075038, Train Acc: 0.880769 | Val Loss: 0.110490, Val Acc: 0.783505\n",
      "Epoch 26432 - Train Loss: 0.075036, Train Acc: 0.880769 | Val Loss: 0.110489, Val Acc: 0.783505\n",
      "Epoch 26433 - Train Loss: 0.075035, Train Acc: 0.880769 | Val Loss: 0.110489, Val Acc: 0.783505\n",
      "Epoch 26434 - Train Loss: 0.075033, Train Acc: 0.880769 | Val Loss: 0.110488, Val Acc: 0.783505\n",
      "Epoch 26435 - Train Loss: 0.075032, Train Acc: 0.880769 | Val Loss: 0.110488, Val Acc: 0.783505\n",
      "Epoch 26436 - Train Loss: 0.075030, Train Acc: 0.880769 | Val Loss: 0.110488, Val Acc: 0.783505\n",
      "Epoch 26437 - Train Loss: 0.075029, Train Acc: 0.880769 | Val Loss: 0.110487, Val Acc: 0.783505\n",
      "Epoch 26438 - Train Loss: 0.075028, Train Acc: 0.880769 | Val Loss: 0.110487, Val Acc: 0.783505\n",
      "Epoch 26439 - Train Loss: 0.075026, Train Acc: 0.880769 | Val Loss: 0.110486, Val Acc: 0.783505\n",
      "Epoch 26440 - Train Loss: 0.075025, Train Acc: 0.880769 | Val Loss: 0.110486, Val Acc: 0.783505\n",
      "Epoch 26441 - Train Loss: 0.075023, Train Acc: 0.880769 | Val Loss: 0.110485, Val Acc: 0.783505\n",
      "Epoch 26442 - Train Loss: 0.075022, Train Acc: 0.880769 | Val Loss: 0.110485, Val Acc: 0.783505\n",
      "Epoch 26443 - Train Loss: 0.075020, Train Acc: 0.880769 | Val Loss: 0.110484, Val Acc: 0.783505\n",
      "Epoch 26444 - Train Loss: 0.075019, Train Acc: 0.880769 | Val Loss: 0.110484, Val Acc: 0.783505\n",
      "Epoch 26445 - Train Loss: 0.075017, Train Acc: 0.880769 | Val Loss: 0.110484, Val Acc: 0.783505\n",
      "Epoch 26446 - Train Loss: 0.075016, Train Acc: 0.880769 | Val Loss: 0.110483, Val Acc: 0.783505\n",
      "Epoch 26447 - Train Loss: 0.075014, Train Acc: 0.880769 | Val Loss: 0.110483, Val Acc: 0.783505\n",
      "Epoch 26448 - Train Loss: 0.075013, Train Acc: 0.880769 | Val Loss: 0.110482, Val Acc: 0.783505\n",
      "Epoch 26449 - Train Loss: 0.075012, Train Acc: 0.880769 | Val Loss: 0.110482, Val Acc: 0.783505\n",
      "Epoch 26450 - Train Loss: 0.075010, Train Acc: 0.880769 | Val Loss: 0.110481, Val Acc: 0.783505\n",
      "Epoch 26451 - Train Loss: 0.075009, Train Acc: 0.880769 | Val Loss: 0.110481, Val Acc: 0.783505\n",
      "Epoch 26452 - Train Loss: 0.075007, Train Acc: 0.880769 | Val Loss: 0.110480, Val Acc: 0.783505\n",
      "Epoch 26453 - Train Loss: 0.075006, Train Acc: 0.880769 | Val Loss: 0.110480, Val Acc: 0.783505\n",
      "Epoch 26454 - Train Loss: 0.075004, Train Acc: 0.880769 | Val Loss: 0.110480, Val Acc: 0.783505\n",
      "Epoch 26455 - Train Loss: 0.075003, Train Acc: 0.880769 | Val Loss: 0.110479, Val Acc: 0.783505\n",
      "Epoch 26456 - Train Loss: 0.075001, Train Acc: 0.880769 | Val Loss: 0.110479, Val Acc: 0.783505\n",
      "Epoch 26457 - Train Loss: 0.075000, Train Acc: 0.880769 | Val Loss: 0.110478, Val Acc: 0.783505\n",
      "Epoch 26458 - Train Loss: 0.074998, Train Acc: 0.880769 | Val Loss: 0.110478, Val Acc: 0.783505\n",
      "Epoch 26459 - Train Loss: 0.074997, Train Acc: 0.880769 | Val Loss: 0.110477, Val Acc: 0.783505\n",
      "Epoch 26460 - Train Loss: 0.074996, Train Acc: 0.880769 | Val Loss: 0.110477, Val Acc: 0.783505\n",
      "Epoch 26461 - Train Loss: 0.074994, Train Acc: 0.880769 | Val Loss: 0.110476, Val Acc: 0.783505\n",
      "Epoch 26462 - Train Loss: 0.074993, Train Acc: 0.880769 | Val Loss: 0.110476, Val Acc: 0.783505\n",
      "Epoch 26463 - Train Loss: 0.074991, Train Acc: 0.880769 | Val Loss: 0.110476, Val Acc: 0.783505\n",
      "Epoch 26464 - Train Loss: 0.074990, Train Acc: 0.880769 | Val Loss: 0.110475, Val Acc: 0.783505\n",
      "Epoch 26465 - Train Loss: 0.074988, Train Acc: 0.880769 | Val Loss: 0.110475, Val Acc: 0.783505\n",
      "Epoch 26466 - Train Loss: 0.074987, Train Acc: 0.880769 | Val Loss: 0.110474, Val Acc: 0.783505\n",
      "Epoch 26467 - Train Loss: 0.074985, Train Acc: 0.880769 | Val Loss: 0.110474, Val Acc: 0.783505\n",
      "Epoch 26468 - Train Loss: 0.074984, Train Acc: 0.880769 | Val Loss: 0.110473, Val Acc: 0.783505\n",
      "Epoch 26469 - Train Loss: 0.074982, Train Acc: 0.880769 | Val Loss: 0.110473, Val Acc: 0.783505\n",
      "Epoch 26470 - Train Loss: 0.074981, Train Acc: 0.880769 | Val Loss: 0.110472, Val Acc: 0.783505\n",
      "Epoch 26471 - Train Loss: 0.074980, Train Acc: 0.880769 | Val Loss: 0.110472, Val Acc: 0.783505\n",
      "Epoch 26472 - Train Loss: 0.074978, Train Acc: 0.880769 | Val Loss: 0.110472, Val Acc: 0.783505\n",
      "Epoch 26473 - Train Loss: 0.074977, Train Acc: 0.880769 | Val Loss: 0.110471, Val Acc: 0.783505\n",
      "Epoch 26474 - Train Loss: 0.074975, Train Acc: 0.880769 | Val Loss: 0.110471, Val Acc: 0.783505\n",
      "Epoch 26475 - Train Loss: 0.074974, Train Acc: 0.880769 | Val Loss: 0.110470, Val Acc: 0.783505\n",
      "Epoch 26476 - Train Loss: 0.074972, Train Acc: 0.880769 | Val Loss: 0.110470, Val Acc: 0.783505\n",
      "Epoch 26477 - Train Loss: 0.074971, Train Acc: 0.880769 | Val Loss: 0.110469, Val Acc: 0.783505\n",
      "Epoch 26478 - Train Loss: 0.074969, Train Acc: 0.880769 | Val Loss: 0.110469, Val Acc: 0.783505\n",
      "Epoch 26479 - Train Loss: 0.074968, Train Acc: 0.880769 | Val Loss: 0.110468, Val Acc: 0.783505\n",
      "Epoch 26480 - Train Loss: 0.074967, Train Acc: 0.880769 | Val Loss: 0.110468, Val Acc: 0.783505\n",
      "Epoch 26481 - Train Loss: 0.074965, Train Acc: 0.880769 | Val Loss: 0.110468, Val Acc: 0.783505\n",
      "Epoch 26482 - Train Loss: 0.074964, Train Acc: 0.880769 | Val Loss: 0.110467, Val Acc: 0.783505\n",
      "Epoch 26483 - Train Loss: 0.074962, Train Acc: 0.880769 | Val Loss: 0.110467, Val Acc: 0.783505\n",
      "Epoch 26484 - Train Loss: 0.074961, Train Acc: 0.880769 | Val Loss: 0.110466, Val Acc: 0.783505\n",
      "Epoch 26485 - Train Loss: 0.074959, Train Acc: 0.880769 | Val Loss: 0.110466, Val Acc: 0.783505\n",
      "Epoch 26486 - Train Loss: 0.074958, Train Acc: 0.880769 | Val Loss: 0.110465, Val Acc: 0.783505\n",
      "Epoch 26487 - Train Loss: 0.074956, Train Acc: 0.880769 | Val Loss: 0.110465, Val Acc: 0.783505\n",
      "Epoch 26488 - Train Loss: 0.074955, Train Acc: 0.880769 | Val Loss: 0.110464, Val Acc: 0.783505\n",
      "Epoch 26489 - Train Loss: 0.074953, Train Acc: 0.880769 | Val Loss: 0.110464, Val Acc: 0.783505\n",
      "Epoch 26490 - Train Loss: 0.074952, Train Acc: 0.880769 | Val Loss: 0.110464, Val Acc: 0.783505\n",
      "Epoch 26491 - Train Loss: 0.074951, Train Acc: 0.880769 | Val Loss: 0.110463, Val Acc: 0.783505\n",
      "Epoch 26492 - Train Loss: 0.074949, Train Acc: 0.880769 | Val Loss: 0.110463, Val Acc: 0.783505\n",
      "Epoch 26493 - Train Loss: 0.074948, Train Acc: 0.880769 | Val Loss: 0.110462, Val Acc: 0.783505\n",
      "Epoch 26494 - Train Loss: 0.074946, Train Acc: 0.880769 | Val Loss: 0.110462, Val Acc: 0.783505\n",
      "Epoch 26495 - Train Loss: 0.074945, Train Acc: 0.880769 | Val Loss: 0.110461, Val Acc: 0.783505\n",
      "Epoch 26496 - Train Loss: 0.074943, Train Acc: 0.880769 | Val Loss: 0.110461, Val Acc: 0.783505\n",
      "Epoch 26497 - Train Loss: 0.074942, Train Acc: 0.880769 | Val Loss: 0.110461, Val Acc: 0.783505\n",
      "Epoch 26498 - Train Loss: 0.074940, Train Acc: 0.880769 | Val Loss: 0.110460, Val Acc: 0.783505\n",
      "Epoch 26499 - Train Loss: 0.074939, Train Acc: 0.880769 | Val Loss: 0.110460, Val Acc: 0.783505\n",
      "Epoch 26500 - Train Loss: 0.074938, Train Acc: 0.880769 | Val Loss: 0.110459, Val Acc: 0.783505\n",
      "Epoch 26501 - Train Loss: 0.074936, Train Acc: 0.880769 | Val Loss: 0.110459, Val Acc: 0.783505\n",
      "Epoch 26502 - Train Loss: 0.074935, Train Acc: 0.880769 | Val Loss: 0.110458, Val Acc: 0.783505\n",
      "Epoch 26503 - Train Loss: 0.074933, Train Acc: 0.880769 | Val Loss: 0.110458, Val Acc: 0.783505\n",
      "Epoch 26504 - Train Loss: 0.074932, Train Acc: 0.880769 | Val Loss: 0.110457, Val Acc: 0.783505\n",
      "Epoch 26505 - Train Loss: 0.074930, Train Acc: 0.880769 | Val Loss: 0.110457, Val Acc: 0.783505\n",
      "Epoch 26506 - Train Loss: 0.074929, Train Acc: 0.880769 | Val Loss: 0.110457, Val Acc: 0.783505\n",
      "Epoch 26507 - Train Loss: 0.074927, Train Acc: 0.880769 | Val Loss: 0.110456, Val Acc: 0.783505\n",
      "Epoch 26508 - Train Loss: 0.074926, Train Acc: 0.880769 | Val Loss: 0.110456, Val Acc: 0.783505\n",
      "Epoch 26509 - Train Loss: 0.074924, Train Acc: 0.880769 | Val Loss: 0.110455, Val Acc: 0.783505\n",
      "Epoch 26510 - Train Loss: 0.074923, Train Acc: 0.880769 | Val Loss: 0.110455, Val Acc: 0.783505\n",
      "Epoch 26511 - Train Loss: 0.074922, Train Acc: 0.880769 | Val Loss: 0.110454, Val Acc: 0.783505\n",
      "Epoch 26512 - Train Loss: 0.074920, Train Acc: 0.880769 | Val Loss: 0.110454, Val Acc: 0.783505\n",
      "Epoch 26513 - Train Loss: 0.074919, Train Acc: 0.880769 | Val Loss: 0.110453, Val Acc: 0.783505\n",
      "Epoch 26514 - Train Loss: 0.074917, Train Acc: 0.880769 | Val Loss: 0.110453, Val Acc: 0.783505\n",
      "Epoch 26515 - Train Loss: 0.074916, Train Acc: 0.880769 | Val Loss: 0.110453, Val Acc: 0.783505\n",
      "Epoch 26516 - Train Loss: 0.074914, Train Acc: 0.880769 | Val Loss: 0.110452, Val Acc: 0.783505\n",
      "Epoch 26517 - Train Loss: 0.074913, Train Acc: 0.880769 | Val Loss: 0.110452, Val Acc: 0.783505\n",
      "Epoch 26518 - Train Loss: 0.074911, Train Acc: 0.880769 | Val Loss: 0.110451, Val Acc: 0.783505\n",
      "Epoch 26519 - Train Loss: 0.074910, Train Acc: 0.880769 | Val Loss: 0.110451, Val Acc: 0.783505\n",
      "Epoch 26520 - Train Loss: 0.074909, Train Acc: 0.880769 | Val Loss: 0.110450, Val Acc: 0.783505\n",
      "Epoch 26521 - Train Loss: 0.074907, Train Acc: 0.880769 | Val Loss: 0.110450, Val Acc: 0.783505\n",
      "Epoch 26522 - Train Loss: 0.074906, Train Acc: 0.880769 | Val Loss: 0.110450, Val Acc: 0.783505\n",
      "Epoch 26523 - Train Loss: 0.074904, Train Acc: 0.880769 | Val Loss: 0.110449, Val Acc: 0.783505\n",
      "Epoch 26524 - Train Loss: 0.074903, Train Acc: 0.880769 | Val Loss: 0.110449, Val Acc: 0.783505\n",
      "Epoch 26525 - Train Loss: 0.074901, Train Acc: 0.880769 | Val Loss: 0.110448, Val Acc: 0.783505\n",
      "Epoch 26526 - Train Loss: 0.074900, Train Acc: 0.880769 | Val Loss: 0.110448, Val Acc: 0.783505\n",
      "Epoch 26527 - Train Loss: 0.074898, Train Acc: 0.880769 | Val Loss: 0.110447, Val Acc: 0.783505\n",
      "Epoch 26528 - Train Loss: 0.074897, Train Acc: 0.880769 | Val Loss: 0.110447, Val Acc: 0.783505\n",
      "Epoch 26529 - Train Loss: 0.074896, Train Acc: 0.880769 | Val Loss: 0.110446, Val Acc: 0.783505\n",
      "Epoch 26530 - Train Loss: 0.074894, Train Acc: 0.880769 | Val Loss: 0.110446, Val Acc: 0.783505\n",
      "Epoch 26531 - Train Loss: 0.074893, Train Acc: 0.880769 | Val Loss: 0.110446, Val Acc: 0.783505\n",
      "Epoch 26532 - Train Loss: 0.074891, Train Acc: 0.880769 | Val Loss: 0.110445, Val Acc: 0.783505\n",
      "Epoch 26533 - Train Loss: 0.074890, Train Acc: 0.880769 | Val Loss: 0.110445, Val Acc: 0.783505\n",
      "Epoch 26534 - Train Loss: 0.074888, Train Acc: 0.880769 | Val Loss: 0.110444, Val Acc: 0.783505\n",
      "Epoch 26535 - Train Loss: 0.074887, Train Acc: 0.880769 | Val Loss: 0.110444, Val Acc: 0.783505\n",
      "Epoch 26536 - Train Loss: 0.074885, Train Acc: 0.880769 | Val Loss: 0.110443, Val Acc: 0.783505\n",
      "Epoch 26537 - Train Loss: 0.074884, Train Acc: 0.880769 | Val Loss: 0.110443, Val Acc: 0.783505\n",
      "Epoch 26538 - Train Loss: 0.074883, Train Acc: 0.880769 | Val Loss: 0.110443, Val Acc: 0.783505\n",
      "Epoch 26539 - Train Loss: 0.074881, Train Acc: 0.880769 | Val Loss: 0.110442, Val Acc: 0.783505\n",
      "Epoch 26540 - Train Loss: 0.074880, Train Acc: 0.880769 | Val Loss: 0.110442, Val Acc: 0.783505\n",
      "Epoch 26541 - Train Loss: 0.074878, Train Acc: 0.880769 | Val Loss: 0.110441, Val Acc: 0.783505\n",
      "Epoch 26542 - Train Loss: 0.074877, Train Acc: 0.880769 | Val Loss: 0.110441, Val Acc: 0.783505\n",
      "Epoch 26543 - Train Loss: 0.074875, Train Acc: 0.880769 | Val Loss: 0.110440, Val Acc: 0.783505\n",
      "Epoch 26544 - Train Loss: 0.074874, Train Acc: 0.880769 | Val Loss: 0.110440, Val Acc: 0.783505\n",
      "Epoch 26545 - Train Loss: 0.074872, Train Acc: 0.880769 | Val Loss: 0.110439, Val Acc: 0.783505\n",
      "Epoch 26546 - Train Loss: 0.074871, Train Acc: 0.880769 | Val Loss: 0.110439, Val Acc: 0.783505\n",
      "Epoch 26547 - Train Loss: 0.074869, Train Acc: 0.880769 | Val Loss: 0.110439, Val Acc: 0.783505\n",
      "Epoch 26548 - Train Loss: 0.074868, Train Acc: 0.880769 | Val Loss: 0.110438, Val Acc: 0.783505\n",
      "Epoch 26549 - Train Loss: 0.074867, Train Acc: 0.880769 | Val Loss: 0.110438, Val Acc: 0.783505\n",
      "Epoch 26550 - Train Loss: 0.074865, Train Acc: 0.880769 | Val Loss: 0.110437, Val Acc: 0.783505\n",
      "Epoch 26551 - Train Loss: 0.074864, Train Acc: 0.880769 | Val Loss: 0.110437, Val Acc: 0.783505\n",
      "Epoch 26552 - Train Loss: 0.074862, Train Acc: 0.880769 | Val Loss: 0.110436, Val Acc: 0.783505\n",
      "Epoch 26553 - Train Loss: 0.074861, Train Acc: 0.880769 | Val Loss: 0.110436, Val Acc: 0.783505\n",
      "Epoch 26554 - Train Loss: 0.074859, Train Acc: 0.880769 | Val Loss: 0.110436, Val Acc: 0.783505\n",
      "Epoch 26555 - Train Loss: 0.074858, Train Acc: 0.880769 | Val Loss: 0.110435, Val Acc: 0.783505\n",
      "Epoch 26556 - Train Loss: 0.074856, Train Acc: 0.880769 | Val Loss: 0.110435, Val Acc: 0.783505\n",
      "Epoch 26557 - Train Loss: 0.074855, Train Acc: 0.880769 | Val Loss: 0.110434, Val Acc: 0.783505\n",
      "Epoch 26558 - Train Loss: 0.074854, Train Acc: 0.880769 | Val Loss: 0.110434, Val Acc: 0.783505\n",
      "Epoch 26559 - Train Loss: 0.074852, Train Acc: 0.880769 | Val Loss: 0.110433, Val Acc: 0.783505\n",
      "Epoch 26560 - Train Loss: 0.074851, Train Acc: 0.880769 | Val Loss: 0.110433, Val Acc: 0.783505\n",
      "Epoch 26561 - Train Loss: 0.074849, Train Acc: 0.880769 | Val Loss: 0.110432, Val Acc: 0.783505\n",
      "Epoch 26562 - Train Loss: 0.074848, Train Acc: 0.880769 | Val Loss: 0.110432, Val Acc: 0.783505\n",
      "Epoch 26563 - Train Loss: 0.074846, Train Acc: 0.880769 | Val Loss: 0.110432, Val Acc: 0.783505\n",
      "Epoch 26564 - Train Loss: 0.074845, Train Acc: 0.880769 | Val Loss: 0.110431, Val Acc: 0.783505\n",
      "Epoch 26565 - Train Loss: 0.074843, Train Acc: 0.880769 | Val Loss: 0.110431, Val Acc: 0.783505\n",
      "Epoch 26566 - Train Loss: 0.074842, Train Acc: 0.880769 | Val Loss: 0.110430, Val Acc: 0.783505\n",
      "Epoch 26567 - Train Loss: 0.074841, Train Acc: 0.880769 | Val Loss: 0.110430, Val Acc: 0.783505\n",
      "Epoch 26568 - Train Loss: 0.074839, Train Acc: 0.880769 | Val Loss: 0.110429, Val Acc: 0.783505\n",
      "Epoch 26569 - Train Loss: 0.074838, Train Acc: 0.880769 | Val Loss: 0.110429, Val Acc: 0.783505\n",
      "Epoch 26570 - Train Loss: 0.074836, Train Acc: 0.880769 | Val Loss: 0.110429, Val Acc: 0.783505\n",
      "Epoch 26571 - Train Loss: 0.074835, Train Acc: 0.880769 | Val Loss: 0.110428, Val Acc: 0.783505\n",
      "Epoch 26572 - Train Loss: 0.074833, Train Acc: 0.880769 | Val Loss: 0.110428, Val Acc: 0.783505\n",
      "Epoch 26573 - Train Loss: 0.074832, Train Acc: 0.880769 | Val Loss: 0.110427, Val Acc: 0.783505\n",
      "Epoch 26574 - Train Loss: 0.074830, Train Acc: 0.880769 | Val Loss: 0.110427, Val Acc: 0.783505\n",
      "Epoch 26575 - Train Loss: 0.074829, Train Acc: 0.880769 | Val Loss: 0.110426, Val Acc: 0.783505\n",
      "Epoch 26576 - Train Loss: 0.074828, Train Acc: 0.880769 | Val Loss: 0.110426, Val Acc: 0.783505\n",
      "Epoch 26577 - Train Loss: 0.074826, Train Acc: 0.880769 | Val Loss: 0.110426, Val Acc: 0.783505\n",
      "Epoch 26578 - Train Loss: 0.074825, Train Acc: 0.880769 | Val Loss: 0.110425, Val Acc: 0.783505\n",
      "Epoch 26579 - Train Loss: 0.074823, Train Acc: 0.880769 | Val Loss: 0.110425, Val Acc: 0.783505\n",
      "Epoch 26580 - Train Loss: 0.074822, Train Acc: 0.880769 | Val Loss: 0.110424, Val Acc: 0.783505\n",
      "Epoch 26581 - Train Loss: 0.074820, Train Acc: 0.880769 | Val Loss: 0.110424, Val Acc: 0.783505\n",
      "Epoch 26582 - Train Loss: 0.074819, Train Acc: 0.880769 | Val Loss: 0.110423, Val Acc: 0.783505\n",
      "Epoch 26583 - Train Loss: 0.074818, Train Acc: 0.880769 | Val Loss: 0.110423, Val Acc: 0.783505\n",
      "Epoch 26584 - Train Loss: 0.074816, Train Acc: 0.880769 | Val Loss: 0.110422, Val Acc: 0.783505\n",
      "Epoch 26585 - Train Loss: 0.074815, Train Acc: 0.880769 | Val Loss: 0.110422, Val Acc: 0.783505\n",
      "Epoch 26586 - Train Loss: 0.074813, Train Acc: 0.880769 | Val Loss: 0.110422, Val Acc: 0.783505\n",
      "Epoch 26587 - Train Loss: 0.074812, Train Acc: 0.880769 | Val Loss: 0.110421, Val Acc: 0.783505\n",
      "Epoch 26588 - Train Loss: 0.074810, Train Acc: 0.880769 | Val Loss: 0.110421, Val Acc: 0.783505\n",
      "Epoch 26589 - Train Loss: 0.074809, Train Acc: 0.880769 | Val Loss: 0.110420, Val Acc: 0.783505\n",
      "Epoch 26590 - Train Loss: 0.074807, Train Acc: 0.880769 | Val Loss: 0.110420, Val Acc: 0.783505\n",
      "Epoch 26591 - Train Loss: 0.074806, Train Acc: 0.880769 | Val Loss: 0.110419, Val Acc: 0.783505\n",
      "Epoch 26592 - Train Loss: 0.074805, Train Acc: 0.880769 | Val Loss: 0.110419, Val Acc: 0.783505\n",
      "Epoch 26593 - Train Loss: 0.074803, Train Acc: 0.880769 | Val Loss: 0.110419, Val Acc: 0.783505\n",
      "Epoch 26594 - Train Loss: 0.074802, Train Acc: 0.880769 | Val Loss: 0.110418, Val Acc: 0.783505\n",
      "Epoch 26595 - Train Loss: 0.074800, Train Acc: 0.880769 | Val Loss: 0.110418, Val Acc: 0.783505\n",
      "Epoch 26596 - Train Loss: 0.074799, Train Acc: 0.880769 | Val Loss: 0.110417, Val Acc: 0.783505\n",
      "Epoch 26597 - Train Loss: 0.074797, Train Acc: 0.880769 | Val Loss: 0.110417, Val Acc: 0.783505\n",
      "Epoch 26598 - Train Loss: 0.074796, Train Acc: 0.880769 | Val Loss: 0.110416, Val Acc: 0.783505\n",
      "Epoch 26599 - Train Loss: 0.074794, Train Acc: 0.880769 | Val Loss: 0.110416, Val Acc: 0.783505\n",
      "Epoch 26600 - Train Loss: 0.074793, Train Acc: 0.880769 | Val Loss: 0.110416, Val Acc: 0.783505\n",
      "Epoch 26601 - Train Loss: 0.074792, Train Acc: 0.880769 | Val Loss: 0.110415, Val Acc: 0.783505\n",
      "Epoch 26602 - Train Loss: 0.074790, Train Acc: 0.880769 | Val Loss: 0.110415, Val Acc: 0.783505\n",
      "Epoch 26603 - Train Loss: 0.074789, Train Acc: 0.880769 | Val Loss: 0.110414, Val Acc: 0.783505\n",
      "Epoch 26604 - Train Loss: 0.074787, Train Acc: 0.880769 | Val Loss: 0.110414, Val Acc: 0.783505\n",
      "Epoch 26605 - Train Loss: 0.074786, Train Acc: 0.880769 | Val Loss: 0.110413, Val Acc: 0.783505\n",
      "Epoch 26606 - Train Loss: 0.074784, Train Acc: 0.880769 | Val Loss: 0.110413, Val Acc: 0.783505\n",
      "Epoch 26607 - Train Loss: 0.074783, Train Acc: 0.880769 | Val Loss: 0.110412, Val Acc: 0.783505\n",
      "Epoch 26608 - Train Loss: 0.074781, Train Acc: 0.880769 | Val Loss: 0.110412, Val Acc: 0.783505\n",
      "Epoch 26609 - Train Loss: 0.074780, Train Acc: 0.880769 | Val Loss: 0.110412, Val Acc: 0.783505\n",
      "Epoch 26610 - Train Loss: 0.074779, Train Acc: 0.880769 | Val Loss: 0.110411, Val Acc: 0.783505\n",
      "Epoch 26611 - Train Loss: 0.074777, Train Acc: 0.880769 | Val Loss: 0.110411, Val Acc: 0.783505\n",
      "Epoch 26612 - Train Loss: 0.074776, Train Acc: 0.880769 | Val Loss: 0.110410, Val Acc: 0.783505\n",
      "Epoch 26613 - Train Loss: 0.074774, Train Acc: 0.880769 | Val Loss: 0.110410, Val Acc: 0.783505\n",
      "Epoch 26614 - Train Loss: 0.074773, Train Acc: 0.880769 | Val Loss: 0.110409, Val Acc: 0.783505\n",
      "Epoch 26615 - Train Loss: 0.074771, Train Acc: 0.880769 | Val Loss: 0.110409, Val Acc: 0.783505\n",
      "Epoch 26616 - Train Loss: 0.074770, Train Acc: 0.880769 | Val Loss: 0.110409, Val Acc: 0.783505\n",
      "Epoch 26617 - Train Loss: 0.074768, Train Acc: 0.880769 | Val Loss: 0.110408, Val Acc: 0.783505\n",
      "Epoch 26618 - Train Loss: 0.074767, Train Acc: 0.880769 | Val Loss: 0.110408, Val Acc: 0.783505\n",
      "Epoch 26619 - Train Loss: 0.074766, Train Acc: 0.880769 | Val Loss: 0.110407, Val Acc: 0.783505\n",
      "Epoch 26620 - Train Loss: 0.074764, Train Acc: 0.880769 | Val Loss: 0.110407, Val Acc: 0.783505\n",
      "Epoch 26621 - Train Loss: 0.074763, Train Acc: 0.880769 | Val Loss: 0.110406, Val Acc: 0.783505\n",
      "Epoch 26622 - Train Loss: 0.074761, Train Acc: 0.880769 | Val Loss: 0.110406, Val Acc: 0.783505\n",
      "Epoch 26623 - Train Loss: 0.074760, Train Acc: 0.880769 | Val Loss: 0.110406, Val Acc: 0.783505\n",
      "Epoch 26624 - Train Loss: 0.074758, Train Acc: 0.880769 | Val Loss: 0.110405, Val Acc: 0.783505\n",
      "Epoch 26625 - Train Loss: 0.074757, Train Acc: 0.880769 | Val Loss: 0.110405, Val Acc: 0.783505\n",
      "Epoch 26626 - Train Loss: 0.074756, Train Acc: 0.880769 | Val Loss: 0.110404, Val Acc: 0.783505\n",
      "Epoch 26627 - Train Loss: 0.074754, Train Acc: 0.880769 | Val Loss: 0.110404, Val Acc: 0.783505\n",
      "Epoch 26628 - Train Loss: 0.074753, Train Acc: 0.880769 | Val Loss: 0.110403, Val Acc: 0.783505\n",
      "Epoch 26629 - Train Loss: 0.074751, Train Acc: 0.880769 | Val Loss: 0.110403, Val Acc: 0.783505\n",
      "Epoch 26630 - Train Loss: 0.074750, Train Acc: 0.880769 | Val Loss: 0.110403, Val Acc: 0.783505\n",
      "Epoch 26631 - Train Loss: 0.074748, Train Acc: 0.880769 | Val Loss: 0.110402, Val Acc: 0.783505\n",
      "Epoch 26632 - Train Loss: 0.074747, Train Acc: 0.880769 | Val Loss: 0.110402, Val Acc: 0.783505\n",
      "Epoch 26633 - Train Loss: 0.074745, Train Acc: 0.880769 | Val Loss: 0.110401, Val Acc: 0.783505\n",
      "Epoch 26634 - Train Loss: 0.074744, Train Acc: 0.880769 | Val Loss: 0.110401, Val Acc: 0.783505\n",
      "Epoch 26635 - Train Loss: 0.074743, Train Acc: 0.880769 | Val Loss: 0.110400, Val Acc: 0.783505\n",
      "Epoch 26636 - Train Loss: 0.074741, Train Acc: 0.880769 | Val Loss: 0.110400, Val Acc: 0.783505\n",
      "Epoch 26637 - Train Loss: 0.074740, Train Acc: 0.880769 | Val Loss: 0.110400, Val Acc: 0.783505\n",
      "Epoch 26638 - Train Loss: 0.074738, Train Acc: 0.880769 | Val Loss: 0.110399, Val Acc: 0.783505\n",
      "Epoch 26639 - Train Loss: 0.074737, Train Acc: 0.880769 | Val Loss: 0.110399, Val Acc: 0.783505\n",
      "Epoch 26640 - Train Loss: 0.074735, Train Acc: 0.880769 | Val Loss: 0.110398, Val Acc: 0.783505\n",
      "Epoch 26641 - Train Loss: 0.074734, Train Acc: 0.880769 | Val Loss: 0.110398, Val Acc: 0.783505\n",
      "Epoch 26642 - Train Loss: 0.074733, Train Acc: 0.880769 | Val Loss: 0.110397, Val Acc: 0.783505\n",
      "Epoch 26643 - Train Loss: 0.074731, Train Acc: 0.880769 | Val Loss: 0.110397, Val Acc: 0.783505\n",
      "Epoch 26644 - Train Loss: 0.074730, Train Acc: 0.880769 | Val Loss: 0.110397, Val Acc: 0.783505\n",
      "Epoch 26645 - Train Loss: 0.074728, Train Acc: 0.880769 | Val Loss: 0.110396, Val Acc: 0.783505\n",
      "Epoch 26646 - Train Loss: 0.074727, Train Acc: 0.880769 | Val Loss: 0.110396, Val Acc: 0.783505\n",
      "Epoch 26647 - Train Loss: 0.074725, Train Acc: 0.880769 | Val Loss: 0.110395, Val Acc: 0.783505\n",
      "Epoch 26648 - Train Loss: 0.074724, Train Acc: 0.880769 | Val Loss: 0.110395, Val Acc: 0.783505\n",
      "Epoch 26649 - Train Loss: 0.074722, Train Acc: 0.880769 | Val Loss: 0.110394, Val Acc: 0.783505\n",
      "Epoch 26650 - Train Loss: 0.074721, Train Acc: 0.880769 | Val Loss: 0.110394, Val Acc: 0.783505\n",
      "Epoch 26651 - Train Loss: 0.074720, Train Acc: 0.880769 | Val Loss: 0.110393, Val Acc: 0.783505\n",
      "Epoch 26652 - Train Loss: 0.074718, Train Acc: 0.880769 | Val Loss: 0.110393, Val Acc: 0.783505\n",
      "Epoch 26653 - Train Loss: 0.074717, Train Acc: 0.880769 | Val Loss: 0.110393, Val Acc: 0.783505\n",
      "Epoch 26654 - Train Loss: 0.074715, Train Acc: 0.880769 | Val Loss: 0.110392, Val Acc: 0.783505\n",
      "Epoch 26655 - Train Loss: 0.074714, Train Acc: 0.880769 | Val Loss: 0.110392, Val Acc: 0.783505\n",
      "Epoch 26656 - Train Loss: 0.074712, Train Acc: 0.880769 | Val Loss: 0.110391, Val Acc: 0.783505\n",
      "Epoch 26657 - Train Loss: 0.074711, Train Acc: 0.880769 | Val Loss: 0.110391, Val Acc: 0.783505\n",
      "Epoch 26658 - Train Loss: 0.074710, Train Acc: 0.880769 | Val Loss: 0.110390, Val Acc: 0.783505\n",
      "Epoch 26659 - Train Loss: 0.074708, Train Acc: 0.880769 | Val Loss: 0.110390, Val Acc: 0.783505\n",
      "Epoch 26660 - Train Loss: 0.074707, Train Acc: 0.880769 | Val Loss: 0.110390, Val Acc: 0.783505\n",
      "Epoch 26661 - Train Loss: 0.074705, Train Acc: 0.880769 | Val Loss: 0.110389, Val Acc: 0.783505\n",
      "Epoch 26662 - Train Loss: 0.074704, Train Acc: 0.880769 | Val Loss: 0.110389, Val Acc: 0.783505\n",
      "Epoch 26663 - Train Loss: 0.074702, Train Acc: 0.880769 | Val Loss: 0.110388, Val Acc: 0.783505\n",
      "Epoch 26664 - Train Loss: 0.074701, Train Acc: 0.880769 | Val Loss: 0.110388, Val Acc: 0.783505\n",
      "Epoch 26665 - Train Loss: 0.074699, Train Acc: 0.880769 | Val Loss: 0.110387, Val Acc: 0.783505\n",
      "Epoch 26666 - Train Loss: 0.074698, Train Acc: 0.880769 | Val Loss: 0.110387, Val Acc: 0.783505\n",
      "Epoch 26667 - Train Loss: 0.074697, Train Acc: 0.880769 | Val Loss: 0.110387, Val Acc: 0.783505\n",
      "Epoch 26668 - Train Loss: 0.074695, Train Acc: 0.880769 | Val Loss: 0.110386, Val Acc: 0.783505\n",
      "Epoch 26669 - Train Loss: 0.074694, Train Acc: 0.880769 | Val Loss: 0.110386, Val Acc: 0.783505\n",
      "Epoch 26670 - Train Loss: 0.074692, Train Acc: 0.880769 | Val Loss: 0.110385, Val Acc: 0.783505\n",
      "Epoch 26671 - Train Loss: 0.074691, Train Acc: 0.880769 | Val Loss: 0.110385, Val Acc: 0.783505\n",
      "Epoch 26672 - Train Loss: 0.074689, Train Acc: 0.880769 | Val Loss: 0.110384, Val Acc: 0.783505\n",
      "Epoch 26673 - Train Loss: 0.074688, Train Acc: 0.880769 | Val Loss: 0.110384, Val Acc: 0.783505\n",
      "Epoch 26674 - Train Loss: 0.074687, Train Acc: 0.880769 | Val Loss: 0.110384, Val Acc: 0.783505\n",
      "Epoch 26675 - Train Loss: 0.074685, Train Acc: 0.880769 | Val Loss: 0.110383, Val Acc: 0.783505\n",
      "Epoch 26676 - Train Loss: 0.074684, Train Acc: 0.880769 | Val Loss: 0.110383, Val Acc: 0.783505\n",
      "Epoch 26677 - Train Loss: 0.074682, Train Acc: 0.880769 | Val Loss: 0.110382, Val Acc: 0.783505\n",
      "Epoch 26678 - Train Loss: 0.074681, Train Acc: 0.880769 | Val Loss: 0.110382, Val Acc: 0.783505\n",
      "Epoch 26679 - Train Loss: 0.074679, Train Acc: 0.880769 | Val Loss: 0.110381, Val Acc: 0.783505\n",
      "Epoch 26680 - Train Loss: 0.074678, Train Acc: 0.880769 | Val Loss: 0.110381, Val Acc: 0.783505\n",
      "Epoch 26681 - Train Loss: 0.074676, Train Acc: 0.880769 | Val Loss: 0.110381, Val Acc: 0.783505\n",
      "Epoch 26682 - Train Loss: 0.074675, Train Acc: 0.880769 | Val Loss: 0.110380, Val Acc: 0.783505\n",
      "Epoch 26683 - Train Loss: 0.074674, Train Acc: 0.880769 | Val Loss: 0.110380, Val Acc: 0.783505\n",
      "Epoch 26684 - Train Loss: 0.074672, Train Acc: 0.880769 | Val Loss: 0.110379, Val Acc: 0.783505\n",
      "Epoch 26685 - Train Loss: 0.074671, Train Acc: 0.880769 | Val Loss: 0.110379, Val Acc: 0.783505\n",
      "Epoch 26686 - Train Loss: 0.074669, Train Acc: 0.880769 | Val Loss: 0.110378, Val Acc: 0.783505\n",
      "Epoch 26687 - Train Loss: 0.074668, Train Acc: 0.880769 | Val Loss: 0.110378, Val Acc: 0.783505\n",
      "Epoch 26688 - Train Loss: 0.074666, Train Acc: 0.880769 | Val Loss: 0.110378, Val Acc: 0.783505\n",
      "Epoch 26689 - Train Loss: 0.074665, Train Acc: 0.880769 | Val Loss: 0.110377, Val Acc: 0.783505\n",
      "Epoch 26690 - Train Loss: 0.074664, Train Acc: 0.880769 | Val Loss: 0.110377, Val Acc: 0.783505\n",
      "Epoch 26691 - Train Loss: 0.074662, Train Acc: 0.880769 | Val Loss: 0.110376, Val Acc: 0.783505\n",
      "Epoch 26692 - Train Loss: 0.074661, Train Acc: 0.880769 | Val Loss: 0.110376, Val Acc: 0.783505\n",
      "Epoch 26693 - Train Loss: 0.074659, Train Acc: 0.880769 | Val Loss: 0.110375, Val Acc: 0.783505\n",
      "Epoch 26694 - Train Loss: 0.074658, Train Acc: 0.880769 | Val Loss: 0.110375, Val Acc: 0.783505\n",
      "Epoch 26695 - Train Loss: 0.074656, Train Acc: 0.880769 | Val Loss: 0.110375, Val Acc: 0.783505\n",
      "Epoch 26696 - Train Loss: 0.074655, Train Acc: 0.880769 | Val Loss: 0.110374, Val Acc: 0.783505\n",
      "Epoch 26697 - Train Loss: 0.074654, Train Acc: 0.880769 | Val Loss: 0.110374, Val Acc: 0.783505\n",
      "Epoch 26698 - Train Loss: 0.074652, Train Acc: 0.880769 | Val Loss: 0.110373, Val Acc: 0.783505\n",
      "Epoch 26699 - Train Loss: 0.074651, Train Acc: 0.880769 | Val Loss: 0.110373, Val Acc: 0.783505\n",
      "Epoch 26700 - Train Loss: 0.074649, Train Acc: 0.880769 | Val Loss: 0.110372, Val Acc: 0.783505\n",
      "Epoch 26701 - Train Loss: 0.074648, Train Acc: 0.880769 | Val Loss: 0.110372, Val Acc: 0.783505\n",
      "Epoch 26702 - Train Loss: 0.074646, Train Acc: 0.880769 | Val Loss: 0.110372, Val Acc: 0.783505\n",
      "Epoch 26703 - Train Loss: 0.074645, Train Acc: 0.880769 | Val Loss: 0.110371, Val Acc: 0.783505\n",
      "Epoch 26704 - Train Loss: 0.074644, Train Acc: 0.880769 | Val Loss: 0.110371, Val Acc: 0.783505\n",
      "Epoch 26705 - Train Loss: 0.074642, Train Acc: 0.880769 | Val Loss: 0.110370, Val Acc: 0.783505\n",
      "Epoch 26706 - Train Loss: 0.074641, Train Acc: 0.880769 | Val Loss: 0.110370, Val Acc: 0.783505\n",
      "Epoch 26707 - Train Loss: 0.074639, Train Acc: 0.880769 | Val Loss: 0.110369, Val Acc: 0.783505\n",
      "Epoch 26708 - Train Loss: 0.074638, Train Acc: 0.880769 | Val Loss: 0.110369, Val Acc: 0.783505\n",
      "Epoch 26709 - Train Loss: 0.074636, Train Acc: 0.880769 | Val Loss: 0.110369, Val Acc: 0.783505\n",
      "Epoch 26710 - Train Loss: 0.074635, Train Acc: 0.880769 | Val Loss: 0.110368, Val Acc: 0.783505\n",
      "Epoch 26711 - Train Loss: 0.074633, Train Acc: 0.880769 | Val Loss: 0.110368, Val Acc: 0.783505\n",
      "Epoch 26712 - Train Loss: 0.074632, Train Acc: 0.880769 | Val Loss: 0.110367, Val Acc: 0.783505\n",
      "Epoch 26713 - Train Loss: 0.074631, Train Acc: 0.880769 | Val Loss: 0.110367, Val Acc: 0.783505\n",
      "Epoch 26714 - Train Loss: 0.074629, Train Acc: 0.880769 | Val Loss: 0.110366, Val Acc: 0.783505\n",
      "Epoch 26715 - Train Loss: 0.074628, Train Acc: 0.880769 | Val Loss: 0.110366, Val Acc: 0.783505\n",
      "Epoch 26716 - Train Loss: 0.074626, Train Acc: 0.880769 | Val Loss: 0.110366, Val Acc: 0.783505\n",
      "Epoch 26717 - Train Loss: 0.074625, Train Acc: 0.880769 | Val Loss: 0.110365, Val Acc: 0.783505\n",
      "Epoch 26718 - Train Loss: 0.074623, Train Acc: 0.880769 | Val Loss: 0.110365, Val Acc: 0.783505\n",
      "Epoch 26719 - Train Loss: 0.074622, Train Acc: 0.880769 | Val Loss: 0.110364, Val Acc: 0.783505\n",
      "Epoch 26720 - Train Loss: 0.074621, Train Acc: 0.880769 | Val Loss: 0.110364, Val Acc: 0.783505\n",
      "Epoch 26721 - Train Loss: 0.074619, Train Acc: 0.880769 | Val Loss: 0.110364, Val Acc: 0.783505\n",
      "Epoch 26722 - Train Loss: 0.074618, Train Acc: 0.880769 | Val Loss: 0.110363, Val Acc: 0.783505\n",
      "Epoch 26723 - Train Loss: 0.074616, Train Acc: 0.880769 | Val Loss: 0.110363, Val Acc: 0.783505\n",
      "Epoch 26724 - Train Loss: 0.074615, Train Acc: 0.880769 | Val Loss: 0.110362, Val Acc: 0.783505\n",
      "Epoch 26725 - Train Loss: 0.074613, Train Acc: 0.880769 | Val Loss: 0.110362, Val Acc: 0.783505\n",
      "Epoch 26726 - Train Loss: 0.074612, Train Acc: 0.880769 | Val Loss: 0.110361, Val Acc: 0.783505\n",
      "Epoch 26727 - Train Loss: 0.074611, Train Acc: 0.880769 | Val Loss: 0.110361, Val Acc: 0.783505\n",
      "Epoch 26728 - Train Loss: 0.074609, Train Acc: 0.880769 | Val Loss: 0.110361, Val Acc: 0.783505\n",
      "Epoch 26729 - Train Loss: 0.074608, Train Acc: 0.880769 | Val Loss: 0.110360, Val Acc: 0.783505\n",
      "Epoch 26730 - Train Loss: 0.074606, Train Acc: 0.880769 | Val Loss: 0.110360, Val Acc: 0.783505\n",
      "Epoch 26731 - Train Loss: 0.074605, Train Acc: 0.880769 | Val Loss: 0.110359, Val Acc: 0.783505\n",
      "Epoch 26732 - Train Loss: 0.074603, Train Acc: 0.880769 | Val Loss: 0.110359, Val Acc: 0.783505\n",
      "Epoch 26733 - Train Loss: 0.074602, Train Acc: 0.880769 | Val Loss: 0.110358, Val Acc: 0.783505\n",
      "Epoch 26734 - Train Loss: 0.074601, Train Acc: 0.880769 | Val Loss: 0.110358, Val Acc: 0.783505\n",
      "Epoch 26735 - Train Loss: 0.074599, Train Acc: 0.880769 | Val Loss: 0.110358, Val Acc: 0.783505\n",
      "Epoch 26736 - Train Loss: 0.074598, Train Acc: 0.880769 | Val Loss: 0.110357, Val Acc: 0.783505\n",
      "Epoch 26737 - Train Loss: 0.074596, Train Acc: 0.880769 | Val Loss: 0.110357, Val Acc: 0.783505\n",
      "Epoch 26738 - Train Loss: 0.074595, Train Acc: 0.880769 | Val Loss: 0.110356, Val Acc: 0.783505\n",
      "Epoch 26739 - Train Loss: 0.074593, Train Acc: 0.880769 | Val Loss: 0.110356, Val Acc: 0.783505\n",
      "Epoch 26740 - Train Loss: 0.074592, Train Acc: 0.880769 | Val Loss: 0.110355, Val Acc: 0.783505\n",
      "Epoch 26741 - Train Loss: 0.074591, Train Acc: 0.880769 | Val Loss: 0.110355, Val Acc: 0.783505\n",
      "Epoch 26742 - Train Loss: 0.074589, Train Acc: 0.880769 | Val Loss: 0.110355, Val Acc: 0.783505\n",
      "Epoch 26743 - Train Loss: 0.074588, Train Acc: 0.880769 | Val Loss: 0.110354, Val Acc: 0.783505\n",
      "Epoch 26744 - Train Loss: 0.074586, Train Acc: 0.880769 | Val Loss: 0.110354, Val Acc: 0.783505\n",
      "Epoch 26745 - Train Loss: 0.074585, Train Acc: 0.880769 | Val Loss: 0.110353, Val Acc: 0.783505\n",
      "Epoch 26746 - Train Loss: 0.074583, Train Acc: 0.880769 | Val Loss: 0.110353, Val Acc: 0.783505\n",
      "Epoch 26747 - Train Loss: 0.074582, Train Acc: 0.880769 | Val Loss: 0.110352, Val Acc: 0.783505\n",
      "Epoch 26748 - Train Loss: 0.074581, Train Acc: 0.880769 | Val Loss: 0.110352, Val Acc: 0.783505\n",
      "Epoch 26749 - Train Loss: 0.074579, Train Acc: 0.880769 | Val Loss: 0.110352, Val Acc: 0.783505\n",
      "Epoch 26750 - Train Loss: 0.074578, Train Acc: 0.880769 | Val Loss: 0.110351, Val Acc: 0.783505\n",
      "Epoch 26751 - Train Loss: 0.074576, Train Acc: 0.880769 | Val Loss: 0.110351, Val Acc: 0.783505\n",
      "Epoch 26752 - Train Loss: 0.074575, Train Acc: 0.880769 | Val Loss: 0.110350, Val Acc: 0.783505\n",
      "Epoch 26753 - Train Loss: 0.074573, Train Acc: 0.880769 | Val Loss: 0.110350, Val Acc: 0.783505\n",
      "Epoch 26754 - Train Loss: 0.074572, Train Acc: 0.880769 | Val Loss: 0.110349, Val Acc: 0.783505\n",
      "Epoch 26755 - Train Loss: 0.074571, Train Acc: 0.880769 | Val Loss: 0.110349, Val Acc: 0.783505\n",
      "Epoch 26756 - Train Loss: 0.074569, Train Acc: 0.880769 | Val Loss: 0.110349, Val Acc: 0.783505\n",
      "Epoch 26757 - Train Loss: 0.074568, Train Acc: 0.880769 | Val Loss: 0.110348, Val Acc: 0.783505\n",
      "Epoch 26758 - Train Loss: 0.074566, Train Acc: 0.880769 | Val Loss: 0.110348, Val Acc: 0.783505\n",
      "Epoch 26759 - Train Loss: 0.074565, Train Acc: 0.880769 | Val Loss: 0.110347, Val Acc: 0.783505\n",
      "Epoch 26760 - Train Loss: 0.074563, Train Acc: 0.880769 | Val Loss: 0.110347, Val Acc: 0.783505\n",
      "Epoch 26761 - Train Loss: 0.074562, Train Acc: 0.880769 | Val Loss: 0.110347, Val Acc: 0.783505\n",
      "Epoch 26762 - Train Loss: 0.074561, Train Acc: 0.880769 | Val Loss: 0.110346, Val Acc: 0.783505\n",
      "Epoch 26763 - Train Loss: 0.074559, Train Acc: 0.880769 | Val Loss: 0.110346, Val Acc: 0.783505\n",
      "Epoch 26764 - Train Loss: 0.074558, Train Acc: 0.880769 | Val Loss: 0.110345, Val Acc: 0.783505\n",
      "Epoch 26765 - Train Loss: 0.074556, Train Acc: 0.880769 | Val Loss: 0.110345, Val Acc: 0.783505\n",
      "Epoch 26766 - Train Loss: 0.074555, Train Acc: 0.880769 | Val Loss: 0.110344, Val Acc: 0.783505\n",
      "Epoch 26767 - Train Loss: 0.074553, Train Acc: 0.880769 | Val Loss: 0.110344, Val Acc: 0.783505\n",
      "Epoch 26768 - Train Loss: 0.074552, Train Acc: 0.880769 | Val Loss: 0.110344, Val Acc: 0.783505\n",
      "Epoch 26769 - Train Loss: 0.074551, Train Acc: 0.880769 | Val Loss: 0.110343, Val Acc: 0.783505\n",
      "Epoch 26770 - Train Loss: 0.074549, Train Acc: 0.880769 | Val Loss: 0.110343, Val Acc: 0.783505\n",
      "Epoch 26771 - Train Loss: 0.074548, Train Acc: 0.880769 | Val Loss: 0.110342, Val Acc: 0.783505\n",
      "Epoch 26772 - Train Loss: 0.074546, Train Acc: 0.880769 | Val Loss: 0.110342, Val Acc: 0.783505\n",
      "Epoch 26773 - Train Loss: 0.074545, Train Acc: 0.880769 | Val Loss: 0.110341, Val Acc: 0.783505\n",
      "Epoch 26774 - Train Loss: 0.074543, Train Acc: 0.880769 | Val Loss: 0.110341, Val Acc: 0.783505\n",
      "Epoch 26775 - Train Loss: 0.074542, Train Acc: 0.880769 | Val Loss: 0.110341, Val Acc: 0.783505\n",
      "Epoch 26776 - Train Loss: 0.074541, Train Acc: 0.880769 | Val Loss: 0.110340, Val Acc: 0.783505\n",
      "Epoch 26777 - Train Loss: 0.074539, Train Acc: 0.880769 | Val Loss: 0.110340, Val Acc: 0.783505\n",
      "Epoch 26778 - Train Loss: 0.074538, Train Acc: 0.880769 | Val Loss: 0.110339, Val Acc: 0.783505\n",
      "Epoch 26779 - Train Loss: 0.074536, Train Acc: 0.880769 | Val Loss: 0.110339, Val Acc: 0.783505\n",
      "Epoch 26780 - Train Loss: 0.074535, Train Acc: 0.880769 | Val Loss: 0.110338, Val Acc: 0.783505\n",
      "Epoch 26781 - Train Loss: 0.074533, Train Acc: 0.880769 | Val Loss: 0.110338, Val Acc: 0.783505\n",
      "Epoch 26782 - Train Loss: 0.074532, Train Acc: 0.880769 | Val Loss: 0.110338, Val Acc: 0.783505\n",
      "Epoch 26783 - Train Loss: 0.074531, Train Acc: 0.880769 | Val Loss: 0.110337, Val Acc: 0.783505\n",
      "Epoch 26784 - Train Loss: 0.074529, Train Acc: 0.882051 | Val Loss: 0.110337, Val Acc: 0.783505\n",
      "Epoch 26785 - Train Loss: 0.074528, Train Acc: 0.882051 | Val Loss: 0.110336, Val Acc: 0.783505\n",
      "Epoch 26786 - Train Loss: 0.074526, Train Acc: 0.882051 | Val Loss: 0.110336, Val Acc: 0.783505\n",
      "Epoch 26787 - Train Loss: 0.074525, Train Acc: 0.882051 | Val Loss: 0.110336, Val Acc: 0.783505\n",
      "Epoch 26788 - Train Loss: 0.074523, Train Acc: 0.882051 | Val Loss: 0.110335, Val Acc: 0.783505\n",
      "Epoch 26789 - Train Loss: 0.074522, Train Acc: 0.882051 | Val Loss: 0.110335, Val Acc: 0.783505\n",
      "Epoch 26790 - Train Loss: 0.074521, Train Acc: 0.882051 | Val Loss: 0.110334, Val Acc: 0.783505\n",
      "Epoch 26791 - Train Loss: 0.074519, Train Acc: 0.882051 | Val Loss: 0.110334, Val Acc: 0.783505\n",
      "Epoch 26792 - Train Loss: 0.074518, Train Acc: 0.882051 | Val Loss: 0.110333, Val Acc: 0.783505\n",
      "Epoch 26793 - Train Loss: 0.074516, Train Acc: 0.882051 | Val Loss: 0.110333, Val Acc: 0.783505\n",
      "Epoch 26794 - Train Loss: 0.074515, Train Acc: 0.882051 | Val Loss: 0.110333, Val Acc: 0.783505\n",
      "Epoch 26795 - Train Loss: 0.074513, Train Acc: 0.882051 | Val Loss: 0.110332, Val Acc: 0.783505\n",
      "Epoch 26796 - Train Loss: 0.074512, Train Acc: 0.882051 | Val Loss: 0.110332, Val Acc: 0.783505\n",
      "Epoch 26797 - Train Loss: 0.074511, Train Acc: 0.882051 | Val Loss: 0.110331, Val Acc: 0.783505\n",
      "Epoch 26798 - Train Loss: 0.074509, Train Acc: 0.882051 | Val Loss: 0.110331, Val Acc: 0.783505\n",
      "Epoch 26799 - Train Loss: 0.074508, Train Acc: 0.882051 | Val Loss: 0.110330, Val Acc: 0.783505\n",
      "Epoch 26800 - Train Loss: 0.074506, Train Acc: 0.882051 | Val Loss: 0.110330, Val Acc: 0.783505\n",
      "Epoch 26801 - Train Loss: 0.074505, Train Acc: 0.882051 | Val Loss: 0.110330, Val Acc: 0.783505\n",
      "Epoch 26802 - Train Loss: 0.074503, Train Acc: 0.882051 | Val Loss: 0.110329, Val Acc: 0.783505\n",
      "Epoch 26803 - Train Loss: 0.074502, Train Acc: 0.882051 | Val Loss: 0.110329, Val Acc: 0.783505\n",
      "Epoch 26804 - Train Loss: 0.074501, Train Acc: 0.882051 | Val Loss: 0.110328, Val Acc: 0.783505\n",
      "Epoch 26805 - Train Loss: 0.074499, Train Acc: 0.882051 | Val Loss: 0.110328, Val Acc: 0.783505\n",
      "Epoch 26806 - Train Loss: 0.074498, Train Acc: 0.882051 | Val Loss: 0.110328, Val Acc: 0.783505\n",
      "Epoch 26807 - Train Loss: 0.074496, Train Acc: 0.882051 | Val Loss: 0.110327, Val Acc: 0.783505\n",
      "Epoch 26808 - Train Loss: 0.074495, Train Acc: 0.882051 | Val Loss: 0.110327, Val Acc: 0.783505\n",
      "Epoch 26809 - Train Loss: 0.074493, Train Acc: 0.882051 | Val Loss: 0.110326, Val Acc: 0.783505\n",
      "Epoch 26810 - Train Loss: 0.074492, Train Acc: 0.882051 | Val Loss: 0.110326, Val Acc: 0.783505\n",
      "Epoch 26811 - Train Loss: 0.074491, Train Acc: 0.882051 | Val Loss: 0.110325, Val Acc: 0.783505\n",
      "Epoch 26812 - Train Loss: 0.074489, Train Acc: 0.882051 | Val Loss: 0.110325, Val Acc: 0.783505\n",
      "Epoch 26813 - Train Loss: 0.074488, Train Acc: 0.882051 | Val Loss: 0.110325, Val Acc: 0.783505\n",
      "Epoch 26814 - Train Loss: 0.074486, Train Acc: 0.882051 | Val Loss: 0.110324, Val Acc: 0.783505\n",
      "Epoch 26815 - Train Loss: 0.074485, Train Acc: 0.882051 | Val Loss: 0.110324, Val Acc: 0.783505\n",
      "Epoch 26816 - Train Loss: 0.074483, Train Acc: 0.882051 | Val Loss: 0.110323, Val Acc: 0.783505\n",
      "Epoch 26817 - Train Loss: 0.074482, Train Acc: 0.882051 | Val Loss: 0.110323, Val Acc: 0.783505\n",
      "Epoch 26818 - Train Loss: 0.074481, Train Acc: 0.882051 | Val Loss: 0.110322, Val Acc: 0.783505\n",
      "Epoch 26819 - Train Loss: 0.074479, Train Acc: 0.882051 | Val Loss: 0.110322, Val Acc: 0.783505\n",
      "Epoch 26820 - Train Loss: 0.074478, Train Acc: 0.882051 | Val Loss: 0.110322, Val Acc: 0.783505\n",
      "Epoch 26821 - Train Loss: 0.074476, Train Acc: 0.882051 | Val Loss: 0.110321, Val Acc: 0.783505\n",
      "Epoch 26822 - Train Loss: 0.074475, Train Acc: 0.882051 | Val Loss: 0.110321, Val Acc: 0.783505\n",
      "Epoch 26823 - Train Loss: 0.074473, Train Acc: 0.882051 | Val Loss: 0.110320, Val Acc: 0.783505\n",
      "Epoch 26824 - Train Loss: 0.074472, Train Acc: 0.882051 | Val Loss: 0.110320, Val Acc: 0.783505\n",
      "Epoch 26825 - Train Loss: 0.074471, Train Acc: 0.882051 | Val Loss: 0.110320, Val Acc: 0.783505\n",
      "Epoch 26826 - Train Loss: 0.074469, Train Acc: 0.882051 | Val Loss: 0.110319, Val Acc: 0.783505\n",
      "Epoch 26827 - Train Loss: 0.074468, Train Acc: 0.882051 | Val Loss: 0.110319, Val Acc: 0.783505\n",
      "Epoch 26828 - Train Loss: 0.074466, Train Acc: 0.882051 | Val Loss: 0.110318, Val Acc: 0.783505\n",
      "Epoch 26829 - Train Loss: 0.074465, Train Acc: 0.882051 | Val Loss: 0.110318, Val Acc: 0.783505\n",
      "Epoch 26830 - Train Loss: 0.074464, Train Acc: 0.882051 | Val Loss: 0.110317, Val Acc: 0.783505\n",
      "Epoch 26831 - Train Loss: 0.074462, Train Acc: 0.882051 | Val Loss: 0.110317, Val Acc: 0.783505\n",
      "Epoch 26832 - Train Loss: 0.074461, Train Acc: 0.882051 | Val Loss: 0.110317, Val Acc: 0.783505\n",
      "Epoch 26833 - Train Loss: 0.074459, Train Acc: 0.882051 | Val Loss: 0.110316, Val Acc: 0.783505\n",
      "Epoch 26834 - Train Loss: 0.074458, Train Acc: 0.882051 | Val Loss: 0.110316, Val Acc: 0.783505\n",
      "Epoch 26835 - Train Loss: 0.074456, Train Acc: 0.882051 | Val Loss: 0.110315, Val Acc: 0.783505\n",
      "Epoch 26836 - Train Loss: 0.074455, Train Acc: 0.882051 | Val Loss: 0.110315, Val Acc: 0.783505\n",
      "Epoch 26837 - Train Loss: 0.074454, Train Acc: 0.882051 | Val Loss: 0.110314, Val Acc: 0.783505\n",
      "Epoch 26838 - Train Loss: 0.074452, Train Acc: 0.882051 | Val Loss: 0.110314, Val Acc: 0.783505\n",
      "Epoch 26839 - Train Loss: 0.074451, Train Acc: 0.882051 | Val Loss: 0.110314, Val Acc: 0.783505\n",
      "Epoch 26840 - Train Loss: 0.074449, Train Acc: 0.882051 | Val Loss: 0.110313, Val Acc: 0.783505\n",
      "Epoch 26841 - Train Loss: 0.074448, Train Acc: 0.882051 | Val Loss: 0.110313, Val Acc: 0.783505\n",
      "Epoch 26842 - Train Loss: 0.074446, Train Acc: 0.882051 | Val Loss: 0.110312, Val Acc: 0.783505\n",
      "Epoch 26843 - Train Loss: 0.074445, Train Acc: 0.882051 | Val Loss: 0.110312, Val Acc: 0.783505\n",
      "Epoch 26844 - Train Loss: 0.074444, Train Acc: 0.882051 | Val Loss: 0.110312, Val Acc: 0.783505\n",
      "Epoch 26845 - Train Loss: 0.074442, Train Acc: 0.882051 | Val Loss: 0.110311, Val Acc: 0.783505\n",
      "Epoch 26846 - Train Loss: 0.074441, Train Acc: 0.882051 | Val Loss: 0.110311, Val Acc: 0.783505\n",
      "Epoch 26847 - Train Loss: 0.074439, Train Acc: 0.882051 | Val Loss: 0.110310, Val Acc: 0.783505\n",
      "Epoch 26848 - Train Loss: 0.074438, Train Acc: 0.882051 | Val Loss: 0.110310, Val Acc: 0.783505\n",
      "Epoch 26849 - Train Loss: 0.074436, Train Acc: 0.882051 | Val Loss: 0.110309, Val Acc: 0.783505\n",
      "Epoch 26850 - Train Loss: 0.074435, Train Acc: 0.882051 | Val Loss: 0.110309, Val Acc: 0.783505\n",
      "Epoch 26851 - Train Loss: 0.074434, Train Acc: 0.882051 | Val Loss: 0.110309, Val Acc: 0.783505\n",
      "Epoch 26852 - Train Loss: 0.074432, Train Acc: 0.882051 | Val Loss: 0.110308, Val Acc: 0.783505\n",
      "Epoch 26853 - Train Loss: 0.074431, Train Acc: 0.882051 | Val Loss: 0.110308, Val Acc: 0.783505\n",
      "Epoch 26854 - Train Loss: 0.074429, Train Acc: 0.882051 | Val Loss: 0.110307, Val Acc: 0.783505\n",
      "Epoch 26855 - Train Loss: 0.074428, Train Acc: 0.882051 | Val Loss: 0.110307, Val Acc: 0.783505\n",
      "Epoch 26856 - Train Loss: 0.074427, Train Acc: 0.882051 | Val Loss: 0.110307, Val Acc: 0.783505\n",
      "Epoch 26857 - Train Loss: 0.074425, Train Acc: 0.882051 | Val Loss: 0.110306, Val Acc: 0.783505\n",
      "Epoch 26858 - Train Loss: 0.074424, Train Acc: 0.882051 | Val Loss: 0.110306, Val Acc: 0.783505\n",
      "Epoch 26859 - Train Loss: 0.074422, Train Acc: 0.882051 | Val Loss: 0.110305, Val Acc: 0.783505\n",
      "Epoch 26860 - Train Loss: 0.074421, Train Acc: 0.882051 | Val Loss: 0.110305, Val Acc: 0.783505\n",
      "Epoch 26861 - Train Loss: 0.074419, Train Acc: 0.882051 | Val Loss: 0.110304, Val Acc: 0.783505\n",
      "Epoch 26862 - Train Loss: 0.074418, Train Acc: 0.882051 | Val Loss: 0.110304, Val Acc: 0.783505\n",
      "Epoch 26863 - Train Loss: 0.074417, Train Acc: 0.882051 | Val Loss: 0.110304, Val Acc: 0.783505\n",
      "Epoch 26864 - Train Loss: 0.074415, Train Acc: 0.882051 | Val Loss: 0.110303, Val Acc: 0.783505\n",
      "Epoch 26865 - Train Loss: 0.074414, Train Acc: 0.882051 | Val Loss: 0.110303, Val Acc: 0.783505\n",
      "Epoch 26866 - Train Loss: 0.074412, Train Acc: 0.882051 | Val Loss: 0.110302, Val Acc: 0.783505\n",
      "Epoch 26867 - Train Loss: 0.074411, Train Acc: 0.882051 | Val Loss: 0.110302, Val Acc: 0.783505\n",
      "Epoch 26868 - Train Loss: 0.074409, Train Acc: 0.882051 | Val Loss: 0.110302, Val Acc: 0.783505\n",
      "Epoch 26869 - Train Loss: 0.074408, Train Acc: 0.882051 | Val Loss: 0.110301, Val Acc: 0.783505\n",
      "Epoch 26870 - Train Loss: 0.074407, Train Acc: 0.882051 | Val Loss: 0.110301, Val Acc: 0.783505\n",
      "Epoch 26871 - Train Loss: 0.074405, Train Acc: 0.882051 | Val Loss: 0.110300, Val Acc: 0.783505\n",
      "Epoch 26872 - Train Loss: 0.074404, Train Acc: 0.882051 | Val Loss: 0.110300, Val Acc: 0.783505\n",
      "Epoch 26873 - Train Loss: 0.074402, Train Acc: 0.882051 | Val Loss: 0.110299, Val Acc: 0.783505\n",
      "Epoch 26874 - Train Loss: 0.074401, Train Acc: 0.882051 | Val Loss: 0.110299, Val Acc: 0.783505\n",
      "Epoch 26875 - Train Loss: 0.074400, Train Acc: 0.882051 | Val Loss: 0.110299, Val Acc: 0.783505\n",
      "Epoch 26876 - Train Loss: 0.074398, Train Acc: 0.882051 | Val Loss: 0.110298, Val Acc: 0.783505\n",
      "Epoch 26877 - Train Loss: 0.074397, Train Acc: 0.882051 | Val Loss: 0.110298, Val Acc: 0.783505\n",
      "Epoch 26878 - Train Loss: 0.074395, Train Acc: 0.882051 | Val Loss: 0.110297, Val Acc: 0.783505\n",
      "Epoch 26879 - Train Loss: 0.074394, Train Acc: 0.882051 | Val Loss: 0.110297, Val Acc: 0.783505\n",
      "Epoch 26880 - Train Loss: 0.074392, Train Acc: 0.882051 | Val Loss: 0.110297, Val Acc: 0.783505\n",
      "Epoch 26881 - Train Loss: 0.074391, Train Acc: 0.882051 | Val Loss: 0.110296, Val Acc: 0.783505\n",
      "Epoch 26882 - Train Loss: 0.074390, Train Acc: 0.882051 | Val Loss: 0.110296, Val Acc: 0.783505\n",
      "Epoch 26883 - Train Loss: 0.074388, Train Acc: 0.882051 | Val Loss: 0.110295, Val Acc: 0.783505\n",
      "Epoch 26884 - Train Loss: 0.074387, Train Acc: 0.882051 | Val Loss: 0.110295, Val Acc: 0.783505\n",
      "Epoch 26885 - Train Loss: 0.074385, Train Acc: 0.882051 | Val Loss: 0.110294, Val Acc: 0.783505\n",
      "Epoch 26886 - Train Loss: 0.074384, Train Acc: 0.882051 | Val Loss: 0.110294, Val Acc: 0.783505\n",
      "Epoch 26887 - Train Loss: 0.074382, Train Acc: 0.882051 | Val Loss: 0.110294, Val Acc: 0.783505\n",
      "Epoch 26888 - Train Loss: 0.074381, Train Acc: 0.882051 | Val Loss: 0.110293, Val Acc: 0.783505\n",
      "Epoch 26889 - Train Loss: 0.074380, Train Acc: 0.882051 | Val Loss: 0.110293, Val Acc: 0.783505\n",
      "Epoch 26890 - Train Loss: 0.074378, Train Acc: 0.882051 | Val Loss: 0.110292, Val Acc: 0.783505\n",
      "Epoch 26891 - Train Loss: 0.074377, Train Acc: 0.882051 | Val Loss: 0.110292, Val Acc: 0.783505\n",
      "Epoch 26892 - Train Loss: 0.074375, Train Acc: 0.882051 | Val Loss: 0.110292, Val Acc: 0.783505\n",
      "Epoch 26893 - Train Loss: 0.074374, Train Acc: 0.882051 | Val Loss: 0.110291, Val Acc: 0.783505\n",
      "Epoch 26894 - Train Loss: 0.074373, Train Acc: 0.882051 | Val Loss: 0.110291, Val Acc: 0.783505\n",
      "Epoch 26895 - Train Loss: 0.074371, Train Acc: 0.882051 | Val Loss: 0.110290, Val Acc: 0.783505\n",
      "Epoch 26896 - Train Loss: 0.074370, Train Acc: 0.882051 | Val Loss: 0.110290, Val Acc: 0.783505\n",
      "Epoch 26897 - Train Loss: 0.074368, Train Acc: 0.882051 | Val Loss: 0.110289, Val Acc: 0.783505\n",
      "Epoch 26898 - Train Loss: 0.074367, Train Acc: 0.882051 | Val Loss: 0.110289, Val Acc: 0.783505\n",
      "Epoch 26899 - Train Loss: 0.074365, Train Acc: 0.882051 | Val Loss: 0.110289, Val Acc: 0.783505\n",
      "Epoch 26900 - Train Loss: 0.074364, Train Acc: 0.882051 | Val Loss: 0.110288, Val Acc: 0.783505\n",
      "Epoch 26901 - Train Loss: 0.074363, Train Acc: 0.882051 | Val Loss: 0.110288, Val Acc: 0.783505\n",
      "Epoch 26902 - Train Loss: 0.074361, Train Acc: 0.882051 | Val Loss: 0.110287, Val Acc: 0.783505\n",
      "Epoch 26903 - Train Loss: 0.074360, Train Acc: 0.882051 | Val Loss: 0.110287, Val Acc: 0.783505\n",
      "Epoch 26904 - Train Loss: 0.074358, Train Acc: 0.882051 | Val Loss: 0.110287, Val Acc: 0.783505\n",
      "Epoch 26905 - Train Loss: 0.074357, Train Acc: 0.882051 | Val Loss: 0.110286, Val Acc: 0.783505\n",
      "Epoch 26906 - Train Loss: 0.074356, Train Acc: 0.882051 | Val Loss: 0.110286, Val Acc: 0.783505\n",
      "Epoch 26907 - Train Loss: 0.074354, Train Acc: 0.882051 | Val Loss: 0.110285, Val Acc: 0.783505\n",
      "Epoch 26908 - Train Loss: 0.074353, Train Acc: 0.882051 | Val Loss: 0.110285, Val Acc: 0.783505\n",
      "Epoch 26909 - Train Loss: 0.074351, Train Acc: 0.882051 | Val Loss: 0.110284, Val Acc: 0.783505\n",
      "Epoch 26910 - Train Loss: 0.074350, Train Acc: 0.882051 | Val Loss: 0.110284, Val Acc: 0.783505\n",
      "Epoch 26911 - Train Loss: 0.074348, Train Acc: 0.882051 | Val Loss: 0.110284, Val Acc: 0.783505\n",
      "Epoch 26912 - Train Loss: 0.074347, Train Acc: 0.882051 | Val Loss: 0.110283, Val Acc: 0.783505\n",
      "Epoch 26913 - Train Loss: 0.074346, Train Acc: 0.882051 | Val Loss: 0.110283, Val Acc: 0.783505\n",
      "Epoch 26914 - Train Loss: 0.074344, Train Acc: 0.882051 | Val Loss: 0.110282, Val Acc: 0.783505\n",
      "Epoch 26915 - Train Loss: 0.074343, Train Acc: 0.882051 | Val Loss: 0.110282, Val Acc: 0.783505\n",
      "Epoch 26916 - Train Loss: 0.074341, Train Acc: 0.882051 | Val Loss: 0.110282, Val Acc: 0.783505\n",
      "Epoch 26917 - Train Loss: 0.074340, Train Acc: 0.882051 | Val Loss: 0.110281, Val Acc: 0.783505\n",
      "Epoch 26918 - Train Loss: 0.074339, Train Acc: 0.882051 | Val Loss: 0.110281, Val Acc: 0.783505\n",
      "Epoch 26919 - Train Loss: 0.074337, Train Acc: 0.882051 | Val Loss: 0.110280, Val Acc: 0.783505\n",
      "Epoch 26920 - Train Loss: 0.074336, Train Acc: 0.882051 | Val Loss: 0.110280, Val Acc: 0.783505\n",
      "Epoch 26921 - Train Loss: 0.074334, Train Acc: 0.882051 | Val Loss: 0.110280, Val Acc: 0.783505\n",
      "Epoch 26922 - Train Loss: 0.074333, Train Acc: 0.882051 | Val Loss: 0.110279, Val Acc: 0.783505\n",
      "Epoch 26923 - Train Loss: 0.074331, Train Acc: 0.882051 | Val Loss: 0.110279, Val Acc: 0.783505\n",
      "Epoch 26924 - Train Loss: 0.074330, Train Acc: 0.882051 | Val Loss: 0.110278, Val Acc: 0.783505\n",
      "Epoch 26925 - Train Loss: 0.074329, Train Acc: 0.882051 | Val Loss: 0.110278, Val Acc: 0.783505\n",
      "Epoch 26926 - Train Loss: 0.074327, Train Acc: 0.882051 | Val Loss: 0.110277, Val Acc: 0.783505\n",
      "Epoch 26927 - Train Loss: 0.074326, Train Acc: 0.882051 | Val Loss: 0.110277, Val Acc: 0.783505\n",
      "Epoch 26928 - Train Loss: 0.074324, Train Acc: 0.882051 | Val Loss: 0.110277, Val Acc: 0.783505\n",
      "Epoch 26929 - Train Loss: 0.074323, Train Acc: 0.882051 | Val Loss: 0.110276, Val Acc: 0.783505\n",
      "Epoch 26930 - Train Loss: 0.074322, Train Acc: 0.882051 | Val Loss: 0.110276, Val Acc: 0.783505\n",
      "Epoch 26931 - Train Loss: 0.074320, Train Acc: 0.882051 | Val Loss: 0.110275, Val Acc: 0.783505\n",
      "Epoch 26932 - Train Loss: 0.074319, Train Acc: 0.882051 | Val Loss: 0.110275, Val Acc: 0.783505\n",
      "Epoch 26933 - Train Loss: 0.074317, Train Acc: 0.882051 | Val Loss: 0.110275, Val Acc: 0.783505\n",
      "Epoch 26934 - Train Loss: 0.074316, Train Acc: 0.882051 | Val Loss: 0.110274, Val Acc: 0.783505\n",
      "Epoch 26935 - Train Loss: 0.074314, Train Acc: 0.882051 | Val Loss: 0.110274, Val Acc: 0.783505\n",
      "Epoch 26936 - Train Loss: 0.074313, Train Acc: 0.882051 | Val Loss: 0.110273, Val Acc: 0.783505\n",
      "Epoch 26937 - Train Loss: 0.074312, Train Acc: 0.882051 | Val Loss: 0.110273, Val Acc: 0.783505\n",
      "Epoch 26938 - Train Loss: 0.074310, Train Acc: 0.882051 | Val Loss: 0.110272, Val Acc: 0.783505\n",
      "Epoch 26939 - Train Loss: 0.074309, Train Acc: 0.882051 | Val Loss: 0.110272, Val Acc: 0.783505\n",
      "Epoch 26940 - Train Loss: 0.074307, Train Acc: 0.882051 | Val Loss: 0.110272, Val Acc: 0.783505\n",
      "Epoch 26941 - Train Loss: 0.074306, Train Acc: 0.882051 | Val Loss: 0.110271, Val Acc: 0.783505\n",
      "Epoch 26942 - Train Loss: 0.074305, Train Acc: 0.882051 | Val Loss: 0.110271, Val Acc: 0.783505\n",
      "Epoch 26943 - Train Loss: 0.074303, Train Acc: 0.882051 | Val Loss: 0.110270, Val Acc: 0.783505\n",
      "Epoch 26944 - Train Loss: 0.074302, Train Acc: 0.882051 | Val Loss: 0.110270, Val Acc: 0.783505\n",
      "Epoch 26945 - Train Loss: 0.074300, Train Acc: 0.882051 | Val Loss: 0.110270, Val Acc: 0.783505\n",
      "Epoch 26946 - Train Loss: 0.074299, Train Acc: 0.882051 | Val Loss: 0.110269, Val Acc: 0.783505\n",
      "Epoch 26947 - Train Loss: 0.074297, Train Acc: 0.882051 | Val Loss: 0.110269, Val Acc: 0.783505\n",
      "Epoch 26948 - Train Loss: 0.074296, Train Acc: 0.882051 | Val Loss: 0.110268, Val Acc: 0.783505\n",
      "Epoch 26949 - Train Loss: 0.074295, Train Acc: 0.882051 | Val Loss: 0.110268, Val Acc: 0.783505\n",
      "Epoch 26950 - Train Loss: 0.074293, Train Acc: 0.882051 | Val Loss: 0.110268, Val Acc: 0.783505\n",
      "Epoch 26951 - Train Loss: 0.074292, Train Acc: 0.882051 | Val Loss: 0.110267, Val Acc: 0.783505\n",
      "Epoch 26952 - Train Loss: 0.074290, Train Acc: 0.882051 | Val Loss: 0.110267, Val Acc: 0.783505\n",
      "Epoch 26953 - Train Loss: 0.074289, Train Acc: 0.883333 | Val Loss: 0.110266, Val Acc: 0.783505\n",
      "Epoch 26954 - Train Loss: 0.074288, Train Acc: 0.883333 | Val Loss: 0.110266, Val Acc: 0.783505\n",
      "Epoch 26955 - Train Loss: 0.074286, Train Acc: 0.883333 | Val Loss: 0.110265, Val Acc: 0.783505\n",
      "Epoch 26956 - Train Loss: 0.074285, Train Acc: 0.883333 | Val Loss: 0.110265, Val Acc: 0.783505\n",
      "Epoch 26957 - Train Loss: 0.074283, Train Acc: 0.883333 | Val Loss: 0.110265, Val Acc: 0.783505\n",
      "Epoch 26958 - Train Loss: 0.074282, Train Acc: 0.883333 | Val Loss: 0.110264, Val Acc: 0.783505\n",
      "Epoch 26959 - Train Loss: 0.074281, Train Acc: 0.883333 | Val Loss: 0.110264, Val Acc: 0.783505\n",
      "Epoch 26960 - Train Loss: 0.074279, Train Acc: 0.883333 | Val Loss: 0.110263, Val Acc: 0.783505\n",
      "Epoch 26961 - Train Loss: 0.074278, Train Acc: 0.883333 | Val Loss: 0.110263, Val Acc: 0.783505\n",
      "Epoch 26962 - Train Loss: 0.074276, Train Acc: 0.883333 | Val Loss: 0.110263, Val Acc: 0.783505\n",
      "Epoch 26963 - Train Loss: 0.074275, Train Acc: 0.883333 | Val Loss: 0.110262, Val Acc: 0.783505\n",
      "Epoch 26964 - Train Loss: 0.074273, Train Acc: 0.883333 | Val Loss: 0.110262, Val Acc: 0.783505\n",
      "Epoch 26965 - Train Loss: 0.074272, Train Acc: 0.883333 | Val Loss: 0.110261, Val Acc: 0.783505\n",
      "Epoch 26966 - Train Loss: 0.074271, Train Acc: 0.883333 | Val Loss: 0.110261, Val Acc: 0.783505\n",
      "Epoch 26967 - Train Loss: 0.074269, Train Acc: 0.883333 | Val Loss: 0.110261, Val Acc: 0.783505\n",
      "Epoch 26968 - Train Loss: 0.074268, Train Acc: 0.883333 | Val Loss: 0.110260, Val Acc: 0.783505\n",
      "Epoch 26969 - Train Loss: 0.074266, Train Acc: 0.883333 | Val Loss: 0.110260, Val Acc: 0.783505\n",
      "Epoch 26970 - Train Loss: 0.074265, Train Acc: 0.883333 | Val Loss: 0.110259, Val Acc: 0.783505\n",
      "Epoch 26971 - Train Loss: 0.074264, Train Acc: 0.883333 | Val Loss: 0.110259, Val Acc: 0.783505\n",
      "Epoch 26972 - Train Loss: 0.074262, Train Acc: 0.883333 | Val Loss: 0.110258, Val Acc: 0.783505\n",
      "Epoch 26973 - Train Loss: 0.074261, Train Acc: 0.883333 | Val Loss: 0.110258, Val Acc: 0.783505\n",
      "Epoch 26974 - Train Loss: 0.074259, Train Acc: 0.883333 | Val Loss: 0.110258, Val Acc: 0.783505\n",
      "Epoch 26975 - Train Loss: 0.074258, Train Acc: 0.883333 | Val Loss: 0.110257, Val Acc: 0.783505\n",
      "Epoch 26976 - Train Loss: 0.074256, Train Acc: 0.883333 | Val Loss: 0.110257, Val Acc: 0.783505\n",
      "Epoch 26977 - Train Loss: 0.074255, Train Acc: 0.883333 | Val Loss: 0.110256, Val Acc: 0.783505\n",
      "Epoch 26978 - Train Loss: 0.074254, Train Acc: 0.883333 | Val Loss: 0.110256, Val Acc: 0.783505\n",
      "Epoch 26979 - Train Loss: 0.074252, Train Acc: 0.883333 | Val Loss: 0.110256, Val Acc: 0.783505\n",
      "Epoch 26980 - Train Loss: 0.074251, Train Acc: 0.883333 | Val Loss: 0.110255, Val Acc: 0.783505\n",
      "Epoch 26981 - Train Loss: 0.074249, Train Acc: 0.883333 | Val Loss: 0.110255, Val Acc: 0.783505\n",
      "Epoch 26982 - Train Loss: 0.074248, Train Acc: 0.883333 | Val Loss: 0.110254, Val Acc: 0.783505\n",
      "Epoch 26983 - Train Loss: 0.074247, Train Acc: 0.883333 | Val Loss: 0.110254, Val Acc: 0.783505\n",
      "Epoch 26984 - Train Loss: 0.074245, Train Acc: 0.883333 | Val Loss: 0.110254, Val Acc: 0.783505\n",
      "Epoch 26985 - Train Loss: 0.074244, Train Acc: 0.883333 | Val Loss: 0.110253, Val Acc: 0.783505\n",
      "Epoch 26986 - Train Loss: 0.074242, Train Acc: 0.883333 | Val Loss: 0.110253, Val Acc: 0.783505\n",
      "Epoch 26987 - Train Loss: 0.074241, Train Acc: 0.883333 | Val Loss: 0.110252, Val Acc: 0.783505\n",
      "Epoch 26988 - Train Loss: 0.074240, Train Acc: 0.883333 | Val Loss: 0.110252, Val Acc: 0.783505\n",
      "Epoch 26989 - Train Loss: 0.074238, Train Acc: 0.883333 | Val Loss: 0.110252, Val Acc: 0.783505\n",
      "Epoch 26990 - Train Loss: 0.074237, Train Acc: 0.883333 | Val Loss: 0.110251, Val Acc: 0.783505\n",
      "Epoch 26991 - Train Loss: 0.074235, Train Acc: 0.883333 | Val Loss: 0.110251, Val Acc: 0.783505\n",
      "Epoch 26992 - Train Loss: 0.074234, Train Acc: 0.883333 | Val Loss: 0.110250, Val Acc: 0.783505\n",
      "Epoch 26993 - Train Loss: 0.074232, Train Acc: 0.883333 | Val Loss: 0.110250, Val Acc: 0.783505\n",
      "Epoch 26994 - Train Loss: 0.074231, Train Acc: 0.883333 | Val Loss: 0.110249, Val Acc: 0.783505\n",
      "Epoch 26995 - Train Loss: 0.074230, Train Acc: 0.883333 | Val Loss: 0.110249, Val Acc: 0.783505\n",
      "Epoch 26996 - Train Loss: 0.074228, Train Acc: 0.883333 | Val Loss: 0.110249, Val Acc: 0.783505\n",
      "Epoch 26997 - Train Loss: 0.074227, Train Acc: 0.883333 | Val Loss: 0.110248, Val Acc: 0.783505\n",
      "Epoch 26998 - Train Loss: 0.074225, Train Acc: 0.883333 | Val Loss: 0.110248, Val Acc: 0.783505\n",
      "Epoch 26999 - Train Loss: 0.074224, Train Acc: 0.883333 | Val Loss: 0.110247, Val Acc: 0.783505\n",
      "Epoch 27000 - Train Loss: 0.074223, Train Acc: 0.883333 | Val Loss: 0.110247, Val Acc: 0.783505\n",
      "Epoch 27001 - Train Loss: 0.074221, Train Acc: 0.883333 | Val Loss: 0.110247, Val Acc: 0.783505\n",
      "Epoch 27002 - Train Loss: 0.074220, Train Acc: 0.883333 | Val Loss: 0.110246, Val Acc: 0.783505\n",
      "Epoch 27003 - Train Loss: 0.074218, Train Acc: 0.883333 | Val Loss: 0.110246, Val Acc: 0.783505\n",
      "Epoch 27004 - Train Loss: 0.074217, Train Acc: 0.883333 | Val Loss: 0.110245, Val Acc: 0.783505\n",
      "Epoch 27005 - Train Loss: 0.074216, Train Acc: 0.883333 | Val Loss: 0.110245, Val Acc: 0.783505\n",
      "Epoch 27006 - Train Loss: 0.074214, Train Acc: 0.883333 | Val Loss: 0.110245, Val Acc: 0.783505\n",
      "Epoch 27007 - Train Loss: 0.074213, Train Acc: 0.883333 | Val Loss: 0.110244, Val Acc: 0.783505\n",
      "Epoch 27008 - Train Loss: 0.074211, Train Acc: 0.883333 | Val Loss: 0.110244, Val Acc: 0.783505\n",
      "Epoch 27009 - Train Loss: 0.074210, Train Acc: 0.883333 | Val Loss: 0.110243, Val Acc: 0.783505\n",
      "Epoch 27010 - Train Loss: 0.074208, Train Acc: 0.883333 | Val Loss: 0.110243, Val Acc: 0.783505\n",
      "Epoch 27011 - Train Loss: 0.074207, Train Acc: 0.883333 | Val Loss: 0.110242, Val Acc: 0.783505\n",
      "Epoch 27012 - Train Loss: 0.074206, Train Acc: 0.883333 | Val Loss: 0.110242, Val Acc: 0.783505\n",
      "Epoch 27013 - Train Loss: 0.074204, Train Acc: 0.883333 | Val Loss: 0.110242, Val Acc: 0.783505\n",
      "Epoch 27014 - Train Loss: 0.074203, Train Acc: 0.883333 | Val Loss: 0.110241, Val Acc: 0.783505\n",
      "Epoch 27015 - Train Loss: 0.074201, Train Acc: 0.883333 | Val Loss: 0.110241, Val Acc: 0.783505\n",
      "Epoch 27016 - Train Loss: 0.074200, Train Acc: 0.883333 | Val Loss: 0.110240, Val Acc: 0.783505\n",
      "Epoch 27017 - Train Loss: 0.074199, Train Acc: 0.883333 | Val Loss: 0.110240, Val Acc: 0.783505\n",
      "Epoch 27018 - Train Loss: 0.074197, Train Acc: 0.883333 | Val Loss: 0.110240, Val Acc: 0.783505\n",
      "Epoch 27019 - Train Loss: 0.074196, Train Acc: 0.883333 | Val Loss: 0.110239, Val Acc: 0.783505\n",
      "Epoch 27020 - Train Loss: 0.074194, Train Acc: 0.883333 | Val Loss: 0.110239, Val Acc: 0.783505\n",
      "Epoch 27021 - Train Loss: 0.074193, Train Acc: 0.883333 | Val Loss: 0.110238, Val Acc: 0.783505\n",
      "Epoch 27022 - Train Loss: 0.074192, Train Acc: 0.883333 | Val Loss: 0.110238, Val Acc: 0.783505\n",
      "Epoch 27023 - Train Loss: 0.074190, Train Acc: 0.883333 | Val Loss: 0.110238, Val Acc: 0.783505\n",
      "Epoch 27024 - Train Loss: 0.074189, Train Acc: 0.883333 | Val Loss: 0.110237, Val Acc: 0.783505\n",
      "Epoch 27025 - Train Loss: 0.074187, Train Acc: 0.883333 | Val Loss: 0.110237, Val Acc: 0.783505\n",
      "Epoch 27026 - Train Loss: 0.074186, Train Acc: 0.883333 | Val Loss: 0.110236, Val Acc: 0.783505\n",
      "Epoch 27027 - Train Loss: 0.074185, Train Acc: 0.883333 | Val Loss: 0.110236, Val Acc: 0.783505\n",
      "Epoch 27028 - Train Loss: 0.074183, Train Acc: 0.883333 | Val Loss: 0.110236, Val Acc: 0.783505\n",
      "Epoch 27029 - Train Loss: 0.074182, Train Acc: 0.883333 | Val Loss: 0.110235, Val Acc: 0.783505\n",
      "Epoch 27030 - Train Loss: 0.074180, Train Acc: 0.883333 | Val Loss: 0.110235, Val Acc: 0.783505\n",
      "Epoch 27031 - Train Loss: 0.074179, Train Acc: 0.883333 | Val Loss: 0.110234, Val Acc: 0.783505\n",
      "Epoch 27032 - Train Loss: 0.074177, Train Acc: 0.883333 | Val Loss: 0.110234, Val Acc: 0.783505\n",
      "Epoch 27033 - Train Loss: 0.074176, Train Acc: 0.883333 | Val Loss: 0.110233, Val Acc: 0.783505\n",
      "Epoch 27034 - Train Loss: 0.074175, Train Acc: 0.883333 | Val Loss: 0.110233, Val Acc: 0.783505\n",
      "Epoch 27035 - Train Loss: 0.074173, Train Acc: 0.883333 | Val Loss: 0.110233, Val Acc: 0.783505\n",
      "Epoch 27036 - Train Loss: 0.074172, Train Acc: 0.883333 | Val Loss: 0.110232, Val Acc: 0.783505\n",
      "Epoch 27037 - Train Loss: 0.074170, Train Acc: 0.883333 | Val Loss: 0.110232, Val Acc: 0.783505\n",
      "Epoch 27038 - Train Loss: 0.074169, Train Acc: 0.883333 | Val Loss: 0.110231, Val Acc: 0.783505\n",
      "Epoch 27039 - Train Loss: 0.074168, Train Acc: 0.883333 | Val Loss: 0.110231, Val Acc: 0.783505\n",
      "Epoch 27040 - Train Loss: 0.074166, Train Acc: 0.883333 | Val Loss: 0.110231, Val Acc: 0.783505\n",
      "Epoch 27041 - Train Loss: 0.074165, Train Acc: 0.883333 | Val Loss: 0.110230, Val Acc: 0.783505\n",
      "Epoch 27042 - Train Loss: 0.074163, Train Acc: 0.883333 | Val Loss: 0.110230, Val Acc: 0.783505\n",
      "Epoch 27043 - Train Loss: 0.074162, Train Acc: 0.883333 | Val Loss: 0.110229, Val Acc: 0.783505\n",
      "Epoch 27044 - Train Loss: 0.074161, Train Acc: 0.883333 | Val Loss: 0.110229, Val Acc: 0.783505\n",
      "Epoch 27045 - Train Loss: 0.074159, Train Acc: 0.883333 | Val Loss: 0.110229, Val Acc: 0.783505\n",
      "Epoch 27046 - Train Loss: 0.074158, Train Acc: 0.883333 | Val Loss: 0.110228, Val Acc: 0.783505\n",
      "Epoch 27047 - Train Loss: 0.074156, Train Acc: 0.883333 | Val Loss: 0.110228, Val Acc: 0.783505\n",
      "Epoch 27048 - Train Loss: 0.074155, Train Acc: 0.883333 | Val Loss: 0.110227, Val Acc: 0.783505\n",
      "Epoch 27049 - Train Loss: 0.074154, Train Acc: 0.883333 | Val Loss: 0.110227, Val Acc: 0.783505\n",
      "Epoch 27050 - Train Loss: 0.074152, Train Acc: 0.883333 | Val Loss: 0.110227, Val Acc: 0.783505\n",
      "Epoch 27051 - Train Loss: 0.074151, Train Acc: 0.883333 | Val Loss: 0.110226, Val Acc: 0.783505\n",
      "Epoch 27052 - Train Loss: 0.074149, Train Acc: 0.883333 | Val Loss: 0.110226, Val Acc: 0.783505\n",
      "Epoch 27053 - Train Loss: 0.074148, Train Acc: 0.883333 | Val Loss: 0.110225, Val Acc: 0.783505\n",
      "Epoch 27054 - Train Loss: 0.074147, Train Acc: 0.883333 | Val Loss: 0.110225, Val Acc: 0.783505\n",
      "Epoch 27055 - Train Loss: 0.074145, Train Acc: 0.883333 | Val Loss: 0.110225, Val Acc: 0.783505\n",
      "Epoch 27056 - Train Loss: 0.074144, Train Acc: 0.883333 | Val Loss: 0.110224, Val Acc: 0.783505\n",
      "Epoch 27057 - Train Loss: 0.074142, Train Acc: 0.883333 | Val Loss: 0.110224, Val Acc: 0.783505\n",
      "Epoch 27058 - Train Loss: 0.074141, Train Acc: 0.883333 | Val Loss: 0.110223, Val Acc: 0.783505\n",
      "Epoch 27059 - Train Loss: 0.074139, Train Acc: 0.883333 | Val Loss: 0.110223, Val Acc: 0.783505\n",
      "Epoch 27060 - Train Loss: 0.074138, Train Acc: 0.883333 | Val Loss: 0.110222, Val Acc: 0.783505\n",
      "Epoch 27061 - Train Loss: 0.074137, Train Acc: 0.883333 | Val Loss: 0.110222, Val Acc: 0.783505\n",
      "Epoch 27062 - Train Loss: 0.074135, Train Acc: 0.883333 | Val Loss: 0.110222, Val Acc: 0.783505\n",
      "Epoch 27063 - Train Loss: 0.074134, Train Acc: 0.883333 | Val Loss: 0.110221, Val Acc: 0.783505\n",
      "Epoch 27064 - Train Loss: 0.074132, Train Acc: 0.883333 | Val Loss: 0.110221, Val Acc: 0.783505\n",
      "Epoch 27065 - Train Loss: 0.074131, Train Acc: 0.883333 | Val Loss: 0.110220, Val Acc: 0.783505\n",
      "Epoch 27066 - Train Loss: 0.074130, Train Acc: 0.883333 | Val Loss: 0.110220, Val Acc: 0.783505\n",
      "Epoch 27067 - Train Loss: 0.074128, Train Acc: 0.883333 | Val Loss: 0.110220, Val Acc: 0.783505\n",
      "Epoch 27068 - Train Loss: 0.074127, Train Acc: 0.883333 | Val Loss: 0.110219, Val Acc: 0.783505\n",
      "Epoch 27069 - Train Loss: 0.074125, Train Acc: 0.883333 | Val Loss: 0.110219, Val Acc: 0.783505\n",
      "Epoch 27070 - Train Loss: 0.074124, Train Acc: 0.883333 | Val Loss: 0.110218, Val Acc: 0.783505\n",
      "Epoch 27071 - Train Loss: 0.074123, Train Acc: 0.883333 | Val Loss: 0.110218, Val Acc: 0.783505\n",
      "Epoch 27072 - Train Loss: 0.074121, Train Acc: 0.883333 | Val Loss: 0.110218, Val Acc: 0.783505\n",
      "Epoch 27073 - Train Loss: 0.074120, Train Acc: 0.883333 | Val Loss: 0.110217, Val Acc: 0.783505\n",
      "Epoch 27074 - Train Loss: 0.074118, Train Acc: 0.883333 | Val Loss: 0.110217, Val Acc: 0.783505\n",
      "Epoch 27075 - Train Loss: 0.074117, Train Acc: 0.883333 | Val Loss: 0.110216, Val Acc: 0.783505\n",
      "Epoch 27076 - Train Loss: 0.074116, Train Acc: 0.883333 | Val Loss: 0.110216, Val Acc: 0.783505\n",
      "Epoch 27077 - Train Loss: 0.074114, Train Acc: 0.883333 | Val Loss: 0.110216, Val Acc: 0.783505\n",
      "Epoch 27078 - Train Loss: 0.074113, Train Acc: 0.883333 | Val Loss: 0.110215, Val Acc: 0.783505\n",
      "Epoch 27079 - Train Loss: 0.074111, Train Acc: 0.883333 | Val Loss: 0.110215, Val Acc: 0.783505\n",
      "Epoch 27080 - Train Loss: 0.074110, Train Acc: 0.883333 | Val Loss: 0.110214, Val Acc: 0.783505\n",
      "Epoch 27081 - Train Loss: 0.074109, Train Acc: 0.883333 | Val Loss: 0.110214, Val Acc: 0.783505\n",
      "Epoch 27082 - Train Loss: 0.074107, Train Acc: 0.883333 | Val Loss: 0.110214, Val Acc: 0.783505\n",
      "Epoch 27083 - Train Loss: 0.074106, Train Acc: 0.883333 | Val Loss: 0.110213, Val Acc: 0.783505\n",
      "Epoch 27084 - Train Loss: 0.074104, Train Acc: 0.883333 | Val Loss: 0.110213, Val Acc: 0.783505\n",
      "Epoch 27085 - Train Loss: 0.074103, Train Acc: 0.883333 | Val Loss: 0.110212, Val Acc: 0.783505\n",
      "Epoch 27086 - Train Loss: 0.074102, Train Acc: 0.883333 | Val Loss: 0.110212, Val Acc: 0.783505\n",
      "Epoch 27087 - Train Loss: 0.074100, Train Acc: 0.883333 | Val Loss: 0.110212, Val Acc: 0.783505\n",
      "Epoch 27088 - Train Loss: 0.074099, Train Acc: 0.883333 | Val Loss: 0.110211, Val Acc: 0.783505\n",
      "Epoch 27089 - Train Loss: 0.074097, Train Acc: 0.883333 | Val Loss: 0.110211, Val Acc: 0.783505\n",
      "Epoch 27090 - Train Loss: 0.074096, Train Acc: 0.883333 | Val Loss: 0.110210, Val Acc: 0.783505\n",
      "Epoch 27091 - Train Loss: 0.074094, Train Acc: 0.883333 | Val Loss: 0.110210, Val Acc: 0.783505\n",
      "Epoch 27092 - Train Loss: 0.074093, Train Acc: 0.883333 | Val Loss: 0.110210, Val Acc: 0.783505\n",
      "Epoch 27093 - Train Loss: 0.074092, Train Acc: 0.883333 | Val Loss: 0.110209, Val Acc: 0.783505\n",
      "Epoch 27094 - Train Loss: 0.074090, Train Acc: 0.883333 | Val Loss: 0.110209, Val Acc: 0.783505\n",
      "Epoch 27095 - Train Loss: 0.074089, Train Acc: 0.883333 | Val Loss: 0.110208, Val Acc: 0.783505\n",
      "Epoch 27096 - Train Loss: 0.074087, Train Acc: 0.883333 | Val Loss: 0.110208, Val Acc: 0.783505\n",
      "Epoch 27097 - Train Loss: 0.074086, Train Acc: 0.883333 | Val Loss: 0.110208, Val Acc: 0.783505\n",
      "Epoch 27098 - Train Loss: 0.074085, Train Acc: 0.883333 | Val Loss: 0.110207, Val Acc: 0.783505\n",
      "Epoch 27099 - Train Loss: 0.074083, Train Acc: 0.883333 | Val Loss: 0.110207, Val Acc: 0.783505\n",
      "Epoch 27100 - Train Loss: 0.074082, Train Acc: 0.883333 | Val Loss: 0.110206, Val Acc: 0.783505\n",
      "Epoch 27101 - Train Loss: 0.074080, Train Acc: 0.883333 | Val Loss: 0.110206, Val Acc: 0.783505\n",
      "Epoch 27102 - Train Loss: 0.074079, Train Acc: 0.883333 | Val Loss: 0.110205, Val Acc: 0.783505\n",
      "Epoch 27103 - Train Loss: 0.074078, Train Acc: 0.883333 | Val Loss: 0.110205, Val Acc: 0.783505\n",
      "Epoch 27104 - Train Loss: 0.074076, Train Acc: 0.883333 | Val Loss: 0.110205, Val Acc: 0.783505\n",
      "Epoch 27105 - Train Loss: 0.074075, Train Acc: 0.883333 | Val Loss: 0.110204, Val Acc: 0.783505\n",
      "Epoch 27106 - Train Loss: 0.074073, Train Acc: 0.883333 | Val Loss: 0.110204, Val Acc: 0.783505\n",
      "Epoch 27107 - Train Loss: 0.074072, Train Acc: 0.883333 | Val Loss: 0.110203, Val Acc: 0.783505\n",
      "Epoch 27108 - Train Loss: 0.074071, Train Acc: 0.883333 | Val Loss: 0.110203, Val Acc: 0.783505\n",
      "Epoch 27109 - Train Loss: 0.074069, Train Acc: 0.883333 | Val Loss: 0.110203, Val Acc: 0.783505\n",
      "Epoch 27110 - Train Loss: 0.074068, Train Acc: 0.883333 | Val Loss: 0.110202, Val Acc: 0.783505\n",
      "Epoch 27111 - Train Loss: 0.074066, Train Acc: 0.883333 | Val Loss: 0.110202, Val Acc: 0.783505\n",
      "Epoch 27112 - Train Loss: 0.074065, Train Acc: 0.883333 | Val Loss: 0.110201, Val Acc: 0.783505\n",
      "Epoch 27113 - Train Loss: 0.074064, Train Acc: 0.883333 | Val Loss: 0.110201, Val Acc: 0.783505\n",
      "Epoch 27114 - Train Loss: 0.074062, Train Acc: 0.883333 | Val Loss: 0.110201, Val Acc: 0.783505\n",
      "Epoch 27115 - Train Loss: 0.074061, Train Acc: 0.883333 | Val Loss: 0.110200, Val Acc: 0.783505\n",
      "Epoch 27116 - Train Loss: 0.074059, Train Acc: 0.883333 | Val Loss: 0.110200, Val Acc: 0.783505\n",
      "Epoch 27117 - Train Loss: 0.074058, Train Acc: 0.883333 | Val Loss: 0.110199, Val Acc: 0.783505\n",
      "Epoch 27118 - Train Loss: 0.074057, Train Acc: 0.883333 | Val Loss: 0.110199, Val Acc: 0.783505\n",
      "Epoch 27119 - Train Loss: 0.074055, Train Acc: 0.883333 | Val Loss: 0.110199, Val Acc: 0.783505\n",
      "Epoch 27120 - Train Loss: 0.074054, Train Acc: 0.883333 | Val Loss: 0.110198, Val Acc: 0.783505\n",
      "Epoch 27121 - Train Loss: 0.074052, Train Acc: 0.883333 | Val Loss: 0.110198, Val Acc: 0.783505\n",
      "Epoch 27122 - Train Loss: 0.074051, Train Acc: 0.883333 | Val Loss: 0.110197, Val Acc: 0.783505\n",
      "Epoch 27123 - Train Loss: 0.074050, Train Acc: 0.883333 | Val Loss: 0.110197, Val Acc: 0.783505\n",
      "Epoch 27124 - Train Loss: 0.074048, Train Acc: 0.883333 | Val Loss: 0.110197, Val Acc: 0.783505\n",
      "Epoch 27125 - Train Loss: 0.074047, Train Acc: 0.883333 | Val Loss: 0.110196, Val Acc: 0.783505\n",
      "Epoch 27126 - Train Loss: 0.074045, Train Acc: 0.883333 | Val Loss: 0.110196, Val Acc: 0.783505\n",
      "Epoch 27127 - Train Loss: 0.074044, Train Acc: 0.883333 | Val Loss: 0.110195, Val Acc: 0.783505\n",
      "Epoch 27128 - Train Loss: 0.074043, Train Acc: 0.883333 | Val Loss: 0.110195, Val Acc: 0.783505\n",
      "Epoch 27129 - Train Loss: 0.074041, Train Acc: 0.883333 | Val Loss: 0.110195, Val Acc: 0.783505\n",
      "Epoch 27130 - Train Loss: 0.074040, Train Acc: 0.883333 | Val Loss: 0.110194, Val Acc: 0.783505\n",
      "Epoch 27131 - Train Loss: 0.074038, Train Acc: 0.883333 | Val Loss: 0.110194, Val Acc: 0.783505\n",
      "Epoch 27132 - Train Loss: 0.074037, Train Acc: 0.883333 | Val Loss: 0.110193, Val Acc: 0.783505\n",
      "Epoch 27133 - Train Loss: 0.074036, Train Acc: 0.883333 | Val Loss: 0.110193, Val Acc: 0.783505\n",
      "Epoch 27134 - Train Loss: 0.074034, Train Acc: 0.883333 | Val Loss: 0.110193, Val Acc: 0.783505\n",
      "Epoch 27135 - Train Loss: 0.074033, Train Acc: 0.883333 | Val Loss: 0.110192, Val Acc: 0.783505\n",
      "Epoch 27136 - Train Loss: 0.074031, Train Acc: 0.883333 | Val Loss: 0.110192, Val Acc: 0.783505\n",
      "Epoch 27137 - Train Loss: 0.074030, Train Acc: 0.883333 | Val Loss: 0.110191, Val Acc: 0.783505\n",
      "Epoch 27138 - Train Loss: 0.074029, Train Acc: 0.883333 | Val Loss: 0.110191, Val Acc: 0.783505\n",
      "Epoch 27139 - Train Loss: 0.074027, Train Acc: 0.883333 | Val Loss: 0.110191, Val Acc: 0.783505\n",
      "Epoch 27140 - Train Loss: 0.074026, Train Acc: 0.883333 | Val Loss: 0.110190, Val Acc: 0.783505\n",
      "Epoch 27141 - Train Loss: 0.074024, Train Acc: 0.883333 | Val Loss: 0.110190, Val Acc: 0.783505\n",
      "Epoch 27142 - Train Loss: 0.074023, Train Acc: 0.883333 | Val Loss: 0.110189, Val Acc: 0.783505\n",
      "Epoch 27143 - Train Loss: 0.074022, Train Acc: 0.883333 | Val Loss: 0.110189, Val Acc: 0.783505\n",
      "Epoch 27144 - Train Loss: 0.074020, Train Acc: 0.883333 | Val Loss: 0.110189, Val Acc: 0.783505\n",
      "Epoch 27145 - Train Loss: 0.074019, Train Acc: 0.883333 | Val Loss: 0.110188, Val Acc: 0.783505\n",
      "Epoch 27146 - Train Loss: 0.074017, Train Acc: 0.883333 | Val Loss: 0.110188, Val Acc: 0.783505\n",
      "Epoch 27147 - Train Loss: 0.074016, Train Acc: 0.883333 | Val Loss: 0.110187, Val Acc: 0.783505\n",
      "Epoch 27148 - Train Loss: 0.074015, Train Acc: 0.883333 | Val Loss: 0.110187, Val Acc: 0.783505\n",
      "Epoch 27149 - Train Loss: 0.074013, Train Acc: 0.883333 | Val Loss: 0.110187, Val Acc: 0.783505\n",
      "Epoch 27150 - Train Loss: 0.074012, Train Acc: 0.883333 | Val Loss: 0.110186, Val Acc: 0.783505\n",
      "Epoch 27151 - Train Loss: 0.074010, Train Acc: 0.883333 | Val Loss: 0.110186, Val Acc: 0.783505\n",
      "Epoch 27152 - Train Loss: 0.074009, Train Acc: 0.883333 | Val Loss: 0.110185, Val Acc: 0.783505\n",
      "Epoch 27153 - Train Loss: 0.074008, Train Acc: 0.883333 | Val Loss: 0.110185, Val Acc: 0.783505\n",
      "Epoch 27154 - Train Loss: 0.074006, Train Acc: 0.883333 | Val Loss: 0.110185, Val Acc: 0.783505\n",
      "Epoch 27155 - Train Loss: 0.074005, Train Acc: 0.883333 | Val Loss: 0.110184, Val Acc: 0.783505\n",
      "Epoch 27156 - Train Loss: 0.074003, Train Acc: 0.883333 | Val Loss: 0.110184, Val Acc: 0.783505\n",
      "Epoch 27157 - Train Loss: 0.074002, Train Acc: 0.883333 | Val Loss: 0.110183, Val Acc: 0.783505\n",
      "Epoch 27158 - Train Loss: 0.074001, Train Acc: 0.883333 | Val Loss: 0.110183, Val Acc: 0.783505\n",
      "Epoch 27159 - Train Loss: 0.073999, Train Acc: 0.883333 | Val Loss: 0.110183, Val Acc: 0.783505\n",
      "Epoch 27160 - Train Loss: 0.073998, Train Acc: 0.883333 | Val Loss: 0.110182, Val Acc: 0.783505\n",
      "Epoch 27161 - Train Loss: 0.073996, Train Acc: 0.883333 | Val Loss: 0.110182, Val Acc: 0.783505\n",
      "Epoch 27162 - Train Loss: 0.073995, Train Acc: 0.883333 | Val Loss: 0.110181, Val Acc: 0.783505\n",
      "Epoch 27163 - Train Loss: 0.073994, Train Acc: 0.883333 | Val Loss: 0.110181, Val Acc: 0.783505\n",
      "Epoch 27164 - Train Loss: 0.073992, Train Acc: 0.883333 | Val Loss: 0.110181, Val Acc: 0.783505\n",
      "Epoch 27165 - Train Loss: 0.073991, Train Acc: 0.883333 | Val Loss: 0.110180, Val Acc: 0.783505\n",
      "Epoch 27166 - Train Loss: 0.073989, Train Acc: 0.883333 | Val Loss: 0.110180, Val Acc: 0.783505\n",
      "Epoch 27167 - Train Loss: 0.073988, Train Acc: 0.883333 | Val Loss: 0.110179, Val Acc: 0.783505\n",
      "Epoch 27168 - Train Loss: 0.073987, Train Acc: 0.883333 | Val Loss: 0.110179, Val Acc: 0.783505\n",
      "Epoch 27169 - Train Loss: 0.073985, Train Acc: 0.883333 | Val Loss: 0.110179, Val Acc: 0.783505\n",
      "Epoch 27170 - Train Loss: 0.073984, Train Acc: 0.883333 | Val Loss: 0.110178, Val Acc: 0.783505\n",
      "Epoch 27171 - Train Loss: 0.073982, Train Acc: 0.883333 | Val Loss: 0.110178, Val Acc: 0.783505\n",
      "Epoch 27172 - Train Loss: 0.073981, Train Acc: 0.883333 | Val Loss: 0.110177, Val Acc: 0.783505\n",
      "Epoch 27173 - Train Loss: 0.073980, Train Acc: 0.883333 | Val Loss: 0.110177, Val Acc: 0.783505\n",
      "Epoch 27174 - Train Loss: 0.073978, Train Acc: 0.883333 | Val Loss: 0.110177, Val Acc: 0.783505\n",
      "Epoch 27175 - Train Loss: 0.073977, Train Acc: 0.883333 | Val Loss: 0.110176, Val Acc: 0.783505\n",
      "Epoch 27176 - Train Loss: 0.073975, Train Acc: 0.883333 | Val Loss: 0.110176, Val Acc: 0.783505\n",
      "Epoch 27177 - Train Loss: 0.073974, Train Acc: 0.883333 | Val Loss: 0.110175, Val Acc: 0.783505\n",
      "Epoch 27178 - Train Loss: 0.073973, Train Acc: 0.883333 | Val Loss: 0.110175, Val Acc: 0.783505\n",
      "Epoch 27179 - Train Loss: 0.073971, Train Acc: 0.883333 | Val Loss: 0.110175, Val Acc: 0.783505\n",
      "Epoch 27180 - Train Loss: 0.073970, Train Acc: 0.883333 | Val Loss: 0.110174, Val Acc: 0.783505\n",
      "Epoch 27181 - Train Loss: 0.073968, Train Acc: 0.883333 | Val Loss: 0.110174, Val Acc: 0.783505\n",
      "Epoch 27182 - Train Loss: 0.073967, Train Acc: 0.883333 | Val Loss: 0.110173, Val Acc: 0.783505\n",
      "Epoch 27183 - Train Loss: 0.073966, Train Acc: 0.883333 | Val Loss: 0.110173, Val Acc: 0.783505\n",
      "Epoch 27184 - Train Loss: 0.073964, Train Acc: 0.883333 | Val Loss: 0.110173, Val Acc: 0.783505\n",
      "Epoch 27185 - Train Loss: 0.073963, Train Acc: 0.883333 | Val Loss: 0.110172, Val Acc: 0.783505\n",
      "Epoch 27186 - Train Loss: 0.073961, Train Acc: 0.883333 | Val Loss: 0.110172, Val Acc: 0.783505\n",
      "Epoch 27187 - Train Loss: 0.073960, Train Acc: 0.883333 | Val Loss: 0.110171, Val Acc: 0.783505\n",
      "Epoch 27188 - Train Loss: 0.073959, Train Acc: 0.884615 | Val Loss: 0.110171, Val Acc: 0.783505\n",
      "Epoch 27189 - Train Loss: 0.073957, Train Acc: 0.884615 | Val Loss: 0.110171, Val Acc: 0.783505\n",
      "Epoch 27190 - Train Loss: 0.073956, Train Acc: 0.884615 | Val Loss: 0.110170, Val Acc: 0.783505\n",
      "Epoch 27191 - Train Loss: 0.073954, Train Acc: 0.884615 | Val Loss: 0.110170, Val Acc: 0.783505\n",
      "Epoch 27192 - Train Loss: 0.073953, Train Acc: 0.884615 | Val Loss: 0.110169, Val Acc: 0.783505\n",
      "Epoch 27193 - Train Loss: 0.073952, Train Acc: 0.884615 | Val Loss: 0.110169, Val Acc: 0.783505\n",
      "Epoch 27194 - Train Loss: 0.073950, Train Acc: 0.884615 | Val Loss: 0.110169, Val Acc: 0.783505\n",
      "Epoch 27195 - Train Loss: 0.073949, Train Acc: 0.884615 | Val Loss: 0.110168, Val Acc: 0.783505\n",
      "Epoch 27196 - Train Loss: 0.073947, Train Acc: 0.884615 | Val Loss: 0.110168, Val Acc: 0.783505\n",
      "Epoch 27197 - Train Loss: 0.073946, Train Acc: 0.884615 | Val Loss: 0.110167, Val Acc: 0.783505\n",
      "Epoch 27198 - Train Loss: 0.073945, Train Acc: 0.884615 | Val Loss: 0.110167, Val Acc: 0.783505\n",
      "Epoch 27199 - Train Loss: 0.073943, Train Acc: 0.884615 | Val Loss: 0.110167, Val Acc: 0.783505\n",
      "Epoch 27200 - Train Loss: 0.073942, Train Acc: 0.884615 | Val Loss: 0.110166, Val Acc: 0.783505\n",
      "Epoch 27201 - Train Loss: 0.073940, Train Acc: 0.884615 | Val Loss: 0.110166, Val Acc: 0.783505\n",
      "Epoch 27202 - Train Loss: 0.073939, Train Acc: 0.884615 | Val Loss: 0.110165, Val Acc: 0.783505\n",
      "Epoch 27203 - Train Loss: 0.073938, Train Acc: 0.884615 | Val Loss: 0.110165, Val Acc: 0.783505\n",
      "Epoch 27204 - Train Loss: 0.073936, Train Acc: 0.884615 | Val Loss: 0.110165, Val Acc: 0.783505\n",
      "Epoch 27205 - Train Loss: 0.073935, Train Acc: 0.884615 | Val Loss: 0.110164, Val Acc: 0.783505\n",
      "Epoch 27206 - Train Loss: 0.073933, Train Acc: 0.884615 | Val Loss: 0.110164, Val Acc: 0.783505\n",
      "Epoch 27207 - Train Loss: 0.073932, Train Acc: 0.884615 | Val Loss: 0.110164, Val Acc: 0.783505\n",
      "Epoch 27208 - Train Loss: 0.073931, Train Acc: 0.884615 | Val Loss: 0.110163, Val Acc: 0.783505\n",
      "Epoch 27209 - Train Loss: 0.073929, Train Acc: 0.884615 | Val Loss: 0.110163, Val Acc: 0.783505\n",
      "Epoch 27210 - Train Loss: 0.073928, Train Acc: 0.884615 | Val Loss: 0.110162, Val Acc: 0.783505\n",
      "Epoch 27211 - Train Loss: 0.073927, Train Acc: 0.884615 | Val Loss: 0.110162, Val Acc: 0.783505\n",
      "Epoch 27212 - Train Loss: 0.073925, Train Acc: 0.884615 | Val Loss: 0.110162, Val Acc: 0.783505\n",
      "Epoch 27213 - Train Loss: 0.073924, Train Acc: 0.884615 | Val Loss: 0.110161, Val Acc: 0.783505\n",
      "Epoch 27214 - Train Loss: 0.073922, Train Acc: 0.884615 | Val Loss: 0.110161, Val Acc: 0.783505\n",
      "Epoch 27215 - Train Loss: 0.073921, Train Acc: 0.884615 | Val Loss: 0.110160, Val Acc: 0.783505\n",
      "Epoch 27216 - Train Loss: 0.073920, Train Acc: 0.884615 | Val Loss: 0.110160, Val Acc: 0.783505\n",
      "Epoch 27217 - Train Loss: 0.073918, Train Acc: 0.884615 | Val Loss: 0.110160, Val Acc: 0.783505\n",
      "Epoch 27218 - Train Loss: 0.073917, Train Acc: 0.884615 | Val Loss: 0.110159, Val Acc: 0.783505\n",
      "Epoch 27219 - Train Loss: 0.073915, Train Acc: 0.884615 | Val Loss: 0.110159, Val Acc: 0.783505\n",
      "Epoch 27220 - Train Loss: 0.073914, Train Acc: 0.884615 | Val Loss: 0.110158, Val Acc: 0.783505\n",
      "Epoch 27221 - Train Loss: 0.073913, Train Acc: 0.884615 | Val Loss: 0.110158, Val Acc: 0.783505\n",
      "Epoch 27222 - Train Loss: 0.073911, Train Acc: 0.884615 | Val Loss: 0.110158, Val Acc: 0.783505\n",
      "Epoch 27223 - Train Loss: 0.073910, Train Acc: 0.884615 | Val Loss: 0.110157, Val Acc: 0.783505\n",
      "Epoch 27224 - Train Loss: 0.073908, Train Acc: 0.884615 | Val Loss: 0.110157, Val Acc: 0.783505\n",
      "Epoch 27225 - Train Loss: 0.073907, Train Acc: 0.884615 | Val Loss: 0.110156, Val Acc: 0.783505\n",
      "Epoch 27226 - Train Loss: 0.073906, Train Acc: 0.884615 | Val Loss: 0.110156, Val Acc: 0.783505\n",
      "Epoch 27227 - Train Loss: 0.073904, Train Acc: 0.884615 | Val Loss: 0.110156, Val Acc: 0.783505\n",
      "Epoch 27228 - Train Loss: 0.073903, Train Acc: 0.884615 | Val Loss: 0.110155, Val Acc: 0.783505\n",
      "Epoch 27229 - Train Loss: 0.073901, Train Acc: 0.884615 | Val Loss: 0.110155, Val Acc: 0.783505\n",
      "Epoch 27230 - Train Loss: 0.073900, Train Acc: 0.884615 | Val Loss: 0.110154, Val Acc: 0.783505\n",
      "Epoch 27231 - Train Loss: 0.073899, Train Acc: 0.884615 | Val Loss: 0.110154, Val Acc: 0.783505\n",
      "Epoch 27232 - Train Loss: 0.073897, Train Acc: 0.884615 | Val Loss: 0.110154, Val Acc: 0.783505\n",
      "Epoch 27233 - Train Loss: 0.073896, Train Acc: 0.884615 | Val Loss: 0.110153, Val Acc: 0.783505\n",
      "Epoch 27234 - Train Loss: 0.073894, Train Acc: 0.884615 | Val Loss: 0.110153, Val Acc: 0.783505\n",
      "Epoch 27235 - Train Loss: 0.073893, Train Acc: 0.884615 | Val Loss: 0.110152, Val Acc: 0.783505\n",
      "Epoch 27236 - Train Loss: 0.073892, Train Acc: 0.884615 | Val Loss: 0.110152, Val Acc: 0.783505\n",
      "Epoch 27237 - Train Loss: 0.073890, Train Acc: 0.884615 | Val Loss: 0.110152, Val Acc: 0.783505\n",
      "Epoch 27238 - Train Loss: 0.073889, Train Acc: 0.884615 | Val Loss: 0.110151, Val Acc: 0.783505\n",
      "Epoch 27239 - Train Loss: 0.073887, Train Acc: 0.884615 | Val Loss: 0.110151, Val Acc: 0.783505\n",
      "Epoch 27240 - Train Loss: 0.073886, Train Acc: 0.884615 | Val Loss: 0.110150, Val Acc: 0.783505\n",
      "Epoch 27241 - Train Loss: 0.073885, Train Acc: 0.884615 | Val Loss: 0.110150, Val Acc: 0.783505\n",
      "Epoch 27242 - Train Loss: 0.073883, Train Acc: 0.884615 | Val Loss: 0.110150, Val Acc: 0.783505\n",
      "Epoch 27243 - Train Loss: 0.073882, Train Acc: 0.884615 | Val Loss: 0.110149, Val Acc: 0.783505\n",
      "Epoch 27244 - Train Loss: 0.073880, Train Acc: 0.884615 | Val Loss: 0.110149, Val Acc: 0.783505\n",
      "Epoch 27245 - Train Loss: 0.073879, Train Acc: 0.884615 | Val Loss: 0.110148, Val Acc: 0.783505\n",
      "Epoch 27246 - Train Loss: 0.073878, Train Acc: 0.884615 | Val Loss: 0.110148, Val Acc: 0.783505\n",
      "Epoch 27247 - Train Loss: 0.073876, Train Acc: 0.884615 | Val Loss: 0.110148, Val Acc: 0.783505\n",
      "Epoch 27248 - Train Loss: 0.073875, Train Acc: 0.884615 | Val Loss: 0.110147, Val Acc: 0.783505\n",
      "Epoch 27249 - Train Loss: 0.073874, Train Acc: 0.884615 | Val Loss: 0.110147, Val Acc: 0.783505\n",
      "Epoch 27250 - Train Loss: 0.073872, Train Acc: 0.884615 | Val Loss: 0.110146, Val Acc: 0.783505\n",
      "Epoch 27251 - Train Loss: 0.073871, Train Acc: 0.884615 | Val Loss: 0.110146, Val Acc: 0.783505\n",
      "Epoch 27252 - Train Loss: 0.073869, Train Acc: 0.884615 | Val Loss: 0.110146, Val Acc: 0.783505\n",
      "Epoch 27253 - Train Loss: 0.073868, Train Acc: 0.884615 | Val Loss: 0.110145, Val Acc: 0.783505\n",
      "Epoch 27254 - Train Loss: 0.073867, Train Acc: 0.884615 | Val Loss: 0.110145, Val Acc: 0.783505\n",
      "Epoch 27255 - Train Loss: 0.073865, Train Acc: 0.884615 | Val Loss: 0.110145, Val Acc: 0.783505\n",
      "Epoch 27256 - Train Loss: 0.073864, Train Acc: 0.884615 | Val Loss: 0.110144, Val Acc: 0.783505\n",
      "Epoch 27257 - Train Loss: 0.073862, Train Acc: 0.884615 | Val Loss: 0.110144, Val Acc: 0.783505\n",
      "Epoch 27258 - Train Loss: 0.073861, Train Acc: 0.884615 | Val Loss: 0.110143, Val Acc: 0.783505\n",
      "Epoch 27259 - Train Loss: 0.073860, Train Acc: 0.884615 | Val Loss: 0.110143, Val Acc: 0.783505\n",
      "Epoch 27260 - Train Loss: 0.073858, Train Acc: 0.884615 | Val Loss: 0.110143, Val Acc: 0.783505\n",
      "Epoch 27261 - Train Loss: 0.073857, Train Acc: 0.884615 | Val Loss: 0.110142, Val Acc: 0.783505\n",
      "Epoch 27262 - Train Loss: 0.073855, Train Acc: 0.884615 | Val Loss: 0.110142, Val Acc: 0.783505\n",
      "Epoch 27263 - Train Loss: 0.073854, Train Acc: 0.884615 | Val Loss: 0.110141, Val Acc: 0.783505\n",
      "Epoch 27264 - Train Loss: 0.073853, Train Acc: 0.884615 | Val Loss: 0.110141, Val Acc: 0.783505\n",
      "Epoch 27265 - Train Loss: 0.073851, Train Acc: 0.884615 | Val Loss: 0.110141, Val Acc: 0.783505\n",
      "Epoch 27266 - Train Loss: 0.073850, Train Acc: 0.884615 | Val Loss: 0.110140, Val Acc: 0.783505\n",
      "Epoch 27267 - Train Loss: 0.073848, Train Acc: 0.884615 | Val Loss: 0.110140, Val Acc: 0.783505\n",
      "Epoch 27268 - Train Loss: 0.073847, Train Acc: 0.884615 | Val Loss: 0.110139, Val Acc: 0.783505\n",
      "Epoch 27269 - Train Loss: 0.073846, Train Acc: 0.884615 | Val Loss: 0.110139, Val Acc: 0.783505\n",
      "Epoch 27270 - Train Loss: 0.073844, Train Acc: 0.884615 | Val Loss: 0.110139, Val Acc: 0.783505\n",
      "Epoch 27271 - Train Loss: 0.073843, Train Acc: 0.884615 | Val Loss: 0.110138, Val Acc: 0.783505\n",
      "Epoch 27272 - Train Loss: 0.073842, Train Acc: 0.884615 | Val Loss: 0.110138, Val Acc: 0.783505\n",
      "Epoch 27273 - Train Loss: 0.073840, Train Acc: 0.884615 | Val Loss: 0.110137, Val Acc: 0.783505\n",
      "Epoch 27274 - Train Loss: 0.073839, Train Acc: 0.884615 | Val Loss: 0.110137, Val Acc: 0.783505\n",
      "Epoch 27275 - Train Loss: 0.073837, Train Acc: 0.884615 | Val Loss: 0.110137, Val Acc: 0.783505\n",
      "Epoch 27276 - Train Loss: 0.073836, Train Acc: 0.884615 | Val Loss: 0.110136, Val Acc: 0.783505\n",
      "Epoch 27277 - Train Loss: 0.073835, Train Acc: 0.884615 | Val Loss: 0.110136, Val Acc: 0.783505\n",
      "Epoch 27278 - Train Loss: 0.073833, Train Acc: 0.884615 | Val Loss: 0.110135, Val Acc: 0.783505\n",
      "Epoch 27279 - Train Loss: 0.073832, Train Acc: 0.884615 | Val Loss: 0.110135, Val Acc: 0.783505\n",
      "Epoch 27280 - Train Loss: 0.073830, Train Acc: 0.884615 | Val Loss: 0.110135, Val Acc: 0.783505\n",
      "Epoch 27281 - Train Loss: 0.073829, Train Acc: 0.884615 | Val Loss: 0.110134, Val Acc: 0.783505\n",
      "Epoch 27282 - Train Loss: 0.073828, Train Acc: 0.884615 | Val Loss: 0.110134, Val Acc: 0.783505\n",
      "Epoch 27283 - Train Loss: 0.073826, Train Acc: 0.884615 | Val Loss: 0.110134, Val Acc: 0.783505\n",
      "Epoch 27284 - Train Loss: 0.073825, Train Acc: 0.884615 | Val Loss: 0.110133, Val Acc: 0.783505\n",
      "Epoch 27285 - Train Loss: 0.073823, Train Acc: 0.884615 | Val Loss: 0.110133, Val Acc: 0.783505\n",
      "Epoch 27286 - Train Loss: 0.073822, Train Acc: 0.884615 | Val Loss: 0.110132, Val Acc: 0.783505\n",
      "Epoch 27287 - Train Loss: 0.073821, Train Acc: 0.884615 | Val Loss: 0.110132, Val Acc: 0.783505\n",
      "Epoch 27288 - Train Loss: 0.073819, Train Acc: 0.884615 | Val Loss: 0.110132, Val Acc: 0.783505\n",
      "Epoch 27289 - Train Loss: 0.073818, Train Acc: 0.884615 | Val Loss: 0.110131, Val Acc: 0.783505\n",
      "Epoch 27290 - Train Loss: 0.073816, Train Acc: 0.884615 | Val Loss: 0.110131, Val Acc: 0.783505\n",
      "Epoch 27291 - Train Loss: 0.073815, Train Acc: 0.884615 | Val Loss: 0.110130, Val Acc: 0.783505\n",
      "Epoch 27292 - Train Loss: 0.073814, Train Acc: 0.884615 | Val Loss: 0.110130, Val Acc: 0.783505\n",
      "Epoch 27293 - Train Loss: 0.073812, Train Acc: 0.884615 | Val Loss: 0.110130, Val Acc: 0.783505\n",
      "Epoch 27294 - Train Loss: 0.073811, Train Acc: 0.884615 | Val Loss: 0.110129, Val Acc: 0.783505\n",
      "Epoch 27295 - Train Loss: 0.073810, Train Acc: 0.884615 | Val Loss: 0.110129, Val Acc: 0.783505\n",
      "Epoch 27296 - Train Loss: 0.073808, Train Acc: 0.884615 | Val Loss: 0.110128, Val Acc: 0.783505\n",
      "Epoch 27297 - Train Loss: 0.073807, Train Acc: 0.884615 | Val Loss: 0.110128, Val Acc: 0.783505\n",
      "Epoch 27298 - Train Loss: 0.073805, Train Acc: 0.884615 | Val Loss: 0.110128, Val Acc: 0.783505\n",
      "Epoch 27299 - Train Loss: 0.073804, Train Acc: 0.884615 | Val Loss: 0.110127, Val Acc: 0.783505\n",
      "Epoch 27300 - Train Loss: 0.073803, Train Acc: 0.884615 | Val Loss: 0.110127, Val Acc: 0.783505\n",
      "Epoch 27301 - Train Loss: 0.073801, Train Acc: 0.884615 | Val Loss: 0.110126, Val Acc: 0.783505\n",
      "Epoch 27302 - Train Loss: 0.073800, Train Acc: 0.884615 | Val Loss: 0.110126, Val Acc: 0.783505\n",
      "Epoch 27303 - Train Loss: 0.073798, Train Acc: 0.884615 | Val Loss: 0.110126, Val Acc: 0.783505\n",
      "Epoch 27304 - Train Loss: 0.073797, Train Acc: 0.884615 | Val Loss: 0.110125, Val Acc: 0.783505\n",
      "Epoch 27305 - Train Loss: 0.073796, Train Acc: 0.884615 | Val Loss: 0.110125, Val Acc: 0.783505\n",
      "Epoch 27306 - Train Loss: 0.073794, Train Acc: 0.884615 | Val Loss: 0.110125, Val Acc: 0.783505\n",
      "Epoch 27307 - Train Loss: 0.073793, Train Acc: 0.884615 | Val Loss: 0.110124, Val Acc: 0.783505\n",
      "Epoch 27308 - Train Loss: 0.073791, Train Acc: 0.884615 | Val Loss: 0.110124, Val Acc: 0.783505\n",
      "Epoch 27309 - Train Loss: 0.073790, Train Acc: 0.884615 | Val Loss: 0.110123, Val Acc: 0.783505\n",
      "Epoch 27310 - Train Loss: 0.073789, Train Acc: 0.884615 | Val Loss: 0.110123, Val Acc: 0.783505\n",
      "Epoch 27311 - Train Loss: 0.073787, Train Acc: 0.884615 | Val Loss: 0.110123, Val Acc: 0.783505\n",
      "Epoch 27312 - Train Loss: 0.073786, Train Acc: 0.884615 | Val Loss: 0.110122, Val Acc: 0.783505\n",
      "Epoch 27313 - Train Loss: 0.073785, Train Acc: 0.884615 | Val Loss: 0.110122, Val Acc: 0.783505\n",
      "Epoch 27314 - Train Loss: 0.073783, Train Acc: 0.884615 | Val Loss: 0.110121, Val Acc: 0.783505\n",
      "Epoch 27315 - Train Loss: 0.073782, Train Acc: 0.884615 | Val Loss: 0.110121, Val Acc: 0.783505\n",
      "Epoch 27316 - Train Loss: 0.073780, Train Acc: 0.884615 | Val Loss: 0.110121, Val Acc: 0.783505\n",
      "Epoch 27317 - Train Loss: 0.073779, Train Acc: 0.884615 | Val Loss: 0.110120, Val Acc: 0.783505\n",
      "Epoch 27318 - Train Loss: 0.073778, Train Acc: 0.884615 | Val Loss: 0.110120, Val Acc: 0.783505\n",
      "Epoch 27319 - Train Loss: 0.073776, Train Acc: 0.884615 | Val Loss: 0.110119, Val Acc: 0.783505\n",
      "Epoch 27320 - Train Loss: 0.073775, Train Acc: 0.884615 | Val Loss: 0.110119, Val Acc: 0.783505\n",
      "Epoch 27321 - Train Loss: 0.073773, Train Acc: 0.884615 | Val Loss: 0.110119, Val Acc: 0.783505\n",
      "Epoch 27322 - Train Loss: 0.073772, Train Acc: 0.884615 | Val Loss: 0.110118, Val Acc: 0.783505\n",
      "Epoch 27323 - Train Loss: 0.073771, Train Acc: 0.884615 | Val Loss: 0.110118, Val Acc: 0.783505\n",
      "Epoch 27324 - Train Loss: 0.073769, Train Acc: 0.884615 | Val Loss: 0.110117, Val Acc: 0.783505\n",
      "Epoch 27325 - Train Loss: 0.073768, Train Acc: 0.884615 | Val Loss: 0.110117, Val Acc: 0.783505\n",
      "Epoch 27326 - Train Loss: 0.073766, Train Acc: 0.884615 | Val Loss: 0.110117, Val Acc: 0.783505\n",
      "Epoch 27327 - Train Loss: 0.073765, Train Acc: 0.884615 | Val Loss: 0.110116, Val Acc: 0.783505\n",
      "Epoch 27328 - Train Loss: 0.073764, Train Acc: 0.884615 | Val Loss: 0.110116, Val Acc: 0.783505\n",
      "Epoch 27329 - Train Loss: 0.073762, Train Acc: 0.884615 | Val Loss: 0.110115, Val Acc: 0.783505\n",
      "Epoch 27330 - Train Loss: 0.073761, Train Acc: 0.884615 | Val Loss: 0.110115, Val Acc: 0.783505\n",
      "Epoch 27331 - Train Loss: 0.073760, Train Acc: 0.884615 | Val Loss: 0.110115, Val Acc: 0.783505\n",
      "Epoch 27332 - Train Loss: 0.073758, Train Acc: 0.884615 | Val Loss: 0.110114, Val Acc: 0.783505\n",
      "Epoch 27333 - Train Loss: 0.073757, Train Acc: 0.884615 | Val Loss: 0.110114, Val Acc: 0.783505\n",
      "Epoch 27334 - Train Loss: 0.073755, Train Acc: 0.884615 | Val Loss: 0.110113, Val Acc: 0.783505\n",
      "Epoch 27335 - Train Loss: 0.073754, Train Acc: 0.884615 | Val Loss: 0.110113, Val Acc: 0.783505\n",
      "Epoch 27336 - Train Loss: 0.073753, Train Acc: 0.884615 | Val Loss: 0.110113, Val Acc: 0.783505\n",
      "Epoch 27337 - Train Loss: 0.073751, Train Acc: 0.884615 | Val Loss: 0.110112, Val Acc: 0.783505\n",
      "Epoch 27338 - Train Loss: 0.073750, Train Acc: 0.884615 | Val Loss: 0.110112, Val Acc: 0.783505\n",
      "Epoch 27339 - Train Loss: 0.073748, Train Acc: 0.884615 | Val Loss: 0.110111, Val Acc: 0.783505\n",
      "Epoch 27340 - Train Loss: 0.073747, Train Acc: 0.884615 | Val Loss: 0.110111, Val Acc: 0.783505\n",
      "Epoch 27341 - Train Loss: 0.073746, Train Acc: 0.884615 | Val Loss: 0.110111, Val Acc: 0.783505\n",
      "Epoch 27342 - Train Loss: 0.073744, Train Acc: 0.884615 | Val Loss: 0.110110, Val Acc: 0.783505\n",
      "Epoch 27343 - Train Loss: 0.073743, Train Acc: 0.884615 | Val Loss: 0.110110, Val Acc: 0.783505\n",
      "Epoch 27344 - Train Loss: 0.073742, Train Acc: 0.884615 | Val Loss: 0.110109, Val Acc: 0.783505\n",
      "Epoch 27345 - Train Loss: 0.073740, Train Acc: 0.884615 | Val Loss: 0.110109, Val Acc: 0.783505\n",
      "Epoch 27346 - Train Loss: 0.073739, Train Acc: 0.884615 | Val Loss: 0.110109, Val Acc: 0.783505\n",
      "Epoch 27347 - Train Loss: 0.073737, Train Acc: 0.884615 | Val Loss: 0.110108, Val Acc: 0.783505\n",
      "Epoch 27348 - Train Loss: 0.073736, Train Acc: 0.884615 | Val Loss: 0.110108, Val Acc: 0.783505\n",
      "Epoch 27349 - Train Loss: 0.073735, Train Acc: 0.884615 | Val Loss: 0.110107, Val Acc: 0.783505\n",
      "Epoch 27350 - Train Loss: 0.073733, Train Acc: 0.884615 | Val Loss: 0.110107, Val Acc: 0.783505\n",
      "Epoch 27351 - Train Loss: 0.073732, Train Acc: 0.884615 | Val Loss: 0.110107, Val Acc: 0.783505\n",
      "Epoch 27352 - Train Loss: 0.073730, Train Acc: 0.884615 | Val Loss: 0.110106, Val Acc: 0.783505\n",
      "Epoch 27353 - Train Loss: 0.073729, Train Acc: 0.884615 | Val Loss: 0.110106, Val Acc: 0.783505\n",
      "Epoch 27354 - Train Loss: 0.073728, Train Acc: 0.884615 | Val Loss: 0.110106, Val Acc: 0.783505\n",
      "Epoch 27355 - Train Loss: 0.073726, Train Acc: 0.884615 | Val Loss: 0.110105, Val Acc: 0.783505\n",
      "Epoch 27356 - Train Loss: 0.073725, Train Acc: 0.884615 | Val Loss: 0.110105, Val Acc: 0.783505\n",
      "Epoch 27357 - Train Loss: 0.073723, Train Acc: 0.884615 | Val Loss: 0.110104, Val Acc: 0.783505\n",
      "Epoch 27358 - Train Loss: 0.073722, Train Acc: 0.884615 | Val Loss: 0.110104, Val Acc: 0.783505\n",
      "Epoch 27359 - Train Loss: 0.073721, Train Acc: 0.884615 | Val Loss: 0.110104, Val Acc: 0.783505\n",
      "Epoch 27360 - Train Loss: 0.073719, Train Acc: 0.884615 | Val Loss: 0.110103, Val Acc: 0.783505\n",
      "Epoch 27361 - Train Loss: 0.073718, Train Acc: 0.884615 | Val Loss: 0.110103, Val Acc: 0.783505\n",
      "Epoch 27362 - Train Loss: 0.073717, Train Acc: 0.884615 | Val Loss: 0.110102, Val Acc: 0.783505\n",
      "Epoch 27363 - Train Loss: 0.073715, Train Acc: 0.884615 | Val Loss: 0.110102, Val Acc: 0.783505\n",
      "Epoch 27364 - Train Loss: 0.073714, Train Acc: 0.884615 | Val Loss: 0.110102, Val Acc: 0.783505\n",
      "Epoch 27365 - Train Loss: 0.073712, Train Acc: 0.884615 | Val Loss: 0.110101, Val Acc: 0.783505\n",
      "Epoch 27366 - Train Loss: 0.073711, Train Acc: 0.884615 | Val Loss: 0.110101, Val Acc: 0.783505\n",
      "Epoch 27367 - Train Loss: 0.073710, Train Acc: 0.884615 | Val Loss: 0.110100, Val Acc: 0.783505\n",
      "Epoch 27368 - Train Loss: 0.073708, Train Acc: 0.884615 | Val Loss: 0.110100, Val Acc: 0.783505\n",
      "Epoch 27369 - Train Loss: 0.073707, Train Acc: 0.884615 | Val Loss: 0.110100, Val Acc: 0.783505\n",
      "Epoch 27370 - Train Loss: 0.073705, Train Acc: 0.884615 | Val Loss: 0.110099, Val Acc: 0.783505\n",
      "Epoch 27371 - Train Loss: 0.073704, Train Acc: 0.884615 | Val Loss: 0.110099, Val Acc: 0.783505\n",
      "Epoch 27372 - Train Loss: 0.073703, Train Acc: 0.884615 | Val Loss: 0.110099, Val Acc: 0.783505\n",
      "Epoch 27373 - Train Loss: 0.073701, Train Acc: 0.884615 | Val Loss: 0.110098, Val Acc: 0.783505\n",
      "Epoch 27374 - Train Loss: 0.073700, Train Acc: 0.884615 | Val Loss: 0.110098, Val Acc: 0.783505\n",
      "Epoch 27375 - Train Loss: 0.073699, Train Acc: 0.884615 | Val Loss: 0.110097, Val Acc: 0.783505\n",
      "Epoch 27376 - Train Loss: 0.073697, Train Acc: 0.884615 | Val Loss: 0.110097, Val Acc: 0.783505\n",
      "Epoch 27377 - Train Loss: 0.073696, Train Acc: 0.884615 | Val Loss: 0.110097, Val Acc: 0.783505\n",
      "Epoch 27378 - Train Loss: 0.073694, Train Acc: 0.884615 | Val Loss: 0.110096, Val Acc: 0.783505\n",
      "Epoch 27379 - Train Loss: 0.073693, Train Acc: 0.884615 | Val Loss: 0.110096, Val Acc: 0.783505\n",
      "Epoch 27380 - Train Loss: 0.073692, Train Acc: 0.884615 | Val Loss: 0.110095, Val Acc: 0.783505\n",
      "Epoch 27381 - Train Loss: 0.073690, Train Acc: 0.884615 | Val Loss: 0.110095, Val Acc: 0.783505\n",
      "Epoch 27382 - Train Loss: 0.073689, Train Acc: 0.884615 | Val Loss: 0.110095, Val Acc: 0.783505\n",
      "Epoch 27383 - Train Loss: 0.073687, Train Acc: 0.884615 | Val Loss: 0.110094, Val Acc: 0.783505\n",
      "Epoch 27384 - Train Loss: 0.073686, Train Acc: 0.884615 | Val Loss: 0.110094, Val Acc: 0.783505\n",
      "Epoch 27385 - Train Loss: 0.073685, Train Acc: 0.884615 | Val Loss: 0.110093, Val Acc: 0.783505\n",
      "Epoch 27386 - Train Loss: 0.073683, Train Acc: 0.884615 | Val Loss: 0.110093, Val Acc: 0.783505\n",
      "Epoch 27387 - Train Loss: 0.073682, Train Acc: 0.884615 | Val Loss: 0.110093, Val Acc: 0.783505\n",
      "Epoch 27388 - Train Loss: 0.073681, Train Acc: 0.884615 | Val Loss: 0.110092, Val Acc: 0.783505\n",
      "Epoch 27389 - Train Loss: 0.073679, Train Acc: 0.884615 | Val Loss: 0.110092, Val Acc: 0.783505\n",
      "Epoch 27390 - Train Loss: 0.073678, Train Acc: 0.884615 | Val Loss: 0.110092, Val Acc: 0.783505\n",
      "Epoch 27391 - Train Loss: 0.073676, Train Acc: 0.884615 | Val Loss: 0.110091, Val Acc: 0.783505\n",
      "Epoch 27392 - Train Loss: 0.073675, Train Acc: 0.884615 | Val Loss: 0.110091, Val Acc: 0.783505\n",
      "Epoch 27393 - Train Loss: 0.073674, Train Acc: 0.884615 | Val Loss: 0.110090, Val Acc: 0.783505\n",
      "Epoch 27394 - Train Loss: 0.073672, Train Acc: 0.884615 | Val Loss: 0.110090, Val Acc: 0.783505\n",
      "Epoch 27395 - Train Loss: 0.073671, Train Acc: 0.884615 | Val Loss: 0.110090, Val Acc: 0.783505\n",
      "Epoch 27396 - Train Loss: 0.073669, Train Acc: 0.884615 | Val Loss: 0.110089, Val Acc: 0.783505\n",
      "Epoch 27397 - Train Loss: 0.073668, Train Acc: 0.884615 | Val Loss: 0.110089, Val Acc: 0.783505\n",
      "Epoch 27398 - Train Loss: 0.073667, Train Acc: 0.884615 | Val Loss: 0.110088, Val Acc: 0.783505\n",
      "Epoch 27399 - Train Loss: 0.073665, Train Acc: 0.884615 | Val Loss: 0.110088, Val Acc: 0.773196\n",
      "Epoch 27400 - Train Loss: 0.073664, Train Acc: 0.884615 | Val Loss: 0.110088, Val Acc: 0.773196\n",
      "Epoch 27401 - Train Loss: 0.073663, Train Acc: 0.884615 | Val Loss: 0.110087, Val Acc: 0.773196\n",
      "Epoch 27402 - Train Loss: 0.073661, Train Acc: 0.884615 | Val Loss: 0.110087, Val Acc: 0.773196\n",
      "Epoch 27403 - Train Loss: 0.073660, Train Acc: 0.884615 | Val Loss: 0.110086, Val Acc: 0.773196\n",
      "Epoch 27404 - Train Loss: 0.073658, Train Acc: 0.884615 | Val Loss: 0.110086, Val Acc: 0.773196\n",
      "Epoch 27405 - Train Loss: 0.073657, Train Acc: 0.884615 | Val Loss: 0.110086, Val Acc: 0.773196\n",
      "Epoch 27406 - Train Loss: 0.073656, Train Acc: 0.884615 | Val Loss: 0.110085, Val Acc: 0.773196\n",
      "Epoch 27407 - Train Loss: 0.073654, Train Acc: 0.884615 | Val Loss: 0.110085, Val Acc: 0.773196\n",
      "Epoch 27408 - Train Loss: 0.073653, Train Acc: 0.884615 | Val Loss: 0.110085, Val Acc: 0.773196\n",
      "Epoch 27409 - Train Loss: 0.073652, Train Acc: 0.884615 | Val Loss: 0.110084, Val Acc: 0.773196\n",
      "Epoch 27410 - Train Loss: 0.073650, Train Acc: 0.884615 | Val Loss: 0.110084, Val Acc: 0.773196\n",
      "Epoch 27411 - Train Loss: 0.073649, Train Acc: 0.884615 | Val Loss: 0.110083, Val Acc: 0.773196\n",
      "Epoch 27412 - Train Loss: 0.073647, Train Acc: 0.884615 | Val Loss: 0.110083, Val Acc: 0.773196\n",
      "Epoch 27413 - Train Loss: 0.073646, Train Acc: 0.884615 | Val Loss: 0.110083, Val Acc: 0.773196\n",
      "Epoch 27414 - Train Loss: 0.073645, Train Acc: 0.884615 | Val Loss: 0.110082, Val Acc: 0.773196\n",
      "Epoch 27415 - Train Loss: 0.073643, Train Acc: 0.884615 | Val Loss: 0.110082, Val Acc: 0.773196\n",
      "Epoch 27416 - Train Loss: 0.073642, Train Acc: 0.884615 | Val Loss: 0.110081, Val Acc: 0.773196\n",
      "Epoch 27417 - Train Loss: 0.073640, Train Acc: 0.884615 | Val Loss: 0.110081, Val Acc: 0.773196\n",
      "Epoch 27418 - Train Loss: 0.073639, Train Acc: 0.884615 | Val Loss: 0.110081, Val Acc: 0.773196\n",
      "Epoch 27419 - Train Loss: 0.073638, Train Acc: 0.884615 | Val Loss: 0.110080, Val Acc: 0.773196\n",
      "Epoch 27420 - Train Loss: 0.073636, Train Acc: 0.884615 | Val Loss: 0.110080, Val Acc: 0.773196\n",
      "Epoch 27421 - Train Loss: 0.073635, Train Acc: 0.884615 | Val Loss: 0.110080, Val Acc: 0.773196\n",
      "Epoch 27422 - Train Loss: 0.073634, Train Acc: 0.884615 | Val Loss: 0.110079, Val Acc: 0.773196\n",
      "Epoch 27423 - Train Loss: 0.073632, Train Acc: 0.884615 | Val Loss: 0.110079, Val Acc: 0.773196\n",
      "Epoch 27424 - Train Loss: 0.073631, Train Acc: 0.884615 | Val Loss: 0.110078, Val Acc: 0.773196\n",
      "Epoch 27425 - Train Loss: 0.073629, Train Acc: 0.884615 | Val Loss: 0.110078, Val Acc: 0.773196\n",
      "Epoch 27426 - Train Loss: 0.073628, Train Acc: 0.884615 | Val Loss: 0.110078, Val Acc: 0.773196\n",
      "Epoch 27427 - Train Loss: 0.073627, Train Acc: 0.884615 | Val Loss: 0.110077, Val Acc: 0.773196\n",
      "Epoch 27428 - Train Loss: 0.073625, Train Acc: 0.884615 | Val Loss: 0.110077, Val Acc: 0.773196\n",
      "Epoch 27429 - Train Loss: 0.073624, Train Acc: 0.884615 | Val Loss: 0.110076, Val Acc: 0.773196\n",
      "Epoch 27430 - Train Loss: 0.073622, Train Acc: 0.884615 | Val Loss: 0.110076, Val Acc: 0.773196\n",
      "Epoch 27431 - Train Loss: 0.073621, Train Acc: 0.884615 | Val Loss: 0.110076, Val Acc: 0.773196\n",
      "Epoch 27432 - Train Loss: 0.073620, Train Acc: 0.884615 | Val Loss: 0.110075, Val Acc: 0.773196\n",
      "Epoch 27433 - Train Loss: 0.073618, Train Acc: 0.884615 | Val Loss: 0.110075, Val Acc: 0.773196\n",
      "Epoch 27434 - Train Loss: 0.073617, Train Acc: 0.884615 | Val Loss: 0.110075, Val Acc: 0.773196\n",
      "Epoch 27435 - Train Loss: 0.073616, Train Acc: 0.884615 | Val Loss: 0.110074, Val Acc: 0.773196\n",
      "Epoch 27436 - Train Loss: 0.073614, Train Acc: 0.884615 | Val Loss: 0.110074, Val Acc: 0.773196\n",
      "Epoch 27437 - Train Loss: 0.073613, Train Acc: 0.884615 | Val Loss: 0.110073, Val Acc: 0.773196\n",
      "Epoch 27438 - Train Loss: 0.073611, Train Acc: 0.884615 | Val Loss: 0.110073, Val Acc: 0.773196\n",
      "Epoch 27439 - Train Loss: 0.073610, Train Acc: 0.884615 | Val Loss: 0.110073, Val Acc: 0.773196\n",
      "Epoch 27440 - Train Loss: 0.073609, Train Acc: 0.884615 | Val Loss: 0.110072, Val Acc: 0.773196\n",
      "Epoch 27441 - Train Loss: 0.073607, Train Acc: 0.884615 | Val Loss: 0.110072, Val Acc: 0.773196\n",
      "Epoch 27442 - Train Loss: 0.073606, Train Acc: 0.884615 | Val Loss: 0.110072, Val Acc: 0.773196\n",
      "Epoch 27443 - Train Loss: 0.073605, Train Acc: 0.884615 | Val Loss: 0.110071, Val Acc: 0.773196\n",
      "Epoch 27444 - Train Loss: 0.073603, Train Acc: 0.884615 | Val Loss: 0.110071, Val Acc: 0.773196\n",
      "Epoch 27445 - Train Loss: 0.073602, Train Acc: 0.884615 | Val Loss: 0.110070, Val Acc: 0.773196\n",
      "Epoch 27446 - Train Loss: 0.073600, Train Acc: 0.884615 | Val Loss: 0.110070, Val Acc: 0.773196\n",
      "Epoch 27447 - Train Loss: 0.073599, Train Acc: 0.884615 | Val Loss: 0.110070, Val Acc: 0.773196\n",
      "Epoch 27448 - Train Loss: 0.073598, Train Acc: 0.884615 | Val Loss: 0.110069, Val Acc: 0.773196\n",
      "Epoch 27449 - Train Loss: 0.073596, Train Acc: 0.884615 | Val Loss: 0.110069, Val Acc: 0.773196\n",
      "Epoch 27450 - Train Loss: 0.073595, Train Acc: 0.884615 | Val Loss: 0.110068, Val Acc: 0.773196\n",
      "Epoch 27451 - Train Loss: 0.073594, Train Acc: 0.884615 | Val Loss: 0.110068, Val Acc: 0.773196\n",
      "Epoch 27452 - Train Loss: 0.073592, Train Acc: 0.884615 | Val Loss: 0.110068, Val Acc: 0.773196\n",
      "Epoch 27453 - Train Loss: 0.073591, Train Acc: 0.884615 | Val Loss: 0.110067, Val Acc: 0.773196\n",
      "Epoch 27454 - Train Loss: 0.073589, Train Acc: 0.884615 | Val Loss: 0.110067, Val Acc: 0.773196\n",
      "Epoch 27455 - Train Loss: 0.073588, Train Acc: 0.884615 | Val Loss: 0.110067, Val Acc: 0.773196\n",
      "Epoch 27456 - Train Loss: 0.073587, Train Acc: 0.884615 | Val Loss: 0.110066, Val Acc: 0.773196\n",
      "Epoch 27457 - Train Loss: 0.073585, Train Acc: 0.884615 | Val Loss: 0.110066, Val Acc: 0.773196\n",
      "Epoch 27458 - Train Loss: 0.073584, Train Acc: 0.884615 | Val Loss: 0.110065, Val Acc: 0.773196\n",
      "Epoch 27459 - Train Loss: 0.073582, Train Acc: 0.884615 | Val Loss: 0.110065, Val Acc: 0.773196\n",
      "Epoch 27460 - Train Loss: 0.073581, Train Acc: 0.884615 | Val Loss: 0.110065, Val Acc: 0.773196\n",
      "Epoch 27461 - Train Loss: 0.073580, Train Acc: 0.884615 | Val Loss: 0.110064, Val Acc: 0.773196\n",
      "Epoch 27462 - Train Loss: 0.073578, Train Acc: 0.884615 | Val Loss: 0.110064, Val Acc: 0.773196\n",
      "Epoch 27463 - Train Loss: 0.073577, Train Acc: 0.884615 | Val Loss: 0.110063, Val Acc: 0.773196\n",
      "Epoch 27464 - Train Loss: 0.073576, Train Acc: 0.884615 | Val Loss: 0.110063, Val Acc: 0.773196\n",
      "Epoch 27465 - Train Loss: 0.073574, Train Acc: 0.884615 | Val Loss: 0.110063, Val Acc: 0.773196\n",
      "Epoch 27466 - Train Loss: 0.073573, Train Acc: 0.884615 | Val Loss: 0.110062, Val Acc: 0.773196\n",
      "Epoch 27467 - Train Loss: 0.073571, Train Acc: 0.884615 | Val Loss: 0.110062, Val Acc: 0.773196\n",
      "Epoch 27468 - Train Loss: 0.073570, Train Acc: 0.884615 | Val Loss: 0.110062, Val Acc: 0.773196\n",
      "Epoch 27469 - Train Loss: 0.073569, Train Acc: 0.884615 | Val Loss: 0.110061, Val Acc: 0.773196\n",
      "Epoch 27470 - Train Loss: 0.073567, Train Acc: 0.884615 | Val Loss: 0.110061, Val Acc: 0.773196\n",
      "Epoch 27471 - Train Loss: 0.073566, Train Acc: 0.884615 | Val Loss: 0.110060, Val Acc: 0.773196\n",
      "Epoch 27472 - Train Loss: 0.073565, Train Acc: 0.884615 | Val Loss: 0.110060, Val Acc: 0.773196\n",
      "Epoch 27473 - Train Loss: 0.073563, Train Acc: 0.884615 | Val Loss: 0.110060, Val Acc: 0.773196\n",
      "Epoch 27474 - Train Loss: 0.073562, Train Acc: 0.884615 | Val Loss: 0.110059, Val Acc: 0.773196\n",
      "Epoch 27475 - Train Loss: 0.073560, Train Acc: 0.884615 | Val Loss: 0.110059, Val Acc: 0.773196\n",
      "Epoch 27476 - Train Loss: 0.073559, Train Acc: 0.884615 | Val Loss: 0.110059, Val Acc: 0.773196\n",
      "Epoch 27477 - Train Loss: 0.073558, Train Acc: 0.884615 | Val Loss: 0.110058, Val Acc: 0.773196\n",
      "Epoch 27478 - Train Loss: 0.073556, Train Acc: 0.884615 | Val Loss: 0.110058, Val Acc: 0.773196\n",
      "Epoch 27479 - Train Loss: 0.073555, Train Acc: 0.884615 | Val Loss: 0.110057, Val Acc: 0.773196\n",
      "Epoch 27480 - Train Loss: 0.073554, Train Acc: 0.884615 | Val Loss: 0.110057, Val Acc: 0.773196\n",
      "Epoch 27481 - Train Loss: 0.073552, Train Acc: 0.884615 | Val Loss: 0.110057, Val Acc: 0.773196\n",
      "Epoch 27482 - Train Loss: 0.073551, Train Acc: 0.884615 | Val Loss: 0.110056, Val Acc: 0.773196\n",
      "Epoch 27483 - Train Loss: 0.073549, Train Acc: 0.884615 | Val Loss: 0.110056, Val Acc: 0.773196\n",
      "Epoch 27484 - Train Loss: 0.073548, Train Acc: 0.884615 | Val Loss: 0.110055, Val Acc: 0.773196\n",
      "Epoch 27485 - Train Loss: 0.073547, Train Acc: 0.884615 | Val Loss: 0.110055, Val Acc: 0.773196\n",
      "Epoch 27486 - Train Loss: 0.073545, Train Acc: 0.884615 | Val Loss: 0.110055, Val Acc: 0.773196\n",
      "Epoch 27487 - Train Loss: 0.073544, Train Acc: 0.884615 | Val Loss: 0.110054, Val Acc: 0.773196\n",
      "Epoch 27488 - Train Loss: 0.073543, Train Acc: 0.884615 | Val Loss: 0.110054, Val Acc: 0.773196\n",
      "Epoch 27489 - Train Loss: 0.073541, Train Acc: 0.884615 | Val Loss: 0.110054, Val Acc: 0.773196\n",
      "Epoch 27490 - Train Loss: 0.073540, Train Acc: 0.884615 | Val Loss: 0.110053, Val Acc: 0.773196\n",
      "Epoch 27491 - Train Loss: 0.073538, Train Acc: 0.884615 | Val Loss: 0.110053, Val Acc: 0.773196\n",
      "Epoch 27492 - Train Loss: 0.073537, Train Acc: 0.884615 | Val Loss: 0.110052, Val Acc: 0.773196\n",
      "Epoch 27493 - Train Loss: 0.073536, Train Acc: 0.884615 | Val Loss: 0.110052, Val Acc: 0.773196\n",
      "Epoch 27494 - Train Loss: 0.073534, Train Acc: 0.884615 | Val Loss: 0.110052, Val Acc: 0.773196\n",
      "Epoch 27495 - Train Loss: 0.073533, Train Acc: 0.884615 | Val Loss: 0.110051, Val Acc: 0.773196\n",
      "Epoch 27496 - Train Loss: 0.073532, Train Acc: 0.884615 | Val Loss: 0.110051, Val Acc: 0.773196\n",
      "Epoch 27497 - Train Loss: 0.073530, Train Acc: 0.884615 | Val Loss: 0.110051, Val Acc: 0.773196\n",
      "Epoch 27498 - Train Loss: 0.073529, Train Acc: 0.884615 | Val Loss: 0.110050, Val Acc: 0.773196\n",
      "Epoch 27499 - Train Loss: 0.073527, Train Acc: 0.884615 | Val Loss: 0.110050, Val Acc: 0.773196\n",
      "Epoch 27500 - Train Loss: 0.073526, Train Acc: 0.884615 | Val Loss: 0.110049, Val Acc: 0.773196\n",
      "Epoch 27501 - Train Loss: 0.073525, Train Acc: 0.884615 | Val Loss: 0.110049, Val Acc: 0.773196\n",
      "Epoch 27502 - Train Loss: 0.073523, Train Acc: 0.884615 | Val Loss: 0.110049, Val Acc: 0.773196\n",
      "Epoch 27503 - Train Loss: 0.073522, Train Acc: 0.884615 | Val Loss: 0.110048, Val Acc: 0.773196\n",
      "Epoch 27504 - Train Loss: 0.073521, Train Acc: 0.884615 | Val Loss: 0.110048, Val Acc: 0.773196\n",
      "Epoch 27505 - Train Loss: 0.073519, Train Acc: 0.884615 | Val Loss: 0.110047, Val Acc: 0.773196\n",
      "Epoch 27506 - Train Loss: 0.073518, Train Acc: 0.884615 | Val Loss: 0.110047, Val Acc: 0.773196\n",
      "Epoch 27507 - Train Loss: 0.073516, Train Acc: 0.884615 | Val Loss: 0.110047, Val Acc: 0.773196\n",
      "Epoch 27508 - Train Loss: 0.073515, Train Acc: 0.884615 | Val Loss: 0.110046, Val Acc: 0.773196\n",
      "Epoch 27509 - Train Loss: 0.073514, Train Acc: 0.884615 | Val Loss: 0.110046, Val Acc: 0.773196\n",
      "Epoch 27510 - Train Loss: 0.073512, Train Acc: 0.884615 | Val Loss: 0.110046, Val Acc: 0.773196\n",
      "Epoch 27511 - Train Loss: 0.073511, Train Acc: 0.884615 | Val Loss: 0.110045, Val Acc: 0.773196\n",
      "Epoch 27512 - Train Loss: 0.073510, Train Acc: 0.884615 | Val Loss: 0.110045, Val Acc: 0.773196\n",
      "Epoch 27513 - Train Loss: 0.073508, Train Acc: 0.884615 | Val Loss: 0.110044, Val Acc: 0.773196\n",
      "Epoch 27514 - Train Loss: 0.073507, Train Acc: 0.884615 | Val Loss: 0.110044, Val Acc: 0.773196\n",
      "Epoch 27515 - Train Loss: 0.073505, Train Acc: 0.884615 | Val Loss: 0.110044, Val Acc: 0.773196\n",
      "Epoch 27516 - Train Loss: 0.073504, Train Acc: 0.884615 | Val Loss: 0.110043, Val Acc: 0.773196\n",
      "Epoch 27517 - Train Loss: 0.073503, Train Acc: 0.884615 | Val Loss: 0.110043, Val Acc: 0.773196\n",
      "Epoch 27518 - Train Loss: 0.073501, Train Acc: 0.884615 | Val Loss: 0.110043, Val Acc: 0.773196\n",
      "Epoch 27519 - Train Loss: 0.073500, Train Acc: 0.884615 | Val Loss: 0.110042, Val Acc: 0.773196\n",
      "Epoch 27520 - Train Loss: 0.073499, Train Acc: 0.884615 | Val Loss: 0.110042, Val Acc: 0.773196\n",
      "Epoch 27521 - Train Loss: 0.073497, Train Acc: 0.884615 | Val Loss: 0.110041, Val Acc: 0.773196\n",
      "Epoch 27522 - Train Loss: 0.073496, Train Acc: 0.884615 | Val Loss: 0.110041, Val Acc: 0.773196\n",
      "Epoch 27523 - Train Loss: 0.073494, Train Acc: 0.884615 | Val Loss: 0.110041, Val Acc: 0.773196\n",
      "Epoch 27524 - Train Loss: 0.073493, Train Acc: 0.884615 | Val Loss: 0.110040, Val Acc: 0.773196\n",
      "Epoch 27525 - Train Loss: 0.073492, Train Acc: 0.884615 | Val Loss: 0.110040, Val Acc: 0.773196\n",
      "Epoch 27526 - Train Loss: 0.073490, Train Acc: 0.884615 | Val Loss: 0.110040, Val Acc: 0.773196\n",
      "Epoch 27527 - Train Loss: 0.073489, Train Acc: 0.884615 | Val Loss: 0.110039, Val Acc: 0.773196\n",
      "Epoch 27528 - Train Loss: 0.073488, Train Acc: 0.884615 | Val Loss: 0.110039, Val Acc: 0.773196\n",
      "Epoch 27529 - Train Loss: 0.073486, Train Acc: 0.884615 | Val Loss: 0.110038, Val Acc: 0.773196\n",
      "Epoch 27530 - Train Loss: 0.073485, Train Acc: 0.884615 | Val Loss: 0.110038, Val Acc: 0.773196\n",
      "Epoch 27531 - Train Loss: 0.073483, Train Acc: 0.884615 | Val Loss: 0.110038, Val Acc: 0.773196\n",
      "Epoch 27532 - Train Loss: 0.073482, Train Acc: 0.884615 | Val Loss: 0.110037, Val Acc: 0.773196\n",
      "Epoch 27533 - Train Loss: 0.073481, Train Acc: 0.884615 | Val Loss: 0.110037, Val Acc: 0.773196\n",
      "Epoch 27534 - Train Loss: 0.073479, Train Acc: 0.884615 | Val Loss: 0.110037, Val Acc: 0.773196\n",
      "Epoch 27535 - Train Loss: 0.073478, Train Acc: 0.884615 | Val Loss: 0.110036, Val Acc: 0.773196\n",
      "Epoch 27536 - Train Loss: 0.073477, Train Acc: 0.884615 | Val Loss: 0.110036, Val Acc: 0.773196\n",
      "Epoch 27537 - Train Loss: 0.073475, Train Acc: 0.884615 | Val Loss: 0.110035, Val Acc: 0.773196\n",
      "Epoch 27538 - Train Loss: 0.073474, Train Acc: 0.884615 | Val Loss: 0.110035, Val Acc: 0.773196\n",
      "Epoch 27539 - Train Loss: 0.073472, Train Acc: 0.884615 | Val Loss: 0.110035, Val Acc: 0.773196\n",
      "Epoch 27540 - Train Loss: 0.073471, Train Acc: 0.884615 | Val Loss: 0.110034, Val Acc: 0.773196\n",
      "Epoch 27541 - Train Loss: 0.073470, Train Acc: 0.884615 | Val Loss: 0.110034, Val Acc: 0.773196\n",
      "Epoch 27542 - Train Loss: 0.073468, Train Acc: 0.884615 | Val Loss: 0.110034, Val Acc: 0.773196\n",
      "Epoch 27543 - Train Loss: 0.073467, Train Acc: 0.884615 | Val Loss: 0.110033, Val Acc: 0.773196\n",
      "Epoch 27544 - Train Loss: 0.073466, Train Acc: 0.884615 | Val Loss: 0.110033, Val Acc: 0.773196\n",
      "Epoch 27545 - Train Loss: 0.073464, Train Acc: 0.884615 | Val Loss: 0.110032, Val Acc: 0.773196\n",
      "Epoch 27546 - Train Loss: 0.073463, Train Acc: 0.884615 | Val Loss: 0.110032, Val Acc: 0.773196\n",
      "Epoch 27547 - Train Loss: 0.073461, Train Acc: 0.884615 | Val Loss: 0.110032, Val Acc: 0.773196\n",
      "Epoch 27548 - Train Loss: 0.073460, Train Acc: 0.884615 | Val Loss: 0.110031, Val Acc: 0.773196\n",
      "Epoch 27549 - Train Loss: 0.073459, Train Acc: 0.884615 | Val Loss: 0.110031, Val Acc: 0.773196\n",
      "Epoch 27550 - Train Loss: 0.073457, Train Acc: 0.884615 | Val Loss: 0.110030, Val Acc: 0.773196\n",
      "Epoch 27551 - Train Loss: 0.073456, Train Acc: 0.884615 | Val Loss: 0.110030, Val Acc: 0.773196\n",
      "Epoch 27552 - Train Loss: 0.073455, Train Acc: 0.884615 | Val Loss: 0.110030, Val Acc: 0.773196\n",
      "Epoch 27553 - Train Loss: 0.073453, Train Acc: 0.884615 | Val Loss: 0.110029, Val Acc: 0.773196\n",
      "Epoch 27554 - Train Loss: 0.073452, Train Acc: 0.884615 | Val Loss: 0.110029, Val Acc: 0.773196\n",
      "Epoch 27555 - Train Loss: 0.073450, Train Acc: 0.884615 | Val Loss: 0.110029, Val Acc: 0.773196\n",
      "Epoch 27556 - Train Loss: 0.073449, Train Acc: 0.884615 | Val Loss: 0.110028, Val Acc: 0.773196\n",
      "Epoch 27557 - Train Loss: 0.073448, Train Acc: 0.884615 | Val Loss: 0.110028, Val Acc: 0.773196\n",
      "Epoch 27558 - Train Loss: 0.073446, Train Acc: 0.884615 | Val Loss: 0.110027, Val Acc: 0.773196\n",
      "Epoch 27559 - Train Loss: 0.073445, Train Acc: 0.884615 | Val Loss: 0.110027, Val Acc: 0.773196\n",
      "Epoch 27560 - Train Loss: 0.073444, Train Acc: 0.884615 | Val Loss: 0.110027, Val Acc: 0.773196\n",
      "Epoch 27561 - Train Loss: 0.073442, Train Acc: 0.884615 | Val Loss: 0.110026, Val Acc: 0.773196\n",
      "Epoch 27562 - Train Loss: 0.073441, Train Acc: 0.884615 | Val Loss: 0.110026, Val Acc: 0.773196\n",
      "Epoch 27563 - Train Loss: 0.073439, Train Acc: 0.884615 | Val Loss: 0.110026, Val Acc: 0.773196\n",
      "Epoch 27564 - Train Loss: 0.073438, Train Acc: 0.884615 | Val Loss: 0.110025, Val Acc: 0.773196\n",
      "Epoch 27565 - Train Loss: 0.073437, Train Acc: 0.884615 | Val Loss: 0.110025, Val Acc: 0.773196\n",
      "Epoch 27566 - Train Loss: 0.073435, Train Acc: 0.884615 | Val Loss: 0.110024, Val Acc: 0.773196\n",
      "Epoch 27567 - Train Loss: 0.073434, Train Acc: 0.884615 | Val Loss: 0.110024, Val Acc: 0.773196\n",
      "Epoch 27568 - Train Loss: 0.073433, Train Acc: 0.884615 | Val Loss: 0.110024, Val Acc: 0.773196\n",
      "Epoch 27569 - Train Loss: 0.073431, Train Acc: 0.884615 | Val Loss: 0.110023, Val Acc: 0.773196\n",
      "Epoch 27570 - Train Loss: 0.073430, Train Acc: 0.884615 | Val Loss: 0.110023, Val Acc: 0.773196\n",
      "Epoch 27571 - Train Loss: 0.073429, Train Acc: 0.884615 | Val Loss: 0.110023, Val Acc: 0.773196\n",
      "Epoch 27572 - Train Loss: 0.073427, Train Acc: 0.884615 | Val Loss: 0.110022, Val Acc: 0.773196\n",
      "Epoch 27573 - Train Loss: 0.073426, Train Acc: 0.884615 | Val Loss: 0.110022, Val Acc: 0.773196\n",
      "Epoch 27574 - Train Loss: 0.073424, Train Acc: 0.884615 | Val Loss: 0.110021, Val Acc: 0.773196\n",
      "Epoch 27575 - Train Loss: 0.073423, Train Acc: 0.884615 | Val Loss: 0.110021, Val Acc: 0.773196\n",
      "Epoch 27576 - Train Loss: 0.073422, Train Acc: 0.884615 | Val Loss: 0.110021, Val Acc: 0.773196\n",
      "Epoch 27577 - Train Loss: 0.073420, Train Acc: 0.884615 | Val Loss: 0.110020, Val Acc: 0.773196\n",
      "Epoch 27578 - Train Loss: 0.073419, Train Acc: 0.884615 | Val Loss: 0.110020, Val Acc: 0.773196\n",
      "Epoch 27579 - Train Loss: 0.073418, Train Acc: 0.884615 | Val Loss: 0.110020, Val Acc: 0.773196\n",
      "Epoch 27580 - Train Loss: 0.073416, Train Acc: 0.884615 | Val Loss: 0.110019, Val Acc: 0.773196\n",
      "Epoch 27581 - Train Loss: 0.073415, Train Acc: 0.884615 | Val Loss: 0.110019, Val Acc: 0.773196\n",
      "Epoch 27582 - Train Loss: 0.073413, Train Acc: 0.884615 | Val Loss: 0.110018, Val Acc: 0.773196\n",
      "Epoch 27583 - Train Loss: 0.073412, Train Acc: 0.884615 | Val Loss: 0.110018, Val Acc: 0.773196\n",
      "Epoch 27584 - Train Loss: 0.073411, Train Acc: 0.884615 | Val Loss: 0.110018, Val Acc: 0.773196\n",
      "Epoch 27585 - Train Loss: 0.073409, Train Acc: 0.884615 | Val Loss: 0.110017, Val Acc: 0.773196\n",
      "Epoch 27586 - Train Loss: 0.073408, Train Acc: 0.884615 | Val Loss: 0.110017, Val Acc: 0.773196\n",
      "Epoch 27587 - Train Loss: 0.073407, Train Acc: 0.884615 | Val Loss: 0.110017, Val Acc: 0.773196\n",
      "Epoch 27588 - Train Loss: 0.073405, Train Acc: 0.884615 | Val Loss: 0.110016, Val Acc: 0.773196\n",
      "Epoch 27589 - Train Loss: 0.073404, Train Acc: 0.884615 | Val Loss: 0.110016, Val Acc: 0.773196\n",
      "Epoch 27590 - Train Loss: 0.073402, Train Acc: 0.884615 | Val Loss: 0.110015, Val Acc: 0.773196\n",
      "Epoch 27591 - Train Loss: 0.073401, Train Acc: 0.884615 | Val Loss: 0.110015, Val Acc: 0.773196\n",
      "Epoch 27592 - Train Loss: 0.073400, Train Acc: 0.884615 | Val Loss: 0.110015, Val Acc: 0.773196\n",
      "Epoch 27593 - Train Loss: 0.073398, Train Acc: 0.884615 | Val Loss: 0.110014, Val Acc: 0.773196\n",
      "Epoch 27594 - Train Loss: 0.073397, Train Acc: 0.884615 | Val Loss: 0.110014, Val Acc: 0.773196\n",
      "Epoch 27595 - Train Loss: 0.073396, Train Acc: 0.884615 | Val Loss: 0.110014, Val Acc: 0.773196\n",
      "Epoch 27596 - Train Loss: 0.073394, Train Acc: 0.884615 | Val Loss: 0.110013, Val Acc: 0.773196\n",
      "Epoch 27597 - Train Loss: 0.073393, Train Acc: 0.884615 | Val Loss: 0.110013, Val Acc: 0.773196\n",
      "Epoch 27598 - Train Loss: 0.073392, Train Acc: 0.884615 | Val Loss: 0.110012, Val Acc: 0.773196\n",
      "Epoch 27599 - Train Loss: 0.073390, Train Acc: 0.884615 | Val Loss: 0.110012, Val Acc: 0.773196\n",
      "Epoch 27600 - Train Loss: 0.073389, Train Acc: 0.884615 | Val Loss: 0.110012, Val Acc: 0.773196\n",
      "Epoch 27601 - Train Loss: 0.073387, Train Acc: 0.884615 | Val Loss: 0.110011, Val Acc: 0.773196\n",
      "Epoch 27602 - Train Loss: 0.073386, Train Acc: 0.884615 | Val Loss: 0.110011, Val Acc: 0.773196\n",
      "Epoch 27603 - Train Loss: 0.073385, Train Acc: 0.884615 | Val Loss: 0.110011, Val Acc: 0.773196\n",
      "Epoch 27604 - Train Loss: 0.073383, Train Acc: 0.884615 | Val Loss: 0.110010, Val Acc: 0.773196\n",
      "Epoch 27605 - Train Loss: 0.073382, Train Acc: 0.884615 | Val Loss: 0.110010, Val Acc: 0.773196\n",
      "Epoch 27606 - Train Loss: 0.073381, Train Acc: 0.884615 | Val Loss: 0.110009, Val Acc: 0.773196\n",
      "Epoch 27607 - Train Loss: 0.073379, Train Acc: 0.884615 | Val Loss: 0.110009, Val Acc: 0.773196\n",
      "Epoch 27608 - Train Loss: 0.073378, Train Acc: 0.884615 | Val Loss: 0.110009, Val Acc: 0.773196\n",
      "Epoch 27609 - Train Loss: 0.073376, Train Acc: 0.884615 | Val Loss: 0.110008, Val Acc: 0.773196\n",
      "Epoch 27610 - Train Loss: 0.073375, Train Acc: 0.884615 | Val Loss: 0.110008, Val Acc: 0.773196\n",
      "Epoch 27611 - Train Loss: 0.073374, Train Acc: 0.884615 | Val Loss: 0.110008, Val Acc: 0.773196\n",
      "Epoch 27612 - Train Loss: 0.073372, Train Acc: 0.884615 | Val Loss: 0.110007, Val Acc: 0.773196\n",
      "Epoch 27613 - Train Loss: 0.073371, Train Acc: 0.884615 | Val Loss: 0.110007, Val Acc: 0.773196\n",
      "Epoch 27614 - Train Loss: 0.073370, Train Acc: 0.884615 | Val Loss: 0.110007, Val Acc: 0.773196\n",
      "Epoch 27615 - Train Loss: 0.073368, Train Acc: 0.884615 | Val Loss: 0.110006, Val Acc: 0.773196\n",
      "Epoch 27616 - Train Loss: 0.073367, Train Acc: 0.884615 | Val Loss: 0.110006, Val Acc: 0.773196\n",
      "Epoch 27617 - Train Loss: 0.073366, Train Acc: 0.884615 | Val Loss: 0.110005, Val Acc: 0.773196\n",
      "Epoch 27618 - Train Loss: 0.073364, Train Acc: 0.884615 | Val Loss: 0.110005, Val Acc: 0.773196\n",
      "Epoch 27619 - Train Loss: 0.073363, Train Acc: 0.884615 | Val Loss: 0.110005, Val Acc: 0.773196\n",
      "Epoch 27620 - Train Loss: 0.073361, Train Acc: 0.884615 | Val Loss: 0.110004, Val Acc: 0.773196\n",
      "Epoch 27621 - Train Loss: 0.073360, Train Acc: 0.884615 | Val Loss: 0.110004, Val Acc: 0.773196\n",
      "Epoch 27622 - Train Loss: 0.073359, Train Acc: 0.884615 | Val Loss: 0.110004, Val Acc: 0.773196\n",
      "Epoch 27623 - Train Loss: 0.073357, Train Acc: 0.884615 | Val Loss: 0.110003, Val Acc: 0.773196\n",
      "Epoch 27624 - Train Loss: 0.073356, Train Acc: 0.884615 | Val Loss: 0.110003, Val Acc: 0.773196\n",
      "Epoch 27625 - Train Loss: 0.073355, Train Acc: 0.884615 | Val Loss: 0.110002, Val Acc: 0.773196\n",
      "Epoch 27626 - Train Loss: 0.073353, Train Acc: 0.884615 | Val Loss: 0.110002, Val Acc: 0.773196\n",
      "Epoch 27627 - Train Loss: 0.073352, Train Acc: 0.884615 | Val Loss: 0.110002, Val Acc: 0.773196\n",
      "Epoch 27628 - Train Loss: 0.073350, Train Acc: 0.884615 | Val Loss: 0.110001, Val Acc: 0.773196\n",
      "Epoch 27629 - Train Loss: 0.073349, Train Acc: 0.884615 | Val Loss: 0.110001, Val Acc: 0.773196\n",
      "Epoch 27630 - Train Loss: 0.073348, Train Acc: 0.884615 | Val Loss: 0.110001, Val Acc: 0.773196\n",
      "Epoch 27631 - Train Loss: 0.073346, Train Acc: 0.884615 | Val Loss: 0.110000, Val Acc: 0.773196\n",
      "Epoch 27632 - Train Loss: 0.073345, Train Acc: 0.884615 | Val Loss: 0.110000, Val Acc: 0.773196\n",
      "Epoch 27633 - Train Loss: 0.073344, Train Acc: 0.884615 | Val Loss: 0.109999, Val Acc: 0.773196\n",
      "Epoch 27634 - Train Loss: 0.073342, Train Acc: 0.884615 | Val Loss: 0.109999, Val Acc: 0.773196\n",
      "Epoch 27635 - Train Loss: 0.073341, Train Acc: 0.884615 | Val Loss: 0.109999, Val Acc: 0.773196\n",
      "Epoch 27636 - Train Loss: 0.073340, Train Acc: 0.884615 | Val Loss: 0.109998, Val Acc: 0.773196\n",
      "Epoch 27637 - Train Loss: 0.073338, Train Acc: 0.884615 | Val Loss: 0.109998, Val Acc: 0.773196\n",
      "Epoch 27638 - Train Loss: 0.073337, Train Acc: 0.884615 | Val Loss: 0.109998, Val Acc: 0.773196\n",
      "Epoch 27639 - Train Loss: 0.073335, Train Acc: 0.884615 | Val Loss: 0.109997, Val Acc: 0.773196\n",
      "Epoch 27640 - Train Loss: 0.073334, Train Acc: 0.884615 | Val Loss: 0.109997, Val Acc: 0.773196\n",
      "Epoch 27641 - Train Loss: 0.073333, Train Acc: 0.884615 | Val Loss: 0.109996, Val Acc: 0.773196\n",
      "Epoch 27642 - Train Loss: 0.073331, Train Acc: 0.884615 | Val Loss: 0.109996, Val Acc: 0.773196\n",
      "Epoch 27643 - Train Loss: 0.073330, Train Acc: 0.884615 | Val Loss: 0.109996, Val Acc: 0.773196\n",
      "Epoch 27644 - Train Loss: 0.073329, Train Acc: 0.884615 | Val Loss: 0.109995, Val Acc: 0.773196\n",
      "Epoch 27645 - Train Loss: 0.073327, Train Acc: 0.884615 | Val Loss: 0.109995, Val Acc: 0.773196\n",
      "Epoch 27646 - Train Loss: 0.073326, Train Acc: 0.884615 | Val Loss: 0.109995, Val Acc: 0.773196\n",
      "Epoch 27647 - Train Loss: 0.073325, Train Acc: 0.884615 | Val Loss: 0.109994, Val Acc: 0.773196\n",
      "Epoch 27648 - Train Loss: 0.073323, Train Acc: 0.884615 | Val Loss: 0.109994, Val Acc: 0.773196\n",
      "Epoch 27649 - Train Loss: 0.073322, Train Acc: 0.884615 | Val Loss: 0.109993, Val Acc: 0.773196\n",
      "Epoch 27650 - Train Loss: 0.073320, Train Acc: 0.884615 | Val Loss: 0.109993, Val Acc: 0.773196\n",
      "Epoch 27651 - Train Loss: 0.073319, Train Acc: 0.884615 | Val Loss: 0.109993, Val Acc: 0.773196\n",
      "Epoch 27652 - Train Loss: 0.073318, Train Acc: 0.884615 | Val Loss: 0.109992, Val Acc: 0.773196\n",
      "Epoch 27653 - Train Loss: 0.073316, Train Acc: 0.884615 | Val Loss: 0.109992, Val Acc: 0.773196\n",
      "Epoch 27654 - Train Loss: 0.073315, Train Acc: 0.884615 | Val Loss: 0.109992, Val Acc: 0.773196\n",
      "Epoch 27655 - Train Loss: 0.073314, Train Acc: 0.884615 | Val Loss: 0.109991, Val Acc: 0.773196\n",
      "Epoch 27656 - Train Loss: 0.073312, Train Acc: 0.884615 | Val Loss: 0.109991, Val Acc: 0.773196\n",
      "Epoch 27657 - Train Loss: 0.073311, Train Acc: 0.884615 | Val Loss: 0.109991, Val Acc: 0.773196\n",
      "Epoch 27658 - Train Loss: 0.073310, Train Acc: 0.884615 | Val Loss: 0.109990, Val Acc: 0.773196\n",
      "Epoch 27659 - Train Loss: 0.073308, Train Acc: 0.884615 | Val Loss: 0.109990, Val Acc: 0.773196\n",
      "Epoch 27660 - Train Loss: 0.073307, Train Acc: 0.884615 | Val Loss: 0.109989, Val Acc: 0.773196\n",
      "Epoch 27661 - Train Loss: 0.073305, Train Acc: 0.884615 | Val Loss: 0.109989, Val Acc: 0.773196\n",
      "Epoch 27662 - Train Loss: 0.073304, Train Acc: 0.884615 | Val Loss: 0.109989, Val Acc: 0.773196\n",
      "Epoch 27663 - Train Loss: 0.073303, Train Acc: 0.884615 | Val Loss: 0.109988, Val Acc: 0.773196\n",
      "Epoch 27664 - Train Loss: 0.073301, Train Acc: 0.884615 | Val Loss: 0.109988, Val Acc: 0.773196\n",
      "Epoch 27665 - Train Loss: 0.073300, Train Acc: 0.884615 | Val Loss: 0.109988, Val Acc: 0.773196\n",
      "Epoch 27666 - Train Loss: 0.073299, Train Acc: 0.884615 | Val Loss: 0.109987, Val Acc: 0.773196\n",
      "Epoch 27667 - Train Loss: 0.073297, Train Acc: 0.884615 | Val Loss: 0.109987, Val Acc: 0.773196\n",
      "Epoch 27668 - Train Loss: 0.073296, Train Acc: 0.884615 | Val Loss: 0.109986, Val Acc: 0.773196\n",
      "Epoch 27669 - Train Loss: 0.073295, Train Acc: 0.884615 | Val Loss: 0.109986, Val Acc: 0.773196\n",
      "Epoch 27670 - Train Loss: 0.073293, Train Acc: 0.884615 | Val Loss: 0.109986, Val Acc: 0.773196\n",
      "Epoch 27671 - Train Loss: 0.073292, Train Acc: 0.884615 | Val Loss: 0.109985, Val Acc: 0.773196\n",
      "Epoch 27672 - Train Loss: 0.073290, Train Acc: 0.884615 | Val Loss: 0.109985, Val Acc: 0.773196\n",
      "Epoch 27673 - Train Loss: 0.073289, Train Acc: 0.884615 | Val Loss: 0.109985, Val Acc: 0.773196\n",
      "Epoch 27674 - Train Loss: 0.073288, Train Acc: 0.884615 | Val Loss: 0.109984, Val Acc: 0.773196\n",
      "Epoch 27675 - Train Loss: 0.073286, Train Acc: 0.884615 | Val Loss: 0.109984, Val Acc: 0.773196\n",
      "Epoch 27676 - Train Loss: 0.073285, Train Acc: 0.884615 | Val Loss: 0.109983, Val Acc: 0.773196\n",
      "Epoch 27677 - Train Loss: 0.073284, Train Acc: 0.884615 | Val Loss: 0.109983, Val Acc: 0.773196\n",
      "Epoch 27678 - Train Loss: 0.073282, Train Acc: 0.884615 | Val Loss: 0.109983, Val Acc: 0.773196\n",
      "Epoch 27679 - Train Loss: 0.073281, Train Acc: 0.884615 | Val Loss: 0.109982, Val Acc: 0.773196\n",
      "Epoch 27680 - Train Loss: 0.073280, Train Acc: 0.884615 | Val Loss: 0.109982, Val Acc: 0.773196\n",
      "Epoch 27681 - Train Loss: 0.073278, Train Acc: 0.884615 | Val Loss: 0.109982, Val Acc: 0.773196\n",
      "Epoch 27682 - Train Loss: 0.073277, Train Acc: 0.884615 | Val Loss: 0.109981, Val Acc: 0.773196\n",
      "Epoch 27683 - Train Loss: 0.073275, Train Acc: 0.884615 | Val Loss: 0.109981, Val Acc: 0.773196\n",
      "Epoch 27684 - Train Loss: 0.073274, Train Acc: 0.884615 | Val Loss: 0.109981, Val Acc: 0.773196\n",
      "Epoch 27685 - Train Loss: 0.073273, Train Acc: 0.884615 | Val Loss: 0.109980, Val Acc: 0.773196\n",
      "Epoch 27686 - Train Loss: 0.073271, Train Acc: 0.884615 | Val Loss: 0.109980, Val Acc: 0.773196\n",
      "Epoch 27687 - Train Loss: 0.073270, Train Acc: 0.884615 | Val Loss: 0.109979, Val Acc: 0.773196\n",
      "Epoch 27688 - Train Loss: 0.073269, Train Acc: 0.884615 | Val Loss: 0.109979, Val Acc: 0.773196\n",
      "Epoch 27689 - Train Loss: 0.073267, Train Acc: 0.884615 | Val Loss: 0.109979, Val Acc: 0.773196\n",
      "Epoch 27690 - Train Loss: 0.073266, Train Acc: 0.884615 | Val Loss: 0.109978, Val Acc: 0.773196\n",
      "Epoch 27691 - Train Loss: 0.073265, Train Acc: 0.884615 | Val Loss: 0.109978, Val Acc: 0.773196\n",
      "Epoch 27692 - Train Loss: 0.073263, Train Acc: 0.884615 | Val Loss: 0.109978, Val Acc: 0.773196\n",
      "Epoch 27693 - Train Loss: 0.073262, Train Acc: 0.884615 | Val Loss: 0.109977, Val Acc: 0.773196\n",
      "Epoch 27694 - Train Loss: 0.073260, Train Acc: 0.884615 | Val Loss: 0.109977, Val Acc: 0.773196\n",
      "Epoch 27695 - Train Loss: 0.073259, Train Acc: 0.884615 | Val Loss: 0.109976, Val Acc: 0.773196\n",
      "Epoch 27696 - Train Loss: 0.073258, Train Acc: 0.884615 | Val Loss: 0.109976, Val Acc: 0.773196\n",
      "Epoch 27697 - Train Loss: 0.073256, Train Acc: 0.884615 | Val Loss: 0.109976, Val Acc: 0.773196\n",
      "Epoch 27698 - Train Loss: 0.073255, Train Acc: 0.884615 | Val Loss: 0.109975, Val Acc: 0.773196\n",
      "Epoch 27699 - Train Loss: 0.073254, Train Acc: 0.884615 | Val Loss: 0.109975, Val Acc: 0.773196\n",
      "Epoch 27700 - Train Loss: 0.073252, Train Acc: 0.884615 | Val Loss: 0.109975, Val Acc: 0.773196\n",
      "Epoch 27701 - Train Loss: 0.073251, Train Acc: 0.884615 | Val Loss: 0.109974, Val Acc: 0.773196\n",
      "Epoch 27702 - Train Loss: 0.073250, Train Acc: 0.884615 | Val Loss: 0.109974, Val Acc: 0.773196\n",
      "Epoch 27703 - Train Loss: 0.073248, Train Acc: 0.884615 | Val Loss: 0.109974, Val Acc: 0.773196\n",
      "Epoch 27704 - Train Loss: 0.073247, Train Acc: 0.884615 | Val Loss: 0.109973, Val Acc: 0.773196\n",
      "Epoch 27705 - Train Loss: 0.073245, Train Acc: 0.884615 | Val Loss: 0.109973, Val Acc: 0.773196\n",
      "Epoch 27706 - Train Loss: 0.073244, Train Acc: 0.884615 | Val Loss: 0.109972, Val Acc: 0.773196\n",
      "Epoch 27707 - Train Loss: 0.073243, Train Acc: 0.884615 | Val Loss: 0.109972, Val Acc: 0.773196\n",
      "Epoch 27708 - Train Loss: 0.073241, Train Acc: 0.884615 | Val Loss: 0.109972, Val Acc: 0.773196\n",
      "Epoch 27709 - Train Loss: 0.073240, Train Acc: 0.884615 | Val Loss: 0.109971, Val Acc: 0.773196\n",
      "Epoch 27710 - Train Loss: 0.073239, Train Acc: 0.884615 | Val Loss: 0.109971, Val Acc: 0.773196\n",
      "Epoch 27711 - Train Loss: 0.073237, Train Acc: 0.884615 | Val Loss: 0.109971, Val Acc: 0.773196\n",
      "Epoch 27712 - Train Loss: 0.073236, Train Acc: 0.884615 | Val Loss: 0.109970, Val Acc: 0.773196\n",
      "Epoch 27713 - Train Loss: 0.073235, Train Acc: 0.884615 | Val Loss: 0.109970, Val Acc: 0.773196\n",
      "Epoch 27714 - Train Loss: 0.073233, Train Acc: 0.884615 | Val Loss: 0.109969, Val Acc: 0.773196\n",
      "Epoch 27715 - Train Loss: 0.073232, Train Acc: 0.884615 | Val Loss: 0.109969, Val Acc: 0.773196\n",
      "Epoch 27716 - Train Loss: 0.073230, Train Acc: 0.884615 | Val Loss: 0.109969, Val Acc: 0.773196\n",
      "Epoch 27717 - Train Loss: 0.073229, Train Acc: 0.884615 | Val Loss: 0.109968, Val Acc: 0.773196\n",
      "Epoch 27718 - Train Loss: 0.073228, Train Acc: 0.884615 | Val Loss: 0.109968, Val Acc: 0.773196\n",
      "Epoch 27719 - Train Loss: 0.073226, Train Acc: 0.884615 | Val Loss: 0.109968, Val Acc: 0.773196\n",
      "Epoch 27720 - Train Loss: 0.073225, Train Acc: 0.884615 | Val Loss: 0.109967, Val Acc: 0.773196\n",
      "Epoch 27721 - Train Loss: 0.073224, Train Acc: 0.884615 | Val Loss: 0.109967, Val Acc: 0.773196\n",
      "Epoch 27722 - Train Loss: 0.073222, Train Acc: 0.884615 | Val Loss: 0.109967, Val Acc: 0.773196\n",
      "Epoch 27723 - Train Loss: 0.073221, Train Acc: 0.884615 | Val Loss: 0.109966, Val Acc: 0.773196\n",
      "Epoch 27724 - Train Loss: 0.073220, Train Acc: 0.884615 | Val Loss: 0.109966, Val Acc: 0.773196\n",
      "Epoch 27725 - Train Loss: 0.073218, Train Acc: 0.884615 | Val Loss: 0.109965, Val Acc: 0.773196\n",
      "Epoch 27726 - Train Loss: 0.073217, Train Acc: 0.884615 | Val Loss: 0.109965, Val Acc: 0.773196\n",
      "Epoch 27727 - Train Loss: 0.073216, Train Acc: 0.884615 | Val Loss: 0.109965, Val Acc: 0.773196\n",
      "Epoch 27728 - Train Loss: 0.073214, Train Acc: 0.884615 | Val Loss: 0.109964, Val Acc: 0.773196\n",
      "Epoch 27729 - Train Loss: 0.073213, Train Acc: 0.884615 | Val Loss: 0.109964, Val Acc: 0.773196\n",
      "Epoch 27730 - Train Loss: 0.073211, Train Acc: 0.884615 | Val Loss: 0.109964, Val Acc: 0.773196\n",
      "Epoch 27731 - Train Loss: 0.073210, Train Acc: 0.884615 | Val Loss: 0.109963, Val Acc: 0.773196\n",
      "Epoch 27732 - Train Loss: 0.073209, Train Acc: 0.884615 | Val Loss: 0.109963, Val Acc: 0.773196\n",
      "Epoch 27733 - Train Loss: 0.073207, Train Acc: 0.884615 | Val Loss: 0.109963, Val Acc: 0.773196\n",
      "Epoch 27734 - Train Loss: 0.073206, Train Acc: 0.884615 | Val Loss: 0.109962, Val Acc: 0.773196\n",
      "Epoch 27735 - Train Loss: 0.073205, Train Acc: 0.884615 | Val Loss: 0.109962, Val Acc: 0.773196\n",
      "Epoch 27736 - Train Loss: 0.073203, Train Acc: 0.884615 | Val Loss: 0.109961, Val Acc: 0.773196\n",
      "Epoch 27737 - Train Loss: 0.073202, Train Acc: 0.884615 | Val Loss: 0.109961, Val Acc: 0.773196\n",
      "Epoch 27738 - Train Loss: 0.073201, Train Acc: 0.884615 | Val Loss: 0.109961, Val Acc: 0.773196\n",
      "Epoch 27739 - Train Loss: 0.073199, Train Acc: 0.884615 | Val Loss: 0.109960, Val Acc: 0.773196\n",
      "Epoch 27740 - Train Loss: 0.073198, Train Acc: 0.884615 | Val Loss: 0.109960, Val Acc: 0.773196\n",
      "Epoch 27741 - Train Loss: 0.073197, Train Acc: 0.884615 | Val Loss: 0.109960, Val Acc: 0.773196\n",
      "Epoch 27742 - Train Loss: 0.073195, Train Acc: 0.884615 | Val Loss: 0.109959, Val Acc: 0.773196\n",
      "Epoch 27743 - Train Loss: 0.073194, Train Acc: 0.884615 | Val Loss: 0.109959, Val Acc: 0.773196\n",
      "Epoch 27744 - Train Loss: 0.073192, Train Acc: 0.884615 | Val Loss: 0.109958, Val Acc: 0.773196\n",
      "Epoch 27745 - Train Loss: 0.073191, Train Acc: 0.884615 | Val Loss: 0.109958, Val Acc: 0.773196\n",
      "Epoch 27746 - Train Loss: 0.073190, Train Acc: 0.884615 | Val Loss: 0.109958, Val Acc: 0.773196\n",
      "Epoch 27747 - Train Loss: 0.073188, Train Acc: 0.884615 | Val Loss: 0.109957, Val Acc: 0.773196\n",
      "Epoch 27748 - Train Loss: 0.073187, Train Acc: 0.884615 | Val Loss: 0.109957, Val Acc: 0.773196\n",
      "Epoch 27749 - Train Loss: 0.073186, Train Acc: 0.884615 | Val Loss: 0.109957, Val Acc: 0.773196\n",
      "Epoch 27750 - Train Loss: 0.073184, Train Acc: 0.884615 | Val Loss: 0.109956, Val Acc: 0.773196\n",
      "Epoch 27751 - Train Loss: 0.073183, Train Acc: 0.884615 | Val Loss: 0.109956, Val Acc: 0.773196\n",
      "Epoch 27752 - Train Loss: 0.073182, Train Acc: 0.884615 | Val Loss: 0.109956, Val Acc: 0.773196\n",
      "Epoch 27753 - Train Loss: 0.073180, Train Acc: 0.884615 | Val Loss: 0.109955, Val Acc: 0.773196\n",
      "Epoch 27754 - Train Loss: 0.073179, Train Acc: 0.884615 | Val Loss: 0.109955, Val Acc: 0.773196\n",
      "Epoch 27755 - Train Loss: 0.073177, Train Acc: 0.884615 | Val Loss: 0.109954, Val Acc: 0.773196\n",
      "Epoch 27756 - Train Loss: 0.073176, Train Acc: 0.884615 | Val Loss: 0.109954, Val Acc: 0.773196\n",
      "Epoch 27757 - Train Loss: 0.073175, Train Acc: 0.884615 | Val Loss: 0.109954, Val Acc: 0.773196\n",
      "Epoch 27758 - Train Loss: 0.073173, Train Acc: 0.884615 | Val Loss: 0.109953, Val Acc: 0.773196\n",
      "Epoch 27759 - Train Loss: 0.073172, Train Acc: 0.884615 | Val Loss: 0.109953, Val Acc: 0.773196\n",
      "Epoch 27760 - Train Loss: 0.073171, Train Acc: 0.884615 | Val Loss: 0.109953, Val Acc: 0.773196\n",
      "Epoch 27761 - Train Loss: 0.073169, Train Acc: 0.884615 | Val Loss: 0.109952, Val Acc: 0.773196\n",
      "Epoch 27762 - Train Loss: 0.073168, Train Acc: 0.884615 | Val Loss: 0.109952, Val Acc: 0.773196\n",
      "Epoch 27763 - Train Loss: 0.073167, Train Acc: 0.884615 | Val Loss: 0.109952, Val Acc: 0.773196\n",
      "Epoch 27764 - Train Loss: 0.073165, Train Acc: 0.884615 | Val Loss: 0.109951, Val Acc: 0.773196\n",
      "Epoch 27765 - Train Loss: 0.073164, Train Acc: 0.884615 | Val Loss: 0.109951, Val Acc: 0.773196\n",
      "Epoch 27766 - Train Loss: 0.073163, Train Acc: 0.884615 | Val Loss: 0.109950, Val Acc: 0.773196\n",
      "Epoch 27767 - Train Loss: 0.073161, Train Acc: 0.884615 | Val Loss: 0.109950, Val Acc: 0.773196\n",
      "Epoch 27768 - Train Loss: 0.073160, Train Acc: 0.884615 | Val Loss: 0.109950, Val Acc: 0.773196\n",
      "Epoch 27769 - Train Loss: 0.073158, Train Acc: 0.884615 | Val Loss: 0.109949, Val Acc: 0.773196\n",
      "Epoch 27770 - Train Loss: 0.073157, Train Acc: 0.884615 | Val Loss: 0.109949, Val Acc: 0.773196\n",
      "Epoch 27771 - Train Loss: 0.073156, Train Acc: 0.884615 | Val Loss: 0.109949, Val Acc: 0.773196\n",
      "Epoch 27772 - Train Loss: 0.073154, Train Acc: 0.884615 | Val Loss: 0.109948, Val Acc: 0.773196\n",
      "Epoch 27773 - Train Loss: 0.073153, Train Acc: 0.884615 | Val Loss: 0.109948, Val Acc: 0.773196\n",
      "Epoch 27774 - Train Loss: 0.073152, Train Acc: 0.884615 | Val Loss: 0.109948, Val Acc: 0.773196\n",
      "Epoch 27775 - Train Loss: 0.073150, Train Acc: 0.884615 | Val Loss: 0.109947, Val Acc: 0.773196\n",
      "Epoch 27776 - Train Loss: 0.073149, Train Acc: 0.884615 | Val Loss: 0.109947, Val Acc: 0.773196\n",
      "Epoch 27777 - Train Loss: 0.073148, Train Acc: 0.884615 | Val Loss: 0.109946, Val Acc: 0.773196\n",
      "Epoch 27778 - Train Loss: 0.073146, Train Acc: 0.884615 | Val Loss: 0.109946, Val Acc: 0.773196\n",
      "Epoch 27779 - Train Loss: 0.073145, Train Acc: 0.884615 | Val Loss: 0.109946, Val Acc: 0.773196\n",
      "Epoch 27780 - Train Loss: 0.073144, Train Acc: 0.884615 | Val Loss: 0.109945, Val Acc: 0.773196\n",
      "Epoch 27781 - Train Loss: 0.073142, Train Acc: 0.884615 | Val Loss: 0.109945, Val Acc: 0.773196\n",
      "Epoch 27782 - Train Loss: 0.073141, Train Acc: 0.884615 | Val Loss: 0.109945, Val Acc: 0.773196\n",
      "Epoch 27783 - Train Loss: 0.073139, Train Acc: 0.884615 | Val Loss: 0.109944, Val Acc: 0.773196\n",
      "Epoch 27784 - Train Loss: 0.073138, Train Acc: 0.884615 | Val Loss: 0.109944, Val Acc: 0.773196\n",
      "Epoch 27785 - Train Loss: 0.073137, Train Acc: 0.884615 | Val Loss: 0.109944, Val Acc: 0.773196\n",
      "Epoch 27786 - Train Loss: 0.073135, Train Acc: 0.884615 | Val Loss: 0.109943, Val Acc: 0.773196\n",
      "Epoch 27787 - Train Loss: 0.073134, Train Acc: 0.884615 | Val Loss: 0.109943, Val Acc: 0.773196\n",
      "Epoch 27788 - Train Loss: 0.073133, Train Acc: 0.884615 | Val Loss: 0.109942, Val Acc: 0.773196\n",
      "Epoch 27789 - Train Loss: 0.073131, Train Acc: 0.884615 | Val Loss: 0.109942, Val Acc: 0.773196\n",
      "Epoch 27790 - Train Loss: 0.073130, Train Acc: 0.884615 | Val Loss: 0.109942, Val Acc: 0.773196\n",
      "Epoch 27791 - Train Loss: 0.073129, Train Acc: 0.884615 | Val Loss: 0.109941, Val Acc: 0.773196\n",
      "Epoch 27792 - Train Loss: 0.073127, Train Acc: 0.884615 | Val Loss: 0.109941, Val Acc: 0.773196\n",
      "Epoch 27793 - Train Loss: 0.073126, Train Acc: 0.884615 | Val Loss: 0.109941, Val Acc: 0.773196\n",
      "Epoch 27794 - Train Loss: 0.073125, Train Acc: 0.884615 | Val Loss: 0.109940, Val Acc: 0.773196\n",
      "Epoch 27795 - Train Loss: 0.073123, Train Acc: 0.884615 | Val Loss: 0.109940, Val Acc: 0.773196\n",
      "Epoch 27796 - Train Loss: 0.073122, Train Acc: 0.884615 | Val Loss: 0.109940, Val Acc: 0.773196\n",
      "Epoch 27797 - Train Loss: 0.073121, Train Acc: 0.884615 | Val Loss: 0.109939, Val Acc: 0.773196\n",
      "Epoch 27798 - Train Loss: 0.073119, Train Acc: 0.884615 | Val Loss: 0.109939, Val Acc: 0.773196\n",
      "Epoch 27799 - Train Loss: 0.073118, Train Acc: 0.884615 | Val Loss: 0.109938, Val Acc: 0.773196\n",
      "Epoch 27800 - Train Loss: 0.073116, Train Acc: 0.884615 | Val Loss: 0.109938, Val Acc: 0.773196\n",
      "Epoch 27801 - Train Loss: 0.073115, Train Acc: 0.884615 | Val Loss: 0.109938, Val Acc: 0.773196\n",
      "Epoch 27802 - Train Loss: 0.073114, Train Acc: 0.884615 | Val Loss: 0.109937, Val Acc: 0.773196\n",
      "Epoch 27803 - Train Loss: 0.073112, Train Acc: 0.884615 | Val Loss: 0.109937, Val Acc: 0.773196\n",
      "Epoch 27804 - Train Loss: 0.073111, Train Acc: 0.884615 | Val Loss: 0.109937, Val Acc: 0.773196\n",
      "Epoch 27805 - Train Loss: 0.073110, Train Acc: 0.884615 | Val Loss: 0.109936, Val Acc: 0.773196\n",
      "Epoch 27806 - Train Loss: 0.073108, Train Acc: 0.884615 | Val Loss: 0.109936, Val Acc: 0.773196\n",
      "Epoch 27807 - Train Loss: 0.073107, Train Acc: 0.884615 | Val Loss: 0.109936, Val Acc: 0.773196\n",
      "Epoch 27808 - Train Loss: 0.073106, Train Acc: 0.884615 | Val Loss: 0.109935, Val Acc: 0.773196\n",
      "Epoch 27809 - Train Loss: 0.073104, Train Acc: 0.884615 | Val Loss: 0.109935, Val Acc: 0.773196\n",
      "Epoch 27810 - Train Loss: 0.073103, Train Acc: 0.884615 | Val Loss: 0.109934, Val Acc: 0.773196\n",
      "Epoch 27811 - Train Loss: 0.073102, Train Acc: 0.884615 | Val Loss: 0.109934, Val Acc: 0.773196\n",
      "Epoch 27812 - Train Loss: 0.073100, Train Acc: 0.884615 | Val Loss: 0.109934, Val Acc: 0.773196\n",
      "Epoch 27813 - Train Loss: 0.073099, Train Acc: 0.884615 | Val Loss: 0.109933, Val Acc: 0.773196\n",
      "Epoch 27814 - Train Loss: 0.073097, Train Acc: 0.884615 | Val Loss: 0.109933, Val Acc: 0.773196\n",
      "Epoch 27815 - Train Loss: 0.073096, Train Acc: 0.884615 | Val Loss: 0.109933, Val Acc: 0.773196\n",
      "Epoch 27816 - Train Loss: 0.073095, Train Acc: 0.884615 | Val Loss: 0.109932, Val Acc: 0.773196\n",
      "Epoch 27817 - Train Loss: 0.073093, Train Acc: 0.884615 | Val Loss: 0.109932, Val Acc: 0.773196\n",
      "Epoch 27818 - Train Loss: 0.073092, Train Acc: 0.884615 | Val Loss: 0.109932, Val Acc: 0.773196\n",
      "Epoch 27819 - Train Loss: 0.073091, Train Acc: 0.884615 | Val Loss: 0.109931, Val Acc: 0.773196\n",
      "Epoch 27820 - Train Loss: 0.073089, Train Acc: 0.884615 | Val Loss: 0.109931, Val Acc: 0.773196\n",
      "Epoch 27821 - Train Loss: 0.073088, Train Acc: 0.884615 | Val Loss: 0.109931, Val Acc: 0.773196\n",
      "Epoch 27822 - Train Loss: 0.073087, Train Acc: 0.884615 | Val Loss: 0.109930, Val Acc: 0.773196\n",
      "Epoch 27823 - Train Loss: 0.073085, Train Acc: 0.884615 | Val Loss: 0.109930, Val Acc: 0.773196\n",
      "Epoch 27824 - Train Loss: 0.073084, Train Acc: 0.884615 | Val Loss: 0.109929, Val Acc: 0.773196\n",
      "Epoch 27825 - Train Loss: 0.073083, Train Acc: 0.884615 | Val Loss: 0.109929, Val Acc: 0.773196\n",
      "Epoch 27826 - Train Loss: 0.073081, Train Acc: 0.884615 | Val Loss: 0.109929, Val Acc: 0.773196\n",
      "Epoch 27827 - Train Loss: 0.073080, Train Acc: 0.884615 | Val Loss: 0.109928, Val Acc: 0.773196\n",
      "Epoch 27828 - Train Loss: 0.073079, Train Acc: 0.884615 | Val Loss: 0.109928, Val Acc: 0.773196\n",
      "Epoch 27829 - Train Loss: 0.073077, Train Acc: 0.884615 | Val Loss: 0.109928, Val Acc: 0.773196\n",
      "Epoch 27830 - Train Loss: 0.073076, Train Acc: 0.884615 | Val Loss: 0.109927, Val Acc: 0.773196\n",
      "Epoch 27831 - Train Loss: 0.073074, Train Acc: 0.884615 | Val Loss: 0.109927, Val Acc: 0.773196\n",
      "Epoch 27832 - Train Loss: 0.073073, Train Acc: 0.884615 | Val Loss: 0.109927, Val Acc: 0.773196\n",
      "Epoch 27833 - Train Loss: 0.073072, Train Acc: 0.884615 | Val Loss: 0.109926, Val Acc: 0.773196\n",
      "Epoch 27834 - Train Loss: 0.073070, Train Acc: 0.884615 | Val Loss: 0.109926, Val Acc: 0.773196\n",
      "Epoch 27835 - Train Loss: 0.073069, Train Acc: 0.884615 | Val Loss: 0.109925, Val Acc: 0.773196\n",
      "Epoch 27836 - Train Loss: 0.073068, Train Acc: 0.884615 | Val Loss: 0.109925, Val Acc: 0.773196\n",
      "Epoch 27837 - Train Loss: 0.073066, Train Acc: 0.884615 | Val Loss: 0.109925, Val Acc: 0.773196\n",
      "Epoch 27838 - Train Loss: 0.073065, Train Acc: 0.884615 | Val Loss: 0.109924, Val Acc: 0.773196\n",
      "Epoch 27839 - Train Loss: 0.073064, Train Acc: 0.884615 | Val Loss: 0.109924, Val Acc: 0.773196\n",
      "Epoch 27840 - Train Loss: 0.073062, Train Acc: 0.884615 | Val Loss: 0.109924, Val Acc: 0.773196\n",
      "Epoch 27841 - Train Loss: 0.073061, Train Acc: 0.884615 | Val Loss: 0.109923, Val Acc: 0.773196\n",
      "Epoch 27842 - Train Loss: 0.073060, Train Acc: 0.884615 | Val Loss: 0.109923, Val Acc: 0.773196\n",
      "Epoch 27843 - Train Loss: 0.073058, Train Acc: 0.884615 | Val Loss: 0.109923, Val Acc: 0.773196\n",
      "Epoch 27844 - Train Loss: 0.073057, Train Acc: 0.884615 | Val Loss: 0.109922, Val Acc: 0.773196\n",
      "Epoch 27845 - Train Loss: 0.073056, Train Acc: 0.884615 | Val Loss: 0.109922, Val Acc: 0.773196\n",
      "Epoch 27846 - Train Loss: 0.073054, Train Acc: 0.884615 | Val Loss: 0.109921, Val Acc: 0.773196\n",
      "Epoch 27847 - Train Loss: 0.073053, Train Acc: 0.884615 | Val Loss: 0.109921, Val Acc: 0.773196\n",
      "Epoch 27848 - Train Loss: 0.073052, Train Acc: 0.884615 | Val Loss: 0.109921, Val Acc: 0.773196\n",
      "Epoch 27849 - Train Loss: 0.073050, Train Acc: 0.884615 | Val Loss: 0.109920, Val Acc: 0.773196\n",
      "Epoch 27850 - Train Loss: 0.073049, Train Acc: 0.884615 | Val Loss: 0.109920, Val Acc: 0.773196\n",
      "Epoch 27851 - Train Loss: 0.073047, Train Acc: 0.884615 | Val Loss: 0.109920, Val Acc: 0.773196\n",
      "Epoch 27852 - Train Loss: 0.073046, Train Acc: 0.884615 | Val Loss: 0.109919, Val Acc: 0.773196\n",
      "Epoch 27853 - Train Loss: 0.073045, Train Acc: 0.884615 | Val Loss: 0.109919, Val Acc: 0.773196\n",
      "Epoch 27854 - Train Loss: 0.073043, Train Acc: 0.884615 | Val Loss: 0.109919, Val Acc: 0.773196\n",
      "Epoch 27855 - Train Loss: 0.073042, Train Acc: 0.884615 | Val Loss: 0.109918, Val Acc: 0.773196\n",
      "Epoch 27856 - Train Loss: 0.073041, Train Acc: 0.884615 | Val Loss: 0.109918, Val Acc: 0.773196\n",
      "Epoch 27857 - Train Loss: 0.073039, Train Acc: 0.884615 | Val Loss: 0.109918, Val Acc: 0.773196\n",
      "Epoch 27858 - Train Loss: 0.073038, Train Acc: 0.884615 | Val Loss: 0.109917, Val Acc: 0.773196\n",
      "Epoch 27859 - Train Loss: 0.073037, Train Acc: 0.884615 | Val Loss: 0.109917, Val Acc: 0.773196\n",
      "Epoch 27860 - Train Loss: 0.073035, Train Acc: 0.884615 | Val Loss: 0.109916, Val Acc: 0.773196\n",
      "Epoch 27861 - Train Loss: 0.073034, Train Acc: 0.884615 | Val Loss: 0.109916, Val Acc: 0.773196\n",
      "Epoch 27862 - Train Loss: 0.073033, Train Acc: 0.884615 | Val Loss: 0.109916, Val Acc: 0.773196\n",
      "Epoch 27863 - Train Loss: 0.073031, Train Acc: 0.884615 | Val Loss: 0.109915, Val Acc: 0.773196\n",
      "Epoch 27864 - Train Loss: 0.073030, Train Acc: 0.884615 | Val Loss: 0.109915, Val Acc: 0.773196\n",
      "Epoch 27865 - Train Loss: 0.073029, Train Acc: 0.884615 | Val Loss: 0.109915, Val Acc: 0.773196\n",
      "Epoch 27866 - Train Loss: 0.073027, Train Acc: 0.884615 | Val Loss: 0.109914, Val Acc: 0.773196\n",
      "Epoch 27867 - Train Loss: 0.073026, Train Acc: 0.884615 | Val Loss: 0.109914, Val Acc: 0.773196\n",
      "Epoch 27868 - Train Loss: 0.073024, Train Acc: 0.884615 | Val Loss: 0.109913, Val Acc: 0.773196\n",
      "Epoch 27869 - Train Loss: 0.073023, Train Acc: 0.884615 | Val Loss: 0.109913, Val Acc: 0.773196\n",
      "Epoch 27870 - Train Loss: 0.073022, Train Acc: 0.884615 | Val Loss: 0.109913, Val Acc: 0.773196\n",
      "Epoch 27871 - Train Loss: 0.073020, Train Acc: 0.884615 | Val Loss: 0.109912, Val Acc: 0.773196\n",
      "Epoch 27872 - Train Loss: 0.073019, Train Acc: 0.884615 | Val Loss: 0.109912, Val Acc: 0.773196\n",
      "Epoch 27873 - Train Loss: 0.073018, Train Acc: 0.884615 | Val Loss: 0.109912, Val Acc: 0.773196\n",
      "Epoch 27874 - Train Loss: 0.073016, Train Acc: 0.884615 | Val Loss: 0.109911, Val Acc: 0.773196\n",
      "Epoch 27875 - Train Loss: 0.073015, Train Acc: 0.884615 | Val Loss: 0.109911, Val Acc: 0.773196\n",
      "Epoch 27876 - Train Loss: 0.073014, Train Acc: 0.884615 | Val Loss: 0.109911, Val Acc: 0.773196\n",
      "Epoch 27877 - Train Loss: 0.073012, Train Acc: 0.884615 | Val Loss: 0.109910, Val Acc: 0.773196\n",
      "Epoch 27878 - Train Loss: 0.073011, Train Acc: 0.884615 | Val Loss: 0.109910, Val Acc: 0.773196\n",
      "Epoch 27879 - Train Loss: 0.073010, Train Acc: 0.884615 | Val Loss: 0.109909, Val Acc: 0.773196\n",
      "Epoch 27880 - Train Loss: 0.073008, Train Acc: 0.884615 | Val Loss: 0.109909, Val Acc: 0.773196\n",
      "Epoch 27881 - Train Loss: 0.073007, Train Acc: 0.884615 | Val Loss: 0.109909, Val Acc: 0.773196\n",
      "Epoch 27882 - Train Loss: 0.073006, Train Acc: 0.884615 | Val Loss: 0.109908, Val Acc: 0.773196\n",
      "Epoch 27883 - Train Loss: 0.073004, Train Acc: 0.884615 | Val Loss: 0.109908, Val Acc: 0.773196\n",
      "Epoch 27884 - Train Loss: 0.073003, Train Acc: 0.884615 | Val Loss: 0.109908, Val Acc: 0.773196\n",
      "Epoch 27885 - Train Loss: 0.073002, Train Acc: 0.884615 | Val Loss: 0.109907, Val Acc: 0.773196\n",
      "Epoch 27886 - Train Loss: 0.073000, Train Acc: 0.884615 | Val Loss: 0.109907, Val Acc: 0.773196\n",
      "Epoch 27887 - Train Loss: 0.072999, Train Acc: 0.884615 | Val Loss: 0.109907, Val Acc: 0.773196\n",
      "Epoch 27888 - Train Loss: 0.072997, Train Acc: 0.884615 | Val Loss: 0.109906, Val Acc: 0.773196\n",
      "Epoch 27889 - Train Loss: 0.072996, Train Acc: 0.884615 | Val Loss: 0.109906, Val Acc: 0.773196\n",
      "Epoch 27890 - Train Loss: 0.072995, Train Acc: 0.884615 | Val Loss: 0.109905, Val Acc: 0.773196\n",
      "Epoch 27891 - Train Loss: 0.072993, Train Acc: 0.884615 | Val Loss: 0.109905, Val Acc: 0.773196\n",
      "Epoch 27892 - Train Loss: 0.072992, Train Acc: 0.884615 | Val Loss: 0.109905, Val Acc: 0.773196\n",
      "Epoch 27893 - Train Loss: 0.072991, Train Acc: 0.884615 | Val Loss: 0.109904, Val Acc: 0.773196\n",
      "Epoch 27894 - Train Loss: 0.072989, Train Acc: 0.884615 | Val Loss: 0.109904, Val Acc: 0.773196\n",
      "Epoch 27895 - Train Loss: 0.072988, Train Acc: 0.884615 | Val Loss: 0.109904, Val Acc: 0.773196\n",
      "Epoch 27896 - Train Loss: 0.072987, Train Acc: 0.884615 | Val Loss: 0.109903, Val Acc: 0.773196\n",
      "Epoch 27897 - Train Loss: 0.072985, Train Acc: 0.884615 | Val Loss: 0.109903, Val Acc: 0.773196\n",
      "Epoch 27898 - Train Loss: 0.072984, Train Acc: 0.884615 | Val Loss: 0.109903, Val Acc: 0.773196\n",
      "Epoch 27899 - Train Loss: 0.072983, Train Acc: 0.884615 | Val Loss: 0.109902, Val Acc: 0.773196\n",
      "Epoch 27900 - Train Loss: 0.072981, Train Acc: 0.884615 | Val Loss: 0.109902, Val Acc: 0.773196\n",
      "Epoch 27901 - Train Loss: 0.072980, Train Acc: 0.884615 | Val Loss: 0.109902, Val Acc: 0.773196\n",
      "Epoch 27902 - Train Loss: 0.072979, Train Acc: 0.884615 | Val Loss: 0.109901, Val Acc: 0.773196\n",
      "Epoch 27903 - Train Loss: 0.072977, Train Acc: 0.884615 | Val Loss: 0.109901, Val Acc: 0.773196\n",
      "Epoch 27904 - Train Loss: 0.072976, Train Acc: 0.884615 | Val Loss: 0.109900, Val Acc: 0.773196\n",
      "Epoch 27905 - Train Loss: 0.072975, Train Acc: 0.884615 | Val Loss: 0.109900, Val Acc: 0.773196\n",
      "Epoch 27906 - Train Loss: 0.072973, Train Acc: 0.884615 | Val Loss: 0.109900, Val Acc: 0.773196\n",
      "Epoch 27907 - Train Loss: 0.072972, Train Acc: 0.884615 | Val Loss: 0.109899, Val Acc: 0.773196\n",
      "Epoch 27908 - Train Loss: 0.072970, Train Acc: 0.884615 | Val Loss: 0.109899, Val Acc: 0.773196\n",
      "Epoch 27909 - Train Loss: 0.072969, Train Acc: 0.884615 | Val Loss: 0.109899, Val Acc: 0.773196\n",
      "Epoch 27910 - Train Loss: 0.072968, Train Acc: 0.884615 | Val Loss: 0.109898, Val Acc: 0.773196\n",
      "Epoch 27911 - Train Loss: 0.072966, Train Acc: 0.884615 | Val Loss: 0.109898, Val Acc: 0.773196\n",
      "Epoch 27912 - Train Loss: 0.072965, Train Acc: 0.884615 | Val Loss: 0.109898, Val Acc: 0.773196\n",
      "Epoch 27913 - Train Loss: 0.072964, Train Acc: 0.884615 | Val Loss: 0.109897, Val Acc: 0.773196\n",
      "Epoch 27914 - Train Loss: 0.072962, Train Acc: 0.884615 | Val Loss: 0.109897, Val Acc: 0.773196\n",
      "Epoch 27915 - Train Loss: 0.072961, Train Acc: 0.884615 | Val Loss: 0.109896, Val Acc: 0.773196\n",
      "Epoch 27916 - Train Loss: 0.072960, Train Acc: 0.884615 | Val Loss: 0.109896, Val Acc: 0.773196\n",
      "Epoch 27917 - Train Loss: 0.072958, Train Acc: 0.884615 | Val Loss: 0.109896, Val Acc: 0.773196\n",
      "Epoch 27918 - Train Loss: 0.072957, Train Acc: 0.884615 | Val Loss: 0.109895, Val Acc: 0.773196\n",
      "Epoch 27919 - Train Loss: 0.072956, Train Acc: 0.884615 | Val Loss: 0.109895, Val Acc: 0.773196\n",
      "Epoch 27920 - Train Loss: 0.072954, Train Acc: 0.884615 | Val Loss: 0.109895, Val Acc: 0.773196\n",
      "Epoch 27921 - Train Loss: 0.072953, Train Acc: 0.884615 | Val Loss: 0.109894, Val Acc: 0.773196\n",
      "Epoch 27922 - Train Loss: 0.072952, Train Acc: 0.884615 | Val Loss: 0.109894, Val Acc: 0.773196\n",
      "Epoch 27923 - Train Loss: 0.072950, Train Acc: 0.884615 | Val Loss: 0.109894, Val Acc: 0.773196\n",
      "Epoch 27924 - Train Loss: 0.072949, Train Acc: 0.884615 | Val Loss: 0.109893, Val Acc: 0.773196\n",
      "Epoch 27925 - Train Loss: 0.072948, Train Acc: 0.884615 | Val Loss: 0.109893, Val Acc: 0.773196\n",
      "Epoch 27926 - Train Loss: 0.072946, Train Acc: 0.884615 | Val Loss: 0.109893, Val Acc: 0.773196\n",
      "Epoch 27927 - Train Loss: 0.072945, Train Acc: 0.884615 | Val Loss: 0.109892, Val Acc: 0.773196\n",
      "Epoch 27928 - Train Loss: 0.072944, Train Acc: 0.884615 | Val Loss: 0.109892, Val Acc: 0.773196\n",
      "Epoch 27929 - Train Loss: 0.072942, Train Acc: 0.884615 | Val Loss: 0.109892, Val Acc: 0.773196\n",
      "Epoch 27930 - Train Loss: 0.072941, Train Acc: 0.884615 | Val Loss: 0.109891, Val Acc: 0.773196\n",
      "Epoch 27931 - Train Loss: 0.072939, Train Acc: 0.884615 | Val Loss: 0.109891, Val Acc: 0.773196\n",
      "Epoch 27932 - Train Loss: 0.072938, Train Acc: 0.884615 | Val Loss: 0.109890, Val Acc: 0.773196\n",
      "Epoch 27933 - Train Loss: 0.072937, Train Acc: 0.884615 | Val Loss: 0.109890, Val Acc: 0.773196\n",
      "Epoch 27934 - Train Loss: 0.072935, Train Acc: 0.884615 | Val Loss: 0.109890, Val Acc: 0.773196\n",
      "Epoch 27935 - Train Loss: 0.072934, Train Acc: 0.884615 | Val Loss: 0.109889, Val Acc: 0.773196\n",
      "Epoch 27936 - Train Loss: 0.072933, Train Acc: 0.884615 | Val Loss: 0.109889, Val Acc: 0.773196\n",
      "Epoch 27937 - Train Loss: 0.072931, Train Acc: 0.884615 | Val Loss: 0.109889, Val Acc: 0.773196\n",
      "Epoch 27938 - Train Loss: 0.072930, Train Acc: 0.884615 | Val Loss: 0.109888, Val Acc: 0.773196\n",
      "Epoch 27939 - Train Loss: 0.072929, Train Acc: 0.884615 | Val Loss: 0.109888, Val Acc: 0.773196\n",
      "Epoch 27940 - Train Loss: 0.072927, Train Acc: 0.884615 | Val Loss: 0.109888, Val Acc: 0.773196\n",
      "Epoch 27941 - Train Loss: 0.072926, Train Acc: 0.884615 | Val Loss: 0.109887, Val Acc: 0.773196\n",
      "Epoch 27942 - Train Loss: 0.072925, Train Acc: 0.884615 | Val Loss: 0.109887, Val Acc: 0.773196\n",
      "Epoch 27943 - Train Loss: 0.072923, Train Acc: 0.884615 | Val Loss: 0.109887, Val Acc: 0.773196\n",
      "Epoch 27944 - Train Loss: 0.072922, Train Acc: 0.884615 | Val Loss: 0.109886, Val Acc: 0.773196\n",
      "Epoch 27945 - Train Loss: 0.072921, Train Acc: 0.884615 | Val Loss: 0.109886, Val Acc: 0.773196\n",
      "Epoch 27946 - Train Loss: 0.072919, Train Acc: 0.884615 | Val Loss: 0.109886, Val Acc: 0.773196\n",
      "Epoch 27947 - Train Loss: 0.072918, Train Acc: 0.884615 | Val Loss: 0.109885, Val Acc: 0.773196\n",
      "Epoch 27948 - Train Loss: 0.072917, Train Acc: 0.884615 | Val Loss: 0.109885, Val Acc: 0.773196\n",
      "Epoch 27949 - Train Loss: 0.072915, Train Acc: 0.884615 | Val Loss: 0.109884, Val Acc: 0.773196\n",
      "Epoch 27950 - Train Loss: 0.072914, Train Acc: 0.884615 | Val Loss: 0.109884, Val Acc: 0.773196\n",
      "Epoch 27951 - Train Loss: 0.072913, Train Acc: 0.884615 | Val Loss: 0.109884, Val Acc: 0.773196\n",
      "Epoch 27952 - Train Loss: 0.072911, Train Acc: 0.884615 | Val Loss: 0.109883, Val Acc: 0.773196\n",
      "Epoch 27953 - Train Loss: 0.072910, Train Acc: 0.884615 | Val Loss: 0.109883, Val Acc: 0.773196\n",
      "Epoch 27954 - Train Loss: 0.072909, Train Acc: 0.884615 | Val Loss: 0.109883, Val Acc: 0.773196\n",
      "Epoch 27955 - Train Loss: 0.072907, Train Acc: 0.884615 | Val Loss: 0.109882, Val Acc: 0.773196\n",
      "Epoch 27956 - Train Loss: 0.072906, Train Acc: 0.884615 | Val Loss: 0.109882, Val Acc: 0.773196\n",
      "Epoch 27957 - Train Loss: 0.072905, Train Acc: 0.884615 | Val Loss: 0.109882, Val Acc: 0.773196\n",
      "Epoch 27958 - Train Loss: 0.072903, Train Acc: 0.884615 | Val Loss: 0.109881, Val Acc: 0.773196\n",
      "Epoch 27959 - Train Loss: 0.072902, Train Acc: 0.884615 | Val Loss: 0.109881, Val Acc: 0.773196\n",
      "Epoch 27960 - Train Loss: 0.072900, Train Acc: 0.884615 | Val Loss: 0.109881, Val Acc: 0.773196\n",
      "Epoch 27961 - Train Loss: 0.072899, Train Acc: 0.884615 | Val Loss: 0.109880, Val Acc: 0.773196\n",
      "Epoch 27962 - Train Loss: 0.072898, Train Acc: 0.884615 | Val Loss: 0.109880, Val Acc: 0.773196\n",
      "Epoch 27963 - Train Loss: 0.072896, Train Acc: 0.884615 | Val Loss: 0.109880, Val Acc: 0.773196\n",
      "Epoch 27964 - Train Loss: 0.072895, Train Acc: 0.884615 | Val Loss: 0.109879, Val Acc: 0.773196\n",
      "Epoch 27965 - Train Loss: 0.072894, Train Acc: 0.884615 | Val Loss: 0.109879, Val Acc: 0.773196\n",
      "Epoch 27966 - Train Loss: 0.072892, Train Acc: 0.884615 | Val Loss: 0.109878, Val Acc: 0.773196\n",
      "Epoch 27967 - Train Loss: 0.072891, Train Acc: 0.884615 | Val Loss: 0.109878, Val Acc: 0.773196\n",
      "Epoch 27968 - Train Loss: 0.072890, Train Acc: 0.884615 | Val Loss: 0.109878, Val Acc: 0.773196\n",
      "Epoch 27969 - Train Loss: 0.072888, Train Acc: 0.884615 | Val Loss: 0.109877, Val Acc: 0.773196\n",
      "Epoch 27970 - Train Loss: 0.072887, Train Acc: 0.884615 | Val Loss: 0.109877, Val Acc: 0.773196\n",
      "Epoch 27971 - Train Loss: 0.072886, Train Acc: 0.884615 | Val Loss: 0.109877, Val Acc: 0.773196\n",
      "Epoch 27972 - Train Loss: 0.072884, Train Acc: 0.884615 | Val Loss: 0.109876, Val Acc: 0.773196\n",
      "Epoch 27973 - Train Loss: 0.072883, Train Acc: 0.884615 | Val Loss: 0.109876, Val Acc: 0.773196\n",
      "Epoch 27974 - Train Loss: 0.072882, Train Acc: 0.884615 | Val Loss: 0.109876, Val Acc: 0.773196\n",
      "Epoch 27975 - Train Loss: 0.072880, Train Acc: 0.884615 | Val Loss: 0.109875, Val Acc: 0.773196\n",
      "Epoch 27976 - Train Loss: 0.072879, Train Acc: 0.884615 | Val Loss: 0.109875, Val Acc: 0.773196\n",
      "Epoch 27977 - Train Loss: 0.072878, Train Acc: 0.884615 | Val Loss: 0.109875, Val Acc: 0.773196\n",
      "Epoch 27978 - Train Loss: 0.072876, Train Acc: 0.884615 | Val Loss: 0.109874, Val Acc: 0.773196\n",
      "Epoch 27979 - Train Loss: 0.072875, Train Acc: 0.884615 | Val Loss: 0.109874, Val Acc: 0.773196\n",
      "Epoch 27980 - Train Loss: 0.072874, Train Acc: 0.884615 | Val Loss: 0.109874, Val Acc: 0.773196\n",
      "Epoch 27981 - Train Loss: 0.072872, Train Acc: 0.884615 | Val Loss: 0.109873, Val Acc: 0.773196\n",
      "Epoch 27982 - Train Loss: 0.072871, Train Acc: 0.884615 | Val Loss: 0.109873, Val Acc: 0.773196\n",
      "Epoch 27983 - Train Loss: 0.072870, Train Acc: 0.884615 | Val Loss: 0.109872, Val Acc: 0.773196\n",
      "Epoch 27984 - Train Loss: 0.072868, Train Acc: 0.884615 | Val Loss: 0.109872, Val Acc: 0.773196\n",
      "Epoch 27985 - Train Loss: 0.072867, Train Acc: 0.884615 | Val Loss: 0.109872, Val Acc: 0.773196\n",
      "Epoch 27986 - Train Loss: 0.072866, Train Acc: 0.884615 | Val Loss: 0.109871, Val Acc: 0.773196\n",
      "Epoch 27987 - Train Loss: 0.072864, Train Acc: 0.884615 | Val Loss: 0.109871, Val Acc: 0.773196\n",
      "Epoch 27988 - Train Loss: 0.072863, Train Acc: 0.884615 | Val Loss: 0.109871, Val Acc: 0.773196\n",
      "Epoch 27989 - Train Loss: 0.072862, Train Acc: 0.884615 | Val Loss: 0.109870, Val Acc: 0.773196\n",
      "Epoch 27990 - Train Loss: 0.072860, Train Acc: 0.884615 | Val Loss: 0.109870, Val Acc: 0.773196\n",
      "Epoch 27991 - Train Loss: 0.072859, Train Acc: 0.884615 | Val Loss: 0.109870, Val Acc: 0.773196\n",
      "Epoch 27992 - Train Loss: 0.072857, Train Acc: 0.884615 | Val Loss: 0.109869, Val Acc: 0.773196\n",
      "Epoch 27993 - Train Loss: 0.072856, Train Acc: 0.884615 | Val Loss: 0.109869, Val Acc: 0.773196\n",
      "Epoch 27994 - Train Loss: 0.072855, Train Acc: 0.884615 | Val Loss: 0.109869, Val Acc: 0.773196\n",
      "Epoch 27995 - Train Loss: 0.072853, Train Acc: 0.884615 | Val Loss: 0.109868, Val Acc: 0.773196\n",
      "Epoch 27996 - Train Loss: 0.072852, Train Acc: 0.884615 | Val Loss: 0.109868, Val Acc: 0.773196\n",
      "Epoch 27997 - Train Loss: 0.072851, Train Acc: 0.884615 | Val Loss: 0.109868, Val Acc: 0.773196\n",
      "Epoch 27998 - Train Loss: 0.072849, Train Acc: 0.884615 | Val Loss: 0.109867, Val Acc: 0.773196\n",
      "Epoch 27999 - Train Loss: 0.072848, Train Acc: 0.884615 | Val Loss: 0.109867, Val Acc: 0.773196\n",
      "Epoch 28000 - Train Loss: 0.072847, Train Acc: 0.884615 | Val Loss: 0.109866, Val Acc: 0.773196\n",
      "Epoch 28001 - Train Loss: 0.072845, Train Acc: 0.884615 | Val Loss: 0.109866, Val Acc: 0.773196\n",
      "Epoch 28002 - Train Loss: 0.072844, Train Acc: 0.884615 | Val Loss: 0.109866, Val Acc: 0.773196\n",
      "Epoch 28003 - Train Loss: 0.072843, Train Acc: 0.884615 | Val Loss: 0.109865, Val Acc: 0.773196\n",
      "Epoch 28004 - Train Loss: 0.072841, Train Acc: 0.884615 | Val Loss: 0.109865, Val Acc: 0.773196\n",
      "Epoch 28005 - Train Loss: 0.072840, Train Acc: 0.884615 | Val Loss: 0.109865, Val Acc: 0.773196\n",
      "Epoch 28006 - Train Loss: 0.072839, Train Acc: 0.884615 | Val Loss: 0.109864, Val Acc: 0.773196\n",
      "Epoch 28007 - Train Loss: 0.072837, Train Acc: 0.884615 | Val Loss: 0.109864, Val Acc: 0.773196\n",
      "Epoch 28008 - Train Loss: 0.072836, Train Acc: 0.884615 | Val Loss: 0.109864, Val Acc: 0.773196\n",
      "Epoch 28009 - Train Loss: 0.072835, Train Acc: 0.884615 | Val Loss: 0.109863, Val Acc: 0.773196\n",
      "Epoch 28010 - Train Loss: 0.072833, Train Acc: 0.884615 | Val Loss: 0.109863, Val Acc: 0.773196\n",
      "Epoch 28011 - Train Loss: 0.072832, Train Acc: 0.884615 | Val Loss: 0.109863, Val Acc: 0.773196\n",
      "Epoch 28012 - Train Loss: 0.072831, Train Acc: 0.884615 | Val Loss: 0.109862, Val Acc: 0.773196\n",
      "Epoch 28013 - Train Loss: 0.072829, Train Acc: 0.884615 | Val Loss: 0.109862, Val Acc: 0.773196\n",
      "Epoch 28014 - Train Loss: 0.072828, Train Acc: 0.884615 | Val Loss: 0.109862, Val Acc: 0.773196\n",
      "Epoch 28015 - Train Loss: 0.072827, Train Acc: 0.884615 | Val Loss: 0.109861, Val Acc: 0.773196\n",
      "Epoch 28016 - Train Loss: 0.072825, Train Acc: 0.884615 | Val Loss: 0.109861, Val Acc: 0.773196\n",
      "Epoch 28017 - Train Loss: 0.072824, Train Acc: 0.884615 | Val Loss: 0.109861, Val Acc: 0.773196\n",
      "Epoch 28018 - Train Loss: 0.072823, Train Acc: 0.884615 | Val Loss: 0.109860, Val Acc: 0.773196\n",
      "Epoch 28019 - Train Loss: 0.072821, Train Acc: 0.884615 | Val Loss: 0.109860, Val Acc: 0.773196\n",
      "Epoch 28020 - Train Loss: 0.072820, Train Acc: 0.884615 | Val Loss: 0.109859, Val Acc: 0.773196\n",
      "Epoch 28021 - Train Loss: 0.072819, Train Acc: 0.884615 | Val Loss: 0.109859, Val Acc: 0.773196\n",
      "Epoch 28022 - Train Loss: 0.072817, Train Acc: 0.884615 | Val Loss: 0.109859, Val Acc: 0.773196\n",
      "Epoch 28023 - Train Loss: 0.072816, Train Acc: 0.884615 | Val Loss: 0.109858, Val Acc: 0.773196\n",
      "Epoch 28024 - Train Loss: 0.072815, Train Acc: 0.884615 | Val Loss: 0.109858, Val Acc: 0.773196\n",
      "Epoch 28025 - Train Loss: 0.072813, Train Acc: 0.884615 | Val Loss: 0.109858, Val Acc: 0.773196\n",
      "Epoch 28026 - Train Loss: 0.072812, Train Acc: 0.884615 | Val Loss: 0.109857, Val Acc: 0.773196\n",
      "Epoch 28027 - Train Loss: 0.072811, Train Acc: 0.884615 | Val Loss: 0.109857, Val Acc: 0.773196\n",
      "Epoch 28028 - Train Loss: 0.072809, Train Acc: 0.884615 | Val Loss: 0.109857, Val Acc: 0.773196\n",
      "Epoch 28029 - Train Loss: 0.072808, Train Acc: 0.884615 | Val Loss: 0.109856, Val Acc: 0.773196\n",
      "Epoch 28030 - Train Loss: 0.072807, Train Acc: 0.884615 | Val Loss: 0.109856, Val Acc: 0.773196\n",
      "Epoch 28031 - Train Loss: 0.072805, Train Acc: 0.884615 | Val Loss: 0.109856, Val Acc: 0.773196\n",
      "Epoch 28032 - Train Loss: 0.072804, Train Acc: 0.884615 | Val Loss: 0.109855, Val Acc: 0.773196\n",
      "Epoch 28033 - Train Loss: 0.072803, Train Acc: 0.884615 | Val Loss: 0.109855, Val Acc: 0.773196\n",
      "Epoch 28034 - Train Loss: 0.072801, Train Acc: 0.884615 | Val Loss: 0.109855, Val Acc: 0.773196\n",
      "Epoch 28035 - Train Loss: 0.072800, Train Acc: 0.884615 | Val Loss: 0.109854, Val Acc: 0.773196\n",
      "Epoch 28036 - Train Loss: 0.072798, Train Acc: 0.884615 | Val Loss: 0.109854, Val Acc: 0.773196\n",
      "Epoch 28037 - Train Loss: 0.072797, Train Acc: 0.884615 | Val Loss: 0.109854, Val Acc: 0.773196\n",
      "Epoch 28038 - Train Loss: 0.072796, Train Acc: 0.884615 | Val Loss: 0.109853, Val Acc: 0.773196\n",
      "Epoch 28039 - Train Loss: 0.072794, Train Acc: 0.884615 | Val Loss: 0.109853, Val Acc: 0.773196\n",
      "Epoch 28040 - Train Loss: 0.072793, Train Acc: 0.884615 | Val Loss: 0.109853, Val Acc: 0.773196\n",
      "Epoch 28041 - Train Loss: 0.072792, Train Acc: 0.884615 | Val Loss: 0.109853, Val Acc: 0.773196\n",
      "Epoch 28042 - Train Loss: 0.072790, Train Acc: 0.884615 | Val Loss: 0.109852, Val Acc: 0.773196\n",
      "Epoch 28043 - Train Loss: 0.072789, Train Acc: 0.884615 | Val Loss: 0.109852, Val Acc: 0.773196\n",
      "Epoch 28044 - Train Loss: 0.072788, Train Acc: 0.884615 | Val Loss: 0.109852, Val Acc: 0.773196\n",
      "Epoch 28045 - Train Loss: 0.072786, Train Acc: 0.884615 | Val Loss: 0.109851, Val Acc: 0.773196\n",
      "Epoch 28046 - Train Loss: 0.072785, Train Acc: 0.884615 | Val Loss: 0.109851, Val Acc: 0.773196\n",
      "Epoch 28047 - Train Loss: 0.072784, Train Acc: 0.884615 | Val Loss: 0.109851, Val Acc: 0.773196\n",
      "Epoch 28048 - Train Loss: 0.072782, Train Acc: 0.884615 | Val Loss: 0.109850, Val Acc: 0.773196\n",
      "Epoch 28049 - Train Loss: 0.072781, Train Acc: 0.884615 | Val Loss: 0.109850, Val Acc: 0.773196\n",
      "Epoch 28050 - Train Loss: 0.072780, Train Acc: 0.884615 | Val Loss: 0.109850, Val Acc: 0.773196\n",
      "Epoch 28051 - Train Loss: 0.072778, Train Acc: 0.884615 | Val Loss: 0.109849, Val Acc: 0.773196\n",
      "Epoch 28052 - Train Loss: 0.072777, Train Acc: 0.884615 | Val Loss: 0.109849, Val Acc: 0.773196\n",
      "Epoch 28053 - Train Loss: 0.072776, Train Acc: 0.884615 | Val Loss: 0.109849, Val Acc: 0.773196\n",
      "Epoch 28054 - Train Loss: 0.072774, Train Acc: 0.884615 | Val Loss: 0.109848, Val Acc: 0.773196\n",
      "Epoch 28055 - Train Loss: 0.072773, Train Acc: 0.884615 | Val Loss: 0.109848, Val Acc: 0.773196\n",
      "Epoch 28056 - Train Loss: 0.072772, Train Acc: 0.884615 | Val Loss: 0.109847, Val Acc: 0.773196\n",
      "Epoch 28057 - Train Loss: 0.072770, Train Acc: 0.884615 | Val Loss: 0.109847, Val Acc: 0.773196\n",
      "Epoch 28058 - Train Loss: 0.072769, Train Acc: 0.884615 | Val Loss: 0.109847, Val Acc: 0.773196\n",
      "Epoch 28059 - Train Loss: 0.072768, Train Acc: 0.884615 | Val Loss: 0.109846, Val Acc: 0.773196\n",
      "Epoch 28060 - Train Loss: 0.072766, Train Acc: 0.884615 | Val Loss: 0.109846, Val Acc: 0.773196\n",
      "Epoch 28061 - Train Loss: 0.072765, Train Acc: 0.884615 | Val Loss: 0.109846, Val Acc: 0.773196\n",
      "Epoch 28062 - Train Loss: 0.072764, Train Acc: 0.884615 | Val Loss: 0.109845, Val Acc: 0.773196\n",
      "Epoch 28063 - Train Loss: 0.072762, Train Acc: 0.884615 | Val Loss: 0.109845, Val Acc: 0.773196\n",
      "Epoch 28064 - Train Loss: 0.072761, Train Acc: 0.884615 | Val Loss: 0.109845, Val Acc: 0.773196\n",
      "Epoch 28065 - Train Loss: 0.072760, Train Acc: 0.884615 | Val Loss: 0.109845, Val Acc: 0.773196\n",
      "Epoch 28066 - Train Loss: 0.072758, Train Acc: 0.884615 | Val Loss: 0.109844, Val Acc: 0.773196\n",
      "Epoch 28067 - Train Loss: 0.072757, Train Acc: 0.884615 | Val Loss: 0.109844, Val Acc: 0.773196\n",
      "Epoch 28068 - Train Loss: 0.072756, Train Acc: 0.884615 | Val Loss: 0.109843, Val Acc: 0.773196\n",
      "Epoch 28069 - Train Loss: 0.072754, Train Acc: 0.884615 | Val Loss: 0.109843, Val Acc: 0.773196\n",
      "Epoch 28070 - Train Loss: 0.072753, Train Acc: 0.884615 | Val Loss: 0.109843, Val Acc: 0.773196\n",
      "Epoch 28071 - Train Loss: 0.072752, Train Acc: 0.884615 | Val Loss: 0.109842, Val Acc: 0.773196\n",
      "Epoch 28072 - Train Loss: 0.072750, Train Acc: 0.884615 | Val Loss: 0.109842, Val Acc: 0.773196\n",
      "Epoch 28073 - Train Loss: 0.072749, Train Acc: 0.884615 | Val Loss: 0.109842, Val Acc: 0.773196\n",
      "Epoch 28074 - Train Loss: 0.072748, Train Acc: 0.884615 | Val Loss: 0.109841, Val Acc: 0.773196\n",
      "Epoch 28075 - Train Loss: 0.072746, Train Acc: 0.884615 | Val Loss: 0.109841, Val Acc: 0.773196\n",
      "Epoch 28076 - Train Loss: 0.072745, Train Acc: 0.884615 | Val Loss: 0.109841, Val Acc: 0.773196\n",
      "Epoch 28077 - Train Loss: 0.072744, Train Acc: 0.884615 | Val Loss: 0.109840, Val Acc: 0.773196\n",
      "Epoch 28078 - Train Loss: 0.072742, Train Acc: 0.884615 | Val Loss: 0.109840, Val Acc: 0.773196\n",
      "Epoch 28079 - Train Loss: 0.072741, Train Acc: 0.884615 | Val Loss: 0.109840, Val Acc: 0.773196\n",
      "Epoch 28080 - Train Loss: 0.072740, Train Acc: 0.884615 | Val Loss: 0.109839, Val Acc: 0.773196\n",
      "Epoch 28081 - Train Loss: 0.072738, Train Acc: 0.884615 | Val Loss: 0.109839, Val Acc: 0.773196\n",
      "Epoch 28082 - Train Loss: 0.072737, Train Acc: 0.884615 | Val Loss: 0.109839, Val Acc: 0.773196\n",
      "Epoch 28083 - Train Loss: 0.072736, Train Acc: 0.884615 | Val Loss: 0.109838, Val Acc: 0.773196\n",
      "Epoch 28084 - Train Loss: 0.072734, Train Acc: 0.884615 | Val Loss: 0.109838, Val Acc: 0.773196\n",
      "Epoch 28085 - Train Loss: 0.072733, Train Acc: 0.884615 | Val Loss: 0.109838, Val Acc: 0.773196\n",
      "Epoch 28086 - Train Loss: 0.072732, Train Acc: 0.884615 | Val Loss: 0.109837, Val Acc: 0.773196\n",
      "Epoch 28087 - Train Loss: 0.072730, Train Acc: 0.884615 | Val Loss: 0.109837, Val Acc: 0.773196\n",
      "Epoch 28088 - Train Loss: 0.072729, Train Acc: 0.884615 | Val Loss: 0.109837, Val Acc: 0.773196\n",
      "Epoch 28089 - Train Loss: 0.072728, Train Acc: 0.884615 | Val Loss: 0.109836, Val Acc: 0.773196\n",
      "Epoch 28090 - Train Loss: 0.072726, Train Acc: 0.884615 | Val Loss: 0.109836, Val Acc: 0.773196\n",
      "Epoch 28091 - Train Loss: 0.072725, Train Acc: 0.884615 | Val Loss: 0.109836, Val Acc: 0.773196\n",
      "Epoch 28092 - Train Loss: 0.072724, Train Acc: 0.884615 | Val Loss: 0.109835, Val Acc: 0.773196\n",
      "Epoch 28093 - Train Loss: 0.072722, Train Acc: 0.884615 | Val Loss: 0.109835, Val Acc: 0.773196\n",
      "Epoch 28094 - Train Loss: 0.072721, Train Acc: 0.884615 | Val Loss: 0.109835, Val Acc: 0.773196\n",
      "Epoch 28095 - Train Loss: 0.072720, Train Acc: 0.884615 | Val Loss: 0.109834, Val Acc: 0.773196\n",
      "Epoch 28096 - Train Loss: 0.072718, Train Acc: 0.884615 | Val Loss: 0.109834, Val Acc: 0.773196\n",
      "Epoch 28097 - Train Loss: 0.072717, Train Acc: 0.884615 | Val Loss: 0.109834, Val Acc: 0.773196\n",
      "Epoch 28098 - Train Loss: 0.072716, Train Acc: 0.884615 | Val Loss: 0.109833, Val Acc: 0.773196\n",
      "Epoch 28099 - Train Loss: 0.072714, Train Acc: 0.884615 | Val Loss: 0.109833, Val Acc: 0.773196\n",
      "Epoch 28100 - Train Loss: 0.072713, Train Acc: 0.884615 | Val Loss: 0.109833, Val Acc: 0.773196\n",
      "Epoch 28101 - Train Loss: 0.072712, Train Acc: 0.884615 | Val Loss: 0.109832, Val Acc: 0.773196\n",
      "Epoch 28102 - Train Loss: 0.072710, Train Acc: 0.884615 | Val Loss: 0.109832, Val Acc: 0.773196\n",
      "Epoch 28103 - Train Loss: 0.072709, Train Acc: 0.884615 | Val Loss: 0.109832, Val Acc: 0.773196\n",
      "Epoch 28104 - Train Loss: 0.072708, Train Acc: 0.884615 | Val Loss: 0.109831, Val Acc: 0.773196\n",
      "Epoch 28105 - Train Loss: 0.072706, Train Acc: 0.884615 | Val Loss: 0.109831, Val Acc: 0.773196\n",
      "Epoch 28106 - Train Loss: 0.072705, Train Acc: 0.884615 | Val Loss: 0.109831, Val Acc: 0.773196\n",
      "Epoch 28107 - Train Loss: 0.072704, Train Acc: 0.884615 | Val Loss: 0.109830, Val Acc: 0.773196\n",
      "Epoch 28108 - Train Loss: 0.072702, Train Acc: 0.884615 | Val Loss: 0.109830, Val Acc: 0.773196\n",
      "Epoch 28109 - Train Loss: 0.072701, Train Acc: 0.884615 | Val Loss: 0.109830, Val Acc: 0.773196\n",
      "Epoch 28110 - Train Loss: 0.072700, Train Acc: 0.884615 | Val Loss: 0.109829, Val Acc: 0.773196\n",
      "Epoch 28111 - Train Loss: 0.072698, Train Acc: 0.884615 | Val Loss: 0.109829, Val Acc: 0.773196\n",
      "Epoch 28112 - Train Loss: 0.072697, Train Acc: 0.884615 | Val Loss: 0.109828, Val Acc: 0.773196\n",
      "Epoch 28113 - Train Loss: 0.072696, Train Acc: 0.884615 | Val Loss: 0.109828, Val Acc: 0.773196\n",
      "Epoch 28114 - Train Loss: 0.072694, Train Acc: 0.884615 | Val Loss: 0.109828, Val Acc: 0.773196\n",
      "Epoch 28115 - Train Loss: 0.072693, Train Acc: 0.884615 | Val Loss: 0.109828, Val Acc: 0.773196\n",
      "Epoch 28116 - Train Loss: 0.072692, Train Acc: 0.884615 | Val Loss: 0.109827, Val Acc: 0.773196\n",
      "Epoch 28117 - Train Loss: 0.072690, Train Acc: 0.884615 | Val Loss: 0.109827, Val Acc: 0.773196\n",
      "Epoch 28118 - Train Loss: 0.072689, Train Acc: 0.884615 | Val Loss: 0.109827, Val Acc: 0.773196\n",
      "Epoch 28119 - Train Loss: 0.072688, Train Acc: 0.884615 | Val Loss: 0.109826, Val Acc: 0.773196\n",
      "Epoch 28120 - Train Loss: 0.072686, Train Acc: 0.884615 | Val Loss: 0.109826, Val Acc: 0.773196\n",
      "Epoch 28121 - Train Loss: 0.072685, Train Acc: 0.884615 | Val Loss: 0.109825, Val Acc: 0.773196\n",
      "Epoch 28122 - Train Loss: 0.072684, Train Acc: 0.884615 | Val Loss: 0.109825, Val Acc: 0.773196\n",
      "Epoch 28123 - Train Loss: 0.072682, Train Acc: 0.884615 | Val Loss: 0.109825, Val Acc: 0.773196\n",
      "Epoch 28124 - Train Loss: 0.072681, Train Acc: 0.884615 | Val Loss: 0.109825, Val Acc: 0.773196\n",
      "Epoch 28125 - Train Loss: 0.072680, Train Acc: 0.884615 | Val Loss: 0.109824, Val Acc: 0.773196\n",
      "Epoch 28126 - Train Loss: 0.072678, Train Acc: 0.884615 | Val Loss: 0.109824, Val Acc: 0.773196\n",
      "Epoch 28127 - Train Loss: 0.072677, Train Acc: 0.884615 | Val Loss: 0.109823, Val Acc: 0.773196\n",
      "Epoch 28128 - Train Loss: 0.072676, Train Acc: 0.884615 | Val Loss: 0.109823, Val Acc: 0.773196\n",
      "Epoch 28129 - Train Loss: 0.072674, Train Acc: 0.884615 | Val Loss: 0.109823, Val Acc: 0.773196\n",
      "Epoch 28130 - Train Loss: 0.072673, Train Acc: 0.884615 | Val Loss: 0.109822, Val Acc: 0.773196\n",
      "Epoch 28131 - Train Loss: 0.072672, Train Acc: 0.884615 | Val Loss: 0.109822, Val Acc: 0.773196\n",
      "Epoch 28132 - Train Loss: 0.072670, Train Acc: 0.884615 | Val Loss: 0.109822, Val Acc: 0.773196\n",
      "Epoch 28133 - Train Loss: 0.072669, Train Acc: 0.884615 | Val Loss: 0.109821, Val Acc: 0.773196\n",
      "Epoch 28134 - Train Loss: 0.072668, Train Acc: 0.884615 | Val Loss: 0.109821, Val Acc: 0.773196\n",
      "Epoch 28135 - Train Loss: 0.072666, Train Acc: 0.884615 | Val Loss: 0.109821, Val Acc: 0.773196\n",
      "Epoch 28136 - Train Loss: 0.072665, Train Acc: 0.884615 | Val Loss: 0.109820, Val Acc: 0.773196\n",
      "Epoch 28137 - Train Loss: 0.072664, Train Acc: 0.884615 | Val Loss: 0.109820, Val Acc: 0.773196\n",
      "Epoch 28138 - Train Loss: 0.072662, Train Acc: 0.884615 | Val Loss: 0.109820, Val Acc: 0.773196\n",
      "Epoch 28139 - Train Loss: 0.072661, Train Acc: 0.884615 | Val Loss: 0.109819, Val Acc: 0.773196\n",
      "Epoch 28140 - Train Loss: 0.072660, Train Acc: 0.884615 | Val Loss: 0.109819, Val Acc: 0.773196\n",
      "Epoch 28141 - Train Loss: 0.072658, Train Acc: 0.884615 | Val Loss: 0.109819, Val Acc: 0.773196\n",
      "Epoch 28142 - Train Loss: 0.072657, Train Acc: 0.884615 | Val Loss: 0.109818, Val Acc: 0.773196\n",
      "Epoch 28143 - Train Loss: 0.072656, Train Acc: 0.884615 | Val Loss: 0.109818, Val Acc: 0.773196\n",
      "Epoch 28144 - Train Loss: 0.072654, Train Acc: 0.884615 | Val Loss: 0.109818, Val Acc: 0.773196\n",
      "Epoch 28145 - Train Loss: 0.072653, Train Acc: 0.884615 | Val Loss: 0.109817, Val Acc: 0.773196\n",
      "Epoch 28146 - Train Loss: 0.072652, Train Acc: 0.884615 | Val Loss: 0.109817, Val Acc: 0.773196\n",
      "Epoch 28147 - Train Loss: 0.072650, Train Acc: 0.884615 | Val Loss: 0.109817, Val Acc: 0.773196\n",
      "Epoch 28148 - Train Loss: 0.072649, Train Acc: 0.884615 | Val Loss: 0.109816, Val Acc: 0.773196\n",
      "Epoch 28149 - Train Loss: 0.072648, Train Acc: 0.884615 | Val Loss: 0.109816, Val Acc: 0.773196\n",
      "Epoch 28150 - Train Loss: 0.072646, Train Acc: 0.884615 | Val Loss: 0.109816, Val Acc: 0.773196\n",
      "Epoch 28151 - Train Loss: 0.072645, Train Acc: 0.884615 | Val Loss: 0.109815, Val Acc: 0.773196\n",
      "Epoch 28152 - Train Loss: 0.072644, Train Acc: 0.884615 | Val Loss: 0.109815, Val Acc: 0.773196\n",
      "Epoch 28153 - Train Loss: 0.072642, Train Acc: 0.884615 | Val Loss: 0.109815, Val Acc: 0.773196\n",
      "Epoch 28154 - Train Loss: 0.072641, Train Acc: 0.884615 | Val Loss: 0.109814, Val Acc: 0.773196\n",
      "Epoch 28155 - Train Loss: 0.072640, Train Acc: 0.884615 | Val Loss: 0.109814, Val Acc: 0.773196\n",
      "Epoch 28156 - Train Loss: 0.072638, Train Acc: 0.884615 | Val Loss: 0.109814, Val Acc: 0.773196\n",
      "Epoch 28157 - Train Loss: 0.072637, Train Acc: 0.884615 | Val Loss: 0.109813, Val Acc: 0.773196\n",
      "Epoch 28158 - Train Loss: 0.072636, Train Acc: 0.884615 | Val Loss: 0.109813, Val Acc: 0.773196\n",
      "Epoch 28159 - Train Loss: 0.072634, Train Acc: 0.884615 | Val Loss: 0.109813, Val Acc: 0.773196\n",
      "Epoch 28160 - Train Loss: 0.072633, Train Acc: 0.884615 | Val Loss: 0.109812, Val Acc: 0.773196\n",
      "Epoch 28161 - Train Loss: 0.072632, Train Acc: 0.884615 | Val Loss: 0.109812, Val Acc: 0.773196\n",
      "Epoch 28162 - Train Loss: 0.072630, Train Acc: 0.884615 | Val Loss: 0.109812, Val Acc: 0.773196\n",
      "Epoch 28163 - Train Loss: 0.072629, Train Acc: 0.884615 | Val Loss: 0.109811, Val Acc: 0.773196\n",
      "Epoch 28164 - Train Loss: 0.072628, Train Acc: 0.884615 | Val Loss: 0.109811, Val Acc: 0.773196\n",
      "Epoch 28165 - Train Loss: 0.072626, Train Acc: 0.884615 | Val Loss: 0.109811, Val Acc: 0.773196\n",
      "Epoch 28166 - Train Loss: 0.072625, Train Acc: 0.884615 | Val Loss: 0.109810, Val Acc: 0.773196\n",
      "Epoch 28167 - Train Loss: 0.072624, Train Acc: 0.884615 | Val Loss: 0.109810, Val Acc: 0.773196\n",
      "Epoch 28168 - Train Loss: 0.072622, Train Acc: 0.884615 | Val Loss: 0.109810, Val Acc: 0.773196\n",
      "Epoch 28169 - Train Loss: 0.072621, Train Acc: 0.884615 | Val Loss: 0.109809, Val Acc: 0.773196\n",
      "Epoch 28170 - Train Loss: 0.072620, Train Acc: 0.884615 | Val Loss: 0.109809, Val Acc: 0.773196\n",
      "Epoch 28171 - Train Loss: 0.072618, Train Acc: 0.884615 | Val Loss: 0.109809, Val Acc: 0.773196\n",
      "Epoch 28172 - Train Loss: 0.072617, Train Acc: 0.884615 | Val Loss: 0.109808, Val Acc: 0.773196\n",
      "Epoch 28173 - Train Loss: 0.072616, Train Acc: 0.884615 | Val Loss: 0.109808, Val Acc: 0.773196\n",
      "Epoch 28174 - Train Loss: 0.072614, Train Acc: 0.884615 | Val Loss: 0.109807, Val Acc: 0.773196\n",
      "Epoch 28175 - Train Loss: 0.072613, Train Acc: 0.884615 | Val Loss: 0.109807, Val Acc: 0.773196\n",
      "Epoch 28176 - Train Loss: 0.072612, Train Acc: 0.884615 | Val Loss: 0.109807, Val Acc: 0.773196\n",
      "Epoch 28177 - Train Loss: 0.072610, Train Acc: 0.884615 | Val Loss: 0.109806, Val Acc: 0.773196\n",
      "Epoch 28178 - Train Loss: 0.072609, Train Acc: 0.884615 | Val Loss: 0.109806, Val Acc: 0.773196\n",
      "Epoch 28179 - Train Loss: 0.072608, Train Acc: 0.884615 | Val Loss: 0.109806, Val Acc: 0.773196\n",
      "Epoch 28180 - Train Loss: 0.072606, Train Acc: 0.884615 | Val Loss: 0.109805, Val Acc: 0.773196\n",
      "Epoch 28181 - Train Loss: 0.072605, Train Acc: 0.884615 | Val Loss: 0.109805, Val Acc: 0.773196\n",
      "Epoch 28182 - Train Loss: 0.072604, Train Acc: 0.884615 | Val Loss: 0.109805, Val Acc: 0.773196\n",
      "Epoch 28183 - Train Loss: 0.072602, Train Acc: 0.884615 | Val Loss: 0.109805, Val Acc: 0.773196\n",
      "Epoch 28184 - Train Loss: 0.072601, Train Acc: 0.884615 | Val Loss: 0.109804, Val Acc: 0.773196\n",
      "Epoch 28185 - Train Loss: 0.072600, Train Acc: 0.884615 | Val Loss: 0.109804, Val Acc: 0.773196\n",
      "Epoch 28186 - Train Loss: 0.072598, Train Acc: 0.884615 | Val Loss: 0.109803, Val Acc: 0.773196\n",
      "Epoch 28187 - Train Loss: 0.072597, Train Acc: 0.884615 | Val Loss: 0.109803, Val Acc: 0.773196\n",
      "Epoch 28188 - Train Loss: 0.072596, Train Acc: 0.884615 | Val Loss: 0.109803, Val Acc: 0.773196\n",
      "Epoch 28189 - Train Loss: 0.072594, Train Acc: 0.884615 | Val Loss: 0.109802, Val Acc: 0.773196\n",
      "Epoch 28190 - Train Loss: 0.072593, Train Acc: 0.884615 | Val Loss: 0.109802, Val Acc: 0.773196\n",
      "Epoch 28191 - Train Loss: 0.072592, Train Acc: 0.884615 | Val Loss: 0.109802, Val Acc: 0.773196\n",
      "Epoch 28192 - Train Loss: 0.072590, Train Acc: 0.884615 | Val Loss: 0.109801, Val Acc: 0.773196\n",
      "Epoch 28193 - Train Loss: 0.072589, Train Acc: 0.884615 | Val Loss: 0.109801, Val Acc: 0.773196\n",
      "Epoch 28194 - Train Loss: 0.072588, Train Acc: 0.884615 | Val Loss: 0.109801, Val Acc: 0.773196\n",
      "Epoch 28195 - Train Loss: 0.072586, Train Acc: 0.884615 | Val Loss: 0.109800, Val Acc: 0.773196\n",
      "Epoch 28196 - Train Loss: 0.072585, Train Acc: 0.884615 | Val Loss: 0.109800, Val Acc: 0.773196\n",
      "Epoch 28197 - Train Loss: 0.072584, Train Acc: 0.884615 | Val Loss: 0.109800, Val Acc: 0.773196\n",
      "Epoch 28198 - Train Loss: 0.072582, Train Acc: 0.884615 | Val Loss: 0.109799, Val Acc: 0.773196\n",
      "Epoch 28199 - Train Loss: 0.072581, Train Acc: 0.884615 | Val Loss: 0.109799, Val Acc: 0.773196\n",
      "Epoch 28200 - Train Loss: 0.072580, Train Acc: 0.884615 | Val Loss: 0.109799, Val Acc: 0.773196\n",
      "Epoch 28201 - Train Loss: 0.072578, Train Acc: 0.884615 | Val Loss: 0.109798, Val Acc: 0.773196\n",
      "Epoch 28202 - Train Loss: 0.072577, Train Acc: 0.884615 | Val Loss: 0.109798, Val Acc: 0.773196\n",
      "Epoch 28203 - Train Loss: 0.072576, Train Acc: 0.884615 | Val Loss: 0.109798, Val Acc: 0.773196\n",
      "Epoch 28204 - Train Loss: 0.072574, Train Acc: 0.884615 | Val Loss: 0.109797, Val Acc: 0.773196\n",
      "Epoch 28205 - Train Loss: 0.072573, Train Acc: 0.884615 | Val Loss: 0.109797, Val Acc: 0.773196\n",
      "Epoch 28206 - Train Loss: 0.072572, Train Acc: 0.884615 | Val Loss: 0.109797, Val Acc: 0.773196\n",
      "Epoch 28207 - Train Loss: 0.072570, Train Acc: 0.884615 | Val Loss: 0.109796, Val Acc: 0.773196\n",
      "Epoch 28208 - Train Loss: 0.072569, Train Acc: 0.884615 | Val Loss: 0.109796, Val Acc: 0.773196\n",
      "Epoch 28209 - Train Loss: 0.072568, Train Acc: 0.884615 | Val Loss: 0.109796, Val Acc: 0.773196\n",
      "Epoch 28210 - Train Loss: 0.072566, Train Acc: 0.884615 | Val Loss: 0.109795, Val Acc: 0.773196\n",
      "Epoch 28211 - Train Loss: 0.072565, Train Acc: 0.884615 | Val Loss: 0.109795, Val Acc: 0.773196\n",
      "Epoch 28212 - Train Loss: 0.072564, Train Acc: 0.884615 | Val Loss: 0.109795, Val Acc: 0.773196\n",
      "Epoch 28213 - Train Loss: 0.072562, Train Acc: 0.884615 | Val Loss: 0.109794, Val Acc: 0.773196\n",
      "Epoch 28214 - Train Loss: 0.072561, Train Acc: 0.884615 | Val Loss: 0.109794, Val Acc: 0.773196\n",
      "Epoch 28215 - Train Loss: 0.072560, Train Acc: 0.884615 | Val Loss: 0.109794, Val Acc: 0.773196\n",
      "Epoch 28216 - Train Loss: 0.072559, Train Acc: 0.884615 | Val Loss: 0.109793, Val Acc: 0.773196\n",
      "Epoch 28217 - Train Loss: 0.072557, Train Acc: 0.884615 | Val Loss: 0.109793, Val Acc: 0.773196\n",
      "Epoch 28218 - Train Loss: 0.072556, Train Acc: 0.884615 | Val Loss: 0.109793, Val Acc: 0.773196\n",
      "Epoch 28219 - Train Loss: 0.072555, Train Acc: 0.884615 | Val Loss: 0.109792, Val Acc: 0.773196\n",
      "Epoch 28220 - Train Loss: 0.072553, Train Acc: 0.884615 | Val Loss: 0.109792, Val Acc: 0.773196\n",
      "Epoch 28221 - Train Loss: 0.072552, Train Acc: 0.884615 | Val Loss: 0.109792, Val Acc: 0.773196\n",
      "Epoch 28222 - Train Loss: 0.072551, Train Acc: 0.884615 | Val Loss: 0.109791, Val Acc: 0.773196\n",
      "Epoch 28223 - Train Loss: 0.072549, Train Acc: 0.884615 | Val Loss: 0.109791, Val Acc: 0.773196\n",
      "Epoch 28224 - Train Loss: 0.072548, Train Acc: 0.884615 | Val Loss: 0.109791, Val Acc: 0.773196\n",
      "Epoch 28225 - Train Loss: 0.072547, Train Acc: 0.884615 | Val Loss: 0.109790, Val Acc: 0.773196\n",
      "Epoch 28226 - Train Loss: 0.072545, Train Acc: 0.884615 | Val Loss: 0.109790, Val Acc: 0.773196\n",
      "Epoch 28227 - Train Loss: 0.072544, Train Acc: 0.884615 | Val Loss: 0.109790, Val Acc: 0.773196\n",
      "Epoch 28228 - Train Loss: 0.072543, Train Acc: 0.884615 | Val Loss: 0.109789, Val Acc: 0.773196\n",
      "Epoch 28229 - Train Loss: 0.072541, Train Acc: 0.884615 | Val Loss: 0.109789, Val Acc: 0.773196\n",
      "Epoch 28230 - Train Loss: 0.072540, Train Acc: 0.884615 | Val Loss: 0.109789, Val Acc: 0.773196\n",
      "Epoch 28231 - Train Loss: 0.072539, Train Acc: 0.884615 | Val Loss: 0.109788, Val Acc: 0.773196\n",
      "Epoch 28232 - Train Loss: 0.072537, Train Acc: 0.884615 | Val Loss: 0.109788, Val Acc: 0.773196\n",
      "Epoch 28233 - Train Loss: 0.072536, Train Acc: 0.884615 | Val Loss: 0.109788, Val Acc: 0.773196\n",
      "Epoch 28234 - Train Loss: 0.072535, Train Acc: 0.884615 | Val Loss: 0.109787, Val Acc: 0.773196\n",
      "Epoch 28235 - Train Loss: 0.072533, Train Acc: 0.884615 | Val Loss: 0.109787, Val Acc: 0.773196\n",
      "Epoch 28236 - Train Loss: 0.072532, Train Acc: 0.884615 | Val Loss: 0.109787, Val Acc: 0.773196\n",
      "Epoch 28237 - Train Loss: 0.072531, Train Acc: 0.884615 | Val Loss: 0.109786, Val Acc: 0.773196\n",
      "Epoch 28238 - Train Loss: 0.072529, Train Acc: 0.884615 | Val Loss: 0.109786, Val Acc: 0.773196\n",
      "Epoch 28239 - Train Loss: 0.072528, Train Acc: 0.885897 | Val Loss: 0.109786, Val Acc: 0.773196\n",
      "Epoch 28240 - Train Loss: 0.072527, Train Acc: 0.885897 | Val Loss: 0.109785, Val Acc: 0.773196\n",
      "Epoch 28241 - Train Loss: 0.072525, Train Acc: 0.885897 | Val Loss: 0.109785, Val Acc: 0.773196\n",
      "Epoch 28242 - Train Loss: 0.072524, Train Acc: 0.885897 | Val Loss: 0.109785, Val Acc: 0.773196\n",
      "Epoch 28243 - Train Loss: 0.072523, Train Acc: 0.885897 | Val Loss: 0.109784, Val Acc: 0.773196\n",
      "Epoch 28244 - Train Loss: 0.072521, Train Acc: 0.885897 | Val Loss: 0.109784, Val Acc: 0.773196\n",
      "Epoch 28245 - Train Loss: 0.072520, Train Acc: 0.885897 | Val Loss: 0.109784, Val Acc: 0.773196\n",
      "Epoch 28246 - Train Loss: 0.072519, Train Acc: 0.885897 | Val Loss: 0.109783, Val Acc: 0.773196\n",
      "Epoch 28247 - Train Loss: 0.072517, Train Acc: 0.885897 | Val Loss: 0.109783, Val Acc: 0.773196\n",
      "Epoch 28248 - Train Loss: 0.072516, Train Acc: 0.885897 | Val Loss: 0.109783, Val Acc: 0.773196\n",
      "Epoch 28249 - Train Loss: 0.072515, Train Acc: 0.885897 | Val Loss: 0.109782, Val Acc: 0.773196\n",
      "Epoch 28250 - Train Loss: 0.072513, Train Acc: 0.885897 | Val Loss: 0.109782, Val Acc: 0.773196\n",
      "Epoch 28251 - Train Loss: 0.072512, Train Acc: 0.885897 | Val Loss: 0.109781, Val Acc: 0.773196\n",
      "Epoch 28252 - Train Loss: 0.072511, Train Acc: 0.885897 | Val Loss: 0.109781, Val Acc: 0.773196\n",
      "Epoch 28253 - Train Loss: 0.072509, Train Acc: 0.885897 | Val Loss: 0.109781, Val Acc: 0.773196\n",
      "Epoch 28254 - Train Loss: 0.072508, Train Acc: 0.885897 | Val Loss: 0.109781, Val Acc: 0.773196\n",
      "Epoch 28255 - Train Loss: 0.072507, Train Acc: 0.885897 | Val Loss: 0.109780, Val Acc: 0.773196\n",
      "Epoch 28256 - Train Loss: 0.072505, Train Acc: 0.885897 | Val Loss: 0.109780, Val Acc: 0.773196\n",
      "Epoch 28257 - Train Loss: 0.072504, Train Acc: 0.885897 | Val Loss: 0.109780, Val Acc: 0.773196\n",
      "Epoch 28258 - Train Loss: 0.072503, Train Acc: 0.885897 | Val Loss: 0.109779, Val Acc: 0.773196\n",
      "Epoch 28259 - Train Loss: 0.072502, Train Acc: 0.885897 | Val Loss: 0.109779, Val Acc: 0.773196\n",
      "Epoch 28260 - Train Loss: 0.072500, Train Acc: 0.885897 | Val Loss: 0.109779, Val Acc: 0.773196\n",
      "Epoch 28261 - Train Loss: 0.072499, Train Acc: 0.885897 | Val Loss: 0.109778, Val Acc: 0.773196\n",
      "Epoch 28262 - Train Loss: 0.072498, Train Acc: 0.885897 | Val Loss: 0.109778, Val Acc: 0.773196\n",
      "Epoch 28263 - Train Loss: 0.072496, Train Acc: 0.885897 | Val Loss: 0.109778, Val Acc: 0.773196\n",
      "Epoch 28264 - Train Loss: 0.072495, Train Acc: 0.885897 | Val Loss: 0.109777, Val Acc: 0.773196\n",
      "Epoch 28265 - Train Loss: 0.072494, Train Acc: 0.885897 | Val Loss: 0.109777, Val Acc: 0.773196\n",
      "Epoch 28266 - Train Loss: 0.072492, Train Acc: 0.885897 | Val Loss: 0.109777, Val Acc: 0.773196\n",
      "Epoch 28267 - Train Loss: 0.072491, Train Acc: 0.885897 | Val Loss: 0.109776, Val Acc: 0.773196\n",
      "Epoch 28268 - Train Loss: 0.072490, Train Acc: 0.885897 | Val Loss: 0.109776, Val Acc: 0.773196\n",
      "Epoch 28269 - Train Loss: 0.072488, Train Acc: 0.885897 | Val Loss: 0.109775, Val Acc: 0.773196\n",
      "Epoch 28270 - Train Loss: 0.072487, Train Acc: 0.885897 | Val Loss: 0.109775, Val Acc: 0.773196\n",
      "Epoch 28271 - Train Loss: 0.072486, Train Acc: 0.885897 | Val Loss: 0.109775, Val Acc: 0.773196\n",
      "Epoch 28272 - Train Loss: 0.072484, Train Acc: 0.885897 | Val Loss: 0.109774, Val Acc: 0.773196\n",
      "Epoch 28273 - Train Loss: 0.072483, Train Acc: 0.885897 | Val Loss: 0.109774, Val Acc: 0.773196\n",
      "Epoch 28274 - Train Loss: 0.072482, Train Acc: 0.885897 | Val Loss: 0.109774, Val Acc: 0.773196\n",
      "Epoch 28275 - Train Loss: 0.072480, Train Acc: 0.885897 | Val Loss: 0.109774, Val Acc: 0.773196\n",
      "Epoch 28276 - Train Loss: 0.072479, Train Acc: 0.885897 | Val Loss: 0.109773, Val Acc: 0.773196\n",
      "Epoch 28277 - Train Loss: 0.072478, Train Acc: 0.885897 | Val Loss: 0.109773, Val Acc: 0.773196\n",
      "Epoch 28278 - Train Loss: 0.072476, Train Acc: 0.885897 | Val Loss: 0.109773, Val Acc: 0.773196\n",
      "Epoch 28279 - Train Loss: 0.072475, Train Acc: 0.885897 | Val Loss: 0.109772, Val Acc: 0.773196\n",
      "Epoch 28280 - Train Loss: 0.072474, Train Acc: 0.885897 | Val Loss: 0.109772, Val Acc: 0.773196\n",
      "Epoch 28281 - Train Loss: 0.072472, Train Acc: 0.885897 | Val Loss: 0.109772, Val Acc: 0.773196\n",
      "Epoch 28282 - Train Loss: 0.072471, Train Acc: 0.885897 | Val Loss: 0.109771, Val Acc: 0.773196\n",
      "Epoch 28283 - Train Loss: 0.072470, Train Acc: 0.885897 | Val Loss: 0.109771, Val Acc: 0.773196\n",
      "Epoch 28284 - Train Loss: 0.072468, Train Acc: 0.885897 | Val Loss: 0.109770, Val Acc: 0.773196\n",
      "Epoch 28285 - Train Loss: 0.072467, Train Acc: 0.885897 | Val Loss: 0.109770, Val Acc: 0.773196\n",
      "Epoch 28286 - Train Loss: 0.072466, Train Acc: 0.885897 | Val Loss: 0.109770, Val Acc: 0.773196\n",
      "Epoch 28287 - Train Loss: 0.072464, Train Acc: 0.885897 | Val Loss: 0.109769, Val Acc: 0.773196\n",
      "Epoch 28288 - Train Loss: 0.072463, Train Acc: 0.885897 | Val Loss: 0.109769, Val Acc: 0.773196\n",
      "Epoch 28289 - Train Loss: 0.072462, Train Acc: 0.885897 | Val Loss: 0.109769, Val Acc: 0.773196\n",
      "Epoch 28290 - Train Loss: 0.072460, Train Acc: 0.885897 | Val Loss: 0.109768, Val Acc: 0.773196\n",
      "Epoch 28291 - Train Loss: 0.072459, Train Acc: 0.885897 | Val Loss: 0.109768, Val Acc: 0.773196\n",
      "Epoch 28292 - Train Loss: 0.072458, Train Acc: 0.885897 | Val Loss: 0.109768, Val Acc: 0.773196\n",
      "Epoch 28293 - Train Loss: 0.072457, Train Acc: 0.885897 | Val Loss: 0.109768, Val Acc: 0.773196\n",
      "Epoch 28294 - Train Loss: 0.072455, Train Acc: 0.885897 | Val Loss: 0.109767, Val Acc: 0.773196\n",
      "Epoch 28295 - Train Loss: 0.072454, Train Acc: 0.885897 | Val Loss: 0.109767, Val Acc: 0.773196\n",
      "Epoch 28296 - Train Loss: 0.072453, Train Acc: 0.885897 | Val Loss: 0.109767, Val Acc: 0.773196\n",
      "Epoch 28297 - Train Loss: 0.072451, Train Acc: 0.885897 | Val Loss: 0.109766, Val Acc: 0.773196\n",
      "Epoch 28298 - Train Loss: 0.072450, Train Acc: 0.885897 | Val Loss: 0.109766, Val Acc: 0.773196\n",
      "Epoch 28299 - Train Loss: 0.072449, Train Acc: 0.885897 | Val Loss: 0.109766, Val Acc: 0.773196\n",
      "Epoch 28300 - Train Loss: 0.072447, Train Acc: 0.885897 | Val Loss: 0.109765, Val Acc: 0.773196\n",
      "Epoch 28301 - Train Loss: 0.072446, Train Acc: 0.885897 | Val Loss: 0.109765, Val Acc: 0.773196\n",
      "Epoch 28302 - Train Loss: 0.072445, Train Acc: 0.885897 | Val Loss: 0.109764, Val Acc: 0.773196\n",
      "Epoch 28303 - Train Loss: 0.072443, Train Acc: 0.885897 | Val Loss: 0.109764, Val Acc: 0.773196\n",
      "Epoch 28304 - Train Loss: 0.072442, Train Acc: 0.885897 | Val Loss: 0.109764, Val Acc: 0.773196\n",
      "Epoch 28305 - Train Loss: 0.072441, Train Acc: 0.885897 | Val Loss: 0.109763, Val Acc: 0.773196\n",
      "Epoch 28306 - Train Loss: 0.072439, Train Acc: 0.885897 | Val Loss: 0.109763, Val Acc: 0.773196\n",
      "Epoch 28307 - Train Loss: 0.072438, Train Acc: 0.885897 | Val Loss: 0.109763, Val Acc: 0.773196\n",
      "Epoch 28308 - Train Loss: 0.072437, Train Acc: 0.885897 | Val Loss: 0.109763, Val Acc: 0.773196\n",
      "Epoch 28309 - Train Loss: 0.072435, Train Acc: 0.885897 | Val Loss: 0.109762, Val Acc: 0.773196\n",
      "Epoch 28310 - Train Loss: 0.072434, Train Acc: 0.885897 | Val Loss: 0.109762, Val Acc: 0.773196\n",
      "Epoch 28311 - Train Loss: 0.072433, Train Acc: 0.885897 | Val Loss: 0.109762, Val Acc: 0.773196\n",
      "Epoch 28312 - Train Loss: 0.072431, Train Acc: 0.885897 | Val Loss: 0.109761, Val Acc: 0.773196\n",
      "Epoch 28313 - Train Loss: 0.072430, Train Acc: 0.885897 | Val Loss: 0.109761, Val Acc: 0.773196\n",
      "Epoch 28314 - Train Loss: 0.072429, Train Acc: 0.885897 | Val Loss: 0.109761, Val Acc: 0.773196\n",
      "Epoch 28315 - Train Loss: 0.072427, Train Acc: 0.885897 | Val Loss: 0.109760, Val Acc: 0.773196\n",
      "Epoch 28316 - Train Loss: 0.072426, Train Acc: 0.885897 | Val Loss: 0.109760, Val Acc: 0.773196\n",
      "Epoch 28317 - Train Loss: 0.072425, Train Acc: 0.885897 | Val Loss: 0.109759, Val Acc: 0.773196\n",
      "Epoch 28318 - Train Loss: 0.072423, Train Acc: 0.885897 | Val Loss: 0.109759, Val Acc: 0.773196\n",
      "Epoch 28319 - Train Loss: 0.072422, Train Acc: 0.885897 | Val Loss: 0.109759, Val Acc: 0.773196\n",
      "Epoch 28320 - Train Loss: 0.072421, Train Acc: 0.885897 | Val Loss: 0.109758, Val Acc: 0.773196\n",
      "Epoch 28321 - Train Loss: 0.072420, Train Acc: 0.885897 | Val Loss: 0.109758, Val Acc: 0.773196\n",
      "Epoch 28322 - Train Loss: 0.072418, Train Acc: 0.885897 | Val Loss: 0.109758, Val Acc: 0.773196\n",
      "Epoch 28323 - Train Loss: 0.072417, Train Acc: 0.885897 | Val Loss: 0.109758, Val Acc: 0.773196\n",
      "Epoch 28324 - Train Loss: 0.072416, Train Acc: 0.885897 | Val Loss: 0.109757, Val Acc: 0.773196\n",
      "Epoch 28325 - Train Loss: 0.072414, Train Acc: 0.885897 | Val Loss: 0.109757, Val Acc: 0.773196\n",
      "Epoch 28326 - Train Loss: 0.072413, Train Acc: 0.885897 | Val Loss: 0.109757, Val Acc: 0.773196\n",
      "Epoch 28327 - Train Loss: 0.072412, Train Acc: 0.885897 | Val Loss: 0.109756, Val Acc: 0.773196\n",
      "Epoch 28328 - Train Loss: 0.072410, Train Acc: 0.885897 | Val Loss: 0.109756, Val Acc: 0.773196\n",
      "Epoch 28329 - Train Loss: 0.072409, Train Acc: 0.885897 | Val Loss: 0.109756, Val Acc: 0.773196\n",
      "Epoch 28330 - Train Loss: 0.072408, Train Acc: 0.885897 | Val Loss: 0.109755, Val Acc: 0.773196\n",
      "Epoch 28331 - Train Loss: 0.072406, Train Acc: 0.885897 | Val Loss: 0.109755, Val Acc: 0.773196\n",
      "Epoch 28332 - Train Loss: 0.072405, Train Acc: 0.885897 | Val Loss: 0.109754, Val Acc: 0.773196\n",
      "Epoch 28333 - Train Loss: 0.072404, Train Acc: 0.885897 | Val Loss: 0.109754, Val Acc: 0.773196\n",
      "Epoch 28334 - Train Loss: 0.072402, Train Acc: 0.885897 | Val Loss: 0.109754, Val Acc: 0.773196\n",
      "Epoch 28335 - Train Loss: 0.072401, Train Acc: 0.885897 | Val Loss: 0.109753, Val Acc: 0.773196\n",
      "Epoch 28336 - Train Loss: 0.072400, Train Acc: 0.885897 | Val Loss: 0.109753, Val Acc: 0.773196\n",
      "Epoch 28337 - Train Loss: 0.072398, Train Acc: 0.885897 | Val Loss: 0.109753, Val Acc: 0.773196\n",
      "Epoch 28338 - Train Loss: 0.072397, Train Acc: 0.885897 | Val Loss: 0.109753, Val Acc: 0.773196\n",
      "Epoch 28339 - Train Loss: 0.072396, Train Acc: 0.885897 | Val Loss: 0.109752, Val Acc: 0.773196\n",
      "Epoch 28340 - Train Loss: 0.072394, Train Acc: 0.885897 | Val Loss: 0.109752, Val Acc: 0.773196\n",
      "Epoch 28341 - Train Loss: 0.072393, Train Acc: 0.885897 | Val Loss: 0.109752, Val Acc: 0.773196\n",
      "Epoch 28342 - Train Loss: 0.072392, Train Acc: 0.885897 | Val Loss: 0.109751, Val Acc: 0.773196\n",
      "Epoch 28343 - Train Loss: 0.072390, Train Acc: 0.885897 | Val Loss: 0.109751, Val Acc: 0.773196\n",
      "Epoch 28344 - Train Loss: 0.072389, Train Acc: 0.885897 | Val Loss: 0.109751, Val Acc: 0.773196\n",
      "Epoch 28345 - Train Loss: 0.072388, Train Acc: 0.885897 | Val Loss: 0.109750, Val Acc: 0.773196\n",
      "Epoch 28346 - Train Loss: 0.072387, Train Acc: 0.885897 | Val Loss: 0.109750, Val Acc: 0.773196\n",
      "Epoch 28347 - Train Loss: 0.072385, Train Acc: 0.885897 | Val Loss: 0.109749, Val Acc: 0.773196\n",
      "Epoch 28348 - Train Loss: 0.072384, Train Acc: 0.885897 | Val Loss: 0.109749, Val Acc: 0.773196\n",
      "Epoch 28349 - Train Loss: 0.072383, Train Acc: 0.885897 | Val Loss: 0.109749, Val Acc: 0.773196\n",
      "Epoch 28350 - Train Loss: 0.072381, Train Acc: 0.885897 | Val Loss: 0.109749, Val Acc: 0.773196\n",
      "Epoch 28351 - Train Loss: 0.072380, Train Acc: 0.885897 | Val Loss: 0.109748, Val Acc: 0.773196\n",
      "Epoch 28352 - Train Loss: 0.072379, Train Acc: 0.885897 | Val Loss: 0.109748, Val Acc: 0.773196\n",
      "Epoch 28353 - Train Loss: 0.072377, Train Acc: 0.885897 | Val Loss: 0.109748, Val Acc: 0.773196\n",
      "Epoch 28354 - Train Loss: 0.072376, Train Acc: 0.885897 | Val Loss: 0.109747, Val Acc: 0.773196\n",
      "Epoch 28355 - Train Loss: 0.072375, Train Acc: 0.885897 | Val Loss: 0.109747, Val Acc: 0.773196\n",
      "Epoch 28356 - Train Loss: 0.072373, Train Acc: 0.885897 | Val Loss: 0.109747, Val Acc: 0.773196\n",
      "Epoch 28357 - Train Loss: 0.072372, Train Acc: 0.885897 | Val Loss: 0.109746, Val Acc: 0.773196\n",
      "Epoch 28358 - Train Loss: 0.072371, Train Acc: 0.885897 | Val Loss: 0.109746, Val Acc: 0.773196\n",
      "Epoch 28359 - Train Loss: 0.072369, Train Acc: 0.885897 | Val Loss: 0.109746, Val Acc: 0.773196\n",
      "Epoch 28360 - Train Loss: 0.072368, Train Acc: 0.885897 | Val Loss: 0.109745, Val Acc: 0.773196\n",
      "Epoch 28361 - Train Loss: 0.072367, Train Acc: 0.885897 | Val Loss: 0.109745, Val Acc: 0.773196\n",
      "Epoch 28362 - Train Loss: 0.072365, Train Acc: 0.885897 | Val Loss: 0.109745, Val Acc: 0.773196\n",
      "Epoch 28363 - Train Loss: 0.072364, Train Acc: 0.885897 | Val Loss: 0.109744, Val Acc: 0.773196\n",
      "Epoch 28364 - Train Loss: 0.072363, Train Acc: 0.885897 | Val Loss: 0.109744, Val Acc: 0.773196\n",
      "Epoch 28365 - Train Loss: 0.072361, Train Acc: 0.885897 | Val Loss: 0.109744, Val Acc: 0.773196\n",
      "Epoch 28366 - Train Loss: 0.072360, Train Acc: 0.885897 | Val Loss: 0.109743, Val Acc: 0.773196\n",
      "Epoch 28367 - Train Loss: 0.072359, Train Acc: 0.885897 | Val Loss: 0.109743, Val Acc: 0.773196\n",
      "Epoch 28368 - Train Loss: 0.072358, Train Acc: 0.885897 | Val Loss: 0.109743, Val Acc: 0.773196\n",
      "Epoch 28369 - Train Loss: 0.072356, Train Acc: 0.885897 | Val Loss: 0.109742, Val Acc: 0.773196\n",
      "Epoch 28370 - Train Loss: 0.072355, Train Acc: 0.885897 | Val Loss: 0.109742, Val Acc: 0.773196\n",
      "Epoch 28371 - Train Loss: 0.072354, Train Acc: 0.885897 | Val Loss: 0.109742, Val Acc: 0.773196\n",
      "Epoch 28372 - Train Loss: 0.072352, Train Acc: 0.885897 | Val Loss: 0.109741, Val Acc: 0.773196\n",
      "Epoch 28373 - Train Loss: 0.072351, Train Acc: 0.885897 | Val Loss: 0.109741, Val Acc: 0.773196\n",
      "Epoch 28374 - Train Loss: 0.072350, Train Acc: 0.885897 | Val Loss: 0.109741, Val Acc: 0.773196\n",
      "Epoch 28375 - Train Loss: 0.072348, Train Acc: 0.885897 | Val Loss: 0.109740, Val Acc: 0.773196\n",
      "Epoch 28376 - Train Loss: 0.072347, Train Acc: 0.885897 | Val Loss: 0.109740, Val Acc: 0.773196\n",
      "Epoch 28377 - Train Loss: 0.072346, Train Acc: 0.885897 | Val Loss: 0.109740, Val Acc: 0.773196\n",
      "Epoch 28378 - Train Loss: 0.072344, Train Acc: 0.885897 | Val Loss: 0.109739, Val Acc: 0.773196\n",
      "Epoch 28379 - Train Loss: 0.072343, Train Acc: 0.885897 | Val Loss: 0.109739, Val Acc: 0.773196\n",
      "Epoch 28380 - Train Loss: 0.072342, Train Acc: 0.885897 | Val Loss: 0.109739, Val Acc: 0.773196\n",
      "Epoch 28381 - Train Loss: 0.072340, Train Acc: 0.885897 | Val Loss: 0.109738, Val Acc: 0.773196\n",
      "Epoch 28382 - Train Loss: 0.072339, Train Acc: 0.885897 | Val Loss: 0.109738, Val Acc: 0.773196\n",
      "Epoch 28383 - Train Loss: 0.072338, Train Acc: 0.885897 | Val Loss: 0.109738, Val Acc: 0.773196\n",
      "Epoch 28384 - Train Loss: 0.072336, Train Acc: 0.885897 | Val Loss: 0.109737, Val Acc: 0.773196\n",
      "Epoch 28385 - Train Loss: 0.072335, Train Acc: 0.885897 | Val Loss: 0.109737, Val Acc: 0.773196\n",
      "Epoch 28386 - Train Loss: 0.072334, Train Acc: 0.885897 | Val Loss: 0.109737, Val Acc: 0.773196\n",
      "Epoch 28387 - Train Loss: 0.072333, Train Acc: 0.885897 | Val Loss: 0.109736, Val Acc: 0.773196\n",
      "Epoch 28388 - Train Loss: 0.072331, Train Acc: 0.885897 | Val Loss: 0.109736, Val Acc: 0.773196\n",
      "Epoch 28389 - Train Loss: 0.072330, Train Acc: 0.885897 | Val Loss: 0.109736, Val Acc: 0.773196\n",
      "Epoch 28390 - Train Loss: 0.072329, Train Acc: 0.885897 | Val Loss: 0.109735, Val Acc: 0.773196\n",
      "Epoch 28391 - Train Loss: 0.072327, Train Acc: 0.885897 | Val Loss: 0.109735, Val Acc: 0.773196\n",
      "Epoch 28392 - Train Loss: 0.072326, Train Acc: 0.885897 | Val Loss: 0.109735, Val Acc: 0.773196\n",
      "Epoch 28393 - Train Loss: 0.072325, Train Acc: 0.885897 | Val Loss: 0.109734, Val Acc: 0.773196\n",
      "Epoch 28394 - Train Loss: 0.072323, Train Acc: 0.885897 | Val Loss: 0.109734, Val Acc: 0.773196\n",
      "Epoch 28395 - Train Loss: 0.072322, Train Acc: 0.885897 | Val Loss: 0.109734, Val Acc: 0.773196\n",
      "Epoch 28396 - Train Loss: 0.072321, Train Acc: 0.885897 | Val Loss: 0.109733, Val Acc: 0.773196\n",
      "Epoch 28397 - Train Loss: 0.072319, Train Acc: 0.885897 | Val Loss: 0.109733, Val Acc: 0.773196\n",
      "Epoch 28398 - Train Loss: 0.072318, Train Acc: 0.885897 | Val Loss: 0.109733, Val Acc: 0.773196\n",
      "Epoch 28399 - Train Loss: 0.072317, Train Acc: 0.884615 | Val Loss: 0.109732, Val Acc: 0.773196\n",
      "Epoch 28400 - Train Loss: 0.072315, Train Acc: 0.884615 | Val Loss: 0.109732, Val Acc: 0.773196\n",
      "Epoch 28401 - Train Loss: 0.072314, Train Acc: 0.884615 | Val Loss: 0.109732, Val Acc: 0.773196\n",
      "Epoch 28402 - Train Loss: 0.072313, Train Acc: 0.884615 | Val Loss: 0.109731, Val Acc: 0.773196\n",
      "Epoch 28403 - Train Loss: 0.072311, Train Acc: 0.884615 | Val Loss: 0.109731, Val Acc: 0.773196\n",
      "Epoch 28404 - Train Loss: 0.072310, Train Acc: 0.884615 | Val Loss: 0.109731, Val Acc: 0.773196\n",
      "Epoch 28405 - Train Loss: 0.072309, Train Acc: 0.884615 | Val Loss: 0.109730, Val Acc: 0.773196\n",
      "Epoch 28406 - Train Loss: 0.072308, Train Acc: 0.884615 | Val Loss: 0.109730, Val Acc: 0.773196\n",
      "Epoch 28407 - Train Loss: 0.072306, Train Acc: 0.884615 | Val Loss: 0.109730, Val Acc: 0.773196\n",
      "Epoch 28408 - Train Loss: 0.072305, Train Acc: 0.885897 | Val Loss: 0.109729, Val Acc: 0.773196\n",
      "Epoch 28409 - Train Loss: 0.072304, Train Acc: 0.885897 | Val Loss: 0.109729, Val Acc: 0.773196\n",
      "Epoch 28410 - Train Loss: 0.072302, Train Acc: 0.885897 | Val Loss: 0.109729, Val Acc: 0.773196\n",
      "Epoch 28411 - Train Loss: 0.072301, Train Acc: 0.885897 | Val Loss: 0.109729, Val Acc: 0.773196\n",
      "Epoch 28412 - Train Loss: 0.072300, Train Acc: 0.885897 | Val Loss: 0.109728, Val Acc: 0.773196\n",
      "Epoch 28413 - Train Loss: 0.072298, Train Acc: 0.885897 | Val Loss: 0.109728, Val Acc: 0.773196\n",
      "Epoch 28414 - Train Loss: 0.072297, Train Acc: 0.885897 | Val Loss: 0.109728, Val Acc: 0.773196\n",
      "Epoch 28415 - Train Loss: 0.072296, Train Acc: 0.885897 | Val Loss: 0.109727, Val Acc: 0.773196\n",
      "Epoch 28416 - Train Loss: 0.072294, Train Acc: 0.885897 | Val Loss: 0.109727, Val Acc: 0.773196\n",
      "Epoch 28417 - Train Loss: 0.072293, Train Acc: 0.885897 | Val Loss: 0.109726, Val Acc: 0.773196\n",
      "Epoch 28418 - Train Loss: 0.072292, Train Acc: 0.885897 | Val Loss: 0.109726, Val Acc: 0.773196\n",
      "Epoch 28419 - Train Loss: 0.072290, Train Acc: 0.885897 | Val Loss: 0.109726, Val Acc: 0.773196\n",
      "Epoch 28420 - Train Loss: 0.072289, Train Acc: 0.885897 | Val Loss: 0.109726, Val Acc: 0.773196\n",
      "Epoch 28421 - Train Loss: 0.072288, Train Acc: 0.885897 | Val Loss: 0.109725, Val Acc: 0.773196\n",
      "Epoch 28422 - Train Loss: 0.072287, Train Acc: 0.885897 | Val Loss: 0.109725, Val Acc: 0.773196\n",
      "Epoch 28423 - Train Loss: 0.072285, Train Acc: 0.885897 | Val Loss: 0.109725, Val Acc: 0.773196\n",
      "Epoch 28424 - Train Loss: 0.072284, Train Acc: 0.885897 | Val Loss: 0.109724, Val Acc: 0.773196\n",
      "Epoch 28425 - Train Loss: 0.072283, Train Acc: 0.885897 | Val Loss: 0.109724, Val Acc: 0.773196\n",
      "Epoch 28426 - Train Loss: 0.072281, Train Acc: 0.885897 | Val Loss: 0.109724, Val Acc: 0.773196\n",
      "Epoch 28427 - Train Loss: 0.072280, Train Acc: 0.885897 | Val Loss: 0.109723, Val Acc: 0.773196\n",
      "Epoch 28428 - Train Loss: 0.072279, Train Acc: 0.885897 | Val Loss: 0.109723, Val Acc: 0.773196\n",
      "Epoch 28429 - Train Loss: 0.072277, Train Acc: 0.885897 | Val Loss: 0.109723, Val Acc: 0.773196\n",
      "Epoch 28430 - Train Loss: 0.072276, Train Acc: 0.885897 | Val Loss: 0.109722, Val Acc: 0.773196\n",
      "Epoch 28431 - Train Loss: 0.072275, Train Acc: 0.885897 | Val Loss: 0.109722, Val Acc: 0.773196\n",
      "Epoch 28432 - Train Loss: 0.072273, Train Acc: 0.885897 | Val Loss: 0.109722, Val Acc: 0.773196\n",
      "Epoch 28433 - Train Loss: 0.072272, Train Acc: 0.885897 | Val Loss: 0.109721, Val Acc: 0.773196\n",
      "Epoch 28434 - Train Loss: 0.072271, Train Acc: 0.885897 | Val Loss: 0.109721, Val Acc: 0.773196\n",
      "Epoch 28435 - Train Loss: 0.072269, Train Acc: 0.885897 | Val Loss: 0.109721, Val Acc: 0.773196\n",
      "Epoch 28436 - Train Loss: 0.072268, Train Acc: 0.885897 | Val Loss: 0.109720, Val Acc: 0.773196\n",
      "Epoch 28437 - Train Loss: 0.072267, Train Acc: 0.885897 | Val Loss: 0.109720, Val Acc: 0.773196\n",
      "Epoch 28438 - Train Loss: 0.072265, Train Acc: 0.885897 | Val Loss: 0.109720, Val Acc: 0.773196\n",
      "Epoch 28439 - Train Loss: 0.072264, Train Acc: 0.885897 | Val Loss: 0.109719, Val Acc: 0.773196\n",
      "Epoch 28440 - Train Loss: 0.072263, Train Acc: 0.885897 | Val Loss: 0.109719, Val Acc: 0.773196\n",
      "Epoch 28441 - Train Loss: 0.072262, Train Acc: 0.885897 | Val Loss: 0.109719, Val Acc: 0.773196\n",
      "Epoch 28442 - Train Loss: 0.072260, Train Acc: 0.885897 | Val Loss: 0.109718, Val Acc: 0.773196\n",
      "Epoch 28443 - Train Loss: 0.072259, Train Acc: 0.885897 | Val Loss: 0.109718, Val Acc: 0.773196\n",
      "Epoch 28444 - Train Loss: 0.072258, Train Acc: 0.885897 | Val Loss: 0.109718, Val Acc: 0.773196\n",
      "Epoch 28445 - Train Loss: 0.072256, Train Acc: 0.885897 | Val Loss: 0.109717, Val Acc: 0.773196\n",
      "Epoch 28446 - Train Loss: 0.072255, Train Acc: 0.885897 | Val Loss: 0.109717, Val Acc: 0.773196\n",
      "Epoch 28447 - Train Loss: 0.072254, Train Acc: 0.885897 | Val Loss: 0.109717, Val Acc: 0.773196\n",
      "Epoch 28448 - Train Loss: 0.072252, Train Acc: 0.885897 | Val Loss: 0.109716, Val Acc: 0.773196\n",
      "Epoch 28449 - Train Loss: 0.072251, Train Acc: 0.885897 | Val Loss: 0.109716, Val Acc: 0.773196\n",
      "Epoch 28450 - Train Loss: 0.072250, Train Acc: 0.885897 | Val Loss: 0.109716, Val Acc: 0.773196\n",
      "Epoch 28451 - Train Loss: 0.072248, Train Acc: 0.885897 | Val Loss: 0.109715, Val Acc: 0.773196\n",
      "Epoch 28452 - Train Loss: 0.072247, Train Acc: 0.885897 | Val Loss: 0.109715, Val Acc: 0.773196\n",
      "Epoch 28453 - Train Loss: 0.072246, Train Acc: 0.885897 | Val Loss: 0.109715, Val Acc: 0.773196\n",
      "Epoch 28454 - Train Loss: 0.072244, Train Acc: 0.885897 | Val Loss: 0.109714, Val Acc: 0.773196\n",
      "Epoch 28455 - Train Loss: 0.072243, Train Acc: 0.885897 | Val Loss: 0.109714, Val Acc: 0.773196\n",
      "Epoch 28456 - Train Loss: 0.072242, Train Acc: 0.885897 | Val Loss: 0.109714, Val Acc: 0.773196\n",
      "Epoch 28457 - Train Loss: 0.072241, Train Acc: 0.885897 | Val Loss: 0.109713, Val Acc: 0.773196\n",
      "Epoch 28458 - Train Loss: 0.072239, Train Acc: 0.885897 | Val Loss: 0.109713, Val Acc: 0.773196\n",
      "Epoch 28459 - Train Loss: 0.072238, Train Acc: 0.885897 | Val Loss: 0.109713, Val Acc: 0.773196\n",
      "Epoch 28460 - Train Loss: 0.072237, Train Acc: 0.885897 | Val Loss: 0.109713, Val Acc: 0.773196\n",
      "Epoch 28461 - Train Loss: 0.072235, Train Acc: 0.885897 | Val Loss: 0.109712, Val Acc: 0.773196\n",
      "Epoch 28462 - Train Loss: 0.072234, Train Acc: 0.885897 | Val Loss: 0.109712, Val Acc: 0.773196\n",
      "Epoch 28463 - Train Loss: 0.072233, Train Acc: 0.885897 | Val Loss: 0.109711, Val Acc: 0.773196\n",
      "Epoch 28464 - Train Loss: 0.072231, Train Acc: 0.885897 | Val Loss: 0.109711, Val Acc: 0.773196\n",
      "Epoch 28465 - Train Loss: 0.072230, Train Acc: 0.885897 | Val Loss: 0.109711, Val Acc: 0.773196\n",
      "Epoch 28466 - Train Loss: 0.072229, Train Acc: 0.885897 | Val Loss: 0.109711, Val Acc: 0.773196\n",
      "Epoch 28467 - Train Loss: 0.072227, Train Acc: 0.885897 | Val Loss: 0.109710, Val Acc: 0.773196\n",
      "Epoch 28468 - Train Loss: 0.072226, Train Acc: 0.885897 | Val Loss: 0.109710, Val Acc: 0.773196\n",
      "Epoch 28469 - Train Loss: 0.072225, Train Acc: 0.885897 | Val Loss: 0.109710, Val Acc: 0.773196\n",
      "Epoch 28470 - Train Loss: 0.072224, Train Acc: 0.885897 | Val Loss: 0.109709, Val Acc: 0.773196\n",
      "Epoch 28471 - Train Loss: 0.072222, Train Acc: 0.885897 | Val Loss: 0.109709, Val Acc: 0.773196\n",
      "Epoch 28472 - Train Loss: 0.072221, Train Acc: 0.885897 | Val Loss: 0.109709, Val Acc: 0.773196\n",
      "Epoch 28473 - Train Loss: 0.072220, Train Acc: 0.885897 | Val Loss: 0.109708, Val Acc: 0.773196\n",
      "Epoch 28474 - Train Loss: 0.072218, Train Acc: 0.885897 | Val Loss: 0.109708, Val Acc: 0.773196\n",
      "Epoch 28475 - Train Loss: 0.072217, Train Acc: 0.885897 | Val Loss: 0.109708, Val Acc: 0.773196\n",
      "Epoch 28476 - Train Loss: 0.072216, Train Acc: 0.885897 | Val Loss: 0.109707, Val Acc: 0.773196\n",
      "Epoch 28477 - Train Loss: 0.072214, Train Acc: 0.885897 | Val Loss: 0.109707, Val Acc: 0.773196\n",
      "Epoch 28478 - Train Loss: 0.072213, Train Acc: 0.885897 | Val Loss: 0.109707, Val Acc: 0.773196\n",
      "Epoch 28479 - Train Loss: 0.072212, Train Acc: 0.885897 | Val Loss: 0.109706, Val Acc: 0.773196\n",
      "Epoch 28480 - Train Loss: 0.072210, Train Acc: 0.885897 | Val Loss: 0.109706, Val Acc: 0.773196\n",
      "Epoch 28481 - Train Loss: 0.072209, Train Acc: 0.885897 | Val Loss: 0.109706, Val Acc: 0.773196\n",
      "Epoch 28482 - Train Loss: 0.072208, Train Acc: 0.885897 | Val Loss: 0.109705, Val Acc: 0.773196\n",
      "Epoch 28483 - Train Loss: 0.072206, Train Acc: 0.885897 | Val Loss: 0.109705, Val Acc: 0.773196\n",
      "Epoch 28484 - Train Loss: 0.072205, Train Acc: 0.885897 | Val Loss: 0.109705, Val Acc: 0.773196\n",
      "Epoch 28485 - Train Loss: 0.072204, Train Acc: 0.885897 | Val Loss: 0.109704, Val Acc: 0.773196\n",
      "Epoch 28486 - Train Loss: 0.072203, Train Acc: 0.885897 | Val Loss: 0.109704, Val Acc: 0.773196\n",
      "Epoch 28487 - Train Loss: 0.072201, Train Acc: 0.885897 | Val Loss: 0.109704, Val Acc: 0.773196\n",
      "Epoch 28488 - Train Loss: 0.072200, Train Acc: 0.885897 | Val Loss: 0.109703, Val Acc: 0.773196\n",
      "Epoch 28489 - Train Loss: 0.072199, Train Acc: 0.885897 | Val Loss: 0.109703, Val Acc: 0.773196\n",
      "Epoch 28490 - Train Loss: 0.072197, Train Acc: 0.885897 | Val Loss: 0.109703, Val Acc: 0.773196\n",
      "Epoch 28491 - Train Loss: 0.072196, Train Acc: 0.885897 | Val Loss: 0.109702, Val Acc: 0.773196\n",
      "Epoch 28492 - Train Loss: 0.072195, Train Acc: 0.885897 | Val Loss: 0.109702, Val Acc: 0.773196\n",
      "Epoch 28493 - Train Loss: 0.072193, Train Acc: 0.885897 | Val Loss: 0.109702, Val Acc: 0.773196\n",
      "Epoch 28494 - Train Loss: 0.072192, Train Acc: 0.885897 | Val Loss: 0.109701, Val Acc: 0.773196\n",
      "Epoch 28495 - Train Loss: 0.072191, Train Acc: 0.885897 | Val Loss: 0.109701, Val Acc: 0.773196\n",
      "Epoch 28496 - Train Loss: 0.072189, Train Acc: 0.885897 | Val Loss: 0.109701, Val Acc: 0.773196\n",
      "Epoch 28497 - Train Loss: 0.072188, Train Acc: 0.885897 | Val Loss: 0.109700, Val Acc: 0.773196\n",
      "Epoch 28498 - Train Loss: 0.072187, Train Acc: 0.885897 | Val Loss: 0.109700, Val Acc: 0.773196\n",
      "Epoch 28499 - Train Loss: 0.072186, Train Acc: 0.885897 | Val Loss: 0.109700, Val Acc: 0.773196\n",
      "Epoch 28500 - Train Loss: 0.072184, Train Acc: 0.885897 | Val Loss: 0.109700, Val Acc: 0.773196\n",
      "Epoch 28501 - Train Loss: 0.072183, Train Acc: 0.885897 | Val Loss: 0.109699, Val Acc: 0.773196\n",
      "Epoch 28502 - Train Loss: 0.072182, Train Acc: 0.885897 | Val Loss: 0.109699, Val Acc: 0.773196\n",
      "Epoch 28503 - Train Loss: 0.072180, Train Acc: 0.885897 | Val Loss: 0.109699, Val Acc: 0.773196\n",
      "Epoch 28504 - Train Loss: 0.072179, Train Acc: 0.885897 | Val Loss: 0.109698, Val Acc: 0.773196\n",
      "Epoch 28505 - Train Loss: 0.072178, Train Acc: 0.885897 | Val Loss: 0.109698, Val Acc: 0.773196\n",
      "Epoch 28506 - Train Loss: 0.072176, Train Acc: 0.885897 | Val Loss: 0.109698, Val Acc: 0.773196\n",
      "Epoch 28507 - Train Loss: 0.072175, Train Acc: 0.885897 | Val Loss: 0.109697, Val Acc: 0.773196\n",
      "Epoch 28508 - Train Loss: 0.072174, Train Acc: 0.885897 | Val Loss: 0.109697, Val Acc: 0.773196\n",
      "Epoch 28509 - Train Loss: 0.072172, Train Acc: 0.885897 | Val Loss: 0.109697, Val Acc: 0.773196\n",
      "Epoch 28510 - Train Loss: 0.072171, Train Acc: 0.885897 | Val Loss: 0.109696, Val Acc: 0.773196\n",
      "Epoch 28511 - Train Loss: 0.072170, Train Acc: 0.885897 | Val Loss: 0.109696, Val Acc: 0.773196\n",
      "Epoch 28512 - Train Loss: 0.072169, Train Acc: 0.885897 | Val Loss: 0.109696, Val Acc: 0.773196\n",
      "Epoch 28513 - Train Loss: 0.072167, Train Acc: 0.885897 | Val Loss: 0.109695, Val Acc: 0.773196\n",
      "Epoch 28514 - Train Loss: 0.072166, Train Acc: 0.885897 | Val Loss: 0.109695, Val Acc: 0.773196\n",
      "Epoch 28515 - Train Loss: 0.072165, Train Acc: 0.885897 | Val Loss: 0.109695, Val Acc: 0.773196\n",
      "Epoch 28516 - Train Loss: 0.072163, Train Acc: 0.885897 | Val Loss: 0.109694, Val Acc: 0.773196\n",
      "Epoch 28517 - Train Loss: 0.072162, Train Acc: 0.885897 | Val Loss: 0.109694, Val Acc: 0.773196\n",
      "Epoch 28518 - Train Loss: 0.072161, Train Acc: 0.885897 | Val Loss: 0.109694, Val Acc: 0.773196\n",
      "Epoch 28519 - Train Loss: 0.072159, Train Acc: 0.885897 | Val Loss: 0.109693, Val Acc: 0.773196\n",
      "Epoch 28520 - Train Loss: 0.072158, Train Acc: 0.885897 | Val Loss: 0.109693, Val Acc: 0.773196\n",
      "Epoch 28521 - Train Loss: 0.072157, Train Acc: 0.885897 | Val Loss: 0.109693, Val Acc: 0.773196\n",
      "Epoch 28522 - Train Loss: 0.072155, Train Acc: 0.885897 | Val Loss: 0.109693, Val Acc: 0.773196\n",
      "Epoch 28523 - Train Loss: 0.072154, Train Acc: 0.885897 | Val Loss: 0.109692, Val Acc: 0.773196\n",
      "Epoch 28524 - Train Loss: 0.072153, Train Acc: 0.885897 | Val Loss: 0.109692, Val Acc: 0.773196\n",
      "Epoch 28525 - Train Loss: 0.072152, Train Acc: 0.885897 | Val Loss: 0.109691, Val Acc: 0.773196\n",
      "Epoch 28526 - Train Loss: 0.072150, Train Acc: 0.885897 | Val Loss: 0.109691, Val Acc: 0.773196\n",
      "Epoch 28527 - Train Loss: 0.072149, Train Acc: 0.885897 | Val Loss: 0.109691, Val Acc: 0.773196\n",
      "Epoch 28528 - Train Loss: 0.072148, Train Acc: 0.885897 | Val Loss: 0.109691, Val Acc: 0.773196\n",
      "Epoch 28529 - Train Loss: 0.072146, Train Acc: 0.885897 | Val Loss: 0.109690, Val Acc: 0.773196\n",
      "Epoch 28530 - Train Loss: 0.072145, Train Acc: 0.885897 | Val Loss: 0.109690, Val Acc: 0.773196\n",
      "Epoch 28531 - Train Loss: 0.072144, Train Acc: 0.885897 | Val Loss: 0.109690, Val Acc: 0.773196\n",
      "Epoch 28532 - Train Loss: 0.072142, Train Acc: 0.885897 | Val Loss: 0.109689, Val Acc: 0.773196\n",
      "Epoch 28533 - Train Loss: 0.072141, Train Acc: 0.885897 | Val Loss: 0.109689, Val Acc: 0.773196\n",
      "Epoch 28534 - Train Loss: 0.072140, Train Acc: 0.885897 | Val Loss: 0.109689, Val Acc: 0.773196\n",
      "Epoch 28535 - Train Loss: 0.072138, Train Acc: 0.885897 | Val Loss: 0.109688, Val Acc: 0.773196\n",
      "Epoch 28536 - Train Loss: 0.072137, Train Acc: 0.885897 | Val Loss: 0.109688, Val Acc: 0.773196\n",
      "Epoch 28537 - Train Loss: 0.072136, Train Acc: 0.885897 | Val Loss: 0.109688, Val Acc: 0.773196\n",
      "Epoch 28538 - Train Loss: 0.072135, Train Acc: 0.885897 | Val Loss: 0.109687, Val Acc: 0.773196\n",
      "Epoch 28539 - Train Loss: 0.072133, Train Acc: 0.885897 | Val Loss: 0.109687, Val Acc: 0.773196\n",
      "Epoch 28540 - Train Loss: 0.072132, Train Acc: 0.885897 | Val Loss: 0.109687, Val Acc: 0.773196\n",
      "Epoch 28541 - Train Loss: 0.072131, Train Acc: 0.885897 | Val Loss: 0.109686, Val Acc: 0.773196\n",
      "Epoch 28542 - Train Loss: 0.072129, Train Acc: 0.885897 | Val Loss: 0.109686, Val Acc: 0.773196\n",
      "Epoch 28543 - Train Loss: 0.072128, Train Acc: 0.885897 | Val Loss: 0.109686, Val Acc: 0.773196\n",
      "Epoch 28544 - Train Loss: 0.072127, Train Acc: 0.885897 | Val Loss: 0.109685, Val Acc: 0.773196\n",
      "Epoch 28545 - Train Loss: 0.072125, Train Acc: 0.885897 | Val Loss: 0.109685, Val Acc: 0.773196\n",
      "Epoch 28546 - Train Loss: 0.072124, Train Acc: 0.885897 | Val Loss: 0.109685, Val Acc: 0.773196\n",
      "Epoch 28547 - Train Loss: 0.072123, Train Acc: 0.885897 | Val Loss: 0.109684, Val Acc: 0.773196\n",
      "Epoch 28548 - Train Loss: 0.072121, Train Acc: 0.885897 | Val Loss: 0.109684, Val Acc: 0.773196\n",
      "Epoch 28549 - Train Loss: 0.072120, Train Acc: 0.885897 | Val Loss: 0.109684, Val Acc: 0.773196\n",
      "Epoch 28550 - Train Loss: 0.072119, Train Acc: 0.885897 | Val Loss: 0.109684, Val Acc: 0.773196\n",
      "Epoch 28551 - Train Loss: 0.072118, Train Acc: 0.885897 | Val Loss: 0.109683, Val Acc: 0.773196\n",
      "Epoch 28552 - Train Loss: 0.072116, Train Acc: 0.885897 | Val Loss: 0.109683, Val Acc: 0.773196\n",
      "Epoch 28553 - Train Loss: 0.072115, Train Acc: 0.885897 | Val Loss: 0.109682, Val Acc: 0.773196\n",
      "Epoch 28554 - Train Loss: 0.072114, Train Acc: 0.885897 | Val Loss: 0.109682, Val Acc: 0.773196\n",
      "Epoch 28555 - Train Loss: 0.072112, Train Acc: 0.885897 | Val Loss: 0.109682, Val Acc: 0.773196\n",
      "Epoch 28556 - Train Loss: 0.072111, Train Acc: 0.885897 | Val Loss: 0.109682, Val Acc: 0.773196\n",
      "Epoch 28557 - Train Loss: 0.072110, Train Acc: 0.885897 | Val Loss: 0.109681, Val Acc: 0.773196\n",
      "Epoch 28558 - Train Loss: 0.072108, Train Acc: 0.885897 | Val Loss: 0.109681, Val Acc: 0.773196\n",
      "Epoch 28559 - Train Loss: 0.072107, Train Acc: 0.885897 | Val Loss: 0.109681, Val Acc: 0.773196\n",
      "Epoch 28560 - Train Loss: 0.072106, Train Acc: 0.885897 | Val Loss: 0.109680, Val Acc: 0.773196\n",
      "Epoch 28561 - Train Loss: 0.072105, Train Acc: 0.885897 | Val Loss: 0.109680, Val Acc: 0.773196\n",
      "Epoch 28562 - Train Loss: 0.072103, Train Acc: 0.885897 | Val Loss: 0.109680, Val Acc: 0.773196\n",
      "Epoch 28563 - Train Loss: 0.072102, Train Acc: 0.885897 | Val Loss: 0.109679, Val Acc: 0.773196\n",
      "Epoch 28564 - Train Loss: 0.072101, Train Acc: 0.885897 | Val Loss: 0.109679, Val Acc: 0.773196\n",
      "Epoch 28565 - Train Loss: 0.072099, Train Acc: 0.885897 | Val Loss: 0.109679, Val Acc: 0.773196\n",
      "Epoch 28566 - Train Loss: 0.072098, Train Acc: 0.885897 | Val Loss: 0.109678, Val Acc: 0.773196\n",
      "Epoch 28567 - Train Loss: 0.072097, Train Acc: 0.885897 | Val Loss: 0.109678, Val Acc: 0.773196\n",
      "Epoch 28568 - Train Loss: 0.072095, Train Acc: 0.885897 | Val Loss: 0.109678, Val Acc: 0.773196\n",
      "Epoch 28569 - Train Loss: 0.072094, Train Acc: 0.885897 | Val Loss: 0.109677, Val Acc: 0.773196\n",
      "Epoch 28570 - Train Loss: 0.072093, Train Acc: 0.885897 | Val Loss: 0.109677, Val Acc: 0.773196\n",
      "Epoch 28571 - Train Loss: 0.072091, Train Acc: 0.885897 | Val Loss: 0.109677, Val Acc: 0.773196\n",
      "Epoch 28572 - Train Loss: 0.072090, Train Acc: 0.885897 | Val Loss: 0.109676, Val Acc: 0.773196\n",
      "Epoch 28573 - Train Loss: 0.072089, Train Acc: 0.885897 | Val Loss: 0.109676, Val Acc: 0.773196\n",
      "Epoch 28574 - Train Loss: 0.072088, Train Acc: 0.885897 | Val Loss: 0.109676, Val Acc: 0.773196\n",
      "Epoch 28575 - Train Loss: 0.072086, Train Acc: 0.885897 | Val Loss: 0.109675, Val Acc: 0.773196\n",
      "Epoch 28576 - Train Loss: 0.072085, Train Acc: 0.885897 | Val Loss: 0.109675, Val Acc: 0.773196\n",
      "Epoch 28577 - Train Loss: 0.072084, Train Acc: 0.885897 | Val Loss: 0.109675, Val Acc: 0.773196\n",
      "Epoch 28578 - Train Loss: 0.072082, Train Acc: 0.885897 | Val Loss: 0.109675, Val Acc: 0.773196\n",
      "Epoch 28579 - Train Loss: 0.072081, Train Acc: 0.885897 | Val Loss: 0.109674, Val Acc: 0.773196\n",
      "Epoch 28580 - Train Loss: 0.072080, Train Acc: 0.885897 | Val Loss: 0.109674, Val Acc: 0.773196\n",
      "Epoch 28581 - Train Loss: 0.072078, Train Acc: 0.885897 | Val Loss: 0.109674, Val Acc: 0.773196\n",
      "Epoch 28582 - Train Loss: 0.072077, Train Acc: 0.885897 | Val Loss: 0.109673, Val Acc: 0.773196\n",
      "Epoch 28583 - Train Loss: 0.072076, Train Acc: 0.885897 | Val Loss: 0.109673, Val Acc: 0.773196\n",
      "Epoch 28584 - Train Loss: 0.072075, Train Acc: 0.885897 | Val Loss: 0.109673, Val Acc: 0.773196\n",
      "Epoch 28585 - Train Loss: 0.072073, Train Acc: 0.885897 | Val Loss: 0.109672, Val Acc: 0.773196\n",
      "Epoch 28586 - Train Loss: 0.072072, Train Acc: 0.885897 | Val Loss: 0.109672, Val Acc: 0.773196\n",
      "Epoch 28587 - Train Loss: 0.072071, Train Acc: 0.885897 | Val Loss: 0.109672, Val Acc: 0.773196\n",
      "Epoch 28588 - Train Loss: 0.072069, Train Acc: 0.885897 | Val Loss: 0.109671, Val Acc: 0.773196\n",
      "Epoch 28589 - Train Loss: 0.072068, Train Acc: 0.885897 | Val Loss: 0.109671, Val Acc: 0.773196\n",
      "Epoch 28590 - Train Loss: 0.072067, Train Acc: 0.885897 | Val Loss: 0.109671, Val Acc: 0.773196\n",
      "Epoch 28591 - Train Loss: 0.072065, Train Acc: 0.885897 | Val Loss: 0.109670, Val Acc: 0.773196\n",
      "Epoch 28592 - Train Loss: 0.072064, Train Acc: 0.885897 | Val Loss: 0.109670, Val Acc: 0.773196\n",
      "Epoch 28593 - Train Loss: 0.072063, Train Acc: 0.885897 | Val Loss: 0.109670, Val Acc: 0.773196\n",
      "Epoch 28594 - Train Loss: 0.072061, Train Acc: 0.885897 | Val Loss: 0.109669, Val Acc: 0.773196\n",
      "Epoch 28595 - Train Loss: 0.072060, Train Acc: 0.885897 | Val Loss: 0.109669, Val Acc: 0.773196\n",
      "Epoch 28596 - Train Loss: 0.072059, Train Acc: 0.885897 | Val Loss: 0.109669, Val Acc: 0.773196\n",
      "Epoch 28597 - Train Loss: 0.072058, Train Acc: 0.885897 | Val Loss: 0.109668, Val Acc: 0.773196\n",
      "Epoch 28598 - Train Loss: 0.072056, Train Acc: 0.885897 | Val Loss: 0.109668, Val Acc: 0.773196\n",
      "Epoch 28599 - Train Loss: 0.072055, Train Acc: 0.885897 | Val Loss: 0.109668, Val Acc: 0.773196\n",
      "Epoch 28600 - Train Loss: 0.072054, Train Acc: 0.885897 | Val Loss: 0.109668, Val Acc: 0.773196\n",
      "Epoch 28601 - Train Loss: 0.072052, Train Acc: 0.885897 | Val Loss: 0.109667, Val Acc: 0.773196\n",
      "Epoch 28602 - Train Loss: 0.072051, Train Acc: 0.885897 | Val Loss: 0.109667, Val Acc: 0.773196\n",
      "Epoch 28603 - Train Loss: 0.072050, Train Acc: 0.885897 | Val Loss: 0.109667, Val Acc: 0.773196\n",
      "Epoch 28604 - Train Loss: 0.072048, Train Acc: 0.885897 | Val Loss: 0.109666, Val Acc: 0.773196\n",
      "Epoch 28605 - Train Loss: 0.072047, Train Acc: 0.885897 | Val Loss: 0.109666, Val Acc: 0.773196\n",
      "Epoch 28606 - Train Loss: 0.072046, Train Acc: 0.885897 | Val Loss: 0.109666, Val Acc: 0.773196\n",
      "Epoch 28607 - Train Loss: 0.072045, Train Acc: 0.885897 | Val Loss: 0.109665, Val Acc: 0.773196\n",
      "Epoch 28608 - Train Loss: 0.072043, Train Acc: 0.885897 | Val Loss: 0.109665, Val Acc: 0.773196\n",
      "Epoch 28609 - Train Loss: 0.072042, Train Acc: 0.885897 | Val Loss: 0.109665, Val Acc: 0.773196\n",
      "Epoch 28610 - Train Loss: 0.072041, Train Acc: 0.885897 | Val Loss: 0.109664, Val Acc: 0.773196\n",
      "Epoch 28611 - Train Loss: 0.072039, Train Acc: 0.885897 | Val Loss: 0.109664, Val Acc: 0.773196\n",
      "Epoch 28612 - Train Loss: 0.072038, Train Acc: 0.885897 | Val Loss: 0.109664, Val Acc: 0.773196\n",
      "Epoch 28613 - Train Loss: 0.072037, Train Acc: 0.885897 | Val Loss: 0.109663, Val Acc: 0.773196\n",
      "Epoch 28614 - Train Loss: 0.072035, Train Acc: 0.885897 | Val Loss: 0.109663, Val Acc: 0.773196\n",
      "Epoch 28615 - Train Loss: 0.072034, Train Acc: 0.885897 | Val Loss: 0.109663, Val Acc: 0.773196\n",
      "Epoch 28616 - Train Loss: 0.072033, Train Acc: 0.885897 | Val Loss: 0.109662, Val Acc: 0.773196\n",
      "Epoch 28617 - Train Loss: 0.072032, Train Acc: 0.885897 | Val Loss: 0.109662, Val Acc: 0.773196\n",
      "Epoch 28618 - Train Loss: 0.072030, Train Acc: 0.885897 | Val Loss: 0.109662, Val Acc: 0.773196\n",
      "Epoch 28619 - Train Loss: 0.072029, Train Acc: 0.885897 | Val Loss: 0.109662, Val Acc: 0.773196\n",
      "Epoch 28620 - Train Loss: 0.072028, Train Acc: 0.885897 | Val Loss: 0.109661, Val Acc: 0.773196\n",
      "Epoch 28621 - Train Loss: 0.072026, Train Acc: 0.885897 | Val Loss: 0.109661, Val Acc: 0.773196\n",
      "Epoch 28622 - Train Loss: 0.072025, Train Acc: 0.885897 | Val Loss: 0.109660, Val Acc: 0.773196\n",
      "Epoch 28623 - Train Loss: 0.072024, Train Acc: 0.885897 | Val Loss: 0.109660, Val Acc: 0.773196\n",
      "Epoch 28624 - Train Loss: 0.072022, Train Acc: 0.885897 | Val Loss: 0.109660, Val Acc: 0.773196\n",
      "Epoch 28625 - Train Loss: 0.072021, Train Acc: 0.885897 | Val Loss: 0.109660, Val Acc: 0.773196\n",
      "Epoch 28626 - Train Loss: 0.072020, Train Acc: 0.885897 | Val Loss: 0.109659, Val Acc: 0.773196\n",
      "Epoch 28627 - Train Loss: 0.072019, Train Acc: 0.885897 | Val Loss: 0.109659, Val Acc: 0.773196\n",
      "Epoch 28628 - Train Loss: 0.072017, Train Acc: 0.885897 | Val Loss: 0.109659, Val Acc: 0.773196\n",
      "Epoch 28629 - Train Loss: 0.072016, Train Acc: 0.885897 | Val Loss: 0.109658, Val Acc: 0.773196\n",
      "Epoch 28630 - Train Loss: 0.072015, Train Acc: 0.885897 | Val Loss: 0.109658, Val Acc: 0.773196\n",
      "Epoch 28631 - Train Loss: 0.072013, Train Acc: 0.885897 | Val Loss: 0.109658, Val Acc: 0.773196\n",
      "Epoch 28632 - Train Loss: 0.072012, Train Acc: 0.885897 | Val Loss: 0.109657, Val Acc: 0.773196\n",
      "Epoch 28633 - Train Loss: 0.072011, Train Acc: 0.885897 | Val Loss: 0.109657, Val Acc: 0.773196\n",
      "Epoch 28634 - Train Loss: 0.072009, Train Acc: 0.885897 | Val Loss: 0.109657, Val Acc: 0.773196\n",
      "Epoch 28635 - Train Loss: 0.072008, Train Acc: 0.885897 | Val Loss: 0.109656, Val Acc: 0.773196\n",
      "Epoch 28636 - Train Loss: 0.072007, Train Acc: 0.885897 | Val Loss: 0.109656, Val Acc: 0.773196\n",
      "Epoch 28637 - Train Loss: 0.072006, Train Acc: 0.885897 | Val Loss: 0.109656, Val Acc: 0.773196\n",
      "Epoch 28638 - Train Loss: 0.072004, Train Acc: 0.885897 | Val Loss: 0.109655, Val Acc: 0.773196\n",
      "Epoch 28639 - Train Loss: 0.072003, Train Acc: 0.885897 | Val Loss: 0.109655, Val Acc: 0.773196\n",
      "Epoch 28640 - Train Loss: 0.072002, Train Acc: 0.885897 | Val Loss: 0.109655, Val Acc: 0.773196\n",
      "Epoch 28641 - Train Loss: 0.072000, Train Acc: 0.885897 | Val Loss: 0.109655, Val Acc: 0.773196\n",
      "Epoch 28642 - Train Loss: 0.071999, Train Acc: 0.885897 | Val Loss: 0.109654, Val Acc: 0.773196\n",
      "Epoch 28643 - Train Loss: 0.071998, Train Acc: 0.885897 | Val Loss: 0.109654, Val Acc: 0.773196\n",
      "Epoch 28644 - Train Loss: 0.071996, Train Acc: 0.885897 | Val Loss: 0.109654, Val Acc: 0.773196\n",
      "Epoch 28645 - Train Loss: 0.071995, Train Acc: 0.885897 | Val Loss: 0.109653, Val Acc: 0.773196\n",
      "Epoch 28646 - Train Loss: 0.071994, Train Acc: 0.885897 | Val Loss: 0.109653, Val Acc: 0.773196\n",
      "Epoch 28647 - Train Loss: 0.071993, Train Acc: 0.885897 | Val Loss: 0.109653, Val Acc: 0.773196\n",
      "Epoch 28648 - Train Loss: 0.071991, Train Acc: 0.885897 | Val Loss: 0.109652, Val Acc: 0.773196\n",
      "Epoch 28649 - Train Loss: 0.071990, Train Acc: 0.885897 | Val Loss: 0.109652, Val Acc: 0.773196\n",
      "Epoch 28650 - Train Loss: 0.071989, Train Acc: 0.885897 | Val Loss: 0.109652, Val Acc: 0.773196\n",
      "Epoch 28651 - Train Loss: 0.071987, Train Acc: 0.885897 | Val Loss: 0.109651, Val Acc: 0.773196\n",
      "Epoch 28652 - Train Loss: 0.071986, Train Acc: 0.885897 | Val Loss: 0.109651, Val Acc: 0.773196\n",
      "Epoch 28653 - Train Loss: 0.071985, Train Acc: 0.885897 | Val Loss: 0.109651, Val Acc: 0.773196\n",
      "Epoch 28654 - Train Loss: 0.071983, Train Acc: 0.885897 | Val Loss: 0.109650, Val Acc: 0.773196\n",
      "Epoch 28655 - Train Loss: 0.071982, Train Acc: 0.885897 | Val Loss: 0.109650, Val Acc: 0.773196\n",
      "Epoch 28656 - Train Loss: 0.071981, Train Acc: 0.885897 | Val Loss: 0.109650, Val Acc: 0.773196\n",
      "Epoch 28657 - Train Loss: 0.071980, Train Acc: 0.885897 | Val Loss: 0.109650, Val Acc: 0.773196\n",
      "Epoch 28658 - Train Loss: 0.071978, Train Acc: 0.885897 | Val Loss: 0.109649, Val Acc: 0.773196\n",
      "Epoch 28659 - Train Loss: 0.071977, Train Acc: 0.885897 | Val Loss: 0.109649, Val Acc: 0.773196\n",
      "Epoch 28660 - Train Loss: 0.071976, Train Acc: 0.885897 | Val Loss: 0.109648, Val Acc: 0.773196\n",
      "Epoch 28661 - Train Loss: 0.071974, Train Acc: 0.885897 | Val Loss: 0.109648, Val Acc: 0.773196\n",
      "Epoch 28662 - Train Loss: 0.071973, Train Acc: 0.885897 | Val Loss: 0.109648, Val Acc: 0.773196\n",
      "Epoch 28663 - Train Loss: 0.071972, Train Acc: 0.885897 | Val Loss: 0.109648, Val Acc: 0.773196\n",
      "Epoch 28664 - Train Loss: 0.071970, Train Acc: 0.885897 | Val Loss: 0.109647, Val Acc: 0.773196\n",
      "Epoch 28665 - Train Loss: 0.071969, Train Acc: 0.885897 | Val Loss: 0.109647, Val Acc: 0.773196\n",
      "Epoch 28666 - Train Loss: 0.071968, Train Acc: 0.885897 | Val Loss: 0.109647, Val Acc: 0.773196\n",
      "Epoch 28667 - Train Loss: 0.071967, Train Acc: 0.885897 | Val Loss: 0.109646, Val Acc: 0.773196\n",
      "Epoch 28668 - Train Loss: 0.071965, Train Acc: 0.885897 | Val Loss: 0.109646, Val Acc: 0.773196\n",
      "Epoch 28669 - Train Loss: 0.071964, Train Acc: 0.885897 | Val Loss: 0.109646, Val Acc: 0.773196\n",
      "Epoch 28670 - Train Loss: 0.071963, Train Acc: 0.885897 | Val Loss: 0.109645, Val Acc: 0.773196\n",
      "Epoch 28671 - Train Loss: 0.071961, Train Acc: 0.885897 | Val Loss: 0.109645, Val Acc: 0.773196\n",
      "Epoch 28672 - Train Loss: 0.071960, Train Acc: 0.885897 | Val Loss: 0.109645, Val Acc: 0.773196\n",
      "Epoch 28673 - Train Loss: 0.071959, Train Acc: 0.885897 | Val Loss: 0.109644, Val Acc: 0.773196\n",
      "Epoch 28674 - Train Loss: 0.071957, Train Acc: 0.885897 | Val Loss: 0.109644, Val Acc: 0.773196\n",
      "Epoch 28675 - Train Loss: 0.071956, Train Acc: 0.885897 | Val Loss: 0.109644, Val Acc: 0.773196\n",
      "Epoch 28676 - Train Loss: 0.071955, Train Acc: 0.885897 | Val Loss: 0.109643, Val Acc: 0.773196\n",
      "Epoch 28677 - Train Loss: 0.071954, Train Acc: 0.885897 | Val Loss: 0.109643, Val Acc: 0.773196\n",
      "Epoch 28678 - Train Loss: 0.071952, Train Acc: 0.885897 | Val Loss: 0.109643, Val Acc: 0.773196\n",
      "Epoch 28679 - Train Loss: 0.071951, Train Acc: 0.885897 | Val Loss: 0.109643, Val Acc: 0.773196\n",
      "Epoch 28680 - Train Loss: 0.071950, Train Acc: 0.885897 | Val Loss: 0.109642, Val Acc: 0.773196\n",
      "Epoch 28681 - Train Loss: 0.071948, Train Acc: 0.885897 | Val Loss: 0.109642, Val Acc: 0.773196\n",
      "Epoch 28682 - Train Loss: 0.071947, Train Acc: 0.885897 | Val Loss: 0.109642, Val Acc: 0.773196\n",
      "Epoch 28683 - Train Loss: 0.071946, Train Acc: 0.885897 | Val Loss: 0.109641, Val Acc: 0.773196\n",
      "Epoch 28684 - Train Loss: 0.071945, Train Acc: 0.885897 | Val Loss: 0.109641, Val Acc: 0.773196\n",
      "Epoch 28685 - Train Loss: 0.071943, Train Acc: 0.885897 | Val Loss: 0.109641, Val Acc: 0.773196\n",
      "Epoch 28686 - Train Loss: 0.071942, Train Acc: 0.885897 | Val Loss: 0.109640, Val Acc: 0.773196\n",
      "Epoch 28687 - Train Loss: 0.071941, Train Acc: 0.885897 | Val Loss: 0.109640, Val Acc: 0.773196\n",
      "Epoch 28688 - Train Loss: 0.071939, Train Acc: 0.885897 | Val Loss: 0.109640, Val Acc: 0.773196\n",
      "Epoch 28689 - Train Loss: 0.071938, Train Acc: 0.885897 | Val Loss: 0.109639, Val Acc: 0.773196\n",
      "Epoch 28690 - Train Loss: 0.071937, Train Acc: 0.885897 | Val Loss: 0.109639, Val Acc: 0.773196\n",
      "Epoch 28691 - Train Loss: 0.071935, Train Acc: 0.885897 | Val Loss: 0.109639, Val Acc: 0.773196\n",
      "Epoch 28692 - Train Loss: 0.071934, Train Acc: 0.885897 | Val Loss: 0.109638, Val Acc: 0.773196\n",
      "Epoch 28693 - Train Loss: 0.071933, Train Acc: 0.885897 | Val Loss: 0.109638, Val Acc: 0.773196\n",
      "Epoch 28694 - Train Loss: 0.071932, Train Acc: 0.885897 | Val Loss: 0.109638, Val Acc: 0.773196\n",
      "Epoch 28695 - Train Loss: 0.071930, Train Acc: 0.885897 | Val Loss: 0.109637, Val Acc: 0.773196\n",
      "Epoch 28696 - Train Loss: 0.071929, Train Acc: 0.885897 | Val Loss: 0.109637, Val Acc: 0.773196\n",
      "Epoch 28697 - Train Loss: 0.071928, Train Acc: 0.885897 | Val Loss: 0.109637, Val Acc: 0.773196\n",
      "Epoch 28698 - Train Loss: 0.071926, Train Acc: 0.885897 | Val Loss: 0.109637, Val Acc: 0.773196\n",
      "Epoch 28699 - Train Loss: 0.071925, Train Acc: 0.885897 | Val Loss: 0.109636, Val Acc: 0.773196\n",
      "Epoch 28700 - Train Loss: 0.071924, Train Acc: 0.885897 | Val Loss: 0.109636, Val Acc: 0.773196\n",
      "Epoch 28701 - Train Loss: 0.071922, Train Acc: 0.885897 | Val Loss: 0.109636, Val Acc: 0.773196\n",
      "Epoch 28702 - Train Loss: 0.071921, Train Acc: 0.885897 | Val Loss: 0.109635, Val Acc: 0.773196\n",
      "Epoch 28703 - Train Loss: 0.071920, Train Acc: 0.885897 | Val Loss: 0.109635, Val Acc: 0.773196\n",
      "Epoch 28704 - Train Loss: 0.071919, Train Acc: 0.885897 | Val Loss: 0.109635, Val Acc: 0.773196\n",
      "Epoch 28705 - Train Loss: 0.071917, Train Acc: 0.885897 | Val Loss: 0.109634, Val Acc: 0.773196\n",
      "Epoch 28706 - Train Loss: 0.071916, Train Acc: 0.885897 | Val Loss: 0.109634, Val Acc: 0.773196\n",
      "Epoch 28707 - Train Loss: 0.071915, Train Acc: 0.885897 | Val Loss: 0.109634, Val Acc: 0.773196\n",
      "Epoch 28708 - Train Loss: 0.071913, Train Acc: 0.885897 | Val Loss: 0.109634, Val Acc: 0.773196\n",
      "Epoch 28709 - Train Loss: 0.071912, Train Acc: 0.885897 | Val Loss: 0.109633, Val Acc: 0.773196\n",
      "Epoch 28710 - Train Loss: 0.071911, Train Acc: 0.885897 | Val Loss: 0.109633, Val Acc: 0.773196\n",
      "Epoch 28711 - Train Loss: 0.071910, Train Acc: 0.885897 | Val Loss: 0.109633, Val Acc: 0.773196\n",
      "Epoch 28712 - Train Loss: 0.071908, Train Acc: 0.885897 | Val Loss: 0.109632, Val Acc: 0.773196\n",
      "Epoch 28713 - Train Loss: 0.071907, Train Acc: 0.885897 | Val Loss: 0.109632, Val Acc: 0.773196\n",
      "Epoch 28714 - Train Loss: 0.071906, Train Acc: 0.885897 | Val Loss: 0.109632, Val Acc: 0.773196\n",
      "Epoch 28715 - Train Loss: 0.071904, Train Acc: 0.885897 | Val Loss: 0.109631, Val Acc: 0.773196\n",
      "Epoch 28716 - Train Loss: 0.071903, Train Acc: 0.885897 | Val Loss: 0.109631, Val Acc: 0.773196\n",
      "Epoch 28717 - Train Loss: 0.071902, Train Acc: 0.885897 | Val Loss: 0.109631, Val Acc: 0.773196\n",
      "Epoch 28718 - Train Loss: 0.071900, Train Acc: 0.885897 | Val Loss: 0.109630, Val Acc: 0.773196\n",
      "Epoch 28719 - Train Loss: 0.071899, Train Acc: 0.885897 | Val Loss: 0.109630, Val Acc: 0.773196\n",
      "Epoch 28720 - Train Loss: 0.071898, Train Acc: 0.885897 | Val Loss: 0.109630, Val Acc: 0.773196\n",
      "Epoch 28721 - Train Loss: 0.071897, Train Acc: 0.885897 | Val Loss: 0.109629, Val Acc: 0.773196\n",
      "Epoch 28722 - Train Loss: 0.071895, Train Acc: 0.885897 | Val Loss: 0.109629, Val Acc: 0.773196\n",
      "Epoch 28723 - Train Loss: 0.071894, Train Acc: 0.885897 | Val Loss: 0.109629, Val Acc: 0.773196\n",
      "Epoch 28724 - Train Loss: 0.071893, Train Acc: 0.885897 | Val Loss: 0.109628, Val Acc: 0.773196\n",
      "Epoch 28725 - Train Loss: 0.071891, Train Acc: 0.885897 | Val Loss: 0.109628, Val Acc: 0.773196\n",
      "Epoch 28726 - Train Loss: 0.071890, Train Acc: 0.885897 | Val Loss: 0.109628, Val Acc: 0.773196\n",
      "Epoch 28727 - Train Loss: 0.071889, Train Acc: 0.885897 | Val Loss: 0.109628, Val Acc: 0.773196\n",
      "Epoch 28728 - Train Loss: 0.071888, Train Acc: 0.885897 | Val Loss: 0.109627, Val Acc: 0.773196\n",
      "Epoch 28729 - Train Loss: 0.071886, Train Acc: 0.885897 | Val Loss: 0.109627, Val Acc: 0.773196\n",
      "Epoch 28730 - Train Loss: 0.071885, Train Acc: 0.885897 | Val Loss: 0.109627, Val Acc: 0.773196\n",
      "Epoch 28731 - Train Loss: 0.071884, Train Acc: 0.885897 | Val Loss: 0.109626, Val Acc: 0.773196\n",
      "Epoch 28732 - Train Loss: 0.071882, Train Acc: 0.885897 | Val Loss: 0.109626, Val Acc: 0.773196\n",
      "Epoch 28733 - Train Loss: 0.071881, Train Acc: 0.885897 | Val Loss: 0.109626, Val Acc: 0.773196\n",
      "Epoch 28734 - Train Loss: 0.071880, Train Acc: 0.885897 | Val Loss: 0.109625, Val Acc: 0.773196\n",
      "Epoch 28735 - Train Loss: 0.071878, Train Acc: 0.885897 | Val Loss: 0.109625, Val Acc: 0.773196\n",
      "Epoch 28736 - Train Loss: 0.071877, Train Acc: 0.885897 | Val Loss: 0.109625, Val Acc: 0.773196\n",
      "Epoch 28737 - Train Loss: 0.071876, Train Acc: 0.885897 | Val Loss: 0.109624, Val Acc: 0.773196\n",
      "Epoch 28738 - Train Loss: 0.071875, Train Acc: 0.885897 | Val Loss: 0.109624, Val Acc: 0.773196\n",
      "Epoch 28739 - Train Loss: 0.071873, Train Acc: 0.885897 | Val Loss: 0.109624, Val Acc: 0.773196\n",
      "Epoch 28740 - Train Loss: 0.071872, Train Acc: 0.885897 | Val Loss: 0.109624, Val Acc: 0.773196\n",
      "Epoch 28741 - Train Loss: 0.071871, Train Acc: 0.885897 | Val Loss: 0.109623, Val Acc: 0.773196\n",
      "Epoch 28742 - Train Loss: 0.071869, Train Acc: 0.885897 | Val Loss: 0.109623, Val Acc: 0.773196\n",
      "Epoch 28743 - Train Loss: 0.071868, Train Acc: 0.885897 | Val Loss: 0.109623, Val Acc: 0.773196\n",
      "Epoch 28744 - Train Loss: 0.071867, Train Acc: 0.885897 | Val Loss: 0.109622, Val Acc: 0.773196\n",
      "Epoch 28745 - Train Loss: 0.071866, Train Acc: 0.885897 | Val Loss: 0.109622, Val Acc: 0.773196\n",
      "Epoch 28746 - Train Loss: 0.071864, Train Acc: 0.885897 | Val Loss: 0.109622, Val Acc: 0.773196\n",
      "Epoch 28747 - Train Loss: 0.071863, Train Acc: 0.885897 | Val Loss: 0.109621, Val Acc: 0.773196\n",
      "Epoch 28748 - Train Loss: 0.071862, Train Acc: 0.885897 | Val Loss: 0.109621, Val Acc: 0.773196\n",
      "Epoch 28749 - Train Loss: 0.071860, Train Acc: 0.885897 | Val Loss: 0.109621, Val Acc: 0.773196\n",
      "Epoch 28750 - Train Loss: 0.071859, Train Acc: 0.885897 | Val Loss: 0.109620, Val Acc: 0.773196\n",
      "Epoch 28751 - Train Loss: 0.071858, Train Acc: 0.885897 | Val Loss: 0.109620, Val Acc: 0.773196\n",
      "Epoch 28752 - Train Loss: 0.071856, Train Acc: 0.885897 | Val Loss: 0.109620, Val Acc: 0.773196\n",
      "Epoch 28753 - Train Loss: 0.071855, Train Acc: 0.885897 | Val Loss: 0.109620, Val Acc: 0.773196\n",
      "Epoch 28754 - Train Loss: 0.071854, Train Acc: 0.885897 | Val Loss: 0.109619, Val Acc: 0.773196\n",
      "Epoch 28755 - Train Loss: 0.071853, Train Acc: 0.885897 | Val Loss: 0.109619, Val Acc: 0.773196\n",
      "Epoch 28756 - Train Loss: 0.071851, Train Acc: 0.885897 | Val Loss: 0.109618, Val Acc: 0.773196\n",
      "Epoch 28757 - Train Loss: 0.071850, Train Acc: 0.885897 | Val Loss: 0.109618, Val Acc: 0.773196\n",
      "Epoch 28758 - Train Loss: 0.071849, Train Acc: 0.885897 | Val Loss: 0.109618, Val Acc: 0.773196\n",
      "Epoch 28759 - Train Loss: 0.071847, Train Acc: 0.885897 | Val Loss: 0.109618, Val Acc: 0.773196\n",
      "Epoch 28760 - Train Loss: 0.071846, Train Acc: 0.885897 | Val Loss: 0.109617, Val Acc: 0.773196\n",
      "Epoch 28761 - Train Loss: 0.071845, Train Acc: 0.885897 | Val Loss: 0.109617, Val Acc: 0.773196\n",
      "Epoch 28762 - Train Loss: 0.071844, Train Acc: 0.885897 | Val Loss: 0.109617, Val Acc: 0.773196\n",
      "Epoch 28763 - Train Loss: 0.071842, Train Acc: 0.885897 | Val Loss: 0.109616, Val Acc: 0.773196\n",
      "Epoch 28764 - Train Loss: 0.071841, Train Acc: 0.885897 | Val Loss: 0.109616, Val Acc: 0.773196\n",
      "Epoch 28765 - Train Loss: 0.071840, Train Acc: 0.885897 | Val Loss: 0.109616, Val Acc: 0.773196\n",
      "Epoch 28766 - Train Loss: 0.071838, Train Acc: 0.885897 | Val Loss: 0.109615, Val Acc: 0.773196\n",
      "Epoch 28767 - Train Loss: 0.071837, Train Acc: 0.885897 | Val Loss: 0.109615, Val Acc: 0.773196\n",
      "Epoch 28768 - Train Loss: 0.071836, Train Acc: 0.885897 | Val Loss: 0.109615, Val Acc: 0.773196\n",
      "Epoch 28769 - Train Loss: 0.071835, Train Acc: 0.885897 | Val Loss: 0.109614, Val Acc: 0.773196\n",
      "Epoch 28770 - Train Loss: 0.071833, Train Acc: 0.885897 | Val Loss: 0.109614, Val Acc: 0.773196\n",
      "Epoch 28771 - Train Loss: 0.071832, Train Acc: 0.885897 | Val Loss: 0.109614, Val Acc: 0.773196\n",
      "Epoch 28772 - Train Loss: 0.071831, Train Acc: 0.885897 | Val Loss: 0.109614, Val Acc: 0.773196\n",
      "Epoch 28773 - Train Loss: 0.071829, Train Acc: 0.885897 | Val Loss: 0.109613, Val Acc: 0.773196\n",
      "Epoch 28774 - Train Loss: 0.071828, Train Acc: 0.885897 | Val Loss: 0.109613, Val Acc: 0.773196\n",
      "Epoch 28775 - Train Loss: 0.071827, Train Acc: 0.885897 | Val Loss: 0.109613, Val Acc: 0.773196\n",
      "Epoch 28776 - Train Loss: 0.071825, Train Acc: 0.885897 | Val Loss: 0.109612, Val Acc: 0.773196\n",
      "Epoch 28777 - Train Loss: 0.071824, Train Acc: 0.885897 | Val Loss: 0.109612, Val Acc: 0.773196\n",
      "Epoch 28778 - Train Loss: 0.071823, Train Acc: 0.885897 | Val Loss: 0.109612, Val Acc: 0.773196\n",
      "Epoch 28779 - Train Loss: 0.071822, Train Acc: 0.885897 | Val Loss: 0.109611, Val Acc: 0.773196\n",
      "Epoch 28780 - Train Loss: 0.071820, Train Acc: 0.885897 | Val Loss: 0.109611, Val Acc: 0.773196\n",
      "Epoch 28781 - Train Loss: 0.071819, Train Acc: 0.885897 | Val Loss: 0.109611, Val Acc: 0.773196\n",
      "Epoch 28782 - Train Loss: 0.071818, Train Acc: 0.885897 | Val Loss: 0.109610, Val Acc: 0.773196\n",
      "Epoch 28783 - Train Loss: 0.071816, Train Acc: 0.885897 | Val Loss: 0.109610, Val Acc: 0.773196\n",
      "Epoch 28784 - Train Loss: 0.071815, Train Acc: 0.885897 | Val Loss: 0.109610, Val Acc: 0.773196\n",
      "Epoch 28785 - Train Loss: 0.071814, Train Acc: 0.885897 | Val Loss: 0.109610, Val Acc: 0.773196\n",
      "Epoch 28786 - Train Loss: 0.071813, Train Acc: 0.885897 | Val Loss: 0.109609, Val Acc: 0.773196\n",
      "Epoch 28787 - Train Loss: 0.071811, Train Acc: 0.885897 | Val Loss: 0.109609, Val Acc: 0.773196\n",
      "Epoch 28788 - Train Loss: 0.071810, Train Acc: 0.885897 | Val Loss: 0.109609, Val Acc: 0.773196\n",
      "Epoch 28789 - Train Loss: 0.071809, Train Acc: 0.885897 | Val Loss: 0.109608, Val Acc: 0.773196\n",
      "Epoch 28790 - Train Loss: 0.071807, Train Acc: 0.885897 | Val Loss: 0.109608, Val Acc: 0.773196\n",
      "Epoch 28791 - Train Loss: 0.071806, Train Acc: 0.885897 | Val Loss: 0.109608, Val Acc: 0.773196\n",
      "Epoch 28792 - Train Loss: 0.071805, Train Acc: 0.885897 | Val Loss: 0.109607, Val Acc: 0.773196\n",
      "Epoch 28793 - Train Loss: 0.071804, Train Acc: 0.885897 | Val Loss: 0.109607, Val Acc: 0.773196\n",
      "Epoch 28794 - Train Loss: 0.071802, Train Acc: 0.885897 | Val Loss: 0.109607, Val Acc: 0.773196\n",
      "Epoch 28795 - Train Loss: 0.071801, Train Acc: 0.885897 | Val Loss: 0.109606, Val Acc: 0.773196\n",
      "Epoch 28796 - Train Loss: 0.071800, Train Acc: 0.885897 | Val Loss: 0.109606, Val Acc: 0.773196\n",
      "Epoch 28797 - Train Loss: 0.071798, Train Acc: 0.885897 | Val Loss: 0.109606, Val Acc: 0.773196\n",
      "Epoch 28798 - Train Loss: 0.071797, Train Acc: 0.885897 | Val Loss: 0.109605, Val Acc: 0.773196\n",
      "Epoch 28799 - Train Loss: 0.071796, Train Acc: 0.885897 | Val Loss: 0.109605, Val Acc: 0.773196\n",
      "Epoch 28800 - Train Loss: 0.071795, Train Acc: 0.885897 | Val Loss: 0.109605, Val Acc: 0.773196\n",
      "Epoch 28801 - Train Loss: 0.071793, Train Acc: 0.885897 | Val Loss: 0.109605, Val Acc: 0.773196\n",
      "Epoch 28802 - Train Loss: 0.071792, Train Acc: 0.885897 | Val Loss: 0.109604, Val Acc: 0.773196\n",
      "Epoch 28803 - Train Loss: 0.071791, Train Acc: 0.885897 | Val Loss: 0.109604, Val Acc: 0.773196\n",
      "Epoch 28804 - Train Loss: 0.071789, Train Acc: 0.885897 | Val Loss: 0.109604, Val Acc: 0.773196\n",
      "Epoch 28805 - Train Loss: 0.071788, Train Acc: 0.885897 | Val Loss: 0.109603, Val Acc: 0.773196\n",
      "Epoch 28806 - Train Loss: 0.071787, Train Acc: 0.885897 | Val Loss: 0.109603, Val Acc: 0.773196\n",
      "Epoch 28807 - Train Loss: 0.071785, Train Acc: 0.885897 | Val Loss: 0.109603, Val Acc: 0.773196\n",
      "Epoch 28808 - Train Loss: 0.071784, Train Acc: 0.885897 | Val Loss: 0.109603, Val Acc: 0.773196\n",
      "Epoch 28809 - Train Loss: 0.071783, Train Acc: 0.885897 | Val Loss: 0.109602, Val Acc: 0.773196\n",
      "Epoch 28810 - Train Loss: 0.071782, Train Acc: 0.885897 | Val Loss: 0.109602, Val Acc: 0.773196\n",
      "Epoch 28811 - Train Loss: 0.071780, Train Acc: 0.885897 | Val Loss: 0.109602, Val Acc: 0.773196\n",
      "Epoch 28812 - Train Loss: 0.071779, Train Acc: 0.885897 | Val Loss: 0.109601, Val Acc: 0.773196\n",
      "Epoch 28813 - Train Loss: 0.071778, Train Acc: 0.885897 | Val Loss: 0.109601, Val Acc: 0.773196\n",
      "Epoch 28814 - Train Loss: 0.071776, Train Acc: 0.885897 | Val Loss: 0.109601, Val Acc: 0.773196\n",
      "Epoch 28815 - Train Loss: 0.071775, Train Acc: 0.885897 | Val Loss: 0.109600, Val Acc: 0.773196\n",
      "Epoch 28816 - Train Loss: 0.071774, Train Acc: 0.885897 | Val Loss: 0.109600, Val Acc: 0.773196\n",
      "Epoch 28817 - Train Loss: 0.071773, Train Acc: 0.885897 | Val Loss: 0.109600, Val Acc: 0.773196\n",
      "Epoch 28818 - Train Loss: 0.071771, Train Acc: 0.885897 | Val Loss: 0.109599, Val Acc: 0.773196\n",
      "Epoch 28819 - Train Loss: 0.071770, Train Acc: 0.885897 | Val Loss: 0.109599, Val Acc: 0.773196\n",
      "Epoch 28820 - Train Loss: 0.071769, Train Acc: 0.885897 | Val Loss: 0.109599, Val Acc: 0.773196\n",
      "Epoch 28821 - Train Loss: 0.071767, Train Acc: 0.885897 | Val Loss: 0.109598, Val Acc: 0.773196\n",
      "Epoch 28822 - Train Loss: 0.071766, Train Acc: 0.885897 | Val Loss: 0.109598, Val Acc: 0.773196\n",
      "Epoch 28823 - Train Loss: 0.071765, Train Acc: 0.885897 | Val Loss: 0.109598, Val Acc: 0.773196\n",
      "Epoch 28824 - Train Loss: 0.071764, Train Acc: 0.885897 | Val Loss: 0.109598, Val Acc: 0.773196\n",
      "Epoch 28825 - Train Loss: 0.071762, Train Acc: 0.885897 | Val Loss: 0.109597, Val Acc: 0.773196\n",
      "Epoch 28826 - Train Loss: 0.071761, Train Acc: 0.885897 | Val Loss: 0.109597, Val Acc: 0.773196\n",
      "Epoch 28827 - Train Loss: 0.071760, Train Acc: 0.885897 | Val Loss: 0.109597, Val Acc: 0.773196\n",
      "Epoch 28828 - Train Loss: 0.071758, Train Acc: 0.885897 | Val Loss: 0.109596, Val Acc: 0.773196\n",
      "Epoch 28829 - Train Loss: 0.071757, Train Acc: 0.885897 | Val Loss: 0.109596, Val Acc: 0.773196\n",
      "Epoch 28830 - Train Loss: 0.071756, Train Acc: 0.885897 | Val Loss: 0.109596, Val Acc: 0.773196\n",
      "Epoch 28831 - Train Loss: 0.071755, Train Acc: 0.885897 | Val Loss: 0.109595, Val Acc: 0.773196\n",
      "Epoch 28832 - Train Loss: 0.071753, Train Acc: 0.885897 | Val Loss: 0.109595, Val Acc: 0.773196\n",
      "Epoch 28833 - Train Loss: 0.071752, Train Acc: 0.885897 | Val Loss: 0.109595, Val Acc: 0.773196\n",
      "Epoch 28834 - Train Loss: 0.071751, Train Acc: 0.885897 | Val Loss: 0.109594, Val Acc: 0.773196\n",
      "Epoch 28835 - Train Loss: 0.071749, Train Acc: 0.885897 | Val Loss: 0.109594, Val Acc: 0.773196\n",
      "Epoch 28836 - Train Loss: 0.071748, Train Acc: 0.885897 | Val Loss: 0.109594, Val Acc: 0.773196\n",
      "Epoch 28837 - Train Loss: 0.071747, Train Acc: 0.885897 | Val Loss: 0.109594, Val Acc: 0.773196\n",
      "Epoch 28838 - Train Loss: 0.071746, Train Acc: 0.885897 | Val Loss: 0.109593, Val Acc: 0.773196\n",
      "Epoch 28839 - Train Loss: 0.071744, Train Acc: 0.885897 | Val Loss: 0.109593, Val Acc: 0.773196\n",
      "Epoch 28840 - Train Loss: 0.071743, Train Acc: 0.885897 | Val Loss: 0.109593, Val Acc: 0.773196\n",
      "Epoch 28841 - Train Loss: 0.071742, Train Acc: 0.885897 | Val Loss: 0.109592, Val Acc: 0.773196\n",
      "Epoch 28842 - Train Loss: 0.071740, Train Acc: 0.885897 | Val Loss: 0.109592, Val Acc: 0.773196\n",
      "Epoch 28843 - Train Loss: 0.071739, Train Acc: 0.885897 | Val Loss: 0.109592, Val Acc: 0.773196\n",
      "Epoch 28844 - Train Loss: 0.071738, Train Acc: 0.885897 | Val Loss: 0.109591, Val Acc: 0.773196\n",
      "Epoch 28845 - Train Loss: 0.071737, Train Acc: 0.885897 | Val Loss: 0.109591, Val Acc: 0.773196\n",
      "Epoch 28846 - Train Loss: 0.071735, Train Acc: 0.885897 | Val Loss: 0.109591, Val Acc: 0.773196\n",
      "Epoch 28847 - Train Loss: 0.071734, Train Acc: 0.885897 | Val Loss: 0.109591, Val Acc: 0.773196\n",
      "Epoch 28848 - Train Loss: 0.071733, Train Acc: 0.885897 | Val Loss: 0.109590, Val Acc: 0.773196\n",
      "Epoch 28849 - Train Loss: 0.071731, Train Acc: 0.885897 | Val Loss: 0.109590, Val Acc: 0.773196\n",
      "Epoch 28850 - Train Loss: 0.071730, Train Acc: 0.885897 | Val Loss: 0.109590, Val Acc: 0.773196\n",
      "Epoch 28851 - Train Loss: 0.071729, Train Acc: 0.885897 | Val Loss: 0.109589, Val Acc: 0.773196\n",
      "Epoch 28852 - Train Loss: 0.071728, Train Acc: 0.885897 | Val Loss: 0.109589, Val Acc: 0.773196\n",
      "Epoch 28853 - Train Loss: 0.071726, Train Acc: 0.885897 | Val Loss: 0.109589, Val Acc: 0.773196\n",
      "Epoch 28854 - Train Loss: 0.071725, Train Acc: 0.885897 | Val Loss: 0.109588, Val Acc: 0.773196\n",
      "Epoch 28855 - Train Loss: 0.071724, Train Acc: 0.885897 | Val Loss: 0.109588, Val Acc: 0.773196\n",
      "Epoch 28856 - Train Loss: 0.071722, Train Acc: 0.885897 | Val Loss: 0.109588, Val Acc: 0.773196\n",
      "Epoch 28857 - Train Loss: 0.071721, Train Acc: 0.885897 | Val Loss: 0.109587, Val Acc: 0.773196\n",
      "Epoch 28858 - Train Loss: 0.071720, Train Acc: 0.885897 | Val Loss: 0.109587, Val Acc: 0.773196\n",
      "Epoch 28859 - Train Loss: 0.071719, Train Acc: 0.885897 | Val Loss: 0.109587, Val Acc: 0.773196\n",
      "Epoch 28860 - Train Loss: 0.071717, Train Acc: 0.885897 | Val Loss: 0.109587, Val Acc: 0.773196\n",
      "Epoch 28861 - Train Loss: 0.071716, Train Acc: 0.885897 | Val Loss: 0.109586, Val Acc: 0.773196\n",
      "Epoch 28862 - Train Loss: 0.071715, Train Acc: 0.885897 | Val Loss: 0.109586, Val Acc: 0.773196\n",
      "Epoch 28863 - Train Loss: 0.071713, Train Acc: 0.885897 | Val Loss: 0.109586, Val Acc: 0.773196\n",
      "Epoch 28864 - Train Loss: 0.071712, Train Acc: 0.885897 | Val Loss: 0.109585, Val Acc: 0.773196\n",
      "Epoch 28865 - Train Loss: 0.071711, Train Acc: 0.885897 | Val Loss: 0.109585, Val Acc: 0.773196\n",
      "Epoch 28866 - Train Loss: 0.071710, Train Acc: 0.885897 | Val Loss: 0.109585, Val Acc: 0.773196\n",
      "Epoch 28867 - Train Loss: 0.071708, Train Acc: 0.885897 | Val Loss: 0.109584, Val Acc: 0.773196\n",
      "Epoch 28868 - Train Loss: 0.071707, Train Acc: 0.885897 | Val Loss: 0.109584, Val Acc: 0.773196\n",
      "Epoch 28869 - Train Loss: 0.071706, Train Acc: 0.885897 | Val Loss: 0.109584, Val Acc: 0.773196\n",
      "Epoch 28870 - Train Loss: 0.071704, Train Acc: 0.885897 | Val Loss: 0.109584, Val Acc: 0.773196\n",
      "Epoch 28871 - Train Loss: 0.071703, Train Acc: 0.885897 | Val Loss: 0.109583, Val Acc: 0.773196\n",
      "Epoch 28872 - Train Loss: 0.071702, Train Acc: 0.885897 | Val Loss: 0.109583, Val Acc: 0.773196\n",
      "Epoch 28873 - Train Loss: 0.071701, Train Acc: 0.885897 | Val Loss: 0.109583, Val Acc: 0.773196\n",
      "Epoch 28874 - Train Loss: 0.071699, Train Acc: 0.885897 | Val Loss: 0.109582, Val Acc: 0.773196\n",
      "Epoch 28875 - Train Loss: 0.071698, Train Acc: 0.885897 | Val Loss: 0.109582, Val Acc: 0.773196\n",
      "Epoch 28876 - Train Loss: 0.071697, Train Acc: 0.885897 | Val Loss: 0.109582, Val Acc: 0.773196\n",
      "Epoch 28877 - Train Loss: 0.071695, Train Acc: 0.885897 | Val Loss: 0.109581, Val Acc: 0.773196\n",
      "Epoch 28878 - Train Loss: 0.071694, Train Acc: 0.885897 | Val Loss: 0.109581, Val Acc: 0.773196\n",
      "Epoch 28879 - Train Loss: 0.071693, Train Acc: 0.885897 | Val Loss: 0.109581, Val Acc: 0.773196\n",
      "Epoch 28880 - Train Loss: 0.071692, Train Acc: 0.885897 | Val Loss: 0.109581, Val Acc: 0.773196\n",
      "Epoch 28881 - Train Loss: 0.071690, Train Acc: 0.885897 | Val Loss: 0.109580, Val Acc: 0.773196\n",
      "Epoch 28882 - Train Loss: 0.071689, Train Acc: 0.885897 | Val Loss: 0.109580, Val Acc: 0.773196\n",
      "Epoch 28883 - Train Loss: 0.071688, Train Acc: 0.885897 | Val Loss: 0.109580, Val Acc: 0.773196\n",
      "Epoch 28884 - Train Loss: 0.071686, Train Acc: 0.885897 | Val Loss: 0.109579, Val Acc: 0.773196\n",
      "Epoch 28885 - Train Loss: 0.071685, Train Acc: 0.885897 | Val Loss: 0.109579, Val Acc: 0.773196\n",
      "Epoch 28886 - Train Loss: 0.071684, Train Acc: 0.885897 | Val Loss: 0.109579, Val Acc: 0.773196\n",
      "Epoch 28887 - Train Loss: 0.071683, Train Acc: 0.885897 | Val Loss: 0.109578, Val Acc: 0.773196\n",
      "Epoch 28888 - Train Loss: 0.071681, Train Acc: 0.885897 | Val Loss: 0.109578, Val Acc: 0.773196\n",
      "Epoch 28889 - Train Loss: 0.071680, Train Acc: 0.885897 | Val Loss: 0.109578, Val Acc: 0.773196\n",
      "Epoch 28890 - Train Loss: 0.071679, Train Acc: 0.885897 | Val Loss: 0.109577, Val Acc: 0.773196\n",
      "Epoch 28891 - Train Loss: 0.071677, Train Acc: 0.885897 | Val Loss: 0.109577, Val Acc: 0.773196\n",
      "Epoch 28892 - Train Loss: 0.071676, Train Acc: 0.885897 | Val Loss: 0.109577, Val Acc: 0.773196\n",
      "Epoch 28893 - Train Loss: 0.071675, Train Acc: 0.885897 | Val Loss: 0.109576, Val Acc: 0.773196\n",
      "Epoch 28894 - Train Loss: 0.071674, Train Acc: 0.885897 | Val Loss: 0.109576, Val Acc: 0.773196\n",
      "Epoch 28895 - Train Loss: 0.071672, Train Acc: 0.885897 | Val Loss: 0.109576, Val Acc: 0.773196\n",
      "Epoch 28896 - Train Loss: 0.071671, Train Acc: 0.885897 | Val Loss: 0.109576, Val Acc: 0.773196\n",
      "Epoch 28897 - Train Loss: 0.071670, Train Acc: 0.885897 | Val Loss: 0.109575, Val Acc: 0.773196\n",
      "Epoch 28898 - Train Loss: 0.071668, Train Acc: 0.885897 | Val Loss: 0.109575, Val Acc: 0.773196\n",
      "Epoch 28899 - Train Loss: 0.071667, Train Acc: 0.885897 | Val Loss: 0.109575, Val Acc: 0.773196\n",
      "Epoch 28900 - Train Loss: 0.071666, Train Acc: 0.885897 | Val Loss: 0.109574, Val Acc: 0.773196\n",
      "Epoch 28901 - Train Loss: 0.071665, Train Acc: 0.885897 | Val Loss: 0.109574, Val Acc: 0.773196\n",
      "Epoch 28902 - Train Loss: 0.071663, Train Acc: 0.885897 | Val Loss: 0.109574, Val Acc: 0.773196\n",
      "Epoch 28903 - Train Loss: 0.071662, Train Acc: 0.885897 | Val Loss: 0.109573, Val Acc: 0.773196\n",
      "Epoch 28904 - Train Loss: 0.071661, Train Acc: 0.885897 | Val Loss: 0.109573, Val Acc: 0.773196\n",
      "Epoch 28905 - Train Loss: 0.071659, Train Acc: 0.885897 | Val Loss: 0.109573, Val Acc: 0.773196\n",
      "Epoch 28906 - Train Loss: 0.071658, Train Acc: 0.885897 | Val Loss: 0.109573, Val Acc: 0.773196\n",
      "Epoch 28907 - Train Loss: 0.071657, Train Acc: 0.885897 | Val Loss: 0.109572, Val Acc: 0.773196\n",
      "Epoch 28908 - Train Loss: 0.071656, Train Acc: 0.885897 | Val Loss: 0.109572, Val Acc: 0.773196\n",
      "Epoch 28909 - Train Loss: 0.071654, Train Acc: 0.885897 | Val Loss: 0.109572, Val Acc: 0.773196\n",
      "Epoch 28910 - Train Loss: 0.071653, Train Acc: 0.885897 | Val Loss: 0.109571, Val Acc: 0.773196\n",
      "Epoch 28911 - Train Loss: 0.071652, Train Acc: 0.885897 | Val Loss: 0.109571, Val Acc: 0.773196\n",
      "Epoch 28912 - Train Loss: 0.071650, Train Acc: 0.885897 | Val Loss: 0.109571, Val Acc: 0.773196\n",
      "Epoch 28913 - Train Loss: 0.071649, Train Acc: 0.885897 | Val Loss: 0.109570, Val Acc: 0.773196\n",
      "Epoch 28914 - Train Loss: 0.071648, Train Acc: 0.885897 | Val Loss: 0.109570, Val Acc: 0.773196\n",
      "Epoch 28915 - Train Loss: 0.071647, Train Acc: 0.885897 | Val Loss: 0.109570, Val Acc: 0.773196\n",
      "Epoch 28916 - Train Loss: 0.071645, Train Acc: 0.885897 | Val Loss: 0.109570, Val Acc: 0.773196\n",
      "Epoch 28917 - Train Loss: 0.071644, Train Acc: 0.885897 | Val Loss: 0.109569, Val Acc: 0.773196\n",
      "Epoch 28918 - Train Loss: 0.071643, Train Acc: 0.885897 | Val Loss: 0.109569, Val Acc: 0.773196\n",
      "Epoch 28919 - Train Loss: 0.071641, Train Acc: 0.885897 | Val Loss: 0.109569, Val Acc: 0.773196\n",
      "Epoch 28920 - Train Loss: 0.071640, Train Acc: 0.885897 | Val Loss: 0.109568, Val Acc: 0.773196\n",
      "Epoch 28921 - Train Loss: 0.071639, Train Acc: 0.885897 | Val Loss: 0.109568, Val Acc: 0.773196\n",
      "Epoch 28922 - Train Loss: 0.071638, Train Acc: 0.885897 | Val Loss: 0.109568, Val Acc: 0.773196\n",
      "Epoch 28923 - Train Loss: 0.071636, Train Acc: 0.885897 | Val Loss: 0.109567, Val Acc: 0.773196\n",
      "Epoch 28924 - Train Loss: 0.071635, Train Acc: 0.885897 | Val Loss: 0.109567, Val Acc: 0.773196\n",
      "Epoch 28925 - Train Loss: 0.071634, Train Acc: 0.885897 | Val Loss: 0.109567, Val Acc: 0.773196\n",
      "Epoch 28926 - Train Loss: 0.071633, Train Acc: 0.885897 | Val Loss: 0.109567, Val Acc: 0.773196\n",
      "Epoch 28927 - Train Loss: 0.071631, Train Acc: 0.885897 | Val Loss: 0.109566, Val Acc: 0.773196\n",
      "Epoch 28928 - Train Loss: 0.071630, Train Acc: 0.885897 | Val Loss: 0.109566, Val Acc: 0.773196\n",
      "Epoch 28929 - Train Loss: 0.071629, Train Acc: 0.885897 | Val Loss: 0.109566, Val Acc: 0.773196\n",
      "Epoch 28930 - Train Loss: 0.071627, Train Acc: 0.885897 | Val Loss: 0.109565, Val Acc: 0.773196\n",
      "Epoch 28931 - Train Loss: 0.071626, Train Acc: 0.885897 | Val Loss: 0.109565, Val Acc: 0.773196\n",
      "Epoch 28932 - Train Loss: 0.071625, Train Acc: 0.885897 | Val Loss: 0.109565, Val Acc: 0.773196\n",
      "Epoch 28933 - Train Loss: 0.071624, Train Acc: 0.885897 | Val Loss: 0.109564, Val Acc: 0.773196\n",
      "Epoch 28934 - Train Loss: 0.071622, Train Acc: 0.885897 | Val Loss: 0.109564, Val Acc: 0.773196\n",
      "Epoch 28935 - Train Loss: 0.071621, Train Acc: 0.885897 | Val Loss: 0.109564, Val Acc: 0.773196\n",
      "Epoch 28936 - Train Loss: 0.071620, Train Acc: 0.885897 | Val Loss: 0.109564, Val Acc: 0.773196\n",
      "Epoch 28937 - Train Loss: 0.071618, Train Acc: 0.885897 | Val Loss: 0.109563, Val Acc: 0.773196\n",
      "Epoch 28938 - Train Loss: 0.071617, Train Acc: 0.885897 | Val Loss: 0.109563, Val Acc: 0.773196\n",
      "Epoch 28939 - Train Loss: 0.071616, Train Acc: 0.885897 | Val Loss: 0.109563, Val Acc: 0.773196\n",
      "Epoch 28940 - Train Loss: 0.071615, Train Acc: 0.885897 | Val Loss: 0.109562, Val Acc: 0.773196\n",
      "Epoch 28941 - Train Loss: 0.071613, Train Acc: 0.885897 | Val Loss: 0.109562, Val Acc: 0.773196\n",
      "Epoch 28942 - Train Loss: 0.071612, Train Acc: 0.885897 | Val Loss: 0.109562, Val Acc: 0.773196\n",
      "Epoch 28943 - Train Loss: 0.071611, Train Acc: 0.885897 | Val Loss: 0.109561, Val Acc: 0.773196\n",
      "Epoch 28944 - Train Loss: 0.071609, Train Acc: 0.885897 | Val Loss: 0.109561, Val Acc: 0.773196\n",
      "Epoch 28945 - Train Loss: 0.071608, Train Acc: 0.885897 | Val Loss: 0.109561, Val Acc: 0.773196\n",
      "Epoch 28946 - Train Loss: 0.071607, Train Acc: 0.885897 | Val Loss: 0.109561, Val Acc: 0.773196\n",
      "Epoch 28947 - Train Loss: 0.071606, Train Acc: 0.885897 | Val Loss: 0.109560, Val Acc: 0.773196\n",
      "Epoch 28948 - Train Loss: 0.071604, Train Acc: 0.885897 | Val Loss: 0.109560, Val Acc: 0.773196\n",
      "Epoch 28949 - Train Loss: 0.071603, Train Acc: 0.885897 | Val Loss: 0.109560, Val Acc: 0.773196\n",
      "Epoch 28950 - Train Loss: 0.071602, Train Acc: 0.885897 | Val Loss: 0.109559, Val Acc: 0.773196\n",
      "Epoch 28951 - Train Loss: 0.071601, Train Acc: 0.885897 | Val Loss: 0.109559, Val Acc: 0.773196\n",
      "Epoch 28952 - Train Loss: 0.071599, Train Acc: 0.885897 | Val Loss: 0.109559, Val Acc: 0.773196\n",
      "Epoch 28953 - Train Loss: 0.071598, Train Acc: 0.885897 | Val Loss: 0.109558, Val Acc: 0.773196\n",
      "Epoch 28954 - Train Loss: 0.071597, Train Acc: 0.885897 | Val Loss: 0.109558, Val Acc: 0.773196\n",
      "Epoch 28955 - Train Loss: 0.071595, Train Acc: 0.885897 | Val Loss: 0.109558, Val Acc: 0.773196\n",
      "Epoch 28956 - Train Loss: 0.071594, Train Acc: 0.885897 | Val Loss: 0.109558, Val Acc: 0.773196\n",
      "Epoch 28957 - Train Loss: 0.071593, Train Acc: 0.885897 | Val Loss: 0.109557, Val Acc: 0.773196\n",
      "Epoch 28958 - Train Loss: 0.071592, Train Acc: 0.885897 | Val Loss: 0.109557, Val Acc: 0.773196\n",
      "Epoch 28959 - Train Loss: 0.071590, Train Acc: 0.885897 | Val Loss: 0.109557, Val Acc: 0.773196\n",
      "Epoch 28960 - Train Loss: 0.071589, Train Acc: 0.885897 | Val Loss: 0.109556, Val Acc: 0.773196\n",
      "Epoch 28961 - Train Loss: 0.071588, Train Acc: 0.885897 | Val Loss: 0.109556, Val Acc: 0.773196\n",
      "Epoch 28962 - Train Loss: 0.071586, Train Acc: 0.885897 | Val Loss: 0.109556, Val Acc: 0.773196\n",
      "Epoch 28963 - Train Loss: 0.071585, Train Acc: 0.885897 | Val Loss: 0.109555, Val Acc: 0.773196\n",
      "Epoch 28964 - Train Loss: 0.071584, Train Acc: 0.885897 | Val Loss: 0.109555, Val Acc: 0.773196\n",
      "Epoch 28965 - Train Loss: 0.071583, Train Acc: 0.885897 | Val Loss: 0.109555, Val Acc: 0.773196\n",
      "Epoch 28966 - Train Loss: 0.071581, Train Acc: 0.885897 | Val Loss: 0.109555, Val Acc: 0.773196\n",
      "Epoch 28967 - Train Loss: 0.071580, Train Acc: 0.885897 | Val Loss: 0.109554, Val Acc: 0.773196\n",
      "Epoch 28968 - Train Loss: 0.071579, Train Acc: 0.885897 | Val Loss: 0.109554, Val Acc: 0.773196\n",
      "Epoch 28969 - Train Loss: 0.071577, Train Acc: 0.885897 | Val Loss: 0.109554, Val Acc: 0.773196\n",
      "Epoch 28970 - Train Loss: 0.071576, Train Acc: 0.885897 | Val Loss: 0.109553, Val Acc: 0.773196\n",
      "Epoch 28971 - Train Loss: 0.071575, Train Acc: 0.885897 | Val Loss: 0.109553, Val Acc: 0.773196\n",
      "Epoch 28972 - Train Loss: 0.071574, Train Acc: 0.885897 | Val Loss: 0.109553, Val Acc: 0.773196\n",
      "Epoch 28973 - Train Loss: 0.071572, Train Acc: 0.885897 | Val Loss: 0.109552, Val Acc: 0.773196\n",
      "Epoch 28974 - Train Loss: 0.071571, Train Acc: 0.885897 | Val Loss: 0.109552, Val Acc: 0.773196\n",
      "Epoch 28975 - Train Loss: 0.071570, Train Acc: 0.885897 | Val Loss: 0.109552, Val Acc: 0.773196\n",
      "Epoch 28976 - Train Loss: 0.071569, Train Acc: 0.885897 | Val Loss: 0.109552, Val Acc: 0.773196\n",
      "Epoch 28977 - Train Loss: 0.071567, Train Acc: 0.885897 | Val Loss: 0.109551, Val Acc: 0.773196\n",
      "Epoch 28978 - Train Loss: 0.071566, Train Acc: 0.885897 | Val Loss: 0.109551, Val Acc: 0.773196\n",
      "Epoch 28979 - Train Loss: 0.071565, Train Acc: 0.885897 | Val Loss: 0.109551, Val Acc: 0.773196\n",
      "Epoch 28980 - Train Loss: 0.071563, Train Acc: 0.885897 | Val Loss: 0.109550, Val Acc: 0.773196\n",
      "Epoch 28981 - Train Loss: 0.071562, Train Acc: 0.885897 | Val Loss: 0.109550, Val Acc: 0.773196\n",
      "Epoch 28982 - Train Loss: 0.071561, Train Acc: 0.885897 | Val Loss: 0.109550, Val Acc: 0.773196\n",
      "Epoch 28983 - Train Loss: 0.071560, Train Acc: 0.885897 | Val Loss: 0.109549, Val Acc: 0.773196\n",
      "Epoch 28984 - Train Loss: 0.071558, Train Acc: 0.885897 | Val Loss: 0.109549, Val Acc: 0.773196\n",
      "Epoch 28985 - Train Loss: 0.071557, Train Acc: 0.885897 | Val Loss: 0.109549, Val Acc: 0.773196\n",
      "Epoch 28986 - Train Loss: 0.071556, Train Acc: 0.885897 | Val Loss: 0.109549, Val Acc: 0.773196\n",
      "Epoch 28987 - Train Loss: 0.071554, Train Acc: 0.885897 | Val Loss: 0.109548, Val Acc: 0.773196\n",
      "Epoch 28988 - Train Loss: 0.071553, Train Acc: 0.885897 | Val Loss: 0.109548, Val Acc: 0.773196\n",
      "Epoch 28989 - Train Loss: 0.071552, Train Acc: 0.885897 | Val Loss: 0.109548, Val Acc: 0.773196\n",
      "Epoch 28990 - Train Loss: 0.071551, Train Acc: 0.885897 | Val Loss: 0.109547, Val Acc: 0.773196\n",
      "Epoch 28991 - Train Loss: 0.071549, Train Acc: 0.885897 | Val Loss: 0.109547, Val Acc: 0.773196\n",
      "Epoch 28992 - Train Loss: 0.071548, Train Acc: 0.885897 | Val Loss: 0.109547, Val Acc: 0.773196\n",
      "Epoch 28993 - Train Loss: 0.071547, Train Acc: 0.885897 | Val Loss: 0.109546, Val Acc: 0.773196\n",
      "Epoch 28994 - Train Loss: 0.071546, Train Acc: 0.885897 | Val Loss: 0.109546, Val Acc: 0.773196\n",
      "Epoch 28995 - Train Loss: 0.071544, Train Acc: 0.885897 | Val Loss: 0.109546, Val Acc: 0.773196\n",
      "Epoch 28996 - Train Loss: 0.071543, Train Acc: 0.885897 | Val Loss: 0.109546, Val Acc: 0.773196\n",
      "Epoch 28997 - Train Loss: 0.071542, Train Acc: 0.885897 | Val Loss: 0.109545, Val Acc: 0.773196\n",
      "Epoch 28998 - Train Loss: 0.071540, Train Acc: 0.885897 | Val Loss: 0.109545, Val Acc: 0.773196\n",
      "Epoch 28999 - Train Loss: 0.071539, Train Acc: 0.885897 | Val Loss: 0.109545, Val Acc: 0.773196\n",
      "Epoch 29000 - Train Loss: 0.071538, Train Acc: 0.885897 | Val Loss: 0.109544, Val Acc: 0.773196\n",
      "Epoch 29001 - Train Loss: 0.071537, Train Acc: 0.885897 | Val Loss: 0.109544, Val Acc: 0.773196\n",
      "Epoch 29002 - Train Loss: 0.071535, Train Acc: 0.885897 | Val Loss: 0.109544, Val Acc: 0.773196\n",
      "Epoch 29003 - Train Loss: 0.071534, Train Acc: 0.885897 | Val Loss: 0.109543, Val Acc: 0.773196\n",
      "Epoch 29004 - Train Loss: 0.071533, Train Acc: 0.885897 | Val Loss: 0.109543, Val Acc: 0.773196\n",
      "Epoch 29005 - Train Loss: 0.071531, Train Acc: 0.885897 | Val Loss: 0.109543, Val Acc: 0.773196\n",
      "Epoch 29006 - Train Loss: 0.071530, Train Acc: 0.885897 | Val Loss: 0.109543, Val Acc: 0.773196\n",
      "Epoch 29007 - Train Loss: 0.071529, Train Acc: 0.885897 | Val Loss: 0.109542, Val Acc: 0.773196\n",
      "Epoch 29008 - Train Loss: 0.071528, Train Acc: 0.885897 | Val Loss: 0.109542, Val Acc: 0.773196\n",
      "Epoch 29009 - Train Loss: 0.071526, Train Acc: 0.885897 | Val Loss: 0.109542, Val Acc: 0.773196\n",
      "Epoch 29010 - Train Loss: 0.071525, Train Acc: 0.885897 | Val Loss: 0.109541, Val Acc: 0.773196\n",
      "Epoch 29011 - Train Loss: 0.071524, Train Acc: 0.885897 | Val Loss: 0.109541, Val Acc: 0.773196\n",
      "Epoch 29012 - Train Loss: 0.071523, Train Acc: 0.885897 | Val Loss: 0.109541, Val Acc: 0.773196\n",
      "Epoch 29013 - Train Loss: 0.071521, Train Acc: 0.885897 | Val Loss: 0.109541, Val Acc: 0.773196\n",
      "Epoch 29014 - Train Loss: 0.071520, Train Acc: 0.885897 | Val Loss: 0.109540, Val Acc: 0.773196\n",
      "Epoch 29015 - Train Loss: 0.071519, Train Acc: 0.885897 | Val Loss: 0.109540, Val Acc: 0.773196\n",
      "Epoch 29016 - Train Loss: 0.071517, Train Acc: 0.885897 | Val Loss: 0.109540, Val Acc: 0.773196\n",
      "Epoch 29017 - Train Loss: 0.071516, Train Acc: 0.885897 | Val Loss: 0.109539, Val Acc: 0.773196\n",
      "Epoch 29018 - Train Loss: 0.071515, Train Acc: 0.885897 | Val Loss: 0.109539, Val Acc: 0.773196\n",
      "Epoch 29019 - Train Loss: 0.071514, Train Acc: 0.885897 | Val Loss: 0.109539, Val Acc: 0.773196\n",
      "Epoch 29020 - Train Loss: 0.071512, Train Acc: 0.884615 | Val Loss: 0.109538, Val Acc: 0.773196\n",
      "Epoch 29021 - Train Loss: 0.071511, Train Acc: 0.884615 | Val Loss: 0.109538, Val Acc: 0.773196\n",
      "Epoch 29022 - Train Loss: 0.071510, Train Acc: 0.884615 | Val Loss: 0.109538, Val Acc: 0.773196\n",
      "Epoch 29023 - Train Loss: 0.071508, Train Acc: 0.884615 | Val Loss: 0.109538, Val Acc: 0.773196\n",
      "Epoch 29024 - Train Loss: 0.071507, Train Acc: 0.884615 | Val Loss: 0.109537, Val Acc: 0.773196\n",
      "Epoch 29025 - Train Loss: 0.071506, Train Acc: 0.884615 | Val Loss: 0.109537, Val Acc: 0.773196\n",
      "Epoch 29026 - Train Loss: 0.071505, Train Acc: 0.884615 | Val Loss: 0.109537, Val Acc: 0.773196\n",
      "Epoch 29027 - Train Loss: 0.071503, Train Acc: 0.884615 | Val Loss: 0.109536, Val Acc: 0.773196\n",
      "Epoch 29028 - Train Loss: 0.071502, Train Acc: 0.884615 | Val Loss: 0.109536, Val Acc: 0.773196\n",
      "Epoch 29029 - Train Loss: 0.071501, Train Acc: 0.884615 | Val Loss: 0.109536, Val Acc: 0.773196\n",
      "Epoch 29030 - Train Loss: 0.071500, Train Acc: 0.884615 | Val Loss: 0.109535, Val Acc: 0.773196\n",
      "Epoch 29031 - Train Loss: 0.071498, Train Acc: 0.884615 | Val Loss: 0.109535, Val Acc: 0.773196\n",
      "Epoch 29032 - Train Loss: 0.071497, Train Acc: 0.884615 | Val Loss: 0.109535, Val Acc: 0.773196\n",
      "Epoch 29033 - Train Loss: 0.071496, Train Acc: 0.884615 | Val Loss: 0.109535, Val Acc: 0.773196\n",
      "Epoch 29034 - Train Loss: 0.071494, Train Acc: 0.884615 | Val Loss: 0.109534, Val Acc: 0.773196\n",
      "Epoch 29035 - Train Loss: 0.071493, Train Acc: 0.884615 | Val Loss: 0.109534, Val Acc: 0.773196\n",
      "Epoch 29036 - Train Loss: 0.071492, Train Acc: 0.884615 | Val Loss: 0.109534, Val Acc: 0.773196\n",
      "Epoch 29037 - Train Loss: 0.071491, Train Acc: 0.884615 | Val Loss: 0.109533, Val Acc: 0.773196\n",
      "Epoch 29038 - Train Loss: 0.071489, Train Acc: 0.884615 | Val Loss: 0.109533, Val Acc: 0.773196\n",
      "Epoch 29039 - Train Loss: 0.071488, Train Acc: 0.884615 | Val Loss: 0.109533, Val Acc: 0.773196\n",
      "Epoch 29040 - Train Loss: 0.071487, Train Acc: 0.884615 | Val Loss: 0.109533, Val Acc: 0.773196\n",
      "Epoch 29041 - Train Loss: 0.071486, Train Acc: 0.884615 | Val Loss: 0.109532, Val Acc: 0.773196\n",
      "Epoch 29042 - Train Loss: 0.071484, Train Acc: 0.884615 | Val Loss: 0.109532, Val Acc: 0.773196\n",
      "Epoch 29043 - Train Loss: 0.071483, Train Acc: 0.884615 | Val Loss: 0.109532, Val Acc: 0.773196\n",
      "Epoch 29044 - Train Loss: 0.071482, Train Acc: 0.884615 | Val Loss: 0.109531, Val Acc: 0.773196\n",
      "Epoch 29045 - Train Loss: 0.071480, Train Acc: 0.884615 | Val Loss: 0.109531, Val Acc: 0.773196\n",
      "Epoch 29046 - Train Loss: 0.071479, Train Acc: 0.884615 | Val Loss: 0.109531, Val Acc: 0.773196\n",
      "Epoch 29047 - Train Loss: 0.071478, Train Acc: 0.884615 | Val Loss: 0.109530, Val Acc: 0.773196\n",
      "Epoch 29048 - Train Loss: 0.071477, Train Acc: 0.884615 | Val Loss: 0.109530, Val Acc: 0.773196\n",
      "Epoch 29049 - Train Loss: 0.071475, Train Acc: 0.884615 | Val Loss: 0.109530, Val Acc: 0.773196\n",
      "Epoch 29050 - Train Loss: 0.071474, Train Acc: 0.884615 | Val Loss: 0.109530, Val Acc: 0.773196\n",
      "Epoch 29051 - Train Loss: 0.071473, Train Acc: 0.884615 | Val Loss: 0.109529, Val Acc: 0.773196\n",
      "Epoch 29052 - Train Loss: 0.071472, Train Acc: 0.884615 | Val Loss: 0.109529, Val Acc: 0.773196\n",
      "Epoch 29053 - Train Loss: 0.071470, Train Acc: 0.884615 | Val Loss: 0.109529, Val Acc: 0.773196\n",
      "Epoch 29054 - Train Loss: 0.071469, Train Acc: 0.884615 | Val Loss: 0.109528, Val Acc: 0.773196\n",
      "Epoch 29055 - Train Loss: 0.071468, Train Acc: 0.884615 | Val Loss: 0.109528, Val Acc: 0.773196\n",
      "Epoch 29056 - Train Loss: 0.071466, Train Acc: 0.884615 | Val Loss: 0.109528, Val Acc: 0.773196\n",
      "Epoch 29057 - Train Loss: 0.071465, Train Acc: 0.884615 | Val Loss: 0.109527, Val Acc: 0.773196\n",
      "Epoch 29058 - Train Loss: 0.071464, Train Acc: 0.884615 | Val Loss: 0.109527, Val Acc: 0.773196\n",
      "Epoch 29059 - Train Loss: 0.071463, Train Acc: 0.884615 | Val Loss: 0.109527, Val Acc: 0.773196\n",
      "Epoch 29060 - Train Loss: 0.071461, Train Acc: 0.884615 | Val Loss: 0.109527, Val Acc: 0.773196\n",
      "Epoch 29061 - Train Loss: 0.071460, Train Acc: 0.884615 | Val Loss: 0.109526, Val Acc: 0.773196\n",
      "Epoch 29062 - Train Loss: 0.071459, Train Acc: 0.884615 | Val Loss: 0.109526, Val Acc: 0.773196\n",
      "Epoch 29063 - Train Loss: 0.071458, Train Acc: 0.884615 | Val Loss: 0.109526, Val Acc: 0.773196\n",
      "Epoch 29064 - Train Loss: 0.071456, Train Acc: 0.884615 | Val Loss: 0.109525, Val Acc: 0.773196\n",
      "Epoch 29065 - Train Loss: 0.071455, Train Acc: 0.884615 | Val Loss: 0.109525, Val Acc: 0.773196\n",
      "Epoch 29066 - Train Loss: 0.071454, Train Acc: 0.884615 | Val Loss: 0.109525, Val Acc: 0.773196\n",
      "Epoch 29067 - Train Loss: 0.071452, Train Acc: 0.885897 | Val Loss: 0.109525, Val Acc: 0.773196\n",
      "Epoch 29068 - Train Loss: 0.071451, Train Acc: 0.885897 | Val Loss: 0.109524, Val Acc: 0.773196\n",
      "Epoch 29069 - Train Loss: 0.071450, Train Acc: 0.885897 | Val Loss: 0.109524, Val Acc: 0.773196\n",
      "Epoch 29070 - Train Loss: 0.071449, Train Acc: 0.885897 | Val Loss: 0.109524, Val Acc: 0.773196\n",
      "Epoch 29071 - Train Loss: 0.071447, Train Acc: 0.885897 | Val Loss: 0.109523, Val Acc: 0.773196\n",
      "Epoch 29072 - Train Loss: 0.071446, Train Acc: 0.885897 | Val Loss: 0.109523, Val Acc: 0.773196\n",
      "Epoch 29073 - Train Loss: 0.071445, Train Acc: 0.885897 | Val Loss: 0.109523, Val Acc: 0.773196\n",
      "Epoch 29074 - Train Loss: 0.071444, Train Acc: 0.885897 | Val Loss: 0.109522, Val Acc: 0.773196\n",
      "Epoch 29075 - Train Loss: 0.071442, Train Acc: 0.885897 | Val Loss: 0.109522, Val Acc: 0.773196\n",
      "Epoch 29076 - Train Loss: 0.071441, Train Acc: 0.885897 | Val Loss: 0.109522, Val Acc: 0.773196\n",
      "Epoch 29077 - Train Loss: 0.071440, Train Acc: 0.885897 | Val Loss: 0.109522, Val Acc: 0.773196\n",
      "Epoch 29078 - Train Loss: 0.071438, Train Acc: 0.885897 | Val Loss: 0.109521, Val Acc: 0.773196\n",
      "Epoch 29079 - Train Loss: 0.071437, Train Acc: 0.885897 | Val Loss: 0.109521, Val Acc: 0.773196\n",
      "Epoch 29080 - Train Loss: 0.071436, Train Acc: 0.885897 | Val Loss: 0.109521, Val Acc: 0.773196\n",
      "Epoch 29081 - Train Loss: 0.071435, Train Acc: 0.885897 | Val Loss: 0.109520, Val Acc: 0.773196\n",
      "Epoch 29082 - Train Loss: 0.071433, Train Acc: 0.885897 | Val Loss: 0.109520, Val Acc: 0.773196\n",
      "Epoch 29083 - Train Loss: 0.071432, Train Acc: 0.885897 | Val Loss: 0.109520, Val Acc: 0.773196\n",
      "Epoch 29084 - Train Loss: 0.071431, Train Acc: 0.885897 | Val Loss: 0.109520, Val Acc: 0.773196\n",
      "Epoch 29085 - Train Loss: 0.071430, Train Acc: 0.885897 | Val Loss: 0.109519, Val Acc: 0.773196\n",
      "Epoch 29086 - Train Loss: 0.071428, Train Acc: 0.885897 | Val Loss: 0.109519, Val Acc: 0.773196\n",
      "Epoch 29087 - Train Loss: 0.071427, Train Acc: 0.885897 | Val Loss: 0.109519, Val Acc: 0.773196\n",
      "Epoch 29088 - Train Loss: 0.071426, Train Acc: 0.885897 | Val Loss: 0.109518, Val Acc: 0.773196\n",
      "Epoch 29089 - Train Loss: 0.071424, Train Acc: 0.885897 | Val Loss: 0.109518, Val Acc: 0.773196\n",
      "Epoch 29090 - Train Loss: 0.071423, Train Acc: 0.885897 | Val Loss: 0.109518, Val Acc: 0.773196\n",
      "Epoch 29091 - Train Loss: 0.071422, Train Acc: 0.885897 | Val Loss: 0.109517, Val Acc: 0.773196\n",
      "Epoch 29092 - Train Loss: 0.071421, Train Acc: 0.885897 | Val Loss: 0.109517, Val Acc: 0.773196\n",
      "Epoch 29093 - Train Loss: 0.071419, Train Acc: 0.885897 | Val Loss: 0.109517, Val Acc: 0.773196\n",
      "Epoch 29094 - Train Loss: 0.071418, Train Acc: 0.885897 | Val Loss: 0.109517, Val Acc: 0.773196\n",
      "Epoch 29095 - Train Loss: 0.071417, Train Acc: 0.885897 | Val Loss: 0.109516, Val Acc: 0.773196\n",
      "Epoch 29096 - Train Loss: 0.071416, Train Acc: 0.885897 | Val Loss: 0.109516, Val Acc: 0.773196\n",
      "Epoch 29097 - Train Loss: 0.071414, Train Acc: 0.885897 | Val Loss: 0.109516, Val Acc: 0.773196\n",
      "Epoch 29098 - Train Loss: 0.071413, Train Acc: 0.885897 | Val Loss: 0.109515, Val Acc: 0.773196\n",
      "Epoch 29099 - Train Loss: 0.071412, Train Acc: 0.885897 | Val Loss: 0.109515, Val Acc: 0.773196\n",
      "Epoch 29100 - Train Loss: 0.071410, Train Acc: 0.885897 | Val Loss: 0.109515, Val Acc: 0.773196\n",
      "Epoch 29101 - Train Loss: 0.071409, Train Acc: 0.885897 | Val Loss: 0.109515, Val Acc: 0.773196\n",
      "Epoch 29102 - Train Loss: 0.071408, Train Acc: 0.885897 | Val Loss: 0.109514, Val Acc: 0.773196\n",
      "Epoch 29103 - Train Loss: 0.071407, Train Acc: 0.885897 | Val Loss: 0.109514, Val Acc: 0.773196\n",
      "Epoch 29104 - Train Loss: 0.071405, Train Acc: 0.885897 | Val Loss: 0.109514, Val Acc: 0.773196\n",
      "Epoch 29105 - Train Loss: 0.071404, Train Acc: 0.885897 | Val Loss: 0.109513, Val Acc: 0.773196\n",
      "Epoch 29106 - Train Loss: 0.071403, Train Acc: 0.885897 | Val Loss: 0.109513, Val Acc: 0.773196\n",
      "Epoch 29107 - Train Loss: 0.071402, Train Acc: 0.885897 | Val Loss: 0.109513, Val Acc: 0.773196\n",
      "Epoch 29108 - Train Loss: 0.071400, Train Acc: 0.885897 | Val Loss: 0.109513, Val Acc: 0.773196\n",
      "Epoch 29109 - Train Loss: 0.071399, Train Acc: 0.885897 | Val Loss: 0.109512, Val Acc: 0.773196\n",
      "Epoch 29110 - Train Loss: 0.071398, Train Acc: 0.885897 | Val Loss: 0.109512, Val Acc: 0.773196\n",
      "Epoch 29111 - Train Loss: 0.071396, Train Acc: 0.885897 | Val Loss: 0.109512, Val Acc: 0.773196\n",
      "Epoch 29112 - Train Loss: 0.071395, Train Acc: 0.885897 | Val Loss: 0.109511, Val Acc: 0.773196\n",
      "Epoch 29113 - Train Loss: 0.071394, Train Acc: 0.885897 | Val Loss: 0.109511, Val Acc: 0.773196\n",
      "Epoch 29114 - Train Loss: 0.071393, Train Acc: 0.885897 | Val Loss: 0.109511, Val Acc: 0.773196\n",
      "Epoch 29115 - Train Loss: 0.071391, Train Acc: 0.885897 | Val Loss: 0.109510, Val Acc: 0.773196\n",
      "Epoch 29116 - Train Loss: 0.071390, Train Acc: 0.885897 | Val Loss: 0.109510, Val Acc: 0.773196\n",
      "Epoch 29117 - Train Loss: 0.071389, Train Acc: 0.885897 | Val Loss: 0.109510, Val Acc: 0.773196\n",
      "Epoch 29118 - Train Loss: 0.071388, Train Acc: 0.885897 | Val Loss: 0.109510, Val Acc: 0.773196\n",
      "Epoch 29119 - Train Loss: 0.071386, Train Acc: 0.885897 | Val Loss: 0.109509, Val Acc: 0.773196\n",
      "Epoch 29120 - Train Loss: 0.071385, Train Acc: 0.885897 | Val Loss: 0.109509, Val Acc: 0.773196\n",
      "Epoch 29121 - Train Loss: 0.071384, Train Acc: 0.885897 | Val Loss: 0.109509, Val Acc: 0.773196\n",
      "Epoch 29122 - Train Loss: 0.071383, Train Acc: 0.885897 | Val Loss: 0.109508, Val Acc: 0.773196\n",
      "Epoch 29123 - Train Loss: 0.071381, Train Acc: 0.885897 | Val Loss: 0.109508, Val Acc: 0.773196\n",
      "Epoch 29124 - Train Loss: 0.071380, Train Acc: 0.885897 | Val Loss: 0.109508, Val Acc: 0.773196\n",
      "Epoch 29125 - Train Loss: 0.071379, Train Acc: 0.885897 | Val Loss: 0.109508, Val Acc: 0.773196\n",
      "Epoch 29126 - Train Loss: 0.071377, Train Acc: 0.885897 | Val Loss: 0.109507, Val Acc: 0.773196\n",
      "Epoch 29127 - Train Loss: 0.071376, Train Acc: 0.885897 | Val Loss: 0.109507, Val Acc: 0.773196\n",
      "Epoch 29128 - Train Loss: 0.071375, Train Acc: 0.885897 | Val Loss: 0.109507, Val Acc: 0.773196\n",
      "Epoch 29129 - Train Loss: 0.071374, Train Acc: 0.885897 | Val Loss: 0.109506, Val Acc: 0.773196\n",
      "Epoch 29130 - Train Loss: 0.071372, Train Acc: 0.885897 | Val Loss: 0.109506, Val Acc: 0.773196\n",
      "Epoch 29131 - Train Loss: 0.071371, Train Acc: 0.885897 | Val Loss: 0.109506, Val Acc: 0.773196\n",
      "Epoch 29132 - Train Loss: 0.071370, Train Acc: 0.885897 | Val Loss: 0.109505, Val Acc: 0.773196\n",
      "Epoch 29133 - Train Loss: 0.071369, Train Acc: 0.885897 | Val Loss: 0.109505, Val Acc: 0.773196\n",
      "Epoch 29134 - Train Loss: 0.071367, Train Acc: 0.885897 | Val Loss: 0.109505, Val Acc: 0.773196\n",
      "Epoch 29135 - Train Loss: 0.071366, Train Acc: 0.885897 | Val Loss: 0.109505, Val Acc: 0.773196\n",
      "Epoch 29136 - Train Loss: 0.071365, Train Acc: 0.885897 | Val Loss: 0.109504, Val Acc: 0.773196\n",
      "Epoch 29137 - Train Loss: 0.071363, Train Acc: 0.885897 | Val Loss: 0.109504, Val Acc: 0.773196\n",
      "Epoch 29138 - Train Loss: 0.071362, Train Acc: 0.885897 | Val Loss: 0.109504, Val Acc: 0.773196\n",
      "Epoch 29139 - Train Loss: 0.071361, Train Acc: 0.885897 | Val Loss: 0.109503, Val Acc: 0.773196\n",
      "Epoch 29140 - Train Loss: 0.071360, Train Acc: 0.885897 | Val Loss: 0.109503, Val Acc: 0.773196\n",
      "Epoch 29141 - Train Loss: 0.071358, Train Acc: 0.885897 | Val Loss: 0.109503, Val Acc: 0.773196\n",
      "Epoch 29142 - Train Loss: 0.071357, Train Acc: 0.885897 | Val Loss: 0.109503, Val Acc: 0.773196\n",
      "Epoch 29143 - Train Loss: 0.071356, Train Acc: 0.885897 | Val Loss: 0.109502, Val Acc: 0.773196\n",
      "Epoch 29144 - Train Loss: 0.071355, Train Acc: 0.885897 | Val Loss: 0.109502, Val Acc: 0.773196\n",
      "Epoch 29145 - Train Loss: 0.071353, Train Acc: 0.885897 | Val Loss: 0.109502, Val Acc: 0.773196\n",
      "Epoch 29146 - Train Loss: 0.071352, Train Acc: 0.885897 | Val Loss: 0.109501, Val Acc: 0.773196\n",
      "Epoch 29147 - Train Loss: 0.071351, Train Acc: 0.885897 | Val Loss: 0.109501, Val Acc: 0.773196\n",
      "Epoch 29148 - Train Loss: 0.071350, Train Acc: 0.885897 | Val Loss: 0.109501, Val Acc: 0.773196\n",
      "Epoch 29149 - Train Loss: 0.071348, Train Acc: 0.885897 | Val Loss: 0.109501, Val Acc: 0.773196\n",
      "Epoch 29150 - Train Loss: 0.071347, Train Acc: 0.885897 | Val Loss: 0.109500, Val Acc: 0.773196\n",
      "Epoch 29151 - Train Loss: 0.071346, Train Acc: 0.885897 | Val Loss: 0.109500, Val Acc: 0.773196\n",
      "Epoch 29152 - Train Loss: 0.071344, Train Acc: 0.885897 | Val Loss: 0.109500, Val Acc: 0.773196\n",
      "Epoch 29153 - Train Loss: 0.071343, Train Acc: 0.885897 | Val Loss: 0.109499, Val Acc: 0.773196\n",
      "Epoch 29154 - Train Loss: 0.071342, Train Acc: 0.885897 | Val Loss: 0.109499, Val Acc: 0.773196\n",
      "Epoch 29155 - Train Loss: 0.071341, Train Acc: 0.885897 | Val Loss: 0.109499, Val Acc: 0.773196\n",
      "Epoch 29156 - Train Loss: 0.071339, Train Acc: 0.885897 | Val Loss: 0.109499, Val Acc: 0.773196\n",
      "Epoch 29157 - Train Loss: 0.071338, Train Acc: 0.885897 | Val Loss: 0.109498, Val Acc: 0.773196\n",
      "Epoch 29158 - Train Loss: 0.071337, Train Acc: 0.885897 | Val Loss: 0.109498, Val Acc: 0.773196\n",
      "Epoch 29159 - Train Loss: 0.071336, Train Acc: 0.885897 | Val Loss: 0.109498, Val Acc: 0.773196\n",
      "Epoch 29160 - Train Loss: 0.071334, Train Acc: 0.885897 | Val Loss: 0.109497, Val Acc: 0.773196\n",
      "Epoch 29161 - Train Loss: 0.071333, Train Acc: 0.885897 | Val Loss: 0.109497, Val Acc: 0.773196\n",
      "Epoch 29162 - Train Loss: 0.071332, Train Acc: 0.885897 | Val Loss: 0.109497, Val Acc: 0.773196\n",
      "Epoch 29163 - Train Loss: 0.071330, Train Acc: 0.885897 | Val Loss: 0.109496, Val Acc: 0.773196\n",
      "Epoch 29164 - Train Loss: 0.071329, Train Acc: 0.885897 | Val Loss: 0.109496, Val Acc: 0.773196\n",
      "Epoch 29165 - Train Loss: 0.071328, Train Acc: 0.885897 | Val Loss: 0.109496, Val Acc: 0.773196\n",
      "Epoch 29166 - Train Loss: 0.071327, Train Acc: 0.885897 | Val Loss: 0.109496, Val Acc: 0.773196\n",
      "Epoch 29167 - Train Loss: 0.071325, Train Acc: 0.885897 | Val Loss: 0.109495, Val Acc: 0.773196\n",
      "Epoch 29168 - Train Loss: 0.071324, Train Acc: 0.885897 | Val Loss: 0.109495, Val Acc: 0.773196\n",
      "Epoch 29169 - Train Loss: 0.071323, Train Acc: 0.885897 | Val Loss: 0.109495, Val Acc: 0.773196\n",
      "Epoch 29170 - Train Loss: 0.071322, Train Acc: 0.885897 | Val Loss: 0.109494, Val Acc: 0.773196\n",
      "Epoch 29171 - Train Loss: 0.071320, Train Acc: 0.885897 | Val Loss: 0.109494, Val Acc: 0.773196\n",
      "Epoch 29172 - Train Loss: 0.071319, Train Acc: 0.885897 | Val Loss: 0.109494, Val Acc: 0.773196\n",
      "Epoch 29173 - Train Loss: 0.071318, Train Acc: 0.885897 | Val Loss: 0.109494, Val Acc: 0.773196\n",
      "Epoch 29174 - Train Loss: 0.071317, Train Acc: 0.885897 | Val Loss: 0.109493, Val Acc: 0.773196\n",
      "Epoch 29175 - Train Loss: 0.071315, Train Acc: 0.885897 | Val Loss: 0.109493, Val Acc: 0.773196\n",
      "Epoch 29176 - Train Loss: 0.071314, Train Acc: 0.885897 | Val Loss: 0.109493, Val Acc: 0.773196\n",
      "Epoch 29177 - Train Loss: 0.071313, Train Acc: 0.885897 | Val Loss: 0.109493, Val Acc: 0.773196\n",
      "Epoch 29178 - Train Loss: 0.071311, Train Acc: 0.885897 | Val Loss: 0.109492, Val Acc: 0.773196\n",
      "Epoch 29179 - Train Loss: 0.071310, Train Acc: 0.885897 | Val Loss: 0.109492, Val Acc: 0.773196\n",
      "Epoch 29180 - Train Loss: 0.071309, Train Acc: 0.885897 | Val Loss: 0.109492, Val Acc: 0.773196\n",
      "Epoch 29181 - Train Loss: 0.071308, Train Acc: 0.885897 | Val Loss: 0.109491, Val Acc: 0.773196\n",
      "Epoch 29182 - Train Loss: 0.071306, Train Acc: 0.885897 | Val Loss: 0.109491, Val Acc: 0.773196\n",
      "Epoch 29183 - Train Loss: 0.071305, Train Acc: 0.885897 | Val Loss: 0.109491, Val Acc: 0.773196\n",
      "Epoch 29184 - Train Loss: 0.071304, Train Acc: 0.885897 | Val Loss: 0.109490, Val Acc: 0.773196\n",
      "Epoch 29185 - Train Loss: 0.071303, Train Acc: 0.885897 | Val Loss: 0.109490, Val Acc: 0.773196\n",
      "Epoch 29186 - Train Loss: 0.071301, Train Acc: 0.885897 | Val Loss: 0.109490, Val Acc: 0.773196\n",
      "Epoch 29187 - Train Loss: 0.071300, Train Acc: 0.885897 | Val Loss: 0.109490, Val Acc: 0.773196\n",
      "Epoch 29188 - Train Loss: 0.071299, Train Acc: 0.885897 | Val Loss: 0.109489, Val Acc: 0.773196\n",
      "Epoch 29189 - Train Loss: 0.071298, Train Acc: 0.885897 | Val Loss: 0.109489, Val Acc: 0.773196\n",
      "Epoch 29190 - Train Loss: 0.071296, Train Acc: 0.885897 | Val Loss: 0.109489, Val Acc: 0.773196\n",
      "Epoch 29191 - Train Loss: 0.071295, Train Acc: 0.885897 | Val Loss: 0.109488, Val Acc: 0.773196\n",
      "Epoch 29192 - Train Loss: 0.071294, Train Acc: 0.885897 | Val Loss: 0.109488, Val Acc: 0.773196\n",
      "Epoch 29193 - Train Loss: 0.071293, Train Acc: 0.885897 | Val Loss: 0.109488, Val Acc: 0.773196\n",
      "Epoch 29194 - Train Loss: 0.071291, Train Acc: 0.885897 | Val Loss: 0.109488, Val Acc: 0.773196\n",
      "Epoch 29195 - Train Loss: 0.071290, Train Acc: 0.885897 | Val Loss: 0.109487, Val Acc: 0.773196\n",
      "Epoch 29196 - Train Loss: 0.071289, Train Acc: 0.885897 | Val Loss: 0.109487, Val Acc: 0.773196\n",
      "Epoch 29197 - Train Loss: 0.071287, Train Acc: 0.885897 | Val Loss: 0.109487, Val Acc: 0.773196\n",
      "Epoch 29198 - Train Loss: 0.071286, Train Acc: 0.885897 | Val Loss: 0.109486, Val Acc: 0.773196\n",
      "Epoch 29199 - Train Loss: 0.071285, Train Acc: 0.885897 | Val Loss: 0.109486, Val Acc: 0.773196\n",
      "Epoch 29200 - Train Loss: 0.071284, Train Acc: 0.885897 | Val Loss: 0.109486, Val Acc: 0.773196\n",
      "Epoch 29201 - Train Loss: 0.071282, Train Acc: 0.885897 | Val Loss: 0.109485, Val Acc: 0.773196\n",
      "Epoch 29202 - Train Loss: 0.071281, Train Acc: 0.885897 | Val Loss: 0.109485, Val Acc: 0.773196\n",
      "Epoch 29203 - Train Loss: 0.071280, Train Acc: 0.885897 | Val Loss: 0.109485, Val Acc: 0.773196\n",
      "Epoch 29204 - Train Loss: 0.071279, Train Acc: 0.885897 | Val Loss: 0.109485, Val Acc: 0.773196\n",
      "Epoch 29205 - Train Loss: 0.071277, Train Acc: 0.885897 | Val Loss: 0.109484, Val Acc: 0.773196\n",
      "Epoch 29206 - Train Loss: 0.071276, Train Acc: 0.885897 | Val Loss: 0.109484, Val Acc: 0.773196\n",
      "Epoch 29207 - Train Loss: 0.071275, Train Acc: 0.885897 | Val Loss: 0.109484, Val Acc: 0.773196\n",
      "Epoch 29208 - Train Loss: 0.071274, Train Acc: 0.885897 | Val Loss: 0.109483, Val Acc: 0.773196\n",
      "Epoch 29209 - Train Loss: 0.071272, Train Acc: 0.885897 | Val Loss: 0.109483, Val Acc: 0.773196\n",
      "Epoch 29210 - Train Loss: 0.071271, Train Acc: 0.885897 | Val Loss: 0.109483, Val Acc: 0.773196\n",
      "Epoch 29211 - Train Loss: 0.071270, Train Acc: 0.885897 | Val Loss: 0.109483, Val Acc: 0.773196\n",
      "Epoch 29212 - Train Loss: 0.071268, Train Acc: 0.885897 | Val Loss: 0.109482, Val Acc: 0.773196\n",
      "Epoch 29213 - Train Loss: 0.071267, Train Acc: 0.885897 | Val Loss: 0.109482, Val Acc: 0.773196\n",
      "Epoch 29214 - Train Loss: 0.071266, Train Acc: 0.885897 | Val Loss: 0.109482, Val Acc: 0.773196\n",
      "Epoch 29215 - Train Loss: 0.071265, Train Acc: 0.885897 | Val Loss: 0.109481, Val Acc: 0.773196\n",
      "Epoch 29216 - Train Loss: 0.071263, Train Acc: 0.885897 | Val Loss: 0.109481, Val Acc: 0.773196\n",
      "Epoch 29217 - Train Loss: 0.071262, Train Acc: 0.885897 | Val Loss: 0.109481, Val Acc: 0.773196\n",
      "Epoch 29218 - Train Loss: 0.071261, Train Acc: 0.885897 | Val Loss: 0.109481, Val Acc: 0.773196\n",
      "Epoch 29219 - Train Loss: 0.071260, Train Acc: 0.885897 | Val Loss: 0.109480, Val Acc: 0.773196\n",
      "Epoch 29220 - Train Loss: 0.071258, Train Acc: 0.885897 | Val Loss: 0.109480, Val Acc: 0.773196\n",
      "Epoch 29221 - Train Loss: 0.071257, Train Acc: 0.885897 | Val Loss: 0.109480, Val Acc: 0.773196\n",
      "Epoch 29222 - Train Loss: 0.071256, Train Acc: 0.885897 | Val Loss: 0.109480, Val Acc: 0.773196\n",
      "Epoch 29223 - Train Loss: 0.071255, Train Acc: 0.885897 | Val Loss: 0.109479, Val Acc: 0.773196\n",
      "Epoch 29224 - Train Loss: 0.071253, Train Acc: 0.885897 | Val Loss: 0.109479, Val Acc: 0.773196\n",
      "Epoch 29225 - Train Loss: 0.071252, Train Acc: 0.885897 | Val Loss: 0.109479, Val Acc: 0.773196\n",
      "Epoch 29226 - Train Loss: 0.071251, Train Acc: 0.885897 | Val Loss: 0.109478, Val Acc: 0.773196\n",
      "Epoch 29227 - Train Loss: 0.071250, Train Acc: 0.885897 | Val Loss: 0.109478, Val Acc: 0.773196\n",
      "Epoch 29228 - Train Loss: 0.071248, Train Acc: 0.885897 | Val Loss: 0.109478, Val Acc: 0.773196\n",
      "Epoch 29229 - Train Loss: 0.071247, Train Acc: 0.885897 | Val Loss: 0.109478, Val Acc: 0.773196\n",
      "Epoch 29230 - Train Loss: 0.071246, Train Acc: 0.885897 | Val Loss: 0.109477, Val Acc: 0.773196\n",
      "Epoch 29231 - Train Loss: 0.071244, Train Acc: 0.885897 | Val Loss: 0.109477, Val Acc: 0.773196\n",
      "Epoch 29232 - Train Loss: 0.071243, Train Acc: 0.885897 | Val Loss: 0.109477, Val Acc: 0.773196\n",
      "Epoch 29233 - Train Loss: 0.071242, Train Acc: 0.885897 | Val Loss: 0.109476, Val Acc: 0.773196\n",
      "Epoch 29234 - Train Loss: 0.071241, Train Acc: 0.885897 | Val Loss: 0.109476, Val Acc: 0.773196\n",
      "Epoch 29235 - Train Loss: 0.071239, Train Acc: 0.885897 | Val Loss: 0.109476, Val Acc: 0.773196\n",
      "Epoch 29236 - Train Loss: 0.071238, Train Acc: 0.885897 | Val Loss: 0.109476, Val Acc: 0.773196\n",
      "Epoch 29237 - Train Loss: 0.071237, Train Acc: 0.885897 | Val Loss: 0.109475, Val Acc: 0.773196\n",
      "Epoch 29238 - Train Loss: 0.071236, Train Acc: 0.885897 | Val Loss: 0.109475, Val Acc: 0.773196\n",
      "Epoch 29239 - Train Loss: 0.071234, Train Acc: 0.885897 | Val Loss: 0.109475, Val Acc: 0.773196\n",
      "Epoch 29240 - Train Loss: 0.071233, Train Acc: 0.885897 | Val Loss: 0.109474, Val Acc: 0.773196\n",
      "Epoch 29241 - Train Loss: 0.071232, Train Acc: 0.885897 | Val Loss: 0.109474, Val Acc: 0.773196\n",
      "Epoch 29242 - Train Loss: 0.071231, Train Acc: 0.885897 | Val Loss: 0.109474, Val Acc: 0.773196\n",
      "Epoch 29243 - Train Loss: 0.071229, Train Acc: 0.885897 | Val Loss: 0.109474, Val Acc: 0.773196\n",
      "Epoch 29244 - Train Loss: 0.071228, Train Acc: 0.885897 | Val Loss: 0.109473, Val Acc: 0.773196\n",
      "Epoch 29245 - Train Loss: 0.071227, Train Acc: 0.885897 | Val Loss: 0.109473, Val Acc: 0.773196\n",
      "Epoch 29246 - Train Loss: 0.071226, Train Acc: 0.885897 | Val Loss: 0.109473, Val Acc: 0.773196\n",
      "Epoch 29247 - Train Loss: 0.071224, Train Acc: 0.885897 | Val Loss: 0.109472, Val Acc: 0.773196\n",
      "Epoch 29248 - Train Loss: 0.071223, Train Acc: 0.885897 | Val Loss: 0.109472, Val Acc: 0.773196\n",
      "Epoch 29249 - Train Loss: 0.071222, Train Acc: 0.885897 | Val Loss: 0.109472, Val Acc: 0.773196\n",
      "Epoch 29250 - Train Loss: 0.071220, Train Acc: 0.885897 | Val Loss: 0.109472, Val Acc: 0.773196\n",
      "Epoch 29251 - Train Loss: 0.071219, Train Acc: 0.885897 | Val Loss: 0.109471, Val Acc: 0.773196\n",
      "Epoch 29252 - Train Loss: 0.071218, Train Acc: 0.885897 | Val Loss: 0.109471, Val Acc: 0.773196\n",
      "Epoch 29253 - Train Loss: 0.071217, Train Acc: 0.885897 | Val Loss: 0.109471, Val Acc: 0.773196\n",
      "Epoch 29254 - Train Loss: 0.071215, Train Acc: 0.885897 | Val Loss: 0.109470, Val Acc: 0.773196\n",
      "Epoch 29255 - Train Loss: 0.071214, Train Acc: 0.885897 | Val Loss: 0.109470, Val Acc: 0.773196\n",
      "Epoch 29256 - Train Loss: 0.071213, Train Acc: 0.885897 | Val Loss: 0.109470, Val Acc: 0.773196\n",
      "Epoch 29257 - Train Loss: 0.071212, Train Acc: 0.885897 | Val Loss: 0.109469, Val Acc: 0.773196\n",
      "Epoch 29258 - Train Loss: 0.071210, Train Acc: 0.885897 | Val Loss: 0.109469, Val Acc: 0.773196\n",
      "Epoch 29259 - Train Loss: 0.071209, Train Acc: 0.885897 | Val Loss: 0.109469, Val Acc: 0.773196\n",
      "Epoch 29260 - Train Loss: 0.071208, Train Acc: 0.885897 | Val Loss: 0.109469, Val Acc: 0.773196\n",
      "Epoch 29261 - Train Loss: 0.071207, Train Acc: 0.885897 | Val Loss: 0.109468, Val Acc: 0.773196\n",
      "Epoch 29262 - Train Loss: 0.071205, Train Acc: 0.885897 | Val Loss: 0.109468, Val Acc: 0.773196\n",
      "Epoch 29263 - Train Loss: 0.071204, Train Acc: 0.885897 | Val Loss: 0.109468, Val Acc: 0.773196\n",
      "Epoch 29264 - Train Loss: 0.071203, Train Acc: 0.885897 | Val Loss: 0.109467, Val Acc: 0.773196\n",
      "Epoch 29265 - Train Loss: 0.071202, Train Acc: 0.885897 | Val Loss: 0.109467, Val Acc: 0.773196\n",
      "Epoch 29266 - Train Loss: 0.071200, Train Acc: 0.885897 | Val Loss: 0.109467, Val Acc: 0.773196\n",
      "Epoch 29267 - Train Loss: 0.071199, Train Acc: 0.885897 | Val Loss: 0.109467, Val Acc: 0.773196\n",
      "Epoch 29268 - Train Loss: 0.071198, Train Acc: 0.885897 | Val Loss: 0.109466, Val Acc: 0.773196\n",
      "Epoch 29269 - Train Loss: 0.071197, Train Acc: 0.885897 | Val Loss: 0.109466, Val Acc: 0.773196\n",
      "Epoch 29270 - Train Loss: 0.071195, Train Acc: 0.885897 | Val Loss: 0.109466, Val Acc: 0.773196\n",
      "Epoch 29271 - Train Loss: 0.071194, Train Acc: 0.885897 | Val Loss: 0.109465, Val Acc: 0.773196\n",
      "Epoch 29272 - Train Loss: 0.071193, Train Acc: 0.885897 | Val Loss: 0.109465, Val Acc: 0.773196\n",
      "Epoch 29273 - Train Loss: 0.071191, Train Acc: 0.885897 | Val Loss: 0.109465, Val Acc: 0.773196\n",
      "Epoch 29274 - Train Loss: 0.071190, Train Acc: 0.885897 | Val Loss: 0.109465, Val Acc: 0.773196\n",
      "Epoch 29275 - Train Loss: 0.071189, Train Acc: 0.885897 | Val Loss: 0.109464, Val Acc: 0.773196\n",
      "Epoch 29276 - Train Loss: 0.071188, Train Acc: 0.885897 | Val Loss: 0.109464, Val Acc: 0.773196\n",
      "Epoch 29277 - Train Loss: 0.071186, Train Acc: 0.885897 | Val Loss: 0.109464, Val Acc: 0.773196\n",
      "Epoch 29278 - Train Loss: 0.071185, Train Acc: 0.885897 | Val Loss: 0.109464, Val Acc: 0.773196\n",
      "Epoch 29279 - Train Loss: 0.071184, Train Acc: 0.885897 | Val Loss: 0.109463, Val Acc: 0.773196\n",
      "Epoch 29280 - Train Loss: 0.071183, Train Acc: 0.885897 | Val Loss: 0.109463, Val Acc: 0.773196\n",
      "Epoch 29281 - Train Loss: 0.071181, Train Acc: 0.885897 | Val Loss: 0.109463, Val Acc: 0.773196\n",
      "Epoch 29282 - Train Loss: 0.071180, Train Acc: 0.885897 | Val Loss: 0.109462, Val Acc: 0.773196\n",
      "Epoch 29283 - Train Loss: 0.071179, Train Acc: 0.885897 | Val Loss: 0.109462, Val Acc: 0.783505\n",
      "Epoch 29284 - Train Loss: 0.071178, Train Acc: 0.885897 | Val Loss: 0.109462, Val Acc: 0.783505\n",
      "Epoch 29285 - Train Loss: 0.071176, Train Acc: 0.885897 | Val Loss: 0.109462, Val Acc: 0.783505\n",
      "Epoch 29286 - Train Loss: 0.071175, Train Acc: 0.885897 | Val Loss: 0.109461, Val Acc: 0.783505\n",
      "Epoch 29287 - Train Loss: 0.071174, Train Acc: 0.885897 | Val Loss: 0.109461, Val Acc: 0.783505\n",
      "Epoch 29288 - Train Loss: 0.071173, Train Acc: 0.885897 | Val Loss: 0.109461, Val Acc: 0.783505\n",
      "Epoch 29289 - Train Loss: 0.071171, Train Acc: 0.885897 | Val Loss: 0.109460, Val Acc: 0.783505\n",
      "Epoch 29290 - Train Loss: 0.071170, Train Acc: 0.885897 | Val Loss: 0.109460, Val Acc: 0.783505\n",
      "Epoch 29291 - Train Loss: 0.071169, Train Acc: 0.885897 | Val Loss: 0.109460, Val Acc: 0.783505\n",
      "Epoch 29292 - Train Loss: 0.071168, Train Acc: 0.885897 | Val Loss: 0.109460, Val Acc: 0.783505\n",
      "Epoch 29293 - Train Loss: 0.071166, Train Acc: 0.885897 | Val Loss: 0.109459, Val Acc: 0.783505\n",
      "Epoch 29294 - Train Loss: 0.071165, Train Acc: 0.885897 | Val Loss: 0.109459, Val Acc: 0.783505\n",
      "Epoch 29295 - Train Loss: 0.071164, Train Acc: 0.885897 | Val Loss: 0.109459, Val Acc: 0.783505\n",
      "Epoch 29296 - Train Loss: 0.071163, Train Acc: 0.885897 | Val Loss: 0.109458, Val Acc: 0.783505\n",
      "Epoch 29297 - Train Loss: 0.071161, Train Acc: 0.885897 | Val Loss: 0.109458, Val Acc: 0.783505\n",
      "Epoch 29298 - Train Loss: 0.071160, Train Acc: 0.885897 | Val Loss: 0.109458, Val Acc: 0.783505\n",
      "Epoch 29299 - Train Loss: 0.071159, Train Acc: 0.885897 | Val Loss: 0.109458, Val Acc: 0.783505\n",
      "Epoch 29300 - Train Loss: 0.071157, Train Acc: 0.885897 | Val Loss: 0.109457, Val Acc: 0.783505\n",
      "Epoch 29301 - Train Loss: 0.071156, Train Acc: 0.885897 | Val Loss: 0.109457, Val Acc: 0.783505\n",
      "Epoch 29302 - Train Loss: 0.071155, Train Acc: 0.885897 | Val Loss: 0.109457, Val Acc: 0.783505\n",
      "Epoch 29303 - Train Loss: 0.071154, Train Acc: 0.885897 | Val Loss: 0.109456, Val Acc: 0.783505\n",
      "Epoch 29304 - Train Loss: 0.071152, Train Acc: 0.885897 | Val Loss: 0.109456, Val Acc: 0.783505\n",
      "Epoch 29305 - Train Loss: 0.071151, Train Acc: 0.885897 | Val Loss: 0.109456, Val Acc: 0.783505\n",
      "Epoch 29306 - Train Loss: 0.071150, Train Acc: 0.885897 | Val Loss: 0.109456, Val Acc: 0.783505\n",
      "Epoch 29307 - Train Loss: 0.071149, Train Acc: 0.885897 | Val Loss: 0.109455, Val Acc: 0.783505\n",
      "Epoch 29308 - Train Loss: 0.071147, Train Acc: 0.885897 | Val Loss: 0.109455, Val Acc: 0.783505\n",
      "Epoch 29309 - Train Loss: 0.071146, Train Acc: 0.885897 | Val Loss: 0.109455, Val Acc: 0.783505\n",
      "Epoch 29310 - Train Loss: 0.071145, Train Acc: 0.885897 | Val Loss: 0.109454, Val Acc: 0.783505\n",
      "Epoch 29311 - Train Loss: 0.071144, Train Acc: 0.885897 | Val Loss: 0.109454, Val Acc: 0.783505\n",
      "Epoch 29312 - Train Loss: 0.071142, Train Acc: 0.885897 | Val Loss: 0.109454, Val Acc: 0.783505\n",
      "Epoch 29313 - Train Loss: 0.071141, Train Acc: 0.885897 | Val Loss: 0.109454, Val Acc: 0.783505\n",
      "Epoch 29314 - Train Loss: 0.071140, Train Acc: 0.885897 | Val Loss: 0.109453, Val Acc: 0.783505\n",
      "Epoch 29315 - Train Loss: 0.071139, Train Acc: 0.885897 | Val Loss: 0.109453, Val Acc: 0.783505\n",
      "Epoch 29316 - Train Loss: 0.071137, Train Acc: 0.885897 | Val Loss: 0.109453, Val Acc: 0.783505\n",
      "Epoch 29317 - Train Loss: 0.071136, Train Acc: 0.885897 | Val Loss: 0.109452, Val Acc: 0.783505\n",
      "Epoch 29318 - Train Loss: 0.071135, Train Acc: 0.885897 | Val Loss: 0.109452, Val Acc: 0.783505\n",
      "Epoch 29319 - Train Loss: 0.071134, Train Acc: 0.885897 | Val Loss: 0.109452, Val Acc: 0.783505\n",
      "Epoch 29320 - Train Loss: 0.071132, Train Acc: 0.885897 | Val Loss: 0.109452, Val Acc: 0.783505\n",
      "Epoch 29321 - Train Loss: 0.071131, Train Acc: 0.885897 | Val Loss: 0.109451, Val Acc: 0.783505\n",
      "Epoch 29322 - Train Loss: 0.071130, Train Acc: 0.885897 | Val Loss: 0.109451, Val Acc: 0.783505\n",
      "Epoch 29323 - Train Loss: 0.071129, Train Acc: 0.885897 | Val Loss: 0.109451, Val Acc: 0.783505\n",
      "Epoch 29324 - Train Loss: 0.071127, Train Acc: 0.885897 | Val Loss: 0.109450, Val Acc: 0.783505\n",
      "Epoch 29325 - Train Loss: 0.071126, Train Acc: 0.885897 | Val Loss: 0.109450, Val Acc: 0.783505\n",
      "Epoch 29326 - Train Loss: 0.071125, Train Acc: 0.885897 | Val Loss: 0.109450, Val Acc: 0.783505\n",
      "Epoch 29327 - Train Loss: 0.071124, Train Acc: 0.885897 | Val Loss: 0.109450, Val Acc: 0.783505\n",
      "Epoch 29328 - Train Loss: 0.071122, Train Acc: 0.885897 | Val Loss: 0.109449, Val Acc: 0.783505\n",
      "Epoch 29329 - Train Loss: 0.071121, Train Acc: 0.885897 | Val Loss: 0.109449, Val Acc: 0.783505\n",
      "Epoch 29330 - Train Loss: 0.071120, Train Acc: 0.885897 | Val Loss: 0.109449, Val Acc: 0.783505\n",
      "Epoch 29331 - Train Loss: 0.071118, Train Acc: 0.885897 | Val Loss: 0.109448, Val Acc: 0.783505\n",
      "Epoch 29332 - Train Loss: 0.071117, Train Acc: 0.885897 | Val Loss: 0.109448, Val Acc: 0.783505\n",
      "Epoch 29333 - Train Loss: 0.071116, Train Acc: 0.885897 | Val Loss: 0.109448, Val Acc: 0.783505\n",
      "Epoch 29334 - Train Loss: 0.071115, Train Acc: 0.885897 | Val Loss: 0.109448, Val Acc: 0.783505\n",
      "Epoch 29335 - Train Loss: 0.071113, Train Acc: 0.885897 | Val Loss: 0.109447, Val Acc: 0.783505\n",
      "Epoch 29336 - Train Loss: 0.071112, Train Acc: 0.885897 | Val Loss: 0.109447, Val Acc: 0.783505\n",
      "Epoch 29337 - Train Loss: 0.071111, Train Acc: 0.885897 | Val Loss: 0.109447, Val Acc: 0.783505\n",
      "Epoch 29338 - Train Loss: 0.071110, Train Acc: 0.885897 | Val Loss: 0.109446, Val Acc: 0.783505\n",
      "Epoch 29339 - Train Loss: 0.071108, Train Acc: 0.885897 | Val Loss: 0.109446, Val Acc: 0.783505\n",
      "Epoch 29340 - Train Loss: 0.071107, Train Acc: 0.885897 | Val Loss: 0.109446, Val Acc: 0.783505\n",
      "Epoch 29341 - Train Loss: 0.071106, Train Acc: 0.885897 | Val Loss: 0.109446, Val Acc: 0.783505\n",
      "Epoch 29342 - Train Loss: 0.071105, Train Acc: 0.885897 | Val Loss: 0.109445, Val Acc: 0.783505\n",
      "Epoch 29343 - Train Loss: 0.071103, Train Acc: 0.885897 | Val Loss: 0.109445, Val Acc: 0.783505\n",
      "Epoch 29344 - Train Loss: 0.071102, Train Acc: 0.885897 | Val Loss: 0.109445, Val Acc: 0.783505\n",
      "Epoch 29345 - Train Loss: 0.071101, Train Acc: 0.885897 | Val Loss: 0.109445, Val Acc: 0.783505\n",
      "Epoch 29346 - Train Loss: 0.071100, Train Acc: 0.885897 | Val Loss: 0.109444, Val Acc: 0.783505\n",
      "Epoch 29347 - Train Loss: 0.071098, Train Acc: 0.885897 | Val Loss: 0.109444, Val Acc: 0.783505\n",
      "Epoch 29348 - Train Loss: 0.071097, Train Acc: 0.885897 | Val Loss: 0.109444, Val Acc: 0.783505\n",
      "Epoch 29349 - Train Loss: 0.071096, Train Acc: 0.885897 | Val Loss: 0.109443, Val Acc: 0.783505\n",
      "Epoch 29350 - Train Loss: 0.071095, Train Acc: 0.885897 | Val Loss: 0.109443, Val Acc: 0.783505\n",
      "Epoch 29351 - Train Loss: 0.071093, Train Acc: 0.885897 | Val Loss: 0.109443, Val Acc: 0.783505\n",
      "Epoch 29352 - Train Loss: 0.071092, Train Acc: 0.885897 | Val Loss: 0.109443, Val Acc: 0.783505\n",
      "Epoch 29353 - Train Loss: 0.071091, Train Acc: 0.885897 | Val Loss: 0.109442, Val Acc: 0.783505\n",
      "Epoch 29354 - Train Loss: 0.071090, Train Acc: 0.885897 | Val Loss: 0.109442, Val Acc: 0.783505\n",
      "Epoch 29355 - Train Loss: 0.071088, Train Acc: 0.885897 | Val Loss: 0.109442, Val Acc: 0.783505\n",
      "Epoch 29356 - Train Loss: 0.071087, Train Acc: 0.885897 | Val Loss: 0.109442, Val Acc: 0.783505\n",
      "Epoch 29357 - Train Loss: 0.071086, Train Acc: 0.885897 | Val Loss: 0.109441, Val Acc: 0.783505\n",
      "Epoch 29358 - Train Loss: 0.071085, Train Acc: 0.885897 | Val Loss: 0.109441, Val Acc: 0.783505\n",
      "Epoch 29359 - Train Loss: 0.071083, Train Acc: 0.885897 | Val Loss: 0.109441, Val Acc: 0.783505\n",
      "Epoch 29360 - Train Loss: 0.071082, Train Acc: 0.885897 | Val Loss: 0.109440, Val Acc: 0.783505\n",
      "Epoch 29361 - Train Loss: 0.071081, Train Acc: 0.885897 | Val Loss: 0.109440, Val Acc: 0.783505\n",
      "Epoch 29362 - Train Loss: 0.071080, Train Acc: 0.885897 | Val Loss: 0.109440, Val Acc: 0.783505\n",
      "Epoch 29363 - Train Loss: 0.071078, Train Acc: 0.885897 | Val Loss: 0.109440, Val Acc: 0.783505\n",
      "Epoch 29364 - Train Loss: 0.071077, Train Acc: 0.885897 | Val Loss: 0.109439, Val Acc: 0.783505\n",
      "Epoch 29365 - Train Loss: 0.071076, Train Acc: 0.885897 | Val Loss: 0.109439, Val Acc: 0.783505\n",
      "Epoch 29366 - Train Loss: 0.071075, Train Acc: 0.885897 | Val Loss: 0.109439, Val Acc: 0.783505\n",
      "Epoch 29367 - Train Loss: 0.071073, Train Acc: 0.885897 | Val Loss: 0.109438, Val Acc: 0.783505\n",
      "Epoch 29368 - Train Loss: 0.071072, Train Acc: 0.885897 | Val Loss: 0.109438, Val Acc: 0.783505\n",
      "Epoch 29369 - Train Loss: 0.071071, Train Acc: 0.885897 | Val Loss: 0.109438, Val Acc: 0.783505\n",
      "Epoch 29370 - Train Loss: 0.071070, Train Acc: 0.885897 | Val Loss: 0.109437, Val Acc: 0.783505\n",
      "Epoch 29371 - Train Loss: 0.071068, Train Acc: 0.885897 | Val Loss: 0.109437, Val Acc: 0.783505\n",
      "Epoch 29372 - Train Loss: 0.071067, Train Acc: 0.885897 | Val Loss: 0.109437, Val Acc: 0.783505\n",
      "Epoch 29373 - Train Loss: 0.071066, Train Acc: 0.885897 | Val Loss: 0.109437, Val Acc: 0.783505\n",
      "Epoch 29374 - Train Loss: 0.071064, Train Acc: 0.885897 | Val Loss: 0.109436, Val Acc: 0.783505\n",
      "Epoch 29375 - Train Loss: 0.071063, Train Acc: 0.885897 | Val Loss: 0.109436, Val Acc: 0.783505\n",
      "Epoch 29376 - Train Loss: 0.071062, Train Acc: 0.885897 | Val Loss: 0.109436, Val Acc: 0.783505\n",
      "Epoch 29377 - Train Loss: 0.071061, Train Acc: 0.885897 | Val Loss: 0.109436, Val Acc: 0.783505\n",
      "Epoch 29378 - Train Loss: 0.071059, Train Acc: 0.885897 | Val Loss: 0.109435, Val Acc: 0.783505\n",
      "Epoch 29379 - Train Loss: 0.071058, Train Acc: 0.885897 | Val Loss: 0.109435, Val Acc: 0.783505\n",
      "Epoch 29380 - Train Loss: 0.071057, Train Acc: 0.885897 | Val Loss: 0.109435, Val Acc: 0.783505\n",
      "Epoch 29381 - Train Loss: 0.071056, Train Acc: 0.885897 | Val Loss: 0.109434, Val Acc: 0.783505\n",
      "Epoch 29382 - Train Loss: 0.071054, Train Acc: 0.885897 | Val Loss: 0.109434, Val Acc: 0.783505\n",
      "Epoch 29383 - Train Loss: 0.071053, Train Acc: 0.885897 | Val Loss: 0.109434, Val Acc: 0.783505\n",
      "Epoch 29384 - Train Loss: 0.071052, Train Acc: 0.885897 | Val Loss: 0.109434, Val Acc: 0.783505\n",
      "Epoch 29385 - Train Loss: 0.071051, Train Acc: 0.885897 | Val Loss: 0.109433, Val Acc: 0.783505\n",
      "Epoch 29386 - Train Loss: 0.071049, Train Acc: 0.885897 | Val Loss: 0.109433, Val Acc: 0.783505\n",
      "Epoch 29387 - Train Loss: 0.071048, Train Acc: 0.885897 | Val Loss: 0.109433, Val Acc: 0.783505\n",
      "Epoch 29388 - Train Loss: 0.071047, Train Acc: 0.885897 | Val Loss: 0.109433, Val Acc: 0.783505\n",
      "Epoch 29389 - Train Loss: 0.071046, Train Acc: 0.885897 | Val Loss: 0.109432, Val Acc: 0.783505\n",
      "Epoch 29390 - Train Loss: 0.071044, Train Acc: 0.885897 | Val Loss: 0.109432, Val Acc: 0.783505\n",
      "Epoch 29391 - Train Loss: 0.071043, Train Acc: 0.885897 | Val Loss: 0.109432, Val Acc: 0.783505\n",
      "Epoch 29392 - Train Loss: 0.071042, Train Acc: 0.885897 | Val Loss: 0.109431, Val Acc: 0.783505\n",
      "Epoch 29393 - Train Loss: 0.071041, Train Acc: 0.885897 | Val Loss: 0.109431, Val Acc: 0.783505\n",
      "Epoch 29394 - Train Loss: 0.071039, Train Acc: 0.885897 | Val Loss: 0.109431, Val Acc: 0.783505\n",
      "Epoch 29395 - Train Loss: 0.071038, Train Acc: 0.885897 | Val Loss: 0.109430, Val Acc: 0.783505\n",
      "Epoch 29396 - Train Loss: 0.071037, Train Acc: 0.885897 | Val Loss: 0.109430, Val Acc: 0.783505\n",
      "Epoch 29397 - Train Loss: 0.071036, Train Acc: 0.885897 | Val Loss: 0.109430, Val Acc: 0.783505\n",
      "Epoch 29398 - Train Loss: 0.071034, Train Acc: 0.885897 | Val Loss: 0.109430, Val Acc: 0.783505\n",
      "Epoch 29399 - Train Loss: 0.071033, Train Acc: 0.885897 | Val Loss: 0.109429, Val Acc: 0.783505\n",
      "Epoch 29400 - Train Loss: 0.071032, Train Acc: 0.885897 | Val Loss: 0.109429, Val Acc: 0.783505\n",
      "Epoch 29401 - Train Loss: 0.071031, Train Acc: 0.885897 | Val Loss: 0.109429, Val Acc: 0.783505\n",
      "Epoch 29402 - Train Loss: 0.071029, Train Acc: 0.885897 | Val Loss: 0.109429, Val Acc: 0.783505\n",
      "Epoch 29403 - Train Loss: 0.071028, Train Acc: 0.885897 | Val Loss: 0.109428, Val Acc: 0.783505\n",
      "Epoch 29404 - Train Loss: 0.071027, Train Acc: 0.885897 | Val Loss: 0.109428, Val Acc: 0.783505\n",
      "Epoch 29405 - Train Loss: 0.071026, Train Acc: 0.885897 | Val Loss: 0.109428, Val Acc: 0.783505\n",
      "Epoch 29406 - Train Loss: 0.071024, Train Acc: 0.885897 | Val Loss: 0.109428, Val Acc: 0.783505\n",
      "Epoch 29407 - Train Loss: 0.071023, Train Acc: 0.885897 | Val Loss: 0.109427, Val Acc: 0.783505\n",
      "Epoch 29408 - Train Loss: 0.071022, Train Acc: 0.885897 | Val Loss: 0.109427, Val Acc: 0.783505\n",
      "Epoch 29409 - Train Loss: 0.071021, Train Acc: 0.885897 | Val Loss: 0.109427, Val Acc: 0.783505\n",
      "Epoch 29410 - Train Loss: 0.071019, Train Acc: 0.885897 | Val Loss: 0.109426, Val Acc: 0.783505\n",
      "Epoch 29411 - Train Loss: 0.071018, Train Acc: 0.885897 | Val Loss: 0.109426, Val Acc: 0.783505\n",
      "Epoch 29412 - Train Loss: 0.071017, Train Acc: 0.885897 | Val Loss: 0.109426, Val Acc: 0.783505\n",
      "Epoch 29413 - Train Loss: 0.071016, Train Acc: 0.885897 | Val Loss: 0.109426, Val Acc: 0.783505\n",
      "Epoch 29414 - Train Loss: 0.071014, Train Acc: 0.885897 | Val Loss: 0.109425, Val Acc: 0.783505\n",
      "Epoch 29415 - Train Loss: 0.071013, Train Acc: 0.885897 | Val Loss: 0.109425, Val Acc: 0.783505\n",
      "Epoch 29416 - Train Loss: 0.071012, Train Acc: 0.885897 | Val Loss: 0.109425, Val Acc: 0.783505\n",
      "Epoch 29417 - Train Loss: 0.071011, Train Acc: 0.885897 | Val Loss: 0.109424, Val Acc: 0.783505\n",
      "Epoch 29418 - Train Loss: 0.071009, Train Acc: 0.885897 | Val Loss: 0.109424, Val Acc: 0.783505\n",
      "Epoch 29419 - Train Loss: 0.071008, Train Acc: 0.885897 | Val Loss: 0.109424, Val Acc: 0.783505\n",
      "Epoch 29420 - Train Loss: 0.071007, Train Acc: 0.885897 | Val Loss: 0.109424, Val Acc: 0.783505\n",
      "Epoch 29421 - Train Loss: 0.071006, Train Acc: 0.885897 | Val Loss: 0.109423, Val Acc: 0.783505\n",
      "Epoch 29422 - Train Loss: 0.071004, Train Acc: 0.885897 | Val Loss: 0.109423, Val Acc: 0.783505\n",
      "Epoch 29423 - Train Loss: 0.071003, Train Acc: 0.885897 | Val Loss: 0.109423, Val Acc: 0.783505\n",
      "Epoch 29424 - Train Loss: 0.071002, Train Acc: 0.885897 | Val Loss: 0.109422, Val Acc: 0.783505\n",
      "Epoch 29425 - Train Loss: 0.071001, Train Acc: 0.885897 | Val Loss: 0.109422, Val Acc: 0.783505\n",
      "Epoch 29426 - Train Loss: 0.070999, Train Acc: 0.885897 | Val Loss: 0.109422, Val Acc: 0.783505\n",
      "Epoch 29427 - Train Loss: 0.070998, Train Acc: 0.885897 | Val Loss: 0.109422, Val Acc: 0.783505\n",
      "Epoch 29428 - Train Loss: 0.070997, Train Acc: 0.885897 | Val Loss: 0.109421, Val Acc: 0.783505\n",
      "Epoch 29429 - Train Loss: 0.070996, Train Acc: 0.885897 | Val Loss: 0.109421, Val Acc: 0.783505\n",
      "Epoch 29430 - Train Loss: 0.070994, Train Acc: 0.885897 | Val Loss: 0.109421, Val Acc: 0.783505\n",
      "Epoch 29431 - Train Loss: 0.070993, Train Acc: 0.885897 | Val Loss: 0.109421, Val Acc: 0.783505\n",
      "Epoch 29432 - Train Loss: 0.070992, Train Acc: 0.885897 | Val Loss: 0.109420, Val Acc: 0.783505\n",
      "Epoch 29433 - Train Loss: 0.070991, Train Acc: 0.885897 | Val Loss: 0.109420, Val Acc: 0.783505\n",
      "Epoch 29434 - Train Loss: 0.070989, Train Acc: 0.885897 | Val Loss: 0.109420, Val Acc: 0.783505\n",
      "Epoch 29435 - Train Loss: 0.070988, Train Acc: 0.885897 | Val Loss: 0.109419, Val Acc: 0.783505\n",
      "Epoch 29436 - Train Loss: 0.070987, Train Acc: 0.885897 | Val Loss: 0.109419, Val Acc: 0.783505\n",
      "Epoch 29437 - Train Loss: 0.070986, Train Acc: 0.885897 | Val Loss: 0.109419, Val Acc: 0.783505\n",
      "Epoch 29438 - Train Loss: 0.070984, Train Acc: 0.885897 | Val Loss: 0.109419, Val Acc: 0.783505\n",
      "Epoch 29439 - Train Loss: 0.070983, Train Acc: 0.885897 | Val Loss: 0.109418, Val Acc: 0.783505\n",
      "Epoch 29440 - Train Loss: 0.070982, Train Acc: 0.885897 | Val Loss: 0.109418, Val Acc: 0.783505\n",
      "Epoch 29441 - Train Loss: 0.070981, Train Acc: 0.885897 | Val Loss: 0.109418, Val Acc: 0.783505\n",
      "Epoch 29442 - Train Loss: 0.070979, Train Acc: 0.885897 | Val Loss: 0.109417, Val Acc: 0.783505\n",
      "Epoch 29443 - Train Loss: 0.070978, Train Acc: 0.885897 | Val Loss: 0.109417, Val Acc: 0.783505\n",
      "Epoch 29444 - Train Loss: 0.070977, Train Acc: 0.885897 | Val Loss: 0.109417, Val Acc: 0.783505\n",
      "Epoch 29445 - Train Loss: 0.070976, Train Acc: 0.885897 | Val Loss: 0.109417, Val Acc: 0.783505\n",
      "Epoch 29446 - Train Loss: 0.070974, Train Acc: 0.885897 | Val Loss: 0.109416, Val Acc: 0.783505\n",
      "Epoch 29447 - Train Loss: 0.070973, Train Acc: 0.885897 | Val Loss: 0.109416, Val Acc: 0.783505\n",
      "Epoch 29448 - Train Loss: 0.070972, Train Acc: 0.885897 | Val Loss: 0.109416, Val Acc: 0.783505\n",
      "Epoch 29449 - Train Loss: 0.070971, Train Acc: 0.885897 | Val Loss: 0.109416, Val Acc: 0.783505\n",
      "Epoch 29450 - Train Loss: 0.070969, Train Acc: 0.885897 | Val Loss: 0.109415, Val Acc: 0.783505\n",
      "Epoch 29451 - Train Loss: 0.070968, Train Acc: 0.885897 | Val Loss: 0.109415, Val Acc: 0.783505\n",
      "Epoch 29452 - Train Loss: 0.070967, Train Acc: 0.885897 | Val Loss: 0.109415, Val Acc: 0.783505\n",
      "Epoch 29453 - Train Loss: 0.070966, Train Acc: 0.885897 | Val Loss: 0.109414, Val Acc: 0.783505\n",
      "Epoch 29454 - Train Loss: 0.070964, Train Acc: 0.885897 | Val Loss: 0.109414, Val Acc: 0.783505\n",
      "Epoch 29455 - Train Loss: 0.070963, Train Acc: 0.885897 | Val Loss: 0.109414, Val Acc: 0.783505\n",
      "Epoch 29456 - Train Loss: 0.070962, Train Acc: 0.885897 | Val Loss: 0.109414, Val Acc: 0.783505\n",
      "Epoch 29457 - Train Loss: 0.070961, Train Acc: 0.885897 | Val Loss: 0.109413, Val Acc: 0.783505\n",
      "Epoch 29458 - Train Loss: 0.070959, Train Acc: 0.885897 | Val Loss: 0.109413, Val Acc: 0.783505\n",
      "Epoch 29459 - Train Loss: 0.070958, Train Acc: 0.885897 | Val Loss: 0.109413, Val Acc: 0.783505\n",
      "Epoch 29460 - Train Loss: 0.070957, Train Acc: 0.885897 | Val Loss: 0.109413, Val Acc: 0.783505\n",
      "Epoch 29461 - Train Loss: 0.070956, Train Acc: 0.885897 | Val Loss: 0.109412, Val Acc: 0.783505\n",
      "Epoch 29462 - Train Loss: 0.070954, Train Acc: 0.885897 | Val Loss: 0.109412, Val Acc: 0.783505\n",
      "Epoch 29463 - Train Loss: 0.070953, Train Acc: 0.885897 | Val Loss: 0.109412, Val Acc: 0.783505\n",
      "Epoch 29464 - Train Loss: 0.070952, Train Acc: 0.885897 | Val Loss: 0.109411, Val Acc: 0.783505\n",
      "Epoch 29465 - Train Loss: 0.070951, Train Acc: 0.885897 | Val Loss: 0.109411, Val Acc: 0.783505\n",
      "Epoch 29466 - Train Loss: 0.070949, Train Acc: 0.885897 | Val Loss: 0.109411, Val Acc: 0.783505\n",
      "Epoch 29467 - Train Loss: 0.070948, Train Acc: 0.885897 | Val Loss: 0.109411, Val Acc: 0.783505\n",
      "Epoch 29468 - Train Loss: 0.070947, Train Acc: 0.885897 | Val Loss: 0.109410, Val Acc: 0.783505\n",
      "Epoch 29469 - Train Loss: 0.070946, Train Acc: 0.885897 | Val Loss: 0.109410, Val Acc: 0.783505\n",
      "Epoch 29470 - Train Loss: 0.070944, Train Acc: 0.885897 | Val Loss: 0.109410, Val Acc: 0.783505\n",
      "Epoch 29471 - Train Loss: 0.070943, Train Acc: 0.885897 | Val Loss: 0.109409, Val Acc: 0.783505\n",
      "Epoch 29472 - Train Loss: 0.070942, Train Acc: 0.885897 | Val Loss: 0.109409, Val Acc: 0.783505\n",
      "Epoch 29473 - Train Loss: 0.070941, Train Acc: 0.885897 | Val Loss: 0.109409, Val Acc: 0.783505\n",
      "Epoch 29474 - Train Loss: 0.070939, Train Acc: 0.885897 | Val Loss: 0.109409, Val Acc: 0.783505\n",
      "Epoch 29475 - Train Loss: 0.070938, Train Acc: 0.885897 | Val Loss: 0.109408, Val Acc: 0.783505\n",
      "Epoch 29476 - Train Loss: 0.070937, Train Acc: 0.885897 | Val Loss: 0.109408, Val Acc: 0.783505\n",
      "Epoch 29477 - Train Loss: 0.070936, Train Acc: 0.885897 | Val Loss: 0.109408, Val Acc: 0.783505\n",
      "Epoch 29478 - Train Loss: 0.070934, Train Acc: 0.885897 | Val Loss: 0.109408, Val Acc: 0.783505\n",
      "Epoch 29479 - Train Loss: 0.070933, Train Acc: 0.885897 | Val Loss: 0.109407, Val Acc: 0.783505\n",
      "Epoch 29480 - Train Loss: 0.070932, Train Acc: 0.885897 | Val Loss: 0.109407, Val Acc: 0.783505\n",
      "Epoch 29481 - Train Loss: 0.070931, Train Acc: 0.885897 | Val Loss: 0.109407, Val Acc: 0.783505\n",
      "Epoch 29482 - Train Loss: 0.070929, Train Acc: 0.885897 | Val Loss: 0.109407, Val Acc: 0.783505\n",
      "Epoch 29483 - Train Loss: 0.070928, Train Acc: 0.885897 | Val Loss: 0.109406, Val Acc: 0.783505\n",
      "Epoch 29484 - Train Loss: 0.070927, Train Acc: 0.885897 | Val Loss: 0.109406, Val Acc: 0.783505\n",
      "Epoch 29485 - Train Loss: 0.070926, Train Acc: 0.885897 | Val Loss: 0.109406, Val Acc: 0.783505\n",
      "Epoch 29486 - Train Loss: 0.070924, Train Acc: 0.885897 | Val Loss: 0.109405, Val Acc: 0.783505\n",
      "Epoch 29487 - Train Loss: 0.070923, Train Acc: 0.885897 | Val Loss: 0.109405, Val Acc: 0.783505\n",
      "Epoch 29488 - Train Loss: 0.070922, Train Acc: 0.885897 | Val Loss: 0.109405, Val Acc: 0.783505\n",
      "Epoch 29489 - Train Loss: 0.070921, Train Acc: 0.885897 | Val Loss: 0.109405, Val Acc: 0.783505\n",
      "Epoch 29490 - Train Loss: 0.070919, Train Acc: 0.885897 | Val Loss: 0.109404, Val Acc: 0.783505\n",
      "Epoch 29491 - Train Loss: 0.070918, Train Acc: 0.885897 | Val Loss: 0.109404, Val Acc: 0.783505\n",
      "Epoch 29492 - Train Loss: 0.070917, Train Acc: 0.885897 | Val Loss: 0.109404, Val Acc: 0.783505\n",
      "Epoch 29493 - Train Loss: 0.070916, Train Acc: 0.885897 | Val Loss: 0.109403, Val Acc: 0.783505\n",
      "Epoch 29494 - Train Loss: 0.070914, Train Acc: 0.885897 | Val Loss: 0.109403, Val Acc: 0.783505\n",
      "Epoch 29495 - Train Loss: 0.070913, Train Acc: 0.885897 | Val Loss: 0.109403, Val Acc: 0.783505\n",
      "Epoch 29496 - Train Loss: 0.070912, Train Acc: 0.885897 | Val Loss: 0.109403, Val Acc: 0.783505\n",
      "Epoch 29497 - Train Loss: 0.070911, Train Acc: 0.885897 | Val Loss: 0.109402, Val Acc: 0.783505\n",
      "Epoch 29498 - Train Loss: 0.070909, Train Acc: 0.885897 | Val Loss: 0.109402, Val Acc: 0.783505\n",
      "Epoch 29499 - Train Loss: 0.070908, Train Acc: 0.885897 | Val Loss: 0.109402, Val Acc: 0.783505\n",
      "Epoch 29500 - Train Loss: 0.070907, Train Acc: 0.885897 | Val Loss: 0.109402, Val Acc: 0.783505\n",
      "Epoch 29501 - Train Loss: 0.070906, Train Acc: 0.885897 | Val Loss: 0.109401, Val Acc: 0.783505\n",
      "Epoch 29502 - Train Loss: 0.070904, Train Acc: 0.885897 | Val Loss: 0.109401, Val Acc: 0.783505\n",
      "Epoch 29503 - Train Loss: 0.070903, Train Acc: 0.885897 | Val Loss: 0.109401, Val Acc: 0.783505\n",
      "Epoch 29504 - Train Loss: 0.070902, Train Acc: 0.885897 | Val Loss: 0.109400, Val Acc: 0.783505\n",
      "Epoch 29505 - Train Loss: 0.070901, Train Acc: 0.885897 | Val Loss: 0.109400, Val Acc: 0.783505\n",
      "Epoch 29506 - Train Loss: 0.070899, Train Acc: 0.885897 | Val Loss: 0.109400, Val Acc: 0.783505\n",
      "Epoch 29507 - Train Loss: 0.070898, Train Acc: 0.885897 | Val Loss: 0.109400, Val Acc: 0.783505\n",
      "Epoch 29508 - Train Loss: 0.070897, Train Acc: 0.885897 | Val Loss: 0.109399, Val Acc: 0.783505\n",
      "Epoch 29509 - Train Loss: 0.070896, Train Acc: 0.885897 | Val Loss: 0.109399, Val Acc: 0.783505\n",
      "Epoch 29510 - Train Loss: 0.070894, Train Acc: 0.885897 | Val Loss: 0.109399, Val Acc: 0.783505\n",
      "Epoch 29511 - Train Loss: 0.070893, Train Acc: 0.885897 | Val Loss: 0.109399, Val Acc: 0.783505\n",
      "Epoch 29512 - Train Loss: 0.070892, Train Acc: 0.885897 | Val Loss: 0.109398, Val Acc: 0.783505\n",
      "Epoch 29513 - Train Loss: 0.070891, Train Acc: 0.885897 | Val Loss: 0.109398, Val Acc: 0.783505\n",
      "Epoch 29514 - Train Loss: 0.070889, Train Acc: 0.885897 | Val Loss: 0.109398, Val Acc: 0.783505\n",
      "Epoch 29515 - Train Loss: 0.070888, Train Acc: 0.885897 | Val Loss: 0.109397, Val Acc: 0.783505\n",
      "Epoch 29516 - Train Loss: 0.070887, Train Acc: 0.885897 | Val Loss: 0.109397, Val Acc: 0.783505\n",
      "Epoch 29517 - Train Loss: 0.070886, Train Acc: 0.885897 | Val Loss: 0.109397, Val Acc: 0.783505\n",
      "Epoch 29518 - Train Loss: 0.070884, Train Acc: 0.885897 | Val Loss: 0.109397, Val Acc: 0.783505\n",
      "Epoch 29519 - Train Loss: 0.070883, Train Acc: 0.885897 | Val Loss: 0.109396, Val Acc: 0.783505\n",
      "Epoch 29520 - Train Loss: 0.070882, Train Acc: 0.885897 | Val Loss: 0.109396, Val Acc: 0.783505\n",
      "Epoch 29521 - Train Loss: 0.070881, Train Acc: 0.885897 | Val Loss: 0.109396, Val Acc: 0.783505\n",
      "Epoch 29522 - Train Loss: 0.070879, Train Acc: 0.885897 | Val Loss: 0.109396, Val Acc: 0.783505\n",
      "Epoch 29523 - Train Loss: 0.070878, Train Acc: 0.885897 | Val Loss: 0.109395, Val Acc: 0.783505\n",
      "Epoch 29524 - Train Loss: 0.070877, Train Acc: 0.885897 | Val Loss: 0.109395, Val Acc: 0.783505\n",
      "Epoch 29525 - Train Loss: 0.070876, Train Acc: 0.885897 | Val Loss: 0.109395, Val Acc: 0.783505\n",
      "Epoch 29526 - Train Loss: 0.070875, Train Acc: 0.885897 | Val Loss: 0.109394, Val Acc: 0.783505\n",
      "Epoch 29527 - Train Loss: 0.070873, Train Acc: 0.885897 | Val Loss: 0.109394, Val Acc: 0.783505\n",
      "Epoch 29528 - Train Loss: 0.070872, Train Acc: 0.885897 | Val Loss: 0.109394, Val Acc: 0.783505\n",
      "Epoch 29529 - Train Loss: 0.070871, Train Acc: 0.885897 | Val Loss: 0.109394, Val Acc: 0.783505\n",
      "Epoch 29530 - Train Loss: 0.070870, Train Acc: 0.885897 | Val Loss: 0.109393, Val Acc: 0.783505\n",
      "Epoch 29531 - Train Loss: 0.070868, Train Acc: 0.885897 | Val Loss: 0.109393, Val Acc: 0.783505\n",
      "Epoch 29532 - Train Loss: 0.070867, Train Acc: 0.885897 | Val Loss: 0.109393, Val Acc: 0.783505\n",
      "Epoch 29533 - Train Loss: 0.070866, Train Acc: 0.885897 | Val Loss: 0.109393, Val Acc: 0.783505\n",
      "Epoch 29534 - Train Loss: 0.070865, Train Acc: 0.885897 | Val Loss: 0.109392, Val Acc: 0.783505\n",
      "Epoch 29535 - Train Loss: 0.070863, Train Acc: 0.885897 | Val Loss: 0.109392, Val Acc: 0.783505\n",
      "Epoch 29536 - Train Loss: 0.070862, Train Acc: 0.885897 | Val Loss: 0.109392, Val Acc: 0.783505\n",
      "Epoch 29537 - Train Loss: 0.070861, Train Acc: 0.885897 | Val Loss: 0.109392, Val Acc: 0.783505\n",
      "Epoch 29538 - Train Loss: 0.070860, Train Acc: 0.885897 | Val Loss: 0.109391, Val Acc: 0.783505\n",
      "Epoch 29539 - Train Loss: 0.070858, Train Acc: 0.885897 | Val Loss: 0.109391, Val Acc: 0.783505\n",
      "Epoch 29540 - Train Loss: 0.070857, Train Acc: 0.885897 | Val Loss: 0.109391, Val Acc: 0.783505\n",
      "Epoch 29541 - Train Loss: 0.070856, Train Acc: 0.885897 | Val Loss: 0.109390, Val Acc: 0.783505\n",
      "Epoch 29542 - Train Loss: 0.070855, Train Acc: 0.885897 | Val Loss: 0.109390, Val Acc: 0.783505\n",
      "Epoch 29543 - Train Loss: 0.070853, Train Acc: 0.885897 | Val Loss: 0.109390, Val Acc: 0.783505\n",
      "Epoch 29544 - Train Loss: 0.070852, Train Acc: 0.885897 | Val Loss: 0.109390, Val Acc: 0.783505\n",
      "Epoch 29545 - Train Loss: 0.070851, Train Acc: 0.885897 | Val Loss: 0.109389, Val Acc: 0.783505\n",
      "Epoch 29546 - Train Loss: 0.070850, Train Acc: 0.885897 | Val Loss: 0.109389, Val Acc: 0.783505\n",
      "Epoch 29547 - Train Loss: 0.070848, Train Acc: 0.885897 | Val Loss: 0.109389, Val Acc: 0.783505\n",
      "Epoch 29548 - Train Loss: 0.070847, Train Acc: 0.885897 | Val Loss: 0.109389, Val Acc: 0.783505\n",
      "Epoch 29549 - Train Loss: 0.070846, Train Acc: 0.885897 | Val Loss: 0.109388, Val Acc: 0.783505\n",
      "Epoch 29550 - Train Loss: 0.070845, Train Acc: 0.885897 | Val Loss: 0.109388, Val Acc: 0.783505\n",
      "Epoch 29551 - Train Loss: 0.070843, Train Acc: 0.885897 | Val Loss: 0.109388, Val Acc: 0.783505\n",
      "Epoch 29552 - Train Loss: 0.070842, Train Acc: 0.885897 | Val Loss: 0.109387, Val Acc: 0.783505\n",
      "Epoch 29553 - Train Loss: 0.070841, Train Acc: 0.885897 | Val Loss: 0.109387, Val Acc: 0.783505\n",
      "Epoch 29554 - Train Loss: 0.070840, Train Acc: 0.885897 | Val Loss: 0.109387, Val Acc: 0.783505\n",
      "Epoch 29555 - Train Loss: 0.070838, Train Acc: 0.885897 | Val Loss: 0.109387, Val Acc: 0.783505\n",
      "Epoch 29556 - Train Loss: 0.070837, Train Acc: 0.885897 | Val Loss: 0.109386, Val Acc: 0.783505\n",
      "Epoch 29557 - Train Loss: 0.070836, Train Acc: 0.885897 | Val Loss: 0.109386, Val Acc: 0.783505\n",
      "Epoch 29558 - Train Loss: 0.070835, Train Acc: 0.885897 | Val Loss: 0.109386, Val Acc: 0.783505\n",
      "Epoch 29559 - Train Loss: 0.070833, Train Acc: 0.885897 | Val Loss: 0.109386, Val Acc: 0.783505\n",
      "Epoch 29560 - Train Loss: 0.070832, Train Acc: 0.885897 | Val Loss: 0.109385, Val Acc: 0.783505\n",
      "Epoch 29561 - Train Loss: 0.070831, Train Acc: 0.885897 | Val Loss: 0.109385, Val Acc: 0.783505\n",
      "Epoch 29562 - Train Loss: 0.070830, Train Acc: 0.885897 | Val Loss: 0.109385, Val Acc: 0.783505\n",
      "Epoch 29563 - Train Loss: 0.070828, Train Acc: 0.885897 | Val Loss: 0.109384, Val Acc: 0.783505\n",
      "Epoch 29564 - Train Loss: 0.070827, Train Acc: 0.885897 | Val Loss: 0.109384, Val Acc: 0.783505\n",
      "Epoch 29565 - Train Loss: 0.070826, Train Acc: 0.885897 | Val Loss: 0.109384, Val Acc: 0.783505\n",
      "Epoch 29566 - Train Loss: 0.070825, Train Acc: 0.885897 | Val Loss: 0.109384, Val Acc: 0.783505\n",
      "Epoch 29567 - Train Loss: 0.070823, Train Acc: 0.885897 | Val Loss: 0.109383, Val Acc: 0.783505\n",
      "Epoch 29568 - Train Loss: 0.070822, Train Acc: 0.885897 | Val Loss: 0.109383, Val Acc: 0.783505\n",
      "Epoch 29569 - Train Loss: 0.070821, Train Acc: 0.885897 | Val Loss: 0.109383, Val Acc: 0.783505\n",
      "Epoch 29570 - Train Loss: 0.070820, Train Acc: 0.885897 | Val Loss: 0.109383, Val Acc: 0.783505\n",
      "Epoch 29571 - Train Loss: 0.070819, Train Acc: 0.885897 | Val Loss: 0.109382, Val Acc: 0.783505\n",
      "Epoch 29572 - Train Loss: 0.070817, Train Acc: 0.885897 | Val Loss: 0.109382, Val Acc: 0.783505\n",
      "Epoch 29573 - Train Loss: 0.070816, Train Acc: 0.885897 | Val Loss: 0.109382, Val Acc: 0.783505\n",
      "Epoch 29574 - Train Loss: 0.070815, Train Acc: 0.885897 | Val Loss: 0.109381, Val Acc: 0.783505\n",
      "Epoch 29575 - Train Loss: 0.070814, Train Acc: 0.885897 | Val Loss: 0.109381, Val Acc: 0.783505\n",
      "Epoch 29576 - Train Loss: 0.070812, Train Acc: 0.885897 | Val Loss: 0.109381, Val Acc: 0.783505\n",
      "Epoch 29577 - Train Loss: 0.070811, Train Acc: 0.885897 | Val Loss: 0.109381, Val Acc: 0.783505\n",
      "Epoch 29578 - Train Loss: 0.070810, Train Acc: 0.885897 | Val Loss: 0.109380, Val Acc: 0.783505\n",
      "Epoch 29579 - Train Loss: 0.070809, Train Acc: 0.885897 | Val Loss: 0.109380, Val Acc: 0.783505\n",
      "Epoch 29580 - Train Loss: 0.070807, Train Acc: 0.885897 | Val Loss: 0.109380, Val Acc: 0.783505\n",
      "Epoch 29581 - Train Loss: 0.070806, Train Acc: 0.885897 | Val Loss: 0.109380, Val Acc: 0.783505\n",
      "Epoch 29582 - Train Loss: 0.070805, Train Acc: 0.885897 | Val Loss: 0.109379, Val Acc: 0.783505\n",
      "Epoch 29583 - Train Loss: 0.070804, Train Acc: 0.885897 | Val Loss: 0.109379, Val Acc: 0.783505\n",
      "Epoch 29584 - Train Loss: 0.070802, Train Acc: 0.885897 | Val Loss: 0.109379, Val Acc: 0.783505\n",
      "Epoch 29585 - Train Loss: 0.070801, Train Acc: 0.885897 | Val Loss: 0.109378, Val Acc: 0.783505\n",
      "Epoch 29586 - Train Loss: 0.070800, Train Acc: 0.885897 | Val Loss: 0.109378, Val Acc: 0.783505\n",
      "Epoch 29587 - Train Loss: 0.070799, Train Acc: 0.885897 | Val Loss: 0.109378, Val Acc: 0.783505\n",
      "Epoch 29588 - Train Loss: 0.070797, Train Acc: 0.885897 | Val Loss: 0.109378, Val Acc: 0.783505\n",
      "Epoch 29589 - Train Loss: 0.070796, Train Acc: 0.885897 | Val Loss: 0.109377, Val Acc: 0.783505\n",
      "Epoch 29590 - Train Loss: 0.070795, Train Acc: 0.885897 | Val Loss: 0.109377, Val Acc: 0.783505\n",
      "Epoch 29591 - Train Loss: 0.070794, Train Acc: 0.885897 | Val Loss: 0.109377, Val Acc: 0.783505\n",
      "Epoch 29592 - Train Loss: 0.070792, Train Acc: 0.885897 | Val Loss: 0.109377, Val Acc: 0.783505\n",
      "Epoch 29593 - Train Loss: 0.070791, Train Acc: 0.885897 | Val Loss: 0.109376, Val Acc: 0.783505\n",
      "Epoch 29594 - Train Loss: 0.070790, Train Acc: 0.885897 | Val Loss: 0.109376, Val Acc: 0.783505\n",
      "Epoch 29595 - Train Loss: 0.070789, Train Acc: 0.885897 | Val Loss: 0.109376, Val Acc: 0.783505\n",
      "Epoch 29596 - Train Loss: 0.070787, Train Acc: 0.885897 | Val Loss: 0.109375, Val Acc: 0.783505\n",
      "Epoch 29597 - Train Loss: 0.070786, Train Acc: 0.885897 | Val Loss: 0.109375, Val Acc: 0.783505\n",
      "Epoch 29598 - Train Loss: 0.070785, Train Acc: 0.885897 | Val Loss: 0.109375, Val Acc: 0.783505\n",
      "Epoch 29599 - Train Loss: 0.070784, Train Acc: 0.885897 | Val Loss: 0.109375, Val Acc: 0.783505\n",
      "Epoch 29600 - Train Loss: 0.070783, Train Acc: 0.885897 | Val Loss: 0.109374, Val Acc: 0.783505\n",
      "Epoch 29601 - Train Loss: 0.070781, Train Acc: 0.885897 | Val Loss: 0.109374, Val Acc: 0.783505\n",
      "Epoch 29602 - Train Loss: 0.070780, Train Acc: 0.885897 | Val Loss: 0.109374, Val Acc: 0.783505\n",
      "Epoch 29603 - Train Loss: 0.070779, Train Acc: 0.885897 | Val Loss: 0.109374, Val Acc: 0.783505\n",
      "Epoch 29604 - Train Loss: 0.070778, Train Acc: 0.885897 | Val Loss: 0.109373, Val Acc: 0.783505\n",
      "Epoch 29605 - Train Loss: 0.070776, Train Acc: 0.885897 | Val Loss: 0.109373, Val Acc: 0.783505\n",
      "Epoch 29606 - Train Loss: 0.070775, Train Acc: 0.885897 | Val Loss: 0.109373, Val Acc: 0.783505\n",
      "Epoch 29607 - Train Loss: 0.070774, Train Acc: 0.885897 | Val Loss: 0.109373, Val Acc: 0.783505\n",
      "Epoch 29608 - Train Loss: 0.070773, Train Acc: 0.885897 | Val Loss: 0.109372, Val Acc: 0.783505\n",
      "Epoch 29609 - Train Loss: 0.070771, Train Acc: 0.885897 | Val Loss: 0.109372, Val Acc: 0.783505\n",
      "Epoch 29610 - Train Loss: 0.070770, Train Acc: 0.885897 | Val Loss: 0.109372, Val Acc: 0.783505\n",
      "Epoch 29611 - Train Loss: 0.070769, Train Acc: 0.885897 | Val Loss: 0.109371, Val Acc: 0.783505\n",
      "Epoch 29612 - Train Loss: 0.070768, Train Acc: 0.885897 | Val Loss: 0.109371, Val Acc: 0.783505\n",
      "Epoch 29613 - Train Loss: 0.070766, Train Acc: 0.885897 | Val Loss: 0.109371, Val Acc: 0.783505\n",
      "Epoch 29614 - Train Loss: 0.070765, Train Acc: 0.885897 | Val Loss: 0.109371, Val Acc: 0.783505\n",
      "Epoch 29615 - Train Loss: 0.070764, Train Acc: 0.885897 | Val Loss: 0.109370, Val Acc: 0.783505\n",
      "Epoch 29616 - Train Loss: 0.070763, Train Acc: 0.885897 | Val Loss: 0.109370, Val Acc: 0.783505\n",
      "Epoch 29617 - Train Loss: 0.070761, Train Acc: 0.885897 | Val Loss: 0.109370, Val Acc: 0.783505\n",
      "Epoch 29618 - Train Loss: 0.070760, Train Acc: 0.885897 | Val Loss: 0.109370, Val Acc: 0.783505\n",
      "Epoch 29619 - Train Loss: 0.070759, Train Acc: 0.885897 | Val Loss: 0.109369, Val Acc: 0.783505\n",
      "Epoch 29620 - Train Loss: 0.070758, Train Acc: 0.885897 | Val Loss: 0.109369, Val Acc: 0.783505\n",
      "Epoch 29621 - Train Loss: 0.070756, Train Acc: 0.885897 | Val Loss: 0.109369, Val Acc: 0.783505\n",
      "Epoch 29622 - Train Loss: 0.070755, Train Acc: 0.885897 | Val Loss: 0.109368, Val Acc: 0.783505\n",
      "Epoch 29623 - Train Loss: 0.070754, Train Acc: 0.885897 | Val Loss: 0.109368, Val Acc: 0.783505\n",
      "Epoch 29624 - Train Loss: 0.070753, Train Acc: 0.885897 | Val Loss: 0.109368, Val Acc: 0.783505\n",
      "Epoch 29625 - Train Loss: 0.070752, Train Acc: 0.885897 | Val Loss: 0.109368, Val Acc: 0.783505\n",
      "Epoch 29626 - Train Loss: 0.070750, Train Acc: 0.885897 | Val Loss: 0.109367, Val Acc: 0.783505\n",
      "Epoch 29627 - Train Loss: 0.070749, Train Acc: 0.885897 | Val Loss: 0.109367, Val Acc: 0.783505\n",
      "Epoch 29628 - Train Loss: 0.070748, Train Acc: 0.885897 | Val Loss: 0.109367, Val Acc: 0.783505\n",
      "Epoch 29629 - Train Loss: 0.070747, Train Acc: 0.885897 | Val Loss: 0.109367, Val Acc: 0.783505\n",
      "Epoch 29630 - Train Loss: 0.070745, Train Acc: 0.885897 | Val Loss: 0.109366, Val Acc: 0.783505\n",
      "Epoch 29631 - Train Loss: 0.070744, Train Acc: 0.885897 | Val Loss: 0.109366, Val Acc: 0.783505\n",
      "Epoch 29632 - Train Loss: 0.070743, Train Acc: 0.885897 | Val Loss: 0.109366, Val Acc: 0.783505\n",
      "Epoch 29633 - Train Loss: 0.070742, Train Acc: 0.885897 | Val Loss: 0.109366, Val Acc: 0.783505\n",
      "Epoch 29634 - Train Loss: 0.070740, Train Acc: 0.885897 | Val Loss: 0.109365, Val Acc: 0.783505\n",
      "Epoch 29635 - Train Loss: 0.070739, Train Acc: 0.885897 | Val Loss: 0.109365, Val Acc: 0.783505\n",
      "Epoch 29636 - Train Loss: 0.070738, Train Acc: 0.885897 | Val Loss: 0.109365, Val Acc: 0.783505\n",
      "Epoch 29637 - Train Loss: 0.070737, Train Acc: 0.885897 | Val Loss: 0.109364, Val Acc: 0.783505\n",
      "Epoch 29638 - Train Loss: 0.070735, Train Acc: 0.885897 | Val Loss: 0.109364, Val Acc: 0.783505\n",
      "Epoch 29639 - Train Loss: 0.070734, Train Acc: 0.885897 | Val Loss: 0.109364, Val Acc: 0.783505\n",
      "Epoch 29640 - Train Loss: 0.070733, Train Acc: 0.885897 | Val Loss: 0.109364, Val Acc: 0.783505\n",
      "Epoch 29641 - Train Loss: 0.070732, Train Acc: 0.885897 | Val Loss: 0.109363, Val Acc: 0.783505\n",
      "Epoch 29642 - Train Loss: 0.070730, Train Acc: 0.885897 | Val Loss: 0.109363, Val Acc: 0.783505\n",
      "Epoch 29643 - Train Loss: 0.070729, Train Acc: 0.885897 | Val Loss: 0.109363, Val Acc: 0.783505\n",
      "Epoch 29644 - Train Loss: 0.070728, Train Acc: 0.885897 | Val Loss: 0.109363, Val Acc: 0.783505\n",
      "Epoch 29645 - Train Loss: 0.070727, Train Acc: 0.885897 | Val Loss: 0.109362, Val Acc: 0.783505\n",
      "Epoch 29646 - Train Loss: 0.070725, Train Acc: 0.885897 | Val Loss: 0.109362, Val Acc: 0.783505\n",
      "Epoch 29647 - Train Loss: 0.070724, Train Acc: 0.885897 | Val Loss: 0.109362, Val Acc: 0.783505\n",
      "Epoch 29648 - Train Loss: 0.070723, Train Acc: 0.885897 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 29649 - Train Loss: 0.070722, Train Acc: 0.885897 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 29650 - Train Loss: 0.070721, Train Acc: 0.885897 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 29651 - Train Loss: 0.070719, Train Acc: 0.885897 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 29652 - Train Loss: 0.070718, Train Acc: 0.885897 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 29653 - Train Loss: 0.070717, Train Acc: 0.885897 | Val Loss: 0.109360, Val Acc: 0.783505\n",
      "Epoch 29654 - Train Loss: 0.070716, Train Acc: 0.885897 | Val Loss: 0.109360, Val Acc: 0.783505\n",
      "Epoch 29655 - Train Loss: 0.070714, Train Acc: 0.885897 | Val Loss: 0.109360, Val Acc: 0.783505\n",
      "Epoch 29656 - Train Loss: 0.070713, Train Acc: 0.885897 | Val Loss: 0.109359, Val Acc: 0.783505\n",
      "Epoch 29657 - Train Loss: 0.070712, Train Acc: 0.885897 | Val Loss: 0.109359, Val Acc: 0.783505\n",
      "Epoch 29658 - Train Loss: 0.070711, Train Acc: 0.885897 | Val Loss: 0.109359, Val Acc: 0.783505\n",
      "Epoch 29659 - Train Loss: 0.070709, Train Acc: 0.885897 | Val Loss: 0.109359, Val Acc: 0.783505\n",
      "Epoch 29660 - Train Loss: 0.070708, Train Acc: 0.885897 | Val Loss: 0.109358, Val Acc: 0.783505\n",
      "Epoch 29661 - Train Loss: 0.070707, Train Acc: 0.885897 | Val Loss: 0.109358, Val Acc: 0.783505\n",
      "Epoch 29662 - Train Loss: 0.070706, Train Acc: 0.885897 | Val Loss: 0.109358, Val Acc: 0.783505\n",
      "Epoch 29663 - Train Loss: 0.070704, Train Acc: 0.885897 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 29664 - Train Loss: 0.070703, Train Acc: 0.885897 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 29665 - Train Loss: 0.070702, Train Acc: 0.885897 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 29666 - Train Loss: 0.070701, Train Acc: 0.885897 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 29667 - Train Loss: 0.070700, Train Acc: 0.885897 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 29668 - Train Loss: 0.070698, Train Acc: 0.885897 | Val Loss: 0.109356, Val Acc: 0.783505\n",
      "Epoch 29669 - Train Loss: 0.070697, Train Acc: 0.885897 | Val Loss: 0.109356, Val Acc: 0.783505\n",
      "Epoch 29670 - Train Loss: 0.070696, Train Acc: 0.885897 | Val Loss: 0.109356, Val Acc: 0.783505\n",
      "Epoch 29671 - Train Loss: 0.070695, Train Acc: 0.885897 | Val Loss: 0.109355, Val Acc: 0.783505\n",
      "Epoch 29672 - Train Loss: 0.070693, Train Acc: 0.885897 | Val Loss: 0.109355, Val Acc: 0.783505\n",
      "Epoch 29673 - Train Loss: 0.070692, Train Acc: 0.885897 | Val Loss: 0.109355, Val Acc: 0.783505\n",
      "Epoch 29674 - Train Loss: 0.070691, Train Acc: 0.885897 | Val Loss: 0.109355, Val Acc: 0.783505\n",
      "Epoch 29675 - Train Loss: 0.070690, Train Acc: 0.885897 | Val Loss: 0.109354, Val Acc: 0.783505\n",
      "Epoch 29676 - Train Loss: 0.070688, Train Acc: 0.885897 | Val Loss: 0.109354, Val Acc: 0.783505\n",
      "Epoch 29677 - Train Loss: 0.070687, Train Acc: 0.885897 | Val Loss: 0.109354, Val Acc: 0.783505\n",
      "Epoch 29678 - Train Loss: 0.070686, Train Acc: 0.885897 | Val Loss: 0.109354, Val Acc: 0.783505\n",
      "Epoch 29679 - Train Loss: 0.070685, Train Acc: 0.885897 | Val Loss: 0.109353, Val Acc: 0.783505\n",
      "Epoch 29680 - Train Loss: 0.070683, Train Acc: 0.885897 | Val Loss: 0.109353, Val Acc: 0.783505\n",
      "Epoch 29681 - Train Loss: 0.070682, Train Acc: 0.885897 | Val Loss: 0.109353, Val Acc: 0.783505\n",
      "Epoch 29682 - Train Loss: 0.070681, Train Acc: 0.885897 | Val Loss: 0.109352, Val Acc: 0.783505\n",
      "Epoch 29683 - Train Loss: 0.070680, Train Acc: 0.885897 | Val Loss: 0.109352, Val Acc: 0.783505\n",
      "Epoch 29684 - Train Loss: 0.070678, Train Acc: 0.885897 | Val Loss: 0.109352, Val Acc: 0.783505\n",
      "Epoch 29685 - Train Loss: 0.070677, Train Acc: 0.885897 | Val Loss: 0.109352, Val Acc: 0.783505\n",
      "Epoch 29686 - Train Loss: 0.070676, Train Acc: 0.885897 | Val Loss: 0.109351, Val Acc: 0.783505\n",
      "Epoch 29687 - Train Loss: 0.070675, Train Acc: 0.885897 | Val Loss: 0.109351, Val Acc: 0.783505\n",
      "Epoch 29688 - Train Loss: 0.070674, Train Acc: 0.885897 | Val Loss: 0.109351, Val Acc: 0.783505\n",
      "Epoch 29689 - Train Loss: 0.070672, Train Acc: 0.885897 | Val Loss: 0.109351, Val Acc: 0.783505\n",
      "Epoch 29690 - Train Loss: 0.070671, Train Acc: 0.885897 | Val Loss: 0.109350, Val Acc: 0.783505\n",
      "Epoch 29691 - Train Loss: 0.070670, Train Acc: 0.885897 | Val Loss: 0.109350, Val Acc: 0.783505\n",
      "Epoch 29692 - Train Loss: 0.070669, Train Acc: 0.885897 | Val Loss: 0.109350, Val Acc: 0.783505\n",
      "Epoch 29693 - Train Loss: 0.070667, Train Acc: 0.885897 | Val Loss: 0.109350, Val Acc: 0.783505\n",
      "Epoch 29694 - Train Loss: 0.070666, Train Acc: 0.885897 | Val Loss: 0.109349, Val Acc: 0.783505\n",
      "Epoch 29695 - Train Loss: 0.070665, Train Acc: 0.885897 | Val Loss: 0.109349, Val Acc: 0.783505\n",
      "Epoch 29696 - Train Loss: 0.070664, Train Acc: 0.885897 | Val Loss: 0.109349, Val Acc: 0.783505\n",
      "Epoch 29697 - Train Loss: 0.070662, Train Acc: 0.885897 | Val Loss: 0.109349, Val Acc: 0.783505\n",
      "Epoch 29698 - Train Loss: 0.070661, Train Acc: 0.885897 | Val Loss: 0.109348, Val Acc: 0.783505\n",
      "Epoch 29699 - Train Loss: 0.070660, Train Acc: 0.885897 | Val Loss: 0.109348, Val Acc: 0.783505\n",
      "Epoch 29700 - Train Loss: 0.070659, Train Acc: 0.885897 | Val Loss: 0.109348, Val Acc: 0.783505\n",
      "Epoch 29701 - Train Loss: 0.070657, Train Acc: 0.885897 | Val Loss: 0.109348, Val Acc: 0.783505\n",
      "Epoch 29702 - Train Loss: 0.070656, Train Acc: 0.885897 | Val Loss: 0.109347, Val Acc: 0.783505\n",
      "Epoch 29703 - Train Loss: 0.070655, Train Acc: 0.885897 | Val Loss: 0.109347, Val Acc: 0.783505\n",
      "Epoch 29704 - Train Loss: 0.070654, Train Acc: 0.885897 | Val Loss: 0.109347, Val Acc: 0.783505\n",
      "Epoch 29705 - Train Loss: 0.070653, Train Acc: 0.885897 | Val Loss: 0.109346, Val Acc: 0.783505\n",
      "Epoch 29706 - Train Loss: 0.070651, Train Acc: 0.885897 | Val Loss: 0.109346, Val Acc: 0.783505\n",
      "Epoch 29707 - Train Loss: 0.070650, Train Acc: 0.885897 | Val Loss: 0.109346, Val Acc: 0.783505\n",
      "Epoch 29708 - Train Loss: 0.070649, Train Acc: 0.885897 | Val Loss: 0.109346, Val Acc: 0.783505\n",
      "Epoch 29709 - Train Loss: 0.070648, Train Acc: 0.885897 | Val Loss: 0.109345, Val Acc: 0.783505\n",
      "Epoch 29710 - Train Loss: 0.070646, Train Acc: 0.885897 | Val Loss: 0.109345, Val Acc: 0.783505\n",
      "Epoch 29711 - Train Loss: 0.070645, Train Acc: 0.885897 | Val Loss: 0.109345, Val Acc: 0.783505\n",
      "Epoch 29712 - Train Loss: 0.070644, Train Acc: 0.885897 | Val Loss: 0.109345, Val Acc: 0.783505\n",
      "Epoch 29713 - Train Loss: 0.070643, Train Acc: 0.885897 | Val Loss: 0.109344, Val Acc: 0.783505\n",
      "Epoch 29714 - Train Loss: 0.070641, Train Acc: 0.885897 | Val Loss: 0.109344, Val Acc: 0.783505\n",
      "Epoch 29715 - Train Loss: 0.070640, Train Acc: 0.885897 | Val Loss: 0.109344, Val Acc: 0.783505\n",
      "Epoch 29716 - Train Loss: 0.070639, Train Acc: 0.885897 | Val Loss: 0.109343, Val Acc: 0.783505\n",
      "Epoch 29717 - Train Loss: 0.070638, Train Acc: 0.885897 | Val Loss: 0.109343, Val Acc: 0.783505\n",
      "Epoch 29718 - Train Loss: 0.070637, Train Acc: 0.885897 | Val Loss: 0.109343, Val Acc: 0.783505\n",
      "Epoch 29719 - Train Loss: 0.070635, Train Acc: 0.885897 | Val Loss: 0.109343, Val Acc: 0.783505\n",
      "Epoch 29720 - Train Loss: 0.070634, Train Acc: 0.885897 | Val Loss: 0.109342, Val Acc: 0.783505\n",
      "Epoch 29721 - Train Loss: 0.070633, Train Acc: 0.885897 | Val Loss: 0.109342, Val Acc: 0.783505\n",
      "Epoch 29722 - Train Loss: 0.070632, Train Acc: 0.885897 | Val Loss: 0.109342, Val Acc: 0.783505\n",
      "Epoch 29723 - Train Loss: 0.070630, Train Acc: 0.885897 | Val Loss: 0.109342, Val Acc: 0.783505\n",
      "Epoch 29724 - Train Loss: 0.070629, Train Acc: 0.885897 | Val Loss: 0.109341, Val Acc: 0.783505\n",
      "Epoch 29725 - Train Loss: 0.070628, Train Acc: 0.885897 | Val Loss: 0.109341, Val Acc: 0.783505\n",
      "Epoch 29726 - Train Loss: 0.070627, Train Acc: 0.885897 | Val Loss: 0.109341, Val Acc: 0.783505\n",
      "Epoch 29727 - Train Loss: 0.070625, Train Acc: 0.885897 | Val Loss: 0.109341, Val Acc: 0.783505\n",
      "Epoch 29728 - Train Loss: 0.070624, Train Acc: 0.885897 | Val Loss: 0.109340, Val Acc: 0.783505\n",
      "Epoch 29729 - Train Loss: 0.070623, Train Acc: 0.885897 | Val Loss: 0.109340, Val Acc: 0.783505\n",
      "Epoch 29730 - Train Loss: 0.070622, Train Acc: 0.885897 | Val Loss: 0.109340, Val Acc: 0.783505\n",
      "Epoch 29731 - Train Loss: 0.070620, Train Acc: 0.885897 | Val Loss: 0.109340, Val Acc: 0.783505\n",
      "Epoch 29732 - Train Loss: 0.070619, Train Acc: 0.885897 | Val Loss: 0.109339, Val Acc: 0.783505\n",
      "Epoch 29733 - Train Loss: 0.070618, Train Acc: 0.885897 | Val Loss: 0.109339, Val Acc: 0.783505\n",
      "Epoch 29734 - Train Loss: 0.070617, Train Acc: 0.885897 | Val Loss: 0.109339, Val Acc: 0.783505\n",
      "Epoch 29735 - Train Loss: 0.070616, Train Acc: 0.885897 | Val Loss: 0.109339, Val Acc: 0.783505\n",
      "Epoch 29736 - Train Loss: 0.070614, Train Acc: 0.885897 | Val Loss: 0.109338, Val Acc: 0.783505\n",
      "Epoch 29737 - Train Loss: 0.070613, Train Acc: 0.885897 | Val Loss: 0.109338, Val Acc: 0.783505\n",
      "Epoch 29738 - Train Loss: 0.070612, Train Acc: 0.885897 | Val Loss: 0.109338, Val Acc: 0.783505\n",
      "Epoch 29739 - Train Loss: 0.070611, Train Acc: 0.885897 | Val Loss: 0.109337, Val Acc: 0.783505\n",
      "Epoch 29740 - Train Loss: 0.070609, Train Acc: 0.885897 | Val Loss: 0.109337, Val Acc: 0.783505\n",
      "Epoch 29741 - Train Loss: 0.070608, Train Acc: 0.885897 | Val Loss: 0.109337, Val Acc: 0.783505\n",
      "Epoch 29742 - Train Loss: 0.070607, Train Acc: 0.885897 | Val Loss: 0.109337, Val Acc: 0.783505\n",
      "Epoch 29743 - Train Loss: 0.070606, Train Acc: 0.885897 | Val Loss: 0.109336, Val Acc: 0.783505\n",
      "Epoch 29744 - Train Loss: 0.070604, Train Acc: 0.885897 | Val Loss: 0.109336, Val Acc: 0.783505\n",
      "Epoch 29745 - Train Loss: 0.070603, Train Acc: 0.885897 | Val Loss: 0.109336, Val Acc: 0.783505\n",
      "Epoch 29746 - Train Loss: 0.070602, Train Acc: 0.885897 | Val Loss: 0.109336, Val Acc: 0.783505\n",
      "Epoch 29747 - Train Loss: 0.070601, Train Acc: 0.885897 | Val Loss: 0.109335, Val Acc: 0.783505\n",
      "Epoch 29748 - Train Loss: 0.070600, Train Acc: 0.885897 | Val Loss: 0.109335, Val Acc: 0.783505\n",
      "Epoch 29749 - Train Loss: 0.070598, Train Acc: 0.885897 | Val Loss: 0.109335, Val Acc: 0.783505\n",
      "Epoch 29750 - Train Loss: 0.070597, Train Acc: 0.885897 | Val Loss: 0.109335, Val Acc: 0.783505\n",
      "Epoch 29751 - Train Loss: 0.070596, Train Acc: 0.885897 | Val Loss: 0.109334, Val Acc: 0.783505\n",
      "Epoch 29752 - Train Loss: 0.070595, Train Acc: 0.885897 | Val Loss: 0.109334, Val Acc: 0.783505\n",
      "Epoch 29753 - Train Loss: 0.070593, Train Acc: 0.885897 | Val Loss: 0.109334, Val Acc: 0.783505\n",
      "Epoch 29754 - Train Loss: 0.070592, Train Acc: 0.885897 | Val Loss: 0.109334, Val Acc: 0.783505\n",
      "Epoch 29755 - Train Loss: 0.070591, Train Acc: 0.885897 | Val Loss: 0.109333, Val Acc: 0.783505\n",
      "Epoch 29756 - Train Loss: 0.070590, Train Acc: 0.885897 | Val Loss: 0.109333, Val Acc: 0.783505\n",
      "Epoch 29757 - Train Loss: 0.070588, Train Acc: 0.885897 | Val Loss: 0.109333, Val Acc: 0.783505\n",
      "Epoch 29758 - Train Loss: 0.070587, Train Acc: 0.885897 | Val Loss: 0.109332, Val Acc: 0.783505\n",
      "Epoch 29759 - Train Loss: 0.070586, Train Acc: 0.885897 | Val Loss: 0.109332, Val Acc: 0.783505\n",
      "Epoch 29760 - Train Loss: 0.070585, Train Acc: 0.885897 | Val Loss: 0.109332, Val Acc: 0.783505\n",
      "Epoch 29761 - Train Loss: 0.070583, Train Acc: 0.885897 | Val Loss: 0.109332, Val Acc: 0.783505\n",
      "Epoch 29762 - Train Loss: 0.070582, Train Acc: 0.885897 | Val Loss: 0.109331, Val Acc: 0.783505\n",
      "Epoch 29763 - Train Loss: 0.070581, Train Acc: 0.885897 | Val Loss: 0.109331, Val Acc: 0.783505\n",
      "Epoch 29764 - Train Loss: 0.070580, Train Acc: 0.885897 | Val Loss: 0.109331, Val Acc: 0.783505\n",
      "Epoch 29765 - Train Loss: 0.070579, Train Acc: 0.885897 | Val Loss: 0.109331, Val Acc: 0.783505\n",
      "Epoch 29766 - Train Loss: 0.070577, Train Acc: 0.885897 | Val Loss: 0.109330, Val Acc: 0.783505\n",
      "Epoch 29767 - Train Loss: 0.070576, Train Acc: 0.885897 | Val Loss: 0.109330, Val Acc: 0.783505\n",
      "Epoch 29768 - Train Loss: 0.070575, Train Acc: 0.885897 | Val Loss: 0.109330, Val Acc: 0.783505\n",
      "Epoch 29769 - Train Loss: 0.070574, Train Acc: 0.885897 | Val Loss: 0.109330, Val Acc: 0.783505\n",
      "Epoch 29770 - Train Loss: 0.070572, Train Acc: 0.885897 | Val Loss: 0.109329, Val Acc: 0.783505\n",
      "Epoch 29771 - Train Loss: 0.070571, Train Acc: 0.885897 | Val Loss: 0.109329, Val Acc: 0.783505\n",
      "Epoch 29772 - Train Loss: 0.070570, Train Acc: 0.885897 | Val Loss: 0.109329, Val Acc: 0.783505\n",
      "Epoch 29773 - Train Loss: 0.070569, Train Acc: 0.885897 | Val Loss: 0.109328, Val Acc: 0.783505\n",
      "Epoch 29774 - Train Loss: 0.070567, Train Acc: 0.885897 | Val Loss: 0.109328, Val Acc: 0.783505\n",
      "Epoch 29775 - Train Loss: 0.070566, Train Acc: 0.885897 | Val Loss: 0.109328, Val Acc: 0.783505\n",
      "Epoch 29776 - Train Loss: 0.070565, Train Acc: 0.885897 | Val Loss: 0.109328, Val Acc: 0.783505\n",
      "Epoch 29777 - Train Loss: 0.070564, Train Acc: 0.885897 | Val Loss: 0.109328, Val Acc: 0.783505\n",
      "Epoch 29778 - Train Loss: 0.070563, Train Acc: 0.885897 | Val Loss: 0.109327, Val Acc: 0.783505\n",
      "Epoch 29779 - Train Loss: 0.070561, Train Acc: 0.885897 | Val Loss: 0.109327, Val Acc: 0.783505\n",
      "Epoch 29780 - Train Loss: 0.070560, Train Acc: 0.885897 | Val Loss: 0.109327, Val Acc: 0.783505\n",
      "Epoch 29781 - Train Loss: 0.070559, Train Acc: 0.885897 | Val Loss: 0.109327, Val Acc: 0.783505\n",
      "Epoch 29782 - Train Loss: 0.070558, Train Acc: 0.885897 | Val Loss: 0.109326, Val Acc: 0.783505\n",
      "Epoch 29783 - Train Loss: 0.070556, Train Acc: 0.885897 | Val Loss: 0.109326, Val Acc: 0.783505\n",
      "Epoch 29784 - Train Loss: 0.070555, Train Acc: 0.885897 | Val Loss: 0.109326, Val Acc: 0.783505\n",
      "Epoch 29785 - Train Loss: 0.070554, Train Acc: 0.885897 | Val Loss: 0.109325, Val Acc: 0.783505\n",
      "Epoch 29786 - Train Loss: 0.070553, Train Acc: 0.885897 | Val Loss: 0.109325, Val Acc: 0.783505\n",
      "Epoch 29787 - Train Loss: 0.070552, Train Acc: 0.885897 | Val Loss: 0.109325, Val Acc: 0.783505\n",
      "Epoch 29788 - Train Loss: 0.070550, Train Acc: 0.885897 | Val Loss: 0.109325, Val Acc: 0.783505\n",
      "Epoch 29789 - Train Loss: 0.070549, Train Acc: 0.885897 | Val Loss: 0.109324, Val Acc: 0.783505\n",
      "Epoch 29790 - Train Loss: 0.070548, Train Acc: 0.885897 | Val Loss: 0.109324, Val Acc: 0.783505\n",
      "Epoch 29791 - Train Loss: 0.070547, Train Acc: 0.885897 | Val Loss: 0.109324, Val Acc: 0.783505\n",
      "Epoch 29792 - Train Loss: 0.070545, Train Acc: 0.885897 | Val Loss: 0.109324, Val Acc: 0.783505\n",
      "Epoch 29793 - Train Loss: 0.070544, Train Acc: 0.885897 | Val Loss: 0.109323, Val Acc: 0.783505\n",
      "Epoch 29794 - Train Loss: 0.070543, Train Acc: 0.885897 | Val Loss: 0.109323, Val Acc: 0.783505\n",
      "Epoch 29795 - Train Loss: 0.070542, Train Acc: 0.885897 | Val Loss: 0.109323, Val Acc: 0.783505\n",
      "Epoch 29796 - Train Loss: 0.070540, Train Acc: 0.885897 | Val Loss: 0.109323, Val Acc: 0.783505\n",
      "Epoch 29797 - Train Loss: 0.070539, Train Acc: 0.885897 | Val Loss: 0.109322, Val Acc: 0.783505\n",
      "Epoch 29798 - Train Loss: 0.070538, Train Acc: 0.885897 | Val Loss: 0.109322, Val Acc: 0.783505\n",
      "Epoch 29799 - Train Loss: 0.070537, Train Acc: 0.885897 | Val Loss: 0.109322, Val Acc: 0.783505\n",
      "Epoch 29800 - Train Loss: 0.070536, Train Acc: 0.885897 | Val Loss: 0.109322, Val Acc: 0.783505\n",
      "Epoch 29801 - Train Loss: 0.070534, Train Acc: 0.885897 | Val Loss: 0.109321, Val Acc: 0.783505\n",
      "Epoch 29802 - Train Loss: 0.070533, Train Acc: 0.885897 | Val Loss: 0.109321, Val Acc: 0.783505\n",
      "Epoch 29803 - Train Loss: 0.070532, Train Acc: 0.885897 | Val Loss: 0.109321, Val Acc: 0.783505\n",
      "Epoch 29804 - Train Loss: 0.070531, Train Acc: 0.885897 | Val Loss: 0.109320, Val Acc: 0.783505\n",
      "Epoch 29805 - Train Loss: 0.070529, Train Acc: 0.885897 | Val Loss: 0.109320, Val Acc: 0.783505\n",
      "Epoch 29806 - Train Loss: 0.070528, Train Acc: 0.885897 | Val Loss: 0.109320, Val Acc: 0.783505\n",
      "Epoch 29807 - Train Loss: 0.070527, Train Acc: 0.885897 | Val Loss: 0.109320, Val Acc: 0.783505\n",
      "Epoch 29808 - Train Loss: 0.070526, Train Acc: 0.885897 | Val Loss: 0.109319, Val Acc: 0.783505\n",
      "Epoch 29809 - Train Loss: 0.070524, Train Acc: 0.885897 | Val Loss: 0.109319, Val Acc: 0.783505\n",
      "Epoch 29810 - Train Loss: 0.070523, Train Acc: 0.885897 | Val Loss: 0.109319, Val Acc: 0.783505\n",
      "Epoch 29811 - Train Loss: 0.070522, Train Acc: 0.885897 | Val Loss: 0.109319, Val Acc: 0.783505\n",
      "Epoch 29812 - Train Loss: 0.070521, Train Acc: 0.885897 | Val Loss: 0.109318, Val Acc: 0.783505\n",
      "Epoch 29813 - Train Loss: 0.070520, Train Acc: 0.885897 | Val Loss: 0.109318, Val Acc: 0.783505\n",
      "Epoch 29814 - Train Loss: 0.070518, Train Acc: 0.885897 | Val Loss: 0.109318, Val Acc: 0.783505\n",
      "Epoch 29815 - Train Loss: 0.070517, Train Acc: 0.885897 | Val Loss: 0.109318, Val Acc: 0.783505\n",
      "Epoch 29816 - Train Loss: 0.070516, Train Acc: 0.885897 | Val Loss: 0.109317, Val Acc: 0.783505\n",
      "Epoch 29817 - Train Loss: 0.070515, Train Acc: 0.885897 | Val Loss: 0.109317, Val Acc: 0.783505\n",
      "Epoch 29818 - Train Loss: 0.070513, Train Acc: 0.885897 | Val Loss: 0.109317, Val Acc: 0.783505\n",
      "Epoch 29819 - Train Loss: 0.070512, Train Acc: 0.885897 | Val Loss: 0.109317, Val Acc: 0.783505\n",
      "Epoch 29820 - Train Loss: 0.070511, Train Acc: 0.885897 | Val Loss: 0.109316, Val Acc: 0.783505\n",
      "Epoch 29821 - Train Loss: 0.070510, Train Acc: 0.885897 | Val Loss: 0.109316, Val Acc: 0.783505\n",
      "Epoch 29822 - Train Loss: 0.070508, Train Acc: 0.885897 | Val Loss: 0.109316, Val Acc: 0.783505\n",
      "Epoch 29823 - Train Loss: 0.070507, Train Acc: 0.885897 | Val Loss: 0.109316, Val Acc: 0.783505\n",
      "Epoch 29824 - Train Loss: 0.070506, Train Acc: 0.885897 | Val Loss: 0.109315, Val Acc: 0.783505\n",
      "Epoch 29825 - Train Loss: 0.070505, Train Acc: 0.885897 | Val Loss: 0.109315, Val Acc: 0.783505\n",
      "Epoch 29826 - Train Loss: 0.070504, Train Acc: 0.885897 | Val Loss: 0.109315, Val Acc: 0.783505\n",
      "Epoch 29827 - Train Loss: 0.070502, Train Acc: 0.885897 | Val Loss: 0.109314, Val Acc: 0.783505\n",
      "Epoch 29828 - Train Loss: 0.070501, Train Acc: 0.885897 | Val Loss: 0.109314, Val Acc: 0.783505\n",
      "Epoch 29829 - Train Loss: 0.070500, Train Acc: 0.885897 | Val Loss: 0.109314, Val Acc: 0.783505\n",
      "Epoch 29830 - Train Loss: 0.070499, Train Acc: 0.885897 | Val Loss: 0.109314, Val Acc: 0.783505\n",
      "Epoch 29831 - Train Loss: 0.070497, Train Acc: 0.885897 | Val Loss: 0.109313, Val Acc: 0.783505\n",
      "Epoch 29832 - Train Loss: 0.070496, Train Acc: 0.885897 | Val Loss: 0.109313, Val Acc: 0.783505\n",
      "Epoch 29833 - Train Loss: 0.070495, Train Acc: 0.885897 | Val Loss: 0.109313, Val Acc: 0.783505\n",
      "Epoch 29834 - Train Loss: 0.070494, Train Acc: 0.885897 | Val Loss: 0.109313, Val Acc: 0.783505\n",
      "Epoch 29835 - Train Loss: 0.070493, Train Acc: 0.885897 | Val Loss: 0.109312, Val Acc: 0.783505\n",
      "Epoch 29836 - Train Loss: 0.070491, Train Acc: 0.885897 | Val Loss: 0.109312, Val Acc: 0.783505\n",
      "Epoch 29837 - Train Loss: 0.070490, Train Acc: 0.885897 | Val Loss: 0.109312, Val Acc: 0.783505\n",
      "Epoch 29838 - Train Loss: 0.070489, Train Acc: 0.885897 | Val Loss: 0.109312, Val Acc: 0.783505\n",
      "Epoch 29839 - Train Loss: 0.070488, Train Acc: 0.885897 | Val Loss: 0.109311, Val Acc: 0.783505\n",
      "Epoch 29840 - Train Loss: 0.070486, Train Acc: 0.885897 | Val Loss: 0.109311, Val Acc: 0.783505\n",
      "Epoch 29841 - Train Loss: 0.070485, Train Acc: 0.885897 | Val Loss: 0.109311, Val Acc: 0.783505\n",
      "Epoch 29842 - Train Loss: 0.070484, Train Acc: 0.885897 | Val Loss: 0.109311, Val Acc: 0.783505\n",
      "Epoch 29843 - Train Loss: 0.070483, Train Acc: 0.885897 | Val Loss: 0.109310, Val Acc: 0.783505\n",
      "Epoch 29844 - Train Loss: 0.070481, Train Acc: 0.885897 | Val Loss: 0.109310, Val Acc: 0.783505\n",
      "Epoch 29845 - Train Loss: 0.070480, Train Acc: 0.885897 | Val Loss: 0.109310, Val Acc: 0.783505\n",
      "Epoch 29846 - Train Loss: 0.070479, Train Acc: 0.885897 | Val Loss: 0.109310, Val Acc: 0.783505\n",
      "Epoch 29847 - Train Loss: 0.070478, Train Acc: 0.885897 | Val Loss: 0.109309, Val Acc: 0.783505\n",
      "Epoch 29848 - Train Loss: 0.070477, Train Acc: 0.885897 | Val Loss: 0.109309, Val Acc: 0.783505\n",
      "Epoch 29849 - Train Loss: 0.070475, Train Acc: 0.885897 | Val Loss: 0.109309, Val Acc: 0.783505\n",
      "Epoch 29850 - Train Loss: 0.070474, Train Acc: 0.885897 | Val Loss: 0.109309, Val Acc: 0.783505\n",
      "Epoch 29851 - Train Loss: 0.070473, Train Acc: 0.885897 | Val Loss: 0.109308, Val Acc: 0.783505\n",
      "Epoch 29852 - Train Loss: 0.070472, Train Acc: 0.885897 | Val Loss: 0.109308, Val Acc: 0.783505\n",
      "Epoch 29853 - Train Loss: 0.070470, Train Acc: 0.885897 | Val Loss: 0.109308, Val Acc: 0.783505\n",
      "Epoch 29854 - Train Loss: 0.070469, Train Acc: 0.885897 | Val Loss: 0.109308, Val Acc: 0.783505\n",
      "Epoch 29855 - Train Loss: 0.070468, Train Acc: 0.885897 | Val Loss: 0.109307, Val Acc: 0.783505\n",
      "Epoch 29856 - Train Loss: 0.070467, Train Acc: 0.885897 | Val Loss: 0.109307, Val Acc: 0.783505\n",
      "Epoch 29857 - Train Loss: 0.070466, Train Acc: 0.885897 | Val Loss: 0.109307, Val Acc: 0.783505\n",
      "Epoch 29858 - Train Loss: 0.070464, Train Acc: 0.885897 | Val Loss: 0.109306, Val Acc: 0.783505\n",
      "Epoch 29859 - Train Loss: 0.070463, Train Acc: 0.885897 | Val Loss: 0.109306, Val Acc: 0.783505\n",
      "Epoch 29860 - Train Loss: 0.070462, Train Acc: 0.885897 | Val Loss: 0.109306, Val Acc: 0.783505\n",
      "Epoch 29861 - Train Loss: 0.070461, Train Acc: 0.885897 | Val Loss: 0.109306, Val Acc: 0.783505\n",
      "Epoch 29862 - Train Loss: 0.070459, Train Acc: 0.885897 | Val Loss: 0.109305, Val Acc: 0.783505\n",
      "Epoch 29863 - Train Loss: 0.070458, Train Acc: 0.885897 | Val Loss: 0.109305, Val Acc: 0.783505\n",
      "Epoch 29864 - Train Loss: 0.070457, Train Acc: 0.885897 | Val Loss: 0.109305, Val Acc: 0.783505\n",
      "Epoch 29865 - Train Loss: 0.070456, Train Acc: 0.885897 | Val Loss: 0.109305, Val Acc: 0.783505\n",
      "Epoch 29866 - Train Loss: 0.070455, Train Acc: 0.885897 | Val Loss: 0.109304, Val Acc: 0.783505\n",
      "Epoch 29867 - Train Loss: 0.070453, Train Acc: 0.885897 | Val Loss: 0.109304, Val Acc: 0.783505\n",
      "Epoch 29868 - Train Loss: 0.070452, Train Acc: 0.885897 | Val Loss: 0.109304, Val Acc: 0.783505\n",
      "Epoch 29869 - Train Loss: 0.070451, Train Acc: 0.885897 | Val Loss: 0.109304, Val Acc: 0.783505\n",
      "Epoch 29870 - Train Loss: 0.070450, Train Acc: 0.885897 | Val Loss: 0.109303, Val Acc: 0.783505\n",
      "Epoch 29871 - Train Loss: 0.070448, Train Acc: 0.885897 | Val Loss: 0.109303, Val Acc: 0.783505\n",
      "Epoch 29872 - Train Loss: 0.070447, Train Acc: 0.885897 | Val Loss: 0.109303, Val Acc: 0.783505\n",
      "Epoch 29873 - Train Loss: 0.070446, Train Acc: 0.885897 | Val Loss: 0.109303, Val Acc: 0.783505\n",
      "Epoch 29874 - Train Loss: 0.070445, Train Acc: 0.885897 | Val Loss: 0.109302, Val Acc: 0.783505\n",
      "Epoch 29875 - Train Loss: 0.070443, Train Acc: 0.885897 | Val Loss: 0.109302, Val Acc: 0.783505\n",
      "Epoch 29876 - Train Loss: 0.070442, Train Acc: 0.885897 | Val Loss: 0.109302, Val Acc: 0.783505\n",
      "Epoch 29877 - Train Loss: 0.070441, Train Acc: 0.885897 | Val Loss: 0.109302, Val Acc: 0.783505\n",
      "Epoch 29878 - Train Loss: 0.070440, Train Acc: 0.885897 | Val Loss: 0.109301, Val Acc: 0.783505\n",
      "Epoch 29879 - Train Loss: 0.070439, Train Acc: 0.885897 | Val Loss: 0.109301, Val Acc: 0.783505\n",
      "Epoch 29880 - Train Loss: 0.070437, Train Acc: 0.885897 | Val Loss: 0.109301, Val Acc: 0.783505\n",
      "Epoch 29881 - Train Loss: 0.070436, Train Acc: 0.885897 | Val Loss: 0.109301, Val Acc: 0.783505\n",
      "Epoch 29882 - Train Loss: 0.070435, Train Acc: 0.885897 | Val Loss: 0.109300, Val Acc: 0.783505\n",
      "Epoch 29883 - Train Loss: 0.070434, Train Acc: 0.885897 | Val Loss: 0.109300, Val Acc: 0.783505\n",
      "Epoch 29884 - Train Loss: 0.070432, Train Acc: 0.885897 | Val Loss: 0.109300, Val Acc: 0.783505\n",
      "Epoch 29885 - Train Loss: 0.070431, Train Acc: 0.885897 | Val Loss: 0.109300, Val Acc: 0.783505\n",
      "Epoch 29886 - Train Loss: 0.070430, Train Acc: 0.885897 | Val Loss: 0.109299, Val Acc: 0.783505\n",
      "Epoch 29887 - Train Loss: 0.070429, Train Acc: 0.885897 | Val Loss: 0.109299, Val Acc: 0.783505\n",
      "Epoch 29888 - Train Loss: 0.070428, Train Acc: 0.885897 | Val Loss: 0.109299, Val Acc: 0.783505\n",
      "Epoch 29889 - Train Loss: 0.070426, Train Acc: 0.885897 | Val Loss: 0.109299, Val Acc: 0.783505\n",
      "Epoch 29890 - Train Loss: 0.070425, Train Acc: 0.885897 | Val Loss: 0.109298, Val Acc: 0.783505\n",
      "Epoch 29891 - Train Loss: 0.070424, Train Acc: 0.885897 | Val Loss: 0.109298, Val Acc: 0.783505\n",
      "Epoch 29892 - Train Loss: 0.070423, Train Acc: 0.885897 | Val Loss: 0.109298, Val Acc: 0.783505\n",
      "Epoch 29893 - Train Loss: 0.070421, Train Acc: 0.885897 | Val Loss: 0.109298, Val Acc: 0.783505\n",
      "Epoch 29894 - Train Loss: 0.070420, Train Acc: 0.885897 | Val Loss: 0.109297, Val Acc: 0.783505\n",
      "Epoch 29895 - Train Loss: 0.070419, Train Acc: 0.885897 | Val Loss: 0.109297, Val Acc: 0.783505\n",
      "Epoch 29896 - Train Loss: 0.070418, Train Acc: 0.885897 | Val Loss: 0.109297, Val Acc: 0.783505\n",
      "Epoch 29897 - Train Loss: 0.070417, Train Acc: 0.885897 | Val Loss: 0.109297, Val Acc: 0.783505\n",
      "Epoch 29898 - Train Loss: 0.070415, Train Acc: 0.885897 | Val Loss: 0.109296, Val Acc: 0.783505\n",
      "Epoch 29899 - Train Loss: 0.070414, Train Acc: 0.885897 | Val Loss: 0.109296, Val Acc: 0.783505\n",
      "Epoch 29900 - Train Loss: 0.070413, Train Acc: 0.885897 | Val Loss: 0.109296, Val Acc: 0.783505\n",
      "Epoch 29901 - Train Loss: 0.070412, Train Acc: 0.885897 | Val Loss: 0.109296, Val Acc: 0.783505\n",
      "Epoch 29902 - Train Loss: 0.070410, Train Acc: 0.885897 | Val Loss: 0.109295, Val Acc: 0.783505\n",
      "Epoch 29903 - Train Loss: 0.070409, Train Acc: 0.885897 | Val Loss: 0.109295, Val Acc: 0.783505\n",
      "Epoch 29904 - Train Loss: 0.070408, Train Acc: 0.885897 | Val Loss: 0.109295, Val Acc: 0.783505\n",
      "Epoch 29905 - Train Loss: 0.070407, Train Acc: 0.885897 | Val Loss: 0.109294, Val Acc: 0.783505\n",
      "Epoch 29906 - Train Loss: 0.070406, Train Acc: 0.885897 | Val Loss: 0.109294, Val Acc: 0.783505\n",
      "Epoch 29907 - Train Loss: 0.070404, Train Acc: 0.885897 | Val Loss: 0.109294, Val Acc: 0.783505\n",
      "Epoch 29908 - Train Loss: 0.070403, Train Acc: 0.885897 | Val Loss: 0.109294, Val Acc: 0.783505\n",
      "Epoch 29909 - Train Loss: 0.070402, Train Acc: 0.885897 | Val Loss: 0.109293, Val Acc: 0.783505\n",
      "Epoch 29910 - Train Loss: 0.070401, Train Acc: 0.885897 | Val Loss: 0.109293, Val Acc: 0.783505\n",
      "Epoch 29911 - Train Loss: 0.070399, Train Acc: 0.885897 | Val Loss: 0.109293, Val Acc: 0.783505\n",
      "Epoch 29912 - Train Loss: 0.070398, Train Acc: 0.885897 | Val Loss: 0.109293, Val Acc: 0.783505\n",
      "Epoch 29913 - Train Loss: 0.070397, Train Acc: 0.885897 | Val Loss: 0.109292, Val Acc: 0.783505\n",
      "Epoch 29914 - Train Loss: 0.070396, Train Acc: 0.885897 | Val Loss: 0.109292, Val Acc: 0.783505\n",
      "Epoch 29915 - Train Loss: 0.070395, Train Acc: 0.885897 | Val Loss: 0.109292, Val Acc: 0.783505\n",
      "Epoch 29916 - Train Loss: 0.070393, Train Acc: 0.885897 | Val Loss: 0.109292, Val Acc: 0.783505\n",
      "Epoch 29917 - Train Loss: 0.070392, Train Acc: 0.885897 | Val Loss: 0.109291, Val Acc: 0.783505\n",
      "Epoch 29918 - Train Loss: 0.070391, Train Acc: 0.885897 | Val Loss: 0.109291, Val Acc: 0.783505\n",
      "Epoch 29919 - Train Loss: 0.070390, Train Acc: 0.885897 | Val Loss: 0.109291, Val Acc: 0.783505\n",
      "Epoch 29920 - Train Loss: 0.070388, Train Acc: 0.885897 | Val Loss: 0.109291, Val Acc: 0.783505\n",
      "Epoch 29921 - Train Loss: 0.070387, Train Acc: 0.885897 | Val Loss: 0.109290, Val Acc: 0.783505\n",
      "Epoch 29922 - Train Loss: 0.070386, Train Acc: 0.885897 | Val Loss: 0.109290, Val Acc: 0.783505\n",
      "Epoch 29923 - Train Loss: 0.070385, Train Acc: 0.885897 | Val Loss: 0.109290, Val Acc: 0.783505\n",
      "Epoch 29924 - Train Loss: 0.070384, Train Acc: 0.885897 | Val Loss: 0.109290, Val Acc: 0.783505\n",
      "Epoch 29925 - Train Loss: 0.070382, Train Acc: 0.885897 | Val Loss: 0.109289, Val Acc: 0.783505\n",
      "Epoch 29926 - Train Loss: 0.070381, Train Acc: 0.885897 | Val Loss: 0.109289, Val Acc: 0.783505\n",
      "Epoch 29927 - Train Loss: 0.070380, Train Acc: 0.885897 | Val Loss: 0.109289, Val Acc: 0.783505\n",
      "Epoch 29928 - Train Loss: 0.070379, Train Acc: 0.885897 | Val Loss: 0.109289, Val Acc: 0.783505\n",
      "Epoch 29929 - Train Loss: 0.070377, Train Acc: 0.885897 | Val Loss: 0.109288, Val Acc: 0.783505\n",
      "Epoch 29930 - Train Loss: 0.070376, Train Acc: 0.885897 | Val Loss: 0.109288, Val Acc: 0.783505\n",
      "Epoch 29931 - Train Loss: 0.070375, Train Acc: 0.885897 | Val Loss: 0.109288, Val Acc: 0.783505\n",
      "Epoch 29932 - Train Loss: 0.070374, Train Acc: 0.885897 | Val Loss: 0.109288, Val Acc: 0.783505\n",
      "Epoch 29933 - Train Loss: 0.070373, Train Acc: 0.885897 | Val Loss: 0.109287, Val Acc: 0.783505\n",
      "Epoch 29934 - Train Loss: 0.070371, Train Acc: 0.885897 | Val Loss: 0.109287, Val Acc: 0.783505\n",
      "Epoch 29935 - Train Loss: 0.070370, Train Acc: 0.885897 | Val Loss: 0.109287, Val Acc: 0.783505\n",
      "Epoch 29936 - Train Loss: 0.070369, Train Acc: 0.885897 | Val Loss: 0.109287, Val Acc: 0.783505\n",
      "Epoch 29937 - Train Loss: 0.070368, Train Acc: 0.885897 | Val Loss: 0.109286, Val Acc: 0.783505\n",
      "Epoch 29938 - Train Loss: 0.070366, Train Acc: 0.885897 | Val Loss: 0.109286, Val Acc: 0.783505\n",
      "Epoch 29939 - Train Loss: 0.070365, Train Acc: 0.885897 | Val Loss: 0.109286, Val Acc: 0.783505\n",
      "Epoch 29940 - Train Loss: 0.070364, Train Acc: 0.885897 | Val Loss: 0.109286, Val Acc: 0.783505\n",
      "Epoch 29941 - Train Loss: 0.070363, Train Acc: 0.885897 | Val Loss: 0.109285, Val Acc: 0.783505\n",
      "Epoch 29942 - Train Loss: 0.070362, Train Acc: 0.885897 | Val Loss: 0.109285, Val Acc: 0.783505\n",
      "Epoch 29943 - Train Loss: 0.070360, Train Acc: 0.885897 | Val Loss: 0.109285, Val Acc: 0.783505\n",
      "Epoch 29944 - Train Loss: 0.070359, Train Acc: 0.885897 | Val Loss: 0.109285, Val Acc: 0.783505\n",
      "Epoch 29945 - Train Loss: 0.070358, Train Acc: 0.885897 | Val Loss: 0.109284, Val Acc: 0.783505\n",
      "Epoch 29946 - Train Loss: 0.070357, Train Acc: 0.885897 | Val Loss: 0.109284, Val Acc: 0.783505\n",
      "Epoch 29947 - Train Loss: 0.070355, Train Acc: 0.885897 | Val Loss: 0.109284, Val Acc: 0.783505\n",
      "Epoch 29948 - Train Loss: 0.070354, Train Acc: 0.885897 | Val Loss: 0.109283, Val Acc: 0.783505\n",
      "Epoch 29949 - Train Loss: 0.070353, Train Acc: 0.885897 | Val Loss: 0.109283, Val Acc: 0.783505\n",
      "Epoch 29950 - Train Loss: 0.070352, Train Acc: 0.885897 | Val Loss: 0.109283, Val Acc: 0.783505\n",
      "Epoch 29951 - Train Loss: 0.070351, Train Acc: 0.885897 | Val Loss: 0.109283, Val Acc: 0.783505\n",
      "Epoch 29952 - Train Loss: 0.070349, Train Acc: 0.885897 | Val Loss: 0.109282, Val Acc: 0.783505\n",
      "Epoch 29953 - Train Loss: 0.070348, Train Acc: 0.885897 | Val Loss: 0.109282, Val Acc: 0.783505\n",
      "Epoch 29954 - Train Loss: 0.070347, Train Acc: 0.885897 | Val Loss: 0.109282, Val Acc: 0.783505\n",
      "Epoch 29955 - Train Loss: 0.070346, Train Acc: 0.885897 | Val Loss: 0.109282, Val Acc: 0.783505\n",
      "Epoch 29956 - Train Loss: 0.070344, Train Acc: 0.885897 | Val Loss: 0.109281, Val Acc: 0.783505\n",
      "Epoch 29957 - Train Loss: 0.070343, Train Acc: 0.885897 | Val Loss: 0.109281, Val Acc: 0.783505\n",
      "Epoch 29958 - Train Loss: 0.070342, Train Acc: 0.885897 | Val Loss: 0.109281, Val Acc: 0.783505\n",
      "Epoch 29959 - Train Loss: 0.070341, Train Acc: 0.885897 | Val Loss: 0.109281, Val Acc: 0.783505\n",
      "Epoch 29960 - Train Loss: 0.070340, Train Acc: 0.885897 | Val Loss: 0.109280, Val Acc: 0.783505\n",
      "Epoch 29961 - Train Loss: 0.070338, Train Acc: 0.885897 | Val Loss: 0.109280, Val Acc: 0.783505\n",
      "Epoch 29962 - Train Loss: 0.070337, Train Acc: 0.885897 | Val Loss: 0.109280, Val Acc: 0.783505\n",
      "Epoch 29963 - Train Loss: 0.070336, Train Acc: 0.885897 | Val Loss: 0.109280, Val Acc: 0.783505\n",
      "Epoch 29964 - Train Loss: 0.070335, Train Acc: 0.885897 | Val Loss: 0.109279, Val Acc: 0.783505\n",
      "Epoch 29965 - Train Loss: 0.070333, Train Acc: 0.885897 | Val Loss: 0.109279, Val Acc: 0.783505\n",
      "Epoch 29966 - Train Loss: 0.070332, Train Acc: 0.885897 | Val Loss: 0.109279, Val Acc: 0.783505\n",
      "Epoch 29967 - Train Loss: 0.070331, Train Acc: 0.885897 | Val Loss: 0.109279, Val Acc: 0.783505\n",
      "Epoch 29968 - Train Loss: 0.070330, Train Acc: 0.885897 | Val Loss: 0.109278, Val Acc: 0.783505\n",
      "Epoch 29969 - Train Loss: 0.070329, Train Acc: 0.885897 | Val Loss: 0.109278, Val Acc: 0.783505\n",
      "Epoch 29970 - Train Loss: 0.070327, Train Acc: 0.885897 | Val Loss: 0.109278, Val Acc: 0.783505\n",
      "Epoch 29971 - Train Loss: 0.070326, Train Acc: 0.885897 | Val Loss: 0.109278, Val Acc: 0.783505\n",
      "Epoch 29972 - Train Loss: 0.070325, Train Acc: 0.885897 | Val Loss: 0.109277, Val Acc: 0.783505\n",
      "Epoch 29973 - Train Loss: 0.070324, Train Acc: 0.885897 | Val Loss: 0.109277, Val Acc: 0.783505\n",
      "Epoch 29974 - Train Loss: 0.070323, Train Acc: 0.885897 | Val Loss: 0.109277, Val Acc: 0.783505\n",
      "Epoch 29975 - Train Loss: 0.070321, Train Acc: 0.885897 | Val Loss: 0.109277, Val Acc: 0.783505\n",
      "Epoch 29976 - Train Loss: 0.070320, Train Acc: 0.885897 | Val Loss: 0.109276, Val Acc: 0.783505\n",
      "Epoch 29977 - Train Loss: 0.070319, Train Acc: 0.885897 | Val Loss: 0.109276, Val Acc: 0.783505\n",
      "Epoch 29978 - Train Loss: 0.070318, Train Acc: 0.885897 | Val Loss: 0.109276, Val Acc: 0.783505\n",
      "Epoch 29979 - Train Loss: 0.070316, Train Acc: 0.885897 | Val Loss: 0.109276, Val Acc: 0.783505\n",
      "Epoch 29980 - Train Loss: 0.070315, Train Acc: 0.885897 | Val Loss: 0.109275, Val Acc: 0.783505\n",
      "Epoch 29981 - Train Loss: 0.070314, Train Acc: 0.885897 | Val Loss: 0.109275, Val Acc: 0.783505\n",
      "Epoch 29982 - Train Loss: 0.070313, Train Acc: 0.885897 | Val Loss: 0.109275, Val Acc: 0.783505\n",
      "Epoch 29983 - Train Loss: 0.070312, Train Acc: 0.885897 | Val Loss: 0.109275, Val Acc: 0.783505\n",
      "Epoch 29984 - Train Loss: 0.070310, Train Acc: 0.885897 | Val Loss: 0.109274, Val Acc: 0.783505\n",
      "Epoch 29985 - Train Loss: 0.070309, Train Acc: 0.885897 | Val Loss: 0.109274, Val Acc: 0.783505\n",
      "Epoch 29986 - Train Loss: 0.070308, Train Acc: 0.885897 | Val Loss: 0.109274, Val Acc: 0.783505\n",
      "Epoch 29987 - Train Loss: 0.070307, Train Acc: 0.885897 | Val Loss: 0.109274, Val Acc: 0.783505\n",
      "Epoch 29988 - Train Loss: 0.070305, Train Acc: 0.885897 | Val Loss: 0.109273, Val Acc: 0.783505\n",
      "Epoch 29989 - Train Loss: 0.070304, Train Acc: 0.885897 | Val Loss: 0.109273, Val Acc: 0.783505\n",
      "Epoch 29990 - Train Loss: 0.070303, Train Acc: 0.885897 | Val Loss: 0.109273, Val Acc: 0.783505\n",
      "Epoch 29991 - Train Loss: 0.070302, Train Acc: 0.885897 | Val Loss: 0.109273, Val Acc: 0.783505\n",
      "Epoch 29992 - Train Loss: 0.070301, Train Acc: 0.885897 | Val Loss: 0.109272, Val Acc: 0.783505\n",
      "Epoch 29993 - Train Loss: 0.070299, Train Acc: 0.885897 | Val Loss: 0.109272, Val Acc: 0.783505\n",
      "Epoch 29994 - Train Loss: 0.070298, Train Acc: 0.885897 | Val Loss: 0.109272, Val Acc: 0.783505\n",
      "Epoch 29995 - Train Loss: 0.070297, Train Acc: 0.885897 | Val Loss: 0.109272, Val Acc: 0.783505\n",
      "Epoch 29996 - Train Loss: 0.070296, Train Acc: 0.885897 | Val Loss: 0.109271, Val Acc: 0.783505\n",
      "Epoch 29997 - Train Loss: 0.070294, Train Acc: 0.885897 | Val Loss: 0.109271, Val Acc: 0.783505\n",
      "Epoch 29998 - Train Loss: 0.070293, Train Acc: 0.885897 | Val Loss: 0.109271, Val Acc: 0.783505\n",
      "Epoch 29999 - Train Loss: 0.070292, Train Acc: 0.885897 | Val Loss: 0.109271, Val Acc: 0.783505\n",
      "Epoch 30000 - Train Loss: 0.070291, Train Acc: 0.885897 | Val Loss: 0.109270, Val Acc: 0.783505\n",
      "Epoch 30001 - Train Loss: 0.070290, Train Acc: 0.885897 | Val Loss: 0.109270, Val Acc: 0.783505\n",
      "Epoch 30002 - Train Loss: 0.070288, Train Acc: 0.885897 | Val Loss: 0.109270, Val Acc: 0.783505\n",
      "Epoch 30003 - Train Loss: 0.070287, Train Acc: 0.885897 | Val Loss: 0.109270, Val Acc: 0.783505\n",
      "Epoch 30004 - Train Loss: 0.070286, Train Acc: 0.885897 | Val Loss: 0.109269, Val Acc: 0.783505\n",
      "Epoch 30005 - Train Loss: 0.070285, Train Acc: 0.885897 | Val Loss: 0.109269, Val Acc: 0.783505\n",
      "Epoch 30006 - Train Loss: 0.070284, Train Acc: 0.885897 | Val Loss: 0.109269, Val Acc: 0.783505\n",
      "Epoch 30007 - Train Loss: 0.070282, Train Acc: 0.885897 | Val Loss: 0.109269, Val Acc: 0.783505\n",
      "Epoch 30008 - Train Loss: 0.070281, Train Acc: 0.885897 | Val Loss: 0.109268, Val Acc: 0.783505\n",
      "Epoch 30009 - Train Loss: 0.070280, Train Acc: 0.885897 | Val Loss: 0.109268, Val Acc: 0.783505\n",
      "Epoch 30010 - Train Loss: 0.070279, Train Acc: 0.885897 | Val Loss: 0.109268, Val Acc: 0.783505\n",
      "Epoch 30011 - Train Loss: 0.070277, Train Acc: 0.885897 | Val Loss: 0.109268, Val Acc: 0.783505\n",
      "Epoch 30012 - Train Loss: 0.070276, Train Acc: 0.885897 | Val Loss: 0.109267, Val Acc: 0.783505\n",
      "Epoch 30013 - Train Loss: 0.070275, Train Acc: 0.885897 | Val Loss: 0.109267, Val Acc: 0.783505\n",
      "Epoch 30014 - Train Loss: 0.070274, Train Acc: 0.885897 | Val Loss: 0.109267, Val Acc: 0.783505\n",
      "Epoch 30015 - Train Loss: 0.070273, Train Acc: 0.885897 | Val Loss: 0.109267, Val Acc: 0.783505\n",
      "Epoch 30016 - Train Loss: 0.070271, Train Acc: 0.885897 | Val Loss: 0.109266, Val Acc: 0.783505\n",
      "Epoch 30017 - Train Loss: 0.070270, Train Acc: 0.885897 | Val Loss: 0.109266, Val Acc: 0.783505\n",
      "Epoch 30018 - Train Loss: 0.070269, Train Acc: 0.885897 | Val Loss: 0.109266, Val Acc: 0.783505\n",
      "Epoch 30019 - Train Loss: 0.070268, Train Acc: 0.885897 | Val Loss: 0.109266, Val Acc: 0.783505\n",
      "Epoch 30020 - Train Loss: 0.070267, Train Acc: 0.885897 | Val Loss: 0.109265, Val Acc: 0.783505\n",
      "Epoch 30021 - Train Loss: 0.070265, Train Acc: 0.885897 | Val Loss: 0.109265, Val Acc: 0.783505\n",
      "Epoch 30022 - Train Loss: 0.070264, Train Acc: 0.885897 | Val Loss: 0.109265, Val Acc: 0.783505\n",
      "Epoch 30023 - Train Loss: 0.070263, Train Acc: 0.885897 | Val Loss: 0.109265, Val Acc: 0.783505\n",
      "Epoch 30024 - Train Loss: 0.070262, Train Acc: 0.885897 | Val Loss: 0.109264, Val Acc: 0.783505\n",
      "Epoch 30025 - Train Loss: 0.070260, Train Acc: 0.885897 | Val Loss: 0.109264, Val Acc: 0.783505\n",
      "Epoch 30026 - Train Loss: 0.070259, Train Acc: 0.885897 | Val Loss: 0.109264, Val Acc: 0.783505\n",
      "Epoch 30027 - Train Loss: 0.070258, Train Acc: 0.885897 | Val Loss: 0.109264, Val Acc: 0.783505\n",
      "Epoch 30028 - Train Loss: 0.070257, Train Acc: 0.885897 | Val Loss: 0.109263, Val Acc: 0.783505\n",
      "Epoch 30029 - Train Loss: 0.070256, Train Acc: 0.885897 | Val Loss: 0.109263, Val Acc: 0.783505\n",
      "Epoch 30030 - Train Loss: 0.070254, Train Acc: 0.885897 | Val Loss: 0.109263, Val Acc: 0.783505\n",
      "Epoch 30031 - Train Loss: 0.070253, Train Acc: 0.885897 | Val Loss: 0.109263, Val Acc: 0.783505\n",
      "Epoch 30032 - Train Loss: 0.070252, Train Acc: 0.885897 | Val Loss: 0.109262, Val Acc: 0.783505\n",
      "Epoch 30033 - Train Loss: 0.070251, Train Acc: 0.885897 | Val Loss: 0.109262, Val Acc: 0.783505\n",
      "Epoch 30034 - Train Loss: 0.070249, Train Acc: 0.885897 | Val Loss: 0.109262, Val Acc: 0.783505\n",
      "Epoch 30035 - Train Loss: 0.070248, Train Acc: 0.885897 | Val Loss: 0.109262, Val Acc: 0.783505\n",
      "Epoch 30036 - Train Loss: 0.070247, Train Acc: 0.885897 | Val Loss: 0.109261, Val Acc: 0.783505\n",
      "Epoch 30037 - Train Loss: 0.070246, Train Acc: 0.885897 | Val Loss: 0.109261, Val Acc: 0.783505\n",
      "Epoch 30038 - Train Loss: 0.070245, Train Acc: 0.885897 | Val Loss: 0.109261, Val Acc: 0.783505\n",
      "Epoch 30039 - Train Loss: 0.070243, Train Acc: 0.885897 | Val Loss: 0.109261, Val Acc: 0.783505\n",
      "Epoch 30040 - Train Loss: 0.070242, Train Acc: 0.885897 | Val Loss: 0.109260, Val Acc: 0.783505\n",
      "Epoch 30041 - Train Loss: 0.070241, Train Acc: 0.885897 | Val Loss: 0.109260, Val Acc: 0.783505\n",
      "Epoch 30042 - Train Loss: 0.070240, Train Acc: 0.885897 | Val Loss: 0.109260, Val Acc: 0.783505\n",
      "Epoch 30043 - Train Loss: 0.070239, Train Acc: 0.885897 | Val Loss: 0.109260, Val Acc: 0.783505\n",
      "Epoch 30044 - Train Loss: 0.070237, Train Acc: 0.885897 | Val Loss: 0.109259, Val Acc: 0.783505\n",
      "Epoch 30045 - Train Loss: 0.070236, Train Acc: 0.885897 | Val Loss: 0.109259, Val Acc: 0.783505\n",
      "Epoch 30046 - Train Loss: 0.070235, Train Acc: 0.885897 | Val Loss: 0.109259, Val Acc: 0.783505\n",
      "Epoch 30047 - Train Loss: 0.070234, Train Acc: 0.885897 | Val Loss: 0.109259, Val Acc: 0.783505\n",
      "Epoch 30048 - Train Loss: 0.070232, Train Acc: 0.885897 | Val Loss: 0.109258, Val Acc: 0.783505\n",
      "Epoch 30049 - Train Loss: 0.070231, Train Acc: 0.885897 | Val Loss: 0.109258, Val Acc: 0.783505\n",
      "Epoch 30050 - Train Loss: 0.070230, Train Acc: 0.885897 | Val Loss: 0.109258, Val Acc: 0.783505\n",
      "Epoch 30051 - Train Loss: 0.070229, Train Acc: 0.885897 | Val Loss: 0.109258, Val Acc: 0.783505\n",
      "Epoch 30052 - Train Loss: 0.070228, Train Acc: 0.885897 | Val Loss: 0.109257, Val Acc: 0.783505\n",
      "Epoch 30053 - Train Loss: 0.070226, Train Acc: 0.885897 | Val Loss: 0.109257, Val Acc: 0.783505\n",
      "Epoch 30054 - Train Loss: 0.070225, Train Acc: 0.885897 | Val Loss: 0.109257, Val Acc: 0.783505\n",
      "Epoch 30055 - Train Loss: 0.070224, Train Acc: 0.885897 | Val Loss: 0.109257, Val Acc: 0.783505\n",
      "Epoch 30056 - Train Loss: 0.070223, Train Acc: 0.885897 | Val Loss: 0.109256, Val Acc: 0.783505\n",
      "Epoch 30057 - Train Loss: 0.070222, Train Acc: 0.885897 | Val Loss: 0.109256, Val Acc: 0.783505\n",
      "Epoch 30058 - Train Loss: 0.070220, Train Acc: 0.885897 | Val Loss: 0.109256, Val Acc: 0.783505\n",
      "Epoch 30059 - Train Loss: 0.070219, Train Acc: 0.885897 | Val Loss: 0.109256, Val Acc: 0.783505\n",
      "Epoch 30060 - Train Loss: 0.070218, Train Acc: 0.885897 | Val Loss: 0.109255, Val Acc: 0.783505\n",
      "Epoch 30061 - Train Loss: 0.070217, Train Acc: 0.885897 | Val Loss: 0.109255, Val Acc: 0.783505\n",
      "Epoch 30062 - Train Loss: 0.070215, Train Acc: 0.885897 | Val Loss: 0.109255, Val Acc: 0.783505\n",
      "Epoch 30063 - Train Loss: 0.070214, Train Acc: 0.885897 | Val Loss: 0.109255, Val Acc: 0.783505\n",
      "Epoch 30064 - Train Loss: 0.070213, Train Acc: 0.885897 | Val Loss: 0.109254, Val Acc: 0.783505\n",
      "Epoch 30065 - Train Loss: 0.070212, Train Acc: 0.885897 | Val Loss: 0.109254, Val Acc: 0.783505\n",
      "Epoch 30066 - Train Loss: 0.070211, Train Acc: 0.885897 | Val Loss: 0.109254, Val Acc: 0.783505\n",
      "Epoch 30067 - Train Loss: 0.070209, Train Acc: 0.885897 | Val Loss: 0.109254, Val Acc: 0.783505\n",
      "Epoch 30068 - Train Loss: 0.070208, Train Acc: 0.885897 | Val Loss: 0.109253, Val Acc: 0.783505\n",
      "Epoch 30069 - Train Loss: 0.070207, Train Acc: 0.885897 | Val Loss: 0.109253, Val Acc: 0.783505\n",
      "Epoch 30070 - Train Loss: 0.070206, Train Acc: 0.885897 | Val Loss: 0.109253, Val Acc: 0.783505\n",
      "Epoch 30071 - Train Loss: 0.070205, Train Acc: 0.885897 | Val Loss: 0.109253, Val Acc: 0.783505\n",
      "Epoch 30072 - Train Loss: 0.070203, Train Acc: 0.885897 | Val Loss: 0.109252, Val Acc: 0.783505\n",
      "Epoch 30073 - Train Loss: 0.070202, Train Acc: 0.885897 | Val Loss: 0.109252, Val Acc: 0.783505\n",
      "Epoch 30074 - Train Loss: 0.070201, Train Acc: 0.885897 | Val Loss: 0.109252, Val Acc: 0.783505\n",
      "Epoch 30075 - Train Loss: 0.070200, Train Acc: 0.885897 | Val Loss: 0.109252, Val Acc: 0.783505\n",
      "Epoch 30076 - Train Loss: 0.070198, Train Acc: 0.885897 | Val Loss: 0.109251, Val Acc: 0.783505\n",
      "Epoch 30077 - Train Loss: 0.070197, Train Acc: 0.885897 | Val Loss: 0.109251, Val Acc: 0.783505\n",
      "Epoch 30078 - Train Loss: 0.070196, Train Acc: 0.885897 | Val Loss: 0.109251, Val Acc: 0.783505\n",
      "Epoch 30079 - Train Loss: 0.070195, Train Acc: 0.885897 | Val Loss: 0.109251, Val Acc: 0.783505\n",
      "Epoch 30080 - Train Loss: 0.070194, Train Acc: 0.885897 | Val Loss: 0.109250, Val Acc: 0.783505\n",
      "Epoch 30081 - Train Loss: 0.070192, Train Acc: 0.885897 | Val Loss: 0.109250, Val Acc: 0.783505\n",
      "Epoch 30082 - Train Loss: 0.070191, Train Acc: 0.885897 | Val Loss: 0.109250, Val Acc: 0.783505\n",
      "Epoch 30083 - Train Loss: 0.070190, Train Acc: 0.885897 | Val Loss: 0.109250, Val Acc: 0.783505\n",
      "Epoch 30084 - Train Loss: 0.070189, Train Acc: 0.885897 | Val Loss: 0.109249, Val Acc: 0.783505\n",
      "Epoch 30085 - Train Loss: 0.070188, Train Acc: 0.885897 | Val Loss: 0.109249, Val Acc: 0.783505\n",
      "Epoch 30086 - Train Loss: 0.070186, Train Acc: 0.885897 | Val Loss: 0.109249, Val Acc: 0.783505\n",
      "Epoch 30087 - Train Loss: 0.070185, Train Acc: 0.885897 | Val Loss: 0.109249, Val Acc: 0.783505\n",
      "Epoch 30088 - Train Loss: 0.070184, Train Acc: 0.885897 | Val Loss: 0.109248, Val Acc: 0.783505\n",
      "Epoch 30089 - Train Loss: 0.070183, Train Acc: 0.885897 | Val Loss: 0.109248, Val Acc: 0.783505\n",
      "Epoch 30090 - Train Loss: 0.070181, Train Acc: 0.885897 | Val Loss: 0.109248, Val Acc: 0.783505\n",
      "Epoch 30091 - Train Loss: 0.070180, Train Acc: 0.885897 | Val Loss: 0.109248, Val Acc: 0.783505\n",
      "Epoch 30092 - Train Loss: 0.070179, Train Acc: 0.885897 | Val Loss: 0.109247, Val Acc: 0.783505\n",
      "Epoch 30093 - Train Loss: 0.070178, Train Acc: 0.885897 | Val Loss: 0.109247, Val Acc: 0.783505\n",
      "Epoch 30094 - Train Loss: 0.070177, Train Acc: 0.885897 | Val Loss: 0.109247, Val Acc: 0.783505\n",
      "Epoch 30095 - Train Loss: 0.070175, Train Acc: 0.885897 | Val Loss: 0.109247, Val Acc: 0.783505\n",
      "Epoch 30096 - Train Loss: 0.070174, Train Acc: 0.885897 | Val Loss: 0.109246, Val Acc: 0.783505\n",
      "Epoch 30097 - Train Loss: 0.070173, Train Acc: 0.885897 | Val Loss: 0.109246, Val Acc: 0.783505\n",
      "Epoch 30098 - Train Loss: 0.070172, Train Acc: 0.885897 | Val Loss: 0.109246, Val Acc: 0.783505\n",
      "Epoch 30099 - Train Loss: 0.070171, Train Acc: 0.885897 | Val Loss: 0.109246, Val Acc: 0.783505\n",
      "Epoch 30100 - Train Loss: 0.070169, Train Acc: 0.885897 | Val Loss: 0.109245, Val Acc: 0.783505\n",
      "Epoch 30101 - Train Loss: 0.070168, Train Acc: 0.885897 | Val Loss: 0.109245, Val Acc: 0.783505\n",
      "Epoch 30102 - Train Loss: 0.070167, Train Acc: 0.885897 | Val Loss: 0.109245, Val Acc: 0.783505\n",
      "Epoch 30103 - Train Loss: 0.070166, Train Acc: 0.885897 | Val Loss: 0.109245, Val Acc: 0.783505\n",
      "Epoch 30104 - Train Loss: 0.070165, Train Acc: 0.885897 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 30105 - Train Loss: 0.070163, Train Acc: 0.885897 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 30106 - Train Loss: 0.070162, Train Acc: 0.885897 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 30107 - Train Loss: 0.070161, Train Acc: 0.885897 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 30108 - Train Loss: 0.070160, Train Acc: 0.885897 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 30109 - Train Loss: 0.070158, Train Acc: 0.885897 | Val Loss: 0.109243, Val Acc: 0.783505\n",
      "Epoch 30110 - Train Loss: 0.070157, Train Acc: 0.885897 | Val Loss: 0.109243, Val Acc: 0.783505\n",
      "Epoch 30111 - Train Loss: 0.070156, Train Acc: 0.885897 | Val Loss: 0.109243, Val Acc: 0.783505\n",
      "Epoch 30112 - Train Loss: 0.070155, Train Acc: 0.885897 | Val Loss: 0.109243, Val Acc: 0.783505\n",
      "Epoch 30113 - Train Loss: 0.070154, Train Acc: 0.885897 | Val Loss: 0.109242, Val Acc: 0.783505\n",
      "Epoch 30114 - Train Loss: 0.070152, Train Acc: 0.885897 | Val Loss: 0.109242, Val Acc: 0.783505\n",
      "Epoch 30115 - Train Loss: 0.070151, Train Acc: 0.885897 | Val Loss: 0.109242, Val Acc: 0.783505\n",
      "Epoch 30116 - Train Loss: 0.070150, Train Acc: 0.885897 | Val Loss: 0.109241, Val Acc: 0.783505\n",
      "Epoch 30117 - Train Loss: 0.070149, Train Acc: 0.885897 | Val Loss: 0.109241, Val Acc: 0.783505\n",
      "Epoch 30118 - Train Loss: 0.070148, Train Acc: 0.885897 | Val Loss: 0.109241, Val Acc: 0.783505\n",
      "Epoch 30119 - Train Loss: 0.070146, Train Acc: 0.885897 | Val Loss: 0.109241, Val Acc: 0.783505\n",
      "Epoch 30120 - Train Loss: 0.070145, Train Acc: 0.885897 | Val Loss: 0.109241, Val Acc: 0.783505\n",
      "Epoch 30121 - Train Loss: 0.070144, Train Acc: 0.885897 | Val Loss: 0.109240, Val Acc: 0.783505\n",
      "Epoch 30122 - Train Loss: 0.070143, Train Acc: 0.885897 | Val Loss: 0.109240, Val Acc: 0.783505\n",
      "Epoch 30123 - Train Loss: 0.070141, Train Acc: 0.885897 | Val Loss: 0.109240, Val Acc: 0.783505\n",
      "Epoch 30124 - Train Loss: 0.070140, Train Acc: 0.885897 | Val Loss: 0.109240, Val Acc: 0.783505\n",
      "Epoch 30125 - Train Loss: 0.070139, Train Acc: 0.885897 | Val Loss: 0.109239, Val Acc: 0.783505\n",
      "Epoch 30126 - Train Loss: 0.070138, Train Acc: 0.885897 | Val Loss: 0.109239, Val Acc: 0.783505\n",
      "Epoch 30127 - Train Loss: 0.070137, Train Acc: 0.885897 | Val Loss: 0.109239, Val Acc: 0.783505\n",
      "Epoch 30128 - Train Loss: 0.070135, Train Acc: 0.885897 | Val Loss: 0.109239, Val Acc: 0.783505\n",
      "Epoch 30129 - Train Loss: 0.070134, Train Acc: 0.885897 | Val Loss: 0.109238, Val Acc: 0.783505\n",
      "Epoch 30130 - Train Loss: 0.070133, Train Acc: 0.885897 | Val Loss: 0.109238, Val Acc: 0.783505\n",
      "Epoch 30131 - Train Loss: 0.070132, Train Acc: 0.885897 | Val Loss: 0.109238, Val Acc: 0.783505\n",
      "Epoch 30132 - Train Loss: 0.070131, Train Acc: 0.885897 | Val Loss: 0.109238, Val Acc: 0.783505\n",
      "Epoch 30133 - Train Loss: 0.070129, Train Acc: 0.885897 | Val Loss: 0.109237, Val Acc: 0.783505\n",
      "Epoch 30134 - Train Loss: 0.070128, Train Acc: 0.885897 | Val Loss: 0.109237, Val Acc: 0.783505\n",
      "Epoch 30135 - Train Loss: 0.070127, Train Acc: 0.885897 | Val Loss: 0.109237, Val Acc: 0.783505\n",
      "Epoch 30136 - Train Loss: 0.070126, Train Acc: 0.885897 | Val Loss: 0.109237, Val Acc: 0.783505\n",
      "Epoch 30137 - Train Loss: 0.070125, Train Acc: 0.885897 | Val Loss: 0.109236, Val Acc: 0.783505\n",
      "Epoch 30138 - Train Loss: 0.070123, Train Acc: 0.885897 | Val Loss: 0.109236, Val Acc: 0.783505\n",
      "Epoch 30139 - Train Loss: 0.070122, Train Acc: 0.885897 | Val Loss: 0.109236, Val Acc: 0.783505\n",
      "Epoch 30140 - Train Loss: 0.070121, Train Acc: 0.885897 | Val Loss: 0.109236, Val Acc: 0.783505\n",
      "Epoch 30141 - Train Loss: 0.070120, Train Acc: 0.885897 | Val Loss: 0.109235, Val Acc: 0.783505\n",
      "Epoch 30142 - Train Loss: 0.070119, Train Acc: 0.885897 | Val Loss: 0.109235, Val Acc: 0.783505\n",
      "Epoch 30143 - Train Loss: 0.070117, Train Acc: 0.885897 | Val Loss: 0.109235, Val Acc: 0.783505\n",
      "Epoch 30144 - Train Loss: 0.070116, Train Acc: 0.885897 | Val Loss: 0.109235, Val Acc: 0.783505\n",
      "Epoch 30145 - Train Loss: 0.070115, Train Acc: 0.885897 | Val Loss: 0.109234, Val Acc: 0.783505\n",
      "Epoch 30146 - Train Loss: 0.070114, Train Acc: 0.885897 | Val Loss: 0.109234, Val Acc: 0.783505\n",
      "Epoch 30147 - Train Loss: 0.070112, Train Acc: 0.885897 | Val Loss: 0.109234, Val Acc: 0.783505\n",
      "Epoch 30148 - Train Loss: 0.070111, Train Acc: 0.885897 | Val Loss: 0.109234, Val Acc: 0.783505\n",
      "Epoch 30149 - Train Loss: 0.070110, Train Acc: 0.885897 | Val Loss: 0.109233, Val Acc: 0.783505\n",
      "Epoch 30150 - Train Loss: 0.070109, Train Acc: 0.885897 | Val Loss: 0.109233, Val Acc: 0.783505\n",
      "Epoch 30151 - Train Loss: 0.070108, Train Acc: 0.885897 | Val Loss: 0.109233, Val Acc: 0.783505\n",
      "Epoch 30152 - Train Loss: 0.070106, Train Acc: 0.885897 | Val Loss: 0.109233, Val Acc: 0.783505\n",
      "Epoch 30153 - Train Loss: 0.070105, Train Acc: 0.885897 | Val Loss: 0.109232, Val Acc: 0.783505\n",
      "Epoch 30154 - Train Loss: 0.070104, Train Acc: 0.885897 | Val Loss: 0.109232, Val Acc: 0.783505\n",
      "Epoch 30155 - Train Loss: 0.070103, Train Acc: 0.885897 | Val Loss: 0.109232, Val Acc: 0.783505\n",
      "Epoch 30156 - Train Loss: 0.070102, Train Acc: 0.885897 | Val Loss: 0.109232, Val Acc: 0.783505\n",
      "Epoch 30157 - Train Loss: 0.070100, Train Acc: 0.885897 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 30158 - Train Loss: 0.070099, Train Acc: 0.885897 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 30159 - Train Loss: 0.070098, Train Acc: 0.885897 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 30160 - Train Loss: 0.070097, Train Acc: 0.885897 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 30161 - Train Loss: 0.070096, Train Acc: 0.885897 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 30162 - Train Loss: 0.070094, Train Acc: 0.885897 | Val Loss: 0.109230, Val Acc: 0.783505\n",
      "Epoch 30163 - Train Loss: 0.070093, Train Acc: 0.885897 | Val Loss: 0.109230, Val Acc: 0.783505\n",
      "Epoch 30164 - Train Loss: 0.070092, Train Acc: 0.885897 | Val Loss: 0.109230, Val Acc: 0.783505\n",
      "Epoch 30165 - Train Loss: 0.070091, Train Acc: 0.885897 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 30166 - Train Loss: 0.070089, Train Acc: 0.885897 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 30167 - Train Loss: 0.070088, Train Acc: 0.885897 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 30168 - Train Loss: 0.070087, Train Acc: 0.885897 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 30169 - Train Loss: 0.070086, Train Acc: 0.885897 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 30170 - Train Loss: 0.070085, Train Acc: 0.885897 | Val Loss: 0.109228, Val Acc: 0.783505\n",
      "Epoch 30171 - Train Loss: 0.070083, Train Acc: 0.885897 | Val Loss: 0.109228, Val Acc: 0.783505\n",
      "Epoch 30172 - Train Loss: 0.070082, Train Acc: 0.885897 | Val Loss: 0.109228, Val Acc: 0.783505\n",
      "Epoch 30173 - Train Loss: 0.070081, Train Acc: 0.885897 | Val Loss: 0.109228, Val Acc: 0.783505\n",
      "Epoch 30174 - Train Loss: 0.070080, Train Acc: 0.885897 | Val Loss: 0.109227, Val Acc: 0.783505\n",
      "Epoch 30175 - Train Loss: 0.070079, Train Acc: 0.885897 | Val Loss: 0.109227, Val Acc: 0.783505\n",
      "Epoch 30176 - Train Loss: 0.070077, Train Acc: 0.885897 | Val Loss: 0.109227, Val Acc: 0.783505\n",
      "Epoch 30177 - Train Loss: 0.070076, Train Acc: 0.885897 | Val Loss: 0.109227, Val Acc: 0.783505\n",
      "Epoch 30178 - Train Loss: 0.070075, Train Acc: 0.885897 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 30179 - Train Loss: 0.070074, Train Acc: 0.885897 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 30180 - Train Loss: 0.070073, Train Acc: 0.885897 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 30181 - Train Loss: 0.070071, Train Acc: 0.885897 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 30182 - Train Loss: 0.070070, Train Acc: 0.885897 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 30183 - Train Loss: 0.070069, Train Acc: 0.885897 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 30184 - Train Loss: 0.070068, Train Acc: 0.885897 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 30185 - Train Loss: 0.070067, Train Acc: 0.885897 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 30186 - Train Loss: 0.070065, Train Acc: 0.885897 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 30187 - Train Loss: 0.070064, Train Acc: 0.885897 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 30188 - Train Loss: 0.070063, Train Acc: 0.885897 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 30189 - Train Loss: 0.070062, Train Acc: 0.885897 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 30190 - Train Loss: 0.070061, Train Acc: 0.885897 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 30191 - Train Loss: 0.070059, Train Acc: 0.885897 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 30192 - Train Loss: 0.070058, Train Acc: 0.885897 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 30193 - Train Loss: 0.070057, Train Acc: 0.885897 | Val Loss: 0.109223, Val Acc: 0.783505\n",
      "Epoch 30194 - Train Loss: 0.070056, Train Acc: 0.885897 | Val Loss: 0.109223, Val Acc: 0.783505\n",
      "Epoch 30195 - Train Loss: 0.070054, Train Acc: 0.885897 | Val Loss: 0.109223, Val Acc: 0.783505\n",
      "Epoch 30196 - Train Loss: 0.070053, Train Acc: 0.885897 | Val Loss: 0.109223, Val Acc: 0.783505\n",
      "Epoch 30197 - Train Loss: 0.070052, Train Acc: 0.885897 | Val Loss: 0.109222, Val Acc: 0.783505\n",
      "Epoch 30198 - Train Loss: 0.070051, Train Acc: 0.885897 | Val Loss: 0.109222, Val Acc: 0.783505\n",
      "Epoch 30199 - Train Loss: 0.070050, Train Acc: 0.885897 | Val Loss: 0.109222, Val Acc: 0.783505\n",
      "Epoch 30200 - Train Loss: 0.070048, Train Acc: 0.885897 | Val Loss: 0.109222, Val Acc: 0.783505\n",
      "Epoch 30201 - Train Loss: 0.070047, Train Acc: 0.885897 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 30202 - Train Loss: 0.070046, Train Acc: 0.885897 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 30203 - Train Loss: 0.070045, Train Acc: 0.885897 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 30204 - Train Loss: 0.070044, Train Acc: 0.885897 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 30205 - Train Loss: 0.070042, Train Acc: 0.885897 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 30206 - Train Loss: 0.070041, Train Acc: 0.885897 | Val Loss: 0.109220, Val Acc: 0.783505\n",
      "Epoch 30207 - Train Loss: 0.070040, Train Acc: 0.885897 | Val Loss: 0.109220, Val Acc: 0.783505\n",
      "Epoch 30208 - Train Loss: 0.070039, Train Acc: 0.885897 | Val Loss: 0.109220, Val Acc: 0.783505\n",
      "Epoch 30209 - Train Loss: 0.070038, Train Acc: 0.885897 | Val Loss: 0.109220, Val Acc: 0.783505\n",
      "Epoch 30210 - Train Loss: 0.070036, Train Acc: 0.885897 | Val Loss: 0.109219, Val Acc: 0.783505\n",
      "Epoch 30211 - Train Loss: 0.070035, Train Acc: 0.885897 | Val Loss: 0.109219, Val Acc: 0.783505\n",
      "Epoch 30212 - Train Loss: 0.070034, Train Acc: 0.885897 | Val Loss: 0.109219, Val Acc: 0.783505\n",
      "Epoch 30213 - Train Loss: 0.070033, Train Acc: 0.885897 | Val Loss: 0.109219, Val Acc: 0.783505\n",
      "Epoch 30214 - Train Loss: 0.070032, Train Acc: 0.885897 | Val Loss: 0.109218, Val Acc: 0.783505\n",
      "Epoch 30215 - Train Loss: 0.070030, Train Acc: 0.885897 | Val Loss: 0.109218, Val Acc: 0.783505\n",
      "Epoch 30216 - Train Loss: 0.070029, Train Acc: 0.885897 | Val Loss: 0.109218, Val Acc: 0.783505\n",
      "Epoch 30217 - Train Loss: 0.070028, Train Acc: 0.885897 | Val Loss: 0.109218, Val Acc: 0.783505\n",
      "Epoch 30218 - Train Loss: 0.070027, Train Acc: 0.885897 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 30219 - Train Loss: 0.070026, Train Acc: 0.885897 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 30220 - Train Loss: 0.070024, Train Acc: 0.885897 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 30221 - Train Loss: 0.070023, Train Acc: 0.885897 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 30222 - Train Loss: 0.070022, Train Acc: 0.885897 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 30223 - Train Loss: 0.070021, Train Acc: 0.885897 | Val Loss: 0.109216, Val Acc: 0.783505\n",
      "Epoch 30224 - Train Loss: 0.070020, Train Acc: 0.885897 | Val Loss: 0.109216, Val Acc: 0.783505\n",
      "Epoch 30225 - Train Loss: 0.070018, Train Acc: 0.885897 | Val Loss: 0.109216, Val Acc: 0.783505\n",
      "Epoch 30226 - Train Loss: 0.070017, Train Acc: 0.885897 | Val Loss: 0.109216, Val Acc: 0.783505\n",
      "Epoch 30227 - Train Loss: 0.070016, Train Acc: 0.885897 | Val Loss: 0.109215, Val Acc: 0.783505\n",
      "Epoch 30228 - Train Loss: 0.070015, Train Acc: 0.885897 | Val Loss: 0.109215, Val Acc: 0.783505\n",
      "Epoch 30229 - Train Loss: 0.070013, Train Acc: 0.885897 | Val Loss: 0.109215, Val Acc: 0.783505\n",
      "Epoch 30230 - Train Loss: 0.070012, Train Acc: 0.885897 | Val Loss: 0.109215, Val Acc: 0.783505\n",
      "Epoch 30231 - Train Loss: 0.070011, Train Acc: 0.885897 | Val Loss: 0.109214, Val Acc: 0.783505\n",
      "Epoch 30232 - Train Loss: 0.070010, Train Acc: 0.885897 | Val Loss: 0.109214, Val Acc: 0.783505\n",
      "Epoch 30233 - Train Loss: 0.070009, Train Acc: 0.885897 | Val Loss: 0.109214, Val Acc: 0.783505\n",
      "Epoch 30234 - Train Loss: 0.070007, Train Acc: 0.885897 | Val Loss: 0.109214, Val Acc: 0.783505\n",
      "Epoch 30235 - Train Loss: 0.070006, Train Acc: 0.885897 | Val Loss: 0.109213, Val Acc: 0.783505\n",
      "Epoch 30236 - Train Loss: 0.070005, Train Acc: 0.885897 | Val Loss: 0.109213, Val Acc: 0.783505\n",
      "Epoch 30237 - Train Loss: 0.070004, Train Acc: 0.885897 | Val Loss: 0.109213, Val Acc: 0.783505\n",
      "Epoch 30238 - Train Loss: 0.070003, Train Acc: 0.885897 | Val Loss: 0.109213, Val Acc: 0.783505\n",
      "Epoch 30239 - Train Loss: 0.070001, Train Acc: 0.885897 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 30240 - Train Loss: 0.070000, Train Acc: 0.885897 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 30241 - Train Loss: 0.069999, Train Acc: 0.885897 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 30242 - Train Loss: 0.069998, Train Acc: 0.885897 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 30243 - Train Loss: 0.069997, Train Acc: 0.885897 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 30244 - Train Loss: 0.069995, Train Acc: 0.885897 | Val Loss: 0.109211, Val Acc: 0.783505\n",
      "Epoch 30245 - Train Loss: 0.069994, Train Acc: 0.885897 | Val Loss: 0.109211, Val Acc: 0.783505\n",
      "Epoch 30246 - Train Loss: 0.069993, Train Acc: 0.885897 | Val Loss: 0.109211, Val Acc: 0.783505\n",
      "Epoch 30247 - Train Loss: 0.069992, Train Acc: 0.885897 | Val Loss: 0.109211, Val Acc: 0.783505\n",
      "Epoch 30248 - Train Loss: 0.069991, Train Acc: 0.885897 | Val Loss: 0.109210, Val Acc: 0.783505\n",
      "Epoch 30249 - Train Loss: 0.069989, Train Acc: 0.885897 | Val Loss: 0.109210, Val Acc: 0.783505\n",
      "Epoch 30250 - Train Loss: 0.069988, Train Acc: 0.885897 | Val Loss: 0.109210, Val Acc: 0.783505\n",
      "Epoch 30251 - Train Loss: 0.069987, Train Acc: 0.885897 | Val Loss: 0.109210, Val Acc: 0.783505\n",
      "Epoch 30252 - Train Loss: 0.069986, Train Acc: 0.885897 | Val Loss: 0.109209, Val Acc: 0.783505\n",
      "Epoch 30253 - Train Loss: 0.069985, Train Acc: 0.885897 | Val Loss: 0.109209, Val Acc: 0.783505\n",
      "Epoch 30254 - Train Loss: 0.069983, Train Acc: 0.885897 | Val Loss: 0.109209, Val Acc: 0.783505\n",
      "Epoch 30255 - Train Loss: 0.069982, Train Acc: 0.885897 | Val Loss: 0.109209, Val Acc: 0.783505\n",
      "Epoch 30256 - Train Loss: 0.069981, Train Acc: 0.885897 | Val Loss: 0.109208, Val Acc: 0.783505\n",
      "Epoch 30257 - Train Loss: 0.069980, Train Acc: 0.885897 | Val Loss: 0.109208, Val Acc: 0.783505\n",
      "Epoch 30258 - Train Loss: 0.069979, Train Acc: 0.885897 | Val Loss: 0.109208, Val Acc: 0.783505\n",
      "Epoch 30259 - Train Loss: 0.069977, Train Acc: 0.885897 | Val Loss: 0.109208, Val Acc: 0.783505\n",
      "Epoch 30260 - Train Loss: 0.069976, Train Acc: 0.885897 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 30261 - Train Loss: 0.069975, Train Acc: 0.885897 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 30262 - Train Loss: 0.069974, Train Acc: 0.885897 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 30263 - Train Loss: 0.069973, Train Acc: 0.885897 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 30264 - Train Loss: 0.069971, Train Acc: 0.885897 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 30265 - Train Loss: 0.069970, Train Acc: 0.885897 | Val Loss: 0.109206, Val Acc: 0.783505\n",
      "Epoch 30266 - Train Loss: 0.069969, Train Acc: 0.885897 | Val Loss: 0.109206, Val Acc: 0.783505\n",
      "Epoch 30267 - Train Loss: 0.069968, Train Acc: 0.885897 | Val Loss: 0.109206, Val Acc: 0.783505\n",
      "Epoch 30268 - Train Loss: 0.069967, Train Acc: 0.885897 | Val Loss: 0.109206, Val Acc: 0.783505\n",
      "Epoch 30269 - Train Loss: 0.069965, Train Acc: 0.885897 | Val Loss: 0.109205, Val Acc: 0.783505\n",
      "Epoch 30270 - Train Loss: 0.069964, Train Acc: 0.885897 | Val Loss: 0.109205, Val Acc: 0.783505\n",
      "Epoch 30271 - Train Loss: 0.069963, Train Acc: 0.885897 | Val Loss: 0.109205, Val Acc: 0.783505\n",
      "Epoch 30272 - Train Loss: 0.069962, Train Acc: 0.885897 | Val Loss: 0.109205, Val Acc: 0.783505\n",
      "Epoch 30273 - Train Loss: 0.069961, Train Acc: 0.885897 | Val Loss: 0.109204, Val Acc: 0.783505\n",
      "Epoch 30274 - Train Loss: 0.069959, Train Acc: 0.885897 | Val Loss: 0.109204, Val Acc: 0.783505\n",
      "Epoch 30275 - Train Loss: 0.069958, Train Acc: 0.885897 | Val Loss: 0.109204, Val Acc: 0.783505\n",
      "Epoch 30276 - Train Loss: 0.069957, Train Acc: 0.885897 | Val Loss: 0.109204, Val Acc: 0.783505\n",
      "Epoch 30277 - Train Loss: 0.069956, Train Acc: 0.885897 | Val Loss: 0.109203, Val Acc: 0.783505\n",
      "Epoch 30278 - Train Loss: 0.069955, Train Acc: 0.885897 | Val Loss: 0.109203, Val Acc: 0.783505\n",
      "Epoch 30279 - Train Loss: 0.069953, Train Acc: 0.885897 | Val Loss: 0.109203, Val Acc: 0.783505\n",
      "Epoch 30280 - Train Loss: 0.069952, Train Acc: 0.885897 | Val Loss: 0.109203, Val Acc: 0.783505\n",
      "Epoch 30281 - Train Loss: 0.069951, Train Acc: 0.885897 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 30282 - Train Loss: 0.069950, Train Acc: 0.885897 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 30283 - Train Loss: 0.069949, Train Acc: 0.885897 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 30284 - Train Loss: 0.069947, Train Acc: 0.885897 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 30285 - Train Loss: 0.069946, Train Acc: 0.885897 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 30286 - Train Loss: 0.069945, Train Acc: 0.885897 | Val Loss: 0.109201, Val Acc: 0.783505\n",
      "Epoch 30287 - Train Loss: 0.069944, Train Acc: 0.885897 | Val Loss: 0.109201, Val Acc: 0.783505\n",
      "Epoch 30288 - Train Loss: 0.069943, Train Acc: 0.885897 | Val Loss: 0.109201, Val Acc: 0.783505\n",
      "Epoch 30289 - Train Loss: 0.069941, Train Acc: 0.885897 | Val Loss: 0.109201, Val Acc: 0.783505\n",
      "Epoch 30290 - Train Loss: 0.069940, Train Acc: 0.885897 | Val Loss: 0.109200, Val Acc: 0.783505\n",
      "Epoch 30291 - Train Loss: 0.069939, Train Acc: 0.885897 | Val Loss: 0.109200, Val Acc: 0.783505\n",
      "Epoch 30292 - Train Loss: 0.069938, Train Acc: 0.885897 | Val Loss: 0.109200, Val Acc: 0.783505\n",
      "Epoch 30293 - Train Loss: 0.069936, Train Acc: 0.885897 | Val Loss: 0.109200, Val Acc: 0.783505\n",
      "Epoch 30294 - Train Loss: 0.069935, Train Acc: 0.885897 | Val Loss: 0.109199, Val Acc: 0.783505\n",
      "Epoch 30295 - Train Loss: 0.069934, Train Acc: 0.885897 | Val Loss: 0.109199, Val Acc: 0.783505\n",
      "Epoch 30296 - Train Loss: 0.069933, Train Acc: 0.885897 | Val Loss: 0.109199, Val Acc: 0.783505\n",
      "Epoch 30297 - Train Loss: 0.069932, Train Acc: 0.885897 | Val Loss: 0.109199, Val Acc: 0.783505\n",
      "Epoch 30298 - Train Loss: 0.069930, Train Acc: 0.885897 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 30299 - Train Loss: 0.069929, Train Acc: 0.885897 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 30300 - Train Loss: 0.069928, Train Acc: 0.885897 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 30301 - Train Loss: 0.069927, Train Acc: 0.885897 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 30302 - Train Loss: 0.069926, Train Acc: 0.885897 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 30303 - Train Loss: 0.069924, Train Acc: 0.885897 | Val Loss: 0.109197, Val Acc: 0.783505\n",
      "Epoch 30304 - Train Loss: 0.069923, Train Acc: 0.885897 | Val Loss: 0.109197, Val Acc: 0.783505\n",
      "Epoch 30305 - Train Loss: 0.069922, Train Acc: 0.885897 | Val Loss: 0.109197, Val Acc: 0.783505\n",
      "Epoch 30306 - Train Loss: 0.069921, Train Acc: 0.885897 | Val Loss: 0.109197, Val Acc: 0.783505\n",
      "Epoch 30307 - Train Loss: 0.069920, Train Acc: 0.885897 | Val Loss: 0.109196, Val Acc: 0.783505\n",
      "Epoch 30308 - Train Loss: 0.069918, Train Acc: 0.885897 | Val Loss: 0.109196, Val Acc: 0.783505\n",
      "Epoch 30309 - Train Loss: 0.069917, Train Acc: 0.885897 | Val Loss: 0.109196, Val Acc: 0.783505\n",
      "Epoch 30310 - Train Loss: 0.069916, Train Acc: 0.885897 | Val Loss: 0.109196, Val Acc: 0.783505\n",
      "Epoch 30311 - Train Loss: 0.069915, Train Acc: 0.885897 | Val Loss: 0.109195, Val Acc: 0.783505\n",
      "Epoch 30312 - Train Loss: 0.069914, Train Acc: 0.885897 | Val Loss: 0.109195, Val Acc: 0.783505\n",
      "Epoch 30313 - Train Loss: 0.069912, Train Acc: 0.885897 | Val Loss: 0.109195, Val Acc: 0.783505\n",
      "Epoch 30314 - Train Loss: 0.069911, Train Acc: 0.885897 | Val Loss: 0.109195, Val Acc: 0.783505\n",
      "Epoch 30315 - Train Loss: 0.069910, Train Acc: 0.885897 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 30316 - Train Loss: 0.069909, Train Acc: 0.885897 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 30317 - Train Loss: 0.069908, Train Acc: 0.885897 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 30318 - Train Loss: 0.069906, Train Acc: 0.885897 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 30319 - Train Loss: 0.069905, Train Acc: 0.885897 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 30320 - Train Loss: 0.069904, Train Acc: 0.885897 | Val Loss: 0.109193, Val Acc: 0.783505\n",
      "Epoch 30321 - Train Loss: 0.069903, Train Acc: 0.885897 | Val Loss: 0.109193, Val Acc: 0.783505\n",
      "Epoch 30322 - Train Loss: 0.069902, Train Acc: 0.885897 | Val Loss: 0.109193, Val Acc: 0.783505\n",
      "Epoch 30323 - Train Loss: 0.069900, Train Acc: 0.885897 | Val Loss: 0.109193, Val Acc: 0.783505\n",
      "Epoch 30324 - Train Loss: 0.069899, Train Acc: 0.885897 | Val Loss: 0.109192, Val Acc: 0.783505\n",
      "Epoch 30325 - Train Loss: 0.069898, Train Acc: 0.885897 | Val Loss: 0.109192, Val Acc: 0.783505\n",
      "Epoch 30326 - Train Loss: 0.069897, Train Acc: 0.885897 | Val Loss: 0.109192, Val Acc: 0.783505\n",
      "Epoch 30327 - Train Loss: 0.069896, Train Acc: 0.885897 | Val Loss: 0.109192, Val Acc: 0.783505\n",
      "Epoch 30328 - Train Loss: 0.069894, Train Acc: 0.885897 | Val Loss: 0.109191, Val Acc: 0.783505\n",
      "Epoch 30329 - Train Loss: 0.069893, Train Acc: 0.885897 | Val Loss: 0.109191, Val Acc: 0.783505\n",
      "Epoch 30330 - Train Loss: 0.069892, Train Acc: 0.885897 | Val Loss: 0.109191, Val Acc: 0.783505\n",
      "Epoch 30331 - Train Loss: 0.069891, Train Acc: 0.885897 | Val Loss: 0.109191, Val Acc: 0.783505\n",
      "Epoch 30332 - Train Loss: 0.069890, Train Acc: 0.885897 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 30333 - Train Loss: 0.069888, Train Acc: 0.885897 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 30334 - Train Loss: 0.069887, Train Acc: 0.885897 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 30335 - Train Loss: 0.069886, Train Acc: 0.885897 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 30336 - Train Loss: 0.069885, Train Acc: 0.885897 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 30337 - Train Loss: 0.069884, Train Acc: 0.885897 | Val Loss: 0.109189, Val Acc: 0.783505\n",
      "Epoch 30338 - Train Loss: 0.069882, Train Acc: 0.885897 | Val Loss: 0.109189, Val Acc: 0.783505\n",
      "Epoch 30339 - Train Loss: 0.069881, Train Acc: 0.885897 | Val Loss: 0.109189, Val Acc: 0.783505\n",
      "Epoch 30340 - Train Loss: 0.069880, Train Acc: 0.885897 | Val Loss: 0.109189, Val Acc: 0.783505\n",
      "Epoch 30341 - Train Loss: 0.069879, Train Acc: 0.885897 | Val Loss: 0.109188, Val Acc: 0.783505\n",
      "Epoch 30342 - Train Loss: 0.069878, Train Acc: 0.885897 | Val Loss: 0.109188, Val Acc: 0.783505\n",
      "Epoch 30343 - Train Loss: 0.069877, Train Acc: 0.885897 | Val Loss: 0.109188, Val Acc: 0.783505\n",
      "Epoch 30344 - Train Loss: 0.069875, Train Acc: 0.885897 | Val Loss: 0.109188, Val Acc: 0.783505\n",
      "Epoch 30345 - Train Loss: 0.069874, Train Acc: 0.885897 | Val Loss: 0.109187, Val Acc: 0.783505\n",
      "Epoch 30346 - Train Loss: 0.069873, Train Acc: 0.885897 | Val Loss: 0.109187, Val Acc: 0.783505\n",
      "Epoch 30347 - Train Loss: 0.069872, Train Acc: 0.885897 | Val Loss: 0.109187, Val Acc: 0.783505\n",
      "Epoch 30348 - Train Loss: 0.069871, Train Acc: 0.885897 | Val Loss: 0.109187, Val Acc: 0.783505\n",
      "Epoch 30349 - Train Loss: 0.069869, Train Acc: 0.885897 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 30350 - Train Loss: 0.069868, Train Acc: 0.885897 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 30351 - Train Loss: 0.069867, Train Acc: 0.885897 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 30352 - Train Loss: 0.069866, Train Acc: 0.885897 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 30353 - Train Loss: 0.069865, Train Acc: 0.885897 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 30354 - Train Loss: 0.069863, Train Acc: 0.885897 | Val Loss: 0.109185, Val Acc: 0.783505\n",
      "Epoch 30355 - Train Loss: 0.069862, Train Acc: 0.885897 | Val Loss: 0.109185, Val Acc: 0.783505\n",
      "Epoch 30356 - Train Loss: 0.069861, Train Acc: 0.885897 | Val Loss: 0.109185, Val Acc: 0.783505\n",
      "Epoch 30357 - Train Loss: 0.069860, Train Acc: 0.885897 | Val Loss: 0.109185, Val Acc: 0.783505\n",
      "Epoch 30358 - Train Loss: 0.069859, Train Acc: 0.885897 | Val Loss: 0.109184, Val Acc: 0.783505\n",
      "Epoch 30359 - Train Loss: 0.069857, Train Acc: 0.885897 | Val Loss: 0.109184, Val Acc: 0.783505\n",
      "Epoch 30360 - Train Loss: 0.069856, Train Acc: 0.885897 | Val Loss: 0.109184, Val Acc: 0.783505\n",
      "Epoch 30361 - Train Loss: 0.069855, Train Acc: 0.885897 | Val Loss: 0.109184, Val Acc: 0.783505\n",
      "Epoch 30362 - Train Loss: 0.069854, Train Acc: 0.885897 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 30363 - Train Loss: 0.069853, Train Acc: 0.885897 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 30364 - Train Loss: 0.069851, Train Acc: 0.885897 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 30365 - Train Loss: 0.069850, Train Acc: 0.885897 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 30366 - Train Loss: 0.069849, Train Acc: 0.885897 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 30367 - Train Loss: 0.069848, Train Acc: 0.885897 | Val Loss: 0.109182, Val Acc: 0.783505\n",
      "Epoch 30368 - Train Loss: 0.069847, Train Acc: 0.885897 | Val Loss: 0.109182, Val Acc: 0.783505\n",
      "Epoch 30369 - Train Loss: 0.069845, Train Acc: 0.885897 | Val Loss: 0.109182, Val Acc: 0.783505\n",
      "Epoch 30370 - Train Loss: 0.069844, Train Acc: 0.885897 | Val Loss: 0.109182, Val Acc: 0.783505\n",
      "Epoch 30371 - Train Loss: 0.069843, Train Acc: 0.885897 | Val Loss: 0.109181, Val Acc: 0.783505\n",
      "Epoch 30372 - Train Loss: 0.069842, Train Acc: 0.885897 | Val Loss: 0.109181, Val Acc: 0.783505\n",
      "Epoch 30373 - Train Loss: 0.069841, Train Acc: 0.885897 | Val Loss: 0.109181, Val Acc: 0.783505\n",
      "Epoch 30374 - Train Loss: 0.069839, Train Acc: 0.885897 | Val Loss: 0.109181, Val Acc: 0.783505\n",
      "Epoch 30375 - Train Loss: 0.069838, Train Acc: 0.885897 | Val Loss: 0.109180, Val Acc: 0.783505\n",
      "Epoch 30376 - Train Loss: 0.069837, Train Acc: 0.885897 | Val Loss: 0.109180, Val Acc: 0.783505\n",
      "Epoch 30377 - Train Loss: 0.069836, Train Acc: 0.885897 | Val Loss: 0.109180, Val Acc: 0.783505\n",
      "Epoch 30378 - Train Loss: 0.069835, Train Acc: 0.885897 | Val Loss: 0.109180, Val Acc: 0.783505\n",
      "Epoch 30379 - Train Loss: 0.069833, Train Acc: 0.885897 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 30380 - Train Loss: 0.069832, Train Acc: 0.885897 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 30381 - Train Loss: 0.069831, Train Acc: 0.885897 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 30382 - Train Loss: 0.069830, Train Acc: 0.885897 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 30383 - Train Loss: 0.069829, Train Acc: 0.885897 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 30384 - Train Loss: 0.069827, Train Acc: 0.885897 | Val Loss: 0.109178, Val Acc: 0.783505\n",
      "Epoch 30385 - Train Loss: 0.069826, Train Acc: 0.885897 | Val Loss: 0.109178, Val Acc: 0.783505\n",
      "Epoch 30386 - Train Loss: 0.069825, Train Acc: 0.885897 | Val Loss: 0.109178, Val Acc: 0.783505\n",
      "Epoch 30387 - Train Loss: 0.069824, Train Acc: 0.885897 | Val Loss: 0.109178, Val Acc: 0.783505\n",
      "Epoch 30388 - Train Loss: 0.069823, Train Acc: 0.885897 | Val Loss: 0.109177, Val Acc: 0.783505\n",
      "Epoch 30389 - Train Loss: 0.069821, Train Acc: 0.885897 | Val Loss: 0.109177, Val Acc: 0.783505\n",
      "Epoch 30390 - Train Loss: 0.069820, Train Acc: 0.885897 | Val Loss: 0.109177, Val Acc: 0.783505\n",
      "Epoch 30391 - Train Loss: 0.069819, Train Acc: 0.885897 | Val Loss: 0.109177, Val Acc: 0.783505\n",
      "Epoch 30392 - Train Loss: 0.069818, Train Acc: 0.885897 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 30393 - Train Loss: 0.069817, Train Acc: 0.885897 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 30394 - Train Loss: 0.069815, Train Acc: 0.885897 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 30395 - Train Loss: 0.069814, Train Acc: 0.885897 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 30396 - Train Loss: 0.069813, Train Acc: 0.885897 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 30397 - Train Loss: 0.069812, Train Acc: 0.885897 | Val Loss: 0.109175, Val Acc: 0.783505\n",
      "Epoch 30398 - Train Loss: 0.069811, Train Acc: 0.885897 | Val Loss: 0.109175, Val Acc: 0.783505\n",
      "Epoch 30399 - Train Loss: 0.069809, Train Acc: 0.885897 | Val Loss: 0.109175, Val Acc: 0.783505\n",
      "Epoch 30400 - Train Loss: 0.069808, Train Acc: 0.885897 | Val Loss: 0.109175, Val Acc: 0.783505\n",
      "Epoch 30401 - Train Loss: 0.069807, Train Acc: 0.885897 | Val Loss: 0.109174, Val Acc: 0.783505\n",
      "Epoch 30402 - Train Loss: 0.069806, Train Acc: 0.885897 | Val Loss: 0.109174, Val Acc: 0.783505\n",
      "Epoch 30403 - Train Loss: 0.069805, Train Acc: 0.885897 | Val Loss: 0.109174, Val Acc: 0.783505\n",
      "Epoch 30404 - Train Loss: 0.069804, Train Acc: 0.885897 | Val Loss: 0.109174, Val Acc: 0.783505\n",
      "Epoch 30405 - Train Loss: 0.069802, Train Acc: 0.885897 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 30406 - Train Loss: 0.069801, Train Acc: 0.885897 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 30407 - Train Loss: 0.069800, Train Acc: 0.887179 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 30408 - Train Loss: 0.069799, Train Acc: 0.887179 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 30409 - Train Loss: 0.069798, Train Acc: 0.887179 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 30410 - Train Loss: 0.069796, Train Acc: 0.887179 | Val Loss: 0.109172, Val Acc: 0.783505\n",
      "Epoch 30411 - Train Loss: 0.069795, Train Acc: 0.887179 | Val Loss: 0.109172, Val Acc: 0.783505\n",
      "Epoch 30412 - Train Loss: 0.069794, Train Acc: 0.887179 | Val Loss: 0.109172, Val Acc: 0.783505\n",
      "Epoch 30413 - Train Loss: 0.069793, Train Acc: 0.887179 | Val Loss: 0.109172, Val Acc: 0.783505\n",
      "Epoch 30414 - Train Loss: 0.069792, Train Acc: 0.887179 | Val Loss: 0.109171, Val Acc: 0.783505\n",
      "Epoch 30415 - Train Loss: 0.069790, Train Acc: 0.887179 | Val Loss: 0.109171, Val Acc: 0.783505\n",
      "Epoch 30416 - Train Loss: 0.069789, Train Acc: 0.887179 | Val Loss: 0.109171, Val Acc: 0.783505\n",
      "Epoch 30417 - Train Loss: 0.069788, Train Acc: 0.887179 | Val Loss: 0.109171, Val Acc: 0.783505\n",
      "Epoch 30418 - Train Loss: 0.069787, Train Acc: 0.887179 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 30419 - Train Loss: 0.069786, Train Acc: 0.887179 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 30420 - Train Loss: 0.069784, Train Acc: 0.887179 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 30421 - Train Loss: 0.069783, Train Acc: 0.887179 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 30422 - Train Loss: 0.069782, Train Acc: 0.887179 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 30423 - Train Loss: 0.069781, Train Acc: 0.887179 | Val Loss: 0.109169, Val Acc: 0.783505\n",
      "Epoch 30424 - Train Loss: 0.069780, Train Acc: 0.887179 | Val Loss: 0.109169, Val Acc: 0.783505\n",
      "Epoch 30425 - Train Loss: 0.069778, Train Acc: 0.887179 | Val Loss: 0.109169, Val Acc: 0.783505\n",
      "Epoch 30426 - Train Loss: 0.069777, Train Acc: 0.887179 | Val Loss: 0.109169, Val Acc: 0.783505\n",
      "Epoch 30427 - Train Loss: 0.069776, Train Acc: 0.887179 | Val Loss: 0.109168, Val Acc: 0.783505\n",
      "Epoch 30428 - Train Loss: 0.069775, Train Acc: 0.887179 | Val Loss: 0.109168, Val Acc: 0.783505\n",
      "Epoch 30429 - Train Loss: 0.069774, Train Acc: 0.887179 | Val Loss: 0.109168, Val Acc: 0.783505\n",
      "Epoch 30430 - Train Loss: 0.069772, Train Acc: 0.887179 | Val Loss: 0.109168, Val Acc: 0.783505\n",
      "Epoch 30431 - Train Loss: 0.069771, Train Acc: 0.887179 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 30432 - Train Loss: 0.069770, Train Acc: 0.887179 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 30433 - Train Loss: 0.069769, Train Acc: 0.887179 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 30434 - Train Loss: 0.069768, Train Acc: 0.887179 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 30435 - Train Loss: 0.069766, Train Acc: 0.887179 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 30436 - Train Loss: 0.069765, Train Acc: 0.887179 | Val Loss: 0.109166, Val Acc: 0.783505\n",
      "Epoch 30437 - Train Loss: 0.069764, Train Acc: 0.887179 | Val Loss: 0.109166, Val Acc: 0.783505\n",
      "Epoch 30438 - Train Loss: 0.069763, Train Acc: 0.887179 | Val Loss: 0.109166, Val Acc: 0.783505\n",
      "Epoch 30439 - Train Loss: 0.069762, Train Acc: 0.887179 | Val Loss: 0.109166, Val Acc: 0.783505\n",
      "Epoch 30440 - Train Loss: 0.069761, Train Acc: 0.887179 | Val Loss: 0.109165, Val Acc: 0.783505\n",
      "Epoch 30441 - Train Loss: 0.069759, Train Acc: 0.887179 | Val Loss: 0.109165, Val Acc: 0.783505\n",
      "Epoch 30442 - Train Loss: 0.069758, Train Acc: 0.887179 | Val Loss: 0.109165, Val Acc: 0.783505\n",
      "Epoch 30443 - Train Loss: 0.069757, Train Acc: 0.887179 | Val Loss: 0.109165, Val Acc: 0.783505\n",
      "Epoch 30444 - Train Loss: 0.069756, Train Acc: 0.887179 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 30445 - Train Loss: 0.069755, Train Acc: 0.887179 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 30446 - Train Loss: 0.069753, Train Acc: 0.887179 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 30447 - Train Loss: 0.069752, Train Acc: 0.887179 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 30448 - Train Loss: 0.069751, Train Acc: 0.887179 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 30449 - Train Loss: 0.069750, Train Acc: 0.887179 | Val Loss: 0.109163, Val Acc: 0.783505\n",
      "Epoch 30450 - Train Loss: 0.069749, Train Acc: 0.887179 | Val Loss: 0.109163, Val Acc: 0.783505\n",
      "Epoch 30451 - Train Loss: 0.069747, Train Acc: 0.887179 | Val Loss: 0.109163, Val Acc: 0.783505\n",
      "Epoch 30452 - Train Loss: 0.069746, Train Acc: 0.887179 | Val Loss: 0.109163, Val Acc: 0.783505\n",
      "Epoch 30453 - Train Loss: 0.069745, Train Acc: 0.887179 | Val Loss: 0.109162, Val Acc: 0.783505\n",
      "Epoch 30454 - Train Loss: 0.069744, Train Acc: 0.887179 | Val Loss: 0.109162, Val Acc: 0.783505\n",
      "Epoch 30455 - Train Loss: 0.069743, Train Acc: 0.887179 | Val Loss: 0.109162, Val Acc: 0.783505\n",
      "Epoch 30456 - Train Loss: 0.069741, Train Acc: 0.887179 | Val Loss: 0.109162, Val Acc: 0.783505\n",
      "Epoch 30457 - Train Loss: 0.069740, Train Acc: 0.887179 | Val Loss: 0.109161, Val Acc: 0.783505\n",
      "Epoch 30458 - Train Loss: 0.069739, Train Acc: 0.887179 | Val Loss: 0.109161, Val Acc: 0.783505\n",
      "Epoch 30459 - Train Loss: 0.069738, Train Acc: 0.887179 | Val Loss: 0.109161, Val Acc: 0.783505\n",
      "Epoch 30460 - Train Loss: 0.069737, Train Acc: 0.887179 | Val Loss: 0.109161, Val Acc: 0.783505\n",
      "Epoch 30461 - Train Loss: 0.069735, Train Acc: 0.887179 | Val Loss: 0.109161, Val Acc: 0.783505\n",
      "Epoch 30462 - Train Loss: 0.069734, Train Acc: 0.887179 | Val Loss: 0.109160, Val Acc: 0.783505\n",
      "Epoch 30463 - Train Loss: 0.069733, Train Acc: 0.887179 | Val Loss: 0.109160, Val Acc: 0.783505\n",
      "Epoch 30464 - Train Loss: 0.069732, Train Acc: 0.887179 | Val Loss: 0.109160, Val Acc: 0.783505\n",
      "Epoch 30465 - Train Loss: 0.069731, Train Acc: 0.887179 | Val Loss: 0.109160, Val Acc: 0.783505\n",
      "Epoch 30466 - Train Loss: 0.069730, Train Acc: 0.887179 | Val Loss: 0.109159, Val Acc: 0.783505\n",
      "Epoch 30467 - Train Loss: 0.069728, Train Acc: 0.887179 | Val Loss: 0.109159, Val Acc: 0.783505\n",
      "Epoch 30468 - Train Loss: 0.069727, Train Acc: 0.887179 | Val Loss: 0.109159, Val Acc: 0.783505\n",
      "Epoch 30469 - Train Loss: 0.069726, Train Acc: 0.887179 | Val Loss: 0.109159, Val Acc: 0.783505\n",
      "Epoch 30470 - Train Loss: 0.069725, Train Acc: 0.887179 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 30471 - Train Loss: 0.069724, Train Acc: 0.887179 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 30472 - Train Loss: 0.069722, Train Acc: 0.887179 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 30473 - Train Loss: 0.069721, Train Acc: 0.887179 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 30474 - Train Loss: 0.069720, Train Acc: 0.887179 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 30475 - Train Loss: 0.069719, Train Acc: 0.887179 | Val Loss: 0.109157, Val Acc: 0.783505\n",
      "Epoch 30476 - Train Loss: 0.069718, Train Acc: 0.887179 | Val Loss: 0.109157, Val Acc: 0.783505\n",
      "Epoch 30477 - Train Loss: 0.069716, Train Acc: 0.887179 | Val Loss: 0.109157, Val Acc: 0.783505\n",
      "Epoch 30478 - Train Loss: 0.069715, Train Acc: 0.887179 | Val Loss: 0.109157, Val Acc: 0.783505\n",
      "Epoch 30479 - Train Loss: 0.069714, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 30480 - Train Loss: 0.069713, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 30481 - Train Loss: 0.069712, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 30482 - Train Loss: 0.069710, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 30483 - Train Loss: 0.069709, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 30484 - Train Loss: 0.069708, Train Acc: 0.887179 | Val Loss: 0.109155, Val Acc: 0.783505\n",
      "Epoch 30485 - Train Loss: 0.069707, Train Acc: 0.887179 | Val Loss: 0.109155, Val Acc: 0.783505\n",
      "Epoch 30486 - Train Loss: 0.069706, Train Acc: 0.887179 | Val Loss: 0.109155, Val Acc: 0.783505\n",
      "Epoch 30487 - Train Loss: 0.069705, Train Acc: 0.887179 | Val Loss: 0.109155, Val Acc: 0.783505\n",
      "Epoch 30488 - Train Loss: 0.069703, Train Acc: 0.887179 | Val Loss: 0.109154, Val Acc: 0.783505\n",
      "Epoch 30489 - Train Loss: 0.069702, Train Acc: 0.887179 | Val Loss: 0.109154, Val Acc: 0.783505\n",
      "Epoch 30490 - Train Loss: 0.069701, Train Acc: 0.887179 | Val Loss: 0.109154, Val Acc: 0.783505\n",
      "Epoch 30491 - Train Loss: 0.069700, Train Acc: 0.887179 | Val Loss: 0.109154, Val Acc: 0.783505\n",
      "Epoch 30492 - Train Loss: 0.069699, Train Acc: 0.887179 | Val Loss: 0.109153, Val Acc: 0.783505\n",
      "Epoch 30493 - Train Loss: 0.069697, Train Acc: 0.887179 | Val Loss: 0.109153, Val Acc: 0.783505\n",
      "Epoch 30494 - Train Loss: 0.069696, Train Acc: 0.887179 | Val Loss: 0.109153, Val Acc: 0.783505\n",
      "Epoch 30495 - Train Loss: 0.069695, Train Acc: 0.887179 | Val Loss: 0.109153, Val Acc: 0.783505\n",
      "Epoch 30496 - Train Loss: 0.069694, Train Acc: 0.887179 | Val Loss: 0.109153, Val Acc: 0.783505\n",
      "Epoch 30497 - Train Loss: 0.069693, Train Acc: 0.887179 | Val Loss: 0.109152, Val Acc: 0.783505\n",
      "Epoch 30498 - Train Loss: 0.069691, Train Acc: 0.887179 | Val Loss: 0.109152, Val Acc: 0.783505\n",
      "Epoch 30499 - Train Loss: 0.069690, Train Acc: 0.887179 | Val Loss: 0.109152, Val Acc: 0.783505\n",
      "Epoch 30500 - Train Loss: 0.069689, Train Acc: 0.887179 | Val Loss: 0.109152, Val Acc: 0.783505\n",
      "Epoch 30501 - Train Loss: 0.069688, Train Acc: 0.887179 | Val Loss: 0.109151, Val Acc: 0.783505\n",
      "Epoch 30502 - Train Loss: 0.069687, Train Acc: 0.887179 | Val Loss: 0.109151, Val Acc: 0.783505\n",
      "Epoch 30503 - Train Loss: 0.069685, Train Acc: 0.887179 | Val Loss: 0.109151, Val Acc: 0.783505\n",
      "Epoch 30504 - Train Loss: 0.069684, Train Acc: 0.887179 | Val Loss: 0.109151, Val Acc: 0.783505\n",
      "Epoch 30505 - Train Loss: 0.069683, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 30506 - Train Loss: 0.069682, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 30507 - Train Loss: 0.069681, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 30508 - Train Loss: 0.069680, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 30509 - Train Loss: 0.069678, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 30510 - Train Loss: 0.069677, Train Acc: 0.887179 | Val Loss: 0.109149, Val Acc: 0.783505\n",
      "Epoch 30511 - Train Loss: 0.069676, Train Acc: 0.887179 | Val Loss: 0.109149, Val Acc: 0.783505\n",
      "Epoch 30512 - Train Loss: 0.069675, Train Acc: 0.887179 | Val Loss: 0.109149, Val Acc: 0.783505\n",
      "Epoch 30513 - Train Loss: 0.069674, Train Acc: 0.887179 | Val Loss: 0.109149, Val Acc: 0.783505\n",
      "Epoch 30514 - Train Loss: 0.069672, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 30515 - Train Loss: 0.069671, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 30516 - Train Loss: 0.069670, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 30517 - Train Loss: 0.069669, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 30518 - Train Loss: 0.069668, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 30519 - Train Loss: 0.069666, Train Acc: 0.887179 | Val Loss: 0.109147, Val Acc: 0.783505\n",
      "Epoch 30520 - Train Loss: 0.069665, Train Acc: 0.887179 | Val Loss: 0.109147, Val Acc: 0.783505\n",
      "Epoch 30521 - Train Loss: 0.069664, Train Acc: 0.887179 | Val Loss: 0.109147, Val Acc: 0.783505\n",
      "Epoch 30522 - Train Loss: 0.069663, Train Acc: 0.887179 | Val Loss: 0.109147, Val Acc: 0.783505\n",
      "Epoch 30523 - Train Loss: 0.069662, Train Acc: 0.887179 | Val Loss: 0.109146, Val Acc: 0.783505\n",
      "Epoch 30524 - Train Loss: 0.069661, Train Acc: 0.887179 | Val Loss: 0.109146, Val Acc: 0.783505\n",
      "Epoch 30525 - Train Loss: 0.069659, Train Acc: 0.887179 | Val Loss: 0.109146, Val Acc: 0.783505\n",
      "Epoch 30526 - Train Loss: 0.069658, Train Acc: 0.887179 | Val Loss: 0.109146, Val Acc: 0.783505\n",
      "Epoch 30527 - Train Loss: 0.069657, Train Acc: 0.887179 | Val Loss: 0.109146, Val Acc: 0.783505\n",
      "Epoch 30528 - Train Loss: 0.069656, Train Acc: 0.887179 | Val Loss: 0.109145, Val Acc: 0.783505\n",
      "Epoch 30529 - Train Loss: 0.069655, Train Acc: 0.887179 | Val Loss: 0.109145, Val Acc: 0.783505\n",
      "Epoch 30530 - Train Loss: 0.069653, Train Acc: 0.887179 | Val Loss: 0.109145, Val Acc: 0.783505\n",
      "Epoch 30531 - Train Loss: 0.069652, Train Acc: 0.887179 | Val Loss: 0.109145, Val Acc: 0.783505\n",
      "Epoch 30532 - Train Loss: 0.069651, Train Acc: 0.887179 | Val Loss: 0.109144, Val Acc: 0.783505\n",
      "Epoch 30533 - Train Loss: 0.069650, Train Acc: 0.887179 | Val Loss: 0.109144, Val Acc: 0.783505\n",
      "Epoch 30534 - Train Loss: 0.069649, Train Acc: 0.887179 | Val Loss: 0.109144, Val Acc: 0.783505\n",
      "Epoch 30535 - Train Loss: 0.069647, Train Acc: 0.887179 | Val Loss: 0.109144, Val Acc: 0.783505\n",
      "Epoch 30536 - Train Loss: 0.069646, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 30537 - Train Loss: 0.069645, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 30538 - Train Loss: 0.069644, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 30539 - Train Loss: 0.069643, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 30540 - Train Loss: 0.069641, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 30541 - Train Loss: 0.069640, Train Acc: 0.887179 | Val Loss: 0.109142, Val Acc: 0.783505\n",
      "Epoch 30542 - Train Loss: 0.069639, Train Acc: 0.887179 | Val Loss: 0.109142, Val Acc: 0.783505\n",
      "Epoch 30543 - Train Loss: 0.069638, Train Acc: 0.887179 | Val Loss: 0.109142, Val Acc: 0.783505\n",
      "Epoch 30544 - Train Loss: 0.069637, Train Acc: 0.887179 | Val Loss: 0.109142, Val Acc: 0.783505\n",
      "Epoch 30545 - Train Loss: 0.069636, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 30546 - Train Loss: 0.069634, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 30547 - Train Loss: 0.069633, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 30548 - Train Loss: 0.069632, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 30549 - Train Loss: 0.069631, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 30550 - Train Loss: 0.069630, Train Acc: 0.887179 | Val Loss: 0.109140, Val Acc: 0.783505\n",
      "Epoch 30551 - Train Loss: 0.069628, Train Acc: 0.887179 | Val Loss: 0.109140, Val Acc: 0.783505\n",
      "Epoch 30552 - Train Loss: 0.069627, Train Acc: 0.887179 | Val Loss: 0.109140, Val Acc: 0.783505\n",
      "Epoch 30553 - Train Loss: 0.069626, Train Acc: 0.887179 | Val Loss: 0.109140, Val Acc: 0.783505\n",
      "Epoch 30554 - Train Loss: 0.069625, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 30555 - Train Loss: 0.069624, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 30556 - Train Loss: 0.069623, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 30557 - Train Loss: 0.069621, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 30558 - Train Loss: 0.069620, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 30559 - Train Loss: 0.069619, Train Acc: 0.887179 | Val Loss: 0.109138, Val Acc: 0.783505\n",
      "Epoch 30560 - Train Loss: 0.069618, Train Acc: 0.887179 | Val Loss: 0.109138, Val Acc: 0.783505\n",
      "Epoch 30561 - Train Loss: 0.069617, Train Acc: 0.887179 | Val Loss: 0.109138, Val Acc: 0.783505\n",
      "Epoch 30562 - Train Loss: 0.069615, Train Acc: 0.887179 | Val Loss: 0.109138, Val Acc: 0.783505\n",
      "Epoch 30563 - Train Loss: 0.069614, Train Acc: 0.887179 | Val Loss: 0.109137, Val Acc: 0.783505\n",
      "Epoch 30564 - Train Loss: 0.069613, Train Acc: 0.887179 | Val Loss: 0.109137, Val Acc: 0.783505\n",
      "Epoch 30565 - Train Loss: 0.069612, Train Acc: 0.887179 | Val Loss: 0.109137, Val Acc: 0.783505\n",
      "Epoch 30566 - Train Loss: 0.069611, Train Acc: 0.887179 | Val Loss: 0.109137, Val Acc: 0.783505\n",
      "Epoch 30567 - Train Loss: 0.069609, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 30568 - Train Loss: 0.069608, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 30569 - Train Loss: 0.069607, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 30570 - Train Loss: 0.069606, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 30571 - Train Loss: 0.069605, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 30572 - Train Loss: 0.069604, Train Acc: 0.887179 | Val Loss: 0.109135, Val Acc: 0.783505\n",
      "Epoch 30573 - Train Loss: 0.069602, Train Acc: 0.887179 | Val Loss: 0.109135, Val Acc: 0.783505\n",
      "Epoch 30574 - Train Loss: 0.069601, Train Acc: 0.887179 | Val Loss: 0.109135, Val Acc: 0.783505\n",
      "Epoch 30575 - Train Loss: 0.069600, Train Acc: 0.887179 | Val Loss: 0.109135, Val Acc: 0.783505\n",
      "Epoch 30576 - Train Loss: 0.069599, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 30577 - Train Loss: 0.069598, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 30578 - Train Loss: 0.069596, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 30579 - Train Loss: 0.069595, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 30580 - Train Loss: 0.069594, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 30581 - Train Loss: 0.069593, Train Acc: 0.887179 | Val Loss: 0.109133, Val Acc: 0.783505\n",
      "Epoch 30582 - Train Loss: 0.069592, Train Acc: 0.887179 | Val Loss: 0.109133, Val Acc: 0.783505\n",
      "Epoch 30583 - Train Loss: 0.069590, Train Acc: 0.887179 | Val Loss: 0.109133, Val Acc: 0.783505\n",
      "Epoch 30584 - Train Loss: 0.069589, Train Acc: 0.887179 | Val Loss: 0.109133, Val Acc: 0.783505\n",
      "Epoch 30585 - Train Loss: 0.069588, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 30586 - Train Loss: 0.069587, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 30587 - Train Loss: 0.069586, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 30588 - Train Loss: 0.069585, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 30589 - Train Loss: 0.069583, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 30590 - Train Loss: 0.069582, Train Acc: 0.887179 | Val Loss: 0.109131, Val Acc: 0.783505\n",
      "Epoch 30591 - Train Loss: 0.069581, Train Acc: 0.887179 | Val Loss: 0.109131, Val Acc: 0.783505\n",
      "Epoch 30592 - Train Loss: 0.069580, Train Acc: 0.887179 | Val Loss: 0.109131, Val Acc: 0.783505\n",
      "Epoch 30593 - Train Loss: 0.069579, Train Acc: 0.887179 | Val Loss: 0.109131, Val Acc: 0.783505\n",
      "Epoch 30594 - Train Loss: 0.069577, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 30595 - Train Loss: 0.069576, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 30596 - Train Loss: 0.069575, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 30597 - Train Loss: 0.069574, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 30598 - Train Loss: 0.069573, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 30599 - Train Loss: 0.069572, Train Acc: 0.887179 | Val Loss: 0.109129, Val Acc: 0.783505\n",
      "Epoch 30600 - Train Loss: 0.069570, Train Acc: 0.887179 | Val Loss: 0.109129, Val Acc: 0.783505\n",
      "Epoch 30601 - Train Loss: 0.069569, Train Acc: 0.887179 | Val Loss: 0.109129, Val Acc: 0.783505\n",
      "Epoch 30602 - Train Loss: 0.069568, Train Acc: 0.887179 | Val Loss: 0.109129, Val Acc: 0.783505\n",
      "Epoch 30603 - Train Loss: 0.069567, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 30604 - Train Loss: 0.069566, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 30605 - Train Loss: 0.069564, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 30606 - Train Loss: 0.069563, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 30607 - Train Loss: 0.069562, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 30608 - Train Loss: 0.069561, Train Acc: 0.887179 | Val Loss: 0.109127, Val Acc: 0.783505\n",
      "Epoch 30609 - Train Loss: 0.069560, Train Acc: 0.887179 | Val Loss: 0.109127, Val Acc: 0.783505\n",
      "Epoch 30610 - Train Loss: 0.069559, Train Acc: 0.887179 | Val Loss: 0.109127, Val Acc: 0.783505\n",
      "Epoch 30611 - Train Loss: 0.069557, Train Acc: 0.887179 | Val Loss: 0.109127, Val Acc: 0.783505\n",
      "Epoch 30612 - Train Loss: 0.069556, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 30613 - Train Loss: 0.069555, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 30614 - Train Loss: 0.069554, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 30615 - Train Loss: 0.069553, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 30616 - Train Loss: 0.069551, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 30617 - Train Loss: 0.069550, Train Acc: 0.887179 | Val Loss: 0.109125, Val Acc: 0.783505\n",
      "Epoch 30618 - Train Loss: 0.069549, Train Acc: 0.887179 | Val Loss: 0.109125, Val Acc: 0.783505\n",
      "Epoch 30619 - Train Loss: 0.069548, Train Acc: 0.887179 | Val Loss: 0.109125, Val Acc: 0.783505\n",
      "Epoch 30620 - Train Loss: 0.069547, Train Acc: 0.887179 | Val Loss: 0.109125, Val Acc: 0.783505\n",
      "Epoch 30621 - Train Loss: 0.069545, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 30622 - Train Loss: 0.069544, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 30623 - Train Loss: 0.069543, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 30624 - Train Loss: 0.069542, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 30625 - Train Loss: 0.069541, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 30626 - Train Loss: 0.069540, Train Acc: 0.887179 | Val Loss: 0.109123, Val Acc: 0.783505\n",
      "Epoch 30627 - Train Loss: 0.069538, Train Acc: 0.887179 | Val Loss: 0.109123, Val Acc: 0.783505\n",
      "Epoch 30628 - Train Loss: 0.069537, Train Acc: 0.887179 | Val Loss: 0.109123, Val Acc: 0.783505\n",
      "Epoch 30629 - Train Loss: 0.069536, Train Acc: 0.887179 | Val Loss: 0.109123, Val Acc: 0.783505\n",
      "Epoch 30630 - Train Loss: 0.069535, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 30631 - Train Loss: 0.069534, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 30632 - Train Loss: 0.069532, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 30633 - Train Loss: 0.069531, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 30634 - Train Loss: 0.069530, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 30635 - Train Loss: 0.069529, Train Acc: 0.887179 | Val Loss: 0.109121, Val Acc: 0.783505\n",
      "Epoch 30636 - Train Loss: 0.069528, Train Acc: 0.887179 | Val Loss: 0.109121, Val Acc: 0.783505\n",
      "Epoch 30637 - Train Loss: 0.069527, Train Acc: 0.887179 | Val Loss: 0.109121, Val Acc: 0.783505\n",
      "Epoch 30638 - Train Loss: 0.069525, Train Acc: 0.887179 | Val Loss: 0.109121, Val Acc: 0.783505\n",
      "Epoch 30639 - Train Loss: 0.069524, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 30640 - Train Loss: 0.069523, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 30641 - Train Loss: 0.069522, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 30642 - Train Loss: 0.069521, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 30643 - Train Loss: 0.069519, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 30644 - Train Loss: 0.069518, Train Acc: 0.887179 | Val Loss: 0.109119, Val Acc: 0.783505\n",
      "Epoch 30645 - Train Loss: 0.069517, Train Acc: 0.887179 | Val Loss: 0.109119, Val Acc: 0.783505\n",
      "Epoch 30646 - Train Loss: 0.069516, Train Acc: 0.887179 | Val Loss: 0.109119, Val Acc: 0.783505\n",
      "Epoch 30647 - Train Loss: 0.069515, Train Acc: 0.887179 | Val Loss: 0.109119, Val Acc: 0.783505\n",
      "Epoch 30648 - Train Loss: 0.069514, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 30649 - Train Loss: 0.069512, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 30650 - Train Loss: 0.069511, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 30651 - Train Loss: 0.069510, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 30652 - Train Loss: 0.069509, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 30653 - Train Loss: 0.069508, Train Acc: 0.887179 | Val Loss: 0.109117, Val Acc: 0.783505\n",
      "Epoch 30654 - Train Loss: 0.069506, Train Acc: 0.887179 | Val Loss: 0.109117, Val Acc: 0.783505\n",
      "Epoch 30655 - Train Loss: 0.069505, Train Acc: 0.887179 | Val Loss: 0.109117, Val Acc: 0.783505\n",
      "Epoch 30656 - Train Loss: 0.069504, Train Acc: 0.887179 | Val Loss: 0.109117, Val Acc: 0.783505\n",
      "Epoch 30657 - Train Loss: 0.069503, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 30658 - Train Loss: 0.069502, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 30659 - Train Loss: 0.069501, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 30660 - Train Loss: 0.069499, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 30661 - Train Loss: 0.069498, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 30662 - Train Loss: 0.069497, Train Acc: 0.887179 | Val Loss: 0.109115, Val Acc: 0.783505\n",
      "Epoch 30663 - Train Loss: 0.069496, Train Acc: 0.887179 | Val Loss: 0.109115, Val Acc: 0.783505\n",
      "Epoch 30664 - Train Loss: 0.069495, Train Acc: 0.887179 | Val Loss: 0.109115, Val Acc: 0.783505\n",
      "Epoch 30665 - Train Loss: 0.069493, Train Acc: 0.887179 | Val Loss: 0.109115, Val Acc: 0.783505\n",
      "Epoch 30666 - Train Loss: 0.069492, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 30667 - Train Loss: 0.069491, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 30668 - Train Loss: 0.069490, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 30669 - Train Loss: 0.069489, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 30670 - Train Loss: 0.069488, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 30671 - Train Loss: 0.069486, Train Acc: 0.887179 | Val Loss: 0.109113, Val Acc: 0.783505\n",
      "Epoch 30672 - Train Loss: 0.069485, Train Acc: 0.887179 | Val Loss: 0.109113, Val Acc: 0.783505\n",
      "Epoch 30673 - Train Loss: 0.069484, Train Acc: 0.887179 | Val Loss: 0.109113, Val Acc: 0.783505\n",
      "Epoch 30674 - Train Loss: 0.069483, Train Acc: 0.887179 | Val Loss: 0.109113, Val Acc: 0.783505\n",
      "Epoch 30675 - Train Loss: 0.069482, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 30676 - Train Loss: 0.069480, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 30677 - Train Loss: 0.069479, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 30678 - Train Loss: 0.069478, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 30679 - Train Loss: 0.069477, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 30680 - Train Loss: 0.069476, Train Acc: 0.887179 | Val Loss: 0.109111, Val Acc: 0.783505\n",
      "Epoch 30681 - Train Loss: 0.069475, Train Acc: 0.887179 | Val Loss: 0.109111, Val Acc: 0.783505\n",
      "Epoch 30682 - Train Loss: 0.069473, Train Acc: 0.887179 | Val Loss: 0.109111, Val Acc: 0.783505\n",
      "Epoch 30683 - Train Loss: 0.069472, Train Acc: 0.887179 | Val Loss: 0.109111, Val Acc: 0.783505\n",
      "Epoch 30684 - Train Loss: 0.069471, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 30685 - Train Loss: 0.069470, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 30686 - Train Loss: 0.069469, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 30687 - Train Loss: 0.069468, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 30688 - Train Loss: 0.069466, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 30689 - Train Loss: 0.069465, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 30690 - Train Loss: 0.069464, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 30691 - Train Loss: 0.069463, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 30692 - Train Loss: 0.069462, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 30693 - Train Loss: 0.069460, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 30694 - Train Loss: 0.069459, Train Acc: 0.887179 | Val Loss: 0.109108, Val Acc: 0.783505\n",
      "Epoch 30695 - Train Loss: 0.069458, Train Acc: 0.887179 | Val Loss: 0.109108, Val Acc: 0.783505\n",
      "Epoch 30696 - Train Loss: 0.069457, Train Acc: 0.887179 | Val Loss: 0.109108, Val Acc: 0.783505\n",
      "Epoch 30697 - Train Loss: 0.069456, Train Acc: 0.887179 | Val Loss: 0.109108, Val Acc: 0.783505\n",
      "Epoch 30698 - Train Loss: 0.069455, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 30699 - Train Loss: 0.069453, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 30700 - Train Loss: 0.069452, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 30701 - Train Loss: 0.069451, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 30702 - Train Loss: 0.069450, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 30703 - Train Loss: 0.069449, Train Acc: 0.887179 | Val Loss: 0.109106, Val Acc: 0.783505\n",
      "Epoch 30704 - Train Loss: 0.069447, Train Acc: 0.887179 | Val Loss: 0.109106, Val Acc: 0.783505\n",
      "Epoch 30705 - Train Loss: 0.069446, Train Acc: 0.887179 | Val Loss: 0.109106, Val Acc: 0.783505\n",
      "Epoch 30706 - Train Loss: 0.069445, Train Acc: 0.887179 | Val Loss: 0.109106, Val Acc: 0.783505\n",
      "Epoch 30707 - Train Loss: 0.069444, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 30708 - Train Loss: 0.069443, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 30709 - Train Loss: 0.069442, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 30710 - Train Loss: 0.069440, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 30711 - Train Loss: 0.069439, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 30712 - Train Loss: 0.069438, Train Acc: 0.887179 | Val Loss: 0.109104, Val Acc: 0.783505\n",
      "Epoch 30713 - Train Loss: 0.069437, Train Acc: 0.887179 | Val Loss: 0.109104, Val Acc: 0.783505\n",
      "Epoch 30714 - Train Loss: 0.069436, Train Acc: 0.887179 | Val Loss: 0.109104, Val Acc: 0.783505\n",
      "Epoch 30715 - Train Loss: 0.069435, Train Acc: 0.887179 | Val Loss: 0.109104, Val Acc: 0.783505\n",
      "Epoch 30716 - Train Loss: 0.069433, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 30717 - Train Loss: 0.069432, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 30718 - Train Loss: 0.069431, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 30719 - Train Loss: 0.069430, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 30720 - Train Loss: 0.069429, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 30721 - Train Loss: 0.069427, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 30722 - Train Loss: 0.069426, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 30723 - Train Loss: 0.069425, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 30724 - Train Loss: 0.069424, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 30725 - Train Loss: 0.069423, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 30726 - Train Loss: 0.069422, Train Acc: 0.887179 | Val Loss: 0.109101, Val Acc: 0.783505\n",
      "Epoch 30727 - Train Loss: 0.069420, Train Acc: 0.887179 | Val Loss: 0.109101, Val Acc: 0.783505\n",
      "Epoch 30728 - Train Loss: 0.069419, Train Acc: 0.887179 | Val Loss: 0.109101, Val Acc: 0.783505\n",
      "Epoch 30729 - Train Loss: 0.069418, Train Acc: 0.887179 | Val Loss: 0.109101, Val Acc: 0.783505\n",
      "Epoch 30730 - Train Loss: 0.069417, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 30731 - Train Loss: 0.069416, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 30732 - Train Loss: 0.069414, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 30733 - Train Loss: 0.069413, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 30734 - Train Loss: 0.069412, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 30735 - Train Loss: 0.069411, Train Acc: 0.887179 | Val Loss: 0.109099, Val Acc: 0.783505\n",
      "Epoch 30736 - Train Loss: 0.069410, Train Acc: 0.887179 | Val Loss: 0.109099, Val Acc: 0.783505\n",
      "Epoch 30737 - Train Loss: 0.069409, Train Acc: 0.887179 | Val Loss: 0.109099, Val Acc: 0.783505\n",
      "Epoch 30738 - Train Loss: 0.069407, Train Acc: 0.887179 | Val Loss: 0.109099, Val Acc: 0.783505\n",
      "Epoch 30739 - Train Loss: 0.069406, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 30740 - Train Loss: 0.069405, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 30741 - Train Loss: 0.069404, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 30742 - Train Loss: 0.069403, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 30743 - Train Loss: 0.069402, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 30744 - Train Loss: 0.069400, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 30745 - Train Loss: 0.069399, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 30746 - Train Loss: 0.069398, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 30747 - Train Loss: 0.069397, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 30748 - Train Loss: 0.069396, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 30749 - Train Loss: 0.069394, Train Acc: 0.887179 | Val Loss: 0.109096, Val Acc: 0.783505\n",
      "Epoch 30750 - Train Loss: 0.069393, Train Acc: 0.887179 | Val Loss: 0.109096, Val Acc: 0.783505\n",
      "Epoch 30751 - Train Loss: 0.069392, Train Acc: 0.887179 | Val Loss: 0.109096, Val Acc: 0.783505\n",
      "Epoch 30752 - Train Loss: 0.069391, Train Acc: 0.887179 | Val Loss: 0.109096, Val Acc: 0.783505\n",
      "Epoch 30753 - Train Loss: 0.069390, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 30754 - Train Loss: 0.069389, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 30755 - Train Loss: 0.069387, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 30756 - Train Loss: 0.069386, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 30757 - Train Loss: 0.069385, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 30758 - Train Loss: 0.069384, Train Acc: 0.887179 | Val Loss: 0.109094, Val Acc: 0.783505\n",
      "Epoch 30759 - Train Loss: 0.069383, Train Acc: 0.887179 | Val Loss: 0.109094, Val Acc: 0.783505\n",
      "Epoch 30760 - Train Loss: 0.069382, Train Acc: 0.887179 | Val Loss: 0.109094, Val Acc: 0.783505\n",
      "Epoch 30761 - Train Loss: 0.069380, Train Acc: 0.887179 | Val Loss: 0.109094, Val Acc: 0.783505\n",
      "Epoch 30762 - Train Loss: 0.069379, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 30763 - Train Loss: 0.069378, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 30764 - Train Loss: 0.069377, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 30765 - Train Loss: 0.069376, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 30766 - Train Loss: 0.069374, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 30767 - Train Loss: 0.069373, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 30768 - Train Loss: 0.069372, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 30769 - Train Loss: 0.069371, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 30770 - Train Loss: 0.069370, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 30771 - Train Loss: 0.069369, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 30772 - Train Loss: 0.069367, Train Acc: 0.887179 | Val Loss: 0.109091, Val Acc: 0.783505\n",
      "Epoch 30773 - Train Loss: 0.069366, Train Acc: 0.887179 | Val Loss: 0.109091, Val Acc: 0.783505\n",
      "Epoch 30774 - Train Loss: 0.069365, Train Acc: 0.887179 | Val Loss: 0.109091, Val Acc: 0.783505\n",
      "Epoch 30775 - Train Loss: 0.069364, Train Acc: 0.887179 | Val Loss: 0.109091, Val Acc: 0.783505\n",
      "Epoch 30776 - Train Loss: 0.069363, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 30777 - Train Loss: 0.069362, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 30778 - Train Loss: 0.069360, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 30779 - Train Loss: 0.069359, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 30780 - Train Loss: 0.069358, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 30781 - Train Loss: 0.069357, Train Acc: 0.887179 | Val Loss: 0.109089, Val Acc: 0.783505\n",
      "Epoch 30782 - Train Loss: 0.069356, Train Acc: 0.887179 | Val Loss: 0.109089, Val Acc: 0.783505\n",
      "Epoch 30783 - Train Loss: 0.069355, Train Acc: 0.887179 | Val Loss: 0.109089, Val Acc: 0.783505\n",
      "Epoch 30784 - Train Loss: 0.069353, Train Acc: 0.887179 | Val Loss: 0.109089, Val Acc: 0.783505\n",
      "Epoch 30785 - Train Loss: 0.069352, Train Acc: 0.887179 | Val Loss: 0.109089, Val Acc: 0.783505\n",
      "Epoch 30786 - Train Loss: 0.069351, Train Acc: 0.887179 | Val Loss: 0.109088, Val Acc: 0.783505\n",
      "Epoch 30787 - Train Loss: 0.069350, Train Acc: 0.887179 | Val Loss: 0.109088, Val Acc: 0.783505\n",
      "Epoch 30788 - Train Loss: 0.069349, Train Acc: 0.887179 | Val Loss: 0.109088, Val Acc: 0.783505\n",
      "Epoch 30789 - Train Loss: 0.069347, Train Acc: 0.887179 | Val Loss: 0.109088, Val Acc: 0.783505\n",
      "Epoch 30790 - Train Loss: 0.069346, Train Acc: 0.885897 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 30791 - Train Loss: 0.069345, Train Acc: 0.885897 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 30792 - Train Loss: 0.069344, Train Acc: 0.885897 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 30793 - Train Loss: 0.069343, Train Acc: 0.885897 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 30794 - Train Loss: 0.069342, Train Acc: 0.885897 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 30795 - Train Loss: 0.069340, Train Acc: 0.885897 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 30796 - Train Loss: 0.069339, Train Acc: 0.885897 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 30797 - Train Loss: 0.069338, Train Acc: 0.885897 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 30798 - Train Loss: 0.069337, Train Acc: 0.885897 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 30799 - Train Loss: 0.069336, Train Acc: 0.885897 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 30800 - Train Loss: 0.069335, Train Acc: 0.885897 | Val Loss: 0.109085, Val Acc: 0.783505\n",
      "Epoch 30801 - Train Loss: 0.069333, Train Acc: 0.885897 | Val Loss: 0.109085, Val Acc: 0.783505\n",
      "Epoch 30802 - Train Loss: 0.069332, Train Acc: 0.885897 | Val Loss: 0.109085, Val Acc: 0.783505\n",
      "Epoch 30803 - Train Loss: 0.069331, Train Acc: 0.885897 | Val Loss: 0.109085, Val Acc: 0.783505\n",
      "Epoch 30804 - Train Loss: 0.069330, Train Acc: 0.885897 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 30805 - Train Loss: 0.069329, Train Acc: 0.885897 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 30806 - Train Loss: 0.069328, Train Acc: 0.885897 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 30807 - Train Loss: 0.069326, Train Acc: 0.885897 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 30808 - Train Loss: 0.069325, Train Acc: 0.885897 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 30809 - Train Loss: 0.069324, Train Acc: 0.885897 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 30810 - Train Loss: 0.069323, Train Acc: 0.885897 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 30811 - Train Loss: 0.069322, Train Acc: 0.885897 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 30812 - Train Loss: 0.069320, Train Acc: 0.885897 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 30813 - Train Loss: 0.069319, Train Acc: 0.885897 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 30814 - Train Loss: 0.069318, Train Acc: 0.885897 | Val Loss: 0.109082, Val Acc: 0.783505\n",
      "Epoch 30815 - Train Loss: 0.069317, Train Acc: 0.885897 | Val Loss: 0.109082, Val Acc: 0.783505\n",
      "Epoch 30816 - Train Loss: 0.069316, Train Acc: 0.885897 | Val Loss: 0.109082, Val Acc: 0.783505\n",
      "Epoch 30817 - Train Loss: 0.069315, Train Acc: 0.885897 | Val Loss: 0.109082, Val Acc: 0.783505\n",
      "Epoch 30818 - Train Loss: 0.069313, Train Acc: 0.885897 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 30819 - Train Loss: 0.069312, Train Acc: 0.885897 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 30820 - Train Loss: 0.069311, Train Acc: 0.885897 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 30821 - Train Loss: 0.069310, Train Acc: 0.885897 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 30822 - Train Loss: 0.069309, Train Acc: 0.885897 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 30823 - Train Loss: 0.069308, Train Acc: 0.885897 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 30824 - Train Loss: 0.069306, Train Acc: 0.885897 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 30825 - Train Loss: 0.069305, Train Acc: 0.885897 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 30826 - Train Loss: 0.069304, Train Acc: 0.885897 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 30827 - Train Loss: 0.069303, Train Acc: 0.885897 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 30828 - Train Loss: 0.069302, Train Acc: 0.885897 | Val Loss: 0.109079, Val Acc: 0.783505\n",
      "Epoch 30829 - Train Loss: 0.069301, Train Acc: 0.885897 | Val Loss: 0.109079, Val Acc: 0.783505\n",
      "Epoch 30830 - Train Loss: 0.069299, Train Acc: 0.885897 | Val Loss: 0.109079, Val Acc: 0.783505\n",
      "Epoch 30831 - Train Loss: 0.069298, Train Acc: 0.885897 | Val Loss: 0.109079, Val Acc: 0.783505\n",
      "Epoch 30832 - Train Loss: 0.069297, Train Acc: 0.885897 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 30833 - Train Loss: 0.069296, Train Acc: 0.885897 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 30834 - Train Loss: 0.069295, Train Acc: 0.885897 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 30835 - Train Loss: 0.069294, Train Acc: 0.885897 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 30836 - Train Loss: 0.069292, Train Acc: 0.885897 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 30837 - Train Loss: 0.069291, Train Acc: 0.885897 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 30838 - Train Loss: 0.069290, Train Acc: 0.885897 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 30839 - Train Loss: 0.069289, Train Acc: 0.885897 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 30840 - Train Loss: 0.069288, Train Acc: 0.885897 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 30841 - Train Loss: 0.069286, Train Acc: 0.885897 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 30842 - Train Loss: 0.069285, Train Acc: 0.885897 | Val Loss: 0.109076, Val Acc: 0.783505\n",
      "Epoch 30843 - Train Loss: 0.069284, Train Acc: 0.885897 | Val Loss: 0.109076, Val Acc: 0.783505\n",
      "Epoch 30844 - Train Loss: 0.069283, Train Acc: 0.885897 | Val Loss: 0.109076, Val Acc: 0.783505\n",
      "Epoch 30845 - Train Loss: 0.069282, Train Acc: 0.885897 | Val Loss: 0.109076, Val Acc: 0.783505\n",
      "Epoch 30846 - Train Loss: 0.069281, Train Acc: 0.885897 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 30847 - Train Loss: 0.069279, Train Acc: 0.885897 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 30848 - Train Loss: 0.069278, Train Acc: 0.885897 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 30849 - Train Loss: 0.069277, Train Acc: 0.885897 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 30850 - Train Loss: 0.069276, Train Acc: 0.885897 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 30851 - Train Loss: 0.069275, Train Acc: 0.885897 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 30852 - Train Loss: 0.069274, Train Acc: 0.885897 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 30853 - Train Loss: 0.069272, Train Acc: 0.885897 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 30854 - Train Loss: 0.069271, Train Acc: 0.885897 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 30855 - Train Loss: 0.069270, Train Acc: 0.885897 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 30856 - Train Loss: 0.069269, Train Acc: 0.885897 | Val Loss: 0.109073, Val Acc: 0.783505\n",
      "Epoch 30857 - Train Loss: 0.069268, Train Acc: 0.885897 | Val Loss: 0.109073, Val Acc: 0.783505\n",
      "Epoch 30858 - Train Loss: 0.069267, Train Acc: 0.885897 | Val Loss: 0.109073, Val Acc: 0.783505\n",
      "Epoch 30859 - Train Loss: 0.069265, Train Acc: 0.885897 | Val Loss: 0.109073, Val Acc: 0.783505\n",
      "Epoch 30860 - Train Loss: 0.069264, Train Acc: 0.885897 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 30861 - Train Loss: 0.069263, Train Acc: 0.885897 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 30862 - Train Loss: 0.069262, Train Acc: 0.885897 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 30863 - Train Loss: 0.069261, Train Acc: 0.885897 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 30864 - Train Loss: 0.069260, Train Acc: 0.885897 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 30865 - Train Loss: 0.069258, Train Acc: 0.885897 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 30866 - Train Loss: 0.069257, Train Acc: 0.885897 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 30867 - Train Loss: 0.069256, Train Acc: 0.885897 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 30868 - Train Loss: 0.069255, Train Acc: 0.885897 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 30869 - Train Loss: 0.069254, Train Acc: 0.885897 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 30870 - Train Loss: 0.069253, Train Acc: 0.885897 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 30871 - Train Loss: 0.069251, Train Acc: 0.885897 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 30872 - Train Loss: 0.069250, Train Acc: 0.885897 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 30873 - Train Loss: 0.069249, Train Acc: 0.885897 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 30874 - Train Loss: 0.069248, Train Acc: 0.885897 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 30875 - Train Loss: 0.069247, Train Acc: 0.885897 | Val Loss: 0.109069, Val Acc: 0.783505\n",
      "Epoch 30876 - Train Loss: 0.069246, Train Acc: 0.885897 | Val Loss: 0.109069, Val Acc: 0.783505\n",
      "Epoch 30877 - Train Loss: 0.069244, Train Acc: 0.885897 | Val Loss: 0.109069, Val Acc: 0.783505\n",
      "Epoch 30878 - Train Loss: 0.069243, Train Acc: 0.885897 | Val Loss: 0.109069, Val Acc: 0.783505\n",
      "Epoch 30879 - Train Loss: 0.069242, Train Acc: 0.885897 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 30880 - Train Loss: 0.069241, Train Acc: 0.885897 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 30881 - Train Loss: 0.069240, Train Acc: 0.885897 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 30882 - Train Loss: 0.069238, Train Acc: 0.885897 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 30883 - Train Loss: 0.069237, Train Acc: 0.885897 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 30884 - Train Loss: 0.069236, Train Acc: 0.885897 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 30885 - Train Loss: 0.069235, Train Acc: 0.885897 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 30886 - Train Loss: 0.069234, Train Acc: 0.885897 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 30887 - Train Loss: 0.069233, Train Acc: 0.885897 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 30888 - Train Loss: 0.069231, Train Acc: 0.885897 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 30889 - Train Loss: 0.069230, Train Acc: 0.885897 | Val Loss: 0.109066, Val Acc: 0.783505\n",
      "Epoch 30890 - Train Loss: 0.069229, Train Acc: 0.885897 | Val Loss: 0.109066, Val Acc: 0.783505\n",
      "Epoch 30891 - Train Loss: 0.069228, Train Acc: 0.885897 | Val Loss: 0.109066, Val Acc: 0.783505\n",
      "Epoch 30892 - Train Loss: 0.069227, Train Acc: 0.885897 | Val Loss: 0.109066, Val Acc: 0.783505\n",
      "Epoch 30893 - Train Loss: 0.069226, Train Acc: 0.885897 | Val Loss: 0.109065, Val Acc: 0.783505\n",
      "Epoch 30894 - Train Loss: 0.069224, Train Acc: 0.885897 | Val Loss: 0.109065, Val Acc: 0.783505\n",
      "Epoch 30895 - Train Loss: 0.069223, Train Acc: 0.885897 | Val Loss: 0.109065, Val Acc: 0.783505\n",
      "Epoch 30896 - Train Loss: 0.069222, Train Acc: 0.885897 | Val Loss: 0.109065, Val Acc: 0.783505\n",
      "Epoch 30897 - Train Loss: 0.069221, Train Acc: 0.885897 | Val Loss: 0.109065, Val Acc: 0.783505\n",
      "Epoch 30898 - Train Loss: 0.069220, Train Acc: 0.885897 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 30899 - Train Loss: 0.069219, Train Acc: 0.885897 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 30900 - Train Loss: 0.069217, Train Acc: 0.885897 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 30901 - Train Loss: 0.069216, Train Acc: 0.885897 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 30902 - Train Loss: 0.069215, Train Acc: 0.885897 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 30903 - Train Loss: 0.069214, Train Acc: 0.885897 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 30904 - Train Loss: 0.069213, Train Acc: 0.885897 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 30905 - Train Loss: 0.069212, Train Acc: 0.885897 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 30906 - Train Loss: 0.069210, Train Acc: 0.885897 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 30907 - Train Loss: 0.069209, Train Acc: 0.885897 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 30908 - Train Loss: 0.069208, Train Acc: 0.885897 | Val Loss: 0.109062, Val Acc: 0.783505\n",
      "Epoch 30909 - Train Loss: 0.069207, Train Acc: 0.885897 | Val Loss: 0.109062, Val Acc: 0.783505\n",
      "Epoch 30910 - Train Loss: 0.069206, Train Acc: 0.885897 | Val Loss: 0.109062, Val Acc: 0.783505\n",
      "Epoch 30911 - Train Loss: 0.069205, Train Acc: 0.885897 | Val Loss: 0.109062, Val Acc: 0.783505\n",
      "Epoch 30912 - Train Loss: 0.069203, Train Acc: 0.885897 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 30913 - Train Loss: 0.069202, Train Acc: 0.885897 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 30914 - Train Loss: 0.069201, Train Acc: 0.885897 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 30915 - Train Loss: 0.069200, Train Acc: 0.885897 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 30916 - Train Loss: 0.069199, Train Acc: 0.885897 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 30917 - Train Loss: 0.069198, Train Acc: 0.885897 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 30918 - Train Loss: 0.069196, Train Acc: 0.885897 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 30919 - Train Loss: 0.069195, Train Acc: 0.885897 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 30920 - Train Loss: 0.069194, Train Acc: 0.885897 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 30921 - Train Loss: 0.069193, Train Acc: 0.885897 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 30922 - Train Loss: 0.069192, Train Acc: 0.885897 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 30923 - Train Loss: 0.069191, Train Acc: 0.885897 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 30924 - Train Loss: 0.069189, Train Acc: 0.885897 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 30925 - Train Loss: 0.069188, Train Acc: 0.885897 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 30926 - Train Loss: 0.069187, Train Acc: 0.885897 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 30927 - Train Loss: 0.069186, Train Acc: 0.885897 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 30928 - Train Loss: 0.069185, Train Acc: 0.885897 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 30929 - Train Loss: 0.069184, Train Acc: 0.885897 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 30930 - Train Loss: 0.069182, Train Acc: 0.885897 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 30931 - Train Loss: 0.069181, Train Acc: 0.885897 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 30932 - Train Loss: 0.069180, Train Acc: 0.885897 | Val Loss: 0.109057, Val Acc: 0.783505\n",
      "Epoch 30933 - Train Loss: 0.069179, Train Acc: 0.885897 | Val Loss: 0.109057, Val Acc: 0.783505\n",
      "Epoch 30934 - Train Loss: 0.069178, Train Acc: 0.885897 | Val Loss: 0.109057, Val Acc: 0.783505\n",
      "Epoch 30935 - Train Loss: 0.069177, Train Acc: 0.885897 | Val Loss: 0.109057, Val Acc: 0.783505\n",
      "Epoch 30936 - Train Loss: 0.069175, Train Acc: 0.885897 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 30937 - Train Loss: 0.069174, Train Acc: 0.885897 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 30938 - Train Loss: 0.069173, Train Acc: 0.885897 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 30939 - Train Loss: 0.069172, Train Acc: 0.885897 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 30940 - Train Loss: 0.069171, Train Acc: 0.885897 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 30941 - Train Loss: 0.069170, Train Acc: 0.885897 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 30942 - Train Loss: 0.069168, Train Acc: 0.885897 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 30943 - Train Loss: 0.069167, Train Acc: 0.885897 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 30944 - Train Loss: 0.069166, Train Acc: 0.885897 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 30945 - Train Loss: 0.069165, Train Acc: 0.885897 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 30946 - Train Loss: 0.069164, Train Acc: 0.885897 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 30947 - Train Loss: 0.069163, Train Acc: 0.885897 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 30948 - Train Loss: 0.069161, Train Acc: 0.885897 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 30949 - Train Loss: 0.069160, Train Acc: 0.885897 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 30950 - Train Loss: 0.069159, Train Acc: 0.885897 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 30951 - Train Loss: 0.069158, Train Acc: 0.885897 | Val Loss: 0.109053, Val Acc: 0.783505\n",
      "Epoch 30952 - Train Loss: 0.069157, Train Acc: 0.885897 | Val Loss: 0.109053, Val Acc: 0.783505\n",
      "Epoch 30953 - Train Loss: 0.069156, Train Acc: 0.885897 | Val Loss: 0.109053, Val Acc: 0.783505\n",
      "Epoch 30954 - Train Loss: 0.069154, Train Acc: 0.885897 | Val Loss: 0.109053, Val Acc: 0.783505\n",
      "Epoch 30955 - Train Loss: 0.069153, Train Acc: 0.885897 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 30956 - Train Loss: 0.069152, Train Acc: 0.885897 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 30957 - Train Loss: 0.069151, Train Acc: 0.885897 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 30958 - Train Loss: 0.069150, Train Acc: 0.885897 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 30959 - Train Loss: 0.069149, Train Acc: 0.885897 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 30960 - Train Loss: 0.069147, Train Acc: 0.885897 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 30961 - Train Loss: 0.069146, Train Acc: 0.885897 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 30962 - Train Loss: 0.069145, Train Acc: 0.885897 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 30963 - Train Loss: 0.069144, Train Acc: 0.885897 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 30964 - Train Loss: 0.069143, Train Acc: 0.885897 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 30965 - Train Loss: 0.069142, Train Acc: 0.885897 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 30966 - Train Loss: 0.069140, Train Acc: 0.885897 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 30967 - Train Loss: 0.069139, Train Acc: 0.885897 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 30968 - Train Loss: 0.069138, Train Acc: 0.885897 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 30969 - Train Loss: 0.069137, Train Acc: 0.885897 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 30970 - Train Loss: 0.069136, Train Acc: 0.885897 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 30971 - Train Loss: 0.069135, Train Acc: 0.885897 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 30972 - Train Loss: 0.069133, Train Acc: 0.885897 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 30973 - Train Loss: 0.069132, Train Acc: 0.885897 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 30974 - Train Loss: 0.069131, Train Acc: 0.885897 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 30975 - Train Loss: 0.069130, Train Acc: 0.885897 | Val Loss: 0.109048, Val Acc: 0.783505\n",
      "Epoch 30976 - Train Loss: 0.069129, Train Acc: 0.885897 | Val Loss: 0.109048, Val Acc: 0.783505\n",
      "Epoch 30977 - Train Loss: 0.069128, Train Acc: 0.885897 | Val Loss: 0.109048, Val Acc: 0.783505\n",
      "Epoch 30978 - Train Loss: 0.069126, Train Acc: 0.885897 | Val Loss: 0.109048, Val Acc: 0.783505\n",
      "Epoch 30979 - Train Loss: 0.069125, Train Acc: 0.885897 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 30980 - Train Loss: 0.069124, Train Acc: 0.885897 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 30981 - Train Loss: 0.069123, Train Acc: 0.885897 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 30982 - Train Loss: 0.069122, Train Acc: 0.885897 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 30983 - Train Loss: 0.069121, Train Acc: 0.885897 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 30984 - Train Loss: 0.069120, Train Acc: 0.885897 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 30985 - Train Loss: 0.069118, Train Acc: 0.885897 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 30986 - Train Loss: 0.069117, Train Acc: 0.885897 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 30987 - Train Loss: 0.069116, Train Acc: 0.885897 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 30988 - Train Loss: 0.069115, Train Acc: 0.885897 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 30989 - Train Loss: 0.069114, Train Acc: 0.885897 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 30990 - Train Loss: 0.069113, Train Acc: 0.885897 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 30991 - Train Loss: 0.069111, Train Acc: 0.885897 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 30992 - Train Loss: 0.069110, Train Acc: 0.885897 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 30993 - Train Loss: 0.069109, Train Acc: 0.885897 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 30994 - Train Loss: 0.069108, Train Acc: 0.885897 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 30995 - Train Loss: 0.069107, Train Acc: 0.885897 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 30996 - Train Loss: 0.069106, Train Acc: 0.885897 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 30997 - Train Loss: 0.069104, Train Acc: 0.885897 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 30998 - Train Loss: 0.069103, Train Acc: 0.885897 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 30999 - Train Loss: 0.069102, Train Acc: 0.885897 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 31000 - Train Loss: 0.069101, Train Acc: 0.885897 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 31001 - Train Loss: 0.069100, Train Acc: 0.885897 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 31002 - Train Loss: 0.069099, Train Acc: 0.885897 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 31003 - Train Loss: 0.069097, Train Acc: 0.885897 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 31004 - Train Loss: 0.069096, Train Acc: 0.885897 | Val Loss: 0.109042, Val Acc: 0.783505\n",
      "Epoch 31005 - Train Loss: 0.069095, Train Acc: 0.885897 | Val Loss: 0.109042, Val Acc: 0.783505\n",
      "Epoch 31006 - Train Loss: 0.069094, Train Acc: 0.885897 | Val Loss: 0.109042, Val Acc: 0.783505\n",
      "Epoch 31007 - Train Loss: 0.069093, Train Acc: 0.885897 | Val Loss: 0.109042, Val Acc: 0.783505\n",
      "Epoch 31008 - Train Loss: 0.069092, Train Acc: 0.885897 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 31009 - Train Loss: 0.069090, Train Acc: 0.885897 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 31010 - Train Loss: 0.069089, Train Acc: 0.885897 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 31011 - Train Loss: 0.069088, Train Acc: 0.885897 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 31012 - Train Loss: 0.069087, Train Acc: 0.885897 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 31013 - Train Loss: 0.069086, Train Acc: 0.885897 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 31014 - Train Loss: 0.069085, Train Acc: 0.885897 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 31015 - Train Loss: 0.069083, Train Acc: 0.885897 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 31016 - Train Loss: 0.069082, Train Acc: 0.885897 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 31017 - Train Loss: 0.069081, Train Acc: 0.885897 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 31018 - Train Loss: 0.069080, Train Acc: 0.885897 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 31019 - Train Loss: 0.069079, Train Acc: 0.885897 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 31020 - Train Loss: 0.069078, Train Acc: 0.885897 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 31021 - Train Loss: 0.069076, Train Acc: 0.885897 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 31022 - Train Loss: 0.069075, Train Acc: 0.885897 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 31023 - Train Loss: 0.069074, Train Acc: 0.885897 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 31024 - Train Loss: 0.069073, Train Acc: 0.885897 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 31025 - Train Loss: 0.069072, Train Acc: 0.885897 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 31026 - Train Loss: 0.069071, Train Acc: 0.885897 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 31027 - Train Loss: 0.069070, Train Acc: 0.885897 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 31028 - Train Loss: 0.069068, Train Acc: 0.885897 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 31029 - Train Loss: 0.069067, Train Acc: 0.885897 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 31030 - Train Loss: 0.069066, Train Acc: 0.885897 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 31031 - Train Loss: 0.069065, Train Acc: 0.885897 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 31032 - Train Loss: 0.069064, Train Acc: 0.885897 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 31033 - Train Loss: 0.069063, Train Acc: 0.885897 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 31034 - Train Loss: 0.069061, Train Acc: 0.885897 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 31035 - Train Loss: 0.069060, Train Acc: 0.885897 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 31036 - Train Loss: 0.069059, Train Acc: 0.885897 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 31037 - Train Loss: 0.069058, Train Acc: 0.885897 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 31038 - Train Loss: 0.069057, Train Acc: 0.885897 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 31039 - Train Loss: 0.069056, Train Acc: 0.885897 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 31040 - Train Loss: 0.069054, Train Acc: 0.885897 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 31041 - Train Loss: 0.069053, Train Acc: 0.885897 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 31042 - Train Loss: 0.069052, Train Acc: 0.885897 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 31043 - Train Loss: 0.069051, Train Acc: 0.885897 | Val Loss: 0.109034, Val Acc: 0.783505\n",
      "Epoch 31044 - Train Loss: 0.069050, Train Acc: 0.885897 | Val Loss: 0.109034, Val Acc: 0.783505\n",
      "Epoch 31045 - Train Loss: 0.069049, Train Acc: 0.885897 | Val Loss: 0.109034, Val Acc: 0.783505\n",
      "Epoch 31046 - Train Loss: 0.069047, Train Acc: 0.885897 | Val Loss: 0.109034, Val Acc: 0.783505\n",
      "Epoch 31047 - Train Loss: 0.069046, Train Acc: 0.885897 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 31048 - Train Loss: 0.069045, Train Acc: 0.885897 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 31049 - Train Loss: 0.069044, Train Acc: 0.885897 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 31050 - Train Loss: 0.069043, Train Acc: 0.885897 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 31051 - Train Loss: 0.069042, Train Acc: 0.885897 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 31052 - Train Loss: 0.069040, Train Acc: 0.885897 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 31053 - Train Loss: 0.069039, Train Acc: 0.885897 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 31054 - Train Loss: 0.069038, Train Acc: 0.885897 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 31055 - Train Loss: 0.069037, Train Acc: 0.885897 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 31056 - Train Loss: 0.069036, Train Acc: 0.885897 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 31057 - Train Loss: 0.069035, Train Acc: 0.885897 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 31058 - Train Loss: 0.069034, Train Acc: 0.885897 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 31059 - Train Loss: 0.069032, Train Acc: 0.885897 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 31060 - Train Loss: 0.069031, Train Acc: 0.885897 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 31061 - Train Loss: 0.069030, Train Acc: 0.885897 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 31062 - Train Loss: 0.069029, Train Acc: 0.885897 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 31063 - Train Loss: 0.069028, Train Acc: 0.885897 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 31064 - Train Loss: 0.069027, Train Acc: 0.885897 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 31065 - Train Loss: 0.069025, Train Acc: 0.885897 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 31066 - Train Loss: 0.069024, Train Acc: 0.885897 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 31067 - Train Loss: 0.069023, Train Acc: 0.885897 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 31068 - Train Loss: 0.069022, Train Acc: 0.885897 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 31069 - Train Loss: 0.069021, Train Acc: 0.885897 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 31070 - Train Loss: 0.069020, Train Acc: 0.885897 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 31071 - Train Loss: 0.069018, Train Acc: 0.885897 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 31072 - Train Loss: 0.069017, Train Acc: 0.885897 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 31073 - Train Loss: 0.069016, Train Acc: 0.885897 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 31074 - Train Loss: 0.069015, Train Acc: 0.885897 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 31075 - Train Loss: 0.069014, Train Acc: 0.885897 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 31076 - Train Loss: 0.069013, Train Acc: 0.885897 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 31077 - Train Loss: 0.069011, Train Acc: 0.885897 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 31078 - Train Loss: 0.069010, Train Acc: 0.885897 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 31079 - Train Loss: 0.069009, Train Acc: 0.885897 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 31080 - Train Loss: 0.069008, Train Acc: 0.885897 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 31081 - Train Loss: 0.069007, Train Acc: 0.885897 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 31082 - Train Loss: 0.069006, Train Acc: 0.885897 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 31083 - Train Loss: 0.069005, Train Acc: 0.885897 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 31084 - Train Loss: 0.069003, Train Acc: 0.885897 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 31085 - Train Loss: 0.069002, Train Acc: 0.885897 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 31086 - Train Loss: 0.069001, Train Acc: 0.885897 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 31087 - Train Loss: 0.069000, Train Acc: 0.885897 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 31088 - Train Loss: 0.068999, Train Acc: 0.885897 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 31089 - Train Loss: 0.068998, Train Acc: 0.885897 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 31090 - Train Loss: 0.068996, Train Acc: 0.885897 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 31091 - Train Loss: 0.068995, Train Acc: 0.885897 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 31092 - Train Loss: 0.068994, Train Acc: 0.885897 | Val Loss: 0.109024, Val Acc: 0.783505\n",
      "Epoch 31093 - Train Loss: 0.068993, Train Acc: 0.885897 | Val Loss: 0.109024, Val Acc: 0.783505\n",
      "Epoch 31094 - Train Loss: 0.068992, Train Acc: 0.885897 | Val Loss: 0.109024, Val Acc: 0.783505\n",
      "Epoch 31095 - Train Loss: 0.068991, Train Acc: 0.885897 | Val Loss: 0.109024, Val Acc: 0.783505\n",
      "Epoch 31096 - Train Loss: 0.068989, Train Acc: 0.885897 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 31097 - Train Loss: 0.068988, Train Acc: 0.885897 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 31098 - Train Loss: 0.068987, Train Acc: 0.885897 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 31099 - Train Loss: 0.068986, Train Acc: 0.885897 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 31100 - Train Loss: 0.068985, Train Acc: 0.885897 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 31101 - Train Loss: 0.068984, Train Acc: 0.885897 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 31102 - Train Loss: 0.068983, Train Acc: 0.885897 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 31103 - Train Loss: 0.068981, Train Acc: 0.885897 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 31104 - Train Loss: 0.068980, Train Acc: 0.885897 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 31105 - Train Loss: 0.068979, Train Acc: 0.885897 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 31106 - Train Loss: 0.068978, Train Acc: 0.885897 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 31107 - Train Loss: 0.068977, Train Acc: 0.885897 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 31108 - Train Loss: 0.068976, Train Acc: 0.885897 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 31109 - Train Loss: 0.068974, Train Acc: 0.885897 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 31110 - Train Loss: 0.068973, Train Acc: 0.885897 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 31111 - Train Loss: 0.068972, Train Acc: 0.885897 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 31112 - Train Loss: 0.068971, Train Acc: 0.885897 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 31113 - Train Loss: 0.068970, Train Acc: 0.885897 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 31114 - Train Loss: 0.068969, Train Acc: 0.885897 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 31115 - Train Loss: 0.068967, Train Acc: 0.885897 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 31116 - Train Loss: 0.068966, Train Acc: 0.885897 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 31117 - Train Loss: 0.068965, Train Acc: 0.885897 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 31118 - Train Loss: 0.068964, Train Acc: 0.885897 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 31119 - Train Loss: 0.068963, Train Acc: 0.885897 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 31120 - Train Loss: 0.068962, Train Acc: 0.885897 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 31121 - Train Loss: 0.068961, Train Acc: 0.885897 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 31122 - Train Loss: 0.068959, Train Acc: 0.885897 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 31123 - Train Loss: 0.068958, Train Acc: 0.885897 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 31124 - Train Loss: 0.068957, Train Acc: 0.885897 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 31125 - Train Loss: 0.068956, Train Acc: 0.885897 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 31126 - Train Loss: 0.068955, Train Acc: 0.885897 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 31127 - Train Loss: 0.068954, Train Acc: 0.885897 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 31128 - Train Loss: 0.068952, Train Acc: 0.885897 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 31129 - Train Loss: 0.068951, Train Acc: 0.885897 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 31130 - Train Loss: 0.068950, Train Acc: 0.885897 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 31131 - Train Loss: 0.068949, Train Acc: 0.885897 | Val Loss: 0.109016, Val Acc: 0.783505\n",
      "Epoch 31132 - Train Loss: 0.068948, Train Acc: 0.885897 | Val Loss: 0.109016, Val Acc: 0.783505\n",
      "Epoch 31133 - Train Loss: 0.068947, Train Acc: 0.885897 | Val Loss: 0.109016, Val Acc: 0.783505\n",
      "Epoch 31134 - Train Loss: 0.068946, Train Acc: 0.885897 | Val Loss: 0.109016, Val Acc: 0.783505\n",
      "Epoch 31135 - Train Loss: 0.068944, Train Acc: 0.885897 | Val Loss: 0.109016, Val Acc: 0.783505\n",
      "Epoch 31136 - Train Loss: 0.068943, Train Acc: 0.885897 | Val Loss: 0.109015, Val Acc: 0.783505\n",
      "Epoch 31137 - Train Loss: 0.068942, Train Acc: 0.885897 | Val Loss: 0.109015, Val Acc: 0.783505\n",
      "Epoch 31138 - Train Loss: 0.068941, Train Acc: 0.885897 | Val Loss: 0.109015, Val Acc: 0.783505\n",
      "Epoch 31139 - Train Loss: 0.068940, Train Acc: 0.885897 | Val Loss: 0.109015, Val Acc: 0.783505\n",
      "Epoch 31140 - Train Loss: 0.068939, Train Acc: 0.885897 | Val Loss: 0.109015, Val Acc: 0.783505\n",
      "Epoch 31141 - Train Loss: 0.068937, Train Acc: 0.885897 | Val Loss: 0.109014, Val Acc: 0.783505\n",
      "Epoch 31142 - Train Loss: 0.068936, Train Acc: 0.885897 | Val Loss: 0.109014, Val Acc: 0.783505\n",
      "Epoch 31143 - Train Loss: 0.068935, Train Acc: 0.885897 | Val Loss: 0.109014, Val Acc: 0.783505\n",
      "Epoch 31144 - Train Loss: 0.068934, Train Acc: 0.885897 | Val Loss: 0.109014, Val Acc: 0.783505\n",
      "Epoch 31145 - Train Loss: 0.068933, Train Acc: 0.885897 | Val Loss: 0.109014, Val Acc: 0.783505\n",
      "Epoch 31146 - Train Loss: 0.068932, Train Acc: 0.885897 | Val Loss: 0.109013, Val Acc: 0.783505\n",
      "Epoch 31147 - Train Loss: 0.068930, Train Acc: 0.885897 | Val Loss: 0.109013, Val Acc: 0.783505\n",
      "Epoch 31148 - Train Loss: 0.068929, Train Acc: 0.885897 | Val Loss: 0.109013, Val Acc: 0.783505\n",
      "Epoch 31149 - Train Loss: 0.068928, Train Acc: 0.885897 | Val Loss: 0.109013, Val Acc: 0.783505\n",
      "Epoch 31150 - Train Loss: 0.068927, Train Acc: 0.885897 | Val Loss: 0.109013, Val Acc: 0.783505\n",
      "Epoch 31151 - Train Loss: 0.068926, Train Acc: 0.885897 | Val Loss: 0.109012, Val Acc: 0.783505\n",
      "Epoch 31152 - Train Loss: 0.068925, Train Acc: 0.885897 | Val Loss: 0.109012, Val Acc: 0.783505\n",
      "Epoch 31153 - Train Loss: 0.068924, Train Acc: 0.885897 | Val Loss: 0.109012, Val Acc: 0.783505\n",
      "Epoch 31154 - Train Loss: 0.068922, Train Acc: 0.885897 | Val Loss: 0.109012, Val Acc: 0.783505\n",
      "Epoch 31155 - Train Loss: 0.068921, Train Acc: 0.885897 | Val Loss: 0.109012, Val Acc: 0.783505\n",
      "Epoch 31156 - Train Loss: 0.068920, Train Acc: 0.885897 | Val Loss: 0.109011, Val Acc: 0.783505\n",
      "Epoch 31157 - Train Loss: 0.068919, Train Acc: 0.885897 | Val Loss: 0.109011, Val Acc: 0.783505\n",
      "Epoch 31158 - Train Loss: 0.068918, Train Acc: 0.885897 | Val Loss: 0.109011, Val Acc: 0.783505\n",
      "Epoch 31159 - Train Loss: 0.068917, Train Acc: 0.885897 | Val Loss: 0.109011, Val Acc: 0.783505\n",
      "Epoch 31160 - Train Loss: 0.068915, Train Acc: 0.885897 | Val Loss: 0.109011, Val Acc: 0.783505\n",
      "Epoch 31161 - Train Loss: 0.068914, Train Acc: 0.885897 | Val Loss: 0.109010, Val Acc: 0.783505\n",
      "Epoch 31162 - Train Loss: 0.068913, Train Acc: 0.885897 | Val Loss: 0.109010, Val Acc: 0.783505\n",
      "Epoch 31163 - Train Loss: 0.068912, Train Acc: 0.885897 | Val Loss: 0.109010, Val Acc: 0.783505\n",
      "Epoch 31164 - Train Loss: 0.068911, Train Acc: 0.887179 | Val Loss: 0.109010, Val Acc: 0.783505\n",
      "Epoch 31165 - Train Loss: 0.068910, Train Acc: 0.887179 | Val Loss: 0.109010, Val Acc: 0.783505\n",
      "Epoch 31166 - Train Loss: 0.068909, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.783505\n",
      "Epoch 31167 - Train Loss: 0.068907, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.783505\n",
      "Epoch 31168 - Train Loss: 0.068906, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.783505\n",
      "Epoch 31169 - Train Loss: 0.068905, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.783505\n",
      "Epoch 31170 - Train Loss: 0.068904, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.783505\n",
      "Epoch 31171 - Train Loss: 0.068903, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.783505\n",
      "Epoch 31172 - Train Loss: 0.068902, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.783505\n",
      "Epoch 31173 - Train Loss: 0.068900, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.783505\n",
      "Epoch 31174 - Train Loss: 0.068899, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.783505\n",
      "Epoch 31175 - Train Loss: 0.068898, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.783505\n",
      "Epoch 31176 - Train Loss: 0.068897, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.783505\n",
      "Epoch 31177 - Train Loss: 0.068896, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.783505\n",
      "Epoch 31178 - Train Loss: 0.068895, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.783505\n",
      "Epoch 31179 - Train Loss: 0.068894, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.783505\n",
      "Epoch 31180 - Train Loss: 0.068892, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.783505\n",
      "Epoch 31181 - Train Loss: 0.068891, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.783505\n",
      "Epoch 31182 - Train Loss: 0.068890, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.783505\n",
      "Epoch 31183 - Train Loss: 0.068889, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.783505\n",
      "Epoch 31184 - Train Loss: 0.068888, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.783505\n",
      "Epoch 31185 - Train Loss: 0.068887, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.783505\n",
      "Epoch 31186 - Train Loss: 0.068885, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.783505\n",
      "Epoch 31187 - Train Loss: 0.068884, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.783505\n",
      "Epoch 31188 - Train Loss: 0.068883, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.783505\n",
      "Epoch 31189 - Train Loss: 0.068882, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.783505\n",
      "Epoch 31190 - Train Loss: 0.068881, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.783505\n",
      "Epoch 31191 - Train Loss: 0.068880, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.783505\n",
      "Epoch 31192 - Train Loss: 0.068879, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.783505\n",
      "Epoch 31193 - Train Loss: 0.068877, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.783505\n",
      "Epoch 31194 - Train Loss: 0.068876, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.783505\n",
      "Epoch 31195 - Train Loss: 0.068875, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.783505\n",
      "Epoch 31196 - Train Loss: 0.068874, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.783505\n",
      "Epoch 31197 - Train Loss: 0.068873, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.783505\n",
      "Epoch 31198 - Train Loss: 0.068872, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.783505\n",
      "Epoch 31199 - Train Loss: 0.068870, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.783505\n",
      "Epoch 31200 - Train Loss: 0.068869, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.783505\n",
      "Epoch 31201 - Train Loss: 0.068868, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.783505\n",
      "Epoch 31202 - Train Loss: 0.068867, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.783505\n",
      "Epoch 31203 - Train Loss: 0.068866, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.783505\n",
      "Epoch 31204 - Train Loss: 0.068865, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.783505\n",
      "Epoch 31205 - Train Loss: 0.068864, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.783505\n",
      "Epoch 31206 - Train Loss: 0.068862, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.783505\n",
      "Epoch 31207 - Train Loss: 0.068861, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.783505\n",
      "Epoch 31208 - Train Loss: 0.068860, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.783505\n",
      "Epoch 31209 - Train Loss: 0.068859, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.783505\n",
      "Epoch 31210 - Train Loss: 0.068858, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.783505\n",
      "Epoch 31211 - Train Loss: 0.068857, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.783505\n",
      "Epoch 31212 - Train Loss: 0.068855, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.783505\n",
      "Epoch 31213 - Train Loss: 0.068854, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.783505\n",
      "Epoch 31214 - Train Loss: 0.068853, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.783505\n",
      "Epoch 31215 - Train Loss: 0.068852, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.783505\n",
      "Epoch 31216 - Train Loss: 0.068851, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.783505\n",
      "Epoch 31217 - Train Loss: 0.068850, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.783505\n",
      "Epoch 31218 - Train Loss: 0.068849, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.783505\n",
      "Epoch 31219 - Train Loss: 0.068847, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.783505\n",
      "Epoch 31220 - Train Loss: 0.068846, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.783505\n",
      "Epoch 31221 - Train Loss: 0.068845, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.783505\n",
      "Epoch 31222 - Train Loss: 0.068844, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.783505\n",
      "Epoch 31223 - Train Loss: 0.068843, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.783505\n",
      "Epoch 31224 - Train Loss: 0.068842, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.783505\n",
      "Epoch 31225 - Train Loss: 0.068841, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.783505\n",
      "Epoch 31226 - Train Loss: 0.068839, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.783505\n",
      "Epoch 31227 - Train Loss: 0.068838, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.783505\n",
      "Epoch 31228 - Train Loss: 0.068837, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.783505\n",
      "Epoch 31229 - Train Loss: 0.068836, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.783505\n",
      "Epoch 31230 - Train Loss: 0.068835, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.783505\n",
      "Epoch 31231 - Train Loss: 0.068834, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.783505\n",
      "Epoch 31232 - Train Loss: 0.068832, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.783505\n",
      "Epoch 31233 - Train Loss: 0.068831, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.783505\n",
      "Epoch 31234 - Train Loss: 0.068830, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.783505\n",
      "Epoch 31235 - Train Loss: 0.068829, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.783505\n",
      "Epoch 31236 - Train Loss: 0.068828, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.783505\n",
      "Epoch 31237 - Train Loss: 0.068827, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.783505\n",
      "Epoch 31238 - Train Loss: 0.068826, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.783505\n",
      "Epoch 31239 - Train Loss: 0.068824, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.783505\n",
      "Epoch 31240 - Train Loss: 0.068823, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.783505\n",
      "Epoch 31241 - Train Loss: 0.068822, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.783505\n",
      "Epoch 31242 - Train Loss: 0.068821, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.783505\n",
      "Epoch 31243 - Train Loss: 0.068820, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.783505\n",
      "Epoch 31244 - Train Loss: 0.068819, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.783505\n",
      "Epoch 31245 - Train Loss: 0.068818, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.783505\n",
      "Epoch 31246 - Train Loss: 0.068816, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.783505\n",
      "Epoch 31247 - Train Loss: 0.068815, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.783505\n",
      "Epoch 31248 - Train Loss: 0.068814, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.783505\n",
      "Epoch 31249 - Train Loss: 0.068813, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.783505\n",
      "Epoch 31250 - Train Loss: 0.068812, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.783505\n",
      "Epoch 31251 - Train Loss: 0.068811, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.783505\n",
      "Epoch 31252 - Train Loss: 0.068809, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.783505\n",
      "Epoch 31253 - Train Loss: 0.068808, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.783505\n",
      "Epoch 31254 - Train Loss: 0.068807, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.783505\n",
      "Epoch 31255 - Train Loss: 0.068806, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.783505\n",
      "Epoch 31256 - Train Loss: 0.068805, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.783505\n",
      "Epoch 31257 - Train Loss: 0.068804, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.783505\n",
      "Epoch 31258 - Train Loss: 0.068803, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.783505\n",
      "Epoch 31259 - Train Loss: 0.068801, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.783505\n",
      "Epoch 31260 - Train Loss: 0.068800, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.783505\n",
      "Epoch 31261 - Train Loss: 0.068799, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.783505\n",
      "Epoch 31262 - Train Loss: 0.068798, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.783505\n",
      "Epoch 31263 - Train Loss: 0.068797, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.783505\n",
      "Epoch 31264 - Train Loss: 0.068796, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.783505\n",
      "Epoch 31265 - Train Loss: 0.068795, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.783505\n",
      "Epoch 31266 - Train Loss: 0.068793, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.783505\n",
      "Epoch 31267 - Train Loss: 0.068792, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.783505\n",
      "Epoch 31268 - Train Loss: 0.068791, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.783505\n",
      "Epoch 31269 - Train Loss: 0.068790, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.783505\n",
      "Epoch 31270 - Train Loss: 0.068789, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.783505\n",
      "Epoch 31271 - Train Loss: 0.068788, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.783505\n",
      "Epoch 31272 - Train Loss: 0.068786, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.783505\n",
      "Epoch 31273 - Train Loss: 0.068785, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.783505\n",
      "Epoch 31274 - Train Loss: 0.068784, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.783505\n",
      "Epoch 31275 - Train Loss: 0.068783, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.783505\n",
      "Epoch 31276 - Train Loss: 0.068782, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.783505\n",
      "Epoch 31277 - Train Loss: 0.068781, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.783505\n",
      "Epoch 31278 - Train Loss: 0.068780, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.783505\n",
      "Epoch 31279 - Train Loss: 0.068778, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.783505\n",
      "Epoch 31280 - Train Loss: 0.068777, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.783505\n",
      "Epoch 31281 - Train Loss: 0.068776, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.783505\n",
      "Epoch 31282 - Train Loss: 0.068775, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.783505\n",
      "Epoch 31283 - Train Loss: 0.068774, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.783505\n",
      "Epoch 31284 - Train Loss: 0.068773, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.783505\n",
      "Epoch 31285 - Train Loss: 0.068772, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.783505\n",
      "Epoch 31286 - Train Loss: 0.068770, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.783505\n",
      "Epoch 31287 - Train Loss: 0.068769, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.783505\n",
      "Epoch 31288 - Train Loss: 0.068768, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.783505\n",
      "Epoch 31289 - Train Loss: 0.068767, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.783505\n",
      "Epoch 31290 - Train Loss: 0.068766, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.783505\n",
      "Epoch 31291 - Train Loss: 0.068765, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.783505\n",
      "Epoch 31292 - Train Loss: 0.068764, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.783505\n",
      "Epoch 31293 - Train Loss: 0.068762, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.783505\n",
      "Epoch 31294 - Train Loss: 0.068761, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.783505\n",
      "Epoch 31295 - Train Loss: 0.068760, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.783505\n",
      "Epoch 31296 - Train Loss: 0.068759, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.783505\n",
      "Epoch 31297 - Train Loss: 0.068758, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.783505\n",
      "Epoch 31298 - Train Loss: 0.068757, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.783505\n",
      "Epoch 31299 - Train Loss: 0.068755, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.783505\n",
      "Epoch 31300 - Train Loss: 0.068754, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.783505\n",
      "Epoch 31301 - Train Loss: 0.068753, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.783505\n",
      "Epoch 31302 - Train Loss: 0.068752, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.783505\n",
      "Epoch 31303 - Train Loss: 0.068751, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.783505\n",
      "Epoch 31304 - Train Loss: 0.068750, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.783505\n",
      "Epoch 31305 - Train Loss: 0.068749, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.783505\n",
      "Epoch 31306 - Train Loss: 0.068747, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.783505\n",
      "Epoch 31307 - Train Loss: 0.068746, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.783505\n",
      "Epoch 31308 - Train Loss: 0.068745, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.783505\n",
      "Epoch 31309 - Train Loss: 0.068744, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.783505\n",
      "Epoch 31310 - Train Loss: 0.068743, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.783505\n",
      "Epoch 31311 - Train Loss: 0.068742, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.783505\n",
      "Epoch 31312 - Train Loss: 0.068741, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.783505\n",
      "Epoch 31313 - Train Loss: 0.068739, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.783505\n",
      "Epoch 31314 - Train Loss: 0.068738, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.783505\n",
      "Epoch 31315 - Train Loss: 0.068737, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.783505\n",
      "Epoch 31316 - Train Loss: 0.068736, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.783505\n",
      "Epoch 31317 - Train Loss: 0.068735, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.783505\n",
      "Epoch 31318 - Train Loss: 0.068734, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.783505\n",
      "Epoch 31319 - Train Loss: 0.068733, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.783505\n",
      "Epoch 31320 - Train Loss: 0.068731, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.783505\n",
      "Epoch 31321 - Train Loss: 0.068730, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.783505\n",
      "Epoch 31322 - Train Loss: 0.068729, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.783505\n",
      "Epoch 31323 - Train Loss: 0.068728, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.783505\n",
      "Epoch 31324 - Train Loss: 0.068727, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.783505\n",
      "Epoch 31325 - Train Loss: 0.068726, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.783505\n",
      "Epoch 31326 - Train Loss: 0.068725, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.783505\n",
      "Epoch 31327 - Train Loss: 0.068723, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.783505\n",
      "Epoch 31328 - Train Loss: 0.068722, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.783505\n",
      "Epoch 31329 - Train Loss: 0.068721, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.783505\n",
      "Epoch 31330 - Train Loss: 0.068720, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.783505\n",
      "Epoch 31331 - Train Loss: 0.068719, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.783505\n",
      "Epoch 31332 - Train Loss: 0.068718, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.783505\n",
      "Epoch 31333 - Train Loss: 0.068717, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.783505\n",
      "Epoch 31334 - Train Loss: 0.068715, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.783505\n",
      "Epoch 31335 - Train Loss: 0.068714, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.783505\n",
      "Epoch 31336 - Train Loss: 0.068713, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.783505\n",
      "Epoch 31337 - Train Loss: 0.068712, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.783505\n",
      "Epoch 31338 - Train Loss: 0.068711, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.783505\n",
      "Epoch 31339 - Train Loss: 0.068710, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.783505\n",
      "Epoch 31340 - Train Loss: 0.068709, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.783505\n",
      "Epoch 31341 - Train Loss: 0.068707, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.783505\n",
      "Epoch 31342 - Train Loss: 0.068706, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.783505\n",
      "Epoch 31343 - Train Loss: 0.068705, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.783505\n",
      "Epoch 31344 - Train Loss: 0.068704, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.783505\n",
      "Epoch 31345 - Train Loss: 0.068703, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.783505\n",
      "Epoch 31346 - Train Loss: 0.068702, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.783505\n",
      "Epoch 31347 - Train Loss: 0.068700, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.783505\n",
      "Epoch 31348 - Train Loss: 0.068699, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.783505\n",
      "Epoch 31349 - Train Loss: 0.068698, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.783505\n",
      "Epoch 31350 - Train Loss: 0.068697, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.783505\n",
      "Epoch 31351 - Train Loss: 0.068696, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.783505\n",
      "Epoch 31352 - Train Loss: 0.068695, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.783505\n",
      "Epoch 31353 - Train Loss: 0.068694, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.783505\n",
      "Epoch 31354 - Train Loss: 0.068692, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.783505\n",
      "Epoch 31355 - Train Loss: 0.068691, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.783505\n",
      "Epoch 31356 - Train Loss: 0.068690, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.783505\n",
      "Epoch 31357 - Train Loss: 0.068689, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.783505\n",
      "Epoch 31358 - Train Loss: 0.068688, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.783505\n",
      "Epoch 31359 - Train Loss: 0.068687, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.783505\n",
      "Epoch 31360 - Train Loss: 0.068686, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.783505\n",
      "Epoch 31361 - Train Loss: 0.068684, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.783505\n",
      "Epoch 31362 - Train Loss: 0.068683, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.783505\n",
      "Epoch 31363 - Train Loss: 0.068682, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.783505\n",
      "Epoch 31364 - Train Loss: 0.068681, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.783505\n",
      "Epoch 31365 - Train Loss: 0.068680, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.783505\n",
      "Epoch 31366 - Train Loss: 0.068679, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.783505\n",
      "Epoch 31367 - Train Loss: 0.068678, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.783505\n",
      "Epoch 31368 - Train Loss: 0.068676, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.783505\n",
      "Epoch 31369 - Train Loss: 0.068675, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.783505\n",
      "Epoch 31370 - Train Loss: 0.068674, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.783505\n",
      "Epoch 31371 - Train Loss: 0.068673, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.783505\n",
      "Epoch 31372 - Train Loss: 0.068672, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.783505\n",
      "Epoch 31373 - Train Loss: 0.068671, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.783505\n",
      "Epoch 31374 - Train Loss: 0.068670, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.783505\n",
      "Epoch 31375 - Train Loss: 0.068668, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.783505\n",
      "Epoch 31376 - Train Loss: 0.068667, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.783505\n",
      "Epoch 31377 - Train Loss: 0.068666, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.783505\n",
      "Epoch 31378 - Train Loss: 0.068665, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.783505\n",
      "Epoch 31379 - Train Loss: 0.068664, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.783505\n",
      "Epoch 31380 - Train Loss: 0.068663, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.783505\n",
      "Epoch 31381 - Train Loss: 0.068662, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.783505\n",
      "Epoch 31382 - Train Loss: 0.068660, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.783505\n",
      "Epoch 31383 - Train Loss: 0.068659, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.783505\n",
      "Epoch 31384 - Train Loss: 0.068658, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.783505\n",
      "Epoch 31385 - Train Loss: 0.068657, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.783505\n",
      "Epoch 31386 - Train Loss: 0.068656, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.783505\n",
      "Epoch 31387 - Train Loss: 0.068655, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.783505\n",
      "Epoch 31388 - Train Loss: 0.068654, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.783505\n",
      "Epoch 31389 - Train Loss: 0.068652, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.783505\n",
      "Epoch 31390 - Train Loss: 0.068651, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.783505\n",
      "Epoch 31391 - Train Loss: 0.068650, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.783505\n",
      "Epoch 31392 - Train Loss: 0.068649, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.783505\n",
      "Epoch 31393 - Train Loss: 0.068648, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.783505\n",
      "Epoch 31394 - Train Loss: 0.068647, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.783505\n",
      "Epoch 31395 - Train Loss: 0.068646, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.783505\n",
      "Epoch 31396 - Train Loss: 0.068644, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.783505\n",
      "Epoch 31397 - Train Loss: 0.068643, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.783505\n",
      "Epoch 31398 - Train Loss: 0.068642, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.783505\n",
      "Epoch 31399 - Train Loss: 0.068641, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.783505\n",
      "Epoch 31400 - Train Loss: 0.068640, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.783505\n",
      "Epoch 31401 - Train Loss: 0.068639, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.783505\n",
      "Epoch 31402 - Train Loss: 0.068638, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.783505\n",
      "Epoch 31403 - Train Loss: 0.068636, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.783505\n",
      "Epoch 31404 - Train Loss: 0.068635, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.783505\n",
      "Epoch 31405 - Train Loss: 0.068634, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.783505\n",
      "Epoch 31406 - Train Loss: 0.068633, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.783505\n",
      "Epoch 31407 - Train Loss: 0.068632, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.783505\n",
      "Epoch 31408 - Train Loss: 0.068631, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.783505\n",
      "Epoch 31409 - Train Loss: 0.068630, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.783505\n",
      "Epoch 31410 - Train Loss: 0.068628, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.783505\n",
      "Epoch 31411 - Train Loss: 0.068627, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.783505\n",
      "Epoch 31412 - Train Loss: 0.068626, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.783505\n",
      "Epoch 31413 - Train Loss: 0.068625, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.783505\n",
      "Epoch 31414 - Train Loss: 0.068624, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.783505\n",
      "Epoch 31415 - Train Loss: 0.068623, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.783505\n",
      "Epoch 31416 - Train Loss: 0.068622, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.783505\n",
      "Epoch 31417 - Train Loss: 0.068621, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.783505\n",
      "Epoch 31418 - Train Loss: 0.068619, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.783505\n",
      "Epoch 31419 - Train Loss: 0.068618, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.783505\n",
      "Epoch 31420 - Train Loss: 0.068617, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.783505\n",
      "Epoch 31421 - Train Loss: 0.068616, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.783505\n",
      "Epoch 31422 - Train Loss: 0.068615, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.783505\n",
      "Epoch 31423 - Train Loss: 0.068614, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.783505\n",
      "Epoch 31424 - Train Loss: 0.068613, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.783505\n",
      "Epoch 31425 - Train Loss: 0.068611, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.783505\n",
      "Epoch 31426 - Train Loss: 0.068610, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.783505\n",
      "Epoch 31427 - Train Loss: 0.068609, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.783505\n",
      "Epoch 31428 - Train Loss: 0.068608, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.783505\n",
      "Epoch 31429 - Train Loss: 0.068607, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.783505\n",
      "Epoch 31430 - Train Loss: 0.068606, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.783505\n",
      "Epoch 31431 - Train Loss: 0.068605, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.783505\n",
      "Epoch 31432 - Train Loss: 0.068603, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.783505\n",
      "Epoch 31433 - Train Loss: 0.068602, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.783505\n",
      "Epoch 31434 - Train Loss: 0.068601, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.783505\n",
      "Epoch 31435 - Train Loss: 0.068600, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.783505\n",
      "Epoch 31436 - Train Loss: 0.068599, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.783505\n",
      "Epoch 31437 - Train Loss: 0.068598, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.783505\n",
      "Epoch 31438 - Train Loss: 0.068597, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.783505\n",
      "Epoch 31439 - Train Loss: 0.068595, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.783505\n",
      "Epoch 31440 - Train Loss: 0.068594, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.783505\n",
      "Epoch 31441 - Train Loss: 0.068593, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.783505\n",
      "Epoch 31442 - Train Loss: 0.068592, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.783505\n",
      "Epoch 31443 - Train Loss: 0.068591, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.783505\n",
      "Epoch 31444 - Train Loss: 0.068590, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.783505\n",
      "Epoch 31445 - Train Loss: 0.068589, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.783505\n",
      "Epoch 31446 - Train Loss: 0.068587, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.783505\n",
      "Epoch 31447 - Train Loss: 0.068586, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.783505\n",
      "Epoch 31448 - Train Loss: 0.068585, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.783505\n",
      "Epoch 31449 - Train Loss: 0.068584, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.783505\n",
      "Epoch 31450 - Train Loss: 0.068583, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.783505\n",
      "Epoch 31451 - Train Loss: 0.068582, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.783505\n",
      "Epoch 31452 - Train Loss: 0.068581, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.783505\n",
      "Epoch 31453 - Train Loss: 0.068579, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.783505\n",
      "Epoch 31454 - Train Loss: 0.068578, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.783505\n",
      "Epoch 31455 - Train Loss: 0.068577, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.783505\n",
      "Epoch 31456 - Train Loss: 0.068576, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.783505\n",
      "Epoch 31457 - Train Loss: 0.068575, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.783505\n",
      "Epoch 31458 - Train Loss: 0.068574, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.783505\n",
      "Epoch 31459 - Train Loss: 0.068573, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.783505\n",
      "Epoch 31460 - Train Loss: 0.068571, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.783505\n",
      "Epoch 31461 - Train Loss: 0.068570, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.783505\n",
      "Epoch 31462 - Train Loss: 0.068569, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.783505\n",
      "Epoch 31463 - Train Loss: 0.068568, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.783505\n",
      "Epoch 31464 - Train Loss: 0.068567, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.783505\n",
      "Epoch 31465 - Train Loss: 0.068566, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.783505\n",
      "Epoch 31466 - Train Loss: 0.068565, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.783505\n",
      "Epoch 31467 - Train Loss: 0.068564, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.783505\n",
      "Epoch 31468 - Train Loss: 0.068562, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.783505\n",
      "Epoch 31469 - Train Loss: 0.068561, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.783505\n",
      "Epoch 31470 - Train Loss: 0.068560, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.783505\n",
      "Epoch 31471 - Train Loss: 0.068559, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.783505\n",
      "Epoch 31472 - Train Loss: 0.068558, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.783505\n",
      "Epoch 31473 - Train Loss: 0.068557, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.783505\n",
      "Epoch 31474 - Train Loss: 0.068556, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.783505\n",
      "Epoch 31475 - Train Loss: 0.068554, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.783505\n",
      "Epoch 31476 - Train Loss: 0.068553, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.783505\n",
      "Epoch 31477 - Train Loss: 0.068552, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.783505\n",
      "Epoch 31478 - Train Loss: 0.068551, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.783505\n",
      "Epoch 31479 - Train Loss: 0.068550, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.783505\n",
      "Epoch 31480 - Train Loss: 0.068549, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.783505\n",
      "Epoch 31481 - Train Loss: 0.068548, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.783505\n",
      "Epoch 31482 - Train Loss: 0.068546, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.783505\n",
      "Epoch 31483 - Train Loss: 0.068545, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.783505\n",
      "Epoch 31484 - Train Loss: 0.068544, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.783505\n",
      "Epoch 31485 - Train Loss: 0.068543, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.783505\n",
      "Epoch 31486 - Train Loss: 0.068542, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.783505\n",
      "Epoch 31487 - Train Loss: 0.068541, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.783505\n",
      "Epoch 31488 - Train Loss: 0.068540, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.783505\n",
      "Epoch 31489 - Train Loss: 0.068538, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.783505\n",
      "Epoch 31490 - Train Loss: 0.068537, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.783505\n",
      "Epoch 31491 - Train Loss: 0.068536, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.783505\n",
      "Epoch 31492 - Train Loss: 0.068535, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.783505\n",
      "Epoch 31493 - Train Loss: 0.068534, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.783505\n",
      "Epoch 31494 - Train Loss: 0.068533, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.783505\n",
      "Epoch 31495 - Train Loss: 0.068532, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.783505\n",
      "Epoch 31496 - Train Loss: 0.068531, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.783505\n",
      "Epoch 31497 - Train Loss: 0.068529, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.783505\n",
      "Epoch 31498 - Train Loss: 0.068528, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.783505\n",
      "Epoch 31499 - Train Loss: 0.068527, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.783505\n",
      "Epoch 31500 - Train Loss: 0.068526, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.783505\n",
      "Epoch 31501 - Train Loss: 0.068525, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.783505\n",
      "Epoch 31502 - Train Loss: 0.068524, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.783505\n",
      "Epoch 31503 - Train Loss: 0.068523, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.783505\n",
      "Epoch 31504 - Train Loss: 0.068521, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.783505\n",
      "Epoch 31505 - Train Loss: 0.068520, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.783505\n",
      "Epoch 31506 - Train Loss: 0.068519, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.783505\n",
      "Epoch 31507 - Train Loss: 0.068518, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.783505\n",
      "Epoch 31508 - Train Loss: 0.068517, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.783505\n",
      "Epoch 31509 - Train Loss: 0.068516, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.783505\n",
      "Epoch 31510 - Train Loss: 0.068515, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.783505\n",
      "Epoch 31511 - Train Loss: 0.068513, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.783505\n",
      "Epoch 31512 - Train Loss: 0.068512, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.783505\n",
      "Epoch 31513 - Train Loss: 0.068511, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.783505\n",
      "Epoch 31514 - Train Loss: 0.068510, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.783505\n",
      "Epoch 31515 - Train Loss: 0.068509, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.783505\n",
      "Epoch 31516 - Train Loss: 0.068508, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.783505\n",
      "Epoch 31517 - Train Loss: 0.068507, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.783505\n",
      "Epoch 31518 - Train Loss: 0.068506, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.783505\n",
      "Epoch 31519 - Train Loss: 0.068504, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.783505\n",
      "Epoch 31520 - Train Loss: 0.068503, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.783505\n",
      "Epoch 31521 - Train Loss: 0.068502, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.783505\n",
      "Epoch 31522 - Train Loss: 0.068501, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.783505\n",
      "Epoch 31523 - Train Loss: 0.068500, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.783505\n",
      "Epoch 31524 - Train Loss: 0.068499, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.783505\n",
      "Epoch 31525 - Train Loss: 0.068498, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.783505\n",
      "Epoch 31526 - Train Loss: 0.068496, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.783505\n",
      "Epoch 31527 - Train Loss: 0.068495, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.783505\n",
      "Epoch 31528 - Train Loss: 0.068494, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.783505\n",
      "Epoch 31529 - Train Loss: 0.068493, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.783505\n",
      "Epoch 31530 - Train Loss: 0.068492, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.783505\n",
      "Epoch 31531 - Train Loss: 0.068491, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.783505\n",
      "Epoch 31532 - Train Loss: 0.068490, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.783505\n",
      "Epoch 31533 - Train Loss: 0.068488, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.783505\n",
      "Epoch 31534 - Train Loss: 0.068487, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.783505\n",
      "Epoch 31535 - Train Loss: 0.068486, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.783505\n",
      "Epoch 31536 - Train Loss: 0.068485, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.783505\n",
      "Epoch 31537 - Train Loss: 0.068484, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.783505\n",
      "Epoch 31538 - Train Loss: 0.068483, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.783505\n",
      "Epoch 31539 - Train Loss: 0.068482, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.783505\n",
      "Epoch 31540 - Train Loss: 0.068481, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.783505\n",
      "Epoch 31541 - Train Loss: 0.068479, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.783505\n",
      "Epoch 31542 - Train Loss: 0.068478, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.783505\n",
      "Epoch 31543 - Train Loss: 0.068477, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.783505\n",
      "Epoch 31544 - Train Loss: 0.068476, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.783505\n",
      "Epoch 31545 - Train Loss: 0.068475, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.783505\n",
      "Epoch 31546 - Train Loss: 0.068474, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.783505\n",
      "Epoch 31547 - Train Loss: 0.068473, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.783505\n",
      "Epoch 31548 - Train Loss: 0.068471, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.783505\n",
      "Epoch 31549 - Train Loss: 0.068470, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.783505\n",
      "Epoch 31550 - Train Loss: 0.068469, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.783505\n",
      "Epoch 31551 - Train Loss: 0.068468, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.783505\n",
      "Epoch 31552 - Train Loss: 0.068467, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.783505\n",
      "Epoch 31553 - Train Loss: 0.068466, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.783505\n",
      "Epoch 31554 - Train Loss: 0.068465, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.783505\n",
      "Epoch 31555 - Train Loss: 0.068464, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.783505\n",
      "Epoch 31556 - Train Loss: 0.068462, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.783505\n",
      "Epoch 31557 - Train Loss: 0.068461, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.783505\n",
      "Epoch 31558 - Train Loss: 0.068460, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.783505\n",
      "Epoch 31559 - Train Loss: 0.068459, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.783505\n",
      "Epoch 31560 - Train Loss: 0.068458, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.783505\n",
      "Epoch 31561 - Train Loss: 0.068457, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.783505\n",
      "Epoch 31562 - Train Loss: 0.068456, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.783505\n",
      "Epoch 31563 - Train Loss: 0.068454, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.783505\n",
      "Epoch 31564 - Train Loss: 0.068453, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.783505\n",
      "Epoch 31565 - Train Loss: 0.068452, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.783505\n",
      "Epoch 31566 - Train Loss: 0.068451, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.783505\n",
      "Epoch 31567 - Train Loss: 0.068450, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.783505\n",
      "Epoch 31568 - Train Loss: 0.068449, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.783505\n",
      "Epoch 31569 - Train Loss: 0.068448, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.783505\n",
      "Epoch 31570 - Train Loss: 0.068447, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.783505\n",
      "Epoch 31571 - Train Loss: 0.068445, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.783505\n",
      "Epoch 31572 - Train Loss: 0.068444, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.783505\n",
      "Epoch 31573 - Train Loss: 0.068443, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.783505\n",
      "Epoch 31574 - Train Loss: 0.068442, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.783505\n",
      "Epoch 31575 - Train Loss: 0.068441, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.783505\n",
      "Epoch 31576 - Train Loss: 0.068440, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.783505\n",
      "Epoch 31577 - Train Loss: 0.068439, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.783505\n",
      "Epoch 31578 - Train Loss: 0.068437, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.783505\n",
      "Epoch 31579 - Train Loss: 0.068436, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.783505\n",
      "Epoch 31580 - Train Loss: 0.068435, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.783505\n",
      "Epoch 31581 - Train Loss: 0.068434, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.783505\n",
      "Epoch 31582 - Train Loss: 0.068433, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.783505\n",
      "Epoch 31583 - Train Loss: 0.068432, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.783505\n",
      "Epoch 31584 - Train Loss: 0.068431, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.783505\n",
      "Epoch 31585 - Train Loss: 0.068430, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.783505\n",
      "Epoch 31586 - Train Loss: 0.068428, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.783505\n",
      "Epoch 31587 - Train Loss: 0.068427, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.783505\n",
      "Epoch 31588 - Train Loss: 0.068426, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.783505\n",
      "Epoch 31589 - Train Loss: 0.068425, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.783505\n",
      "Epoch 31590 - Train Loss: 0.068424, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.783505\n",
      "Epoch 31591 - Train Loss: 0.068423, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.783505\n",
      "Epoch 31592 - Train Loss: 0.068422, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.783505\n",
      "Epoch 31593 - Train Loss: 0.068420, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.783505\n",
      "Epoch 31594 - Train Loss: 0.068419, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.783505\n",
      "Epoch 31595 - Train Loss: 0.068418, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.783505\n",
      "Epoch 31596 - Train Loss: 0.068417, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.783505\n",
      "Epoch 31597 - Train Loss: 0.068416, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.783505\n",
      "Epoch 31598 - Train Loss: 0.068415, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.783505\n",
      "Epoch 31599 - Train Loss: 0.068414, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.783505\n",
      "Epoch 31600 - Train Loss: 0.068413, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.783505\n",
      "Epoch 31601 - Train Loss: 0.068411, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.783505\n",
      "Epoch 31602 - Train Loss: 0.068410, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.783505\n",
      "Epoch 31603 - Train Loss: 0.068409, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.783505\n",
      "Epoch 31604 - Train Loss: 0.068408, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.783505\n",
      "Epoch 31605 - Train Loss: 0.068407, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.783505\n",
      "Epoch 31606 - Train Loss: 0.068406, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.783505\n",
      "Epoch 31607 - Train Loss: 0.068405, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.783505\n",
      "Epoch 31608 - Train Loss: 0.068404, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.783505\n",
      "Epoch 31609 - Train Loss: 0.068402, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.783505\n",
      "Epoch 31610 - Train Loss: 0.068401, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.783505\n",
      "Epoch 31611 - Train Loss: 0.068400, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.783505\n",
      "Epoch 31612 - Train Loss: 0.068399, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.783505\n",
      "Epoch 31613 - Train Loss: 0.068398, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.783505\n",
      "Epoch 31614 - Train Loss: 0.068397, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.783505\n",
      "Epoch 31615 - Train Loss: 0.068396, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.783505\n",
      "Epoch 31616 - Train Loss: 0.068394, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.783505\n",
      "Epoch 31617 - Train Loss: 0.068393, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.783505\n",
      "Epoch 31618 - Train Loss: 0.068392, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.783505\n",
      "Epoch 31619 - Train Loss: 0.068391, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.783505\n",
      "Epoch 31620 - Train Loss: 0.068390, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.783505\n",
      "Epoch 31621 - Train Loss: 0.068389, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.783505\n",
      "Epoch 31622 - Train Loss: 0.068388, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.783505\n",
      "Epoch 31623 - Train Loss: 0.068387, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.783505\n",
      "Epoch 31624 - Train Loss: 0.068385, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.783505\n",
      "Epoch 31625 - Train Loss: 0.068384, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.783505\n",
      "Epoch 31626 - Train Loss: 0.068383, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.783505\n",
      "Epoch 31627 - Train Loss: 0.068382, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.783505\n",
      "Epoch 31628 - Train Loss: 0.068381, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.783505\n",
      "Epoch 31629 - Train Loss: 0.068380, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.783505\n",
      "Epoch 31630 - Train Loss: 0.068379, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.783505\n",
      "Epoch 31631 - Train Loss: 0.068378, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.783505\n",
      "Epoch 31632 - Train Loss: 0.068376, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.783505\n",
      "Epoch 31633 - Train Loss: 0.068375, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.783505\n",
      "Epoch 31634 - Train Loss: 0.068374, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.783505\n",
      "Epoch 31635 - Train Loss: 0.068373, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.783505\n",
      "Epoch 31636 - Train Loss: 0.068372, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.783505\n",
      "Epoch 31637 - Train Loss: 0.068371, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.783505\n",
      "Epoch 31638 - Train Loss: 0.068370, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.783505\n",
      "Epoch 31639 - Train Loss: 0.068368, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.783505\n",
      "Epoch 31640 - Train Loss: 0.068367, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.783505\n",
      "Epoch 31641 - Train Loss: 0.068366, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.783505\n",
      "Epoch 31642 - Train Loss: 0.068365, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.783505\n",
      "Epoch 31643 - Train Loss: 0.068364, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.783505\n",
      "Epoch 31644 - Train Loss: 0.068363, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.783505\n",
      "Epoch 31645 - Train Loss: 0.068362, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.783505\n",
      "Epoch 31646 - Train Loss: 0.068361, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.783505\n",
      "Epoch 31647 - Train Loss: 0.068359, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.783505\n",
      "Epoch 31648 - Train Loss: 0.068358, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.783505\n",
      "Epoch 31649 - Train Loss: 0.068357, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.783505\n",
      "Epoch 31650 - Train Loss: 0.068356, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.783505\n",
      "Epoch 31651 - Train Loss: 0.068355, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.783505\n",
      "Epoch 31652 - Train Loss: 0.068354, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.783505\n",
      "Epoch 31653 - Train Loss: 0.068353, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.783505\n",
      "Epoch 31654 - Train Loss: 0.068352, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.783505\n",
      "Epoch 31655 - Train Loss: 0.068350, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.783505\n",
      "Epoch 31656 - Train Loss: 0.068349, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.783505\n",
      "Epoch 31657 - Train Loss: 0.068348, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.783505\n",
      "Epoch 31658 - Train Loss: 0.068347, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.783505\n",
      "Epoch 31659 - Train Loss: 0.068346, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.783505\n",
      "Epoch 31660 - Train Loss: 0.068345, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.783505\n",
      "Epoch 31661 - Train Loss: 0.068344, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.783505\n",
      "Epoch 31662 - Train Loss: 0.068342, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.783505\n",
      "Epoch 31663 - Train Loss: 0.068341, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.783505\n",
      "Epoch 31664 - Train Loss: 0.068340, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.783505\n",
      "Epoch 31665 - Train Loss: 0.068339, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.783505\n",
      "Epoch 31666 - Train Loss: 0.068338, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.783505\n",
      "Epoch 31667 - Train Loss: 0.068337, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.783505\n",
      "Epoch 31668 - Train Loss: 0.068336, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.783505\n",
      "Epoch 31669 - Train Loss: 0.068335, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.783505\n",
      "Epoch 31670 - Train Loss: 0.068333, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.783505\n",
      "Epoch 31671 - Train Loss: 0.068332, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.783505\n",
      "Epoch 31672 - Train Loss: 0.068331, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.783505\n",
      "Epoch 31673 - Train Loss: 0.068330, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.783505\n",
      "Epoch 31674 - Train Loss: 0.068329, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.783505\n",
      "Epoch 31675 - Train Loss: 0.068328, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.783505\n",
      "Epoch 31676 - Train Loss: 0.068327, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.783505\n",
      "Epoch 31677 - Train Loss: 0.068326, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.783505\n",
      "Epoch 31678 - Train Loss: 0.068324, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.783505\n",
      "Epoch 31679 - Train Loss: 0.068323, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.783505\n",
      "Epoch 31680 - Train Loss: 0.068322, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.783505\n",
      "Epoch 31681 - Train Loss: 0.068321, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.783505\n",
      "Epoch 31682 - Train Loss: 0.068320, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.783505\n",
      "Epoch 31683 - Train Loss: 0.068319, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.783505\n",
      "Epoch 31684 - Train Loss: 0.068318, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.783505\n",
      "Epoch 31685 - Train Loss: 0.068317, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.783505\n",
      "Epoch 31686 - Train Loss: 0.068315, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.783505\n",
      "Epoch 31687 - Train Loss: 0.068314, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.783505\n",
      "Epoch 31688 - Train Loss: 0.068313, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.783505\n",
      "Epoch 31689 - Train Loss: 0.068312, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.783505\n",
      "Epoch 31690 - Train Loss: 0.068311, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.783505\n",
      "Epoch 31691 - Train Loss: 0.068310, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.783505\n",
      "Epoch 31692 - Train Loss: 0.068309, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.783505\n",
      "Epoch 31693 - Train Loss: 0.068308, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.783505\n",
      "Epoch 31694 - Train Loss: 0.068306, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.783505\n",
      "Epoch 31695 - Train Loss: 0.068305, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.783505\n",
      "Epoch 31696 - Train Loss: 0.068304, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.783505\n",
      "Epoch 31697 - Train Loss: 0.068303, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.783505\n",
      "Epoch 31698 - Train Loss: 0.068302, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.783505\n",
      "Epoch 31699 - Train Loss: 0.068301, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.783505\n",
      "Epoch 31700 - Train Loss: 0.068300, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.783505\n",
      "Epoch 31701 - Train Loss: 0.068299, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.783505\n",
      "Epoch 31702 - Train Loss: 0.068297, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.783505\n",
      "Epoch 31703 - Train Loss: 0.068296, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.783505\n",
      "Epoch 31704 - Train Loss: 0.068295, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.783505\n",
      "Epoch 31705 - Train Loss: 0.068294, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.783505\n",
      "Epoch 31706 - Train Loss: 0.068293, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.783505\n",
      "Epoch 31707 - Train Loss: 0.068292, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.783505\n",
      "Epoch 31708 - Train Loss: 0.068291, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.783505\n",
      "Epoch 31709 - Train Loss: 0.068290, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.783505\n",
      "Epoch 31710 - Train Loss: 0.068288, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.783505\n",
      "Epoch 31711 - Train Loss: 0.068287, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.783505\n",
      "Epoch 31712 - Train Loss: 0.068286, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.783505\n",
      "Epoch 31713 - Train Loss: 0.068285, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.783505\n",
      "Epoch 31714 - Train Loss: 0.068284, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.783505\n",
      "Epoch 31715 - Train Loss: 0.068283, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.783505\n",
      "Epoch 31716 - Train Loss: 0.068282, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.783505\n",
      "Epoch 31717 - Train Loss: 0.068280, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.783505\n",
      "Epoch 31718 - Train Loss: 0.068279, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.783505\n",
      "Epoch 31719 - Train Loss: 0.068278, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.783505\n",
      "Epoch 31720 - Train Loss: 0.068277, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.783505\n",
      "Epoch 31721 - Train Loss: 0.068276, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.783505\n",
      "Epoch 31722 - Train Loss: 0.068275, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.783505\n",
      "Epoch 31723 - Train Loss: 0.068274, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.783505\n",
      "Epoch 31724 - Train Loss: 0.068273, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.783505\n",
      "Epoch 31725 - Train Loss: 0.068271, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.783505\n",
      "Epoch 31726 - Train Loss: 0.068270, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.783505\n",
      "Epoch 31727 - Train Loss: 0.068269, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.783505\n",
      "Epoch 31728 - Train Loss: 0.068268, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.783505\n",
      "Epoch 31729 - Train Loss: 0.068267, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.783505\n",
      "Epoch 31730 - Train Loss: 0.068266, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.783505\n",
      "Epoch 31731 - Train Loss: 0.068265, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.783505\n",
      "Epoch 31732 - Train Loss: 0.068264, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.783505\n",
      "Epoch 31733 - Train Loss: 0.068262, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.783505\n",
      "Epoch 31734 - Train Loss: 0.068261, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.783505\n",
      "Epoch 31735 - Train Loss: 0.068260, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.783505\n",
      "Epoch 31736 - Train Loss: 0.068259, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.783505\n",
      "Epoch 31737 - Train Loss: 0.068258, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.783505\n",
      "Epoch 31738 - Train Loss: 0.068257, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.783505\n",
      "Epoch 31739 - Train Loss: 0.068256, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.783505\n",
      "Epoch 31740 - Train Loss: 0.068255, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.783505\n",
      "Epoch 31741 - Train Loss: 0.068253, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.783505\n",
      "Epoch 31742 - Train Loss: 0.068252, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.783505\n",
      "Epoch 31743 - Train Loss: 0.068251, Train Acc: 0.887179 | Val Loss: 0.108901, Val Acc: 0.783505\n",
      "Epoch 31744 - Train Loss: 0.068250, Train Acc: 0.887179 | Val Loss: 0.108901, Val Acc: 0.783505\n",
      "Epoch 31745 - Train Loss: 0.068249, Train Acc: 0.887179 | Val Loss: 0.108901, Val Acc: 0.783505\n",
      "Epoch 31746 - Train Loss: 0.068248, Train Acc: 0.887179 | Val Loss: 0.108901, Val Acc: 0.783505\n",
      "Epoch 31747 - Train Loss: 0.068247, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.783505\n",
      "Epoch 31748 - Train Loss: 0.068246, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.783505\n",
      "Epoch 31749 - Train Loss: 0.068244, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.783505\n",
      "Epoch 31750 - Train Loss: 0.068243, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.783505\n",
      "Epoch 31751 - Train Loss: 0.068242, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.783505\n",
      "Epoch 31752 - Train Loss: 0.068241, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.783505\n",
      "Epoch 31753 - Train Loss: 0.068240, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.783505\n",
      "Epoch 31754 - Train Loss: 0.068239, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.783505\n",
      "Epoch 31755 - Train Loss: 0.068238, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.783505\n",
      "Epoch 31756 - Train Loss: 0.068237, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.783505\n",
      "Epoch 31757 - Train Loss: 0.068236, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.783505\n",
      "Epoch 31758 - Train Loss: 0.068234, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.783505\n",
      "Epoch 31759 - Train Loss: 0.068233, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.783505\n",
      "Epoch 31760 - Train Loss: 0.068232, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.783505\n",
      "Epoch 31761 - Train Loss: 0.068231, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.783505\n",
      "Epoch 31762 - Train Loss: 0.068230, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.783505\n",
      "Epoch 31763 - Train Loss: 0.068229, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.783505\n",
      "Epoch 31764 - Train Loss: 0.068228, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.783505\n",
      "Epoch 31765 - Train Loss: 0.068227, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.783505\n",
      "Epoch 31766 - Train Loss: 0.068225, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.783505\n",
      "Epoch 31767 - Train Loss: 0.068224, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.783505\n",
      "Epoch 31768 - Train Loss: 0.068223, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.783505\n",
      "Epoch 31769 - Train Loss: 0.068222, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.783505\n",
      "Epoch 31770 - Train Loss: 0.068221, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.783505\n",
      "Epoch 31771 - Train Loss: 0.068220, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.783505\n",
      "Epoch 31772 - Train Loss: 0.068219, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.783505\n",
      "Epoch 31773 - Train Loss: 0.068218, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 31774 - Train Loss: 0.068216, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 31775 - Train Loss: 0.068215, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 31776 - Train Loss: 0.068214, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 31777 - Train Loss: 0.068213, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 31778 - Train Loss: 0.068212, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 31779 - Train Loss: 0.068211, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.783505\n",
      "Epoch 31780 - Train Loss: 0.068210, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.783505\n",
      "Epoch 31781 - Train Loss: 0.068209, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.783505\n",
      "Epoch 31782 - Train Loss: 0.068207, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.783505\n",
      "Epoch 31783 - Train Loss: 0.068206, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.783505\n",
      "Epoch 31784 - Train Loss: 0.068205, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 31785 - Train Loss: 0.068204, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 31786 - Train Loss: 0.068203, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 31787 - Train Loss: 0.068202, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 31788 - Train Loss: 0.068201, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 31789 - Train Loss: 0.068200, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 31790 - Train Loss: 0.068198, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 31791 - Train Loss: 0.068197, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 31792 - Train Loss: 0.068196, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 31793 - Train Loss: 0.068195, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 31794 - Train Loss: 0.068194, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 31795 - Train Loss: 0.068193, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 31796 - Train Loss: 0.068192, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.783505\n",
      "Epoch 31797 - Train Loss: 0.068191, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.783505\n",
      "Epoch 31798 - Train Loss: 0.068189, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.783505\n",
      "Epoch 31799 - Train Loss: 0.068188, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.783505\n",
      "Epoch 31800 - Train Loss: 0.068187, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.783505\n",
      "Epoch 31801 - Train Loss: 0.068186, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 31802 - Train Loss: 0.068185, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 31803 - Train Loss: 0.068184, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 31804 - Train Loss: 0.068183, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 31805 - Train Loss: 0.068182, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 31806 - Train Loss: 0.068181, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 31807 - Train Loss: 0.068179, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 31808 - Train Loss: 0.068178, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 31809 - Train Loss: 0.068177, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 31810 - Train Loss: 0.068176, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 31811 - Train Loss: 0.068175, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 31812 - Train Loss: 0.068174, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 31813 - Train Loss: 0.068173, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 31814 - Train Loss: 0.068172, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 31815 - Train Loss: 0.068170, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 31816 - Train Loss: 0.068169, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 31817 - Train Loss: 0.068168, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 31818 - Train Loss: 0.068167, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 31819 - Train Loss: 0.068166, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.783505\n",
      "Epoch 31820 - Train Loss: 0.068165, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.783505\n",
      "Epoch 31821 - Train Loss: 0.068164, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.783505\n",
      "Epoch 31822 - Train Loss: 0.068163, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.783505\n",
      "Epoch 31823 - Train Loss: 0.068161, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.783505\n",
      "Epoch 31824 - Train Loss: 0.068160, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 31825 - Train Loss: 0.068159, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 31826 - Train Loss: 0.068158, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 31827 - Train Loss: 0.068157, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 31828 - Train Loss: 0.068156, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 31829 - Train Loss: 0.068155, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 31830 - Train Loss: 0.068154, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.783505\n",
      "Epoch 31831 - Train Loss: 0.068153, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.783505\n",
      "Epoch 31832 - Train Loss: 0.068151, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.783505\n",
      "Epoch 31833 - Train Loss: 0.068150, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.783505\n",
      "Epoch 31834 - Train Loss: 0.068149, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.783505\n",
      "Epoch 31835 - Train Loss: 0.068148, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.783505\n",
      "Epoch 31836 - Train Loss: 0.068147, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 31837 - Train Loss: 0.068146, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 31838 - Train Loss: 0.068145, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 31839 - Train Loss: 0.068144, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 31840 - Train Loss: 0.068142, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 31841 - Train Loss: 0.068141, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 31842 - Train Loss: 0.068140, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 31843 - Train Loss: 0.068139, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 31844 - Train Loss: 0.068138, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 31845 - Train Loss: 0.068137, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 31846 - Train Loss: 0.068136, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 31847 - Train Loss: 0.068135, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 31848 - Train Loss: 0.068133, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.783505\n",
      "Epoch 31849 - Train Loss: 0.068132, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.783505\n",
      "Epoch 31850 - Train Loss: 0.068131, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.783505\n",
      "Epoch 31851 - Train Loss: 0.068130, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.783505\n",
      "Epoch 31852 - Train Loss: 0.068129, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.783505\n",
      "Epoch 31853 - Train Loss: 0.068128, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 31854 - Train Loss: 0.068127, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 31855 - Train Loss: 0.068126, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 31856 - Train Loss: 0.068125, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 31857 - Train Loss: 0.068123, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 31858 - Train Loss: 0.068122, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 31859 - Train Loss: 0.068121, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 31860 - Train Loss: 0.068120, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 31861 - Train Loss: 0.068119, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 31862 - Train Loss: 0.068118, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 31863 - Train Loss: 0.068117, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 31864 - Train Loss: 0.068116, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 31865 - Train Loss: 0.068114, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 31866 - Train Loss: 0.068113, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 31867 - Train Loss: 0.068112, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 31868 - Train Loss: 0.068111, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 31869 - Train Loss: 0.068110, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 31870 - Train Loss: 0.068109, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 31871 - Train Loss: 0.068108, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.783505\n",
      "Epoch 31872 - Train Loss: 0.068107, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.783505\n",
      "Epoch 31873 - Train Loss: 0.068106, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.783505\n",
      "Epoch 31874 - Train Loss: 0.068104, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.783505\n",
      "Epoch 31875 - Train Loss: 0.068103, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.783505\n",
      "Epoch 31876 - Train Loss: 0.068102, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.783505\n",
      "Epoch 31877 - Train Loss: 0.068101, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 31878 - Train Loss: 0.068100, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 31879 - Train Loss: 0.068099, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 31880 - Train Loss: 0.068098, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 31881 - Train Loss: 0.068097, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 31882 - Train Loss: 0.068095, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 31883 - Train Loss: 0.068094, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.783505\n",
      "Epoch 31884 - Train Loss: 0.068093, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.783505\n",
      "Epoch 31885 - Train Loss: 0.068092, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.783505\n",
      "Epoch 31886 - Train Loss: 0.068091, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.783505\n",
      "Epoch 31887 - Train Loss: 0.068090, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.783505\n",
      "Epoch 31888 - Train Loss: 0.068089, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 31889 - Train Loss: 0.068088, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 31890 - Train Loss: 0.068087, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 31891 - Train Loss: 0.068085, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 31892 - Train Loss: 0.068084, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 31893 - Train Loss: 0.068083, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 31894 - Train Loss: 0.068082, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 31895 - Train Loss: 0.068081, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 31896 - Train Loss: 0.068080, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 31897 - Train Loss: 0.068079, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 31898 - Train Loss: 0.068078, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 31899 - Train Loss: 0.068076, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 31900 - Train Loss: 0.068075, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 31901 - Train Loss: 0.068074, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 31902 - Train Loss: 0.068073, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 31903 - Train Loss: 0.068072, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 31904 - Train Loss: 0.068071, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 31905 - Train Loss: 0.068070, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 31906 - Train Loss: 0.068069, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.783505\n",
      "Epoch 31907 - Train Loss: 0.068068, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.783505\n",
      "Epoch 31908 - Train Loss: 0.068066, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.783505\n",
      "Epoch 31909 - Train Loss: 0.068065, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.783505\n",
      "Epoch 31910 - Train Loss: 0.068064, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.783505\n",
      "Epoch 31911 - Train Loss: 0.068063, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.783505\n",
      "Epoch 31912 - Train Loss: 0.068062, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 31913 - Train Loss: 0.068061, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 31914 - Train Loss: 0.068060, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 31915 - Train Loss: 0.068059, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 31916 - Train Loss: 0.068057, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 31917 - Train Loss: 0.068056, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 31918 - Train Loss: 0.068055, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 31919 - Train Loss: 0.068054, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 31920 - Train Loss: 0.068053, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 31921 - Train Loss: 0.068052, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 31922 - Train Loss: 0.068051, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 31923 - Train Loss: 0.068050, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 31924 - Train Loss: 0.068049, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 31925 - Train Loss: 0.068047, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 31926 - Train Loss: 0.068046, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 31927 - Train Loss: 0.068045, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 31928 - Train Loss: 0.068044, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 31929 - Train Loss: 0.068043, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 31930 - Train Loss: 0.068042, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.783505\n",
      "Epoch 31931 - Train Loss: 0.068041, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.783505\n",
      "Epoch 31932 - Train Loss: 0.068040, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.783505\n",
      "Epoch 31933 - Train Loss: 0.068039, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.783505\n",
      "Epoch 31934 - Train Loss: 0.068037, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.783505\n",
      "Epoch 31935 - Train Loss: 0.068036, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 31936 - Train Loss: 0.068035, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 31937 - Train Loss: 0.068034, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 31938 - Train Loss: 0.068033, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 31939 - Train Loss: 0.068032, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 31940 - Train Loss: 0.068031, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 31941 - Train Loss: 0.068030, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 31942 - Train Loss: 0.068028, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 31943 - Train Loss: 0.068027, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 31944 - Train Loss: 0.068026, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 31945 - Train Loss: 0.068025, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 31946 - Train Loss: 0.068024, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 31947 - Train Loss: 0.068023, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.783505\n",
      "Epoch 31948 - Train Loss: 0.068022, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.783505\n",
      "Epoch 31949 - Train Loss: 0.068021, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.783505\n",
      "Epoch 31950 - Train Loss: 0.068020, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.783505\n",
      "Epoch 31951 - Train Loss: 0.068018, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.783505\n",
      "Epoch 31952 - Train Loss: 0.068017, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.783505\n",
      "Epoch 31953 - Train Loss: 0.068016, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 31954 - Train Loss: 0.068015, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 31955 - Train Loss: 0.068014, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 31956 - Train Loss: 0.068013, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 31957 - Train Loss: 0.068012, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 31958 - Train Loss: 0.068011, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 31959 - Train Loss: 0.068010, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 31960 - Train Loss: 0.068008, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 31961 - Train Loss: 0.068007, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 31962 - Train Loss: 0.068006, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 31963 - Train Loss: 0.068005, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 31964 - Train Loss: 0.068004, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 31965 - Train Loss: 0.068003, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 31966 - Train Loss: 0.068002, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 31967 - Train Loss: 0.068001, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 31968 - Train Loss: 0.068000, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 31969 - Train Loss: 0.067998, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 31970 - Train Loss: 0.067997, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 31971 - Train Loss: 0.067996, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 31972 - Train Loss: 0.067995, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 31973 - Train Loss: 0.067994, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 31974 - Train Loss: 0.067993, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 31975 - Train Loss: 0.067992, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 31976 - Train Loss: 0.067991, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 31977 - Train Loss: 0.067990, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 31978 - Train Loss: 0.067988, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 31979 - Train Loss: 0.067987, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 31980 - Train Loss: 0.067986, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 31981 - Train Loss: 0.067985, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 31982 - Train Loss: 0.067984, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 31983 - Train Loss: 0.067983, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.783505\n",
      "Epoch 31984 - Train Loss: 0.067982, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.783505\n",
      "Epoch 31985 - Train Loss: 0.067981, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.783505\n",
      "Epoch 31986 - Train Loss: 0.067980, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.783505\n",
      "Epoch 31987 - Train Loss: 0.067978, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.783505\n",
      "Epoch 31988 - Train Loss: 0.067977, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.783505\n",
      "Epoch 31989 - Train Loss: 0.067976, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 31990 - Train Loss: 0.067975, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 31991 - Train Loss: 0.067974, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 31992 - Train Loss: 0.067973, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 31993 - Train Loss: 0.067972, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 31994 - Train Loss: 0.067971, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 31995 - Train Loss: 0.067970, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 31996 - Train Loss: 0.067968, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 31997 - Train Loss: 0.067967, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 31998 - Train Loss: 0.067966, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 31999 - Train Loss: 0.067965, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 32000 - Train Loss: 0.067964, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 32001 - Train Loss: 0.067963, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 32002 - Train Loss: 0.067962, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 32003 - Train Loss: 0.067961, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 32004 - Train Loss: 0.067959, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 32005 - Train Loss: 0.067958, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 32006 - Train Loss: 0.067957, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 32007 - Train Loss: 0.067956, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 32008 - Train Loss: 0.067955, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 32009 - Train Loss: 0.067954, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 32010 - Train Loss: 0.067953, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 32011 - Train Loss: 0.067952, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 32012 - Train Loss: 0.067951, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 32013 - Train Loss: 0.067949, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 32014 - Train Loss: 0.067948, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 32015 - Train Loss: 0.067947, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 32016 - Train Loss: 0.067946, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 32017 - Train Loss: 0.067945, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 32018 - Train Loss: 0.067944, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 32019 - Train Loss: 0.067943, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 32020 - Train Loss: 0.067942, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 32021 - Train Loss: 0.067941, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 32022 - Train Loss: 0.067940, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 32023 - Train Loss: 0.067938, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 32024 - Train Loss: 0.067937, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 32025 - Train Loss: 0.067936, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 32026 - Train Loss: 0.067935, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 32027 - Train Loss: 0.067934, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 32028 - Train Loss: 0.067933, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 32029 - Train Loss: 0.067932, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 32030 - Train Loss: 0.067931, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 32031 - Train Loss: 0.067930, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.783505\n",
      "Epoch 32032 - Train Loss: 0.067928, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.783505\n",
      "Epoch 32033 - Train Loss: 0.067927, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.783505\n",
      "Epoch 32034 - Train Loss: 0.067926, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.783505\n",
      "Epoch 32035 - Train Loss: 0.067925, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.783505\n",
      "Epoch 32036 - Train Loss: 0.067924, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.783505\n",
      "Epoch 32037 - Train Loss: 0.067923, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 32038 - Train Loss: 0.067922, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 32039 - Train Loss: 0.067921, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 32040 - Train Loss: 0.067920, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 32041 - Train Loss: 0.067918, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 32042 - Train Loss: 0.067917, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 32043 - Train Loss: 0.067916, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 32044 - Train Loss: 0.067915, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 32045 - Train Loss: 0.067914, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 32046 - Train Loss: 0.067913, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 32047 - Train Loss: 0.067912, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 32048 - Train Loss: 0.067911, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 32049 - Train Loss: 0.067910, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 32050 - Train Loss: 0.067908, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 32051 - Train Loss: 0.067907, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 32052 - Train Loss: 0.067906, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 32053 - Train Loss: 0.067905, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 32054 - Train Loss: 0.067904, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 32055 - Train Loss: 0.067903, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 32056 - Train Loss: 0.067902, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 32057 - Train Loss: 0.067901, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 32058 - Train Loss: 0.067900, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 32059 - Train Loss: 0.067898, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 32060 - Train Loss: 0.067897, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 32061 - Train Loss: 0.067896, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32062 - Train Loss: 0.067895, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32063 - Train Loss: 0.067894, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32064 - Train Loss: 0.067893, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32065 - Train Loss: 0.067892, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32066 - Train Loss: 0.067891, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32067 - Train Loss: 0.067890, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 32068 - Train Loss: 0.067888, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.783505\n",
      "Epoch 32069 - Train Loss: 0.067887, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.783505\n",
      "Epoch 32070 - Train Loss: 0.067886, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.783505\n",
      "Epoch 32071 - Train Loss: 0.067885, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.783505\n",
      "Epoch 32072 - Train Loss: 0.067884, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.783505\n",
      "Epoch 32073 - Train Loss: 0.067883, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.783505\n",
      "Epoch 32074 - Train Loss: 0.067882, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 32075 - Train Loss: 0.067881, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 32076 - Train Loss: 0.067880, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 32077 - Train Loss: 0.067878, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 32078 - Train Loss: 0.067877, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 32079 - Train Loss: 0.067876, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 32080 - Train Loss: 0.067875, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 32081 - Train Loss: 0.067874, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 32082 - Train Loss: 0.067873, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 32083 - Train Loss: 0.067872, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 32084 - Train Loss: 0.067871, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 32085 - Train Loss: 0.067870, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 32086 - Train Loss: 0.067869, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 32087 - Train Loss: 0.067867, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 32088 - Train Loss: 0.067866, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 32089 - Train Loss: 0.067865, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 32090 - Train Loss: 0.067864, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 32091 - Train Loss: 0.067863, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 32092 - Train Loss: 0.067862, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 32093 - Train Loss: 0.067861, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 32094 - Train Loss: 0.067860, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 32095 - Train Loss: 0.067859, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 32096 - Train Loss: 0.067857, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 32097 - Train Loss: 0.067856, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 32098 - Train Loss: 0.067855, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 32099 - Train Loss: 0.067854, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 32100 - Train Loss: 0.067853, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 32101 - Train Loss: 0.067852, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 32102 - Train Loss: 0.067851, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 32103 - Train Loss: 0.067850, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 32104 - Train Loss: 0.067849, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 32105 - Train Loss: 0.067847, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 32106 - Train Loss: 0.067846, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 32107 - Train Loss: 0.067845, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 32108 - Train Loss: 0.067844, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 32109 - Train Loss: 0.067843, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 32110 - Train Loss: 0.067842, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32111 - Train Loss: 0.067841, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32112 - Train Loss: 0.067840, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32113 - Train Loss: 0.067839, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32114 - Train Loss: 0.067838, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32115 - Train Loss: 0.067836, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32116 - Train Loss: 0.067835, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.783505\n",
      "Epoch 32117 - Train Loss: 0.067834, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 32118 - Train Loss: 0.067833, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 32119 - Train Loss: 0.067832, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 32120 - Train Loss: 0.067831, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 32121 - Train Loss: 0.067830, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 32122 - Train Loss: 0.067829, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 32123 - Train Loss: 0.067828, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 32124 - Train Loss: 0.067826, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 32125 - Train Loss: 0.067825, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 32126 - Train Loss: 0.067824, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 32127 - Train Loss: 0.067823, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 32128 - Train Loss: 0.067822, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 32129 - Train Loss: 0.067821, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 32130 - Train Loss: 0.067820, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 32131 - Train Loss: 0.067819, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 32132 - Train Loss: 0.067818, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 32133 - Train Loss: 0.067817, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 32134 - Train Loss: 0.067815, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 32135 - Train Loss: 0.067814, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 32136 - Train Loss: 0.067813, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 32137 - Train Loss: 0.067812, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 32138 - Train Loss: 0.067811, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 32139 - Train Loss: 0.067810, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 32140 - Train Loss: 0.067809, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 32141 - Train Loss: 0.067808, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32142 - Train Loss: 0.067807, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32143 - Train Loss: 0.067805, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32144 - Train Loss: 0.067804, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32145 - Train Loss: 0.067803, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32146 - Train Loss: 0.067802, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32147 - Train Loss: 0.067801, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 32148 - Train Loss: 0.067800, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 32149 - Train Loss: 0.067799, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 32150 - Train Loss: 0.067798, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 32151 - Train Loss: 0.067797, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 32152 - Train Loss: 0.067796, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 32153 - Train Loss: 0.067794, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 32154 - Train Loss: 0.067793, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.783505\n",
      "Epoch 32155 - Train Loss: 0.067792, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.783505\n",
      "Epoch 32156 - Train Loss: 0.067791, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.783505\n",
      "Epoch 32157 - Train Loss: 0.067790, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.783505\n",
      "Epoch 32158 - Train Loss: 0.067789, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.783505\n",
      "Epoch 32159 - Train Loss: 0.067788, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.783505\n",
      "Epoch 32160 - Train Loss: 0.067787, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 32161 - Train Loss: 0.067786, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 32162 - Train Loss: 0.067785, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 32163 - Train Loss: 0.067783, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 32164 - Train Loss: 0.067782, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 32165 - Train Loss: 0.067781, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 32166 - Train Loss: 0.067780, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 32167 - Train Loss: 0.067779, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 32168 - Train Loss: 0.067778, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 32169 - Train Loss: 0.067777, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 32170 - Train Loss: 0.067776, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 32171 - Train Loss: 0.067775, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 32172 - Train Loss: 0.067773, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32173 - Train Loss: 0.067772, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32174 - Train Loss: 0.067771, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32175 - Train Loss: 0.067770, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32176 - Train Loss: 0.067769, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32177 - Train Loss: 0.067768, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32178 - Train Loss: 0.067767, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 32179 - Train Loss: 0.067766, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 32180 - Train Loss: 0.067765, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 32181 - Train Loss: 0.067764, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 32182 - Train Loss: 0.067762, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 32183 - Train Loss: 0.067761, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 32184 - Train Loss: 0.067760, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 32185 - Train Loss: 0.067759, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 32186 - Train Loss: 0.067758, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 32187 - Train Loss: 0.067757, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 32188 - Train Loss: 0.067756, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 32189 - Train Loss: 0.067755, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 32190 - Train Loss: 0.067754, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 32191 - Train Loss: 0.067753, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32192 - Train Loss: 0.067751, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32193 - Train Loss: 0.067750, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32194 - Train Loss: 0.067749, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32195 - Train Loss: 0.067748, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32196 - Train Loss: 0.067747, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32197 - Train Loss: 0.067746, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 32198 - Train Loss: 0.067745, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.783505\n",
      "Epoch 32199 - Train Loss: 0.067744, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.783505\n",
      "Epoch 32200 - Train Loss: 0.067743, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.783505\n",
      "Epoch 32201 - Train Loss: 0.067741, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.783505\n",
      "Epoch 32202 - Train Loss: 0.067740, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.783505\n",
      "Epoch 32203 - Train Loss: 0.067739, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.783505\n",
      "Epoch 32204 - Train Loss: 0.067738, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 32205 - Train Loss: 0.067737, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 32206 - Train Loss: 0.067736, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 32207 - Train Loss: 0.067735, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 32208 - Train Loss: 0.067734, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 32209 - Train Loss: 0.067733, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 32210 - Train Loss: 0.067732, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 32211 - Train Loss: 0.067730, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 32212 - Train Loss: 0.067729, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 32213 - Train Loss: 0.067728, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 32214 - Train Loss: 0.067727, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 32215 - Train Loss: 0.067726, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 32216 - Train Loss: 0.067725, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32217 - Train Loss: 0.067724, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32218 - Train Loss: 0.067723, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32219 - Train Loss: 0.067722, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32220 - Train Loss: 0.067721, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32221 - Train Loss: 0.067719, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32222 - Train Loss: 0.067718, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 32223 - Train Loss: 0.067717, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 32224 - Train Loss: 0.067716, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 32225 - Train Loss: 0.067715, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 32226 - Train Loss: 0.067714, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 32227 - Train Loss: 0.067713, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 32228 - Train Loss: 0.067712, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 32229 - Train Loss: 0.067711, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 32230 - Train Loss: 0.067710, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 32231 - Train Loss: 0.067708, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 32232 - Train Loss: 0.067707, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 32233 - Train Loss: 0.067706, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 32234 - Train Loss: 0.067705, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 32235 - Train Loss: 0.067704, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32236 - Train Loss: 0.067703, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32237 - Train Loss: 0.067702, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32238 - Train Loss: 0.067701, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32239 - Train Loss: 0.067700, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32240 - Train Loss: 0.067699, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32241 - Train Loss: 0.067697, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.783505\n",
      "Epoch 32242 - Train Loss: 0.067696, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 32243 - Train Loss: 0.067695, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 32244 - Train Loss: 0.067694, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 32245 - Train Loss: 0.067693, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 32246 - Train Loss: 0.067692, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 32247 - Train Loss: 0.067691, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 32248 - Train Loss: 0.067690, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 32249 - Train Loss: 0.067689, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 32250 - Train Loss: 0.067688, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 32251 - Train Loss: 0.067686, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 32252 - Train Loss: 0.067685, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 32253 - Train Loss: 0.067684, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 32254 - Train Loss: 0.067683, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32255 - Train Loss: 0.067682, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32256 - Train Loss: 0.067681, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32257 - Train Loss: 0.067680, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32258 - Train Loss: 0.067679, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32259 - Train Loss: 0.067678, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32260 - Train Loss: 0.067677, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 32261 - Train Loss: 0.067675, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 32262 - Train Loss: 0.067674, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 32263 - Train Loss: 0.067673, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 32264 - Train Loss: 0.067672, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 32265 - Train Loss: 0.067671, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 32266 - Train Loss: 0.067670, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 32267 - Train Loss: 0.067669, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32268 - Train Loss: 0.067668, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32269 - Train Loss: 0.067667, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32270 - Train Loss: 0.067666, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32271 - Train Loss: 0.067664, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32272 - Train Loss: 0.067663, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32273 - Train Loss: 0.067662, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 32274 - Train Loss: 0.067661, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 32275 - Train Loss: 0.067660, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 32276 - Train Loss: 0.067659, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 32277 - Train Loss: 0.067658, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 32278 - Train Loss: 0.067657, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 32279 - Train Loss: 0.067656, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 32280 - Train Loss: 0.067655, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 32281 - Train Loss: 0.067653, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 32282 - Train Loss: 0.067652, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 32283 - Train Loss: 0.067651, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 32284 - Train Loss: 0.067650, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 32285 - Train Loss: 0.067649, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 32286 - Train Loss: 0.067648, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32287 - Train Loss: 0.067647, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32288 - Train Loss: 0.067646, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32289 - Train Loss: 0.067645, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32290 - Train Loss: 0.067644, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32291 - Train Loss: 0.067643, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32292 - Train Loss: 0.067641, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.783505\n",
      "Epoch 32293 - Train Loss: 0.067640, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 32294 - Train Loss: 0.067639, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 32295 - Train Loss: 0.067638, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 32296 - Train Loss: 0.067637, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 32297 - Train Loss: 0.067636, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 32298 - Train Loss: 0.067635, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 32299 - Train Loss: 0.067634, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32300 - Train Loss: 0.067633, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32301 - Train Loss: 0.067632, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32302 - Train Loss: 0.067630, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32303 - Train Loss: 0.067629, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32304 - Train Loss: 0.067628, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32305 - Train Loss: 0.067627, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 32306 - Train Loss: 0.067626, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 32307 - Train Loss: 0.067625, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 32308 - Train Loss: 0.067624, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 32309 - Train Loss: 0.067623, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 32310 - Train Loss: 0.067622, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 32311 - Train Loss: 0.067621, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 32312 - Train Loss: 0.067619, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32313 - Train Loss: 0.067618, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32314 - Train Loss: 0.067617, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32315 - Train Loss: 0.067616, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32316 - Train Loss: 0.067615, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32317 - Train Loss: 0.067614, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32318 - Train Loss: 0.067613, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 32319 - Train Loss: 0.067612, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 32320 - Train Loss: 0.067611, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 32321 - Train Loss: 0.067610, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 32322 - Train Loss: 0.067609, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 32323 - Train Loss: 0.067607, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 32324 - Train Loss: 0.067606, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 32325 - Train Loss: 0.067605, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32326 - Train Loss: 0.067604, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32327 - Train Loss: 0.067603, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32328 - Train Loss: 0.067602, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32329 - Train Loss: 0.067601, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32330 - Train Loss: 0.067600, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32331 - Train Loss: 0.067599, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 32332 - Train Loss: 0.067598, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.783505\n",
      "Epoch 32333 - Train Loss: 0.067596, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.783505\n",
      "Epoch 32334 - Train Loss: 0.067595, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.783505\n",
      "Epoch 32335 - Train Loss: 0.067594, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.783505\n",
      "Epoch 32336 - Train Loss: 0.067593, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.783505\n",
      "Epoch 32337 - Train Loss: 0.067592, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.783505\n",
      "Epoch 32338 - Train Loss: 0.067591, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32339 - Train Loss: 0.067590, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32340 - Train Loss: 0.067589, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32341 - Train Loss: 0.067588, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32342 - Train Loss: 0.067587, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32343 - Train Loss: 0.067586, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32344 - Train Loss: 0.067584, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 32345 - Train Loss: 0.067583, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 32346 - Train Loss: 0.067582, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 32347 - Train Loss: 0.067581, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 32348 - Train Loss: 0.067580, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 32349 - Train Loss: 0.067579, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 32350 - Train Loss: 0.067578, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 32351 - Train Loss: 0.067577, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32352 - Train Loss: 0.067576, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32353 - Train Loss: 0.067575, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32354 - Train Loss: 0.067573, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32355 - Train Loss: 0.067572, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32356 - Train Loss: 0.067571, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32357 - Train Loss: 0.067570, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 32358 - Train Loss: 0.067569, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 32359 - Train Loss: 0.067568, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 32360 - Train Loss: 0.067567, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 32361 - Train Loss: 0.067566, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 32362 - Train Loss: 0.067565, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 32363 - Train Loss: 0.067564, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 32364 - Train Loss: 0.067563, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32365 - Train Loss: 0.067561, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32366 - Train Loss: 0.067560, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32367 - Train Loss: 0.067559, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32368 - Train Loss: 0.067558, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32369 - Train Loss: 0.067557, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32370 - Train Loss: 0.067556, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 32371 - Train Loss: 0.067555, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 32372 - Train Loss: 0.067554, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 32373 - Train Loss: 0.067553, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 32374 - Train Loss: 0.067552, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 32375 - Train Loss: 0.067550, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 32376 - Train Loss: 0.067549, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 32377 - Train Loss: 0.067548, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32378 - Train Loss: 0.067547, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32379 - Train Loss: 0.067546, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32380 - Train Loss: 0.067545, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32381 - Train Loss: 0.067544, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32382 - Train Loss: 0.067543, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32383 - Train Loss: 0.067542, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.783505\n",
      "Epoch 32384 - Train Loss: 0.067541, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 32385 - Train Loss: 0.067540, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 32386 - Train Loss: 0.067538, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 32387 - Train Loss: 0.067537, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 32388 - Train Loss: 0.067536, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 32389 - Train Loss: 0.067535, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 32390 - Train Loss: 0.067534, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32391 - Train Loss: 0.067533, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32392 - Train Loss: 0.067532, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32393 - Train Loss: 0.067531, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32394 - Train Loss: 0.067530, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32395 - Train Loss: 0.067529, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32396 - Train Loss: 0.067528, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 32397 - Train Loss: 0.067526, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 32398 - Train Loss: 0.067525, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 32399 - Train Loss: 0.067524, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 32400 - Train Loss: 0.067523, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 32401 - Train Loss: 0.067522, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 32402 - Train Loss: 0.067521, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 32403 - Train Loss: 0.067520, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32404 - Train Loss: 0.067519, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32405 - Train Loss: 0.067518, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32406 - Train Loss: 0.067517, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32407 - Train Loss: 0.067516, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32408 - Train Loss: 0.067514, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32409 - Train Loss: 0.067513, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 32410 - Train Loss: 0.067512, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32411 - Train Loss: 0.067511, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32412 - Train Loss: 0.067510, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32413 - Train Loss: 0.067509, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32414 - Train Loss: 0.067508, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32415 - Train Loss: 0.067507, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32416 - Train Loss: 0.067506, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 32417 - Train Loss: 0.067505, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 32418 - Train Loss: 0.067503, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 32419 - Train Loss: 0.067502, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 32420 - Train Loss: 0.067501, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 32421 - Train Loss: 0.067500, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 32422 - Train Loss: 0.067499, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 32423 - Train Loss: 0.067498, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32424 - Train Loss: 0.067497, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32425 - Train Loss: 0.067496, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32426 - Train Loss: 0.067495, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32427 - Train Loss: 0.067494, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32428 - Train Loss: 0.067493, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32429 - Train Loss: 0.067491, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.773196\n",
      "Epoch 32430 - Train Loss: 0.067490, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.773196\n",
      "Epoch 32431 - Train Loss: 0.067489, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.773196\n",
      "Epoch 32432 - Train Loss: 0.067488, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.773196\n",
      "Epoch 32433 - Train Loss: 0.067487, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.773196\n",
      "Epoch 32434 - Train Loss: 0.067486, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.773196\n",
      "Epoch 32435 - Train Loss: 0.067485, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.773196\n",
      "Epoch 32436 - Train Loss: 0.067484, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32437 - Train Loss: 0.067483, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32438 - Train Loss: 0.067482, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32439 - Train Loss: 0.067481, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32440 - Train Loss: 0.067479, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32441 - Train Loss: 0.067478, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32442 - Train Loss: 0.067477, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.773196\n",
      "Epoch 32443 - Train Loss: 0.067476, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32444 - Train Loss: 0.067475, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32445 - Train Loss: 0.067474, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32446 - Train Loss: 0.067473, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32447 - Train Loss: 0.067472, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32448 - Train Loss: 0.067471, Train Acc: 0.888462 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32449 - Train Loss: 0.067470, Train Acc: 0.888462 | Val Loss: 0.108786, Val Acc: 0.773196\n",
      "Epoch 32450 - Train Loss: 0.067469, Train Acc: 0.888462 | Val Loss: 0.108785, Val Acc: 0.773196\n",
      "Epoch 32451 - Train Loss: 0.067467, Train Acc: 0.888462 | Val Loss: 0.108785, Val Acc: 0.773196\n",
      "Epoch 32452 - Train Loss: 0.067466, Train Acc: 0.888462 | Val Loss: 0.108785, Val Acc: 0.773196\n",
      "Epoch 32453 - Train Loss: 0.067465, Train Acc: 0.888462 | Val Loss: 0.108785, Val Acc: 0.773196\n",
      "Epoch 32454 - Train Loss: 0.067464, Train Acc: 0.888462 | Val Loss: 0.108785, Val Acc: 0.773196\n",
      "Epoch 32455 - Train Loss: 0.067463, Train Acc: 0.888462 | Val Loss: 0.108785, Val Acc: 0.773196\n",
      "Epoch 32456 - Train Loss: 0.067462, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32457 - Train Loss: 0.067461, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32458 - Train Loss: 0.067460, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32459 - Train Loss: 0.067459, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32460 - Train Loss: 0.067458, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32461 - Train Loss: 0.067457, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32462 - Train Loss: 0.067456, Train Acc: 0.888462 | Val Loss: 0.108784, Val Acc: 0.773196\n",
      "Epoch 32463 - Train Loss: 0.067454, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32464 - Train Loss: 0.067453, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32465 - Train Loss: 0.067452, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32466 - Train Loss: 0.067451, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32467 - Train Loss: 0.067450, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32468 - Train Loss: 0.067449, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32469 - Train Loss: 0.067448, Train Acc: 0.888462 | Val Loss: 0.108783, Val Acc: 0.773196\n",
      "Epoch 32470 - Train Loss: 0.067447, Train Acc: 0.888462 | Val Loss: 0.108782, Val Acc: 0.773196\n",
      "Epoch 32471 - Train Loss: 0.067446, Train Acc: 0.888462 | Val Loss: 0.108782, Val Acc: 0.773196\n",
      "Epoch 32472 - Train Loss: 0.067445, Train Acc: 0.888462 | Val Loss: 0.108782, Val Acc: 0.773196\n",
      "Epoch 32473 - Train Loss: 0.067444, Train Acc: 0.888462 | Val Loss: 0.108782, Val Acc: 0.773196\n",
      "Epoch 32474 - Train Loss: 0.067442, Train Acc: 0.888462 | Val Loss: 0.108782, Val Acc: 0.773196\n",
      "Epoch 32475 - Train Loss: 0.067441, Train Acc: 0.888462 | Val Loss: 0.108782, Val Acc: 0.773196\n",
      "Epoch 32476 - Train Loss: 0.067440, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32477 - Train Loss: 0.067439, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32478 - Train Loss: 0.067438, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32479 - Train Loss: 0.067437, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32480 - Train Loss: 0.067436, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32481 - Train Loss: 0.067435, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32482 - Train Loss: 0.067434, Train Acc: 0.888462 | Val Loss: 0.108781, Val Acc: 0.773196\n",
      "Epoch 32483 - Train Loss: 0.067433, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32484 - Train Loss: 0.067432, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32485 - Train Loss: 0.067430, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32486 - Train Loss: 0.067429, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32487 - Train Loss: 0.067428, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32488 - Train Loss: 0.067427, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32489 - Train Loss: 0.067426, Train Acc: 0.888462 | Val Loss: 0.108780, Val Acc: 0.773196\n",
      "Epoch 32490 - Train Loss: 0.067425, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32491 - Train Loss: 0.067424, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32492 - Train Loss: 0.067423, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32493 - Train Loss: 0.067422, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32494 - Train Loss: 0.067421, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32495 - Train Loss: 0.067420, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32496 - Train Loss: 0.067418, Train Acc: 0.888462 | Val Loss: 0.108779, Val Acc: 0.773196\n",
      "Epoch 32497 - Train Loss: 0.067417, Train Acc: 0.888462 | Val Loss: 0.108778, Val Acc: 0.773196\n",
      "Epoch 32498 - Train Loss: 0.067416, Train Acc: 0.888462 | Val Loss: 0.108778, Val Acc: 0.773196\n",
      "Epoch 32499 - Train Loss: 0.067415, Train Acc: 0.888462 | Val Loss: 0.108778, Val Acc: 0.773196\n",
      "Epoch 32500 - Train Loss: 0.067414, Train Acc: 0.888462 | Val Loss: 0.108778, Val Acc: 0.773196\n",
      "Epoch 32501 - Train Loss: 0.067413, Train Acc: 0.888462 | Val Loss: 0.108778, Val Acc: 0.773196\n",
      "Epoch 32502 - Train Loss: 0.067412, Train Acc: 0.888462 | Val Loss: 0.108778, Val Acc: 0.773196\n",
      "Epoch 32503 - Train Loss: 0.067411, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32504 - Train Loss: 0.067410, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32505 - Train Loss: 0.067409, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32506 - Train Loss: 0.067408, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32507 - Train Loss: 0.067407, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32508 - Train Loss: 0.067405, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32509 - Train Loss: 0.067404, Train Acc: 0.888462 | Val Loss: 0.108777, Val Acc: 0.773196\n",
      "Epoch 32510 - Train Loss: 0.067403, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32511 - Train Loss: 0.067402, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32512 - Train Loss: 0.067401, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32513 - Train Loss: 0.067400, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32514 - Train Loss: 0.067399, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32515 - Train Loss: 0.067398, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32516 - Train Loss: 0.067397, Train Acc: 0.888462 | Val Loss: 0.108776, Val Acc: 0.773196\n",
      "Epoch 32517 - Train Loss: 0.067396, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32518 - Train Loss: 0.067395, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32519 - Train Loss: 0.067393, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32520 - Train Loss: 0.067392, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32521 - Train Loss: 0.067391, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32522 - Train Loss: 0.067390, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32523 - Train Loss: 0.067389, Train Acc: 0.888462 | Val Loss: 0.108775, Val Acc: 0.773196\n",
      "Epoch 32524 - Train Loss: 0.067388, Train Acc: 0.888462 | Val Loss: 0.108774, Val Acc: 0.773196\n",
      "Epoch 32525 - Train Loss: 0.067387, Train Acc: 0.888462 | Val Loss: 0.108774, Val Acc: 0.773196\n",
      "Epoch 32526 - Train Loss: 0.067386, Train Acc: 0.888462 | Val Loss: 0.108774, Val Acc: 0.773196\n",
      "Epoch 32527 - Train Loss: 0.067385, Train Acc: 0.888462 | Val Loss: 0.108774, Val Acc: 0.773196\n",
      "Epoch 32528 - Train Loss: 0.067384, Train Acc: 0.888462 | Val Loss: 0.108774, Val Acc: 0.773196\n",
      "Epoch 32529 - Train Loss: 0.067383, Train Acc: 0.888462 | Val Loss: 0.108774, Val Acc: 0.773196\n",
      "Epoch 32530 - Train Loss: 0.067382, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32531 - Train Loss: 0.067380, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32532 - Train Loss: 0.067379, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32533 - Train Loss: 0.067378, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32534 - Train Loss: 0.067377, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32535 - Train Loss: 0.067376, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32536 - Train Loss: 0.067375, Train Acc: 0.888462 | Val Loss: 0.108773, Val Acc: 0.773196\n",
      "Epoch 32537 - Train Loss: 0.067374, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32538 - Train Loss: 0.067373, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32539 - Train Loss: 0.067372, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32540 - Train Loss: 0.067371, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32541 - Train Loss: 0.067370, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32542 - Train Loss: 0.067369, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32543 - Train Loss: 0.067367, Train Acc: 0.888462 | Val Loss: 0.108772, Val Acc: 0.773196\n",
      "Epoch 32544 - Train Loss: 0.067366, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32545 - Train Loss: 0.067365, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32546 - Train Loss: 0.067364, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32547 - Train Loss: 0.067363, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32548 - Train Loss: 0.067362, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32549 - Train Loss: 0.067361, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32550 - Train Loss: 0.067360, Train Acc: 0.888462 | Val Loss: 0.108771, Val Acc: 0.773196\n",
      "Epoch 32551 - Train Loss: 0.067359, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32552 - Train Loss: 0.067358, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32553 - Train Loss: 0.067357, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32554 - Train Loss: 0.067355, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32555 - Train Loss: 0.067354, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32556 - Train Loss: 0.067353, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32557 - Train Loss: 0.067352, Train Acc: 0.888462 | Val Loss: 0.108770, Val Acc: 0.773196\n",
      "Epoch 32558 - Train Loss: 0.067351, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32559 - Train Loss: 0.067350, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32560 - Train Loss: 0.067349, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32561 - Train Loss: 0.067348, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32562 - Train Loss: 0.067347, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32563 - Train Loss: 0.067346, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32564 - Train Loss: 0.067345, Train Acc: 0.888462 | Val Loss: 0.108769, Val Acc: 0.773196\n",
      "Epoch 32565 - Train Loss: 0.067344, Train Acc: 0.888462 | Val Loss: 0.108768, Val Acc: 0.773196\n",
      "Epoch 32566 - Train Loss: 0.067342, Train Acc: 0.888462 | Val Loss: 0.108768, Val Acc: 0.773196\n",
      "Epoch 32567 - Train Loss: 0.067341, Train Acc: 0.888462 | Val Loss: 0.108768, Val Acc: 0.773196\n",
      "Epoch 32568 - Train Loss: 0.067340, Train Acc: 0.888462 | Val Loss: 0.108768, Val Acc: 0.773196\n",
      "Epoch 32569 - Train Loss: 0.067339, Train Acc: 0.888462 | Val Loss: 0.108768, Val Acc: 0.773196\n",
      "Epoch 32570 - Train Loss: 0.067338, Train Acc: 0.888462 | Val Loss: 0.108768, Val Acc: 0.773196\n",
      "Epoch 32571 - Train Loss: 0.067337, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32572 - Train Loss: 0.067336, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32573 - Train Loss: 0.067335, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32574 - Train Loss: 0.067334, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32575 - Train Loss: 0.067333, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32576 - Train Loss: 0.067332, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32577 - Train Loss: 0.067331, Train Acc: 0.888462 | Val Loss: 0.108767, Val Acc: 0.773196\n",
      "Epoch 32578 - Train Loss: 0.067329, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32579 - Train Loss: 0.067328, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32580 - Train Loss: 0.067327, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32581 - Train Loss: 0.067326, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32582 - Train Loss: 0.067325, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32583 - Train Loss: 0.067324, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32584 - Train Loss: 0.067323, Train Acc: 0.888462 | Val Loss: 0.108766, Val Acc: 0.773196\n",
      "Epoch 32585 - Train Loss: 0.067322, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32586 - Train Loss: 0.067321, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32587 - Train Loss: 0.067320, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32588 - Train Loss: 0.067319, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32589 - Train Loss: 0.067318, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32590 - Train Loss: 0.067316, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32591 - Train Loss: 0.067315, Train Acc: 0.888462 | Val Loss: 0.108765, Val Acc: 0.773196\n",
      "Epoch 32592 - Train Loss: 0.067314, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32593 - Train Loss: 0.067313, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32594 - Train Loss: 0.067312, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32595 - Train Loss: 0.067311, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32596 - Train Loss: 0.067310, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32597 - Train Loss: 0.067309, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32598 - Train Loss: 0.067308, Train Acc: 0.888462 | Val Loss: 0.108764, Val Acc: 0.773196\n",
      "Epoch 32599 - Train Loss: 0.067307, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32600 - Train Loss: 0.067306, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32601 - Train Loss: 0.067305, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32602 - Train Loss: 0.067303, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32603 - Train Loss: 0.067302, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32604 - Train Loss: 0.067301, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32605 - Train Loss: 0.067300, Train Acc: 0.888462 | Val Loss: 0.108763, Val Acc: 0.773196\n",
      "Epoch 32606 - Train Loss: 0.067299, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32607 - Train Loss: 0.067298, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32608 - Train Loss: 0.067297, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32609 - Train Loss: 0.067296, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32610 - Train Loss: 0.067295, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32611 - Train Loss: 0.067294, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32612 - Train Loss: 0.067293, Train Acc: 0.888462 | Val Loss: 0.108762, Val Acc: 0.773196\n",
      "Epoch 32613 - Train Loss: 0.067292, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32614 - Train Loss: 0.067290, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32615 - Train Loss: 0.067289, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32616 - Train Loss: 0.067288, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32617 - Train Loss: 0.067287, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32618 - Train Loss: 0.067286, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32619 - Train Loss: 0.067285, Train Acc: 0.888462 | Val Loss: 0.108761, Val Acc: 0.773196\n",
      "Epoch 32620 - Train Loss: 0.067284, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32621 - Train Loss: 0.067283, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32622 - Train Loss: 0.067282, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32623 - Train Loss: 0.067281, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32624 - Train Loss: 0.067280, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32625 - Train Loss: 0.067279, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32626 - Train Loss: 0.067277, Train Acc: 0.888462 | Val Loss: 0.108760, Val Acc: 0.773196\n",
      "Epoch 32627 - Train Loss: 0.067276, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32628 - Train Loss: 0.067275, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32629 - Train Loss: 0.067274, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32630 - Train Loss: 0.067273, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32631 - Train Loss: 0.067272, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32632 - Train Loss: 0.067271, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32633 - Train Loss: 0.067270, Train Acc: 0.888462 | Val Loss: 0.108759, Val Acc: 0.773196\n",
      "Epoch 32634 - Train Loss: 0.067269, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32635 - Train Loss: 0.067268, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32636 - Train Loss: 0.067267, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32637 - Train Loss: 0.067266, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32638 - Train Loss: 0.067264, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32639 - Train Loss: 0.067263, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32640 - Train Loss: 0.067262, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.773196\n",
      "Epoch 32641 - Train Loss: 0.067261, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32642 - Train Loss: 0.067260, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32643 - Train Loss: 0.067259, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32644 - Train Loss: 0.067258, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32645 - Train Loss: 0.067257, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32646 - Train Loss: 0.067256, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32647 - Train Loss: 0.067255, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.773196\n",
      "Epoch 32648 - Train Loss: 0.067254, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32649 - Train Loss: 0.067253, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32650 - Train Loss: 0.067252, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32651 - Train Loss: 0.067250, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32652 - Train Loss: 0.067249, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32653 - Train Loss: 0.067248, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32654 - Train Loss: 0.067247, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.773196\n",
      "Epoch 32655 - Train Loss: 0.067246, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32656 - Train Loss: 0.067245, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32657 - Train Loss: 0.067244, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32658 - Train Loss: 0.067243, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32659 - Train Loss: 0.067242, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32660 - Train Loss: 0.067241, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32661 - Train Loss: 0.067240, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.773196\n",
      "Epoch 32662 - Train Loss: 0.067239, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32663 - Train Loss: 0.067237, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32664 - Train Loss: 0.067236, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32665 - Train Loss: 0.067235, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32666 - Train Loss: 0.067234, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32667 - Train Loss: 0.067233, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32668 - Train Loss: 0.067232, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.773196\n",
      "Epoch 32669 - Train Loss: 0.067231, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32670 - Train Loss: 0.067230, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32671 - Train Loss: 0.067229, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32672 - Train Loss: 0.067228, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32673 - Train Loss: 0.067227, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32674 - Train Loss: 0.067226, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32675 - Train Loss: 0.067225, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.773196\n",
      "Epoch 32676 - Train Loss: 0.067223, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32677 - Train Loss: 0.067222, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32678 - Train Loss: 0.067221, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32679 - Train Loss: 0.067220, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32680 - Train Loss: 0.067219, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32681 - Train Loss: 0.067218, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32682 - Train Loss: 0.067217, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.773196\n",
      "Epoch 32683 - Train Loss: 0.067216, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32684 - Train Loss: 0.067215, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32685 - Train Loss: 0.067214, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32686 - Train Loss: 0.067213, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32687 - Train Loss: 0.067212, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32688 - Train Loss: 0.067210, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32689 - Train Loss: 0.067209, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.773196\n",
      "Epoch 32690 - Train Loss: 0.067208, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32691 - Train Loss: 0.067207, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32692 - Train Loss: 0.067206, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32693 - Train Loss: 0.067205, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32694 - Train Loss: 0.067204, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32695 - Train Loss: 0.067203, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32696 - Train Loss: 0.067202, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.773196\n",
      "Epoch 32697 - Train Loss: 0.067201, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32698 - Train Loss: 0.067200, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32699 - Train Loss: 0.067199, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32700 - Train Loss: 0.067198, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32701 - Train Loss: 0.067196, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32702 - Train Loss: 0.067195, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32703 - Train Loss: 0.067194, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.773196\n",
      "Epoch 32704 - Train Loss: 0.067193, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32705 - Train Loss: 0.067192, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32706 - Train Loss: 0.067191, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32707 - Train Loss: 0.067190, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32708 - Train Loss: 0.067189, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32709 - Train Loss: 0.067188, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32710 - Train Loss: 0.067187, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.773196\n",
      "Epoch 32711 - Train Loss: 0.067186, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32712 - Train Loss: 0.067185, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32713 - Train Loss: 0.067184, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32714 - Train Loss: 0.067182, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32715 - Train Loss: 0.067181, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32716 - Train Loss: 0.067180, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32717 - Train Loss: 0.067179, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32718 - Train Loss: 0.067178, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.773196\n",
      "Epoch 32719 - Train Loss: 0.067177, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32720 - Train Loss: 0.067176, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32721 - Train Loss: 0.067175, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32722 - Train Loss: 0.067174, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32723 - Train Loss: 0.067173, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32724 - Train Loss: 0.067172, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32725 - Train Loss: 0.067171, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.773196\n",
      "Epoch 32726 - Train Loss: 0.067170, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32727 - Train Loss: 0.067168, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32728 - Train Loss: 0.067167, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32729 - Train Loss: 0.067166, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32730 - Train Loss: 0.067165, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32731 - Train Loss: 0.067164, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32732 - Train Loss: 0.067163, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.773196\n",
      "Epoch 32733 - Train Loss: 0.067162, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32734 - Train Loss: 0.067161, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32735 - Train Loss: 0.067160, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32736 - Train Loss: 0.067159, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32737 - Train Loss: 0.067158, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32738 - Train Loss: 0.067157, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32739 - Train Loss: 0.067156, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.773196\n",
      "Epoch 32740 - Train Loss: 0.067154, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32741 - Train Loss: 0.067153, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32742 - Train Loss: 0.067152, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32743 - Train Loss: 0.067151, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32744 - Train Loss: 0.067150, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32745 - Train Loss: 0.067149, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32746 - Train Loss: 0.067148, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.773196\n",
      "Epoch 32747 - Train Loss: 0.067147, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32748 - Train Loss: 0.067146, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32749 - Train Loss: 0.067145, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32750 - Train Loss: 0.067144, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32751 - Train Loss: 0.067143, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32752 - Train Loss: 0.067142, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32753 - Train Loss: 0.067140, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.773196\n",
      "Epoch 32754 - Train Loss: 0.067139, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32755 - Train Loss: 0.067138, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32756 - Train Loss: 0.067137, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32757 - Train Loss: 0.067136, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32758 - Train Loss: 0.067135, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32759 - Train Loss: 0.067134, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32760 - Train Loss: 0.067133, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32761 - Train Loss: 0.067132, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.773196\n",
      "Epoch 32762 - Train Loss: 0.067131, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32763 - Train Loss: 0.067130, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32764 - Train Loss: 0.067129, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32765 - Train Loss: 0.067128, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32766 - Train Loss: 0.067126, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32767 - Train Loss: 0.067125, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32768 - Train Loss: 0.067124, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.773196\n",
      "Epoch 32769 - Train Loss: 0.067123, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32770 - Train Loss: 0.067122, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32771 - Train Loss: 0.067121, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32772 - Train Loss: 0.067120, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32773 - Train Loss: 0.067119, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32774 - Train Loss: 0.067118, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32775 - Train Loss: 0.067117, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.773196\n",
      "Epoch 32776 - Train Loss: 0.067116, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32777 - Train Loss: 0.067115, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32778 - Train Loss: 0.067114, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32779 - Train Loss: 0.067112, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32780 - Train Loss: 0.067111, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32781 - Train Loss: 0.067110, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32782 - Train Loss: 0.067109, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.773196\n",
      "Epoch 32783 - Train Loss: 0.067108, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32784 - Train Loss: 0.067107, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32785 - Train Loss: 0.067106, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32786 - Train Loss: 0.067105, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32787 - Train Loss: 0.067104, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32788 - Train Loss: 0.067103, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32789 - Train Loss: 0.067102, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32790 - Train Loss: 0.067101, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.773196\n",
      "Epoch 32791 - Train Loss: 0.067100, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32792 - Train Loss: 0.067099, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32793 - Train Loss: 0.067097, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32794 - Train Loss: 0.067096, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32795 - Train Loss: 0.067095, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32796 - Train Loss: 0.067094, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32797 - Train Loss: 0.067093, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.773196\n",
      "Epoch 32798 - Train Loss: 0.067092, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32799 - Train Loss: 0.067091, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32800 - Train Loss: 0.067090, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32801 - Train Loss: 0.067089, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32802 - Train Loss: 0.067088, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32803 - Train Loss: 0.067087, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32804 - Train Loss: 0.067086, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.773196\n",
      "Epoch 32805 - Train Loss: 0.067085, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32806 - Train Loss: 0.067083, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32807 - Train Loss: 0.067082, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32808 - Train Loss: 0.067081, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32809 - Train Loss: 0.067080, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32810 - Train Loss: 0.067079, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32811 - Train Loss: 0.067078, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.773196\n",
      "Epoch 32812 - Train Loss: 0.067077, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32813 - Train Loss: 0.067076, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32814 - Train Loss: 0.067075, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32815 - Train Loss: 0.067074, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32816 - Train Loss: 0.067073, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32817 - Train Loss: 0.067072, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32818 - Train Loss: 0.067071, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32819 - Train Loss: 0.067070, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.773196\n",
      "Epoch 32820 - Train Loss: 0.067068, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32821 - Train Loss: 0.067067, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32822 - Train Loss: 0.067066, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32823 - Train Loss: 0.067065, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32824 - Train Loss: 0.067064, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32825 - Train Loss: 0.067063, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32826 - Train Loss: 0.067062, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.773196\n",
      "Epoch 32827 - Train Loss: 0.067061, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32828 - Train Loss: 0.067060, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32829 - Train Loss: 0.067059, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32830 - Train Loss: 0.067058, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32831 - Train Loss: 0.067057, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32832 - Train Loss: 0.067056, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32833 - Train Loss: 0.067055, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.773196\n",
      "Epoch 32834 - Train Loss: 0.067053, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32835 - Train Loss: 0.067052, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32836 - Train Loss: 0.067051, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32837 - Train Loss: 0.067050, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32838 - Train Loss: 0.067049, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32839 - Train Loss: 0.067048, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32840 - Train Loss: 0.067047, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32841 - Train Loss: 0.067046, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.773196\n",
      "Epoch 32842 - Train Loss: 0.067045, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32843 - Train Loss: 0.067044, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32844 - Train Loss: 0.067043, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32845 - Train Loss: 0.067042, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32846 - Train Loss: 0.067041, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32847 - Train Loss: 0.067039, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32848 - Train Loss: 0.067038, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.773196\n",
      "Epoch 32849 - Train Loss: 0.067037, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32850 - Train Loss: 0.067036, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32851 - Train Loss: 0.067035, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32852 - Train Loss: 0.067034, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32853 - Train Loss: 0.067033, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32854 - Train Loss: 0.067032, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32855 - Train Loss: 0.067031, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32856 - Train Loss: 0.067030, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.773196\n",
      "Epoch 32857 - Train Loss: 0.067029, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32858 - Train Loss: 0.067028, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32859 - Train Loss: 0.067027, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32860 - Train Loss: 0.067026, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32861 - Train Loss: 0.067024, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32862 - Train Loss: 0.067023, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32863 - Train Loss: 0.067022, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.773196\n",
      "Epoch 32864 - Train Loss: 0.067021, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32865 - Train Loss: 0.067020, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32866 - Train Loss: 0.067019, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32867 - Train Loss: 0.067018, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32868 - Train Loss: 0.067017, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32869 - Train Loss: 0.067016, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32870 - Train Loss: 0.067015, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.773196\n",
      "Epoch 32871 - Train Loss: 0.067014, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32872 - Train Loss: 0.067013, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32873 - Train Loss: 0.067012, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32874 - Train Loss: 0.067011, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32875 - Train Loss: 0.067010, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32876 - Train Loss: 0.067008, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32877 - Train Loss: 0.067007, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32878 - Train Loss: 0.067006, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.773196\n",
      "Epoch 32879 - Train Loss: 0.067005, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32880 - Train Loss: 0.067004, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32881 - Train Loss: 0.067003, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32882 - Train Loss: 0.067002, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32883 - Train Loss: 0.067001, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32884 - Train Loss: 0.067000, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32885 - Train Loss: 0.066999, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.773196\n",
      "Epoch 32886 - Train Loss: 0.066998, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32887 - Train Loss: 0.066997, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32888 - Train Loss: 0.066996, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32889 - Train Loss: 0.066995, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32890 - Train Loss: 0.066993, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32891 - Train Loss: 0.066992, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32892 - Train Loss: 0.066991, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32893 - Train Loss: 0.066990, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.773196\n",
      "Epoch 32894 - Train Loss: 0.066989, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32895 - Train Loss: 0.066988, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32896 - Train Loss: 0.066987, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32897 - Train Loss: 0.066986, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32898 - Train Loss: 0.066985, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32899 - Train Loss: 0.066984, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32900 - Train Loss: 0.066983, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.773196\n",
      "Epoch 32901 - Train Loss: 0.066982, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32902 - Train Loss: 0.066981, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32903 - Train Loss: 0.066980, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32904 - Train Loss: 0.066978, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32905 - Train Loss: 0.066977, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32906 - Train Loss: 0.066976, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32907 - Train Loss: 0.066975, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32908 - Train Loss: 0.066974, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.773196\n",
      "Epoch 32909 - Train Loss: 0.066973, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32910 - Train Loss: 0.066972, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32911 - Train Loss: 0.066971, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32912 - Train Loss: 0.066970, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32913 - Train Loss: 0.066969, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32914 - Train Loss: 0.066968, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32915 - Train Loss: 0.066967, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.773196\n",
      "Epoch 32916 - Train Loss: 0.066966, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32917 - Train Loss: 0.066965, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32918 - Train Loss: 0.066964, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32919 - Train Loss: 0.066962, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32920 - Train Loss: 0.066961, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32921 - Train Loss: 0.066960, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32922 - Train Loss: 0.066959, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32923 - Train Loss: 0.066958, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.773196\n",
      "Epoch 32924 - Train Loss: 0.066957, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32925 - Train Loss: 0.066956, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32926 - Train Loss: 0.066955, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32927 - Train Loss: 0.066954, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32928 - Train Loss: 0.066953, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32929 - Train Loss: 0.066952, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32930 - Train Loss: 0.066951, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.773196\n",
      "Epoch 32931 - Train Loss: 0.066950, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32932 - Train Loss: 0.066949, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32933 - Train Loss: 0.066947, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32934 - Train Loss: 0.066946, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32935 - Train Loss: 0.066945, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32936 - Train Loss: 0.066944, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32937 - Train Loss: 0.066943, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32938 - Train Loss: 0.066942, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.773196\n",
      "Epoch 32939 - Train Loss: 0.066941, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32940 - Train Loss: 0.066940, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32941 - Train Loss: 0.066939, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32942 - Train Loss: 0.066938, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32943 - Train Loss: 0.066937, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32944 - Train Loss: 0.066936, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32945 - Train Loss: 0.066935, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.773196\n",
      "Epoch 32946 - Train Loss: 0.066934, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32947 - Train Loss: 0.066933, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32948 - Train Loss: 0.066931, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32949 - Train Loss: 0.066930, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32950 - Train Loss: 0.066929, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32951 - Train Loss: 0.066928, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32952 - Train Loss: 0.066927, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32953 - Train Loss: 0.066926, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.773196\n",
      "Epoch 32954 - Train Loss: 0.066925, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32955 - Train Loss: 0.066924, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32956 - Train Loss: 0.066923, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32957 - Train Loss: 0.066922, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32958 - Train Loss: 0.066921, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32959 - Train Loss: 0.066920, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32960 - Train Loss: 0.066919, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32961 - Train Loss: 0.066918, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.773196\n",
      "Epoch 32962 - Train Loss: 0.066917, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32963 - Train Loss: 0.066915, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32964 - Train Loss: 0.066914, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32965 - Train Loss: 0.066913, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32966 - Train Loss: 0.066912, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32967 - Train Loss: 0.066911, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32968 - Train Loss: 0.066910, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.773196\n",
      "Epoch 32969 - Train Loss: 0.066909, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32970 - Train Loss: 0.066908, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32971 - Train Loss: 0.066907, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32972 - Train Loss: 0.066906, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32973 - Train Loss: 0.066905, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32974 - Train Loss: 0.066904, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32975 - Train Loss: 0.066903, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32976 - Train Loss: 0.066902, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.773196\n",
      "Epoch 32977 - Train Loss: 0.066901, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32978 - Train Loss: 0.066899, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32979 - Train Loss: 0.066898, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32980 - Train Loss: 0.066897, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32981 - Train Loss: 0.066896, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32982 - Train Loss: 0.066895, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32983 - Train Loss: 0.066894, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.773196\n",
      "Epoch 32984 - Train Loss: 0.066893, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32985 - Train Loss: 0.066892, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32986 - Train Loss: 0.066891, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32987 - Train Loss: 0.066890, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32988 - Train Loss: 0.066889, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32989 - Train Loss: 0.066888, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32990 - Train Loss: 0.066887, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32991 - Train Loss: 0.066886, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.773196\n",
      "Epoch 32992 - Train Loss: 0.066885, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32993 - Train Loss: 0.066884, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32994 - Train Loss: 0.066882, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32995 - Train Loss: 0.066881, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32996 - Train Loss: 0.066880, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32997 - Train Loss: 0.066879, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32998 - Train Loss: 0.066878, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 32999 - Train Loss: 0.066877, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.773196\n",
      "Epoch 33000 - Train Loss: 0.066876, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33001 - Train Loss: 0.066875, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33002 - Train Loss: 0.066874, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33003 - Train Loss: 0.066873, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33004 - Train Loss: 0.066872, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33005 - Train Loss: 0.066871, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33006 - Train Loss: 0.066870, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.773196\n",
      "Epoch 33007 - Train Loss: 0.066869, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33008 - Train Loss: 0.066868, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33009 - Train Loss: 0.066866, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33010 - Train Loss: 0.066865, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33011 - Train Loss: 0.066864, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33012 - Train Loss: 0.066863, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33013 - Train Loss: 0.066862, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33014 - Train Loss: 0.066861, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.773196\n",
      "Epoch 33015 - Train Loss: 0.066860, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33016 - Train Loss: 0.066859, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33017 - Train Loss: 0.066858, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33018 - Train Loss: 0.066857, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33019 - Train Loss: 0.066856, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33020 - Train Loss: 0.066855, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33021 - Train Loss: 0.066854, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33022 - Train Loss: 0.066853, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.773196\n",
      "Epoch 33023 - Train Loss: 0.066852, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33024 - Train Loss: 0.066851, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33025 - Train Loss: 0.066849, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33026 - Train Loss: 0.066848, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33027 - Train Loss: 0.066847, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33028 - Train Loss: 0.066846, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33029 - Train Loss: 0.066845, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33030 - Train Loss: 0.066844, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.773196\n",
      "Epoch 33031 - Train Loss: 0.066843, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33032 - Train Loss: 0.066842, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33033 - Train Loss: 0.066841, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33034 - Train Loss: 0.066840, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33035 - Train Loss: 0.066839, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33036 - Train Loss: 0.066838, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33037 - Train Loss: 0.066837, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.773196\n",
      "Epoch 33038 - Train Loss: 0.066836, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33039 - Train Loss: 0.066835, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33040 - Train Loss: 0.066834, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33041 - Train Loss: 0.066832, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33042 - Train Loss: 0.066831, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33043 - Train Loss: 0.066830, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33044 - Train Loss: 0.066829, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33045 - Train Loss: 0.066828, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.773196\n",
      "Epoch 33046 - Train Loss: 0.066827, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33047 - Train Loss: 0.066826, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33048 - Train Loss: 0.066825, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33049 - Train Loss: 0.066824, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33050 - Train Loss: 0.066823, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33051 - Train Loss: 0.066822, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33052 - Train Loss: 0.066821, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33053 - Train Loss: 0.066820, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.773196\n",
      "Epoch 33054 - Train Loss: 0.066819, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33055 - Train Loss: 0.066818, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33056 - Train Loss: 0.066817, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33057 - Train Loss: 0.066815, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33058 - Train Loss: 0.066814, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33059 - Train Loss: 0.066813, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33060 - Train Loss: 0.066812, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33061 - Train Loss: 0.066811, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.773196\n",
      "Epoch 33062 - Train Loss: 0.066810, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33063 - Train Loss: 0.066809, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33064 - Train Loss: 0.066808, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33065 - Train Loss: 0.066807, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33066 - Train Loss: 0.066806, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33067 - Train Loss: 0.066805, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33068 - Train Loss: 0.066804, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33069 - Train Loss: 0.066803, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.773196\n",
      "Epoch 33070 - Train Loss: 0.066802, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33071 - Train Loss: 0.066801, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33072 - Train Loss: 0.066800, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33073 - Train Loss: 0.066798, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33074 - Train Loss: 0.066797, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33075 - Train Loss: 0.066796, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33076 - Train Loss: 0.066795, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.773196\n",
      "Epoch 33077 - Train Loss: 0.066794, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33078 - Train Loss: 0.066793, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33079 - Train Loss: 0.066792, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33080 - Train Loss: 0.066791, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33081 - Train Loss: 0.066790, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33082 - Train Loss: 0.066789, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33083 - Train Loss: 0.066788, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33084 - Train Loss: 0.066787, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.773196\n",
      "Epoch 33085 - Train Loss: 0.066786, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33086 - Train Loss: 0.066785, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33087 - Train Loss: 0.066784, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33088 - Train Loss: 0.066783, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33089 - Train Loss: 0.066781, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33090 - Train Loss: 0.066780, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33091 - Train Loss: 0.066779, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33092 - Train Loss: 0.066778, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.773196\n",
      "Epoch 33093 - Train Loss: 0.066777, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33094 - Train Loss: 0.066776, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33095 - Train Loss: 0.066775, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33096 - Train Loss: 0.066774, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33097 - Train Loss: 0.066773, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33098 - Train Loss: 0.066772, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33099 - Train Loss: 0.066771, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33100 - Train Loss: 0.066770, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.773196\n",
      "Epoch 33101 - Train Loss: 0.066769, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33102 - Train Loss: 0.066768, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33103 - Train Loss: 0.066767, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33104 - Train Loss: 0.066766, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33105 - Train Loss: 0.066765, Train Acc: 0.889744 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33106 - Train Loss: 0.066763, Train Acc: 0.889744 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33107 - Train Loss: 0.066762, Train Acc: 0.889744 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33108 - Train Loss: 0.066761, Train Acc: 0.889744 | Val Loss: 0.108695, Val Acc: 0.773196\n",
      "Epoch 33109 - Train Loss: 0.066760, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33110 - Train Loss: 0.066759, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33111 - Train Loss: 0.066758, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33112 - Train Loss: 0.066757, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33113 - Train Loss: 0.066756, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33114 - Train Loss: 0.066755, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33115 - Train Loss: 0.066754, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33116 - Train Loss: 0.066753, Train Acc: 0.889744 | Val Loss: 0.108694, Val Acc: 0.773196\n",
      "Epoch 33117 - Train Loss: 0.066752, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33118 - Train Loss: 0.066751, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33119 - Train Loss: 0.066750, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33120 - Train Loss: 0.066749, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33121 - Train Loss: 0.066748, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33122 - Train Loss: 0.066746, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33123 - Train Loss: 0.066745, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33124 - Train Loss: 0.066744, Train Acc: 0.889744 | Val Loss: 0.108693, Val Acc: 0.773196\n",
      "Epoch 33125 - Train Loss: 0.066743, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33126 - Train Loss: 0.066742, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33127 - Train Loss: 0.066741, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33128 - Train Loss: 0.066740, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33129 - Train Loss: 0.066739, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33130 - Train Loss: 0.066738, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33131 - Train Loss: 0.066737, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33132 - Train Loss: 0.066736, Train Acc: 0.889744 | Val Loss: 0.108692, Val Acc: 0.773196\n",
      "Epoch 33133 - Train Loss: 0.066735, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33134 - Train Loss: 0.066734, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33135 - Train Loss: 0.066733, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33136 - Train Loss: 0.066732, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33137 - Train Loss: 0.066731, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33138 - Train Loss: 0.066730, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33139 - Train Loss: 0.066728, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33140 - Train Loss: 0.066727, Train Acc: 0.889744 | Val Loss: 0.108691, Val Acc: 0.773196\n",
      "Epoch 33141 - Train Loss: 0.066726, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33142 - Train Loss: 0.066725, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33143 - Train Loss: 0.066724, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33144 - Train Loss: 0.066723, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33145 - Train Loss: 0.066722, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33146 - Train Loss: 0.066721, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33147 - Train Loss: 0.066720, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33148 - Train Loss: 0.066719, Train Acc: 0.889744 | Val Loss: 0.108690, Val Acc: 0.773196\n",
      "Epoch 33149 - Train Loss: 0.066718, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33150 - Train Loss: 0.066717, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33151 - Train Loss: 0.066716, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33152 - Train Loss: 0.066715, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33153 - Train Loss: 0.066714, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33154 - Train Loss: 0.066713, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33155 - Train Loss: 0.066712, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33156 - Train Loss: 0.066711, Train Acc: 0.889744 | Val Loss: 0.108689, Val Acc: 0.773196\n",
      "Epoch 33157 - Train Loss: 0.066709, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33158 - Train Loss: 0.066708, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33159 - Train Loss: 0.066707, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33160 - Train Loss: 0.066706, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33161 - Train Loss: 0.066705, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33162 - Train Loss: 0.066704, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33163 - Train Loss: 0.066703, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33164 - Train Loss: 0.066702, Train Acc: 0.889744 | Val Loss: 0.108688, Val Acc: 0.773196\n",
      "Epoch 33165 - Train Loss: 0.066701, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33166 - Train Loss: 0.066700, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33167 - Train Loss: 0.066699, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33168 - Train Loss: 0.066698, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33169 - Train Loss: 0.066697, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33170 - Train Loss: 0.066696, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33171 - Train Loss: 0.066695, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33172 - Train Loss: 0.066694, Train Acc: 0.889744 | Val Loss: 0.108687, Val Acc: 0.773196\n",
      "Epoch 33173 - Train Loss: 0.066693, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33174 - Train Loss: 0.066691, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33175 - Train Loss: 0.066690, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33176 - Train Loss: 0.066689, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33177 - Train Loss: 0.066688, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33178 - Train Loss: 0.066687, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33179 - Train Loss: 0.066686, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33180 - Train Loss: 0.066685, Train Acc: 0.889744 | Val Loss: 0.108686, Val Acc: 0.773196\n",
      "Epoch 33181 - Train Loss: 0.066684, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33182 - Train Loss: 0.066683, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33183 - Train Loss: 0.066682, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33184 - Train Loss: 0.066681, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33185 - Train Loss: 0.066680, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33186 - Train Loss: 0.066679, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33187 - Train Loss: 0.066678, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33188 - Train Loss: 0.066677, Train Acc: 0.889744 | Val Loss: 0.108685, Val Acc: 0.773196\n",
      "Epoch 33189 - Train Loss: 0.066676, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33190 - Train Loss: 0.066675, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33191 - Train Loss: 0.066674, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33192 - Train Loss: 0.066672, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33193 - Train Loss: 0.066671, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33194 - Train Loss: 0.066670, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33195 - Train Loss: 0.066669, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33196 - Train Loss: 0.066668, Train Acc: 0.889744 | Val Loss: 0.108684, Val Acc: 0.773196\n",
      "Epoch 33197 - Train Loss: 0.066667, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33198 - Train Loss: 0.066666, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33199 - Train Loss: 0.066665, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33200 - Train Loss: 0.066664, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33201 - Train Loss: 0.066663, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33202 - Train Loss: 0.066662, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33203 - Train Loss: 0.066661, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33204 - Train Loss: 0.066660, Train Acc: 0.889744 | Val Loss: 0.108683, Val Acc: 0.773196\n",
      "Epoch 33205 - Train Loss: 0.066659, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33206 - Train Loss: 0.066658, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33207 - Train Loss: 0.066657, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33208 - Train Loss: 0.066656, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33209 - Train Loss: 0.066655, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33210 - Train Loss: 0.066653, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33211 - Train Loss: 0.066652, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33212 - Train Loss: 0.066651, Train Acc: 0.889744 | Val Loss: 0.108682, Val Acc: 0.773196\n",
      "Epoch 33213 - Train Loss: 0.066650, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33214 - Train Loss: 0.066649, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33215 - Train Loss: 0.066648, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33216 - Train Loss: 0.066647, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33217 - Train Loss: 0.066646, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33218 - Train Loss: 0.066645, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33219 - Train Loss: 0.066644, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33220 - Train Loss: 0.066643, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33221 - Train Loss: 0.066642, Train Acc: 0.889744 | Val Loss: 0.108681, Val Acc: 0.773196\n",
      "Epoch 33222 - Train Loss: 0.066641, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33223 - Train Loss: 0.066640, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33224 - Train Loss: 0.066639, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33225 - Train Loss: 0.066638, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33226 - Train Loss: 0.066637, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33227 - Train Loss: 0.066636, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33228 - Train Loss: 0.066634, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33229 - Train Loss: 0.066633, Train Acc: 0.889744 | Val Loss: 0.108680, Val Acc: 0.773196\n",
      "Epoch 33230 - Train Loss: 0.066632, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33231 - Train Loss: 0.066631, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33232 - Train Loss: 0.066630, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33233 - Train Loss: 0.066629, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33234 - Train Loss: 0.066628, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33235 - Train Loss: 0.066627, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33236 - Train Loss: 0.066626, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33237 - Train Loss: 0.066625, Train Acc: 0.889744 | Val Loss: 0.108679, Val Acc: 0.773196\n",
      "Epoch 33238 - Train Loss: 0.066624, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33239 - Train Loss: 0.066623, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33240 - Train Loss: 0.066622, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33241 - Train Loss: 0.066621, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33242 - Train Loss: 0.066620, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33243 - Train Loss: 0.066619, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33244 - Train Loss: 0.066618, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33245 - Train Loss: 0.066617, Train Acc: 0.889744 | Val Loss: 0.108678, Val Acc: 0.773196\n",
      "Epoch 33246 - Train Loss: 0.066615, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33247 - Train Loss: 0.066614, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33248 - Train Loss: 0.066613, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33249 - Train Loss: 0.066612, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33250 - Train Loss: 0.066611, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33251 - Train Loss: 0.066610, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33252 - Train Loss: 0.066609, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33253 - Train Loss: 0.066608, Train Acc: 0.889744 | Val Loss: 0.108677, Val Acc: 0.773196\n",
      "Epoch 33254 - Train Loss: 0.066607, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33255 - Train Loss: 0.066606, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33256 - Train Loss: 0.066605, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33257 - Train Loss: 0.066604, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33258 - Train Loss: 0.066603, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33259 - Train Loss: 0.066602, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33260 - Train Loss: 0.066601, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33261 - Train Loss: 0.066600, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33262 - Train Loss: 0.066599, Train Acc: 0.889744 | Val Loss: 0.108676, Val Acc: 0.773196\n",
      "Epoch 33263 - Train Loss: 0.066598, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33264 - Train Loss: 0.066597, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33265 - Train Loss: 0.066595, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33266 - Train Loss: 0.066594, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33267 - Train Loss: 0.066593, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33268 - Train Loss: 0.066592, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33269 - Train Loss: 0.066591, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33270 - Train Loss: 0.066590, Train Acc: 0.889744 | Val Loss: 0.108675, Val Acc: 0.773196\n",
      "Epoch 33271 - Train Loss: 0.066589, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33272 - Train Loss: 0.066588, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33273 - Train Loss: 0.066587, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33274 - Train Loss: 0.066586, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33275 - Train Loss: 0.066585, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33276 - Train Loss: 0.066584, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33277 - Train Loss: 0.066583, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33278 - Train Loss: 0.066582, Train Acc: 0.889744 | Val Loss: 0.108674, Val Acc: 0.773196\n",
      "Epoch 33279 - Train Loss: 0.066581, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33280 - Train Loss: 0.066580, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33281 - Train Loss: 0.066579, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33282 - Train Loss: 0.066578, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33283 - Train Loss: 0.066577, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33284 - Train Loss: 0.066575, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33285 - Train Loss: 0.066574, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33286 - Train Loss: 0.066573, Train Acc: 0.889744 | Val Loss: 0.108673, Val Acc: 0.773196\n",
      "Epoch 33287 - Train Loss: 0.066572, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33288 - Train Loss: 0.066571, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33289 - Train Loss: 0.066570, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33290 - Train Loss: 0.066569, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33291 - Train Loss: 0.066568, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33292 - Train Loss: 0.066567, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33293 - Train Loss: 0.066566, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33294 - Train Loss: 0.066565, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33295 - Train Loss: 0.066564, Train Acc: 0.889744 | Val Loss: 0.108672, Val Acc: 0.773196\n",
      "Epoch 33296 - Train Loss: 0.066563, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33297 - Train Loss: 0.066562, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33298 - Train Loss: 0.066561, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33299 - Train Loss: 0.066560, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33300 - Train Loss: 0.066559, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33301 - Train Loss: 0.066558, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33302 - Train Loss: 0.066557, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33303 - Train Loss: 0.066556, Train Acc: 0.889744 | Val Loss: 0.108671, Val Acc: 0.773196\n",
      "Epoch 33304 - Train Loss: 0.066554, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33305 - Train Loss: 0.066553, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33306 - Train Loss: 0.066552, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33307 - Train Loss: 0.066551, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33308 - Train Loss: 0.066550, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33309 - Train Loss: 0.066549, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33310 - Train Loss: 0.066548, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33311 - Train Loss: 0.066547, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33312 - Train Loss: 0.066546, Train Acc: 0.889744 | Val Loss: 0.108670, Val Acc: 0.773196\n",
      "Epoch 33313 - Train Loss: 0.066545, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33314 - Train Loss: 0.066544, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33315 - Train Loss: 0.066543, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33316 - Train Loss: 0.066542, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33317 - Train Loss: 0.066541, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33318 - Train Loss: 0.066540, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33319 - Train Loss: 0.066539, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33320 - Train Loss: 0.066538, Train Acc: 0.889744 | Val Loss: 0.108669, Val Acc: 0.773196\n",
      "Epoch 33321 - Train Loss: 0.066537, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33322 - Train Loss: 0.066536, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33323 - Train Loss: 0.066534, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33324 - Train Loss: 0.066533, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33325 - Train Loss: 0.066532, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33326 - Train Loss: 0.066531, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33327 - Train Loss: 0.066530, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33328 - Train Loss: 0.066529, Train Acc: 0.889744 | Val Loss: 0.108668, Val Acc: 0.773196\n",
      "Epoch 33329 - Train Loss: 0.066528, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33330 - Train Loss: 0.066527, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33331 - Train Loss: 0.066526, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33332 - Train Loss: 0.066525, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33333 - Train Loss: 0.066524, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33334 - Train Loss: 0.066523, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33335 - Train Loss: 0.066522, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33336 - Train Loss: 0.066521, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33337 - Train Loss: 0.066520, Train Acc: 0.889744 | Val Loss: 0.108667, Val Acc: 0.773196\n",
      "Epoch 33338 - Train Loss: 0.066519, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33339 - Train Loss: 0.066518, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33340 - Train Loss: 0.066517, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33341 - Train Loss: 0.066516, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33342 - Train Loss: 0.066515, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33343 - Train Loss: 0.066513, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33344 - Train Loss: 0.066512, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33345 - Train Loss: 0.066511, Train Acc: 0.889744 | Val Loss: 0.108666, Val Acc: 0.773196\n",
      "Epoch 33346 - Train Loss: 0.066510, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33347 - Train Loss: 0.066509, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33348 - Train Loss: 0.066508, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33349 - Train Loss: 0.066507, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33350 - Train Loss: 0.066506, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33351 - Train Loss: 0.066505, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33352 - Train Loss: 0.066504, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33353 - Train Loss: 0.066503, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33354 - Train Loss: 0.066502, Train Acc: 0.889744 | Val Loss: 0.108665, Val Acc: 0.773196\n",
      "Epoch 33355 - Train Loss: 0.066501, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33356 - Train Loss: 0.066500, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33357 - Train Loss: 0.066499, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33358 - Train Loss: 0.066498, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33359 - Train Loss: 0.066497, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33360 - Train Loss: 0.066496, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33361 - Train Loss: 0.066495, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33362 - Train Loss: 0.066494, Train Acc: 0.889744 | Val Loss: 0.108664, Val Acc: 0.773196\n",
      "Epoch 33363 - Train Loss: 0.066493, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33364 - Train Loss: 0.066491, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33365 - Train Loss: 0.066490, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33366 - Train Loss: 0.066489, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33367 - Train Loss: 0.066488, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33368 - Train Loss: 0.066487, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33369 - Train Loss: 0.066486, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33370 - Train Loss: 0.066485, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33371 - Train Loss: 0.066484, Train Acc: 0.889744 | Val Loss: 0.108663, Val Acc: 0.773196\n",
      "Epoch 33372 - Train Loss: 0.066483, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33373 - Train Loss: 0.066482, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33374 - Train Loss: 0.066481, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33375 - Train Loss: 0.066480, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33376 - Train Loss: 0.066479, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33377 - Train Loss: 0.066478, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33378 - Train Loss: 0.066477, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33379 - Train Loss: 0.066476, Train Acc: 0.889744 | Val Loss: 0.108662, Val Acc: 0.773196\n",
      "Epoch 33380 - Train Loss: 0.066475, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33381 - Train Loss: 0.066474, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33382 - Train Loss: 0.066473, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33383 - Train Loss: 0.066472, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33384 - Train Loss: 0.066471, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33385 - Train Loss: 0.066469, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33386 - Train Loss: 0.066468, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33387 - Train Loss: 0.066467, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33388 - Train Loss: 0.066466, Train Acc: 0.889744 | Val Loss: 0.108661, Val Acc: 0.773196\n",
      "Epoch 33389 - Train Loss: 0.066465, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33390 - Train Loss: 0.066464, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33391 - Train Loss: 0.066463, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33392 - Train Loss: 0.066462, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33393 - Train Loss: 0.066461, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33394 - Train Loss: 0.066460, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33395 - Train Loss: 0.066459, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33396 - Train Loss: 0.066458, Train Acc: 0.889744 | Val Loss: 0.108660, Val Acc: 0.773196\n",
      "Epoch 33397 - Train Loss: 0.066457, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33398 - Train Loss: 0.066456, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33399 - Train Loss: 0.066455, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33400 - Train Loss: 0.066454, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33401 - Train Loss: 0.066453, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33402 - Train Loss: 0.066452, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33403 - Train Loss: 0.066451, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33404 - Train Loss: 0.066450, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33405 - Train Loss: 0.066449, Train Acc: 0.889744 | Val Loss: 0.108659, Val Acc: 0.773196\n",
      "Epoch 33406 - Train Loss: 0.066447, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33407 - Train Loss: 0.066446, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33408 - Train Loss: 0.066445, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33409 - Train Loss: 0.066444, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33410 - Train Loss: 0.066443, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33411 - Train Loss: 0.066442, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33412 - Train Loss: 0.066441, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33413 - Train Loss: 0.066440, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33414 - Train Loss: 0.066439, Train Acc: 0.889744 | Val Loss: 0.108658, Val Acc: 0.773196\n",
      "Epoch 33415 - Train Loss: 0.066438, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33416 - Train Loss: 0.066437, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33417 - Train Loss: 0.066436, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33418 - Train Loss: 0.066435, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33419 - Train Loss: 0.066434, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33420 - Train Loss: 0.066433, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33421 - Train Loss: 0.066432, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33422 - Train Loss: 0.066431, Train Acc: 0.889744 | Val Loss: 0.108657, Val Acc: 0.773196\n",
      "Epoch 33423 - Train Loss: 0.066430, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33424 - Train Loss: 0.066429, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33425 - Train Loss: 0.066428, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33426 - Train Loss: 0.066427, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33427 - Train Loss: 0.066425, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33428 - Train Loss: 0.066424, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33429 - Train Loss: 0.066423, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33430 - Train Loss: 0.066422, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33431 - Train Loss: 0.066421, Train Acc: 0.889744 | Val Loss: 0.108656, Val Acc: 0.773196\n",
      "Epoch 33432 - Train Loss: 0.066420, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33433 - Train Loss: 0.066419, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33434 - Train Loss: 0.066418, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33435 - Train Loss: 0.066417, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33436 - Train Loss: 0.066416, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33437 - Train Loss: 0.066415, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33438 - Train Loss: 0.066414, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33439 - Train Loss: 0.066413, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33440 - Train Loss: 0.066412, Train Acc: 0.889744 | Val Loss: 0.108655, Val Acc: 0.773196\n",
      "Epoch 33441 - Train Loss: 0.066411, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33442 - Train Loss: 0.066410, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33443 - Train Loss: 0.066409, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33444 - Train Loss: 0.066408, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33445 - Train Loss: 0.066407, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33446 - Train Loss: 0.066406, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33447 - Train Loss: 0.066405, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33448 - Train Loss: 0.066404, Train Acc: 0.889744 | Val Loss: 0.108654, Val Acc: 0.773196\n",
      "Epoch 33449 - Train Loss: 0.066403, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33450 - Train Loss: 0.066401, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33451 - Train Loss: 0.066400, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33452 - Train Loss: 0.066399, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33453 - Train Loss: 0.066398, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33454 - Train Loss: 0.066397, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33455 - Train Loss: 0.066396, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33456 - Train Loss: 0.066395, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33457 - Train Loss: 0.066394, Train Acc: 0.889744 | Val Loss: 0.108653, Val Acc: 0.773196\n",
      "Epoch 33458 - Train Loss: 0.066393, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33459 - Train Loss: 0.066392, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33460 - Train Loss: 0.066391, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33461 - Train Loss: 0.066390, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33462 - Train Loss: 0.066389, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33463 - Train Loss: 0.066388, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33464 - Train Loss: 0.066387, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33465 - Train Loss: 0.066386, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33466 - Train Loss: 0.066385, Train Acc: 0.889744 | Val Loss: 0.108652, Val Acc: 0.773196\n",
      "Epoch 33467 - Train Loss: 0.066384, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33468 - Train Loss: 0.066383, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33469 - Train Loss: 0.066382, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33470 - Train Loss: 0.066381, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33471 - Train Loss: 0.066380, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33472 - Train Loss: 0.066378, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33473 - Train Loss: 0.066377, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33474 - Train Loss: 0.066376, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33475 - Train Loss: 0.066375, Train Acc: 0.889744 | Val Loss: 0.108651, Val Acc: 0.773196\n",
      "Epoch 33476 - Train Loss: 0.066374, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33477 - Train Loss: 0.066373, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33478 - Train Loss: 0.066372, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33479 - Train Loss: 0.066371, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33480 - Train Loss: 0.066370, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33481 - Train Loss: 0.066369, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33482 - Train Loss: 0.066368, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33483 - Train Loss: 0.066367, Train Acc: 0.889744 | Val Loss: 0.108650, Val Acc: 0.773196\n",
      "Epoch 33484 - Train Loss: 0.066366, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33485 - Train Loss: 0.066365, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33486 - Train Loss: 0.066364, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33487 - Train Loss: 0.066363, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33488 - Train Loss: 0.066362, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33489 - Train Loss: 0.066361, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33490 - Train Loss: 0.066360, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33491 - Train Loss: 0.066359, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33492 - Train Loss: 0.066358, Train Acc: 0.889744 | Val Loss: 0.108649, Val Acc: 0.773196\n",
      "Epoch 33493 - Train Loss: 0.066357, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33494 - Train Loss: 0.066356, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33495 - Train Loss: 0.066354, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33496 - Train Loss: 0.066353, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33497 - Train Loss: 0.066352, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33498 - Train Loss: 0.066351, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33499 - Train Loss: 0.066350, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33500 - Train Loss: 0.066349, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33501 - Train Loss: 0.066348, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.773196\n",
      "Epoch 33502 - Train Loss: 0.066347, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33503 - Train Loss: 0.066346, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33504 - Train Loss: 0.066345, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33505 - Train Loss: 0.066344, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33506 - Train Loss: 0.066343, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33507 - Train Loss: 0.066342, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33508 - Train Loss: 0.066341, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33509 - Train Loss: 0.066340, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33510 - Train Loss: 0.066339, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.773196\n",
      "Epoch 33511 - Train Loss: 0.066338, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33512 - Train Loss: 0.066337, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33513 - Train Loss: 0.066336, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33514 - Train Loss: 0.066335, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33515 - Train Loss: 0.066334, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33516 - Train Loss: 0.066333, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33517 - Train Loss: 0.066332, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33518 - Train Loss: 0.066331, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33519 - Train Loss: 0.066329, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.773196\n",
      "Epoch 33520 - Train Loss: 0.066328, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33521 - Train Loss: 0.066327, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33522 - Train Loss: 0.066326, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33523 - Train Loss: 0.066325, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33524 - Train Loss: 0.066324, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33525 - Train Loss: 0.066323, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33526 - Train Loss: 0.066322, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33527 - Train Loss: 0.066321, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33528 - Train Loss: 0.066320, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.773196\n",
      "Epoch 33529 - Train Loss: 0.066319, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33530 - Train Loss: 0.066318, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33531 - Train Loss: 0.066317, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33532 - Train Loss: 0.066316, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33533 - Train Loss: 0.066315, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33534 - Train Loss: 0.066314, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33535 - Train Loss: 0.066313, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33536 - Train Loss: 0.066312, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33537 - Train Loss: 0.066311, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.773196\n",
      "Epoch 33538 - Train Loss: 0.066310, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33539 - Train Loss: 0.066309, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33540 - Train Loss: 0.066308, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33541 - Train Loss: 0.066307, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33542 - Train Loss: 0.066306, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33543 - Train Loss: 0.066304, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33544 - Train Loss: 0.066303, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33545 - Train Loss: 0.066302, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33546 - Train Loss: 0.066301, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.773196\n",
      "Epoch 33547 - Train Loss: 0.066300, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33548 - Train Loss: 0.066299, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33549 - Train Loss: 0.066298, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33550 - Train Loss: 0.066297, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33551 - Train Loss: 0.066296, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33552 - Train Loss: 0.066295, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33553 - Train Loss: 0.066294, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33554 - Train Loss: 0.066293, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33555 - Train Loss: 0.066292, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.773196\n",
      "Epoch 33556 - Train Loss: 0.066291, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33557 - Train Loss: 0.066290, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33558 - Train Loss: 0.066289, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33559 - Train Loss: 0.066288, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33560 - Train Loss: 0.066287, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33561 - Train Loss: 0.066286, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33562 - Train Loss: 0.066285, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33563 - Train Loss: 0.066284, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33564 - Train Loss: 0.066283, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.773196\n",
      "Epoch 33565 - Train Loss: 0.066282, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33566 - Train Loss: 0.066281, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33567 - Train Loss: 0.066280, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33568 - Train Loss: 0.066278, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33569 - Train Loss: 0.066277, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33570 - Train Loss: 0.066276, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33571 - Train Loss: 0.066275, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33572 - Train Loss: 0.066274, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33573 - Train Loss: 0.066273, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.773196\n",
      "Epoch 33574 - Train Loss: 0.066272, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33575 - Train Loss: 0.066271, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33576 - Train Loss: 0.066270, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33577 - Train Loss: 0.066269, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33578 - Train Loss: 0.066268, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33579 - Train Loss: 0.066267, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33580 - Train Loss: 0.066266, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33581 - Train Loss: 0.066265, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33582 - Train Loss: 0.066264, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.773196\n",
      "Epoch 33583 - Train Loss: 0.066263, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33584 - Train Loss: 0.066262, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33585 - Train Loss: 0.066261, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33586 - Train Loss: 0.066260, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33587 - Train Loss: 0.066259, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33588 - Train Loss: 0.066258, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33589 - Train Loss: 0.066257, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33590 - Train Loss: 0.066256, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33591 - Train Loss: 0.066255, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.773196\n",
      "Epoch 33592 - Train Loss: 0.066254, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33593 - Train Loss: 0.066253, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33594 - Train Loss: 0.066251, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33595 - Train Loss: 0.066250, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33596 - Train Loss: 0.066249, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33597 - Train Loss: 0.066248, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33598 - Train Loss: 0.066247, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33599 - Train Loss: 0.066246, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33600 - Train Loss: 0.066245, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.773196\n",
      "Epoch 33601 - Train Loss: 0.066244, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33602 - Train Loss: 0.066243, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33603 - Train Loss: 0.066242, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33604 - Train Loss: 0.066241, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33605 - Train Loss: 0.066240, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33606 - Train Loss: 0.066239, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33607 - Train Loss: 0.066238, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33608 - Train Loss: 0.066237, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33609 - Train Loss: 0.066236, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.773196\n",
      "Epoch 33610 - Train Loss: 0.066235, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33611 - Train Loss: 0.066234, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33612 - Train Loss: 0.066233, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33613 - Train Loss: 0.066232, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33614 - Train Loss: 0.066231, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33615 - Train Loss: 0.066230, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33616 - Train Loss: 0.066229, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33617 - Train Loss: 0.066228, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33618 - Train Loss: 0.066227, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.773196\n",
      "Epoch 33619 - Train Loss: 0.066226, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33620 - Train Loss: 0.066224, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33621 - Train Loss: 0.066223, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33622 - Train Loss: 0.066222, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33623 - Train Loss: 0.066221, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33624 - Train Loss: 0.066220, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33625 - Train Loss: 0.066219, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33626 - Train Loss: 0.066218, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33627 - Train Loss: 0.066217, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33628 - Train Loss: 0.066216, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.773196\n",
      "Epoch 33629 - Train Loss: 0.066215, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33630 - Train Loss: 0.066214, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33631 - Train Loss: 0.066213, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33632 - Train Loss: 0.066212, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33633 - Train Loss: 0.066211, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33634 - Train Loss: 0.066210, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33635 - Train Loss: 0.066209, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33636 - Train Loss: 0.066208, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33637 - Train Loss: 0.066207, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.773196\n",
      "Epoch 33638 - Train Loss: 0.066206, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33639 - Train Loss: 0.066205, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33640 - Train Loss: 0.066204, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33641 - Train Loss: 0.066203, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33642 - Train Loss: 0.066202, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33643 - Train Loss: 0.066201, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33644 - Train Loss: 0.066200, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33645 - Train Loss: 0.066199, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33646 - Train Loss: 0.066198, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.773196\n",
      "Epoch 33647 - Train Loss: 0.066197, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33648 - Train Loss: 0.066195, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33649 - Train Loss: 0.066194, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33650 - Train Loss: 0.066193, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33651 - Train Loss: 0.066192, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33652 - Train Loss: 0.066191, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33653 - Train Loss: 0.066190, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33654 - Train Loss: 0.066189, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33655 - Train Loss: 0.066188, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.773196\n",
      "Epoch 33656 - Train Loss: 0.066187, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33657 - Train Loss: 0.066186, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33658 - Train Loss: 0.066185, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33659 - Train Loss: 0.066184, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33660 - Train Loss: 0.066183, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33661 - Train Loss: 0.066182, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33662 - Train Loss: 0.066181, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33663 - Train Loss: 0.066180, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33664 - Train Loss: 0.066179, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33665 - Train Loss: 0.066178, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.773196\n",
      "Epoch 33666 - Train Loss: 0.066177, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33667 - Train Loss: 0.066176, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33668 - Train Loss: 0.066175, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33669 - Train Loss: 0.066174, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33670 - Train Loss: 0.066173, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33671 - Train Loss: 0.066172, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33672 - Train Loss: 0.066171, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33673 - Train Loss: 0.066170, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33674 - Train Loss: 0.066169, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.773196\n",
      "Epoch 33675 - Train Loss: 0.066168, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33676 - Train Loss: 0.066166, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33677 - Train Loss: 0.066165, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33678 - Train Loss: 0.066164, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33679 - Train Loss: 0.066163, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33680 - Train Loss: 0.066162, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33681 - Train Loss: 0.066161, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33682 - Train Loss: 0.066160, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33683 - Train Loss: 0.066159, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.773196\n",
      "Epoch 33684 - Train Loss: 0.066158, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33685 - Train Loss: 0.066157, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33686 - Train Loss: 0.066156, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33687 - Train Loss: 0.066155, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33688 - Train Loss: 0.066154, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33689 - Train Loss: 0.066153, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33690 - Train Loss: 0.066152, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33691 - Train Loss: 0.066151, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33692 - Train Loss: 0.066150, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33693 - Train Loss: 0.066149, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.773196\n",
      "Epoch 33694 - Train Loss: 0.066148, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33695 - Train Loss: 0.066147, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33696 - Train Loss: 0.066146, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33697 - Train Loss: 0.066145, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33698 - Train Loss: 0.066144, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33699 - Train Loss: 0.066143, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33700 - Train Loss: 0.066142, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33701 - Train Loss: 0.066141, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33702 - Train Loss: 0.066140, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.773196\n",
      "Epoch 33703 - Train Loss: 0.066139, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33704 - Train Loss: 0.066138, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33705 - Train Loss: 0.066136, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33706 - Train Loss: 0.066135, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33707 - Train Loss: 0.066134, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33708 - Train Loss: 0.066133, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33709 - Train Loss: 0.066132, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33710 - Train Loss: 0.066131, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33711 - Train Loss: 0.066130, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.773196\n",
      "Epoch 33712 - Train Loss: 0.066129, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33713 - Train Loss: 0.066128, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33714 - Train Loss: 0.066127, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33715 - Train Loss: 0.066126, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33716 - Train Loss: 0.066125, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33717 - Train Loss: 0.066124, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33718 - Train Loss: 0.066123, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33719 - Train Loss: 0.066122, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33720 - Train Loss: 0.066121, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33721 - Train Loss: 0.066120, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.773196\n",
      "Epoch 33722 - Train Loss: 0.066119, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33723 - Train Loss: 0.066118, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33724 - Train Loss: 0.066117, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33725 - Train Loss: 0.066116, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33726 - Train Loss: 0.066115, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33727 - Train Loss: 0.066114, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33728 - Train Loss: 0.066113, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33729 - Train Loss: 0.066112, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33730 - Train Loss: 0.066111, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.773196\n",
      "Epoch 33731 - Train Loss: 0.066110, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33732 - Train Loss: 0.066109, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33733 - Train Loss: 0.066108, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33734 - Train Loss: 0.066107, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33735 - Train Loss: 0.066105, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33736 - Train Loss: 0.066104, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33737 - Train Loss: 0.066103, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33738 - Train Loss: 0.066102, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33739 - Train Loss: 0.066101, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33740 - Train Loss: 0.066100, Train Acc: 0.891026 | Val Loss: 0.108622, Val Acc: 0.773196\n",
      "Epoch 33741 - Train Loss: 0.066099, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33742 - Train Loss: 0.066098, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33743 - Train Loss: 0.066097, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33744 - Train Loss: 0.066096, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33745 - Train Loss: 0.066095, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33746 - Train Loss: 0.066094, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33747 - Train Loss: 0.066093, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33748 - Train Loss: 0.066092, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33749 - Train Loss: 0.066091, Train Acc: 0.891026 | Val Loss: 0.108621, Val Acc: 0.773196\n",
      "Epoch 33750 - Train Loss: 0.066090, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33751 - Train Loss: 0.066089, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33752 - Train Loss: 0.066088, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33753 - Train Loss: 0.066087, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33754 - Train Loss: 0.066086, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33755 - Train Loss: 0.066085, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33756 - Train Loss: 0.066084, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33757 - Train Loss: 0.066083, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33758 - Train Loss: 0.066082, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33759 - Train Loss: 0.066081, Train Acc: 0.891026 | Val Loss: 0.108620, Val Acc: 0.773196\n",
      "Epoch 33760 - Train Loss: 0.066080, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33761 - Train Loss: 0.066079, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33762 - Train Loss: 0.066078, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33763 - Train Loss: 0.066077, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33764 - Train Loss: 0.066076, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33765 - Train Loss: 0.066075, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33766 - Train Loss: 0.066074, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33767 - Train Loss: 0.066072, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33768 - Train Loss: 0.066071, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33769 - Train Loss: 0.066070, Train Acc: 0.891026 | Val Loss: 0.108619, Val Acc: 0.773196\n",
      "Epoch 33770 - Train Loss: 0.066069, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33771 - Train Loss: 0.066068, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33772 - Train Loss: 0.066067, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33773 - Train Loss: 0.066066, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33774 - Train Loss: 0.066065, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33775 - Train Loss: 0.066064, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33776 - Train Loss: 0.066063, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33777 - Train Loss: 0.066062, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33778 - Train Loss: 0.066061, Train Acc: 0.891026 | Val Loss: 0.108618, Val Acc: 0.773196\n",
      "Epoch 33779 - Train Loss: 0.066060, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33780 - Train Loss: 0.066059, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33781 - Train Loss: 0.066058, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33782 - Train Loss: 0.066057, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33783 - Train Loss: 0.066056, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33784 - Train Loss: 0.066055, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33785 - Train Loss: 0.066054, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33786 - Train Loss: 0.066053, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33787 - Train Loss: 0.066052, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33788 - Train Loss: 0.066051, Train Acc: 0.891026 | Val Loss: 0.108617, Val Acc: 0.773196\n",
      "Epoch 33789 - Train Loss: 0.066050, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33790 - Train Loss: 0.066049, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33791 - Train Loss: 0.066048, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33792 - Train Loss: 0.066047, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33793 - Train Loss: 0.066046, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33794 - Train Loss: 0.066045, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33795 - Train Loss: 0.066044, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33796 - Train Loss: 0.066043, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33797 - Train Loss: 0.066042, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33798 - Train Loss: 0.066041, Train Acc: 0.891026 | Val Loss: 0.108616, Val Acc: 0.773196\n",
      "Epoch 33799 - Train Loss: 0.066040, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33800 - Train Loss: 0.066038, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33801 - Train Loss: 0.066037, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33802 - Train Loss: 0.066036, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33803 - Train Loss: 0.066035, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33804 - Train Loss: 0.066034, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33805 - Train Loss: 0.066033, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33806 - Train Loss: 0.066032, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33807 - Train Loss: 0.066031, Train Acc: 0.891026 | Val Loss: 0.108615, Val Acc: 0.773196\n",
      "Epoch 33808 - Train Loss: 0.066030, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33809 - Train Loss: 0.066029, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33810 - Train Loss: 0.066028, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33811 - Train Loss: 0.066027, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33812 - Train Loss: 0.066026, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33813 - Train Loss: 0.066025, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33814 - Train Loss: 0.066024, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33815 - Train Loss: 0.066023, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33816 - Train Loss: 0.066022, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33817 - Train Loss: 0.066021, Train Acc: 0.891026 | Val Loss: 0.108614, Val Acc: 0.773196\n",
      "Epoch 33818 - Train Loss: 0.066020, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33819 - Train Loss: 0.066019, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33820 - Train Loss: 0.066018, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33821 - Train Loss: 0.066017, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33822 - Train Loss: 0.066016, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33823 - Train Loss: 0.066015, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33824 - Train Loss: 0.066014, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33825 - Train Loss: 0.066013, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33826 - Train Loss: 0.066012, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33827 - Train Loss: 0.066011, Train Acc: 0.891026 | Val Loss: 0.108613, Val Acc: 0.773196\n",
      "Epoch 33828 - Train Loss: 0.066010, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33829 - Train Loss: 0.066009, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33830 - Train Loss: 0.066008, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33831 - Train Loss: 0.066007, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33832 - Train Loss: 0.066006, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33833 - Train Loss: 0.066005, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33834 - Train Loss: 0.066004, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33835 - Train Loss: 0.066002, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33836 - Train Loss: 0.066001, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33837 - Train Loss: 0.066000, Train Acc: 0.891026 | Val Loss: 0.108612, Val Acc: 0.773196\n",
      "Epoch 33838 - Train Loss: 0.065999, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33839 - Train Loss: 0.065998, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33840 - Train Loss: 0.065997, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33841 - Train Loss: 0.065996, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33842 - Train Loss: 0.065995, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33843 - Train Loss: 0.065994, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33844 - Train Loss: 0.065993, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33845 - Train Loss: 0.065992, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33846 - Train Loss: 0.065991, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33847 - Train Loss: 0.065990, Train Acc: 0.891026 | Val Loss: 0.108611, Val Acc: 0.773196\n",
      "Epoch 33848 - Train Loss: 0.065989, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33849 - Train Loss: 0.065988, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33850 - Train Loss: 0.065987, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33851 - Train Loss: 0.065986, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33852 - Train Loss: 0.065985, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33853 - Train Loss: 0.065984, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33854 - Train Loss: 0.065983, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33855 - Train Loss: 0.065982, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33856 - Train Loss: 0.065981, Train Acc: 0.891026 | Val Loss: 0.108610, Val Acc: 0.773196\n",
      "Epoch 33857 - Train Loss: 0.065980, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33858 - Train Loss: 0.065979, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33859 - Train Loss: 0.065978, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33860 - Train Loss: 0.065977, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33861 - Train Loss: 0.065976, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33862 - Train Loss: 0.065975, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33863 - Train Loss: 0.065974, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33864 - Train Loss: 0.065973, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33865 - Train Loss: 0.065972, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33866 - Train Loss: 0.065971, Train Acc: 0.891026 | Val Loss: 0.108609, Val Acc: 0.773196\n",
      "Epoch 33867 - Train Loss: 0.065970, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33868 - Train Loss: 0.065969, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33869 - Train Loss: 0.065968, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33870 - Train Loss: 0.065967, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33871 - Train Loss: 0.065965, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33872 - Train Loss: 0.065964, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33873 - Train Loss: 0.065963, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33874 - Train Loss: 0.065962, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33875 - Train Loss: 0.065961, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33876 - Train Loss: 0.065960, Train Acc: 0.891026 | Val Loss: 0.108608, Val Acc: 0.773196\n",
      "Epoch 33877 - Train Loss: 0.065959, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33878 - Train Loss: 0.065958, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33879 - Train Loss: 0.065957, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33880 - Train Loss: 0.065956, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33881 - Train Loss: 0.065955, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33882 - Train Loss: 0.065954, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33883 - Train Loss: 0.065953, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33884 - Train Loss: 0.065952, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33885 - Train Loss: 0.065951, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33886 - Train Loss: 0.065950, Train Acc: 0.891026 | Val Loss: 0.108607, Val Acc: 0.773196\n",
      "Epoch 33887 - Train Loss: 0.065949, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33888 - Train Loss: 0.065948, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33889 - Train Loss: 0.065947, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33890 - Train Loss: 0.065946, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33891 - Train Loss: 0.065945, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33892 - Train Loss: 0.065944, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33893 - Train Loss: 0.065943, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33894 - Train Loss: 0.065942, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33895 - Train Loss: 0.065941, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33896 - Train Loss: 0.065940, Train Acc: 0.891026 | Val Loss: 0.108606, Val Acc: 0.773196\n",
      "Epoch 33897 - Train Loss: 0.065939, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33898 - Train Loss: 0.065938, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33899 - Train Loss: 0.065937, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33900 - Train Loss: 0.065936, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33901 - Train Loss: 0.065935, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33902 - Train Loss: 0.065934, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33903 - Train Loss: 0.065933, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33904 - Train Loss: 0.065932, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33905 - Train Loss: 0.065931, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33906 - Train Loss: 0.065930, Train Acc: 0.891026 | Val Loss: 0.108605, Val Acc: 0.773196\n",
      "Epoch 33907 - Train Loss: 0.065929, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33908 - Train Loss: 0.065928, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33909 - Train Loss: 0.065927, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33910 - Train Loss: 0.065925, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33911 - Train Loss: 0.065924, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33912 - Train Loss: 0.065923, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33913 - Train Loss: 0.065922, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33914 - Train Loss: 0.065921, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33915 - Train Loss: 0.065920, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33916 - Train Loss: 0.065919, Train Acc: 0.891026 | Val Loss: 0.108604, Val Acc: 0.773196\n",
      "Epoch 33917 - Train Loss: 0.065918, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33918 - Train Loss: 0.065917, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33919 - Train Loss: 0.065916, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33920 - Train Loss: 0.065915, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33921 - Train Loss: 0.065914, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33922 - Train Loss: 0.065913, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33923 - Train Loss: 0.065912, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33924 - Train Loss: 0.065911, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33925 - Train Loss: 0.065910, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33926 - Train Loss: 0.065909, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33927 - Train Loss: 0.065908, Train Acc: 0.891026 | Val Loss: 0.108603, Val Acc: 0.773196\n",
      "Epoch 33928 - Train Loss: 0.065907, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33929 - Train Loss: 0.065906, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33930 - Train Loss: 0.065905, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33931 - Train Loss: 0.065904, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33932 - Train Loss: 0.065903, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33933 - Train Loss: 0.065902, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33934 - Train Loss: 0.065901, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33935 - Train Loss: 0.065900, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33936 - Train Loss: 0.065899, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33937 - Train Loss: 0.065898, Train Acc: 0.891026 | Val Loss: 0.108602, Val Acc: 0.773196\n",
      "Epoch 33938 - Train Loss: 0.065897, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33939 - Train Loss: 0.065896, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33940 - Train Loss: 0.065895, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33941 - Train Loss: 0.065894, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33942 - Train Loss: 0.065893, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33943 - Train Loss: 0.065892, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33944 - Train Loss: 0.065891, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33945 - Train Loss: 0.065890, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33946 - Train Loss: 0.065889, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33947 - Train Loss: 0.065888, Train Acc: 0.891026 | Val Loss: 0.108601, Val Acc: 0.773196\n",
      "Epoch 33948 - Train Loss: 0.065887, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33949 - Train Loss: 0.065886, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33950 - Train Loss: 0.065885, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33951 - Train Loss: 0.065884, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33952 - Train Loss: 0.065882, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33953 - Train Loss: 0.065881, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33954 - Train Loss: 0.065880, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33955 - Train Loss: 0.065879, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33956 - Train Loss: 0.065878, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33957 - Train Loss: 0.065877, Train Acc: 0.891026 | Val Loss: 0.108600, Val Acc: 0.773196\n",
      "Epoch 33958 - Train Loss: 0.065876, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33959 - Train Loss: 0.065875, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33960 - Train Loss: 0.065874, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33961 - Train Loss: 0.065873, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33962 - Train Loss: 0.065872, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33963 - Train Loss: 0.065871, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33964 - Train Loss: 0.065870, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33965 - Train Loss: 0.065869, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33966 - Train Loss: 0.065868, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33967 - Train Loss: 0.065867, Train Acc: 0.891026 | Val Loss: 0.108599, Val Acc: 0.773196\n",
      "Epoch 33968 - Train Loss: 0.065866, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33969 - Train Loss: 0.065865, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33970 - Train Loss: 0.065864, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33971 - Train Loss: 0.065863, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33972 - Train Loss: 0.065862, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33973 - Train Loss: 0.065861, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33974 - Train Loss: 0.065860, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33975 - Train Loss: 0.065859, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33976 - Train Loss: 0.065858, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33977 - Train Loss: 0.065857, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33978 - Train Loss: 0.065856, Train Acc: 0.891026 | Val Loss: 0.108598, Val Acc: 0.773196\n",
      "Epoch 33979 - Train Loss: 0.065855, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33980 - Train Loss: 0.065854, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33981 - Train Loss: 0.065853, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33982 - Train Loss: 0.065852, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33983 - Train Loss: 0.065851, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33984 - Train Loss: 0.065850, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33985 - Train Loss: 0.065849, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33986 - Train Loss: 0.065848, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33987 - Train Loss: 0.065847, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33988 - Train Loss: 0.065846, Train Acc: 0.891026 | Val Loss: 0.108597, Val Acc: 0.773196\n",
      "Epoch 33989 - Train Loss: 0.065845, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33990 - Train Loss: 0.065844, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33991 - Train Loss: 0.065843, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33992 - Train Loss: 0.065842, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33993 - Train Loss: 0.065841, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33994 - Train Loss: 0.065840, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33995 - Train Loss: 0.065839, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33996 - Train Loss: 0.065838, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33997 - Train Loss: 0.065836, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33998 - Train Loss: 0.065835, Train Acc: 0.891026 | Val Loss: 0.108596, Val Acc: 0.773196\n",
      "Epoch 33999 - Train Loss: 0.065834, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34000 - Train Loss: 0.065833, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34001 - Train Loss: 0.065832, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34002 - Train Loss: 0.065831, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34003 - Train Loss: 0.065830, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34004 - Train Loss: 0.065829, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34005 - Train Loss: 0.065828, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34006 - Train Loss: 0.065827, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34007 - Train Loss: 0.065826, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34008 - Train Loss: 0.065825, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34009 - Train Loss: 0.065824, Train Acc: 0.891026 | Val Loss: 0.108595, Val Acc: 0.773196\n",
      "Epoch 34010 - Train Loss: 0.065823, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34011 - Train Loss: 0.065822, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34012 - Train Loss: 0.065821, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34013 - Train Loss: 0.065820, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34014 - Train Loss: 0.065819, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34015 - Train Loss: 0.065818, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34016 - Train Loss: 0.065817, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34017 - Train Loss: 0.065816, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34018 - Train Loss: 0.065815, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34019 - Train Loss: 0.065814, Train Acc: 0.891026 | Val Loss: 0.108594, Val Acc: 0.773196\n",
      "Epoch 34020 - Train Loss: 0.065813, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34021 - Train Loss: 0.065812, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34022 - Train Loss: 0.065811, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34023 - Train Loss: 0.065810, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34024 - Train Loss: 0.065809, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34025 - Train Loss: 0.065808, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34026 - Train Loss: 0.065807, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34027 - Train Loss: 0.065806, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34028 - Train Loss: 0.065805, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34029 - Train Loss: 0.065804, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34030 - Train Loss: 0.065803, Train Acc: 0.891026 | Val Loss: 0.108593, Val Acc: 0.773196\n",
      "Epoch 34031 - Train Loss: 0.065802, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34032 - Train Loss: 0.065801, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34033 - Train Loss: 0.065800, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34034 - Train Loss: 0.065799, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34035 - Train Loss: 0.065798, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34036 - Train Loss: 0.065797, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34037 - Train Loss: 0.065796, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34038 - Train Loss: 0.065795, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34039 - Train Loss: 0.065794, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34040 - Train Loss: 0.065793, Train Acc: 0.891026 | Val Loss: 0.108592, Val Acc: 0.773196\n",
      "Epoch 34041 - Train Loss: 0.065792, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34042 - Train Loss: 0.065791, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34043 - Train Loss: 0.065790, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34044 - Train Loss: 0.065789, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34045 - Train Loss: 0.065788, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34046 - Train Loss: 0.065787, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34047 - Train Loss: 0.065785, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34048 - Train Loss: 0.065784, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34049 - Train Loss: 0.065783, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34050 - Train Loss: 0.065782, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34051 - Train Loss: 0.065781, Train Acc: 0.891026 | Val Loss: 0.108591, Val Acc: 0.773196\n",
      "Epoch 34052 - Train Loss: 0.065780, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34053 - Train Loss: 0.065779, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34054 - Train Loss: 0.065778, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34055 - Train Loss: 0.065777, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34056 - Train Loss: 0.065776, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34057 - Train Loss: 0.065775, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34058 - Train Loss: 0.065774, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34059 - Train Loss: 0.065773, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34060 - Train Loss: 0.065772, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34061 - Train Loss: 0.065771, Train Acc: 0.891026 | Val Loss: 0.108590, Val Acc: 0.773196\n",
      "Epoch 34062 - Train Loss: 0.065770, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34063 - Train Loss: 0.065769, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34064 - Train Loss: 0.065768, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34065 - Train Loss: 0.065767, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34066 - Train Loss: 0.065766, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34067 - Train Loss: 0.065765, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34068 - Train Loss: 0.065764, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34069 - Train Loss: 0.065763, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34070 - Train Loss: 0.065762, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34071 - Train Loss: 0.065761, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34072 - Train Loss: 0.065760, Train Acc: 0.891026 | Val Loss: 0.108589, Val Acc: 0.773196\n",
      "Epoch 34073 - Train Loss: 0.065759, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34074 - Train Loss: 0.065758, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34075 - Train Loss: 0.065757, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34076 - Train Loss: 0.065756, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34077 - Train Loss: 0.065755, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34078 - Train Loss: 0.065754, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34079 - Train Loss: 0.065753, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34080 - Train Loss: 0.065752, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34081 - Train Loss: 0.065751, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34082 - Train Loss: 0.065750, Train Acc: 0.891026 | Val Loss: 0.108588, Val Acc: 0.773196\n",
      "Epoch 34083 - Train Loss: 0.065749, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34084 - Train Loss: 0.065748, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34085 - Train Loss: 0.065747, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34086 - Train Loss: 0.065746, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34087 - Train Loss: 0.065745, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34088 - Train Loss: 0.065744, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34089 - Train Loss: 0.065743, Train Acc: 0.891026 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34090 - Train Loss: 0.065742, Train Acc: 0.892308 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34091 - Train Loss: 0.065741, Train Acc: 0.892308 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34092 - Train Loss: 0.065740, Train Acc: 0.892308 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34093 - Train Loss: 0.065739, Train Acc: 0.892308 | Val Loss: 0.108587, Val Acc: 0.773196\n",
      "Epoch 34094 - Train Loss: 0.065738, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34095 - Train Loss: 0.065737, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34096 - Train Loss: 0.065736, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34097 - Train Loss: 0.065735, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34098 - Train Loss: 0.065734, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34099 - Train Loss: 0.065733, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34100 - Train Loss: 0.065732, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34101 - Train Loss: 0.065731, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34102 - Train Loss: 0.065730, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34103 - Train Loss: 0.065728, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34104 - Train Loss: 0.065727, Train Acc: 0.892308 | Val Loss: 0.108586, Val Acc: 0.773196\n",
      "Epoch 34105 - Train Loss: 0.065726, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34106 - Train Loss: 0.065725, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34107 - Train Loss: 0.065724, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34108 - Train Loss: 0.065723, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34109 - Train Loss: 0.065722, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34110 - Train Loss: 0.065721, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34111 - Train Loss: 0.065720, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34112 - Train Loss: 0.065719, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34113 - Train Loss: 0.065718, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34114 - Train Loss: 0.065717, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34115 - Train Loss: 0.065716, Train Acc: 0.892308 | Val Loss: 0.108585, Val Acc: 0.773196\n",
      "Epoch 34116 - Train Loss: 0.065715, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34117 - Train Loss: 0.065714, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34118 - Train Loss: 0.065713, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34119 - Train Loss: 0.065712, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34120 - Train Loss: 0.065711, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34121 - Train Loss: 0.065710, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34122 - Train Loss: 0.065709, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34123 - Train Loss: 0.065708, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34124 - Train Loss: 0.065707, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34125 - Train Loss: 0.065706, Train Acc: 0.892308 | Val Loss: 0.108584, Val Acc: 0.773196\n",
      "Epoch 34126 - Train Loss: 0.065705, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34127 - Train Loss: 0.065704, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34128 - Train Loss: 0.065703, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34129 - Train Loss: 0.065702, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34130 - Train Loss: 0.065701, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34131 - Train Loss: 0.065700, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34132 - Train Loss: 0.065699, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34133 - Train Loss: 0.065698, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34134 - Train Loss: 0.065697, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34135 - Train Loss: 0.065696, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34136 - Train Loss: 0.065695, Train Acc: 0.892308 | Val Loss: 0.108583, Val Acc: 0.773196\n",
      "Epoch 34137 - Train Loss: 0.065694, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34138 - Train Loss: 0.065693, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34139 - Train Loss: 0.065692, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34140 - Train Loss: 0.065691, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34141 - Train Loss: 0.065690, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34142 - Train Loss: 0.065689, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34143 - Train Loss: 0.065688, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34144 - Train Loss: 0.065687, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34145 - Train Loss: 0.065686, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34146 - Train Loss: 0.065685, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34147 - Train Loss: 0.065684, Train Acc: 0.892308 | Val Loss: 0.108582, Val Acc: 0.773196\n",
      "Epoch 34148 - Train Loss: 0.065683, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34149 - Train Loss: 0.065682, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34150 - Train Loss: 0.065681, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34151 - Train Loss: 0.065680, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34152 - Train Loss: 0.065679, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34153 - Train Loss: 0.065678, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34154 - Train Loss: 0.065677, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34155 - Train Loss: 0.065676, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34156 - Train Loss: 0.065675, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34157 - Train Loss: 0.065674, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34158 - Train Loss: 0.065673, Train Acc: 0.892308 | Val Loss: 0.108581, Val Acc: 0.773196\n",
      "Epoch 34159 - Train Loss: 0.065672, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34160 - Train Loss: 0.065671, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34161 - Train Loss: 0.065670, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34162 - Train Loss: 0.065669, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34163 - Train Loss: 0.065668, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34164 - Train Loss: 0.065667, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34165 - Train Loss: 0.065666, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34166 - Train Loss: 0.065665, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34167 - Train Loss: 0.065664, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34168 - Train Loss: 0.065663, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34169 - Train Loss: 0.065661, Train Acc: 0.892308 | Val Loss: 0.108580, Val Acc: 0.773196\n",
      "Epoch 34170 - Train Loss: 0.065660, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34171 - Train Loss: 0.065659, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34172 - Train Loss: 0.065658, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34173 - Train Loss: 0.065657, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34174 - Train Loss: 0.065656, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34175 - Train Loss: 0.065655, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34176 - Train Loss: 0.065654, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34177 - Train Loss: 0.065653, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34178 - Train Loss: 0.065652, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34179 - Train Loss: 0.065651, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34180 - Train Loss: 0.065650, Train Acc: 0.892308 | Val Loss: 0.108579, Val Acc: 0.773196\n",
      "Epoch 34181 - Train Loss: 0.065649, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34182 - Train Loss: 0.065648, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34183 - Train Loss: 0.065647, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34184 - Train Loss: 0.065646, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34185 - Train Loss: 0.065645, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34186 - Train Loss: 0.065644, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34187 - Train Loss: 0.065643, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34188 - Train Loss: 0.065642, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34189 - Train Loss: 0.065641, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34190 - Train Loss: 0.065640, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34191 - Train Loss: 0.065639, Train Acc: 0.892308 | Val Loss: 0.108578, Val Acc: 0.773196\n",
      "Epoch 34192 - Train Loss: 0.065638, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34193 - Train Loss: 0.065637, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34194 - Train Loss: 0.065636, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34195 - Train Loss: 0.065635, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34196 - Train Loss: 0.065634, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34197 - Train Loss: 0.065633, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34198 - Train Loss: 0.065632, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34199 - Train Loss: 0.065631, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34200 - Train Loss: 0.065630, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34201 - Train Loss: 0.065629, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34202 - Train Loss: 0.065628, Train Acc: 0.892308 | Val Loss: 0.108577, Val Acc: 0.773196\n",
      "Epoch 34203 - Train Loss: 0.065627, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34204 - Train Loss: 0.065626, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34205 - Train Loss: 0.065625, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34206 - Train Loss: 0.065624, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34207 - Train Loss: 0.065623, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34208 - Train Loss: 0.065622, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34209 - Train Loss: 0.065621, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34210 - Train Loss: 0.065620, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34211 - Train Loss: 0.065619, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34212 - Train Loss: 0.065618, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34213 - Train Loss: 0.065617, Train Acc: 0.892308 | Val Loss: 0.108576, Val Acc: 0.773196\n",
      "Epoch 34214 - Train Loss: 0.065616, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34215 - Train Loss: 0.065615, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34216 - Train Loss: 0.065614, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34217 - Train Loss: 0.065613, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34218 - Train Loss: 0.065612, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34219 - Train Loss: 0.065611, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34220 - Train Loss: 0.065610, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34221 - Train Loss: 0.065609, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34222 - Train Loss: 0.065608, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34223 - Train Loss: 0.065607, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34224 - Train Loss: 0.065606, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34225 - Train Loss: 0.065605, Train Acc: 0.892308 | Val Loss: 0.108575, Val Acc: 0.773196\n",
      "Epoch 34226 - Train Loss: 0.065604, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34227 - Train Loss: 0.065603, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34228 - Train Loss: 0.065602, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34229 - Train Loss: 0.065601, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34230 - Train Loss: 0.065600, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34231 - Train Loss: 0.065599, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34232 - Train Loss: 0.065598, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34233 - Train Loss: 0.065597, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34234 - Train Loss: 0.065596, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34235 - Train Loss: 0.065595, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34236 - Train Loss: 0.065594, Train Acc: 0.892308 | Val Loss: 0.108574, Val Acc: 0.773196\n",
      "Epoch 34237 - Train Loss: 0.065593, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34238 - Train Loss: 0.065592, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34239 - Train Loss: 0.065591, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34240 - Train Loss: 0.065590, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34241 - Train Loss: 0.065589, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34242 - Train Loss: 0.065588, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34243 - Train Loss: 0.065587, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34244 - Train Loss: 0.065586, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34245 - Train Loss: 0.065585, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34246 - Train Loss: 0.065584, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34247 - Train Loss: 0.065583, Train Acc: 0.892308 | Val Loss: 0.108573, Val Acc: 0.773196\n",
      "Epoch 34248 - Train Loss: 0.065582, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34249 - Train Loss: 0.065581, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34250 - Train Loss: 0.065580, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34251 - Train Loss: 0.065578, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34252 - Train Loss: 0.065577, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34253 - Train Loss: 0.065576, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34254 - Train Loss: 0.065575, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34255 - Train Loss: 0.065574, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34256 - Train Loss: 0.065573, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34257 - Train Loss: 0.065572, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34258 - Train Loss: 0.065571, Train Acc: 0.892308 | Val Loss: 0.108572, Val Acc: 0.773196\n",
      "Epoch 34259 - Train Loss: 0.065570, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34260 - Train Loss: 0.065569, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34261 - Train Loss: 0.065568, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34262 - Train Loss: 0.065567, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34263 - Train Loss: 0.065566, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34264 - Train Loss: 0.065565, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34265 - Train Loss: 0.065564, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34266 - Train Loss: 0.065563, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34267 - Train Loss: 0.065562, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34268 - Train Loss: 0.065561, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34269 - Train Loss: 0.065560, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34270 - Train Loss: 0.065559, Train Acc: 0.892308 | Val Loss: 0.108571, Val Acc: 0.773196\n",
      "Epoch 34271 - Train Loss: 0.065558, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34272 - Train Loss: 0.065557, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34273 - Train Loss: 0.065556, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34274 - Train Loss: 0.065555, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34275 - Train Loss: 0.065554, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34276 - Train Loss: 0.065553, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34277 - Train Loss: 0.065552, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34278 - Train Loss: 0.065551, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34279 - Train Loss: 0.065550, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34280 - Train Loss: 0.065549, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34281 - Train Loss: 0.065548, Train Acc: 0.892308 | Val Loss: 0.108570, Val Acc: 0.773196\n",
      "Epoch 34282 - Train Loss: 0.065547, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34283 - Train Loss: 0.065546, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34284 - Train Loss: 0.065545, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34285 - Train Loss: 0.065544, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34286 - Train Loss: 0.065543, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34287 - Train Loss: 0.065542, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34288 - Train Loss: 0.065541, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34289 - Train Loss: 0.065540, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34290 - Train Loss: 0.065539, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34291 - Train Loss: 0.065538, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34292 - Train Loss: 0.065537, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34293 - Train Loss: 0.065536, Train Acc: 0.892308 | Val Loss: 0.108569, Val Acc: 0.773196\n",
      "Epoch 34294 - Train Loss: 0.065535, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34295 - Train Loss: 0.065534, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34296 - Train Loss: 0.065533, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34297 - Train Loss: 0.065532, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34298 - Train Loss: 0.065531, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34299 - Train Loss: 0.065530, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34300 - Train Loss: 0.065529, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34301 - Train Loss: 0.065528, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34302 - Train Loss: 0.065527, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34303 - Train Loss: 0.065526, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34304 - Train Loss: 0.065525, Train Acc: 0.892308 | Val Loss: 0.108568, Val Acc: 0.773196\n",
      "Epoch 34305 - Train Loss: 0.065524, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34306 - Train Loss: 0.065523, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34307 - Train Loss: 0.065522, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34308 - Train Loss: 0.065521, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34309 - Train Loss: 0.065520, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34310 - Train Loss: 0.065519, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34311 - Train Loss: 0.065518, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34312 - Train Loss: 0.065517, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34313 - Train Loss: 0.065516, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34314 - Train Loss: 0.065515, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34315 - Train Loss: 0.065514, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34316 - Train Loss: 0.065513, Train Acc: 0.892308 | Val Loss: 0.108567, Val Acc: 0.773196\n",
      "Epoch 34317 - Train Loss: 0.065512, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34318 - Train Loss: 0.065511, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34319 - Train Loss: 0.065510, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34320 - Train Loss: 0.065509, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34321 - Train Loss: 0.065508, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34322 - Train Loss: 0.065507, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34323 - Train Loss: 0.065506, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34324 - Train Loss: 0.065505, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34325 - Train Loss: 0.065504, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34326 - Train Loss: 0.065503, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34327 - Train Loss: 0.065502, Train Acc: 0.892308 | Val Loss: 0.108566, Val Acc: 0.773196\n",
      "Epoch 34328 - Train Loss: 0.065501, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34329 - Train Loss: 0.065500, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34330 - Train Loss: 0.065499, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34331 - Train Loss: 0.065498, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34332 - Train Loss: 0.065497, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34333 - Train Loss: 0.065496, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34334 - Train Loss: 0.065495, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34335 - Train Loss: 0.065494, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34336 - Train Loss: 0.065493, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34337 - Train Loss: 0.065492, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34338 - Train Loss: 0.065491, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34339 - Train Loss: 0.065490, Train Acc: 0.892308 | Val Loss: 0.108565, Val Acc: 0.773196\n",
      "Epoch 34340 - Train Loss: 0.065489, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34341 - Train Loss: 0.065488, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34342 - Train Loss: 0.065487, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34343 - Train Loss: 0.065486, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34344 - Train Loss: 0.065485, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34345 - Train Loss: 0.065484, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34346 - Train Loss: 0.065483, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34347 - Train Loss: 0.065482, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34348 - Train Loss: 0.065481, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34349 - Train Loss: 0.065480, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34350 - Train Loss: 0.065479, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34351 - Train Loss: 0.065478, Train Acc: 0.892308 | Val Loss: 0.108564, Val Acc: 0.773196\n",
      "Epoch 34352 - Train Loss: 0.065477, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34353 - Train Loss: 0.065476, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34354 - Train Loss: 0.065475, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34355 - Train Loss: 0.065474, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34356 - Train Loss: 0.065473, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34357 - Train Loss: 0.065472, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34358 - Train Loss: 0.065471, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34359 - Train Loss: 0.065470, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34360 - Train Loss: 0.065469, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34361 - Train Loss: 0.065468, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34362 - Train Loss: 0.065467, Train Acc: 0.892308 | Val Loss: 0.108563, Val Acc: 0.773196\n",
      "Epoch 34363 - Train Loss: 0.065466, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34364 - Train Loss: 0.065465, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34365 - Train Loss: 0.065464, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34366 - Train Loss: 0.065463, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34367 - Train Loss: 0.065462, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34368 - Train Loss: 0.065461, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34369 - Train Loss: 0.065460, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34370 - Train Loss: 0.065459, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34371 - Train Loss: 0.065458, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34372 - Train Loss: 0.065457, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34373 - Train Loss: 0.065456, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34374 - Train Loss: 0.065455, Train Acc: 0.892308 | Val Loss: 0.108562, Val Acc: 0.773196\n",
      "Epoch 34375 - Train Loss: 0.065454, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34376 - Train Loss: 0.065453, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34377 - Train Loss: 0.065452, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34378 - Train Loss: 0.065450, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34379 - Train Loss: 0.065449, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34380 - Train Loss: 0.065448, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34381 - Train Loss: 0.065447, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34382 - Train Loss: 0.065446, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34383 - Train Loss: 0.065445, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34384 - Train Loss: 0.065444, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34385 - Train Loss: 0.065443, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34386 - Train Loss: 0.065442, Train Acc: 0.892308 | Val Loss: 0.108561, Val Acc: 0.773196\n",
      "Epoch 34387 - Train Loss: 0.065441, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34388 - Train Loss: 0.065440, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34389 - Train Loss: 0.065439, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34390 - Train Loss: 0.065438, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34391 - Train Loss: 0.065437, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34392 - Train Loss: 0.065436, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34393 - Train Loss: 0.065435, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34394 - Train Loss: 0.065434, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34395 - Train Loss: 0.065433, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34396 - Train Loss: 0.065432, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34397 - Train Loss: 0.065431, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34398 - Train Loss: 0.065430, Train Acc: 0.892308 | Val Loss: 0.108560, Val Acc: 0.773196\n",
      "Epoch 34399 - Train Loss: 0.065429, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34400 - Train Loss: 0.065428, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34401 - Train Loss: 0.065427, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34402 - Train Loss: 0.065426, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34403 - Train Loss: 0.065425, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34404 - Train Loss: 0.065424, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34405 - Train Loss: 0.065423, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34406 - Train Loss: 0.065422, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34407 - Train Loss: 0.065421, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34408 - Train Loss: 0.065420, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34409 - Train Loss: 0.065419, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34410 - Train Loss: 0.065418, Train Acc: 0.892308 | Val Loss: 0.108559, Val Acc: 0.773196\n",
      "Epoch 34411 - Train Loss: 0.065417, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34412 - Train Loss: 0.065416, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34413 - Train Loss: 0.065415, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34414 - Train Loss: 0.065414, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34415 - Train Loss: 0.065413, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34416 - Train Loss: 0.065412, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34417 - Train Loss: 0.065411, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34418 - Train Loss: 0.065410, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34419 - Train Loss: 0.065409, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34420 - Train Loss: 0.065408, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34421 - Train Loss: 0.065407, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34422 - Train Loss: 0.065406, Train Acc: 0.892308 | Val Loss: 0.108558, Val Acc: 0.773196\n",
      "Epoch 34423 - Train Loss: 0.065405, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34424 - Train Loss: 0.065404, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34425 - Train Loss: 0.065403, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34426 - Train Loss: 0.065402, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34427 - Train Loss: 0.065401, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34428 - Train Loss: 0.065400, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34429 - Train Loss: 0.065399, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34430 - Train Loss: 0.065398, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34431 - Train Loss: 0.065397, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34432 - Train Loss: 0.065396, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34433 - Train Loss: 0.065395, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34434 - Train Loss: 0.065394, Train Acc: 0.892308 | Val Loss: 0.108557, Val Acc: 0.773196\n",
      "Epoch 34435 - Train Loss: 0.065393, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34436 - Train Loss: 0.065392, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34437 - Train Loss: 0.065391, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34438 - Train Loss: 0.065390, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34439 - Train Loss: 0.065389, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34440 - Train Loss: 0.065388, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34441 - Train Loss: 0.065387, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34442 - Train Loss: 0.065386, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34443 - Train Loss: 0.065385, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34444 - Train Loss: 0.065384, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34445 - Train Loss: 0.065383, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34446 - Train Loss: 0.065382, Train Acc: 0.892308 | Val Loss: 0.108556, Val Acc: 0.773196\n",
      "Epoch 34447 - Train Loss: 0.065381, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34448 - Train Loss: 0.065380, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34449 - Train Loss: 0.065379, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34450 - Train Loss: 0.065378, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34451 - Train Loss: 0.065377, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34452 - Train Loss: 0.065376, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34453 - Train Loss: 0.065375, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34454 - Train Loss: 0.065374, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34455 - Train Loss: 0.065373, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34456 - Train Loss: 0.065372, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34457 - Train Loss: 0.065371, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34458 - Train Loss: 0.065370, Train Acc: 0.892308 | Val Loss: 0.108555, Val Acc: 0.773196\n",
      "Epoch 34459 - Train Loss: 0.065369, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34460 - Train Loss: 0.065368, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34461 - Train Loss: 0.065367, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34462 - Train Loss: 0.065366, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34463 - Train Loss: 0.065365, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34464 - Train Loss: 0.065364, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34465 - Train Loss: 0.065363, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34466 - Train Loss: 0.065362, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34467 - Train Loss: 0.065361, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34468 - Train Loss: 0.065360, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34469 - Train Loss: 0.065359, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34470 - Train Loss: 0.065358, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34471 - Train Loss: 0.065357, Train Acc: 0.892308 | Val Loss: 0.108554, Val Acc: 0.773196\n",
      "Epoch 34472 - Train Loss: 0.065356, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34473 - Train Loss: 0.065355, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34474 - Train Loss: 0.065354, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34475 - Train Loss: 0.065353, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34476 - Train Loss: 0.065352, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34477 - Train Loss: 0.065351, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34478 - Train Loss: 0.065350, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34479 - Train Loss: 0.065349, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34480 - Train Loss: 0.065348, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34481 - Train Loss: 0.065347, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34482 - Train Loss: 0.065346, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34483 - Train Loss: 0.065345, Train Acc: 0.892308 | Val Loss: 0.108553, Val Acc: 0.773196\n",
      "Epoch 34484 - Train Loss: 0.065344, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34485 - Train Loss: 0.065343, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34486 - Train Loss: 0.065342, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34487 - Train Loss: 0.065341, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34488 - Train Loss: 0.065340, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34489 - Train Loss: 0.065339, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34490 - Train Loss: 0.065338, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34491 - Train Loss: 0.065337, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34492 - Train Loss: 0.065336, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34493 - Train Loss: 0.065335, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34494 - Train Loss: 0.065334, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34495 - Train Loss: 0.065333, Train Acc: 0.892308 | Val Loss: 0.108552, Val Acc: 0.773196\n",
      "Epoch 34496 - Train Loss: 0.065332, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34497 - Train Loss: 0.065331, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34498 - Train Loss: 0.065330, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34499 - Train Loss: 0.065329, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34500 - Train Loss: 0.065328, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34501 - Train Loss: 0.065327, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34502 - Train Loss: 0.065326, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34503 - Train Loss: 0.065325, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34504 - Train Loss: 0.065324, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34505 - Train Loss: 0.065323, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34506 - Train Loss: 0.065322, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34507 - Train Loss: 0.065321, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34508 - Train Loss: 0.065320, Train Acc: 0.892308 | Val Loss: 0.108551, Val Acc: 0.773196\n",
      "Epoch 34509 - Train Loss: 0.065319, Train Acc: 0.892308 | Val Loss: 0.108550, Val Acc: 0.773196\n",
      "Cost has not changed for 10 epochs, stopping training.\n",
      "--- 76.95543360710144 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X_train.shape[0], 10, 5)\n",
    "\n",
    "# init time for training\n",
    "import time\n",
    "start_time = time.time()\n",
    "history_cost, history_acc, val_cost, val_acc = model.train_until_cost_doesnt_change(\n",
    "    X_train, y_train, 0.005, X_val, y_val\n",
    ")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b55dc684f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cost and accuracy in one graph\n",
    "plt.plot(history_cost, label='Train Loss')\n",
    "plt.plot(val_cost, label='Validation Loss')\n",
    "plt.plot(history_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.text(len(history_cost) - 50, history_cost[-1] + 0.01, str(round(history_cost[-1], 3)))\n",
    "plt.text(len(history_acc) - 50, history_acc[-1] - 0.03, str(round(history_acc[-1], 3)))\n",
    "plt.text(len(val_cost) - 50, val_cost[-1] + 0.01, str(round(val_cost[-1], 3)))\n",
    "plt.text(len(val_acc) - 50, val_acc[-1] - 0.03, str(round(val_acc[-1], 3)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss / Accuracy')\n",
    "plt.title('Train and Validation Metrics for Model ' + model_name)\n",
    "plt.legend(fontsize=8)  # Ukuran font legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and the cost and accuracy\n",
    "file_name = 'NeuralNetwork_Model_' + model_name + '.pkl'\n",
    "file_name_cost_acc = 'Cost_Accuracy_Model_' + model_name + '.csv'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save cost & accuracy\n",
    "cost_acc = pd.DataFrame({\n",
    "    'train_cost': history_cost,\n",
    "    'train_acc': history_acc,\n",
    "    'val_cost': val_cost,\n",
    "    'val_acc': val_acc\n",
    "})\n",
    "cost_acc.to_csv(file_name_cost_acc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 4, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 0, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 4, 0, 0, 3, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 4, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 0, 0, 1, 0, 0, 4, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       3, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 4, 0, 0, 0, 0, 1, 4, 4,\n",
      "       0, 3, 0, 4, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 0, 4, 3, 0, 2, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 4, 3, 1, 1, 0, 0, 4, 2, 0, 0, 0, 2, 0, 4, 2, 0,\n",
      "       3, 0, 4, 0, 3, 0, 0, 4, 4, 0, 2, 0, 2, 3, 0, 0, 4, 4, 4, 1, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 2, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 4, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       0, 4, 0, 1, 0, 0, 4, 4, 0, 0, 4, 0, 4, 0, 3, 0, 0, 4, 0, 0, 4, 1,\n",
      "       4, 0, 0, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 3, 0,\n",
      "       3, 2, 3, 4, 0, 3, 0, 3, 0, 4, 0, 3, 0, 2, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 4, 0, 0, 0, 1, 0, 0, 3, 0, 0, 2, 0, 4, 1, 0, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 0, 0,\n",
      "       0, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 3, 2, 4, 4, 0, 0, 0, 4, 3,\n",
      "       0, 3, 1, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 3, 0, 0, 2, 3, 3, 0, 0,\n",
      "       4, 0, 4, 0, 0, 0, 2, 0, 0, 0, 4, 4, 0, 4, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 3, 4, 0, 4, 2, 0, 0, 0, 3, 0, 0, 0, 0, 1, 4, 0, 0, 4, 4, 0,\n",
      "       3, 2, 0, 4, 2, 3, 3, 0, 0, 0, 1, 0, 0, 0, 4, 0, 2, 4, 0, 4, 0, 2,\n",
      "       0, 0, 3, 2, 1, 3, 0, 0, 4, 4, 0, 1, 0, 1, 0, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 4, 3, 0, 0, 0, 4, 1, 0, 4, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 3, 0, 4, 4, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 4, 0, 1, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 0,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 2, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 4, 0,\n",
      "       0, 0, 0, 0, 0, 0, 2, 2, 0, 3], dtype=int64), array([0, 4, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 3, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 2, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 3, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 4, 0, 1, 0, 0, 3, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 2, 0, 0, 0, 0, 1, 4, 3,\n",
      "       0, 3, 2, 0, 1, 0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 1, 4, 3, 0, 2, 4, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 4, 3, 1, 1, 0, 0, 3, 2, 0, 4, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 1, 0, 3, 0, 0, 4, 4, 0, 4, 0, 2, 3, 4, 0, 4, 4, 2, 0, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       1, 4, 0, 1, 0, 0, 4, 4, 0, 0, 2, 0, 0, 0, 3, 0, 0, 4, 0, 0, 3, 1,\n",
      "       3, 0, 2, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 1, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 2, 0, 4, 0, 3, 0, 1, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 2, 0, 4, 1, 4, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 2, 0, 0,\n",
      "       4, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 4, 2, 4, 4, 0, 0, 4, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 4, 0, 0, 2, 3, 3, 4, 0,\n",
      "       0, 0, 4, 4, 0, 0, 2, 0, 1, 0, 4, 4, 4, 0, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 2, 4, 0, 4, 2, 0, 0, 0, 3, 0, 0, 4, 0, 1, 4, 0, 0, 0, 4, 4,\n",
      "       4, 2, 0, 3, 2, 3, 4, 0, 1, 0, 1, 0, 0, 0, 4, 0, 2, 0, 0, 3, 0, 2,\n",
      "       0, 0, 4, 2, 1, 1, 0, 0, 4, 0, 0, 1, 0, 1, 2, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 3, 3, 0, 0, 0, 4, 1, 0, 3, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 3, 0, 3, 4, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 3, 0, 1, 3, 3, 3, 3, 0, 3, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 3,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 0, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 4, 0, 0, 3, 0, 4, 4,\n",
      "       0, 0, 0, 4, 0, 0, 2, 2, 0, 3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train, y_train)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
