{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Berita</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category_id</th>\n",
       "      <th>Word2Vec Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ayah', 'pinrang', 'tangkap', 'sandera', 'anc...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1796092838048935, 0.4170130491256714, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['duga', 'anak', 'bawa', 'orang', 'kenal', 'at...</td>\n",
       "      <td>orang asing</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.10238317400217056, 0.2470414936542511, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['dpa', 'laku', 'damping', 'korban', 'laku', '...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.35820725560188293, 0.20362965762615204, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['inara', 'rusli', 'bawa', 'kunci', 'bukti', '...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.16313651204109192, 0.26164698600769043, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['viral', 'video', 'bocah', 'ikat', 'tiang', '...</td>\n",
       "      <td>orang asing</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.2542842924594879, 0.24875245988368988, 0.26...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Berita        Label  \\\n",
       "0  ['ayah', 'pinrang', 'tangkap', 'sandera', 'anc...     keluarga   \n",
       "1  ['duga', 'anak', 'bawa', 'orang', 'kenal', 'at...  orang asing   \n",
       "2  ['dpa', 'laku', 'damping', 'korban', 'laku', '...        teman   \n",
       "3  ['inara', 'rusli', 'bawa', 'kunci', 'bukti', '...     keluarga   \n",
       "4  ['viral', 'video', 'bocah', 'ikat', 'tiang', '...  orang asing   \n",
       "\n",
       "   Category_id                                    Word2Vec Vector  \n",
       "0            0  [0.1796092838048935, 0.4170130491256714, -0.04...  \n",
       "1            4  [0.10238317400217056, 0.2470414936542511, 0.27...  \n",
       "2            3  [0.35820725560188293, 0.20362965762615204, 0.2...  \n",
       "3            0  [0.16313651204109192, 0.26164698600769043, 0.2...  \n",
       "4            4  [0.2542842924594879, 0.24875245988368988, 0.26...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = \"Train_Data.csv\"\n",
    "train_df = pd.read_csv(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Berita</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category_id</th>\n",
       "      <th>Word2Vec Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['kali', 'anak', 'selebgram', 'aghnia', 'aniay...</td>\n",
       "      <td>pengasuh</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3540416359901428, 0.3076167106628418, 0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['heboh', 'anak', 'vincent', 'rompies', 'libat...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.28507089614868164, 0.20352721214294434, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['keras', 'sma', 'negeri', 'tasikmalaya', 'mas...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.277415931224823, 0.2662486135959625, 0.2400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['poin', 'kpai', 'kawal', 'bullying', 'geng', ...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.28439921140670776, 0.27106228470802307, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['duga', 'hamil', 'jual', 'anak', 'hasil', 'se...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4781922698020935, 0.3863716125488281, 0.245...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Berita     Label  Category_id  \\\n",
       "0  ['kali', 'anak', 'selebgram', 'aghnia', 'aniay...  pengasuh            1   \n",
       "1  ['heboh', 'anak', 'vincent', 'rompies', 'libat...     teman            3   \n",
       "2  ['keras', 'sma', 'negeri', 'tasikmalaya', 'mas...     teman            3   \n",
       "3  ['poin', 'kpai', 'kawal', 'bullying', 'geng', ...     teman            3   \n",
       "4  ['duga', 'hamil', 'jual', 'anak', 'hasil', 'se...  keluarga            0   \n",
       "\n",
       "                                     Word2Vec Vector  \n",
       "0  [0.3540416359901428, 0.3076167106628418, 0.085...  \n",
       "1  [0.28507089614868164, 0.20352721214294434, 0.1...  \n",
       "2  [0.277415931224823, 0.2662486135959625, 0.2400...  \n",
       "3  [0.28439921140670776, 0.27106228470802307, 0.3...  \n",
       "4  [0.4781922698020935, 0.3863716125488281, 0.245...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = \"Val_Data.csv\"\n",
    "val_df = pd.read_csv(val_df)\n",
    "val_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing The Data for Neural Network Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the locations\n",
    "X_train = train_df['Word2Vec Vector']\n",
    "y_train = train_df['Category_id']\n",
    "X_val = val_df['Word2Vec Vector']\n",
    "y_val = val_df['Category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17960928  0.41701305 -0.04744937 ...  0.40574414  0.245582\n",
      "   0.08898055]\n",
      " [ 0.10238317  0.24704149  0.27464882 ...  0.08813259  0.30407691\n",
      "   0.43934801]\n",
      " [ 0.35820726  0.20362966  0.2630544  ...  0.2579141   0.35038081\n",
      "   0.36289123]\n",
      " ...\n",
      " [ 0.27806711  0.24155277  0.24423018 ...  0.28065443  0.53148139\n",
      "   0.43777528]\n",
      " [ 0.42479664  0.10447986 -0.03571824 ...  0.26021251  0.16793445\n",
      "   0.25592601]\n",
      " [ 0.35719058  0.26109946  0.15572512 ...  0.1309738   0.32690907\n",
      "   0.12616619]]\n",
      "[[ 0.35404164  0.30761671  0.08512706 ...  0.2467062   0.2330083\n",
      "   0.29866689]\n",
      " [ 0.2850709   0.20352721  0.14480667 ...  0.20088911  0.2974396\n",
      "   0.22488372]\n",
      " [ 0.27741593  0.26624861  0.24004306 ...  0.2734699   0.46699813\n",
      "   0.09709835]\n",
      " ...\n",
      " [ 0.34807277  0.34124702 -0.12281044 ...  0.40926725  0.36617047\n",
      "   0.1402137 ]\n",
      " [ 0.26805174  0.2869263   0.12354009 ...  0.36130354  0.19468924\n",
      "   0.23578319]\n",
      " [ 0.27741507  0.2287111  -0.0033286  ...  0.2329713   0.16494793\n",
      "   0.14489825]]\n"
     ]
    }
   ],
   "source": [
    "# Convert string to float\n",
    "X_train = np.array([list(map(float, row.strip(\"[]\").split(','))) for row in X_train])\n",
    "print(X_train)\n",
    "X_train = X_train.T\n",
    "\n",
    "X_val = np.array([list(map(float, row.strip(\"[]\").split(','))) for row in X_val])\n",
    "print(X_val)\n",
    "X_val = X_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17960928,  0.10238317,  0.35820726, ...,  0.27806711,\n",
       "         0.42479664,  0.35719058],\n",
       "       [ 0.41701305,  0.24704149,  0.20362966, ...,  0.24155277,\n",
       "         0.10447986,  0.26109946],\n",
       "       [-0.04744937,  0.27464882,  0.2630544 , ...,  0.24423018,\n",
       "        -0.03571824,  0.15572512],\n",
       "       ...,\n",
       "       [ 0.40574414,  0.08813259,  0.2579141 , ...,  0.28065443,\n",
       "         0.26021251,  0.1309738 ],\n",
       "       [ 0.245582  ,  0.30407691,  0.35038081, ...,  0.53148139,\n",
       "         0.16793445,  0.32690907],\n",
       "       [ 0.08898055,  0.43934801,  0.36289123, ...,  0.43777528,\n",
       "         0.25592601,  0.12616619]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35404164,  0.2850709 ,  0.27741593, ...,  0.34807277,\n",
       "         0.26805174,  0.27741507],\n",
       "       [ 0.30761671,  0.20352721,  0.26624861, ...,  0.34124702,\n",
       "         0.2869263 ,  0.2287111 ],\n",
       "       [ 0.08512706,  0.14480667,  0.24004306, ..., -0.12281044,\n",
       "         0.12354009, -0.0033286 ],\n",
       "       ...,\n",
       "       [ 0.2467062 ,  0.20088911,  0.2734699 , ...,  0.40926725,\n",
       "         0.36130354,  0.2329713 ],\n",
       "       [ 0.2330083 ,  0.2974396 ,  0.46699813, ...,  0.36617047,\n",
       "         0.19468924,  0.16494793],\n",
       "       [ 0.29866689,  0.22488372,  0.09709835, ...,  0.1402137 ,\n",
       "         0.23578319,  0.14489825]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_Train:  (100, 780)\n",
      "Shape y_Train:  (780,)\n",
      "Shape X_Val:  (100, 97)\n",
      "Shape y_Val:  (97,)\n"
     ]
    }
   ],
   "source": [
    "# Make it suitable for my Neural Network input\n",
    "print(\"Shape X_Train: \", X_train.shape)\n",
    "print(\"Shape y_Train: \", y_train.shape)\n",
    "print(\"Shape X_Val: \", X_val.shape)\n",
    "print(\"Shape y_Val: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Type: <class 'numpy.ndarray'>\n",
      "y_train Type: <class 'numpy.ndarray'>\n",
      "X_val Type: <class 'numpy.ndarray'>\n",
      "y_val Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Type:\", type(X_train))\n",
    "print(\"y_train Type:\", type(y_train))\n",
    "print(\"X_val Type:\", type(X_val))\n",
    "print(\"y_val Type:\", type(y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Y2 (Node Hidden Layer 1 = 30, Learning Rate = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_Network_Val import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Y2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.294629, Train Acc: 0.503846 | Val Loss: 0.311966, Val Acc: 0.474227\n",
      "Epoch 2 - Train Loss: 0.294043, Train Acc: 0.503846 | Val Loss: 0.311274, Val Acc: 0.474227\n",
      "Epoch 3 - Train Loss: 0.293476, Train Acc: 0.503846 | Val Loss: 0.310599, Val Acc: 0.474227\n",
      "Epoch 4 - Train Loss: 0.292927, Train Acc: 0.503846 | Val Loss: 0.309942, Val Acc: 0.474227\n",
      "Epoch 5 - Train Loss: 0.292395, Train Acc: 0.503846 | Val Loss: 0.309303, Val Acc: 0.474227\n",
      "Epoch 6 - Train Loss: 0.291880, Train Acc: 0.503846 | Val Loss: 0.308683, Val Acc: 0.474227\n",
      "Epoch 7 - Train Loss: 0.291380, Train Acc: 0.503846 | Val Loss: 0.308081, Val Acc: 0.474227\n",
      "Epoch 8 - Train Loss: 0.290895, Train Acc: 0.503846 | Val Loss: 0.307495, Val Acc: 0.474227\n",
      "Epoch 9 - Train Loss: 0.290425, Train Acc: 0.503846 | Val Loss: 0.306922, Val Acc: 0.474227\n",
      "Epoch 10 - Train Loss: 0.289969, Train Acc: 0.503846 | Val Loss: 0.306367, Val Acc: 0.474227\n",
      "Epoch 11 - Train Loss: 0.289526, Train Acc: 0.503846 | Val Loss: 0.305825, Val Acc: 0.474227\n",
      "Epoch 12 - Train Loss: 0.289097, Train Acc: 0.503846 | Val Loss: 0.305297, Val Acc: 0.474227\n",
      "Epoch 13 - Train Loss: 0.288680, Train Acc: 0.503846 | Val Loss: 0.304782, Val Acc: 0.474227\n",
      "Epoch 14 - Train Loss: 0.288275, Train Acc: 0.503846 | Val Loss: 0.304283, Val Acc: 0.474227\n",
      "Epoch 15 - Train Loss: 0.287883, Train Acc: 0.503846 | Val Loss: 0.303796, Val Acc: 0.474227\n",
      "Epoch 16 - Train Loss: 0.287501, Train Acc: 0.503846 | Val Loss: 0.303322, Val Acc: 0.474227\n",
      "Epoch 17 - Train Loss: 0.287129, Train Acc: 0.503846 | Val Loss: 0.302859, Val Acc: 0.474227\n",
      "Epoch 18 - Train Loss: 0.286768, Train Acc: 0.503846 | Val Loss: 0.302408, Val Acc: 0.474227\n",
      "Epoch 19 - Train Loss: 0.286417, Train Acc: 0.503846 | Val Loss: 0.301969, Val Acc: 0.474227\n",
      "Epoch 20 - Train Loss: 0.286076, Train Acc: 0.503846 | Val Loss: 0.301541, Val Acc: 0.474227\n",
      "Epoch 21 - Train Loss: 0.285745, Train Acc: 0.503846 | Val Loss: 0.301122, Val Acc: 0.474227\n",
      "Epoch 22 - Train Loss: 0.285422, Train Acc: 0.503846 | Val Loss: 0.300713, Val Acc: 0.474227\n",
      "Epoch 23 - Train Loss: 0.285107, Train Acc: 0.503846 | Val Loss: 0.300314, Val Acc: 0.474227\n",
      "Epoch 24 - Train Loss: 0.284800, Train Acc: 0.503846 | Val Loss: 0.299924, Val Acc: 0.474227\n",
      "Epoch 25 - Train Loss: 0.284502, Train Acc: 0.503846 | Val Loss: 0.299545, Val Acc: 0.474227\n",
      "Epoch 26 - Train Loss: 0.284211, Train Acc: 0.503846 | Val Loss: 0.299172, Val Acc: 0.474227\n",
      "Epoch 27 - Train Loss: 0.283927, Train Acc: 0.503846 | Val Loss: 0.298807, Val Acc: 0.474227\n",
      "Epoch 28 - Train Loss: 0.283651, Train Acc: 0.503846 | Val Loss: 0.298448, Val Acc: 0.474227\n",
      "Epoch 29 - Train Loss: 0.283380, Train Acc: 0.503846 | Val Loss: 0.298095, Val Acc: 0.474227\n",
      "Epoch 30 - Train Loss: 0.283114, Train Acc: 0.503846 | Val Loss: 0.297750, Val Acc: 0.474227\n",
      "Epoch 31 - Train Loss: 0.282854, Train Acc: 0.503846 | Val Loss: 0.297411, Val Acc: 0.474227\n",
      "Epoch 32 - Train Loss: 0.282600, Train Acc: 0.503846 | Val Loss: 0.297079, Val Acc: 0.474227\n",
      "Epoch 33 - Train Loss: 0.282351, Train Acc: 0.503846 | Val Loss: 0.296754, Val Acc: 0.474227\n",
      "Epoch 34 - Train Loss: 0.282107, Train Acc: 0.503846 | Val Loss: 0.296436, Val Acc: 0.474227\n",
      "Epoch 35 - Train Loss: 0.281869, Train Acc: 0.503846 | Val Loss: 0.296123, Val Acc: 0.474227\n",
      "Epoch 36 - Train Loss: 0.281637, Train Acc: 0.503846 | Val Loss: 0.295817, Val Acc: 0.474227\n",
      "Epoch 37 - Train Loss: 0.281409, Train Acc: 0.503846 | Val Loss: 0.295517, Val Acc: 0.474227\n",
      "Epoch 38 - Train Loss: 0.281186, Train Acc: 0.503846 | Val Loss: 0.295224, Val Acc: 0.474227\n",
      "Epoch 39 - Train Loss: 0.280968, Train Acc: 0.503846 | Val Loss: 0.294936, Val Acc: 0.474227\n",
      "Epoch 40 - Train Loss: 0.280755, Train Acc: 0.503846 | Val Loss: 0.294653, Val Acc: 0.474227\n",
      "Epoch 41 - Train Loss: 0.280546, Train Acc: 0.503846 | Val Loss: 0.294376, Val Acc: 0.474227\n",
      "Epoch 42 - Train Loss: 0.280341, Train Acc: 0.503846 | Val Loss: 0.294104, Val Acc: 0.474227\n",
      "Epoch 43 - Train Loss: 0.280140, Train Acc: 0.503846 | Val Loss: 0.293836, Val Acc: 0.474227\n",
      "Epoch 44 - Train Loss: 0.279942, Train Acc: 0.503846 | Val Loss: 0.293574, Val Acc: 0.474227\n",
      "Epoch 45 - Train Loss: 0.279748, Train Acc: 0.503846 | Val Loss: 0.293316, Val Acc: 0.474227\n",
      "Epoch 46 - Train Loss: 0.279558, Train Acc: 0.503846 | Val Loss: 0.293063, Val Acc: 0.474227\n",
      "Epoch 47 - Train Loss: 0.279372, Train Acc: 0.503846 | Val Loss: 0.292815, Val Acc: 0.474227\n",
      "Epoch 48 - Train Loss: 0.279189, Train Acc: 0.503846 | Val Loss: 0.292571, Val Acc: 0.474227\n",
      "Epoch 49 - Train Loss: 0.279010, Train Acc: 0.503846 | Val Loss: 0.292331, Val Acc: 0.474227\n",
      "Epoch 50 - Train Loss: 0.278833, Train Acc: 0.503846 | Val Loss: 0.292095, Val Acc: 0.474227\n",
      "Epoch 51 - Train Loss: 0.278659, Train Acc: 0.503846 | Val Loss: 0.291863, Val Acc: 0.474227\n",
      "Epoch 52 - Train Loss: 0.278489, Train Acc: 0.503846 | Val Loss: 0.291635, Val Acc: 0.474227\n",
      "Epoch 53 - Train Loss: 0.278321, Train Acc: 0.503846 | Val Loss: 0.291411, Val Acc: 0.474227\n",
      "Epoch 54 - Train Loss: 0.278157, Train Acc: 0.503846 | Val Loss: 0.291191, Val Acc: 0.474227\n",
      "Epoch 55 - Train Loss: 0.277995, Train Acc: 0.503846 | Val Loss: 0.290975, Val Acc: 0.474227\n",
      "Epoch 56 - Train Loss: 0.277837, Train Acc: 0.503846 | Val Loss: 0.290762, Val Acc: 0.474227\n",
      "Epoch 57 - Train Loss: 0.277681, Train Acc: 0.503846 | Val Loss: 0.290553, Val Acc: 0.474227\n",
      "Epoch 58 - Train Loss: 0.277528, Train Acc: 0.503846 | Val Loss: 0.290347, Val Acc: 0.474227\n",
      "Epoch 59 - Train Loss: 0.277377, Train Acc: 0.503846 | Val Loss: 0.290145, Val Acc: 0.474227\n",
      "Epoch 60 - Train Loss: 0.277230, Train Acc: 0.503846 | Val Loss: 0.289946, Val Acc: 0.474227\n",
      "Epoch 61 - Train Loss: 0.277085, Train Acc: 0.503846 | Val Loss: 0.289750, Val Acc: 0.474227\n",
      "Epoch 62 - Train Loss: 0.276943, Train Acc: 0.503846 | Val Loss: 0.289557, Val Acc: 0.474227\n",
      "Epoch 63 - Train Loss: 0.276803, Train Acc: 0.503846 | Val Loss: 0.289366, Val Acc: 0.474227\n",
      "Epoch 64 - Train Loss: 0.276666, Train Acc: 0.503846 | Val Loss: 0.289179, Val Acc: 0.474227\n",
      "Epoch 65 - Train Loss: 0.276530, Train Acc: 0.503846 | Val Loss: 0.288995, Val Acc: 0.474227\n",
      "Epoch 66 - Train Loss: 0.276397, Train Acc: 0.503846 | Val Loss: 0.288813, Val Acc: 0.474227\n",
      "Epoch 67 - Train Loss: 0.276265, Train Acc: 0.503846 | Val Loss: 0.288634, Val Acc: 0.474227\n",
      "Epoch 68 - Train Loss: 0.276135, Train Acc: 0.503846 | Val Loss: 0.288457, Val Acc: 0.474227\n",
      "Epoch 69 - Train Loss: 0.276008, Train Acc: 0.503846 | Val Loss: 0.288283, Val Acc: 0.474227\n",
      "Epoch 70 - Train Loss: 0.275882, Train Acc: 0.503846 | Val Loss: 0.288112, Val Acc: 0.474227\n",
      "Epoch 71 - Train Loss: 0.275758, Train Acc: 0.503846 | Val Loss: 0.287943, Val Acc: 0.474227\n",
      "Epoch 72 - Train Loss: 0.275637, Train Acc: 0.503846 | Val Loss: 0.287776, Val Acc: 0.474227\n",
      "Epoch 73 - Train Loss: 0.275517, Train Acc: 0.503846 | Val Loss: 0.287612, Val Acc: 0.474227\n",
      "Epoch 74 - Train Loss: 0.275398, Train Acc: 0.503846 | Val Loss: 0.287451, Val Acc: 0.474227\n",
      "Epoch 75 - Train Loss: 0.275282, Train Acc: 0.503846 | Val Loss: 0.287291, Val Acc: 0.474227\n",
      "Epoch 76 - Train Loss: 0.275167, Train Acc: 0.503846 | Val Loss: 0.287133, Val Acc: 0.474227\n",
      "Epoch 77 - Train Loss: 0.275054, Train Acc: 0.503846 | Val Loss: 0.286978, Val Acc: 0.474227\n",
      "Epoch 78 - Train Loss: 0.274942, Train Acc: 0.503846 | Val Loss: 0.286825, Val Acc: 0.474227\n",
      "Epoch 79 - Train Loss: 0.274833, Train Acc: 0.503846 | Val Loss: 0.286674, Val Acc: 0.474227\n",
      "Epoch 80 - Train Loss: 0.274724, Train Acc: 0.503846 | Val Loss: 0.286525, Val Acc: 0.474227\n",
      "Epoch 81 - Train Loss: 0.274617, Train Acc: 0.503846 | Val Loss: 0.286378, Val Acc: 0.474227\n",
      "Epoch 82 - Train Loss: 0.274512, Train Acc: 0.503846 | Val Loss: 0.286233, Val Acc: 0.474227\n",
      "Epoch 83 - Train Loss: 0.274408, Train Acc: 0.503846 | Val Loss: 0.286090, Val Acc: 0.474227\n",
      "Epoch 84 - Train Loss: 0.274306, Train Acc: 0.503846 | Val Loss: 0.285949, Val Acc: 0.474227\n",
      "Epoch 85 - Train Loss: 0.274205, Train Acc: 0.503846 | Val Loss: 0.285809, Val Acc: 0.474227\n",
      "Epoch 86 - Train Loss: 0.274106, Train Acc: 0.503846 | Val Loss: 0.285672, Val Acc: 0.474227\n",
      "Epoch 87 - Train Loss: 0.274007, Train Acc: 0.503846 | Val Loss: 0.285536, Val Acc: 0.474227\n",
      "Epoch 88 - Train Loss: 0.273910, Train Acc: 0.503846 | Val Loss: 0.285402, Val Acc: 0.474227\n",
      "Epoch 89 - Train Loss: 0.273815, Train Acc: 0.503846 | Val Loss: 0.285270, Val Acc: 0.474227\n",
      "Epoch 90 - Train Loss: 0.273720, Train Acc: 0.503846 | Val Loss: 0.285139, Val Acc: 0.474227\n",
      "Epoch 91 - Train Loss: 0.273627, Train Acc: 0.503846 | Val Loss: 0.285010, Val Acc: 0.474227\n",
      "Epoch 92 - Train Loss: 0.273534, Train Acc: 0.503846 | Val Loss: 0.284882, Val Acc: 0.474227\n",
      "Epoch 93 - Train Loss: 0.273443, Train Acc: 0.503846 | Val Loss: 0.284756, Val Acc: 0.474227\n",
      "Epoch 94 - Train Loss: 0.273353, Train Acc: 0.503846 | Val Loss: 0.284632, Val Acc: 0.474227\n",
      "Epoch 95 - Train Loss: 0.273265, Train Acc: 0.503846 | Val Loss: 0.284509, Val Acc: 0.474227\n",
      "Epoch 96 - Train Loss: 0.273177, Train Acc: 0.503846 | Val Loss: 0.284388, Val Acc: 0.474227\n",
      "Epoch 97 - Train Loss: 0.273090, Train Acc: 0.503846 | Val Loss: 0.284268, Val Acc: 0.474227\n",
      "Epoch 98 - Train Loss: 0.273005, Train Acc: 0.503846 | Val Loss: 0.284150, Val Acc: 0.474227\n",
      "Epoch 99 - Train Loss: 0.272920, Train Acc: 0.503846 | Val Loss: 0.284034, Val Acc: 0.474227\n",
      "Epoch 100 - Train Loss: 0.272837, Train Acc: 0.503846 | Val Loss: 0.283919, Val Acc: 0.474227\n",
      "Epoch 101 - Train Loss: 0.272755, Train Acc: 0.503846 | Val Loss: 0.283806, Val Acc: 0.474227\n",
      "Epoch 102 - Train Loss: 0.272674, Train Acc: 0.503846 | Val Loss: 0.283694, Val Acc: 0.474227\n",
      "Epoch 103 - Train Loss: 0.272594, Train Acc: 0.503846 | Val Loss: 0.283583, Val Acc: 0.474227\n",
      "Epoch 104 - Train Loss: 0.272516, Train Acc: 0.503846 | Val Loss: 0.283474, Val Acc: 0.474227\n",
      "Epoch 105 - Train Loss: 0.272438, Train Acc: 0.503846 | Val Loss: 0.283366, Val Acc: 0.474227\n",
      "Epoch 106 - Train Loss: 0.272361, Train Acc: 0.503846 | Val Loss: 0.283259, Val Acc: 0.474227\n",
      "Epoch 107 - Train Loss: 0.272285, Train Acc: 0.503846 | Val Loss: 0.283154, Val Acc: 0.474227\n",
      "Epoch 108 - Train Loss: 0.272211, Train Acc: 0.503846 | Val Loss: 0.283050, Val Acc: 0.474227\n",
      "Epoch 109 - Train Loss: 0.272137, Train Acc: 0.503846 | Val Loss: 0.282948, Val Acc: 0.474227\n",
      "Epoch 110 - Train Loss: 0.272064, Train Acc: 0.503846 | Val Loss: 0.282847, Val Acc: 0.474227\n",
      "Epoch 111 - Train Loss: 0.271993, Train Acc: 0.503846 | Val Loss: 0.282747, Val Acc: 0.474227\n",
      "Epoch 112 - Train Loss: 0.271922, Train Acc: 0.503846 | Val Loss: 0.282648, Val Acc: 0.474227\n",
      "Epoch 113 - Train Loss: 0.271852, Train Acc: 0.503846 | Val Loss: 0.282550, Val Acc: 0.474227\n",
      "Epoch 114 - Train Loss: 0.271783, Train Acc: 0.503846 | Val Loss: 0.282454, Val Acc: 0.474227\n",
      "Epoch 115 - Train Loss: 0.271715, Train Acc: 0.503846 | Val Loss: 0.282358, Val Acc: 0.474227\n",
      "Epoch 116 - Train Loss: 0.271648, Train Acc: 0.503846 | Val Loss: 0.282264, Val Acc: 0.474227\n",
      "Epoch 117 - Train Loss: 0.271581, Train Acc: 0.503846 | Val Loss: 0.282171, Val Acc: 0.474227\n",
      "Epoch 118 - Train Loss: 0.271516, Train Acc: 0.503846 | Val Loss: 0.282079, Val Acc: 0.474227\n",
      "Epoch 119 - Train Loss: 0.271451, Train Acc: 0.503846 | Val Loss: 0.281988, Val Acc: 0.474227\n",
      "Epoch 120 - Train Loss: 0.271387, Train Acc: 0.503846 | Val Loss: 0.281897, Val Acc: 0.474227\n",
      "Epoch 121 - Train Loss: 0.271323, Train Acc: 0.503846 | Val Loss: 0.281808, Val Acc: 0.474227\n",
      "Epoch 122 - Train Loss: 0.271261, Train Acc: 0.503846 | Val Loss: 0.281720, Val Acc: 0.474227\n",
      "Epoch 123 - Train Loss: 0.271199, Train Acc: 0.503846 | Val Loss: 0.281633, Val Acc: 0.474227\n",
      "Epoch 124 - Train Loss: 0.271138, Train Acc: 0.503846 | Val Loss: 0.281547, Val Acc: 0.474227\n",
      "Epoch 125 - Train Loss: 0.271077, Train Acc: 0.503846 | Val Loss: 0.281462, Val Acc: 0.474227\n",
      "Epoch 126 - Train Loss: 0.271018, Train Acc: 0.503846 | Val Loss: 0.281378, Val Acc: 0.474227\n",
      "Epoch 127 - Train Loss: 0.270959, Train Acc: 0.503846 | Val Loss: 0.281295, Val Acc: 0.474227\n",
      "Epoch 128 - Train Loss: 0.270901, Train Acc: 0.503846 | Val Loss: 0.281213, Val Acc: 0.474227\n",
      "Epoch 129 - Train Loss: 0.270843, Train Acc: 0.503846 | Val Loss: 0.281132, Val Acc: 0.474227\n",
      "Epoch 130 - Train Loss: 0.270786, Train Acc: 0.503846 | Val Loss: 0.281052, Val Acc: 0.474227\n",
      "Epoch 131 - Train Loss: 0.270730, Train Acc: 0.503846 | Val Loss: 0.280972, Val Acc: 0.474227\n",
      "Epoch 132 - Train Loss: 0.270675, Train Acc: 0.503846 | Val Loss: 0.280894, Val Acc: 0.474227\n",
      "Epoch 133 - Train Loss: 0.270620, Train Acc: 0.503846 | Val Loss: 0.280816, Val Acc: 0.474227\n",
      "Epoch 134 - Train Loss: 0.270566, Train Acc: 0.503846 | Val Loss: 0.280740, Val Acc: 0.474227\n",
      "Epoch 135 - Train Loss: 0.270512, Train Acc: 0.503846 | Val Loss: 0.280664, Val Acc: 0.474227\n",
      "Epoch 136 - Train Loss: 0.270459, Train Acc: 0.503846 | Val Loss: 0.280589, Val Acc: 0.474227\n",
      "Epoch 137 - Train Loss: 0.270407, Train Acc: 0.503846 | Val Loss: 0.280515, Val Acc: 0.474227\n",
      "Epoch 138 - Train Loss: 0.270355, Train Acc: 0.503846 | Val Loss: 0.280442, Val Acc: 0.474227\n",
      "Epoch 139 - Train Loss: 0.270304, Train Acc: 0.503846 | Val Loss: 0.280370, Val Acc: 0.474227\n",
      "Epoch 140 - Train Loss: 0.270254, Train Acc: 0.503846 | Val Loss: 0.280298, Val Acc: 0.474227\n",
      "Epoch 141 - Train Loss: 0.270204, Train Acc: 0.503846 | Val Loss: 0.280228, Val Acc: 0.474227\n",
      "Epoch 142 - Train Loss: 0.270155, Train Acc: 0.503846 | Val Loss: 0.280158, Val Acc: 0.474227\n",
      "Epoch 143 - Train Loss: 0.270106, Train Acc: 0.503846 | Val Loss: 0.280089, Val Acc: 0.474227\n",
      "Epoch 144 - Train Loss: 0.270058, Train Acc: 0.503846 | Val Loss: 0.280021, Val Acc: 0.474227\n",
      "Epoch 145 - Train Loss: 0.270010, Train Acc: 0.503846 | Val Loss: 0.279953, Val Acc: 0.474227\n",
      "Epoch 146 - Train Loss: 0.269963, Train Acc: 0.503846 | Val Loss: 0.279886, Val Acc: 0.474227\n",
      "Epoch 147 - Train Loss: 0.269917, Train Acc: 0.503846 | Val Loss: 0.279820, Val Acc: 0.474227\n",
      "Epoch 148 - Train Loss: 0.269871, Train Acc: 0.503846 | Val Loss: 0.279755, Val Acc: 0.474227\n",
      "Epoch 149 - Train Loss: 0.269825, Train Acc: 0.503846 | Val Loss: 0.279690, Val Acc: 0.474227\n",
      "Epoch 150 - Train Loss: 0.269780, Train Acc: 0.503846 | Val Loss: 0.279626, Val Acc: 0.474227\n",
      "Epoch 151 - Train Loss: 0.269736, Train Acc: 0.503846 | Val Loss: 0.279563, Val Acc: 0.474227\n",
      "Epoch 152 - Train Loss: 0.269692, Train Acc: 0.503846 | Val Loss: 0.279501, Val Acc: 0.474227\n",
      "Epoch 153 - Train Loss: 0.269648, Train Acc: 0.503846 | Val Loss: 0.279439, Val Acc: 0.474227\n",
      "Epoch 154 - Train Loss: 0.269605, Train Acc: 0.503846 | Val Loss: 0.279378, Val Acc: 0.474227\n",
      "Epoch 155 - Train Loss: 0.269562, Train Acc: 0.503846 | Val Loss: 0.279317, Val Acc: 0.474227\n",
      "Epoch 156 - Train Loss: 0.269520, Train Acc: 0.503846 | Val Loss: 0.279257, Val Acc: 0.474227\n",
      "Epoch 157 - Train Loss: 0.269478, Train Acc: 0.503846 | Val Loss: 0.279198, Val Acc: 0.474227\n",
      "Epoch 158 - Train Loss: 0.269437, Train Acc: 0.503846 | Val Loss: 0.279140, Val Acc: 0.474227\n",
      "Epoch 159 - Train Loss: 0.269396, Train Acc: 0.503846 | Val Loss: 0.279082, Val Acc: 0.474227\n",
      "Epoch 160 - Train Loss: 0.269355, Train Acc: 0.503846 | Val Loss: 0.279024, Val Acc: 0.474227\n",
      "Epoch 161 - Train Loss: 0.269315, Train Acc: 0.503846 | Val Loss: 0.278968, Val Acc: 0.474227\n",
      "Epoch 162 - Train Loss: 0.269275, Train Acc: 0.503846 | Val Loss: 0.278911, Val Acc: 0.474227\n",
      "Epoch 163 - Train Loss: 0.269236, Train Acc: 0.503846 | Val Loss: 0.278856, Val Acc: 0.474227\n",
      "Epoch 164 - Train Loss: 0.269197, Train Acc: 0.503846 | Val Loss: 0.278801, Val Acc: 0.474227\n",
      "Epoch 165 - Train Loss: 0.269159, Train Acc: 0.503846 | Val Loss: 0.278746, Val Acc: 0.474227\n",
      "Epoch 166 - Train Loss: 0.269121, Train Acc: 0.503846 | Val Loss: 0.278692, Val Acc: 0.474227\n",
      "Epoch 167 - Train Loss: 0.269083, Train Acc: 0.503846 | Val Loss: 0.278639, Val Acc: 0.474227\n",
      "Epoch 168 - Train Loss: 0.269045, Train Acc: 0.503846 | Val Loss: 0.278586, Val Acc: 0.474227\n",
      "Epoch 169 - Train Loss: 0.269008, Train Acc: 0.503846 | Val Loss: 0.278534, Val Acc: 0.474227\n",
      "Epoch 170 - Train Loss: 0.268972, Train Acc: 0.503846 | Val Loss: 0.278482, Val Acc: 0.474227\n",
      "Epoch 171 - Train Loss: 0.268935, Train Acc: 0.503846 | Val Loss: 0.278431, Val Acc: 0.474227\n",
      "Epoch 172 - Train Loss: 0.268899, Train Acc: 0.503846 | Val Loss: 0.278380, Val Acc: 0.474227\n",
      "Epoch 173 - Train Loss: 0.268864, Train Acc: 0.503846 | Val Loss: 0.278329, Val Acc: 0.474227\n",
      "Epoch 174 - Train Loss: 0.268828, Train Acc: 0.503846 | Val Loss: 0.278280, Val Acc: 0.474227\n",
      "Epoch 175 - Train Loss: 0.268793, Train Acc: 0.503846 | Val Loss: 0.278230, Val Acc: 0.474227\n",
      "Epoch 176 - Train Loss: 0.268759, Train Acc: 0.503846 | Val Loss: 0.278181, Val Acc: 0.474227\n",
      "Epoch 177 - Train Loss: 0.268724, Train Acc: 0.503846 | Val Loss: 0.278133, Val Acc: 0.474227\n",
      "Epoch 178 - Train Loss: 0.268691, Train Acc: 0.503846 | Val Loss: 0.278085, Val Acc: 0.474227\n",
      "Epoch 179 - Train Loss: 0.268657, Train Acc: 0.503846 | Val Loss: 0.278038, Val Acc: 0.474227\n",
      "Epoch 180 - Train Loss: 0.268624, Train Acc: 0.503846 | Val Loss: 0.277991, Val Acc: 0.474227\n",
      "Epoch 181 - Train Loss: 0.268590, Train Acc: 0.503846 | Val Loss: 0.277944, Val Acc: 0.474227\n",
      "Epoch 182 - Train Loss: 0.268558, Train Acc: 0.503846 | Val Loss: 0.277898, Val Acc: 0.474227\n",
      "Epoch 183 - Train Loss: 0.268525, Train Acc: 0.503846 | Val Loss: 0.277853, Val Acc: 0.474227\n",
      "Epoch 184 - Train Loss: 0.268493, Train Acc: 0.503846 | Val Loss: 0.277807, Val Acc: 0.474227\n",
      "Epoch 185 - Train Loss: 0.268461, Train Acc: 0.503846 | Val Loss: 0.277763, Val Acc: 0.474227\n",
      "Epoch 186 - Train Loss: 0.268429, Train Acc: 0.503846 | Val Loss: 0.277718, Val Acc: 0.474227\n",
      "Epoch 187 - Train Loss: 0.268398, Train Acc: 0.503846 | Val Loss: 0.277674, Val Acc: 0.474227\n",
      "Epoch 188 - Train Loss: 0.268367, Train Acc: 0.503846 | Val Loss: 0.277630, Val Acc: 0.474227\n",
      "Epoch 189 - Train Loss: 0.268336, Train Acc: 0.503846 | Val Loss: 0.277587, Val Acc: 0.474227\n",
      "Epoch 190 - Train Loss: 0.268306, Train Acc: 0.503846 | Val Loss: 0.277544, Val Acc: 0.474227\n",
      "Epoch 191 - Train Loss: 0.268275, Train Acc: 0.503846 | Val Loss: 0.277502, Val Acc: 0.474227\n",
      "Epoch 192 - Train Loss: 0.268245, Train Acc: 0.503846 | Val Loss: 0.277460, Val Acc: 0.474227\n",
      "Epoch 193 - Train Loss: 0.268216, Train Acc: 0.503846 | Val Loss: 0.277418, Val Acc: 0.474227\n",
      "Epoch 194 - Train Loss: 0.268186, Train Acc: 0.503846 | Val Loss: 0.277377, Val Acc: 0.474227\n",
      "Epoch 195 - Train Loss: 0.268157, Train Acc: 0.503846 | Val Loss: 0.277336, Val Acc: 0.474227\n",
      "Epoch 196 - Train Loss: 0.268128, Train Acc: 0.503846 | Val Loss: 0.277295, Val Acc: 0.474227\n",
      "Epoch 197 - Train Loss: 0.268099, Train Acc: 0.503846 | Val Loss: 0.277255, Val Acc: 0.474227\n",
      "Epoch 198 - Train Loss: 0.268070, Train Acc: 0.503846 | Val Loss: 0.277215, Val Acc: 0.474227\n",
      "Epoch 199 - Train Loss: 0.268042, Train Acc: 0.503846 | Val Loss: 0.277175, Val Acc: 0.474227\n",
      "Epoch 200 - Train Loss: 0.268014, Train Acc: 0.503846 | Val Loss: 0.277136, Val Acc: 0.474227\n",
      "Epoch 201 - Train Loss: 0.267986, Train Acc: 0.503846 | Val Loss: 0.277097, Val Acc: 0.474227\n",
      "Epoch 202 - Train Loss: 0.267958, Train Acc: 0.503846 | Val Loss: 0.277059, Val Acc: 0.474227\n",
      "Epoch 203 - Train Loss: 0.267931, Train Acc: 0.503846 | Val Loss: 0.277020, Val Acc: 0.474227\n",
      "Epoch 204 - Train Loss: 0.267904, Train Acc: 0.503846 | Val Loss: 0.276982, Val Acc: 0.474227\n",
      "Epoch 205 - Train Loss: 0.267877, Train Acc: 0.503846 | Val Loss: 0.276945, Val Acc: 0.474227\n",
      "Epoch 206 - Train Loss: 0.267850, Train Acc: 0.503846 | Val Loss: 0.276907, Val Acc: 0.474227\n",
      "Epoch 207 - Train Loss: 0.267823, Train Acc: 0.503846 | Val Loss: 0.276870, Val Acc: 0.474227\n",
      "Epoch 208 - Train Loss: 0.267796, Train Acc: 0.503846 | Val Loss: 0.276834, Val Acc: 0.474227\n",
      "Epoch 209 - Train Loss: 0.267770, Train Acc: 0.503846 | Val Loss: 0.276797, Val Acc: 0.474227\n",
      "Epoch 210 - Train Loss: 0.267744, Train Acc: 0.503846 | Val Loss: 0.276761, Val Acc: 0.474227\n",
      "Epoch 211 - Train Loss: 0.267718, Train Acc: 0.503846 | Val Loss: 0.276725, Val Acc: 0.474227\n",
      "Epoch 212 - Train Loss: 0.267692, Train Acc: 0.503846 | Val Loss: 0.276690, Val Acc: 0.474227\n",
      "Epoch 213 - Train Loss: 0.267667, Train Acc: 0.503846 | Val Loss: 0.276654, Val Acc: 0.474227\n",
      "Epoch 214 - Train Loss: 0.267641, Train Acc: 0.503846 | Val Loss: 0.276619, Val Acc: 0.474227\n",
      "Epoch 215 - Train Loss: 0.267616, Train Acc: 0.503846 | Val Loss: 0.276584, Val Acc: 0.474227\n",
      "Epoch 216 - Train Loss: 0.267591, Train Acc: 0.503846 | Val Loss: 0.276550, Val Acc: 0.474227\n",
      "Epoch 217 - Train Loss: 0.267566, Train Acc: 0.503846 | Val Loss: 0.276515, Val Acc: 0.474227\n",
      "Epoch 218 - Train Loss: 0.267541, Train Acc: 0.503846 | Val Loss: 0.276481, Val Acc: 0.474227\n",
      "Epoch 219 - Train Loss: 0.267517, Train Acc: 0.503846 | Val Loss: 0.276447, Val Acc: 0.474227\n",
      "Epoch 220 - Train Loss: 0.267492, Train Acc: 0.503846 | Val Loss: 0.276414, Val Acc: 0.474227\n",
      "Epoch 221 - Train Loss: 0.267468, Train Acc: 0.503846 | Val Loss: 0.276380, Val Acc: 0.474227\n",
      "Epoch 222 - Train Loss: 0.267444, Train Acc: 0.503846 | Val Loss: 0.276347, Val Acc: 0.474227\n",
      "Epoch 223 - Train Loss: 0.267420, Train Acc: 0.503846 | Val Loss: 0.276314, Val Acc: 0.474227\n",
      "Epoch 224 - Train Loss: 0.267396, Train Acc: 0.503846 | Val Loss: 0.276282, Val Acc: 0.474227\n",
      "Epoch 225 - Train Loss: 0.267372, Train Acc: 0.503846 | Val Loss: 0.276249, Val Acc: 0.474227\n",
      "Epoch 226 - Train Loss: 0.267349, Train Acc: 0.503846 | Val Loss: 0.276217, Val Acc: 0.474227\n",
      "Epoch 227 - Train Loss: 0.267325, Train Acc: 0.503846 | Val Loss: 0.276185, Val Acc: 0.474227\n",
      "Epoch 228 - Train Loss: 0.267302, Train Acc: 0.503846 | Val Loss: 0.276153, Val Acc: 0.474227\n",
      "Epoch 229 - Train Loss: 0.267279, Train Acc: 0.503846 | Val Loss: 0.276122, Val Acc: 0.474227\n",
      "Epoch 230 - Train Loss: 0.267256, Train Acc: 0.503846 | Val Loss: 0.276090, Val Acc: 0.474227\n",
      "Epoch 231 - Train Loss: 0.267233, Train Acc: 0.503846 | Val Loss: 0.276059, Val Acc: 0.474227\n",
      "Epoch 232 - Train Loss: 0.267210, Train Acc: 0.503846 | Val Loss: 0.276028, Val Acc: 0.474227\n",
      "Epoch 233 - Train Loss: 0.267188, Train Acc: 0.503846 | Val Loss: 0.275998, Val Acc: 0.474227\n",
      "Epoch 234 - Train Loss: 0.267165, Train Acc: 0.503846 | Val Loss: 0.275967, Val Acc: 0.474227\n",
      "Epoch 235 - Train Loss: 0.267143, Train Acc: 0.503846 | Val Loss: 0.275937, Val Acc: 0.474227\n",
      "Epoch 236 - Train Loss: 0.267121, Train Acc: 0.503846 | Val Loss: 0.275907, Val Acc: 0.474227\n",
      "Epoch 237 - Train Loss: 0.267099, Train Acc: 0.503846 | Val Loss: 0.275877, Val Acc: 0.474227\n",
      "Epoch 238 - Train Loss: 0.267077, Train Acc: 0.503846 | Val Loss: 0.275847, Val Acc: 0.474227\n",
      "Epoch 239 - Train Loss: 0.267055, Train Acc: 0.503846 | Val Loss: 0.275817, Val Acc: 0.474227\n",
      "Epoch 240 - Train Loss: 0.267033, Train Acc: 0.503846 | Val Loss: 0.275788, Val Acc: 0.474227\n",
      "Epoch 241 - Train Loss: 0.267011, Train Acc: 0.503846 | Val Loss: 0.275759, Val Acc: 0.474227\n",
      "Epoch 242 - Train Loss: 0.266990, Train Acc: 0.503846 | Val Loss: 0.275730, Val Acc: 0.474227\n",
      "Epoch 243 - Train Loss: 0.266968, Train Acc: 0.503846 | Val Loss: 0.275701, Val Acc: 0.474227\n",
      "Epoch 244 - Train Loss: 0.266947, Train Acc: 0.503846 | Val Loss: 0.275672, Val Acc: 0.474227\n",
      "Epoch 245 - Train Loss: 0.266926, Train Acc: 0.503846 | Val Loss: 0.275644, Val Acc: 0.474227\n",
      "Epoch 246 - Train Loss: 0.266905, Train Acc: 0.503846 | Val Loss: 0.275616, Val Acc: 0.474227\n",
      "Epoch 247 - Train Loss: 0.266883, Train Acc: 0.503846 | Val Loss: 0.275587, Val Acc: 0.474227\n",
      "Epoch 248 - Train Loss: 0.266863, Train Acc: 0.503846 | Val Loss: 0.275559, Val Acc: 0.474227\n",
      "Epoch 249 - Train Loss: 0.266842, Train Acc: 0.503846 | Val Loss: 0.275532, Val Acc: 0.474227\n",
      "Epoch 250 - Train Loss: 0.266821, Train Acc: 0.503846 | Val Loss: 0.275504, Val Acc: 0.474227\n",
      "Epoch 251 - Train Loss: 0.266800, Train Acc: 0.503846 | Val Loss: 0.275477, Val Acc: 0.474227\n",
      "Epoch 252 - Train Loss: 0.266780, Train Acc: 0.503846 | Val Loss: 0.275449, Val Acc: 0.474227\n",
      "Epoch 253 - Train Loss: 0.266759, Train Acc: 0.503846 | Val Loss: 0.275422, Val Acc: 0.474227\n",
      "Epoch 254 - Train Loss: 0.266739, Train Acc: 0.503846 | Val Loss: 0.275395, Val Acc: 0.474227\n",
      "Epoch 255 - Train Loss: 0.266718, Train Acc: 0.503846 | Val Loss: 0.275368, Val Acc: 0.474227\n",
      "Epoch 256 - Train Loss: 0.266698, Train Acc: 0.503846 | Val Loss: 0.275341, Val Acc: 0.474227\n",
      "Epoch 257 - Train Loss: 0.266678, Train Acc: 0.503846 | Val Loss: 0.275314, Val Acc: 0.474227\n",
      "Epoch 258 - Train Loss: 0.266658, Train Acc: 0.503846 | Val Loss: 0.275288, Val Acc: 0.474227\n",
      "Epoch 259 - Train Loss: 0.266638, Train Acc: 0.503846 | Val Loss: 0.275262, Val Acc: 0.474227\n",
      "Epoch 260 - Train Loss: 0.266618, Train Acc: 0.503846 | Val Loss: 0.275236, Val Acc: 0.474227\n",
      "Epoch 261 - Train Loss: 0.266598, Train Acc: 0.503846 | Val Loss: 0.275210, Val Acc: 0.474227\n",
      "Epoch 262 - Train Loss: 0.266578, Train Acc: 0.503846 | Val Loss: 0.275184, Val Acc: 0.474227\n",
      "Epoch 263 - Train Loss: 0.266559, Train Acc: 0.503846 | Val Loss: 0.275158, Val Acc: 0.474227\n",
      "Epoch 264 - Train Loss: 0.266539, Train Acc: 0.503846 | Val Loss: 0.275132, Val Acc: 0.474227\n",
      "Epoch 265 - Train Loss: 0.266520, Train Acc: 0.503846 | Val Loss: 0.275107, Val Acc: 0.474227\n",
      "Epoch 266 - Train Loss: 0.266500, Train Acc: 0.503846 | Val Loss: 0.275082, Val Acc: 0.474227\n",
      "Epoch 267 - Train Loss: 0.266481, Train Acc: 0.503846 | Val Loss: 0.275056, Val Acc: 0.474227\n",
      "Epoch 268 - Train Loss: 0.266462, Train Acc: 0.503846 | Val Loss: 0.275031, Val Acc: 0.474227\n",
      "Epoch 269 - Train Loss: 0.266443, Train Acc: 0.503846 | Val Loss: 0.275006, Val Acc: 0.474227\n",
      "Epoch 270 - Train Loss: 0.266424, Train Acc: 0.503846 | Val Loss: 0.274981, Val Acc: 0.474227\n",
      "Epoch 271 - Train Loss: 0.266405, Train Acc: 0.503846 | Val Loss: 0.274957, Val Acc: 0.474227\n",
      "Epoch 272 - Train Loss: 0.266386, Train Acc: 0.503846 | Val Loss: 0.274932, Val Acc: 0.474227\n",
      "Epoch 273 - Train Loss: 0.266367, Train Acc: 0.503846 | Val Loss: 0.274908, Val Acc: 0.474227\n",
      "Epoch 274 - Train Loss: 0.266348, Train Acc: 0.503846 | Val Loss: 0.274883, Val Acc: 0.474227\n",
      "Epoch 275 - Train Loss: 0.266329, Train Acc: 0.503846 | Val Loss: 0.274859, Val Acc: 0.474227\n",
      "Epoch 276 - Train Loss: 0.266310, Train Acc: 0.503846 | Val Loss: 0.274835, Val Acc: 0.474227\n",
      "Epoch 277 - Train Loss: 0.266292, Train Acc: 0.503846 | Val Loss: 0.274811, Val Acc: 0.474227\n",
      "Epoch 278 - Train Loss: 0.266273, Train Acc: 0.503846 | Val Loss: 0.274787, Val Acc: 0.474227\n",
      "Epoch 279 - Train Loss: 0.266255, Train Acc: 0.503846 | Val Loss: 0.274763, Val Acc: 0.474227\n",
      "Epoch 280 - Train Loss: 0.266236, Train Acc: 0.503846 | Val Loss: 0.274739, Val Acc: 0.474227\n",
      "Epoch 281 - Train Loss: 0.266218, Train Acc: 0.503846 | Val Loss: 0.274715, Val Acc: 0.474227\n",
      "Epoch 282 - Train Loss: 0.266199, Train Acc: 0.503846 | Val Loss: 0.274692, Val Acc: 0.474227\n",
      "Epoch 283 - Train Loss: 0.266181, Train Acc: 0.503846 | Val Loss: 0.274668, Val Acc: 0.474227\n",
      "Epoch 284 - Train Loss: 0.266163, Train Acc: 0.503846 | Val Loss: 0.274645, Val Acc: 0.474227\n",
      "Epoch 285 - Train Loss: 0.266145, Train Acc: 0.503846 | Val Loss: 0.274622, Val Acc: 0.474227\n",
      "Epoch 286 - Train Loss: 0.266127, Train Acc: 0.503846 | Val Loss: 0.274599, Val Acc: 0.474227\n",
      "Epoch 287 - Train Loss: 0.266109, Train Acc: 0.503846 | Val Loss: 0.274576, Val Acc: 0.474227\n",
      "Epoch 288 - Train Loss: 0.266091, Train Acc: 0.503846 | Val Loss: 0.274553, Val Acc: 0.474227\n",
      "Epoch 289 - Train Loss: 0.266073, Train Acc: 0.503846 | Val Loss: 0.274530, Val Acc: 0.474227\n",
      "Epoch 290 - Train Loss: 0.266055, Train Acc: 0.503846 | Val Loss: 0.274507, Val Acc: 0.474227\n",
      "Epoch 291 - Train Loss: 0.266037, Train Acc: 0.503846 | Val Loss: 0.274485, Val Acc: 0.474227\n",
      "Epoch 292 - Train Loss: 0.266019, Train Acc: 0.503846 | Val Loss: 0.274462, Val Acc: 0.474227\n",
      "Epoch 293 - Train Loss: 0.266001, Train Acc: 0.503846 | Val Loss: 0.274440, Val Acc: 0.474227\n",
      "Epoch 294 - Train Loss: 0.265984, Train Acc: 0.503846 | Val Loss: 0.274418, Val Acc: 0.474227\n",
      "Epoch 295 - Train Loss: 0.265966, Train Acc: 0.503846 | Val Loss: 0.274395, Val Acc: 0.474227\n",
      "Epoch 296 - Train Loss: 0.265948, Train Acc: 0.503846 | Val Loss: 0.274373, Val Acc: 0.474227\n",
      "Epoch 297 - Train Loss: 0.265931, Train Acc: 0.503846 | Val Loss: 0.274351, Val Acc: 0.474227\n",
      "Epoch 298 - Train Loss: 0.265913, Train Acc: 0.503846 | Val Loss: 0.274329, Val Acc: 0.474227\n",
      "Epoch 299 - Train Loss: 0.265896, Train Acc: 0.503846 | Val Loss: 0.274307, Val Acc: 0.474227\n",
      "Epoch 300 - Train Loss: 0.265878, Train Acc: 0.503846 | Val Loss: 0.274286, Val Acc: 0.474227\n",
      "Epoch 301 - Train Loss: 0.265861, Train Acc: 0.503846 | Val Loss: 0.274264, Val Acc: 0.474227\n",
      "Epoch 302 - Train Loss: 0.265844, Train Acc: 0.503846 | Val Loss: 0.274242, Val Acc: 0.474227\n",
      "Epoch 303 - Train Loss: 0.265826, Train Acc: 0.503846 | Val Loss: 0.274221, Val Acc: 0.474227\n",
      "Epoch 304 - Train Loss: 0.265809, Train Acc: 0.503846 | Val Loss: 0.274199, Val Acc: 0.474227\n",
      "Epoch 305 - Train Loss: 0.265792, Train Acc: 0.503846 | Val Loss: 0.274178, Val Acc: 0.474227\n",
      "Epoch 306 - Train Loss: 0.265774, Train Acc: 0.503846 | Val Loss: 0.274157, Val Acc: 0.474227\n",
      "Epoch 307 - Train Loss: 0.265757, Train Acc: 0.503846 | Val Loss: 0.274135, Val Acc: 0.474227\n",
      "Epoch 308 - Train Loss: 0.265740, Train Acc: 0.503846 | Val Loss: 0.274114, Val Acc: 0.474227\n",
      "Epoch 309 - Train Loss: 0.265723, Train Acc: 0.503846 | Val Loss: 0.274093, Val Acc: 0.474227\n",
      "Epoch 310 - Train Loss: 0.265706, Train Acc: 0.503846 | Val Loss: 0.274072, Val Acc: 0.474227\n",
      "Epoch 311 - Train Loss: 0.265689, Train Acc: 0.503846 | Val Loss: 0.274051, Val Acc: 0.474227\n",
      "Epoch 312 - Train Loss: 0.265672, Train Acc: 0.503846 | Val Loss: 0.274030, Val Acc: 0.474227\n",
      "Epoch 313 - Train Loss: 0.265655, Train Acc: 0.503846 | Val Loss: 0.274009, Val Acc: 0.474227\n",
      "Epoch 314 - Train Loss: 0.265638, Train Acc: 0.503846 | Val Loss: 0.273988, Val Acc: 0.474227\n",
      "Epoch 315 - Train Loss: 0.265621, Train Acc: 0.503846 | Val Loss: 0.273968, Val Acc: 0.474227\n",
      "Epoch 316 - Train Loss: 0.265604, Train Acc: 0.503846 | Val Loss: 0.273947, Val Acc: 0.474227\n",
      "Epoch 317 - Train Loss: 0.265587, Train Acc: 0.503846 | Val Loss: 0.273926, Val Acc: 0.474227\n",
      "Epoch 318 - Train Loss: 0.265570, Train Acc: 0.503846 | Val Loss: 0.273906, Val Acc: 0.474227\n",
      "Epoch 319 - Train Loss: 0.265553, Train Acc: 0.503846 | Val Loss: 0.273885, Val Acc: 0.474227\n",
      "Epoch 320 - Train Loss: 0.265537, Train Acc: 0.503846 | Val Loss: 0.273865, Val Acc: 0.474227\n",
      "Epoch 321 - Train Loss: 0.265520, Train Acc: 0.503846 | Val Loss: 0.273845, Val Acc: 0.474227\n",
      "Epoch 322 - Train Loss: 0.265503, Train Acc: 0.503846 | Val Loss: 0.273824, Val Acc: 0.474227\n",
      "Epoch 323 - Train Loss: 0.265487, Train Acc: 0.503846 | Val Loss: 0.273804, Val Acc: 0.474227\n",
      "Epoch 324 - Train Loss: 0.265470, Train Acc: 0.503846 | Val Loss: 0.273784, Val Acc: 0.474227\n",
      "Epoch 325 - Train Loss: 0.265453, Train Acc: 0.503846 | Val Loss: 0.273764, Val Acc: 0.474227\n",
      "Epoch 326 - Train Loss: 0.265437, Train Acc: 0.503846 | Val Loss: 0.273744, Val Acc: 0.474227\n",
      "Epoch 327 - Train Loss: 0.265420, Train Acc: 0.503846 | Val Loss: 0.273724, Val Acc: 0.474227\n",
      "Epoch 328 - Train Loss: 0.265403, Train Acc: 0.503846 | Val Loss: 0.273704, Val Acc: 0.474227\n",
      "Epoch 329 - Train Loss: 0.265387, Train Acc: 0.503846 | Val Loss: 0.273684, Val Acc: 0.474227\n",
      "Epoch 330 - Train Loss: 0.265370, Train Acc: 0.503846 | Val Loss: 0.273664, Val Acc: 0.474227\n",
      "Epoch 331 - Train Loss: 0.265354, Train Acc: 0.503846 | Val Loss: 0.273644, Val Acc: 0.474227\n",
      "Epoch 332 - Train Loss: 0.265337, Train Acc: 0.503846 | Val Loss: 0.273624, Val Acc: 0.474227\n",
      "Epoch 333 - Train Loss: 0.265321, Train Acc: 0.503846 | Val Loss: 0.273605, Val Acc: 0.474227\n",
      "Epoch 334 - Train Loss: 0.265305, Train Acc: 0.503846 | Val Loss: 0.273585, Val Acc: 0.474227\n",
      "Epoch 335 - Train Loss: 0.265288, Train Acc: 0.503846 | Val Loss: 0.273566, Val Acc: 0.474227\n",
      "Epoch 336 - Train Loss: 0.265272, Train Acc: 0.503846 | Val Loss: 0.273546, Val Acc: 0.474227\n",
      "Epoch 337 - Train Loss: 0.265256, Train Acc: 0.503846 | Val Loss: 0.273527, Val Acc: 0.474227\n",
      "Epoch 338 - Train Loss: 0.265239, Train Acc: 0.503846 | Val Loss: 0.273507, Val Acc: 0.474227\n",
      "Epoch 339 - Train Loss: 0.265223, Train Acc: 0.503846 | Val Loss: 0.273488, Val Acc: 0.474227\n",
      "Epoch 340 - Train Loss: 0.265207, Train Acc: 0.503846 | Val Loss: 0.273469, Val Acc: 0.474227\n",
      "Epoch 341 - Train Loss: 0.265190, Train Acc: 0.503846 | Val Loss: 0.273450, Val Acc: 0.474227\n",
      "Epoch 342 - Train Loss: 0.265174, Train Acc: 0.503846 | Val Loss: 0.273430, Val Acc: 0.474227\n",
      "Epoch 343 - Train Loss: 0.265158, Train Acc: 0.503846 | Val Loss: 0.273411, Val Acc: 0.474227\n",
      "Epoch 344 - Train Loss: 0.265142, Train Acc: 0.503846 | Val Loss: 0.273392, Val Acc: 0.474227\n",
      "Epoch 345 - Train Loss: 0.265125, Train Acc: 0.503846 | Val Loss: 0.273373, Val Acc: 0.474227\n",
      "Epoch 346 - Train Loss: 0.265109, Train Acc: 0.503846 | Val Loss: 0.273354, Val Acc: 0.474227\n",
      "Epoch 347 - Train Loss: 0.265093, Train Acc: 0.503846 | Val Loss: 0.273335, Val Acc: 0.474227\n",
      "Epoch 348 - Train Loss: 0.265077, Train Acc: 0.503846 | Val Loss: 0.273317, Val Acc: 0.474227\n",
      "Epoch 349 - Train Loss: 0.265061, Train Acc: 0.503846 | Val Loss: 0.273298, Val Acc: 0.474227\n",
      "Epoch 350 - Train Loss: 0.265045, Train Acc: 0.503846 | Val Loss: 0.273279, Val Acc: 0.474227\n",
      "Epoch 351 - Train Loss: 0.265029, Train Acc: 0.503846 | Val Loss: 0.273261, Val Acc: 0.474227\n",
      "Epoch 352 - Train Loss: 0.265013, Train Acc: 0.503846 | Val Loss: 0.273242, Val Acc: 0.474227\n",
      "Epoch 353 - Train Loss: 0.264997, Train Acc: 0.503846 | Val Loss: 0.273223, Val Acc: 0.474227\n",
      "Epoch 354 - Train Loss: 0.264981, Train Acc: 0.503846 | Val Loss: 0.273205, Val Acc: 0.474227\n",
      "Epoch 355 - Train Loss: 0.264965, Train Acc: 0.503846 | Val Loss: 0.273186, Val Acc: 0.474227\n",
      "Epoch 356 - Train Loss: 0.264949, Train Acc: 0.503846 | Val Loss: 0.273168, Val Acc: 0.474227\n",
      "Epoch 357 - Train Loss: 0.264933, Train Acc: 0.503846 | Val Loss: 0.273149, Val Acc: 0.474227\n",
      "Epoch 358 - Train Loss: 0.264917, Train Acc: 0.503846 | Val Loss: 0.273131, Val Acc: 0.474227\n",
      "Epoch 359 - Train Loss: 0.264901, Train Acc: 0.503846 | Val Loss: 0.273113, Val Acc: 0.474227\n",
      "Epoch 360 - Train Loss: 0.264885, Train Acc: 0.503846 | Val Loss: 0.273094, Val Acc: 0.474227\n",
      "Epoch 361 - Train Loss: 0.264869, Train Acc: 0.503846 | Val Loss: 0.273076, Val Acc: 0.474227\n",
      "Epoch 362 - Train Loss: 0.264853, Train Acc: 0.503846 | Val Loss: 0.273057, Val Acc: 0.474227\n",
      "Epoch 363 - Train Loss: 0.264837, Train Acc: 0.503846 | Val Loss: 0.273039, Val Acc: 0.474227\n",
      "Epoch 364 - Train Loss: 0.264821, Train Acc: 0.503846 | Val Loss: 0.273021, Val Acc: 0.474227\n",
      "Epoch 365 - Train Loss: 0.264805, Train Acc: 0.503846 | Val Loss: 0.273003, Val Acc: 0.474227\n",
      "Epoch 366 - Train Loss: 0.264790, Train Acc: 0.503846 | Val Loss: 0.272984, Val Acc: 0.474227\n",
      "Epoch 367 - Train Loss: 0.264774, Train Acc: 0.503846 | Val Loss: 0.272966, Val Acc: 0.474227\n",
      "Epoch 368 - Train Loss: 0.264758, Train Acc: 0.503846 | Val Loss: 0.272948, Val Acc: 0.474227\n",
      "Epoch 369 - Train Loss: 0.264742, Train Acc: 0.503846 | Val Loss: 0.272930, Val Acc: 0.474227\n",
      "Epoch 370 - Train Loss: 0.264726, Train Acc: 0.503846 | Val Loss: 0.272912, Val Acc: 0.474227\n",
      "Epoch 371 - Train Loss: 0.264711, Train Acc: 0.503846 | Val Loss: 0.272893, Val Acc: 0.474227\n",
      "Epoch 372 - Train Loss: 0.264695, Train Acc: 0.503846 | Val Loss: 0.272875, Val Acc: 0.474227\n",
      "Epoch 373 - Train Loss: 0.264679, Train Acc: 0.503846 | Val Loss: 0.272857, Val Acc: 0.474227\n",
      "Epoch 374 - Train Loss: 0.264663, Train Acc: 0.503846 | Val Loss: 0.272839, Val Acc: 0.474227\n",
      "Epoch 375 - Train Loss: 0.264648, Train Acc: 0.503846 | Val Loss: 0.272821, Val Acc: 0.474227\n",
      "Epoch 376 - Train Loss: 0.264632, Train Acc: 0.503846 | Val Loss: 0.272803, Val Acc: 0.474227\n",
      "Epoch 377 - Train Loss: 0.264616, Train Acc: 0.503846 | Val Loss: 0.272785, Val Acc: 0.474227\n",
      "Epoch 378 - Train Loss: 0.264601, Train Acc: 0.503846 | Val Loss: 0.272767, Val Acc: 0.474227\n",
      "Epoch 379 - Train Loss: 0.264585, Train Acc: 0.503846 | Val Loss: 0.272750, Val Acc: 0.474227\n",
      "Epoch 380 - Train Loss: 0.264569, Train Acc: 0.503846 | Val Loss: 0.272732, Val Acc: 0.474227\n",
      "Epoch 381 - Train Loss: 0.264554, Train Acc: 0.503846 | Val Loss: 0.272714, Val Acc: 0.474227\n",
      "Epoch 382 - Train Loss: 0.264538, Train Acc: 0.503846 | Val Loss: 0.272696, Val Acc: 0.474227\n",
      "Epoch 383 - Train Loss: 0.264522, Train Acc: 0.503846 | Val Loss: 0.272678, Val Acc: 0.474227\n",
      "Epoch 384 - Train Loss: 0.264507, Train Acc: 0.503846 | Val Loss: 0.272660, Val Acc: 0.474227\n",
      "Epoch 385 - Train Loss: 0.264491, Train Acc: 0.503846 | Val Loss: 0.272643, Val Acc: 0.474227\n",
      "Epoch 386 - Train Loss: 0.264475, Train Acc: 0.503846 | Val Loss: 0.272625, Val Acc: 0.474227\n",
      "Epoch 387 - Train Loss: 0.264460, Train Acc: 0.503846 | Val Loss: 0.272607, Val Acc: 0.474227\n",
      "Epoch 388 - Train Loss: 0.264444, Train Acc: 0.503846 | Val Loss: 0.272589, Val Acc: 0.474227\n",
      "Epoch 389 - Train Loss: 0.264429, Train Acc: 0.503846 | Val Loss: 0.272571, Val Acc: 0.474227\n",
      "Epoch 390 - Train Loss: 0.264413, Train Acc: 0.503846 | Val Loss: 0.272554, Val Acc: 0.474227\n",
      "Epoch 391 - Train Loss: 0.264397, Train Acc: 0.503846 | Val Loss: 0.272536, Val Acc: 0.474227\n",
      "Epoch 392 - Train Loss: 0.264382, Train Acc: 0.503846 | Val Loss: 0.272518, Val Acc: 0.474227\n",
      "Epoch 393 - Train Loss: 0.264366, Train Acc: 0.503846 | Val Loss: 0.272501, Val Acc: 0.474227\n",
      "Epoch 394 - Train Loss: 0.264351, Train Acc: 0.503846 | Val Loss: 0.272483, Val Acc: 0.474227\n",
      "Epoch 395 - Train Loss: 0.264335, Train Acc: 0.503846 | Val Loss: 0.272465, Val Acc: 0.474227\n",
      "Epoch 396 - Train Loss: 0.264320, Train Acc: 0.503846 | Val Loss: 0.272448, Val Acc: 0.474227\n",
      "Epoch 397 - Train Loss: 0.264304, Train Acc: 0.503846 | Val Loss: 0.272430, Val Acc: 0.474227\n",
      "Epoch 398 - Train Loss: 0.264289, Train Acc: 0.503846 | Val Loss: 0.272413, Val Acc: 0.474227\n",
      "Epoch 399 - Train Loss: 0.264273, Train Acc: 0.503846 | Val Loss: 0.272395, Val Acc: 0.474227\n",
      "Epoch 400 - Train Loss: 0.264258, Train Acc: 0.503846 | Val Loss: 0.272378, Val Acc: 0.474227\n",
      "Epoch 401 - Train Loss: 0.264242, Train Acc: 0.503846 | Val Loss: 0.272360, Val Acc: 0.474227\n",
      "Epoch 402 - Train Loss: 0.264227, Train Acc: 0.503846 | Val Loss: 0.272343, Val Acc: 0.474227\n",
      "Epoch 403 - Train Loss: 0.264211, Train Acc: 0.503846 | Val Loss: 0.272326, Val Acc: 0.474227\n",
      "Epoch 404 - Train Loss: 0.264196, Train Acc: 0.503846 | Val Loss: 0.272308, Val Acc: 0.474227\n",
      "Epoch 405 - Train Loss: 0.264180, Train Acc: 0.503846 | Val Loss: 0.272291, Val Acc: 0.474227\n",
      "Epoch 406 - Train Loss: 0.264165, Train Acc: 0.503846 | Val Loss: 0.272273, Val Acc: 0.474227\n",
      "Epoch 407 - Train Loss: 0.264149, Train Acc: 0.503846 | Val Loss: 0.272256, Val Acc: 0.474227\n",
      "Epoch 408 - Train Loss: 0.264134, Train Acc: 0.503846 | Val Loss: 0.272239, Val Acc: 0.474227\n",
      "Epoch 409 - Train Loss: 0.264118, Train Acc: 0.503846 | Val Loss: 0.272222, Val Acc: 0.474227\n",
      "Epoch 410 - Train Loss: 0.264103, Train Acc: 0.503846 | Val Loss: 0.272204, Val Acc: 0.474227\n",
      "Epoch 411 - Train Loss: 0.264088, Train Acc: 0.503846 | Val Loss: 0.272187, Val Acc: 0.474227\n",
      "Epoch 412 - Train Loss: 0.264072, Train Acc: 0.503846 | Val Loss: 0.272170, Val Acc: 0.474227\n",
      "Epoch 413 - Train Loss: 0.264057, Train Acc: 0.503846 | Val Loss: 0.272153, Val Acc: 0.474227\n",
      "Epoch 414 - Train Loss: 0.264041, Train Acc: 0.503846 | Val Loss: 0.272136, Val Acc: 0.474227\n",
      "Epoch 415 - Train Loss: 0.264026, Train Acc: 0.503846 | Val Loss: 0.272119, Val Acc: 0.474227\n",
      "Epoch 416 - Train Loss: 0.264011, Train Acc: 0.503846 | Val Loss: 0.272101, Val Acc: 0.474227\n",
      "Epoch 417 - Train Loss: 0.263995, Train Acc: 0.503846 | Val Loss: 0.272084, Val Acc: 0.474227\n",
      "Epoch 418 - Train Loss: 0.263980, Train Acc: 0.503846 | Val Loss: 0.272067, Val Acc: 0.474227\n",
      "Epoch 419 - Train Loss: 0.263964, Train Acc: 0.503846 | Val Loss: 0.272050, Val Acc: 0.474227\n",
      "Epoch 420 - Train Loss: 0.263949, Train Acc: 0.503846 | Val Loss: 0.272033, Val Acc: 0.474227\n",
      "Epoch 421 - Train Loss: 0.263934, Train Acc: 0.503846 | Val Loss: 0.272016, Val Acc: 0.474227\n",
      "Epoch 422 - Train Loss: 0.263918, Train Acc: 0.503846 | Val Loss: 0.271999, Val Acc: 0.474227\n",
      "Epoch 423 - Train Loss: 0.263903, Train Acc: 0.503846 | Val Loss: 0.271982, Val Acc: 0.474227\n",
      "Epoch 424 - Train Loss: 0.263888, Train Acc: 0.503846 | Val Loss: 0.271965, Val Acc: 0.474227\n",
      "Epoch 425 - Train Loss: 0.263872, Train Acc: 0.503846 | Val Loss: 0.271948, Val Acc: 0.474227\n",
      "Epoch 426 - Train Loss: 0.263857, Train Acc: 0.503846 | Val Loss: 0.271931, Val Acc: 0.474227\n",
      "Epoch 427 - Train Loss: 0.263841, Train Acc: 0.503846 | Val Loss: 0.271914, Val Acc: 0.474227\n",
      "Epoch 428 - Train Loss: 0.263826, Train Acc: 0.503846 | Val Loss: 0.271897, Val Acc: 0.474227\n",
      "Epoch 429 - Train Loss: 0.263811, Train Acc: 0.503846 | Val Loss: 0.271880, Val Acc: 0.474227\n",
      "Epoch 430 - Train Loss: 0.263795, Train Acc: 0.503846 | Val Loss: 0.271864, Val Acc: 0.474227\n",
      "Epoch 431 - Train Loss: 0.263780, Train Acc: 0.503846 | Val Loss: 0.271847, Val Acc: 0.474227\n",
      "Epoch 432 - Train Loss: 0.263765, Train Acc: 0.503846 | Val Loss: 0.271830, Val Acc: 0.474227\n",
      "Epoch 433 - Train Loss: 0.263749, Train Acc: 0.503846 | Val Loss: 0.271813, Val Acc: 0.474227\n",
      "Epoch 434 - Train Loss: 0.263734, Train Acc: 0.503846 | Val Loss: 0.271796, Val Acc: 0.474227\n",
      "Epoch 435 - Train Loss: 0.263719, Train Acc: 0.503846 | Val Loss: 0.271779, Val Acc: 0.474227\n",
      "Epoch 436 - Train Loss: 0.263703, Train Acc: 0.503846 | Val Loss: 0.271763, Val Acc: 0.474227\n",
      "Epoch 437 - Train Loss: 0.263688, Train Acc: 0.503846 | Val Loss: 0.271746, Val Acc: 0.474227\n",
      "Epoch 438 - Train Loss: 0.263673, Train Acc: 0.503846 | Val Loss: 0.271729, Val Acc: 0.474227\n",
      "Epoch 439 - Train Loss: 0.263657, Train Acc: 0.503846 | Val Loss: 0.271712, Val Acc: 0.474227\n",
      "Epoch 440 - Train Loss: 0.263642, Train Acc: 0.503846 | Val Loss: 0.271696, Val Acc: 0.474227\n",
      "Epoch 441 - Train Loss: 0.263627, Train Acc: 0.503846 | Val Loss: 0.271679, Val Acc: 0.474227\n",
      "Epoch 442 - Train Loss: 0.263611, Train Acc: 0.503846 | Val Loss: 0.271662, Val Acc: 0.474227\n",
      "Epoch 443 - Train Loss: 0.263596, Train Acc: 0.503846 | Val Loss: 0.271645, Val Acc: 0.474227\n",
      "Epoch 444 - Train Loss: 0.263581, Train Acc: 0.503846 | Val Loss: 0.271629, Val Acc: 0.474227\n",
      "Epoch 445 - Train Loss: 0.263565, Train Acc: 0.503846 | Val Loss: 0.271612, Val Acc: 0.474227\n",
      "Epoch 446 - Train Loss: 0.263550, Train Acc: 0.503846 | Val Loss: 0.271595, Val Acc: 0.474227\n",
      "Epoch 447 - Train Loss: 0.263535, Train Acc: 0.503846 | Val Loss: 0.271579, Val Acc: 0.474227\n",
      "Epoch 448 - Train Loss: 0.263520, Train Acc: 0.503846 | Val Loss: 0.271562, Val Acc: 0.474227\n",
      "Epoch 449 - Train Loss: 0.263504, Train Acc: 0.503846 | Val Loss: 0.271545, Val Acc: 0.474227\n",
      "Epoch 450 - Train Loss: 0.263489, Train Acc: 0.503846 | Val Loss: 0.271529, Val Acc: 0.474227\n",
      "Epoch 451 - Train Loss: 0.263474, Train Acc: 0.503846 | Val Loss: 0.271512, Val Acc: 0.474227\n",
      "Epoch 452 - Train Loss: 0.263458, Train Acc: 0.503846 | Val Loss: 0.271496, Val Acc: 0.474227\n",
      "Epoch 453 - Train Loss: 0.263443, Train Acc: 0.503846 | Val Loss: 0.271479, Val Acc: 0.474227\n",
      "Epoch 454 - Train Loss: 0.263428, Train Acc: 0.503846 | Val Loss: 0.271462, Val Acc: 0.474227\n",
      "Epoch 455 - Train Loss: 0.263413, Train Acc: 0.503846 | Val Loss: 0.271446, Val Acc: 0.474227\n",
      "Epoch 456 - Train Loss: 0.263397, Train Acc: 0.503846 | Val Loss: 0.271429, Val Acc: 0.474227\n",
      "Epoch 457 - Train Loss: 0.263382, Train Acc: 0.503846 | Val Loss: 0.271413, Val Acc: 0.474227\n",
      "Epoch 458 - Train Loss: 0.263367, Train Acc: 0.503846 | Val Loss: 0.271396, Val Acc: 0.474227\n",
      "Epoch 459 - Train Loss: 0.263352, Train Acc: 0.503846 | Val Loss: 0.271380, Val Acc: 0.474227\n",
      "Epoch 460 - Train Loss: 0.263336, Train Acc: 0.503846 | Val Loss: 0.271363, Val Acc: 0.474227\n",
      "Epoch 461 - Train Loss: 0.263321, Train Acc: 0.503846 | Val Loss: 0.271347, Val Acc: 0.474227\n",
      "Epoch 462 - Train Loss: 0.263306, Train Acc: 0.503846 | Val Loss: 0.271330, Val Acc: 0.474227\n",
      "Epoch 463 - Train Loss: 0.263291, Train Acc: 0.503846 | Val Loss: 0.271314, Val Acc: 0.474227\n",
      "Epoch 464 - Train Loss: 0.263275, Train Acc: 0.503846 | Val Loss: 0.271297, Val Acc: 0.474227\n",
      "Epoch 465 - Train Loss: 0.263260, Train Acc: 0.503846 | Val Loss: 0.271281, Val Acc: 0.474227\n",
      "Epoch 466 - Train Loss: 0.263245, Train Acc: 0.503846 | Val Loss: 0.271264, Val Acc: 0.474227\n",
      "Epoch 467 - Train Loss: 0.263230, Train Acc: 0.503846 | Val Loss: 0.271248, Val Acc: 0.474227\n",
      "Epoch 468 - Train Loss: 0.263214, Train Acc: 0.503846 | Val Loss: 0.271231, Val Acc: 0.474227\n",
      "Epoch 469 - Train Loss: 0.263199, Train Acc: 0.503846 | Val Loss: 0.271215, Val Acc: 0.474227\n",
      "Epoch 470 - Train Loss: 0.263184, Train Acc: 0.503846 | Val Loss: 0.271198, Val Acc: 0.474227\n",
      "Epoch 471 - Train Loss: 0.263169, Train Acc: 0.503846 | Val Loss: 0.271182, Val Acc: 0.474227\n",
      "Epoch 472 - Train Loss: 0.263153, Train Acc: 0.503846 | Val Loss: 0.271165, Val Acc: 0.474227\n",
      "Epoch 473 - Train Loss: 0.263138, Train Acc: 0.503846 | Val Loss: 0.271149, Val Acc: 0.474227\n",
      "Epoch 474 - Train Loss: 0.263123, Train Acc: 0.503846 | Val Loss: 0.271133, Val Acc: 0.474227\n",
      "Epoch 475 - Train Loss: 0.263108, Train Acc: 0.503846 | Val Loss: 0.271116, Val Acc: 0.474227\n",
      "Epoch 476 - Train Loss: 0.263093, Train Acc: 0.503846 | Val Loss: 0.271100, Val Acc: 0.474227\n",
      "Epoch 477 - Train Loss: 0.263077, Train Acc: 0.503846 | Val Loss: 0.271083, Val Acc: 0.474227\n",
      "Epoch 478 - Train Loss: 0.263062, Train Acc: 0.503846 | Val Loss: 0.271067, Val Acc: 0.474227\n",
      "Epoch 479 - Train Loss: 0.263047, Train Acc: 0.503846 | Val Loss: 0.271051, Val Acc: 0.474227\n",
      "Epoch 480 - Train Loss: 0.263032, Train Acc: 0.503846 | Val Loss: 0.271034, Val Acc: 0.474227\n",
      "Epoch 481 - Train Loss: 0.263016, Train Acc: 0.503846 | Val Loss: 0.271018, Val Acc: 0.474227\n",
      "Epoch 482 - Train Loss: 0.263001, Train Acc: 0.503846 | Val Loss: 0.271002, Val Acc: 0.474227\n",
      "Epoch 483 - Train Loss: 0.262986, Train Acc: 0.503846 | Val Loss: 0.270985, Val Acc: 0.474227\n",
      "Epoch 484 - Train Loss: 0.262971, Train Acc: 0.503846 | Val Loss: 0.270969, Val Acc: 0.474227\n",
      "Epoch 485 - Train Loss: 0.262955, Train Acc: 0.503846 | Val Loss: 0.270953, Val Acc: 0.474227\n",
      "Epoch 486 - Train Loss: 0.262940, Train Acc: 0.503846 | Val Loss: 0.270937, Val Acc: 0.474227\n",
      "Epoch 487 - Train Loss: 0.262925, Train Acc: 0.503846 | Val Loss: 0.270920, Val Acc: 0.474227\n",
      "Epoch 488 - Train Loss: 0.262910, Train Acc: 0.503846 | Val Loss: 0.270904, Val Acc: 0.474227\n",
      "Epoch 489 - Train Loss: 0.262895, Train Acc: 0.503846 | Val Loss: 0.270888, Val Acc: 0.474227\n",
      "Epoch 490 - Train Loss: 0.262879, Train Acc: 0.503846 | Val Loss: 0.270872, Val Acc: 0.474227\n",
      "Epoch 491 - Train Loss: 0.262864, Train Acc: 0.503846 | Val Loss: 0.270855, Val Acc: 0.474227\n",
      "Epoch 492 - Train Loss: 0.262849, Train Acc: 0.503846 | Val Loss: 0.270839, Val Acc: 0.474227\n",
      "Epoch 493 - Train Loss: 0.262834, Train Acc: 0.503846 | Val Loss: 0.270823, Val Acc: 0.474227\n",
      "Epoch 494 - Train Loss: 0.262818, Train Acc: 0.503846 | Val Loss: 0.270807, Val Acc: 0.474227\n",
      "Epoch 495 - Train Loss: 0.262803, Train Acc: 0.503846 | Val Loss: 0.270790, Val Acc: 0.474227\n",
      "Epoch 496 - Train Loss: 0.262788, Train Acc: 0.503846 | Val Loss: 0.270774, Val Acc: 0.474227\n",
      "Epoch 497 - Train Loss: 0.262773, Train Acc: 0.503846 | Val Loss: 0.270758, Val Acc: 0.474227\n",
      "Epoch 498 - Train Loss: 0.262758, Train Acc: 0.503846 | Val Loss: 0.270742, Val Acc: 0.474227\n",
      "Epoch 499 - Train Loss: 0.262742, Train Acc: 0.503846 | Val Loss: 0.270726, Val Acc: 0.474227\n",
      "Epoch 500 - Train Loss: 0.262727, Train Acc: 0.503846 | Val Loss: 0.270709, Val Acc: 0.474227\n",
      "Epoch 501 - Train Loss: 0.262712, Train Acc: 0.503846 | Val Loss: 0.270693, Val Acc: 0.474227\n",
      "Epoch 502 - Train Loss: 0.262697, Train Acc: 0.503846 | Val Loss: 0.270677, Val Acc: 0.474227\n",
      "Epoch 503 - Train Loss: 0.262681, Train Acc: 0.503846 | Val Loss: 0.270661, Val Acc: 0.474227\n",
      "Epoch 504 - Train Loss: 0.262666, Train Acc: 0.503846 | Val Loss: 0.270645, Val Acc: 0.474227\n",
      "Epoch 505 - Train Loss: 0.262651, Train Acc: 0.503846 | Val Loss: 0.270628, Val Acc: 0.474227\n",
      "Epoch 506 - Train Loss: 0.262636, Train Acc: 0.503846 | Val Loss: 0.270612, Val Acc: 0.474227\n",
      "Epoch 507 - Train Loss: 0.262621, Train Acc: 0.503846 | Val Loss: 0.270596, Val Acc: 0.474227\n",
      "Epoch 508 - Train Loss: 0.262605, Train Acc: 0.503846 | Val Loss: 0.270580, Val Acc: 0.474227\n",
      "Epoch 509 - Train Loss: 0.262590, Train Acc: 0.503846 | Val Loss: 0.270564, Val Acc: 0.474227\n",
      "Epoch 510 - Train Loss: 0.262575, Train Acc: 0.503846 | Val Loss: 0.270547, Val Acc: 0.474227\n",
      "Epoch 511 - Train Loss: 0.262560, Train Acc: 0.503846 | Val Loss: 0.270531, Val Acc: 0.474227\n",
      "Epoch 512 - Train Loss: 0.262545, Train Acc: 0.503846 | Val Loss: 0.270515, Val Acc: 0.474227\n",
      "Epoch 513 - Train Loss: 0.262529, Train Acc: 0.503846 | Val Loss: 0.270499, Val Acc: 0.474227\n",
      "Epoch 514 - Train Loss: 0.262514, Train Acc: 0.503846 | Val Loss: 0.270483, Val Acc: 0.474227\n",
      "Epoch 515 - Train Loss: 0.262499, Train Acc: 0.503846 | Val Loss: 0.270467, Val Acc: 0.474227\n",
      "Epoch 516 - Train Loss: 0.262484, Train Acc: 0.503846 | Val Loss: 0.270451, Val Acc: 0.474227\n",
      "Epoch 517 - Train Loss: 0.262469, Train Acc: 0.503846 | Val Loss: 0.270434, Val Acc: 0.474227\n",
      "Epoch 518 - Train Loss: 0.262453, Train Acc: 0.503846 | Val Loss: 0.270418, Val Acc: 0.474227\n",
      "Epoch 519 - Train Loss: 0.262438, Train Acc: 0.503846 | Val Loss: 0.270402, Val Acc: 0.474227\n",
      "Epoch 520 - Train Loss: 0.262423, Train Acc: 0.503846 | Val Loss: 0.270386, Val Acc: 0.474227\n",
      "Epoch 521 - Train Loss: 0.262408, Train Acc: 0.503846 | Val Loss: 0.270370, Val Acc: 0.474227\n",
      "Epoch 522 - Train Loss: 0.262393, Train Acc: 0.503846 | Val Loss: 0.270354, Val Acc: 0.474227\n",
      "Epoch 523 - Train Loss: 0.262377, Train Acc: 0.503846 | Val Loss: 0.270338, Val Acc: 0.474227\n",
      "Epoch 524 - Train Loss: 0.262362, Train Acc: 0.503846 | Val Loss: 0.270322, Val Acc: 0.474227\n",
      "Epoch 525 - Train Loss: 0.262347, Train Acc: 0.503846 | Val Loss: 0.270306, Val Acc: 0.474227\n",
      "Epoch 526 - Train Loss: 0.262332, Train Acc: 0.503846 | Val Loss: 0.270290, Val Acc: 0.474227\n",
      "Epoch 527 - Train Loss: 0.262317, Train Acc: 0.503846 | Val Loss: 0.270274, Val Acc: 0.474227\n",
      "Epoch 528 - Train Loss: 0.262301, Train Acc: 0.503846 | Val Loss: 0.270257, Val Acc: 0.474227\n",
      "Epoch 529 - Train Loss: 0.262286, Train Acc: 0.503846 | Val Loss: 0.270241, Val Acc: 0.474227\n",
      "Epoch 530 - Train Loss: 0.262271, Train Acc: 0.503846 | Val Loss: 0.270225, Val Acc: 0.474227\n",
      "Epoch 531 - Train Loss: 0.262256, Train Acc: 0.503846 | Val Loss: 0.270209, Val Acc: 0.474227\n",
      "Epoch 532 - Train Loss: 0.262241, Train Acc: 0.503846 | Val Loss: 0.270193, Val Acc: 0.474227\n",
      "Epoch 533 - Train Loss: 0.262226, Train Acc: 0.503846 | Val Loss: 0.270177, Val Acc: 0.474227\n",
      "Epoch 534 - Train Loss: 0.262210, Train Acc: 0.503846 | Val Loss: 0.270161, Val Acc: 0.474227\n",
      "Epoch 535 - Train Loss: 0.262195, Train Acc: 0.503846 | Val Loss: 0.270145, Val Acc: 0.474227\n",
      "Epoch 536 - Train Loss: 0.262180, Train Acc: 0.503846 | Val Loss: 0.270129, Val Acc: 0.474227\n",
      "Epoch 537 - Train Loss: 0.262165, Train Acc: 0.503846 | Val Loss: 0.270113, Val Acc: 0.474227\n",
      "Epoch 538 - Train Loss: 0.262150, Train Acc: 0.503846 | Val Loss: 0.270096, Val Acc: 0.474227\n",
      "Epoch 539 - Train Loss: 0.262134, Train Acc: 0.503846 | Val Loss: 0.270080, Val Acc: 0.474227\n",
      "Epoch 540 - Train Loss: 0.262119, Train Acc: 0.503846 | Val Loss: 0.270064, Val Acc: 0.474227\n",
      "Epoch 541 - Train Loss: 0.262104, Train Acc: 0.503846 | Val Loss: 0.270048, Val Acc: 0.474227\n",
      "Epoch 542 - Train Loss: 0.262089, Train Acc: 0.503846 | Val Loss: 0.270032, Val Acc: 0.474227\n",
      "Epoch 543 - Train Loss: 0.262074, Train Acc: 0.503846 | Val Loss: 0.270016, Val Acc: 0.474227\n",
      "Epoch 544 - Train Loss: 0.262058, Train Acc: 0.503846 | Val Loss: 0.270000, Val Acc: 0.474227\n",
      "Epoch 545 - Train Loss: 0.262043, Train Acc: 0.503846 | Val Loss: 0.269984, Val Acc: 0.474227\n",
      "Epoch 546 - Train Loss: 0.262028, Train Acc: 0.503846 | Val Loss: 0.269968, Val Acc: 0.474227\n",
      "Epoch 547 - Train Loss: 0.262013, Train Acc: 0.503846 | Val Loss: 0.269952, Val Acc: 0.474227\n",
      "Epoch 548 - Train Loss: 0.261998, Train Acc: 0.503846 | Val Loss: 0.269936, Val Acc: 0.474227\n",
      "Epoch 549 - Train Loss: 0.261982, Train Acc: 0.503846 | Val Loss: 0.269919, Val Acc: 0.474227\n",
      "Epoch 550 - Train Loss: 0.261967, Train Acc: 0.503846 | Val Loss: 0.269903, Val Acc: 0.474227\n",
      "Epoch 551 - Train Loss: 0.261952, Train Acc: 0.503846 | Val Loss: 0.269887, Val Acc: 0.474227\n",
      "Epoch 552 - Train Loss: 0.261937, Train Acc: 0.503846 | Val Loss: 0.269871, Val Acc: 0.474227\n",
      "Epoch 553 - Train Loss: 0.261921, Train Acc: 0.503846 | Val Loss: 0.269855, Val Acc: 0.474227\n",
      "Epoch 554 - Train Loss: 0.261906, Train Acc: 0.503846 | Val Loss: 0.269839, Val Acc: 0.474227\n",
      "Epoch 555 - Train Loss: 0.261891, Train Acc: 0.503846 | Val Loss: 0.269823, Val Acc: 0.474227\n",
      "Epoch 556 - Train Loss: 0.261876, Train Acc: 0.503846 | Val Loss: 0.269807, Val Acc: 0.474227\n",
      "Epoch 557 - Train Loss: 0.261861, Train Acc: 0.503846 | Val Loss: 0.269791, Val Acc: 0.474227\n",
      "Epoch 558 - Train Loss: 0.261845, Train Acc: 0.503846 | Val Loss: 0.269775, Val Acc: 0.474227\n",
      "Epoch 559 - Train Loss: 0.261830, Train Acc: 0.503846 | Val Loss: 0.269759, Val Acc: 0.474227\n",
      "Epoch 560 - Train Loss: 0.261815, Train Acc: 0.503846 | Val Loss: 0.269743, Val Acc: 0.474227\n",
      "Epoch 561 - Train Loss: 0.261800, Train Acc: 0.503846 | Val Loss: 0.269727, Val Acc: 0.474227\n",
      "Epoch 562 - Train Loss: 0.261784, Train Acc: 0.503846 | Val Loss: 0.269710, Val Acc: 0.474227\n",
      "Epoch 563 - Train Loss: 0.261769, Train Acc: 0.503846 | Val Loss: 0.269694, Val Acc: 0.474227\n",
      "Epoch 564 - Train Loss: 0.261754, Train Acc: 0.503846 | Val Loss: 0.269678, Val Acc: 0.474227\n",
      "Epoch 565 - Train Loss: 0.261739, Train Acc: 0.503846 | Val Loss: 0.269662, Val Acc: 0.474227\n",
      "Epoch 566 - Train Loss: 0.261724, Train Acc: 0.503846 | Val Loss: 0.269646, Val Acc: 0.474227\n",
      "Epoch 567 - Train Loss: 0.261708, Train Acc: 0.503846 | Val Loss: 0.269630, Val Acc: 0.474227\n",
      "Epoch 568 - Train Loss: 0.261693, Train Acc: 0.503846 | Val Loss: 0.269614, Val Acc: 0.474227\n",
      "Epoch 569 - Train Loss: 0.261678, Train Acc: 0.503846 | Val Loss: 0.269598, Val Acc: 0.474227\n",
      "Epoch 570 - Train Loss: 0.261663, Train Acc: 0.503846 | Val Loss: 0.269582, Val Acc: 0.474227\n",
      "Epoch 571 - Train Loss: 0.261647, Train Acc: 0.503846 | Val Loss: 0.269566, Val Acc: 0.474227\n",
      "Epoch 572 - Train Loss: 0.261632, Train Acc: 0.503846 | Val Loss: 0.269550, Val Acc: 0.474227\n",
      "Epoch 573 - Train Loss: 0.261617, Train Acc: 0.503846 | Val Loss: 0.269534, Val Acc: 0.474227\n",
      "Epoch 574 - Train Loss: 0.261602, Train Acc: 0.503846 | Val Loss: 0.269518, Val Acc: 0.474227\n",
      "Epoch 575 - Train Loss: 0.261586, Train Acc: 0.503846 | Val Loss: 0.269502, Val Acc: 0.474227\n",
      "Epoch 576 - Train Loss: 0.261571, Train Acc: 0.503846 | Val Loss: 0.269486, Val Acc: 0.474227\n",
      "Epoch 577 - Train Loss: 0.261556, Train Acc: 0.503846 | Val Loss: 0.269470, Val Acc: 0.474227\n",
      "Epoch 578 - Train Loss: 0.261541, Train Acc: 0.503846 | Val Loss: 0.269454, Val Acc: 0.474227\n",
      "Epoch 579 - Train Loss: 0.261525, Train Acc: 0.503846 | Val Loss: 0.269438, Val Acc: 0.474227\n",
      "Epoch 580 - Train Loss: 0.261510, Train Acc: 0.503846 | Val Loss: 0.269422, Val Acc: 0.474227\n",
      "Epoch 581 - Train Loss: 0.261495, Train Acc: 0.503846 | Val Loss: 0.269406, Val Acc: 0.474227\n",
      "Epoch 582 - Train Loss: 0.261480, Train Acc: 0.503846 | Val Loss: 0.269389, Val Acc: 0.474227\n",
      "Epoch 583 - Train Loss: 0.261464, Train Acc: 0.503846 | Val Loss: 0.269373, Val Acc: 0.474227\n",
      "Epoch 584 - Train Loss: 0.261449, Train Acc: 0.503846 | Val Loss: 0.269357, Val Acc: 0.474227\n",
      "Epoch 585 - Train Loss: 0.261434, Train Acc: 0.503846 | Val Loss: 0.269341, Val Acc: 0.474227\n",
      "Epoch 586 - Train Loss: 0.261418, Train Acc: 0.503846 | Val Loss: 0.269325, Val Acc: 0.474227\n",
      "Epoch 587 - Train Loss: 0.261403, Train Acc: 0.503846 | Val Loss: 0.269309, Val Acc: 0.474227\n",
      "Epoch 588 - Train Loss: 0.261388, Train Acc: 0.503846 | Val Loss: 0.269293, Val Acc: 0.474227\n",
      "Epoch 589 - Train Loss: 0.261373, Train Acc: 0.503846 | Val Loss: 0.269277, Val Acc: 0.474227\n",
      "Epoch 590 - Train Loss: 0.261357, Train Acc: 0.503846 | Val Loss: 0.269260, Val Acc: 0.474227\n",
      "Epoch 591 - Train Loss: 0.261342, Train Acc: 0.503846 | Val Loss: 0.269244, Val Acc: 0.474227\n",
      "Epoch 592 - Train Loss: 0.261327, Train Acc: 0.503846 | Val Loss: 0.269228, Val Acc: 0.474227\n",
      "Epoch 593 - Train Loss: 0.261311, Train Acc: 0.503846 | Val Loss: 0.269212, Val Acc: 0.474227\n",
      "Epoch 594 - Train Loss: 0.261296, Train Acc: 0.503846 | Val Loss: 0.269196, Val Acc: 0.474227\n",
      "Epoch 595 - Train Loss: 0.261281, Train Acc: 0.503846 | Val Loss: 0.269180, Val Acc: 0.474227\n",
      "Epoch 596 - Train Loss: 0.261266, Train Acc: 0.503846 | Val Loss: 0.269164, Val Acc: 0.474227\n",
      "Epoch 597 - Train Loss: 0.261250, Train Acc: 0.503846 | Val Loss: 0.269148, Val Acc: 0.474227\n",
      "Epoch 598 - Train Loss: 0.261235, Train Acc: 0.503846 | Val Loss: 0.269132, Val Acc: 0.474227\n",
      "Epoch 599 - Train Loss: 0.261220, Train Acc: 0.503846 | Val Loss: 0.269115, Val Acc: 0.474227\n",
      "Epoch 600 - Train Loss: 0.261204, Train Acc: 0.503846 | Val Loss: 0.269099, Val Acc: 0.474227\n",
      "Epoch 601 - Train Loss: 0.261189, Train Acc: 0.503846 | Val Loss: 0.269083, Val Acc: 0.474227\n",
      "Epoch 602 - Train Loss: 0.261174, Train Acc: 0.503846 | Val Loss: 0.269067, Val Acc: 0.474227\n",
      "Epoch 603 - Train Loss: 0.261159, Train Acc: 0.503846 | Val Loss: 0.269051, Val Acc: 0.474227\n",
      "Epoch 604 - Train Loss: 0.261143, Train Acc: 0.503846 | Val Loss: 0.269035, Val Acc: 0.474227\n",
      "Epoch 605 - Train Loss: 0.261128, Train Acc: 0.503846 | Val Loss: 0.269018, Val Acc: 0.474227\n",
      "Epoch 606 - Train Loss: 0.261113, Train Acc: 0.503846 | Val Loss: 0.269002, Val Acc: 0.474227\n",
      "Epoch 607 - Train Loss: 0.261097, Train Acc: 0.503846 | Val Loss: 0.268986, Val Acc: 0.474227\n",
      "Epoch 608 - Train Loss: 0.261082, Train Acc: 0.503846 | Val Loss: 0.268970, Val Acc: 0.474227\n",
      "Epoch 609 - Train Loss: 0.261066, Train Acc: 0.503846 | Val Loss: 0.268953, Val Acc: 0.474227\n",
      "Epoch 610 - Train Loss: 0.261051, Train Acc: 0.503846 | Val Loss: 0.268937, Val Acc: 0.474227\n",
      "Epoch 611 - Train Loss: 0.261036, Train Acc: 0.503846 | Val Loss: 0.268921, Val Acc: 0.474227\n",
      "Epoch 612 - Train Loss: 0.261020, Train Acc: 0.503846 | Val Loss: 0.268905, Val Acc: 0.474227\n",
      "Epoch 613 - Train Loss: 0.261005, Train Acc: 0.503846 | Val Loss: 0.268888, Val Acc: 0.474227\n",
      "Epoch 614 - Train Loss: 0.260989, Train Acc: 0.503846 | Val Loss: 0.268872, Val Acc: 0.474227\n",
      "Epoch 615 - Train Loss: 0.260974, Train Acc: 0.503846 | Val Loss: 0.268856, Val Acc: 0.474227\n",
      "Epoch 616 - Train Loss: 0.260959, Train Acc: 0.503846 | Val Loss: 0.268839, Val Acc: 0.474227\n",
      "Epoch 617 - Train Loss: 0.260943, Train Acc: 0.503846 | Val Loss: 0.268823, Val Acc: 0.474227\n",
      "Epoch 618 - Train Loss: 0.260928, Train Acc: 0.503846 | Val Loss: 0.268807, Val Acc: 0.474227\n",
      "Epoch 619 - Train Loss: 0.260912, Train Acc: 0.503846 | Val Loss: 0.268791, Val Acc: 0.474227\n",
      "Epoch 620 - Train Loss: 0.260897, Train Acc: 0.503846 | Val Loss: 0.268774, Val Acc: 0.474227\n",
      "Epoch 621 - Train Loss: 0.260881, Train Acc: 0.503846 | Val Loss: 0.268758, Val Acc: 0.474227\n",
      "Epoch 622 - Train Loss: 0.260866, Train Acc: 0.503846 | Val Loss: 0.268742, Val Acc: 0.474227\n",
      "Epoch 623 - Train Loss: 0.260851, Train Acc: 0.503846 | Val Loss: 0.268725, Val Acc: 0.474227\n",
      "Epoch 624 - Train Loss: 0.260835, Train Acc: 0.503846 | Val Loss: 0.268709, Val Acc: 0.474227\n",
      "Epoch 625 - Train Loss: 0.260820, Train Acc: 0.503846 | Val Loss: 0.268693, Val Acc: 0.474227\n",
      "Epoch 626 - Train Loss: 0.260804, Train Acc: 0.503846 | Val Loss: 0.268677, Val Acc: 0.474227\n",
      "Epoch 627 - Train Loss: 0.260789, Train Acc: 0.503846 | Val Loss: 0.268660, Val Acc: 0.474227\n",
      "Epoch 628 - Train Loss: 0.260773, Train Acc: 0.503846 | Val Loss: 0.268644, Val Acc: 0.474227\n",
      "Epoch 629 - Train Loss: 0.260758, Train Acc: 0.503846 | Val Loss: 0.268628, Val Acc: 0.474227\n",
      "Epoch 630 - Train Loss: 0.260743, Train Acc: 0.503846 | Val Loss: 0.268611, Val Acc: 0.474227\n",
      "Epoch 631 - Train Loss: 0.260727, Train Acc: 0.503846 | Val Loss: 0.268595, Val Acc: 0.474227\n",
      "Epoch 632 - Train Loss: 0.260712, Train Acc: 0.503846 | Val Loss: 0.268579, Val Acc: 0.474227\n",
      "Epoch 633 - Train Loss: 0.260696, Train Acc: 0.503846 | Val Loss: 0.268563, Val Acc: 0.474227\n",
      "Epoch 634 - Train Loss: 0.260681, Train Acc: 0.503846 | Val Loss: 0.268546, Val Acc: 0.474227\n",
      "Epoch 635 - Train Loss: 0.260665, Train Acc: 0.503846 | Val Loss: 0.268530, Val Acc: 0.474227\n",
      "Epoch 636 - Train Loss: 0.260650, Train Acc: 0.503846 | Val Loss: 0.268514, Val Acc: 0.474227\n",
      "Epoch 637 - Train Loss: 0.260634, Train Acc: 0.503846 | Val Loss: 0.268498, Val Acc: 0.474227\n",
      "Epoch 638 - Train Loss: 0.260619, Train Acc: 0.503846 | Val Loss: 0.268482, Val Acc: 0.474227\n",
      "Epoch 639 - Train Loss: 0.260604, Train Acc: 0.503846 | Val Loss: 0.268465, Val Acc: 0.474227\n",
      "Epoch 640 - Train Loss: 0.260588, Train Acc: 0.503846 | Val Loss: 0.268449, Val Acc: 0.474227\n",
      "Epoch 641 - Train Loss: 0.260573, Train Acc: 0.503846 | Val Loss: 0.268433, Val Acc: 0.474227\n",
      "Epoch 642 - Train Loss: 0.260557, Train Acc: 0.503846 | Val Loss: 0.268417, Val Acc: 0.474227\n",
      "Epoch 643 - Train Loss: 0.260542, Train Acc: 0.503846 | Val Loss: 0.268401, Val Acc: 0.474227\n",
      "Epoch 644 - Train Loss: 0.260526, Train Acc: 0.503846 | Val Loss: 0.268384, Val Acc: 0.474227\n",
      "Epoch 645 - Train Loss: 0.260511, Train Acc: 0.503846 | Val Loss: 0.268368, Val Acc: 0.474227\n",
      "Epoch 646 - Train Loss: 0.260495, Train Acc: 0.503846 | Val Loss: 0.268352, Val Acc: 0.474227\n",
      "Epoch 647 - Train Loss: 0.260480, Train Acc: 0.503846 | Val Loss: 0.268336, Val Acc: 0.474227\n",
      "Epoch 648 - Train Loss: 0.260465, Train Acc: 0.503846 | Val Loss: 0.268319, Val Acc: 0.474227\n",
      "Epoch 649 - Train Loss: 0.260449, Train Acc: 0.503846 | Val Loss: 0.268303, Val Acc: 0.474227\n",
      "Epoch 650 - Train Loss: 0.260434, Train Acc: 0.503846 | Val Loss: 0.268287, Val Acc: 0.474227\n",
      "Epoch 651 - Train Loss: 0.260418, Train Acc: 0.503846 | Val Loss: 0.268271, Val Acc: 0.474227\n",
      "Epoch 652 - Train Loss: 0.260403, Train Acc: 0.503846 | Val Loss: 0.268254, Val Acc: 0.474227\n",
      "Epoch 653 - Train Loss: 0.260387, Train Acc: 0.503846 | Val Loss: 0.268238, Val Acc: 0.474227\n",
      "Epoch 654 - Train Loss: 0.260372, Train Acc: 0.503846 | Val Loss: 0.268222, Val Acc: 0.474227\n",
      "Epoch 655 - Train Loss: 0.260356, Train Acc: 0.503846 | Val Loss: 0.268206, Val Acc: 0.474227\n",
      "Epoch 656 - Train Loss: 0.260341, Train Acc: 0.503846 | Val Loss: 0.268189, Val Acc: 0.474227\n",
      "Epoch 657 - Train Loss: 0.260325, Train Acc: 0.503846 | Val Loss: 0.268173, Val Acc: 0.474227\n",
      "Epoch 658 - Train Loss: 0.260310, Train Acc: 0.503846 | Val Loss: 0.268157, Val Acc: 0.474227\n",
      "Epoch 659 - Train Loss: 0.260294, Train Acc: 0.503846 | Val Loss: 0.268140, Val Acc: 0.474227\n",
      "Epoch 660 - Train Loss: 0.260278, Train Acc: 0.503846 | Val Loss: 0.268124, Val Acc: 0.474227\n",
      "Epoch 661 - Train Loss: 0.260263, Train Acc: 0.503846 | Val Loss: 0.268108, Val Acc: 0.474227\n",
      "Epoch 662 - Train Loss: 0.260247, Train Acc: 0.503846 | Val Loss: 0.268091, Val Acc: 0.474227\n",
      "Epoch 663 - Train Loss: 0.260232, Train Acc: 0.503846 | Val Loss: 0.268075, Val Acc: 0.474227\n",
      "Epoch 664 - Train Loss: 0.260216, Train Acc: 0.503846 | Val Loss: 0.268059, Val Acc: 0.474227\n",
      "Epoch 665 - Train Loss: 0.260201, Train Acc: 0.503846 | Val Loss: 0.268042, Val Acc: 0.474227\n",
      "Epoch 666 - Train Loss: 0.260185, Train Acc: 0.503846 | Val Loss: 0.268026, Val Acc: 0.474227\n",
      "Epoch 667 - Train Loss: 0.260170, Train Acc: 0.503846 | Val Loss: 0.268009, Val Acc: 0.474227\n",
      "Epoch 668 - Train Loss: 0.260154, Train Acc: 0.503846 | Val Loss: 0.267993, Val Acc: 0.474227\n",
      "Epoch 669 - Train Loss: 0.260138, Train Acc: 0.503846 | Val Loss: 0.267977, Val Acc: 0.474227\n",
      "Epoch 670 - Train Loss: 0.260123, Train Acc: 0.503846 | Val Loss: 0.267960, Val Acc: 0.474227\n",
      "Epoch 671 - Train Loss: 0.260107, Train Acc: 0.503846 | Val Loss: 0.267944, Val Acc: 0.474227\n",
      "Epoch 672 - Train Loss: 0.260092, Train Acc: 0.503846 | Val Loss: 0.267927, Val Acc: 0.474227\n",
      "Epoch 673 - Train Loss: 0.260076, Train Acc: 0.503846 | Val Loss: 0.267911, Val Acc: 0.474227\n",
      "Epoch 674 - Train Loss: 0.260060, Train Acc: 0.503846 | Val Loss: 0.267895, Val Acc: 0.474227\n",
      "Epoch 675 - Train Loss: 0.260045, Train Acc: 0.503846 | Val Loss: 0.267878, Val Acc: 0.474227\n",
      "Epoch 676 - Train Loss: 0.260029, Train Acc: 0.503846 | Val Loss: 0.267862, Val Acc: 0.474227\n",
      "Epoch 677 - Train Loss: 0.260014, Train Acc: 0.503846 | Val Loss: 0.267846, Val Acc: 0.474227\n",
      "Epoch 678 - Train Loss: 0.259998, Train Acc: 0.503846 | Val Loss: 0.267830, Val Acc: 0.474227\n",
      "Epoch 679 - Train Loss: 0.259982, Train Acc: 0.503846 | Val Loss: 0.267813, Val Acc: 0.474227\n",
      "Epoch 680 - Train Loss: 0.259967, Train Acc: 0.503846 | Val Loss: 0.267797, Val Acc: 0.474227\n",
      "Epoch 681 - Train Loss: 0.259951, Train Acc: 0.503846 | Val Loss: 0.267781, Val Acc: 0.474227\n",
      "Epoch 682 - Train Loss: 0.259935, Train Acc: 0.503846 | Val Loss: 0.267764, Val Acc: 0.474227\n",
      "Epoch 683 - Train Loss: 0.259920, Train Acc: 0.503846 | Val Loss: 0.267748, Val Acc: 0.474227\n",
      "Epoch 684 - Train Loss: 0.259904, Train Acc: 0.503846 | Val Loss: 0.267732, Val Acc: 0.474227\n",
      "Epoch 685 - Train Loss: 0.259888, Train Acc: 0.503846 | Val Loss: 0.267716, Val Acc: 0.474227\n",
      "Epoch 686 - Train Loss: 0.259873, Train Acc: 0.503846 | Val Loss: 0.267699, Val Acc: 0.474227\n",
      "Epoch 687 - Train Loss: 0.259857, Train Acc: 0.503846 | Val Loss: 0.267683, Val Acc: 0.474227\n",
      "Epoch 688 - Train Loss: 0.259841, Train Acc: 0.503846 | Val Loss: 0.267667, Val Acc: 0.474227\n",
      "Epoch 689 - Train Loss: 0.259826, Train Acc: 0.503846 | Val Loss: 0.267650, Val Acc: 0.474227\n",
      "Epoch 690 - Train Loss: 0.259810, Train Acc: 0.503846 | Val Loss: 0.267634, Val Acc: 0.474227\n",
      "Epoch 691 - Train Loss: 0.259794, Train Acc: 0.503846 | Val Loss: 0.267618, Val Acc: 0.474227\n",
      "Epoch 692 - Train Loss: 0.259779, Train Acc: 0.503846 | Val Loss: 0.267601, Val Acc: 0.474227\n",
      "Epoch 693 - Train Loss: 0.259763, Train Acc: 0.503846 | Val Loss: 0.267585, Val Acc: 0.474227\n",
      "Epoch 694 - Train Loss: 0.259747, Train Acc: 0.503846 | Val Loss: 0.267569, Val Acc: 0.474227\n",
      "Epoch 695 - Train Loss: 0.259732, Train Acc: 0.503846 | Val Loss: 0.267553, Val Acc: 0.474227\n",
      "Epoch 696 - Train Loss: 0.259716, Train Acc: 0.503846 | Val Loss: 0.267536, Val Acc: 0.474227\n",
      "Epoch 697 - Train Loss: 0.259700, Train Acc: 0.503846 | Val Loss: 0.267520, Val Acc: 0.474227\n",
      "Epoch 698 - Train Loss: 0.259685, Train Acc: 0.503846 | Val Loss: 0.267504, Val Acc: 0.474227\n",
      "Epoch 699 - Train Loss: 0.259669, Train Acc: 0.503846 | Val Loss: 0.267487, Val Acc: 0.474227\n",
      "Epoch 700 - Train Loss: 0.259653, Train Acc: 0.503846 | Val Loss: 0.267471, Val Acc: 0.474227\n",
      "Epoch 701 - Train Loss: 0.259638, Train Acc: 0.503846 | Val Loss: 0.267455, Val Acc: 0.474227\n",
      "Epoch 702 - Train Loss: 0.259622, Train Acc: 0.503846 | Val Loss: 0.267438, Val Acc: 0.474227\n",
      "Epoch 703 - Train Loss: 0.259606, Train Acc: 0.503846 | Val Loss: 0.267422, Val Acc: 0.474227\n",
      "Epoch 704 - Train Loss: 0.259590, Train Acc: 0.503846 | Val Loss: 0.267406, Val Acc: 0.474227\n",
      "Epoch 705 - Train Loss: 0.259575, Train Acc: 0.503846 | Val Loss: 0.267389, Val Acc: 0.474227\n",
      "Epoch 706 - Train Loss: 0.259559, Train Acc: 0.503846 | Val Loss: 0.267373, Val Acc: 0.474227\n",
      "Epoch 707 - Train Loss: 0.259543, Train Acc: 0.503846 | Val Loss: 0.267357, Val Acc: 0.474227\n",
      "Epoch 708 - Train Loss: 0.259528, Train Acc: 0.503846 | Val Loss: 0.267340, Val Acc: 0.474227\n",
      "Epoch 709 - Train Loss: 0.259512, Train Acc: 0.503846 | Val Loss: 0.267324, Val Acc: 0.474227\n",
      "Epoch 710 - Train Loss: 0.259496, Train Acc: 0.503846 | Val Loss: 0.267308, Val Acc: 0.474227\n",
      "Epoch 711 - Train Loss: 0.259480, Train Acc: 0.503846 | Val Loss: 0.267291, Val Acc: 0.474227\n",
      "Epoch 712 - Train Loss: 0.259465, Train Acc: 0.503846 | Val Loss: 0.267275, Val Acc: 0.474227\n",
      "Epoch 713 - Train Loss: 0.259449, Train Acc: 0.503846 | Val Loss: 0.267259, Val Acc: 0.474227\n",
      "Epoch 714 - Train Loss: 0.259433, Train Acc: 0.503846 | Val Loss: 0.267242, Val Acc: 0.474227\n",
      "Epoch 715 - Train Loss: 0.259417, Train Acc: 0.503846 | Val Loss: 0.267226, Val Acc: 0.474227\n",
      "Epoch 716 - Train Loss: 0.259402, Train Acc: 0.503846 | Val Loss: 0.267210, Val Acc: 0.474227\n",
      "Epoch 717 - Train Loss: 0.259386, Train Acc: 0.503846 | Val Loss: 0.267194, Val Acc: 0.474227\n",
      "Epoch 718 - Train Loss: 0.259370, Train Acc: 0.503846 | Val Loss: 0.267177, Val Acc: 0.474227\n",
      "Epoch 719 - Train Loss: 0.259354, Train Acc: 0.503846 | Val Loss: 0.267161, Val Acc: 0.474227\n",
      "Epoch 720 - Train Loss: 0.259339, Train Acc: 0.503846 | Val Loss: 0.267145, Val Acc: 0.474227\n",
      "Epoch 721 - Train Loss: 0.259323, Train Acc: 0.503846 | Val Loss: 0.267129, Val Acc: 0.474227\n",
      "Epoch 722 - Train Loss: 0.259307, Train Acc: 0.503846 | Val Loss: 0.267112, Val Acc: 0.474227\n",
      "Epoch 723 - Train Loss: 0.259292, Train Acc: 0.503846 | Val Loss: 0.267096, Val Acc: 0.474227\n",
      "Epoch 724 - Train Loss: 0.259276, Train Acc: 0.503846 | Val Loss: 0.267080, Val Acc: 0.474227\n",
      "Epoch 725 - Train Loss: 0.259260, Train Acc: 0.503846 | Val Loss: 0.267064, Val Acc: 0.474227\n",
      "Epoch 726 - Train Loss: 0.259245, Train Acc: 0.503846 | Val Loss: 0.267047, Val Acc: 0.474227\n",
      "Epoch 727 - Train Loss: 0.259229, Train Acc: 0.503846 | Val Loss: 0.267031, Val Acc: 0.474227\n",
      "Epoch 728 - Train Loss: 0.259213, Train Acc: 0.503846 | Val Loss: 0.267015, Val Acc: 0.474227\n",
      "Epoch 729 - Train Loss: 0.259197, Train Acc: 0.503846 | Val Loss: 0.266998, Val Acc: 0.474227\n",
      "Epoch 730 - Train Loss: 0.259182, Train Acc: 0.503846 | Val Loss: 0.266982, Val Acc: 0.474227\n",
      "Epoch 731 - Train Loss: 0.259166, Train Acc: 0.503846 | Val Loss: 0.266966, Val Acc: 0.474227\n",
      "Epoch 732 - Train Loss: 0.259150, Train Acc: 0.503846 | Val Loss: 0.266949, Val Acc: 0.474227\n",
      "Epoch 733 - Train Loss: 0.259134, Train Acc: 0.503846 | Val Loss: 0.266933, Val Acc: 0.474227\n",
      "Epoch 734 - Train Loss: 0.259118, Train Acc: 0.503846 | Val Loss: 0.266916, Val Acc: 0.474227\n",
      "Epoch 735 - Train Loss: 0.259102, Train Acc: 0.503846 | Val Loss: 0.266900, Val Acc: 0.474227\n",
      "Epoch 736 - Train Loss: 0.259087, Train Acc: 0.503846 | Val Loss: 0.266884, Val Acc: 0.474227\n",
      "Epoch 737 - Train Loss: 0.259071, Train Acc: 0.503846 | Val Loss: 0.266867, Val Acc: 0.474227\n",
      "Epoch 738 - Train Loss: 0.259055, Train Acc: 0.503846 | Val Loss: 0.266851, Val Acc: 0.474227\n",
      "Epoch 739 - Train Loss: 0.259039, Train Acc: 0.503846 | Val Loss: 0.266834, Val Acc: 0.474227\n",
      "Epoch 740 - Train Loss: 0.259023, Train Acc: 0.503846 | Val Loss: 0.266818, Val Acc: 0.474227\n",
      "Epoch 741 - Train Loss: 0.259007, Train Acc: 0.503846 | Val Loss: 0.266801, Val Acc: 0.474227\n",
      "Epoch 742 - Train Loss: 0.258991, Train Acc: 0.503846 | Val Loss: 0.266785, Val Acc: 0.474227\n",
      "Epoch 743 - Train Loss: 0.258975, Train Acc: 0.503846 | Val Loss: 0.266768, Val Acc: 0.474227\n",
      "Epoch 744 - Train Loss: 0.258959, Train Acc: 0.503846 | Val Loss: 0.266751, Val Acc: 0.474227\n",
      "Epoch 745 - Train Loss: 0.258943, Train Acc: 0.503846 | Val Loss: 0.266735, Val Acc: 0.474227\n",
      "Epoch 746 - Train Loss: 0.258927, Train Acc: 0.503846 | Val Loss: 0.266718, Val Acc: 0.474227\n",
      "Epoch 747 - Train Loss: 0.258911, Train Acc: 0.503846 | Val Loss: 0.266702, Val Acc: 0.474227\n",
      "Epoch 748 - Train Loss: 0.258896, Train Acc: 0.503846 | Val Loss: 0.266685, Val Acc: 0.474227\n",
      "Epoch 749 - Train Loss: 0.258880, Train Acc: 0.503846 | Val Loss: 0.266668, Val Acc: 0.474227\n",
      "Epoch 750 - Train Loss: 0.258864, Train Acc: 0.503846 | Val Loss: 0.266652, Val Acc: 0.474227\n",
      "Epoch 751 - Train Loss: 0.258848, Train Acc: 0.503846 | Val Loss: 0.266635, Val Acc: 0.474227\n",
      "Epoch 752 - Train Loss: 0.258832, Train Acc: 0.503846 | Val Loss: 0.266619, Val Acc: 0.474227\n",
      "Epoch 753 - Train Loss: 0.258816, Train Acc: 0.503846 | Val Loss: 0.266602, Val Acc: 0.474227\n",
      "Epoch 754 - Train Loss: 0.258800, Train Acc: 0.503846 | Val Loss: 0.266586, Val Acc: 0.474227\n",
      "Epoch 755 - Train Loss: 0.258784, Train Acc: 0.503846 | Val Loss: 0.266569, Val Acc: 0.474227\n",
      "Epoch 756 - Train Loss: 0.258768, Train Acc: 0.503846 | Val Loss: 0.266553, Val Acc: 0.474227\n",
      "Epoch 757 - Train Loss: 0.258753, Train Acc: 0.503846 | Val Loss: 0.266536, Val Acc: 0.474227\n",
      "Epoch 758 - Train Loss: 0.258737, Train Acc: 0.503846 | Val Loss: 0.266520, Val Acc: 0.474227\n",
      "Epoch 759 - Train Loss: 0.258721, Train Acc: 0.503846 | Val Loss: 0.266503, Val Acc: 0.474227\n",
      "Epoch 760 - Train Loss: 0.258705, Train Acc: 0.503846 | Val Loss: 0.266487, Val Acc: 0.474227\n",
      "Epoch 761 - Train Loss: 0.258689, Train Acc: 0.503846 | Val Loss: 0.266470, Val Acc: 0.474227\n",
      "Epoch 762 - Train Loss: 0.258673, Train Acc: 0.503846 | Val Loss: 0.266453, Val Acc: 0.474227\n",
      "Epoch 763 - Train Loss: 0.258657, Train Acc: 0.503846 | Val Loss: 0.266437, Val Acc: 0.474227\n",
      "Epoch 764 - Train Loss: 0.258641, Train Acc: 0.503846 | Val Loss: 0.266420, Val Acc: 0.474227\n",
      "Epoch 765 - Train Loss: 0.258625, Train Acc: 0.503846 | Val Loss: 0.266404, Val Acc: 0.474227\n",
      "Epoch 766 - Train Loss: 0.258609, Train Acc: 0.503846 | Val Loss: 0.266387, Val Acc: 0.474227\n",
      "Epoch 767 - Train Loss: 0.258593, Train Acc: 0.503846 | Val Loss: 0.266370, Val Acc: 0.474227\n",
      "Epoch 768 - Train Loss: 0.258577, Train Acc: 0.503846 | Val Loss: 0.266354, Val Acc: 0.474227\n",
      "Epoch 769 - Train Loss: 0.258561, Train Acc: 0.503846 | Val Loss: 0.266337, Val Acc: 0.474227\n",
      "Epoch 770 - Train Loss: 0.258545, Train Acc: 0.503846 | Val Loss: 0.266320, Val Acc: 0.474227\n",
      "Epoch 771 - Train Loss: 0.258529, Train Acc: 0.503846 | Val Loss: 0.266304, Val Acc: 0.474227\n",
      "Epoch 772 - Train Loss: 0.258513, Train Acc: 0.503846 | Val Loss: 0.266287, Val Acc: 0.474227\n",
      "Epoch 773 - Train Loss: 0.258497, Train Acc: 0.503846 | Val Loss: 0.266270, Val Acc: 0.474227\n",
      "Epoch 774 - Train Loss: 0.258481, Train Acc: 0.503846 | Val Loss: 0.266254, Val Acc: 0.474227\n",
      "Epoch 775 - Train Loss: 0.258465, Train Acc: 0.503846 | Val Loss: 0.266237, Val Acc: 0.474227\n",
      "Epoch 776 - Train Loss: 0.258449, Train Acc: 0.503846 | Val Loss: 0.266220, Val Acc: 0.474227\n",
      "Epoch 777 - Train Loss: 0.258433, Train Acc: 0.503846 | Val Loss: 0.266203, Val Acc: 0.474227\n",
      "Epoch 778 - Train Loss: 0.258417, Train Acc: 0.503846 | Val Loss: 0.266186, Val Acc: 0.474227\n",
      "Epoch 779 - Train Loss: 0.258401, Train Acc: 0.503846 | Val Loss: 0.266170, Val Acc: 0.474227\n",
      "Epoch 780 - Train Loss: 0.258385, Train Acc: 0.503846 | Val Loss: 0.266153, Val Acc: 0.474227\n",
      "Epoch 781 - Train Loss: 0.258369, Train Acc: 0.503846 | Val Loss: 0.266136, Val Acc: 0.474227\n",
      "Epoch 782 - Train Loss: 0.258353, Train Acc: 0.503846 | Val Loss: 0.266119, Val Acc: 0.474227\n",
      "Epoch 783 - Train Loss: 0.258337, Train Acc: 0.503846 | Val Loss: 0.266102, Val Acc: 0.474227\n",
      "Epoch 784 - Train Loss: 0.258321, Train Acc: 0.503846 | Val Loss: 0.266085, Val Acc: 0.474227\n",
      "Epoch 785 - Train Loss: 0.258304, Train Acc: 0.503846 | Val Loss: 0.266068, Val Acc: 0.474227\n",
      "Epoch 786 - Train Loss: 0.258288, Train Acc: 0.503846 | Val Loss: 0.266051, Val Acc: 0.474227\n",
      "Epoch 787 - Train Loss: 0.258272, Train Acc: 0.503846 | Val Loss: 0.266035, Val Acc: 0.474227\n",
      "Epoch 788 - Train Loss: 0.258256, Train Acc: 0.503846 | Val Loss: 0.266018, Val Acc: 0.474227\n",
      "Epoch 789 - Train Loss: 0.258240, Train Acc: 0.503846 | Val Loss: 0.266001, Val Acc: 0.474227\n",
      "Epoch 790 - Train Loss: 0.258224, Train Acc: 0.503846 | Val Loss: 0.265984, Val Acc: 0.474227\n",
      "Epoch 791 - Train Loss: 0.258208, Train Acc: 0.503846 | Val Loss: 0.265967, Val Acc: 0.474227\n",
      "Epoch 792 - Train Loss: 0.258191, Train Acc: 0.503846 | Val Loss: 0.265950, Val Acc: 0.474227\n",
      "Epoch 793 - Train Loss: 0.258175, Train Acc: 0.503846 | Val Loss: 0.265933, Val Acc: 0.474227\n",
      "Epoch 794 - Train Loss: 0.258159, Train Acc: 0.503846 | Val Loss: 0.265916, Val Acc: 0.474227\n",
      "Epoch 795 - Train Loss: 0.258143, Train Acc: 0.503846 | Val Loss: 0.265899, Val Acc: 0.474227\n",
      "Epoch 796 - Train Loss: 0.258127, Train Acc: 0.503846 | Val Loss: 0.265882, Val Acc: 0.474227\n",
      "Epoch 797 - Train Loss: 0.258110, Train Acc: 0.503846 | Val Loss: 0.265865, Val Acc: 0.474227\n",
      "Epoch 798 - Train Loss: 0.258094, Train Acc: 0.503846 | Val Loss: 0.265848, Val Acc: 0.474227\n",
      "Epoch 799 - Train Loss: 0.258078, Train Acc: 0.503846 | Val Loss: 0.265831, Val Acc: 0.474227\n",
      "Epoch 800 - Train Loss: 0.258061, Train Acc: 0.503846 | Val Loss: 0.265814, Val Acc: 0.474227\n",
      "Epoch 801 - Train Loss: 0.258045, Train Acc: 0.503846 | Val Loss: 0.265796, Val Acc: 0.474227\n",
      "Epoch 802 - Train Loss: 0.258029, Train Acc: 0.503846 | Val Loss: 0.265779, Val Acc: 0.474227\n",
      "Epoch 803 - Train Loss: 0.258012, Train Acc: 0.503846 | Val Loss: 0.265762, Val Acc: 0.474227\n",
      "Epoch 804 - Train Loss: 0.257996, Train Acc: 0.503846 | Val Loss: 0.265745, Val Acc: 0.474227\n",
      "Epoch 805 - Train Loss: 0.257979, Train Acc: 0.503846 | Val Loss: 0.265728, Val Acc: 0.474227\n",
      "Epoch 806 - Train Loss: 0.257963, Train Acc: 0.503846 | Val Loss: 0.265710, Val Acc: 0.474227\n",
      "Epoch 807 - Train Loss: 0.257946, Train Acc: 0.503846 | Val Loss: 0.265693, Val Acc: 0.474227\n",
      "Epoch 808 - Train Loss: 0.257930, Train Acc: 0.503846 | Val Loss: 0.265676, Val Acc: 0.474227\n",
      "Epoch 809 - Train Loss: 0.257913, Train Acc: 0.503846 | Val Loss: 0.265658, Val Acc: 0.474227\n",
      "Epoch 810 - Train Loss: 0.257897, Train Acc: 0.503846 | Val Loss: 0.265641, Val Acc: 0.474227\n",
      "Epoch 811 - Train Loss: 0.257880, Train Acc: 0.503846 | Val Loss: 0.265623, Val Acc: 0.474227\n",
      "Epoch 812 - Train Loss: 0.257864, Train Acc: 0.503846 | Val Loss: 0.265606, Val Acc: 0.474227\n",
      "Epoch 813 - Train Loss: 0.257847, Train Acc: 0.503846 | Val Loss: 0.265589, Val Acc: 0.474227\n",
      "Epoch 814 - Train Loss: 0.257831, Train Acc: 0.503846 | Val Loss: 0.265571, Val Acc: 0.474227\n",
      "Epoch 815 - Train Loss: 0.257814, Train Acc: 0.503846 | Val Loss: 0.265554, Val Acc: 0.474227\n",
      "Epoch 816 - Train Loss: 0.257798, Train Acc: 0.503846 | Val Loss: 0.265537, Val Acc: 0.474227\n",
      "Epoch 817 - Train Loss: 0.257781, Train Acc: 0.503846 | Val Loss: 0.265519, Val Acc: 0.474227\n",
      "Epoch 818 - Train Loss: 0.257765, Train Acc: 0.503846 | Val Loss: 0.265502, Val Acc: 0.474227\n",
      "Epoch 819 - Train Loss: 0.257748, Train Acc: 0.503846 | Val Loss: 0.265485, Val Acc: 0.474227\n",
      "Epoch 820 - Train Loss: 0.257732, Train Acc: 0.503846 | Val Loss: 0.265467, Val Acc: 0.474227\n",
      "Epoch 821 - Train Loss: 0.257715, Train Acc: 0.503846 | Val Loss: 0.265450, Val Acc: 0.474227\n",
      "Epoch 822 - Train Loss: 0.257699, Train Acc: 0.503846 | Val Loss: 0.265433, Val Acc: 0.474227\n",
      "Epoch 823 - Train Loss: 0.257682, Train Acc: 0.503846 | Val Loss: 0.265416, Val Acc: 0.474227\n",
      "Epoch 824 - Train Loss: 0.257666, Train Acc: 0.503846 | Val Loss: 0.265399, Val Acc: 0.474227\n",
      "Epoch 825 - Train Loss: 0.257649, Train Acc: 0.503846 | Val Loss: 0.265381, Val Acc: 0.474227\n",
      "Epoch 826 - Train Loss: 0.257633, Train Acc: 0.503846 | Val Loss: 0.265364, Val Acc: 0.474227\n",
      "Epoch 827 - Train Loss: 0.257616, Train Acc: 0.503846 | Val Loss: 0.265347, Val Acc: 0.474227\n",
      "Epoch 828 - Train Loss: 0.257600, Train Acc: 0.503846 | Val Loss: 0.265330, Val Acc: 0.474227\n",
      "Epoch 829 - Train Loss: 0.257583, Train Acc: 0.503846 | Val Loss: 0.265313, Val Acc: 0.474227\n",
      "Epoch 830 - Train Loss: 0.257567, Train Acc: 0.503846 | Val Loss: 0.265296, Val Acc: 0.474227\n",
      "Epoch 831 - Train Loss: 0.257550, Train Acc: 0.503846 | Val Loss: 0.265279, Val Acc: 0.474227\n",
      "Epoch 832 - Train Loss: 0.257534, Train Acc: 0.503846 | Val Loss: 0.265262, Val Acc: 0.474227\n",
      "Epoch 833 - Train Loss: 0.257518, Train Acc: 0.503846 | Val Loss: 0.265245, Val Acc: 0.474227\n",
      "Epoch 834 - Train Loss: 0.257501, Train Acc: 0.503846 | Val Loss: 0.265228, Val Acc: 0.474227\n",
      "Epoch 835 - Train Loss: 0.257485, Train Acc: 0.503846 | Val Loss: 0.265211, Val Acc: 0.474227\n",
      "Epoch 836 - Train Loss: 0.257468, Train Acc: 0.503846 | Val Loss: 0.265194, Val Acc: 0.474227\n",
      "Epoch 837 - Train Loss: 0.257452, Train Acc: 0.503846 | Val Loss: 0.265177, Val Acc: 0.474227\n",
      "Epoch 838 - Train Loss: 0.257435, Train Acc: 0.503846 | Val Loss: 0.265160, Val Acc: 0.474227\n",
      "Epoch 839 - Train Loss: 0.257419, Train Acc: 0.503846 | Val Loss: 0.265143, Val Acc: 0.474227\n",
      "Epoch 840 - Train Loss: 0.257402, Train Acc: 0.503846 | Val Loss: 0.265126, Val Acc: 0.474227\n",
      "Epoch 841 - Train Loss: 0.257386, Train Acc: 0.503846 | Val Loss: 0.265109, Val Acc: 0.474227\n",
      "Epoch 842 - Train Loss: 0.257369, Train Acc: 0.503846 | Val Loss: 0.265092, Val Acc: 0.474227\n",
      "Epoch 843 - Train Loss: 0.257353, Train Acc: 0.503846 | Val Loss: 0.265075, Val Acc: 0.474227\n",
      "Epoch 844 - Train Loss: 0.257336, Train Acc: 0.503846 | Val Loss: 0.265058, Val Acc: 0.474227\n",
      "Epoch 845 - Train Loss: 0.257319, Train Acc: 0.503846 | Val Loss: 0.265040, Val Acc: 0.474227\n",
      "Epoch 846 - Train Loss: 0.257303, Train Acc: 0.503846 | Val Loss: 0.265023, Val Acc: 0.474227\n",
      "Epoch 847 - Train Loss: 0.257286, Train Acc: 0.503846 | Val Loss: 0.265006, Val Acc: 0.474227\n",
      "Epoch 848 - Train Loss: 0.257269, Train Acc: 0.503846 | Val Loss: 0.264989, Val Acc: 0.474227\n",
      "Epoch 849 - Train Loss: 0.257253, Train Acc: 0.503846 | Val Loss: 0.264972, Val Acc: 0.474227\n",
      "Epoch 850 - Train Loss: 0.257236, Train Acc: 0.503846 | Val Loss: 0.264955, Val Acc: 0.474227\n",
      "Epoch 851 - Train Loss: 0.257219, Train Acc: 0.503846 | Val Loss: 0.264937, Val Acc: 0.474227\n",
      "Epoch 852 - Train Loss: 0.257203, Train Acc: 0.503846 | Val Loss: 0.264920, Val Acc: 0.474227\n",
      "Epoch 853 - Train Loss: 0.257186, Train Acc: 0.503846 | Val Loss: 0.264903, Val Acc: 0.474227\n",
      "Epoch 854 - Train Loss: 0.257169, Train Acc: 0.503846 | Val Loss: 0.264886, Val Acc: 0.474227\n",
      "Epoch 855 - Train Loss: 0.257152, Train Acc: 0.503846 | Val Loss: 0.264868, Val Acc: 0.474227\n",
      "Epoch 856 - Train Loss: 0.257135, Train Acc: 0.503846 | Val Loss: 0.264851, Val Acc: 0.474227\n",
      "Epoch 857 - Train Loss: 0.257119, Train Acc: 0.503846 | Val Loss: 0.264834, Val Acc: 0.474227\n",
      "Epoch 858 - Train Loss: 0.257102, Train Acc: 0.503846 | Val Loss: 0.264816, Val Acc: 0.474227\n",
      "Epoch 859 - Train Loss: 0.257085, Train Acc: 0.503846 | Val Loss: 0.264799, Val Acc: 0.474227\n",
      "Epoch 860 - Train Loss: 0.257068, Train Acc: 0.503846 | Val Loss: 0.264782, Val Acc: 0.474227\n",
      "Epoch 861 - Train Loss: 0.257052, Train Acc: 0.503846 | Val Loss: 0.264764, Val Acc: 0.474227\n",
      "Epoch 862 - Train Loss: 0.257035, Train Acc: 0.503846 | Val Loss: 0.264747, Val Acc: 0.474227\n",
      "Epoch 863 - Train Loss: 0.257018, Train Acc: 0.503846 | Val Loss: 0.264729, Val Acc: 0.474227\n",
      "Epoch 864 - Train Loss: 0.257002, Train Acc: 0.503846 | Val Loss: 0.264712, Val Acc: 0.474227\n",
      "Epoch 865 - Train Loss: 0.256985, Train Acc: 0.503846 | Val Loss: 0.264695, Val Acc: 0.474227\n",
      "Epoch 866 - Train Loss: 0.256968, Train Acc: 0.503846 | Val Loss: 0.264677, Val Acc: 0.474227\n",
      "Epoch 867 - Train Loss: 0.256951, Train Acc: 0.503846 | Val Loss: 0.264660, Val Acc: 0.474227\n",
      "Epoch 868 - Train Loss: 0.256935, Train Acc: 0.503846 | Val Loss: 0.264643, Val Acc: 0.474227\n",
      "Epoch 869 - Train Loss: 0.256918, Train Acc: 0.503846 | Val Loss: 0.264625, Val Acc: 0.474227\n",
      "Epoch 870 - Train Loss: 0.256901, Train Acc: 0.503846 | Val Loss: 0.264608, Val Acc: 0.474227\n",
      "Epoch 871 - Train Loss: 0.256884, Train Acc: 0.503846 | Val Loss: 0.264590, Val Acc: 0.474227\n",
      "Epoch 872 - Train Loss: 0.256868, Train Acc: 0.503846 | Val Loss: 0.264573, Val Acc: 0.474227\n",
      "Epoch 873 - Train Loss: 0.256851, Train Acc: 0.503846 | Val Loss: 0.264555, Val Acc: 0.474227\n",
      "Epoch 874 - Train Loss: 0.256834, Train Acc: 0.503846 | Val Loss: 0.264537, Val Acc: 0.474227\n",
      "Epoch 875 - Train Loss: 0.256817, Train Acc: 0.503846 | Val Loss: 0.264520, Val Acc: 0.474227\n",
      "Epoch 876 - Train Loss: 0.256800, Train Acc: 0.503846 | Val Loss: 0.264502, Val Acc: 0.474227\n",
      "Epoch 877 - Train Loss: 0.256783, Train Acc: 0.503846 | Val Loss: 0.264485, Val Acc: 0.474227\n",
      "Epoch 878 - Train Loss: 0.256767, Train Acc: 0.503846 | Val Loss: 0.264467, Val Acc: 0.474227\n",
      "Epoch 879 - Train Loss: 0.256750, Train Acc: 0.503846 | Val Loss: 0.264450, Val Acc: 0.474227\n",
      "Epoch 880 - Train Loss: 0.256733, Train Acc: 0.503846 | Val Loss: 0.264432, Val Acc: 0.474227\n",
      "Epoch 881 - Train Loss: 0.256716, Train Acc: 0.503846 | Val Loss: 0.264415, Val Acc: 0.474227\n",
      "Epoch 882 - Train Loss: 0.256700, Train Acc: 0.503846 | Val Loss: 0.264397, Val Acc: 0.474227\n",
      "Epoch 883 - Train Loss: 0.256683, Train Acc: 0.503846 | Val Loss: 0.264380, Val Acc: 0.474227\n",
      "Epoch 884 - Train Loss: 0.256666, Train Acc: 0.503846 | Val Loss: 0.264363, Val Acc: 0.474227\n",
      "Epoch 885 - Train Loss: 0.256649, Train Acc: 0.503846 | Val Loss: 0.264345, Val Acc: 0.474227\n",
      "Epoch 886 - Train Loss: 0.256632, Train Acc: 0.503846 | Val Loss: 0.264328, Val Acc: 0.474227\n",
      "Epoch 887 - Train Loss: 0.256615, Train Acc: 0.503846 | Val Loss: 0.264310, Val Acc: 0.474227\n",
      "Epoch 888 - Train Loss: 0.256598, Train Acc: 0.503846 | Val Loss: 0.264292, Val Acc: 0.474227\n",
      "Epoch 889 - Train Loss: 0.256581, Train Acc: 0.503846 | Val Loss: 0.264275, Val Acc: 0.474227\n",
      "Epoch 890 - Train Loss: 0.256564, Train Acc: 0.505128 | Val Loss: 0.264257, Val Acc: 0.474227\n",
      "Epoch 891 - Train Loss: 0.256547, Train Acc: 0.505128 | Val Loss: 0.264240, Val Acc: 0.474227\n",
      "Epoch 892 - Train Loss: 0.256530, Train Acc: 0.505128 | Val Loss: 0.264222, Val Acc: 0.474227\n",
      "Epoch 893 - Train Loss: 0.256513, Train Acc: 0.505128 | Val Loss: 0.264205, Val Acc: 0.474227\n",
      "Epoch 894 - Train Loss: 0.256496, Train Acc: 0.505128 | Val Loss: 0.264187, Val Acc: 0.474227\n",
      "Epoch 895 - Train Loss: 0.256479, Train Acc: 0.505128 | Val Loss: 0.264169, Val Acc: 0.474227\n",
      "Epoch 896 - Train Loss: 0.256462, Train Acc: 0.505128 | Val Loss: 0.264152, Val Acc: 0.474227\n",
      "Epoch 897 - Train Loss: 0.256445, Train Acc: 0.505128 | Val Loss: 0.264134, Val Acc: 0.474227\n",
      "Epoch 898 - Train Loss: 0.256428, Train Acc: 0.505128 | Val Loss: 0.264116, Val Acc: 0.474227\n",
      "Epoch 899 - Train Loss: 0.256411, Train Acc: 0.505128 | Val Loss: 0.264098, Val Acc: 0.474227\n",
      "Epoch 900 - Train Loss: 0.256393, Train Acc: 0.505128 | Val Loss: 0.264080, Val Acc: 0.474227\n",
      "Epoch 901 - Train Loss: 0.256376, Train Acc: 0.505128 | Val Loss: 0.264062, Val Acc: 0.474227\n",
      "Epoch 902 - Train Loss: 0.256359, Train Acc: 0.505128 | Val Loss: 0.264044, Val Acc: 0.474227\n",
      "Epoch 903 - Train Loss: 0.256342, Train Acc: 0.505128 | Val Loss: 0.264026, Val Acc: 0.474227\n",
      "Epoch 904 - Train Loss: 0.256324, Train Acc: 0.505128 | Val Loss: 0.264009, Val Acc: 0.474227\n",
      "Epoch 905 - Train Loss: 0.256307, Train Acc: 0.505128 | Val Loss: 0.263991, Val Acc: 0.474227\n",
      "Epoch 906 - Train Loss: 0.256290, Train Acc: 0.505128 | Val Loss: 0.263973, Val Acc: 0.474227\n",
      "Epoch 907 - Train Loss: 0.256273, Train Acc: 0.505128 | Val Loss: 0.263955, Val Acc: 0.474227\n",
      "Epoch 908 - Train Loss: 0.256256, Train Acc: 0.505128 | Val Loss: 0.263937, Val Acc: 0.474227\n",
      "Epoch 909 - Train Loss: 0.256239, Train Acc: 0.505128 | Val Loss: 0.263919, Val Acc: 0.474227\n",
      "Epoch 910 - Train Loss: 0.256221, Train Acc: 0.505128 | Val Loss: 0.263901, Val Acc: 0.474227\n",
      "Epoch 911 - Train Loss: 0.256204, Train Acc: 0.505128 | Val Loss: 0.263883, Val Acc: 0.474227\n",
      "Epoch 912 - Train Loss: 0.256187, Train Acc: 0.505128 | Val Loss: 0.263865, Val Acc: 0.474227\n",
      "Epoch 913 - Train Loss: 0.256169, Train Acc: 0.505128 | Val Loss: 0.263847, Val Acc: 0.474227\n",
      "Epoch 914 - Train Loss: 0.256152, Train Acc: 0.505128 | Val Loss: 0.263829, Val Acc: 0.474227\n",
      "Epoch 915 - Train Loss: 0.256135, Train Acc: 0.505128 | Val Loss: 0.263811, Val Acc: 0.474227\n",
      "Epoch 916 - Train Loss: 0.256117, Train Acc: 0.506410 | Val Loss: 0.263793, Val Acc: 0.474227\n",
      "Epoch 917 - Train Loss: 0.256100, Train Acc: 0.506410 | Val Loss: 0.263775, Val Acc: 0.474227\n",
      "Epoch 918 - Train Loss: 0.256083, Train Acc: 0.506410 | Val Loss: 0.263757, Val Acc: 0.474227\n",
      "Epoch 919 - Train Loss: 0.256065, Train Acc: 0.506410 | Val Loss: 0.263739, Val Acc: 0.474227\n",
      "Epoch 920 - Train Loss: 0.256048, Train Acc: 0.506410 | Val Loss: 0.263720, Val Acc: 0.474227\n",
      "Epoch 921 - Train Loss: 0.256031, Train Acc: 0.506410 | Val Loss: 0.263702, Val Acc: 0.474227\n",
      "Epoch 922 - Train Loss: 0.256013, Train Acc: 0.506410 | Val Loss: 0.263684, Val Acc: 0.474227\n",
      "Epoch 923 - Train Loss: 0.255996, Train Acc: 0.506410 | Val Loss: 0.263667, Val Acc: 0.474227\n",
      "Epoch 924 - Train Loss: 0.255978, Train Acc: 0.506410 | Val Loss: 0.263649, Val Acc: 0.474227\n",
      "Epoch 925 - Train Loss: 0.255961, Train Acc: 0.506410 | Val Loss: 0.263631, Val Acc: 0.474227\n",
      "Epoch 926 - Train Loss: 0.255943, Train Acc: 0.506410 | Val Loss: 0.263613, Val Acc: 0.474227\n",
      "Epoch 927 - Train Loss: 0.255926, Train Acc: 0.506410 | Val Loss: 0.263595, Val Acc: 0.474227\n",
      "Epoch 928 - Train Loss: 0.255908, Train Acc: 0.506410 | Val Loss: 0.263577, Val Acc: 0.474227\n",
      "Epoch 929 - Train Loss: 0.255891, Train Acc: 0.506410 | Val Loss: 0.263558, Val Acc: 0.474227\n",
      "Epoch 930 - Train Loss: 0.255873, Train Acc: 0.506410 | Val Loss: 0.263540, Val Acc: 0.474227\n",
      "Epoch 931 - Train Loss: 0.255855, Train Acc: 0.506410 | Val Loss: 0.263522, Val Acc: 0.474227\n",
      "Epoch 932 - Train Loss: 0.255838, Train Acc: 0.506410 | Val Loss: 0.263504, Val Acc: 0.474227\n",
      "Epoch 933 - Train Loss: 0.255820, Train Acc: 0.506410 | Val Loss: 0.263486, Val Acc: 0.474227\n",
      "Epoch 934 - Train Loss: 0.255802, Train Acc: 0.506410 | Val Loss: 0.263467, Val Acc: 0.474227\n",
      "Epoch 935 - Train Loss: 0.255785, Train Acc: 0.506410 | Val Loss: 0.263449, Val Acc: 0.474227\n",
      "Epoch 936 - Train Loss: 0.255767, Train Acc: 0.506410 | Val Loss: 0.263431, Val Acc: 0.474227\n",
      "Epoch 937 - Train Loss: 0.255750, Train Acc: 0.506410 | Val Loss: 0.263413, Val Acc: 0.474227\n",
      "Epoch 938 - Train Loss: 0.255732, Train Acc: 0.506410 | Val Loss: 0.263395, Val Acc: 0.474227\n",
      "Epoch 939 - Train Loss: 0.255714, Train Acc: 0.506410 | Val Loss: 0.263376, Val Acc: 0.474227\n",
      "Epoch 940 - Train Loss: 0.255697, Train Acc: 0.506410 | Val Loss: 0.263358, Val Acc: 0.474227\n",
      "Epoch 941 - Train Loss: 0.255679, Train Acc: 0.506410 | Val Loss: 0.263340, Val Acc: 0.474227\n",
      "Epoch 942 - Train Loss: 0.255662, Train Acc: 0.506410 | Val Loss: 0.263321, Val Acc: 0.474227\n",
      "Epoch 943 - Train Loss: 0.255644, Train Acc: 0.506410 | Val Loss: 0.263303, Val Acc: 0.474227\n",
      "Epoch 944 - Train Loss: 0.255626, Train Acc: 0.506410 | Val Loss: 0.263284, Val Acc: 0.474227\n",
      "Epoch 945 - Train Loss: 0.255609, Train Acc: 0.506410 | Val Loss: 0.263266, Val Acc: 0.474227\n",
      "Epoch 946 - Train Loss: 0.255591, Train Acc: 0.506410 | Val Loss: 0.263247, Val Acc: 0.474227\n",
      "Epoch 947 - Train Loss: 0.255574, Train Acc: 0.506410 | Val Loss: 0.263228, Val Acc: 0.474227\n",
      "Epoch 948 - Train Loss: 0.255556, Train Acc: 0.506410 | Val Loss: 0.263209, Val Acc: 0.474227\n",
      "Epoch 949 - Train Loss: 0.255538, Train Acc: 0.506410 | Val Loss: 0.263190, Val Acc: 0.474227\n",
      "Epoch 950 - Train Loss: 0.255521, Train Acc: 0.506410 | Val Loss: 0.263171, Val Acc: 0.474227\n",
      "Epoch 951 - Train Loss: 0.255503, Train Acc: 0.506410 | Val Loss: 0.263152, Val Acc: 0.474227\n",
      "Epoch 952 - Train Loss: 0.255485, Train Acc: 0.506410 | Val Loss: 0.263133, Val Acc: 0.474227\n",
      "Epoch 953 - Train Loss: 0.255467, Train Acc: 0.506410 | Val Loss: 0.263114, Val Acc: 0.474227\n",
      "Epoch 954 - Train Loss: 0.255449, Train Acc: 0.506410 | Val Loss: 0.263095, Val Acc: 0.474227\n",
      "Epoch 955 - Train Loss: 0.255431, Train Acc: 0.506410 | Val Loss: 0.263075, Val Acc: 0.474227\n",
      "Epoch 956 - Train Loss: 0.255413, Train Acc: 0.506410 | Val Loss: 0.263056, Val Acc: 0.474227\n",
      "Epoch 957 - Train Loss: 0.255396, Train Acc: 0.506410 | Val Loss: 0.263037, Val Acc: 0.474227\n",
      "Epoch 958 - Train Loss: 0.255378, Train Acc: 0.506410 | Val Loss: 0.263018, Val Acc: 0.474227\n",
      "Epoch 959 - Train Loss: 0.255361, Train Acc: 0.506410 | Val Loss: 0.262999, Val Acc: 0.474227\n",
      "Epoch 960 - Train Loss: 0.255343, Train Acc: 0.506410 | Val Loss: 0.262980, Val Acc: 0.474227\n",
      "Epoch 961 - Train Loss: 0.255325, Train Acc: 0.506410 | Val Loss: 0.262961, Val Acc: 0.474227\n",
      "Epoch 962 - Train Loss: 0.255308, Train Acc: 0.506410 | Val Loss: 0.262942, Val Acc: 0.474227\n",
      "Epoch 963 - Train Loss: 0.255290, Train Acc: 0.506410 | Val Loss: 0.262923, Val Acc: 0.474227\n",
      "Epoch 964 - Train Loss: 0.255272, Train Acc: 0.506410 | Val Loss: 0.262904, Val Acc: 0.474227\n",
      "Epoch 965 - Train Loss: 0.255254, Train Acc: 0.506410 | Val Loss: 0.262884, Val Acc: 0.474227\n",
      "Epoch 966 - Train Loss: 0.255237, Train Acc: 0.506410 | Val Loss: 0.262865, Val Acc: 0.474227\n",
      "Epoch 967 - Train Loss: 0.255219, Train Acc: 0.506410 | Val Loss: 0.262846, Val Acc: 0.474227\n",
      "Epoch 968 - Train Loss: 0.255201, Train Acc: 0.506410 | Val Loss: 0.262827, Val Acc: 0.474227\n",
      "Epoch 969 - Train Loss: 0.255184, Train Acc: 0.506410 | Val Loss: 0.262807, Val Acc: 0.474227\n",
      "Epoch 970 - Train Loss: 0.255166, Train Acc: 0.506410 | Val Loss: 0.262788, Val Acc: 0.474227\n",
      "Epoch 971 - Train Loss: 0.255148, Train Acc: 0.506410 | Val Loss: 0.262769, Val Acc: 0.474227\n",
      "Epoch 972 - Train Loss: 0.255131, Train Acc: 0.506410 | Val Loss: 0.262749, Val Acc: 0.474227\n",
      "Epoch 973 - Train Loss: 0.255113, Train Acc: 0.506410 | Val Loss: 0.262730, Val Acc: 0.474227\n",
      "Epoch 974 - Train Loss: 0.255095, Train Acc: 0.506410 | Val Loss: 0.262710, Val Acc: 0.474227\n",
      "Epoch 975 - Train Loss: 0.255078, Train Acc: 0.506410 | Val Loss: 0.262691, Val Acc: 0.474227\n",
      "Epoch 976 - Train Loss: 0.255060, Train Acc: 0.506410 | Val Loss: 0.262672, Val Acc: 0.474227\n",
      "Epoch 977 - Train Loss: 0.255042, Train Acc: 0.506410 | Val Loss: 0.262652, Val Acc: 0.474227\n",
      "Epoch 978 - Train Loss: 0.255025, Train Acc: 0.506410 | Val Loss: 0.262633, Val Acc: 0.474227\n",
      "Epoch 979 - Train Loss: 0.255007, Train Acc: 0.506410 | Val Loss: 0.262613, Val Acc: 0.474227\n",
      "Epoch 980 - Train Loss: 0.254989, Train Acc: 0.506410 | Val Loss: 0.262594, Val Acc: 0.474227\n",
      "Epoch 981 - Train Loss: 0.254972, Train Acc: 0.506410 | Val Loss: 0.262575, Val Acc: 0.474227\n",
      "Epoch 982 - Train Loss: 0.254954, Train Acc: 0.506410 | Val Loss: 0.262556, Val Acc: 0.474227\n",
      "Epoch 983 - Train Loss: 0.254937, Train Acc: 0.506410 | Val Loss: 0.262536, Val Acc: 0.474227\n",
      "Epoch 984 - Train Loss: 0.254919, Train Acc: 0.506410 | Val Loss: 0.262517, Val Acc: 0.474227\n",
      "Epoch 985 - Train Loss: 0.254901, Train Acc: 0.506410 | Val Loss: 0.262497, Val Acc: 0.474227\n",
      "Epoch 986 - Train Loss: 0.254883, Train Acc: 0.506410 | Val Loss: 0.262477, Val Acc: 0.474227\n",
      "Epoch 987 - Train Loss: 0.254866, Train Acc: 0.506410 | Val Loss: 0.262458, Val Acc: 0.474227\n",
      "Epoch 988 - Train Loss: 0.254848, Train Acc: 0.506410 | Val Loss: 0.262438, Val Acc: 0.474227\n",
      "Epoch 989 - Train Loss: 0.254830, Train Acc: 0.506410 | Val Loss: 0.262419, Val Acc: 0.474227\n",
      "Epoch 990 - Train Loss: 0.254813, Train Acc: 0.506410 | Val Loss: 0.262399, Val Acc: 0.474227\n",
      "Epoch 991 - Train Loss: 0.254795, Train Acc: 0.506410 | Val Loss: 0.262380, Val Acc: 0.474227\n",
      "Epoch 992 - Train Loss: 0.254777, Train Acc: 0.506410 | Val Loss: 0.262360, Val Acc: 0.474227\n",
      "Epoch 993 - Train Loss: 0.254759, Train Acc: 0.506410 | Val Loss: 0.262340, Val Acc: 0.474227\n",
      "Epoch 994 - Train Loss: 0.254742, Train Acc: 0.506410 | Val Loss: 0.262320, Val Acc: 0.474227\n",
      "Epoch 995 - Train Loss: 0.254724, Train Acc: 0.506410 | Val Loss: 0.262300, Val Acc: 0.474227\n",
      "Epoch 996 - Train Loss: 0.254706, Train Acc: 0.506410 | Val Loss: 0.262280, Val Acc: 0.474227\n",
      "Epoch 997 - Train Loss: 0.254688, Train Acc: 0.506410 | Val Loss: 0.262260, Val Acc: 0.474227\n",
      "Epoch 998 - Train Loss: 0.254670, Train Acc: 0.506410 | Val Loss: 0.262240, Val Acc: 0.474227\n",
      "Epoch 999 - Train Loss: 0.254653, Train Acc: 0.506410 | Val Loss: 0.262220, Val Acc: 0.474227\n",
      "Epoch 1000 - Train Loss: 0.254635, Train Acc: 0.506410 | Val Loss: 0.262200, Val Acc: 0.474227\n",
      "Epoch 1001 - Train Loss: 0.254617, Train Acc: 0.506410 | Val Loss: 0.262180, Val Acc: 0.474227\n",
      "Epoch 1002 - Train Loss: 0.254599, Train Acc: 0.506410 | Val Loss: 0.262160, Val Acc: 0.474227\n",
      "Epoch 1003 - Train Loss: 0.254581, Train Acc: 0.506410 | Val Loss: 0.262139, Val Acc: 0.474227\n",
      "Epoch 1004 - Train Loss: 0.254563, Train Acc: 0.506410 | Val Loss: 0.262119, Val Acc: 0.474227\n",
      "Epoch 1005 - Train Loss: 0.254545, Train Acc: 0.506410 | Val Loss: 0.262099, Val Acc: 0.474227\n",
      "Epoch 1006 - Train Loss: 0.254527, Train Acc: 0.506410 | Val Loss: 0.262079, Val Acc: 0.474227\n",
      "Epoch 1007 - Train Loss: 0.254509, Train Acc: 0.506410 | Val Loss: 0.262059, Val Acc: 0.474227\n",
      "Epoch 1008 - Train Loss: 0.254491, Train Acc: 0.506410 | Val Loss: 0.262040, Val Acc: 0.474227\n",
      "Epoch 1009 - Train Loss: 0.254473, Train Acc: 0.506410 | Val Loss: 0.262020, Val Acc: 0.474227\n",
      "Epoch 1010 - Train Loss: 0.254456, Train Acc: 0.506410 | Val Loss: 0.262000, Val Acc: 0.474227\n",
      "Epoch 1011 - Train Loss: 0.254438, Train Acc: 0.506410 | Val Loss: 0.261980, Val Acc: 0.474227\n",
      "Epoch 1012 - Train Loss: 0.254420, Train Acc: 0.506410 | Val Loss: 0.261961, Val Acc: 0.474227\n",
      "Epoch 1013 - Train Loss: 0.254402, Train Acc: 0.506410 | Val Loss: 0.261941, Val Acc: 0.474227\n",
      "Epoch 1014 - Train Loss: 0.254384, Train Acc: 0.506410 | Val Loss: 0.261921, Val Acc: 0.474227\n",
      "Epoch 1015 - Train Loss: 0.254366, Train Acc: 0.506410 | Val Loss: 0.261900, Val Acc: 0.474227\n",
      "Epoch 1016 - Train Loss: 0.254348, Train Acc: 0.506410 | Val Loss: 0.261880, Val Acc: 0.474227\n",
      "Epoch 1017 - Train Loss: 0.254329, Train Acc: 0.506410 | Val Loss: 0.261860, Val Acc: 0.474227\n",
      "Epoch 1018 - Train Loss: 0.254311, Train Acc: 0.506410 | Val Loss: 0.261840, Val Acc: 0.474227\n",
      "Epoch 1019 - Train Loss: 0.254293, Train Acc: 0.506410 | Val Loss: 0.261820, Val Acc: 0.474227\n",
      "Epoch 1020 - Train Loss: 0.254275, Train Acc: 0.506410 | Val Loss: 0.261800, Val Acc: 0.474227\n",
      "Epoch 1021 - Train Loss: 0.254257, Train Acc: 0.506410 | Val Loss: 0.261780, Val Acc: 0.474227\n",
      "Epoch 1022 - Train Loss: 0.254238, Train Acc: 0.506410 | Val Loss: 0.261760, Val Acc: 0.474227\n",
      "Epoch 1023 - Train Loss: 0.254220, Train Acc: 0.506410 | Val Loss: 0.261740, Val Acc: 0.474227\n",
      "Epoch 1024 - Train Loss: 0.254202, Train Acc: 0.506410 | Val Loss: 0.261720, Val Acc: 0.474227\n",
      "Epoch 1025 - Train Loss: 0.254183, Train Acc: 0.506410 | Val Loss: 0.261700, Val Acc: 0.474227\n",
      "Epoch 1026 - Train Loss: 0.254165, Train Acc: 0.506410 | Val Loss: 0.261680, Val Acc: 0.474227\n",
      "Epoch 1027 - Train Loss: 0.254147, Train Acc: 0.506410 | Val Loss: 0.261660, Val Acc: 0.474227\n",
      "Epoch 1028 - Train Loss: 0.254128, Train Acc: 0.506410 | Val Loss: 0.261640, Val Acc: 0.474227\n",
      "Epoch 1029 - Train Loss: 0.254110, Train Acc: 0.506410 | Val Loss: 0.261620, Val Acc: 0.474227\n",
      "Epoch 1030 - Train Loss: 0.254091, Train Acc: 0.506410 | Val Loss: 0.261600, Val Acc: 0.474227\n",
      "Epoch 1031 - Train Loss: 0.254073, Train Acc: 0.506410 | Val Loss: 0.261579, Val Acc: 0.474227\n",
      "Epoch 1032 - Train Loss: 0.254055, Train Acc: 0.506410 | Val Loss: 0.261559, Val Acc: 0.474227\n",
      "Epoch 1033 - Train Loss: 0.254036, Train Acc: 0.506410 | Val Loss: 0.261539, Val Acc: 0.474227\n",
      "Epoch 1034 - Train Loss: 0.254017, Train Acc: 0.506410 | Val Loss: 0.261519, Val Acc: 0.474227\n",
      "Epoch 1035 - Train Loss: 0.253999, Train Acc: 0.506410 | Val Loss: 0.261499, Val Acc: 0.474227\n",
      "Epoch 1036 - Train Loss: 0.253980, Train Acc: 0.506410 | Val Loss: 0.261478, Val Acc: 0.474227\n",
      "Epoch 1037 - Train Loss: 0.253962, Train Acc: 0.506410 | Val Loss: 0.261458, Val Acc: 0.474227\n",
      "Epoch 1038 - Train Loss: 0.253943, Train Acc: 0.506410 | Val Loss: 0.261438, Val Acc: 0.474227\n",
      "Epoch 1039 - Train Loss: 0.253925, Train Acc: 0.506410 | Val Loss: 0.261417, Val Acc: 0.474227\n",
      "Epoch 1040 - Train Loss: 0.253906, Train Acc: 0.506410 | Val Loss: 0.261397, Val Acc: 0.474227\n",
      "Epoch 1041 - Train Loss: 0.253887, Train Acc: 0.506410 | Val Loss: 0.261377, Val Acc: 0.474227\n",
      "Epoch 1042 - Train Loss: 0.253869, Train Acc: 0.506410 | Val Loss: 0.261357, Val Acc: 0.474227\n",
      "Epoch 1043 - Train Loss: 0.253850, Train Acc: 0.506410 | Val Loss: 0.261337, Val Acc: 0.474227\n",
      "Epoch 1044 - Train Loss: 0.253832, Train Acc: 0.506410 | Val Loss: 0.261317, Val Acc: 0.474227\n",
      "Epoch 1045 - Train Loss: 0.253813, Train Acc: 0.506410 | Val Loss: 0.261296, Val Acc: 0.474227\n",
      "Epoch 1046 - Train Loss: 0.253795, Train Acc: 0.506410 | Val Loss: 0.261276, Val Acc: 0.474227\n",
      "Epoch 1047 - Train Loss: 0.253776, Train Acc: 0.506410 | Val Loss: 0.261255, Val Acc: 0.474227\n",
      "Epoch 1048 - Train Loss: 0.253758, Train Acc: 0.506410 | Val Loss: 0.261235, Val Acc: 0.474227\n",
      "Epoch 1049 - Train Loss: 0.253739, Train Acc: 0.506410 | Val Loss: 0.261215, Val Acc: 0.474227\n",
      "Epoch 1050 - Train Loss: 0.253720, Train Acc: 0.506410 | Val Loss: 0.261194, Val Acc: 0.474227\n",
      "Epoch 1051 - Train Loss: 0.253702, Train Acc: 0.506410 | Val Loss: 0.261174, Val Acc: 0.474227\n",
      "Epoch 1052 - Train Loss: 0.253683, Train Acc: 0.506410 | Val Loss: 0.261154, Val Acc: 0.474227\n",
      "Epoch 1053 - Train Loss: 0.253665, Train Acc: 0.506410 | Val Loss: 0.261133, Val Acc: 0.474227\n",
      "Epoch 1054 - Train Loss: 0.253646, Train Acc: 0.506410 | Val Loss: 0.261113, Val Acc: 0.474227\n",
      "Epoch 1055 - Train Loss: 0.253627, Train Acc: 0.506410 | Val Loss: 0.261093, Val Acc: 0.474227\n",
      "Epoch 1056 - Train Loss: 0.253609, Train Acc: 0.506410 | Val Loss: 0.261072, Val Acc: 0.474227\n",
      "Epoch 1057 - Train Loss: 0.253590, Train Acc: 0.506410 | Val Loss: 0.261052, Val Acc: 0.474227\n",
      "Epoch 1058 - Train Loss: 0.253572, Train Acc: 0.506410 | Val Loss: 0.261032, Val Acc: 0.474227\n",
      "Epoch 1059 - Train Loss: 0.253553, Train Acc: 0.507692 | Val Loss: 0.261012, Val Acc: 0.474227\n",
      "Epoch 1060 - Train Loss: 0.253535, Train Acc: 0.507692 | Val Loss: 0.260991, Val Acc: 0.474227\n",
      "Epoch 1061 - Train Loss: 0.253516, Train Acc: 0.507692 | Val Loss: 0.260971, Val Acc: 0.474227\n",
      "Epoch 1062 - Train Loss: 0.253498, Train Acc: 0.507692 | Val Loss: 0.260951, Val Acc: 0.474227\n",
      "Epoch 1063 - Train Loss: 0.253479, Train Acc: 0.507692 | Val Loss: 0.260930, Val Acc: 0.474227\n",
      "Epoch 1064 - Train Loss: 0.253460, Train Acc: 0.507692 | Val Loss: 0.260910, Val Acc: 0.474227\n",
      "Epoch 1065 - Train Loss: 0.253442, Train Acc: 0.507692 | Val Loss: 0.260890, Val Acc: 0.474227\n",
      "Epoch 1066 - Train Loss: 0.253424, Train Acc: 0.507692 | Val Loss: 0.260871, Val Acc: 0.474227\n",
      "Epoch 1067 - Train Loss: 0.253405, Train Acc: 0.507692 | Val Loss: 0.260851, Val Acc: 0.474227\n",
      "Epoch 1068 - Train Loss: 0.253387, Train Acc: 0.507692 | Val Loss: 0.260831, Val Acc: 0.474227\n",
      "Epoch 1069 - Train Loss: 0.253369, Train Acc: 0.507692 | Val Loss: 0.260811, Val Acc: 0.474227\n",
      "Epoch 1070 - Train Loss: 0.253350, Train Acc: 0.507692 | Val Loss: 0.260791, Val Acc: 0.474227\n",
      "Epoch 1071 - Train Loss: 0.253332, Train Acc: 0.507692 | Val Loss: 0.260771, Val Acc: 0.474227\n",
      "Epoch 1072 - Train Loss: 0.253313, Train Acc: 0.507692 | Val Loss: 0.260752, Val Acc: 0.474227\n",
      "Epoch 1073 - Train Loss: 0.253294, Train Acc: 0.507692 | Val Loss: 0.260731, Val Acc: 0.474227\n",
      "Epoch 1074 - Train Loss: 0.253276, Train Acc: 0.507692 | Val Loss: 0.260711, Val Acc: 0.474227\n",
      "Epoch 1075 - Train Loss: 0.253257, Train Acc: 0.507692 | Val Loss: 0.260691, Val Acc: 0.474227\n",
      "Epoch 1076 - Train Loss: 0.253238, Train Acc: 0.507692 | Val Loss: 0.260671, Val Acc: 0.474227\n",
      "Epoch 1077 - Train Loss: 0.253220, Train Acc: 0.507692 | Val Loss: 0.260651, Val Acc: 0.474227\n",
      "Epoch 1078 - Train Loss: 0.253201, Train Acc: 0.507692 | Val Loss: 0.260630, Val Acc: 0.474227\n",
      "Epoch 1079 - Train Loss: 0.253182, Train Acc: 0.507692 | Val Loss: 0.260610, Val Acc: 0.474227\n",
      "Epoch 1080 - Train Loss: 0.253163, Train Acc: 0.507692 | Val Loss: 0.260590, Val Acc: 0.474227\n",
      "Epoch 1081 - Train Loss: 0.253145, Train Acc: 0.507692 | Val Loss: 0.260569, Val Acc: 0.474227\n",
      "Epoch 1082 - Train Loss: 0.253126, Train Acc: 0.507692 | Val Loss: 0.260549, Val Acc: 0.474227\n",
      "Epoch 1083 - Train Loss: 0.253106, Train Acc: 0.507692 | Val Loss: 0.260528, Val Acc: 0.474227\n",
      "Epoch 1084 - Train Loss: 0.253087, Train Acc: 0.507692 | Val Loss: 0.260508, Val Acc: 0.474227\n",
      "Epoch 1085 - Train Loss: 0.253068, Train Acc: 0.507692 | Val Loss: 0.260487, Val Acc: 0.474227\n",
      "Epoch 1086 - Train Loss: 0.253049, Train Acc: 0.507692 | Val Loss: 0.260467, Val Acc: 0.474227\n",
      "Epoch 1087 - Train Loss: 0.253030, Train Acc: 0.507692 | Val Loss: 0.260447, Val Acc: 0.474227\n",
      "Epoch 1088 - Train Loss: 0.253011, Train Acc: 0.507692 | Val Loss: 0.260426, Val Acc: 0.474227\n",
      "Epoch 1089 - Train Loss: 0.252992, Train Acc: 0.507692 | Val Loss: 0.260406, Val Acc: 0.474227\n",
      "Epoch 1090 - Train Loss: 0.252973, Train Acc: 0.507692 | Val Loss: 0.260385, Val Acc: 0.474227\n",
      "Epoch 1091 - Train Loss: 0.252954, Train Acc: 0.507692 | Val Loss: 0.260365, Val Acc: 0.474227\n",
      "Epoch 1092 - Train Loss: 0.252935, Train Acc: 0.507692 | Val Loss: 0.260344, Val Acc: 0.474227\n",
      "Epoch 1093 - Train Loss: 0.252916, Train Acc: 0.507692 | Val Loss: 0.260324, Val Acc: 0.474227\n",
      "Epoch 1094 - Train Loss: 0.252897, Train Acc: 0.507692 | Val Loss: 0.260303, Val Acc: 0.474227\n",
      "Epoch 1095 - Train Loss: 0.252878, Train Acc: 0.507692 | Val Loss: 0.260282, Val Acc: 0.474227\n",
      "Epoch 1096 - Train Loss: 0.252858, Train Acc: 0.507692 | Val Loss: 0.260261, Val Acc: 0.474227\n",
      "Epoch 1097 - Train Loss: 0.252839, Train Acc: 0.507692 | Val Loss: 0.260240, Val Acc: 0.474227\n",
      "Epoch 1098 - Train Loss: 0.252820, Train Acc: 0.507692 | Val Loss: 0.260219, Val Acc: 0.474227\n",
      "Epoch 1099 - Train Loss: 0.252800, Train Acc: 0.507692 | Val Loss: 0.260198, Val Acc: 0.474227\n",
      "Epoch 1100 - Train Loss: 0.252781, Train Acc: 0.507692 | Val Loss: 0.260177, Val Acc: 0.474227\n",
      "Epoch 1101 - Train Loss: 0.252762, Train Acc: 0.507692 | Val Loss: 0.260156, Val Acc: 0.474227\n",
      "Epoch 1102 - Train Loss: 0.252743, Train Acc: 0.507692 | Val Loss: 0.260135, Val Acc: 0.474227\n",
      "Epoch 1103 - Train Loss: 0.252723, Train Acc: 0.507692 | Val Loss: 0.260114, Val Acc: 0.474227\n",
      "Epoch 1104 - Train Loss: 0.252704, Train Acc: 0.507692 | Val Loss: 0.260093, Val Acc: 0.474227\n",
      "Epoch 1105 - Train Loss: 0.252685, Train Acc: 0.507692 | Val Loss: 0.260073, Val Acc: 0.474227\n",
      "Epoch 1106 - Train Loss: 0.252666, Train Acc: 0.507692 | Val Loss: 0.260052, Val Acc: 0.474227\n",
      "Epoch 1107 - Train Loss: 0.252647, Train Acc: 0.507692 | Val Loss: 0.260031, Val Acc: 0.474227\n",
      "Epoch 1108 - Train Loss: 0.252628, Train Acc: 0.507692 | Val Loss: 0.260010, Val Acc: 0.474227\n",
      "Epoch 1109 - Train Loss: 0.252608, Train Acc: 0.507692 | Val Loss: 0.259989, Val Acc: 0.474227\n",
      "Epoch 1110 - Train Loss: 0.252589, Train Acc: 0.507692 | Val Loss: 0.259968, Val Acc: 0.474227\n",
      "Epoch 1111 - Train Loss: 0.252570, Train Acc: 0.507692 | Val Loss: 0.259947, Val Acc: 0.474227\n",
      "Epoch 1112 - Train Loss: 0.252551, Train Acc: 0.507692 | Val Loss: 0.259926, Val Acc: 0.474227\n",
      "Epoch 1113 - Train Loss: 0.252532, Train Acc: 0.507692 | Val Loss: 0.259905, Val Acc: 0.474227\n",
      "Epoch 1114 - Train Loss: 0.252513, Train Acc: 0.507692 | Val Loss: 0.259884, Val Acc: 0.474227\n",
      "Epoch 1115 - Train Loss: 0.252494, Train Acc: 0.507692 | Val Loss: 0.259863, Val Acc: 0.474227\n",
      "Epoch 1116 - Train Loss: 0.252475, Train Acc: 0.507692 | Val Loss: 0.259842, Val Acc: 0.474227\n",
      "Epoch 1117 - Train Loss: 0.252456, Train Acc: 0.507692 | Val Loss: 0.259821, Val Acc: 0.474227\n",
      "Epoch 1118 - Train Loss: 0.252437, Train Acc: 0.507692 | Val Loss: 0.259800, Val Acc: 0.474227\n",
      "Epoch 1119 - Train Loss: 0.252418, Train Acc: 0.507692 | Val Loss: 0.259779, Val Acc: 0.474227\n",
      "Epoch 1120 - Train Loss: 0.252399, Train Acc: 0.507692 | Val Loss: 0.259757, Val Acc: 0.474227\n",
      "Epoch 1121 - Train Loss: 0.252380, Train Acc: 0.507692 | Val Loss: 0.259736, Val Acc: 0.474227\n",
      "Epoch 1122 - Train Loss: 0.252360, Train Acc: 0.507692 | Val Loss: 0.259715, Val Acc: 0.474227\n",
      "Epoch 1123 - Train Loss: 0.252341, Train Acc: 0.507692 | Val Loss: 0.259693, Val Acc: 0.474227\n",
      "Epoch 1124 - Train Loss: 0.252322, Train Acc: 0.507692 | Val Loss: 0.259672, Val Acc: 0.474227\n",
      "Epoch 1125 - Train Loss: 0.252303, Train Acc: 0.507692 | Val Loss: 0.259651, Val Acc: 0.474227\n",
      "Epoch 1126 - Train Loss: 0.252283, Train Acc: 0.507692 | Val Loss: 0.259629, Val Acc: 0.474227\n",
      "Epoch 1127 - Train Loss: 0.252264, Train Acc: 0.507692 | Val Loss: 0.259607, Val Acc: 0.474227\n",
      "Epoch 1128 - Train Loss: 0.252245, Train Acc: 0.507692 | Val Loss: 0.259586, Val Acc: 0.474227\n",
      "Epoch 1129 - Train Loss: 0.252226, Train Acc: 0.507692 | Val Loss: 0.259565, Val Acc: 0.474227\n",
      "Epoch 1130 - Train Loss: 0.252206, Train Acc: 0.507692 | Val Loss: 0.259543, Val Acc: 0.474227\n",
      "Epoch 1131 - Train Loss: 0.252187, Train Acc: 0.507692 | Val Loss: 0.259522, Val Acc: 0.474227\n",
      "Epoch 1132 - Train Loss: 0.252168, Train Acc: 0.507692 | Val Loss: 0.259500, Val Acc: 0.474227\n",
      "Epoch 1133 - Train Loss: 0.252149, Train Acc: 0.508974 | Val Loss: 0.259479, Val Acc: 0.474227\n",
      "Epoch 1134 - Train Loss: 0.252130, Train Acc: 0.508974 | Val Loss: 0.259458, Val Acc: 0.474227\n",
      "Epoch 1135 - Train Loss: 0.252110, Train Acc: 0.508974 | Val Loss: 0.259437, Val Acc: 0.474227\n",
      "Epoch 1136 - Train Loss: 0.252091, Train Acc: 0.508974 | Val Loss: 0.259415, Val Acc: 0.474227\n",
      "Epoch 1137 - Train Loss: 0.252072, Train Acc: 0.508974 | Val Loss: 0.259394, Val Acc: 0.474227\n",
      "Epoch 1138 - Train Loss: 0.252053, Train Acc: 0.508974 | Val Loss: 0.259372, Val Acc: 0.474227\n",
      "Epoch 1139 - Train Loss: 0.252033, Train Acc: 0.508974 | Val Loss: 0.259351, Val Acc: 0.474227\n",
      "Epoch 1140 - Train Loss: 0.252014, Train Acc: 0.508974 | Val Loss: 0.259330, Val Acc: 0.474227\n",
      "Epoch 1141 - Train Loss: 0.251995, Train Acc: 0.508974 | Val Loss: 0.259309, Val Acc: 0.474227\n",
      "Epoch 1142 - Train Loss: 0.251975, Train Acc: 0.508974 | Val Loss: 0.259288, Val Acc: 0.474227\n",
      "Epoch 1143 - Train Loss: 0.251956, Train Acc: 0.508974 | Val Loss: 0.259267, Val Acc: 0.474227\n",
      "Epoch 1144 - Train Loss: 0.251936, Train Acc: 0.508974 | Val Loss: 0.259245, Val Acc: 0.474227\n",
      "Epoch 1145 - Train Loss: 0.251916, Train Acc: 0.508974 | Val Loss: 0.259224, Val Acc: 0.474227\n",
      "Epoch 1146 - Train Loss: 0.251897, Train Acc: 0.508974 | Val Loss: 0.259203, Val Acc: 0.474227\n",
      "Epoch 1147 - Train Loss: 0.251877, Train Acc: 0.508974 | Val Loss: 0.259182, Val Acc: 0.474227\n",
      "Epoch 1148 - Train Loss: 0.251858, Train Acc: 0.508974 | Val Loss: 0.259161, Val Acc: 0.474227\n",
      "Epoch 1149 - Train Loss: 0.251838, Train Acc: 0.508974 | Val Loss: 0.259140, Val Acc: 0.474227\n",
      "Epoch 1150 - Train Loss: 0.251819, Train Acc: 0.508974 | Val Loss: 0.259119, Val Acc: 0.474227\n",
      "Epoch 1151 - Train Loss: 0.251799, Train Acc: 0.508974 | Val Loss: 0.259098, Val Acc: 0.474227\n",
      "Epoch 1152 - Train Loss: 0.251780, Train Acc: 0.508974 | Val Loss: 0.259077, Val Acc: 0.474227\n",
      "Epoch 1153 - Train Loss: 0.251760, Train Acc: 0.508974 | Val Loss: 0.259056, Val Acc: 0.474227\n",
      "Epoch 1154 - Train Loss: 0.251741, Train Acc: 0.508974 | Val Loss: 0.259035, Val Acc: 0.474227\n",
      "Epoch 1155 - Train Loss: 0.251721, Train Acc: 0.508974 | Val Loss: 0.259014, Val Acc: 0.474227\n",
      "Epoch 1156 - Train Loss: 0.251702, Train Acc: 0.508974 | Val Loss: 0.258993, Val Acc: 0.474227\n",
      "Epoch 1157 - Train Loss: 0.251682, Train Acc: 0.508974 | Val Loss: 0.258972, Val Acc: 0.474227\n",
      "Epoch 1158 - Train Loss: 0.251663, Train Acc: 0.508974 | Val Loss: 0.258951, Val Acc: 0.474227\n",
      "Epoch 1159 - Train Loss: 0.251644, Train Acc: 0.508974 | Val Loss: 0.258930, Val Acc: 0.474227\n",
      "Epoch 1160 - Train Loss: 0.251624, Train Acc: 0.508974 | Val Loss: 0.258909, Val Acc: 0.474227\n",
      "Epoch 1161 - Train Loss: 0.251605, Train Acc: 0.508974 | Val Loss: 0.258889, Val Acc: 0.474227\n",
      "Epoch 1162 - Train Loss: 0.251585, Train Acc: 0.508974 | Val Loss: 0.258867, Val Acc: 0.474227\n",
      "Epoch 1163 - Train Loss: 0.251566, Train Acc: 0.508974 | Val Loss: 0.258847, Val Acc: 0.474227\n",
      "Epoch 1164 - Train Loss: 0.251547, Train Acc: 0.508974 | Val Loss: 0.258826, Val Acc: 0.474227\n",
      "Epoch 1165 - Train Loss: 0.251527, Train Acc: 0.510256 | Val Loss: 0.258805, Val Acc: 0.474227\n",
      "Epoch 1166 - Train Loss: 0.251508, Train Acc: 0.510256 | Val Loss: 0.258784, Val Acc: 0.474227\n",
      "Epoch 1167 - Train Loss: 0.251489, Train Acc: 0.510256 | Val Loss: 0.258763, Val Acc: 0.474227\n",
      "Epoch 1168 - Train Loss: 0.251470, Train Acc: 0.510256 | Val Loss: 0.258742, Val Acc: 0.474227\n",
      "Epoch 1169 - Train Loss: 0.251450, Train Acc: 0.510256 | Val Loss: 0.258721, Val Acc: 0.474227\n",
      "Epoch 1170 - Train Loss: 0.251431, Train Acc: 0.510256 | Val Loss: 0.258700, Val Acc: 0.474227\n",
      "Epoch 1171 - Train Loss: 0.251412, Train Acc: 0.510256 | Val Loss: 0.258679, Val Acc: 0.474227\n",
      "Epoch 1172 - Train Loss: 0.251393, Train Acc: 0.510256 | Val Loss: 0.258657, Val Acc: 0.474227\n",
      "Epoch 1173 - Train Loss: 0.251373, Train Acc: 0.510256 | Val Loss: 0.258636, Val Acc: 0.474227\n",
      "Epoch 1174 - Train Loss: 0.251354, Train Acc: 0.510256 | Val Loss: 0.258615, Val Acc: 0.474227\n",
      "Epoch 1175 - Train Loss: 0.251334, Train Acc: 0.510256 | Val Loss: 0.258594, Val Acc: 0.474227\n",
      "Epoch 1176 - Train Loss: 0.251315, Train Acc: 0.510256 | Val Loss: 0.258573, Val Acc: 0.474227\n",
      "Epoch 1177 - Train Loss: 0.251295, Train Acc: 0.510256 | Val Loss: 0.258552, Val Acc: 0.474227\n",
      "Epoch 1178 - Train Loss: 0.251276, Train Acc: 0.510256 | Val Loss: 0.258531, Val Acc: 0.474227\n",
      "Epoch 1179 - Train Loss: 0.251257, Train Acc: 0.510256 | Val Loss: 0.258511, Val Acc: 0.474227\n",
      "Epoch 1180 - Train Loss: 0.251237, Train Acc: 0.510256 | Val Loss: 0.258491, Val Acc: 0.474227\n",
      "Epoch 1181 - Train Loss: 0.251217, Train Acc: 0.510256 | Val Loss: 0.258470, Val Acc: 0.474227\n",
      "Epoch 1182 - Train Loss: 0.251198, Train Acc: 0.510256 | Val Loss: 0.258450, Val Acc: 0.474227\n",
      "Epoch 1183 - Train Loss: 0.251178, Train Acc: 0.510256 | Val Loss: 0.258430, Val Acc: 0.474227\n",
      "Epoch 1184 - Train Loss: 0.251158, Train Acc: 0.510256 | Val Loss: 0.258409, Val Acc: 0.474227\n",
      "Epoch 1185 - Train Loss: 0.251139, Train Acc: 0.510256 | Val Loss: 0.258389, Val Acc: 0.474227\n",
      "Epoch 1186 - Train Loss: 0.251119, Train Acc: 0.510256 | Val Loss: 0.258368, Val Acc: 0.474227\n",
      "Epoch 1187 - Train Loss: 0.251099, Train Acc: 0.510256 | Val Loss: 0.258348, Val Acc: 0.474227\n",
      "Epoch 1188 - Train Loss: 0.251079, Train Acc: 0.510256 | Val Loss: 0.258328, Val Acc: 0.474227\n",
      "Epoch 1189 - Train Loss: 0.251059, Train Acc: 0.510256 | Val Loss: 0.258308, Val Acc: 0.474227\n",
      "Epoch 1190 - Train Loss: 0.251039, Train Acc: 0.510256 | Val Loss: 0.258288, Val Acc: 0.474227\n",
      "Epoch 1191 - Train Loss: 0.251019, Train Acc: 0.510256 | Val Loss: 0.258268, Val Acc: 0.474227\n",
      "Epoch 1192 - Train Loss: 0.250999, Train Acc: 0.510256 | Val Loss: 0.258248, Val Acc: 0.474227\n",
      "Epoch 1193 - Train Loss: 0.250979, Train Acc: 0.510256 | Val Loss: 0.258228, Val Acc: 0.474227\n",
      "Epoch 1194 - Train Loss: 0.250959, Train Acc: 0.510256 | Val Loss: 0.258208, Val Acc: 0.474227\n",
      "Epoch 1195 - Train Loss: 0.250939, Train Acc: 0.510256 | Val Loss: 0.258189, Val Acc: 0.474227\n",
      "Epoch 1196 - Train Loss: 0.250919, Train Acc: 0.510256 | Val Loss: 0.258169, Val Acc: 0.474227\n",
      "Epoch 1197 - Train Loss: 0.250898, Train Acc: 0.510256 | Val Loss: 0.258150, Val Acc: 0.474227\n",
      "Epoch 1198 - Train Loss: 0.250878, Train Acc: 0.510256 | Val Loss: 0.258130, Val Acc: 0.474227\n",
      "Epoch 1199 - Train Loss: 0.250858, Train Acc: 0.510256 | Val Loss: 0.258111, Val Acc: 0.474227\n",
      "Epoch 1200 - Train Loss: 0.250838, Train Acc: 0.510256 | Val Loss: 0.258091, Val Acc: 0.474227\n",
      "Epoch 1201 - Train Loss: 0.250818, Train Acc: 0.510256 | Val Loss: 0.258071, Val Acc: 0.474227\n",
      "Epoch 1202 - Train Loss: 0.250798, Train Acc: 0.510256 | Val Loss: 0.258052, Val Acc: 0.474227\n",
      "Epoch 1203 - Train Loss: 0.250777, Train Acc: 0.510256 | Val Loss: 0.258032, Val Acc: 0.474227\n",
      "Epoch 1204 - Train Loss: 0.250757, Train Acc: 0.510256 | Val Loss: 0.258013, Val Acc: 0.474227\n",
      "Epoch 1205 - Train Loss: 0.250737, Train Acc: 0.510256 | Val Loss: 0.257993, Val Acc: 0.474227\n",
      "Epoch 1206 - Train Loss: 0.250717, Train Acc: 0.510256 | Val Loss: 0.257974, Val Acc: 0.474227\n",
      "Epoch 1207 - Train Loss: 0.250697, Train Acc: 0.510256 | Val Loss: 0.257954, Val Acc: 0.474227\n",
      "Epoch 1208 - Train Loss: 0.250677, Train Acc: 0.510256 | Val Loss: 0.257934, Val Acc: 0.474227\n",
      "Epoch 1209 - Train Loss: 0.250657, Train Acc: 0.510256 | Val Loss: 0.257915, Val Acc: 0.474227\n",
      "Epoch 1210 - Train Loss: 0.250637, Train Acc: 0.510256 | Val Loss: 0.257895, Val Acc: 0.474227\n",
      "Epoch 1211 - Train Loss: 0.250617, Train Acc: 0.510256 | Val Loss: 0.257876, Val Acc: 0.474227\n",
      "Epoch 1212 - Train Loss: 0.250598, Train Acc: 0.510256 | Val Loss: 0.257856, Val Acc: 0.474227\n",
      "Epoch 1213 - Train Loss: 0.250578, Train Acc: 0.510256 | Val Loss: 0.257836, Val Acc: 0.474227\n",
      "Epoch 1214 - Train Loss: 0.250558, Train Acc: 0.510256 | Val Loss: 0.257816, Val Acc: 0.474227\n",
      "Epoch 1215 - Train Loss: 0.250538, Train Acc: 0.510256 | Val Loss: 0.257796, Val Acc: 0.474227\n",
      "Epoch 1216 - Train Loss: 0.250518, Train Acc: 0.510256 | Val Loss: 0.257776, Val Acc: 0.474227\n",
      "Epoch 1217 - Train Loss: 0.250498, Train Acc: 0.510256 | Val Loss: 0.257756, Val Acc: 0.474227\n",
      "Epoch 1218 - Train Loss: 0.250478, Train Acc: 0.510256 | Val Loss: 0.257736, Val Acc: 0.474227\n",
      "Epoch 1219 - Train Loss: 0.250459, Train Acc: 0.510256 | Val Loss: 0.257716, Val Acc: 0.474227\n",
      "Epoch 1220 - Train Loss: 0.250439, Train Acc: 0.510256 | Val Loss: 0.257697, Val Acc: 0.474227\n",
      "Epoch 1221 - Train Loss: 0.250419, Train Acc: 0.510256 | Val Loss: 0.257677, Val Acc: 0.474227\n",
      "Epoch 1222 - Train Loss: 0.250399, Train Acc: 0.510256 | Val Loss: 0.257658, Val Acc: 0.474227\n",
      "Epoch 1223 - Train Loss: 0.250379, Train Acc: 0.510256 | Val Loss: 0.257638, Val Acc: 0.474227\n",
      "Epoch 1224 - Train Loss: 0.250360, Train Acc: 0.510256 | Val Loss: 0.257618, Val Acc: 0.474227\n",
      "Epoch 1225 - Train Loss: 0.250340, Train Acc: 0.510256 | Val Loss: 0.257599, Val Acc: 0.474227\n",
      "Epoch 1226 - Train Loss: 0.250320, Train Acc: 0.510256 | Val Loss: 0.257579, Val Acc: 0.474227\n",
      "Epoch 1227 - Train Loss: 0.250300, Train Acc: 0.510256 | Val Loss: 0.257560, Val Acc: 0.474227\n",
      "Epoch 1228 - Train Loss: 0.250280, Train Acc: 0.510256 | Val Loss: 0.257540, Val Acc: 0.474227\n",
      "Epoch 1229 - Train Loss: 0.250260, Train Acc: 0.510256 | Val Loss: 0.257521, Val Acc: 0.474227\n",
      "Epoch 1230 - Train Loss: 0.250240, Train Acc: 0.510256 | Val Loss: 0.257501, Val Acc: 0.474227\n",
      "Epoch 1231 - Train Loss: 0.250221, Train Acc: 0.510256 | Val Loss: 0.257481, Val Acc: 0.474227\n",
      "Epoch 1232 - Train Loss: 0.250201, Train Acc: 0.510256 | Val Loss: 0.257462, Val Acc: 0.474227\n",
      "Epoch 1233 - Train Loss: 0.250181, Train Acc: 0.510256 | Val Loss: 0.257443, Val Acc: 0.474227\n",
      "Epoch 1234 - Train Loss: 0.250162, Train Acc: 0.510256 | Val Loss: 0.257423, Val Acc: 0.474227\n",
      "Epoch 1235 - Train Loss: 0.250142, Train Acc: 0.510256 | Val Loss: 0.257404, Val Acc: 0.474227\n",
      "Epoch 1236 - Train Loss: 0.250122, Train Acc: 0.510256 | Val Loss: 0.257384, Val Acc: 0.474227\n",
      "Epoch 1237 - Train Loss: 0.250103, Train Acc: 0.510256 | Val Loss: 0.257365, Val Acc: 0.474227\n",
      "Epoch 1238 - Train Loss: 0.250083, Train Acc: 0.510256 | Val Loss: 0.257345, Val Acc: 0.474227\n",
      "Epoch 1239 - Train Loss: 0.250064, Train Acc: 0.510256 | Val Loss: 0.257326, Val Acc: 0.474227\n",
      "Epoch 1240 - Train Loss: 0.250044, Train Acc: 0.510256 | Val Loss: 0.257306, Val Acc: 0.474227\n",
      "Epoch 1241 - Train Loss: 0.250025, Train Acc: 0.510256 | Val Loss: 0.257287, Val Acc: 0.474227\n",
      "Epoch 1242 - Train Loss: 0.250005, Train Acc: 0.510256 | Val Loss: 0.257267, Val Acc: 0.474227\n",
      "Epoch 1243 - Train Loss: 0.249986, Train Acc: 0.510256 | Val Loss: 0.257248, Val Acc: 0.474227\n",
      "Epoch 1244 - Train Loss: 0.249966, Train Acc: 0.510256 | Val Loss: 0.257229, Val Acc: 0.474227\n",
      "Epoch 1245 - Train Loss: 0.249947, Train Acc: 0.510256 | Val Loss: 0.257209, Val Acc: 0.474227\n",
      "Epoch 1246 - Train Loss: 0.249927, Train Acc: 0.510256 | Val Loss: 0.257190, Val Acc: 0.474227\n",
      "Epoch 1247 - Train Loss: 0.249908, Train Acc: 0.510256 | Val Loss: 0.257171, Val Acc: 0.474227\n",
      "Epoch 1248 - Train Loss: 0.249889, Train Acc: 0.510256 | Val Loss: 0.257151, Val Acc: 0.474227\n",
      "Epoch 1249 - Train Loss: 0.249870, Train Acc: 0.510256 | Val Loss: 0.257132, Val Acc: 0.474227\n",
      "Epoch 1250 - Train Loss: 0.249851, Train Acc: 0.510256 | Val Loss: 0.257112, Val Acc: 0.474227\n",
      "Epoch 1251 - Train Loss: 0.249832, Train Acc: 0.510256 | Val Loss: 0.257093, Val Acc: 0.474227\n",
      "Epoch 1252 - Train Loss: 0.249812, Train Acc: 0.510256 | Val Loss: 0.257074, Val Acc: 0.474227\n",
      "Epoch 1253 - Train Loss: 0.249793, Train Acc: 0.510256 | Val Loss: 0.257054, Val Acc: 0.474227\n",
      "Epoch 1254 - Train Loss: 0.249774, Train Acc: 0.510256 | Val Loss: 0.257035, Val Acc: 0.474227\n",
      "Epoch 1255 - Train Loss: 0.249755, Train Acc: 0.510256 | Val Loss: 0.257016, Val Acc: 0.474227\n",
      "Epoch 1256 - Train Loss: 0.249735, Train Acc: 0.510256 | Val Loss: 0.256996, Val Acc: 0.474227\n",
      "Epoch 1257 - Train Loss: 0.249716, Train Acc: 0.510256 | Val Loss: 0.256977, Val Acc: 0.474227\n",
      "Epoch 1258 - Train Loss: 0.249697, Train Acc: 0.510256 | Val Loss: 0.256958, Val Acc: 0.474227\n",
      "Epoch 1259 - Train Loss: 0.249678, Train Acc: 0.510256 | Val Loss: 0.256938, Val Acc: 0.474227\n",
      "Epoch 1260 - Train Loss: 0.249659, Train Acc: 0.510256 | Val Loss: 0.256919, Val Acc: 0.474227\n",
      "Epoch 1261 - Train Loss: 0.249640, Train Acc: 0.510256 | Val Loss: 0.256900, Val Acc: 0.474227\n",
      "Epoch 1262 - Train Loss: 0.249621, Train Acc: 0.510256 | Val Loss: 0.256881, Val Acc: 0.474227\n",
      "Epoch 1263 - Train Loss: 0.249601, Train Acc: 0.510256 | Val Loss: 0.256861, Val Acc: 0.474227\n",
      "Epoch 1264 - Train Loss: 0.249582, Train Acc: 0.511538 | Val Loss: 0.256842, Val Acc: 0.474227\n",
      "Epoch 1265 - Train Loss: 0.249563, Train Acc: 0.511538 | Val Loss: 0.256823, Val Acc: 0.474227\n",
      "Epoch 1266 - Train Loss: 0.249544, Train Acc: 0.511538 | Val Loss: 0.256803, Val Acc: 0.474227\n",
      "Epoch 1267 - Train Loss: 0.249525, Train Acc: 0.511538 | Val Loss: 0.256784, Val Acc: 0.474227\n",
      "Epoch 1268 - Train Loss: 0.249506, Train Acc: 0.511538 | Val Loss: 0.256765, Val Acc: 0.474227\n",
      "Epoch 1269 - Train Loss: 0.249486, Train Acc: 0.511538 | Val Loss: 0.256745, Val Acc: 0.474227\n",
      "Epoch 1270 - Train Loss: 0.249467, Train Acc: 0.511538 | Val Loss: 0.256726, Val Acc: 0.474227\n",
      "Epoch 1271 - Train Loss: 0.249448, Train Acc: 0.511538 | Val Loss: 0.256707, Val Acc: 0.474227\n",
      "Epoch 1272 - Train Loss: 0.249429, Train Acc: 0.511538 | Val Loss: 0.256688, Val Acc: 0.474227\n",
      "Epoch 1273 - Train Loss: 0.249409, Train Acc: 0.511538 | Val Loss: 0.256668, Val Acc: 0.474227\n",
      "Epoch 1274 - Train Loss: 0.249390, Train Acc: 0.511538 | Val Loss: 0.256649, Val Acc: 0.474227\n",
      "Epoch 1275 - Train Loss: 0.249371, Train Acc: 0.511538 | Val Loss: 0.256630, Val Acc: 0.474227\n",
      "Epoch 1276 - Train Loss: 0.249352, Train Acc: 0.511538 | Val Loss: 0.256610, Val Acc: 0.474227\n",
      "Epoch 1277 - Train Loss: 0.249333, Train Acc: 0.511538 | Val Loss: 0.256591, Val Acc: 0.474227\n",
      "Epoch 1278 - Train Loss: 0.249314, Train Acc: 0.511538 | Val Loss: 0.256572, Val Acc: 0.474227\n",
      "Epoch 1279 - Train Loss: 0.249294, Train Acc: 0.511538 | Val Loss: 0.256552, Val Acc: 0.474227\n",
      "Epoch 1280 - Train Loss: 0.249275, Train Acc: 0.511538 | Val Loss: 0.256533, Val Acc: 0.474227\n",
      "Epoch 1281 - Train Loss: 0.249256, Train Acc: 0.511538 | Val Loss: 0.256514, Val Acc: 0.474227\n",
      "Epoch 1282 - Train Loss: 0.249237, Train Acc: 0.511538 | Val Loss: 0.256495, Val Acc: 0.474227\n",
      "Epoch 1283 - Train Loss: 0.249218, Train Acc: 0.511538 | Val Loss: 0.256475, Val Acc: 0.474227\n",
      "Epoch 1284 - Train Loss: 0.249199, Train Acc: 0.511538 | Val Loss: 0.256456, Val Acc: 0.474227\n",
      "Epoch 1285 - Train Loss: 0.249179, Train Acc: 0.511538 | Val Loss: 0.256437, Val Acc: 0.474227\n",
      "Epoch 1286 - Train Loss: 0.249160, Train Acc: 0.511538 | Val Loss: 0.256417, Val Acc: 0.474227\n",
      "Epoch 1287 - Train Loss: 0.249141, Train Acc: 0.511538 | Val Loss: 0.256398, Val Acc: 0.474227\n",
      "Epoch 1288 - Train Loss: 0.249122, Train Acc: 0.511538 | Val Loss: 0.256379, Val Acc: 0.474227\n",
      "Epoch 1289 - Train Loss: 0.249103, Train Acc: 0.511538 | Val Loss: 0.256359, Val Acc: 0.474227\n",
      "Epoch 1290 - Train Loss: 0.249083, Train Acc: 0.511538 | Val Loss: 0.256340, Val Acc: 0.474227\n",
      "Epoch 1291 - Train Loss: 0.249064, Train Acc: 0.511538 | Val Loss: 0.256321, Val Acc: 0.474227\n",
      "Epoch 1292 - Train Loss: 0.249045, Train Acc: 0.511538 | Val Loss: 0.256301, Val Acc: 0.474227\n",
      "Epoch 1293 - Train Loss: 0.249025, Train Acc: 0.511538 | Val Loss: 0.256282, Val Acc: 0.474227\n",
      "Epoch 1294 - Train Loss: 0.249006, Train Acc: 0.511538 | Val Loss: 0.256263, Val Acc: 0.474227\n",
      "Epoch 1295 - Train Loss: 0.248987, Train Acc: 0.511538 | Val Loss: 0.256243, Val Acc: 0.474227\n",
      "Epoch 1296 - Train Loss: 0.248968, Train Acc: 0.511538 | Val Loss: 0.256224, Val Acc: 0.474227\n",
      "Epoch 1297 - Train Loss: 0.248948, Train Acc: 0.511538 | Val Loss: 0.256204, Val Acc: 0.474227\n",
      "Epoch 1298 - Train Loss: 0.248929, Train Acc: 0.511538 | Val Loss: 0.256185, Val Acc: 0.474227\n",
      "Epoch 1299 - Train Loss: 0.248910, Train Acc: 0.511538 | Val Loss: 0.256166, Val Acc: 0.474227\n",
      "Epoch 1300 - Train Loss: 0.248890, Train Acc: 0.511538 | Val Loss: 0.256146, Val Acc: 0.474227\n",
      "Epoch 1301 - Train Loss: 0.248871, Train Acc: 0.511538 | Val Loss: 0.256127, Val Acc: 0.474227\n",
      "Epoch 1302 - Train Loss: 0.248852, Train Acc: 0.511538 | Val Loss: 0.256107, Val Acc: 0.474227\n",
      "Epoch 1303 - Train Loss: 0.248833, Train Acc: 0.511538 | Val Loss: 0.256088, Val Acc: 0.474227\n",
      "Epoch 1304 - Train Loss: 0.248813, Train Acc: 0.511538 | Val Loss: 0.256069, Val Acc: 0.474227\n",
      "Epoch 1305 - Train Loss: 0.248794, Train Acc: 0.511538 | Val Loss: 0.256049, Val Acc: 0.474227\n",
      "Epoch 1306 - Train Loss: 0.248775, Train Acc: 0.511538 | Val Loss: 0.256030, Val Acc: 0.474227\n",
      "Epoch 1307 - Train Loss: 0.248755, Train Acc: 0.511538 | Val Loss: 0.256011, Val Acc: 0.474227\n",
      "Epoch 1308 - Train Loss: 0.248736, Train Acc: 0.511538 | Val Loss: 0.255991, Val Acc: 0.474227\n",
      "Epoch 1309 - Train Loss: 0.248717, Train Acc: 0.511538 | Val Loss: 0.255972, Val Acc: 0.474227\n",
      "Epoch 1310 - Train Loss: 0.248698, Train Acc: 0.511538 | Val Loss: 0.255952, Val Acc: 0.474227\n",
      "Epoch 1311 - Train Loss: 0.248678, Train Acc: 0.511538 | Val Loss: 0.255933, Val Acc: 0.474227\n",
      "Epoch 1312 - Train Loss: 0.248659, Train Acc: 0.511538 | Val Loss: 0.255914, Val Acc: 0.474227\n",
      "Epoch 1313 - Train Loss: 0.248640, Train Acc: 0.512821 | Val Loss: 0.255894, Val Acc: 0.474227\n",
      "Epoch 1314 - Train Loss: 0.248620, Train Acc: 0.512821 | Val Loss: 0.255875, Val Acc: 0.474227\n",
      "Epoch 1315 - Train Loss: 0.248601, Train Acc: 0.512821 | Val Loss: 0.255855, Val Acc: 0.474227\n",
      "Epoch 1316 - Train Loss: 0.248582, Train Acc: 0.512821 | Val Loss: 0.255836, Val Acc: 0.474227\n",
      "Epoch 1317 - Train Loss: 0.248562, Train Acc: 0.512821 | Val Loss: 0.255817, Val Acc: 0.474227\n",
      "Epoch 1318 - Train Loss: 0.248543, Train Acc: 0.512821 | Val Loss: 0.255797, Val Acc: 0.474227\n",
      "Epoch 1319 - Train Loss: 0.248524, Train Acc: 0.512821 | Val Loss: 0.255778, Val Acc: 0.474227\n",
      "Epoch 1320 - Train Loss: 0.248505, Train Acc: 0.512821 | Val Loss: 0.255758, Val Acc: 0.474227\n",
      "Epoch 1321 - Train Loss: 0.248485, Train Acc: 0.512821 | Val Loss: 0.255739, Val Acc: 0.474227\n",
      "Epoch 1322 - Train Loss: 0.248466, Train Acc: 0.512821 | Val Loss: 0.255720, Val Acc: 0.474227\n",
      "Epoch 1323 - Train Loss: 0.248446, Train Acc: 0.512821 | Val Loss: 0.255700, Val Acc: 0.474227\n",
      "Epoch 1324 - Train Loss: 0.248427, Train Acc: 0.512821 | Val Loss: 0.255681, Val Acc: 0.474227\n",
      "Epoch 1325 - Train Loss: 0.248408, Train Acc: 0.512821 | Val Loss: 0.255661, Val Acc: 0.474227\n",
      "Epoch 1326 - Train Loss: 0.248388, Train Acc: 0.512821 | Val Loss: 0.255642, Val Acc: 0.474227\n",
      "Epoch 1327 - Train Loss: 0.248369, Train Acc: 0.512821 | Val Loss: 0.255622, Val Acc: 0.474227\n",
      "Epoch 1328 - Train Loss: 0.248349, Train Acc: 0.512821 | Val Loss: 0.255603, Val Acc: 0.474227\n",
      "Epoch 1329 - Train Loss: 0.248330, Train Acc: 0.512821 | Val Loss: 0.255584, Val Acc: 0.474227\n",
      "Epoch 1330 - Train Loss: 0.248311, Train Acc: 0.512821 | Val Loss: 0.255564, Val Acc: 0.474227\n",
      "Epoch 1331 - Train Loss: 0.248291, Train Acc: 0.512821 | Val Loss: 0.255545, Val Acc: 0.474227\n",
      "Epoch 1332 - Train Loss: 0.248272, Train Acc: 0.512821 | Val Loss: 0.255525, Val Acc: 0.474227\n",
      "Epoch 1333 - Train Loss: 0.248252, Train Acc: 0.512821 | Val Loss: 0.255506, Val Acc: 0.474227\n",
      "Epoch 1334 - Train Loss: 0.248233, Train Acc: 0.512821 | Val Loss: 0.255486, Val Acc: 0.474227\n",
      "Epoch 1335 - Train Loss: 0.248213, Train Acc: 0.512821 | Val Loss: 0.255467, Val Acc: 0.474227\n",
      "Epoch 1336 - Train Loss: 0.248194, Train Acc: 0.514103 | Val Loss: 0.255447, Val Acc: 0.474227\n",
      "Epoch 1337 - Train Loss: 0.248174, Train Acc: 0.514103 | Val Loss: 0.255428, Val Acc: 0.474227\n",
      "Epoch 1338 - Train Loss: 0.248155, Train Acc: 0.514103 | Val Loss: 0.255408, Val Acc: 0.474227\n",
      "Epoch 1339 - Train Loss: 0.248135, Train Acc: 0.515385 | Val Loss: 0.255389, Val Acc: 0.474227\n",
      "Epoch 1340 - Train Loss: 0.248116, Train Acc: 0.515385 | Val Loss: 0.255370, Val Acc: 0.474227\n",
      "Epoch 1341 - Train Loss: 0.248096, Train Acc: 0.515385 | Val Loss: 0.255350, Val Acc: 0.474227\n",
      "Epoch 1342 - Train Loss: 0.248077, Train Acc: 0.515385 | Val Loss: 0.255331, Val Acc: 0.474227\n",
      "Epoch 1343 - Train Loss: 0.248057, Train Acc: 0.515385 | Val Loss: 0.255311, Val Acc: 0.474227\n",
      "Epoch 1344 - Train Loss: 0.248038, Train Acc: 0.515385 | Val Loss: 0.255292, Val Acc: 0.474227\n",
      "Epoch 1345 - Train Loss: 0.248018, Train Acc: 0.515385 | Val Loss: 0.255272, Val Acc: 0.474227\n",
      "Epoch 1346 - Train Loss: 0.247999, Train Acc: 0.515385 | Val Loss: 0.255253, Val Acc: 0.474227\n",
      "Epoch 1347 - Train Loss: 0.247980, Train Acc: 0.515385 | Val Loss: 0.255233, Val Acc: 0.474227\n",
      "Epoch 1348 - Train Loss: 0.247960, Train Acc: 0.515385 | Val Loss: 0.255214, Val Acc: 0.474227\n",
      "Epoch 1349 - Train Loss: 0.247941, Train Acc: 0.515385 | Val Loss: 0.255195, Val Acc: 0.474227\n",
      "Epoch 1350 - Train Loss: 0.247921, Train Acc: 0.515385 | Val Loss: 0.255175, Val Acc: 0.474227\n",
      "Epoch 1351 - Train Loss: 0.247902, Train Acc: 0.515385 | Val Loss: 0.255156, Val Acc: 0.474227\n",
      "Epoch 1352 - Train Loss: 0.247883, Train Acc: 0.515385 | Val Loss: 0.255136, Val Acc: 0.474227\n",
      "Epoch 1353 - Train Loss: 0.247863, Train Acc: 0.515385 | Val Loss: 0.255117, Val Acc: 0.474227\n",
      "Epoch 1354 - Train Loss: 0.247844, Train Acc: 0.515385 | Val Loss: 0.255098, Val Acc: 0.474227\n",
      "Epoch 1355 - Train Loss: 0.247824, Train Acc: 0.515385 | Val Loss: 0.255079, Val Acc: 0.474227\n",
      "Epoch 1356 - Train Loss: 0.247805, Train Acc: 0.515385 | Val Loss: 0.255060, Val Acc: 0.474227\n",
      "Epoch 1357 - Train Loss: 0.247785, Train Acc: 0.515385 | Val Loss: 0.255041, Val Acc: 0.474227\n",
      "Epoch 1358 - Train Loss: 0.247766, Train Acc: 0.515385 | Val Loss: 0.255021, Val Acc: 0.474227\n",
      "Epoch 1359 - Train Loss: 0.247746, Train Acc: 0.515385 | Val Loss: 0.255002, Val Acc: 0.474227\n",
      "Epoch 1360 - Train Loss: 0.247727, Train Acc: 0.515385 | Val Loss: 0.254983, Val Acc: 0.474227\n",
      "Epoch 1361 - Train Loss: 0.247708, Train Acc: 0.515385 | Val Loss: 0.254964, Val Acc: 0.474227\n",
      "Epoch 1362 - Train Loss: 0.247688, Train Acc: 0.515385 | Val Loss: 0.254945, Val Acc: 0.474227\n",
      "Epoch 1363 - Train Loss: 0.247669, Train Acc: 0.515385 | Val Loss: 0.254925, Val Acc: 0.474227\n",
      "Epoch 1364 - Train Loss: 0.247649, Train Acc: 0.515385 | Val Loss: 0.254906, Val Acc: 0.484536\n",
      "Epoch 1365 - Train Loss: 0.247630, Train Acc: 0.515385 | Val Loss: 0.254887, Val Acc: 0.484536\n",
      "Epoch 1366 - Train Loss: 0.247611, Train Acc: 0.515385 | Val Loss: 0.254868, Val Acc: 0.484536\n",
      "Epoch 1367 - Train Loss: 0.247591, Train Acc: 0.515385 | Val Loss: 0.254849, Val Acc: 0.484536\n",
      "Epoch 1368 - Train Loss: 0.247572, Train Acc: 0.515385 | Val Loss: 0.254830, Val Acc: 0.484536\n",
      "Epoch 1369 - Train Loss: 0.247552, Train Acc: 0.515385 | Val Loss: 0.254810, Val Acc: 0.484536\n",
      "Epoch 1370 - Train Loss: 0.247533, Train Acc: 0.515385 | Val Loss: 0.254791, Val Acc: 0.484536\n",
      "Epoch 1371 - Train Loss: 0.247514, Train Acc: 0.515385 | Val Loss: 0.254772, Val Acc: 0.484536\n",
      "Epoch 1372 - Train Loss: 0.247494, Train Acc: 0.515385 | Val Loss: 0.254753, Val Acc: 0.484536\n",
      "Epoch 1373 - Train Loss: 0.247475, Train Acc: 0.515385 | Val Loss: 0.254734, Val Acc: 0.484536\n",
      "Epoch 1374 - Train Loss: 0.247456, Train Acc: 0.515385 | Val Loss: 0.254714, Val Acc: 0.484536\n",
      "Epoch 1375 - Train Loss: 0.247436, Train Acc: 0.515385 | Val Loss: 0.254695, Val Acc: 0.484536\n",
      "Epoch 1376 - Train Loss: 0.247417, Train Acc: 0.515385 | Val Loss: 0.254676, Val Acc: 0.484536\n",
      "Epoch 1377 - Train Loss: 0.247398, Train Acc: 0.515385 | Val Loss: 0.254657, Val Acc: 0.484536\n",
      "Epoch 1378 - Train Loss: 0.247378, Train Acc: 0.515385 | Val Loss: 0.254638, Val Acc: 0.484536\n",
      "Epoch 1379 - Train Loss: 0.247359, Train Acc: 0.515385 | Val Loss: 0.254619, Val Acc: 0.484536\n",
      "Epoch 1380 - Train Loss: 0.247340, Train Acc: 0.515385 | Val Loss: 0.254599, Val Acc: 0.484536\n",
      "Epoch 1381 - Train Loss: 0.247320, Train Acc: 0.515385 | Val Loss: 0.254580, Val Acc: 0.484536\n",
      "Epoch 1382 - Train Loss: 0.247301, Train Acc: 0.515385 | Val Loss: 0.254561, Val Acc: 0.484536\n",
      "Epoch 1383 - Train Loss: 0.247281, Train Acc: 0.515385 | Val Loss: 0.254542, Val Acc: 0.484536\n",
      "Epoch 1384 - Train Loss: 0.247262, Train Acc: 0.515385 | Val Loss: 0.254523, Val Acc: 0.484536\n",
      "Epoch 1385 - Train Loss: 0.247243, Train Acc: 0.515385 | Val Loss: 0.254504, Val Acc: 0.484536\n",
      "Epoch 1386 - Train Loss: 0.247223, Train Acc: 0.515385 | Val Loss: 0.254484, Val Acc: 0.484536\n",
      "Epoch 1387 - Train Loss: 0.247204, Train Acc: 0.515385 | Val Loss: 0.254465, Val Acc: 0.484536\n",
      "Epoch 1388 - Train Loss: 0.247184, Train Acc: 0.515385 | Val Loss: 0.254446, Val Acc: 0.484536\n",
      "Epoch 1389 - Train Loss: 0.247165, Train Acc: 0.516667 | Val Loss: 0.254427, Val Acc: 0.484536\n",
      "Epoch 1390 - Train Loss: 0.247145, Train Acc: 0.516667 | Val Loss: 0.254407, Val Acc: 0.484536\n",
      "Epoch 1391 - Train Loss: 0.247126, Train Acc: 0.516667 | Val Loss: 0.254388, Val Acc: 0.484536\n",
      "Epoch 1392 - Train Loss: 0.247106, Train Acc: 0.516667 | Val Loss: 0.254369, Val Acc: 0.484536\n",
      "Epoch 1393 - Train Loss: 0.247087, Train Acc: 0.516667 | Val Loss: 0.254350, Val Acc: 0.484536\n",
      "Epoch 1394 - Train Loss: 0.247067, Train Acc: 0.516667 | Val Loss: 0.254330, Val Acc: 0.484536\n",
      "Epoch 1395 - Train Loss: 0.247048, Train Acc: 0.516667 | Val Loss: 0.254311, Val Acc: 0.484536\n",
      "Epoch 1396 - Train Loss: 0.247029, Train Acc: 0.516667 | Val Loss: 0.254292, Val Acc: 0.484536\n",
      "Epoch 1397 - Train Loss: 0.247009, Train Acc: 0.516667 | Val Loss: 0.254272, Val Acc: 0.484536\n",
      "Epoch 1398 - Train Loss: 0.246990, Train Acc: 0.516667 | Val Loss: 0.254253, Val Acc: 0.484536\n",
      "Epoch 1399 - Train Loss: 0.246970, Train Acc: 0.516667 | Val Loss: 0.254234, Val Acc: 0.484536\n",
      "Epoch 1400 - Train Loss: 0.246951, Train Acc: 0.516667 | Val Loss: 0.254214, Val Acc: 0.484536\n",
      "Epoch 1401 - Train Loss: 0.246931, Train Acc: 0.516667 | Val Loss: 0.254195, Val Acc: 0.484536\n",
      "Epoch 1402 - Train Loss: 0.246911, Train Acc: 0.516667 | Val Loss: 0.254176, Val Acc: 0.484536\n",
      "Epoch 1403 - Train Loss: 0.246892, Train Acc: 0.516667 | Val Loss: 0.254156, Val Acc: 0.484536\n",
      "Epoch 1404 - Train Loss: 0.246872, Train Acc: 0.516667 | Val Loss: 0.254137, Val Acc: 0.484536\n",
      "Epoch 1405 - Train Loss: 0.246853, Train Acc: 0.516667 | Val Loss: 0.254118, Val Acc: 0.484536\n",
      "Epoch 1406 - Train Loss: 0.246833, Train Acc: 0.516667 | Val Loss: 0.254098, Val Acc: 0.484536\n",
      "Epoch 1407 - Train Loss: 0.246814, Train Acc: 0.516667 | Val Loss: 0.254079, Val Acc: 0.484536\n",
      "Epoch 1408 - Train Loss: 0.246794, Train Acc: 0.516667 | Val Loss: 0.254059, Val Acc: 0.484536\n",
      "Epoch 1409 - Train Loss: 0.246774, Train Acc: 0.516667 | Val Loss: 0.254040, Val Acc: 0.484536\n",
      "Epoch 1410 - Train Loss: 0.246755, Train Acc: 0.516667 | Val Loss: 0.254021, Val Acc: 0.484536\n",
      "Epoch 1411 - Train Loss: 0.246735, Train Acc: 0.516667 | Val Loss: 0.254001, Val Acc: 0.484536\n",
      "Epoch 1412 - Train Loss: 0.246715, Train Acc: 0.516667 | Val Loss: 0.253982, Val Acc: 0.484536\n",
      "Epoch 1413 - Train Loss: 0.246696, Train Acc: 0.516667 | Val Loss: 0.253963, Val Acc: 0.484536\n",
      "Epoch 1414 - Train Loss: 0.246676, Train Acc: 0.516667 | Val Loss: 0.253943, Val Acc: 0.484536\n",
      "Epoch 1415 - Train Loss: 0.246657, Train Acc: 0.516667 | Val Loss: 0.253924, Val Acc: 0.484536\n",
      "Epoch 1416 - Train Loss: 0.246637, Train Acc: 0.516667 | Val Loss: 0.253904, Val Acc: 0.484536\n",
      "Epoch 1417 - Train Loss: 0.246617, Train Acc: 0.516667 | Val Loss: 0.253885, Val Acc: 0.484536\n",
      "Epoch 1418 - Train Loss: 0.246598, Train Acc: 0.516667 | Val Loss: 0.253866, Val Acc: 0.484536\n",
      "Epoch 1419 - Train Loss: 0.246578, Train Acc: 0.516667 | Val Loss: 0.253847, Val Acc: 0.484536\n",
      "Epoch 1420 - Train Loss: 0.246558, Train Acc: 0.516667 | Val Loss: 0.253828, Val Acc: 0.484536\n",
      "Epoch 1421 - Train Loss: 0.246539, Train Acc: 0.516667 | Val Loss: 0.253809, Val Acc: 0.484536\n",
      "Epoch 1422 - Train Loss: 0.246519, Train Acc: 0.516667 | Val Loss: 0.253789, Val Acc: 0.484536\n",
      "Epoch 1423 - Train Loss: 0.246499, Train Acc: 0.516667 | Val Loss: 0.253770, Val Acc: 0.484536\n",
      "Epoch 1424 - Train Loss: 0.246480, Train Acc: 0.516667 | Val Loss: 0.253751, Val Acc: 0.484536\n",
      "Epoch 1425 - Train Loss: 0.246460, Train Acc: 0.516667 | Val Loss: 0.253732, Val Acc: 0.484536\n",
      "Epoch 1426 - Train Loss: 0.246441, Train Acc: 0.516667 | Val Loss: 0.253713, Val Acc: 0.484536\n",
      "Epoch 1427 - Train Loss: 0.246421, Train Acc: 0.516667 | Val Loss: 0.253694, Val Acc: 0.484536\n",
      "Epoch 1428 - Train Loss: 0.246401, Train Acc: 0.516667 | Val Loss: 0.253675, Val Acc: 0.484536\n",
      "Epoch 1429 - Train Loss: 0.246381, Train Acc: 0.516667 | Val Loss: 0.253656, Val Acc: 0.484536\n",
      "Epoch 1430 - Train Loss: 0.246362, Train Acc: 0.516667 | Val Loss: 0.253636, Val Acc: 0.484536\n",
      "Epoch 1431 - Train Loss: 0.246342, Train Acc: 0.516667 | Val Loss: 0.253617, Val Acc: 0.484536\n",
      "Epoch 1432 - Train Loss: 0.246322, Train Acc: 0.516667 | Val Loss: 0.253598, Val Acc: 0.484536\n",
      "Epoch 1433 - Train Loss: 0.246303, Train Acc: 0.516667 | Val Loss: 0.253579, Val Acc: 0.484536\n",
      "Epoch 1434 - Train Loss: 0.246283, Train Acc: 0.516667 | Val Loss: 0.253560, Val Acc: 0.484536\n",
      "Epoch 1435 - Train Loss: 0.246263, Train Acc: 0.516667 | Val Loss: 0.253541, Val Acc: 0.484536\n",
      "Epoch 1436 - Train Loss: 0.246243, Train Acc: 0.516667 | Val Loss: 0.253521, Val Acc: 0.484536\n",
      "Epoch 1437 - Train Loss: 0.246224, Train Acc: 0.516667 | Val Loss: 0.253502, Val Acc: 0.484536\n",
      "Epoch 1438 - Train Loss: 0.246204, Train Acc: 0.516667 | Val Loss: 0.253483, Val Acc: 0.484536\n",
      "Epoch 1439 - Train Loss: 0.246184, Train Acc: 0.516667 | Val Loss: 0.253464, Val Acc: 0.484536\n",
      "Epoch 1440 - Train Loss: 0.246164, Train Acc: 0.516667 | Val Loss: 0.253445, Val Acc: 0.484536\n",
      "Epoch 1441 - Train Loss: 0.246144, Train Acc: 0.516667 | Val Loss: 0.253425, Val Acc: 0.484536\n",
      "Epoch 1442 - Train Loss: 0.246125, Train Acc: 0.517949 | Val Loss: 0.253406, Val Acc: 0.484536\n",
      "Epoch 1443 - Train Loss: 0.246105, Train Acc: 0.517949 | Val Loss: 0.253387, Val Acc: 0.484536\n",
      "Epoch 1444 - Train Loss: 0.246085, Train Acc: 0.517949 | Val Loss: 0.253368, Val Acc: 0.484536\n",
      "Epoch 1445 - Train Loss: 0.246065, Train Acc: 0.517949 | Val Loss: 0.253349, Val Acc: 0.484536\n",
      "Epoch 1446 - Train Loss: 0.246046, Train Acc: 0.517949 | Val Loss: 0.253329, Val Acc: 0.484536\n",
      "Epoch 1447 - Train Loss: 0.246026, Train Acc: 0.517949 | Val Loss: 0.253310, Val Acc: 0.484536\n",
      "Epoch 1448 - Train Loss: 0.246007, Train Acc: 0.517949 | Val Loss: 0.253291, Val Acc: 0.484536\n",
      "Epoch 1449 - Train Loss: 0.245987, Train Acc: 0.517949 | Val Loss: 0.253271, Val Acc: 0.484536\n",
      "Epoch 1450 - Train Loss: 0.245967, Train Acc: 0.517949 | Val Loss: 0.253252, Val Acc: 0.484536\n",
      "Epoch 1451 - Train Loss: 0.245948, Train Acc: 0.517949 | Val Loss: 0.253233, Val Acc: 0.484536\n",
      "Epoch 1452 - Train Loss: 0.245928, Train Acc: 0.517949 | Val Loss: 0.253214, Val Acc: 0.484536\n",
      "Epoch 1453 - Train Loss: 0.245909, Train Acc: 0.517949 | Val Loss: 0.253194, Val Acc: 0.484536\n",
      "Epoch 1454 - Train Loss: 0.245889, Train Acc: 0.517949 | Val Loss: 0.253175, Val Acc: 0.484536\n",
      "Epoch 1455 - Train Loss: 0.245869, Train Acc: 0.517949 | Val Loss: 0.253156, Val Acc: 0.484536\n",
      "Epoch 1456 - Train Loss: 0.245850, Train Acc: 0.517949 | Val Loss: 0.253137, Val Acc: 0.484536\n",
      "Epoch 1457 - Train Loss: 0.245830, Train Acc: 0.517949 | Val Loss: 0.253117, Val Acc: 0.484536\n",
      "Epoch 1458 - Train Loss: 0.245810, Train Acc: 0.517949 | Val Loss: 0.253098, Val Acc: 0.484536\n",
      "Epoch 1459 - Train Loss: 0.245791, Train Acc: 0.517949 | Val Loss: 0.253079, Val Acc: 0.484536\n",
      "Epoch 1460 - Train Loss: 0.245771, Train Acc: 0.517949 | Val Loss: 0.253059, Val Acc: 0.484536\n",
      "Epoch 1461 - Train Loss: 0.245752, Train Acc: 0.519231 | Val Loss: 0.253040, Val Acc: 0.484536\n",
      "Epoch 1462 - Train Loss: 0.245732, Train Acc: 0.519231 | Val Loss: 0.253021, Val Acc: 0.484536\n",
      "Epoch 1463 - Train Loss: 0.245712, Train Acc: 0.519231 | Val Loss: 0.253001, Val Acc: 0.484536\n",
      "Epoch 1464 - Train Loss: 0.245693, Train Acc: 0.519231 | Val Loss: 0.252982, Val Acc: 0.484536\n",
      "Epoch 1465 - Train Loss: 0.245673, Train Acc: 0.519231 | Val Loss: 0.252963, Val Acc: 0.484536\n",
      "Epoch 1466 - Train Loss: 0.245654, Train Acc: 0.519231 | Val Loss: 0.252943, Val Acc: 0.484536\n",
      "Epoch 1467 - Train Loss: 0.245634, Train Acc: 0.519231 | Val Loss: 0.252924, Val Acc: 0.484536\n",
      "Epoch 1468 - Train Loss: 0.245614, Train Acc: 0.519231 | Val Loss: 0.252905, Val Acc: 0.484536\n",
      "Epoch 1469 - Train Loss: 0.245595, Train Acc: 0.519231 | Val Loss: 0.252885, Val Acc: 0.484536\n",
      "Epoch 1470 - Train Loss: 0.245575, Train Acc: 0.519231 | Val Loss: 0.252866, Val Acc: 0.484536\n",
      "Epoch 1471 - Train Loss: 0.245556, Train Acc: 0.519231 | Val Loss: 0.252847, Val Acc: 0.484536\n",
      "Epoch 1472 - Train Loss: 0.245536, Train Acc: 0.519231 | Val Loss: 0.252828, Val Acc: 0.484536\n",
      "Epoch 1473 - Train Loss: 0.245517, Train Acc: 0.519231 | Val Loss: 0.252808, Val Acc: 0.484536\n",
      "Epoch 1474 - Train Loss: 0.245497, Train Acc: 0.519231 | Val Loss: 0.252789, Val Acc: 0.484536\n",
      "Epoch 1475 - Train Loss: 0.245477, Train Acc: 0.519231 | Val Loss: 0.252770, Val Acc: 0.484536\n",
      "Epoch 1476 - Train Loss: 0.245458, Train Acc: 0.519231 | Val Loss: 0.252750, Val Acc: 0.484536\n",
      "Epoch 1477 - Train Loss: 0.245438, Train Acc: 0.520513 | Val Loss: 0.252731, Val Acc: 0.484536\n",
      "Epoch 1478 - Train Loss: 0.245419, Train Acc: 0.520513 | Val Loss: 0.252712, Val Acc: 0.484536\n",
      "Epoch 1479 - Train Loss: 0.245399, Train Acc: 0.520513 | Val Loss: 0.252692, Val Acc: 0.484536\n",
      "Epoch 1480 - Train Loss: 0.245380, Train Acc: 0.520513 | Val Loss: 0.252673, Val Acc: 0.484536\n",
      "Epoch 1481 - Train Loss: 0.245360, Train Acc: 0.520513 | Val Loss: 0.252654, Val Acc: 0.484536\n",
      "Epoch 1482 - Train Loss: 0.245340, Train Acc: 0.520513 | Val Loss: 0.252634, Val Acc: 0.484536\n",
      "Epoch 1483 - Train Loss: 0.245321, Train Acc: 0.520513 | Val Loss: 0.252615, Val Acc: 0.484536\n",
      "Epoch 1484 - Train Loss: 0.245301, Train Acc: 0.520513 | Val Loss: 0.252596, Val Acc: 0.484536\n",
      "Epoch 1485 - Train Loss: 0.245282, Train Acc: 0.520513 | Val Loss: 0.252577, Val Acc: 0.484536\n",
      "Epoch 1486 - Train Loss: 0.245262, Train Acc: 0.520513 | Val Loss: 0.252557, Val Acc: 0.484536\n",
      "Epoch 1487 - Train Loss: 0.245242, Train Acc: 0.520513 | Val Loss: 0.252538, Val Acc: 0.484536\n",
      "Epoch 1488 - Train Loss: 0.245223, Train Acc: 0.520513 | Val Loss: 0.252519, Val Acc: 0.484536\n",
      "Epoch 1489 - Train Loss: 0.245203, Train Acc: 0.520513 | Val Loss: 0.252499, Val Acc: 0.484536\n",
      "Epoch 1490 - Train Loss: 0.245184, Train Acc: 0.520513 | Val Loss: 0.252480, Val Acc: 0.484536\n",
      "Epoch 1491 - Train Loss: 0.245164, Train Acc: 0.520513 | Val Loss: 0.252461, Val Acc: 0.484536\n",
      "Epoch 1492 - Train Loss: 0.245145, Train Acc: 0.520513 | Val Loss: 0.252441, Val Acc: 0.484536\n",
      "Epoch 1493 - Train Loss: 0.245125, Train Acc: 0.520513 | Val Loss: 0.252422, Val Acc: 0.484536\n",
      "Epoch 1494 - Train Loss: 0.245105, Train Acc: 0.520513 | Val Loss: 0.252403, Val Acc: 0.484536\n",
      "Epoch 1495 - Train Loss: 0.245086, Train Acc: 0.520513 | Val Loss: 0.252383, Val Acc: 0.484536\n",
      "Epoch 1496 - Train Loss: 0.245066, Train Acc: 0.520513 | Val Loss: 0.252364, Val Acc: 0.484536\n",
      "Epoch 1497 - Train Loss: 0.245047, Train Acc: 0.520513 | Val Loss: 0.252345, Val Acc: 0.484536\n",
      "Epoch 1498 - Train Loss: 0.245027, Train Acc: 0.520513 | Val Loss: 0.252326, Val Acc: 0.484536\n",
      "Epoch 1499 - Train Loss: 0.245007, Train Acc: 0.520513 | Val Loss: 0.252306, Val Acc: 0.484536\n",
      "Epoch 1500 - Train Loss: 0.244988, Train Acc: 0.520513 | Val Loss: 0.252287, Val Acc: 0.484536\n",
      "Epoch 1501 - Train Loss: 0.244968, Train Acc: 0.520513 | Val Loss: 0.252268, Val Acc: 0.484536\n",
      "Epoch 1502 - Train Loss: 0.244949, Train Acc: 0.520513 | Val Loss: 0.252248, Val Acc: 0.484536\n",
      "Epoch 1503 - Train Loss: 0.244929, Train Acc: 0.521795 | Val Loss: 0.252229, Val Acc: 0.484536\n",
      "Epoch 1504 - Train Loss: 0.244909, Train Acc: 0.521795 | Val Loss: 0.252210, Val Acc: 0.484536\n",
      "Epoch 1505 - Train Loss: 0.244890, Train Acc: 0.523077 | Val Loss: 0.252190, Val Acc: 0.484536\n",
      "Epoch 1506 - Train Loss: 0.244870, Train Acc: 0.523077 | Val Loss: 0.252171, Val Acc: 0.484536\n",
      "Epoch 1507 - Train Loss: 0.244851, Train Acc: 0.523077 | Val Loss: 0.252152, Val Acc: 0.484536\n",
      "Epoch 1508 - Train Loss: 0.244831, Train Acc: 0.523077 | Val Loss: 0.252132, Val Acc: 0.484536\n",
      "Epoch 1509 - Train Loss: 0.244811, Train Acc: 0.523077 | Val Loss: 0.252113, Val Acc: 0.484536\n",
      "Epoch 1510 - Train Loss: 0.244792, Train Acc: 0.523077 | Val Loss: 0.252094, Val Acc: 0.484536\n",
      "Epoch 1511 - Train Loss: 0.244772, Train Acc: 0.523077 | Val Loss: 0.252074, Val Acc: 0.484536\n",
      "Epoch 1512 - Train Loss: 0.244753, Train Acc: 0.523077 | Val Loss: 0.252055, Val Acc: 0.484536\n",
      "Epoch 1513 - Train Loss: 0.244733, Train Acc: 0.523077 | Val Loss: 0.252035, Val Acc: 0.484536\n",
      "Epoch 1514 - Train Loss: 0.244713, Train Acc: 0.523077 | Val Loss: 0.252016, Val Acc: 0.484536\n",
      "Epoch 1515 - Train Loss: 0.244694, Train Acc: 0.523077 | Val Loss: 0.251997, Val Acc: 0.484536\n",
      "Epoch 1516 - Train Loss: 0.244674, Train Acc: 0.523077 | Val Loss: 0.251977, Val Acc: 0.484536\n",
      "Epoch 1517 - Train Loss: 0.244654, Train Acc: 0.523077 | Val Loss: 0.251958, Val Acc: 0.484536\n",
      "Epoch 1518 - Train Loss: 0.244635, Train Acc: 0.523077 | Val Loss: 0.251938, Val Acc: 0.484536\n",
      "Epoch 1519 - Train Loss: 0.244615, Train Acc: 0.523077 | Val Loss: 0.251919, Val Acc: 0.484536\n",
      "Epoch 1520 - Train Loss: 0.244596, Train Acc: 0.523077 | Val Loss: 0.251900, Val Acc: 0.484536\n",
      "Epoch 1521 - Train Loss: 0.244576, Train Acc: 0.523077 | Val Loss: 0.251880, Val Acc: 0.484536\n",
      "Epoch 1522 - Train Loss: 0.244556, Train Acc: 0.523077 | Val Loss: 0.251861, Val Acc: 0.484536\n",
      "Epoch 1523 - Train Loss: 0.244537, Train Acc: 0.523077 | Val Loss: 0.251841, Val Acc: 0.484536\n",
      "Epoch 1524 - Train Loss: 0.244517, Train Acc: 0.523077 | Val Loss: 0.251822, Val Acc: 0.484536\n",
      "Epoch 1525 - Train Loss: 0.244497, Train Acc: 0.523077 | Val Loss: 0.251802, Val Acc: 0.484536\n",
      "Epoch 1526 - Train Loss: 0.244478, Train Acc: 0.523077 | Val Loss: 0.251783, Val Acc: 0.484536\n",
      "Epoch 1527 - Train Loss: 0.244458, Train Acc: 0.523077 | Val Loss: 0.251764, Val Acc: 0.484536\n",
      "Epoch 1528 - Train Loss: 0.244439, Train Acc: 0.523077 | Val Loss: 0.251744, Val Acc: 0.484536\n",
      "Epoch 1529 - Train Loss: 0.244419, Train Acc: 0.523077 | Val Loss: 0.251725, Val Acc: 0.484536\n",
      "Epoch 1530 - Train Loss: 0.244399, Train Acc: 0.523077 | Val Loss: 0.251705, Val Acc: 0.484536\n",
      "Epoch 1531 - Train Loss: 0.244380, Train Acc: 0.523077 | Val Loss: 0.251686, Val Acc: 0.484536\n",
      "Epoch 1532 - Train Loss: 0.244360, Train Acc: 0.523077 | Val Loss: 0.251666, Val Acc: 0.484536\n",
      "Epoch 1533 - Train Loss: 0.244340, Train Acc: 0.523077 | Val Loss: 0.251647, Val Acc: 0.484536\n",
      "Epoch 1534 - Train Loss: 0.244321, Train Acc: 0.523077 | Val Loss: 0.251627, Val Acc: 0.484536\n",
      "Epoch 1535 - Train Loss: 0.244301, Train Acc: 0.523077 | Val Loss: 0.251608, Val Acc: 0.484536\n",
      "Epoch 1536 - Train Loss: 0.244281, Train Acc: 0.523077 | Val Loss: 0.251588, Val Acc: 0.484536\n",
      "Epoch 1537 - Train Loss: 0.244262, Train Acc: 0.523077 | Val Loss: 0.251569, Val Acc: 0.484536\n",
      "Epoch 1538 - Train Loss: 0.244242, Train Acc: 0.523077 | Val Loss: 0.251549, Val Acc: 0.484536\n",
      "Epoch 1539 - Train Loss: 0.244222, Train Acc: 0.523077 | Val Loss: 0.251530, Val Acc: 0.484536\n",
      "Epoch 1540 - Train Loss: 0.244202, Train Acc: 0.523077 | Val Loss: 0.251510, Val Acc: 0.484536\n",
      "Epoch 1541 - Train Loss: 0.244183, Train Acc: 0.523077 | Val Loss: 0.251491, Val Acc: 0.484536\n",
      "Epoch 1542 - Train Loss: 0.244163, Train Acc: 0.523077 | Val Loss: 0.251471, Val Acc: 0.484536\n",
      "Epoch 1543 - Train Loss: 0.244143, Train Acc: 0.523077 | Val Loss: 0.251452, Val Acc: 0.484536\n",
      "Epoch 1544 - Train Loss: 0.244124, Train Acc: 0.523077 | Val Loss: 0.251432, Val Acc: 0.484536\n",
      "Epoch 1545 - Train Loss: 0.244104, Train Acc: 0.523077 | Val Loss: 0.251413, Val Acc: 0.484536\n",
      "Epoch 1546 - Train Loss: 0.244084, Train Acc: 0.523077 | Val Loss: 0.251393, Val Acc: 0.484536\n",
      "Epoch 1547 - Train Loss: 0.244065, Train Acc: 0.523077 | Val Loss: 0.251373, Val Acc: 0.484536\n",
      "Epoch 1548 - Train Loss: 0.244045, Train Acc: 0.523077 | Val Loss: 0.251354, Val Acc: 0.484536\n",
      "Epoch 1549 - Train Loss: 0.244025, Train Acc: 0.523077 | Val Loss: 0.251334, Val Acc: 0.484536\n",
      "Epoch 1550 - Train Loss: 0.244006, Train Acc: 0.524359 | Val Loss: 0.251315, Val Acc: 0.484536\n",
      "Epoch 1551 - Train Loss: 0.243986, Train Acc: 0.524359 | Val Loss: 0.251295, Val Acc: 0.484536\n",
      "Epoch 1552 - Train Loss: 0.243967, Train Acc: 0.524359 | Val Loss: 0.251275, Val Acc: 0.484536\n",
      "Epoch 1553 - Train Loss: 0.243947, Train Acc: 0.524359 | Val Loss: 0.251256, Val Acc: 0.484536\n",
      "Epoch 1554 - Train Loss: 0.243927, Train Acc: 0.524359 | Val Loss: 0.251236, Val Acc: 0.484536\n",
      "Epoch 1555 - Train Loss: 0.243908, Train Acc: 0.524359 | Val Loss: 0.251217, Val Acc: 0.484536\n",
      "Epoch 1556 - Train Loss: 0.243888, Train Acc: 0.524359 | Val Loss: 0.251197, Val Acc: 0.484536\n",
      "Epoch 1557 - Train Loss: 0.243868, Train Acc: 0.524359 | Val Loss: 0.251178, Val Acc: 0.484536\n",
      "Epoch 1558 - Train Loss: 0.243849, Train Acc: 0.524359 | Val Loss: 0.251158, Val Acc: 0.484536\n",
      "Epoch 1559 - Train Loss: 0.243829, Train Acc: 0.525641 | Val Loss: 0.251138, Val Acc: 0.484536\n",
      "Epoch 1560 - Train Loss: 0.243809, Train Acc: 0.525641 | Val Loss: 0.251119, Val Acc: 0.484536\n",
      "Epoch 1561 - Train Loss: 0.243790, Train Acc: 0.525641 | Val Loss: 0.251099, Val Acc: 0.484536\n",
      "Epoch 1562 - Train Loss: 0.243770, Train Acc: 0.525641 | Val Loss: 0.251080, Val Acc: 0.484536\n",
      "Epoch 1563 - Train Loss: 0.243750, Train Acc: 0.526923 | Val Loss: 0.251060, Val Acc: 0.484536\n",
      "Epoch 1564 - Train Loss: 0.243731, Train Acc: 0.526923 | Val Loss: 0.251040, Val Acc: 0.484536\n",
      "Epoch 1565 - Train Loss: 0.243711, Train Acc: 0.526923 | Val Loss: 0.251021, Val Acc: 0.484536\n",
      "Epoch 1566 - Train Loss: 0.243691, Train Acc: 0.526923 | Val Loss: 0.251001, Val Acc: 0.484536\n",
      "Epoch 1567 - Train Loss: 0.243671, Train Acc: 0.528205 | Val Loss: 0.250982, Val Acc: 0.484536\n",
      "Epoch 1568 - Train Loss: 0.243652, Train Acc: 0.528205 | Val Loss: 0.250962, Val Acc: 0.484536\n",
      "Epoch 1569 - Train Loss: 0.243632, Train Acc: 0.528205 | Val Loss: 0.250942, Val Acc: 0.484536\n",
      "Epoch 1570 - Train Loss: 0.243612, Train Acc: 0.528205 | Val Loss: 0.250923, Val Acc: 0.484536\n",
      "Epoch 1571 - Train Loss: 0.243593, Train Acc: 0.528205 | Val Loss: 0.250903, Val Acc: 0.484536\n",
      "Epoch 1572 - Train Loss: 0.243573, Train Acc: 0.528205 | Val Loss: 0.250884, Val Acc: 0.484536\n",
      "Epoch 1573 - Train Loss: 0.243553, Train Acc: 0.528205 | Val Loss: 0.250864, Val Acc: 0.484536\n",
      "Epoch 1574 - Train Loss: 0.243534, Train Acc: 0.528205 | Val Loss: 0.250844, Val Acc: 0.484536\n",
      "Epoch 1575 - Train Loss: 0.243514, Train Acc: 0.528205 | Val Loss: 0.250825, Val Acc: 0.484536\n",
      "Epoch 1576 - Train Loss: 0.243494, Train Acc: 0.528205 | Val Loss: 0.250805, Val Acc: 0.484536\n",
      "Epoch 1577 - Train Loss: 0.243474, Train Acc: 0.528205 | Val Loss: 0.250785, Val Acc: 0.484536\n",
      "Epoch 1578 - Train Loss: 0.243455, Train Acc: 0.528205 | Val Loss: 0.250766, Val Acc: 0.484536\n",
      "Epoch 1579 - Train Loss: 0.243435, Train Acc: 0.528205 | Val Loss: 0.250746, Val Acc: 0.484536\n",
      "Epoch 1580 - Train Loss: 0.243415, Train Acc: 0.528205 | Val Loss: 0.250726, Val Acc: 0.484536\n",
      "Epoch 1581 - Train Loss: 0.243395, Train Acc: 0.528205 | Val Loss: 0.250707, Val Acc: 0.484536\n",
      "Epoch 1582 - Train Loss: 0.243376, Train Acc: 0.528205 | Val Loss: 0.250687, Val Acc: 0.484536\n",
      "Epoch 1583 - Train Loss: 0.243356, Train Acc: 0.528205 | Val Loss: 0.250667, Val Acc: 0.484536\n",
      "Epoch 1584 - Train Loss: 0.243336, Train Acc: 0.528205 | Val Loss: 0.250648, Val Acc: 0.484536\n",
      "Epoch 1585 - Train Loss: 0.243316, Train Acc: 0.528205 | Val Loss: 0.250628, Val Acc: 0.484536\n",
      "Epoch 1586 - Train Loss: 0.243297, Train Acc: 0.528205 | Val Loss: 0.250608, Val Acc: 0.494845\n",
      "Epoch 1587 - Train Loss: 0.243277, Train Acc: 0.528205 | Val Loss: 0.250589, Val Acc: 0.494845\n",
      "Epoch 1588 - Train Loss: 0.243257, Train Acc: 0.528205 | Val Loss: 0.250569, Val Acc: 0.494845\n",
      "Epoch 1589 - Train Loss: 0.243237, Train Acc: 0.528205 | Val Loss: 0.250549, Val Acc: 0.494845\n",
      "Epoch 1590 - Train Loss: 0.243218, Train Acc: 0.528205 | Val Loss: 0.250529, Val Acc: 0.494845\n",
      "Epoch 1591 - Train Loss: 0.243198, Train Acc: 0.528205 | Val Loss: 0.250510, Val Acc: 0.494845\n",
      "Epoch 1592 - Train Loss: 0.243178, Train Acc: 0.528205 | Val Loss: 0.250490, Val Acc: 0.494845\n",
      "Epoch 1593 - Train Loss: 0.243158, Train Acc: 0.528205 | Val Loss: 0.250470, Val Acc: 0.494845\n",
      "Epoch 1594 - Train Loss: 0.243139, Train Acc: 0.528205 | Val Loss: 0.250450, Val Acc: 0.494845\n",
      "Epoch 1595 - Train Loss: 0.243119, Train Acc: 0.528205 | Val Loss: 0.250431, Val Acc: 0.494845\n",
      "Epoch 1596 - Train Loss: 0.243099, Train Acc: 0.528205 | Val Loss: 0.250411, Val Acc: 0.494845\n",
      "Epoch 1597 - Train Loss: 0.243079, Train Acc: 0.528205 | Val Loss: 0.250391, Val Acc: 0.494845\n",
      "Epoch 1598 - Train Loss: 0.243059, Train Acc: 0.528205 | Val Loss: 0.250371, Val Acc: 0.494845\n",
      "Epoch 1599 - Train Loss: 0.243040, Train Acc: 0.528205 | Val Loss: 0.250351, Val Acc: 0.494845\n",
      "Epoch 1600 - Train Loss: 0.243020, Train Acc: 0.528205 | Val Loss: 0.250332, Val Acc: 0.494845\n",
      "Epoch 1601 - Train Loss: 0.243000, Train Acc: 0.528205 | Val Loss: 0.250312, Val Acc: 0.494845\n",
      "Epoch 1602 - Train Loss: 0.242980, Train Acc: 0.528205 | Val Loss: 0.250292, Val Acc: 0.494845\n",
      "Epoch 1603 - Train Loss: 0.242961, Train Acc: 0.528205 | Val Loss: 0.250272, Val Acc: 0.494845\n",
      "Epoch 1604 - Train Loss: 0.242941, Train Acc: 0.528205 | Val Loss: 0.250252, Val Acc: 0.494845\n",
      "Epoch 1605 - Train Loss: 0.242921, Train Acc: 0.528205 | Val Loss: 0.250232, Val Acc: 0.494845\n",
      "Epoch 1606 - Train Loss: 0.242901, Train Acc: 0.528205 | Val Loss: 0.250213, Val Acc: 0.494845\n",
      "Epoch 1607 - Train Loss: 0.242881, Train Acc: 0.528205 | Val Loss: 0.250193, Val Acc: 0.494845\n",
      "Epoch 1608 - Train Loss: 0.242861, Train Acc: 0.528205 | Val Loss: 0.250173, Val Acc: 0.494845\n",
      "Epoch 1609 - Train Loss: 0.242842, Train Acc: 0.528205 | Val Loss: 0.250153, Val Acc: 0.494845\n",
      "Epoch 1610 - Train Loss: 0.242822, Train Acc: 0.528205 | Val Loss: 0.250133, Val Acc: 0.494845\n",
      "Epoch 1611 - Train Loss: 0.242802, Train Acc: 0.528205 | Val Loss: 0.250113, Val Acc: 0.494845\n",
      "Epoch 1612 - Train Loss: 0.242782, Train Acc: 0.528205 | Val Loss: 0.250094, Val Acc: 0.494845\n",
      "Epoch 1613 - Train Loss: 0.242762, Train Acc: 0.528205 | Val Loss: 0.250074, Val Acc: 0.494845\n",
      "Epoch 1614 - Train Loss: 0.242743, Train Acc: 0.528205 | Val Loss: 0.250054, Val Acc: 0.494845\n",
      "Epoch 1615 - Train Loss: 0.242723, Train Acc: 0.528205 | Val Loss: 0.250034, Val Acc: 0.494845\n",
      "Epoch 1616 - Train Loss: 0.242703, Train Acc: 0.528205 | Val Loss: 0.250014, Val Acc: 0.494845\n",
      "Epoch 1617 - Train Loss: 0.242683, Train Acc: 0.528205 | Val Loss: 0.249994, Val Acc: 0.494845\n",
      "Epoch 1618 - Train Loss: 0.242663, Train Acc: 0.528205 | Val Loss: 0.249975, Val Acc: 0.494845\n",
      "Epoch 1619 - Train Loss: 0.242643, Train Acc: 0.528205 | Val Loss: 0.249955, Val Acc: 0.494845\n",
      "Epoch 1620 - Train Loss: 0.242624, Train Acc: 0.528205 | Val Loss: 0.249935, Val Acc: 0.494845\n",
      "Epoch 1621 - Train Loss: 0.242604, Train Acc: 0.528205 | Val Loss: 0.249915, Val Acc: 0.494845\n",
      "Epoch 1622 - Train Loss: 0.242584, Train Acc: 0.528205 | Val Loss: 0.249895, Val Acc: 0.494845\n",
      "Epoch 1623 - Train Loss: 0.242564, Train Acc: 0.528205 | Val Loss: 0.249875, Val Acc: 0.494845\n",
      "Epoch 1624 - Train Loss: 0.242544, Train Acc: 0.528205 | Val Loss: 0.249856, Val Acc: 0.494845\n",
      "Epoch 1625 - Train Loss: 0.242524, Train Acc: 0.528205 | Val Loss: 0.249836, Val Acc: 0.494845\n",
      "Epoch 1626 - Train Loss: 0.242505, Train Acc: 0.528205 | Val Loss: 0.249816, Val Acc: 0.494845\n",
      "Epoch 1627 - Train Loss: 0.242485, Train Acc: 0.528205 | Val Loss: 0.249796, Val Acc: 0.494845\n",
      "Epoch 1628 - Train Loss: 0.242465, Train Acc: 0.529487 | Val Loss: 0.249776, Val Acc: 0.494845\n",
      "Epoch 1629 - Train Loss: 0.242445, Train Acc: 0.529487 | Val Loss: 0.249756, Val Acc: 0.494845\n",
      "Epoch 1630 - Train Loss: 0.242425, Train Acc: 0.529487 | Val Loss: 0.249737, Val Acc: 0.494845\n",
      "Epoch 1631 - Train Loss: 0.242405, Train Acc: 0.529487 | Val Loss: 0.249717, Val Acc: 0.494845\n",
      "Epoch 1632 - Train Loss: 0.242385, Train Acc: 0.529487 | Val Loss: 0.249697, Val Acc: 0.494845\n",
      "Epoch 1633 - Train Loss: 0.242366, Train Acc: 0.529487 | Val Loss: 0.249677, Val Acc: 0.494845\n",
      "Epoch 1634 - Train Loss: 0.242346, Train Acc: 0.529487 | Val Loss: 0.249657, Val Acc: 0.494845\n",
      "Epoch 1635 - Train Loss: 0.242326, Train Acc: 0.529487 | Val Loss: 0.249638, Val Acc: 0.494845\n",
      "Epoch 1636 - Train Loss: 0.242306, Train Acc: 0.529487 | Val Loss: 0.249618, Val Acc: 0.494845\n",
      "Epoch 1637 - Train Loss: 0.242286, Train Acc: 0.530769 | Val Loss: 0.249598, Val Acc: 0.494845\n",
      "Epoch 1638 - Train Loss: 0.242266, Train Acc: 0.530769 | Val Loss: 0.249578, Val Acc: 0.494845\n",
      "Epoch 1639 - Train Loss: 0.242246, Train Acc: 0.530769 | Val Loss: 0.249558, Val Acc: 0.494845\n",
      "Epoch 1640 - Train Loss: 0.242227, Train Acc: 0.530769 | Val Loss: 0.249539, Val Acc: 0.494845\n",
      "Epoch 1641 - Train Loss: 0.242207, Train Acc: 0.530769 | Val Loss: 0.249519, Val Acc: 0.494845\n",
      "Epoch 1642 - Train Loss: 0.242187, Train Acc: 0.530769 | Val Loss: 0.249499, Val Acc: 0.494845\n",
      "Epoch 1643 - Train Loss: 0.242167, Train Acc: 0.530769 | Val Loss: 0.249479, Val Acc: 0.494845\n",
      "Epoch 1644 - Train Loss: 0.242147, Train Acc: 0.532051 | Val Loss: 0.249459, Val Acc: 0.494845\n",
      "Epoch 1645 - Train Loss: 0.242127, Train Acc: 0.532051 | Val Loss: 0.249440, Val Acc: 0.494845\n",
      "Epoch 1646 - Train Loss: 0.242107, Train Acc: 0.532051 | Val Loss: 0.249420, Val Acc: 0.494845\n",
      "Epoch 1647 - Train Loss: 0.242088, Train Acc: 0.532051 | Val Loss: 0.249400, Val Acc: 0.494845\n",
      "Epoch 1648 - Train Loss: 0.242068, Train Acc: 0.532051 | Val Loss: 0.249380, Val Acc: 0.494845\n",
      "Epoch 1649 - Train Loss: 0.242048, Train Acc: 0.532051 | Val Loss: 0.249360, Val Acc: 0.494845\n",
      "Epoch 1650 - Train Loss: 0.242028, Train Acc: 0.532051 | Val Loss: 0.249341, Val Acc: 0.494845\n",
      "Epoch 1651 - Train Loss: 0.242008, Train Acc: 0.532051 | Val Loss: 0.249321, Val Acc: 0.494845\n",
      "Epoch 1652 - Train Loss: 0.241988, Train Acc: 0.532051 | Val Loss: 0.249301, Val Acc: 0.494845\n",
      "Epoch 1653 - Train Loss: 0.241968, Train Acc: 0.532051 | Val Loss: 0.249281, Val Acc: 0.494845\n",
      "Epoch 1654 - Train Loss: 0.241948, Train Acc: 0.532051 | Val Loss: 0.249261, Val Acc: 0.494845\n",
      "Epoch 1655 - Train Loss: 0.241929, Train Acc: 0.532051 | Val Loss: 0.249241, Val Acc: 0.494845\n",
      "Epoch 1656 - Train Loss: 0.241909, Train Acc: 0.532051 | Val Loss: 0.249221, Val Acc: 0.494845\n",
      "Epoch 1657 - Train Loss: 0.241889, Train Acc: 0.532051 | Val Loss: 0.249202, Val Acc: 0.494845\n",
      "Epoch 1658 - Train Loss: 0.241869, Train Acc: 0.532051 | Val Loss: 0.249182, Val Acc: 0.494845\n",
      "Epoch 1659 - Train Loss: 0.241849, Train Acc: 0.532051 | Val Loss: 0.249162, Val Acc: 0.494845\n",
      "Epoch 1660 - Train Loss: 0.241829, Train Acc: 0.532051 | Val Loss: 0.249142, Val Acc: 0.494845\n",
      "Epoch 1661 - Train Loss: 0.241809, Train Acc: 0.532051 | Val Loss: 0.249122, Val Acc: 0.494845\n",
      "Epoch 1662 - Train Loss: 0.241789, Train Acc: 0.532051 | Val Loss: 0.249102, Val Acc: 0.494845\n",
      "Epoch 1663 - Train Loss: 0.241769, Train Acc: 0.532051 | Val Loss: 0.249082, Val Acc: 0.494845\n",
      "Epoch 1664 - Train Loss: 0.241749, Train Acc: 0.532051 | Val Loss: 0.249062, Val Acc: 0.494845\n",
      "Epoch 1665 - Train Loss: 0.241730, Train Acc: 0.532051 | Val Loss: 0.249043, Val Acc: 0.494845\n",
      "Epoch 1666 - Train Loss: 0.241710, Train Acc: 0.534615 | Val Loss: 0.249023, Val Acc: 0.494845\n",
      "Epoch 1667 - Train Loss: 0.241690, Train Acc: 0.534615 | Val Loss: 0.249003, Val Acc: 0.494845\n",
      "Epoch 1668 - Train Loss: 0.241670, Train Acc: 0.534615 | Val Loss: 0.248983, Val Acc: 0.494845\n",
      "Epoch 1669 - Train Loss: 0.241650, Train Acc: 0.534615 | Val Loss: 0.248963, Val Acc: 0.494845\n",
      "Epoch 1670 - Train Loss: 0.241630, Train Acc: 0.534615 | Val Loss: 0.248943, Val Acc: 0.494845\n",
      "Epoch 1671 - Train Loss: 0.241610, Train Acc: 0.534615 | Val Loss: 0.248923, Val Acc: 0.494845\n",
      "Epoch 1672 - Train Loss: 0.241590, Train Acc: 0.534615 | Val Loss: 0.248904, Val Acc: 0.494845\n",
      "Epoch 1673 - Train Loss: 0.241570, Train Acc: 0.534615 | Val Loss: 0.248884, Val Acc: 0.494845\n",
      "Epoch 1674 - Train Loss: 0.241550, Train Acc: 0.534615 | Val Loss: 0.248864, Val Acc: 0.494845\n",
      "Epoch 1675 - Train Loss: 0.241530, Train Acc: 0.534615 | Val Loss: 0.248844, Val Acc: 0.494845\n",
      "Epoch 1676 - Train Loss: 0.241511, Train Acc: 0.534615 | Val Loss: 0.248824, Val Acc: 0.494845\n",
      "Epoch 1677 - Train Loss: 0.241491, Train Acc: 0.534615 | Val Loss: 0.248804, Val Acc: 0.494845\n",
      "Epoch 1678 - Train Loss: 0.241471, Train Acc: 0.534615 | Val Loss: 0.248784, Val Acc: 0.494845\n",
      "Epoch 1679 - Train Loss: 0.241451, Train Acc: 0.534615 | Val Loss: 0.248764, Val Acc: 0.494845\n",
      "Epoch 1680 - Train Loss: 0.241431, Train Acc: 0.534615 | Val Loss: 0.248744, Val Acc: 0.494845\n",
      "Epoch 1681 - Train Loss: 0.241411, Train Acc: 0.534615 | Val Loss: 0.248724, Val Acc: 0.494845\n",
      "Epoch 1682 - Train Loss: 0.241391, Train Acc: 0.534615 | Val Loss: 0.248704, Val Acc: 0.494845\n",
      "Epoch 1683 - Train Loss: 0.241371, Train Acc: 0.534615 | Val Loss: 0.248684, Val Acc: 0.494845\n",
      "Epoch 1684 - Train Loss: 0.241351, Train Acc: 0.534615 | Val Loss: 0.248664, Val Acc: 0.494845\n",
      "Epoch 1685 - Train Loss: 0.241331, Train Acc: 0.534615 | Val Loss: 0.248644, Val Acc: 0.494845\n",
      "Epoch 1686 - Train Loss: 0.241311, Train Acc: 0.534615 | Val Loss: 0.248624, Val Acc: 0.494845\n",
      "Epoch 1687 - Train Loss: 0.241291, Train Acc: 0.534615 | Val Loss: 0.248604, Val Acc: 0.494845\n",
      "Epoch 1688 - Train Loss: 0.241271, Train Acc: 0.534615 | Val Loss: 0.248584, Val Acc: 0.494845\n",
      "Epoch 1689 - Train Loss: 0.241251, Train Acc: 0.534615 | Val Loss: 0.248564, Val Acc: 0.494845\n",
      "Epoch 1690 - Train Loss: 0.241231, Train Acc: 0.534615 | Val Loss: 0.248544, Val Acc: 0.494845\n",
      "Epoch 1691 - Train Loss: 0.241211, Train Acc: 0.534615 | Val Loss: 0.248524, Val Acc: 0.494845\n",
      "Epoch 1692 - Train Loss: 0.241191, Train Acc: 0.534615 | Val Loss: 0.248504, Val Acc: 0.494845\n",
      "Epoch 1693 - Train Loss: 0.241171, Train Acc: 0.534615 | Val Loss: 0.248484, Val Acc: 0.494845\n",
      "Epoch 1694 - Train Loss: 0.241152, Train Acc: 0.534615 | Val Loss: 0.248464, Val Acc: 0.494845\n",
      "Epoch 1695 - Train Loss: 0.241132, Train Acc: 0.534615 | Val Loss: 0.248444, Val Acc: 0.494845\n",
      "Epoch 1696 - Train Loss: 0.241112, Train Acc: 0.534615 | Val Loss: 0.248424, Val Acc: 0.494845\n",
      "Epoch 1697 - Train Loss: 0.241092, Train Acc: 0.534615 | Val Loss: 0.248404, Val Acc: 0.494845\n",
      "Epoch 1698 - Train Loss: 0.241072, Train Acc: 0.534615 | Val Loss: 0.248384, Val Acc: 0.494845\n",
      "Epoch 1699 - Train Loss: 0.241052, Train Acc: 0.534615 | Val Loss: 0.248364, Val Acc: 0.494845\n",
      "Epoch 1700 - Train Loss: 0.241032, Train Acc: 0.534615 | Val Loss: 0.248344, Val Acc: 0.494845\n",
      "Epoch 1701 - Train Loss: 0.241012, Train Acc: 0.534615 | Val Loss: 0.248324, Val Acc: 0.494845\n",
      "Epoch 1702 - Train Loss: 0.240992, Train Acc: 0.534615 | Val Loss: 0.248304, Val Acc: 0.494845\n",
      "Epoch 1703 - Train Loss: 0.240972, Train Acc: 0.534615 | Val Loss: 0.248284, Val Acc: 0.494845\n",
      "Epoch 1704 - Train Loss: 0.240952, Train Acc: 0.534615 | Val Loss: 0.248264, Val Acc: 0.494845\n",
      "Epoch 1705 - Train Loss: 0.240932, Train Acc: 0.534615 | Val Loss: 0.248244, Val Acc: 0.494845\n",
      "Epoch 1706 - Train Loss: 0.240912, Train Acc: 0.534615 | Val Loss: 0.248224, Val Acc: 0.494845\n",
      "Epoch 1707 - Train Loss: 0.240891, Train Acc: 0.534615 | Val Loss: 0.248204, Val Acc: 0.494845\n",
      "Epoch 1708 - Train Loss: 0.240871, Train Acc: 0.534615 | Val Loss: 0.248184, Val Acc: 0.494845\n",
      "Epoch 1709 - Train Loss: 0.240851, Train Acc: 0.534615 | Val Loss: 0.248163, Val Acc: 0.494845\n",
      "Epoch 1710 - Train Loss: 0.240831, Train Acc: 0.534615 | Val Loss: 0.248143, Val Acc: 0.494845\n",
      "Epoch 1711 - Train Loss: 0.240811, Train Acc: 0.534615 | Val Loss: 0.248123, Val Acc: 0.494845\n",
      "Epoch 1712 - Train Loss: 0.240791, Train Acc: 0.534615 | Val Loss: 0.248103, Val Acc: 0.494845\n",
      "Epoch 1713 - Train Loss: 0.240771, Train Acc: 0.534615 | Val Loss: 0.248083, Val Acc: 0.494845\n",
      "Epoch 1714 - Train Loss: 0.240751, Train Acc: 0.534615 | Val Loss: 0.248063, Val Acc: 0.494845\n",
      "Epoch 1715 - Train Loss: 0.240731, Train Acc: 0.534615 | Val Loss: 0.248043, Val Acc: 0.494845\n",
      "Epoch 1716 - Train Loss: 0.240711, Train Acc: 0.534615 | Val Loss: 0.248023, Val Acc: 0.494845\n",
      "Epoch 1717 - Train Loss: 0.240691, Train Acc: 0.534615 | Val Loss: 0.248003, Val Acc: 0.494845\n",
      "Epoch 1718 - Train Loss: 0.240671, Train Acc: 0.534615 | Val Loss: 0.247983, Val Acc: 0.494845\n",
      "Epoch 1719 - Train Loss: 0.240651, Train Acc: 0.534615 | Val Loss: 0.247963, Val Acc: 0.494845\n",
      "Epoch 1720 - Train Loss: 0.240631, Train Acc: 0.534615 | Val Loss: 0.247942, Val Acc: 0.494845\n",
      "Epoch 1721 - Train Loss: 0.240611, Train Acc: 0.535897 | Val Loss: 0.247922, Val Acc: 0.494845\n",
      "Epoch 1722 - Train Loss: 0.240591, Train Acc: 0.535897 | Val Loss: 0.247902, Val Acc: 0.494845\n",
      "Epoch 1723 - Train Loss: 0.240571, Train Acc: 0.535897 | Val Loss: 0.247882, Val Acc: 0.494845\n",
      "Epoch 1724 - Train Loss: 0.240551, Train Acc: 0.535897 | Val Loss: 0.247862, Val Acc: 0.494845\n",
      "Epoch 1725 - Train Loss: 0.240531, Train Acc: 0.535897 | Val Loss: 0.247842, Val Acc: 0.494845\n",
      "Epoch 1726 - Train Loss: 0.240510, Train Acc: 0.535897 | Val Loss: 0.247822, Val Acc: 0.494845\n",
      "Epoch 1727 - Train Loss: 0.240490, Train Acc: 0.535897 | Val Loss: 0.247801, Val Acc: 0.494845\n",
      "Epoch 1728 - Train Loss: 0.240470, Train Acc: 0.535897 | Val Loss: 0.247781, Val Acc: 0.494845\n",
      "Epoch 1729 - Train Loss: 0.240450, Train Acc: 0.535897 | Val Loss: 0.247761, Val Acc: 0.494845\n",
      "Epoch 1730 - Train Loss: 0.240430, Train Acc: 0.535897 | Val Loss: 0.247741, Val Acc: 0.494845\n",
      "Epoch 1731 - Train Loss: 0.240410, Train Acc: 0.535897 | Val Loss: 0.247721, Val Acc: 0.494845\n",
      "Epoch 1732 - Train Loss: 0.240390, Train Acc: 0.535897 | Val Loss: 0.247701, Val Acc: 0.494845\n",
      "Epoch 1733 - Train Loss: 0.240370, Train Acc: 0.535897 | Val Loss: 0.247681, Val Acc: 0.494845\n",
      "Epoch 1734 - Train Loss: 0.240350, Train Acc: 0.535897 | Val Loss: 0.247661, Val Acc: 0.494845\n",
      "Epoch 1735 - Train Loss: 0.240330, Train Acc: 0.535897 | Val Loss: 0.247641, Val Acc: 0.494845\n",
      "Epoch 1736 - Train Loss: 0.240310, Train Acc: 0.535897 | Val Loss: 0.247621, Val Acc: 0.494845\n",
      "Epoch 1737 - Train Loss: 0.240290, Train Acc: 0.535897 | Val Loss: 0.247601, Val Acc: 0.494845\n",
      "Epoch 1738 - Train Loss: 0.240269, Train Acc: 0.537179 | Val Loss: 0.247581, Val Acc: 0.494845\n",
      "Epoch 1739 - Train Loss: 0.240249, Train Acc: 0.537179 | Val Loss: 0.247561, Val Acc: 0.494845\n",
      "Epoch 1740 - Train Loss: 0.240229, Train Acc: 0.537179 | Val Loss: 0.247541, Val Acc: 0.494845\n",
      "Epoch 1741 - Train Loss: 0.240209, Train Acc: 0.537179 | Val Loss: 0.247521, Val Acc: 0.494845\n",
      "Epoch 1742 - Train Loss: 0.240189, Train Acc: 0.537179 | Val Loss: 0.247501, Val Acc: 0.494845\n",
      "Epoch 1743 - Train Loss: 0.240169, Train Acc: 0.537179 | Val Loss: 0.247481, Val Acc: 0.494845\n",
      "Epoch 1744 - Train Loss: 0.240149, Train Acc: 0.537179 | Val Loss: 0.247461, Val Acc: 0.494845\n",
      "Epoch 1745 - Train Loss: 0.240129, Train Acc: 0.538462 | Val Loss: 0.247441, Val Acc: 0.494845\n",
      "Epoch 1746 - Train Loss: 0.240109, Train Acc: 0.538462 | Val Loss: 0.247420, Val Acc: 0.494845\n",
      "Epoch 1747 - Train Loss: 0.240088, Train Acc: 0.538462 | Val Loss: 0.247400, Val Acc: 0.494845\n",
      "Epoch 1748 - Train Loss: 0.240068, Train Acc: 0.538462 | Val Loss: 0.247380, Val Acc: 0.494845\n",
      "Epoch 1749 - Train Loss: 0.240048, Train Acc: 0.538462 | Val Loss: 0.247360, Val Acc: 0.494845\n",
      "Epoch 1750 - Train Loss: 0.240028, Train Acc: 0.538462 | Val Loss: 0.247340, Val Acc: 0.494845\n",
      "Epoch 1751 - Train Loss: 0.240008, Train Acc: 0.538462 | Val Loss: 0.247320, Val Acc: 0.494845\n",
      "Epoch 1752 - Train Loss: 0.239988, Train Acc: 0.539744 | Val Loss: 0.247300, Val Acc: 0.494845\n",
      "Epoch 1753 - Train Loss: 0.239968, Train Acc: 0.539744 | Val Loss: 0.247280, Val Acc: 0.494845\n",
      "Epoch 1754 - Train Loss: 0.239948, Train Acc: 0.539744 | Val Loss: 0.247259, Val Acc: 0.494845\n",
      "Epoch 1755 - Train Loss: 0.239927, Train Acc: 0.539744 | Val Loss: 0.247239, Val Acc: 0.494845\n",
      "Epoch 1756 - Train Loss: 0.239907, Train Acc: 0.539744 | Val Loss: 0.247219, Val Acc: 0.494845\n",
      "Epoch 1757 - Train Loss: 0.239887, Train Acc: 0.539744 | Val Loss: 0.247199, Val Acc: 0.494845\n",
      "Epoch 1758 - Train Loss: 0.239867, Train Acc: 0.539744 | Val Loss: 0.247179, Val Acc: 0.494845\n",
      "Epoch 1759 - Train Loss: 0.239847, Train Acc: 0.539744 | Val Loss: 0.247159, Val Acc: 0.494845\n",
      "Epoch 1760 - Train Loss: 0.239827, Train Acc: 0.539744 | Val Loss: 0.247138, Val Acc: 0.494845\n",
      "Epoch 1761 - Train Loss: 0.239806, Train Acc: 0.539744 | Val Loss: 0.247118, Val Acc: 0.494845\n",
      "Epoch 1762 - Train Loss: 0.239786, Train Acc: 0.539744 | Val Loss: 0.247098, Val Acc: 0.494845\n",
      "Epoch 1763 - Train Loss: 0.239766, Train Acc: 0.539744 | Val Loss: 0.247078, Val Acc: 0.494845\n",
      "Epoch 1764 - Train Loss: 0.239746, Train Acc: 0.539744 | Val Loss: 0.247058, Val Acc: 0.494845\n",
      "Epoch 1765 - Train Loss: 0.239726, Train Acc: 0.539744 | Val Loss: 0.247037, Val Acc: 0.494845\n",
      "Epoch 1766 - Train Loss: 0.239706, Train Acc: 0.539744 | Val Loss: 0.247017, Val Acc: 0.494845\n",
      "Epoch 1767 - Train Loss: 0.239685, Train Acc: 0.539744 | Val Loss: 0.246997, Val Acc: 0.494845\n",
      "Epoch 1768 - Train Loss: 0.239665, Train Acc: 0.539744 | Val Loss: 0.246977, Val Acc: 0.494845\n",
      "Epoch 1769 - Train Loss: 0.239645, Train Acc: 0.539744 | Val Loss: 0.246957, Val Acc: 0.494845\n",
      "Epoch 1770 - Train Loss: 0.239625, Train Acc: 0.539744 | Val Loss: 0.246936, Val Acc: 0.494845\n",
      "Epoch 1771 - Train Loss: 0.239605, Train Acc: 0.539744 | Val Loss: 0.246916, Val Acc: 0.494845\n",
      "Epoch 1772 - Train Loss: 0.239585, Train Acc: 0.539744 | Val Loss: 0.246896, Val Acc: 0.494845\n",
      "Epoch 1773 - Train Loss: 0.239564, Train Acc: 0.539744 | Val Loss: 0.246876, Val Acc: 0.494845\n",
      "Epoch 1774 - Train Loss: 0.239544, Train Acc: 0.541026 | Val Loss: 0.246856, Val Acc: 0.494845\n",
      "Epoch 1775 - Train Loss: 0.239524, Train Acc: 0.541026 | Val Loss: 0.246836, Val Acc: 0.494845\n",
      "Epoch 1776 - Train Loss: 0.239504, Train Acc: 0.541026 | Val Loss: 0.246815, Val Acc: 0.494845\n",
      "Epoch 1777 - Train Loss: 0.239484, Train Acc: 0.541026 | Val Loss: 0.246795, Val Acc: 0.494845\n",
      "Epoch 1778 - Train Loss: 0.239464, Train Acc: 0.541026 | Val Loss: 0.246775, Val Acc: 0.494845\n",
      "Epoch 1779 - Train Loss: 0.239443, Train Acc: 0.541026 | Val Loss: 0.246755, Val Acc: 0.494845\n",
      "Epoch 1780 - Train Loss: 0.239423, Train Acc: 0.541026 | Val Loss: 0.246735, Val Acc: 0.494845\n",
      "Epoch 1781 - Train Loss: 0.239403, Train Acc: 0.541026 | Val Loss: 0.246715, Val Acc: 0.494845\n",
      "Epoch 1782 - Train Loss: 0.239383, Train Acc: 0.541026 | Val Loss: 0.246694, Val Acc: 0.494845\n",
      "Epoch 1783 - Train Loss: 0.239363, Train Acc: 0.541026 | Val Loss: 0.246674, Val Acc: 0.494845\n",
      "Epoch 1784 - Train Loss: 0.239342, Train Acc: 0.541026 | Val Loss: 0.246654, Val Acc: 0.494845\n",
      "Epoch 1785 - Train Loss: 0.239322, Train Acc: 0.541026 | Val Loss: 0.246634, Val Acc: 0.494845\n",
      "Epoch 1786 - Train Loss: 0.239302, Train Acc: 0.541026 | Val Loss: 0.246613, Val Acc: 0.494845\n",
      "Epoch 1787 - Train Loss: 0.239282, Train Acc: 0.541026 | Val Loss: 0.246593, Val Acc: 0.505155\n",
      "Epoch 1788 - Train Loss: 0.239262, Train Acc: 0.541026 | Val Loss: 0.246573, Val Acc: 0.505155\n",
      "Epoch 1789 - Train Loss: 0.239241, Train Acc: 0.541026 | Val Loss: 0.246553, Val Acc: 0.505155\n",
      "Epoch 1790 - Train Loss: 0.239221, Train Acc: 0.541026 | Val Loss: 0.246532, Val Acc: 0.505155\n",
      "Epoch 1791 - Train Loss: 0.239201, Train Acc: 0.541026 | Val Loss: 0.246512, Val Acc: 0.505155\n",
      "Epoch 1792 - Train Loss: 0.239181, Train Acc: 0.541026 | Val Loss: 0.246492, Val Acc: 0.505155\n",
      "Epoch 1793 - Train Loss: 0.239161, Train Acc: 0.541026 | Val Loss: 0.246472, Val Acc: 0.505155\n",
      "Epoch 1794 - Train Loss: 0.239140, Train Acc: 0.541026 | Val Loss: 0.246452, Val Acc: 0.505155\n",
      "Epoch 1795 - Train Loss: 0.239120, Train Acc: 0.541026 | Val Loss: 0.246432, Val Acc: 0.505155\n",
      "Epoch 1796 - Train Loss: 0.239100, Train Acc: 0.541026 | Val Loss: 0.246412, Val Acc: 0.505155\n",
      "Epoch 1797 - Train Loss: 0.239080, Train Acc: 0.541026 | Val Loss: 0.246392, Val Acc: 0.505155\n",
      "Epoch 1798 - Train Loss: 0.239059, Train Acc: 0.542308 | Val Loss: 0.246372, Val Acc: 0.505155\n",
      "Epoch 1799 - Train Loss: 0.239039, Train Acc: 0.542308 | Val Loss: 0.246351, Val Acc: 0.505155\n",
      "Epoch 1800 - Train Loss: 0.239019, Train Acc: 0.542308 | Val Loss: 0.246331, Val Acc: 0.505155\n",
      "Epoch 1801 - Train Loss: 0.238999, Train Acc: 0.542308 | Val Loss: 0.246311, Val Acc: 0.505155\n",
      "Epoch 1802 - Train Loss: 0.238979, Train Acc: 0.542308 | Val Loss: 0.246291, Val Acc: 0.505155\n",
      "Epoch 1803 - Train Loss: 0.238958, Train Acc: 0.542308 | Val Loss: 0.246271, Val Acc: 0.505155\n",
      "Epoch 1804 - Train Loss: 0.238938, Train Acc: 0.542308 | Val Loss: 0.246251, Val Acc: 0.505155\n",
      "Epoch 1805 - Train Loss: 0.238918, Train Acc: 0.542308 | Val Loss: 0.246231, Val Acc: 0.505155\n",
      "Epoch 1806 - Train Loss: 0.238898, Train Acc: 0.542308 | Val Loss: 0.246211, Val Acc: 0.505155\n",
      "Epoch 1807 - Train Loss: 0.238877, Train Acc: 0.542308 | Val Loss: 0.246191, Val Acc: 0.505155\n",
      "Epoch 1808 - Train Loss: 0.238857, Train Acc: 0.542308 | Val Loss: 0.246171, Val Acc: 0.505155\n",
      "Epoch 1809 - Train Loss: 0.238837, Train Acc: 0.542308 | Val Loss: 0.246150, Val Acc: 0.505155\n",
      "Epoch 1810 - Train Loss: 0.238817, Train Acc: 0.542308 | Val Loss: 0.246130, Val Acc: 0.505155\n",
      "Epoch 1811 - Train Loss: 0.238797, Train Acc: 0.542308 | Val Loss: 0.246110, Val Acc: 0.505155\n",
      "Epoch 1812 - Train Loss: 0.238776, Train Acc: 0.542308 | Val Loss: 0.246090, Val Acc: 0.505155\n",
      "Epoch 1813 - Train Loss: 0.238756, Train Acc: 0.542308 | Val Loss: 0.246070, Val Acc: 0.505155\n",
      "Epoch 1814 - Train Loss: 0.238736, Train Acc: 0.542308 | Val Loss: 0.246050, Val Acc: 0.505155\n",
      "Epoch 1815 - Train Loss: 0.238716, Train Acc: 0.542308 | Val Loss: 0.246030, Val Acc: 0.505155\n",
      "Epoch 1816 - Train Loss: 0.238695, Train Acc: 0.542308 | Val Loss: 0.246010, Val Acc: 0.505155\n",
      "Epoch 1817 - Train Loss: 0.238675, Train Acc: 0.542308 | Val Loss: 0.245990, Val Acc: 0.505155\n",
      "Epoch 1818 - Train Loss: 0.238655, Train Acc: 0.542308 | Val Loss: 0.245970, Val Acc: 0.505155\n",
      "Epoch 1819 - Train Loss: 0.238635, Train Acc: 0.542308 | Val Loss: 0.245949, Val Acc: 0.505155\n",
      "Epoch 1820 - Train Loss: 0.238614, Train Acc: 0.542308 | Val Loss: 0.245929, Val Acc: 0.505155\n",
      "Epoch 1821 - Train Loss: 0.238594, Train Acc: 0.543590 | Val Loss: 0.245909, Val Acc: 0.505155\n",
      "Epoch 1822 - Train Loss: 0.238574, Train Acc: 0.543590 | Val Loss: 0.245889, Val Acc: 0.505155\n",
      "Epoch 1823 - Train Loss: 0.238554, Train Acc: 0.543590 | Val Loss: 0.245869, Val Acc: 0.505155\n",
      "Epoch 1824 - Train Loss: 0.238533, Train Acc: 0.543590 | Val Loss: 0.245849, Val Acc: 0.505155\n",
      "Epoch 1825 - Train Loss: 0.238513, Train Acc: 0.543590 | Val Loss: 0.245829, Val Acc: 0.505155\n",
      "Epoch 1826 - Train Loss: 0.238493, Train Acc: 0.543590 | Val Loss: 0.245809, Val Acc: 0.505155\n",
      "Epoch 1827 - Train Loss: 0.238473, Train Acc: 0.543590 | Val Loss: 0.245788, Val Acc: 0.505155\n",
      "Epoch 1828 - Train Loss: 0.238452, Train Acc: 0.543590 | Val Loss: 0.245768, Val Acc: 0.505155\n",
      "Epoch 1829 - Train Loss: 0.238432, Train Acc: 0.543590 | Val Loss: 0.245748, Val Acc: 0.505155\n",
      "Epoch 1830 - Train Loss: 0.238412, Train Acc: 0.543590 | Val Loss: 0.245728, Val Acc: 0.505155\n",
      "Epoch 1831 - Train Loss: 0.238391, Train Acc: 0.543590 | Val Loss: 0.245708, Val Acc: 0.505155\n",
      "Epoch 1832 - Train Loss: 0.238371, Train Acc: 0.543590 | Val Loss: 0.245687, Val Acc: 0.505155\n",
      "Epoch 1833 - Train Loss: 0.238351, Train Acc: 0.543590 | Val Loss: 0.245667, Val Acc: 0.505155\n",
      "Epoch 1834 - Train Loss: 0.238331, Train Acc: 0.543590 | Val Loss: 0.245647, Val Acc: 0.505155\n",
      "Epoch 1835 - Train Loss: 0.238310, Train Acc: 0.543590 | Val Loss: 0.245627, Val Acc: 0.505155\n",
      "Epoch 1836 - Train Loss: 0.238290, Train Acc: 0.543590 | Val Loss: 0.245607, Val Acc: 0.505155\n",
      "Epoch 1837 - Train Loss: 0.238270, Train Acc: 0.543590 | Val Loss: 0.245586, Val Acc: 0.505155\n",
      "Epoch 1838 - Train Loss: 0.238249, Train Acc: 0.543590 | Val Loss: 0.245566, Val Acc: 0.505155\n",
      "Epoch 1839 - Train Loss: 0.238229, Train Acc: 0.543590 | Val Loss: 0.245546, Val Acc: 0.505155\n",
      "Epoch 1840 - Train Loss: 0.238209, Train Acc: 0.543590 | Val Loss: 0.245525, Val Acc: 0.505155\n",
      "Epoch 1841 - Train Loss: 0.238188, Train Acc: 0.543590 | Val Loss: 0.245505, Val Acc: 0.505155\n",
      "Epoch 1842 - Train Loss: 0.238168, Train Acc: 0.543590 | Val Loss: 0.245485, Val Acc: 0.505155\n",
      "Epoch 1843 - Train Loss: 0.238148, Train Acc: 0.543590 | Val Loss: 0.245464, Val Acc: 0.505155\n",
      "Epoch 1844 - Train Loss: 0.238127, Train Acc: 0.543590 | Val Loss: 0.245444, Val Acc: 0.505155\n",
      "Epoch 1845 - Train Loss: 0.238107, Train Acc: 0.543590 | Val Loss: 0.245423, Val Acc: 0.505155\n",
      "Epoch 1846 - Train Loss: 0.238087, Train Acc: 0.543590 | Val Loss: 0.245403, Val Acc: 0.505155\n",
      "Epoch 1847 - Train Loss: 0.238066, Train Acc: 0.543590 | Val Loss: 0.245383, Val Acc: 0.505155\n",
      "Epoch 1848 - Train Loss: 0.238046, Train Acc: 0.543590 | Val Loss: 0.245362, Val Acc: 0.505155\n",
      "Epoch 1849 - Train Loss: 0.238026, Train Acc: 0.543590 | Val Loss: 0.245342, Val Acc: 0.505155\n",
      "Epoch 1850 - Train Loss: 0.238005, Train Acc: 0.543590 | Val Loss: 0.245321, Val Acc: 0.505155\n",
      "Epoch 1851 - Train Loss: 0.237985, Train Acc: 0.543590 | Val Loss: 0.245301, Val Acc: 0.505155\n",
      "Epoch 1852 - Train Loss: 0.237964, Train Acc: 0.543590 | Val Loss: 0.245280, Val Acc: 0.505155\n",
      "Epoch 1853 - Train Loss: 0.237944, Train Acc: 0.543590 | Val Loss: 0.245260, Val Acc: 0.505155\n",
      "Epoch 1854 - Train Loss: 0.237924, Train Acc: 0.543590 | Val Loss: 0.245240, Val Acc: 0.505155\n",
      "Epoch 1855 - Train Loss: 0.237903, Train Acc: 0.543590 | Val Loss: 0.245219, Val Acc: 0.505155\n",
      "Epoch 1856 - Train Loss: 0.237883, Train Acc: 0.543590 | Val Loss: 0.245198, Val Acc: 0.505155\n",
      "Epoch 1857 - Train Loss: 0.237862, Train Acc: 0.543590 | Val Loss: 0.245178, Val Acc: 0.505155\n",
      "Epoch 1858 - Train Loss: 0.237842, Train Acc: 0.543590 | Val Loss: 0.245157, Val Acc: 0.505155\n",
      "Epoch 1859 - Train Loss: 0.237822, Train Acc: 0.543590 | Val Loss: 0.245137, Val Acc: 0.505155\n",
      "Epoch 1860 - Train Loss: 0.237801, Train Acc: 0.543590 | Val Loss: 0.245116, Val Acc: 0.505155\n",
      "Epoch 1861 - Train Loss: 0.237781, Train Acc: 0.543590 | Val Loss: 0.245096, Val Acc: 0.505155\n",
      "Epoch 1862 - Train Loss: 0.237760, Train Acc: 0.543590 | Val Loss: 0.245075, Val Acc: 0.505155\n",
      "Epoch 1863 - Train Loss: 0.237740, Train Acc: 0.543590 | Val Loss: 0.245054, Val Acc: 0.505155\n",
      "Epoch 1864 - Train Loss: 0.237719, Train Acc: 0.543590 | Val Loss: 0.245034, Val Acc: 0.505155\n",
      "Epoch 1865 - Train Loss: 0.237699, Train Acc: 0.543590 | Val Loss: 0.245013, Val Acc: 0.505155\n",
      "Epoch 1866 - Train Loss: 0.237678, Train Acc: 0.543590 | Val Loss: 0.244993, Val Acc: 0.505155\n",
      "Epoch 1867 - Train Loss: 0.237658, Train Acc: 0.543590 | Val Loss: 0.244972, Val Acc: 0.505155\n",
      "Epoch 1868 - Train Loss: 0.237638, Train Acc: 0.543590 | Val Loss: 0.244951, Val Acc: 0.505155\n",
      "Epoch 1869 - Train Loss: 0.237617, Train Acc: 0.543590 | Val Loss: 0.244931, Val Acc: 0.505155\n",
      "Epoch 1870 - Train Loss: 0.237597, Train Acc: 0.543590 | Val Loss: 0.244910, Val Acc: 0.505155\n",
      "Epoch 1871 - Train Loss: 0.237576, Train Acc: 0.543590 | Val Loss: 0.244889, Val Acc: 0.505155\n",
      "Epoch 1872 - Train Loss: 0.237556, Train Acc: 0.543590 | Val Loss: 0.244869, Val Acc: 0.505155\n",
      "Epoch 1873 - Train Loss: 0.237535, Train Acc: 0.543590 | Val Loss: 0.244848, Val Acc: 0.505155\n",
      "Epoch 1874 - Train Loss: 0.237515, Train Acc: 0.543590 | Val Loss: 0.244828, Val Acc: 0.505155\n",
      "Epoch 1875 - Train Loss: 0.237494, Train Acc: 0.543590 | Val Loss: 0.244807, Val Acc: 0.505155\n",
      "Epoch 1876 - Train Loss: 0.237474, Train Acc: 0.543590 | Val Loss: 0.244786, Val Acc: 0.505155\n",
      "Epoch 1877 - Train Loss: 0.237453, Train Acc: 0.543590 | Val Loss: 0.244766, Val Acc: 0.505155\n",
      "Epoch 1878 - Train Loss: 0.237433, Train Acc: 0.543590 | Val Loss: 0.244745, Val Acc: 0.505155\n",
      "Epoch 1879 - Train Loss: 0.237412, Train Acc: 0.543590 | Val Loss: 0.244725, Val Acc: 0.505155\n",
      "Epoch 1880 - Train Loss: 0.237392, Train Acc: 0.543590 | Val Loss: 0.244704, Val Acc: 0.505155\n",
      "Epoch 1881 - Train Loss: 0.237372, Train Acc: 0.543590 | Val Loss: 0.244684, Val Acc: 0.505155\n",
      "Epoch 1882 - Train Loss: 0.237351, Train Acc: 0.543590 | Val Loss: 0.244663, Val Acc: 0.505155\n",
      "Epoch 1883 - Train Loss: 0.237331, Train Acc: 0.543590 | Val Loss: 0.244643, Val Acc: 0.505155\n",
      "Epoch 1884 - Train Loss: 0.237310, Train Acc: 0.543590 | Val Loss: 0.244622, Val Acc: 0.505155\n",
      "Epoch 1885 - Train Loss: 0.237290, Train Acc: 0.543590 | Val Loss: 0.244602, Val Acc: 0.505155\n",
      "Epoch 1886 - Train Loss: 0.237269, Train Acc: 0.543590 | Val Loss: 0.244581, Val Acc: 0.505155\n",
      "Epoch 1887 - Train Loss: 0.237249, Train Acc: 0.543590 | Val Loss: 0.244561, Val Acc: 0.505155\n",
      "Epoch 1888 - Train Loss: 0.237229, Train Acc: 0.543590 | Val Loss: 0.244540, Val Acc: 0.505155\n",
      "Epoch 1889 - Train Loss: 0.237208, Train Acc: 0.543590 | Val Loss: 0.244520, Val Acc: 0.505155\n",
      "Epoch 1890 - Train Loss: 0.237188, Train Acc: 0.543590 | Val Loss: 0.244500, Val Acc: 0.505155\n",
      "Epoch 1891 - Train Loss: 0.237167, Train Acc: 0.543590 | Val Loss: 0.244479, Val Acc: 0.505155\n",
      "Epoch 1892 - Train Loss: 0.237147, Train Acc: 0.543590 | Val Loss: 0.244459, Val Acc: 0.505155\n",
      "Epoch 1893 - Train Loss: 0.237126, Train Acc: 0.543590 | Val Loss: 0.244438, Val Acc: 0.505155\n",
      "Epoch 1894 - Train Loss: 0.237106, Train Acc: 0.543590 | Val Loss: 0.244418, Val Acc: 0.505155\n",
      "Epoch 1895 - Train Loss: 0.237086, Train Acc: 0.543590 | Val Loss: 0.244397, Val Acc: 0.505155\n",
      "Epoch 1896 - Train Loss: 0.237065, Train Acc: 0.543590 | Val Loss: 0.244377, Val Acc: 0.505155\n",
      "Epoch 1897 - Train Loss: 0.237045, Train Acc: 0.543590 | Val Loss: 0.244356, Val Acc: 0.505155\n",
      "Epoch 1898 - Train Loss: 0.237024, Train Acc: 0.542308 | Val Loss: 0.244336, Val Acc: 0.505155\n",
      "Epoch 1899 - Train Loss: 0.237004, Train Acc: 0.542308 | Val Loss: 0.244315, Val Acc: 0.505155\n",
      "Epoch 1900 - Train Loss: 0.236983, Train Acc: 0.542308 | Val Loss: 0.244295, Val Acc: 0.505155\n",
      "Epoch 1901 - Train Loss: 0.236963, Train Acc: 0.542308 | Val Loss: 0.244274, Val Acc: 0.515464\n",
      "Epoch 1902 - Train Loss: 0.236942, Train Acc: 0.542308 | Val Loss: 0.244254, Val Acc: 0.515464\n",
      "Epoch 1903 - Train Loss: 0.236922, Train Acc: 0.542308 | Val Loss: 0.244233, Val Acc: 0.515464\n",
      "Epoch 1904 - Train Loss: 0.236901, Train Acc: 0.542308 | Val Loss: 0.244213, Val Acc: 0.515464\n",
      "Epoch 1905 - Train Loss: 0.236881, Train Acc: 0.542308 | Val Loss: 0.244192, Val Acc: 0.515464\n",
      "Epoch 1906 - Train Loss: 0.236860, Train Acc: 0.542308 | Val Loss: 0.244172, Val Acc: 0.515464\n",
      "Epoch 1907 - Train Loss: 0.236840, Train Acc: 0.542308 | Val Loss: 0.244151, Val Acc: 0.515464\n",
      "Epoch 1908 - Train Loss: 0.236819, Train Acc: 0.542308 | Val Loss: 0.244131, Val Acc: 0.515464\n",
      "Epoch 1909 - Train Loss: 0.236799, Train Acc: 0.542308 | Val Loss: 0.244111, Val Acc: 0.515464\n",
      "Epoch 1910 - Train Loss: 0.236779, Train Acc: 0.542308 | Val Loss: 0.244090, Val Acc: 0.515464\n",
      "Epoch 1911 - Train Loss: 0.236758, Train Acc: 0.542308 | Val Loss: 0.244070, Val Acc: 0.515464\n",
      "Epoch 1912 - Train Loss: 0.236738, Train Acc: 0.542308 | Val Loss: 0.244050, Val Acc: 0.515464\n",
      "Epoch 1913 - Train Loss: 0.236717, Train Acc: 0.542308 | Val Loss: 0.244029, Val Acc: 0.515464\n",
      "Epoch 1914 - Train Loss: 0.236697, Train Acc: 0.542308 | Val Loss: 0.244009, Val Acc: 0.515464\n",
      "Epoch 1915 - Train Loss: 0.236676, Train Acc: 0.542308 | Val Loss: 0.243989, Val Acc: 0.515464\n",
      "Epoch 1916 - Train Loss: 0.236656, Train Acc: 0.542308 | Val Loss: 0.243968, Val Acc: 0.515464\n",
      "Epoch 1917 - Train Loss: 0.236635, Train Acc: 0.542308 | Val Loss: 0.243948, Val Acc: 0.515464\n",
      "Epoch 1918 - Train Loss: 0.236615, Train Acc: 0.542308 | Val Loss: 0.243927, Val Acc: 0.515464\n",
      "Epoch 1919 - Train Loss: 0.236595, Train Acc: 0.542308 | Val Loss: 0.243907, Val Acc: 0.515464\n",
      "Epoch 1920 - Train Loss: 0.236574, Train Acc: 0.542308 | Val Loss: 0.243887, Val Acc: 0.515464\n",
      "Epoch 1921 - Train Loss: 0.236554, Train Acc: 0.542308 | Val Loss: 0.243866, Val Acc: 0.515464\n",
      "Epoch 1922 - Train Loss: 0.236533, Train Acc: 0.542308 | Val Loss: 0.243846, Val Acc: 0.515464\n",
      "Epoch 1923 - Train Loss: 0.236513, Train Acc: 0.542308 | Val Loss: 0.243825, Val Acc: 0.515464\n",
      "Epoch 1924 - Train Loss: 0.236492, Train Acc: 0.542308 | Val Loss: 0.243805, Val Acc: 0.515464\n",
      "Epoch 1925 - Train Loss: 0.236472, Train Acc: 0.542308 | Val Loss: 0.243784, Val Acc: 0.515464\n",
      "Epoch 1926 - Train Loss: 0.236451, Train Acc: 0.542308 | Val Loss: 0.243764, Val Acc: 0.515464\n",
      "Epoch 1927 - Train Loss: 0.236431, Train Acc: 0.542308 | Val Loss: 0.243744, Val Acc: 0.515464\n",
      "Epoch 1928 - Train Loss: 0.236410, Train Acc: 0.542308 | Val Loss: 0.243723, Val Acc: 0.515464\n",
      "Epoch 1929 - Train Loss: 0.236390, Train Acc: 0.542308 | Val Loss: 0.243703, Val Acc: 0.515464\n",
      "Epoch 1930 - Train Loss: 0.236369, Train Acc: 0.542308 | Val Loss: 0.243682, Val Acc: 0.515464\n",
      "Epoch 1931 - Train Loss: 0.236349, Train Acc: 0.542308 | Val Loss: 0.243662, Val Acc: 0.515464\n",
      "Epoch 1932 - Train Loss: 0.236328, Train Acc: 0.542308 | Val Loss: 0.243641, Val Acc: 0.515464\n",
      "Epoch 1933 - Train Loss: 0.236308, Train Acc: 0.542308 | Val Loss: 0.243621, Val Acc: 0.515464\n",
      "Epoch 1934 - Train Loss: 0.236287, Train Acc: 0.542308 | Val Loss: 0.243600, Val Acc: 0.515464\n",
      "Epoch 1935 - Train Loss: 0.236267, Train Acc: 0.542308 | Val Loss: 0.243580, Val Acc: 0.515464\n",
      "Epoch 1936 - Train Loss: 0.236246, Train Acc: 0.542308 | Val Loss: 0.243559, Val Acc: 0.515464\n",
      "Epoch 1937 - Train Loss: 0.236226, Train Acc: 0.542308 | Val Loss: 0.243538, Val Acc: 0.515464\n",
      "Epoch 1938 - Train Loss: 0.236205, Train Acc: 0.542308 | Val Loss: 0.243518, Val Acc: 0.515464\n",
      "Epoch 1939 - Train Loss: 0.236185, Train Acc: 0.542308 | Val Loss: 0.243497, Val Acc: 0.515464\n",
      "Epoch 1940 - Train Loss: 0.236164, Train Acc: 0.542308 | Val Loss: 0.243477, Val Acc: 0.515464\n",
      "Epoch 1941 - Train Loss: 0.236144, Train Acc: 0.543590 | Val Loss: 0.243457, Val Acc: 0.515464\n",
      "Epoch 1942 - Train Loss: 0.236123, Train Acc: 0.543590 | Val Loss: 0.243436, Val Acc: 0.515464\n",
      "Epoch 1943 - Train Loss: 0.236103, Train Acc: 0.543590 | Val Loss: 0.243416, Val Acc: 0.515464\n",
      "Epoch 1944 - Train Loss: 0.236082, Train Acc: 0.543590 | Val Loss: 0.243395, Val Acc: 0.515464\n",
      "Epoch 1945 - Train Loss: 0.236062, Train Acc: 0.543590 | Val Loss: 0.243375, Val Acc: 0.515464\n",
      "Epoch 1946 - Train Loss: 0.236042, Train Acc: 0.543590 | Val Loss: 0.243354, Val Acc: 0.515464\n",
      "Epoch 1947 - Train Loss: 0.236021, Train Acc: 0.543590 | Val Loss: 0.243334, Val Acc: 0.515464\n",
      "Epoch 1948 - Train Loss: 0.236001, Train Acc: 0.543590 | Val Loss: 0.243313, Val Acc: 0.515464\n",
      "Epoch 1949 - Train Loss: 0.235980, Train Acc: 0.543590 | Val Loss: 0.243293, Val Acc: 0.515464\n",
      "Epoch 1950 - Train Loss: 0.235960, Train Acc: 0.543590 | Val Loss: 0.243272, Val Acc: 0.515464\n",
      "Epoch 1951 - Train Loss: 0.235939, Train Acc: 0.543590 | Val Loss: 0.243252, Val Acc: 0.515464\n",
      "Epoch 1952 - Train Loss: 0.235919, Train Acc: 0.543590 | Val Loss: 0.243232, Val Acc: 0.515464\n",
      "Epoch 1953 - Train Loss: 0.235898, Train Acc: 0.543590 | Val Loss: 0.243211, Val Acc: 0.515464\n",
      "Epoch 1954 - Train Loss: 0.235878, Train Acc: 0.543590 | Val Loss: 0.243191, Val Acc: 0.515464\n",
      "Epoch 1955 - Train Loss: 0.235857, Train Acc: 0.543590 | Val Loss: 0.243170, Val Acc: 0.515464\n",
      "Epoch 1956 - Train Loss: 0.235837, Train Acc: 0.543590 | Val Loss: 0.243150, Val Acc: 0.515464\n",
      "Epoch 1957 - Train Loss: 0.235816, Train Acc: 0.543590 | Val Loss: 0.243129, Val Acc: 0.515464\n",
      "Epoch 1958 - Train Loss: 0.235796, Train Acc: 0.543590 | Val Loss: 0.243109, Val Acc: 0.515464\n",
      "Epoch 1959 - Train Loss: 0.235775, Train Acc: 0.543590 | Val Loss: 0.243088, Val Acc: 0.515464\n",
      "Epoch 1960 - Train Loss: 0.235755, Train Acc: 0.543590 | Val Loss: 0.243068, Val Acc: 0.515464\n",
      "Epoch 1961 - Train Loss: 0.235734, Train Acc: 0.543590 | Val Loss: 0.243047, Val Acc: 0.515464\n",
      "Epoch 1962 - Train Loss: 0.235714, Train Acc: 0.543590 | Val Loss: 0.243027, Val Acc: 0.515464\n",
      "Epoch 1963 - Train Loss: 0.235693, Train Acc: 0.543590 | Val Loss: 0.243006, Val Acc: 0.515464\n",
      "Epoch 1964 - Train Loss: 0.235673, Train Acc: 0.543590 | Val Loss: 0.242985, Val Acc: 0.515464\n",
      "Epoch 1965 - Train Loss: 0.235652, Train Acc: 0.543590 | Val Loss: 0.242965, Val Acc: 0.515464\n",
      "Epoch 1966 - Train Loss: 0.235632, Train Acc: 0.543590 | Val Loss: 0.242944, Val Acc: 0.515464\n",
      "Epoch 1967 - Train Loss: 0.235611, Train Acc: 0.543590 | Val Loss: 0.242924, Val Acc: 0.515464\n",
      "Epoch 1968 - Train Loss: 0.235591, Train Acc: 0.543590 | Val Loss: 0.242903, Val Acc: 0.515464\n",
      "Epoch 1969 - Train Loss: 0.235570, Train Acc: 0.543590 | Val Loss: 0.242883, Val Acc: 0.515464\n",
      "Epoch 1970 - Train Loss: 0.235550, Train Acc: 0.543590 | Val Loss: 0.242862, Val Acc: 0.515464\n",
      "Epoch 1971 - Train Loss: 0.235529, Train Acc: 0.543590 | Val Loss: 0.242842, Val Acc: 0.515464\n",
      "Epoch 1972 - Train Loss: 0.235509, Train Acc: 0.543590 | Val Loss: 0.242821, Val Acc: 0.515464\n",
      "Epoch 1973 - Train Loss: 0.235488, Train Acc: 0.543590 | Val Loss: 0.242801, Val Acc: 0.515464\n",
      "Epoch 1974 - Train Loss: 0.235468, Train Acc: 0.543590 | Val Loss: 0.242780, Val Acc: 0.515464\n",
      "Epoch 1975 - Train Loss: 0.235447, Train Acc: 0.543590 | Val Loss: 0.242760, Val Acc: 0.515464\n",
      "Epoch 1976 - Train Loss: 0.235427, Train Acc: 0.543590 | Val Loss: 0.242740, Val Acc: 0.515464\n",
      "Epoch 1977 - Train Loss: 0.235406, Train Acc: 0.543590 | Val Loss: 0.242719, Val Acc: 0.515464\n",
      "Epoch 1978 - Train Loss: 0.235386, Train Acc: 0.543590 | Val Loss: 0.242699, Val Acc: 0.515464\n",
      "Epoch 1979 - Train Loss: 0.235365, Train Acc: 0.543590 | Val Loss: 0.242679, Val Acc: 0.515464\n",
      "Epoch 1980 - Train Loss: 0.235345, Train Acc: 0.543590 | Val Loss: 0.242658, Val Acc: 0.515464\n",
      "Epoch 1981 - Train Loss: 0.235324, Train Acc: 0.543590 | Val Loss: 0.242638, Val Acc: 0.515464\n",
      "Epoch 1982 - Train Loss: 0.235304, Train Acc: 0.543590 | Val Loss: 0.242617, Val Acc: 0.515464\n",
      "Epoch 1983 - Train Loss: 0.235283, Train Acc: 0.543590 | Val Loss: 0.242597, Val Acc: 0.515464\n",
      "Epoch 1984 - Train Loss: 0.235263, Train Acc: 0.543590 | Val Loss: 0.242577, Val Acc: 0.515464\n",
      "Epoch 1985 - Train Loss: 0.235242, Train Acc: 0.543590 | Val Loss: 0.242556, Val Acc: 0.515464\n",
      "Epoch 1986 - Train Loss: 0.235222, Train Acc: 0.543590 | Val Loss: 0.242536, Val Acc: 0.515464\n",
      "Epoch 1987 - Train Loss: 0.235201, Train Acc: 0.543590 | Val Loss: 0.242515, Val Acc: 0.515464\n",
      "Epoch 1988 - Train Loss: 0.235181, Train Acc: 0.543590 | Val Loss: 0.242495, Val Acc: 0.515464\n",
      "Epoch 1989 - Train Loss: 0.235160, Train Acc: 0.543590 | Val Loss: 0.242475, Val Acc: 0.515464\n",
      "Epoch 1990 - Train Loss: 0.235140, Train Acc: 0.544872 | Val Loss: 0.242454, Val Acc: 0.515464\n",
      "Epoch 1991 - Train Loss: 0.235119, Train Acc: 0.544872 | Val Loss: 0.242434, Val Acc: 0.515464\n",
      "Epoch 1992 - Train Loss: 0.235099, Train Acc: 0.544872 | Val Loss: 0.242414, Val Acc: 0.515464\n",
      "Epoch 1993 - Train Loss: 0.235078, Train Acc: 0.544872 | Val Loss: 0.242393, Val Acc: 0.515464\n",
      "Epoch 1994 - Train Loss: 0.235058, Train Acc: 0.544872 | Val Loss: 0.242373, Val Acc: 0.515464\n",
      "Epoch 1995 - Train Loss: 0.235037, Train Acc: 0.544872 | Val Loss: 0.242352, Val Acc: 0.515464\n",
      "Epoch 1996 - Train Loss: 0.235017, Train Acc: 0.544872 | Val Loss: 0.242332, Val Acc: 0.515464\n",
      "Epoch 1997 - Train Loss: 0.234996, Train Acc: 0.544872 | Val Loss: 0.242312, Val Acc: 0.515464\n",
      "Epoch 1998 - Train Loss: 0.234976, Train Acc: 0.544872 | Val Loss: 0.242291, Val Acc: 0.515464\n",
      "Epoch 1999 - Train Loss: 0.234955, Train Acc: 0.544872 | Val Loss: 0.242271, Val Acc: 0.515464\n",
      "Epoch 2000 - Train Loss: 0.234935, Train Acc: 0.544872 | Val Loss: 0.242250, Val Acc: 0.515464\n",
      "Epoch 2001 - Train Loss: 0.234914, Train Acc: 0.544872 | Val Loss: 0.242230, Val Acc: 0.515464\n",
      "Epoch 2002 - Train Loss: 0.234894, Train Acc: 0.544872 | Val Loss: 0.242209, Val Acc: 0.515464\n",
      "Epoch 2003 - Train Loss: 0.234873, Train Acc: 0.544872 | Val Loss: 0.242189, Val Acc: 0.515464\n",
      "Epoch 2004 - Train Loss: 0.234853, Train Acc: 0.544872 | Val Loss: 0.242168, Val Acc: 0.515464\n",
      "Epoch 2005 - Train Loss: 0.234832, Train Acc: 0.544872 | Val Loss: 0.242148, Val Acc: 0.515464\n",
      "Epoch 2006 - Train Loss: 0.234812, Train Acc: 0.544872 | Val Loss: 0.242127, Val Acc: 0.515464\n",
      "Epoch 2007 - Train Loss: 0.234791, Train Acc: 0.544872 | Val Loss: 0.242107, Val Acc: 0.515464\n",
      "Epoch 2008 - Train Loss: 0.234771, Train Acc: 0.544872 | Val Loss: 0.242086, Val Acc: 0.515464\n",
      "Epoch 2009 - Train Loss: 0.234750, Train Acc: 0.544872 | Val Loss: 0.242066, Val Acc: 0.515464\n",
      "Epoch 2010 - Train Loss: 0.234730, Train Acc: 0.544872 | Val Loss: 0.242045, Val Acc: 0.515464\n",
      "Epoch 2011 - Train Loss: 0.234709, Train Acc: 0.544872 | Val Loss: 0.242025, Val Acc: 0.515464\n",
      "Epoch 2012 - Train Loss: 0.234688, Train Acc: 0.544872 | Val Loss: 0.242005, Val Acc: 0.515464\n",
      "Epoch 2013 - Train Loss: 0.234668, Train Acc: 0.544872 | Val Loss: 0.241984, Val Acc: 0.515464\n",
      "Epoch 2014 - Train Loss: 0.234647, Train Acc: 0.544872 | Val Loss: 0.241963, Val Acc: 0.515464\n",
      "Epoch 2015 - Train Loss: 0.234627, Train Acc: 0.544872 | Val Loss: 0.241943, Val Acc: 0.515464\n",
      "Epoch 2016 - Train Loss: 0.234606, Train Acc: 0.544872 | Val Loss: 0.241922, Val Acc: 0.515464\n",
      "Epoch 2017 - Train Loss: 0.234586, Train Acc: 0.544872 | Val Loss: 0.241902, Val Acc: 0.515464\n",
      "Epoch 2018 - Train Loss: 0.234565, Train Acc: 0.544872 | Val Loss: 0.241881, Val Acc: 0.515464\n",
      "Epoch 2019 - Train Loss: 0.234545, Train Acc: 0.544872 | Val Loss: 0.241861, Val Acc: 0.515464\n",
      "Epoch 2020 - Train Loss: 0.234524, Train Acc: 0.544872 | Val Loss: 0.241840, Val Acc: 0.515464\n",
      "Epoch 2021 - Train Loss: 0.234504, Train Acc: 0.544872 | Val Loss: 0.241819, Val Acc: 0.515464\n",
      "Epoch 2022 - Train Loss: 0.234483, Train Acc: 0.544872 | Val Loss: 0.241799, Val Acc: 0.515464\n",
      "Epoch 2023 - Train Loss: 0.234462, Train Acc: 0.544872 | Val Loss: 0.241778, Val Acc: 0.515464\n",
      "Epoch 2024 - Train Loss: 0.234442, Train Acc: 0.544872 | Val Loss: 0.241758, Val Acc: 0.515464\n",
      "Epoch 2025 - Train Loss: 0.234421, Train Acc: 0.544872 | Val Loss: 0.241737, Val Acc: 0.515464\n",
      "Epoch 2026 - Train Loss: 0.234401, Train Acc: 0.544872 | Val Loss: 0.241717, Val Acc: 0.515464\n",
      "Epoch 2027 - Train Loss: 0.234380, Train Acc: 0.544872 | Val Loss: 0.241696, Val Acc: 0.515464\n",
      "Epoch 2028 - Train Loss: 0.234360, Train Acc: 0.544872 | Val Loss: 0.241676, Val Acc: 0.515464\n",
      "Epoch 2029 - Train Loss: 0.234339, Train Acc: 0.544872 | Val Loss: 0.241655, Val Acc: 0.515464\n",
      "Epoch 2030 - Train Loss: 0.234319, Train Acc: 0.544872 | Val Loss: 0.241635, Val Acc: 0.515464\n",
      "Epoch 2031 - Train Loss: 0.234298, Train Acc: 0.544872 | Val Loss: 0.241614, Val Acc: 0.515464\n",
      "Epoch 2032 - Train Loss: 0.234278, Train Acc: 0.544872 | Val Loss: 0.241594, Val Acc: 0.515464\n",
      "Epoch 2033 - Train Loss: 0.234257, Train Acc: 0.544872 | Val Loss: 0.241573, Val Acc: 0.515464\n",
      "Epoch 2034 - Train Loss: 0.234236, Train Acc: 0.544872 | Val Loss: 0.241553, Val Acc: 0.515464\n",
      "Epoch 2035 - Train Loss: 0.234216, Train Acc: 0.544872 | Val Loss: 0.241532, Val Acc: 0.515464\n",
      "Epoch 2036 - Train Loss: 0.234195, Train Acc: 0.544872 | Val Loss: 0.241512, Val Acc: 0.515464\n",
      "Epoch 2037 - Train Loss: 0.234175, Train Acc: 0.544872 | Val Loss: 0.241491, Val Acc: 0.515464\n",
      "Epoch 2038 - Train Loss: 0.234154, Train Acc: 0.544872 | Val Loss: 0.241471, Val Acc: 0.515464\n",
      "Epoch 2039 - Train Loss: 0.234134, Train Acc: 0.544872 | Val Loss: 0.241450, Val Acc: 0.515464\n",
      "Epoch 2040 - Train Loss: 0.234113, Train Acc: 0.544872 | Val Loss: 0.241430, Val Acc: 0.515464\n",
      "Epoch 2041 - Train Loss: 0.234093, Train Acc: 0.544872 | Val Loss: 0.241409, Val Acc: 0.515464\n",
      "Epoch 2042 - Train Loss: 0.234072, Train Acc: 0.546154 | Val Loss: 0.241388, Val Acc: 0.515464\n",
      "Epoch 2043 - Train Loss: 0.234051, Train Acc: 0.546154 | Val Loss: 0.241368, Val Acc: 0.515464\n",
      "Epoch 2044 - Train Loss: 0.234031, Train Acc: 0.546154 | Val Loss: 0.241347, Val Acc: 0.515464\n",
      "Epoch 2045 - Train Loss: 0.234010, Train Acc: 0.546154 | Val Loss: 0.241327, Val Acc: 0.515464\n",
      "Epoch 2046 - Train Loss: 0.233990, Train Acc: 0.546154 | Val Loss: 0.241306, Val Acc: 0.515464\n",
      "Epoch 2047 - Train Loss: 0.233969, Train Acc: 0.546154 | Val Loss: 0.241286, Val Acc: 0.515464\n",
      "Epoch 2048 - Train Loss: 0.233949, Train Acc: 0.546154 | Val Loss: 0.241265, Val Acc: 0.515464\n",
      "Epoch 2049 - Train Loss: 0.233928, Train Acc: 0.546154 | Val Loss: 0.241245, Val Acc: 0.515464\n",
      "Epoch 2050 - Train Loss: 0.233907, Train Acc: 0.546154 | Val Loss: 0.241224, Val Acc: 0.515464\n",
      "Epoch 2051 - Train Loss: 0.233887, Train Acc: 0.546154 | Val Loss: 0.241204, Val Acc: 0.515464\n",
      "Epoch 2052 - Train Loss: 0.233866, Train Acc: 0.546154 | Val Loss: 0.241183, Val Acc: 0.515464\n",
      "Epoch 2053 - Train Loss: 0.233846, Train Acc: 0.546154 | Val Loss: 0.241163, Val Acc: 0.515464\n",
      "Epoch 2054 - Train Loss: 0.233825, Train Acc: 0.546154 | Val Loss: 0.241142, Val Acc: 0.515464\n",
      "Epoch 2055 - Train Loss: 0.233805, Train Acc: 0.546154 | Val Loss: 0.241122, Val Acc: 0.515464\n",
      "Epoch 2056 - Train Loss: 0.233784, Train Acc: 0.546154 | Val Loss: 0.241101, Val Acc: 0.515464\n",
      "Epoch 2057 - Train Loss: 0.233763, Train Acc: 0.546154 | Val Loss: 0.241081, Val Acc: 0.515464\n",
      "Epoch 2058 - Train Loss: 0.233743, Train Acc: 0.547436 | Val Loss: 0.241060, Val Acc: 0.515464\n",
      "Epoch 2059 - Train Loss: 0.233722, Train Acc: 0.547436 | Val Loss: 0.241040, Val Acc: 0.515464\n",
      "Epoch 2060 - Train Loss: 0.233702, Train Acc: 0.547436 | Val Loss: 0.241019, Val Acc: 0.515464\n",
      "Epoch 2061 - Train Loss: 0.233681, Train Acc: 0.547436 | Val Loss: 0.240998, Val Acc: 0.515464\n",
      "Epoch 2062 - Train Loss: 0.233660, Train Acc: 0.547436 | Val Loss: 0.240978, Val Acc: 0.515464\n",
      "Epoch 2063 - Train Loss: 0.233640, Train Acc: 0.547436 | Val Loss: 0.240957, Val Acc: 0.515464\n",
      "Epoch 2064 - Train Loss: 0.233619, Train Acc: 0.547436 | Val Loss: 0.240937, Val Acc: 0.515464\n",
      "Epoch 2065 - Train Loss: 0.233599, Train Acc: 0.547436 | Val Loss: 0.240916, Val Acc: 0.515464\n",
      "Epoch 2066 - Train Loss: 0.233578, Train Acc: 0.547436 | Val Loss: 0.240896, Val Acc: 0.515464\n",
      "Epoch 2067 - Train Loss: 0.233558, Train Acc: 0.548718 | Val Loss: 0.240875, Val Acc: 0.515464\n",
      "Epoch 2068 - Train Loss: 0.233537, Train Acc: 0.548718 | Val Loss: 0.240855, Val Acc: 0.515464\n",
      "Epoch 2069 - Train Loss: 0.233517, Train Acc: 0.550000 | Val Loss: 0.240834, Val Acc: 0.515464\n",
      "Epoch 2070 - Train Loss: 0.233496, Train Acc: 0.550000 | Val Loss: 0.240814, Val Acc: 0.515464\n",
      "Epoch 2071 - Train Loss: 0.233475, Train Acc: 0.550000 | Val Loss: 0.240793, Val Acc: 0.515464\n",
      "Epoch 2072 - Train Loss: 0.233455, Train Acc: 0.550000 | Val Loss: 0.240773, Val Acc: 0.515464\n",
      "Epoch 2073 - Train Loss: 0.233434, Train Acc: 0.550000 | Val Loss: 0.240752, Val Acc: 0.515464\n",
      "Epoch 2074 - Train Loss: 0.233414, Train Acc: 0.550000 | Val Loss: 0.240732, Val Acc: 0.515464\n",
      "Epoch 2075 - Train Loss: 0.233393, Train Acc: 0.550000 | Val Loss: 0.240711, Val Acc: 0.515464\n",
      "Epoch 2076 - Train Loss: 0.233372, Train Acc: 0.550000 | Val Loss: 0.240691, Val Acc: 0.515464\n",
      "Epoch 2077 - Train Loss: 0.233352, Train Acc: 0.550000 | Val Loss: 0.240670, Val Acc: 0.515464\n",
      "Epoch 2078 - Train Loss: 0.233331, Train Acc: 0.550000 | Val Loss: 0.240649, Val Acc: 0.515464\n",
      "Epoch 2079 - Train Loss: 0.233311, Train Acc: 0.550000 | Val Loss: 0.240629, Val Acc: 0.515464\n",
      "Epoch 2080 - Train Loss: 0.233290, Train Acc: 0.550000 | Val Loss: 0.240608, Val Acc: 0.525773\n",
      "Epoch 2081 - Train Loss: 0.233269, Train Acc: 0.550000 | Val Loss: 0.240587, Val Acc: 0.525773\n",
      "Epoch 2082 - Train Loss: 0.233249, Train Acc: 0.550000 | Val Loss: 0.240567, Val Acc: 0.525773\n",
      "Epoch 2083 - Train Loss: 0.233228, Train Acc: 0.550000 | Val Loss: 0.240546, Val Acc: 0.525773\n",
      "Epoch 2084 - Train Loss: 0.233207, Train Acc: 0.548718 | Val Loss: 0.240525, Val Acc: 0.525773\n",
      "Epoch 2085 - Train Loss: 0.233187, Train Acc: 0.548718 | Val Loss: 0.240505, Val Acc: 0.525773\n",
      "Epoch 2086 - Train Loss: 0.233166, Train Acc: 0.548718 | Val Loss: 0.240484, Val Acc: 0.525773\n",
      "Epoch 2087 - Train Loss: 0.233146, Train Acc: 0.548718 | Val Loss: 0.240463, Val Acc: 0.525773\n",
      "Epoch 2088 - Train Loss: 0.233125, Train Acc: 0.548718 | Val Loss: 0.240443, Val Acc: 0.525773\n",
      "Epoch 2089 - Train Loss: 0.233104, Train Acc: 0.548718 | Val Loss: 0.240422, Val Acc: 0.525773\n",
      "Epoch 2090 - Train Loss: 0.233084, Train Acc: 0.548718 | Val Loss: 0.240401, Val Acc: 0.525773\n",
      "Epoch 2091 - Train Loss: 0.233063, Train Acc: 0.548718 | Val Loss: 0.240381, Val Acc: 0.525773\n",
      "Epoch 2092 - Train Loss: 0.233043, Train Acc: 0.548718 | Val Loss: 0.240360, Val Acc: 0.525773\n",
      "Epoch 2093 - Train Loss: 0.233022, Train Acc: 0.548718 | Val Loss: 0.240340, Val Acc: 0.525773\n",
      "Epoch 2094 - Train Loss: 0.233001, Train Acc: 0.548718 | Val Loss: 0.240319, Val Acc: 0.525773\n",
      "Epoch 2095 - Train Loss: 0.232981, Train Acc: 0.548718 | Val Loss: 0.240298, Val Acc: 0.525773\n",
      "Epoch 2096 - Train Loss: 0.232960, Train Acc: 0.548718 | Val Loss: 0.240278, Val Acc: 0.525773\n",
      "Epoch 2097 - Train Loss: 0.232940, Train Acc: 0.548718 | Val Loss: 0.240257, Val Acc: 0.525773\n",
      "Epoch 2098 - Train Loss: 0.232919, Train Acc: 0.548718 | Val Loss: 0.240237, Val Acc: 0.525773\n",
      "Epoch 2099 - Train Loss: 0.232899, Train Acc: 0.548718 | Val Loss: 0.240216, Val Acc: 0.525773\n",
      "Epoch 2100 - Train Loss: 0.232878, Train Acc: 0.548718 | Val Loss: 0.240196, Val Acc: 0.525773\n",
      "Epoch 2101 - Train Loss: 0.232857, Train Acc: 0.548718 | Val Loss: 0.240175, Val Acc: 0.525773\n",
      "Epoch 2102 - Train Loss: 0.232837, Train Acc: 0.548718 | Val Loss: 0.240154, Val Acc: 0.525773\n",
      "Epoch 2103 - Train Loss: 0.232816, Train Acc: 0.548718 | Val Loss: 0.240134, Val Acc: 0.525773\n",
      "Epoch 2104 - Train Loss: 0.232796, Train Acc: 0.548718 | Val Loss: 0.240113, Val Acc: 0.525773\n",
      "Epoch 2105 - Train Loss: 0.232775, Train Acc: 0.548718 | Val Loss: 0.240092, Val Acc: 0.525773\n",
      "Epoch 2106 - Train Loss: 0.232754, Train Acc: 0.548718 | Val Loss: 0.240072, Val Acc: 0.525773\n",
      "Epoch 2107 - Train Loss: 0.232734, Train Acc: 0.548718 | Val Loss: 0.240052, Val Acc: 0.525773\n",
      "Epoch 2108 - Train Loss: 0.232713, Train Acc: 0.548718 | Val Loss: 0.240031, Val Acc: 0.525773\n",
      "Epoch 2109 - Train Loss: 0.232692, Train Acc: 0.548718 | Val Loss: 0.240011, Val Acc: 0.525773\n",
      "Epoch 2110 - Train Loss: 0.232672, Train Acc: 0.548718 | Val Loss: 0.239990, Val Acc: 0.525773\n",
      "Epoch 2111 - Train Loss: 0.232651, Train Acc: 0.548718 | Val Loss: 0.239970, Val Acc: 0.525773\n",
      "Epoch 2112 - Train Loss: 0.232631, Train Acc: 0.548718 | Val Loss: 0.239949, Val Acc: 0.525773\n",
      "Epoch 2113 - Train Loss: 0.232610, Train Acc: 0.548718 | Val Loss: 0.239929, Val Acc: 0.525773\n",
      "Epoch 2114 - Train Loss: 0.232589, Train Acc: 0.550000 | Val Loss: 0.239908, Val Acc: 0.525773\n",
      "Epoch 2115 - Train Loss: 0.232569, Train Acc: 0.550000 | Val Loss: 0.239888, Val Acc: 0.525773\n",
      "Epoch 2116 - Train Loss: 0.232548, Train Acc: 0.550000 | Val Loss: 0.239868, Val Acc: 0.525773\n",
      "Epoch 2117 - Train Loss: 0.232527, Train Acc: 0.550000 | Val Loss: 0.239847, Val Acc: 0.525773\n",
      "Epoch 2118 - Train Loss: 0.232507, Train Acc: 0.550000 | Val Loss: 0.239827, Val Acc: 0.525773\n",
      "Epoch 2119 - Train Loss: 0.232486, Train Acc: 0.550000 | Val Loss: 0.239806, Val Acc: 0.525773\n",
      "Epoch 2120 - Train Loss: 0.232466, Train Acc: 0.550000 | Val Loss: 0.239786, Val Acc: 0.525773\n",
      "Epoch 2121 - Train Loss: 0.232445, Train Acc: 0.550000 | Val Loss: 0.239766, Val Acc: 0.525773\n",
      "Epoch 2122 - Train Loss: 0.232424, Train Acc: 0.550000 | Val Loss: 0.239745, Val Acc: 0.525773\n",
      "Epoch 2123 - Train Loss: 0.232404, Train Acc: 0.550000 | Val Loss: 0.239725, Val Acc: 0.525773\n",
      "Epoch 2124 - Train Loss: 0.232383, Train Acc: 0.550000 | Val Loss: 0.239705, Val Acc: 0.525773\n",
      "Epoch 2125 - Train Loss: 0.232363, Train Acc: 0.550000 | Val Loss: 0.239684, Val Acc: 0.525773\n",
      "Epoch 2126 - Train Loss: 0.232342, Train Acc: 0.550000 | Val Loss: 0.239664, Val Acc: 0.525773\n",
      "Epoch 2127 - Train Loss: 0.232321, Train Acc: 0.550000 | Val Loss: 0.239644, Val Acc: 0.525773\n",
      "Epoch 2128 - Train Loss: 0.232301, Train Acc: 0.551282 | Val Loss: 0.239623, Val Acc: 0.525773\n",
      "Epoch 2129 - Train Loss: 0.232280, Train Acc: 0.551282 | Val Loss: 0.239603, Val Acc: 0.525773\n",
      "Epoch 2130 - Train Loss: 0.232260, Train Acc: 0.551282 | Val Loss: 0.239583, Val Acc: 0.525773\n",
      "Epoch 2131 - Train Loss: 0.232239, Train Acc: 0.551282 | Val Loss: 0.239563, Val Acc: 0.525773\n",
      "Epoch 2132 - Train Loss: 0.232218, Train Acc: 0.551282 | Val Loss: 0.239542, Val Acc: 0.525773\n",
      "Epoch 2133 - Train Loss: 0.232198, Train Acc: 0.551282 | Val Loss: 0.239522, Val Acc: 0.525773\n",
      "Epoch 2134 - Train Loss: 0.232177, Train Acc: 0.551282 | Val Loss: 0.239502, Val Acc: 0.525773\n",
      "Epoch 2135 - Train Loss: 0.232157, Train Acc: 0.551282 | Val Loss: 0.239481, Val Acc: 0.525773\n",
      "Epoch 2136 - Train Loss: 0.232136, Train Acc: 0.551282 | Val Loss: 0.239461, Val Acc: 0.525773\n",
      "Epoch 2137 - Train Loss: 0.232115, Train Acc: 0.551282 | Val Loss: 0.239441, Val Acc: 0.525773\n",
      "Epoch 2138 - Train Loss: 0.232095, Train Acc: 0.551282 | Val Loss: 0.239421, Val Acc: 0.525773\n",
      "Epoch 2139 - Train Loss: 0.232074, Train Acc: 0.551282 | Val Loss: 0.239400, Val Acc: 0.525773\n",
      "Epoch 2140 - Train Loss: 0.232054, Train Acc: 0.551282 | Val Loss: 0.239380, Val Acc: 0.525773\n",
      "Epoch 2141 - Train Loss: 0.232033, Train Acc: 0.551282 | Val Loss: 0.239360, Val Acc: 0.525773\n",
      "Epoch 2142 - Train Loss: 0.232012, Train Acc: 0.551282 | Val Loss: 0.239340, Val Acc: 0.525773\n",
      "Epoch 2143 - Train Loss: 0.231992, Train Acc: 0.551282 | Val Loss: 0.239319, Val Acc: 0.525773\n",
      "Epoch 2144 - Train Loss: 0.231971, Train Acc: 0.551282 | Val Loss: 0.239299, Val Acc: 0.525773\n",
      "Epoch 2145 - Train Loss: 0.231951, Train Acc: 0.551282 | Val Loss: 0.239279, Val Acc: 0.525773\n",
      "Epoch 2146 - Train Loss: 0.231930, Train Acc: 0.551282 | Val Loss: 0.239259, Val Acc: 0.525773\n",
      "Epoch 2147 - Train Loss: 0.231910, Train Acc: 0.551282 | Val Loss: 0.239238, Val Acc: 0.525773\n",
      "Epoch 2148 - Train Loss: 0.231889, Train Acc: 0.551282 | Val Loss: 0.239218, Val Acc: 0.525773\n",
      "Epoch 2149 - Train Loss: 0.231868, Train Acc: 0.552564 | Val Loss: 0.239198, Val Acc: 0.525773\n",
      "Epoch 2150 - Train Loss: 0.231848, Train Acc: 0.552564 | Val Loss: 0.239178, Val Acc: 0.525773\n",
      "Epoch 2151 - Train Loss: 0.231827, Train Acc: 0.552564 | Val Loss: 0.239157, Val Acc: 0.525773\n",
      "Epoch 2152 - Train Loss: 0.231807, Train Acc: 0.552564 | Val Loss: 0.239137, Val Acc: 0.525773\n",
      "Epoch 2153 - Train Loss: 0.231786, Train Acc: 0.553846 | Val Loss: 0.239117, Val Acc: 0.525773\n",
      "Epoch 2154 - Train Loss: 0.231765, Train Acc: 0.553846 | Val Loss: 0.239097, Val Acc: 0.525773\n",
      "Epoch 2155 - Train Loss: 0.231745, Train Acc: 0.553846 | Val Loss: 0.239076, Val Acc: 0.525773\n",
      "Epoch 2156 - Train Loss: 0.231724, Train Acc: 0.553846 | Val Loss: 0.239056, Val Acc: 0.525773\n",
      "Epoch 2157 - Train Loss: 0.231703, Train Acc: 0.555128 | Val Loss: 0.239036, Val Acc: 0.525773\n",
      "Epoch 2158 - Train Loss: 0.231683, Train Acc: 0.555128 | Val Loss: 0.239015, Val Acc: 0.525773\n",
      "Epoch 2159 - Train Loss: 0.231662, Train Acc: 0.555128 | Val Loss: 0.238995, Val Acc: 0.525773\n",
      "Epoch 2160 - Train Loss: 0.231642, Train Acc: 0.555128 | Val Loss: 0.238975, Val Acc: 0.525773\n",
      "Epoch 2161 - Train Loss: 0.231621, Train Acc: 0.555128 | Val Loss: 0.238955, Val Acc: 0.525773\n",
      "Epoch 2162 - Train Loss: 0.231600, Train Acc: 0.555128 | Val Loss: 0.238934, Val Acc: 0.525773\n",
      "Epoch 2163 - Train Loss: 0.231580, Train Acc: 0.555128 | Val Loss: 0.238914, Val Acc: 0.525773\n",
      "Epoch 2164 - Train Loss: 0.231559, Train Acc: 0.555128 | Val Loss: 0.238894, Val Acc: 0.525773\n",
      "Epoch 2165 - Train Loss: 0.231538, Train Acc: 0.555128 | Val Loss: 0.238873, Val Acc: 0.525773\n",
      "Epoch 2166 - Train Loss: 0.231518, Train Acc: 0.555128 | Val Loss: 0.238853, Val Acc: 0.525773\n",
      "Epoch 2167 - Train Loss: 0.231497, Train Acc: 0.556410 | Val Loss: 0.238833, Val Acc: 0.525773\n",
      "Epoch 2168 - Train Loss: 0.231476, Train Acc: 0.556410 | Val Loss: 0.238813, Val Acc: 0.525773\n",
      "Epoch 2169 - Train Loss: 0.231456, Train Acc: 0.556410 | Val Loss: 0.238792, Val Acc: 0.525773\n",
      "Epoch 2170 - Train Loss: 0.231435, Train Acc: 0.556410 | Val Loss: 0.238772, Val Acc: 0.525773\n",
      "Epoch 2171 - Train Loss: 0.231415, Train Acc: 0.556410 | Val Loss: 0.238752, Val Acc: 0.525773\n",
      "Epoch 2172 - Train Loss: 0.231394, Train Acc: 0.556410 | Val Loss: 0.238732, Val Acc: 0.525773\n",
      "Epoch 2173 - Train Loss: 0.231373, Train Acc: 0.556410 | Val Loss: 0.238711, Val Acc: 0.525773\n",
      "Epoch 2174 - Train Loss: 0.231353, Train Acc: 0.556410 | Val Loss: 0.238691, Val Acc: 0.525773\n",
      "Epoch 2175 - Train Loss: 0.231332, Train Acc: 0.556410 | Val Loss: 0.238671, Val Acc: 0.525773\n",
      "Epoch 2176 - Train Loss: 0.231312, Train Acc: 0.556410 | Val Loss: 0.238651, Val Acc: 0.525773\n",
      "Epoch 2177 - Train Loss: 0.231291, Train Acc: 0.556410 | Val Loss: 0.238630, Val Acc: 0.525773\n",
      "Epoch 2178 - Train Loss: 0.231270, Train Acc: 0.556410 | Val Loss: 0.238610, Val Acc: 0.525773\n",
      "Epoch 2179 - Train Loss: 0.231250, Train Acc: 0.557692 | Val Loss: 0.238590, Val Acc: 0.525773\n",
      "Epoch 2180 - Train Loss: 0.231229, Train Acc: 0.557692 | Val Loss: 0.238570, Val Acc: 0.525773\n",
      "Epoch 2181 - Train Loss: 0.231209, Train Acc: 0.557692 | Val Loss: 0.238550, Val Acc: 0.525773\n",
      "Epoch 2182 - Train Loss: 0.231188, Train Acc: 0.557692 | Val Loss: 0.238530, Val Acc: 0.525773\n",
      "Epoch 2183 - Train Loss: 0.231167, Train Acc: 0.557692 | Val Loss: 0.238509, Val Acc: 0.525773\n",
      "Epoch 2184 - Train Loss: 0.231147, Train Acc: 0.557692 | Val Loss: 0.238489, Val Acc: 0.525773\n",
      "Epoch 2185 - Train Loss: 0.231126, Train Acc: 0.557692 | Val Loss: 0.238469, Val Acc: 0.525773\n",
      "Epoch 2186 - Train Loss: 0.231106, Train Acc: 0.557692 | Val Loss: 0.238449, Val Acc: 0.525773\n",
      "Epoch 2187 - Train Loss: 0.231085, Train Acc: 0.557692 | Val Loss: 0.238429, Val Acc: 0.525773\n",
      "Epoch 2188 - Train Loss: 0.231064, Train Acc: 0.557692 | Val Loss: 0.238408, Val Acc: 0.525773\n",
      "Epoch 2189 - Train Loss: 0.231044, Train Acc: 0.557692 | Val Loss: 0.238388, Val Acc: 0.525773\n",
      "Epoch 2190 - Train Loss: 0.231023, Train Acc: 0.557692 | Val Loss: 0.238368, Val Acc: 0.536082\n",
      "Epoch 2191 - Train Loss: 0.231003, Train Acc: 0.557692 | Val Loss: 0.238348, Val Acc: 0.536082\n",
      "Epoch 2192 - Train Loss: 0.230982, Train Acc: 0.557692 | Val Loss: 0.238328, Val Acc: 0.536082\n",
      "Epoch 2193 - Train Loss: 0.230962, Train Acc: 0.557692 | Val Loss: 0.238307, Val Acc: 0.536082\n",
      "Epoch 2194 - Train Loss: 0.230941, Train Acc: 0.557692 | Val Loss: 0.238287, Val Acc: 0.536082\n",
      "Epoch 2195 - Train Loss: 0.230920, Train Acc: 0.557692 | Val Loss: 0.238267, Val Acc: 0.536082\n",
      "Epoch 2196 - Train Loss: 0.230900, Train Acc: 0.558974 | Val Loss: 0.238247, Val Acc: 0.536082\n",
      "Epoch 2197 - Train Loss: 0.230879, Train Acc: 0.558974 | Val Loss: 0.238227, Val Acc: 0.536082\n",
      "Epoch 2198 - Train Loss: 0.230859, Train Acc: 0.558974 | Val Loss: 0.238206, Val Acc: 0.536082\n",
      "Epoch 2199 - Train Loss: 0.230838, Train Acc: 0.558974 | Val Loss: 0.238186, Val Acc: 0.536082\n",
      "Epoch 2200 - Train Loss: 0.230817, Train Acc: 0.558974 | Val Loss: 0.238166, Val Acc: 0.536082\n",
      "Epoch 2201 - Train Loss: 0.230797, Train Acc: 0.558974 | Val Loss: 0.238146, Val Acc: 0.536082\n",
      "Epoch 2202 - Train Loss: 0.230776, Train Acc: 0.558974 | Val Loss: 0.238125, Val Acc: 0.536082\n",
      "Epoch 2203 - Train Loss: 0.230756, Train Acc: 0.558974 | Val Loss: 0.238105, Val Acc: 0.536082\n",
      "Epoch 2204 - Train Loss: 0.230735, Train Acc: 0.558974 | Val Loss: 0.238085, Val Acc: 0.536082\n",
      "Epoch 2205 - Train Loss: 0.230714, Train Acc: 0.558974 | Val Loss: 0.238064, Val Acc: 0.536082\n",
      "Epoch 2206 - Train Loss: 0.230694, Train Acc: 0.558974 | Val Loss: 0.238044, Val Acc: 0.536082\n",
      "Epoch 2207 - Train Loss: 0.230673, Train Acc: 0.558974 | Val Loss: 0.238024, Val Acc: 0.536082\n",
      "Epoch 2208 - Train Loss: 0.230652, Train Acc: 0.558974 | Val Loss: 0.238004, Val Acc: 0.536082\n",
      "Epoch 2209 - Train Loss: 0.230632, Train Acc: 0.558974 | Val Loss: 0.237983, Val Acc: 0.536082\n",
      "Epoch 2210 - Train Loss: 0.230611, Train Acc: 0.558974 | Val Loss: 0.237963, Val Acc: 0.536082\n",
      "Epoch 2211 - Train Loss: 0.230591, Train Acc: 0.558974 | Val Loss: 0.237943, Val Acc: 0.536082\n",
      "Epoch 2212 - Train Loss: 0.230570, Train Acc: 0.560256 | Val Loss: 0.237922, Val Acc: 0.536082\n",
      "Epoch 2213 - Train Loss: 0.230549, Train Acc: 0.560256 | Val Loss: 0.237902, Val Acc: 0.536082\n",
      "Epoch 2214 - Train Loss: 0.230529, Train Acc: 0.560256 | Val Loss: 0.237882, Val Acc: 0.536082\n",
      "Epoch 2215 - Train Loss: 0.230508, Train Acc: 0.560256 | Val Loss: 0.237861, Val Acc: 0.536082\n",
      "Epoch 2216 - Train Loss: 0.230488, Train Acc: 0.560256 | Val Loss: 0.237841, Val Acc: 0.536082\n",
      "Epoch 2217 - Train Loss: 0.230467, Train Acc: 0.560256 | Val Loss: 0.237821, Val Acc: 0.536082\n",
      "Epoch 2218 - Train Loss: 0.230446, Train Acc: 0.561538 | Val Loss: 0.237800, Val Acc: 0.536082\n",
      "Epoch 2219 - Train Loss: 0.230426, Train Acc: 0.561538 | Val Loss: 0.237780, Val Acc: 0.536082\n",
      "Epoch 2220 - Train Loss: 0.230405, Train Acc: 0.561538 | Val Loss: 0.237760, Val Acc: 0.536082\n",
      "Epoch 2221 - Train Loss: 0.230384, Train Acc: 0.561538 | Val Loss: 0.237739, Val Acc: 0.536082\n",
      "Epoch 2222 - Train Loss: 0.230364, Train Acc: 0.561538 | Val Loss: 0.237719, Val Acc: 0.536082\n",
      "Epoch 2223 - Train Loss: 0.230343, Train Acc: 0.561538 | Val Loss: 0.237699, Val Acc: 0.536082\n",
      "Epoch 2224 - Train Loss: 0.230323, Train Acc: 0.561538 | Val Loss: 0.237678, Val Acc: 0.536082\n",
      "Epoch 2225 - Train Loss: 0.230302, Train Acc: 0.561538 | Val Loss: 0.237658, Val Acc: 0.536082\n",
      "Epoch 2226 - Train Loss: 0.230281, Train Acc: 0.561538 | Val Loss: 0.237638, Val Acc: 0.536082\n",
      "Epoch 2227 - Train Loss: 0.230261, Train Acc: 0.561538 | Val Loss: 0.237617, Val Acc: 0.536082\n",
      "Epoch 2228 - Train Loss: 0.230240, Train Acc: 0.561538 | Val Loss: 0.237597, Val Acc: 0.536082\n",
      "Epoch 2229 - Train Loss: 0.230220, Train Acc: 0.561538 | Val Loss: 0.237577, Val Acc: 0.536082\n",
      "Epoch 2230 - Train Loss: 0.230199, Train Acc: 0.561538 | Val Loss: 0.237557, Val Acc: 0.536082\n",
      "Epoch 2231 - Train Loss: 0.230178, Train Acc: 0.561538 | Val Loss: 0.237536, Val Acc: 0.536082\n",
      "Epoch 2232 - Train Loss: 0.230158, Train Acc: 0.561538 | Val Loss: 0.237516, Val Acc: 0.536082\n",
      "Epoch 2233 - Train Loss: 0.230137, Train Acc: 0.561538 | Val Loss: 0.237496, Val Acc: 0.536082\n",
      "Epoch 2234 - Train Loss: 0.230117, Train Acc: 0.562821 | Val Loss: 0.237476, Val Acc: 0.536082\n",
      "Epoch 2235 - Train Loss: 0.230096, Train Acc: 0.562821 | Val Loss: 0.237455, Val Acc: 0.536082\n",
      "Epoch 2236 - Train Loss: 0.230075, Train Acc: 0.562821 | Val Loss: 0.237435, Val Acc: 0.536082\n",
      "Epoch 2237 - Train Loss: 0.230055, Train Acc: 0.562821 | Val Loss: 0.237415, Val Acc: 0.536082\n",
      "Epoch 2238 - Train Loss: 0.230034, Train Acc: 0.562821 | Val Loss: 0.237395, Val Acc: 0.536082\n",
      "Epoch 2239 - Train Loss: 0.230014, Train Acc: 0.562821 | Val Loss: 0.237375, Val Acc: 0.536082\n",
      "Epoch 2240 - Train Loss: 0.229993, Train Acc: 0.562821 | Val Loss: 0.237354, Val Acc: 0.536082\n",
      "Epoch 2241 - Train Loss: 0.229973, Train Acc: 0.562821 | Val Loss: 0.237334, Val Acc: 0.536082\n",
      "Epoch 2242 - Train Loss: 0.229952, Train Acc: 0.562821 | Val Loss: 0.237314, Val Acc: 0.536082\n",
      "Epoch 2243 - Train Loss: 0.229931, Train Acc: 0.564103 | Val Loss: 0.237294, Val Acc: 0.536082\n",
      "Epoch 2244 - Train Loss: 0.229911, Train Acc: 0.564103 | Val Loss: 0.237274, Val Acc: 0.536082\n",
      "Epoch 2245 - Train Loss: 0.229890, Train Acc: 0.564103 | Val Loss: 0.237253, Val Acc: 0.536082\n",
      "Epoch 2246 - Train Loss: 0.229870, Train Acc: 0.564103 | Val Loss: 0.237233, Val Acc: 0.536082\n",
      "Epoch 2247 - Train Loss: 0.229849, Train Acc: 0.564103 | Val Loss: 0.237213, Val Acc: 0.536082\n",
      "Epoch 2248 - Train Loss: 0.229829, Train Acc: 0.564103 | Val Loss: 0.237193, Val Acc: 0.536082\n",
      "Epoch 2249 - Train Loss: 0.229808, Train Acc: 0.564103 | Val Loss: 0.237173, Val Acc: 0.536082\n",
      "Epoch 2250 - Train Loss: 0.229788, Train Acc: 0.564103 | Val Loss: 0.237153, Val Acc: 0.536082\n",
      "Epoch 2251 - Train Loss: 0.229767, Train Acc: 0.564103 | Val Loss: 0.237132, Val Acc: 0.536082\n",
      "Epoch 2252 - Train Loss: 0.229746, Train Acc: 0.564103 | Val Loss: 0.237112, Val Acc: 0.536082\n",
      "Epoch 2253 - Train Loss: 0.229726, Train Acc: 0.564103 | Val Loss: 0.237092, Val Acc: 0.536082\n",
      "Epoch 2254 - Train Loss: 0.229705, Train Acc: 0.564103 | Val Loss: 0.237072, Val Acc: 0.536082\n",
      "Epoch 2255 - Train Loss: 0.229685, Train Acc: 0.564103 | Val Loss: 0.237052, Val Acc: 0.536082\n",
      "Epoch 2256 - Train Loss: 0.229664, Train Acc: 0.564103 | Val Loss: 0.237032, Val Acc: 0.536082\n",
      "Epoch 2257 - Train Loss: 0.229644, Train Acc: 0.564103 | Val Loss: 0.237011, Val Acc: 0.536082\n",
      "Epoch 2258 - Train Loss: 0.229623, Train Acc: 0.564103 | Val Loss: 0.236991, Val Acc: 0.536082\n",
      "Epoch 2259 - Train Loss: 0.229603, Train Acc: 0.564103 | Val Loss: 0.236971, Val Acc: 0.536082\n",
      "Epoch 2260 - Train Loss: 0.229582, Train Acc: 0.564103 | Val Loss: 0.236951, Val Acc: 0.536082\n",
      "Epoch 2261 - Train Loss: 0.229562, Train Acc: 0.564103 | Val Loss: 0.236931, Val Acc: 0.536082\n",
      "Epoch 2262 - Train Loss: 0.229541, Train Acc: 0.564103 | Val Loss: 0.236911, Val Acc: 0.536082\n",
      "Epoch 2263 - Train Loss: 0.229520, Train Acc: 0.564103 | Val Loss: 0.236890, Val Acc: 0.536082\n",
      "Epoch 2264 - Train Loss: 0.229500, Train Acc: 0.564103 | Val Loss: 0.236870, Val Acc: 0.536082\n",
      "Epoch 2265 - Train Loss: 0.229479, Train Acc: 0.564103 | Val Loss: 0.236850, Val Acc: 0.536082\n",
      "Epoch 2266 - Train Loss: 0.229459, Train Acc: 0.564103 | Val Loss: 0.236830, Val Acc: 0.536082\n",
      "Epoch 2267 - Train Loss: 0.229438, Train Acc: 0.564103 | Val Loss: 0.236810, Val Acc: 0.536082\n",
      "Epoch 2268 - Train Loss: 0.229418, Train Acc: 0.564103 | Val Loss: 0.236789, Val Acc: 0.536082\n",
      "Epoch 2269 - Train Loss: 0.229397, Train Acc: 0.564103 | Val Loss: 0.236769, Val Acc: 0.536082\n",
      "Epoch 2270 - Train Loss: 0.229377, Train Acc: 0.564103 | Val Loss: 0.236749, Val Acc: 0.536082\n",
      "Epoch 2271 - Train Loss: 0.229356, Train Acc: 0.564103 | Val Loss: 0.236729, Val Acc: 0.536082\n",
      "Epoch 2272 - Train Loss: 0.229335, Train Acc: 0.564103 | Val Loss: 0.236709, Val Acc: 0.536082\n",
      "Epoch 2273 - Train Loss: 0.229315, Train Acc: 0.564103 | Val Loss: 0.236689, Val Acc: 0.536082\n",
      "Epoch 2274 - Train Loss: 0.229294, Train Acc: 0.564103 | Val Loss: 0.236668, Val Acc: 0.536082\n",
      "Epoch 2275 - Train Loss: 0.229274, Train Acc: 0.565385 | Val Loss: 0.236648, Val Acc: 0.536082\n",
      "Epoch 2276 - Train Loss: 0.229253, Train Acc: 0.565385 | Val Loss: 0.236628, Val Acc: 0.536082\n",
      "Epoch 2277 - Train Loss: 0.229233, Train Acc: 0.565385 | Val Loss: 0.236608, Val Acc: 0.536082\n",
      "Epoch 2278 - Train Loss: 0.229212, Train Acc: 0.565385 | Val Loss: 0.236588, Val Acc: 0.536082\n",
      "Epoch 2279 - Train Loss: 0.229192, Train Acc: 0.566667 | Val Loss: 0.236568, Val Acc: 0.536082\n",
      "Epoch 2280 - Train Loss: 0.229171, Train Acc: 0.566667 | Val Loss: 0.236547, Val Acc: 0.536082\n",
      "Epoch 2281 - Train Loss: 0.229151, Train Acc: 0.566667 | Val Loss: 0.236527, Val Acc: 0.536082\n",
      "Epoch 2282 - Train Loss: 0.229130, Train Acc: 0.566667 | Val Loss: 0.236507, Val Acc: 0.536082\n",
      "Epoch 2283 - Train Loss: 0.229110, Train Acc: 0.566667 | Val Loss: 0.236487, Val Acc: 0.536082\n",
      "Epoch 2284 - Train Loss: 0.229089, Train Acc: 0.566667 | Val Loss: 0.236467, Val Acc: 0.536082\n",
      "Epoch 2285 - Train Loss: 0.229068, Train Acc: 0.566667 | Val Loss: 0.236447, Val Acc: 0.536082\n",
      "Epoch 2286 - Train Loss: 0.229048, Train Acc: 0.566667 | Val Loss: 0.236427, Val Acc: 0.536082\n",
      "Epoch 2287 - Train Loss: 0.229027, Train Acc: 0.566667 | Val Loss: 0.236406, Val Acc: 0.536082\n",
      "Epoch 2288 - Train Loss: 0.229007, Train Acc: 0.566667 | Val Loss: 0.236386, Val Acc: 0.536082\n",
      "Epoch 2289 - Train Loss: 0.228986, Train Acc: 0.566667 | Val Loss: 0.236366, Val Acc: 0.536082\n",
      "Epoch 2290 - Train Loss: 0.228966, Train Acc: 0.566667 | Val Loss: 0.236346, Val Acc: 0.536082\n",
      "Epoch 2291 - Train Loss: 0.228945, Train Acc: 0.566667 | Val Loss: 0.236326, Val Acc: 0.536082\n",
      "Epoch 2292 - Train Loss: 0.228925, Train Acc: 0.566667 | Val Loss: 0.236306, Val Acc: 0.536082\n",
      "Epoch 2293 - Train Loss: 0.228904, Train Acc: 0.566667 | Val Loss: 0.236286, Val Acc: 0.536082\n",
      "Epoch 2294 - Train Loss: 0.228884, Train Acc: 0.566667 | Val Loss: 0.236266, Val Acc: 0.536082\n",
      "Epoch 2295 - Train Loss: 0.228863, Train Acc: 0.566667 | Val Loss: 0.236245, Val Acc: 0.536082\n",
      "Epoch 2296 - Train Loss: 0.228843, Train Acc: 0.566667 | Val Loss: 0.236225, Val Acc: 0.536082\n",
      "Epoch 2297 - Train Loss: 0.228822, Train Acc: 0.566667 | Val Loss: 0.236205, Val Acc: 0.536082\n",
      "Epoch 2298 - Train Loss: 0.228802, Train Acc: 0.566667 | Val Loss: 0.236185, Val Acc: 0.536082\n",
      "Epoch 2299 - Train Loss: 0.228781, Train Acc: 0.566667 | Val Loss: 0.236165, Val Acc: 0.536082\n",
      "Epoch 2300 - Train Loss: 0.228761, Train Acc: 0.566667 | Val Loss: 0.236145, Val Acc: 0.536082\n",
      "Epoch 2301 - Train Loss: 0.228740, Train Acc: 0.566667 | Val Loss: 0.236125, Val Acc: 0.536082\n",
      "Epoch 2302 - Train Loss: 0.228720, Train Acc: 0.566667 | Val Loss: 0.236105, Val Acc: 0.536082\n",
      "Epoch 2303 - Train Loss: 0.228699, Train Acc: 0.566667 | Val Loss: 0.236084, Val Acc: 0.536082\n",
      "Epoch 2304 - Train Loss: 0.228679, Train Acc: 0.567949 | Val Loss: 0.236064, Val Acc: 0.536082\n",
      "Epoch 2305 - Train Loss: 0.228658, Train Acc: 0.567949 | Val Loss: 0.236044, Val Acc: 0.536082\n",
      "Epoch 2306 - Train Loss: 0.228638, Train Acc: 0.567949 | Val Loss: 0.236024, Val Acc: 0.536082\n",
      "Epoch 2307 - Train Loss: 0.228617, Train Acc: 0.567949 | Val Loss: 0.236004, Val Acc: 0.536082\n",
      "Epoch 2308 - Train Loss: 0.228597, Train Acc: 0.567949 | Val Loss: 0.235984, Val Acc: 0.536082\n",
      "Epoch 2309 - Train Loss: 0.228576, Train Acc: 0.567949 | Val Loss: 0.235963, Val Acc: 0.536082\n",
      "Epoch 2310 - Train Loss: 0.228556, Train Acc: 0.567949 | Val Loss: 0.235943, Val Acc: 0.536082\n",
      "Epoch 2311 - Train Loss: 0.228535, Train Acc: 0.567949 | Val Loss: 0.235923, Val Acc: 0.536082\n",
      "Epoch 2312 - Train Loss: 0.228515, Train Acc: 0.567949 | Val Loss: 0.235903, Val Acc: 0.536082\n",
      "Epoch 2313 - Train Loss: 0.228495, Train Acc: 0.567949 | Val Loss: 0.235883, Val Acc: 0.536082\n",
      "Epoch 2314 - Train Loss: 0.228474, Train Acc: 0.567949 | Val Loss: 0.235863, Val Acc: 0.536082\n",
      "Epoch 2315 - Train Loss: 0.228454, Train Acc: 0.567949 | Val Loss: 0.235843, Val Acc: 0.536082\n",
      "Epoch 2316 - Train Loss: 0.228433, Train Acc: 0.567949 | Val Loss: 0.235822, Val Acc: 0.536082\n",
      "Epoch 2317 - Train Loss: 0.228413, Train Acc: 0.569231 | Val Loss: 0.235802, Val Acc: 0.536082\n",
      "Epoch 2318 - Train Loss: 0.228392, Train Acc: 0.569231 | Val Loss: 0.235782, Val Acc: 0.536082\n",
      "Epoch 2319 - Train Loss: 0.228372, Train Acc: 0.569231 | Val Loss: 0.235762, Val Acc: 0.536082\n",
      "Epoch 2320 - Train Loss: 0.228351, Train Acc: 0.569231 | Val Loss: 0.235742, Val Acc: 0.536082\n",
      "Epoch 2321 - Train Loss: 0.228331, Train Acc: 0.569231 | Val Loss: 0.235722, Val Acc: 0.536082\n",
      "Epoch 2322 - Train Loss: 0.228310, Train Acc: 0.569231 | Val Loss: 0.235702, Val Acc: 0.536082\n",
      "Epoch 2323 - Train Loss: 0.228290, Train Acc: 0.569231 | Val Loss: 0.235681, Val Acc: 0.536082\n",
      "Epoch 2324 - Train Loss: 0.228269, Train Acc: 0.569231 | Val Loss: 0.235661, Val Acc: 0.536082\n",
      "Epoch 2325 - Train Loss: 0.228249, Train Acc: 0.569231 | Val Loss: 0.235641, Val Acc: 0.536082\n",
      "Epoch 2326 - Train Loss: 0.228228, Train Acc: 0.569231 | Val Loss: 0.235621, Val Acc: 0.536082\n",
      "Epoch 2327 - Train Loss: 0.228208, Train Acc: 0.569231 | Val Loss: 0.235601, Val Acc: 0.536082\n",
      "Epoch 2328 - Train Loss: 0.228187, Train Acc: 0.570513 | Val Loss: 0.235581, Val Acc: 0.536082\n",
      "Epoch 2329 - Train Loss: 0.228167, Train Acc: 0.570513 | Val Loss: 0.235561, Val Acc: 0.536082\n",
      "Epoch 2330 - Train Loss: 0.228147, Train Acc: 0.570513 | Val Loss: 0.235540, Val Acc: 0.536082\n",
      "Epoch 2331 - Train Loss: 0.228126, Train Acc: 0.570513 | Val Loss: 0.235520, Val Acc: 0.536082\n",
      "Epoch 2332 - Train Loss: 0.228106, Train Acc: 0.570513 | Val Loss: 0.235500, Val Acc: 0.536082\n",
      "Epoch 2333 - Train Loss: 0.228085, Train Acc: 0.570513 | Val Loss: 0.235480, Val Acc: 0.536082\n",
      "Epoch 2334 - Train Loss: 0.228065, Train Acc: 0.570513 | Val Loss: 0.235460, Val Acc: 0.536082\n",
      "Epoch 2335 - Train Loss: 0.228044, Train Acc: 0.570513 | Val Loss: 0.235440, Val Acc: 0.536082\n",
      "Epoch 2336 - Train Loss: 0.228024, Train Acc: 0.570513 | Val Loss: 0.235420, Val Acc: 0.536082\n",
      "Epoch 2337 - Train Loss: 0.228004, Train Acc: 0.570513 | Val Loss: 0.235400, Val Acc: 0.536082\n",
      "Epoch 2338 - Train Loss: 0.227983, Train Acc: 0.570513 | Val Loss: 0.235380, Val Acc: 0.536082\n",
      "Epoch 2339 - Train Loss: 0.227963, Train Acc: 0.570513 | Val Loss: 0.235360, Val Acc: 0.536082\n",
      "Epoch 2340 - Train Loss: 0.227942, Train Acc: 0.570513 | Val Loss: 0.235340, Val Acc: 0.536082\n",
      "Epoch 2341 - Train Loss: 0.227922, Train Acc: 0.570513 | Val Loss: 0.235320, Val Acc: 0.536082\n",
      "Epoch 2342 - Train Loss: 0.227902, Train Acc: 0.570513 | Val Loss: 0.235300, Val Acc: 0.536082\n",
      "Epoch 2343 - Train Loss: 0.227881, Train Acc: 0.570513 | Val Loss: 0.235280, Val Acc: 0.536082\n",
      "Epoch 2344 - Train Loss: 0.227861, Train Acc: 0.570513 | Val Loss: 0.235260, Val Acc: 0.536082\n",
      "Epoch 2345 - Train Loss: 0.227840, Train Acc: 0.570513 | Val Loss: 0.235240, Val Acc: 0.536082\n",
      "Epoch 2346 - Train Loss: 0.227820, Train Acc: 0.570513 | Val Loss: 0.235220, Val Acc: 0.536082\n",
      "Epoch 2347 - Train Loss: 0.227799, Train Acc: 0.570513 | Val Loss: 0.235200, Val Acc: 0.536082\n",
      "Epoch 2348 - Train Loss: 0.227779, Train Acc: 0.570513 | Val Loss: 0.235180, Val Acc: 0.536082\n",
      "Epoch 2349 - Train Loss: 0.227759, Train Acc: 0.570513 | Val Loss: 0.235160, Val Acc: 0.536082\n",
      "Epoch 2350 - Train Loss: 0.227738, Train Acc: 0.570513 | Val Loss: 0.235140, Val Acc: 0.536082\n",
      "Epoch 2351 - Train Loss: 0.227718, Train Acc: 0.570513 | Val Loss: 0.235120, Val Acc: 0.536082\n",
      "Epoch 2352 - Train Loss: 0.227698, Train Acc: 0.570513 | Val Loss: 0.235100, Val Acc: 0.536082\n",
      "Epoch 2353 - Train Loss: 0.227677, Train Acc: 0.570513 | Val Loss: 0.235080, Val Acc: 0.536082\n",
      "Epoch 2354 - Train Loss: 0.227657, Train Acc: 0.570513 | Val Loss: 0.235060, Val Acc: 0.536082\n",
      "Epoch 2355 - Train Loss: 0.227636, Train Acc: 0.570513 | Val Loss: 0.235040, Val Acc: 0.536082\n",
      "Epoch 2356 - Train Loss: 0.227616, Train Acc: 0.570513 | Val Loss: 0.235020, Val Acc: 0.536082\n",
      "Epoch 2357 - Train Loss: 0.227596, Train Acc: 0.570513 | Val Loss: 0.235000, Val Acc: 0.536082\n",
      "Epoch 2358 - Train Loss: 0.227575, Train Acc: 0.570513 | Val Loss: 0.234980, Val Acc: 0.536082\n",
      "Epoch 2359 - Train Loss: 0.227555, Train Acc: 0.571795 | Val Loss: 0.234960, Val Acc: 0.536082\n",
      "Epoch 2360 - Train Loss: 0.227534, Train Acc: 0.571795 | Val Loss: 0.234940, Val Acc: 0.536082\n",
      "Epoch 2361 - Train Loss: 0.227514, Train Acc: 0.571795 | Val Loss: 0.234920, Val Acc: 0.536082\n",
      "Epoch 2362 - Train Loss: 0.227494, Train Acc: 0.571795 | Val Loss: 0.234900, Val Acc: 0.536082\n",
      "Epoch 2363 - Train Loss: 0.227473, Train Acc: 0.571795 | Val Loss: 0.234880, Val Acc: 0.536082\n",
      "Epoch 2364 - Train Loss: 0.227453, Train Acc: 0.571795 | Val Loss: 0.234860, Val Acc: 0.536082\n",
      "Epoch 2365 - Train Loss: 0.227433, Train Acc: 0.571795 | Val Loss: 0.234840, Val Acc: 0.536082\n",
      "Epoch 2366 - Train Loss: 0.227412, Train Acc: 0.571795 | Val Loss: 0.234820, Val Acc: 0.536082\n",
      "Epoch 2367 - Train Loss: 0.227392, Train Acc: 0.571795 | Val Loss: 0.234800, Val Acc: 0.536082\n",
      "Epoch 2368 - Train Loss: 0.227371, Train Acc: 0.571795 | Val Loss: 0.234780, Val Acc: 0.536082\n",
      "Epoch 2369 - Train Loss: 0.227351, Train Acc: 0.571795 | Val Loss: 0.234760, Val Acc: 0.536082\n",
      "Epoch 2370 - Train Loss: 0.227331, Train Acc: 0.571795 | Val Loss: 0.234740, Val Acc: 0.536082\n",
      "Epoch 2371 - Train Loss: 0.227310, Train Acc: 0.571795 | Val Loss: 0.234720, Val Acc: 0.536082\n",
      "Epoch 2372 - Train Loss: 0.227290, Train Acc: 0.571795 | Val Loss: 0.234700, Val Acc: 0.536082\n",
      "Epoch 2373 - Train Loss: 0.227269, Train Acc: 0.571795 | Val Loss: 0.234680, Val Acc: 0.536082\n",
      "Epoch 2374 - Train Loss: 0.227249, Train Acc: 0.571795 | Val Loss: 0.234660, Val Acc: 0.536082\n",
      "Epoch 2375 - Train Loss: 0.227229, Train Acc: 0.571795 | Val Loss: 0.234641, Val Acc: 0.536082\n",
      "Epoch 2376 - Train Loss: 0.227208, Train Acc: 0.571795 | Val Loss: 0.234621, Val Acc: 0.536082\n",
      "Epoch 2377 - Train Loss: 0.227188, Train Acc: 0.571795 | Val Loss: 0.234601, Val Acc: 0.536082\n",
      "Epoch 2378 - Train Loss: 0.227168, Train Acc: 0.571795 | Val Loss: 0.234581, Val Acc: 0.536082\n",
      "Epoch 2379 - Train Loss: 0.227147, Train Acc: 0.571795 | Val Loss: 0.234561, Val Acc: 0.536082\n",
      "Epoch 2380 - Train Loss: 0.227127, Train Acc: 0.571795 | Val Loss: 0.234541, Val Acc: 0.536082\n",
      "Epoch 2381 - Train Loss: 0.227106, Train Acc: 0.571795 | Val Loss: 0.234521, Val Acc: 0.536082\n",
      "Epoch 2382 - Train Loss: 0.227086, Train Acc: 0.571795 | Val Loss: 0.234501, Val Acc: 0.536082\n",
      "Epoch 2383 - Train Loss: 0.227066, Train Acc: 0.571795 | Val Loss: 0.234481, Val Acc: 0.536082\n",
      "Epoch 2384 - Train Loss: 0.227045, Train Acc: 0.571795 | Val Loss: 0.234461, Val Acc: 0.536082\n",
      "Epoch 2385 - Train Loss: 0.227025, Train Acc: 0.571795 | Val Loss: 0.234441, Val Acc: 0.536082\n",
      "Epoch 2386 - Train Loss: 0.227005, Train Acc: 0.571795 | Val Loss: 0.234421, Val Acc: 0.536082\n",
      "Epoch 2387 - Train Loss: 0.226984, Train Acc: 0.571795 | Val Loss: 0.234401, Val Acc: 0.536082\n",
      "Epoch 2388 - Train Loss: 0.226964, Train Acc: 0.571795 | Val Loss: 0.234381, Val Acc: 0.536082\n",
      "Epoch 2389 - Train Loss: 0.226944, Train Acc: 0.571795 | Val Loss: 0.234361, Val Acc: 0.536082\n",
      "Epoch 2390 - Train Loss: 0.226923, Train Acc: 0.573077 | Val Loss: 0.234342, Val Acc: 0.536082\n",
      "Epoch 2391 - Train Loss: 0.226903, Train Acc: 0.573077 | Val Loss: 0.234322, Val Acc: 0.536082\n",
      "Epoch 2392 - Train Loss: 0.226882, Train Acc: 0.573077 | Val Loss: 0.234302, Val Acc: 0.536082\n",
      "Epoch 2393 - Train Loss: 0.226862, Train Acc: 0.574359 | Val Loss: 0.234282, Val Acc: 0.536082\n",
      "Epoch 2394 - Train Loss: 0.226842, Train Acc: 0.574359 | Val Loss: 0.234262, Val Acc: 0.536082\n",
      "Epoch 2395 - Train Loss: 0.226821, Train Acc: 0.574359 | Val Loss: 0.234242, Val Acc: 0.536082\n",
      "Epoch 2396 - Train Loss: 0.226801, Train Acc: 0.574359 | Val Loss: 0.234222, Val Acc: 0.536082\n",
      "Epoch 2397 - Train Loss: 0.226781, Train Acc: 0.574359 | Val Loss: 0.234202, Val Acc: 0.536082\n",
      "Epoch 2398 - Train Loss: 0.226760, Train Acc: 0.574359 | Val Loss: 0.234182, Val Acc: 0.536082\n",
      "Epoch 2399 - Train Loss: 0.226740, Train Acc: 0.574359 | Val Loss: 0.234163, Val Acc: 0.536082\n",
      "Epoch 2400 - Train Loss: 0.226720, Train Acc: 0.574359 | Val Loss: 0.234143, Val Acc: 0.536082\n",
      "Epoch 2401 - Train Loss: 0.226699, Train Acc: 0.574359 | Val Loss: 0.234123, Val Acc: 0.536082\n",
      "Epoch 2402 - Train Loss: 0.226679, Train Acc: 0.574359 | Val Loss: 0.234103, Val Acc: 0.536082\n",
      "Epoch 2403 - Train Loss: 0.226658, Train Acc: 0.574359 | Val Loss: 0.234083, Val Acc: 0.536082\n",
      "Epoch 2404 - Train Loss: 0.226638, Train Acc: 0.574359 | Val Loss: 0.234063, Val Acc: 0.536082\n",
      "Epoch 2405 - Train Loss: 0.226618, Train Acc: 0.575641 | Val Loss: 0.234043, Val Acc: 0.536082\n",
      "Epoch 2406 - Train Loss: 0.226597, Train Acc: 0.575641 | Val Loss: 0.234023, Val Acc: 0.536082\n",
      "Epoch 2407 - Train Loss: 0.226577, Train Acc: 0.575641 | Val Loss: 0.234004, Val Acc: 0.536082\n",
      "Epoch 2408 - Train Loss: 0.226556, Train Acc: 0.575641 | Val Loss: 0.233984, Val Acc: 0.536082\n",
      "Epoch 2409 - Train Loss: 0.226536, Train Acc: 0.575641 | Val Loss: 0.233964, Val Acc: 0.536082\n",
      "Epoch 2410 - Train Loss: 0.226516, Train Acc: 0.575641 | Val Loss: 0.233944, Val Acc: 0.536082\n",
      "Epoch 2411 - Train Loss: 0.226495, Train Acc: 0.576923 | Val Loss: 0.233924, Val Acc: 0.536082\n",
      "Epoch 2412 - Train Loss: 0.226475, Train Acc: 0.576923 | Val Loss: 0.233904, Val Acc: 0.536082\n",
      "Epoch 2413 - Train Loss: 0.226454, Train Acc: 0.576923 | Val Loss: 0.233884, Val Acc: 0.536082\n",
      "Epoch 2414 - Train Loss: 0.226434, Train Acc: 0.576923 | Val Loss: 0.233865, Val Acc: 0.536082\n",
      "Epoch 2415 - Train Loss: 0.226414, Train Acc: 0.576923 | Val Loss: 0.233845, Val Acc: 0.536082\n",
      "Epoch 2416 - Train Loss: 0.226393, Train Acc: 0.576923 | Val Loss: 0.233825, Val Acc: 0.536082\n",
      "Epoch 2417 - Train Loss: 0.226373, Train Acc: 0.576923 | Val Loss: 0.233805, Val Acc: 0.536082\n",
      "Epoch 2418 - Train Loss: 0.226352, Train Acc: 0.576923 | Val Loss: 0.233785, Val Acc: 0.536082\n",
      "Epoch 2419 - Train Loss: 0.226332, Train Acc: 0.576923 | Val Loss: 0.233765, Val Acc: 0.536082\n",
      "Epoch 2420 - Train Loss: 0.226312, Train Acc: 0.578205 | Val Loss: 0.233745, Val Acc: 0.536082\n",
      "Epoch 2421 - Train Loss: 0.226291, Train Acc: 0.578205 | Val Loss: 0.233725, Val Acc: 0.536082\n",
      "Epoch 2422 - Train Loss: 0.226271, Train Acc: 0.578205 | Val Loss: 0.233705, Val Acc: 0.536082\n",
      "Epoch 2423 - Train Loss: 0.226251, Train Acc: 0.578205 | Val Loss: 0.233686, Val Acc: 0.536082\n",
      "Epoch 2424 - Train Loss: 0.226230, Train Acc: 0.578205 | Val Loss: 0.233666, Val Acc: 0.536082\n",
      "Epoch 2425 - Train Loss: 0.226210, Train Acc: 0.578205 | Val Loss: 0.233646, Val Acc: 0.536082\n",
      "Epoch 2426 - Train Loss: 0.226189, Train Acc: 0.578205 | Val Loss: 0.233626, Val Acc: 0.536082\n",
      "Epoch 2427 - Train Loss: 0.226169, Train Acc: 0.578205 | Val Loss: 0.233606, Val Acc: 0.536082\n",
      "Epoch 2428 - Train Loss: 0.226149, Train Acc: 0.578205 | Val Loss: 0.233586, Val Acc: 0.536082\n",
      "Epoch 2429 - Train Loss: 0.226128, Train Acc: 0.578205 | Val Loss: 0.233566, Val Acc: 0.536082\n",
      "Epoch 2430 - Train Loss: 0.226108, Train Acc: 0.578205 | Val Loss: 0.233546, Val Acc: 0.536082\n",
      "Epoch 2431 - Train Loss: 0.226088, Train Acc: 0.579487 | Val Loss: 0.233526, Val Acc: 0.536082\n",
      "Epoch 2432 - Train Loss: 0.226067, Train Acc: 0.579487 | Val Loss: 0.233506, Val Acc: 0.536082\n",
      "Epoch 2433 - Train Loss: 0.226047, Train Acc: 0.579487 | Val Loss: 0.233486, Val Acc: 0.536082\n",
      "Epoch 2434 - Train Loss: 0.226026, Train Acc: 0.579487 | Val Loss: 0.233466, Val Acc: 0.536082\n",
      "Epoch 2435 - Train Loss: 0.226006, Train Acc: 0.579487 | Val Loss: 0.233447, Val Acc: 0.536082\n",
      "Epoch 2436 - Train Loss: 0.225986, Train Acc: 0.579487 | Val Loss: 0.233427, Val Acc: 0.536082\n",
      "Epoch 2437 - Train Loss: 0.225965, Train Acc: 0.579487 | Val Loss: 0.233407, Val Acc: 0.536082\n",
      "Epoch 2438 - Train Loss: 0.225945, Train Acc: 0.579487 | Val Loss: 0.233387, Val Acc: 0.536082\n",
      "Epoch 2439 - Train Loss: 0.225925, Train Acc: 0.579487 | Val Loss: 0.233367, Val Acc: 0.536082\n",
      "Epoch 2440 - Train Loss: 0.225904, Train Acc: 0.579487 | Val Loss: 0.233347, Val Acc: 0.536082\n",
      "Epoch 2441 - Train Loss: 0.225884, Train Acc: 0.579487 | Val Loss: 0.233327, Val Acc: 0.536082\n",
      "Epoch 2442 - Train Loss: 0.225864, Train Acc: 0.579487 | Val Loss: 0.233307, Val Acc: 0.536082\n",
      "Epoch 2443 - Train Loss: 0.225843, Train Acc: 0.579487 | Val Loss: 0.233288, Val Acc: 0.536082\n",
      "Epoch 2444 - Train Loss: 0.225823, Train Acc: 0.579487 | Val Loss: 0.233268, Val Acc: 0.536082\n",
      "Epoch 2445 - Train Loss: 0.225803, Train Acc: 0.579487 | Val Loss: 0.233248, Val Acc: 0.536082\n",
      "Epoch 2446 - Train Loss: 0.225783, Train Acc: 0.579487 | Val Loss: 0.233228, Val Acc: 0.536082\n",
      "Epoch 2447 - Train Loss: 0.225762, Train Acc: 0.580769 | Val Loss: 0.233208, Val Acc: 0.536082\n",
      "Epoch 2448 - Train Loss: 0.225742, Train Acc: 0.582051 | Val Loss: 0.233188, Val Acc: 0.536082\n",
      "Epoch 2449 - Train Loss: 0.225722, Train Acc: 0.582051 | Val Loss: 0.233169, Val Acc: 0.536082\n",
      "Epoch 2450 - Train Loss: 0.225701, Train Acc: 0.582051 | Val Loss: 0.233149, Val Acc: 0.536082\n",
      "Epoch 2451 - Train Loss: 0.225681, Train Acc: 0.582051 | Val Loss: 0.233129, Val Acc: 0.536082\n",
      "Epoch 2452 - Train Loss: 0.225661, Train Acc: 0.582051 | Val Loss: 0.233109, Val Acc: 0.536082\n",
      "Epoch 2453 - Train Loss: 0.225640, Train Acc: 0.582051 | Val Loss: 0.233089, Val Acc: 0.536082\n",
      "Epoch 2454 - Train Loss: 0.225620, Train Acc: 0.582051 | Val Loss: 0.233069, Val Acc: 0.536082\n",
      "Epoch 2455 - Train Loss: 0.225600, Train Acc: 0.582051 | Val Loss: 0.233049, Val Acc: 0.536082\n",
      "Epoch 2456 - Train Loss: 0.225579, Train Acc: 0.582051 | Val Loss: 0.233030, Val Acc: 0.536082\n",
      "Epoch 2457 - Train Loss: 0.225559, Train Acc: 0.582051 | Val Loss: 0.233010, Val Acc: 0.536082\n",
      "Epoch 2458 - Train Loss: 0.225539, Train Acc: 0.582051 | Val Loss: 0.232990, Val Acc: 0.536082\n",
      "Epoch 2459 - Train Loss: 0.225518, Train Acc: 0.582051 | Val Loss: 0.232970, Val Acc: 0.536082\n",
      "Epoch 2460 - Train Loss: 0.225498, Train Acc: 0.582051 | Val Loss: 0.232950, Val Acc: 0.536082\n",
      "Epoch 2461 - Train Loss: 0.225478, Train Acc: 0.582051 | Val Loss: 0.232930, Val Acc: 0.536082\n",
      "Epoch 2462 - Train Loss: 0.225457, Train Acc: 0.582051 | Val Loss: 0.232911, Val Acc: 0.536082\n",
      "Epoch 2463 - Train Loss: 0.225437, Train Acc: 0.582051 | Val Loss: 0.232891, Val Acc: 0.536082\n",
      "Epoch 2464 - Train Loss: 0.225417, Train Acc: 0.582051 | Val Loss: 0.232871, Val Acc: 0.536082\n",
      "Epoch 2465 - Train Loss: 0.225396, Train Acc: 0.582051 | Val Loss: 0.232851, Val Acc: 0.536082\n",
      "Epoch 2466 - Train Loss: 0.225376, Train Acc: 0.582051 | Val Loss: 0.232831, Val Acc: 0.536082\n",
      "Epoch 2467 - Train Loss: 0.225356, Train Acc: 0.583333 | Val Loss: 0.232811, Val Acc: 0.536082\n",
      "Epoch 2468 - Train Loss: 0.225335, Train Acc: 0.583333 | Val Loss: 0.232791, Val Acc: 0.536082\n",
      "Epoch 2469 - Train Loss: 0.225315, Train Acc: 0.583333 | Val Loss: 0.232771, Val Acc: 0.536082\n",
      "Epoch 2470 - Train Loss: 0.225295, Train Acc: 0.583333 | Val Loss: 0.232752, Val Acc: 0.536082\n",
      "Epoch 2471 - Train Loss: 0.225274, Train Acc: 0.583333 | Val Loss: 0.232732, Val Acc: 0.536082\n",
      "Epoch 2472 - Train Loss: 0.225254, Train Acc: 0.583333 | Val Loss: 0.232712, Val Acc: 0.536082\n",
      "Epoch 2473 - Train Loss: 0.225233, Train Acc: 0.584615 | Val Loss: 0.232692, Val Acc: 0.536082\n",
      "Epoch 2474 - Train Loss: 0.225213, Train Acc: 0.584615 | Val Loss: 0.232672, Val Acc: 0.536082\n",
      "Epoch 2475 - Train Loss: 0.225193, Train Acc: 0.584615 | Val Loss: 0.232652, Val Acc: 0.536082\n",
      "Epoch 2476 - Train Loss: 0.225172, Train Acc: 0.584615 | Val Loss: 0.232633, Val Acc: 0.536082\n",
      "Epoch 2477 - Train Loss: 0.225152, Train Acc: 0.584615 | Val Loss: 0.232613, Val Acc: 0.536082\n",
      "Epoch 2478 - Train Loss: 0.225132, Train Acc: 0.584615 | Val Loss: 0.232593, Val Acc: 0.536082\n",
      "Epoch 2479 - Train Loss: 0.225111, Train Acc: 0.584615 | Val Loss: 0.232573, Val Acc: 0.536082\n",
      "Epoch 2480 - Train Loss: 0.225091, Train Acc: 0.584615 | Val Loss: 0.232553, Val Acc: 0.536082\n",
      "Epoch 2481 - Train Loss: 0.225071, Train Acc: 0.584615 | Val Loss: 0.232534, Val Acc: 0.536082\n",
      "Epoch 2482 - Train Loss: 0.225050, Train Acc: 0.584615 | Val Loss: 0.232514, Val Acc: 0.536082\n",
      "Epoch 2483 - Train Loss: 0.225030, Train Acc: 0.584615 | Val Loss: 0.232494, Val Acc: 0.536082\n",
      "Epoch 2484 - Train Loss: 0.225010, Train Acc: 0.584615 | Val Loss: 0.232474, Val Acc: 0.536082\n",
      "Epoch 2485 - Train Loss: 0.224989, Train Acc: 0.584615 | Val Loss: 0.232454, Val Acc: 0.536082\n",
      "Epoch 2486 - Train Loss: 0.224969, Train Acc: 0.584615 | Val Loss: 0.232434, Val Acc: 0.536082\n",
      "Epoch 2487 - Train Loss: 0.224949, Train Acc: 0.584615 | Val Loss: 0.232414, Val Acc: 0.536082\n",
      "Epoch 2488 - Train Loss: 0.224928, Train Acc: 0.584615 | Val Loss: 0.232395, Val Acc: 0.536082\n",
      "Epoch 2489 - Train Loss: 0.224908, Train Acc: 0.584615 | Val Loss: 0.232375, Val Acc: 0.536082\n",
      "Epoch 2490 - Train Loss: 0.224888, Train Acc: 0.584615 | Val Loss: 0.232355, Val Acc: 0.536082\n",
      "Epoch 2491 - Train Loss: 0.224867, Train Acc: 0.584615 | Val Loss: 0.232335, Val Acc: 0.536082\n",
      "Epoch 2492 - Train Loss: 0.224847, Train Acc: 0.584615 | Val Loss: 0.232315, Val Acc: 0.536082\n",
      "Epoch 2493 - Train Loss: 0.224827, Train Acc: 0.584615 | Val Loss: 0.232296, Val Acc: 0.536082\n",
      "Epoch 2494 - Train Loss: 0.224807, Train Acc: 0.584615 | Val Loss: 0.232276, Val Acc: 0.546392\n",
      "Epoch 2495 - Train Loss: 0.224786, Train Acc: 0.584615 | Val Loss: 0.232256, Val Acc: 0.546392\n",
      "Epoch 2496 - Train Loss: 0.224766, Train Acc: 0.584615 | Val Loss: 0.232236, Val Acc: 0.546392\n",
      "Epoch 2497 - Train Loss: 0.224746, Train Acc: 0.584615 | Val Loss: 0.232216, Val Acc: 0.546392\n",
      "Epoch 2498 - Train Loss: 0.224725, Train Acc: 0.584615 | Val Loss: 0.232196, Val Acc: 0.546392\n",
      "Epoch 2499 - Train Loss: 0.224705, Train Acc: 0.584615 | Val Loss: 0.232177, Val Acc: 0.546392\n",
      "Epoch 2500 - Train Loss: 0.224685, Train Acc: 0.584615 | Val Loss: 0.232157, Val Acc: 0.546392\n",
      "Epoch 2501 - Train Loss: 0.224664, Train Acc: 0.585897 | Val Loss: 0.232137, Val Acc: 0.546392\n",
      "Epoch 2502 - Train Loss: 0.224644, Train Acc: 0.585897 | Val Loss: 0.232117, Val Acc: 0.546392\n",
      "Epoch 2503 - Train Loss: 0.224623, Train Acc: 0.585897 | Val Loss: 0.232097, Val Acc: 0.546392\n",
      "Epoch 2504 - Train Loss: 0.224603, Train Acc: 0.585897 | Val Loss: 0.232077, Val Acc: 0.546392\n",
      "Epoch 2505 - Train Loss: 0.224583, Train Acc: 0.585897 | Val Loss: 0.232057, Val Acc: 0.546392\n",
      "Epoch 2506 - Train Loss: 0.224562, Train Acc: 0.585897 | Val Loss: 0.232037, Val Acc: 0.546392\n",
      "Epoch 2507 - Train Loss: 0.224542, Train Acc: 0.585897 | Val Loss: 0.232017, Val Acc: 0.546392\n",
      "Epoch 2508 - Train Loss: 0.224522, Train Acc: 0.585897 | Val Loss: 0.231997, Val Acc: 0.546392\n",
      "Epoch 2509 - Train Loss: 0.224501, Train Acc: 0.585897 | Val Loss: 0.231977, Val Acc: 0.546392\n",
      "Epoch 2510 - Train Loss: 0.224481, Train Acc: 0.585897 | Val Loss: 0.231957, Val Acc: 0.546392\n",
      "Epoch 2511 - Train Loss: 0.224461, Train Acc: 0.585897 | Val Loss: 0.231938, Val Acc: 0.546392\n",
      "Epoch 2512 - Train Loss: 0.224440, Train Acc: 0.585897 | Val Loss: 0.231918, Val Acc: 0.546392\n",
      "Epoch 2513 - Train Loss: 0.224420, Train Acc: 0.585897 | Val Loss: 0.231898, Val Acc: 0.546392\n",
      "Epoch 2514 - Train Loss: 0.224400, Train Acc: 0.585897 | Val Loss: 0.231878, Val Acc: 0.546392\n",
      "Epoch 2515 - Train Loss: 0.224379, Train Acc: 0.585897 | Val Loss: 0.231858, Val Acc: 0.546392\n",
      "Epoch 2516 - Train Loss: 0.224359, Train Acc: 0.585897 | Val Loss: 0.231838, Val Acc: 0.546392\n",
      "Epoch 2517 - Train Loss: 0.224339, Train Acc: 0.585897 | Val Loss: 0.231819, Val Acc: 0.546392\n",
      "Epoch 2518 - Train Loss: 0.224318, Train Acc: 0.585897 | Val Loss: 0.231799, Val Acc: 0.546392\n",
      "Epoch 2519 - Train Loss: 0.224298, Train Acc: 0.585897 | Val Loss: 0.231779, Val Acc: 0.546392\n",
      "Epoch 2520 - Train Loss: 0.224278, Train Acc: 0.585897 | Val Loss: 0.231759, Val Acc: 0.546392\n",
      "Epoch 2521 - Train Loss: 0.224257, Train Acc: 0.585897 | Val Loss: 0.231739, Val Acc: 0.546392\n",
      "Epoch 2522 - Train Loss: 0.224237, Train Acc: 0.585897 | Val Loss: 0.231720, Val Acc: 0.546392\n",
      "Epoch 2523 - Train Loss: 0.224217, Train Acc: 0.585897 | Val Loss: 0.231700, Val Acc: 0.546392\n",
      "Epoch 2524 - Train Loss: 0.224196, Train Acc: 0.585897 | Val Loss: 0.231680, Val Acc: 0.546392\n",
      "Epoch 2525 - Train Loss: 0.224176, Train Acc: 0.585897 | Val Loss: 0.231661, Val Acc: 0.546392\n",
      "Epoch 2526 - Train Loss: 0.224156, Train Acc: 0.585897 | Val Loss: 0.231641, Val Acc: 0.546392\n",
      "Epoch 2527 - Train Loss: 0.224136, Train Acc: 0.585897 | Val Loss: 0.231621, Val Acc: 0.546392\n",
      "Epoch 2528 - Train Loss: 0.224115, Train Acc: 0.585897 | Val Loss: 0.231602, Val Acc: 0.546392\n",
      "Epoch 2529 - Train Loss: 0.224095, Train Acc: 0.585897 | Val Loss: 0.231582, Val Acc: 0.546392\n",
      "Epoch 2530 - Train Loss: 0.224075, Train Acc: 0.585897 | Val Loss: 0.231562, Val Acc: 0.546392\n",
      "Epoch 2531 - Train Loss: 0.224055, Train Acc: 0.585897 | Val Loss: 0.231543, Val Acc: 0.546392\n",
      "Epoch 2532 - Train Loss: 0.224034, Train Acc: 0.585897 | Val Loss: 0.231523, Val Acc: 0.546392\n",
      "Epoch 2533 - Train Loss: 0.224014, Train Acc: 0.585897 | Val Loss: 0.231503, Val Acc: 0.546392\n",
      "Epoch 2534 - Train Loss: 0.223994, Train Acc: 0.585897 | Val Loss: 0.231484, Val Acc: 0.546392\n",
      "Epoch 2535 - Train Loss: 0.223974, Train Acc: 0.585897 | Val Loss: 0.231464, Val Acc: 0.546392\n",
      "Epoch 2536 - Train Loss: 0.223953, Train Acc: 0.585897 | Val Loss: 0.231444, Val Acc: 0.546392\n",
      "Epoch 2537 - Train Loss: 0.223933, Train Acc: 0.585897 | Val Loss: 0.231425, Val Acc: 0.546392\n",
      "Epoch 2538 - Train Loss: 0.223913, Train Acc: 0.585897 | Val Loss: 0.231405, Val Acc: 0.546392\n",
      "Epoch 2539 - Train Loss: 0.223893, Train Acc: 0.585897 | Val Loss: 0.231385, Val Acc: 0.546392\n",
      "Epoch 2540 - Train Loss: 0.223872, Train Acc: 0.585897 | Val Loss: 0.231366, Val Acc: 0.546392\n",
      "Epoch 2541 - Train Loss: 0.223852, Train Acc: 0.585897 | Val Loss: 0.231346, Val Acc: 0.546392\n",
      "Epoch 2542 - Train Loss: 0.223832, Train Acc: 0.585897 | Val Loss: 0.231326, Val Acc: 0.546392\n",
      "Epoch 2543 - Train Loss: 0.223812, Train Acc: 0.585897 | Val Loss: 0.231307, Val Acc: 0.546392\n",
      "Epoch 2544 - Train Loss: 0.223792, Train Acc: 0.585897 | Val Loss: 0.231287, Val Acc: 0.546392\n",
      "Epoch 2545 - Train Loss: 0.223771, Train Acc: 0.585897 | Val Loss: 0.231268, Val Acc: 0.546392\n",
      "Epoch 2546 - Train Loss: 0.223751, Train Acc: 0.585897 | Val Loss: 0.231248, Val Acc: 0.546392\n",
      "Epoch 2547 - Train Loss: 0.223731, Train Acc: 0.585897 | Val Loss: 0.231228, Val Acc: 0.546392\n",
      "Epoch 2548 - Train Loss: 0.223711, Train Acc: 0.585897 | Val Loss: 0.231209, Val Acc: 0.546392\n",
      "Epoch 2549 - Train Loss: 0.223690, Train Acc: 0.585897 | Val Loss: 0.231189, Val Acc: 0.546392\n",
      "Epoch 2550 - Train Loss: 0.223670, Train Acc: 0.585897 | Val Loss: 0.231169, Val Acc: 0.546392\n",
      "Epoch 2551 - Train Loss: 0.223650, Train Acc: 0.585897 | Val Loss: 0.231150, Val Acc: 0.546392\n",
      "Epoch 2552 - Train Loss: 0.223630, Train Acc: 0.585897 | Val Loss: 0.231130, Val Acc: 0.546392\n",
      "Epoch 2553 - Train Loss: 0.223610, Train Acc: 0.585897 | Val Loss: 0.231111, Val Acc: 0.546392\n",
      "Epoch 2554 - Train Loss: 0.223589, Train Acc: 0.585897 | Val Loss: 0.231091, Val Acc: 0.546392\n",
      "Epoch 2555 - Train Loss: 0.223569, Train Acc: 0.585897 | Val Loss: 0.231071, Val Acc: 0.546392\n",
      "Epoch 2556 - Train Loss: 0.223549, Train Acc: 0.585897 | Val Loss: 0.231052, Val Acc: 0.546392\n",
      "Epoch 2557 - Train Loss: 0.223529, Train Acc: 0.585897 | Val Loss: 0.231032, Val Acc: 0.546392\n",
      "Epoch 2558 - Train Loss: 0.223509, Train Acc: 0.585897 | Val Loss: 0.231013, Val Acc: 0.546392\n",
      "Epoch 2559 - Train Loss: 0.223489, Train Acc: 0.585897 | Val Loss: 0.230993, Val Acc: 0.546392\n",
      "Epoch 2560 - Train Loss: 0.223468, Train Acc: 0.585897 | Val Loss: 0.230974, Val Acc: 0.546392\n",
      "Epoch 2561 - Train Loss: 0.223448, Train Acc: 0.585897 | Val Loss: 0.230954, Val Acc: 0.546392\n",
      "Epoch 2562 - Train Loss: 0.223428, Train Acc: 0.585897 | Val Loss: 0.230934, Val Acc: 0.546392\n",
      "Epoch 2563 - Train Loss: 0.223408, Train Acc: 0.585897 | Val Loss: 0.230915, Val Acc: 0.546392\n",
      "Epoch 2564 - Train Loss: 0.223388, Train Acc: 0.585897 | Val Loss: 0.230895, Val Acc: 0.546392\n",
      "Epoch 2565 - Train Loss: 0.223367, Train Acc: 0.585897 | Val Loss: 0.230876, Val Acc: 0.546392\n",
      "Epoch 2566 - Train Loss: 0.223347, Train Acc: 0.585897 | Val Loss: 0.230856, Val Acc: 0.546392\n",
      "Epoch 2567 - Train Loss: 0.223327, Train Acc: 0.585897 | Val Loss: 0.230837, Val Acc: 0.546392\n",
      "Epoch 2568 - Train Loss: 0.223307, Train Acc: 0.585897 | Val Loss: 0.230817, Val Acc: 0.546392\n",
      "Epoch 2569 - Train Loss: 0.223287, Train Acc: 0.585897 | Val Loss: 0.230797, Val Acc: 0.546392\n",
      "Epoch 2570 - Train Loss: 0.223267, Train Acc: 0.585897 | Val Loss: 0.230778, Val Acc: 0.546392\n",
      "Epoch 2571 - Train Loss: 0.223247, Train Acc: 0.585897 | Val Loss: 0.230758, Val Acc: 0.546392\n",
      "Epoch 2572 - Train Loss: 0.223226, Train Acc: 0.585897 | Val Loss: 0.230739, Val Acc: 0.546392\n",
      "Epoch 2573 - Train Loss: 0.223206, Train Acc: 0.585897 | Val Loss: 0.230719, Val Acc: 0.546392\n",
      "Epoch 2574 - Train Loss: 0.223186, Train Acc: 0.585897 | Val Loss: 0.230700, Val Acc: 0.546392\n",
      "Epoch 2575 - Train Loss: 0.223166, Train Acc: 0.585897 | Val Loss: 0.230680, Val Acc: 0.546392\n",
      "Epoch 2576 - Train Loss: 0.223146, Train Acc: 0.585897 | Val Loss: 0.230660, Val Acc: 0.546392\n",
      "Epoch 2577 - Train Loss: 0.223126, Train Acc: 0.585897 | Val Loss: 0.230641, Val Acc: 0.546392\n",
      "Epoch 2578 - Train Loss: 0.223106, Train Acc: 0.585897 | Val Loss: 0.230621, Val Acc: 0.546392\n",
      "Epoch 2579 - Train Loss: 0.223085, Train Acc: 0.587179 | Val Loss: 0.230602, Val Acc: 0.546392\n",
      "Epoch 2580 - Train Loss: 0.223065, Train Acc: 0.587179 | Val Loss: 0.230582, Val Acc: 0.546392\n",
      "Epoch 2581 - Train Loss: 0.223045, Train Acc: 0.587179 | Val Loss: 0.230563, Val Acc: 0.546392\n",
      "Epoch 2582 - Train Loss: 0.223025, Train Acc: 0.588462 | Val Loss: 0.230543, Val Acc: 0.546392\n",
      "Epoch 2583 - Train Loss: 0.223005, Train Acc: 0.588462 | Val Loss: 0.230524, Val Acc: 0.546392\n",
      "Epoch 2584 - Train Loss: 0.222985, Train Acc: 0.588462 | Val Loss: 0.230504, Val Acc: 0.546392\n",
      "Epoch 2585 - Train Loss: 0.222965, Train Acc: 0.588462 | Val Loss: 0.230485, Val Acc: 0.546392\n",
      "Epoch 2586 - Train Loss: 0.222944, Train Acc: 0.588462 | Val Loss: 0.230465, Val Acc: 0.546392\n",
      "Epoch 2587 - Train Loss: 0.222924, Train Acc: 0.588462 | Val Loss: 0.230446, Val Acc: 0.546392\n",
      "Epoch 2588 - Train Loss: 0.222904, Train Acc: 0.588462 | Val Loss: 0.230426, Val Acc: 0.546392\n",
      "Epoch 2589 - Train Loss: 0.222884, Train Acc: 0.588462 | Val Loss: 0.230407, Val Acc: 0.546392\n",
      "Epoch 2590 - Train Loss: 0.222864, Train Acc: 0.588462 | Val Loss: 0.230387, Val Acc: 0.546392\n",
      "Epoch 2591 - Train Loss: 0.222844, Train Acc: 0.588462 | Val Loss: 0.230368, Val Acc: 0.546392\n",
      "Epoch 2592 - Train Loss: 0.222824, Train Acc: 0.588462 | Val Loss: 0.230348, Val Acc: 0.546392\n",
      "Epoch 2593 - Train Loss: 0.222804, Train Acc: 0.588462 | Val Loss: 0.230329, Val Acc: 0.546392\n",
      "Epoch 2594 - Train Loss: 0.222783, Train Acc: 0.588462 | Val Loss: 0.230309, Val Acc: 0.546392\n",
      "Epoch 2595 - Train Loss: 0.222763, Train Acc: 0.588462 | Val Loss: 0.230290, Val Acc: 0.546392\n",
      "Epoch 2596 - Train Loss: 0.222743, Train Acc: 0.589744 | Val Loss: 0.230270, Val Acc: 0.546392\n",
      "Epoch 2597 - Train Loss: 0.222723, Train Acc: 0.589744 | Val Loss: 0.230251, Val Acc: 0.546392\n",
      "Epoch 2598 - Train Loss: 0.222703, Train Acc: 0.589744 | Val Loss: 0.230231, Val Acc: 0.546392\n",
      "Epoch 2599 - Train Loss: 0.222683, Train Acc: 0.589744 | Val Loss: 0.230212, Val Acc: 0.546392\n",
      "Epoch 2600 - Train Loss: 0.222662, Train Acc: 0.589744 | Val Loss: 0.230192, Val Acc: 0.546392\n",
      "Epoch 2601 - Train Loss: 0.222642, Train Acc: 0.589744 | Val Loss: 0.230173, Val Acc: 0.546392\n",
      "Epoch 2602 - Train Loss: 0.222622, Train Acc: 0.589744 | Val Loss: 0.230153, Val Acc: 0.546392\n",
      "Epoch 2603 - Train Loss: 0.222602, Train Acc: 0.589744 | Val Loss: 0.230134, Val Acc: 0.546392\n",
      "Epoch 2604 - Train Loss: 0.222582, Train Acc: 0.589744 | Val Loss: 0.230114, Val Acc: 0.546392\n",
      "Epoch 2605 - Train Loss: 0.222562, Train Acc: 0.589744 | Val Loss: 0.230095, Val Acc: 0.546392\n",
      "Epoch 2606 - Train Loss: 0.222542, Train Acc: 0.589744 | Val Loss: 0.230076, Val Acc: 0.546392\n",
      "Epoch 2607 - Train Loss: 0.222521, Train Acc: 0.589744 | Val Loss: 0.230056, Val Acc: 0.546392\n",
      "Epoch 2608 - Train Loss: 0.222501, Train Acc: 0.589744 | Val Loss: 0.230037, Val Acc: 0.546392\n",
      "Epoch 2609 - Train Loss: 0.222481, Train Acc: 0.589744 | Val Loss: 0.230017, Val Acc: 0.546392\n",
      "Epoch 2610 - Train Loss: 0.222461, Train Acc: 0.589744 | Val Loss: 0.229998, Val Acc: 0.546392\n",
      "Epoch 2611 - Train Loss: 0.222441, Train Acc: 0.589744 | Val Loss: 0.229978, Val Acc: 0.546392\n",
      "Epoch 2612 - Train Loss: 0.222421, Train Acc: 0.589744 | Val Loss: 0.229959, Val Acc: 0.546392\n",
      "Epoch 2613 - Train Loss: 0.222401, Train Acc: 0.589744 | Val Loss: 0.229939, Val Acc: 0.546392\n",
      "Epoch 2614 - Train Loss: 0.222381, Train Acc: 0.589744 | Val Loss: 0.229920, Val Acc: 0.546392\n",
      "Epoch 2615 - Train Loss: 0.222361, Train Acc: 0.589744 | Val Loss: 0.229901, Val Acc: 0.546392\n",
      "Epoch 2616 - Train Loss: 0.222341, Train Acc: 0.589744 | Val Loss: 0.229881, Val Acc: 0.546392\n",
      "Epoch 2617 - Train Loss: 0.222321, Train Acc: 0.589744 | Val Loss: 0.229862, Val Acc: 0.546392\n",
      "Epoch 2618 - Train Loss: 0.222301, Train Acc: 0.589744 | Val Loss: 0.229843, Val Acc: 0.546392\n",
      "Epoch 2619 - Train Loss: 0.222280, Train Acc: 0.589744 | Val Loss: 0.229823, Val Acc: 0.546392\n",
      "Epoch 2620 - Train Loss: 0.222260, Train Acc: 0.589744 | Val Loss: 0.229804, Val Acc: 0.546392\n",
      "Epoch 2621 - Train Loss: 0.222240, Train Acc: 0.589744 | Val Loss: 0.229785, Val Acc: 0.546392\n",
      "Epoch 2622 - Train Loss: 0.222220, Train Acc: 0.589744 | Val Loss: 0.229765, Val Acc: 0.546392\n",
      "Epoch 2623 - Train Loss: 0.222200, Train Acc: 0.589744 | Val Loss: 0.229746, Val Acc: 0.546392\n",
      "Epoch 2624 - Train Loss: 0.222180, Train Acc: 0.589744 | Val Loss: 0.229727, Val Acc: 0.546392\n",
      "Epoch 2625 - Train Loss: 0.222160, Train Acc: 0.589744 | Val Loss: 0.229707, Val Acc: 0.546392\n",
      "Epoch 2626 - Train Loss: 0.222140, Train Acc: 0.589744 | Val Loss: 0.229688, Val Acc: 0.546392\n",
      "Epoch 2627 - Train Loss: 0.222120, Train Acc: 0.589744 | Val Loss: 0.229668, Val Acc: 0.546392\n",
      "Epoch 2628 - Train Loss: 0.222100, Train Acc: 0.589744 | Val Loss: 0.229649, Val Acc: 0.546392\n",
      "Epoch 2629 - Train Loss: 0.222080, Train Acc: 0.589744 | Val Loss: 0.229629, Val Acc: 0.546392\n",
      "Epoch 2630 - Train Loss: 0.222060, Train Acc: 0.589744 | Val Loss: 0.229610, Val Acc: 0.546392\n",
      "Epoch 2631 - Train Loss: 0.222039, Train Acc: 0.589744 | Val Loss: 0.229591, Val Acc: 0.546392\n",
      "Epoch 2632 - Train Loss: 0.222019, Train Acc: 0.589744 | Val Loss: 0.229571, Val Acc: 0.546392\n",
      "Epoch 2633 - Train Loss: 0.221999, Train Acc: 0.589744 | Val Loss: 0.229552, Val Acc: 0.546392\n",
      "Epoch 2634 - Train Loss: 0.221979, Train Acc: 0.589744 | Val Loss: 0.229532, Val Acc: 0.546392\n",
      "Epoch 2635 - Train Loss: 0.221959, Train Acc: 0.589744 | Val Loss: 0.229513, Val Acc: 0.546392\n",
      "Epoch 2636 - Train Loss: 0.221939, Train Acc: 0.589744 | Val Loss: 0.229494, Val Acc: 0.546392\n",
      "Epoch 2637 - Train Loss: 0.221919, Train Acc: 0.589744 | Val Loss: 0.229474, Val Acc: 0.546392\n",
      "Epoch 2638 - Train Loss: 0.221899, Train Acc: 0.589744 | Val Loss: 0.229455, Val Acc: 0.546392\n",
      "Epoch 2639 - Train Loss: 0.221878, Train Acc: 0.589744 | Val Loss: 0.229436, Val Acc: 0.546392\n",
      "Epoch 2640 - Train Loss: 0.221858, Train Acc: 0.589744 | Val Loss: 0.229416, Val Acc: 0.546392\n",
      "Epoch 2641 - Train Loss: 0.221838, Train Acc: 0.589744 | Val Loss: 0.229397, Val Acc: 0.546392\n",
      "Epoch 2642 - Train Loss: 0.221818, Train Acc: 0.589744 | Val Loss: 0.229377, Val Acc: 0.546392\n",
      "Epoch 2643 - Train Loss: 0.221798, Train Acc: 0.589744 | Val Loss: 0.229358, Val Acc: 0.546392\n",
      "Epoch 2644 - Train Loss: 0.221777, Train Acc: 0.589744 | Val Loss: 0.229338, Val Acc: 0.546392\n",
      "Epoch 2645 - Train Loss: 0.221757, Train Acc: 0.589744 | Val Loss: 0.229319, Val Acc: 0.546392\n",
      "Epoch 2646 - Train Loss: 0.221737, Train Acc: 0.589744 | Val Loss: 0.229299, Val Acc: 0.546392\n",
      "Epoch 2647 - Train Loss: 0.221717, Train Acc: 0.589744 | Val Loss: 0.229280, Val Acc: 0.546392\n",
      "Epoch 2648 - Train Loss: 0.221696, Train Acc: 0.589744 | Val Loss: 0.229261, Val Acc: 0.546392\n",
      "Epoch 2649 - Train Loss: 0.221676, Train Acc: 0.589744 | Val Loss: 0.229241, Val Acc: 0.546392\n",
      "Epoch 2650 - Train Loss: 0.221656, Train Acc: 0.589744 | Val Loss: 0.229222, Val Acc: 0.546392\n",
      "Epoch 2651 - Train Loss: 0.221636, Train Acc: 0.591026 | Val Loss: 0.229202, Val Acc: 0.546392\n",
      "Epoch 2652 - Train Loss: 0.221616, Train Acc: 0.591026 | Val Loss: 0.229183, Val Acc: 0.546392\n",
      "Epoch 2653 - Train Loss: 0.221596, Train Acc: 0.591026 | Val Loss: 0.229163, Val Acc: 0.546392\n",
      "Epoch 2654 - Train Loss: 0.221575, Train Acc: 0.591026 | Val Loss: 0.229144, Val Acc: 0.546392\n",
      "Epoch 2655 - Train Loss: 0.221555, Train Acc: 0.591026 | Val Loss: 0.229124, Val Acc: 0.546392\n",
      "Epoch 2656 - Train Loss: 0.221535, Train Acc: 0.591026 | Val Loss: 0.229105, Val Acc: 0.546392\n",
      "Epoch 2657 - Train Loss: 0.221515, Train Acc: 0.591026 | Val Loss: 0.229086, Val Acc: 0.546392\n",
      "Epoch 2658 - Train Loss: 0.221495, Train Acc: 0.591026 | Val Loss: 0.229066, Val Acc: 0.546392\n",
      "Epoch 2659 - Train Loss: 0.221475, Train Acc: 0.591026 | Val Loss: 0.229047, Val Acc: 0.556701\n",
      "Epoch 2660 - Train Loss: 0.221455, Train Acc: 0.591026 | Val Loss: 0.229027, Val Acc: 0.556701\n",
      "Epoch 2661 - Train Loss: 0.221435, Train Acc: 0.591026 | Val Loss: 0.229008, Val Acc: 0.556701\n",
      "Epoch 2662 - Train Loss: 0.221415, Train Acc: 0.591026 | Val Loss: 0.228988, Val Acc: 0.556701\n",
      "Epoch 2663 - Train Loss: 0.221395, Train Acc: 0.591026 | Val Loss: 0.228969, Val Acc: 0.556701\n",
      "Epoch 2664 - Train Loss: 0.221375, Train Acc: 0.591026 | Val Loss: 0.228949, Val Acc: 0.556701\n",
      "Epoch 2665 - Train Loss: 0.221355, Train Acc: 0.591026 | Val Loss: 0.228930, Val Acc: 0.556701\n",
      "Epoch 2666 - Train Loss: 0.221335, Train Acc: 0.591026 | Val Loss: 0.228910, Val Acc: 0.556701\n",
      "Epoch 2667 - Train Loss: 0.221315, Train Acc: 0.591026 | Val Loss: 0.228891, Val Acc: 0.556701\n",
      "Epoch 2668 - Train Loss: 0.221295, Train Acc: 0.591026 | Val Loss: 0.228872, Val Acc: 0.556701\n",
      "Epoch 2669 - Train Loss: 0.221274, Train Acc: 0.591026 | Val Loss: 0.228852, Val Acc: 0.556701\n",
      "Epoch 2670 - Train Loss: 0.221254, Train Acc: 0.591026 | Val Loss: 0.228833, Val Acc: 0.556701\n",
      "Epoch 2671 - Train Loss: 0.221234, Train Acc: 0.591026 | Val Loss: 0.228813, Val Acc: 0.556701\n",
      "Epoch 2672 - Train Loss: 0.221214, Train Acc: 0.589744 | Val Loss: 0.228794, Val Acc: 0.556701\n",
      "Epoch 2673 - Train Loss: 0.221194, Train Acc: 0.589744 | Val Loss: 0.228775, Val Acc: 0.556701\n",
      "Epoch 2674 - Train Loss: 0.221174, Train Acc: 0.589744 | Val Loss: 0.228755, Val Acc: 0.556701\n",
      "Epoch 2675 - Train Loss: 0.221154, Train Acc: 0.589744 | Val Loss: 0.228736, Val Acc: 0.556701\n",
      "Epoch 2676 - Train Loss: 0.221134, Train Acc: 0.589744 | Val Loss: 0.228716, Val Acc: 0.556701\n",
      "Epoch 2677 - Train Loss: 0.221114, Train Acc: 0.589744 | Val Loss: 0.228697, Val Acc: 0.556701\n",
      "Epoch 2678 - Train Loss: 0.221094, Train Acc: 0.589744 | Val Loss: 0.228677, Val Acc: 0.556701\n",
      "Epoch 2679 - Train Loss: 0.221074, Train Acc: 0.589744 | Val Loss: 0.228657, Val Acc: 0.556701\n",
      "Epoch 2680 - Train Loss: 0.221054, Train Acc: 0.589744 | Val Loss: 0.228638, Val Acc: 0.556701\n",
      "Epoch 2681 - Train Loss: 0.221034, Train Acc: 0.589744 | Val Loss: 0.228618, Val Acc: 0.556701\n",
      "Epoch 2682 - Train Loss: 0.221014, Train Acc: 0.589744 | Val Loss: 0.228599, Val Acc: 0.556701\n",
      "Epoch 2683 - Train Loss: 0.220994, Train Acc: 0.589744 | Val Loss: 0.228579, Val Acc: 0.556701\n",
      "Epoch 2684 - Train Loss: 0.220974, Train Acc: 0.589744 | Val Loss: 0.228559, Val Acc: 0.556701\n",
      "Epoch 2685 - Train Loss: 0.220954, Train Acc: 0.589744 | Val Loss: 0.228540, Val Acc: 0.556701\n",
      "Epoch 2686 - Train Loss: 0.220933, Train Acc: 0.589744 | Val Loss: 0.228520, Val Acc: 0.556701\n",
      "Epoch 2687 - Train Loss: 0.220913, Train Acc: 0.589744 | Val Loss: 0.228501, Val Acc: 0.556701\n",
      "Epoch 2688 - Train Loss: 0.220893, Train Acc: 0.589744 | Val Loss: 0.228481, Val Acc: 0.556701\n",
      "Epoch 2689 - Train Loss: 0.220873, Train Acc: 0.589744 | Val Loss: 0.228461, Val Acc: 0.556701\n",
      "Epoch 2690 - Train Loss: 0.220853, Train Acc: 0.589744 | Val Loss: 0.228442, Val Acc: 0.556701\n",
      "Epoch 2691 - Train Loss: 0.220833, Train Acc: 0.589744 | Val Loss: 0.228422, Val Acc: 0.556701\n",
      "Epoch 2692 - Train Loss: 0.220812, Train Acc: 0.589744 | Val Loss: 0.228402, Val Acc: 0.556701\n",
      "Epoch 2693 - Train Loss: 0.220792, Train Acc: 0.589744 | Val Loss: 0.228383, Val Acc: 0.556701\n",
      "Epoch 2694 - Train Loss: 0.220772, Train Acc: 0.589744 | Val Loss: 0.228363, Val Acc: 0.556701\n",
      "Epoch 2695 - Train Loss: 0.220752, Train Acc: 0.589744 | Val Loss: 0.228343, Val Acc: 0.556701\n",
      "Epoch 2696 - Train Loss: 0.220732, Train Acc: 0.589744 | Val Loss: 0.228324, Val Acc: 0.556701\n",
      "Epoch 2697 - Train Loss: 0.220712, Train Acc: 0.589744 | Val Loss: 0.228304, Val Acc: 0.556701\n",
      "Epoch 2698 - Train Loss: 0.220691, Train Acc: 0.589744 | Val Loss: 0.228284, Val Acc: 0.556701\n",
      "Epoch 2699 - Train Loss: 0.220671, Train Acc: 0.589744 | Val Loss: 0.228264, Val Acc: 0.556701\n",
      "Epoch 2700 - Train Loss: 0.220651, Train Acc: 0.589744 | Val Loss: 0.228245, Val Acc: 0.556701\n",
      "Epoch 2701 - Train Loss: 0.220631, Train Acc: 0.589744 | Val Loss: 0.228225, Val Acc: 0.556701\n",
      "Epoch 2702 - Train Loss: 0.220611, Train Acc: 0.589744 | Val Loss: 0.228205, Val Acc: 0.556701\n",
      "Epoch 2703 - Train Loss: 0.220590, Train Acc: 0.589744 | Val Loss: 0.228185, Val Acc: 0.556701\n",
      "Epoch 2704 - Train Loss: 0.220570, Train Acc: 0.589744 | Val Loss: 0.228166, Val Acc: 0.556701\n",
      "Epoch 2705 - Train Loss: 0.220550, Train Acc: 0.589744 | Val Loss: 0.228146, Val Acc: 0.556701\n",
      "Epoch 2706 - Train Loss: 0.220530, Train Acc: 0.589744 | Val Loss: 0.228126, Val Acc: 0.556701\n",
      "Epoch 2707 - Train Loss: 0.220510, Train Acc: 0.589744 | Val Loss: 0.228106, Val Acc: 0.556701\n",
      "Epoch 2708 - Train Loss: 0.220490, Train Acc: 0.589744 | Val Loss: 0.228087, Val Acc: 0.556701\n",
      "Epoch 2709 - Train Loss: 0.220470, Train Acc: 0.589744 | Val Loss: 0.228067, Val Acc: 0.556701\n",
      "Epoch 2710 - Train Loss: 0.220449, Train Acc: 0.589744 | Val Loss: 0.228047, Val Acc: 0.556701\n",
      "Epoch 2711 - Train Loss: 0.220429, Train Acc: 0.589744 | Val Loss: 0.228028, Val Acc: 0.556701\n",
      "Epoch 2712 - Train Loss: 0.220409, Train Acc: 0.589744 | Val Loss: 0.228008, Val Acc: 0.556701\n",
      "Epoch 2713 - Train Loss: 0.220389, Train Acc: 0.589744 | Val Loss: 0.227988, Val Acc: 0.556701\n",
      "Epoch 2714 - Train Loss: 0.220369, Train Acc: 0.589744 | Val Loss: 0.227969, Val Acc: 0.556701\n",
      "Epoch 2715 - Train Loss: 0.220349, Train Acc: 0.589744 | Val Loss: 0.227949, Val Acc: 0.556701\n",
      "Epoch 2716 - Train Loss: 0.220329, Train Acc: 0.589744 | Val Loss: 0.227929, Val Acc: 0.556701\n",
      "Epoch 2717 - Train Loss: 0.220309, Train Acc: 0.589744 | Val Loss: 0.227909, Val Acc: 0.556701\n",
      "Epoch 2718 - Train Loss: 0.220289, Train Acc: 0.589744 | Val Loss: 0.227890, Val Acc: 0.556701\n",
      "Epoch 2719 - Train Loss: 0.220269, Train Acc: 0.589744 | Val Loss: 0.227870, Val Acc: 0.556701\n",
      "Epoch 2720 - Train Loss: 0.220249, Train Acc: 0.589744 | Val Loss: 0.227850, Val Acc: 0.556701\n",
      "Epoch 2721 - Train Loss: 0.220229, Train Acc: 0.589744 | Val Loss: 0.227831, Val Acc: 0.556701\n",
      "Epoch 2722 - Train Loss: 0.220209, Train Acc: 0.589744 | Val Loss: 0.227811, Val Acc: 0.556701\n",
      "Epoch 2723 - Train Loss: 0.220189, Train Acc: 0.591026 | Val Loss: 0.227791, Val Acc: 0.556701\n",
      "Epoch 2724 - Train Loss: 0.220169, Train Acc: 0.591026 | Val Loss: 0.227772, Val Acc: 0.556701\n",
      "Epoch 2725 - Train Loss: 0.220149, Train Acc: 0.591026 | Val Loss: 0.227752, Val Acc: 0.556701\n",
      "Epoch 2726 - Train Loss: 0.220129, Train Acc: 0.591026 | Val Loss: 0.227733, Val Acc: 0.556701\n",
      "Epoch 2727 - Train Loss: 0.220109, Train Acc: 0.591026 | Val Loss: 0.227713, Val Acc: 0.556701\n",
      "Epoch 2728 - Train Loss: 0.220089, Train Acc: 0.591026 | Val Loss: 0.227694, Val Acc: 0.556701\n",
      "Epoch 2729 - Train Loss: 0.220069, Train Acc: 0.591026 | Val Loss: 0.227674, Val Acc: 0.556701\n",
      "Epoch 2730 - Train Loss: 0.220049, Train Acc: 0.591026 | Val Loss: 0.227655, Val Acc: 0.556701\n",
      "Epoch 2731 - Train Loss: 0.220029, Train Acc: 0.591026 | Val Loss: 0.227635, Val Acc: 0.556701\n",
      "Epoch 2732 - Train Loss: 0.220009, Train Acc: 0.591026 | Val Loss: 0.227616, Val Acc: 0.556701\n",
      "Epoch 2733 - Train Loss: 0.219989, Train Acc: 0.591026 | Val Loss: 0.227596, Val Acc: 0.556701\n",
      "Epoch 2734 - Train Loss: 0.219969, Train Acc: 0.591026 | Val Loss: 0.227577, Val Acc: 0.556701\n",
      "Epoch 2735 - Train Loss: 0.219949, Train Acc: 0.591026 | Val Loss: 0.227557, Val Acc: 0.556701\n",
      "Epoch 2736 - Train Loss: 0.219929, Train Acc: 0.591026 | Val Loss: 0.227538, Val Acc: 0.556701\n",
      "Epoch 2737 - Train Loss: 0.219909, Train Acc: 0.591026 | Val Loss: 0.227518, Val Acc: 0.556701\n",
      "Epoch 2738 - Train Loss: 0.219889, Train Acc: 0.591026 | Val Loss: 0.227499, Val Acc: 0.556701\n",
      "Epoch 2739 - Train Loss: 0.219869, Train Acc: 0.591026 | Val Loss: 0.227479, Val Acc: 0.556701\n",
      "Epoch 2740 - Train Loss: 0.219850, Train Acc: 0.591026 | Val Loss: 0.227460, Val Acc: 0.556701\n",
      "Epoch 2741 - Train Loss: 0.219830, Train Acc: 0.591026 | Val Loss: 0.227440, Val Acc: 0.556701\n",
      "Epoch 2742 - Train Loss: 0.219810, Train Acc: 0.591026 | Val Loss: 0.227421, Val Acc: 0.556701\n",
      "Epoch 2743 - Train Loss: 0.219790, Train Acc: 0.591026 | Val Loss: 0.227401, Val Acc: 0.556701\n",
      "Epoch 2744 - Train Loss: 0.219770, Train Acc: 0.592308 | Val Loss: 0.227382, Val Acc: 0.556701\n",
      "Epoch 2745 - Train Loss: 0.219750, Train Acc: 0.592308 | Val Loss: 0.227362, Val Acc: 0.556701\n",
      "Epoch 2746 - Train Loss: 0.219730, Train Acc: 0.592308 | Val Loss: 0.227342, Val Acc: 0.556701\n",
      "Epoch 2747 - Train Loss: 0.219710, Train Acc: 0.592308 | Val Loss: 0.227323, Val Acc: 0.556701\n",
      "Epoch 2748 - Train Loss: 0.219690, Train Acc: 0.592308 | Val Loss: 0.227303, Val Acc: 0.556701\n",
      "Epoch 2749 - Train Loss: 0.219670, Train Acc: 0.592308 | Val Loss: 0.227284, Val Acc: 0.556701\n",
      "Epoch 2750 - Train Loss: 0.219650, Train Acc: 0.592308 | Val Loss: 0.227264, Val Acc: 0.556701\n",
      "Epoch 2751 - Train Loss: 0.219630, Train Acc: 0.592308 | Val Loss: 0.227244, Val Acc: 0.556701\n",
      "Epoch 2752 - Train Loss: 0.219610, Train Acc: 0.592308 | Val Loss: 0.227225, Val Acc: 0.556701\n",
      "Epoch 2753 - Train Loss: 0.219590, Train Acc: 0.592308 | Val Loss: 0.227205, Val Acc: 0.556701\n",
      "Epoch 2754 - Train Loss: 0.219570, Train Acc: 0.592308 | Val Loss: 0.227186, Val Acc: 0.556701\n",
      "Epoch 2755 - Train Loss: 0.219550, Train Acc: 0.592308 | Val Loss: 0.227166, Val Acc: 0.556701\n",
      "Epoch 2756 - Train Loss: 0.219530, Train Acc: 0.592308 | Val Loss: 0.227147, Val Acc: 0.556701\n",
      "Epoch 2757 - Train Loss: 0.219511, Train Acc: 0.592308 | Val Loss: 0.227127, Val Acc: 0.556701\n",
      "Epoch 2758 - Train Loss: 0.219491, Train Acc: 0.592308 | Val Loss: 0.227108, Val Acc: 0.556701\n",
      "Epoch 2759 - Train Loss: 0.219471, Train Acc: 0.592308 | Val Loss: 0.227088, Val Acc: 0.556701\n",
      "Epoch 2760 - Train Loss: 0.219451, Train Acc: 0.592308 | Val Loss: 0.227069, Val Acc: 0.556701\n",
      "Epoch 2761 - Train Loss: 0.219431, Train Acc: 0.592308 | Val Loss: 0.227049, Val Acc: 0.556701\n",
      "Epoch 2762 - Train Loss: 0.219411, Train Acc: 0.592308 | Val Loss: 0.227030, Val Acc: 0.556701\n",
      "Epoch 2763 - Train Loss: 0.219391, Train Acc: 0.592308 | Val Loss: 0.227010, Val Acc: 0.556701\n",
      "Epoch 2764 - Train Loss: 0.219371, Train Acc: 0.592308 | Val Loss: 0.226991, Val Acc: 0.556701\n",
      "Epoch 2765 - Train Loss: 0.219351, Train Acc: 0.592308 | Val Loss: 0.226971, Val Acc: 0.556701\n",
      "Epoch 2766 - Train Loss: 0.219331, Train Acc: 0.592308 | Val Loss: 0.226952, Val Acc: 0.556701\n",
      "Epoch 2767 - Train Loss: 0.219311, Train Acc: 0.592308 | Val Loss: 0.226932, Val Acc: 0.556701\n",
      "Epoch 2768 - Train Loss: 0.219291, Train Acc: 0.592308 | Val Loss: 0.226913, Val Acc: 0.556701\n",
      "Epoch 2769 - Train Loss: 0.219271, Train Acc: 0.592308 | Val Loss: 0.226893, Val Acc: 0.556701\n",
      "Epoch 2770 - Train Loss: 0.219251, Train Acc: 0.592308 | Val Loss: 0.226874, Val Acc: 0.556701\n",
      "Epoch 2771 - Train Loss: 0.219231, Train Acc: 0.592308 | Val Loss: 0.226854, Val Acc: 0.556701\n",
      "Epoch 2772 - Train Loss: 0.219211, Train Acc: 0.593590 | Val Loss: 0.226834, Val Acc: 0.556701\n",
      "Epoch 2773 - Train Loss: 0.219191, Train Acc: 0.593590 | Val Loss: 0.226815, Val Acc: 0.556701\n",
      "Epoch 2774 - Train Loss: 0.219171, Train Acc: 0.593590 | Val Loss: 0.226795, Val Acc: 0.556701\n",
      "Epoch 2775 - Train Loss: 0.219151, Train Acc: 0.593590 | Val Loss: 0.226776, Val Acc: 0.556701\n",
      "Epoch 2776 - Train Loss: 0.219131, Train Acc: 0.593590 | Val Loss: 0.226756, Val Acc: 0.556701\n",
      "Epoch 2777 - Train Loss: 0.219111, Train Acc: 0.593590 | Val Loss: 0.226736, Val Acc: 0.556701\n",
      "Epoch 2778 - Train Loss: 0.219091, Train Acc: 0.593590 | Val Loss: 0.226717, Val Acc: 0.556701\n",
      "Epoch 2779 - Train Loss: 0.219071, Train Acc: 0.593590 | Val Loss: 0.226697, Val Acc: 0.556701\n",
      "Epoch 2780 - Train Loss: 0.219051, Train Acc: 0.593590 | Val Loss: 0.226677, Val Acc: 0.556701\n",
      "Epoch 2781 - Train Loss: 0.219031, Train Acc: 0.593590 | Val Loss: 0.226657, Val Acc: 0.556701\n",
      "Epoch 2782 - Train Loss: 0.219011, Train Acc: 0.593590 | Val Loss: 0.226638, Val Acc: 0.556701\n",
      "Epoch 2783 - Train Loss: 0.218991, Train Acc: 0.593590 | Val Loss: 0.226618, Val Acc: 0.556701\n",
      "Epoch 2784 - Train Loss: 0.218971, Train Acc: 0.593590 | Val Loss: 0.226598, Val Acc: 0.556701\n",
      "Epoch 2785 - Train Loss: 0.218951, Train Acc: 0.593590 | Val Loss: 0.226578, Val Acc: 0.556701\n",
      "Epoch 2786 - Train Loss: 0.218931, Train Acc: 0.593590 | Val Loss: 0.226559, Val Acc: 0.556701\n",
      "Epoch 2787 - Train Loss: 0.218911, Train Acc: 0.593590 | Val Loss: 0.226539, Val Acc: 0.556701\n",
      "Epoch 2788 - Train Loss: 0.218891, Train Acc: 0.593590 | Val Loss: 0.226519, Val Acc: 0.556701\n",
      "Epoch 2789 - Train Loss: 0.218871, Train Acc: 0.593590 | Val Loss: 0.226499, Val Acc: 0.556701\n",
      "Epoch 2790 - Train Loss: 0.218851, Train Acc: 0.593590 | Val Loss: 0.226480, Val Acc: 0.556701\n",
      "Epoch 2791 - Train Loss: 0.218830, Train Acc: 0.593590 | Val Loss: 0.226460, Val Acc: 0.556701\n",
      "Epoch 2792 - Train Loss: 0.218810, Train Acc: 0.593590 | Val Loss: 0.226441, Val Acc: 0.556701\n",
      "Epoch 2793 - Train Loss: 0.218790, Train Acc: 0.593590 | Val Loss: 0.226421, Val Acc: 0.556701\n",
      "Epoch 2794 - Train Loss: 0.218770, Train Acc: 0.593590 | Val Loss: 0.226401, Val Acc: 0.556701\n",
      "Epoch 2795 - Train Loss: 0.218750, Train Acc: 0.593590 | Val Loss: 0.226382, Val Acc: 0.556701\n",
      "Epoch 2796 - Train Loss: 0.218730, Train Acc: 0.593590 | Val Loss: 0.226362, Val Acc: 0.556701\n",
      "Epoch 2797 - Train Loss: 0.218710, Train Acc: 0.593590 | Val Loss: 0.226342, Val Acc: 0.556701\n",
      "Epoch 2798 - Train Loss: 0.218689, Train Acc: 0.593590 | Val Loss: 0.226322, Val Acc: 0.556701\n",
      "Epoch 2799 - Train Loss: 0.218669, Train Acc: 0.593590 | Val Loss: 0.226303, Val Acc: 0.556701\n",
      "Epoch 2800 - Train Loss: 0.218649, Train Acc: 0.593590 | Val Loss: 0.226283, Val Acc: 0.556701\n",
      "Epoch 2801 - Train Loss: 0.218629, Train Acc: 0.593590 | Val Loss: 0.226263, Val Acc: 0.556701\n",
      "Epoch 2802 - Train Loss: 0.218609, Train Acc: 0.593590 | Val Loss: 0.226244, Val Acc: 0.556701\n",
      "Epoch 2803 - Train Loss: 0.218589, Train Acc: 0.593590 | Val Loss: 0.226224, Val Acc: 0.556701\n",
      "Epoch 2804 - Train Loss: 0.218569, Train Acc: 0.593590 | Val Loss: 0.226204, Val Acc: 0.556701\n",
      "Epoch 2805 - Train Loss: 0.218548, Train Acc: 0.593590 | Val Loss: 0.226184, Val Acc: 0.556701\n",
      "Epoch 2806 - Train Loss: 0.218528, Train Acc: 0.593590 | Val Loss: 0.226165, Val Acc: 0.556701\n",
      "Epoch 2807 - Train Loss: 0.218508, Train Acc: 0.593590 | Val Loss: 0.226145, Val Acc: 0.556701\n",
      "Epoch 2808 - Train Loss: 0.218488, Train Acc: 0.593590 | Val Loss: 0.226126, Val Acc: 0.556701\n",
      "Epoch 2809 - Train Loss: 0.218468, Train Acc: 0.593590 | Val Loss: 0.226106, Val Acc: 0.556701\n",
      "Epoch 2810 - Train Loss: 0.218448, Train Acc: 0.593590 | Val Loss: 0.226087, Val Acc: 0.556701\n",
      "Epoch 2811 - Train Loss: 0.218428, Train Acc: 0.593590 | Val Loss: 0.226067, Val Acc: 0.556701\n",
      "Epoch 2812 - Train Loss: 0.218408, Train Acc: 0.593590 | Val Loss: 0.226048, Val Acc: 0.556701\n",
      "Epoch 2813 - Train Loss: 0.218388, Train Acc: 0.593590 | Val Loss: 0.226028, Val Acc: 0.556701\n",
      "Epoch 2814 - Train Loss: 0.218368, Train Acc: 0.593590 | Val Loss: 0.226009, Val Acc: 0.556701\n",
      "Epoch 2815 - Train Loss: 0.218348, Train Acc: 0.593590 | Val Loss: 0.225990, Val Acc: 0.556701\n",
      "Epoch 2816 - Train Loss: 0.218328, Train Acc: 0.593590 | Val Loss: 0.225971, Val Acc: 0.556701\n",
      "Epoch 2817 - Train Loss: 0.218308, Train Acc: 0.593590 | Val Loss: 0.225951, Val Acc: 0.556701\n",
      "Epoch 2818 - Train Loss: 0.218288, Train Acc: 0.593590 | Val Loss: 0.225932, Val Acc: 0.556701\n",
      "Epoch 2819 - Train Loss: 0.218268, Train Acc: 0.593590 | Val Loss: 0.225913, Val Acc: 0.556701\n",
      "Epoch 2820 - Train Loss: 0.218248, Train Acc: 0.593590 | Val Loss: 0.225893, Val Acc: 0.556701\n",
      "Epoch 2821 - Train Loss: 0.218227, Train Acc: 0.593590 | Val Loss: 0.225874, Val Acc: 0.556701\n",
      "Epoch 2822 - Train Loss: 0.218207, Train Acc: 0.593590 | Val Loss: 0.225855, Val Acc: 0.556701\n",
      "Epoch 2823 - Train Loss: 0.218187, Train Acc: 0.593590 | Val Loss: 0.225836, Val Acc: 0.556701\n",
      "Epoch 2824 - Train Loss: 0.218167, Train Acc: 0.593590 | Val Loss: 0.225816, Val Acc: 0.556701\n",
      "Epoch 2825 - Train Loss: 0.218147, Train Acc: 0.593590 | Val Loss: 0.225797, Val Acc: 0.556701\n",
      "Epoch 2826 - Train Loss: 0.218127, Train Acc: 0.593590 | Val Loss: 0.225778, Val Acc: 0.556701\n",
      "Epoch 2827 - Train Loss: 0.218107, Train Acc: 0.593590 | Val Loss: 0.225759, Val Acc: 0.556701\n",
      "Epoch 2828 - Train Loss: 0.218087, Train Acc: 0.593590 | Val Loss: 0.225739, Val Acc: 0.556701\n",
      "Epoch 2829 - Train Loss: 0.218067, Train Acc: 0.593590 | Val Loss: 0.225720, Val Acc: 0.556701\n",
      "Epoch 2830 - Train Loss: 0.218047, Train Acc: 0.593590 | Val Loss: 0.225700, Val Acc: 0.556701\n",
      "Epoch 2831 - Train Loss: 0.218027, Train Acc: 0.593590 | Val Loss: 0.225681, Val Acc: 0.556701\n",
      "Epoch 2832 - Train Loss: 0.218006, Train Acc: 0.593590 | Val Loss: 0.225661, Val Acc: 0.556701\n",
      "Epoch 2833 - Train Loss: 0.217986, Train Acc: 0.593590 | Val Loss: 0.225641, Val Acc: 0.556701\n",
      "Epoch 2834 - Train Loss: 0.217966, Train Acc: 0.593590 | Val Loss: 0.225622, Val Acc: 0.556701\n",
      "Epoch 2835 - Train Loss: 0.217946, Train Acc: 0.593590 | Val Loss: 0.225602, Val Acc: 0.556701\n",
      "Epoch 2836 - Train Loss: 0.217926, Train Acc: 0.593590 | Val Loss: 0.225583, Val Acc: 0.556701\n",
      "Epoch 2837 - Train Loss: 0.217905, Train Acc: 0.593590 | Val Loss: 0.225563, Val Acc: 0.556701\n",
      "Epoch 2838 - Train Loss: 0.217885, Train Acc: 0.593590 | Val Loss: 0.225543, Val Acc: 0.556701\n",
      "Epoch 2839 - Train Loss: 0.217865, Train Acc: 0.593590 | Val Loss: 0.225524, Val Acc: 0.556701\n",
      "Epoch 2840 - Train Loss: 0.217845, Train Acc: 0.593590 | Val Loss: 0.225504, Val Acc: 0.556701\n",
      "Epoch 2841 - Train Loss: 0.217825, Train Acc: 0.593590 | Val Loss: 0.225484, Val Acc: 0.556701\n",
      "Epoch 2842 - Train Loss: 0.217804, Train Acc: 0.593590 | Val Loss: 0.225465, Val Acc: 0.556701\n",
      "Epoch 2843 - Train Loss: 0.217784, Train Acc: 0.593590 | Val Loss: 0.225445, Val Acc: 0.556701\n",
      "Epoch 2844 - Train Loss: 0.217764, Train Acc: 0.593590 | Val Loss: 0.225426, Val Acc: 0.556701\n",
      "Epoch 2845 - Train Loss: 0.217744, Train Acc: 0.593590 | Val Loss: 0.225406, Val Acc: 0.556701\n",
      "Epoch 2846 - Train Loss: 0.217723, Train Acc: 0.593590 | Val Loss: 0.225386, Val Acc: 0.556701\n",
      "Epoch 2847 - Train Loss: 0.217703, Train Acc: 0.593590 | Val Loss: 0.225367, Val Acc: 0.556701\n",
      "Epoch 2848 - Train Loss: 0.217683, Train Acc: 0.593590 | Val Loss: 0.225347, Val Acc: 0.556701\n",
      "Epoch 2849 - Train Loss: 0.217663, Train Acc: 0.593590 | Val Loss: 0.225327, Val Acc: 0.556701\n",
      "Epoch 2850 - Train Loss: 0.217642, Train Acc: 0.593590 | Val Loss: 0.225308, Val Acc: 0.556701\n",
      "Epoch 2851 - Train Loss: 0.217622, Train Acc: 0.594872 | Val Loss: 0.225288, Val Acc: 0.556701\n",
      "Epoch 2852 - Train Loss: 0.217602, Train Acc: 0.594872 | Val Loss: 0.225269, Val Acc: 0.556701\n",
      "Epoch 2853 - Train Loss: 0.217582, Train Acc: 0.594872 | Val Loss: 0.225249, Val Acc: 0.556701\n",
      "Epoch 2854 - Train Loss: 0.217561, Train Acc: 0.594872 | Val Loss: 0.225230, Val Acc: 0.556701\n",
      "Epoch 2855 - Train Loss: 0.217541, Train Acc: 0.594872 | Val Loss: 0.225210, Val Acc: 0.556701\n",
      "Epoch 2856 - Train Loss: 0.217521, Train Acc: 0.594872 | Val Loss: 0.225191, Val Acc: 0.556701\n",
      "Epoch 2857 - Train Loss: 0.217501, Train Acc: 0.594872 | Val Loss: 0.225172, Val Acc: 0.556701\n",
      "Epoch 2858 - Train Loss: 0.217480, Train Acc: 0.594872 | Val Loss: 0.225152, Val Acc: 0.556701\n",
      "Epoch 2859 - Train Loss: 0.217460, Train Acc: 0.594872 | Val Loss: 0.225133, Val Acc: 0.556701\n",
      "Epoch 2860 - Train Loss: 0.217440, Train Acc: 0.594872 | Val Loss: 0.225114, Val Acc: 0.556701\n",
      "Epoch 2861 - Train Loss: 0.217420, Train Acc: 0.594872 | Val Loss: 0.225095, Val Acc: 0.556701\n",
      "Epoch 2862 - Train Loss: 0.217399, Train Acc: 0.594872 | Val Loss: 0.225075, Val Acc: 0.556701\n",
      "Epoch 2863 - Train Loss: 0.217379, Train Acc: 0.594872 | Val Loss: 0.225056, Val Acc: 0.556701\n",
      "Epoch 2864 - Train Loss: 0.217359, Train Acc: 0.594872 | Val Loss: 0.225037, Val Acc: 0.556701\n",
      "Epoch 2865 - Train Loss: 0.217339, Train Acc: 0.594872 | Val Loss: 0.225018, Val Acc: 0.556701\n",
      "Epoch 2866 - Train Loss: 0.217319, Train Acc: 0.594872 | Val Loss: 0.224999, Val Acc: 0.556701\n",
      "Epoch 2867 - Train Loss: 0.217299, Train Acc: 0.593590 | Val Loss: 0.224980, Val Acc: 0.556701\n",
      "Epoch 2868 - Train Loss: 0.217279, Train Acc: 0.593590 | Val Loss: 0.224961, Val Acc: 0.556701\n",
      "Epoch 2869 - Train Loss: 0.217259, Train Acc: 0.593590 | Val Loss: 0.224942, Val Acc: 0.556701\n",
      "Epoch 2870 - Train Loss: 0.217238, Train Acc: 0.593590 | Val Loss: 0.224922, Val Acc: 0.556701\n",
      "Epoch 2871 - Train Loss: 0.217218, Train Acc: 0.593590 | Val Loss: 0.224903, Val Acc: 0.556701\n",
      "Epoch 2872 - Train Loss: 0.217198, Train Acc: 0.593590 | Val Loss: 0.224884, Val Acc: 0.556701\n",
      "Epoch 2873 - Train Loss: 0.217178, Train Acc: 0.593590 | Val Loss: 0.224865, Val Acc: 0.556701\n",
      "Epoch 2874 - Train Loss: 0.217158, Train Acc: 0.593590 | Val Loss: 0.224846, Val Acc: 0.556701\n",
      "Epoch 2875 - Train Loss: 0.217137, Train Acc: 0.593590 | Val Loss: 0.224827, Val Acc: 0.556701\n",
      "Epoch 2876 - Train Loss: 0.217117, Train Acc: 0.593590 | Val Loss: 0.224808, Val Acc: 0.556701\n",
      "Epoch 2877 - Train Loss: 0.217097, Train Acc: 0.593590 | Val Loss: 0.224789, Val Acc: 0.556701\n",
      "Epoch 2878 - Train Loss: 0.217076, Train Acc: 0.593590 | Val Loss: 0.224770, Val Acc: 0.556701\n",
      "Epoch 2879 - Train Loss: 0.217056, Train Acc: 0.593590 | Val Loss: 0.224750, Val Acc: 0.556701\n",
      "Epoch 2880 - Train Loss: 0.217036, Train Acc: 0.593590 | Val Loss: 0.224731, Val Acc: 0.556701\n",
      "Epoch 2881 - Train Loss: 0.217015, Train Acc: 0.593590 | Val Loss: 0.224712, Val Acc: 0.556701\n",
      "Epoch 2882 - Train Loss: 0.216995, Train Acc: 0.593590 | Val Loss: 0.224693, Val Acc: 0.556701\n",
      "Epoch 2883 - Train Loss: 0.216975, Train Acc: 0.593590 | Val Loss: 0.224674, Val Acc: 0.556701\n",
      "Epoch 2884 - Train Loss: 0.216955, Train Acc: 0.593590 | Val Loss: 0.224655, Val Acc: 0.556701\n",
      "Epoch 2885 - Train Loss: 0.216934, Train Acc: 0.593590 | Val Loss: 0.224636, Val Acc: 0.556701\n",
      "Epoch 2886 - Train Loss: 0.216914, Train Acc: 0.594872 | Val Loss: 0.224617, Val Acc: 0.556701\n",
      "Epoch 2887 - Train Loss: 0.216894, Train Acc: 0.596154 | Val Loss: 0.224598, Val Acc: 0.556701\n",
      "Epoch 2888 - Train Loss: 0.216874, Train Acc: 0.596154 | Val Loss: 0.224579, Val Acc: 0.556701\n",
      "Epoch 2889 - Train Loss: 0.216853, Train Acc: 0.596154 | Val Loss: 0.224559, Val Acc: 0.556701\n",
      "Epoch 2890 - Train Loss: 0.216833, Train Acc: 0.596154 | Val Loss: 0.224540, Val Acc: 0.556701\n",
      "Epoch 2891 - Train Loss: 0.216812, Train Acc: 0.596154 | Val Loss: 0.224521, Val Acc: 0.556701\n",
      "Epoch 2892 - Train Loss: 0.216792, Train Acc: 0.596154 | Val Loss: 0.224502, Val Acc: 0.556701\n",
      "Epoch 2893 - Train Loss: 0.216771, Train Acc: 0.596154 | Val Loss: 0.224483, Val Acc: 0.556701\n",
      "Epoch 2894 - Train Loss: 0.216751, Train Acc: 0.596154 | Val Loss: 0.224464, Val Acc: 0.556701\n",
      "Epoch 2895 - Train Loss: 0.216730, Train Acc: 0.596154 | Val Loss: 0.224445, Val Acc: 0.556701\n",
      "Epoch 2896 - Train Loss: 0.216710, Train Acc: 0.596154 | Val Loss: 0.224425, Val Acc: 0.556701\n",
      "Epoch 2897 - Train Loss: 0.216689, Train Acc: 0.596154 | Val Loss: 0.224406, Val Acc: 0.556701\n",
      "Epoch 2898 - Train Loss: 0.216669, Train Acc: 0.596154 | Val Loss: 0.224386, Val Acc: 0.556701\n",
      "Epoch 2899 - Train Loss: 0.216648, Train Acc: 0.596154 | Val Loss: 0.224367, Val Acc: 0.556701\n",
      "Epoch 2900 - Train Loss: 0.216628, Train Acc: 0.596154 | Val Loss: 0.224347, Val Acc: 0.556701\n",
      "Epoch 2901 - Train Loss: 0.216607, Train Acc: 0.596154 | Val Loss: 0.224328, Val Acc: 0.556701\n",
      "Epoch 2902 - Train Loss: 0.216586, Train Acc: 0.596154 | Val Loss: 0.224308, Val Acc: 0.556701\n",
      "Epoch 2903 - Train Loss: 0.216566, Train Acc: 0.596154 | Val Loss: 0.224289, Val Acc: 0.556701\n",
      "Epoch 2904 - Train Loss: 0.216545, Train Acc: 0.596154 | Val Loss: 0.224269, Val Acc: 0.556701\n",
      "Epoch 2905 - Train Loss: 0.216524, Train Acc: 0.596154 | Val Loss: 0.224250, Val Acc: 0.556701\n",
      "Epoch 2906 - Train Loss: 0.216504, Train Acc: 0.596154 | Val Loss: 0.224231, Val Acc: 0.556701\n",
      "Epoch 2907 - Train Loss: 0.216483, Train Acc: 0.596154 | Val Loss: 0.224211, Val Acc: 0.556701\n",
      "Epoch 2908 - Train Loss: 0.216462, Train Acc: 0.596154 | Val Loss: 0.224192, Val Acc: 0.556701\n",
      "Epoch 2909 - Train Loss: 0.216442, Train Acc: 0.596154 | Val Loss: 0.224173, Val Acc: 0.556701\n",
      "Epoch 2910 - Train Loss: 0.216421, Train Acc: 0.596154 | Val Loss: 0.224153, Val Acc: 0.556701\n",
      "Epoch 2911 - Train Loss: 0.216400, Train Acc: 0.596154 | Val Loss: 0.224134, Val Acc: 0.556701\n",
      "Epoch 2912 - Train Loss: 0.216380, Train Acc: 0.596154 | Val Loss: 0.224115, Val Acc: 0.556701\n",
      "Epoch 2913 - Train Loss: 0.216359, Train Acc: 0.596154 | Val Loss: 0.224096, Val Acc: 0.556701\n",
      "Epoch 2914 - Train Loss: 0.216339, Train Acc: 0.596154 | Val Loss: 0.224076, Val Acc: 0.556701\n",
      "Epoch 2915 - Train Loss: 0.216318, Train Acc: 0.596154 | Val Loss: 0.224057, Val Acc: 0.556701\n",
      "Epoch 2916 - Train Loss: 0.216298, Train Acc: 0.596154 | Val Loss: 0.224038, Val Acc: 0.546392\n",
      "Epoch 2917 - Train Loss: 0.216278, Train Acc: 0.596154 | Val Loss: 0.224018, Val Acc: 0.546392\n",
      "Epoch 2918 - Train Loss: 0.216257, Train Acc: 0.596154 | Val Loss: 0.223999, Val Acc: 0.546392\n",
      "Epoch 2919 - Train Loss: 0.216237, Train Acc: 0.596154 | Val Loss: 0.223979, Val Acc: 0.546392\n",
      "Epoch 2920 - Train Loss: 0.216216, Train Acc: 0.597436 | Val Loss: 0.223960, Val Acc: 0.546392\n",
      "Epoch 2921 - Train Loss: 0.216196, Train Acc: 0.597436 | Val Loss: 0.223940, Val Acc: 0.546392\n",
      "Epoch 2922 - Train Loss: 0.216175, Train Acc: 0.597436 | Val Loss: 0.223921, Val Acc: 0.546392\n",
      "Epoch 2923 - Train Loss: 0.216155, Train Acc: 0.597436 | Val Loss: 0.223901, Val Acc: 0.546392\n",
      "Epoch 2924 - Train Loss: 0.216135, Train Acc: 0.597436 | Val Loss: 0.223882, Val Acc: 0.546392\n",
      "Epoch 2925 - Train Loss: 0.216114, Train Acc: 0.597436 | Val Loss: 0.223863, Val Acc: 0.546392\n",
      "Epoch 2926 - Train Loss: 0.216094, Train Acc: 0.597436 | Val Loss: 0.223843, Val Acc: 0.546392\n",
      "Epoch 2927 - Train Loss: 0.216073, Train Acc: 0.597436 | Val Loss: 0.223824, Val Acc: 0.546392\n",
      "Epoch 2928 - Train Loss: 0.216053, Train Acc: 0.597436 | Val Loss: 0.223804, Val Acc: 0.546392\n",
      "Epoch 2929 - Train Loss: 0.216033, Train Acc: 0.598718 | Val Loss: 0.223785, Val Acc: 0.546392\n",
      "Epoch 2930 - Train Loss: 0.216012, Train Acc: 0.598718 | Val Loss: 0.223765, Val Acc: 0.546392\n",
      "Epoch 2931 - Train Loss: 0.215992, Train Acc: 0.598718 | Val Loss: 0.223746, Val Acc: 0.546392\n",
      "Epoch 2932 - Train Loss: 0.215971, Train Acc: 0.598718 | Val Loss: 0.223726, Val Acc: 0.546392\n",
      "Epoch 2933 - Train Loss: 0.215951, Train Acc: 0.598718 | Val Loss: 0.223706, Val Acc: 0.546392\n",
      "Epoch 2934 - Train Loss: 0.215930, Train Acc: 0.598718 | Val Loss: 0.223687, Val Acc: 0.546392\n",
      "Epoch 2935 - Train Loss: 0.215910, Train Acc: 0.598718 | Val Loss: 0.223667, Val Acc: 0.546392\n",
      "Epoch 2936 - Train Loss: 0.215889, Train Acc: 0.598718 | Val Loss: 0.223647, Val Acc: 0.546392\n",
      "Epoch 2937 - Train Loss: 0.215869, Train Acc: 0.598718 | Val Loss: 0.223627, Val Acc: 0.546392\n",
      "Epoch 2938 - Train Loss: 0.215848, Train Acc: 0.598718 | Val Loss: 0.223607, Val Acc: 0.546392\n",
      "Epoch 2939 - Train Loss: 0.215827, Train Acc: 0.598718 | Val Loss: 0.223587, Val Acc: 0.546392\n",
      "Epoch 2940 - Train Loss: 0.215807, Train Acc: 0.598718 | Val Loss: 0.223567, Val Acc: 0.546392\n",
      "Epoch 2941 - Train Loss: 0.215786, Train Acc: 0.598718 | Val Loss: 0.223547, Val Acc: 0.546392\n",
      "Epoch 2942 - Train Loss: 0.215766, Train Acc: 0.598718 | Val Loss: 0.223526, Val Acc: 0.546392\n",
      "Epoch 2943 - Train Loss: 0.215745, Train Acc: 0.598718 | Val Loss: 0.223506, Val Acc: 0.546392\n",
      "Epoch 2944 - Train Loss: 0.215725, Train Acc: 0.598718 | Val Loss: 0.223486, Val Acc: 0.546392\n",
      "Epoch 2945 - Train Loss: 0.215704, Train Acc: 0.598718 | Val Loss: 0.223466, Val Acc: 0.546392\n",
      "Epoch 2946 - Train Loss: 0.215684, Train Acc: 0.598718 | Val Loss: 0.223446, Val Acc: 0.546392\n",
      "Epoch 2947 - Train Loss: 0.215663, Train Acc: 0.598718 | Val Loss: 0.223425, Val Acc: 0.546392\n",
      "Epoch 2948 - Train Loss: 0.215643, Train Acc: 0.598718 | Val Loss: 0.223405, Val Acc: 0.546392\n",
      "Epoch 2949 - Train Loss: 0.215623, Train Acc: 0.598718 | Val Loss: 0.223385, Val Acc: 0.546392\n",
      "Epoch 2950 - Train Loss: 0.215602, Train Acc: 0.598718 | Val Loss: 0.223365, Val Acc: 0.546392\n",
      "Epoch 2951 - Train Loss: 0.215582, Train Acc: 0.598718 | Val Loss: 0.223345, Val Acc: 0.546392\n",
      "Epoch 2952 - Train Loss: 0.215561, Train Acc: 0.598718 | Val Loss: 0.223325, Val Acc: 0.546392\n",
      "Epoch 2953 - Train Loss: 0.215541, Train Acc: 0.600000 | Val Loss: 0.223306, Val Acc: 0.546392\n",
      "Epoch 2954 - Train Loss: 0.215521, Train Acc: 0.600000 | Val Loss: 0.223286, Val Acc: 0.546392\n",
      "Epoch 2955 - Train Loss: 0.215500, Train Acc: 0.600000 | Val Loss: 0.223267, Val Acc: 0.546392\n",
      "Epoch 2956 - Train Loss: 0.215480, Train Acc: 0.600000 | Val Loss: 0.223247, Val Acc: 0.546392\n",
      "Epoch 2957 - Train Loss: 0.215460, Train Acc: 0.600000 | Val Loss: 0.223228, Val Acc: 0.546392\n",
      "Epoch 2958 - Train Loss: 0.215440, Train Acc: 0.600000 | Val Loss: 0.223208, Val Acc: 0.546392\n",
      "Epoch 2959 - Train Loss: 0.215419, Train Acc: 0.600000 | Val Loss: 0.223188, Val Acc: 0.546392\n",
      "Epoch 2960 - Train Loss: 0.215399, Train Acc: 0.600000 | Val Loss: 0.223169, Val Acc: 0.546392\n",
      "Epoch 2961 - Train Loss: 0.215379, Train Acc: 0.600000 | Val Loss: 0.223149, Val Acc: 0.546392\n",
      "Epoch 2962 - Train Loss: 0.215359, Train Acc: 0.600000 | Val Loss: 0.223130, Val Acc: 0.546392\n",
      "Epoch 2963 - Train Loss: 0.215339, Train Acc: 0.600000 | Val Loss: 0.223110, Val Acc: 0.546392\n",
      "Epoch 2964 - Train Loss: 0.215319, Train Acc: 0.600000 | Val Loss: 0.223091, Val Acc: 0.546392\n",
      "Epoch 2965 - Train Loss: 0.215298, Train Acc: 0.600000 | Val Loss: 0.223071, Val Acc: 0.546392\n",
      "Epoch 2966 - Train Loss: 0.215278, Train Acc: 0.600000 | Val Loss: 0.223052, Val Acc: 0.546392\n",
      "Epoch 2967 - Train Loss: 0.215258, Train Acc: 0.600000 | Val Loss: 0.223032, Val Acc: 0.546392\n",
      "Epoch 2968 - Train Loss: 0.215238, Train Acc: 0.600000 | Val Loss: 0.223013, Val Acc: 0.546392\n",
      "Epoch 2969 - Train Loss: 0.215218, Train Acc: 0.600000 | Val Loss: 0.222993, Val Acc: 0.546392\n",
      "Epoch 2970 - Train Loss: 0.215198, Train Acc: 0.600000 | Val Loss: 0.222973, Val Acc: 0.546392\n",
      "Epoch 2971 - Train Loss: 0.215177, Train Acc: 0.600000 | Val Loss: 0.222954, Val Acc: 0.546392\n",
      "Epoch 2972 - Train Loss: 0.215157, Train Acc: 0.600000 | Val Loss: 0.222934, Val Acc: 0.546392\n",
      "Epoch 2973 - Train Loss: 0.215137, Train Acc: 0.600000 | Val Loss: 0.222915, Val Acc: 0.546392\n",
      "Epoch 2974 - Train Loss: 0.215117, Train Acc: 0.600000 | Val Loss: 0.222895, Val Acc: 0.546392\n",
      "Epoch 2975 - Train Loss: 0.215097, Train Acc: 0.600000 | Val Loss: 0.222875, Val Acc: 0.546392\n",
      "Epoch 2976 - Train Loss: 0.215077, Train Acc: 0.600000 | Val Loss: 0.222856, Val Acc: 0.546392\n",
      "Epoch 2977 - Train Loss: 0.215057, Train Acc: 0.600000 | Val Loss: 0.222836, Val Acc: 0.546392\n",
      "Epoch 2978 - Train Loss: 0.215036, Train Acc: 0.600000 | Val Loss: 0.222816, Val Acc: 0.546392\n",
      "Epoch 2979 - Train Loss: 0.215016, Train Acc: 0.600000 | Val Loss: 0.222797, Val Acc: 0.546392\n",
      "Epoch 2980 - Train Loss: 0.214996, Train Acc: 0.600000 | Val Loss: 0.222777, Val Acc: 0.546392\n",
      "Epoch 2981 - Train Loss: 0.214976, Train Acc: 0.600000 | Val Loss: 0.222758, Val Acc: 0.546392\n",
      "Epoch 2982 - Train Loss: 0.214956, Train Acc: 0.600000 | Val Loss: 0.222738, Val Acc: 0.546392\n",
      "Epoch 2983 - Train Loss: 0.214936, Train Acc: 0.600000 | Val Loss: 0.222718, Val Acc: 0.546392\n",
      "Epoch 2984 - Train Loss: 0.214915, Train Acc: 0.600000 | Val Loss: 0.222699, Val Acc: 0.546392\n",
      "Epoch 2985 - Train Loss: 0.214895, Train Acc: 0.600000 | Val Loss: 0.222679, Val Acc: 0.546392\n",
      "Epoch 2986 - Train Loss: 0.214875, Train Acc: 0.600000 | Val Loss: 0.222660, Val Acc: 0.546392\n",
      "Epoch 2987 - Train Loss: 0.214856, Train Acc: 0.600000 | Val Loss: 0.222640, Val Acc: 0.546392\n",
      "Epoch 2988 - Train Loss: 0.214836, Train Acc: 0.600000 | Val Loss: 0.222621, Val Acc: 0.546392\n",
      "Epoch 2989 - Train Loss: 0.214816, Train Acc: 0.600000 | Val Loss: 0.222601, Val Acc: 0.546392\n",
      "Epoch 2990 - Train Loss: 0.214796, Train Acc: 0.600000 | Val Loss: 0.222582, Val Acc: 0.546392\n",
      "Epoch 2991 - Train Loss: 0.214776, Train Acc: 0.598718 | Val Loss: 0.222563, Val Acc: 0.546392\n",
      "Epoch 2992 - Train Loss: 0.214756, Train Acc: 0.598718 | Val Loss: 0.222543, Val Acc: 0.546392\n",
      "Epoch 2993 - Train Loss: 0.214736, Train Acc: 0.598718 | Val Loss: 0.222524, Val Acc: 0.546392\n",
      "Epoch 2994 - Train Loss: 0.214716, Train Acc: 0.598718 | Val Loss: 0.222504, Val Acc: 0.546392\n",
      "Epoch 2995 - Train Loss: 0.214696, Train Acc: 0.598718 | Val Loss: 0.222485, Val Acc: 0.546392\n",
      "Epoch 2996 - Train Loss: 0.214676, Train Acc: 0.598718 | Val Loss: 0.222466, Val Acc: 0.546392\n",
      "Epoch 2997 - Train Loss: 0.214656, Train Acc: 0.598718 | Val Loss: 0.222447, Val Acc: 0.546392\n",
      "Epoch 2998 - Train Loss: 0.214636, Train Acc: 0.598718 | Val Loss: 0.222427, Val Acc: 0.546392\n",
      "Epoch 2999 - Train Loss: 0.214616, Train Acc: 0.598718 | Val Loss: 0.222408, Val Acc: 0.546392\n",
      "Epoch 3000 - Train Loss: 0.214596, Train Acc: 0.598718 | Val Loss: 0.222389, Val Acc: 0.546392\n",
      "Epoch 3001 - Train Loss: 0.214576, Train Acc: 0.598718 | Val Loss: 0.222369, Val Acc: 0.546392\n",
      "Epoch 3002 - Train Loss: 0.214557, Train Acc: 0.598718 | Val Loss: 0.222350, Val Acc: 0.546392\n",
      "Epoch 3003 - Train Loss: 0.214537, Train Acc: 0.598718 | Val Loss: 0.222331, Val Acc: 0.546392\n",
      "Epoch 3004 - Train Loss: 0.214517, Train Acc: 0.598718 | Val Loss: 0.222311, Val Acc: 0.546392\n",
      "Epoch 3005 - Train Loss: 0.214497, Train Acc: 0.598718 | Val Loss: 0.222292, Val Acc: 0.546392\n",
      "Epoch 3006 - Train Loss: 0.214477, Train Acc: 0.598718 | Val Loss: 0.222272, Val Acc: 0.546392\n",
      "Epoch 3007 - Train Loss: 0.214457, Train Acc: 0.598718 | Val Loss: 0.222253, Val Acc: 0.546392\n",
      "Epoch 3008 - Train Loss: 0.214437, Train Acc: 0.598718 | Val Loss: 0.222233, Val Acc: 0.546392\n",
      "Epoch 3009 - Train Loss: 0.214417, Train Acc: 0.598718 | Val Loss: 0.222214, Val Acc: 0.546392\n",
      "Epoch 3010 - Train Loss: 0.214398, Train Acc: 0.598718 | Val Loss: 0.222195, Val Acc: 0.546392\n",
      "Epoch 3011 - Train Loss: 0.214378, Train Acc: 0.598718 | Val Loss: 0.222175, Val Acc: 0.546392\n",
      "Epoch 3012 - Train Loss: 0.214358, Train Acc: 0.598718 | Val Loss: 0.222156, Val Acc: 0.546392\n",
      "Epoch 3013 - Train Loss: 0.214338, Train Acc: 0.598718 | Val Loss: 0.222137, Val Acc: 0.546392\n",
      "Epoch 3014 - Train Loss: 0.214318, Train Acc: 0.598718 | Val Loss: 0.222117, Val Acc: 0.546392\n",
      "Epoch 3015 - Train Loss: 0.214298, Train Acc: 0.598718 | Val Loss: 0.222098, Val Acc: 0.546392\n",
      "Epoch 3016 - Train Loss: 0.214278, Train Acc: 0.598718 | Val Loss: 0.222079, Val Acc: 0.546392\n",
      "Epoch 3017 - Train Loss: 0.214258, Train Acc: 0.598718 | Val Loss: 0.222060, Val Acc: 0.546392\n",
      "Epoch 3018 - Train Loss: 0.214238, Train Acc: 0.598718 | Val Loss: 0.222041, Val Acc: 0.546392\n",
      "Epoch 3019 - Train Loss: 0.214218, Train Acc: 0.598718 | Val Loss: 0.222022, Val Acc: 0.546392\n",
      "Epoch 3020 - Train Loss: 0.214198, Train Acc: 0.598718 | Val Loss: 0.222002, Val Acc: 0.546392\n",
      "Epoch 3021 - Train Loss: 0.214178, Train Acc: 0.600000 | Val Loss: 0.221983, Val Acc: 0.546392\n",
      "Epoch 3022 - Train Loss: 0.214158, Train Acc: 0.600000 | Val Loss: 0.221964, Val Acc: 0.546392\n",
      "Epoch 3023 - Train Loss: 0.214138, Train Acc: 0.600000 | Val Loss: 0.221945, Val Acc: 0.546392\n",
      "Epoch 3024 - Train Loss: 0.214119, Train Acc: 0.601282 | Val Loss: 0.221926, Val Acc: 0.546392\n",
      "Epoch 3025 - Train Loss: 0.214099, Train Acc: 0.601282 | Val Loss: 0.221907, Val Acc: 0.546392\n",
      "Epoch 3026 - Train Loss: 0.214079, Train Acc: 0.601282 | Val Loss: 0.221888, Val Acc: 0.556701\n",
      "Epoch 3027 - Train Loss: 0.214059, Train Acc: 0.601282 | Val Loss: 0.221868, Val Acc: 0.556701\n",
      "Epoch 3028 - Train Loss: 0.214039, Train Acc: 0.601282 | Val Loss: 0.221849, Val Acc: 0.556701\n",
      "Epoch 3029 - Train Loss: 0.214019, Train Acc: 0.600000 | Val Loss: 0.221830, Val Acc: 0.556701\n",
      "Epoch 3030 - Train Loss: 0.214000, Train Acc: 0.600000 | Val Loss: 0.221811, Val Acc: 0.556701\n",
      "Epoch 3031 - Train Loss: 0.213980, Train Acc: 0.600000 | Val Loss: 0.221792, Val Acc: 0.556701\n",
      "Epoch 3032 - Train Loss: 0.213960, Train Acc: 0.600000 | Val Loss: 0.221773, Val Acc: 0.556701\n",
      "Epoch 3033 - Train Loss: 0.213940, Train Acc: 0.600000 | Val Loss: 0.221754, Val Acc: 0.556701\n",
      "Epoch 3034 - Train Loss: 0.213921, Train Acc: 0.600000 | Val Loss: 0.221735, Val Acc: 0.556701\n",
      "Epoch 3035 - Train Loss: 0.213901, Train Acc: 0.600000 | Val Loss: 0.221716, Val Acc: 0.556701\n",
      "Epoch 3036 - Train Loss: 0.213881, Train Acc: 0.600000 | Val Loss: 0.221697, Val Acc: 0.556701\n",
      "Epoch 3037 - Train Loss: 0.213862, Train Acc: 0.600000 | Val Loss: 0.221678, Val Acc: 0.556701\n",
      "Epoch 3038 - Train Loss: 0.213842, Train Acc: 0.600000 | Val Loss: 0.221659, Val Acc: 0.556701\n",
      "Epoch 3039 - Train Loss: 0.213822, Train Acc: 0.600000 | Val Loss: 0.221640, Val Acc: 0.556701\n",
      "Epoch 3040 - Train Loss: 0.213802, Train Acc: 0.600000 | Val Loss: 0.221620, Val Acc: 0.556701\n",
      "Epoch 3041 - Train Loss: 0.213783, Train Acc: 0.600000 | Val Loss: 0.221601, Val Acc: 0.556701\n",
      "Epoch 3042 - Train Loss: 0.213763, Train Acc: 0.600000 | Val Loss: 0.221582, Val Acc: 0.556701\n",
      "Epoch 3043 - Train Loss: 0.213743, Train Acc: 0.601282 | Val Loss: 0.221563, Val Acc: 0.556701\n",
      "Epoch 3044 - Train Loss: 0.213724, Train Acc: 0.601282 | Val Loss: 0.221544, Val Acc: 0.556701\n",
      "Epoch 3045 - Train Loss: 0.213704, Train Acc: 0.601282 | Val Loss: 0.221525, Val Acc: 0.556701\n",
      "Epoch 3046 - Train Loss: 0.213684, Train Acc: 0.601282 | Val Loss: 0.221506, Val Acc: 0.556701\n",
      "Epoch 3047 - Train Loss: 0.213665, Train Acc: 0.601282 | Val Loss: 0.221487, Val Acc: 0.556701\n",
      "Epoch 3048 - Train Loss: 0.213645, Train Acc: 0.601282 | Val Loss: 0.221468, Val Acc: 0.556701\n",
      "Epoch 3049 - Train Loss: 0.213625, Train Acc: 0.601282 | Val Loss: 0.221449, Val Acc: 0.556701\n",
      "Epoch 3050 - Train Loss: 0.213606, Train Acc: 0.601282 | Val Loss: 0.221430, Val Acc: 0.556701\n",
      "Epoch 3051 - Train Loss: 0.213586, Train Acc: 0.601282 | Val Loss: 0.221411, Val Acc: 0.556701\n",
      "Epoch 3052 - Train Loss: 0.213566, Train Acc: 0.601282 | Val Loss: 0.221392, Val Acc: 0.556701\n",
      "Epoch 3053 - Train Loss: 0.213547, Train Acc: 0.601282 | Val Loss: 0.221373, Val Acc: 0.556701\n",
      "Epoch 3054 - Train Loss: 0.213527, Train Acc: 0.601282 | Val Loss: 0.221354, Val Acc: 0.556701\n",
      "Epoch 3055 - Train Loss: 0.213507, Train Acc: 0.601282 | Val Loss: 0.221335, Val Acc: 0.556701\n",
      "Epoch 3056 - Train Loss: 0.213487, Train Acc: 0.601282 | Val Loss: 0.221316, Val Acc: 0.556701\n",
      "Epoch 3057 - Train Loss: 0.213468, Train Acc: 0.601282 | Val Loss: 0.221297, Val Acc: 0.556701\n",
      "Epoch 3058 - Train Loss: 0.213448, Train Acc: 0.601282 | Val Loss: 0.221278, Val Acc: 0.556701\n",
      "Epoch 3059 - Train Loss: 0.213428, Train Acc: 0.601282 | Val Loss: 0.221260, Val Acc: 0.556701\n",
      "Epoch 3060 - Train Loss: 0.213409, Train Acc: 0.601282 | Val Loss: 0.221241, Val Acc: 0.556701\n",
      "Epoch 3061 - Train Loss: 0.213389, Train Acc: 0.601282 | Val Loss: 0.221223, Val Acc: 0.556701\n",
      "Epoch 3062 - Train Loss: 0.213369, Train Acc: 0.601282 | Val Loss: 0.221204, Val Acc: 0.556701\n",
      "Epoch 3063 - Train Loss: 0.213349, Train Acc: 0.601282 | Val Loss: 0.221186, Val Acc: 0.556701\n",
      "Epoch 3064 - Train Loss: 0.213330, Train Acc: 0.601282 | Val Loss: 0.221167, Val Acc: 0.556701\n",
      "Epoch 3065 - Train Loss: 0.213310, Train Acc: 0.601282 | Val Loss: 0.221148, Val Acc: 0.556701\n",
      "Epoch 3066 - Train Loss: 0.213290, Train Acc: 0.601282 | Val Loss: 0.221130, Val Acc: 0.556701\n",
      "Epoch 3067 - Train Loss: 0.213270, Train Acc: 0.601282 | Val Loss: 0.221111, Val Acc: 0.556701\n",
      "Epoch 3068 - Train Loss: 0.213251, Train Acc: 0.601282 | Val Loss: 0.221093, Val Acc: 0.556701\n",
      "Epoch 3069 - Train Loss: 0.213231, Train Acc: 0.601282 | Val Loss: 0.221074, Val Acc: 0.556701\n",
      "Epoch 3070 - Train Loss: 0.213212, Train Acc: 0.601282 | Val Loss: 0.221055, Val Acc: 0.556701\n",
      "Epoch 3071 - Train Loss: 0.213192, Train Acc: 0.601282 | Val Loss: 0.221037, Val Acc: 0.556701\n",
      "Epoch 3072 - Train Loss: 0.213172, Train Acc: 0.602564 | Val Loss: 0.221018, Val Acc: 0.556701\n",
      "Epoch 3073 - Train Loss: 0.213153, Train Acc: 0.602564 | Val Loss: 0.220999, Val Acc: 0.556701\n",
      "Epoch 3074 - Train Loss: 0.213133, Train Acc: 0.602564 | Val Loss: 0.220981, Val Acc: 0.556701\n",
      "Epoch 3075 - Train Loss: 0.213114, Train Acc: 0.603846 | Val Loss: 0.220962, Val Acc: 0.556701\n",
      "Epoch 3076 - Train Loss: 0.213094, Train Acc: 0.603846 | Val Loss: 0.220943, Val Acc: 0.556701\n",
      "Epoch 3077 - Train Loss: 0.213075, Train Acc: 0.603846 | Val Loss: 0.220925, Val Acc: 0.556701\n",
      "Epoch 3078 - Train Loss: 0.213055, Train Acc: 0.603846 | Val Loss: 0.220906, Val Acc: 0.556701\n",
      "Epoch 3079 - Train Loss: 0.213036, Train Acc: 0.603846 | Val Loss: 0.220887, Val Acc: 0.556701\n",
      "Epoch 3080 - Train Loss: 0.213016, Train Acc: 0.603846 | Val Loss: 0.220868, Val Acc: 0.556701\n",
      "Epoch 3081 - Train Loss: 0.212996, Train Acc: 0.603846 | Val Loss: 0.220850, Val Acc: 0.556701\n",
      "Epoch 3082 - Train Loss: 0.212977, Train Acc: 0.603846 | Val Loss: 0.220831, Val Acc: 0.556701\n",
      "Epoch 3083 - Train Loss: 0.212958, Train Acc: 0.603846 | Val Loss: 0.220812, Val Acc: 0.556701\n",
      "Epoch 3084 - Train Loss: 0.212938, Train Acc: 0.603846 | Val Loss: 0.220793, Val Acc: 0.556701\n",
      "Epoch 3085 - Train Loss: 0.212919, Train Acc: 0.603846 | Val Loss: 0.220775, Val Acc: 0.556701\n",
      "Epoch 3086 - Train Loss: 0.212899, Train Acc: 0.603846 | Val Loss: 0.220756, Val Acc: 0.556701\n",
      "Epoch 3087 - Train Loss: 0.212880, Train Acc: 0.603846 | Val Loss: 0.220737, Val Acc: 0.556701\n",
      "Epoch 3088 - Train Loss: 0.212860, Train Acc: 0.603846 | Val Loss: 0.220718, Val Acc: 0.556701\n",
      "Epoch 3089 - Train Loss: 0.212841, Train Acc: 0.603846 | Val Loss: 0.220700, Val Acc: 0.556701\n",
      "Epoch 3090 - Train Loss: 0.212821, Train Acc: 0.603846 | Val Loss: 0.220681, Val Acc: 0.556701\n",
      "Epoch 3091 - Train Loss: 0.212802, Train Acc: 0.603846 | Val Loss: 0.220662, Val Acc: 0.556701\n",
      "Epoch 3092 - Train Loss: 0.212782, Train Acc: 0.603846 | Val Loss: 0.220644, Val Acc: 0.556701\n",
      "Epoch 3093 - Train Loss: 0.212763, Train Acc: 0.603846 | Val Loss: 0.220625, Val Acc: 0.556701\n",
      "Epoch 3094 - Train Loss: 0.212743, Train Acc: 0.603846 | Val Loss: 0.220606, Val Acc: 0.556701\n",
      "Epoch 3095 - Train Loss: 0.212724, Train Acc: 0.603846 | Val Loss: 0.220587, Val Acc: 0.556701\n",
      "Epoch 3096 - Train Loss: 0.212704, Train Acc: 0.603846 | Val Loss: 0.220569, Val Acc: 0.556701\n",
      "Epoch 3097 - Train Loss: 0.212685, Train Acc: 0.603846 | Val Loss: 0.220550, Val Acc: 0.556701\n",
      "Epoch 3098 - Train Loss: 0.212665, Train Acc: 0.603846 | Val Loss: 0.220531, Val Acc: 0.556701\n",
      "Epoch 3099 - Train Loss: 0.212646, Train Acc: 0.603846 | Val Loss: 0.220513, Val Acc: 0.556701\n",
      "Epoch 3100 - Train Loss: 0.212626, Train Acc: 0.603846 | Val Loss: 0.220494, Val Acc: 0.556701\n",
      "Epoch 3101 - Train Loss: 0.212607, Train Acc: 0.603846 | Val Loss: 0.220475, Val Acc: 0.556701\n",
      "Epoch 3102 - Train Loss: 0.212587, Train Acc: 0.603846 | Val Loss: 0.220457, Val Acc: 0.556701\n",
      "Epoch 3103 - Train Loss: 0.212568, Train Acc: 0.603846 | Val Loss: 0.220438, Val Acc: 0.556701\n",
      "Epoch 3104 - Train Loss: 0.212548, Train Acc: 0.605128 | Val Loss: 0.220419, Val Acc: 0.556701\n",
      "Epoch 3105 - Train Loss: 0.212529, Train Acc: 0.605128 | Val Loss: 0.220401, Val Acc: 0.556701\n",
      "Epoch 3106 - Train Loss: 0.212509, Train Acc: 0.605128 | Val Loss: 0.220382, Val Acc: 0.556701\n",
      "Epoch 3107 - Train Loss: 0.212490, Train Acc: 0.605128 | Val Loss: 0.220363, Val Acc: 0.556701\n",
      "Epoch 3108 - Train Loss: 0.212470, Train Acc: 0.605128 | Val Loss: 0.220344, Val Acc: 0.556701\n",
      "Epoch 3109 - Train Loss: 0.212451, Train Acc: 0.605128 | Val Loss: 0.220325, Val Acc: 0.556701\n",
      "Epoch 3110 - Train Loss: 0.212432, Train Acc: 0.605128 | Val Loss: 0.220306, Val Acc: 0.556701\n",
      "Epoch 3111 - Train Loss: 0.212412, Train Acc: 0.605128 | Val Loss: 0.220287, Val Acc: 0.556701\n",
      "Epoch 3112 - Train Loss: 0.212393, Train Acc: 0.605128 | Val Loss: 0.220269, Val Acc: 0.556701\n",
      "Epoch 3113 - Train Loss: 0.212374, Train Acc: 0.605128 | Val Loss: 0.220250, Val Acc: 0.556701\n",
      "Epoch 3114 - Train Loss: 0.212354, Train Acc: 0.605128 | Val Loss: 0.220231, Val Acc: 0.556701\n",
      "Epoch 3115 - Train Loss: 0.212335, Train Acc: 0.605128 | Val Loss: 0.220213, Val Acc: 0.556701\n",
      "Epoch 3116 - Train Loss: 0.212316, Train Acc: 0.605128 | Val Loss: 0.220194, Val Acc: 0.556701\n",
      "Epoch 3117 - Train Loss: 0.212296, Train Acc: 0.605128 | Val Loss: 0.220176, Val Acc: 0.556701\n",
      "Epoch 3118 - Train Loss: 0.212277, Train Acc: 0.605128 | Val Loss: 0.220157, Val Acc: 0.556701\n",
      "Epoch 3119 - Train Loss: 0.212258, Train Acc: 0.605128 | Val Loss: 0.220138, Val Acc: 0.556701\n",
      "Epoch 3120 - Train Loss: 0.212238, Train Acc: 0.605128 | Val Loss: 0.220120, Val Acc: 0.556701\n",
      "Epoch 3121 - Train Loss: 0.212219, Train Acc: 0.605128 | Val Loss: 0.220101, Val Acc: 0.556701\n",
      "Epoch 3122 - Train Loss: 0.212200, Train Acc: 0.605128 | Val Loss: 0.220082, Val Acc: 0.556701\n",
      "Epoch 3123 - Train Loss: 0.212180, Train Acc: 0.605128 | Val Loss: 0.220064, Val Acc: 0.556701\n",
      "Epoch 3124 - Train Loss: 0.212161, Train Acc: 0.605128 | Val Loss: 0.220045, Val Acc: 0.556701\n",
      "Epoch 3125 - Train Loss: 0.212142, Train Acc: 0.605128 | Val Loss: 0.220027, Val Acc: 0.556701\n",
      "Epoch 3126 - Train Loss: 0.212123, Train Acc: 0.605128 | Val Loss: 0.220008, Val Acc: 0.556701\n",
      "Epoch 3127 - Train Loss: 0.212103, Train Acc: 0.605128 | Val Loss: 0.219990, Val Acc: 0.556701\n",
      "Epoch 3128 - Train Loss: 0.212084, Train Acc: 0.605128 | Val Loss: 0.219971, Val Acc: 0.556701\n",
      "Epoch 3129 - Train Loss: 0.212065, Train Acc: 0.606410 | Val Loss: 0.219952, Val Acc: 0.556701\n",
      "Epoch 3130 - Train Loss: 0.212045, Train Acc: 0.606410 | Val Loss: 0.219934, Val Acc: 0.556701\n",
      "Epoch 3131 - Train Loss: 0.212026, Train Acc: 0.606410 | Val Loss: 0.219915, Val Acc: 0.556701\n",
      "Epoch 3132 - Train Loss: 0.212007, Train Acc: 0.606410 | Val Loss: 0.219897, Val Acc: 0.556701\n",
      "Epoch 3133 - Train Loss: 0.211988, Train Acc: 0.606410 | Val Loss: 0.219878, Val Acc: 0.556701\n",
      "Epoch 3134 - Train Loss: 0.211969, Train Acc: 0.606410 | Val Loss: 0.219860, Val Acc: 0.556701\n",
      "Epoch 3135 - Train Loss: 0.211949, Train Acc: 0.606410 | Val Loss: 0.219841, Val Acc: 0.556701\n",
      "Epoch 3136 - Train Loss: 0.211930, Train Acc: 0.606410 | Val Loss: 0.219823, Val Acc: 0.556701\n",
      "Epoch 3137 - Train Loss: 0.211911, Train Acc: 0.606410 | Val Loss: 0.219804, Val Acc: 0.556701\n",
      "Epoch 3138 - Train Loss: 0.211892, Train Acc: 0.606410 | Val Loss: 0.219785, Val Acc: 0.556701\n",
      "Epoch 3139 - Train Loss: 0.211873, Train Acc: 0.606410 | Val Loss: 0.219767, Val Acc: 0.556701\n",
      "Epoch 3140 - Train Loss: 0.211854, Train Acc: 0.606410 | Val Loss: 0.219748, Val Acc: 0.556701\n",
      "Epoch 3141 - Train Loss: 0.211835, Train Acc: 0.606410 | Val Loss: 0.219730, Val Acc: 0.567010\n",
      "Epoch 3142 - Train Loss: 0.211816, Train Acc: 0.606410 | Val Loss: 0.219711, Val Acc: 0.567010\n",
      "Epoch 3143 - Train Loss: 0.211797, Train Acc: 0.606410 | Val Loss: 0.219693, Val Acc: 0.567010\n",
      "Epoch 3144 - Train Loss: 0.211778, Train Acc: 0.606410 | Val Loss: 0.219674, Val Acc: 0.567010\n",
      "Epoch 3145 - Train Loss: 0.211759, Train Acc: 0.606410 | Val Loss: 0.219656, Val Acc: 0.567010\n",
      "Epoch 3146 - Train Loss: 0.211740, Train Acc: 0.606410 | Val Loss: 0.219637, Val Acc: 0.567010\n",
      "Epoch 3147 - Train Loss: 0.211721, Train Acc: 0.606410 | Val Loss: 0.219619, Val Acc: 0.567010\n",
      "Epoch 3148 - Train Loss: 0.211702, Train Acc: 0.606410 | Val Loss: 0.219600, Val Acc: 0.567010\n",
      "Epoch 3149 - Train Loss: 0.211683, Train Acc: 0.606410 | Val Loss: 0.219582, Val Acc: 0.567010\n",
      "Epoch 3150 - Train Loss: 0.211664, Train Acc: 0.606410 | Val Loss: 0.219563, Val Acc: 0.567010\n",
      "Epoch 3151 - Train Loss: 0.211645, Train Acc: 0.606410 | Val Loss: 0.219545, Val Acc: 0.567010\n",
      "Epoch 3152 - Train Loss: 0.211626, Train Acc: 0.606410 | Val Loss: 0.219527, Val Acc: 0.567010\n",
      "Epoch 3153 - Train Loss: 0.211607, Train Acc: 0.606410 | Val Loss: 0.219508, Val Acc: 0.567010\n",
      "Epoch 3154 - Train Loss: 0.211588, Train Acc: 0.606410 | Val Loss: 0.219490, Val Acc: 0.567010\n",
      "Epoch 3155 - Train Loss: 0.211569, Train Acc: 0.606410 | Val Loss: 0.219471, Val Acc: 0.567010\n",
      "Epoch 3156 - Train Loss: 0.211550, Train Acc: 0.606410 | Val Loss: 0.219453, Val Acc: 0.567010\n",
      "Epoch 3157 - Train Loss: 0.211531, Train Acc: 0.606410 | Val Loss: 0.219434, Val Acc: 0.567010\n",
      "Epoch 3158 - Train Loss: 0.211512, Train Acc: 0.606410 | Val Loss: 0.219416, Val Acc: 0.567010\n",
      "Epoch 3159 - Train Loss: 0.211493, Train Acc: 0.606410 | Val Loss: 0.219398, Val Acc: 0.567010\n",
      "Epoch 3160 - Train Loss: 0.211474, Train Acc: 0.607692 | Val Loss: 0.219379, Val Acc: 0.567010\n",
      "Epoch 3161 - Train Loss: 0.211455, Train Acc: 0.607692 | Val Loss: 0.219361, Val Acc: 0.567010\n",
      "Epoch 3162 - Train Loss: 0.211436, Train Acc: 0.607692 | Val Loss: 0.219342, Val Acc: 0.567010\n",
      "Epoch 3163 - Train Loss: 0.211417, Train Acc: 0.607692 | Val Loss: 0.219324, Val Acc: 0.567010\n",
      "Epoch 3164 - Train Loss: 0.211398, Train Acc: 0.607692 | Val Loss: 0.219306, Val Acc: 0.567010\n",
      "Epoch 3165 - Train Loss: 0.211380, Train Acc: 0.607692 | Val Loss: 0.219287, Val Acc: 0.567010\n",
      "Epoch 3166 - Train Loss: 0.211361, Train Acc: 0.607692 | Val Loss: 0.219269, Val Acc: 0.567010\n",
      "Epoch 3167 - Train Loss: 0.211342, Train Acc: 0.607692 | Val Loss: 0.219250, Val Acc: 0.567010\n",
      "Epoch 3168 - Train Loss: 0.211323, Train Acc: 0.607692 | Val Loss: 0.219232, Val Acc: 0.567010\n",
      "Epoch 3169 - Train Loss: 0.211304, Train Acc: 0.608974 | Val Loss: 0.219214, Val Acc: 0.567010\n",
      "Epoch 3170 - Train Loss: 0.211285, Train Acc: 0.608974 | Val Loss: 0.219195, Val Acc: 0.567010\n",
      "Epoch 3171 - Train Loss: 0.211266, Train Acc: 0.608974 | Val Loss: 0.219177, Val Acc: 0.567010\n",
      "Epoch 3172 - Train Loss: 0.211247, Train Acc: 0.608974 | Val Loss: 0.219159, Val Acc: 0.567010\n",
      "Epoch 3173 - Train Loss: 0.211228, Train Acc: 0.608974 | Val Loss: 0.219140, Val Acc: 0.567010\n",
      "Epoch 3174 - Train Loss: 0.211209, Train Acc: 0.608974 | Val Loss: 0.219122, Val Acc: 0.567010\n",
      "Epoch 3175 - Train Loss: 0.211190, Train Acc: 0.608974 | Val Loss: 0.219104, Val Acc: 0.567010\n",
      "Epoch 3176 - Train Loss: 0.211172, Train Acc: 0.608974 | Val Loss: 0.219085, Val Acc: 0.567010\n",
      "Epoch 3177 - Train Loss: 0.211153, Train Acc: 0.608974 | Val Loss: 0.219067, Val Acc: 0.567010\n",
      "Epoch 3178 - Train Loss: 0.211134, Train Acc: 0.608974 | Val Loss: 0.219049, Val Acc: 0.567010\n",
      "Epoch 3179 - Train Loss: 0.211115, Train Acc: 0.608974 | Val Loss: 0.219031, Val Acc: 0.567010\n",
      "Epoch 3180 - Train Loss: 0.211096, Train Acc: 0.608974 | Val Loss: 0.219012, Val Acc: 0.567010\n",
      "Epoch 3181 - Train Loss: 0.211077, Train Acc: 0.608974 | Val Loss: 0.218994, Val Acc: 0.567010\n",
      "Epoch 3182 - Train Loss: 0.211058, Train Acc: 0.608974 | Val Loss: 0.218976, Val Acc: 0.567010\n",
      "Epoch 3183 - Train Loss: 0.211039, Train Acc: 0.608974 | Val Loss: 0.218957, Val Acc: 0.567010\n",
      "Epoch 3184 - Train Loss: 0.211020, Train Acc: 0.608974 | Val Loss: 0.218939, Val Acc: 0.567010\n",
      "Epoch 3185 - Train Loss: 0.211002, Train Acc: 0.608974 | Val Loss: 0.218921, Val Acc: 0.567010\n",
      "Epoch 3186 - Train Loss: 0.210983, Train Acc: 0.608974 | Val Loss: 0.218903, Val Acc: 0.567010\n",
      "Epoch 3187 - Train Loss: 0.210964, Train Acc: 0.608974 | Val Loss: 0.218884, Val Acc: 0.567010\n",
      "Epoch 3188 - Train Loss: 0.210945, Train Acc: 0.608974 | Val Loss: 0.218866, Val Acc: 0.567010\n",
      "Epoch 3189 - Train Loss: 0.210926, Train Acc: 0.608974 | Val Loss: 0.218848, Val Acc: 0.567010\n",
      "Epoch 3190 - Train Loss: 0.210907, Train Acc: 0.608974 | Val Loss: 0.218830, Val Acc: 0.567010\n",
      "Epoch 3191 - Train Loss: 0.210889, Train Acc: 0.608974 | Val Loss: 0.218811, Val Acc: 0.567010\n",
      "Epoch 3192 - Train Loss: 0.210870, Train Acc: 0.608974 | Val Loss: 0.218793, Val Acc: 0.567010\n",
      "Epoch 3193 - Train Loss: 0.210851, Train Acc: 0.608974 | Val Loss: 0.218775, Val Acc: 0.567010\n",
      "Epoch 3194 - Train Loss: 0.210832, Train Acc: 0.608974 | Val Loss: 0.218757, Val Acc: 0.567010\n",
      "Epoch 3195 - Train Loss: 0.210814, Train Acc: 0.608974 | Val Loss: 0.218738, Val Acc: 0.567010\n",
      "Epoch 3196 - Train Loss: 0.210795, Train Acc: 0.608974 | Val Loss: 0.218720, Val Acc: 0.567010\n",
      "Epoch 3197 - Train Loss: 0.210776, Train Acc: 0.608974 | Val Loss: 0.218702, Val Acc: 0.567010\n",
      "Epoch 3198 - Train Loss: 0.210757, Train Acc: 0.608974 | Val Loss: 0.218684, Val Acc: 0.567010\n",
      "Epoch 3199 - Train Loss: 0.210739, Train Acc: 0.608974 | Val Loss: 0.218666, Val Acc: 0.567010\n",
      "Epoch 3200 - Train Loss: 0.210720, Train Acc: 0.608974 | Val Loss: 0.218647, Val Acc: 0.567010\n",
      "Epoch 3201 - Train Loss: 0.210701, Train Acc: 0.608974 | Val Loss: 0.218629, Val Acc: 0.567010\n",
      "Epoch 3202 - Train Loss: 0.210683, Train Acc: 0.608974 | Val Loss: 0.218611, Val Acc: 0.567010\n",
      "Epoch 3203 - Train Loss: 0.210664, Train Acc: 0.608974 | Val Loss: 0.218593, Val Acc: 0.567010\n",
      "Epoch 3204 - Train Loss: 0.210645, Train Acc: 0.608974 | Val Loss: 0.218575, Val Acc: 0.567010\n",
      "Epoch 3205 - Train Loss: 0.210626, Train Acc: 0.608974 | Val Loss: 0.218556, Val Acc: 0.567010\n",
      "Epoch 3206 - Train Loss: 0.210608, Train Acc: 0.608974 | Val Loss: 0.218538, Val Acc: 0.567010\n",
      "Epoch 3207 - Train Loss: 0.210589, Train Acc: 0.608974 | Val Loss: 0.218520, Val Acc: 0.567010\n",
      "Epoch 3208 - Train Loss: 0.210570, Train Acc: 0.608974 | Val Loss: 0.218502, Val Acc: 0.567010\n",
      "Epoch 3209 - Train Loss: 0.210552, Train Acc: 0.608974 | Val Loss: 0.218484, Val Acc: 0.567010\n",
      "Epoch 3210 - Train Loss: 0.210533, Train Acc: 0.608974 | Val Loss: 0.218466, Val Acc: 0.567010\n",
      "Epoch 3211 - Train Loss: 0.210514, Train Acc: 0.608974 | Val Loss: 0.218448, Val Acc: 0.567010\n",
      "Epoch 3212 - Train Loss: 0.210495, Train Acc: 0.608974 | Val Loss: 0.218429, Val Acc: 0.567010\n",
      "Epoch 3213 - Train Loss: 0.210477, Train Acc: 0.608974 | Val Loss: 0.218411, Val Acc: 0.567010\n",
      "Epoch 3214 - Train Loss: 0.210458, Train Acc: 0.608974 | Val Loss: 0.218393, Val Acc: 0.567010\n",
      "Epoch 3215 - Train Loss: 0.210439, Train Acc: 0.608974 | Val Loss: 0.218375, Val Acc: 0.567010\n",
      "Epoch 3216 - Train Loss: 0.210421, Train Acc: 0.608974 | Val Loss: 0.218357, Val Acc: 0.567010\n",
      "Epoch 3217 - Train Loss: 0.210402, Train Acc: 0.608974 | Val Loss: 0.218339, Val Acc: 0.567010\n",
      "Epoch 3218 - Train Loss: 0.210383, Train Acc: 0.608974 | Val Loss: 0.218321, Val Acc: 0.567010\n",
      "Epoch 3219 - Train Loss: 0.210364, Train Acc: 0.608974 | Val Loss: 0.218303, Val Acc: 0.567010\n",
      "Epoch 3220 - Train Loss: 0.210346, Train Acc: 0.608974 | Val Loss: 0.218285, Val Acc: 0.567010\n",
      "Epoch 3221 - Train Loss: 0.210327, Train Acc: 0.608974 | Val Loss: 0.218267, Val Acc: 0.567010\n",
      "Epoch 3222 - Train Loss: 0.210308, Train Acc: 0.608974 | Val Loss: 0.218249, Val Acc: 0.567010\n",
      "Epoch 3223 - Train Loss: 0.210290, Train Acc: 0.608974 | Val Loss: 0.218231, Val Acc: 0.567010\n",
      "Epoch 3224 - Train Loss: 0.210271, Train Acc: 0.608974 | Val Loss: 0.218213, Val Acc: 0.567010\n",
      "Epoch 3225 - Train Loss: 0.210252, Train Acc: 0.608974 | Val Loss: 0.218195, Val Acc: 0.567010\n",
      "Epoch 3226 - Train Loss: 0.210234, Train Acc: 0.608974 | Val Loss: 0.218177, Val Acc: 0.567010\n",
      "Epoch 3227 - Train Loss: 0.210215, Train Acc: 0.608974 | Val Loss: 0.218159, Val Acc: 0.567010\n",
      "Epoch 3228 - Train Loss: 0.210196, Train Acc: 0.607692 | Val Loss: 0.218141, Val Acc: 0.567010\n",
      "Epoch 3229 - Train Loss: 0.210177, Train Acc: 0.607692 | Val Loss: 0.218123, Val Acc: 0.567010\n",
      "Epoch 3230 - Train Loss: 0.210159, Train Acc: 0.607692 | Val Loss: 0.218105, Val Acc: 0.567010\n",
      "Epoch 3231 - Train Loss: 0.210140, Train Acc: 0.607692 | Val Loss: 0.218087, Val Acc: 0.567010\n",
      "Epoch 3232 - Train Loss: 0.210121, Train Acc: 0.607692 | Val Loss: 0.218069, Val Acc: 0.567010\n",
      "Epoch 3233 - Train Loss: 0.210103, Train Acc: 0.607692 | Val Loss: 0.218051, Val Acc: 0.567010\n",
      "Epoch 3234 - Train Loss: 0.210084, Train Acc: 0.607692 | Val Loss: 0.218034, Val Acc: 0.567010\n",
      "Epoch 3235 - Train Loss: 0.210065, Train Acc: 0.607692 | Val Loss: 0.218016, Val Acc: 0.567010\n",
      "Epoch 3236 - Train Loss: 0.210047, Train Acc: 0.607692 | Val Loss: 0.217998, Val Acc: 0.567010\n",
      "Epoch 3237 - Train Loss: 0.210028, Train Acc: 0.607692 | Val Loss: 0.217980, Val Acc: 0.567010\n",
      "Epoch 3238 - Train Loss: 0.210009, Train Acc: 0.607692 | Val Loss: 0.217962, Val Acc: 0.567010\n",
      "Epoch 3239 - Train Loss: 0.209991, Train Acc: 0.607692 | Val Loss: 0.217944, Val Acc: 0.567010\n",
      "Epoch 3240 - Train Loss: 0.209972, Train Acc: 0.608974 | Val Loss: 0.217926, Val Acc: 0.567010\n",
      "Epoch 3241 - Train Loss: 0.209953, Train Acc: 0.608974 | Val Loss: 0.217908, Val Acc: 0.567010\n",
      "Epoch 3242 - Train Loss: 0.209935, Train Acc: 0.608974 | Val Loss: 0.217890, Val Acc: 0.567010\n",
      "Epoch 3243 - Train Loss: 0.209916, Train Acc: 0.608974 | Val Loss: 0.217872, Val Acc: 0.567010\n",
      "Epoch 3244 - Train Loss: 0.209897, Train Acc: 0.610256 | Val Loss: 0.217854, Val Acc: 0.567010\n",
      "Epoch 3245 - Train Loss: 0.209879, Train Acc: 0.610256 | Val Loss: 0.217837, Val Acc: 0.567010\n",
      "Epoch 3246 - Train Loss: 0.209860, Train Acc: 0.610256 | Val Loss: 0.217819, Val Acc: 0.567010\n",
      "Epoch 3247 - Train Loss: 0.209841, Train Acc: 0.610256 | Val Loss: 0.217801, Val Acc: 0.567010\n",
      "Epoch 3248 - Train Loss: 0.209823, Train Acc: 0.610256 | Val Loss: 0.217783, Val Acc: 0.567010\n",
      "Epoch 3249 - Train Loss: 0.209804, Train Acc: 0.610256 | Val Loss: 0.217765, Val Acc: 0.567010\n",
      "Epoch 3250 - Train Loss: 0.209786, Train Acc: 0.610256 | Val Loss: 0.217747, Val Acc: 0.567010\n",
      "Epoch 3251 - Train Loss: 0.209767, Train Acc: 0.610256 | Val Loss: 0.217729, Val Acc: 0.567010\n",
      "Epoch 3252 - Train Loss: 0.209748, Train Acc: 0.610256 | Val Loss: 0.217711, Val Acc: 0.567010\n",
      "Epoch 3253 - Train Loss: 0.209730, Train Acc: 0.610256 | Val Loss: 0.217694, Val Acc: 0.567010\n",
      "Epoch 3254 - Train Loss: 0.209711, Train Acc: 0.610256 | Val Loss: 0.217676, Val Acc: 0.567010\n",
      "Epoch 3255 - Train Loss: 0.209693, Train Acc: 0.611538 | Val Loss: 0.217658, Val Acc: 0.567010\n",
      "Epoch 3256 - Train Loss: 0.209674, Train Acc: 0.611538 | Val Loss: 0.217640, Val Acc: 0.567010\n",
      "Epoch 3257 - Train Loss: 0.209656, Train Acc: 0.611538 | Val Loss: 0.217622, Val Acc: 0.567010\n",
      "Epoch 3258 - Train Loss: 0.209637, Train Acc: 0.611538 | Val Loss: 0.217604, Val Acc: 0.567010\n",
      "Epoch 3259 - Train Loss: 0.209618, Train Acc: 0.611538 | Val Loss: 0.217586, Val Acc: 0.567010\n",
      "Epoch 3260 - Train Loss: 0.209600, Train Acc: 0.612821 | Val Loss: 0.217569, Val Acc: 0.567010\n",
      "Epoch 3261 - Train Loss: 0.209581, Train Acc: 0.612821 | Val Loss: 0.217551, Val Acc: 0.567010\n",
      "Epoch 3262 - Train Loss: 0.209563, Train Acc: 0.612821 | Val Loss: 0.217533, Val Acc: 0.567010\n",
      "Epoch 3263 - Train Loss: 0.209544, Train Acc: 0.612821 | Val Loss: 0.217515, Val Acc: 0.567010\n",
      "Epoch 3264 - Train Loss: 0.209526, Train Acc: 0.612821 | Val Loss: 0.217497, Val Acc: 0.567010\n",
      "Epoch 3265 - Train Loss: 0.209507, Train Acc: 0.612821 | Val Loss: 0.217480, Val Acc: 0.567010\n",
      "Epoch 3266 - Train Loss: 0.209489, Train Acc: 0.612821 | Val Loss: 0.217462, Val Acc: 0.567010\n",
      "Epoch 3267 - Train Loss: 0.209470, Train Acc: 0.612821 | Val Loss: 0.217444, Val Acc: 0.567010\n",
      "Epoch 3268 - Train Loss: 0.209452, Train Acc: 0.612821 | Val Loss: 0.217426, Val Acc: 0.567010\n",
      "Epoch 3269 - Train Loss: 0.209433, Train Acc: 0.612821 | Val Loss: 0.217408, Val Acc: 0.567010\n",
      "Epoch 3270 - Train Loss: 0.209415, Train Acc: 0.612821 | Val Loss: 0.217391, Val Acc: 0.567010\n",
      "Epoch 3271 - Train Loss: 0.209396, Train Acc: 0.612821 | Val Loss: 0.217373, Val Acc: 0.567010\n",
      "Epoch 3272 - Train Loss: 0.209378, Train Acc: 0.612821 | Val Loss: 0.217355, Val Acc: 0.567010\n",
      "Epoch 3273 - Train Loss: 0.209359, Train Acc: 0.612821 | Val Loss: 0.217337, Val Acc: 0.567010\n",
      "Epoch 3274 - Train Loss: 0.209341, Train Acc: 0.612821 | Val Loss: 0.217320, Val Acc: 0.567010\n",
      "Epoch 3275 - Train Loss: 0.209322, Train Acc: 0.612821 | Val Loss: 0.217302, Val Acc: 0.567010\n",
      "Epoch 3276 - Train Loss: 0.209304, Train Acc: 0.612821 | Val Loss: 0.217284, Val Acc: 0.567010\n",
      "Epoch 3277 - Train Loss: 0.209286, Train Acc: 0.612821 | Val Loss: 0.217266, Val Acc: 0.567010\n",
      "Epoch 3278 - Train Loss: 0.209267, Train Acc: 0.612821 | Val Loss: 0.217249, Val Acc: 0.567010\n",
      "Epoch 3279 - Train Loss: 0.209249, Train Acc: 0.614103 | Val Loss: 0.217231, Val Acc: 0.567010\n",
      "Epoch 3280 - Train Loss: 0.209230, Train Acc: 0.614103 | Val Loss: 0.217213, Val Acc: 0.567010\n",
      "Epoch 3281 - Train Loss: 0.209212, Train Acc: 0.614103 | Val Loss: 0.217195, Val Acc: 0.567010\n",
      "Epoch 3282 - Train Loss: 0.209194, Train Acc: 0.615385 | Val Loss: 0.217178, Val Acc: 0.567010\n",
      "Epoch 3283 - Train Loss: 0.209175, Train Acc: 0.615385 | Val Loss: 0.217160, Val Acc: 0.567010\n",
      "Epoch 3284 - Train Loss: 0.209157, Train Acc: 0.616667 | Val Loss: 0.217142, Val Acc: 0.567010\n",
      "Epoch 3285 - Train Loss: 0.209138, Train Acc: 0.616667 | Val Loss: 0.217124, Val Acc: 0.567010\n",
      "Epoch 3286 - Train Loss: 0.209120, Train Acc: 0.616667 | Val Loss: 0.217107, Val Acc: 0.567010\n",
      "Epoch 3287 - Train Loss: 0.209101, Train Acc: 0.616667 | Val Loss: 0.217089, Val Acc: 0.567010\n",
      "Epoch 3288 - Train Loss: 0.209083, Train Acc: 0.616667 | Val Loss: 0.217071, Val Acc: 0.567010\n",
      "Epoch 3289 - Train Loss: 0.209065, Train Acc: 0.616667 | Val Loss: 0.217054, Val Acc: 0.567010\n",
      "Epoch 3290 - Train Loss: 0.209046, Train Acc: 0.616667 | Val Loss: 0.217036, Val Acc: 0.567010\n",
      "Epoch 3291 - Train Loss: 0.209028, Train Acc: 0.616667 | Val Loss: 0.217018, Val Acc: 0.567010\n",
      "Epoch 3292 - Train Loss: 0.209010, Train Acc: 0.616667 | Val Loss: 0.217000, Val Acc: 0.567010\n",
      "Epoch 3293 - Train Loss: 0.208991, Train Acc: 0.616667 | Val Loss: 0.216983, Val Acc: 0.567010\n",
      "Epoch 3294 - Train Loss: 0.208973, Train Acc: 0.616667 | Val Loss: 0.216965, Val Acc: 0.567010\n",
      "Epoch 3295 - Train Loss: 0.208954, Train Acc: 0.616667 | Val Loss: 0.216947, Val Acc: 0.567010\n",
      "Epoch 3296 - Train Loss: 0.208936, Train Acc: 0.616667 | Val Loss: 0.216930, Val Acc: 0.567010\n",
      "Epoch 3297 - Train Loss: 0.208918, Train Acc: 0.616667 | Val Loss: 0.216912, Val Acc: 0.567010\n",
      "Epoch 3298 - Train Loss: 0.208899, Train Acc: 0.616667 | Val Loss: 0.216894, Val Acc: 0.567010\n",
      "Epoch 3299 - Train Loss: 0.208881, Train Acc: 0.616667 | Val Loss: 0.216877, Val Acc: 0.567010\n",
      "Epoch 3300 - Train Loss: 0.208862, Train Acc: 0.616667 | Val Loss: 0.216859, Val Acc: 0.567010\n",
      "Epoch 3301 - Train Loss: 0.208844, Train Acc: 0.616667 | Val Loss: 0.216841, Val Acc: 0.567010\n",
      "Epoch 3302 - Train Loss: 0.208826, Train Acc: 0.616667 | Val Loss: 0.216824, Val Acc: 0.567010\n",
      "Epoch 3303 - Train Loss: 0.208807, Train Acc: 0.616667 | Val Loss: 0.216806, Val Acc: 0.567010\n",
      "Epoch 3304 - Train Loss: 0.208789, Train Acc: 0.616667 | Val Loss: 0.216788, Val Acc: 0.567010\n",
      "Epoch 3305 - Train Loss: 0.208771, Train Acc: 0.616667 | Val Loss: 0.216771, Val Acc: 0.567010\n",
      "Epoch 3306 - Train Loss: 0.208752, Train Acc: 0.616667 | Val Loss: 0.216753, Val Acc: 0.567010\n",
      "Epoch 3307 - Train Loss: 0.208734, Train Acc: 0.616667 | Val Loss: 0.216735, Val Acc: 0.567010\n",
      "Epoch 3308 - Train Loss: 0.208716, Train Acc: 0.616667 | Val Loss: 0.216718, Val Acc: 0.567010\n",
      "Epoch 3309 - Train Loss: 0.208697, Train Acc: 0.616667 | Val Loss: 0.216700, Val Acc: 0.567010\n",
      "Epoch 3310 - Train Loss: 0.208679, Train Acc: 0.615385 | Val Loss: 0.216682, Val Acc: 0.567010\n",
      "Epoch 3311 - Train Loss: 0.208661, Train Acc: 0.615385 | Val Loss: 0.216665, Val Acc: 0.567010\n",
      "Epoch 3312 - Train Loss: 0.208642, Train Acc: 0.615385 | Val Loss: 0.216647, Val Acc: 0.567010\n",
      "Epoch 3313 - Train Loss: 0.208624, Train Acc: 0.615385 | Val Loss: 0.216629, Val Acc: 0.567010\n",
      "Epoch 3314 - Train Loss: 0.208606, Train Acc: 0.615385 | Val Loss: 0.216612, Val Acc: 0.567010\n",
      "Epoch 3315 - Train Loss: 0.208587, Train Acc: 0.615385 | Val Loss: 0.216594, Val Acc: 0.567010\n",
      "Epoch 3316 - Train Loss: 0.208569, Train Acc: 0.615385 | Val Loss: 0.216576, Val Acc: 0.567010\n",
      "Epoch 3317 - Train Loss: 0.208551, Train Acc: 0.615385 | Val Loss: 0.216559, Val Acc: 0.567010\n",
      "Epoch 3318 - Train Loss: 0.208532, Train Acc: 0.615385 | Val Loss: 0.216541, Val Acc: 0.567010\n",
      "Epoch 3319 - Train Loss: 0.208514, Train Acc: 0.615385 | Val Loss: 0.216523, Val Acc: 0.567010\n",
      "Epoch 3320 - Train Loss: 0.208496, Train Acc: 0.615385 | Val Loss: 0.216506, Val Acc: 0.567010\n",
      "Epoch 3321 - Train Loss: 0.208478, Train Acc: 0.615385 | Val Loss: 0.216488, Val Acc: 0.567010\n",
      "Epoch 3322 - Train Loss: 0.208459, Train Acc: 0.615385 | Val Loss: 0.216471, Val Acc: 0.567010\n",
      "Epoch 3323 - Train Loss: 0.208441, Train Acc: 0.615385 | Val Loss: 0.216453, Val Acc: 0.567010\n",
      "Epoch 3324 - Train Loss: 0.208423, Train Acc: 0.615385 | Val Loss: 0.216435, Val Acc: 0.567010\n",
      "Epoch 3325 - Train Loss: 0.208404, Train Acc: 0.615385 | Val Loss: 0.216418, Val Acc: 0.567010\n",
      "Epoch 3326 - Train Loss: 0.208386, Train Acc: 0.615385 | Val Loss: 0.216400, Val Acc: 0.567010\n",
      "Epoch 3327 - Train Loss: 0.208368, Train Acc: 0.615385 | Val Loss: 0.216382, Val Acc: 0.567010\n",
      "Epoch 3328 - Train Loss: 0.208350, Train Acc: 0.615385 | Val Loss: 0.216365, Val Acc: 0.567010\n",
      "Epoch 3329 - Train Loss: 0.208331, Train Acc: 0.615385 | Val Loss: 0.216347, Val Acc: 0.567010\n",
      "Epoch 3330 - Train Loss: 0.208313, Train Acc: 0.615385 | Val Loss: 0.216330, Val Acc: 0.567010\n",
      "Epoch 3331 - Train Loss: 0.208295, Train Acc: 0.615385 | Val Loss: 0.216312, Val Acc: 0.567010\n",
      "Epoch 3332 - Train Loss: 0.208277, Train Acc: 0.615385 | Val Loss: 0.216294, Val Acc: 0.567010\n",
      "Epoch 3333 - Train Loss: 0.208258, Train Acc: 0.615385 | Val Loss: 0.216277, Val Acc: 0.567010\n",
      "Epoch 3334 - Train Loss: 0.208240, Train Acc: 0.615385 | Val Loss: 0.216259, Val Acc: 0.567010\n",
      "Epoch 3335 - Train Loss: 0.208222, Train Acc: 0.615385 | Val Loss: 0.216242, Val Acc: 0.567010\n",
      "Epoch 3336 - Train Loss: 0.208204, Train Acc: 0.615385 | Val Loss: 0.216224, Val Acc: 0.567010\n",
      "Epoch 3337 - Train Loss: 0.208185, Train Acc: 0.615385 | Val Loss: 0.216207, Val Acc: 0.567010\n",
      "Epoch 3338 - Train Loss: 0.208167, Train Acc: 0.615385 | Val Loss: 0.216189, Val Acc: 0.567010\n",
      "Epoch 3339 - Train Loss: 0.208149, Train Acc: 0.615385 | Val Loss: 0.216171, Val Acc: 0.567010\n",
      "Epoch 3340 - Train Loss: 0.208131, Train Acc: 0.615385 | Val Loss: 0.216154, Val Acc: 0.567010\n",
      "Epoch 3341 - Train Loss: 0.208112, Train Acc: 0.615385 | Val Loss: 0.216136, Val Acc: 0.567010\n",
      "Epoch 3342 - Train Loss: 0.208094, Train Acc: 0.615385 | Val Loss: 0.216119, Val Acc: 0.567010\n",
      "Epoch 3343 - Train Loss: 0.208076, Train Acc: 0.615385 | Val Loss: 0.216101, Val Acc: 0.567010\n",
      "Epoch 3344 - Train Loss: 0.208058, Train Acc: 0.615385 | Val Loss: 0.216084, Val Acc: 0.567010\n",
      "Epoch 3345 - Train Loss: 0.208040, Train Acc: 0.615385 | Val Loss: 0.216066, Val Acc: 0.567010\n",
      "Epoch 3346 - Train Loss: 0.208021, Train Acc: 0.615385 | Val Loss: 0.216049, Val Acc: 0.567010\n",
      "Epoch 3347 - Train Loss: 0.208003, Train Acc: 0.615385 | Val Loss: 0.216031, Val Acc: 0.567010\n",
      "Epoch 3348 - Train Loss: 0.207985, Train Acc: 0.615385 | Val Loss: 0.216014, Val Acc: 0.567010\n",
      "Epoch 3349 - Train Loss: 0.207967, Train Acc: 0.615385 | Val Loss: 0.215996, Val Acc: 0.567010\n",
      "Epoch 3350 - Train Loss: 0.207948, Train Acc: 0.615385 | Val Loss: 0.215979, Val Acc: 0.567010\n",
      "Epoch 3351 - Train Loss: 0.207930, Train Acc: 0.615385 | Val Loss: 0.215961, Val Acc: 0.567010\n",
      "Epoch 3352 - Train Loss: 0.207912, Train Acc: 0.615385 | Val Loss: 0.215944, Val Acc: 0.567010\n",
      "Epoch 3353 - Train Loss: 0.207894, Train Acc: 0.614103 | Val Loss: 0.215926, Val Acc: 0.567010\n",
      "Epoch 3354 - Train Loss: 0.207876, Train Acc: 0.614103 | Val Loss: 0.215909, Val Acc: 0.567010\n",
      "Epoch 3355 - Train Loss: 0.207857, Train Acc: 0.614103 | Val Loss: 0.215891, Val Acc: 0.567010\n",
      "Epoch 3356 - Train Loss: 0.207839, Train Acc: 0.614103 | Val Loss: 0.215874, Val Acc: 0.567010\n",
      "Epoch 3357 - Train Loss: 0.207821, Train Acc: 0.614103 | Val Loss: 0.215856, Val Acc: 0.567010\n",
      "Epoch 3358 - Train Loss: 0.207803, Train Acc: 0.614103 | Val Loss: 0.215839, Val Acc: 0.567010\n",
      "Epoch 3359 - Train Loss: 0.207785, Train Acc: 0.614103 | Val Loss: 0.215821, Val Acc: 0.567010\n",
      "Epoch 3360 - Train Loss: 0.207767, Train Acc: 0.614103 | Val Loss: 0.215804, Val Acc: 0.567010\n",
      "Epoch 3361 - Train Loss: 0.207748, Train Acc: 0.614103 | Val Loss: 0.215786, Val Acc: 0.567010\n",
      "Epoch 3362 - Train Loss: 0.207730, Train Acc: 0.614103 | Val Loss: 0.215769, Val Acc: 0.567010\n",
      "Epoch 3363 - Train Loss: 0.207712, Train Acc: 0.614103 | Val Loss: 0.215751, Val Acc: 0.567010\n",
      "Epoch 3364 - Train Loss: 0.207694, Train Acc: 0.614103 | Val Loss: 0.215734, Val Acc: 0.567010\n",
      "Epoch 3365 - Train Loss: 0.207676, Train Acc: 0.614103 | Val Loss: 0.215716, Val Acc: 0.567010\n",
      "Epoch 3366 - Train Loss: 0.207658, Train Acc: 0.614103 | Val Loss: 0.215699, Val Acc: 0.567010\n",
      "Epoch 3367 - Train Loss: 0.207639, Train Acc: 0.614103 | Val Loss: 0.215681, Val Acc: 0.567010\n",
      "Epoch 3368 - Train Loss: 0.207621, Train Acc: 0.614103 | Val Loss: 0.215664, Val Acc: 0.567010\n",
      "Epoch 3369 - Train Loss: 0.207603, Train Acc: 0.614103 | Val Loss: 0.215647, Val Acc: 0.567010\n",
      "Epoch 3370 - Train Loss: 0.207585, Train Acc: 0.614103 | Val Loss: 0.215629, Val Acc: 0.567010\n",
      "Epoch 3371 - Train Loss: 0.207567, Train Acc: 0.614103 | Val Loss: 0.215612, Val Acc: 0.567010\n",
      "Epoch 3372 - Train Loss: 0.207549, Train Acc: 0.614103 | Val Loss: 0.215594, Val Acc: 0.567010\n",
      "Epoch 3373 - Train Loss: 0.207530, Train Acc: 0.614103 | Val Loss: 0.215577, Val Acc: 0.567010\n",
      "Epoch 3374 - Train Loss: 0.207512, Train Acc: 0.614103 | Val Loss: 0.215559, Val Acc: 0.567010\n",
      "Epoch 3375 - Train Loss: 0.207494, Train Acc: 0.614103 | Val Loss: 0.215542, Val Acc: 0.567010\n",
      "Epoch 3376 - Train Loss: 0.207476, Train Acc: 0.614103 | Val Loss: 0.215525, Val Acc: 0.567010\n",
      "Epoch 3377 - Train Loss: 0.207458, Train Acc: 0.614103 | Val Loss: 0.215507, Val Acc: 0.567010\n",
      "Epoch 3378 - Train Loss: 0.207440, Train Acc: 0.614103 | Val Loss: 0.215490, Val Acc: 0.567010\n",
      "Epoch 3379 - Train Loss: 0.207421, Train Acc: 0.614103 | Val Loss: 0.215472, Val Acc: 0.567010\n",
      "Epoch 3380 - Train Loss: 0.207403, Train Acc: 0.614103 | Val Loss: 0.215455, Val Acc: 0.567010\n",
      "Epoch 3381 - Train Loss: 0.207385, Train Acc: 0.614103 | Val Loss: 0.215438, Val Acc: 0.567010\n",
      "Epoch 3382 - Train Loss: 0.207367, Train Acc: 0.614103 | Val Loss: 0.215420, Val Acc: 0.567010\n",
      "Epoch 3383 - Train Loss: 0.207349, Train Acc: 0.614103 | Val Loss: 0.215403, Val Acc: 0.567010\n",
      "Epoch 3384 - Train Loss: 0.207331, Train Acc: 0.614103 | Val Loss: 0.215385, Val Acc: 0.567010\n",
      "Epoch 3385 - Train Loss: 0.207313, Train Acc: 0.614103 | Val Loss: 0.215368, Val Acc: 0.567010\n",
      "Epoch 3386 - Train Loss: 0.207295, Train Acc: 0.614103 | Val Loss: 0.215351, Val Acc: 0.567010\n",
      "Epoch 3387 - Train Loss: 0.207277, Train Acc: 0.614103 | Val Loss: 0.215333, Val Acc: 0.567010\n",
      "Epoch 3388 - Train Loss: 0.207258, Train Acc: 0.614103 | Val Loss: 0.215316, Val Acc: 0.567010\n",
      "Epoch 3389 - Train Loss: 0.207240, Train Acc: 0.614103 | Val Loss: 0.215298, Val Acc: 0.567010\n",
      "Epoch 3390 - Train Loss: 0.207222, Train Acc: 0.614103 | Val Loss: 0.215281, Val Acc: 0.567010\n",
      "Epoch 3391 - Train Loss: 0.207204, Train Acc: 0.614103 | Val Loss: 0.215264, Val Acc: 0.567010\n",
      "Epoch 3392 - Train Loss: 0.207186, Train Acc: 0.614103 | Val Loss: 0.215246, Val Acc: 0.567010\n",
      "Epoch 3393 - Train Loss: 0.207168, Train Acc: 0.614103 | Val Loss: 0.215229, Val Acc: 0.567010\n",
      "Epoch 3394 - Train Loss: 0.207150, Train Acc: 0.614103 | Val Loss: 0.215212, Val Acc: 0.567010\n",
      "Epoch 3395 - Train Loss: 0.207132, Train Acc: 0.614103 | Val Loss: 0.215194, Val Acc: 0.567010\n",
      "Epoch 3396 - Train Loss: 0.207114, Train Acc: 0.614103 | Val Loss: 0.215177, Val Acc: 0.567010\n",
      "Epoch 3397 - Train Loss: 0.207096, Train Acc: 0.614103 | Val Loss: 0.215160, Val Acc: 0.567010\n",
      "Epoch 3398 - Train Loss: 0.207078, Train Acc: 0.614103 | Val Loss: 0.215142, Val Acc: 0.567010\n",
      "Epoch 3399 - Train Loss: 0.207060, Train Acc: 0.614103 | Val Loss: 0.215125, Val Acc: 0.567010\n",
      "Epoch 3400 - Train Loss: 0.207042, Train Acc: 0.614103 | Val Loss: 0.215107, Val Acc: 0.567010\n",
      "Epoch 3401 - Train Loss: 0.207024, Train Acc: 0.614103 | Val Loss: 0.215090, Val Acc: 0.567010\n",
      "Epoch 3402 - Train Loss: 0.207006, Train Acc: 0.614103 | Val Loss: 0.215073, Val Acc: 0.567010\n",
      "Epoch 3403 - Train Loss: 0.206988, Train Acc: 0.614103 | Val Loss: 0.215056, Val Acc: 0.567010\n",
      "Epoch 3404 - Train Loss: 0.206970, Train Acc: 0.614103 | Val Loss: 0.215038, Val Acc: 0.567010\n",
      "Epoch 3405 - Train Loss: 0.206952, Train Acc: 0.614103 | Val Loss: 0.215021, Val Acc: 0.567010\n",
      "Epoch 3406 - Train Loss: 0.206934, Train Acc: 0.614103 | Val Loss: 0.215004, Val Acc: 0.567010\n",
      "Epoch 3407 - Train Loss: 0.206916, Train Acc: 0.614103 | Val Loss: 0.214986, Val Acc: 0.567010\n",
      "Epoch 3408 - Train Loss: 0.206898, Train Acc: 0.614103 | Val Loss: 0.214969, Val Acc: 0.567010\n",
      "Epoch 3409 - Train Loss: 0.206880, Train Acc: 0.614103 | Val Loss: 0.214952, Val Acc: 0.567010\n",
      "Epoch 3410 - Train Loss: 0.206862, Train Acc: 0.614103 | Val Loss: 0.214934, Val Acc: 0.567010\n",
      "Epoch 3411 - Train Loss: 0.206844, Train Acc: 0.614103 | Val Loss: 0.214917, Val Acc: 0.567010\n",
      "Epoch 3412 - Train Loss: 0.206826, Train Acc: 0.614103 | Val Loss: 0.214900, Val Acc: 0.567010\n",
      "Epoch 3413 - Train Loss: 0.206808, Train Acc: 0.614103 | Val Loss: 0.214883, Val Acc: 0.567010\n",
      "Epoch 3414 - Train Loss: 0.206790, Train Acc: 0.614103 | Val Loss: 0.214865, Val Acc: 0.567010\n",
      "Epoch 3415 - Train Loss: 0.206772, Train Acc: 0.614103 | Val Loss: 0.214848, Val Acc: 0.567010\n",
      "Epoch 3416 - Train Loss: 0.206754, Train Acc: 0.614103 | Val Loss: 0.214831, Val Acc: 0.567010\n",
      "Epoch 3417 - Train Loss: 0.206736, Train Acc: 0.614103 | Val Loss: 0.214813, Val Acc: 0.567010\n",
      "Epoch 3418 - Train Loss: 0.206718, Train Acc: 0.614103 | Val Loss: 0.214796, Val Acc: 0.567010\n",
      "Epoch 3419 - Train Loss: 0.206700, Train Acc: 0.614103 | Val Loss: 0.214779, Val Acc: 0.567010\n",
      "Epoch 3420 - Train Loss: 0.206682, Train Acc: 0.614103 | Val Loss: 0.214762, Val Acc: 0.567010\n",
      "Epoch 3421 - Train Loss: 0.206664, Train Acc: 0.614103 | Val Loss: 0.214744, Val Acc: 0.567010\n",
      "Epoch 3422 - Train Loss: 0.206646, Train Acc: 0.614103 | Val Loss: 0.214727, Val Acc: 0.567010\n",
      "Epoch 3423 - Train Loss: 0.206628, Train Acc: 0.614103 | Val Loss: 0.214710, Val Acc: 0.567010\n",
      "Epoch 3424 - Train Loss: 0.206610, Train Acc: 0.614103 | Val Loss: 0.214693, Val Acc: 0.567010\n",
      "Epoch 3425 - Train Loss: 0.206592, Train Acc: 0.614103 | Val Loss: 0.214675, Val Acc: 0.567010\n",
      "Epoch 3426 - Train Loss: 0.206574, Train Acc: 0.614103 | Val Loss: 0.214658, Val Acc: 0.567010\n",
      "Epoch 3427 - Train Loss: 0.206556, Train Acc: 0.614103 | Val Loss: 0.214641, Val Acc: 0.567010\n",
      "Epoch 3428 - Train Loss: 0.206538, Train Acc: 0.614103 | Val Loss: 0.214624, Val Acc: 0.567010\n",
      "Epoch 3429 - Train Loss: 0.206520, Train Acc: 0.614103 | Val Loss: 0.214606, Val Acc: 0.567010\n",
      "Epoch 3430 - Train Loss: 0.206502, Train Acc: 0.614103 | Val Loss: 0.214589, Val Acc: 0.567010\n",
      "Epoch 3431 - Train Loss: 0.206484, Train Acc: 0.614103 | Val Loss: 0.214572, Val Acc: 0.567010\n",
      "Epoch 3432 - Train Loss: 0.206466, Train Acc: 0.614103 | Val Loss: 0.214555, Val Acc: 0.567010\n",
      "Epoch 3433 - Train Loss: 0.206448, Train Acc: 0.614103 | Val Loss: 0.214538, Val Acc: 0.567010\n",
      "Epoch 3434 - Train Loss: 0.206430, Train Acc: 0.614103 | Val Loss: 0.214520, Val Acc: 0.567010\n",
      "Epoch 3435 - Train Loss: 0.206412, Train Acc: 0.614103 | Val Loss: 0.214503, Val Acc: 0.567010\n",
      "Epoch 3436 - Train Loss: 0.206395, Train Acc: 0.615385 | Val Loss: 0.214486, Val Acc: 0.567010\n",
      "Epoch 3437 - Train Loss: 0.206377, Train Acc: 0.615385 | Val Loss: 0.214469, Val Acc: 0.567010\n",
      "Epoch 3438 - Train Loss: 0.206359, Train Acc: 0.615385 | Val Loss: 0.214452, Val Acc: 0.567010\n",
      "Epoch 3439 - Train Loss: 0.206341, Train Acc: 0.615385 | Val Loss: 0.214434, Val Acc: 0.567010\n",
      "Epoch 3440 - Train Loss: 0.206323, Train Acc: 0.615385 | Val Loss: 0.214417, Val Acc: 0.567010\n",
      "Epoch 3441 - Train Loss: 0.206305, Train Acc: 0.615385 | Val Loss: 0.214400, Val Acc: 0.567010\n",
      "Epoch 3442 - Train Loss: 0.206287, Train Acc: 0.615385 | Val Loss: 0.214383, Val Acc: 0.567010\n",
      "Epoch 3443 - Train Loss: 0.206269, Train Acc: 0.615385 | Val Loss: 0.214366, Val Acc: 0.567010\n",
      "Epoch 3444 - Train Loss: 0.206251, Train Acc: 0.615385 | Val Loss: 0.214348, Val Acc: 0.567010\n",
      "Epoch 3445 - Train Loss: 0.206233, Train Acc: 0.615385 | Val Loss: 0.214331, Val Acc: 0.567010\n",
      "Epoch 3446 - Train Loss: 0.206215, Train Acc: 0.615385 | Val Loss: 0.214314, Val Acc: 0.567010\n",
      "Epoch 3447 - Train Loss: 0.206198, Train Acc: 0.615385 | Val Loss: 0.214297, Val Acc: 0.567010\n",
      "Epoch 3448 - Train Loss: 0.206180, Train Acc: 0.615385 | Val Loss: 0.214280, Val Acc: 0.567010\n",
      "Epoch 3449 - Train Loss: 0.206162, Train Acc: 0.615385 | Val Loss: 0.214263, Val Acc: 0.567010\n",
      "Epoch 3450 - Train Loss: 0.206144, Train Acc: 0.615385 | Val Loss: 0.214246, Val Acc: 0.567010\n",
      "Epoch 3451 - Train Loss: 0.206126, Train Acc: 0.615385 | Val Loss: 0.214228, Val Acc: 0.567010\n",
      "Epoch 3452 - Train Loss: 0.206108, Train Acc: 0.615385 | Val Loss: 0.214211, Val Acc: 0.567010\n",
      "Epoch 3453 - Train Loss: 0.206090, Train Acc: 0.615385 | Val Loss: 0.214194, Val Acc: 0.567010\n",
      "Epoch 3454 - Train Loss: 0.206072, Train Acc: 0.615385 | Val Loss: 0.214177, Val Acc: 0.567010\n",
      "Epoch 3455 - Train Loss: 0.206054, Train Acc: 0.615385 | Val Loss: 0.214160, Val Acc: 0.567010\n",
      "Epoch 3456 - Train Loss: 0.206037, Train Acc: 0.615385 | Val Loss: 0.214143, Val Acc: 0.567010\n",
      "Epoch 3457 - Train Loss: 0.206019, Train Acc: 0.615385 | Val Loss: 0.214126, Val Acc: 0.567010\n",
      "Epoch 3458 - Train Loss: 0.206001, Train Acc: 0.615385 | Val Loss: 0.214109, Val Acc: 0.567010\n",
      "Epoch 3459 - Train Loss: 0.205983, Train Acc: 0.615385 | Val Loss: 0.214091, Val Acc: 0.567010\n",
      "Epoch 3460 - Train Loss: 0.205965, Train Acc: 0.615385 | Val Loss: 0.214074, Val Acc: 0.567010\n",
      "Epoch 3461 - Train Loss: 0.205947, Train Acc: 0.615385 | Val Loss: 0.214057, Val Acc: 0.567010\n",
      "Epoch 3462 - Train Loss: 0.205929, Train Acc: 0.615385 | Val Loss: 0.214040, Val Acc: 0.567010\n",
      "Epoch 3463 - Train Loss: 0.205911, Train Acc: 0.615385 | Val Loss: 0.214023, Val Acc: 0.567010\n",
      "Epoch 3464 - Train Loss: 0.205894, Train Acc: 0.615385 | Val Loss: 0.214006, Val Acc: 0.567010\n",
      "Epoch 3465 - Train Loss: 0.205876, Train Acc: 0.615385 | Val Loss: 0.213989, Val Acc: 0.567010\n",
      "Epoch 3466 - Train Loss: 0.205858, Train Acc: 0.615385 | Val Loss: 0.213972, Val Acc: 0.567010\n",
      "Epoch 3467 - Train Loss: 0.205840, Train Acc: 0.615385 | Val Loss: 0.213955, Val Acc: 0.567010\n",
      "Epoch 3468 - Train Loss: 0.205822, Train Acc: 0.615385 | Val Loss: 0.213938, Val Acc: 0.567010\n",
      "Epoch 3469 - Train Loss: 0.205804, Train Acc: 0.615385 | Val Loss: 0.213920, Val Acc: 0.567010\n",
      "Epoch 3470 - Train Loss: 0.205787, Train Acc: 0.615385 | Val Loss: 0.213903, Val Acc: 0.567010\n",
      "Epoch 3471 - Train Loss: 0.205769, Train Acc: 0.615385 | Val Loss: 0.213886, Val Acc: 0.567010\n",
      "Epoch 3472 - Train Loss: 0.205751, Train Acc: 0.615385 | Val Loss: 0.213869, Val Acc: 0.567010\n",
      "Epoch 3473 - Train Loss: 0.205733, Train Acc: 0.615385 | Val Loss: 0.213852, Val Acc: 0.567010\n",
      "Epoch 3474 - Train Loss: 0.205715, Train Acc: 0.615385 | Val Loss: 0.213835, Val Acc: 0.567010\n",
      "Epoch 3475 - Train Loss: 0.205697, Train Acc: 0.615385 | Val Loss: 0.213818, Val Acc: 0.567010\n",
      "Epoch 3476 - Train Loss: 0.205680, Train Acc: 0.615385 | Val Loss: 0.213801, Val Acc: 0.567010\n",
      "Epoch 3477 - Train Loss: 0.205662, Train Acc: 0.615385 | Val Loss: 0.213784, Val Acc: 0.567010\n",
      "Epoch 3478 - Train Loss: 0.205644, Train Acc: 0.615385 | Val Loss: 0.213766, Val Acc: 0.567010\n",
      "Epoch 3479 - Train Loss: 0.205626, Train Acc: 0.615385 | Val Loss: 0.213749, Val Acc: 0.577320\n",
      "Epoch 3480 - Train Loss: 0.205609, Train Acc: 0.615385 | Val Loss: 0.213732, Val Acc: 0.577320\n",
      "Epoch 3481 - Train Loss: 0.205591, Train Acc: 0.615385 | Val Loss: 0.213715, Val Acc: 0.577320\n",
      "Epoch 3482 - Train Loss: 0.205573, Train Acc: 0.615385 | Val Loss: 0.213698, Val Acc: 0.577320\n",
      "Epoch 3483 - Train Loss: 0.205555, Train Acc: 0.615385 | Val Loss: 0.213681, Val Acc: 0.577320\n",
      "Epoch 3484 - Train Loss: 0.205537, Train Acc: 0.615385 | Val Loss: 0.213664, Val Acc: 0.577320\n",
      "Epoch 3485 - Train Loss: 0.205520, Train Acc: 0.615385 | Val Loss: 0.213647, Val Acc: 0.577320\n",
      "Epoch 3486 - Train Loss: 0.205502, Train Acc: 0.615385 | Val Loss: 0.213630, Val Acc: 0.577320\n",
      "Epoch 3487 - Train Loss: 0.205484, Train Acc: 0.615385 | Val Loss: 0.213613, Val Acc: 0.577320\n",
      "Epoch 3488 - Train Loss: 0.205466, Train Acc: 0.615385 | Val Loss: 0.213596, Val Acc: 0.577320\n",
      "Epoch 3489 - Train Loss: 0.205449, Train Acc: 0.615385 | Val Loss: 0.213579, Val Acc: 0.577320\n",
      "Epoch 3490 - Train Loss: 0.205431, Train Acc: 0.615385 | Val Loss: 0.213562, Val Acc: 0.577320\n",
      "Epoch 3491 - Train Loss: 0.205413, Train Acc: 0.615385 | Val Loss: 0.213545, Val Acc: 0.577320\n",
      "Epoch 3492 - Train Loss: 0.205396, Train Acc: 0.615385 | Val Loss: 0.213527, Val Acc: 0.577320\n",
      "Epoch 3493 - Train Loss: 0.205378, Train Acc: 0.615385 | Val Loss: 0.213510, Val Acc: 0.577320\n",
      "Epoch 3494 - Train Loss: 0.205360, Train Acc: 0.615385 | Val Loss: 0.213493, Val Acc: 0.577320\n",
      "Epoch 3495 - Train Loss: 0.205342, Train Acc: 0.615385 | Val Loss: 0.213476, Val Acc: 0.577320\n",
      "Epoch 3496 - Train Loss: 0.205325, Train Acc: 0.615385 | Val Loss: 0.213459, Val Acc: 0.577320\n",
      "Epoch 3497 - Train Loss: 0.205307, Train Acc: 0.615385 | Val Loss: 0.213442, Val Acc: 0.577320\n",
      "Epoch 3498 - Train Loss: 0.205289, Train Acc: 0.615385 | Val Loss: 0.213425, Val Acc: 0.577320\n",
      "Epoch 3499 - Train Loss: 0.205272, Train Acc: 0.615385 | Val Loss: 0.213408, Val Acc: 0.577320\n",
      "Epoch 3500 - Train Loss: 0.205254, Train Acc: 0.615385 | Val Loss: 0.213391, Val Acc: 0.577320\n",
      "Epoch 3501 - Train Loss: 0.205236, Train Acc: 0.615385 | Val Loss: 0.213374, Val Acc: 0.577320\n",
      "Epoch 3502 - Train Loss: 0.205219, Train Acc: 0.615385 | Val Loss: 0.213357, Val Acc: 0.577320\n",
      "Epoch 3503 - Train Loss: 0.205201, Train Acc: 0.615385 | Val Loss: 0.213340, Val Acc: 0.577320\n",
      "Epoch 3504 - Train Loss: 0.205183, Train Acc: 0.615385 | Val Loss: 0.213323, Val Acc: 0.577320\n",
      "Epoch 3505 - Train Loss: 0.205166, Train Acc: 0.615385 | Val Loss: 0.213306, Val Acc: 0.577320\n",
      "Epoch 3506 - Train Loss: 0.205148, Train Acc: 0.615385 | Val Loss: 0.213289, Val Acc: 0.577320\n",
      "Epoch 3507 - Train Loss: 0.205130, Train Acc: 0.614103 | Val Loss: 0.213272, Val Acc: 0.577320\n",
      "Epoch 3508 - Train Loss: 0.205113, Train Acc: 0.614103 | Val Loss: 0.213255, Val Acc: 0.577320\n",
      "Epoch 3509 - Train Loss: 0.205095, Train Acc: 0.614103 | Val Loss: 0.213238, Val Acc: 0.577320\n",
      "Epoch 3510 - Train Loss: 0.205077, Train Acc: 0.614103 | Val Loss: 0.213221, Val Acc: 0.577320\n",
      "Epoch 3511 - Train Loss: 0.205060, Train Acc: 0.614103 | Val Loss: 0.213204, Val Acc: 0.577320\n",
      "Epoch 3512 - Train Loss: 0.205042, Train Acc: 0.614103 | Val Loss: 0.213187, Val Acc: 0.567010\n",
      "Epoch 3513 - Train Loss: 0.205024, Train Acc: 0.614103 | Val Loss: 0.213170, Val Acc: 0.567010\n",
      "Epoch 3514 - Train Loss: 0.205007, Train Acc: 0.614103 | Val Loss: 0.213153, Val Acc: 0.567010\n",
      "Epoch 3515 - Train Loss: 0.204989, Train Acc: 0.614103 | Val Loss: 0.213136, Val Acc: 0.567010\n",
      "Epoch 3516 - Train Loss: 0.204971, Train Acc: 0.614103 | Val Loss: 0.213119, Val Acc: 0.567010\n",
      "Epoch 3517 - Train Loss: 0.204954, Train Acc: 0.614103 | Val Loss: 0.213102, Val Acc: 0.567010\n",
      "Epoch 3518 - Train Loss: 0.204936, Train Acc: 0.614103 | Val Loss: 0.213085, Val Acc: 0.567010\n",
      "Epoch 3519 - Train Loss: 0.204919, Train Acc: 0.614103 | Val Loss: 0.213068, Val Acc: 0.567010\n",
      "Epoch 3520 - Train Loss: 0.204901, Train Acc: 0.614103 | Val Loss: 0.213051, Val Acc: 0.567010\n",
      "Epoch 3521 - Train Loss: 0.204883, Train Acc: 0.614103 | Val Loss: 0.213034, Val Acc: 0.567010\n",
      "Epoch 3522 - Train Loss: 0.204866, Train Acc: 0.614103 | Val Loss: 0.213017, Val Acc: 0.567010\n",
      "Epoch 3523 - Train Loss: 0.204848, Train Acc: 0.614103 | Val Loss: 0.213000, Val Acc: 0.567010\n",
      "Epoch 3524 - Train Loss: 0.204831, Train Acc: 0.614103 | Val Loss: 0.212983, Val Acc: 0.567010\n",
      "Epoch 3525 - Train Loss: 0.204813, Train Acc: 0.614103 | Val Loss: 0.212966, Val Acc: 0.567010\n",
      "Epoch 3526 - Train Loss: 0.204795, Train Acc: 0.614103 | Val Loss: 0.212949, Val Acc: 0.567010\n",
      "Epoch 3527 - Train Loss: 0.204778, Train Acc: 0.614103 | Val Loss: 0.212932, Val Acc: 0.567010\n",
      "Epoch 3528 - Train Loss: 0.204760, Train Acc: 0.614103 | Val Loss: 0.212915, Val Acc: 0.567010\n",
      "Epoch 3529 - Train Loss: 0.204743, Train Acc: 0.614103 | Val Loss: 0.212898, Val Acc: 0.567010\n",
      "Epoch 3530 - Train Loss: 0.204725, Train Acc: 0.614103 | Val Loss: 0.212881, Val Acc: 0.567010\n",
      "Epoch 3531 - Train Loss: 0.204708, Train Acc: 0.614103 | Val Loss: 0.212864, Val Acc: 0.567010\n",
      "Epoch 3532 - Train Loss: 0.204690, Train Acc: 0.614103 | Val Loss: 0.212848, Val Acc: 0.567010\n",
      "Epoch 3533 - Train Loss: 0.204673, Train Acc: 0.614103 | Val Loss: 0.212831, Val Acc: 0.567010\n",
      "Epoch 3534 - Train Loss: 0.204655, Train Acc: 0.614103 | Val Loss: 0.212814, Val Acc: 0.567010\n",
      "Epoch 3535 - Train Loss: 0.204637, Train Acc: 0.614103 | Val Loss: 0.212797, Val Acc: 0.567010\n",
      "Epoch 3536 - Train Loss: 0.204620, Train Acc: 0.614103 | Val Loss: 0.212780, Val Acc: 0.567010\n",
      "Epoch 3537 - Train Loss: 0.204602, Train Acc: 0.614103 | Val Loss: 0.212763, Val Acc: 0.567010\n",
      "Epoch 3538 - Train Loss: 0.204585, Train Acc: 0.614103 | Val Loss: 0.212746, Val Acc: 0.567010\n",
      "Epoch 3539 - Train Loss: 0.204567, Train Acc: 0.614103 | Val Loss: 0.212729, Val Acc: 0.567010\n",
      "Epoch 3540 - Train Loss: 0.204550, Train Acc: 0.614103 | Val Loss: 0.212712, Val Acc: 0.567010\n",
      "Epoch 3541 - Train Loss: 0.204532, Train Acc: 0.614103 | Val Loss: 0.212695, Val Acc: 0.567010\n",
      "Epoch 3542 - Train Loss: 0.204515, Train Acc: 0.614103 | Val Loss: 0.212678, Val Acc: 0.567010\n",
      "Epoch 3543 - Train Loss: 0.204497, Train Acc: 0.614103 | Val Loss: 0.212662, Val Acc: 0.567010\n",
      "Epoch 3544 - Train Loss: 0.204480, Train Acc: 0.614103 | Val Loss: 0.212645, Val Acc: 0.567010\n",
      "Epoch 3545 - Train Loss: 0.204462, Train Acc: 0.614103 | Val Loss: 0.212628, Val Acc: 0.567010\n",
      "Epoch 3546 - Train Loss: 0.204445, Train Acc: 0.614103 | Val Loss: 0.212611, Val Acc: 0.567010\n",
      "Epoch 3547 - Train Loss: 0.204427, Train Acc: 0.614103 | Val Loss: 0.212594, Val Acc: 0.567010\n",
      "Epoch 3548 - Train Loss: 0.204410, Train Acc: 0.614103 | Val Loss: 0.212577, Val Acc: 0.567010\n",
      "Epoch 3549 - Train Loss: 0.204392, Train Acc: 0.614103 | Val Loss: 0.212560, Val Acc: 0.567010\n",
      "Epoch 3550 - Train Loss: 0.204375, Train Acc: 0.614103 | Val Loss: 0.212543, Val Acc: 0.567010\n",
      "Epoch 3551 - Train Loss: 0.204357, Train Acc: 0.614103 | Val Loss: 0.212526, Val Acc: 0.567010\n",
      "Epoch 3552 - Train Loss: 0.204340, Train Acc: 0.614103 | Val Loss: 0.212510, Val Acc: 0.567010\n",
      "Epoch 3553 - Train Loss: 0.204322, Train Acc: 0.614103 | Val Loss: 0.212493, Val Acc: 0.567010\n",
      "Epoch 3554 - Train Loss: 0.204305, Train Acc: 0.614103 | Val Loss: 0.212476, Val Acc: 0.567010\n",
      "Epoch 3555 - Train Loss: 0.204287, Train Acc: 0.614103 | Val Loss: 0.212459, Val Acc: 0.567010\n",
      "Epoch 3556 - Train Loss: 0.204270, Train Acc: 0.614103 | Val Loss: 0.212442, Val Acc: 0.567010\n",
      "Epoch 3557 - Train Loss: 0.204252, Train Acc: 0.614103 | Val Loss: 0.212425, Val Acc: 0.567010\n",
      "Epoch 3558 - Train Loss: 0.204235, Train Acc: 0.614103 | Val Loss: 0.212408, Val Acc: 0.567010\n",
      "Epoch 3559 - Train Loss: 0.204217, Train Acc: 0.614103 | Val Loss: 0.212391, Val Acc: 0.567010\n",
      "Epoch 3560 - Train Loss: 0.204200, Train Acc: 0.614103 | Val Loss: 0.212375, Val Acc: 0.567010\n",
      "Epoch 3561 - Train Loss: 0.204182, Train Acc: 0.614103 | Val Loss: 0.212358, Val Acc: 0.567010\n",
      "Epoch 3562 - Train Loss: 0.204165, Train Acc: 0.614103 | Val Loss: 0.212341, Val Acc: 0.567010\n",
      "Epoch 3563 - Train Loss: 0.204147, Train Acc: 0.614103 | Val Loss: 0.212324, Val Acc: 0.567010\n",
      "Epoch 3564 - Train Loss: 0.204130, Train Acc: 0.614103 | Val Loss: 0.212307, Val Acc: 0.567010\n",
      "Epoch 3565 - Train Loss: 0.204112, Train Acc: 0.614103 | Val Loss: 0.212290, Val Acc: 0.567010\n",
      "Epoch 3566 - Train Loss: 0.204095, Train Acc: 0.614103 | Val Loss: 0.212274, Val Acc: 0.567010\n",
      "Epoch 3567 - Train Loss: 0.204078, Train Acc: 0.615385 | Val Loss: 0.212257, Val Acc: 0.567010\n",
      "Epoch 3568 - Train Loss: 0.204060, Train Acc: 0.616667 | Val Loss: 0.212240, Val Acc: 0.567010\n",
      "Epoch 3569 - Train Loss: 0.204043, Train Acc: 0.616667 | Val Loss: 0.212223, Val Acc: 0.567010\n",
      "Epoch 3570 - Train Loss: 0.204025, Train Acc: 0.616667 | Val Loss: 0.212206, Val Acc: 0.567010\n",
      "Epoch 3571 - Train Loss: 0.204008, Train Acc: 0.616667 | Val Loss: 0.212190, Val Acc: 0.567010\n",
      "Epoch 3572 - Train Loss: 0.203990, Train Acc: 0.616667 | Val Loss: 0.212173, Val Acc: 0.567010\n",
      "Epoch 3573 - Train Loss: 0.203973, Train Acc: 0.616667 | Val Loss: 0.212156, Val Acc: 0.567010\n",
      "Epoch 3574 - Train Loss: 0.203956, Train Acc: 0.616667 | Val Loss: 0.212139, Val Acc: 0.567010\n",
      "Epoch 3575 - Train Loss: 0.203938, Train Acc: 0.616667 | Val Loss: 0.212122, Val Acc: 0.567010\n",
      "Epoch 3576 - Train Loss: 0.203921, Train Acc: 0.616667 | Val Loss: 0.212106, Val Acc: 0.567010\n",
      "Epoch 3577 - Train Loss: 0.203903, Train Acc: 0.616667 | Val Loss: 0.212089, Val Acc: 0.567010\n",
      "Epoch 3578 - Train Loss: 0.203886, Train Acc: 0.616667 | Val Loss: 0.212072, Val Acc: 0.567010\n",
      "Epoch 3579 - Train Loss: 0.203868, Train Acc: 0.616667 | Val Loss: 0.212055, Val Acc: 0.567010\n",
      "Epoch 3580 - Train Loss: 0.203851, Train Acc: 0.616667 | Val Loss: 0.212039, Val Acc: 0.567010\n",
      "Epoch 3581 - Train Loss: 0.203834, Train Acc: 0.616667 | Val Loss: 0.212022, Val Acc: 0.567010\n",
      "Epoch 3582 - Train Loss: 0.203816, Train Acc: 0.616667 | Val Loss: 0.212005, Val Acc: 0.567010\n",
      "Epoch 3583 - Train Loss: 0.203799, Train Acc: 0.616667 | Val Loss: 0.211988, Val Acc: 0.567010\n",
      "Epoch 3584 - Train Loss: 0.203782, Train Acc: 0.616667 | Val Loss: 0.211971, Val Acc: 0.567010\n",
      "Epoch 3585 - Train Loss: 0.203764, Train Acc: 0.616667 | Val Loss: 0.211955, Val Acc: 0.567010\n",
      "Epoch 3586 - Train Loss: 0.203747, Train Acc: 0.616667 | Val Loss: 0.211938, Val Acc: 0.567010\n",
      "Epoch 3587 - Train Loss: 0.203729, Train Acc: 0.616667 | Val Loss: 0.211921, Val Acc: 0.567010\n",
      "Epoch 3588 - Train Loss: 0.203712, Train Acc: 0.616667 | Val Loss: 0.211905, Val Acc: 0.567010\n",
      "Epoch 3589 - Train Loss: 0.203695, Train Acc: 0.616667 | Val Loss: 0.211888, Val Acc: 0.567010\n",
      "Epoch 3590 - Train Loss: 0.203677, Train Acc: 0.616667 | Val Loss: 0.211871, Val Acc: 0.567010\n",
      "Epoch 3591 - Train Loss: 0.203660, Train Acc: 0.616667 | Val Loss: 0.211854, Val Acc: 0.567010\n",
      "Epoch 3592 - Train Loss: 0.203643, Train Acc: 0.616667 | Val Loss: 0.211838, Val Acc: 0.567010\n",
      "Epoch 3593 - Train Loss: 0.203625, Train Acc: 0.616667 | Val Loss: 0.211821, Val Acc: 0.567010\n",
      "Epoch 3594 - Train Loss: 0.203608, Train Acc: 0.616667 | Val Loss: 0.211804, Val Acc: 0.567010\n",
      "Epoch 3595 - Train Loss: 0.203590, Train Acc: 0.616667 | Val Loss: 0.211787, Val Acc: 0.567010\n",
      "Epoch 3596 - Train Loss: 0.203573, Train Acc: 0.616667 | Val Loss: 0.211771, Val Acc: 0.567010\n",
      "Epoch 3597 - Train Loss: 0.203556, Train Acc: 0.616667 | Val Loss: 0.211754, Val Acc: 0.567010\n",
      "Epoch 3598 - Train Loss: 0.203538, Train Acc: 0.616667 | Val Loss: 0.211737, Val Acc: 0.567010\n",
      "Epoch 3599 - Train Loss: 0.203521, Train Acc: 0.616667 | Val Loss: 0.211721, Val Acc: 0.567010\n",
      "Epoch 3600 - Train Loss: 0.203504, Train Acc: 0.616667 | Val Loss: 0.211704, Val Acc: 0.567010\n",
      "Epoch 3601 - Train Loss: 0.203486, Train Acc: 0.616667 | Val Loss: 0.211687, Val Acc: 0.567010\n",
      "Epoch 3602 - Train Loss: 0.203469, Train Acc: 0.616667 | Val Loss: 0.211671, Val Acc: 0.567010\n",
      "Epoch 3603 - Train Loss: 0.203452, Train Acc: 0.616667 | Val Loss: 0.211654, Val Acc: 0.567010\n",
      "Epoch 3604 - Train Loss: 0.203434, Train Acc: 0.616667 | Val Loss: 0.211637, Val Acc: 0.567010\n",
      "Epoch 3605 - Train Loss: 0.203417, Train Acc: 0.617949 | Val Loss: 0.211620, Val Acc: 0.567010\n",
      "Epoch 3606 - Train Loss: 0.203400, Train Acc: 0.617949 | Val Loss: 0.211604, Val Acc: 0.567010\n",
      "Epoch 3607 - Train Loss: 0.203383, Train Acc: 0.617949 | Val Loss: 0.211587, Val Acc: 0.567010\n",
      "Epoch 3608 - Train Loss: 0.203365, Train Acc: 0.617949 | Val Loss: 0.211570, Val Acc: 0.567010\n",
      "Epoch 3609 - Train Loss: 0.203348, Train Acc: 0.617949 | Val Loss: 0.211554, Val Acc: 0.567010\n",
      "Epoch 3610 - Train Loss: 0.203331, Train Acc: 0.617949 | Val Loss: 0.211537, Val Acc: 0.567010\n",
      "Epoch 3611 - Train Loss: 0.203313, Train Acc: 0.617949 | Val Loss: 0.211521, Val Acc: 0.567010\n",
      "Epoch 3612 - Train Loss: 0.203296, Train Acc: 0.617949 | Val Loss: 0.211504, Val Acc: 0.567010\n",
      "Epoch 3613 - Train Loss: 0.203279, Train Acc: 0.617949 | Val Loss: 0.211487, Val Acc: 0.567010\n",
      "Epoch 3614 - Train Loss: 0.203261, Train Acc: 0.617949 | Val Loss: 0.211471, Val Acc: 0.567010\n",
      "Epoch 3615 - Train Loss: 0.203244, Train Acc: 0.617949 | Val Loss: 0.211454, Val Acc: 0.567010\n",
      "Epoch 3616 - Train Loss: 0.203227, Train Acc: 0.617949 | Val Loss: 0.211437, Val Acc: 0.567010\n",
      "Epoch 3617 - Train Loss: 0.203210, Train Acc: 0.617949 | Val Loss: 0.211421, Val Acc: 0.567010\n",
      "Epoch 3618 - Train Loss: 0.203192, Train Acc: 0.617949 | Val Loss: 0.211404, Val Acc: 0.567010\n",
      "Epoch 3619 - Train Loss: 0.203175, Train Acc: 0.617949 | Val Loss: 0.211387, Val Acc: 0.567010\n",
      "Epoch 3620 - Train Loss: 0.203158, Train Acc: 0.617949 | Val Loss: 0.211371, Val Acc: 0.567010\n",
      "Epoch 3621 - Train Loss: 0.203140, Train Acc: 0.617949 | Val Loss: 0.211354, Val Acc: 0.567010\n",
      "Epoch 3622 - Train Loss: 0.203123, Train Acc: 0.617949 | Val Loss: 0.211338, Val Acc: 0.567010\n",
      "Epoch 3623 - Train Loss: 0.203106, Train Acc: 0.617949 | Val Loss: 0.211321, Val Acc: 0.567010\n",
      "Epoch 3624 - Train Loss: 0.203089, Train Acc: 0.619231 | Val Loss: 0.211304, Val Acc: 0.567010\n",
      "Epoch 3625 - Train Loss: 0.203071, Train Acc: 0.619231 | Val Loss: 0.211288, Val Acc: 0.567010\n",
      "Epoch 3626 - Train Loss: 0.203054, Train Acc: 0.619231 | Val Loss: 0.211271, Val Acc: 0.567010\n",
      "Epoch 3627 - Train Loss: 0.203037, Train Acc: 0.619231 | Val Loss: 0.211255, Val Acc: 0.567010\n",
      "Epoch 3628 - Train Loss: 0.203020, Train Acc: 0.619231 | Val Loss: 0.211238, Val Acc: 0.577320\n",
      "Epoch 3629 - Train Loss: 0.203002, Train Acc: 0.619231 | Val Loss: 0.211221, Val Acc: 0.577320\n",
      "Epoch 3630 - Train Loss: 0.202985, Train Acc: 0.619231 | Val Loss: 0.211205, Val Acc: 0.577320\n",
      "Epoch 3631 - Train Loss: 0.202968, Train Acc: 0.619231 | Val Loss: 0.211188, Val Acc: 0.577320\n",
      "Epoch 3632 - Train Loss: 0.202951, Train Acc: 0.619231 | Val Loss: 0.211172, Val Acc: 0.577320\n",
      "Epoch 3633 - Train Loss: 0.202934, Train Acc: 0.619231 | Val Loss: 0.211155, Val Acc: 0.577320\n",
      "Epoch 3634 - Train Loss: 0.202916, Train Acc: 0.619231 | Val Loss: 0.211138, Val Acc: 0.577320\n",
      "Epoch 3635 - Train Loss: 0.202899, Train Acc: 0.619231 | Val Loss: 0.211122, Val Acc: 0.577320\n",
      "Epoch 3636 - Train Loss: 0.202882, Train Acc: 0.619231 | Val Loss: 0.211105, Val Acc: 0.577320\n",
      "Epoch 3637 - Train Loss: 0.202865, Train Acc: 0.619231 | Val Loss: 0.211089, Val Acc: 0.577320\n",
      "Epoch 3638 - Train Loss: 0.202848, Train Acc: 0.619231 | Val Loss: 0.211072, Val Acc: 0.577320\n",
      "Epoch 3639 - Train Loss: 0.202830, Train Acc: 0.619231 | Val Loss: 0.211056, Val Acc: 0.577320\n",
      "Epoch 3640 - Train Loss: 0.202813, Train Acc: 0.619231 | Val Loss: 0.211039, Val Acc: 0.577320\n",
      "Epoch 3641 - Train Loss: 0.202796, Train Acc: 0.619231 | Val Loss: 0.211023, Val Acc: 0.577320\n",
      "Epoch 3642 - Train Loss: 0.202779, Train Acc: 0.619231 | Val Loss: 0.211006, Val Acc: 0.577320\n",
      "Epoch 3643 - Train Loss: 0.202762, Train Acc: 0.619231 | Val Loss: 0.210990, Val Acc: 0.577320\n",
      "Epoch 3644 - Train Loss: 0.202744, Train Acc: 0.619231 | Val Loss: 0.210973, Val Acc: 0.577320\n",
      "Epoch 3645 - Train Loss: 0.202727, Train Acc: 0.619231 | Val Loss: 0.210956, Val Acc: 0.577320\n",
      "Epoch 3646 - Train Loss: 0.202710, Train Acc: 0.619231 | Val Loss: 0.210940, Val Acc: 0.577320\n",
      "Epoch 3647 - Train Loss: 0.202693, Train Acc: 0.619231 | Val Loss: 0.210923, Val Acc: 0.577320\n",
      "Epoch 3648 - Train Loss: 0.202676, Train Acc: 0.619231 | Val Loss: 0.210907, Val Acc: 0.577320\n",
      "Epoch 3649 - Train Loss: 0.202658, Train Acc: 0.619231 | Val Loss: 0.210890, Val Acc: 0.577320\n",
      "Epoch 3650 - Train Loss: 0.202641, Train Acc: 0.619231 | Val Loss: 0.210874, Val Acc: 0.577320\n",
      "Epoch 3651 - Train Loss: 0.202624, Train Acc: 0.619231 | Val Loss: 0.210857, Val Acc: 0.577320\n",
      "Epoch 3652 - Train Loss: 0.202607, Train Acc: 0.619231 | Val Loss: 0.210841, Val Acc: 0.577320\n",
      "Epoch 3653 - Train Loss: 0.202590, Train Acc: 0.619231 | Val Loss: 0.210824, Val Acc: 0.577320\n",
      "Epoch 3654 - Train Loss: 0.202573, Train Acc: 0.619231 | Val Loss: 0.210808, Val Acc: 0.577320\n",
      "Epoch 3655 - Train Loss: 0.202555, Train Acc: 0.619231 | Val Loss: 0.210791, Val Acc: 0.577320\n",
      "Epoch 3656 - Train Loss: 0.202538, Train Acc: 0.619231 | Val Loss: 0.210775, Val Acc: 0.577320\n",
      "Epoch 3657 - Train Loss: 0.202521, Train Acc: 0.619231 | Val Loss: 0.210758, Val Acc: 0.577320\n",
      "Epoch 3658 - Train Loss: 0.202504, Train Acc: 0.619231 | Val Loss: 0.210742, Val Acc: 0.577320\n",
      "Epoch 3659 - Train Loss: 0.202487, Train Acc: 0.619231 | Val Loss: 0.210725, Val Acc: 0.577320\n",
      "Epoch 3660 - Train Loss: 0.202470, Train Acc: 0.619231 | Val Loss: 0.210709, Val Acc: 0.577320\n",
      "Epoch 3661 - Train Loss: 0.202453, Train Acc: 0.619231 | Val Loss: 0.210692, Val Acc: 0.577320\n",
      "Epoch 3662 - Train Loss: 0.202435, Train Acc: 0.619231 | Val Loss: 0.210676, Val Acc: 0.577320\n",
      "Epoch 3663 - Train Loss: 0.202418, Train Acc: 0.619231 | Val Loss: 0.210659, Val Acc: 0.577320\n",
      "Epoch 3664 - Train Loss: 0.202401, Train Acc: 0.619231 | Val Loss: 0.210643, Val Acc: 0.577320\n",
      "Epoch 3665 - Train Loss: 0.202384, Train Acc: 0.619231 | Val Loss: 0.210627, Val Acc: 0.577320\n",
      "Epoch 3666 - Train Loss: 0.202367, Train Acc: 0.619231 | Val Loss: 0.210610, Val Acc: 0.577320\n",
      "Epoch 3667 - Train Loss: 0.202350, Train Acc: 0.619231 | Val Loss: 0.210594, Val Acc: 0.577320\n",
      "Epoch 3668 - Train Loss: 0.202333, Train Acc: 0.619231 | Val Loss: 0.210577, Val Acc: 0.577320\n",
      "Epoch 3669 - Train Loss: 0.202316, Train Acc: 0.619231 | Val Loss: 0.210561, Val Acc: 0.577320\n",
      "Epoch 3670 - Train Loss: 0.202299, Train Acc: 0.619231 | Val Loss: 0.210544, Val Acc: 0.577320\n",
      "Epoch 3671 - Train Loss: 0.202281, Train Acc: 0.619231 | Val Loss: 0.210528, Val Acc: 0.577320\n",
      "Epoch 3672 - Train Loss: 0.202264, Train Acc: 0.619231 | Val Loss: 0.210511, Val Acc: 0.577320\n",
      "Epoch 3673 - Train Loss: 0.202247, Train Acc: 0.619231 | Val Loss: 0.210495, Val Acc: 0.577320\n",
      "Epoch 3674 - Train Loss: 0.202230, Train Acc: 0.619231 | Val Loss: 0.210479, Val Acc: 0.577320\n",
      "Epoch 3675 - Train Loss: 0.202213, Train Acc: 0.619231 | Val Loss: 0.210462, Val Acc: 0.577320\n",
      "Epoch 3676 - Train Loss: 0.202196, Train Acc: 0.619231 | Val Loss: 0.210446, Val Acc: 0.577320\n",
      "Epoch 3677 - Train Loss: 0.202179, Train Acc: 0.619231 | Val Loss: 0.210429, Val Acc: 0.577320\n",
      "Epoch 3678 - Train Loss: 0.202162, Train Acc: 0.619231 | Val Loss: 0.210413, Val Acc: 0.577320\n",
      "Epoch 3679 - Train Loss: 0.202145, Train Acc: 0.619231 | Val Loss: 0.210396, Val Acc: 0.577320\n",
      "Epoch 3680 - Train Loss: 0.202128, Train Acc: 0.619231 | Val Loss: 0.210380, Val Acc: 0.577320\n",
      "Epoch 3681 - Train Loss: 0.202111, Train Acc: 0.619231 | Val Loss: 0.210364, Val Acc: 0.577320\n",
      "Epoch 3682 - Train Loss: 0.202093, Train Acc: 0.619231 | Val Loss: 0.210347, Val Acc: 0.577320\n",
      "Epoch 3683 - Train Loss: 0.202076, Train Acc: 0.619231 | Val Loss: 0.210331, Val Acc: 0.567010\n",
      "Epoch 3684 - Train Loss: 0.202059, Train Acc: 0.619231 | Val Loss: 0.210314, Val Acc: 0.567010\n",
      "Epoch 3685 - Train Loss: 0.202042, Train Acc: 0.619231 | Val Loss: 0.210298, Val Acc: 0.567010\n",
      "Epoch 3686 - Train Loss: 0.202025, Train Acc: 0.619231 | Val Loss: 0.210281, Val Acc: 0.567010\n",
      "Epoch 3687 - Train Loss: 0.202008, Train Acc: 0.619231 | Val Loss: 0.210265, Val Acc: 0.567010\n",
      "Epoch 3688 - Train Loss: 0.201991, Train Acc: 0.619231 | Val Loss: 0.210249, Val Acc: 0.567010\n",
      "Epoch 3689 - Train Loss: 0.201974, Train Acc: 0.619231 | Val Loss: 0.210232, Val Acc: 0.567010\n",
      "Epoch 3690 - Train Loss: 0.201957, Train Acc: 0.619231 | Val Loss: 0.210216, Val Acc: 0.567010\n",
      "Epoch 3691 - Train Loss: 0.201940, Train Acc: 0.619231 | Val Loss: 0.210200, Val Acc: 0.567010\n",
      "Epoch 3692 - Train Loss: 0.201923, Train Acc: 0.619231 | Val Loss: 0.210183, Val Acc: 0.567010\n",
      "Epoch 3693 - Train Loss: 0.201906, Train Acc: 0.619231 | Val Loss: 0.210167, Val Acc: 0.567010\n",
      "Epoch 3694 - Train Loss: 0.201889, Train Acc: 0.619231 | Val Loss: 0.210151, Val Acc: 0.567010\n",
      "Epoch 3695 - Train Loss: 0.201872, Train Acc: 0.619231 | Val Loss: 0.210134, Val Acc: 0.567010\n",
      "Epoch 3696 - Train Loss: 0.201855, Train Acc: 0.620513 | Val Loss: 0.210118, Val Acc: 0.567010\n",
      "Epoch 3697 - Train Loss: 0.201838, Train Acc: 0.620513 | Val Loss: 0.210101, Val Acc: 0.567010\n",
      "Epoch 3698 - Train Loss: 0.201821, Train Acc: 0.620513 | Val Loss: 0.210085, Val Acc: 0.567010\n",
      "Epoch 3699 - Train Loss: 0.201804, Train Acc: 0.620513 | Val Loss: 0.210069, Val Acc: 0.567010\n",
      "Epoch 3700 - Train Loss: 0.201787, Train Acc: 0.620513 | Val Loss: 0.210052, Val Acc: 0.567010\n",
      "Epoch 3701 - Train Loss: 0.201770, Train Acc: 0.620513 | Val Loss: 0.210036, Val Acc: 0.567010\n",
      "Epoch 3702 - Train Loss: 0.201753, Train Acc: 0.620513 | Val Loss: 0.210020, Val Acc: 0.567010\n",
      "Epoch 3703 - Train Loss: 0.201736, Train Acc: 0.620513 | Val Loss: 0.210003, Val Acc: 0.567010\n",
      "Epoch 3704 - Train Loss: 0.201719, Train Acc: 0.620513 | Val Loss: 0.209987, Val Acc: 0.567010\n",
      "Epoch 3705 - Train Loss: 0.201702, Train Acc: 0.620513 | Val Loss: 0.209971, Val Acc: 0.567010\n",
      "Epoch 3706 - Train Loss: 0.201685, Train Acc: 0.620513 | Val Loss: 0.209954, Val Acc: 0.567010\n",
      "Epoch 3707 - Train Loss: 0.201668, Train Acc: 0.620513 | Val Loss: 0.209938, Val Acc: 0.567010\n",
      "Epoch 3708 - Train Loss: 0.201651, Train Acc: 0.620513 | Val Loss: 0.209922, Val Acc: 0.567010\n",
      "Epoch 3709 - Train Loss: 0.201634, Train Acc: 0.620513 | Val Loss: 0.209906, Val Acc: 0.567010\n",
      "Epoch 3710 - Train Loss: 0.201617, Train Acc: 0.620513 | Val Loss: 0.209889, Val Acc: 0.567010\n",
      "Epoch 3711 - Train Loss: 0.201600, Train Acc: 0.620513 | Val Loss: 0.209873, Val Acc: 0.567010\n",
      "Epoch 3712 - Train Loss: 0.201583, Train Acc: 0.620513 | Val Loss: 0.209857, Val Acc: 0.567010\n",
      "Epoch 3713 - Train Loss: 0.201566, Train Acc: 0.620513 | Val Loss: 0.209840, Val Acc: 0.567010\n",
      "Epoch 3714 - Train Loss: 0.201549, Train Acc: 0.620513 | Val Loss: 0.209824, Val Acc: 0.567010\n",
      "Epoch 3715 - Train Loss: 0.201532, Train Acc: 0.620513 | Val Loss: 0.209808, Val Acc: 0.567010\n",
      "Epoch 3716 - Train Loss: 0.201515, Train Acc: 0.620513 | Val Loss: 0.209792, Val Acc: 0.567010\n",
      "Epoch 3717 - Train Loss: 0.201498, Train Acc: 0.620513 | Val Loss: 0.209775, Val Acc: 0.567010\n",
      "Epoch 3718 - Train Loss: 0.201481, Train Acc: 0.620513 | Val Loss: 0.209759, Val Acc: 0.567010\n",
      "Epoch 3719 - Train Loss: 0.201464, Train Acc: 0.620513 | Val Loss: 0.209743, Val Acc: 0.567010\n",
      "Epoch 3720 - Train Loss: 0.201447, Train Acc: 0.620513 | Val Loss: 0.209726, Val Acc: 0.567010\n",
      "Epoch 3721 - Train Loss: 0.201430, Train Acc: 0.620513 | Val Loss: 0.209710, Val Acc: 0.567010\n",
      "Epoch 3722 - Train Loss: 0.201414, Train Acc: 0.620513 | Val Loss: 0.209694, Val Acc: 0.567010\n",
      "Epoch 3723 - Train Loss: 0.201397, Train Acc: 0.620513 | Val Loss: 0.209678, Val Acc: 0.567010\n",
      "Epoch 3724 - Train Loss: 0.201380, Train Acc: 0.620513 | Val Loss: 0.209661, Val Acc: 0.567010\n",
      "Epoch 3725 - Train Loss: 0.201363, Train Acc: 0.620513 | Val Loss: 0.209645, Val Acc: 0.567010\n",
      "Epoch 3726 - Train Loss: 0.201346, Train Acc: 0.620513 | Val Loss: 0.209629, Val Acc: 0.567010\n",
      "Epoch 3727 - Train Loss: 0.201329, Train Acc: 0.620513 | Val Loss: 0.209613, Val Acc: 0.567010\n",
      "Epoch 3728 - Train Loss: 0.201312, Train Acc: 0.620513 | Val Loss: 0.209596, Val Acc: 0.567010\n",
      "Epoch 3729 - Train Loss: 0.201295, Train Acc: 0.620513 | Val Loss: 0.209580, Val Acc: 0.567010\n",
      "Epoch 3730 - Train Loss: 0.201278, Train Acc: 0.620513 | Val Loss: 0.209564, Val Acc: 0.567010\n",
      "Epoch 3731 - Train Loss: 0.201261, Train Acc: 0.620513 | Val Loss: 0.209548, Val Acc: 0.567010\n",
      "Epoch 3732 - Train Loss: 0.201244, Train Acc: 0.620513 | Val Loss: 0.209531, Val Acc: 0.567010\n",
      "Epoch 3733 - Train Loss: 0.201227, Train Acc: 0.620513 | Val Loss: 0.209515, Val Acc: 0.567010\n",
      "Epoch 3734 - Train Loss: 0.201211, Train Acc: 0.620513 | Val Loss: 0.209499, Val Acc: 0.567010\n",
      "Epoch 3735 - Train Loss: 0.201194, Train Acc: 0.620513 | Val Loss: 0.209483, Val Acc: 0.567010\n",
      "Epoch 3736 - Train Loss: 0.201177, Train Acc: 0.620513 | Val Loss: 0.209467, Val Acc: 0.567010\n",
      "Epoch 3737 - Train Loss: 0.201160, Train Acc: 0.620513 | Val Loss: 0.209450, Val Acc: 0.567010\n",
      "Epoch 3738 - Train Loss: 0.201143, Train Acc: 0.620513 | Val Loss: 0.209434, Val Acc: 0.567010\n",
      "Epoch 3739 - Train Loss: 0.201126, Train Acc: 0.620513 | Val Loss: 0.209418, Val Acc: 0.567010\n",
      "Epoch 3740 - Train Loss: 0.201109, Train Acc: 0.620513 | Val Loss: 0.209402, Val Acc: 0.567010\n",
      "Epoch 3741 - Train Loss: 0.201092, Train Acc: 0.620513 | Val Loss: 0.209386, Val Acc: 0.567010\n",
      "Epoch 3742 - Train Loss: 0.201075, Train Acc: 0.620513 | Val Loss: 0.209369, Val Acc: 0.567010\n",
      "Epoch 3743 - Train Loss: 0.201059, Train Acc: 0.620513 | Val Loss: 0.209353, Val Acc: 0.567010\n",
      "Epoch 3744 - Train Loss: 0.201042, Train Acc: 0.620513 | Val Loss: 0.209337, Val Acc: 0.567010\n",
      "Epoch 3745 - Train Loss: 0.201025, Train Acc: 0.620513 | Val Loss: 0.209321, Val Acc: 0.567010\n",
      "Epoch 3746 - Train Loss: 0.201008, Train Acc: 0.620513 | Val Loss: 0.209305, Val Acc: 0.567010\n",
      "Epoch 3747 - Train Loss: 0.200991, Train Acc: 0.620513 | Val Loss: 0.209288, Val Acc: 0.567010\n",
      "Epoch 3748 - Train Loss: 0.200974, Train Acc: 0.620513 | Val Loss: 0.209272, Val Acc: 0.567010\n",
      "Epoch 3749 - Train Loss: 0.200957, Train Acc: 0.620513 | Val Loss: 0.209256, Val Acc: 0.567010\n",
      "Epoch 3750 - Train Loss: 0.200941, Train Acc: 0.620513 | Val Loss: 0.209240, Val Acc: 0.567010\n",
      "Epoch 3751 - Train Loss: 0.200924, Train Acc: 0.620513 | Val Loss: 0.209224, Val Acc: 0.567010\n",
      "Epoch 3752 - Train Loss: 0.200907, Train Acc: 0.620513 | Val Loss: 0.209208, Val Acc: 0.567010\n",
      "Epoch 3753 - Train Loss: 0.200890, Train Acc: 0.620513 | Val Loss: 0.209191, Val Acc: 0.567010\n",
      "Epoch 3754 - Train Loss: 0.200873, Train Acc: 0.620513 | Val Loss: 0.209175, Val Acc: 0.567010\n",
      "Epoch 3755 - Train Loss: 0.200856, Train Acc: 0.620513 | Val Loss: 0.209159, Val Acc: 0.567010\n",
      "Epoch 3756 - Train Loss: 0.200840, Train Acc: 0.620513 | Val Loss: 0.209143, Val Acc: 0.567010\n",
      "Epoch 3757 - Train Loss: 0.200823, Train Acc: 0.620513 | Val Loss: 0.209127, Val Acc: 0.567010\n",
      "Epoch 3758 - Train Loss: 0.200806, Train Acc: 0.620513 | Val Loss: 0.209111, Val Acc: 0.567010\n",
      "Epoch 3759 - Train Loss: 0.200789, Train Acc: 0.620513 | Val Loss: 0.209095, Val Acc: 0.567010\n",
      "Epoch 3760 - Train Loss: 0.200772, Train Acc: 0.620513 | Val Loss: 0.209078, Val Acc: 0.567010\n",
      "Epoch 3761 - Train Loss: 0.200755, Train Acc: 0.620513 | Val Loss: 0.209062, Val Acc: 0.567010\n",
      "Epoch 3762 - Train Loss: 0.200739, Train Acc: 0.620513 | Val Loss: 0.209046, Val Acc: 0.567010\n",
      "Epoch 3763 - Train Loss: 0.200722, Train Acc: 0.620513 | Val Loss: 0.209030, Val Acc: 0.567010\n",
      "Epoch 3764 - Train Loss: 0.200705, Train Acc: 0.620513 | Val Loss: 0.209014, Val Acc: 0.567010\n",
      "Epoch 3765 - Train Loss: 0.200688, Train Acc: 0.620513 | Val Loss: 0.208998, Val Acc: 0.567010\n",
      "Epoch 3766 - Train Loss: 0.200671, Train Acc: 0.620513 | Val Loss: 0.208982, Val Acc: 0.567010\n",
      "Epoch 3767 - Train Loss: 0.200655, Train Acc: 0.620513 | Val Loss: 0.208966, Val Acc: 0.567010\n",
      "Epoch 3768 - Train Loss: 0.200638, Train Acc: 0.620513 | Val Loss: 0.208949, Val Acc: 0.567010\n",
      "Epoch 3769 - Train Loss: 0.200621, Train Acc: 0.620513 | Val Loss: 0.208933, Val Acc: 0.567010\n",
      "Epoch 3770 - Train Loss: 0.200604, Train Acc: 0.620513 | Val Loss: 0.208917, Val Acc: 0.567010\n",
      "Epoch 3771 - Train Loss: 0.200587, Train Acc: 0.620513 | Val Loss: 0.208901, Val Acc: 0.567010\n",
      "Epoch 3772 - Train Loss: 0.200571, Train Acc: 0.620513 | Val Loss: 0.208885, Val Acc: 0.567010\n",
      "Epoch 3773 - Train Loss: 0.200554, Train Acc: 0.620513 | Val Loss: 0.208869, Val Acc: 0.567010\n",
      "Epoch 3774 - Train Loss: 0.200537, Train Acc: 0.620513 | Val Loss: 0.208853, Val Acc: 0.577320\n",
      "Epoch 3775 - Train Loss: 0.200520, Train Acc: 0.620513 | Val Loss: 0.208837, Val Acc: 0.577320\n",
      "Epoch 3776 - Train Loss: 0.200504, Train Acc: 0.620513 | Val Loss: 0.208821, Val Acc: 0.577320\n",
      "Epoch 3777 - Train Loss: 0.200487, Train Acc: 0.620513 | Val Loss: 0.208805, Val Acc: 0.577320\n",
      "Epoch 3778 - Train Loss: 0.200470, Train Acc: 0.620513 | Val Loss: 0.208789, Val Acc: 0.577320\n",
      "Epoch 3779 - Train Loss: 0.200453, Train Acc: 0.620513 | Val Loss: 0.208772, Val Acc: 0.577320\n",
      "Epoch 3780 - Train Loss: 0.200436, Train Acc: 0.620513 | Val Loss: 0.208756, Val Acc: 0.577320\n",
      "Epoch 3781 - Train Loss: 0.200420, Train Acc: 0.620513 | Val Loss: 0.208740, Val Acc: 0.577320\n",
      "Epoch 3782 - Train Loss: 0.200403, Train Acc: 0.620513 | Val Loss: 0.208724, Val Acc: 0.577320\n",
      "Epoch 3783 - Train Loss: 0.200386, Train Acc: 0.620513 | Val Loss: 0.208708, Val Acc: 0.577320\n",
      "Epoch 3784 - Train Loss: 0.200369, Train Acc: 0.620513 | Val Loss: 0.208692, Val Acc: 0.577320\n",
      "Epoch 3785 - Train Loss: 0.200353, Train Acc: 0.620513 | Val Loss: 0.208676, Val Acc: 0.577320\n",
      "Epoch 3786 - Train Loss: 0.200336, Train Acc: 0.620513 | Val Loss: 0.208660, Val Acc: 0.577320\n",
      "Epoch 3787 - Train Loss: 0.200319, Train Acc: 0.620513 | Val Loss: 0.208644, Val Acc: 0.577320\n",
      "Epoch 3788 - Train Loss: 0.200302, Train Acc: 0.620513 | Val Loss: 0.208628, Val Acc: 0.577320\n",
      "Epoch 3789 - Train Loss: 0.200286, Train Acc: 0.620513 | Val Loss: 0.208612, Val Acc: 0.577320\n",
      "Epoch 3790 - Train Loss: 0.200269, Train Acc: 0.620513 | Val Loss: 0.208596, Val Acc: 0.577320\n",
      "Epoch 3791 - Train Loss: 0.200252, Train Acc: 0.620513 | Val Loss: 0.208580, Val Acc: 0.577320\n",
      "Epoch 3792 - Train Loss: 0.200236, Train Acc: 0.620513 | Val Loss: 0.208564, Val Acc: 0.577320\n",
      "Epoch 3793 - Train Loss: 0.200219, Train Acc: 0.620513 | Val Loss: 0.208548, Val Acc: 0.577320\n",
      "Epoch 3794 - Train Loss: 0.200202, Train Acc: 0.620513 | Val Loss: 0.208532, Val Acc: 0.577320\n",
      "Epoch 3795 - Train Loss: 0.200185, Train Acc: 0.620513 | Val Loss: 0.208516, Val Acc: 0.577320\n",
      "Epoch 3796 - Train Loss: 0.200169, Train Acc: 0.620513 | Val Loss: 0.208500, Val Acc: 0.577320\n",
      "Epoch 3797 - Train Loss: 0.200152, Train Acc: 0.620513 | Val Loss: 0.208484, Val Acc: 0.577320\n",
      "Epoch 3798 - Train Loss: 0.200135, Train Acc: 0.620513 | Val Loss: 0.208468, Val Acc: 0.577320\n",
      "Epoch 3799 - Train Loss: 0.200119, Train Acc: 0.620513 | Val Loss: 0.208452, Val Acc: 0.577320\n",
      "Epoch 3800 - Train Loss: 0.200102, Train Acc: 0.620513 | Val Loss: 0.208436, Val Acc: 0.577320\n",
      "Epoch 3801 - Train Loss: 0.200085, Train Acc: 0.620513 | Val Loss: 0.208420, Val Acc: 0.577320\n",
      "Epoch 3802 - Train Loss: 0.200068, Train Acc: 0.620513 | Val Loss: 0.208404, Val Acc: 0.577320\n",
      "Epoch 3803 - Train Loss: 0.200052, Train Acc: 0.620513 | Val Loss: 0.208388, Val Acc: 0.577320\n",
      "Epoch 3804 - Train Loss: 0.200035, Train Acc: 0.620513 | Val Loss: 0.208372, Val Acc: 0.577320\n",
      "Epoch 3805 - Train Loss: 0.200018, Train Acc: 0.620513 | Val Loss: 0.208356, Val Acc: 0.577320\n",
      "Epoch 3806 - Train Loss: 0.200002, Train Acc: 0.620513 | Val Loss: 0.208340, Val Acc: 0.577320\n",
      "Epoch 3807 - Train Loss: 0.199985, Train Acc: 0.620513 | Val Loss: 0.208324, Val Acc: 0.577320\n",
      "Epoch 3808 - Train Loss: 0.199968, Train Acc: 0.620513 | Val Loss: 0.208308, Val Acc: 0.577320\n",
      "Epoch 3809 - Train Loss: 0.199952, Train Acc: 0.620513 | Val Loss: 0.208292, Val Acc: 0.577320\n",
      "Epoch 3810 - Train Loss: 0.199935, Train Acc: 0.620513 | Val Loss: 0.208276, Val Acc: 0.577320\n",
      "Epoch 3811 - Train Loss: 0.199918, Train Acc: 0.621795 | Val Loss: 0.208260, Val Acc: 0.577320\n",
      "Epoch 3812 - Train Loss: 0.199902, Train Acc: 0.621795 | Val Loss: 0.208244, Val Acc: 0.577320\n",
      "Epoch 3813 - Train Loss: 0.199885, Train Acc: 0.621795 | Val Loss: 0.208228, Val Acc: 0.577320\n",
      "Epoch 3814 - Train Loss: 0.199868, Train Acc: 0.621795 | Val Loss: 0.208212, Val Acc: 0.577320\n",
      "Epoch 3815 - Train Loss: 0.199852, Train Acc: 0.621795 | Val Loss: 0.208196, Val Acc: 0.577320\n",
      "Epoch 3816 - Train Loss: 0.199835, Train Acc: 0.621795 | Val Loss: 0.208180, Val Acc: 0.577320\n",
      "Epoch 3817 - Train Loss: 0.199818, Train Acc: 0.621795 | Val Loss: 0.208164, Val Acc: 0.577320\n",
      "Epoch 3818 - Train Loss: 0.199802, Train Acc: 0.621795 | Val Loss: 0.208148, Val Acc: 0.577320\n",
      "Epoch 3819 - Train Loss: 0.199785, Train Acc: 0.621795 | Val Loss: 0.208132, Val Acc: 0.577320\n",
      "Epoch 3820 - Train Loss: 0.199768, Train Acc: 0.621795 | Val Loss: 0.208116, Val Acc: 0.577320\n",
      "Epoch 3821 - Train Loss: 0.199752, Train Acc: 0.621795 | Val Loss: 0.208100, Val Acc: 0.577320\n",
      "Epoch 3822 - Train Loss: 0.199735, Train Acc: 0.621795 | Val Loss: 0.208085, Val Acc: 0.577320\n",
      "Epoch 3823 - Train Loss: 0.199718, Train Acc: 0.621795 | Val Loss: 0.208069, Val Acc: 0.577320\n",
      "Epoch 3824 - Train Loss: 0.199702, Train Acc: 0.621795 | Val Loss: 0.208053, Val Acc: 0.577320\n",
      "Epoch 3825 - Train Loss: 0.199685, Train Acc: 0.623077 | Val Loss: 0.208037, Val Acc: 0.577320\n",
      "Epoch 3826 - Train Loss: 0.199669, Train Acc: 0.623077 | Val Loss: 0.208021, Val Acc: 0.577320\n",
      "Epoch 3827 - Train Loss: 0.199652, Train Acc: 0.623077 | Val Loss: 0.208005, Val Acc: 0.577320\n",
      "Epoch 3828 - Train Loss: 0.199635, Train Acc: 0.623077 | Val Loss: 0.207989, Val Acc: 0.577320\n",
      "Epoch 3829 - Train Loss: 0.199619, Train Acc: 0.623077 | Val Loss: 0.207973, Val Acc: 0.577320\n",
      "Epoch 3830 - Train Loss: 0.199602, Train Acc: 0.623077 | Val Loss: 0.207957, Val Acc: 0.577320\n",
      "Epoch 3831 - Train Loss: 0.199585, Train Acc: 0.623077 | Val Loss: 0.207941, Val Acc: 0.577320\n",
      "Epoch 3832 - Train Loss: 0.199569, Train Acc: 0.623077 | Val Loss: 0.207925, Val Acc: 0.577320\n",
      "Epoch 3833 - Train Loss: 0.199552, Train Acc: 0.623077 | Val Loss: 0.207909, Val Acc: 0.577320\n",
      "Epoch 3834 - Train Loss: 0.199536, Train Acc: 0.623077 | Val Loss: 0.207894, Val Acc: 0.577320\n",
      "Epoch 3835 - Train Loss: 0.199519, Train Acc: 0.623077 | Val Loss: 0.207878, Val Acc: 0.577320\n",
      "Epoch 3836 - Train Loss: 0.199502, Train Acc: 0.623077 | Val Loss: 0.207862, Val Acc: 0.577320\n",
      "Epoch 3837 - Train Loss: 0.199486, Train Acc: 0.623077 | Val Loss: 0.207846, Val Acc: 0.577320\n",
      "Epoch 3838 - Train Loss: 0.199469, Train Acc: 0.623077 | Val Loss: 0.207830, Val Acc: 0.577320\n",
      "Epoch 3839 - Train Loss: 0.199453, Train Acc: 0.623077 | Val Loss: 0.207814, Val Acc: 0.577320\n",
      "Epoch 3840 - Train Loss: 0.199436, Train Acc: 0.623077 | Val Loss: 0.207798, Val Acc: 0.577320\n",
      "Epoch 3841 - Train Loss: 0.199420, Train Acc: 0.623077 | Val Loss: 0.207782, Val Acc: 0.577320\n",
      "Epoch 3842 - Train Loss: 0.199403, Train Acc: 0.623077 | Val Loss: 0.207767, Val Acc: 0.577320\n",
      "Epoch 3843 - Train Loss: 0.199386, Train Acc: 0.623077 | Val Loss: 0.207751, Val Acc: 0.577320\n",
      "Epoch 3844 - Train Loss: 0.199370, Train Acc: 0.623077 | Val Loss: 0.207735, Val Acc: 0.577320\n",
      "Epoch 3845 - Train Loss: 0.199353, Train Acc: 0.623077 | Val Loss: 0.207719, Val Acc: 0.577320\n",
      "Epoch 3846 - Train Loss: 0.199337, Train Acc: 0.623077 | Val Loss: 0.207703, Val Acc: 0.577320\n",
      "Epoch 3847 - Train Loss: 0.199320, Train Acc: 0.623077 | Val Loss: 0.207687, Val Acc: 0.577320\n",
      "Epoch 3848 - Train Loss: 0.199303, Train Acc: 0.623077 | Val Loss: 0.207671, Val Acc: 0.577320\n",
      "Epoch 3849 - Train Loss: 0.199287, Train Acc: 0.623077 | Val Loss: 0.207656, Val Acc: 0.577320\n",
      "Epoch 3850 - Train Loss: 0.199270, Train Acc: 0.623077 | Val Loss: 0.207640, Val Acc: 0.577320\n",
      "Epoch 3851 - Train Loss: 0.199254, Train Acc: 0.623077 | Val Loss: 0.207624, Val Acc: 0.577320\n",
      "Epoch 3852 - Train Loss: 0.199237, Train Acc: 0.623077 | Val Loss: 0.207608, Val Acc: 0.577320\n",
      "Epoch 3853 - Train Loss: 0.199221, Train Acc: 0.623077 | Val Loss: 0.207592, Val Acc: 0.577320\n",
      "Epoch 3854 - Train Loss: 0.199204, Train Acc: 0.623077 | Val Loss: 0.207576, Val Acc: 0.577320\n",
      "Epoch 3855 - Train Loss: 0.199188, Train Acc: 0.623077 | Val Loss: 0.207561, Val Acc: 0.577320\n",
      "Epoch 3856 - Train Loss: 0.199171, Train Acc: 0.623077 | Val Loss: 0.207545, Val Acc: 0.577320\n",
      "Epoch 3857 - Train Loss: 0.199155, Train Acc: 0.623077 | Val Loss: 0.207529, Val Acc: 0.577320\n",
      "Epoch 3858 - Train Loss: 0.199138, Train Acc: 0.623077 | Val Loss: 0.207513, Val Acc: 0.577320\n",
      "Epoch 3859 - Train Loss: 0.199122, Train Acc: 0.623077 | Val Loss: 0.207497, Val Acc: 0.577320\n",
      "Epoch 3860 - Train Loss: 0.199105, Train Acc: 0.623077 | Val Loss: 0.207481, Val Acc: 0.577320\n",
      "Epoch 3861 - Train Loss: 0.199088, Train Acc: 0.623077 | Val Loss: 0.207466, Val Acc: 0.577320\n",
      "Epoch 3862 - Train Loss: 0.199072, Train Acc: 0.623077 | Val Loss: 0.207450, Val Acc: 0.577320\n",
      "Epoch 3863 - Train Loss: 0.199055, Train Acc: 0.623077 | Val Loss: 0.207434, Val Acc: 0.577320\n",
      "Epoch 3864 - Train Loss: 0.199039, Train Acc: 0.623077 | Val Loss: 0.207418, Val Acc: 0.577320\n",
      "Epoch 3865 - Train Loss: 0.199022, Train Acc: 0.623077 | Val Loss: 0.207403, Val Acc: 0.577320\n",
      "Epoch 3866 - Train Loss: 0.199006, Train Acc: 0.623077 | Val Loss: 0.207387, Val Acc: 0.577320\n",
      "Epoch 3867 - Train Loss: 0.198989, Train Acc: 0.623077 | Val Loss: 0.207371, Val Acc: 0.577320\n",
      "Epoch 3868 - Train Loss: 0.198973, Train Acc: 0.623077 | Val Loss: 0.207355, Val Acc: 0.577320\n",
      "Epoch 3869 - Train Loss: 0.198956, Train Acc: 0.623077 | Val Loss: 0.207339, Val Acc: 0.577320\n",
      "Epoch 3870 - Train Loss: 0.198940, Train Acc: 0.623077 | Val Loss: 0.207324, Val Acc: 0.577320\n",
      "Epoch 3871 - Train Loss: 0.198923, Train Acc: 0.623077 | Val Loss: 0.207308, Val Acc: 0.577320\n",
      "Epoch 3872 - Train Loss: 0.198907, Train Acc: 0.623077 | Val Loss: 0.207292, Val Acc: 0.577320\n",
      "Epoch 3873 - Train Loss: 0.198890, Train Acc: 0.623077 | Val Loss: 0.207276, Val Acc: 0.577320\n",
      "Epoch 3874 - Train Loss: 0.198874, Train Acc: 0.623077 | Val Loss: 0.207261, Val Acc: 0.577320\n",
      "Epoch 3875 - Train Loss: 0.198858, Train Acc: 0.623077 | Val Loss: 0.207245, Val Acc: 0.577320\n",
      "Epoch 3876 - Train Loss: 0.198841, Train Acc: 0.623077 | Val Loss: 0.207229, Val Acc: 0.577320\n",
      "Epoch 3877 - Train Loss: 0.198825, Train Acc: 0.623077 | Val Loss: 0.207213, Val Acc: 0.577320\n",
      "Epoch 3878 - Train Loss: 0.198808, Train Acc: 0.623077 | Val Loss: 0.207198, Val Acc: 0.577320\n",
      "Epoch 3879 - Train Loss: 0.198792, Train Acc: 0.623077 | Val Loss: 0.207182, Val Acc: 0.577320\n",
      "Epoch 3880 - Train Loss: 0.198775, Train Acc: 0.623077 | Val Loss: 0.207166, Val Acc: 0.577320\n",
      "Epoch 3881 - Train Loss: 0.198759, Train Acc: 0.623077 | Val Loss: 0.207150, Val Acc: 0.577320\n",
      "Epoch 3882 - Train Loss: 0.198742, Train Acc: 0.623077 | Val Loss: 0.207135, Val Acc: 0.577320\n",
      "Epoch 3883 - Train Loss: 0.198726, Train Acc: 0.623077 | Val Loss: 0.207119, Val Acc: 0.577320\n",
      "Epoch 3884 - Train Loss: 0.198709, Train Acc: 0.623077 | Val Loss: 0.207103, Val Acc: 0.577320\n",
      "Epoch 3885 - Train Loss: 0.198693, Train Acc: 0.623077 | Val Loss: 0.207087, Val Acc: 0.577320\n",
      "Epoch 3886 - Train Loss: 0.198676, Train Acc: 0.623077 | Val Loss: 0.207072, Val Acc: 0.577320\n",
      "Epoch 3887 - Train Loss: 0.198660, Train Acc: 0.623077 | Val Loss: 0.207056, Val Acc: 0.577320\n",
      "Epoch 3888 - Train Loss: 0.198644, Train Acc: 0.623077 | Val Loss: 0.207040, Val Acc: 0.577320\n",
      "Epoch 3889 - Train Loss: 0.198627, Train Acc: 0.623077 | Val Loss: 0.207025, Val Acc: 0.577320\n",
      "Epoch 3890 - Train Loss: 0.198611, Train Acc: 0.623077 | Val Loss: 0.207009, Val Acc: 0.577320\n",
      "Epoch 3891 - Train Loss: 0.198594, Train Acc: 0.623077 | Val Loss: 0.206993, Val Acc: 0.577320\n",
      "Epoch 3892 - Train Loss: 0.198578, Train Acc: 0.623077 | Val Loss: 0.206977, Val Acc: 0.577320\n",
      "Epoch 3893 - Train Loss: 0.198561, Train Acc: 0.623077 | Val Loss: 0.206962, Val Acc: 0.577320\n",
      "Epoch 3894 - Train Loss: 0.198545, Train Acc: 0.623077 | Val Loss: 0.206946, Val Acc: 0.577320\n",
      "Epoch 3895 - Train Loss: 0.198528, Train Acc: 0.623077 | Val Loss: 0.206930, Val Acc: 0.577320\n",
      "Epoch 3896 - Train Loss: 0.198512, Train Acc: 0.623077 | Val Loss: 0.206915, Val Acc: 0.577320\n",
      "Epoch 3897 - Train Loss: 0.198496, Train Acc: 0.623077 | Val Loss: 0.206899, Val Acc: 0.577320\n",
      "Epoch 3898 - Train Loss: 0.198479, Train Acc: 0.623077 | Val Loss: 0.206883, Val Acc: 0.577320\n",
      "Epoch 3899 - Train Loss: 0.198463, Train Acc: 0.623077 | Val Loss: 0.206868, Val Acc: 0.577320\n",
      "Epoch 3900 - Train Loss: 0.198446, Train Acc: 0.623077 | Val Loss: 0.206852, Val Acc: 0.577320\n",
      "Epoch 3901 - Train Loss: 0.198430, Train Acc: 0.623077 | Val Loss: 0.206836, Val Acc: 0.577320\n",
      "Epoch 3902 - Train Loss: 0.198414, Train Acc: 0.623077 | Val Loss: 0.206821, Val Acc: 0.577320\n",
      "Epoch 3903 - Train Loss: 0.198397, Train Acc: 0.623077 | Val Loss: 0.206805, Val Acc: 0.577320\n",
      "Epoch 3904 - Train Loss: 0.198381, Train Acc: 0.623077 | Val Loss: 0.206789, Val Acc: 0.577320\n",
      "Epoch 3905 - Train Loss: 0.198364, Train Acc: 0.623077 | Val Loss: 0.206774, Val Acc: 0.577320\n",
      "Epoch 3906 - Train Loss: 0.198348, Train Acc: 0.623077 | Val Loss: 0.206758, Val Acc: 0.577320\n",
      "Epoch 3907 - Train Loss: 0.198332, Train Acc: 0.623077 | Val Loss: 0.206742, Val Acc: 0.577320\n",
      "Epoch 3908 - Train Loss: 0.198315, Train Acc: 0.623077 | Val Loss: 0.206727, Val Acc: 0.577320\n",
      "Epoch 3909 - Train Loss: 0.198299, Train Acc: 0.623077 | Val Loss: 0.206711, Val Acc: 0.577320\n",
      "Epoch 3910 - Train Loss: 0.198282, Train Acc: 0.623077 | Val Loss: 0.206696, Val Acc: 0.577320\n",
      "Epoch 3911 - Train Loss: 0.198266, Train Acc: 0.623077 | Val Loss: 0.206680, Val Acc: 0.577320\n",
      "Epoch 3912 - Train Loss: 0.198250, Train Acc: 0.623077 | Val Loss: 0.206664, Val Acc: 0.577320\n",
      "Epoch 3913 - Train Loss: 0.198233, Train Acc: 0.623077 | Val Loss: 0.206649, Val Acc: 0.577320\n",
      "Epoch 3914 - Train Loss: 0.198217, Train Acc: 0.623077 | Val Loss: 0.206633, Val Acc: 0.577320\n",
      "Epoch 3915 - Train Loss: 0.198201, Train Acc: 0.623077 | Val Loss: 0.206617, Val Acc: 0.577320\n",
      "Epoch 3916 - Train Loss: 0.198184, Train Acc: 0.623077 | Val Loss: 0.206602, Val Acc: 0.577320\n",
      "Epoch 3917 - Train Loss: 0.198168, Train Acc: 0.623077 | Val Loss: 0.206586, Val Acc: 0.577320\n",
      "Epoch 3918 - Train Loss: 0.198151, Train Acc: 0.623077 | Val Loss: 0.206571, Val Acc: 0.577320\n",
      "Epoch 3919 - Train Loss: 0.198135, Train Acc: 0.623077 | Val Loss: 0.206555, Val Acc: 0.577320\n",
      "Epoch 3920 - Train Loss: 0.198119, Train Acc: 0.623077 | Val Loss: 0.206539, Val Acc: 0.577320\n",
      "Epoch 3921 - Train Loss: 0.198102, Train Acc: 0.623077 | Val Loss: 0.206524, Val Acc: 0.577320\n",
      "Epoch 3922 - Train Loss: 0.198086, Train Acc: 0.623077 | Val Loss: 0.206508, Val Acc: 0.577320\n",
      "Epoch 3923 - Train Loss: 0.198070, Train Acc: 0.623077 | Val Loss: 0.206493, Val Acc: 0.587629\n",
      "Epoch 3924 - Train Loss: 0.198053, Train Acc: 0.623077 | Val Loss: 0.206477, Val Acc: 0.587629\n",
      "Epoch 3925 - Train Loss: 0.198037, Train Acc: 0.623077 | Val Loss: 0.206461, Val Acc: 0.587629\n",
      "Epoch 3926 - Train Loss: 0.198021, Train Acc: 0.623077 | Val Loss: 0.206446, Val Acc: 0.587629\n",
      "Epoch 3927 - Train Loss: 0.198004, Train Acc: 0.623077 | Val Loss: 0.206430, Val Acc: 0.587629\n",
      "Epoch 3928 - Train Loss: 0.197988, Train Acc: 0.623077 | Val Loss: 0.206415, Val Acc: 0.587629\n",
      "Epoch 3929 - Train Loss: 0.197972, Train Acc: 0.623077 | Val Loss: 0.206399, Val Acc: 0.587629\n",
      "Epoch 3930 - Train Loss: 0.197955, Train Acc: 0.623077 | Val Loss: 0.206384, Val Acc: 0.587629\n",
      "Epoch 3931 - Train Loss: 0.197939, Train Acc: 0.623077 | Val Loss: 0.206368, Val Acc: 0.587629\n",
      "Epoch 3932 - Train Loss: 0.197923, Train Acc: 0.623077 | Val Loss: 0.206352, Val Acc: 0.587629\n",
      "Epoch 3933 - Train Loss: 0.197906, Train Acc: 0.623077 | Val Loss: 0.206337, Val Acc: 0.587629\n",
      "Epoch 3934 - Train Loss: 0.197890, Train Acc: 0.623077 | Val Loss: 0.206321, Val Acc: 0.587629\n",
      "Epoch 3935 - Train Loss: 0.197874, Train Acc: 0.623077 | Val Loss: 0.206306, Val Acc: 0.587629\n",
      "Epoch 3936 - Train Loss: 0.197857, Train Acc: 0.623077 | Val Loss: 0.206290, Val Acc: 0.587629\n",
      "Epoch 3937 - Train Loss: 0.197841, Train Acc: 0.623077 | Val Loss: 0.206275, Val Acc: 0.587629\n",
      "Epoch 3938 - Train Loss: 0.197825, Train Acc: 0.623077 | Val Loss: 0.206259, Val Acc: 0.587629\n",
      "Epoch 3939 - Train Loss: 0.197808, Train Acc: 0.623077 | Val Loss: 0.206244, Val Acc: 0.587629\n",
      "Epoch 3940 - Train Loss: 0.197792, Train Acc: 0.623077 | Val Loss: 0.206228, Val Acc: 0.587629\n",
      "Epoch 3941 - Train Loss: 0.197776, Train Acc: 0.623077 | Val Loss: 0.206213, Val Acc: 0.587629\n",
      "Epoch 3942 - Train Loss: 0.197760, Train Acc: 0.623077 | Val Loss: 0.206197, Val Acc: 0.587629\n",
      "Epoch 3943 - Train Loss: 0.197743, Train Acc: 0.623077 | Val Loss: 0.206181, Val Acc: 0.587629\n",
      "Epoch 3944 - Train Loss: 0.197727, Train Acc: 0.623077 | Val Loss: 0.206166, Val Acc: 0.587629\n",
      "Epoch 3945 - Train Loss: 0.197711, Train Acc: 0.623077 | Val Loss: 0.206150, Val Acc: 0.587629\n",
      "Epoch 3946 - Train Loss: 0.197694, Train Acc: 0.623077 | Val Loss: 0.206135, Val Acc: 0.587629\n",
      "Epoch 3947 - Train Loss: 0.197678, Train Acc: 0.623077 | Val Loss: 0.206119, Val Acc: 0.587629\n",
      "Epoch 3948 - Train Loss: 0.197662, Train Acc: 0.623077 | Val Loss: 0.206104, Val Acc: 0.587629\n",
      "Epoch 3949 - Train Loss: 0.197646, Train Acc: 0.623077 | Val Loss: 0.206088, Val Acc: 0.587629\n",
      "Epoch 3950 - Train Loss: 0.197629, Train Acc: 0.623077 | Val Loss: 0.206073, Val Acc: 0.587629\n",
      "Epoch 3951 - Train Loss: 0.197613, Train Acc: 0.623077 | Val Loss: 0.206057, Val Acc: 0.587629\n",
      "Epoch 3952 - Train Loss: 0.197597, Train Acc: 0.623077 | Val Loss: 0.206042, Val Acc: 0.587629\n",
      "Epoch 3953 - Train Loss: 0.197580, Train Acc: 0.623077 | Val Loss: 0.206026, Val Acc: 0.587629\n",
      "Epoch 3954 - Train Loss: 0.197564, Train Acc: 0.623077 | Val Loss: 0.206011, Val Acc: 0.587629\n",
      "Epoch 3955 - Train Loss: 0.197548, Train Acc: 0.623077 | Val Loss: 0.205995, Val Acc: 0.587629\n",
      "Epoch 3956 - Train Loss: 0.197532, Train Acc: 0.623077 | Val Loss: 0.205980, Val Acc: 0.587629\n",
      "Epoch 3957 - Train Loss: 0.197515, Train Acc: 0.623077 | Val Loss: 0.205964, Val Acc: 0.587629\n",
      "Epoch 3958 - Train Loss: 0.197499, Train Acc: 0.623077 | Val Loss: 0.205949, Val Acc: 0.587629\n",
      "Epoch 3959 - Train Loss: 0.197483, Train Acc: 0.623077 | Val Loss: 0.205933, Val Acc: 0.587629\n",
      "Epoch 3960 - Train Loss: 0.197467, Train Acc: 0.623077 | Val Loss: 0.205918, Val Acc: 0.587629\n",
      "Epoch 3961 - Train Loss: 0.197450, Train Acc: 0.623077 | Val Loss: 0.205903, Val Acc: 0.587629\n",
      "Epoch 3962 - Train Loss: 0.197434, Train Acc: 0.623077 | Val Loss: 0.205887, Val Acc: 0.587629\n",
      "Epoch 3963 - Train Loss: 0.197418, Train Acc: 0.623077 | Val Loss: 0.205872, Val Acc: 0.587629\n",
      "Epoch 3964 - Train Loss: 0.197402, Train Acc: 0.623077 | Val Loss: 0.205856, Val Acc: 0.587629\n",
      "Epoch 3965 - Train Loss: 0.197385, Train Acc: 0.623077 | Val Loss: 0.205841, Val Acc: 0.587629\n",
      "Epoch 3966 - Train Loss: 0.197369, Train Acc: 0.623077 | Val Loss: 0.205825, Val Acc: 0.587629\n",
      "Epoch 3967 - Train Loss: 0.197353, Train Acc: 0.623077 | Val Loss: 0.205810, Val Acc: 0.587629\n",
      "Epoch 3968 - Train Loss: 0.197337, Train Acc: 0.623077 | Val Loss: 0.205794, Val Acc: 0.587629\n",
      "Epoch 3969 - Train Loss: 0.197320, Train Acc: 0.623077 | Val Loss: 0.205779, Val Acc: 0.587629\n",
      "Epoch 3970 - Train Loss: 0.197304, Train Acc: 0.623077 | Val Loss: 0.205763, Val Acc: 0.587629\n",
      "Epoch 3971 - Train Loss: 0.197288, Train Acc: 0.623077 | Val Loss: 0.205748, Val Acc: 0.587629\n",
      "Epoch 3972 - Train Loss: 0.197272, Train Acc: 0.623077 | Val Loss: 0.205732, Val Acc: 0.587629\n",
      "Epoch 3973 - Train Loss: 0.197256, Train Acc: 0.623077 | Val Loss: 0.205717, Val Acc: 0.587629\n",
      "Epoch 3974 - Train Loss: 0.197239, Train Acc: 0.623077 | Val Loss: 0.205702, Val Acc: 0.587629\n",
      "Epoch 3975 - Train Loss: 0.197223, Train Acc: 0.623077 | Val Loss: 0.205686, Val Acc: 0.587629\n",
      "Epoch 3976 - Train Loss: 0.197207, Train Acc: 0.623077 | Val Loss: 0.205671, Val Acc: 0.587629\n",
      "Epoch 3977 - Train Loss: 0.197191, Train Acc: 0.623077 | Val Loss: 0.205655, Val Acc: 0.587629\n",
      "Epoch 3978 - Train Loss: 0.197175, Train Acc: 0.623077 | Val Loss: 0.205640, Val Acc: 0.587629\n",
      "Epoch 3979 - Train Loss: 0.197158, Train Acc: 0.623077 | Val Loss: 0.205624, Val Acc: 0.587629\n",
      "Epoch 3980 - Train Loss: 0.197142, Train Acc: 0.623077 | Val Loss: 0.205609, Val Acc: 0.587629\n",
      "Epoch 3981 - Train Loss: 0.197126, Train Acc: 0.623077 | Val Loss: 0.205594, Val Acc: 0.587629\n",
      "Epoch 3982 - Train Loss: 0.197110, Train Acc: 0.623077 | Val Loss: 0.205578, Val Acc: 0.587629\n",
      "Epoch 3983 - Train Loss: 0.197094, Train Acc: 0.623077 | Val Loss: 0.205563, Val Acc: 0.587629\n",
      "Epoch 3984 - Train Loss: 0.197077, Train Acc: 0.623077 | Val Loss: 0.205547, Val Acc: 0.587629\n",
      "Epoch 3985 - Train Loss: 0.197061, Train Acc: 0.623077 | Val Loss: 0.205532, Val Acc: 0.587629\n",
      "Epoch 3986 - Train Loss: 0.197045, Train Acc: 0.623077 | Val Loss: 0.205517, Val Acc: 0.587629\n",
      "Epoch 3987 - Train Loss: 0.197029, Train Acc: 0.623077 | Val Loss: 0.205501, Val Acc: 0.587629\n",
      "Epoch 3988 - Train Loss: 0.197013, Train Acc: 0.623077 | Val Loss: 0.205486, Val Acc: 0.587629\n",
      "Epoch 3989 - Train Loss: 0.196996, Train Acc: 0.623077 | Val Loss: 0.205470, Val Acc: 0.587629\n",
      "Epoch 3990 - Train Loss: 0.196980, Train Acc: 0.623077 | Val Loss: 0.205455, Val Acc: 0.587629\n",
      "Epoch 3991 - Train Loss: 0.196964, Train Acc: 0.623077 | Val Loss: 0.205440, Val Acc: 0.587629\n",
      "Epoch 3992 - Train Loss: 0.196948, Train Acc: 0.623077 | Val Loss: 0.205424, Val Acc: 0.587629\n",
      "Epoch 3993 - Train Loss: 0.196932, Train Acc: 0.623077 | Val Loss: 0.205409, Val Acc: 0.587629\n",
      "Epoch 3994 - Train Loss: 0.196916, Train Acc: 0.624359 | Val Loss: 0.205393, Val Acc: 0.587629\n",
      "Epoch 3995 - Train Loss: 0.196899, Train Acc: 0.624359 | Val Loss: 0.205378, Val Acc: 0.587629\n",
      "Epoch 3996 - Train Loss: 0.196883, Train Acc: 0.624359 | Val Loss: 0.205363, Val Acc: 0.587629\n",
      "Epoch 3997 - Train Loss: 0.196867, Train Acc: 0.624359 | Val Loss: 0.205347, Val Acc: 0.587629\n",
      "Epoch 3998 - Train Loss: 0.196851, Train Acc: 0.624359 | Val Loss: 0.205332, Val Acc: 0.587629\n",
      "Epoch 3999 - Train Loss: 0.196835, Train Acc: 0.624359 | Val Loss: 0.205317, Val Acc: 0.587629\n",
      "Epoch 4000 - Train Loss: 0.196819, Train Acc: 0.624359 | Val Loss: 0.205301, Val Acc: 0.587629\n",
      "Epoch 4001 - Train Loss: 0.196802, Train Acc: 0.624359 | Val Loss: 0.205286, Val Acc: 0.587629\n",
      "Epoch 4002 - Train Loss: 0.196786, Train Acc: 0.624359 | Val Loss: 0.205271, Val Acc: 0.587629\n",
      "Epoch 4003 - Train Loss: 0.196770, Train Acc: 0.624359 | Val Loss: 0.205255, Val Acc: 0.587629\n",
      "Epoch 4004 - Train Loss: 0.196754, Train Acc: 0.624359 | Val Loss: 0.205240, Val Acc: 0.587629\n",
      "Epoch 4005 - Train Loss: 0.196738, Train Acc: 0.624359 | Val Loss: 0.205224, Val Acc: 0.587629\n",
      "Epoch 4006 - Train Loss: 0.196722, Train Acc: 0.624359 | Val Loss: 0.205209, Val Acc: 0.587629\n",
      "Epoch 4007 - Train Loss: 0.196706, Train Acc: 0.624359 | Val Loss: 0.205194, Val Acc: 0.587629\n",
      "Epoch 4008 - Train Loss: 0.196690, Train Acc: 0.625641 | Val Loss: 0.205178, Val Acc: 0.587629\n",
      "Epoch 4009 - Train Loss: 0.196673, Train Acc: 0.625641 | Val Loss: 0.205163, Val Acc: 0.587629\n",
      "Epoch 4010 - Train Loss: 0.196657, Train Acc: 0.625641 | Val Loss: 0.205148, Val Acc: 0.587629\n",
      "Epoch 4011 - Train Loss: 0.196641, Train Acc: 0.625641 | Val Loss: 0.205132, Val Acc: 0.587629\n",
      "Epoch 4012 - Train Loss: 0.196625, Train Acc: 0.625641 | Val Loss: 0.205117, Val Acc: 0.587629\n",
      "Epoch 4013 - Train Loss: 0.196609, Train Acc: 0.625641 | Val Loss: 0.205102, Val Acc: 0.587629\n",
      "Epoch 4014 - Train Loss: 0.196593, Train Acc: 0.625641 | Val Loss: 0.205086, Val Acc: 0.587629\n",
      "Epoch 4015 - Train Loss: 0.196577, Train Acc: 0.625641 | Val Loss: 0.205071, Val Acc: 0.587629\n",
      "Epoch 4016 - Train Loss: 0.196561, Train Acc: 0.625641 | Val Loss: 0.205056, Val Acc: 0.587629\n",
      "Epoch 4017 - Train Loss: 0.196544, Train Acc: 0.625641 | Val Loss: 0.205041, Val Acc: 0.587629\n",
      "Epoch 4018 - Train Loss: 0.196528, Train Acc: 0.625641 | Val Loss: 0.205025, Val Acc: 0.587629\n",
      "Epoch 4019 - Train Loss: 0.196512, Train Acc: 0.625641 | Val Loss: 0.205010, Val Acc: 0.587629\n",
      "Epoch 4020 - Train Loss: 0.196496, Train Acc: 0.625641 | Val Loss: 0.204995, Val Acc: 0.587629\n",
      "Epoch 4021 - Train Loss: 0.196480, Train Acc: 0.625641 | Val Loss: 0.204979, Val Acc: 0.587629\n",
      "Epoch 4022 - Train Loss: 0.196464, Train Acc: 0.625641 | Val Loss: 0.204964, Val Acc: 0.587629\n",
      "Epoch 4023 - Train Loss: 0.196448, Train Acc: 0.625641 | Val Loss: 0.204949, Val Acc: 0.587629\n",
      "Epoch 4024 - Train Loss: 0.196432, Train Acc: 0.625641 | Val Loss: 0.204933, Val Acc: 0.587629\n",
      "Epoch 4025 - Train Loss: 0.196416, Train Acc: 0.625641 | Val Loss: 0.204918, Val Acc: 0.587629\n",
      "Epoch 4026 - Train Loss: 0.196400, Train Acc: 0.625641 | Val Loss: 0.204903, Val Acc: 0.587629\n",
      "Epoch 4027 - Train Loss: 0.196384, Train Acc: 0.625641 | Val Loss: 0.204888, Val Acc: 0.587629\n",
      "Epoch 4028 - Train Loss: 0.196367, Train Acc: 0.625641 | Val Loss: 0.204872, Val Acc: 0.587629\n",
      "Epoch 4029 - Train Loss: 0.196351, Train Acc: 0.625641 | Val Loss: 0.204857, Val Acc: 0.587629\n",
      "Epoch 4030 - Train Loss: 0.196335, Train Acc: 0.625641 | Val Loss: 0.204842, Val Acc: 0.587629\n",
      "Epoch 4031 - Train Loss: 0.196319, Train Acc: 0.625641 | Val Loss: 0.204827, Val Acc: 0.587629\n",
      "Epoch 4032 - Train Loss: 0.196303, Train Acc: 0.625641 | Val Loss: 0.204811, Val Acc: 0.587629\n",
      "Epoch 4033 - Train Loss: 0.196287, Train Acc: 0.625641 | Val Loss: 0.204796, Val Acc: 0.587629\n",
      "Epoch 4034 - Train Loss: 0.196271, Train Acc: 0.625641 | Val Loss: 0.204781, Val Acc: 0.587629\n",
      "Epoch 4035 - Train Loss: 0.196255, Train Acc: 0.625641 | Val Loss: 0.204765, Val Acc: 0.587629\n",
      "Epoch 4036 - Train Loss: 0.196239, Train Acc: 0.625641 | Val Loss: 0.204750, Val Acc: 0.587629\n",
      "Epoch 4037 - Train Loss: 0.196223, Train Acc: 0.625641 | Val Loss: 0.204735, Val Acc: 0.587629\n",
      "Epoch 4038 - Train Loss: 0.196207, Train Acc: 0.625641 | Val Loss: 0.204720, Val Acc: 0.587629\n",
      "Epoch 4039 - Train Loss: 0.196191, Train Acc: 0.625641 | Val Loss: 0.204704, Val Acc: 0.587629\n",
      "Epoch 4040 - Train Loss: 0.196175, Train Acc: 0.625641 | Val Loss: 0.204689, Val Acc: 0.587629\n",
      "Epoch 4041 - Train Loss: 0.196159, Train Acc: 0.625641 | Val Loss: 0.204674, Val Acc: 0.587629\n",
      "Epoch 4042 - Train Loss: 0.196143, Train Acc: 0.625641 | Val Loss: 0.204659, Val Acc: 0.587629\n",
      "Epoch 4043 - Train Loss: 0.196127, Train Acc: 0.625641 | Val Loss: 0.204644, Val Acc: 0.587629\n",
      "Epoch 4044 - Train Loss: 0.196111, Train Acc: 0.625641 | Val Loss: 0.204628, Val Acc: 0.587629\n",
      "Epoch 4045 - Train Loss: 0.196095, Train Acc: 0.625641 | Val Loss: 0.204613, Val Acc: 0.587629\n",
      "Epoch 4046 - Train Loss: 0.196079, Train Acc: 0.626923 | Val Loss: 0.204598, Val Acc: 0.587629\n",
      "Epoch 4047 - Train Loss: 0.196063, Train Acc: 0.626923 | Val Loss: 0.204583, Val Acc: 0.587629\n",
      "Epoch 4048 - Train Loss: 0.196047, Train Acc: 0.626923 | Val Loss: 0.204567, Val Acc: 0.587629\n",
      "Epoch 4049 - Train Loss: 0.196030, Train Acc: 0.626923 | Val Loss: 0.204552, Val Acc: 0.587629\n",
      "Epoch 4050 - Train Loss: 0.196014, Train Acc: 0.626923 | Val Loss: 0.204537, Val Acc: 0.587629\n",
      "Epoch 4051 - Train Loss: 0.195998, Train Acc: 0.626923 | Val Loss: 0.204522, Val Acc: 0.587629\n",
      "Epoch 4052 - Train Loss: 0.195982, Train Acc: 0.626923 | Val Loss: 0.204507, Val Acc: 0.587629\n",
      "Epoch 4053 - Train Loss: 0.195966, Train Acc: 0.626923 | Val Loss: 0.204491, Val Acc: 0.587629\n",
      "Epoch 4054 - Train Loss: 0.195950, Train Acc: 0.626923 | Val Loss: 0.204476, Val Acc: 0.587629\n",
      "Epoch 4055 - Train Loss: 0.195934, Train Acc: 0.626923 | Val Loss: 0.204461, Val Acc: 0.587629\n",
      "Epoch 4056 - Train Loss: 0.195918, Train Acc: 0.626923 | Val Loss: 0.204446, Val Acc: 0.587629\n",
      "Epoch 4057 - Train Loss: 0.195902, Train Acc: 0.626923 | Val Loss: 0.204431, Val Acc: 0.587629\n",
      "Epoch 4058 - Train Loss: 0.195886, Train Acc: 0.626923 | Val Loss: 0.204415, Val Acc: 0.587629\n",
      "Epoch 4059 - Train Loss: 0.195870, Train Acc: 0.626923 | Val Loss: 0.204400, Val Acc: 0.587629\n",
      "Epoch 4060 - Train Loss: 0.195854, Train Acc: 0.626923 | Val Loss: 0.204385, Val Acc: 0.587629\n",
      "Epoch 4061 - Train Loss: 0.195838, Train Acc: 0.626923 | Val Loss: 0.204370, Val Acc: 0.587629\n",
      "Epoch 4062 - Train Loss: 0.195822, Train Acc: 0.626923 | Val Loss: 0.204355, Val Acc: 0.587629\n",
      "Epoch 4063 - Train Loss: 0.195806, Train Acc: 0.626923 | Val Loss: 0.204339, Val Acc: 0.587629\n",
      "Epoch 4064 - Train Loss: 0.195790, Train Acc: 0.626923 | Val Loss: 0.204324, Val Acc: 0.587629\n",
      "Epoch 4065 - Train Loss: 0.195775, Train Acc: 0.626923 | Val Loss: 0.204309, Val Acc: 0.587629\n",
      "Epoch 4066 - Train Loss: 0.195759, Train Acc: 0.626923 | Val Loss: 0.204294, Val Acc: 0.587629\n",
      "Epoch 4067 - Train Loss: 0.195743, Train Acc: 0.626923 | Val Loss: 0.204279, Val Acc: 0.587629\n",
      "Epoch 4068 - Train Loss: 0.195727, Train Acc: 0.626923 | Val Loss: 0.204264, Val Acc: 0.587629\n",
      "Epoch 4069 - Train Loss: 0.195711, Train Acc: 0.626923 | Val Loss: 0.204248, Val Acc: 0.587629\n",
      "Epoch 4070 - Train Loss: 0.195695, Train Acc: 0.628205 | Val Loss: 0.204233, Val Acc: 0.587629\n",
      "Epoch 4071 - Train Loss: 0.195679, Train Acc: 0.628205 | Val Loss: 0.204218, Val Acc: 0.587629\n",
      "Epoch 4072 - Train Loss: 0.195663, Train Acc: 0.628205 | Val Loss: 0.204203, Val Acc: 0.587629\n",
      "Epoch 4073 - Train Loss: 0.195647, Train Acc: 0.628205 | Val Loss: 0.204188, Val Acc: 0.587629\n",
      "Epoch 4074 - Train Loss: 0.195631, Train Acc: 0.628205 | Val Loss: 0.204173, Val Acc: 0.587629\n",
      "Epoch 4075 - Train Loss: 0.195615, Train Acc: 0.628205 | Val Loss: 0.204158, Val Acc: 0.587629\n",
      "Epoch 4076 - Train Loss: 0.195599, Train Acc: 0.628205 | Val Loss: 0.204142, Val Acc: 0.587629\n",
      "Epoch 4077 - Train Loss: 0.195583, Train Acc: 0.628205 | Val Loss: 0.204127, Val Acc: 0.587629\n",
      "Epoch 4078 - Train Loss: 0.195567, Train Acc: 0.628205 | Val Loss: 0.204112, Val Acc: 0.587629\n",
      "Epoch 4079 - Train Loss: 0.195551, Train Acc: 0.628205 | Val Loss: 0.204097, Val Acc: 0.587629\n",
      "Epoch 4080 - Train Loss: 0.195535, Train Acc: 0.628205 | Val Loss: 0.204082, Val Acc: 0.587629\n",
      "Epoch 4081 - Train Loss: 0.195519, Train Acc: 0.628205 | Val Loss: 0.204067, Val Acc: 0.587629\n",
      "Epoch 4082 - Train Loss: 0.195503, Train Acc: 0.628205 | Val Loss: 0.204052, Val Acc: 0.587629\n",
      "Epoch 4083 - Train Loss: 0.195487, Train Acc: 0.628205 | Val Loss: 0.204036, Val Acc: 0.587629\n",
      "Epoch 4084 - Train Loss: 0.195471, Train Acc: 0.628205 | Val Loss: 0.204021, Val Acc: 0.587629\n",
      "Epoch 4085 - Train Loss: 0.195455, Train Acc: 0.628205 | Val Loss: 0.204006, Val Acc: 0.587629\n",
      "Epoch 4086 - Train Loss: 0.195440, Train Acc: 0.628205 | Val Loss: 0.203991, Val Acc: 0.587629\n",
      "Epoch 4087 - Train Loss: 0.195424, Train Acc: 0.628205 | Val Loss: 0.203976, Val Acc: 0.587629\n",
      "Epoch 4088 - Train Loss: 0.195408, Train Acc: 0.628205 | Val Loss: 0.203961, Val Acc: 0.587629\n",
      "Epoch 4089 - Train Loss: 0.195392, Train Acc: 0.628205 | Val Loss: 0.203946, Val Acc: 0.587629\n",
      "Epoch 4090 - Train Loss: 0.195376, Train Acc: 0.628205 | Val Loss: 0.203931, Val Acc: 0.587629\n",
      "Epoch 4091 - Train Loss: 0.195360, Train Acc: 0.628205 | Val Loss: 0.203916, Val Acc: 0.587629\n",
      "Epoch 4092 - Train Loss: 0.195344, Train Acc: 0.628205 | Val Loss: 0.203900, Val Acc: 0.587629\n",
      "Epoch 4093 - Train Loss: 0.195328, Train Acc: 0.628205 | Val Loss: 0.203885, Val Acc: 0.587629\n",
      "Epoch 4094 - Train Loss: 0.195312, Train Acc: 0.628205 | Val Loss: 0.203870, Val Acc: 0.587629\n",
      "Epoch 4095 - Train Loss: 0.195296, Train Acc: 0.628205 | Val Loss: 0.203855, Val Acc: 0.587629\n",
      "Epoch 4096 - Train Loss: 0.195280, Train Acc: 0.628205 | Val Loss: 0.203840, Val Acc: 0.587629\n",
      "Epoch 4097 - Train Loss: 0.195265, Train Acc: 0.628205 | Val Loss: 0.203825, Val Acc: 0.587629\n",
      "Epoch 4098 - Train Loss: 0.195249, Train Acc: 0.628205 | Val Loss: 0.203810, Val Acc: 0.587629\n",
      "Epoch 4099 - Train Loss: 0.195233, Train Acc: 0.628205 | Val Loss: 0.203795, Val Acc: 0.587629\n",
      "Epoch 4100 - Train Loss: 0.195217, Train Acc: 0.629487 | Val Loss: 0.203780, Val Acc: 0.587629\n",
      "Epoch 4101 - Train Loss: 0.195201, Train Acc: 0.629487 | Val Loss: 0.203765, Val Acc: 0.587629\n",
      "Epoch 4102 - Train Loss: 0.195185, Train Acc: 0.629487 | Val Loss: 0.203750, Val Acc: 0.587629\n",
      "Epoch 4103 - Train Loss: 0.195169, Train Acc: 0.629487 | Val Loss: 0.203735, Val Acc: 0.587629\n",
      "Epoch 4104 - Train Loss: 0.195153, Train Acc: 0.629487 | Val Loss: 0.203719, Val Acc: 0.587629\n",
      "Epoch 4105 - Train Loss: 0.195137, Train Acc: 0.629487 | Val Loss: 0.203704, Val Acc: 0.587629\n",
      "Epoch 4106 - Train Loss: 0.195122, Train Acc: 0.629487 | Val Loss: 0.203689, Val Acc: 0.587629\n",
      "Epoch 4107 - Train Loss: 0.195106, Train Acc: 0.629487 | Val Loss: 0.203674, Val Acc: 0.587629\n",
      "Epoch 4108 - Train Loss: 0.195090, Train Acc: 0.629487 | Val Loss: 0.203659, Val Acc: 0.587629\n",
      "Epoch 4109 - Train Loss: 0.195074, Train Acc: 0.629487 | Val Loss: 0.203644, Val Acc: 0.587629\n",
      "Epoch 4110 - Train Loss: 0.195058, Train Acc: 0.629487 | Val Loss: 0.203629, Val Acc: 0.587629\n",
      "Epoch 4111 - Train Loss: 0.195042, Train Acc: 0.629487 | Val Loss: 0.203614, Val Acc: 0.587629\n",
      "Epoch 4112 - Train Loss: 0.195026, Train Acc: 0.629487 | Val Loss: 0.203599, Val Acc: 0.587629\n",
      "Epoch 4113 - Train Loss: 0.195011, Train Acc: 0.629487 | Val Loss: 0.203584, Val Acc: 0.587629\n",
      "Epoch 4114 - Train Loss: 0.194995, Train Acc: 0.629487 | Val Loss: 0.203569, Val Acc: 0.587629\n",
      "Epoch 4115 - Train Loss: 0.194979, Train Acc: 0.629487 | Val Loss: 0.203554, Val Acc: 0.587629\n",
      "Epoch 4116 - Train Loss: 0.194963, Train Acc: 0.629487 | Val Loss: 0.203539, Val Acc: 0.587629\n",
      "Epoch 4117 - Train Loss: 0.194947, Train Acc: 0.629487 | Val Loss: 0.203524, Val Acc: 0.587629\n",
      "Epoch 4118 - Train Loss: 0.194931, Train Acc: 0.629487 | Val Loss: 0.203509, Val Acc: 0.587629\n",
      "Epoch 4119 - Train Loss: 0.194915, Train Acc: 0.629487 | Val Loss: 0.203494, Val Acc: 0.587629\n",
      "Epoch 4120 - Train Loss: 0.194900, Train Acc: 0.629487 | Val Loss: 0.203479, Val Acc: 0.587629\n",
      "Epoch 4121 - Train Loss: 0.194884, Train Acc: 0.629487 | Val Loss: 0.203464, Val Acc: 0.587629\n",
      "Epoch 4122 - Train Loss: 0.194868, Train Acc: 0.629487 | Val Loss: 0.203449, Val Acc: 0.587629\n",
      "Epoch 4123 - Train Loss: 0.194852, Train Acc: 0.629487 | Val Loss: 0.203434, Val Acc: 0.587629\n",
      "Epoch 4124 - Train Loss: 0.194836, Train Acc: 0.629487 | Val Loss: 0.203419, Val Acc: 0.587629\n",
      "Epoch 4125 - Train Loss: 0.194820, Train Acc: 0.629487 | Val Loss: 0.203404, Val Acc: 0.587629\n",
      "Epoch 4126 - Train Loss: 0.194805, Train Acc: 0.629487 | Val Loss: 0.203389, Val Acc: 0.587629\n",
      "Epoch 4127 - Train Loss: 0.194789, Train Acc: 0.629487 | Val Loss: 0.203374, Val Acc: 0.587629\n",
      "Epoch 4128 - Train Loss: 0.194773, Train Acc: 0.629487 | Val Loss: 0.203359, Val Acc: 0.587629\n",
      "Epoch 4129 - Train Loss: 0.194757, Train Acc: 0.629487 | Val Loss: 0.203344, Val Acc: 0.587629\n",
      "Epoch 4130 - Train Loss: 0.194741, Train Acc: 0.629487 | Val Loss: 0.203329, Val Acc: 0.587629\n",
      "Epoch 4131 - Train Loss: 0.194726, Train Acc: 0.629487 | Val Loss: 0.203314, Val Acc: 0.587629\n",
      "Epoch 4132 - Train Loss: 0.194710, Train Acc: 0.630769 | Val Loss: 0.203299, Val Acc: 0.587629\n",
      "Epoch 4133 - Train Loss: 0.194694, Train Acc: 0.630769 | Val Loss: 0.203284, Val Acc: 0.587629\n",
      "Epoch 4134 - Train Loss: 0.194678, Train Acc: 0.630769 | Val Loss: 0.203269, Val Acc: 0.587629\n",
      "Epoch 4135 - Train Loss: 0.194662, Train Acc: 0.630769 | Val Loss: 0.203254, Val Acc: 0.587629\n",
      "Epoch 4136 - Train Loss: 0.194647, Train Acc: 0.630769 | Val Loss: 0.203239, Val Acc: 0.587629\n",
      "Epoch 4137 - Train Loss: 0.194631, Train Acc: 0.630769 | Val Loss: 0.203224, Val Acc: 0.587629\n",
      "Epoch 4138 - Train Loss: 0.194615, Train Acc: 0.630769 | Val Loss: 0.203209, Val Acc: 0.587629\n",
      "Epoch 4139 - Train Loss: 0.194599, Train Acc: 0.630769 | Val Loss: 0.203194, Val Acc: 0.587629\n",
      "Epoch 4140 - Train Loss: 0.194583, Train Acc: 0.630769 | Val Loss: 0.203179, Val Acc: 0.587629\n",
      "Epoch 4141 - Train Loss: 0.194568, Train Acc: 0.630769 | Val Loss: 0.203164, Val Acc: 0.587629\n",
      "Epoch 4142 - Train Loss: 0.194552, Train Acc: 0.630769 | Val Loss: 0.203149, Val Acc: 0.587629\n",
      "Epoch 4143 - Train Loss: 0.194536, Train Acc: 0.630769 | Val Loss: 0.203134, Val Acc: 0.587629\n",
      "Epoch 4144 - Train Loss: 0.194520, Train Acc: 0.630769 | Val Loss: 0.203119, Val Acc: 0.587629\n",
      "Epoch 4145 - Train Loss: 0.194504, Train Acc: 0.630769 | Val Loss: 0.203104, Val Acc: 0.587629\n",
      "Epoch 4146 - Train Loss: 0.194489, Train Acc: 0.630769 | Val Loss: 0.203089, Val Acc: 0.587629\n",
      "Epoch 4147 - Train Loss: 0.194473, Train Acc: 0.630769 | Val Loss: 0.203074, Val Acc: 0.587629\n",
      "Epoch 4148 - Train Loss: 0.194457, Train Acc: 0.630769 | Val Loss: 0.203059, Val Acc: 0.587629\n",
      "Epoch 4149 - Train Loss: 0.194441, Train Acc: 0.630769 | Val Loss: 0.203044, Val Acc: 0.587629\n",
      "Epoch 4150 - Train Loss: 0.194426, Train Acc: 0.630769 | Val Loss: 0.203029, Val Acc: 0.587629\n",
      "Epoch 4151 - Train Loss: 0.194410, Train Acc: 0.630769 | Val Loss: 0.203014, Val Acc: 0.587629\n",
      "Epoch 4152 - Train Loss: 0.194394, Train Acc: 0.630769 | Val Loss: 0.203000, Val Acc: 0.587629\n",
      "Epoch 4153 - Train Loss: 0.194378, Train Acc: 0.630769 | Val Loss: 0.202985, Val Acc: 0.587629\n",
      "Epoch 4154 - Train Loss: 0.194363, Train Acc: 0.630769 | Val Loss: 0.202970, Val Acc: 0.587629\n",
      "Epoch 4155 - Train Loss: 0.194347, Train Acc: 0.630769 | Val Loss: 0.202955, Val Acc: 0.587629\n",
      "Epoch 4156 - Train Loss: 0.194331, Train Acc: 0.630769 | Val Loss: 0.202940, Val Acc: 0.587629\n",
      "Epoch 4157 - Train Loss: 0.194315, Train Acc: 0.630769 | Val Loss: 0.202925, Val Acc: 0.587629\n",
      "Epoch 4158 - Train Loss: 0.194300, Train Acc: 0.630769 | Val Loss: 0.202910, Val Acc: 0.587629\n",
      "Epoch 4159 - Train Loss: 0.194284, Train Acc: 0.630769 | Val Loss: 0.202895, Val Acc: 0.587629\n",
      "Epoch 4160 - Train Loss: 0.194268, Train Acc: 0.630769 | Val Loss: 0.202880, Val Acc: 0.587629\n",
      "Epoch 4161 - Train Loss: 0.194252, Train Acc: 0.630769 | Val Loss: 0.202865, Val Acc: 0.587629\n",
      "Epoch 4162 - Train Loss: 0.194237, Train Acc: 0.630769 | Val Loss: 0.202850, Val Acc: 0.587629\n",
      "Epoch 4163 - Train Loss: 0.194221, Train Acc: 0.630769 | Val Loss: 0.202835, Val Acc: 0.587629\n",
      "Epoch 4164 - Train Loss: 0.194205, Train Acc: 0.630769 | Val Loss: 0.202821, Val Acc: 0.587629\n",
      "Epoch 4165 - Train Loss: 0.194189, Train Acc: 0.630769 | Val Loss: 0.202806, Val Acc: 0.587629\n",
      "Epoch 4166 - Train Loss: 0.194174, Train Acc: 0.630769 | Val Loss: 0.202791, Val Acc: 0.587629\n",
      "Epoch 4167 - Train Loss: 0.194158, Train Acc: 0.630769 | Val Loss: 0.202776, Val Acc: 0.587629\n",
      "Epoch 4168 - Train Loss: 0.194142, Train Acc: 0.630769 | Val Loss: 0.202761, Val Acc: 0.587629\n",
      "Epoch 4169 - Train Loss: 0.194127, Train Acc: 0.630769 | Val Loss: 0.202746, Val Acc: 0.587629\n",
      "Epoch 4170 - Train Loss: 0.194111, Train Acc: 0.630769 | Val Loss: 0.202731, Val Acc: 0.587629\n",
      "Epoch 4171 - Train Loss: 0.194095, Train Acc: 0.630769 | Val Loss: 0.202716, Val Acc: 0.587629\n",
      "Epoch 4172 - Train Loss: 0.194079, Train Acc: 0.630769 | Val Loss: 0.202701, Val Acc: 0.587629\n",
      "Epoch 4173 - Train Loss: 0.194064, Train Acc: 0.630769 | Val Loss: 0.202687, Val Acc: 0.587629\n",
      "Epoch 4174 - Train Loss: 0.194048, Train Acc: 0.630769 | Val Loss: 0.202672, Val Acc: 0.587629\n",
      "Epoch 4175 - Train Loss: 0.194032, Train Acc: 0.630769 | Val Loss: 0.202657, Val Acc: 0.587629\n",
      "Epoch 4176 - Train Loss: 0.194017, Train Acc: 0.630769 | Val Loss: 0.202642, Val Acc: 0.587629\n",
      "Epoch 4177 - Train Loss: 0.194001, Train Acc: 0.630769 | Val Loss: 0.202627, Val Acc: 0.587629\n",
      "Epoch 4178 - Train Loss: 0.193985, Train Acc: 0.630769 | Val Loss: 0.202612, Val Acc: 0.587629\n",
      "Epoch 4179 - Train Loss: 0.193970, Train Acc: 0.630769 | Val Loss: 0.202597, Val Acc: 0.587629\n",
      "Epoch 4180 - Train Loss: 0.193954, Train Acc: 0.630769 | Val Loss: 0.202582, Val Acc: 0.587629\n",
      "Epoch 4181 - Train Loss: 0.193938, Train Acc: 0.630769 | Val Loss: 0.202568, Val Acc: 0.587629\n",
      "Epoch 4182 - Train Loss: 0.193923, Train Acc: 0.630769 | Val Loss: 0.202553, Val Acc: 0.587629\n",
      "Epoch 4183 - Train Loss: 0.193907, Train Acc: 0.630769 | Val Loss: 0.202538, Val Acc: 0.587629\n",
      "Epoch 4184 - Train Loss: 0.193891, Train Acc: 0.630769 | Val Loss: 0.202523, Val Acc: 0.587629\n",
      "Epoch 4185 - Train Loss: 0.193875, Train Acc: 0.630769 | Val Loss: 0.202508, Val Acc: 0.587629\n",
      "Epoch 4186 - Train Loss: 0.193860, Train Acc: 0.630769 | Val Loss: 0.202493, Val Acc: 0.587629\n",
      "Epoch 4187 - Train Loss: 0.193844, Train Acc: 0.630769 | Val Loss: 0.202479, Val Acc: 0.587629\n",
      "Epoch 4188 - Train Loss: 0.193828, Train Acc: 0.630769 | Val Loss: 0.202464, Val Acc: 0.587629\n",
      "Epoch 4189 - Train Loss: 0.193813, Train Acc: 0.630769 | Val Loss: 0.202449, Val Acc: 0.587629\n",
      "Epoch 4190 - Train Loss: 0.193797, Train Acc: 0.630769 | Val Loss: 0.202434, Val Acc: 0.587629\n",
      "Epoch 4191 - Train Loss: 0.193781, Train Acc: 0.630769 | Val Loss: 0.202419, Val Acc: 0.587629\n",
      "Epoch 4192 - Train Loss: 0.193766, Train Acc: 0.630769 | Val Loss: 0.202404, Val Acc: 0.587629\n",
      "Epoch 4193 - Train Loss: 0.193750, Train Acc: 0.630769 | Val Loss: 0.202389, Val Acc: 0.587629\n",
      "Epoch 4194 - Train Loss: 0.193735, Train Acc: 0.630769 | Val Loss: 0.202374, Val Acc: 0.587629\n",
      "Epoch 4195 - Train Loss: 0.193719, Train Acc: 0.630769 | Val Loss: 0.202359, Val Acc: 0.587629\n",
      "Epoch 4196 - Train Loss: 0.193703, Train Acc: 0.630769 | Val Loss: 0.202345, Val Acc: 0.587629\n",
      "Epoch 4197 - Train Loss: 0.193688, Train Acc: 0.630769 | Val Loss: 0.202330, Val Acc: 0.587629\n",
      "Epoch 4198 - Train Loss: 0.193672, Train Acc: 0.630769 | Val Loss: 0.202315, Val Acc: 0.587629\n",
      "Epoch 4199 - Train Loss: 0.193656, Train Acc: 0.630769 | Val Loss: 0.202300, Val Acc: 0.587629\n",
      "Epoch 4200 - Train Loss: 0.193641, Train Acc: 0.630769 | Val Loss: 0.202285, Val Acc: 0.587629\n",
      "Epoch 4201 - Train Loss: 0.193625, Train Acc: 0.630769 | Val Loss: 0.202270, Val Acc: 0.587629\n",
      "Epoch 4202 - Train Loss: 0.193609, Train Acc: 0.632051 | Val Loss: 0.202255, Val Acc: 0.587629\n",
      "Epoch 4203 - Train Loss: 0.193594, Train Acc: 0.632051 | Val Loss: 0.202240, Val Acc: 0.587629\n",
      "Epoch 4204 - Train Loss: 0.193578, Train Acc: 0.632051 | Val Loss: 0.202226, Val Acc: 0.587629\n",
      "Epoch 4205 - Train Loss: 0.193562, Train Acc: 0.632051 | Val Loss: 0.202211, Val Acc: 0.587629\n",
      "Epoch 4206 - Train Loss: 0.193547, Train Acc: 0.632051 | Val Loss: 0.202196, Val Acc: 0.587629\n",
      "Epoch 4207 - Train Loss: 0.193531, Train Acc: 0.632051 | Val Loss: 0.202181, Val Acc: 0.587629\n",
      "Epoch 4208 - Train Loss: 0.193516, Train Acc: 0.632051 | Val Loss: 0.202166, Val Acc: 0.587629\n",
      "Epoch 4209 - Train Loss: 0.193500, Train Acc: 0.632051 | Val Loss: 0.202151, Val Acc: 0.587629\n",
      "Epoch 4210 - Train Loss: 0.193484, Train Acc: 0.632051 | Val Loss: 0.202136, Val Acc: 0.587629\n",
      "Epoch 4211 - Train Loss: 0.193469, Train Acc: 0.632051 | Val Loss: 0.202121, Val Acc: 0.587629\n",
      "Epoch 4212 - Train Loss: 0.193453, Train Acc: 0.632051 | Val Loss: 0.202107, Val Acc: 0.587629\n",
      "Epoch 4213 - Train Loss: 0.193438, Train Acc: 0.632051 | Val Loss: 0.202092, Val Acc: 0.587629\n",
      "Epoch 4214 - Train Loss: 0.193422, Train Acc: 0.632051 | Val Loss: 0.202077, Val Acc: 0.587629\n",
      "Epoch 4215 - Train Loss: 0.193406, Train Acc: 0.632051 | Val Loss: 0.202062, Val Acc: 0.587629\n",
      "Epoch 4216 - Train Loss: 0.193391, Train Acc: 0.632051 | Val Loss: 0.202047, Val Acc: 0.587629\n",
      "Epoch 4217 - Train Loss: 0.193375, Train Acc: 0.632051 | Val Loss: 0.202032, Val Acc: 0.587629\n",
      "Epoch 4218 - Train Loss: 0.193360, Train Acc: 0.632051 | Val Loss: 0.202018, Val Acc: 0.587629\n",
      "Epoch 4219 - Train Loss: 0.193344, Train Acc: 0.632051 | Val Loss: 0.202003, Val Acc: 0.587629\n",
      "Epoch 4220 - Train Loss: 0.193328, Train Acc: 0.632051 | Val Loss: 0.201988, Val Acc: 0.587629\n",
      "Epoch 4221 - Train Loss: 0.193313, Train Acc: 0.632051 | Val Loss: 0.201973, Val Acc: 0.587629\n",
      "Epoch 4222 - Train Loss: 0.193297, Train Acc: 0.632051 | Val Loss: 0.201958, Val Acc: 0.587629\n",
      "Epoch 4223 - Train Loss: 0.193282, Train Acc: 0.632051 | Val Loss: 0.201943, Val Acc: 0.587629\n",
      "Epoch 4224 - Train Loss: 0.193266, Train Acc: 0.632051 | Val Loss: 0.201929, Val Acc: 0.587629\n",
      "Epoch 4225 - Train Loss: 0.193250, Train Acc: 0.632051 | Val Loss: 0.201914, Val Acc: 0.587629\n",
      "Epoch 4226 - Train Loss: 0.193235, Train Acc: 0.632051 | Val Loss: 0.201899, Val Acc: 0.587629\n",
      "Epoch 4227 - Train Loss: 0.193219, Train Acc: 0.632051 | Val Loss: 0.201884, Val Acc: 0.587629\n",
      "Epoch 4228 - Train Loss: 0.193204, Train Acc: 0.632051 | Val Loss: 0.201869, Val Acc: 0.587629\n",
      "Epoch 4229 - Train Loss: 0.193188, Train Acc: 0.632051 | Val Loss: 0.201855, Val Acc: 0.587629\n",
      "Epoch 4230 - Train Loss: 0.193173, Train Acc: 0.632051 | Val Loss: 0.201840, Val Acc: 0.587629\n",
      "Epoch 4231 - Train Loss: 0.193157, Train Acc: 0.632051 | Val Loss: 0.201825, Val Acc: 0.587629\n",
      "Epoch 4232 - Train Loss: 0.193141, Train Acc: 0.632051 | Val Loss: 0.201810, Val Acc: 0.587629\n",
      "Epoch 4233 - Train Loss: 0.193126, Train Acc: 0.632051 | Val Loss: 0.201795, Val Acc: 0.587629\n",
      "Epoch 4234 - Train Loss: 0.193110, Train Acc: 0.632051 | Val Loss: 0.201781, Val Acc: 0.587629\n",
      "Epoch 4235 - Train Loss: 0.193095, Train Acc: 0.632051 | Val Loss: 0.201766, Val Acc: 0.587629\n",
      "Epoch 4236 - Train Loss: 0.193079, Train Acc: 0.632051 | Val Loss: 0.201751, Val Acc: 0.587629\n",
      "Epoch 4237 - Train Loss: 0.193064, Train Acc: 0.632051 | Val Loss: 0.201736, Val Acc: 0.587629\n",
      "Epoch 4238 - Train Loss: 0.193048, Train Acc: 0.630769 | Val Loss: 0.201722, Val Acc: 0.587629\n",
      "Epoch 4239 - Train Loss: 0.193033, Train Acc: 0.630769 | Val Loss: 0.201707, Val Acc: 0.587629\n",
      "Epoch 4240 - Train Loss: 0.193017, Train Acc: 0.630769 | Val Loss: 0.201692, Val Acc: 0.587629\n",
      "Epoch 4241 - Train Loss: 0.193001, Train Acc: 0.630769 | Val Loss: 0.201678, Val Acc: 0.587629\n",
      "Epoch 4242 - Train Loss: 0.192986, Train Acc: 0.630769 | Val Loss: 0.201663, Val Acc: 0.587629\n",
      "Epoch 4243 - Train Loss: 0.192970, Train Acc: 0.630769 | Val Loss: 0.201648, Val Acc: 0.587629\n",
      "Epoch 4244 - Train Loss: 0.192955, Train Acc: 0.630769 | Val Loss: 0.201633, Val Acc: 0.587629\n",
      "Epoch 4245 - Train Loss: 0.192939, Train Acc: 0.630769 | Val Loss: 0.201619, Val Acc: 0.587629\n",
      "Epoch 4246 - Train Loss: 0.192924, Train Acc: 0.630769 | Val Loss: 0.201604, Val Acc: 0.587629\n",
      "Epoch 4247 - Train Loss: 0.192908, Train Acc: 0.630769 | Val Loss: 0.201589, Val Acc: 0.587629\n",
      "Epoch 4248 - Train Loss: 0.192893, Train Acc: 0.630769 | Val Loss: 0.201575, Val Acc: 0.587629\n",
      "Epoch 4249 - Train Loss: 0.192877, Train Acc: 0.630769 | Val Loss: 0.201560, Val Acc: 0.587629\n",
      "Epoch 4250 - Train Loss: 0.192862, Train Acc: 0.630769 | Val Loss: 0.201545, Val Acc: 0.587629\n",
      "Epoch 4251 - Train Loss: 0.192846, Train Acc: 0.630769 | Val Loss: 0.201531, Val Acc: 0.587629\n",
      "Epoch 4252 - Train Loss: 0.192831, Train Acc: 0.630769 | Val Loss: 0.201516, Val Acc: 0.587629\n",
      "Epoch 4253 - Train Loss: 0.192815, Train Acc: 0.630769 | Val Loss: 0.201501, Val Acc: 0.587629\n",
      "Epoch 4254 - Train Loss: 0.192800, Train Acc: 0.630769 | Val Loss: 0.201487, Val Acc: 0.587629\n",
      "Epoch 4255 - Train Loss: 0.192784, Train Acc: 0.630769 | Val Loss: 0.201472, Val Acc: 0.587629\n",
      "Epoch 4256 - Train Loss: 0.192769, Train Acc: 0.630769 | Val Loss: 0.201457, Val Acc: 0.587629\n",
      "Epoch 4257 - Train Loss: 0.192753, Train Acc: 0.630769 | Val Loss: 0.201443, Val Acc: 0.587629\n",
      "Epoch 4258 - Train Loss: 0.192738, Train Acc: 0.630769 | Val Loss: 0.201428, Val Acc: 0.587629\n",
      "Epoch 4259 - Train Loss: 0.192722, Train Acc: 0.630769 | Val Loss: 0.201413, Val Acc: 0.587629\n",
      "Epoch 4260 - Train Loss: 0.192707, Train Acc: 0.630769 | Val Loss: 0.201399, Val Acc: 0.587629\n",
      "Epoch 4261 - Train Loss: 0.192691, Train Acc: 0.630769 | Val Loss: 0.201384, Val Acc: 0.587629\n",
      "Epoch 4262 - Train Loss: 0.192676, Train Acc: 0.630769 | Val Loss: 0.201370, Val Acc: 0.597938\n",
      "Epoch 4263 - Train Loss: 0.192660, Train Acc: 0.630769 | Val Loss: 0.201355, Val Acc: 0.597938\n",
      "Epoch 4264 - Train Loss: 0.192645, Train Acc: 0.630769 | Val Loss: 0.201340, Val Acc: 0.597938\n",
      "Epoch 4265 - Train Loss: 0.192629, Train Acc: 0.630769 | Val Loss: 0.201326, Val Acc: 0.597938\n",
      "Epoch 4266 - Train Loss: 0.192614, Train Acc: 0.630769 | Val Loss: 0.201311, Val Acc: 0.597938\n",
      "Epoch 4267 - Train Loss: 0.192598, Train Acc: 0.630769 | Val Loss: 0.201296, Val Acc: 0.597938\n",
      "Epoch 4268 - Train Loss: 0.192583, Train Acc: 0.630769 | Val Loss: 0.201282, Val Acc: 0.597938\n",
      "Epoch 4269 - Train Loss: 0.192567, Train Acc: 0.630769 | Val Loss: 0.201267, Val Acc: 0.597938\n",
      "Epoch 4270 - Train Loss: 0.192552, Train Acc: 0.630769 | Val Loss: 0.201252, Val Acc: 0.597938\n",
      "Epoch 4271 - Train Loss: 0.192536, Train Acc: 0.630769 | Val Loss: 0.201238, Val Acc: 0.597938\n",
      "Epoch 4272 - Train Loss: 0.192521, Train Acc: 0.630769 | Val Loss: 0.201223, Val Acc: 0.597938\n",
      "Epoch 4273 - Train Loss: 0.192505, Train Acc: 0.630769 | Val Loss: 0.201209, Val Acc: 0.597938\n",
      "Epoch 4274 - Train Loss: 0.192490, Train Acc: 0.630769 | Val Loss: 0.201194, Val Acc: 0.597938\n",
      "Epoch 4275 - Train Loss: 0.192474, Train Acc: 0.630769 | Val Loss: 0.201179, Val Acc: 0.597938\n",
      "Epoch 4276 - Train Loss: 0.192459, Train Acc: 0.630769 | Val Loss: 0.201165, Val Acc: 0.597938\n",
      "Epoch 4277 - Train Loss: 0.192444, Train Acc: 0.630769 | Val Loss: 0.201150, Val Acc: 0.597938\n",
      "Epoch 4278 - Train Loss: 0.192428, Train Acc: 0.630769 | Val Loss: 0.201136, Val Acc: 0.597938\n",
      "Epoch 4279 - Train Loss: 0.192413, Train Acc: 0.632051 | Val Loss: 0.201121, Val Acc: 0.597938\n",
      "Epoch 4280 - Train Loss: 0.192397, Train Acc: 0.632051 | Val Loss: 0.201106, Val Acc: 0.597938\n",
      "Epoch 4281 - Train Loss: 0.192382, Train Acc: 0.632051 | Val Loss: 0.201092, Val Acc: 0.597938\n",
      "Epoch 4282 - Train Loss: 0.192366, Train Acc: 0.632051 | Val Loss: 0.201077, Val Acc: 0.597938\n",
      "Epoch 4283 - Train Loss: 0.192351, Train Acc: 0.632051 | Val Loss: 0.201063, Val Acc: 0.597938\n",
      "Epoch 4284 - Train Loss: 0.192335, Train Acc: 0.632051 | Val Loss: 0.201048, Val Acc: 0.597938\n",
      "Epoch 4285 - Train Loss: 0.192320, Train Acc: 0.632051 | Val Loss: 0.201033, Val Acc: 0.597938\n",
      "Epoch 4286 - Train Loss: 0.192305, Train Acc: 0.632051 | Val Loss: 0.201019, Val Acc: 0.597938\n",
      "Epoch 4287 - Train Loss: 0.192289, Train Acc: 0.632051 | Val Loss: 0.201004, Val Acc: 0.597938\n",
      "Epoch 4288 - Train Loss: 0.192274, Train Acc: 0.632051 | Val Loss: 0.200990, Val Acc: 0.597938\n",
      "Epoch 4289 - Train Loss: 0.192258, Train Acc: 0.632051 | Val Loss: 0.200975, Val Acc: 0.597938\n",
      "Epoch 4290 - Train Loss: 0.192243, Train Acc: 0.632051 | Val Loss: 0.200961, Val Acc: 0.597938\n",
      "Epoch 4291 - Train Loss: 0.192227, Train Acc: 0.632051 | Val Loss: 0.200946, Val Acc: 0.597938\n",
      "Epoch 4292 - Train Loss: 0.192212, Train Acc: 0.630769 | Val Loss: 0.200931, Val Acc: 0.597938\n",
      "Epoch 4293 - Train Loss: 0.192197, Train Acc: 0.630769 | Val Loss: 0.200917, Val Acc: 0.597938\n",
      "Epoch 4294 - Train Loss: 0.192181, Train Acc: 0.630769 | Val Loss: 0.200902, Val Acc: 0.597938\n",
      "Epoch 4295 - Train Loss: 0.192166, Train Acc: 0.633333 | Val Loss: 0.200888, Val Acc: 0.597938\n",
      "Epoch 4296 - Train Loss: 0.192150, Train Acc: 0.633333 | Val Loss: 0.200873, Val Acc: 0.597938\n",
      "Epoch 4297 - Train Loss: 0.192135, Train Acc: 0.633333 | Val Loss: 0.200859, Val Acc: 0.597938\n",
      "Epoch 4298 - Train Loss: 0.192120, Train Acc: 0.633333 | Val Loss: 0.200844, Val Acc: 0.597938\n",
      "Epoch 4299 - Train Loss: 0.192104, Train Acc: 0.633333 | Val Loss: 0.200830, Val Acc: 0.597938\n",
      "Epoch 4300 - Train Loss: 0.192089, Train Acc: 0.633333 | Val Loss: 0.200815, Val Acc: 0.597938\n",
      "Epoch 4301 - Train Loss: 0.192073, Train Acc: 0.633333 | Val Loss: 0.200801, Val Acc: 0.597938\n",
      "Epoch 4302 - Train Loss: 0.192058, Train Acc: 0.633333 | Val Loss: 0.200786, Val Acc: 0.597938\n",
      "Epoch 4303 - Train Loss: 0.192043, Train Acc: 0.633333 | Val Loss: 0.200772, Val Acc: 0.597938\n",
      "Epoch 4304 - Train Loss: 0.192027, Train Acc: 0.633333 | Val Loss: 0.200757, Val Acc: 0.597938\n",
      "Epoch 4305 - Train Loss: 0.192012, Train Acc: 0.633333 | Val Loss: 0.200742, Val Acc: 0.597938\n",
      "Epoch 4306 - Train Loss: 0.191996, Train Acc: 0.633333 | Val Loss: 0.200728, Val Acc: 0.597938\n",
      "Epoch 4307 - Train Loss: 0.191981, Train Acc: 0.633333 | Val Loss: 0.200713, Val Acc: 0.597938\n",
      "Epoch 4308 - Train Loss: 0.191966, Train Acc: 0.633333 | Val Loss: 0.200699, Val Acc: 0.597938\n",
      "Epoch 4309 - Train Loss: 0.191950, Train Acc: 0.633333 | Val Loss: 0.200684, Val Acc: 0.597938\n",
      "Epoch 4310 - Train Loss: 0.191935, Train Acc: 0.633333 | Val Loss: 0.200670, Val Acc: 0.597938\n",
      "Epoch 4311 - Train Loss: 0.191919, Train Acc: 0.633333 | Val Loss: 0.200655, Val Acc: 0.597938\n",
      "Epoch 4312 - Train Loss: 0.191904, Train Acc: 0.633333 | Val Loss: 0.200641, Val Acc: 0.597938\n",
      "Epoch 4313 - Train Loss: 0.191889, Train Acc: 0.633333 | Val Loss: 0.200626, Val Acc: 0.597938\n",
      "Epoch 4314 - Train Loss: 0.191873, Train Acc: 0.633333 | Val Loss: 0.200612, Val Acc: 0.597938\n",
      "Epoch 4315 - Train Loss: 0.191858, Train Acc: 0.633333 | Val Loss: 0.200597, Val Acc: 0.597938\n",
      "Epoch 4316 - Train Loss: 0.191843, Train Acc: 0.633333 | Val Loss: 0.200583, Val Acc: 0.597938\n",
      "Epoch 4317 - Train Loss: 0.191827, Train Acc: 0.634615 | Val Loss: 0.200568, Val Acc: 0.597938\n",
      "Epoch 4318 - Train Loss: 0.191812, Train Acc: 0.634615 | Val Loss: 0.200554, Val Acc: 0.597938\n",
      "Epoch 4319 - Train Loss: 0.191797, Train Acc: 0.634615 | Val Loss: 0.200540, Val Acc: 0.597938\n",
      "Epoch 4320 - Train Loss: 0.191781, Train Acc: 0.634615 | Val Loss: 0.200525, Val Acc: 0.597938\n",
      "Epoch 4321 - Train Loss: 0.191766, Train Acc: 0.634615 | Val Loss: 0.200511, Val Acc: 0.597938\n",
      "Epoch 4322 - Train Loss: 0.191751, Train Acc: 0.634615 | Val Loss: 0.200496, Val Acc: 0.597938\n",
      "Epoch 4323 - Train Loss: 0.191735, Train Acc: 0.634615 | Val Loss: 0.200482, Val Acc: 0.597938\n",
      "Epoch 4324 - Train Loss: 0.191720, Train Acc: 0.634615 | Val Loss: 0.200467, Val Acc: 0.597938\n",
      "Epoch 4325 - Train Loss: 0.191704, Train Acc: 0.634615 | Val Loss: 0.200453, Val Acc: 0.597938\n",
      "Epoch 4326 - Train Loss: 0.191689, Train Acc: 0.634615 | Val Loss: 0.200438, Val Acc: 0.597938\n",
      "Epoch 4327 - Train Loss: 0.191674, Train Acc: 0.634615 | Val Loss: 0.200424, Val Acc: 0.597938\n",
      "Epoch 4328 - Train Loss: 0.191658, Train Acc: 0.634615 | Val Loss: 0.200409, Val Acc: 0.597938\n",
      "Epoch 4329 - Train Loss: 0.191643, Train Acc: 0.634615 | Val Loss: 0.200395, Val Acc: 0.597938\n",
      "Epoch 4330 - Train Loss: 0.191628, Train Acc: 0.634615 | Val Loss: 0.200380, Val Acc: 0.597938\n",
      "Epoch 4331 - Train Loss: 0.191612, Train Acc: 0.634615 | Val Loss: 0.200366, Val Acc: 0.597938\n",
      "Epoch 4332 - Train Loss: 0.191597, Train Acc: 0.634615 | Val Loss: 0.200351, Val Acc: 0.597938\n",
      "Epoch 4333 - Train Loss: 0.191582, Train Acc: 0.634615 | Val Loss: 0.200337, Val Acc: 0.597938\n",
      "Epoch 4334 - Train Loss: 0.191567, Train Acc: 0.634615 | Val Loss: 0.200323, Val Acc: 0.597938\n",
      "Epoch 4335 - Train Loss: 0.191551, Train Acc: 0.634615 | Val Loss: 0.200308, Val Acc: 0.597938\n",
      "Epoch 4336 - Train Loss: 0.191536, Train Acc: 0.634615 | Val Loss: 0.200294, Val Acc: 0.597938\n",
      "Epoch 4337 - Train Loss: 0.191521, Train Acc: 0.634615 | Val Loss: 0.200279, Val Acc: 0.597938\n",
      "Epoch 4338 - Train Loss: 0.191505, Train Acc: 0.634615 | Val Loss: 0.200265, Val Acc: 0.597938\n",
      "Epoch 4339 - Train Loss: 0.191490, Train Acc: 0.634615 | Val Loss: 0.200250, Val Acc: 0.597938\n",
      "Epoch 4340 - Train Loss: 0.191475, Train Acc: 0.634615 | Val Loss: 0.200236, Val Acc: 0.597938\n",
      "Epoch 4341 - Train Loss: 0.191459, Train Acc: 0.634615 | Val Loss: 0.200221, Val Acc: 0.597938\n",
      "Epoch 4342 - Train Loss: 0.191444, Train Acc: 0.634615 | Val Loss: 0.200207, Val Acc: 0.597938\n",
      "Epoch 4343 - Train Loss: 0.191429, Train Acc: 0.634615 | Val Loss: 0.200193, Val Acc: 0.597938\n",
      "Epoch 4344 - Train Loss: 0.191413, Train Acc: 0.634615 | Val Loss: 0.200178, Val Acc: 0.597938\n",
      "Epoch 4345 - Train Loss: 0.191398, Train Acc: 0.634615 | Val Loss: 0.200164, Val Acc: 0.597938\n",
      "Epoch 4346 - Train Loss: 0.191383, Train Acc: 0.634615 | Val Loss: 0.200149, Val Acc: 0.597938\n",
      "Epoch 4347 - Train Loss: 0.191368, Train Acc: 0.634615 | Val Loss: 0.200135, Val Acc: 0.597938\n",
      "Epoch 4348 - Train Loss: 0.191352, Train Acc: 0.634615 | Val Loss: 0.200121, Val Acc: 0.597938\n",
      "Epoch 4349 - Train Loss: 0.191337, Train Acc: 0.634615 | Val Loss: 0.200106, Val Acc: 0.597938\n",
      "Epoch 4350 - Train Loss: 0.191322, Train Acc: 0.634615 | Val Loss: 0.200092, Val Acc: 0.597938\n",
      "Epoch 4351 - Train Loss: 0.191306, Train Acc: 0.634615 | Val Loss: 0.200077, Val Acc: 0.597938\n",
      "Epoch 4352 - Train Loss: 0.191291, Train Acc: 0.634615 | Val Loss: 0.200063, Val Acc: 0.597938\n",
      "Epoch 4353 - Train Loss: 0.191276, Train Acc: 0.634615 | Val Loss: 0.200048, Val Acc: 0.597938\n",
      "Epoch 4354 - Train Loss: 0.191261, Train Acc: 0.634615 | Val Loss: 0.200034, Val Acc: 0.597938\n",
      "Epoch 4355 - Train Loss: 0.191245, Train Acc: 0.634615 | Val Loss: 0.200020, Val Acc: 0.597938\n",
      "Epoch 4356 - Train Loss: 0.191230, Train Acc: 0.634615 | Val Loss: 0.200005, Val Acc: 0.597938\n",
      "Epoch 4357 - Train Loss: 0.191215, Train Acc: 0.634615 | Val Loss: 0.199991, Val Acc: 0.597938\n",
      "Epoch 4358 - Train Loss: 0.191199, Train Acc: 0.634615 | Val Loss: 0.199976, Val Acc: 0.597938\n",
      "Epoch 4359 - Train Loss: 0.191184, Train Acc: 0.634615 | Val Loss: 0.199962, Val Acc: 0.597938\n",
      "Epoch 4360 - Train Loss: 0.191169, Train Acc: 0.634615 | Val Loss: 0.199948, Val Acc: 0.597938\n",
      "Epoch 4361 - Train Loss: 0.191154, Train Acc: 0.634615 | Val Loss: 0.199933, Val Acc: 0.597938\n",
      "Epoch 4362 - Train Loss: 0.191138, Train Acc: 0.634615 | Val Loss: 0.199919, Val Acc: 0.597938\n",
      "Epoch 4363 - Train Loss: 0.191123, Train Acc: 0.634615 | Val Loss: 0.199905, Val Acc: 0.597938\n",
      "Epoch 4364 - Train Loss: 0.191108, Train Acc: 0.634615 | Val Loss: 0.199890, Val Acc: 0.597938\n",
      "Epoch 4365 - Train Loss: 0.191093, Train Acc: 0.634615 | Val Loss: 0.199876, Val Acc: 0.597938\n",
      "Epoch 4366 - Train Loss: 0.191077, Train Acc: 0.634615 | Val Loss: 0.199861, Val Acc: 0.597938\n",
      "Epoch 4367 - Train Loss: 0.191062, Train Acc: 0.635897 | Val Loss: 0.199847, Val Acc: 0.597938\n",
      "Epoch 4368 - Train Loss: 0.191047, Train Acc: 0.635897 | Val Loss: 0.199833, Val Acc: 0.597938\n",
      "Epoch 4369 - Train Loss: 0.191032, Train Acc: 0.635897 | Val Loss: 0.199818, Val Acc: 0.597938\n",
      "Epoch 4370 - Train Loss: 0.191016, Train Acc: 0.635897 | Val Loss: 0.199804, Val Acc: 0.597938\n",
      "Epoch 4371 - Train Loss: 0.191001, Train Acc: 0.635897 | Val Loss: 0.199790, Val Acc: 0.597938\n",
      "Epoch 4372 - Train Loss: 0.190986, Train Acc: 0.635897 | Val Loss: 0.199775, Val Acc: 0.597938\n",
      "Epoch 4373 - Train Loss: 0.190971, Train Acc: 0.635897 | Val Loss: 0.199761, Val Acc: 0.597938\n",
      "Epoch 4374 - Train Loss: 0.190955, Train Acc: 0.635897 | Val Loss: 0.199747, Val Acc: 0.597938\n",
      "Epoch 4375 - Train Loss: 0.190940, Train Acc: 0.635897 | Val Loss: 0.199732, Val Acc: 0.597938\n",
      "Epoch 4376 - Train Loss: 0.190925, Train Acc: 0.635897 | Val Loss: 0.199718, Val Acc: 0.597938\n",
      "Epoch 4377 - Train Loss: 0.190910, Train Acc: 0.635897 | Val Loss: 0.199703, Val Acc: 0.597938\n",
      "Epoch 4378 - Train Loss: 0.190895, Train Acc: 0.635897 | Val Loss: 0.199689, Val Acc: 0.597938\n",
      "Epoch 4379 - Train Loss: 0.190879, Train Acc: 0.635897 | Val Loss: 0.199675, Val Acc: 0.597938\n",
      "Epoch 4380 - Train Loss: 0.190864, Train Acc: 0.635897 | Val Loss: 0.199660, Val Acc: 0.597938\n",
      "Epoch 4381 - Train Loss: 0.190849, Train Acc: 0.635897 | Val Loss: 0.199646, Val Acc: 0.597938\n",
      "Epoch 4382 - Train Loss: 0.190834, Train Acc: 0.635897 | Val Loss: 0.199632, Val Acc: 0.597938\n",
      "Epoch 4383 - Train Loss: 0.190818, Train Acc: 0.635897 | Val Loss: 0.199617, Val Acc: 0.597938\n",
      "Epoch 4384 - Train Loss: 0.190803, Train Acc: 0.635897 | Val Loss: 0.199603, Val Acc: 0.597938\n",
      "Epoch 4385 - Train Loss: 0.190788, Train Acc: 0.635897 | Val Loss: 0.199589, Val Acc: 0.597938\n",
      "Epoch 4386 - Train Loss: 0.190773, Train Acc: 0.635897 | Val Loss: 0.199574, Val Acc: 0.597938\n",
      "Epoch 4387 - Train Loss: 0.190758, Train Acc: 0.635897 | Val Loss: 0.199560, Val Acc: 0.597938\n",
      "Epoch 4388 - Train Loss: 0.190742, Train Acc: 0.635897 | Val Loss: 0.199546, Val Acc: 0.597938\n",
      "Epoch 4389 - Train Loss: 0.190727, Train Acc: 0.635897 | Val Loss: 0.199532, Val Acc: 0.597938\n",
      "Epoch 4390 - Train Loss: 0.190712, Train Acc: 0.635897 | Val Loss: 0.199517, Val Acc: 0.597938\n",
      "Epoch 4391 - Train Loss: 0.190697, Train Acc: 0.635897 | Val Loss: 0.199503, Val Acc: 0.597938\n",
      "Epoch 4392 - Train Loss: 0.190682, Train Acc: 0.635897 | Val Loss: 0.199489, Val Acc: 0.597938\n",
      "Epoch 4393 - Train Loss: 0.190666, Train Acc: 0.635897 | Val Loss: 0.199474, Val Acc: 0.597938\n",
      "Epoch 4394 - Train Loss: 0.190651, Train Acc: 0.635897 | Val Loss: 0.199460, Val Acc: 0.597938\n",
      "Epoch 4395 - Train Loss: 0.190636, Train Acc: 0.635897 | Val Loss: 0.199446, Val Acc: 0.597938\n",
      "Epoch 4396 - Train Loss: 0.190621, Train Acc: 0.635897 | Val Loss: 0.199431, Val Acc: 0.597938\n",
      "Epoch 4397 - Train Loss: 0.190606, Train Acc: 0.635897 | Val Loss: 0.199417, Val Acc: 0.597938\n",
      "Epoch 4398 - Train Loss: 0.190591, Train Acc: 0.635897 | Val Loss: 0.199403, Val Acc: 0.597938\n",
      "Epoch 4399 - Train Loss: 0.190575, Train Acc: 0.635897 | Val Loss: 0.199389, Val Acc: 0.597938\n",
      "Epoch 4400 - Train Loss: 0.190560, Train Acc: 0.635897 | Val Loss: 0.199374, Val Acc: 0.597938\n",
      "Epoch 4401 - Train Loss: 0.190545, Train Acc: 0.635897 | Val Loss: 0.199360, Val Acc: 0.597938\n",
      "Epoch 4402 - Train Loss: 0.190530, Train Acc: 0.635897 | Val Loss: 0.199346, Val Acc: 0.597938\n",
      "Epoch 4403 - Train Loss: 0.190515, Train Acc: 0.637179 | Val Loss: 0.199331, Val Acc: 0.597938\n",
      "Epoch 4404 - Train Loss: 0.190500, Train Acc: 0.637179 | Val Loss: 0.199317, Val Acc: 0.597938\n",
      "Epoch 4405 - Train Loss: 0.190484, Train Acc: 0.637179 | Val Loss: 0.199303, Val Acc: 0.597938\n",
      "Epoch 4406 - Train Loss: 0.190469, Train Acc: 0.637179 | Val Loss: 0.199288, Val Acc: 0.597938\n",
      "Epoch 4407 - Train Loss: 0.190454, Train Acc: 0.637179 | Val Loss: 0.199274, Val Acc: 0.597938\n",
      "Epoch 4408 - Train Loss: 0.190439, Train Acc: 0.637179 | Val Loss: 0.199260, Val Acc: 0.597938\n",
      "Epoch 4409 - Train Loss: 0.190424, Train Acc: 0.637179 | Val Loss: 0.199246, Val Acc: 0.597938\n",
      "Epoch 4410 - Train Loss: 0.190409, Train Acc: 0.637179 | Val Loss: 0.199231, Val Acc: 0.597938\n",
      "Epoch 4411 - Train Loss: 0.190393, Train Acc: 0.637179 | Val Loss: 0.199217, Val Acc: 0.597938\n",
      "Epoch 4412 - Train Loss: 0.190378, Train Acc: 0.637179 | Val Loss: 0.199203, Val Acc: 0.597938\n",
      "Epoch 4413 - Train Loss: 0.190363, Train Acc: 0.637179 | Val Loss: 0.199189, Val Acc: 0.597938\n",
      "Epoch 4414 - Train Loss: 0.190348, Train Acc: 0.637179 | Val Loss: 0.199174, Val Acc: 0.597938\n",
      "Epoch 4415 - Train Loss: 0.190333, Train Acc: 0.637179 | Val Loss: 0.199160, Val Acc: 0.597938\n",
      "Epoch 4416 - Train Loss: 0.190318, Train Acc: 0.637179 | Val Loss: 0.199146, Val Acc: 0.597938\n",
      "Epoch 4417 - Train Loss: 0.190303, Train Acc: 0.637179 | Val Loss: 0.199132, Val Acc: 0.597938\n",
      "Epoch 4418 - Train Loss: 0.190288, Train Acc: 0.637179 | Val Loss: 0.199117, Val Acc: 0.597938\n",
      "Epoch 4419 - Train Loss: 0.190272, Train Acc: 0.637179 | Val Loss: 0.199103, Val Acc: 0.597938\n",
      "Epoch 4420 - Train Loss: 0.190257, Train Acc: 0.637179 | Val Loss: 0.199089, Val Acc: 0.597938\n",
      "Epoch 4421 - Train Loss: 0.190242, Train Acc: 0.637179 | Val Loss: 0.199075, Val Acc: 0.597938\n",
      "Epoch 4422 - Train Loss: 0.190227, Train Acc: 0.637179 | Val Loss: 0.199060, Val Acc: 0.597938\n",
      "Epoch 4423 - Train Loss: 0.190212, Train Acc: 0.637179 | Val Loss: 0.199046, Val Acc: 0.597938\n",
      "Epoch 4424 - Train Loss: 0.190197, Train Acc: 0.637179 | Val Loss: 0.199032, Val Acc: 0.597938\n",
      "Epoch 4425 - Train Loss: 0.190182, Train Acc: 0.637179 | Val Loss: 0.199018, Val Acc: 0.597938\n",
      "Epoch 4426 - Train Loss: 0.190167, Train Acc: 0.637179 | Val Loss: 0.199003, Val Acc: 0.597938\n",
      "Epoch 4427 - Train Loss: 0.190151, Train Acc: 0.637179 | Val Loss: 0.198989, Val Acc: 0.597938\n",
      "Epoch 4428 - Train Loss: 0.190136, Train Acc: 0.637179 | Val Loss: 0.198975, Val Acc: 0.597938\n",
      "Epoch 4429 - Train Loss: 0.190121, Train Acc: 0.637179 | Val Loss: 0.198961, Val Acc: 0.597938\n",
      "Epoch 4430 - Train Loss: 0.190106, Train Acc: 0.637179 | Val Loss: 0.198947, Val Acc: 0.597938\n",
      "Epoch 4431 - Train Loss: 0.190091, Train Acc: 0.637179 | Val Loss: 0.198932, Val Acc: 0.597938\n",
      "Epoch 4432 - Train Loss: 0.190076, Train Acc: 0.637179 | Val Loss: 0.198918, Val Acc: 0.597938\n",
      "Epoch 4433 - Train Loss: 0.190061, Train Acc: 0.637179 | Val Loss: 0.198904, Val Acc: 0.597938\n",
      "Epoch 4434 - Train Loss: 0.190046, Train Acc: 0.637179 | Val Loss: 0.198890, Val Acc: 0.597938\n",
      "Epoch 4435 - Train Loss: 0.190031, Train Acc: 0.637179 | Val Loss: 0.198875, Val Acc: 0.597938\n",
      "Epoch 4436 - Train Loss: 0.190016, Train Acc: 0.637179 | Val Loss: 0.198861, Val Acc: 0.597938\n",
      "Epoch 4437 - Train Loss: 0.190001, Train Acc: 0.637179 | Val Loss: 0.198847, Val Acc: 0.597938\n",
      "Epoch 4438 - Train Loss: 0.189985, Train Acc: 0.637179 | Val Loss: 0.198833, Val Acc: 0.597938\n",
      "Epoch 4439 - Train Loss: 0.189970, Train Acc: 0.637179 | Val Loss: 0.198819, Val Acc: 0.597938\n",
      "Epoch 4440 - Train Loss: 0.189955, Train Acc: 0.637179 | Val Loss: 0.198804, Val Acc: 0.597938\n",
      "Epoch 4441 - Train Loss: 0.189940, Train Acc: 0.637179 | Val Loss: 0.198790, Val Acc: 0.597938\n",
      "Epoch 4442 - Train Loss: 0.189925, Train Acc: 0.637179 | Val Loss: 0.198776, Val Acc: 0.597938\n",
      "Epoch 4443 - Train Loss: 0.189910, Train Acc: 0.637179 | Val Loss: 0.198762, Val Acc: 0.597938\n",
      "Epoch 4444 - Train Loss: 0.189895, Train Acc: 0.637179 | Val Loss: 0.198748, Val Acc: 0.597938\n",
      "Epoch 4445 - Train Loss: 0.189880, Train Acc: 0.637179 | Val Loss: 0.198734, Val Acc: 0.597938\n",
      "Epoch 4446 - Train Loss: 0.189865, Train Acc: 0.637179 | Val Loss: 0.198719, Val Acc: 0.597938\n",
      "Epoch 4447 - Train Loss: 0.189850, Train Acc: 0.637179 | Val Loss: 0.198705, Val Acc: 0.597938\n",
      "Epoch 4448 - Train Loss: 0.189835, Train Acc: 0.637179 | Val Loss: 0.198691, Val Acc: 0.597938\n",
      "Epoch 4449 - Train Loss: 0.189820, Train Acc: 0.637179 | Val Loss: 0.198677, Val Acc: 0.608247\n",
      "Epoch 4450 - Train Loss: 0.189805, Train Acc: 0.637179 | Val Loss: 0.198663, Val Acc: 0.608247\n",
      "Epoch 4451 - Train Loss: 0.189790, Train Acc: 0.637179 | Val Loss: 0.198648, Val Acc: 0.608247\n",
      "Epoch 4452 - Train Loss: 0.189774, Train Acc: 0.637179 | Val Loss: 0.198634, Val Acc: 0.608247\n",
      "Epoch 4453 - Train Loss: 0.189759, Train Acc: 0.637179 | Val Loss: 0.198620, Val Acc: 0.608247\n",
      "Epoch 4454 - Train Loss: 0.189744, Train Acc: 0.637179 | Val Loss: 0.198606, Val Acc: 0.608247\n",
      "Epoch 4455 - Train Loss: 0.189729, Train Acc: 0.637179 | Val Loss: 0.198592, Val Acc: 0.608247\n",
      "Epoch 4456 - Train Loss: 0.189714, Train Acc: 0.637179 | Val Loss: 0.198578, Val Acc: 0.608247\n",
      "Epoch 4457 - Train Loss: 0.189699, Train Acc: 0.637179 | Val Loss: 0.198564, Val Acc: 0.608247\n",
      "Epoch 4458 - Train Loss: 0.189684, Train Acc: 0.637179 | Val Loss: 0.198549, Val Acc: 0.608247\n",
      "Epoch 4459 - Train Loss: 0.189669, Train Acc: 0.637179 | Val Loss: 0.198535, Val Acc: 0.608247\n",
      "Epoch 4460 - Train Loss: 0.189654, Train Acc: 0.637179 | Val Loss: 0.198521, Val Acc: 0.608247\n",
      "Epoch 4461 - Train Loss: 0.189639, Train Acc: 0.637179 | Val Loss: 0.198507, Val Acc: 0.608247\n",
      "Epoch 4462 - Train Loss: 0.189624, Train Acc: 0.637179 | Val Loss: 0.198493, Val Acc: 0.608247\n",
      "Epoch 4463 - Train Loss: 0.189609, Train Acc: 0.637179 | Val Loss: 0.198479, Val Acc: 0.608247\n",
      "Epoch 4464 - Train Loss: 0.189594, Train Acc: 0.637179 | Val Loss: 0.198464, Val Acc: 0.608247\n",
      "Epoch 4465 - Train Loss: 0.189579, Train Acc: 0.637179 | Val Loss: 0.198450, Val Acc: 0.608247\n",
      "Epoch 4466 - Train Loss: 0.189564, Train Acc: 0.637179 | Val Loss: 0.198436, Val Acc: 0.608247\n",
      "Epoch 4467 - Train Loss: 0.189549, Train Acc: 0.637179 | Val Loss: 0.198422, Val Acc: 0.608247\n",
      "Epoch 4468 - Train Loss: 0.189534, Train Acc: 0.637179 | Val Loss: 0.198408, Val Acc: 0.608247\n",
      "Epoch 4469 - Train Loss: 0.189519, Train Acc: 0.637179 | Val Loss: 0.198394, Val Acc: 0.608247\n",
      "Epoch 4470 - Train Loss: 0.189504, Train Acc: 0.637179 | Val Loss: 0.198380, Val Acc: 0.608247\n",
      "Epoch 4471 - Train Loss: 0.189489, Train Acc: 0.637179 | Val Loss: 0.198366, Val Acc: 0.608247\n",
      "Epoch 4472 - Train Loss: 0.189474, Train Acc: 0.637179 | Val Loss: 0.198351, Val Acc: 0.608247\n",
      "Epoch 4473 - Train Loss: 0.189459, Train Acc: 0.637179 | Val Loss: 0.198337, Val Acc: 0.608247\n",
      "Epoch 4474 - Train Loss: 0.189444, Train Acc: 0.637179 | Val Loss: 0.198323, Val Acc: 0.608247\n",
      "Epoch 4475 - Train Loss: 0.189429, Train Acc: 0.637179 | Val Loss: 0.198309, Val Acc: 0.608247\n",
      "Epoch 4476 - Train Loss: 0.189414, Train Acc: 0.637179 | Val Loss: 0.198295, Val Acc: 0.608247\n",
      "Epoch 4477 - Train Loss: 0.189399, Train Acc: 0.637179 | Val Loss: 0.198281, Val Acc: 0.608247\n",
      "Epoch 4478 - Train Loss: 0.189384, Train Acc: 0.637179 | Val Loss: 0.198267, Val Acc: 0.608247\n",
      "Epoch 4479 - Train Loss: 0.189369, Train Acc: 0.637179 | Val Loss: 0.198253, Val Acc: 0.608247\n",
      "Epoch 4480 - Train Loss: 0.189354, Train Acc: 0.638462 | Val Loss: 0.198239, Val Acc: 0.608247\n",
      "Epoch 4481 - Train Loss: 0.189339, Train Acc: 0.638462 | Val Loss: 0.198224, Val Acc: 0.608247\n",
      "Epoch 4482 - Train Loss: 0.189324, Train Acc: 0.638462 | Val Loss: 0.198210, Val Acc: 0.608247\n",
      "Epoch 4483 - Train Loss: 0.189309, Train Acc: 0.638462 | Val Loss: 0.198196, Val Acc: 0.608247\n",
      "Epoch 4484 - Train Loss: 0.189294, Train Acc: 0.638462 | Val Loss: 0.198182, Val Acc: 0.608247\n",
      "Epoch 4485 - Train Loss: 0.189279, Train Acc: 0.638462 | Val Loss: 0.198168, Val Acc: 0.608247\n",
      "Epoch 4486 - Train Loss: 0.189264, Train Acc: 0.638462 | Val Loss: 0.198154, Val Acc: 0.608247\n",
      "Epoch 4487 - Train Loss: 0.189249, Train Acc: 0.638462 | Val Loss: 0.198140, Val Acc: 0.608247\n",
      "Epoch 4488 - Train Loss: 0.189234, Train Acc: 0.638462 | Val Loss: 0.198126, Val Acc: 0.608247\n",
      "Epoch 4489 - Train Loss: 0.189219, Train Acc: 0.638462 | Val Loss: 0.198112, Val Acc: 0.608247\n",
      "Epoch 4490 - Train Loss: 0.189204, Train Acc: 0.638462 | Val Loss: 0.198098, Val Acc: 0.608247\n",
      "Epoch 4491 - Train Loss: 0.189189, Train Acc: 0.638462 | Val Loss: 0.198083, Val Acc: 0.608247\n",
      "Epoch 4492 - Train Loss: 0.189174, Train Acc: 0.638462 | Val Loss: 0.198069, Val Acc: 0.608247\n",
      "Epoch 4493 - Train Loss: 0.189159, Train Acc: 0.638462 | Val Loss: 0.198055, Val Acc: 0.608247\n",
      "Epoch 4494 - Train Loss: 0.189144, Train Acc: 0.638462 | Val Loss: 0.198041, Val Acc: 0.608247\n",
      "Epoch 4495 - Train Loss: 0.189129, Train Acc: 0.638462 | Val Loss: 0.198027, Val Acc: 0.618557\n",
      "Epoch 4496 - Train Loss: 0.189114, Train Acc: 0.638462 | Val Loss: 0.198013, Val Acc: 0.618557\n",
      "Epoch 4497 - Train Loss: 0.189099, Train Acc: 0.638462 | Val Loss: 0.197999, Val Acc: 0.618557\n",
      "Epoch 4498 - Train Loss: 0.189085, Train Acc: 0.638462 | Val Loss: 0.197985, Val Acc: 0.618557\n",
      "Epoch 4499 - Train Loss: 0.189070, Train Acc: 0.638462 | Val Loss: 0.197971, Val Acc: 0.618557\n",
      "Epoch 4500 - Train Loss: 0.189055, Train Acc: 0.638462 | Val Loss: 0.197957, Val Acc: 0.618557\n",
      "Epoch 4501 - Train Loss: 0.189040, Train Acc: 0.638462 | Val Loss: 0.197943, Val Acc: 0.618557\n",
      "Epoch 4502 - Train Loss: 0.189025, Train Acc: 0.638462 | Val Loss: 0.197929, Val Acc: 0.618557\n",
      "Epoch 4503 - Train Loss: 0.189010, Train Acc: 0.639744 | Val Loss: 0.197915, Val Acc: 0.618557\n",
      "Epoch 4504 - Train Loss: 0.188995, Train Acc: 0.639744 | Val Loss: 0.197901, Val Acc: 0.618557\n",
      "Epoch 4505 - Train Loss: 0.188980, Train Acc: 0.639744 | Val Loss: 0.197887, Val Acc: 0.618557\n",
      "Epoch 4506 - Train Loss: 0.188965, Train Acc: 0.639744 | Val Loss: 0.197873, Val Acc: 0.618557\n",
      "Epoch 4507 - Train Loss: 0.188950, Train Acc: 0.639744 | Val Loss: 0.197859, Val Acc: 0.618557\n",
      "Epoch 4508 - Train Loss: 0.188935, Train Acc: 0.639744 | Val Loss: 0.197845, Val Acc: 0.618557\n",
      "Epoch 4509 - Train Loss: 0.188920, Train Acc: 0.639744 | Val Loss: 0.197831, Val Acc: 0.618557\n",
      "Epoch 4510 - Train Loss: 0.188905, Train Acc: 0.639744 | Val Loss: 0.197816, Val Acc: 0.618557\n",
      "Epoch 4511 - Train Loss: 0.188890, Train Acc: 0.639744 | Val Loss: 0.197802, Val Acc: 0.618557\n",
      "Epoch 4512 - Train Loss: 0.188875, Train Acc: 0.639744 | Val Loss: 0.197788, Val Acc: 0.618557\n",
      "Epoch 4513 - Train Loss: 0.188860, Train Acc: 0.639744 | Val Loss: 0.197774, Val Acc: 0.618557\n",
      "Epoch 4514 - Train Loss: 0.188846, Train Acc: 0.639744 | Val Loss: 0.197760, Val Acc: 0.618557\n",
      "Epoch 4515 - Train Loss: 0.188831, Train Acc: 0.639744 | Val Loss: 0.197746, Val Acc: 0.618557\n",
      "Epoch 4516 - Train Loss: 0.188816, Train Acc: 0.639744 | Val Loss: 0.197732, Val Acc: 0.618557\n",
      "Epoch 4517 - Train Loss: 0.188801, Train Acc: 0.639744 | Val Loss: 0.197718, Val Acc: 0.618557\n",
      "Epoch 4518 - Train Loss: 0.188786, Train Acc: 0.639744 | Val Loss: 0.197704, Val Acc: 0.618557\n",
      "Epoch 4519 - Train Loss: 0.188771, Train Acc: 0.639744 | Val Loss: 0.197690, Val Acc: 0.618557\n",
      "Epoch 4520 - Train Loss: 0.188756, Train Acc: 0.639744 | Val Loss: 0.197676, Val Acc: 0.618557\n",
      "Epoch 4521 - Train Loss: 0.188741, Train Acc: 0.639744 | Val Loss: 0.197662, Val Acc: 0.618557\n",
      "Epoch 4522 - Train Loss: 0.188726, Train Acc: 0.639744 | Val Loss: 0.197648, Val Acc: 0.618557\n",
      "Epoch 4523 - Train Loss: 0.188711, Train Acc: 0.639744 | Val Loss: 0.197634, Val Acc: 0.618557\n",
      "Epoch 4524 - Train Loss: 0.188696, Train Acc: 0.639744 | Val Loss: 0.197620, Val Acc: 0.618557\n",
      "Epoch 4525 - Train Loss: 0.188682, Train Acc: 0.639744 | Val Loss: 0.197606, Val Acc: 0.618557\n",
      "Epoch 4526 - Train Loss: 0.188667, Train Acc: 0.639744 | Val Loss: 0.197592, Val Acc: 0.618557\n",
      "Epoch 4527 - Train Loss: 0.188652, Train Acc: 0.639744 | Val Loss: 0.197578, Val Acc: 0.618557\n",
      "Epoch 4528 - Train Loss: 0.188637, Train Acc: 0.639744 | Val Loss: 0.197564, Val Acc: 0.618557\n",
      "Epoch 4529 - Train Loss: 0.188622, Train Acc: 0.639744 | Val Loss: 0.197550, Val Acc: 0.618557\n",
      "Epoch 4530 - Train Loss: 0.188607, Train Acc: 0.639744 | Val Loss: 0.197536, Val Acc: 0.618557\n",
      "Epoch 4531 - Train Loss: 0.188592, Train Acc: 0.639744 | Val Loss: 0.197522, Val Acc: 0.618557\n",
      "Epoch 4532 - Train Loss: 0.188577, Train Acc: 0.639744 | Val Loss: 0.197508, Val Acc: 0.618557\n",
      "Epoch 4533 - Train Loss: 0.188562, Train Acc: 0.639744 | Val Loss: 0.197494, Val Acc: 0.618557\n",
      "Epoch 4534 - Train Loss: 0.188548, Train Acc: 0.639744 | Val Loss: 0.197481, Val Acc: 0.618557\n",
      "Epoch 4535 - Train Loss: 0.188533, Train Acc: 0.639744 | Val Loss: 0.197467, Val Acc: 0.618557\n",
      "Epoch 4536 - Train Loss: 0.188518, Train Acc: 0.639744 | Val Loss: 0.197453, Val Acc: 0.618557\n",
      "Epoch 4537 - Train Loss: 0.188503, Train Acc: 0.639744 | Val Loss: 0.197439, Val Acc: 0.618557\n",
      "Epoch 4538 - Train Loss: 0.188488, Train Acc: 0.639744 | Val Loss: 0.197425, Val Acc: 0.618557\n",
      "Epoch 4539 - Train Loss: 0.188473, Train Acc: 0.639744 | Val Loss: 0.197411, Val Acc: 0.618557\n",
      "Epoch 4540 - Train Loss: 0.188458, Train Acc: 0.639744 | Val Loss: 0.197397, Val Acc: 0.618557\n",
      "Epoch 4541 - Train Loss: 0.188443, Train Acc: 0.639744 | Val Loss: 0.197383, Val Acc: 0.618557\n",
      "Epoch 4542 - Train Loss: 0.188429, Train Acc: 0.639744 | Val Loss: 0.197369, Val Acc: 0.618557\n",
      "Epoch 4543 - Train Loss: 0.188414, Train Acc: 0.639744 | Val Loss: 0.197355, Val Acc: 0.618557\n",
      "Epoch 4544 - Train Loss: 0.188399, Train Acc: 0.639744 | Val Loss: 0.197341, Val Acc: 0.618557\n",
      "Epoch 4545 - Train Loss: 0.188384, Train Acc: 0.641026 | Val Loss: 0.197327, Val Acc: 0.618557\n",
      "Epoch 4546 - Train Loss: 0.188369, Train Acc: 0.641026 | Val Loss: 0.197313, Val Acc: 0.618557\n",
      "Epoch 4547 - Train Loss: 0.188354, Train Acc: 0.641026 | Val Loss: 0.197299, Val Acc: 0.618557\n",
      "Epoch 4548 - Train Loss: 0.188339, Train Acc: 0.641026 | Val Loss: 0.197285, Val Acc: 0.618557\n",
      "Epoch 4549 - Train Loss: 0.188325, Train Acc: 0.641026 | Val Loss: 0.197271, Val Acc: 0.618557\n",
      "Epoch 4550 - Train Loss: 0.188310, Train Acc: 0.641026 | Val Loss: 0.197257, Val Acc: 0.618557\n",
      "Epoch 4551 - Train Loss: 0.188295, Train Acc: 0.641026 | Val Loss: 0.197243, Val Acc: 0.618557\n",
      "Epoch 4552 - Train Loss: 0.188280, Train Acc: 0.641026 | Val Loss: 0.197229, Val Acc: 0.618557\n",
      "Epoch 4553 - Train Loss: 0.188265, Train Acc: 0.641026 | Val Loss: 0.197215, Val Acc: 0.618557\n",
      "Epoch 4554 - Train Loss: 0.188250, Train Acc: 0.641026 | Val Loss: 0.197202, Val Acc: 0.618557\n",
      "Epoch 4555 - Train Loss: 0.188236, Train Acc: 0.641026 | Val Loss: 0.197188, Val Acc: 0.618557\n",
      "Epoch 4556 - Train Loss: 0.188221, Train Acc: 0.641026 | Val Loss: 0.197174, Val Acc: 0.618557\n",
      "Epoch 4557 - Train Loss: 0.188206, Train Acc: 0.641026 | Val Loss: 0.197160, Val Acc: 0.618557\n",
      "Epoch 4558 - Train Loss: 0.188191, Train Acc: 0.641026 | Val Loss: 0.197146, Val Acc: 0.618557\n",
      "Epoch 4559 - Train Loss: 0.188176, Train Acc: 0.641026 | Val Loss: 0.197132, Val Acc: 0.618557\n",
      "Epoch 4560 - Train Loss: 0.188161, Train Acc: 0.641026 | Val Loss: 0.197118, Val Acc: 0.618557\n",
      "Epoch 4561 - Train Loss: 0.188147, Train Acc: 0.641026 | Val Loss: 0.197104, Val Acc: 0.618557\n",
      "Epoch 4562 - Train Loss: 0.188132, Train Acc: 0.641026 | Val Loss: 0.197090, Val Acc: 0.618557\n",
      "Epoch 4563 - Train Loss: 0.188117, Train Acc: 0.641026 | Val Loss: 0.197076, Val Acc: 0.618557\n",
      "Epoch 4564 - Train Loss: 0.188102, Train Acc: 0.641026 | Val Loss: 0.197062, Val Acc: 0.618557\n",
      "Epoch 4565 - Train Loss: 0.188087, Train Acc: 0.641026 | Val Loss: 0.197048, Val Acc: 0.618557\n",
      "Epoch 4566 - Train Loss: 0.188072, Train Acc: 0.641026 | Val Loss: 0.197035, Val Acc: 0.618557\n",
      "Epoch 4567 - Train Loss: 0.188058, Train Acc: 0.641026 | Val Loss: 0.197021, Val Acc: 0.618557\n",
      "Epoch 4568 - Train Loss: 0.188043, Train Acc: 0.641026 | Val Loss: 0.197007, Val Acc: 0.618557\n",
      "Epoch 4569 - Train Loss: 0.188028, Train Acc: 0.641026 | Val Loss: 0.196993, Val Acc: 0.618557\n",
      "Epoch 4570 - Train Loss: 0.188013, Train Acc: 0.641026 | Val Loss: 0.196979, Val Acc: 0.618557\n",
      "Epoch 4571 - Train Loss: 0.187998, Train Acc: 0.641026 | Val Loss: 0.196965, Val Acc: 0.618557\n",
      "Epoch 4572 - Train Loss: 0.187984, Train Acc: 0.641026 | Val Loss: 0.196951, Val Acc: 0.618557\n",
      "Epoch 4573 - Train Loss: 0.187969, Train Acc: 0.641026 | Val Loss: 0.196937, Val Acc: 0.618557\n",
      "Epoch 4574 - Train Loss: 0.187954, Train Acc: 0.641026 | Val Loss: 0.196923, Val Acc: 0.618557\n",
      "Epoch 4575 - Train Loss: 0.187939, Train Acc: 0.641026 | Val Loss: 0.196910, Val Acc: 0.618557\n",
      "Epoch 4576 - Train Loss: 0.187924, Train Acc: 0.641026 | Val Loss: 0.196896, Val Acc: 0.618557\n",
      "Epoch 4577 - Train Loss: 0.187910, Train Acc: 0.641026 | Val Loss: 0.196882, Val Acc: 0.618557\n",
      "Epoch 4578 - Train Loss: 0.187895, Train Acc: 0.641026 | Val Loss: 0.196868, Val Acc: 0.618557\n",
      "Epoch 4579 - Train Loss: 0.187880, Train Acc: 0.641026 | Val Loss: 0.196854, Val Acc: 0.618557\n",
      "Epoch 4580 - Train Loss: 0.187865, Train Acc: 0.641026 | Val Loss: 0.196840, Val Acc: 0.618557\n",
      "Epoch 4581 - Train Loss: 0.187851, Train Acc: 0.641026 | Val Loss: 0.196826, Val Acc: 0.618557\n",
      "Epoch 4582 - Train Loss: 0.187836, Train Acc: 0.641026 | Val Loss: 0.196812, Val Acc: 0.618557\n",
      "Epoch 4583 - Train Loss: 0.187821, Train Acc: 0.641026 | Val Loss: 0.196799, Val Acc: 0.618557\n",
      "Epoch 4584 - Train Loss: 0.187806, Train Acc: 0.641026 | Val Loss: 0.196785, Val Acc: 0.618557\n",
      "Epoch 4585 - Train Loss: 0.187791, Train Acc: 0.641026 | Val Loss: 0.196771, Val Acc: 0.618557\n",
      "Epoch 4586 - Train Loss: 0.187777, Train Acc: 0.641026 | Val Loss: 0.196757, Val Acc: 0.618557\n",
      "Epoch 4587 - Train Loss: 0.187762, Train Acc: 0.641026 | Val Loss: 0.196743, Val Acc: 0.618557\n",
      "Epoch 4588 - Train Loss: 0.187747, Train Acc: 0.641026 | Val Loss: 0.196729, Val Acc: 0.618557\n",
      "Epoch 4589 - Train Loss: 0.187732, Train Acc: 0.641026 | Val Loss: 0.196715, Val Acc: 0.618557\n",
      "Epoch 4590 - Train Loss: 0.187718, Train Acc: 0.641026 | Val Loss: 0.196702, Val Acc: 0.618557\n",
      "Epoch 4591 - Train Loss: 0.187703, Train Acc: 0.641026 | Val Loss: 0.196688, Val Acc: 0.618557\n",
      "Epoch 4592 - Train Loss: 0.187688, Train Acc: 0.641026 | Val Loss: 0.196674, Val Acc: 0.618557\n",
      "Epoch 4593 - Train Loss: 0.187673, Train Acc: 0.641026 | Val Loss: 0.196660, Val Acc: 0.618557\n",
      "Epoch 4594 - Train Loss: 0.187659, Train Acc: 0.641026 | Val Loss: 0.196646, Val Acc: 0.618557\n",
      "Epoch 4595 - Train Loss: 0.187644, Train Acc: 0.641026 | Val Loss: 0.196632, Val Acc: 0.618557\n",
      "Epoch 4596 - Train Loss: 0.187629, Train Acc: 0.641026 | Val Loss: 0.196618, Val Acc: 0.618557\n",
      "Epoch 4597 - Train Loss: 0.187614, Train Acc: 0.641026 | Val Loss: 0.196605, Val Acc: 0.618557\n",
      "Epoch 4598 - Train Loss: 0.187600, Train Acc: 0.641026 | Val Loss: 0.196591, Val Acc: 0.618557\n",
      "Epoch 4599 - Train Loss: 0.187585, Train Acc: 0.641026 | Val Loss: 0.196577, Val Acc: 0.618557\n",
      "Epoch 4600 - Train Loss: 0.187570, Train Acc: 0.641026 | Val Loss: 0.196563, Val Acc: 0.618557\n",
      "Epoch 4601 - Train Loss: 0.187555, Train Acc: 0.641026 | Val Loss: 0.196549, Val Acc: 0.618557\n",
      "Epoch 4602 - Train Loss: 0.187541, Train Acc: 0.642308 | Val Loss: 0.196535, Val Acc: 0.618557\n",
      "Epoch 4603 - Train Loss: 0.187526, Train Acc: 0.642308 | Val Loss: 0.196522, Val Acc: 0.618557\n",
      "Epoch 4604 - Train Loss: 0.187511, Train Acc: 0.642308 | Val Loss: 0.196508, Val Acc: 0.618557\n",
      "Epoch 4605 - Train Loss: 0.187496, Train Acc: 0.643590 | Val Loss: 0.196494, Val Acc: 0.618557\n",
      "Epoch 4606 - Train Loss: 0.187482, Train Acc: 0.643590 | Val Loss: 0.196480, Val Acc: 0.618557\n",
      "Epoch 4607 - Train Loss: 0.187467, Train Acc: 0.643590 | Val Loss: 0.196466, Val Acc: 0.618557\n",
      "Epoch 4608 - Train Loss: 0.187452, Train Acc: 0.643590 | Val Loss: 0.196452, Val Acc: 0.618557\n",
      "Epoch 4609 - Train Loss: 0.187437, Train Acc: 0.643590 | Val Loss: 0.196439, Val Acc: 0.618557\n",
      "Epoch 4610 - Train Loss: 0.187423, Train Acc: 0.643590 | Val Loss: 0.196425, Val Acc: 0.618557\n",
      "Epoch 4611 - Train Loss: 0.187408, Train Acc: 0.643590 | Val Loss: 0.196411, Val Acc: 0.618557\n",
      "Epoch 4612 - Train Loss: 0.187393, Train Acc: 0.643590 | Val Loss: 0.196397, Val Acc: 0.618557\n",
      "Epoch 4613 - Train Loss: 0.187379, Train Acc: 0.643590 | Val Loss: 0.196383, Val Acc: 0.618557\n",
      "Epoch 4614 - Train Loss: 0.187364, Train Acc: 0.643590 | Val Loss: 0.196370, Val Acc: 0.618557\n",
      "Epoch 4615 - Train Loss: 0.187349, Train Acc: 0.643590 | Val Loss: 0.196356, Val Acc: 0.618557\n",
      "Epoch 4616 - Train Loss: 0.187334, Train Acc: 0.643590 | Val Loss: 0.196342, Val Acc: 0.618557\n",
      "Epoch 4617 - Train Loss: 0.187320, Train Acc: 0.643590 | Val Loss: 0.196328, Val Acc: 0.618557\n",
      "Epoch 4618 - Train Loss: 0.187305, Train Acc: 0.643590 | Val Loss: 0.196314, Val Acc: 0.618557\n",
      "Epoch 4619 - Train Loss: 0.187290, Train Acc: 0.643590 | Val Loss: 0.196301, Val Acc: 0.618557\n",
      "Epoch 4620 - Train Loss: 0.187276, Train Acc: 0.643590 | Val Loss: 0.196287, Val Acc: 0.618557\n",
      "Epoch 4621 - Train Loss: 0.187261, Train Acc: 0.643590 | Val Loss: 0.196273, Val Acc: 0.618557\n",
      "Epoch 4622 - Train Loss: 0.187246, Train Acc: 0.643590 | Val Loss: 0.196259, Val Acc: 0.618557\n",
      "Epoch 4623 - Train Loss: 0.187231, Train Acc: 0.643590 | Val Loss: 0.196246, Val Acc: 0.618557\n",
      "Epoch 4624 - Train Loss: 0.187217, Train Acc: 0.643590 | Val Loss: 0.196232, Val Acc: 0.618557\n",
      "Epoch 4625 - Train Loss: 0.187202, Train Acc: 0.643590 | Val Loss: 0.196218, Val Acc: 0.618557\n",
      "Epoch 4626 - Train Loss: 0.187187, Train Acc: 0.643590 | Val Loss: 0.196204, Val Acc: 0.618557\n",
      "Epoch 4627 - Train Loss: 0.187173, Train Acc: 0.643590 | Val Loss: 0.196191, Val Acc: 0.618557\n",
      "Epoch 4628 - Train Loss: 0.187158, Train Acc: 0.643590 | Val Loss: 0.196177, Val Acc: 0.618557\n",
      "Epoch 4629 - Train Loss: 0.187143, Train Acc: 0.643590 | Val Loss: 0.196163, Val Acc: 0.618557\n",
      "Epoch 4630 - Train Loss: 0.187129, Train Acc: 0.643590 | Val Loss: 0.196149, Val Acc: 0.618557\n",
      "Epoch 4631 - Train Loss: 0.187114, Train Acc: 0.643590 | Val Loss: 0.196136, Val Acc: 0.618557\n",
      "Epoch 4632 - Train Loss: 0.187099, Train Acc: 0.643590 | Val Loss: 0.196122, Val Acc: 0.618557\n",
      "Epoch 4633 - Train Loss: 0.187085, Train Acc: 0.643590 | Val Loss: 0.196108, Val Acc: 0.618557\n",
      "Epoch 4634 - Train Loss: 0.187070, Train Acc: 0.643590 | Val Loss: 0.196094, Val Acc: 0.618557\n",
      "Epoch 4635 - Train Loss: 0.187055, Train Acc: 0.643590 | Val Loss: 0.196081, Val Acc: 0.618557\n",
      "Epoch 4636 - Train Loss: 0.187040, Train Acc: 0.643590 | Val Loss: 0.196067, Val Acc: 0.618557\n",
      "Epoch 4637 - Train Loss: 0.187026, Train Acc: 0.643590 | Val Loss: 0.196053, Val Acc: 0.618557\n",
      "Epoch 4638 - Train Loss: 0.187011, Train Acc: 0.643590 | Val Loss: 0.196039, Val Acc: 0.618557\n",
      "Epoch 4639 - Train Loss: 0.186996, Train Acc: 0.643590 | Val Loss: 0.196026, Val Acc: 0.618557\n",
      "Epoch 4640 - Train Loss: 0.186982, Train Acc: 0.643590 | Val Loss: 0.196012, Val Acc: 0.618557\n",
      "Epoch 4641 - Train Loss: 0.186967, Train Acc: 0.643590 | Val Loss: 0.195998, Val Acc: 0.618557\n",
      "Epoch 4642 - Train Loss: 0.186952, Train Acc: 0.643590 | Val Loss: 0.195985, Val Acc: 0.628866\n",
      "Epoch 4643 - Train Loss: 0.186938, Train Acc: 0.643590 | Val Loss: 0.195971, Val Acc: 0.628866\n",
      "Epoch 4644 - Train Loss: 0.186923, Train Acc: 0.643590 | Val Loss: 0.195957, Val Acc: 0.628866\n",
      "Epoch 4645 - Train Loss: 0.186908, Train Acc: 0.643590 | Val Loss: 0.195943, Val Acc: 0.628866\n",
      "Epoch 4646 - Train Loss: 0.186894, Train Acc: 0.643590 | Val Loss: 0.195930, Val Acc: 0.628866\n",
      "Epoch 4647 - Train Loss: 0.186879, Train Acc: 0.643590 | Val Loss: 0.195916, Val Acc: 0.628866\n",
      "Epoch 4648 - Train Loss: 0.186864, Train Acc: 0.643590 | Val Loss: 0.195902, Val Acc: 0.628866\n",
      "Epoch 4649 - Train Loss: 0.186850, Train Acc: 0.643590 | Val Loss: 0.195889, Val Acc: 0.628866\n",
      "Epoch 4650 - Train Loss: 0.186835, Train Acc: 0.643590 | Val Loss: 0.195875, Val Acc: 0.628866\n",
      "Epoch 4651 - Train Loss: 0.186820, Train Acc: 0.643590 | Val Loss: 0.195861, Val Acc: 0.628866\n",
      "Epoch 4652 - Train Loss: 0.186806, Train Acc: 0.643590 | Val Loss: 0.195847, Val Acc: 0.628866\n",
      "Epoch 4653 - Train Loss: 0.186791, Train Acc: 0.643590 | Val Loss: 0.195834, Val Acc: 0.628866\n",
      "Epoch 4654 - Train Loss: 0.186777, Train Acc: 0.643590 | Val Loss: 0.195820, Val Acc: 0.628866\n",
      "Epoch 4655 - Train Loss: 0.186762, Train Acc: 0.643590 | Val Loss: 0.195806, Val Acc: 0.628866\n",
      "Epoch 4656 - Train Loss: 0.186747, Train Acc: 0.643590 | Val Loss: 0.195793, Val Acc: 0.628866\n",
      "Epoch 4657 - Train Loss: 0.186733, Train Acc: 0.643590 | Val Loss: 0.195779, Val Acc: 0.628866\n",
      "Epoch 4658 - Train Loss: 0.186718, Train Acc: 0.643590 | Val Loss: 0.195765, Val Acc: 0.628866\n",
      "Epoch 4659 - Train Loss: 0.186703, Train Acc: 0.643590 | Val Loss: 0.195752, Val Acc: 0.628866\n",
      "Epoch 4660 - Train Loss: 0.186689, Train Acc: 0.643590 | Val Loss: 0.195738, Val Acc: 0.628866\n",
      "Epoch 4661 - Train Loss: 0.186674, Train Acc: 0.643590 | Val Loss: 0.195724, Val Acc: 0.628866\n",
      "Epoch 4662 - Train Loss: 0.186659, Train Acc: 0.643590 | Val Loss: 0.195711, Val Acc: 0.628866\n",
      "Epoch 4663 - Train Loss: 0.186645, Train Acc: 0.643590 | Val Loss: 0.195697, Val Acc: 0.628866\n",
      "Epoch 4664 - Train Loss: 0.186630, Train Acc: 0.643590 | Val Loss: 0.195683, Val Acc: 0.628866\n",
      "Epoch 4665 - Train Loss: 0.186616, Train Acc: 0.643590 | Val Loss: 0.195670, Val Acc: 0.628866\n",
      "Epoch 4666 - Train Loss: 0.186601, Train Acc: 0.643590 | Val Loss: 0.195656, Val Acc: 0.628866\n",
      "Epoch 4667 - Train Loss: 0.186586, Train Acc: 0.643590 | Val Loss: 0.195642, Val Acc: 0.628866\n",
      "Epoch 4668 - Train Loss: 0.186572, Train Acc: 0.643590 | Val Loss: 0.195629, Val Acc: 0.628866\n",
      "Epoch 4669 - Train Loss: 0.186557, Train Acc: 0.643590 | Val Loss: 0.195615, Val Acc: 0.628866\n",
      "Epoch 4670 - Train Loss: 0.186542, Train Acc: 0.643590 | Val Loss: 0.195601, Val Acc: 0.628866\n",
      "Epoch 4671 - Train Loss: 0.186528, Train Acc: 0.643590 | Val Loss: 0.195588, Val Acc: 0.628866\n",
      "Epoch 4672 - Train Loss: 0.186513, Train Acc: 0.643590 | Val Loss: 0.195574, Val Acc: 0.628866\n",
      "Epoch 4673 - Train Loss: 0.186499, Train Acc: 0.643590 | Val Loss: 0.195560, Val Acc: 0.628866\n",
      "Epoch 4674 - Train Loss: 0.186484, Train Acc: 0.643590 | Val Loss: 0.195547, Val Acc: 0.628866\n",
      "Epoch 4675 - Train Loss: 0.186469, Train Acc: 0.643590 | Val Loss: 0.195533, Val Acc: 0.628866\n",
      "Epoch 4676 - Train Loss: 0.186455, Train Acc: 0.643590 | Val Loss: 0.195519, Val Acc: 0.628866\n",
      "Epoch 4677 - Train Loss: 0.186440, Train Acc: 0.643590 | Val Loss: 0.195506, Val Acc: 0.628866\n",
      "Epoch 4678 - Train Loss: 0.186426, Train Acc: 0.643590 | Val Loss: 0.195492, Val Acc: 0.628866\n",
      "Epoch 4679 - Train Loss: 0.186411, Train Acc: 0.643590 | Val Loss: 0.195479, Val Acc: 0.628866\n",
      "Epoch 4680 - Train Loss: 0.186396, Train Acc: 0.643590 | Val Loss: 0.195465, Val Acc: 0.628866\n",
      "Epoch 4681 - Train Loss: 0.186382, Train Acc: 0.643590 | Val Loss: 0.195451, Val Acc: 0.628866\n",
      "Epoch 4682 - Train Loss: 0.186367, Train Acc: 0.643590 | Val Loss: 0.195438, Val Acc: 0.628866\n",
      "Epoch 4683 - Train Loss: 0.186353, Train Acc: 0.643590 | Val Loss: 0.195424, Val Acc: 0.628866\n",
      "Epoch 4684 - Train Loss: 0.186338, Train Acc: 0.643590 | Val Loss: 0.195410, Val Acc: 0.628866\n",
      "Epoch 4685 - Train Loss: 0.186323, Train Acc: 0.643590 | Val Loss: 0.195397, Val Acc: 0.628866\n",
      "Epoch 4686 - Train Loss: 0.186309, Train Acc: 0.643590 | Val Loss: 0.195383, Val Acc: 0.628866\n",
      "Epoch 4687 - Train Loss: 0.186294, Train Acc: 0.643590 | Val Loss: 0.195370, Val Acc: 0.628866\n",
      "Epoch 4688 - Train Loss: 0.186280, Train Acc: 0.643590 | Val Loss: 0.195356, Val Acc: 0.628866\n",
      "Epoch 4689 - Train Loss: 0.186265, Train Acc: 0.643590 | Val Loss: 0.195342, Val Acc: 0.628866\n",
      "Epoch 4690 - Train Loss: 0.186251, Train Acc: 0.643590 | Val Loss: 0.195329, Val Acc: 0.628866\n",
      "Epoch 4691 - Train Loss: 0.186236, Train Acc: 0.643590 | Val Loss: 0.195315, Val Acc: 0.628866\n",
      "Epoch 4692 - Train Loss: 0.186221, Train Acc: 0.643590 | Val Loss: 0.195301, Val Acc: 0.628866\n",
      "Epoch 4693 - Train Loss: 0.186207, Train Acc: 0.643590 | Val Loss: 0.195288, Val Acc: 0.628866\n",
      "Epoch 4694 - Train Loss: 0.186192, Train Acc: 0.643590 | Val Loss: 0.195274, Val Acc: 0.628866\n",
      "Epoch 4695 - Train Loss: 0.186178, Train Acc: 0.643590 | Val Loss: 0.195261, Val Acc: 0.628866\n",
      "Epoch 4696 - Train Loss: 0.186163, Train Acc: 0.643590 | Val Loss: 0.195247, Val Acc: 0.628866\n",
      "Epoch 4697 - Train Loss: 0.186149, Train Acc: 0.643590 | Val Loss: 0.195233, Val Acc: 0.628866\n",
      "Epoch 4698 - Train Loss: 0.186134, Train Acc: 0.643590 | Val Loss: 0.195220, Val Acc: 0.628866\n",
      "Epoch 4699 - Train Loss: 0.186119, Train Acc: 0.643590 | Val Loss: 0.195206, Val Acc: 0.628866\n",
      "Epoch 4700 - Train Loss: 0.186105, Train Acc: 0.643590 | Val Loss: 0.195193, Val Acc: 0.628866\n",
      "Epoch 4701 - Train Loss: 0.186090, Train Acc: 0.643590 | Val Loss: 0.195179, Val Acc: 0.628866\n",
      "Epoch 4702 - Train Loss: 0.186076, Train Acc: 0.643590 | Val Loss: 0.195165, Val Acc: 0.628866\n",
      "Epoch 4703 - Train Loss: 0.186061, Train Acc: 0.643590 | Val Loss: 0.195152, Val Acc: 0.628866\n",
      "Epoch 4704 - Train Loss: 0.186047, Train Acc: 0.643590 | Val Loss: 0.195138, Val Acc: 0.628866\n",
      "Epoch 4705 - Train Loss: 0.186032, Train Acc: 0.643590 | Val Loss: 0.195125, Val Acc: 0.628866\n",
      "Epoch 4706 - Train Loss: 0.186018, Train Acc: 0.643590 | Val Loss: 0.195111, Val Acc: 0.628866\n",
      "Epoch 4707 - Train Loss: 0.186003, Train Acc: 0.643590 | Val Loss: 0.195098, Val Acc: 0.628866\n",
      "Epoch 4708 - Train Loss: 0.185989, Train Acc: 0.643590 | Val Loss: 0.195084, Val Acc: 0.628866\n",
      "Epoch 4709 - Train Loss: 0.185974, Train Acc: 0.643590 | Val Loss: 0.195070, Val Acc: 0.628866\n",
      "Epoch 4710 - Train Loss: 0.185959, Train Acc: 0.643590 | Val Loss: 0.195057, Val Acc: 0.628866\n",
      "Epoch 4711 - Train Loss: 0.185945, Train Acc: 0.643590 | Val Loss: 0.195043, Val Acc: 0.628866\n",
      "Epoch 4712 - Train Loss: 0.185930, Train Acc: 0.643590 | Val Loss: 0.195030, Val Acc: 0.628866\n",
      "Epoch 4713 - Train Loss: 0.185916, Train Acc: 0.643590 | Val Loss: 0.195016, Val Acc: 0.628866\n",
      "Epoch 4714 - Train Loss: 0.185901, Train Acc: 0.643590 | Val Loss: 0.195002, Val Acc: 0.628866\n",
      "Epoch 4715 - Train Loss: 0.185887, Train Acc: 0.643590 | Val Loss: 0.194989, Val Acc: 0.628866\n",
      "Epoch 4716 - Train Loss: 0.185872, Train Acc: 0.643590 | Val Loss: 0.194975, Val Acc: 0.628866\n",
      "Epoch 4717 - Train Loss: 0.185858, Train Acc: 0.643590 | Val Loss: 0.194962, Val Acc: 0.628866\n",
      "Epoch 4718 - Train Loss: 0.185843, Train Acc: 0.643590 | Val Loss: 0.194948, Val Acc: 0.628866\n",
      "Epoch 4719 - Train Loss: 0.185829, Train Acc: 0.643590 | Val Loss: 0.194935, Val Acc: 0.628866\n",
      "Epoch 4720 - Train Loss: 0.185814, Train Acc: 0.643590 | Val Loss: 0.194921, Val Acc: 0.628866\n",
      "Epoch 4721 - Train Loss: 0.185800, Train Acc: 0.643590 | Val Loss: 0.194907, Val Acc: 0.628866\n",
      "Epoch 4722 - Train Loss: 0.185785, Train Acc: 0.643590 | Val Loss: 0.194894, Val Acc: 0.628866\n",
      "Epoch 4723 - Train Loss: 0.185771, Train Acc: 0.643590 | Val Loss: 0.194880, Val Acc: 0.628866\n",
      "Epoch 4724 - Train Loss: 0.185756, Train Acc: 0.643590 | Val Loss: 0.194867, Val Acc: 0.628866\n",
      "Epoch 4725 - Train Loss: 0.185742, Train Acc: 0.644872 | Val Loss: 0.194853, Val Acc: 0.628866\n",
      "Epoch 4726 - Train Loss: 0.185727, Train Acc: 0.644872 | Val Loss: 0.194840, Val Acc: 0.628866\n",
      "Epoch 4727 - Train Loss: 0.185713, Train Acc: 0.644872 | Val Loss: 0.194826, Val Acc: 0.628866\n",
      "Epoch 4728 - Train Loss: 0.185698, Train Acc: 0.644872 | Val Loss: 0.194813, Val Acc: 0.628866\n",
      "Epoch 4729 - Train Loss: 0.185684, Train Acc: 0.644872 | Val Loss: 0.194799, Val Acc: 0.628866\n",
      "Epoch 4730 - Train Loss: 0.185669, Train Acc: 0.646154 | Val Loss: 0.194785, Val Acc: 0.628866\n",
      "Epoch 4731 - Train Loss: 0.185655, Train Acc: 0.646154 | Val Loss: 0.194772, Val Acc: 0.628866\n",
      "Epoch 4732 - Train Loss: 0.185640, Train Acc: 0.646154 | Val Loss: 0.194758, Val Acc: 0.628866\n",
      "Epoch 4733 - Train Loss: 0.185626, Train Acc: 0.646154 | Val Loss: 0.194745, Val Acc: 0.628866\n",
      "Epoch 4734 - Train Loss: 0.185611, Train Acc: 0.646154 | Val Loss: 0.194731, Val Acc: 0.628866\n",
      "Epoch 4735 - Train Loss: 0.185597, Train Acc: 0.646154 | Val Loss: 0.194718, Val Acc: 0.628866\n",
      "Epoch 4736 - Train Loss: 0.185582, Train Acc: 0.646154 | Val Loss: 0.194704, Val Acc: 0.628866\n",
      "Epoch 4737 - Train Loss: 0.185568, Train Acc: 0.646154 | Val Loss: 0.194691, Val Acc: 0.628866\n",
      "Epoch 4738 - Train Loss: 0.185553, Train Acc: 0.646154 | Val Loss: 0.194677, Val Acc: 0.628866\n",
      "Epoch 4739 - Train Loss: 0.185539, Train Acc: 0.646154 | Val Loss: 0.194664, Val Acc: 0.628866\n",
      "Epoch 4740 - Train Loss: 0.185524, Train Acc: 0.646154 | Val Loss: 0.194650, Val Acc: 0.639175\n",
      "Epoch 4741 - Train Loss: 0.185510, Train Acc: 0.646154 | Val Loss: 0.194637, Val Acc: 0.639175\n",
      "Epoch 4742 - Train Loss: 0.185495, Train Acc: 0.646154 | Val Loss: 0.194623, Val Acc: 0.639175\n",
      "Epoch 4743 - Train Loss: 0.185481, Train Acc: 0.646154 | Val Loss: 0.194610, Val Acc: 0.639175\n",
      "Epoch 4744 - Train Loss: 0.185466, Train Acc: 0.646154 | Val Loss: 0.194596, Val Acc: 0.639175\n",
      "Epoch 4745 - Train Loss: 0.185452, Train Acc: 0.646154 | Val Loss: 0.194583, Val Acc: 0.639175\n",
      "Epoch 4746 - Train Loss: 0.185437, Train Acc: 0.646154 | Val Loss: 0.194569, Val Acc: 0.639175\n",
      "Epoch 4747 - Train Loss: 0.185423, Train Acc: 0.646154 | Val Loss: 0.194555, Val Acc: 0.639175\n",
      "Epoch 4748 - Train Loss: 0.185409, Train Acc: 0.646154 | Val Loss: 0.194542, Val Acc: 0.639175\n",
      "Epoch 4749 - Train Loss: 0.185394, Train Acc: 0.646154 | Val Loss: 0.194528, Val Acc: 0.639175\n",
      "Epoch 4750 - Train Loss: 0.185380, Train Acc: 0.646154 | Val Loss: 0.194515, Val Acc: 0.639175\n",
      "Epoch 4751 - Train Loss: 0.185365, Train Acc: 0.646154 | Val Loss: 0.194501, Val Acc: 0.639175\n",
      "Epoch 4752 - Train Loss: 0.185351, Train Acc: 0.646154 | Val Loss: 0.194488, Val Acc: 0.639175\n",
      "Epoch 4753 - Train Loss: 0.185336, Train Acc: 0.646154 | Val Loss: 0.194474, Val Acc: 0.639175\n",
      "Epoch 4754 - Train Loss: 0.185322, Train Acc: 0.646154 | Val Loss: 0.194461, Val Acc: 0.639175\n",
      "Epoch 4755 - Train Loss: 0.185307, Train Acc: 0.646154 | Val Loss: 0.194447, Val Acc: 0.639175\n",
      "Epoch 4756 - Train Loss: 0.185293, Train Acc: 0.646154 | Val Loss: 0.194434, Val Acc: 0.639175\n",
      "Epoch 4757 - Train Loss: 0.185278, Train Acc: 0.646154 | Val Loss: 0.194420, Val Acc: 0.639175\n",
      "Epoch 4758 - Train Loss: 0.185264, Train Acc: 0.646154 | Val Loss: 0.194407, Val Acc: 0.639175\n",
      "Epoch 4759 - Train Loss: 0.185250, Train Acc: 0.646154 | Val Loss: 0.194393, Val Acc: 0.639175\n",
      "Epoch 4760 - Train Loss: 0.185235, Train Acc: 0.646154 | Val Loss: 0.194380, Val Acc: 0.639175\n",
      "Epoch 4761 - Train Loss: 0.185221, Train Acc: 0.646154 | Val Loss: 0.194366, Val Acc: 0.639175\n",
      "Epoch 4762 - Train Loss: 0.185206, Train Acc: 0.646154 | Val Loss: 0.194353, Val Acc: 0.639175\n",
      "Epoch 4763 - Train Loss: 0.185192, Train Acc: 0.646154 | Val Loss: 0.194339, Val Acc: 0.639175\n",
      "Epoch 4764 - Train Loss: 0.185177, Train Acc: 0.646154 | Val Loss: 0.194326, Val Acc: 0.639175\n",
      "Epoch 4765 - Train Loss: 0.185163, Train Acc: 0.646154 | Val Loss: 0.194313, Val Acc: 0.639175\n",
      "Epoch 4766 - Train Loss: 0.185149, Train Acc: 0.646154 | Val Loss: 0.194299, Val Acc: 0.639175\n",
      "Epoch 4767 - Train Loss: 0.185134, Train Acc: 0.646154 | Val Loss: 0.194286, Val Acc: 0.639175\n",
      "Epoch 4768 - Train Loss: 0.185120, Train Acc: 0.646154 | Val Loss: 0.194272, Val Acc: 0.639175\n",
      "Epoch 4769 - Train Loss: 0.185105, Train Acc: 0.646154 | Val Loss: 0.194259, Val Acc: 0.639175\n",
      "Epoch 4770 - Train Loss: 0.185091, Train Acc: 0.646154 | Val Loss: 0.194245, Val Acc: 0.639175\n",
      "Epoch 4771 - Train Loss: 0.185076, Train Acc: 0.646154 | Val Loss: 0.194232, Val Acc: 0.639175\n",
      "Epoch 4772 - Train Loss: 0.185062, Train Acc: 0.646154 | Val Loss: 0.194218, Val Acc: 0.639175\n",
      "Epoch 4773 - Train Loss: 0.185048, Train Acc: 0.646154 | Val Loss: 0.194205, Val Acc: 0.639175\n",
      "Epoch 4774 - Train Loss: 0.185033, Train Acc: 0.646154 | Val Loss: 0.194191, Val Acc: 0.639175\n",
      "Epoch 4775 - Train Loss: 0.185019, Train Acc: 0.646154 | Val Loss: 0.194178, Val Acc: 0.639175\n",
      "Epoch 4776 - Train Loss: 0.185004, Train Acc: 0.646154 | Val Loss: 0.194164, Val Acc: 0.639175\n",
      "Epoch 4777 - Train Loss: 0.184990, Train Acc: 0.646154 | Val Loss: 0.194151, Val Acc: 0.639175\n",
      "Epoch 4778 - Train Loss: 0.184976, Train Acc: 0.646154 | Val Loss: 0.194137, Val Acc: 0.639175\n",
      "Epoch 4779 - Train Loss: 0.184961, Train Acc: 0.646154 | Val Loss: 0.194124, Val Acc: 0.639175\n",
      "Epoch 4780 - Train Loss: 0.184947, Train Acc: 0.646154 | Val Loss: 0.194111, Val Acc: 0.639175\n",
      "Epoch 4781 - Train Loss: 0.184932, Train Acc: 0.646154 | Val Loss: 0.194097, Val Acc: 0.639175\n",
      "Epoch 4782 - Train Loss: 0.184918, Train Acc: 0.646154 | Val Loss: 0.194084, Val Acc: 0.639175\n",
      "Epoch 4783 - Train Loss: 0.184904, Train Acc: 0.646154 | Val Loss: 0.194070, Val Acc: 0.639175\n",
      "Epoch 4784 - Train Loss: 0.184889, Train Acc: 0.646154 | Val Loss: 0.194057, Val Acc: 0.639175\n",
      "Epoch 4785 - Train Loss: 0.184875, Train Acc: 0.646154 | Val Loss: 0.194043, Val Acc: 0.639175\n",
      "Epoch 4786 - Train Loss: 0.184860, Train Acc: 0.646154 | Val Loss: 0.194030, Val Acc: 0.639175\n",
      "Epoch 4787 - Train Loss: 0.184846, Train Acc: 0.647436 | Val Loss: 0.194017, Val Acc: 0.639175\n",
      "Epoch 4788 - Train Loss: 0.184832, Train Acc: 0.647436 | Val Loss: 0.194003, Val Acc: 0.639175\n",
      "Epoch 4789 - Train Loss: 0.184817, Train Acc: 0.647436 | Val Loss: 0.193990, Val Acc: 0.639175\n",
      "Epoch 4790 - Train Loss: 0.184803, Train Acc: 0.647436 | Val Loss: 0.193976, Val Acc: 0.639175\n",
      "Epoch 4791 - Train Loss: 0.184789, Train Acc: 0.647436 | Val Loss: 0.193963, Val Acc: 0.639175\n",
      "Epoch 4792 - Train Loss: 0.184774, Train Acc: 0.647436 | Val Loss: 0.193949, Val Acc: 0.639175\n",
      "Epoch 4793 - Train Loss: 0.184760, Train Acc: 0.647436 | Val Loss: 0.193936, Val Acc: 0.639175\n",
      "Epoch 4794 - Train Loss: 0.184745, Train Acc: 0.647436 | Val Loss: 0.193923, Val Acc: 0.639175\n",
      "Epoch 4795 - Train Loss: 0.184731, Train Acc: 0.647436 | Val Loss: 0.193909, Val Acc: 0.639175\n",
      "Epoch 4796 - Train Loss: 0.184717, Train Acc: 0.647436 | Val Loss: 0.193896, Val Acc: 0.639175\n",
      "Epoch 4797 - Train Loss: 0.184702, Train Acc: 0.647436 | Val Loss: 0.193882, Val Acc: 0.639175\n",
      "Epoch 4798 - Train Loss: 0.184688, Train Acc: 0.647436 | Val Loss: 0.193869, Val Acc: 0.639175\n",
      "Epoch 4799 - Train Loss: 0.184674, Train Acc: 0.647436 | Val Loss: 0.193856, Val Acc: 0.639175\n",
      "Epoch 4800 - Train Loss: 0.184659, Train Acc: 0.647436 | Val Loss: 0.193842, Val Acc: 0.639175\n",
      "Epoch 4801 - Train Loss: 0.184645, Train Acc: 0.647436 | Val Loss: 0.193829, Val Acc: 0.639175\n",
      "Epoch 4802 - Train Loss: 0.184630, Train Acc: 0.647436 | Val Loss: 0.193815, Val Acc: 0.639175\n",
      "Epoch 4803 - Train Loss: 0.184616, Train Acc: 0.647436 | Val Loss: 0.193802, Val Acc: 0.639175\n",
      "Epoch 4804 - Train Loss: 0.184602, Train Acc: 0.647436 | Val Loss: 0.193789, Val Acc: 0.639175\n",
      "Epoch 4805 - Train Loss: 0.184587, Train Acc: 0.647436 | Val Loss: 0.193775, Val Acc: 0.639175\n",
      "Epoch 4806 - Train Loss: 0.184573, Train Acc: 0.647436 | Val Loss: 0.193762, Val Acc: 0.639175\n",
      "Epoch 4807 - Train Loss: 0.184559, Train Acc: 0.647436 | Val Loss: 0.193748, Val Acc: 0.639175\n",
      "Epoch 4808 - Train Loss: 0.184544, Train Acc: 0.647436 | Val Loss: 0.193735, Val Acc: 0.639175\n",
      "Epoch 4809 - Train Loss: 0.184530, Train Acc: 0.647436 | Val Loss: 0.193722, Val Acc: 0.639175\n",
      "Epoch 4810 - Train Loss: 0.184516, Train Acc: 0.647436 | Val Loss: 0.193708, Val Acc: 0.639175\n",
      "Epoch 4811 - Train Loss: 0.184501, Train Acc: 0.647436 | Val Loss: 0.193695, Val Acc: 0.639175\n",
      "Epoch 4812 - Train Loss: 0.184487, Train Acc: 0.647436 | Val Loss: 0.193682, Val Acc: 0.639175\n",
      "Epoch 4813 - Train Loss: 0.184473, Train Acc: 0.647436 | Val Loss: 0.193668, Val Acc: 0.639175\n",
      "Epoch 4814 - Train Loss: 0.184458, Train Acc: 0.647436 | Val Loss: 0.193655, Val Acc: 0.639175\n",
      "Epoch 4815 - Train Loss: 0.184444, Train Acc: 0.647436 | Val Loss: 0.193641, Val Acc: 0.639175\n",
      "Epoch 4816 - Train Loss: 0.184430, Train Acc: 0.647436 | Val Loss: 0.193628, Val Acc: 0.639175\n",
      "Epoch 4817 - Train Loss: 0.184415, Train Acc: 0.647436 | Val Loss: 0.193615, Val Acc: 0.639175\n",
      "Epoch 4818 - Train Loss: 0.184401, Train Acc: 0.647436 | Val Loss: 0.193601, Val Acc: 0.639175\n",
      "Epoch 4819 - Train Loss: 0.184387, Train Acc: 0.647436 | Val Loss: 0.193588, Val Acc: 0.639175\n",
      "Epoch 4820 - Train Loss: 0.184372, Train Acc: 0.647436 | Val Loss: 0.193575, Val Acc: 0.639175\n",
      "Epoch 4821 - Train Loss: 0.184358, Train Acc: 0.647436 | Val Loss: 0.193561, Val Acc: 0.639175\n",
      "Epoch 4822 - Train Loss: 0.184344, Train Acc: 0.647436 | Val Loss: 0.193548, Val Acc: 0.639175\n",
      "Epoch 4823 - Train Loss: 0.184329, Train Acc: 0.647436 | Val Loss: 0.193535, Val Acc: 0.639175\n",
      "Epoch 4824 - Train Loss: 0.184315, Train Acc: 0.647436 | Val Loss: 0.193521, Val Acc: 0.639175\n",
      "Epoch 4825 - Train Loss: 0.184301, Train Acc: 0.647436 | Val Loss: 0.193508, Val Acc: 0.639175\n",
      "Epoch 4826 - Train Loss: 0.184286, Train Acc: 0.647436 | Val Loss: 0.193495, Val Acc: 0.639175\n",
      "Epoch 4827 - Train Loss: 0.184272, Train Acc: 0.647436 | Val Loss: 0.193481, Val Acc: 0.639175\n",
      "Epoch 4828 - Train Loss: 0.184258, Train Acc: 0.647436 | Val Loss: 0.193468, Val Acc: 0.639175\n",
      "Epoch 4829 - Train Loss: 0.184243, Train Acc: 0.647436 | Val Loss: 0.193454, Val Acc: 0.639175\n",
      "Epoch 4830 - Train Loss: 0.184229, Train Acc: 0.647436 | Val Loss: 0.193441, Val Acc: 0.639175\n",
      "Epoch 4831 - Train Loss: 0.184215, Train Acc: 0.647436 | Val Loss: 0.193428, Val Acc: 0.639175\n",
      "Epoch 4832 - Train Loss: 0.184201, Train Acc: 0.647436 | Val Loss: 0.193414, Val Acc: 0.639175\n",
      "Epoch 4833 - Train Loss: 0.184186, Train Acc: 0.647436 | Val Loss: 0.193401, Val Acc: 0.639175\n",
      "Epoch 4834 - Train Loss: 0.184172, Train Acc: 0.646154 | Val Loss: 0.193388, Val Acc: 0.639175\n",
      "Epoch 4835 - Train Loss: 0.184158, Train Acc: 0.646154 | Val Loss: 0.193374, Val Acc: 0.639175\n",
      "Epoch 4836 - Train Loss: 0.184143, Train Acc: 0.646154 | Val Loss: 0.193361, Val Acc: 0.639175\n",
      "Epoch 4837 - Train Loss: 0.184129, Train Acc: 0.646154 | Val Loss: 0.193348, Val Acc: 0.639175\n",
      "Epoch 4838 - Train Loss: 0.184115, Train Acc: 0.646154 | Val Loss: 0.193334, Val Acc: 0.639175\n",
      "Epoch 4839 - Train Loss: 0.184100, Train Acc: 0.646154 | Val Loss: 0.193321, Val Acc: 0.639175\n",
      "Epoch 4840 - Train Loss: 0.184086, Train Acc: 0.646154 | Val Loss: 0.193308, Val Acc: 0.639175\n",
      "Epoch 4841 - Train Loss: 0.184072, Train Acc: 0.646154 | Val Loss: 0.193294, Val Acc: 0.639175\n",
      "Epoch 4842 - Train Loss: 0.184058, Train Acc: 0.646154 | Val Loss: 0.193281, Val Acc: 0.639175\n",
      "Epoch 4843 - Train Loss: 0.184043, Train Acc: 0.646154 | Val Loss: 0.193268, Val Acc: 0.639175\n",
      "Epoch 4844 - Train Loss: 0.184029, Train Acc: 0.646154 | Val Loss: 0.193254, Val Acc: 0.639175\n",
      "Epoch 4845 - Train Loss: 0.184015, Train Acc: 0.646154 | Val Loss: 0.193241, Val Acc: 0.639175\n",
      "Epoch 4846 - Train Loss: 0.184001, Train Acc: 0.646154 | Val Loss: 0.193228, Val Acc: 0.639175\n",
      "Epoch 4847 - Train Loss: 0.183986, Train Acc: 0.646154 | Val Loss: 0.193215, Val Acc: 0.639175\n",
      "Epoch 4848 - Train Loss: 0.183972, Train Acc: 0.646154 | Val Loss: 0.193201, Val Acc: 0.639175\n",
      "Epoch 4849 - Train Loss: 0.183958, Train Acc: 0.646154 | Val Loss: 0.193188, Val Acc: 0.639175\n",
      "Epoch 4850 - Train Loss: 0.183943, Train Acc: 0.646154 | Val Loss: 0.193175, Val Acc: 0.639175\n",
      "Epoch 4851 - Train Loss: 0.183929, Train Acc: 0.646154 | Val Loss: 0.193161, Val Acc: 0.639175\n",
      "Epoch 4852 - Train Loss: 0.183915, Train Acc: 0.646154 | Val Loss: 0.193148, Val Acc: 0.639175\n",
      "Epoch 4853 - Train Loss: 0.183901, Train Acc: 0.646154 | Val Loss: 0.193135, Val Acc: 0.639175\n",
      "Epoch 4854 - Train Loss: 0.183886, Train Acc: 0.646154 | Val Loss: 0.193121, Val Acc: 0.639175\n",
      "Epoch 4855 - Train Loss: 0.183872, Train Acc: 0.646154 | Val Loss: 0.193108, Val Acc: 0.639175\n",
      "Epoch 4856 - Train Loss: 0.183858, Train Acc: 0.646154 | Val Loss: 0.193095, Val Acc: 0.639175\n",
      "Epoch 4857 - Train Loss: 0.183844, Train Acc: 0.646154 | Val Loss: 0.193082, Val Acc: 0.639175\n",
      "Epoch 4858 - Train Loss: 0.183829, Train Acc: 0.646154 | Val Loss: 0.193068, Val Acc: 0.639175\n",
      "Epoch 4859 - Train Loss: 0.183815, Train Acc: 0.646154 | Val Loss: 0.193055, Val Acc: 0.639175\n",
      "Epoch 4860 - Train Loss: 0.183801, Train Acc: 0.646154 | Val Loss: 0.193042, Val Acc: 0.639175\n",
      "Epoch 4861 - Train Loss: 0.183787, Train Acc: 0.646154 | Val Loss: 0.193028, Val Acc: 0.639175\n",
      "Epoch 4862 - Train Loss: 0.183772, Train Acc: 0.646154 | Val Loss: 0.193015, Val Acc: 0.639175\n",
      "Epoch 4863 - Train Loss: 0.183758, Train Acc: 0.647436 | Val Loss: 0.193002, Val Acc: 0.639175\n",
      "Epoch 4864 - Train Loss: 0.183744, Train Acc: 0.647436 | Val Loss: 0.192989, Val Acc: 0.639175\n",
      "Epoch 4865 - Train Loss: 0.183730, Train Acc: 0.647436 | Val Loss: 0.192975, Val Acc: 0.639175\n",
      "Epoch 4866 - Train Loss: 0.183715, Train Acc: 0.647436 | Val Loss: 0.192962, Val Acc: 0.639175\n",
      "Epoch 4867 - Train Loss: 0.183701, Train Acc: 0.647436 | Val Loss: 0.192949, Val Acc: 0.639175\n",
      "Epoch 4868 - Train Loss: 0.183687, Train Acc: 0.647436 | Val Loss: 0.192936, Val Acc: 0.639175\n",
      "Epoch 4869 - Train Loss: 0.183673, Train Acc: 0.647436 | Val Loss: 0.192922, Val Acc: 0.639175\n",
      "Epoch 4870 - Train Loss: 0.183658, Train Acc: 0.647436 | Val Loss: 0.192909, Val Acc: 0.639175\n",
      "Epoch 4871 - Train Loss: 0.183644, Train Acc: 0.647436 | Val Loss: 0.192896, Val Acc: 0.639175\n",
      "Epoch 4872 - Train Loss: 0.183630, Train Acc: 0.647436 | Val Loss: 0.192883, Val Acc: 0.639175\n",
      "Epoch 4873 - Train Loss: 0.183616, Train Acc: 0.647436 | Val Loss: 0.192870, Val Acc: 0.639175\n",
      "Epoch 4874 - Train Loss: 0.183602, Train Acc: 0.647436 | Val Loss: 0.192856, Val Acc: 0.639175\n",
      "Epoch 4875 - Train Loss: 0.183587, Train Acc: 0.647436 | Val Loss: 0.192843, Val Acc: 0.639175\n",
      "Epoch 4876 - Train Loss: 0.183573, Train Acc: 0.647436 | Val Loss: 0.192830, Val Acc: 0.639175\n",
      "Epoch 4877 - Train Loss: 0.183559, Train Acc: 0.647436 | Val Loss: 0.192817, Val Acc: 0.639175\n",
      "Epoch 4878 - Train Loss: 0.183545, Train Acc: 0.647436 | Val Loss: 0.192803, Val Acc: 0.639175\n",
      "Epoch 4879 - Train Loss: 0.183530, Train Acc: 0.647436 | Val Loss: 0.192790, Val Acc: 0.639175\n",
      "Epoch 4880 - Train Loss: 0.183516, Train Acc: 0.647436 | Val Loss: 0.192777, Val Acc: 0.639175\n",
      "Epoch 4881 - Train Loss: 0.183502, Train Acc: 0.647436 | Val Loss: 0.192764, Val Acc: 0.639175\n",
      "Epoch 4882 - Train Loss: 0.183488, Train Acc: 0.647436 | Val Loss: 0.192751, Val Acc: 0.639175\n",
      "Epoch 4883 - Train Loss: 0.183474, Train Acc: 0.647436 | Val Loss: 0.192737, Val Acc: 0.639175\n",
      "Epoch 4884 - Train Loss: 0.183459, Train Acc: 0.647436 | Val Loss: 0.192724, Val Acc: 0.639175\n",
      "Epoch 4885 - Train Loss: 0.183445, Train Acc: 0.647436 | Val Loss: 0.192711, Val Acc: 0.639175\n",
      "Epoch 4886 - Train Loss: 0.183431, Train Acc: 0.647436 | Val Loss: 0.192698, Val Acc: 0.639175\n",
      "Epoch 4887 - Train Loss: 0.183417, Train Acc: 0.647436 | Val Loss: 0.192685, Val Acc: 0.639175\n",
      "Epoch 4888 - Train Loss: 0.183403, Train Acc: 0.647436 | Val Loss: 0.192671, Val Acc: 0.639175\n",
      "Epoch 4889 - Train Loss: 0.183388, Train Acc: 0.647436 | Val Loss: 0.192658, Val Acc: 0.639175\n",
      "Epoch 4890 - Train Loss: 0.183374, Train Acc: 0.647436 | Val Loss: 0.192645, Val Acc: 0.639175\n",
      "Epoch 4891 - Train Loss: 0.183360, Train Acc: 0.647436 | Val Loss: 0.192632, Val Acc: 0.639175\n",
      "Epoch 4892 - Train Loss: 0.183346, Train Acc: 0.647436 | Val Loss: 0.192619, Val Acc: 0.639175\n",
      "Epoch 4893 - Train Loss: 0.183332, Train Acc: 0.647436 | Val Loss: 0.192605, Val Acc: 0.639175\n",
      "Epoch 4894 - Train Loss: 0.183317, Train Acc: 0.647436 | Val Loss: 0.192592, Val Acc: 0.639175\n",
      "Epoch 4895 - Train Loss: 0.183303, Train Acc: 0.647436 | Val Loss: 0.192579, Val Acc: 0.639175\n",
      "Epoch 4896 - Train Loss: 0.183289, Train Acc: 0.647436 | Val Loss: 0.192566, Val Acc: 0.639175\n",
      "Epoch 4897 - Train Loss: 0.183275, Train Acc: 0.647436 | Val Loss: 0.192553, Val Acc: 0.639175\n",
      "Epoch 4898 - Train Loss: 0.183261, Train Acc: 0.647436 | Val Loss: 0.192539, Val Acc: 0.639175\n",
      "Epoch 4899 - Train Loss: 0.183246, Train Acc: 0.647436 | Val Loss: 0.192526, Val Acc: 0.639175\n",
      "Epoch 4900 - Train Loss: 0.183232, Train Acc: 0.647436 | Val Loss: 0.192513, Val Acc: 0.639175\n",
      "Epoch 4901 - Train Loss: 0.183218, Train Acc: 0.647436 | Val Loss: 0.192500, Val Acc: 0.639175\n",
      "Epoch 4902 - Train Loss: 0.183204, Train Acc: 0.647436 | Val Loss: 0.192487, Val Acc: 0.639175\n",
      "Epoch 4903 - Train Loss: 0.183190, Train Acc: 0.647436 | Val Loss: 0.192474, Val Acc: 0.639175\n",
      "Epoch 4904 - Train Loss: 0.183176, Train Acc: 0.647436 | Val Loss: 0.192460, Val Acc: 0.639175\n",
      "Epoch 4905 - Train Loss: 0.183161, Train Acc: 0.647436 | Val Loss: 0.192447, Val Acc: 0.639175\n",
      "Epoch 4906 - Train Loss: 0.183147, Train Acc: 0.647436 | Val Loss: 0.192434, Val Acc: 0.639175\n",
      "Epoch 4907 - Train Loss: 0.183133, Train Acc: 0.647436 | Val Loss: 0.192421, Val Acc: 0.639175\n",
      "Epoch 4908 - Train Loss: 0.183119, Train Acc: 0.647436 | Val Loss: 0.192408, Val Acc: 0.639175\n",
      "Epoch 4909 - Train Loss: 0.183105, Train Acc: 0.647436 | Val Loss: 0.192395, Val Acc: 0.639175\n",
      "Epoch 4910 - Train Loss: 0.183091, Train Acc: 0.647436 | Val Loss: 0.192382, Val Acc: 0.639175\n",
      "Epoch 4911 - Train Loss: 0.183076, Train Acc: 0.647436 | Val Loss: 0.192368, Val Acc: 0.639175\n",
      "Epoch 4912 - Train Loss: 0.183062, Train Acc: 0.647436 | Val Loss: 0.192355, Val Acc: 0.639175\n",
      "Epoch 4913 - Train Loss: 0.183048, Train Acc: 0.647436 | Val Loss: 0.192342, Val Acc: 0.639175\n",
      "Epoch 4914 - Train Loss: 0.183034, Train Acc: 0.647436 | Val Loss: 0.192329, Val Acc: 0.639175\n",
      "Epoch 4915 - Train Loss: 0.183020, Train Acc: 0.647436 | Val Loss: 0.192316, Val Acc: 0.639175\n",
      "Epoch 4916 - Train Loss: 0.183006, Train Acc: 0.647436 | Val Loss: 0.192303, Val Acc: 0.639175\n",
      "Epoch 4917 - Train Loss: 0.182991, Train Acc: 0.647436 | Val Loss: 0.192290, Val Acc: 0.639175\n",
      "Epoch 4918 - Train Loss: 0.182977, Train Acc: 0.647436 | Val Loss: 0.192276, Val Acc: 0.639175\n",
      "Epoch 4919 - Train Loss: 0.182963, Train Acc: 0.647436 | Val Loss: 0.192263, Val Acc: 0.639175\n",
      "Epoch 4920 - Train Loss: 0.182949, Train Acc: 0.647436 | Val Loss: 0.192250, Val Acc: 0.639175\n",
      "Epoch 4921 - Train Loss: 0.182935, Train Acc: 0.647436 | Val Loss: 0.192237, Val Acc: 0.639175\n",
      "Epoch 4922 - Train Loss: 0.182921, Train Acc: 0.647436 | Val Loss: 0.192224, Val Acc: 0.639175\n",
      "Epoch 4923 - Train Loss: 0.182907, Train Acc: 0.647436 | Val Loss: 0.192211, Val Acc: 0.639175\n",
      "Epoch 4924 - Train Loss: 0.182892, Train Acc: 0.647436 | Val Loss: 0.192198, Val Acc: 0.639175\n",
      "Epoch 4925 - Train Loss: 0.182878, Train Acc: 0.647436 | Val Loss: 0.192185, Val Acc: 0.639175\n",
      "Epoch 4926 - Train Loss: 0.182864, Train Acc: 0.647436 | Val Loss: 0.192171, Val Acc: 0.639175\n",
      "Epoch 4927 - Train Loss: 0.182850, Train Acc: 0.647436 | Val Loss: 0.192158, Val Acc: 0.639175\n",
      "Epoch 4928 - Train Loss: 0.182836, Train Acc: 0.647436 | Val Loss: 0.192145, Val Acc: 0.639175\n",
      "Epoch 4929 - Train Loss: 0.182822, Train Acc: 0.647436 | Val Loss: 0.192132, Val Acc: 0.639175\n",
      "Epoch 4930 - Train Loss: 0.182808, Train Acc: 0.647436 | Val Loss: 0.192119, Val Acc: 0.639175\n",
      "Epoch 4931 - Train Loss: 0.182793, Train Acc: 0.647436 | Val Loss: 0.192106, Val Acc: 0.639175\n",
      "Epoch 4932 - Train Loss: 0.182779, Train Acc: 0.647436 | Val Loss: 0.192093, Val Acc: 0.639175\n",
      "Epoch 4933 - Train Loss: 0.182765, Train Acc: 0.647436 | Val Loss: 0.192080, Val Acc: 0.639175\n",
      "Epoch 4934 - Train Loss: 0.182751, Train Acc: 0.647436 | Val Loss: 0.192067, Val Acc: 0.639175\n",
      "Epoch 4935 - Train Loss: 0.182737, Train Acc: 0.647436 | Val Loss: 0.192053, Val Acc: 0.639175\n",
      "Epoch 4936 - Train Loss: 0.182723, Train Acc: 0.647436 | Val Loss: 0.192040, Val Acc: 0.639175\n",
      "Epoch 4937 - Train Loss: 0.182709, Train Acc: 0.647436 | Val Loss: 0.192027, Val Acc: 0.639175\n",
      "Epoch 4938 - Train Loss: 0.182695, Train Acc: 0.647436 | Val Loss: 0.192014, Val Acc: 0.639175\n",
      "Epoch 4939 - Train Loss: 0.182680, Train Acc: 0.647436 | Val Loss: 0.192001, Val Acc: 0.639175\n",
      "Epoch 4940 - Train Loss: 0.182666, Train Acc: 0.647436 | Val Loss: 0.191988, Val Acc: 0.639175\n",
      "Epoch 4941 - Train Loss: 0.182652, Train Acc: 0.647436 | Val Loss: 0.191975, Val Acc: 0.639175\n",
      "Epoch 4942 - Train Loss: 0.182638, Train Acc: 0.647436 | Val Loss: 0.191962, Val Acc: 0.639175\n",
      "Epoch 4943 - Train Loss: 0.182624, Train Acc: 0.647436 | Val Loss: 0.191949, Val Acc: 0.639175\n",
      "Epoch 4944 - Train Loss: 0.182610, Train Acc: 0.647436 | Val Loss: 0.191936, Val Acc: 0.639175\n",
      "Epoch 4945 - Train Loss: 0.182596, Train Acc: 0.647436 | Val Loss: 0.191923, Val Acc: 0.639175\n",
      "Epoch 4946 - Train Loss: 0.182582, Train Acc: 0.647436 | Val Loss: 0.191909, Val Acc: 0.639175\n",
      "Epoch 4947 - Train Loss: 0.182568, Train Acc: 0.647436 | Val Loss: 0.191896, Val Acc: 0.639175\n",
      "Epoch 4948 - Train Loss: 0.182554, Train Acc: 0.647436 | Val Loss: 0.191883, Val Acc: 0.639175\n",
      "Epoch 4949 - Train Loss: 0.182539, Train Acc: 0.647436 | Val Loss: 0.191870, Val Acc: 0.639175\n",
      "Epoch 4950 - Train Loss: 0.182525, Train Acc: 0.647436 | Val Loss: 0.191857, Val Acc: 0.639175\n",
      "Epoch 4951 - Train Loss: 0.182511, Train Acc: 0.647436 | Val Loss: 0.191844, Val Acc: 0.639175\n",
      "Epoch 4952 - Train Loss: 0.182497, Train Acc: 0.647436 | Val Loss: 0.191831, Val Acc: 0.639175\n",
      "Epoch 4953 - Train Loss: 0.182483, Train Acc: 0.647436 | Val Loss: 0.191818, Val Acc: 0.639175\n",
      "Epoch 4954 - Train Loss: 0.182469, Train Acc: 0.647436 | Val Loss: 0.191805, Val Acc: 0.639175\n",
      "Epoch 4955 - Train Loss: 0.182455, Train Acc: 0.647436 | Val Loss: 0.191792, Val Acc: 0.639175\n",
      "Epoch 4956 - Train Loss: 0.182441, Train Acc: 0.647436 | Val Loss: 0.191779, Val Acc: 0.639175\n",
      "Epoch 4957 - Train Loss: 0.182427, Train Acc: 0.647436 | Val Loss: 0.191766, Val Acc: 0.639175\n",
      "Epoch 4958 - Train Loss: 0.182413, Train Acc: 0.648718 | Val Loss: 0.191753, Val Acc: 0.639175\n",
      "Epoch 4959 - Train Loss: 0.182399, Train Acc: 0.648718 | Val Loss: 0.191740, Val Acc: 0.639175\n",
      "Epoch 4960 - Train Loss: 0.182384, Train Acc: 0.648718 | Val Loss: 0.191727, Val Acc: 0.639175\n",
      "Epoch 4961 - Train Loss: 0.182370, Train Acc: 0.648718 | Val Loss: 0.191714, Val Acc: 0.639175\n",
      "Epoch 4962 - Train Loss: 0.182356, Train Acc: 0.648718 | Val Loss: 0.191700, Val Acc: 0.639175\n",
      "Epoch 4963 - Train Loss: 0.182342, Train Acc: 0.648718 | Val Loss: 0.191687, Val Acc: 0.639175\n",
      "Epoch 4964 - Train Loss: 0.182328, Train Acc: 0.648718 | Val Loss: 0.191674, Val Acc: 0.639175\n",
      "Epoch 4965 - Train Loss: 0.182314, Train Acc: 0.648718 | Val Loss: 0.191661, Val Acc: 0.639175\n",
      "Epoch 4966 - Train Loss: 0.182300, Train Acc: 0.648718 | Val Loss: 0.191648, Val Acc: 0.639175\n",
      "Epoch 4967 - Train Loss: 0.182286, Train Acc: 0.648718 | Val Loss: 0.191635, Val Acc: 0.639175\n",
      "Epoch 4968 - Train Loss: 0.182272, Train Acc: 0.648718 | Val Loss: 0.191622, Val Acc: 0.639175\n",
      "Epoch 4969 - Train Loss: 0.182258, Train Acc: 0.648718 | Val Loss: 0.191609, Val Acc: 0.639175\n",
      "Epoch 4970 - Train Loss: 0.182244, Train Acc: 0.648718 | Val Loss: 0.191596, Val Acc: 0.639175\n",
      "Epoch 4971 - Train Loss: 0.182230, Train Acc: 0.648718 | Val Loss: 0.191583, Val Acc: 0.639175\n",
      "Epoch 4972 - Train Loss: 0.182216, Train Acc: 0.648718 | Val Loss: 0.191570, Val Acc: 0.639175\n",
      "Epoch 4973 - Train Loss: 0.182202, Train Acc: 0.648718 | Val Loss: 0.191557, Val Acc: 0.639175\n",
      "Epoch 4974 - Train Loss: 0.182187, Train Acc: 0.648718 | Val Loss: 0.191544, Val Acc: 0.639175\n",
      "Epoch 4975 - Train Loss: 0.182173, Train Acc: 0.648718 | Val Loss: 0.191531, Val Acc: 0.639175\n",
      "Epoch 4976 - Train Loss: 0.182159, Train Acc: 0.648718 | Val Loss: 0.191518, Val Acc: 0.639175\n",
      "Epoch 4977 - Train Loss: 0.182145, Train Acc: 0.648718 | Val Loss: 0.191505, Val Acc: 0.639175\n",
      "Epoch 4978 - Train Loss: 0.182131, Train Acc: 0.648718 | Val Loss: 0.191492, Val Acc: 0.639175\n",
      "Epoch 4979 - Train Loss: 0.182117, Train Acc: 0.648718 | Val Loss: 0.191479, Val Acc: 0.639175\n",
      "Epoch 4980 - Train Loss: 0.182103, Train Acc: 0.648718 | Val Loss: 0.191466, Val Acc: 0.639175\n",
      "Epoch 4981 - Train Loss: 0.182089, Train Acc: 0.648718 | Val Loss: 0.191453, Val Acc: 0.639175\n",
      "Epoch 4982 - Train Loss: 0.182075, Train Acc: 0.648718 | Val Loss: 0.191440, Val Acc: 0.639175\n",
      "Epoch 4983 - Train Loss: 0.182061, Train Acc: 0.648718 | Val Loss: 0.191427, Val Acc: 0.639175\n",
      "Epoch 4984 - Train Loss: 0.182047, Train Acc: 0.648718 | Val Loss: 0.191414, Val Acc: 0.639175\n",
      "Epoch 4985 - Train Loss: 0.182033, Train Acc: 0.648718 | Val Loss: 0.191401, Val Acc: 0.639175\n",
      "Epoch 4986 - Train Loss: 0.182019, Train Acc: 0.648718 | Val Loss: 0.191388, Val Acc: 0.639175\n",
      "Epoch 4987 - Train Loss: 0.182005, Train Acc: 0.648718 | Val Loss: 0.191375, Val Acc: 0.639175\n",
      "Epoch 4988 - Train Loss: 0.181991, Train Acc: 0.648718 | Val Loss: 0.191362, Val Acc: 0.639175\n",
      "Epoch 4989 - Train Loss: 0.181977, Train Acc: 0.648718 | Val Loss: 0.191349, Val Acc: 0.639175\n",
      "Epoch 4990 - Train Loss: 0.181963, Train Acc: 0.648718 | Val Loss: 0.191336, Val Acc: 0.639175\n",
      "Epoch 4991 - Train Loss: 0.181949, Train Acc: 0.648718 | Val Loss: 0.191323, Val Acc: 0.639175\n",
      "Epoch 4992 - Train Loss: 0.181935, Train Acc: 0.648718 | Val Loss: 0.191310, Val Acc: 0.639175\n",
      "Epoch 4993 - Train Loss: 0.181921, Train Acc: 0.648718 | Val Loss: 0.191297, Val Acc: 0.639175\n",
      "Epoch 4994 - Train Loss: 0.181907, Train Acc: 0.648718 | Val Loss: 0.191284, Val Acc: 0.639175\n",
      "Epoch 4995 - Train Loss: 0.181893, Train Acc: 0.648718 | Val Loss: 0.191271, Val Acc: 0.639175\n",
      "Epoch 4996 - Train Loss: 0.181879, Train Acc: 0.648718 | Val Loss: 0.191258, Val Acc: 0.639175\n",
      "Epoch 4997 - Train Loss: 0.181865, Train Acc: 0.648718 | Val Loss: 0.191245, Val Acc: 0.639175\n",
      "Epoch 4998 - Train Loss: 0.181851, Train Acc: 0.648718 | Val Loss: 0.191232, Val Acc: 0.639175\n",
      "Epoch 4999 - Train Loss: 0.181837, Train Acc: 0.648718 | Val Loss: 0.191219, Val Acc: 0.639175\n",
      "Epoch 5000 - Train Loss: 0.181823, Train Acc: 0.648718 | Val Loss: 0.191206, Val Acc: 0.639175\n",
      "Epoch 5001 - Train Loss: 0.181809, Train Acc: 0.648718 | Val Loss: 0.191193, Val Acc: 0.639175\n",
      "Epoch 5002 - Train Loss: 0.181795, Train Acc: 0.648718 | Val Loss: 0.191180, Val Acc: 0.639175\n",
      "Epoch 5003 - Train Loss: 0.181781, Train Acc: 0.648718 | Val Loss: 0.191167, Val Acc: 0.639175\n",
      "Epoch 5004 - Train Loss: 0.181766, Train Acc: 0.648718 | Val Loss: 0.191154, Val Acc: 0.639175\n",
      "Epoch 5005 - Train Loss: 0.181752, Train Acc: 0.648718 | Val Loss: 0.191141, Val Acc: 0.639175\n",
      "Epoch 5006 - Train Loss: 0.181738, Train Acc: 0.648718 | Val Loss: 0.191128, Val Acc: 0.639175\n",
      "Epoch 5007 - Train Loss: 0.181724, Train Acc: 0.648718 | Val Loss: 0.191115, Val Acc: 0.639175\n",
      "Epoch 5008 - Train Loss: 0.181710, Train Acc: 0.648718 | Val Loss: 0.191103, Val Acc: 0.639175\n",
      "Epoch 5009 - Train Loss: 0.181696, Train Acc: 0.648718 | Val Loss: 0.191090, Val Acc: 0.639175\n",
      "Epoch 5010 - Train Loss: 0.181682, Train Acc: 0.648718 | Val Loss: 0.191077, Val Acc: 0.639175\n",
      "Epoch 5011 - Train Loss: 0.181668, Train Acc: 0.648718 | Val Loss: 0.191064, Val Acc: 0.639175\n",
      "Epoch 5012 - Train Loss: 0.181654, Train Acc: 0.648718 | Val Loss: 0.191051, Val Acc: 0.639175\n",
      "Epoch 5013 - Train Loss: 0.181640, Train Acc: 0.648718 | Val Loss: 0.191038, Val Acc: 0.639175\n",
      "Epoch 5014 - Train Loss: 0.181626, Train Acc: 0.648718 | Val Loss: 0.191025, Val Acc: 0.639175\n",
      "Epoch 5015 - Train Loss: 0.181612, Train Acc: 0.648718 | Val Loss: 0.191012, Val Acc: 0.639175\n",
      "Epoch 5016 - Train Loss: 0.181599, Train Acc: 0.648718 | Val Loss: 0.190999, Val Acc: 0.639175\n",
      "Epoch 5017 - Train Loss: 0.181585, Train Acc: 0.648718 | Val Loss: 0.190986, Val Acc: 0.639175\n",
      "Epoch 5018 - Train Loss: 0.181571, Train Acc: 0.648718 | Val Loss: 0.190973, Val Acc: 0.639175\n",
      "Epoch 5019 - Train Loss: 0.181557, Train Acc: 0.648718 | Val Loss: 0.190960, Val Acc: 0.639175\n",
      "Epoch 5020 - Train Loss: 0.181543, Train Acc: 0.648718 | Val Loss: 0.190947, Val Acc: 0.639175\n",
      "Epoch 5021 - Train Loss: 0.181529, Train Acc: 0.648718 | Val Loss: 0.190934, Val Acc: 0.639175\n",
      "Epoch 5022 - Train Loss: 0.181515, Train Acc: 0.648718 | Val Loss: 0.190921, Val Acc: 0.639175\n",
      "Epoch 5023 - Train Loss: 0.181501, Train Acc: 0.648718 | Val Loss: 0.190908, Val Acc: 0.639175\n",
      "Epoch 5024 - Train Loss: 0.181487, Train Acc: 0.648718 | Val Loss: 0.190896, Val Acc: 0.639175\n",
      "Epoch 5025 - Train Loss: 0.181473, Train Acc: 0.648718 | Val Loss: 0.190883, Val Acc: 0.639175\n",
      "Epoch 5026 - Train Loss: 0.181459, Train Acc: 0.648718 | Val Loss: 0.190870, Val Acc: 0.639175\n",
      "Epoch 5027 - Train Loss: 0.181445, Train Acc: 0.648718 | Val Loss: 0.190857, Val Acc: 0.639175\n",
      "Epoch 5028 - Train Loss: 0.181431, Train Acc: 0.648718 | Val Loss: 0.190844, Val Acc: 0.639175\n",
      "Epoch 5029 - Train Loss: 0.181417, Train Acc: 0.648718 | Val Loss: 0.190831, Val Acc: 0.639175\n",
      "Epoch 5030 - Train Loss: 0.181403, Train Acc: 0.648718 | Val Loss: 0.190818, Val Acc: 0.639175\n",
      "Epoch 5031 - Train Loss: 0.181389, Train Acc: 0.648718 | Val Loss: 0.190805, Val Acc: 0.639175\n",
      "Epoch 5032 - Train Loss: 0.181375, Train Acc: 0.648718 | Val Loss: 0.190792, Val Acc: 0.639175\n",
      "Epoch 5033 - Train Loss: 0.181361, Train Acc: 0.648718 | Val Loss: 0.190779, Val Acc: 0.639175\n",
      "Epoch 5034 - Train Loss: 0.181347, Train Acc: 0.648718 | Val Loss: 0.190766, Val Acc: 0.639175\n",
      "Epoch 5035 - Train Loss: 0.181333, Train Acc: 0.648718 | Val Loss: 0.190754, Val Acc: 0.639175\n",
      "Epoch 5036 - Train Loss: 0.181319, Train Acc: 0.648718 | Val Loss: 0.190741, Val Acc: 0.639175\n",
      "Epoch 5037 - Train Loss: 0.181305, Train Acc: 0.648718 | Val Loss: 0.190728, Val Acc: 0.639175\n",
      "Epoch 5038 - Train Loss: 0.181291, Train Acc: 0.648718 | Val Loss: 0.190715, Val Acc: 0.639175\n",
      "Epoch 5039 - Train Loss: 0.181277, Train Acc: 0.648718 | Val Loss: 0.190702, Val Acc: 0.639175\n",
      "Epoch 5040 - Train Loss: 0.181263, Train Acc: 0.648718 | Val Loss: 0.190689, Val Acc: 0.639175\n",
      "Epoch 5041 - Train Loss: 0.181249, Train Acc: 0.648718 | Val Loss: 0.190676, Val Acc: 0.639175\n",
      "Epoch 5042 - Train Loss: 0.181235, Train Acc: 0.648718 | Val Loss: 0.190663, Val Acc: 0.639175\n",
      "Epoch 5043 - Train Loss: 0.181221, Train Acc: 0.648718 | Val Loss: 0.190650, Val Acc: 0.639175\n",
      "Epoch 5044 - Train Loss: 0.181207, Train Acc: 0.648718 | Val Loss: 0.190638, Val Acc: 0.639175\n",
      "Epoch 5045 - Train Loss: 0.181193, Train Acc: 0.648718 | Val Loss: 0.190625, Val Acc: 0.639175\n",
      "Epoch 5046 - Train Loss: 0.181180, Train Acc: 0.648718 | Val Loss: 0.190612, Val Acc: 0.639175\n",
      "Epoch 5047 - Train Loss: 0.181166, Train Acc: 0.648718 | Val Loss: 0.190599, Val Acc: 0.639175\n",
      "Epoch 5048 - Train Loss: 0.181152, Train Acc: 0.648718 | Val Loss: 0.190586, Val Acc: 0.639175\n",
      "Epoch 5049 - Train Loss: 0.181138, Train Acc: 0.648718 | Val Loss: 0.190573, Val Acc: 0.639175\n",
      "Epoch 5050 - Train Loss: 0.181124, Train Acc: 0.648718 | Val Loss: 0.190560, Val Acc: 0.639175\n",
      "Epoch 5051 - Train Loss: 0.181110, Train Acc: 0.648718 | Val Loss: 0.190547, Val Acc: 0.639175\n",
      "Epoch 5052 - Train Loss: 0.181096, Train Acc: 0.648718 | Val Loss: 0.190535, Val Acc: 0.639175\n",
      "Epoch 5053 - Train Loss: 0.181082, Train Acc: 0.648718 | Val Loss: 0.190522, Val Acc: 0.639175\n",
      "Epoch 5054 - Train Loss: 0.181068, Train Acc: 0.648718 | Val Loss: 0.190509, Val Acc: 0.639175\n",
      "Epoch 5055 - Train Loss: 0.181054, Train Acc: 0.648718 | Val Loss: 0.190496, Val Acc: 0.639175\n",
      "Epoch 5056 - Train Loss: 0.181040, Train Acc: 0.648718 | Val Loss: 0.190483, Val Acc: 0.639175\n",
      "Epoch 5057 - Train Loss: 0.181026, Train Acc: 0.648718 | Val Loss: 0.190470, Val Acc: 0.639175\n",
      "Epoch 5058 - Train Loss: 0.181012, Train Acc: 0.648718 | Val Loss: 0.190457, Val Acc: 0.639175\n",
      "Epoch 5059 - Train Loss: 0.180998, Train Acc: 0.648718 | Val Loss: 0.190445, Val Acc: 0.639175\n",
      "Epoch 5060 - Train Loss: 0.180985, Train Acc: 0.648718 | Val Loss: 0.190432, Val Acc: 0.639175\n",
      "Epoch 5061 - Train Loss: 0.180971, Train Acc: 0.648718 | Val Loss: 0.190419, Val Acc: 0.639175\n",
      "Epoch 5062 - Train Loss: 0.180957, Train Acc: 0.648718 | Val Loss: 0.190406, Val Acc: 0.639175\n",
      "Epoch 5063 - Train Loss: 0.180943, Train Acc: 0.648718 | Val Loss: 0.190393, Val Acc: 0.639175\n",
      "Epoch 5064 - Train Loss: 0.180929, Train Acc: 0.648718 | Val Loss: 0.190380, Val Acc: 0.639175\n",
      "Epoch 5065 - Train Loss: 0.180915, Train Acc: 0.648718 | Val Loss: 0.190367, Val Acc: 0.639175\n",
      "Epoch 5066 - Train Loss: 0.180901, Train Acc: 0.648718 | Val Loss: 0.190355, Val Acc: 0.639175\n",
      "Epoch 5067 - Train Loss: 0.180887, Train Acc: 0.648718 | Val Loss: 0.190342, Val Acc: 0.639175\n",
      "Epoch 5068 - Train Loss: 0.180873, Train Acc: 0.648718 | Val Loss: 0.190329, Val Acc: 0.639175\n",
      "Epoch 5069 - Train Loss: 0.180859, Train Acc: 0.648718 | Val Loss: 0.190316, Val Acc: 0.639175\n",
      "Epoch 5070 - Train Loss: 0.180845, Train Acc: 0.648718 | Val Loss: 0.190303, Val Acc: 0.639175\n",
      "Epoch 5071 - Train Loss: 0.180832, Train Acc: 0.648718 | Val Loss: 0.190290, Val Acc: 0.639175\n",
      "Epoch 5072 - Train Loss: 0.180818, Train Acc: 0.648718 | Val Loss: 0.190278, Val Acc: 0.639175\n",
      "Epoch 5073 - Train Loss: 0.180804, Train Acc: 0.648718 | Val Loss: 0.190265, Val Acc: 0.639175\n",
      "Epoch 5074 - Train Loss: 0.180790, Train Acc: 0.648718 | Val Loss: 0.190252, Val Acc: 0.639175\n",
      "Epoch 5075 - Train Loss: 0.180776, Train Acc: 0.648718 | Val Loss: 0.190239, Val Acc: 0.639175\n",
      "Epoch 5076 - Train Loss: 0.180762, Train Acc: 0.648718 | Val Loss: 0.190226, Val Acc: 0.639175\n",
      "Epoch 5077 - Train Loss: 0.180748, Train Acc: 0.648718 | Val Loss: 0.190213, Val Acc: 0.639175\n",
      "Epoch 5078 - Train Loss: 0.180734, Train Acc: 0.648718 | Val Loss: 0.190201, Val Acc: 0.639175\n",
      "Epoch 5079 - Train Loss: 0.180720, Train Acc: 0.648718 | Val Loss: 0.190188, Val Acc: 0.639175\n",
      "Epoch 5080 - Train Loss: 0.180706, Train Acc: 0.648718 | Val Loss: 0.190175, Val Acc: 0.639175\n",
      "Epoch 5081 - Train Loss: 0.180693, Train Acc: 0.648718 | Val Loss: 0.190162, Val Acc: 0.639175\n",
      "Epoch 5082 - Train Loss: 0.180679, Train Acc: 0.648718 | Val Loss: 0.190149, Val Acc: 0.639175\n",
      "Epoch 5083 - Train Loss: 0.180665, Train Acc: 0.648718 | Val Loss: 0.190137, Val Acc: 0.639175\n",
      "Epoch 5084 - Train Loss: 0.180651, Train Acc: 0.648718 | Val Loss: 0.190124, Val Acc: 0.639175\n",
      "Epoch 5085 - Train Loss: 0.180637, Train Acc: 0.648718 | Val Loss: 0.190111, Val Acc: 0.639175\n",
      "Epoch 5086 - Train Loss: 0.180623, Train Acc: 0.648718 | Val Loss: 0.190098, Val Acc: 0.639175\n",
      "Epoch 5087 - Train Loss: 0.180609, Train Acc: 0.648718 | Val Loss: 0.190085, Val Acc: 0.639175\n",
      "Epoch 5088 - Train Loss: 0.180595, Train Acc: 0.648718 | Val Loss: 0.190072, Val Acc: 0.639175\n",
      "Epoch 5089 - Train Loss: 0.180582, Train Acc: 0.648718 | Val Loss: 0.190060, Val Acc: 0.639175\n",
      "Epoch 5090 - Train Loss: 0.180568, Train Acc: 0.648718 | Val Loss: 0.190047, Val Acc: 0.639175\n",
      "Epoch 5091 - Train Loss: 0.180554, Train Acc: 0.648718 | Val Loss: 0.190034, Val Acc: 0.639175\n",
      "Epoch 5092 - Train Loss: 0.180540, Train Acc: 0.648718 | Val Loss: 0.190021, Val Acc: 0.639175\n",
      "Epoch 5093 - Train Loss: 0.180526, Train Acc: 0.648718 | Val Loss: 0.190008, Val Acc: 0.639175\n",
      "Epoch 5094 - Train Loss: 0.180512, Train Acc: 0.648718 | Val Loss: 0.189996, Val Acc: 0.639175\n",
      "Epoch 5095 - Train Loss: 0.180498, Train Acc: 0.648718 | Val Loss: 0.189983, Val Acc: 0.639175\n",
      "Epoch 5096 - Train Loss: 0.180484, Train Acc: 0.648718 | Val Loss: 0.189970, Val Acc: 0.639175\n",
      "Epoch 5097 - Train Loss: 0.180471, Train Acc: 0.648718 | Val Loss: 0.189957, Val Acc: 0.639175\n",
      "Epoch 5098 - Train Loss: 0.180457, Train Acc: 0.648718 | Val Loss: 0.189945, Val Acc: 0.639175\n",
      "Epoch 5099 - Train Loss: 0.180443, Train Acc: 0.648718 | Val Loss: 0.189932, Val Acc: 0.639175\n",
      "Epoch 5100 - Train Loss: 0.180429, Train Acc: 0.648718 | Val Loss: 0.189919, Val Acc: 0.639175\n",
      "Epoch 5101 - Train Loss: 0.180415, Train Acc: 0.648718 | Val Loss: 0.189906, Val Acc: 0.639175\n",
      "Epoch 5102 - Train Loss: 0.180401, Train Acc: 0.648718 | Val Loss: 0.189893, Val Acc: 0.639175\n",
      "Epoch 5103 - Train Loss: 0.180387, Train Acc: 0.648718 | Val Loss: 0.189881, Val Acc: 0.639175\n",
      "Epoch 5104 - Train Loss: 0.180374, Train Acc: 0.648718 | Val Loss: 0.189868, Val Acc: 0.639175\n",
      "Epoch 5105 - Train Loss: 0.180360, Train Acc: 0.648718 | Val Loss: 0.189855, Val Acc: 0.639175\n",
      "Epoch 5106 - Train Loss: 0.180346, Train Acc: 0.648718 | Val Loss: 0.189842, Val Acc: 0.639175\n",
      "Epoch 5107 - Train Loss: 0.180332, Train Acc: 0.648718 | Val Loss: 0.189829, Val Acc: 0.639175\n",
      "Epoch 5108 - Train Loss: 0.180318, Train Acc: 0.648718 | Val Loss: 0.189817, Val Acc: 0.639175\n",
      "Epoch 5109 - Train Loss: 0.180304, Train Acc: 0.648718 | Val Loss: 0.189804, Val Acc: 0.639175\n",
      "Epoch 5110 - Train Loss: 0.180291, Train Acc: 0.648718 | Val Loss: 0.189791, Val Acc: 0.639175\n",
      "Epoch 5111 - Train Loss: 0.180277, Train Acc: 0.648718 | Val Loss: 0.189778, Val Acc: 0.639175\n",
      "Epoch 5112 - Train Loss: 0.180263, Train Acc: 0.648718 | Val Loss: 0.189766, Val Acc: 0.639175\n",
      "Epoch 5113 - Train Loss: 0.180249, Train Acc: 0.648718 | Val Loss: 0.189753, Val Acc: 0.639175\n",
      "Epoch 5114 - Train Loss: 0.180235, Train Acc: 0.648718 | Val Loss: 0.189740, Val Acc: 0.639175\n",
      "Epoch 5115 - Train Loss: 0.180221, Train Acc: 0.648718 | Val Loss: 0.189727, Val Acc: 0.639175\n",
      "Epoch 5116 - Train Loss: 0.180208, Train Acc: 0.648718 | Val Loss: 0.189715, Val Acc: 0.639175\n",
      "Epoch 5117 - Train Loss: 0.180194, Train Acc: 0.648718 | Val Loss: 0.189702, Val Acc: 0.639175\n",
      "Epoch 5118 - Train Loss: 0.180180, Train Acc: 0.648718 | Val Loss: 0.189689, Val Acc: 0.639175\n",
      "Epoch 5119 - Train Loss: 0.180166, Train Acc: 0.648718 | Val Loss: 0.189676, Val Acc: 0.639175\n",
      "Epoch 5120 - Train Loss: 0.180152, Train Acc: 0.648718 | Val Loss: 0.189664, Val Acc: 0.639175\n",
      "Epoch 5121 - Train Loss: 0.180138, Train Acc: 0.648718 | Val Loss: 0.189651, Val Acc: 0.639175\n",
      "Epoch 5122 - Train Loss: 0.180125, Train Acc: 0.650000 | Val Loss: 0.189638, Val Acc: 0.639175\n",
      "Epoch 5123 - Train Loss: 0.180111, Train Acc: 0.650000 | Val Loss: 0.189625, Val Acc: 0.639175\n",
      "Epoch 5124 - Train Loss: 0.180097, Train Acc: 0.650000 | Val Loss: 0.189613, Val Acc: 0.639175\n",
      "Epoch 5125 - Train Loss: 0.180083, Train Acc: 0.651282 | Val Loss: 0.189600, Val Acc: 0.639175\n",
      "Epoch 5126 - Train Loss: 0.180069, Train Acc: 0.651282 | Val Loss: 0.189587, Val Acc: 0.639175\n",
      "Epoch 5127 - Train Loss: 0.180056, Train Acc: 0.651282 | Val Loss: 0.189574, Val Acc: 0.639175\n",
      "Epoch 5128 - Train Loss: 0.180042, Train Acc: 0.651282 | Val Loss: 0.189562, Val Acc: 0.639175\n",
      "Epoch 5129 - Train Loss: 0.180028, Train Acc: 0.651282 | Val Loss: 0.189549, Val Acc: 0.639175\n",
      "Epoch 5130 - Train Loss: 0.180014, Train Acc: 0.651282 | Val Loss: 0.189536, Val Acc: 0.639175\n",
      "Epoch 5131 - Train Loss: 0.180000, Train Acc: 0.651282 | Val Loss: 0.189524, Val Acc: 0.639175\n",
      "Epoch 5132 - Train Loss: 0.179986, Train Acc: 0.651282 | Val Loss: 0.189511, Val Acc: 0.639175\n",
      "Epoch 5133 - Train Loss: 0.179973, Train Acc: 0.651282 | Val Loss: 0.189498, Val Acc: 0.639175\n",
      "Epoch 5134 - Train Loss: 0.179959, Train Acc: 0.651282 | Val Loss: 0.189485, Val Acc: 0.639175\n",
      "Epoch 5135 - Train Loss: 0.179945, Train Acc: 0.651282 | Val Loss: 0.189473, Val Acc: 0.639175\n",
      "Epoch 5136 - Train Loss: 0.179931, Train Acc: 0.651282 | Val Loss: 0.189460, Val Acc: 0.639175\n",
      "Epoch 5137 - Train Loss: 0.179917, Train Acc: 0.651282 | Val Loss: 0.189447, Val Acc: 0.639175\n",
      "Epoch 5138 - Train Loss: 0.179904, Train Acc: 0.651282 | Val Loss: 0.189435, Val Acc: 0.639175\n",
      "Epoch 5139 - Train Loss: 0.179890, Train Acc: 0.651282 | Val Loss: 0.189422, Val Acc: 0.639175\n",
      "Epoch 5140 - Train Loss: 0.179876, Train Acc: 0.651282 | Val Loss: 0.189409, Val Acc: 0.639175\n",
      "Epoch 5141 - Train Loss: 0.179862, Train Acc: 0.651282 | Val Loss: 0.189396, Val Acc: 0.639175\n",
      "Epoch 5142 - Train Loss: 0.179848, Train Acc: 0.651282 | Val Loss: 0.189384, Val Acc: 0.639175\n",
      "Epoch 5143 - Train Loss: 0.179835, Train Acc: 0.651282 | Val Loss: 0.189371, Val Acc: 0.639175\n",
      "Epoch 5144 - Train Loss: 0.179821, Train Acc: 0.651282 | Val Loss: 0.189358, Val Acc: 0.639175\n",
      "Epoch 5145 - Train Loss: 0.179807, Train Acc: 0.651282 | Val Loss: 0.189346, Val Acc: 0.639175\n",
      "Epoch 5146 - Train Loss: 0.179793, Train Acc: 0.651282 | Val Loss: 0.189333, Val Acc: 0.639175\n",
      "Epoch 5147 - Train Loss: 0.179780, Train Acc: 0.651282 | Val Loss: 0.189320, Val Acc: 0.639175\n",
      "Epoch 5148 - Train Loss: 0.179766, Train Acc: 0.651282 | Val Loss: 0.189307, Val Acc: 0.639175\n",
      "Epoch 5149 - Train Loss: 0.179752, Train Acc: 0.651282 | Val Loss: 0.189295, Val Acc: 0.639175\n",
      "Epoch 5150 - Train Loss: 0.179738, Train Acc: 0.651282 | Val Loss: 0.189282, Val Acc: 0.639175\n",
      "Epoch 5151 - Train Loss: 0.179724, Train Acc: 0.651282 | Val Loss: 0.189269, Val Acc: 0.639175\n",
      "Epoch 5152 - Train Loss: 0.179711, Train Acc: 0.651282 | Val Loss: 0.189257, Val Acc: 0.639175\n",
      "Epoch 5153 - Train Loss: 0.179697, Train Acc: 0.651282 | Val Loss: 0.189244, Val Acc: 0.639175\n",
      "Epoch 5154 - Train Loss: 0.179683, Train Acc: 0.651282 | Val Loss: 0.189231, Val Acc: 0.639175\n",
      "Epoch 5155 - Train Loss: 0.179669, Train Acc: 0.651282 | Val Loss: 0.189219, Val Acc: 0.639175\n",
      "Epoch 5156 - Train Loss: 0.179656, Train Acc: 0.651282 | Val Loss: 0.189206, Val Acc: 0.639175\n",
      "Epoch 5157 - Train Loss: 0.179642, Train Acc: 0.651282 | Val Loss: 0.189193, Val Acc: 0.639175\n",
      "Epoch 5158 - Train Loss: 0.179628, Train Acc: 0.651282 | Val Loss: 0.189181, Val Acc: 0.639175\n",
      "Epoch 5159 - Train Loss: 0.179614, Train Acc: 0.651282 | Val Loss: 0.189168, Val Acc: 0.639175\n",
      "Epoch 5160 - Train Loss: 0.179600, Train Acc: 0.651282 | Val Loss: 0.189155, Val Acc: 0.639175\n",
      "Epoch 5161 - Train Loss: 0.179587, Train Acc: 0.651282 | Val Loss: 0.189143, Val Acc: 0.639175\n",
      "Epoch 5162 - Train Loss: 0.179573, Train Acc: 0.651282 | Val Loss: 0.189130, Val Acc: 0.639175\n",
      "Epoch 5163 - Train Loss: 0.179559, Train Acc: 0.651282 | Val Loss: 0.189117, Val Acc: 0.639175\n",
      "Epoch 5164 - Train Loss: 0.179545, Train Acc: 0.651282 | Val Loss: 0.189105, Val Acc: 0.639175\n",
      "Epoch 5165 - Train Loss: 0.179532, Train Acc: 0.651282 | Val Loss: 0.189092, Val Acc: 0.639175\n",
      "Epoch 5166 - Train Loss: 0.179518, Train Acc: 0.651282 | Val Loss: 0.189079, Val Acc: 0.639175\n",
      "Epoch 5167 - Train Loss: 0.179504, Train Acc: 0.651282 | Val Loss: 0.189067, Val Acc: 0.639175\n",
      "Epoch 5168 - Train Loss: 0.179490, Train Acc: 0.651282 | Val Loss: 0.189054, Val Acc: 0.639175\n",
      "Epoch 5169 - Train Loss: 0.179477, Train Acc: 0.651282 | Val Loss: 0.189041, Val Acc: 0.639175\n",
      "Epoch 5170 - Train Loss: 0.179463, Train Acc: 0.651282 | Val Loss: 0.189029, Val Acc: 0.639175\n",
      "Epoch 5171 - Train Loss: 0.179449, Train Acc: 0.651282 | Val Loss: 0.189016, Val Acc: 0.639175\n",
      "Epoch 5172 - Train Loss: 0.179435, Train Acc: 0.651282 | Val Loss: 0.189003, Val Acc: 0.639175\n",
      "Epoch 5173 - Train Loss: 0.179422, Train Acc: 0.651282 | Val Loss: 0.188991, Val Acc: 0.639175\n",
      "Epoch 5174 - Train Loss: 0.179408, Train Acc: 0.651282 | Val Loss: 0.188978, Val Acc: 0.639175\n",
      "Epoch 5175 - Train Loss: 0.179394, Train Acc: 0.651282 | Val Loss: 0.188965, Val Acc: 0.639175\n",
      "Epoch 5176 - Train Loss: 0.179380, Train Acc: 0.651282 | Val Loss: 0.188953, Val Acc: 0.639175\n",
      "Epoch 5177 - Train Loss: 0.179367, Train Acc: 0.651282 | Val Loss: 0.188940, Val Acc: 0.639175\n",
      "Epoch 5178 - Train Loss: 0.179353, Train Acc: 0.651282 | Val Loss: 0.188927, Val Acc: 0.639175\n",
      "Epoch 5179 - Train Loss: 0.179339, Train Acc: 0.651282 | Val Loss: 0.188915, Val Acc: 0.639175\n",
      "Epoch 5180 - Train Loss: 0.179325, Train Acc: 0.651282 | Val Loss: 0.188902, Val Acc: 0.639175\n",
      "Epoch 5181 - Train Loss: 0.179312, Train Acc: 0.651282 | Val Loss: 0.188890, Val Acc: 0.639175\n",
      "Epoch 5182 - Train Loss: 0.179298, Train Acc: 0.651282 | Val Loss: 0.188877, Val Acc: 0.639175\n",
      "Epoch 5183 - Train Loss: 0.179284, Train Acc: 0.651282 | Val Loss: 0.188864, Val Acc: 0.639175\n",
      "Epoch 5184 - Train Loss: 0.179271, Train Acc: 0.651282 | Val Loss: 0.188852, Val Acc: 0.639175\n",
      "Epoch 5185 - Train Loss: 0.179257, Train Acc: 0.651282 | Val Loss: 0.188839, Val Acc: 0.639175\n",
      "Epoch 5186 - Train Loss: 0.179243, Train Acc: 0.651282 | Val Loss: 0.188826, Val Acc: 0.639175\n",
      "Epoch 5187 - Train Loss: 0.179229, Train Acc: 0.651282 | Val Loss: 0.188814, Val Acc: 0.639175\n",
      "Epoch 5188 - Train Loss: 0.179216, Train Acc: 0.651282 | Val Loss: 0.188801, Val Acc: 0.639175\n",
      "Epoch 5189 - Train Loss: 0.179202, Train Acc: 0.651282 | Val Loss: 0.188789, Val Acc: 0.639175\n",
      "Epoch 5190 - Train Loss: 0.179188, Train Acc: 0.651282 | Val Loss: 0.188776, Val Acc: 0.639175\n",
      "Epoch 5191 - Train Loss: 0.179175, Train Acc: 0.651282 | Val Loss: 0.188763, Val Acc: 0.639175\n",
      "Epoch 5192 - Train Loss: 0.179161, Train Acc: 0.651282 | Val Loss: 0.188751, Val Acc: 0.639175\n",
      "Epoch 5193 - Train Loss: 0.179147, Train Acc: 0.651282 | Val Loss: 0.188738, Val Acc: 0.639175\n",
      "Epoch 5194 - Train Loss: 0.179133, Train Acc: 0.651282 | Val Loss: 0.188725, Val Acc: 0.639175\n",
      "Epoch 5195 - Train Loss: 0.179120, Train Acc: 0.651282 | Val Loss: 0.188713, Val Acc: 0.639175\n",
      "Epoch 5196 - Train Loss: 0.179106, Train Acc: 0.651282 | Val Loss: 0.188700, Val Acc: 0.639175\n",
      "Epoch 5197 - Train Loss: 0.179092, Train Acc: 0.651282 | Val Loss: 0.188688, Val Acc: 0.639175\n",
      "Epoch 5198 - Train Loss: 0.179079, Train Acc: 0.651282 | Val Loss: 0.188675, Val Acc: 0.639175\n",
      "Epoch 5199 - Train Loss: 0.179065, Train Acc: 0.651282 | Val Loss: 0.188662, Val Acc: 0.639175\n",
      "Epoch 5200 - Train Loss: 0.179051, Train Acc: 0.651282 | Val Loss: 0.188650, Val Acc: 0.639175\n",
      "Epoch 5201 - Train Loss: 0.179037, Train Acc: 0.651282 | Val Loss: 0.188637, Val Acc: 0.639175\n",
      "Epoch 5202 - Train Loss: 0.179024, Train Acc: 0.651282 | Val Loss: 0.188625, Val Acc: 0.639175\n",
      "Epoch 5203 - Train Loss: 0.179010, Train Acc: 0.651282 | Val Loss: 0.188612, Val Acc: 0.639175\n",
      "Epoch 5204 - Train Loss: 0.178996, Train Acc: 0.651282 | Val Loss: 0.188599, Val Acc: 0.639175\n",
      "Epoch 5205 - Train Loss: 0.178983, Train Acc: 0.651282 | Val Loss: 0.188587, Val Acc: 0.639175\n",
      "Epoch 5206 - Train Loss: 0.178969, Train Acc: 0.651282 | Val Loss: 0.188574, Val Acc: 0.639175\n",
      "Epoch 5207 - Train Loss: 0.178955, Train Acc: 0.651282 | Val Loss: 0.188562, Val Acc: 0.639175\n",
      "Epoch 5208 - Train Loss: 0.178942, Train Acc: 0.651282 | Val Loss: 0.188549, Val Acc: 0.649485\n",
      "Epoch 5209 - Train Loss: 0.178928, Train Acc: 0.651282 | Val Loss: 0.188536, Val Acc: 0.649485\n",
      "Epoch 5210 - Train Loss: 0.178914, Train Acc: 0.651282 | Val Loss: 0.188524, Val Acc: 0.649485\n",
      "Epoch 5211 - Train Loss: 0.178900, Train Acc: 0.651282 | Val Loss: 0.188511, Val Acc: 0.649485\n",
      "Epoch 5212 - Train Loss: 0.178887, Train Acc: 0.651282 | Val Loss: 0.188499, Val Acc: 0.649485\n",
      "Epoch 5213 - Train Loss: 0.178873, Train Acc: 0.651282 | Val Loss: 0.188486, Val Acc: 0.649485\n",
      "Epoch 5214 - Train Loss: 0.178859, Train Acc: 0.651282 | Val Loss: 0.188474, Val Acc: 0.649485\n",
      "Epoch 5215 - Train Loss: 0.178846, Train Acc: 0.651282 | Val Loss: 0.188461, Val Acc: 0.649485\n",
      "Epoch 5216 - Train Loss: 0.178832, Train Acc: 0.651282 | Val Loss: 0.188448, Val Acc: 0.649485\n",
      "Epoch 5217 - Train Loss: 0.178818, Train Acc: 0.651282 | Val Loss: 0.188436, Val Acc: 0.649485\n",
      "Epoch 5218 - Train Loss: 0.178805, Train Acc: 0.651282 | Val Loss: 0.188423, Val Acc: 0.649485\n",
      "Epoch 5219 - Train Loss: 0.178791, Train Acc: 0.651282 | Val Loss: 0.188411, Val Acc: 0.649485\n",
      "Epoch 5220 - Train Loss: 0.178777, Train Acc: 0.651282 | Val Loss: 0.188398, Val Acc: 0.649485\n",
      "Epoch 5221 - Train Loss: 0.178764, Train Acc: 0.651282 | Val Loss: 0.188386, Val Acc: 0.649485\n",
      "Epoch 5222 - Train Loss: 0.178750, Train Acc: 0.651282 | Val Loss: 0.188373, Val Acc: 0.649485\n",
      "Epoch 5223 - Train Loss: 0.178736, Train Acc: 0.651282 | Val Loss: 0.188360, Val Acc: 0.649485\n",
      "Epoch 5224 - Train Loss: 0.178723, Train Acc: 0.651282 | Val Loss: 0.188348, Val Acc: 0.649485\n",
      "Epoch 5225 - Train Loss: 0.178709, Train Acc: 0.651282 | Val Loss: 0.188335, Val Acc: 0.649485\n",
      "Epoch 5226 - Train Loss: 0.178695, Train Acc: 0.651282 | Val Loss: 0.188323, Val Acc: 0.649485\n",
      "Epoch 5227 - Train Loss: 0.178682, Train Acc: 0.651282 | Val Loss: 0.188310, Val Acc: 0.649485\n",
      "Epoch 5228 - Train Loss: 0.178668, Train Acc: 0.651282 | Val Loss: 0.188298, Val Acc: 0.649485\n",
      "Epoch 5229 - Train Loss: 0.178654, Train Acc: 0.651282 | Val Loss: 0.188285, Val Acc: 0.649485\n",
      "Epoch 5230 - Train Loss: 0.178641, Train Acc: 0.651282 | Val Loss: 0.188273, Val Acc: 0.649485\n",
      "Epoch 5231 - Train Loss: 0.178627, Train Acc: 0.651282 | Val Loss: 0.188260, Val Acc: 0.649485\n",
      "Epoch 5232 - Train Loss: 0.178613, Train Acc: 0.651282 | Val Loss: 0.188248, Val Acc: 0.649485\n",
      "Epoch 5233 - Train Loss: 0.178600, Train Acc: 0.651282 | Val Loss: 0.188235, Val Acc: 0.649485\n",
      "Epoch 5234 - Train Loss: 0.178586, Train Acc: 0.651282 | Val Loss: 0.188222, Val Acc: 0.649485\n",
      "Epoch 5235 - Train Loss: 0.178572, Train Acc: 0.651282 | Val Loss: 0.188210, Val Acc: 0.649485\n",
      "Epoch 5236 - Train Loss: 0.178559, Train Acc: 0.651282 | Val Loss: 0.188197, Val Acc: 0.649485\n",
      "Epoch 5237 - Train Loss: 0.178545, Train Acc: 0.651282 | Val Loss: 0.188185, Val Acc: 0.649485\n",
      "Epoch 5238 - Train Loss: 0.178531, Train Acc: 0.651282 | Val Loss: 0.188172, Val Acc: 0.649485\n",
      "Epoch 5239 - Train Loss: 0.178518, Train Acc: 0.651282 | Val Loss: 0.188160, Val Acc: 0.649485\n",
      "Epoch 5240 - Train Loss: 0.178504, Train Acc: 0.651282 | Val Loss: 0.188147, Val Acc: 0.649485\n",
      "Epoch 5241 - Train Loss: 0.178490, Train Acc: 0.651282 | Val Loss: 0.188135, Val Acc: 0.649485\n",
      "Epoch 5242 - Train Loss: 0.178477, Train Acc: 0.651282 | Val Loss: 0.188122, Val Acc: 0.649485\n",
      "Epoch 5243 - Train Loss: 0.178463, Train Acc: 0.651282 | Val Loss: 0.188110, Val Acc: 0.649485\n",
      "Epoch 5244 - Train Loss: 0.178450, Train Acc: 0.651282 | Val Loss: 0.188097, Val Acc: 0.649485\n",
      "Epoch 5245 - Train Loss: 0.178436, Train Acc: 0.651282 | Val Loss: 0.188085, Val Acc: 0.649485\n",
      "Epoch 5246 - Train Loss: 0.178422, Train Acc: 0.651282 | Val Loss: 0.188072, Val Acc: 0.649485\n",
      "Epoch 5247 - Train Loss: 0.178409, Train Acc: 0.651282 | Val Loss: 0.188060, Val Acc: 0.649485\n",
      "Epoch 5248 - Train Loss: 0.178395, Train Acc: 0.651282 | Val Loss: 0.188047, Val Acc: 0.649485\n",
      "Epoch 5249 - Train Loss: 0.178381, Train Acc: 0.651282 | Val Loss: 0.188035, Val Acc: 0.649485\n",
      "Epoch 5250 - Train Loss: 0.178368, Train Acc: 0.651282 | Val Loss: 0.188022, Val Acc: 0.649485\n",
      "Epoch 5251 - Train Loss: 0.178354, Train Acc: 0.651282 | Val Loss: 0.188009, Val Acc: 0.649485\n",
      "Epoch 5252 - Train Loss: 0.178340, Train Acc: 0.651282 | Val Loss: 0.187997, Val Acc: 0.649485\n",
      "Epoch 5253 - Train Loss: 0.178327, Train Acc: 0.651282 | Val Loss: 0.187984, Val Acc: 0.649485\n",
      "Epoch 5254 - Train Loss: 0.178313, Train Acc: 0.651282 | Val Loss: 0.187972, Val Acc: 0.649485\n",
      "Epoch 5255 - Train Loss: 0.178300, Train Acc: 0.651282 | Val Loss: 0.187959, Val Acc: 0.649485\n",
      "Epoch 5256 - Train Loss: 0.178286, Train Acc: 0.652564 | Val Loss: 0.187947, Val Acc: 0.649485\n",
      "Epoch 5257 - Train Loss: 0.178272, Train Acc: 0.652564 | Val Loss: 0.187934, Val Acc: 0.649485\n",
      "Epoch 5258 - Train Loss: 0.178259, Train Acc: 0.652564 | Val Loss: 0.187922, Val Acc: 0.649485\n",
      "Epoch 5259 - Train Loss: 0.178245, Train Acc: 0.652564 | Val Loss: 0.187909, Val Acc: 0.649485\n",
      "Epoch 5260 - Train Loss: 0.178231, Train Acc: 0.651282 | Val Loss: 0.187897, Val Acc: 0.649485\n",
      "Epoch 5261 - Train Loss: 0.178218, Train Acc: 0.651282 | Val Loss: 0.187884, Val Acc: 0.649485\n",
      "Epoch 5262 - Train Loss: 0.178204, Train Acc: 0.651282 | Val Loss: 0.187872, Val Acc: 0.649485\n",
      "Epoch 5263 - Train Loss: 0.178191, Train Acc: 0.651282 | Val Loss: 0.187859, Val Acc: 0.649485\n",
      "Epoch 5264 - Train Loss: 0.178177, Train Acc: 0.651282 | Val Loss: 0.187847, Val Acc: 0.649485\n",
      "Epoch 5265 - Train Loss: 0.178163, Train Acc: 0.651282 | Val Loss: 0.187834, Val Acc: 0.649485\n",
      "Epoch 5266 - Train Loss: 0.178150, Train Acc: 0.651282 | Val Loss: 0.187822, Val Acc: 0.649485\n",
      "Epoch 5267 - Train Loss: 0.178136, Train Acc: 0.651282 | Val Loss: 0.187810, Val Acc: 0.649485\n",
      "Epoch 5268 - Train Loss: 0.178123, Train Acc: 0.651282 | Val Loss: 0.187797, Val Acc: 0.649485\n",
      "Epoch 5269 - Train Loss: 0.178109, Train Acc: 0.651282 | Val Loss: 0.187785, Val Acc: 0.649485\n",
      "Epoch 5270 - Train Loss: 0.178095, Train Acc: 0.651282 | Val Loss: 0.187772, Val Acc: 0.649485\n",
      "Epoch 5271 - Train Loss: 0.178082, Train Acc: 0.651282 | Val Loss: 0.187760, Val Acc: 0.649485\n",
      "Epoch 5272 - Train Loss: 0.178068, Train Acc: 0.651282 | Val Loss: 0.187747, Val Acc: 0.649485\n",
      "Epoch 5273 - Train Loss: 0.178055, Train Acc: 0.651282 | Val Loss: 0.187735, Val Acc: 0.649485\n",
      "Epoch 5274 - Train Loss: 0.178041, Train Acc: 0.651282 | Val Loss: 0.187722, Val Acc: 0.649485\n",
      "Epoch 5275 - Train Loss: 0.178027, Train Acc: 0.651282 | Val Loss: 0.187710, Val Acc: 0.649485\n",
      "Epoch 5276 - Train Loss: 0.178014, Train Acc: 0.651282 | Val Loss: 0.187697, Val Acc: 0.649485\n",
      "Epoch 5277 - Train Loss: 0.178000, Train Acc: 0.651282 | Val Loss: 0.187685, Val Acc: 0.649485\n",
      "Epoch 5278 - Train Loss: 0.177987, Train Acc: 0.651282 | Val Loss: 0.187672, Val Acc: 0.649485\n",
      "Epoch 5279 - Train Loss: 0.177973, Train Acc: 0.651282 | Val Loss: 0.187660, Val Acc: 0.659794\n",
      "Epoch 5280 - Train Loss: 0.177959, Train Acc: 0.651282 | Val Loss: 0.187647, Val Acc: 0.659794\n",
      "Epoch 5281 - Train Loss: 0.177946, Train Acc: 0.651282 | Val Loss: 0.187635, Val Acc: 0.659794\n",
      "Epoch 5282 - Train Loss: 0.177932, Train Acc: 0.651282 | Val Loss: 0.187622, Val Acc: 0.659794\n",
      "Epoch 5283 - Train Loss: 0.177919, Train Acc: 0.651282 | Val Loss: 0.187610, Val Acc: 0.659794\n",
      "Epoch 5284 - Train Loss: 0.177905, Train Acc: 0.651282 | Val Loss: 0.187598, Val Acc: 0.659794\n",
      "Epoch 5285 - Train Loss: 0.177892, Train Acc: 0.651282 | Val Loss: 0.187585, Val Acc: 0.659794\n",
      "Epoch 5286 - Train Loss: 0.177878, Train Acc: 0.651282 | Val Loss: 0.187573, Val Acc: 0.659794\n",
      "Epoch 5287 - Train Loss: 0.177864, Train Acc: 0.651282 | Val Loss: 0.187560, Val Acc: 0.659794\n",
      "Epoch 5288 - Train Loss: 0.177851, Train Acc: 0.651282 | Val Loss: 0.187548, Val Acc: 0.659794\n",
      "Epoch 5289 - Train Loss: 0.177837, Train Acc: 0.651282 | Val Loss: 0.187535, Val Acc: 0.659794\n",
      "Epoch 5290 - Train Loss: 0.177824, Train Acc: 0.651282 | Val Loss: 0.187523, Val Acc: 0.659794\n",
      "Epoch 5291 - Train Loss: 0.177810, Train Acc: 0.651282 | Val Loss: 0.187510, Val Acc: 0.659794\n",
      "Epoch 5292 - Train Loss: 0.177796, Train Acc: 0.652564 | Val Loss: 0.187498, Val Acc: 0.659794\n",
      "Epoch 5293 - Train Loss: 0.177783, Train Acc: 0.652564 | Val Loss: 0.187486, Val Acc: 0.659794\n",
      "Epoch 5294 - Train Loss: 0.177769, Train Acc: 0.652564 | Val Loss: 0.187473, Val Acc: 0.659794\n",
      "Epoch 5295 - Train Loss: 0.177756, Train Acc: 0.652564 | Val Loss: 0.187461, Val Acc: 0.659794\n",
      "Epoch 5296 - Train Loss: 0.177742, Train Acc: 0.652564 | Val Loss: 0.187448, Val Acc: 0.659794\n",
      "Epoch 5297 - Train Loss: 0.177729, Train Acc: 0.652564 | Val Loss: 0.187436, Val Acc: 0.659794\n",
      "Epoch 5298 - Train Loss: 0.177715, Train Acc: 0.652564 | Val Loss: 0.187423, Val Acc: 0.659794\n",
      "Epoch 5299 - Train Loss: 0.177702, Train Acc: 0.653846 | Val Loss: 0.187411, Val Acc: 0.659794\n",
      "Epoch 5300 - Train Loss: 0.177688, Train Acc: 0.653846 | Val Loss: 0.187398, Val Acc: 0.659794\n",
      "Epoch 5301 - Train Loss: 0.177674, Train Acc: 0.653846 | Val Loss: 0.187386, Val Acc: 0.659794\n",
      "Epoch 5302 - Train Loss: 0.177661, Train Acc: 0.653846 | Val Loss: 0.187374, Val Acc: 0.659794\n",
      "Epoch 5303 - Train Loss: 0.177647, Train Acc: 0.653846 | Val Loss: 0.187361, Val Acc: 0.659794\n",
      "Epoch 5304 - Train Loss: 0.177634, Train Acc: 0.653846 | Val Loss: 0.187349, Val Acc: 0.659794\n",
      "Epoch 5305 - Train Loss: 0.177620, Train Acc: 0.653846 | Val Loss: 0.187336, Val Acc: 0.659794\n",
      "Epoch 5306 - Train Loss: 0.177607, Train Acc: 0.653846 | Val Loss: 0.187324, Val Acc: 0.659794\n",
      "Epoch 5307 - Train Loss: 0.177593, Train Acc: 0.653846 | Val Loss: 0.187312, Val Acc: 0.659794\n",
      "Epoch 5308 - Train Loss: 0.177580, Train Acc: 0.653846 | Val Loss: 0.187299, Val Acc: 0.659794\n",
      "Epoch 5309 - Train Loss: 0.177566, Train Acc: 0.653846 | Val Loss: 0.187287, Val Acc: 0.659794\n",
      "Epoch 5310 - Train Loss: 0.177552, Train Acc: 0.653846 | Val Loss: 0.187274, Val Acc: 0.659794\n",
      "Epoch 5311 - Train Loss: 0.177539, Train Acc: 0.655128 | Val Loss: 0.187262, Val Acc: 0.659794\n",
      "Epoch 5312 - Train Loss: 0.177525, Train Acc: 0.655128 | Val Loss: 0.187249, Val Acc: 0.659794\n",
      "Epoch 5313 - Train Loss: 0.177512, Train Acc: 0.656410 | Val Loss: 0.187237, Val Acc: 0.659794\n",
      "Epoch 5314 - Train Loss: 0.177498, Train Acc: 0.656410 | Val Loss: 0.187225, Val Acc: 0.659794\n",
      "Epoch 5315 - Train Loss: 0.177485, Train Acc: 0.656410 | Val Loss: 0.187212, Val Acc: 0.659794\n",
      "Epoch 5316 - Train Loss: 0.177471, Train Acc: 0.656410 | Val Loss: 0.187200, Val Acc: 0.659794\n",
      "Epoch 5317 - Train Loss: 0.177458, Train Acc: 0.656410 | Val Loss: 0.187187, Val Acc: 0.659794\n",
      "Epoch 5318 - Train Loss: 0.177444, Train Acc: 0.656410 | Val Loss: 0.187175, Val Acc: 0.659794\n",
      "Epoch 5319 - Train Loss: 0.177431, Train Acc: 0.656410 | Val Loss: 0.187163, Val Acc: 0.659794\n",
      "Epoch 5320 - Train Loss: 0.177417, Train Acc: 0.656410 | Val Loss: 0.187150, Val Acc: 0.659794\n",
      "Epoch 5321 - Train Loss: 0.177404, Train Acc: 0.656410 | Val Loss: 0.187138, Val Acc: 0.659794\n",
      "Epoch 5322 - Train Loss: 0.177390, Train Acc: 0.656410 | Val Loss: 0.187125, Val Acc: 0.659794\n",
      "Epoch 5323 - Train Loss: 0.177376, Train Acc: 0.656410 | Val Loss: 0.187113, Val Acc: 0.659794\n",
      "Epoch 5324 - Train Loss: 0.177363, Train Acc: 0.656410 | Val Loss: 0.187101, Val Acc: 0.659794\n",
      "Epoch 5325 - Train Loss: 0.177349, Train Acc: 0.656410 | Val Loss: 0.187088, Val Acc: 0.659794\n",
      "Epoch 5326 - Train Loss: 0.177336, Train Acc: 0.656410 | Val Loss: 0.187076, Val Acc: 0.659794\n",
      "Epoch 5327 - Train Loss: 0.177322, Train Acc: 0.656410 | Val Loss: 0.187064, Val Acc: 0.659794\n",
      "Epoch 5328 - Train Loss: 0.177309, Train Acc: 0.656410 | Val Loss: 0.187051, Val Acc: 0.659794\n",
      "Epoch 5329 - Train Loss: 0.177295, Train Acc: 0.656410 | Val Loss: 0.187039, Val Acc: 0.659794\n",
      "Epoch 5330 - Train Loss: 0.177282, Train Acc: 0.656410 | Val Loss: 0.187026, Val Acc: 0.659794\n",
      "Epoch 5331 - Train Loss: 0.177268, Train Acc: 0.656410 | Val Loss: 0.187014, Val Acc: 0.659794\n",
      "Epoch 5332 - Train Loss: 0.177255, Train Acc: 0.656410 | Val Loss: 0.187002, Val Acc: 0.659794\n",
      "Epoch 5333 - Train Loss: 0.177241, Train Acc: 0.656410 | Val Loss: 0.186989, Val Acc: 0.659794\n",
      "Epoch 5334 - Train Loss: 0.177228, Train Acc: 0.656410 | Val Loss: 0.186977, Val Acc: 0.659794\n",
      "Epoch 5335 - Train Loss: 0.177214, Train Acc: 0.656410 | Val Loss: 0.186965, Val Acc: 0.659794\n",
      "Epoch 5336 - Train Loss: 0.177201, Train Acc: 0.656410 | Val Loss: 0.186952, Val Acc: 0.659794\n",
      "Epoch 5337 - Train Loss: 0.177187, Train Acc: 0.657692 | Val Loss: 0.186940, Val Acc: 0.659794\n",
      "Epoch 5338 - Train Loss: 0.177174, Train Acc: 0.657692 | Val Loss: 0.186927, Val Acc: 0.659794\n",
      "Epoch 5339 - Train Loss: 0.177160, Train Acc: 0.657692 | Val Loss: 0.186915, Val Acc: 0.659794\n",
      "Epoch 5340 - Train Loss: 0.177147, Train Acc: 0.657692 | Val Loss: 0.186903, Val Acc: 0.659794\n",
      "Epoch 5341 - Train Loss: 0.177133, Train Acc: 0.657692 | Val Loss: 0.186890, Val Acc: 0.659794\n",
      "Epoch 5342 - Train Loss: 0.177120, Train Acc: 0.657692 | Val Loss: 0.186878, Val Acc: 0.659794\n",
      "Epoch 5343 - Train Loss: 0.177106, Train Acc: 0.657692 | Val Loss: 0.186866, Val Acc: 0.659794\n",
      "Epoch 5344 - Train Loss: 0.177093, Train Acc: 0.657692 | Val Loss: 0.186853, Val Acc: 0.659794\n",
      "Epoch 5345 - Train Loss: 0.177079, Train Acc: 0.657692 | Val Loss: 0.186841, Val Acc: 0.659794\n",
      "Epoch 5346 - Train Loss: 0.177066, Train Acc: 0.657692 | Val Loss: 0.186829, Val Acc: 0.659794\n",
      "Epoch 5347 - Train Loss: 0.177052, Train Acc: 0.657692 | Val Loss: 0.186816, Val Acc: 0.659794\n",
      "Epoch 5348 - Train Loss: 0.177039, Train Acc: 0.657692 | Val Loss: 0.186804, Val Acc: 0.659794\n",
      "Epoch 5349 - Train Loss: 0.177025, Train Acc: 0.657692 | Val Loss: 0.186792, Val Acc: 0.659794\n",
      "Epoch 5350 - Train Loss: 0.177012, Train Acc: 0.657692 | Val Loss: 0.186779, Val Acc: 0.659794\n",
      "Epoch 5351 - Train Loss: 0.176998, Train Acc: 0.657692 | Val Loss: 0.186767, Val Acc: 0.659794\n",
      "Epoch 5352 - Train Loss: 0.176985, Train Acc: 0.657692 | Val Loss: 0.186755, Val Acc: 0.659794\n",
      "Epoch 5353 - Train Loss: 0.176971, Train Acc: 0.657692 | Val Loss: 0.186742, Val Acc: 0.659794\n",
      "Epoch 5354 - Train Loss: 0.176958, Train Acc: 0.657692 | Val Loss: 0.186730, Val Acc: 0.659794\n",
      "Epoch 5355 - Train Loss: 0.176944, Train Acc: 0.657692 | Val Loss: 0.186718, Val Acc: 0.659794\n",
      "Epoch 5356 - Train Loss: 0.176931, Train Acc: 0.657692 | Val Loss: 0.186705, Val Acc: 0.659794\n",
      "Epoch 5357 - Train Loss: 0.176917, Train Acc: 0.657692 | Val Loss: 0.186693, Val Acc: 0.659794\n",
      "Epoch 5358 - Train Loss: 0.176904, Train Acc: 0.657692 | Val Loss: 0.186681, Val Acc: 0.659794\n",
      "Epoch 5359 - Train Loss: 0.176890, Train Acc: 0.657692 | Val Loss: 0.186668, Val Acc: 0.659794\n",
      "Epoch 5360 - Train Loss: 0.176877, Train Acc: 0.657692 | Val Loss: 0.186656, Val Acc: 0.659794\n",
      "Epoch 5361 - Train Loss: 0.176863, Train Acc: 0.657692 | Val Loss: 0.186644, Val Acc: 0.659794\n",
      "Epoch 5362 - Train Loss: 0.176850, Train Acc: 0.657692 | Val Loss: 0.186631, Val Acc: 0.659794\n",
      "Epoch 5363 - Train Loss: 0.176836, Train Acc: 0.657692 | Val Loss: 0.186619, Val Acc: 0.659794\n",
      "Epoch 5364 - Train Loss: 0.176823, Train Acc: 0.657692 | Val Loss: 0.186607, Val Acc: 0.659794\n",
      "Epoch 5365 - Train Loss: 0.176810, Train Acc: 0.657692 | Val Loss: 0.186594, Val Acc: 0.659794\n",
      "Epoch 5366 - Train Loss: 0.176796, Train Acc: 0.657692 | Val Loss: 0.186582, Val Acc: 0.659794\n",
      "Epoch 5367 - Train Loss: 0.176783, Train Acc: 0.657692 | Val Loss: 0.186570, Val Acc: 0.659794\n",
      "Epoch 5368 - Train Loss: 0.176769, Train Acc: 0.657692 | Val Loss: 0.186557, Val Acc: 0.659794\n",
      "Epoch 5369 - Train Loss: 0.176756, Train Acc: 0.657692 | Val Loss: 0.186545, Val Acc: 0.659794\n",
      "Epoch 5370 - Train Loss: 0.176742, Train Acc: 0.657692 | Val Loss: 0.186533, Val Acc: 0.659794\n",
      "Epoch 5371 - Train Loss: 0.176729, Train Acc: 0.657692 | Val Loss: 0.186520, Val Acc: 0.659794\n",
      "Epoch 5372 - Train Loss: 0.176715, Train Acc: 0.657692 | Val Loss: 0.186508, Val Acc: 0.659794\n",
      "Epoch 5373 - Train Loss: 0.176702, Train Acc: 0.657692 | Val Loss: 0.186496, Val Acc: 0.659794\n",
      "Epoch 5374 - Train Loss: 0.176688, Train Acc: 0.657692 | Val Loss: 0.186483, Val Acc: 0.659794\n",
      "Epoch 5375 - Train Loss: 0.176675, Train Acc: 0.657692 | Val Loss: 0.186471, Val Acc: 0.659794\n",
      "Epoch 5376 - Train Loss: 0.176661, Train Acc: 0.657692 | Val Loss: 0.186459, Val Acc: 0.659794\n",
      "Epoch 5377 - Train Loss: 0.176648, Train Acc: 0.657692 | Val Loss: 0.186447, Val Acc: 0.659794\n",
      "Epoch 5378 - Train Loss: 0.176635, Train Acc: 0.657692 | Val Loss: 0.186434, Val Acc: 0.659794\n",
      "Epoch 5379 - Train Loss: 0.176621, Train Acc: 0.657692 | Val Loss: 0.186422, Val Acc: 0.659794\n",
      "Epoch 5380 - Train Loss: 0.176608, Train Acc: 0.657692 | Val Loss: 0.186410, Val Acc: 0.659794\n",
      "Epoch 5381 - Train Loss: 0.176594, Train Acc: 0.657692 | Val Loss: 0.186397, Val Acc: 0.659794\n",
      "Epoch 5382 - Train Loss: 0.176581, Train Acc: 0.657692 | Val Loss: 0.186385, Val Acc: 0.659794\n",
      "Epoch 5383 - Train Loss: 0.176567, Train Acc: 0.657692 | Val Loss: 0.186373, Val Acc: 0.659794\n",
      "Epoch 5384 - Train Loss: 0.176554, Train Acc: 0.657692 | Val Loss: 0.186360, Val Acc: 0.659794\n",
      "Epoch 5385 - Train Loss: 0.176540, Train Acc: 0.657692 | Val Loss: 0.186348, Val Acc: 0.659794\n",
      "Epoch 5386 - Train Loss: 0.176527, Train Acc: 0.657692 | Val Loss: 0.186336, Val Acc: 0.659794\n",
      "Epoch 5387 - Train Loss: 0.176514, Train Acc: 0.657692 | Val Loss: 0.186323, Val Acc: 0.659794\n",
      "Epoch 5388 - Train Loss: 0.176500, Train Acc: 0.657692 | Val Loss: 0.186311, Val Acc: 0.659794\n",
      "Epoch 5389 - Train Loss: 0.176487, Train Acc: 0.657692 | Val Loss: 0.186299, Val Acc: 0.659794\n",
      "Epoch 5390 - Train Loss: 0.176473, Train Acc: 0.657692 | Val Loss: 0.186287, Val Acc: 0.659794\n",
      "Epoch 5391 - Train Loss: 0.176460, Train Acc: 0.657692 | Val Loss: 0.186274, Val Acc: 0.659794\n",
      "Epoch 5392 - Train Loss: 0.176446, Train Acc: 0.657692 | Val Loss: 0.186262, Val Acc: 0.659794\n",
      "Epoch 5393 - Train Loss: 0.176433, Train Acc: 0.657692 | Val Loss: 0.186250, Val Acc: 0.659794\n",
      "Epoch 5394 - Train Loss: 0.176420, Train Acc: 0.657692 | Val Loss: 0.186237, Val Acc: 0.659794\n",
      "Epoch 5395 - Train Loss: 0.176406, Train Acc: 0.657692 | Val Loss: 0.186225, Val Acc: 0.659794\n",
      "Epoch 5396 - Train Loss: 0.176393, Train Acc: 0.657692 | Val Loss: 0.186213, Val Acc: 0.659794\n",
      "Epoch 5397 - Train Loss: 0.176379, Train Acc: 0.657692 | Val Loss: 0.186201, Val Acc: 0.659794\n",
      "Epoch 5398 - Train Loss: 0.176366, Train Acc: 0.657692 | Val Loss: 0.186188, Val Acc: 0.659794\n",
      "Epoch 5399 - Train Loss: 0.176352, Train Acc: 0.657692 | Val Loss: 0.186176, Val Acc: 0.659794\n",
      "Epoch 5400 - Train Loss: 0.176339, Train Acc: 0.657692 | Val Loss: 0.186164, Val Acc: 0.659794\n",
      "Epoch 5401 - Train Loss: 0.176326, Train Acc: 0.657692 | Val Loss: 0.186151, Val Acc: 0.659794\n",
      "Epoch 5402 - Train Loss: 0.176312, Train Acc: 0.657692 | Val Loss: 0.186139, Val Acc: 0.659794\n",
      "Epoch 5403 - Train Loss: 0.176299, Train Acc: 0.657692 | Val Loss: 0.186127, Val Acc: 0.659794\n",
      "Epoch 5404 - Train Loss: 0.176285, Train Acc: 0.657692 | Val Loss: 0.186115, Val Acc: 0.659794\n",
      "Epoch 5405 - Train Loss: 0.176272, Train Acc: 0.657692 | Val Loss: 0.186102, Val Acc: 0.659794\n",
      "Epoch 5406 - Train Loss: 0.176259, Train Acc: 0.657692 | Val Loss: 0.186090, Val Acc: 0.659794\n",
      "Epoch 5407 - Train Loss: 0.176245, Train Acc: 0.657692 | Val Loss: 0.186078, Val Acc: 0.659794\n",
      "Epoch 5408 - Train Loss: 0.176232, Train Acc: 0.657692 | Val Loss: 0.186066, Val Acc: 0.659794\n",
      "Epoch 5409 - Train Loss: 0.176218, Train Acc: 0.657692 | Val Loss: 0.186053, Val Acc: 0.659794\n",
      "Epoch 5410 - Train Loss: 0.176205, Train Acc: 0.657692 | Val Loss: 0.186041, Val Acc: 0.659794\n",
      "Epoch 5411 - Train Loss: 0.176192, Train Acc: 0.657692 | Val Loss: 0.186029, Val Acc: 0.659794\n",
      "Epoch 5412 - Train Loss: 0.176178, Train Acc: 0.657692 | Val Loss: 0.186017, Val Acc: 0.659794\n",
      "Epoch 5413 - Train Loss: 0.176165, Train Acc: 0.657692 | Val Loss: 0.186004, Val Acc: 0.659794\n",
      "Epoch 5414 - Train Loss: 0.176151, Train Acc: 0.657692 | Val Loss: 0.185992, Val Acc: 0.659794\n",
      "Epoch 5415 - Train Loss: 0.176138, Train Acc: 0.657692 | Val Loss: 0.185980, Val Acc: 0.659794\n",
      "Epoch 5416 - Train Loss: 0.176125, Train Acc: 0.657692 | Val Loss: 0.185968, Val Acc: 0.659794\n",
      "Epoch 5417 - Train Loss: 0.176111, Train Acc: 0.657692 | Val Loss: 0.185955, Val Acc: 0.659794\n",
      "Epoch 5418 - Train Loss: 0.176098, Train Acc: 0.657692 | Val Loss: 0.185943, Val Acc: 0.659794\n",
      "Epoch 5419 - Train Loss: 0.176084, Train Acc: 0.657692 | Val Loss: 0.185931, Val Acc: 0.659794\n",
      "Epoch 5420 - Train Loss: 0.176071, Train Acc: 0.657692 | Val Loss: 0.185919, Val Acc: 0.659794\n",
      "Epoch 5421 - Train Loss: 0.176058, Train Acc: 0.657692 | Val Loss: 0.185906, Val Acc: 0.659794\n",
      "Epoch 5422 - Train Loss: 0.176044, Train Acc: 0.657692 | Val Loss: 0.185894, Val Acc: 0.659794\n",
      "Epoch 5423 - Train Loss: 0.176031, Train Acc: 0.657692 | Val Loss: 0.185882, Val Acc: 0.659794\n",
      "Epoch 5424 - Train Loss: 0.176017, Train Acc: 0.657692 | Val Loss: 0.185870, Val Acc: 0.659794\n",
      "Epoch 5425 - Train Loss: 0.176004, Train Acc: 0.657692 | Val Loss: 0.185857, Val Acc: 0.659794\n",
      "Epoch 5426 - Train Loss: 0.175991, Train Acc: 0.657692 | Val Loss: 0.185845, Val Acc: 0.659794\n",
      "Epoch 5427 - Train Loss: 0.175977, Train Acc: 0.657692 | Val Loss: 0.185833, Val Acc: 0.659794\n",
      "Epoch 5428 - Train Loss: 0.175964, Train Acc: 0.657692 | Val Loss: 0.185821, Val Acc: 0.659794\n",
      "Epoch 5429 - Train Loss: 0.175950, Train Acc: 0.657692 | Val Loss: 0.185808, Val Acc: 0.659794\n",
      "Epoch 5430 - Train Loss: 0.175937, Train Acc: 0.657692 | Val Loss: 0.185796, Val Acc: 0.659794\n",
      "Epoch 5431 - Train Loss: 0.175924, Train Acc: 0.657692 | Val Loss: 0.185784, Val Acc: 0.659794\n",
      "Epoch 5432 - Train Loss: 0.175910, Train Acc: 0.657692 | Val Loss: 0.185772, Val Acc: 0.659794\n",
      "Epoch 5433 - Train Loss: 0.175897, Train Acc: 0.657692 | Val Loss: 0.185760, Val Acc: 0.659794\n",
      "Epoch 5434 - Train Loss: 0.175884, Train Acc: 0.657692 | Val Loss: 0.185747, Val Acc: 0.659794\n",
      "Epoch 5435 - Train Loss: 0.175870, Train Acc: 0.657692 | Val Loss: 0.185735, Val Acc: 0.659794\n",
      "Epoch 5436 - Train Loss: 0.175857, Train Acc: 0.657692 | Val Loss: 0.185723, Val Acc: 0.659794\n",
      "Epoch 5437 - Train Loss: 0.175844, Train Acc: 0.657692 | Val Loss: 0.185711, Val Acc: 0.659794\n",
      "Epoch 5438 - Train Loss: 0.175830, Train Acc: 0.657692 | Val Loss: 0.185699, Val Acc: 0.659794\n",
      "Epoch 5439 - Train Loss: 0.175817, Train Acc: 0.657692 | Val Loss: 0.185686, Val Acc: 0.659794\n",
      "Epoch 5440 - Train Loss: 0.175803, Train Acc: 0.657692 | Val Loss: 0.185674, Val Acc: 0.659794\n",
      "Epoch 5441 - Train Loss: 0.175790, Train Acc: 0.657692 | Val Loss: 0.185662, Val Acc: 0.659794\n",
      "Epoch 5442 - Train Loss: 0.175777, Train Acc: 0.657692 | Val Loss: 0.185650, Val Acc: 0.659794\n",
      "Epoch 5443 - Train Loss: 0.175763, Train Acc: 0.657692 | Val Loss: 0.185638, Val Acc: 0.659794\n",
      "Epoch 5444 - Train Loss: 0.175750, Train Acc: 0.657692 | Val Loss: 0.185625, Val Acc: 0.659794\n",
      "Epoch 5445 - Train Loss: 0.175737, Train Acc: 0.657692 | Val Loss: 0.185613, Val Acc: 0.659794\n",
      "Epoch 5446 - Train Loss: 0.175723, Train Acc: 0.657692 | Val Loss: 0.185601, Val Acc: 0.659794\n",
      "Epoch 5447 - Train Loss: 0.175710, Train Acc: 0.657692 | Val Loss: 0.185589, Val Acc: 0.659794\n",
      "Epoch 5448 - Train Loss: 0.175697, Train Acc: 0.657692 | Val Loss: 0.185577, Val Acc: 0.659794\n",
      "Epoch 5449 - Train Loss: 0.175683, Train Acc: 0.657692 | Val Loss: 0.185564, Val Acc: 0.659794\n",
      "Epoch 5450 - Train Loss: 0.175670, Train Acc: 0.657692 | Val Loss: 0.185552, Val Acc: 0.659794\n",
      "Epoch 5451 - Train Loss: 0.175656, Train Acc: 0.657692 | Val Loss: 0.185540, Val Acc: 0.659794\n",
      "Epoch 5452 - Train Loss: 0.175643, Train Acc: 0.657692 | Val Loss: 0.185528, Val Acc: 0.659794\n",
      "Epoch 5453 - Train Loss: 0.175630, Train Acc: 0.657692 | Val Loss: 0.185516, Val Acc: 0.659794\n",
      "Epoch 5454 - Train Loss: 0.175616, Train Acc: 0.657692 | Val Loss: 0.185503, Val Acc: 0.659794\n",
      "Epoch 5455 - Train Loss: 0.175603, Train Acc: 0.657692 | Val Loss: 0.185491, Val Acc: 0.659794\n",
      "Epoch 5456 - Train Loss: 0.175590, Train Acc: 0.658974 | Val Loss: 0.185479, Val Acc: 0.659794\n",
      "Epoch 5457 - Train Loss: 0.175576, Train Acc: 0.658974 | Val Loss: 0.185467, Val Acc: 0.659794\n",
      "Epoch 5458 - Train Loss: 0.175563, Train Acc: 0.658974 | Val Loss: 0.185455, Val Acc: 0.659794\n",
      "Epoch 5459 - Train Loss: 0.175550, Train Acc: 0.658974 | Val Loss: 0.185442, Val Acc: 0.659794\n",
      "Epoch 5460 - Train Loss: 0.175536, Train Acc: 0.658974 | Val Loss: 0.185430, Val Acc: 0.659794\n",
      "Epoch 5461 - Train Loss: 0.175523, Train Acc: 0.658974 | Val Loss: 0.185418, Val Acc: 0.659794\n",
      "Epoch 5462 - Train Loss: 0.175510, Train Acc: 0.658974 | Val Loss: 0.185406, Val Acc: 0.659794\n",
      "Epoch 5463 - Train Loss: 0.175496, Train Acc: 0.658974 | Val Loss: 0.185394, Val Acc: 0.659794\n",
      "Epoch 5464 - Train Loss: 0.175483, Train Acc: 0.658974 | Val Loss: 0.185382, Val Acc: 0.659794\n",
      "Epoch 5465 - Train Loss: 0.175470, Train Acc: 0.658974 | Val Loss: 0.185369, Val Acc: 0.659794\n",
      "Epoch 5466 - Train Loss: 0.175456, Train Acc: 0.658974 | Val Loss: 0.185357, Val Acc: 0.659794\n",
      "Epoch 5467 - Train Loss: 0.175443, Train Acc: 0.658974 | Val Loss: 0.185345, Val Acc: 0.659794\n",
      "Epoch 5468 - Train Loss: 0.175430, Train Acc: 0.658974 | Val Loss: 0.185333, Val Acc: 0.659794\n",
      "Epoch 5469 - Train Loss: 0.175416, Train Acc: 0.658974 | Val Loss: 0.185321, Val Acc: 0.659794\n",
      "Epoch 5470 - Train Loss: 0.175403, Train Acc: 0.658974 | Val Loss: 0.185309, Val Acc: 0.659794\n",
      "Epoch 5471 - Train Loss: 0.175390, Train Acc: 0.658974 | Val Loss: 0.185296, Val Acc: 0.659794\n",
      "Epoch 5472 - Train Loss: 0.175376, Train Acc: 0.658974 | Val Loss: 0.185284, Val Acc: 0.659794\n",
      "Epoch 5473 - Train Loss: 0.175363, Train Acc: 0.658974 | Val Loss: 0.185272, Val Acc: 0.659794\n",
      "Epoch 5474 - Train Loss: 0.175350, Train Acc: 0.658974 | Val Loss: 0.185260, Val Acc: 0.659794\n",
      "Epoch 5475 - Train Loss: 0.175336, Train Acc: 0.658974 | Val Loss: 0.185248, Val Acc: 0.659794\n",
      "Epoch 5476 - Train Loss: 0.175323, Train Acc: 0.658974 | Val Loss: 0.185236, Val Acc: 0.659794\n",
      "Epoch 5477 - Train Loss: 0.175310, Train Acc: 0.658974 | Val Loss: 0.185223, Val Acc: 0.659794\n",
      "Epoch 5478 - Train Loss: 0.175297, Train Acc: 0.658974 | Val Loss: 0.185211, Val Acc: 0.659794\n",
      "Epoch 5479 - Train Loss: 0.175283, Train Acc: 0.658974 | Val Loss: 0.185199, Val Acc: 0.659794\n",
      "Epoch 5480 - Train Loss: 0.175270, Train Acc: 0.658974 | Val Loss: 0.185187, Val Acc: 0.659794\n",
      "Epoch 5481 - Train Loss: 0.175257, Train Acc: 0.658974 | Val Loss: 0.185175, Val Acc: 0.659794\n",
      "Epoch 5482 - Train Loss: 0.175243, Train Acc: 0.658974 | Val Loss: 0.185163, Val Acc: 0.659794\n",
      "Epoch 5483 - Train Loss: 0.175230, Train Acc: 0.658974 | Val Loss: 0.185150, Val Acc: 0.659794\n",
      "Epoch 5484 - Train Loss: 0.175217, Train Acc: 0.658974 | Val Loss: 0.185138, Val Acc: 0.659794\n",
      "Epoch 5485 - Train Loss: 0.175203, Train Acc: 0.658974 | Val Loss: 0.185126, Val Acc: 0.659794\n",
      "Epoch 5486 - Train Loss: 0.175190, Train Acc: 0.660256 | Val Loss: 0.185114, Val Acc: 0.659794\n",
      "Epoch 5487 - Train Loss: 0.175177, Train Acc: 0.660256 | Val Loss: 0.185102, Val Acc: 0.659794\n",
      "Epoch 5488 - Train Loss: 0.175163, Train Acc: 0.660256 | Val Loss: 0.185090, Val Acc: 0.659794\n",
      "Epoch 5489 - Train Loss: 0.175150, Train Acc: 0.660256 | Val Loss: 0.185078, Val Acc: 0.659794\n",
      "Epoch 5490 - Train Loss: 0.175137, Train Acc: 0.660256 | Val Loss: 0.185065, Val Acc: 0.659794\n",
      "Epoch 5491 - Train Loss: 0.175124, Train Acc: 0.660256 | Val Loss: 0.185053, Val Acc: 0.659794\n",
      "Epoch 5492 - Train Loss: 0.175110, Train Acc: 0.660256 | Val Loss: 0.185041, Val Acc: 0.659794\n",
      "Epoch 5493 - Train Loss: 0.175097, Train Acc: 0.660256 | Val Loss: 0.185029, Val Acc: 0.659794\n",
      "Epoch 5494 - Train Loss: 0.175084, Train Acc: 0.660256 | Val Loss: 0.185017, Val Acc: 0.659794\n",
      "Epoch 5495 - Train Loss: 0.175070, Train Acc: 0.660256 | Val Loss: 0.185005, Val Acc: 0.659794\n",
      "Epoch 5496 - Train Loss: 0.175057, Train Acc: 0.660256 | Val Loss: 0.184993, Val Acc: 0.659794\n",
      "Epoch 5497 - Train Loss: 0.175044, Train Acc: 0.660256 | Val Loss: 0.184980, Val Acc: 0.659794\n",
      "Epoch 5498 - Train Loss: 0.175031, Train Acc: 0.660256 | Val Loss: 0.184968, Val Acc: 0.659794\n",
      "Epoch 5499 - Train Loss: 0.175017, Train Acc: 0.660256 | Val Loss: 0.184956, Val Acc: 0.659794\n",
      "Epoch 5500 - Train Loss: 0.175004, Train Acc: 0.660256 | Val Loss: 0.184944, Val Acc: 0.659794\n",
      "Epoch 5501 - Train Loss: 0.174991, Train Acc: 0.660256 | Val Loss: 0.184932, Val Acc: 0.659794\n",
      "Epoch 5502 - Train Loss: 0.174977, Train Acc: 0.660256 | Val Loss: 0.184920, Val Acc: 0.659794\n",
      "Epoch 5503 - Train Loss: 0.174964, Train Acc: 0.660256 | Val Loss: 0.184908, Val Acc: 0.659794\n",
      "Epoch 5504 - Train Loss: 0.174951, Train Acc: 0.660256 | Val Loss: 0.184896, Val Acc: 0.659794\n",
      "Epoch 5505 - Train Loss: 0.174938, Train Acc: 0.660256 | Val Loss: 0.184884, Val Acc: 0.659794\n",
      "Epoch 5506 - Train Loss: 0.174924, Train Acc: 0.660256 | Val Loss: 0.184871, Val Acc: 0.659794\n",
      "Epoch 5507 - Train Loss: 0.174911, Train Acc: 0.660256 | Val Loss: 0.184859, Val Acc: 0.659794\n",
      "Epoch 5508 - Train Loss: 0.174898, Train Acc: 0.660256 | Val Loss: 0.184847, Val Acc: 0.659794\n",
      "Epoch 5509 - Train Loss: 0.174884, Train Acc: 0.660256 | Val Loss: 0.184835, Val Acc: 0.659794\n",
      "Epoch 5510 - Train Loss: 0.174871, Train Acc: 0.660256 | Val Loss: 0.184823, Val Acc: 0.659794\n",
      "Epoch 5511 - Train Loss: 0.174858, Train Acc: 0.661538 | Val Loss: 0.184811, Val Acc: 0.659794\n",
      "Epoch 5512 - Train Loss: 0.174845, Train Acc: 0.661538 | Val Loss: 0.184799, Val Acc: 0.659794\n",
      "Epoch 5513 - Train Loss: 0.174831, Train Acc: 0.661538 | Val Loss: 0.184787, Val Acc: 0.659794\n",
      "Epoch 5514 - Train Loss: 0.174818, Train Acc: 0.661538 | Val Loss: 0.184775, Val Acc: 0.659794\n",
      "Epoch 5515 - Train Loss: 0.174805, Train Acc: 0.661538 | Val Loss: 0.184762, Val Acc: 0.659794\n",
      "Epoch 5516 - Train Loss: 0.174792, Train Acc: 0.661538 | Val Loss: 0.184750, Val Acc: 0.659794\n",
      "Epoch 5517 - Train Loss: 0.174778, Train Acc: 0.661538 | Val Loss: 0.184738, Val Acc: 0.659794\n",
      "Epoch 5518 - Train Loss: 0.174765, Train Acc: 0.661538 | Val Loss: 0.184726, Val Acc: 0.659794\n",
      "Epoch 5519 - Train Loss: 0.174752, Train Acc: 0.661538 | Val Loss: 0.184714, Val Acc: 0.659794\n",
      "Epoch 5520 - Train Loss: 0.174739, Train Acc: 0.661538 | Val Loss: 0.184702, Val Acc: 0.659794\n",
      "Epoch 5521 - Train Loss: 0.174725, Train Acc: 0.661538 | Val Loss: 0.184690, Val Acc: 0.659794\n",
      "Epoch 5522 - Train Loss: 0.174712, Train Acc: 0.661538 | Val Loss: 0.184678, Val Acc: 0.659794\n",
      "Epoch 5523 - Train Loss: 0.174699, Train Acc: 0.661538 | Val Loss: 0.184666, Val Acc: 0.659794\n",
      "Epoch 5524 - Train Loss: 0.174686, Train Acc: 0.661538 | Val Loss: 0.184654, Val Acc: 0.659794\n",
      "Epoch 5525 - Train Loss: 0.174672, Train Acc: 0.661538 | Val Loss: 0.184642, Val Acc: 0.659794\n",
      "Epoch 5526 - Train Loss: 0.174659, Train Acc: 0.661538 | Val Loss: 0.184630, Val Acc: 0.659794\n",
      "Epoch 5527 - Train Loss: 0.174646, Train Acc: 0.661538 | Val Loss: 0.184617, Val Acc: 0.659794\n",
      "Epoch 5528 - Train Loss: 0.174633, Train Acc: 0.662821 | Val Loss: 0.184605, Val Acc: 0.659794\n",
      "Epoch 5529 - Train Loss: 0.174619, Train Acc: 0.662821 | Val Loss: 0.184593, Val Acc: 0.659794\n",
      "Epoch 5530 - Train Loss: 0.174606, Train Acc: 0.662821 | Val Loss: 0.184581, Val Acc: 0.659794\n",
      "Epoch 5531 - Train Loss: 0.174593, Train Acc: 0.662821 | Val Loss: 0.184569, Val Acc: 0.659794\n",
      "Epoch 5532 - Train Loss: 0.174580, Train Acc: 0.662821 | Val Loss: 0.184557, Val Acc: 0.659794\n",
      "Epoch 5533 - Train Loss: 0.174566, Train Acc: 0.662821 | Val Loss: 0.184545, Val Acc: 0.659794\n",
      "Epoch 5534 - Train Loss: 0.174553, Train Acc: 0.662821 | Val Loss: 0.184533, Val Acc: 0.659794\n",
      "Epoch 5535 - Train Loss: 0.174540, Train Acc: 0.662821 | Val Loss: 0.184521, Val Acc: 0.659794\n",
      "Epoch 5536 - Train Loss: 0.174527, Train Acc: 0.662821 | Val Loss: 0.184509, Val Acc: 0.659794\n",
      "Epoch 5537 - Train Loss: 0.174513, Train Acc: 0.662821 | Val Loss: 0.184497, Val Acc: 0.659794\n",
      "Epoch 5538 - Train Loss: 0.174500, Train Acc: 0.662821 | Val Loss: 0.184485, Val Acc: 0.659794\n",
      "Epoch 5539 - Train Loss: 0.174487, Train Acc: 0.662821 | Val Loss: 0.184473, Val Acc: 0.659794\n",
      "Epoch 5540 - Train Loss: 0.174474, Train Acc: 0.662821 | Val Loss: 0.184461, Val Acc: 0.659794\n",
      "Epoch 5541 - Train Loss: 0.174460, Train Acc: 0.662821 | Val Loss: 0.184449, Val Acc: 0.659794\n",
      "Epoch 5542 - Train Loss: 0.174447, Train Acc: 0.662821 | Val Loss: 0.184436, Val Acc: 0.659794\n",
      "Epoch 5543 - Train Loss: 0.174434, Train Acc: 0.662821 | Val Loss: 0.184424, Val Acc: 0.659794\n",
      "Epoch 5544 - Train Loss: 0.174421, Train Acc: 0.661538 | Val Loss: 0.184412, Val Acc: 0.659794\n",
      "Epoch 5545 - Train Loss: 0.174408, Train Acc: 0.661538 | Val Loss: 0.184400, Val Acc: 0.659794\n",
      "Epoch 5546 - Train Loss: 0.174394, Train Acc: 0.661538 | Val Loss: 0.184388, Val Acc: 0.659794\n",
      "Epoch 5547 - Train Loss: 0.174381, Train Acc: 0.661538 | Val Loss: 0.184376, Val Acc: 0.659794\n",
      "Epoch 5548 - Train Loss: 0.174368, Train Acc: 0.661538 | Val Loss: 0.184364, Val Acc: 0.659794\n",
      "Epoch 5549 - Train Loss: 0.174355, Train Acc: 0.661538 | Val Loss: 0.184352, Val Acc: 0.659794\n",
      "Epoch 5550 - Train Loss: 0.174341, Train Acc: 0.661538 | Val Loss: 0.184340, Val Acc: 0.659794\n",
      "Epoch 5551 - Train Loss: 0.174328, Train Acc: 0.661538 | Val Loss: 0.184328, Val Acc: 0.659794\n",
      "Epoch 5552 - Train Loss: 0.174315, Train Acc: 0.661538 | Val Loss: 0.184316, Val Acc: 0.659794\n",
      "Epoch 5553 - Train Loss: 0.174302, Train Acc: 0.661538 | Val Loss: 0.184304, Val Acc: 0.659794\n",
      "Epoch 5554 - Train Loss: 0.174289, Train Acc: 0.661538 | Val Loss: 0.184292, Val Acc: 0.659794\n",
      "Epoch 5555 - Train Loss: 0.174275, Train Acc: 0.661538 | Val Loss: 0.184280, Val Acc: 0.659794\n",
      "Epoch 5556 - Train Loss: 0.174262, Train Acc: 0.661538 | Val Loss: 0.184268, Val Acc: 0.659794\n",
      "Epoch 5557 - Train Loss: 0.174249, Train Acc: 0.661538 | Val Loss: 0.184256, Val Acc: 0.659794\n",
      "Epoch 5558 - Train Loss: 0.174236, Train Acc: 0.661538 | Val Loss: 0.184244, Val Acc: 0.659794\n",
      "Epoch 5559 - Train Loss: 0.174222, Train Acc: 0.661538 | Val Loss: 0.184232, Val Acc: 0.659794\n",
      "Epoch 5560 - Train Loss: 0.174209, Train Acc: 0.661538 | Val Loss: 0.184220, Val Acc: 0.659794\n",
      "Epoch 5561 - Train Loss: 0.174196, Train Acc: 0.661538 | Val Loss: 0.184208, Val Acc: 0.659794\n",
      "Epoch 5562 - Train Loss: 0.174183, Train Acc: 0.661538 | Val Loss: 0.184196, Val Acc: 0.659794\n",
      "Epoch 5563 - Train Loss: 0.174170, Train Acc: 0.661538 | Val Loss: 0.184184, Val Acc: 0.659794\n",
      "Epoch 5564 - Train Loss: 0.174156, Train Acc: 0.661538 | Val Loss: 0.184172, Val Acc: 0.659794\n",
      "Epoch 5565 - Train Loss: 0.174143, Train Acc: 0.661538 | Val Loss: 0.184160, Val Acc: 0.659794\n",
      "Epoch 5566 - Train Loss: 0.174130, Train Acc: 0.661538 | Val Loss: 0.184148, Val Acc: 0.659794\n",
      "Epoch 5567 - Train Loss: 0.174117, Train Acc: 0.661538 | Val Loss: 0.184136, Val Acc: 0.659794\n",
      "Epoch 5568 - Train Loss: 0.174104, Train Acc: 0.661538 | Val Loss: 0.184124, Val Acc: 0.659794\n",
      "Epoch 5569 - Train Loss: 0.174090, Train Acc: 0.661538 | Val Loss: 0.184112, Val Acc: 0.659794\n",
      "Epoch 5570 - Train Loss: 0.174077, Train Acc: 0.661538 | Val Loss: 0.184100, Val Acc: 0.659794\n",
      "Epoch 5571 - Train Loss: 0.174064, Train Acc: 0.661538 | Val Loss: 0.184088, Val Acc: 0.659794\n",
      "Epoch 5572 - Train Loss: 0.174051, Train Acc: 0.661538 | Val Loss: 0.184076, Val Acc: 0.659794\n",
      "Epoch 5573 - Train Loss: 0.174038, Train Acc: 0.661538 | Val Loss: 0.184064, Val Acc: 0.659794\n",
      "Epoch 5574 - Train Loss: 0.174025, Train Acc: 0.661538 | Val Loss: 0.184052, Val Acc: 0.659794\n",
      "Epoch 5575 - Train Loss: 0.174011, Train Acc: 0.661538 | Val Loss: 0.184040, Val Acc: 0.659794\n",
      "Epoch 5576 - Train Loss: 0.173998, Train Acc: 0.661538 | Val Loss: 0.184028, Val Acc: 0.659794\n",
      "Epoch 5577 - Train Loss: 0.173985, Train Acc: 0.661538 | Val Loss: 0.184016, Val Acc: 0.659794\n",
      "Epoch 5578 - Train Loss: 0.173972, Train Acc: 0.661538 | Val Loss: 0.184004, Val Acc: 0.659794\n",
      "Epoch 5579 - Train Loss: 0.173959, Train Acc: 0.661538 | Val Loss: 0.183992, Val Acc: 0.659794\n",
      "Epoch 5580 - Train Loss: 0.173945, Train Acc: 0.661538 | Val Loss: 0.183980, Val Acc: 0.659794\n",
      "Epoch 5581 - Train Loss: 0.173932, Train Acc: 0.661538 | Val Loss: 0.183968, Val Acc: 0.659794\n",
      "Epoch 5582 - Train Loss: 0.173919, Train Acc: 0.661538 | Val Loss: 0.183956, Val Acc: 0.659794\n",
      "Epoch 5583 - Train Loss: 0.173906, Train Acc: 0.661538 | Val Loss: 0.183944, Val Acc: 0.659794\n",
      "Epoch 5584 - Train Loss: 0.173893, Train Acc: 0.661538 | Val Loss: 0.183932, Val Acc: 0.659794\n",
      "Epoch 5585 - Train Loss: 0.173880, Train Acc: 0.662821 | Val Loss: 0.183920, Val Acc: 0.659794\n",
      "Epoch 5586 - Train Loss: 0.173866, Train Acc: 0.662821 | Val Loss: 0.183908, Val Acc: 0.659794\n",
      "Epoch 5587 - Train Loss: 0.173853, Train Acc: 0.662821 | Val Loss: 0.183896, Val Acc: 0.659794\n",
      "Epoch 5588 - Train Loss: 0.173840, Train Acc: 0.662821 | Val Loss: 0.183884, Val Acc: 0.659794\n",
      "Epoch 5589 - Train Loss: 0.173827, Train Acc: 0.662821 | Val Loss: 0.183872, Val Acc: 0.659794\n",
      "Epoch 5590 - Train Loss: 0.173814, Train Acc: 0.662821 | Val Loss: 0.183860, Val Acc: 0.659794\n",
      "Epoch 5591 - Train Loss: 0.173800, Train Acc: 0.662821 | Val Loss: 0.183848, Val Acc: 0.659794\n",
      "Epoch 5592 - Train Loss: 0.173787, Train Acc: 0.662821 | Val Loss: 0.183836, Val Acc: 0.659794\n",
      "Epoch 5593 - Train Loss: 0.173774, Train Acc: 0.662821 | Val Loss: 0.183824, Val Acc: 0.659794\n",
      "Epoch 5594 - Train Loss: 0.173761, Train Acc: 0.662821 | Val Loss: 0.183812, Val Acc: 0.659794\n",
      "Epoch 5595 - Train Loss: 0.173748, Train Acc: 0.662821 | Val Loss: 0.183800, Val Acc: 0.659794\n",
      "Epoch 5596 - Train Loss: 0.173735, Train Acc: 0.662821 | Val Loss: 0.183788, Val Acc: 0.659794\n",
      "Epoch 5597 - Train Loss: 0.173722, Train Acc: 0.662821 | Val Loss: 0.183776, Val Acc: 0.659794\n",
      "Epoch 5598 - Train Loss: 0.173708, Train Acc: 0.662821 | Val Loss: 0.183764, Val Acc: 0.659794\n",
      "Epoch 5599 - Train Loss: 0.173695, Train Acc: 0.662821 | Val Loss: 0.183752, Val Acc: 0.659794\n",
      "Epoch 5600 - Train Loss: 0.173682, Train Acc: 0.662821 | Val Loss: 0.183740, Val Acc: 0.659794\n",
      "Epoch 5601 - Train Loss: 0.173669, Train Acc: 0.662821 | Val Loss: 0.183728, Val Acc: 0.659794\n",
      "Epoch 5602 - Train Loss: 0.173656, Train Acc: 0.662821 | Val Loss: 0.183716, Val Acc: 0.659794\n",
      "Epoch 5603 - Train Loss: 0.173643, Train Acc: 0.662821 | Val Loss: 0.183704, Val Acc: 0.659794\n",
      "Epoch 5604 - Train Loss: 0.173629, Train Acc: 0.662821 | Val Loss: 0.183692, Val Acc: 0.659794\n",
      "Epoch 5605 - Train Loss: 0.173616, Train Acc: 0.662821 | Val Loss: 0.183680, Val Acc: 0.659794\n",
      "Epoch 5606 - Train Loss: 0.173603, Train Acc: 0.662821 | Val Loss: 0.183668, Val Acc: 0.659794\n",
      "Epoch 5607 - Train Loss: 0.173590, Train Acc: 0.662821 | Val Loss: 0.183656, Val Acc: 0.659794\n",
      "Epoch 5608 - Train Loss: 0.173577, Train Acc: 0.662821 | Val Loss: 0.183645, Val Acc: 0.659794\n",
      "Epoch 5609 - Train Loss: 0.173564, Train Acc: 0.662821 | Val Loss: 0.183633, Val Acc: 0.659794\n",
      "Epoch 5610 - Train Loss: 0.173551, Train Acc: 0.662821 | Val Loss: 0.183621, Val Acc: 0.659794\n",
      "Epoch 5611 - Train Loss: 0.173537, Train Acc: 0.662821 | Val Loss: 0.183609, Val Acc: 0.659794\n",
      "Epoch 5612 - Train Loss: 0.173524, Train Acc: 0.662821 | Val Loss: 0.183597, Val Acc: 0.659794\n",
      "Epoch 5613 - Train Loss: 0.173511, Train Acc: 0.662821 | Val Loss: 0.183585, Val Acc: 0.659794\n",
      "Epoch 5614 - Train Loss: 0.173498, Train Acc: 0.662821 | Val Loss: 0.183573, Val Acc: 0.659794\n",
      "Epoch 5615 - Train Loss: 0.173485, Train Acc: 0.662821 | Val Loss: 0.183561, Val Acc: 0.659794\n",
      "Epoch 5616 - Train Loss: 0.173472, Train Acc: 0.662821 | Val Loss: 0.183549, Val Acc: 0.659794\n",
      "Epoch 5617 - Train Loss: 0.173459, Train Acc: 0.662821 | Val Loss: 0.183537, Val Acc: 0.659794\n",
      "Epoch 5618 - Train Loss: 0.173445, Train Acc: 0.662821 | Val Loss: 0.183525, Val Acc: 0.659794\n",
      "Epoch 5619 - Train Loss: 0.173432, Train Acc: 0.664103 | Val Loss: 0.183513, Val Acc: 0.659794\n",
      "Epoch 5620 - Train Loss: 0.173419, Train Acc: 0.664103 | Val Loss: 0.183501, Val Acc: 0.659794\n",
      "Epoch 5621 - Train Loss: 0.173406, Train Acc: 0.664103 | Val Loss: 0.183489, Val Acc: 0.659794\n",
      "Epoch 5622 - Train Loss: 0.173393, Train Acc: 0.664103 | Val Loss: 0.183477, Val Acc: 0.659794\n",
      "Epoch 5623 - Train Loss: 0.173380, Train Acc: 0.664103 | Val Loss: 0.183465, Val Acc: 0.659794\n",
      "Epoch 5624 - Train Loss: 0.173367, Train Acc: 0.664103 | Val Loss: 0.183454, Val Acc: 0.659794\n",
      "Epoch 5625 - Train Loss: 0.173354, Train Acc: 0.664103 | Val Loss: 0.183442, Val Acc: 0.659794\n",
      "Epoch 5626 - Train Loss: 0.173340, Train Acc: 0.664103 | Val Loss: 0.183430, Val Acc: 0.659794\n",
      "Epoch 5627 - Train Loss: 0.173327, Train Acc: 0.664103 | Val Loss: 0.183418, Val Acc: 0.659794\n",
      "Epoch 5628 - Train Loss: 0.173314, Train Acc: 0.664103 | Val Loss: 0.183406, Val Acc: 0.659794\n",
      "Epoch 5629 - Train Loss: 0.173301, Train Acc: 0.664103 | Val Loss: 0.183394, Val Acc: 0.659794\n",
      "Epoch 5630 - Train Loss: 0.173288, Train Acc: 0.664103 | Val Loss: 0.183382, Val Acc: 0.659794\n",
      "Epoch 5631 - Train Loss: 0.173275, Train Acc: 0.664103 | Val Loss: 0.183370, Val Acc: 0.659794\n",
      "Epoch 5632 - Train Loss: 0.173262, Train Acc: 0.664103 | Val Loss: 0.183358, Val Acc: 0.659794\n",
      "Epoch 5633 - Train Loss: 0.173249, Train Acc: 0.664103 | Val Loss: 0.183346, Val Acc: 0.659794\n",
      "Epoch 5634 - Train Loss: 0.173235, Train Acc: 0.664103 | Val Loss: 0.183334, Val Acc: 0.659794\n",
      "Epoch 5635 - Train Loss: 0.173222, Train Acc: 0.664103 | Val Loss: 0.183323, Val Acc: 0.659794\n",
      "Epoch 5636 - Train Loss: 0.173209, Train Acc: 0.664103 | Val Loss: 0.183311, Val Acc: 0.659794\n",
      "Epoch 5637 - Train Loss: 0.173196, Train Acc: 0.664103 | Val Loss: 0.183299, Val Acc: 0.659794\n",
      "Epoch 5638 - Train Loss: 0.173183, Train Acc: 0.664103 | Val Loss: 0.183287, Val Acc: 0.659794\n",
      "Epoch 5639 - Train Loss: 0.173170, Train Acc: 0.664103 | Val Loss: 0.183275, Val Acc: 0.659794\n",
      "Epoch 5640 - Train Loss: 0.173157, Train Acc: 0.664103 | Val Loss: 0.183263, Val Acc: 0.659794\n",
      "Epoch 5641 - Train Loss: 0.173144, Train Acc: 0.664103 | Val Loss: 0.183251, Val Acc: 0.659794\n",
      "Epoch 5642 - Train Loss: 0.173131, Train Acc: 0.664103 | Val Loss: 0.183239, Val Acc: 0.659794\n",
      "Epoch 5643 - Train Loss: 0.173118, Train Acc: 0.664103 | Val Loss: 0.183227, Val Acc: 0.659794\n",
      "Epoch 5644 - Train Loss: 0.173104, Train Acc: 0.664103 | Val Loss: 0.183215, Val Acc: 0.659794\n",
      "Epoch 5645 - Train Loss: 0.173091, Train Acc: 0.664103 | Val Loss: 0.183204, Val Acc: 0.659794\n",
      "Epoch 5646 - Train Loss: 0.173078, Train Acc: 0.664103 | Val Loss: 0.183192, Val Acc: 0.659794\n",
      "Epoch 5647 - Train Loss: 0.173065, Train Acc: 0.664103 | Val Loss: 0.183180, Val Acc: 0.659794\n",
      "Epoch 5648 - Train Loss: 0.173052, Train Acc: 0.664103 | Val Loss: 0.183168, Val Acc: 0.659794\n",
      "Epoch 5649 - Train Loss: 0.173039, Train Acc: 0.664103 | Val Loss: 0.183156, Val Acc: 0.659794\n",
      "Epoch 5650 - Train Loss: 0.173026, Train Acc: 0.664103 | Val Loss: 0.183144, Val Acc: 0.659794\n",
      "Epoch 5651 - Train Loss: 0.173013, Train Acc: 0.664103 | Val Loss: 0.183132, Val Acc: 0.659794\n",
      "Epoch 5652 - Train Loss: 0.173000, Train Acc: 0.664103 | Val Loss: 0.183120, Val Acc: 0.659794\n",
      "Epoch 5653 - Train Loss: 0.172987, Train Acc: 0.664103 | Val Loss: 0.183108, Val Acc: 0.659794\n",
      "Epoch 5654 - Train Loss: 0.172973, Train Acc: 0.664103 | Val Loss: 0.183097, Val Acc: 0.659794\n",
      "Epoch 5655 - Train Loss: 0.172960, Train Acc: 0.664103 | Val Loss: 0.183085, Val Acc: 0.659794\n",
      "Epoch 5656 - Train Loss: 0.172947, Train Acc: 0.664103 | Val Loss: 0.183073, Val Acc: 0.659794\n",
      "Epoch 5657 - Train Loss: 0.172934, Train Acc: 0.664103 | Val Loss: 0.183061, Val Acc: 0.659794\n",
      "Epoch 5658 - Train Loss: 0.172921, Train Acc: 0.664103 | Val Loss: 0.183049, Val Acc: 0.659794\n",
      "Epoch 5659 - Train Loss: 0.172908, Train Acc: 0.664103 | Val Loss: 0.183037, Val Acc: 0.659794\n",
      "Epoch 5660 - Train Loss: 0.172895, Train Acc: 0.664103 | Val Loss: 0.183025, Val Acc: 0.659794\n",
      "Epoch 5661 - Train Loss: 0.172882, Train Acc: 0.664103 | Val Loss: 0.183014, Val Acc: 0.659794\n",
      "Epoch 5662 - Train Loss: 0.172869, Train Acc: 0.664103 | Val Loss: 0.183002, Val Acc: 0.659794\n",
      "Epoch 5663 - Train Loss: 0.172856, Train Acc: 0.664103 | Val Loss: 0.182990, Val Acc: 0.659794\n",
      "Epoch 5664 - Train Loss: 0.172843, Train Acc: 0.664103 | Val Loss: 0.182978, Val Acc: 0.659794\n",
      "Epoch 5665 - Train Loss: 0.172830, Train Acc: 0.664103 | Val Loss: 0.182966, Val Acc: 0.659794\n",
      "Epoch 5666 - Train Loss: 0.172817, Train Acc: 0.664103 | Val Loss: 0.182954, Val Acc: 0.659794\n",
      "Epoch 5667 - Train Loss: 0.172803, Train Acc: 0.664103 | Val Loss: 0.182942, Val Acc: 0.659794\n",
      "Epoch 5668 - Train Loss: 0.172790, Train Acc: 0.664103 | Val Loss: 0.182930, Val Acc: 0.659794\n",
      "Epoch 5669 - Train Loss: 0.172777, Train Acc: 0.664103 | Val Loss: 0.182919, Val Acc: 0.659794\n",
      "Epoch 5670 - Train Loss: 0.172764, Train Acc: 0.664103 | Val Loss: 0.182907, Val Acc: 0.659794\n",
      "Epoch 5671 - Train Loss: 0.172751, Train Acc: 0.665385 | Val Loss: 0.182895, Val Acc: 0.659794\n",
      "Epoch 5672 - Train Loss: 0.172738, Train Acc: 0.665385 | Val Loss: 0.182883, Val Acc: 0.659794\n",
      "Epoch 5673 - Train Loss: 0.172725, Train Acc: 0.665385 | Val Loss: 0.182871, Val Acc: 0.659794\n",
      "Epoch 5674 - Train Loss: 0.172712, Train Acc: 0.665385 | Val Loss: 0.182859, Val Acc: 0.659794\n",
      "Epoch 5675 - Train Loss: 0.172699, Train Acc: 0.665385 | Val Loss: 0.182848, Val Acc: 0.659794\n",
      "Epoch 5676 - Train Loss: 0.172686, Train Acc: 0.665385 | Val Loss: 0.182836, Val Acc: 0.659794\n",
      "Epoch 5677 - Train Loss: 0.172673, Train Acc: 0.665385 | Val Loss: 0.182824, Val Acc: 0.659794\n",
      "Epoch 5678 - Train Loss: 0.172660, Train Acc: 0.665385 | Val Loss: 0.182812, Val Acc: 0.659794\n",
      "Epoch 5679 - Train Loss: 0.172647, Train Acc: 0.665385 | Val Loss: 0.182800, Val Acc: 0.659794\n",
      "Epoch 5680 - Train Loss: 0.172634, Train Acc: 0.665385 | Val Loss: 0.182788, Val Acc: 0.659794\n",
      "Epoch 5681 - Train Loss: 0.172621, Train Acc: 0.665385 | Val Loss: 0.182777, Val Acc: 0.659794\n",
      "Epoch 5682 - Train Loss: 0.172607, Train Acc: 0.665385 | Val Loss: 0.182765, Val Acc: 0.659794\n",
      "Epoch 5683 - Train Loss: 0.172594, Train Acc: 0.665385 | Val Loss: 0.182753, Val Acc: 0.659794\n",
      "Epoch 5684 - Train Loss: 0.172581, Train Acc: 0.665385 | Val Loss: 0.182741, Val Acc: 0.659794\n",
      "Epoch 5685 - Train Loss: 0.172568, Train Acc: 0.665385 | Val Loss: 0.182729, Val Acc: 0.659794\n",
      "Epoch 5686 - Train Loss: 0.172555, Train Acc: 0.665385 | Val Loss: 0.182717, Val Acc: 0.659794\n",
      "Epoch 5687 - Train Loss: 0.172542, Train Acc: 0.665385 | Val Loss: 0.182706, Val Acc: 0.659794\n",
      "Epoch 5688 - Train Loss: 0.172529, Train Acc: 0.665385 | Val Loss: 0.182694, Val Acc: 0.659794\n",
      "Epoch 5689 - Train Loss: 0.172516, Train Acc: 0.665385 | Val Loss: 0.182682, Val Acc: 0.659794\n",
      "Epoch 5690 - Train Loss: 0.172503, Train Acc: 0.665385 | Val Loss: 0.182670, Val Acc: 0.659794\n",
      "Epoch 5691 - Train Loss: 0.172490, Train Acc: 0.665385 | Val Loss: 0.182658, Val Acc: 0.659794\n",
      "Epoch 5692 - Train Loss: 0.172477, Train Acc: 0.665385 | Val Loss: 0.182646, Val Acc: 0.659794\n",
      "Epoch 5693 - Train Loss: 0.172464, Train Acc: 0.665385 | Val Loss: 0.182635, Val Acc: 0.659794\n",
      "Epoch 5694 - Train Loss: 0.172451, Train Acc: 0.665385 | Val Loss: 0.182623, Val Acc: 0.659794\n",
      "Epoch 5695 - Train Loss: 0.172438, Train Acc: 0.665385 | Val Loss: 0.182611, Val Acc: 0.659794\n",
      "Epoch 5696 - Train Loss: 0.172425, Train Acc: 0.665385 | Val Loss: 0.182599, Val Acc: 0.659794\n",
      "Epoch 5697 - Train Loss: 0.172412, Train Acc: 0.665385 | Val Loss: 0.182587, Val Acc: 0.659794\n",
      "Epoch 5698 - Train Loss: 0.172399, Train Acc: 0.665385 | Val Loss: 0.182576, Val Acc: 0.659794\n",
      "Epoch 5699 - Train Loss: 0.172386, Train Acc: 0.665385 | Val Loss: 0.182564, Val Acc: 0.659794\n",
      "Epoch 5700 - Train Loss: 0.172373, Train Acc: 0.665385 | Val Loss: 0.182552, Val Acc: 0.659794\n",
      "Epoch 5701 - Train Loss: 0.172360, Train Acc: 0.665385 | Val Loss: 0.182540, Val Acc: 0.659794\n",
      "Epoch 5702 - Train Loss: 0.172347, Train Acc: 0.665385 | Val Loss: 0.182528, Val Acc: 0.659794\n",
      "Epoch 5703 - Train Loss: 0.172334, Train Acc: 0.665385 | Val Loss: 0.182517, Val Acc: 0.659794\n",
      "Epoch 5704 - Train Loss: 0.172321, Train Acc: 0.665385 | Val Loss: 0.182505, Val Acc: 0.659794\n",
      "Epoch 5705 - Train Loss: 0.172308, Train Acc: 0.665385 | Val Loss: 0.182493, Val Acc: 0.659794\n",
      "Epoch 5706 - Train Loss: 0.172295, Train Acc: 0.665385 | Val Loss: 0.182481, Val Acc: 0.659794\n",
      "Epoch 5707 - Train Loss: 0.172282, Train Acc: 0.665385 | Val Loss: 0.182469, Val Acc: 0.659794\n",
      "Epoch 5708 - Train Loss: 0.172269, Train Acc: 0.665385 | Val Loss: 0.182458, Val Acc: 0.659794\n",
      "Epoch 5709 - Train Loss: 0.172256, Train Acc: 0.665385 | Val Loss: 0.182446, Val Acc: 0.659794\n",
      "Epoch 5710 - Train Loss: 0.172242, Train Acc: 0.665385 | Val Loss: 0.182434, Val Acc: 0.659794\n",
      "Epoch 5711 - Train Loss: 0.172229, Train Acc: 0.665385 | Val Loss: 0.182422, Val Acc: 0.659794\n",
      "Epoch 5712 - Train Loss: 0.172216, Train Acc: 0.665385 | Val Loss: 0.182410, Val Acc: 0.659794\n",
      "Epoch 5713 - Train Loss: 0.172203, Train Acc: 0.665385 | Val Loss: 0.182399, Val Acc: 0.659794\n",
      "Epoch 5714 - Train Loss: 0.172190, Train Acc: 0.665385 | Val Loss: 0.182387, Val Acc: 0.659794\n",
      "Epoch 5715 - Train Loss: 0.172177, Train Acc: 0.665385 | Val Loss: 0.182375, Val Acc: 0.659794\n",
      "Epoch 5716 - Train Loss: 0.172164, Train Acc: 0.665385 | Val Loss: 0.182363, Val Acc: 0.659794\n",
      "Epoch 5717 - Train Loss: 0.172151, Train Acc: 0.665385 | Val Loss: 0.182351, Val Acc: 0.659794\n",
      "Epoch 5718 - Train Loss: 0.172138, Train Acc: 0.665385 | Val Loss: 0.182340, Val Acc: 0.659794\n",
      "Epoch 5719 - Train Loss: 0.172125, Train Acc: 0.665385 | Val Loss: 0.182328, Val Acc: 0.659794\n",
      "Epoch 5720 - Train Loss: 0.172112, Train Acc: 0.665385 | Val Loss: 0.182316, Val Acc: 0.659794\n",
      "Epoch 5721 - Train Loss: 0.172099, Train Acc: 0.665385 | Val Loss: 0.182304, Val Acc: 0.659794\n",
      "Epoch 5722 - Train Loss: 0.172086, Train Acc: 0.665385 | Val Loss: 0.182293, Val Acc: 0.659794\n",
      "Epoch 5723 - Train Loss: 0.172073, Train Acc: 0.665385 | Val Loss: 0.182281, Val Acc: 0.659794\n",
      "Epoch 5724 - Train Loss: 0.172060, Train Acc: 0.665385 | Val Loss: 0.182269, Val Acc: 0.659794\n",
      "Epoch 5725 - Train Loss: 0.172047, Train Acc: 0.665385 | Val Loss: 0.182257, Val Acc: 0.659794\n",
      "Epoch 5726 - Train Loss: 0.172034, Train Acc: 0.665385 | Val Loss: 0.182245, Val Acc: 0.659794\n",
      "Epoch 5727 - Train Loss: 0.172021, Train Acc: 0.665385 | Val Loss: 0.182234, Val Acc: 0.659794\n",
      "Epoch 5728 - Train Loss: 0.172008, Train Acc: 0.665385 | Val Loss: 0.182222, Val Acc: 0.659794\n",
      "Epoch 5729 - Train Loss: 0.171995, Train Acc: 0.665385 | Val Loss: 0.182210, Val Acc: 0.659794\n",
      "Epoch 5730 - Train Loss: 0.171982, Train Acc: 0.665385 | Val Loss: 0.182198, Val Acc: 0.659794\n",
      "Epoch 5731 - Train Loss: 0.171969, Train Acc: 0.665385 | Val Loss: 0.182187, Val Acc: 0.659794\n",
      "Epoch 5732 - Train Loss: 0.171956, Train Acc: 0.665385 | Val Loss: 0.182175, Val Acc: 0.659794\n",
      "Epoch 5733 - Train Loss: 0.171943, Train Acc: 0.665385 | Val Loss: 0.182163, Val Acc: 0.659794\n",
      "Epoch 5734 - Train Loss: 0.171930, Train Acc: 0.665385 | Val Loss: 0.182151, Val Acc: 0.659794\n",
      "Epoch 5735 - Train Loss: 0.171917, Train Acc: 0.665385 | Val Loss: 0.182140, Val Acc: 0.659794\n",
      "Epoch 5736 - Train Loss: 0.171904, Train Acc: 0.665385 | Val Loss: 0.182128, Val Acc: 0.659794\n",
      "Epoch 5737 - Train Loss: 0.171891, Train Acc: 0.665385 | Val Loss: 0.182116, Val Acc: 0.659794\n",
      "Epoch 5738 - Train Loss: 0.171878, Train Acc: 0.665385 | Val Loss: 0.182104, Val Acc: 0.659794\n",
      "Epoch 5739 - Train Loss: 0.171865, Train Acc: 0.665385 | Val Loss: 0.182093, Val Acc: 0.659794\n",
      "Epoch 5740 - Train Loss: 0.171852, Train Acc: 0.665385 | Val Loss: 0.182081, Val Acc: 0.659794\n",
      "Epoch 5741 - Train Loss: 0.171839, Train Acc: 0.665385 | Val Loss: 0.182069, Val Acc: 0.659794\n",
      "Epoch 5742 - Train Loss: 0.171826, Train Acc: 0.665385 | Val Loss: 0.182057, Val Acc: 0.659794\n",
      "Epoch 5743 - Train Loss: 0.171813, Train Acc: 0.665385 | Val Loss: 0.182046, Val Acc: 0.659794\n",
      "Epoch 5744 - Train Loss: 0.171800, Train Acc: 0.665385 | Val Loss: 0.182034, Val Acc: 0.659794\n",
      "Epoch 5745 - Train Loss: 0.171788, Train Acc: 0.665385 | Val Loss: 0.182022, Val Acc: 0.659794\n",
      "Epoch 5746 - Train Loss: 0.171775, Train Acc: 0.665385 | Val Loss: 0.182010, Val Acc: 0.659794\n",
      "Epoch 5747 - Train Loss: 0.171762, Train Acc: 0.665385 | Val Loss: 0.181999, Val Acc: 0.659794\n",
      "Epoch 5748 - Train Loss: 0.171749, Train Acc: 0.665385 | Val Loss: 0.181987, Val Acc: 0.659794\n",
      "Epoch 5749 - Train Loss: 0.171736, Train Acc: 0.665385 | Val Loss: 0.181975, Val Acc: 0.659794\n",
      "Epoch 5750 - Train Loss: 0.171723, Train Acc: 0.665385 | Val Loss: 0.181963, Val Acc: 0.659794\n",
      "Epoch 5751 - Train Loss: 0.171710, Train Acc: 0.665385 | Val Loss: 0.181952, Val Acc: 0.659794\n",
      "Epoch 5752 - Train Loss: 0.171697, Train Acc: 0.665385 | Val Loss: 0.181940, Val Acc: 0.659794\n",
      "Epoch 5753 - Train Loss: 0.171684, Train Acc: 0.665385 | Val Loss: 0.181928, Val Acc: 0.659794\n",
      "Epoch 5754 - Train Loss: 0.171671, Train Acc: 0.665385 | Val Loss: 0.181917, Val Acc: 0.659794\n",
      "Epoch 5755 - Train Loss: 0.171658, Train Acc: 0.665385 | Val Loss: 0.181905, Val Acc: 0.659794\n",
      "Epoch 5756 - Train Loss: 0.171645, Train Acc: 0.665385 | Val Loss: 0.181893, Val Acc: 0.659794\n",
      "Epoch 5757 - Train Loss: 0.171632, Train Acc: 0.665385 | Val Loss: 0.181881, Val Acc: 0.659794\n",
      "Epoch 5758 - Train Loss: 0.171619, Train Acc: 0.665385 | Val Loss: 0.181870, Val Acc: 0.659794\n",
      "Epoch 5759 - Train Loss: 0.171606, Train Acc: 0.665385 | Val Loss: 0.181858, Val Acc: 0.659794\n",
      "Epoch 5760 - Train Loss: 0.171593, Train Acc: 0.665385 | Val Loss: 0.181846, Val Acc: 0.659794\n",
      "Epoch 5761 - Train Loss: 0.171580, Train Acc: 0.665385 | Val Loss: 0.181834, Val Acc: 0.659794\n",
      "Epoch 5762 - Train Loss: 0.171567, Train Acc: 0.665385 | Val Loss: 0.181823, Val Acc: 0.659794\n",
      "Epoch 5763 - Train Loss: 0.171554, Train Acc: 0.665385 | Val Loss: 0.181811, Val Acc: 0.659794\n",
      "Epoch 5764 - Train Loss: 0.171541, Train Acc: 0.665385 | Val Loss: 0.181799, Val Acc: 0.659794\n",
      "Epoch 5765 - Train Loss: 0.171528, Train Acc: 0.666667 | Val Loss: 0.181788, Val Acc: 0.659794\n",
      "Epoch 5766 - Train Loss: 0.171515, Train Acc: 0.666667 | Val Loss: 0.181776, Val Acc: 0.659794\n",
      "Epoch 5767 - Train Loss: 0.171502, Train Acc: 0.666667 | Val Loss: 0.181764, Val Acc: 0.659794\n",
      "Epoch 5768 - Train Loss: 0.171489, Train Acc: 0.666667 | Val Loss: 0.181752, Val Acc: 0.659794\n",
      "Epoch 5769 - Train Loss: 0.171476, Train Acc: 0.666667 | Val Loss: 0.181741, Val Acc: 0.659794\n",
      "Epoch 5770 - Train Loss: 0.171463, Train Acc: 0.666667 | Val Loss: 0.181729, Val Acc: 0.659794\n",
      "Epoch 5771 - Train Loss: 0.171451, Train Acc: 0.666667 | Val Loss: 0.181717, Val Acc: 0.659794\n",
      "Epoch 5772 - Train Loss: 0.171438, Train Acc: 0.666667 | Val Loss: 0.181706, Val Acc: 0.659794\n",
      "Epoch 5773 - Train Loss: 0.171425, Train Acc: 0.666667 | Val Loss: 0.181694, Val Acc: 0.659794\n",
      "Epoch 5774 - Train Loss: 0.171412, Train Acc: 0.666667 | Val Loss: 0.181682, Val Acc: 0.659794\n",
      "Epoch 5775 - Train Loss: 0.171399, Train Acc: 0.666667 | Val Loss: 0.181670, Val Acc: 0.659794\n",
      "Epoch 5776 - Train Loss: 0.171386, Train Acc: 0.666667 | Val Loss: 0.181659, Val Acc: 0.659794\n",
      "Epoch 5777 - Train Loss: 0.171373, Train Acc: 0.666667 | Val Loss: 0.181647, Val Acc: 0.659794\n",
      "Epoch 5778 - Train Loss: 0.171360, Train Acc: 0.666667 | Val Loss: 0.181635, Val Acc: 0.659794\n",
      "Epoch 5779 - Train Loss: 0.171347, Train Acc: 0.666667 | Val Loss: 0.181624, Val Acc: 0.659794\n",
      "Epoch 5780 - Train Loss: 0.171334, Train Acc: 0.666667 | Val Loss: 0.181612, Val Acc: 0.659794\n",
      "Epoch 5781 - Train Loss: 0.171321, Train Acc: 0.666667 | Val Loss: 0.181600, Val Acc: 0.659794\n",
      "Epoch 5782 - Train Loss: 0.171308, Train Acc: 0.666667 | Val Loss: 0.181589, Val Acc: 0.659794\n",
      "Epoch 5783 - Train Loss: 0.171295, Train Acc: 0.666667 | Val Loss: 0.181577, Val Acc: 0.659794\n",
      "Epoch 5784 - Train Loss: 0.171282, Train Acc: 0.666667 | Val Loss: 0.181565, Val Acc: 0.659794\n",
      "Epoch 5785 - Train Loss: 0.171269, Train Acc: 0.666667 | Val Loss: 0.181554, Val Acc: 0.659794\n",
      "Epoch 5786 - Train Loss: 0.171256, Train Acc: 0.666667 | Val Loss: 0.181542, Val Acc: 0.659794\n",
      "Epoch 5787 - Train Loss: 0.171244, Train Acc: 0.666667 | Val Loss: 0.181530, Val Acc: 0.659794\n",
      "Epoch 5788 - Train Loss: 0.171231, Train Acc: 0.666667 | Val Loss: 0.181518, Val Acc: 0.659794\n",
      "Epoch 5789 - Train Loss: 0.171218, Train Acc: 0.666667 | Val Loss: 0.181507, Val Acc: 0.659794\n",
      "Epoch 5790 - Train Loss: 0.171205, Train Acc: 0.666667 | Val Loss: 0.181495, Val Acc: 0.659794\n",
      "Epoch 5791 - Train Loss: 0.171192, Train Acc: 0.666667 | Val Loss: 0.181483, Val Acc: 0.659794\n",
      "Epoch 5792 - Train Loss: 0.171179, Train Acc: 0.666667 | Val Loss: 0.181472, Val Acc: 0.659794\n",
      "Epoch 5793 - Train Loss: 0.171166, Train Acc: 0.666667 | Val Loss: 0.181460, Val Acc: 0.659794\n",
      "Epoch 5794 - Train Loss: 0.171153, Train Acc: 0.666667 | Val Loss: 0.181448, Val Acc: 0.659794\n",
      "Epoch 5795 - Train Loss: 0.171140, Train Acc: 0.666667 | Val Loss: 0.181437, Val Acc: 0.659794\n",
      "Epoch 5796 - Train Loss: 0.171127, Train Acc: 0.666667 | Val Loss: 0.181425, Val Acc: 0.659794\n",
      "Epoch 5797 - Train Loss: 0.171114, Train Acc: 0.666667 | Val Loss: 0.181413, Val Acc: 0.659794\n",
      "Epoch 5798 - Train Loss: 0.171101, Train Acc: 0.666667 | Val Loss: 0.181402, Val Acc: 0.659794\n",
      "Epoch 5799 - Train Loss: 0.171088, Train Acc: 0.666667 | Val Loss: 0.181390, Val Acc: 0.659794\n",
      "Epoch 5800 - Train Loss: 0.171076, Train Acc: 0.666667 | Val Loss: 0.181378, Val Acc: 0.659794\n",
      "Epoch 5801 - Train Loss: 0.171063, Train Acc: 0.666667 | Val Loss: 0.181367, Val Acc: 0.659794\n",
      "Epoch 5802 - Train Loss: 0.171050, Train Acc: 0.666667 | Val Loss: 0.181355, Val Acc: 0.659794\n",
      "Epoch 5803 - Train Loss: 0.171037, Train Acc: 0.666667 | Val Loss: 0.181343, Val Acc: 0.659794\n",
      "Epoch 5804 - Train Loss: 0.171024, Train Acc: 0.666667 | Val Loss: 0.181332, Val Acc: 0.659794\n",
      "Epoch 5805 - Train Loss: 0.171011, Train Acc: 0.666667 | Val Loss: 0.181320, Val Acc: 0.659794\n",
      "Epoch 5806 - Train Loss: 0.170998, Train Acc: 0.666667 | Val Loss: 0.181308, Val Acc: 0.659794\n",
      "Epoch 5807 - Train Loss: 0.170985, Train Acc: 0.666667 | Val Loss: 0.181297, Val Acc: 0.659794\n",
      "Epoch 5808 - Train Loss: 0.170972, Train Acc: 0.666667 | Val Loss: 0.181285, Val Acc: 0.659794\n",
      "Epoch 5809 - Train Loss: 0.170959, Train Acc: 0.666667 | Val Loss: 0.181273, Val Acc: 0.659794\n",
      "Epoch 5810 - Train Loss: 0.170946, Train Acc: 0.666667 | Val Loss: 0.181262, Val Acc: 0.659794\n",
      "Epoch 5811 - Train Loss: 0.170934, Train Acc: 0.666667 | Val Loss: 0.181250, Val Acc: 0.659794\n",
      "Epoch 5812 - Train Loss: 0.170921, Train Acc: 0.666667 | Val Loss: 0.181238, Val Acc: 0.659794\n",
      "Epoch 5813 - Train Loss: 0.170908, Train Acc: 0.666667 | Val Loss: 0.181227, Val Acc: 0.659794\n",
      "Epoch 5814 - Train Loss: 0.170895, Train Acc: 0.666667 | Val Loss: 0.181215, Val Acc: 0.659794\n",
      "Epoch 5815 - Train Loss: 0.170882, Train Acc: 0.666667 | Val Loss: 0.181203, Val Acc: 0.659794\n",
      "Epoch 5816 - Train Loss: 0.170869, Train Acc: 0.666667 | Val Loss: 0.181192, Val Acc: 0.659794\n",
      "Epoch 5817 - Train Loss: 0.170856, Train Acc: 0.666667 | Val Loss: 0.181180, Val Acc: 0.659794\n",
      "Epoch 5818 - Train Loss: 0.170843, Train Acc: 0.666667 | Val Loss: 0.181168, Val Acc: 0.659794\n",
      "Epoch 5819 - Train Loss: 0.170830, Train Acc: 0.666667 | Val Loss: 0.181157, Val Acc: 0.659794\n",
      "Epoch 5820 - Train Loss: 0.170818, Train Acc: 0.666667 | Val Loss: 0.181145, Val Acc: 0.659794\n",
      "Epoch 5821 - Train Loss: 0.170805, Train Acc: 0.666667 | Val Loss: 0.181133, Val Acc: 0.659794\n",
      "Epoch 5822 - Train Loss: 0.170792, Train Acc: 0.666667 | Val Loss: 0.181122, Val Acc: 0.659794\n",
      "Epoch 5823 - Train Loss: 0.170779, Train Acc: 0.666667 | Val Loss: 0.181110, Val Acc: 0.659794\n",
      "Epoch 5824 - Train Loss: 0.170766, Train Acc: 0.666667 | Val Loss: 0.181099, Val Acc: 0.659794\n",
      "Epoch 5825 - Train Loss: 0.170753, Train Acc: 0.666667 | Val Loss: 0.181087, Val Acc: 0.659794\n",
      "Epoch 5826 - Train Loss: 0.170740, Train Acc: 0.666667 | Val Loss: 0.181075, Val Acc: 0.659794\n",
      "Epoch 5827 - Train Loss: 0.170727, Train Acc: 0.666667 | Val Loss: 0.181064, Val Acc: 0.659794\n",
      "Epoch 5828 - Train Loss: 0.170714, Train Acc: 0.666667 | Val Loss: 0.181052, Val Acc: 0.659794\n",
      "Epoch 5829 - Train Loss: 0.170702, Train Acc: 0.666667 | Val Loss: 0.181040, Val Acc: 0.659794\n",
      "Epoch 5830 - Train Loss: 0.170689, Train Acc: 0.666667 | Val Loss: 0.181029, Val Acc: 0.659794\n",
      "Epoch 5831 - Train Loss: 0.170676, Train Acc: 0.666667 | Val Loss: 0.181017, Val Acc: 0.659794\n",
      "Epoch 5832 - Train Loss: 0.170663, Train Acc: 0.666667 | Val Loss: 0.181006, Val Acc: 0.659794\n",
      "Epoch 5833 - Train Loss: 0.170650, Train Acc: 0.666667 | Val Loss: 0.180994, Val Acc: 0.659794\n",
      "Epoch 5834 - Train Loss: 0.170637, Train Acc: 0.666667 | Val Loss: 0.180982, Val Acc: 0.659794\n",
      "Epoch 5835 - Train Loss: 0.170624, Train Acc: 0.666667 | Val Loss: 0.180971, Val Acc: 0.659794\n",
      "Epoch 5836 - Train Loss: 0.170611, Train Acc: 0.666667 | Val Loss: 0.180959, Val Acc: 0.659794\n",
      "Epoch 5837 - Train Loss: 0.170599, Train Acc: 0.666667 | Val Loss: 0.180947, Val Acc: 0.659794\n",
      "Epoch 5838 - Train Loss: 0.170586, Train Acc: 0.667949 | Val Loss: 0.180936, Val Acc: 0.659794\n",
      "Epoch 5839 - Train Loss: 0.170573, Train Acc: 0.667949 | Val Loss: 0.180924, Val Acc: 0.659794\n",
      "Epoch 5840 - Train Loss: 0.170560, Train Acc: 0.667949 | Val Loss: 0.180913, Val Acc: 0.659794\n",
      "Epoch 5841 - Train Loss: 0.170547, Train Acc: 0.667949 | Val Loss: 0.180901, Val Acc: 0.659794\n",
      "Epoch 5842 - Train Loss: 0.170534, Train Acc: 0.667949 | Val Loss: 0.180889, Val Acc: 0.659794\n",
      "Epoch 5843 - Train Loss: 0.170521, Train Acc: 0.667949 | Val Loss: 0.180878, Val Acc: 0.659794\n",
      "Epoch 5844 - Train Loss: 0.170509, Train Acc: 0.667949 | Val Loss: 0.180866, Val Acc: 0.659794\n",
      "Epoch 5845 - Train Loss: 0.170496, Train Acc: 0.667949 | Val Loss: 0.180854, Val Acc: 0.659794\n",
      "Epoch 5846 - Train Loss: 0.170483, Train Acc: 0.667949 | Val Loss: 0.180843, Val Acc: 0.659794\n",
      "Epoch 5847 - Train Loss: 0.170470, Train Acc: 0.667949 | Val Loss: 0.180831, Val Acc: 0.659794\n",
      "Epoch 5848 - Train Loss: 0.170457, Train Acc: 0.667949 | Val Loss: 0.180820, Val Acc: 0.659794\n",
      "Epoch 5849 - Train Loss: 0.170444, Train Acc: 0.667949 | Val Loss: 0.180808, Val Acc: 0.659794\n",
      "Epoch 5850 - Train Loss: 0.170431, Train Acc: 0.667949 | Val Loss: 0.180796, Val Acc: 0.659794\n",
      "Epoch 5851 - Train Loss: 0.170419, Train Acc: 0.667949 | Val Loss: 0.180785, Val Acc: 0.659794\n",
      "Epoch 5852 - Train Loss: 0.170406, Train Acc: 0.667949 | Val Loss: 0.180773, Val Acc: 0.659794\n",
      "Epoch 5853 - Train Loss: 0.170393, Train Acc: 0.667949 | Val Loss: 0.180762, Val Acc: 0.659794\n",
      "Epoch 5854 - Train Loss: 0.170380, Train Acc: 0.667949 | Val Loss: 0.180750, Val Acc: 0.659794\n",
      "Epoch 5855 - Train Loss: 0.170367, Train Acc: 0.667949 | Val Loss: 0.180738, Val Acc: 0.659794\n",
      "Epoch 5856 - Train Loss: 0.170354, Train Acc: 0.667949 | Val Loss: 0.180727, Val Acc: 0.659794\n",
      "Epoch 5857 - Train Loss: 0.170341, Train Acc: 0.667949 | Val Loss: 0.180715, Val Acc: 0.659794\n",
      "Epoch 5858 - Train Loss: 0.170329, Train Acc: 0.667949 | Val Loss: 0.180704, Val Acc: 0.659794\n",
      "Epoch 5859 - Train Loss: 0.170316, Train Acc: 0.667949 | Val Loss: 0.180692, Val Acc: 0.659794\n",
      "Epoch 5860 - Train Loss: 0.170303, Train Acc: 0.667949 | Val Loss: 0.180681, Val Acc: 0.659794\n",
      "Epoch 5861 - Train Loss: 0.170290, Train Acc: 0.667949 | Val Loss: 0.180669, Val Acc: 0.659794\n",
      "Epoch 5862 - Train Loss: 0.170277, Train Acc: 0.667949 | Val Loss: 0.180657, Val Acc: 0.659794\n",
      "Epoch 5863 - Train Loss: 0.170264, Train Acc: 0.667949 | Val Loss: 0.180646, Val Acc: 0.659794\n",
      "Epoch 5864 - Train Loss: 0.170252, Train Acc: 0.667949 | Val Loss: 0.180634, Val Acc: 0.659794\n",
      "Epoch 5865 - Train Loss: 0.170239, Train Acc: 0.667949 | Val Loss: 0.180623, Val Acc: 0.659794\n",
      "Epoch 5866 - Train Loss: 0.170226, Train Acc: 0.667949 | Val Loss: 0.180611, Val Acc: 0.659794\n",
      "Epoch 5867 - Train Loss: 0.170213, Train Acc: 0.667949 | Val Loss: 0.180599, Val Acc: 0.659794\n",
      "Epoch 5868 - Train Loss: 0.170200, Train Acc: 0.667949 | Val Loss: 0.180588, Val Acc: 0.659794\n",
      "Epoch 5869 - Train Loss: 0.170187, Train Acc: 0.667949 | Val Loss: 0.180576, Val Acc: 0.659794\n",
      "Epoch 5870 - Train Loss: 0.170175, Train Acc: 0.667949 | Val Loss: 0.180565, Val Acc: 0.659794\n",
      "Epoch 5871 - Train Loss: 0.170162, Train Acc: 0.667949 | Val Loss: 0.180553, Val Acc: 0.659794\n",
      "Epoch 5872 - Train Loss: 0.170149, Train Acc: 0.667949 | Val Loss: 0.180542, Val Acc: 0.659794\n",
      "Epoch 5873 - Train Loss: 0.170136, Train Acc: 0.667949 | Val Loss: 0.180530, Val Acc: 0.659794\n",
      "Epoch 5874 - Train Loss: 0.170123, Train Acc: 0.667949 | Val Loss: 0.180518, Val Acc: 0.659794\n",
      "Epoch 5875 - Train Loss: 0.170110, Train Acc: 0.667949 | Val Loss: 0.180507, Val Acc: 0.659794\n",
      "Epoch 5876 - Train Loss: 0.170098, Train Acc: 0.667949 | Val Loss: 0.180495, Val Acc: 0.659794\n",
      "Epoch 5877 - Train Loss: 0.170085, Train Acc: 0.667949 | Val Loss: 0.180484, Val Acc: 0.659794\n",
      "Epoch 5878 - Train Loss: 0.170072, Train Acc: 0.667949 | Val Loss: 0.180472, Val Acc: 0.659794\n",
      "Epoch 5879 - Train Loss: 0.170059, Train Acc: 0.667949 | Val Loss: 0.180461, Val Acc: 0.659794\n",
      "Epoch 5880 - Train Loss: 0.170046, Train Acc: 0.667949 | Val Loss: 0.180449, Val Acc: 0.659794\n",
      "Epoch 5881 - Train Loss: 0.170034, Train Acc: 0.667949 | Val Loss: 0.180438, Val Acc: 0.659794\n",
      "Epoch 5882 - Train Loss: 0.170021, Train Acc: 0.667949 | Val Loss: 0.180426, Val Acc: 0.659794\n",
      "Epoch 5883 - Train Loss: 0.170008, Train Acc: 0.667949 | Val Loss: 0.180414, Val Acc: 0.659794\n",
      "Epoch 5884 - Train Loss: 0.169995, Train Acc: 0.667949 | Val Loss: 0.180403, Val Acc: 0.659794\n",
      "Epoch 5885 - Train Loss: 0.169982, Train Acc: 0.667949 | Val Loss: 0.180391, Val Acc: 0.659794\n",
      "Epoch 5886 - Train Loss: 0.169969, Train Acc: 0.667949 | Val Loss: 0.180380, Val Acc: 0.659794\n",
      "Epoch 5887 - Train Loss: 0.169957, Train Acc: 0.667949 | Val Loss: 0.180368, Val Acc: 0.659794\n",
      "Epoch 5888 - Train Loss: 0.169944, Train Acc: 0.667949 | Val Loss: 0.180357, Val Acc: 0.659794\n",
      "Epoch 5889 - Train Loss: 0.169931, Train Acc: 0.667949 | Val Loss: 0.180345, Val Acc: 0.659794\n",
      "Epoch 5890 - Train Loss: 0.169918, Train Acc: 0.667949 | Val Loss: 0.180334, Val Acc: 0.659794\n",
      "Epoch 5891 - Train Loss: 0.169905, Train Acc: 0.667949 | Val Loss: 0.180322, Val Acc: 0.659794\n",
      "Epoch 5892 - Train Loss: 0.169893, Train Acc: 0.667949 | Val Loss: 0.180310, Val Acc: 0.659794\n",
      "Epoch 5893 - Train Loss: 0.169880, Train Acc: 0.667949 | Val Loss: 0.180299, Val Acc: 0.659794\n",
      "Epoch 5894 - Train Loss: 0.169867, Train Acc: 0.667949 | Val Loss: 0.180287, Val Acc: 0.659794\n",
      "Epoch 5895 - Train Loss: 0.169854, Train Acc: 0.667949 | Val Loss: 0.180276, Val Acc: 0.659794\n",
      "Epoch 5896 - Train Loss: 0.169841, Train Acc: 0.667949 | Val Loss: 0.180264, Val Acc: 0.659794\n",
      "Epoch 5897 - Train Loss: 0.169829, Train Acc: 0.667949 | Val Loss: 0.180253, Val Acc: 0.659794\n",
      "Epoch 5898 - Train Loss: 0.169816, Train Acc: 0.667949 | Val Loss: 0.180241, Val Acc: 0.659794\n",
      "Epoch 5899 - Train Loss: 0.169803, Train Acc: 0.667949 | Val Loss: 0.180230, Val Acc: 0.659794\n",
      "Epoch 5900 - Train Loss: 0.169790, Train Acc: 0.667949 | Val Loss: 0.180218, Val Acc: 0.659794\n",
      "Epoch 5901 - Train Loss: 0.169777, Train Acc: 0.667949 | Val Loss: 0.180207, Val Acc: 0.659794\n",
      "Epoch 5902 - Train Loss: 0.169765, Train Acc: 0.667949 | Val Loss: 0.180195, Val Acc: 0.659794\n",
      "Epoch 5903 - Train Loss: 0.169752, Train Acc: 0.667949 | Val Loss: 0.180184, Val Acc: 0.659794\n",
      "Epoch 5904 - Train Loss: 0.169739, Train Acc: 0.667949 | Val Loss: 0.180172, Val Acc: 0.659794\n",
      "Epoch 5905 - Train Loss: 0.169726, Train Acc: 0.667949 | Val Loss: 0.180161, Val Acc: 0.659794\n",
      "Epoch 5906 - Train Loss: 0.169714, Train Acc: 0.667949 | Val Loss: 0.180149, Val Acc: 0.659794\n",
      "Epoch 5907 - Train Loss: 0.169701, Train Acc: 0.667949 | Val Loss: 0.180137, Val Acc: 0.659794\n",
      "Epoch 5908 - Train Loss: 0.169688, Train Acc: 0.667949 | Val Loss: 0.180126, Val Acc: 0.659794\n",
      "Epoch 5909 - Train Loss: 0.169675, Train Acc: 0.667949 | Val Loss: 0.180114, Val Acc: 0.659794\n",
      "Epoch 5910 - Train Loss: 0.169662, Train Acc: 0.667949 | Val Loss: 0.180103, Val Acc: 0.659794\n",
      "Epoch 5911 - Train Loss: 0.169650, Train Acc: 0.667949 | Val Loss: 0.180091, Val Acc: 0.659794\n",
      "Epoch 5912 - Train Loss: 0.169637, Train Acc: 0.667949 | Val Loss: 0.180080, Val Acc: 0.659794\n",
      "Epoch 5913 - Train Loss: 0.169624, Train Acc: 0.667949 | Val Loss: 0.180068, Val Acc: 0.659794\n",
      "Epoch 5914 - Train Loss: 0.169611, Train Acc: 0.667949 | Val Loss: 0.180057, Val Acc: 0.659794\n",
      "Epoch 5915 - Train Loss: 0.169598, Train Acc: 0.667949 | Val Loss: 0.180045, Val Acc: 0.659794\n",
      "Epoch 5916 - Train Loss: 0.169586, Train Acc: 0.667949 | Val Loss: 0.180034, Val Acc: 0.659794\n",
      "Epoch 5917 - Train Loss: 0.169573, Train Acc: 0.667949 | Val Loss: 0.180022, Val Acc: 0.659794\n",
      "Epoch 5918 - Train Loss: 0.169560, Train Acc: 0.667949 | Val Loss: 0.180011, Val Acc: 0.659794\n",
      "Epoch 5919 - Train Loss: 0.169547, Train Acc: 0.667949 | Val Loss: 0.179999, Val Acc: 0.659794\n",
      "Epoch 5920 - Train Loss: 0.169535, Train Acc: 0.667949 | Val Loss: 0.179988, Val Acc: 0.659794\n",
      "Epoch 5921 - Train Loss: 0.169522, Train Acc: 0.667949 | Val Loss: 0.179976, Val Acc: 0.659794\n",
      "Epoch 5922 - Train Loss: 0.169509, Train Acc: 0.667949 | Val Loss: 0.179965, Val Acc: 0.659794\n",
      "Epoch 5923 - Train Loss: 0.169496, Train Acc: 0.667949 | Val Loss: 0.179953, Val Acc: 0.659794\n",
      "Epoch 5924 - Train Loss: 0.169484, Train Acc: 0.667949 | Val Loss: 0.179942, Val Acc: 0.659794\n",
      "Epoch 5925 - Train Loss: 0.169471, Train Acc: 0.667949 | Val Loss: 0.179930, Val Acc: 0.659794\n",
      "Epoch 5926 - Train Loss: 0.169458, Train Acc: 0.667949 | Val Loss: 0.179919, Val Acc: 0.659794\n",
      "Epoch 5927 - Train Loss: 0.169445, Train Acc: 0.667949 | Val Loss: 0.179907, Val Acc: 0.659794\n",
      "Epoch 5928 - Train Loss: 0.169432, Train Acc: 0.667949 | Val Loss: 0.179896, Val Acc: 0.659794\n",
      "Epoch 5929 - Train Loss: 0.169420, Train Acc: 0.667949 | Val Loss: 0.179884, Val Acc: 0.659794\n",
      "Epoch 5930 - Train Loss: 0.169407, Train Acc: 0.667949 | Val Loss: 0.179873, Val Acc: 0.659794\n",
      "Epoch 5931 - Train Loss: 0.169394, Train Acc: 0.667949 | Val Loss: 0.179861, Val Acc: 0.659794\n",
      "Epoch 5932 - Train Loss: 0.169381, Train Acc: 0.669231 | Val Loss: 0.179850, Val Acc: 0.659794\n",
      "Epoch 5933 - Train Loss: 0.169369, Train Acc: 0.669231 | Val Loss: 0.179838, Val Acc: 0.659794\n",
      "Epoch 5934 - Train Loss: 0.169356, Train Acc: 0.669231 | Val Loss: 0.179827, Val Acc: 0.659794\n",
      "Epoch 5935 - Train Loss: 0.169343, Train Acc: 0.669231 | Val Loss: 0.179815, Val Acc: 0.659794\n",
      "Epoch 5936 - Train Loss: 0.169330, Train Acc: 0.669231 | Val Loss: 0.179804, Val Acc: 0.659794\n",
      "Epoch 5937 - Train Loss: 0.169318, Train Acc: 0.669231 | Val Loss: 0.179792, Val Acc: 0.659794\n",
      "Epoch 5938 - Train Loss: 0.169305, Train Acc: 0.669231 | Val Loss: 0.179781, Val Acc: 0.659794\n",
      "Epoch 5939 - Train Loss: 0.169292, Train Acc: 0.669231 | Val Loss: 0.179769, Val Acc: 0.659794\n",
      "Epoch 5940 - Train Loss: 0.169279, Train Acc: 0.669231 | Val Loss: 0.179758, Val Acc: 0.659794\n",
      "Epoch 5941 - Train Loss: 0.169267, Train Acc: 0.669231 | Val Loss: 0.179746, Val Acc: 0.659794\n",
      "Epoch 5942 - Train Loss: 0.169254, Train Acc: 0.670513 | Val Loss: 0.179735, Val Acc: 0.659794\n",
      "Epoch 5943 - Train Loss: 0.169241, Train Acc: 0.670513 | Val Loss: 0.179723, Val Acc: 0.659794\n",
      "Epoch 5944 - Train Loss: 0.169228, Train Acc: 0.670513 | Val Loss: 0.179712, Val Acc: 0.659794\n",
      "Epoch 5945 - Train Loss: 0.169216, Train Acc: 0.670513 | Val Loss: 0.179701, Val Acc: 0.659794\n",
      "Epoch 5946 - Train Loss: 0.169203, Train Acc: 0.670513 | Val Loss: 0.179689, Val Acc: 0.659794\n",
      "Epoch 5947 - Train Loss: 0.169190, Train Acc: 0.670513 | Val Loss: 0.179678, Val Acc: 0.659794\n",
      "Epoch 5948 - Train Loss: 0.169177, Train Acc: 0.670513 | Val Loss: 0.179666, Val Acc: 0.659794\n",
      "Epoch 5949 - Train Loss: 0.169165, Train Acc: 0.670513 | Val Loss: 0.179655, Val Acc: 0.659794\n",
      "Epoch 5950 - Train Loss: 0.169152, Train Acc: 0.670513 | Val Loss: 0.179643, Val Acc: 0.659794\n",
      "Epoch 5951 - Train Loss: 0.169139, Train Acc: 0.670513 | Val Loss: 0.179632, Val Acc: 0.659794\n",
      "Epoch 5952 - Train Loss: 0.169127, Train Acc: 0.670513 | Val Loss: 0.179620, Val Acc: 0.659794\n",
      "Epoch 5953 - Train Loss: 0.169114, Train Acc: 0.670513 | Val Loss: 0.179609, Val Acc: 0.659794\n",
      "Epoch 5954 - Train Loss: 0.169101, Train Acc: 0.670513 | Val Loss: 0.179597, Val Acc: 0.659794\n",
      "Epoch 5955 - Train Loss: 0.169088, Train Acc: 0.670513 | Val Loss: 0.179586, Val Acc: 0.659794\n",
      "Epoch 5956 - Train Loss: 0.169076, Train Acc: 0.670513 | Val Loss: 0.179574, Val Acc: 0.659794\n",
      "Epoch 5957 - Train Loss: 0.169063, Train Acc: 0.670513 | Val Loss: 0.179563, Val Acc: 0.659794\n",
      "Epoch 5958 - Train Loss: 0.169050, Train Acc: 0.671795 | Val Loss: 0.179551, Val Acc: 0.659794\n",
      "Epoch 5959 - Train Loss: 0.169037, Train Acc: 0.671795 | Val Loss: 0.179540, Val Acc: 0.659794\n",
      "Epoch 5960 - Train Loss: 0.169025, Train Acc: 0.671795 | Val Loss: 0.179529, Val Acc: 0.659794\n",
      "Epoch 5961 - Train Loss: 0.169012, Train Acc: 0.671795 | Val Loss: 0.179517, Val Acc: 0.659794\n",
      "Epoch 5962 - Train Loss: 0.168999, Train Acc: 0.671795 | Val Loss: 0.179506, Val Acc: 0.659794\n",
      "Epoch 5963 - Train Loss: 0.168986, Train Acc: 0.671795 | Val Loss: 0.179494, Val Acc: 0.659794\n",
      "Epoch 5964 - Train Loss: 0.168974, Train Acc: 0.671795 | Val Loss: 0.179483, Val Acc: 0.659794\n",
      "Epoch 5965 - Train Loss: 0.168961, Train Acc: 0.671795 | Val Loss: 0.179471, Val Acc: 0.659794\n",
      "Epoch 5966 - Train Loss: 0.168948, Train Acc: 0.671795 | Val Loss: 0.179460, Val Acc: 0.659794\n",
      "Epoch 5967 - Train Loss: 0.168936, Train Acc: 0.671795 | Val Loss: 0.179448, Val Acc: 0.659794\n",
      "Epoch 5968 - Train Loss: 0.168923, Train Acc: 0.671795 | Val Loss: 0.179437, Val Acc: 0.659794\n",
      "Epoch 5969 - Train Loss: 0.168910, Train Acc: 0.671795 | Val Loss: 0.179426, Val Acc: 0.659794\n",
      "Epoch 5970 - Train Loss: 0.168897, Train Acc: 0.671795 | Val Loss: 0.179414, Val Acc: 0.659794\n",
      "Epoch 5971 - Train Loss: 0.168885, Train Acc: 0.671795 | Val Loss: 0.179403, Val Acc: 0.659794\n",
      "Epoch 5972 - Train Loss: 0.168872, Train Acc: 0.671795 | Val Loss: 0.179391, Val Acc: 0.659794\n",
      "Epoch 5973 - Train Loss: 0.168859, Train Acc: 0.671795 | Val Loss: 0.179380, Val Acc: 0.659794\n",
      "Epoch 5974 - Train Loss: 0.168847, Train Acc: 0.671795 | Val Loss: 0.179368, Val Acc: 0.659794\n",
      "Epoch 5975 - Train Loss: 0.168834, Train Acc: 0.671795 | Val Loss: 0.179357, Val Acc: 0.659794\n",
      "Epoch 5976 - Train Loss: 0.168821, Train Acc: 0.671795 | Val Loss: 0.179345, Val Acc: 0.659794\n",
      "Epoch 5977 - Train Loss: 0.168809, Train Acc: 0.671795 | Val Loss: 0.179334, Val Acc: 0.659794\n",
      "Epoch 5978 - Train Loss: 0.168796, Train Acc: 0.671795 | Val Loss: 0.179323, Val Acc: 0.659794\n",
      "Epoch 5979 - Train Loss: 0.168783, Train Acc: 0.671795 | Val Loss: 0.179311, Val Acc: 0.659794\n",
      "Epoch 5980 - Train Loss: 0.168770, Train Acc: 0.671795 | Val Loss: 0.179300, Val Acc: 0.659794\n",
      "Epoch 5981 - Train Loss: 0.168758, Train Acc: 0.671795 | Val Loss: 0.179288, Val Acc: 0.659794\n",
      "Epoch 5982 - Train Loss: 0.168745, Train Acc: 0.671795 | Val Loss: 0.179277, Val Acc: 0.659794\n",
      "Epoch 5983 - Train Loss: 0.168732, Train Acc: 0.671795 | Val Loss: 0.179266, Val Acc: 0.659794\n",
      "Epoch 5984 - Train Loss: 0.168720, Train Acc: 0.671795 | Val Loss: 0.179254, Val Acc: 0.659794\n",
      "Epoch 5985 - Train Loss: 0.168707, Train Acc: 0.671795 | Val Loss: 0.179243, Val Acc: 0.659794\n",
      "Epoch 5986 - Train Loss: 0.168694, Train Acc: 0.671795 | Val Loss: 0.179231, Val Acc: 0.659794\n",
      "Epoch 5987 - Train Loss: 0.168682, Train Acc: 0.671795 | Val Loss: 0.179220, Val Acc: 0.659794\n",
      "Epoch 5988 - Train Loss: 0.168669, Train Acc: 0.671795 | Val Loss: 0.179208, Val Acc: 0.659794\n",
      "Epoch 5989 - Train Loss: 0.168656, Train Acc: 0.671795 | Val Loss: 0.179197, Val Acc: 0.659794\n",
      "Epoch 5990 - Train Loss: 0.168643, Train Acc: 0.671795 | Val Loss: 0.179186, Val Acc: 0.659794\n",
      "Epoch 5991 - Train Loss: 0.168631, Train Acc: 0.671795 | Val Loss: 0.179174, Val Acc: 0.659794\n",
      "Epoch 5992 - Train Loss: 0.168618, Train Acc: 0.671795 | Val Loss: 0.179163, Val Acc: 0.659794\n",
      "Epoch 5993 - Train Loss: 0.168605, Train Acc: 0.671795 | Val Loss: 0.179151, Val Acc: 0.659794\n",
      "Epoch 5994 - Train Loss: 0.168593, Train Acc: 0.671795 | Val Loss: 0.179140, Val Acc: 0.659794\n",
      "Epoch 5995 - Train Loss: 0.168580, Train Acc: 0.671795 | Val Loss: 0.179129, Val Acc: 0.659794\n",
      "Epoch 5996 - Train Loss: 0.168567, Train Acc: 0.671795 | Val Loss: 0.179117, Val Acc: 0.659794\n",
      "Epoch 5997 - Train Loss: 0.168555, Train Acc: 0.671795 | Val Loss: 0.179106, Val Acc: 0.659794\n",
      "Epoch 5998 - Train Loss: 0.168542, Train Acc: 0.671795 | Val Loss: 0.179094, Val Acc: 0.659794\n",
      "Epoch 5999 - Train Loss: 0.168529, Train Acc: 0.671795 | Val Loss: 0.179083, Val Acc: 0.659794\n",
      "Epoch 6000 - Train Loss: 0.168517, Train Acc: 0.671795 | Val Loss: 0.179072, Val Acc: 0.659794\n",
      "Epoch 6001 - Train Loss: 0.168504, Train Acc: 0.671795 | Val Loss: 0.179060, Val Acc: 0.659794\n",
      "Epoch 6002 - Train Loss: 0.168491, Train Acc: 0.671795 | Val Loss: 0.179049, Val Acc: 0.659794\n",
      "Epoch 6003 - Train Loss: 0.168479, Train Acc: 0.671795 | Val Loss: 0.179037, Val Acc: 0.659794\n",
      "Epoch 6004 - Train Loss: 0.168466, Train Acc: 0.671795 | Val Loss: 0.179026, Val Acc: 0.659794\n",
      "Epoch 6005 - Train Loss: 0.168453, Train Acc: 0.671795 | Val Loss: 0.179015, Val Acc: 0.659794\n",
      "Epoch 6006 - Train Loss: 0.168441, Train Acc: 0.671795 | Val Loss: 0.179003, Val Acc: 0.659794\n",
      "Epoch 6007 - Train Loss: 0.168428, Train Acc: 0.671795 | Val Loss: 0.178992, Val Acc: 0.659794\n",
      "Epoch 6008 - Train Loss: 0.168415, Train Acc: 0.671795 | Val Loss: 0.178980, Val Acc: 0.659794\n",
      "Epoch 6009 - Train Loss: 0.168403, Train Acc: 0.671795 | Val Loss: 0.178969, Val Acc: 0.659794\n",
      "Epoch 6010 - Train Loss: 0.168390, Train Acc: 0.671795 | Val Loss: 0.178958, Val Acc: 0.659794\n",
      "Epoch 6011 - Train Loss: 0.168377, Train Acc: 0.671795 | Val Loss: 0.178946, Val Acc: 0.659794\n",
      "Epoch 6012 - Train Loss: 0.168365, Train Acc: 0.671795 | Val Loss: 0.178935, Val Acc: 0.659794\n",
      "Epoch 6013 - Train Loss: 0.168352, Train Acc: 0.671795 | Val Loss: 0.178923, Val Acc: 0.659794\n",
      "Epoch 6014 - Train Loss: 0.168339, Train Acc: 0.671795 | Val Loss: 0.178912, Val Acc: 0.659794\n",
      "Epoch 6015 - Train Loss: 0.168327, Train Acc: 0.671795 | Val Loss: 0.178901, Val Acc: 0.659794\n",
      "Epoch 6016 - Train Loss: 0.168314, Train Acc: 0.671795 | Val Loss: 0.178889, Val Acc: 0.659794\n",
      "Epoch 6017 - Train Loss: 0.168301, Train Acc: 0.671795 | Val Loss: 0.178878, Val Acc: 0.659794\n",
      "Epoch 6018 - Train Loss: 0.168289, Train Acc: 0.671795 | Val Loss: 0.178867, Val Acc: 0.659794\n",
      "Epoch 6019 - Train Loss: 0.168276, Train Acc: 0.671795 | Val Loss: 0.178855, Val Acc: 0.659794\n",
      "Epoch 6020 - Train Loss: 0.168263, Train Acc: 0.671795 | Val Loss: 0.178844, Val Acc: 0.659794\n",
      "Epoch 6021 - Train Loss: 0.168251, Train Acc: 0.671795 | Val Loss: 0.178832, Val Acc: 0.659794\n",
      "Epoch 6022 - Train Loss: 0.168238, Train Acc: 0.671795 | Val Loss: 0.178821, Val Acc: 0.659794\n",
      "Epoch 6023 - Train Loss: 0.168225, Train Acc: 0.671795 | Val Loss: 0.178810, Val Acc: 0.659794\n",
      "Epoch 6024 - Train Loss: 0.168213, Train Acc: 0.671795 | Val Loss: 0.178798, Val Acc: 0.659794\n",
      "Epoch 6025 - Train Loss: 0.168200, Train Acc: 0.671795 | Val Loss: 0.178787, Val Acc: 0.659794\n",
      "Epoch 6026 - Train Loss: 0.168187, Train Acc: 0.671795 | Val Loss: 0.178776, Val Acc: 0.659794\n",
      "Epoch 6027 - Train Loss: 0.168175, Train Acc: 0.671795 | Val Loss: 0.178764, Val Acc: 0.659794\n",
      "Epoch 6028 - Train Loss: 0.168162, Train Acc: 0.671795 | Val Loss: 0.178753, Val Acc: 0.659794\n",
      "Epoch 6029 - Train Loss: 0.168149, Train Acc: 0.671795 | Val Loss: 0.178742, Val Acc: 0.659794\n",
      "Epoch 6030 - Train Loss: 0.168137, Train Acc: 0.671795 | Val Loss: 0.178730, Val Acc: 0.659794\n",
      "Epoch 6031 - Train Loss: 0.168124, Train Acc: 0.671795 | Val Loss: 0.178719, Val Acc: 0.659794\n",
      "Epoch 6032 - Train Loss: 0.168111, Train Acc: 0.671795 | Val Loss: 0.178707, Val Acc: 0.659794\n",
      "Epoch 6033 - Train Loss: 0.168099, Train Acc: 0.671795 | Val Loss: 0.178696, Val Acc: 0.659794\n",
      "Epoch 6034 - Train Loss: 0.168086, Train Acc: 0.671795 | Val Loss: 0.178685, Val Acc: 0.659794\n",
      "Epoch 6035 - Train Loss: 0.168073, Train Acc: 0.671795 | Val Loss: 0.178673, Val Acc: 0.659794\n",
      "Epoch 6036 - Train Loss: 0.168061, Train Acc: 0.671795 | Val Loss: 0.178662, Val Acc: 0.659794\n",
      "Epoch 6037 - Train Loss: 0.168048, Train Acc: 0.671795 | Val Loss: 0.178651, Val Acc: 0.659794\n",
      "Epoch 6038 - Train Loss: 0.168036, Train Acc: 0.671795 | Val Loss: 0.178639, Val Acc: 0.659794\n",
      "Epoch 6039 - Train Loss: 0.168023, Train Acc: 0.671795 | Val Loss: 0.178628, Val Acc: 0.659794\n",
      "Epoch 6040 - Train Loss: 0.168010, Train Acc: 0.671795 | Val Loss: 0.178617, Val Acc: 0.659794\n",
      "Epoch 6041 - Train Loss: 0.167998, Train Acc: 0.671795 | Val Loss: 0.178605, Val Acc: 0.659794\n",
      "Epoch 6042 - Train Loss: 0.167985, Train Acc: 0.671795 | Val Loss: 0.178594, Val Acc: 0.659794\n",
      "Epoch 6043 - Train Loss: 0.167972, Train Acc: 0.671795 | Val Loss: 0.178583, Val Acc: 0.659794\n",
      "Epoch 6044 - Train Loss: 0.167960, Train Acc: 0.671795 | Val Loss: 0.178571, Val Acc: 0.659794\n",
      "Epoch 6045 - Train Loss: 0.167947, Train Acc: 0.671795 | Val Loss: 0.178560, Val Acc: 0.659794\n",
      "Epoch 6046 - Train Loss: 0.167935, Train Acc: 0.671795 | Val Loss: 0.178549, Val Acc: 0.659794\n",
      "Epoch 6047 - Train Loss: 0.167922, Train Acc: 0.671795 | Val Loss: 0.178537, Val Acc: 0.659794\n",
      "Epoch 6048 - Train Loss: 0.167909, Train Acc: 0.671795 | Val Loss: 0.178526, Val Acc: 0.659794\n",
      "Epoch 6049 - Train Loss: 0.167897, Train Acc: 0.671795 | Val Loss: 0.178515, Val Acc: 0.659794\n",
      "Epoch 6050 - Train Loss: 0.167884, Train Acc: 0.671795 | Val Loss: 0.178503, Val Acc: 0.659794\n",
      "Epoch 6051 - Train Loss: 0.167871, Train Acc: 0.671795 | Val Loss: 0.178492, Val Acc: 0.659794\n",
      "Epoch 6052 - Train Loss: 0.167859, Train Acc: 0.671795 | Val Loss: 0.178481, Val Acc: 0.659794\n",
      "Epoch 6053 - Train Loss: 0.167846, Train Acc: 0.671795 | Val Loss: 0.178469, Val Acc: 0.659794\n",
      "Epoch 6054 - Train Loss: 0.167834, Train Acc: 0.671795 | Val Loss: 0.178458, Val Acc: 0.659794\n",
      "Epoch 6055 - Train Loss: 0.167821, Train Acc: 0.671795 | Val Loss: 0.178447, Val Acc: 0.659794\n",
      "Epoch 6056 - Train Loss: 0.167808, Train Acc: 0.671795 | Val Loss: 0.178435, Val Acc: 0.659794\n",
      "Epoch 6057 - Train Loss: 0.167796, Train Acc: 0.671795 | Val Loss: 0.178424, Val Acc: 0.659794\n",
      "Epoch 6058 - Train Loss: 0.167783, Train Acc: 0.671795 | Val Loss: 0.178413, Val Acc: 0.659794\n",
      "Epoch 6059 - Train Loss: 0.167770, Train Acc: 0.671795 | Val Loss: 0.178401, Val Acc: 0.659794\n",
      "Epoch 6060 - Train Loss: 0.167758, Train Acc: 0.671795 | Val Loss: 0.178390, Val Acc: 0.659794\n",
      "Epoch 6061 - Train Loss: 0.167745, Train Acc: 0.671795 | Val Loss: 0.178379, Val Acc: 0.659794\n",
      "Epoch 6062 - Train Loss: 0.167733, Train Acc: 0.671795 | Val Loss: 0.178367, Val Acc: 0.659794\n",
      "Epoch 6063 - Train Loss: 0.167720, Train Acc: 0.671795 | Val Loss: 0.178356, Val Acc: 0.659794\n",
      "Epoch 6064 - Train Loss: 0.167707, Train Acc: 0.671795 | Val Loss: 0.178345, Val Acc: 0.659794\n",
      "Epoch 6065 - Train Loss: 0.167695, Train Acc: 0.671795 | Val Loss: 0.178334, Val Acc: 0.659794\n",
      "Epoch 6066 - Train Loss: 0.167682, Train Acc: 0.673077 | Val Loss: 0.178322, Val Acc: 0.659794\n",
      "Epoch 6067 - Train Loss: 0.167670, Train Acc: 0.673077 | Val Loss: 0.178311, Val Acc: 0.659794\n",
      "Epoch 6068 - Train Loss: 0.167657, Train Acc: 0.673077 | Val Loss: 0.178300, Val Acc: 0.659794\n",
      "Epoch 6069 - Train Loss: 0.167644, Train Acc: 0.673077 | Val Loss: 0.178288, Val Acc: 0.659794\n",
      "Epoch 6070 - Train Loss: 0.167632, Train Acc: 0.674359 | Val Loss: 0.178277, Val Acc: 0.659794\n",
      "Epoch 6071 - Train Loss: 0.167619, Train Acc: 0.674359 | Val Loss: 0.178266, Val Acc: 0.659794\n",
      "Epoch 6072 - Train Loss: 0.167607, Train Acc: 0.674359 | Val Loss: 0.178254, Val Acc: 0.659794\n",
      "Epoch 6073 - Train Loss: 0.167594, Train Acc: 0.674359 | Val Loss: 0.178243, Val Acc: 0.659794\n",
      "Epoch 6074 - Train Loss: 0.167581, Train Acc: 0.674359 | Val Loss: 0.178232, Val Acc: 0.659794\n",
      "Epoch 6075 - Train Loss: 0.167569, Train Acc: 0.674359 | Val Loss: 0.178220, Val Acc: 0.659794\n",
      "Epoch 6076 - Train Loss: 0.167556, Train Acc: 0.674359 | Val Loss: 0.178209, Val Acc: 0.659794\n",
      "Epoch 6077 - Train Loss: 0.167544, Train Acc: 0.674359 | Val Loss: 0.178198, Val Acc: 0.659794\n",
      "Epoch 6078 - Train Loss: 0.167531, Train Acc: 0.674359 | Val Loss: 0.178187, Val Acc: 0.659794\n",
      "Epoch 6079 - Train Loss: 0.167518, Train Acc: 0.674359 | Val Loss: 0.178175, Val Acc: 0.659794\n",
      "Epoch 6080 - Train Loss: 0.167506, Train Acc: 0.674359 | Val Loss: 0.178164, Val Acc: 0.659794\n",
      "Epoch 6081 - Train Loss: 0.167493, Train Acc: 0.674359 | Val Loss: 0.178153, Val Acc: 0.659794\n",
      "Epoch 6082 - Train Loss: 0.167481, Train Acc: 0.674359 | Val Loss: 0.178141, Val Acc: 0.659794\n",
      "Epoch 6083 - Train Loss: 0.167468, Train Acc: 0.674359 | Val Loss: 0.178130, Val Acc: 0.659794\n",
      "Epoch 6084 - Train Loss: 0.167455, Train Acc: 0.674359 | Val Loss: 0.178119, Val Acc: 0.659794\n",
      "Epoch 6085 - Train Loss: 0.167443, Train Acc: 0.674359 | Val Loss: 0.178108, Val Acc: 0.659794\n",
      "Epoch 6086 - Train Loss: 0.167430, Train Acc: 0.674359 | Val Loss: 0.178096, Val Acc: 0.659794\n",
      "Epoch 6087 - Train Loss: 0.167418, Train Acc: 0.674359 | Val Loss: 0.178085, Val Acc: 0.659794\n",
      "Epoch 6088 - Train Loss: 0.167405, Train Acc: 0.674359 | Val Loss: 0.178074, Val Acc: 0.659794\n",
      "Epoch 6089 - Train Loss: 0.167393, Train Acc: 0.674359 | Val Loss: 0.178062, Val Acc: 0.659794\n",
      "Epoch 6090 - Train Loss: 0.167380, Train Acc: 0.674359 | Val Loss: 0.178051, Val Acc: 0.659794\n",
      "Epoch 6091 - Train Loss: 0.167367, Train Acc: 0.674359 | Val Loss: 0.178040, Val Acc: 0.659794\n",
      "Epoch 6092 - Train Loss: 0.167355, Train Acc: 0.674359 | Val Loss: 0.178029, Val Acc: 0.659794\n",
      "Epoch 6093 - Train Loss: 0.167342, Train Acc: 0.674359 | Val Loss: 0.178017, Val Acc: 0.659794\n",
      "Epoch 6094 - Train Loss: 0.167330, Train Acc: 0.674359 | Val Loss: 0.178006, Val Acc: 0.659794\n",
      "Epoch 6095 - Train Loss: 0.167317, Train Acc: 0.674359 | Val Loss: 0.177995, Val Acc: 0.659794\n",
      "Epoch 6096 - Train Loss: 0.167305, Train Acc: 0.674359 | Val Loss: 0.177984, Val Acc: 0.659794\n",
      "Epoch 6097 - Train Loss: 0.167292, Train Acc: 0.674359 | Val Loss: 0.177972, Val Acc: 0.659794\n",
      "Epoch 6098 - Train Loss: 0.167279, Train Acc: 0.674359 | Val Loss: 0.177961, Val Acc: 0.659794\n",
      "Epoch 6099 - Train Loss: 0.167267, Train Acc: 0.674359 | Val Loss: 0.177950, Val Acc: 0.659794\n",
      "Epoch 6100 - Train Loss: 0.167254, Train Acc: 0.674359 | Val Loss: 0.177938, Val Acc: 0.659794\n",
      "Epoch 6101 - Train Loss: 0.167242, Train Acc: 0.674359 | Val Loss: 0.177927, Val Acc: 0.659794\n",
      "Epoch 6102 - Train Loss: 0.167229, Train Acc: 0.674359 | Val Loss: 0.177916, Val Acc: 0.659794\n",
      "Epoch 6103 - Train Loss: 0.167217, Train Acc: 0.674359 | Val Loss: 0.177905, Val Acc: 0.659794\n",
      "Epoch 6104 - Train Loss: 0.167204, Train Acc: 0.674359 | Val Loss: 0.177893, Val Acc: 0.659794\n",
      "Epoch 6105 - Train Loss: 0.167191, Train Acc: 0.674359 | Val Loss: 0.177882, Val Acc: 0.659794\n",
      "Epoch 6106 - Train Loss: 0.167179, Train Acc: 0.674359 | Val Loss: 0.177871, Val Acc: 0.659794\n",
      "Epoch 6107 - Train Loss: 0.167166, Train Acc: 0.674359 | Val Loss: 0.177860, Val Acc: 0.659794\n",
      "Epoch 6108 - Train Loss: 0.167154, Train Acc: 0.674359 | Val Loss: 0.177848, Val Acc: 0.659794\n",
      "Epoch 6109 - Train Loss: 0.167141, Train Acc: 0.675641 | Val Loss: 0.177837, Val Acc: 0.659794\n",
      "Epoch 6110 - Train Loss: 0.167129, Train Acc: 0.675641 | Val Loss: 0.177826, Val Acc: 0.659794\n",
      "Epoch 6111 - Train Loss: 0.167116, Train Acc: 0.675641 | Val Loss: 0.177815, Val Acc: 0.659794\n",
      "Epoch 6112 - Train Loss: 0.167103, Train Acc: 0.675641 | Val Loss: 0.177803, Val Acc: 0.659794\n",
      "Epoch 6113 - Train Loss: 0.167091, Train Acc: 0.675641 | Val Loss: 0.177792, Val Acc: 0.659794\n",
      "Epoch 6114 - Train Loss: 0.167078, Train Acc: 0.675641 | Val Loss: 0.177781, Val Acc: 0.659794\n",
      "Epoch 6115 - Train Loss: 0.167066, Train Acc: 0.675641 | Val Loss: 0.177770, Val Acc: 0.659794\n",
      "Epoch 6116 - Train Loss: 0.167053, Train Acc: 0.675641 | Val Loss: 0.177758, Val Acc: 0.659794\n",
      "Epoch 6117 - Train Loss: 0.167041, Train Acc: 0.675641 | Val Loss: 0.177747, Val Acc: 0.659794\n",
      "Epoch 6118 - Train Loss: 0.167028, Train Acc: 0.675641 | Val Loss: 0.177736, Val Acc: 0.659794\n",
      "Epoch 6119 - Train Loss: 0.167016, Train Acc: 0.675641 | Val Loss: 0.177725, Val Acc: 0.659794\n",
      "Epoch 6120 - Train Loss: 0.167003, Train Acc: 0.675641 | Val Loss: 0.177713, Val Acc: 0.659794\n",
      "Epoch 6121 - Train Loss: 0.166990, Train Acc: 0.675641 | Val Loss: 0.177702, Val Acc: 0.659794\n",
      "Epoch 6122 - Train Loss: 0.166978, Train Acc: 0.675641 | Val Loss: 0.177691, Val Acc: 0.659794\n",
      "Epoch 6123 - Train Loss: 0.166965, Train Acc: 0.675641 | Val Loss: 0.177680, Val Acc: 0.659794\n",
      "Epoch 6124 - Train Loss: 0.166953, Train Acc: 0.675641 | Val Loss: 0.177668, Val Acc: 0.659794\n",
      "Epoch 6125 - Train Loss: 0.166940, Train Acc: 0.675641 | Val Loss: 0.177657, Val Acc: 0.659794\n",
      "Epoch 6126 - Train Loss: 0.166928, Train Acc: 0.675641 | Val Loss: 0.177646, Val Acc: 0.659794\n",
      "Epoch 6127 - Train Loss: 0.166915, Train Acc: 0.675641 | Val Loss: 0.177635, Val Acc: 0.659794\n",
      "Epoch 6128 - Train Loss: 0.166903, Train Acc: 0.675641 | Val Loss: 0.177623, Val Acc: 0.659794\n",
      "Epoch 6129 - Train Loss: 0.166890, Train Acc: 0.675641 | Val Loss: 0.177612, Val Acc: 0.659794\n",
      "Epoch 6130 - Train Loss: 0.166878, Train Acc: 0.675641 | Val Loss: 0.177601, Val Acc: 0.659794\n",
      "Epoch 6131 - Train Loss: 0.166865, Train Acc: 0.675641 | Val Loss: 0.177590, Val Acc: 0.659794\n",
      "Epoch 6132 - Train Loss: 0.166853, Train Acc: 0.675641 | Val Loss: 0.177578, Val Acc: 0.659794\n",
      "Epoch 6133 - Train Loss: 0.166840, Train Acc: 0.675641 | Val Loss: 0.177567, Val Acc: 0.659794\n",
      "Epoch 6134 - Train Loss: 0.166827, Train Acc: 0.675641 | Val Loss: 0.177556, Val Acc: 0.659794\n",
      "Epoch 6135 - Train Loss: 0.166815, Train Acc: 0.675641 | Val Loss: 0.177545, Val Acc: 0.659794\n",
      "Epoch 6136 - Train Loss: 0.166802, Train Acc: 0.675641 | Val Loss: 0.177534, Val Acc: 0.659794\n",
      "Epoch 6137 - Train Loss: 0.166790, Train Acc: 0.675641 | Val Loss: 0.177522, Val Acc: 0.659794\n",
      "Epoch 6138 - Train Loss: 0.166777, Train Acc: 0.675641 | Val Loss: 0.177511, Val Acc: 0.659794\n",
      "Epoch 6139 - Train Loss: 0.166765, Train Acc: 0.675641 | Val Loss: 0.177500, Val Acc: 0.659794\n",
      "Epoch 6140 - Train Loss: 0.166752, Train Acc: 0.675641 | Val Loss: 0.177489, Val Acc: 0.659794\n",
      "Epoch 6141 - Train Loss: 0.166740, Train Acc: 0.675641 | Val Loss: 0.177477, Val Acc: 0.659794\n",
      "Epoch 6142 - Train Loss: 0.166727, Train Acc: 0.675641 | Val Loss: 0.177466, Val Acc: 0.659794\n",
      "Epoch 6143 - Train Loss: 0.166715, Train Acc: 0.675641 | Val Loss: 0.177455, Val Acc: 0.659794\n",
      "Epoch 6144 - Train Loss: 0.166702, Train Acc: 0.675641 | Val Loss: 0.177444, Val Acc: 0.659794\n",
      "Epoch 6145 - Train Loss: 0.166690, Train Acc: 0.675641 | Val Loss: 0.177433, Val Acc: 0.659794\n",
      "Epoch 6146 - Train Loss: 0.166677, Train Acc: 0.675641 | Val Loss: 0.177421, Val Acc: 0.659794\n",
      "Epoch 6147 - Train Loss: 0.166665, Train Acc: 0.675641 | Val Loss: 0.177410, Val Acc: 0.659794\n",
      "Epoch 6148 - Train Loss: 0.166652, Train Acc: 0.675641 | Val Loss: 0.177399, Val Acc: 0.659794\n",
      "Epoch 6149 - Train Loss: 0.166640, Train Acc: 0.675641 | Val Loss: 0.177388, Val Acc: 0.659794\n",
      "Epoch 6150 - Train Loss: 0.166627, Train Acc: 0.675641 | Val Loss: 0.177376, Val Acc: 0.659794\n",
      "Epoch 6151 - Train Loss: 0.166615, Train Acc: 0.675641 | Val Loss: 0.177365, Val Acc: 0.659794\n",
      "Epoch 6152 - Train Loss: 0.166602, Train Acc: 0.675641 | Val Loss: 0.177354, Val Acc: 0.659794\n",
      "Epoch 6153 - Train Loss: 0.166590, Train Acc: 0.675641 | Val Loss: 0.177343, Val Acc: 0.659794\n",
      "Epoch 6154 - Train Loss: 0.166577, Train Acc: 0.675641 | Val Loss: 0.177332, Val Acc: 0.659794\n",
      "Epoch 6155 - Train Loss: 0.166565, Train Acc: 0.675641 | Val Loss: 0.177320, Val Acc: 0.659794\n",
      "Epoch 6156 - Train Loss: 0.166552, Train Acc: 0.675641 | Val Loss: 0.177309, Val Acc: 0.659794\n",
      "Epoch 6157 - Train Loss: 0.166540, Train Acc: 0.675641 | Val Loss: 0.177298, Val Acc: 0.659794\n",
      "Epoch 6158 - Train Loss: 0.166527, Train Acc: 0.675641 | Val Loss: 0.177287, Val Acc: 0.659794\n",
      "Epoch 6159 - Train Loss: 0.166514, Train Acc: 0.675641 | Val Loss: 0.177276, Val Acc: 0.659794\n",
      "Epoch 6160 - Train Loss: 0.166502, Train Acc: 0.675641 | Val Loss: 0.177264, Val Acc: 0.659794\n",
      "Epoch 6161 - Train Loss: 0.166489, Train Acc: 0.675641 | Val Loss: 0.177253, Val Acc: 0.659794\n",
      "Epoch 6162 - Train Loss: 0.166477, Train Acc: 0.675641 | Val Loss: 0.177242, Val Acc: 0.659794\n",
      "Epoch 6163 - Train Loss: 0.166464, Train Acc: 0.675641 | Val Loss: 0.177231, Val Acc: 0.659794\n",
      "Epoch 6164 - Train Loss: 0.166452, Train Acc: 0.675641 | Val Loss: 0.177220, Val Acc: 0.659794\n",
      "Epoch 6165 - Train Loss: 0.166439, Train Acc: 0.675641 | Val Loss: 0.177209, Val Acc: 0.659794\n",
      "Epoch 6166 - Train Loss: 0.166427, Train Acc: 0.675641 | Val Loss: 0.177197, Val Acc: 0.659794\n",
      "Epoch 6167 - Train Loss: 0.166414, Train Acc: 0.675641 | Val Loss: 0.177186, Val Acc: 0.659794\n",
      "Epoch 6168 - Train Loss: 0.166402, Train Acc: 0.675641 | Val Loss: 0.177175, Val Acc: 0.659794\n",
      "Epoch 6169 - Train Loss: 0.166389, Train Acc: 0.675641 | Val Loss: 0.177164, Val Acc: 0.659794\n",
      "Epoch 6170 - Train Loss: 0.166377, Train Acc: 0.675641 | Val Loss: 0.177153, Val Acc: 0.659794\n",
      "Epoch 6171 - Train Loss: 0.166365, Train Acc: 0.675641 | Val Loss: 0.177141, Val Acc: 0.659794\n",
      "Epoch 6172 - Train Loss: 0.166352, Train Acc: 0.675641 | Val Loss: 0.177130, Val Acc: 0.659794\n",
      "Epoch 6173 - Train Loss: 0.166340, Train Acc: 0.675641 | Val Loss: 0.177119, Val Acc: 0.659794\n",
      "Epoch 6174 - Train Loss: 0.166327, Train Acc: 0.675641 | Val Loss: 0.177108, Val Acc: 0.659794\n",
      "Epoch 6175 - Train Loss: 0.166315, Train Acc: 0.675641 | Val Loss: 0.177097, Val Acc: 0.659794\n",
      "Epoch 6176 - Train Loss: 0.166302, Train Acc: 0.675641 | Val Loss: 0.177086, Val Acc: 0.659794\n",
      "Epoch 6177 - Train Loss: 0.166290, Train Acc: 0.675641 | Val Loss: 0.177074, Val Acc: 0.659794\n",
      "Epoch 6178 - Train Loss: 0.166277, Train Acc: 0.675641 | Val Loss: 0.177063, Val Acc: 0.659794\n",
      "Epoch 6179 - Train Loss: 0.166265, Train Acc: 0.675641 | Val Loss: 0.177052, Val Acc: 0.659794\n",
      "Epoch 6180 - Train Loss: 0.166252, Train Acc: 0.676923 | Val Loss: 0.177041, Val Acc: 0.659794\n",
      "Epoch 6181 - Train Loss: 0.166240, Train Acc: 0.676923 | Val Loss: 0.177030, Val Acc: 0.659794\n",
      "Epoch 6182 - Train Loss: 0.166227, Train Acc: 0.676923 | Val Loss: 0.177018, Val Acc: 0.659794\n",
      "Epoch 6183 - Train Loss: 0.166215, Train Acc: 0.676923 | Val Loss: 0.177007, Val Acc: 0.659794\n",
      "Epoch 6184 - Train Loss: 0.166202, Train Acc: 0.676923 | Val Loss: 0.176996, Val Acc: 0.659794\n",
      "Epoch 6185 - Train Loss: 0.166190, Train Acc: 0.676923 | Val Loss: 0.176985, Val Acc: 0.659794\n",
      "Epoch 6186 - Train Loss: 0.166177, Train Acc: 0.676923 | Val Loss: 0.176974, Val Acc: 0.659794\n",
      "Epoch 6187 - Train Loss: 0.166165, Train Acc: 0.676923 | Val Loss: 0.176963, Val Acc: 0.659794\n",
      "Epoch 6188 - Train Loss: 0.166152, Train Acc: 0.676923 | Val Loss: 0.176951, Val Acc: 0.659794\n",
      "Epoch 6189 - Train Loss: 0.166140, Train Acc: 0.676923 | Val Loss: 0.176940, Val Acc: 0.659794\n",
      "Epoch 6190 - Train Loss: 0.166127, Train Acc: 0.676923 | Val Loss: 0.176929, Val Acc: 0.659794\n",
      "Epoch 6191 - Train Loss: 0.166115, Train Acc: 0.676923 | Val Loss: 0.176918, Val Acc: 0.659794\n",
      "Epoch 6192 - Train Loss: 0.166102, Train Acc: 0.676923 | Val Loss: 0.176907, Val Acc: 0.659794\n",
      "Epoch 6193 - Train Loss: 0.166090, Train Acc: 0.676923 | Val Loss: 0.176896, Val Acc: 0.659794\n",
      "Epoch 6194 - Train Loss: 0.166077, Train Acc: 0.676923 | Val Loss: 0.176885, Val Acc: 0.659794\n",
      "Epoch 6195 - Train Loss: 0.166065, Train Acc: 0.676923 | Val Loss: 0.176873, Val Acc: 0.659794\n",
      "Epoch 6196 - Train Loss: 0.166053, Train Acc: 0.676923 | Val Loss: 0.176862, Val Acc: 0.659794\n",
      "Epoch 6197 - Train Loss: 0.166040, Train Acc: 0.676923 | Val Loss: 0.176851, Val Acc: 0.659794\n",
      "Epoch 6198 - Train Loss: 0.166028, Train Acc: 0.676923 | Val Loss: 0.176840, Val Acc: 0.659794\n",
      "Epoch 6199 - Train Loss: 0.166015, Train Acc: 0.676923 | Val Loss: 0.176829, Val Acc: 0.659794\n",
      "Epoch 6200 - Train Loss: 0.166003, Train Acc: 0.676923 | Val Loss: 0.176818, Val Acc: 0.659794\n",
      "Epoch 6201 - Train Loss: 0.165990, Train Acc: 0.676923 | Val Loss: 0.176806, Val Acc: 0.659794\n",
      "Epoch 6202 - Train Loss: 0.165978, Train Acc: 0.676923 | Val Loss: 0.176795, Val Acc: 0.659794\n",
      "Epoch 6203 - Train Loss: 0.165965, Train Acc: 0.676923 | Val Loss: 0.176784, Val Acc: 0.659794\n",
      "Epoch 6204 - Train Loss: 0.165953, Train Acc: 0.676923 | Val Loss: 0.176773, Val Acc: 0.659794\n",
      "Epoch 6205 - Train Loss: 0.165940, Train Acc: 0.676923 | Val Loss: 0.176762, Val Acc: 0.659794\n",
      "Epoch 6206 - Train Loss: 0.165928, Train Acc: 0.676923 | Val Loss: 0.176751, Val Acc: 0.659794\n",
      "Epoch 6207 - Train Loss: 0.165916, Train Acc: 0.676923 | Val Loss: 0.176740, Val Acc: 0.659794\n",
      "Epoch 6208 - Train Loss: 0.165903, Train Acc: 0.676923 | Val Loss: 0.176728, Val Acc: 0.659794\n",
      "Epoch 6209 - Train Loss: 0.165891, Train Acc: 0.676923 | Val Loss: 0.176717, Val Acc: 0.659794\n",
      "Epoch 6210 - Train Loss: 0.165878, Train Acc: 0.676923 | Val Loss: 0.176706, Val Acc: 0.659794\n",
      "Epoch 6211 - Train Loss: 0.165866, Train Acc: 0.676923 | Val Loss: 0.176695, Val Acc: 0.659794\n",
      "Epoch 6212 - Train Loss: 0.165853, Train Acc: 0.676923 | Val Loss: 0.176684, Val Acc: 0.659794\n",
      "Epoch 6213 - Train Loss: 0.165841, Train Acc: 0.676923 | Val Loss: 0.176673, Val Acc: 0.659794\n",
      "Epoch 6214 - Train Loss: 0.165828, Train Acc: 0.676923 | Val Loss: 0.176662, Val Acc: 0.659794\n",
      "Epoch 6215 - Train Loss: 0.165816, Train Acc: 0.676923 | Val Loss: 0.176651, Val Acc: 0.659794\n",
      "Epoch 6216 - Train Loss: 0.165803, Train Acc: 0.676923 | Val Loss: 0.176639, Val Acc: 0.659794\n",
      "Epoch 6217 - Train Loss: 0.165791, Train Acc: 0.676923 | Val Loss: 0.176628, Val Acc: 0.659794\n",
      "Epoch 6218 - Train Loss: 0.165779, Train Acc: 0.676923 | Val Loss: 0.176617, Val Acc: 0.659794\n",
      "Epoch 6219 - Train Loss: 0.165766, Train Acc: 0.676923 | Val Loss: 0.176606, Val Acc: 0.659794\n",
      "Epoch 6220 - Train Loss: 0.165754, Train Acc: 0.676923 | Val Loss: 0.176595, Val Acc: 0.659794\n",
      "Epoch 6221 - Train Loss: 0.165741, Train Acc: 0.676923 | Val Loss: 0.176584, Val Acc: 0.659794\n",
      "Epoch 6222 - Train Loss: 0.165729, Train Acc: 0.676923 | Val Loss: 0.176573, Val Acc: 0.659794\n",
      "Epoch 6223 - Train Loss: 0.165716, Train Acc: 0.676923 | Val Loss: 0.176562, Val Acc: 0.659794\n",
      "Epoch 6224 - Train Loss: 0.165704, Train Acc: 0.676923 | Val Loss: 0.176550, Val Acc: 0.659794\n",
      "Epoch 6225 - Train Loss: 0.165692, Train Acc: 0.676923 | Val Loss: 0.176539, Val Acc: 0.659794\n",
      "Epoch 6226 - Train Loss: 0.165679, Train Acc: 0.676923 | Val Loss: 0.176528, Val Acc: 0.659794\n",
      "Epoch 6227 - Train Loss: 0.165667, Train Acc: 0.676923 | Val Loss: 0.176517, Val Acc: 0.659794\n",
      "Epoch 6228 - Train Loss: 0.165654, Train Acc: 0.676923 | Val Loss: 0.176506, Val Acc: 0.659794\n",
      "Epoch 6229 - Train Loss: 0.165642, Train Acc: 0.676923 | Val Loss: 0.176495, Val Acc: 0.659794\n",
      "Epoch 6230 - Train Loss: 0.165629, Train Acc: 0.676923 | Val Loss: 0.176484, Val Acc: 0.659794\n",
      "Epoch 6231 - Train Loss: 0.165617, Train Acc: 0.676923 | Val Loss: 0.176473, Val Acc: 0.659794\n",
      "Epoch 6232 - Train Loss: 0.165605, Train Acc: 0.676923 | Val Loss: 0.176462, Val Acc: 0.659794\n",
      "Epoch 6233 - Train Loss: 0.165592, Train Acc: 0.676923 | Val Loss: 0.176450, Val Acc: 0.659794\n",
      "Epoch 6234 - Train Loss: 0.165580, Train Acc: 0.676923 | Val Loss: 0.176439, Val Acc: 0.659794\n",
      "Epoch 6235 - Train Loss: 0.165567, Train Acc: 0.676923 | Val Loss: 0.176428, Val Acc: 0.659794\n",
      "Epoch 6236 - Train Loss: 0.165555, Train Acc: 0.676923 | Val Loss: 0.176417, Val Acc: 0.659794\n",
      "Epoch 6237 - Train Loss: 0.165542, Train Acc: 0.676923 | Val Loss: 0.176406, Val Acc: 0.659794\n",
      "Epoch 6238 - Train Loss: 0.165530, Train Acc: 0.676923 | Val Loss: 0.176395, Val Acc: 0.659794\n",
      "Epoch 6239 - Train Loss: 0.165518, Train Acc: 0.676923 | Val Loss: 0.176384, Val Acc: 0.659794\n",
      "Epoch 6240 - Train Loss: 0.165505, Train Acc: 0.676923 | Val Loss: 0.176373, Val Acc: 0.659794\n",
      "Epoch 6241 - Train Loss: 0.165493, Train Acc: 0.676923 | Val Loss: 0.176362, Val Acc: 0.659794\n",
      "Epoch 6242 - Train Loss: 0.165480, Train Acc: 0.676923 | Val Loss: 0.176350, Val Acc: 0.659794\n",
      "Epoch 6243 - Train Loss: 0.165468, Train Acc: 0.676923 | Val Loss: 0.176339, Val Acc: 0.659794\n",
      "Epoch 6244 - Train Loss: 0.165455, Train Acc: 0.678205 | Val Loss: 0.176328, Val Acc: 0.659794\n",
      "Epoch 6245 - Train Loss: 0.165443, Train Acc: 0.678205 | Val Loss: 0.176317, Val Acc: 0.659794\n",
      "Epoch 6246 - Train Loss: 0.165431, Train Acc: 0.680769 | Val Loss: 0.176306, Val Acc: 0.659794\n",
      "Epoch 6247 - Train Loss: 0.165418, Train Acc: 0.680769 | Val Loss: 0.176295, Val Acc: 0.659794\n",
      "Epoch 6248 - Train Loss: 0.165406, Train Acc: 0.680769 | Val Loss: 0.176284, Val Acc: 0.659794\n",
      "Epoch 6249 - Train Loss: 0.165393, Train Acc: 0.680769 | Val Loss: 0.176273, Val Acc: 0.659794\n",
      "Epoch 6250 - Train Loss: 0.165381, Train Acc: 0.680769 | Val Loss: 0.176262, Val Acc: 0.659794\n",
      "Epoch 6251 - Train Loss: 0.165369, Train Acc: 0.680769 | Val Loss: 0.176251, Val Acc: 0.659794\n",
      "Epoch 6252 - Train Loss: 0.165356, Train Acc: 0.680769 | Val Loss: 0.176240, Val Acc: 0.659794\n",
      "Epoch 6253 - Train Loss: 0.165344, Train Acc: 0.682051 | Val Loss: 0.176229, Val Acc: 0.659794\n",
      "Epoch 6254 - Train Loss: 0.165331, Train Acc: 0.682051 | Val Loss: 0.176217, Val Acc: 0.659794\n",
      "Epoch 6255 - Train Loss: 0.165319, Train Acc: 0.682051 | Val Loss: 0.176206, Val Acc: 0.659794\n",
      "Epoch 6256 - Train Loss: 0.165307, Train Acc: 0.682051 | Val Loss: 0.176195, Val Acc: 0.659794\n",
      "Epoch 6257 - Train Loss: 0.165294, Train Acc: 0.682051 | Val Loss: 0.176184, Val Acc: 0.659794\n",
      "Epoch 6258 - Train Loss: 0.165282, Train Acc: 0.682051 | Val Loss: 0.176173, Val Acc: 0.659794\n",
      "Epoch 6259 - Train Loss: 0.165269, Train Acc: 0.682051 | Val Loss: 0.176162, Val Acc: 0.659794\n",
      "Epoch 6260 - Train Loss: 0.165257, Train Acc: 0.682051 | Val Loss: 0.176151, Val Acc: 0.659794\n",
      "Epoch 6261 - Train Loss: 0.165245, Train Acc: 0.682051 | Val Loss: 0.176140, Val Acc: 0.659794\n",
      "Epoch 6262 - Train Loss: 0.165232, Train Acc: 0.682051 | Val Loss: 0.176129, Val Acc: 0.659794\n",
      "Epoch 6263 - Train Loss: 0.165220, Train Acc: 0.683333 | Val Loss: 0.176118, Val Acc: 0.659794\n",
      "Epoch 6264 - Train Loss: 0.165207, Train Acc: 0.683333 | Val Loss: 0.176107, Val Acc: 0.659794\n",
      "Epoch 6265 - Train Loss: 0.165195, Train Acc: 0.683333 | Val Loss: 0.176096, Val Acc: 0.659794\n",
      "Epoch 6266 - Train Loss: 0.165183, Train Acc: 0.683333 | Val Loss: 0.176085, Val Acc: 0.659794\n",
      "Epoch 6267 - Train Loss: 0.165170, Train Acc: 0.683333 | Val Loss: 0.176074, Val Acc: 0.659794\n",
      "Epoch 6268 - Train Loss: 0.165158, Train Acc: 0.683333 | Val Loss: 0.176063, Val Acc: 0.659794\n",
      "Epoch 6269 - Train Loss: 0.165146, Train Acc: 0.683333 | Val Loss: 0.176051, Val Acc: 0.659794\n",
      "Epoch 6270 - Train Loss: 0.165133, Train Acc: 0.683333 | Val Loss: 0.176040, Val Acc: 0.659794\n",
      "Epoch 6271 - Train Loss: 0.165121, Train Acc: 0.683333 | Val Loss: 0.176029, Val Acc: 0.659794\n",
      "Epoch 6272 - Train Loss: 0.165108, Train Acc: 0.683333 | Val Loss: 0.176018, Val Acc: 0.659794\n",
      "Epoch 6273 - Train Loss: 0.165096, Train Acc: 0.683333 | Val Loss: 0.176007, Val Acc: 0.659794\n",
      "Epoch 6274 - Train Loss: 0.165084, Train Acc: 0.683333 | Val Loss: 0.175996, Val Acc: 0.659794\n",
      "Epoch 6275 - Train Loss: 0.165071, Train Acc: 0.683333 | Val Loss: 0.175985, Val Acc: 0.659794\n",
      "Epoch 6276 - Train Loss: 0.165059, Train Acc: 0.683333 | Val Loss: 0.175974, Val Acc: 0.659794\n",
      "Epoch 6277 - Train Loss: 0.165047, Train Acc: 0.683333 | Val Loss: 0.175963, Val Acc: 0.659794\n",
      "Epoch 6278 - Train Loss: 0.165034, Train Acc: 0.683333 | Val Loss: 0.175952, Val Acc: 0.659794\n",
      "Epoch 6279 - Train Loss: 0.165022, Train Acc: 0.683333 | Val Loss: 0.175941, Val Acc: 0.659794\n",
      "Epoch 6280 - Train Loss: 0.165009, Train Acc: 0.683333 | Val Loss: 0.175930, Val Acc: 0.659794\n",
      "Epoch 6281 - Train Loss: 0.164997, Train Acc: 0.683333 | Val Loss: 0.175919, Val Acc: 0.659794\n",
      "Epoch 6282 - Train Loss: 0.164985, Train Acc: 0.683333 | Val Loss: 0.175908, Val Acc: 0.659794\n",
      "Epoch 6283 - Train Loss: 0.164972, Train Acc: 0.683333 | Val Loss: 0.175897, Val Acc: 0.659794\n",
      "Epoch 6284 - Train Loss: 0.164960, Train Acc: 0.683333 | Val Loss: 0.175886, Val Acc: 0.659794\n",
      "Epoch 6285 - Train Loss: 0.164948, Train Acc: 0.683333 | Val Loss: 0.175875, Val Acc: 0.659794\n",
      "Epoch 6286 - Train Loss: 0.164935, Train Acc: 0.683333 | Val Loss: 0.175864, Val Acc: 0.659794\n",
      "Epoch 6287 - Train Loss: 0.164923, Train Acc: 0.683333 | Val Loss: 0.175853, Val Acc: 0.659794\n",
      "Epoch 6288 - Train Loss: 0.164910, Train Acc: 0.683333 | Val Loss: 0.175842, Val Acc: 0.659794\n",
      "Epoch 6289 - Train Loss: 0.164898, Train Acc: 0.683333 | Val Loss: 0.175830, Val Acc: 0.659794\n",
      "Epoch 6290 - Train Loss: 0.164886, Train Acc: 0.683333 | Val Loss: 0.175819, Val Acc: 0.659794\n",
      "Epoch 6291 - Train Loss: 0.164873, Train Acc: 0.683333 | Val Loss: 0.175808, Val Acc: 0.659794\n",
      "Epoch 6292 - Train Loss: 0.164861, Train Acc: 0.683333 | Val Loss: 0.175797, Val Acc: 0.659794\n",
      "Epoch 6293 - Train Loss: 0.164849, Train Acc: 0.683333 | Val Loss: 0.175786, Val Acc: 0.659794\n",
      "Epoch 6294 - Train Loss: 0.164836, Train Acc: 0.683333 | Val Loss: 0.175775, Val Acc: 0.659794\n",
      "Epoch 6295 - Train Loss: 0.164824, Train Acc: 0.683333 | Val Loss: 0.175764, Val Acc: 0.659794\n",
      "Epoch 6296 - Train Loss: 0.164812, Train Acc: 0.683333 | Val Loss: 0.175753, Val Acc: 0.659794\n",
      "Epoch 6297 - Train Loss: 0.164799, Train Acc: 0.683333 | Val Loss: 0.175742, Val Acc: 0.659794\n",
      "Epoch 6298 - Train Loss: 0.164787, Train Acc: 0.683333 | Val Loss: 0.175731, Val Acc: 0.659794\n",
      "Epoch 6299 - Train Loss: 0.164774, Train Acc: 0.683333 | Val Loss: 0.175720, Val Acc: 0.659794\n",
      "Epoch 6300 - Train Loss: 0.164762, Train Acc: 0.683333 | Val Loss: 0.175709, Val Acc: 0.659794\n",
      "Epoch 6301 - Train Loss: 0.164750, Train Acc: 0.683333 | Val Loss: 0.175698, Val Acc: 0.659794\n",
      "Epoch 6302 - Train Loss: 0.164737, Train Acc: 0.683333 | Val Loss: 0.175687, Val Acc: 0.659794\n",
      "Epoch 6303 - Train Loss: 0.164725, Train Acc: 0.683333 | Val Loss: 0.175676, Val Acc: 0.659794\n",
      "Epoch 6304 - Train Loss: 0.164713, Train Acc: 0.683333 | Val Loss: 0.175665, Val Acc: 0.659794\n",
      "Epoch 6305 - Train Loss: 0.164700, Train Acc: 0.683333 | Val Loss: 0.175654, Val Acc: 0.659794\n",
      "Epoch 6306 - Train Loss: 0.164688, Train Acc: 0.683333 | Val Loss: 0.175643, Val Acc: 0.659794\n",
      "Epoch 6307 - Train Loss: 0.164676, Train Acc: 0.683333 | Val Loss: 0.175632, Val Acc: 0.659794\n",
      "Epoch 6308 - Train Loss: 0.164663, Train Acc: 0.683333 | Val Loss: 0.175621, Val Acc: 0.659794\n",
      "Epoch 6309 - Train Loss: 0.164651, Train Acc: 0.683333 | Val Loss: 0.175610, Val Acc: 0.659794\n",
      "Epoch 6310 - Train Loss: 0.164639, Train Acc: 0.683333 | Val Loss: 0.175599, Val Acc: 0.659794\n",
      "Epoch 6311 - Train Loss: 0.164626, Train Acc: 0.683333 | Val Loss: 0.175588, Val Acc: 0.659794\n",
      "Epoch 6312 - Train Loss: 0.164614, Train Acc: 0.683333 | Val Loss: 0.175577, Val Acc: 0.659794\n",
      "Epoch 6313 - Train Loss: 0.164602, Train Acc: 0.683333 | Val Loss: 0.175566, Val Acc: 0.659794\n",
      "Epoch 6314 - Train Loss: 0.164589, Train Acc: 0.683333 | Val Loss: 0.175555, Val Acc: 0.659794\n",
      "Epoch 6315 - Train Loss: 0.164577, Train Acc: 0.683333 | Val Loss: 0.175544, Val Acc: 0.659794\n",
      "Epoch 6316 - Train Loss: 0.164565, Train Acc: 0.683333 | Val Loss: 0.175533, Val Acc: 0.659794\n",
      "Epoch 6317 - Train Loss: 0.164552, Train Acc: 0.683333 | Val Loss: 0.175522, Val Acc: 0.659794\n",
      "Epoch 6318 - Train Loss: 0.164540, Train Acc: 0.683333 | Val Loss: 0.175511, Val Acc: 0.659794\n",
      "Epoch 6319 - Train Loss: 0.164528, Train Acc: 0.683333 | Val Loss: 0.175500, Val Acc: 0.659794\n",
      "Epoch 6320 - Train Loss: 0.164515, Train Acc: 0.683333 | Val Loss: 0.175489, Val Acc: 0.659794\n",
      "Epoch 6321 - Train Loss: 0.164503, Train Acc: 0.683333 | Val Loss: 0.175478, Val Acc: 0.659794\n",
      "Epoch 6322 - Train Loss: 0.164491, Train Acc: 0.683333 | Val Loss: 0.175467, Val Acc: 0.659794\n",
      "Epoch 6323 - Train Loss: 0.164478, Train Acc: 0.683333 | Val Loss: 0.175456, Val Acc: 0.659794\n",
      "Epoch 6324 - Train Loss: 0.164466, Train Acc: 0.683333 | Val Loss: 0.175445, Val Acc: 0.659794\n",
      "Epoch 6325 - Train Loss: 0.164454, Train Acc: 0.683333 | Val Loss: 0.175434, Val Acc: 0.659794\n",
      "Epoch 6326 - Train Loss: 0.164441, Train Acc: 0.683333 | Val Loss: 0.175423, Val Acc: 0.659794\n",
      "Epoch 6327 - Train Loss: 0.164429, Train Acc: 0.683333 | Val Loss: 0.175412, Val Acc: 0.659794\n",
      "Epoch 6328 - Train Loss: 0.164417, Train Acc: 0.683333 | Val Loss: 0.175401, Val Acc: 0.659794\n",
      "Epoch 6329 - Train Loss: 0.164404, Train Acc: 0.683333 | Val Loss: 0.175390, Val Acc: 0.659794\n",
      "Epoch 6330 - Train Loss: 0.164392, Train Acc: 0.683333 | Val Loss: 0.175379, Val Acc: 0.659794\n",
      "Epoch 6331 - Train Loss: 0.164380, Train Acc: 0.683333 | Val Loss: 0.175368, Val Acc: 0.659794\n",
      "Epoch 6332 - Train Loss: 0.164367, Train Acc: 0.683333 | Val Loss: 0.175357, Val Acc: 0.659794\n",
      "Epoch 6333 - Train Loss: 0.164355, Train Acc: 0.684615 | Val Loss: 0.175346, Val Acc: 0.659794\n",
      "Epoch 6334 - Train Loss: 0.164343, Train Acc: 0.684615 | Val Loss: 0.175335, Val Acc: 0.659794\n",
      "Epoch 6335 - Train Loss: 0.164331, Train Acc: 0.684615 | Val Loss: 0.175324, Val Acc: 0.659794\n",
      "Epoch 6336 - Train Loss: 0.164318, Train Acc: 0.684615 | Val Loss: 0.175313, Val Acc: 0.659794\n",
      "Epoch 6337 - Train Loss: 0.164306, Train Acc: 0.684615 | Val Loss: 0.175302, Val Acc: 0.659794\n",
      "Epoch 6338 - Train Loss: 0.164294, Train Acc: 0.684615 | Val Loss: 0.175291, Val Acc: 0.659794\n",
      "Epoch 6339 - Train Loss: 0.164281, Train Acc: 0.684615 | Val Loss: 0.175280, Val Acc: 0.659794\n",
      "Epoch 6340 - Train Loss: 0.164269, Train Acc: 0.684615 | Val Loss: 0.175269, Val Acc: 0.659794\n",
      "Epoch 6341 - Train Loss: 0.164257, Train Acc: 0.684615 | Val Loss: 0.175258, Val Acc: 0.659794\n",
      "Epoch 6342 - Train Loss: 0.164244, Train Acc: 0.684615 | Val Loss: 0.175247, Val Acc: 0.659794\n",
      "Epoch 6343 - Train Loss: 0.164232, Train Acc: 0.684615 | Val Loss: 0.175236, Val Acc: 0.659794\n",
      "Epoch 6344 - Train Loss: 0.164220, Train Acc: 0.684615 | Val Loss: 0.175225, Val Acc: 0.659794\n",
      "Epoch 6345 - Train Loss: 0.164207, Train Acc: 0.684615 | Val Loss: 0.175214, Val Acc: 0.659794\n",
      "Epoch 6346 - Train Loss: 0.164195, Train Acc: 0.684615 | Val Loss: 0.175203, Val Acc: 0.659794\n",
      "Epoch 6347 - Train Loss: 0.164183, Train Acc: 0.684615 | Val Loss: 0.175192, Val Acc: 0.659794\n",
      "Epoch 6348 - Train Loss: 0.164171, Train Acc: 0.684615 | Val Loss: 0.175181, Val Acc: 0.659794\n",
      "Epoch 6349 - Train Loss: 0.164158, Train Acc: 0.684615 | Val Loss: 0.175170, Val Acc: 0.659794\n",
      "Epoch 6350 - Train Loss: 0.164146, Train Acc: 0.684615 | Val Loss: 0.175159, Val Acc: 0.659794\n",
      "Epoch 6351 - Train Loss: 0.164134, Train Acc: 0.684615 | Val Loss: 0.175148, Val Acc: 0.659794\n",
      "Epoch 6352 - Train Loss: 0.164121, Train Acc: 0.684615 | Val Loss: 0.175137, Val Acc: 0.659794\n",
      "Epoch 6353 - Train Loss: 0.164109, Train Acc: 0.684615 | Val Loss: 0.175126, Val Acc: 0.659794\n",
      "Epoch 6354 - Train Loss: 0.164097, Train Acc: 0.684615 | Val Loss: 0.175115, Val Acc: 0.659794\n",
      "Epoch 6355 - Train Loss: 0.164085, Train Acc: 0.684615 | Val Loss: 0.175104, Val Acc: 0.659794\n",
      "Epoch 6356 - Train Loss: 0.164072, Train Acc: 0.684615 | Val Loss: 0.175093, Val Acc: 0.659794\n",
      "Epoch 6357 - Train Loss: 0.164060, Train Acc: 0.684615 | Val Loss: 0.175082, Val Acc: 0.659794\n",
      "Epoch 6358 - Train Loss: 0.164048, Train Acc: 0.684615 | Val Loss: 0.175072, Val Acc: 0.659794\n",
      "Epoch 6359 - Train Loss: 0.164035, Train Acc: 0.684615 | Val Loss: 0.175061, Val Acc: 0.659794\n",
      "Epoch 6360 - Train Loss: 0.164023, Train Acc: 0.684615 | Val Loss: 0.175050, Val Acc: 0.659794\n",
      "Epoch 6361 - Train Loss: 0.164011, Train Acc: 0.684615 | Val Loss: 0.175039, Val Acc: 0.659794\n",
      "Epoch 6362 - Train Loss: 0.163999, Train Acc: 0.684615 | Val Loss: 0.175028, Val Acc: 0.659794\n",
      "Epoch 6363 - Train Loss: 0.163986, Train Acc: 0.684615 | Val Loss: 0.175017, Val Acc: 0.659794\n",
      "Epoch 6364 - Train Loss: 0.163974, Train Acc: 0.684615 | Val Loss: 0.175006, Val Acc: 0.659794\n",
      "Epoch 6365 - Train Loss: 0.163962, Train Acc: 0.684615 | Val Loss: 0.174995, Val Acc: 0.659794\n",
      "Epoch 6366 - Train Loss: 0.163949, Train Acc: 0.684615 | Val Loss: 0.174984, Val Acc: 0.659794\n",
      "Epoch 6367 - Train Loss: 0.163937, Train Acc: 0.684615 | Val Loss: 0.174973, Val Acc: 0.659794\n",
      "Epoch 6368 - Train Loss: 0.163925, Train Acc: 0.684615 | Val Loss: 0.174962, Val Acc: 0.659794\n",
      "Epoch 6369 - Train Loss: 0.163913, Train Acc: 0.684615 | Val Loss: 0.174951, Val Acc: 0.659794\n",
      "Epoch 6370 - Train Loss: 0.163900, Train Acc: 0.684615 | Val Loss: 0.174940, Val Acc: 0.659794\n",
      "Epoch 6371 - Train Loss: 0.163888, Train Acc: 0.684615 | Val Loss: 0.174929, Val Acc: 0.659794\n",
      "Epoch 6372 - Train Loss: 0.163876, Train Acc: 0.684615 | Val Loss: 0.174918, Val Acc: 0.659794\n",
      "Epoch 6373 - Train Loss: 0.163863, Train Acc: 0.685897 | Val Loss: 0.174907, Val Acc: 0.659794\n",
      "Epoch 6374 - Train Loss: 0.163851, Train Acc: 0.685897 | Val Loss: 0.174896, Val Acc: 0.659794\n",
      "Epoch 6375 - Train Loss: 0.163839, Train Acc: 0.685897 | Val Loss: 0.174885, Val Acc: 0.659794\n",
      "Epoch 6376 - Train Loss: 0.163827, Train Acc: 0.685897 | Val Loss: 0.174874, Val Acc: 0.659794\n",
      "Epoch 6377 - Train Loss: 0.163814, Train Acc: 0.685897 | Val Loss: 0.174863, Val Acc: 0.659794\n",
      "Epoch 6378 - Train Loss: 0.163802, Train Acc: 0.685897 | Val Loss: 0.174853, Val Acc: 0.659794\n",
      "Epoch 6379 - Train Loss: 0.163790, Train Acc: 0.685897 | Val Loss: 0.174842, Val Acc: 0.659794\n",
      "Epoch 6380 - Train Loss: 0.163778, Train Acc: 0.685897 | Val Loss: 0.174831, Val Acc: 0.659794\n",
      "Epoch 6381 - Train Loss: 0.163765, Train Acc: 0.685897 | Val Loss: 0.174820, Val Acc: 0.659794\n",
      "Epoch 6382 - Train Loss: 0.163753, Train Acc: 0.685897 | Val Loss: 0.174809, Val Acc: 0.659794\n",
      "Epoch 6383 - Train Loss: 0.163741, Train Acc: 0.685897 | Val Loss: 0.174798, Val Acc: 0.659794\n",
      "Epoch 6384 - Train Loss: 0.163729, Train Acc: 0.685897 | Val Loss: 0.174787, Val Acc: 0.659794\n",
      "Epoch 6385 - Train Loss: 0.163716, Train Acc: 0.685897 | Val Loss: 0.174776, Val Acc: 0.659794\n",
      "Epoch 6386 - Train Loss: 0.163704, Train Acc: 0.685897 | Val Loss: 0.174765, Val Acc: 0.659794\n",
      "Epoch 6387 - Train Loss: 0.163692, Train Acc: 0.685897 | Val Loss: 0.174754, Val Acc: 0.659794\n",
      "Epoch 6388 - Train Loss: 0.163679, Train Acc: 0.685897 | Val Loss: 0.174743, Val Acc: 0.659794\n",
      "Epoch 6389 - Train Loss: 0.163667, Train Acc: 0.685897 | Val Loss: 0.174732, Val Acc: 0.659794\n",
      "Epoch 6390 - Train Loss: 0.163655, Train Acc: 0.685897 | Val Loss: 0.174721, Val Acc: 0.659794\n",
      "Epoch 6391 - Train Loss: 0.163643, Train Acc: 0.685897 | Val Loss: 0.174710, Val Acc: 0.659794\n",
      "Epoch 6392 - Train Loss: 0.163630, Train Acc: 0.685897 | Val Loss: 0.174700, Val Acc: 0.659794\n",
      "Epoch 6393 - Train Loss: 0.163618, Train Acc: 0.685897 | Val Loss: 0.174689, Val Acc: 0.659794\n",
      "Epoch 6394 - Train Loss: 0.163606, Train Acc: 0.687179 | Val Loss: 0.174678, Val Acc: 0.659794\n",
      "Epoch 6395 - Train Loss: 0.163594, Train Acc: 0.687179 | Val Loss: 0.174667, Val Acc: 0.659794\n",
      "Epoch 6396 - Train Loss: 0.163581, Train Acc: 0.687179 | Val Loss: 0.174656, Val Acc: 0.659794\n",
      "Epoch 6397 - Train Loss: 0.163569, Train Acc: 0.687179 | Val Loss: 0.174645, Val Acc: 0.659794\n",
      "Epoch 6398 - Train Loss: 0.163557, Train Acc: 0.687179 | Val Loss: 0.174634, Val Acc: 0.659794\n",
      "Epoch 6399 - Train Loss: 0.163545, Train Acc: 0.687179 | Val Loss: 0.174623, Val Acc: 0.659794\n",
      "Epoch 6400 - Train Loss: 0.163532, Train Acc: 0.687179 | Val Loss: 0.174612, Val Acc: 0.659794\n",
      "Epoch 6401 - Train Loss: 0.163520, Train Acc: 0.687179 | Val Loss: 0.174601, Val Acc: 0.659794\n",
      "Epoch 6402 - Train Loss: 0.163508, Train Acc: 0.687179 | Val Loss: 0.174590, Val Acc: 0.659794\n",
      "Epoch 6403 - Train Loss: 0.163496, Train Acc: 0.687179 | Val Loss: 0.174579, Val Acc: 0.659794\n",
      "Epoch 6404 - Train Loss: 0.163484, Train Acc: 0.687179 | Val Loss: 0.174569, Val Acc: 0.659794\n",
      "Epoch 6405 - Train Loss: 0.163471, Train Acc: 0.687179 | Val Loss: 0.174558, Val Acc: 0.659794\n",
      "Epoch 6406 - Train Loss: 0.163459, Train Acc: 0.687179 | Val Loss: 0.174547, Val Acc: 0.659794\n",
      "Epoch 6407 - Train Loss: 0.163447, Train Acc: 0.687179 | Val Loss: 0.174536, Val Acc: 0.659794\n",
      "Epoch 6408 - Train Loss: 0.163435, Train Acc: 0.687179 | Val Loss: 0.174525, Val Acc: 0.659794\n",
      "Epoch 6409 - Train Loss: 0.163422, Train Acc: 0.687179 | Val Loss: 0.174514, Val Acc: 0.659794\n",
      "Epoch 6410 - Train Loss: 0.163410, Train Acc: 0.687179 | Val Loss: 0.174503, Val Acc: 0.659794\n",
      "Epoch 6411 - Train Loss: 0.163398, Train Acc: 0.687179 | Val Loss: 0.174492, Val Acc: 0.659794\n",
      "Epoch 6412 - Train Loss: 0.163386, Train Acc: 0.687179 | Val Loss: 0.174481, Val Acc: 0.659794\n",
      "Epoch 6413 - Train Loss: 0.163373, Train Acc: 0.687179 | Val Loss: 0.174470, Val Acc: 0.659794\n",
      "Epoch 6414 - Train Loss: 0.163361, Train Acc: 0.687179 | Val Loss: 0.174460, Val Acc: 0.659794\n",
      "Epoch 6415 - Train Loss: 0.163349, Train Acc: 0.687179 | Val Loss: 0.174449, Val Acc: 0.659794\n",
      "Epoch 6416 - Train Loss: 0.163337, Train Acc: 0.687179 | Val Loss: 0.174438, Val Acc: 0.659794\n",
      "Epoch 6417 - Train Loss: 0.163325, Train Acc: 0.687179 | Val Loss: 0.174427, Val Acc: 0.659794\n",
      "Epoch 6418 - Train Loss: 0.163312, Train Acc: 0.687179 | Val Loss: 0.174416, Val Acc: 0.659794\n",
      "Epoch 6419 - Train Loss: 0.163300, Train Acc: 0.687179 | Val Loss: 0.174405, Val Acc: 0.659794\n",
      "Epoch 6420 - Train Loss: 0.163288, Train Acc: 0.687179 | Val Loss: 0.174394, Val Acc: 0.659794\n",
      "Epoch 6421 - Train Loss: 0.163276, Train Acc: 0.687179 | Val Loss: 0.174383, Val Acc: 0.659794\n",
      "Epoch 6422 - Train Loss: 0.163263, Train Acc: 0.687179 | Val Loss: 0.174372, Val Acc: 0.659794\n",
      "Epoch 6423 - Train Loss: 0.163251, Train Acc: 0.687179 | Val Loss: 0.174362, Val Acc: 0.659794\n",
      "Epoch 6424 - Train Loss: 0.163239, Train Acc: 0.687179 | Val Loss: 0.174351, Val Acc: 0.659794\n",
      "Epoch 6425 - Train Loss: 0.163227, Train Acc: 0.687179 | Val Loss: 0.174340, Val Acc: 0.659794\n",
      "Epoch 6426 - Train Loss: 0.163215, Train Acc: 0.687179 | Val Loss: 0.174329, Val Acc: 0.659794\n",
      "Epoch 6427 - Train Loss: 0.163202, Train Acc: 0.687179 | Val Loss: 0.174318, Val Acc: 0.659794\n",
      "Epoch 6428 - Train Loss: 0.163190, Train Acc: 0.687179 | Val Loss: 0.174307, Val Acc: 0.659794\n",
      "Epoch 6429 - Train Loss: 0.163178, Train Acc: 0.687179 | Val Loss: 0.174296, Val Acc: 0.659794\n",
      "Epoch 6430 - Train Loss: 0.163166, Train Acc: 0.687179 | Val Loss: 0.174285, Val Acc: 0.659794\n",
      "Epoch 6431 - Train Loss: 0.163153, Train Acc: 0.687179 | Val Loss: 0.174275, Val Acc: 0.659794\n",
      "Epoch 6432 - Train Loss: 0.163141, Train Acc: 0.687179 | Val Loss: 0.174264, Val Acc: 0.659794\n",
      "Epoch 6433 - Train Loss: 0.163129, Train Acc: 0.687179 | Val Loss: 0.174253, Val Acc: 0.659794\n",
      "Epoch 6434 - Train Loss: 0.163117, Train Acc: 0.687179 | Val Loss: 0.174242, Val Acc: 0.659794\n",
      "Epoch 6435 - Train Loss: 0.163105, Train Acc: 0.687179 | Val Loss: 0.174231, Val Acc: 0.659794\n",
      "Epoch 6436 - Train Loss: 0.163092, Train Acc: 0.687179 | Val Loss: 0.174220, Val Acc: 0.659794\n",
      "Epoch 6437 - Train Loss: 0.163080, Train Acc: 0.687179 | Val Loss: 0.174209, Val Acc: 0.659794\n",
      "Epoch 6438 - Train Loss: 0.163068, Train Acc: 0.687179 | Val Loss: 0.174198, Val Acc: 0.659794\n",
      "Epoch 6439 - Train Loss: 0.163056, Train Acc: 0.687179 | Val Loss: 0.174188, Val Acc: 0.659794\n",
      "Epoch 6440 - Train Loss: 0.163044, Train Acc: 0.687179 | Val Loss: 0.174177, Val Acc: 0.659794\n",
      "Epoch 6441 - Train Loss: 0.163031, Train Acc: 0.687179 | Val Loss: 0.174166, Val Acc: 0.659794\n",
      "Epoch 6442 - Train Loss: 0.163019, Train Acc: 0.687179 | Val Loss: 0.174155, Val Acc: 0.659794\n",
      "Epoch 6443 - Train Loss: 0.163007, Train Acc: 0.687179 | Val Loss: 0.174144, Val Acc: 0.659794\n",
      "Epoch 6444 - Train Loss: 0.162995, Train Acc: 0.687179 | Val Loss: 0.174133, Val Acc: 0.659794\n",
      "Epoch 6445 - Train Loss: 0.162983, Train Acc: 0.687179 | Val Loss: 0.174122, Val Acc: 0.659794\n",
      "Epoch 6446 - Train Loss: 0.162970, Train Acc: 0.687179 | Val Loss: 0.174112, Val Acc: 0.659794\n",
      "Epoch 6447 - Train Loss: 0.162958, Train Acc: 0.687179 | Val Loss: 0.174101, Val Acc: 0.659794\n",
      "Epoch 6448 - Train Loss: 0.162946, Train Acc: 0.687179 | Val Loss: 0.174090, Val Acc: 0.659794\n",
      "Epoch 6449 - Train Loss: 0.162934, Train Acc: 0.687179 | Val Loss: 0.174079, Val Acc: 0.659794\n",
      "Epoch 6450 - Train Loss: 0.162922, Train Acc: 0.687179 | Val Loss: 0.174068, Val Acc: 0.659794\n",
      "Epoch 6451 - Train Loss: 0.162909, Train Acc: 0.687179 | Val Loss: 0.174057, Val Acc: 0.659794\n",
      "Epoch 6452 - Train Loss: 0.162897, Train Acc: 0.687179 | Val Loss: 0.174046, Val Acc: 0.659794\n",
      "Epoch 6453 - Train Loss: 0.162885, Train Acc: 0.687179 | Val Loss: 0.174036, Val Acc: 0.659794\n",
      "Epoch 6454 - Train Loss: 0.162873, Train Acc: 0.687179 | Val Loss: 0.174025, Val Acc: 0.659794\n",
      "Epoch 6455 - Train Loss: 0.162861, Train Acc: 0.687179 | Val Loss: 0.174014, Val Acc: 0.659794\n",
      "Epoch 6456 - Train Loss: 0.162849, Train Acc: 0.687179 | Val Loss: 0.174003, Val Acc: 0.659794\n",
      "Epoch 6457 - Train Loss: 0.162836, Train Acc: 0.687179 | Val Loss: 0.173992, Val Acc: 0.659794\n",
      "Epoch 6458 - Train Loss: 0.162824, Train Acc: 0.687179 | Val Loss: 0.173981, Val Acc: 0.659794\n",
      "Epoch 6459 - Train Loss: 0.162812, Train Acc: 0.687179 | Val Loss: 0.173970, Val Acc: 0.659794\n",
      "Epoch 6460 - Train Loss: 0.162800, Train Acc: 0.687179 | Val Loss: 0.173960, Val Acc: 0.659794\n",
      "Epoch 6461 - Train Loss: 0.162788, Train Acc: 0.687179 | Val Loss: 0.173949, Val Acc: 0.659794\n",
      "Epoch 6462 - Train Loss: 0.162775, Train Acc: 0.687179 | Val Loss: 0.173938, Val Acc: 0.659794\n",
      "Epoch 6463 - Train Loss: 0.162763, Train Acc: 0.687179 | Val Loss: 0.173927, Val Acc: 0.659794\n",
      "Epoch 6464 - Train Loss: 0.162751, Train Acc: 0.687179 | Val Loss: 0.173916, Val Acc: 0.659794\n",
      "Epoch 6465 - Train Loss: 0.162739, Train Acc: 0.687179 | Val Loss: 0.173905, Val Acc: 0.659794\n",
      "Epoch 6466 - Train Loss: 0.162727, Train Acc: 0.687179 | Val Loss: 0.173895, Val Acc: 0.659794\n",
      "Epoch 6467 - Train Loss: 0.162715, Train Acc: 0.687179 | Val Loss: 0.173884, Val Acc: 0.659794\n",
      "Epoch 6468 - Train Loss: 0.162702, Train Acc: 0.687179 | Val Loss: 0.173873, Val Acc: 0.659794\n",
      "Epoch 6469 - Train Loss: 0.162690, Train Acc: 0.687179 | Val Loss: 0.173862, Val Acc: 0.659794\n",
      "Epoch 6470 - Train Loss: 0.162678, Train Acc: 0.687179 | Val Loss: 0.173851, Val Acc: 0.659794\n",
      "Epoch 6471 - Train Loss: 0.162666, Train Acc: 0.687179 | Val Loss: 0.173840, Val Acc: 0.659794\n",
      "Epoch 6472 - Train Loss: 0.162654, Train Acc: 0.687179 | Val Loss: 0.173830, Val Acc: 0.659794\n",
      "Epoch 6473 - Train Loss: 0.162642, Train Acc: 0.687179 | Val Loss: 0.173819, Val Acc: 0.659794\n",
      "Epoch 6474 - Train Loss: 0.162629, Train Acc: 0.687179 | Val Loss: 0.173808, Val Acc: 0.659794\n",
      "Epoch 6475 - Train Loss: 0.162617, Train Acc: 0.687179 | Val Loss: 0.173797, Val Acc: 0.659794\n",
      "Epoch 6476 - Train Loss: 0.162605, Train Acc: 0.687179 | Val Loss: 0.173786, Val Acc: 0.659794\n",
      "Epoch 6477 - Train Loss: 0.162593, Train Acc: 0.687179 | Val Loss: 0.173775, Val Acc: 0.659794\n",
      "Epoch 6478 - Train Loss: 0.162581, Train Acc: 0.687179 | Val Loss: 0.173765, Val Acc: 0.659794\n",
      "Epoch 6479 - Train Loss: 0.162569, Train Acc: 0.687179 | Val Loss: 0.173754, Val Acc: 0.659794\n",
      "Epoch 6480 - Train Loss: 0.162556, Train Acc: 0.687179 | Val Loss: 0.173743, Val Acc: 0.659794\n",
      "Epoch 6481 - Train Loss: 0.162544, Train Acc: 0.687179 | Val Loss: 0.173732, Val Acc: 0.659794\n",
      "Epoch 6482 - Train Loss: 0.162532, Train Acc: 0.687179 | Val Loss: 0.173721, Val Acc: 0.659794\n",
      "Epoch 6483 - Train Loss: 0.162520, Train Acc: 0.687179 | Val Loss: 0.173711, Val Acc: 0.659794\n",
      "Epoch 6484 - Train Loss: 0.162508, Train Acc: 0.687179 | Val Loss: 0.173700, Val Acc: 0.659794\n",
      "Epoch 6485 - Train Loss: 0.162496, Train Acc: 0.687179 | Val Loss: 0.173689, Val Acc: 0.659794\n",
      "Epoch 6486 - Train Loss: 0.162483, Train Acc: 0.687179 | Val Loss: 0.173678, Val Acc: 0.659794\n",
      "Epoch 6487 - Train Loss: 0.162471, Train Acc: 0.687179 | Val Loss: 0.173667, Val Acc: 0.659794\n",
      "Epoch 6488 - Train Loss: 0.162459, Train Acc: 0.687179 | Val Loss: 0.173656, Val Acc: 0.659794\n",
      "Epoch 6489 - Train Loss: 0.162447, Train Acc: 0.687179 | Val Loss: 0.173646, Val Acc: 0.659794\n",
      "Epoch 6490 - Train Loss: 0.162435, Train Acc: 0.687179 | Val Loss: 0.173635, Val Acc: 0.659794\n",
      "Epoch 6491 - Train Loss: 0.162423, Train Acc: 0.687179 | Val Loss: 0.173624, Val Acc: 0.659794\n",
      "Epoch 6492 - Train Loss: 0.162411, Train Acc: 0.687179 | Val Loss: 0.173613, Val Acc: 0.659794\n",
      "Epoch 6493 - Train Loss: 0.162398, Train Acc: 0.687179 | Val Loss: 0.173602, Val Acc: 0.659794\n",
      "Epoch 6494 - Train Loss: 0.162386, Train Acc: 0.687179 | Val Loss: 0.173592, Val Acc: 0.659794\n",
      "Epoch 6495 - Train Loss: 0.162374, Train Acc: 0.687179 | Val Loss: 0.173581, Val Acc: 0.659794\n",
      "Epoch 6496 - Train Loss: 0.162362, Train Acc: 0.687179 | Val Loss: 0.173570, Val Acc: 0.659794\n",
      "Epoch 6497 - Train Loss: 0.162350, Train Acc: 0.687179 | Val Loss: 0.173559, Val Acc: 0.659794\n",
      "Epoch 6498 - Train Loss: 0.162338, Train Acc: 0.687179 | Val Loss: 0.173548, Val Acc: 0.659794\n",
      "Epoch 6499 - Train Loss: 0.162326, Train Acc: 0.687179 | Val Loss: 0.173538, Val Acc: 0.659794\n",
      "Epoch 6500 - Train Loss: 0.162313, Train Acc: 0.687179 | Val Loss: 0.173527, Val Acc: 0.659794\n",
      "Epoch 6501 - Train Loss: 0.162301, Train Acc: 0.687179 | Val Loss: 0.173516, Val Acc: 0.659794\n",
      "Epoch 6502 - Train Loss: 0.162289, Train Acc: 0.687179 | Val Loss: 0.173505, Val Acc: 0.659794\n",
      "Epoch 6503 - Train Loss: 0.162277, Train Acc: 0.687179 | Val Loss: 0.173494, Val Acc: 0.659794\n",
      "Epoch 6504 - Train Loss: 0.162265, Train Acc: 0.687179 | Val Loss: 0.173484, Val Acc: 0.659794\n",
      "Epoch 6505 - Train Loss: 0.162253, Train Acc: 0.687179 | Val Loss: 0.173473, Val Acc: 0.659794\n",
      "Epoch 6506 - Train Loss: 0.162241, Train Acc: 0.688462 | Val Loss: 0.173462, Val Acc: 0.659794\n",
      "Epoch 6507 - Train Loss: 0.162228, Train Acc: 0.688462 | Val Loss: 0.173451, Val Acc: 0.659794\n",
      "Epoch 6508 - Train Loss: 0.162216, Train Acc: 0.688462 | Val Loss: 0.173441, Val Acc: 0.659794\n",
      "Epoch 6509 - Train Loss: 0.162204, Train Acc: 0.689744 | Val Loss: 0.173430, Val Acc: 0.659794\n",
      "Epoch 6510 - Train Loss: 0.162192, Train Acc: 0.689744 | Val Loss: 0.173419, Val Acc: 0.659794\n",
      "Epoch 6511 - Train Loss: 0.162180, Train Acc: 0.689744 | Val Loss: 0.173408, Val Acc: 0.659794\n",
      "Epoch 6512 - Train Loss: 0.162168, Train Acc: 0.689744 | Val Loss: 0.173397, Val Acc: 0.659794\n",
      "Epoch 6513 - Train Loss: 0.162156, Train Acc: 0.689744 | Val Loss: 0.173387, Val Acc: 0.659794\n",
      "Epoch 6514 - Train Loss: 0.162144, Train Acc: 0.689744 | Val Loss: 0.173376, Val Acc: 0.659794\n",
      "Epoch 6515 - Train Loss: 0.162131, Train Acc: 0.689744 | Val Loss: 0.173365, Val Acc: 0.659794\n",
      "Epoch 6516 - Train Loss: 0.162119, Train Acc: 0.689744 | Val Loss: 0.173354, Val Acc: 0.659794\n",
      "Epoch 6517 - Train Loss: 0.162107, Train Acc: 0.689744 | Val Loss: 0.173344, Val Acc: 0.659794\n",
      "Epoch 6518 - Train Loss: 0.162095, Train Acc: 0.689744 | Val Loss: 0.173333, Val Acc: 0.659794\n",
      "Epoch 6519 - Train Loss: 0.162083, Train Acc: 0.689744 | Val Loss: 0.173322, Val Acc: 0.659794\n",
      "Epoch 6520 - Train Loss: 0.162071, Train Acc: 0.689744 | Val Loss: 0.173311, Val Acc: 0.659794\n",
      "Epoch 6521 - Train Loss: 0.162059, Train Acc: 0.689744 | Val Loss: 0.173300, Val Acc: 0.659794\n",
      "Epoch 6522 - Train Loss: 0.162047, Train Acc: 0.689744 | Val Loss: 0.173290, Val Acc: 0.659794\n",
      "Epoch 6523 - Train Loss: 0.162035, Train Acc: 0.689744 | Val Loss: 0.173279, Val Acc: 0.659794\n",
      "Epoch 6524 - Train Loss: 0.162022, Train Acc: 0.689744 | Val Loss: 0.173268, Val Acc: 0.659794\n",
      "Epoch 6525 - Train Loss: 0.162010, Train Acc: 0.689744 | Val Loss: 0.173257, Val Acc: 0.659794\n",
      "Epoch 6526 - Train Loss: 0.161998, Train Acc: 0.689744 | Val Loss: 0.173247, Val Acc: 0.659794\n",
      "Epoch 6527 - Train Loss: 0.161986, Train Acc: 0.689744 | Val Loss: 0.173236, Val Acc: 0.659794\n",
      "Epoch 6528 - Train Loss: 0.161974, Train Acc: 0.689744 | Val Loss: 0.173225, Val Acc: 0.659794\n",
      "Epoch 6529 - Train Loss: 0.161962, Train Acc: 0.689744 | Val Loss: 0.173214, Val Acc: 0.659794\n",
      "Epoch 6530 - Train Loss: 0.161950, Train Acc: 0.689744 | Val Loss: 0.173204, Val Acc: 0.659794\n",
      "Epoch 6531 - Train Loss: 0.161938, Train Acc: 0.689744 | Val Loss: 0.173193, Val Acc: 0.659794\n",
      "Epoch 6532 - Train Loss: 0.161926, Train Acc: 0.689744 | Val Loss: 0.173182, Val Acc: 0.659794\n",
      "Epoch 6533 - Train Loss: 0.161913, Train Acc: 0.689744 | Val Loss: 0.173171, Val Acc: 0.659794\n",
      "Epoch 6534 - Train Loss: 0.161901, Train Acc: 0.689744 | Val Loss: 0.173160, Val Acc: 0.659794\n",
      "Epoch 6535 - Train Loss: 0.161889, Train Acc: 0.689744 | Val Loss: 0.173150, Val Acc: 0.659794\n",
      "Epoch 6536 - Train Loss: 0.161877, Train Acc: 0.689744 | Val Loss: 0.173139, Val Acc: 0.659794\n",
      "Epoch 6537 - Train Loss: 0.161865, Train Acc: 0.689744 | Val Loss: 0.173128, Val Acc: 0.659794\n",
      "Epoch 6538 - Train Loss: 0.161853, Train Acc: 0.689744 | Val Loss: 0.173117, Val Acc: 0.659794\n",
      "Epoch 6539 - Train Loss: 0.161841, Train Acc: 0.689744 | Val Loss: 0.173107, Val Acc: 0.659794\n",
      "Epoch 6540 - Train Loss: 0.161829, Train Acc: 0.689744 | Val Loss: 0.173096, Val Acc: 0.659794\n",
      "Epoch 6541 - Train Loss: 0.161817, Train Acc: 0.689744 | Val Loss: 0.173085, Val Acc: 0.659794\n",
      "Epoch 6542 - Train Loss: 0.161805, Train Acc: 0.689744 | Val Loss: 0.173074, Val Acc: 0.659794\n",
      "Epoch 6543 - Train Loss: 0.161792, Train Acc: 0.689744 | Val Loss: 0.173064, Val Acc: 0.659794\n",
      "Epoch 6544 - Train Loss: 0.161780, Train Acc: 0.689744 | Val Loss: 0.173053, Val Acc: 0.659794\n",
      "Epoch 6545 - Train Loss: 0.161768, Train Acc: 0.689744 | Val Loss: 0.173042, Val Acc: 0.659794\n",
      "Epoch 6546 - Train Loss: 0.161756, Train Acc: 0.689744 | Val Loss: 0.173031, Val Acc: 0.659794\n",
      "Epoch 6547 - Train Loss: 0.161744, Train Acc: 0.689744 | Val Loss: 0.173021, Val Acc: 0.659794\n",
      "Epoch 6548 - Train Loss: 0.161732, Train Acc: 0.689744 | Val Loss: 0.173010, Val Acc: 0.659794\n",
      "Epoch 6549 - Train Loss: 0.161720, Train Acc: 0.689744 | Val Loss: 0.172999, Val Acc: 0.659794\n",
      "Epoch 6550 - Train Loss: 0.161708, Train Acc: 0.689744 | Val Loss: 0.172989, Val Acc: 0.659794\n",
      "Epoch 6551 - Train Loss: 0.161696, Train Acc: 0.689744 | Val Loss: 0.172978, Val Acc: 0.659794\n",
      "Epoch 6552 - Train Loss: 0.161684, Train Acc: 0.689744 | Val Loss: 0.172967, Val Acc: 0.659794\n",
      "Epoch 6553 - Train Loss: 0.161672, Train Acc: 0.689744 | Val Loss: 0.172956, Val Acc: 0.659794\n",
      "Epoch 6554 - Train Loss: 0.161659, Train Acc: 0.689744 | Val Loss: 0.172946, Val Acc: 0.659794\n",
      "Epoch 6555 - Train Loss: 0.161647, Train Acc: 0.689744 | Val Loss: 0.172935, Val Acc: 0.659794\n",
      "Epoch 6556 - Train Loss: 0.161635, Train Acc: 0.689744 | Val Loss: 0.172924, Val Acc: 0.659794\n",
      "Epoch 6557 - Train Loss: 0.161623, Train Acc: 0.689744 | Val Loss: 0.172913, Val Acc: 0.659794\n",
      "Epoch 6558 - Train Loss: 0.161611, Train Acc: 0.689744 | Val Loss: 0.172903, Val Acc: 0.659794\n",
      "Epoch 6559 - Train Loss: 0.161599, Train Acc: 0.689744 | Val Loss: 0.172892, Val Acc: 0.659794\n",
      "Epoch 6560 - Train Loss: 0.161587, Train Acc: 0.689744 | Val Loss: 0.172881, Val Acc: 0.659794\n",
      "Epoch 6561 - Train Loss: 0.161575, Train Acc: 0.689744 | Val Loss: 0.172870, Val Acc: 0.659794\n",
      "Epoch 6562 - Train Loss: 0.161563, Train Acc: 0.689744 | Val Loss: 0.172860, Val Acc: 0.659794\n",
      "Epoch 6563 - Train Loss: 0.161551, Train Acc: 0.689744 | Val Loss: 0.172849, Val Acc: 0.659794\n",
      "Epoch 6564 - Train Loss: 0.161539, Train Acc: 0.689744 | Val Loss: 0.172838, Val Acc: 0.659794\n",
      "Epoch 6565 - Train Loss: 0.161527, Train Acc: 0.689744 | Val Loss: 0.172828, Val Acc: 0.659794\n",
      "Epoch 6566 - Train Loss: 0.161515, Train Acc: 0.689744 | Val Loss: 0.172817, Val Acc: 0.659794\n",
      "Epoch 6567 - Train Loss: 0.161502, Train Acc: 0.689744 | Val Loss: 0.172806, Val Acc: 0.659794\n",
      "Epoch 6568 - Train Loss: 0.161490, Train Acc: 0.689744 | Val Loss: 0.172795, Val Acc: 0.659794\n",
      "Epoch 6569 - Train Loss: 0.161478, Train Acc: 0.689744 | Val Loss: 0.172785, Val Acc: 0.659794\n",
      "Epoch 6570 - Train Loss: 0.161466, Train Acc: 0.689744 | Val Loss: 0.172774, Val Acc: 0.659794\n",
      "Epoch 6571 - Train Loss: 0.161454, Train Acc: 0.689744 | Val Loss: 0.172763, Val Acc: 0.659794\n",
      "Epoch 6572 - Train Loss: 0.161442, Train Acc: 0.689744 | Val Loss: 0.172752, Val Acc: 0.659794\n",
      "Epoch 6573 - Train Loss: 0.161430, Train Acc: 0.689744 | Val Loss: 0.172742, Val Acc: 0.659794\n",
      "Epoch 6574 - Train Loss: 0.161418, Train Acc: 0.689744 | Val Loss: 0.172731, Val Acc: 0.659794\n",
      "Epoch 6575 - Train Loss: 0.161406, Train Acc: 0.689744 | Val Loss: 0.172720, Val Acc: 0.659794\n",
      "Epoch 6576 - Train Loss: 0.161394, Train Acc: 0.689744 | Val Loss: 0.172710, Val Acc: 0.659794\n",
      "Epoch 6577 - Train Loss: 0.161382, Train Acc: 0.689744 | Val Loss: 0.172699, Val Acc: 0.659794\n",
      "Epoch 6578 - Train Loss: 0.161370, Train Acc: 0.691026 | Val Loss: 0.172688, Val Acc: 0.659794\n",
      "Epoch 6579 - Train Loss: 0.161358, Train Acc: 0.691026 | Val Loss: 0.172678, Val Acc: 0.659794\n",
      "Epoch 6580 - Train Loss: 0.161346, Train Acc: 0.691026 | Val Loss: 0.172667, Val Acc: 0.659794\n",
      "Epoch 6581 - Train Loss: 0.161334, Train Acc: 0.691026 | Val Loss: 0.172656, Val Acc: 0.659794\n",
      "Epoch 6582 - Train Loss: 0.161321, Train Acc: 0.691026 | Val Loss: 0.172645, Val Acc: 0.659794\n",
      "Epoch 6583 - Train Loss: 0.161309, Train Acc: 0.691026 | Val Loss: 0.172635, Val Acc: 0.659794\n",
      "Epoch 6584 - Train Loss: 0.161297, Train Acc: 0.691026 | Val Loss: 0.172624, Val Acc: 0.659794\n",
      "Epoch 6585 - Train Loss: 0.161285, Train Acc: 0.691026 | Val Loss: 0.172613, Val Acc: 0.659794\n",
      "Epoch 6586 - Train Loss: 0.161273, Train Acc: 0.691026 | Val Loss: 0.172603, Val Acc: 0.659794\n",
      "Epoch 6587 - Train Loss: 0.161261, Train Acc: 0.691026 | Val Loss: 0.172592, Val Acc: 0.659794\n",
      "Epoch 6588 - Train Loss: 0.161249, Train Acc: 0.691026 | Val Loss: 0.172581, Val Acc: 0.659794\n",
      "Epoch 6589 - Train Loss: 0.161237, Train Acc: 0.691026 | Val Loss: 0.172571, Val Acc: 0.659794\n",
      "Epoch 6590 - Train Loss: 0.161225, Train Acc: 0.691026 | Val Loss: 0.172560, Val Acc: 0.659794\n",
      "Epoch 6591 - Train Loss: 0.161213, Train Acc: 0.692308 | Val Loss: 0.172549, Val Acc: 0.659794\n",
      "Epoch 6592 - Train Loss: 0.161201, Train Acc: 0.692308 | Val Loss: 0.172538, Val Acc: 0.659794\n",
      "Epoch 6593 - Train Loss: 0.161189, Train Acc: 0.692308 | Val Loss: 0.172528, Val Acc: 0.659794\n",
      "Epoch 6594 - Train Loss: 0.161177, Train Acc: 0.692308 | Val Loss: 0.172517, Val Acc: 0.659794\n",
      "Epoch 6595 - Train Loss: 0.161165, Train Acc: 0.692308 | Val Loss: 0.172506, Val Acc: 0.659794\n",
      "Epoch 6596 - Train Loss: 0.161153, Train Acc: 0.692308 | Val Loss: 0.172496, Val Acc: 0.659794\n",
      "Epoch 6597 - Train Loss: 0.161141, Train Acc: 0.692308 | Val Loss: 0.172485, Val Acc: 0.659794\n",
      "Epoch 6598 - Train Loss: 0.161129, Train Acc: 0.692308 | Val Loss: 0.172474, Val Acc: 0.659794\n",
      "Epoch 6599 - Train Loss: 0.161117, Train Acc: 0.692308 | Val Loss: 0.172464, Val Acc: 0.659794\n",
      "Epoch 6600 - Train Loss: 0.161105, Train Acc: 0.692308 | Val Loss: 0.172453, Val Acc: 0.659794\n",
      "Epoch 6601 - Train Loss: 0.161093, Train Acc: 0.692308 | Val Loss: 0.172442, Val Acc: 0.659794\n",
      "Epoch 6602 - Train Loss: 0.161081, Train Acc: 0.692308 | Val Loss: 0.172432, Val Acc: 0.659794\n",
      "Epoch 6603 - Train Loss: 0.161069, Train Acc: 0.692308 | Val Loss: 0.172421, Val Acc: 0.659794\n",
      "Epoch 6604 - Train Loss: 0.161057, Train Acc: 0.692308 | Val Loss: 0.172410, Val Acc: 0.659794\n",
      "Epoch 6605 - Train Loss: 0.161044, Train Acc: 0.693590 | Val Loss: 0.172400, Val Acc: 0.659794\n",
      "Epoch 6606 - Train Loss: 0.161032, Train Acc: 0.693590 | Val Loss: 0.172389, Val Acc: 0.659794\n",
      "Epoch 6607 - Train Loss: 0.161020, Train Acc: 0.693590 | Val Loss: 0.172378, Val Acc: 0.659794\n",
      "Epoch 6608 - Train Loss: 0.161008, Train Acc: 0.693590 | Val Loss: 0.172367, Val Acc: 0.659794\n",
      "Epoch 6609 - Train Loss: 0.160996, Train Acc: 0.693590 | Val Loss: 0.172357, Val Acc: 0.659794\n",
      "Epoch 6610 - Train Loss: 0.160984, Train Acc: 0.693590 | Val Loss: 0.172346, Val Acc: 0.659794\n",
      "Epoch 6611 - Train Loss: 0.160972, Train Acc: 0.693590 | Val Loss: 0.172335, Val Acc: 0.659794\n",
      "Epoch 6612 - Train Loss: 0.160960, Train Acc: 0.694872 | Val Loss: 0.172325, Val Acc: 0.659794\n",
      "Epoch 6613 - Train Loss: 0.160948, Train Acc: 0.694872 | Val Loss: 0.172314, Val Acc: 0.659794\n",
      "Epoch 6614 - Train Loss: 0.160936, Train Acc: 0.694872 | Val Loss: 0.172303, Val Acc: 0.659794\n",
      "Epoch 6615 - Train Loss: 0.160924, Train Acc: 0.694872 | Val Loss: 0.172293, Val Acc: 0.659794\n",
      "Epoch 6616 - Train Loss: 0.160912, Train Acc: 0.693590 | Val Loss: 0.172282, Val Acc: 0.659794\n",
      "Epoch 6617 - Train Loss: 0.160900, Train Acc: 0.693590 | Val Loss: 0.172271, Val Acc: 0.659794\n",
      "Epoch 6618 - Train Loss: 0.160888, Train Acc: 0.693590 | Val Loss: 0.172261, Val Acc: 0.659794\n",
      "Epoch 6619 - Train Loss: 0.160876, Train Acc: 0.693590 | Val Loss: 0.172250, Val Acc: 0.659794\n",
      "Epoch 6620 - Train Loss: 0.160864, Train Acc: 0.693590 | Val Loss: 0.172239, Val Acc: 0.659794\n",
      "Epoch 6621 - Train Loss: 0.160852, Train Acc: 0.693590 | Val Loss: 0.172229, Val Acc: 0.659794\n",
      "Epoch 6622 - Train Loss: 0.160840, Train Acc: 0.693590 | Val Loss: 0.172218, Val Acc: 0.659794\n",
      "Epoch 6623 - Train Loss: 0.160828, Train Acc: 0.693590 | Val Loss: 0.172207, Val Acc: 0.659794\n",
      "Epoch 6624 - Train Loss: 0.160816, Train Acc: 0.693590 | Val Loss: 0.172197, Val Acc: 0.659794\n",
      "Epoch 6625 - Train Loss: 0.160804, Train Acc: 0.693590 | Val Loss: 0.172186, Val Acc: 0.659794\n",
      "Epoch 6626 - Train Loss: 0.160792, Train Acc: 0.693590 | Val Loss: 0.172175, Val Acc: 0.659794\n",
      "Epoch 6627 - Train Loss: 0.160780, Train Acc: 0.693590 | Val Loss: 0.172165, Val Acc: 0.659794\n",
      "Epoch 6628 - Train Loss: 0.160768, Train Acc: 0.693590 | Val Loss: 0.172154, Val Acc: 0.659794\n",
      "Epoch 6629 - Train Loss: 0.160756, Train Acc: 0.693590 | Val Loss: 0.172143, Val Acc: 0.659794\n",
      "Epoch 6630 - Train Loss: 0.160744, Train Acc: 0.694872 | Val Loss: 0.172133, Val Acc: 0.659794\n",
      "Epoch 6631 - Train Loss: 0.160732, Train Acc: 0.694872 | Val Loss: 0.172122, Val Acc: 0.659794\n",
      "Epoch 6632 - Train Loss: 0.160720, Train Acc: 0.694872 | Val Loss: 0.172111, Val Acc: 0.659794\n",
      "Epoch 6633 - Train Loss: 0.160708, Train Acc: 0.694872 | Val Loss: 0.172101, Val Acc: 0.659794\n",
      "Epoch 6634 - Train Loss: 0.160696, Train Acc: 0.694872 | Val Loss: 0.172090, Val Acc: 0.659794\n",
      "Epoch 6635 - Train Loss: 0.160684, Train Acc: 0.694872 | Val Loss: 0.172079, Val Acc: 0.659794\n",
      "Epoch 6636 - Train Loss: 0.160672, Train Acc: 0.694872 | Val Loss: 0.172069, Val Acc: 0.659794\n",
      "Epoch 6637 - Train Loss: 0.160660, Train Acc: 0.694872 | Val Loss: 0.172058, Val Acc: 0.659794\n",
      "Epoch 6638 - Train Loss: 0.160648, Train Acc: 0.694872 | Val Loss: 0.172048, Val Acc: 0.659794\n",
      "Epoch 6639 - Train Loss: 0.160636, Train Acc: 0.694872 | Val Loss: 0.172037, Val Acc: 0.659794\n",
      "Epoch 6640 - Train Loss: 0.160624, Train Acc: 0.694872 | Val Loss: 0.172026, Val Acc: 0.659794\n",
      "Epoch 6641 - Train Loss: 0.160612, Train Acc: 0.694872 | Val Loss: 0.172016, Val Acc: 0.659794\n",
      "Epoch 6642 - Train Loss: 0.160600, Train Acc: 0.694872 | Val Loss: 0.172005, Val Acc: 0.659794\n",
      "Epoch 6643 - Train Loss: 0.160588, Train Acc: 0.694872 | Val Loss: 0.171994, Val Acc: 0.659794\n",
      "Epoch 6644 - Train Loss: 0.160576, Train Acc: 0.694872 | Val Loss: 0.171984, Val Acc: 0.659794\n",
      "Epoch 6645 - Train Loss: 0.160564, Train Acc: 0.694872 | Val Loss: 0.171973, Val Acc: 0.659794\n",
      "Epoch 6646 - Train Loss: 0.160552, Train Acc: 0.694872 | Val Loss: 0.171962, Val Acc: 0.659794\n",
      "Epoch 6647 - Train Loss: 0.160540, Train Acc: 0.694872 | Val Loss: 0.171952, Val Acc: 0.659794\n",
      "Epoch 6648 - Train Loss: 0.160528, Train Acc: 0.694872 | Val Loss: 0.171941, Val Acc: 0.659794\n",
      "Epoch 6649 - Train Loss: 0.160516, Train Acc: 0.694872 | Val Loss: 0.171930, Val Acc: 0.659794\n",
      "Epoch 6650 - Train Loss: 0.160504, Train Acc: 0.694872 | Val Loss: 0.171920, Val Acc: 0.659794\n",
      "Epoch 6651 - Train Loss: 0.160492, Train Acc: 0.694872 | Val Loss: 0.171909, Val Acc: 0.659794\n",
      "Epoch 6652 - Train Loss: 0.160480, Train Acc: 0.694872 | Val Loss: 0.171899, Val Acc: 0.659794\n",
      "Epoch 6653 - Train Loss: 0.160468, Train Acc: 0.694872 | Val Loss: 0.171888, Val Acc: 0.659794\n",
      "Epoch 6654 - Train Loss: 0.160456, Train Acc: 0.694872 | Val Loss: 0.171877, Val Acc: 0.659794\n",
      "Epoch 6655 - Train Loss: 0.160444, Train Acc: 0.694872 | Val Loss: 0.171867, Val Acc: 0.659794\n",
      "Epoch 6656 - Train Loss: 0.160432, Train Acc: 0.694872 | Val Loss: 0.171856, Val Acc: 0.659794\n",
      "Epoch 6657 - Train Loss: 0.160420, Train Acc: 0.694872 | Val Loss: 0.171845, Val Acc: 0.659794\n",
      "Epoch 6658 - Train Loss: 0.160408, Train Acc: 0.694872 | Val Loss: 0.171835, Val Acc: 0.659794\n",
      "Epoch 6659 - Train Loss: 0.160396, Train Acc: 0.694872 | Val Loss: 0.171824, Val Acc: 0.659794\n",
      "Epoch 6660 - Train Loss: 0.160384, Train Acc: 0.694872 | Val Loss: 0.171813, Val Acc: 0.659794\n",
      "Epoch 6661 - Train Loss: 0.160372, Train Acc: 0.694872 | Val Loss: 0.171803, Val Acc: 0.659794\n",
      "Epoch 6662 - Train Loss: 0.160360, Train Acc: 0.694872 | Val Loss: 0.171792, Val Acc: 0.659794\n",
      "Epoch 6663 - Train Loss: 0.160348, Train Acc: 0.694872 | Val Loss: 0.171782, Val Acc: 0.659794\n",
      "Epoch 6664 - Train Loss: 0.160336, Train Acc: 0.694872 | Val Loss: 0.171771, Val Acc: 0.659794\n",
      "Epoch 6665 - Train Loss: 0.160324, Train Acc: 0.694872 | Val Loss: 0.171760, Val Acc: 0.659794\n",
      "Epoch 6666 - Train Loss: 0.160312, Train Acc: 0.694872 | Val Loss: 0.171750, Val Acc: 0.659794\n",
      "Epoch 6667 - Train Loss: 0.160300, Train Acc: 0.694872 | Val Loss: 0.171739, Val Acc: 0.659794\n",
      "Epoch 6668 - Train Loss: 0.160288, Train Acc: 0.696154 | Val Loss: 0.171728, Val Acc: 0.659794\n",
      "Epoch 6669 - Train Loss: 0.160277, Train Acc: 0.696154 | Val Loss: 0.171718, Val Acc: 0.659794\n",
      "Epoch 6670 - Train Loss: 0.160265, Train Acc: 0.696154 | Val Loss: 0.171707, Val Acc: 0.659794\n",
      "Epoch 6671 - Train Loss: 0.160253, Train Acc: 0.697436 | Val Loss: 0.171697, Val Acc: 0.659794\n",
      "Epoch 6672 - Train Loss: 0.160241, Train Acc: 0.697436 | Val Loss: 0.171686, Val Acc: 0.659794\n",
      "Epoch 6673 - Train Loss: 0.160229, Train Acc: 0.698718 | Val Loss: 0.171675, Val Acc: 0.659794\n",
      "Epoch 6674 - Train Loss: 0.160217, Train Acc: 0.698718 | Val Loss: 0.171665, Val Acc: 0.659794\n",
      "Epoch 6675 - Train Loss: 0.160205, Train Acc: 0.698718 | Val Loss: 0.171654, Val Acc: 0.659794\n",
      "Epoch 6676 - Train Loss: 0.160193, Train Acc: 0.698718 | Val Loss: 0.171644, Val Acc: 0.659794\n",
      "Epoch 6677 - Train Loss: 0.160181, Train Acc: 0.698718 | Val Loss: 0.171633, Val Acc: 0.659794\n",
      "Epoch 6678 - Train Loss: 0.160169, Train Acc: 0.698718 | Val Loss: 0.171622, Val Acc: 0.659794\n",
      "Epoch 6679 - Train Loss: 0.160157, Train Acc: 0.698718 | Val Loss: 0.171612, Val Acc: 0.659794\n",
      "Epoch 6680 - Train Loss: 0.160145, Train Acc: 0.698718 | Val Loss: 0.171601, Val Acc: 0.659794\n",
      "Epoch 6681 - Train Loss: 0.160133, Train Acc: 0.698718 | Val Loss: 0.171591, Val Acc: 0.659794\n",
      "Epoch 6682 - Train Loss: 0.160121, Train Acc: 0.698718 | Val Loss: 0.171580, Val Acc: 0.659794\n",
      "Epoch 6683 - Train Loss: 0.160109, Train Acc: 0.698718 | Val Loss: 0.171569, Val Acc: 0.659794\n",
      "Epoch 6684 - Train Loss: 0.160097, Train Acc: 0.698718 | Val Loss: 0.171559, Val Acc: 0.659794\n",
      "Epoch 6685 - Train Loss: 0.160085, Train Acc: 0.698718 | Val Loss: 0.171548, Val Acc: 0.659794\n",
      "Epoch 6686 - Train Loss: 0.160073, Train Acc: 0.698718 | Val Loss: 0.171538, Val Acc: 0.659794\n",
      "Epoch 6687 - Train Loss: 0.160061, Train Acc: 0.698718 | Val Loss: 0.171527, Val Acc: 0.659794\n",
      "Epoch 6688 - Train Loss: 0.160049, Train Acc: 0.698718 | Val Loss: 0.171516, Val Acc: 0.659794\n",
      "Epoch 6689 - Train Loss: 0.160037, Train Acc: 0.698718 | Val Loss: 0.171506, Val Acc: 0.659794\n",
      "Epoch 6690 - Train Loss: 0.160025, Train Acc: 0.698718 | Val Loss: 0.171495, Val Acc: 0.659794\n",
      "Epoch 6691 - Train Loss: 0.160014, Train Acc: 0.700000 | Val Loss: 0.171485, Val Acc: 0.659794\n",
      "Epoch 6692 - Train Loss: 0.160002, Train Acc: 0.700000 | Val Loss: 0.171474, Val Acc: 0.659794\n",
      "Epoch 6693 - Train Loss: 0.159990, Train Acc: 0.700000 | Val Loss: 0.171463, Val Acc: 0.659794\n",
      "Epoch 6694 - Train Loss: 0.159978, Train Acc: 0.700000 | Val Loss: 0.171453, Val Acc: 0.659794\n",
      "Epoch 6695 - Train Loss: 0.159966, Train Acc: 0.700000 | Val Loss: 0.171442, Val Acc: 0.659794\n",
      "Epoch 6696 - Train Loss: 0.159954, Train Acc: 0.700000 | Val Loss: 0.171432, Val Acc: 0.659794\n",
      "Epoch 6697 - Train Loss: 0.159942, Train Acc: 0.700000 | Val Loss: 0.171421, Val Acc: 0.659794\n",
      "Epoch 6698 - Train Loss: 0.159930, Train Acc: 0.700000 | Val Loss: 0.171410, Val Acc: 0.659794\n",
      "Epoch 6699 - Train Loss: 0.159918, Train Acc: 0.700000 | Val Loss: 0.171400, Val Acc: 0.659794\n",
      "Epoch 6700 - Train Loss: 0.159906, Train Acc: 0.700000 | Val Loss: 0.171389, Val Acc: 0.659794\n",
      "Epoch 6701 - Train Loss: 0.159894, Train Acc: 0.700000 | Val Loss: 0.171379, Val Acc: 0.659794\n",
      "Epoch 6702 - Train Loss: 0.159882, Train Acc: 0.700000 | Val Loss: 0.171368, Val Acc: 0.659794\n",
      "Epoch 6703 - Train Loss: 0.159870, Train Acc: 0.700000 | Val Loss: 0.171358, Val Acc: 0.659794\n",
      "Epoch 6704 - Train Loss: 0.159858, Train Acc: 0.700000 | Val Loss: 0.171347, Val Acc: 0.659794\n",
      "Epoch 6705 - Train Loss: 0.159846, Train Acc: 0.700000 | Val Loss: 0.171336, Val Acc: 0.659794\n",
      "Epoch 6706 - Train Loss: 0.159834, Train Acc: 0.700000 | Val Loss: 0.171326, Val Acc: 0.659794\n",
      "Epoch 6707 - Train Loss: 0.159823, Train Acc: 0.700000 | Val Loss: 0.171315, Val Acc: 0.659794\n",
      "Epoch 6708 - Train Loss: 0.159811, Train Acc: 0.700000 | Val Loss: 0.171305, Val Acc: 0.659794\n",
      "Epoch 6709 - Train Loss: 0.159799, Train Acc: 0.700000 | Val Loss: 0.171294, Val Acc: 0.659794\n",
      "Epoch 6710 - Train Loss: 0.159787, Train Acc: 0.700000 | Val Loss: 0.171284, Val Acc: 0.659794\n",
      "Epoch 6711 - Train Loss: 0.159775, Train Acc: 0.700000 | Val Loss: 0.171273, Val Acc: 0.659794\n",
      "Epoch 6712 - Train Loss: 0.159763, Train Acc: 0.700000 | Val Loss: 0.171262, Val Acc: 0.659794\n",
      "Epoch 6713 - Train Loss: 0.159751, Train Acc: 0.700000 | Val Loss: 0.171252, Val Acc: 0.659794\n",
      "Epoch 6714 - Train Loss: 0.159739, Train Acc: 0.700000 | Val Loss: 0.171241, Val Acc: 0.659794\n",
      "Epoch 6715 - Train Loss: 0.159727, Train Acc: 0.700000 | Val Loss: 0.171231, Val Acc: 0.659794\n",
      "Epoch 6716 - Train Loss: 0.159715, Train Acc: 0.700000 | Val Loss: 0.171220, Val Acc: 0.659794\n",
      "Epoch 6717 - Train Loss: 0.159703, Train Acc: 0.700000 | Val Loss: 0.171210, Val Acc: 0.659794\n",
      "Epoch 6718 - Train Loss: 0.159691, Train Acc: 0.700000 | Val Loss: 0.171199, Val Acc: 0.659794\n",
      "Epoch 6719 - Train Loss: 0.159679, Train Acc: 0.700000 | Val Loss: 0.171188, Val Acc: 0.659794\n",
      "Epoch 6720 - Train Loss: 0.159668, Train Acc: 0.700000 | Val Loss: 0.171178, Val Acc: 0.659794\n",
      "Epoch 6721 - Train Loss: 0.159656, Train Acc: 0.701282 | Val Loss: 0.171167, Val Acc: 0.659794\n",
      "Epoch 6722 - Train Loss: 0.159644, Train Acc: 0.701282 | Val Loss: 0.171157, Val Acc: 0.659794\n",
      "Epoch 6723 - Train Loss: 0.159632, Train Acc: 0.701282 | Val Loss: 0.171146, Val Acc: 0.659794\n",
      "Epoch 6724 - Train Loss: 0.159620, Train Acc: 0.701282 | Val Loss: 0.171136, Val Acc: 0.659794\n",
      "Epoch 6725 - Train Loss: 0.159608, Train Acc: 0.701282 | Val Loss: 0.171125, Val Acc: 0.659794\n",
      "Epoch 6726 - Train Loss: 0.159596, Train Acc: 0.701282 | Val Loss: 0.171114, Val Acc: 0.659794\n",
      "Epoch 6727 - Train Loss: 0.159584, Train Acc: 0.701282 | Val Loss: 0.171104, Val Acc: 0.659794\n",
      "Epoch 6728 - Train Loss: 0.159572, Train Acc: 0.701282 | Val Loss: 0.171093, Val Acc: 0.659794\n",
      "Epoch 6729 - Train Loss: 0.159560, Train Acc: 0.701282 | Val Loss: 0.171083, Val Acc: 0.659794\n",
      "Epoch 6730 - Train Loss: 0.159548, Train Acc: 0.701282 | Val Loss: 0.171072, Val Acc: 0.659794\n",
      "Epoch 6731 - Train Loss: 0.159537, Train Acc: 0.701282 | Val Loss: 0.171062, Val Acc: 0.659794\n",
      "Epoch 6732 - Train Loss: 0.159525, Train Acc: 0.701282 | Val Loss: 0.171051, Val Acc: 0.659794\n",
      "Epoch 6733 - Train Loss: 0.159513, Train Acc: 0.701282 | Val Loss: 0.171041, Val Acc: 0.659794\n",
      "Epoch 6734 - Train Loss: 0.159501, Train Acc: 0.701282 | Val Loss: 0.171030, Val Acc: 0.659794\n",
      "Epoch 6735 - Train Loss: 0.159489, Train Acc: 0.701282 | Val Loss: 0.171020, Val Acc: 0.659794\n",
      "Epoch 6736 - Train Loss: 0.159477, Train Acc: 0.701282 | Val Loss: 0.171009, Val Acc: 0.659794\n",
      "Epoch 6737 - Train Loss: 0.159465, Train Acc: 0.701282 | Val Loss: 0.170998, Val Acc: 0.659794\n",
      "Epoch 6738 - Train Loss: 0.159453, Train Acc: 0.701282 | Val Loss: 0.170988, Val Acc: 0.659794\n",
      "Epoch 6739 - Train Loss: 0.159441, Train Acc: 0.701282 | Val Loss: 0.170977, Val Acc: 0.659794\n",
      "Epoch 6740 - Train Loss: 0.159430, Train Acc: 0.701282 | Val Loss: 0.170967, Val Acc: 0.659794\n",
      "Epoch 6741 - Train Loss: 0.159418, Train Acc: 0.701282 | Val Loss: 0.170956, Val Acc: 0.659794\n",
      "Epoch 6742 - Train Loss: 0.159406, Train Acc: 0.701282 | Val Loss: 0.170946, Val Acc: 0.659794\n",
      "Epoch 6743 - Train Loss: 0.159394, Train Acc: 0.701282 | Val Loss: 0.170935, Val Acc: 0.659794\n",
      "Epoch 6744 - Train Loss: 0.159382, Train Acc: 0.701282 | Val Loss: 0.170925, Val Acc: 0.659794\n",
      "Epoch 6745 - Train Loss: 0.159370, Train Acc: 0.701282 | Val Loss: 0.170914, Val Acc: 0.659794\n",
      "Epoch 6746 - Train Loss: 0.159358, Train Acc: 0.701282 | Val Loss: 0.170904, Val Acc: 0.659794\n",
      "Epoch 6747 - Train Loss: 0.159346, Train Acc: 0.701282 | Val Loss: 0.170893, Val Acc: 0.659794\n",
      "Epoch 6748 - Train Loss: 0.159334, Train Acc: 0.701282 | Val Loss: 0.170882, Val Acc: 0.659794\n",
      "Epoch 6749 - Train Loss: 0.159323, Train Acc: 0.701282 | Val Loss: 0.170872, Val Acc: 0.659794\n",
      "Epoch 6750 - Train Loss: 0.159311, Train Acc: 0.701282 | Val Loss: 0.170861, Val Acc: 0.659794\n",
      "Epoch 6751 - Train Loss: 0.159299, Train Acc: 0.701282 | Val Loss: 0.170851, Val Acc: 0.659794\n",
      "Epoch 6752 - Train Loss: 0.159287, Train Acc: 0.701282 | Val Loss: 0.170840, Val Acc: 0.659794\n",
      "Epoch 6753 - Train Loss: 0.159275, Train Acc: 0.701282 | Val Loss: 0.170830, Val Acc: 0.659794\n",
      "Epoch 6754 - Train Loss: 0.159263, Train Acc: 0.701282 | Val Loss: 0.170819, Val Acc: 0.659794\n",
      "Epoch 6755 - Train Loss: 0.159251, Train Acc: 0.701282 | Val Loss: 0.170809, Val Acc: 0.659794\n",
      "Epoch 6756 - Train Loss: 0.159239, Train Acc: 0.701282 | Val Loss: 0.170798, Val Acc: 0.659794\n",
      "Epoch 6757 - Train Loss: 0.159227, Train Acc: 0.701282 | Val Loss: 0.170788, Val Acc: 0.659794\n",
      "Epoch 6758 - Train Loss: 0.159216, Train Acc: 0.701282 | Val Loss: 0.170777, Val Acc: 0.659794\n",
      "Epoch 6759 - Train Loss: 0.159204, Train Acc: 0.701282 | Val Loss: 0.170767, Val Acc: 0.659794\n",
      "Epoch 6760 - Train Loss: 0.159192, Train Acc: 0.701282 | Val Loss: 0.170756, Val Acc: 0.659794\n",
      "Epoch 6761 - Train Loss: 0.159180, Train Acc: 0.701282 | Val Loss: 0.170746, Val Acc: 0.659794\n",
      "Epoch 6762 - Train Loss: 0.159168, Train Acc: 0.701282 | Val Loss: 0.170735, Val Acc: 0.659794\n",
      "Epoch 6763 - Train Loss: 0.159156, Train Acc: 0.701282 | Val Loss: 0.170725, Val Acc: 0.659794\n",
      "Epoch 6764 - Train Loss: 0.159144, Train Acc: 0.701282 | Val Loss: 0.170714, Val Acc: 0.659794\n",
      "Epoch 6765 - Train Loss: 0.159132, Train Acc: 0.701282 | Val Loss: 0.170704, Val Acc: 0.659794\n",
      "Epoch 6766 - Train Loss: 0.159121, Train Acc: 0.701282 | Val Loss: 0.170693, Val Acc: 0.659794\n",
      "Epoch 6767 - Train Loss: 0.159109, Train Acc: 0.701282 | Val Loss: 0.170683, Val Acc: 0.659794\n",
      "Epoch 6768 - Train Loss: 0.159097, Train Acc: 0.701282 | Val Loss: 0.170672, Val Acc: 0.659794\n",
      "Epoch 6769 - Train Loss: 0.159085, Train Acc: 0.701282 | Val Loss: 0.170661, Val Acc: 0.659794\n",
      "Epoch 6770 - Train Loss: 0.159073, Train Acc: 0.701282 | Val Loss: 0.170651, Val Acc: 0.659794\n",
      "Epoch 6771 - Train Loss: 0.159061, Train Acc: 0.701282 | Val Loss: 0.170640, Val Acc: 0.659794\n",
      "Epoch 6772 - Train Loss: 0.159049, Train Acc: 0.701282 | Val Loss: 0.170630, Val Acc: 0.659794\n",
      "Epoch 6773 - Train Loss: 0.159038, Train Acc: 0.701282 | Val Loss: 0.170619, Val Acc: 0.659794\n",
      "Epoch 6774 - Train Loss: 0.159026, Train Acc: 0.701282 | Val Loss: 0.170609, Val Acc: 0.659794\n",
      "Epoch 6775 - Train Loss: 0.159014, Train Acc: 0.701282 | Val Loss: 0.170598, Val Acc: 0.659794\n",
      "Epoch 6776 - Train Loss: 0.159002, Train Acc: 0.701282 | Val Loss: 0.170588, Val Acc: 0.670103\n",
      "Epoch 6777 - Train Loss: 0.158990, Train Acc: 0.701282 | Val Loss: 0.170577, Val Acc: 0.670103\n",
      "Epoch 6778 - Train Loss: 0.158978, Train Acc: 0.701282 | Val Loss: 0.170567, Val Acc: 0.670103\n",
      "Epoch 6779 - Train Loss: 0.158966, Train Acc: 0.701282 | Val Loss: 0.170556, Val Acc: 0.670103\n",
      "Epoch 6780 - Train Loss: 0.158955, Train Acc: 0.701282 | Val Loss: 0.170546, Val Acc: 0.670103\n",
      "Epoch 6781 - Train Loss: 0.158943, Train Acc: 0.701282 | Val Loss: 0.170535, Val Acc: 0.670103\n",
      "Epoch 6782 - Train Loss: 0.158931, Train Acc: 0.702564 | Val Loss: 0.170525, Val Acc: 0.670103\n",
      "Epoch 6783 - Train Loss: 0.158919, Train Acc: 0.702564 | Val Loss: 0.170514, Val Acc: 0.670103\n",
      "Epoch 6784 - Train Loss: 0.158907, Train Acc: 0.702564 | Val Loss: 0.170504, Val Acc: 0.670103\n",
      "Epoch 6785 - Train Loss: 0.158895, Train Acc: 0.702564 | Val Loss: 0.170493, Val Acc: 0.670103\n",
      "Epoch 6786 - Train Loss: 0.158883, Train Acc: 0.702564 | Val Loss: 0.170483, Val Acc: 0.670103\n",
      "Epoch 6787 - Train Loss: 0.158872, Train Acc: 0.702564 | Val Loss: 0.170472, Val Acc: 0.670103\n",
      "Epoch 6788 - Train Loss: 0.158860, Train Acc: 0.702564 | Val Loss: 0.170462, Val Acc: 0.670103\n",
      "Epoch 6789 - Train Loss: 0.158848, Train Acc: 0.702564 | Val Loss: 0.170451, Val Acc: 0.670103\n",
      "Epoch 6790 - Train Loss: 0.158836, Train Acc: 0.702564 | Val Loss: 0.170441, Val Acc: 0.670103\n",
      "Epoch 6791 - Train Loss: 0.158824, Train Acc: 0.702564 | Val Loss: 0.170431, Val Acc: 0.670103\n",
      "Epoch 6792 - Train Loss: 0.158812, Train Acc: 0.702564 | Val Loss: 0.170420, Val Acc: 0.670103\n",
      "Epoch 6793 - Train Loss: 0.158800, Train Acc: 0.703846 | Val Loss: 0.170410, Val Acc: 0.670103\n",
      "Epoch 6794 - Train Loss: 0.158789, Train Acc: 0.703846 | Val Loss: 0.170399, Val Acc: 0.670103\n",
      "Epoch 6795 - Train Loss: 0.158777, Train Acc: 0.703846 | Val Loss: 0.170389, Val Acc: 0.670103\n",
      "Epoch 6796 - Train Loss: 0.158765, Train Acc: 0.703846 | Val Loss: 0.170378, Val Acc: 0.670103\n",
      "Epoch 6797 - Train Loss: 0.158753, Train Acc: 0.703846 | Val Loss: 0.170368, Val Acc: 0.670103\n",
      "Epoch 6798 - Train Loss: 0.158741, Train Acc: 0.703846 | Val Loss: 0.170357, Val Acc: 0.670103\n",
      "Epoch 6799 - Train Loss: 0.158729, Train Acc: 0.703846 | Val Loss: 0.170347, Val Acc: 0.670103\n",
      "Epoch 6800 - Train Loss: 0.158718, Train Acc: 0.703846 | Val Loss: 0.170336, Val Acc: 0.670103\n",
      "Epoch 6801 - Train Loss: 0.158706, Train Acc: 0.703846 | Val Loss: 0.170326, Val Acc: 0.670103\n",
      "Epoch 6802 - Train Loss: 0.158694, Train Acc: 0.703846 | Val Loss: 0.170315, Val Acc: 0.670103\n",
      "Epoch 6803 - Train Loss: 0.158682, Train Acc: 0.703846 | Val Loss: 0.170305, Val Acc: 0.670103\n",
      "Epoch 6804 - Train Loss: 0.158670, Train Acc: 0.703846 | Val Loss: 0.170294, Val Acc: 0.670103\n",
      "Epoch 6805 - Train Loss: 0.158658, Train Acc: 0.703846 | Val Loss: 0.170284, Val Acc: 0.670103\n",
      "Epoch 6806 - Train Loss: 0.158646, Train Acc: 0.703846 | Val Loss: 0.170273, Val Acc: 0.670103\n",
      "Epoch 6807 - Train Loss: 0.158635, Train Acc: 0.703846 | Val Loss: 0.170263, Val Acc: 0.670103\n",
      "Epoch 6808 - Train Loss: 0.158623, Train Acc: 0.703846 | Val Loss: 0.170252, Val Acc: 0.670103\n",
      "Epoch 6809 - Train Loss: 0.158611, Train Acc: 0.703846 | Val Loss: 0.170242, Val Acc: 0.670103\n",
      "Epoch 6810 - Train Loss: 0.158599, Train Acc: 0.703846 | Val Loss: 0.170232, Val Acc: 0.670103\n",
      "Epoch 6811 - Train Loss: 0.158587, Train Acc: 0.703846 | Val Loss: 0.170221, Val Acc: 0.670103\n",
      "Epoch 6812 - Train Loss: 0.158575, Train Acc: 0.703846 | Val Loss: 0.170211, Val Acc: 0.670103\n",
      "Epoch 6813 - Train Loss: 0.158564, Train Acc: 0.703846 | Val Loss: 0.170200, Val Acc: 0.670103\n",
      "Epoch 6814 - Train Loss: 0.158552, Train Acc: 0.703846 | Val Loss: 0.170190, Val Acc: 0.670103\n",
      "Epoch 6815 - Train Loss: 0.158540, Train Acc: 0.703846 | Val Loss: 0.170179, Val Acc: 0.670103\n",
      "Epoch 6816 - Train Loss: 0.158528, Train Acc: 0.703846 | Val Loss: 0.170169, Val Acc: 0.670103\n",
      "Epoch 6817 - Train Loss: 0.158516, Train Acc: 0.703846 | Val Loss: 0.170158, Val Acc: 0.670103\n",
      "Epoch 6818 - Train Loss: 0.158505, Train Acc: 0.703846 | Val Loss: 0.170148, Val Acc: 0.670103\n",
      "Epoch 6819 - Train Loss: 0.158493, Train Acc: 0.705128 | Val Loss: 0.170138, Val Acc: 0.670103\n",
      "Epoch 6820 - Train Loss: 0.158481, Train Acc: 0.705128 | Val Loss: 0.170127, Val Acc: 0.670103\n",
      "Epoch 6821 - Train Loss: 0.158469, Train Acc: 0.705128 | Val Loss: 0.170117, Val Acc: 0.670103\n",
      "Epoch 6822 - Train Loss: 0.158457, Train Acc: 0.705128 | Val Loss: 0.170106, Val Acc: 0.670103\n",
      "Epoch 6823 - Train Loss: 0.158445, Train Acc: 0.705128 | Val Loss: 0.170096, Val Acc: 0.670103\n",
      "Epoch 6824 - Train Loss: 0.158434, Train Acc: 0.705128 | Val Loss: 0.170085, Val Acc: 0.670103\n",
      "Epoch 6825 - Train Loss: 0.158422, Train Acc: 0.705128 | Val Loss: 0.170075, Val Acc: 0.670103\n",
      "Epoch 6826 - Train Loss: 0.158410, Train Acc: 0.705128 | Val Loss: 0.170064, Val Acc: 0.670103\n",
      "Epoch 6827 - Train Loss: 0.158398, Train Acc: 0.705128 | Val Loss: 0.170054, Val Acc: 0.670103\n",
      "Epoch 6828 - Train Loss: 0.158386, Train Acc: 0.705128 | Val Loss: 0.170044, Val Acc: 0.670103\n",
      "Epoch 6829 - Train Loss: 0.158375, Train Acc: 0.705128 | Val Loss: 0.170033, Val Acc: 0.670103\n",
      "Epoch 6830 - Train Loss: 0.158363, Train Acc: 0.705128 | Val Loss: 0.170023, Val Acc: 0.670103\n",
      "Epoch 6831 - Train Loss: 0.158351, Train Acc: 0.705128 | Val Loss: 0.170012, Val Acc: 0.670103\n",
      "Epoch 6832 - Train Loss: 0.158339, Train Acc: 0.705128 | Val Loss: 0.170002, Val Acc: 0.670103\n",
      "Epoch 6833 - Train Loss: 0.158327, Train Acc: 0.705128 | Val Loss: 0.169991, Val Acc: 0.670103\n",
      "Epoch 6834 - Train Loss: 0.158316, Train Acc: 0.705128 | Val Loss: 0.169981, Val Acc: 0.670103\n",
      "Epoch 6835 - Train Loss: 0.158304, Train Acc: 0.705128 | Val Loss: 0.169971, Val Acc: 0.670103\n",
      "Epoch 6836 - Train Loss: 0.158292, Train Acc: 0.705128 | Val Loss: 0.169960, Val Acc: 0.670103\n",
      "Epoch 6837 - Train Loss: 0.158280, Train Acc: 0.705128 | Val Loss: 0.169950, Val Acc: 0.670103\n",
      "Epoch 6838 - Train Loss: 0.158268, Train Acc: 0.705128 | Val Loss: 0.169939, Val Acc: 0.670103\n",
      "Epoch 6839 - Train Loss: 0.158257, Train Acc: 0.705128 | Val Loss: 0.169929, Val Acc: 0.670103\n",
      "Epoch 6840 - Train Loss: 0.158245, Train Acc: 0.705128 | Val Loss: 0.169918, Val Acc: 0.670103\n",
      "Epoch 6841 - Train Loss: 0.158233, Train Acc: 0.705128 | Val Loss: 0.169908, Val Acc: 0.670103\n",
      "Epoch 6842 - Train Loss: 0.158221, Train Acc: 0.705128 | Val Loss: 0.169898, Val Acc: 0.670103\n",
      "Epoch 6843 - Train Loss: 0.158209, Train Acc: 0.703846 | Val Loss: 0.169887, Val Acc: 0.670103\n",
      "Epoch 6844 - Train Loss: 0.158198, Train Acc: 0.703846 | Val Loss: 0.169877, Val Acc: 0.670103\n",
      "Epoch 6845 - Train Loss: 0.158186, Train Acc: 0.703846 | Val Loss: 0.169866, Val Acc: 0.670103\n",
      "Epoch 6846 - Train Loss: 0.158174, Train Acc: 0.705128 | Val Loss: 0.169856, Val Acc: 0.670103\n",
      "Epoch 6847 - Train Loss: 0.158162, Train Acc: 0.705128 | Val Loss: 0.169845, Val Acc: 0.670103\n",
      "Epoch 6848 - Train Loss: 0.158150, Train Acc: 0.705128 | Val Loss: 0.169835, Val Acc: 0.670103\n",
      "Epoch 6849 - Train Loss: 0.158139, Train Acc: 0.705128 | Val Loss: 0.169825, Val Acc: 0.670103\n",
      "Epoch 6850 - Train Loss: 0.158127, Train Acc: 0.705128 | Val Loss: 0.169814, Val Acc: 0.670103\n",
      "Epoch 6851 - Train Loss: 0.158115, Train Acc: 0.705128 | Val Loss: 0.169804, Val Acc: 0.670103\n",
      "Epoch 6852 - Train Loss: 0.158103, Train Acc: 0.705128 | Val Loss: 0.169793, Val Acc: 0.670103\n",
      "Epoch 6853 - Train Loss: 0.158091, Train Acc: 0.705128 | Val Loss: 0.169783, Val Acc: 0.670103\n",
      "Epoch 6854 - Train Loss: 0.158080, Train Acc: 0.705128 | Val Loss: 0.169773, Val Acc: 0.670103\n",
      "Epoch 6855 - Train Loss: 0.158068, Train Acc: 0.705128 | Val Loss: 0.169762, Val Acc: 0.670103\n",
      "Epoch 6856 - Train Loss: 0.158056, Train Acc: 0.705128 | Val Loss: 0.169752, Val Acc: 0.670103\n",
      "Epoch 6857 - Train Loss: 0.158044, Train Acc: 0.705128 | Val Loss: 0.169741, Val Acc: 0.670103\n",
      "Epoch 6858 - Train Loss: 0.158033, Train Acc: 0.705128 | Val Loss: 0.169731, Val Acc: 0.670103\n",
      "Epoch 6859 - Train Loss: 0.158021, Train Acc: 0.705128 | Val Loss: 0.169721, Val Acc: 0.670103\n",
      "Epoch 6860 - Train Loss: 0.158009, Train Acc: 0.705128 | Val Loss: 0.169710, Val Acc: 0.670103\n",
      "Epoch 6861 - Train Loss: 0.157997, Train Acc: 0.705128 | Val Loss: 0.169700, Val Acc: 0.670103\n",
      "Epoch 6862 - Train Loss: 0.157985, Train Acc: 0.705128 | Val Loss: 0.169689, Val Acc: 0.670103\n",
      "Epoch 6863 - Train Loss: 0.157974, Train Acc: 0.705128 | Val Loss: 0.169679, Val Acc: 0.670103\n",
      "Epoch 6864 - Train Loss: 0.157962, Train Acc: 0.705128 | Val Loss: 0.169669, Val Acc: 0.670103\n",
      "Epoch 6865 - Train Loss: 0.157950, Train Acc: 0.705128 | Val Loss: 0.169658, Val Acc: 0.670103\n",
      "Epoch 6866 - Train Loss: 0.157938, Train Acc: 0.705128 | Val Loss: 0.169648, Val Acc: 0.670103\n",
      "Epoch 6867 - Train Loss: 0.157927, Train Acc: 0.705128 | Val Loss: 0.169637, Val Acc: 0.670103\n",
      "Epoch 6868 - Train Loss: 0.157915, Train Acc: 0.705128 | Val Loss: 0.169627, Val Acc: 0.670103\n",
      "Epoch 6869 - Train Loss: 0.157903, Train Acc: 0.705128 | Val Loss: 0.169617, Val Acc: 0.670103\n",
      "Epoch 6870 - Train Loss: 0.157891, Train Acc: 0.705128 | Val Loss: 0.169606, Val Acc: 0.670103\n",
      "Epoch 6871 - Train Loss: 0.157880, Train Acc: 0.705128 | Val Loss: 0.169596, Val Acc: 0.670103\n",
      "Epoch 6872 - Train Loss: 0.157868, Train Acc: 0.705128 | Val Loss: 0.169585, Val Acc: 0.670103\n",
      "Epoch 6873 - Train Loss: 0.157856, Train Acc: 0.705128 | Val Loss: 0.169575, Val Acc: 0.670103\n",
      "Epoch 6874 - Train Loss: 0.157844, Train Acc: 0.705128 | Val Loss: 0.169565, Val Acc: 0.670103\n",
      "Epoch 6875 - Train Loss: 0.157832, Train Acc: 0.705128 | Val Loss: 0.169554, Val Acc: 0.670103\n",
      "Epoch 6876 - Train Loss: 0.157821, Train Acc: 0.705128 | Val Loss: 0.169544, Val Acc: 0.670103\n",
      "Epoch 6877 - Train Loss: 0.157809, Train Acc: 0.705128 | Val Loss: 0.169533, Val Acc: 0.670103\n",
      "Epoch 6878 - Train Loss: 0.157797, Train Acc: 0.705128 | Val Loss: 0.169523, Val Acc: 0.670103\n",
      "Epoch 6879 - Train Loss: 0.157785, Train Acc: 0.705128 | Val Loss: 0.169513, Val Acc: 0.670103\n",
      "Epoch 6880 - Train Loss: 0.157774, Train Acc: 0.705128 | Val Loss: 0.169502, Val Acc: 0.670103\n",
      "Epoch 6881 - Train Loss: 0.157762, Train Acc: 0.705128 | Val Loss: 0.169492, Val Acc: 0.670103\n",
      "Epoch 6882 - Train Loss: 0.157750, Train Acc: 0.705128 | Val Loss: 0.169482, Val Acc: 0.670103\n",
      "Epoch 6883 - Train Loss: 0.157738, Train Acc: 0.705128 | Val Loss: 0.169471, Val Acc: 0.670103\n",
      "Epoch 6884 - Train Loss: 0.157727, Train Acc: 0.705128 | Val Loss: 0.169461, Val Acc: 0.670103\n",
      "Epoch 6885 - Train Loss: 0.157715, Train Acc: 0.705128 | Val Loss: 0.169450, Val Acc: 0.670103\n",
      "Epoch 6886 - Train Loss: 0.157703, Train Acc: 0.705128 | Val Loss: 0.169440, Val Acc: 0.670103\n",
      "Epoch 6887 - Train Loss: 0.157691, Train Acc: 0.705128 | Val Loss: 0.169430, Val Acc: 0.670103\n",
      "Epoch 6888 - Train Loss: 0.157680, Train Acc: 0.705128 | Val Loss: 0.169419, Val Acc: 0.670103\n",
      "Epoch 6889 - Train Loss: 0.157668, Train Acc: 0.705128 | Val Loss: 0.169409, Val Acc: 0.670103\n",
      "Epoch 6890 - Train Loss: 0.157656, Train Acc: 0.705128 | Val Loss: 0.169399, Val Acc: 0.670103\n",
      "Epoch 6891 - Train Loss: 0.157644, Train Acc: 0.705128 | Val Loss: 0.169388, Val Acc: 0.670103\n",
      "Epoch 6892 - Train Loss: 0.157633, Train Acc: 0.705128 | Val Loss: 0.169378, Val Acc: 0.670103\n",
      "Epoch 6893 - Train Loss: 0.157621, Train Acc: 0.705128 | Val Loss: 0.169368, Val Acc: 0.670103\n",
      "Epoch 6894 - Train Loss: 0.157609, Train Acc: 0.705128 | Val Loss: 0.169357, Val Acc: 0.670103\n",
      "Epoch 6895 - Train Loss: 0.157597, Train Acc: 0.705128 | Val Loss: 0.169347, Val Acc: 0.670103\n",
      "Epoch 6896 - Train Loss: 0.157586, Train Acc: 0.705128 | Val Loss: 0.169336, Val Acc: 0.670103\n",
      "Epoch 6897 - Train Loss: 0.157574, Train Acc: 0.705128 | Val Loss: 0.169326, Val Acc: 0.670103\n",
      "Epoch 6898 - Train Loss: 0.157562, Train Acc: 0.705128 | Val Loss: 0.169316, Val Acc: 0.670103\n",
      "Epoch 6899 - Train Loss: 0.157550, Train Acc: 0.705128 | Val Loss: 0.169305, Val Acc: 0.670103\n",
      "Epoch 6900 - Train Loss: 0.157539, Train Acc: 0.705128 | Val Loss: 0.169295, Val Acc: 0.670103\n",
      "Epoch 6901 - Train Loss: 0.157527, Train Acc: 0.705128 | Val Loss: 0.169285, Val Acc: 0.670103\n",
      "Epoch 6902 - Train Loss: 0.157515, Train Acc: 0.705128 | Val Loss: 0.169274, Val Acc: 0.670103\n",
      "Epoch 6903 - Train Loss: 0.157504, Train Acc: 0.706410 | Val Loss: 0.169264, Val Acc: 0.670103\n",
      "Epoch 6904 - Train Loss: 0.157492, Train Acc: 0.706410 | Val Loss: 0.169254, Val Acc: 0.670103\n",
      "Epoch 6905 - Train Loss: 0.157480, Train Acc: 0.707692 | Val Loss: 0.169243, Val Acc: 0.670103\n",
      "Epoch 6906 - Train Loss: 0.157468, Train Acc: 0.707692 | Val Loss: 0.169233, Val Acc: 0.670103\n",
      "Epoch 6907 - Train Loss: 0.157457, Train Acc: 0.707692 | Val Loss: 0.169223, Val Acc: 0.670103\n",
      "Epoch 6908 - Train Loss: 0.157445, Train Acc: 0.707692 | Val Loss: 0.169212, Val Acc: 0.670103\n",
      "Epoch 6909 - Train Loss: 0.157433, Train Acc: 0.707692 | Val Loss: 0.169202, Val Acc: 0.670103\n",
      "Epoch 6910 - Train Loss: 0.157421, Train Acc: 0.707692 | Val Loss: 0.169191, Val Acc: 0.670103\n",
      "Epoch 6911 - Train Loss: 0.157410, Train Acc: 0.707692 | Val Loss: 0.169181, Val Acc: 0.670103\n",
      "Epoch 6912 - Train Loss: 0.157398, Train Acc: 0.707692 | Val Loss: 0.169171, Val Acc: 0.670103\n",
      "Epoch 6913 - Train Loss: 0.157386, Train Acc: 0.707692 | Val Loss: 0.169160, Val Acc: 0.670103\n",
      "Epoch 6914 - Train Loss: 0.157375, Train Acc: 0.707692 | Val Loss: 0.169150, Val Acc: 0.670103\n",
      "Epoch 6915 - Train Loss: 0.157363, Train Acc: 0.707692 | Val Loss: 0.169140, Val Acc: 0.670103\n",
      "Epoch 6916 - Train Loss: 0.157351, Train Acc: 0.707692 | Val Loss: 0.169129, Val Acc: 0.670103\n",
      "Epoch 6917 - Train Loss: 0.157339, Train Acc: 0.707692 | Val Loss: 0.169119, Val Acc: 0.670103\n",
      "Epoch 6918 - Train Loss: 0.157328, Train Acc: 0.707692 | Val Loss: 0.169109, Val Acc: 0.670103\n",
      "Epoch 6919 - Train Loss: 0.157316, Train Acc: 0.707692 | Val Loss: 0.169098, Val Acc: 0.670103\n",
      "Epoch 6920 - Train Loss: 0.157304, Train Acc: 0.707692 | Val Loss: 0.169088, Val Acc: 0.670103\n",
      "Epoch 6921 - Train Loss: 0.157292, Train Acc: 0.707692 | Val Loss: 0.169078, Val Acc: 0.670103\n",
      "Epoch 6922 - Train Loss: 0.157281, Train Acc: 0.707692 | Val Loss: 0.169067, Val Acc: 0.670103\n",
      "Epoch 6923 - Train Loss: 0.157269, Train Acc: 0.707692 | Val Loss: 0.169057, Val Acc: 0.670103\n",
      "Epoch 6924 - Train Loss: 0.157257, Train Acc: 0.707692 | Val Loss: 0.169047, Val Acc: 0.670103\n",
      "Epoch 6925 - Train Loss: 0.157246, Train Acc: 0.707692 | Val Loss: 0.169036, Val Acc: 0.680412\n",
      "Epoch 6926 - Train Loss: 0.157234, Train Acc: 0.707692 | Val Loss: 0.169026, Val Acc: 0.680412\n",
      "Epoch 6927 - Train Loss: 0.157222, Train Acc: 0.707692 | Val Loss: 0.169016, Val Acc: 0.680412\n",
      "Epoch 6928 - Train Loss: 0.157211, Train Acc: 0.707692 | Val Loss: 0.169005, Val Acc: 0.680412\n",
      "Epoch 6929 - Train Loss: 0.157199, Train Acc: 0.707692 | Val Loss: 0.168995, Val Acc: 0.680412\n",
      "Epoch 6930 - Train Loss: 0.157187, Train Acc: 0.707692 | Val Loss: 0.168985, Val Acc: 0.680412\n",
      "Epoch 6931 - Train Loss: 0.157175, Train Acc: 0.707692 | Val Loss: 0.168974, Val Acc: 0.680412\n",
      "Epoch 6932 - Train Loss: 0.157164, Train Acc: 0.707692 | Val Loss: 0.168964, Val Acc: 0.680412\n",
      "Epoch 6933 - Train Loss: 0.157152, Train Acc: 0.707692 | Val Loss: 0.168954, Val Acc: 0.680412\n",
      "Epoch 6934 - Train Loss: 0.157140, Train Acc: 0.707692 | Val Loss: 0.168944, Val Acc: 0.680412\n",
      "Epoch 6935 - Train Loss: 0.157129, Train Acc: 0.707692 | Val Loss: 0.168933, Val Acc: 0.680412\n",
      "Epoch 6936 - Train Loss: 0.157117, Train Acc: 0.707692 | Val Loss: 0.168923, Val Acc: 0.680412\n",
      "Epoch 6937 - Train Loss: 0.157105, Train Acc: 0.707692 | Val Loss: 0.168913, Val Acc: 0.680412\n",
      "Epoch 6938 - Train Loss: 0.157094, Train Acc: 0.707692 | Val Loss: 0.168902, Val Acc: 0.680412\n",
      "Epoch 6939 - Train Loss: 0.157082, Train Acc: 0.707692 | Val Loss: 0.168892, Val Acc: 0.680412\n",
      "Epoch 6940 - Train Loss: 0.157070, Train Acc: 0.707692 | Val Loss: 0.168882, Val Acc: 0.680412\n",
      "Epoch 6941 - Train Loss: 0.157058, Train Acc: 0.707692 | Val Loss: 0.168871, Val Acc: 0.680412\n",
      "Epoch 6942 - Train Loss: 0.157047, Train Acc: 0.707692 | Val Loss: 0.168861, Val Acc: 0.680412\n",
      "Epoch 6943 - Train Loss: 0.157035, Train Acc: 0.707692 | Val Loss: 0.168851, Val Acc: 0.680412\n",
      "Epoch 6944 - Train Loss: 0.157023, Train Acc: 0.707692 | Val Loss: 0.168840, Val Acc: 0.680412\n",
      "Epoch 6945 - Train Loss: 0.157012, Train Acc: 0.707692 | Val Loss: 0.168830, Val Acc: 0.680412\n",
      "Epoch 6946 - Train Loss: 0.157000, Train Acc: 0.707692 | Val Loss: 0.168820, Val Acc: 0.680412\n",
      "Epoch 6947 - Train Loss: 0.156988, Train Acc: 0.707692 | Val Loss: 0.168809, Val Acc: 0.680412\n",
      "Epoch 6948 - Train Loss: 0.156977, Train Acc: 0.707692 | Val Loss: 0.168799, Val Acc: 0.680412\n",
      "Epoch 6949 - Train Loss: 0.156965, Train Acc: 0.707692 | Val Loss: 0.168789, Val Acc: 0.680412\n",
      "Epoch 6950 - Train Loss: 0.156953, Train Acc: 0.707692 | Val Loss: 0.168779, Val Acc: 0.680412\n",
      "Epoch 6951 - Train Loss: 0.156942, Train Acc: 0.708974 | Val Loss: 0.168768, Val Acc: 0.680412\n",
      "Epoch 6952 - Train Loss: 0.156930, Train Acc: 0.708974 | Val Loss: 0.168758, Val Acc: 0.680412\n",
      "Epoch 6953 - Train Loss: 0.156918, Train Acc: 0.708974 | Val Loss: 0.168748, Val Acc: 0.680412\n",
      "Epoch 6954 - Train Loss: 0.156907, Train Acc: 0.708974 | Val Loss: 0.168737, Val Acc: 0.680412\n",
      "Epoch 6955 - Train Loss: 0.156895, Train Acc: 0.708974 | Val Loss: 0.168727, Val Acc: 0.680412\n",
      "Epoch 6956 - Train Loss: 0.156883, Train Acc: 0.708974 | Val Loss: 0.168717, Val Acc: 0.680412\n",
      "Epoch 6957 - Train Loss: 0.156871, Train Acc: 0.708974 | Val Loss: 0.168706, Val Acc: 0.680412\n",
      "Epoch 6958 - Train Loss: 0.156860, Train Acc: 0.708974 | Val Loss: 0.168696, Val Acc: 0.680412\n",
      "Epoch 6959 - Train Loss: 0.156848, Train Acc: 0.708974 | Val Loss: 0.168686, Val Acc: 0.680412\n",
      "Epoch 6960 - Train Loss: 0.156836, Train Acc: 0.708974 | Val Loss: 0.168676, Val Acc: 0.680412\n",
      "Epoch 6961 - Train Loss: 0.156825, Train Acc: 0.708974 | Val Loss: 0.168665, Val Acc: 0.680412\n",
      "Epoch 6962 - Train Loss: 0.156813, Train Acc: 0.708974 | Val Loss: 0.168655, Val Acc: 0.680412\n",
      "Epoch 6963 - Train Loss: 0.156801, Train Acc: 0.708974 | Val Loss: 0.168645, Val Acc: 0.680412\n",
      "Epoch 6964 - Train Loss: 0.156790, Train Acc: 0.708974 | Val Loss: 0.168634, Val Acc: 0.680412\n",
      "Epoch 6965 - Train Loss: 0.156778, Train Acc: 0.708974 | Val Loss: 0.168624, Val Acc: 0.680412\n",
      "Epoch 6966 - Train Loss: 0.156766, Train Acc: 0.708974 | Val Loss: 0.168614, Val Acc: 0.680412\n",
      "Epoch 6967 - Train Loss: 0.156755, Train Acc: 0.708974 | Val Loss: 0.168604, Val Acc: 0.680412\n",
      "Epoch 6968 - Train Loss: 0.156743, Train Acc: 0.708974 | Val Loss: 0.168593, Val Acc: 0.680412\n",
      "Epoch 6969 - Train Loss: 0.156731, Train Acc: 0.708974 | Val Loss: 0.168583, Val Acc: 0.680412\n",
      "Epoch 6970 - Train Loss: 0.156720, Train Acc: 0.708974 | Val Loss: 0.168573, Val Acc: 0.680412\n",
      "Epoch 6971 - Train Loss: 0.156708, Train Acc: 0.708974 | Val Loss: 0.168562, Val Acc: 0.680412\n",
      "Epoch 6972 - Train Loss: 0.156696, Train Acc: 0.708974 | Val Loss: 0.168552, Val Acc: 0.680412\n",
      "Epoch 6973 - Train Loss: 0.156685, Train Acc: 0.708974 | Val Loss: 0.168542, Val Acc: 0.680412\n",
      "Epoch 6974 - Train Loss: 0.156673, Train Acc: 0.708974 | Val Loss: 0.168532, Val Acc: 0.680412\n",
      "Epoch 6975 - Train Loss: 0.156661, Train Acc: 0.708974 | Val Loss: 0.168521, Val Acc: 0.680412\n",
      "Epoch 6976 - Train Loss: 0.156650, Train Acc: 0.708974 | Val Loss: 0.168511, Val Acc: 0.680412\n",
      "Epoch 6977 - Train Loss: 0.156638, Train Acc: 0.708974 | Val Loss: 0.168501, Val Acc: 0.680412\n",
      "Epoch 6978 - Train Loss: 0.156626, Train Acc: 0.708974 | Val Loss: 0.168491, Val Acc: 0.680412\n",
      "Epoch 6979 - Train Loss: 0.156615, Train Acc: 0.708974 | Val Loss: 0.168480, Val Acc: 0.680412\n",
      "Epoch 6980 - Train Loss: 0.156603, Train Acc: 0.708974 | Val Loss: 0.168470, Val Acc: 0.680412\n",
      "Epoch 6981 - Train Loss: 0.156592, Train Acc: 0.708974 | Val Loss: 0.168460, Val Acc: 0.680412\n",
      "Epoch 6982 - Train Loss: 0.156580, Train Acc: 0.708974 | Val Loss: 0.168449, Val Acc: 0.680412\n",
      "Epoch 6983 - Train Loss: 0.156568, Train Acc: 0.708974 | Val Loss: 0.168439, Val Acc: 0.680412\n",
      "Epoch 6984 - Train Loss: 0.156557, Train Acc: 0.708974 | Val Loss: 0.168429, Val Acc: 0.680412\n",
      "Epoch 6985 - Train Loss: 0.156545, Train Acc: 0.708974 | Val Loss: 0.168419, Val Acc: 0.680412\n",
      "Epoch 6986 - Train Loss: 0.156533, Train Acc: 0.708974 | Val Loss: 0.168408, Val Acc: 0.680412\n",
      "Epoch 6987 - Train Loss: 0.156522, Train Acc: 0.708974 | Val Loss: 0.168398, Val Acc: 0.680412\n",
      "Epoch 6988 - Train Loss: 0.156510, Train Acc: 0.708974 | Val Loss: 0.168388, Val Acc: 0.680412\n",
      "Epoch 6989 - Train Loss: 0.156498, Train Acc: 0.710256 | Val Loss: 0.168378, Val Acc: 0.680412\n",
      "Epoch 6990 - Train Loss: 0.156487, Train Acc: 0.710256 | Val Loss: 0.168367, Val Acc: 0.680412\n",
      "Epoch 6991 - Train Loss: 0.156475, Train Acc: 0.710256 | Val Loss: 0.168357, Val Acc: 0.680412\n",
      "Epoch 6992 - Train Loss: 0.156463, Train Acc: 0.710256 | Val Loss: 0.168347, Val Acc: 0.680412\n",
      "Epoch 6993 - Train Loss: 0.156452, Train Acc: 0.710256 | Val Loss: 0.168337, Val Acc: 0.680412\n",
      "Epoch 6994 - Train Loss: 0.156440, Train Acc: 0.710256 | Val Loss: 0.168326, Val Acc: 0.680412\n",
      "Epoch 6995 - Train Loss: 0.156429, Train Acc: 0.710256 | Val Loss: 0.168316, Val Acc: 0.680412\n",
      "Epoch 6996 - Train Loss: 0.156417, Train Acc: 0.710256 | Val Loss: 0.168306, Val Acc: 0.680412\n",
      "Epoch 6997 - Train Loss: 0.156405, Train Acc: 0.710256 | Val Loss: 0.168296, Val Acc: 0.680412\n",
      "Epoch 6998 - Train Loss: 0.156394, Train Acc: 0.710256 | Val Loss: 0.168285, Val Acc: 0.680412\n",
      "Epoch 6999 - Train Loss: 0.156382, Train Acc: 0.710256 | Val Loss: 0.168275, Val Acc: 0.680412\n",
      "Epoch 7000 - Train Loss: 0.156370, Train Acc: 0.710256 | Val Loss: 0.168265, Val Acc: 0.680412\n",
      "Epoch 7001 - Train Loss: 0.156359, Train Acc: 0.710256 | Val Loss: 0.168255, Val Acc: 0.680412\n",
      "Epoch 7002 - Train Loss: 0.156347, Train Acc: 0.710256 | Val Loss: 0.168244, Val Acc: 0.680412\n",
      "Epoch 7003 - Train Loss: 0.156335, Train Acc: 0.710256 | Val Loss: 0.168234, Val Acc: 0.680412\n",
      "Epoch 7004 - Train Loss: 0.156324, Train Acc: 0.710256 | Val Loss: 0.168224, Val Acc: 0.680412\n",
      "Epoch 7005 - Train Loss: 0.156312, Train Acc: 0.710256 | Val Loss: 0.168214, Val Acc: 0.680412\n",
      "Epoch 7006 - Train Loss: 0.156301, Train Acc: 0.710256 | Val Loss: 0.168203, Val Acc: 0.680412\n",
      "Epoch 7007 - Train Loss: 0.156289, Train Acc: 0.710256 | Val Loss: 0.168193, Val Acc: 0.680412\n",
      "Epoch 7008 - Train Loss: 0.156277, Train Acc: 0.710256 | Val Loss: 0.168183, Val Acc: 0.680412\n",
      "Epoch 7009 - Train Loss: 0.156266, Train Acc: 0.710256 | Val Loss: 0.168173, Val Acc: 0.680412\n",
      "Epoch 7010 - Train Loss: 0.156254, Train Acc: 0.710256 | Val Loss: 0.168162, Val Acc: 0.680412\n",
      "Epoch 7011 - Train Loss: 0.156242, Train Acc: 0.710256 | Val Loss: 0.168152, Val Acc: 0.680412\n",
      "Epoch 7012 - Train Loss: 0.156231, Train Acc: 0.710256 | Val Loss: 0.168142, Val Acc: 0.680412\n",
      "Epoch 7013 - Train Loss: 0.156219, Train Acc: 0.711538 | Val Loss: 0.168132, Val Acc: 0.680412\n",
      "Epoch 7014 - Train Loss: 0.156208, Train Acc: 0.711538 | Val Loss: 0.168122, Val Acc: 0.680412\n",
      "Epoch 7015 - Train Loss: 0.156196, Train Acc: 0.711538 | Val Loss: 0.168111, Val Acc: 0.680412\n",
      "Epoch 7016 - Train Loss: 0.156184, Train Acc: 0.711538 | Val Loss: 0.168101, Val Acc: 0.680412\n",
      "Epoch 7017 - Train Loss: 0.156173, Train Acc: 0.711538 | Val Loss: 0.168091, Val Acc: 0.680412\n",
      "Epoch 7018 - Train Loss: 0.156161, Train Acc: 0.711538 | Val Loss: 0.168081, Val Acc: 0.680412\n",
      "Epoch 7019 - Train Loss: 0.156150, Train Acc: 0.711538 | Val Loss: 0.168070, Val Acc: 0.680412\n",
      "Epoch 7020 - Train Loss: 0.156138, Train Acc: 0.711538 | Val Loss: 0.168060, Val Acc: 0.680412\n",
      "Epoch 7021 - Train Loss: 0.156126, Train Acc: 0.711538 | Val Loss: 0.168050, Val Acc: 0.680412\n",
      "Epoch 7022 - Train Loss: 0.156115, Train Acc: 0.711538 | Val Loss: 0.168040, Val Acc: 0.680412\n",
      "Epoch 7023 - Train Loss: 0.156103, Train Acc: 0.711538 | Val Loss: 0.168029, Val Acc: 0.680412\n",
      "Epoch 7024 - Train Loss: 0.156091, Train Acc: 0.711538 | Val Loss: 0.168019, Val Acc: 0.680412\n",
      "Epoch 7025 - Train Loss: 0.156080, Train Acc: 0.711538 | Val Loss: 0.168009, Val Acc: 0.680412\n",
      "Epoch 7026 - Train Loss: 0.156068, Train Acc: 0.711538 | Val Loss: 0.167999, Val Acc: 0.680412\n",
      "Epoch 7027 - Train Loss: 0.156057, Train Acc: 0.711538 | Val Loss: 0.167989, Val Acc: 0.680412\n",
      "Epoch 7028 - Train Loss: 0.156045, Train Acc: 0.711538 | Val Loss: 0.167978, Val Acc: 0.680412\n",
      "Epoch 7029 - Train Loss: 0.156033, Train Acc: 0.711538 | Val Loss: 0.167968, Val Acc: 0.680412\n",
      "Epoch 7030 - Train Loss: 0.156022, Train Acc: 0.711538 | Val Loss: 0.167958, Val Acc: 0.680412\n",
      "Epoch 7031 - Train Loss: 0.156010, Train Acc: 0.711538 | Val Loss: 0.167948, Val Acc: 0.680412\n",
      "Epoch 7032 - Train Loss: 0.155999, Train Acc: 0.712821 | Val Loss: 0.167937, Val Acc: 0.680412\n",
      "Epoch 7033 - Train Loss: 0.155987, Train Acc: 0.712821 | Val Loss: 0.167927, Val Acc: 0.680412\n",
      "Epoch 7034 - Train Loss: 0.155975, Train Acc: 0.712821 | Val Loss: 0.167917, Val Acc: 0.680412\n",
      "Epoch 7035 - Train Loss: 0.155964, Train Acc: 0.712821 | Val Loss: 0.167907, Val Acc: 0.680412\n",
      "Epoch 7036 - Train Loss: 0.155952, Train Acc: 0.712821 | Val Loss: 0.167897, Val Acc: 0.680412\n",
      "Epoch 7037 - Train Loss: 0.155941, Train Acc: 0.712821 | Val Loss: 0.167886, Val Acc: 0.680412\n",
      "Epoch 7038 - Train Loss: 0.155929, Train Acc: 0.712821 | Val Loss: 0.167876, Val Acc: 0.680412\n",
      "Epoch 7039 - Train Loss: 0.155917, Train Acc: 0.712821 | Val Loss: 0.167866, Val Acc: 0.680412\n",
      "Epoch 7040 - Train Loss: 0.155906, Train Acc: 0.712821 | Val Loss: 0.167856, Val Acc: 0.680412\n",
      "Epoch 7041 - Train Loss: 0.155894, Train Acc: 0.712821 | Val Loss: 0.167846, Val Acc: 0.680412\n",
      "Epoch 7042 - Train Loss: 0.155883, Train Acc: 0.712821 | Val Loss: 0.167835, Val Acc: 0.680412\n",
      "Epoch 7043 - Train Loss: 0.155871, Train Acc: 0.712821 | Val Loss: 0.167825, Val Acc: 0.680412\n",
      "Epoch 7044 - Train Loss: 0.155859, Train Acc: 0.712821 | Val Loss: 0.167815, Val Acc: 0.680412\n",
      "Epoch 7045 - Train Loss: 0.155848, Train Acc: 0.712821 | Val Loss: 0.167805, Val Acc: 0.680412\n",
      "Epoch 7046 - Train Loss: 0.155836, Train Acc: 0.712821 | Val Loss: 0.167795, Val Acc: 0.680412\n",
      "Epoch 7047 - Train Loss: 0.155825, Train Acc: 0.712821 | Val Loss: 0.167784, Val Acc: 0.680412\n",
      "Epoch 7048 - Train Loss: 0.155813, Train Acc: 0.712821 | Val Loss: 0.167774, Val Acc: 0.680412\n",
      "Epoch 7049 - Train Loss: 0.155802, Train Acc: 0.712821 | Val Loss: 0.167764, Val Acc: 0.680412\n",
      "Epoch 7050 - Train Loss: 0.155790, Train Acc: 0.712821 | Val Loss: 0.167754, Val Acc: 0.680412\n",
      "Epoch 7051 - Train Loss: 0.155778, Train Acc: 0.712821 | Val Loss: 0.167744, Val Acc: 0.680412\n",
      "Epoch 7052 - Train Loss: 0.155767, Train Acc: 0.712821 | Val Loss: 0.167733, Val Acc: 0.680412\n",
      "Epoch 7053 - Train Loss: 0.155755, Train Acc: 0.712821 | Val Loss: 0.167723, Val Acc: 0.680412\n",
      "Epoch 7054 - Train Loss: 0.155744, Train Acc: 0.712821 | Val Loss: 0.167713, Val Acc: 0.680412\n",
      "Epoch 7055 - Train Loss: 0.155732, Train Acc: 0.712821 | Val Loss: 0.167703, Val Acc: 0.680412\n",
      "Epoch 7056 - Train Loss: 0.155720, Train Acc: 0.712821 | Val Loss: 0.167693, Val Acc: 0.680412\n",
      "Epoch 7057 - Train Loss: 0.155709, Train Acc: 0.712821 | Val Loss: 0.167682, Val Acc: 0.680412\n",
      "Epoch 7058 - Train Loss: 0.155697, Train Acc: 0.712821 | Val Loss: 0.167672, Val Acc: 0.680412\n",
      "Epoch 7059 - Train Loss: 0.155686, Train Acc: 0.712821 | Val Loss: 0.167662, Val Acc: 0.680412\n",
      "Epoch 7060 - Train Loss: 0.155674, Train Acc: 0.712821 | Val Loss: 0.167652, Val Acc: 0.680412\n",
      "Epoch 7061 - Train Loss: 0.155663, Train Acc: 0.712821 | Val Loss: 0.167642, Val Acc: 0.680412\n",
      "Epoch 7062 - Train Loss: 0.155651, Train Acc: 0.712821 | Val Loss: 0.167631, Val Acc: 0.680412\n",
      "Epoch 7063 - Train Loss: 0.155639, Train Acc: 0.712821 | Val Loss: 0.167621, Val Acc: 0.680412\n",
      "Epoch 7064 - Train Loss: 0.155628, Train Acc: 0.712821 | Val Loss: 0.167611, Val Acc: 0.680412\n",
      "Epoch 7065 - Train Loss: 0.155616, Train Acc: 0.712821 | Val Loss: 0.167601, Val Acc: 0.680412\n",
      "Epoch 7066 - Train Loss: 0.155605, Train Acc: 0.712821 | Val Loss: 0.167591, Val Acc: 0.680412\n",
      "Epoch 7067 - Train Loss: 0.155593, Train Acc: 0.712821 | Val Loss: 0.167580, Val Acc: 0.680412\n",
      "Epoch 7068 - Train Loss: 0.155582, Train Acc: 0.712821 | Val Loss: 0.167570, Val Acc: 0.680412\n",
      "Epoch 7069 - Train Loss: 0.155570, Train Acc: 0.712821 | Val Loss: 0.167560, Val Acc: 0.680412\n",
      "Epoch 7070 - Train Loss: 0.155558, Train Acc: 0.712821 | Val Loss: 0.167550, Val Acc: 0.680412\n",
      "Epoch 7071 - Train Loss: 0.155547, Train Acc: 0.712821 | Val Loss: 0.167540, Val Acc: 0.680412\n",
      "Epoch 7072 - Train Loss: 0.155535, Train Acc: 0.712821 | Val Loss: 0.167530, Val Acc: 0.680412\n",
      "Epoch 7073 - Train Loss: 0.155524, Train Acc: 0.712821 | Val Loss: 0.167519, Val Acc: 0.680412\n",
      "Epoch 7074 - Train Loss: 0.155512, Train Acc: 0.712821 | Val Loss: 0.167509, Val Acc: 0.680412\n",
      "Epoch 7075 - Train Loss: 0.155501, Train Acc: 0.712821 | Val Loss: 0.167499, Val Acc: 0.680412\n",
      "Epoch 7076 - Train Loss: 0.155489, Train Acc: 0.712821 | Val Loss: 0.167489, Val Acc: 0.680412\n",
      "Epoch 7077 - Train Loss: 0.155478, Train Acc: 0.712821 | Val Loss: 0.167479, Val Acc: 0.680412\n",
      "Epoch 7078 - Train Loss: 0.155466, Train Acc: 0.712821 | Val Loss: 0.167469, Val Acc: 0.680412\n",
      "Epoch 7079 - Train Loss: 0.155454, Train Acc: 0.712821 | Val Loss: 0.167458, Val Acc: 0.680412\n",
      "Epoch 7080 - Train Loss: 0.155443, Train Acc: 0.712821 | Val Loss: 0.167448, Val Acc: 0.680412\n",
      "Epoch 7081 - Train Loss: 0.155431, Train Acc: 0.712821 | Val Loss: 0.167438, Val Acc: 0.680412\n",
      "Epoch 7082 - Train Loss: 0.155420, Train Acc: 0.712821 | Val Loss: 0.167428, Val Acc: 0.680412\n",
      "Epoch 7083 - Train Loss: 0.155408, Train Acc: 0.712821 | Val Loss: 0.167418, Val Acc: 0.680412\n",
      "Epoch 7084 - Train Loss: 0.155397, Train Acc: 0.712821 | Val Loss: 0.167408, Val Acc: 0.680412\n",
      "Epoch 7085 - Train Loss: 0.155385, Train Acc: 0.712821 | Val Loss: 0.167397, Val Acc: 0.680412\n",
      "Epoch 7086 - Train Loss: 0.155374, Train Acc: 0.712821 | Val Loss: 0.167387, Val Acc: 0.680412\n",
      "Epoch 7087 - Train Loss: 0.155362, Train Acc: 0.712821 | Val Loss: 0.167377, Val Acc: 0.680412\n",
      "Epoch 7088 - Train Loss: 0.155350, Train Acc: 0.712821 | Val Loss: 0.167367, Val Acc: 0.680412\n",
      "Epoch 7089 - Train Loss: 0.155339, Train Acc: 0.712821 | Val Loss: 0.167357, Val Acc: 0.680412\n",
      "Epoch 7090 - Train Loss: 0.155327, Train Acc: 0.712821 | Val Loss: 0.167347, Val Acc: 0.680412\n",
      "Epoch 7091 - Train Loss: 0.155316, Train Acc: 0.712821 | Val Loss: 0.167336, Val Acc: 0.680412\n",
      "Epoch 7092 - Train Loss: 0.155304, Train Acc: 0.712821 | Val Loss: 0.167326, Val Acc: 0.680412\n",
      "Epoch 7093 - Train Loss: 0.155293, Train Acc: 0.712821 | Val Loss: 0.167316, Val Acc: 0.680412\n",
      "Epoch 7094 - Train Loss: 0.155281, Train Acc: 0.712821 | Val Loss: 0.167306, Val Acc: 0.680412\n",
      "Epoch 7095 - Train Loss: 0.155270, Train Acc: 0.712821 | Val Loss: 0.167296, Val Acc: 0.680412\n",
      "Epoch 7096 - Train Loss: 0.155258, Train Acc: 0.712821 | Val Loss: 0.167286, Val Acc: 0.680412\n",
      "Epoch 7097 - Train Loss: 0.155247, Train Acc: 0.712821 | Val Loss: 0.167276, Val Acc: 0.680412\n",
      "Epoch 7098 - Train Loss: 0.155235, Train Acc: 0.712821 | Val Loss: 0.167265, Val Acc: 0.680412\n",
      "Epoch 7099 - Train Loss: 0.155224, Train Acc: 0.712821 | Val Loss: 0.167255, Val Acc: 0.680412\n",
      "Epoch 7100 - Train Loss: 0.155212, Train Acc: 0.712821 | Val Loss: 0.167245, Val Acc: 0.680412\n",
      "Epoch 7101 - Train Loss: 0.155200, Train Acc: 0.712821 | Val Loss: 0.167235, Val Acc: 0.680412\n",
      "Epoch 7102 - Train Loss: 0.155189, Train Acc: 0.712821 | Val Loss: 0.167225, Val Acc: 0.680412\n",
      "Epoch 7103 - Train Loss: 0.155177, Train Acc: 0.712821 | Val Loss: 0.167215, Val Acc: 0.680412\n",
      "Epoch 7104 - Train Loss: 0.155166, Train Acc: 0.712821 | Val Loss: 0.167205, Val Acc: 0.680412\n",
      "Epoch 7105 - Train Loss: 0.155154, Train Acc: 0.712821 | Val Loss: 0.167194, Val Acc: 0.680412\n",
      "Epoch 7106 - Train Loss: 0.155143, Train Acc: 0.712821 | Val Loss: 0.167184, Val Acc: 0.680412\n",
      "Epoch 7107 - Train Loss: 0.155131, Train Acc: 0.712821 | Val Loss: 0.167174, Val Acc: 0.680412\n",
      "Epoch 7108 - Train Loss: 0.155120, Train Acc: 0.712821 | Val Loss: 0.167164, Val Acc: 0.680412\n",
      "Epoch 7109 - Train Loss: 0.155108, Train Acc: 0.712821 | Val Loss: 0.167154, Val Acc: 0.680412\n",
      "Epoch 7110 - Train Loss: 0.155097, Train Acc: 0.712821 | Val Loss: 0.167144, Val Acc: 0.680412\n",
      "Epoch 7111 - Train Loss: 0.155085, Train Acc: 0.712821 | Val Loss: 0.167134, Val Acc: 0.680412\n",
      "Epoch 7112 - Train Loss: 0.155074, Train Acc: 0.712821 | Val Loss: 0.167123, Val Acc: 0.680412\n",
      "Epoch 7113 - Train Loss: 0.155062, Train Acc: 0.712821 | Val Loss: 0.167113, Val Acc: 0.680412\n",
      "Epoch 7114 - Train Loss: 0.155051, Train Acc: 0.712821 | Val Loss: 0.167103, Val Acc: 0.680412\n",
      "Epoch 7115 - Train Loss: 0.155039, Train Acc: 0.712821 | Val Loss: 0.167093, Val Acc: 0.680412\n",
      "Epoch 7116 - Train Loss: 0.155028, Train Acc: 0.712821 | Val Loss: 0.167083, Val Acc: 0.680412\n",
      "Epoch 7117 - Train Loss: 0.155016, Train Acc: 0.712821 | Val Loss: 0.167073, Val Acc: 0.680412\n",
      "Epoch 7118 - Train Loss: 0.155005, Train Acc: 0.712821 | Val Loss: 0.167063, Val Acc: 0.680412\n",
      "Epoch 7119 - Train Loss: 0.154993, Train Acc: 0.712821 | Val Loss: 0.167053, Val Acc: 0.680412\n",
      "Epoch 7120 - Train Loss: 0.154982, Train Acc: 0.712821 | Val Loss: 0.167042, Val Acc: 0.680412\n",
      "Epoch 7121 - Train Loss: 0.154970, Train Acc: 0.712821 | Val Loss: 0.167032, Val Acc: 0.680412\n",
      "Epoch 7122 - Train Loss: 0.154958, Train Acc: 0.712821 | Val Loss: 0.167022, Val Acc: 0.680412\n",
      "Epoch 7123 - Train Loss: 0.154947, Train Acc: 0.714103 | Val Loss: 0.167012, Val Acc: 0.680412\n",
      "Epoch 7124 - Train Loss: 0.154935, Train Acc: 0.714103 | Val Loss: 0.167002, Val Acc: 0.680412\n",
      "Epoch 7125 - Train Loss: 0.154924, Train Acc: 0.714103 | Val Loss: 0.166992, Val Acc: 0.680412\n",
      "Epoch 7126 - Train Loss: 0.154912, Train Acc: 0.714103 | Val Loss: 0.166982, Val Acc: 0.680412\n",
      "Epoch 7127 - Train Loss: 0.154901, Train Acc: 0.714103 | Val Loss: 0.166972, Val Acc: 0.680412\n",
      "Epoch 7128 - Train Loss: 0.154889, Train Acc: 0.714103 | Val Loss: 0.166962, Val Acc: 0.680412\n",
      "Epoch 7129 - Train Loss: 0.154878, Train Acc: 0.714103 | Val Loss: 0.166951, Val Acc: 0.680412\n",
      "Epoch 7130 - Train Loss: 0.154866, Train Acc: 0.714103 | Val Loss: 0.166941, Val Acc: 0.680412\n",
      "Epoch 7131 - Train Loss: 0.154855, Train Acc: 0.714103 | Val Loss: 0.166931, Val Acc: 0.680412\n",
      "Epoch 7132 - Train Loss: 0.154843, Train Acc: 0.714103 | Val Loss: 0.166921, Val Acc: 0.680412\n",
      "Epoch 7133 - Train Loss: 0.154832, Train Acc: 0.714103 | Val Loss: 0.166911, Val Acc: 0.680412\n",
      "Epoch 7134 - Train Loss: 0.154820, Train Acc: 0.714103 | Val Loss: 0.166901, Val Acc: 0.680412\n",
      "Epoch 7135 - Train Loss: 0.154809, Train Acc: 0.714103 | Val Loss: 0.166891, Val Acc: 0.680412\n",
      "Epoch 7136 - Train Loss: 0.154797, Train Acc: 0.714103 | Val Loss: 0.166881, Val Acc: 0.680412\n",
      "Epoch 7137 - Train Loss: 0.154786, Train Acc: 0.714103 | Val Loss: 0.166871, Val Acc: 0.680412\n",
      "Epoch 7138 - Train Loss: 0.154774, Train Acc: 0.714103 | Val Loss: 0.166860, Val Acc: 0.680412\n",
      "Epoch 7139 - Train Loss: 0.154763, Train Acc: 0.714103 | Val Loss: 0.166850, Val Acc: 0.680412\n",
      "Epoch 7140 - Train Loss: 0.154751, Train Acc: 0.714103 | Val Loss: 0.166840, Val Acc: 0.680412\n",
      "Epoch 7141 - Train Loss: 0.154740, Train Acc: 0.714103 | Val Loss: 0.166830, Val Acc: 0.680412\n",
      "Epoch 7142 - Train Loss: 0.154728, Train Acc: 0.714103 | Val Loss: 0.166820, Val Acc: 0.680412\n",
      "Epoch 7143 - Train Loss: 0.154717, Train Acc: 0.714103 | Val Loss: 0.166810, Val Acc: 0.680412\n",
      "Epoch 7144 - Train Loss: 0.154706, Train Acc: 0.714103 | Val Loss: 0.166800, Val Acc: 0.680412\n",
      "Epoch 7145 - Train Loss: 0.154694, Train Acc: 0.714103 | Val Loss: 0.166790, Val Acc: 0.680412\n",
      "Epoch 7146 - Train Loss: 0.154683, Train Acc: 0.714103 | Val Loss: 0.166780, Val Acc: 0.680412\n",
      "Epoch 7147 - Train Loss: 0.154671, Train Acc: 0.714103 | Val Loss: 0.166770, Val Acc: 0.680412\n",
      "Epoch 7148 - Train Loss: 0.154660, Train Acc: 0.714103 | Val Loss: 0.166759, Val Acc: 0.680412\n",
      "Epoch 7149 - Train Loss: 0.154648, Train Acc: 0.714103 | Val Loss: 0.166749, Val Acc: 0.680412\n",
      "Epoch 7150 - Train Loss: 0.154637, Train Acc: 0.714103 | Val Loss: 0.166739, Val Acc: 0.680412\n",
      "Epoch 7151 - Train Loss: 0.154625, Train Acc: 0.714103 | Val Loss: 0.166729, Val Acc: 0.680412\n",
      "Epoch 7152 - Train Loss: 0.154614, Train Acc: 0.714103 | Val Loss: 0.166719, Val Acc: 0.680412\n",
      "Epoch 7153 - Train Loss: 0.154602, Train Acc: 0.714103 | Val Loss: 0.166709, Val Acc: 0.680412\n",
      "Epoch 7154 - Train Loss: 0.154591, Train Acc: 0.714103 | Val Loss: 0.166699, Val Acc: 0.680412\n",
      "Epoch 7155 - Train Loss: 0.154579, Train Acc: 0.714103 | Val Loss: 0.166689, Val Acc: 0.680412\n",
      "Epoch 7156 - Train Loss: 0.154568, Train Acc: 0.714103 | Val Loss: 0.166679, Val Acc: 0.680412\n",
      "Epoch 7157 - Train Loss: 0.154556, Train Acc: 0.714103 | Val Loss: 0.166669, Val Acc: 0.680412\n",
      "Epoch 7158 - Train Loss: 0.154545, Train Acc: 0.714103 | Val Loss: 0.166659, Val Acc: 0.680412\n",
      "Epoch 7159 - Train Loss: 0.154533, Train Acc: 0.714103 | Val Loss: 0.166648, Val Acc: 0.680412\n",
      "Epoch 7160 - Train Loss: 0.154522, Train Acc: 0.714103 | Val Loss: 0.166638, Val Acc: 0.680412\n",
      "Epoch 7161 - Train Loss: 0.154510, Train Acc: 0.714103 | Val Loss: 0.166628, Val Acc: 0.680412\n",
      "Epoch 7162 - Train Loss: 0.154499, Train Acc: 0.714103 | Val Loss: 0.166618, Val Acc: 0.680412\n",
      "Epoch 7163 - Train Loss: 0.154487, Train Acc: 0.714103 | Val Loss: 0.166608, Val Acc: 0.680412\n",
      "Epoch 7164 - Train Loss: 0.154476, Train Acc: 0.714103 | Val Loss: 0.166598, Val Acc: 0.680412\n",
      "Epoch 7165 - Train Loss: 0.154464, Train Acc: 0.714103 | Val Loss: 0.166588, Val Acc: 0.680412\n",
      "Epoch 7166 - Train Loss: 0.154453, Train Acc: 0.714103 | Val Loss: 0.166578, Val Acc: 0.680412\n",
      "Epoch 7167 - Train Loss: 0.154442, Train Acc: 0.714103 | Val Loss: 0.166568, Val Acc: 0.680412\n",
      "Epoch 7168 - Train Loss: 0.154430, Train Acc: 0.714103 | Val Loss: 0.166558, Val Acc: 0.680412\n",
      "Epoch 7169 - Train Loss: 0.154419, Train Acc: 0.714103 | Val Loss: 0.166548, Val Acc: 0.680412\n",
      "Epoch 7170 - Train Loss: 0.154407, Train Acc: 0.714103 | Val Loss: 0.166538, Val Acc: 0.680412\n",
      "Epoch 7171 - Train Loss: 0.154396, Train Acc: 0.714103 | Val Loss: 0.166528, Val Acc: 0.680412\n",
      "Epoch 7172 - Train Loss: 0.154384, Train Acc: 0.714103 | Val Loss: 0.166517, Val Acc: 0.680412\n",
      "Epoch 7173 - Train Loss: 0.154373, Train Acc: 0.714103 | Val Loss: 0.166507, Val Acc: 0.680412\n",
      "Epoch 7174 - Train Loss: 0.154361, Train Acc: 0.715385 | Val Loss: 0.166497, Val Acc: 0.680412\n",
      "Epoch 7175 - Train Loss: 0.154350, Train Acc: 0.715385 | Val Loss: 0.166487, Val Acc: 0.680412\n",
      "Epoch 7176 - Train Loss: 0.154338, Train Acc: 0.715385 | Val Loss: 0.166477, Val Acc: 0.680412\n",
      "Epoch 7177 - Train Loss: 0.154327, Train Acc: 0.715385 | Val Loss: 0.166467, Val Acc: 0.680412\n",
      "Epoch 7178 - Train Loss: 0.154315, Train Acc: 0.715385 | Val Loss: 0.166457, Val Acc: 0.680412\n",
      "Epoch 7179 - Train Loss: 0.154304, Train Acc: 0.715385 | Val Loss: 0.166447, Val Acc: 0.680412\n",
      "Epoch 7180 - Train Loss: 0.154293, Train Acc: 0.715385 | Val Loss: 0.166437, Val Acc: 0.680412\n",
      "Epoch 7181 - Train Loss: 0.154281, Train Acc: 0.715385 | Val Loss: 0.166427, Val Acc: 0.680412\n",
      "Epoch 7182 - Train Loss: 0.154270, Train Acc: 0.715385 | Val Loss: 0.166417, Val Acc: 0.680412\n",
      "Epoch 7183 - Train Loss: 0.154258, Train Acc: 0.715385 | Val Loss: 0.166407, Val Acc: 0.680412\n",
      "Epoch 7184 - Train Loss: 0.154247, Train Acc: 0.715385 | Val Loss: 0.166397, Val Acc: 0.680412\n",
      "Epoch 7185 - Train Loss: 0.154235, Train Acc: 0.715385 | Val Loss: 0.166387, Val Acc: 0.680412\n",
      "Epoch 7186 - Train Loss: 0.154224, Train Acc: 0.715385 | Val Loss: 0.166377, Val Acc: 0.680412\n",
      "Epoch 7187 - Train Loss: 0.154212, Train Acc: 0.715385 | Val Loss: 0.166366, Val Acc: 0.680412\n",
      "Epoch 7188 - Train Loss: 0.154201, Train Acc: 0.715385 | Val Loss: 0.166356, Val Acc: 0.680412\n",
      "Epoch 7189 - Train Loss: 0.154190, Train Acc: 0.715385 | Val Loss: 0.166346, Val Acc: 0.680412\n",
      "Epoch 7190 - Train Loss: 0.154178, Train Acc: 0.715385 | Val Loss: 0.166336, Val Acc: 0.680412\n",
      "Epoch 7191 - Train Loss: 0.154167, Train Acc: 0.715385 | Val Loss: 0.166326, Val Acc: 0.680412\n",
      "Epoch 7192 - Train Loss: 0.154155, Train Acc: 0.715385 | Val Loss: 0.166316, Val Acc: 0.680412\n",
      "Epoch 7193 - Train Loss: 0.154144, Train Acc: 0.715385 | Val Loss: 0.166306, Val Acc: 0.680412\n",
      "Epoch 7194 - Train Loss: 0.154132, Train Acc: 0.715385 | Val Loss: 0.166296, Val Acc: 0.680412\n",
      "Epoch 7195 - Train Loss: 0.154121, Train Acc: 0.715385 | Val Loss: 0.166286, Val Acc: 0.680412\n",
      "Epoch 7196 - Train Loss: 0.154109, Train Acc: 0.715385 | Val Loss: 0.166276, Val Acc: 0.680412\n",
      "Epoch 7197 - Train Loss: 0.154098, Train Acc: 0.716667 | Val Loss: 0.166266, Val Acc: 0.680412\n",
      "Epoch 7198 - Train Loss: 0.154087, Train Acc: 0.716667 | Val Loss: 0.166256, Val Acc: 0.680412\n",
      "Epoch 7199 - Train Loss: 0.154075, Train Acc: 0.716667 | Val Loss: 0.166246, Val Acc: 0.680412\n",
      "Epoch 7200 - Train Loss: 0.154064, Train Acc: 0.716667 | Val Loss: 0.166236, Val Acc: 0.680412\n",
      "Epoch 7201 - Train Loss: 0.154052, Train Acc: 0.716667 | Val Loss: 0.166226, Val Acc: 0.680412\n",
      "Epoch 7202 - Train Loss: 0.154041, Train Acc: 0.716667 | Val Loss: 0.166216, Val Acc: 0.680412\n",
      "Epoch 7203 - Train Loss: 0.154029, Train Acc: 0.716667 | Val Loss: 0.166206, Val Acc: 0.680412\n",
      "Epoch 7204 - Train Loss: 0.154018, Train Acc: 0.716667 | Val Loss: 0.166196, Val Acc: 0.680412\n",
      "Epoch 7205 - Train Loss: 0.154007, Train Acc: 0.716667 | Val Loss: 0.166186, Val Acc: 0.680412\n",
      "Epoch 7206 - Train Loss: 0.153995, Train Acc: 0.716667 | Val Loss: 0.166176, Val Acc: 0.680412\n",
      "Epoch 7207 - Train Loss: 0.153984, Train Acc: 0.716667 | Val Loss: 0.166166, Val Acc: 0.680412\n",
      "Epoch 7208 - Train Loss: 0.153972, Train Acc: 0.716667 | Val Loss: 0.166156, Val Acc: 0.680412\n",
      "Epoch 7209 - Train Loss: 0.153961, Train Acc: 0.716667 | Val Loss: 0.166146, Val Acc: 0.680412\n",
      "Epoch 7210 - Train Loss: 0.153949, Train Acc: 0.716667 | Val Loss: 0.166136, Val Acc: 0.680412\n",
      "Epoch 7211 - Train Loss: 0.153938, Train Acc: 0.716667 | Val Loss: 0.166125, Val Acc: 0.680412\n",
      "Epoch 7212 - Train Loss: 0.153927, Train Acc: 0.716667 | Val Loss: 0.166115, Val Acc: 0.680412\n",
      "Epoch 7213 - Train Loss: 0.153915, Train Acc: 0.716667 | Val Loss: 0.166105, Val Acc: 0.680412\n",
      "Epoch 7214 - Train Loss: 0.153904, Train Acc: 0.716667 | Val Loss: 0.166095, Val Acc: 0.680412\n",
      "Epoch 7215 - Train Loss: 0.153892, Train Acc: 0.716667 | Val Loss: 0.166085, Val Acc: 0.680412\n",
      "Epoch 7216 - Train Loss: 0.153881, Train Acc: 0.716667 | Val Loss: 0.166075, Val Acc: 0.680412\n",
      "Epoch 7217 - Train Loss: 0.153870, Train Acc: 0.716667 | Val Loss: 0.166065, Val Acc: 0.680412\n",
      "Epoch 7218 - Train Loss: 0.153858, Train Acc: 0.716667 | Val Loss: 0.166055, Val Acc: 0.680412\n",
      "Epoch 7219 - Train Loss: 0.153847, Train Acc: 0.716667 | Val Loss: 0.166045, Val Acc: 0.680412\n",
      "Epoch 7220 - Train Loss: 0.153835, Train Acc: 0.716667 | Val Loss: 0.166035, Val Acc: 0.680412\n",
      "Epoch 7221 - Train Loss: 0.153824, Train Acc: 0.716667 | Val Loss: 0.166025, Val Acc: 0.680412\n",
      "Epoch 7222 - Train Loss: 0.153813, Train Acc: 0.716667 | Val Loss: 0.166015, Val Acc: 0.680412\n",
      "Epoch 7223 - Train Loss: 0.153801, Train Acc: 0.716667 | Val Loss: 0.166005, Val Acc: 0.680412\n",
      "Epoch 7224 - Train Loss: 0.153790, Train Acc: 0.716667 | Val Loss: 0.165995, Val Acc: 0.680412\n",
      "Epoch 7225 - Train Loss: 0.153778, Train Acc: 0.716667 | Val Loss: 0.165985, Val Acc: 0.680412\n",
      "Epoch 7226 - Train Loss: 0.153767, Train Acc: 0.716667 | Val Loss: 0.165975, Val Acc: 0.680412\n",
      "Epoch 7227 - Train Loss: 0.153755, Train Acc: 0.716667 | Val Loss: 0.165965, Val Acc: 0.680412\n",
      "Epoch 7228 - Train Loss: 0.153744, Train Acc: 0.716667 | Val Loss: 0.165955, Val Acc: 0.680412\n",
      "Epoch 7229 - Train Loss: 0.153733, Train Acc: 0.716667 | Val Loss: 0.165945, Val Acc: 0.680412\n",
      "Epoch 7230 - Train Loss: 0.153721, Train Acc: 0.716667 | Val Loss: 0.165935, Val Acc: 0.680412\n",
      "Epoch 7231 - Train Loss: 0.153710, Train Acc: 0.716667 | Val Loss: 0.165925, Val Acc: 0.680412\n",
      "Epoch 7232 - Train Loss: 0.153698, Train Acc: 0.716667 | Val Loss: 0.165915, Val Acc: 0.680412\n",
      "Epoch 7233 - Train Loss: 0.153687, Train Acc: 0.716667 | Val Loss: 0.165905, Val Acc: 0.680412\n",
      "Epoch 7234 - Train Loss: 0.153676, Train Acc: 0.716667 | Val Loss: 0.165895, Val Acc: 0.680412\n",
      "Epoch 7235 - Train Loss: 0.153664, Train Acc: 0.716667 | Val Loss: 0.165885, Val Acc: 0.680412\n",
      "Epoch 7236 - Train Loss: 0.153653, Train Acc: 0.716667 | Val Loss: 0.165875, Val Acc: 0.680412\n",
      "Epoch 7237 - Train Loss: 0.153642, Train Acc: 0.716667 | Val Loss: 0.165865, Val Acc: 0.680412\n",
      "Epoch 7238 - Train Loss: 0.153630, Train Acc: 0.716667 | Val Loss: 0.165855, Val Acc: 0.680412\n",
      "Epoch 7239 - Train Loss: 0.153619, Train Acc: 0.716667 | Val Loss: 0.165845, Val Acc: 0.680412\n",
      "Epoch 7240 - Train Loss: 0.153607, Train Acc: 0.716667 | Val Loss: 0.165835, Val Acc: 0.680412\n",
      "Epoch 7241 - Train Loss: 0.153596, Train Acc: 0.716667 | Val Loss: 0.165825, Val Acc: 0.680412\n",
      "Epoch 7242 - Train Loss: 0.153585, Train Acc: 0.716667 | Val Loss: 0.165815, Val Acc: 0.680412\n",
      "Epoch 7243 - Train Loss: 0.153573, Train Acc: 0.716667 | Val Loss: 0.165805, Val Acc: 0.680412\n",
      "Epoch 7244 - Train Loss: 0.153562, Train Acc: 0.716667 | Val Loss: 0.165795, Val Acc: 0.680412\n",
      "Epoch 7245 - Train Loss: 0.153550, Train Acc: 0.716667 | Val Loss: 0.165785, Val Acc: 0.680412\n",
      "Epoch 7246 - Train Loss: 0.153539, Train Acc: 0.716667 | Val Loss: 0.165775, Val Acc: 0.680412\n",
      "Epoch 7247 - Train Loss: 0.153528, Train Acc: 0.716667 | Val Loss: 0.165765, Val Acc: 0.680412\n",
      "Epoch 7248 - Train Loss: 0.153516, Train Acc: 0.716667 | Val Loss: 0.165755, Val Acc: 0.680412\n",
      "Epoch 7249 - Train Loss: 0.153505, Train Acc: 0.716667 | Val Loss: 0.165745, Val Acc: 0.680412\n",
      "Epoch 7250 - Train Loss: 0.153493, Train Acc: 0.716667 | Val Loss: 0.165735, Val Acc: 0.680412\n",
      "Epoch 7251 - Train Loss: 0.153482, Train Acc: 0.716667 | Val Loss: 0.165725, Val Acc: 0.680412\n",
      "Epoch 7252 - Train Loss: 0.153471, Train Acc: 0.716667 | Val Loss: 0.165715, Val Acc: 0.680412\n",
      "Epoch 7253 - Train Loss: 0.153459, Train Acc: 0.716667 | Val Loss: 0.165705, Val Acc: 0.680412\n",
      "Epoch 7254 - Train Loss: 0.153448, Train Acc: 0.716667 | Val Loss: 0.165695, Val Acc: 0.680412\n",
      "Epoch 7255 - Train Loss: 0.153437, Train Acc: 0.716667 | Val Loss: 0.165685, Val Acc: 0.680412\n",
      "Epoch 7256 - Train Loss: 0.153425, Train Acc: 0.716667 | Val Loss: 0.165675, Val Acc: 0.680412\n",
      "Epoch 7257 - Train Loss: 0.153414, Train Acc: 0.716667 | Val Loss: 0.165665, Val Acc: 0.680412\n",
      "Epoch 7258 - Train Loss: 0.153402, Train Acc: 0.716667 | Val Loss: 0.165655, Val Acc: 0.680412\n",
      "Epoch 7259 - Train Loss: 0.153391, Train Acc: 0.716667 | Val Loss: 0.165645, Val Acc: 0.680412\n",
      "Epoch 7260 - Train Loss: 0.153380, Train Acc: 0.716667 | Val Loss: 0.165635, Val Acc: 0.680412\n",
      "Epoch 7261 - Train Loss: 0.153368, Train Acc: 0.716667 | Val Loss: 0.165625, Val Acc: 0.680412\n",
      "Epoch 7262 - Train Loss: 0.153357, Train Acc: 0.716667 | Val Loss: 0.165615, Val Acc: 0.680412\n",
      "Epoch 7263 - Train Loss: 0.153346, Train Acc: 0.716667 | Val Loss: 0.165605, Val Acc: 0.680412\n",
      "Epoch 7264 - Train Loss: 0.153334, Train Acc: 0.716667 | Val Loss: 0.165595, Val Acc: 0.680412\n",
      "Epoch 7265 - Train Loss: 0.153323, Train Acc: 0.716667 | Val Loss: 0.165585, Val Acc: 0.680412\n",
      "Epoch 7266 - Train Loss: 0.153312, Train Acc: 0.716667 | Val Loss: 0.165575, Val Acc: 0.680412\n",
      "Epoch 7267 - Train Loss: 0.153300, Train Acc: 0.716667 | Val Loss: 0.165565, Val Acc: 0.680412\n",
      "Epoch 7268 - Train Loss: 0.153289, Train Acc: 0.716667 | Val Loss: 0.165556, Val Acc: 0.680412\n",
      "Epoch 7269 - Train Loss: 0.153277, Train Acc: 0.716667 | Val Loss: 0.165546, Val Acc: 0.680412\n",
      "Epoch 7270 - Train Loss: 0.153266, Train Acc: 0.716667 | Val Loss: 0.165536, Val Acc: 0.680412\n",
      "Epoch 7271 - Train Loss: 0.153255, Train Acc: 0.716667 | Val Loss: 0.165526, Val Acc: 0.680412\n",
      "Epoch 7272 - Train Loss: 0.153243, Train Acc: 0.716667 | Val Loss: 0.165516, Val Acc: 0.680412\n",
      "Epoch 7273 - Train Loss: 0.153232, Train Acc: 0.716667 | Val Loss: 0.165506, Val Acc: 0.680412\n",
      "Epoch 7274 - Train Loss: 0.153221, Train Acc: 0.716667 | Val Loss: 0.165496, Val Acc: 0.680412\n",
      "Epoch 7275 - Train Loss: 0.153209, Train Acc: 0.716667 | Val Loss: 0.165486, Val Acc: 0.680412\n",
      "Epoch 7276 - Train Loss: 0.153198, Train Acc: 0.716667 | Val Loss: 0.165476, Val Acc: 0.680412\n",
      "Epoch 7277 - Train Loss: 0.153187, Train Acc: 0.716667 | Val Loss: 0.165466, Val Acc: 0.680412\n",
      "Epoch 7278 - Train Loss: 0.153175, Train Acc: 0.716667 | Val Loss: 0.165456, Val Acc: 0.680412\n",
      "Epoch 7279 - Train Loss: 0.153164, Train Acc: 0.716667 | Val Loss: 0.165446, Val Acc: 0.680412\n",
      "Epoch 7280 - Train Loss: 0.153153, Train Acc: 0.716667 | Val Loss: 0.165436, Val Acc: 0.680412\n",
      "Epoch 7281 - Train Loss: 0.153141, Train Acc: 0.716667 | Val Loss: 0.165426, Val Acc: 0.680412\n",
      "Epoch 7282 - Train Loss: 0.153130, Train Acc: 0.716667 | Val Loss: 0.165416, Val Acc: 0.680412\n",
      "Epoch 7283 - Train Loss: 0.153119, Train Acc: 0.716667 | Val Loss: 0.165406, Val Acc: 0.680412\n",
      "Epoch 7284 - Train Loss: 0.153107, Train Acc: 0.716667 | Val Loss: 0.165396, Val Acc: 0.680412\n",
      "Epoch 7285 - Train Loss: 0.153096, Train Acc: 0.716667 | Val Loss: 0.165386, Val Acc: 0.680412\n",
      "Epoch 7286 - Train Loss: 0.153084, Train Acc: 0.716667 | Val Loss: 0.165376, Val Acc: 0.680412\n",
      "Epoch 7287 - Train Loss: 0.153073, Train Acc: 0.716667 | Val Loss: 0.165366, Val Acc: 0.680412\n",
      "Epoch 7288 - Train Loss: 0.153062, Train Acc: 0.716667 | Val Loss: 0.165356, Val Acc: 0.680412\n",
      "Epoch 7289 - Train Loss: 0.153050, Train Acc: 0.716667 | Val Loss: 0.165346, Val Acc: 0.680412\n",
      "Epoch 7290 - Train Loss: 0.153039, Train Acc: 0.716667 | Val Loss: 0.165336, Val Acc: 0.680412\n",
      "Epoch 7291 - Train Loss: 0.153028, Train Acc: 0.716667 | Val Loss: 0.165327, Val Acc: 0.680412\n",
      "Epoch 7292 - Train Loss: 0.153016, Train Acc: 0.716667 | Val Loss: 0.165317, Val Acc: 0.680412\n",
      "Epoch 7293 - Train Loss: 0.153005, Train Acc: 0.716667 | Val Loss: 0.165307, Val Acc: 0.680412\n",
      "Epoch 7294 - Train Loss: 0.152994, Train Acc: 0.716667 | Val Loss: 0.165297, Val Acc: 0.680412\n",
      "Epoch 7295 - Train Loss: 0.152982, Train Acc: 0.716667 | Val Loss: 0.165287, Val Acc: 0.680412\n",
      "Epoch 7296 - Train Loss: 0.152971, Train Acc: 0.716667 | Val Loss: 0.165277, Val Acc: 0.680412\n",
      "Epoch 7297 - Train Loss: 0.152960, Train Acc: 0.716667 | Val Loss: 0.165267, Val Acc: 0.680412\n",
      "Epoch 7298 - Train Loss: 0.152948, Train Acc: 0.716667 | Val Loss: 0.165257, Val Acc: 0.680412\n",
      "Epoch 7299 - Train Loss: 0.152937, Train Acc: 0.716667 | Val Loss: 0.165247, Val Acc: 0.680412\n",
      "Epoch 7300 - Train Loss: 0.152926, Train Acc: 0.716667 | Val Loss: 0.165237, Val Acc: 0.680412\n",
      "Epoch 7301 - Train Loss: 0.152914, Train Acc: 0.716667 | Val Loss: 0.165227, Val Acc: 0.680412\n",
      "Epoch 7302 - Train Loss: 0.152903, Train Acc: 0.716667 | Val Loss: 0.165217, Val Acc: 0.680412\n",
      "Epoch 7303 - Train Loss: 0.152892, Train Acc: 0.716667 | Val Loss: 0.165207, Val Acc: 0.680412\n",
      "Epoch 7304 - Train Loss: 0.152880, Train Acc: 0.716667 | Val Loss: 0.165198, Val Acc: 0.680412\n",
      "Epoch 7305 - Train Loss: 0.152869, Train Acc: 0.716667 | Val Loss: 0.165188, Val Acc: 0.680412\n",
      "Epoch 7306 - Train Loss: 0.152858, Train Acc: 0.716667 | Val Loss: 0.165178, Val Acc: 0.680412\n",
      "Epoch 7307 - Train Loss: 0.152847, Train Acc: 0.716667 | Val Loss: 0.165168, Val Acc: 0.680412\n",
      "Epoch 7308 - Train Loss: 0.152835, Train Acc: 0.716667 | Val Loss: 0.165158, Val Acc: 0.680412\n",
      "Epoch 7309 - Train Loss: 0.152824, Train Acc: 0.716667 | Val Loss: 0.165148, Val Acc: 0.680412\n",
      "Epoch 7310 - Train Loss: 0.152813, Train Acc: 0.716667 | Val Loss: 0.165138, Val Acc: 0.680412\n",
      "Epoch 7311 - Train Loss: 0.152801, Train Acc: 0.716667 | Val Loss: 0.165128, Val Acc: 0.680412\n",
      "Epoch 7312 - Train Loss: 0.152790, Train Acc: 0.716667 | Val Loss: 0.165118, Val Acc: 0.680412\n",
      "Epoch 7313 - Train Loss: 0.152779, Train Acc: 0.716667 | Val Loss: 0.165108, Val Acc: 0.680412\n",
      "Epoch 7314 - Train Loss: 0.152767, Train Acc: 0.716667 | Val Loss: 0.165099, Val Acc: 0.680412\n",
      "Epoch 7315 - Train Loss: 0.152756, Train Acc: 0.716667 | Val Loss: 0.165089, Val Acc: 0.680412\n",
      "Epoch 7316 - Train Loss: 0.152745, Train Acc: 0.716667 | Val Loss: 0.165079, Val Acc: 0.680412\n",
      "Epoch 7317 - Train Loss: 0.152733, Train Acc: 0.716667 | Val Loss: 0.165069, Val Acc: 0.680412\n",
      "Epoch 7318 - Train Loss: 0.152722, Train Acc: 0.716667 | Val Loss: 0.165059, Val Acc: 0.680412\n",
      "Epoch 7319 - Train Loss: 0.152711, Train Acc: 0.716667 | Val Loss: 0.165049, Val Acc: 0.680412\n",
      "Epoch 7320 - Train Loss: 0.152699, Train Acc: 0.716667 | Val Loss: 0.165039, Val Acc: 0.680412\n",
      "Epoch 7321 - Train Loss: 0.152688, Train Acc: 0.716667 | Val Loss: 0.165029, Val Acc: 0.680412\n",
      "Epoch 7322 - Train Loss: 0.152677, Train Acc: 0.716667 | Val Loss: 0.165019, Val Acc: 0.680412\n",
      "Epoch 7323 - Train Loss: 0.152665, Train Acc: 0.716667 | Val Loss: 0.165009, Val Acc: 0.680412\n",
      "Epoch 7324 - Train Loss: 0.152654, Train Acc: 0.716667 | Val Loss: 0.165000, Val Acc: 0.680412\n",
      "Epoch 7325 - Train Loss: 0.152643, Train Acc: 0.716667 | Val Loss: 0.164990, Val Acc: 0.680412\n",
      "Epoch 7326 - Train Loss: 0.152632, Train Acc: 0.716667 | Val Loss: 0.164980, Val Acc: 0.680412\n",
      "Epoch 7327 - Train Loss: 0.152620, Train Acc: 0.716667 | Val Loss: 0.164970, Val Acc: 0.680412\n",
      "Epoch 7328 - Train Loss: 0.152609, Train Acc: 0.716667 | Val Loss: 0.164960, Val Acc: 0.680412\n",
      "Epoch 7329 - Train Loss: 0.152598, Train Acc: 0.716667 | Val Loss: 0.164950, Val Acc: 0.680412\n",
      "Epoch 7330 - Train Loss: 0.152586, Train Acc: 0.716667 | Val Loss: 0.164940, Val Acc: 0.680412\n",
      "Epoch 7331 - Train Loss: 0.152575, Train Acc: 0.716667 | Val Loss: 0.164930, Val Acc: 0.680412\n",
      "Epoch 7332 - Train Loss: 0.152564, Train Acc: 0.716667 | Val Loss: 0.164921, Val Acc: 0.680412\n",
      "Epoch 7333 - Train Loss: 0.152552, Train Acc: 0.716667 | Val Loss: 0.164911, Val Acc: 0.680412\n",
      "Epoch 7334 - Train Loss: 0.152541, Train Acc: 0.716667 | Val Loss: 0.164901, Val Acc: 0.680412\n",
      "Epoch 7335 - Train Loss: 0.152530, Train Acc: 0.716667 | Val Loss: 0.164891, Val Acc: 0.680412\n",
      "Epoch 7336 - Train Loss: 0.152519, Train Acc: 0.716667 | Val Loss: 0.164881, Val Acc: 0.680412\n",
      "Epoch 7337 - Train Loss: 0.152507, Train Acc: 0.716667 | Val Loss: 0.164871, Val Acc: 0.680412\n",
      "Epoch 7338 - Train Loss: 0.152496, Train Acc: 0.716667 | Val Loss: 0.164861, Val Acc: 0.680412\n",
      "Epoch 7339 - Train Loss: 0.152485, Train Acc: 0.716667 | Val Loss: 0.164851, Val Acc: 0.680412\n",
      "Epoch 7340 - Train Loss: 0.152473, Train Acc: 0.716667 | Val Loss: 0.164842, Val Acc: 0.680412\n",
      "Epoch 7341 - Train Loss: 0.152462, Train Acc: 0.716667 | Val Loss: 0.164832, Val Acc: 0.680412\n",
      "Epoch 7342 - Train Loss: 0.152451, Train Acc: 0.716667 | Val Loss: 0.164822, Val Acc: 0.680412\n",
      "Epoch 7343 - Train Loss: 0.152440, Train Acc: 0.716667 | Val Loss: 0.164812, Val Acc: 0.680412\n",
      "Epoch 7344 - Train Loss: 0.152428, Train Acc: 0.716667 | Val Loss: 0.164802, Val Acc: 0.680412\n",
      "Epoch 7345 - Train Loss: 0.152417, Train Acc: 0.716667 | Val Loss: 0.164792, Val Acc: 0.680412\n",
      "Epoch 7346 - Train Loss: 0.152406, Train Acc: 0.716667 | Val Loss: 0.164782, Val Acc: 0.680412\n",
      "Epoch 7347 - Train Loss: 0.152394, Train Acc: 0.716667 | Val Loss: 0.164772, Val Acc: 0.680412\n",
      "Epoch 7348 - Train Loss: 0.152383, Train Acc: 0.716667 | Val Loss: 0.164763, Val Acc: 0.680412\n",
      "Epoch 7349 - Train Loss: 0.152372, Train Acc: 0.716667 | Val Loss: 0.164753, Val Acc: 0.680412\n",
      "Epoch 7350 - Train Loss: 0.152361, Train Acc: 0.716667 | Val Loss: 0.164743, Val Acc: 0.680412\n",
      "Epoch 7351 - Train Loss: 0.152349, Train Acc: 0.716667 | Val Loss: 0.164733, Val Acc: 0.680412\n",
      "Epoch 7352 - Train Loss: 0.152338, Train Acc: 0.716667 | Val Loss: 0.164723, Val Acc: 0.680412\n",
      "Epoch 7353 - Train Loss: 0.152327, Train Acc: 0.716667 | Val Loss: 0.164713, Val Acc: 0.690722\n",
      "Epoch 7354 - Train Loss: 0.152316, Train Acc: 0.716667 | Val Loss: 0.164703, Val Acc: 0.690722\n",
      "Epoch 7355 - Train Loss: 0.152304, Train Acc: 0.716667 | Val Loss: 0.164694, Val Acc: 0.690722\n",
      "Epoch 7356 - Train Loss: 0.152293, Train Acc: 0.716667 | Val Loss: 0.164684, Val Acc: 0.690722\n",
      "Epoch 7357 - Train Loss: 0.152282, Train Acc: 0.716667 | Val Loss: 0.164674, Val Acc: 0.690722\n",
      "Epoch 7358 - Train Loss: 0.152270, Train Acc: 0.716667 | Val Loss: 0.164664, Val Acc: 0.690722\n",
      "Epoch 7359 - Train Loss: 0.152259, Train Acc: 0.716667 | Val Loss: 0.164654, Val Acc: 0.690722\n",
      "Epoch 7360 - Train Loss: 0.152248, Train Acc: 0.716667 | Val Loss: 0.164644, Val Acc: 0.690722\n",
      "Epoch 7361 - Train Loss: 0.152237, Train Acc: 0.717949 | Val Loss: 0.164635, Val Acc: 0.690722\n",
      "Epoch 7362 - Train Loss: 0.152225, Train Acc: 0.717949 | Val Loss: 0.164625, Val Acc: 0.690722\n",
      "Epoch 7363 - Train Loss: 0.152214, Train Acc: 0.717949 | Val Loss: 0.164615, Val Acc: 0.690722\n",
      "Epoch 7364 - Train Loss: 0.152203, Train Acc: 0.717949 | Val Loss: 0.164605, Val Acc: 0.690722\n",
      "Epoch 7365 - Train Loss: 0.152192, Train Acc: 0.717949 | Val Loss: 0.164595, Val Acc: 0.690722\n",
      "Epoch 7366 - Train Loss: 0.152180, Train Acc: 0.717949 | Val Loss: 0.164585, Val Acc: 0.690722\n",
      "Epoch 7367 - Train Loss: 0.152169, Train Acc: 0.717949 | Val Loss: 0.164575, Val Acc: 0.690722\n",
      "Epoch 7368 - Train Loss: 0.152158, Train Acc: 0.717949 | Val Loss: 0.164566, Val Acc: 0.690722\n",
      "Epoch 7369 - Train Loss: 0.152147, Train Acc: 0.717949 | Val Loss: 0.164556, Val Acc: 0.690722\n",
      "Epoch 7370 - Train Loss: 0.152135, Train Acc: 0.717949 | Val Loss: 0.164546, Val Acc: 0.690722\n",
      "Epoch 7371 - Train Loss: 0.152124, Train Acc: 0.717949 | Val Loss: 0.164536, Val Acc: 0.690722\n",
      "Epoch 7372 - Train Loss: 0.152113, Train Acc: 0.717949 | Val Loss: 0.164526, Val Acc: 0.690722\n",
      "Epoch 7373 - Train Loss: 0.152102, Train Acc: 0.717949 | Val Loss: 0.164516, Val Acc: 0.690722\n",
      "Epoch 7374 - Train Loss: 0.152090, Train Acc: 0.719231 | Val Loss: 0.164507, Val Acc: 0.690722\n",
      "Epoch 7375 - Train Loss: 0.152079, Train Acc: 0.719231 | Val Loss: 0.164497, Val Acc: 0.690722\n",
      "Epoch 7376 - Train Loss: 0.152068, Train Acc: 0.719231 | Val Loss: 0.164487, Val Acc: 0.690722\n",
      "Epoch 7377 - Train Loss: 0.152057, Train Acc: 0.720513 | Val Loss: 0.164477, Val Acc: 0.690722\n",
      "Epoch 7378 - Train Loss: 0.152045, Train Acc: 0.720513 | Val Loss: 0.164467, Val Acc: 0.690722\n",
      "Epoch 7379 - Train Loss: 0.152034, Train Acc: 0.720513 | Val Loss: 0.164457, Val Acc: 0.690722\n",
      "Epoch 7380 - Train Loss: 0.152023, Train Acc: 0.720513 | Val Loss: 0.164448, Val Acc: 0.690722\n",
      "Epoch 7381 - Train Loss: 0.152012, Train Acc: 0.720513 | Val Loss: 0.164438, Val Acc: 0.690722\n",
      "Epoch 7382 - Train Loss: 0.152000, Train Acc: 0.720513 | Val Loss: 0.164428, Val Acc: 0.690722\n",
      "Epoch 7383 - Train Loss: 0.151989, Train Acc: 0.720513 | Val Loss: 0.164418, Val Acc: 0.690722\n",
      "Epoch 7384 - Train Loss: 0.151978, Train Acc: 0.720513 | Val Loss: 0.164408, Val Acc: 0.690722\n",
      "Epoch 7385 - Train Loss: 0.151967, Train Acc: 0.720513 | Val Loss: 0.164398, Val Acc: 0.690722\n",
      "Epoch 7386 - Train Loss: 0.151955, Train Acc: 0.720513 | Val Loss: 0.164389, Val Acc: 0.690722\n",
      "Epoch 7387 - Train Loss: 0.151944, Train Acc: 0.720513 | Val Loss: 0.164379, Val Acc: 0.690722\n",
      "Epoch 7388 - Train Loss: 0.151933, Train Acc: 0.720513 | Val Loss: 0.164369, Val Acc: 0.690722\n",
      "Epoch 7389 - Train Loss: 0.151922, Train Acc: 0.720513 | Val Loss: 0.164359, Val Acc: 0.690722\n",
      "Epoch 7390 - Train Loss: 0.151910, Train Acc: 0.720513 | Val Loss: 0.164349, Val Acc: 0.690722\n",
      "Epoch 7391 - Train Loss: 0.151899, Train Acc: 0.720513 | Val Loss: 0.164340, Val Acc: 0.690722\n",
      "Epoch 7392 - Train Loss: 0.151888, Train Acc: 0.720513 | Val Loss: 0.164330, Val Acc: 0.690722\n",
      "Epoch 7393 - Train Loss: 0.151877, Train Acc: 0.720513 | Val Loss: 0.164320, Val Acc: 0.690722\n",
      "Epoch 7394 - Train Loss: 0.151865, Train Acc: 0.720513 | Val Loss: 0.164310, Val Acc: 0.690722\n",
      "Epoch 7395 - Train Loss: 0.151854, Train Acc: 0.720513 | Val Loss: 0.164300, Val Acc: 0.690722\n",
      "Epoch 7396 - Train Loss: 0.151843, Train Acc: 0.720513 | Val Loss: 0.164291, Val Acc: 0.690722\n",
      "Epoch 7397 - Train Loss: 0.151832, Train Acc: 0.720513 | Val Loss: 0.164281, Val Acc: 0.690722\n",
      "Epoch 7398 - Train Loss: 0.151821, Train Acc: 0.720513 | Val Loss: 0.164271, Val Acc: 0.690722\n",
      "Epoch 7399 - Train Loss: 0.151809, Train Acc: 0.720513 | Val Loss: 0.164261, Val Acc: 0.690722\n",
      "Epoch 7400 - Train Loss: 0.151798, Train Acc: 0.720513 | Val Loss: 0.164251, Val Acc: 0.690722\n",
      "Epoch 7401 - Train Loss: 0.151787, Train Acc: 0.720513 | Val Loss: 0.164242, Val Acc: 0.690722\n",
      "Epoch 7402 - Train Loss: 0.151776, Train Acc: 0.720513 | Val Loss: 0.164232, Val Acc: 0.690722\n",
      "Epoch 7403 - Train Loss: 0.151764, Train Acc: 0.720513 | Val Loss: 0.164222, Val Acc: 0.690722\n",
      "Epoch 7404 - Train Loss: 0.151753, Train Acc: 0.720513 | Val Loss: 0.164212, Val Acc: 0.690722\n",
      "Epoch 7405 - Train Loss: 0.151742, Train Acc: 0.720513 | Val Loss: 0.164202, Val Acc: 0.690722\n",
      "Epoch 7406 - Train Loss: 0.151731, Train Acc: 0.720513 | Val Loss: 0.164192, Val Acc: 0.690722\n",
      "Epoch 7407 - Train Loss: 0.151720, Train Acc: 0.720513 | Val Loss: 0.164183, Val Acc: 0.690722\n",
      "Epoch 7408 - Train Loss: 0.151708, Train Acc: 0.720513 | Val Loss: 0.164173, Val Acc: 0.690722\n",
      "Epoch 7409 - Train Loss: 0.151697, Train Acc: 0.720513 | Val Loss: 0.164163, Val Acc: 0.690722\n",
      "Epoch 7410 - Train Loss: 0.151686, Train Acc: 0.720513 | Val Loss: 0.164153, Val Acc: 0.690722\n",
      "Epoch 7411 - Train Loss: 0.151675, Train Acc: 0.720513 | Val Loss: 0.164144, Val Acc: 0.690722\n",
      "Epoch 7412 - Train Loss: 0.151663, Train Acc: 0.720513 | Val Loss: 0.164134, Val Acc: 0.690722\n",
      "Epoch 7413 - Train Loss: 0.151652, Train Acc: 0.720513 | Val Loss: 0.164124, Val Acc: 0.690722\n",
      "Epoch 7414 - Train Loss: 0.151641, Train Acc: 0.720513 | Val Loss: 0.164114, Val Acc: 0.690722\n",
      "Epoch 7415 - Train Loss: 0.151630, Train Acc: 0.720513 | Val Loss: 0.164104, Val Acc: 0.690722\n",
      "Epoch 7416 - Train Loss: 0.151619, Train Acc: 0.720513 | Val Loss: 0.164095, Val Acc: 0.690722\n",
      "Epoch 7417 - Train Loss: 0.151607, Train Acc: 0.720513 | Val Loss: 0.164085, Val Acc: 0.690722\n",
      "Epoch 7418 - Train Loss: 0.151596, Train Acc: 0.720513 | Val Loss: 0.164075, Val Acc: 0.690722\n",
      "Epoch 7419 - Train Loss: 0.151585, Train Acc: 0.720513 | Val Loss: 0.164065, Val Acc: 0.690722\n",
      "Epoch 7420 - Train Loss: 0.151574, Train Acc: 0.720513 | Val Loss: 0.164055, Val Acc: 0.690722\n",
      "Epoch 7421 - Train Loss: 0.151563, Train Acc: 0.720513 | Val Loss: 0.164046, Val Acc: 0.690722\n",
      "Epoch 7422 - Train Loss: 0.151551, Train Acc: 0.720513 | Val Loss: 0.164036, Val Acc: 0.690722\n",
      "Epoch 7423 - Train Loss: 0.151540, Train Acc: 0.720513 | Val Loss: 0.164026, Val Acc: 0.690722\n",
      "Epoch 7424 - Train Loss: 0.151529, Train Acc: 0.720513 | Val Loss: 0.164016, Val Acc: 0.690722\n",
      "Epoch 7425 - Train Loss: 0.151518, Train Acc: 0.720513 | Val Loss: 0.164007, Val Acc: 0.690722\n",
      "Epoch 7426 - Train Loss: 0.151507, Train Acc: 0.720513 | Val Loss: 0.163997, Val Acc: 0.690722\n",
      "Epoch 7427 - Train Loss: 0.151495, Train Acc: 0.720513 | Val Loss: 0.163987, Val Acc: 0.690722\n",
      "Epoch 7428 - Train Loss: 0.151484, Train Acc: 0.720513 | Val Loss: 0.163977, Val Acc: 0.690722\n",
      "Epoch 7429 - Train Loss: 0.151473, Train Acc: 0.720513 | Val Loss: 0.163967, Val Acc: 0.690722\n",
      "Epoch 7430 - Train Loss: 0.151462, Train Acc: 0.720513 | Val Loss: 0.163958, Val Acc: 0.690722\n",
      "Epoch 7431 - Train Loss: 0.151451, Train Acc: 0.719231 | Val Loss: 0.163948, Val Acc: 0.690722\n",
      "Epoch 7432 - Train Loss: 0.151439, Train Acc: 0.719231 | Val Loss: 0.163938, Val Acc: 0.690722\n",
      "Epoch 7433 - Train Loss: 0.151428, Train Acc: 0.719231 | Val Loss: 0.163928, Val Acc: 0.690722\n",
      "Epoch 7434 - Train Loss: 0.151417, Train Acc: 0.719231 | Val Loss: 0.163919, Val Acc: 0.690722\n",
      "Epoch 7435 - Train Loss: 0.151406, Train Acc: 0.719231 | Val Loss: 0.163909, Val Acc: 0.690722\n",
      "Epoch 7436 - Train Loss: 0.151395, Train Acc: 0.719231 | Val Loss: 0.163899, Val Acc: 0.690722\n",
      "Epoch 7437 - Train Loss: 0.151383, Train Acc: 0.719231 | Val Loss: 0.163889, Val Acc: 0.690722\n",
      "Epoch 7438 - Train Loss: 0.151372, Train Acc: 0.719231 | Val Loss: 0.163879, Val Acc: 0.690722\n",
      "Epoch 7439 - Train Loss: 0.151361, Train Acc: 0.719231 | Val Loss: 0.163870, Val Acc: 0.690722\n",
      "Epoch 7440 - Train Loss: 0.151350, Train Acc: 0.719231 | Val Loss: 0.163860, Val Acc: 0.690722\n",
      "Epoch 7441 - Train Loss: 0.151339, Train Acc: 0.719231 | Val Loss: 0.163850, Val Acc: 0.690722\n",
      "Epoch 7442 - Train Loss: 0.151328, Train Acc: 0.719231 | Val Loss: 0.163840, Val Acc: 0.690722\n",
      "Epoch 7443 - Train Loss: 0.151316, Train Acc: 0.719231 | Val Loss: 0.163831, Val Acc: 0.690722\n",
      "Epoch 7444 - Train Loss: 0.151305, Train Acc: 0.719231 | Val Loss: 0.163821, Val Acc: 0.690722\n",
      "Epoch 7445 - Train Loss: 0.151294, Train Acc: 0.719231 | Val Loss: 0.163811, Val Acc: 0.690722\n",
      "Epoch 7446 - Train Loss: 0.151283, Train Acc: 0.719231 | Val Loss: 0.163801, Val Acc: 0.690722\n",
      "Epoch 7447 - Train Loss: 0.151272, Train Acc: 0.719231 | Val Loss: 0.163792, Val Acc: 0.690722\n",
      "Epoch 7448 - Train Loss: 0.151260, Train Acc: 0.719231 | Val Loss: 0.163782, Val Acc: 0.690722\n",
      "Epoch 7449 - Train Loss: 0.151249, Train Acc: 0.719231 | Val Loss: 0.163772, Val Acc: 0.690722\n",
      "Epoch 7450 - Train Loss: 0.151238, Train Acc: 0.719231 | Val Loss: 0.163762, Val Acc: 0.690722\n",
      "Epoch 7451 - Train Loss: 0.151227, Train Acc: 0.719231 | Val Loss: 0.163753, Val Acc: 0.690722\n",
      "Epoch 7452 - Train Loss: 0.151216, Train Acc: 0.719231 | Val Loss: 0.163743, Val Acc: 0.690722\n",
      "Epoch 7453 - Train Loss: 0.151205, Train Acc: 0.719231 | Val Loss: 0.163733, Val Acc: 0.690722\n",
      "Epoch 7454 - Train Loss: 0.151193, Train Acc: 0.719231 | Val Loss: 0.163723, Val Acc: 0.690722\n",
      "Epoch 7455 - Train Loss: 0.151182, Train Acc: 0.719231 | Val Loss: 0.163714, Val Acc: 0.690722\n",
      "Epoch 7456 - Train Loss: 0.151171, Train Acc: 0.719231 | Val Loss: 0.163704, Val Acc: 0.690722\n",
      "Epoch 7457 - Train Loss: 0.151160, Train Acc: 0.719231 | Val Loss: 0.163694, Val Acc: 0.690722\n",
      "Epoch 7458 - Train Loss: 0.151149, Train Acc: 0.719231 | Val Loss: 0.163684, Val Acc: 0.690722\n",
      "Epoch 7459 - Train Loss: 0.151138, Train Acc: 0.719231 | Val Loss: 0.163675, Val Acc: 0.690722\n",
      "Epoch 7460 - Train Loss: 0.151126, Train Acc: 0.719231 | Val Loss: 0.163665, Val Acc: 0.690722\n",
      "Epoch 7461 - Train Loss: 0.151115, Train Acc: 0.719231 | Val Loss: 0.163655, Val Acc: 0.690722\n",
      "Epoch 7462 - Train Loss: 0.151104, Train Acc: 0.719231 | Val Loss: 0.163645, Val Acc: 0.690722\n",
      "Epoch 7463 - Train Loss: 0.151093, Train Acc: 0.719231 | Val Loss: 0.163636, Val Acc: 0.690722\n",
      "Epoch 7464 - Train Loss: 0.151082, Train Acc: 0.719231 | Val Loss: 0.163626, Val Acc: 0.690722\n",
      "Epoch 7465 - Train Loss: 0.151071, Train Acc: 0.719231 | Val Loss: 0.163616, Val Acc: 0.690722\n",
      "Epoch 7466 - Train Loss: 0.151059, Train Acc: 0.719231 | Val Loss: 0.163607, Val Acc: 0.690722\n",
      "Epoch 7467 - Train Loss: 0.151048, Train Acc: 0.719231 | Val Loss: 0.163597, Val Acc: 0.690722\n",
      "Epoch 7468 - Train Loss: 0.151037, Train Acc: 0.719231 | Val Loss: 0.163587, Val Acc: 0.690722\n",
      "Epoch 7469 - Train Loss: 0.151026, Train Acc: 0.719231 | Val Loss: 0.163577, Val Acc: 0.690722\n",
      "Epoch 7470 - Train Loss: 0.151015, Train Acc: 0.719231 | Val Loss: 0.163568, Val Acc: 0.690722\n",
      "Epoch 7471 - Train Loss: 0.151004, Train Acc: 0.719231 | Val Loss: 0.163558, Val Acc: 0.690722\n",
      "Epoch 7472 - Train Loss: 0.150993, Train Acc: 0.719231 | Val Loss: 0.163548, Val Acc: 0.690722\n",
      "Epoch 7473 - Train Loss: 0.150981, Train Acc: 0.719231 | Val Loss: 0.163538, Val Acc: 0.690722\n",
      "Epoch 7474 - Train Loss: 0.150970, Train Acc: 0.719231 | Val Loss: 0.163529, Val Acc: 0.690722\n",
      "Epoch 7475 - Train Loss: 0.150959, Train Acc: 0.719231 | Val Loss: 0.163519, Val Acc: 0.690722\n",
      "Epoch 7476 - Train Loss: 0.150948, Train Acc: 0.719231 | Val Loss: 0.163509, Val Acc: 0.690722\n",
      "Epoch 7477 - Train Loss: 0.150937, Train Acc: 0.719231 | Val Loss: 0.163500, Val Acc: 0.690722\n",
      "Epoch 7478 - Train Loss: 0.150926, Train Acc: 0.719231 | Val Loss: 0.163490, Val Acc: 0.690722\n",
      "Epoch 7479 - Train Loss: 0.150915, Train Acc: 0.719231 | Val Loss: 0.163480, Val Acc: 0.690722\n",
      "Epoch 7480 - Train Loss: 0.150903, Train Acc: 0.719231 | Val Loss: 0.163470, Val Acc: 0.690722\n",
      "Epoch 7481 - Train Loss: 0.150892, Train Acc: 0.719231 | Val Loss: 0.163461, Val Acc: 0.690722\n",
      "Epoch 7482 - Train Loss: 0.150881, Train Acc: 0.719231 | Val Loss: 0.163451, Val Acc: 0.690722\n",
      "Epoch 7483 - Train Loss: 0.150870, Train Acc: 0.719231 | Val Loss: 0.163441, Val Acc: 0.690722\n",
      "Epoch 7484 - Train Loss: 0.150859, Train Acc: 0.719231 | Val Loss: 0.163432, Val Acc: 0.690722\n",
      "Epoch 7485 - Train Loss: 0.150848, Train Acc: 0.719231 | Val Loss: 0.163422, Val Acc: 0.690722\n",
      "Epoch 7486 - Train Loss: 0.150837, Train Acc: 0.719231 | Val Loss: 0.163412, Val Acc: 0.690722\n",
      "Epoch 7487 - Train Loss: 0.150825, Train Acc: 0.719231 | Val Loss: 0.163402, Val Acc: 0.690722\n",
      "Epoch 7488 - Train Loss: 0.150814, Train Acc: 0.719231 | Val Loss: 0.163393, Val Acc: 0.690722\n",
      "Epoch 7489 - Train Loss: 0.150803, Train Acc: 0.719231 | Val Loss: 0.163383, Val Acc: 0.690722\n",
      "Epoch 7490 - Train Loss: 0.150792, Train Acc: 0.719231 | Val Loss: 0.163373, Val Acc: 0.690722\n",
      "Epoch 7491 - Train Loss: 0.150781, Train Acc: 0.719231 | Val Loss: 0.163364, Val Acc: 0.701031\n",
      "Epoch 7492 - Train Loss: 0.150770, Train Acc: 0.719231 | Val Loss: 0.163354, Val Acc: 0.701031\n",
      "Epoch 7493 - Train Loss: 0.150759, Train Acc: 0.720513 | Val Loss: 0.163344, Val Acc: 0.701031\n",
      "Epoch 7494 - Train Loss: 0.150748, Train Acc: 0.720513 | Val Loss: 0.163334, Val Acc: 0.701031\n",
      "Epoch 7495 - Train Loss: 0.150736, Train Acc: 0.720513 | Val Loss: 0.163325, Val Acc: 0.701031\n",
      "Epoch 7496 - Train Loss: 0.150725, Train Acc: 0.720513 | Val Loss: 0.163315, Val Acc: 0.701031\n",
      "Epoch 7497 - Train Loss: 0.150714, Train Acc: 0.720513 | Val Loss: 0.163305, Val Acc: 0.701031\n",
      "Epoch 7498 - Train Loss: 0.150703, Train Acc: 0.720513 | Val Loss: 0.163296, Val Acc: 0.701031\n",
      "Epoch 7499 - Train Loss: 0.150692, Train Acc: 0.720513 | Val Loss: 0.163286, Val Acc: 0.701031\n",
      "Epoch 7500 - Train Loss: 0.150681, Train Acc: 0.720513 | Val Loss: 0.163276, Val Acc: 0.701031\n",
      "Epoch 7501 - Train Loss: 0.150670, Train Acc: 0.720513 | Val Loss: 0.163267, Val Acc: 0.701031\n",
      "Epoch 7502 - Train Loss: 0.150659, Train Acc: 0.720513 | Val Loss: 0.163257, Val Acc: 0.701031\n",
      "Epoch 7503 - Train Loss: 0.150647, Train Acc: 0.720513 | Val Loss: 0.163247, Val Acc: 0.701031\n",
      "Epoch 7504 - Train Loss: 0.150636, Train Acc: 0.720513 | Val Loss: 0.163238, Val Acc: 0.701031\n",
      "Epoch 7505 - Train Loss: 0.150625, Train Acc: 0.720513 | Val Loss: 0.163228, Val Acc: 0.701031\n",
      "Epoch 7506 - Train Loss: 0.150614, Train Acc: 0.720513 | Val Loss: 0.163218, Val Acc: 0.701031\n",
      "Epoch 7507 - Train Loss: 0.150603, Train Acc: 0.720513 | Val Loss: 0.163208, Val Acc: 0.701031\n",
      "Epoch 7508 - Train Loss: 0.150592, Train Acc: 0.720513 | Val Loss: 0.163199, Val Acc: 0.701031\n",
      "Epoch 7509 - Train Loss: 0.150581, Train Acc: 0.720513 | Val Loss: 0.163189, Val Acc: 0.701031\n",
      "Epoch 7510 - Train Loss: 0.150570, Train Acc: 0.720513 | Val Loss: 0.163179, Val Acc: 0.701031\n",
      "Epoch 7511 - Train Loss: 0.150558, Train Acc: 0.720513 | Val Loss: 0.163170, Val Acc: 0.701031\n",
      "Epoch 7512 - Train Loss: 0.150547, Train Acc: 0.720513 | Val Loss: 0.163160, Val Acc: 0.701031\n",
      "Epoch 7513 - Train Loss: 0.150536, Train Acc: 0.720513 | Val Loss: 0.163150, Val Acc: 0.701031\n",
      "Epoch 7514 - Train Loss: 0.150525, Train Acc: 0.720513 | Val Loss: 0.163141, Val Acc: 0.701031\n",
      "Epoch 7515 - Train Loss: 0.150514, Train Acc: 0.720513 | Val Loss: 0.163131, Val Acc: 0.701031\n",
      "Epoch 7516 - Train Loss: 0.150503, Train Acc: 0.720513 | Val Loss: 0.163121, Val Acc: 0.701031\n",
      "Epoch 7517 - Train Loss: 0.150492, Train Acc: 0.720513 | Val Loss: 0.163112, Val Acc: 0.701031\n",
      "Epoch 7518 - Train Loss: 0.150481, Train Acc: 0.720513 | Val Loss: 0.163102, Val Acc: 0.701031\n",
      "Epoch 7519 - Train Loss: 0.150470, Train Acc: 0.720513 | Val Loss: 0.163092, Val Acc: 0.701031\n",
      "Epoch 7520 - Train Loss: 0.150459, Train Acc: 0.720513 | Val Loss: 0.163083, Val Acc: 0.701031\n",
      "Epoch 7521 - Train Loss: 0.150447, Train Acc: 0.720513 | Val Loss: 0.163073, Val Acc: 0.701031\n",
      "Epoch 7522 - Train Loss: 0.150436, Train Acc: 0.720513 | Val Loss: 0.163063, Val Acc: 0.701031\n",
      "Epoch 7523 - Train Loss: 0.150425, Train Acc: 0.720513 | Val Loss: 0.163054, Val Acc: 0.701031\n",
      "Epoch 7524 - Train Loss: 0.150414, Train Acc: 0.720513 | Val Loss: 0.163044, Val Acc: 0.701031\n",
      "Epoch 7525 - Train Loss: 0.150403, Train Acc: 0.720513 | Val Loss: 0.163034, Val Acc: 0.701031\n",
      "Epoch 7526 - Train Loss: 0.150392, Train Acc: 0.720513 | Val Loss: 0.163025, Val Acc: 0.701031\n",
      "Epoch 7527 - Train Loss: 0.150381, Train Acc: 0.720513 | Val Loss: 0.163015, Val Acc: 0.701031\n",
      "Epoch 7528 - Train Loss: 0.150370, Train Acc: 0.721795 | Val Loss: 0.163005, Val Acc: 0.701031\n",
      "Epoch 7529 - Train Loss: 0.150359, Train Acc: 0.721795 | Val Loss: 0.162996, Val Acc: 0.701031\n",
      "Epoch 7530 - Train Loss: 0.150348, Train Acc: 0.721795 | Val Loss: 0.162986, Val Acc: 0.701031\n",
      "Epoch 7531 - Train Loss: 0.150337, Train Acc: 0.721795 | Val Loss: 0.162976, Val Acc: 0.701031\n",
      "Epoch 7532 - Train Loss: 0.150325, Train Acc: 0.721795 | Val Loss: 0.162967, Val Acc: 0.701031\n",
      "Epoch 7533 - Train Loss: 0.150314, Train Acc: 0.721795 | Val Loss: 0.162957, Val Acc: 0.701031\n",
      "Epoch 7534 - Train Loss: 0.150303, Train Acc: 0.721795 | Val Loss: 0.162947, Val Acc: 0.701031\n",
      "Epoch 7535 - Train Loss: 0.150292, Train Acc: 0.721795 | Val Loss: 0.162938, Val Acc: 0.701031\n",
      "Epoch 7536 - Train Loss: 0.150281, Train Acc: 0.721795 | Val Loss: 0.162928, Val Acc: 0.701031\n",
      "Epoch 7537 - Train Loss: 0.150270, Train Acc: 0.721795 | Val Loss: 0.162918, Val Acc: 0.701031\n",
      "Epoch 7538 - Train Loss: 0.150259, Train Acc: 0.721795 | Val Loss: 0.162909, Val Acc: 0.701031\n",
      "Epoch 7539 - Train Loss: 0.150248, Train Acc: 0.721795 | Val Loss: 0.162899, Val Acc: 0.701031\n",
      "Epoch 7540 - Train Loss: 0.150237, Train Acc: 0.721795 | Val Loss: 0.162890, Val Acc: 0.701031\n",
      "Epoch 7541 - Train Loss: 0.150226, Train Acc: 0.721795 | Val Loss: 0.162880, Val Acc: 0.701031\n",
      "Epoch 7542 - Train Loss: 0.150215, Train Acc: 0.721795 | Val Loss: 0.162870, Val Acc: 0.701031\n",
      "Epoch 7543 - Train Loss: 0.150204, Train Acc: 0.721795 | Val Loss: 0.162861, Val Acc: 0.701031\n",
      "Epoch 7544 - Train Loss: 0.150192, Train Acc: 0.721795 | Val Loss: 0.162851, Val Acc: 0.711340\n",
      "Epoch 7545 - Train Loss: 0.150181, Train Acc: 0.721795 | Val Loss: 0.162841, Val Acc: 0.711340\n",
      "Epoch 7546 - Train Loss: 0.150170, Train Acc: 0.723077 | Val Loss: 0.162832, Val Acc: 0.711340\n",
      "Epoch 7547 - Train Loss: 0.150159, Train Acc: 0.723077 | Val Loss: 0.162822, Val Acc: 0.711340\n",
      "Epoch 7548 - Train Loss: 0.150148, Train Acc: 0.724359 | Val Loss: 0.162812, Val Acc: 0.711340\n",
      "Epoch 7549 - Train Loss: 0.150137, Train Acc: 0.724359 | Val Loss: 0.162803, Val Acc: 0.711340\n",
      "Epoch 7550 - Train Loss: 0.150126, Train Acc: 0.724359 | Val Loss: 0.162793, Val Acc: 0.711340\n",
      "Epoch 7551 - Train Loss: 0.150115, Train Acc: 0.724359 | Val Loss: 0.162783, Val Acc: 0.711340\n",
      "Epoch 7552 - Train Loss: 0.150104, Train Acc: 0.724359 | Val Loss: 0.162774, Val Acc: 0.711340\n",
      "Epoch 7553 - Train Loss: 0.150093, Train Acc: 0.724359 | Val Loss: 0.162764, Val Acc: 0.711340\n",
      "Epoch 7554 - Train Loss: 0.150082, Train Acc: 0.724359 | Val Loss: 0.162755, Val Acc: 0.711340\n",
      "Epoch 7555 - Train Loss: 0.150071, Train Acc: 0.724359 | Val Loss: 0.162745, Val Acc: 0.711340\n",
      "Epoch 7556 - Train Loss: 0.150060, Train Acc: 0.724359 | Val Loss: 0.162735, Val Acc: 0.711340\n",
      "Epoch 7557 - Train Loss: 0.150049, Train Acc: 0.724359 | Val Loss: 0.162726, Val Acc: 0.711340\n",
      "Epoch 7558 - Train Loss: 0.150037, Train Acc: 0.724359 | Val Loss: 0.162716, Val Acc: 0.711340\n",
      "Epoch 7559 - Train Loss: 0.150026, Train Acc: 0.724359 | Val Loss: 0.162706, Val Acc: 0.711340\n",
      "Epoch 7560 - Train Loss: 0.150015, Train Acc: 0.724359 | Val Loss: 0.162697, Val Acc: 0.711340\n",
      "Epoch 7561 - Train Loss: 0.150004, Train Acc: 0.724359 | Val Loss: 0.162687, Val Acc: 0.711340\n",
      "Epoch 7562 - Train Loss: 0.149993, Train Acc: 0.724359 | Val Loss: 0.162678, Val Acc: 0.711340\n",
      "Epoch 7563 - Train Loss: 0.149982, Train Acc: 0.724359 | Val Loss: 0.162668, Val Acc: 0.711340\n",
      "Epoch 7564 - Train Loss: 0.149971, Train Acc: 0.724359 | Val Loss: 0.162658, Val Acc: 0.711340\n",
      "Epoch 7565 - Train Loss: 0.149960, Train Acc: 0.724359 | Val Loss: 0.162649, Val Acc: 0.711340\n",
      "Epoch 7566 - Train Loss: 0.149949, Train Acc: 0.724359 | Val Loss: 0.162639, Val Acc: 0.711340\n",
      "Epoch 7567 - Train Loss: 0.149938, Train Acc: 0.724359 | Val Loss: 0.162629, Val Acc: 0.711340\n",
      "Epoch 7568 - Train Loss: 0.149927, Train Acc: 0.724359 | Val Loss: 0.162620, Val Acc: 0.711340\n",
      "Epoch 7569 - Train Loss: 0.149916, Train Acc: 0.724359 | Val Loss: 0.162610, Val Acc: 0.711340\n",
      "Epoch 7570 - Train Loss: 0.149905, Train Acc: 0.724359 | Val Loss: 0.162601, Val Acc: 0.711340\n",
      "Epoch 7571 - Train Loss: 0.149894, Train Acc: 0.724359 | Val Loss: 0.162591, Val Acc: 0.711340\n",
      "Epoch 7572 - Train Loss: 0.149883, Train Acc: 0.724359 | Val Loss: 0.162581, Val Acc: 0.711340\n",
      "Epoch 7573 - Train Loss: 0.149872, Train Acc: 0.724359 | Val Loss: 0.162572, Val Acc: 0.711340\n",
      "Epoch 7574 - Train Loss: 0.149861, Train Acc: 0.724359 | Val Loss: 0.162562, Val Acc: 0.711340\n",
      "Epoch 7575 - Train Loss: 0.149850, Train Acc: 0.725641 | Val Loss: 0.162553, Val Acc: 0.711340\n",
      "Epoch 7576 - Train Loss: 0.149839, Train Acc: 0.725641 | Val Loss: 0.162543, Val Acc: 0.711340\n",
      "Epoch 7577 - Train Loss: 0.149828, Train Acc: 0.725641 | Val Loss: 0.162533, Val Acc: 0.711340\n",
      "Epoch 7578 - Train Loss: 0.149816, Train Acc: 0.725641 | Val Loss: 0.162524, Val Acc: 0.711340\n",
      "Epoch 7579 - Train Loss: 0.149805, Train Acc: 0.725641 | Val Loss: 0.162514, Val Acc: 0.711340\n",
      "Epoch 7580 - Train Loss: 0.149794, Train Acc: 0.725641 | Val Loss: 0.162504, Val Acc: 0.711340\n",
      "Epoch 7581 - Train Loss: 0.149783, Train Acc: 0.725641 | Val Loss: 0.162495, Val Acc: 0.711340\n",
      "Epoch 7582 - Train Loss: 0.149772, Train Acc: 0.725641 | Val Loss: 0.162485, Val Acc: 0.711340\n",
      "Epoch 7583 - Train Loss: 0.149761, Train Acc: 0.725641 | Val Loss: 0.162476, Val Acc: 0.711340\n",
      "Epoch 7584 - Train Loss: 0.149750, Train Acc: 0.725641 | Val Loss: 0.162466, Val Acc: 0.711340\n",
      "Epoch 7585 - Train Loss: 0.149739, Train Acc: 0.725641 | Val Loss: 0.162456, Val Acc: 0.711340\n",
      "Epoch 7586 - Train Loss: 0.149728, Train Acc: 0.725641 | Val Loss: 0.162447, Val Acc: 0.711340\n",
      "Epoch 7587 - Train Loss: 0.149717, Train Acc: 0.725641 | Val Loss: 0.162437, Val Acc: 0.711340\n",
      "Epoch 7588 - Train Loss: 0.149706, Train Acc: 0.725641 | Val Loss: 0.162428, Val Acc: 0.711340\n",
      "Epoch 7589 - Train Loss: 0.149695, Train Acc: 0.725641 | Val Loss: 0.162418, Val Acc: 0.711340\n",
      "Epoch 7590 - Train Loss: 0.149684, Train Acc: 0.725641 | Val Loss: 0.162408, Val Acc: 0.711340\n",
      "Epoch 7591 - Train Loss: 0.149673, Train Acc: 0.725641 | Val Loss: 0.162399, Val Acc: 0.711340\n",
      "Epoch 7592 - Train Loss: 0.149662, Train Acc: 0.725641 | Val Loss: 0.162389, Val Acc: 0.711340\n",
      "Epoch 7593 - Train Loss: 0.149651, Train Acc: 0.725641 | Val Loss: 0.162380, Val Acc: 0.711340\n",
      "Epoch 7594 - Train Loss: 0.149640, Train Acc: 0.725641 | Val Loss: 0.162370, Val Acc: 0.711340\n",
      "Epoch 7595 - Train Loss: 0.149629, Train Acc: 0.725641 | Val Loss: 0.162361, Val Acc: 0.711340\n",
      "Epoch 7596 - Train Loss: 0.149618, Train Acc: 0.725641 | Val Loss: 0.162351, Val Acc: 0.711340\n",
      "Epoch 7597 - Train Loss: 0.149607, Train Acc: 0.725641 | Val Loss: 0.162341, Val Acc: 0.711340\n",
      "Epoch 7598 - Train Loss: 0.149596, Train Acc: 0.725641 | Val Loss: 0.162332, Val Acc: 0.711340\n",
      "Epoch 7599 - Train Loss: 0.149585, Train Acc: 0.726923 | Val Loss: 0.162322, Val Acc: 0.711340\n",
      "Epoch 7600 - Train Loss: 0.149574, Train Acc: 0.726923 | Val Loss: 0.162313, Val Acc: 0.711340\n",
      "Epoch 7601 - Train Loss: 0.149563, Train Acc: 0.726923 | Val Loss: 0.162303, Val Acc: 0.711340\n",
      "Epoch 7602 - Train Loss: 0.149552, Train Acc: 0.726923 | Val Loss: 0.162293, Val Acc: 0.711340\n",
      "Epoch 7603 - Train Loss: 0.149541, Train Acc: 0.726923 | Val Loss: 0.162284, Val Acc: 0.711340\n",
      "Epoch 7604 - Train Loss: 0.149530, Train Acc: 0.726923 | Val Loss: 0.162274, Val Acc: 0.711340\n",
      "Epoch 7605 - Train Loss: 0.149519, Train Acc: 0.726923 | Val Loss: 0.162265, Val Acc: 0.711340\n",
      "Epoch 7606 - Train Loss: 0.149508, Train Acc: 0.726923 | Val Loss: 0.162255, Val Acc: 0.711340\n",
      "Epoch 7607 - Train Loss: 0.149497, Train Acc: 0.726923 | Val Loss: 0.162246, Val Acc: 0.711340\n",
      "Epoch 7608 - Train Loss: 0.149486, Train Acc: 0.726923 | Val Loss: 0.162236, Val Acc: 0.711340\n",
      "Epoch 7609 - Train Loss: 0.149475, Train Acc: 0.726923 | Val Loss: 0.162226, Val Acc: 0.711340\n",
      "Epoch 7610 - Train Loss: 0.149464, Train Acc: 0.726923 | Val Loss: 0.162217, Val Acc: 0.711340\n",
      "Epoch 7611 - Train Loss: 0.149453, Train Acc: 0.726923 | Val Loss: 0.162207, Val Acc: 0.711340\n",
      "Epoch 7612 - Train Loss: 0.149442, Train Acc: 0.726923 | Val Loss: 0.162198, Val Acc: 0.711340\n",
      "Epoch 7613 - Train Loss: 0.149431, Train Acc: 0.726923 | Val Loss: 0.162188, Val Acc: 0.711340\n",
      "Epoch 7614 - Train Loss: 0.149420, Train Acc: 0.726923 | Val Loss: 0.162179, Val Acc: 0.711340\n",
      "Epoch 7615 - Train Loss: 0.149409, Train Acc: 0.726923 | Val Loss: 0.162169, Val Acc: 0.711340\n",
      "Epoch 7616 - Train Loss: 0.149398, Train Acc: 0.726923 | Val Loss: 0.162159, Val Acc: 0.711340\n",
      "Epoch 7617 - Train Loss: 0.149387, Train Acc: 0.726923 | Val Loss: 0.162150, Val Acc: 0.711340\n",
      "Epoch 7618 - Train Loss: 0.149376, Train Acc: 0.726923 | Val Loss: 0.162140, Val Acc: 0.711340\n",
      "Epoch 7619 - Train Loss: 0.149365, Train Acc: 0.726923 | Val Loss: 0.162131, Val Acc: 0.711340\n",
      "Epoch 7620 - Train Loss: 0.149354, Train Acc: 0.726923 | Val Loss: 0.162121, Val Acc: 0.711340\n",
      "Epoch 7621 - Train Loss: 0.149343, Train Acc: 0.726923 | Val Loss: 0.162112, Val Acc: 0.711340\n",
      "Epoch 7622 - Train Loss: 0.149332, Train Acc: 0.726923 | Val Loss: 0.162102, Val Acc: 0.711340\n",
      "Epoch 7623 - Train Loss: 0.149321, Train Acc: 0.726923 | Val Loss: 0.162092, Val Acc: 0.711340\n",
      "Epoch 7624 - Train Loss: 0.149310, Train Acc: 0.726923 | Val Loss: 0.162083, Val Acc: 0.711340\n",
      "Epoch 7625 - Train Loss: 0.149299, Train Acc: 0.726923 | Val Loss: 0.162073, Val Acc: 0.711340\n",
      "Epoch 7626 - Train Loss: 0.149288, Train Acc: 0.726923 | Val Loss: 0.162064, Val Acc: 0.711340\n",
      "Epoch 7627 - Train Loss: 0.149277, Train Acc: 0.726923 | Val Loss: 0.162054, Val Acc: 0.711340\n",
      "Epoch 7628 - Train Loss: 0.149266, Train Acc: 0.726923 | Val Loss: 0.162045, Val Acc: 0.711340\n",
      "Epoch 7629 - Train Loss: 0.149255, Train Acc: 0.726923 | Val Loss: 0.162035, Val Acc: 0.711340\n",
      "Epoch 7630 - Train Loss: 0.149244, Train Acc: 0.726923 | Val Loss: 0.162026, Val Acc: 0.711340\n",
      "Epoch 7631 - Train Loss: 0.149233, Train Acc: 0.726923 | Val Loss: 0.162016, Val Acc: 0.711340\n",
      "Epoch 7632 - Train Loss: 0.149222, Train Acc: 0.726923 | Val Loss: 0.162006, Val Acc: 0.711340\n",
      "Epoch 7633 - Train Loss: 0.149211, Train Acc: 0.726923 | Val Loss: 0.161997, Val Acc: 0.711340\n",
      "Epoch 7634 - Train Loss: 0.149200, Train Acc: 0.726923 | Val Loss: 0.161987, Val Acc: 0.711340\n",
      "Epoch 7635 - Train Loss: 0.149189, Train Acc: 0.726923 | Val Loss: 0.161978, Val Acc: 0.711340\n",
      "Epoch 7636 - Train Loss: 0.149178, Train Acc: 0.726923 | Val Loss: 0.161968, Val Acc: 0.711340\n",
      "Epoch 7637 - Train Loss: 0.149167, Train Acc: 0.726923 | Val Loss: 0.161959, Val Acc: 0.711340\n",
      "Epoch 7638 - Train Loss: 0.149156, Train Acc: 0.726923 | Val Loss: 0.161949, Val Acc: 0.711340\n",
      "Epoch 7639 - Train Loss: 0.149145, Train Acc: 0.726923 | Val Loss: 0.161940, Val Acc: 0.711340\n",
      "Epoch 7640 - Train Loss: 0.149134, Train Acc: 0.726923 | Val Loss: 0.161930, Val Acc: 0.711340\n",
      "Epoch 7641 - Train Loss: 0.149123, Train Acc: 0.726923 | Val Loss: 0.161921, Val Acc: 0.711340\n",
      "Epoch 7642 - Train Loss: 0.149112, Train Acc: 0.726923 | Val Loss: 0.161911, Val Acc: 0.711340\n",
      "Epoch 7643 - Train Loss: 0.149101, Train Acc: 0.726923 | Val Loss: 0.161902, Val Acc: 0.711340\n",
      "Epoch 7644 - Train Loss: 0.149090, Train Acc: 0.726923 | Val Loss: 0.161892, Val Acc: 0.711340\n",
      "Epoch 7645 - Train Loss: 0.149079, Train Acc: 0.726923 | Val Loss: 0.161882, Val Acc: 0.711340\n",
      "Epoch 7646 - Train Loss: 0.149068, Train Acc: 0.726923 | Val Loss: 0.161873, Val Acc: 0.711340\n",
      "Epoch 7647 - Train Loss: 0.149057, Train Acc: 0.726923 | Val Loss: 0.161863, Val Acc: 0.711340\n",
      "Epoch 7648 - Train Loss: 0.149046, Train Acc: 0.726923 | Val Loss: 0.161854, Val Acc: 0.711340\n",
      "Epoch 7649 - Train Loss: 0.149035, Train Acc: 0.726923 | Val Loss: 0.161844, Val Acc: 0.711340\n",
      "Epoch 7650 - Train Loss: 0.149024, Train Acc: 0.726923 | Val Loss: 0.161835, Val Acc: 0.711340\n",
      "Epoch 7651 - Train Loss: 0.149013, Train Acc: 0.726923 | Val Loss: 0.161825, Val Acc: 0.711340\n",
      "Epoch 7652 - Train Loss: 0.149002, Train Acc: 0.726923 | Val Loss: 0.161816, Val Acc: 0.711340\n",
      "Epoch 7653 - Train Loss: 0.148991, Train Acc: 0.726923 | Val Loss: 0.161806, Val Acc: 0.711340\n",
      "Epoch 7654 - Train Loss: 0.148981, Train Acc: 0.726923 | Val Loss: 0.161797, Val Acc: 0.711340\n",
      "Epoch 7655 - Train Loss: 0.148970, Train Acc: 0.726923 | Val Loss: 0.161787, Val Acc: 0.711340\n",
      "Epoch 7656 - Train Loss: 0.148959, Train Acc: 0.726923 | Val Loss: 0.161778, Val Acc: 0.711340\n",
      "Epoch 7657 - Train Loss: 0.148948, Train Acc: 0.726923 | Val Loss: 0.161768, Val Acc: 0.711340\n",
      "Epoch 7658 - Train Loss: 0.148937, Train Acc: 0.726923 | Val Loss: 0.161759, Val Acc: 0.711340\n",
      "Epoch 7659 - Train Loss: 0.148926, Train Acc: 0.726923 | Val Loss: 0.161749, Val Acc: 0.711340\n",
      "Epoch 7660 - Train Loss: 0.148915, Train Acc: 0.726923 | Val Loss: 0.161740, Val Acc: 0.711340\n",
      "Epoch 7661 - Train Loss: 0.148904, Train Acc: 0.726923 | Val Loss: 0.161730, Val Acc: 0.711340\n",
      "Epoch 7662 - Train Loss: 0.148893, Train Acc: 0.726923 | Val Loss: 0.161720, Val Acc: 0.711340\n",
      "Epoch 7663 - Train Loss: 0.148882, Train Acc: 0.726923 | Val Loss: 0.161711, Val Acc: 0.711340\n",
      "Epoch 7664 - Train Loss: 0.148871, Train Acc: 0.726923 | Val Loss: 0.161701, Val Acc: 0.711340\n",
      "Epoch 7665 - Train Loss: 0.148860, Train Acc: 0.726923 | Val Loss: 0.161692, Val Acc: 0.711340\n",
      "Epoch 7666 - Train Loss: 0.148849, Train Acc: 0.726923 | Val Loss: 0.161682, Val Acc: 0.711340\n",
      "Epoch 7667 - Train Loss: 0.148838, Train Acc: 0.726923 | Val Loss: 0.161673, Val Acc: 0.711340\n",
      "Epoch 7668 - Train Loss: 0.148827, Train Acc: 0.726923 | Val Loss: 0.161663, Val Acc: 0.711340\n",
      "Epoch 7669 - Train Loss: 0.148816, Train Acc: 0.726923 | Val Loss: 0.161654, Val Acc: 0.711340\n",
      "Epoch 7670 - Train Loss: 0.148805, Train Acc: 0.726923 | Val Loss: 0.161644, Val Acc: 0.711340\n",
      "Epoch 7671 - Train Loss: 0.148794, Train Acc: 0.726923 | Val Loss: 0.161635, Val Acc: 0.711340\n",
      "Epoch 7672 - Train Loss: 0.148783, Train Acc: 0.726923 | Val Loss: 0.161625, Val Acc: 0.711340\n",
      "Epoch 7673 - Train Loss: 0.148772, Train Acc: 0.726923 | Val Loss: 0.161616, Val Acc: 0.711340\n",
      "Epoch 7674 - Train Loss: 0.148762, Train Acc: 0.726923 | Val Loss: 0.161606, Val Acc: 0.711340\n",
      "Epoch 7675 - Train Loss: 0.148751, Train Acc: 0.726923 | Val Loss: 0.161597, Val Acc: 0.711340\n",
      "Epoch 7676 - Train Loss: 0.148740, Train Acc: 0.726923 | Val Loss: 0.161587, Val Acc: 0.711340\n",
      "Epoch 7677 - Train Loss: 0.148729, Train Acc: 0.728205 | Val Loss: 0.161578, Val Acc: 0.711340\n",
      "Epoch 7678 - Train Loss: 0.148718, Train Acc: 0.728205 | Val Loss: 0.161568, Val Acc: 0.711340\n",
      "Epoch 7679 - Train Loss: 0.148707, Train Acc: 0.728205 | Val Loss: 0.161559, Val Acc: 0.711340\n",
      "Epoch 7680 - Train Loss: 0.148696, Train Acc: 0.728205 | Val Loss: 0.161549, Val Acc: 0.711340\n",
      "Epoch 7681 - Train Loss: 0.148685, Train Acc: 0.728205 | Val Loss: 0.161540, Val Acc: 0.711340\n",
      "Epoch 7682 - Train Loss: 0.148674, Train Acc: 0.728205 | Val Loss: 0.161530, Val Acc: 0.711340\n",
      "Epoch 7683 - Train Loss: 0.148663, Train Acc: 0.728205 | Val Loss: 0.161521, Val Acc: 0.711340\n",
      "Epoch 7684 - Train Loss: 0.148652, Train Acc: 0.728205 | Val Loss: 0.161511, Val Acc: 0.711340\n",
      "Epoch 7685 - Train Loss: 0.148641, Train Acc: 0.728205 | Val Loss: 0.161501, Val Acc: 0.711340\n",
      "Epoch 7686 - Train Loss: 0.148630, Train Acc: 0.728205 | Val Loss: 0.161492, Val Acc: 0.711340\n",
      "Epoch 7687 - Train Loss: 0.148620, Train Acc: 0.728205 | Val Loss: 0.161482, Val Acc: 0.711340\n",
      "Epoch 7688 - Train Loss: 0.148609, Train Acc: 0.728205 | Val Loss: 0.161472, Val Acc: 0.711340\n",
      "Epoch 7689 - Train Loss: 0.148598, Train Acc: 0.728205 | Val Loss: 0.161463, Val Acc: 0.711340\n",
      "Epoch 7690 - Train Loss: 0.148587, Train Acc: 0.728205 | Val Loss: 0.161453, Val Acc: 0.711340\n",
      "Epoch 7691 - Train Loss: 0.148576, Train Acc: 0.728205 | Val Loss: 0.161444, Val Acc: 0.711340\n",
      "Epoch 7692 - Train Loss: 0.148565, Train Acc: 0.728205 | Val Loss: 0.161434, Val Acc: 0.711340\n",
      "Epoch 7693 - Train Loss: 0.148554, Train Acc: 0.728205 | Val Loss: 0.161425, Val Acc: 0.711340\n",
      "Epoch 7694 - Train Loss: 0.148543, Train Acc: 0.728205 | Val Loss: 0.161415, Val Acc: 0.711340\n",
      "Epoch 7695 - Train Loss: 0.148532, Train Acc: 0.728205 | Val Loss: 0.161405, Val Acc: 0.711340\n",
      "Epoch 7696 - Train Loss: 0.148522, Train Acc: 0.729487 | Val Loss: 0.161396, Val Acc: 0.711340\n",
      "Epoch 7697 - Train Loss: 0.148511, Train Acc: 0.729487 | Val Loss: 0.161386, Val Acc: 0.711340\n",
      "Epoch 7698 - Train Loss: 0.148500, Train Acc: 0.729487 | Val Loss: 0.161377, Val Acc: 0.711340\n",
      "Epoch 7699 - Train Loss: 0.148489, Train Acc: 0.729487 | Val Loss: 0.161367, Val Acc: 0.711340\n",
      "Epoch 7700 - Train Loss: 0.148478, Train Acc: 0.729487 | Val Loss: 0.161357, Val Acc: 0.711340\n",
      "Epoch 7701 - Train Loss: 0.148467, Train Acc: 0.729487 | Val Loss: 0.161348, Val Acc: 0.711340\n",
      "Epoch 7702 - Train Loss: 0.148456, Train Acc: 0.729487 | Val Loss: 0.161338, Val Acc: 0.711340\n",
      "Epoch 7703 - Train Loss: 0.148445, Train Acc: 0.729487 | Val Loss: 0.161329, Val Acc: 0.711340\n",
      "Epoch 7704 - Train Loss: 0.148434, Train Acc: 0.729487 | Val Loss: 0.161319, Val Acc: 0.711340\n",
      "Epoch 7705 - Train Loss: 0.148424, Train Acc: 0.729487 | Val Loss: 0.161310, Val Acc: 0.711340\n",
      "Epoch 7706 - Train Loss: 0.148413, Train Acc: 0.729487 | Val Loss: 0.161300, Val Acc: 0.711340\n",
      "Epoch 7707 - Train Loss: 0.148402, Train Acc: 0.729487 | Val Loss: 0.161291, Val Acc: 0.711340\n",
      "Epoch 7708 - Train Loss: 0.148391, Train Acc: 0.729487 | Val Loss: 0.161281, Val Acc: 0.711340\n",
      "Epoch 7709 - Train Loss: 0.148380, Train Acc: 0.729487 | Val Loss: 0.161271, Val Acc: 0.711340\n",
      "Epoch 7710 - Train Loss: 0.148369, Train Acc: 0.729487 | Val Loss: 0.161262, Val Acc: 0.711340\n",
      "Epoch 7711 - Train Loss: 0.148358, Train Acc: 0.729487 | Val Loss: 0.161252, Val Acc: 0.711340\n",
      "Epoch 7712 - Train Loss: 0.148347, Train Acc: 0.729487 | Val Loss: 0.161243, Val Acc: 0.711340\n",
      "Epoch 7713 - Train Loss: 0.148337, Train Acc: 0.729487 | Val Loss: 0.161233, Val Acc: 0.711340\n",
      "Epoch 7714 - Train Loss: 0.148326, Train Acc: 0.729487 | Val Loss: 0.161224, Val Acc: 0.711340\n",
      "Epoch 7715 - Train Loss: 0.148315, Train Acc: 0.729487 | Val Loss: 0.161214, Val Acc: 0.711340\n",
      "Epoch 7716 - Train Loss: 0.148304, Train Acc: 0.729487 | Val Loss: 0.161205, Val Acc: 0.711340\n",
      "Epoch 7717 - Train Loss: 0.148293, Train Acc: 0.729487 | Val Loss: 0.161195, Val Acc: 0.711340\n",
      "Epoch 7718 - Train Loss: 0.148282, Train Acc: 0.729487 | Val Loss: 0.161186, Val Acc: 0.711340\n",
      "Epoch 7719 - Train Loss: 0.148271, Train Acc: 0.730769 | Val Loss: 0.161176, Val Acc: 0.711340\n",
      "Epoch 7720 - Train Loss: 0.148260, Train Acc: 0.730769 | Val Loss: 0.161167, Val Acc: 0.711340\n",
      "Epoch 7721 - Train Loss: 0.148250, Train Acc: 0.730769 | Val Loss: 0.161157, Val Acc: 0.711340\n",
      "Epoch 7722 - Train Loss: 0.148239, Train Acc: 0.730769 | Val Loss: 0.161148, Val Acc: 0.711340\n",
      "Epoch 7723 - Train Loss: 0.148228, Train Acc: 0.730769 | Val Loss: 0.161138, Val Acc: 0.711340\n",
      "Epoch 7724 - Train Loss: 0.148217, Train Acc: 0.730769 | Val Loss: 0.161129, Val Acc: 0.711340\n",
      "Epoch 7725 - Train Loss: 0.148206, Train Acc: 0.730769 | Val Loss: 0.161119, Val Acc: 0.711340\n",
      "Epoch 7726 - Train Loss: 0.148195, Train Acc: 0.730769 | Val Loss: 0.161109, Val Acc: 0.711340\n",
      "Epoch 7727 - Train Loss: 0.148184, Train Acc: 0.730769 | Val Loss: 0.161100, Val Acc: 0.711340\n",
      "Epoch 7728 - Train Loss: 0.148174, Train Acc: 0.730769 | Val Loss: 0.161090, Val Acc: 0.711340\n",
      "Epoch 7729 - Train Loss: 0.148163, Train Acc: 0.730769 | Val Loss: 0.161081, Val Acc: 0.711340\n",
      "Epoch 7730 - Train Loss: 0.148152, Train Acc: 0.730769 | Val Loss: 0.161071, Val Acc: 0.711340\n",
      "Epoch 7731 - Train Loss: 0.148141, Train Acc: 0.730769 | Val Loss: 0.161062, Val Acc: 0.711340\n",
      "Epoch 7732 - Train Loss: 0.148130, Train Acc: 0.730769 | Val Loss: 0.161052, Val Acc: 0.711340\n",
      "Epoch 7733 - Train Loss: 0.148119, Train Acc: 0.730769 | Val Loss: 0.161043, Val Acc: 0.711340\n",
      "Epoch 7734 - Train Loss: 0.148108, Train Acc: 0.730769 | Val Loss: 0.161034, Val Acc: 0.711340\n",
      "Epoch 7735 - Train Loss: 0.148098, Train Acc: 0.730769 | Val Loss: 0.161024, Val Acc: 0.711340\n",
      "Epoch 7736 - Train Loss: 0.148087, Train Acc: 0.730769 | Val Loss: 0.161015, Val Acc: 0.711340\n",
      "Epoch 7737 - Train Loss: 0.148076, Train Acc: 0.730769 | Val Loss: 0.161005, Val Acc: 0.711340\n",
      "Epoch 7738 - Train Loss: 0.148065, Train Acc: 0.730769 | Val Loss: 0.160996, Val Acc: 0.711340\n",
      "Epoch 7739 - Train Loss: 0.148054, Train Acc: 0.730769 | Val Loss: 0.160986, Val Acc: 0.711340\n",
      "Epoch 7740 - Train Loss: 0.148043, Train Acc: 0.730769 | Val Loss: 0.160977, Val Acc: 0.711340\n",
      "Epoch 7741 - Train Loss: 0.148033, Train Acc: 0.730769 | Val Loss: 0.160967, Val Acc: 0.711340\n",
      "Epoch 7742 - Train Loss: 0.148022, Train Acc: 0.730769 | Val Loss: 0.160958, Val Acc: 0.711340\n",
      "Epoch 7743 - Train Loss: 0.148011, Train Acc: 0.730769 | Val Loss: 0.160948, Val Acc: 0.711340\n",
      "Epoch 7744 - Train Loss: 0.148000, Train Acc: 0.730769 | Val Loss: 0.160939, Val Acc: 0.711340\n",
      "Epoch 7745 - Train Loss: 0.147989, Train Acc: 0.730769 | Val Loss: 0.160929, Val Acc: 0.711340\n",
      "Epoch 7746 - Train Loss: 0.147978, Train Acc: 0.730769 | Val Loss: 0.160920, Val Acc: 0.711340\n",
      "Epoch 7747 - Train Loss: 0.147967, Train Acc: 0.730769 | Val Loss: 0.160910, Val Acc: 0.711340\n",
      "Epoch 7748 - Train Loss: 0.147957, Train Acc: 0.730769 | Val Loss: 0.160901, Val Acc: 0.711340\n",
      "Epoch 7749 - Train Loss: 0.147946, Train Acc: 0.730769 | Val Loss: 0.160891, Val Acc: 0.711340\n",
      "Epoch 7750 - Train Loss: 0.147935, Train Acc: 0.730769 | Val Loss: 0.160882, Val Acc: 0.711340\n",
      "Epoch 7751 - Train Loss: 0.147924, Train Acc: 0.730769 | Val Loss: 0.160872, Val Acc: 0.711340\n",
      "Epoch 7752 - Train Loss: 0.147913, Train Acc: 0.730769 | Val Loss: 0.160863, Val Acc: 0.711340\n",
      "Epoch 7753 - Train Loss: 0.147902, Train Acc: 0.730769 | Val Loss: 0.160853, Val Acc: 0.711340\n",
      "Epoch 7754 - Train Loss: 0.147892, Train Acc: 0.730769 | Val Loss: 0.160844, Val Acc: 0.711340\n",
      "Epoch 7755 - Train Loss: 0.147881, Train Acc: 0.730769 | Val Loss: 0.160834, Val Acc: 0.711340\n",
      "Epoch 7756 - Train Loss: 0.147870, Train Acc: 0.730769 | Val Loss: 0.160825, Val Acc: 0.711340\n",
      "Epoch 7757 - Train Loss: 0.147859, Train Acc: 0.730769 | Val Loss: 0.160816, Val Acc: 0.711340\n",
      "Epoch 7758 - Train Loss: 0.147848, Train Acc: 0.732051 | Val Loss: 0.160806, Val Acc: 0.711340\n",
      "Epoch 7759 - Train Loss: 0.147838, Train Acc: 0.732051 | Val Loss: 0.160797, Val Acc: 0.711340\n",
      "Epoch 7760 - Train Loss: 0.147827, Train Acc: 0.732051 | Val Loss: 0.160787, Val Acc: 0.711340\n",
      "Epoch 7761 - Train Loss: 0.147816, Train Acc: 0.732051 | Val Loss: 0.160778, Val Acc: 0.711340\n",
      "Epoch 7762 - Train Loss: 0.147805, Train Acc: 0.732051 | Val Loss: 0.160768, Val Acc: 0.711340\n",
      "Epoch 7763 - Train Loss: 0.147794, Train Acc: 0.732051 | Val Loss: 0.160759, Val Acc: 0.711340\n",
      "Epoch 7764 - Train Loss: 0.147783, Train Acc: 0.732051 | Val Loss: 0.160749, Val Acc: 0.711340\n",
      "Epoch 7765 - Train Loss: 0.147773, Train Acc: 0.732051 | Val Loss: 0.160740, Val Acc: 0.711340\n",
      "Epoch 7766 - Train Loss: 0.147762, Train Acc: 0.732051 | Val Loss: 0.160730, Val Acc: 0.711340\n",
      "Epoch 7767 - Train Loss: 0.147751, Train Acc: 0.733333 | Val Loss: 0.160721, Val Acc: 0.711340\n",
      "Epoch 7768 - Train Loss: 0.147740, Train Acc: 0.733333 | Val Loss: 0.160712, Val Acc: 0.711340\n",
      "Epoch 7769 - Train Loss: 0.147729, Train Acc: 0.733333 | Val Loss: 0.160702, Val Acc: 0.711340\n",
      "Epoch 7770 - Train Loss: 0.147719, Train Acc: 0.733333 | Val Loss: 0.160693, Val Acc: 0.711340\n",
      "Epoch 7771 - Train Loss: 0.147708, Train Acc: 0.733333 | Val Loss: 0.160683, Val Acc: 0.711340\n",
      "Epoch 7772 - Train Loss: 0.147697, Train Acc: 0.733333 | Val Loss: 0.160674, Val Acc: 0.711340\n",
      "Epoch 7773 - Train Loss: 0.147686, Train Acc: 0.733333 | Val Loss: 0.160664, Val Acc: 0.711340\n",
      "Epoch 7774 - Train Loss: 0.147675, Train Acc: 0.733333 | Val Loss: 0.160655, Val Acc: 0.711340\n",
      "Epoch 7775 - Train Loss: 0.147665, Train Acc: 0.733333 | Val Loss: 0.160646, Val Acc: 0.711340\n",
      "Epoch 7776 - Train Loss: 0.147654, Train Acc: 0.733333 | Val Loss: 0.160636, Val Acc: 0.711340\n",
      "Epoch 7777 - Train Loss: 0.147643, Train Acc: 0.733333 | Val Loss: 0.160627, Val Acc: 0.711340\n",
      "Epoch 7778 - Train Loss: 0.147632, Train Acc: 0.733333 | Val Loss: 0.160617, Val Acc: 0.711340\n",
      "Epoch 7779 - Train Loss: 0.147621, Train Acc: 0.733333 | Val Loss: 0.160608, Val Acc: 0.711340\n",
      "Epoch 7780 - Train Loss: 0.147611, Train Acc: 0.733333 | Val Loss: 0.160598, Val Acc: 0.711340\n",
      "Epoch 7781 - Train Loss: 0.147600, Train Acc: 0.733333 | Val Loss: 0.160589, Val Acc: 0.711340\n",
      "Epoch 7782 - Train Loss: 0.147589, Train Acc: 0.733333 | Val Loss: 0.160580, Val Acc: 0.711340\n",
      "Epoch 7783 - Train Loss: 0.147578, Train Acc: 0.733333 | Val Loss: 0.160570, Val Acc: 0.711340\n",
      "Epoch 7784 - Train Loss: 0.147567, Train Acc: 0.733333 | Val Loss: 0.160561, Val Acc: 0.711340\n",
      "Epoch 7785 - Train Loss: 0.147557, Train Acc: 0.733333 | Val Loss: 0.160551, Val Acc: 0.711340\n",
      "Epoch 7786 - Train Loss: 0.147546, Train Acc: 0.733333 | Val Loss: 0.160542, Val Acc: 0.711340\n",
      "Epoch 7787 - Train Loss: 0.147535, Train Acc: 0.733333 | Val Loss: 0.160532, Val Acc: 0.711340\n",
      "Epoch 7788 - Train Loss: 0.147524, Train Acc: 0.733333 | Val Loss: 0.160523, Val Acc: 0.711340\n",
      "Epoch 7789 - Train Loss: 0.147513, Train Acc: 0.733333 | Val Loss: 0.160514, Val Acc: 0.711340\n",
      "Epoch 7790 - Train Loss: 0.147503, Train Acc: 0.733333 | Val Loss: 0.160504, Val Acc: 0.711340\n",
      "Epoch 7791 - Train Loss: 0.147492, Train Acc: 0.733333 | Val Loss: 0.160495, Val Acc: 0.711340\n",
      "Epoch 7792 - Train Loss: 0.147481, Train Acc: 0.733333 | Val Loss: 0.160485, Val Acc: 0.711340\n",
      "Epoch 7793 - Train Loss: 0.147470, Train Acc: 0.733333 | Val Loss: 0.160476, Val Acc: 0.711340\n",
      "Epoch 7794 - Train Loss: 0.147459, Train Acc: 0.733333 | Val Loss: 0.160467, Val Acc: 0.711340\n",
      "Epoch 7795 - Train Loss: 0.147449, Train Acc: 0.733333 | Val Loss: 0.160457, Val Acc: 0.711340\n",
      "Epoch 7796 - Train Loss: 0.147438, Train Acc: 0.733333 | Val Loss: 0.160448, Val Acc: 0.711340\n",
      "Epoch 7797 - Train Loss: 0.147427, Train Acc: 0.733333 | Val Loss: 0.160438, Val Acc: 0.711340\n",
      "Epoch 7798 - Train Loss: 0.147416, Train Acc: 0.733333 | Val Loss: 0.160429, Val Acc: 0.711340\n",
      "Epoch 7799 - Train Loss: 0.147405, Train Acc: 0.733333 | Val Loss: 0.160420, Val Acc: 0.711340\n",
      "Epoch 7800 - Train Loss: 0.147395, Train Acc: 0.733333 | Val Loss: 0.160410, Val Acc: 0.711340\n",
      "Epoch 7801 - Train Loss: 0.147384, Train Acc: 0.733333 | Val Loss: 0.160401, Val Acc: 0.711340\n",
      "Epoch 7802 - Train Loss: 0.147373, Train Acc: 0.733333 | Val Loss: 0.160391, Val Acc: 0.711340\n",
      "Epoch 7803 - Train Loss: 0.147362, Train Acc: 0.733333 | Val Loss: 0.160382, Val Acc: 0.711340\n",
      "Epoch 7804 - Train Loss: 0.147352, Train Acc: 0.733333 | Val Loss: 0.160373, Val Acc: 0.711340\n",
      "Epoch 7805 - Train Loss: 0.147341, Train Acc: 0.733333 | Val Loss: 0.160363, Val Acc: 0.711340\n",
      "Epoch 7806 - Train Loss: 0.147330, Train Acc: 0.733333 | Val Loss: 0.160354, Val Acc: 0.711340\n",
      "Epoch 7807 - Train Loss: 0.147319, Train Acc: 0.733333 | Val Loss: 0.160344, Val Acc: 0.711340\n",
      "Epoch 7808 - Train Loss: 0.147309, Train Acc: 0.733333 | Val Loss: 0.160335, Val Acc: 0.711340\n",
      "Epoch 7809 - Train Loss: 0.147298, Train Acc: 0.733333 | Val Loss: 0.160326, Val Acc: 0.711340\n",
      "Epoch 7810 - Train Loss: 0.147287, Train Acc: 0.733333 | Val Loss: 0.160316, Val Acc: 0.711340\n",
      "Epoch 7811 - Train Loss: 0.147276, Train Acc: 0.733333 | Val Loss: 0.160307, Val Acc: 0.711340\n",
      "Epoch 7812 - Train Loss: 0.147265, Train Acc: 0.733333 | Val Loss: 0.160297, Val Acc: 0.711340\n",
      "Epoch 7813 - Train Loss: 0.147255, Train Acc: 0.733333 | Val Loss: 0.160288, Val Acc: 0.711340\n",
      "Epoch 7814 - Train Loss: 0.147244, Train Acc: 0.733333 | Val Loss: 0.160279, Val Acc: 0.711340\n",
      "Epoch 7815 - Train Loss: 0.147233, Train Acc: 0.733333 | Val Loss: 0.160269, Val Acc: 0.711340\n",
      "Epoch 7816 - Train Loss: 0.147222, Train Acc: 0.733333 | Val Loss: 0.160260, Val Acc: 0.711340\n",
      "Epoch 7817 - Train Loss: 0.147212, Train Acc: 0.733333 | Val Loss: 0.160251, Val Acc: 0.711340\n",
      "Epoch 7818 - Train Loss: 0.147201, Train Acc: 0.733333 | Val Loss: 0.160241, Val Acc: 0.711340\n",
      "Epoch 7819 - Train Loss: 0.147190, Train Acc: 0.733333 | Val Loss: 0.160232, Val Acc: 0.711340\n",
      "Epoch 7820 - Train Loss: 0.147179, Train Acc: 0.733333 | Val Loss: 0.160222, Val Acc: 0.711340\n",
      "Epoch 7821 - Train Loss: 0.147169, Train Acc: 0.733333 | Val Loss: 0.160213, Val Acc: 0.711340\n",
      "Epoch 7822 - Train Loss: 0.147158, Train Acc: 0.733333 | Val Loss: 0.160204, Val Acc: 0.711340\n",
      "Epoch 7823 - Train Loss: 0.147147, Train Acc: 0.733333 | Val Loss: 0.160194, Val Acc: 0.711340\n",
      "Epoch 7824 - Train Loss: 0.147136, Train Acc: 0.733333 | Val Loss: 0.160185, Val Acc: 0.711340\n",
      "Epoch 7825 - Train Loss: 0.147126, Train Acc: 0.733333 | Val Loss: 0.160175, Val Acc: 0.711340\n",
      "Epoch 7826 - Train Loss: 0.147115, Train Acc: 0.733333 | Val Loss: 0.160166, Val Acc: 0.711340\n",
      "Epoch 7827 - Train Loss: 0.147104, Train Acc: 0.733333 | Val Loss: 0.160157, Val Acc: 0.711340\n",
      "Epoch 7828 - Train Loss: 0.147093, Train Acc: 0.733333 | Val Loss: 0.160147, Val Acc: 0.711340\n",
      "Epoch 7829 - Train Loss: 0.147083, Train Acc: 0.733333 | Val Loss: 0.160138, Val Acc: 0.711340\n",
      "Epoch 7830 - Train Loss: 0.147072, Train Acc: 0.733333 | Val Loss: 0.160129, Val Acc: 0.711340\n",
      "Epoch 7831 - Train Loss: 0.147061, Train Acc: 0.733333 | Val Loss: 0.160119, Val Acc: 0.711340\n",
      "Epoch 7832 - Train Loss: 0.147050, Train Acc: 0.733333 | Val Loss: 0.160110, Val Acc: 0.711340\n",
      "Epoch 7833 - Train Loss: 0.147040, Train Acc: 0.733333 | Val Loss: 0.160100, Val Acc: 0.711340\n",
      "Epoch 7834 - Train Loss: 0.147029, Train Acc: 0.733333 | Val Loss: 0.160091, Val Acc: 0.711340\n",
      "Epoch 7835 - Train Loss: 0.147018, Train Acc: 0.733333 | Val Loss: 0.160082, Val Acc: 0.711340\n",
      "Epoch 7836 - Train Loss: 0.147007, Train Acc: 0.733333 | Val Loss: 0.160072, Val Acc: 0.711340\n",
      "Epoch 7837 - Train Loss: 0.146997, Train Acc: 0.733333 | Val Loss: 0.160063, Val Acc: 0.711340\n",
      "Epoch 7838 - Train Loss: 0.146986, Train Acc: 0.733333 | Val Loss: 0.160054, Val Acc: 0.711340\n",
      "Epoch 7839 - Train Loss: 0.146975, Train Acc: 0.733333 | Val Loss: 0.160044, Val Acc: 0.711340\n",
      "Epoch 7840 - Train Loss: 0.146965, Train Acc: 0.733333 | Val Loss: 0.160035, Val Acc: 0.711340\n",
      "Epoch 7841 - Train Loss: 0.146954, Train Acc: 0.733333 | Val Loss: 0.160026, Val Acc: 0.711340\n",
      "Epoch 7842 - Train Loss: 0.146943, Train Acc: 0.733333 | Val Loss: 0.160016, Val Acc: 0.711340\n",
      "Epoch 7843 - Train Loss: 0.146932, Train Acc: 0.733333 | Val Loss: 0.160007, Val Acc: 0.711340\n",
      "Epoch 7844 - Train Loss: 0.146922, Train Acc: 0.733333 | Val Loss: 0.159998, Val Acc: 0.711340\n",
      "Epoch 7845 - Train Loss: 0.146911, Train Acc: 0.733333 | Val Loss: 0.159988, Val Acc: 0.711340\n",
      "Epoch 7846 - Train Loss: 0.146900, Train Acc: 0.733333 | Val Loss: 0.159979, Val Acc: 0.711340\n",
      "Epoch 7847 - Train Loss: 0.146889, Train Acc: 0.733333 | Val Loss: 0.159970, Val Acc: 0.711340\n",
      "Epoch 7848 - Train Loss: 0.146879, Train Acc: 0.733333 | Val Loss: 0.159960, Val Acc: 0.711340\n",
      "Epoch 7849 - Train Loss: 0.146868, Train Acc: 0.733333 | Val Loss: 0.159951, Val Acc: 0.711340\n",
      "Epoch 7850 - Train Loss: 0.146857, Train Acc: 0.733333 | Val Loss: 0.159942, Val Acc: 0.711340\n",
      "Epoch 7851 - Train Loss: 0.146847, Train Acc: 0.733333 | Val Loss: 0.159932, Val Acc: 0.711340\n",
      "Epoch 7852 - Train Loss: 0.146836, Train Acc: 0.733333 | Val Loss: 0.159923, Val Acc: 0.711340\n",
      "Epoch 7853 - Train Loss: 0.146825, Train Acc: 0.732051 | Val Loss: 0.159914, Val Acc: 0.711340\n",
      "Epoch 7854 - Train Loss: 0.146814, Train Acc: 0.732051 | Val Loss: 0.159904, Val Acc: 0.711340\n",
      "Epoch 7855 - Train Loss: 0.146804, Train Acc: 0.733333 | Val Loss: 0.159895, Val Acc: 0.711340\n",
      "Epoch 7856 - Train Loss: 0.146793, Train Acc: 0.733333 | Val Loss: 0.159886, Val Acc: 0.711340\n",
      "Epoch 7857 - Train Loss: 0.146782, Train Acc: 0.733333 | Val Loss: 0.159876, Val Acc: 0.711340\n",
      "Epoch 7858 - Train Loss: 0.146772, Train Acc: 0.733333 | Val Loss: 0.159867, Val Acc: 0.711340\n",
      "Epoch 7859 - Train Loss: 0.146761, Train Acc: 0.733333 | Val Loss: 0.159858, Val Acc: 0.711340\n",
      "Epoch 7860 - Train Loss: 0.146750, Train Acc: 0.733333 | Val Loss: 0.159848, Val Acc: 0.711340\n",
      "Epoch 7861 - Train Loss: 0.146739, Train Acc: 0.733333 | Val Loss: 0.159839, Val Acc: 0.711340\n",
      "Epoch 7862 - Train Loss: 0.146729, Train Acc: 0.733333 | Val Loss: 0.159830, Val Acc: 0.711340\n",
      "Epoch 7863 - Train Loss: 0.146718, Train Acc: 0.733333 | Val Loss: 0.159820, Val Acc: 0.711340\n",
      "Epoch 7864 - Train Loss: 0.146707, Train Acc: 0.733333 | Val Loss: 0.159811, Val Acc: 0.711340\n",
      "Epoch 7865 - Train Loss: 0.146697, Train Acc: 0.733333 | Val Loss: 0.159802, Val Acc: 0.711340\n",
      "Epoch 7866 - Train Loss: 0.146686, Train Acc: 0.733333 | Val Loss: 0.159792, Val Acc: 0.711340\n",
      "Epoch 7867 - Train Loss: 0.146675, Train Acc: 0.733333 | Val Loss: 0.159783, Val Acc: 0.711340\n",
      "Epoch 7868 - Train Loss: 0.146664, Train Acc: 0.733333 | Val Loss: 0.159774, Val Acc: 0.711340\n",
      "Epoch 7869 - Train Loss: 0.146654, Train Acc: 0.733333 | Val Loss: 0.159765, Val Acc: 0.711340\n",
      "Epoch 7870 - Train Loss: 0.146643, Train Acc: 0.733333 | Val Loss: 0.159755, Val Acc: 0.711340\n",
      "Epoch 7871 - Train Loss: 0.146632, Train Acc: 0.733333 | Val Loss: 0.159746, Val Acc: 0.711340\n",
      "Epoch 7872 - Train Loss: 0.146622, Train Acc: 0.733333 | Val Loss: 0.159737, Val Acc: 0.711340\n",
      "Epoch 7873 - Train Loss: 0.146611, Train Acc: 0.733333 | Val Loss: 0.159727, Val Acc: 0.711340\n",
      "Epoch 7874 - Train Loss: 0.146600, Train Acc: 0.734615 | Val Loss: 0.159718, Val Acc: 0.711340\n",
      "Epoch 7875 - Train Loss: 0.146590, Train Acc: 0.734615 | Val Loss: 0.159709, Val Acc: 0.711340\n",
      "Epoch 7876 - Train Loss: 0.146579, Train Acc: 0.734615 | Val Loss: 0.159699, Val Acc: 0.711340\n",
      "Epoch 7877 - Train Loss: 0.146568, Train Acc: 0.734615 | Val Loss: 0.159690, Val Acc: 0.711340\n",
      "Epoch 7878 - Train Loss: 0.146557, Train Acc: 0.734615 | Val Loss: 0.159681, Val Acc: 0.711340\n",
      "Epoch 7879 - Train Loss: 0.146547, Train Acc: 0.734615 | Val Loss: 0.159672, Val Acc: 0.711340\n",
      "Epoch 7880 - Train Loss: 0.146536, Train Acc: 0.734615 | Val Loss: 0.159662, Val Acc: 0.711340\n",
      "Epoch 7881 - Train Loss: 0.146525, Train Acc: 0.734615 | Val Loss: 0.159653, Val Acc: 0.711340\n",
      "Epoch 7882 - Train Loss: 0.146515, Train Acc: 0.734615 | Val Loss: 0.159644, Val Acc: 0.711340\n",
      "Epoch 7883 - Train Loss: 0.146504, Train Acc: 0.734615 | Val Loss: 0.159634, Val Acc: 0.711340\n",
      "Epoch 7884 - Train Loss: 0.146493, Train Acc: 0.734615 | Val Loss: 0.159625, Val Acc: 0.711340\n",
      "Epoch 7885 - Train Loss: 0.146483, Train Acc: 0.734615 | Val Loss: 0.159616, Val Acc: 0.711340\n",
      "Epoch 7886 - Train Loss: 0.146472, Train Acc: 0.734615 | Val Loss: 0.159607, Val Acc: 0.711340\n",
      "Epoch 7887 - Train Loss: 0.146461, Train Acc: 0.734615 | Val Loss: 0.159597, Val Acc: 0.711340\n",
      "Epoch 7888 - Train Loss: 0.146451, Train Acc: 0.734615 | Val Loss: 0.159588, Val Acc: 0.711340\n",
      "Epoch 7889 - Train Loss: 0.146440, Train Acc: 0.734615 | Val Loss: 0.159579, Val Acc: 0.711340\n",
      "Epoch 7890 - Train Loss: 0.146429, Train Acc: 0.734615 | Val Loss: 0.159569, Val Acc: 0.711340\n",
      "Epoch 7891 - Train Loss: 0.146419, Train Acc: 0.734615 | Val Loss: 0.159560, Val Acc: 0.711340\n",
      "Epoch 7892 - Train Loss: 0.146408, Train Acc: 0.734615 | Val Loss: 0.159551, Val Acc: 0.711340\n",
      "Epoch 7893 - Train Loss: 0.146397, Train Acc: 0.734615 | Val Loss: 0.159542, Val Acc: 0.711340\n",
      "Epoch 7894 - Train Loss: 0.146387, Train Acc: 0.734615 | Val Loss: 0.159532, Val Acc: 0.711340\n",
      "Epoch 7895 - Train Loss: 0.146376, Train Acc: 0.734615 | Val Loss: 0.159523, Val Acc: 0.711340\n",
      "Epoch 7896 - Train Loss: 0.146365, Train Acc: 0.734615 | Val Loss: 0.159514, Val Acc: 0.711340\n",
      "Epoch 7897 - Train Loss: 0.146355, Train Acc: 0.735897 | Val Loss: 0.159504, Val Acc: 0.711340\n",
      "Epoch 7898 - Train Loss: 0.146344, Train Acc: 0.735897 | Val Loss: 0.159495, Val Acc: 0.711340\n",
      "Epoch 7899 - Train Loss: 0.146333, Train Acc: 0.735897 | Val Loss: 0.159486, Val Acc: 0.711340\n",
      "Epoch 7900 - Train Loss: 0.146323, Train Acc: 0.735897 | Val Loss: 0.159477, Val Acc: 0.711340\n",
      "Epoch 7901 - Train Loss: 0.146312, Train Acc: 0.735897 | Val Loss: 0.159467, Val Acc: 0.711340\n",
      "Epoch 7902 - Train Loss: 0.146301, Train Acc: 0.735897 | Val Loss: 0.159458, Val Acc: 0.711340\n",
      "Epoch 7903 - Train Loss: 0.146291, Train Acc: 0.735897 | Val Loss: 0.159449, Val Acc: 0.711340\n",
      "Epoch 7904 - Train Loss: 0.146280, Train Acc: 0.735897 | Val Loss: 0.159440, Val Acc: 0.711340\n",
      "Epoch 7905 - Train Loss: 0.146269, Train Acc: 0.735897 | Val Loss: 0.159430, Val Acc: 0.711340\n",
      "Epoch 7906 - Train Loss: 0.146259, Train Acc: 0.735897 | Val Loss: 0.159421, Val Acc: 0.711340\n",
      "Epoch 7907 - Train Loss: 0.146248, Train Acc: 0.735897 | Val Loss: 0.159412, Val Acc: 0.711340\n",
      "Epoch 7908 - Train Loss: 0.146237, Train Acc: 0.735897 | Val Loss: 0.159403, Val Acc: 0.711340\n",
      "Epoch 7909 - Train Loss: 0.146227, Train Acc: 0.735897 | Val Loss: 0.159393, Val Acc: 0.711340\n",
      "Epoch 7910 - Train Loss: 0.146216, Train Acc: 0.735897 | Val Loss: 0.159384, Val Acc: 0.711340\n",
      "Epoch 7911 - Train Loss: 0.146205, Train Acc: 0.735897 | Val Loss: 0.159375, Val Acc: 0.711340\n",
      "Epoch 7912 - Train Loss: 0.146195, Train Acc: 0.735897 | Val Loss: 0.159365, Val Acc: 0.711340\n",
      "Epoch 7913 - Train Loss: 0.146184, Train Acc: 0.735897 | Val Loss: 0.159356, Val Acc: 0.711340\n",
      "Epoch 7914 - Train Loss: 0.146173, Train Acc: 0.735897 | Val Loss: 0.159347, Val Acc: 0.711340\n",
      "Epoch 7915 - Train Loss: 0.146163, Train Acc: 0.735897 | Val Loss: 0.159338, Val Acc: 0.711340\n",
      "Epoch 7916 - Train Loss: 0.146152, Train Acc: 0.735897 | Val Loss: 0.159328, Val Acc: 0.711340\n",
      "Epoch 7917 - Train Loss: 0.146141, Train Acc: 0.735897 | Val Loss: 0.159319, Val Acc: 0.711340\n",
      "Epoch 7918 - Train Loss: 0.146131, Train Acc: 0.737179 | Val Loss: 0.159310, Val Acc: 0.711340\n",
      "Epoch 7919 - Train Loss: 0.146120, Train Acc: 0.737179 | Val Loss: 0.159301, Val Acc: 0.711340\n",
      "Epoch 7920 - Train Loss: 0.146109, Train Acc: 0.737179 | Val Loss: 0.159291, Val Acc: 0.711340\n",
      "Epoch 7921 - Train Loss: 0.146099, Train Acc: 0.737179 | Val Loss: 0.159282, Val Acc: 0.711340\n",
      "Epoch 7922 - Train Loss: 0.146088, Train Acc: 0.737179 | Val Loss: 0.159273, Val Acc: 0.711340\n",
      "Epoch 7923 - Train Loss: 0.146077, Train Acc: 0.737179 | Val Loss: 0.159264, Val Acc: 0.711340\n",
      "Epoch 7924 - Train Loss: 0.146067, Train Acc: 0.737179 | Val Loss: 0.159254, Val Acc: 0.711340\n",
      "Epoch 7925 - Train Loss: 0.146056, Train Acc: 0.737179 | Val Loss: 0.159245, Val Acc: 0.711340\n",
      "Epoch 7926 - Train Loss: 0.146045, Train Acc: 0.737179 | Val Loss: 0.159236, Val Acc: 0.711340\n",
      "Epoch 7927 - Train Loss: 0.146035, Train Acc: 0.737179 | Val Loss: 0.159227, Val Acc: 0.711340\n",
      "Epoch 7928 - Train Loss: 0.146024, Train Acc: 0.737179 | Val Loss: 0.159218, Val Acc: 0.711340\n",
      "Epoch 7929 - Train Loss: 0.146014, Train Acc: 0.737179 | Val Loss: 0.159208, Val Acc: 0.711340\n",
      "Epoch 7930 - Train Loss: 0.146003, Train Acc: 0.737179 | Val Loss: 0.159199, Val Acc: 0.711340\n",
      "Epoch 7931 - Train Loss: 0.145992, Train Acc: 0.737179 | Val Loss: 0.159190, Val Acc: 0.711340\n",
      "Epoch 7932 - Train Loss: 0.145982, Train Acc: 0.737179 | Val Loss: 0.159181, Val Acc: 0.711340\n",
      "Epoch 7933 - Train Loss: 0.145971, Train Acc: 0.737179 | Val Loss: 0.159171, Val Acc: 0.711340\n",
      "Epoch 7934 - Train Loss: 0.145960, Train Acc: 0.737179 | Val Loss: 0.159162, Val Acc: 0.711340\n",
      "Epoch 7935 - Train Loss: 0.145950, Train Acc: 0.737179 | Val Loss: 0.159153, Val Acc: 0.711340\n",
      "Epoch 7936 - Train Loss: 0.145939, Train Acc: 0.737179 | Val Loss: 0.159144, Val Acc: 0.711340\n",
      "Epoch 7937 - Train Loss: 0.145928, Train Acc: 0.737179 | Val Loss: 0.159134, Val Acc: 0.711340\n",
      "Epoch 7938 - Train Loss: 0.145918, Train Acc: 0.737179 | Val Loss: 0.159125, Val Acc: 0.711340\n",
      "Epoch 7939 - Train Loss: 0.145907, Train Acc: 0.737179 | Val Loss: 0.159116, Val Acc: 0.711340\n",
      "Epoch 7940 - Train Loss: 0.145897, Train Acc: 0.737179 | Val Loss: 0.159107, Val Acc: 0.711340\n",
      "Epoch 7941 - Train Loss: 0.145886, Train Acc: 0.737179 | Val Loss: 0.159098, Val Acc: 0.711340\n",
      "Epoch 7942 - Train Loss: 0.145875, Train Acc: 0.737179 | Val Loss: 0.159088, Val Acc: 0.711340\n",
      "Epoch 7943 - Train Loss: 0.145865, Train Acc: 0.737179 | Val Loss: 0.159079, Val Acc: 0.711340\n",
      "Epoch 7944 - Train Loss: 0.145854, Train Acc: 0.738462 | Val Loss: 0.159070, Val Acc: 0.711340\n",
      "Epoch 7945 - Train Loss: 0.145843, Train Acc: 0.738462 | Val Loss: 0.159061, Val Acc: 0.711340\n",
      "Epoch 7946 - Train Loss: 0.145833, Train Acc: 0.738462 | Val Loss: 0.159051, Val Acc: 0.711340\n",
      "Epoch 7947 - Train Loss: 0.145822, Train Acc: 0.738462 | Val Loss: 0.159042, Val Acc: 0.711340\n",
      "Epoch 7948 - Train Loss: 0.145812, Train Acc: 0.738462 | Val Loss: 0.159033, Val Acc: 0.711340\n",
      "Epoch 7949 - Train Loss: 0.145801, Train Acc: 0.738462 | Val Loss: 0.159024, Val Acc: 0.711340\n",
      "Epoch 7950 - Train Loss: 0.145790, Train Acc: 0.738462 | Val Loss: 0.159015, Val Acc: 0.711340\n",
      "Epoch 7951 - Train Loss: 0.145780, Train Acc: 0.738462 | Val Loss: 0.159005, Val Acc: 0.711340\n",
      "Epoch 7952 - Train Loss: 0.145769, Train Acc: 0.738462 | Val Loss: 0.158996, Val Acc: 0.711340\n",
      "Epoch 7953 - Train Loss: 0.145758, Train Acc: 0.738462 | Val Loss: 0.158987, Val Acc: 0.711340\n",
      "Epoch 7954 - Train Loss: 0.145748, Train Acc: 0.738462 | Val Loss: 0.158978, Val Acc: 0.711340\n",
      "Epoch 7955 - Train Loss: 0.145737, Train Acc: 0.739744 | Val Loss: 0.158969, Val Acc: 0.711340\n",
      "Epoch 7956 - Train Loss: 0.145727, Train Acc: 0.739744 | Val Loss: 0.158959, Val Acc: 0.711340\n",
      "Epoch 7957 - Train Loss: 0.145716, Train Acc: 0.739744 | Val Loss: 0.158950, Val Acc: 0.711340\n",
      "Epoch 7958 - Train Loss: 0.145705, Train Acc: 0.739744 | Val Loss: 0.158941, Val Acc: 0.711340\n",
      "Epoch 7959 - Train Loss: 0.145695, Train Acc: 0.739744 | Val Loss: 0.158932, Val Acc: 0.711340\n",
      "Epoch 7960 - Train Loss: 0.145684, Train Acc: 0.739744 | Val Loss: 0.158923, Val Acc: 0.711340\n",
      "Epoch 7961 - Train Loss: 0.145674, Train Acc: 0.739744 | Val Loss: 0.158913, Val Acc: 0.711340\n",
      "Epoch 7962 - Train Loss: 0.145663, Train Acc: 0.739744 | Val Loss: 0.158904, Val Acc: 0.711340\n",
      "Epoch 7963 - Train Loss: 0.145652, Train Acc: 0.739744 | Val Loss: 0.158895, Val Acc: 0.711340\n",
      "Epoch 7964 - Train Loss: 0.145642, Train Acc: 0.739744 | Val Loss: 0.158886, Val Acc: 0.711340\n",
      "Epoch 7965 - Train Loss: 0.145631, Train Acc: 0.739744 | Val Loss: 0.158877, Val Acc: 0.711340\n",
      "Epoch 7966 - Train Loss: 0.145621, Train Acc: 0.739744 | Val Loss: 0.158867, Val Acc: 0.711340\n",
      "Epoch 7967 - Train Loss: 0.145610, Train Acc: 0.739744 | Val Loss: 0.158858, Val Acc: 0.711340\n",
      "Epoch 7968 - Train Loss: 0.145599, Train Acc: 0.739744 | Val Loss: 0.158849, Val Acc: 0.711340\n",
      "Epoch 7969 - Train Loss: 0.145589, Train Acc: 0.739744 | Val Loss: 0.158840, Val Acc: 0.711340\n",
      "Epoch 7970 - Train Loss: 0.145578, Train Acc: 0.739744 | Val Loss: 0.158831, Val Acc: 0.711340\n",
      "Epoch 7971 - Train Loss: 0.145568, Train Acc: 0.739744 | Val Loss: 0.158821, Val Acc: 0.711340\n",
      "Epoch 7972 - Train Loss: 0.145557, Train Acc: 0.739744 | Val Loss: 0.158812, Val Acc: 0.711340\n",
      "Epoch 7973 - Train Loss: 0.145546, Train Acc: 0.739744 | Val Loss: 0.158803, Val Acc: 0.711340\n",
      "Epoch 7974 - Train Loss: 0.145536, Train Acc: 0.739744 | Val Loss: 0.158794, Val Acc: 0.711340\n",
      "Epoch 7975 - Train Loss: 0.145525, Train Acc: 0.739744 | Val Loss: 0.158785, Val Acc: 0.711340\n",
      "Epoch 7976 - Train Loss: 0.145515, Train Acc: 0.739744 | Val Loss: 0.158776, Val Acc: 0.711340\n",
      "Epoch 7977 - Train Loss: 0.145504, Train Acc: 0.739744 | Val Loss: 0.158766, Val Acc: 0.711340\n",
      "Epoch 7978 - Train Loss: 0.145494, Train Acc: 0.739744 | Val Loss: 0.158757, Val Acc: 0.711340\n",
      "Epoch 7979 - Train Loss: 0.145483, Train Acc: 0.739744 | Val Loss: 0.158748, Val Acc: 0.711340\n",
      "Epoch 7980 - Train Loss: 0.145472, Train Acc: 0.739744 | Val Loss: 0.158739, Val Acc: 0.711340\n",
      "Epoch 7981 - Train Loss: 0.145462, Train Acc: 0.739744 | Val Loss: 0.158730, Val Acc: 0.711340\n",
      "Epoch 7982 - Train Loss: 0.145451, Train Acc: 0.739744 | Val Loss: 0.158720, Val Acc: 0.711340\n",
      "Epoch 7983 - Train Loss: 0.145441, Train Acc: 0.739744 | Val Loss: 0.158711, Val Acc: 0.711340\n",
      "Epoch 7984 - Train Loss: 0.145430, Train Acc: 0.739744 | Val Loss: 0.158702, Val Acc: 0.711340\n",
      "Epoch 7985 - Train Loss: 0.145419, Train Acc: 0.739744 | Val Loss: 0.158693, Val Acc: 0.711340\n",
      "Epoch 7986 - Train Loss: 0.145409, Train Acc: 0.739744 | Val Loss: 0.158684, Val Acc: 0.711340\n",
      "Epoch 7987 - Train Loss: 0.145398, Train Acc: 0.739744 | Val Loss: 0.158675, Val Acc: 0.711340\n",
      "Epoch 7988 - Train Loss: 0.145388, Train Acc: 0.739744 | Val Loss: 0.158665, Val Acc: 0.711340\n",
      "Epoch 7989 - Train Loss: 0.145377, Train Acc: 0.739744 | Val Loss: 0.158656, Val Acc: 0.711340\n",
      "Epoch 7990 - Train Loss: 0.145367, Train Acc: 0.739744 | Val Loss: 0.158647, Val Acc: 0.711340\n",
      "Epoch 7991 - Train Loss: 0.145356, Train Acc: 0.739744 | Val Loss: 0.158638, Val Acc: 0.711340\n",
      "Epoch 7992 - Train Loss: 0.145345, Train Acc: 0.739744 | Val Loss: 0.158629, Val Acc: 0.711340\n",
      "Epoch 7993 - Train Loss: 0.145335, Train Acc: 0.739744 | Val Loss: 0.158619, Val Acc: 0.711340\n",
      "Epoch 7994 - Train Loss: 0.145324, Train Acc: 0.739744 | Val Loss: 0.158610, Val Acc: 0.711340\n",
      "Epoch 7995 - Train Loss: 0.145314, Train Acc: 0.739744 | Val Loss: 0.158601, Val Acc: 0.711340\n",
      "Epoch 7996 - Train Loss: 0.145303, Train Acc: 0.739744 | Val Loss: 0.158592, Val Acc: 0.711340\n",
      "Epoch 7997 - Train Loss: 0.145293, Train Acc: 0.739744 | Val Loss: 0.158582, Val Acc: 0.711340\n",
      "Epoch 7998 - Train Loss: 0.145282, Train Acc: 0.739744 | Val Loss: 0.158573, Val Acc: 0.711340\n",
      "Epoch 7999 - Train Loss: 0.145272, Train Acc: 0.739744 | Val Loss: 0.158564, Val Acc: 0.711340\n",
      "Epoch 8000 - Train Loss: 0.145261, Train Acc: 0.739744 | Val Loss: 0.158555, Val Acc: 0.711340\n",
      "Epoch 8001 - Train Loss: 0.145250, Train Acc: 0.739744 | Val Loss: 0.158545, Val Acc: 0.711340\n",
      "Epoch 8002 - Train Loss: 0.145240, Train Acc: 0.739744 | Val Loss: 0.158536, Val Acc: 0.711340\n",
      "Epoch 8003 - Train Loss: 0.145229, Train Acc: 0.739744 | Val Loss: 0.158527, Val Acc: 0.711340\n",
      "Epoch 8004 - Train Loss: 0.145219, Train Acc: 0.739744 | Val Loss: 0.158518, Val Acc: 0.711340\n",
      "Epoch 8005 - Train Loss: 0.145208, Train Acc: 0.739744 | Val Loss: 0.158509, Val Acc: 0.711340\n",
      "Epoch 8006 - Train Loss: 0.145198, Train Acc: 0.739744 | Val Loss: 0.158499, Val Acc: 0.711340\n",
      "Epoch 8007 - Train Loss: 0.145187, Train Acc: 0.739744 | Val Loss: 0.158490, Val Acc: 0.711340\n",
      "Epoch 8008 - Train Loss: 0.145177, Train Acc: 0.739744 | Val Loss: 0.158481, Val Acc: 0.711340\n",
      "Epoch 8009 - Train Loss: 0.145166, Train Acc: 0.739744 | Val Loss: 0.158472, Val Acc: 0.711340\n",
      "Epoch 8010 - Train Loss: 0.145156, Train Acc: 0.739744 | Val Loss: 0.158463, Val Acc: 0.711340\n",
      "Epoch 8011 - Train Loss: 0.145145, Train Acc: 0.739744 | Val Loss: 0.158453, Val Acc: 0.711340\n",
      "Epoch 8012 - Train Loss: 0.145135, Train Acc: 0.739744 | Val Loss: 0.158444, Val Acc: 0.711340\n",
      "Epoch 8013 - Train Loss: 0.145124, Train Acc: 0.739744 | Val Loss: 0.158435, Val Acc: 0.711340\n",
      "Epoch 8014 - Train Loss: 0.145114, Train Acc: 0.739744 | Val Loss: 0.158426, Val Acc: 0.711340\n",
      "Epoch 8015 - Train Loss: 0.145103, Train Acc: 0.739744 | Val Loss: 0.158417, Val Acc: 0.711340\n",
      "Epoch 8016 - Train Loss: 0.145092, Train Acc: 0.739744 | Val Loss: 0.158407, Val Acc: 0.711340\n",
      "Epoch 8017 - Train Loss: 0.145082, Train Acc: 0.739744 | Val Loss: 0.158398, Val Acc: 0.711340\n",
      "Epoch 8018 - Train Loss: 0.145071, Train Acc: 0.739744 | Val Loss: 0.158389, Val Acc: 0.711340\n",
      "Epoch 8019 - Train Loss: 0.145061, Train Acc: 0.739744 | Val Loss: 0.158380, Val Acc: 0.711340\n",
      "Epoch 8020 - Train Loss: 0.145050, Train Acc: 0.739744 | Val Loss: 0.158371, Val Acc: 0.711340\n",
      "Epoch 8021 - Train Loss: 0.145040, Train Acc: 0.739744 | Val Loss: 0.158362, Val Acc: 0.711340\n",
      "Epoch 8022 - Train Loss: 0.145029, Train Acc: 0.739744 | Val Loss: 0.158352, Val Acc: 0.711340\n",
      "Epoch 8023 - Train Loss: 0.145019, Train Acc: 0.739744 | Val Loss: 0.158343, Val Acc: 0.711340\n",
      "Epoch 8024 - Train Loss: 0.145008, Train Acc: 0.739744 | Val Loss: 0.158334, Val Acc: 0.711340\n",
      "Epoch 8025 - Train Loss: 0.144998, Train Acc: 0.739744 | Val Loss: 0.158325, Val Acc: 0.711340\n",
      "Epoch 8026 - Train Loss: 0.144987, Train Acc: 0.739744 | Val Loss: 0.158316, Val Acc: 0.711340\n",
      "Epoch 8027 - Train Loss: 0.144977, Train Acc: 0.739744 | Val Loss: 0.158307, Val Acc: 0.711340\n",
      "Epoch 8028 - Train Loss: 0.144966, Train Acc: 0.739744 | Val Loss: 0.158297, Val Acc: 0.711340\n",
      "Epoch 8029 - Train Loss: 0.144956, Train Acc: 0.739744 | Val Loss: 0.158288, Val Acc: 0.711340\n",
      "Epoch 8030 - Train Loss: 0.144945, Train Acc: 0.739744 | Val Loss: 0.158279, Val Acc: 0.711340\n",
      "Epoch 8031 - Train Loss: 0.144935, Train Acc: 0.739744 | Val Loss: 0.158270, Val Acc: 0.711340\n",
      "Epoch 8032 - Train Loss: 0.144924, Train Acc: 0.739744 | Val Loss: 0.158261, Val Acc: 0.711340\n",
      "Epoch 8033 - Train Loss: 0.144914, Train Acc: 0.739744 | Val Loss: 0.158252, Val Acc: 0.711340\n",
      "Epoch 8034 - Train Loss: 0.144903, Train Acc: 0.739744 | Val Loss: 0.158242, Val Acc: 0.711340\n",
      "Epoch 8035 - Train Loss: 0.144893, Train Acc: 0.739744 | Val Loss: 0.158233, Val Acc: 0.711340\n",
      "Epoch 8036 - Train Loss: 0.144882, Train Acc: 0.739744 | Val Loss: 0.158224, Val Acc: 0.711340\n",
      "Epoch 8037 - Train Loss: 0.144872, Train Acc: 0.739744 | Val Loss: 0.158215, Val Acc: 0.711340\n",
      "Epoch 8038 - Train Loss: 0.144861, Train Acc: 0.739744 | Val Loss: 0.158206, Val Acc: 0.711340\n",
      "Epoch 8039 - Train Loss: 0.144851, Train Acc: 0.739744 | Val Loss: 0.158197, Val Acc: 0.711340\n",
      "Epoch 8040 - Train Loss: 0.144840, Train Acc: 0.739744 | Val Loss: 0.158188, Val Acc: 0.711340\n",
      "Epoch 8041 - Train Loss: 0.144830, Train Acc: 0.739744 | Val Loss: 0.158178, Val Acc: 0.711340\n",
      "Epoch 8042 - Train Loss: 0.144819, Train Acc: 0.739744 | Val Loss: 0.158169, Val Acc: 0.711340\n",
      "Epoch 8043 - Train Loss: 0.144809, Train Acc: 0.739744 | Val Loss: 0.158160, Val Acc: 0.711340\n",
      "Epoch 8044 - Train Loss: 0.144798, Train Acc: 0.739744 | Val Loss: 0.158151, Val Acc: 0.711340\n",
      "Epoch 8045 - Train Loss: 0.144788, Train Acc: 0.739744 | Val Loss: 0.158142, Val Acc: 0.711340\n",
      "Epoch 8046 - Train Loss: 0.144777, Train Acc: 0.739744 | Val Loss: 0.158133, Val Acc: 0.711340\n",
      "Epoch 8047 - Train Loss: 0.144767, Train Acc: 0.739744 | Val Loss: 0.158124, Val Acc: 0.711340\n",
      "Epoch 8048 - Train Loss: 0.144756, Train Acc: 0.739744 | Val Loss: 0.158115, Val Acc: 0.711340\n",
      "Epoch 8049 - Train Loss: 0.144746, Train Acc: 0.739744 | Val Loss: 0.158105, Val Acc: 0.711340\n",
      "Epoch 8050 - Train Loss: 0.144735, Train Acc: 0.739744 | Val Loss: 0.158096, Val Acc: 0.711340\n",
      "Epoch 8051 - Train Loss: 0.144725, Train Acc: 0.739744 | Val Loss: 0.158087, Val Acc: 0.711340\n",
      "Epoch 8052 - Train Loss: 0.144714, Train Acc: 0.739744 | Val Loss: 0.158078, Val Acc: 0.711340\n",
      "Epoch 8053 - Train Loss: 0.144704, Train Acc: 0.739744 | Val Loss: 0.158069, Val Acc: 0.711340\n",
      "Epoch 8054 - Train Loss: 0.144693, Train Acc: 0.739744 | Val Loss: 0.158060, Val Acc: 0.711340\n",
      "Epoch 8055 - Train Loss: 0.144683, Train Acc: 0.739744 | Val Loss: 0.158051, Val Acc: 0.711340\n",
      "Epoch 8056 - Train Loss: 0.144672, Train Acc: 0.739744 | Val Loss: 0.158042, Val Acc: 0.711340\n",
      "Epoch 8057 - Train Loss: 0.144662, Train Acc: 0.739744 | Val Loss: 0.158032, Val Acc: 0.711340\n",
      "Epoch 8058 - Train Loss: 0.144651, Train Acc: 0.739744 | Val Loss: 0.158023, Val Acc: 0.711340\n",
      "Epoch 8059 - Train Loss: 0.144641, Train Acc: 0.739744 | Val Loss: 0.158014, Val Acc: 0.711340\n",
      "Epoch 8060 - Train Loss: 0.144630, Train Acc: 0.739744 | Val Loss: 0.158005, Val Acc: 0.711340\n",
      "Epoch 8061 - Train Loss: 0.144620, Train Acc: 0.739744 | Val Loss: 0.157996, Val Acc: 0.711340\n",
      "Epoch 8062 - Train Loss: 0.144609, Train Acc: 0.739744 | Val Loss: 0.157987, Val Acc: 0.711340\n",
      "Epoch 8063 - Train Loss: 0.144599, Train Acc: 0.739744 | Val Loss: 0.157978, Val Acc: 0.711340\n",
      "Epoch 8064 - Train Loss: 0.144588, Train Acc: 0.739744 | Val Loss: 0.157969, Val Acc: 0.711340\n",
      "Epoch 8065 - Train Loss: 0.144578, Train Acc: 0.739744 | Val Loss: 0.157960, Val Acc: 0.711340\n",
      "Epoch 8066 - Train Loss: 0.144567, Train Acc: 0.739744 | Val Loss: 0.157951, Val Acc: 0.711340\n",
      "Epoch 8067 - Train Loss: 0.144557, Train Acc: 0.739744 | Val Loss: 0.157941, Val Acc: 0.711340\n",
      "Epoch 8068 - Train Loss: 0.144546, Train Acc: 0.739744 | Val Loss: 0.157932, Val Acc: 0.711340\n",
      "Epoch 8069 - Train Loss: 0.144536, Train Acc: 0.739744 | Val Loss: 0.157923, Val Acc: 0.711340\n",
      "Epoch 8070 - Train Loss: 0.144526, Train Acc: 0.739744 | Val Loss: 0.157914, Val Acc: 0.711340\n",
      "Epoch 8071 - Train Loss: 0.144515, Train Acc: 0.739744 | Val Loss: 0.157905, Val Acc: 0.711340\n",
      "Epoch 8072 - Train Loss: 0.144505, Train Acc: 0.739744 | Val Loss: 0.157896, Val Acc: 0.711340\n",
      "Epoch 8073 - Train Loss: 0.144494, Train Acc: 0.739744 | Val Loss: 0.157887, Val Acc: 0.711340\n",
      "Epoch 8074 - Train Loss: 0.144484, Train Acc: 0.739744 | Val Loss: 0.157878, Val Acc: 0.711340\n",
      "Epoch 8075 - Train Loss: 0.144473, Train Acc: 0.739744 | Val Loss: 0.157869, Val Acc: 0.711340\n",
      "Epoch 8076 - Train Loss: 0.144463, Train Acc: 0.739744 | Val Loss: 0.157860, Val Acc: 0.711340\n",
      "Epoch 8077 - Train Loss: 0.144452, Train Acc: 0.739744 | Val Loss: 0.157851, Val Acc: 0.711340\n",
      "Epoch 8078 - Train Loss: 0.144442, Train Acc: 0.739744 | Val Loss: 0.157842, Val Acc: 0.711340\n",
      "Epoch 8079 - Train Loss: 0.144431, Train Acc: 0.739744 | Val Loss: 0.157832, Val Acc: 0.711340\n",
      "Epoch 8080 - Train Loss: 0.144421, Train Acc: 0.739744 | Val Loss: 0.157823, Val Acc: 0.711340\n",
      "Epoch 8081 - Train Loss: 0.144410, Train Acc: 0.739744 | Val Loss: 0.157814, Val Acc: 0.711340\n",
      "Epoch 8082 - Train Loss: 0.144400, Train Acc: 0.739744 | Val Loss: 0.157805, Val Acc: 0.711340\n",
      "Epoch 8083 - Train Loss: 0.144390, Train Acc: 0.739744 | Val Loss: 0.157796, Val Acc: 0.711340\n",
      "Epoch 8084 - Train Loss: 0.144379, Train Acc: 0.739744 | Val Loss: 0.157787, Val Acc: 0.711340\n",
      "Epoch 8085 - Train Loss: 0.144369, Train Acc: 0.739744 | Val Loss: 0.157778, Val Acc: 0.711340\n",
      "Epoch 8086 - Train Loss: 0.144358, Train Acc: 0.739744 | Val Loss: 0.157769, Val Acc: 0.711340\n",
      "Epoch 8087 - Train Loss: 0.144348, Train Acc: 0.739744 | Val Loss: 0.157760, Val Acc: 0.711340\n",
      "Epoch 8088 - Train Loss: 0.144337, Train Acc: 0.739744 | Val Loss: 0.157751, Val Acc: 0.711340\n",
      "Epoch 8089 - Train Loss: 0.144327, Train Acc: 0.739744 | Val Loss: 0.157742, Val Acc: 0.711340\n",
      "Epoch 8090 - Train Loss: 0.144316, Train Acc: 0.739744 | Val Loss: 0.157733, Val Acc: 0.711340\n",
      "Epoch 8091 - Train Loss: 0.144306, Train Acc: 0.739744 | Val Loss: 0.157724, Val Acc: 0.711340\n",
      "Epoch 8092 - Train Loss: 0.144295, Train Acc: 0.739744 | Val Loss: 0.157715, Val Acc: 0.711340\n",
      "Epoch 8093 - Train Loss: 0.144285, Train Acc: 0.739744 | Val Loss: 0.157706, Val Acc: 0.711340\n",
      "Epoch 8094 - Train Loss: 0.144275, Train Acc: 0.739744 | Val Loss: 0.157696, Val Acc: 0.711340\n",
      "Epoch 8095 - Train Loss: 0.144264, Train Acc: 0.739744 | Val Loss: 0.157687, Val Acc: 0.711340\n",
      "Epoch 8096 - Train Loss: 0.144254, Train Acc: 0.739744 | Val Loss: 0.157678, Val Acc: 0.711340\n",
      "Epoch 8097 - Train Loss: 0.144243, Train Acc: 0.739744 | Val Loss: 0.157669, Val Acc: 0.711340\n",
      "Epoch 8098 - Train Loss: 0.144233, Train Acc: 0.739744 | Val Loss: 0.157660, Val Acc: 0.711340\n",
      "Epoch 8099 - Train Loss: 0.144222, Train Acc: 0.739744 | Val Loss: 0.157651, Val Acc: 0.711340\n",
      "Epoch 8100 - Train Loss: 0.144212, Train Acc: 0.739744 | Val Loss: 0.157642, Val Acc: 0.711340\n",
      "Epoch 8101 - Train Loss: 0.144202, Train Acc: 0.739744 | Val Loss: 0.157633, Val Acc: 0.711340\n",
      "Epoch 8102 - Train Loss: 0.144191, Train Acc: 0.739744 | Val Loss: 0.157624, Val Acc: 0.711340\n",
      "Epoch 8103 - Train Loss: 0.144181, Train Acc: 0.739744 | Val Loss: 0.157615, Val Acc: 0.711340\n",
      "Epoch 8104 - Train Loss: 0.144170, Train Acc: 0.739744 | Val Loss: 0.157606, Val Acc: 0.711340\n",
      "Epoch 8105 - Train Loss: 0.144160, Train Acc: 0.739744 | Val Loss: 0.157597, Val Acc: 0.711340\n",
      "Epoch 8106 - Train Loss: 0.144149, Train Acc: 0.739744 | Val Loss: 0.157588, Val Acc: 0.711340\n",
      "Epoch 8107 - Train Loss: 0.144139, Train Acc: 0.739744 | Val Loss: 0.157579, Val Acc: 0.711340\n",
      "Epoch 8108 - Train Loss: 0.144129, Train Acc: 0.739744 | Val Loss: 0.157570, Val Acc: 0.711340\n",
      "Epoch 8109 - Train Loss: 0.144118, Train Acc: 0.739744 | Val Loss: 0.157561, Val Acc: 0.711340\n",
      "Epoch 8110 - Train Loss: 0.144108, Train Acc: 0.739744 | Val Loss: 0.157552, Val Acc: 0.711340\n",
      "Epoch 8111 - Train Loss: 0.144097, Train Acc: 0.739744 | Val Loss: 0.157543, Val Acc: 0.711340\n",
      "Epoch 8112 - Train Loss: 0.144087, Train Acc: 0.739744 | Val Loss: 0.157534, Val Acc: 0.711340\n",
      "Epoch 8113 - Train Loss: 0.144076, Train Acc: 0.739744 | Val Loss: 0.157525, Val Acc: 0.711340\n",
      "Epoch 8114 - Train Loss: 0.144066, Train Acc: 0.739744 | Val Loss: 0.157516, Val Acc: 0.711340\n",
      "Epoch 8115 - Train Loss: 0.144056, Train Acc: 0.739744 | Val Loss: 0.157507, Val Acc: 0.711340\n",
      "Epoch 8116 - Train Loss: 0.144045, Train Acc: 0.739744 | Val Loss: 0.157498, Val Acc: 0.711340\n",
      "Epoch 8117 - Train Loss: 0.144035, Train Acc: 0.739744 | Val Loss: 0.157489, Val Acc: 0.711340\n",
      "Epoch 8118 - Train Loss: 0.144024, Train Acc: 0.739744 | Val Loss: 0.157479, Val Acc: 0.711340\n",
      "Epoch 8119 - Train Loss: 0.144014, Train Acc: 0.739744 | Val Loss: 0.157470, Val Acc: 0.711340\n",
      "Epoch 8120 - Train Loss: 0.144003, Train Acc: 0.739744 | Val Loss: 0.157461, Val Acc: 0.711340\n",
      "Epoch 8121 - Train Loss: 0.143993, Train Acc: 0.739744 | Val Loss: 0.157452, Val Acc: 0.711340\n",
      "Epoch 8122 - Train Loss: 0.143983, Train Acc: 0.739744 | Val Loss: 0.157443, Val Acc: 0.711340\n",
      "Epoch 8123 - Train Loss: 0.143972, Train Acc: 0.739744 | Val Loss: 0.157434, Val Acc: 0.711340\n",
      "Epoch 8124 - Train Loss: 0.143962, Train Acc: 0.739744 | Val Loss: 0.157425, Val Acc: 0.711340\n",
      "Epoch 8125 - Train Loss: 0.143951, Train Acc: 0.739744 | Val Loss: 0.157416, Val Acc: 0.711340\n",
      "Epoch 8126 - Train Loss: 0.143941, Train Acc: 0.739744 | Val Loss: 0.157407, Val Acc: 0.711340\n",
      "Epoch 8127 - Train Loss: 0.143931, Train Acc: 0.739744 | Val Loss: 0.157398, Val Acc: 0.711340\n",
      "Epoch 8128 - Train Loss: 0.143920, Train Acc: 0.739744 | Val Loss: 0.157389, Val Acc: 0.711340\n",
      "Epoch 8129 - Train Loss: 0.143910, Train Acc: 0.739744 | Val Loss: 0.157380, Val Acc: 0.711340\n",
      "Epoch 8130 - Train Loss: 0.143899, Train Acc: 0.739744 | Val Loss: 0.157371, Val Acc: 0.711340\n",
      "Epoch 8131 - Train Loss: 0.143889, Train Acc: 0.739744 | Val Loss: 0.157362, Val Acc: 0.711340\n",
      "Epoch 8132 - Train Loss: 0.143879, Train Acc: 0.739744 | Val Loss: 0.157353, Val Acc: 0.711340\n",
      "Epoch 8133 - Train Loss: 0.143868, Train Acc: 0.739744 | Val Loss: 0.157344, Val Acc: 0.711340\n",
      "Epoch 8134 - Train Loss: 0.143858, Train Acc: 0.739744 | Val Loss: 0.157335, Val Acc: 0.711340\n",
      "Epoch 8135 - Train Loss: 0.143847, Train Acc: 0.739744 | Val Loss: 0.157326, Val Acc: 0.711340\n",
      "Epoch 8136 - Train Loss: 0.143837, Train Acc: 0.739744 | Val Loss: 0.157317, Val Acc: 0.711340\n",
      "Epoch 8137 - Train Loss: 0.143827, Train Acc: 0.739744 | Val Loss: 0.157308, Val Acc: 0.711340\n",
      "Epoch 8138 - Train Loss: 0.143816, Train Acc: 0.739744 | Val Loss: 0.157299, Val Acc: 0.711340\n",
      "Epoch 8139 - Train Loss: 0.143806, Train Acc: 0.739744 | Val Loss: 0.157290, Val Acc: 0.711340\n",
      "Epoch 8140 - Train Loss: 0.143795, Train Acc: 0.739744 | Val Loss: 0.157281, Val Acc: 0.711340\n",
      "Epoch 8141 - Train Loss: 0.143785, Train Acc: 0.739744 | Val Loss: 0.157272, Val Acc: 0.711340\n",
      "Epoch 8142 - Train Loss: 0.143775, Train Acc: 0.739744 | Val Loss: 0.157263, Val Acc: 0.711340\n",
      "Epoch 8143 - Train Loss: 0.143764, Train Acc: 0.739744 | Val Loss: 0.157254, Val Acc: 0.711340\n",
      "Epoch 8144 - Train Loss: 0.143754, Train Acc: 0.739744 | Val Loss: 0.157245, Val Acc: 0.711340\n",
      "Epoch 8145 - Train Loss: 0.143743, Train Acc: 0.739744 | Val Loss: 0.157236, Val Acc: 0.711340\n",
      "Epoch 8146 - Train Loss: 0.143733, Train Acc: 0.739744 | Val Loss: 0.157227, Val Acc: 0.711340\n",
      "Epoch 8147 - Train Loss: 0.143723, Train Acc: 0.739744 | Val Loss: 0.157218, Val Acc: 0.711340\n",
      "Epoch 8148 - Train Loss: 0.143712, Train Acc: 0.739744 | Val Loss: 0.157209, Val Acc: 0.711340\n",
      "Epoch 8149 - Train Loss: 0.143702, Train Acc: 0.739744 | Val Loss: 0.157200, Val Acc: 0.711340\n",
      "Epoch 8150 - Train Loss: 0.143692, Train Acc: 0.739744 | Val Loss: 0.157191, Val Acc: 0.711340\n",
      "Epoch 8151 - Train Loss: 0.143681, Train Acc: 0.739744 | Val Loss: 0.157182, Val Acc: 0.711340\n",
      "Epoch 8152 - Train Loss: 0.143671, Train Acc: 0.739744 | Val Loss: 0.157173, Val Acc: 0.711340\n",
      "Epoch 8153 - Train Loss: 0.143660, Train Acc: 0.739744 | Val Loss: 0.157164, Val Acc: 0.711340\n",
      "Epoch 8154 - Train Loss: 0.143650, Train Acc: 0.739744 | Val Loss: 0.157156, Val Acc: 0.711340\n",
      "Epoch 8155 - Train Loss: 0.143640, Train Acc: 0.739744 | Val Loss: 0.157147, Val Acc: 0.711340\n",
      "Epoch 8156 - Train Loss: 0.143629, Train Acc: 0.739744 | Val Loss: 0.157138, Val Acc: 0.711340\n",
      "Epoch 8157 - Train Loss: 0.143619, Train Acc: 0.739744 | Val Loss: 0.157129, Val Acc: 0.711340\n",
      "Epoch 8158 - Train Loss: 0.143608, Train Acc: 0.739744 | Val Loss: 0.157120, Val Acc: 0.711340\n",
      "Epoch 8159 - Train Loss: 0.143598, Train Acc: 0.739744 | Val Loss: 0.157111, Val Acc: 0.711340\n",
      "Epoch 8160 - Train Loss: 0.143588, Train Acc: 0.739744 | Val Loss: 0.157102, Val Acc: 0.711340\n",
      "Epoch 8161 - Train Loss: 0.143577, Train Acc: 0.739744 | Val Loss: 0.157093, Val Acc: 0.711340\n",
      "Epoch 8162 - Train Loss: 0.143567, Train Acc: 0.739744 | Val Loss: 0.157084, Val Acc: 0.711340\n",
      "Epoch 8163 - Train Loss: 0.143557, Train Acc: 0.739744 | Val Loss: 0.157075, Val Acc: 0.711340\n",
      "Epoch 8164 - Train Loss: 0.143546, Train Acc: 0.739744 | Val Loss: 0.157066, Val Acc: 0.711340\n",
      "Epoch 8165 - Train Loss: 0.143536, Train Acc: 0.739744 | Val Loss: 0.157057, Val Acc: 0.711340\n",
      "Epoch 8166 - Train Loss: 0.143526, Train Acc: 0.739744 | Val Loss: 0.157048, Val Acc: 0.711340\n",
      "Epoch 8167 - Train Loss: 0.143515, Train Acc: 0.739744 | Val Loss: 0.157039, Val Acc: 0.711340\n",
      "Epoch 8168 - Train Loss: 0.143505, Train Acc: 0.739744 | Val Loss: 0.157030, Val Acc: 0.711340\n",
      "Epoch 8169 - Train Loss: 0.143494, Train Acc: 0.739744 | Val Loss: 0.157021, Val Acc: 0.711340\n",
      "Epoch 8170 - Train Loss: 0.143484, Train Acc: 0.739744 | Val Loss: 0.157012, Val Acc: 0.711340\n",
      "Epoch 8171 - Train Loss: 0.143474, Train Acc: 0.739744 | Val Loss: 0.157003, Val Acc: 0.711340\n",
      "Epoch 8172 - Train Loss: 0.143463, Train Acc: 0.739744 | Val Loss: 0.156994, Val Acc: 0.711340\n",
      "Epoch 8173 - Train Loss: 0.143453, Train Acc: 0.739744 | Val Loss: 0.156985, Val Acc: 0.711340\n",
      "Epoch 8174 - Train Loss: 0.143443, Train Acc: 0.739744 | Val Loss: 0.156976, Val Acc: 0.711340\n",
      "Epoch 8175 - Train Loss: 0.143432, Train Acc: 0.739744 | Val Loss: 0.156967, Val Acc: 0.711340\n",
      "Epoch 8176 - Train Loss: 0.143422, Train Acc: 0.739744 | Val Loss: 0.156958, Val Acc: 0.711340\n",
      "Epoch 8177 - Train Loss: 0.143412, Train Acc: 0.739744 | Val Loss: 0.156949, Val Acc: 0.711340\n",
      "Epoch 8178 - Train Loss: 0.143401, Train Acc: 0.739744 | Val Loss: 0.156940, Val Acc: 0.711340\n",
      "Epoch 8179 - Train Loss: 0.143391, Train Acc: 0.739744 | Val Loss: 0.156931, Val Acc: 0.711340\n",
      "Epoch 8180 - Train Loss: 0.143381, Train Acc: 0.739744 | Val Loss: 0.156922, Val Acc: 0.711340\n",
      "Epoch 8181 - Train Loss: 0.143370, Train Acc: 0.739744 | Val Loss: 0.156914, Val Acc: 0.711340\n",
      "Epoch 8182 - Train Loss: 0.143360, Train Acc: 0.739744 | Val Loss: 0.156905, Val Acc: 0.711340\n",
      "Epoch 8183 - Train Loss: 0.143349, Train Acc: 0.739744 | Val Loss: 0.156896, Val Acc: 0.711340\n",
      "Epoch 8184 - Train Loss: 0.143339, Train Acc: 0.739744 | Val Loss: 0.156887, Val Acc: 0.711340\n",
      "Epoch 8185 - Train Loss: 0.143329, Train Acc: 0.739744 | Val Loss: 0.156878, Val Acc: 0.711340\n",
      "Epoch 8186 - Train Loss: 0.143318, Train Acc: 0.739744 | Val Loss: 0.156869, Val Acc: 0.711340\n",
      "Epoch 8187 - Train Loss: 0.143308, Train Acc: 0.739744 | Val Loss: 0.156860, Val Acc: 0.711340\n",
      "Epoch 8188 - Train Loss: 0.143298, Train Acc: 0.739744 | Val Loss: 0.156851, Val Acc: 0.711340\n",
      "Epoch 8189 - Train Loss: 0.143287, Train Acc: 0.739744 | Val Loss: 0.156842, Val Acc: 0.711340\n",
      "Epoch 8190 - Train Loss: 0.143277, Train Acc: 0.739744 | Val Loss: 0.156833, Val Acc: 0.711340\n",
      "Epoch 8191 - Train Loss: 0.143267, Train Acc: 0.739744 | Val Loss: 0.156824, Val Acc: 0.711340\n",
      "Epoch 8192 - Train Loss: 0.143256, Train Acc: 0.739744 | Val Loss: 0.156815, Val Acc: 0.711340\n",
      "Epoch 8193 - Train Loss: 0.143246, Train Acc: 0.739744 | Val Loss: 0.156806, Val Acc: 0.711340\n",
      "Epoch 8194 - Train Loss: 0.143236, Train Acc: 0.739744 | Val Loss: 0.156797, Val Acc: 0.711340\n",
      "Epoch 8195 - Train Loss: 0.143225, Train Acc: 0.739744 | Val Loss: 0.156788, Val Acc: 0.711340\n",
      "Epoch 8196 - Train Loss: 0.143215, Train Acc: 0.739744 | Val Loss: 0.156779, Val Acc: 0.711340\n",
      "Epoch 8197 - Train Loss: 0.143205, Train Acc: 0.739744 | Val Loss: 0.156771, Val Acc: 0.711340\n",
      "Epoch 8198 - Train Loss: 0.143194, Train Acc: 0.739744 | Val Loss: 0.156762, Val Acc: 0.711340\n",
      "Epoch 8199 - Train Loss: 0.143184, Train Acc: 0.739744 | Val Loss: 0.156753, Val Acc: 0.711340\n",
      "Epoch 8200 - Train Loss: 0.143174, Train Acc: 0.739744 | Val Loss: 0.156744, Val Acc: 0.711340\n",
      "Epoch 8201 - Train Loss: 0.143163, Train Acc: 0.739744 | Val Loss: 0.156735, Val Acc: 0.711340\n",
      "Epoch 8202 - Train Loss: 0.143153, Train Acc: 0.739744 | Val Loss: 0.156726, Val Acc: 0.711340\n",
      "Epoch 8203 - Train Loss: 0.143143, Train Acc: 0.739744 | Val Loss: 0.156717, Val Acc: 0.711340\n",
      "Epoch 8204 - Train Loss: 0.143132, Train Acc: 0.739744 | Val Loss: 0.156708, Val Acc: 0.711340\n",
      "Epoch 8205 - Train Loss: 0.143122, Train Acc: 0.739744 | Val Loss: 0.156699, Val Acc: 0.711340\n",
      "Epoch 8206 - Train Loss: 0.143112, Train Acc: 0.739744 | Val Loss: 0.156690, Val Acc: 0.711340\n",
      "Epoch 8207 - Train Loss: 0.143102, Train Acc: 0.739744 | Val Loss: 0.156681, Val Acc: 0.711340\n",
      "Epoch 8208 - Train Loss: 0.143091, Train Acc: 0.739744 | Val Loss: 0.156672, Val Acc: 0.711340\n",
      "Epoch 8209 - Train Loss: 0.143081, Train Acc: 0.739744 | Val Loss: 0.156664, Val Acc: 0.711340\n",
      "Epoch 8210 - Train Loss: 0.143071, Train Acc: 0.739744 | Val Loss: 0.156655, Val Acc: 0.711340\n",
      "Epoch 8211 - Train Loss: 0.143060, Train Acc: 0.739744 | Val Loss: 0.156646, Val Acc: 0.711340\n",
      "Epoch 8212 - Train Loss: 0.143050, Train Acc: 0.741026 | Val Loss: 0.156637, Val Acc: 0.711340\n",
      "Epoch 8213 - Train Loss: 0.143040, Train Acc: 0.741026 | Val Loss: 0.156628, Val Acc: 0.711340\n",
      "Epoch 8214 - Train Loss: 0.143029, Train Acc: 0.741026 | Val Loss: 0.156619, Val Acc: 0.711340\n",
      "Epoch 8215 - Train Loss: 0.143019, Train Acc: 0.741026 | Val Loss: 0.156610, Val Acc: 0.711340\n",
      "Epoch 8216 - Train Loss: 0.143009, Train Acc: 0.741026 | Val Loss: 0.156601, Val Acc: 0.711340\n",
      "Epoch 8217 - Train Loss: 0.142998, Train Acc: 0.741026 | Val Loss: 0.156592, Val Acc: 0.711340\n",
      "Epoch 8218 - Train Loss: 0.142988, Train Acc: 0.741026 | Val Loss: 0.156583, Val Acc: 0.711340\n",
      "Epoch 8219 - Train Loss: 0.142978, Train Acc: 0.741026 | Val Loss: 0.156574, Val Acc: 0.711340\n",
      "Epoch 8220 - Train Loss: 0.142967, Train Acc: 0.741026 | Val Loss: 0.156566, Val Acc: 0.711340\n",
      "Epoch 8221 - Train Loss: 0.142957, Train Acc: 0.741026 | Val Loss: 0.156557, Val Acc: 0.711340\n",
      "Epoch 8222 - Train Loss: 0.142947, Train Acc: 0.741026 | Val Loss: 0.156548, Val Acc: 0.711340\n",
      "Epoch 8223 - Train Loss: 0.142937, Train Acc: 0.741026 | Val Loss: 0.156539, Val Acc: 0.711340\n",
      "Epoch 8224 - Train Loss: 0.142926, Train Acc: 0.741026 | Val Loss: 0.156530, Val Acc: 0.711340\n",
      "Epoch 8225 - Train Loss: 0.142916, Train Acc: 0.741026 | Val Loss: 0.156521, Val Acc: 0.711340\n",
      "Epoch 8226 - Train Loss: 0.142906, Train Acc: 0.741026 | Val Loss: 0.156512, Val Acc: 0.711340\n",
      "Epoch 8227 - Train Loss: 0.142895, Train Acc: 0.741026 | Val Loss: 0.156503, Val Acc: 0.711340\n",
      "Epoch 8228 - Train Loss: 0.142885, Train Acc: 0.741026 | Val Loss: 0.156494, Val Acc: 0.711340\n",
      "Epoch 8229 - Train Loss: 0.142875, Train Acc: 0.741026 | Val Loss: 0.156485, Val Acc: 0.711340\n",
      "Epoch 8230 - Train Loss: 0.142864, Train Acc: 0.741026 | Val Loss: 0.156477, Val Acc: 0.711340\n",
      "Epoch 8231 - Train Loss: 0.142854, Train Acc: 0.741026 | Val Loss: 0.156468, Val Acc: 0.711340\n",
      "Epoch 8232 - Train Loss: 0.142844, Train Acc: 0.741026 | Val Loss: 0.156459, Val Acc: 0.711340\n",
      "Epoch 8233 - Train Loss: 0.142834, Train Acc: 0.741026 | Val Loss: 0.156450, Val Acc: 0.711340\n",
      "Epoch 8234 - Train Loss: 0.142823, Train Acc: 0.741026 | Val Loss: 0.156441, Val Acc: 0.711340\n",
      "Epoch 8235 - Train Loss: 0.142813, Train Acc: 0.741026 | Val Loss: 0.156432, Val Acc: 0.711340\n",
      "Epoch 8236 - Train Loss: 0.142803, Train Acc: 0.741026 | Val Loss: 0.156423, Val Acc: 0.711340\n",
      "Epoch 8237 - Train Loss: 0.142792, Train Acc: 0.741026 | Val Loss: 0.156414, Val Acc: 0.711340\n",
      "Epoch 8238 - Train Loss: 0.142782, Train Acc: 0.741026 | Val Loss: 0.156405, Val Acc: 0.711340\n",
      "Epoch 8239 - Train Loss: 0.142772, Train Acc: 0.741026 | Val Loss: 0.156397, Val Acc: 0.711340\n",
      "Epoch 8240 - Train Loss: 0.142762, Train Acc: 0.741026 | Val Loss: 0.156388, Val Acc: 0.711340\n",
      "Epoch 8241 - Train Loss: 0.142751, Train Acc: 0.741026 | Val Loss: 0.156379, Val Acc: 0.711340\n",
      "Epoch 8242 - Train Loss: 0.142741, Train Acc: 0.741026 | Val Loss: 0.156370, Val Acc: 0.711340\n",
      "Epoch 8243 - Train Loss: 0.142731, Train Acc: 0.741026 | Val Loss: 0.156361, Val Acc: 0.711340\n",
      "Epoch 8244 - Train Loss: 0.142720, Train Acc: 0.741026 | Val Loss: 0.156352, Val Acc: 0.711340\n",
      "Epoch 8245 - Train Loss: 0.142710, Train Acc: 0.741026 | Val Loss: 0.156343, Val Acc: 0.711340\n",
      "Epoch 8246 - Train Loss: 0.142700, Train Acc: 0.741026 | Val Loss: 0.156334, Val Acc: 0.711340\n",
      "Epoch 8247 - Train Loss: 0.142690, Train Acc: 0.741026 | Val Loss: 0.156326, Val Acc: 0.711340\n",
      "Epoch 8248 - Train Loss: 0.142679, Train Acc: 0.741026 | Val Loss: 0.156317, Val Acc: 0.711340\n",
      "Epoch 8249 - Train Loss: 0.142669, Train Acc: 0.741026 | Val Loss: 0.156308, Val Acc: 0.711340\n",
      "Epoch 8250 - Train Loss: 0.142659, Train Acc: 0.741026 | Val Loss: 0.156299, Val Acc: 0.711340\n",
      "Epoch 8251 - Train Loss: 0.142648, Train Acc: 0.741026 | Val Loss: 0.156290, Val Acc: 0.711340\n",
      "Epoch 8252 - Train Loss: 0.142638, Train Acc: 0.741026 | Val Loss: 0.156281, Val Acc: 0.711340\n",
      "Epoch 8253 - Train Loss: 0.142628, Train Acc: 0.741026 | Val Loss: 0.156272, Val Acc: 0.711340\n",
      "Epoch 8254 - Train Loss: 0.142618, Train Acc: 0.741026 | Val Loss: 0.156264, Val Acc: 0.711340\n",
      "Epoch 8255 - Train Loss: 0.142607, Train Acc: 0.741026 | Val Loss: 0.156255, Val Acc: 0.711340\n",
      "Epoch 8256 - Train Loss: 0.142597, Train Acc: 0.741026 | Val Loss: 0.156246, Val Acc: 0.711340\n",
      "Epoch 8257 - Train Loss: 0.142587, Train Acc: 0.741026 | Val Loss: 0.156237, Val Acc: 0.711340\n",
      "Epoch 8258 - Train Loss: 0.142577, Train Acc: 0.741026 | Val Loss: 0.156228, Val Acc: 0.711340\n",
      "Epoch 8259 - Train Loss: 0.142566, Train Acc: 0.741026 | Val Loss: 0.156219, Val Acc: 0.711340\n",
      "Epoch 8260 - Train Loss: 0.142556, Train Acc: 0.741026 | Val Loss: 0.156210, Val Acc: 0.711340\n",
      "Epoch 8261 - Train Loss: 0.142546, Train Acc: 0.741026 | Val Loss: 0.156201, Val Acc: 0.711340\n",
      "Epoch 8262 - Train Loss: 0.142536, Train Acc: 0.741026 | Val Loss: 0.156193, Val Acc: 0.711340\n",
      "Epoch 8263 - Train Loss: 0.142525, Train Acc: 0.741026 | Val Loss: 0.156184, Val Acc: 0.711340\n",
      "Epoch 8264 - Train Loss: 0.142515, Train Acc: 0.741026 | Val Loss: 0.156175, Val Acc: 0.711340\n",
      "Epoch 8265 - Train Loss: 0.142505, Train Acc: 0.741026 | Val Loss: 0.156166, Val Acc: 0.711340\n",
      "Epoch 8266 - Train Loss: 0.142494, Train Acc: 0.741026 | Val Loss: 0.156157, Val Acc: 0.711340\n",
      "Epoch 8267 - Train Loss: 0.142484, Train Acc: 0.741026 | Val Loss: 0.156148, Val Acc: 0.711340\n",
      "Epoch 8268 - Train Loss: 0.142474, Train Acc: 0.741026 | Val Loss: 0.156140, Val Acc: 0.711340\n",
      "Epoch 8269 - Train Loss: 0.142464, Train Acc: 0.741026 | Val Loss: 0.156131, Val Acc: 0.711340\n",
      "Epoch 8270 - Train Loss: 0.142453, Train Acc: 0.741026 | Val Loss: 0.156122, Val Acc: 0.711340\n",
      "Epoch 8271 - Train Loss: 0.142443, Train Acc: 0.741026 | Val Loss: 0.156113, Val Acc: 0.711340\n",
      "Epoch 8272 - Train Loss: 0.142433, Train Acc: 0.741026 | Val Loss: 0.156104, Val Acc: 0.711340\n",
      "Epoch 8273 - Train Loss: 0.142423, Train Acc: 0.741026 | Val Loss: 0.156095, Val Acc: 0.711340\n",
      "Epoch 8274 - Train Loss: 0.142412, Train Acc: 0.741026 | Val Loss: 0.156086, Val Acc: 0.711340\n",
      "Epoch 8275 - Train Loss: 0.142402, Train Acc: 0.741026 | Val Loss: 0.156078, Val Acc: 0.711340\n",
      "Epoch 8276 - Train Loss: 0.142392, Train Acc: 0.741026 | Val Loss: 0.156069, Val Acc: 0.711340\n",
      "Epoch 8277 - Train Loss: 0.142382, Train Acc: 0.741026 | Val Loss: 0.156060, Val Acc: 0.711340\n",
      "Epoch 8278 - Train Loss: 0.142371, Train Acc: 0.741026 | Val Loss: 0.156051, Val Acc: 0.711340\n",
      "Epoch 8279 - Train Loss: 0.142361, Train Acc: 0.741026 | Val Loss: 0.156042, Val Acc: 0.711340\n",
      "Epoch 8280 - Train Loss: 0.142351, Train Acc: 0.741026 | Val Loss: 0.156033, Val Acc: 0.711340\n",
      "Epoch 8281 - Train Loss: 0.142341, Train Acc: 0.741026 | Val Loss: 0.156025, Val Acc: 0.711340\n",
      "Epoch 8282 - Train Loss: 0.142331, Train Acc: 0.741026 | Val Loss: 0.156016, Val Acc: 0.711340\n",
      "Epoch 8283 - Train Loss: 0.142320, Train Acc: 0.741026 | Val Loss: 0.156007, Val Acc: 0.711340\n",
      "Epoch 8284 - Train Loss: 0.142310, Train Acc: 0.741026 | Val Loss: 0.155998, Val Acc: 0.711340\n",
      "Epoch 8285 - Train Loss: 0.142300, Train Acc: 0.741026 | Val Loss: 0.155989, Val Acc: 0.711340\n",
      "Epoch 8286 - Train Loss: 0.142290, Train Acc: 0.741026 | Val Loss: 0.155980, Val Acc: 0.711340\n",
      "Epoch 8287 - Train Loss: 0.142279, Train Acc: 0.741026 | Val Loss: 0.155972, Val Acc: 0.711340\n",
      "Epoch 8288 - Train Loss: 0.142269, Train Acc: 0.741026 | Val Loss: 0.155963, Val Acc: 0.711340\n",
      "Epoch 8289 - Train Loss: 0.142259, Train Acc: 0.741026 | Val Loss: 0.155954, Val Acc: 0.711340\n",
      "Epoch 8290 - Train Loss: 0.142249, Train Acc: 0.741026 | Val Loss: 0.155945, Val Acc: 0.711340\n",
      "Epoch 8291 - Train Loss: 0.142238, Train Acc: 0.741026 | Val Loss: 0.155936, Val Acc: 0.711340\n",
      "Epoch 8292 - Train Loss: 0.142228, Train Acc: 0.741026 | Val Loss: 0.155927, Val Acc: 0.711340\n",
      "Epoch 8293 - Train Loss: 0.142218, Train Acc: 0.741026 | Val Loss: 0.155919, Val Acc: 0.711340\n",
      "Epoch 8294 - Train Loss: 0.142208, Train Acc: 0.741026 | Val Loss: 0.155910, Val Acc: 0.711340\n",
      "Epoch 8295 - Train Loss: 0.142198, Train Acc: 0.741026 | Val Loss: 0.155901, Val Acc: 0.711340\n",
      "Epoch 8296 - Train Loss: 0.142187, Train Acc: 0.741026 | Val Loss: 0.155892, Val Acc: 0.711340\n",
      "Epoch 8297 - Train Loss: 0.142177, Train Acc: 0.741026 | Val Loss: 0.155883, Val Acc: 0.711340\n",
      "Epoch 8298 - Train Loss: 0.142167, Train Acc: 0.741026 | Val Loss: 0.155875, Val Acc: 0.711340\n",
      "Epoch 8299 - Train Loss: 0.142157, Train Acc: 0.741026 | Val Loss: 0.155866, Val Acc: 0.711340\n",
      "Epoch 8300 - Train Loss: 0.142146, Train Acc: 0.741026 | Val Loss: 0.155857, Val Acc: 0.711340\n",
      "Epoch 8301 - Train Loss: 0.142136, Train Acc: 0.741026 | Val Loss: 0.155848, Val Acc: 0.711340\n",
      "Epoch 8302 - Train Loss: 0.142126, Train Acc: 0.741026 | Val Loss: 0.155839, Val Acc: 0.711340\n",
      "Epoch 8303 - Train Loss: 0.142116, Train Acc: 0.741026 | Val Loss: 0.155831, Val Acc: 0.711340\n",
      "Epoch 8304 - Train Loss: 0.142106, Train Acc: 0.741026 | Val Loss: 0.155822, Val Acc: 0.711340\n",
      "Epoch 8305 - Train Loss: 0.142095, Train Acc: 0.741026 | Val Loss: 0.155813, Val Acc: 0.711340\n",
      "Epoch 8306 - Train Loss: 0.142085, Train Acc: 0.741026 | Val Loss: 0.155804, Val Acc: 0.711340\n",
      "Epoch 8307 - Train Loss: 0.142075, Train Acc: 0.741026 | Val Loss: 0.155795, Val Acc: 0.711340\n",
      "Epoch 8308 - Train Loss: 0.142065, Train Acc: 0.741026 | Val Loss: 0.155786, Val Acc: 0.711340\n",
      "Epoch 8309 - Train Loss: 0.142054, Train Acc: 0.741026 | Val Loss: 0.155778, Val Acc: 0.711340\n",
      "Epoch 8310 - Train Loss: 0.142044, Train Acc: 0.741026 | Val Loss: 0.155769, Val Acc: 0.711340\n",
      "Epoch 8311 - Train Loss: 0.142034, Train Acc: 0.741026 | Val Loss: 0.155760, Val Acc: 0.711340\n",
      "Epoch 8312 - Train Loss: 0.142024, Train Acc: 0.741026 | Val Loss: 0.155751, Val Acc: 0.701031\n",
      "Epoch 8313 - Train Loss: 0.142014, Train Acc: 0.741026 | Val Loss: 0.155742, Val Acc: 0.701031\n",
      "Epoch 8314 - Train Loss: 0.142003, Train Acc: 0.741026 | Val Loss: 0.155734, Val Acc: 0.701031\n",
      "Epoch 8315 - Train Loss: 0.141993, Train Acc: 0.741026 | Val Loss: 0.155725, Val Acc: 0.701031\n",
      "Epoch 8316 - Train Loss: 0.141983, Train Acc: 0.741026 | Val Loss: 0.155716, Val Acc: 0.701031\n",
      "Epoch 8317 - Train Loss: 0.141973, Train Acc: 0.741026 | Val Loss: 0.155707, Val Acc: 0.701031\n",
      "Epoch 8318 - Train Loss: 0.141963, Train Acc: 0.741026 | Val Loss: 0.155698, Val Acc: 0.701031\n",
      "Epoch 8319 - Train Loss: 0.141952, Train Acc: 0.742308 | Val Loss: 0.155690, Val Acc: 0.701031\n",
      "Epoch 8320 - Train Loss: 0.141942, Train Acc: 0.742308 | Val Loss: 0.155681, Val Acc: 0.701031\n",
      "Epoch 8321 - Train Loss: 0.141932, Train Acc: 0.742308 | Val Loss: 0.155672, Val Acc: 0.701031\n",
      "Epoch 8322 - Train Loss: 0.141922, Train Acc: 0.742308 | Val Loss: 0.155663, Val Acc: 0.701031\n",
      "Epoch 8323 - Train Loss: 0.141912, Train Acc: 0.742308 | Val Loss: 0.155655, Val Acc: 0.701031\n",
      "Epoch 8324 - Train Loss: 0.141901, Train Acc: 0.742308 | Val Loss: 0.155646, Val Acc: 0.701031\n",
      "Epoch 8325 - Train Loss: 0.141891, Train Acc: 0.742308 | Val Loss: 0.155637, Val Acc: 0.701031\n",
      "Epoch 8326 - Train Loss: 0.141881, Train Acc: 0.742308 | Val Loss: 0.155628, Val Acc: 0.701031\n",
      "Epoch 8327 - Train Loss: 0.141871, Train Acc: 0.742308 | Val Loss: 0.155619, Val Acc: 0.701031\n",
      "Epoch 8328 - Train Loss: 0.141861, Train Acc: 0.742308 | Val Loss: 0.155611, Val Acc: 0.701031\n",
      "Epoch 8329 - Train Loss: 0.141851, Train Acc: 0.742308 | Val Loss: 0.155602, Val Acc: 0.701031\n",
      "Epoch 8330 - Train Loss: 0.141840, Train Acc: 0.742308 | Val Loss: 0.155593, Val Acc: 0.701031\n",
      "Epoch 8331 - Train Loss: 0.141830, Train Acc: 0.742308 | Val Loss: 0.155584, Val Acc: 0.701031\n",
      "Epoch 8332 - Train Loss: 0.141820, Train Acc: 0.742308 | Val Loss: 0.155575, Val Acc: 0.701031\n",
      "Epoch 8333 - Train Loss: 0.141810, Train Acc: 0.742308 | Val Loss: 0.155567, Val Acc: 0.701031\n",
      "Epoch 8334 - Train Loss: 0.141800, Train Acc: 0.742308 | Val Loss: 0.155558, Val Acc: 0.701031\n",
      "Epoch 8335 - Train Loss: 0.141789, Train Acc: 0.742308 | Val Loss: 0.155549, Val Acc: 0.701031\n",
      "Epoch 8336 - Train Loss: 0.141779, Train Acc: 0.742308 | Val Loss: 0.155540, Val Acc: 0.701031\n",
      "Epoch 8337 - Train Loss: 0.141769, Train Acc: 0.742308 | Val Loss: 0.155532, Val Acc: 0.701031\n",
      "Epoch 8338 - Train Loss: 0.141759, Train Acc: 0.742308 | Val Loss: 0.155523, Val Acc: 0.701031\n",
      "Epoch 8339 - Train Loss: 0.141749, Train Acc: 0.742308 | Val Loss: 0.155514, Val Acc: 0.701031\n",
      "Epoch 8340 - Train Loss: 0.141739, Train Acc: 0.742308 | Val Loss: 0.155505, Val Acc: 0.701031\n",
      "Epoch 8341 - Train Loss: 0.141728, Train Acc: 0.742308 | Val Loss: 0.155497, Val Acc: 0.701031\n",
      "Epoch 8342 - Train Loss: 0.141718, Train Acc: 0.742308 | Val Loss: 0.155488, Val Acc: 0.701031\n",
      "Epoch 8343 - Train Loss: 0.141708, Train Acc: 0.742308 | Val Loss: 0.155479, Val Acc: 0.701031\n",
      "Epoch 8344 - Train Loss: 0.141698, Train Acc: 0.742308 | Val Loss: 0.155470, Val Acc: 0.701031\n",
      "Epoch 8345 - Train Loss: 0.141688, Train Acc: 0.742308 | Val Loss: 0.155461, Val Acc: 0.701031\n",
      "Epoch 8346 - Train Loss: 0.141678, Train Acc: 0.742308 | Val Loss: 0.155452, Val Acc: 0.701031\n",
      "Epoch 8347 - Train Loss: 0.141667, Train Acc: 0.742308 | Val Loss: 0.155444, Val Acc: 0.701031\n",
      "Epoch 8348 - Train Loss: 0.141657, Train Acc: 0.742308 | Val Loss: 0.155435, Val Acc: 0.701031\n",
      "Epoch 8349 - Train Loss: 0.141647, Train Acc: 0.742308 | Val Loss: 0.155426, Val Acc: 0.701031\n",
      "Epoch 8350 - Train Loss: 0.141637, Train Acc: 0.742308 | Val Loss: 0.155417, Val Acc: 0.701031\n",
      "Epoch 8351 - Train Loss: 0.141627, Train Acc: 0.742308 | Val Loss: 0.155408, Val Acc: 0.701031\n",
      "Epoch 8352 - Train Loss: 0.141617, Train Acc: 0.742308 | Val Loss: 0.155399, Val Acc: 0.701031\n",
      "Epoch 8353 - Train Loss: 0.141606, Train Acc: 0.742308 | Val Loss: 0.155391, Val Acc: 0.701031\n",
      "Epoch 8354 - Train Loss: 0.141596, Train Acc: 0.742308 | Val Loss: 0.155382, Val Acc: 0.701031\n",
      "Epoch 8355 - Train Loss: 0.141586, Train Acc: 0.742308 | Val Loss: 0.155373, Val Acc: 0.701031\n",
      "Epoch 8356 - Train Loss: 0.141576, Train Acc: 0.742308 | Val Loss: 0.155364, Val Acc: 0.701031\n",
      "Epoch 8357 - Train Loss: 0.141566, Train Acc: 0.742308 | Val Loss: 0.155355, Val Acc: 0.701031\n",
      "Epoch 8358 - Train Loss: 0.141556, Train Acc: 0.742308 | Val Loss: 0.155347, Val Acc: 0.701031\n",
      "Epoch 8359 - Train Loss: 0.141546, Train Acc: 0.742308 | Val Loss: 0.155338, Val Acc: 0.701031\n",
      "Epoch 8360 - Train Loss: 0.141535, Train Acc: 0.742308 | Val Loss: 0.155329, Val Acc: 0.701031\n",
      "Epoch 8361 - Train Loss: 0.141525, Train Acc: 0.743590 | Val Loss: 0.155320, Val Acc: 0.701031\n",
      "Epoch 8362 - Train Loss: 0.141515, Train Acc: 0.743590 | Val Loss: 0.155311, Val Acc: 0.701031\n",
      "Epoch 8363 - Train Loss: 0.141505, Train Acc: 0.743590 | Val Loss: 0.155303, Val Acc: 0.701031\n",
      "Epoch 8364 - Train Loss: 0.141495, Train Acc: 0.743590 | Val Loss: 0.155294, Val Acc: 0.701031\n",
      "Epoch 8365 - Train Loss: 0.141485, Train Acc: 0.743590 | Val Loss: 0.155285, Val Acc: 0.701031\n",
      "Epoch 8366 - Train Loss: 0.141475, Train Acc: 0.743590 | Val Loss: 0.155276, Val Acc: 0.701031\n",
      "Epoch 8367 - Train Loss: 0.141465, Train Acc: 0.743590 | Val Loss: 0.155267, Val Acc: 0.701031\n",
      "Epoch 8368 - Train Loss: 0.141454, Train Acc: 0.743590 | Val Loss: 0.155259, Val Acc: 0.701031\n",
      "Epoch 8369 - Train Loss: 0.141444, Train Acc: 0.743590 | Val Loss: 0.155250, Val Acc: 0.701031\n",
      "Epoch 8370 - Train Loss: 0.141434, Train Acc: 0.743590 | Val Loss: 0.155241, Val Acc: 0.701031\n",
      "Epoch 8371 - Train Loss: 0.141424, Train Acc: 0.743590 | Val Loss: 0.155232, Val Acc: 0.701031\n",
      "Epoch 8372 - Train Loss: 0.141414, Train Acc: 0.743590 | Val Loss: 0.155223, Val Acc: 0.701031\n",
      "Epoch 8373 - Train Loss: 0.141404, Train Acc: 0.743590 | Val Loss: 0.155215, Val Acc: 0.701031\n",
      "Epoch 8374 - Train Loss: 0.141394, Train Acc: 0.743590 | Val Loss: 0.155206, Val Acc: 0.701031\n",
      "Epoch 8375 - Train Loss: 0.141384, Train Acc: 0.743590 | Val Loss: 0.155197, Val Acc: 0.701031\n",
      "Epoch 8376 - Train Loss: 0.141373, Train Acc: 0.743590 | Val Loss: 0.155188, Val Acc: 0.701031\n",
      "Epoch 8377 - Train Loss: 0.141363, Train Acc: 0.743590 | Val Loss: 0.155180, Val Acc: 0.701031\n",
      "Epoch 8378 - Train Loss: 0.141353, Train Acc: 0.743590 | Val Loss: 0.155171, Val Acc: 0.701031\n",
      "Epoch 8379 - Train Loss: 0.141343, Train Acc: 0.743590 | Val Loss: 0.155162, Val Acc: 0.701031\n",
      "Epoch 8380 - Train Loss: 0.141333, Train Acc: 0.743590 | Val Loss: 0.155153, Val Acc: 0.701031\n",
      "Epoch 8381 - Train Loss: 0.141323, Train Acc: 0.743590 | Val Loss: 0.155145, Val Acc: 0.701031\n",
      "Epoch 8382 - Train Loss: 0.141313, Train Acc: 0.743590 | Val Loss: 0.155136, Val Acc: 0.701031\n",
      "Epoch 8383 - Train Loss: 0.141303, Train Acc: 0.743590 | Val Loss: 0.155127, Val Acc: 0.701031\n",
      "Epoch 8384 - Train Loss: 0.141292, Train Acc: 0.743590 | Val Loss: 0.155118, Val Acc: 0.701031\n",
      "Epoch 8385 - Train Loss: 0.141282, Train Acc: 0.743590 | Val Loss: 0.155109, Val Acc: 0.701031\n",
      "Epoch 8386 - Train Loss: 0.141272, Train Acc: 0.743590 | Val Loss: 0.155101, Val Acc: 0.701031\n",
      "Epoch 8387 - Train Loss: 0.141262, Train Acc: 0.743590 | Val Loss: 0.155092, Val Acc: 0.701031\n",
      "Epoch 8388 - Train Loss: 0.141252, Train Acc: 0.743590 | Val Loss: 0.155083, Val Acc: 0.701031\n",
      "Epoch 8389 - Train Loss: 0.141242, Train Acc: 0.743590 | Val Loss: 0.155074, Val Acc: 0.701031\n",
      "Epoch 8390 - Train Loss: 0.141232, Train Acc: 0.743590 | Val Loss: 0.155066, Val Acc: 0.701031\n",
      "Epoch 8391 - Train Loss: 0.141222, Train Acc: 0.743590 | Val Loss: 0.155057, Val Acc: 0.701031\n",
      "Epoch 8392 - Train Loss: 0.141212, Train Acc: 0.743590 | Val Loss: 0.155048, Val Acc: 0.701031\n",
      "Epoch 8393 - Train Loss: 0.141202, Train Acc: 0.743590 | Val Loss: 0.155039, Val Acc: 0.701031\n",
      "Epoch 8394 - Train Loss: 0.141191, Train Acc: 0.743590 | Val Loss: 0.155031, Val Acc: 0.701031\n",
      "Epoch 8395 - Train Loss: 0.141181, Train Acc: 0.743590 | Val Loss: 0.155022, Val Acc: 0.701031\n",
      "Epoch 8396 - Train Loss: 0.141171, Train Acc: 0.743590 | Val Loss: 0.155013, Val Acc: 0.701031\n",
      "Epoch 8397 - Train Loss: 0.141161, Train Acc: 0.743590 | Val Loss: 0.155005, Val Acc: 0.701031\n",
      "Epoch 8398 - Train Loss: 0.141151, Train Acc: 0.744872 | Val Loss: 0.154996, Val Acc: 0.701031\n",
      "Epoch 8399 - Train Loss: 0.141141, Train Acc: 0.744872 | Val Loss: 0.154987, Val Acc: 0.701031\n",
      "Epoch 8400 - Train Loss: 0.141131, Train Acc: 0.744872 | Val Loss: 0.154978, Val Acc: 0.701031\n",
      "Epoch 8401 - Train Loss: 0.141121, Train Acc: 0.744872 | Val Loss: 0.154970, Val Acc: 0.701031\n",
      "Epoch 8402 - Train Loss: 0.141111, Train Acc: 0.744872 | Val Loss: 0.154961, Val Acc: 0.701031\n",
      "Epoch 8403 - Train Loss: 0.141101, Train Acc: 0.744872 | Val Loss: 0.154952, Val Acc: 0.701031\n",
      "Epoch 8404 - Train Loss: 0.141091, Train Acc: 0.744872 | Val Loss: 0.154943, Val Acc: 0.701031\n",
      "Epoch 8405 - Train Loss: 0.141080, Train Acc: 0.744872 | Val Loss: 0.154934, Val Acc: 0.701031\n",
      "Epoch 8406 - Train Loss: 0.141070, Train Acc: 0.744872 | Val Loss: 0.154926, Val Acc: 0.701031\n",
      "Epoch 8407 - Train Loss: 0.141060, Train Acc: 0.744872 | Val Loss: 0.154917, Val Acc: 0.701031\n",
      "Epoch 8408 - Train Loss: 0.141050, Train Acc: 0.744872 | Val Loss: 0.154908, Val Acc: 0.701031\n",
      "Epoch 8409 - Train Loss: 0.141040, Train Acc: 0.744872 | Val Loss: 0.154899, Val Acc: 0.701031\n",
      "Epoch 8410 - Train Loss: 0.141030, Train Acc: 0.744872 | Val Loss: 0.154890, Val Acc: 0.701031\n",
      "Epoch 8411 - Train Loss: 0.141020, Train Acc: 0.744872 | Val Loss: 0.154882, Val Acc: 0.701031\n",
      "Epoch 8412 - Train Loss: 0.141010, Train Acc: 0.744872 | Val Loss: 0.154873, Val Acc: 0.701031\n",
      "Epoch 8413 - Train Loss: 0.141000, Train Acc: 0.744872 | Val Loss: 0.154864, Val Acc: 0.701031\n",
      "Epoch 8414 - Train Loss: 0.140990, Train Acc: 0.744872 | Val Loss: 0.154855, Val Acc: 0.701031\n",
      "Epoch 8415 - Train Loss: 0.140980, Train Acc: 0.744872 | Val Loss: 0.154847, Val Acc: 0.701031\n",
      "Epoch 8416 - Train Loss: 0.140970, Train Acc: 0.744872 | Val Loss: 0.154838, Val Acc: 0.701031\n",
      "Epoch 8417 - Train Loss: 0.140960, Train Acc: 0.744872 | Val Loss: 0.154829, Val Acc: 0.701031\n",
      "Epoch 8418 - Train Loss: 0.140950, Train Acc: 0.744872 | Val Loss: 0.154820, Val Acc: 0.701031\n",
      "Epoch 8419 - Train Loss: 0.140940, Train Acc: 0.744872 | Val Loss: 0.154812, Val Acc: 0.701031\n",
      "Epoch 8420 - Train Loss: 0.140929, Train Acc: 0.744872 | Val Loss: 0.154803, Val Acc: 0.701031\n",
      "Epoch 8421 - Train Loss: 0.140919, Train Acc: 0.744872 | Val Loss: 0.154794, Val Acc: 0.701031\n",
      "Epoch 8422 - Train Loss: 0.140909, Train Acc: 0.744872 | Val Loss: 0.154785, Val Acc: 0.701031\n",
      "Epoch 8423 - Train Loss: 0.140899, Train Acc: 0.744872 | Val Loss: 0.154777, Val Acc: 0.701031\n",
      "Epoch 8424 - Train Loss: 0.140889, Train Acc: 0.744872 | Val Loss: 0.154768, Val Acc: 0.701031\n",
      "Epoch 8425 - Train Loss: 0.140879, Train Acc: 0.744872 | Val Loss: 0.154759, Val Acc: 0.701031\n",
      "Epoch 8426 - Train Loss: 0.140869, Train Acc: 0.744872 | Val Loss: 0.154750, Val Acc: 0.701031\n",
      "Epoch 8427 - Train Loss: 0.140859, Train Acc: 0.744872 | Val Loss: 0.154742, Val Acc: 0.701031\n",
      "Epoch 8428 - Train Loss: 0.140849, Train Acc: 0.744872 | Val Loss: 0.154733, Val Acc: 0.701031\n",
      "Epoch 8429 - Train Loss: 0.140839, Train Acc: 0.744872 | Val Loss: 0.154724, Val Acc: 0.701031\n",
      "Epoch 8430 - Train Loss: 0.140829, Train Acc: 0.744872 | Val Loss: 0.154715, Val Acc: 0.701031\n",
      "Epoch 8431 - Train Loss: 0.140819, Train Acc: 0.744872 | Val Loss: 0.154707, Val Acc: 0.701031\n",
      "Epoch 8432 - Train Loss: 0.140809, Train Acc: 0.744872 | Val Loss: 0.154698, Val Acc: 0.701031\n",
      "Epoch 8433 - Train Loss: 0.140799, Train Acc: 0.744872 | Val Loss: 0.154689, Val Acc: 0.701031\n",
      "Epoch 8434 - Train Loss: 0.140789, Train Acc: 0.744872 | Val Loss: 0.154680, Val Acc: 0.701031\n",
      "Epoch 8435 - Train Loss: 0.140779, Train Acc: 0.744872 | Val Loss: 0.154672, Val Acc: 0.701031\n",
      "Epoch 8436 - Train Loss: 0.140769, Train Acc: 0.744872 | Val Loss: 0.154663, Val Acc: 0.701031\n",
      "Epoch 8437 - Train Loss: 0.140759, Train Acc: 0.744872 | Val Loss: 0.154654, Val Acc: 0.701031\n",
      "Epoch 8438 - Train Loss: 0.140749, Train Acc: 0.744872 | Val Loss: 0.154646, Val Acc: 0.701031\n",
      "Epoch 8439 - Train Loss: 0.140739, Train Acc: 0.744872 | Val Loss: 0.154637, Val Acc: 0.701031\n",
      "Epoch 8440 - Train Loss: 0.140728, Train Acc: 0.744872 | Val Loss: 0.154628, Val Acc: 0.701031\n",
      "Epoch 8441 - Train Loss: 0.140718, Train Acc: 0.744872 | Val Loss: 0.154620, Val Acc: 0.701031\n",
      "Epoch 8442 - Train Loss: 0.140708, Train Acc: 0.746154 | Val Loss: 0.154611, Val Acc: 0.701031\n",
      "Epoch 8443 - Train Loss: 0.140698, Train Acc: 0.746154 | Val Loss: 0.154602, Val Acc: 0.701031\n",
      "Epoch 8444 - Train Loss: 0.140688, Train Acc: 0.746154 | Val Loss: 0.154593, Val Acc: 0.701031\n",
      "Epoch 8445 - Train Loss: 0.140678, Train Acc: 0.746154 | Val Loss: 0.154585, Val Acc: 0.701031\n",
      "Epoch 8446 - Train Loss: 0.140668, Train Acc: 0.746154 | Val Loss: 0.154576, Val Acc: 0.701031\n",
      "Epoch 8447 - Train Loss: 0.140658, Train Acc: 0.746154 | Val Loss: 0.154567, Val Acc: 0.701031\n",
      "Epoch 8448 - Train Loss: 0.140648, Train Acc: 0.746154 | Val Loss: 0.154559, Val Acc: 0.701031\n",
      "Epoch 8449 - Train Loss: 0.140638, Train Acc: 0.746154 | Val Loss: 0.154550, Val Acc: 0.701031\n",
      "Epoch 8450 - Train Loss: 0.140628, Train Acc: 0.746154 | Val Loss: 0.154541, Val Acc: 0.701031\n",
      "Epoch 8451 - Train Loss: 0.140618, Train Acc: 0.746154 | Val Loss: 0.154533, Val Acc: 0.701031\n",
      "Epoch 8452 - Train Loss: 0.140608, Train Acc: 0.746154 | Val Loss: 0.154524, Val Acc: 0.701031\n",
      "Epoch 8453 - Train Loss: 0.140598, Train Acc: 0.746154 | Val Loss: 0.154515, Val Acc: 0.701031\n",
      "Epoch 8454 - Train Loss: 0.140588, Train Acc: 0.746154 | Val Loss: 0.154507, Val Acc: 0.701031\n",
      "Epoch 8455 - Train Loss: 0.140578, Train Acc: 0.746154 | Val Loss: 0.154498, Val Acc: 0.701031\n",
      "Epoch 8456 - Train Loss: 0.140568, Train Acc: 0.746154 | Val Loss: 0.154489, Val Acc: 0.701031\n",
      "Epoch 8457 - Train Loss: 0.140558, Train Acc: 0.746154 | Val Loss: 0.154481, Val Acc: 0.701031\n",
      "Epoch 8458 - Train Loss: 0.140548, Train Acc: 0.746154 | Val Loss: 0.154472, Val Acc: 0.701031\n",
      "Epoch 8459 - Train Loss: 0.140538, Train Acc: 0.746154 | Val Loss: 0.154463, Val Acc: 0.701031\n",
      "Epoch 8460 - Train Loss: 0.140528, Train Acc: 0.746154 | Val Loss: 0.154455, Val Acc: 0.701031\n",
      "Epoch 8461 - Train Loss: 0.140518, Train Acc: 0.746154 | Val Loss: 0.154446, Val Acc: 0.701031\n",
      "Epoch 8462 - Train Loss: 0.140508, Train Acc: 0.746154 | Val Loss: 0.154437, Val Acc: 0.701031\n",
      "Epoch 8463 - Train Loss: 0.140498, Train Acc: 0.746154 | Val Loss: 0.154429, Val Acc: 0.701031\n",
      "Epoch 8464 - Train Loss: 0.140488, Train Acc: 0.746154 | Val Loss: 0.154420, Val Acc: 0.701031\n",
      "Epoch 8465 - Train Loss: 0.140478, Train Acc: 0.746154 | Val Loss: 0.154411, Val Acc: 0.701031\n",
      "Epoch 8466 - Train Loss: 0.140468, Train Acc: 0.746154 | Val Loss: 0.154403, Val Acc: 0.701031\n",
      "Epoch 8467 - Train Loss: 0.140458, Train Acc: 0.746154 | Val Loss: 0.154394, Val Acc: 0.701031\n",
      "Epoch 8468 - Train Loss: 0.140448, Train Acc: 0.746154 | Val Loss: 0.154385, Val Acc: 0.701031\n",
      "Epoch 8469 - Train Loss: 0.140438, Train Acc: 0.746154 | Val Loss: 0.154377, Val Acc: 0.701031\n",
      "Epoch 8470 - Train Loss: 0.140428, Train Acc: 0.746154 | Val Loss: 0.154368, Val Acc: 0.701031\n",
      "Epoch 8471 - Train Loss: 0.140418, Train Acc: 0.746154 | Val Loss: 0.154359, Val Acc: 0.701031\n",
      "Epoch 8472 - Train Loss: 0.140408, Train Acc: 0.746154 | Val Loss: 0.154351, Val Acc: 0.701031\n",
      "Epoch 8473 - Train Loss: 0.140398, Train Acc: 0.746154 | Val Loss: 0.154342, Val Acc: 0.701031\n",
      "Epoch 8474 - Train Loss: 0.140388, Train Acc: 0.746154 | Val Loss: 0.154333, Val Acc: 0.701031\n",
      "Epoch 8475 - Train Loss: 0.140378, Train Acc: 0.746154 | Val Loss: 0.154325, Val Acc: 0.701031\n",
      "Epoch 8476 - Train Loss: 0.140368, Train Acc: 0.746154 | Val Loss: 0.154316, Val Acc: 0.701031\n",
      "Epoch 8477 - Train Loss: 0.140358, Train Acc: 0.746154 | Val Loss: 0.154308, Val Acc: 0.701031\n",
      "Epoch 8478 - Train Loss: 0.140348, Train Acc: 0.746154 | Val Loss: 0.154299, Val Acc: 0.701031\n",
      "Epoch 8479 - Train Loss: 0.140338, Train Acc: 0.746154 | Val Loss: 0.154290, Val Acc: 0.701031\n",
      "Epoch 8480 - Train Loss: 0.140328, Train Acc: 0.746154 | Val Loss: 0.154282, Val Acc: 0.701031\n",
      "Epoch 8481 - Train Loss: 0.140318, Train Acc: 0.746154 | Val Loss: 0.154273, Val Acc: 0.701031\n",
      "Epoch 8482 - Train Loss: 0.140308, Train Acc: 0.746154 | Val Loss: 0.154264, Val Acc: 0.701031\n",
      "Epoch 8483 - Train Loss: 0.140298, Train Acc: 0.746154 | Val Loss: 0.154256, Val Acc: 0.701031\n",
      "Epoch 8484 - Train Loss: 0.140288, Train Acc: 0.746154 | Val Loss: 0.154247, Val Acc: 0.701031\n",
      "Epoch 8485 - Train Loss: 0.140278, Train Acc: 0.746154 | Val Loss: 0.154239, Val Acc: 0.701031\n",
      "Epoch 8486 - Train Loss: 0.140268, Train Acc: 0.746154 | Val Loss: 0.154230, Val Acc: 0.701031\n",
      "Epoch 8487 - Train Loss: 0.140258, Train Acc: 0.747436 | Val Loss: 0.154221, Val Acc: 0.701031\n",
      "Epoch 8488 - Train Loss: 0.140248, Train Acc: 0.747436 | Val Loss: 0.154213, Val Acc: 0.701031\n",
      "Epoch 8489 - Train Loss: 0.140238, Train Acc: 0.747436 | Val Loss: 0.154204, Val Acc: 0.701031\n",
      "Epoch 8490 - Train Loss: 0.140228, Train Acc: 0.747436 | Val Loss: 0.154195, Val Acc: 0.701031\n",
      "Epoch 8491 - Train Loss: 0.140218, Train Acc: 0.747436 | Val Loss: 0.154187, Val Acc: 0.701031\n",
      "Epoch 8492 - Train Loss: 0.140208, Train Acc: 0.747436 | Val Loss: 0.154178, Val Acc: 0.701031\n",
      "Epoch 8493 - Train Loss: 0.140198, Train Acc: 0.747436 | Val Loss: 0.154170, Val Acc: 0.701031\n",
      "Epoch 8494 - Train Loss: 0.140188, Train Acc: 0.747436 | Val Loss: 0.154161, Val Acc: 0.701031\n",
      "Epoch 8495 - Train Loss: 0.140178, Train Acc: 0.747436 | Val Loss: 0.154152, Val Acc: 0.701031\n",
      "Epoch 8496 - Train Loss: 0.140168, Train Acc: 0.747436 | Val Loss: 0.154144, Val Acc: 0.701031\n",
      "Epoch 8497 - Train Loss: 0.140158, Train Acc: 0.747436 | Val Loss: 0.154135, Val Acc: 0.701031\n",
      "Epoch 8498 - Train Loss: 0.140148, Train Acc: 0.747436 | Val Loss: 0.154127, Val Acc: 0.701031\n",
      "Epoch 8499 - Train Loss: 0.140138, Train Acc: 0.747436 | Val Loss: 0.154118, Val Acc: 0.701031\n",
      "Epoch 8500 - Train Loss: 0.140128, Train Acc: 0.747436 | Val Loss: 0.154109, Val Acc: 0.701031\n",
      "Epoch 8501 - Train Loss: 0.140118, Train Acc: 0.747436 | Val Loss: 0.154101, Val Acc: 0.701031\n",
      "Epoch 8502 - Train Loss: 0.140108, Train Acc: 0.748718 | Val Loss: 0.154092, Val Acc: 0.701031\n",
      "Epoch 8503 - Train Loss: 0.140098, Train Acc: 0.748718 | Val Loss: 0.154084, Val Acc: 0.701031\n",
      "Epoch 8504 - Train Loss: 0.140088, Train Acc: 0.748718 | Val Loss: 0.154075, Val Acc: 0.701031\n",
      "Epoch 8505 - Train Loss: 0.140078, Train Acc: 0.748718 | Val Loss: 0.154066, Val Acc: 0.701031\n",
      "Epoch 8506 - Train Loss: 0.140068, Train Acc: 0.748718 | Val Loss: 0.154058, Val Acc: 0.701031\n",
      "Epoch 8507 - Train Loss: 0.140059, Train Acc: 0.748718 | Val Loss: 0.154049, Val Acc: 0.701031\n",
      "Epoch 8508 - Train Loss: 0.140049, Train Acc: 0.748718 | Val Loss: 0.154041, Val Acc: 0.701031\n",
      "Epoch 8509 - Train Loss: 0.140039, Train Acc: 0.748718 | Val Loss: 0.154032, Val Acc: 0.701031\n",
      "Epoch 8510 - Train Loss: 0.140029, Train Acc: 0.748718 | Val Loss: 0.154023, Val Acc: 0.701031\n",
      "Epoch 8511 - Train Loss: 0.140019, Train Acc: 0.748718 | Val Loss: 0.154015, Val Acc: 0.701031\n",
      "Epoch 8512 - Train Loss: 0.140009, Train Acc: 0.748718 | Val Loss: 0.154006, Val Acc: 0.701031\n",
      "Epoch 8513 - Train Loss: 0.139999, Train Acc: 0.748718 | Val Loss: 0.153997, Val Acc: 0.701031\n",
      "Epoch 8514 - Train Loss: 0.139989, Train Acc: 0.748718 | Val Loss: 0.153989, Val Acc: 0.701031\n",
      "Epoch 8515 - Train Loss: 0.139979, Train Acc: 0.748718 | Val Loss: 0.153980, Val Acc: 0.701031\n",
      "Epoch 8516 - Train Loss: 0.139969, Train Acc: 0.748718 | Val Loss: 0.153971, Val Acc: 0.701031\n",
      "Epoch 8517 - Train Loss: 0.139959, Train Acc: 0.748718 | Val Loss: 0.153963, Val Acc: 0.701031\n",
      "Epoch 8518 - Train Loss: 0.139949, Train Acc: 0.748718 | Val Loss: 0.153954, Val Acc: 0.701031\n",
      "Epoch 8519 - Train Loss: 0.139939, Train Acc: 0.748718 | Val Loss: 0.153945, Val Acc: 0.701031\n",
      "Epoch 8520 - Train Loss: 0.139929, Train Acc: 0.748718 | Val Loss: 0.153937, Val Acc: 0.701031\n",
      "Epoch 8521 - Train Loss: 0.139919, Train Acc: 0.748718 | Val Loss: 0.153928, Val Acc: 0.701031\n",
      "Epoch 8522 - Train Loss: 0.139909, Train Acc: 0.748718 | Val Loss: 0.153920, Val Acc: 0.701031\n",
      "Epoch 8523 - Train Loss: 0.139899, Train Acc: 0.748718 | Val Loss: 0.153911, Val Acc: 0.701031\n",
      "Epoch 8524 - Train Loss: 0.139889, Train Acc: 0.748718 | Val Loss: 0.153902, Val Acc: 0.701031\n",
      "Epoch 8525 - Train Loss: 0.139879, Train Acc: 0.748718 | Val Loss: 0.153894, Val Acc: 0.701031\n",
      "Epoch 8526 - Train Loss: 0.139870, Train Acc: 0.748718 | Val Loss: 0.153885, Val Acc: 0.701031\n",
      "Epoch 8527 - Train Loss: 0.139860, Train Acc: 0.748718 | Val Loss: 0.153876, Val Acc: 0.701031\n",
      "Epoch 8528 - Train Loss: 0.139850, Train Acc: 0.750000 | Val Loss: 0.153868, Val Acc: 0.701031\n",
      "Epoch 8529 - Train Loss: 0.139840, Train Acc: 0.750000 | Val Loss: 0.153859, Val Acc: 0.701031\n",
      "Epoch 8530 - Train Loss: 0.139830, Train Acc: 0.750000 | Val Loss: 0.153851, Val Acc: 0.701031\n",
      "Epoch 8531 - Train Loss: 0.139820, Train Acc: 0.750000 | Val Loss: 0.153842, Val Acc: 0.701031\n",
      "Epoch 8532 - Train Loss: 0.139810, Train Acc: 0.750000 | Val Loss: 0.153833, Val Acc: 0.701031\n",
      "Epoch 8533 - Train Loss: 0.139800, Train Acc: 0.750000 | Val Loss: 0.153825, Val Acc: 0.701031\n",
      "Epoch 8534 - Train Loss: 0.139790, Train Acc: 0.750000 | Val Loss: 0.153816, Val Acc: 0.701031\n",
      "Epoch 8535 - Train Loss: 0.139780, Train Acc: 0.750000 | Val Loss: 0.153807, Val Acc: 0.701031\n",
      "Epoch 8536 - Train Loss: 0.139770, Train Acc: 0.750000 | Val Loss: 0.153799, Val Acc: 0.701031\n",
      "Epoch 8537 - Train Loss: 0.139760, Train Acc: 0.750000 | Val Loss: 0.153790, Val Acc: 0.701031\n",
      "Epoch 8538 - Train Loss: 0.139750, Train Acc: 0.750000 | Val Loss: 0.153782, Val Acc: 0.701031\n",
      "Epoch 8539 - Train Loss: 0.139741, Train Acc: 0.750000 | Val Loss: 0.153773, Val Acc: 0.701031\n",
      "Epoch 8540 - Train Loss: 0.139731, Train Acc: 0.750000 | Val Loss: 0.153765, Val Acc: 0.701031\n",
      "Epoch 8541 - Train Loss: 0.139721, Train Acc: 0.750000 | Val Loss: 0.153756, Val Acc: 0.701031\n",
      "Epoch 8542 - Train Loss: 0.139711, Train Acc: 0.750000 | Val Loss: 0.153747, Val Acc: 0.701031\n",
      "Epoch 8543 - Train Loss: 0.139701, Train Acc: 0.750000 | Val Loss: 0.153739, Val Acc: 0.701031\n",
      "Epoch 8544 - Train Loss: 0.139691, Train Acc: 0.750000 | Val Loss: 0.153730, Val Acc: 0.701031\n",
      "Epoch 8545 - Train Loss: 0.139681, Train Acc: 0.750000 | Val Loss: 0.153722, Val Acc: 0.701031\n",
      "Epoch 8546 - Train Loss: 0.139671, Train Acc: 0.750000 | Val Loss: 0.153713, Val Acc: 0.701031\n",
      "Epoch 8547 - Train Loss: 0.139661, Train Acc: 0.750000 | Val Loss: 0.153704, Val Acc: 0.701031\n",
      "Epoch 8548 - Train Loss: 0.139651, Train Acc: 0.750000 | Val Loss: 0.153696, Val Acc: 0.701031\n",
      "Epoch 8549 - Train Loss: 0.139641, Train Acc: 0.750000 | Val Loss: 0.153687, Val Acc: 0.701031\n",
      "Epoch 8550 - Train Loss: 0.139631, Train Acc: 0.750000 | Val Loss: 0.153679, Val Acc: 0.701031\n",
      "Epoch 8551 - Train Loss: 0.139622, Train Acc: 0.750000 | Val Loss: 0.153670, Val Acc: 0.701031\n",
      "Epoch 8552 - Train Loss: 0.139612, Train Acc: 0.750000 | Val Loss: 0.153662, Val Acc: 0.701031\n",
      "Epoch 8553 - Train Loss: 0.139602, Train Acc: 0.750000 | Val Loss: 0.153653, Val Acc: 0.701031\n",
      "Epoch 8554 - Train Loss: 0.139592, Train Acc: 0.750000 | Val Loss: 0.153644, Val Acc: 0.701031\n",
      "Epoch 8555 - Train Loss: 0.139582, Train Acc: 0.750000 | Val Loss: 0.153636, Val Acc: 0.701031\n",
      "Epoch 8556 - Train Loss: 0.139572, Train Acc: 0.750000 | Val Loss: 0.153627, Val Acc: 0.701031\n",
      "Epoch 8557 - Train Loss: 0.139562, Train Acc: 0.750000 | Val Loss: 0.153619, Val Acc: 0.701031\n",
      "Epoch 8558 - Train Loss: 0.139552, Train Acc: 0.750000 | Val Loss: 0.153610, Val Acc: 0.701031\n",
      "Epoch 8559 - Train Loss: 0.139542, Train Acc: 0.750000 | Val Loss: 0.153602, Val Acc: 0.701031\n",
      "Epoch 8560 - Train Loss: 0.139532, Train Acc: 0.750000 | Val Loss: 0.153593, Val Acc: 0.701031\n",
      "Epoch 8561 - Train Loss: 0.139523, Train Acc: 0.750000 | Val Loss: 0.153585, Val Acc: 0.701031\n",
      "Epoch 8562 - Train Loss: 0.139513, Train Acc: 0.750000 | Val Loss: 0.153576, Val Acc: 0.701031\n",
      "Epoch 8563 - Train Loss: 0.139503, Train Acc: 0.750000 | Val Loss: 0.153568, Val Acc: 0.701031\n",
      "Epoch 8564 - Train Loss: 0.139493, Train Acc: 0.750000 | Val Loss: 0.153559, Val Acc: 0.701031\n",
      "Epoch 8565 - Train Loss: 0.139483, Train Acc: 0.750000 | Val Loss: 0.153550, Val Acc: 0.701031\n",
      "Epoch 8566 - Train Loss: 0.139473, Train Acc: 0.750000 | Val Loss: 0.153542, Val Acc: 0.701031\n",
      "Epoch 8567 - Train Loss: 0.139463, Train Acc: 0.750000 | Val Loss: 0.153533, Val Acc: 0.701031\n",
      "Epoch 8568 - Train Loss: 0.139453, Train Acc: 0.750000 | Val Loss: 0.153525, Val Acc: 0.701031\n",
      "Epoch 8569 - Train Loss: 0.139443, Train Acc: 0.750000 | Val Loss: 0.153516, Val Acc: 0.701031\n",
      "Epoch 8570 - Train Loss: 0.139434, Train Acc: 0.750000 | Val Loss: 0.153508, Val Acc: 0.701031\n",
      "Epoch 8571 - Train Loss: 0.139424, Train Acc: 0.750000 | Val Loss: 0.153499, Val Acc: 0.701031\n",
      "Epoch 8572 - Train Loss: 0.139414, Train Acc: 0.750000 | Val Loss: 0.153491, Val Acc: 0.701031\n",
      "Epoch 8573 - Train Loss: 0.139404, Train Acc: 0.750000 | Val Loss: 0.153482, Val Acc: 0.701031\n",
      "Epoch 8574 - Train Loss: 0.139394, Train Acc: 0.750000 | Val Loss: 0.153474, Val Acc: 0.701031\n",
      "Epoch 8575 - Train Loss: 0.139384, Train Acc: 0.750000 | Val Loss: 0.153465, Val Acc: 0.701031\n",
      "Epoch 8576 - Train Loss: 0.139374, Train Acc: 0.750000 | Val Loss: 0.153457, Val Acc: 0.701031\n",
      "Epoch 8577 - Train Loss: 0.139364, Train Acc: 0.750000 | Val Loss: 0.153448, Val Acc: 0.701031\n",
      "Epoch 8578 - Train Loss: 0.139355, Train Acc: 0.750000 | Val Loss: 0.153440, Val Acc: 0.701031\n",
      "Epoch 8579 - Train Loss: 0.139345, Train Acc: 0.750000 | Val Loss: 0.153431, Val Acc: 0.701031\n",
      "Epoch 8580 - Train Loss: 0.139335, Train Acc: 0.750000 | Val Loss: 0.153423, Val Acc: 0.701031\n",
      "Epoch 8581 - Train Loss: 0.139325, Train Acc: 0.750000 | Val Loss: 0.153414, Val Acc: 0.701031\n",
      "Epoch 8582 - Train Loss: 0.139315, Train Acc: 0.750000 | Val Loss: 0.153406, Val Acc: 0.701031\n",
      "Epoch 8583 - Train Loss: 0.139305, Train Acc: 0.750000 | Val Loss: 0.153397, Val Acc: 0.701031\n",
      "Epoch 8584 - Train Loss: 0.139295, Train Acc: 0.750000 | Val Loss: 0.153389, Val Acc: 0.701031\n",
      "Epoch 8585 - Train Loss: 0.139285, Train Acc: 0.750000 | Val Loss: 0.153380, Val Acc: 0.701031\n",
      "Epoch 8586 - Train Loss: 0.139276, Train Acc: 0.750000 | Val Loss: 0.153372, Val Acc: 0.701031\n",
      "Epoch 8587 - Train Loss: 0.139266, Train Acc: 0.750000 | Val Loss: 0.153363, Val Acc: 0.701031\n",
      "Epoch 8588 - Train Loss: 0.139256, Train Acc: 0.750000 | Val Loss: 0.153355, Val Acc: 0.701031\n",
      "Epoch 8589 - Train Loss: 0.139246, Train Acc: 0.750000 | Val Loss: 0.153346, Val Acc: 0.701031\n",
      "Epoch 8590 - Train Loss: 0.139236, Train Acc: 0.750000 | Val Loss: 0.153338, Val Acc: 0.701031\n",
      "Epoch 8591 - Train Loss: 0.139226, Train Acc: 0.750000 | Val Loss: 0.153329, Val Acc: 0.701031\n",
      "Epoch 8592 - Train Loss: 0.139216, Train Acc: 0.750000 | Val Loss: 0.153321, Val Acc: 0.701031\n",
      "Epoch 8593 - Train Loss: 0.139207, Train Acc: 0.750000 | Val Loss: 0.153312, Val Acc: 0.701031\n",
      "Epoch 8594 - Train Loss: 0.139197, Train Acc: 0.750000 | Val Loss: 0.153304, Val Acc: 0.701031\n",
      "Epoch 8595 - Train Loss: 0.139187, Train Acc: 0.750000 | Val Loss: 0.153295, Val Acc: 0.701031\n",
      "Epoch 8596 - Train Loss: 0.139177, Train Acc: 0.750000 | Val Loss: 0.153287, Val Acc: 0.701031\n",
      "Epoch 8597 - Train Loss: 0.139167, Train Acc: 0.750000 | Val Loss: 0.153278, Val Acc: 0.701031\n",
      "Epoch 8598 - Train Loss: 0.139157, Train Acc: 0.750000 | Val Loss: 0.153270, Val Acc: 0.701031\n",
      "Epoch 8599 - Train Loss: 0.139147, Train Acc: 0.750000 | Val Loss: 0.153261, Val Acc: 0.701031\n",
      "Epoch 8600 - Train Loss: 0.139138, Train Acc: 0.750000 | Val Loss: 0.153253, Val Acc: 0.701031\n",
      "Epoch 8601 - Train Loss: 0.139128, Train Acc: 0.750000 | Val Loss: 0.153244, Val Acc: 0.701031\n",
      "Epoch 8602 - Train Loss: 0.139118, Train Acc: 0.750000 | Val Loss: 0.153236, Val Acc: 0.701031\n",
      "Epoch 8603 - Train Loss: 0.139108, Train Acc: 0.750000 | Val Loss: 0.153227, Val Acc: 0.701031\n",
      "Epoch 8604 - Train Loss: 0.139098, Train Acc: 0.750000 | Val Loss: 0.153219, Val Acc: 0.701031\n",
      "Epoch 8605 - Train Loss: 0.139088, Train Acc: 0.750000 | Val Loss: 0.153210, Val Acc: 0.701031\n",
      "Epoch 8606 - Train Loss: 0.139078, Train Acc: 0.750000 | Val Loss: 0.153202, Val Acc: 0.701031\n",
      "Epoch 8607 - Train Loss: 0.139069, Train Acc: 0.750000 | Val Loss: 0.153193, Val Acc: 0.701031\n",
      "Epoch 8608 - Train Loss: 0.139059, Train Acc: 0.750000 | Val Loss: 0.153185, Val Acc: 0.701031\n",
      "Epoch 8609 - Train Loss: 0.139049, Train Acc: 0.750000 | Val Loss: 0.153177, Val Acc: 0.701031\n",
      "Epoch 8610 - Train Loss: 0.139039, Train Acc: 0.750000 | Val Loss: 0.153168, Val Acc: 0.701031\n",
      "Epoch 8611 - Train Loss: 0.139029, Train Acc: 0.750000 | Val Loss: 0.153160, Val Acc: 0.701031\n",
      "Epoch 8612 - Train Loss: 0.139019, Train Acc: 0.750000 | Val Loss: 0.153151, Val Acc: 0.701031\n",
      "Epoch 8613 - Train Loss: 0.139010, Train Acc: 0.750000 | Val Loss: 0.153143, Val Acc: 0.701031\n",
      "Epoch 8614 - Train Loss: 0.139000, Train Acc: 0.750000 | Val Loss: 0.153134, Val Acc: 0.701031\n",
      "Epoch 8615 - Train Loss: 0.138990, Train Acc: 0.750000 | Val Loss: 0.153126, Val Acc: 0.701031\n",
      "Epoch 8616 - Train Loss: 0.138980, Train Acc: 0.750000 | Val Loss: 0.153117, Val Acc: 0.701031\n",
      "Epoch 8617 - Train Loss: 0.138970, Train Acc: 0.750000 | Val Loss: 0.153109, Val Acc: 0.701031\n",
      "Epoch 8618 - Train Loss: 0.138960, Train Acc: 0.750000 | Val Loss: 0.153100, Val Acc: 0.701031\n",
      "Epoch 8619 - Train Loss: 0.138951, Train Acc: 0.750000 | Val Loss: 0.153092, Val Acc: 0.701031\n",
      "Epoch 8620 - Train Loss: 0.138941, Train Acc: 0.750000 | Val Loss: 0.153084, Val Acc: 0.701031\n",
      "Epoch 8621 - Train Loss: 0.138931, Train Acc: 0.750000 | Val Loss: 0.153075, Val Acc: 0.701031\n",
      "Epoch 8622 - Train Loss: 0.138921, Train Acc: 0.750000 | Val Loss: 0.153067, Val Acc: 0.701031\n",
      "Epoch 8623 - Train Loss: 0.138911, Train Acc: 0.750000 | Val Loss: 0.153058, Val Acc: 0.701031\n",
      "Epoch 8624 - Train Loss: 0.138901, Train Acc: 0.750000 | Val Loss: 0.153050, Val Acc: 0.701031\n",
      "Epoch 8625 - Train Loss: 0.138892, Train Acc: 0.750000 | Val Loss: 0.153041, Val Acc: 0.701031\n",
      "Epoch 8626 - Train Loss: 0.138882, Train Acc: 0.751282 | Val Loss: 0.153033, Val Acc: 0.701031\n",
      "Epoch 8627 - Train Loss: 0.138872, Train Acc: 0.751282 | Val Loss: 0.153024, Val Acc: 0.701031\n",
      "Epoch 8628 - Train Loss: 0.138862, Train Acc: 0.751282 | Val Loss: 0.153016, Val Acc: 0.701031\n",
      "Epoch 8629 - Train Loss: 0.138852, Train Acc: 0.751282 | Val Loss: 0.153008, Val Acc: 0.701031\n",
      "Epoch 8630 - Train Loss: 0.138843, Train Acc: 0.751282 | Val Loss: 0.152999, Val Acc: 0.701031\n",
      "Epoch 8631 - Train Loss: 0.138833, Train Acc: 0.751282 | Val Loss: 0.152991, Val Acc: 0.701031\n",
      "Epoch 8632 - Train Loss: 0.138823, Train Acc: 0.751282 | Val Loss: 0.152982, Val Acc: 0.701031\n",
      "Epoch 8633 - Train Loss: 0.138813, Train Acc: 0.751282 | Val Loss: 0.152974, Val Acc: 0.701031\n",
      "Epoch 8634 - Train Loss: 0.138803, Train Acc: 0.751282 | Val Loss: 0.152965, Val Acc: 0.701031\n",
      "Epoch 8635 - Train Loss: 0.138793, Train Acc: 0.751282 | Val Loss: 0.152957, Val Acc: 0.701031\n",
      "Epoch 8636 - Train Loss: 0.138784, Train Acc: 0.751282 | Val Loss: 0.152949, Val Acc: 0.701031\n",
      "Epoch 8637 - Train Loss: 0.138774, Train Acc: 0.751282 | Val Loss: 0.152940, Val Acc: 0.701031\n",
      "Epoch 8638 - Train Loss: 0.138764, Train Acc: 0.751282 | Val Loss: 0.152932, Val Acc: 0.701031\n",
      "Epoch 8639 - Train Loss: 0.138754, Train Acc: 0.751282 | Val Loss: 0.152923, Val Acc: 0.701031\n",
      "Epoch 8640 - Train Loss: 0.138744, Train Acc: 0.751282 | Val Loss: 0.152915, Val Acc: 0.701031\n",
      "Epoch 8641 - Train Loss: 0.138735, Train Acc: 0.751282 | Val Loss: 0.152907, Val Acc: 0.701031\n",
      "Epoch 8642 - Train Loss: 0.138725, Train Acc: 0.751282 | Val Loss: 0.152898, Val Acc: 0.701031\n",
      "Epoch 8643 - Train Loss: 0.138715, Train Acc: 0.752564 | Val Loss: 0.152890, Val Acc: 0.701031\n",
      "Epoch 8644 - Train Loss: 0.138705, Train Acc: 0.752564 | Val Loss: 0.152881, Val Acc: 0.701031\n",
      "Epoch 8645 - Train Loss: 0.138695, Train Acc: 0.752564 | Val Loss: 0.152873, Val Acc: 0.701031\n",
      "Epoch 8646 - Train Loss: 0.138686, Train Acc: 0.752564 | Val Loss: 0.152864, Val Acc: 0.701031\n",
      "Epoch 8647 - Train Loss: 0.138676, Train Acc: 0.752564 | Val Loss: 0.152856, Val Acc: 0.701031\n",
      "Epoch 8648 - Train Loss: 0.138666, Train Acc: 0.752564 | Val Loss: 0.152848, Val Acc: 0.701031\n",
      "Epoch 8649 - Train Loss: 0.138656, Train Acc: 0.752564 | Val Loss: 0.152839, Val Acc: 0.701031\n",
      "Epoch 8650 - Train Loss: 0.138646, Train Acc: 0.752564 | Val Loss: 0.152831, Val Acc: 0.701031\n",
      "Epoch 8651 - Train Loss: 0.138637, Train Acc: 0.752564 | Val Loss: 0.152822, Val Acc: 0.701031\n",
      "Epoch 8652 - Train Loss: 0.138627, Train Acc: 0.752564 | Val Loss: 0.152814, Val Acc: 0.701031\n",
      "Epoch 8653 - Train Loss: 0.138617, Train Acc: 0.752564 | Val Loss: 0.152806, Val Acc: 0.701031\n",
      "Epoch 8654 - Train Loss: 0.138607, Train Acc: 0.752564 | Val Loss: 0.152797, Val Acc: 0.701031\n",
      "Epoch 8655 - Train Loss: 0.138597, Train Acc: 0.752564 | Val Loss: 0.152789, Val Acc: 0.701031\n",
      "Epoch 8656 - Train Loss: 0.138588, Train Acc: 0.752564 | Val Loss: 0.152780, Val Acc: 0.701031\n",
      "Epoch 8657 - Train Loss: 0.138578, Train Acc: 0.752564 | Val Loss: 0.152772, Val Acc: 0.701031\n",
      "Epoch 8658 - Train Loss: 0.138568, Train Acc: 0.752564 | Val Loss: 0.152764, Val Acc: 0.701031\n",
      "Epoch 8659 - Train Loss: 0.138558, Train Acc: 0.752564 | Val Loss: 0.152755, Val Acc: 0.701031\n",
      "Epoch 8660 - Train Loss: 0.138549, Train Acc: 0.752564 | Val Loss: 0.152747, Val Acc: 0.701031\n",
      "Epoch 8661 - Train Loss: 0.138539, Train Acc: 0.752564 | Val Loss: 0.152738, Val Acc: 0.701031\n",
      "Epoch 8662 - Train Loss: 0.138529, Train Acc: 0.752564 | Val Loss: 0.152730, Val Acc: 0.701031\n",
      "Epoch 8663 - Train Loss: 0.138519, Train Acc: 0.752564 | Val Loss: 0.152722, Val Acc: 0.701031\n",
      "Epoch 8664 - Train Loss: 0.138509, Train Acc: 0.752564 | Val Loss: 0.152713, Val Acc: 0.701031\n",
      "Epoch 8665 - Train Loss: 0.138500, Train Acc: 0.752564 | Val Loss: 0.152705, Val Acc: 0.701031\n",
      "Epoch 8666 - Train Loss: 0.138490, Train Acc: 0.752564 | Val Loss: 0.152697, Val Acc: 0.701031\n",
      "Epoch 8667 - Train Loss: 0.138480, Train Acc: 0.752564 | Val Loss: 0.152688, Val Acc: 0.701031\n",
      "Epoch 8668 - Train Loss: 0.138470, Train Acc: 0.752564 | Val Loss: 0.152680, Val Acc: 0.701031\n",
      "Epoch 8669 - Train Loss: 0.138461, Train Acc: 0.753846 | Val Loss: 0.152671, Val Acc: 0.701031\n",
      "Epoch 8670 - Train Loss: 0.138451, Train Acc: 0.753846 | Val Loss: 0.152663, Val Acc: 0.701031\n",
      "Epoch 8671 - Train Loss: 0.138441, Train Acc: 0.753846 | Val Loss: 0.152655, Val Acc: 0.701031\n",
      "Epoch 8672 - Train Loss: 0.138431, Train Acc: 0.753846 | Val Loss: 0.152646, Val Acc: 0.701031\n",
      "Epoch 8673 - Train Loss: 0.138421, Train Acc: 0.753846 | Val Loss: 0.152638, Val Acc: 0.701031\n",
      "Epoch 8674 - Train Loss: 0.138412, Train Acc: 0.753846 | Val Loss: 0.152630, Val Acc: 0.701031\n",
      "Epoch 8675 - Train Loss: 0.138402, Train Acc: 0.753846 | Val Loss: 0.152621, Val Acc: 0.701031\n",
      "Epoch 8676 - Train Loss: 0.138392, Train Acc: 0.753846 | Val Loss: 0.152613, Val Acc: 0.701031\n",
      "Epoch 8677 - Train Loss: 0.138382, Train Acc: 0.753846 | Val Loss: 0.152604, Val Acc: 0.701031\n",
      "Epoch 8678 - Train Loss: 0.138373, Train Acc: 0.753846 | Val Loss: 0.152596, Val Acc: 0.701031\n",
      "Epoch 8679 - Train Loss: 0.138363, Train Acc: 0.753846 | Val Loss: 0.152588, Val Acc: 0.701031\n",
      "Epoch 8680 - Train Loss: 0.138353, Train Acc: 0.753846 | Val Loss: 0.152579, Val Acc: 0.701031\n",
      "Epoch 8681 - Train Loss: 0.138343, Train Acc: 0.753846 | Val Loss: 0.152571, Val Acc: 0.701031\n",
      "Epoch 8682 - Train Loss: 0.138334, Train Acc: 0.753846 | Val Loss: 0.152563, Val Acc: 0.701031\n",
      "Epoch 8683 - Train Loss: 0.138324, Train Acc: 0.753846 | Val Loss: 0.152554, Val Acc: 0.701031\n",
      "Epoch 8684 - Train Loss: 0.138314, Train Acc: 0.753846 | Val Loss: 0.152546, Val Acc: 0.701031\n",
      "Epoch 8685 - Train Loss: 0.138304, Train Acc: 0.753846 | Val Loss: 0.152538, Val Acc: 0.701031\n",
      "Epoch 8686 - Train Loss: 0.138295, Train Acc: 0.753846 | Val Loss: 0.152529, Val Acc: 0.701031\n",
      "Epoch 8687 - Train Loss: 0.138285, Train Acc: 0.753846 | Val Loss: 0.152521, Val Acc: 0.701031\n",
      "Epoch 8688 - Train Loss: 0.138275, Train Acc: 0.753846 | Val Loss: 0.152512, Val Acc: 0.701031\n",
      "Epoch 8689 - Train Loss: 0.138265, Train Acc: 0.753846 | Val Loss: 0.152504, Val Acc: 0.701031\n",
      "Epoch 8690 - Train Loss: 0.138256, Train Acc: 0.753846 | Val Loss: 0.152496, Val Acc: 0.701031\n",
      "Epoch 8691 - Train Loss: 0.138246, Train Acc: 0.753846 | Val Loss: 0.152487, Val Acc: 0.701031\n",
      "Epoch 8692 - Train Loss: 0.138236, Train Acc: 0.753846 | Val Loss: 0.152479, Val Acc: 0.701031\n",
      "Epoch 8693 - Train Loss: 0.138226, Train Acc: 0.753846 | Val Loss: 0.152471, Val Acc: 0.701031\n",
      "Epoch 8694 - Train Loss: 0.138217, Train Acc: 0.753846 | Val Loss: 0.152462, Val Acc: 0.701031\n",
      "Epoch 8695 - Train Loss: 0.138207, Train Acc: 0.753846 | Val Loss: 0.152454, Val Acc: 0.701031\n",
      "Epoch 8696 - Train Loss: 0.138197, Train Acc: 0.753846 | Val Loss: 0.152446, Val Acc: 0.701031\n",
      "Epoch 8697 - Train Loss: 0.138187, Train Acc: 0.753846 | Val Loss: 0.152437, Val Acc: 0.701031\n",
      "Epoch 8698 - Train Loss: 0.138178, Train Acc: 0.753846 | Val Loss: 0.152429, Val Acc: 0.701031\n",
      "Epoch 8699 - Train Loss: 0.138168, Train Acc: 0.753846 | Val Loss: 0.152421, Val Acc: 0.701031\n",
      "Epoch 8700 - Train Loss: 0.138158, Train Acc: 0.753846 | Val Loss: 0.152412, Val Acc: 0.701031\n",
      "Epoch 8701 - Train Loss: 0.138148, Train Acc: 0.753846 | Val Loss: 0.152404, Val Acc: 0.701031\n",
      "Epoch 8702 - Train Loss: 0.138139, Train Acc: 0.753846 | Val Loss: 0.152396, Val Acc: 0.701031\n",
      "Epoch 8703 - Train Loss: 0.138129, Train Acc: 0.753846 | Val Loss: 0.152387, Val Acc: 0.701031\n",
      "Epoch 8704 - Train Loss: 0.138119, Train Acc: 0.753846 | Val Loss: 0.152379, Val Acc: 0.701031\n",
      "Epoch 8705 - Train Loss: 0.138109, Train Acc: 0.753846 | Val Loss: 0.152371, Val Acc: 0.701031\n",
      "Epoch 8706 - Train Loss: 0.138100, Train Acc: 0.753846 | Val Loss: 0.152362, Val Acc: 0.701031\n",
      "Epoch 8707 - Train Loss: 0.138090, Train Acc: 0.753846 | Val Loss: 0.152354, Val Acc: 0.701031\n",
      "Epoch 8708 - Train Loss: 0.138080, Train Acc: 0.753846 | Val Loss: 0.152346, Val Acc: 0.701031\n",
      "Epoch 8709 - Train Loss: 0.138070, Train Acc: 0.753846 | Val Loss: 0.152337, Val Acc: 0.701031\n",
      "Epoch 8710 - Train Loss: 0.138061, Train Acc: 0.753846 | Val Loss: 0.152329, Val Acc: 0.701031\n",
      "Epoch 8711 - Train Loss: 0.138051, Train Acc: 0.753846 | Val Loss: 0.152321, Val Acc: 0.701031\n",
      "Epoch 8712 - Train Loss: 0.138041, Train Acc: 0.753846 | Val Loss: 0.152312, Val Acc: 0.701031\n",
      "Epoch 8713 - Train Loss: 0.138032, Train Acc: 0.753846 | Val Loss: 0.152304, Val Acc: 0.701031\n",
      "Epoch 8714 - Train Loss: 0.138022, Train Acc: 0.753846 | Val Loss: 0.152296, Val Acc: 0.701031\n",
      "Epoch 8715 - Train Loss: 0.138012, Train Acc: 0.753846 | Val Loss: 0.152287, Val Acc: 0.701031\n",
      "Epoch 8716 - Train Loss: 0.138002, Train Acc: 0.753846 | Val Loss: 0.152279, Val Acc: 0.701031\n",
      "Epoch 8717 - Train Loss: 0.137993, Train Acc: 0.753846 | Val Loss: 0.152271, Val Acc: 0.701031\n",
      "Epoch 8718 - Train Loss: 0.137983, Train Acc: 0.753846 | Val Loss: 0.152262, Val Acc: 0.701031\n",
      "Epoch 8719 - Train Loss: 0.137973, Train Acc: 0.753846 | Val Loss: 0.152254, Val Acc: 0.701031\n",
      "Epoch 8720 - Train Loss: 0.137964, Train Acc: 0.753846 | Val Loss: 0.152246, Val Acc: 0.701031\n",
      "Epoch 8721 - Train Loss: 0.137954, Train Acc: 0.753846 | Val Loss: 0.152237, Val Acc: 0.701031\n",
      "Epoch 8722 - Train Loss: 0.137944, Train Acc: 0.753846 | Val Loss: 0.152229, Val Acc: 0.701031\n",
      "Epoch 8723 - Train Loss: 0.137934, Train Acc: 0.753846 | Val Loss: 0.152221, Val Acc: 0.701031\n",
      "Epoch 8724 - Train Loss: 0.137925, Train Acc: 0.753846 | Val Loss: 0.152213, Val Acc: 0.701031\n",
      "Epoch 8725 - Train Loss: 0.137915, Train Acc: 0.753846 | Val Loss: 0.152204, Val Acc: 0.701031\n",
      "Epoch 8726 - Train Loss: 0.137905, Train Acc: 0.753846 | Val Loss: 0.152196, Val Acc: 0.701031\n",
      "Epoch 8727 - Train Loss: 0.137896, Train Acc: 0.753846 | Val Loss: 0.152188, Val Acc: 0.701031\n",
      "Epoch 8728 - Train Loss: 0.137886, Train Acc: 0.753846 | Val Loss: 0.152179, Val Acc: 0.701031\n",
      "Epoch 8729 - Train Loss: 0.137876, Train Acc: 0.753846 | Val Loss: 0.152171, Val Acc: 0.701031\n",
      "Epoch 8730 - Train Loss: 0.137866, Train Acc: 0.753846 | Val Loss: 0.152163, Val Acc: 0.701031\n",
      "Epoch 8731 - Train Loss: 0.137857, Train Acc: 0.752564 | Val Loss: 0.152154, Val Acc: 0.701031\n",
      "Epoch 8732 - Train Loss: 0.137847, Train Acc: 0.752564 | Val Loss: 0.152146, Val Acc: 0.701031\n",
      "Epoch 8733 - Train Loss: 0.137837, Train Acc: 0.752564 | Val Loss: 0.152138, Val Acc: 0.701031\n",
      "Epoch 8734 - Train Loss: 0.137828, Train Acc: 0.752564 | Val Loss: 0.152130, Val Acc: 0.701031\n",
      "Epoch 8735 - Train Loss: 0.137818, Train Acc: 0.752564 | Val Loss: 0.152121, Val Acc: 0.701031\n",
      "Epoch 8736 - Train Loss: 0.137808, Train Acc: 0.752564 | Val Loss: 0.152113, Val Acc: 0.701031\n",
      "Epoch 8737 - Train Loss: 0.137799, Train Acc: 0.752564 | Val Loss: 0.152105, Val Acc: 0.701031\n",
      "Epoch 8738 - Train Loss: 0.137789, Train Acc: 0.752564 | Val Loss: 0.152096, Val Acc: 0.701031\n",
      "Epoch 8739 - Train Loss: 0.137779, Train Acc: 0.752564 | Val Loss: 0.152088, Val Acc: 0.701031\n",
      "Epoch 8740 - Train Loss: 0.137769, Train Acc: 0.752564 | Val Loss: 0.152080, Val Acc: 0.701031\n",
      "Epoch 8741 - Train Loss: 0.137760, Train Acc: 0.752564 | Val Loss: 0.152071, Val Acc: 0.701031\n",
      "Epoch 8742 - Train Loss: 0.137750, Train Acc: 0.752564 | Val Loss: 0.152063, Val Acc: 0.701031\n",
      "Epoch 8743 - Train Loss: 0.137740, Train Acc: 0.752564 | Val Loss: 0.152055, Val Acc: 0.701031\n",
      "Epoch 8744 - Train Loss: 0.137731, Train Acc: 0.751282 | Val Loss: 0.152047, Val Acc: 0.701031\n",
      "Epoch 8745 - Train Loss: 0.137721, Train Acc: 0.751282 | Val Loss: 0.152038, Val Acc: 0.701031\n",
      "Epoch 8746 - Train Loss: 0.137711, Train Acc: 0.751282 | Val Loss: 0.152030, Val Acc: 0.701031\n",
      "Epoch 8747 - Train Loss: 0.137702, Train Acc: 0.751282 | Val Loss: 0.152022, Val Acc: 0.701031\n",
      "Epoch 8748 - Train Loss: 0.137692, Train Acc: 0.751282 | Val Loss: 0.152013, Val Acc: 0.701031\n",
      "Epoch 8749 - Train Loss: 0.137682, Train Acc: 0.751282 | Val Loss: 0.152005, Val Acc: 0.701031\n",
      "Epoch 8750 - Train Loss: 0.137673, Train Acc: 0.751282 | Val Loss: 0.151997, Val Acc: 0.701031\n",
      "Epoch 8751 - Train Loss: 0.137663, Train Acc: 0.751282 | Val Loss: 0.151989, Val Acc: 0.701031\n",
      "Epoch 8752 - Train Loss: 0.137653, Train Acc: 0.751282 | Val Loss: 0.151980, Val Acc: 0.701031\n",
      "Epoch 8753 - Train Loss: 0.137643, Train Acc: 0.751282 | Val Loss: 0.151972, Val Acc: 0.701031\n",
      "Epoch 8754 - Train Loss: 0.137634, Train Acc: 0.751282 | Val Loss: 0.151964, Val Acc: 0.701031\n",
      "Epoch 8755 - Train Loss: 0.137624, Train Acc: 0.751282 | Val Loss: 0.151956, Val Acc: 0.701031\n",
      "Epoch 8756 - Train Loss: 0.137614, Train Acc: 0.751282 | Val Loss: 0.151947, Val Acc: 0.701031\n",
      "Epoch 8757 - Train Loss: 0.137605, Train Acc: 0.751282 | Val Loss: 0.151939, Val Acc: 0.701031\n",
      "Epoch 8758 - Train Loss: 0.137595, Train Acc: 0.751282 | Val Loss: 0.151931, Val Acc: 0.701031\n",
      "Epoch 8759 - Train Loss: 0.137585, Train Acc: 0.751282 | Val Loss: 0.151922, Val Acc: 0.701031\n",
      "Epoch 8760 - Train Loss: 0.137576, Train Acc: 0.751282 | Val Loss: 0.151914, Val Acc: 0.701031\n",
      "Epoch 8761 - Train Loss: 0.137566, Train Acc: 0.751282 | Val Loss: 0.151906, Val Acc: 0.701031\n",
      "Epoch 8762 - Train Loss: 0.137556, Train Acc: 0.751282 | Val Loss: 0.151898, Val Acc: 0.701031\n",
      "Epoch 8763 - Train Loss: 0.137547, Train Acc: 0.751282 | Val Loss: 0.151889, Val Acc: 0.701031\n",
      "Epoch 8764 - Train Loss: 0.137537, Train Acc: 0.751282 | Val Loss: 0.151881, Val Acc: 0.701031\n",
      "Epoch 8765 - Train Loss: 0.137527, Train Acc: 0.751282 | Val Loss: 0.151873, Val Acc: 0.701031\n",
      "Epoch 8766 - Train Loss: 0.137518, Train Acc: 0.751282 | Val Loss: 0.151865, Val Acc: 0.701031\n",
      "Epoch 8767 - Train Loss: 0.137508, Train Acc: 0.751282 | Val Loss: 0.151856, Val Acc: 0.701031\n",
      "Epoch 8768 - Train Loss: 0.137498, Train Acc: 0.751282 | Val Loss: 0.151848, Val Acc: 0.701031\n",
      "Epoch 8769 - Train Loss: 0.137489, Train Acc: 0.751282 | Val Loss: 0.151840, Val Acc: 0.711340\n",
      "Epoch 8770 - Train Loss: 0.137479, Train Acc: 0.751282 | Val Loss: 0.151832, Val Acc: 0.711340\n",
      "Epoch 8771 - Train Loss: 0.137469, Train Acc: 0.751282 | Val Loss: 0.151823, Val Acc: 0.711340\n",
      "Epoch 8772 - Train Loss: 0.137460, Train Acc: 0.751282 | Val Loss: 0.151815, Val Acc: 0.711340\n",
      "Epoch 8773 - Train Loss: 0.137450, Train Acc: 0.751282 | Val Loss: 0.151807, Val Acc: 0.711340\n",
      "Epoch 8774 - Train Loss: 0.137440, Train Acc: 0.751282 | Val Loss: 0.151799, Val Acc: 0.711340\n",
      "Epoch 8775 - Train Loss: 0.137431, Train Acc: 0.751282 | Val Loss: 0.151790, Val Acc: 0.711340\n",
      "Epoch 8776 - Train Loss: 0.137421, Train Acc: 0.751282 | Val Loss: 0.151782, Val Acc: 0.711340\n",
      "Epoch 8777 - Train Loss: 0.137412, Train Acc: 0.751282 | Val Loss: 0.151774, Val Acc: 0.711340\n",
      "Epoch 8778 - Train Loss: 0.137402, Train Acc: 0.751282 | Val Loss: 0.151765, Val Acc: 0.711340\n",
      "Epoch 8779 - Train Loss: 0.137392, Train Acc: 0.751282 | Val Loss: 0.151757, Val Acc: 0.711340\n",
      "Epoch 8780 - Train Loss: 0.137383, Train Acc: 0.751282 | Val Loss: 0.151749, Val Acc: 0.711340\n",
      "Epoch 8781 - Train Loss: 0.137373, Train Acc: 0.751282 | Val Loss: 0.151741, Val Acc: 0.711340\n",
      "Epoch 8782 - Train Loss: 0.137363, Train Acc: 0.751282 | Val Loss: 0.151732, Val Acc: 0.711340\n",
      "Epoch 8783 - Train Loss: 0.137354, Train Acc: 0.751282 | Val Loss: 0.151724, Val Acc: 0.711340\n",
      "Epoch 8784 - Train Loss: 0.137344, Train Acc: 0.751282 | Val Loss: 0.151716, Val Acc: 0.711340\n",
      "Epoch 8785 - Train Loss: 0.137334, Train Acc: 0.751282 | Val Loss: 0.151708, Val Acc: 0.711340\n",
      "Epoch 8786 - Train Loss: 0.137325, Train Acc: 0.751282 | Val Loss: 0.151699, Val Acc: 0.711340\n",
      "Epoch 8787 - Train Loss: 0.137315, Train Acc: 0.751282 | Val Loss: 0.151691, Val Acc: 0.711340\n",
      "Epoch 8788 - Train Loss: 0.137305, Train Acc: 0.751282 | Val Loss: 0.151683, Val Acc: 0.711340\n",
      "Epoch 8789 - Train Loss: 0.137296, Train Acc: 0.751282 | Val Loss: 0.151675, Val Acc: 0.711340\n",
      "Epoch 8790 - Train Loss: 0.137286, Train Acc: 0.751282 | Val Loss: 0.151666, Val Acc: 0.711340\n",
      "Epoch 8791 - Train Loss: 0.137277, Train Acc: 0.751282 | Val Loss: 0.151658, Val Acc: 0.711340\n",
      "Epoch 8792 - Train Loss: 0.137267, Train Acc: 0.751282 | Val Loss: 0.151650, Val Acc: 0.711340\n",
      "Epoch 8793 - Train Loss: 0.137257, Train Acc: 0.751282 | Val Loss: 0.151642, Val Acc: 0.711340\n",
      "Epoch 8794 - Train Loss: 0.137248, Train Acc: 0.752564 | Val Loss: 0.151633, Val Acc: 0.711340\n",
      "Epoch 8795 - Train Loss: 0.137238, Train Acc: 0.752564 | Val Loss: 0.151625, Val Acc: 0.711340\n",
      "Epoch 8796 - Train Loss: 0.137228, Train Acc: 0.752564 | Val Loss: 0.151617, Val Acc: 0.711340\n",
      "Epoch 8797 - Train Loss: 0.137219, Train Acc: 0.752564 | Val Loss: 0.151609, Val Acc: 0.711340\n",
      "Epoch 8798 - Train Loss: 0.137209, Train Acc: 0.752564 | Val Loss: 0.151600, Val Acc: 0.711340\n",
      "Epoch 8799 - Train Loss: 0.137200, Train Acc: 0.752564 | Val Loss: 0.151592, Val Acc: 0.711340\n",
      "Epoch 8800 - Train Loss: 0.137190, Train Acc: 0.752564 | Val Loss: 0.151584, Val Acc: 0.711340\n",
      "Epoch 8801 - Train Loss: 0.137180, Train Acc: 0.752564 | Val Loss: 0.151576, Val Acc: 0.711340\n",
      "Epoch 8802 - Train Loss: 0.137171, Train Acc: 0.752564 | Val Loss: 0.151567, Val Acc: 0.711340\n",
      "Epoch 8803 - Train Loss: 0.137161, Train Acc: 0.752564 | Val Loss: 0.151559, Val Acc: 0.711340\n",
      "Epoch 8804 - Train Loss: 0.137151, Train Acc: 0.752564 | Val Loss: 0.151551, Val Acc: 0.711340\n",
      "Epoch 8805 - Train Loss: 0.137142, Train Acc: 0.752564 | Val Loss: 0.151543, Val Acc: 0.711340\n",
      "Epoch 8806 - Train Loss: 0.137132, Train Acc: 0.752564 | Val Loss: 0.151535, Val Acc: 0.711340\n",
      "Epoch 8807 - Train Loss: 0.137123, Train Acc: 0.752564 | Val Loss: 0.151526, Val Acc: 0.711340\n",
      "Epoch 8808 - Train Loss: 0.137113, Train Acc: 0.752564 | Val Loss: 0.151518, Val Acc: 0.711340\n",
      "Epoch 8809 - Train Loss: 0.137103, Train Acc: 0.752564 | Val Loss: 0.151510, Val Acc: 0.711340\n",
      "Epoch 8810 - Train Loss: 0.137094, Train Acc: 0.752564 | Val Loss: 0.151502, Val Acc: 0.711340\n",
      "Epoch 8811 - Train Loss: 0.137084, Train Acc: 0.752564 | Val Loss: 0.151493, Val Acc: 0.711340\n",
      "Epoch 8812 - Train Loss: 0.137074, Train Acc: 0.752564 | Val Loss: 0.151485, Val Acc: 0.711340\n",
      "Epoch 8813 - Train Loss: 0.137065, Train Acc: 0.752564 | Val Loss: 0.151477, Val Acc: 0.711340\n",
      "Epoch 8814 - Train Loss: 0.137055, Train Acc: 0.752564 | Val Loss: 0.151469, Val Acc: 0.711340\n",
      "Epoch 8815 - Train Loss: 0.137046, Train Acc: 0.752564 | Val Loss: 0.151461, Val Acc: 0.711340\n",
      "Epoch 8816 - Train Loss: 0.137036, Train Acc: 0.752564 | Val Loss: 0.151452, Val Acc: 0.711340\n",
      "Epoch 8817 - Train Loss: 0.137026, Train Acc: 0.752564 | Val Loss: 0.151444, Val Acc: 0.711340\n",
      "Epoch 8818 - Train Loss: 0.137017, Train Acc: 0.752564 | Val Loss: 0.151436, Val Acc: 0.711340\n",
      "Epoch 8819 - Train Loss: 0.137007, Train Acc: 0.752564 | Val Loss: 0.151428, Val Acc: 0.711340\n",
      "Epoch 8820 - Train Loss: 0.136998, Train Acc: 0.752564 | Val Loss: 0.151419, Val Acc: 0.711340\n",
      "Epoch 8821 - Train Loss: 0.136988, Train Acc: 0.752564 | Val Loss: 0.151411, Val Acc: 0.711340\n",
      "Epoch 8822 - Train Loss: 0.136978, Train Acc: 0.752564 | Val Loss: 0.151403, Val Acc: 0.711340\n",
      "Epoch 8823 - Train Loss: 0.136969, Train Acc: 0.752564 | Val Loss: 0.151395, Val Acc: 0.711340\n",
      "Epoch 8824 - Train Loss: 0.136959, Train Acc: 0.752564 | Val Loss: 0.151387, Val Acc: 0.711340\n",
      "Epoch 8825 - Train Loss: 0.136950, Train Acc: 0.752564 | Val Loss: 0.151378, Val Acc: 0.711340\n",
      "Epoch 8826 - Train Loss: 0.136940, Train Acc: 0.752564 | Val Loss: 0.151370, Val Acc: 0.711340\n",
      "Epoch 8827 - Train Loss: 0.136930, Train Acc: 0.752564 | Val Loss: 0.151362, Val Acc: 0.711340\n",
      "Epoch 8828 - Train Loss: 0.136921, Train Acc: 0.752564 | Val Loss: 0.151354, Val Acc: 0.711340\n",
      "Epoch 8829 - Train Loss: 0.136911, Train Acc: 0.752564 | Val Loss: 0.151346, Val Acc: 0.711340\n",
      "Epoch 8830 - Train Loss: 0.136902, Train Acc: 0.752564 | Val Loss: 0.151337, Val Acc: 0.711340\n",
      "Epoch 8831 - Train Loss: 0.136892, Train Acc: 0.752564 | Val Loss: 0.151329, Val Acc: 0.711340\n",
      "Epoch 8832 - Train Loss: 0.136882, Train Acc: 0.752564 | Val Loss: 0.151321, Val Acc: 0.711340\n",
      "Epoch 8833 - Train Loss: 0.136873, Train Acc: 0.753846 | Val Loss: 0.151313, Val Acc: 0.711340\n",
      "Epoch 8834 - Train Loss: 0.136863, Train Acc: 0.753846 | Val Loss: 0.151305, Val Acc: 0.711340\n",
      "Epoch 8835 - Train Loss: 0.136854, Train Acc: 0.753846 | Val Loss: 0.151296, Val Acc: 0.711340\n",
      "Epoch 8836 - Train Loss: 0.136844, Train Acc: 0.753846 | Val Loss: 0.151288, Val Acc: 0.711340\n",
      "Epoch 8837 - Train Loss: 0.136835, Train Acc: 0.753846 | Val Loss: 0.151280, Val Acc: 0.711340\n",
      "Epoch 8838 - Train Loss: 0.136825, Train Acc: 0.755128 | Val Loss: 0.151272, Val Acc: 0.711340\n",
      "Epoch 8839 - Train Loss: 0.136815, Train Acc: 0.755128 | Val Loss: 0.151264, Val Acc: 0.711340\n",
      "Epoch 8840 - Train Loss: 0.136806, Train Acc: 0.755128 | Val Loss: 0.151255, Val Acc: 0.711340\n",
      "Epoch 8841 - Train Loss: 0.136796, Train Acc: 0.755128 | Val Loss: 0.151247, Val Acc: 0.711340\n",
      "Epoch 8842 - Train Loss: 0.136787, Train Acc: 0.755128 | Val Loss: 0.151239, Val Acc: 0.711340\n",
      "Epoch 8843 - Train Loss: 0.136777, Train Acc: 0.755128 | Val Loss: 0.151231, Val Acc: 0.711340\n",
      "Epoch 8844 - Train Loss: 0.136768, Train Acc: 0.755128 | Val Loss: 0.151223, Val Acc: 0.711340\n",
      "Epoch 8845 - Train Loss: 0.136758, Train Acc: 0.755128 | Val Loss: 0.151215, Val Acc: 0.711340\n",
      "Epoch 8846 - Train Loss: 0.136748, Train Acc: 0.755128 | Val Loss: 0.151206, Val Acc: 0.711340\n",
      "Epoch 8847 - Train Loss: 0.136739, Train Acc: 0.755128 | Val Loss: 0.151198, Val Acc: 0.711340\n",
      "Epoch 8848 - Train Loss: 0.136729, Train Acc: 0.755128 | Val Loss: 0.151190, Val Acc: 0.711340\n",
      "Epoch 8849 - Train Loss: 0.136720, Train Acc: 0.755128 | Val Loss: 0.151182, Val Acc: 0.711340\n",
      "Epoch 8850 - Train Loss: 0.136710, Train Acc: 0.755128 | Val Loss: 0.151174, Val Acc: 0.711340\n",
      "Epoch 8851 - Train Loss: 0.136701, Train Acc: 0.755128 | Val Loss: 0.151165, Val Acc: 0.711340\n",
      "Epoch 8852 - Train Loss: 0.136691, Train Acc: 0.755128 | Val Loss: 0.151157, Val Acc: 0.711340\n",
      "Epoch 8853 - Train Loss: 0.136681, Train Acc: 0.755128 | Val Loss: 0.151149, Val Acc: 0.711340\n",
      "Epoch 8854 - Train Loss: 0.136672, Train Acc: 0.755128 | Val Loss: 0.151141, Val Acc: 0.711340\n",
      "Epoch 8855 - Train Loss: 0.136662, Train Acc: 0.755128 | Val Loss: 0.151133, Val Acc: 0.711340\n",
      "Epoch 8856 - Train Loss: 0.136653, Train Acc: 0.755128 | Val Loss: 0.151125, Val Acc: 0.711340\n",
      "Epoch 8857 - Train Loss: 0.136643, Train Acc: 0.755128 | Val Loss: 0.151116, Val Acc: 0.711340\n",
      "Epoch 8858 - Train Loss: 0.136634, Train Acc: 0.755128 | Val Loss: 0.151108, Val Acc: 0.711340\n",
      "Epoch 8859 - Train Loss: 0.136624, Train Acc: 0.755128 | Val Loss: 0.151100, Val Acc: 0.711340\n",
      "Epoch 8860 - Train Loss: 0.136614, Train Acc: 0.755128 | Val Loss: 0.151092, Val Acc: 0.711340\n",
      "Epoch 8861 - Train Loss: 0.136605, Train Acc: 0.755128 | Val Loss: 0.151084, Val Acc: 0.711340\n",
      "Epoch 8862 - Train Loss: 0.136595, Train Acc: 0.755128 | Val Loss: 0.151076, Val Acc: 0.711340\n",
      "Epoch 8863 - Train Loss: 0.136586, Train Acc: 0.755128 | Val Loss: 0.151067, Val Acc: 0.711340\n",
      "Epoch 8864 - Train Loss: 0.136576, Train Acc: 0.755128 | Val Loss: 0.151059, Val Acc: 0.711340\n",
      "Epoch 8865 - Train Loss: 0.136567, Train Acc: 0.755128 | Val Loss: 0.151051, Val Acc: 0.711340\n",
      "Epoch 8866 - Train Loss: 0.136557, Train Acc: 0.755128 | Val Loss: 0.151043, Val Acc: 0.711340\n",
      "Epoch 8867 - Train Loss: 0.136548, Train Acc: 0.755128 | Val Loss: 0.151035, Val Acc: 0.711340\n",
      "Epoch 8868 - Train Loss: 0.136538, Train Acc: 0.755128 | Val Loss: 0.151027, Val Acc: 0.711340\n",
      "Epoch 8869 - Train Loss: 0.136529, Train Acc: 0.755128 | Val Loss: 0.151019, Val Acc: 0.711340\n",
      "Epoch 8870 - Train Loss: 0.136519, Train Acc: 0.755128 | Val Loss: 0.151010, Val Acc: 0.711340\n",
      "Epoch 8871 - Train Loss: 0.136509, Train Acc: 0.755128 | Val Loss: 0.151002, Val Acc: 0.711340\n",
      "Epoch 8872 - Train Loss: 0.136500, Train Acc: 0.755128 | Val Loss: 0.150994, Val Acc: 0.711340\n",
      "Epoch 8873 - Train Loss: 0.136490, Train Acc: 0.755128 | Val Loss: 0.150986, Val Acc: 0.721649\n",
      "Epoch 8874 - Train Loss: 0.136481, Train Acc: 0.755128 | Val Loss: 0.150978, Val Acc: 0.721649\n",
      "Epoch 8875 - Train Loss: 0.136471, Train Acc: 0.755128 | Val Loss: 0.150969, Val Acc: 0.721649\n",
      "Epoch 8876 - Train Loss: 0.136462, Train Acc: 0.755128 | Val Loss: 0.150961, Val Acc: 0.721649\n",
      "Epoch 8877 - Train Loss: 0.136452, Train Acc: 0.755128 | Val Loss: 0.150953, Val Acc: 0.721649\n",
      "Epoch 8878 - Train Loss: 0.136443, Train Acc: 0.755128 | Val Loss: 0.150945, Val Acc: 0.721649\n",
      "Epoch 8879 - Train Loss: 0.136433, Train Acc: 0.755128 | Val Loss: 0.150937, Val Acc: 0.721649\n",
      "Epoch 8880 - Train Loss: 0.136424, Train Acc: 0.755128 | Val Loss: 0.150928, Val Acc: 0.721649\n",
      "Epoch 8881 - Train Loss: 0.136414, Train Acc: 0.755128 | Val Loss: 0.150920, Val Acc: 0.721649\n",
      "Epoch 8882 - Train Loss: 0.136405, Train Acc: 0.757692 | Val Loss: 0.150912, Val Acc: 0.721649\n",
      "Epoch 8883 - Train Loss: 0.136395, Train Acc: 0.757692 | Val Loss: 0.150904, Val Acc: 0.721649\n",
      "Epoch 8884 - Train Loss: 0.136386, Train Acc: 0.757692 | Val Loss: 0.150896, Val Acc: 0.721649\n",
      "Epoch 8885 - Train Loss: 0.136376, Train Acc: 0.757692 | Val Loss: 0.150887, Val Acc: 0.721649\n",
      "Epoch 8886 - Train Loss: 0.136367, Train Acc: 0.757692 | Val Loss: 0.150879, Val Acc: 0.721649\n",
      "Epoch 8887 - Train Loss: 0.136357, Train Acc: 0.757692 | Val Loss: 0.150871, Val Acc: 0.721649\n",
      "Epoch 8888 - Train Loss: 0.136348, Train Acc: 0.757692 | Val Loss: 0.150863, Val Acc: 0.721649\n",
      "Epoch 8889 - Train Loss: 0.136338, Train Acc: 0.757692 | Val Loss: 0.150855, Val Acc: 0.721649\n",
      "Epoch 8890 - Train Loss: 0.136329, Train Acc: 0.757692 | Val Loss: 0.150846, Val Acc: 0.721649\n",
      "Epoch 8891 - Train Loss: 0.136319, Train Acc: 0.757692 | Val Loss: 0.150838, Val Acc: 0.721649\n",
      "Epoch 8892 - Train Loss: 0.136309, Train Acc: 0.757692 | Val Loss: 0.150830, Val Acc: 0.721649\n",
      "Epoch 8893 - Train Loss: 0.136300, Train Acc: 0.757692 | Val Loss: 0.150822, Val Acc: 0.721649\n",
      "Epoch 8894 - Train Loss: 0.136290, Train Acc: 0.757692 | Val Loss: 0.150814, Val Acc: 0.721649\n",
      "Epoch 8895 - Train Loss: 0.136281, Train Acc: 0.757692 | Val Loss: 0.150806, Val Acc: 0.721649\n",
      "Epoch 8896 - Train Loss: 0.136271, Train Acc: 0.757692 | Val Loss: 0.150798, Val Acc: 0.721649\n",
      "Epoch 8897 - Train Loss: 0.136262, Train Acc: 0.757692 | Val Loss: 0.150789, Val Acc: 0.721649\n",
      "Epoch 8898 - Train Loss: 0.136252, Train Acc: 0.757692 | Val Loss: 0.150781, Val Acc: 0.721649\n",
      "Epoch 8899 - Train Loss: 0.136243, Train Acc: 0.757692 | Val Loss: 0.150773, Val Acc: 0.721649\n",
      "Epoch 8900 - Train Loss: 0.136233, Train Acc: 0.757692 | Val Loss: 0.150765, Val Acc: 0.721649\n",
      "Epoch 8901 - Train Loss: 0.136224, Train Acc: 0.757692 | Val Loss: 0.150757, Val Acc: 0.721649\n",
      "Epoch 8902 - Train Loss: 0.136214, Train Acc: 0.757692 | Val Loss: 0.150749, Val Acc: 0.721649\n",
      "Epoch 8903 - Train Loss: 0.136205, Train Acc: 0.757692 | Val Loss: 0.150740, Val Acc: 0.721649\n",
      "Epoch 8904 - Train Loss: 0.136195, Train Acc: 0.757692 | Val Loss: 0.150732, Val Acc: 0.721649\n",
      "Epoch 8905 - Train Loss: 0.136186, Train Acc: 0.757692 | Val Loss: 0.150724, Val Acc: 0.721649\n",
      "Epoch 8906 - Train Loss: 0.136176, Train Acc: 0.757692 | Val Loss: 0.150716, Val Acc: 0.721649\n",
      "Epoch 8907 - Train Loss: 0.136167, Train Acc: 0.757692 | Val Loss: 0.150708, Val Acc: 0.721649\n",
      "Epoch 8908 - Train Loss: 0.136157, Train Acc: 0.757692 | Val Loss: 0.150700, Val Acc: 0.721649\n",
      "Epoch 8909 - Train Loss: 0.136148, Train Acc: 0.757692 | Val Loss: 0.150692, Val Acc: 0.721649\n",
      "Epoch 8910 - Train Loss: 0.136138, Train Acc: 0.757692 | Val Loss: 0.150684, Val Acc: 0.721649\n",
      "Epoch 8911 - Train Loss: 0.136129, Train Acc: 0.757692 | Val Loss: 0.150675, Val Acc: 0.721649\n",
      "Epoch 8912 - Train Loss: 0.136119, Train Acc: 0.757692 | Val Loss: 0.150667, Val Acc: 0.721649\n",
      "Epoch 8913 - Train Loss: 0.136110, Train Acc: 0.757692 | Val Loss: 0.150659, Val Acc: 0.721649\n",
      "Epoch 8914 - Train Loss: 0.136100, Train Acc: 0.757692 | Val Loss: 0.150651, Val Acc: 0.721649\n",
      "Epoch 8915 - Train Loss: 0.136091, Train Acc: 0.757692 | Val Loss: 0.150643, Val Acc: 0.721649\n",
      "Epoch 8916 - Train Loss: 0.136082, Train Acc: 0.757692 | Val Loss: 0.150635, Val Acc: 0.721649\n",
      "Epoch 8917 - Train Loss: 0.136072, Train Acc: 0.757692 | Val Loss: 0.150627, Val Acc: 0.721649\n",
      "Epoch 8918 - Train Loss: 0.136063, Train Acc: 0.757692 | Val Loss: 0.150619, Val Acc: 0.721649\n",
      "Epoch 8919 - Train Loss: 0.136053, Train Acc: 0.757692 | Val Loss: 0.150610, Val Acc: 0.721649\n",
      "Epoch 8920 - Train Loss: 0.136044, Train Acc: 0.757692 | Val Loss: 0.150602, Val Acc: 0.721649\n",
      "Epoch 8921 - Train Loss: 0.136034, Train Acc: 0.757692 | Val Loss: 0.150594, Val Acc: 0.721649\n",
      "Epoch 8922 - Train Loss: 0.136025, Train Acc: 0.757692 | Val Loss: 0.150586, Val Acc: 0.721649\n",
      "Epoch 8923 - Train Loss: 0.136015, Train Acc: 0.757692 | Val Loss: 0.150578, Val Acc: 0.721649\n",
      "Epoch 8924 - Train Loss: 0.136006, Train Acc: 0.757692 | Val Loss: 0.150570, Val Acc: 0.721649\n",
      "Epoch 8925 - Train Loss: 0.135996, Train Acc: 0.757692 | Val Loss: 0.150562, Val Acc: 0.721649\n",
      "Epoch 8926 - Train Loss: 0.135987, Train Acc: 0.757692 | Val Loss: 0.150554, Val Acc: 0.721649\n",
      "Epoch 8927 - Train Loss: 0.135977, Train Acc: 0.757692 | Val Loss: 0.150546, Val Acc: 0.721649\n",
      "Epoch 8928 - Train Loss: 0.135968, Train Acc: 0.757692 | Val Loss: 0.150538, Val Acc: 0.721649\n",
      "Epoch 8929 - Train Loss: 0.135958, Train Acc: 0.757692 | Val Loss: 0.150529, Val Acc: 0.721649\n",
      "Epoch 8930 - Train Loss: 0.135949, Train Acc: 0.757692 | Val Loss: 0.150521, Val Acc: 0.721649\n",
      "Epoch 8931 - Train Loss: 0.135939, Train Acc: 0.757692 | Val Loss: 0.150513, Val Acc: 0.721649\n",
      "Epoch 8932 - Train Loss: 0.135930, Train Acc: 0.757692 | Val Loss: 0.150505, Val Acc: 0.721649\n",
      "Epoch 8933 - Train Loss: 0.135920, Train Acc: 0.757692 | Val Loss: 0.150497, Val Acc: 0.721649\n",
      "Epoch 8934 - Train Loss: 0.135911, Train Acc: 0.757692 | Val Loss: 0.150489, Val Acc: 0.721649\n",
      "Epoch 8935 - Train Loss: 0.135901, Train Acc: 0.757692 | Val Loss: 0.150481, Val Acc: 0.721649\n",
      "Epoch 8936 - Train Loss: 0.135892, Train Acc: 0.757692 | Val Loss: 0.150473, Val Acc: 0.721649\n",
      "Epoch 8937 - Train Loss: 0.135883, Train Acc: 0.757692 | Val Loss: 0.150465, Val Acc: 0.721649\n",
      "Epoch 8938 - Train Loss: 0.135873, Train Acc: 0.757692 | Val Loss: 0.150457, Val Acc: 0.721649\n",
      "Epoch 8939 - Train Loss: 0.135864, Train Acc: 0.757692 | Val Loss: 0.150449, Val Acc: 0.721649\n",
      "Epoch 8940 - Train Loss: 0.135854, Train Acc: 0.757692 | Val Loss: 0.150440, Val Acc: 0.721649\n",
      "Epoch 8941 - Train Loss: 0.135845, Train Acc: 0.757692 | Val Loss: 0.150432, Val Acc: 0.721649\n",
      "Epoch 8942 - Train Loss: 0.135835, Train Acc: 0.757692 | Val Loss: 0.150424, Val Acc: 0.721649\n",
      "Epoch 8943 - Train Loss: 0.135826, Train Acc: 0.757692 | Val Loss: 0.150416, Val Acc: 0.721649\n",
      "Epoch 8944 - Train Loss: 0.135816, Train Acc: 0.757692 | Val Loss: 0.150408, Val Acc: 0.721649\n",
      "Epoch 8945 - Train Loss: 0.135807, Train Acc: 0.757692 | Val Loss: 0.150400, Val Acc: 0.721649\n",
      "Epoch 8946 - Train Loss: 0.135797, Train Acc: 0.757692 | Val Loss: 0.150392, Val Acc: 0.721649\n",
      "Epoch 8947 - Train Loss: 0.135788, Train Acc: 0.757692 | Val Loss: 0.150384, Val Acc: 0.721649\n",
      "Epoch 8948 - Train Loss: 0.135779, Train Acc: 0.757692 | Val Loss: 0.150376, Val Acc: 0.721649\n",
      "Epoch 8949 - Train Loss: 0.135769, Train Acc: 0.757692 | Val Loss: 0.150368, Val Acc: 0.721649\n",
      "Epoch 8950 - Train Loss: 0.135760, Train Acc: 0.757692 | Val Loss: 0.150360, Val Acc: 0.721649\n",
      "Epoch 8951 - Train Loss: 0.135750, Train Acc: 0.757692 | Val Loss: 0.150352, Val Acc: 0.721649\n",
      "Epoch 8952 - Train Loss: 0.135741, Train Acc: 0.757692 | Val Loss: 0.150344, Val Acc: 0.721649\n",
      "Epoch 8953 - Train Loss: 0.135731, Train Acc: 0.757692 | Val Loss: 0.150336, Val Acc: 0.721649\n",
      "Epoch 8954 - Train Loss: 0.135722, Train Acc: 0.757692 | Val Loss: 0.150328, Val Acc: 0.721649\n",
      "Epoch 8955 - Train Loss: 0.135712, Train Acc: 0.757692 | Val Loss: 0.150319, Val Acc: 0.721649\n",
      "Epoch 8956 - Train Loss: 0.135703, Train Acc: 0.757692 | Val Loss: 0.150311, Val Acc: 0.721649\n",
      "Epoch 8957 - Train Loss: 0.135694, Train Acc: 0.757692 | Val Loss: 0.150303, Val Acc: 0.721649\n",
      "Epoch 8958 - Train Loss: 0.135684, Train Acc: 0.757692 | Val Loss: 0.150295, Val Acc: 0.721649\n",
      "Epoch 8959 - Train Loss: 0.135675, Train Acc: 0.757692 | Val Loss: 0.150287, Val Acc: 0.721649\n",
      "Epoch 8960 - Train Loss: 0.135665, Train Acc: 0.757692 | Val Loss: 0.150279, Val Acc: 0.721649\n",
      "Epoch 8961 - Train Loss: 0.135656, Train Acc: 0.758974 | Val Loss: 0.150271, Val Acc: 0.721649\n",
      "Epoch 8962 - Train Loss: 0.135646, Train Acc: 0.758974 | Val Loss: 0.150263, Val Acc: 0.721649\n",
      "Epoch 8963 - Train Loss: 0.135637, Train Acc: 0.758974 | Val Loss: 0.150255, Val Acc: 0.721649\n",
      "Epoch 8964 - Train Loss: 0.135627, Train Acc: 0.758974 | Val Loss: 0.150247, Val Acc: 0.721649\n",
      "Epoch 8965 - Train Loss: 0.135618, Train Acc: 0.758974 | Val Loss: 0.150239, Val Acc: 0.721649\n",
      "Epoch 8966 - Train Loss: 0.135609, Train Acc: 0.758974 | Val Loss: 0.150231, Val Acc: 0.721649\n",
      "Epoch 8967 - Train Loss: 0.135599, Train Acc: 0.758974 | Val Loss: 0.150223, Val Acc: 0.721649\n",
      "Epoch 8968 - Train Loss: 0.135590, Train Acc: 0.758974 | Val Loss: 0.150215, Val Acc: 0.721649\n",
      "Epoch 8969 - Train Loss: 0.135580, Train Acc: 0.758974 | Val Loss: 0.150207, Val Acc: 0.721649\n",
      "Epoch 8970 - Train Loss: 0.135571, Train Acc: 0.758974 | Val Loss: 0.150199, Val Acc: 0.721649\n",
      "Epoch 8971 - Train Loss: 0.135562, Train Acc: 0.758974 | Val Loss: 0.150191, Val Acc: 0.721649\n",
      "Epoch 8972 - Train Loss: 0.135552, Train Acc: 0.758974 | Val Loss: 0.150183, Val Acc: 0.721649\n",
      "Epoch 8973 - Train Loss: 0.135543, Train Acc: 0.758974 | Val Loss: 0.150175, Val Acc: 0.721649\n",
      "Epoch 8974 - Train Loss: 0.135533, Train Acc: 0.758974 | Val Loss: 0.150167, Val Acc: 0.721649\n",
      "Epoch 8975 - Train Loss: 0.135524, Train Acc: 0.758974 | Val Loss: 0.150159, Val Acc: 0.721649\n",
      "Epoch 8976 - Train Loss: 0.135514, Train Acc: 0.758974 | Val Loss: 0.150151, Val Acc: 0.721649\n",
      "Epoch 8977 - Train Loss: 0.135505, Train Acc: 0.758974 | Val Loss: 0.150143, Val Acc: 0.721649\n",
      "Epoch 8978 - Train Loss: 0.135496, Train Acc: 0.758974 | Val Loss: 0.150135, Val Acc: 0.721649\n",
      "Epoch 8979 - Train Loss: 0.135486, Train Acc: 0.758974 | Val Loss: 0.150127, Val Acc: 0.721649\n",
      "Epoch 8980 - Train Loss: 0.135477, Train Acc: 0.758974 | Val Loss: 0.150118, Val Acc: 0.721649\n",
      "Epoch 8981 - Train Loss: 0.135467, Train Acc: 0.758974 | Val Loss: 0.150110, Val Acc: 0.721649\n",
      "Epoch 8982 - Train Loss: 0.135458, Train Acc: 0.758974 | Val Loss: 0.150102, Val Acc: 0.721649\n",
      "Epoch 8983 - Train Loss: 0.135449, Train Acc: 0.758974 | Val Loss: 0.150094, Val Acc: 0.721649\n",
      "Epoch 8984 - Train Loss: 0.135439, Train Acc: 0.758974 | Val Loss: 0.150086, Val Acc: 0.721649\n",
      "Epoch 8985 - Train Loss: 0.135430, Train Acc: 0.758974 | Val Loss: 0.150078, Val Acc: 0.721649\n",
      "Epoch 8986 - Train Loss: 0.135420, Train Acc: 0.758974 | Val Loss: 0.150070, Val Acc: 0.721649\n",
      "Epoch 8987 - Train Loss: 0.135411, Train Acc: 0.758974 | Val Loss: 0.150062, Val Acc: 0.721649\n",
      "Epoch 8988 - Train Loss: 0.135401, Train Acc: 0.758974 | Val Loss: 0.150054, Val Acc: 0.721649\n",
      "Epoch 8989 - Train Loss: 0.135392, Train Acc: 0.758974 | Val Loss: 0.150046, Val Acc: 0.721649\n",
      "Epoch 8990 - Train Loss: 0.135383, Train Acc: 0.758974 | Val Loss: 0.150038, Val Acc: 0.721649\n",
      "Epoch 8991 - Train Loss: 0.135373, Train Acc: 0.758974 | Val Loss: 0.150030, Val Acc: 0.721649\n",
      "Epoch 8992 - Train Loss: 0.135364, Train Acc: 0.758974 | Val Loss: 0.150022, Val Acc: 0.721649\n",
      "Epoch 8993 - Train Loss: 0.135354, Train Acc: 0.758974 | Val Loss: 0.150014, Val Acc: 0.721649\n",
      "Epoch 8994 - Train Loss: 0.135345, Train Acc: 0.758974 | Val Loss: 0.150006, Val Acc: 0.721649\n",
      "Epoch 8995 - Train Loss: 0.135336, Train Acc: 0.758974 | Val Loss: 0.149998, Val Acc: 0.721649\n",
      "Epoch 8996 - Train Loss: 0.135326, Train Acc: 0.758974 | Val Loss: 0.149990, Val Acc: 0.721649\n",
      "Epoch 8997 - Train Loss: 0.135317, Train Acc: 0.758974 | Val Loss: 0.149982, Val Acc: 0.721649\n",
      "Epoch 8998 - Train Loss: 0.135308, Train Acc: 0.758974 | Val Loss: 0.149974, Val Acc: 0.721649\n",
      "Epoch 8999 - Train Loss: 0.135298, Train Acc: 0.758974 | Val Loss: 0.149966, Val Acc: 0.721649\n",
      "Epoch 9000 - Train Loss: 0.135289, Train Acc: 0.758974 | Val Loss: 0.149958, Val Acc: 0.721649\n",
      "Epoch 9001 - Train Loss: 0.135279, Train Acc: 0.758974 | Val Loss: 0.149950, Val Acc: 0.721649\n",
      "Epoch 9002 - Train Loss: 0.135270, Train Acc: 0.758974 | Val Loss: 0.149942, Val Acc: 0.721649\n",
      "Epoch 9003 - Train Loss: 0.135261, Train Acc: 0.758974 | Val Loss: 0.149934, Val Acc: 0.721649\n",
      "Epoch 9004 - Train Loss: 0.135251, Train Acc: 0.758974 | Val Loss: 0.149926, Val Acc: 0.721649\n",
      "Epoch 9005 - Train Loss: 0.135242, Train Acc: 0.758974 | Val Loss: 0.149918, Val Acc: 0.721649\n",
      "Epoch 9006 - Train Loss: 0.135232, Train Acc: 0.758974 | Val Loss: 0.149910, Val Acc: 0.721649\n",
      "Epoch 9007 - Train Loss: 0.135223, Train Acc: 0.758974 | Val Loss: 0.149902, Val Acc: 0.721649\n",
      "Epoch 9008 - Train Loss: 0.135214, Train Acc: 0.758974 | Val Loss: 0.149894, Val Acc: 0.721649\n",
      "Epoch 9009 - Train Loss: 0.135204, Train Acc: 0.758974 | Val Loss: 0.149886, Val Acc: 0.721649\n",
      "Epoch 9010 - Train Loss: 0.135195, Train Acc: 0.758974 | Val Loss: 0.149878, Val Acc: 0.721649\n",
      "Epoch 9011 - Train Loss: 0.135185, Train Acc: 0.758974 | Val Loss: 0.149870, Val Acc: 0.721649\n",
      "Epoch 9012 - Train Loss: 0.135176, Train Acc: 0.758974 | Val Loss: 0.149862, Val Acc: 0.721649\n",
      "Epoch 9013 - Train Loss: 0.135167, Train Acc: 0.758974 | Val Loss: 0.149854, Val Acc: 0.721649\n",
      "Epoch 9014 - Train Loss: 0.135157, Train Acc: 0.758974 | Val Loss: 0.149846, Val Acc: 0.721649\n",
      "Epoch 9015 - Train Loss: 0.135148, Train Acc: 0.758974 | Val Loss: 0.149838, Val Acc: 0.721649\n",
      "Epoch 9016 - Train Loss: 0.135139, Train Acc: 0.758974 | Val Loss: 0.149830, Val Acc: 0.721649\n",
      "Epoch 9017 - Train Loss: 0.135129, Train Acc: 0.758974 | Val Loss: 0.149823, Val Acc: 0.721649\n",
      "Epoch 9018 - Train Loss: 0.135120, Train Acc: 0.758974 | Val Loss: 0.149815, Val Acc: 0.721649\n",
      "Epoch 9019 - Train Loss: 0.135111, Train Acc: 0.758974 | Val Loss: 0.149807, Val Acc: 0.721649\n",
      "Epoch 9020 - Train Loss: 0.135101, Train Acc: 0.758974 | Val Loss: 0.149799, Val Acc: 0.721649\n",
      "Epoch 9021 - Train Loss: 0.135092, Train Acc: 0.758974 | Val Loss: 0.149791, Val Acc: 0.721649\n",
      "Epoch 9022 - Train Loss: 0.135082, Train Acc: 0.758974 | Val Loss: 0.149783, Val Acc: 0.721649\n",
      "Epoch 9023 - Train Loss: 0.135073, Train Acc: 0.758974 | Val Loss: 0.149775, Val Acc: 0.721649\n",
      "Epoch 9024 - Train Loss: 0.135064, Train Acc: 0.758974 | Val Loss: 0.149767, Val Acc: 0.721649\n",
      "Epoch 9025 - Train Loss: 0.135054, Train Acc: 0.758974 | Val Loss: 0.149759, Val Acc: 0.721649\n",
      "Epoch 9026 - Train Loss: 0.135045, Train Acc: 0.758974 | Val Loss: 0.149751, Val Acc: 0.721649\n",
      "Epoch 9027 - Train Loss: 0.135036, Train Acc: 0.758974 | Val Loss: 0.149743, Val Acc: 0.721649\n",
      "Epoch 9028 - Train Loss: 0.135026, Train Acc: 0.758974 | Val Loss: 0.149735, Val Acc: 0.721649\n",
      "Epoch 9029 - Train Loss: 0.135017, Train Acc: 0.758974 | Val Loss: 0.149727, Val Acc: 0.721649\n",
      "Epoch 9030 - Train Loss: 0.135008, Train Acc: 0.758974 | Val Loss: 0.149719, Val Acc: 0.721649\n",
      "Epoch 9031 - Train Loss: 0.134998, Train Acc: 0.758974 | Val Loss: 0.149711, Val Acc: 0.721649\n",
      "Epoch 9032 - Train Loss: 0.134989, Train Acc: 0.758974 | Val Loss: 0.149703, Val Acc: 0.721649\n",
      "Epoch 9033 - Train Loss: 0.134979, Train Acc: 0.758974 | Val Loss: 0.149695, Val Acc: 0.721649\n",
      "Epoch 9034 - Train Loss: 0.134970, Train Acc: 0.758974 | Val Loss: 0.149687, Val Acc: 0.721649\n",
      "Epoch 9035 - Train Loss: 0.134961, Train Acc: 0.758974 | Val Loss: 0.149679, Val Acc: 0.721649\n",
      "Epoch 9036 - Train Loss: 0.134951, Train Acc: 0.758974 | Val Loss: 0.149671, Val Acc: 0.721649\n",
      "Epoch 9037 - Train Loss: 0.134942, Train Acc: 0.758974 | Val Loss: 0.149663, Val Acc: 0.721649\n",
      "Epoch 9038 - Train Loss: 0.134933, Train Acc: 0.758974 | Val Loss: 0.149655, Val Acc: 0.721649\n",
      "Epoch 9039 - Train Loss: 0.134923, Train Acc: 0.758974 | Val Loss: 0.149647, Val Acc: 0.721649\n",
      "Epoch 9040 - Train Loss: 0.134914, Train Acc: 0.758974 | Val Loss: 0.149639, Val Acc: 0.721649\n",
      "Epoch 9041 - Train Loss: 0.134905, Train Acc: 0.758974 | Val Loss: 0.149631, Val Acc: 0.721649\n",
      "Epoch 9042 - Train Loss: 0.134895, Train Acc: 0.758974 | Val Loss: 0.149623, Val Acc: 0.721649\n",
      "Epoch 9043 - Train Loss: 0.134886, Train Acc: 0.758974 | Val Loss: 0.149616, Val Acc: 0.721649\n",
      "Epoch 9044 - Train Loss: 0.134877, Train Acc: 0.758974 | Val Loss: 0.149608, Val Acc: 0.721649\n",
      "Epoch 9045 - Train Loss: 0.134867, Train Acc: 0.758974 | Val Loss: 0.149600, Val Acc: 0.721649\n",
      "Epoch 9046 - Train Loss: 0.134858, Train Acc: 0.758974 | Val Loss: 0.149592, Val Acc: 0.721649\n",
      "Epoch 9047 - Train Loss: 0.134849, Train Acc: 0.758974 | Val Loss: 0.149584, Val Acc: 0.721649\n",
      "Epoch 9048 - Train Loss: 0.134839, Train Acc: 0.758974 | Val Loss: 0.149576, Val Acc: 0.721649\n",
      "Epoch 9049 - Train Loss: 0.134830, Train Acc: 0.758974 | Val Loss: 0.149568, Val Acc: 0.721649\n",
      "Epoch 9050 - Train Loss: 0.134821, Train Acc: 0.758974 | Val Loss: 0.149560, Val Acc: 0.721649\n",
      "Epoch 9051 - Train Loss: 0.134811, Train Acc: 0.758974 | Val Loss: 0.149552, Val Acc: 0.721649\n",
      "Epoch 9052 - Train Loss: 0.134802, Train Acc: 0.758974 | Val Loss: 0.149544, Val Acc: 0.721649\n",
      "Epoch 9053 - Train Loss: 0.134793, Train Acc: 0.758974 | Val Loss: 0.149536, Val Acc: 0.721649\n",
      "Epoch 9054 - Train Loss: 0.134783, Train Acc: 0.758974 | Val Loss: 0.149528, Val Acc: 0.721649\n",
      "Epoch 9055 - Train Loss: 0.134774, Train Acc: 0.758974 | Val Loss: 0.149520, Val Acc: 0.721649\n",
      "Epoch 9056 - Train Loss: 0.134765, Train Acc: 0.758974 | Val Loss: 0.149512, Val Acc: 0.721649\n",
      "Epoch 9057 - Train Loss: 0.134755, Train Acc: 0.758974 | Val Loss: 0.149504, Val Acc: 0.721649\n",
      "Epoch 9058 - Train Loss: 0.134746, Train Acc: 0.758974 | Val Loss: 0.149497, Val Acc: 0.721649\n",
      "Epoch 9059 - Train Loss: 0.134737, Train Acc: 0.758974 | Val Loss: 0.149489, Val Acc: 0.721649\n",
      "Epoch 9060 - Train Loss: 0.134727, Train Acc: 0.758974 | Val Loss: 0.149481, Val Acc: 0.721649\n",
      "Epoch 9061 - Train Loss: 0.134718, Train Acc: 0.760256 | Val Loss: 0.149473, Val Acc: 0.721649\n",
      "Epoch 9062 - Train Loss: 0.134709, Train Acc: 0.760256 | Val Loss: 0.149465, Val Acc: 0.721649\n",
      "Epoch 9063 - Train Loss: 0.134699, Train Acc: 0.760256 | Val Loss: 0.149457, Val Acc: 0.721649\n",
      "Epoch 9064 - Train Loss: 0.134690, Train Acc: 0.760256 | Val Loss: 0.149449, Val Acc: 0.721649\n",
      "Epoch 9065 - Train Loss: 0.134681, Train Acc: 0.760256 | Val Loss: 0.149441, Val Acc: 0.721649\n",
      "Epoch 9066 - Train Loss: 0.134671, Train Acc: 0.760256 | Val Loss: 0.149433, Val Acc: 0.721649\n",
      "Epoch 9067 - Train Loss: 0.134662, Train Acc: 0.760256 | Val Loss: 0.149425, Val Acc: 0.721649\n",
      "Epoch 9068 - Train Loss: 0.134653, Train Acc: 0.760256 | Val Loss: 0.149417, Val Acc: 0.721649\n",
      "Epoch 9069 - Train Loss: 0.134643, Train Acc: 0.760256 | Val Loss: 0.149409, Val Acc: 0.721649\n",
      "Epoch 9070 - Train Loss: 0.134634, Train Acc: 0.760256 | Val Loss: 0.149401, Val Acc: 0.721649\n",
      "Epoch 9071 - Train Loss: 0.134625, Train Acc: 0.760256 | Val Loss: 0.149394, Val Acc: 0.721649\n",
      "Epoch 9072 - Train Loss: 0.134616, Train Acc: 0.760256 | Val Loss: 0.149386, Val Acc: 0.721649\n",
      "Epoch 9073 - Train Loss: 0.134606, Train Acc: 0.760256 | Val Loss: 0.149378, Val Acc: 0.721649\n",
      "Epoch 9074 - Train Loss: 0.134597, Train Acc: 0.760256 | Val Loss: 0.149370, Val Acc: 0.721649\n",
      "Epoch 9075 - Train Loss: 0.134588, Train Acc: 0.760256 | Val Loss: 0.149362, Val Acc: 0.721649\n",
      "Epoch 9076 - Train Loss: 0.134578, Train Acc: 0.760256 | Val Loss: 0.149354, Val Acc: 0.721649\n",
      "Epoch 9077 - Train Loss: 0.134569, Train Acc: 0.760256 | Val Loss: 0.149346, Val Acc: 0.721649\n",
      "Epoch 9078 - Train Loss: 0.134560, Train Acc: 0.760256 | Val Loss: 0.149338, Val Acc: 0.721649\n",
      "Epoch 9079 - Train Loss: 0.134550, Train Acc: 0.760256 | Val Loss: 0.149330, Val Acc: 0.721649\n",
      "Epoch 9080 - Train Loss: 0.134541, Train Acc: 0.760256 | Val Loss: 0.149322, Val Acc: 0.721649\n",
      "Epoch 9081 - Train Loss: 0.134532, Train Acc: 0.760256 | Val Loss: 0.149315, Val Acc: 0.721649\n",
      "Epoch 9082 - Train Loss: 0.134522, Train Acc: 0.760256 | Val Loss: 0.149307, Val Acc: 0.721649\n",
      "Epoch 9083 - Train Loss: 0.134513, Train Acc: 0.760256 | Val Loss: 0.149299, Val Acc: 0.721649\n",
      "Epoch 9084 - Train Loss: 0.134504, Train Acc: 0.760256 | Val Loss: 0.149291, Val Acc: 0.721649\n",
      "Epoch 9085 - Train Loss: 0.134495, Train Acc: 0.760256 | Val Loss: 0.149283, Val Acc: 0.721649\n",
      "Epoch 9086 - Train Loss: 0.134485, Train Acc: 0.760256 | Val Loss: 0.149275, Val Acc: 0.721649\n",
      "Epoch 9087 - Train Loss: 0.134476, Train Acc: 0.760256 | Val Loss: 0.149267, Val Acc: 0.721649\n",
      "Epoch 9088 - Train Loss: 0.134467, Train Acc: 0.760256 | Val Loss: 0.149259, Val Acc: 0.721649\n",
      "Epoch 9089 - Train Loss: 0.134457, Train Acc: 0.760256 | Val Loss: 0.149251, Val Acc: 0.721649\n",
      "Epoch 9090 - Train Loss: 0.134448, Train Acc: 0.760256 | Val Loss: 0.149243, Val Acc: 0.721649\n",
      "Epoch 9091 - Train Loss: 0.134439, Train Acc: 0.760256 | Val Loss: 0.149236, Val Acc: 0.721649\n",
      "Epoch 9092 - Train Loss: 0.134430, Train Acc: 0.760256 | Val Loss: 0.149228, Val Acc: 0.721649\n",
      "Epoch 9093 - Train Loss: 0.134420, Train Acc: 0.760256 | Val Loss: 0.149220, Val Acc: 0.721649\n",
      "Epoch 9094 - Train Loss: 0.134411, Train Acc: 0.760256 | Val Loss: 0.149212, Val Acc: 0.721649\n",
      "Epoch 9095 - Train Loss: 0.134402, Train Acc: 0.760256 | Val Loss: 0.149204, Val Acc: 0.721649\n",
      "Epoch 9096 - Train Loss: 0.134392, Train Acc: 0.760256 | Val Loss: 0.149196, Val Acc: 0.721649\n",
      "Epoch 9097 - Train Loss: 0.134383, Train Acc: 0.760256 | Val Loss: 0.149188, Val Acc: 0.721649\n",
      "Epoch 9098 - Train Loss: 0.134374, Train Acc: 0.760256 | Val Loss: 0.149180, Val Acc: 0.721649\n",
      "Epoch 9099 - Train Loss: 0.134365, Train Acc: 0.760256 | Val Loss: 0.149173, Val Acc: 0.721649\n",
      "Epoch 9100 - Train Loss: 0.134355, Train Acc: 0.760256 | Val Loss: 0.149165, Val Acc: 0.721649\n",
      "Epoch 9101 - Train Loss: 0.134346, Train Acc: 0.760256 | Val Loss: 0.149157, Val Acc: 0.721649\n",
      "Epoch 9102 - Train Loss: 0.134337, Train Acc: 0.760256 | Val Loss: 0.149149, Val Acc: 0.721649\n",
      "Epoch 9103 - Train Loss: 0.134327, Train Acc: 0.760256 | Val Loss: 0.149141, Val Acc: 0.721649\n",
      "Epoch 9104 - Train Loss: 0.134318, Train Acc: 0.760256 | Val Loss: 0.149133, Val Acc: 0.721649\n",
      "Epoch 9105 - Train Loss: 0.134309, Train Acc: 0.760256 | Val Loss: 0.149125, Val Acc: 0.721649\n",
      "Epoch 9106 - Train Loss: 0.134300, Train Acc: 0.760256 | Val Loss: 0.149117, Val Acc: 0.721649\n",
      "Epoch 9107 - Train Loss: 0.134290, Train Acc: 0.760256 | Val Loss: 0.149110, Val Acc: 0.721649\n",
      "Epoch 9108 - Train Loss: 0.134281, Train Acc: 0.760256 | Val Loss: 0.149102, Val Acc: 0.721649\n",
      "Epoch 9109 - Train Loss: 0.134272, Train Acc: 0.760256 | Val Loss: 0.149094, Val Acc: 0.721649\n",
      "Epoch 9110 - Train Loss: 0.134263, Train Acc: 0.760256 | Val Loss: 0.149086, Val Acc: 0.721649\n",
      "Epoch 9111 - Train Loss: 0.134253, Train Acc: 0.760256 | Val Loss: 0.149078, Val Acc: 0.721649\n",
      "Epoch 9112 - Train Loss: 0.134244, Train Acc: 0.760256 | Val Loss: 0.149070, Val Acc: 0.721649\n",
      "Epoch 9113 - Train Loss: 0.134235, Train Acc: 0.760256 | Val Loss: 0.149062, Val Acc: 0.721649\n",
      "Epoch 9114 - Train Loss: 0.134226, Train Acc: 0.760256 | Val Loss: 0.149054, Val Acc: 0.721649\n",
      "Epoch 9115 - Train Loss: 0.134216, Train Acc: 0.760256 | Val Loss: 0.149047, Val Acc: 0.721649\n",
      "Epoch 9116 - Train Loss: 0.134207, Train Acc: 0.760256 | Val Loss: 0.149039, Val Acc: 0.721649\n",
      "Epoch 9117 - Train Loss: 0.134198, Train Acc: 0.760256 | Val Loss: 0.149031, Val Acc: 0.721649\n",
      "Epoch 9118 - Train Loss: 0.134188, Train Acc: 0.760256 | Val Loss: 0.149023, Val Acc: 0.721649\n",
      "Epoch 9119 - Train Loss: 0.134179, Train Acc: 0.760256 | Val Loss: 0.149015, Val Acc: 0.721649\n",
      "Epoch 9120 - Train Loss: 0.134170, Train Acc: 0.760256 | Val Loss: 0.149007, Val Acc: 0.721649\n",
      "Epoch 9121 - Train Loss: 0.134161, Train Acc: 0.760256 | Val Loss: 0.148999, Val Acc: 0.721649\n",
      "Epoch 9122 - Train Loss: 0.134151, Train Acc: 0.760256 | Val Loss: 0.148992, Val Acc: 0.721649\n",
      "Epoch 9123 - Train Loss: 0.134142, Train Acc: 0.760256 | Val Loss: 0.148984, Val Acc: 0.721649\n",
      "Epoch 9124 - Train Loss: 0.134133, Train Acc: 0.760256 | Val Loss: 0.148976, Val Acc: 0.721649\n",
      "Epoch 9125 - Train Loss: 0.134124, Train Acc: 0.760256 | Val Loss: 0.148968, Val Acc: 0.721649\n",
      "Epoch 9126 - Train Loss: 0.134114, Train Acc: 0.760256 | Val Loss: 0.148960, Val Acc: 0.721649\n",
      "Epoch 9127 - Train Loss: 0.134105, Train Acc: 0.760256 | Val Loss: 0.148952, Val Acc: 0.721649\n",
      "Epoch 9128 - Train Loss: 0.134096, Train Acc: 0.760256 | Val Loss: 0.148945, Val Acc: 0.721649\n",
      "Epoch 9129 - Train Loss: 0.134087, Train Acc: 0.760256 | Val Loss: 0.148937, Val Acc: 0.721649\n",
      "Epoch 9130 - Train Loss: 0.134077, Train Acc: 0.760256 | Val Loss: 0.148929, Val Acc: 0.721649\n",
      "Epoch 9131 - Train Loss: 0.134068, Train Acc: 0.760256 | Val Loss: 0.148921, Val Acc: 0.721649\n",
      "Epoch 9132 - Train Loss: 0.134059, Train Acc: 0.760256 | Val Loss: 0.148913, Val Acc: 0.721649\n",
      "Epoch 9133 - Train Loss: 0.134050, Train Acc: 0.760256 | Val Loss: 0.148905, Val Acc: 0.721649\n",
      "Epoch 9134 - Train Loss: 0.134041, Train Acc: 0.760256 | Val Loss: 0.148897, Val Acc: 0.721649\n",
      "Epoch 9135 - Train Loss: 0.134031, Train Acc: 0.760256 | Val Loss: 0.148890, Val Acc: 0.721649\n",
      "Epoch 9136 - Train Loss: 0.134022, Train Acc: 0.760256 | Val Loss: 0.148882, Val Acc: 0.721649\n",
      "Epoch 9137 - Train Loss: 0.134013, Train Acc: 0.760256 | Val Loss: 0.148874, Val Acc: 0.721649\n",
      "Epoch 9138 - Train Loss: 0.134004, Train Acc: 0.760256 | Val Loss: 0.148866, Val Acc: 0.721649\n",
      "Epoch 9139 - Train Loss: 0.133994, Train Acc: 0.760256 | Val Loss: 0.148858, Val Acc: 0.721649\n",
      "Epoch 9140 - Train Loss: 0.133985, Train Acc: 0.760256 | Val Loss: 0.148850, Val Acc: 0.721649\n",
      "Epoch 9141 - Train Loss: 0.133976, Train Acc: 0.760256 | Val Loss: 0.148843, Val Acc: 0.721649\n",
      "Epoch 9142 - Train Loss: 0.133967, Train Acc: 0.760256 | Val Loss: 0.148835, Val Acc: 0.721649\n",
      "Epoch 9143 - Train Loss: 0.133957, Train Acc: 0.760256 | Val Loss: 0.148827, Val Acc: 0.721649\n",
      "Epoch 9144 - Train Loss: 0.133948, Train Acc: 0.760256 | Val Loss: 0.148819, Val Acc: 0.721649\n",
      "Epoch 9145 - Train Loss: 0.133939, Train Acc: 0.760256 | Val Loss: 0.148811, Val Acc: 0.721649\n",
      "Epoch 9146 - Train Loss: 0.133930, Train Acc: 0.760256 | Val Loss: 0.148803, Val Acc: 0.721649\n",
      "Epoch 9147 - Train Loss: 0.133920, Train Acc: 0.760256 | Val Loss: 0.148796, Val Acc: 0.721649\n",
      "Epoch 9148 - Train Loss: 0.133911, Train Acc: 0.760256 | Val Loss: 0.148788, Val Acc: 0.721649\n",
      "Epoch 9149 - Train Loss: 0.133902, Train Acc: 0.760256 | Val Loss: 0.148780, Val Acc: 0.721649\n",
      "Epoch 9150 - Train Loss: 0.133893, Train Acc: 0.760256 | Val Loss: 0.148772, Val Acc: 0.721649\n",
      "Epoch 9151 - Train Loss: 0.133884, Train Acc: 0.760256 | Val Loss: 0.148764, Val Acc: 0.721649\n",
      "Epoch 9152 - Train Loss: 0.133874, Train Acc: 0.760256 | Val Loss: 0.148757, Val Acc: 0.721649\n",
      "Epoch 9153 - Train Loss: 0.133865, Train Acc: 0.760256 | Val Loss: 0.148749, Val Acc: 0.721649\n",
      "Epoch 9154 - Train Loss: 0.133856, Train Acc: 0.760256 | Val Loss: 0.148741, Val Acc: 0.721649\n",
      "Epoch 9155 - Train Loss: 0.133847, Train Acc: 0.760256 | Val Loss: 0.148733, Val Acc: 0.721649\n",
      "Epoch 9156 - Train Loss: 0.133838, Train Acc: 0.760256 | Val Loss: 0.148725, Val Acc: 0.721649\n",
      "Epoch 9157 - Train Loss: 0.133828, Train Acc: 0.760256 | Val Loss: 0.148718, Val Acc: 0.721649\n",
      "Epoch 9158 - Train Loss: 0.133819, Train Acc: 0.760256 | Val Loss: 0.148710, Val Acc: 0.721649\n",
      "Epoch 9159 - Train Loss: 0.133810, Train Acc: 0.760256 | Val Loss: 0.148702, Val Acc: 0.721649\n",
      "Epoch 9160 - Train Loss: 0.133801, Train Acc: 0.760256 | Val Loss: 0.148694, Val Acc: 0.721649\n",
      "Epoch 9161 - Train Loss: 0.133791, Train Acc: 0.760256 | Val Loss: 0.148686, Val Acc: 0.721649\n",
      "Epoch 9162 - Train Loss: 0.133782, Train Acc: 0.760256 | Val Loss: 0.148678, Val Acc: 0.721649\n",
      "Epoch 9163 - Train Loss: 0.133773, Train Acc: 0.760256 | Val Loss: 0.148671, Val Acc: 0.721649\n",
      "Epoch 9164 - Train Loss: 0.133764, Train Acc: 0.760256 | Val Loss: 0.148663, Val Acc: 0.721649\n",
      "Epoch 9165 - Train Loss: 0.133755, Train Acc: 0.760256 | Val Loss: 0.148655, Val Acc: 0.721649\n",
      "Epoch 9166 - Train Loss: 0.133745, Train Acc: 0.760256 | Val Loss: 0.148647, Val Acc: 0.721649\n",
      "Epoch 9167 - Train Loss: 0.133736, Train Acc: 0.760256 | Val Loss: 0.148639, Val Acc: 0.721649\n",
      "Epoch 9168 - Train Loss: 0.133727, Train Acc: 0.760256 | Val Loss: 0.148632, Val Acc: 0.721649\n",
      "Epoch 9169 - Train Loss: 0.133718, Train Acc: 0.760256 | Val Loss: 0.148624, Val Acc: 0.721649\n",
      "Epoch 9170 - Train Loss: 0.133709, Train Acc: 0.761538 | Val Loss: 0.148616, Val Acc: 0.721649\n",
      "Epoch 9171 - Train Loss: 0.133699, Train Acc: 0.761538 | Val Loss: 0.148608, Val Acc: 0.721649\n",
      "Epoch 9172 - Train Loss: 0.133690, Train Acc: 0.761538 | Val Loss: 0.148601, Val Acc: 0.721649\n",
      "Epoch 9173 - Train Loss: 0.133681, Train Acc: 0.761538 | Val Loss: 0.148593, Val Acc: 0.721649\n",
      "Epoch 9174 - Train Loss: 0.133672, Train Acc: 0.761538 | Val Loss: 0.148585, Val Acc: 0.721649\n",
      "Epoch 9175 - Train Loss: 0.133663, Train Acc: 0.761538 | Val Loss: 0.148577, Val Acc: 0.721649\n",
      "Epoch 9176 - Train Loss: 0.133653, Train Acc: 0.761538 | Val Loss: 0.148569, Val Acc: 0.721649\n",
      "Epoch 9177 - Train Loss: 0.133644, Train Acc: 0.761538 | Val Loss: 0.148562, Val Acc: 0.721649\n",
      "Epoch 9178 - Train Loss: 0.133635, Train Acc: 0.761538 | Val Loss: 0.148554, Val Acc: 0.721649\n",
      "Epoch 9179 - Train Loss: 0.133626, Train Acc: 0.761538 | Val Loss: 0.148546, Val Acc: 0.721649\n",
      "Epoch 9180 - Train Loss: 0.133617, Train Acc: 0.761538 | Val Loss: 0.148538, Val Acc: 0.721649\n",
      "Epoch 9181 - Train Loss: 0.133607, Train Acc: 0.761538 | Val Loss: 0.148530, Val Acc: 0.721649\n",
      "Epoch 9182 - Train Loss: 0.133598, Train Acc: 0.761538 | Val Loss: 0.148523, Val Acc: 0.721649\n",
      "Epoch 9183 - Train Loss: 0.133589, Train Acc: 0.761538 | Val Loss: 0.148515, Val Acc: 0.721649\n",
      "Epoch 9184 - Train Loss: 0.133580, Train Acc: 0.761538 | Val Loss: 0.148507, Val Acc: 0.721649\n",
      "Epoch 9185 - Train Loss: 0.133571, Train Acc: 0.761538 | Val Loss: 0.148499, Val Acc: 0.721649\n",
      "Epoch 9186 - Train Loss: 0.133562, Train Acc: 0.761538 | Val Loss: 0.148492, Val Acc: 0.721649\n",
      "Epoch 9187 - Train Loss: 0.133552, Train Acc: 0.761538 | Val Loss: 0.148484, Val Acc: 0.721649\n",
      "Epoch 9188 - Train Loss: 0.133543, Train Acc: 0.761538 | Val Loss: 0.148476, Val Acc: 0.721649\n",
      "Epoch 9189 - Train Loss: 0.133534, Train Acc: 0.761538 | Val Loss: 0.148468, Val Acc: 0.721649\n",
      "Epoch 9190 - Train Loss: 0.133525, Train Acc: 0.761538 | Val Loss: 0.148460, Val Acc: 0.721649\n",
      "Epoch 9191 - Train Loss: 0.133516, Train Acc: 0.761538 | Val Loss: 0.148453, Val Acc: 0.721649\n",
      "Epoch 9192 - Train Loss: 0.133507, Train Acc: 0.761538 | Val Loss: 0.148445, Val Acc: 0.721649\n",
      "Epoch 9193 - Train Loss: 0.133497, Train Acc: 0.761538 | Val Loss: 0.148437, Val Acc: 0.721649\n",
      "Epoch 9194 - Train Loss: 0.133488, Train Acc: 0.761538 | Val Loss: 0.148429, Val Acc: 0.721649\n",
      "Epoch 9195 - Train Loss: 0.133479, Train Acc: 0.761538 | Val Loss: 0.148422, Val Acc: 0.721649\n",
      "Epoch 9196 - Train Loss: 0.133470, Train Acc: 0.761538 | Val Loss: 0.148414, Val Acc: 0.721649\n",
      "Epoch 9197 - Train Loss: 0.133461, Train Acc: 0.761538 | Val Loss: 0.148406, Val Acc: 0.721649\n",
      "Epoch 9198 - Train Loss: 0.133451, Train Acc: 0.761538 | Val Loss: 0.148398, Val Acc: 0.721649\n",
      "Epoch 9199 - Train Loss: 0.133442, Train Acc: 0.761538 | Val Loss: 0.148390, Val Acc: 0.721649\n",
      "Epoch 9200 - Train Loss: 0.133433, Train Acc: 0.761538 | Val Loss: 0.148383, Val Acc: 0.721649\n",
      "Epoch 9201 - Train Loss: 0.133424, Train Acc: 0.761538 | Val Loss: 0.148375, Val Acc: 0.721649\n",
      "Epoch 9202 - Train Loss: 0.133415, Train Acc: 0.761538 | Val Loss: 0.148367, Val Acc: 0.721649\n",
      "Epoch 9203 - Train Loss: 0.133406, Train Acc: 0.761538 | Val Loss: 0.148359, Val Acc: 0.721649\n",
      "Epoch 9204 - Train Loss: 0.133396, Train Acc: 0.761538 | Val Loss: 0.148352, Val Acc: 0.721649\n",
      "Epoch 9205 - Train Loss: 0.133387, Train Acc: 0.761538 | Val Loss: 0.148344, Val Acc: 0.721649\n",
      "Epoch 9206 - Train Loss: 0.133378, Train Acc: 0.761538 | Val Loss: 0.148336, Val Acc: 0.721649\n",
      "Epoch 9207 - Train Loss: 0.133369, Train Acc: 0.761538 | Val Loss: 0.148328, Val Acc: 0.721649\n",
      "Epoch 9208 - Train Loss: 0.133360, Train Acc: 0.761538 | Val Loss: 0.148321, Val Acc: 0.721649\n",
      "Epoch 9209 - Train Loss: 0.133351, Train Acc: 0.761538 | Val Loss: 0.148313, Val Acc: 0.721649\n",
      "Epoch 9210 - Train Loss: 0.133342, Train Acc: 0.761538 | Val Loss: 0.148305, Val Acc: 0.721649\n",
      "Epoch 9211 - Train Loss: 0.133332, Train Acc: 0.761538 | Val Loss: 0.148297, Val Acc: 0.721649\n",
      "Epoch 9212 - Train Loss: 0.133323, Train Acc: 0.761538 | Val Loss: 0.148290, Val Acc: 0.721649\n",
      "Epoch 9213 - Train Loss: 0.133314, Train Acc: 0.761538 | Val Loss: 0.148282, Val Acc: 0.721649\n",
      "Epoch 9214 - Train Loss: 0.133305, Train Acc: 0.761538 | Val Loss: 0.148274, Val Acc: 0.721649\n",
      "Epoch 9215 - Train Loss: 0.133296, Train Acc: 0.761538 | Val Loss: 0.148266, Val Acc: 0.721649\n",
      "Epoch 9216 - Train Loss: 0.133287, Train Acc: 0.761538 | Val Loss: 0.148259, Val Acc: 0.721649\n",
      "Epoch 9217 - Train Loss: 0.133278, Train Acc: 0.761538 | Val Loss: 0.148251, Val Acc: 0.721649\n",
      "Epoch 9218 - Train Loss: 0.133268, Train Acc: 0.761538 | Val Loss: 0.148243, Val Acc: 0.721649\n",
      "Epoch 9219 - Train Loss: 0.133259, Train Acc: 0.761538 | Val Loss: 0.148235, Val Acc: 0.721649\n",
      "Epoch 9220 - Train Loss: 0.133250, Train Acc: 0.761538 | Val Loss: 0.148228, Val Acc: 0.721649\n",
      "Epoch 9221 - Train Loss: 0.133241, Train Acc: 0.761538 | Val Loss: 0.148220, Val Acc: 0.721649\n",
      "Epoch 9222 - Train Loss: 0.133232, Train Acc: 0.761538 | Val Loss: 0.148212, Val Acc: 0.721649\n",
      "Epoch 9223 - Train Loss: 0.133223, Train Acc: 0.761538 | Val Loss: 0.148204, Val Acc: 0.721649\n",
      "Epoch 9224 - Train Loss: 0.133213, Train Acc: 0.761538 | Val Loss: 0.148197, Val Acc: 0.721649\n",
      "Epoch 9225 - Train Loss: 0.133204, Train Acc: 0.761538 | Val Loss: 0.148189, Val Acc: 0.721649\n",
      "Epoch 9226 - Train Loss: 0.133195, Train Acc: 0.761538 | Val Loss: 0.148181, Val Acc: 0.721649\n",
      "Epoch 9227 - Train Loss: 0.133186, Train Acc: 0.761538 | Val Loss: 0.148173, Val Acc: 0.721649\n",
      "Epoch 9228 - Train Loss: 0.133177, Train Acc: 0.761538 | Val Loss: 0.148166, Val Acc: 0.721649\n",
      "Epoch 9229 - Train Loss: 0.133168, Train Acc: 0.761538 | Val Loss: 0.148158, Val Acc: 0.721649\n",
      "Epoch 9230 - Train Loss: 0.133159, Train Acc: 0.761538 | Val Loss: 0.148150, Val Acc: 0.721649\n",
      "Epoch 9231 - Train Loss: 0.133150, Train Acc: 0.761538 | Val Loss: 0.148143, Val Acc: 0.721649\n",
      "Epoch 9232 - Train Loss: 0.133140, Train Acc: 0.761538 | Val Loss: 0.148135, Val Acc: 0.721649\n",
      "Epoch 9233 - Train Loss: 0.133131, Train Acc: 0.761538 | Val Loss: 0.148127, Val Acc: 0.721649\n",
      "Epoch 9234 - Train Loss: 0.133122, Train Acc: 0.761538 | Val Loss: 0.148119, Val Acc: 0.721649\n",
      "Epoch 9235 - Train Loss: 0.133113, Train Acc: 0.761538 | Val Loss: 0.148112, Val Acc: 0.721649\n",
      "Epoch 9236 - Train Loss: 0.133104, Train Acc: 0.761538 | Val Loss: 0.148104, Val Acc: 0.721649\n",
      "Epoch 9237 - Train Loss: 0.133095, Train Acc: 0.761538 | Val Loss: 0.148096, Val Acc: 0.721649\n",
      "Epoch 9238 - Train Loss: 0.133086, Train Acc: 0.761538 | Val Loss: 0.148088, Val Acc: 0.721649\n",
      "Epoch 9239 - Train Loss: 0.133077, Train Acc: 0.761538 | Val Loss: 0.148081, Val Acc: 0.721649\n",
      "Epoch 9240 - Train Loss: 0.133067, Train Acc: 0.761538 | Val Loss: 0.148073, Val Acc: 0.721649\n",
      "Epoch 9241 - Train Loss: 0.133058, Train Acc: 0.761538 | Val Loss: 0.148065, Val Acc: 0.721649\n",
      "Epoch 9242 - Train Loss: 0.133049, Train Acc: 0.761538 | Val Loss: 0.148058, Val Acc: 0.721649\n",
      "Epoch 9243 - Train Loss: 0.133040, Train Acc: 0.761538 | Val Loss: 0.148050, Val Acc: 0.721649\n",
      "Epoch 9244 - Train Loss: 0.133031, Train Acc: 0.762821 | Val Loss: 0.148042, Val Acc: 0.721649\n",
      "Epoch 9245 - Train Loss: 0.133022, Train Acc: 0.762821 | Val Loss: 0.148034, Val Acc: 0.721649\n",
      "Epoch 9246 - Train Loss: 0.133013, Train Acc: 0.762821 | Val Loss: 0.148027, Val Acc: 0.721649\n",
      "Epoch 9247 - Train Loss: 0.133004, Train Acc: 0.762821 | Val Loss: 0.148019, Val Acc: 0.721649\n",
      "Epoch 9248 - Train Loss: 0.132994, Train Acc: 0.762821 | Val Loss: 0.148011, Val Acc: 0.721649\n",
      "Epoch 9249 - Train Loss: 0.132985, Train Acc: 0.762821 | Val Loss: 0.148004, Val Acc: 0.721649\n",
      "Epoch 9250 - Train Loss: 0.132976, Train Acc: 0.762821 | Val Loss: 0.147996, Val Acc: 0.721649\n",
      "Epoch 9251 - Train Loss: 0.132967, Train Acc: 0.762821 | Val Loss: 0.147988, Val Acc: 0.721649\n",
      "Epoch 9252 - Train Loss: 0.132958, Train Acc: 0.762821 | Val Loss: 0.147980, Val Acc: 0.721649\n",
      "Epoch 9253 - Train Loss: 0.132949, Train Acc: 0.762821 | Val Loss: 0.147973, Val Acc: 0.721649\n",
      "Epoch 9254 - Train Loss: 0.132940, Train Acc: 0.762821 | Val Loss: 0.147965, Val Acc: 0.721649\n",
      "Epoch 9255 - Train Loss: 0.132931, Train Acc: 0.762821 | Val Loss: 0.147957, Val Acc: 0.721649\n",
      "Epoch 9256 - Train Loss: 0.132922, Train Acc: 0.762821 | Val Loss: 0.147950, Val Acc: 0.721649\n",
      "Epoch 9257 - Train Loss: 0.132913, Train Acc: 0.762821 | Val Loss: 0.147942, Val Acc: 0.721649\n",
      "Epoch 9258 - Train Loss: 0.132903, Train Acc: 0.762821 | Val Loss: 0.147934, Val Acc: 0.721649\n",
      "Epoch 9259 - Train Loss: 0.132894, Train Acc: 0.762821 | Val Loss: 0.147927, Val Acc: 0.721649\n",
      "Epoch 9260 - Train Loss: 0.132885, Train Acc: 0.762821 | Val Loss: 0.147919, Val Acc: 0.721649\n",
      "Epoch 9261 - Train Loss: 0.132876, Train Acc: 0.762821 | Val Loss: 0.147911, Val Acc: 0.721649\n",
      "Epoch 9262 - Train Loss: 0.132867, Train Acc: 0.762821 | Val Loss: 0.147903, Val Acc: 0.721649\n",
      "Epoch 9263 - Train Loss: 0.132858, Train Acc: 0.762821 | Val Loss: 0.147896, Val Acc: 0.721649\n",
      "Epoch 9264 - Train Loss: 0.132849, Train Acc: 0.762821 | Val Loss: 0.147888, Val Acc: 0.721649\n",
      "Epoch 9265 - Train Loss: 0.132840, Train Acc: 0.762821 | Val Loss: 0.147880, Val Acc: 0.721649\n",
      "Epoch 9266 - Train Loss: 0.132831, Train Acc: 0.762821 | Val Loss: 0.147873, Val Acc: 0.721649\n",
      "Epoch 9267 - Train Loss: 0.132822, Train Acc: 0.762821 | Val Loss: 0.147865, Val Acc: 0.721649\n",
      "Epoch 9268 - Train Loss: 0.132812, Train Acc: 0.762821 | Val Loss: 0.147857, Val Acc: 0.721649\n",
      "Epoch 9269 - Train Loss: 0.132803, Train Acc: 0.762821 | Val Loss: 0.147850, Val Acc: 0.721649\n",
      "Epoch 9270 - Train Loss: 0.132794, Train Acc: 0.762821 | Val Loss: 0.147842, Val Acc: 0.721649\n",
      "Epoch 9271 - Train Loss: 0.132785, Train Acc: 0.762821 | Val Loss: 0.147834, Val Acc: 0.721649\n",
      "Epoch 9272 - Train Loss: 0.132776, Train Acc: 0.762821 | Val Loss: 0.147826, Val Acc: 0.721649\n",
      "Epoch 9273 - Train Loss: 0.132767, Train Acc: 0.762821 | Val Loss: 0.147819, Val Acc: 0.721649\n",
      "Epoch 9274 - Train Loss: 0.132758, Train Acc: 0.762821 | Val Loss: 0.147811, Val Acc: 0.721649\n",
      "Epoch 9275 - Train Loss: 0.132749, Train Acc: 0.762821 | Val Loss: 0.147803, Val Acc: 0.721649\n",
      "Epoch 9276 - Train Loss: 0.132740, Train Acc: 0.762821 | Val Loss: 0.147796, Val Acc: 0.721649\n",
      "Epoch 9277 - Train Loss: 0.132731, Train Acc: 0.762821 | Val Loss: 0.147788, Val Acc: 0.721649\n",
      "Epoch 9278 - Train Loss: 0.132722, Train Acc: 0.762821 | Val Loss: 0.147780, Val Acc: 0.721649\n",
      "Epoch 9279 - Train Loss: 0.132713, Train Acc: 0.762821 | Val Loss: 0.147773, Val Acc: 0.721649\n",
      "Epoch 9280 - Train Loss: 0.132703, Train Acc: 0.762821 | Val Loss: 0.147765, Val Acc: 0.721649\n",
      "Epoch 9281 - Train Loss: 0.132694, Train Acc: 0.762821 | Val Loss: 0.147757, Val Acc: 0.721649\n",
      "Epoch 9282 - Train Loss: 0.132685, Train Acc: 0.761538 | Val Loss: 0.147750, Val Acc: 0.721649\n",
      "Epoch 9283 - Train Loss: 0.132676, Train Acc: 0.761538 | Val Loss: 0.147742, Val Acc: 0.721649\n",
      "Epoch 9284 - Train Loss: 0.132667, Train Acc: 0.761538 | Val Loss: 0.147734, Val Acc: 0.721649\n",
      "Epoch 9285 - Train Loss: 0.132658, Train Acc: 0.761538 | Val Loss: 0.147727, Val Acc: 0.721649\n",
      "Epoch 9286 - Train Loss: 0.132649, Train Acc: 0.761538 | Val Loss: 0.147719, Val Acc: 0.721649\n",
      "Epoch 9287 - Train Loss: 0.132640, Train Acc: 0.761538 | Val Loss: 0.147711, Val Acc: 0.721649\n",
      "Epoch 9288 - Train Loss: 0.132631, Train Acc: 0.761538 | Val Loss: 0.147704, Val Acc: 0.721649\n",
      "Epoch 9289 - Train Loss: 0.132622, Train Acc: 0.761538 | Val Loss: 0.147696, Val Acc: 0.721649\n",
      "Epoch 9290 - Train Loss: 0.132613, Train Acc: 0.761538 | Val Loss: 0.147688, Val Acc: 0.721649\n",
      "Epoch 9291 - Train Loss: 0.132604, Train Acc: 0.761538 | Val Loss: 0.147681, Val Acc: 0.721649\n",
      "Epoch 9292 - Train Loss: 0.132595, Train Acc: 0.761538 | Val Loss: 0.147673, Val Acc: 0.721649\n",
      "Epoch 9293 - Train Loss: 0.132586, Train Acc: 0.761538 | Val Loss: 0.147665, Val Acc: 0.721649\n",
      "Epoch 9294 - Train Loss: 0.132576, Train Acc: 0.761538 | Val Loss: 0.147658, Val Acc: 0.721649\n",
      "Epoch 9295 - Train Loss: 0.132567, Train Acc: 0.761538 | Val Loss: 0.147650, Val Acc: 0.721649\n",
      "Epoch 9296 - Train Loss: 0.132558, Train Acc: 0.761538 | Val Loss: 0.147642, Val Acc: 0.721649\n",
      "Epoch 9297 - Train Loss: 0.132549, Train Acc: 0.761538 | Val Loss: 0.147635, Val Acc: 0.721649\n",
      "Epoch 9298 - Train Loss: 0.132540, Train Acc: 0.761538 | Val Loss: 0.147627, Val Acc: 0.721649\n",
      "Epoch 9299 - Train Loss: 0.132531, Train Acc: 0.761538 | Val Loss: 0.147619, Val Acc: 0.721649\n",
      "Epoch 9300 - Train Loss: 0.132522, Train Acc: 0.762821 | Val Loss: 0.147612, Val Acc: 0.721649\n",
      "Epoch 9301 - Train Loss: 0.132513, Train Acc: 0.762821 | Val Loss: 0.147604, Val Acc: 0.721649\n",
      "Epoch 9302 - Train Loss: 0.132504, Train Acc: 0.762821 | Val Loss: 0.147596, Val Acc: 0.721649\n",
      "Epoch 9303 - Train Loss: 0.132495, Train Acc: 0.762821 | Val Loss: 0.147589, Val Acc: 0.721649\n",
      "Epoch 9304 - Train Loss: 0.132486, Train Acc: 0.762821 | Val Loss: 0.147581, Val Acc: 0.721649\n",
      "Epoch 9305 - Train Loss: 0.132477, Train Acc: 0.762821 | Val Loss: 0.147573, Val Acc: 0.721649\n",
      "Epoch 9306 - Train Loss: 0.132468, Train Acc: 0.762821 | Val Loss: 0.147566, Val Acc: 0.721649\n",
      "Epoch 9307 - Train Loss: 0.132459, Train Acc: 0.762821 | Val Loss: 0.147558, Val Acc: 0.721649\n",
      "Epoch 9308 - Train Loss: 0.132450, Train Acc: 0.762821 | Val Loss: 0.147550, Val Acc: 0.721649\n",
      "Epoch 9309 - Train Loss: 0.132441, Train Acc: 0.762821 | Val Loss: 0.147543, Val Acc: 0.721649\n",
      "Epoch 9310 - Train Loss: 0.132432, Train Acc: 0.762821 | Val Loss: 0.147535, Val Acc: 0.721649\n",
      "Epoch 9311 - Train Loss: 0.132423, Train Acc: 0.762821 | Val Loss: 0.147528, Val Acc: 0.721649\n",
      "Epoch 9312 - Train Loss: 0.132414, Train Acc: 0.762821 | Val Loss: 0.147520, Val Acc: 0.721649\n",
      "Epoch 9313 - Train Loss: 0.132405, Train Acc: 0.762821 | Val Loss: 0.147512, Val Acc: 0.721649\n",
      "Epoch 9314 - Train Loss: 0.132396, Train Acc: 0.762821 | Val Loss: 0.147505, Val Acc: 0.721649\n",
      "Epoch 9315 - Train Loss: 0.132386, Train Acc: 0.762821 | Val Loss: 0.147497, Val Acc: 0.721649\n",
      "Epoch 9316 - Train Loss: 0.132377, Train Acc: 0.762821 | Val Loss: 0.147489, Val Acc: 0.721649\n",
      "Epoch 9317 - Train Loss: 0.132368, Train Acc: 0.762821 | Val Loss: 0.147482, Val Acc: 0.721649\n",
      "Epoch 9318 - Train Loss: 0.132359, Train Acc: 0.762821 | Val Loss: 0.147474, Val Acc: 0.721649\n",
      "Epoch 9319 - Train Loss: 0.132350, Train Acc: 0.762821 | Val Loss: 0.147466, Val Acc: 0.721649\n",
      "Epoch 9320 - Train Loss: 0.132341, Train Acc: 0.762821 | Val Loss: 0.147459, Val Acc: 0.721649\n",
      "Epoch 9321 - Train Loss: 0.132332, Train Acc: 0.762821 | Val Loss: 0.147451, Val Acc: 0.721649\n",
      "Epoch 9322 - Train Loss: 0.132323, Train Acc: 0.762821 | Val Loss: 0.147443, Val Acc: 0.721649\n",
      "Epoch 9323 - Train Loss: 0.132314, Train Acc: 0.762821 | Val Loss: 0.147436, Val Acc: 0.721649\n",
      "Epoch 9324 - Train Loss: 0.132305, Train Acc: 0.762821 | Val Loss: 0.147428, Val Acc: 0.721649\n",
      "Epoch 9325 - Train Loss: 0.132296, Train Acc: 0.762821 | Val Loss: 0.147421, Val Acc: 0.721649\n",
      "Epoch 9326 - Train Loss: 0.132287, Train Acc: 0.762821 | Val Loss: 0.147413, Val Acc: 0.721649\n",
      "Epoch 9327 - Train Loss: 0.132278, Train Acc: 0.762821 | Val Loss: 0.147405, Val Acc: 0.721649\n",
      "Epoch 9328 - Train Loss: 0.132269, Train Acc: 0.762821 | Val Loss: 0.147398, Val Acc: 0.721649\n",
      "Epoch 9329 - Train Loss: 0.132260, Train Acc: 0.762821 | Val Loss: 0.147390, Val Acc: 0.721649\n",
      "Epoch 9330 - Train Loss: 0.132251, Train Acc: 0.764103 | Val Loss: 0.147382, Val Acc: 0.721649\n",
      "Epoch 9331 - Train Loss: 0.132242, Train Acc: 0.764103 | Val Loss: 0.147375, Val Acc: 0.721649\n",
      "Epoch 9332 - Train Loss: 0.132233, Train Acc: 0.764103 | Val Loss: 0.147367, Val Acc: 0.721649\n",
      "Epoch 9333 - Train Loss: 0.132224, Train Acc: 0.764103 | Val Loss: 0.147360, Val Acc: 0.721649\n",
      "Epoch 9334 - Train Loss: 0.132215, Train Acc: 0.764103 | Val Loss: 0.147352, Val Acc: 0.721649\n",
      "Epoch 9335 - Train Loss: 0.132206, Train Acc: 0.764103 | Val Loss: 0.147344, Val Acc: 0.721649\n",
      "Epoch 9336 - Train Loss: 0.132197, Train Acc: 0.764103 | Val Loss: 0.147337, Val Acc: 0.721649\n",
      "Epoch 9337 - Train Loss: 0.132188, Train Acc: 0.764103 | Val Loss: 0.147329, Val Acc: 0.721649\n",
      "Epoch 9338 - Train Loss: 0.132179, Train Acc: 0.764103 | Val Loss: 0.147321, Val Acc: 0.721649\n",
      "Epoch 9339 - Train Loss: 0.132170, Train Acc: 0.764103 | Val Loss: 0.147314, Val Acc: 0.721649\n",
      "Epoch 9340 - Train Loss: 0.132161, Train Acc: 0.764103 | Val Loss: 0.147306, Val Acc: 0.721649\n",
      "Epoch 9341 - Train Loss: 0.132152, Train Acc: 0.764103 | Val Loss: 0.147299, Val Acc: 0.721649\n",
      "Epoch 9342 - Train Loss: 0.132143, Train Acc: 0.765385 | Val Loss: 0.147291, Val Acc: 0.721649\n",
      "Epoch 9343 - Train Loss: 0.132134, Train Acc: 0.765385 | Val Loss: 0.147283, Val Acc: 0.721649\n",
      "Epoch 9344 - Train Loss: 0.132125, Train Acc: 0.765385 | Val Loss: 0.147276, Val Acc: 0.721649\n",
      "Epoch 9345 - Train Loss: 0.132116, Train Acc: 0.765385 | Val Loss: 0.147268, Val Acc: 0.721649\n",
      "Epoch 9346 - Train Loss: 0.132107, Train Acc: 0.765385 | Val Loss: 0.147261, Val Acc: 0.721649\n",
      "Epoch 9347 - Train Loss: 0.132098, Train Acc: 0.765385 | Val Loss: 0.147253, Val Acc: 0.721649\n",
      "Epoch 9348 - Train Loss: 0.132089, Train Acc: 0.765385 | Val Loss: 0.147245, Val Acc: 0.721649\n",
      "Epoch 9349 - Train Loss: 0.132080, Train Acc: 0.765385 | Val Loss: 0.147238, Val Acc: 0.721649\n",
      "Epoch 9350 - Train Loss: 0.132071, Train Acc: 0.765385 | Val Loss: 0.147230, Val Acc: 0.721649\n",
      "Epoch 9351 - Train Loss: 0.132062, Train Acc: 0.765385 | Val Loss: 0.147223, Val Acc: 0.721649\n",
      "Epoch 9352 - Train Loss: 0.132053, Train Acc: 0.765385 | Val Loss: 0.147215, Val Acc: 0.721649\n",
      "Epoch 9353 - Train Loss: 0.132044, Train Acc: 0.765385 | Val Loss: 0.147207, Val Acc: 0.721649\n",
      "Epoch 9354 - Train Loss: 0.132035, Train Acc: 0.765385 | Val Loss: 0.147200, Val Acc: 0.721649\n",
      "Epoch 9355 - Train Loss: 0.132026, Train Acc: 0.765385 | Val Loss: 0.147192, Val Acc: 0.721649\n",
      "Epoch 9356 - Train Loss: 0.132017, Train Acc: 0.765385 | Val Loss: 0.147185, Val Acc: 0.721649\n",
      "Epoch 9357 - Train Loss: 0.132008, Train Acc: 0.766667 | Val Loss: 0.147177, Val Acc: 0.721649\n",
      "Epoch 9358 - Train Loss: 0.131999, Train Acc: 0.766667 | Val Loss: 0.147169, Val Acc: 0.721649\n",
      "Epoch 9359 - Train Loss: 0.131990, Train Acc: 0.766667 | Val Loss: 0.147162, Val Acc: 0.721649\n",
      "Epoch 9360 - Train Loss: 0.131981, Train Acc: 0.766667 | Val Loss: 0.147154, Val Acc: 0.721649\n",
      "Epoch 9361 - Train Loss: 0.131972, Train Acc: 0.766667 | Val Loss: 0.147147, Val Acc: 0.721649\n",
      "Epoch 9362 - Train Loss: 0.131963, Train Acc: 0.766667 | Val Loss: 0.147139, Val Acc: 0.721649\n",
      "Epoch 9363 - Train Loss: 0.131954, Train Acc: 0.766667 | Val Loss: 0.147131, Val Acc: 0.721649\n",
      "Epoch 9364 - Train Loss: 0.131945, Train Acc: 0.766667 | Val Loss: 0.147124, Val Acc: 0.721649\n",
      "Epoch 9365 - Train Loss: 0.131936, Train Acc: 0.766667 | Val Loss: 0.147116, Val Acc: 0.721649\n",
      "Epoch 9366 - Train Loss: 0.131927, Train Acc: 0.766667 | Val Loss: 0.147109, Val Acc: 0.721649\n",
      "Epoch 9367 - Train Loss: 0.131918, Train Acc: 0.766667 | Val Loss: 0.147101, Val Acc: 0.721649\n",
      "Epoch 9368 - Train Loss: 0.131909, Train Acc: 0.766667 | Val Loss: 0.147094, Val Acc: 0.721649\n",
      "Epoch 9369 - Train Loss: 0.131900, Train Acc: 0.766667 | Val Loss: 0.147086, Val Acc: 0.721649\n",
      "Epoch 9370 - Train Loss: 0.131891, Train Acc: 0.766667 | Val Loss: 0.147078, Val Acc: 0.721649\n",
      "Epoch 9371 - Train Loss: 0.131882, Train Acc: 0.766667 | Val Loss: 0.147071, Val Acc: 0.721649\n",
      "Epoch 9372 - Train Loss: 0.131873, Train Acc: 0.766667 | Val Loss: 0.147063, Val Acc: 0.721649\n",
      "Epoch 9373 - Train Loss: 0.131864, Train Acc: 0.766667 | Val Loss: 0.147056, Val Acc: 0.721649\n",
      "Epoch 9374 - Train Loss: 0.131855, Train Acc: 0.766667 | Val Loss: 0.147048, Val Acc: 0.721649\n",
      "Epoch 9375 - Train Loss: 0.131846, Train Acc: 0.766667 | Val Loss: 0.147040, Val Acc: 0.721649\n",
      "Epoch 9376 - Train Loss: 0.131837, Train Acc: 0.766667 | Val Loss: 0.147033, Val Acc: 0.721649\n",
      "Epoch 9377 - Train Loss: 0.131828, Train Acc: 0.766667 | Val Loss: 0.147025, Val Acc: 0.721649\n",
      "Epoch 9378 - Train Loss: 0.131819, Train Acc: 0.766667 | Val Loss: 0.147018, Val Acc: 0.721649\n",
      "Epoch 9379 - Train Loss: 0.131810, Train Acc: 0.766667 | Val Loss: 0.147010, Val Acc: 0.721649\n",
      "Epoch 9380 - Train Loss: 0.131801, Train Acc: 0.767949 | Val Loss: 0.147003, Val Acc: 0.721649\n",
      "Epoch 9381 - Train Loss: 0.131792, Train Acc: 0.767949 | Val Loss: 0.146995, Val Acc: 0.721649\n",
      "Epoch 9382 - Train Loss: 0.131784, Train Acc: 0.767949 | Val Loss: 0.146987, Val Acc: 0.721649\n",
      "Epoch 9383 - Train Loss: 0.131775, Train Acc: 0.767949 | Val Loss: 0.146980, Val Acc: 0.721649\n",
      "Epoch 9384 - Train Loss: 0.131766, Train Acc: 0.767949 | Val Loss: 0.146972, Val Acc: 0.721649\n",
      "Epoch 9385 - Train Loss: 0.131757, Train Acc: 0.767949 | Val Loss: 0.146965, Val Acc: 0.721649\n",
      "Epoch 9386 - Train Loss: 0.131748, Train Acc: 0.767949 | Val Loss: 0.146957, Val Acc: 0.721649\n",
      "Epoch 9387 - Train Loss: 0.131739, Train Acc: 0.767949 | Val Loss: 0.146950, Val Acc: 0.721649\n",
      "Epoch 9388 - Train Loss: 0.131730, Train Acc: 0.767949 | Val Loss: 0.146942, Val Acc: 0.721649\n",
      "Epoch 9389 - Train Loss: 0.131721, Train Acc: 0.767949 | Val Loss: 0.146935, Val Acc: 0.721649\n",
      "Epoch 9390 - Train Loss: 0.131712, Train Acc: 0.767949 | Val Loss: 0.146927, Val Acc: 0.721649\n",
      "Epoch 9391 - Train Loss: 0.131703, Train Acc: 0.767949 | Val Loss: 0.146919, Val Acc: 0.721649\n",
      "Epoch 9392 - Train Loss: 0.131694, Train Acc: 0.767949 | Val Loss: 0.146912, Val Acc: 0.721649\n",
      "Epoch 9393 - Train Loss: 0.131685, Train Acc: 0.767949 | Val Loss: 0.146904, Val Acc: 0.721649\n",
      "Epoch 9394 - Train Loss: 0.131676, Train Acc: 0.767949 | Val Loss: 0.146897, Val Acc: 0.721649\n",
      "Epoch 9395 - Train Loss: 0.131667, Train Acc: 0.767949 | Val Loss: 0.146889, Val Acc: 0.721649\n",
      "Epoch 9396 - Train Loss: 0.131658, Train Acc: 0.767949 | Val Loss: 0.146882, Val Acc: 0.721649\n",
      "Epoch 9397 - Train Loss: 0.131649, Train Acc: 0.767949 | Val Loss: 0.146874, Val Acc: 0.721649\n",
      "Epoch 9398 - Train Loss: 0.131640, Train Acc: 0.767949 | Val Loss: 0.146866, Val Acc: 0.721649\n",
      "Epoch 9399 - Train Loss: 0.131631, Train Acc: 0.767949 | Val Loss: 0.146859, Val Acc: 0.721649\n",
      "Epoch 9400 - Train Loss: 0.131622, Train Acc: 0.767949 | Val Loss: 0.146851, Val Acc: 0.721649\n",
      "Epoch 9401 - Train Loss: 0.131613, Train Acc: 0.767949 | Val Loss: 0.146844, Val Acc: 0.721649\n",
      "Epoch 9402 - Train Loss: 0.131605, Train Acc: 0.767949 | Val Loss: 0.146836, Val Acc: 0.721649\n",
      "Epoch 9403 - Train Loss: 0.131596, Train Acc: 0.767949 | Val Loss: 0.146829, Val Acc: 0.721649\n",
      "Epoch 9404 - Train Loss: 0.131587, Train Acc: 0.767949 | Val Loss: 0.146821, Val Acc: 0.721649\n",
      "Epoch 9405 - Train Loss: 0.131578, Train Acc: 0.767949 | Val Loss: 0.146814, Val Acc: 0.721649\n",
      "Epoch 9406 - Train Loss: 0.131569, Train Acc: 0.767949 | Val Loss: 0.146806, Val Acc: 0.721649\n",
      "Epoch 9407 - Train Loss: 0.131560, Train Acc: 0.767949 | Val Loss: 0.146799, Val Acc: 0.721649\n",
      "Epoch 9408 - Train Loss: 0.131551, Train Acc: 0.767949 | Val Loss: 0.146791, Val Acc: 0.721649\n",
      "Epoch 9409 - Train Loss: 0.131542, Train Acc: 0.767949 | Val Loss: 0.146783, Val Acc: 0.721649\n",
      "Epoch 9410 - Train Loss: 0.131533, Train Acc: 0.767949 | Val Loss: 0.146776, Val Acc: 0.721649\n",
      "Epoch 9411 - Train Loss: 0.131524, Train Acc: 0.767949 | Val Loss: 0.146768, Val Acc: 0.721649\n",
      "Epoch 9412 - Train Loss: 0.131515, Train Acc: 0.767949 | Val Loss: 0.146761, Val Acc: 0.721649\n",
      "Epoch 9413 - Train Loss: 0.131506, Train Acc: 0.767949 | Val Loss: 0.146753, Val Acc: 0.721649\n",
      "Epoch 9414 - Train Loss: 0.131497, Train Acc: 0.767949 | Val Loss: 0.146746, Val Acc: 0.721649\n",
      "Epoch 9415 - Train Loss: 0.131488, Train Acc: 0.767949 | Val Loss: 0.146738, Val Acc: 0.721649\n",
      "Epoch 9416 - Train Loss: 0.131479, Train Acc: 0.767949 | Val Loss: 0.146731, Val Acc: 0.721649\n",
      "Epoch 9417 - Train Loss: 0.131471, Train Acc: 0.767949 | Val Loss: 0.146723, Val Acc: 0.721649\n",
      "Epoch 9418 - Train Loss: 0.131462, Train Acc: 0.767949 | Val Loss: 0.146716, Val Acc: 0.721649\n",
      "Epoch 9419 - Train Loss: 0.131453, Train Acc: 0.767949 | Val Loss: 0.146708, Val Acc: 0.721649\n",
      "Epoch 9420 - Train Loss: 0.131444, Train Acc: 0.767949 | Val Loss: 0.146701, Val Acc: 0.721649\n",
      "Epoch 9421 - Train Loss: 0.131435, Train Acc: 0.767949 | Val Loss: 0.146693, Val Acc: 0.721649\n",
      "Epoch 9422 - Train Loss: 0.131426, Train Acc: 0.767949 | Val Loss: 0.146686, Val Acc: 0.721649\n",
      "Epoch 9423 - Train Loss: 0.131417, Train Acc: 0.767949 | Val Loss: 0.146678, Val Acc: 0.721649\n",
      "Epoch 9424 - Train Loss: 0.131408, Train Acc: 0.767949 | Val Loss: 0.146671, Val Acc: 0.721649\n",
      "Epoch 9425 - Train Loss: 0.131399, Train Acc: 0.767949 | Val Loss: 0.146663, Val Acc: 0.721649\n",
      "Epoch 9426 - Train Loss: 0.131390, Train Acc: 0.767949 | Val Loss: 0.146655, Val Acc: 0.721649\n",
      "Epoch 9427 - Train Loss: 0.131381, Train Acc: 0.767949 | Val Loss: 0.146648, Val Acc: 0.721649\n",
      "Epoch 9428 - Train Loss: 0.131372, Train Acc: 0.767949 | Val Loss: 0.146640, Val Acc: 0.721649\n",
      "Epoch 9429 - Train Loss: 0.131364, Train Acc: 0.767949 | Val Loss: 0.146633, Val Acc: 0.721649\n",
      "Epoch 9430 - Train Loss: 0.131355, Train Acc: 0.767949 | Val Loss: 0.146625, Val Acc: 0.721649\n",
      "Epoch 9431 - Train Loss: 0.131346, Train Acc: 0.767949 | Val Loss: 0.146618, Val Acc: 0.721649\n",
      "Epoch 9432 - Train Loss: 0.131337, Train Acc: 0.767949 | Val Loss: 0.146610, Val Acc: 0.721649\n",
      "Epoch 9433 - Train Loss: 0.131328, Train Acc: 0.767949 | Val Loss: 0.146603, Val Acc: 0.721649\n",
      "Epoch 9434 - Train Loss: 0.131319, Train Acc: 0.767949 | Val Loss: 0.146595, Val Acc: 0.721649\n",
      "Epoch 9435 - Train Loss: 0.131310, Train Acc: 0.767949 | Val Loss: 0.146588, Val Acc: 0.721649\n",
      "Epoch 9436 - Train Loss: 0.131301, Train Acc: 0.767949 | Val Loss: 0.146580, Val Acc: 0.721649\n",
      "Epoch 9437 - Train Loss: 0.131292, Train Acc: 0.767949 | Val Loss: 0.146573, Val Acc: 0.721649\n",
      "Epoch 9438 - Train Loss: 0.131283, Train Acc: 0.769231 | Val Loss: 0.146565, Val Acc: 0.721649\n",
      "Epoch 9439 - Train Loss: 0.131275, Train Acc: 0.769231 | Val Loss: 0.146558, Val Acc: 0.721649\n",
      "Epoch 9440 - Train Loss: 0.131266, Train Acc: 0.769231 | Val Loss: 0.146550, Val Acc: 0.721649\n",
      "Epoch 9441 - Train Loss: 0.131257, Train Acc: 0.769231 | Val Loss: 0.146543, Val Acc: 0.721649\n",
      "Epoch 9442 - Train Loss: 0.131248, Train Acc: 0.769231 | Val Loss: 0.146535, Val Acc: 0.721649\n",
      "Epoch 9443 - Train Loss: 0.131239, Train Acc: 0.769231 | Val Loss: 0.146528, Val Acc: 0.721649\n",
      "Epoch 9444 - Train Loss: 0.131230, Train Acc: 0.769231 | Val Loss: 0.146520, Val Acc: 0.721649\n",
      "Epoch 9445 - Train Loss: 0.131221, Train Acc: 0.769231 | Val Loss: 0.146513, Val Acc: 0.721649\n",
      "Epoch 9446 - Train Loss: 0.131212, Train Acc: 0.769231 | Val Loss: 0.146505, Val Acc: 0.721649\n",
      "Epoch 9447 - Train Loss: 0.131203, Train Acc: 0.769231 | Val Loss: 0.146498, Val Acc: 0.721649\n",
      "Epoch 9448 - Train Loss: 0.131195, Train Acc: 0.769231 | Val Loss: 0.146490, Val Acc: 0.721649\n",
      "Epoch 9449 - Train Loss: 0.131186, Train Acc: 0.769231 | Val Loss: 0.146483, Val Acc: 0.721649\n",
      "Epoch 9450 - Train Loss: 0.131177, Train Acc: 0.769231 | Val Loss: 0.146475, Val Acc: 0.721649\n",
      "Epoch 9451 - Train Loss: 0.131168, Train Acc: 0.769231 | Val Loss: 0.146468, Val Acc: 0.721649\n",
      "Epoch 9452 - Train Loss: 0.131159, Train Acc: 0.769231 | Val Loss: 0.146460, Val Acc: 0.721649\n",
      "Epoch 9453 - Train Loss: 0.131150, Train Acc: 0.769231 | Val Loss: 0.146453, Val Acc: 0.721649\n",
      "Epoch 9454 - Train Loss: 0.131141, Train Acc: 0.769231 | Val Loss: 0.146445, Val Acc: 0.721649\n",
      "Epoch 9455 - Train Loss: 0.131132, Train Acc: 0.769231 | Val Loss: 0.146438, Val Acc: 0.721649\n",
      "Epoch 9456 - Train Loss: 0.131123, Train Acc: 0.769231 | Val Loss: 0.146430, Val Acc: 0.721649\n",
      "Epoch 9457 - Train Loss: 0.131115, Train Acc: 0.769231 | Val Loss: 0.146423, Val Acc: 0.721649\n",
      "Epoch 9458 - Train Loss: 0.131106, Train Acc: 0.769231 | Val Loss: 0.146415, Val Acc: 0.711340\n",
      "Epoch 9459 - Train Loss: 0.131097, Train Acc: 0.769231 | Val Loss: 0.146408, Val Acc: 0.721649\n",
      "Epoch 9460 - Train Loss: 0.131088, Train Acc: 0.769231 | Val Loss: 0.146400, Val Acc: 0.721649\n",
      "Epoch 9461 - Train Loss: 0.131079, Train Acc: 0.769231 | Val Loss: 0.146393, Val Acc: 0.711340\n",
      "Epoch 9462 - Train Loss: 0.131070, Train Acc: 0.769231 | Val Loss: 0.146385, Val Acc: 0.721649\n",
      "Epoch 9463 - Train Loss: 0.131061, Train Acc: 0.769231 | Val Loss: 0.146378, Val Acc: 0.711340\n",
      "Epoch 9464 - Train Loss: 0.131052, Train Acc: 0.769231 | Val Loss: 0.146371, Val Acc: 0.711340\n",
      "Epoch 9465 - Train Loss: 0.131044, Train Acc: 0.769231 | Val Loss: 0.146363, Val Acc: 0.711340\n",
      "Epoch 9466 - Train Loss: 0.131035, Train Acc: 0.769231 | Val Loss: 0.146356, Val Acc: 0.711340\n",
      "Epoch 9467 - Train Loss: 0.131026, Train Acc: 0.769231 | Val Loss: 0.146348, Val Acc: 0.711340\n",
      "Epoch 9468 - Train Loss: 0.131017, Train Acc: 0.769231 | Val Loss: 0.146341, Val Acc: 0.711340\n",
      "Epoch 9469 - Train Loss: 0.131008, Train Acc: 0.769231 | Val Loss: 0.146333, Val Acc: 0.711340\n",
      "Epoch 9470 - Train Loss: 0.130999, Train Acc: 0.769231 | Val Loss: 0.146326, Val Acc: 0.711340\n",
      "Epoch 9471 - Train Loss: 0.130990, Train Acc: 0.769231 | Val Loss: 0.146318, Val Acc: 0.711340\n",
      "Epoch 9472 - Train Loss: 0.130982, Train Acc: 0.769231 | Val Loss: 0.146311, Val Acc: 0.711340\n",
      "Epoch 9473 - Train Loss: 0.130973, Train Acc: 0.769231 | Val Loss: 0.146303, Val Acc: 0.711340\n",
      "Epoch 9474 - Train Loss: 0.130964, Train Acc: 0.769231 | Val Loss: 0.146296, Val Acc: 0.711340\n",
      "Epoch 9475 - Train Loss: 0.130955, Train Acc: 0.769231 | Val Loss: 0.146288, Val Acc: 0.711340\n",
      "Epoch 9476 - Train Loss: 0.130946, Train Acc: 0.769231 | Val Loss: 0.146281, Val Acc: 0.711340\n",
      "Epoch 9477 - Train Loss: 0.130937, Train Acc: 0.769231 | Val Loss: 0.146273, Val Acc: 0.711340\n",
      "Epoch 9478 - Train Loss: 0.130928, Train Acc: 0.769231 | Val Loss: 0.146266, Val Acc: 0.711340\n",
      "Epoch 9479 - Train Loss: 0.130920, Train Acc: 0.769231 | Val Loss: 0.146258, Val Acc: 0.711340\n",
      "Epoch 9480 - Train Loss: 0.130911, Train Acc: 0.769231 | Val Loss: 0.146251, Val Acc: 0.711340\n",
      "Epoch 9481 - Train Loss: 0.130902, Train Acc: 0.769231 | Val Loss: 0.146244, Val Acc: 0.711340\n",
      "Epoch 9482 - Train Loss: 0.130893, Train Acc: 0.769231 | Val Loss: 0.146236, Val Acc: 0.711340\n",
      "Epoch 9483 - Train Loss: 0.130884, Train Acc: 0.769231 | Val Loss: 0.146229, Val Acc: 0.711340\n",
      "Epoch 9484 - Train Loss: 0.130875, Train Acc: 0.769231 | Val Loss: 0.146221, Val Acc: 0.711340\n",
      "Epoch 9485 - Train Loss: 0.130866, Train Acc: 0.769231 | Val Loss: 0.146214, Val Acc: 0.711340\n",
      "Epoch 9486 - Train Loss: 0.130858, Train Acc: 0.769231 | Val Loss: 0.146206, Val Acc: 0.711340\n",
      "Epoch 9487 - Train Loss: 0.130849, Train Acc: 0.769231 | Val Loss: 0.146199, Val Acc: 0.711340\n",
      "Epoch 9488 - Train Loss: 0.130840, Train Acc: 0.769231 | Val Loss: 0.146191, Val Acc: 0.711340\n",
      "Epoch 9489 - Train Loss: 0.130831, Train Acc: 0.769231 | Val Loss: 0.146184, Val Acc: 0.711340\n",
      "Epoch 9490 - Train Loss: 0.130822, Train Acc: 0.769231 | Val Loss: 0.146176, Val Acc: 0.711340\n",
      "Epoch 9491 - Train Loss: 0.130813, Train Acc: 0.769231 | Val Loss: 0.146169, Val Acc: 0.711340\n",
      "Epoch 9492 - Train Loss: 0.130805, Train Acc: 0.769231 | Val Loss: 0.146162, Val Acc: 0.711340\n",
      "Epoch 9493 - Train Loss: 0.130796, Train Acc: 0.769231 | Val Loss: 0.146154, Val Acc: 0.711340\n",
      "Epoch 9494 - Train Loss: 0.130787, Train Acc: 0.769231 | Val Loss: 0.146147, Val Acc: 0.711340\n",
      "Epoch 9495 - Train Loss: 0.130778, Train Acc: 0.769231 | Val Loss: 0.146139, Val Acc: 0.711340\n",
      "Epoch 9496 - Train Loss: 0.130769, Train Acc: 0.769231 | Val Loss: 0.146132, Val Acc: 0.711340\n",
      "Epoch 9497 - Train Loss: 0.130760, Train Acc: 0.769231 | Val Loss: 0.146124, Val Acc: 0.711340\n",
      "Epoch 9498 - Train Loss: 0.130752, Train Acc: 0.769231 | Val Loss: 0.146117, Val Acc: 0.711340\n",
      "Epoch 9499 - Train Loss: 0.130743, Train Acc: 0.769231 | Val Loss: 0.146109, Val Acc: 0.711340\n",
      "Epoch 9500 - Train Loss: 0.130734, Train Acc: 0.769231 | Val Loss: 0.146102, Val Acc: 0.711340\n",
      "Epoch 9501 - Train Loss: 0.130725, Train Acc: 0.769231 | Val Loss: 0.146094, Val Acc: 0.711340\n",
      "Epoch 9502 - Train Loss: 0.130716, Train Acc: 0.769231 | Val Loss: 0.146087, Val Acc: 0.711340\n",
      "Epoch 9503 - Train Loss: 0.130707, Train Acc: 0.769231 | Val Loss: 0.146079, Val Acc: 0.711340\n",
      "Epoch 9504 - Train Loss: 0.130699, Train Acc: 0.769231 | Val Loss: 0.146072, Val Acc: 0.711340\n",
      "Epoch 9505 - Train Loss: 0.130690, Train Acc: 0.769231 | Val Loss: 0.146064, Val Acc: 0.711340\n",
      "Epoch 9506 - Train Loss: 0.130681, Train Acc: 0.769231 | Val Loss: 0.146057, Val Acc: 0.711340\n",
      "Epoch 9507 - Train Loss: 0.130672, Train Acc: 0.769231 | Val Loss: 0.146049, Val Acc: 0.711340\n",
      "Epoch 9508 - Train Loss: 0.130663, Train Acc: 0.769231 | Val Loss: 0.146042, Val Acc: 0.711340\n",
      "Epoch 9509 - Train Loss: 0.130655, Train Acc: 0.769231 | Val Loss: 0.146034, Val Acc: 0.711340\n",
      "Epoch 9510 - Train Loss: 0.130646, Train Acc: 0.769231 | Val Loss: 0.146027, Val Acc: 0.711340\n",
      "Epoch 9511 - Train Loss: 0.130637, Train Acc: 0.769231 | Val Loss: 0.146019, Val Acc: 0.711340\n",
      "Epoch 9512 - Train Loss: 0.130628, Train Acc: 0.769231 | Val Loss: 0.146012, Val Acc: 0.711340\n",
      "Epoch 9513 - Train Loss: 0.130619, Train Acc: 0.769231 | Val Loss: 0.146004, Val Acc: 0.711340\n",
      "Epoch 9514 - Train Loss: 0.130611, Train Acc: 0.769231 | Val Loss: 0.145997, Val Acc: 0.711340\n",
      "Epoch 9515 - Train Loss: 0.130602, Train Acc: 0.769231 | Val Loss: 0.145989, Val Acc: 0.711340\n",
      "Epoch 9516 - Train Loss: 0.130593, Train Acc: 0.769231 | Val Loss: 0.145982, Val Acc: 0.711340\n",
      "Epoch 9517 - Train Loss: 0.130584, Train Acc: 0.769231 | Val Loss: 0.145974, Val Acc: 0.711340\n",
      "Epoch 9518 - Train Loss: 0.130575, Train Acc: 0.769231 | Val Loss: 0.145967, Val Acc: 0.711340\n",
      "Epoch 9519 - Train Loss: 0.130567, Train Acc: 0.769231 | Val Loss: 0.145959, Val Acc: 0.711340\n",
      "Epoch 9520 - Train Loss: 0.130558, Train Acc: 0.769231 | Val Loss: 0.145952, Val Acc: 0.711340\n",
      "Epoch 9521 - Train Loss: 0.130549, Train Acc: 0.769231 | Val Loss: 0.145944, Val Acc: 0.711340\n",
      "Epoch 9522 - Train Loss: 0.130540, Train Acc: 0.769231 | Val Loss: 0.145937, Val Acc: 0.711340\n",
      "Epoch 9523 - Train Loss: 0.130531, Train Acc: 0.769231 | Val Loss: 0.145929, Val Acc: 0.711340\n",
      "Epoch 9524 - Train Loss: 0.130523, Train Acc: 0.769231 | Val Loss: 0.145922, Val Acc: 0.711340\n",
      "Epoch 9525 - Train Loss: 0.130514, Train Acc: 0.769231 | Val Loss: 0.145914, Val Acc: 0.711340\n",
      "Epoch 9526 - Train Loss: 0.130505, Train Acc: 0.769231 | Val Loss: 0.145907, Val Acc: 0.711340\n",
      "Epoch 9527 - Train Loss: 0.130496, Train Acc: 0.769231 | Val Loss: 0.145899, Val Acc: 0.711340\n",
      "Epoch 9528 - Train Loss: 0.130487, Train Acc: 0.769231 | Val Loss: 0.145892, Val Acc: 0.711340\n",
      "Epoch 9529 - Train Loss: 0.130479, Train Acc: 0.769231 | Val Loss: 0.145884, Val Acc: 0.711340\n",
      "Epoch 9530 - Train Loss: 0.130470, Train Acc: 0.769231 | Val Loss: 0.145877, Val Acc: 0.711340\n",
      "Epoch 9531 - Train Loss: 0.130461, Train Acc: 0.769231 | Val Loss: 0.145870, Val Acc: 0.711340\n",
      "Epoch 9532 - Train Loss: 0.130452, Train Acc: 0.769231 | Val Loss: 0.145862, Val Acc: 0.711340\n",
      "Epoch 9533 - Train Loss: 0.130443, Train Acc: 0.769231 | Val Loss: 0.145855, Val Acc: 0.711340\n",
      "Epoch 9534 - Train Loss: 0.130435, Train Acc: 0.769231 | Val Loss: 0.145847, Val Acc: 0.711340\n",
      "Epoch 9535 - Train Loss: 0.130426, Train Acc: 0.769231 | Val Loss: 0.145840, Val Acc: 0.711340\n",
      "Epoch 9536 - Train Loss: 0.130417, Train Acc: 0.769231 | Val Loss: 0.145832, Val Acc: 0.711340\n",
      "Epoch 9537 - Train Loss: 0.130408, Train Acc: 0.769231 | Val Loss: 0.145825, Val Acc: 0.711340\n",
      "Epoch 9538 - Train Loss: 0.130399, Train Acc: 0.769231 | Val Loss: 0.145817, Val Acc: 0.711340\n",
      "Epoch 9539 - Train Loss: 0.130391, Train Acc: 0.769231 | Val Loss: 0.145810, Val Acc: 0.711340\n",
      "Epoch 9540 - Train Loss: 0.130382, Train Acc: 0.769231 | Val Loss: 0.145803, Val Acc: 0.711340\n",
      "Epoch 9541 - Train Loss: 0.130373, Train Acc: 0.769231 | Val Loss: 0.145795, Val Acc: 0.711340\n",
      "Epoch 9542 - Train Loss: 0.130364, Train Acc: 0.769231 | Val Loss: 0.145788, Val Acc: 0.711340\n",
      "Epoch 9543 - Train Loss: 0.130356, Train Acc: 0.769231 | Val Loss: 0.145780, Val Acc: 0.711340\n",
      "Epoch 9544 - Train Loss: 0.130347, Train Acc: 0.769231 | Val Loss: 0.145773, Val Acc: 0.711340\n",
      "Epoch 9545 - Train Loss: 0.130338, Train Acc: 0.769231 | Val Loss: 0.145765, Val Acc: 0.711340\n",
      "Epoch 9546 - Train Loss: 0.130329, Train Acc: 0.769231 | Val Loss: 0.145758, Val Acc: 0.711340\n",
      "Epoch 9547 - Train Loss: 0.130321, Train Acc: 0.769231 | Val Loss: 0.145751, Val Acc: 0.711340\n",
      "Epoch 9548 - Train Loss: 0.130312, Train Acc: 0.769231 | Val Loss: 0.145743, Val Acc: 0.711340\n",
      "Epoch 9549 - Train Loss: 0.130303, Train Acc: 0.769231 | Val Loss: 0.145736, Val Acc: 0.711340\n",
      "Epoch 9550 - Train Loss: 0.130294, Train Acc: 0.769231 | Val Loss: 0.145728, Val Acc: 0.711340\n",
      "Epoch 9551 - Train Loss: 0.130285, Train Acc: 0.769231 | Val Loss: 0.145721, Val Acc: 0.711340\n",
      "Epoch 9552 - Train Loss: 0.130277, Train Acc: 0.769231 | Val Loss: 0.145714, Val Acc: 0.711340\n",
      "Epoch 9553 - Train Loss: 0.130268, Train Acc: 0.769231 | Val Loss: 0.145706, Val Acc: 0.711340\n",
      "Epoch 9554 - Train Loss: 0.130259, Train Acc: 0.769231 | Val Loss: 0.145699, Val Acc: 0.711340\n",
      "Epoch 9555 - Train Loss: 0.130250, Train Acc: 0.769231 | Val Loss: 0.145691, Val Acc: 0.711340\n",
      "Epoch 9556 - Train Loss: 0.130242, Train Acc: 0.769231 | Val Loss: 0.145684, Val Acc: 0.711340\n",
      "Epoch 9557 - Train Loss: 0.130233, Train Acc: 0.769231 | Val Loss: 0.145676, Val Acc: 0.711340\n",
      "Epoch 9558 - Train Loss: 0.130224, Train Acc: 0.769231 | Val Loss: 0.145669, Val Acc: 0.711340\n",
      "Epoch 9559 - Train Loss: 0.130215, Train Acc: 0.769231 | Val Loss: 0.145662, Val Acc: 0.711340\n",
      "Epoch 9560 - Train Loss: 0.130207, Train Acc: 0.769231 | Val Loss: 0.145654, Val Acc: 0.711340\n",
      "Epoch 9561 - Train Loss: 0.130198, Train Acc: 0.769231 | Val Loss: 0.145647, Val Acc: 0.711340\n",
      "Epoch 9562 - Train Loss: 0.130189, Train Acc: 0.769231 | Val Loss: 0.145640, Val Acc: 0.711340\n",
      "Epoch 9563 - Train Loss: 0.130180, Train Acc: 0.769231 | Val Loss: 0.145632, Val Acc: 0.711340\n",
      "Epoch 9564 - Train Loss: 0.130172, Train Acc: 0.769231 | Val Loss: 0.145625, Val Acc: 0.711340\n",
      "Epoch 9565 - Train Loss: 0.130163, Train Acc: 0.769231 | Val Loss: 0.145617, Val Acc: 0.711340\n",
      "Epoch 9566 - Train Loss: 0.130154, Train Acc: 0.769231 | Val Loss: 0.145610, Val Acc: 0.711340\n",
      "Epoch 9567 - Train Loss: 0.130145, Train Acc: 0.769231 | Val Loss: 0.145603, Val Acc: 0.711340\n",
      "Epoch 9568 - Train Loss: 0.130137, Train Acc: 0.769231 | Val Loss: 0.145595, Val Acc: 0.711340\n",
      "Epoch 9569 - Train Loss: 0.130128, Train Acc: 0.769231 | Val Loss: 0.145588, Val Acc: 0.711340\n",
      "Epoch 9570 - Train Loss: 0.130119, Train Acc: 0.769231 | Val Loss: 0.145580, Val Acc: 0.711340\n",
      "Epoch 9571 - Train Loss: 0.130110, Train Acc: 0.769231 | Val Loss: 0.145573, Val Acc: 0.711340\n",
      "Epoch 9572 - Train Loss: 0.130102, Train Acc: 0.769231 | Val Loss: 0.145566, Val Acc: 0.711340\n",
      "Epoch 9573 - Train Loss: 0.130093, Train Acc: 0.769231 | Val Loss: 0.145558, Val Acc: 0.711340\n",
      "Epoch 9574 - Train Loss: 0.130084, Train Acc: 0.769231 | Val Loss: 0.145551, Val Acc: 0.711340\n",
      "Epoch 9575 - Train Loss: 0.130075, Train Acc: 0.769231 | Val Loss: 0.145544, Val Acc: 0.711340\n",
      "Epoch 9576 - Train Loss: 0.130067, Train Acc: 0.769231 | Val Loss: 0.145536, Val Acc: 0.711340\n",
      "Epoch 9577 - Train Loss: 0.130058, Train Acc: 0.769231 | Val Loss: 0.145529, Val Acc: 0.711340\n",
      "Epoch 9578 - Train Loss: 0.130049, Train Acc: 0.769231 | Val Loss: 0.145522, Val Acc: 0.711340\n",
      "Epoch 9579 - Train Loss: 0.130040, Train Acc: 0.769231 | Val Loss: 0.145514, Val Acc: 0.711340\n",
      "Epoch 9580 - Train Loss: 0.130032, Train Acc: 0.769231 | Val Loss: 0.145507, Val Acc: 0.711340\n",
      "Epoch 9581 - Train Loss: 0.130023, Train Acc: 0.769231 | Val Loss: 0.145499, Val Acc: 0.711340\n",
      "Epoch 9582 - Train Loss: 0.130014, Train Acc: 0.769231 | Val Loss: 0.145492, Val Acc: 0.711340\n",
      "Epoch 9583 - Train Loss: 0.130006, Train Acc: 0.769231 | Val Loss: 0.145485, Val Acc: 0.711340\n",
      "Epoch 9584 - Train Loss: 0.129997, Train Acc: 0.769231 | Val Loss: 0.145477, Val Acc: 0.711340\n",
      "Epoch 9585 - Train Loss: 0.129988, Train Acc: 0.769231 | Val Loss: 0.145470, Val Acc: 0.711340\n",
      "Epoch 9586 - Train Loss: 0.129979, Train Acc: 0.769231 | Val Loss: 0.145463, Val Acc: 0.711340\n",
      "Epoch 9587 - Train Loss: 0.129971, Train Acc: 0.769231 | Val Loss: 0.145455, Val Acc: 0.711340\n",
      "Epoch 9588 - Train Loss: 0.129962, Train Acc: 0.769231 | Val Loss: 0.145448, Val Acc: 0.701031\n",
      "Epoch 9589 - Train Loss: 0.129953, Train Acc: 0.769231 | Val Loss: 0.145441, Val Acc: 0.701031\n",
      "Epoch 9590 - Train Loss: 0.129944, Train Acc: 0.769231 | Val Loss: 0.145433, Val Acc: 0.701031\n",
      "Epoch 9591 - Train Loss: 0.129936, Train Acc: 0.769231 | Val Loss: 0.145426, Val Acc: 0.701031\n",
      "Epoch 9592 - Train Loss: 0.129927, Train Acc: 0.769231 | Val Loss: 0.145419, Val Acc: 0.701031\n",
      "Epoch 9593 - Train Loss: 0.129918, Train Acc: 0.769231 | Val Loss: 0.145411, Val Acc: 0.701031\n",
      "Epoch 9594 - Train Loss: 0.129910, Train Acc: 0.769231 | Val Loss: 0.145404, Val Acc: 0.701031\n",
      "Epoch 9595 - Train Loss: 0.129901, Train Acc: 0.769231 | Val Loss: 0.145397, Val Acc: 0.701031\n",
      "Epoch 9596 - Train Loss: 0.129892, Train Acc: 0.769231 | Val Loss: 0.145389, Val Acc: 0.701031\n",
      "Epoch 9597 - Train Loss: 0.129883, Train Acc: 0.769231 | Val Loss: 0.145382, Val Acc: 0.701031\n",
      "Epoch 9598 - Train Loss: 0.129875, Train Acc: 0.769231 | Val Loss: 0.145375, Val Acc: 0.701031\n",
      "Epoch 9599 - Train Loss: 0.129866, Train Acc: 0.769231 | Val Loss: 0.145367, Val Acc: 0.701031\n",
      "Epoch 9600 - Train Loss: 0.129857, Train Acc: 0.769231 | Val Loss: 0.145360, Val Acc: 0.701031\n",
      "Epoch 9601 - Train Loss: 0.129849, Train Acc: 0.769231 | Val Loss: 0.145352, Val Acc: 0.701031\n",
      "Epoch 9602 - Train Loss: 0.129840, Train Acc: 0.769231 | Val Loss: 0.145345, Val Acc: 0.701031\n",
      "Epoch 9603 - Train Loss: 0.129831, Train Acc: 0.769231 | Val Loss: 0.145338, Val Acc: 0.701031\n",
      "Epoch 9604 - Train Loss: 0.129822, Train Acc: 0.769231 | Val Loss: 0.145330, Val Acc: 0.701031\n",
      "Epoch 9605 - Train Loss: 0.129814, Train Acc: 0.769231 | Val Loss: 0.145323, Val Acc: 0.701031\n",
      "Epoch 9606 - Train Loss: 0.129805, Train Acc: 0.769231 | Val Loss: 0.145316, Val Acc: 0.701031\n",
      "Epoch 9607 - Train Loss: 0.129796, Train Acc: 0.769231 | Val Loss: 0.145308, Val Acc: 0.701031\n",
      "Epoch 9608 - Train Loss: 0.129788, Train Acc: 0.769231 | Val Loss: 0.145301, Val Acc: 0.701031\n",
      "Epoch 9609 - Train Loss: 0.129779, Train Acc: 0.769231 | Val Loss: 0.145294, Val Acc: 0.701031\n",
      "Epoch 9610 - Train Loss: 0.129770, Train Acc: 0.769231 | Val Loss: 0.145286, Val Acc: 0.701031\n",
      "Epoch 9611 - Train Loss: 0.129762, Train Acc: 0.769231 | Val Loss: 0.145279, Val Acc: 0.701031\n",
      "Epoch 9612 - Train Loss: 0.129753, Train Acc: 0.770513 | Val Loss: 0.145271, Val Acc: 0.701031\n",
      "Epoch 9613 - Train Loss: 0.129744, Train Acc: 0.770513 | Val Loss: 0.145264, Val Acc: 0.701031\n",
      "Epoch 9614 - Train Loss: 0.129736, Train Acc: 0.770513 | Val Loss: 0.145257, Val Acc: 0.701031\n",
      "Epoch 9615 - Train Loss: 0.129727, Train Acc: 0.770513 | Val Loss: 0.145249, Val Acc: 0.701031\n",
      "Epoch 9616 - Train Loss: 0.129718, Train Acc: 0.770513 | Val Loss: 0.145242, Val Acc: 0.701031\n",
      "Epoch 9617 - Train Loss: 0.129709, Train Acc: 0.770513 | Val Loss: 0.145235, Val Acc: 0.701031\n",
      "Epoch 9618 - Train Loss: 0.129701, Train Acc: 0.770513 | Val Loss: 0.145227, Val Acc: 0.701031\n",
      "Epoch 9619 - Train Loss: 0.129692, Train Acc: 0.770513 | Val Loss: 0.145220, Val Acc: 0.701031\n",
      "Epoch 9620 - Train Loss: 0.129683, Train Acc: 0.770513 | Val Loss: 0.145213, Val Acc: 0.701031\n",
      "Epoch 9621 - Train Loss: 0.129675, Train Acc: 0.770513 | Val Loss: 0.145205, Val Acc: 0.701031\n",
      "Epoch 9622 - Train Loss: 0.129666, Train Acc: 0.770513 | Val Loss: 0.145198, Val Acc: 0.701031\n",
      "Epoch 9623 - Train Loss: 0.129657, Train Acc: 0.770513 | Val Loss: 0.145191, Val Acc: 0.701031\n",
      "Epoch 9624 - Train Loss: 0.129649, Train Acc: 0.770513 | Val Loss: 0.145183, Val Acc: 0.701031\n",
      "Epoch 9625 - Train Loss: 0.129640, Train Acc: 0.770513 | Val Loss: 0.145176, Val Acc: 0.701031\n",
      "Epoch 9626 - Train Loss: 0.129631, Train Acc: 0.770513 | Val Loss: 0.145169, Val Acc: 0.701031\n",
      "Epoch 9627 - Train Loss: 0.129623, Train Acc: 0.770513 | Val Loss: 0.145162, Val Acc: 0.701031\n",
      "Epoch 9628 - Train Loss: 0.129614, Train Acc: 0.770513 | Val Loss: 0.145154, Val Acc: 0.701031\n",
      "Epoch 9629 - Train Loss: 0.129605, Train Acc: 0.770513 | Val Loss: 0.145147, Val Acc: 0.701031\n",
      "Epoch 9630 - Train Loss: 0.129597, Train Acc: 0.770513 | Val Loss: 0.145140, Val Acc: 0.701031\n",
      "Epoch 9631 - Train Loss: 0.129588, Train Acc: 0.770513 | Val Loss: 0.145132, Val Acc: 0.701031\n",
      "Epoch 9632 - Train Loss: 0.129579, Train Acc: 0.770513 | Val Loss: 0.145125, Val Acc: 0.701031\n",
      "Epoch 9633 - Train Loss: 0.129571, Train Acc: 0.770513 | Val Loss: 0.145118, Val Acc: 0.701031\n",
      "Epoch 9634 - Train Loss: 0.129562, Train Acc: 0.770513 | Val Loss: 0.145110, Val Acc: 0.701031\n",
      "Epoch 9635 - Train Loss: 0.129553, Train Acc: 0.770513 | Val Loss: 0.145103, Val Acc: 0.701031\n",
      "Epoch 9636 - Train Loss: 0.129545, Train Acc: 0.770513 | Val Loss: 0.145096, Val Acc: 0.701031\n",
      "Epoch 9637 - Train Loss: 0.129536, Train Acc: 0.770513 | Val Loss: 0.145088, Val Acc: 0.701031\n",
      "Epoch 9638 - Train Loss: 0.129527, Train Acc: 0.770513 | Val Loss: 0.145081, Val Acc: 0.701031\n",
      "Epoch 9639 - Train Loss: 0.129519, Train Acc: 0.770513 | Val Loss: 0.145074, Val Acc: 0.701031\n",
      "Epoch 9640 - Train Loss: 0.129510, Train Acc: 0.770513 | Val Loss: 0.145067, Val Acc: 0.701031\n",
      "Epoch 9641 - Train Loss: 0.129501, Train Acc: 0.770513 | Val Loss: 0.145059, Val Acc: 0.701031\n",
      "Epoch 9642 - Train Loss: 0.129493, Train Acc: 0.770513 | Val Loss: 0.145052, Val Acc: 0.701031\n",
      "Epoch 9643 - Train Loss: 0.129484, Train Acc: 0.770513 | Val Loss: 0.145045, Val Acc: 0.701031\n",
      "Epoch 9644 - Train Loss: 0.129475, Train Acc: 0.770513 | Val Loss: 0.145037, Val Acc: 0.701031\n",
      "Epoch 9645 - Train Loss: 0.129467, Train Acc: 0.770513 | Val Loss: 0.145030, Val Acc: 0.701031\n",
      "Epoch 9646 - Train Loss: 0.129458, Train Acc: 0.770513 | Val Loss: 0.145023, Val Acc: 0.701031\n",
      "Epoch 9647 - Train Loss: 0.129449, Train Acc: 0.770513 | Val Loss: 0.145016, Val Acc: 0.701031\n",
      "Epoch 9648 - Train Loss: 0.129441, Train Acc: 0.770513 | Val Loss: 0.145008, Val Acc: 0.701031\n",
      "Epoch 9649 - Train Loss: 0.129432, Train Acc: 0.770513 | Val Loss: 0.145001, Val Acc: 0.701031\n",
      "Epoch 9650 - Train Loss: 0.129423, Train Acc: 0.770513 | Val Loss: 0.144994, Val Acc: 0.701031\n",
      "Epoch 9651 - Train Loss: 0.129415, Train Acc: 0.770513 | Val Loss: 0.144986, Val Acc: 0.701031\n",
      "Epoch 9652 - Train Loss: 0.129406, Train Acc: 0.770513 | Val Loss: 0.144979, Val Acc: 0.701031\n",
      "Epoch 9653 - Train Loss: 0.129397, Train Acc: 0.770513 | Val Loss: 0.144972, Val Acc: 0.701031\n",
      "Epoch 9654 - Train Loss: 0.129389, Train Acc: 0.770513 | Val Loss: 0.144965, Val Acc: 0.701031\n",
      "Epoch 9655 - Train Loss: 0.129380, Train Acc: 0.770513 | Val Loss: 0.144957, Val Acc: 0.701031\n",
      "Epoch 9656 - Train Loss: 0.129371, Train Acc: 0.770513 | Val Loss: 0.144950, Val Acc: 0.701031\n",
      "Epoch 9657 - Train Loss: 0.129363, Train Acc: 0.770513 | Val Loss: 0.144943, Val Acc: 0.701031\n",
      "Epoch 9658 - Train Loss: 0.129354, Train Acc: 0.770513 | Val Loss: 0.144936, Val Acc: 0.701031\n",
      "Epoch 9659 - Train Loss: 0.129346, Train Acc: 0.770513 | Val Loss: 0.144928, Val Acc: 0.701031\n",
      "Epoch 9660 - Train Loss: 0.129337, Train Acc: 0.770513 | Val Loss: 0.144921, Val Acc: 0.701031\n",
      "Epoch 9661 - Train Loss: 0.129328, Train Acc: 0.770513 | Val Loss: 0.144914, Val Acc: 0.701031\n",
      "Epoch 9662 - Train Loss: 0.129320, Train Acc: 0.770513 | Val Loss: 0.144906, Val Acc: 0.701031\n",
      "Epoch 9663 - Train Loss: 0.129311, Train Acc: 0.770513 | Val Loss: 0.144899, Val Acc: 0.701031\n",
      "Epoch 9664 - Train Loss: 0.129302, Train Acc: 0.770513 | Val Loss: 0.144892, Val Acc: 0.701031\n",
      "Epoch 9665 - Train Loss: 0.129294, Train Acc: 0.770513 | Val Loss: 0.144885, Val Acc: 0.701031\n",
      "Epoch 9666 - Train Loss: 0.129285, Train Acc: 0.770513 | Val Loss: 0.144877, Val Acc: 0.701031\n",
      "Epoch 9667 - Train Loss: 0.129276, Train Acc: 0.770513 | Val Loss: 0.144870, Val Acc: 0.701031\n",
      "Epoch 9668 - Train Loss: 0.129268, Train Acc: 0.770513 | Val Loss: 0.144863, Val Acc: 0.701031\n",
      "Epoch 9669 - Train Loss: 0.129259, Train Acc: 0.770513 | Val Loss: 0.144856, Val Acc: 0.701031\n",
      "Epoch 9670 - Train Loss: 0.129251, Train Acc: 0.770513 | Val Loss: 0.144848, Val Acc: 0.701031\n",
      "Epoch 9671 - Train Loss: 0.129242, Train Acc: 0.770513 | Val Loss: 0.144841, Val Acc: 0.701031\n",
      "Epoch 9672 - Train Loss: 0.129233, Train Acc: 0.770513 | Val Loss: 0.144834, Val Acc: 0.701031\n",
      "Epoch 9673 - Train Loss: 0.129225, Train Acc: 0.770513 | Val Loss: 0.144827, Val Acc: 0.701031\n",
      "Epoch 9674 - Train Loss: 0.129216, Train Acc: 0.770513 | Val Loss: 0.144819, Val Acc: 0.701031\n",
      "Epoch 9675 - Train Loss: 0.129207, Train Acc: 0.770513 | Val Loss: 0.144812, Val Acc: 0.701031\n",
      "Epoch 9676 - Train Loss: 0.129199, Train Acc: 0.770513 | Val Loss: 0.144805, Val Acc: 0.701031\n",
      "Epoch 9677 - Train Loss: 0.129190, Train Acc: 0.770513 | Val Loss: 0.144798, Val Acc: 0.701031\n",
      "Epoch 9678 - Train Loss: 0.129182, Train Acc: 0.770513 | Val Loss: 0.144790, Val Acc: 0.701031\n",
      "Epoch 9679 - Train Loss: 0.129173, Train Acc: 0.770513 | Val Loss: 0.144783, Val Acc: 0.701031\n",
      "Epoch 9680 - Train Loss: 0.129164, Train Acc: 0.770513 | Val Loss: 0.144776, Val Acc: 0.701031\n",
      "Epoch 9681 - Train Loss: 0.129156, Train Acc: 0.770513 | Val Loss: 0.144769, Val Acc: 0.701031\n",
      "Epoch 9682 - Train Loss: 0.129147, Train Acc: 0.770513 | Val Loss: 0.144762, Val Acc: 0.701031\n",
      "Epoch 9683 - Train Loss: 0.129139, Train Acc: 0.770513 | Val Loss: 0.144754, Val Acc: 0.701031\n",
      "Epoch 9684 - Train Loss: 0.129130, Train Acc: 0.770513 | Val Loss: 0.144747, Val Acc: 0.701031\n",
      "Epoch 9685 - Train Loss: 0.129121, Train Acc: 0.770513 | Val Loss: 0.144740, Val Acc: 0.701031\n",
      "Epoch 9686 - Train Loss: 0.129113, Train Acc: 0.770513 | Val Loss: 0.144733, Val Acc: 0.701031\n",
      "Epoch 9687 - Train Loss: 0.129104, Train Acc: 0.770513 | Val Loss: 0.144725, Val Acc: 0.701031\n",
      "Epoch 9688 - Train Loss: 0.129095, Train Acc: 0.770513 | Val Loss: 0.144718, Val Acc: 0.701031\n",
      "Epoch 9689 - Train Loss: 0.129087, Train Acc: 0.770513 | Val Loss: 0.144711, Val Acc: 0.701031\n",
      "Epoch 9690 - Train Loss: 0.129078, Train Acc: 0.770513 | Val Loss: 0.144704, Val Acc: 0.701031\n",
      "Epoch 9691 - Train Loss: 0.129070, Train Acc: 0.770513 | Val Loss: 0.144697, Val Acc: 0.701031\n",
      "Epoch 9692 - Train Loss: 0.129061, Train Acc: 0.770513 | Val Loss: 0.144689, Val Acc: 0.701031\n",
      "Epoch 9693 - Train Loss: 0.129052, Train Acc: 0.770513 | Val Loss: 0.144682, Val Acc: 0.701031\n",
      "Epoch 9694 - Train Loss: 0.129044, Train Acc: 0.770513 | Val Loss: 0.144675, Val Acc: 0.701031\n",
      "Epoch 9695 - Train Loss: 0.129035, Train Acc: 0.770513 | Val Loss: 0.144668, Val Acc: 0.701031\n",
      "Epoch 9696 - Train Loss: 0.129027, Train Acc: 0.770513 | Val Loss: 0.144660, Val Acc: 0.701031\n",
      "Epoch 9697 - Train Loss: 0.129018, Train Acc: 0.770513 | Val Loss: 0.144653, Val Acc: 0.701031\n",
      "Epoch 9698 - Train Loss: 0.129009, Train Acc: 0.770513 | Val Loss: 0.144646, Val Acc: 0.701031\n",
      "Epoch 9699 - Train Loss: 0.129001, Train Acc: 0.770513 | Val Loss: 0.144639, Val Acc: 0.701031\n",
      "Epoch 9700 - Train Loss: 0.128992, Train Acc: 0.770513 | Val Loss: 0.144632, Val Acc: 0.701031\n",
      "Epoch 9701 - Train Loss: 0.128984, Train Acc: 0.770513 | Val Loss: 0.144624, Val Acc: 0.701031\n",
      "Epoch 9702 - Train Loss: 0.128975, Train Acc: 0.770513 | Val Loss: 0.144617, Val Acc: 0.701031\n",
      "Epoch 9703 - Train Loss: 0.128966, Train Acc: 0.770513 | Val Loss: 0.144610, Val Acc: 0.701031\n",
      "Epoch 9704 - Train Loss: 0.128958, Train Acc: 0.770513 | Val Loss: 0.144603, Val Acc: 0.701031\n",
      "Epoch 9705 - Train Loss: 0.128949, Train Acc: 0.770513 | Val Loss: 0.144596, Val Acc: 0.701031\n",
      "Epoch 9706 - Train Loss: 0.128941, Train Acc: 0.770513 | Val Loss: 0.144588, Val Acc: 0.701031\n",
      "Epoch 9707 - Train Loss: 0.128932, Train Acc: 0.770513 | Val Loss: 0.144581, Val Acc: 0.701031\n",
      "Epoch 9708 - Train Loss: 0.128924, Train Acc: 0.770513 | Val Loss: 0.144574, Val Acc: 0.701031\n",
      "Epoch 9709 - Train Loss: 0.128915, Train Acc: 0.770513 | Val Loss: 0.144567, Val Acc: 0.701031\n",
      "Epoch 9710 - Train Loss: 0.128906, Train Acc: 0.770513 | Val Loss: 0.144560, Val Acc: 0.701031\n",
      "Epoch 9711 - Train Loss: 0.128898, Train Acc: 0.770513 | Val Loss: 0.144552, Val Acc: 0.701031\n",
      "Epoch 9712 - Train Loss: 0.128889, Train Acc: 0.770513 | Val Loss: 0.144545, Val Acc: 0.701031\n",
      "Epoch 9713 - Train Loss: 0.128881, Train Acc: 0.770513 | Val Loss: 0.144538, Val Acc: 0.701031\n",
      "Epoch 9714 - Train Loss: 0.128872, Train Acc: 0.770513 | Val Loss: 0.144531, Val Acc: 0.701031\n",
      "Epoch 9715 - Train Loss: 0.128863, Train Acc: 0.770513 | Val Loss: 0.144524, Val Acc: 0.701031\n",
      "Epoch 9716 - Train Loss: 0.128855, Train Acc: 0.770513 | Val Loss: 0.144516, Val Acc: 0.701031\n",
      "Epoch 9717 - Train Loss: 0.128846, Train Acc: 0.770513 | Val Loss: 0.144509, Val Acc: 0.701031\n",
      "Epoch 9718 - Train Loss: 0.128838, Train Acc: 0.770513 | Val Loss: 0.144502, Val Acc: 0.701031\n",
      "Epoch 9719 - Train Loss: 0.128829, Train Acc: 0.770513 | Val Loss: 0.144495, Val Acc: 0.701031\n",
      "Epoch 9720 - Train Loss: 0.128821, Train Acc: 0.770513 | Val Loss: 0.144488, Val Acc: 0.701031\n",
      "Epoch 9721 - Train Loss: 0.128812, Train Acc: 0.770513 | Val Loss: 0.144480, Val Acc: 0.701031\n",
      "Epoch 9722 - Train Loss: 0.128803, Train Acc: 0.770513 | Val Loss: 0.144473, Val Acc: 0.701031\n",
      "Epoch 9723 - Train Loss: 0.128795, Train Acc: 0.770513 | Val Loss: 0.144466, Val Acc: 0.701031\n",
      "Epoch 9724 - Train Loss: 0.128786, Train Acc: 0.770513 | Val Loss: 0.144459, Val Acc: 0.701031\n",
      "Epoch 9725 - Train Loss: 0.128778, Train Acc: 0.770513 | Val Loss: 0.144452, Val Acc: 0.701031\n",
      "Epoch 9726 - Train Loss: 0.128769, Train Acc: 0.770513 | Val Loss: 0.144445, Val Acc: 0.701031\n",
      "Epoch 9727 - Train Loss: 0.128761, Train Acc: 0.770513 | Val Loss: 0.144437, Val Acc: 0.701031\n",
      "Epoch 9728 - Train Loss: 0.128752, Train Acc: 0.770513 | Val Loss: 0.144430, Val Acc: 0.701031\n",
      "Epoch 9729 - Train Loss: 0.128743, Train Acc: 0.770513 | Val Loss: 0.144423, Val Acc: 0.701031\n",
      "Epoch 9730 - Train Loss: 0.128735, Train Acc: 0.770513 | Val Loss: 0.144416, Val Acc: 0.701031\n",
      "Epoch 9731 - Train Loss: 0.128726, Train Acc: 0.770513 | Val Loss: 0.144409, Val Acc: 0.701031\n",
      "Epoch 9732 - Train Loss: 0.128718, Train Acc: 0.770513 | Val Loss: 0.144402, Val Acc: 0.701031\n",
      "Epoch 9733 - Train Loss: 0.128709, Train Acc: 0.770513 | Val Loss: 0.144394, Val Acc: 0.701031\n",
      "Epoch 9734 - Train Loss: 0.128701, Train Acc: 0.770513 | Val Loss: 0.144387, Val Acc: 0.701031\n",
      "Epoch 9735 - Train Loss: 0.128692, Train Acc: 0.770513 | Val Loss: 0.144380, Val Acc: 0.701031\n",
      "Epoch 9736 - Train Loss: 0.128683, Train Acc: 0.770513 | Val Loss: 0.144373, Val Acc: 0.701031\n",
      "Epoch 9737 - Train Loss: 0.128675, Train Acc: 0.770513 | Val Loss: 0.144366, Val Acc: 0.701031\n",
      "Epoch 9738 - Train Loss: 0.128666, Train Acc: 0.770513 | Val Loss: 0.144359, Val Acc: 0.701031\n",
      "Epoch 9739 - Train Loss: 0.128658, Train Acc: 0.770513 | Val Loss: 0.144351, Val Acc: 0.701031\n",
      "Epoch 9740 - Train Loss: 0.128649, Train Acc: 0.770513 | Val Loss: 0.144344, Val Acc: 0.701031\n",
      "Epoch 9741 - Train Loss: 0.128641, Train Acc: 0.770513 | Val Loss: 0.144337, Val Acc: 0.701031\n",
      "Epoch 9742 - Train Loss: 0.128632, Train Acc: 0.770513 | Val Loss: 0.144330, Val Acc: 0.701031\n",
      "Epoch 9743 - Train Loss: 0.128624, Train Acc: 0.770513 | Val Loss: 0.144323, Val Acc: 0.701031\n",
      "Epoch 9744 - Train Loss: 0.128615, Train Acc: 0.770513 | Val Loss: 0.144316, Val Acc: 0.701031\n",
      "Epoch 9745 - Train Loss: 0.128607, Train Acc: 0.770513 | Val Loss: 0.144308, Val Acc: 0.701031\n",
      "Epoch 9746 - Train Loss: 0.128598, Train Acc: 0.771795 | Val Loss: 0.144301, Val Acc: 0.701031\n",
      "Epoch 9747 - Train Loss: 0.128589, Train Acc: 0.771795 | Val Loss: 0.144294, Val Acc: 0.701031\n",
      "Epoch 9748 - Train Loss: 0.128581, Train Acc: 0.771795 | Val Loss: 0.144287, Val Acc: 0.701031\n",
      "Epoch 9749 - Train Loss: 0.128572, Train Acc: 0.771795 | Val Loss: 0.144280, Val Acc: 0.701031\n",
      "Epoch 9750 - Train Loss: 0.128564, Train Acc: 0.771795 | Val Loss: 0.144273, Val Acc: 0.701031\n",
      "Epoch 9751 - Train Loss: 0.128555, Train Acc: 0.771795 | Val Loss: 0.144265, Val Acc: 0.701031\n",
      "Epoch 9752 - Train Loss: 0.128547, Train Acc: 0.771795 | Val Loss: 0.144258, Val Acc: 0.701031\n",
      "Epoch 9753 - Train Loss: 0.128538, Train Acc: 0.771795 | Val Loss: 0.144251, Val Acc: 0.701031\n",
      "Epoch 9754 - Train Loss: 0.128530, Train Acc: 0.771795 | Val Loss: 0.144244, Val Acc: 0.701031\n",
      "Epoch 9755 - Train Loss: 0.128521, Train Acc: 0.771795 | Val Loss: 0.144237, Val Acc: 0.701031\n",
      "Epoch 9756 - Train Loss: 0.128513, Train Acc: 0.771795 | Val Loss: 0.144230, Val Acc: 0.701031\n",
      "Epoch 9757 - Train Loss: 0.128504, Train Acc: 0.771795 | Val Loss: 0.144223, Val Acc: 0.701031\n",
      "Epoch 9758 - Train Loss: 0.128496, Train Acc: 0.771795 | Val Loss: 0.144215, Val Acc: 0.701031\n",
      "Epoch 9759 - Train Loss: 0.128487, Train Acc: 0.771795 | Val Loss: 0.144208, Val Acc: 0.701031\n",
      "Epoch 9760 - Train Loss: 0.128478, Train Acc: 0.771795 | Val Loss: 0.144201, Val Acc: 0.701031\n",
      "Epoch 9761 - Train Loss: 0.128470, Train Acc: 0.771795 | Val Loss: 0.144194, Val Acc: 0.701031\n",
      "Epoch 9762 - Train Loss: 0.128461, Train Acc: 0.771795 | Val Loss: 0.144187, Val Acc: 0.701031\n",
      "Epoch 9763 - Train Loss: 0.128453, Train Acc: 0.771795 | Val Loss: 0.144180, Val Acc: 0.701031\n",
      "Epoch 9764 - Train Loss: 0.128444, Train Acc: 0.771795 | Val Loss: 0.144173, Val Acc: 0.701031\n",
      "Epoch 9765 - Train Loss: 0.128436, Train Acc: 0.773077 | Val Loss: 0.144166, Val Acc: 0.701031\n",
      "Epoch 9766 - Train Loss: 0.128427, Train Acc: 0.773077 | Val Loss: 0.144158, Val Acc: 0.701031\n",
      "Epoch 9767 - Train Loss: 0.128419, Train Acc: 0.773077 | Val Loss: 0.144151, Val Acc: 0.701031\n",
      "Epoch 9768 - Train Loss: 0.128410, Train Acc: 0.773077 | Val Loss: 0.144144, Val Acc: 0.701031\n",
      "Epoch 9769 - Train Loss: 0.128402, Train Acc: 0.773077 | Val Loss: 0.144137, Val Acc: 0.701031\n",
      "Epoch 9770 - Train Loss: 0.128393, Train Acc: 0.773077 | Val Loss: 0.144130, Val Acc: 0.701031\n",
      "Epoch 9771 - Train Loss: 0.128385, Train Acc: 0.773077 | Val Loss: 0.144123, Val Acc: 0.701031\n",
      "Epoch 9772 - Train Loss: 0.128376, Train Acc: 0.773077 | Val Loss: 0.144116, Val Acc: 0.701031\n",
      "Epoch 9773 - Train Loss: 0.128368, Train Acc: 0.773077 | Val Loss: 0.144109, Val Acc: 0.701031\n",
      "Epoch 9774 - Train Loss: 0.128359, Train Acc: 0.773077 | Val Loss: 0.144101, Val Acc: 0.701031\n",
      "Epoch 9775 - Train Loss: 0.128351, Train Acc: 0.773077 | Val Loss: 0.144094, Val Acc: 0.701031\n",
      "Epoch 9776 - Train Loss: 0.128342, Train Acc: 0.773077 | Val Loss: 0.144087, Val Acc: 0.701031\n",
      "Epoch 9777 - Train Loss: 0.128334, Train Acc: 0.773077 | Val Loss: 0.144080, Val Acc: 0.701031\n",
      "Epoch 9778 - Train Loss: 0.128325, Train Acc: 0.773077 | Val Loss: 0.144073, Val Acc: 0.701031\n",
      "Epoch 9779 - Train Loss: 0.128317, Train Acc: 0.773077 | Val Loss: 0.144066, Val Acc: 0.701031\n",
      "Epoch 9780 - Train Loss: 0.128308, Train Acc: 0.773077 | Val Loss: 0.144059, Val Acc: 0.701031\n",
      "Epoch 9781 - Train Loss: 0.128300, Train Acc: 0.773077 | Val Loss: 0.144052, Val Acc: 0.701031\n",
      "Epoch 9782 - Train Loss: 0.128291, Train Acc: 0.773077 | Val Loss: 0.144044, Val Acc: 0.701031\n",
      "Epoch 9783 - Train Loss: 0.128283, Train Acc: 0.773077 | Val Loss: 0.144037, Val Acc: 0.701031\n",
      "Epoch 9784 - Train Loss: 0.128274, Train Acc: 0.773077 | Val Loss: 0.144030, Val Acc: 0.701031\n",
      "Epoch 9785 - Train Loss: 0.128266, Train Acc: 0.773077 | Val Loss: 0.144023, Val Acc: 0.701031\n",
      "Epoch 9786 - Train Loss: 0.128257, Train Acc: 0.773077 | Val Loss: 0.144016, Val Acc: 0.701031\n",
      "Epoch 9787 - Train Loss: 0.128248, Train Acc: 0.773077 | Val Loss: 0.144009, Val Acc: 0.701031\n",
      "Epoch 9788 - Train Loss: 0.128240, Train Acc: 0.773077 | Val Loss: 0.144002, Val Acc: 0.701031\n",
      "Epoch 9789 - Train Loss: 0.128231, Train Acc: 0.773077 | Val Loss: 0.143995, Val Acc: 0.701031\n",
      "Epoch 9790 - Train Loss: 0.128223, Train Acc: 0.773077 | Val Loss: 0.143988, Val Acc: 0.701031\n",
      "Epoch 9791 - Train Loss: 0.128214, Train Acc: 0.773077 | Val Loss: 0.143980, Val Acc: 0.701031\n",
      "Epoch 9792 - Train Loss: 0.128206, Train Acc: 0.773077 | Val Loss: 0.143973, Val Acc: 0.701031\n",
      "Epoch 9793 - Train Loss: 0.128197, Train Acc: 0.773077 | Val Loss: 0.143966, Val Acc: 0.701031\n",
      "Epoch 9794 - Train Loss: 0.128189, Train Acc: 0.773077 | Val Loss: 0.143959, Val Acc: 0.701031\n",
      "Epoch 9795 - Train Loss: 0.128180, Train Acc: 0.773077 | Val Loss: 0.143952, Val Acc: 0.701031\n",
      "Epoch 9796 - Train Loss: 0.128172, Train Acc: 0.773077 | Val Loss: 0.143945, Val Acc: 0.701031\n",
      "Epoch 9797 - Train Loss: 0.128163, Train Acc: 0.773077 | Val Loss: 0.143938, Val Acc: 0.701031\n",
      "Epoch 9798 - Train Loss: 0.128155, Train Acc: 0.773077 | Val Loss: 0.143931, Val Acc: 0.701031\n",
      "Epoch 9799 - Train Loss: 0.128147, Train Acc: 0.773077 | Val Loss: 0.143924, Val Acc: 0.701031\n",
      "Epoch 9800 - Train Loss: 0.128138, Train Acc: 0.773077 | Val Loss: 0.143917, Val Acc: 0.701031\n",
      "Epoch 9801 - Train Loss: 0.128130, Train Acc: 0.773077 | Val Loss: 0.143909, Val Acc: 0.701031\n",
      "Epoch 9802 - Train Loss: 0.128121, Train Acc: 0.773077 | Val Loss: 0.143902, Val Acc: 0.701031\n",
      "Epoch 9803 - Train Loss: 0.128113, Train Acc: 0.773077 | Val Loss: 0.143895, Val Acc: 0.701031\n",
      "Epoch 9804 - Train Loss: 0.128104, Train Acc: 0.773077 | Val Loss: 0.143888, Val Acc: 0.701031\n",
      "Epoch 9805 - Train Loss: 0.128096, Train Acc: 0.773077 | Val Loss: 0.143881, Val Acc: 0.701031\n",
      "Epoch 9806 - Train Loss: 0.128087, Train Acc: 0.773077 | Val Loss: 0.143874, Val Acc: 0.701031\n",
      "Epoch 9807 - Train Loss: 0.128079, Train Acc: 0.773077 | Val Loss: 0.143867, Val Acc: 0.701031\n",
      "Epoch 9808 - Train Loss: 0.128070, Train Acc: 0.773077 | Val Loss: 0.143860, Val Acc: 0.701031\n",
      "Epoch 9809 - Train Loss: 0.128062, Train Acc: 0.773077 | Val Loss: 0.143853, Val Acc: 0.701031\n",
      "Epoch 9810 - Train Loss: 0.128053, Train Acc: 0.773077 | Val Loss: 0.143846, Val Acc: 0.701031\n",
      "Epoch 9811 - Train Loss: 0.128045, Train Acc: 0.773077 | Val Loss: 0.143839, Val Acc: 0.701031\n",
      "Epoch 9812 - Train Loss: 0.128036, Train Acc: 0.773077 | Val Loss: 0.143831, Val Acc: 0.701031\n",
      "Epoch 9813 - Train Loss: 0.128028, Train Acc: 0.773077 | Val Loss: 0.143824, Val Acc: 0.701031\n",
      "Epoch 9814 - Train Loss: 0.128019, Train Acc: 0.773077 | Val Loss: 0.143817, Val Acc: 0.701031\n",
      "Epoch 9815 - Train Loss: 0.128011, Train Acc: 0.773077 | Val Loss: 0.143810, Val Acc: 0.701031\n",
      "Epoch 9816 - Train Loss: 0.128002, Train Acc: 0.773077 | Val Loss: 0.143803, Val Acc: 0.701031\n",
      "Epoch 9817 - Train Loss: 0.127994, Train Acc: 0.773077 | Val Loss: 0.143796, Val Acc: 0.701031\n",
      "Epoch 9818 - Train Loss: 0.127985, Train Acc: 0.773077 | Val Loss: 0.143789, Val Acc: 0.701031\n",
      "Epoch 9819 - Train Loss: 0.127977, Train Acc: 0.773077 | Val Loss: 0.143782, Val Acc: 0.701031\n",
      "Epoch 9820 - Train Loss: 0.127968, Train Acc: 0.773077 | Val Loss: 0.143775, Val Acc: 0.701031\n",
      "Epoch 9821 - Train Loss: 0.127960, Train Acc: 0.773077 | Val Loss: 0.143768, Val Acc: 0.701031\n",
      "Epoch 9822 - Train Loss: 0.127952, Train Acc: 0.773077 | Val Loss: 0.143761, Val Acc: 0.701031\n",
      "Epoch 9823 - Train Loss: 0.127943, Train Acc: 0.773077 | Val Loss: 0.143754, Val Acc: 0.701031\n",
      "Epoch 9824 - Train Loss: 0.127935, Train Acc: 0.773077 | Val Loss: 0.143747, Val Acc: 0.701031\n",
      "Epoch 9825 - Train Loss: 0.127926, Train Acc: 0.774359 | Val Loss: 0.143739, Val Acc: 0.701031\n",
      "Epoch 9826 - Train Loss: 0.127918, Train Acc: 0.774359 | Val Loss: 0.143732, Val Acc: 0.701031\n",
      "Epoch 9827 - Train Loss: 0.127909, Train Acc: 0.774359 | Val Loss: 0.143725, Val Acc: 0.701031\n",
      "Epoch 9828 - Train Loss: 0.127901, Train Acc: 0.774359 | Val Loss: 0.143718, Val Acc: 0.701031\n",
      "Epoch 9829 - Train Loss: 0.127892, Train Acc: 0.774359 | Val Loss: 0.143711, Val Acc: 0.701031\n",
      "Epoch 9830 - Train Loss: 0.127884, Train Acc: 0.774359 | Val Loss: 0.143704, Val Acc: 0.701031\n",
      "Epoch 9831 - Train Loss: 0.127875, Train Acc: 0.774359 | Val Loss: 0.143697, Val Acc: 0.701031\n",
      "Epoch 9832 - Train Loss: 0.127867, Train Acc: 0.774359 | Val Loss: 0.143690, Val Acc: 0.701031\n",
      "Epoch 9833 - Train Loss: 0.127858, Train Acc: 0.774359 | Val Loss: 0.143683, Val Acc: 0.701031\n",
      "Epoch 9834 - Train Loss: 0.127850, Train Acc: 0.774359 | Val Loss: 0.143676, Val Acc: 0.701031\n",
      "Epoch 9835 - Train Loss: 0.127842, Train Acc: 0.774359 | Val Loss: 0.143669, Val Acc: 0.701031\n",
      "Epoch 9836 - Train Loss: 0.127833, Train Acc: 0.774359 | Val Loss: 0.143662, Val Acc: 0.701031\n",
      "Epoch 9837 - Train Loss: 0.127825, Train Acc: 0.774359 | Val Loss: 0.143655, Val Acc: 0.701031\n",
      "Epoch 9838 - Train Loss: 0.127816, Train Acc: 0.774359 | Val Loss: 0.143648, Val Acc: 0.701031\n",
      "Epoch 9839 - Train Loss: 0.127808, Train Acc: 0.774359 | Val Loss: 0.143641, Val Acc: 0.701031\n",
      "Epoch 9840 - Train Loss: 0.127799, Train Acc: 0.774359 | Val Loss: 0.143634, Val Acc: 0.701031\n",
      "Epoch 9841 - Train Loss: 0.127791, Train Acc: 0.774359 | Val Loss: 0.143626, Val Acc: 0.701031\n",
      "Epoch 9842 - Train Loss: 0.127782, Train Acc: 0.774359 | Val Loss: 0.143619, Val Acc: 0.701031\n",
      "Epoch 9843 - Train Loss: 0.127774, Train Acc: 0.774359 | Val Loss: 0.143612, Val Acc: 0.701031\n",
      "Epoch 9844 - Train Loss: 0.127766, Train Acc: 0.774359 | Val Loss: 0.143605, Val Acc: 0.701031\n",
      "Epoch 9845 - Train Loss: 0.127757, Train Acc: 0.774359 | Val Loss: 0.143598, Val Acc: 0.701031\n",
      "Epoch 9846 - Train Loss: 0.127749, Train Acc: 0.774359 | Val Loss: 0.143591, Val Acc: 0.701031\n",
      "Epoch 9847 - Train Loss: 0.127740, Train Acc: 0.774359 | Val Loss: 0.143584, Val Acc: 0.701031\n",
      "Epoch 9848 - Train Loss: 0.127732, Train Acc: 0.774359 | Val Loss: 0.143577, Val Acc: 0.701031\n",
      "Epoch 9849 - Train Loss: 0.127723, Train Acc: 0.774359 | Val Loss: 0.143570, Val Acc: 0.701031\n",
      "Epoch 9850 - Train Loss: 0.127715, Train Acc: 0.774359 | Val Loss: 0.143563, Val Acc: 0.701031\n",
      "Epoch 9851 - Train Loss: 0.127706, Train Acc: 0.774359 | Val Loss: 0.143556, Val Acc: 0.701031\n",
      "Epoch 9852 - Train Loss: 0.127698, Train Acc: 0.774359 | Val Loss: 0.143549, Val Acc: 0.701031\n",
      "Epoch 9853 - Train Loss: 0.127690, Train Acc: 0.774359 | Val Loss: 0.143542, Val Acc: 0.701031\n",
      "Epoch 9854 - Train Loss: 0.127681, Train Acc: 0.774359 | Val Loss: 0.143535, Val Acc: 0.701031\n",
      "Epoch 9855 - Train Loss: 0.127673, Train Acc: 0.774359 | Val Loss: 0.143528, Val Acc: 0.701031\n",
      "Epoch 9856 - Train Loss: 0.127664, Train Acc: 0.774359 | Val Loss: 0.143521, Val Acc: 0.701031\n",
      "Epoch 9857 - Train Loss: 0.127656, Train Acc: 0.774359 | Val Loss: 0.143514, Val Acc: 0.701031\n",
      "Epoch 9858 - Train Loss: 0.127647, Train Acc: 0.774359 | Val Loss: 0.143507, Val Acc: 0.701031\n",
      "Epoch 9859 - Train Loss: 0.127639, Train Acc: 0.774359 | Val Loss: 0.143500, Val Acc: 0.701031\n",
      "Epoch 9860 - Train Loss: 0.127631, Train Acc: 0.774359 | Val Loss: 0.143493, Val Acc: 0.701031\n",
      "Epoch 9861 - Train Loss: 0.127622, Train Acc: 0.774359 | Val Loss: 0.143486, Val Acc: 0.701031\n",
      "Epoch 9862 - Train Loss: 0.127614, Train Acc: 0.774359 | Val Loss: 0.143479, Val Acc: 0.701031\n",
      "Epoch 9863 - Train Loss: 0.127605, Train Acc: 0.774359 | Val Loss: 0.143472, Val Acc: 0.701031\n",
      "Epoch 9864 - Train Loss: 0.127597, Train Acc: 0.774359 | Val Loss: 0.143464, Val Acc: 0.701031\n",
      "Epoch 9865 - Train Loss: 0.127589, Train Acc: 0.775641 | Val Loss: 0.143457, Val Acc: 0.701031\n",
      "Epoch 9866 - Train Loss: 0.127580, Train Acc: 0.775641 | Val Loss: 0.143450, Val Acc: 0.701031\n",
      "Epoch 9867 - Train Loss: 0.127572, Train Acc: 0.775641 | Val Loss: 0.143443, Val Acc: 0.701031\n",
      "Epoch 9868 - Train Loss: 0.127563, Train Acc: 0.775641 | Val Loss: 0.143436, Val Acc: 0.701031\n",
      "Epoch 9869 - Train Loss: 0.127555, Train Acc: 0.775641 | Val Loss: 0.143429, Val Acc: 0.701031\n",
      "Epoch 9870 - Train Loss: 0.127546, Train Acc: 0.775641 | Val Loss: 0.143422, Val Acc: 0.701031\n",
      "Epoch 9871 - Train Loss: 0.127538, Train Acc: 0.775641 | Val Loss: 0.143415, Val Acc: 0.701031\n",
      "Epoch 9872 - Train Loss: 0.127530, Train Acc: 0.775641 | Val Loss: 0.143408, Val Acc: 0.701031\n",
      "Epoch 9873 - Train Loss: 0.127521, Train Acc: 0.775641 | Val Loss: 0.143401, Val Acc: 0.701031\n",
      "Epoch 9874 - Train Loss: 0.127513, Train Acc: 0.775641 | Val Loss: 0.143394, Val Acc: 0.701031\n",
      "Epoch 9875 - Train Loss: 0.127504, Train Acc: 0.775641 | Val Loss: 0.143387, Val Acc: 0.701031\n",
      "Epoch 9876 - Train Loss: 0.127496, Train Acc: 0.775641 | Val Loss: 0.143380, Val Acc: 0.701031\n",
      "Epoch 9877 - Train Loss: 0.127488, Train Acc: 0.775641 | Val Loss: 0.143373, Val Acc: 0.701031\n",
      "Epoch 9878 - Train Loss: 0.127479, Train Acc: 0.775641 | Val Loss: 0.143366, Val Acc: 0.701031\n",
      "Epoch 9879 - Train Loss: 0.127471, Train Acc: 0.775641 | Val Loss: 0.143359, Val Acc: 0.701031\n",
      "Epoch 9880 - Train Loss: 0.127462, Train Acc: 0.775641 | Val Loss: 0.143352, Val Acc: 0.701031\n",
      "Epoch 9881 - Train Loss: 0.127454, Train Acc: 0.775641 | Val Loss: 0.143345, Val Acc: 0.701031\n",
      "Epoch 9882 - Train Loss: 0.127446, Train Acc: 0.775641 | Val Loss: 0.143338, Val Acc: 0.701031\n",
      "Epoch 9883 - Train Loss: 0.127437, Train Acc: 0.775641 | Val Loss: 0.143331, Val Acc: 0.701031\n",
      "Epoch 9884 - Train Loss: 0.127429, Train Acc: 0.775641 | Val Loss: 0.143324, Val Acc: 0.701031\n",
      "Epoch 9885 - Train Loss: 0.127420, Train Acc: 0.775641 | Val Loss: 0.143317, Val Acc: 0.701031\n",
      "Epoch 9886 - Train Loss: 0.127412, Train Acc: 0.775641 | Val Loss: 0.143310, Val Acc: 0.701031\n",
      "Epoch 9887 - Train Loss: 0.127404, Train Acc: 0.775641 | Val Loss: 0.143303, Val Acc: 0.701031\n",
      "Epoch 9888 - Train Loss: 0.127395, Train Acc: 0.775641 | Val Loss: 0.143296, Val Acc: 0.701031\n",
      "Epoch 9889 - Train Loss: 0.127387, Train Acc: 0.775641 | Val Loss: 0.143289, Val Acc: 0.701031\n",
      "Epoch 9890 - Train Loss: 0.127379, Train Acc: 0.775641 | Val Loss: 0.143282, Val Acc: 0.701031\n",
      "Epoch 9891 - Train Loss: 0.127370, Train Acc: 0.775641 | Val Loss: 0.143275, Val Acc: 0.701031\n",
      "Epoch 9892 - Train Loss: 0.127362, Train Acc: 0.775641 | Val Loss: 0.143268, Val Acc: 0.701031\n",
      "Epoch 9893 - Train Loss: 0.127353, Train Acc: 0.776923 | Val Loss: 0.143261, Val Acc: 0.701031\n",
      "Epoch 9894 - Train Loss: 0.127345, Train Acc: 0.776923 | Val Loss: 0.143254, Val Acc: 0.701031\n",
      "Epoch 9895 - Train Loss: 0.127337, Train Acc: 0.776923 | Val Loss: 0.143247, Val Acc: 0.701031\n",
      "Epoch 9896 - Train Loss: 0.127328, Train Acc: 0.776923 | Val Loss: 0.143240, Val Acc: 0.701031\n",
      "Epoch 9897 - Train Loss: 0.127320, Train Acc: 0.776923 | Val Loss: 0.143233, Val Acc: 0.701031\n",
      "Epoch 9898 - Train Loss: 0.127311, Train Acc: 0.776923 | Val Loss: 0.143226, Val Acc: 0.701031\n",
      "Epoch 9899 - Train Loss: 0.127303, Train Acc: 0.776923 | Val Loss: 0.143219, Val Acc: 0.701031\n",
      "Epoch 9900 - Train Loss: 0.127295, Train Acc: 0.776923 | Val Loss: 0.143212, Val Acc: 0.701031\n",
      "Epoch 9901 - Train Loss: 0.127286, Train Acc: 0.776923 | Val Loss: 0.143204, Val Acc: 0.701031\n",
      "Epoch 9902 - Train Loss: 0.127278, Train Acc: 0.776923 | Val Loss: 0.143197, Val Acc: 0.701031\n",
      "Epoch 9903 - Train Loss: 0.127270, Train Acc: 0.778205 | Val Loss: 0.143190, Val Acc: 0.701031\n",
      "Epoch 9904 - Train Loss: 0.127261, Train Acc: 0.778205 | Val Loss: 0.143183, Val Acc: 0.701031\n",
      "Epoch 9905 - Train Loss: 0.127253, Train Acc: 0.778205 | Val Loss: 0.143176, Val Acc: 0.701031\n",
      "Epoch 9906 - Train Loss: 0.127244, Train Acc: 0.778205 | Val Loss: 0.143169, Val Acc: 0.701031\n",
      "Epoch 9907 - Train Loss: 0.127236, Train Acc: 0.778205 | Val Loss: 0.143162, Val Acc: 0.701031\n",
      "Epoch 9908 - Train Loss: 0.127228, Train Acc: 0.778205 | Val Loss: 0.143155, Val Acc: 0.701031\n",
      "Epoch 9909 - Train Loss: 0.127219, Train Acc: 0.778205 | Val Loss: 0.143148, Val Acc: 0.701031\n",
      "Epoch 9910 - Train Loss: 0.127211, Train Acc: 0.778205 | Val Loss: 0.143141, Val Acc: 0.701031\n",
      "Epoch 9911 - Train Loss: 0.127203, Train Acc: 0.778205 | Val Loss: 0.143134, Val Acc: 0.701031\n",
      "Epoch 9912 - Train Loss: 0.127194, Train Acc: 0.778205 | Val Loss: 0.143127, Val Acc: 0.701031\n",
      "Epoch 9913 - Train Loss: 0.127186, Train Acc: 0.778205 | Val Loss: 0.143120, Val Acc: 0.701031\n",
      "Epoch 9914 - Train Loss: 0.127178, Train Acc: 0.778205 | Val Loss: 0.143113, Val Acc: 0.701031\n",
      "Epoch 9915 - Train Loss: 0.127169, Train Acc: 0.778205 | Val Loss: 0.143106, Val Acc: 0.701031\n",
      "Epoch 9916 - Train Loss: 0.127161, Train Acc: 0.778205 | Val Loss: 0.143099, Val Acc: 0.701031\n",
      "Epoch 9917 - Train Loss: 0.127153, Train Acc: 0.778205 | Val Loss: 0.143092, Val Acc: 0.701031\n",
      "Epoch 9918 - Train Loss: 0.127144, Train Acc: 0.778205 | Val Loss: 0.143085, Val Acc: 0.701031\n",
      "Epoch 9919 - Train Loss: 0.127136, Train Acc: 0.778205 | Val Loss: 0.143078, Val Acc: 0.701031\n",
      "Epoch 9920 - Train Loss: 0.127127, Train Acc: 0.778205 | Val Loss: 0.143071, Val Acc: 0.701031\n",
      "Epoch 9921 - Train Loss: 0.127119, Train Acc: 0.778205 | Val Loss: 0.143064, Val Acc: 0.701031\n",
      "Epoch 9922 - Train Loss: 0.127111, Train Acc: 0.779487 | Val Loss: 0.143057, Val Acc: 0.701031\n",
      "Epoch 9923 - Train Loss: 0.127102, Train Acc: 0.779487 | Val Loss: 0.143050, Val Acc: 0.701031\n",
      "Epoch 9924 - Train Loss: 0.127094, Train Acc: 0.779487 | Val Loss: 0.143043, Val Acc: 0.701031\n",
      "Epoch 9925 - Train Loss: 0.127086, Train Acc: 0.779487 | Val Loss: 0.143036, Val Acc: 0.701031\n",
      "Epoch 9926 - Train Loss: 0.127077, Train Acc: 0.779487 | Val Loss: 0.143029, Val Acc: 0.701031\n",
      "Epoch 9927 - Train Loss: 0.127069, Train Acc: 0.779487 | Val Loss: 0.143022, Val Acc: 0.701031\n",
      "Epoch 9928 - Train Loss: 0.127061, Train Acc: 0.779487 | Val Loss: 0.143015, Val Acc: 0.701031\n",
      "Epoch 9929 - Train Loss: 0.127052, Train Acc: 0.779487 | Val Loss: 0.143008, Val Acc: 0.701031\n",
      "Epoch 9930 - Train Loss: 0.127044, Train Acc: 0.779487 | Val Loss: 0.143001, Val Acc: 0.701031\n",
      "Epoch 9931 - Train Loss: 0.127036, Train Acc: 0.780769 | Val Loss: 0.142994, Val Acc: 0.701031\n",
      "Epoch 9932 - Train Loss: 0.127027, Train Acc: 0.780769 | Val Loss: 0.142987, Val Acc: 0.701031\n",
      "Epoch 9933 - Train Loss: 0.127019, Train Acc: 0.780769 | Val Loss: 0.142980, Val Acc: 0.701031\n",
      "Epoch 9934 - Train Loss: 0.127011, Train Acc: 0.780769 | Val Loss: 0.142973, Val Acc: 0.701031\n",
      "Epoch 9935 - Train Loss: 0.127002, Train Acc: 0.780769 | Val Loss: 0.142967, Val Acc: 0.701031\n",
      "Epoch 9936 - Train Loss: 0.126994, Train Acc: 0.780769 | Val Loss: 0.142960, Val Acc: 0.701031\n",
      "Epoch 9937 - Train Loss: 0.126986, Train Acc: 0.780769 | Val Loss: 0.142953, Val Acc: 0.701031\n",
      "Epoch 9938 - Train Loss: 0.126977, Train Acc: 0.780769 | Val Loss: 0.142946, Val Acc: 0.701031\n",
      "Epoch 9939 - Train Loss: 0.126969, Train Acc: 0.780769 | Val Loss: 0.142939, Val Acc: 0.701031\n",
      "Epoch 9940 - Train Loss: 0.126961, Train Acc: 0.780769 | Val Loss: 0.142932, Val Acc: 0.701031\n",
      "Epoch 9941 - Train Loss: 0.126952, Train Acc: 0.780769 | Val Loss: 0.142925, Val Acc: 0.701031\n",
      "Epoch 9942 - Train Loss: 0.126944, Train Acc: 0.780769 | Val Loss: 0.142918, Val Acc: 0.701031\n",
      "Epoch 9943 - Train Loss: 0.126936, Train Acc: 0.780769 | Val Loss: 0.142911, Val Acc: 0.701031\n",
      "Epoch 9944 - Train Loss: 0.126927, Train Acc: 0.780769 | Val Loss: 0.142904, Val Acc: 0.701031\n",
      "Epoch 9945 - Train Loss: 0.126919, Train Acc: 0.780769 | Val Loss: 0.142897, Val Acc: 0.701031\n",
      "Epoch 9946 - Train Loss: 0.126911, Train Acc: 0.780769 | Val Loss: 0.142890, Val Acc: 0.701031\n",
      "Epoch 9947 - Train Loss: 0.126902, Train Acc: 0.780769 | Val Loss: 0.142883, Val Acc: 0.701031\n",
      "Epoch 9948 - Train Loss: 0.126894, Train Acc: 0.780769 | Val Loss: 0.142876, Val Acc: 0.701031\n",
      "Epoch 9949 - Train Loss: 0.126886, Train Acc: 0.780769 | Val Loss: 0.142869, Val Acc: 0.701031\n",
      "Epoch 9950 - Train Loss: 0.126877, Train Acc: 0.780769 | Val Loss: 0.142862, Val Acc: 0.701031\n",
      "Epoch 9951 - Train Loss: 0.126869, Train Acc: 0.780769 | Val Loss: 0.142855, Val Acc: 0.701031\n",
      "Epoch 9952 - Train Loss: 0.126861, Train Acc: 0.780769 | Val Loss: 0.142848, Val Acc: 0.701031\n",
      "Epoch 9953 - Train Loss: 0.126852, Train Acc: 0.780769 | Val Loss: 0.142841, Val Acc: 0.701031\n",
      "Epoch 9954 - Train Loss: 0.126844, Train Acc: 0.780769 | Val Loss: 0.142834, Val Acc: 0.701031\n",
      "Epoch 9955 - Train Loss: 0.126836, Train Acc: 0.780769 | Val Loss: 0.142827, Val Acc: 0.701031\n",
      "Epoch 9956 - Train Loss: 0.126828, Train Acc: 0.780769 | Val Loss: 0.142820, Val Acc: 0.701031\n",
      "Epoch 9957 - Train Loss: 0.126819, Train Acc: 0.780769 | Val Loss: 0.142813, Val Acc: 0.701031\n",
      "Epoch 9958 - Train Loss: 0.126811, Train Acc: 0.780769 | Val Loss: 0.142806, Val Acc: 0.701031\n",
      "Epoch 9959 - Train Loss: 0.126803, Train Acc: 0.780769 | Val Loss: 0.142799, Val Acc: 0.701031\n",
      "Epoch 9960 - Train Loss: 0.126794, Train Acc: 0.780769 | Val Loss: 0.142793, Val Acc: 0.701031\n",
      "Epoch 9961 - Train Loss: 0.126786, Train Acc: 0.780769 | Val Loss: 0.142786, Val Acc: 0.701031\n",
      "Epoch 9962 - Train Loss: 0.126778, Train Acc: 0.780769 | Val Loss: 0.142779, Val Acc: 0.701031\n",
      "Epoch 9963 - Train Loss: 0.126769, Train Acc: 0.780769 | Val Loss: 0.142772, Val Acc: 0.701031\n",
      "Epoch 9964 - Train Loss: 0.126761, Train Acc: 0.780769 | Val Loss: 0.142765, Val Acc: 0.701031\n",
      "Epoch 9965 - Train Loss: 0.126753, Train Acc: 0.780769 | Val Loss: 0.142758, Val Acc: 0.701031\n",
      "Epoch 9966 - Train Loss: 0.126744, Train Acc: 0.780769 | Val Loss: 0.142751, Val Acc: 0.701031\n",
      "Epoch 9967 - Train Loss: 0.126736, Train Acc: 0.780769 | Val Loss: 0.142744, Val Acc: 0.701031\n",
      "Epoch 9968 - Train Loss: 0.126728, Train Acc: 0.780769 | Val Loss: 0.142737, Val Acc: 0.701031\n",
      "Epoch 9969 - Train Loss: 0.126720, Train Acc: 0.780769 | Val Loss: 0.142730, Val Acc: 0.701031\n",
      "Epoch 9970 - Train Loss: 0.126711, Train Acc: 0.780769 | Val Loss: 0.142723, Val Acc: 0.701031\n",
      "Epoch 9971 - Train Loss: 0.126703, Train Acc: 0.780769 | Val Loss: 0.142716, Val Acc: 0.701031\n",
      "Epoch 9972 - Train Loss: 0.126695, Train Acc: 0.780769 | Val Loss: 0.142709, Val Acc: 0.701031\n",
      "Epoch 9973 - Train Loss: 0.126686, Train Acc: 0.780769 | Val Loss: 0.142702, Val Acc: 0.701031\n",
      "Epoch 9974 - Train Loss: 0.126678, Train Acc: 0.780769 | Val Loss: 0.142695, Val Acc: 0.701031\n",
      "Epoch 9975 - Train Loss: 0.126670, Train Acc: 0.782051 | Val Loss: 0.142688, Val Acc: 0.701031\n",
      "Epoch 9976 - Train Loss: 0.126662, Train Acc: 0.782051 | Val Loss: 0.142682, Val Acc: 0.701031\n",
      "Epoch 9977 - Train Loss: 0.126653, Train Acc: 0.782051 | Val Loss: 0.142675, Val Acc: 0.701031\n",
      "Epoch 9978 - Train Loss: 0.126645, Train Acc: 0.782051 | Val Loss: 0.142668, Val Acc: 0.701031\n",
      "Epoch 9979 - Train Loss: 0.126637, Train Acc: 0.782051 | Val Loss: 0.142661, Val Acc: 0.701031\n",
      "Epoch 9980 - Train Loss: 0.126628, Train Acc: 0.782051 | Val Loss: 0.142654, Val Acc: 0.701031\n",
      "Epoch 9981 - Train Loss: 0.126620, Train Acc: 0.782051 | Val Loss: 0.142647, Val Acc: 0.701031\n",
      "Epoch 9982 - Train Loss: 0.126612, Train Acc: 0.782051 | Val Loss: 0.142640, Val Acc: 0.701031\n",
      "Epoch 9983 - Train Loss: 0.126604, Train Acc: 0.782051 | Val Loss: 0.142633, Val Acc: 0.701031\n",
      "Epoch 9984 - Train Loss: 0.126595, Train Acc: 0.782051 | Val Loss: 0.142626, Val Acc: 0.701031\n",
      "Epoch 9985 - Train Loss: 0.126587, Train Acc: 0.782051 | Val Loss: 0.142619, Val Acc: 0.701031\n",
      "Epoch 9986 - Train Loss: 0.126579, Train Acc: 0.782051 | Val Loss: 0.142612, Val Acc: 0.701031\n",
      "Epoch 9987 - Train Loss: 0.126570, Train Acc: 0.782051 | Val Loss: 0.142605, Val Acc: 0.701031\n",
      "Epoch 9988 - Train Loss: 0.126562, Train Acc: 0.782051 | Val Loss: 0.142599, Val Acc: 0.701031\n",
      "Epoch 9989 - Train Loss: 0.126554, Train Acc: 0.782051 | Val Loss: 0.142592, Val Acc: 0.701031\n",
      "Epoch 9990 - Train Loss: 0.126546, Train Acc: 0.782051 | Val Loss: 0.142585, Val Acc: 0.701031\n",
      "Epoch 9991 - Train Loss: 0.126537, Train Acc: 0.782051 | Val Loss: 0.142578, Val Acc: 0.701031\n",
      "Epoch 9992 - Train Loss: 0.126529, Train Acc: 0.782051 | Val Loss: 0.142571, Val Acc: 0.701031\n",
      "Epoch 9993 - Train Loss: 0.126521, Train Acc: 0.782051 | Val Loss: 0.142564, Val Acc: 0.701031\n",
      "Epoch 9994 - Train Loss: 0.126512, Train Acc: 0.782051 | Val Loss: 0.142557, Val Acc: 0.701031\n",
      "Epoch 9995 - Train Loss: 0.126504, Train Acc: 0.782051 | Val Loss: 0.142550, Val Acc: 0.701031\n",
      "Epoch 9996 - Train Loss: 0.126496, Train Acc: 0.782051 | Val Loss: 0.142543, Val Acc: 0.701031\n",
      "Epoch 9997 - Train Loss: 0.126488, Train Acc: 0.782051 | Val Loss: 0.142536, Val Acc: 0.701031\n",
      "Epoch 9998 - Train Loss: 0.126479, Train Acc: 0.782051 | Val Loss: 0.142530, Val Acc: 0.701031\n",
      "Epoch 9999 - Train Loss: 0.126471, Train Acc: 0.782051 | Val Loss: 0.142523, Val Acc: 0.701031\n",
      "Epoch 10000 - Train Loss: 0.126463, Train Acc: 0.782051 | Val Loss: 0.142516, Val Acc: 0.701031\n",
      "Epoch 10001 - Train Loss: 0.126455, Train Acc: 0.782051 | Val Loss: 0.142509, Val Acc: 0.701031\n",
      "Epoch 10002 - Train Loss: 0.126446, Train Acc: 0.782051 | Val Loss: 0.142502, Val Acc: 0.701031\n",
      "Epoch 10003 - Train Loss: 0.126438, Train Acc: 0.782051 | Val Loss: 0.142495, Val Acc: 0.701031\n",
      "Epoch 10004 - Train Loss: 0.126430, Train Acc: 0.782051 | Val Loss: 0.142488, Val Acc: 0.701031\n",
      "Epoch 10005 - Train Loss: 0.126422, Train Acc: 0.782051 | Val Loss: 0.142481, Val Acc: 0.701031\n",
      "Epoch 10006 - Train Loss: 0.126413, Train Acc: 0.782051 | Val Loss: 0.142474, Val Acc: 0.701031\n",
      "Epoch 10007 - Train Loss: 0.126405, Train Acc: 0.782051 | Val Loss: 0.142468, Val Acc: 0.701031\n",
      "Epoch 10008 - Train Loss: 0.126397, Train Acc: 0.782051 | Val Loss: 0.142461, Val Acc: 0.701031\n",
      "Epoch 10009 - Train Loss: 0.126389, Train Acc: 0.782051 | Val Loss: 0.142454, Val Acc: 0.701031\n",
      "Epoch 10010 - Train Loss: 0.126380, Train Acc: 0.782051 | Val Loss: 0.142447, Val Acc: 0.701031\n",
      "Epoch 10011 - Train Loss: 0.126372, Train Acc: 0.782051 | Val Loss: 0.142440, Val Acc: 0.701031\n",
      "Epoch 10012 - Train Loss: 0.126364, Train Acc: 0.782051 | Val Loss: 0.142433, Val Acc: 0.701031\n",
      "Epoch 10013 - Train Loss: 0.126356, Train Acc: 0.782051 | Val Loss: 0.142426, Val Acc: 0.701031\n",
      "Epoch 10014 - Train Loss: 0.126347, Train Acc: 0.782051 | Val Loss: 0.142419, Val Acc: 0.701031\n",
      "Epoch 10015 - Train Loss: 0.126339, Train Acc: 0.782051 | Val Loss: 0.142412, Val Acc: 0.701031\n",
      "Epoch 10016 - Train Loss: 0.126331, Train Acc: 0.782051 | Val Loss: 0.142406, Val Acc: 0.701031\n",
      "Epoch 10017 - Train Loss: 0.126323, Train Acc: 0.782051 | Val Loss: 0.142399, Val Acc: 0.701031\n",
      "Epoch 10018 - Train Loss: 0.126314, Train Acc: 0.782051 | Val Loss: 0.142392, Val Acc: 0.701031\n",
      "Epoch 10019 - Train Loss: 0.126306, Train Acc: 0.782051 | Val Loss: 0.142385, Val Acc: 0.701031\n",
      "Epoch 10020 - Train Loss: 0.126298, Train Acc: 0.782051 | Val Loss: 0.142378, Val Acc: 0.701031\n",
      "Epoch 10021 - Train Loss: 0.126290, Train Acc: 0.782051 | Val Loss: 0.142371, Val Acc: 0.701031\n",
      "Epoch 10022 - Train Loss: 0.126281, Train Acc: 0.782051 | Val Loss: 0.142364, Val Acc: 0.701031\n",
      "Epoch 10023 - Train Loss: 0.126273, Train Acc: 0.782051 | Val Loss: 0.142357, Val Acc: 0.701031\n",
      "Epoch 10024 - Train Loss: 0.126265, Train Acc: 0.782051 | Val Loss: 0.142351, Val Acc: 0.701031\n",
      "Epoch 10025 - Train Loss: 0.126257, Train Acc: 0.782051 | Val Loss: 0.142344, Val Acc: 0.701031\n",
      "Epoch 10026 - Train Loss: 0.126248, Train Acc: 0.782051 | Val Loss: 0.142337, Val Acc: 0.701031\n",
      "Epoch 10027 - Train Loss: 0.126240, Train Acc: 0.782051 | Val Loss: 0.142330, Val Acc: 0.701031\n",
      "Epoch 10028 - Train Loss: 0.126232, Train Acc: 0.782051 | Val Loss: 0.142323, Val Acc: 0.701031\n",
      "Epoch 10029 - Train Loss: 0.126224, Train Acc: 0.782051 | Val Loss: 0.142316, Val Acc: 0.701031\n",
      "Epoch 10030 - Train Loss: 0.126216, Train Acc: 0.782051 | Val Loss: 0.142309, Val Acc: 0.701031\n",
      "Epoch 10031 - Train Loss: 0.126207, Train Acc: 0.782051 | Val Loss: 0.142303, Val Acc: 0.701031\n",
      "Epoch 10032 - Train Loss: 0.126199, Train Acc: 0.782051 | Val Loss: 0.142296, Val Acc: 0.701031\n",
      "Epoch 10033 - Train Loss: 0.126191, Train Acc: 0.782051 | Val Loss: 0.142289, Val Acc: 0.701031\n",
      "Epoch 10034 - Train Loss: 0.126183, Train Acc: 0.782051 | Val Loss: 0.142282, Val Acc: 0.701031\n",
      "Epoch 10035 - Train Loss: 0.126174, Train Acc: 0.782051 | Val Loss: 0.142275, Val Acc: 0.701031\n",
      "Epoch 10036 - Train Loss: 0.126166, Train Acc: 0.782051 | Val Loss: 0.142268, Val Acc: 0.701031\n",
      "Epoch 10037 - Train Loss: 0.126158, Train Acc: 0.782051 | Val Loss: 0.142261, Val Acc: 0.701031\n",
      "Epoch 10038 - Train Loss: 0.126150, Train Acc: 0.782051 | Val Loss: 0.142255, Val Acc: 0.701031\n",
      "Epoch 10039 - Train Loss: 0.126142, Train Acc: 0.782051 | Val Loss: 0.142248, Val Acc: 0.701031\n",
      "Epoch 10040 - Train Loss: 0.126133, Train Acc: 0.782051 | Val Loss: 0.142241, Val Acc: 0.701031\n",
      "Epoch 10041 - Train Loss: 0.126125, Train Acc: 0.782051 | Val Loss: 0.142234, Val Acc: 0.701031\n",
      "Epoch 10042 - Train Loss: 0.126117, Train Acc: 0.782051 | Val Loss: 0.142227, Val Acc: 0.701031\n",
      "Epoch 10043 - Train Loss: 0.126109, Train Acc: 0.782051 | Val Loss: 0.142220, Val Acc: 0.701031\n",
      "Epoch 10044 - Train Loss: 0.126100, Train Acc: 0.782051 | Val Loss: 0.142214, Val Acc: 0.701031\n",
      "Epoch 10045 - Train Loss: 0.126092, Train Acc: 0.782051 | Val Loss: 0.142207, Val Acc: 0.701031\n",
      "Epoch 10046 - Train Loss: 0.126084, Train Acc: 0.782051 | Val Loss: 0.142200, Val Acc: 0.701031\n",
      "Epoch 10047 - Train Loss: 0.126076, Train Acc: 0.782051 | Val Loss: 0.142193, Val Acc: 0.701031\n",
      "Epoch 10048 - Train Loss: 0.126068, Train Acc: 0.782051 | Val Loss: 0.142186, Val Acc: 0.701031\n",
      "Epoch 10049 - Train Loss: 0.126059, Train Acc: 0.782051 | Val Loss: 0.142179, Val Acc: 0.701031\n",
      "Epoch 10050 - Train Loss: 0.126051, Train Acc: 0.782051 | Val Loss: 0.142173, Val Acc: 0.701031\n",
      "Epoch 10051 - Train Loss: 0.126043, Train Acc: 0.782051 | Val Loss: 0.142166, Val Acc: 0.701031\n",
      "Epoch 10052 - Train Loss: 0.126035, Train Acc: 0.782051 | Val Loss: 0.142159, Val Acc: 0.701031\n",
      "Epoch 10053 - Train Loss: 0.126027, Train Acc: 0.782051 | Val Loss: 0.142152, Val Acc: 0.701031\n",
      "Epoch 10054 - Train Loss: 0.126018, Train Acc: 0.782051 | Val Loss: 0.142145, Val Acc: 0.701031\n",
      "Epoch 10055 - Train Loss: 0.126010, Train Acc: 0.782051 | Val Loss: 0.142138, Val Acc: 0.701031\n",
      "Epoch 10056 - Train Loss: 0.126002, Train Acc: 0.782051 | Val Loss: 0.142132, Val Acc: 0.701031\n",
      "Epoch 10057 - Train Loss: 0.125994, Train Acc: 0.782051 | Val Loss: 0.142125, Val Acc: 0.701031\n",
      "Epoch 10058 - Train Loss: 0.125986, Train Acc: 0.782051 | Val Loss: 0.142118, Val Acc: 0.701031\n",
      "Epoch 10059 - Train Loss: 0.125977, Train Acc: 0.782051 | Val Loss: 0.142111, Val Acc: 0.701031\n",
      "Epoch 10060 - Train Loss: 0.125969, Train Acc: 0.782051 | Val Loss: 0.142104, Val Acc: 0.701031\n",
      "Epoch 10061 - Train Loss: 0.125961, Train Acc: 0.782051 | Val Loss: 0.142097, Val Acc: 0.701031\n",
      "Epoch 10062 - Train Loss: 0.125953, Train Acc: 0.782051 | Val Loss: 0.142091, Val Acc: 0.701031\n",
      "Epoch 10063 - Train Loss: 0.125945, Train Acc: 0.782051 | Val Loss: 0.142084, Val Acc: 0.711340\n",
      "Epoch 10064 - Train Loss: 0.125936, Train Acc: 0.782051 | Val Loss: 0.142077, Val Acc: 0.711340\n",
      "Epoch 10065 - Train Loss: 0.125928, Train Acc: 0.782051 | Val Loss: 0.142070, Val Acc: 0.711340\n",
      "Epoch 10066 - Train Loss: 0.125920, Train Acc: 0.782051 | Val Loss: 0.142063, Val Acc: 0.711340\n",
      "Epoch 10067 - Train Loss: 0.125912, Train Acc: 0.782051 | Val Loss: 0.142056, Val Acc: 0.711340\n",
      "Epoch 10068 - Train Loss: 0.125904, Train Acc: 0.782051 | Val Loss: 0.142050, Val Acc: 0.711340\n",
      "Epoch 10069 - Train Loss: 0.125895, Train Acc: 0.782051 | Val Loss: 0.142043, Val Acc: 0.711340\n",
      "Epoch 10070 - Train Loss: 0.125887, Train Acc: 0.782051 | Val Loss: 0.142036, Val Acc: 0.711340\n",
      "Epoch 10071 - Train Loss: 0.125879, Train Acc: 0.782051 | Val Loss: 0.142029, Val Acc: 0.711340\n",
      "Epoch 10072 - Train Loss: 0.125871, Train Acc: 0.782051 | Val Loss: 0.142022, Val Acc: 0.711340\n",
      "Epoch 10073 - Train Loss: 0.125863, Train Acc: 0.782051 | Val Loss: 0.142016, Val Acc: 0.711340\n",
      "Epoch 10074 - Train Loss: 0.125855, Train Acc: 0.782051 | Val Loss: 0.142009, Val Acc: 0.711340\n",
      "Epoch 10075 - Train Loss: 0.125846, Train Acc: 0.782051 | Val Loss: 0.142002, Val Acc: 0.711340\n",
      "Epoch 10076 - Train Loss: 0.125838, Train Acc: 0.782051 | Val Loss: 0.141995, Val Acc: 0.711340\n",
      "Epoch 10077 - Train Loss: 0.125830, Train Acc: 0.782051 | Val Loss: 0.141988, Val Acc: 0.711340\n",
      "Epoch 10078 - Train Loss: 0.125822, Train Acc: 0.782051 | Val Loss: 0.141982, Val Acc: 0.711340\n",
      "Epoch 10079 - Train Loss: 0.125814, Train Acc: 0.782051 | Val Loss: 0.141975, Val Acc: 0.711340\n",
      "Epoch 10080 - Train Loss: 0.125805, Train Acc: 0.782051 | Val Loss: 0.141968, Val Acc: 0.711340\n",
      "Epoch 10081 - Train Loss: 0.125797, Train Acc: 0.782051 | Val Loss: 0.141961, Val Acc: 0.711340\n",
      "Epoch 10082 - Train Loss: 0.125789, Train Acc: 0.782051 | Val Loss: 0.141954, Val Acc: 0.711340\n",
      "Epoch 10083 - Train Loss: 0.125781, Train Acc: 0.783333 | Val Loss: 0.141948, Val Acc: 0.711340\n",
      "Epoch 10084 - Train Loss: 0.125773, Train Acc: 0.783333 | Val Loss: 0.141941, Val Acc: 0.711340\n",
      "Epoch 10085 - Train Loss: 0.125765, Train Acc: 0.783333 | Val Loss: 0.141934, Val Acc: 0.711340\n",
      "Epoch 10086 - Train Loss: 0.125756, Train Acc: 0.783333 | Val Loss: 0.141927, Val Acc: 0.711340\n",
      "Epoch 10087 - Train Loss: 0.125748, Train Acc: 0.783333 | Val Loss: 0.141920, Val Acc: 0.711340\n",
      "Epoch 10088 - Train Loss: 0.125740, Train Acc: 0.783333 | Val Loss: 0.141914, Val Acc: 0.711340\n",
      "Epoch 10089 - Train Loss: 0.125732, Train Acc: 0.783333 | Val Loss: 0.141907, Val Acc: 0.711340\n",
      "Epoch 10090 - Train Loss: 0.125724, Train Acc: 0.783333 | Val Loss: 0.141900, Val Acc: 0.711340\n",
      "Epoch 10091 - Train Loss: 0.125716, Train Acc: 0.783333 | Val Loss: 0.141893, Val Acc: 0.711340\n",
      "Epoch 10092 - Train Loss: 0.125707, Train Acc: 0.783333 | Val Loss: 0.141886, Val Acc: 0.711340\n",
      "Epoch 10093 - Train Loss: 0.125699, Train Acc: 0.783333 | Val Loss: 0.141880, Val Acc: 0.711340\n",
      "Epoch 10094 - Train Loss: 0.125691, Train Acc: 0.784615 | Val Loss: 0.141873, Val Acc: 0.711340\n",
      "Epoch 10095 - Train Loss: 0.125683, Train Acc: 0.784615 | Val Loss: 0.141866, Val Acc: 0.711340\n",
      "Epoch 10096 - Train Loss: 0.125675, Train Acc: 0.784615 | Val Loss: 0.141859, Val Acc: 0.711340\n",
      "Epoch 10097 - Train Loss: 0.125667, Train Acc: 0.785897 | Val Loss: 0.141853, Val Acc: 0.711340\n",
      "Epoch 10098 - Train Loss: 0.125659, Train Acc: 0.785897 | Val Loss: 0.141846, Val Acc: 0.711340\n",
      "Epoch 10099 - Train Loss: 0.125650, Train Acc: 0.785897 | Val Loss: 0.141839, Val Acc: 0.711340\n",
      "Epoch 10100 - Train Loss: 0.125642, Train Acc: 0.785897 | Val Loss: 0.141832, Val Acc: 0.711340\n",
      "Epoch 10101 - Train Loss: 0.125634, Train Acc: 0.785897 | Val Loss: 0.141825, Val Acc: 0.711340\n",
      "Epoch 10102 - Train Loss: 0.125626, Train Acc: 0.785897 | Val Loss: 0.141819, Val Acc: 0.711340\n",
      "Epoch 10103 - Train Loss: 0.125618, Train Acc: 0.785897 | Val Loss: 0.141812, Val Acc: 0.711340\n",
      "Epoch 10104 - Train Loss: 0.125610, Train Acc: 0.785897 | Val Loss: 0.141805, Val Acc: 0.711340\n",
      "Epoch 10105 - Train Loss: 0.125601, Train Acc: 0.785897 | Val Loss: 0.141798, Val Acc: 0.711340\n",
      "Epoch 10106 - Train Loss: 0.125593, Train Acc: 0.785897 | Val Loss: 0.141792, Val Acc: 0.711340\n",
      "Epoch 10107 - Train Loss: 0.125585, Train Acc: 0.785897 | Val Loss: 0.141785, Val Acc: 0.711340\n",
      "Epoch 10108 - Train Loss: 0.125577, Train Acc: 0.785897 | Val Loss: 0.141778, Val Acc: 0.711340\n",
      "Epoch 10109 - Train Loss: 0.125569, Train Acc: 0.785897 | Val Loss: 0.141771, Val Acc: 0.711340\n",
      "Epoch 10110 - Train Loss: 0.125561, Train Acc: 0.785897 | Val Loss: 0.141765, Val Acc: 0.711340\n",
      "Epoch 10111 - Train Loss: 0.125553, Train Acc: 0.785897 | Val Loss: 0.141758, Val Acc: 0.711340\n",
      "Epoch 10112 - Train Loss: 0.125544, Train Acc: 0.785897 | Val Loss: 0.141751, Val Acc: 0.711340\n",
      "Epoch 10113 - Train Loss: 0.125536, Train Acc: 0.785897 | Val Loss: 0.141744, Val Acc: 0.711340\n",
      "Epoch 10114 - Train Loss: 0.125528, Train Acc: 0.785897 | Val Loss: 0.141737, Val Acc: 0.711340\n",
      "Epoch 10115 - Train Loss: 0.125520, Train Acc: 0.785897 | Val Loss: 0.141731, Val Acc: 0.711340\n",
      "Epoch 10116 - Train Loss: 0.125512, Train Acc: 0.785897 | Val Loss: 0.141724, Val Acc: 0.711340\n",
      "Epoch 10117 - Train Loss: 0.125504, Train Acc: 0.785897 | Val Loss: 0.141717, Val Acc: 0.711340\n",
      "Epoch 10118 - Train Loss: 0.125496, Train Acc: 0.785897 | Val Loss: 0.141710, Val Acc: 0.711340\n",
      "Epoch 10119 - Train Loss: 0.125488, Train Acc: 0.785897 | Val Loss: 0.141704, Val Acc: 0.711340\n",
      "Epoch 10120 - Train Loss: 0.125479, Train Acc: 0.785897 | Val Loss: 0.141697, Val Acc: 0.711340\n",
      "Epoch 10121 - Train Loss: 0.125471, Train Acc: 0.785897 | Val Loss: 0.141690, Val Acc: 0.711340\n",
      "Epoch 10122 - Train Loss: 0.125463, Train Acc: 0.785897 | Val Loss: 0.141683, Val Acc: 0.711340\n",
      "Epoch 10123 - Train Loss: 0.125455, Train Acc: 0.785897 | Val Loss: 0.141677, Val Acc: 0.711340\n",
      "Epoch 10124 - Train Loss: 0.125447, Train Acc: 0.785897 | Val Loss: 0.141670, Val Acc: 0.711340\n",
      "Epoch 10125 - Train Loss: 0.125439, Train Acc: 0.785897 | Val Loss: 0.141663, Val Acc: 0.711340\n",
      "Epoch 10126 - Train Loss: 0.125431, Train Acc: 0.785897 | Val Loss: 0.141656, Val Acc: 0.711340\n",
      "Epoch 10127 - Train Loss: 0.125423, Train Acc: 0.785897 | Val Loss: 0.141650, Val Acc: 0.711340\n",
      "Epoch 10128 - Train Loss: 0.125414, Train Acc: 0.785897 | Val Loss: 0.141643, Val Acc: 0.711340\n",
      "Epoch 10129 - Train Loss: 0.125406, Train Acc: 0.787179 | Val Loss: 0.141636, Val Acc: 0.711340\n",
      "Epoch 10130 - Train Loss: 0.125398, Train Acc: 0.787179 | Val Loss: 0.141629, Val Acc: 0.711340\n",
      "Epoch 10131 - Train Loss: 0.125390, Train Acc: 0.787179 | Val Loss: 0.141623, Val Acc: 0.711340\n",
      "Epoch 10132 - Train Loss: 0.125382, Train Acc: 0.787179 | Val Loss: 0.141616, Val Acc: 0.711340\n",
      "Epoch 10133 - Train Loss: 0.125374, Train Acc: 0.787179 | Val Loss: 0.141609, Val Acc: 0.711340\n",
      "Epoch 10134 - Train Loss: 0.125366, Train Acc: 0.787179 | Val Loss: 0.141602, Val Acc: 0.711340\n",
      "Epoch 10135 - Train Loss: 0.125358, Train Acc: 0.787179 | Val Loss: 0.141596, Val Acc: 0.711340\n",
      "Epoch 10136 - Train Loss: 0.125350, Train Acc: 0.787179 | Val Loss: 0.141589, Val Acc: 0.711340\n",
      "Epoch 10137 - Train Loss: 0.125341, Train Acc: 0.787179 | Val Loss: 0.141582, Val Acc: 0.711340\n",
      "Epoch 10138 - Train Loss: 0.125333, Train Acc: 0.787179 | Val Loss: 0.141576, Val Acc: 0.711340\n",
      "Epoch 10139 - Train Loss: 0.125325, Train Acc: 0.787179 | Val Loss: 0.141569, Val Acc: 0.711340\n",
      "Epoch 10140 - Train Loss: 0.125317, Train Acc: 0.787179 | Val Loss: 0.141562, Val Acc: 0.711340\n",
      "Epoch 10141 - Train Loss: 0.125309, Train Acc: 0.787179 | Val Loss: 0.141555, Val Acc: 0.711340\n",
      "Epoch 10142 - Train Loss: 0.125301, Train Acc: 0.787179 | Val Loss: 0.141549, Val Acc: 0.711340\n",
      "Epoch 10143 - Train Loss: 0.125293, Train Acc: 0.787179 | Val Loss: 0.141542, Val Acc: 0.711340\n",
      "Epoch 10144 - Train Loss: 0.125285, Train Acc: 0.787179 | Val Loss: 0.141535, Val Acc: 0.711340\n",
      "Epoch 10145 - Train Loss: 0.125277, Train Acc: 0.787179 | Val Loss: 0.141528, Val Acc: 0.711340\n",
      "Epoch 10146 - Train Loss: 0.125268, Train Acc: 0.787179 | Val Loss: 0.141522, Val Acc: 0.711340\n",
      "Epoch 10147 - Train Loss: 0.125260, Train Acc: 0.788462 | Val Loss: 0.141515, Val Acc: 0.711340\n",
      "Epoch 10148 - Train Loss: 0.125252, Train Acc: 0.788462 | Val Loss: 0.141508, Val Acc: 0.711340\n",
      "Epoch 10149 - Train Loss: 0.125244, Train Acc: 0.788462 | Val Loss: 0.141502, Val Acc: 0.711340\n",
      "Epoch 10150 - Train Loss: 0.125236, Train Acc: 0.788462 | Val Loss: 0.141495, Val Acc: 0.711340\n",
      "Epoch 10151 - Train Loss: 0.125228, Train Acc: 0.788462 | Val Loss: 0.141488, Val Acc: 0.711340\n",
      "Epoch 10152 - Train Loss: 0.125220, Train Acc: 0.788462 | Val Loss: 0.141481, Val Acc: 0.711340\n",
      "Epoch 10153 - Train Loss: 0.125212, Train Acc: 0.788462 | Val Loss: 0.141475, Val Acc: 0.711340\n",
      "Epoch 10154 - Train Loss: 0.125204, Train Acc: 0.788462 | Val Loss: 0.141468, Val Acc: 0.711340\n",
      "Epoch 10155 - Train Loss: 0.125196, Train Acc: 0.788462 | Val Loss: 0.141461, Val Acc: 0.711340\n",
      "Epoch 10156 - Train Loss: 0.125188, Train Acc: 0.788462 | Val Loss: 0.141455, Val Acc: 0.711340\n",
      "Epoch 10157 - Train Loss: 0.125179, Train Acc: 0.788462 | Val Loss: 0.141448, Val Acc: 0.711340\n",
      "Epoch 10158 - Train Loss: 0.125171, Train Acc: 0.788462 | Val Loss: 0.141441, Val Acc: 0.721649\n",
      "Epoch 10159 - Train Loss: 0.125163, Train Acc: 0.788462 | Val Loss: 0.141434, Val Acc: 0.721649\n",
      "Epoch 10160 - Train Loss: 0.125155, Train Acc: 0.788462 | Val Loss: 0.141428, Val Acc: 0.721649\n",
      "Epoch 10161 - Train Loss: 0.125147, Train Acc: 0.788462 | Val Loss: 0.141421, Val Acc: 0.721649\n",
      "Epoch 10162 - Train Loss: 0.125139, Train Acc: 0.788462 | Val Loss: 0.141414, Val Acc: 0.721649\n",
      "Epoch 10163 - Train Loss: 0.125131, Train Acc: 0.788462 | Val Loss: 0.141408, Val Acc: 0.721649\n",
      "Epoch 10164 - Train Loss: 0.125123, Train Acc: 0.788462 | Val Loss: 0.141401, Val Acc: 0.721649\n",
      "Epoch 10165 - Train Loss: 0.125115, Train Acc: 0.788462 | Val Loss: 0.141394, Val Acc: 0.721649\n",
      "Epoch 10166 - Train Loss: 0.125107, Train Acc: 0.788462 | Val Loss: 0.141388, Val Acc: 0.721649\n",
      "Epoch 10167 - Train Loss: 0.125099, Train Acc: 0.788462 | Val Loss: 0.141381, Val Acc: 0.721649\n",
      "Epoch 10168 - Train Loss: 0.125091, Train Acc: 0.788462 | Val Loss: 0.141374, Val Acc: 0.721649\n",
      "Epoch 10169 - Train Loss: 0.125082, Train Acc: 0.788462 | Val Loss: 0.141367, Val Acc: 0.721649\n",
      "Epoch 10170 - Train Loss: 0.125074, Train Acc: 0.788462 | Val Loss: 0.141361, Val Acc: 0.721649\n",
      "Epoch 10171 - Train Loss: 0.125066, Train Acc: 0.788462 | Val Loss: 0.141354, Val Acc: 0.721649\n",
      "Epoch 10172 - Train Loss: 0.125058, Train Acc: 0.788462 | Val Loss: 0.141347, Val Acc: 0.721649\n",
      "Epoch 10173 - Train Loss: 0.125050, Train Acc: 0.788462 | Val Loss: 0.141341, Val Acc: 0.721649\n",
      "Epoch 10174 - Train Loss: 0.125042, Train Acc: 0.788462 | Val Loss: 0.141334, Val Acc: 0.721649\n",
      "Epoch 10175 - Train Loss: 0.125034, Train Acc: 0.788462 | Val Loss: 0.141327, Val Acc: 0.721649\n",
      "Epoch 10176 - Train Loss: 0.125026, Train Acc: 0.788462 | Val Loss: 0.141321, Val Acc: 0.721649\n",
      "Epoch 10177 - Train Loss: 0.125018, Train Acc: 0.788462 | Val Loss: 0.141314, Val Acc: 0.721649\n",
      "Epoch 10178 - Train Loss: 0.125010, Train Acc: 0.788462 | Val Loss: 0.141307, Val Acc: 0.721649\n",
      "Epoch 10179 - Train Loss: 0.125002, Train Acc: 0.788462 | Val Loss: 0.141301, Val Acc: 0.721649\n",
      "Epoch 10180 - Train Loss: 0.124994, Train Acc: 0.788462 | Val Loss: 0.141294, Val Acc: 0.721649\n",
      "Epoch 10181 - Train Loss: 0.124986, Train Acc: 0.788462 | Val Loss: 0.141287, Val Acc: 0.721649\n",
      "Epoch 10182 - Train Loss: 0.124978, Train Acc: 0.788462 | Val Loss: 0.141280, Val Acc: 0.721649\n",
      "Epoch 10183 - Train Loss: 0.124970, Train Acc: 0.788462 | Val Loss: 0.141274, Val Acc: 0.721649\n",
      "Epoch 10184 - Train Loss: 0.124961, Train Acc: 0.788462 | Val Loss: 0.141267, Val Acc: 0.721649\n",
      "Epoch 10185 - Train Loss: 0.124953, Train Acc: 0.788462 | Val Loss: 0.141260, Val Acc: 0.721649\n",
      "Epoch 10186 - Train Loss: 0.124945, Train Acc: 0.788462 | Val Loss: 0.141254, Val Acc: 0.721649\n",
      "Epoch 10187 - Train Loss: 0.124937, Train Acc: 0.788462 | Val Loss: 0.141247, Val Acc: 0.721649\n",
      "Epoch 10188 - Train Loss: 0.124929, Train Acc: 0.788462 | Val Loss: 0.141240, Val Acc: 0.721649\n",
      "Epoch 10189 - Train Loss: 0.124921, Train Acc: 0.788462 | Val Loss: 0.141234, Val Acc: 0.721649\n",
      "Epoch 10190 - Train Loss: 0.124913, Train Acc: 0.788462 | Val Loss: 0.141227, Val Acc: 0.721649\n",
      "Epoch 10191 - Train Loss: 0.124905, Train Acc: 0.788462 | Val Loss: 0.141220, Val Acc: 0.721649\n",
      "Epoch 10192 - Train Loss: 0.124897, Train Acc: 0.788462 | Val Loss: 0.141214, Val Acc: 0.721649\n",
      "Epoch 10193 - Train Loss: 0.124889, Train Acc: 0.788462 | Val Loss: 0.141207, Val Acc: 0.721649\n",
      "Epoch 10194 - Train Loss: 0.124881, Train Acc: 0.787179 | Val Loss: 0.141200, Val Acc: 0.721649\n",
      "Epoch 10195 - Train Loss: 0.124873, Train Acc: 0.787179 | Val Loss: 0.141194, Val Acc: 0.721649\n",
      "Epoch 10196 - Train Loss: 0.124865, Train Acc: 0.787179 | Val Loss: 0.141187, Val Acc: 0.721649\n",
      "Epoch 10197 - Train Loss: 0.124857, Train Acc: 0.787179 | Val Loss: 0.141180, Val Acc: 0.721649\n",
      "Epoch 10198 - Train Loss: 0.124849, Train Acc: 0.787179 | Val Loss: 0.141174, Val Acc: 0.721649\n",
      "Epoch 10199 - Train Loss: 0.124841, Train Acc: 0.787179 | Val Loss: 0.141167, Val Acc: 0.721649\n",
      "Epoch 10200 - Train Loss: 0.124833, Train Acc: 0.787179 | Val Loss: 0.141160, Val Acc: 0.721649\n",
      "Epoch 10201 - Train Loss: 0.124825, Train Acc: 0.787179 | Val Loss: 0.141154, Val Acc: 0.721649\n",
      "Epoch 10202 - Train Loss: 0.124817, Train Acc: 0.787179 | Val Loss: 0.141147, Val Acc: 0.721649\n",
      "Epoch 10203 - Train Loss: 0.124809, Train Acc: 0.787179 | Val Loss: 0.141140, Val Acc: 0.721649\n",
      "Epoch 10204 - Train Loss: 0.124800, Train Acc: 0.787179 | Val Loss: 0.141134, Val Acc: 0.721649\n",
      "Epoch 10205 - Train Loss: 0.124792, Train Acc: 0.787179 | Val Loss: 0.141127, Val Acc: 0.721649\n",
      "Epoch 10206 - Train Loss: 0.124784, Train Acc: 0.787179 | Val Loss: 0.141120, Val Acc: 0.721649\n",
      "Epoch 10207 - Train Loss: 0.124776, Train Acc: 0.787179 | Val Loss: 0.141114, Val Acc: 0.721649\n",
      "Epoch 10208 - Train Loss: 0.124768, Train Acc: 0.787179 | Val Loss: 0.141107, Val Acc: 0.721649\n",
      "Epoch 10209 - Train Loss: 0.124760, Train Acc: 0.787179 | Val Loss: 0.141101, Val Acc: 0.721649\n",
      "Epoch 10210 - Train Loss: 0.124752, Train Acc: 0.787179 | Val Loss: 0.141094, Val Acc: 0.721649\n",
      "Epoch 10211 - Train Loss: 0.124744, Train Acc: 0.787179 | Val Loss: 0.141087, Val Acc: 0.721649\n",
      "Epoch 10212 - Train Loss: 0.124736, Train Acc: 0.787179 | Val Loss: 0.141081, Val Acc: 0.721649\n",
      "Epoch 10213 - Train Loss: 0.124728, Train Acc: 0.787179 | Val Loss: 0.141074, Val Acc: 0.721649\n",
      "Epoch 10214 - Train Loss: 0.124720, Train Acc: 0.787179 | Val Loss: 0.141067, Val Acc: 0.721649\n",
      "Epoch 10215 - Train Loss: 0.124712, Train Acc: 0.787179 | Val Loss: 0.141061, Val Acc: 0.721649\n",
      "Epoch 10216 - Train Loss: 0.124704, Train Acc: 0.787179 | Val Loss: 0.141054, Val Acc: 0.721649\n",
      "Epoch 10217 - Train Loss: 0.124696, Train Acc: 0.787179 | Val Loss: 0.141047, Val Acc: 0.721649\n",
      "Epoch 10218 - Train Loss: 0.124688, Train Acc: 0.787179 | Val Loss: 0.141041, Val Acc: 0.721649\n",
      "Epoch 10219 - Train Loss: 0.124680, Train Acc: 0.787179 | Val Loss: 0.141034, Val Acc: 0.721649\n",
      "Epoch 10220 - Train Loss: 0.124672, Train Acc: 0.787179 | Val Loss: 0.141027, Val Acc: 0.721649\n",
      "Epoch 10221 - Train Loss: 0.124664, Train Acc: 0.787179 | Val Loss: 0.141021, Val Acc: 0.721649\n",
      "Epoch 10222 - Train Loss: 0.124656, Train Acc: 0.787179 | Val Loss: 0.141014, Val Acc: 0.721649\n",
      "Epoch 10223 - Train Loss: 0.124648, Train Acc: 0.787179 | Val Loss: 0.141008, Val Acc: 0.721649\n",
      "Epoch 10224 - Train Loss: 0.124640, Train Acc: 0.787179 | Val Loss: 0.141001, Val Acc: 0.721649\n",
      "Epoch 10225 - Train Loss: 0.124632, Train Acc: 0.787179 | Val Loss: 0.140994, Val Acc: 0.721649\n",
      "Epoch 10226 - Train Loss: 0.124624, Train Acc: 0.787179 | Val Loss: 0.140988, Val Acc: 0.721649\n",
      "Epoch 10227 - Train Loss: 0.124616, Train Acc: 0.787179 | Val Loss: 0.140981, Val Acc: 0.721649\n",
      "Epoch 10228 - Train Loss: 0.124608, Train Acc: 0.787179 | Val Loss: 0.140974, Val Acc: 0.721649\n",
      "Epoch 10229 - Train Loss: 0.124600, Train Acc: 0.787179 | Val Loss: 0.140968, Val Acc: 0.721649\n",
      "Epoch 10230 - Train Loss: 0.124592, Train Acc: 0.787179 | Val Loss: 0.140961, Val Acc: 0.721649\n",
      "Epoch 10231 - Train Loss: 0.124584, Train Acc: 0.787179 | Val Loss: 0.140954, Val Acc: 0.721649\n",
      "Epoch 10232 - Train Loss: 0.124576, Train Acc: 0.787179 | Val Loss: 0.140948, Val Acc: 0.721649\n",
      "Epoch 10233 - Train Loss: 0.124568, Train Acc: 0.787179 | Val Loss: 0.140941, Val Acc: 0.721649\n",
      "Epoch 10234 - Train Loss: 0.124560, Train Acc: 0.787179 | Val Loss: 0.140935, Val Acc: 0.721649\n",
      "Epoch 10235 - Train Loss: 0.124552, Train Acc: 0.787179 | Val Loss: 0.140928, Val Acc: 0.721649\n",
      "Epoch 10236 - Train Loss: 0.124544, Train Acc: 0.788462 | Val Loss: 0.140921, Val Acc: 0.721649\n",
      "Epoch 10237 - Train Loss: 0.124536, Train Acc: 0.788462 | Val Loss: 0.140915, Val Acc: 0.721649\n",
      "Epoch 10238 - Train Loss: 0.124528, Train Acc: 0.788462 | Val Loss: 0.140908, Val Acc: 0.721649\n",
      "Epoch 10239 - Train Loss: 0.124520, Train Acc: 0.788462 | Val Loss: 0.140902, Val Acc: 0.721649\n",
      "Epoch 10240 - Train Loss: 0.124512, Train Acc: 0.788462 | Val Loss: 0.140895, Val Acc: 0.721649\n",
      "Epoch 10241 - Train Loss: 0.124504, Train Acc: 0.788462 | Val Loss: 0.140888, Val Acc: 0.721649\n",
      "Epoch 10242 - Train Loss: 0.124496, Train Acc: 0.788462 | Val Loss: 0.140882, Val Acc: 0.721649\n",
      "Epoch 10243 - Train Loss: 0.124488, Train Acc: 0.788462 | Val Loss: 0.140875, Val Acc: 0.721649\n",
      "Epoch 10244 - Train Loss: 0.124480, Train Acc: 0.788462 | Val Loss: 0.140868, Val Acc: 0.721649\n",
      "Epoch 10245 - Train Loss: 0.124472, Train Acc: 0.788462 | Val Loss: 0.140862, Val Acc: 0.721649\n",
      "Epoch 10246 - Train Loss: 0.124464, Train Acc: 0.788462 | Val Loss: 0.140855, Val Acc: 0.721649\n",
      "Epoch 10247 - Train Loss: 0.124456, Train Acc: 0.788462 | Val Loss: 0.140849, Val Acc: 0.721649\n",
      "Epoch 10248 - Train Loss: 0.124448, Train Acc: 0.788462 | Val Loss: 0.140842, Val Acc: 0.721649\n",
      "Epoch 10249 - Train Loss: 0.124440, Train Acc: 0.788462 | Val Loss: 0.140835, Val Acc: 0.721649\n",
      "Epoch 10250 - Train Loss: 0.124432, Train Acc: 0.788462 | Val Loss: 0.140829, Val Acc: 0.721649\n",
      "Epoch 10251 - Train Loss: 0.124424, Train Acc: 0.788462 | Val Loss: 0.140822, Val Acc: 0.721649\n",
      "Epoch 10252 - Train Loss: 0.124416, Train Acc: 0.788462 | Val Loss: 0.140816, Val Acc: 0.721649\n",
      "Epoch 10253 - Train Loss: 0.124408, Train Acc: 0.788462 | Val Loss: 0.140809, Val Acc: 0.721649\n",
      "Epoch 10254 - Train Loss: 0.124400, Train Acc: 0.788462 | Val Loss: 0.140802, Val Acc: 0.721649\n",
      "Epoch 10255 - Train Loss: 0.124392, Train Acc: 0.788462 | Val Loss: 0.140796, Val Acc: 0.721649\n",
      "Epoch 10256 - Train Loss: 0.124384, Train Acc: 0.788462 | Val Loss: 0.140789, Val Acc: 0.721649\n",
      "Epoch 10257 - Train Loss: 0.124376, Train Acc: 0.788462 | Val Loss: 0.140783, Val Acc: 0.721649\n",
      "Epoch 10258 - Train Loss: 0.124368, Train Acc: 0.788462 | Val Loss: 0.140776, Val Acc: 0.721649\n",
      "Epoch 10259 - Train Loss: 0.124360, Train Acc: 0.788462 | Val Loss: 0.140769, Val Acc: 0.721649\n",
      "Epoch 10260 - Train Loss: 0.124352, Train Acc: 0.788462 | Val Loss: 0.140763, Val Acc: 0.721649\n",
      "Epoch 10261 - Train Loss: 0.124344, Train Acc: 0.788462 | Val Loss: 0.140756, Val Acc: 0.721649\n",
      "Epoch 10262 - Train Loss: 0.124336, Train Acc: 0.788462 | Val Loss: 0.140750, Val Acc: 0.721649\n",
      "Epoch 10263 - Train Loss: 0.124328, Train Acc: 0.788462 | Val Loss: 0.140743, Val Acc: 0.721649\n",
      "Epoch 10264 - Train Loss: 0.124320, Train Acc: 0.788462 | Val Loss: 0.140736, Val Acc: 0.721649\n",
      "Epoch 10265 - Train Loss: 0.124312, Train Acc: 0.788462 | Val Loss: 0.140730, Val Acc: 0.721649\n",
      "Epoch 10266 - Train Loss: 0.124304, Train Acc: 0.788462 | Val Loss: 0.140723, Val Acc: 0.721649\n",
      "Epoch 10267 - Train Loss: 0.124296, Train Acc: 0.788462 | Val Loss: 0.140717, Val Acc: 0.721649\n",
      "Epoch 10268 - Train Loss: 0.124288, Train Acc: 0.788462 | Val Loss: 0.140710, Val Acc: 0.721649\n",
      "Epoch 10269 - Train Loss: 0.124280, Train Acc: 0.788462 | Val Loss: 0.140703, Val Acc: 0.721649\n",
      "Epoch 10270 - Train Loss: 0.124272, Train Acc: 0.788462 | Val Loss: 0.140697, Val Acc: 0.721649\n",
      "Epoch 10271 - Train Loss: 0.124265, Train Acc: 0.788462 | Val Loss: 0.140690, Val Acc: 0.721649\n",
      "Epoch 10272 - Train Loss: 0.124257, Train Acc: 0.788462 | Val Loss: 0.140684, Val Acc: 0.721649\n",
      "Epoch 10273 - Train Loss: 0.124249, Train Acc: 0.788462 | Val Loss: 0.140677, Val Acc: 0.721649\n",
      "Epoch 10274 - Train Loss: 0.124241, Train Acc: 0.788462 | Val Loss: 0.140671, Val Acc: 0.721649\n",
      "Epoch 10275 - Train Loss: 0.124233, Train Acc: 0.788462 | Val Loss: 0.140664, Val Acc: 0.721649\n",
      "Epoch 10276 - Train Loss: 0.124225, Train Acc: 0.788462 | Val Loss: 0.140657, Val Acc: 0.721649\n",
      "Epoch 10277 - Train Loss: 0.124217, Train Acc: 0.788462 | Val Loss: 0.140651, Val Acc: 0.721649\n",
      "Epoch 10278 - Train Loss: 0.124209, Train Acc: 0.788462 | Val Loss: 0.140644, Val Acc: 0.721649\n",
      "Epoch 10279 - Train Loss: 0.124201, Train Acc: 0.788462 | Val Loss: 0.140638, Val Acc: 0.721649\n",
      "Epoch 10280 - Train Loss: 0.124193, Train Acc: 0.788462 | Val Loss: 0.140631, Val Acc: 0.721649\n",
      "Epoch 10281 - Train Loss: 0.124185, Train Acc: 0.788462 | Val Loss: 0.140625, Val Acc: 0.721649\n",
      "Epoch 10282 - Train Loss: 0.124177, Train Acc: 0.788462 | Val Loss: 0.140618, Val Acc: 0.721649\n",
      "Epoch 10283 - Train Loss: 0.124169, Train Acc: 0.788462 | Val Loss: 0.140611, Val Acc: 0.721649\n",
      "Epoch 10284 - Train Loss: 0.124161, Train Acc: 0.788462 | Val Loss: 0.140605, Val Acc: 0.721649\n",
      "Epoch 10285 - Train Loss: 0.124153, Train Acc: 0.788462 | Val Loss: 0.140598, Val Acc: 0.721649\n",
      "Epoch 10286 - Train Loss: 0.124145, Train Acc: 0.788462 | Val Loss: 0.140592, Val Acc: 0.721649\n",
      "Epoch 10287 - Train Loss: 0.124137, Train Acc: 0.788462 | Val Loss: 0.140585, Val Acc: 0.721649\n",
      "Epoch 10288 - Train Loss: 0.124129, Train Acc: 0.788462 | Val Loss: 0.140579, Val Acc: 0.721649\n",
      "Epoch 10289 - Train Loss: 0.124121, Train Acc: 0.788462 | Val Loss: 0.140572, Val Acc: 0.721649\n",
      "Epoch 10290 - Train Loss: 0.124113, Train Acc: 0.788462 | Val Loss: 0.140565, Val Acc: 0.721649\n",
      "Epoch 10291 - Train Loss: 0.124105, Train Acc: 0.788462 | Val Loss: 0.140559, Val Acc: 0.721649\n",
      "Epoch 10292 - Train Loss: 0.124098, Train Acc: 0.788462 | Val Loss: 0.140552, Val Acc: 0.721649\n",
      "Epoch 10293 - Train Loss: 0.124090, Train Acc: 0.788462 | Val Loss: 0.140546, Val Acc: 0.721649\n",
      "Epoch 10294 - Train Loss: 0.124082, Train Acc: 0.788462 | Val Loss: 0.140539, Val Acc: 0.721649\n",
      "Epoch 10295 - Train Loss: 0.124074, Train Acc: 0.788462 | Val Loss: 0.140533, Val Acc: 0.721649\n",
      "Epoch 10296 - Train Loss: 0.124066, Train Acc: 0.789744 | Val Loss: 0.140526, Val Acc: 0.721649\n",
      "Epoch 10297 - Train Loss: 0.124058, Train Acc: 0.789744 | Val Loss: 0.140519, Val Acc: 0.721649\n",
      "Epoch 10298 - Train Loss: 0.124050, Train Acc: 0.789744 | Val Loss: 0.140513, Val Acc: 0.721649\n",
      "Epoch 10299 - Train Loss: 0.124042, Train Acc: 0.789744 | Val Loss: 0.140506, Val Acc: 0.721649\n",
      "Epoch 10300 - Train Loss: 0.124034, Train Acc: 0.789744 | Val Loss: 0.140500, Val Acc: 0.721649\n",
      "Epoch 10301 - Train Loss: 0.124026, Train Acc: 0.789744 | Val Loss: 0.140493, Val Acc: 0.721649\n",
      "Epoch 10302 - Train Loss: 0.124018, Train Acc: 0.789744 | Val Loss: 0.140487, Val Acc: 0.721649\n",
      "Epoch 10303 - Train Loss: 0.124010, Train Acc: 0.789744 | Val Loss: 0.140480, Val Acc: 0.721649\n",
      "Epoch 10304 - Train Loss: 0.124002, Train Acc: 0.791026 | Val Loss: 0.140474, Val Acc: 0.721649\n",
      "Epoch 10305 - Train Loss: 0.123994, Train Acc: 0.791026 | Val Loss: 0.140467, Val Acc: 0.721649\n",
      "Epoch 10306 - Train Loss: 0.123986, Train Acc: 0.791026 | Val Loss: 0.140461, Val Acc: 0.721649\n",
      "Epoch 10307 - Train Loss: 0.123979, Train Acc: 0.791026 | Val Loss: 0.140454, Val Acc: 0.721649\n",
      "Epoch 10308 - Train Loss: 0.123971, Train Acc: 0.791026 | Val Loss: 0.140447, Val Acc: 0.721649\n",
      "Epoch 10309 - Train Loss: 0.123963, Train Acc: 0.791026 | Val Loss: 0.140441, Val Acc: 0.721649\n",
      "Epoch 10310 - Train Loss: 0.123955, Train Acc: 0.791026 | Val Loss: 0.140434, Val Acc: 0.721649\n",
      "Epoch 10311 - Train Loss: 0.123947, Train Acc: 0.791026 | Val Loss: 0.140428, Val Acc: 0.721649\n",
      "Epoch 10312 - Train Loss: 0.123939, Train Acc: 0.791026 | Val Loss: 0.140421, Val Acc: 0.721649\n",
      "Epoch 10313 - Train Loss: 0.123931, Train Acc: 0.791026 | Val Loss: 0.140415, Val Acc: 0.721649\n",
      "Epoch 10314 - Train Loss: 0.123923, Train Acc: 0.791026 | Val Loss: 0.140408, Val Acc: 0.721649\n",
      "Epoch 10315 - Train Loss: 0.123915, Train Acc: 0.791026 | Val Loss: 0.140402, Val Acc: 0.721649\n",
      "Epoch 10316 - Train Loss: 0.123907, Train Acc: 0.791026 | Val Loss: 0.140395, Val Acc: 0.721649\n",
      "Epoch 10317 - Train Loss: 0.123899, Train Acc: 0.791026 | Val Loss: 0.140389, Val Acc: 0.721649\n",
      "Epoch 10318 - Train Loss: 0.123891, Train Acc: 0.791026 | Val Loss: 0.140382, Val Acc: 0.721649\n",
      "Epoch 10319 - Train Loss: 0.123884, Train Acc: 0.791026 | Val Loss: 0.140376, Val Acc: 0.721649\n",
      "Epoch 10320 - Train Loss: 0.123876, Train Acc: 0.791026 | Val Loss: 0.140369, Val Acc: 0.721649\n",
      "Epoch 10321 - Train Loss: 0.123868, Train Acc: 0.791026 | Val Loss: 0.140362, Val Acc: 0.721649\n",
      "Epoch 10322 - Train Loss: 0.123860, Train Acc: 0.791026 | Val Loss: 0.140356, Val Acc: 0.721649\n",
      "Epoch 10323 - Train Loss: 0.123852, Train Acc: 0.791026 | Val Loss: 0.140349, Val Acc: 0.721649\n",
      "Epoch 10324 - Train Loss: 0.123844, Train Acc: 0.792308 | Val Loss: 0.140343, Val Acc: 0.721649\n",
      "Epoch 10325 - Train Loss: 0.123836, Train Acc: 0.792308 | Val Loss: 0.140336, Val Acc: 0.721649\n",
      "Epoch 10326 - Train Loss: 0.123828, Train Acc: 0.792308 | Val Loss: 0.140330, Val Acc: 0.721649\n",
      "Epoch 10327 - Train Loss: 0.123820, Train Acc: 0.792308 | Val Loss: 0.140323, Val Acc: 0.721649\n",
      "Epoch 10328 - Train Loss: 0.123812, Train Acc: 0.792308 | Val Loss: 0.140317, Val Acc: 0.721649\n",
      "Epoch 10329 - Train Loss: 0.123804, Train Acc: 0.792308 | Val Loss: 0.140310, Val Acc: 0.721649\n",
      "Epoch 10330 - Train Loss: 0.123797, Train Acc: 0.792308 | Val Loss: 0.140304, Val Acc: 0.721649\n",
      "Epoch 10331 - Train Loss: 0.123789, Train Acc: 0.792308 | Val Loss: 0.140297, Val Acc: 0.721649\n",
      "Epoch 10332 - Train Loss: 0.123781, Train Acc: 0.792308 | Val Loss: 0.140291, Val Acc: 0.721649\n",
      "Epoch 10333 - Train Loss: 0.123773, Train Acc: 0.792308 | Val Loss: 0.140284, Val Acc: 0.721649\n",
      "Epoch 10334 - Train Loss: 0.123765, Train Acc: 0.792308 | Val Loss: 0.140278, Val Acc: 0.721649\n",
      "Epoch 10335 - Train Loss: 0.123757, Train Acc: 0.792308 | Val Loss: 0.140271, Val Acc: 0.721649\n",
      "Epoch 10336 - Train Loss: 0.123749, Train Acc: 0.792308 | Val Loss: 0.140265, Val Acc: 0.721649\n",
      "Epoch 10337 - Train Loss: 0.123741, Train Acc: 0.792308 | Val Loss: 0.140258, Val Acc: 0.721649\n",
      "Epoch 10338 - Train Loss: 0.123733, Train Acc: 0.792308 | Val Loss: 0.140252, Val Acc: 0.721649\n",
      "Epoch 10339 - Train Loss: 0.123726, Train Acc: 0.792308 | Val Loss: 0.140245, Val Acc: 0.721649\n",
      "Epoch 10340 - Train Loss: 0.123718, Train Acc: 0.792308 | Val Loss: 0.140239, Val Acc: 0.721649\n",
      "Epoch 10341 - Train Loss: 0.123710, Train Acc: 0.792308 | Val Loss: 0.140232, Val Acc: 0.721649\n",
      "Epoch 10342 - Train Loss: 0.123702, Train Acc: 0.792308 | Val Loss: 0.140226, Val Acc: 0.721649\n",
      "Epoch 10343 - Train Loss: 0.123694, Train Acc: 0.792308 | Val Loss: 0.140219, Val Acc: 0.721649\n",
      "Epoch 10344 - Train Loss: 0.123686, Train Acc: 0.792308 | Val Loss: 0.140213, Val Acc: 0.721649\n",
      "Epoch 10345 - Train Loss: 0.123678, Train Acc: 0.792308 | Val Loss: 0.140206, Val Acc: 0.721649\n",
      "Epoch 10346 - Train Loss: 0.123670, Train Acc: 0.792308 | Val Loss: 0.140200, Val Acc: 0.721649\n",
      "Epoch 10347 - Train Loss: 0.123662, Train Acc: 0.792308 | Val Loss: 0.140193, Val Acc: 0.721649\n",
      "Epoch 10348 - Train Loss: 0.123655, Train Acc: 0.792308 | Val Loss: 0.140187, Val Acc: 0.721649\n",
      "Epoch 10349 - Train Loss: 0.123647, Train Acc: 0.792308 | Val Loss: 0.140180, Val Acc: 0.721649\n",
      "Epoch 10350 - Train Loss: 0.123639, Train Acc: 0.792308 | Val Loss: 0.140174, Val Acc: 0.721649\n",
      "Epoch 10351 - Train Loss: 0.123631, Train Acc: 0.792308 | Val Loss: 0.140167, Val Acc: 0.721649\n",
      "Epoch 10352 - Train Loss: 0.123623, Train Acc: 0.792308 | Val Loss: 0.140161, Val Acc: 0.721649\n",
      "Epoch 10353 - Train Loss: 0.123615, Train Acc: 0.792308 | Val Loss: 0.140154, Val Acc: 0.721649\n",
      "Epoch 10354 - Train Loss: 0.123607, Train Acc: 0.792308 | Val Loss: 0.140148, Val Acc: 0.721649\n",
      "Epoch 10355 - Train Loss: 0.123599, Train Acc: 0.792308 | Val Loss: 0.140141, Val Acc: 0.721649\n",
      "Epoch 10356 - Train Loss: 0.123592, Train Acc: 0.792308 | Val Loss: 0.140135, Val Acc: 0.721649\n",
      "Epoch 10357 - Train Loss: 0.123584, Train Acc: 0.792308 | Val Loss: 0.140128, Val Acc: 0.721649\n",
      "Epoch 10358 - Train Loss: 0.123576, Train Acc: 0.792308 | Val Loss: 0.140122, Val Acc: 0.721649\n",
      "Epoch 10359 - Train Loss: 0.123568, Train Acc: 0.792308 | Val Loss: 0.140115, Val Acc: 0.721649\n",
      "Epoch 10360 - Train Loss: 0.123560, Train Acc: 0.792308 | Val Loss: 0.140109, Val Acc: 0.721649\n",
      "Epoch 10361 - Train Loss: 0.123552, Train Acc: 0.792308 | Val Loss: 0.140102, Val Acc: 0.721649\n",
      "Epoch 10362 - Train Loss: 0.123544, Train Acc: 0.792308 | Val Loss: 0.140096, Val Acc: 0.721649\n",
      "Epoch 10363 - Train Loss: 0.123536, Train Acc: 0.792308 | Val Loss: 0.140089, Val Acc: 0.721649\n",
      "Epoch 10364 - Train Loss: 0.123529, Train Acc: 0.792308 | Val Loss: 0.140083, Val Acc: 0.721649\n",
      "Epoch 10365 - Train Loss: 0.123521, Train Acc: 0.792308 | Val Loss: 0.140076, Val Acc: 0.721649\n",
      "Epoch 10366 - Train Loss: 0.123513, Train Acc: 0.792308 | Val Loss: 0.140070, Val Acc: 0.721649\n",
      "Epoch 10367 - Train Loss: 0.123505, Train Acc: 0.792308 | Val Loss: 0.140063, Val Acc: 0.721649\n",
      "Epoch 10368 - Train Loss: 0.123497, Train Acc: 0.792308 | Val Loss: 0.140057, Val Acc: 0.721649\n",
      "Epoch 10369 - Train Loss: 0.123489, Train Acc: 0.792308 | Val Loss: 0.140050, Val Acc: 0.721649\n",
      "Epoch 10370 - Train Loss: 0.123481, Train Acc: 0.792308 | Val Loss: 0.140044, Val Acc: 0.721649\n",
      "Epoch 10371 - Train Loss: 0.123474, Train Acc: 0.792308 | Val Loss: 0.140037, Val Acc: 0.721649\n",
      "Epoch 10372 - Train Loss: 0.123466, Train Acc: 0.792308 | Val Loss: 0.140031, Val Acc: 0.721649\n",
      "Epoch 10373 - Train Loss: 0.123458, Train Acc: 0.792308 | Val Loss: 0.140024, Val Acc: 0.721649\n",
      "Epoch 10374 - Train Loss: 0.123450, Train Acc: 0.792308 | Val Loss: 0.140018, Val Acc: 0.721649\n",
      "Epoch 10375 - Train Loss: 0.123442, Train Acc: 0.792308 | Val Loss: 0.140012, Val Acc: 0.721649\n",
      "Epoch 10376 - Train Loss: 0.123434, Train Acc: 0.792308 | Val Loss: 0.140005, Val Acc: 0.721649\n",
      "Epoch 10377 - Train Loss: 0.123426, Train Acc: 0.792308 | Val Loss: 0.139999, Val Acc: 0.721649\n",
      "Epoch 10378 - Train Loss: 0.123419, Train Acc: 0.792308 | Val Loss: 0.139992, Val Acc: 0.721649\n",
      "Epoch 10379 - Train Loss: 0.123411, Train Acc: 0.792308 | Val Loss: 0.139986, Val Acc: 0.721649\n",
      "Epoch 10380 - Train Loss: 0.123403, Train Acc: 0.792308 | Val Loss: 0.139979, Val Acc: 0.721649\n",
      "Epoch 10381 - Train Loss: 0.123395, Train Acc: 0.792308 | Val Loss: 0.139973, Val Acc: 0.721649\n",
      "Epoch 10382 - Train Loss: 0.123387, Train Acc: 0.792308 | Val Loss: 0.139966, Val Acc: 0.721649\n",
      "Epoch 10383 - Train Loss: 0.123379, Train Acc: 0.792308 | Val Loss: 0.139960, Val Acc: 0.721649\n",
      "Epoch 10384 - Train Loss: 0.123372, Train Acc: 0.792308 | Val Loss: 0.139953, Val Acc: 0.721649\n",
      "Epoch 10385 - Train Loss: 0.123364, Train Acc: 0.792308 | Val Loss: 0.139947, Val Acc: 0.721649\n",
      "Epoch 10386 - Train Loss: 0.123356, Train Acc: 0.792308 | Val Loss: 0.139940, Val Acc: 0.721649\n",
      "Epoch 10387 - Train Loss: 0.123348, Train Acc: 0.792308 | Val Loss: 0.139934, Val Acc: 0.721649\n",
      "Epoch 10388 - Train Loss: 0.123340, Train Acc: 0.792308 | Val Loss: 0.139928, Val Acc: 0.721649\n",
      "Epoch 10389 - Train Loss: 0.123332, Train Acc: 0.792308 | Val Loss: 0.139921, Val Acc: 0.721649\n",
      "Epoch 10390 - Train Loss: 0.123325, Train Acc: 0.792308 | Val Loss: 0.139915, Val Acc: 0.721649\n",
      "Epoch 10391 - Train Loss: 0.123317, Train Acc: 0.792308 | Val Loss: 0.139908, Val Acc: 0.721649\n",
      "Epoch 10392 - Train Loss: 0.123309, Train Acc: 0.792308 | Val Loss: 0.139902, Val Acc: 0.721649\n",
      "Epoch 10393 - Train Loss: 0.123301, Train Acc: 0.792308 | Val Loss: 0.139895, Val Acc: 0.721649\n",
      "Epoch 10394 - Train Loss: 0.123293, Train Acc: 0.792308 | Val Loss: 0.139889, Val Acc: 0.721649\n",
      "Epoch 10395 - Train Loss: 0.123285, Train Acc: 0.792308 | Val Loss: 0.139882, Val Acc: 0.721649\n",
      "Epoch 10396 - Train Loss: 0.123278, Train Acc: 0.792308 | Val Loss: 0.139876, Val Acc: 0.721649\n",
      "Epoch 10397 - Train Loss: 0.123270, Train Acc: 0.792308 | Val Loss: 0.139869, Val Acc: 0.721649\n",
      "Epoch 10398 - Train Loss: 0.123262, Train Acc: 0.792308 | Val Loss: 0.139863, Val Acc: 0.721649\n",
      "Epoch 10399 - Train Loss: 0.123254, Train Acc: 0.792308 | Val Loss: 0.139857, Val Acc: 0.721649\n",
      "Epoch 10400 - Train Loss: 0.123246, Train Acc: 0.792308 | Val Loss: 0.139850, Val Acc: 0.721649\n",
      "Epoch 10401 - Train Loss: 0.123238, Train Acc: 0.792308 | Val Loss: 0.139844, Val Acc: 0.721649\n",
      "Epoch 10402 - Train Loss: 0.123231, Train Acc: 0.793590 | Val Loss: 0.139837, Val Acc: 0.721649\n",
      "Epoch 10403 - Train Loss: 0.123223, Train Acc: 0.793590 | Val Loss: 0.139831, Val Acc: 0.721649\n",
      "Epoch 10404 - Train Loss: 0.123215, Train Acc: 0.793590 | Val Loss: 0.139824, Val Acc: 0.721649\n",
      "Epoch 10405 - Train Loss: 0.123207, Train Acc: 0.793590 | Val Loss: 0.139818, Val Acc: 0.721649\n",
      "Epoch 10406 - Train Loss: 0.123199, Train Acc: 0.793590 | Val Loss: 0.139812, Val Acc: 0.721649\n",
      "Epoch 10407 - Train Loss: 0.123192, Train Acc: 0.793590 | Val Loss: 0.139805, Val Acc: 0.721649\n",
      "Epoch 10408 - Train Loss: 0.123184, Train Acc: 0.793590 | Val Loss: 0.139799, Val Acc: 0.721649\n",
      "Epoch 10409 - Train Loss: 0.123176, Train Acc: 0.793590 | Val Loss: 0.139792, Val Acc: 0.721649\n",
      "Epoch 10410 - Train Loss: 0.123168, Train Acc: 0.793590 | Val Loss: 0.139786, Val Acc: 0.721649\n",
      "Epoch 10411 - Train Loss: 0.123160, Train Acc: 0.793590 | Val Loss: 0.139779, Val Acc: 0.721649\n",
      "Epoch 10412 - Train Loss: 0.123152, Train Acc: 0.793590 | Val Loss: 0.139773, Val Acc: 0.721649\n",
      "Epoch 10413 - Train Loss: 0.123145, Train Acc: 0.793590 | Val Loss: 0.139766, Val Acc: 0.721649\n",
      "Epoch 10414 - Train Loss: 0.123137, Train Acc: 0.793590 | Val Loss: 0.139760, Val Acc: 0.721649\n",
      "Epoch 10415 - Train Loss: 0.123129, Train Acc: 0.793590 | Val Loss: 0.139754, Val Acc: 0.721649\n",
      "Epoch 10416 - Train Loss: 0.123121, Train Acc: 0.793590 | Val Loss: 0.139747, Val Acc: 0.721649\n",
      "Epoch 10417 - Train Loss: 0.123113, Train Acc: 0.793590 | Val Loss: 0.139741, Val Acc: 0.721649\n",
      "Epoch 10418 - Train Loss: 0.123106, Train Acc: 0.793590 | Val Loss: 0.139734, Val Acc: 0.721649\n",
      "Epoch 10419 - Train Loss: 0.123098, Train Acc: 0.793590 | Val Loss: 0.139728, Val Acc: 0.721649\n",
      "Epoch 10420 - Train Loss: 0.123090, Train Acc: 0.793590 | Val Loss: 0.139721, Val Acc: 0.721649\n",
      "Epoch 10421 - Train Loss: 0.123082, Train Acc: 0.794872 | Val Loss: 0.139715, Val Acc: 0.721649\n",
      "Epoch 10422 - Train Loss: 0.123074, Train Acc: 0.794872 | Val Loss: 0.139709, Val Acc: 0.721649\n",
      "Epoch 10423 - Train Loss: 0.123067, Train Acc: 0.794872 | Val Loss: 0.139702, Val Acc: 0.721649\n",
      "Epoch 10424 - Train Loss: 0.123059, Train Acc: 0.794872 | Val Loss: 0.139696, Val Acc: 0.721649\n",
      "Epoch 10425 - Train Loss: 0.123051, Train Acc: 0.794872 | Val Loss: 0.139689, Val Acc: 0.721649\n",
      "Epoch 10426 - Train Loss: 0.123043, Train Acc: 0.794872 | Val Loss: 0.139683, Val Acc: 0.721649\n",
      "Epoch 10427 - Train Loss: 0.123035, Train Acc: 0.794872 | Val Loss: 0.139677, Val Acc: 0.721649\n",
      "Epoch 10428 - Train Loss: 0.123028, Train Acc: 0.794872 | Val Loss: 0.139670, Val Acc: 0.721649\n",
      "Epoch 10429 - Train Loss: 0.123020, Train Acc: 0.794872 | Val Loss: 0.139664, Val Acc: 0.721649\n",
      "Epoch 10430 - Train Loss: 0.123012, Train Acc: 0.794872 | Val Loss: 0.139657, Val Acc: 0.721649\n",
      "Epoch 10431 - Train Loss: 0.123004, Train Acc: 0.794872 | Val Loss: 0.139651, Val Acc: 0.721649\n",
      "Epoch 10432 - Train Loss: 0.122996, Train Acc: 0.794872 | Val Loss: 0.139645, Val Acc: 0.721649\n",
      "Epoch 10433 - Train Loss: 0.122989, Train Acc: 0.794872 | Val Loss: 0.139638, Val Acc: 0.721649\n",
      "Epoch 10434 - Train Loss: 0.122981, Train Acc: 0.794872 | Val Loss: 0.139632, Val Acc: 0.721649\n",
      "Epoch 10435 - Train Loss: 0.122973, Train Acc: 0.794872 | Val Loss: 0.139625, Val Acc: 0.721649\n",
      "Epoch 10436 - Train Loss: 0.122965, Train Acc: 0.794872 | Val Loss: 0.139619, Val Acc: 0.721649\n",
      "Epoch 10437 - Train Loss: 0.122958, Train Acc: 0.794872 | Val Loss: 0.139612, Val Acc: 0.721649\n",
      "Epoch 10438 - Train Loss: 0.122950, Train Acc: 0.794872 | Val Loss: 0.139606, Val Acc: 0.721649\n",
      "Epoch 10439 - Train Loss: 0.122942, Train Acc: 0.794872 | Val Loss: 0.139600, Val Acc: 0.721649\n",
      "Epoch 10440 - Train Loss: 0.122934, Train Acc: 0.794872 | Val Loss: 0.139593, Val Acc: 0.721649\n",
      "Epoch 10441 - Train Loss: 0.122926, Train Acc: 0.794872 | Val Loss: 0.139587, Val Acc: 0.721649\n",
      "Epoch 10442 - Train Loss: 0.122919, Train Acc: 0.794872 | Val Loss: 0.139580, Val Acc: 0.721649\n",
      "Epoch 10443 - Train Loss: 0.122911, Train Acc: 0.794872 | Val Loss: 0.139574, Val Acc: 0.721649\n",
      "Epoch 10444 - Train Loss: 0.122903, Train Acc: 0.794872 | Val Loss: 0.139568, Val Acc: 0.721649\n",
      "Epoch 10445 - Train Loss: 0.122895, Train Acc: 0.794872 | Val Loss: 0.139561, Val Acc: 0.721649\n",
      "Epoch 10446 - Train Loss: 0.122888, Train Acc: 0.794872 | Val Loss: 0.139555, Val Acc: 0.721649\n",
      "Epoch 10447 - Train Loss: 0.122880, Train Acc: 0.794872 | Val Loss: 0.139548, Val Acc: 0.721649\n",
      "Epoch 10448 - Train Loss: 0.122872, Train Acc: 0.794872 | Val Loss: 0.139542, Val Acc: 0.721649\n",
      "Epoch 10449 - Train Loss: 0.122864, Train Acc: 0.794872 | Val Loss: 0.139536, Val Acc: 0.721649\n",
      "Epoch 10450 - Train Loss: 0.122856, Train Acc: 0.794872 | Val Loss: 0.139529, Val Acc: 0.721649\n",
      "Epoch 10451 - Train Loss: 0.122849, Train Acc: 0.794872 | Val Loss: 0.139523, Val Acc: 0.721649\n",
      "Epoch 10452 - Train Loss: 0.122841, Train Acc: 0.794872 | Val Loss: 0.139516, Val Acc: 0.721649\n",
      "Epoch 10453 - Train Loss: 0.122833, Train Acc: 0.794872 | Val Loss: 0.139510, Val Acc: 0.721649\n",
      "Epoch 10454 - Train Loss: 0.122825, Train Acc: 0.794872 | Val Loss: 0.139504, Val Acc: 0.721649\n",
      "Epoch 10455 - Train Loss: 0.122818, Train Acc: 0.794872 | Val Loss: 0.139497, Val Acc: 0.721649\n",
      "Epoch 10456 - Train Loss: 0.122810, Train Acc: 0.794872 | Val Loss: 0.139491, Val Acc: 0.721649\n",
      "Epoch 10457 - Train Loss: 0.122802, Train Acc: 0.794872 | Val Loss: 0.139485, Val Acc: 0.721649\n",
      "Epoch 10458 - Train Loss: 0.122794, Train Acc: 0.794872 | Val Loss: 0.139478, Val Acc: 0.721649\n",
      "Epoch 10459 - Train Loss: 0.122787, Train Acc: 0.794872 | Val Loss: 0.139472, Val Acc: 0.721649\n",
      "Epoch 10460 - Train Loss: 0.122779, Train Acc: 0.794872 | Val Loss: 0.139465, Val Acc: 0.721649\n",
      "Epoch 10461 - Train Loss: 0.122771, Train Acc: 0.794872 | Val Loss: 0.139459, Val Acc: 0.721649\n",
      "Epoch 10462 - Train Loss: 0.122763, Train Acc: 0.794872 | Val Loss: 0.139453, Val Acc: 0.721649\n",
      "Epoch 10463 - Train Loss: 0.122756, Train Acc: 0.794872 | Val Loss: 0.139446, Val Acc: 0.721649\n",
      "Epoch 10464 - Train Loss: 0.122748, Train Acc: 0.794872 | Val Loss: 0.139440, Val Acc: 0.721649\n",
      "Epoch 10465 - Train Loss: 0.122740, Train Acc: 0.794872 | Val Loss: 0.139433, Val Acc: 0.721649\n",
      "Epoch 10466 - Train Loss: 0.122732, Train Acc: 0.794872 | Val Loss: 0.139427, Val Acc: 0.721649\n",
      "Epoch 10467 - Train Loss: 0.122725, Train Acc: 0.794872 | Val Loss: 0.139421, Val Acc: 0.721649\n",
      "Epoch 10468 - Train Loss: 0.122717, Train Acc: 0.794872 | Val Loss: 0.139414, Val Acc: 0.721649\n",
      "Epoch 10469 - Train Loss: 0.122709, Train Acc: 0.794872 | Val Loss: 0.139408, Val Acc: 0.721649\n",
      "Epoch 10470 - Train Loss: 0.122701, Train Acc: 0.794872 | Val Loss: 0.139402, Val Acc: 0.721649\n",
      "Epoch 10471 - Train Loss: 0.122694, Train Acc: 0.794872 | Val Loss: 0.139395, Val Acc: 0.721649\n",
      "Epoch 10472 - Train Loss: 0.122686, Train Acc: 0.794872 | Val Loss: 0.139389, Val Acc: 0.721649\n",
      "Epoch 10473 - Train Loss: 0.122678, Train Acc: 0.794872 | Val Loss: 0.139382, Val Acc: 0.721649\n",
      "Epoch 10474 - Train Loss: 0.122670, Train Acc: 0.794872 | Val Loss: 0.139376, Val Acc: 0.721649\n",
      "Epoch 10475 - Train Loss: 0.122663, Train Acc: 0.794872 | Val Loss: 0.139370, Val Acc: 0.721649\n",
      "Epoch 10476 - Train Loss: 0.122655, Train Acc: 0.794872 | Val Loss: 0.139363, Val Acc: 0.721649\n",
      "Epoch 10477 - Train Loss: 0.122647, Train Acc: 0.794872 | Val Loss: 0.139357, Val Acc: 0.721649\n",
      "Epoch 10478 - Train Loss: 0.122639, Train Acc: 0.794872 | Val Loss: 0.139351, Val Acc: 0.721649\n",
      "Epoch 10479 - Train Loss: 0.122632, Train Acc: 0.794872 | Val Loss: 0.139344, Val Acc: 0.721649\n",
      "Epoch 10480 - Train Loss: 0.122624, Train Acc: 0.794872 | Val Loss: 0.139338, Val Acc: 0.721649\n",
      "Epoch 10481 - Train Loss: 0.122616, Train Acc: 0.794872 | Val Loss: 0.139332, Val Acc: 0.721649\n",
      "Epoch 10482 - Train Loss: 0.122608, Train Acc: 0.794872 | Val Loss: 0.139325, Val Acc: 0.721649\n",
      "Epoch 10483 - Train Loss: 0.122601, Train Acc: 0.794872 | Val Loss: 0.139319, Val Acc: 0.721649\n",
      "Epoch 10484 - Train Loss: 0.122593, Train Acc: 0.794872 | Val Loss: 0.139312, Val Acc: 0.721649\n",
      "Epoch 10485 - Train Loss: 0.122585, Train Acc: 0.794872 | Val Loss: 0.139306, Val Acc: 0.721649\n",
      "Epoch 10486 - Train Loss: 0.122577, Train Acc: 0.794872 | Val Loss: 0.139300, Val Acc: 0.721649\n",
      "Epoch 10487 - Train Loss: 0.122570, Train Acc: 0.796154 | Val Loss: 0.139293, Val Acc: 0.721649\n",
      "Epoch 10488 - Train Loss: 0.122562, Train Acc: 0.796154 | Val Loss: 0.139287, Val Acc: 0.721649\n",
      "Epoch 10489 - Train Loss: 0.122554, Train Acc: 0.796154 | Val Loss: 0.139281, Val Acc: 0.721649\n",
      "Epoch 10490 - Train Loss: 0.122547, Train Acc: 0.796154 | Val Loss: 0.139274, Val Acc: 0.721649\n",
      "Epoch 10491 - Train Loss: 0.122539, Train Acc: 0.796154 | Val Loss: 0.139268, Val Acc: 0.721649\n",
      "Epoch 10492 - Train Loss: 0.122531, Train Acc: 0.796154 | Val Loss: 0.139262, Val Acc: 0.721649\n",
      "Epoch 10493 - Train Loss: 0.122523, Train Acc: 0.796154 | Val Loss: 0.139255, Val Acc: 0.721649\n",
      "Epoch 10494 - Train Loss: 0.122516, Train Acc: 0.796154 | Val Loss: 0.139249, Val Acc: 0.721649\n",
      "Epoch 10495 - Train Loss: 0.122508, Train Acc: 0.796154 | Val Loss: 0.139243, Val Acc: 0.721649\n",
      "Epoch 10496 - Train Loss: 0.122500, Train Acc: 0.796154 | Val Loss: 0.139236, Val Acc: 0.721649\n",
      "Epoch 10497 - Train Loss: 0.122493, Train Acc: 0.796154 | Val Loss: 0.139230, Val Acc: 0.721649\n",
      "Epoch 10498 - Train Loss: 0.122485, Train Acc: 0.796154 | Val Loss: 0.139224, Val Acc: 0.721649\n",
      "Epoch 10499 - Train Loss: 0.122477, Train Acc: 0.796154 | Val Loss: 0.139217, Val Acc: 0.721649\n",
      "Epoch 10500 - Train Loss: 0.122469, Train Acc: 0.796154 | Val Loss: 0.139211, Val Acc: 0.721649\n",
      "Epoch 10501 - Train Loss: 0.122462, Train Acc: 0.796154 | Val Loss: 0.139205, Val Acc: 0.721649\n",
      "Epoch 10502 - Train Loss: 0.122454, Train Acc: 0.796154 | Val Loss: 0.139198, Val Acc: 0.721649\n",
      "Epoch 10503 - Train Loss: 0.122446, Train Acc: 0.796154 | Val Loss: 0.139192, Val Acc: 0.721649\n",
      "Epoch 10504 - Train Loss: 0.122439, Train Acc: 0.796154 | Val Loss: 0.139186, Val Acc: 0.721649\n",
      "Epoch 10505 - Train Loss: 0.122431, Train Acc: 0.796154 | Val Loss: 0.139179, Val Acc: 0.721649\n",
      "Epoch 10506 - Train Loss: 0.122423, Train Acc: 0.796154 | Val Loss: 0.139173, Val Acc: 0.721649\n",
      "Epoch 10507 - Train Loss: 0.122415, Train Acc: 0.796154 | Val Loss: 0.139167, Val Acc: 0.721649\n",
      "Epoch 10508 - Train Loss: 0.122408, Train Acc: 0.796154 | Val Loss: 0.139160, Val Acc: 0.721649\n",
      "Epoch 10509 - Train Loss: 0.122400, Train Acc: 0.796154 | Val Loss: 0.139154, Val Acc: 0.721649\n",
      "Epoch 10510 - Train Loss: 0.122392, Train Acc: 0.796154 | Val Loss: 0.139148, Val Acc: 0.721649\n",
      "Epoch 10511 - Train Loss: 0.122385, Train Acc: 0.796154 | Val Loss: 0.139141, Val Acc: 0.721649\n",
      "Epoch 10512 - Train Loss: 0.122377, Train Acc: 0.796154 | Val Loss: 0.139135, Val Acc: 0.721649\n",
      "Epoch 10513 - Train Loss: 0.122369, Train Acc: 0.796154 | Val Loss: 0.139129, Val Acc: 0.721649\n",
      "Epoch 10514 - Train Loss: 0.122361, Train Acc: 0.796154 | Val Loss: 0.139122, Val Acc: 0.721649\n",
      "Epoch 10515 - Train Loss: 0.122354, Train Acc: 0.796154 | Val Loss: 0.139116, Val Acc: 0.721649\n",
      "Epoch 10516 - Train Loss: 0.122346, Train Acc: 0.796154 | Val Loss: 0.139110, Val Acc: 0.721649\n",
      "Epoch 10517 - Train Loss: 0.122338, Train Acc: 0.796154 | Val Loss: 0.139103, Val Acc: 0.721649\n",
      "Epoch 10518 - Train Loss: 0.122331, Train Acc: 0.796154 | Val Loss: 0.139097, Val Acc: 0.721649\n",
      "Epoch 10519 - Train Loss: 0.122323, Train Acc: 0.796154 | Val Loss: 0.139091, Val Acc: 0.721649\n",
      "Epoch 10520 - Train Loss: 0.122315, Train Acc: 0.796154 | Val Loss: 0.139084, Val Acc: 0.721649\n",
      "Epoch 10521 - Train Loss: 0.122308, Train Acc: 0.796154 | Val Loss: 0.139078, Val Acc: 0.721649\n",
      "Epoch 10522 - Train Loss: 0.122300, Train Acc: 0.796154 | Val Loss: 0.139072, Val Acc: 0.721649\n",
      "Epoch 10523 - Train Loss: 0.122292, Train Acc: 0.796154 | Val Loss: 0.139065, Val Acc: 0.721649\n",
      "Epoch 10524 - Train Loss: 0.122285, Train Acc: 0.796154 | Val Loss: 0.139059, Val Acc: 0.721649\n",
      "Epoch 10525 - Train Loss: 0.122277, Train Acc: 0.796154 | Val Loss: 0.139053, Val Acc: 0.721649\n",
      "Epoch 10526 - Train Loss: 0.122269, Train Acc: 0.796154 | Val Loss: 0.139046, Val Acc: 0.721649\n",
      "Epoch 10527 - Train Loss: 0.122261, Train Acc: 0.796154 | Val Loss: 0.139040, Val Acc: 0.721649\n",
      "Epoch 10528 - Train Loss: 0.122254, Train Acc: 0.796154 | Val Loss: 0.139034, Val Acc: 0.721649\n",
      "Epoch 10529 - Train Loss: 0.122246, Train Acc: 0.796154 | Val Loss: 0.139027, Val Acc: 0.721649\n",
      "Epoch 10530 - Train Loss: 0.122238, Train Acc: 0.796154 | Val Loss: 0.139021, Val Acc: 0.721649\n",
      "Epoch 10531 - Train Loss: 0.122231, Train Acc: 0.796154 | Val Loss: 0.139015, Val Acc: 0.721649\n",
      "Epoch 10532 - Train Loss: 0.122223, Train Acc: 0.796154 | Val Loss: 0.139009, Val Acc: 0.721649\n",
      "Epoch 10533 - Train Loss: 0.122215, Train Acc: 0.796154 | Val Loss: 0.139002, Val Acc: 0.721649\n",
      "Epoch 10534 - Train Loss: 0.122208, Train Acc: 0.796154 | Val Loss: 0.138996, Val Acc: 0.721649\n",
      "Epoch 10535 - Train Loss: 0.122200, Train Acc: 0.796154 | Val Loss: 0.138990, Val Acc: 0.721649\n",
      "Epoch 10536 - Train Loss: 0.122192, Train Acc: 0.796154 | Val Loss: 0.138983, Val Acc: 0.721649\n",
      "Epoch 10537 - Train Loss: 0.122185, Train Acc: 0.796154 | Val Loss: 0.138977, Val Acc: 0.721649\n",
      "Epoch 10538 - Train Loss: 0.122177, Train Acc: 0.796154 | Val Loss: 0.138971, Val Acc: 0.721649\n",
      "Epoch 10539 - Train Loss: 0.122169, Train Acc: 0.796154 | Val Loss: 0.138964, Val Acc: 0.721649\n",
      "Epoch 10540 - Train Loss: 0.122162, Train Acc: 0.796154 | Val Loss: 0.138958, Val Acc: 0.721649\n",
      "Epoch 10541 - Train Loss: 0.122154, Train Acc: 0.796154 | Val Loss: 0.138952, Val Acc: 0.721649\n",
      "Epoch 10542 - Train Loss: 0.122146, Train Acc: 0.796154 | Val Loss: 0.138946, Val Acc: 0.721649\n",
      "Epoch 10543 - Train Loss: 0.122139, Train Acc: 0.796154 | Val Loss: 0.138939, Val Acc: 0.721649\n",
      "Epoch 10544 - Train Loss: 0.122131, Train Acc: 0.796154 | Val Loss: 0.138933, Val Acc: 0.721649\n",
      "Epoch 10545 - Train Loss: 0.122123, Train Acc: 0.796154 | Val Loss: 0.138927, Val Acc: 0.721649\n",
      "Epoch 10546 - Train Loss: 0.122116, Train Acc: 0.796154 | Val Loss: 0.138920, Val Acc: 0.721649\n",
      "Epoch 10547 - Train Loss: 0.122108, Train Acc: 0.796154 | Val Loss: 0.138914, Val Acc: 0.721649\n",
      "Epoch 10548 - Train Loss: 0.122100, Train Acc: 0.796154 | Val Loss: 0.138908, Val Acc: 0.721649\n",
      "Epoch 10549 - Train Loss: 0.122093, Train Acc: 0.796154 | Val Loss: 0.138901, Val Acc: 0.721649\n",
      "Epoch 10550 - Train Loss: 0.122085, Train Acc: 0.796154 | Val Loss: 0.138895, Val Acc: 0.721649\n",
      "Epoch 10551 - Train Loss: 0.122077, Train Acc: 0.796154 | Val Loss: 0.138889, Val Acc: 0.721649\n",
      "Epoch 10552 - Train Loss: 0.122070, Train Acc: 0.796154 | Val Loss: 0.138883, Val Acc: 0.721649\n",
      "Epoch 10553 - Train Loss: 0.122062, Train Acc: 0.796154 | Val Loss: 0.138876, Val Acc: 0.721649\n",
      "Epoch 10554 - Train Loss: 0.122054, Train Acc: 0.796154 | Val Loss: 0.138870, Val Acc: 0.721649\n",
      "Epoch 10555 - Train Loss: 0.122047, Train Acc: 0.796154 | Val Loss: 0.138864, Val Acc: 0.721649\n",
      "Epoch 10556 - Train Loss: 0.122039, Train Acc: 0.796154 | Val Loss: 0.138857, Val Acc: 0.721649\n",
      "Epoch 10557 - Train Loss: 0.122031, Train Acc: 0.796154 | Val Loss: 0.138851, Val Acc: 0.721649\n",
      "Epoch 10558 - Train Loss: 0.122024, Train Acc: 0.796154 | Val Loss: 0.138845, Val Acc: 0.721649\n",
      "Epoch 10559 - Train Loss: 0.122016, Train Acc: 0.796154 | Val Loss: 0.138839, Val Acc: 0.721649\n",
      "Epoch 10560 - Train Loss: 0.122008, Train Acc: 0.796154 | Val Loss: 0.138832, Val Acc: 0.721649\n",
      "Epoch 10561 - Train Loss: 0.122001, Train Acc: 0.796154 | Val Loss: 0.138826, Val Acc: 0.721649\n",
      "Epoch 10562 - Train Loss: 0.121993, Train Acc: 0.796154 | Val Loss: 0.138820, Val Acc: 0.721649\n",
      "Epoch 10563 - Train Loss: 0.121985, Train Acc: 0.796154 | Val Loss: 0.138813, Val Acc: 0.721649\n",
      "Epoch 10564 - Train Loss: 0.121978, Train Acc: 0.796154 | Val Loss: 0.138807, Val Acc: 0.721649\n",
      "Epoch 10565 - Train Loss: 0.121970, Train Acc: 0.796154 | Val Loss: 0.138801, Val Acc: 0.721649\n",
      "Epoch 10566 - Train Loss: 0.121962, Train Acc: 0.797436 | Val Loss: 0.138795, Val Acc: 0.721649\n",
      "Epoch 10567 - Train Loss: 0.121955, Train Acc: 0.797436 | Val Loss: 0.138788, Val Acc: 0.721649\n",
      "Epoch 10568 - Train Loss: 0.121947, Train Acc: 0.797436 | Val Loss: 0.138782, Val Acc: 0.721649\n",
      "Epoch 10569 - Train Loss: 0.121940, Train Acc: 0.797436 | Val Loss: 0.138776, Val Acc: 0.721649\n",
      "Epoch 10570 - Train Loss: 0.121932, Train Acc: 0.797436 | Val Loss: 0.138770, Val Acc: 0.721649\n",
      "Epoch 10571 - Train Loss: 0.121924, Train Acc: 0.797436 | Val Loss: 0.138763, Val Acc: 0.721649\n",
      "Epoch 10572 - Train Loss: 0.121917, Train Acc: 0.797436 | Val Loss: 0.138757, Val Acc: 0.721649\n",
      "Epoch 10573 - Train Loss: 0.121909, Train Acc: 0.797436 | Val Loss: 0.138751, Val Acc: 0.721649\n",
      "Epoch 10574 - Train Loss: 0.121901, Train Acc: 0.797436 | Val Loss: 0.138745, Val Acc: 0.721649\n",
      "Epoch 10575 - Train Loss: 0.121894, Train Acc: 0.797436 | Val Loss: 0.138738, Val Acc: 0.721649\n",
      "Epoch 10576 - Train Loss: 0.121886, Train Acc: 0.797436 | Val Loss: 0.138732, Val Acc: 0.721649\n",
      "Epoch 10577 - Train Loss: 0.121878, Train Acc: 0.797436 | Val Loss: 0.138726, Val Acc: 0.721649\n",
      "Epoch 10578 - Train Loss: 0.121871, Train Acc: 0.797436 | Val Loss: 0.138720, Val Acc: 0.721649\n",
      "Epoch 10579 - Train Loss: 0.121863, Train Acc: 0.797436 | Val Loss: 0.138713, Val Acc: 0.721649\n",
      "Epoch 10580 - Train Loss: 0.121856, Train Acc: 0.797436 | Val Loss: 0.138707, Val Acc: 0.721649\n",
      "Epoch 10581 - Train Loss: 0.121848, Train Acc: 0.797436 | Val Loss: 0.138701, Val Acc: 0.721649\n",
      "Epoch 10582 - Train Loss: 0.121840, Train Acc: 0.797436 | Val Loss: 0.138694, Val Acc: 0.721649\n",
      "Epoch 10583 - Train Loss: 0.121833, Train Acc: 0.797436 | Val Loss: 0.138688, Val Acc: 0.721649\n",
      "Epoch 10584 - Train Loss: 0.121825, Train Acc: 0.797436 | Val Loss: 0.138682, Val Acc: 0.721649\n",
      "Epoch 10585 - Train Loss: 0.121817, Train Acc: 0.797436 | Val Loss: 0.138676, Val Acc: 0.721649\n",
      "Epoch 10586 - Train Loss: 0.121810, Train Acc: 0.797436 | Val Loss: 0.138669, Val Acc: 0.721649\n",
      "Epoch 10587 - Train Loss: 0.121802, Train Acc: 0.797436 | Val Loss: 0.138663, Val Acc: 0.721649\n",
      "Epoch 10588 - Train Loss: 0.121795, Train Acc: 0.797436 | Val Loss: 0.138657, Val Acc: 0.721649\n",
      "Epoch 10589 - Train Loss: 0.121787, Train Acc: 0.798718 | Val Loss: 0.138651, Val Acc: 0.721649\n",
      "Epoch 10590 - Train Loss: 0.121779, Train Acc: 0.798718 | Val Loss: 0.138644, Val Acc: 0.721649\n",
      "Epoch 10591 - Train Loss: 0.121772, Train Acc: 0.798718 | Val Loss: 0.138638, Val Acc: 0.721649\n",
      "Epoch 10592 - Train Loss: 0.121764, Train Acc: 0.798718 | Val Loss: 0.138632, Val Acc: 0.721649\n",
      "Epoch 10593 - Train Loss: 0.121756, Train Acc: 0.798718 | Val Loss: 0.138626, Val Acc: 0.721649\n",
      "Epoch 10594 - Train Loss: 0.121749, Train Acc: 0.798718 | Val Loss: 0.138619, Val Acc: 0.721649\n",
      "Epoch 10595 - Train Loss: 0.121741, Train Acc: 0.798718 | Val Loss: 0.138613, Val Acc: 0.721649\n",
      "Epoch 10596 - Train Loss: 0.121734, Train Acc: 0.798718 | Val Loss: 0.138607, Val Acc: 0.721649\n",
      "Epoch 10597 - Train Loss: 0.121726, Train Acc: 0.798718 | Val Loss: 0.138601, Val Acc: 0.721649\n",
      "Epoch 10598 - Train Loss: 0.121718, Train Acc: 0.798718 | Val Loss: 0.138595, Val Acc: 0.721649\n",
      "Epoch 10599 - Train Loss: 0.121711, Train Acc: 0.798718 | Val Loss: 0.138588, Val Acc: 0.721649\n",
      "Epoch 10600 - Train Loss: 0.121703, Train Acc: 0.798718 | Val Loss: 0.138582, Val Acc: 0.721649\n",
      "Epoch 10601 - Train Loss: 0.121696, Train Acc: 0.798718 | Val Loss: 0.138576, Val Acc: 0.721649\n",
      "Epoch 10602 - Train Loss: 0.121688, Train Acc: 0.798718 | Val Loss: 0.138570, Val Acc: 0.721649\n",
      "Epoch 10603 - Train Loss: 0.121680, Train Acc: 0.798718 | Val Loss: 0.138563, Val Acc: 0.721649\n",
      "Epoch 10604 - Train Loss: 0.121673, Train Acc: 0.798718 | Val Loss: 0.138557, Val Acc: 0.721649\n",
      "Epoch 10605 - Train Loss: 0.121665, Train Acc: 0.798718 | Val Loss: 0.138551, Val Acc: 0.721649\n",
      "Epoch 10606 - Train Loss: 0.121658, Train Acc: 0.798718 | Val Loss: 0.138545, Val Acc: 0.721649\n",
      "Epoch 10607 - Train Loss: 0.121650, Train Acc: 0.798718 | Val Loss: 0.138538, Val Acc: 0.721649\n",
      "Epoch 10608 - Train Loss: 0.121642, Train Acc: 0.798718 | Val Loss: 0.138532, Val Acc: 0.721649\n",
      "Epoch 10609 - Train Loss: 0.121635, Train Acc: 0.798718 | Val Loss: 0.138526, Val Acc: 0.721649\n",
      "Epoch 10610 - Train Loss: 0.121627, Train Acc: 0.798718 | Val Loss: 0.138520, Val Acc: 0.721649\n",
      "Epoch 10611 - Train Loss: 0.121620, Train Acc: 0.798718 | Val Loss: 0.138513, Val Acc: 0.721649\n",
      "Epoch 10612 - Train Loss: 0.121612, Train Acc: 0.798718 | Val Loss: 0.138507, Val Acc: 0.721649\n",
      "Epoch 10613 - Train Loss: 0.121604, Train Acc: 0.798718 | Val Loss: 0.138501, Val Acc: 0.721649\n",
      "Epoch 10614 - Train Loss: 0.121597, Train Acc: 0.798718 | Val Loss: 0.138495, Val Acc: 0.721649\n",
      "Epoch 10615 - Train Loss: 0.121589, Train Acc: 0.798718 | Val Loss: 0.138489, Val Acc: 0.721649\n",
      "Epoch 10616 - Train Loss: 0.121582, Train Acc: 0.798718 | Val Loss: 0.138482, Val Acc: 0.721649\n",
      "Epoch 10617 - Train Loss: 0.121574, Train Acc: 0.798718 | Val Loss: 0.138476, Val Acc: 0.721649\n",
      "Epoch 10618 - Train Loss: 0.121566, Train Acc: 0.798718 | Val Loss: 0.138470, Val Acc: 0.721649\n",
      "Epoch 10619 - Train Loss: 0.121559, Train Acc: 0.798718 | Val Loss: 0.138464, Val Acc: 0.721649\n",
      "Epoch 10620 - Train Loss: 0.121551, Train Acc: 0.798718 | Val Loss: 0.138458, Val Acc: 0.721649\n",
      "Epoch 10621 - Train Loss: 0.121544, Train Acc: 0.798718 | Val Loss: 0.138451, Val Acc: 0.721649\n",
      "Epoch 10622 - Train Loss: 0.121536, Train Acc: 0.798718 | Val Loss: 0.138445, Val Acc: 0.721649\n",
      "Epoch 10623 - Train Loss: 0.121528, Train Acc: 0.798718 | Val Loss: 0.138439, Val Acc: 0.721649\n",
      "Epoch 10624 - Train Loss: 0.121521, Train Acc: 0.798718 | Val Loss: 0.138433, Val Acc: 0.721649\n",
      "Epoch 10625 - Train Loss: 0.121513, Train Acc: 0.798718 | Val Loss: 0.138426, Val Acc: 0.721649\n",
      "Epoch 10626 - Train Loss: 0.121506, Train Acc: 0.798718 | Val Loss: 0.138420, Val Acc: 0.721649\n",
      "Epoch 10627 - Train Loss: 0.121498, Train Acc: 0.798718 | Val Loss: 0.138414, Val Acc: 0.721649\n",
      "Epoch 10628 - Train Loss: 0.121491, Train Acc: 0.798718 | Val Loss: 0.138408, Val Acc: 0.721649\n",
      "Epoch 10629 - Train Loss: 0.121483, Train Acc: 0.798718 | Val Loss: 0.138402, Val Acc: 0.721649\n",
      "Epoch 10630 - Train Loss: 0.121475, Train Acc: 0.798718 | Val Loss: 0.138395, Val Acc: 0.721649\n",
      "Epoch 10631 - Train Loss: 0.121468, Train Acc: 0.798718 | Val Loss: 0.138389, Val Acc: 0.721649\n",
      "Epoch 10632 - Train Loss: 0.121460, Train Acc: 0.798718 | Val Loss: 0.138383, Val Acc: 0.721649\n",
      "Epoch 10633 - Train Loss: 0.121453, Train Acc: 0.798718 | Val Loss: 0.138377, Val Acc: 0.721649\n",
      "Epoch 10634 - Train Loss: 0.121445, Train Acc: 0.798718 | Val Loss: 0.138371, Val Acc: 0.721649\n",
      "Epoch 10635 - Train Loss: 0.121437, Train Acc: 0.798718 | Val Loss: 0.138364, Val Acc: 0.721649\n",
      "Epoch 10636 - Train Loss: 0.121430, Train Acc: 0.798718 | Val Loss: 0.138358, Val Acc: 0.721649\n",
      "Epoch 10637 - Train Loss: 0.121422, Train Acc: 0.798718 | Val Loss: 0.138352, Val Acc: 0.721649\n",
      "Epoch 10638 - Train Loss: 0.121415, Train Acc: 0.798718 | Val Loss: 0.138346, Val Acc: 0.721649\n",
      "Epoch 10639 - Train Loss: 0.121407, Train Acc: 0.798718 | Val Loss: 0.138340, Val Acc: 0.721649\n",
      "Epoch 10640 - Train Loss: 0.121400, Train Acc: 0.798718 | Val Loss: 0.138333, Val Acc: 0.721649\n",
      "Epoch 10641 - Train Loss: 0.121392, Train Acc: 0.798718 | Val Loss: 0.138327, Val Acc: 0.721649\n",
      "Epoch 10642 - Train Loss: 0.121385, Train Acc: 0.798718 | Val Loss: 0.138321, Val Acc: 0.721649\n",
      "Epoch 10643 - Train Loss: 0.121377, Train Acc: 0.798718 | Val Loss: 0.138315, Val Acc: 0.721649\n",
      "Epoch 10644 - Train Loss: 0.121369, Train Acc: 0.798718 | Val Loss: 0.138309, Val Acc: 0.721649\n",
      "Epoch 10645 - Train Loss: 0.121362, Train Acc: 0.798718 | Val Loss: 0.138302, Val Acc: 0.721649\n",
      "Epoch 10646 - Train Loss: 0.121354, Train Acc: 0.798718 | Val Loss: 0.138296, Val Acc: 0.721649\n",
      "Epoch 10647 - Train Loss: 0.121347, Train Acc: 0.798718 | Val Loss: 0.138290, Val Acc: 0.721649\n",
      "Epoch 10648 - Train Loss: 0.121339, Train Acc: 0.798718 | Val Loss: 0.138284, Val Acc: 0.721649\n",
      "Epoch 10649 - Train Loss: 0.121332, Train Acc: 0.798718 | Val Loss: 0.138278, Val Acc: 0.721649\n",
      "Epoch 10650 - Train Loss: 0.121324, Train Acc: 0.798718 | Val Loss: 0.138272, Val Acc: 0.721649\n",
      "Epoch 10651 - Train Loss: 0.121316, Train Acc: 0.798718 | Val Loss: 0.138265, Val Acc: 0.721649\n",
      "Epoch 10652 - Train Loss: 0.121309, Train Acc: 0.798718 | Val Loss: 0.138259, Val Acc: 0.721649\n",
      "Epoch 10653 - Train Loss: 0.121301, Train Acc: 0.798718 | Val Loss: 0.138253, Val Acc: 0.721649\n",
      "Epoch 10654 - Train Loss: 0.121294, Train Acc: 0.798718 | Val Loss: 0.138247, Val Acc: 0.721649\n",
      "Epoch 10655 - Train Loss: 0.121286, Train Acc: 0.798718 | Val Loss: 0.138241, Val Acc: 0.721649\n",
      "Epoch 10656 - Train Loss: 0.121279, Train Acc: 0.798718 | Val Loss: 0.138234, Val Acc: 0.721649\n",
      "Epoch 10657 - Train Loss: 0.121271, Train Acc: 0.798718 | Val Loss: 0.138228, Val Acc: 0.721649\n",
      "Epoch 10658 - Train Loss: 0.121264, Train Acc: 0.798718 | Val Loss: 0.138222, Val Acc: 0.721649\n",
      "Epoch 10659 - Train Loss: 0.121256, Train Acc: 0.798718 | Val Loss: 0.138216, Val Acc: 0.721649\n",
      "Epoch 10660 - Train Loss: 0.121249, Train Acc: 0.798718 | Val Loss: 0.138210, Val Acc: 0.721649\n",
      "Epoch 10661 - Train Loss: 0.121241, Train Acc: 0.798718 | Val Loss: 0.138204, Val Acc: 0.721649\n",
      "Epoch 10662 - Train Loss: 0.121233, Train Acc: 0.798718 | Val Loss: 0.138197, Val Acc: 0.721649\n",
      "Epoch 10663 - Train Loss: 0.121226, Train Acc: 0.798718 | Val Loss: 0.138191, Val Acc: 0.721649\n",
      "Epoch 10664 - Train Loss: 0.121218, Train Acc: 0.798718 | Val Loss: 0.138185, Val Acc: 0.721649\n",
      "Epoch 10665 - Train Loss: 0.121211, Train Acc: 0.798718 | Val Loss: 0.138179, Val Acc: 0.721649\n",
      "Epoch 10666 - Train Loss: 0.121203, Train Acc: 0.798718 | Val Loss: 0.138173, Val Acc: 0.721649\n",
      "Epoch 10667 - Train Loss: 0.121196, Train Acc: 0.798718 | Val Loss: 0.138166, Val Acc: 0.721649\n",
      "Epoch 10668 - Train Loss: 0.121188, Train Acc: 0.798718 | Val Loss: 0.138160, Val Acc: 0.721649\n",
      "Epoch 10669 - Train Loss: 0.121181, Train Acc: 0.798718 | Val Loss: 0.138154, Val Acc: 0.721649\n",
      "Epoch 10670 - Train Loss: 0.121173, Train Acc: 0.798718 | Val Loss: 0.138148, Val Acc: 0.721649\n",
      "Epoch 10671 - Train Loss: 0.121166, Train Acc: 0.798718 | Val Loss: 0.138142, Val Acc: 0.721649\n",
      "Epoch 10672 - Train Loss: 0.121158, Train Acc: 0.798718 | Val Loss: 0.138136, Val Acc: 0.721649\n",
      "Epoch 10673 - Train Loss: 0.121151, Train Acc: 0.798718 | Val Loss: 0.138130, Val Acc: 0.721649\n",
      "Epoch 10674 - Train Loss: 0.121143, Train Acc: 0.798718 | Val Loss: 0.138123, Val Acc: 0.721649\n",
      "Epoch 10675 - Train Loss: 0.121135, Train Acc: 0.798718 | Val Loss: 0.138117, Val Acc: 0.721649\n",
      "Epoch 10676 - Train Loss: 0.121128, Train Acc: 0.798718 | Val Loss: 0.138111, Val Acc: 0.721649\n",
      "Epoch 10677 - Train Loss: 0.121120, Train Acc: 0.798718 | Val Loss: 0.138105, Val Acc: 0.721649\n",
      "Epoch 10678 - Train Loss: 0.121113, Train Acc: 0.798718 | Val Loss: 0.138099, Val Acc: 0.721649\n",
      "Epoch 10679 - Train Loss: 0.121105, Train Acc: 0.798718 | Val Loss: 0.138093, Val Acc: 0.721649\n",
      "Epoch 10680 - Train Loss: 0.121098, Train Acc: 0.798718 | Val Loss: 0.138086, Val Acc: 0.721649\n",
      "Epoch 10681 - Train Loss: 0.121090, Train Acc: 0.798718 | Val Loss: 0.138080, Val Acc: 0.721649\n",
      "Epoch 10682 - Train Loss: 0.121083, Train Acc: 0.798718 | Val Loss: 0.138074, Val Acc: 0.721649\n",
      "Epoch 10683 - Train Loss: 0.121075, Train Acc: 0.798718 | Val Loss: 0.138068, Val Acc: 0.721649\n",
      "Epoch 10684 - Train Loss: 0.121068, Train Acc: 0.798718 | Val Loss: 0.138062, Val Acc: 0.721649\n",
      "Epoch 10685 - Train Loss: 0.121060, Train Acc: 0.798718 | Val Loss: 0.138056, Val Acc: 0.721649\n",
      "Epoch 10686 - Train Loss: 0.121053, Train Acc: 0.798718 | Val Loss: 0.138050, Val Acc: 0.721649\n",
      "Epoch 10687 - Train Loss: 0.121045, Train Acc: 0.798718 | Val Loss: 0.138043, Val Acc: 0.721649\n",
      "Epoch 10688 - Train Loss: 0.121038, Train Acc: 0.798718 | Val Loss: 0.138037, Val Acc: 0.721649\n",
      "Epoch 10689 - Train Loss: 0.121030, Train Acc: 0.798718 | Val Loss: 0.138031, Val Acc: 0.721649\n",
      "Epoch 10690 - Train Loss: 0.121023, Train Acc: 0.798718 | Val Loss: 0.138025, Val Acc: 0.721649\n",
      "Epoch 10691 - Train Loss: 0.121015, Train Acc: 0.798718 | Val Loss: 0.138019, Val Acc: 0.721649\n",
      "Epoch 10692 - Train Loss: 0.121008, Train Acc: 0.798718 | Val Loss: 0.138013, Val Acc: 0.721649\n",
      "Epoch 10693 - Train Loss: 0.121000, Train Acc: 0.798718 | Val Loss: 0.138006, Val Acc: 0.721649\n",
      "Epoch 10694 - Train Loss: 0.120993, Train Acc: 0.798718 | Val Loss: 0.138000, Val Acc: 0.721649\n",
      "Epoch 10695 - Train Loss: 0.120985, Train Acc: 0.798718 | Val Loss: 0.137994, Val Acc: 0.721649\n",
      "Epoch 10696 - Train Loss: 0.120978, Train Acc: 0.798718 | Val Loss: 0.137988, Val Acc: 0.721649\n",
      "Epoch 10697 - Train Loss: 0.120970, Train Acc: 0.798718 | Val Loss: 0.137982, Val Acc: 0.721649\n",
      "Epoch 10698 - Train Loss: 0.120963, Train Acc: 0.798718 | Val Loss: 0.137976, Val Acc: 0.721649\n",
      "Epoch 10699 - Train Loss: 0.120955, Train Acc: 0.798718 | Val Loss: 0.137970, Val Acc: 0.721649\n",
      "Epoch 10700 - Train Loss: 0.120948, Train Acc: 0.798718 | Val Loss: 0.137964, Val Acc: 0.721649\n",
      "Epoch 10701 - Train Loss: 0.120940, Train Acc: 0.798718 | Val Loss: 0.137957, Val Acc: 0.721649\n",
      "Epoch 10702 - Train Loss: 0.120933, Train Acc: 0.798718 | Val Loss: 0.137951, Val Acc: 0.721649\n",
      "Epoch 10703 - Train Loss: 0.120925, Train Acc: 0.798718 | Val Loss: 0.137945, Val Acc: 0.721649\n",
      "Epoch 10704 - Train Loss: 0.120918, Train Acc: 0.798718 | Val Loss: 0.137939, Val Acc: 0.721649\n",
      "Epoch 10705 - Train Loss: 0.120910, Train Acc: 0.798718 | Val Loss: 0.137933, Val Acc: 0.721649\n",
      "Epoch 10706 - Train Loss: 0.120903, Train Acc: 0.798718 | Val Loss: 0.137927, Val Acc: 0.721649\n",
      "Epoch 10707 - Train Loss: 0.120895, Train Acc: 0.798718 | Val Loss: 0.137921, Val Acc: 0.721649\n",
      "Epoch 10708 - Train Loss: 0.120888, Train Acc: 0.798718 | Val Loss: 0.137915, Val Acc: 0.721649\n",
      "Epoch 10709 - Train Loss: 0.120880, Train Acc: 0.798718 | Val Loss: 0.137908, Val Acc: 0.721649\n",
      "Epoch 10710 - Train Loss: 0.120873, Train Acc: 0.798718 | Val Loss: 0.137902, Val Acc: 0.721649\n",
      "Epoch 10711 - Train Loss: 0.120865, Train Acc: 0.798718 | Val Loss: 0.137896, Val Acc: 0.721649\n",
      "Epoch 10712 - Train Loss: 0.120858, Train Acc: 0.798718 | Val Loss: 0.137890, Val Acc: 0.721649\n",
      "Epoch 10713 - Train Loss: 0.120850, Train Acc: 0.798718 | Val Loss: 0.137884, Val Acc: 0.721649\n",
      "Epoch 10714 - Train Loss: 0.120843, Train Acc: 0.798718 | Val Loss: 0.137878, Val Acc: 0.721649\n",
      "Epoch 10715 - Train Loss: 0.120835, Train Acc: 0.798718 | Val Loss: 0.137872, Val Acc: 0.721649\n",
      "Epoch 10716 - Train Loss: 0.120828, Train Acc: 0.798718 | Val Loss: 0.137866, Val Acc: 0.721649\n",
      "Epoch 10717 - Train Loss: 0.120820, Train Acc: 0.798718 | Val Loss: 0.137859, Val Acc: 0.721649\n",
      "Epoch 10718 - Train Loss: 0.120813, Train Acc: 0.798718 | Val Loss: 0.137853, Val Acc: 0.721649\n",
      "Epoch 10719 - Train Loss: 0.120805, Train Acc: 0.798718 | Val Loss: 0.137847, Val Acc: 0.721649\n",
      "Epoch 10720 - Train Loss: 0.120798, Train Acc: 0.798718 | Val Loss: 0.137841, Val Acc: 0.721649\n",
      "Epoch 10721 - Train Loss: 0.120790, Train Acc: 0.798718 | Val Loss: 0.137835, Val Acc: 0.721649\n",
      "Epoch 10722 - Train Loss: 0.120783, Train Acc: 0.798718 | Val Loss: 0.137829, Val Acc: 0.721649\n",
      "Epoch 10723 - Train Loss: 0.120775, Train Acc: 0.798718 | Val Loss: 0.137823, Val Acc: 0.721649\n",
      "Epoch 10724 - Train Loss: 0.120768, Train Acc: 0.798718 | Val Loss: 0.137817, Val Acc: 0.721649\n",
      "Epoch 10725 - Train Loss: 0.120760, Train Acc: 0.798718 | Val Loss: 0.137811, Val Acc: 0.721649\n",
      "Epoch 10726 - Train Loss: 0.120753, Train Acc: 0.798718 | Val Loss: 0.137804, Val Acc: 0.721649\n",
      "Epoch 10727 - Train Loss: 0.120745, Train Acc: 0.798718 | Val Loss: 0.137798, Val Acc: 0.721649\n",
      "Epoch 10728 - Train Loss: 0.120738, Train Acc: 0.798718 | Val Loss: 0.137792, Val Acc: 0.721649\n",
      "Epoch 10729 - Train Loss: 0.120730, Train Acc: 0.798718 | Val Loss: 0.137786, Val Acc: 0.721649\n",
      "Epoch 10730 - Train Loss: 0.120723, Train Acc: 0.798718 | Val Loss: 0.137780, Val Acc: 0.721649\n",
      "Epoch 10731 - Train Loss: 0.120715, Train Acc: 0.798718 | Val Loss: 0.137774, Val Acc: 0.721649\n",
      "Epoch 10732 - Train Loss: 0.120708, Train Acc: 0.798718 | Val Loss: 0.137768, Val Acc: 0.721649\n",
      "Epoch 10733 - Train Loss: 0.120700, Train Acc: 0.798718 | Val Loss: 0.137762, Val Acc: 0.721649\n",
      "Epoch 10734 - Train Loss: 0.120693, Train Acc: 0.798718 | Val Loss: 0.137756, Val Acc: 0.721649\n",
      "Epoch 10735 - Train Loss: 0.120686, Train Acc: 0.798718 | Val Loss: 0.137749, Val Acc: 0.721649\n",
      "Epoch 10736 - Train Loss: 0.120678, Train Acc: 0.798718 | Val Loss: 0.137743, Val Acc: 0.721649\n",
      "Epoch 10737 - Train Loss: 0.120671, Train Acc: 0.798718 | Val Loss: 0.137737, Val Acc: 0.721649\n",
      "Epoch 10738 - Train Loss: 0.120663, Train Acc: 0.798718 | Val Loss: 0.137731, Val Acc: 0.721649\n",
      "Epoch 10739 - Train Loss: 0.120656, Train Acc: 0.798718 | Val Loss: 0.137725, Val Acc: 0.721649\n",
      "Epoch 10740 - Train Loss: 0.120648, Train Acc: 0.798718 | Val Loss: 0.137719, Val Acc: 0.721649\n",
      "Epoch 10741 - Train Loss: 0.120641, Train Acc: 0.798718 | Val Loss: 0.137713, Val Acc: 0.721649\n",
      "Epoch 10742 - Train Loss: 0.120633, Train Acc: 0.798718 | Val Loss: 0.137707, Val Acc: 0.721649\n",
      "Epoch 10743 - Train Loss: 0.120626, Train Acc: 0.798718 | Val Loss: 0.137701, Val Acc: 0.721649\n",
      "Epoch 10744 - Train Loss: 0.120618, Train Acc: 0.798718 | Val Loss: 0.137695, Val Acc: 0.721649\n",
      "Epoch 10745 - Train Loss: 0.120611, Train Acc: 0.798718 | Val Loss: 0.137689, Val Acc: 0.721649\n",
      "Epoch 10746 - Train Loss: 0.120603, Train Acc: 0.798718 | Val Loss: 0.137682, Val Acc: 0.721649\n",
      "Epoch 10747 - Train Loss: 0.120596, Train Acc: 0.798718 | Val Loss: 0.137676, Val Acc: 0.721649\n",
      "Epoch 10748 - Train Loss: 0.120589, Train Acc: 0.798718 | Val Loss: 0.137670, Val Acc: 0.721649\n",
      "Epoch 10749 - Train Loss: 0.120581, Train Acc: 0.798718 | Val Loss: 0.137664, Val Acc: 0.721649\n",
      "Epoch 10750 - Train Loss: 0.120574, Train Acc: 0.798718 | Val Loss: 0.137658, Val Acc: 0.721649\n",
      "Epoch 10751 - Train Loss: 0.120566, Train Acc: 0.798718 | Val Loss: 0.137652, Val Acc: 0.721649\n",
      "Epoch 10752 - Train Loss: 0.120559, Train Acc: 0.800000 | Val Loss: 0.137646, Val Acc: 0.721649\n",
      "Epoch 10753 - Train Loss: 0.120551, Train Acc: 0.800000 | Val Loss: 0.137640, Val Acc: 0.721649\n",
      "Epoch 10754 - Train Loss: 0.120544, Train Acc: 0.800000 | Val Loss: 0.137634, Val Acc: 0.721649\n",
      "Epoch 10755 - Train Loss: 0.120536, Train Acc: 0.800000 | Val Loss: 0.137628, Val Acc: 0.721649\n",
      "Epoch 10756 - Train Loss: 0.120529, Train Acc: 0.800000 | Val Loss: 0.137622, Val Acc: 0.721649\n",
      "Epoch 10757 - Train Loss: 0.120521, Train Acc: 0.800000 | Val Loss: 0.137616, Val Acc: 0.721649\n",
      "Epoch 10758 - Train Loss: 0.120514, Train Acc: 0.800000 | Val Loss: 0.137610, Val Acc: 0.721649\n",
      "Epoch 10759 - Train Loss: 0.120507, Train Acc: 0.800000 | Val Loss: 0.137603, Val Acc: 0.721649\n",
      "Epoch 10760 - Train Loss: 0.120499, Train Acc: 0.800000 | Val Loss: 0.137597, Val Acc: 0.721649\n",
      "Epoch 10761 - Train Loss: 0.120492, Train Acc: 0.800000 | Val Loss: 0.137591, Val Acc: 0.721649\n",
      "Epoch 10762 - Train Loss: 0.120484, Train Acc: 0.800000 | Val Loss: 0.137585, Val Acc: 0.721649\n",
      "Epoch 10763 - Train Loss: 0.120477, Train Acc: 0.800000 | Val Loss: 0.137579, Val Acc: 0.721649\n",
      "Epoch 10764 - Train Loss: 0.120469, Train Acc: 0.800000 | Val Loss: 0.137573, Val Acc: 0.721649\n",
      "Epoch 10765 - Train Loss: 0.120462, Train Acc: 0.800000 | Val Loss: 0.137567, Val Acc: 0.721649\n",
      "Epoch 10766 - Train Loss: 0.120455, Train Acc: 0.800000 | Val Loss: 0.137561, Val Acc: 0.721649\n",
      "Epoch 10767 - Train Loss: 0.120447, Train Acc: 0.800000 | Val Loss: 0.137555, Val Acc: 0.721649\n",
      "Epoch 10768 - Train Loss: 0.120440, Train Acc: 0.800000 | Val Loss: 0.137549, Val Acc: 0.721649\n",
      "Epoch 10769 - Train Loss: 0.120432, Train Acc: 0.800000 | Val Loss: 0.137543, Val Acc: 0.721649\n",
      "Epoch 10770 - Train Loss: 0.120425, Train Acc: 0.800000 | Val Loss: 0.137537, Val Acc: 0.721649\n",
      "Epoch 10771 - Train Loss: 0.120417, Train Acc: 0.800000 | Val Loss: 0.137531, Val Acc: 0.721649\n",
      "Epoch 10772 - Train Loss: 0.120410, Train Acc: 0.800000 | Val Loss: 0.137525, Val Acc: 0.721649\n",
      "Epoch 10773 - Train Loss: 0.120403, Train Acc: 0.800000 | Val Loss: 0.137519, Val Acc: 0.721649\n",
      "Epoch 10774 - Train Loss: 0.120395, Train Acc: 0.801282 | Val Loss: 0.137512, Val Acc: 0.721649\n",
      "Epoch 10775 - Train Loss: 0.120388, Train Acc: 0.801282 | Val Loss: 0.137506, Val Acc: 0.721649\n",
      "Epoch 10776 - Train Loss: 0.120380, Train Acc: 0.801282 | Val Loss: 0.137500, Val Acc: 0.721649\n",
      "Epoch 10777 - Train Loss: 0.120373, Train Acc: 0.801282 | Val Loss: 0.137494, Val Acc: 0.721649\n",
      "Epoch 10778 - Train Loss: 0.120365, Train Acc: 0.801282 | Val Loss: 0.137488, Val Acc: 0.721649\n",
      "Epoch 10779 - Train Loss: 0.120358, Train Acc: 0.801282 | Val Loss: 0.137482, Val Acc: 0.721649\n",
      "Epoch 10780 - Train Loss: 0.120351, Train Acc: 0.801282 | Val Loss: 0.137476, Val Acc: 0.721649\n",
      "Epoch 10781 - Train Loss: 0.120343, Train Acc: 0.801282 | Val Loss: 0.137470, Val Acc: 0.721649\n",
      "Epoch 10782 - Train Loss: 0.120336, Train Acc: 0.801282 | Val Loss: 0.137464, Val Acc: 0.721649\n",
      "Epoch 10783 - Train Loss: 0.120328, Train Acc: 0.801282 | Val Loss: 0.137458, Val Acc: 0.721649\n",
      "Epoch 10784 - Train Loss: 0.120321, Train Acc: 0.801282 | Val Loss: 0.137452, Val Acc: 0.721649\n",
      "Epoch 10785 - Train Loss: 0.120313, Train Acc: 0.801282 | Val Loss: 0.137446, Val Acc: 0.721649\n",
      "Epoch 10786 - Train Loss: 0.120306, Train Acc: 0.801282 | Val Loss: 0.137440, Val Acc: 0.721649\n",
      "Epoch 10787 - Train Loss: 0.120299, Train Acc: 0.801282 | Val Loss: 0.137434, Val Acc: 0.721649\n",
      "Epoch 10788 - Train Loss: 0.120291, Train Acc: 0.801282 | Val Loss: 0.137428, Val Acc: 0.721649\n",
      "Epoch 10789 - Train Loss: 0.120284, Train Acc: 0.801282 | Val Loss: 0.137422, Val Acc: 0.721649\n",
      "Epoch 10790 - Train Loss: 0.120276, Train Acc: 0.801282 | Val Loss: 0.137416, Val Acc: 0.721649\n",
      "Epoch 10791 - Train Loss: 0.120269, Train Acc: 0.801282 | Val Loss: 0.137410, Val Acc: 0.721649\n",
      "Epoch 10792 - Train Loss: 0.120262, Train Acc: 0.801282 | Val Loss: 0.137404, Val Acc: 0.721649\n",
      "Epoch 10793 - Train Loss: 0.120254, Train Acc: 0.801282 | Val Loss: 0.137398, Val Acc: 0.721649\n",
      "Epoch 10794 - Train Loss: 0.120247, Train Acc: 0.801282 | Val Loss: 0.137391, Val Acc: 0.721649\n",
      "Epoch 10795 - Train Loss: 0.120239, Train Acc: 0.801282 | Val Loss: 0.137385, Val Acc: 0.721649\n",
      "Epoch 10796 - Train Loss: 0.120232, Train Acc: 0.801282 | Val Loss: 0.137379, Val Acc: 0.721649\n",
      "Epoch 10797 - Train Loss: 0.120225, Train Acc: 0.801282 | Val Loss: 0.137373, Val Acc: 0.721649\n",
      "Epoch 10798 - Train Loss: 0.120217, Train Acc: 0.801282 | Val Loss: 0.137367, Val Acc: 0.721649\n",
      "Epoch 10799 - Train Loss: 0.120210, Train Acc: 0.801282 | Val Loss: 0.137361, Val Acc: 0.721649\n",
      "Epoch 10800 - Train Loss: 0.120202, Train Acc: 0.801282 | Val Loss: 0.137355, Val Acc: 0.721649\n",
      "Epoch 10801 - Train Loss: 0.120195, Train Acc: 0.801282 | Val Loss: 0.137349, Val Acc: 0.721649\n",
      "Epoch 10802 - Train Loss: 0.120188, Train Acc: 0.801282 | Val Loss: 0.137343, Val Acc: 0.721649\n",
      "Epoch 10803 - Train Loss: 0.120180, Train Acc: 0.801282 | Val Loss: 0.137337, Val Acc: 0.721649\n",
      "Epoch 10804 - Train Loss: 0.120173, Train Acc: 0.801282 | Val Loss: 0.137331, Val Acc: 0.721649\n",
      "Epoch 10805 - Train Loss: 0.120165, Train Acc: 0.801282 | Val Loss: 0.137325, Val Acc: 0.721649\n",
      "Epoch 10806 - Train Loss: 0.120158, Train Acc: 0.801282 | Val Loss: 0.137319, Val Acc: 0.721649\n",
      "Epoch 10807 - Train Loss: 0.120151, Train Acc: 0.801282 | Val Loss: 0.137313, Val Acc: 0.721649\n",
      "Epoch 10808 - Train Loss: 0.120143, Train Acc: 0.801282 | Val Loss: 0.137307, Val Acc: 0.721649\n",
      "Epoch 10809 - Train Loss: 0.120136, Train Acc: 0.801282 | Val Loss: 0.137301, Val Acc: 0.721649\n",
      "Epoch 10810 - Train Loss: 0.120128, Train Acc: 0.801282 | Val Loss: 0.137295, Val Acc: 0.721649\n",
      "Epoch 10811 - Train Loss: 0.120121, Train Acc: 0.801282 | Val Loss: 0.137289, Val Acc: 0.721649\n",
      "Epoch 10812 - Train Loss: 0.120114, Train Acc: 0.801282 | Val Loss: 0.137283, Val Acc: 0.721649\n",
      "Epoch 10813 - Train Loss: 0.120106, Train Acc: 0.801282 | Val Loss: 0.137277, Val Acc: 0.721649\n",
      "Epoch 10814 - Train Loss: 0.120099, Train Acc: 0.801282 | Val Loss: 0.137271, Val Acc: 0.721649\n",
      "Epoch 10815 - Train Loss: 0.120091, Train Acc: 0.801282 | Val Loss: 0.137265, Val Acc: 0.721649\n",
      "Epoch 10816 - Train Loss: 0.120084, Train Acc: 0.801282 | Val Loss: 0.137259, Val Acc: 0.721649\n",
      "Epoch 10817 - Train Loss: 0.120077, Train Acc: 0.801282 | Val Loss: 0.137253, Val Acc: 0.721649\n",
      "Epoch 10818 - Train Loss: 0.120069, Train Acc: 0.801282 | Val Loss: 0.137247, Val Acc: 0.721649\n",
      "Epoch 10819 - Train Loss: 0.120062, Train Acc: 0.801282 | Val Loss: 0.137241, Val Acc: 0.721649\n",
      "Epoch 10820 - Train Loss: 0.120055, Train Acc: 0.801282 | Val Loss: 0.137235, Val Acc: 0.721649\n",
      "Epoch 10821 - Train Loss: 0.120047, Train Acc: 0.801282 | Val Loss: 0.137229, Val Acc: 0.721649\n",
      "Epoch 10822 - Train Loss: 0.120040, Train Acc: 0.801282 | Val Loss: 0.137223, Val Acc: 0.721649\n",
      "Epoch 10823 - Train Loss: 0.120032, Train Acc: 0.801282 | Val Loss: 0.137217, Val Acc: 0.721649\n",
      "Epoch 10824 - Train Loss: 0.120025, Train Acc: 0.801282 | Val Loss: 0.137211, Val Acc: 0.721649\n",
      "Epoch 10825 - Train Loss: 0.120018, Train Acc: 0.801282 | Val Loss: 0.137205, Val Acc: 0.721649\n",
      "Epoch 10826 - Train Loss: 0.120010, Train Acc: 0.801282 | Val Loss: 0.137199, Val Acc: 0.721649\n",
      "Epoch 10827 - Train Loss: 0.120003, Train Acc: 0.801282 | Val Loss: 0.137193, Val Acc: 0.721649\n",
      "Epoch 10828 - Train Loss: 0.119995, Train Acc: 0.801282 | Val Loss: 0.137187, Val Acc: 0.721649\n",
      "Epoch 10829 - Train Loss: 0.119988, Train Acc: 0.801282 | Val Loss: 0.137181, Val Acc: 0.721649\n",
      "Epoch 10830 - Train Loss: 0.119981, Train Acc: 0.801282 | Val Loss: 0.137175, Val Acc: 0.721649\n",
      "Epoch 10831 - Train Loss: 0.119973, Train Acc: 0.801282 | Val Loss: 0.137169, Val Acc: 0.721649\n",
      "Epoch 10832 - Train Loss: 0.119966, Train Acc: 0.801282 | Val Loss: 0.137163, Val Acc: 0.721649\n",
      "Epoch 10833 - Train Loss: 0.119959, Train Acc: 0.801282 | Val Loss: 0.137157, Val Acc: 0.721649\n",
      "Epoch 10834 - Train Loss: 0.119951, Train Acc: 0.801282 | Val Loss: 0.137151, Val Acc: 0.721649\n",
      "Epoch 10835 - Train Loss: 0.119944, Train Acc: 0.801282 | Val Loss: 0.137145, Val Acc: 0.721649\n",
      "Epoch 10836 - Train Loss: 0.119937, Train Acc: 0.801282 | Val Loss: 0.137139, Val Acc: 0.721649\n",
      "Epoch 10837 - Train Loss: 0.119929, Train Acc: 0.801282 | Val Loss: 0.137133, Val Acc: 0.721649\n",
      "Epoch 10838 - Train Loss: 0.119922, Train Acc: 0.801282 | Val Loss: 0.137127, Val Acc: 0.721649\n",
      "Epoch 10839 - Train Loss: 0.119914, Train Acc: 0.801282 | Val Loss: 0.137121, Val Acc: 0.721649\n",
      "Epoch 10840 - Train Loss: 0.119907, Train Acc: 0.801282 | Val Loss: 0.137115, Val Acc: 0.721649\n",
      "Epoch 10841 - Train Loss: 0.119900, Train Acc: 0.801282 | Val Loss: 0.137109, Val Acc: 0.721649\n",
      "Epoch 10842 - Train Loss: 0.119892, Train Acc: 0.801282 | Val Loss: 0.137103, Val Acc: 0.721649\n",
      "Epoch 10843 - Train Loss: 0.119885, Train Acc: 0.801282 | Val Loss: 0.137097, Val Acc: 0.721649\n",
      "Epoch 10844 - Train Loss: 0.119878, Train Acc: 0.801282 | Val Loss: 0.137091, Val Acc: 0.721649\n",
      "Epoch 10845 - Train Loss: 0.119870, Train Acc: 0.801282 | Val Loss: 0.137085, Val Acc: 0.721649\n",
      "Epoch 10846 - Train Loss: 0.119863, Train Acc: 0.801282 | Val Loss: 0.137079, Val Acc: 0.721649\n",
      "Epoch 10847 - Train Loss: 0.119856, Train Acc: 0.801282 | Val Loss: 0.137073, Val Acc: 0.721649\n",
      "Epoch 10848 - Train Loss: 0.119848, Train Acc: 0.801282 | Val Loss: 0.137067, Val Acc: 0.721649\n",
      "Epoch 10849 - Train Loss: 0.119841, Train Acc: 0.801282 | Val Loss: 0.137061, Val Acc: 0.721649\n",
      "Epoch 10850 - Train Loss: 0.119834, Train Acc: 0.801282 | Val Loss: 0.137055, Val Acc: 0.721649\n",
      "Epoch 10851 - Train Loss: 0.119826, Train Acc: 0.801282 | Val Loss: 0.137049, Val Acc: 0.721649\n",
      "Epoch 10852 - Train Loss: 0.119819, Train Acc: 0.801282 | Val Loss: 0.137043, Val Acc: 0.721649\n",
      "Epoch 10853 - Train Loss: 0.119812, Train Acc: 0.801282 | Val Loss: 0.137038, Val Acc: 0.721649\n",
      "Epoch 10854 - Train Loss: 0.119804, Train Acc: 0.801282 | Val Loss: 0.137032, Val Acc: 0.721649\n",
      "Epoch 10855 - Train Loss: 0.119797, Train Acc: 0.801282 | Val Loss: 0.137026, Val Acc: 0.721649\n",
      "Epoch 10856 - Train Loss: 0.119789, Train Acc: 0.801282 | Val Loss: 0.137020, Val Acc: 0.721649\n",
      "Epoch 10857 - Train Loss: 0.119782, Train Acc: 0.801282 | Val Loss: 0.137014, Val Acc: 0.721649\n",
      "Epoch 10858 - Train Loss: 0.119775, Train Acc: 0.801282 | Val Loss: 0.137008, Val Acc: 0.721649\n",
      "Epoch 10859 - Train Loss: 0.119767, Train Acc: 0.801282 | Val Loss: 0.137002, Val Acc: 0.721649\n",
      "Epoch 10860 - Train Loss: 0.119760, Train Acc: 0.801282 | Val Loss: 0.136996, Val Acc: 0.721649\n",
      "Epoch 10861 - Train Loss: 0.119753, Train Acc: 0.801282 | Val Loss: 0.136990, Val Acc: 0.721649\n",
      "Epoch 10862 - Train Loss: 0.119745, Train Acc: 0.801282 | Val Loss: 0.136984, Val Acc: 0.721649\n",
      "Epoch 10863 - Train Loss: 0.119738, Train Acc: 0.801282 | Val Loss: 0.136978, Val Acc: 0.721649\n",
      "Epoch 10864 - Train Loss: 0.119731, Train Acc: 0.801282 | Val Loss: 0.136972, Val Acc: 0.721649\n",
      "Epoch 10865 - Train Loss: 0.119723, Train Acc: 0.801282 | Val Loss: 0.136966, Val Acc: 0.721649\n",
      "Epoch 10866 - Train Loss: 0.119716, Train Acc: 0.801282 | Val Loss: 0.136960, Val Acc: 0.721649\n",
      "Epoch 10867 - Train Loss: 0.119709, Train Acc: 0.801282 | Val Loss: 0.136954, Val Acc: 0.721649\n",
      "Epoch 10868 - Train Loss: 0.119701, Train Acc: 0.801282 | Val Loss: 0.136948, Val Acc: 0.721649\n",
      "Epoch 10869 - Train Loss: 0.119694, Train Acc: 0.801282 | Val Loss: 0.136942, Val Acc: 0.721649\n",
      "Epoch 10870 - Train Loss: 0.119687, Train Acc: 0.801282 | Val Loss: 0.136936, Val Acc: 0.721649\n",
      "Epoch 10871 - Train Loss: 0.119679, Train Acc: 0.801282 | Val Loss: 0.136930, Val Acc: 0.721649\n",
      "Epoch 10872 - Train Loss: 0.119672, Train Acc: 0.801282 | Val Loss: 0.136924, Val Acc: 0.721649\n",
      "Epoch 10873 - Train Loss: 0.119665, Train Acc: 0.801282 | Val Loss: 0.136918, Val Acc: 0.721649\n",
      "Epoch 10874 - Train Loss: 0.119657, Train Acc: 0.801282 | Val Loss: 0.136912, Val Acc: 0.721649\n",
      "Epoch 10875 - Train Loss: 0.119650, Train Acc: 0.801282 | Val Loss: 0.136907, Val Acc: 0.721649\n",
      "Epoch 10876 - Train Loss: 0.119643, Train Acc: 0.801282 | Val Loss: 0.136901, Val Acc: 0.721649\n",
      "Epoch 10877 - Train Loss: 0.119635, Train Acc: 0.801282 | Val Loss: 0.136895, Val Acc: 0.721649\n",
      "Epoch 10878 - Train Loss: 0.119628, Train Acc: 0.801282 | Val Loss: 0.136889, Val Acc: 0.721649\n",
      "Epoch 10879 - Train Loss: 0.119621, Train Acc: 0.801282 | Val Loss: 0.136883, Val Acc: 0.721649\n",
      "Epoch 10880 - Train Loss: 0.119614, Train Acc: 0.801282 | Val Loss: 0.136877, Val Acc: 0.721649\n",
      "Epoch 10881 - Train Loss: 0.119606, Train Acc: 0.801282 | Val Loss: 0.136871, Val Acc: 0.721649\n",
      "Epoch 10882 - Train Loss: 0.119599, Train Acc: 0.801282 | Val Loss: 0.136865, Val Acc: 0.721649\n",
      "Epoch 10883 - Train Loss: 0.119592, Train Acc: 0.801282 | Val Loss: 0.136859, Val Acc: 0.721649\n",
      "Epoch 10884 - Train Loss: 0.119584, Train Acc: 0.801282 | Val Loss: 0.136853, Val Acc: 0.721649\n",
      "Epoch 10885 - Train Loss: 0.119577, Train Acc: 0.801282 | Val Loss: 0.136847, Val Acc: 0.721649\n",
      "Epoch 10886 - Train Loss: 0.119570, Train Acc: 0.801282 | Val Loss: 0.136841, Val Acc: 0.721649\n",
      "Epoch 10887 - Train Loss: 0.119562, Train Acc: 0.801282 | Val Loss: 0.136835, Val Acc: 0.721649\n",
      "Epoch 10888 - Train Loss: 0.119555, Train Acc: 0.801282 | Val Loss: 0.136829, Val Acc: 0.721649\n",
      "Epoch 10889 - Train Loss: 0.119548, Train Acc: 0.801282 | Val Loss: 0.136823, Val Acc: 0.721649\n",
      "Epoch 10890 - Train Loss: 0.119540, Train Acc: 0.801282 | Val Loss: 0.136817, Val Acc: 0.721649\n",
      "Epoch 10891 - Train Loss: 0.119533, Train Acc: 0.801282 | Val Loss: 0.136811, Val Acc: 0.721649\n",
      "Epoch 10892 - Train Loss: 0.119526, Train Acc: 0.801282 | Val Loss: 0.136805, Val Acc: 0.721649\n",
      "Epoch 10893 - Train Loss: 0.119519, Train Acc: 0.801282 | Val Loss: 0.136799, Val Acc: 0.721649\n",
      "Epoch 10894 - Train Loss: 0.119511, Train Acc: 0.801282 | Val Loss: 0.136793, Val Acc: 0.721649\n",
      "Epoch 10895 - Train Loss: 0.119504, Train Acc: 0.801282 | Val Loss: 0.136787, Val Acc: 0.721649\n",
      "Epoch 10896 - Train Loss: 0.119497, Train Acc: 0.801282 | Val Loss: 0.136781, Val Acc: 0.721649\n",
      "Epoch 10897 - Train Loss: 0.119489, Train Acc: 0.801282 | Val Loss: 0.136775, Val Acc: 0.721649\n",
      "Epoch 10898 - Train Loss: 0.119482, Train Acc: 0.801282 | Val Loss: 0.136769, Val Acc: 0.721649\n",
      "Epoch 10899 - Train Loss: 0.119475, Train Acc: 0.801282 | Val Loss: 0.136763, Val Acc: 0.721649\n",
      "Epoch 10900 - Train Loss: 0.119467, Train Acc: 0.802564 | Val Loss: 0.136757, Val Acc: 0.721649\n",
      "Epoch 10901 - Train Loss: 0.119460, Train Acc: 0.802564 | Val Loss: 0.136751, Val Acc: 0.721649\n",
      "Epoch 10902 - Train Loss: 0.119453, Train Acc: 0.802564 | Val Loss: 0.136745, Val Acc: 0.721649\n",
      "Epoch 10903 - Train Loss: 0.119446, Train Acc: 0.802564 | Val Loss: 0.136739, Val Acc: 0.721649\n",
      "Epoch 10904 - Train Loss: 0.119438, Train Acc: 0.802564 | Val Loss: 0.136733, Val Acc: 0.721649\n",
      "Epoch 10905 - Train Loss: 0.119431, Train Acc: 0.802564 | Val Loss: 0.136728, Val Acc: 0.721649\n",
      "Epoch 10906 - Train Loss: 0.119424, Train Acc: 0.802564 | Val Loss: 0.136722, Val Acc: 0.721649\n",
      "Epoch 10907 - Train Loss: 0.119416, Train Acc: 0.802564 | Val Loss: 0.136716, Val Acc: 0.721649\n",
      "Epoch 10908 - Train Loss: 0.119409, Train Acc: 0.802564 | Val Loss: 0.136710, Val Acc: 0.721649\n",
      "Epoch 10909 - Train Loss: 0.119402, Train Acc: 0.802564 | Val Loss: 0.136704, Val Acc: 0.721649\n",
      "Epoch 10910 - Train Loss: 0.119395, Train Acc: 0.802564 | Val Loss: 0.136698, Val Acc: 0.721649\n",
      "Epoch 10911 - Train Loss: 0.119387, Train Acc: 0.802564 | Val Loss: 0.136692, Val Acc: 0.721649\n",
      "Epoch 10912 - Train Loss: 0.119380, Train Acc: 0.802564 | Val Loss: 0.136686, Val Acc: 0.721649\n",
      "Epoch 10913 - Train Loss: 0.119373, Train Acc: 0.802564 | Val Loss: 0.136680, Val Acc: 0.721649\n",
      "Epoch 10914 - Train Loss: 0.119365, Train Acc: 0.802564 | Val Loss: 0.136674, Val Acc: 0.721649\n",
      "Epoch 10915 - Train Loss: 0.119358, Train Acc: 0.802564 | Val Loss: 0.136668, Val Acc: 0.721649\n",
      "Epoch 10916 - Train Loss: 0.119351, Train Acc: 0.802564 | Val Loss: 0.136662, Val Acc: 0.721649\n",
      "Epoch 10917 - Train Loss: 0.119344, Train Acc: 0.802564 | Val Loss: 0.136656, Val Acc: 0.721649\n",
      "Epoch 10918 - Train Loss: 0.119336, Train Acc: 0.802564 | Val Loss: 0.136650, Val Acc: 0.721649\n",
      "Epoch 10919 - Train Loss: 0.119329, Train Acc: 0.802564 | Val Loss: 0.136644, Val Acc: 0.721649\n",
      "Epoch 10920 - Train Loss: 0.119322, Train Acc: 0.802564 | Val Loss: 0.136638, Val Acc: 0.721649\n",
      "Epoch 10921 - Train Loss: 0.119315, Train Acc: 0.802564 | Val Loss: 0.136632, Val Acc: 0.721649\n",
      "Epoch 10922 - Train Loss: 0.119307, Train Acc: 0.802564 | Val Loss: 0.136626, Val Acc: 0.721649\n",
      "Epoch 10923 - Train Loss: 0.119300, Train Acc: 0.802564 | Val Loss: 0.136620, Val Acc: 0.721649\n",
      "Epoch 10924 - Train Loss: 0.119293, Train Acc: 0.802564 | Val Loss: 0.136614, Val Acc: 0.721649\n",
      "Epoch 10925 - Train Loss: 0.119285, Train Acc: 0.802564 | Val Loss: 0.136609, Val Acc: 0.721649\n",
      "Epoch 10926 - Train Loss: 0.119278, Train Acc: 0.802564 | Val Loss: 0.136603, Val Acc: 0.721649\n",
      "Epoch 10927 - Train Loss: 0.119271, Train Acc: 0.802564 | Val Loss: 0.136597, Val Acc: 0.721649\n",
      "Epoch 10928 - Train Loss: 0.119264, Train Acc: 0.802564 | Val Loss: 0.136591, Val Acc: 0.721649\n",
      "Epoch 10929 - Train Loss: 0.119256, Train Acc: 0.802564 | Val Loss: 0.136585, Val Acc: 0.721649\n",
      "Epoch 10930 - Train Loss: 0.119249, Train Acc: 0.802564 | Val Loss: 0.136579, Val Acc: 0.721649\n",
      "Epoch 10931 - Train Loss: 0.119242, Train Acc: 0.802564 | Val Loss: 0.136573, Val Acc: 0.721649\n",
      "Epoch 10932 - Train Loss: 0.119235, Train Acc: 0.802564 | Val Loss: 0.136567, Val Acc: 0.721649\n",
      "Epoch 10933 - Train Loss: 0.119227, Train Acc: 0.802564 | Val Loss: 0.136561, Val Acc: 0.721649\n",
      "Epoch 10934 - Train Loss: 0.119220, Train Acc: 0.802564 | Val Loss: 0.136555, Val Acc: 0.721649\n",
      "Epoch 10935 - Train Loss: 0.119213, Train Acc: 0.802564 | Val Loss: 0.136549, Val Acc: 0.721649\n",
      "Epoch 10936 - Train Loss: 0.119206, Train Acc: 0.802564 | Val Loss: 0.136543, Val Acc: 0.721649\n",
      "Epoch 10937 - Train Loss: 0.119198, Train Acc: 0.802564 | Val Loss: 0.136538, Val Acc: 0.721649\n",
      "Epoch 10938 - Train Loss: 0.119191, Train Acc: 0.802564 | Val Loss: 0.136532, Val Acc: 0.721649\n",
      "Epoch 10939 - Train Loss: 0.119184, Train Acc: 0.802564 | Val Loss: 0.136526, Val Acc: 0.721649\n",
      "Epoch 10940 - Train Loss: 0.119177, Train Acc: 0.802564 | Val Loss: 0.136520, Val Acc: 0.721649\n",
      "Epoch 10941 - Train Loss: 0.119169, Train Acc: 0.802564 | Val Loss: 0.136514, Val Acc: 0.721649\n",
      "Epoch 10942 - Train Loss: 0.119162, Train Acc: 0.802564 | Val Loss: 0.136508, Val Acc: 0.721649\n",
      "Epoch 10943 - Train Loss: 0.119155, Train Acc: 0.802564 | Val Loss: 0.136502, Val Acc: 0.721649\n",
      "Epoch 10944 - Train Loss: 0.119148, Train Acc: 0.802564 | Val Loss: 0.136496, Val Acc: 0.721649\n",
      "Epoch 10945 - Train Loss: 0.119140, Train Acc: 0.802564 | Val Loss: 0.136490, Val Acc: 0.721649\n",
      "Epoch 10946 - Train Loss: 0.119133, Train Acc: 0.802564 | Val Loss: 0.136484, Val Acc: 0.721649\n",
      "Epoch 10947 - Train Loss: 0.119126, Train Acc: 0.802564 | Val Loss: 0.136479, Val Acc: 0.721649\n",
      "Epoch 10948 - Train Loss: 0.119119, Train Acc: 0.802564 | Val Loss: 0.136473, Val Acc: 0.721649\n",
      "Epoch 10949 - Train Loss: 0.119111, Train Acc: 0.802564 | Val Loss: 0.136467, Val Acc: 0.721649\n",
      "Epoch 10950 - Train Loss: 0.119104, Train Acc: 0.802564 | Val Loss: 0.136461, Val Acc: 0.721649\n",
      "Epoch 10951 - Train Loss: 0.119097, Train Acc: 0.802564 | Val Loss: 0.136455, Val Acc: 0.721649\n",
      "Epoch 10952 - Train Loss: 0.119090, Train Acc: 0.802564 | Val Loss: 0.136449, Val Acc: 0.721649\n",
      "Epoch 10953 - Train Loss: 0.119082, Train Acc: 0.802564 | Val Loss: 0.136443, Val Acc: 0.721649\n",
      "Epoch 10954 - Train Loss: 0.119075, Train Acc: 0.802564 | Val Loss: 0.136437, Val Acc: 0.721649\n",
      "Epoch 10955 - Train Loss: 0.119068, Train Acc: 0.802564 | Val Loss: 0.136432, Val Acc: 0.721649\n",
      "Epoch 10956 - Train Loss: 0.119061, Train Acc: 0.802564 | Val Loss: 0.136426, Val Acc: 0.721649\n",
      "Epoch 10957 - Train Loss: 0.119053, Train Acc: 0.802564 | Val Loss: 0.136420, Val Acc: 0.721649\n",
      "Epoch 10958 - Train Loss: 0.119046, Train Acc: 0.802564 | Val Loss: 0.136414, Val Acc: 0.721649\n",
      "Epoch 10959 - Train Loss: 0.119039, Train Acc: 0.802564 | Val Loss: 0.136408, Val Acc: 0.721649\n",
      "Epoch 10960 - Train Loss: 0.119032, Train Acc: 0.802564 | Val Loss: 0.136402, Val Acc: 0.721649\n",
      "Epoch 10961 - Train Loss: 0.119025, Train Acc: 0.802564 | Val Loss: 0.136396, Val Acc: 0.721649\n",
      "Epoch 10962 - Train Loss: 0.119017, Train Acc: 0.802564 | Val Loss: 0.136390, Val Acc: 0.721649\n",
      "Epoch 10963 - Train Loss: 0.119010, Train Acc: 0.802564 | Val Loss: 0.136385, Val Acc: 0.721649\n",
      "Epoch 10964 - Train Loss: 0.119003, Train Acc: 0.802564 | Val Loss: 0.136379, Val Acc: 0.721649\n",
      "Epoch 10965 - Train Loss: 0.118996, Train Acc: 0.802564 | Val Loss: 0.136373, Val Acc: 0.721649\n",
      "Epoch 10966 - Train Loss: 0.118988, Train Acc: 0.802564 | Val Loss: 0.136367, Val Acc: 0.721649\n",
      "Epoch 10967 - Train Loss: 0.118981, Train Acc: 0.802564 | Val Loss: 0.136361, Val Acc: 0.721649\n",
      "Epoch 10968 - Train Loss: 0.118974, Train Acc: 0.802564 | Val Loss: 0.136355, Val Acc: 0.721649\n",
      "Epoch 10969 - Train Loss: 0.118967, Train Acc: 0.802564 | Val Loss: 0.136349, Val Acc: 0.721649\n",
      "Epoch 10970 - Train Loss: 0.118960, Train Acc: 0.802564 | Val Loss: 0.136344, Val Acc: 0.721649\n",
      "Epoch 10971 - Train Loss: 0.118952, Train Acc: 0.802564 | Val Loss: 0.136338, Val Acc: 0.721649\n",
      "Epoch 10972 - Train Loss: 0.118945, Train Acc: 0.802564 | Val Loss: 0.136332, Val Acc: 0.721649\n",
      "Epoch 10973 - Train Loss: 0.118938, Train Acc: 0.802564 | Val Loss: 0.136326, Val Acc: 0.721649\n",
      "Epoch 10974 - Train Loss: 0.118931, Train Acc: 0.802564 | Val Loss: 0.136320, Val Acc: 0.721649\n",
      "Epoch 10975 - Train Loss: 0.118923, Train Acc: 0.802564 | Val Loss: 0.136314, Val Acc: 0.721649\n",
      "Epoch 10976 - Train Loss: 0.118916, Train Acc: 0.802564 | Val Loss: 0.136308, Val Acc: 0.721649\n",
      "Epoch 10977 - Train Loss: 0.118909, Train Acc: 0.802564 | Val Loss: 0.136303, Val Acc: 0.721649\n",
      "Epoch 10978 - Train Loss: 0.118902, Train Acc: 0.802564 | Val Loss: 0.136297, Val Acc: 0.721649\n",
      "Epoch 10979 - Train Loss: 0.118895, Train Acc: 0.802564 | Val Loss: 0.136291, Val Acc: 0.721649\n",
      "Epoch 10980 - Train Loss: 0.118887, Train Acc: 0.802564 | Val Loss: 0.136285, Val Acc: 0.721649\n",
      "Epoch 10981 - Train Loss: 0.118880, Train Acc: 0.802564 | Val Loss: 0.136279, Val Acc: 0.721649\n",
      "Epoch 10982 - Train Loss: 0.118873, Train Acc: 0.802564 | Val Loss: 0.136273, Val Acc: 0.721649\n",
      "Epoch 10983 - Train Loss: 0.118866, Train Acc: 0.802564 | Val Loss: 0.136267, Val Acc: 0.721649\n",
      "Epoch 10984 - Train Loss: 0.118859, Train Acc: 0.802564 | Val Loss: 0.136262, Val Acc: 0.721649\n",
      "Epoch 10985 - Train Loss: 0.118851, Train Acc: 0.802564 | Val Loss: 0.136256, Val Acc: 0.721649\n",
      "Epoch 10986 - Train Loss: 0.118844, Train Acc: 0.802564 | Val Loss: 0.136250, Val Acc: 0.721649\n",
      "Epoch 10987 - Train Loss: 0.118837, Train Acc: 0.802564 | Val Loss: 0.136244, Val Acc: 0.721649\n",
      "Epoch 10988 - Train Loss: 0.118830, Train Acc: 0.802564 | Val Loss: 0.136238, Val Acc: 0.721649\n",
      "Epoch 10989 - Train Loss: 0.118823, Train Acc: 0.802564 | Val Loss: 0.136232, Val Acc: 0.721649\n",
      "Epoch 10990 - Train Loss: 0.118815, Train Acc: 0.802564 | Val Loss: 0.136227, Val Acc: 0.721649\n",
      "Epoch 10991 - Train Loss: 0.118808, Train Acc: 0.802564 | Val Loss: 0.136221, Val Acc: 0.721649\n",
      "Epoch 10992 - Train Loss: 0.118801, Train Acc: 0.802564 | Val Loss: 0.136215, Val Acc: 0.721649\n",
      "Epoch 10993 - Train Loss: 0.118794, Train Acc: 0.802564 | Val Loss: 0.136209, Val Acc: 0.721649\n",
      "Epoch 10994 - Train Loss: 0.118787, Train Acc: 0.802564 | Val Loss: 0.136203, Val Acc: 0.721649\n",
      "Epoch 10995 - Train Loss: 0.118779, Train Acc: 0.802564 | Val Loss: 0.136197, Val Acc: 0.721649\n",
      "Epoch 10996 - Train Loss: 0.118772, Train Acc: 0.802564 | Val Loss: 0.136192, Val Acc: 0.721649\n",
      "Epoch 10997 - Train Loss: 0.118765, Train Acc: 0.802564 | Val Loss: 0.136186, Val Acc: 0.721649\n",
      "Epoch 10998 - Train Loss: 0.118758, Train Acc: 0.802564 | Val Loss: 0.136180, Val Acc: 0.721649\n",
      "Epoch 10999 - Train Loss: 0.118751, Train Acc: 0.802564 | Val Loss: 0.136174, Val Acc: 0.721649\n",
      "Epoch 11000 - Train Loss: 0.118743, Train Acc: 0.802564 | Val Loss: 0.136168, Val Acc: 0.721649\n",
      "Epoch 11001 - Train Loss: 0.118736, Train Acc: 0.802564 | Val Loss: 0.136162, Val Acc: 0.721649\n",
      "Epoch 11002 - Train Loss: 0.118729, Train Acc: 0.802564 | Val Loss: 0.136157, Val Acc: 0.721649\n",
      "Epoch 11003 - Train Loss: 0.118722, Train Acc: 0.802564 | Val Loss: 0.136151, Val Acc: 0.721649\n",
      "Epoch 11004 - Train Loss: 0.118715, Train Acc: 0.802564 | Val Loss: 0.136145, Val Acc: 0.721649\n",
      "Epoch 11005 - Train Loss: 0.118707, Train Acc: 0.802564 | Val Loss: 0.136139, Val Acc: 0.721649\n",
      "Epoch 11006 - Train Loss: 0.118700, Train Acc: 0.802564 | Val Loss: 0.136133, Val Acc: 0.721649\n",
      "Epoch 11007 - Train Loss: 0.118693, Train Acc: 0.802564 | Val Loss: 0.136128, Val Acc: 0.721649\n",
      "Epoch 11008 - Train Loss: 0.118686, Train Acc: 0.802564 | Val Loss: 0.136122, Val Acc: 0.721649\n",
      "Epoch 11009 - Train Loss: 0.118679, Train Acc: 0.802564 | Val Loss: 0.136116, Val Acc: 0.721649\n",
      "Epoch 11010 - Train Loss: 0.118672, Train Acc: 0.802564 | Val Loss: 0.136110, Val Acc: 0.721649\n",
      "Epoch 11011 - Train Loss: 0.118664, Train Acc: 0.802564 | Val Loss: 0.136104, Val Acc: 0.721649\n",
      "Epoch 11012 - Train Loss: 0.118657, Train Acc: 0.802564 | Val Loss: 0.136099, Val Acc: 0.721649\n",
      "Epoch 11013 - Train Loss: 0.118650, Train Acc: 0.802564 | Val Loss: 0.136093, Val Acc: 0.721649\n",
      "Epoch 11014 - Train Loss: 0.118643, Train Acc: 0.802564 | Val Loss: 0.136087, Val Acc: 0.721649\n",
      "Epoch 11015 - Train Loss: 0.118636, Train Acc: 0.802564 | Val Loss: 0.136081, Val Acc: 0.721649\n",
      "Epoch 11016 - Train Loss: 0.118628, Train Acc: 0.802564 | Val Loss: 0.136075, Val Acc: 0.721649\n",
      "Epoch 11017 - Train Loss: 0.118621, Train Acc: 0.802564 | Val Loss: 0.136070, Val Acc: 0.721649\n",
      "Epoch 11018 - Train Loss: 0.118614, Train Acc: 0.802564 | Val Loss: 0.136064, Val Acc: 0.721649\n",
      "Epoch 11019 - Train Loss: 0.118607, Train Acc: 0.802564 | Val Loss: 0.136058, Val Acc: 0.721649\n",
      "Epoch 11020 - Train Loss: 0.118600, Train Acc: 0.802564 | Val Loss: 0.136052, Val Acc: 0.721649\n",
      "Epoch 11021 - Train Loss: 0.118593, Train Acc: 0.802564 | Val Loss: 0.136046, Val Acc: 0.721649\n",
      "Epoch 11022 - Train Loss: 0.118585, Train Acc: 0.802564 | Val Loss: 0.136041, Val Acc: 0.721649\n",
      "Epoch 11023 - Train Loss: 0.118578, Train Acc: 0.802564 | Val Loss: 0.136035, Val Acc: 0.721649\n",
      "Epoch 11024 - Train Loss: 0.118571, Train Acc: 0.802564 | Val Loss: 0.136029, Val Acc: 0.721649\n",
      "Epoch 11025 - Train Loss: 0.118564, Train Acc: 0.802564 | Val Loss: 0.136023, Val Acc: 0.721649\n",
      "Epoch 11026 - Train Loss: 0.118557, Train Acc: 0.802564 | Val Loss: 0.136017, Val Acc: 0.721649\n",
      "Epoch 11027 - Train Loss: 0.118550, Train Acc: 0.802564 | Val Loss: 0.136012, Val Acc: 0.721649\n",
      "Epoch 11028 - Train Loss: 0.118542, Train Acc: 0.802564 | Val Loss: 0.136006, Val Acc: 0.721649\n",
      "Epoch 11029 - Train Loss: 0.118535, Train Acc: 0.802564 | Val Loss: 0.136000, Val Acc: 0.721649\n",
      "Epoch 11030 - Train Loss: 0.118528, Train Acc: 0.802564 | Val Loss: 0.135994, Val Acc: 0.721649\n",
      "Epoch 11031 - Train Loss: 0.118521, Train Acc: 0.802564 | Val Loss: 0.135988, Val Acc: 0.721649\n",
      "Epoch 11032 - Train Loss: 0.118514, Train Acc: 0.802564 | Val Loss: 0.135983, Val Acc: 0.721649\n",
      "Epoch 11033 - Train Loss: 0.118507, Train Acc: 0.803846 | Val Loss: 0.135977, Val Acc: 0.721649\n",
      "Epoch 11034 - Train Loss: 0.118500, Train Acc: 0.803846 | Val Loss: 0.135971, Val Acc: 0.721649\n",
      "Epoch 11035 - Train Loss: 0.118492, Train Acc: 0.803846 | Val Loss: 0.135965, Val Acc: 0.721649\n",
      "Epoch 11036 - Train Loss: 0.118485, Train Acc: 0.803846 | Val Loss: 0.135960, Val Acc: 0.721649\n",
      "Epoch 11037 - Train Loss: 0.118478, Train Acc: 0.803846 | Val Loss: 0.135954, Val Acc: 0.721649\n",
      "Epoch 11038 - Train Loss: 0.118471, Train Acc: 0.803846 | Val Loss: 0.135948, Val Acc: 0.721649\n",
      "Epoch 11039 - Train Loss: 0.118464, Train Acc: 0.803846 | Val Loss: 0.135942, Val Acc: 0.721649\n",
      "Epoch 11040 - Train Loss: 0.118457, Train Acc: 0.803846 | Val Loss: 0.135936, Val Acc: 0.721649\n",
      "Epoch 11041 - Train Loss: 0.118449, Train Acc: 0.803846 | Val Loss: 0.135931, Val Acc: 0.721649\n",
      "Epoch 11042 - Train Loss: 0.118442, Train Acc: 0.803846 | Val Loss: 0.135925, Val Acc: 0.721649\n",
      "Epoch 11043 - Train Loss: 0.118435, Train Acc: 0.803846 | Val Loss: 0.135919, Val Acc: 0.721649\n",
      "Epoch 11044 - Train Loss: 0.118428, Train Acc: 0.803846 | Val Loss: 0.135913, Val Acc: 0.721649\n",
      "Epoch 11045 - Train Loss: 0.118421, Train Acc: 0.803846 | Val Loss: 0.135908, Val Acc: 0.721649\n",
      "Epoch 11046 - Train Loss: 0.118414, Train Acc: 0.803846 | Val Loss: 0.135902, Val Acc: 0.721649\n",
      "Epoch 11047 - Train Loss: 0.118407, Train Acc: 0.803846 | Val Loss: 0.135896, Val Acc: 0.721649\n",
      "Epoch 11048 - Train Loss: 0.118399, Train Acc: 0.803846 | Val Loss: 0.135890, Val Acc: 0.721649\n",
      "Epoch 11049 - Train Loss: 0.118392, Train Acc: 0.803846 | Val Loss: 0.135884, Val Acc: 0.721649\n",
      "Epoch 11050 - Train Loss: 0.118385, Train Acc: 0.803846 | Val Loss: 0.135879, Val Acc: 0.721649\n",
      "Epoch 11051 - Train Loss: 0.118378, Train Acc: 0.803846 | Val Loss: 0.135873, Val Acc: 0.721649\n",
      "Epoch 11052 - Train Loss: 0.118371, Train Acc: 0.803846 | Val Loss: 0.135867, Val Acc: 0.721649\n",
      "Epoch 11053 - Train Loss: 0.118364, Train Acc: 0.803846 | Val Loss: 0.135861, Val Acc: 0.721649\n",
      "Epoch 11054 - Train Loss: 0.118357, Train Acc: 0.803846 | Val Loss: 0.135856, Val Acc: 0.721649\n",
      "Epoch 11055 - Train Loss: 0.118349, Train Acc: 0.803846 | Val Loss: 0.135850, Val Acc: 0.721649\n",
      "Epoch 11056 - Train Loss: 0.118342, Train Acc: 0.803846 | Val Loss: 0.135844, Val Acc: 0.721649\n",
      "Epoch 11057 - Train Loss: 0.118335, Train Acc: 0.803846 | Val Loss: 0.135838, Val Acc: 0.721649\n",
      "Epoch 11058 - Train Loss: 0.118328, Train Acc: 0.803846 | Val Loss: 0.135833, Val Acc: 0.721649\n",
      "Epoch 11059 - Train Loss: 0.118321, Train Acc: 0.805128 | Val Loss: 0.135827, Val Acc: 0.721649\n",
      "Epoch 11060 - Train Loss: 0.118314, Train Acc: 0.805128 | Val Loss: 0.135821, Val Acc: 0.721649\n",
      "Epoch 11061 - Train Loss: 0.118307, Train Acc: 0.805128 | Val Loss: 0.135815, Val Acc: 0.721649\n",
      "Epoch 11062 - Train Loss: 0.118300, Train Acc: 0.805128 | Val Loss: 0.135810, Val Acc: 0.721649\n",
      "Epoch 11063 - Train Loss: 0.118292, Train Acc: 0.805128 | Val Loss: 0.135804, Val Acc: 0.721649\n",
      "Epoch 11064 - Train Loss: 0.118285, Train Acc: 0.805128 | Val Loss: 0.135798, Val Acc: 0.721649\n",
      "Epoch 11065 - Train Loss: 0.118278, Train Acc: 0.805128 | Val Loss: 0.135792, Val Acc: 0.721649\n",
      "Epoch 11066 - Train Loss: 0.118271, Train Acc: 0.805128 | Val Loss: 0.135787, Val Acc: 0.721649\n",
      "Epoch 11067 - Train Loss: 0.118264, Train Acc: 0.805128 | Val Loss: 0.135781, Val Acc: 0.721649\n",
      "Epoch 11068 - Train Loss: 0.118257, Train Acc: 0.805128 | Val Loss: 0.135775, Val Acc: 0.721649\n",
      "Epoch 11069 - Train Loss: 0.118250, Train Acc: 0.805128 | Val Loss: 0.135769, Val Acc: 0.721649\n",
      "Epoch 11070 - Train Loss: 0.118243, Train Acc: 0.805128 | Val Loss: 0.135764, Val Acc: 0.721649\n",
      "Epoch 11071 - Train Loss: 0.118235, Train Acc: 0.805128 | Val Loss: 0.135758, Val Acc: 0.721649\n",
      "Epoch 11072 - Train Loss: 0.118228, Train Acc: 0.805128 | Val Loss: 0.135752, Val Acc: 0.721649\n",
      "Epoch 11073 - Train Loss: 0.118221, Train Acc: 0.805128 | Val Loss: 0.135746, Val Acc: 0.721649\n",
      "Epoch 11074 - Train Loss: 0.118214, Train Acc: 0.805128 | Val Loss: 0.135741, Val Acc: 0.721649\n",
      "Epoch 11075 - Train Loss: 0.118207, Train Acc: 0.805128 | Val Loss: 0.135735, Val Acc: 0.721649\n",
      "Epoch 11076 - Train Loss: 0.118200, Train Acc: 0.805128 | Val Loss: 0.135729, Val Acc: 0.721649\n",
      "Epoch 11077 - Train Loss: 0.118193, Train Acc: 0.805128 | Val Loss: 0.135723, Val Acc: 0.721649\n",
      "Epoch 11078 - Train Loss: 0.118186, Train Acc: 0.805128 | Val Loss: 0.135718, Val Acc: 0.721649\n",
      "Epoch 11079 - Train Loss: 0.118179, Train Acc: 0.805128 | Val Loss: 0.135712, Val Acc: 0.721649\n",
      "Epoch 11080 - Train Loss: 0.118171, Train Acc: 0.805128 | Val Loss: 0.135706, Val Acc: 0.721649\n",
      "Epoch 11081 - Train Loss: 0.118164, Train Acc: 0.805128 | Val Loss: 0.135700, Val Acc: 0.721649\n",
      "Epoch 11082 - Train Loss: 0.118157, Train Acc: 0.805128 | Val Loss: 0.135695, Val Acc: 0.721649\n",
      "Epoch 11083 - Train Loss: 0.118150, Train Acc: 0.805128 | Val Loss: 0.135689, Val Acc: 0.721649\n",
      "Epoch 11084 - Train Loss: 0.118143, Train Acc: 0.805128 | Val Loss: 0.135683, Val Acc: 0.721649\n",
      "Epoch 11085 - Train Loss: 0.118136, Train Acc: 0.805128 | Val Loss: 0.135677, Val Acc: 0.721649\n",
      "Epoch 11086 - Train Loss: 0.118129, Train Acc: 0.805128 | Val Loss: 0.135672, Val Acc: 0.721649\n",
      "Epoch 11087 - Train Loss: 0.118122, Train Acc: 0.805128 | Val Loss: 0.135666, Val Acc: 0.721649\n",
      "Epoch 11088 - Train Loss: 0.118115, Train Acc: 0.805128 | Val Loss: 0.135660, Val Acc: 0.721649\n",
      "Epoch 11089 - Train Loss: 0.118108, Train Acc: 0.805128 | Val Loss: 0.135655, Val Acc: 0.721649\n",
      "Epoch 11090 - Train Loss: 0.118100, Train Acc: 0.805128 | Val Loss: 0.135649, Val Acc: 0.721649\n",
      "Epoch 11091 - Train Loss: 0.118093, Train Acc: 0.805128 | Val Loss: 0.135643, Val Acc: 0.721649\n",
      "Epoch 11092 - Train Loss: 0.118086, Train Acc: 0.805128 | Val Loss: 0.135637, Val Acc: 0.721649\n",
      "Epoch 11093 - Train Loss: 0.118079, Train Acc: 0.805128 | Val Loss: 0.135632, Val Acc: 0.721649\n",
      "Epoch 11094 - Train Loss: 0.118072, Train Acc: 0.805128 | Val Loss: 0.135626, Val Acc: 0.721649\n",
      "Epoch 11095 - Train Loss: 0.118065, Train Acc: 0.805128 | Val Loss: 0.135620, Val Acc: 0.721649\n",
      "Epoch 11096 - Train Loss: 0.118058, Train Acc: 0.805128 | Val Loss: 0.135615, Val Acc: 0.721649\n",
      "Epoch 11097 - Train Loss: 0.118051, Train Acc: 0.805128 | Val Loss: 0.135609, Val Acc: 0.721649\n",
      "Epoch 11098 - Train Loss: 0.118044, Train Acc: 0.805128 | Val Loss: 0.135603, Val Acc: 0.721649\n",
      "Epoch 11099 - Train Loss: 0.118037, Train Acc: 0.805128 | Val Loss: 0.135597, Val Acc: 0.721649\n",
      "Epoch 11100 - Train Loss: 0.118029, Train Acc: 0.805128 | Val Loss: 0.135592, Val Acc: 0.721649\n",
      "Epoch 11101 - Train Loss: 0.118022, Train Acc: 0.805128 | Val Loss: 0.135586, Val Acc: 0.721649\n",
      "Epoch 11102 - Train Loss: 0.118015, Train Acc: 0.805128 | Val Loss: 0.135580, Val Acc: 0.721649\n",
      "Epoch 11103 - Train Loss: 0.118008, Train Acc: 0.805128 | Val Loss: 0.135574, Val Acc: 0.721649\n",
      "Epoch 11104 - Train Loss: 0.118001, Train Acc: 0.805128 | Val Loss: 0.135569, Val Acc: 0.721649\n",
      "Epoch 11105 - Train Loss: 0.117994, Train Acc: 0.805128 | Val Loss: 0.135563, Val Acc: 0.721649\n",
      "Epoch 11106 - Train Loss: 0.117987, Train Acc: 0.805128 | Val Loss: 0.135557, Val Acc: 0.721649\n",
      "Epoch 11107 - Train Loss: 0.117980, Train Acc: 0.805128 | Val Loss: 0.135552, Val Acc: 0.721649\n",
      "Epoch 11108 - Train Loss: 0.117973, Train Acc: 0.805128 | Val Loss: 0.135546, Val Acc: 0.721649\n",
      "Epoch 11109 - Train Loss: 0.117966, Train Acc: 0.805128 | Val Loss: 0.135540, Val Acc: 0.721649\n",
      "Epoch 11110 - Train Loss: 0.117959, Train Acc: 0.805128 | Val Loss: 0.135535, Val Acc: 0.721649\n",
      "Epoch 11111 - Train Loss: 0.117952, Train Acc: 0.805128 | Val Loss: 0.135529, Val Acc: 0.721649\n",
      "Epoch 11112 - Train Loss: 0.117944, Train Acc: 0.805128 | Val Loss: 0.135523, Val Acc: 0.721649\n",
      "Epoch 11113 - Train Loss: 0.117937, Train Acc: 0.805128 | Val Loss: 0.135517, Val Acc: 0.721649\n",
      "Epoch 11114 - Train Loss: 0.117930, Train Acc: 0.805128 | Val Loss: 0.135512, Val Acc: 0.721649\n",
      "Epoch 11115 - Train Loss: 0.117923, Train Acc: 0.805128 | Val Loss: 0.135506, Val Acc: 0.721649\n",
      "Epoch 11116 - Train Loss: 0.117916, Train Acc: 0.805128 | Val Loss: 0.135500, Val Acc: 0.721649\n",
      "Epoch 11117 - Train Loss: 0.117909, Train Acc: 0.805128 | Val Loss: 0.135495, Val Acc: 0.721649\n",
      "Epoch 11118 - Train Loss: 0.117902, Train Acc: 0.805128 | Val Loss: 0.135489, Val Acc: 0.721649\n",
      "Epoch 11119 - Train Loss: 0.117895, Train Acc: 0.805128 | Val Loss: 0.135483, Val Acc: 0.721649\n",
      "Epoch 11120 - Train Loss: 0.117888, Train Acc: 0.805128 | Val Loss: 0.135478, Val Acc: 0.721649\n",
      "Epoch 11121 - Train Loss: 0.117881, Train Acc: 0.805128 | Val Loss: 0.135472, Val Acc: 0.721649\n",
      "Epoch 11122 - Train Loss: 0.117874, Train Acc: 0.805128 | Val Loss: 0.135466, Val Acc: 0.721649\n",
      "Epoch 11123 - Train Loss: 0.117867, Train Acc: 0.805128 | Val Loss: 0.135460, Val Acc: 0.721649\n",
      "Epoch 11124 - Train Loss: 0.117860, Train Acc: 0.805128 | Val Loss: 0.135455, Val Acc: 0.721649\n",
      "Epoch 11125 - Train Loss: 0.117853, Train Acc: 0.805128 | Val Loss: 0.135449, Val Acc: 0.721649\n",
      "Epoch 11126 - Train Loss: 0.117846, Train Acc: 0.805128 | Val Loss: 0.135443, Val Acc: 0.721649\n",
      "Epoch 11127 - Train Loss: 0.117838, Train Acc: 0.805128 | Val Loss: 0.135438, Val Acc: 0.721649\n",
      "Epoch 11128 - Train Loss: 0.117831, Train Acc: 0.805128 | Val Loss: 0.135432, Val Acc: 0.721649\n",
      "Epoch 11129 - Train Loss: 0.117824, Train Acc: 0.805128 | Val Loss: 0.135426, Val Acc: 0.721649\n",
      "Epoch 11130 - Train Loss: 0.117817, Train Acc: 0.805128 | Val Loss: 0.135421, Val Acc: 0.721649\n",
      "Epoch 11131 - Train Loss: 0.117810, Train Acc: 0.805128 | Val Loss: 0.135415, Val Acc: 0.721649\n",
      "Epoch 11132 - Train Loss: 0.117803, Train Acc: 0.805128 | Val Loss: 0.135409, Val Acc: 0.721649\n",
      "Epoch 11133 - Train Loss: 0.117796, Train Acc: 0.805128 | Val Loss: 0.135404, Val Acc: 0.721649\n",
      "Epoch 11134 - Train Loss: 0.117789, Train Acc: 0.805128 | Val Loss: 0.135398, Val Acc: 0.721649\n",
      "Epoch 11135 - Train Loss: 0.117782, Train Acc: 0.805128 | Val Loss: 0.135392, Val Acc: 0.721649\n",
      "Epoch 11136 - Train Loss: 0.117775, Train Acc: 0.805128 | Val Loss: 0.135387, Val Acc: 0.721649\n",
      "Epoch 11137 - Train Loss: 0.117768, Train Acc: 0.805128 | Val Loss: 0.135381, Val Acc: 0.721649\n",
      "Epoch 11138 - Train Loss: 0.117761, Train Acc: 0.805128 | Val Loss: 0.135375, Val Acc: 0.721649\n",
      "Epoch 11139 - Train Loss: 0.117754, Train Acc: 0.805128 | Val Loss: 0.135369, Val Acc: 0.721649\n",
      "Epoch 11140 - Train Loss: 0.117747, Train Acc: 0.805128 | Val Loss: 0.135364, Val Acc: 0.721649\n",
      "Epoch 11141 - Train Loss: 0.117740, Train Acc: 0.805128 | Val Loss: 0.135358, Val Acc: 0.721649\n",
      "Epoch 11142 - Train Loss: 0.117733, Train Acc: 0.805128 | Val Loss: 0.135352, Val Acc: 0.721649\n",
      "Epoch 11143 - Train Loss: 0.117726, Train Acc: 0.805128 | Val Loss: 0.135347, Val Acc: 0.721649\n",
      "Epoch 11144 - Train Loss: 0.117719, Train Acc: 0.805128 | Val Loss: 0.135341, Val Acc: 0.721649\n",
      "Epoch 11145 - Train Loss: 0.117712, Train Acc: 0.805128 | Val Loss: 0.135335, Val Acc: 0.721649\n",
      "Epoch 11146 - Train Loss: 0.117704, Train Acc: 0.805128 | Val Loss: 0.135330, Val Acc: 0.721649\n",
      "Epoch 11147 - Train Loss: 0.117697, Train Acc: 0.805128 | Val Loss: 0.135324, Val Acc: 0.721649\n",
      "Epoch 11148 - Train Loss: 0.117690, Train Acc: 0.805128 | Val Loss: 0.135318, Val Acc: 0.721649\n",
      "Epoch 11149 - Train Loss: 0.117683, Train Acc: 0.805128 | Val Loss: 0.135313, Val Acc: 0.721649\n",
      "Epoch 11150 - Train Loss: 0.117676, Train Acc: 0.805128 | Val Loss: 0.135307, Val Acc: 0.721649\n",
      "Epoch 11151 - Train Loss: 0.117669, Train Acc: 0.805128 | Val Loss: 0.135301, Val Acc: 0.721649\n",
      "Epoch 11152 - Train Loss: 0.117662, Train Acc: 0.805128 | Val Loss: 0.135296, Val Acc: 0.721649\n",
      "Epoch 11153 - Train Loss: 0.117655, Train Acc: 0.805128 | Val Loss: 0.135290, Val Acc: 0.721649\n",
      "Epoch 11154 - Train Loss: 0.117648, Train Acc: 0.805128 | Val Loss: 0.135284, Val Acc: 0.721649\n",
      "Epoch 11155 - Train Loss: 0.117641, Train Acc: 0.805128 | Val Loss: 0.135279, Val Acc: 0.721649\n",
      "Epoch 11156 - Train Loss: 0.117634, Train Acc: 0.805128 | Val Loss: 0.135273, Val Acc: 0.721649\n",
      "Epoch 11157 - Train Loss: 0.117627, Train Acc: 0.805128 | Val Loss: 0.135267, Val Acc: 0.721649\n",
      "Epoch 11158 - Train Loss: 0.117620, Train Acc: 0.806410 | Val Loss: 0.135262, Val Acc: 0.721649\n",
      "Epoch 11159 - Train Loss: 0.117613, Train Acc: 0.806410 | Val Loss: 0.135256, Val Acc: 0.721649\n",
      "Epoch 11160 - Train Loss: 0.117606, Train Acc: 0.806410 | Val Loss: 0.135251, Val Acc: 0.721649\n",
      "Epoch 11161 - Train Loss: 0.117599, Train Acc: 0.806410 | Val Loss: 0.135245, Val Acc: 0.721649\n",
      "Epoch 11162 - Train Loss: 0.117592, Train Acc: 0.806410 | Val Loss: 0.135239, Val Acc: 0.721649\n",
      "Epoch 11163 - Train Loss: 0.117585, Train Acc: 0.806410 | Val Loss: 0.135234, Val Acc: 0.721649\n",
      "Epoch 11164 - Train Loss: 0.117578, Train Acc: 0.806410 | Val Loss: 0.135228, Val Acc: 0.721649\n",
      "Epoch 11165 - Train Loss: 0.117571, Train Acc: 0.806410 | Val Loss: 0.135222, Val Acc: 0.721649\n",
      "Epoch 11166 - Train Loss: 0.117564, Train Acc: 0.806410 | Val Loss: 0.135217, Val Acc: 0.721649\n",
      "Epoch 11167 - Train Loss: 0.117557, Train Acc: 0.806410 | Val Loss: 0.135211, Val Acc: 0.721649\n",
      "Epoch 11168 - Train Loss: 0.117550, Train Acc: 0.806410 | Val Loss: 0.135205, Val Acc: 0.721649\n",
      "Epoch 11169 - Train Loss: 0.117543, Train Acc: 0.806410 | Val Loss: 0.135200, Val Acc: 0.721649\n",
      "Epoch 11170 - Train Loss: 0.117536, Train Acc: 0.806410 | Val Loss: 0.135194, Val Acc: 0.721649\n",
      "Epoch 11171 - Train Loss: 0.117529, Train Acc: 0.806410 | Val Loss: 0.135188, Val Acc: 0.721649\n",
      "Epoch 11172 - Train Loss: 0.117522, Train Acc: 0.806410 | Val Loss: 0.135183, Val Acc: 0.721649\n",
      "Epoch 11173 - Train Loss: 0.117515, Train Acc: 0.806410 | Val Loss: 0.135177, Val Acc: 0.721649\n",
      "Epoch 11174 - Train Loss: 0.117508, Train Acc: 0.806410 | Val Loss: 0.135171, Val Acc: 0.721649\n",
      "Epoch 11175 - Train Loss: 0.117501, Train Acc: 0.806410 | Val Loss: 0.135166, Val Acc: 0.721649\n",
      "Epoch 11176 - Train Loss: 0.117494, Train Acc: 0.806410 | Val Loss: 0.135160, Val Acc: 0.721649\n",
      "Epoch 11177 - Train Loss: 0.117487, Train Acc: 0.806410 | Val Loss: 0.135155, Val Acc: 0.721649\n",
      "Epoch 11178 - Train Loss: 0.117480, Train Acc: 0.806410 | Val Loss: 0.135149, Val Acc: 0.721649\n",
      "Epoch 11179 - Train Loss: 0.117473, Train Acc: 0.806410 | Val Loss: 0.135143, Val Acc: 0.721649\n",
      "Epoch 11180 - Train Loss: 0.117466, Train Acc: 0.807692 | Val Loss: 0.135138, Val Acc: 0.721649\n",
      "Epoch 11181 - Train Loss: 0.117459, Train Acc: 0.807692 | Val Loss: 0.135132, Val Acc: 0.721649\n",
      "Epoch 11182 - Train Loss: 0.117452, Train Acc: 0.807692 | Val Loss: 0.135126, Val Acc: 0.721649\n",
      "Epoch 11183 - Train Loss: 0.117445, Train Acc: 0.807692 | Val Loss: 0.135121, Val Acc: 0.721649\n",
      "Epoch 11184 - Train Loss: 0.117438, Train Acc: 0.807692 | Val Loss: 0.135115, Val Acc: 0.721649\n",
      "Epoch 11185 - Train Loss: 0.117431, Train Acc: 0.807692 | Val Loss: 0.135109, Val Acc: 0.721649\n",
      "Epoch 11186 - Train Loss: 0.117424, Train Acc: 0.807692 | Val Loss: 0.135104, Val Acc: 0.721649\n",
      "Epoch 11187 - Train Loss: 0.117417, Train Acc: 0.807692 | Val Loss: 0.135098, Val Acc: 0.721649\n",
      "Epoch 11188 - Train Loss: 0.117410, Train Acc: 0.807692 | Val Loss: 0.135093, Val Acc: 0.721649\n",
      "Epoch 11189 - Train Loss: 0.117403, Train Acc: 0.807692 | Val Loss: 0.135087, Val Acc: 0.721649\n",
      "Epoch 11190 - Train Loss: 0.117396, Train Acc: 0.807692 | Val Loss: 0.135081, Val Acc: 0.721649\n",
      "Epoch 11191 - Train Loss: 0.117389, Train Acc: 0.807692 | Val Loss: 0.135076, Val Acc: 0.721649\n",
      "Epoch 11192 - Train Loss: 0.117382, Train Acc: 0.807692 | Val Loss: 0.135070, Val Acc: 0.721649\n",
      "Epoch 11193 - Train Loss: 0.117375, Train Acc: 0.807692 | Val Loss: 0.135064, Val Acc: 0.721649\n",
      "Epoch 11194 - Train Loss: 0.117368, Train Acc: 0.807692 | Val Loss: 0.135059, Val Acc: 0.721649\n",
      "Epoch 11195 - Train Loss: 0.117361, Train Acc: 0.807692 | Val Loss: 0.135053, Val Acc: 0.721649\n",
      "Epoch 11196 - Train Loss: 0.117354, Train Acc: 0.807692 | Val Loss: 0.135048, Val Acc: 0.721649\n",
      "Epoch 11197 - Train Loss: 0.117347, Train Acc: 0.807692 | Val Loss: 0.135042, Val Acc: 0.721649\n",
      "Epoch 11198 - Train Loss: 0.117340, Train Acc: 0.807692 | Val Loss: 0.135036, Val Acc: 0.721649\n",
      "Epoch 11199 - Train Loss: 0.117333, Train Acc: 0.807692 | Val Loss: 0.135031, Val Acc: 0.721649\n",
      "Epoch 11200 - Train Loss: 0.117326, Train Acc: 0.807692 | Val Loss: 0.135025, Val Acc: 0.721649\n",
      "Epoch 11201 - Train Loss: 0.117319, Train Acc: 0.807692 | Val Loss: 0.135019, Val Acc: 0.721649\n",
      "Epoch 11202 - Train Loss: 0.117312, Train Acc: 0.807692 | Val Loss: 0.135014, Val Acc: 0.721649\n",
      "Epoch 11203 - Train Loss: 0.117305, Train Acc: 0.807692 | Val Loss: 0.135008, Val Acc: 0.721649\n",
      "Epoch 11204 - Train Loss: 0.117298, Train Acc: 0.807692 | Val Loss: 0.135003, Val Acc: 0.721649\n",
      "Epoch 11205 - Train Loss: 0.117291, Train Acc: 0.807692 | Val Loss: 0.134997, Val Acc: 0.721649\n",
      "Epoch 11206 - Train Loss: 0.117284, Train Acc: 0.807692 | Val Loss: 0.134991, Val Acc: 0.721649\n",
      "Epoch 11207 - Train Loss: 0.117277, Train Acc: 0.807692 | Val Loss: 0.134986, Val Acc: 0.721649\n",
      "Epoch 11208 - Train Loss: 0.117270, Train Acc: 0.807692 | Val Loss: 0.134980, Val Acc: 0.721649\n",
      "Epoch 11209 - Train Loss: 0.117263, Train Acc: 0.807692 | Val Loss: 0.134975, Val Acc: 0.721649\n",
      "Epoch 11210 - Train Loss: 0.117256, Train Acc: 0.807692 | Val Loss: 0.134969, Val Acc: 0.721649\n",
      "Epoch 11211 - Train Loss: 0.117249, Train Acc: 0.807692 | Val Loss: 0.134963, Val Acc: 0.721649\n",
      "Epoch 11212 - Train Loss: 0.117242, Train Acc: 0.807692 | Val Loss: 0.134958, Val Acc: 0.721649\n",
      "Epoch 11213 - Train Loss: 0.117235, Train Acc: 0.807692 | Val Loss: 0.134952, Val Acc: 0.721649\n",
      "Epoch 11214 - Train Loss: 0.117228, Train Acc: 0.807692 | Val Loss: 0.134947, Val Acc: 0.721649\n",
      "Epoch 11215 - Train Loss: 0.117221, Train Acc: 0.807692 | Val Loss: 0.134941, Val Acc: 0.721649\n",
      "Epoch 11216 - Train Loss: 0.117214, Train Acc: 0.807692 | Val Loss: 0.134935, Val Acc: 0.721649\n",
      "Epoch 11217 - Train Loss: 0.117207, Train Acc: 0.807692 | Val Loss: 0.134930, Val Acc: 0.721649\n",
      "Epoch 11218 - Train Loss: 0.117200, Train Acc: 0.807692 | Val Loss: 0.134924, Val Acc: 0.721649\n",
      "Epoch 11219 - Train Loss: 0.117193, Train Acc: 0.807692 | Val Loss: 0.134919, Val Acc: 0.721649\n",
      "Epoch 11220 - Train Loss: 0.117186, Train Acc: 0.807692 | Val Loss: 0.134913, Val Acc: 0.721649\n",
      "Epoch 11221 - Train Loss: 0.117179, Train Acc: 0.807692 | Val Loss: 0.134907, Val Acc: 0.721649\n",
      "Epoch 11222 - Train Loss: 0.117172, Train Acc: 0.807692 | Val Loss: 0.134902, Val Acc: 0.721649\n",
      "Epoch 11223 - Train Loss: 0.117165, Train Acc: 0.807692 | Val Loss: 0.134896, Val Acc: 0.721649\n",
      "Epoch 11224 - Train Loss: 0.117158, Train Acc: 0.807692 | Val Loss: 0.134891, Val Acc: 0.721649\n",
      "Epoch 11225 - Train Loss: 0.117151, Train Acc: 0.807692 | Val Loss: 0.134885, Val Acc: 0.721649\n",
      "Epoch 11226 - Train Loss: 0.117144, Train Acc: 0.807692 | Val Loss: 0.134879, Val Acc: 0.721649\n",
      "Epoch 11227 - Train Loss: 0.117137, Train Acc: 0.807692 | Val Loss: 0.134874, Val Acc: 0.721649\n",
      "Epoch 11228 - Train Loss: 0.117130, Train Acc: 0.807692 | Val Loss: 0.134868, Val Acc: 0.721649\n",
      "Epoch 11229 - Train Loss: 0.117123, Train Acc: 0.807692 | Val Loss: 0.134863, Val Acc: 0.721649\n",
      "Epoch 11230 - Train Loss: 0.117116, Train Acc: 0.807692 | Val Loss: 0.134857, Val Acc: 0.721649\n",
      "Epoch 11231 - Train Loss: 0.117109, Train Acc: 0.807692 | Val Loss: 0.134851, Val Acc: 0.721649\n",
      "Epoch 11232 - Train Loss: 0.117103, Train Acc: 0.807692 | Val Loss: 0.134846, Val Acc: 0.721649\n",
      "Epoch 11233 - Train Loss: 0.117096, Train Acc: 0.807692 | Val Loss: 0.134840, Val Acc: 0.721649\n",
      "Epoch 11234 - Train Loss: 0.117089, Train Acc: 0.807692 | Val Loss: 0.134835, Val Acc: 0.721649\n",
      "Epoch 11235 - Train Loss: 0.117082, Train Acc: 0.807692 | Val Loss: 0.134829, Val Acc: 0.721649\n",
      "Epoch 11236 - Train Loss: 0.117075, Train Acc: 0.807692 | Val Loss: 0.134824, Val Acc: 0.721649\n",
      "Epoch 11237 - Train Loss: 0.117068, Train Acc: 0.807692 | Val Loss: 0.134818, Val Acc: 0.721649\n",
      "Epoch 11238 - Train Loss: 0.117061, Train Acc: 0.807692 | Val Loss: 0.134812, Val Acc: 0.721649\n",
      "Epoch 11239 - Train Loss: 0.117054, Train Acc: 0.807692 | Val Loss: 0.134807, Val Acc: 0.721649\n",
      "Epoch 11240 - Train Loss: 0.117047, Train Acc: 0.807692 | Val Loss: 0.134801, Val Acc: 0.721649\n",
      "Epoch 11241 - Train Loss: 0.117040, Train Acc: 0.807692 | Val Loss: 0.134796, Val Acc: 0.721649\n",
      "Epoch 11242 - Train Loss: 0.117033, Train Acc: 0.807692 | Val Loss: 0.134790, Val Acc: 0.721649\n",
      "Epoch 11243 - Train Loss: 0.117026, Train Acc: 0.807692 | Val Loss: 0.134784, Val Acc: 0.721649\n",
      "Epoch 11244 - Train Loss: 0.117019, Train Acc: 0.807692 | Val Loss: 0.134779, Val Acc: 0.721649\n",
      "Epoch 11245 - Train Loss: 0.117012, Train Acc: 0.807692 | Val Loss: 0.134773, Val Acc: 0.721649\n",
      "Epoch 11246 - Train Loss: 0.117005, Train Acc: 0.807692 | Val Loss: 0.134768, Val Acc: 0.721649\n",
      "Epoch 11247 - Train Loss: 0.116998, Train Acc: 0.807692 | Val Loss: 0.134762, Val Acc: 0.721649\n",
      "Epoch 11248 - Train Loss: 0.116991, Train Acc: 0.807692 | Val Loss: 0.134757, Val Acc: 0.721649\n",
      "Epoch 11249 - Train Loss: 0.116984, Train Acc: 0.807692 | Val Loss: 0.134751, Val Acc: 0.721649\n",
      "Epoch 11250 - Train Loss: 0.116977, Train Acc: 0.807692 | Val Loss: 0.134745, Val Acc: 0.721649\n",
      "Epoch 11251 - Train Loss: 0.116971, Train Acc: 0.807692 | Val Loss: 0.134740, Val Acc: 0.721649\n",
      "Epoch 11252 - Train Loss: 0.116964, Train Acc: 0.807692 | Val Loss: 0.134734, Val Acc: 0.721649\n",
      "Epoch 11253 - Train Loss: 0.116957, Train Acc: 0.807692 | Val Loss: 0.134729, Val Acc: 0.721649\n",
      "Epoch 11254 - Train Loss: 0.116950, Train Acc: 0.807692 | Val Loss: 0.134723, Val Acc: 0.721649\n",
      "Epoch 11255 - Train Loss: 0.116943, Train Acc: 0.807692 | Val Loss: 0.134718, Val Acc: 0.721649\n",
      "Epoch 11256 - Train Loss: 0.116936, Train Acc: 0.807692 | Val Loss: 0.134712, Val Acc: 0.721649\n",
      "Epoch 11257 - Train Loss: 0.116929, Train Acc: 0.807692 | Val Loss: 0.134707, Val Acc: 0.721649\n",
      "Epoch 11258 - Train Loss: 0.116922, Train Acc: 0.807692 | Val Loss: 0.134701, Val Acc: 0.721649\n",
      "Epoch 11259 - Train Loss: 0.116915, Train Acc: 0.807692 | Val Loss: 0.134695, Val Acc: 0.721649\n",
      "Epoch 11260 - Train Loss: 0.116908, Train Acc: 0.807692 | Val Loss: 0.134690, Val Acc: 0.721649\n",
      "Epoch 11261 - Train Loss: 0.116901, Train Acc: 0.807692 | Val Loss: 0.134684, Val Acc: 0.721649\n",
      "Epoch 11262 - Train Loss: 0.116894, Train Acc: 0.807692 | Val Loss: 0.134679, Val Acc: 0.721649\n",
      "Epoch 11263 - Train Loss: 0.116887, Train Acc: 0.807692 | Val Loss: 0.134673, Val Acc: 0.721649\n",
      "Epoch 11264 - Train Loss: 0.116880, Train Acc: 0.807692 | Val Loss: 0.134668, Val Acc: 0.721649\n",
      "Epoch 11265 - Train Loss: 0.116873, Train Acc: 0.806410 | Val Loss: 0.134662, Val Acc: 0.721649\n",
      "Epoch 11266 - Train Loss: 0.116867, Train Acc: 0.806410 | Val Loss: 0.134657, Val Acc: 0.721649\n",
      "Epoch 11267 - Train Loss: 0.116860, Train Acc: 0.806410 | Val Loss: 0.134651, Val Acc: 0.721649\n",
      "Epoch 11268 - Train Loss: 0.116853, Train Acc: 0.806410 | Val Loss: 0.134645, Val Acc: 0.721649\n",
      "Epoch 11269 - Train Loss: 0.116846, Train Acc: 0.806410 | Val Loss: 0.134640, Val Acc: 0.721649\n",
      "Epoch 11270 - Train Loss: 0.116839, Train Acc: 0.806410 | Val Loss: 0.134634, Val Acc: 0.721649\n",
      "Epoch 11271 - Train Loss: 0.116832, Train Acc: 0.806410 | Val Loss: 0.134629, Val Acc: 0.721649\n",
      "Epoch 11272 - Train Loss: 0.116825, Train Acc: 0.806410 | Val Loss: 0.134623, Val Acc: 0.721649\n",
      "Epoch 11273 - Train Loss: 0.116818, Train Acc: 0.806410 | Val Loss: 0.134618, Val Acc: 0.721649\n",
      "Epoch 11274 - Train Loss: 0.116811, Train Acc: 0.806410 | Val Loss: 0.134612, Val Acc: 0.721649\n",
      "Epoch 11275 - Train Loss: 0.116804, Train Acc: 0.806410 | Val Loss: 0.134607, Val Acc: 0.721649\n",
      "Epoch 11276 - Train Loss: 0.116797, Train Acc: 0.806410 | Val Loss: 0.134601, Val Acc: 0.721649\n",
      "Epoch 11277 - Train Loss: 0.116790, Train Acc: 0.806410 | Val Loss: 0.134596, Val Acc: 0.721649\n",
      "Epoch 11278 - Train Loss: 0.116784, Train Acc: 0.806410 | Val Loss: 0.134590, Val Acc: 0.721649\n",
      "Epoch 11279 - Train Loss: 0.116777, Train Acc: 0.806410 | Val Loss: 0.134584, Val Acc: 0.721649\n",
      "Epoch 11280 - Train Loss: 0.116770, Train Acc: 0.806410 | Val Loss: 0.134579, Val Acc: 0.721649\n",
      "Epoch 11281 - Train Loss: 0.116763, Train Acc: 0.806410 | Val Loss: 0.134573, Val Acc: 0.721649\n",
      "Epoch 11282 - Train Loss: 0.116756, Train Acc: 0.806410 | Val Loss: 0.134568, Val Acc: 0.721649\n",
      "Epoch 11283 - Train Loss: 0.116749, Train Acc: 0.806410 | Val Loss: 0.134562, Val Acc: 0.721649\n",
      "Epoch 11284 - Train Loss: 0.116742, Train Acc: 0.806410 | Val Loss: 0.134557, Val Acc: 0.721649\n",
      "Epoch 11285 - Train Loss: 0.116735, Train Acc: 0.806410 | Val Loss: 0.134551, Val Acc: 0.721649\n",
      "Epoch 11286 - Train Loss: 0.116728, Train Acc: 0.806410 | Val Loss: 0.134546, Val Acc: 0.721649\n",
      "Epoch 11287 - Train Loss: 0.116721, Train Acc: 0.806410 | Val Loss: 0.134540, Val Acc: 0.721649\n",
      "Epoch 11288 - Train Loss: 0.116714, Train Acc: 0.806410 | Val Loss: 0.134535, Val Acc: 0.721649\n",
      "Epoch 11289 - Train Loss: 0.116708, Train Acc: 0.806410 | Val Loss: 0.134529, Val Acc: 0.721649\n",
      "Epoch 11290 - Train Loss: 0.116701, Train Acc: 0.806410 | Val Loss: 0.134524, Val Acc: 0.721649\n",
      "Epoch 11291 - Train Loss: 0.116694, Train Acc: 0.806410 | Val Loss: 0.134518, Val Acc: 0.721649\n",
      "Epoch 11292 - Train Loss: 0.116687, Train Acc: 0.806410 | Val Loss: 0.134512, Val Acc: 0.721649\n",
      "Epoch 11293 - Train Loss: 0.116680, Train Acc: 0.806410 | Val Loss: 0.134507, Val Acc: 0.721649\n",
      "Epoch 11294 - Train Loss: 0.116673, Train Acc: 0.806410 | Val Loss: 0.134501, Val Acc: 0.721649\n",
      "Epoch 11295 - Train Loss: 0.116666, Train Acc: 0.806410 | Val Loss: 0.134496, Val Acc: 0.721649\n",
      "Epoch 11296 - Train Loss: 0.116659, Train Acc: 0.806410 | Val Loss: 0.134490, Val Acc: 0.721649\n",
      "Epoch 11297 - Train Loss: 0.116652, Train Acc: 0.806410 | Val Loss: 0.134485, Val Acc: 0.721649\n",
      "Epoch 11298 - Train Loss: 0.116645, Train Acc: 0.806410 | Val Loss: 0.134479, Val Acc: 0.721649\n",
      "Epoch 11299 - Train Loss: 0.116639, Train Acc: 0.806410 | Val Loss: 0.134474, Val Acc: 0.721649\n",
      "Epoch 11300 - Train Loss: 0.116632, Train Acc: 0.806410 | Val Loss: 0.134468, Val Acc: 0.721649\n",
      "Epoch 11301 - Train Loss: 0.116625, Train Acc: 0.806410 | Val Loss: 0.134463, Val Acc: 0.721649\n",
      "Epoch 11302 - Train Loss: 0.116618, Train Acc: 0.806410 | Val Loss: 0.134457, Val Acc: 0.721649\n",
      "Epoch 11303 - Train Loss: 0.116611, Train Acc: 0.806410 | Val Loss: 0.134452, Val Acc: 0.721649\n",
      "Epoch 11304 - Train Loss: 0.116604, Train Acc: 0.806410 | Val Loss: 0.134446, Val Acc: 0.721649\n",
      "Epoch 11305 - Train Loss: 0.116597, Train Acc: 0.806410 | Val Loss: 0.134441, Val Acc: 0.721649\n",
      "Epoch 11306 - Train Loss: 0.116590, Train Acc: 0.806410 | Val Loss: 0.134435, Val Acc: 0.721649\n",
      "Epoch 11307 - Train Loss: 0.116584, Train Acc: 0.806410 | Val Loss: 0.134430, Val Acc: 0.721649\n",
      "Epoch 11308 - Train Loss: 0.116577, Train Acc: 0.806410 | Val Loss: 0.134424, Val Acc: 0.721649\n",
      "Epoch 11309 - Train Loss: 0.116570, Train Acc: 0.806410 | Val Loss: 0.134419, Val Acc: 0.721649\n",
      "Epoch 11310 - Train Loss: 0.116563, Train Acc: 0.806410 | Val Loss: 0.134413, Val Acc: 0.721649\n",
      "Epoch 11311 - Train Loss: 0.116556, Train Acc: 0.806410 | Val Loss: 0.134408, Val Acc: 0.721649\n",
      "Epoch 11312 - Train Loss: 0.116549, Train Acc: 0.806410 | Val Loss: 0.134402, Val Acc: 0.721649\n",
      "Epoch 11313 - Train Loss: 0.116542, Train Acc: 0.806410 | Val Loss: 0.134397, Val Acc: 0.721649\n",
      "Epoch 11314 - Train Loss: 0.116535, Train Acc: 0.806410 | Val Loss: 0.134391, Val Acc: 0.721649\n",
      "Epoch 11315 - Train Loss: 0.116528, Train Acc: 0.806410 | Val Loss: 0.134386, Val Acc: 0.721649\n",
      "Epoch 11316 - Train Loss: 0.116522, Train Acc: 0.806410 | Val Loss: 0.134380, Val Acc: 0.721649\n",
      "Epoch 11317 - Train Loss: 0.116515, Train Acc: 0.806410 | Val Loss: 0.134375, Val Acc: 0.721649\n",
      "Epoch 11318 - Train Loss: 0.116508, Train Acc: 0.806410 | Val Loss: 0.134369, Val Acc: 0.721649\n",
      "Epoch 11319 - Train Loss: 0.116501, Train Acc: 0.806410 | Val Loss: 0.134364, Val Acc: 0.721649\n",
      "Epoch 11320 - Train Loss: 0.116494, Train Acc: 0.806410 | Val Loss: 0.134358, Val Acc: 0.721649\n",
      "Epoch 11321 - Train Loss: 0.116487, Train Acc: 0.806410 | Val Loss: 0.134353, Val Acc: 0.721649\n",
      "Epoch 11322 - Train Loss: 0.116480, Train Acc: 0.806410 | Val Loss: 0.134347, Val Acc: 0.721649\n",
      "Epoch 11323 - Train Loss: 0.116474, Train Acc: 0.806410 | Val Loss: 0.134342, Val Acc: 0.721649\n",
      "Epoch 11324 - Train Loss: 0.116467, Train Acc: 0.806410 | Val Loss: 0.134336, Val Acc: 0.721649\n",
      "Epoch 11325 - Train Loss: 0.116460, Train Acc: 0.806410 | Val Loss: 0.134331, Val Acc: 0.721649\n",
      "Epoch 11326 - Train Loss: 0.116453, Train Acc: 0.806410 | Val Loss: 0.134325, Val Acc: 0.721649\n",
      "Epoch 11327 - Train Loss: 0.116446, Train Acc: 0.806410 | Val Loss: 0.134320, Val Acc: 0.721649\n",
      "Epoch 11328 - Train Loss: 0.116439, Train Acc: 0.806410 | Val Loss: 0.134314, Val Acc: 0.721649\n",
      "Epoch 11329 - Train Loss: 0.116432, Train Acc: 0.806410 | Val Loss: 0.134309, Val Acc: 0.721649\n",
      "Epoch 11330 - Train Loss: 0.116425, Train Acc: 0.806410 | Val Loss: 0.134303, Val Acc: 0.721649\n",
      "Epoch 11331 - Train Loss: 0.116419, Train Acc: 0.806410 | Val Loss: 0.134298, Val Acc: 0.721649\n",
      "Epoch 11332 - Train Loss: 0.116412, Train Acc: 0.806410 | Val Loss: 0.134292, Val Acc: 0.731959\n",
      "Epoch 11333 - Train Loss: 0.116405, Train Acc: 0.806410 | Val Loss: 0.134287, Val Acc: 0.731959\n",
      "Epoch 11334 - Train Loss: 0.116398, Train Acc: 0.806410 | Val Loss: 0.134281, Val Acc: 0.731959\n",
      "Epoch 11335 - Train Loss: 0.116391, Train Acc: 0.806410 | Val Loss: 0.134276, Val Acc: 0.731959\n",
      "Epoch 11336 - Train Loss: 0.116384, Train Acc: 0.806410 | Val Loss: 0.134270, Val Acc: 0.731959\n",
      "Epoch 11337 - Train Loss: 0.116377, Train Acc: 0.806410 | Val Loss: 0.134265, Val Acc: 0.731959\n",
      "Epoch 11338 - Train Loss: 0.116371, Train Acc: 0.806410 | Val Loss: 0.134259, Val Acc: 0.731959\n",
      "Epoch 11339 - Train Loss: 0.116364, Train Acc: 0.806410 | Val Loss: 0.134254, Val Acc: 0.731959\n",
      "Epoch 11340 - Train Loss: 0.116357, Train Acc: 0.806410 | Val Loss: 0.134248, Val Acc: 0.731959\n",
      "Epoch 11341 - Train Loss: 0.116350, Train Acc: 0.806410 | Val Loss: 0.134243, Val Acc: 0.731959\n",
      "Epoch 11342 - Train Loss: 0.116343, Train Acc: 0.806410 | Val Loss: 0.134237, Val Acc: 0.731959\n",
      "Epoch 11343 - Train Loss: 0.116336, Train Acc: 0.806410 | Val Loss: 0.134232, Val Acc: 0.731959\n",
      "Epoch 11344 - Train Loss: 0.116330, Train Acc: 0.806410 | Val Loss: 0.134226, Val Acc: 0.731959\n",
      "Epoch 11345 - Train Loss: 0.116323, Train Acc: 0.806410 | Val Loss: 0.134221, Val Acc: 0.731959\n",
      "Epoch 11346 - Train Loss: 0.116316, Train Acc: 0.806410 | Val Loss: 0.134215, Val Acc: 0.731959\n",
      "Epoch 11347 - Train Loss: 0.116309, Train Acc: 0.806410 | Val Loss: 0.134210, Val Acc: 0.731959\n",
      "Epoch 11348 - Train Loss: 0.116302, Train Acc: 0.806410 | Val Loss: 0.134204, Val Acc: 0.731959\n",
      "Epoch 11349 - Train Loss: 0.116295, Train Acc: 0.806410 | Val Loss: 0.134199, Val Acc: 0.731959\n",
      "Epoch 11350 - Train Loss: 0.116288, Train Acc: 0.806410 | Val Loss: 0.134194, Val Acc: 0.731959\n",
      "Epoch 11351 - Train Loss: 0.116282, Train Acc: 0.806410 | Val Loss: 0.134188, Val Acc: 0.731959\n",
      "Epoch 11352 - Train Loss: 0.116275, Train Acc: 0.806410 | Val Loss: 0.134183, Val Acc: 0.731959\n",
      "Epoch 11353 - Train Loss: 0.116268, Train Acc: 0.806410 | Val Loss: 0.134177, Val Acc: 0.731959\n",
      "Epoch 11354 - Train Loss: 0.116261, Train Acc: 0.806410 | Val Loss: 0.134172, Val Acc: 0.731959\n",
      "Epoch 11355 - Train Loss: 0.116254, Train Acc: 0.806410 | Val Loss: 0.134166, Val Acc: 0.731959\n",
      "Epoch 11356 - Train Loss: 0.116247, Train Acc: 0.806410 | Val Loss: 0.134161, Val Acc: 0.731959\n",
      "Epoch 11357 - Train Loss: 0.116241, Train Acc: 0.806410 | Val Loss: 0.134155, Val Acc: 0.731959\n",
      "Epoch 11358 - Train Loss: 0.116234, Train Acc: 0.806410 | Val Loss: 0.134150, Val Acc: 0.731959\n",
      "Epoch 11359 - Train Loss: 0.116227, Train Acc: 0.806410 | Val Loss: 0.134144, Val Acc: 0.731959\n",
      "Epoch 11360 - Train Loss: 0.116220, Train Acc: 0.806410 | Val Loss: 0.134139, Val Acc: 0.731959\n",
      "Epoch 11361 - Train Loss: 0.116213, Train Acc: 0.806410 | Val Loss: 0.134133, Val Acc: 0.731959\n",
      "Epoch 11362 - Train Loss: 0.116206, Train Acc: 0.806410 | Val Loss: 0.134128, Val Acc: 0.731959\n",
      "Epoch 11363 - Train Loss: 0.116200, Train Acc: 0.806410 | Val Loss: 0.134122, Val Acc: 0.731959\n",
      "Epoch 11364 - Train Loss: 0.116193, Train Acc: 0.806410 | Val Loss: 0.134117, Val Acc: 0.731959\n",
      "Epoch 11365 - Train Loss: 0.116186, Train Acc: 0.806410 | Val Loss: 0.134112, Val Acc: 0.731959\n",
      "Epoch 11366 - Train Loss: 0.116179, Train Acc: 0.806410 | Val Loss: 0.134106, Val Acc: 0.731959\n",
      "Epoch 11367 - Train Loss: 0.116172, Train Acc: 0.806410 | Val Loss: 0.134101, Val Acc: 0.731959\n",
      "Epoch 11368 - Train Loss: 0.116165, Train Acc: 0.806410 | Val Loss: 0.134095, Val Acc: 0.731959\n",
      "Epoch 11369 - Train Loss: 0.116159, Train Acc: 0.806410 | Val Loss: 0.134090, Val Acc: 0.731959\n",
      "Epoch 11370 - Train Loss: 0.116152, Train Acc: 0.806410 | Val Loss: 0.134084, Val Acc: 0.731959\n",
      "Epoch 11371 - Train Loss: 0.116145, Train Acc: 0.806410 | Val Loss: 0.134079, Val Acc: 0.731959\n",
      "Epoch 11372 - Train Loss: 0.116138, Train Acc: 0.806410 | Val Loss: 0.134073, Val Acc: 0.731959\n",
      "Epoch 11373 - Train Loss: 0.116131, Train Acc: 0.806410 | Val Loss: 0.134068, Val Acc: 0.731959\n",
      "Epoch 11374 - Train Loss: 0.116125, Train Acc: 0.806410 | Val Loss: 0.134062, Val Acc: 0.731959\n",
      "Epoch 11375 - Train Loss: 0.116118, Train Acc: 0.806410 | Val Loss: 0.134057, Val Acc: 0.731959\n",
      "Epoch 11376 - Train Loss: 0.116111, Train Acc: 0.806410 | Val Loss: 0.134052, Val Acc: 0.731959\n",
      "Epoch 11377 - Train Loss: 0.116104, Train Acc: 0.806410 | Val Loss: 0.134046, Val Acc: 0.731959\n",
      "Epoch 11378 - Train Loss: 0.116097, Train Acc: 0.806410 | Val Loss: 0.134041, Val Acc: 0.731959\n",
      "Epoch 11379 - Train Loss: 0.116090, Train Acc: 0.806410 | Val Loss: 0.134035, Val Acc: 0.731959\n",
      "Epoch 11380 - Train Loss: 0.116084, Train Acc: 0.806410 | Val Loss: 0.134030, Val Acc: 0.731959\n",
      "Epoch 11381 - Train Loss: 0.116077, Train Acc: 0.806410 | Val Loss: 0.134024, Val Acc: 0.731959\n",
      "Epoch 11382 - Train Loss: 0.116070, Train Acc: 0.806410 | Val Loss: 0.134019, Val Acc: 0.731959\n",
      "Epoch 11383 - Train Loss: 0.116063, Train Acc: 0.806410 | Val Loss: 0.134014, Val Acc: 0.731959\n",
      "Epoch 11384 - Train Loss: 0.116056, Train Acc: 0.806410 | Val Loss: 0.134008, Val Acc: 0.731959\n",
      "Epoch 11385 - Train Loss: 0.116050, Train Acc: 0.806410 | Val Loss: 0.134003, Val Acc: 0.731959\n",
      "Epoch 11386 - Train Loss: 0.116043, Train Acc: 0.806410 | Val Loss: 0.133997, Val Acc: 0.731959\n",
      "Epoch 11387 - Train Loss: 0.116036, Train Acc: 0.806410 | Val Loss: 0.133992, Val Acc: 0.731959\n",
      "Epoch 11388 - Train Loss: 0.116029, Train Acc: 0.806410 | Val Loss: 0.133987, Val Acc: 0.731959\n",
      "Epoch 11389 - Train Loss: 0.116022, Train Acc: 0.806410 | Val Loss: 0.133981, Val Acc: 0.731959\n",
      "Epoch 11390 - Train Loss: 0.116016, Train Acc: 0.806410 | Val Loss: 0.133976, Val Acc: 0.731959\n",
      "Epoch 11391 - Train Loss: 0.116009, Train Acc: 0.806410 | Val Loss: 0.133970, Val Acc: 0.731959\n",
      "Epoch 11392 - Train Loss: 0.116002, Train Acc: 0.806410 | Val Loss: 0.133965, Val Acc: 0.731959\n",
      "Epoch 11393 - Train Loss: 0.115995, Train Acc: 0.806410 | Val Loss: 0.133959, Val Acc: 0.731959\n",
      "Epoch 11394 - Train Loss: 0.115988, Train Acc: 0.806410 | Val Loss: 0.133954, Val Acc: 0.731959\n",
      "Epoch 11395 - Train Loss: 0.115982, Train Acc: 0.806410 | Val Loss: 0.133949, Val Acc: 0.731959\n",
      "Epoch 11396 - Train Loss: 0.115975, Train Acc: 0.806410 | Val Loss: 0.133943, Val Acc: 0.731959\n",
      "Epoch 11397 - Train Loss: 0.115968, Train Acc: 0.806410 | Val Loss: 0.133938, Val Acc: 0.731959\n",
      "Epoch 11398 - Train Loss: 0.115961, Train Acc: 0.806410 | Val Loss: 0.133932, Val Acc: 0.731959\n",
      "Epoch 11399 - Train Loss: 0.115954, Train Acc: 0.806410 | Val Loss: 0.133927, Val Acc: 0.731959\n",
      "Epoch 11400 - Train Loss: 0.115948, Train Acc: 0.806410 | Val Loss: 0.133922, Val Acc: 0.731959\n",
      "Epoch 11401 - Train Loss: 0.115941, Train Acc: 0.806410 | Val Loss: 0.133916, Val Acc: 0.731959\n",
      "Epoch 11402 - Train Loss: 0.115934, Train Acc: 0.806410 | Val Loss: 0.133911, Val Acc: 0.731959\n",
      "Epoch 11403 - Train Loss: 0.115927, Train Acc: 0.806410 | Val Loss: 0.133905, Val Acc: 0.742268\n",
      "Epoch 11404 - Train Loss: 0.115920, Train Acc: 0.806410 | Val Loss: 0.133900, Val Acc: 0.742268\n",
      "Epoch 11405 - Train Loss: 0.115914, Train Acc: 0.806410 | Val Loss: 0.133895, Val Acc: 0.742268\n",
      "Epoch 11406 - Train Loss: 0.115907, Train Acc: 0.806410 | Val Loss: 0.133889, Val Acc: 0.742268\n",
      "Epoch 11407 - Train Loss: 0.115900, Train Acc: 0.806410 | Val Loss: 0.133884, Val Acc: 0.742268\n",
      "Epoch 11408 - Train Loss: 0.115893, Train Acc: 0.806410 | Val Loss: 0.133878, Val Acc: 0.742268\n",
      "Epoch 11409 - Train Loss: 0.115887, Train Acc: 0.806410 | Val Loss: 0.133873, Val Acc: 0.742268\n",
      "Epoch 11410 - Train Loss: 0.115880, Train Acc: 0.806410 | Val Loss: 0.133868, Val Acc: 0.742268\n",
      "Epoch 11411 - Train Loss: 0.115873, Train Acc: 0.806410 | Val Loss: 0.133862, Val Acc: 0.742268\n",
      "Epoch 11412 - Train Loss: 0.115866, Train Acc: 0.806410 | Val Loss: 0.133857, Val Acc: 0.742268\n",
      "Epoch 11413 - Train Loss: 0.115859, Train Acc: 0.806410 | Val Loss: 0.133851, Val Acc: 0.742268\n",
      "Epoch 11414 - Train Loss: 0.115853, Train Acc: 0.806410 | Val Loss: 0.133846, Val Acc: 0.742268\n",
      "Epoch 11415 - Train Loss: 0.115846, Train Acc: 0.806410 | Val Loss: 0.133841, Val Acc: 0.742268\n",
      "Epoch 11416 - Train Loss: 0.115839, Train Acc: 0.806410 | Val Loss: 0.133835, Val Acc: 0.742268\n",
      "Epoch 11417 - Train Loss: 0.115832, Train Acc: 0.806410 | Val Loss: 0.133830, Val Acc: 0.742268\n",
      "Epoch 11418 - Train Loss: 0.115826, Train Acc: 0.806410 | Val Loss: 0.133824, Val Acc: 0.742268\n",
      "Epoch 11419 - Train Loss: 0.115819, Train Acc: 0.806410 | Val Loss: 0.133819, Val Acc: 0.742268\n",
      "Epoch 11420 - Train Loss: 0.115812, Train Acc: 0.806410 | Val Loss: 0.133814, Val Acc: 0.742268\n",
      "Epoch 11421 - Train Loss: 0.115805, Train Acc: 0.806410 | Val Loss: 0.133808, Val Acc: 0.742268\n",
      "Epoch 11422 - Train Loss: 0.115799, Train Acc: 0.806410 | Val Loss: 0.133803, Val Acc: 0.742268\n",
      "Epoch 11423 - Train Loss: 0.115792, Train Acc: 0.806410 | Val Loss: 0.133797, Val Acc: 0.742268\n",
      "Epoch 11424 - Train Loss: 0.115785, Train Acc: 0.807692 | Val Loss: 0.133792, Val Acc: 0.742268\n",
      "Epoch 11425 - Train Loss: 0.115778, Train Acc: 0.807692 | Val Loss: 0.133787, Val Acc: 0.742268\n",
      "Epoch 11426 - Train Loss: 0.115771, Train Acc: 0.807692 | Val Loss: 0.133781, Val Acc: 0.742268\n",
      "Epoch 11427 - Train Loss: 0.115765, Train Acc: 0.807692 | Val Loss: 0.133776, Val Acc: 0.742268\n",
      "Epoch 11428 - Train Loss: 0.115758, Train Acc: 0.807692 | Val Loss: 0.133770, Val Acc: 0.742268\n",
      "Epoch 11429 - Train Loss: 0.115751, Train Acc: 0.807692 | Val Loss: 0.133765, Val Acc: 0.742268\n",
      "Epoch 11430 - Train Loss: 0.115744, Train Acc: 0.807692 | Val Loss: 0.133760, Val Acc: 0.742268\n",
      "Epoch 11431 - Train Loss: 0.115738, Train Acc: 0.807692 | Val Loss: 0.133754, Val Acc: 0.742268\n",
      "Epoch 11432 - Train Loss: 0.115731, Train Acc: 0.807692 | Val Loss: 0.133749, Val Acc: 0.742268\n",
      "Epoch 11433 - Train Loss: 0.115724, Train Acc: 0.807692 | Val Loss: 0.133743, Val Acc: 0.742268\n",
      "Epoch 11434 - Train Loss: 0.115717, Train Acc: 0.807692 | Val Loss: 0.133738, Val Acc: 0.742268\n",
      "Epoch 11435 - Train Loss: 0.115711, Train Acc: 0.807692 | Val Loss: 0.133733, Val Acc: 0.742268\n",
      "Epoch 11436 - Train Loss: 0.115704, Train Acc: 0.807692 | Val Loss: 0.133727, Val Acc: 0.742268\n",
      "Epoch 11437 - Train Loss: 0.115697, Train Acc: 0.807692 | Val Loss: 0.133722, Val Acc: 0.742268\n",
      "Epoch 11438 - Train Loss: 0.115690, Train Acc: 0.807692 | Val Loss: 0.133717, Val Acc: 0.742268\n",
      "Epoch 11439 - Train Loss: 0.115684, Train Acc: 0.807692 | Val Loss: 0.133711, Val Acc: 0.742268\n",
      "Epoch 11440 - Train Loss: 0.115677, Train Acc: 0.807692 | Val Loss: 0.133706, Val Acc: 0.742268\n",
      "Epoch 11441 - Train Loss: 0.115670, Train Acc: 0.807692 | Val Loss: 0.133700, Val Acc: 0.742268\n",
      "Epoch 11442 - Train Loss: 0.115663, Train Acc: 0.807692 | Val Loss: 0.133695, Val Acc: 0.742268\n",
      "Epoch 11443 - Train Loss: 0.115657, Train Acc: 0.807692 | Val Loss: 0.133690, Val Acc: 0.742268\n",
      "Epoch 11444 - Train Loss: 0.115650, Train Acc: 0.807692 | Val Loss: 0.133684, Val Acc: 0.742268\n",
      "Epoch 11445 - Train Loss: 0.115643, Train Acc: 0.807692 | Val Loss: 0.133679, Val Acc: 0.742268\n",
      "Epoch 11446 - Train Loss: 0.115636, Train Acc: 0.807692 | Val Loss: 0.133673, Val Acc: 0.742268\n",
      "Epoch 11447 - Train Loss: 0.115630, Train Acc: 0.807692 | Val Loss: 0.133668, Val Acc: 0.742268\n",
      "Epoch 11448 - Train Loss: 0.115623, Train Acc: 0.807692 | Val Loss: 0.133663, Val Acc: 0.742268\n",
      "Epoch 11449 - Train Loss: 0.115616, Train Acc: 0.807692 | Val Loss: 0.133657, Val Acc: 0.742268\n",
      "Epoch 11450 - Train Loss: 0.115609, Train Acc: 0.807692 | Val Loss: 0.133652, Val Acc: 0.742268\n",
      "Epoch 11451 - Train Loss: 0.115603, Train Acc: 0.807692 | Val Loss: 0.133647, Val Acc: 0.742268\n",
      "Epoch 11452 - Train Loss: 0.115596, Train Acc: 0.807692 | Val Loss: 0.133641, Val Acc: 0.742268\n",
      "Epoch 11453 - Train Loss: 0.115589, Train Acc: 0.807692 | Val Loss: 0.133636, Val Acc: 0.742268\n",
      "Epoch 11454 - Train Loss: 0.115582, Train Acc: 0.807692 | Val Loss: 0.133630, Val Acc: 0.742268\n",
      "Epoch 11455 - Train Loss: 0.115576, Train Acc: 0.807692 | Val Loss: 0.133625, Val Acc: 0.742268\n",
      "Epoch 11456 - Train Loss: 0.115569, Train Acc: 0.807692 | Val Loss: 0.133620, Val Acc: 0.742268\n",
      "Epoch 11457 - Train Loss: 0.115562, Train Acc: 0.807692 | Val Loss: 0.133614, Val Acc: 0.742268\n",
      "Epoch 11458 - Train Loss: 0.115555, Train Acc: 0.807692 | Val Loss: 0.133609, Val Acc: 0.742268\n",
      "Epoch 11459 - Train Loss: 0.115549, Train Acc: 0.807692 | Val Loss: 0.133604, Val Acc: 0.742268\n",
      "Epoch 11460 - Train Loss: 0.115542, Train Acc: 0.807692 | Val Loss: 0.133598, Val Acc: 0.742268\n",
      "Epoch 11461 - Train Loss: 0.115535, Train Acc: 0.807692 | Val Loss: 0.133593, Val Acc: 0.742268\n",
      "Epoch 11462 - Train Loss: 0.115529, Train Acc: 0.807692 | Val Loss: 0.133587, Val Acc: 0.742268\n",
      "Epoch 11463 - Train Loss: 0.115522, Train Acc: 0.807692 | Val Loss: 0.133582, Val Acc: 0.742268\n",
      "Epoch 11464 - Train Loss: 0.115515, Train Acc: 0.807692 | Val Loss: 0.133577, Val Acc: 0.742268\n",
      "Epoch 11465 - Train Loss: 0.115508, Train Acc: 0.807692 | Val Loss: 0.133571, Val Acc: 0.742268\n",
      "Epoch 11466 - Train Loss: 0.115502, Train Acc: 0.807692 | Val Loss: 0.133566, Val Acc: 0.742268\n",
      "Epoch 11467 - Train Loss: 0.115495, Train Acc: 0.807692 | Val Loss: 0.133561, Val Acc: 0.742268\n",
      "Epoch 11468 - Train Loss: 0.115488, Train Acc: 0.807692 | Val Loss: 0.133555, Val Acc: 0.742268\n",
      "Epoch 11469 - Train Loss: 0.115481, Train Acc: 0.807692 | Val Loss: 0.133550, Val Acc: 0.742268\n",
      "Epoch 11470 - Train Loss: 0.115475, Train Acc: 0.807692 | Val Loss: 0.133545, Val Acc: 0.742268\n",
      "Epoch 11471 - Train Loss: 0.115468, Train Acc: 0.807692 | Val Loss: 0.133539, Val Acc: 0.742268\n",
      "Epoch 11472 - Train Loss: 0.115461, Train Acc: 0.807692 | Val Loss: 0.133534, Val Acc: 0.742268\n",
      "Epoch 11473 - Train Loss: 0.115455, Train Acc: 0.808974 | Val Loss: 0.133529, Val Acc: 0.742268\n",
      "Epoch 11474 - Train Loss: 0.115448, Train Acc: 0.808974 | Val Loss: 0.133523, Val Acc: 0.742268\n",
      "Epoch 11475 - Train Loss: 0.115441, Train Acc: 0.808974 | Val Loss: 0.133518, Val Acc: 0.742268\n",
      "Epoch 11476 - Train Loss: 0.115434, Train Acc: 0.808974 | Val Loss: 0.133512, Val Acc: 0.742268\n",
      "Epoch 11477 - Train Loss: 0.115428, Train Acc: 0.808974 | Val Loss: 0.133507, Val Acc: 0.742268\n",
      "Epoch 11478 - Train Loss: 0.115421, Train Acc: 0.808974 | Val Loss: 0.133502, Val Acc: 0.742268\n",
      "Epoch 11479 - Train Loss: 0.115414, Train Acc: 0.808974 | Val Loss: 0.133496, Val Acc: 0.742268\n",
      "Epoch 11480 - Train Loss: 0.115408, Train Acc: 0.808974 | Val Loss: 0.133491, Val Acc: 0.742268\n",
      "Epoch 11481 - Train Loss: 0.115401, Train Acc: 0.808974 | Val Loss: 0.133486, Val Acc: 0.742268\n",
      "Epoch 11482 - Train Loss: 0.115394, Train Acc: 0.808974 | Val Loss: 0.133480, Val Acc: 0.742268\n",
      "Epoch 11483 - Train Loss: 0.115387, Train Acc: 0.808974 | Val Loss: 0.133475, Val Acc: 0.742268\n",
      "Epoch 11484 - Train Loss: 0.115381, Train Acc: 0.808974 | Val Loss: 0.133470, Val Acc: 0.742268\n",
      "Epoch 11485 - Train Loss: 0.115374, Train Acc: 0.808974 | Val Loss: 0.133464, Val Acc: 0.742268\n",
      "Epoch 11486 - Train Loss: 0.115367, Train Acc: 0.808974 | Val Loss: 0.133459, Val Acc: 0.742268\n",
      "Epoch 11487 - Train Loss: 0.115361, Train Acc: 0.808974 | Val Loss: 0.133454, Val Acc: 0.742268\n",
      "Epoch 11488 - Train Loss: 0.115354, Train Acc: 0.808974 | Val Loss: 0.133448, Val Acc: 0.742268\n",
      "Epoch 11489 - Train Loss: 0.115347, Train Acc: 0.808974 | Val Loss: 0.133443, Val Acc: 0.742268\n",
      "Epoch 11490 - Train Loss: 0.115340, Train Acc: 0.808974 | Val Loss: 0.133438, Val Acc: 0.742268\n",
      "Epoch 11491 - Train Loss: 0.115334, Train Acc: 0.808974 | Val Loss: 0.133432, Val Acc: 0.742268\n",
      "Epoch 11492 - Train Loss: 0.115327, Train Acc: 0.808974 | Val Loss: 0.133427, Val Acc: 0.742268\n",
      "Epoch 11493 - Train Loss: 0.115320, Train Acc: 0.808974 | Val Loss: 0.133422, Val Acc: 0.742268\n",
      "Epoch 11494 - Train Loss: 0.115314, Train Acc: 0.808974 | Val Loss: 0.133416, Val Acc: 0.742268\n",
      "Epoch 11495 - Train Loss: 0.115307, Train Acc: 0.808974 | Val Loss: 0.133411, Val Acc: 0.742268\n",
      "Epoch 11496 - Train Loss: 0.115300, Train Acc: 0.808974 | Val Loss: 0.133406, Val Acc: 0.742268\n",
      "Epoch 11497 - Train Loss: 0.115294, Train Acc: 0.808974 | Val Loss: 0.133400, Val Acc: 0.742268\n",
      "Epoch 11498 - Train Loss: 0.115287, Train Acc: 0.808974 | Val Loss: 0.133395, Val Acc: 0.742268\n",
      "Epoch 11499 - Train Loss: 0.115280, Train Acc: 0.808974 | Val Loss: 0.133389, Val Acc: 0.742268\n",
      "Epoch 11500 - Train Loss: 0.115273, Train Acc: 0.808974 | Val Loss: 0.133384, Val Acc: 0.742268\n",
      "Epoch 11501 - Train Loss: 0.115267, Train Acc: 0.808974 | Val Loss: 0.133379, Val Acc: 0.742268\n",
      "Epoch 11502 - Train Loss: 0.115260, Train Acc: 0.808974 | Val Loss: 0.133373, Val Acc: 0.742268\n",
      "Epoch 11503 - Train Loss: 0.115253, Train Acc: 0.808974 | Val Loss: 0.133368, Val Acc: 0.752577\n",
      "Epoch 11504 - Train Loss: 0.115247, Train Acc: 0.808974 | Val Loss: 0.133363, Val Acc: 0.752577\n",
      "Epoch 11505 - Train Loss: 0.115240, Train Acc: 0.808974 | Val Loss: 0.133357, Val Acc: 0.752577\n",
      "Epoch 11506 - Train Loss: 0.115233, Train Acc: 0.808974 | Val Loss: 0.133352, Val Acc: 0.752577\n",
      "Epoch 11507 - Train Loss: 0.115227, Train Acc: 0.808974 | Val Loss: 0.133347, Val Acc: 0.752577\n",
      "Epoch 11508 - Train Loss: 0.115220, Train Acc: 0.808974 | Val Loss: 0.133341, Val Acc: 0.752577\n",
      "Epoch 11509 - Train Loss: 0.115213, Train Acc: 0.808974 | Val Loss: 0.133336, Val Acc: 0.752577\n",
      "Epoch 11510 - Train Loss: 0.115207, Train Acc: 0.808974 | Val Loss: 0.133331, Val Acc: 0.752577\n",
      "Epoch 11511 - Train Loss: 0.115200, Train Acc: 0.808974 | Val Loss: 0.133325, Val Acc: 0.752577\n",
      "Epoch 11512 - Train Loss: 0.115193, Train Acc: 0.808974 | Val Loss: 0.133320, Val Acc: 0.752577\n",
      "Epoch 11513 - Train Loss: 0.115186, Train Acc: 0.808974 | Val Loss: 0.133315, Val Acc: 0.752577\n",
      "Epoch 11514 - Train Loss: 0.115180, Train Acc: 0.808974 | Val Loss: 0.133309, Val Acc: 0.752577\n",
      "Epoch 11515 - Train Loss: 0.115173, Train Acc: 0.808974 | Val Loss: 0.133304, Val Acc: 0.752577\n",
      "Epoch 11516 - Train Loss: 0.115166, Train Acc: 0.808974 | Val Loss: 0.133298, Val Acc: 0.752577\n",
      "Epoch 11517 - Train Loss: 0.115160, Train Acc: 0.808974 | Val Loss: 0.133293, Val Acc: 0.752577\n",
      "Epoch 11518 - Train Loss: 0.115153, Train Acc: 0.808974 | Val Loss: 0.133288, Val Acc: 0.752577\n",
      "Epoch 11519 - Train Loss: 0.115146, Train Acc: 0.808974 | Val Loss: 0.133282, Val Acc: 0.752577\n",
      "Epoch 11520 - Train Loss: 0.115140, Train Acc: 0.808974 | Val Loss: 0.133277, Val Acc: 0.752577\n",
      "Epoch 11521 - Train Loss: 0.115133, Train Acc: 0.808974 | Val Loss: 0.133272, Val Acc: 0.752577\n",
      "Epoch 11522 - Train Loss: 0.115126, Train Acc: 0.808974 | Val Loss: 0.133266, Val Acc: 0.752577\n",
      "Epoch 11523 - Train Loss: 0.115120, Train Acc: 0.808974 | Val Loss: 0.133261, Val Acc: 0.752577\n",
      "Epoch 11524 - Train Loss: 0.115113, Train Acc: 0.808974 | Val Loss: 0.133256, Val Acc: 0.752577\n",
      "Epoch 11525 - Train Loss: 0.115106, Train Acc: 0.810256 | Val Loss: 0.133250, Val Acc: 0.752577\n",
      "Epoch 11526 - Train Loss: 0.115100, Train Acc: 0.810256 | Val Loss: 0.133245, Val Acc: 0.752577\n",
      "Epoch 11527 - Train Loss: 0.115093, Train Acc: 0.810256 | Val Loss: 0.133240, Val Acc: 0.752577\n",
      "Epoch 11528 - Train Loss: 0.115086, Train Acc: 0.810256 | Val Loss: 0.133234, Val Acc: 0.752577\n",
      "Epoch 11529 - Train Loss: 0.115080, Train Acc: 0.810256 | Val Loss: 0.133229, Val Acc: 0.752577\n",
      "Epoch 11530 - Train Loss: 0.115073, Train Acc: 0.810256 | Val Loss: 0.133224, Val Acc: 0.752577\n",
      "Epoch 11531 - Train Loss: 0.115066, Train Acc: 0.810256 | Val Loss: 0.133218, Val Acc: 0.752577\n",
      "Epoch 11532 - Train Loss: 0.115060, Train Acc: 0.810256 | Val Loss: 0.133213, Val Acc: 0.752577\n",
      "Epoch 11533 - Train Loss: 0.115053, Train Acc: 0.810256 | Val Loss: 0.133208, Val Acc: 0.752577\n",
      "Epoch 11534 - Train Loss: 0.115046, Train Acc: 0.810256 | Val Loss: 0.133202, Val Acc: 0.752577\n",
      "Epoch 11535 - Train Loss: 0.115040, Train Acc: 0.810256 | Val Loss: 0.133197, Val Acc: 0.752577\n",
      "Epoch 11536 - Train Loss: 0.115033, Train Acc: 0.810256 | Val Loss: 0.133192, Val Acc: 0.752577\n",
      "Epoch 11537 - Train Loss: 0.115026, Train Acc: 0.810256 | Val Loss: 0.133186, Val Acc: 0.752577\n",
      "Epoch 11538 - Train Loss: 0.115020, Train Acc: 0.810256 | Val Loss: 0.133181, Val Acc: 0.752577\n",
      "Epoch 11539 - Train Loss: 0.115013, Train Acc: 0.810256 | Val Loss: 0.133176, Val Acc: 0.752577\n",
      "Epoch 11540 - Train Loss: 0.115006, Train Acc: 0.810256 | Val Loss: 0.133170, Val Acc: 0.752577\n",
      "Epoch 11541 - Train Loss: 0.115000, Train Acc: 0.810256 | Val Loss: 0.133165, Val Acc: 0.752577\n",
      "Epoch 11542 - Train Loss: 0.114993, Train Acc: 0.810256 | Val Loss: 0.133160, Val Acc: 0.752577\n",
      "Epoch 11543 - Train Loss: 0.114986, Train Acc: 0.810256 | Val Loss: 0.133154, Val Acc: 0.752577\n",
      "Epoch 11544 - Train Loss: 0.114980, Train Acc: 0.810256 | Val Loss: 0.133149, Val Acc: 0.752577\n",
      "Epoch 11545 - Train Loss: 0.114973, Train Acc: 0.810256 | Val Loss: 0.133144, Val Acc: 0.752577\n",
      "Epoch 11546 - Train Loss: 0.114966, Train Acc: 0.810256 | Val Loss: 0.133138, Val Acc: 0.752577\n",
      "Epoch 11547 - Train Loss: 0.114960, Train Acc: 0.810256 | Val Loss: 0.133133, Val Acc: 0.752577\n",
      "Epoch 11548 - Train Loss: 0.114953, Train Acc: 0.810256 | Val Loss: 0.133128, Val Acc: 0.752577\n",
      "Epoch 11549 - Train Loss: 0.114947, Train Acc: 0.810256 | Val Loss: 0.133122, Val Acc: 0.752577\n",
      "Epoch 11550 - Train Loss: 0.114940, Train Acc: 0.810256 | Val Loss: 0.133117, Val Acc: 0.752577\n",
      "Epoch 11551 - Train Loss: 0.114933, Train Acc: 0.810256 | Val Loss: 0.133112, Val Acc: 0.752577\n",
      "Epoch 11552 - Train Loss: 0.114927, Train Acc: 0.810256 | Val Loss: 0.133107, Val Acc: 0.752577\n",
      "Epoch 11553 - Train Loss: 0.114920, Train Acc: 0.810256 | Val Loss: 0.133101, Val Acc: 0.752577\n",
      "Epoch 11554 - Train Loss: 0.114913, Train Acc: 0.810256 | Val Loss: 0.133096, Val Acc: 0.752577\n",
      "Epoch 11555 - Train Loss: 0.114907, Train Acc: 0.810256 | Val Loss: 0.133091, Val Acc: 0.752577\n",
      "Epoch 11556 - Train Loss: 0.114900, Train Acc: 0.810256 | Val Loss: 0.133085, Val Acc: 0.752577\n",
      "Epoch 11557 - Train Loss: 0.114893, Train Acc: 0.810256 | Val Loss: 0.133080, Val Acc: 0.752577\n",
      "Epoch 11558 - Train Loss: 0.114887, Train Acc: 0.810256 | Val Loss: 0.133075, Val Acc: 0.752577\n",
      "Epoch 11559 - Train Loss: 0.114880, Train Acc: 0.810256 | Val Loss: 0.133069, Val Acc: 0.752577\n",
      "Epoch 11560 - Train Loss: 0.114873, Train Acc: 0.810256 | Val Loss: 0.133064, Val Acc: 0.752577\n",
      "Epoch 11561 - Train Loss: 0.114867, Train Acc: 0.810256 | Val Loss: 0.133059, Val Acc: 0.752577\n",
      "Epoch 11562 - Train Loss: 0.114860, Train Acc: 0.810256 | Val Loss: 0.133054, Val Acc: 0.752577\n",
      "Epoch 11563 - Train Loss: 0.114854, Train Acc: 0.810256 | Val Loss: 0.133048, Val Acc: 0.752577\n",
      "Epoch 11564 - Train Loss: 0.114847, Train Acc: 0.810256 | Val Loss: 0.133043, Val Acc: 0.752577\n",
      "Epoch 11565 - Train Loss: 0.114840, Train Acc: 0.810256 | Val Loss: 0.133038, Val Acc: 0.752577\n",
      "Epoch 11566 - Train Loss: 0.114834, Train Acc: 0.810256 | Val Loss: 0.133032, Val Acc: 0.752577\n",
      "Epoch 11567 - Train Loss: 0.114827, Train Acc: 0.810256 | Val Loss: 0.133027, Val Acc: 0.752577\n",
      "Epoch 11568 - Train Loss: 0.114820, Train Acc: 0.810256 | Val Loss: 0.133022, Val Acc: 0.752577\n",
      "Epoch 11569 - Train Loss: 0.114814, Train Acc: 0.810256 | Val Loss: 0.133017, Val Acc: 0.752577\n",
      "Epoch 11570 - Train Loss: 0.114807, Train Acc: 0.810256 | Val Loss: 0.133011, Val Acc: 0.752577\n",
      "Epoch 11571 - Train Loss: 0.114801, Train Acc: 0.810256 | Val Loss: 0.133006, Val Acc: 0.752577\n",
      "Epoch 11572 - Train Loss: 0.114794, Train Acc: 0.810256 | Val Loss: 0.133001, Val Acc: 0.752577\n",
      "Epoch 11573 - Train Loss: 0.114787, Train Acc: 0.810256 | Val Loss: 0.132995, Val Acc: 0.752577\n",
      "Epoch 11574 - Train Loss: 0.114781, Train Acc: 0.810256 | Val Loss: 0.132990, Val Acc: 0.752577\n",
      "Epoch 11575 - Train Loss: 0.114774, Train Acc: 0.810256 | Val Loss: 0.132985, Val Acc: 0.752577\n",
      "Epoch 11576 - Train Loss: 0.114767, Train Acc: 0.810256 | Val Loss: 0.132980, Val Acc: 0.752577\n",
      "Epoch 11577 - Train Loss: 0.114761, Train Acc: 0.810256 | Val Loss: 0.132974, Val Acc: 0.752577\n",
      "Epoch 11578 - Train Loss: 0.114754, Train Acc: 0.810256 | Val Loss: 0.132969, Val Acc: 0.752577\n",
      "Epoch 11579 - Train Loss: 0.114748, Train Acc: 0.810256 | Val Loss: 0.132964, Val Acc: 0.752577\n",
      "Epoch 11580 - Train Loss: 0.114741, Train Acc: 0.810256 | Val Loss: 0.132959, Val Acc: 0.752577\n",
      "Epoch 11581 - Train Loss: 0.114734, Train Acc: 0.810256 | Val Loss: 0.132953, Val Acc: 0.752577\n",
      "Epoch 11582 - Train Loss: 0.114728, Train Acc: 0.810256 | Val Loss: 0.132948, Val Acc: 0.752577\n",
      "Epoch 11583 - Train Loss: 0.114721, Train Acc: 0.810256 | Val Loss: 0.132943, Val Acc: 0.752577\n",
      "Epoch 11584 - Train Loss: 0.114714, Train Acc: 0.810256 | Val Loss: 0.132938, Val Acc: 0.752577\n",
      "Epoch 11585 - Train Loss: 0.114708, Train Acc: 0.810256 | Val Loss: 0.132932, Val Acc: 0.752577\n",
      "Epoch 11586 - Train Loss: 0.114701, Train Acc: 0.810256 | Val Loss: 0.132927, Val Acc: 0.752577\n",
      "Epoch 11587 - Train Loss: 0.114695, Train Acc: 0.810256 | Val Loss: 0.132922, Val Acc: 0.752577\n",
      "Epoch 11588 - Train Loss: 0.114688, Train Acc: 0.810256 | Val Loss: 0.132916, Val Acc: 0.752577\n",
      "Epoch 11589 - Train Loss: 0.114681, Train Acc: 0.810256 | Val Loss: 0.132911, Val Acc: 0.752577\n",
      "Epoch 11590 - Train Loss: 0.114675, Train Acc: 0.810256 | Val Loss: 0.132906, Val Acc: 0.752577\n",
      "Epoch 11591 - Train Loss: 0.114668, Train Acc: 0.810256 | Val Loss: 0.132901, Val Acc: 0.752577\n",
      "Epoch 11592 - Train Loss: 0.114662, Train Acc: 0.810256 | Val Loss: 0.132895, Val Acc: 0.752577\n",
      "Epoch 11593 - Train Loss: 0.114655, Train Acc: 0.810256 | Val Loss: 0.132890, Val Acc: 0.752577\n",
      "Epoch 11594 - Train Loss: 0.114648, Train Acc: 0.810256 | Val Loss: 0.132885, Val Acc: 0.752577\n",
      "Epoch 11595 - Train Loss: 0.114642, Train Acc: 0.810256 | Val Loss: 0.132880, Val Acc: 0.752577\n",
      "Epoch 11596 - Train Loss: 0.114635, Train Acc: 0.810256 | Val Loss: 0.132874, Val Acc: 0.752577\n",
      "Epoch 11597 - Train Loss: 0.114629, Train Acc: 0.810256 | Val Loss: 0.132869, Val Acc: 0.752577\n",
      "Epoch 11598 - Train Loss: 0.114622, Train Acc: 0.810256 | Val Loss: 0.132864, Val Acc: 0.752577\n",
      "Epoch 11599 - Train Loss: 0.114615, Train Acc: 0.810256 | Val Loss: 0.132859, Val Acc: 0.752577\n",
      "Epoch 11600 - Train Loss: 0.114609, Train Acc: 0.810256 | Val Loss: 0.132853, Val Acc: 0.752577\n",
      "Epoch 11601 - Train Loss: 0.114602, Train Acc: 0.810256 | Val Loss: 0.132848, Val Acc: 0.752577\n",
      "Epoch 11602 - Train Loss: 0.114596, Train Acc: 0.810256 | Val Loss: 0.132843, Val Acc: 0.752577\n",
      "Epoch 11603 - Train Loss: 0.114589, Train Acc: 0.810256 | Val Loss: 0.132838, Val Acc: 0.752577\n",
      "Epoch 11604 - Train Loss: 0.114582, Train Acc: 0.810256 | Val Loss: 0.132832, Val Acc: 0.752577\n",
      "Epoch 11605 - Train Loss: 0.114576, Train Acc: 0.810256 | Val Loss: 0.132827, Val Acc: 0.752577\n",
      "Epoch 11606 - Train Loss: 0.114569, Train Acc: 0.810256 | Val Loss: 0.132822, Val Acc: 0.752577\n",
      "Epoch 11607 - Train Loss: 0.114563, Train Acc: 0.810256 | Val Loss: 0.132817, Val Acc: 0.752577\n",
      "Epoch 11608 - Train Loss: 0.114556, Train Acc: 0.810256 | Val Loss: 0.132812, Val Acc: 0.752577\n",
      "Epoch 11609 - Train Loss: 0.114549, Train Acc: 0.810256 | Val Loss: 0.132806, Val Acc: 0.752577\n",
      "Epoch 11610 - Train Loss: 0.114543, Train Acc: 0.810256 | Val Loss: 0.132801, Val Acc: 0.752577\n",
      "Epoch 11611 - Train Loss: 0.114536, Train Acc: 0.810256 | Val Loss: 0.132796, Val Acc: 0.752577\n",
      "Epoch 11612 - Train Loss: 0.114530, Train Acc: 0.810256 | Val Loss: 0.132791, Val Acc: 0.752577\n",
      "Epoch 11613 - Train Loss: 0.114523, Train Acc: 0.810256 | Val Loss: 0.132785, Val Acc: 0.752577\n",
      "Epoch 11614 - Train Loss: 0.114516, Train Acc: 0.810256 | Val Loss: 0.132780, Val Acc: 0.752577\n",
      "Epoch 11615 - Train Loss: 0.114510, Train Acc: 0.810256 | Val Loss: 0.132775, Val Acc: 0.752577\n",
      "Epoch 11616 - Train Loss: 0.114503, Train Acc: 0.810256 | Val Loss: 0.132770, Val Acc: 0.752577\n",
      "Epoch 11617 - Train Loss: 0.114497, Train Acc: 0.810256 | Val Loss: 0.132764, Val Acc: 0.752577\n",
      "Epoch 11618 - Train Loss: 0.114490, Train Acc: 0.810256 | Val Loss: 0.132759, Val Acc: 0.752577\n",
      "Epoch 11619 - Train Loss: 0.114483, Train Acc: 0.810256 | Val Loss: 0.132754, Val Acc: 0.752577\n",
      "Epoch 11620 - Train Loss: 0.114477, Train Acc: 0.810256 | Val Loss: 0.132749, Val Acc: 0.752577\n",
      "Epoch 11621 - Train Loss: 0.114470, Train Acc: 0.810256 | Val Loss: 0.132744, Val Acc: 0.752577\n",
      "Epoch 11622 - Train Loss: 0.114464, Train Acc: 0.810256 | Val Loss: 0.132738, Val Acc: 0.752577\n",
      "Epoch 11623 - Train Loss: 0.114457, Train Acc: 0.810256 | Val Loss: 0.132733, Val Acc: 0.752577\n",
      "Epoch 11624 - Train Loss: 0.114451, Train Acc: 0.810256 | Val Loss: 0.132728, Val Acc: 0.752577\n",
      "Epoch 11625 - Train Loss: 0.114444, Train Acc: 0.810256 | Val Loss: 0.132723, Val Acc: 0.752577\n",
      "Epoch 11626 - Train Loss: 0.114437, Train Acc: 0.810256 | Val Loss: 0.132717, Val Acc: 0.752577\n",
      "Epoch 11627 - Train Loss: 0.114431, Train Acc: 0.810256 | Val Loss: 0.132712, Val Acc: 0.752577\n",
      "Epoch 11628 - Train Loss: 0.114424, Train Acc: 0.810256 | Val Loss: 0.132707, Val Acc: 0.752577\n",
      "Epoch 11629 - Train Loss: 0.114418, Train Acc: 0.810256 | Val Loss: 0.132702, Val Acc: 0.752577\n",
      "Epoch 11630 - Train Loss: 0.114411, Train Acc: 0.810256 | Val Loss: 0.132697, Val Acc: 0.752577\n",
      "Epoch 11631 - Train Loss: 0.114405, Train Acc: 0.810256 | Val Loss: 0.132691, Val Acc: 0.752577\n",
      "Epoch 11632 - Train Loss: 0.114398, Train Acc: 0.810256 | Val Loss: 0.132686, Val Acc: 0.752577\n",
      "Epoch 11633 - Train Loss: 0.114391, Train Acc: 0.810256 | Val Loss: 0.132681, Val Acc: 0.752577\n",
      "Epoch 11634 - Train Loss: 0.114385, Train Acc: 0.810256 | Val Loss: 0.132676, Val Acc: 0.752577\n",
      "Epoch 11635 - Train Loss: 0.114378, Train Acc: 0.810256 | Val Loss: 0.132671, Val Acc: 0.752577\n",
      "Epoch 11636 - Train Loss: 0.114372, Train Acc: 0.810256 | Val Loss: 0.132665, Val Acc: 0.752577\n",
      "Epoch 11637 - Train Loss: 0.114365, Train Acc: 0.810256 | Val Loss: 0.132660, Val Acc: 0.752577\n",
      "Epoch 11638 - Train Loss: 0.114359, Train Acc: 0.810256 | Val Loss: 0.132655, Val Acc: 0.752577\n",
      "Epoch 11639 - Train Loss: 0.114352, Train Acc: 0.810256 | Val Loss: 0.132650, Val Acc: 0.752577\n",
      "Epoch 11640 - Train Loss: 0.114345, Train Acc: 0.810256 | Val Loss: 0.132645, Val Acc: 0.752577\n",
      "Epoch 11641 - Train Loss: 0.114339, Train Acc: 0.810256 | Val Loss: 0.132639, Val Acc: 0.752577\n",
      "Epoch 11642 - Train Loss: 0.114332, Train Acc: 0.810256 | Val Loss: 0.132634, Val Acc: 0.752577\n",
      "Epoch 11643 - Train Loss: 0.114326, Train Acc: 0.810256 | Val Loss: 0.132629, Val Acc: 0.752577\n",
      "Epoch 11644 - Train Loss: 0.114319, Train Acc: 0.810256 | Val Loss: 0.132624, Val Acc: 0.752577\n",
      "Epoch 11645 - Train Loss: 0.114313, Train Acc: 0.810256 | Val Loss: 0.132619, Val Acc: 0.752577\n",
      "Epoch 11646 - Train Loss: 0.114306, Train Acc: 0.810256 | Val Loss: 0.132613, Val Acc: 0.752577\n",
      "Epoch 11647 - Train Loss: 0.114300, Train Acc: 0.810256 | Val Loss: 0.132608, Val Acc: 0.752577\n",
      "Epoch 11648 - Train Loss: 0.114293, Train Acc: 0.810256 | Val Loss: 0.132603, Val Acc: 0.752577\n",
      "Epoch 11649 - Train Loss: 0.114286, Train Acc: 0.810256 | Val Loss: 0.132598, Val Acc: 0.752577\n",
      "Epoch 11650 - Train Loss: 0.114280, Train Acc: 0.810256 | Val Loss: 0.132593, Val Acc: 0.752577\n",
      "Epoch 11651 - Train Loss: 0.114273, Train Acc: 0.810256 | Val Loss: 0.132587, Val Acc: 0.752577\n",
      "Epoch 11652 - Train Loss: 0.114267, Train Acc: 0.810256 | Val Loss: 0.132582, Val Acc: 0.752577\n",
      "Epoch 11653 - Train Loss: 0.114260, Train Acc: 0.810256 | Val Loss: 0.132577, Val Acc: 0.752577\n",
      "Epoch 11654 - Train Loss: 0.114254, Train Acc: 0.810256 | Val Loss: 0.132572, Val Acc: 0.752577\n",
      "Epoch 11655 - Train Loss: 0.114247, Train Acc: 0.810256 | Val Loss: 0.132567, Val Acc: 0.752577\n",
      "Epoch 11656 - Train Loss: 0.114241, Train Acc: 0.810256 | Val Loss: 0.132562, Val Acc: 0.752577\n",
      "Epoch 11657 - Train Loss: 0.114234, Train Acc: 0.810256 | Val Loss: 0.132556, Val Acc: 0.752577\n",
      "Epoch 11658 - Train Loss: 0.114227, Train Acc: 0.810256 | Val Loss: 0.132551, Val Acc: 0.752577\n",
      "Epoch 11659 - Train Loss: 0.114221, Train Acc: 0.810256 | Val Loss: 0.132546, Val Acc: 0.752577\n",
      "Epoch 11660 - Train Loss: 0.114214, Train Acc: 0.810256 | Val Loss: 0.132541, Val Acc: 0.752577\n",
      "Epoch 11661 - Train Loss: 0.114208, Train Acc: 0.810256 | Val Loss: 0.132536, Val Acc: 0.752577\n",
      "Epoch 11662 - Train Loss: 0.114201, Train Acc: 0.810256 | Val Loss: 0.132530, Val Acc: 0.752577\n",
      "Epoch 11663 - Train Loss: 0.114195, Train Acc: 0.810256 | Val Loss: 0.132525, Val Acc: 0.752577\n",
      "Epoch 11664 - Train Loss: 0.114188, Train Acc: 0.810256 | Val Loss: 0.132520, Val Acc: 0.752577\n",
      "Epoch 11665 - Train Loss: 0.114182, Train Acc: 0.810256 | Val Loss: 0.132515, Val Acc: 0.752577\n",
      "Epoch 11666 - Train Loss: 0.114175, Train Acc: 0.810256 | Val Loss: 0.132510, Val Acc: 0.752577\n",
      "Epoch 11667 - Train Loss: 0.114169, Train Acc: 0.810256 | Val Loss: 0.132505, Val Acc: 0.752577\n",
      "Epoch 11668 - Train Loss: 0.114162, Train Acc: 0.810256 | Val Loss: 0.132499, Val Acc: 0.752577\n",
      "Epoch 11669 - Train Loss: 0.114155, Train Acc: 0.810256 | Val Loss: 0.132494, Val Acc: 0.752577\n",
      "Epoch 11670 - Train Loss: 0.114149, Train Acc: 0.810256 | Val Loss: 0.132489, Val Acc: 0.752577\n",
      "Epoch 11671 - Train Loss: 0.114142, Train Acc: 0.810256 | Val Loss: 0.132484, Val Acc: 0.752577\n",
      "Epoch 11672 - Train Loss: 0.114136, Train Acc: 0.810256 | Val Loss: 0.132479, Val Acc: 0.752577\n",
      "Epoch 11673 - Train Loss: 0.114129, Train Acc: 0.810256 | Val Loss: 0.132474, Val Acc: 0.752577\n",
      "Epoch 11674 - Train Loss: 0.114123, Train Acc: 0.810256 | Val Loss: 0.132468, Val Acc: 0.752577\n",
      "Epoch 11675 - Train Loss: 0.114116, Train Acc: 0.810256 | Val Loss: 0.132463, Val Acc: 0.752577\n",
      "Epoch 11676 - Train Loss: 0.114110, Train Acc: 0.810256 | Val Loss: 0.132458, Val Acc: 0.752577\n",
      "Epoch 11677 - Train Loss: 0.114103, Train Acc: 0.810256 | Val Loss: 0.132453, Val Acc: 0.752577\n",
      "Epoch 11678 - Train Loss: 0.114097, Train Acc: 0.810256 | Val Loss: 0.132448, Val Acc: 0.752577\n",
      "Epoch 11679 - Train Loss: 0.114090, Train Acc: 0.810256 | Val Loss: 0.132443, Val Acc: 0.752577\n",
      "Epoch 11680 - Train Loss: 0.114084, Train Acc: 0.810256 | Val Loss: 0.132437, Val Acc: 0.752577\n",
      "Epoch 11681 - Train Loss: 0.114077, Train Acc: 0.810256 | Val Loss: 0.132432, Val Acc: 0.752577\n",
      "Epoch 11682 - Train Loss: 0.114071, Train Acc: 0.810256 | Val Loss: 0.132427, Val Acc: 0.752577\n",
      "Epoch 11683 - Train Loss: 0.114064, Train Acc: 0.810256 | Val Loss: 0.132422, Val Acc: 0.752577\n",
      "Epoch 11684 - Train Loss: 0.114058, Train Acc: 0.810256 | Val Loss: 0.132417, Val Acc: 0.752577\n",
      "Epoch 11685 - Train Loss: 0.114051, Train Acc: 0.810256 | Val Loss: 0.132412, Val Acc: 0.752577\n",
      "Epoch 11686 - Train Loss: 0.114045, Train Acc: 0.810256 | Val Loss: 0.132407, Val Acc: 0.752577\n",
      "Epoch 11687 - Train Loss: 0.114038, Train Acc: 0.810256 | Val Loss: 0.132401, Val Acc: 0.752577\n",
      "Epoch 11688 - Train Loss: 0.114031, Train Acc: 0.810256 | Val Loss: 0.132396, Val Acc: 0.752577\n",
      "Epoch 11689 - Train Loss: 0.114025, Train Acc: 0.810256 | Val Loss: 0.132391, Val Acc: 0.752577\n",
      "Epoch 11690 - Train Loss: 0.114018, Train Acc: 0.810256 | Val Loss: 0.132386, Val Acc: 0.752577\n",
      "Epoch 11691 - Train Loss: 0.114012, Train Acc: 0.810256 | Val Loss: 0.132381, Val Acc: 0.752577\n",
      "Epoch 11692 - Train Loss: 0.114005, Train Acc: 0.810256 | Val Loss: 0.132376, Val Acc: 0.752577\n",
      "Epoch 11693 - Train Loss: 0.113999, Train Acc: 0.810256 | Val Loss: 0.132371, Val Acc: 0.752577\n",
      "Epoch 11694 - Train Loss: 0.113992, Train Acc: 0.810256 | Val Loss: 0.132365, Val Acc: 0.752577\n",
      "Epoch 11695 - Train Loss: 0.113986, Train Acc: 0.810256 | Val Loss: 0.132360, Val Acc: 0.752577\n",
      "Epoch 11696 - Train Loss: 0.113979, Train Acc: 0.810256 | Val Loss: 0.132355, Val Acc: 0.752577\n",
      "Epoch 11697 - Train Loss: 0.113973, Train Acc: 0.810256 | Val Loss: 0.132350, Val Acc: 0.752577\n",
      "Epoch 11698 - Train Loss: 0.113966, Train Acc: 0.810256 | Val Loss: 0.132345, Val Acc: 0.752577\n",
      "Epoch 11699 - Train Loss: 0.113960, Train Acc: 0.810256 | Val Loss: 0.132340, Val Acc: 0.752577\n",
      "Epoch 11700 - Train Loss: 0.113953, Train Acc: 0.810256 | Val Loss: 0.132335, Val Acc: 0.752577\n",
      "Epoch 11701 - Train Loss: 0.113947, Train Acc: 0.810256 | Val Loss: 0.132329, Val Acc: 0.752577\n",
      "Epoch 11702 - Train Loss: 0.113940, Train Acc: 0.810256 | Val Loss: 0.132324, Val Acc: 0.752577\n",
      "Epoch 11703 - Train Loss: 0.113934, Train Acc: 0.810256 | Val Loss: 0.132319, Val Acc: 0.752577\n",
      "Epoch 11704 - Train Loss: 0.113927, Train Acc: 0.810256 | Val Loss: 0.132314, Val Acc: 0.752577\n",
      "Epoch 11705 - Train Loss: 0.113921, Train Acc: 0.810256 | Val Loss: 0.132309, Val Acc: 0.752577\n",
      "Epoch 11706 - Train Loss: 0.113914, Train Acc: 0.810256 | Val Loss: 0.132304, Val Acc: 0.752577\n",
      "Epoch 11707 - Train Loss: 0.113908, Train Acc: 0.810256 | Val Loss: 0.132299, Val Acc: 0.752577\n",
      "Epoch 11708 - Train Loss: 0.113901, Train Acc: 0.810256 | Val Loss: 0.132294, Val Acc: 0.752577\n",
      "Epoch 11709 - Train Loss: 0.113895, Train Acc: 0.810256 | Val Loss: 0.132288, Val Acc: 0.752577\n",
      "Epoch 11710 - Train Loss: 0.113888, Train Acc: 0.810256 | Val Loss: 0.132283, Val Acc: 0.752577\n",
      "Epoch 11711 - Train Loss: 0.113882, Train Acc: 0.810256 | Val Loss: 0.132278, Val Acc: 0.752577\n",
      "Epoch 11712 - Train Loss: 0.113875, Train Acc: 0.810256 | Val Loss: 0.132273, Val Acc: 0.752577\n",
      "Epoch 11713 - Train Loss: 0.113869, Train Acc: 0.810256 | Val Loss: 0.132268, Val Acc: 0.752577\n",
      "Epoch 11714 - Train Loss: 0.113862, Train Acc: 0.810256 | Val Loss: 0.132263, Val Acc: 0.752577\n",
      "Epoch 11715 - Train Loss: 0.113856, Train Acc: 0.810256 | Val Loss: 0.132258, Val Acc: 0.752577\n",
      "Epoch 11716 - Train Loss: 0.113849, Train Acc: 0.810256 | Val Loss: 0.132253, Val Acc: 0.752577\n",
      "Epoch 11717 - Train Loss: 0.113843, Train Acc: 0.810256 | Val Loss: 0.132247, Val Acc: 0.752577\n",
      "Epoch 11718 - Train Loss: 0.113836, Train Acc: 0.810256 | Val Loss: 0.132242, Val Acc: 0.752577\n",
      "Epoch 11719 - Train Loss: 0.113830, Train Acc: 0.810256 | Val Loss: 0.132237, Val Acc: 0.752577\n",
      "Epoch 11720 - Train Loss: 0.113823, Train Acc: 0.810256 | Val Loss: 0.132232, Val Acc: 0.752577\n",
      "Epoch 11721 - Train Loss: 0.113817, Train Acc: 0.810256 | Val Loss: 0.132227, Val Acc: 0.752577\n",
      "Epoch 11722 - Train Loss: 0.113810, Train Acc: 0.810256 | Val Loss: 0.132222, Val Acc: 0.752577\n",
      "Epoch 11723 - Train Loss: 0.113804, Train Acc: 0.810256 | Val Loss: 0.132217, Val Acc: 0.752577\n",
      "Epoch 11724 - Train Loss: 0.113797, Train Acc: 0.810256 | Val Loss: 0.132212, Val Acc: 0.752577\n",
      "Epoch 11725 - Train Loss: 0.113791, Train Acc: 0.810256 | Val Loss: 0.132206, Val Acc: 0.752577\n",
      "Epoch 11726 - Train Loss: 0.113784, Train Acc: 0.810256 | Val Loss: 0.132201, Val Acc: 0.752577\n",
      "Epoch 11727 - Train Loss: 0.113778, Train Acc: 0.810256 | Val Loss: 0.132196, Val Acc: 0.752577\n",
      "Epoch 11728 - Train Loss: 0.113771, Train Acc: 0.810256 | Val Loss: 0.132191, Val Acc: 0.752577\n",
      "Epoch 11729 - Train Loss: 0.113765, Train Acc: 0.810256 | Val Loss: 0.132186, Val Acc: 0.752577\n",
      "Epoch 11730 - Train Loss: 0.113759, Train Acc: 0.810256 | Val Loss: 0.132181, Val Acc: 0.752577\n",
      "Epoch 11731 - Train Loss: 0.113752, Train Acc: 0.810256 | Val Loss: 0.132176, Val Acc: 0.752577\n",
      "Epoch 11732 - Train Loss: 0.113746, Train Acc: 0.810256 | Val Loss: 0.132171, Val Acc: 0.752577\n",
      "Epoch 11733 - Train Loss: 0.113739, Train Acc: 0.810256 | Val Loss: 0.132166, Val Acc: 0.752577\n",
      "Epoch 11734 - Train Loss: 0.113733, Train Acc: 0.810256 | Val Loss: 0.132160, Val Acc: 0.752577\n",
      "Epoch 11735 - Train Loss: 0.113726, Train Acc: 0.810256 | Val Loss: 0.132155, Val Acc: 0.752577\n",
      "Epoch 11736 - Train Loss: 0.113720, Train Acc: 0.810256 | Val Loss: 0.132150, Val Acc: 0.752577\n",
      "Epoch 11737 - Train Loss: 0.113713, Train Acc: 0.810256 | Val Loss: 0.132145, Val Acc: 0.752577\n",
      "Epoch 11738 - Train Loss: 0.113707, Train Acc: 0.810256 | Val Loss: 0.132140, Val Acc: 0.752577\n",
      "Epoch 11739 - Train Loss: 0.113700, Train Acc: 0.808974 | Val Loss: 0.132135, Val Acc: 0.752577\n",
      "Epoch 11740 - Train Loss: 0.113694, Train Acc: 0.808974 | Val Loss: 0.132130, Val Acc: 0.752577\n",
      "Epoch 11741 - Train Loss: 0.113687, Train Acc: 0.808974 | Val Loss: 0.132125, Val Acc: 0.752577\n",
      "Epoch 11742 - Train Loss: 0.113681, Train Acc: 0.808974 | Val Loss: 0.132120, Val Acc: 0.752577\n",
      "Epoch 11743 - Train Loss: 0.113674, Train Acc: 0.808974 | Val Loss: 0.132114, Val Acc: 0.752577\n",
      "Epoch 11744 - Train Loss: 0.113668, Train Acc: 0.808974 | Val Loss: 0.132109, Val Acc: 0.752577\n",
      "Epoch 11745 - Train Loss: 0.113661, Train Acc: 0.808974 | Val Loss: 0.132104, Val Acc: 0.752577\n",
      "Epoch 11746 - Train Loss: 0.113655, Train Acc: 0.808974 | Val Loss: 0.132099, Val Acc: 0.752577\n",
      "Epoch 11747 - Train Loss: 0.113649, Train Acc: 0.808974 | Val Loss: 0.132094, Val Acc: 0.752577\n",
      "Epoch 11748 - Train Loss: 0.113642, Train Acc: 0.808974 | Val Loss: 0.132089, Val Acc: 0.752577\n",
      "Epoch 11749 - Train Loss: 0.113636, Train Acc: 0.808974 | Val Loss: 0.132084, Val Acc: 0.752577\n",
      "Epoch 11750 - Train Loss: 0.113629, Train Acc: 0.808974 | Val Loss: 0.132079, Val Acc: 0.752577\n",
      "Epoch 11751 - Train Loss: 0.113623, Train Acc: 0.808974 | Val Loss: 0.132074, Val Acc: 0.752577\n",
      "Epoch 11752 - Train Loss: 0.113616, Train Acc: 0.808974 | Val Loss: 0.132069, Val Acc: 0.752577\n",
      "Epoch 11753 - Train Loss: 0.113610, Train Acc: 0.808974 | Val Loss: 0.132064, Val Acc: 0.752577\n",
      "Epoch 11754 - Train Loss: 0.113603, Train Acc: 0.808974 | Val Loss: 0.132058, Val Acc: 0.752577\n",
      "Epoch 11755 - Train Loss: 0.113597, Train Acc: 0.808974 | Val Loss: 0.132053, Val Acc: 0.752577\n",
      "Epoch 11756 - Train Loss: 0.113590, Train Acc: 0.808974 | Val Loss: 0.132048, Val Acc: 0.752577\n",
      "Epoch 11757 - Train Loss: 0.113584, Train Acc: 0.808974 | Val Loss: 0.132043, Val Acc: 0.752577\n",
      "Epoch 11758 - Train Loss: 0.113577, Train Acc: 0.808974 | Val Loss: 0.132038, Val Acc: 0.752577\n",
      "Epoch 11759 - Train Loss: 0.113571, Train Acc: 0.808974 | Val Loss: 0.132033, Val Acc: 0.752577\n",
      "Epoch 11760 - Train Loss: 0.113565, Train Acc: 0.808974 | Val Loss: 0.132028, Val Acc: 0.752577\n",
      "Epoch 11761 - Train Loss: 0.113558, Train Acc: 0.808974 | Val Loss: 0.132023, Val Acc: 0.752577\n",
      "Epoch 11762 - Train Loss: 0.113552, Train Acc: 0.808974 | Val Loss: 0.132018, Val Acc: 0.752577\n",
      "Epoch 11763 - Train Loss: 0.113545, Train Acc: 0.808974 | Val Loss: 0.132013, Val Acc: 0.752577\n",
      "Epoch 11764 - Train Loss: 0.113539, Train Acc: 0.808974 | Val Loss: 0.132008, Val Acc: 0.752577\n",
      "Epoch 11765 - Train Loss: 0.113532, Train Acc: 0.808974 | Val Loss: 0.132003, Val Acc: 0.752577\n",
      "Epoch 11766 - Train Loss: 0.113526, Train Acc: 0.808974 | Val Loss: 0.131997, Val Acc: 0.752577\n",
      "Epoch 11767 - Train Loss: 0.113519, Train Acc: 0.808974 | Val Loss: 0.131992, Val Acc: 0.752577\n",
      "Epoch 11768 - Train Loss: 0.113513, Train Acc: 0.808974 | Val Loss: 0.131987, Val Acc: 0.742268\n",
      "Epoch 11769 - Train Loss: 0.113507, Train Acc: 0.808974 | Val Loss: 0.131982, Val Acc: 0.742268\n",
      "Epoch 11770 - Train Loss: 0.113500, Train Acc: 0.808974 | Val Loss: 0.131977, Val Acc: 0.742268\n",
      "Epoch 11771 - Train Loss: 0.113494, Train Acc: 0.808974 | Val Loss: 0.131972, Val Acc: 0.742268\n",
      "Epoch 11772 - Train Loss: 0.113487, Train Acc: 0.808974 | Val Loss: 0.131967, Val Acc: 0.742268\n",
      "Epoch 11773 - Train Loss: 0.113481, Train Acc: 0.808974 | Val Loss: 0.131962, Val Acc: 0.742268\n",
      "Epoch 11774 - Train Loss: 0.113474, Train Acc: 0.808974 | Val Loss: 0.131957, Val Acc: 0.742268\n",
      "Epoch 11775 - Train Loss: 0.113468, Train Acc: 0.808974 | Val Loss: 0.131952, Val Acc: 0.742268\n",
      "Epoch 11776 - Train Loss: 0.113461, Train Acc: 0.808974 | Val Loss: 0.131947, Val Acc: 0.742268\n",
      "Epoch 11777 - Train Loss: 0.113455, Train Acc: 0.808974 | Val Loss: 0.131942, Val Acc: 0.742268\n",
      "Epoch 11778 - Train Loss: 0.113449, Train Acc: 0.808974 | Val Loss: 0.131937, Val Acc: 0.742268\n",
      "Epoch 11779 - Train Loss: 0.113442, Train Acc: 0.808974 | Val Loss: 0.131931, Val Acc: 0.742268\n",
      "Epoch 11780 - Train Loss: 0.113436, Train Acc: 0.808974 | Val Loss: 0.131926, Val Acc: 0.742268\n",
      "Epoch 11781 - Train Loss: 0.113429, Train Acc: 0.808974 | Val Loss: 0.131921, Val Acc: 0.742268\n",
      "Epoch 11782 - Train Loss: 0.113423, Train Acc: 0.808974 | Val Loss: 0.131916, Val Acc: 0.742268\n",
      "Epoch 11783 - Train Loss: 0.113416, Train Acc: 0.808974 | Val Loss: 0.131911, Val Acc: 0.742268\n",
      "Epoch 11784 - Train Loss: 0.113410, Train Acc: 0.808974 | Val Loss: 0.131906, Val Acc: 0.742268\n",
      "Epoch 11785 - Train Loss: 0.113404, Train Acc: 0.808974 | Val Loss: 0.131901, Val Acc: 0.742268\n",
      "Epoch 11786 - Train Loss: 0.113397, Train Acc: 0.808974 | Val Loss: 0.131896, Val Acc: 0.742268\n",
      "Epoch 11787 - Train Loss: 0.113391, Train Acc: 0.808974 | Val Loss: 0.131891, Val Acc: 0.742268\n",
      "Epoch 11788 - Train Loss: 0.113384, Train Acc: 0.808974 | Val Loss: 0.131886, Val Acc: 0.742268\n",
      "Epoch 11789 - Train Loss: 0.113378, Train Acc: 0.808974 | Val Loss: 0.131881, Val Acc: 0.742268\n",
      "Epoch 11790 - Train Loss: 0.113371, Train Acc: 0.808974 | Val Loss: 0.131876, Val Acc: 0.742268\n",
      "Epoch 11791 - Train Loss: 0.113365, Train Acc: 0.808974 | Val Loss: 0.131871, Val Acc: 0.742268\n",
      "Epoch 11792 - Train Loss: 0.113359, Train Acc: 0.808974 | Val Loss: 0.131866, Val Acc: 0.742268\n",
      "Epoch 11793 - Train Loss: 0.113352, Train Acc: 0.808974 | Val Loss: 0.131861, Val Acc: 0.742268\n",
      "Epoch 11794 - Train Loss: 0.113346, Train Acc: 0.808974 | Val Loss: 0.131856, Val Acc: 0.742268\n",
      "Epoch 11795 - Train Loss: 0.113339, Train Acc: 0.808974 | Val Loss: 0.131850, Val Acc: 0.742268\n",
      "Epoch 11796 - Train Loss: 0.113333, Train Acc: 0.808974 | Val Loss: 0.131845, Val Acc: 0.742268\n",
      "Epoch 11797 - Train Loss: 0.113326, Train Acc: 0.808974 | Val Loss: 0.131840, Val Acc: 0.742268\n",
      "Epoch 11798 - Train Loss: 0.113320, Train Acc: 0.808974 | Val Loss: 0.131835, Val Acc: 0.742268\n",
      "Epoch 11799 - Train Loss: 0.113314, Train Acc: 0.808974 | Val Loss: 0.131830, Val Acc: 0.742268\n",
      "Epoch 11800 - Train Loss: 0.113307, Train Acc: 0.808974 | Val Loss: 0.131825, Val Acc: 0.742268\n",
      "Epoch 11801 - Train Loss: 0.113301, Train Acc: 0.808974 | Val Loss: 0.131820, Val Acc: 0.742268\n",
      "Epoch 11802 - Train Loss: 0.113294, Train Acc: 0.808974 | Val Loss: 0.131815, Val Acc: 0.742268\n",
      "Epoch 11803 - Train Loss: 0.113288, Train Acc: 0.808974 | Val Loss: 0.131810, Val Acc: 0.742268\n",
      "Epoch 11804 - Train Loss: 0.113282, Train Acc: 0.808974 | Val Loss: 0.131805, Val Acc: 0.742268\n",
      "Epoch 11805 - Train Loss: 0.113275, Train Acc: 0.808974 | Val Loss: 0.131800, Val Acc: 0.742268\n",
      "Epoch 11806 - Train Loss: 0.113269, Train Acc: 0.808974 | Val Loss: 0.131795, Val Acc: 0.742268\n",
      "Epoch 11807 - Train Loss: 0.113262, Train Acc: 0.808974 | Val Loss: 0.131790, Val Acc: 0.742268\n",
      "Epoch 11808 - Train Loss: 0.113256, Train Acc: 0.808974 | Val Loss: 0.131785, Val Acc: 0.742268\n",
      "Epoch 11809 - Train Loss: 0.113250, Train Acc: 0.808974 | Val Loss: 0.131780, Val Acc: 0.742268\n",
      "Epoch 11810 - Train Loss: 0.113243, Train Acc: 0.808974 | Val Loss: 0.131775, Val Acc: 0.742268\n",
      "Epoch 11811 - Train Loss: 0.113237, Train Acc: 0.808974 | Val Loss: 0.131770, Val Acc: 0.742268\n",
      "Epoch 11812 - Train Loss: 0.113230, Train Acc: 0.808974 | Val Loss: 0.131765, Val Acc: 0.742268\n",
      "Epoch 11813 - Train Loss: 0.113224, Train Acc: 0.808974 | Val Loss: 0.131760, Val Acc: 0.742268\n",
      "Epoch 11814 - Train Loss: 0.113217, Train Acc: 0.808974 | Val Loss: 0.131755, Val Acc: 0.742268\n",
      "Epoch 11815 - Train Loss: 0.113211, Train Acc: 0.808974 | Val Loss: 0.131750, Val Acc: 0.742268\n",
      "Epoch 11816 - Train Loss: 0.113205, Train Acc: 0.808974 | Val Loss: 0.131745, Val Acc: 0.742268\n",
      "Epoch 11817 - Train Loss: 0.113198, Train Acc: 0.808974 | Val Loss: 0.131740, Val Acc: 0.742268\n",
      "Epoch 11818 - Train Loss: 0.113192, Train Acc: 0.808974 | Val Loss: 0.131735, Val Acc: 0.742268\n",
      "Epoch 11819 - Train Loss: 0.113185, Train Acc: 0.808974 | Val Loss: 0.131729, Val Acc: 0.742268\n",
      "Epoch 11820 - Train Loss: 0.113179, Train Acc: 0.808974 | Val Loss: 0.131724, Val Acc: 0.742268\n",
      "Epoch 11821 - Train Loss: 0.113173, Train Acc: 0.808974 | Val Loss: 0.131719, Val Acc: 0.742268\n",
      "Epoch 11822 - Train Loss: 0.113166, Train Acc: 0.808974 | Val Loss: 0.131714, Val Acc: 0.742268\n",
      "Epoch 11823 - Train Loss: 0.113160, Train Acc: 0.808974 | Val Loss: 0.131709, Val Acc: 0.742268\n",
      "Epoch 11824 - Train Loss: 0.113154, Train Acc: 0.808974 | Val Loss: 0.131704, Val Acc: 0.742268\n",
      "Epoch 11825 - Train Loss: 0.113147, Train Acc: 0.808974 | Val Loss: 0.131699, Val Acc: 0.742268\n",
      "Epoch 11826 - Train Loss: 0.113141, Train Acc: 0.808974 | Val Loss: 0.131694, Val Acc: 0.742268\n",
      "Epoch 11827 - Train Loss: 0.113134, Train Acc: 0.808974 | Val Loss: 0.131689, Val Acc: 0.742268\n",
      "Epoch 11828 - Train Loss: 0.113128, Train Acc: 0.808974 | Val Loss: 0.131684, Val Acc: 0.742268\n",
      "Epoch 11829 - Train Loss: 0.113122, Train Acc: 0.808974 | Val Loss: 0.131679, Val Acc: 0.742268\n",
      "Epoch 11830 - Train Loss: 0.113115, Train Acc: 0.808974 | Val Loss: 0.131674, Val Acc: 0.742268\n",
      "Epoch 11831 - Train Loss: 0.113109, Train Acc: 0.808974 | Val Loss: 0.131669, Val Acc: 0.742268\n",
      "Epoch 11832 - Train Loss: 0.113102, Train Acc: 0.808974 | Val Loss: 0.131664, Val Acc: 0.742268\n",
      "Epoch 11833 - Train Loss: 0.113096, Train Acc: 0.808974 | Val Loss: 0.131659, Val Acc: 0.742268\n",
      "Epoch 11834 - Train Loss: 0.113090, Train Acc: 0.808974 | Val Loss: 0.131654, Val Acc: 0.742268\n",
      "Epoch 11835 - Train Loss: 0.113083, Train Acc: 0.808974 | Val Loss: 0.131649, Val Acc: 0.742268\n",
      "Epoch 11836 - Train Loss: 0.113077, Train Acc: 0.808974 | Val Loss: 0.131644, Val Acc: 0.742268\n",
      "Epoch 11837 - Train Loss: 0.113070, Train Acc: 0.808974 | Val Loss: 0.131639, Val Acc: 0.742268\n",
      "Epoch 11838 - Train Loss: 0.113064, Train Acc: 0.808974 | Val Loss: 0.131634, Val Acc: 0.742268\n",
      "Epoch 11839 - Train Loss: 0.113058, Train Acc: 0.808974 | Val Loss: 0.131629, Val Acc: 0.742268\n",
      "Epoch 11840 - Train Loss: 0.113051, Train Acc: 0.808974 | Val Loss: 0.131624, Val Acc: 0.742268\n",
      "Epoch 11841 - Train Loss: 0.113045, Train Acc: 0.808974 | Val Loss: 0.131619, Val Acc: 0.742268\n",
      "Epoch 11842 - Train Loss: 0.113039, Train Acc: 0.808974 | Val Loss: 0.131614, Val Acc: 0.742268\n",
      "Epoch 11843 - Train Loss: 0.113032, Train Acc: 0.808974 | Val Loss: 0.131609, Val Acc: 0.742268\n",
      "Epoch 11844 - Train Loss: 0.113026, Train Acc: 0.808974 | Val Loss: 0.131604, Val Acc: 0.742268\n",
      "Epoch 11845 - Train Loss: 0.113019, Train Acc: 0.808974 | Val Loss: 0.131599, Val Acc: 0.742268\n",
      "Epoch 11846 - Train Loss: 0.113013, Train Acc: 0.808974 | Val Loss: 0.131594, Val Acc: 0.742268\n",
      "Epoch 11847 - Train Loss: 0.113007, Train Acc: 0.808974 | Val Loss: 0.131589, Val Acc: 0.742268\n",
      "Epoch 11848 - Train Loss: 0.113000, Train Acc: 0.808974 | Val Loss: 0.131584, Val Acc: 0.742268\n",
      "Epoch 11849 - Train Loss: 0.112994, Train Acc: 0.808974 | Val Loss: 0.131579, Val Acc: 0.742268\n",
      "Epoch 11850 - Train Loss: 0.112988, Train Acc: 0.808974 | Val Loss: 0.131574, Val Acc: 0.742268\n",
      "Epoch 11851 - Train Loss: 0.112981, Train Acc: 0.808974 | Val Loss: 0.131569, Val Acc: 0.742268\n",
      "Epoch 11852 - Train Loss: 0.112975, Train Acc: 0.808974 | Val Loss: 0.131564, Val Acc: 0.742268\n",
      "Epoch 11853 - Train Loss: 0.112968, Train Acc: 0.808974 | Val Loss: 0.131559, Val Acc: 0.742268\n",
      "Epoch 11854 - Train Loss: 0.112962, Train Acc: 0.808974 | Val Loss: 0.131554, Val Acc: 0.742268\n",
      "Epoch 11855 - Train Loss: 0.112956, Train Acc: 0.808974 | Val Loss: 0.131549, Val Acc: 0.742268\n",
      "Epoch 11856 - Train Loss: 0.112949, Train Acc: 0.808974 | Val Loss: 0.131544, Val Acc: 0.742268\n",
      "Epoch 11857 - Train Loss: 0.112943, Train Acc: 0.808974 | Val Loss: 0.131539, Val Acc: 0.742268\n",
      "Epoch 11858 - Train Loss: 0.112937, Train Acc: 0.808974 | Val Loss: 0.131534, Val Acc: 0.742268\n",
      "Epoch 11859 - Train Loss: 0.112930, Train Acc: 0.808974 | Val Loss: 0.131529, Val Acc: 0.752577\n",
      "Epoch 11860 - Train Loss: 0.112924, Train Acc: 0.808974 | Val Loss: 0.131524, Val Acc: 0.752577\n",
      "Epoch 11861 - Train Loss: 0.112918, Train Acc: 0.808974 | Val Loss: 0.131519, Val Acc: 0.752577\n",
      "Epoch 11862 - Train Loss: 0.112911, Train Acc: 0.808974 | Val Loss: 0.131514, Val Acc: 0.752577\n",
      "Epoch 11863 - Train Loss: 0.112905, Train Acc: 0.808974 | Val Loss: 0.131509, Val Acc: 0.752577\n",
      "Epoch 11864 - Train Loss: 0.112899, Train Acc: 0.808974 | Val Loss: 0.131504, Val Acc: 0.752577\n",
      "Epoch 11865 - Train Loss: 0.112892, Train Acc: 0.808974 | Val Loss: 0.131499, Val Acc: 0.752577\n",
      "Epoch 11866 - Train Loss: 0.112886, Train Acc: 0.808974 | Val Loss: 0.131494, Val Acc: 0.752577\n",
      "Epoch 11867 - Train Loss: 0.112879, Train Acc: 0.808974 | Val Loss: 0.131489, Val Acc: 0.752577\n",
      "Epoch 11868 - Train Loss: 0.112873, Train Acc: 0.808974 | Val Loss: 0.131484, Val Acc: 0.752577\n",
      "Epoch 11869 - Train Loss: 0.112867, Train Acc: 0.808974 | Val Loss: 0.131479, Val Acc: 0.752577\n",
      "Epoch 11870 - Train Loss: 0.112860, Train Acc: 0.808974 | Val Loss: 0.131474, Val Acc: 0.752577\n",
      "Epoch 11871 - Train Loss: 0.112854, Train Acc: 0.808974 | Val Loss: 0.131469, Val Acc: 0.752577\n",
      "Epoch 11872 - Train Loss: 0.112848, Train Acc: 0.808974 | Val Loss: 0.131464, Val Acc: 0.752577\n",
      "Epoch 11873 - Train Loss: 0.112841, Train Acc: 0.808974 | Val Loss: 0.131459, Val Acc: 0.752577\n",
      "Epoch 11874 - Train Loss: 0.112835, Train Acc: 0.808974 | Val Loss: 0.131454, Val Acc: 0.752577\n",
      "Epoch 11875 - Train Loss: 0.112829, Train Acc: 0.808974 | Val Loss: 0.131449, Val Acc: 0.752577\n",
      "Epoch 11876 - Train Loss: 0.112822, Train Acc: 0.808974 | Val Loss: 0.131444, Val Acc: 0.752577\n",
      "Epoch 11877 - Train Loss: 0.112816, Train Acc: 0.808974 | Val Loss: 0.131439, Val Acc: 0.752577\n",
      "Epoch 11878 - Train Loss: 0.112810, Train Acc: 0.808974 | Val Loss: 0.131434, Val Acc: 0.752577\n",
      "Epoch 11879 - Train Loss: 0.112803, Train Acc: 0.808974 | Val Loss: 0.131429, Val Acc: 0.752577\n",
      "Epoch 11880 - Train Loss: 0.112797, Train Acc: 0.808974 | Val Loss: 0.131424, Val Acc: 0.752577\n",
      "Epoch 11881 - Train Loss: 0.112791, Train Acc: 0.808974 | Val Loss: 0.131419, Val Acc: 0.752577\n",
      "Epoch 11882 - Train Loss: 0.112784, Train Acc: 0.808974 | Val Loss: 0.131414, Val Acc: 0.752577\n",
      "Epoch 11883 - Train Loss: 0.112778, Train Acc: 0.810256 | Val Loss: 0.131409, Val Acc: 0.752577\n",
      "Epoch 11884 - Train Loss: 0.112772, Train Acc: 0.810256 | Val Loss: 0.131404, Val Acc: 0.752577\n",
      "Epoch 11885 - Train Loss: 0.112765, Train Acc: 0.810256 | Val Loss: 0.131399, Val Acc: 0.752577\n",
      "Epoch 11886 - Train Loss: 0.112759, Train Acc: 0.810256 | Val Loss: 0.131394, Val Acc: 0.752577\n",
      "Epoch 11887 - Train Loss: 0.112753, Train Acc: 0.810256 | Val Loss: 0.131389, Val Acc: 0.752577\n",
      "Epoch 11888 - Train Loss: 0.112746, Train Acc: 0.810256 | Val Loss: 0.131384, Val Acc: 0.752577\n",
      "Epoch 11889 - Train Loss: 0.112740, Train Acc: 0.810256 | Val Loss: 0.131379, Val Acc: 0.752577\n",
      "Epoch 11890 - Train Loss: 0.112734, Train Acc: 0.810256 | Val Loss: 0.131374, Val Acc: 0.752577\n",
      "Epoch 11891 - Train Loss: 0.112727, Train Acc: 0.810256 | Val Loss: 0.131369, Val Acc: 0.752577\n",
      "Epoch 11892 - Train Loss: 0.112721, Train Acc: 0.810256 | Val Loss: 0.131364, Val Acc: 0.752577\n",
      "Epoch 11893 - Train Loss: 0.112715, Train Acc: 0.810256 | Val Loss: 0.131359, Val Acc: 0.752577\n",
      "Epoch 11894 - Train Loss: 0.112708, Train Acc: 0.810256 | Val Loss: 0.131354, Val Acc: 0.752577\n",
      "Epoch 11895 - Train Loss: 0.112702, Train Acc: 0.810256 | Val Loss: 0.131349, Val Acc: 0.752577\n",
      "Epoch 11896 - Train Loss: 0.112696, Train Acc: 0.810256 | Val Loss: 0.131344, Val Acc: 0.752577\n",
      "Epoch 11897 - Train Loss: 0.112689, Train Acc: 0.810256 | Val Loss: 0.131339, Val Acc: 0.752577\n",
      "Epoch 11898 - Train Loss: 0.112683, Train Acc: 0.810256 | Val Loss: 0.131334, Val Acc: 0.752577\n",
      "Epoch 11899 - Train Loss: 0.112677, Train Acc: 0.810256 | Val Loss: 0.131329, Val Acc: 0.752577\n",
      "Epoch 11900 - Train Loss: 0.112670, Train Acc: 0.810256 | Val Loss: 0.131324, Val Acc: 0.752577\n",
      "Epoch 11901 - Train Loss: 0.112664, Train Acc: 0.810256 | Val Loss: 0.131319, Val Acc: 0.752577\n",
      "Epoch 11902 - Train Loss: 0.112658, Train Acc: 0.810256 | Val Loss: 0.131314, Val Acc: 0.752577\n",
      "Epoch 11903 - Train Loss: 0.112651, Train Acc: 0.810256 | Val Loss: 0.131309, Val Acc: 0.752577\n",
      "Epoch 11904 - Train Loss: 0.112645, Train Acc: 0.810256 | Val Loss: 0.131304, Val Acc: 0.752577\n",
      "Epoch 11905 - Train Loss: 0.112639, Train Acc: 0.810256 | Val Loss: 0.131299, Val Acc: 0.752577\n",
      "Epoch 11906 - Train Loss: 0.112632, Train Acc: 0.810256 | Val Loss: 0.131294, Val Acc: 0.752577\n",
      "Epoch 11907 - Train Loss: 0.112626, Train Acc: 0.810256 | Val Loss: 0.131289, Val Acc: 0.752577\n",
      "Epoch 11908 - Train Loss: 0.112620, Train Acc: 0.810256 | Val Loss: 0.131284, Val Acc: 0.752577\n",
      "Epoch 11909 - Train Loss: 0.112613, Train Acc: 0.810256 | Val Loss: 0.131280, Val Acc: 0.752577\n",
      "Epoch 11910 - Train Loss: 0.112607, Train Acc: 0.810256 | Val Loss: 0.131275, Val Acc: 0.752577\n",
      "Epoch 11911 - Train Loss: 0.112601, Train Acc: 0.810256 | Val Loss: 0.131270, Val Acc: 0.752577\n",
      "Epoch 11912 - Train Loss: 0.112594, Train Acc: 0.810256 | Val Loss: 0.131265, Val Acc: 0.752577\n",
      "Epoch 11913 - Train Loss: 0.112588, Train Acc: 0.810256 | Val Loss: 0.131260, Val Acc: 0.752577\n",
      "Epoch 11914 - Train Loss: 0.112582, Train Acc: 0.810256 | Val Loss: 0.131255, Val Acc: 0.752577\n",
      "Epoch 11915 - Train Loss: 0.112575, Train Acc: 0.810256 | Val Loss: 0.131250, Val Acc: 0.752577\n",
      "Epoch 11916 - Train Loss: 0.112569, Train Acc: 0.810256 | Val Loss: 0.131245, Val Acc: 0.752577\n",
      "Epoch 11917 - Train Loss: 0.112563, Train Acc: 0.810256 | Val Loss: 0.131240, Val Acc: 0.752577\n",
      "Epoch 11918 - Train Loss: 0.112557, Train Acc: 0.810256 | Val Loss: 0.131235, Val Acc: 0.752577\n",
      "Epoch 11919 - Train Loss: 0.112550, Train Acc: 0.810256 | Val Loss: 0.131230, Val Acc: 0.752577\n",
      "Epoch 11920 - Train Loss: 0.112544, Train Acc: 0.810256 | Val Loss: 0.131225, Val Acc: 0.752577\n",
      "Epoch 11921 - Train Loss: 0.112538, Train Acc: 0.810256 | Val Loss: 0.131220, Val Acc: 0.752577\n",
      "Epoch 11922 - Train Loss: 0.112531, Train Acc: 0.810256 | Val Loss: 0.131215, Val Acc: 0.752577\n",
      "Epoch 11923 - Train Loss: 0.112525, Train Acc: 0.810256 | Val Loss: 0.131210, Val Acc: 0.752577\n",
      "Epoch 11924 - Train Loss: 0.112519, Train Acc: 0.810256 | Val Loss: 0.131205, Val Acc: 0.752577\n",
      "Epoch 11925 - Train Loss: 0.112512, Train Acc: 0.810256 | Val Loss: 0.131200, Val Acc: 0.752577\n",
      "Epoch 11926 - Train Loss: 0.112506, Train Acc: 0.811538 | Val Loss: 0.131195, Val Acc: 0.752577\n",
      "Epoch 11927 - Train Loss: 0.112500, Train Acc: 0.811538 | Val Loss: 0.131190, Val Acc: 0.752577\n",
      "Epoch 11928 - Train Loss: 0.112493, Train Acc: 0.811538 | Val Loss: 0.131185, Val Acc: 0.752577\n",
      "Epoch 11929 - Train Loss: 0.112487, Train Acc: 0.811538 | Val Loss: 0.131181, Val Acc: 0.752577\n",
      "Epoch 11930 - Train Loss: 0.112481, Train Acc: 0.811538 | Val Loss: 0.131176, Val Acc: 0.752577\n",
      "Epoch 11931 - Train Loss: 0.112475, Train Acc: 0.811538 | Val Loss: 0.131171, Val Acc: 0.752577\n",
      "Epoch 11932 - Train Loss: 0.112468, Train Acc: 0.811538 | Val Loss: 0.131166, Val Acc: 0.752577\n",
      "Epoch 11933 - Train Loss: 0.112462, Train Acc: 0.811538 | Val Loss: 0.131161, Val Acc: 0.752577\n",
      "Epoch 11934 - Train Loss: 0.112456, Train Acc: 0.811538 | Val Loss: 0.131156, Val Acc: 0.752577\n",
      "Epoch 11935 - Train Loss: 0.112449, Train Acc: 0.810256 | Val Loss: 0.131151, Val Acc: 0.752577\n",
      "Epoch 11936 - Train Loss: 0.112443, Train Acc: 0.810256 | Val Loss: 0.131146, Val Acc: 0.752577\n",
      "Epoch 11937 - Train Loss: 0.112437, Train Acc: 0.810256 | Val Loss: 0.131141, Val Acc: 0.752577\n",
      "Epoch 11938 - Train Loss: 0.112431, Train Acc: 0.810256 | Val Loss: 0.131136, Val Acc: 0.752577\n",
      "Epoch 11939 - Train Loss: 0.112424, Train Acc: 0.810256 | Val Loss: 0.131131, Val Acc: 0.752577\n",
      "Epoch 11940 - Train Loss: 0.112418, Train Acc: 0.810256 | Val Loss: 0.131126, Val Acc: 0.752577\n",
      "Epoch 11941 - Train Loss: 0.112412, Train Acc: 0.810256 | Val Loss: 0.131121, Val Acc: 0.752577\n",
      "Epoch 11942 - Train Loss: 0.112405, Train Acc: 0.810256 | Val Loss: 0.131116, Val Acc: 0.752577\n",
      "Epoch 11943 - Train Loss: 0.112399, Train Acc: 0.810256 | Val Loss: 0.131111, Val Acc: 0.752577\n",
      "Epoch 11944 - Train Loss: 0.112393, Train Acc: 0.810256 | Val Loss: 0.131107, Val Acc: 0.752577\n",
      "Epoch 11945 - Train Loss: 0.112387, Train Acc: 0.810256 | Val Loss: 0.131102, Val Acc: 0.752577\n",
      "Epoch 11946 - Train Loss: 0.112380, Train Acc: 0.810256 | Val Loss: 0.131097, Val Acc: 0.752577\n",
      "Epoch 11947 - Train Loss: 0.112374, Train Acc: 0.810256 | Val Loss: 0.131092, Val Acc: 0.752577\n",
      "Epoch 11948 - Train Loss: 0.112368, Train Acc: 0.810256 | Val Loss: 0.131087, Val Acc: 0.752577\n",
      "Epoch 11949 - Train Loss: 0.112361, Train Acc: 0.810256 | Val Loss: 0.131082, Val Acc: 0.752577\n",
      "Epoch 11950 - Train Loss: 0.112355, Train Acc: 0.810256 | Val Loss: 0.131077, Val Acc: 0.752577\n",
      "Epoch 11951 - Train Loss: 0.112349, Train Acc: 0.810256 | Val Loss: 0.131072, Val Acc: 0.752577\n",
      "Epoch 11952 - Train Loss: 0.112343, Train Acc: 0.810256 | Val Loss: 0.131067, Val Acc: 0.752577\n",
      "Epoch 11953 - Train Loss: 0.112336, Train Acc: 0.810256 | Val Loss: 0.131062, Val Acc: 0.752577\n",
      "Epoch 11954 - Train Loss: 0.112330, Train Acc: 0.810256 | Val Loss: 0.131057, Val Acc: 0.752577\n",
      "Epoch 11955 - Train Loss: 0.112324, Train Acc: 0.810256 | Val Loss: 0.131052, Val Acc: 0.752577\n",
      "Epoch 11956 - Train Loss: 0.112317, Train Acc: 0.810256 | Val Loss: 0.131047, Val Acc: 0.752577\n",
      "Epoch 11957 - Train Loss: 0.112311, Train Acc: 0.810256 | Val Loss: 0.131043, Val Acc: 0.752577\n",
      "Epoch 11958 - Train Loss: 0.112305, Train Acc: 0.810256 | Val Loss: 0.131038, Val Acc: 0.752577\n",
      "Epoch 11959 - Train Loss: 0.112299, Train Acc: 0.810256 | Val Loss: 0.131033, Val Acc: 0.752577\n",
      "Epoch 11960 - Train Loss: 0.112292, Train Acc: 0.810256 | Val Loss: 0.131028, Val Acc: 0.752577\n",
      "Epoch 11961 - Train Loss: 0.112286, Train Acc: 0.810256 | Val Loss: 0.131023, Val Acc: 0.752577\n",
      "Epoch 11962 - Train Loss: 0.112280, Train Acc: 0.810256 | Val Loss: 0.131018, Val Acc: 0.752577\n",
      "Epoch 11963 - Train Loss: 0.112274, Train Acc: 0.810256 | Val Loss: 0.131013, Val Acc: 0.752577\n",
      "Epoch 11964 - Train Loss: 0.112267, Train Acc: 0.810256 | Val Loss: 0.131008, Val Acc: 0.752577\n",
      "Epoch 11965 - Train Loss: 0.112261, Train Acc: 0.810256 | Val Loss: 0.131003, Val Acc: 0.752577\n",
      "Epoch 11966 - Train Loss: 0.112255, Train Acc: 0.810256 | Val Loss: 0.130998, Val Acc: 0.752577\n",
      "Epoch 11967 - Train Loss: 0.112249, Train Acc: 0.810256 | Val Loss: 0.130993, Val Acc: 0.752577\n",
      "Epoch 11968 - Train Loss: 0.112242, Train Acc: 0.810256 | Val Loss: 0.130989, Val Acc: 0.752577\n",
      "Epoch 11969 - Train Loss: 0.112236, Train Acc: 0.810256 | Val Loss: 0.130984, Val Acc: 0.752577\n",
      "Epoch 11970 - Train Loss: 0.112230, Train Acc: 0.810256 | Val Loss: 0.130979, Val Acc: 0.752577\n",
      "Epoch 11971 - Train Loss: 0.112223, Train Acc: 0.810256 | Val Loss: 0.130974, Val Acc: 0.752577\n",
      "Epoch 11972 - Train Loss: 0.112217, Train Acc: 0.810256 | Val Loss: 0.130969, Val Acc: 0.752577\n",
      "Epoch 11973 - Train Loss: 0.112211, Train Acc: 0.810256 | Val Loss: 0.130964, Val Acc: 0.752577\n",
      "Epoch 11974 - Train Loss: 0.112205, Train Acc: 0.810256 | Val Loss: 0.130959, Val Acc: 0.752577\n",
      "Epoch 11975 - Train Loss: 0.112198, Train Acc: 0.810256 | Val Loss: 0.130954, Val Acc: 0.752577\n",
      "Epoch 11976 - Train Loss: 0.112192, Train Acc: 0.810256 | Val Loss: 0.130949, Val Acc: 0.752577\n",
      "Epoch 11977 - Train Loss: 0.112186, Train Acc: 0.810256 | Val Loss: 0.130944, Val Acc: 0.752577\n",
      "Epoch 11978 - Train Loss: 0.112180, Train Acc: 0.810256 | Val Loss: 0.130940, Val Acc: 0.752577\n",
      "Epoch 11979 - Train Loss: 0.112173, Train Acc: 0.810256 | Val Loss: 0.130935, Val Acc: 0.752577\n",
      "Epoch 11980 - Train Loss: 0.112167, Train Acc: 0.810256 | Val Loss: 0.130930, Val Acc: 0.752577\n",
      "Epoch 11981 - Train Loss: 0.112161, Train Acc: 0.810256 | Val Loss: 0.130925, Val Acc: 0.752577\n",
      "Epoch 11982 - Train Loss: 0.112155, Train Acc: 0.810256 | Val Loss: 0.130920, Val Acc: 0.752577\n",
      "Epoch 11983 - Train Loss: 0.112148, Train Acc: 0.810256 | Val Loss: 0.130915, Val Acc: 0.752577\n",
      "Epoch 11984 - Train Loss: 0.112142, Train Acc: 0.810256 | Val Loss: 0.130910, Val Acc: 0.752577\n",
      "Epoch 11985 - Train Loss: 0.112136, Train Acc: 0.810256 | Val Loss: 0.130905, Val Acc: 0.752577\n",
      "Epoch 11986 - Train Loss: 0.112130, Train Acc: 0.810256 | Val Loss: 0.130900, Val Acc: 0.752577\n",
      "Epoch 11987 - Train Loss: 0.112123, Train Acc: 0.811538 | Val Loss: 0.130896, Val Acc: 0.752577\n",
      "Epoch 11988 - Train Loss: 0.112117, Train Acc: 0.811538 | Val Loss: 0.130891, Val Acc: 0.752577\n",
      "Epoch 11989 - Train Loss: 0.112111, Train Acc: 0.811538 | Val Loss: 0.130886, Val Acc: 0.752577\n",
      "Epoch 11990 - Train Loss: 0.112105, Train Acc: 0.811538 | Val Loss: 0.130881, Val Acc: 0.752577\n",
      "Epoch 11991 - Train Loss: 0.112098, Train Acc: 0.811538 | Val Loss: 0.130876, Val Acc: 0.752577\n",
      "Epoch 11992 - Train Loss: 0.112092, Train Acc: 0.811538 | Val Loss: 0.130871, Val Acc: 0.752577\n",
      "Epoch 11993 - Train Loss: 0.112086, Train Acc: 0.811538 | Val Loss: 0.130866, Val Acc: 0.752577\n",
      "Epoch 11994 - Train Loss: 0.112080, Train Acc: 0.811538 | Val Loss: 0.130861, Val Acc: 0.752577\n",
      "Epoch 11995 - Train Loss: 0.112073, Train Acc: 0.811538 | Val Loss: 0.130856, Val Acc: 0.752577\n",
      "Epoch 11996 - Train Loss: 0.112067, Train Acc: 0.811538 | Val Loss: 0.130852, Val Acc: 0.752577\n",
      "Epoch 11997 - Train Loss: 0.112061, Train Acc: 0.811538 | Val Loss: 0.130847, Val Acc: 0.752577\n",
      "Epoch 11998 - Train Loss: 0.112055, Train Acc: 0.811538 | Val Loss: 0.130842, Val Acc: 0.752577\n",
      "Epoch 11999 - Train Loss: 0.112049, Train Acc: 0.811538 | Val Loss: 0.130837, Val Acc: 0.752577\n",
      "Epoch 12000 - Train Loss: 0.112042, Train Acc: 0.811538 | Val Loss: 0.130832, Val Acc: 0.752577\n",
      "Epoch 12001 - Train Loss: 0.112036, Train Acc: 0.811538 | Val Loss: 0.130827, Val Acc: 0.752577\n",
      "Epoch 12002 - Train Loss: 0.112030, Train Acc: 0.811538 | Val Loss: 0.130822, Val Acc: 0.752577\n",
      "Epoch 12003 - Train Loss: 0.112024, Train Acc: 0.811538 | Val Loss: 0.130818, Val Acc: 0.752577\n",
      "Epoch 12004 - Train Loss: 0.112017, Train Acc: 0.811538 | Val Loss: 0.130813, Val Acc: 0.752577\n",
      "Epoch 12005 - Train Loss: 0.112011, Train Acc: 0.811538 | Val Loss: 0.130808, Val Acc: 0.752577\n",
      "Epoch 12006 - Train Loss: 0.112005, Train Acc: 0.811538 | Val Loss: 0.130803, Val Acc: 0.752577\n",
      "Epoch 12007 - Train Loss: 0.111999, Train Acc: 0.811538 | Val Loss: 0.130798, Val Acc: 0.752577\n",
      "Epoch 12008 - Train Loss: 0.111992, Train Acc: 0.811538 | Val Loss: 0.130793, Val Acc: 0.752577\n",
      "Epoch 12009 - Train Loss: 0.111986, Train Acc: 0.811538 | Val Loss: 0.130788, Val Acc: 0.752577\n",
      "Epoch 12010 - Train Loss: 0.111980, Train Acc: 0.812821 | Val Loss: 0.130783, Val Acc: 0.752577\n",
      "Epoch 12011 - Train Loss: 0.111974, Train Acc: 0.812821 | Val Loss: 0.130779, Val Acc: 0.752577\n",
      "Epoch 12012 - Train Loss: 0.111968, Train Acc: 0.812821 | Val Loss: 0.130774, Val Acc: 0.752577\n",
      "Epoch 12013 - Train Loss: 0.111961, Train Acc: 0.812821 | Val Loss: 0.130769, Val Acc: 0.752577\n",
      "Epoch 12014 - Train Loss: 0.111955, Train Acc: 0.812821 | Val Loss: 0.130764, Val Acc: 0.752577\n",
      "Epoch 12015 - Train Loss: 0.111949, Train Acc: 0.812821 | Val Loss: 0.130759, Val Acc: 0.752577\n",
      "Epoch 12016 - Train Loss: 0.111943, Train Acc: 0.812821 | Val Loss: 0.130754, Val Acc: 0.752577\n",
      "Epoch 12017 - Train Loss: 0.111936, Train Acc: 0.812821 | Val Loss: 0.130749, Val Acc: 0.752577\n",
      "Epoch 12018 - Train Loss: 0.111930, Train Acc: 0.812821 | Val Loss: 0.130745, Val Acc: 0.752577\n",
      "Epoch 12019 - Train Loss: 0.111924, Train Acc: 0.812821 | Val Loss: 0.130740, Val Acc: 0.752577\n",
      "Epoch 12020 - Train Loss: 0.111918, Train Acc: 0.812821 | Val Loss: 0.130735, Val Acc: 0.752577\n",
      "Epoch 12021 - Train Loss: 0.111912, Train Acc: 0.812821 | Val Loss: 0.130730, Val Acc: 0.752577\n",
      "Epoch 12022 - Train Loss: 0.111905, Train Acc: 0.812821 | Val Loss: 0.130725, Val Acc: 0.752577\n",
      "Epoch 12023 - Train Loss: 0.111899, Train Acc: 0.812821 | Val Loss: 0.130720, Val Acc: 0.752577\n",
      "Epoch 12024 - Train Loss: 0.111893, Train Acc: 0.812821 | Val Loss: 0.130715, Val Acc: 0.752577\n",
      "Epoch 12025 - Train Loss: 0.111887, Train Acc: 0.812821 | Val Loss: 0.130711, Val Acc: 0.752577\n",
      "Epoch 12026 - Train Loss: 0.111880, Train Acc: 0.812821 | Val Loss: 0.130706, Val Acc: 0.752577\n",
      "Epoch 12027 - Train Loss: 0.111874, Train Acc: 0.812821 | Val Loss: 0.130701, Val Acc: 0.752577\n",
      "Epoch 12028 - Train Loss: 0.111868, Train Acc: 0.812821 | Val Loss: 0.130696, Val Acc: 0.752577\n",
      "Epoch 12029 - Train Loss: 0.111862, Train Acc: 0.812821 | Val Loss: 0.130691, Val Acc: 0.752577\n",
      "Epoch 12030 - Train Loss: 0.111856, Train Acc: 0.812821 | Val Loss: 0.130686, Val Acc: 0.752577\n",
      "Epoch 12031 - Train Loss: 0.111849, Train Acc: 0.812821 | Val Loss: 0.130681, Val Acc: 0.752577\n",
      "Epoch 12032 - Train Loss: 0.111843, Train Acc: 0.812821 | Val Loss: 0.130677, Val Acc: 0.752577\n",
      "Epoch 12033 - Train Loss: 0.111837, Train Acc: 0.812821 | Val Loss: 0.130672, Val Acc: 0.752577\n",
      "Epoch 12034 - Train Loss: 0.111831, Train Acc: 0.812821 | Val Loss: 0.130667, Val Acc: 0.752577\n",
      "Epoch 12035 - Train Loss: 0.111825, Train Acc: 0.812821 | Val Loss: 0.130662, Val Acc: 0.752577\n",
      "Epoch 12036 - Train Loss: 0.111818, Train Acc: 0.812821 | Val Loss: 0.130657, Val Acc: 0.752577\n",
      "Epoch 12037 - Train Loss: 0.111812, Train Acc: 0.812821 | Val Loss: 0.130652, Val Acc: 0.752577\n",
      "Epoch 12038 - Train Loss: 0.111806, Train Acc: 0.812821 | Val Loss: 0.130648, Val Acc: 0.752577\n",
      "Epoch 12039 - Train Loss: 0.111800, Train Acc: 0.812821 | Val Loss: 0.130643, Val Acc: 0.752577\n",
      "Epoch 12040 - Train Loss: 0.111794, Train Acc: 0.812821 | Val Loss: 0.130638, Val Acc: 0.752577\n",
      "Epoch 12041 - Train Loss: 0.111787, Train Acc: 0.812821 | Val Loss: 0.130633, Val Acc: 0.752577\n",
      "Epoch 12042 - Train Loss: 0.111781, Train Acc: 0.812821 | Val Loss: 0.130628, Val Acc: 0.752577\n",
      "Epoch 12043 - Train Loss: 0.111775, Train Acc: 0.812821 | Val Loss: 0.130623, Val Acc: 0.752577\n",
      "Epoch 12044 - Train Loss: 0.111769, Train Acc: 0.812821 | Val Loss: 0.130618, Val Acc: 0.752577\n",
      "Epoch 12045 - Train Loss: 0.111763, Train Acc: 0.812821 | Val Loss: 0.130614, Val Acc: 0.752577\n",
      "Epoch 12046 - Train Loss: 0.111756, Train Acc: 0.812821 | Val Loss: 0.130609, Val Acc: 0.752577\n",
      "Epoch 12047 - Train Loss: 0.111750, Train Acc: 0.812821 | Val Loss: 0.130604, Val Acc: 0.752577\n",
      "Epoch 12048 - Train Loss: 0.111744, Train Acc: 0.812821 | Val Loss: 0.130599, Val Acc: 0.752577\n",
      "Epoch 12049 - Train Loss: 0.111738, Train Acc: 0.812821 | Val Loss: 0.130594, Val Acc: 0.752577\n",
      "Epoch 12050 - Train Loss: 0.111732, Train Acc: 0.814103 | Val Loss: 0.130589, Val Acc: 0.752577\n",
      "Epoch 12051 - Train Loss: 0.111725, Train Acc: 0.814103 | Val Loss: 0.130585, Val Acc: 0.752577\n",
      "Epoch 12052 - Train Loss: 0.111719, Train Acc: 0.814103 | Val Loss: 0.130580, Val Acc: 0.752577\n",
      "Epoch 12053 - Train Loss: 0.111713, Train Acc: 0.814103 | Val Loss: 0.130575, Val Acc: 0.752577\n",
      "Epoch 12054 - Train Loss: 0.111707, Train Acc: 0.814103 | Val Loss: 0.130570, Val Acc: 0.752577\n",
      "Epoch 12055 - Train Loss: 0.111701, Train Acc: 0.814103 | Val Loss: 0.130565, Val Acc: 0.752577\n",
      "Epoch 12056 - Train Loss: 0.111695, Train Acc: 0.814103 | Val Loss: 0.130560, Val Acc: 0.752577\n",
      "Epoch 12057 - Train Loss: 0.111688, Train Acc: 0.814103 | Val Loss: 0.130556, Val Acc: 0.752577\n",
      "Epoch 12058 - Train Loss: 0.111682, Train Acc: 0.814103 | Val Loss: 0.130551, Val Acc: 0.752577\n",
      "Epoch 12059 - Train Loss: 0.111676, Train Acc: 0.814103 | Val Loss: 0.130546, Val Acc: 0.752577\n",
      "Epoch 12060 - Train Loss: 0.111670, Train Acc: 0.814103 | Val Loss: 0.130541, Val Acc: 0.752577\n",
      "Epoch 12061 - Train Loss: 0.111664, Train Acc: 0.814103 | Val Loss: 0.130536, Val Acc: 0.752577\n",
      "Epoch 12062 - Train Loss: 0.111657, Train Acc: 0.814103 | Val Loss: 0.130531, Val Acc: 0.752577\n",
      "Epoch 12063 - Train Loss: 0.111651, Train Acc: 0.814103 | Val Loss: 0.130527, Val Acc: 0.752577\n",
      "Epoch 12064 - Train Loss: 0.111645, Train Acc: 0.814103 | Val Loss: 0.130522, Val Acc: 0.752577\n",
      "Epoch 12065 - Train Loss: 0.111639, Train Acc: 0.814103 | Val Loss: 0.130517, Val Acc: 0.752577\n",
      "Epoch 12066 - Train Loss: 0.111633, Train Acc: 0.814103 | Val Loss: 0.130512, Val Acc: 0.752577\n",
      "Epoch 12067 - Train Loss: 0.111627, Train Acc: 0.814103 | Val Loss: 0.130507, Val Acc: 0.752577\n",
      "Epoch 12068 - Train Loss: 0.111620, Train Acc: 0.814103 | Val Loss: 0.130502, Val Acc: 0.752577\n",
      "Epoch 12069 - Train Loss: 0.111614, Train Acc: 0.814103 | Val Loss: 0.130498, Val Acc: 0.752577\n",
      "Epoch 12070 - Train Loss: 0.111608, Train Acc: 0.814103 | Val Loss: 0.130493, Val Acc: 0.752577\n",
      "Epoch 12071 - Train Loss: 0.111602, Train Acc: 0.814103 | Val Loss: 0.130488, Val Acc: 0.752577\n",
      "Epoch 12072 - Train Loss: 0.111596, Train Acc: 0.814103 | Val Loss: 0.130483, Val Acc: 0.752577\n",
      "Epoch 12073 - Train Loss: 0.111589, Train Acc: 0.814103 | Val Loss: 0.130478, Val Acc: 0.752577\n",
      "Epoch 12074 - Train Loss: 0.111583, Train Acc: 0.814103 | Val Loss: 0.130474, Val Acc: 0.752577\n",
      "Epoch 12075 - Train Loss: 0.111577, Train Acc: 0.814103 | Val Loss: 0.130469, Val Acc: 0.752577\n",
      "Epoch 12076 - Train Loss: 0.111571, Train Acc: 0.814103 | Val Loss: 0.130464, Val Acc: 0.752577\n",
      "Epoch 12077 - Train Loss: 0.111565, Train Acc: 0.814103 | Val Loss: 0.130459, Val Acc: 0.752577\n",
      "Epoch 12078 - Train Loss: 0.111559, Train Acc: 0.814103 | Val Loss: 0.130454, Val Acc: 0.752577\n",
      "Epoch 12079 - Train Loss: 0.111552, Train Acc: 0.814103 | Val Loss: 0.130450, Val Acc: 0.752577\n",
      "Epoch 12080 - Train Loss: 0.111546, Train Acc: 0.814103 | Val Loss: 0.130445, Val Acc: 0.752577\n",
      "Epoch 12081 - Train Loss: 0.111540, Train Acc: 0.814103 | Val Loss: 0.130440, Val Acc: 0.752577\n",
      "Epoch 12082 - Train Loss: 0.111534, Train Acc: 0.814103 | Val Loss: 0.130435, Val Acc: 0.752577\n",
      "Epoch 12083 - Train Loss: 0.111528, Train Acc: 0.814103 | Val Loss: 0.130430, Val Acc: 0.752577\n",
      "Epoch 12084 - Train Loss: 0.111522, Train Acc: 0.814103 | Val Loss: 0.130426, Val Acc: 0.752577\n",
      "Epoch 12085 - Train Loss: 0.111516, Train Acc: 0.814103 | Val Loss: 0.130421, Val Acc: 0.752577\n",
      "Epoch 12086 - Train Loss: 0.111509, Train Acc: 0.814103 | Val Loss: 0.130416, Val Acc: 0.752577\n",
      "Epoch 12087 - Train Loss: 0.111503, Train Acc: 0.814103 | Val Loss: 0.130411, Val Acc: 0.752577\n",
      "Epoch 12088 - Train Loss: 0.111497, Train Acc: 0.814103 | Val Loss: 0.130406, Val Acc: 0.752577\n",
      "Epoch 12089 - Train Loss: 0.111491, Train Acc: 0.814103 | Val Loss: 0.130402, Val Acc: 0.752577\n",
      "Epoch 12090 - Train Loss: 0.111485, Train Acc: 0.814103 | Val Loss: 0.130397, Val Acc: 0.752577\n",
      "Epoch 12091 - Train Loss: 0.111479, Train Acc: 0.814103 | Val Loss: 0.130392, Val Acc: 0.752577\n",
      "Epoch 12092 - Train Loss: 0.111472, Train Acc: 0.814103 | Val Loss: 0.130387, Val Acc: 0.752577\n",
      "Epoch 12093 - Train Loss: 0.111466, Train Acc: 0.814103 | Val Loss: 0.130382, Val Acc: 0.752577\n",
      "Epoch 12094 - Train Loss: 0.111460, Train Acc: 0.814103 | Val Loss: 0.130378, Val Acc: 0.752577\n",
      "Epoch 12095 - Train Loss: 0.111454, Train Acc: 0.814103 | Val Loss: 0.130373, Val Acc: 0.752577\n",
      "Epoch 12096 - Train Loss: 0.111448, Train Acc: 0.814103 | Val Loss: 0.130368, Val Acc: 0.752577\n",
      "Epoch 12097 - Train Loss: 0.111442, Train Acc: 0.814103 | Val Loss: 0.130363, Val Acc: 0.752577\n",
      "Epoch 12098 - Train Loss: 0.111436, Train Acc: 0.814103 | Val Loss: 0.130358, Val Acc: 0.752577\n",
      "Epoch 12099 - Train Loss: 0.111429, Train Acc: 0.814103 | Val Loss: 0.130354, Val Acc: 0.752577\n",
      "Epoch 12100 - Train Loss: 0.111423, Train Acc: 0.814103 | Val Loss: 0.130349, Val Acc: 0.752577\n",
      "Epoch 12101 - Train Loss: 0.111417, Train Acc: 0.814103 | Val Loss: 0.130344, Val Acc: 0.752577\n",
      "Epoch 12102 - Train Loss: 0.111411, Train Acc: 0.814103 | Val Loss: 0.130339, Val Acc: 0.752577\n",
      "Epoch 12103 - Train Loss: 0.111405, Train Acc: 0.814103 | Val Loss: 0.130334, Val Acc: 0.752577\n",
      "Epoch 12104 - Train Loss: 0.111399, Train Acc: 0.814103 | Val Loss: 0.130330, Val Acc: 0.752577\n",
      "Epoch 12105 - Train Loss: 0.111393, Train Acc: 0.814103 | Val Loss: 0.130325, Val Acc: 0.752577\n",
      "Epoch 12106 - Train Loss: 0.111386, Train Acc: 0.814103 | Val Loss: 0.130320, Val Acc: 0.752577\n",
      "Epoch 12107 - Train Loss: 0.111380, Train Acc: 0.814103 | Val Loss: 0.130315, Val Acc: 0.752577\n",
      "Epoch 12108 - Train Loss: 0.111374, Train Acc: 0.814103 | Val Loss: 0.130311, Val Acc: 0.752577\n",
      "Epoch 12109 - Train Loss: 0.111368, Train Acc: 0.814103 | Val Loss: 0.130306, Val Acc: 0.752577\n",
      "Epoch 12110 - Train Loss: 0.111362, Train Acc: 0.814103 | Val Loss: 0.130301, Val Acc: 0.752577\n",
      "Epoch 12111 - Train Loss: 0.111356, Train Acc: 0.814103 | Val Loss: 0.130296, Val Acc: 0.752577\n",
      "Epoch 12112 - Train Loss: 0.111350, Train Acc: 0.814103 | Val Loss: 0.130291, Val Acc: 0.752577\n",
      "Epoch 12113 - Train Loss: 0.111343, Train Acc: 0.814103 | Val Loss: 0.130287, Val Acc: 0.752577\n",
      "Epoch 12114 - Train Loss: 0.111337, Train Acc: 0.814103 | Val Loss: 0.130282, Val Acc: 0.752577\n",
      "Epoch 12115 - Train Loss: 0.111331, Train Acc: 0.814103 | Val Loss: 0.130277, Val Acc: 0.752577\n",
      "Epoch 12116 - Train Loss: 0.111325, Train Acc: 0.814103 | Val Loss: 0.130272, Val Acc: 0.752577\n",
      "Epoch 12117 - Train Loss: 0.111319, Train Acc: 0.814103 | Val Loss: 0.130268, Val Acc: 0.752577\n",
      "Epoch 12118 - Train Loss: 0.111313, Train Acc: 0.814103 | Val Loss: 0.130263, Val Acc: 0.752577\n",
      "Epoch 12119 - Train Loss: 0.111307, Train Acc: 0.814103 | Val Loss: 0.130258, Val Acc: 0.752577\n",
      "Epoch 12120 - Train Loss: 0.111300, Train Acc: 0.814103 | Val Loss: 0.130253, Val Acc: 0.752577\n",
      "Epoch 12121 - Train Loss: 0.111294, Train Acc: 0.814103 | Val Loss: 0.130249, Val Acc: 0.752577\n",
      "Epoch 12122 - Train Loss: 0.111288, Train Acc: 0.814103 | Val Loss: 0.130244, Val Acc: 0.752577\n",
      "Epoch 12123 - Train Loss: 0.111282, Train Acc: 0.814103 | Val Loss: 0.130239, Val Acc: 0.752577\n",
      "Epoch 12124 - Train Loss: 0.111276, Train Acc: 0.814103 | Val Loss: 0.130234, Val Acc: 0.752577\n",
      "Epoch 12125 - Train Loss: 0.111270, Train Acc: 0.814103 | Val Loss: 0.130229, Val Acc: 0.752577\n",
      "Epoch 12126 - Train Loss: 0.111264, Train Acc: 0.814103 | Val Loss: 0.130225, Val Acc: 0.752577\n",
      "Epoch 12127 - Train Loss: 0.111258, Train Acc: 0.814103 | Val Loss: 0.130220, Val Acc: 0.752577\n",
      "Epoch 12128 - Train Loss: 0.111251, Train Acc: 0.814103 | Val Loss: 0.130215, Val Acc: 0.752577\n",
      "Epoch 12129 - Train Loss: 0.111245, Train Acc: 0.814103 | Val Loss: 0.130210, Val Acc: 0.752577\n",
      "Epoch 12130 - Train Loss: 0.111239, Train Acc: 0.814103 | Val Loss: 0.130206, Val Acc: 0.752577\n",
      "Epoch 12131 - Train Loss: 0.111233, Train Acc: 0.814103 | Val Loss: 0.130201, Val Acc: 0.752577\n",
      "Epoch 12132 - Train Loss: 0.111227, Train Acc: 0.814103 | Val Loss: 0.130196, Val Acc: 0.752577\n",
      "Epoch 12133 - Train Loss: 0.111221, Train Acc: 0.814103 | Val Loss: 0.130191, Val Acc: 0.752577\n",
      "Epoch 12134 - Train Loss: 0.111215, Train Acc: 0.814103 | Val Loss: 0.130187, Val Acc: 0.752577\n",
      "Epoch 12135 - Train Loss: 0.111209, Train Acc: 0.814103 | Val Loss: 0.130182, Val Acc: 0.752577\n",
      "Epoch 12136 - Train Loss: 0.111203, Train Acc: 0.814103 | Val Loss: 0.130177, Val Acc: 0.752577\n",
      "Epoch 12137 - Train Loss: 0.111196, Train Acc: 0.814103 | Val Loss: 0.130172, Val Acc: 0.752577\n",
      "Epoch 12138 - Train Loss: 0.111190, Train Acc: 0.814103 | Val Loss: 0.130168, Val Acc: 0.752577\n",
      "Epoch 12139 - Train Loss: 0.111184, Train Acc: 0.814103 | Val Loss: 0.130163, Val Acc: 0.752577\n",
      "Epoch 12140 - Train Loss: 0.111178, Train Acc: 0.814103 | Val Loss: 0.130158, Val Acc: 0.752577\n",
      "Epoch 12141 - Train Loss: 0.111172, Train Acc: 0.814103 | Val Loss: 0.130153, Val Acc: 0.752577\n",
      "Epoch 12142 - Train Loss: 0.111166, Train Acc: 0.814103 | Val Loss: 0.130149, Val Acc: 0.752577\n",
      "Epoch 12143 - Train Loss: 0.111160, Train Acc: 0.814103 | Val Loss: 0.130144, Val Acc: 0.752577\n",
      "Epoch 12144 - Train Loss: 0.111154, Train Acc: 0.814103 | Val Loss: 0.130139, Val Acc: 0.752577\n",
      "Epoch 12145 - Train Loss: 0.111148, Train Acc: 0.814103 | Val Loss: 0.130134, Val Acc: 0.752577\n",
      "Epoch 12146 - Train Loss: 0.111141, Train Acc: 0.814103 | Val Loss: 0.130130, Val Acc: 0.752577\n",
      "Epoch 12147 - Train Loss: 0.111135, Train Acc: 0.814103 | Val Loss: 0.130125, Val Acc: 0.752577\n",
      "Epoch 12148 - Train Loss: 0.111129, Train Acc: 0.814103 | Val Loss: 0.130120, Val Acc: 0.752577\n",
      "Epoch 12149 - Train Loss: 0.111123, Train Acc: 0.814103 | Val Loss: 0.130115, Val Acc: 0.752577\n",
      "Epoch 12150 - Train Loss: 0.111117, Train Acc: 0.814103 | Val Loss: 0.130111, Val Acc: 0.752577\n",
      "Epoch 12151 - Train Loss: 0.111111, Train Acc: 0.814103 | Val Loss: 0.130106, Val Acc: 0.752577\n",
      "Epoch 12152 - Train Loss: 0.111105, Train Acc: 0.814103 | Val Loss: 0.130101, Val Acc: 0.752577\n",
      "Epoch 12153 - Train Loss: 0.111099, Train Acc: 0.814103 | Val Loss: 0.130097, Val Acc: 0.752577\n",
      "Epoch 12154 - Train Loss: 0.111093, Train Acc: 0.814103 | Val Loss: 0.130092, Val Acc: 0.752577\n",
      "Epoch 12155 - Train Loss: 0.111087, Train Acc: 0.814103 | Val Loss: 0.130087, Val Acc: 0.752577\n",
      "Epoch 12156 - Train Loss: 0.111080, Train Acc: 0.814103 | Val Loss: 0.130082, Val Acc: 0.752577\n",
      "Epoch 12157 - Train Loss: 0.111074, Train Acc: 0.814103 | Val Loss: 0.130078, Val Acc: 0.752577\n",
      "Epoch 12158 - Train Loss: 0.111068, Train Acc: 0.814103 | Val Loss: 0.130073, Val Acc: 0.752577\n",
      "Epoch 12159 - Train Loss: 0.111062, Train Acc: 0.814103 | Val Loss: 0.130068, Val Acc: 0.752577\n",
      "Epoch 12160 - Train Loss: 0.111056, Train Acc: 0.814103 | Val Loss: 0.130063, Val Acc: 0.752577\n",
      "Epoch 12161 - Train Loss: 0.111050, Train Acc: 0.814103 | Val Loss: 0.130059, Val Acc: 0.752577\n",
      "Epoch 12162 - Train Loss: 0.111044, Train Acc: 0.814103 | Val Loss: 0.130054, Val Acc: 0.752577\n",
      "Epoch 12163 - Train Loss: 0.111038, Train Acc: 0.814103 | Val Loss: 0.130049, Val Acc: 0.752577\n",
      "Epoch 12164 - Train Loss: 0.111032, Train Acc: 0.814103 | Val Loss: 0.130044, Val Acc: 0.752577\n",
      "Epoch 12165 - Train Loss: 0.111026, Train Acc: 0.814103 | Val Loss: 0.130040, Val Acc: 0.752577\n",
      "Epoch 12166 - Train Loss: 0.111020, Train Acc: 0.814103 | Val Loss: 0.130035, Val Acc: 0.752577\n",
      "Epoch 12167 - Train Loss: 0.111013, Train Acc: 0.814103 | Val Loss: 0.130030, Val Acc: 0.752577\n",
      "Epoch 12168 - Train Loss: 0.111007, Train Acc: 0.814103 | Val Loss: 0.130026, Val Acc: 0.752577\n",
      "Epoch 12169 - Train Loss: 0.111001, Train Acc: 0.814103 | Val Loss: 0.130021, Val Acc: 0.752577\n",
      "Epoch 12170 - Train Loss: 0.110995, Train Acc: 0.814103 | Val Loss: 0.130016, Val Acc: 0.752577\n",
      "Epoch 12171 - Train Loss: 0.110989, Train Acc: 0.814103 | Val Loss: 0.130011, Val Acc: 0.752577\n",
      "Epoch 12172 - Train Loss: 0.110983, Train Acc: 0.814103 | Val Loss: 0.130007, Val Acc: 0.752577\n",
      "Epoch 12173 - Train Loss: 0.110977, Train Acc: 0.814103 | Val Loss: 0.130002, Val Acc: 0.752577\n",
      "Epoch 12174 - Train Loss: 0.110971, Train Acc: 0.814103 | Val Loss: 0.129997, Val Acc: 0.752577\n",
      "Epoch 12175 - Train Loss: 0.110965, Train Acc: 0.814103 | Val Loss: 0.129993, Val Acc: 0.752577\n",
      "Epoch 12176 - Train Loss: 0.110959, Train Acc: 0.814103 | Val Loss: 0.129988, Val Acc: 0.752577\n",
      "Epoch 12177 - Train Loss: 0.110953, Train Acc: 0.814103 | Val Loss: 0.129983, Val Acc: 0.752577\n",
      "Epoch 12178 - Train Loss: 0.110947, Train Acc: 0.814103 | Val Loss: 0.129978, Val Acc: 0.752577\n",
      "Epoch 12179 - Train Loss: 0.110940, Train Acc: 0.814103 | Val Loss: 0.129974, Val Acc: 0.752577\n",
      "Epoch 12180 - Train Loss: 0.110934, Train Acc: 0.814103 | Val Loss: 0.129969, Val Acc: 0.752577\n",
      "Epoch 12181 - Train Loss: 0.110928, Train Acc: 0.814103 | Val Loss: 0.129964, Val Acc: 0.752577\n",
      "Epoch 12182 - Train Loss: 0.110922, Train Acc: 0.814103 | Val Loss: 0.129960, Val Acc: 0.752577\n",
      "Epoch 12183 - Train Loss: 0.110916, Train Acc: 0.814103 | Val Loss: 0.129955, Val Acc: 0.752577\n",
      "Epoch 12184 - Train Loss: 0.110910, Train Acc: 0.814103 | Val Loss: 0.129950, Val Acc: 0.752577\n",
      "Epoch 12185 - Train Loss: 0.110904, Train Acc: 0.814103 | Val Loss: 0.129945, Val Acc: 0.752577\n",
      "Epoch 12186 - Train Loss: 0.110898, Train Acc: 0.814103 | Val Loss: 0.129941, Val Acc: 0.752577\n",
      "Epoch 12187 - Train Loss: 0.110892, Train Acc: 0.814103 | Val Loss: 0.129936, Val Acc: 0.752577\n",
      "Epoch 12188 - Train Loss: 0.110886, Train Acc: 0.814103 | Val Loss: 0.129931, Val Acc: 0.752577\n",
      "Epoch 12189 - Train Loss: 0.110880, Train Acc: 0.814103 | Val Loss: 0.129927, Val Acc: 0.752577\n",
      "Epoch 12190 - Train Loss: 0.110874, Train Acc: 0.814103 | Val Loss: 0.129922, Val Acc: 0.752577\n",
      "Epoch 12191 - Train Loss: 0.110868, Train Acc: 0.814103 | Val Loss: 0.129917, Val Acc: 0.752577\n",
      "Epoch 12192 - Train Loss: 0.110862, Train Acc: 0.814103 | Val Loss: 0.129912, Val Acc: 0.752577\n",
      "Epoch 12193 - Train Loss: 0.110855, Train Acc: 0.814103 | Val Loss: 0.129908, Val Acc: 0.752577\n",
      "Epoch 12194 - Train Loss: 0.110849, Train Acc: 0.814103 | Val Loss: 0.129903, Val Acc: 0.752577\n",
      "Epoch 12195 - Train Loss: 0.110843, Train Acc: 0.814103 | Val Loss: 0.129898, Val Acc: 0.752577\n",
      "Epoch 12196 - Train Loss: 0.110837, Train Acc: 0.814103 | Val Loss: 0.129894, Val Acc: 0.752577\n",
      "Epoch 12197 - Train Loss: 0.110831, Train Acc: 0.814103 | Val Loss: 0.129889, Val Acc: 0.752577\n",
      "Epoch 12198 - Train Loss: 0.110825, Train Acc: 0.814103 | Val Loss: 0.129884, Val Acc: 0.752577\n",
      "Epoch 12199 - Train Loss: 0.110819, Train Acc: 0.814103 | Val Loss: 0.129880, Val Acc: 0.752577\n",
      "Epoch 12200 - Train Loss: 0.110813, Train Acc: 0.814103 | Val Loss: 0.129875, Val Acc: 0.752577\n",
      "Epoch 12201 - Train Loss: 0.110807, Train Acc: 0.814103 | Val Loss: 0.129870, Val Acc: 0.752577\n",
      "Epoch 12202 - Train Loss: 0.110801, Train Acc: 0.814103 | Val Loss: 0.129865, Val Acc: 0.752577\n",
      "Epoch 12203 - Train Loss: 0.110795, Train Acc: 0.814103 | Val Loss: 0.129861, Val Acc: 0.752577\n",
      "Epoch 12204 - Train Loss: 0.110789, Train Acc: 0.814103 | Val Loss: 0.129856, Val Acc: 0.752577\n",
      "Epoch 12205 - Train Loss: 0.110783, Train Acc: 0.814103 | Val Loss: 0.129851, Val Acc: 0.752577\n",
      "Epoch 12206 - Train Loss: 0.110777, Train Acc: 0.814103 | Val Loss: 0.129847, Val Acc: 0.752577\n",
      "Epoch 12207 - Train Loss: 0.110771, Train Acc: 0.814103 | Val Loss: 0.129842, Val Acc: 0.752577\n",
      "Epoch 12208 - Train Loss: 0.110765, Train Acc: 0.814103 | Val Loss: 0.129837, Val Acc: 0.752577\n",
      "Epoch 12209 - Train Loss: 0.110759, Train Acc: 0.814103 | Val Loss: 0.129833, Val Acc: 0.752577\n",
      "Epoch 12210 - Train Loss: 0.110752, Train Acc: 0.814103 | Val Loss: 0.129828, Val Acc: 0.752577\n",
      "Epoch 12211 - Train Loss: 0.110746, Train Acc: 0.814103 | Val Loss: 0.129823, Val Acc: 0.752577\n",
      "Epoch 12212 - Train Loss: 0.110740, Train Acc: 0.814103 | Val Loss: 0.129819, Val Acc: 0.752577\n",
      "Epoch 12213 - Train Loss: 0.110734, Train Acc: 0.814103 | Val Loss: 0.129814, Val Acc: 0.752577\n",
      "Epoch 12214 - Train Loss: 0.110728, Train Acc: 0.814103 | Val Loss: 0.129809, Val Acc: 0.752577\n",
      "Epoch 12215 - Train Loss: 0.110722, Train Acc: 0.814103 | Val Loss: 0.129804, Val Acc: 0.752577\n",
      "Epoch 12216 - Train Loss: 0.110716, Train Acc: 0.814103 | Val Loss: 0.129800, Val Acc: 0.752577\n",
      "Epoch 12217 - Train Loss: 0.110710, Train Acc: 0.814103 | Val Loss: 0.129795, Val Acc: 0.752577\n",
      "Epoch 12218 - Train Loss: 0.110704, Train Acc: 0.815385 | Val Loss: 0.129790, Val Acc: 0.752577\n",
      "Epoch 12219 - Train Loss: 0.110698, Train Acc: 0.816667 | Val Loss: 0.129786, Val Acc: 0.752577\n",
      "Epoch 12220 - Train Loss: 0.110692, Train Acc: 0.816667 | Val Loss: 0.129781, Val Acc: 0.752577\n",
      "Epoch 12221 - Train Loss: 0.110686, Train Acc: 0.816667 | Val Loss: 0.129776, Val Acc: 0.752577\n",
      "Epoch 12222 - Train Loss: 0.110680, Train Acc: 0.816667 | Val Loss: 0.129772, Val Acc: 0.752577\n",
      "Epoch 12223 - Train Loss: 0.110674, Train Acc: 0.816667 | Val Loss: 0.129767, Val Acc: 0.752577\n",
      "Epoch 12224 - Train Loss: 0.110668, Train Acc: 0.817949 | Val Loss: 0.129762, Val Acc: 0.752577\n",
      "Epoch 12225 - Train Loss: 0.110662, Train Acc: 0.817949 | Val Loss: 0.129758, Val Acc: 0.752577\n",
      "Epoch 12226 - Train Loss: 0.110656, Train Acc: 0.817949 | Val Loss: 0.129753, Val Acc: 0.752577\n",
      "Epoch 12227 - Train Loss: 0.110650, Train Acc: 0.817949 | Val Loss: 0.129748, Val Acc: 0.752577\n",
      "Epoch 12228 - Train Loss: 0.110644, Train Acc: 0.817949 | Val Loss: 0.129744, Val Acc: 0.752577\n",
      "Epoch 12229 - Train Loss: 0.110638, Train Acc: 0.817949 | Val Loss: 0.129739, Val Acc: 0.752577\n",
      "Epoch 12230 - Train Loss: 0.110632, Train Acc: 0.817949 | Val Loss: 0.129734, Val Acc: 0.752577\n",
      "Epoch 12231 - Train Loss: 0.110626, Train Acc: 0.817949 | Val Loss: 0.129730, Val Acc: 0.752577\n",
      "Epoch 12232 - Train Loss: 0.110620, Train Acc: 0.817949 | Val Loss: 0.129725, Val Acc: 0.752577\n",
      "Epoch 12233 - Train Loss: 0.110614, Train Acc: 0.819231 | Val Loss: 0.129720, Val Acc: 0.752577\n",
      "Epoch 12234 - Train Loss: 0.110607, Train Acc: 0.819231 | Val Loss: 0.129716, Val Acc: 0.752577\n",
      "Epoch 12235 - Train Loss: 0.110601, Train Acc: 0.819231 | Val Loss: 0.129711, Val Acc: 0.752577\n",
      "Epoch 12236 - Train Loss: 0.110595, Train Acc: 0.819231 | Val Loss: 0.129706, Val Acc: 0.752577\n",
      "Epoch 12237 - Train Loss: 0.110589, Train Acc: 0.819231 | Val Loss: 0.129702, Val Acc: 0.752577\n",
      "Epoch 12238 - Train Loss: 0.110583, Train Acc: 0.819231 | Val Loss: 0.129697, Val Acc: 0.752577\n",
      "Epoch 12239 - Train Loss: 0.110577, Train Acc: 0.819231 | Val Loss: 0.129692, Val Acc: 0.752577\n",
      "Epoch 12240 - Train Loss: 0.110571, Train Acc: 0.819231 | Val Loss: 0.129688, Val Acc: 0.752577\n",
      "Epoch 12241 - Train Loss: 0.110565, Train Acc: 0.819231 | Val Loss: 0.129683, Val Acc: 0.752577\n",
      "Epoch 12242 - Train Loss: 0.110559, Train Acc: 0.819231 | Val Loss: 0.129678, Val Acc: 0.752577\n",
      "Epoch 12243 - Train Loss: 0.110553, Train Acc: 0.819231 | Val Loss: 0.129674, Val Acc: 0.752577\n",
      "Epoch 12244 - Train Loss: 0.110547, Train Acc: 0.819231 | Val Loss: 0.129669, Val Acc: 0.752577\n",
      "Epoch 12245 - Train Loss: 0.110541, Train Acc: 0.819231 | Val Loss: 0.129664, Val Acc: 0.752577\n",
      "Epoch 12246 - Train Loss: 0.110535, Train Acc: 0.819231 | Val Loss: 0.129660, Val Acc: 0.752577\n",
      "Epoch 12247 - Train Loss: 0.110529, Train Acc: 0.819231 | Val Loss: 0.129655, Val Acc: 0.752577\n",
      "Epoch 12248 - Train Loss: 0.110523, Train Acc: 0.819231 | Val Loss: 0.129650, Val Acc: 0.752577\n",
      "Epoch 12249 - Train Loss: 0.110517, Train Acc: 0.819231 | Val Loss: 0.129646, Val Acc: 0.752577\n",
      "Epoch 12250 - Train Loss: 0.110511, Train Acc: 0.819231 | Val Loss: 0.129641, Val Acc: 0.752577\n",
      "Epoch 12251 - Train Loss: 0.110505, Train Acc: 0.819231 | Val Loss: 0.129636, Val Acc: 0.752577\n",
      "Epoch 12252 - Train Loss: 0.110499, Train Acc: 0.819231 | Val Loss: 0.129632, Val Acc: 0.752577\n",
      "Epoch 12253 - Train Loss: 0.110493, Train Acc: 0.819231 | Val Loss: 0.129627, Val Acc: 0.752577\n",
      "Epoch 12254 - Train Loss: 0.110487, Train Acc: 0.819231 | Val Loss: 0.129623, Val Acc: 0.752577\n",
      "Epoch 12255 - Train Loss: 0.110481, Train Acc: 0.819231 | Val Loss: 0.129618, Val Acc: 0.752577\n",
      "Epoch 12256 - Train Loss: 0.110475, Train Acc: 0.819231 | Val Loss: 0.129613, Val Acc: 0.752577\n",
      "Epoch 12257 - Train Loss: 0.110469, Train Acc: 0.819231 | Val Loss: 0.129609, Val Acc: 0.752577\n",
      "Epoch 12258 - Train Loss: 0.110463, Train Acc: 0.819231 | Val Loss: 0.129604, Val Acc: 0.752577\n",
      "Epoch 12259 - Train Loss: 0.110457, Train Acc: 0.819231 | Val Loss: 0.129599, Val Acc: 0.752577\n",
      "Epoch 12260 - Train Loss: 0.110451, Train Acc: 0.819231 | Val Loss: 0.129595, Val Acc: 0.752577\n",
      "Epoch 12261 - Train Loss: 0.110445, Train Acc: 0.819231 | Val Loss: 0.129590, Val Acc: 0.752577\n",
      "Epoch 12262 - Train Loss: 0.110439, Train Acc: 0.819231 | Val Loss: 0.129585, Val Acc: 0.752577\n",
      "Epoch 12263 - Train Loss: 0.110433, Train Acc: 0.819231 | Val Loss: 0.129581, Val Acc: 0.752577\n",
      "Epoch 12264 - Train Loss: 0.110427, Train Acc: 0.819231 | Val Loss: 0.129576, Val Acc: 0.752577\n",
      "Epoch 12265 - Train Loss: 0.110421, Train Acc: 0.819231 | Val Loss: 0.129571, Val Acc: 0.752577\n",
      "Epoch 12266 - Train Loss: 0.110415, Train Acc: 0.819231 | Val Loss: 0.129567, Val Acc: 0.752577\n",
      "Epoch 12267 - Train Loss: 0.110409, Train Acc: 0.819231 | Val Loss: 0.129562, Val Acc: 0.752577\n",
      "Epoch 12268 - Train Loss: 0.110403, Train Acc: 0.819231 | Val Loss: 0.129558, Val Acc: 0.752577\n",
      "Epoch 12269 - Train Loss: 0.110397, Train Acc: 0.819231 | Val Loss: 0.129553, Val Acc: 0.752577\n",
      "Epoch 12270 - Train Loss: 0.110391, Train Acc: 0.819231 | Val Loss: 0.129548, Val Acc: 0.752577\n",
      "Epoch 12271 - Train Loss: 0.110385, Train Acc: 0.819231 | Val Loss: 0.129544, Val Acc: 0.752577\n",
      "Epoch 12272 - Train Loss: 0.110379, Train Acc: 0.819231 | Val Loss: 0.129539, Val Acc: 0.752577\n",
      "Epoch 12273 - Train Loss: 0.110373, Train Acc: 0.819231 | Val Loss: 0.129534, Val Acc: 0.752577\n",
      "Epoch 12274 - Train Loss: 0.110367, Train Acc: 0.819231 | Val Loss: 0.129530, Val Acc: 0.752577\n",
      "Epoch 12275 - Train Loss: 0.110361, Train Acc: 0.819231 | Val Loss: 0.129525, Val Acc: 0.752577\n",
      "Epoch 12276 - Train Loss: 0.110355, Train Acc: 0.819231 | Val Loss: 0.129520, Val Acc: 0.752577\n",
      "Epoch 12277 - Train Loss: 0.110349, Train Acc: 0.819231 | Val Loss: 0.129516, Val Acc: 0.752577\n",
      "Epoch 12278 - Train Loss: 0.110343, Train Acc: 0.819231 | Val Loss: 0.129511, Val Acc: 0.752577\n",
      "Epoch 12279 - Train Loss: 0.110337, Train Acc: 0.819231 | Val Loss: 0.129507, Val Acc: 0.752577\n",
      "Epoch 12280 - Train Loss: 0.110331, Train Acc: 0.819231 | Val Loss: 0.129502, Val Acc: 0.752577\n",
      "Epoch 12281 - Train Loss: 0.110325, Train Acc: 0.819231 | Val Loss: 0.129497, Val Acc: 0.752577\n",
      "Epoch 12282 - Train Loss: 0.110319, Train Acc: 0.819231 | Val Loss: 0.129493, Val Acc: 0.752577\n",
      "Epoch 12283 - Train Loss: 0.110313, Train Acc: 0.819231 | Val Loss: 0.129488, Val Acc: 0.752577\n",
      "Epoch 12284 - Train Loss: 0.110307, Train Acc: 0.819231 | Val Loss: 0.129483, Val Acc: 0.752577\n",
      "Epoch 12285 - Train Loss: 0.110301, Train Acc: 0.819231 | Val Loss: 0.129479, Val Acc: 0.752577\n",
      "Epoch 12286 - Train Loss: 0.110295, Train Acc: 0.819231 | Val Loss: 0.129474, Val Acc: 0.752577\n",
      "Epoch 12287 - Train Loss: 0.110289, Train Acc: 0.819231 | Val Loss: 0.129470, Val Acc: 0.752577\n",
      "Epoch 12288 - Train Loss: 0.110283, Train Acc: 0.819231 | Val Loss: 0.129465, Val Acc: 0.752577\n",
      "Epoch 12289 - Train Loss: 0.110277, Train Acc: 0.819231 | Val Loss: 0.129460, Val Acc: 0.752577\n",
      "Epoch 12290 - Train Loss: 0.110271, Train Acc: 0.819231 | Val Loss: 0.129456, Val Acc: 0.752577\n",
      "Epoch 12291 - Train Loss: 0.110265, Train Acc: 0.819231 | Val Loss: 0.129451, Val Acc: 0.752577\n",
      "Epoch 12292 - Train Loss: 0.110259, Train Acc: 0.819231 | Val Loss: 0.129447, Val Acc: 0.752577\n",
      "Epoch 12293 - Train Loss: 0.110253, Train Acc: 0.819231 | Val Loss: 0.129442, Val Acc: 0.752577\n",
      "Epoch 12294 - Train Loss: 0.110247, Train Acc: 0.819231 | Val Loss: 0.129437, Val Acc: 0.752577\n",
      "Epoch 12295 - Train Loss: 0.110241, Train Acc: 0.819231 | Val Loss: 0.129433, Val Acc: 0.752577\n",
      "Epoch 12296 - Train Loss: 0.110235, Train Acc: 0.819231 | Val Loss: 0.129428, Val Acc: 0.752577\n",
      "Epoch 12297 - Train Loss: 0.110229, Train Acc: 0.819231 | Val Loss: 0.129423, Val Acc: 0.752577\n",
      "Epoch 12298 - Train Loss: 0.110223, Train Acc: 0.819231 | Val Loss: 0.129419, Val Acc: 0.752577\n",
      "Epoch 12299 - Train Loss: 0.110217, Train Acc: 0.819231 | Val Loss: 0.129414, Val Acc: 0.752577\n",
      "Epoch 12300 - Train Loss: 0.110211, Train Acc: 0.819231 | Val Loss: 0.129410, Val Acc: 0.752577\n",
      "Epoch 12301 - Train Loss: 0.110205, Train Acc: 0.819231 | Val Loss: 0.129405, Val Acc: 0.752577\n",
      "Epoch 12302 - Train Loss: 0.110199, Train Acc: 0.819231 | Val Loss: 0.129400, Val Acc: 0.752577\n",
      "Epoch 12303 - Train Loss: 0.110193, Train Acc: 0.819231 | Val Loss: 0.129396, Val Acc: 0.752577\n",
      "Epoch 12304 - Train Loss: 0.110187, Train Acc: 0.819231 | Val Loss: 0.129391, Val Acc: 0.752577\n",
      "Epoch 12305 - Train Loss: 0.110181, Train Acc: 0.819231 | Val Loss: 0.129387, Val Acc: 0.752577\n",
      "Epoch 12306 - Train Loss: 0.110175, Train Acc: 0.819231 | Val Loss: 0.129382, Val Acc: 0.752577\n",
      "Epoch 12307 - Train Loss: 0.110170, Train Acc: 0.819231 | Val Loss: 0.129377, Val Acc: 0.752577\n",
      "Epoch 12308 - Train Loss: 0.110164, Train Acc: 0.819231 | Val Loss: 0.129373, Val Acc: 0.752577\n",
      "Epoch 12309 - Train Loss: 0.110158, Train Acc: 0.819231 | Val Loss: 0.129368, Val Acc: 0.752577\n",
      "Epoch 12310 - Train Loss: 0.110152, Train Acc: 0.819231 | Val Loss: 0.129364, Val Acc: 0.752577\n",
      "Epoch 12311 - Train Loss: 0.110146, Train Acc: 0.819231 | Val Loss: 0.129359, Val Acc: 0.752577\n",
      "Epoch 12312 - Train Loss: 0.110140, Train Acc: 0.819231 | Val Loss: 0.129354, Val Acc: 0.752577\n",
      "Epoch 12313 - Train Loss: 0.110134, Train Acc: 0.819231 | Val Loss: 0.129350, Val Acc: 0.752577\n",
      "Epoch 12314 - Train Loss: 0.110128, Train Acc: 0.819231 | Val Loss: 0.129345, Val Acc: 0.752577\n",
      "Epoch 12315 - Train Loss: 0.110122, Train Acc: 0.819231 | Val Loss: 0.129341, Val Acc: 0.752577\n",
      "Epoch 12316 - Train Loss: 0.110116, Train Acc: 0.819231 | Val Loss: 0.129336, Val Acc: 0.752577\n",
      "Epoch 12317 - Train Loss: 0.110110, Train Acc: 0.819231 | Val Loss: 0.129331, Val Acc: 0.752577\n",
      "Epoch 12318 - Train Loss: 0.110104, Train Acc: 0.819231 | Val Loss: 0.129327, Val Acc: 0.752577\n",
      "Epoch 12319 - Train Loss: 0.110098, Train Acc: 0.819231 | Val Loss: 0.129322, Val Acc: 0.752577\n",
      "Epoch 12320 - Train Loss: 0.110092, Train Acc: 0.819231 | Val Loss: 0.129318, Val Acc: 0.752577\n",
      "Epoch 12321 - Train Loss: 0.110086, Train Acc: 0.819231 | Val Loss: 0.129313, Val Acc: 0.752577\n",
      "Epoch 12322 - Train Loss: 0.110080, Train Acc: 0.819231 | Val Loss: 0.129308, Val Acc: 0.752577\n",
      "Epoch 12323 - Train Loss: 0.110074, Train Acc: 0.819231 | Val Loss: 0.129304, Val Acc: 0.752577\n",
      "Epoch 12324 - Train Loss: 0.110068, Train Acc: 0.819231 | Val Loss: 0.129299, Val Acc: 0.752577\n",
      "Epoch 12325 - Train Loss: 0.110062, Train Acc: 0.820513 | Val Loss: 0.129295, Val Acc: 0.752577\n",
      "Epoch 12326 - Train Loss: 0.110056, Train Acc: 0.820513 | Val Loss: 0.129290, Val Acc: 0.752577\n",
      "Epoch 12327 - Train Loss: 0.110050, Train Acc: 0.820513 | Val Loss: 0.129286, Val Acc: 0.752577\n",
      "Epoch 12328 - Train Loss: 0.110044, Train Acc: 0.820513 | Val Loss: 0.129281, Val Acc: 0.752577\n",
      "Epoch 12329 - Train Loss: 0.110038, Train Acc: 0.820513 | Val Loss: 0.129276, Val Acc: 0.752577\n",
      "Epoch 12330 - Train Loss: 0.110032, Train Acc: 0.820513 | Val Loss: 0.129272, Val Acc: 0.752577\n",
      "Epoch 12331 - Train Loss: 0.110027, Train Acc: 0.820513 | Val Loss: 0.129267, Val Acc: 0.752577\n",
      "Epoch 12332 - Train Loss: 0.110021, Train Acc: 0.820513 | Val Loss: 0.129263, Val Acc: 0.752577\n",
      "Epoch 12333 - Train Loss: 0.110015, Train Acc: 0.820513 | Val Loss: 0.129258, Val Acc: 0.752577\n",
      "Epoch 12334 - Train Loss: 0.110009, Train Acc: 0.820513 | Val Loss: 0.129253, Val Acc: 0.752577\n",
      "Epoch 12335 - Train Loss: 0.110003, Train Acc: 0.820513 | Val Loss: 0.129249, Val Acc: 0.752577\n",
      "Epoch 12336 - Train Loss: 0.109997, Train Acc: 0.820513 | Val Loss: 0.129244, Val Acc: 0.752577\n",
      "Epoch 12337 - Train Loss: 0.109991, Train Acc: 0.820513 | Val Loss: 0.129240, Val Acc: 0.752577\n",
      "Epoch 12338 - Train Loss: 0.109985, Train Acc: 0.820513 | Val Loss: 0.129235, Val Acc: 0.752577\n",
      "Epoch 12339 - Train Loss: 0.109979, Train Acc: 0.820513 | Val Loss: 0.129231, Val Acc: 0.752577\n",
      "Epoch 12340 - Train Loss: 0.109973, Train Acc: 0.820513 | Val Loss: 0.129226, Val Acc: 0.752577\n",
      "Epoch 12341 - Train Loss: 0.109967, Train Acc: 0.820513 | Val Loss: 0.129221, Val Acc: 0.752577\n",
      "Epoch 12342 - Train Loss: 0.109961, Train Acc: 0.820513 | Val Loss: 0.129217, Val Acc: 0.752577\n",
      "Epoch 12343 - Train Loss: 0.109955, Train Acc: 0.820513 | Val Loss: 0.129212, Val Acc: 0.752577\n",
      "Epoch 12344 - Train Loss: 0.109949, Train Acc: 0.820513 | Val Loss: 0.129208, Val Acc: 0.752577\n",
      "Epoch 12345 - Train Loss: 0.109943, Train Acc: 0.820513 | Val Loss: 0.129203, Val Acc: 0.752577\n",
      "Epoch 12346 - Train Loss: 0.109937, Train Acc: 0.820513 | Val Loss: 0.129199, Val Acc: 0.752577\n",
      "Epoch 12347 - Train Loss: 0.109931, Train Acc: 0.820513 | Val Loss: 0.129194, Val Acc: 0.752577\n",
      "Epoch 12348 - Train Loss: 0.109926, Train Acc: 0.820513 | Val Loss: 0.129189, Val Acc: 0.752577\n",
      "Epoch 12349 - Train Loss: 0.109920, Train Acc: 0.820513 | Val Loss: 0.129185, Val Acc: 0.752577\n",
      "Epoch 12350 - Train Loss: 0.109914, Train Acc: 0.820513 | Val Loss: 0.129180, Val Acc: 0.752577\n",
      "Epoch 12351 - Train Loss: 0.109908, Train Acc: 0.820513 | Val Loss: 0.129176, Val Acc: 0.752577\n",
      "Epoch 12352 - Train Loss: 0.109902, Train Acc: 0.820513 | Val Loss: 0.129171, Val Acc: 0.752577\n",
      "Epoch 12353 - Train Loss: 0.109896, Train Acc: 0.820513 | Val Loss: 0.129167, Val Acc: 0.752577\n",
      "Epoch 12354 - Train Loss: 0.109890, Train Acc: 0.820513 | Val Loss: 0.129162, Val Acc: 0.752577\n",
      "Epoch 12355 - Train Loss: 0.109884, Train Acc: 0.820513 | Val Loss: 0.129157, Val Acc: 0.752577\n",
      "Epoch 12356 - Train Loss: 0.109878, Train Acc: 0.820513 | Val Loss: 0.129153, Val Acc: 0.752577\n",
      "Epoch 12357 - Train Loss: 0.109872, Train Acc: 0.820513 | Val Loss: 0.129148, Val Acc: 0.752577\n",
      "Epoch 12358 - Train Loss: 0.109866, Train Acc: 0.820513 | Val Loss: 0.129144, Val Acc: 0.752577\n",
      "Epoch 12359 - Train Loss: 0.109860, Train Acc: 0.820513 | Val Loss: 0.129139, Val Acc: 0.752577\n",
      "Epoch 12360 - Train Loss: 0.109854, Train Acc: 0.820513 | Val Loss: 0.129135, Val Acc: 0.752577\n",
      "Epoch 12361 - Train Loss: 0.109848, Train Acc: 0.820513 | Val Loss: 0.129130, Val Acc: 0.752577\n",
      "Epoch 12362 - Train Loss: 0.109843, Train Acc: 0.820513 | Val Loss: 0.129126, Val Acc: 0.752577\n",
      "Epoch 12363 - Train Loss: 0.109837, Train Acc: 0.820513 | Val Loss: 0.129121, Val Acc: 0.752577\n",
      "Epoch 12364 - Train Loss: 0.109831, Train Acc: 0.820513 | Val Loss: 0.129116, Val Acc: 0.752577\n",
      "Epoch 12365 - Train Loss: 0.109825, Train Acc: 0.820513 | Val Loss: 0.129112, Val Acc: 0.752577\n",
      "Epoch 12366 - Train Loss: 0.109819, Train Acc: 0.820513 | Val Loss: 0.129107, Val Acc: 0.752577\n",
      "Epoch 12367 - Train Loss: 0.109813, Train Acc: 0.820513 | Val Loss: 0.129103, Val Acc: 0.752577\n",
      "Epoch 12368 - Train Loss: 0.109807, Train Acc: 0.820513 | Val Loss: 0.129098, Val Acc: 0.752577\n",
      "Epoch 12369 - Train Loss: 0.109801, Train Acc: 0.820513 | Val Loss: 0.129094, Val Acc: 0.752577\n",
      "Epoch 12370 - Train Loss: 0.109795, Train Acc: 0.820513 | Val Loss: 0.129089, Val Acc: 0.752577\n",
      "Epoch 12371 - Train Loss: 0.109789, Train Acc: 0.820513 | Val Loss: 0.129085, Val Acc: 0.752577\n",
      "Epoch 12372 - Train Loss: 0.109783, Train Acc: 0.820513 | Val Loss: 0.129080, Val Acc: 0.752577\n",
      "Epoch 12373 - Train Loss: 0.109777, Train Acc: 0.820513 | Val Loss: 0.129075, Val Acc: 0.752577\n",
      "Epoch 12374 - Train Loss: 0.109772, Train Acc: 0.820513 | Val Loss: 0.129071, Val Acc: 0.752577\n",
      "Epoch 12375 - Train Loss: 0.109766, Train Acc: 0.820513 | Val Loss: 0.129066, Val Acc: 0.752577\n",
      "Epoch 12376 - Train Loss: 0.109760, Train Acc: 0.820513 | Val Loss: 0.129062, Val Acc: 0.752577\n",
      "Epoch 12377 - Train Loss: 0.109754, Train Acc: 0.820513 | Val Loss: 0.129057, Val Acc: 0.752577\n",
      "Epoch 12378 - Train Loss: 0.109748, Train Acc: 0.820513 | Val Loss: 0.129053, Val Acc: 0.752577\n",
      "Epoch 12379 - Train Loss: 0.109742, Train Acc: 0.820513 | Val Loss: 0.129048, Val Acc: 0.752577\n",
      "Epoch 12380 - Train Loss: 0.109736, Train Acc: 0.820513 | Val Loss: 0.129044, Val Acc: 0.752577\n",
      "Epoch 12381 - Train Loss: 0.109730, Train Acc: 0.820513 | Val Loss: 0.129039, Val Acc: 0.752577\n",
      "Epoch 12382 - Train Loss: 0.109724, Train Acc: 0.820513 | Val Loss: 0.129035, Val Acc: 0.752577\n",
      "Epoch 12383 - Train Loss: 0.109718, Train Acc: 0.820513 | Val Loss: 0.129030, Val Acc: 0.752577\n",
      "Epoch 12384 - Train Loss: 0.109712, Train Acc: 0.820513 | Val Loss: 0.129026, Val Acc: 0.752577\n",
      "Epoch 12385 - Train Loss: 0.109707, Train Acc: 0.820513 | Val Loss: 0.129021, Val Acc: 0.752577\n",
      "Epoch 12386 - Train Loss: 0.109701, Train Acc: 0.820513 | Val Loss: 0.129016, Val Acc: 0.752577\n",
      "Epoch 12387 - Train Loss: 0.109695, Train Acc: 0.820513 | Val Loss: 0.129012, Val Acc: 0.752577\n",
      "Epoch 12388 - Train Loss: 0.109689, Train Acc: 0.820513 | Val Loss: 0.129007, Val Acc: 0.752577\n",
      "Epoch 12389 - Train Loss: 0.109683, Train Acc: 0.820513 | Val Loss: 0.129003, Val Acc: 0.752577\n",
      "Epoch 12390 - Train Loss: 0.109677, Train Acc: 0.820513 | Val Loss: 0.128998, Val Acc: 0.752577\n",
      "Epoch 12391 - Train Loss: 0.109671, Train Acc: 0.820513 | Val Loss: 0.128994, Val Acc: 0.752577\n",
      "Epoch 12392 - Train Loss: 0.109665, Train Acc: 0.820513 | Val Loss: 0.128989, Val Acc: 0.752577\n",
      "Epoch 12393 - Train Loss: 0.109659, Train Acc: 0.820513 | Val Loss: 0.128985, Val Acc: 0.752577\n",
      "Epoch 12394 - Train Loss: 0.109654, Train Acc: 0.821795 | Val Loss: 0.128980, Val Acc: 0.752577\n",
      "Epoch 12395 - Train Loss: 0.109648, Train Acc: 0.821795 | Val Loss: 0.128976, Val Acc: 0.752577\n",
      "Epoch 12396 - Train Loss: 0.109642, Train Acc: 0.821795 | Val Loss: 0.128971, Val Acc: 0.752577\n",
      "Epoch 12397 - Train Loss: 0.109636, Train Acc: 0.821795 | Val Loss: 0.128967, Val Acc: 0.752577\n",
      "Epoch 12398 - Train Loss: 0.109630, Train Acc: 0.821795 | Val Loss: 0.128962, Val Acc: 0.752577\n",
      "Epoch 12399 - Train Loss: 0.109624, Train Acc: 0.821795 | Val Loss: 0.128958, Val Acc: 0.752577\n",
      "Epoch 12400 - Train Loss: 0.109618, Train Acc: 0.821795 | Val Loss: 0.128953, Val Acc: 0.752577\n",
      "Epoch 12401 - Train Loss: 0.109612, Train Acc: 0.821795 | Val Loss: 0.128948, Val Acc: 0.752577\n",
      "Epoch 12402 - Train Loss: 0.109606, Train Acc: 0.821795 | Val Loss: 0.128944, Val Acc: 0.752577\n",
      "Epoch 12403 - Train Loss: 0.109601, Train Acc: 0.821795 | Val Loss: 0.128939, Val Acc: 0.752577\n",
      "Epoch 12404 - Train Loss: 0.109595, Train Acc: 0.821795 | Val Loss: 0.128935, Val Acc: 0.752577\n",
      "Epoch 12405 - Train Loss: 0.109589, Train Acc: 0.821795 | Val Loss: 0.128930, Val Acc: 0.752577\n",
      "Epoch 12406 - Train Loss: 0.109583, Train Acc: 0.821795 | Val Loss: 0.128926, Val Acc: 0.752577\n",
      "Epoch 12407 - Train Loss: 0.109577, Train Acc: 0.821795 | Val Loss: 0.128921, Val Acc: 0.752577\n",
      "Epoch 12408 - Train Loss: 0.109571, Train Acc: 0.821795 | Val Loss: 0.128917, Val Acc: 0.752577\n",
      "Epoch 12409 - Train Loss: 0.109565, Train Acc: 0.821795 | Val Loss: 0.128912, Val Acc: 0.752577\n",
      "Epoch 12410 - Train Loss: 0.109559, Train Acc: 0.821795 | Val Loss: 0.128908, Val Acc: 0.752577\n",
      "Epoch 12411 - Train Loss: 0.109554, Train Acc: 0.821795 | Val Loss: 0.128903, Val Acc: 0.752577\n",
      "Epoch 12412 - Train Loss: 0.109548, Train Acc: 0.821795 | Val Loss: 0.128899, Val Acc: 0.752577\n",
      "Epoch 12413 - Train Loss: 0.109542, Train Acc: 0.821795 | Val Loss: 0.128894, Val Acc: 0.752577\n",
      "Epoch 12414 - Train Loss: 0.109536, Train Acc: 0.821795 | Val Loss: 0.128890, Val Acc: 0.752577\n",
      "Epoch 12415 - Train Loss: 0.109530, Train Acc: 0.821795 | Val Loss: 0.128885, Val Acc: 0.752577\n",
      "Epoch 12416 - Train Loss: 0.109524, Train Acc: 0.821795 | Val Loss: 0.128881, Val Acc: 0.752577\n",
      "Epoch 12417 - Train Loss: 0.109518, Train Acc: 0.821795 | Val Loss: 0.128876, Val Acc: 0.752577\n",
      "Epoch 12418 - Train Loss: 0.109512, Train Acc: 0.821795 | Val Loss: 0.128872, Val Acc: 0.752577\n",
      "Epoch 12419 - Train Loss: 0.109507, Train Acc: 0.821795 | Val Loss: 0.128867, Val Acc: 0.752577\n",
      "Epoch 12420 - Train Loss: 0.109501, Train Acc: 0.821795 | Val Loss: 0.128863, Val Acc: 0.752577\n",
      "Epoch 12421 - Train Loss: 0.109495, Train Acc: 0.821795 | Val Loss: 0.128858, Val Acc: 0.752577\n",
      "Epoch 12422 - Train Loss: 0.109489, Train Acc: 0.821795 | Val Loss: 0.128854, Val Acc: 0.752577\n",
      "Epoch 12423 - Train Loss: 0.109483, Train Acc: 0.821795 | Val Loss: 0.128849, Val Acc: 0.752577\n",
      "Epoch 12424 - Train Loss: 0.109477, Train Acc: 0.821795 | Val Loss: 0.128844, Val Acc: 0.752577\n",
      "Epoch 12425 - Train Loss: 0.109471, Train Acc: 0.821795 | Val Loss: 0.128840, Val Acc: 0.752577\n",
      "Epoch 12426 - Train Loss: 0.109466, Train Acc: 0.821795 | Val Loss: 0.128835, Val Acc: 0.752577\n",
      "Epoch 12427 - Train Loss: 0.109460, Train Acc: 0.821795 | Val Loss: 0.128831, Val Acc: 0.752577\n",
      "Epoch 12428 - Train Loss: 0.109454, Train Acc: 0.821795 | Val Loss: 0.128826, Val Acc: 0.752577\n",
      "Epoch 12429 - Train Loss: 0.109448, Train Acc: 0.821795 | Val Loss: 0.128822, Val Acc: 0.752577\n",
      "Epoch 12430 - Train Loss: 0.109442, Train Acc: 0.821795 | Val Loss: 0.128817, Val Acc: 0.752577\n",
      "Epoch 12431 - Train Loss: 0.109436, Train Acc: 0.821795 | Val Loss: 0.128813, Val Acc: 0.752577\n",
      "Epoch 12432 - Train Loss: 0.109430, Train Acc: 0.821795 | Val Loss: 0.128808, Val Acc: 0.752577\n",
      "Epoch 12433 - Train Loss: 0.109425, Train Acc: 0.821795 | Val Loss: 0.128804, Val Acc: 0.752577\n",
      "Epoch 12434 - Train Loss: 0.109419, Train Acc: 0.821795 | Val Loss: 0.128799, Val Acc: 0.752577\n",
      "Epoch 12435 - Train Loss: 0.109413, Train Acc: 0.821795 | Val Loss: 0.128795, Val Acc: 0.752577\n",
      "Epoch 12436 - Train Loss: 0.109407, Train Acc: 0.821795 | Val Loss: 0.128790, Val Acc: 0.752577\n",
      "Epoch 12437 - Train Loss: 0.109401, Train Acc: 0.821795 | Val Loss: 0.128786, Val Acc: 0.752577\n",
      "Epoch 12438 - Train Loss: 0.109395, Train Acc: 0.821795 | Val Loss: 0.128781, Val Acc: 0.752577\n",
      "Epoch 12439 - Train Loss: 0.109389, Train Acc: 0.821795 | Val Loss: 0.128777, Val Acc: 0.752577\n",
      "Epoch 12440 - Train Loss: 0.109384, Train Acc: 0.821795 | Val Loss: 0.128772, Val Acc: 0.752577\n",
      "Epoch 12441 - Train Loss: 0.109378, Train Acc: 0.821795 | Val Loss: 0.128768, Val Acc: 0.752577\n",
      "Epoch 12442 - Train Loss: 0.109372, Train Acc: 0.821795 | Val Loss: 0.128763, Val Acc: 0.752577\n",
      "Epoch 12443 - Train Loss: 0.109366, Train Acc: 0.821795 | Val Loss: 0.128759, Val Acc: 0.752577\n",
      "Epoch 12444 - Train Loss: 0.109360, Train Acc: 0.821795 | Val Loss: 0.128754, Val Acc: 0.752577\n",
      "Epoch 12445 - Train Loss: 0.109354, Train Acc: 0.821795 | Val Loss: 0.128750, Val Acc: 0.752577\n",
      "Epoch 12446 - Train Loss: 0.109348, Train Acc: 0.821795 | Val Loss: 0.128745, Val Acc: 0.752577\n",
      "Epoch 12447 - Train Loss: 0.109343, Train Acc: 0.821795 | Val Loss: 0.128741, Val Acc: 0.752577\n",
      "Epoch 12448 - Train Loss: 0.109337, Train Acc: 0.821795 | Val Loss: 0.128736, Val Acc: 0.752577\n",
      "Epoch 12449 - Train Loss: 0.109331, Train Acc: 0.821795 | Val Loss: 0.128732, Val Acc: 0.752577\n",
      "Epoch 12450 - Train Loss: 0.109325, Train Acc: 0.821795 | Val Loss: 0.128727, Val Acc: 0.752577\n",
      "Epoch 12451 - Train Loss: 0.109319, Train Acc: 0.821795 | Val Loss: 0.128723, Val Acc: 0.752577\n",
      "Epoch 12452 - Train Loss: 0.109313, Train Acc: 0.821795 | Val Loss: 0.128718, Val Acc: 0.752577\n",
      "Epoch 12453 - Train Loss: 0.109308, Train Acc: 0.821795 | Val Loss: 0.128714, Val Acc: 0.752577\n",
      "Epoch 12454 - Train Loss: 0.109302, Train Acc: 0.821795 | Val Loss: 0.128709, Val Acc: 0.752577\n",
      "Epoch 12455 - Train Loss: 0.109296, Train Acc: 0.821795 | Val Loss: 0.128705, Val Acc: 0.752577\n",
      "Epoch 12456 - Train Loss: 0.109290, Train Acc: 0.821795 | Val Loss: 0.128701, Val Acc: 0.752577\n",
      "Epoch 12457 - Train Loss: 0.109284, Train Acc: 0.821795 | Val Loss: 0.128696, Val Acc: 0.752577\n",
      "Epoch 12458 - Train Loss: 0.109278, Train Acc: 0.821795 | Val Loss: 0.128692, Val Acc: 0.752577\n",
      "Epoch 12459 - Train Loss: 0.109273, Train Acc: 0.821795 | Val Loss: 0.128687, Val Acc: 0.752577\n",
      "Epoch 12460 - Train Loss: 0.109267, Train Acc: 0.821795 | Val Loss: 0.128683, Val Acc: 0.752577\n",
      "Epoch 12461 - Train Loss: 0.109261, Train Acc: 0.821795 | Val Loss: 0.128678, Val Acc: 0.752577\n",
      "Epoch 12462 - Train Loss: 0.109255, Train Acc: 0.821795 | Val Loss: 0.128674, Val Acc: 0.752577\n",
      "Epoch 12463 - Train Loss: 0.109249, Train Acc: 0.821795 | Val Loss: 0.128669, Val Acc: 0.752577\n",
      "Epoch 12464 - Train Loss: 0.109243, Train Acc: 0.821795 | Val Loss: 0.128665, Val Acc: 0.752577\n",
      "Epoch 12465 - Train Loss: 0.109238, Train Acc: 0.821795 | Val Loss: 0.128660, Val Acc: 0.752577\n",
      "Epoch 12466 - Train Loss: 0.109232, Train Acc: 0.821795 | Val Loss: 0.128656, Val Acc: 0.752577\n",
      "Epoch 12467 - Train Loss: 0.109226, Train Acc: 0.821795 | Val Loss: 0.128651, Val Acc: 0.752577\n",
      "Epoch 12468 - Train Loss: 0.109220, Train Acc: 0.821795 | Val Loss: 0.128647, Val Acc: 0.752577\n",
      "Epoch 12469 - Train Loss: 0.109214, Train Acc: 0.821795 | Val Loss: 0.128642, Val Acc: 0.752577\n",
      "Epoch 12470 - Train Loss: 0.109208, Train Acc: 0.823077 | Val Loss: 0.128638, Val Acc: 0.752577\n",
      "Epoch 12471 - Train Loss: 0.109203, Train Acc: 0.823077 | Val Loss: 0.128633, Val Acc: 0.752577\n",
      "Epoch 12472 - Train Loss: 0.109197, Train Acc: 0.823077 | Val Loss: 0.128629, Val Acc: 0.752577\n",
      "Epoch 12473 - Train Loss: 0.109191, Train Acc: 0.823077 | Val Loss: 0.128624, Val Acc: 0.752577\n",
      "Epoch 12474 - Train Loss: 0.109185, Train Acc: 0.823077 | Val Loss: 0.128620, Val Acc: 0.752577\n",
      "Epoch 12475 - Train Loss: 0.109179, Train Acc: 0.823077 | Val Loss: 0.128615, Val Acc: 0.752577\n",
      "Epoch 12476 - Train Loss: 0.109173, Train Acc: 0.823077 | Val Loss: 0.128611, Val Acc: 0.752577\n",
      "Epoch 12477 - Train Loss: 0.109168, Train Acc: 0.823077 | Val Loss: 0.128607, Val Acc: 0.752577\n",
      "Epoch 12478 - Train Loss: 0.109162, Train Acc: 0.823077 | Val Loss: 0.128602, Val Acc: 0.752577\n",
      "Epoch 12479 - Train Loss: 0.109156, Train Acc: 0.823077 | Val Loss: 0.128598, Val Acc: 0.752577\n",
      "Epoch 12480 - Train Loss: 0.109150, Train Acc: 0.823077 | Val Loss: 0.128593, Val Acc: 0.752577\n",
      "Epoch 12481 - Train Loss: 0.109144, Train Acc: 0.823077 | Val Loss: 0.128589, Val Acc: 0.752577\n",
      "Epoch 12482 - Train Loss: 0.109139, Train Acc: 0.823077 | Val Loss: 0.128584, Val Acc: 0.752577\n",
      "Epoch 12483 - Train Loss: 0.109133, Train Acc: 0.823077 | Val Loss: 0.128580, Val Acc: 0.752577\n",
      "Epoch 12484 - Train Loss: 0.109127, Train Acc: 0.823077 | Val Loss: 0.128575, Val Acc: 0.752577\n",
      "Epoch 12485 - Train Loss: 0.109121, Train Acc: 0.823077 | Val Loss: 0.128571, Val Acc: 0.752577\n",
      "Epoch 12486 - Train Loss: 0.109115, Train Acc: 0.823077 | Val Loss: 0.128566, Val Acc: 0.752577\n",
      "Epoch 12487 - Train Loss: 0.109109, Train Acc: 0.823077 | Val Loss: 0.128562, Val Acc: 0.752577\n",
      "Epoch 12488 - Train Loss: 0.109104, Train Acc: 0.823077 | Val Loss: 0.128557, Val Acc: 0.752577\n",
      "Epoch 12489 - Train Loss: 0.109098, Train Acc: 0.823077 | Val Loss: 0.128553, Val Acc: 0.752577\n",
      "Epoch 12490 - Train Loss: 0.109092, Train Acc: 0.823077 | Val Loss: 0.128549, Val Acc: 0.752577\n",
      "Epoch 12491 - Train Loss: 0.109086, Train Acc: 0.823077 | Val Loss: 0.128544, Val Acc: 0.752577\n",
      "Epoch 12492 - Train Loss: 0.109080, Train Acc: 0.823077 | Val Loss: 0.128540, Val Acc: 0.752577\n",
      "Epoch 12493 - Train Loss: 0.109075, Train Acc: 0.823077 | Val Loss: 0.128535, Val Acc: 0.752577\n",
      "Epoch 12494 - Train Loss: 0.109069, Train Acc: 0.823077 | Val Loss: 0.128531, Val Acc: 0.752577\n",
      "Epoch 12495 - Train Loss: 0.109063, Train Acc: 0.823077 | Val Loss: 0.128526, Val Acc: 0.752577\n",
      "Epoch 12496 - Train Loss: 0.109057, Train Acc: 0.823077 | Val Loss: 0.128522, Val Acc: 0.752577\n",
      "Epoch 12497 - Train Loss: 0.109051, Train Acc: 0.823077 | Val Loss: 0.128517, Val Acc: 0.752577\n",
      "Epoch 12498 - Train Loss: 0.109046, Train Acc: 0.823077 | Val Loss: 0.128513, Val Acc: 0.752577\n",
      "Epoch 12499 - Train Loss: 0.109040, Train Acc: 0.823077 | Val Loss: 0.128509, Val Acc: 0.752577\n",
      "Epoch 12500 - Train Loss: 0.109034, Train Acc: 0.823077 | Val Loss: 0.128504, Val Acc: 0.752577\n",
      "Epoch 12501 - Train Loss: 0.109028, Train Acc: 0.823077 | Val Loss: 0.128500, Val Acc: 0.752577\n",
      "Epoch 12502 - Train Loss: 0.109022, Train Acc: 0.823077 | Val Loss: 0.128495, Val Acc: 0.752577\n",
      "Epoch 12503 - Train Loss: 0.109017, Train Acc: 0.823077 | Val Loss: 0.128491, Val Acc: 0.752577\n",
      "Epoch 12504 - Train Loss: 0.109011, Train Acc: 0.823077 | Val Loss: 0.128486, Val Acc: 0.752577\n",
      "Epoch 12505 - Train Loss: 0.109005, Train Acc: 0.823077 | Val Loss: 0.128482, Val Acc: 0.752577\n",
      "Epoch 12506 - Train Loss: 0.108999, Train Acc: 0.823077 | Val Loss: 0.128477, Val Acc: 0.752577\n",
      "Epoch 12507 - Train Loss: 0.108993, Train Acc: 0.823077 | Val Loss: 0.128473, Val Acc: 0.752577\n",
      "Epoch 12508 - Train Loss: 0.108988, Train Acc: 0.823077 | Val Loss: 0.128469, Val Acc: 0.752577\n",
      "Epoch 12509 - Train Loss: 0.108982, Train Acc: 0.823077 | Val Loss: 0.128464, Val Acc: 0.752577\n",
      "Epoch 12510 - Train Loss: 0.108976, Train Acc: 0.823077 | Val Loss: 0.128460, Val Acc: 0.752577\n",
      "Epoch 12511 - Train Loss: 0.108970, Train Acc: 0.823077 | Val Loss: 0.128455, Val Acc: 0.752577\n",
      "Epoch 12512 - Train Loss: 0.108964, Train Acc: 0.823077 | Val Loss: 0.128451, Val Acc: 0.752577\n",
      "Epoch 12513 - Train Loss: 0.108959, Train Acc: 0.823077 | Val Loss: 0.128446, Val Acc: 0.752577\n",
      "Epoch 12514 - Train Loss: 0.108953, Train Acc: 0.823077 | Val Loss: 0.128442, Val Acc: 0.752577\n",
      "Epoch 12515 - Train Loss: 0.108947, Train Acc: 0.823077 | Val Loss: 0.128437, Val Acc: 0.752577\n",
      "Epoch 12516 - Train Loss: 0.108941, Train Acc: 0.823077 | Val Loss: 0.128433, Val Acc: 0.752577\n",
      "Epoch 12517 - Train Loss: 0.108935, Train Acc: 0.823077 | Val Loss: 0.128429, Val Acc: 0.752577\n",
      "Epoch 12518 - Train Loss: 0.108930, Train Acc: 0.823077 | Val Loss: 0.128424, Val Acc: 0.752577\n",
      "Epoch 12519 - Train Loss: 0.108924, Train Acc: 0.823077 | Val Loss: 0.128420, Val Acc: 0.752577\n",
      "Epoch 12520 - Train Loss: 0.108918, Train Acc: 0.823077 | Val Loss: 0.128415, Val Acc: 0.752577\n",
      "Epoch 12521 - Train Loss: 0.108912, Train Acc: 0.823077 | Val Loss: 0.128411, Val Acc: 0.752577\n",
      "Epoch 12522 - Train Loss: 0.108907, Train Acc: 0.823077 | Val Loss: 0.128406, Val Acc: 0.752577\n",
      "Epoch 12523 - Train Loss: 0.108901, Train Acc: 0.823077 | Val Loss: 0.128402, Val Acc: 0.752577\n",
      "Epoch 12524 - Train Loss: 0.108895, Train Acc: 0.823077 | Val Loss: 0.128398, Val Acc: 0.752577\n",
      "Epoch 12525 - Train Loss: 0.108889, Train Acc: 0.823077 | Val Loss: 0.128393, Val Acc: 0.752577\n",
      "Epoch 12526 - Train Loss: 0.108883, Train Acc: 0.823077 | Val Loss: 0.128389, Val Acc: 0.752577\n",
      "Epoch 12527 - Train Loss: 0.108878, Train Acc: 0.823077 | Val Loss: 0.128384, Val Acc: 0.752577\n",
      "Epoch 12528 - Train Loss: 0.108872, Train Acc: 0.823077 | Val Loss: 0.128380, Val Acc: 0.752577\n",
      "Epoch 12529 - Train Loss: 0.108866, Train Acc: 0.823077 | Val Loss: 0.128376, Val Acc: 0.752577\n",
      "Epoch 12530 - Train Loss: 0.108860, Train Acc: 0.823077 | Val Loss: 0.128371, Val Acc: 0.752577\n",
      "Epoch 12531 - Train Loss: 0.108855, Train Acc: 0.823077 | Val Loss: 0.128367, Val Acc: 0.752577\n",
      "Epoch 12532 - Train Loss: 0.108849, Train Acc: 0.823077 | Val Loss: 0.128362, Val Acc: 0.752577\n",
      "Epoch 12533 - Train Loss: 0.108843, Train Acc: 0.823077 | Val Loss: 0.128358, Val Acc: 0.752577\n",
      "Epoch 12534 - Train Loss: 0.108837, Train Acc: 0.823077 | Val Loss: 0.128353, Val Acc: 0.752577\n",
      "Epoch 12535 - Train Loss: 0.108831, Train Acc: 0.823077 | Val Loss: 0.128349, Val Acc: 0.752577\n",
      "Epoch 12536 - Train Loss: 0.108826, Train Acc: 0.823077 | Val Loss: 0.128345, Val Acc: 0.752577\n",
      "Epoch 12537 - Train Loss: 0.108820, Train Acc: 0.823077 | Val Loss: 0.128340, Val Acc: 0.752577\n",
      "Epoch 12538 - Train Loss: 0.108814, Train Acc: 0.823077 | Val Loss: 0.128336, Val Acc: 0.752577\n",
      "Epoch 12539 - Train Loss: 0.108808, Train Acc: 0.823077 | Val Loss: 0.128331, Val Acc: 0.752577\n",
      "Epoch 12540 - Train Loss: 0.108803, Train Acc: 0.823077 | Val Loss: 0.128327, Val Acc: 0.752577\n",
      "Epoch 12541 - Train Loss: 0.108797, Train Acc: 0.823077 | Val Loss: 0.128323, Val Acc: 0.752577\n",
      "Epoch 12542 - Train Loss: 0.108791, Train Acc: 0.823077 | Val Loss: 0.128318, Val Acc: 0.752577\n",
      "Epoch 12543 - Train Loss: 0.108785, Train Acc: 0.823077 | Val Loss: 0.128314, Val Acc: 0.752577\n",
      "Epoch 12544 - Train Loss: 0.108780, Train Acc: 0.823077 | Val Loss: 0.128309, Val Acc: 0.752577\n",
      "Epoch 12545 - Train Loss: 0.108774, Train Acc: 0.823077 | Val Loss: 0.128305, Val Acc: 0.752577\n",
      "Epoch 12546 - Train Loss: 0.108768, Train Acc: 0.823077 | Val Loss: 0.128301, Val Acc: 0.752577\n",
      "Epoch 12547 - Train Loss: 0.108762, Train Acc: 0.823077 | Val Loss: 0.128296, Val Acc: 0.752577\n",
      "Epoch 12548 - Train Loss: 0.108756, Train Acc: 0.823077 | Val Loss: 0.128292, Val Acc: 0.752577\n",
      "Epoch 12549 - Train Loss: 0.108751, Train Acc: 0.823077 | Val Loss: 0.128287, Val Acc: 0.752577\n",
      "Epoch 12550 - Train Loss: 0.108745, Train Acc: 0.823077 | Val Loss: 0.128283, Val Acc: 0.752577\n",
      "Epoch 12551 - Train Loss: 0.108739, Train Acc: 0.823077 | Val Loss: 0.128279, Val Acc: 0.752577\n",
      "Epoch 12552 - Train Loss: 0.108733, Train Acc: 0.823077 | Val Loss: 0.128274, Val Acc: 0.752577\n",
      "Epoch 12553 - Train Loss: 0.108728, Train Acc: 0.823077 | Val Loss: 0.128270, Val Acc: 0.752577\n",
      "Epoch 12554 - Train Loss: 0.108722, Train Acc: 0.823077 | Val Loss: 0.128265, Val Acc: 0.752577\n",
      "Epoch 12555 - Train Loss: 0.108716, Train Acc: 0.823077 | Val Loss: 0.128261, Val Acc: 0.752577\n",
      "Epoch 12556 - Train Loss: 0.108710, Train Acc: 0.823077 | Val Loss: 0.128257, Val Acc: 0.752577\n",
      "Epoch 12557 - Train Loss: 0.108705, Train Acc: 0.823077 | Val Loss: 0.128252, Val Acc: 0.752577\n",
      "Epoch 12558 - Train Loss: 0.108699, Train Acc: 0.823077 | Val Loss: 0.128248, Val Acc: 0.752577\n",
      "Epoch 12559 - Train Loss: 0.108693, Train Acc: 0.823077 | Val Loss: 0.128243, Val Acc: 0.752577\n",
      "Epoch 12560 - Train Loss: 0.108687, Train Acc: 0.823077 | Val Loss: 0.128239, Val Acc: 0.752577\n",
      "Epoch 12561 - Train Loss: 0.108682, Train Acc: 0.823077 | Val Loss: 0.128235, Val Acc: 0.752577\n",
      "Epoch 12562 - Train Loss: 0.108676, Train Acc: 0.823077 | Val Loss: 0.128230, Val Acc: 0.752577\n",
      "Epoch 12563 - Train Loss: 0.108670, Train Acc: 0.823077 | Val Loss: 0.128226, Val Acc: 0.752577\n",
      "Epoch 12564 - Train Loss: 0.108664, Train Acc: 0.823077 | Val Loss: 0.128221, Val Acc: 0.752577\n",
      "Epoch 12565 - Train Loss: 0.108659, Train Acc: 0.823077 | Val Loss: 0.128217, Val Acc: 0.752577\n",
      "Epoch 12566 - Train Loss: 0.108653, Train Acc: 0.823077 | Val Loss: 0.128213, Val Acc: 0.752577\n",
      "Epoch 12567 - Train Loss: 0.108647, Train Acc: 0.823077 | Val Loss: 0.128208, Val Acc: 0.752577\n",
      "Epoch 12568 - Train Loss: 0.108641, Train Acc: 0.824359 | Val Loss: 0.128204, Val Acc: 0.752577\n",
      "Epoch 12569 - Train Loss: 0.108636, Train Acc: 0.824359 | Val Loss: 0.128199, Val Acc: 0.752577\n",
      "Epoch 12570 - Train Loss: 0.108630, Train Acc: 0.824359 | Val Loss: 0.128195, Val Acc: 0.752577\n",
      "Epoch 12571 - Train Loss: 0.108624, Train Acc: 0.824359 | Val Loss: 0.128191, Val Acc: 0.752577\n",
      "Epoch 12572 - Train Loss: 0.108618, Train Acc: 0.824359 | Val Loss: 0.128186, Val Acc: 0.752577\n",
      "Epoch 12573 - Train Loss: 0.108613, Train Acc: 0.824359 | Val Loss: 0.128182, Val Acc: 0.752577\n",
      "Epoch 12574 - Train Loss: 0.108607, Train Acc: 0.824359 | Val Loss: 0.128178, Val Acc: 0.752577\n",
      "Epoch 12575 - Train Loss: 0.108601, Train Acc: 0.824359 | Val Loss: 0.128173, Val Acc: 0.752577\n",
      "Epoch 12576 - Train Loss: 0.108595, Train Acc: 0.824359 | Val Loss: 0.128169, Val Acc: 0.752577\n",
      "Epoch 12577 - Train Loss: 0.108590, Train Acc: 0.824359 | Val Loss: 0.128164, Val Acc: 0.752577\n",
      "Epoch 12578 - Train Loss: 0.108584, Train Acc: 0.825641 | Val Loss: 0.128160, Val Acc: 0.752577\n",
      "Epoch 12579 - Train Loss: 0.108578, Train Acc: 0.825641 | Val Loss: 0.128156, Val Acc: 0.752577\n",
      "Epoch 12580 - Train Loss: 0.108573, Train Acc: 0.825641 | Val Loss: 0.128151, Val Acc: 0.752577\n",
      "Epoch 12581 - Train Loss: 0.108567, Train Acc: 0.825641 | Val Loss: 0.128147, Val Acc: 0.752577\n",
      "Epoch 12582 - Train Loss: 0.108561, Train Acc: 0.825641 | Val Loss: 0.128142, Val Acc: 0.752577\n",
      "Epoch 12583 - Train Loss: 0.108555, Train Acc: 0.825641 | Val Loss: 0.128138, Val Acc: 0.752577\n",
      "Epoch 12584 - Train Loss: 0.108550, Train Acc: 0.825641 | Val Loss: 0.128134, Val Acc: 0.752577\n",
      "Epoch 12585 - Train Loss: 0.108544, Train Acc: 0.825641 | Val Loss: 0.128129, Val Acc: 0.752577\n",
      "Epoch 12586 - Train Loss: 0.108538, Train Acc: 0.825641 | Val Loss: 0.128125, Val Acc: 0.752577\n",
      "Epoch 12587 - Train Loss: 0.108532, Train Acc: 0.825641 | Val Loss: 0.128121, Val Acc: 0.752577\n",
      "Epoch 12588 - Train Loss: 0.108527, Train Acc: 0.825641 | Val Loss: 0.128116, Val Acc: 0.752577\n",
      "Epoch 12589 - Train Loss: 0.108521, Train Acc: 0.825641 | Val Loss: 0.128112, Val Acc: 0.752577\n",
      "Epoch 12590 - Train Loss: 0.108515, Train Acc: 0.825641 | Val Loss: 0.128108, Val Acc: 0.752577\n",
      "Epoch 12591 - Train Loss: 0.108509, Train Acc: 0.825641 | Val Loss: 0.128103, Val Acc: 0.752577\n",
      "Epoch 12592 - Train Loss: 0.108504, Train Acc: 0.825641 | Val Loss: 0.128099, Val Acc: 0.752577\n",
      "Epoch 12593 - Train Loss: 0.108498, Train Acc: 0.825641 | Val Loss: 0.128094, Val Acc: 0.752577\n",
      "Epoch 12594 - Train Loss: 0.108492, Train Acc: 0.825641 | Val Loss: 0.128090, Val Acc: 0.752577\n",
      "Epoch 12595 - Train Loss: 0.108487, Train Acc: 0.825641 | Val Loss: 0.128086, Val Acc: 0.752577\n",
      "Epoch 12596 - Train Loss: 0.108481, Train Acc: 0.825641 | Val Loss: 0.128081, Val Acc: 0.752577\n",
      "Epoch 12597 - Train Loss: 0.108475, Train Acc: 0.825641 | Val Loss: 0.128077, Val Acc: 0.752577\n",
      "Epoch 12598 - Train Loss: 0.108469, Train Acc: 0.825641 | Val Loss: 0.128073, Val Acc: 0.752577\n",
      "Epoch 12599 - Train Loss: 0.108464, Train Acc: 0.825641 | Val Loss: 0.128068, Val Acc: 0.752577\n",
      "Epoch 12600 - Train Loss: 0.108458, Train Acc: 0.825641 | Val Loss: 0.128064, Val Acc: 0.752577\n",
      "Epoch 12601 - Train Loss: 0.108452, Train Acc: 0.825641 | Val Loss: 0.128060, Val Acc: 0.752577\n",
      "Epoch 12602 - Train Loss: 0.108447, Train Acc: 0.825641 | Val Loss: 0.128055, Val Acc: 0.752577\n",
      "Epoch 12603 - Train Loss: 0.108441, Train Acc: 0.825641 | Val Loss: 0.128051, Val Acc: 0.752577\n",
      "Epoch 12604 - Train Loss: 0.108435, Train Acc: 0.825641 | Val Loss: 0.128046, Val Acc: 0.752577\n",
      "Epoch 12605 - Train Loss: 0.108429, Train Acc: 0.825641 | Val Loss: 0.128042, Val Acc: 0.752577\n",
      "Epoch 12606 - Train Loss: 0.108424, Train Acc: 0.825641 | Val Loss: 0.128038, Val Acc: 0.752577\n",
      "Epoch 12607 - Train Loss: 0.108418, Train Acc: 0.825641 | Val Loss: 0.128033, Val Acc: 0.752577\n",
      "Epoch 12608 - Train Loss: 0.108412, Train Acc: 0.825641 | Val Loss: 0.128029, Val Acc: 0.752577\n",
      "Epoch 12609 - Train Loss: 0.108407, Train Acc: 0.825641 | Val Loss: 0.128025, Val Acc: 0.752577\n",
      "Epoch 12610 - Train Loss: 0.108401, Train Acc: 0.825641 | Val Loss: 0.128020, Val Acc: 0.752577\n",
      "Epoch 12611 - Train Loss: 0.108395, Train Acc: 0.825641 | Val Loss: 0.128016, Val Acc: 0.752577\n",
      "Epoch 12612 - Train Loss: 0.108389, Train Acc: 0.825641 | Val Loss: 0.128012, Val Acc: 0.752577\n",
      "Epoch 12613 - Train Loss: 0.108384, Train Acc: 0.825641 | Val Loss: 0.128007, Val Acc: 0.752577\n",
      "Epoch 12614 - Train Loss: 0.108378, Train Acc: 0.825641 | Val Loss: 0.128003, Val Acc: 0.752577\n",
      "Epoch 12615 - Train Loss: 0.108372, Train Acc: 0.825641 | Val Loss: 0.127999, Val Acc: 0.752577\n",
      "Epoch 12616 - Train Loss: 0.108367, Train Acc: 0.825641 | Val Loss: 0.127994, Val Acc: 0.752577\n",
      "Epoch 12617 - Train Loss: 0.108361, Train Acc: 0.825641 | Val Loss: 0.127990, Val Acc: 0.752577\n",
      "Epoch 12618 - Train Loss: 0.108355, Train Acc: 0.825641 | Val Loss: 0.127986, Val Acc: 0.752577\n",
      "Epoch 12619 - Train Loss: 0.108349, Train Acc: 0.825641 | Val Loss: 0.127981, Val Acc: 0.752577\n",
      "Epoch 12620 - Train Loss: 0.108344, Train Acc: 0.825641 | Val Loss: 0.127977, Val Acc: 0.752577\n",
      "Epoch 12621 - Train Loss: 0.108338, Train Acc: 0.825641 | Val Loss: 0.127973, Val Acc: 0.752577\n",
      "Epoch 12622 - Train Loss: 0.108332, Train Acc: 0.825641 | Val Loss: 0.127968, Val Acc: 0.752577\n",
      "Epoch 12623 - Train Loss: 0.108327, Train Acc: 0.825641 | Val Loss: 0.127964, Val Acc: 0.752577\n",
      "Epoch 12624 - Train Loss: 0.108321, Train Acc: 0.825641 | Val Loss: 0.127960, Val Acc: 0.752577\n",
      "Epoch 12625 - Train Loss: 0.108315, Train Acc: 0.825641 | Val Loss: 0.127955, Val Acc: 0.752577\n",
      "Epoch 12626 - Train Loss: 0.108310, Train Acc: 0.825641 | Val Loss: 0.127951, Val Acc: 0.752577\n",
      "Epoch 12627 - Train Loss: 0.108304, Train Acc: 0.825641 | Val Loss: 0.127946, Val Acc: 0.752577\n",
      "Epoch 12628 - Train Loss: 0.108298, Train Acc: 0.825641 | Val Loss: 0.127942, Val Acc: 0.752577\n",
      "Epoch 12629 - Train Loss: 0.108292, Train Acc: 0.825641 | Val Loss: 0.127938, Val Acc: 0.752577\n",
      "Epoch 12630 - Train Loss: 0.108287, Train Acc: 0.825641 | Val Loss: 0.127933, Val Acc: 0.752577\n",
      "Epoch 12631 - Train Loss: 0.108281, Train Acc: 0.825641 | Val Loss: 0.127929, Val Acc: 0.752577\n",
      "Epoch 12632 - Train Loss: 0.108275, Train Acc: 0.825641 | Val Loss: 0.127925, Val Acc: 0.752577\n",
      "Epoch 12633 - Train Loss: 0.108270, Train Acc: 0.825641 | Val Loss: 0.127920, Val Acc: 0.752577\n",
      "Epoch 12634 - Train Loss: 0.108264, Train Acc: 0.825641 | Val Loss: 0.127916, Val Acc: 0.752577\n",
      "Epoch 12635 - Train Loss: 0.108258, Train Acc: 0.825641 | Val Loss: 0.127912, Val Acc: 0.752577\n",
      "Epoch 12636 - Train Loss: 0.108253, Train Acc: 0.825641 | Val Loss: 0.127907, Val Acc: 0.752577\n",
      "Epoch 12637 - Train Loss: 0.108247, Train Acc: 0.825641 | Val Loss: 0.127903, Val Acc: 0.752577\n",
      "Epoch 12638 - Train Loss: 0.108241, Train Acc: 0.825641 | Val Loss: 0.127899, Val Acc: 0.752577\n",
      "Epoch 12639 - Train Loss: 0.108235, Train Acc: 0.825641 | Val Loss: 0.127894, Val Acc: 0.752577\n",
      "Epoch 12640 - Train Loss: 0.108230, Train Acc: 0.825641 | Val Loss: 0.127890, Val Acc: 0.752577\n",
      "Epoch 12641 - Train Loss: 0.108224, Train Acc: 0.825641 | Val Loss: 0.127886, Val Acc: 0.752577\n",
      "Epoch 12642 - Train Loss: 0.108218, Train Acc: 0.825641 | Val Loss: 0.127882, Val Acc: 0.752577\n",
      "Epoch 12643 - Train Loss: 0.108213, Train Acc: 0.825641 | Val Loss: 0.127877, Val Acc: 0.752577\n",
      "Epoch 12644 - Train Loss: 0.108207, Train Acc: 0.825641 | Val Loss: 0.127873, Val Acc: 0.752577\n",
      "Epoch 12645 - Train Loss: 0.108201, Train Acc: 0.825641 | Val Loss: 0.127869, Val Acc: 0.752577\n",
      "Epoch 12646 - Train Loss: 0.108196, Train Acc: 0.825641 | Val Loss: 0.127864, Val Acc: 0.752577\n",
      "Epoch 12647 - Train Loss: 0.108190, Train Acc: 0.825641 | Val Loss: 0.127860, Val Acc: 0.752577\n",
      "Epoch 12648 - Train Loss: 0.108184, Train Acc: 0.825641 | Val Loss: 0.127856, Val Acc: 0.752577\n",
      "Epoch 12649 - Train Loss: 0.108179, Train Acc: 0.825641 | Val Loss: 0.127851, Val Acc: 0.752577\n",
      "Epoch 12650 - Train Loss: 0.108173, Train Acc: 0.825641 | Val Loss: 0.127847, Val Acc: 0.752577\n",
      "Epoch 12651 - Train Loss: 0.108167, Train Acc: 0.825641 | Val Loss: 0.127843, Val Acc: 0.752577\n",
      "Epoch 12652 - Train Loss: 0.108162, Train Acc: 0.825641 | Val Loss: 0.127838, Val Acc: 0.752577\n",
      "Epoch 12653 - Train Loss: 0.108156, Train Acc: 0.825641 | Val Loss: 0.127834, Val Acc: 0.752577\n",
      "Epoch 12654 - Train Loss: 0.108150, Train Acc: 0.825641 | Val Loss: 0.127830, Val Acc: 0.752577\n",
      "Epoch 12655 - Train Loss: 0.108145, Train Acc: 0.825641 | Val Loss: 0.127825, Val Acc: 0.752577\n",
      "Epoch 12656 - Train Loss: 0.108139, Train Acc: 0.825641 | Val Loss: 0.127821, Val Acc: 0.752577\n",
      "Epoch 12657 - Train Loss: 0.108133, Train Acc: 0.825641 | Val Loss: 0.127817, Val Acc: 0.752577\n",
      "Epoch 12658 - Train Loss: 0.108128, Train Acc: 0.825641 | Val Loss: 0.127812, Val Acc: 0.752577\n",
      "Epoch 12659 - Train Loss: 0.108122, Train Acc: 0.825641 | Val Loss: 0.127808, Val Acc: 0.752577\n",
      "Epoch 12660 - Train Loss: 0.108116, Train Acc: 0.825641 | Val Loss: 0.127804, Val Acc: 0.752577\n",
      "Epoch 12661 - Train Loss: 0.108111, Train Acc: 0.825641 | Val Loss: 0.127799, Val Acc: 0.752577\n",
      "Epoch 12662 - Train Loss: 0.108105, Train Acc: 0.825641 | Val Loss: 0.127795, Val Acc: 0.752577\n",
      "Epoch 12663 - Train Loss: 0.108099, Train Acc: 0.825641 | Val Loss: 0.127791, Val Acc: 0.752577\n",
      "Epoch 12664 - Train Loss: 0.108094, Train Acc: 0.825641 | Val Loss: 0.127787, Val Acc: 0.752577\n",
      "Epoch 12665 - Train Loss: 0.108088, Train Acc: 0.825641 | Val Loss: 0.127782, Val Acc: 0.752577\n",
      "Epoch 12666 - Train Loss: 0.108082, Train Acc: 0.825641 | Val Loss: 0.127778, Val Acc: 0.752577\n",
      "Epoch 12667 - Train Loss: 0.108077, Train Acc: 0.825641 | Val Loss: 0.127774, Val Acc: 0.752577\n",
      "Epoch 12668 - Train Loss: 0.108071, Train Acc: 0.825641 | Val Loss: 0.127769, Val Acc: 0.752577\n",
      "Epoch 12669 - Train Loss: 0.108065, Train Acc: 0.825641 | Val Loss: 0.127765, Val Acc: 0.752577\n",
      "Epoch 12670 - Train Loss: 0.108060, Train Acc: 0.825641 | Val Loss: 0.127761, Val Acc: 0.752577\n",
      "Epoch 12671 - Train Loss: 0.108054, Train Acc: 0.825641 | Val Loss: 0.127756, Val Acc: 0.752577\n",
      "Epoch 12672 - Train Loss: 0.108048, Train Acc: 0.825641 | Val Loss: 0.127752, Val Acc: 0.752577\n",
      "Epoch 12673 - Train Loss: 0.108043, Train Acc: 0.825641 | Val Loss: 0.127748, Val Acc: 0.752577\n",
      "Epoch 12674 - Train Loss: 0.108037, Train Acc: 0.825641 | Val Loss: 0.127744, Val Acc: 0.752577\n",
      "Epoch 12675 - Train Loss: 0.108031, Train Acc: 0.825641 | Val Loss: 0.127739, Val Acc: 0.752577\n",
      "Epoch 12676 - Train Loss: 0.108026, Train Acc: 0.825641 | Val Loss: 0.127735, Val Acc: 0.752577\n",
      "Epoch 12677 - Train Loss: 0.108020, Train Acc: 0.825641 | Val Loss: 0.127731, Val Acc: 0.752577\n",
      "Epoch 12678 - Train Loss: 0.108014, Train Acc: 0.825641 | Val Loss: 0.127726, Val Acc: 0.752577\n",
      "Epoch 12679 - Train Loss: 0.108009, Train Acc: 0.825641 | Val Loss: 0.127722, Val Acc: 0.752577\n",
      "Epoch 12680 - Train Loss: 0.108003, Train Acc: 0.825641 | Val Loss: 0.127718, Val Acc: 0.752577\n",
      "Epoch 12681 - Train Loss: 0.107997, Train Acc: 0.825641 | Val Loss: 0.127713, Val Acc: 0.752577\n",
      "Epoch 12682 - Train Loss: 0.107992, Train Acc: 0.825641 | Val Loss: 0.127709, Val Acc: 0.752577\n",
      "Epoch 12683 - Train Loss: 0.107986, Train Acc: 0.825641 | Val Loss: 0.127705, Val Acc: 0.752577\n",
      "Epoch 12684 - Train Loss: 0.107980, Train Acc: 0.825641 | Val Loss: 0.127701, Val Acc: 0.752577\n",
      "Epoch 12685 - Train Loss: 0.107975, Train Acc: 0.825641 | Val Loss: 0.127696, Val Acc: 0.752577\n",
      "Epoch 12686 - Train Loss: 0.107969, Train Acc: 0.825641 | Val Loss: 0.127692, Val Acc: 0.752577\n",
      "Epoch 12687 - Train Loss: 0.107963, Train Acc: 0.825641 | Val Loss: 0.127688, Val Acc: 0.752577\n",
      "Epoch 12688 - Train Loss: 0.107958, Train Acc: 0.825641 | Val Loss: 0.127683, Val Acc: 0.752577\n",
      "Epoch 12689 - Train Loss: 0.107952, Train Acc: 0.825641 | Val Loss: 0.127679, Val Acc: 0.752577\n",
      "Epoch 12690 - Train Loss: 0.107946, Train Acc: 0.825641 | Val Loss: 0.127675, Val Acc: 0.752577\n",
      "Epoch 12691 - Train Loss: 0.107941, Train Acc: 0.825641 | Val Loss: 0.127671, Val Acc: 0.752577\n",
      "Epoch 12692 - Train Loss: 0.107935, Train Acc: 0.825641 | Val Loss: 0.127666, Val Acc: 0.752577\n",
      "Epoch 12693 - Train Loss: 0.107929, Train Acc: 0.825641 | Val Loss: 0.127662, Val Acc: 0.752577\n",
      "Epoch 12694 - Train Loss: 0.107924, Train Acc: 0.825641 | Val Loss: 0.127658, Val Acc: 0.752577\n",
      "Epoch 12695 - Train Loss: 0.107918, Train Acc: 0.825641 | Val Loss: 0.127653, Val Acc: 0.752577\n",
      "Epoch 12696 - Train Loss: 0.107913, Train Acc: 0.825641 | Val Loss: 0.127649, Val Acc: 0.752577\n",
      "Epoch 12697 - Train Loss: 0.107907, Train Acc: 0.825641 | Val Loss: 0.127645, Val Acc: 0.752577\n",
      "Epoch 12698 - Train Loss: 0.107901, Train Acc: 0.825641 | Val Loss: 0.127641, Val Acc: 0.752577\n",
      "Epoch 12699 - Train Loss: 0.107896, Train Acc: 0.825641 | Val Loss: 0.127636, Val Acc: 0.752577\n",
      "Epoch 12700 - Train Loss: 0.107890, Train Acc: 0.825641 | Val Loss: 0.127632, Val Acc: 0.752577\n",
      "Epoch 12701 - Train Loss: 0.107884, Train Acc: 0.825641 | Val Loss: 0.127628, Val Acc: 0.752577\n",
      "Epoch 12702 - Train Loss: 0.107879, Train Acc: 0.825641 | Val Loss: 0.127623, Val Acc: 0.752577\n",
      "Epoch 12703 - Train Loss: 0.107873, Train Acc: 0.825641 | Val Loss: 0.127619, Val Acc: 0.752577\n",
      "Epoch 12704 - Train Loss: 0.107867, Train Acc: 0.825641 | Val Loss: 0.127615, Val Acc: 0.752577\n",
      "Epoch 12705 - Train Loss: 0.107862, Train Acc: 0.825641 | Val Loss: 0.127611, Val Acc: 0.752577\n",
      "Epoch 12706 - Train Loss: 0.107856, Train Acc: 0.825641 | Val Loss: 0.127606, Val Acc: 0.752577\n",
      "Epoch 12707 - Train Loss: 0.107850, Train Acc: 0.825641 | Val Loss: 0.127602, Val Acc: 0.752577\n",
      "Epoch 12708 - Train Loss: 0.107845, Train Acc: 0.825641 | Val Loss: 0.127598, Val Acc: 0.752577\n",
      "Epoch 12709 - Train Loss: 0.107839, Train Acc: 0.825641 | Val Loss: 0.127594, Val Acc: 0.752577\n",
      "Epoch 12710 - Train Loss: 0.107834, Train Acc: 0.825641 | Val Loss: 0.127589, Val Acc: 0.752577\n",
      "Epoch 12711 - Train Loss: 0.107828, Train Acc: 0.825641 | Val Loss: 0.127585, Val Acc: 0.752577\n",
      "Epoch 12712 - Train Loss: 0.107822, Train Acc: 0.825641 | Val Loss: 0.127581, Val Acc: 0.752577\n",
      "Epoch 12713 - Train Loss: 0.107817, Train Acc: 0.825641 | Val Loss: 0.127576, Val Acc: 0.752577\n",
      "Epoch 12714 - Train Loss: 0.107811, Train Acc: 0.825641 | Val Loss: 0.127572, Val Acc: 0.752577\n",
      "Epoch 12715 - Train Loss: 0.107805, Train Acc: 0.825641 | Val Loss: 0.127568, Val Acc: 0.752577\n",
      "Epoch 12716 - Train Loss: 0.107800, Train Acc: 0.825641 | Val Loss: 0.127564, Val Acc: 0.752577\n",
      "Epoch 12717 - Train Loss: 0.107794, Train Acc: 0.825641 | Val Loss: 0.127559, Val Acc: 0.752577\n",
      "Epoch 12718 - Train Loss: 0.107789, Train Acc: 0.825641 | Val Loss: 0.127555, Val Acc: 0.752577\n",
      "Epoch 12719 - Train Loss: 0.107783, Train Acc: 0.825641 | Val Loss: 0.127551, Val Acc: 0.752577\n",
      "Epoch 12720 - Train Loss: 0.107777, Train Acc: 0.825641 | Val Loss: 0.127547, Val Acc: 0.752577\n",
      "Epoch 12721 - Train Loss: 0.107772, Train Acc: 0.825641 | Val Loss: 0.127542, Val Acc: 0.752577\n",
      "Epoch 12722 - Train Loss: 0.107766, Train Acc: 0.825641 | Val Loss: 0.127538, Val Acc: 0.752577\n",
      "Epoch 12723 - Train Loss: 0.107760, Train Acc: 0.825641 | Val Loss: 0.127534, Val Acc: 0.752577\n",
      "Epoch 12724 - Train Loss: 0.107755, Train Acc: 0.825641 | Val Loss: 0.127530, Val Acc: 0.752577\n",
      "Epoch 12725 - Train Loss: 0.107749, Train Acc: 0.825641 | Val Loss: 0.127525, Val Acc: 0.752577\n",
      "Epoch 12726 - Train Loss: 0.107744, Train Acc: 0.825641 | Val Loss: 0.127521, Val Acc: 0.752577\n",
      "Epoch 12727 - Train Loss: 0.107738, Train Acc: 0.825641 | Val Loss: 0.127517, Val Acc: 0.752577\n",
      "Epoch 12728 - Train Loss: 0.107732, Train Acc: 0.825641 | Val Loss: 0.127513, Val Acc: 0.752577\n",
      "Epoch 12729 - Train Loss: 0.107727, Train Acc: 0.825641 | Val Loss: 0.127508, Val Acc: 0.752577\n",
      "Epoch 12730 - Train Loss: 0.107721, Train Acc: 0.825641 | Val Loss: 0.127504, Val Acc: 0.752577\n",
      "Epoch 12731 - Train Loss: 0.107715, Train Acc: 0.825641 | Val Loss: 0.127500, Val Acc: 0.752577\n",
      "Epoch 12732 - Train Loss: 0.107710, Train Acc: 0.825641 | Val Loss: 0.127496, Val Acc: 0.752577\n",
      "Epoch 12733 - Train Loss: 0.107704, Train Acc: 0.825641 | Val Loss: 0.127491, Val Acc: 0.752577\n",
      "Epoch 12734 - Train Loss: 0.107699, Train Acc: 0.825641 | Val Loss: 0.127487, Val Acc: 0.752577\n",
      "Epoch 12735 - Train Loss: 0.107693, Train Acc: 0.825641 | Val Loss: 0.127483, Val Acc: 0.752577\n",
      "Epoch 12736 - Train Loss: 0.107687, Train Acc: 0.825641 | Val Loss: 0.127479, Val Acc: 0.752577\n",
      "Epoch 12737 - Train Loss: 0.107682, Train Acc: 0.825641 | Val Loss: 0.127474, Val Acc: 0.752577\n",
      "Epoch 12738 - Train Loss: 0.107676, Train Acc: 0.825641 | Val Loss: 0.127470, Val Acc: 0.752577\n",
      "Epoch 12739 - Train Loss: 0.107671, Train Acc: 0.825641 | Val Loss: 0.127466, Val Acc: 0.752577\n",
      "Epoch 12740 - Train Loss: 0.107665, Train Acc: 0.825641 | Val Loss: 0.127462, Val Acc: 0.752577\n",
      "Epoch 12741 - Train Loss: 0.107659, Train Acc: 0.825641 | Val Loss: 0.127457, Val Acc: 0.752577\n",
      "Epoch 12742 - Train Loss: 0.107654, Train Acc: 0.825641 | Val Loss: 0.127453, Val Acc: 0.752577\n",
      "Epoch 12743 - Train Loss: 0.107648, Train Acc: 0.825641 | Val Loss: 0.127449, Val Acc: 0.752577\n",
      "Epoch 12744 - Train Loss: 0.107643, Train Acc: 0.825641 | Val Loss: 0.127445, Val Acc: 0.752577\n",
      "Epoch 12745 - Train Loss: 0.107637, Train Acc: 0.825641 | Val Loss: 0.127440, Val Acc: 0.752577\n",
      "Epoch 12746 - Train Loss: 0.107631, Train Acc: 0.825641 | Val Loss: 0.127436, Val Acc: 0.752577\n",
      "Epoch 12747 - Train Loss: 0.107626, Train Acc: 0.825641 | Val Loss: 0.127432, Val Acc: 0.752577\n",
      "Epoch 12748 - Train Loss: 0.107620, Train Acc: 0.825641 | Val Loss: 0.127428, Val Acc: 0.752577\n",
      "Epoch 12749 - Train Loss: 0.107615, Train Acc: 0.825641 | Val Loss: 0.127423, Val Acc: 0.752577\n",
      "Epoch 12750 - Train Loss: 0.107609, Train Acc: 0.825641 | Val Loss: 0.127419, Val Acc: 0.752577\n",
      "Epoch 12751 - Train Loss: 0.107603, Train Acc: 0.825641 | Val Loss: 0.127415, Val Acc: 0.752577\n",
      "Epoch 12752 - Train Loss: 0.107598, Train Acc: 0.825641 | Val Loss: 0.127411, Val Acc: 0.752577\n",
      "Epoch 12753 - Train Loss: 0.107592, Train Acc: 0.825641 | Val Loss: 0.127406, Val Acc: 0.752577\n",
      "Epoch 12754 - Train Loss: 0.107587, Train Acc: 0.825641 | Val Loss: 0.127402, Val Acc: 0.752577\n",
      "Epoch 12755 - Train Loss: 0.107581, Train Acc: 0.825641 | Val Loss: 0.127398, Val Acc: 0.752577\n",
      "Epoch 12756 - Train Loss: 0.107575, Train Acc: 0.825641 | Val Loss: 0.127394, Val Acc: 0.752577\n",
      "Epoch 12757 - Train Loss: 0.107570, Train Acc: 0.825641 | Val Loss: 0.127389, Val Acc: 0.752577\n",
      "Epoch 12758 - Train Loss: 0.107564, Train Acc: 0.825641 | Val Loss: 0.127385, Val Acc: 0.752577\n",
      "Epoch 12759 - Train Loss: 0.107559, Train Acc: 0.825641 | Val Loss: 0.127381, Val Acc: 0.752577\n",
      "Epoch 12760 - Train Loss: 0.107553, Train Acc: 0.825641 | Val Loss: 0.127377, Val Acc: 0.752577\n",
      "Epoch 12761 - Train Loss: 0.107547, Train Acc: 0.825641 | Val Loss: 0.127373, Val Acc: 0.752577\n",
      "Epoch 12762 - Train Loss: 0.107542, Train Acc: 0.825641 | Val Loss: 0.127368, Val Acc: 0.752577\n",
      "Epoch 12763 - Train Loss: 0.107536, Train Acc: 0.825641 | Val Loss: 0.127364, Val Acc: 0.752577\n",
      "Epoch 12764 - Train Loss: 0.107531, Train Acc: 0.825641 | Val Loss: 0.127360, Val Acc: 0.752577\n",
      "Epoch 12765 - Train Loss: 0.107525, Train Acc: 0.825641 | Val Loss: 0.127356, Val Acc: 0.752577\n",
      "Epoch 12766 - Train Loss: 0.107519, Train Acc: 0.825641 | Val Loss: 0.127351, Val Acc: 0.752577\n",
      "Epoch 12767 - Train Loss: 0.107514, Train Acc: 0.825641 | Val Loss: 0.127347, Val Acc: 0.752577\n",
      "Epoch 12768 - Train Loss: 0.107508, Train Acc: 0.825641 | Val Loss: 0.127343, Val Acc: 0.752577\n",
      "Epoch 12769 - Train Loss: 0.107503, Train Acc: 0.825641 | Val Loss: 0.127339, Val Acc: 0.752577\n",
      "Epoch 12770 - Train Loss: 0.107497, Train Acc: 0.825641 | Val Loss: 0.127335, Val Acc: 0.752577\n",
      "Epoch 12771 - Train Loss: 0.107492, Train Acc: 0.825641 | Val Loss: 0.127330, Val Acc: 0.752577\n",
      "Epoch 12772 - Train Loss: 0.107486, Train Acc: 0.825641 | Val Loss: 0.127326, Val Acc: 0.752577\n",
      "Epoch 12773 - Train Loss: 0.107480, Train Acc: 0.825641 | Val Loss: 0.127322, Val Acc: 0.752577\n",
      "Epoch 12774 - Train Loss: 0.107475, Train Acc: 0.825641 | Val Loss: 0.127318, Val Acc: 0.752577\n",
      "Epoch 12775 - Train Loss: 0.107469, Train Acc: 0.825641 | Val Loss: 0.127313, Val Acc: 0.752577\n",
      "Epoch 12776 - Train Loss: 0.107464, Train Acc: 0.825641 | Val Loss: 0.127309, Val Acc: 0.752577\n",
      "Epoch 12777 - Train Loss: 0.107458, Train Acc: 0.825641 | Val Loss: 0.127305, Val Acc: 0.752577\n",
      "Epoch 12778 - Train Loss: 0.107452, Train Acc: 0.825641 | Val Loss: 0.127301, Val Acc: 0.752577\n",
      "Epoch 12779 - Train Loss: 0.107447, Train Acc: 0.825641 | Val Loss: 0.127297, Val Acc: 0.752577\n",
      "Epoch 12780 - Train Loss: 0.107441, Train Acc: 0.825641 | Val Loss: 0.127292, Val Acc: 0.752577\n",
      "Epoch 12781 - Train Loss: 0.107436, Train Acc: 0.825641 | Val Loss: 0.127288, Val Acc: 0.752577\n",
      "Epoch 12782 - Train Loss: 0.107430, Train Acc: 0.825641 | Val Loss: 0.127284, Val Acc: 0.752577\n",
      "Epoch 12783 - Train Loss: 0.107425, Train Acc: 0.825641 | Val Loss: 0.127280, Val Acc: 0.752577\n",
      "Epoch 12784 - Train Loss: 0.107419, Train Acc: 0.825641 | Val Loss: 0.127276, Val Acc: 0.752577\n",
      "Epoch 12785 - Train Loss: 0.107413, Train Acc: 0.825641 | Val Loss: 0.127271, Val Acc: 0.752577\n",
      "Epoch 12786 - Train Loss: 0.107408, Train Acc: 0.825641 | Val Loss: 0.127267, Val Acc: 0.752577\n",
      "Epoch 12787 - Train Loss: 0.107402, Train Acc: 0.825641 | Val Loss: 0.127263, Val Acc: 0.752577\n",
      "Epoch 12788 - Train Loss: 0.107397, Train Acc: 0.825641 | Val Loss: 0.127259, Val Acc: 0.752577\n",
      "Epoch 12789 - Train Loss: 0.107391, Train Acc: 0.825641 | Val Loss: 0.127254, Val Acc: 0.752577\n",
      "Epoch 12790 - Train Loss: 0.107386, Train Acc: 0.825641 | Val Loss: 0.127250, Val Acc: 0.752577\n",
      "Epoch 12791 - Train Loss: 0.107380, Train Acc: 0.825641 | Val Loss: 0.127246, Val Acc: 0.752577\n",
      "Epoch 12792 - Train Loss: 0.107374, Train Acc: 0.825641 | Val Loss: 0.127242, Val Acc: 0.752577\n",
      "Epoch 12793 - Train Loss: 0.107369, Train Acc: 0.825641 | Val Loss: 0.127238, Val Acc: 0.752577\n",
      "Epoch 12794 - Train Loss: 0.107363, Train Acc: 0.825641 | Val Loss: 0.127233, Val Acc: 0.752577\n",
      "Epoch 12795 - Train Loss: 0.107358, Train Acc: 0.825641 | Val Loss: 0.127229, Val Acc: 0.752577\n",
      "Epoch 12796 - Train Loss: 0.107352, Train Acc: 0.825641 | Val Loss: 0.127225, Val Acc: 0.752577\n",
      "Epoch 12797 - Train Loss: 0.107347, Train Acc: 0.825641 | Val Loss: 0.127221, Val Acc: 0.752577\n",
      "Epoch 12798 - Train Loss: 0.107341, Train Acc: 0.825641 | Val Loss: 0.127216, Val Acc: 0.752577\n",
      "Epoch 12799 - Train Loss: 0.107335, Train Acc: 0.825641 | Val Loss: 0.127212, Val Acc: 0.752577\n",
      "Epoch 12800 - Train Loss: 0.107330, Train Acc: 0.825641 | Val Loss: 0.127208, Val Acc: 0.752577\n",
      "Epoch 12801 - Train Loss: 0.107324, Train Acc: 0.825641 | Val Loss: 0.127204, Val Acc: 0.752577\n",
      "Epoch 12802 - Train Loss: 0.107319, Train Acc: 0.825641 | Val Loss: 0.127200, Val Acc: 0.752577\n",
      "Epoch 12803 - Train Loss: 0.107313, Train Acc: 0.825641 | Val Loss: 0.127195, Val Acc: 0.752577\n",
      "Epoch 12804 - Train Loss: 0.107308, Train Acc: 0.825641 | Val Loss: 0.127191, Val Acc: 0.752577\n",
      "Epoch 12805 - Train Loss: 0.107302, Train Acc: 0.825641 | Val Loss: 0.127187, Val Acc: 0.752577\n",
      "Epoch 12806 - Train Loss: 0.107297, Train Acc: 0.825641 | Val Loss: 0.127183, Val Acc: 0.752577\n",
      "Epoch 12807 - Train Loss: 0.107291, Train Acc: 0.825641 | Val Loss: 0.127178, Val Acc: 0.752577\n",
      "Epoch 12808 - Train Loss: 0.107285, Train Acc: 0.825641 | Val Loss: 0.127174, Val Acc: 0.752577\n",
      "Epoch 12809 - Train Loss: 0.107280, Train Acc: 0.825641 | Val Loss: 0.127170, Val Acc: 0.752577\n",
      "Epoch 12810 - Train Loss: 0.107274, Train Acc: 0.825641 | Val Loss: 0.127166, Val Acc: 0.752577\n",
      "Epoch 12811 - Train Loss: 0.107269, Train Acc: 0.825641 | Val Loss: 0.127162, Val Acc: 0.752577\n",
      "Epoch 12812 - Train Loss: 0.107263, Train Acc: 0.825641 | Val Loss: 0.127157, Val Acc: 0.752577\n",
      "Epoch 12813 - Train Loss: 0.107258, Train Acc: 0.825641 | Val Loss: 0.127153, Val Acc: 0.752577\n",
      "Epoch 12814 - Train Loss: 0.107252, Train Acc: 0.825641 | Val Loss: 0.127149, Val Acc: 0.752577\n",
      "Epoch 12815 - Train Loss: 0.107247, Train Acc: 0.825641 | Val Loss: 0.127145, Val Acc: 0.752577\n",
      "Epoch 12816 - Train Loss: 0.107241, Train Acc: 0.825641 | Val Loss: 0.127141, Val Acc: 0.752577\n",
      "Epoch 12817 - Train Loss: 0.107235, Train Acc: 0.825641 | Val Loss: 0.127136, Val Acc: 0.752577\n",
      "Epoch 12818 - Train Loss: 0.107230, Train Acc: 0.825641 | Val Loss: 0.127132, Val Acc: 0.752577\n",
      "Epoch 12819 - Train Loss: 0.107224, Train Acc: 0.825641 | Val Loss: 0.127128, Val Acc: 0.752577\n",
      "Epoch 12820 - Train Loss: 0.107219, Train Acc: 0.825641 | Val Loss: 0.127124, Val Acc: 0.752577\n",
      "Epoch 12821 - Train Loss: 0.107213, Train Acc: 0.825641 | Val Loss: 0.127120, Val Acc: 0.752577\n",
      "Epoch 12822 - Train Loss: 0.107208, Train Acc: 0.825641 | Val Loss: 0.127115, Val Acc: 0.752577\n",
      "Epoch 12823 - Train Loss: 0.107202, Train Acc: 0.825641 | Val Loss: 0.127111, Val Acc: 0.752577\n",
      "Epoch 12824 - Train Loss: 0.107197, Train Acc: 0.825641 | Val Loss: 0.127107, Val Acc: 0.752577\n",
      "Epoch 12825 - Train Loss: 0.107191, Train Acc: 0.825641 | Val Loss: 0.127103, Val Acc: 0.752577\n",
      "Epoch 12826 - Train Loss: 0.107186, Train Acc: 0.825641 | Val Loss: 0.127099, Val Acc: 0.752577\n",
      "Epoch 12827 - Train Loss: 0.107180, Train Acc: 0.825641 | Val Loss: 0.127094, Val Acc: 0.752577\n",
      "Epoch 12828 - Train Loss: 0.107175, Train Acc: 0.825641 | Val Loss: 0.127090, Val Acc: 0.752577\n",
      "Epoch 12829 - Train Loss: 0.107169, Train Acc: 0.825641 | Val Loss: 0.127086, Val Acc: 0.752577\n",
      "Epoch 12830 - Train Loss: 0.107163, Train Acc: 0.825641 | Val Loss: 0.127082, Val Acc: 0.752577\n",
      "Epoch 12831 - Train Loss: 0.107158, Train Acc: 0.825641 | Val Loss: 0.127078, Val Acc: 0.752577\n",
      "Epoch 12832 - Train Loss: 0.107152, Train Acc: 0.825641 | Val Loss: 0.127073, Val Acc: 0.752577\n",
      "Epoch 12833 - Train Loss: 0.107147, Train Acc: 0.825641 | Val Loss: 0.127069, Val Acc: 0.752577\n",
      "Epoch 12834 - Train Loss: 0.107141, Train Acc: 0.825641 | Val Loss: 0.127065, Val Acc: 0.752577\n",
      "Epoch 12835 - Train Loss: 0.107136, Train Acc: 0.825641 | Val Loss: 0.127061, Val Acc: 0.752577\n",
      "Epoch 12836 - Train Loss: 0.107130, Train Acc: 0.825641 | Val Loss: 0.127057, Val Acc: 0.752577\n",
      "Epoch 12837 - Train Loss: 0.107125, Train Acc: 0.825641 | Val Loss: 0.127053, Val Acc: 0.752577\n",
      "Epoch 12838 - Train Loss: 0.107119, Train Acc: 0.825641 | Val Loss: 0.127048, Val Acc: 0.752577\n",
      "Epoch 12839 - Train Loss: 0.107114, Train Acc: 0.825641 | Val Loss: 0.127044, Val Acc: 0.752577\n",
      "Epoch 12840 - Train Loss: 0.107108, Train Acc: 0.825641 | Val Loss: 0.127040, Val Acc: 0.752577\n",
      "Epoch 12841 - Train Loss: 0.107103, Train Acc: 0.825641 | Val Loss: 0.127036, Val Acc: 0.752577\n",
      "Epoch 12842 - Train Loss: 0.107097, Train Acc: 0.825641 | Val Loss: 0.127032, Val Acc: 0.752577\n",
      "Epoch 12843 - Train Loss: 0.107092, Train Acc: 0.825641 | Val Loss: 0.127027, Val Acc: 0.752577\n",
      "Epoch 12844 - Train Loss: 0.107086, Train Acc: 0.825641 | Val Loss: 0.127023, Val Acc: 0.752577\n",
      "Epoch 12845 - Train Loss: 0.107080, Train Acc: 0.825641 | Val Loss: 0.127019, Val Acc: 0.752577\n",
      "Epoch 12846 - Train Loss: 0.107075, Train Acc: 0.825641 | Val Loss: 0.127015, Val Acc: 0.752577\n",
      "Epoch 12847 - Train Loss: 0.107069, Train Acc: 0.825641 | Val Loss: 0.127011, Val Acc: 0.752577\n",
      "Epoch 12848 - Train Loss: 0.107064, Train Acc: 0.825641 | Val Loss: 0.127007, Val Acc: 0.752577\n",
      "Epoch 12849 - Train Loss: 0.107058, Train Acc: 0.825641 | Val Loss: 0.127002, Val Acc: 0.752577\n",
      "Epoch 12850 - Train Loss: 0.107053, Train Acc: 0.825641 | Val Loss: 0.126998, Val Acc: 0.752577\n",
      "Epoch 12851 - Train Loss: 0.107047, Train Acc: 0.825641 | Val Loss: 0.126994, Val Acc: 0.752577\n",
      "Epoch 12852 - Train Loss: 0.107042, Train Acc: 0.825641 | Val Loss: 0.126990, Val Acc: 0.752577\n",
      "Epoch 12853 - Train Loss: 0.107036, Train Acc: 0.825641 | Val Loss: 0.126986, Val Acc: 0.752577\n",
      "Epoch 12854 - Train Loss: 0.107031, Train Acc: 0.825641 | Val Loss: 0.126982, Val Acc: 0.752577\n",
      "Epoch 12855 - Train Loss: 0.107025, Train Acc: 0.825641 | Val Loss: 0.126977, Val Acc: 0.752577\n",
      "Epoch 12856 - Train Loss: 0.107020, Train Acc: 0.825641 | Val Loss: 0.126973, Val Acc: 0.752577\n",
      "Epoch 12857 - Train Loss: 0.107014, Train Acc: 0.825641 | Val Loss: 0.126969, Val Acc: 0.752577\n",
      "Epoch 12858 - Train Loss: 0.107009, Train Acc: 0.825641 | Val Loss: 0.126965, Val Acc: 0.752577\n",
      "Epoch 12859 - Train Loss: 0.107003, Train Acc: 0.825641 | Val Loss: 0.126961, Val Acc: 0.752577\n",
      "Epoch 12860 - Train Loss: 0.106998, Train Acc: 0.825641 | Val Loss: 0.126957, Val Acc: 0.752577\n",
      "Epoch 12861 - Train Loss: 0.106992, Train Acc: 0.825641 | Val Loss: 0.126953, Val Acc: 0.752577\n",
      "Epoch 12862 - Train Loss: 0.106987, Train Acc: 0.825641 | Val Loss: 0.126948, Val Acc: 0.752577\n",
      "Epoch 12863 - Train Loss: 0.106981, Train Acc: 0.825641 | Val Loss: 0.126944, Val Acc: 0.752577\n",
      "Epoch 12864 - Train Loss: 0.106976, Train Acc: 0.825641 | Val Loss: 0.126940, Val Acc: 0.752577\n",
      "Epoch 12865 - Train Loss: 0.106970, Train Acc: 0.825641 | Val Loss: 0.126936, Val Acc: 0.752577\n",
      "Epoch 12866 - Train Loss: 0.106965, Train Acc: 0.825641 | Val Loss: 0.126932, Val Acc: 0.752577\n",
      "Epoch 12867 - Train Loss: 0.106959, Train Acc: 0.825641 | Val Loss: 0.126928, Val Acc: 0.752577\n",
      "Epoch 12868 - Train Loss: 0.106954, Train Acc: 0.825641 | Val Loss: 0.126924, Val Acc: 0.752577\n",
      "Epoch 12869 - Train Loss: 0.106948, Train Acc: 0.825641 | Val Loss: 0.126919, Val Acc: 0.752577\n",
      "Epoch 12870 - Train Loss: 0.106943, Train Acc: 0.825641 | Val Loss: 0.126915, Val Acc: 0.752577\n",
      "Epoch 12871 - Train Loss: 0.106937, Train Acc: 0.825641 | Val Loss: 0.126911, Val Acc: 0.752577\n",
      "Epoch 12872 - Train Loss: 0.106932, Train Acc: 0.825641 | Val Loss: 0.126907, Val Acc: 0.752577\n",
      "Epoch 12873 - Train Loss: 0.106926, Train Acc: 0.825641 | Val Loss: 0.126903, Val Acc: 0.752577\n",
      "Epoch 12874 - Train Loss: 0.106921, Train Acc: 0.825641 | Val Loss: 0.126899, Val Acc: 0.752577\n",
      "Epoch 12875 - Train Loss: 0.106915, Train Acc: 0.825641 | Val Loss: 0.126895, Val Acc: 0.752577\n",
      "Epoch 12876 - Train Loss: 0.106910, Train Acc: 0.825641 | Val Loss: 0.126890, Val Acc: 0.752577\n",
      "Epoch 12877 - Train Loss: 0.106904, Train Acc: 0.825641 | Val Loss: 0.126886, Val Acc: 0.752577\n",
      "Epoch 12878 - Train Loss: 0.106899, Train Acc: 0.825641 | Val Loss: 0.126882, Val Acc: 0.752577\n",
      "Epoch 12879 - Train Loss: 0.106893, Train Acc: 0.825641 | Val Loss: 0.126878, Val Acc: 0.752577\n",
      "Epoch 12880 - Train Loss: 0.106888, Train Acc: 0.825641 | Val Loss: 0.126874, Val Acc: 0.752577\n",
      "Epoch 12881 - Train Loss: 0.106882, Train Acc: 0.825641 | Val Loss: 0.126870, Val Acc: 0.752577\n",
      "Epoch 12882 - Train Loss: 0.106877, Train Acc: 0.825641 | Val Loss: 0.126866, Val Acc: 0.752577\n",
      "Epoch 12883 - Train Loss: 0.106871, Train Acc: 0.825641 | Val Loss: 0.126861, Val Acc: 0.752577\n",
      "Epoch 12884 - Train Loss: 0.106866, Train Acc: 0.825641 | Val Loss: 0.126857, Val Acc: 0.752577\n",
      "Epoch 12885 - Train Loss: 0.106860, Train Acc: 0.825641 | Val Loss: 0.126853, Val Acc: 0.752577\n",
      "Epoch 12886 - Train Loss: 0.106855, Train Acc: 0.825641 | Val Loss: 0.126849, Val Acc: 0.752577\n",
      "Epoch 12887 - Train Loss: 0.106849, Train Acc: 0.825641 | Val Loss: 0.126845, Val Acc: 0.752577\n",
      "Epoch 12888 - Train Loss: 0.106844, Train Acc: 0.825641 | Val Loss: 0.126841, Val Acc: 0.752577\n",
      "Epoch 12889 - Train Loss: 0.106838, Train Acc: 0.825641 | Val Loss: 0.126837, Val Acc: 0.752577\n",
      "Epoch 12890 - Train Loss: 0.106833, Train Acc: 0.825641 | Val Loss: 0.126833, Val Acc: 0.752577\n",
      "Epoch 12891 - Train Loss: 0.106827, Train Acc: 0.825641 | Val Loss: 0.126828, Val Acc: 0.752577\n",
      "Epoch 12892 - Train Loss: 0.106822, Train Acc: 0.825641 | Val Loss: 0.126824, Val Acc: 0.752577\n",
      "Epoch 12893 - Train Loss: 0.106816, Train Acc: 0.825641 | Val Loss: 0.126820, Val Acc: 0.752577\n",
      "Epoch 12894 - Train Loss: 0.106811, Train Acc: 0.825641 | Val Loss: 0.126816, Val Acc: 0.752577\n",
      "Epoch 12895 - Train Loss: 0.106805, Train Acc: 0.825641 | Val Loss: 0.126812, Val Acc: 0.752577\n",
      "Epoch 12896 - Train Loss: 0.106800, Train Acc: 0.825641 | Val Loss: 0.126808, Val Acc: 0.752577\n",
      "Epoch 12897 - Train Loss: 0.106794, Train Acc: 0.825641 | Val Loss: 0.126804, Val Acc: 0.752577\n",
      "Epoch 12898 - Train Loss: 0.106789, Train Acc: 0.825641 | Val Loss: 0.126800, Val Acc: 0.752577\n",
      "Epoch 12899 - Train Loss: 0.106783, Train Acc: 0.825641 | Val Loss: 0.126796, Val Acc: 0.752577\n",
      "Epoch 12900 - Train Loss: 0.106778, Train Acc: 0.825641 | Val Loss: 0.126791, Val Acc: 0.752577\n",
      "Epoch 12901 - Train Loss: 0.106772, Train Acc: 0.825641 | Val Loss: 0.126787, Val Acc: 0.752577\n",
      "Epoch 12902 - Train Loss: 0.106767, Train Acc: 0.825641 | Val Loss: 0.126783, Val Acc: 0.752577\n",
      "Epoch 12903 - Train Loss: 0.106761, Train Acc: 0.825641 | Val Loss: 0.126779, Val Acc: 0.752577\n",
      "Epoch 12904 - Train Loss: 0.106756, Train Acc: 0.825641 | Val Loss: 0.126775, Val Acc: 0.752577\n",
      "Epoch 12905 - Train Loss: 0.106750, Train Acc: 0.825641 | Val Loss: 0.126771, Val Acc: 0.752577\n",
      "Epoch 12906 - Train Loss: 0.106745, Train Acc: 0.825641 | Val Loss: 0.126767, Val Acc: 0.752577\n",
      "Epoch 12907 - Train Loss: 0.106739, Train Acc: 0.825641 | Val Loss: 0.126763, Val Acc: 0.752577\n",
      "Epoch 12908 - Train Loss: 0.106734, Train Acc: 0.825641 | Val Loss: 0.126759, Val Acc: 0.752577\n",
      "Epoch 12909 - Train Loss: 0.106728, Train Acc: 0.825641 | Val Loss: 0.126754, Val Acc: 0.752577\n",
      "Epoch 12910 - Train Loss: 0.106723, Train Acc: 0.825641 | Val Loss: 0.126750, Val Acc: 0.752577\n",
      "Epoch 12911 - Train Loss: 0.106717, Train Acc: 0.825641 | Val Loss: 0.126746, Val Acc: 0.752577\n",
      "Epoch 12912 - Train Loss: 0.106712, Train Acc: 0.825641 | Val Loss: 0.126742, Val Acc: 0.752577\n",
      "Epoch 12913 - Train Loss: 0.106706, Train Acc: 0.825641 | Val Loss: 0.126738, Val Acc: 0.752577\n",
      "Epoch 12914 - Train Loss: 0.106701, Train Acc: 0.825641 | Val Loss: 0.126734, Val Acc: 0.752577\n",
      "Epoch 12915 - Train Loss: 0.106696, Train Acc: 0.825641 | Val Loss: 0.126730, Val Acc: 0.752577\n",
      "Epoch 12916 - Train Loss: 0.106690, Train Acc: 0.825641 | Val Loss: 0.126726, Val Acc: 0.752577\n",
      "Epoch 12917 - Train Loss: 0.106685, Train Acc: 0.825641 | Val Loss: 0.126722, Val Acc: 0.752577\n",
      "Epoch 12918 - Train Loss: 0.106679, Train Acc: 0.825641 | Val Loss: 0.126718, Val Acc: 0.752577\n",
      "Epoch 12919 - Train Loss: 0.106674, Train Acc: 0.825641 | Val Loss: 0.126713, Val Acc: 0.752577\n",
      "Epoch 12920 - Train Loss: 0.106668, Train Acc: 0.825641 | Val Loss: 0.126709, Val Acc: 0.752577\n",
      "Epoch 12921 - Train Loss: 0.106663, Train Acc: 0.825641 | Val Loss: 0.126705, Val Acc: 0.752577\n",
      "Epoch 12922 - Train Loss: 0.106657, Train Acc: 0.825641 | Val Loss: 0.126701, Val Acc: 0.752577\n",
      "Epoch 12923 - Train Loss: 0.106652, Train Acc: 0.825641 | Val Loss: 0.126697, Val Acc: 0.752577\n",
      "Epoch 12924 - Train Loss: 0.106646, Train Acc: 0.825641 | Val Loss: 0.126693, Val Acc: 0.752577\n",
      "Epoch 12925 - Train Loss: 0.106641, Train Acc: 0.825641 | Val Loss: 0.126689, Val Acc: 0.752577\n",
      "Epoch 12926 - Train Loss: 0.106635, Train Acc: 0.825641 | Val Loss: 0.126685, Val Acc: 0.752577\n",
      "Epoch 12927 - Train Loss: 0.106630, Train Acc: 0.825641 | Val Loss: 0.126681, Val Acc: 0.752577\n",
      "Epoch 12928 - Train Loss: 0.106624, Train Acc: 0.825641 | Val Loss: 0.126677, Val Acc: 0.752577\n",
      "Epoch 12929 - Train Loss: 0.106619, Train Acc: 0.825641 | Val Loss: 0.126672, Val Acc: 0.752577\n",
      "Epoch 12930 - Train Loss: 0.106614, Train Acc: 0.825641 | Val Loss: 0.126668, Val Acc: 0.752577\n",
      "Epoch 12931 - Train Loss: 0.106608, Train Acc: 0.825641 | Val Loss: 0.126664, Val Acc: 0.752577\n",
      "Epoch 12932 - Train Loss: 0.106603, Train Acc: 0.825641 | Val Loss: 0.126660, Val Acc: 0.752577\n",
      "Epoch 12933 - Train Loss: 0.106597, Train Acc: 0.825641 | Val Loss: 0.126656, Val Acc: 0.752577\n",
      "Epoch 12934 - Train Loss: 0.106592, Train Acc: 0.825641 | Val Loss: 0.126652, Val Acc: 0.752577\n",
      "Epoch 12935 - Train Loss: 0.106586, Train Acc: 0.825641 | Val Loss: 0.126648, Val Acc: 0.752577\n",
      "Epoch 12936 - Train Loss: 0.106581, Train Acc: 0.825641 | Val Loss: 0.126644, Val Acc: 0.752577\n",
      "Epoch 12937 - Train Loss: 0.106575, Train Acc: 0.825641 | Val Loss: 0.126640, Val Acc: 0.752577\n",
      "Epoch 12938 - Train Loss: 0.106570, Train Acc: 0.825641 | Val Loss: 0.126636, Val Acc: 0.752577\n",
      "Epoch 12939 - Train Loss: 0.106564, Train Acc: 0.825641 | Val Loss: 0.126632, Val Acc: 0.752577\n",
      "Epoch 12940 - Train Loss: 0.106559, Train Acc: 0.825641 | Val Loss: 0.126628, Val Acc: 0.752577\n",
      "Epoch 12941 - Train Loss: 0.106554, Train Acc: 0.825641 | Val Loss: 0.126623, Val Acc: 0.752577\n",
      "Epoch 12942 - Train Loss: 0.106548, Train Acc: 0.825641 | Val Loss: 0.126619, Val Acc: 0.752577\n",
      "Epoch 12943 - Train Loss: 0.106543, Train Acc: 0.825641 | Val Loss: 0.126615, Val Acc: 0.752577\n",
      "Epoch 12944 - Train Loss: 0.106537, Train Acc: 0.825641 | Val Loss: 0.126611, Val Acc: 0.752577\n",
      "Epoch 12945 - Train Loss: 0.106532, Train Acc: 0.825641 | Val Loss: 0.126607, Val Acc: 0.752577\n",
      "Epoch 12946 - Train Loss: 0.106526, Train Acc: 0.825641 | Val Loss: 0.126603, Val Acc: 0.752577\n",
      "Epoch 12947 - Train Loss: 0.106521, Train Acc: 0.825641 | Val Loss: 0.126599, Val Acc: 0.752577\n",
      "Epoch 12948 - Train Loss: 0.106515, Train Acc: 0.825641 | Val Loss: 0.126595, Val Acc: 0.752577\n",
      "Epoch 12949 - Train Loss: 0.106510, Train Acc: 0.825641 | Val Loss: 0.126591, Val Acc: 0.752577\n",
      "Epoch 12950 - Train Loss: 0.106504, Train Acc: 0.825641 | Val Loss: 0.126587, Val Acc: 0.752577\n",
      "Epoch 12951 - Train Loss: 0.106499, Train Acc: 0.825641 | Val Loss: 0.126583, Val Acc: 0.752577\n",
      "Epoch 12952 - Train Loss: 0.106494, Train Acc: 0.825641 | Val Loss: 0.126579, Val Acc: 0.752577\n",
      "Epoch 12953 - Train Loss: 0.106488, Train Acc: 0.825641 | Val Loss: 0.126575, Val Acc: 0.752577\n",
      "Epoch 12954 - Train Loss: 0.106483, Train Acc: 0.825641 | Val Loss: 0.126571, Val Acc: 0.752577\n",
      "Epoch 12955 - Train Loss: 0.106477, Train Acc: 0.825641 | Val Loss: 0.126567, Val Acc: 0.752577\n",
      "Epoch 12956 - Train Loss: 0.106472, Train Acc: 0.825641 | Val Loss: 0.126563, Val Acc: 0.752577\n",
      "Epoch 12957 - Train Loss: 0.106466, Train Acc: 0.825641 | Val Loss: 0.126558, Val Acc: 0.752577\n",
      "Epoch 12958 - Train Loss: 0.106461, Train Acc: 0.825641 | Val Loss: 0.126554, Val Acc: 0.752577\n",
      "Epoch 12959 - Train Loss: 0.106456, Train Acc: 0.825641 | Val Loss: 0.126550, Val Acc: 0.752577\n",
      "Epoch 12960 - Train Loss: 0.106450, Train Acc: 0.825641 | Val Loss: 0.126546, Val Acc: 0.752577\n",
      "Epoch 12961 - Train Loss: 0.106445, Train Acc: 0.825641 | Val Loss: 0.126542, Val Acc: 0.752577\n",
      "Epoch 12962 - Train Loss: 0.106439, Train Acc: 0.825641 | Val Loss: 0.126538, Val Acc: 0.752577\n",
      "Epoch 12963 - Train Loss: 0.106434, Train Acc: 0.825641 | Val Loss: 0.126534, Val Acc: 0.752577\n",
      "Epoch 12964 - Train Loss: 0.106428, Train Acc: 0.825641 | Val Loss: 0.126530, Val Acc: 0.752577\n",
      "Epoch 12965 - Train Loss: 0.106423, Train Acc: 0.825641 | Val Loss: 0.126526, Val Acc: 0.752577\n",
      "Epoch 12966 - Train Loss: 0.106417, Train Acc: 0.825641 | Val Loss: 0.126522, Val Acc: 0.752577\n",
      "Epoch 12967 - Train Loss: 0.106412, Train Acc: 0.825641 | Val Loss: 0.126518, Val Acc: 0.752577\n",
      "Epoch 12968 - Train Loss: 0.106407, Train Acc: 0.825641 | Val Loss: 0.126514, Val Acc: 0.752577\n",
      "Epoch 12969 - Train Loss: 0.106401, Train Acc: 0.825641 | Val Loss: 0.126510, Val Acc: 0.752577\n",
      "Epoch 12970 - Train Loss: 0.106396, Train Acc: 0.825641 | Val Loss: 0.126506, Val Acc: 0.752577\n",
      "Epoch 12971 - Train Loss: 0.106390, Train Acc: 0.825641 | Val Loss: 0.126502, Val Acc: 0.752577\n",
      "Epoch 12972 - Train Loss: 0.106385, Train Acc: 0.825641 | Val Loss: 0.126498, Val Acc: 0.752577\n",
      "Epoch 12973 - Train Loss: 0.106379, Train Acc: 0.825641 | Val Loss: 0.126494, Val Acc: 0.752577\n",
      "Epoch 12974 - Train Loss: 0.106374, Train Acc: 0.825641 | Val Loss: 0.126490, Val Acc: 0.752577\n",
      "Epoch 12975 - Train Loss: 0.106369, Train Acc: 0.825641 | Val Loss: 0.126485, Val Acc: 0.752577\n",
      "Epoch 12976 - Train Loss: 0.106363, Train Acc: 0.825641 | Val Loss: 0.126481, Val Acc: 0.752577\n",
      "Epoch 12977 - Train Loss: 0.106358, Train Acc: 0.825641 | Val Loss: 0.126477, Val Acc: 0.752577\n",
      "Epoch 12978 - Train Loss: 0.106352, Train Acc: 0.825641 | Val Loss: 0.126473, Val Acc: 0.752577\n",
      "Epoch 12979 - Train Loss: 0.106347, Train Acc: 0.825641 | Val Loss: 0.126469, Val Acc: 0.752577\n",
      "Epoch 12980 - Train Loss: 0.106341, Train Acc: 0.825641 | Val Loss: 0.126465, Val Acc: 0.752577\n",
      "Epoch 12981 - Train Loss: 0.106336, Train Acc: 0.825641 | Val Loss: 0.126461, Val Acc: 0.752577\n",
      "Epoch 12982 - Train Loss: 0.106331, Train Acc: 0.825641 | Val Loss: 0.126457, Val Acc: 0.752577\n",
      "Epoch 12983 - Train Loss: 0.106325, Train Acc: 0.825641 | Val Loss: 0.126453, Val Acc: 0.752577\n",
      "Epoch 12984 - Train Loss: 0.106320, Train Acc: 0.825641 | Val Loss: 0.126449, Val Acc: 0.752577\n",
      "Epoch 12985 - Train Loss: 0.106314, Train Acc: 0.825641 | Val Loss: 0.126445, Val Acc: 0.752577\n",
      "Epoch 12986 - Train Loss: 0.106309, Train Acc: 0.825641 | Val Loss: 0.126441, Val Acc: 0.752577\n",
      "Epoch 12987 - Train Loss: 0.106304, Train Acc: 0.825641 | Val Loss: 0.126437, Val Acc: 0.752577\n",
      "Epoch 12988 - Train Loss: 0.106298, Train Acc: 0.825641 | Val Loss: 0.126433, Val Acc: 0.752577\n",
      "Epoch 12989 - Train Loss: 0.106293, Train Acc: 0.825641 | Val Loss: 0.126429, Val Acc: 0.752577\n",
      "Epoch 12990 - Train Loss: 0.106287, Train Acc: 0.825641 | Val Loss: 0.126425, Val Acc: 0.752577\n",
      "Epoch 12991 - Train Loss: 0.106282, Train Acc: 0.825641 | Val Loss: 0.126421, Val Acc: 0.752577\n",
      "Epoch 12992 - Train Loss: 0.106276, Train Acc: 0.825641 | Val Loss: 0.126417, Val Acc: 0.752577\n",
      "Epoch 12993 - Train Loss: 0.106271, Train Acc: 0.825641 | Val Loss: 0.126413, Val Acc: 0.752577\n",
      "Epoch 12994 - Train Loss: 0.106266, Train Acc: 0.825641 | Val Loss: 0.126409, Val Acc: 0.752577\n",
      "Epoch 12995 - Train Loss: 0.106260, Train Acc: 0.825641 | Val Loss: 0.126405, Val Acc: 0.752577\n",
      "Epoch 12996 - Train Loss: 0.106255, Train Acc: 0.825641 | Val Loss: 0.126401, Val Acc: 0.752577\n",
      "Epoch 12997 - Train Loss: 0.106249, Train Acc: 0.825641 | Val Loss: 0.126397, Val Acc: 0.752577\n",
      "Epoch 12998 - Train Loss: 0.106244, Train Acc: 0.825641 | Val Loss: 0.126393, Val Acc: 0.752577\n",
      "Epoch 12999 - Train Loss: 0.106239, Train Acc: 0.825641 | Val Loss: 0.126389, Val Acc: 0.752577\n",
      "Epoch 13000 - Train Loss: 0.106233, Train Acc: 0.825641 | Val Loss: 0.126385, Val Acc: 0.752577\n",
      "Epoch 13001 - Train Loss: 0.106228, Train Acc: 0.825641 | Val Loss: 0.126380, Val Acc: 0.752577\n",
      "Epoch 13002 - Train Loss: 0.106222, Train Acc: 0.825641 | Val Loss: 0.126376, Val Acc: 0.752577\n",
      "Epoch 13003 - Train Loss: 0.106217, Train Acc: 0.825641 | Val Loss: 0.126372, Val Acc: 0.752577\n",
      "Epoch 13004 - Train Loss: 0.106212, Train Acc: 0.825641 | Val Loss: 0.126368, Val Acc: 0.752577\n",
      "Epoch 13005 - Train Loss: 0.106206, Train Acc: 0.825641 | Val Loss: 0.126364, Val Acc: 0.752577\n",
      "Epoch 13006 - Train Loss: 0.106201, Train Acc: 0.825641 | Val Loss: 0.126360, Val Acc: 0.752577\n",
      "Epoch 13007 - Train Loss: 0.106195, Train Acc: 0.825641 | Val Loss: 0.126356, Val Acc: 0.752577\n",
      "Epoch 13008 - Train Loss: 0.106190, Train Acc: 0.825641 | Val Loss: 0.126352, Val Acc: 0.752577\n",
      "Epoch 13009 - Train Loss: 0.106185, Train Acc: 0.825641 | Val Loss: 0.126348, Val Acc: 0.752577\n",
      "Epoch 13010 - Train Loss: 0.106179, Train Acc: 0.825641 | Val Loss: 0.126344, Val Acc: 0.752577\n",
      "Epoch 13011 - Train Loss: 0.106174, Train Acc: 0.825641 | Val Loss: 0.126340, Val Acc: 0.752577\n",
      "Epoch 13012 - Train Loss: 0.106168, Train Acc: 0.825641 | Val Loss: 0.126336, Val Acc: 0.752577\n",
      "Epoch 13013 - Train Loss: 0.106163, Train Acc: 0.825641 | Val Loss: 0.126332, Val Acc: 0.752577\n",
      "Epoch 13014 - Train Loss: 0.106158, Train Acc: 0.825641 | Val Loss: 0.126328, Val Acc: 0.752577\n",
      "Epoch 13015 - Train Loss: 0.106152, Train Acc: 0.825641 | Val Loss: 0.126324, Val Acc: 0.752577\n",
      "Epoch 13016 - Train Loss: 0.106147, Train Acc: 0.825641 | Val Loss: 0.126320, Val Acc: 0.752577\n",
      "Epoch 13017 - Train Loss: 0.106141, Train Acc: 0.825641 | Val Loss: 0.126316, Val Acc: 0.752577\n",
      "Epoch 13018 - Train Loss: 0.106136, Train Acc: 0.825641 | Val Loss: 0.126312, Val Acc: 0.752577\n",
      "Epoch 13019 - Train Loss: 0.106131, Train Acc: 0.825641 | Val Loss: 0.126308, Val Acc: 0.752577\n",
      "Epoch 13020 - Train Loss: 0.106125, Train Acc: 0.825641 | Val Loss: 0.126304, Val Acc: 0.752577\n",
      "Epoch 13021 - Train Loss: 0.106120, Train Acc: 0.825641 | Val Loss: 0.126300, Val Acc: 0.752577\n",
      "Epoch 13022 - Train Loss: 0.106114, Train Acc: 0.825641 | Val Loss: 0.126296, Val Acc: 0.752577\n",
      "Epoch 13023 - Train Loss: 0.106109, Train Acc: 0.825641 | Val Loss: 0.126292, Val Acc: 0.752577\n",
      "Epoch 13024 - Train Loss: 0.106104, Train Acc: 0.825641 | Val Loss: 0.126288, Val Acc: 0.752577\n",
      "Epoch 13025 - Train Loss: 0.106098, Train Acc: 0.825641 | Val Loss: 0.126284, Val Acc: 0.752577\n",
      "Epoch 13026 - Train Loss: 0.106093, Train Acc: 0.825641 | Val Loss: 0.126280, Val Acc: 0.752577\n",
      "Epoch 13027 - Train Loss: 0.106087, Train Acc: 0.825641 | Val Loss: 0.126276, Val Acc: 0.752577\n",
      "Epoch 13028 - Train Loss: 0.106082, Train Acc: 0.825641 | Val Loss: 0.126272, Val Acc: 0.752577\n",
      "Epoch 13029 - Train Loss: 0.106077, Train Acc: 0.825641 | Val Loss: 0.126268, Val Acc: 0.752577\n",
      "Epoch 13030 - Train Loss: 0.106071, Train Acc: 0.825641 | Val Loss: 0.126264, Val Acc: 0.752577\n",
      "Epoch 13031 - Train Loss: 0.106066, Train Acc: 0.825641 | Val Loss: 0.126260, Val Acc: 0.752577\n",
      "Epoch 13032 - Train Loss: 0.106061, Train Acc: 0.825641 | Val Loss: 0.126256, Val Acc: 0.752577\n",
      "Epoch 13033 - Train Loss: 0.106055, Train Acc: 0.825641 | Val Loss: 0.126252, Val Acc: 0.752577\n",
      "Epoch 13034 - Train Loss: 0.106050, Train Acc: 0.825641 | Val Loss: 0.126248, Val Acc: 0.752577\n",
      "Epoch 13035 - Train Loss: 0.106044, Train Acc: 0.825641 | Val Loss: 0.126244, Val Acc: 0.752577\n",
      "Epoch 13036 - Train Loss: 0.106039, Train Acc: 0.825641 | Val Loss: 0.126240, Val Acc: 0.752577\n",
      "Epoch 13037 - Train Loss: 0.106034, Train Acc: 0.825641 | Val Loss: 0.126236, Val Acc: 0.752577\n",
      "Epoch 13038 - Train Loss: 0.106028, Train Acc: 0.825641 | Val Loss: 0.126232, Val Acc: 0.752577\n",
      "Epoch 13039 - Train Loss: 0.106023, Train Acc: 0.825641 | Val Loss: 0.126228, Val Acc: 0.752577\n",
      "Epoch 13040 - Train Loss: 0.106018, Train Acc: 0.825641 | Val Loss: 0.126224, Val Acc: 0.752577\n",
      "Epoch 13041 - Train Loss: 0.106012, Train Acc: 0.825641 | Val Loss: 0.126220, Val Acc: 0.752577\n",
      "Epoch 13042 - Train Loss: 0.106007, Train Acc: 0.825641 | Val Loss: 0.126216, Val Acc: 0.752577\n",
      "Epoch 13043 - Train Loss: 0.106001, Train Acc: 0.825641 | Val Loss: 0.126212, Val Acc: 0.752577\n",
      "Epoch 13044 - Train Loss: 0.105996, Train Acc: 0.825641 | Val Loss: 0.126208, Val Acc: 0.752577\n",
      "Epoch 13045 - Train Loss: 0.105991, Train Acc: 0.826923 | Val Loss: 0.126204, Val Acc: 0.752577\n",
      "Epoch 13046 - Train Loss: 0.105985, Train Acc: 0.826923 | Val Loss: 0.126200, Val Acc: 0.752577\n",
      "Epoch 13047 - Train Loss: 0.105980, Train Acc: 0.826923 | Val Loss: 0.126196, Val Acc: 0.752577\n",
      "Epoch 13048 - Train Loss: 0.105975, Train Acc: 0.826923 | Val Loss: 0.126192, Val Acc: 0.752577\n",
      "Epoch 13049 - Train Loss: 0.105969, Train Acc: 0.826923 | Val Loss: 0.126188, Val Acc: 0.752577\n",
      "Epoch 13050 - Train Loss: 0.105964, Train Acc: 0.826923 | Val Loss: 0.126184, Val Acc: 0.752577\n",
      "Epoch 13051 - Train Loss: 0.105958, Train Acc: 0.826923 | Val Loss: 0.126180, Val Acc: 0.752577\n",
      "Epoch 13052 - Train Loss: 0.105953, Train Acc: 0.826923 | Val Loss: 0.126176, Val Acc: 0.752577\n",
      "Epoch 13053 - Train Loss: 0.105948, Train Acc: 0.826923 | Val Loss: 0.126172, Val Acc: 0.752577\n",
      "Epoch 13054 - Train Loss: 0.105942, Train Acc: 0.826923 | Val Loss: 0.126168, Val Acc: 0.752577\n",
      "Epoch 13055 - Train Loss: 0.105937, Train Acc: 0.826923 | Val Loss: 0.126164, Val Acc: 0.752577\n",
      "Epoch 13056 - Train Loss: 0.105932, Train Acc: 0.826923 | Val Loss: 0.126160, Val Acc: 0.752577\n",
      "Epoch 13057 - Train Loss: 0.105926, Train Acc: 0.826923 | Val Loss: 0.126156, Val Acc: 0.752577\n",
      "Epoch 13058 - Train Loss: 0.105921, Train Acc: 0.826923 | Val Loss: 0.126152, Val Acc: 0.752577\n",
      "Epoch 13059 - Train Loss: 0.105915, Train Acc: 0.826923 | Val Loss: 0.126148, Val Acc: 0.752577\n",
      "Epoch 13060 - Train Loss: 0.105910, Train Acc: 0.826923 | Val Loss: 0.126144, Val Acc: 0.752577\n",
      "Epoch 13061 - Train Loss: 0.105905, Train Acc: 0.826923 | Val Loss: 0.126140, Val Acc: 0.752577\n",
      "Epoch 13062 - Train Loss: 0.105899, Train Acc: 0.826923 | Val Loss: 0.126136, Val Acc: 0.752577\n",
      "Epoch 13063 - Train Loss: 0.105894, Train Acc: 0.826923 | Val Loss: 0.126132, Val Acc: 0.752577\n",
      "Epoch 13064 - Train Loss: 0.105889, Train Acc: 0.826923 | Val Loss: 0.126128, Val Acc: 0.752577\n",
      "Epoch 13065 - Train Loss: 0.105883, Train Acc: 0.826923 | Val Loss: 0.126124, Val Acc: 0.752577\n",
      "Epoch 13066 - Train Loss: 0.105878, Train Acc: 0.826923 | Val Loss: 0.126120, Val Acc: 0.752577\n",
      "Epoch 13067 - Train Loss: 0.105873, Train Acc: 0.826923 | Val Loss: 0.126116, Val Acc: 0.752577\n",
      "Epoch 13068 - Train Loss: 0.105867, Train Acc: 0.826923 | Val Loss: 0.126112, Val Acc: 0.752577\n",
      "Epoch 13069 - Train Loss: 0.105862, Train Acc: 0.826923 | Val Loss: 0.126108, Val Acc: 0.752577\n",
      "Epoch 13070 - Train Loss: 0.105857, Train Acc: 0.826923 | Val Loss: 0.126104, Val Acc: 0.752577\n",
      "Epoch 13071 - Train Loss: 0.105851, Train Acc: 0.826923 | Val Loss: 0.126100, Val Acc: 0.752577\n",
      "Epoch 13072 - Train Loss: 0.105846, Train Acc: 0.826923 | Val Loss: 0.126096, Val Acc: 0.752577\n",
      "Epoch 13073 - Train Loss: 0.105840, Train Acc: 0.826923 | Val Loss: 0.126092, Val Acc: 0.752577\n",
      "Epoch 13074 - Train Loss: 0.105835, Train Acc: 0.826923 | Val Loss: 0.126088, Val Acc: 0.752577\n",
      "Epoch 13075 - Train Loss: 0.105830, Train Acc: 0.826923 | Val Loss: 0.126084, Val Acc: 0.752577\n",
      "Epoch 13076 - Train Loss: 0.105824, Train Acc: 0.826923 | Val Loss: 0.126080, Val Acc: 0.752577\n",
      "Epoch 13077 - Train Loss: 0.105819, Train Acc: 0.826923 | Val Loss: 0.126076, Val Acc: 0.752577\n",
      "Epoch 13078 - Train Loss: 0.105814, Train Acc: 0.826923 | Val Loss: 0.126073, Val Acc: 0.752577\n",
      "Epoch 13079 - Train Loss: 0.105808, Train Acc: 0.826923 | Val Loss: 0.126069, Val Acc: 0.752577\n",
      "Epoch 13080 - Train Loss: 0.105803, Train Acc: 0.826923 | Val Loss: 0.126065, Val Acc: 0.752577\n",
      "Epoch 13081 - Train Loss: 0.105798, Train Acc: 0.826923 | Val Loss: 0.126061, Val Acc: 0.752577\n",
      "Epoch 13082 - Train Loss: 0.105792, Train Acc: 0.826923 | Val Loss: 0.126057, Val Acc: 0.752577\n",
      "Epoch 13083 - Train Loss: 0.105787, Train Acc: 0.826923 | Val Loss: 0.126053, Val Acc: 0.752577\n",
      "Epoch 13084 - Train Loss: 0.105782, Train Acc: 0.826923 | Val Loss: 0.126049, Val Acc: 0.752577\n",
      "Epoch 13085 - Train Loss: 0.105776, Train Acc: 0.826923 | Val Loss: 0.126045, Val Acc: 0.752577\n",
      "Epoch 13086 - Train Loss: 0.105771, Train Acc: 0.826923 | Val Loss: 0.126041, Val Acc: 0.752577\n",
      "Epoch 13087 - Train Loss: 0.105766, Train Acc: 0.826923 | Val Loss: 0.126037, Val Acc: 0.752577\n",
      "Epoch 13088 - Train Loss: 0.105760, Train Acc: 0.826923 | Val Loss: 0.126033, Val Acc: 0.752577\n",
      "Epoch 13089 - Train Loss: 0.105755, Train Acc: 0.826923 | Val Loss: 0.126029, Val Acc: 0.752577\n",
      "Epoch 13090 - Train Loss: 0.105750, Train Acc: 0.826923 | Val Loss: 0.126025, Val Acc: 0.752577\n",
      "Epoch 13091 - Train Loss: 0.105744, Train Acc: 0.826923 | Val Loss: 0.126021, Val Acc: 0.752577\n",
      "Epoch 13092 - Train Loss: 0.105739, Train Acc: 0.826923 | Val Loss: 0.126017, Val Acc: 0.752577\n",
      "Epoch 13093 - Train Loss: 0.105734, Train Acc: 0.826923 | Val Loss: 0.126013, Val Acc: 0.752577\n",
      "Epoch 13094 - Train Loss: 0.105728, Train Acc: 0.826923 | Val Loss: 0.126009, Val Acc: 0.752577\n",
      "Epoch 13095 - Train Loss: 0.105723, Train Acc: 0.826923 | Val Loss: 0.126005, Val Acc: 0.752577\n",
      "Epoch 13096 - Train Loss: 0.105718, Train Acc: 0.826923 | Val Loss: 0.126001, Val Acc: 0.752577\n",
      "Epoch 13097 - Train Loss: 0.105712, Train Acc: 0.826923 | Val Loss: 0.125997, Val Acc: 0.752577\n",
      "Epoch 13098 - Train Loss: 0.105707, Train Acc: 0.826923 | Val Loss: 0.125993, Val Acc: 0.752577\n",
      "Epoch 13099 - Train Loss: 0.105702, Train Acc: 0.826923 | Val Loss: 0.125989, Val Acc: 0.752577\n",
      "Epoch 13100 - Train Loss: 0.105696, Train Acc: 0.826923 | Val Loss: 0.125985, Val Acc: 0.752577\n",
      "Epoch 13101 - Train Loss: 0.105691, Train Acc: 0.826923 | Val Loss: 0.125981, Val Acc: 0.752577\n",
      "Epoch 13102 - Train Loss: 0.105686, Train Acc: 0.826923 | Val Loss: 0.125977, Val Acc: 0.752577\n",
      "Epoch 13103 - Train Loss: 0.105680, Train Acc: 0.826923 | Val Loss: 0.125974, Val Acc: 0.752577\n",
      "Epoch 13104 - Train Loss: 0.105675, Train Acc: 0.826923 | Val Loss: 0.125970, Val Acc: 0.752577\n",
      "Epoch 13105 - Train Loss: 0.105670, Train Acc: 0.826923 | Val Loss: 0.125966, Val Acc: 0.752577\n",
      "Epoch 13106 - Train Loss: 0.105664, Train Acc: 0.826923 | Val Loss: 0.125962, Val Acc: 0.752577\n",
      "Epoch 13107 - Train Loss: 0.105659, Train Acc: 0.826923 | Val Loss: 0.125958, Val Acc: 0.752577\n",
      "Epoch 13108 - Train Loss: 0.105654, Train Acc: 0.826923 | Val Loss: 0.125954, Val Acc: 0.752577\n",
      "Epoch 13109 - Train Loss: 0.105648, Train Acc: 0.826923 | Val Loss: 0.125950, Val Acc: 0.752577\n",
      "Epoch 13110 - Train Loss: 0.105643, Train Acc: 0.826923 | Val Loss: 0.125946, Val Acc: 0.752577\n",
      "Epoch 13111 - Train Loss: 0.105638, Train Acc: 0.826923 | Val Loss: 0.125942, Val Acc: 0.752577\n",
      "Epoch 13112 - Train Loss: 0.105632, Train Acc: 0.826923 | Val Loss: 0.125938, Val Acc: 0.752577\n",
      "Epoch 13113 - Train Loss: 0.105627, Train Acc: 0.826923 | Val Loss: 0.125934, Val Acc: 0.752577\n",
      "Epoch 13114 - Train Loss: 0.105622, Train Acc: 0.826923 | Val Loss: 0.125930, Val Acc: 0.752577\n",
      "Epoch 13115 - Train Loss: 0.105616, Train Acc: 0.826923 | Val Loss: 0.125926, Val Acc: 0.752577\n",
      "Epoch 13116 - Train Loss: 0.105611, Train Acc: 0.826923 | Val Loss: 0.125922, Val Acc: 0.752577\n",
      "Epoch 13117 - Train Loss: 0.105606, Train Acc: 0.826923 | Val Loss: 0.125918, Val Acc: 0.752577\n",
      "Epoch 13118 - Train Loss: 0.105600, Train Acc: 0.826923 | Val Loss: 0.125914, Val Acc: 0.752577\n",
      "Epoch 13119 - Train Loss: 0.105595, Train Acc: 0.826923 | Val Loss: 0.125910, Val Acc: 0.752577\n",
      "Epoch 13120 - Train Loss: 0.105590, Train Acc: 0.826923 | Val Loss: 0.125906, Val Acc: 0.752577\n",
      "Epoch 13121 - Train Loss: 0.105584, Train Acc: 0.826923 | Val Loss: 0.125902, Val Acc: 0.752577\n",
      "Epoch 13122 - Train Loss: 0.105579, Train Acc: 0.826923 | Val Loss: 0.125899, Val Acc: 0.752577\n",
      "Epoch 13123 - Train Loss: 0.105574, Train Acc: 0.826923 | Val Loss: 0.125895, Val Acc: 0.752577\n",
      "Epoch 13124 - Train Loss: 0.105568, Train Acc: 0.826923 | Val Loss: 0.125891, Val Acc: 0.752577\n",
      "Epoch 13125 - Train Loss: 0.105563, Train Acc: 0.826923 | Val Loss: 0.125887, Val Acc: 0.752577\n",
      "Epoch 13126 - Train Loss: 0.105558, Train Acc: 0.826923 | Val Loss: 0.125883, Val Acc: 0.752577\n",
      "Epoch 13127 - Train Loss: 0.105552, Train Acc: 0.826923 | Val Loss: 0.125879, Val Acc: 0.752577\n",
      "Epoch 13128 - Train Loss: 0.105547, Train Acc: 0.826923 | Val Loss: 0.125875, Val Acc: 0.752577\n",
      "Epoch 13129 - Train Loss: 0.105542, Train Acc: 0.828205 | Val Loss: 0.125871, Val Acc: 0.752577\n",
      "Epoch 13130 - Train Loss: 0.105537, Train Acc: 0.828205 | Val Loss: 0.125867, Val Acc: 0.752577\n",
      "Epoch 13131 - Train Loss: 0.105531, Train Acc: 0.828205 | Val Loss: 0.125863, Val Acc: 0.752577\n",
      "Epoch 13132 - Train Loss: 0.105526, Train Acc: 0.828205 | Val Loss: 0.125859, Val Acc: 0.752577\n",
      "Epoch 13133 - Train Loss: 0.105521, Train Acc: 0.828205 | Val Loss: 0.125855, Val Acc: 0.752577\n",
      "Epoch 13134 - Train Loss: 0.105515, Train Acc: 0.828205 | Val Loss: 0.125851, Val Acc: 0.752577\n",
      "Epoch 13135 - Train Loss: 0.105510, Train Acc: 0.828205 | Val Loss: 0.125847, Val Acc: 0.752577\n",
      "Epoch 13136 - Train Loss: 0.105505, Train Acc: 0.828205 | Val Loss: 0.125844, Val Acc: 0.752577\n",
      "Epoch 13137 - Train Loss: 0.105499, Train Acc: 0.829487 | Val Loss: 0.125840, Val Acc: 0.752577\n",
      "Epoch 13138 - Train Loss: 0.105494, Train Acc: 0.829487 | Val Loss: 0.125836, Val Acc: 0.752577\n",
      "Epoch 13139 - Train Loss: 0.105489, Train Acc: 0.829487 | Val Loss: 0.125832, Val Acc: 0.752577\n",
      "Epoch 13140 - Train Loss: 0.105483, Train Acc: 0.829487 | Val Loss: 0.125828, Val Acc: 0.752577\n",
      "Epoch 13141 - Train Loss: 0.105478, Train Acc: 0.829487 | Val Loss: 0.125824, Val Acc: 0.752577\n",
      "Epoch 13142 - Train Loss: 0.105473, Train Acc: 0.829487 | Val Loss: 0.125820, Val Acc: 0.752577\n",
      "Epoch 13143 - Train Loss: 0.105468, Train Acc: 0.829487 | Val Loss: 0.125816, Val Acc: 0.752577\n",
      "Epoch 13144 - Train Loss: 0.105462, Train Acc: 0.829487 | Val Loss: 0.125812, Val Acc: 0.752577\n",
      "Epoch 13145 - Train Loss: 0.105457, Train Acc: 0.829487 | Val Loss: 0.125808, Val Acc: 0.752577\n",
      "Epoch 13146 - Train Loss: 0.105452, Train Acc: 0.829487 | Val Loss: 0.125804, Val Acc: 0.752577\n",
      "Epoch 13147 - Train Loss: 0.105446, Train Acc: 0.829487 | Val Loss: 0.125800, Val Acc: 0.752577\n",
      "Epoch 13148 - Train Loss: 0.105441, Train Acc: 0.829487 | Val Loss: 0.125796, Val Acc: 0.752577\n",
      "Epoch 13149 - Train Loss: 0.105436, Train Acc: 0.829487 | Val Loss: 0.125793, Val Acc: 0.752577\n",
      "Epoch 13150 - Train Loss: 0.105430, Train Acc: 0.829487 | Val Loss: 0.125789, Val Acc: 0.752577\n",
      "Epoch 13151 - Train Loss: 0.105425, Train Acc: 0.829487 | Val Loss: 0.125785, Val Acc: 0.752577\n",
      "Epoch 13152 - Train Loss: 0.105420, Train Acc: 0.829487 | Val Loss: 0.125781, Val Acc: 0.752577\n",
      "Epoch 13153 - Train Loss: 0.105415, Train Acc: 0.829487 | Val Loss: 0.125777, Val Acc: 0.752577\n",
      "Epoch 13154 - Train Loss: 0.105409, Train Acc: 0.829487 | Val Loss: 0.125773, Val Acc: 0.752577\n",
      "Epoch 13155 - Train Loss: 0.105404, Train Acc: 0.829487 | Val Loss: 0.125769, Val Acc: 0.752577\n",
      "Epoch 13156 - Train Loss: 0.105399, Train Acc: 0.829487 | Val Loss: 0.125765, Val Acc: 0.752577\n",
      "Epoch 13157 - Train Loss: 0.105393, Train Acc: 0.829487 | Val Loss: 0.125761, Val Acc: 0.752577\n",
      "Epoch 13158 - Train Loss: 0.105388, Train Acc: 0.829487 | Val Loss: 0.125757, Val Acc: 0.752577\n",
      "Epoch 13159 - Train Loss: 0.105383, Train Acc: 0.829487 | Val Loss: 0.125753, Val Acc: 0.752577\n",
      "Epoch 13160 - Train Loss: 0.105378, Train Acc: 0.829487 | Val Loss: 0.125749, Val Acc: 0.752577\n",
      "Epoch 13161 - Train Loss: 0.105372, Train Acc: 0.829487 | Val Loss: 0.125745, Val Acc: 0.752577\n",
      "Epoch 13162 - Train Loss: 0.105367, Train Acc: 0.829487 | Val Loss: 0.125742, Val Acc: 0.752577\n",
      "Epoch 13163 - Train Loss: 0.105362, Train Acc: 0.829487 | Val Loss: 0.125738, Val Acc: 0.752577\n",
      "Epoch 13164 - Train Loss: 0.105356, Train Acc: 0.829487 | Val Loss: 0.125734, Val Acc: 0.752577\n",
      "Epoch 13165 - Train Loss: 0.105351, Train Acc: 0.829487 | Val Loss: 0.125730, Val Acc: 0.752577\n",
      "Epoch 13166 - Train Loss: 0.105346, Train Acc: 0.829487 | Val Loss: 0.125726, Val Acc: 0.752577\n",
      "Epoch 13167 - Train Loss: 0.105341, Train Acc: 0.829487 | Val Loss: 0.125722, Val Acc: 0.752577\n",
      "Epoch 13168 - Train Loss: 0.105335, Train Acc: 0.829487 | Val Loss: 0.125718, Val Acc: 0.752577\n",
      "Epoch 13169 - Train Loss: 0.105330, Train Acc: 0.829487 | Val Loss: 0.125714, Val Acc: 0.752577\n",
      "Epoch 13170 - Train Loss: 0.105325, Train Acc: 0.829487 | Val Loss: 0.125710, Val Acc: 0.752577\n",
      "Epoch 13171 - Train Loss: 0.105319, Train Acc: 0.829487 | Val Loss: 0.125706, Val Acc: 0.752577\n",
      "Epoch 13172 - Train Loss: 0.105314, Train Acc: 0.829487 | Val Loss: 0.125702, Val Acc: 0.752577\n",
      "Epoch 13173 - Train Loss: 0.105309, Train Acc: 0.830769 | Val Loss: 0.125699, Val Acc: 0.752577\n",
      "Epoch 13174 - Train Loss: 0.105304, Train Acc: 0.830769 | Val Loss: 0.125695, Val Acc: 0.752577\n",
      "Epoch 13175 - Train Loss: 0.105298, Train Acc: 0.830769 | Val Loss: 0.125691, Val Acc: 0.752577\n",
      "Epoch 13176 - Train Loss: 0.105293, Train Acc: 0.830769 | Val Loss: 0.125687, Val Acc: 0.752577\n",
      "Epoch 13177 - Train Loss: 0.105288, Train Acc: 0.830769 | Val Loss: 0.125683, Val Acc: 0.752577\n",
      "Epoch 13178 - Train Loss: 0.105283, Train Acc: 0.830769 | Val Loss: 0.125679, Val Acc: 0.752577\n",
      "Epoch 13179 - Train Loss: 0.105277, Train Acc: 0.830769 | Val Loss: 0.125675, Val Acc: 0.752577\n",
      "Epoch 13180 - Train Loss: 0.105272, Train Acc: 0.830769 | Val Loss: 0.125671, Val Acc: 0.752577\n",
      "Epoch 13181 - Train Loss: 0.105267, Train Acc: 0.830769 | Val Loss: 0.125667, Val Acc: 0.752577\n",
      "Epoch 13182 - Train Loss: 0.105261, Train Acc: 0.830769 | Val Loss: 0.125663, Val Acc: 0.752577\n",
      "Epoch 13183 - Train Loss: 0.105256, Train Acc: 0.830769 | Val Loss: 0.125660, Val Acc: 0.752577\n",
      "Epoch 13184 - Train Loss: 0.105251, Train Acc: 0.830769 | Val Loss: 0.125656, Val Acc: 0.752577\n",
      "Epoch 13185 - Train Loss: 0.105246, Train Acc: 0.830769 | Val Loss: 0.125652, Val Acc: 0.752577\n",
      "Epoch 13186 - Train Loss: 0.105240, Train Acc: 0.830769 | Val Loss: 0.125648, Val Acc: 0.752577\n",
      "Epoch 13187 - Train Loss: 0.105235, Train Acc: 0.830769 | Val Loss: 0.125644, Val Acc: 0.752577\n",
      "Epoch 13188 - Train Loss: 0.105230, Train Acc: 0.830769 | Val Loss: 0.125640, Val Acc: 0.752577\n",
      "Epoch 13189 - Train Loss: 0.105225, Train Acc: 0.830769 | Val Loss: 0.125636, Val Acc: 0.752577\n",
      "Epoch 13190 - Train Loss: 0.105219, Train Acc: 0.830769 | Val Loss: 0.125632, Val Acc: 0.752577\n",
      "Epoch 13191 - Train Loss: 0.105214, Train Acc: 0.830769 | Val Loss: 0.125628, Val Acc: 0.752577\n",
      "Epoch 13192 - Train Loss: 0.105209, Train Acc: 0.830769 | Val Loss: 0.125625, Val Acc: 0.752577\n",
      "Epoch 13193 - Train Loss: 0.105203, Train Acc: 0.830769 | Val Loss: 0.125621, Val Acc: 0.752577\n",
      "Epoch 13194 - Train Loss: 0.105198, Train Acc: 0.830769 | Val Loss: 0.125617, Val Acc: 0.752577\n",
      "Epoch 13195 - Train Loss: 0.105193, Train Acc: 0.830769 | Val Loss: 0.125613, Val Acc: 0.752577\n",
      "Epoch 13196 - Train Loss: 0.105188, Train Acc: 0.830769 | Val Loss: 0.125609, Val Acc: 0.752577\n",
      "Epoch 13197 - Train Loss: 0.105182, Train Acc: 0.830769 | Val Loss: 0.125605, Val Acc: 0.752577\n",
      "Epoch 13198 - Train Loss: 0.105177, Train Acc: 0.830769 | Val Loss: 0.125601, Val Acc: 0.752577\n",
      "Epoch 13199 - Train Loss: 0.105172, Train Acc: 0.830769 | Val Loss: 0.125597, Val Acc: 0.752577\n",
      "Epoch 13200 - Train Loss: 0.105167, Train Acc: 0.830769 | Val Loss: 0.125593, Val Acc: 0.752577\n",
      "Epoch 13201 - Train Loss: 0.105161, Train Acc: 0.830769 | Val Loss: 0.125590, Val Acc: 0.752577\n",
      "Epoch 13202 - Train Loss: 0.105156, Train Acc: 0.830769 | Val Loss: 0.125586, Val Acc: 0.752577\n",
      "Epoch 13203 - Train Loss: 0.105151, Train Acc: 0.830769 | Val Loss: 0.125582, Val Acc: 0.752577\n",
      "Epoch 13204 - Train Loss: 0.105146, Train Acc: 0.830769 | Val Loss: 0.125578, Val Acc: 0.752577\n",
      "Epoch 13205 - Train Loss: 0.105140, Train Acc: 0.830769 | Val Loss: 0.125574, Val Acc: 0.752577\n",
      "Epoch 13206 - Train Loss: 0.105135, Train Acc: 0.830769 | Val Loss: 0.125570, Val Acc: 0.752577\n",
      "Epoch 13207 - Train Loss: 0.105130, Train Acc: 0.830769 | Val Loss: 0.125566, Val Acc: 0.752577\n",
      "Epoch 13208 - Train Loss: 0.105125, Train Acc: 0.830769 | Val Loss: 0.125562, Val Acc: 0.752577\n",
      "Epoch 13209 - Train Loss: 0.105119, Train Acc: 0.830769 | Val Loss: 0.125558, Val Acc: 0.752577\n",
      "Epoch 13210 - Train Loss: 0.105114, Train Acc: 0.830769 | Val Loss: 0.125555, Val Acc: 0.752577\n",
      "Epoch 13211 - Train Loss: 0.105109, Train Acc: 0.830769 | Val Loss: 0.125551, Val Acc: 0.752577\n",
      "Epoch 13212 - Train Loss: 0.105104, Train Acc: 0.830769 | Val Loss: 0.125547, Val Acc: 0.752577\n",
      "Epoch 13213 - Train Loss: 0.105098, Train Acc: 0.830769 | Val Loss: 0.125543, Val Acc: 0.752577\n",
      "Epoch 13214 - Train Loss: 0.105093, Train Acc: 0.830769 | Val Loss: 0.125539, Val Acc: 0.752577\n",
      "Epoch 13215 - Train Loss: 0.105088, Train Acc: 0.830769 | Val Loss: 0.125535, Val Acc: 0.752577\n",
      "Epoch 13216 - Train Loss: 0.105083, Train Acc: 0.830769 | Val Loss: 0.125531, Val Acc: 0.752577\n",
      "Epoch 13217 - Train Loss: 0.105077, Train Acc: 0.830769 | Val Loss: 0.125528, Val Acc: 0.752577\n",
      "Epoch 13218 - Train Loss: 0.105072, Train Acc: 0.830769 | Val Loss: 0.125524, Val Acc: 0.752577\n",
      "Epoch 13219 - Train Loss: 0.105067, Train Acc: 0.832051 | Val Loss: 0.125520, Val Acc: 0.752577\n",
      "Epoch 13220 - Train Loss: 0.105062, Train Acc: 0.832051 | Val Loss: 0.125516, Val Acc: 0.752577\n",
      "Epoch 13221 - Train Loss: 0.105056, Train Acc: 0.832051 | Val Loss: 0.125512, Val Acc: 0.752577\n",
      "Epoch 13222 - Train Loss: 0.105051, Train Acc: 0.832051 | Val Loss: 0.125508, Val Acc: 0.752577\n",
      "Epoch 13223 - Train Loss: 0.105046, Train Acc: 0.832051 | Val Loss: 0.125504, Val Acc: 0.752577\n",
      "Epoch 13224 - Train Loss: 0.105041, Train Acc: 0.832051 | Val Loss: 0.125500, Val Acc: 0.752577\n",
      "Epoch 13225 - Train Loss: 0.105035, Train Acc: 0.832051 | Val Loss: 0.125497, Val Acc: 0.752577\n",
      "Epoch 13226 - Train Loss: 0.105030, Train Acc: 0.832051 | Val Loss: 0.125493, Val Acc: 0.752577\n",
      "Epoch 13227 - Train Loss: 0.105025, Train Acc: 0.832051 | Val Loss: 0.125489, Val Acc: 0.752577\n",
      "Epoch 13228 - Train Loss: 0.105020, Train Acc: 0.832051 | Val Loss: 0.125485, Val Acc: 0.752577\n",
      "Epoch 13229 - Train Loss: 0.105014, Train Acc: 0.832051 | Val Loss: 0.125481, Val Acc: 0.752577\n",
      "Epoch 13230 - Train Loss: 0.105009, Train Acc: 0.832051 | Val Loss: 0.125477, Val Acc: 0.752577\n",
      "Epoch 13231 - Train Loss: 0.105004, Train Acc: 0.832051 | Val Loss: 0.125473, Val Acc: 0.752577\n",
      "Epoch 13232 - Train Loss: 0.104999, Train Acc: 0.832051 | Val Loss: 0.125470, Val Acc: 0.752577\n",
      "Epoch 13233 - Train Loss: 0.104994, Train Acc: 0.832051 | Val Loss: 0.125466, Val Acc: 0.752577\n",
      "Epoch 13234 - Train Loss: 0.104988, Train Acc: 0.832051 | Val Loss: 0.125462, Val Acc: 0.752577\n",
      "Epoch 13235 - Train Loss: 0.104983, Train Acc: 0.832051 | Val Loss: 0.125458, Val Acc: 0.752577\n",
      "Epoch 13236 - Train Loss: 0.104978, Train Acc: 0.832051 | Val Loss: 0.125454, Val Acc: 0.752577\n",
      "Epoch 13237 - Train Loss: 0.104973, Train Acc: 0.832051 | Val Loss: 0.125450, Val Acc: 0.752577\n",
      "Epoch 13238 - Train Loss: 0.104967, Train Acc: 0.832051 | Val Loss: 0.125446, Val Acc: 0.752577\n",
      "Epoch 13239 - Train Loss: 0.104962, Train Acc: 0.832051 | Val Loss: 0.125443, Val Acc: 0.752577\n",
      "Epoch 13240 - Train Loss: 0.104957, Train Acc: 0.832051 | Val Loss: 0.125439, Val Acc: 0.752577\n",
      "Epoch 13241 - Train Loss: 0.104952, Train Acc: 0.832051 | Val Loss: 0.125435, Val Acc: 0.752577\n",
      "Epoch 13242 - Train Loss: 0.104946, Train Acc: 0.832051 | Val Loss: 0.125431, Val Acc: 0.752577\n",
      "Epoch 13243 - Train Loss: 0.104941, Train Acc: 0.832051 | Val Loss: 0.125427, Val Acc: 0.752577\n",
      "Epoch 13244 - Train Loss: 0.104936, Train Acc: 0.832051 | Val Loss: 0.125423, Val Acc: 0.752577\n",
      "Epoch 13245 - Train Loss: 0.104931, Train Acc: 0.832051 | Val Loss: 0.125419, Val Acc: 0.752577\n",
      "Epoch 13246 - Train Loss: 0.104926, Train Acc: 0.832051 | Val Loss: 0.125416, Val Acc: 0.752577\n",
      "Epoch 13247 - Train Loss: 0.104920, Train Acc: 0.832051 | Val Loss: 0.125412, Val Acc: 0.752577\n",
      "Epoch 13248 - Train Loss: 0.104915, Train Acc: 0.832051 | Val Loss: 0.125408, Val Acc: 0.752577\n",
      "Epoch 13249 - Train Loss: 0.104910, Train Acc: 0.832051 | Val Loss: 0.125404, Val Acc: 0.752577\n",
      "Epoch 13250 - Train Loss: 0.104905, Train Acc: 0.832051 | Val Loss: 0.125400, Val Acc: 0.752577\n",
      "Epoch 13251 - Train Loss: 0.104899, Train Acc: 0.832051 | Val Loss: 0.125396, Val Acc: 0.752577\n",
      "Epoch 13252 - Train Loss: 0.104894, Train Acc: 0.832051 | Val Loss: 0.125392, Val Acc: 0.752577\n",
      "Epoch 13253 - Train Loss: 0.104889, Train Acc: 0.832051 | Val Loss: 0.125389, Val Acc: 0.752577\n",
      "Epoch 13254 - Train Loss: 0.104884, Train Acc: 0.832051 | Val Loss: 0.125385, Val Acc: 0.752577\n",
      "Epoch 13255 - Train Loss: 0.104879, Train Acc: 0.832051 | Val Loss: 0.125381, Val Acc: 0.752577\n",
      "Epoch 13256 - Train Loss: 0.104873, Train Acc: 0.832051 | Val Loss: 0.125377, Val Acc: 0.752577\n",
      "Epoch 13257 - Train Loss: 0.104868, Train Acc: 0.832051 | Val Loss: 0.125373, Val Acc: 0.752577\n",
      "Epoch 13258 - Train Loss: 0.104863, Train Acc: 0.832051 | Val Loss: 0.125369, Val Acc: 0.752577\n",
      "Epoch 13259 - Train Loss: 0.104858, Train Acc: 0.832051 | Val Loss: 0.125366, Val Acc: 0.752577\n",
      "Epoch 13260 - Train Loss: 0.104852, Train Acc: 0.832051 | Val Loss: 0.125362, Val Acc: 0.752577\n",
      "Epoch 13261 - Train Loss: 0.104847, Train Acc: 0.832051 | Val Loss: 0.125358, Val Acc: 0.752577\n",
      "Epoch 13262 - Train Loss: 0.104842, Train Acc: 0.832051 | Val Loss: 0.125354, Val Acc: 0.752577\n",
      "Epoch 13263 - Train Loss: 0.104837, Train Acc: 0.832051 | Val Loss: 0.125350, Val Acc: 0.752577\n",
      "Epoch 13264 - Train Loss: 0.104832, Train Acc: 0.832051 | Val Loss: 0.125346, Val Acc: 0.752577\n",
      "Epoch 13265 - Train Loss: 0.104826, Train Acc: 0.832051 | Val Loss: 0.125343, Val Acc: 0.752577\n",
      "Epoch 13266 - Train Loss: 0.104821, Train Acc: 0.832051 | Val Loss: 0.125339, Val Acc: 0.752577\n",
      "Epoch 13267 - Train Loss: 0.104816, Train Acc: 0.832051 | Val Loss: 0.125335, Val Acc: 0.752577\n",
      "Epoch 13268 - Train Loss: 0.104811, Train Acc: 0.832051 | Val Loss: 0.125331, Val Acc: 0.752577\n",
      "Epoch 13269 - Train Loss: 0.104806, Train Acc: 0.832051 | Val Loss: 0.125327, Val Acc: 0.752577\n",
      "Epoch 13270 - Train Loss: 0.104800, Train Acc: 0.832051 | Val Loss: 0.125323, Val Acc: 0.752577\n",
      "Epoch 13271 - Train Loss: 0.104795, Train Acc: 0.832051 | Val Loss: 0.125320, Val Acc: 0.752577\n",
      "Epoch 13272 - Train Loss: 0.104790, Train Acc: 0.832051 | Val Loss: 0.125316, Val Acc: 0.752577\n",
      "Epoch 13273 - Train Loss: 0.104785, Train Acc: 0.832051 | Val Loss: 0.125312, Val Acc: 0.752577\n",
      "Epoch 13274 - Train Loss: 0.104780, Train Acc: 0.832051 | Val Loss: 0.125308, Val Acc: 0.752577\n",
      "Epoch 13275 - Train Loss: 0.104774, Train Acc: 0.832051 | Val Loss: 0.125304, Val Acc: 0.752577\n",
      "Epoch 13276 - Train Loss: 0.104769, Train Acc: 0.832051 | Val Loss: 0.125300, Val Acc: 0.752577\n",
      "Epoch 13277 - Train Loss: 0.104764, Train Acc: 0.832051 | Val Loss: 0.125297, Val Acc: 0.752577\n",
      "Epoch 13278 - Train Loss: 0.104759, Train Acc: 0.832051 | Val Loss: 0.125293, Val Acc: 0.752577\n",
      "Epoch 13279 - Train Loss: 0.104754, Train Acc: 0.832051 | Val Loss: 0.125289, Val Acc: 0.752577\n",
      "Epoch 13280 - Train Loss: 0.104748, Train Acc: 0.832051 | Val Loss: 0.125285, Val Acc: 0.752577\n",
      "Epoch 13281 - Train Loss: 0.104743, Train Acc: 0.832051 | Val Loss: 0.125281, Val Acc: 0.752577\n",
      "Epoch 13282 - Train Loss: 0.104738, Train Acc: 0.832051 | Val Loss: 0.125277, Val Acc: 0.752577\n",
      "Epoch 13283 - Train Loss: 0.104733, Train Acc: 0.832051 | Val Loss: 0.125274, Val Acc: 0.752577\n",
      "Epoch 13284 - Train Loss: 0.104728, Train Acc: 0.832051 | Val Loss: 0.125270, Val Acc: 0.752577\n",
      "Epoch 13285 - Train Loss: 0.104722, Train Acc: 0.832051 | Val Loss: 0.125266, Val Acc: 0.752577\n",
      "Epoch 13286 - Train Loss: 0.104717, Train Acc: 0.832051 | Val Loss: 0.125262, Val Acc: 0.752577\n",
      "Epoch 13287 - Train Loss: 0.104712, Train Acc: 0.832051 | Val Loss: 0.125258, Val Acc: 0.752577\n",
      "Epoch 13288 - Train Loss: 0.104707, Train Acc: 0.832051 | Val Loss: 0.125254, Val Acc: 0.752577\n",
      "Epoch 13289 - Train Loss: 0.104702, Train Acc: 0.832051 | Val Loss: 0.125251, Val Acc: 0.752577\n",
      "Epoch 13290 - Train Loss: 0.104696, Train Acc: 0.832051 | Val Loss: 0.125247, Val Acc: 0.752577\n",
      "Epoch 13291 - Train Loss: 0.104691, Train Acc: 0.832051 | Val Loss: 0.125243, Val Acc: 0.752577\n",
      "Epoch 13292 - Train Loss: 0.104686, Train Acc: 0.832051 | Val Loss: 0.125239, Val Acc: 0.752577\n",
      "Epoch 13293 - Train Loss: 0.104681, Train Acc: 0.832051 | Val Loss: 0.125235, Val Acc: 0.752577\n",
      "Epoch 13294 - Train Loss: 0.104676, Train Acc: 0.832051 | Val Loss: 0.125232, Val Acc: 0.752577\n",
      "Epoch 13295 - Train Loss: 0.104670, Train Acc: 0.832051 | Val Loss: 0.125228, Val Acc: 0.752577\n",
      "Epoch 13296 - Train Loss: 0.104665, Train Acc: 0.832051 | Val Loss: 0.125224, Val Acc: 0.752577\n",
      "Epoch 13297 - Train Loss: 0.104660, Train Acc: 0.832051 | Val Loss: 0.125220, Val Acc: 0.752577\n",
      "Epoch 13298 - Train Loss: 0.104655, Train Acc: 0.832051 | Val Loss: 0.125216, Val Acc: 0.752577\n",
      "Epoch 13299 - Train Loss: 0.104650, Train Acc: 0.832051 | Val Loss: 0.125212, Val Acc: 0.752577\n",
      "Epoch 13300 - Train Loss: 0.104644, Train Acc: 0.832051 | Val Loss: 0.125209, Val Acc: 0.752577\n",
      "Epoch 13301 - Train Loss: 0.104639, Train Acc: 0.832051 | Val Loss: 0.125205, Val Acc: 0.752577\n",
      "Epoch 13302 - Train Loss: 0.104634, Train Acc: 0.832051 | Val Loss: 0.125201, Val Acc: 0.752577\n",
      "Epoch 13303 - Train Loss: 0.104629, Train Acc: 0.832051 | Val Loss: 0.125197, Val Acc: 0.752577\n",
      "Epoch 13304 - Train Loss: 0.104624, Train Acc: 0.832051 | Val Loss: 0.125193, Val Acc: 0.752577\n",
      "Epoch 13305 - Train Loss: 0.104619, Train Acc: 0.832051 | Val Loss: 0.125190, Val Acc: 0.752577\n",
      "Epoch 13306 - Train Loss: 0.104613, Train Acc: 0.832051 | Val Loss: 0.125186, Val Acc: 0.752577\n",
      "Epoch 13307 - Train Loss: 0.104608, Train Acc: 0.832051 | Val Loss: 0.125182, Val Acc: 0.752577\n",
      "Epoch 13308 - Train Loss: 0.104603, Train Acc: 0.832051 | Val Loss: 0.125178, Val Acc: 0.752577\n",
      "Epoch 13309 - Train Loss: 0.104598, Train Acc: 0.832051 | Val Loss: 0.125174, Val Acc: 0.752577\n",
      "Epoch 13310 - Train Loss: 0.104593, Train Acc: 0.832051 | Val Loss: 0.125171, Val Acc: 0.752577\n",
      "Epoch 13311 - Train Loss: 0.104588, Train Acc: 0.832051 | Val Loss: 0.125167, Val Acc: 0.752577\n",
      "Epoch 13312 - Train Loss: 0.104582, Train Acc: 0.832051 | Val Loss: 0.125163, Val Acc: 0.752577\n",
      "Epoch 13313 - Train Loss: 0.104577, Train Acc: 0.832051 | Val Loss: 0.125159, Val Acc: 0.752577\n",
      "Epoch 13314 - Train Loss: 0.104572, Train Acc: 0.832051 | Val Loss: 0.125155, Val Acc: 0.752577\n",
      "Epoch 13315 - Train Loss: 0.104567, Train Acc: 0.832051 | Val Loss: 0.125152, Val Acc: 0.752577\n",
      "Epoch 13316 - Train Loss: 0.104562, Train Acc: 0.832051 | Val Loss: 0.125148, Val Acc: 0.752577\n",
      "Epoch 13317 - Train Loss: 0.104557, Train Acc: 0.832051 | Val Loss: 0.125144, Val Acc: 0.752577\n",
      "Epoch 13318 - Train Loss: 0.104551, Train Acc: 0.832051 | Val Loss: 0.125140, Val Acc: 0.752577\n",
      "Epoch 13319 - Train Loss: 0.104546, Train Acc: 0.832051 | Val Loss: 0.125136, Val Acc: 0.752577\n",
      "Epoch 13320 - Train Loss: 0.104541, Train Acc: 0.832051 | Val Loss: 0.125133, Val Acc: 0.752577\n",
      "Epoch 13321 - Train Loss: 0.104536, Train Acc: 0.832051 | Val Loss: 0.125129, Val Acc: 0.752577\n",
      "Epoch 13322 - Train Loss: 0.104531, Train Acc: 0.832051 | Val Loss: 0.125125, Val Acc: 0.752577\n",
      "Epoch 13323 - Train Loss: 0.104526, Train Acc: 0.832051 | Val Loss: 0.125121, Val Acc: 0.752577\n",
      "Epoch 13324 - Train Loss: 0.104520, Train Acc: 0.832051 | Val Loss: 0.125117, Val Acc: 0.752577\n",
      "Epoch 13325 - Train Loss: 0.104515, Train Acc: 0.832051 | Val Loss: 0.125114, Val Acc: 0.752577\n",
      "Epoch 13326 - Train Loss: 0.104510, Train Acc: 0.832051 | Val Loss: 0.125110, Val Acc: 0.752577\n",
      "Epoch 13327 - Train Loss: 0.104505, Train Acc: 0.832051 | Val Loss: 0.125106, Val Acc: 0.752577\n",
      "Epoch 13328 - Train Loss: 0.104500, Train Acc: 0.832051 | Val Loss: 0.125102, Val Acc: 0.752577\n",
      "Epoch 13329 - Train Loss: 0.104495, Train Acc: 0.832051 | Val Loss: 0.125098, Val Acc: 0.752577\n",
      "Epoch 13330 - Train Loss: 0.104489, Train Acc: 0.832051 | Val Loss: 0.125095, Val Acc: 0.752577\n",
      "Epoch 13331 - Train Loss: 0.104484, Train Acc: 0.832051 | Val Loss: 0.125091, Val Acc: 0.752577\n",
      "Epoch 13332 - Train Loss: 0.104479, Train Acc: 0.832051 | Val Loss: 0.125087, Val Acc: 0.752577\n",
      "Epoch 13333 - Train Loss: 0.104474, Train Acc: 0.832051 | Val Loss: 0.125083, Val Acc: 0.752577\n",
      "Epoch 13334 - Train Loss: 0.104469, Train Acc: 0.832051 | Val Loss: 0.125079, Val Acc: 0.752577\n",
      "Epoch 13335 - Train Loss: 0.104464, Train Acc: 0.832051 | Val Loss: 0.125076, Val Acc: 0.752577\n",
      "Epoch 13336 - Train Loss: 0.104458, Train Acc: 0.832051 | Val Loss: 0.125072, Val Acc: 0.752577\n",
      "Epoch 13337 - Train Loss: 0.104453, Train Acc: 0.832051 | Val Loss: 0.125068, Val Acc: 0.752577\n",
      "Epoch 13338 - Train Loss: 0.104448, Train Acc: 0.832051 | Val Loss: 0.125064, Val Acc: 0.752577\n",
      "Epoch 13339 - Train Loss: 0.104443, Train Acc: 0.832051 | Val Loss: 0.125060, Val Acc: 0.752577\n",
      "Epoch 13340 - Train Loss: 0.104438, Train Acc: 0.832051 | Val Loss: 0.125057, Val Acc: 0.752577\n",
      "Epoch 13341 - Train Loss: 0.104433, Train Acc: 0.832051 | Val Loss: 0.125053, Val Acc: 0.752577\n",
      "Epoch 13342 - Train Loss: 0.104428, Train Acc: 0.832051 | Val Loss: 0.125049, Val Acc: 0.752577\n",
      "Epoch 13343 - Train Loss: 0.104422, Train Acc: 0.832051 | Val Loss: 0.125045, Val Acc: 0.752577\n",
      "Epoch 13344 - Train Loss: 0.104417, Train Acc: 0.832051 | Val Loss: 0.125042, Val Acc: 0.752577\n",
      "Epoch 13345 - Train Loss: 0.104412, Train Acc: 0.832051 | Val Loss: 0.125038, Val Acc: 0.752577\n",
      "Epoch 13346 - Train Loss: 0.104407, Train Acc: 0.832051 | Val Loss: 0.125034, Val Acc: 0.752577\n",
      "Epoch 13347 - Train Loss: 0.104402, Train Acc: 0.832051 | Val Loss: 0.125030, Val Acc: 0.752577\n",
      "Epoch 13348 - Train Loss: 0.104397, Train Acc: 0.832051 | Val Loss: 0.125026, Val Acc: 0.752577\n",
      "Epoch 13349 - Train Loss: 0.104392, Train Acc: 0.832051 | Val Loss: 0.125023, Val Acc: 0.752577\n",
      "Epoch 13350 - Train Loss: 0.104386, Train Acc: 0.832051 | Val Loss: 0.125019, Val Acc: 0.752577\n",
      "Epoch 13351 - Train Loss: 0.104381, Train Acc: 0.832051 | Val Loss: 0.125015, Val Acc: 0.752577\n",
      "Epoch 13352 - Train Loss: 0.104376, Train Acc: 0.832051 | Val Loss: 0.125011, Val Acc: 0.752577\n",
      "Epoch 13353 - Train Loss: 0.104371, Train Acc: 0.832051 | Val Loss: 0.125007, Val Acc: 0.752577\n",
      "Epoch 13354 - Train Loss: 0.104366, Train Acc: 0.832051 | Val Loss: 0.125004, Val Acc: 0.752577\n",
      "Epoch 13355 - Train Loss: 0.104361, Train Acc: 0.832051 | Val Loss: 0.125000, Val Acc: 0.752577\n",
      "Epoch 13356 - Train Loss: 0.104356, Train Acc: 0.832051 | Val Loss: 0.124996, Val Acc: 0.752577\n",
      "Epoch 13357 - Train Loss: 0.104350, Train Acc: 0.832051 | Val Loss: 0.124992, Val Acc: 0.752577\n",
      "Epoch 13358 - Train Loss: 0.104345, Train Acc: 0.832051 | Val Loss: 0.124989, Val Acc: 0.752577\n",
      "Epoch 13359 - Train Loss: 0.104340, Train Acc: 0.832051 | Val Loss: 0.124985, Val Acc: 0.752577\n",
      "Epoch 13360 - Train Loss: 0.104335, Train Acc: 0.832051 | Val Loss: 0.124981, Val Acc: 0.752577\n",
      "Epoch 13361 - Train Loss: 0.104330, Train Acc: 0.832051 | Val Loss: 0.124977, Val Acc: 0.752577\n",
      "Epoch 13362 - Train Loss: 0.104325, Train Acc: 0.832051 | Val Loss: 0.124973, Val Acc: 0.752577\n",
      "Epoch 13363 - Train Loss: 0.104320, Train Acc: 0.832051 | Val Loss: 0.124970, Val Acc: 0.752577\n",
      "Epoch 13364 - Train Loss: 0.104314, Train Acc: 0.832051 | Val Loss: 0.124966, Val Acc: 0.752577\n",
      "Epoch 13365 - Train Loss: 0.104309, Train Acc: 0.832051 | Val Loss: 0.124962, Val Acc: 0.752577\n",
      "Epoch 13366 - Train Loss: 0.104304, Train Acc: 0.832051 | Val Loss: 0.124958, Val Acc: 0.752577\n",
      "Epoch 13367 - Train Loss: 0.104299, Train Acc: 0.832051 | Val Loss: 0.124954, Val Acc: 0.752577\n",
      "Epoch 13368 - Train Loss: 0.104294, Train Acc: 0.832051 | Val Loss: 0.124951, Val Acc: 0.752577\n",
      "Epoch 13369 - Train Loss: 0.104289, Train Acc: 0.832051 | Val Loss: 0.124947, Val Acc: 0.752577\n",
      "Epoch 13370 - Train Loss: 0.104284, Train Acc: 0.832051 | Val Loss: 0.124943, Val Acc: 0.752577\n",
      "Epoch 13371 - Train Loss: 0.104279, Train Acc: 0.832051 | Val Loss: 0.124939, Val Acc: 0.752577\n",
      "Epoch 13372 - Train Loss: 0.104273, Train Acc: 0.832051 | Val Loss: 0.124936, Val Acc: 0.752577\n",
      "Epoch 13373 - Train Loss: 0.104268, Train Acc: 0.832051 | Val Loss: 0.124932, Val Acc: 0.752577\n",
      "Epoch 13374 - Train Loss: 0.104263, Train Acc: 0.832051 | Val Loss: 0.124928, Val Acc: 0.752577\n",
      "Epoch 13375 - Train Loss: 0.104258, Train Acc: 0.832051 | Val Loss: 0.124924, Val Acc: 0.752577\n",
      "Epoch 13376 - Train Loss: 0.104253, Train Acc: 0.832051 | Val Loss: 0.124920, Val Acc: 0.752577\n",
      "Epoch 13377 - Train Loss: 0.104248, Train Acc: 0.832051 | Val Loss: 0.124917, Val Acc: 0.752577\n",
      "Epoch 13378 - Train Loss: 0.104243, Train Acc: 0.832051 | Val Loss: 0.124913, Val Acc: 0.752577\n",
      "Epoch 13379 - Train Loss: 0.104238, Train Acc: 0.832051 | Val Loss: 0.124909, Val Acc: 0.752577\n",
      "Epoch 13380 - Train Loss: 0.104232, Train Acc: 0.832051 | Val Loss: 0.124905, Val Acc: 0.752577\n",
      "Epoch 13381 - Train Loss: 0.104227, Train Acc: 0.832051 | Val Loss: 0.124902, Val Acc: 0.752577\n",
      "Epoch 13382 - Train Loss: 0.104222, Train Acc: 0.832051 | Val Loss: 0.124898, Val Acc: 0.752577\n",
      "Epoch 13383 - Train Loss: 0.104217, Train Acc: 0.832051 | Val Loss: 0.124894, Val Acc: 0.752577\n",
      "Epoch 13384 - Train Loss: 0.104212, Train Acc: 0.832051 | Val Loss: 0.124890, Val Acc: 0.752577\n",
      "Epoch 13385 - Train Loss: 0.104207, Train Acc: 0.832051 | Val Loss: 0.124887, Val Acc: 0.752577\n",
      "Epoch 13386 - Train Loss: 0.104202, Train Acc: 0.832051 | Val Loss: 0.124883, Val Acc: 0.752577\n",
      "Epoch 13387 - Train Loss: 0.104197, Train Acc: 0.832051 | Val Loss: 0.124879, Val Acc: 0.752577\n",
      "Epoch 13388 - Train Loss: 0.104191, Train Acc: 0.832051 | Val Loss: 0.124875, Val Acc: 0.752577\n",
      "Epoch 13389 - Train Loss: 0.104186, Train Acc: 0.832051 | Val Loss: 0.124872, Val Acc: 0.752577\n",
      "Epoch 13390 - Train Loss: 0.104181, Train Acc: 0.832051 | Val Loss: 0.124868, Val Acc: 0.752577\n",
      "Epoch 13391 - Train Loss: 0.104176, Train Acc: 0.832051 | Val Loss: 0.124864, Val Acc: 0.752577\n",
      "Epoch 13392 - Train Loss: 0.104171, Train Acc: 0.832051 | Val Loss: 0.124860, Val Acc: 0.752577\n",
      "Epoch 13393 - Train Loss: 0.104166, Train Acc: 0.832051 | Val Loss: 0.124856, Val Acc: 0.752577\n",
      "Epoch 13394 - Train Loss: 0.104161, Train Acc: 0.832051 | Val Loss: 0.124853, Val Acc: 0.752577\n",
      "Epoch 13395 - Train Loss: 0.104156, Train Acc: 0.832051 | Val Loss: 0.124849, Val Acc: 0.752577\n",
      "Epoch 13396 - Train Loss: 0.104151, Train Acc: 0.832051 | Val Loss: 0.124845, Val Acc: 0.752577\n",
      "Epoch 13397 - Train Loss: 0.104145, Train Acc: 0.832051 | Val Loss: 0.124841, Val Acc: 0.752577\n",
      "Epoch 13398 - Train Loss: 0.104140, Train Acc: 0.832051 | Val Loss: 0.124838, Val Acc: 0.752577\n",
      "Epoch 13399 - Train Loss: 0.104135, Train Acc: 0.832051 | Val Loss: 0.124834, Val Acc: 0.752577\n",
      "Epoch 13400 - Train Loss: 0.104130, Train Acc: 0.832051 | Val Loss: 0.124830, Val Acc: 0.752577\n",
      "Epoch 13401 - Train Loss: 0.104125, Train Acc: 0.832051 | Val Loss: 0.124826, Val Acc: 0.752577\n",
      "Epoch 13402 - Train Loss: 0.104120, Train Acc: 0.832051 | Val Loss: 0.124823, Val Acc: 0.752577\n",
      "Epoch 13403 - Train Loss: 0.104115, Train Acc: 0.832051 | Val Loss: 0.124819, Val Acc: 0.752577\n",
      "Epoch 13404 - Train Loss: 0.104110, Train Acc: 0.832051 | Val Loss: 0.124815, Val Acc: 0.752577\n",
      "Epoch 13405 - Train Loss: 0.104105, Train Acc: 0.832051 | Val Loss: 0.124811, Val Acc: 0.752577\n",
      "Epoch 13406 - Train Loss: 0.104099, Train Acc: 0.832051 | Val Loss: 0.124808, Val Acc: 0.752577\n",
      "Epoch 13407 - Train Loss: 0.104094, Train Acc: 0.832051 | Val Loss: 0.124804, Val Acc: 0.752577\n",
      "Epoch 13408 - Train Loss: 0.104089, Train Acc: 0.832051 | Val Loss: 0.124800, Val Acc: 0.752577\n",
      "Epoch 13409 - Train Loss: 0.104084, Train Acc: 0.832051 | Val Loss: 0.124796, Val Acc: 0.752577\n",
      "Epoch 13410 - Train Loss: 0.104079, Train Acc: 0.832051 | Val Loss: 0.124793, Val Acc: 0.752577\n",
      "Epoch 13411 - Train Loss: 0.104074, Train Acc: 0.832051 | Val Loss: 0.124789, Val Acc: 0.752577\n",
      "Epoch 13412 - Train Loss: 0.104069, Train Acc: 0.832051 | Val Loss: 0.124785, Val Acc: 0.752577\n",
      "Epoch 13413 - Train Loss: 0.104064, Train Acc: 0.832051 | Val Loss: 0.124781, Val Acc: 0.752577\n",
      "Epoch 13414 - Train Loss: 0.104059, Train Acc: 0.832051 | Val Loss: 0.124778, Val Acc: 0.752577\n",
      "Epoch 13415 - Train Loss: 0.104054, Train Acc: 0.832051 | Val Loss: 0.124774, Val Acc: 0.752577\n",
      "Epoch 13416 - Train Loss: 0.104048, Train Acc: 0.832051 | Val Loss: 0.124770, Val Acc: 0.752577\n",
      "Epoch 13417 - Train Loss: 0.104043, Train Acc: 0.832051 | Val Loss: 0.124767, Val Acc: 0.752577\n",
      "Epoch 13418 - Train Loss: 0.104038, Train Acc: 0.832051 | Val Loss: 0.124763, Val Acc: 0.752577\n",
      "Epoch 13419 - Train Loss: 0.104033, Train Acc: 0.832051 | Val Loss: 0.124759, Val Acc: 0.752577\n",
      "Epoch 13420 - Train Loss: 0.104028, Train Acc: 0.833333 | Val Loss: 0.124755, Val Acc: 0.752577\n",
      "Epoch 13421 - Train Loss: 0.104023, Train Acc: 0.833333 | Val Loss: 0.124752, Val Acc: 0.752577\n",
      "Epoch 13422 - Train Loss: 0.104018, Train Acc: 0.833333 | Val Loss: 0.124748, Val Acc: 0.752577\n",
      "Epoch 13423 - Train Loss: 0.104013, Train Acc: 0.833333 | Val Loss: 0.124744, Val Acc: 0.752577\n",
      "Epoch 13424 - Train Loss: 0.104008, Train Acc: 0.833333 | Val Loss: 0.124740, Val Acc: 0.752577\n",
      "Epoch 13425 - Train Loss: 0.104003, Train Acc: 0.833333 | Val Loss: 0.124737, Val Acc: 0.752577\n",
      "Epoch 13426 - Train Loss: 0.103998, Train Acc: 0.834615 | Val Loss: 0.124733, Val Acc: 0.752577\n",
      "Epoch 13427 - Train Loss: 0.103992, Train Acc: 0.834615 | Val Loss: 0.124729, Val Acc: 0.752577\n",
      "Epoch 13428 - Train Loss: 0.103987, Train Acc: 0.834615 | Val Loss: 0.124725, Val Acc: 0.752577\n",
      "Epoch 13429 - Train Loss: 0.103982, Train Acc: 0.834615 | Val Loss: 0.124722, Val Acc: 0.752577\n",
      "Epoch 13430 - Train Loss: 0.103977, Train Acc: 0.834615 | Val Loss: 0.124718, Val Acc: 0.752577\n",
      "Epoch 13431 - Train Loss: 0.103972, Train Acc: 0.834615 | Val Loss: 0.124714, Val Acc: 0.752577\n",
      "Epoch 13432 - Train Loss: 0.103967, Train Acc: 0.834615 | Val Loss: 0.124711, Val Acc: 0.752577\n",
      "Epoch 13433 - Train Loss: 0.103962, Train Acc: 0.834615 | Val Loss: 0.124707, Val Acc: 0.752577\n",
      "Epoch 13434 - Train Loss: 0.103957, Train Acc: 0.834615 | Val Loss: 0.124703, Val Acc: 0.762887\n",
      "Epoch 13435 - Train Loss: 0.103952, Train Acc: 0.834615 | Val Loss: 0.124699, Val Acc: 0.762887\n",
      "Epoch 13436 - Train Loss: 0.103947, Train Acc: 0.834615 | Val Loss: 0.124696, Val Acc: 0.762887\n",
      "Epoch 13437 - Train Loss: 0.103942, Train Acc: 0.834615 | Val Loss: 0.124692, Val Acc: 0.762887\n",
      "Epoch 13438 - Train Loss: 0.103937, Train Acc: 0.834615 | Val Loss: 0.124688, Val Acc: 0.762887\n",
      "Epoch 13439 - Train Loss: 0.103931, Train Acc: 0.834615 | Val Loss: 0.124684, Val Acc: 0.762887\n",
      "Epoch 13440 - Train Loss: 0.103926, Train Acc: 0.834615 | Val Loss: 0.124681, Val Acc: 0.762887\n",
      "Epoch 13441 - Train Loss: 0.103921, Train Acc: 0.834615 | Val Loss: 0.124677, Val Acc: 0.762887\n",
      "Epoch 13442 - Train Loss: 0.103916, Train Acc: 0.834615 | Val Loss: 0.124673, Val Acc: 0.762887\n",
      "Epoch 13443 - Train Loss: 0.103911, Train Acc: 0.834615 | Val Loss: 0.124670, Val Acc: 0.762887\n",
      "Epoch 13444 - Train Loss: 0.103906, Train Acc: 0.834615 | Val Loss: 0.124666, Val Acc: 0.762887\n",
      "Epoch 13445 - Train Loss: 0.103901, Train Acc: 0.834615 | Val Loss: 0.124662, Val Acc: 0.762887\n",
      "Epoch 13446 - Train Loss: 0.103896, Train Acc: 0.834615 | Val Loss: 0.124658, Val Acc: 0.762887\n",
      "Epoch 13447 - Train Loss: 0.103891, Train Acc: 0.834615 | Val Loss: 0.124655, Val Acc: 0.762887\n",
      "Epoch 13448 - Train Loss: 0.103886, Train Acc: 0.834615 | Val Loss: 0.124651, Val Acc: 0.762887\n",
      "Epoch 13449 - Train Loss: 0.103881, Train Acc: 0.834615 | Val Loss: 0.124647, Val Acc: 0.762887\n",
      "Epoch 13450 - Train Loss: 0.103876, Train Acc: 0.834615 | Val Loss: 0.124644, Val Acc: 0.762887\n",
      "Epoch 13451 - Train Loss: 0.103871, Train Acc: 0.834615 | Val Loss: 0.124640, Val Acc: 0.762887\n",
      "Epoch 13452 - Train Loss: 0.103865, Train Acc: 0.834615 | Val Loss: 0.124636, Val Acc: 0.762887\n",
      "Epoch 13453 - Train Loss: 0.103860, Train Acc: 0.834615 | Val Loss: 0.124632, Val Acc: 0.762887\n",
      "Epoch 13454 - Train Loss: 0.103855, Train Acc: 0.834615 | Val Loss: 0.124629, Val Acc: 0.762887\n",
      "Epoch 13455 - Train Loss: 0.103850, Train Acc: 0.834615 | Val Loss: 0.124625, Val Acc: 0.762887\n",
      "Epoch 13456 - Train Loss: 0.103845, Train Acc: 0.834615 | Val Loss: 0.124621, Val Acc: 0.762887\n",
      "Epoch 13457 - Train Loss: 0.103840, Train Acc: 0.834615 | Val Loss: 0.124618, Val Acc: 0.762887\n",
      "Epoch 13458 - Train Loss: 0.103835, Train Acc: 0.834615 | Val Loss: 0.124614, Val Acc: 0.762887\n",
      "Epoch 13459 - Train Loss: 0.103830, Train Acc: 0.834615 | Val Loss: 0.124610, Val Acc: 0.762887\n",
      "Epoch 13460 - Train Loss: 0.103825, Train Acc: 0.834615 | Val Loss: 0.124606, Val Acc: 0.762887\n",
      "Epoch 13461 - Train Loss: 0.103820, Train Acc: 0.834615 | Val Loss: 0.124603, Val Acc: 0.762887\n",
      "Epoch 13462 - Train Loss: 0.103815, Train Acc: 0.834615 | Val Loss: 0.124599, Val Acc: 0.762887\n",
      "Epoch 13463 - Train Loss: 0.103810, Train Acc: 0.834615 | Val Loss: 0.124595, Val Acc: 0.762887\n",
      "Epoch 13464 - Train Loss: 0.103805, Train Acc: 0.834615 | Val Loss: 0.124592, Val Acc: 0.762887\n",
      "Epoch 13465 - Train Loss: 0.103800, Train Acc: 0.834615 | Val Loss: 0.124588, Val Acc: 0.762887\n",
      "Epoch 13466 - Train Loss: 0.103795, Train Acc: 0.834615 | Val Loss: 0.124584, Val Acc: 0.762887\n",
      "Epoch 13467 - Train Loss: 0.103789, Train Acc: 0.834615 | Val Loss: 0.124581, Val Acc: 0.762887\n",
      "Epoch 13468 - Train Loss: 0.103784, Train Acc: 0.834615 | Val Loss: 0.124577, Val Acc: 0.762887\n",
      "Epoch 13469 - Train Loss: 0.103779, Train Acc: 0.834615 | Val Loss: 0.124573, Val Acc: 0.762887\n",
      "Epoch 13470 - Train Loss: 0.103774, Train Acc: 0.834615 | Val Loss: 0.124569, Val Acc: 0.762887\n",
      "Epoch 13471 - Train Loss: 0.103769, Train Acc: 0.834615 | Val Loss: 0.124566, Val Acc: 0.762887\n",
      "Epoch 13472 - Train Loss: 0.103764, Train Acc: 0.834615 | Val Loss: 0.124562, Val Acc: 0.762887\n",
      "Epoch 13473 - Train Loss: 0.103759, Train Acc: 0.834615 | Val Loss: 0.124558, Val Acc: 0.762887\n",
      "Epoch 13474 - Train Loss: 0.103754, Train Acc: 0.834615 | Val Loss: 0.124555, Val Acc: 0.762887\n",
      "Epoch 13475 - Train Loss: 0.103749, Train Acc: 0.834615 | Val Loss: 0.124551, Val Acc: 0.762887\n",
      "Epoch 13476 - Train Loss: 0.103744, Train Acc: 0.834615 | Val Loss: 0.124547, Val Acc: 0.762887\n",
      "Epoch 13477 - Train Loss: 0.103739, Train Acc: 0.834615 | Val Loss: 0.124544, Val Acc: 0.762887\n",
      "Epoch 13478 - Train Loss: 0.103734, Train Acc: 0.834615 | Val Loss: 0.124540, Val Acc: 0.762887\n",
      "Epoch 13479 - Train Loss: 0.103729, Train Acc: 0.834615 | Val Loss: 0.124536, Val Acc: 0.762887\n",
      "Epoch 13480 - Train Loss: 0.103724, Train Acc: 0.834615 | Val Loss: 0.124533, Val Acc: 0.762887\n",
      "Epoch 13481 - Train Loss: 0.103719, Train Acc: 0.834615 | Val Loss: 0.124529, Val Acc: 0.762887\n",
      "Epoch 13482 - Train Loss: 0.103714, Train Acc: 0.834615 | Val Loss: 0.124525, Val Acc: 0.762887\n",
      "Epoch 13483 - Train Loss: 0.103709, Train Acc: 0.834615 | Val Loss: 0.124521, Val Acc: 0.762887\n",
      "Epoch 13484 - Train Loss: 0.103704, Train Acc: 0.834615 | Val Loss: 0.124518, Val Acc: 0.762887\n",
      "Epoch 13485 - Train Loss: 0.103698, Train Acc: 0.834615 | Val Loss: 0.124514, Val Acc: 0.762887\n",
      "Epoch 13486 - Train Loss: 0.103693, Train Acc: 0.834615 | Val Loss: 0.124510, Val Acc: 0.762887\n",
      "Epoch 13487 - Train Loss: 0.103688, Train Acc: 0.834615 | Val Loss: 0.124507, Val Acc: 0.762887\n",
      "Epoch 13488 - Train Loss: 0.103683, Train Acc: 0.834615 | Val Loss: 0.124503, Val Acc: 0.762887\n",
      "Epoch 13489 - Train Loss: 0.103678, Train Acc: 0.834615 | Val Loss: 0.124499, Val Acc: 0.762887\n",
      "Epoch 13490 - Train Loss: 0.103673, Train Acc: 0.834615 | Val Loss: 0.124496, Val Acc: 0.762887\n",
      "Epoch 13491 - Train Loss: 0.103668, Train Acc: 0.834615 | Val Loss: 0.124492, Val Acc: 0.762887\n",
      "Epoch 13492 - Train Loss: 0.103663, Train Acc: 0.834615 | Val Loss: 0.124488, Val Acc: 0.762887\n",
      "Epoch 13493 - Train Loss: 0.103658, Train Acc: 0.834615 | Val Loss: 0.124485, Val Acc: 0.762887\n",
      "Epoch 13494 - Train Loss: 0.103653, Train Acc: 0.834615 | Val Loss: 0.124481, Val Acc: 0.762887\n",
      "Epoch 13495 - Train Loss: 0.103648, Train Acc: 0.834615 | Val Loss: 0.124477, Val Acc: 0.762887\n",
      "Epoch 13496 - Train Loss: 0.103643, Train Acc: 0.834615 | Val Loss: 0.124474, Val Acc: 0.762887\n",
      "Epoch 13497 - Train Loss: 0.103638, Train Acc: 0.834615 | Val Loss: 0.124470, Val Acc: 0.762887\n",
      "Epoch 13498 - Train Loss: 0.103633, Train Acc: 0.834615 | Val Loss: 0.124466, Val Acc: 0.762887\n",
      "Epoch 13499 - Train Loss: 0.103628, Train Acc: 0.834615 | Val Loss: 0.124463, Val Acc: 0.762887\n",
      "Epoch 13500 - Train Loss: 0.103623, Train Acc: 0.834615 | Val Loss: 0.124459, Val Acc: 0.762887\n",
      "Epoch 13501 - Train Loss: 0.103618, Train Acc: 0.834615 | Val Loss: 0.124455, Val Acc: 0.762887\n",
      "Epoch 13502 - Train Loss: 0.103613, Train Acc: 0.834615 | Val Loss: 0.124452, Val Acc: 0.762887\n",
      "Epoch 13503 - Train Loss: 0.103608, Train Acc: 0.834615 | Val Loss: 0.124448, Val Acc: 0.762887\n",
      "Epoch 13504 - Train Loss: 0.103603, Train Acc: 0.834615 | Val Loss: 0.124444, Val Acc: 0.762887\n",
      "Epoch 13505 - Train Loss: 0.103598, Train Acc: 0.834615 | Val Loss: 0.124440, Val Acc: 0.762887\n",
      "Epoch 13506 - Train Loss: 0.103593, Train Acc: 0.834615 | Val Loss: 0.124437, Val Acc: 0.762887\n",
      "Epoch 13507 - Train Loss: 0.103588, Train Acc: 0.834615 | Val Loss: 0.124433, Val Acc: 0.762887\n",
      "Epoch 13508 - Train Loss: 0.103583, Train Acc: 0.834615 | Val Loss: 0.124429, Val Acc: 0.762887\n",
      "Epoch 13509 - Train Loss: 0.103578, Train Acc: 0.834615 | Val Loss: 0.124426, Val Acc: 0.762887\n",
      "Epoch 13510 - Train Loss: 0.103573, Train Acc: 0.834615 | Val Loss: 0.124422, Val Acc: 0.762887\n",
      "Epoch 13511 - Train Loss: 0.103567, Train Acc: 0.834615 | Val Loss: 0.124418, Val Acc: 0.762887\n",
      "Epoch 13512 - Train Loss: 0.103562, Train Acc: 0.834615 | Val Loss: 0.124415, Val Acc: 0.762887\n",
      "Epoch 13513 - Train Loss: 0.103557, Train Acc: 0.834615 | Val Loss: 0.124411, Val Acc: 0.762887\n",
      "Epoch 13514 - Train Loss: 0.103552, Train Acc: 0.834615 | Val Loss: 0.124407, Val Acc: 0.762887\n",
      "Epoch 13515 - Train Loss: 0.103547, Train Acc: 0.834615 | Val Loss: 0.124404, Val Acc: 0.762887\n",
      "Epoch 13516 - Train Loss: 0.103542, Train Acc: 0.834615 | Val Loss: 0.124400, Val Acc: 0.762887\n",
      "Epoch 13517 - Train Loss: 0.103537, Train Acc: 0.834615 | Val Loss: 0.124397, Val Acc: 0.762887\n",
      "Epoch 13518 - Train Loss: 0.103532, Train Acc: 0.834615 | Val Loss: 0.124393, Val Acc: 0.762887\n",
      "Epoch 13519 - Train Loss: 0.103527, Train Acc: 0.834615 | Val Loss: 0.124389, Val Acc: 0.762887\n",
      "Epoch 13520 - Train Loss: 0.103522, Train Acc: 0.834615 | Val Loss: 0.124386, Val Acc: 0.762887\n",
      "Epoch 13521 - Train Loss: 0.103517, Train Acc: 0.834615 | Val Loss: 0.124382, Val Acc: 0.762887\n",
      "Epoch 13522 - Train Loss: 0.103512, Train Acc: 0.834615 | Val Loss: 0.124378, Val Acc: 0.762887\n",
      "Epoch 13523 - Train Loss: 0.103507, Train Acc: 0.834615 | Val Loss: 0.124375, Val Acc: 0.762887\n",
      "Epoch 13524 - Train Loss: 0.103502, Train Acc: 0.834615 | Val Loss: 0.124371, Val Acc: 0.762887\n",
      "Epoch 13525 - Train Loss: 0.103497, Train Acc: 0.834615 | Val Loss: 0.124367, Val Acc: 0.762887\n",
      "Epoch 13526 - Train Loss: 0.103492, Train Acc: 0.834615 | Val Loss: 0.124364, Val Acc: 0.762887\n",
      "Epoch 13527 - Train Loss: 0.103487, Train Acc: 0.834615 | Val Loss: 0.124360, Val Acc: 0.762887\n",
      "Epoch 13528 - Train Loss: 0.103482, Train Acc: 0.834615 | Val Loss: 0.124356, Val Acc: 0.762887\n",
      "Epoch 13529 - Train Loss: 0.103477, Train Acc: 0.834615 | Val Loss: 0.124353, Val Acc: 0.762887\n",
      "Epoch 13530 - Train Loss: 0.103472, Train Acc: 0.834615 | Val Loss: 0.124349, Val Acc: 0.762887\n",
      "Epoch 13531 - Train Loss: 0.103467, Train Acc: 0.834615 | Val Loss: 0.124345, Val Acc: 0.762887\n",
      "Epoch 13532 - Train Loss: 0.103462, Train Acc: 0.834615 | Val Loss: 0.124342, Val Acc: 0.762887\n",
      "Epoch 13533 - Train Loss: 0.103457, Train Acc: 0.834615 | Val Loss: 0.124338, Val Acc: 0.762887\n",
      "Epoch 13534 - Train Loss: 0.103452, Train Acc: 0.834615 | Val Loss: 0.124334, Val Acc: 0.762887\n",
      "Epoch 13535 - Train Loss: 0.103447, Train Acc: 0.834615 | Val Loss: 0.124331, Val Acc: 0.762887\n",
      "Epoch 13536 - Train Loss: 0.103442, Train Acc: 0.834615 | Val Loss: 0.124327, Val Acc: 0.762887\n",
      "Epoch 13537 - Train Loss: 0.103437, Train Acc: 0.834615 | Val Loss: 0.124323, Val Acc: 0.762887\n",
      "Epoch 13538 - Train Loss: 0.103432, Train Acc: 0.834615 | Val Loss: 0.124320, Val Acc: 0.762887\n",
      "Epoch 13539 - Train Loss: 0.103427, Train Acc: 0.834615 | Val Loss: 0.124316, Val Acc: 0.762887\n",
      "Epoch 13540 - Train Loss: 0.103422, Train Acc: 0.834615 | Val Loss: 0.124312, Val Acc: 0.762887\n",
      "Epoch 13541 - Train Loss: 0.103417, Train Acc: 0.834615 | Val Loss: 0.124309, Val Acc: 0.762887\n",
      "Epoch 13542 - Train Loss: 0.103412, Train Acc: 0.834615 | Val Loss: 0.124305, Val Acc: 0.762887\n",
      "Epoch 13543 - Train Loss: 0.103407, Train Acc: 0.834615 | Val Loss: 0.124302, Val Acc: 0.762887\n",
      "Epoch 13544 - Train Loss: 0.103402, Train Acc: 0.834615 | Val Loss: 0.124298, Val Acc: 0.762887\n",
      "Epoch 13545 - Train Loss: 0.103397, Train Acc: 0.834615 | Val Loss: 0.124294, Val Acc: 0.762887\n",
      "Epoch 13546 - Train Loss: 0.103392, Train Acc: 0.834615 | Val Loss: 0.124291, Val Acc: 0.762887\n",
      "Epoch 13547 - Train Loss: 0.103387, Train Acc: 0.834615 | Val Loss: 0.124287, Val Acc: 0.762887\n",
      "Epoch 13548 - Train Loss: 0.103382, Train Acc: 0.834615 | Val Loss: 0.124283, Val Acc: 0.762887\n",
      "Epoch 13549 - Train Loss: 0.103377, Train Acc: 0.834615 | Val Loss: 0.124280, Val Acc: 0.762887\n",
      "Epoch 13550 - Train Loss: 0.103372, Train Acc: 0.834615 | Val Loss: 0.124276, Val Acc: 0.762887\n",
      "Epoch 13551 - Train Loss: 0.103367, Train Acc: 0.834615 | Val Loss: 0.124272, Val Acc: 0.762887\n",
      "Epoch 13552 - Train Loss: 0.103362, Train Acc: 0.835897 | Val Loss: 0.124269, Val Acc: 0.762887\n",
      "Epoch 13553 - Train Loss: 0.103357, Train Acc: 0.837179 | Val Loss: 0.124265, Val Acc: 0.762887\n",
      "Epoch 13554 - Train Loss: 0.103352, Train Acc: 0.837179 | Val Loss: 0.124262, Val Acc: 0.762887\n",
      "Epoch 13555 - Train Loss: 0.103347, Train Acc: 0.837179 | Val Loss: 0.124258, Val Acc: 0.762887\n",
      "Epoch 13556 - Train Loss: 0.103342, Train Acc: 0.837179 | Val Loss: 0.124254, Val Acc: 0.762887\n",
      "Epoch 13557 - Train Loss: 0.103337, Train Acc: 0.837179 | Val Loss: 0.124251, Val Acc: 0.762887\n",
      "Epoch 13558 - Train Loss: 0.103332, Train Acc: 0.837179 | Val Loss: 0.124247, Val Acc: 0.762887\n",
      "Epoch 13559 - Train Loss: 0.103327, Train Acc: 0.837179 | Val Loss: 0.124243, Val Acc: 0.762887\n",
      "Epoch 13560 - Train Loss: 0.103322, Train Acc: 0.837179 | Val Loss: 0.124240, Val Acc: 0.762887\n",
      "Epoch 13561 - Train Loss: 0.103317, Train Acc: 0.837179 | Val Loss: 0.124236, Val Acc: 0.762887\n",
      "Epoch 13562 - Train Loss: 0.103312, Train Acc: 0.837179 | Val Loss: 0.124232, Val Acc: 0.762887\n",
      "Epoch 13563 - Train Loss: 0.103307, Train Acc: 0.837179 | Val Loss: 0.124229, Val Acc: 0.762887\n",
      "Epoch 13564 - Train Loss: 0.103302, Train Acc: 0.837179 | Val Loss: 0.124225, Val Acc: 0.762887\n",
      "Epoch 13565 - Train Loss: 0.103297, Train Acc: 0.837179 | Val Loss: 0.124222, Val Acc: 0.762887\n",
      "Epoch 13566 - Train Loss: 0.103292, Train Acc: 0.837179 | Val Loss: 0.124218, Val Acc: 0.762887\n",
      "Epoch 13567 - Train Loss: 0.103287, Train Acc: 0.837179 | Val Loss: 0.124214, Val Acc: 0.762887\n",
      "Epoch 13568 - Train Loss: 0.103282, Train Acc: 0.837179 | Val Loss: 0.124211, Val Acc: 0.762887\n",
      "Epoch 13569 - Train Loss: 0.103277, Train Acc: 0.837179 | Val Loss: 0.124207, Val Acc: 0.762887\n",
      "Epoch 13570 - Train Loss: 0.103272, Train Acc: 0.837179 | Val Loss: 0.124203, Val Acc: 0.762887\n",
      "Epoch 13571 - Train Loss: 0.103267, Train Acc: 0.837179 | Val Loss: 0.124200, Val Acc: 0.762887\n",
      "Epoch 13572 - Train Loss: 0.103262, Train Acc: 0.837179 | Val Loss: 0.124196, Val Acc: 0.762887\n",
      "Epoch 13573 - Train Loss: 0.103257, Train Acc: 0.837179 | Val Loss: 0.124193, Val Acc: 0.762887\n",
      "Epoch 13574 - Train Loss: 0.103252, Train Acc: 0.837179 | Val Loss: 0.124189, Val Acc: 0.762887\n",
      "Epoch 13575 - Train Loss: 0.103247, Train Acc: 0.837179 | Val Loss: 0.124185, Val Acc: 0.762887\n",
      "Epoch 13576 - Train Loss: 0.103242, Train Acc: 0.837179 | Val Loss: 0.124182, Val Acc: 0.762887\n",
      "Epoch 13577 - Train Loss: 0.103237, Train Acc: 0.837179 | Val Loss: 0.124178, Val Acc: 0.762887\n",
      "Epoch 13578 - Train Loss: 0.103232, Train Acc: 0.837179 | Val Loss: 0.124175, Val Acc: 0.762887\n",
      "Epoch 13579 - Train Loss: 0.103227, Train Acc: 0.837179 | Val Loss: 0.124171, Val Acc: 0.762887\n",
      "Epoch 13580 - Train Loss: 0.103222, Train Acc: 0.837179 | Val Loss: 0.124167, Val Acc: 0.762887\n",
      "Epoch 13581 - Train Loss: 0.103217, Train Acc: 0.837179 | Val Loss: 0.124164, Val Acc: 0.762887\n",
      "Epoch 13582 - Train Loss: 0.103212, Train Acc: 0.837179 | Val Loss: 0.124160, Val Acc: 0.762887\n",
      "Epoch 13583 - Train Loss: 0.103207, Train Acc: 0.837179 | Val Loss: 0.124156, Val Acc: 0.762887\n",
      "Epoch 13584 - Train Loss: 0.103202, Train Acc: 0.837179 | Val Loss: 0.124153, Val Acc: 0.762887\n",
      "Epoch 13585 - Train Loss: 0.103197, Train Acc: 0.837179 | Val Loss: 0.124149, Val Acc: 0.762887\n",
      "Epoch 13586 - Train Loss: 0.103192, Train Acc: 0.837179 | Val Loss: 0.124146, Val Acc: 0.762887\n",
      "Epoch 13587 - Train Loss: 0.103187, Train Acc: 0.837179 | Val Loss: 0.124142, Val Acc: 0.762887\n",
      "Epoch 13588 - Train Loss: 0.103182, Train Acc: 0.837179 | Val Loss: 0.124138, Val Acc: 0.762887\n",
      "Epoch 13589 - Train Loss: 0.103177, Train Acc: 0.837179 | Val Loss: 0.124135, Val Acc: 0.762887\n",
      "Epoch 13590 - Train Loss: 0.103172, Train Acc: 0.837179 | Val Loss: 0.124131, Val Acc: 0.762887\n",
      "Epoch 13591 - Train Loss: 0.103167, Train Acc: 0.837179 | Val Loss: 0.124128, Val Acc: 0.762887\n",
      "Epoch 13592 - Train Loss: 0.103162, Train Acc: 0.837179 | Val Loss: 0.124124, Val Acc: 0.762887\n",
      "Epoch 13593 - Train Loss: 0.103157, Train Acc: 0.837179 | Val Loss: 0.124120, Val Acc: 0.762887\n",
      "Epoch 13594 - Train Loss: 0.103152, Train Acc: 0.837179 | Val Loss: 0.124117, Val Acc: 0.762887\n",
      "Epoch 13595 - Train Loss: 0.103147, Train Acc: 0.837179 | Val Loss: 0.124113, Val Acc: 0.762887\n",
      "Epoch 13596 - Train Loss: 0.103142, Train Acc: 0.837179 | Val Loss: 0.124110, Val Acc: 0.762887\n",
      "Epoch 13597 - Train Loss: 0.103137, Train Acc: 0.837179 | Val Loss: 0.124106, Val Acc: 0.762887\n",
      "Epoch 13598 - Train Loss: 0.103133, Train Acc: 0.837179 | Val Loss: 0.124102, Val Acc: 0.762887\n",
      "Epoch 13599 - Train Loss: 0.103128, Train Acc: 0.837179 | Val Loss: 0.124099, Val Acc: 0.762887\n",
      "Epoch 13600 - Train Loss: 0.103123, Train Acc: 0.837179 | Val Loss: 0.124095, Val Acc: 0.762887\n",
      "Epoch 13601 - Train Loss: 0.103118, Train Acc: 0.837179 | Val Loss: 0.124092, Val Acc: 0.762887\n",
      "Epoch 13602 - Train Loss: 0.103113, Train Acc: 0.837179 | Val Loss: 0.124088, Val Acc: 0.762887\n",
      "Epoch 13603 - Train Loss: 0.103108, Train Acc: 0.837179 | Val Loss: 0.124084, Val Acc: 0.762887\n",
      "Epoch 13604 - Train Loss: 0.103103, Train Acc: 0.837179 | Val Loss: 0.124081, Val Acc: 0.762887\n",
      "Epoch 13605 - Train Loss: 0.103098, Train Acc: 0.837179 | Val Loss: 0.124077, Val Acc: 0.762887\n",
      "Epoch 13606 - Train Loss: 0.103093, Train Acc: 0.837179 | Val Loss: 0.124074, Val Acc: 0.762887\n",
      "Epoch 13607 - Train Loss: 0.103088, Train Acc: 0.837179 | Val Loss: 0.124070, Val Acc: 0.762887\n",
      "Epoch 13608 - Train Loss: 0.103083, Train Acc: 0.837179 | Val Loss: 0.124066, Val Acc: 0.762887\n",
      "Epoch 13609 - Train Loss: 0.103078, Train Acc: 0.837179 | Val Loss: 0.124063, Val Acc: 0.762887\n",
      "Epoch 13610 - Train Loss: 0.103073, Train Acc: 0.837179 | Val Loss: 0.124059, Val Acc: 0.762887\n",
      "Epoch 13611 - Train Loss: 0.103068, Train Acc: 0.837179 | Val Loss: 0.124056, Val Acc: 0.762887\n",
      "Epoch 13612 - Train Loss: 0.103063, Train Acc: 0.837179 | Val Loss: 0.124052, Val Acc: 0.762887\n",
      "Epoch 13613 - Train Loss: 0.103058, Train Acc: 0.837179 | Val Loss: 0.124048, Val Acc: 0.762887\n",
      "Epoch 13614 - Train Loss: 0.103053, Train Acc: 0.837179 | Val Loss: 0.124045, Val Acc: 0.762887\n",
      "Epoch 13615 - Train Loss: 0.103048, Train Acc: 0.837179 | Val Loss: 0.124041, Val Acc: 0.762887\n",
      "Epoch 13616 - Train Loss: 0.103043, Train Acc: 0.837179 | Val Loss: 0.124038, Val Acc: 0.762887\n",
      "Epoch 13617 - Train Loss: 0.103038, Train Acc: 0.837179 | Val Loss: 0.124034, Val Acc: 0.762887\n",
      "Epoch 13618 - Train Loss: 0.103033, Train Acc: 0.837179 | Val Loss: 0.124030, Val Acc: 0.762887\n",
      "Epoch 13619 - Train Loss: 0.103028, Train Acc: 0.837179 | Val Loss: 0.124027, Val Acc: 0.762887\n",
      "Epoch 13620 - Train Loss: 0.103023, Train Acc: 0.837179 | Val Loss: 0.124023, Val Acc: 0.762887\n",
      "Epoch 13621 - Train Loss: 0.103018, Train Acc: 0.837179 | Val Loss: 0.124020, Val Acc: 0.762887\n",
      "Epoch 13622 - Train Loss: 0.103013, Train Acc: 0.837179 | Val Loss: 0.124016, Val Acc: 0.762887\n",
      "Epoch 13623 - Train Loss: 0.103008, Train Acc: 0.837179 | Val Loss: 0.124013, Val Acc: 0.762887\n",
      "Epoch 13624 - Train Loss: 0.103004, Train Acc: 0.837179 | Val Loss: 0.124009, Val Acc: 0.762887\n",
      "Epoch 13625 - Train Loss: 0.102999, Train Acc: 0.837179 | Val Loss: 0.124005, Val Acc: 0.762887\n",
      "Epoch 13626 - Train Loss: 0.102994, Train Acc: 0.837179 | Val Loss: 0.124002, Val Acc: 0.762887\n",
      "Epoch 13627 - Train Loss: 0.102989, Train Acc: 0.837179 | Val Loss: 0.123998, Val Acc: 0.762887\n",
      "Epoch 13628 - Train Loss: 0.102984, Train Acc: 0.837179 | Val Loss: 0.123995, Val Acc: 0.762887\n",
      "Epoch 13629 - Train Loss: 0.102979, Train Acc: 0.837179 | Val Loss: 0.123991, Val Acc: 0.762887\n",
      "Epoch 13630 - Train Loss: 0.102974, Train Acc: 0.835897 | Val Loss: 0.123987, Val Acc: 0.762887\n",
      "Epoch 13631 - Train Loss: 0.102969, Train Acc: 0.835897 | Val Loss: 0.123984, Val Acc: 0.762887\n",
      "Epoch 13632 - Train Loss: 0.102964, Train Acc: 0.835897 | Val Loss: 0.123980, Val Acc: 0.762887\n",
      "Epoch 13633 - Train Loss: 0.102959, Train Acc: 0.835897 | Val Loss: 0.123977, Val Acc: 0.762887\n",
      "Epoch 13634 - Train Loss: 0.102954, Train Acc: 0.835897 | Val Loss: 0.123973, Val Acc: 0.762887\n",
      "Epoch 13635 - Train Loss: 0.102949, Train Acc: 0.835897 | Val Loss: 0.123970, Val Acc: 0.762887\n",
      "Epoch 13636 - Train Loss: 0.102944, Train Acc: 0.835897 | Val Loss: 0.123966, Val Acc: 0.762887\n",
      "Epoch 13637 - Train Loss: 0.102939, Train Acc: 0.835897 | Val Loss: 0.123962, Val Acc: 0.762887\n",
      "Epoch 13638 - Train Loss: 0.102934, Train Acc: 0.835897 | Val Loss: 0.123959, Val Acc: 0.762887\n",
      "Epoch 13639 - Train Loss: 0.102929, Train Acc: 0.835897 | Val Loss: 0.123955, Val Acc: 0.762887\n",
      "Epoch 13640 - Train Loss: 0.102924, Train Acc: 0.835897 | Val Loss: 0.123952, Val Acc: 0.762887\n",
      "Epoch 13641 - Train Loss: 0.102919, Train Acc: 0.835897 | Val Loss: 0.123948, Val Acc: 0.762887\n",
      "Epoch 13642 - Train Loss: 0.102915, Train Acc: 0.835897 | Val Loss: 0.123945, Val Acc: 0.762887\n",
      "Epoch 13643 - Train Loss: 0.102910, Train Acc: 0.835897 | Val Loss: 0.123941, Val Acc: 0.762887\n",
      "Epoch 13644 - Train Loss: 0.102905, Train Acc: 0.835897 | Val Loss: 0.123938, Val Acc: 0.762887\n",
      "Epoch 13645 - Train Loss: 0.102900, Train Acc: 0.837179 | Val Loss: 0.123934, Val Acc: 0.762887\n",
      "Epoch 13646 - Train Loss: 0.102895, Train Acc: 0.837179 | Val Loss: 0.123930, Val Acc: 0.762887\n",
      "Epoch 13647 - Train Loss: 0.102890, Train Acc: 0.837179 | Val Loss: 0.123927, Val Acc: 0.762887\n",
      "Epoch 13648 - Train Loss: 0.102885, Train Acc: 0.837179 | Val Loss: 0.123923, Val Acc: 0.762887\n",
      "Epoch 13649 - Train Loss: 0.102880, Train Acc: 0.837179 | Val Loss: 0.123920, Val Acc: 0.762887\n",
      "Epoch 13650 - Train Loss: 0.102875, Train Acc: 0.837179 | Val Loss: 0.123916, Val Acc: 0.762887\n",
      "Epoch 13651 - Train Loss: 0.102870, Train Acc: 0.837179 | Val Loss: 0.123913, Val Acc: 0.762887\n",
      "Epoch 13652 - Train Loss: 0.102865, Train Acc: 0.837179 | Val Loss: 0.123909, Val Acc: 0.762887\n",
      "Epoch 13653 - Train Loss: 0.102860, Train Acc: 0.837179 | Val Loss: 0.123906, Val Acc: 0.762887\n",
      "Epoch 13654 - Train Loss: 0.102855, Train Acc: 0.837179 | Val Loss: 0.123902, Val Acc: 0.762887\n",
      "Epoch 13655 - Train Loss: 0.102850, Train Acc: 0.837179 | Val Loss: 0.123898, Val Acc: 0.762887\n",
      "Epoch 13656 - Train Loss: 0.102845, Train Acc: 0.837179 | Val Loss: 0.123895, Val Acc: 0.762887\n",
      "Epoch 13657 - Train Loss: 0.102841, Train Acc: 0.837179 | Val Loss: 0.123891, Val Acc: 0.762887\n",
      "Epoch 13658 - Train Loss: 0.102836, Train Acc: 0.837179 | Val Loss: 0.123888, Val Acc: 0.762887\n",
      "Epoch 13659 - Train Loss: 0.102831, Train Acc: 0.837179 | Val Loss: 0.123884, Val Acc: 0.762887\n",
      "Epoch 13660 - Train Loss: 0.102826, Train Acc: 0.837179 | Val Loss: 0.123881, Val Acc: 0.762887\n",
      "Epoch 13661 - Train Loss: 0.102821, Train Acc: 0.837179 | Val Loss: 0.123877, Val Acc: 0.762887\n",
      "Epoch 13662 - Train Loss: 0.102816, Train Acc: 0.837179 | Val Loss: 0.123874, Val Acc: 0.762887\n",
      "Epoch 13663 - Train Loss: 0.102811, Train Acc: 0.837179 | Val Loss: 0.123870, Val Acc: 0.762887\n",
      "Epoch 13664 - Train Loss: 0.102806, Train Acc: 0.837179 | Val Loss: 0.123867, Val Acc: 0.762887\n",
      "Epoch 13665 - Train Loss: 0.102801, Train Acc: 0.837179 | Val Loss: 0.123863, Val Acc: 0.762887\n",
      "Epoch 13666 - Train Loss: 0.102796, Train Acc: 0.837179 | Val Loss: 0.123859, Val Acc: 0.762887\n",
      "Epoch 13667 - Train Loss: 0.102791, Train Acc: 0.837179 | Val Loss: 0.123856, Val Acc: 0.762887\n",
      "Epoch 13668 - Train Loss: 0.102786, Train Acc: 0.837179 | Val Loss: 0.123852, Val Acc: 0.762887\n",
      "Epoch 13669 - Train Loss: 0.102781, Train Acc: 0.837179 | Val Loss: 0.123849, Val Acc: 0.762887\n",
      "Epoch 13670 - Train Loss: 0.102777, Train Acc: 0.837179 | Val Loss: 0.123845, Val Acc: 0.762887\n",
      "Epoch 13671 - Train Loss: 0.102772, Train Acc: 0.837179 | Val Loss: 0.123842, Val Acc: 0.762887\n",
      "Epoch 13672 - Train Loss: 0.102767, Train Acc: 0.837179 | Val Loss: 0.123838, Val Acc: 0.762887\n",
      "Epoch 13673 - Train Loss: 0.102762, Train Acc: 0.837179 | Val Loss: 0.123835, Val Acc: 0.762887\n",
      "Epoch 13674 - Train Loss: 0.102757, Train Acc: 0.837179 | Val Loss: 0.123831, Val Acc: 0.762887\n",
      "Epoch 13675 - Train Loss: 0.102752, Train Acc: 0.837179 | Val Loss: 0.123828, Val Acc: 0.762887\n",
      "Epoch 13676 - Train Loss: 0.102747, Train Acc: 0.837179 | Val Loss: 0.123824, Val Acc: 0.762887\n",
      "Epoch 13677 - Train Loss: 0.102742, Train Acc: 0.837179 | Val Loss: 0.123820, Val Acc: 0.762887\n",
      "Epoch 13678 - Train Loss: 0.102737, Train Acc: 0.837179 | Val Loss: 0.123817, Val Acc: 0.762887\n",
      "Epoch 13679 - Train Loss: 0.102732, Train Acc: 0.837179 | Val Loss: 0.123813, Val Acc: 0.762887\n",
      "Epoch 13680 - Train Loss: 0.102727, Train Acc: 0.837179 | Val Loss: 0.123810, Val Acc: 0.762887\n",
      "Epoch 13681 - Train Loss: 0.102722, Train Acc: 0.837179 | Val Loss: 0.123806, Val Acc: 0.762887\n",
      "Epoch 13682 - Train Loss: 0.102718, Train Acc: 0.837179 | Val Loss: 0.123803, Val Acc: 0.762887\n",
      "Epoch 13683 - Train Loss: 0.102713, Train Acc: 0.837179 | Val Loss: 0.123799, Val Acc: 0.762887\n",
      "Epoch 13684 - Train Loss: 0.102708, Train Acc: 0.837179 | Val Loss: 0.123796, Val Acc: 0.762887\n",
      "Epoch 13685 - Train Loss: 0.102703, Train Acc: 0.837179 | Val Loss: 0.123792, Val Acc: 0.762887\n",
      "Epoch 13686 - Train Loss: 0.102698, Train Acc: 0.837179 | Val Loss: 0.123789, Val Acc: 0.762887\n",
      "Epoch 13687 - Train Loss: 0.102693, Train Acc: 0.837179 | Val Loss: 0.123785, Val Acc: 0.762887\n",
      "Epoch 13688 - Train Loss: 0.102688, Train Acc: 0.837179 | Val Loss: 0.123782, Val Acc: 0.762887\n",
      "Epoch 13689 - Train Loss: 0.102683, Train Acc: 0.837179 | Val Loss: 0.123778, Val Acc: 0.762887\n",
      "Epoch 13690 - Train Loss: 0.102678, Train Acc: 0.837179 | Val Loss: 0.123775, Val Acc: 0.762887\n",
      "Epoch 13691 - Train Loss: 0.102673, Train Acc: 0.837179 | Val Loss: 0.123771, Val Acc: 0.762887\n",
      "Epoch 13692 - Train Loss: 0.102669, Train Acc: 0.837179 | Val Loss: 0.123767, Val Acc: 0.762887\n",
      "Epoch 13693 - Train Loss: 0.102664, Train Acc: 0.837179 | Val Loss: 0.123764, Val Acc: 0.762887\n",
      "Epoch 13694 - Train Loss: 0.102659, Train Acc: 0.837179 | Val Loss: 0.123760, Val Acc: 0.762887\n",
      "Epoch 13695 - Train Loss: 0.102654, Train Acc: 0.837179 | Val Loss: 0.123757, Val Acc: 0.762887\n",
      "Epoch 13696 - Train Loss: 0.102649, Train Acc: 0.837179 | Val Loss: 0.123753, Val Acc: 0.762887\n",
      "Epoch 13697 - Train Loss: 0.102644, Train Acc: 0.837179 | Val Loss: 0.123750, Val Acc: 0.762887\n",
      "Epoch 13698 - Train Loss: 0.102639, Train Acc: 0.837179 | Val Loss: 0.123746, Val Acc: 0.762887\n",
      "Epoch 13699 - Train Loss: 0.102634, Train Acc: 0.837179 | Val Loss: 0.123743, Val Acc: 0.762887\n",
      "Epoch 13700 - Train Loss: 0.102629, Train Acc: 0.837179 | Val Loss: 0.123739, Val Acc: 0.762887\n",
      "Epoch 13701 - Train Loss: 0.102624, Train Acc: 0.837179 | Val Loss: 0.123736, Val Acc: 0.762887\n",
      "Epoch 13702 - Train Loss: 0.102620, Train Acc: 0.837179 | Val Loss: 0.123732, Val Acc: 0.762887\n",
      "Epoch 13703 - Train Loss: 0.102615, Train Acc: 0.837179 | Val Loss: 0.123729, Val Acc: 0.762887\n",
      "Epoch 13704 - Train Loss: 0.102610, Train Acc: 0.837179 | Val Loss: 0.123725, Val Acc: 0.762887\n",
      "Epoch 13705 - Train Loss: 0.102605, Train Acc: 0.837179 | Val Loss: 0.123722, Val Acc: 0.762887\n",
      "Epoch 13706 - Train Loss: 0.102600, Train Acc: 0.837179 | Val Loss: 0.123718, Val Acc: 0.762887\n",
      "Epoch 13707 - Train Loss: 0.102595, Train Acc: 0.837179 | Val Loss: 0.123715, Val Acc: 0.762887\n",
      "Epoch 13708 - Train Loss: 0.102590, Train Acc: 0.837179 | Val Loss: 0.123711, Val Acc: 0.762887\n",
      "Epoch 13709 - Train Loss: 0.102585, Train Acc: 0.837179 | Val Loss: 0.123708, Val Acc: 0.762887\n",
      "Epoch 13710 - Train Loss: 0.102580, Train Acc: 0.837179 | Val Loss: 0.123704, Val Acc: 0.762887\n",
      "Epoch 13711 - Train Loss: 0.102575, Train Acc: 0.837179 | Val Loss: 0.123700, Val Acc: 0.762887\n",
      "Epoch 13712 - Train Loss: 0.102571, Train Acc: 0.837179 | Val Loss: 0.123697, Val Acc: 0.762887\n",
      "Epoch 13713 - Train Loss: 0.102566, Train Acc: 0.837179 | Val Loss: 0.123693, Val Acc: 0.762887\n",
      "Epoch 13714 - Train Loss: 0.102561, Train Acc: 0.837179 | Val Loss: 0.123690, Val Acc: 0.762887\n",
      "Epoch 13715 - Train Loss: 0.102556, Train Acc: 0.837179 | Val Loss: 0.123686, Val Acc: 0.762887\n",
      "Epoch 13716 - Train Loss: 0.102551, Train Acc: 0.837179 | Val Loss: 0.123683, Val Acc: 0.762887\n",
      "Epoch 13717 - Train Loss: 0.102546, Train Acc: 0.837179 | Val Loss: 0.123679, Val Acc: 0.762887\n",
      "Epoch 13718 - Train Loss: 0.102541, Train Acc: 0.837179 | Val Loss: 0.123676, Val Acc: 0.762887\n",
      "Epoch 13719 - Train Loss: 0.102536, Train Acc: 0.837179 | Val Loss: 0.123672, Val Acc: 0.762887\n",
      "Epoch 13720 - Train Loss: 0.102531, Train Acc: 0.837179 | Val Loss: 0.123669, Val Acc: 0.762887\n",
      "Epoch 13721 - Train Loss: 0.102527, Train Acc: 0.837179 | Val Loss: 0.123665, Val Acc: 0.762887\n",
      "Epoch 13722 - Train Loss: 0.102522, Train Acc: 0.837179 | Val Loss: 0.123662, Val Acc: 0.762887\n",
      "Epoch 13723 - Train Loss: 0.102517, Train Acc: 0.837179 | Val Loss: 0.123658, Val Acc: 0.762887\n",
      "Epoch 13724 - Train Loss: 0.102512, Train Acc: 0.837179 | Val Loss: 0.123655, Val Acc: 0.762887\n",
      "Epoch 13725 - Train Loss: 0.102507, Train Acc: 0.837179 | Val Loss: 0.123651, Val Acc: 0.762887\n",
      "Epoch 13726 - Train Loss: 0.102502, Train Acc: 0.837179 | Val Loss: 0.123648, Val Acc: 0.762887\n",
      "Epoch 13727 - Train Loss: 0.102497, Train Acc: 0.837179 | Val Loss: 0.123644, Val Acc: 0.762887\n",
      "Epoch 13728 - Train Loss: 0.102492, Train Acc: 0.837179 | Val Loss: 0.123641, Val Acc: 0.762887\n",
      "Epoch 13729 - Train Loss: 0.102488, Train Acc: 0.837179 | Val Loss: 0.123637, Val Acc: 0.762887\n",
      "Epoch 13730 - Train Loss: 0.102483, Train Acc: 0.837179 | Val Loss: 0.123634, Val Acc: 0.762887\n",
      "Epoch 13731 - Train Loss: 0.102478, Train Acc: 0.837179 | Val Loss: 0.123630, Val Acc: 0.762887\n",
      "Epoch 13732 - Train Loss: 0.102473, Train Acc: 0.837179 | Val Loss: 0.123627, Val Acc: 0.762887\n",
      "Epoch 13733 - Train Loss: 0.102468, Train Acc: 0.837179 | Val Loss: 0.123623, Val Acc: 0.762887\n",
      "Epoch 13734 - Train Loss: 0.102463, Train Acc: 0.837179 | Val Loss: 0.123620, Val Acc: 0.762887\n",
      "Epoch 13735 - Train Loss: 0.102458, Train Acc: 0.837179 | Val Loss: 0.123616, Val Acc: 0.762887\n",
      "Epoch 13736 - Train Loss: 0.102453, Train Acc: 0.837179 | Val Loss: 0.123613, Val Acc: 0.762887\n",
      "Epoch 13737 - Train Loss: 0.102449, Train Acc: 0.837179 | Val Loss: 0.123609, Val Acc: 0.762887\n",
      "Epoch 13738 - Train Loss: 0.102444, Train Acc: 0.837179 | Val Loss: 0.123606, Val Acc: 0.762887\n",
      "Epoch 13739 - Train Loss: 0.102439, Train Acc: 0.837179 | Val Loss: 0.123602, Val Acc: 0.762887\n",
      "Epoch 13740 - Train Loss: 0.102434, Train Acc: 0.837179 | Val Loss: 0.123599, Val Acc: 0.762887\n",
      "Epoch 13741 - Train Loss: 0.102429, Train Acc: 0.837179 | Val Loss: 0.123595, Val Acc: 0.762887\n",
      "Epoch 13742 - Train Loss: 0.102424, Train Acc: 0.837179 | Val Loss: 0.123592, Val Acc: 0.762887\n",
      "Epoch 13743 - Train Loss: 0.102419, Train Acc: 0.837179 | Val Loss: 0.123588, Val Acc: 0.762887\n",
      "Epoch 13744 - Train Loss: 0.102414, Train Acc: 0.837179 | Val Loss: 0.123585, Val Acc: 0.762887\n",
      "Epoch 13745 - Train Loss: 0.102410, Train Acc: 0.837179 | Val Loss: 0.123581, Val Acc: 0.762887\n",
      "Epoch 13746 - Train Loss: 0.102405, Train Acc: 0.837179 | Val Loss: 0.123578, Val Acc: 0.762887\n",
      "Epoch 13747 - Train Loss: 0.102400, Train Acc: 0.837179 | Val Loss: 0.123574, Val Acc: 0.762887\n",
      "Epoch 13748 - Train Loss: 0.102395, Train Acc: 0.837179 | Val Loss: 0.123571, Val Acc: 0.762887\n",
      "Epoch 13749 - Train Loss: 0.102390, Train Acc: 0.837179 | Val Loss: 0.123567, Val Acc: 0.762887\n",
      "Epoch 13750 - Train Loss: 0.102385, Train Acc: 0.837179 | Val Loss: 0.123564, Val Acc: 0.762887\n",
      "Epoch 13751 - Train Loss: 0.102380, Train Acc: 0.837179 | Val Loss: 0.123560, Val Acc: 0.762887\n",
      "Epoch 13752 - Train Loss: 0.102375, Train Acc: 0.837179 | Val Loss: 0.123557, Val Acc: 0.762887\n",
      "Epoch 13753 - Train Loss: 0.102371, Train Acc: 0.837179 | Val Loss: 0.123553, Val Acc: 0.762887\n",
      "Epoch 13754 - Train Loss: 0.102366, Train Acc: 0.837179 | Val Loss: 0.123550, Val Acc: 0.762887\n",
      "Epoch 13755 - Train Loss: 0.102361, Train Acc: 0.837179 | Val Loss: 0.123546, Val Acc: 0.762887\n",
      "Epoch 13756 - Train Loss: 0.102356, Train Acc: 0.837179 | Val Loss: 0.123543, Val Acc: 0.762887\n",
      "Epoch 13757 - Train Loss: 0.102351, Train Acc: 0.837179 | Val Loss: 0.123539, Val Acc: 0.762887\n",
      "Epoch 13758 - Train Loss: 0.102346, Train Acc: 0.837179 | Val Loss: 0.123536, Val Acc: 0.762887\n",
      "Epoch 13759 - Train Loss: 0.102341, Train Acc: 0.837179 | Val Loss: 0.123532, Val Acc: 0.762887\n",
      "Epoch 13760 - Train Loss: 0.102337, Train Acc: 0.837179 | Val Loss: 0.123529, Val Acc: 0.762887\n",
      "Epoch 13761 - Train Loss: 0.102332, Train Acc: 0.837179 | Val Loss: 0.123525, Val Acc: 0.762887\n",
      "Epoch 13762 - Train Loss: 0.102327, Train Acc: 0.837179 | Val Loss: 0.123522, Val Acc: 0.762887\n",
      "Epoch 13763 - Train Loss: 0.102322, Train Acc: 0.837179 | Val Loss: 0.123518, Val Acc: 0.762887\n",
      "Epoch 13764 - Train Loss: 0.102317, Train Acc: 0.837179 | Val Loss: 0.123515, Val Acc: 0.762887\n",
      "Epoch 13765 - Train Loss: 0.102312, Train Acc: 0.838462 | Val Loss: 0.123511, Val Acc: 0.762887\n",
      "Epoch 13766 - Train Loss: 0.102307, Train Acc: 0.838462 | Val Loss: 0.123508, Val Acc: 0.762887\n",
      "Epoch 13767 - Train Loss: 0.102303, Train Acc: 0.838462 | Val Loss: 0.123504, Val Acc: 0.762887\n",
      "Epoch 13768 - Train Loss: 0.102298, Train Acc: 0.838462 | Val Loss: 0.123501, Val Acc: 0.762887\n",
      "Epoch 13769 - Train Loss: 0.102293, Train Acc: 0.838462 | Val Loss: 0.123497, Val Acc: 0.762887\n",
      "Epoch 13770 - Train Loss: 0.102288, Train Acc: 0.838462 | Val Loss: 0.123494, Val Acc: 0.762887\n",
      "Epoch 13771 - Train Loss: 0.102283, Train Acc: 0.838462 | Val Loss: 0.123490, Val Acc: 0.762887\n",
      "Epoch 13772 - Train Loss: 0.102278, Train Acc: 0.838462 | Val Loss: 0.123487, Val Acc: 0.762887\n",
      "Epoch 13773 - Train Loss: 0.102274, Train Acc: 0.838462 | Val Loss: 0.123484, Val Acc: 0.762887\n",
      "Epoch 13774 - Train Loss: 0.102269, Train Acc: 0.838462 | Val Loss: 0.123480, Val Acc: 0.762887\n",
      "Epoch 13775 - Train Loss: 0.102264, Train Acc: 0.838462 | Val Loss: 0.123477, Val Acc: 0.762887\n",
      "Epoch 13776 - Train Loss: 0.102259, Train Acc: 0.838462 | Val Loss: 0.123473, Val Acc: 0.762887\n",
      "Epoch 13777 - Train Loss: 0.102254, Train Acc: 0.838462 | Val Loss: 0.123470, Val Acc: 0.762887\n",
      "Epoch 13778 - Train Loss: 0.102249, Train Acc: 0.838462 | Val Loss: 0.123466, Val Acc: 0.762887\n",
      "Epoch 13779 - Train Loss: 0.102244, Train Acc: 0.838462 | Val Loss: 0.123463, Val Acc: 0.762887\n",
      "Epoch 13780 - Train Loss: 0.102240, Train Acc: 0.838462 | Val Loss: 0.123459, Val Acc: 0.762887\n",
      "Epoch 13781 - Train Loss: 0.102235, Train Acc: 0.838462 | Val Loss: 0.123456, Val Acc: 0.762887\n",
      "Epoch 13782 - Train Loss: 0.102230, Train Acc: 0.838462 | Val Loss: 0.123452, Val Acc: 0.762887\n",
      "Epoch 13783 - Train Loss: 0.102225, Train Acc: 0.838462 | Val Loss: 0.123449, Val Acc: 0.762887\n",
      "Epoch 13784 - Train Loss: 0.102220, Train Acc: 0.838462 | Val Loss: 0.123445, Val Acc: 0.762887\n",
      "Epoch 13785 - Train Loss: 0.102215, Train Acc: 0.838462 | Val Loss: 0.123442, Val Acc: 0.762887\n",
      "Epoch 13786 - Train Loss: 0.102211, Train Acc: 0.838462 | Val Loss: 0.123438, Val Acc: 0.762887\n",
      "Epoch 13787 - Train Loss: 0.102206, Train Acc: 0.838462 | Val Loss: 0.123435, Val Acc: 0.762887\n",
      "Epoch 13788 - Train Loss: 0.102201, Train Acc: 0.838462 | Val Loss: 0.123431, Val Acc: 0.762887\n",
      "Epoch 13789 - Train Loss: 0.102196, Train Acc: 0.838462 | Val Loss: 0.123428, Val Acc: 0.762887\n",
      "Epoch 13790 - Train Loss: 0.102191, Train Acc: 0.838462 | Val Loss: 0.123424, Val Acc: 0.762887\n",
      "Epoch 13791 - Train Loss: 0.102186, Train Acc: 0.838462 | Val Loss: 0.123421, Val Acc: 0.762887\n",
      "Epoch 13792 - Train Loss: 0.102182, Train Acc: 0.838462 | Val Loss: 0.123418, Val Acc: 0.762887\n",
      "Epoch 13793 - Train Loss: 0.102177, Train Acc: 0.838462 | Val Loss: 0.123414, Val Acc: 0.762887\n",
      "Epoch 13794 - Train Loss: 0.102172, Train Acc: 0.838462 | Val Loss: 0.123411, Val Acc: 0.762887\n",
      "Epoch 13795 - Train Loss: 0.102167, Train Acc: 0.838462 | Val Loss: 0.123407, Val Acc: 0.762887\n",
      "Epoch 13796 - Train Loss: 0.102162, Train Acc: 0.838462 | Val Loss: 0.123404, Val Acc: 0.762887\n",
      "Epoch 13797 - Train Loss: 0.102157, Train Acc: 0.838462 | Val Loss: 0.123400, Val Acc: 0.762887\n",
      "Epoch 13798 - Train Loss: 0.102153, Train Acc: 0.838462 | Val Loss: 0.123397, Val Acc: 0.762887\n",
      "Epoch 13799 - Train Loss: 0.102148, Train Acc: 0.839744 | Val Loss: 0.123393, Val Acc: 0.762887\n",
      "Epoch 13800 - Train Loss: 0.102143, Train Acc: 0.839744 | Val Loss: 0.123390, Val Acc: 0.762887\n",
      "Epoch 13801 - Train Loss: 0.102138, Train Acc: 0.839744 | Val Loss: 0.123386, Val Acc: 0.762887\n",
      "Epoch 13802 - Train Loss: 0.102133, Train Acc: 0.839744 | Val Loss: 0.123383, Val Acc: 0.762887\n",
      "Epoch 13803 - Train Loss: 0.102128, Train Acc: 0.839744 | Val Loss: 0.123379, Val Acc: 0.762887\n",
      "Epoch 13804 - Train Loss: 0.102124, Train Acc: 0.839744 | Val Loss: 0.123376, Val Acc: 0.762887\n",
      "Epoch 13805 - Train Loss: 0.102119, Train Acc: 0.839744 | Val Loss: 0.123373, Val Acc: 0.762887\n",
      "Epoch 13806 - Train Loss: 0.102114, Train Acc: 0.839744 | Val Loss: 0.123369, Val Acc: 0.762887\n",
      "Epoch 13807 - Train Loss: 0.102109, Train Acc: 0.839744 | Val Loss: 0.123366, Val Acc: 0.762887\n",
      "Epoch 13808 - Train Loss: 0.102104, Train Acc: 0.839744 | Val Loss: 0.123362, Val Acc: 0.762887\n",
      "Epoch 13809 - Train Loss: 0.102099, Train Acc: 0.839744 | Val Loss: 0.123359, Val Acc: 0.762887\n",
      "Epoch 13810 - Train Loss: 0.102095, Train Acc: 0.839744 | Val Loss: 0.123355, Val Acc: 0.762887\n",
      "Epoch 13811 - Train Loss: 0.102090, Train Acc: 0.839744 | Val Loss: 0.123352, Val Acc: 0.762887\n",
      "Epoch 13812 - Train Loss: 0.102085, Train Acc: 0.839744 | Val Loss: 0.123348, Val Acc: 0.762887\n",
      "Epoch 13813 - Train Loss: 0.102080, Train Acc: 0.841026 | Val Loss: 0.123345, Val Acc: 0.762887\n",
      "Epoch 13814 - Train Loss: 0.102075, Train Acc: 0.841026 | Val Loss: 0.123341, Val Acc: 0.762887\n",
      "Epoch 13815 - Train Loss: 0.102070, Train Acc: 0.841026 | Val Loss: 0.123338, Val Acc: 0.762887\n",
      "Epoch 13816 - Train Loss: 0.102066, Train Acc: 0.841026 | Val Loss: 0.123335, Val Acc: 0.762887\n",
      "Epoch 13817 - Train Loss: 0.102061, Train Acc: 0.841026 | Val Loss: 0.123331, Val Acc: 0.762887\n",
      "Epoch 13818 - Train Loss: 0.102056, Train Acc: 0.841026 | Val Loss: 0.123328, Val Acc: 0.762887\n",
      "Epoch 13819 - Train Loss: 0.102051, Train Acc: 0.841026 | Val Loss: 0.123324, Val Acc: 0.762887\n",
      "Epoch 13820 - Train Loss: 0.102046, Train Acc: 0.841026 | Val Loss: 0.123321, Val Acc: 0.762887\n",
      "Epoch 13821 - Train Loss: 0.102042, Train Acc: 0.841026 | Val Loss: 0.123317, Val Acc: 0.762887\n",
      "Epoch 13822 - Train Loss: 0.102037, Train Acc: 0.841026 | Val Loss: 0.123314, Val Acc: 0.762887\n",
      "Epoch 13823 - Train Loss: 0.102032, Train Acc: 0.841026 | Val Loss: 0.123310, Val Acc: 0.762887\n",
      "Epoch 13824 - Train Loss: 0.102027, Train Acc: 0.841026 | Val Loss: 0.123307, Val Acc: 0.762887\n",
      "Epoch 13825 - Train Loss: 0.102022, Train Acc: 0.841026 | Val Loss: 0.123303, Val Acc: 0.762887\n",
      "Epoch 13826 - Train Loss: 0.102017, Train Acc: 0.841026 | Val Loss: 0.123300, Val Acc: 0.762887\n",
      "Epoch 13827 - Train Loss: 0.102013, Train Acc: 0.841026 | Val Loss: 0.123297, Val Acc: 0.762887\n",
      "Epoch 13828 - Train Loss: 0.102008, Train Acc: 0.841026 | Val Loss: 0.123293, Val Acc: 0.762887\n",
      "Epoch 13829 - Train Loss: 0.102003, Train Acc: 0.841026 | Val Loss: 0.123290, Val Acc: 0.762887\n",
      "Epoch 13830 - Train Loss: 0.101998, Train Acc: 0.841026 | Val Loss: 0.123286, Val Acc: 0.762887\n",
      "Epoch 13831 - Train Loss: 0.101993, Train Acc: 0.841026 | Val Loss: 0.123283, Val Acc: 0.762887\n",
      "Epoch 13832 - Train Loss: 0.101989, Train Acc: 0.841026 | Val Loss: 0.123279, Val Acc: 0.762887\n",
      "Epoch 13833 - Train Loss: 0.101984, Train Acc: 0.841026 | Val Loss: 0.123276, Val Acc: 0.762887\n",
      "Epoch 13834 - Train Loss: 0.101979, Train Acc: 0.841026 | Val Loss: 0.123273, Val Acc: 0.762887\n",
      "Epoch 13835 - Train Loss: 0.101974, Train Acc: 0.841026 | Val Loss: 0.123269, Val Acc: 0.762887\n",
      "Epoch 13836 - Train Loss: 0.101969, Train Acc: 0.841026 | Val Loss: 0.123266, Val Acc: 0.762887\n",
      "Epoch 13837 - Train Loss: 0.101965, Train Acc: 0.841026 | Val Loss: 0.123262, Val Acc: 0.762887\n",
      "Epoch 13838 - Train Loss: 0.101960, Train Acc: 0.841026 | Val Loss: 0.123259, Val Acc: 0.762887\n",
      "Epoch 13839 - Train Loss: 0.101955, Train Acc: 0.841026 | Val Loss: 0.123255, Val Acc: 0.762887\n",
      "Epoch 13840 - Train Loss: 0.101950, Train Acc: 0.841026 | Val Loss: 0.123252, Val Acc: 0.762887\n",
      "Epoch 13841 - Train Loss: 0.101945, Train Acc: 0.841026 | Val Loss: 0.123248, Val Acc: 0.762887\n",
      "Epoch 13842 - Train Loss: 0.101941, Train Acc: 0.841026 | Val Loss: 0.123245, Val Acc: 0.762887\n",
      "Epoch 13843 - Train Loss: 0.101936, Train Acc: 0.841026 | Val Loss: 0.123242, Val Acc: 0.762887\n",
      "Epoch 13844 - Train Loss: 0.101931, Train Acc: 0.841026 | Val Loss: 0.123238, Val Acc: 0.762887\n",
      "Epoch 13845 - Train Loss: 0.101926, Train Acc: 0.841026 | Val Loss: 0.123235, Val Acc: 0.762887\n",
      "Epoch 13846 - Train Loss: 0.101921, Train Acc: 0.841026 | Val Loss: 0.123231, Val Acc: 0.762887\n",
      "Epoch 13847 - Train Loss: 0.101916, Train Acc: 0.841026 | Val Loss: 0.123228, Val Acc: 0.762887\n",
      "Epoch 13848 - Train Loss: 0.101912, Train Acc: 0.841026 | Val Loss: 0.123224, Val Acc: 0.762887\n",
      "Epoch 13849 - Train Loss: 0.101907, Train Acc: 0.841026 | Val Loss: 0.123221, Val Acc: 0.762887\n",
      "Epoch 13850 - Train Loss: 0.101902, Train Acc: 0.841026 | Val Loss: 0.123218, Val Acc: 0.762887\n",
      "Epoch 13851 - Train Loss: 0.101897, Train Acc: 0.841026 | Val Loss: 0.123214, Val Acc: 0.762887\n",
      "Epoch 13852 - Train Loss: 0.101893, Train Acc: 0.841026 | Val Loss: 0.123211, Val Acc: 0.762887\n",
      "Epoch 13853 - Train Loss: 0.101888, Train Acc: 0.841026 | Val Loss: 0.123207, Val Acc: 0.762887\n",
      "Epoch 13854 - Train Loss: 0.101883, Train Acc: 0.841026 | Val Loss: 0.123204, Val Acc: 0.762887\n",
      "Epoch 13855 - Train Loss: 0.101878, Train Acc: 0.841026 | Val Loss: 0.123200, Val Acc: 0.762887\n",
      "Epoch 13856 - Train Loss: 0.101873, Train Acc: 0.841026 | Val Loss: 0.123197, Val Acc: 0.762887\n",
      "Epoch 13857 - Train Loss: 0.101869, Train Acc: 0.841026 | Val Loss: 0.123194, Val Acc: 0.762887\n",
      "Epoch 13858 - Train Loss: 0.101864, Train Acc: 0.841026 | Val Loss: 0.123190, Val Acc: 0.762887\n",
      "Epoch 13859 - Train Loss: 0.101859, Train Acc: 0.841026 | Val Loss: 0.123187, Val Acc: 0.762887\n",
      "Epoch 13860 - Train Loss: 0.101854, Train Acc: 0.841026 | Val Loss: 0.123183, Val Acc: 0.762887\n",
      "Epoch 13861 - Train Loss: 0.101849, Train Acc: 0.841026 | Val Loss: 0.123180, Val Acc: 0.762887\n",
      "Epoch 13862 - Train Loss: 0.101845, Train Acc: 0.841026 | Val Loss: 0.123177, Val Acc: 0.762887\n",
      "Epoch 13863 - Train Loss: 0.101840, Train Acc: 0.841026 | Val Loss: 0.123173, Val Acc: 0.762887\n",
      "Epoch 13864 - Train Loss: 0.101835, Train Acc: 0.841026 | Val Loss: 0.123170, Val Acc: 0.762887\n",
      "Epoch 13865 - Train Loss: 0.101830, Train Acc: 0.841026 | Val Loss: 0.123166, Val Acc: 0.762887\n",
      "Epoch 13866 - Train Loss: 0.101825, Train Acc: 0.841026 | Val Loss: 0.123163, Val Acc: 0.762887\n",
      "Epoch 13867 - Train Loss: 0.101821, Train Acc: 0.841026 | Val Loss: 0.123159, Val Acc: 0.762887\n",
      "Epoch 13868 - Train Loss: 0.101816, Train Acc: 0.841026 | Val Loss: 0.123156, Val Acc: 0.762887\n",
      "Epoch 13869 - Train Loss: 0.101811, Train Acc: 0.841026 | Val Loss: 0.123153, Val Acc: 0.762887\n",
      "Epoch 13870 - Train Loss: 0.101806, Train Acc: 0.841026 | Val Loss: 0.123149, Val Acc: 0.762887\n",
      "Epoch 13871 - Train Loss: 0.101801, Train Acc: 0.841026 | Val Loss: 0.123146, Val Acc: 0.762887\n",
      "Epoch 13872 - Train Loss: 0.101797, Train Acc: 0.841026 | Val Loss: 0.123142, Val Acc: 0.762887\n",
      "Epoch 13873 - Train Loss: 0.101792, Train Acc: 0.841026 | Val Loss: 0.123139, Val Acc: 0.762887\n",
      "Epoch 13874 - Train Loss: 0.101787, Train Acc: 0.841026 | Val Loss: 0.123136, Val Acc: 0.762887\n",
      "Epoch 13875 - Train Loss: 0.101782, Train Acc: 0.841026 | Val Loss: 0.123132, Val Acc: 0.762887\n",
      "Epoch 13876 - Train Loss: 0.101778, Train Acc: 0.841026 | Val Loss: 0.123129, Val Acc: 0.762887\n",
      "Epoch 13877 - Train Loss: 0.101773, Train Acc: 0.841026 | Val Loss: 0.123125, Val Acc: 0.762887\n",
      "Epoch 13878 - Train Loss: 0.101768, Train Acc: 0.841026 | Val Loss: 0.123122, Val Acc: 0.762887\n",
      "Epoch 13879 - Train Loss: 0.101763, Train Acc: 0.841026 | Val Loss: 0.123118, Val Acc: 0.762887\n",
      "Epoch 13880 - Train Loss: 0.101758, Train Acc: 0.841026 | Val Loss: 0.123115, Val Acc: 0.762887\n",
      "Epoch 13881 - Train Loss: 0.101754, Train Acc: 0.841026 | Val Loss: 0.123112, Val Acc: 0.762887\n",
      "Epoch 13882 - Train Loss: 0.101749, Train Acc: 0.841026 | Val Loss: 0.123108, Val Acc: 0.762887\n",
      "Epoch 13883 - Train Loss: 0.101744, Train Acc: 0.841026 | Val Loss: 0.123105, Val Acc: 0.762887\n",
      "Epoch 13884 - Train Loss: 0.101739, Train Acc: 0.841026 | Val Loss: 0.123101, Val Acc: 0.762887\n",
      "Epoch 13885 - Train Loss: 0.101735, Train Acc: 0.841026 | Val Loss: 0.123098, Val Acc: 0.762887\n",
      "Epoch 13886 - Train Loss: 0.101730, Train Acc: 0.842308 | Val Loss: 0.123095, Val Acc: 0.762887\n",
      "Epoch 13887 - Train Loss: 0.101725, Train Acc: 0.842308 | Val Loss: 0.123091, Val Acc: 0.762887\n",
      "Epoch 13888 - Train Loss: 0.101720, Train Acc: 0.842308 | Val Loss: 0.123088, Val Acc: 0.762887\n",
      "Epoch 13889 - Train Loss: 0.101715, Train Acc: 0.842308 | Val Loss: 0.123084, Val Acc: 0.762887\n",
      "Epoch 13890 - Train Loss: 0.101711, Train Acc: 0.842308 | Val Loss: 0.123081, Val Acc: 0.762887\n",
      "Epoch 13891 - Train Loss: 0.101706, Train Acc: 0.842308 | Val Loss: 0.123078, Val Acc: 0.762887\n",
      "Epoch 13892 - Train Loss: 0.101701, Train Acc: 0.842308 | Val Loss: 0.123074, Val Acc: 0.762887\n",
      "Epoch 13893 - Train Loss: 0.101696, Train Acc: 0.842308 | Val Loss: 0.123071, Val Acc: 0.762887\n",
      "Epoch 13894 - Train Loss: 0.101692, Train Acc: 0.842308 | Val Loss: 0.123067, Val Acc: 0.762887\n",
      "Epoch 13895 - Train Loss: 0.101687, Train Acc: 0.842308 | Val Loss: 0.123064, Val Acc: 0.762887\n",
      "Epoch 13896 - Train Loss: 0.101682, Train Acc: 0.842308 | Val Loss: 0.123061, Val Acc: 0.762887\n",
      "Epoch 13897 - Train Loss: 0.101677, Train Acc: 0.842308 | Val Loss: 0.123057, Val Acc: 0.762887\n",
      "Epoch 13898 - Train Loss: 0.101673, Train Acc: 0.842308 | Val Loss: 0.123054, Val Acc: 0.762887\n",
      "Epoch 13899 - Train Loss: 0.101668, Train Acc: 0.842308 | Val Loss: 0.123050, Val Acc: 0.762887\n",
      "Epoch 13900 - Train Loss: 0.101663, Train Acc: 0.842308 | Val Loss: 0.123047, Val Acc: 0.762887\n",
      "Epoch 13901 - Train Loss: 0.101658, Train Acc: 0.842308 | Val Loss: 0.123044, Val Acc: 0.762887\n",
      "Epoch 13902 - Train Loss: 0.101653, Train Acc: 0.842308 | Val Loss: 0.123040, Val Acc: 0.762887\n",
      "Epoch 13903 - Train Loss: 0.101649, Train Acc: 0.842308 | Val Loss: 0.123037, Val Acc: 0.762887\n",
      "Epoch 13904 - Train Loss: 0.101644, Train Acc: 0.842308 | Val Loss: 0.123033, Val Acc: 0.762887\n",
      "Epoch 13905 - Train Loss: 0.101639, Train Acc: 0.842308 | Val Loss: 0.123030, Val Acc: 0.762887\n",
      "Epoch 13906 - Train Loss: 0.101634, Train Acc: 0.842308 | Val Loss: 0.123027, Val Acc: 0.762887\n",
      "Epoch 13907 - Train Loss: 0.101630, Train Acc: 0.842308 | Val Loss: 0.123023, Val Acc: 0.762887\n",
      "Epoch 13908 - Train Loss: 0.101625, Train Acc: 0.842308 | Val Loss: 0.123020, Val Acc: 0.762887\n",
      "Epoch 13909 - Train Loss: 0.101620, Train Acc: 0.842308 | Val Loss: 0.123017, Val Acc: 0.762887\n",
      "Epoch 13910 - Train Loss: 0.101615, Train Acc: 0.842308 | Val Loss: 0.123013, Val Acc: 0.762887\n",
      "Epoch 13911 - Train Loss: 0.101611, Train Acc: 0.842308 | Val Loss: 0.123010, Val Acc: 0.762887\n",
      "Epoch 13912 - Train Loss: 0.101606, Train Acc: 0.842308 | Val Loss: 0.123006, Val Acc: 0.762887\n",
      "Epoch 13913 - Train Loss: 0.101601, Train Acc: 0.842308 | Val Loss: 0.123003, Val Acc: 0.762887\n",
      "Epoch 13914 - Train Loss: 0.101596, Train Acc: 0.842308 | Val Loss: 0.123000, Val Acc: 0.762887\n",
      "Epoch 13915 - Train Loss: 0.101592, Train Acc: 0.842308 | Val Loss: 0.122996, Val Acc: 0.762887\n",
      "Epoch 13916 - Train Loss: 0.101587, Train Acc: 0.842308 | Val Loss: 0.122993, Val Acc: 0.762887\n",
      "Epoch 13917 - Train Loss: 0.101582, Train Acc: 0.842308 | Val Loss: 0.122989, Val Acc: 0.762887\n",
      "Epoch 13918 - Train Loss: 0.101577, Train Acc: 0.842308 | Val Loss: 0.122986, Val Acc: 0.762887\n",
      "Epoch 13919 - Train Loss: 0.101573, Train Acc: 0.842308 | Val Loss: 0.122983, Val Acc: 0.762887\n",
      "Epoch 13920 - Train Loss: 0.101568, Train Acc: 0.842308 | Val Loss: 0.122979, Val Acc: 0.762887\n",
      "Epoch 13921 - Train Loss: 0.101563, Train Acc: 0.843590 | Val Loss: 0.122976, Val Acc: 0.762887\n",
      "Epoch 13922 - Train Loss: 0.101558, Train Acc: 0.843590 | Val Loss: 0.122973, Val Acc: 0.762887\n",
      "Epoch 13923 - Train Loss: 0.101554, Train Acc: 0.843590 | Val Loss: 0.122969, Val Acc: 0.762887\n",
      "Epoch 13924 - Train Loss: 0.101549, Train Acc: 0.843590 | Val Loss: 0.122966, Val Acc: 0.762887\n",
      "Epoch 13925 - Train Loss: 0.101544, Train Acc: 0.843590 | Val Loss: 0.122962, Val Acc: 0.762887\n",
      "Epoch 13926 - Train Loss: 0.101539, Train Acc: 0.843590 | Val Loss: 0.122959, Val Acc: 0.762887\n",
      "Epoch 13927 - Train Loss: 0.101535, Train Acc: 0.843590 | Val Loss: 0.122956, Val Acc: 0.762887\n",
      "Epoch 13928 - Train Loss: 0.101530, Train Acc: 0.843590 | Val Loss: 0.122952, Val Acc: 0.762887\n",
      "Epoch 13929 - Train Loss: 0.101525, Train Acc: 0.843590 | Val Loss: 0.122949, Val Acc: 0.762887\n",
      "Epoch 13930 - Train Loss: 0.101520, Train Acc: 0.843590 | Val Loss: 0.122946, Val Acc: 0.762887\n",
      "Epoch 13931 - Train Loss: 0.101516, Train Acc: 0.843590 | Val Loss: 0.122942, Val Acc: 0.762887\n",
      "Epoch 13932 - Train Loss: 0.101511, Train Acc: 0.843590 | Val Loss: 0.122939, Val Acc: 0.762887\n",
      "Epoch 13933 - Train Loss: 0.101506, Train Acc: 0.843590 | Val Loss: 0.122935, Val Acc: 0.762887\n",
      "Epoch 13934 - Train Loss: 0.101501, Train Acc: 0.843590 | Val Loss: 0.122932, Val Acc: 0.762887\n",
      "Epoch 13935 - Train Loss: 0.101497, Train Acc: 0.843590 | Val Loss: 0.122929, Val Acc: 0.762887\n",
      "Epoch 13936 - Train Loss: 0.101492, Train Acc: 0.843590 | Val Loss: 0.122925, Val Acc: 0.762887\n",
      "Epoch 13937 - Train Loss: 0.101487, Train Acc: 0.843590 | Val Loss: 0.122922, Val Acc: 0.762887\n",
      "Epoch 13938 - Train Loss: 0.101482, Train Acc: 0.843590 | Val Loss: 0.122919, Val Acc: 0.762887\n",
      "Epoch 13939 - Train Loss: 0.101478, Train Acc: 0.843590 | Val Loss: 0.122915, Val Acc: 0.762887\n",
      "Epoch 13940 - Train Loss: 0.101473, Train Acc: 0.843590 | Val Loss: 0.122912, Val Acc: 0.762887\n",
      "Epoch 13941 - Train Loss: 0.101468, Train Acc: 0.843590 | Val Loss: 0.122908, Val Acc: 0.762887\n",
      "Epoch 13942 - Train Loss: 0.101463, Train Acc: 0.843590 | Val Loss: 0.122905, Val Acc: 0.762887\n",
      "Epoch 13943 - Train Loss: 0.101459, Train Acc: 0.843590 | Val Loss: 0.122902, Val Acc: 0.762887\n",
      "Epoch 13944 - Train Loss: 0.101454, Train Acc: 0.843590 | Val Loss: 0.122898, Val Acc: 0.762887\n",
      "Epoch 13945 - Train Loss: 0.101449, Train Acc: 0.843590 | Val Loss: 0.122895, Val Acc: 0.762887\n",
      "Epoch 13946 - Train Loss: 0.101444, Train Acc: 0.844872 | Val Loss: 0.122892, Val Acc: 0.762887\n",
      "Epoch 13947 - Train Loss: 0.101440, Train Acc: 0.844872 | Val Loss: 0.122888, Val Acc: 0.762887\n",
      "Epoch 13948 - Train Loss: 0.101435, Train Acc: 0.844872 | Val Loss: 0.122885, Val Acc: 0.762887\n",
      "Epoch 13949 - Train Loss: 0.101430, Train Acc: 0.844872 | Val Loss: 0.122882, Val Acc: 0.762887\n",
      "Epoch 13950 - Train Loss: 0.101426, Train Acc: 0.844872 | Val Loss: 0.122878, Val Acc: 0.762887\n",
      "Epoch 13951 - Train Loss: 0.101421, Train Acc: 0.844872 | Val Loss: 0.122875, Val Acc: 0.762887\n",
      "Epoch 13952 - Train Loss: 0.101416, Train Acc: 0.844872 | Val Loss: 0.122871, Val Acc: 0.762887\n",
      "Epoch 13953 - Train Loss: 0.101411, Train Acc: 0.844872 | Val Loss: 0.122868, Val Acc: 0.762887\n",
      "Epoch 13954 - Train Loss: 0.101407, Train Acc: 0.844872 | Val Loss: 0.122865, Val Acc: 0.762887\n",
      "Epoch 13955 - Train Loss: 0.101402, Train Acc: 0.844872 | Val Loss: 0.122861, Val Acc: 0.762887\n",
      "Epoch 13956 - Train Loss: 0.101397, Train Acc: 0.844872 | Val Loss: 0.122858, Val Acc: 0.762887\n",
      "Epoch 13957 - Train Loss: 0.101392, Train Acc: 0.844872 | Val Loss: 0.122855, Val Acc: 0.762887\n",
      "Epoch 13958 - Train Loss: 0.101388, Train Acc: 0.844872 | Val Loss: 0.122851, Val Acc: 0.762887\n",
      "Epoch 13959 - Train Loss: 0.101383, Train Acc: 0.844872 | Val Loss: 0.122848, Val Acc: 0.762887\n",
      "Epoch 13960 - Train Loss: 0.101378, Train Acc: 0.844872 | Val Loss: 0.122845, Val Acc: 0.762887\n",
      "Epoch 13961 - Train Loss: 0.101374, Train Acc: 0.844872 | Val Loss: 0.122841, Val Acc: 0.762887\n",
      "Epoch 13962 - Train Loss: 0.101369, Train Acc: 0.844872 | Val Loss: 0.122838, Val Acc: 0.762887\n",
      "Epoch 13963 - Train Loss: 0.101364, Train Acc: 0.844872 | Val Loss: 0.122834, Val Acc: 0.762887\n",
      "Epoch 13964 - Train Loss: 0.101359, Train Acc: 0.844872 | Val Loss: 0.122831, Val Acc: 0.762887\n",
      "Epoch 13965 - Train Loss: 0.101355, Train Acc: 0.844872 | Val Loss: 0.122828, Val Acc: 0.762887\n",
      "Epoch 13966 - Train Loss: 0.101350, Train Acc: 0.844872 | Val Loss: 0.122824, Val Acc: 0.762887\n",
      "Epoch 13967 - Train Loss: 0.101345, Train Acc: 0.844872 | Val Loss: 0.122821, Val Acc: 0.762887\n",
      "Epoch 13968 - Train Loss: 0.101340, Train Acc: 0.844872 | Val Loss: 0.122818, Val Acc: 0.762887\n",
      "Epoch 13969 - Train Loss: 0.101336, Train Acc: 0.844872 | Val Loss: 0.122814, Val Acc: 0.762887\n",
      "Epoch 13970 - Train Loss: 0.101331, Train Acc: 0.844872 | Val Loss: 0.122811, Val Acc: 0.762887\n",
      "Epoch 13971 - Train Loss: 0.101326, Train Acc: 0.844872 | Val Loss: 0.122808, Val Acc: 0.762887\n",
      "Epoch 13972 - Train Loss: 0.101322, Train Acc: 0.844872 | Val Loss: 0.122804, Val Acc: 0.762887\n",
      "Epoch 13973 - Train Loss: 0.101317, Train Acc: 0.844872 | Val Loss: 0.122801, Val Acc: 0.762887\n",
      "Epoch 13974 - Train Loss: 0.101312, Train Acc: 0.844872 | Val Loss: 0.122798, Val Acc: 0.762887\n",
      "Epoch 13975 - Train Loss: 0.101307, Train Acc: 0.844872 | Val Loss: 0.122794, Val Acc: 0.762887\n",
      "Epoch 13976 - Train Loss: 0.101303, Train Acc: 0.844872 | Val Loss: 0.122791, Val Acc: 0.762887\n",
      "Epoch 13977 - Train Loss: 0.101298, Train Acc: 0.844872 | Val Loss: 0.122788, Val Acc: 0.762887\n",
      "Epoch 13978 - Train Loss: 0.101293, Train Acc: 0.844872 | Val Loss: 0.122784, Val Acc: 0.762887\n",
      "Epoch 13979 - Train Loss: 0.101289, Train Acc: 0.844872 | Val Loss: 0.122781, Val Acc: 0.762887\n",
      "Epoch 13980 - Train Loss: 0.101284, Train Acc: 0.844872 | Val Loss: 0.122778, Val Acc: 0.762887\n",
      "Epoch 13981 - Train Loss: 0.101279, Train Acc: 0.844872 | Val Loss: 0.122774, Val Acc: 0.762887\n",
      "Epoch 13982 - Train Loss: 0.101274, Train Acc: 0.844872 | Val Loss: 0.122771, Val Acc: 0.762887\n",
      "Epoch 13983 - Train Loss: 0.101270, Train Acc: 0.844872 | Val Loss: 0.122768, Val Acc: 0.762887\n",
      "Epoch 13984 - Train Loss: 0.101265, Train Acc: 0.844872 | Val Loss: 0.122764, Val Acc: 0.762887\n",
      "Epoch 13985 - Train Loss: 0.101260, Train Acc: 0.844872 | Val Loss: 0.122761, Val Acc: 0.762887\n",
      "Epoch 13986 - Train Loss: 0.101256, Train Acc: 0.844872 | Val Loss: 0.122758, Val Acc: 0.762887\n",
      "Epoch 13987 - Train Loss: 0.101251, Train Acc: 0.844872 | Val Loss: 0.122754, Val Acc: 0.762887\n",
      "Epoch 13988 - Train Loss: 0.101246, Train Acc: 0.844872 | Val Loss: 0.122751, Val Acc: 0.762887\n",
      "Epoch 13989 - Train Loss: 0.101241, Train Acc: 0.844872 | Val Loss: 0.122747, Val Acc: 0.762887\n",
      "Epoch 13990 - Train Loss: 0.101237, Train Acc: 0.844872 | Val Loss: 0.122744, Val Acc: 0.762887\n",
      "Epoch 13991 - Train Loss: 0.101232, Train Acc: 0.844872 | Val Loss: 0.122741, Val Acc: 0.762887\n",
      "Epoch 13992 - Train Loss: 0.101227, Train Acc: 0.844872 | Val Loss: 0.122737, Val Acc: 0.762887\n",
      "Epoch 13993 - Train Loss: 0.101223, Train Acc: 0.844872 | Val Loss: 0.122734, Val Acc: 0.762887\n",
      "Epoch 13994 - Train Loss: 0.101218, Train Acc: 0.844872 | Val Loss: 0.122731, Val Acc: 0.762887\n",
      "Epoch 13995 - Train Loss: 0.101213, Train Acc: 0.844872 | Val Loss: 0.122727, Val Acc: 0.762887\n",
      "Epoch 13996 - Train Loss: 0.101209, Train Acc: 0.844872 | Val Loss: 0.122724, Val Acc: 0.762887\n",
      "Epoch 13997 - Train Loss: 0.101204, Train Acc: 0.844872 | Val Loss: 0.122721, Val Acc: 0.762887\n",
      "Epoch 13998 - Train Loss: 0.101199, Train Acc: 0.844872 | Val Loss: 0.122717, Val Acc: 0.762887\n",
      "Epoch 13999 - Train Loss: 0.101194, Train Acc: 0.844872 | Val Loss: 0.122714, Val Acc: 0.762887\n",
      "Epoch 14000 - Train Loss: 0.101190, Train Acc: 0.844872 | Val Loss: 0.122711, Val Acc: 0.762887\n",
      "Epoch 14001 - Train Loss: 0.101185, Train Acc: 0.844872 | Val Loss: 0.122707, Val Acc: 0.762887\n",
      "Epoch 14002 - Train Loss: 0.101180, Train Acc: 0.844872 | Val Loss: 0.122704, Val Acc: 0.762887\n",
      "Epoch 14003 - Train Loss: 0.101176, Train Acc: 0.844872 | Val Loss: 0.122701, Val Acc: 0.762887\n",
      "Epoch 14004 - Train Loss: 0.101171, Train Acc: 0.844872 | Val Loss: 0.122698, Val Acc: 0.762887\n",
      "Epoch 14005 - Train Loss: 0.101166, Train Acc: 0.844872 | Val Loss: 0.122694, Val Acc: 0.762887\n",
      "Epoch 14006 - Train Loss: 0.101162, Train Acc: 0.844872 | Val Loss: 0.122691, Val Acc: 0.762887\n",
      "Epoch 14007 - Train Loss: 0.101157, Train Acc: 0.844872 | Val Loss: 0.122688, Val Acc: 0.762887\n",
      "Epoch 14008 - Train Loss: 0.101152, Train Acc: 0.844872 | Val Loss: 0.122684, Val Acc: 0.762887\n",
      "Epoch 14009 - Train Loss: 0.101147, Train Acc: 0.844872 | Val Loss: 0.122681, Val Acc: 0.762887\n",
      "Epoch 14010 - Train Loss: 0.101143, Train Acc: 0.844872 | Val Loss: 0.122678, Val Acc: 0.762887\n",
      "Epoch 14011 - Train Loss: 0.101138, Train Acc: 0.844872 | Val Loss: 0.122674, Val Acc: 0.762887\n",
      "Epoch 14012 - Train Loss: 0.101133, Train Acc: 0.844872 | Val Loss: 0.122671, Val Acc: 0.762887\n",
      "Epoch 14013 - Train Loss: 0.101129, Train Acc: 0.844872 | Val Loss: 0.122668, Val Acc: 0.762887\n",
      "Epoch 14014 - Train Loss: 0.101124, Train Acc: 0.844872 | Val Loss: 0.122664, Val Acc: 0.762887\n",
      "Epoch 14015 - Train Loss: 0.101119, Train Acc: 0.844872 | Val Loss: 0.122661, Val Acc: 0.762887\n",
      "Epoch 14016 - Train Loss: 0.101115, Train Acc: 0.844872 | Val Loss: 0.122658, Val Acc: 0.762887\n",
      "Epoch 14017 - Train Loss: 0.101110, Train Acc: 0.844872 | Val Loss: 0.122654, Val Acc: 0.762887\n",
      "Epoch 14018 - Train Loss: 0.101105, Train Acc: 0.844872 | Val Loss: 0.122651, Val Acc: 0.762887\n",
      "Epoch 14019 - Train Loss: 0.101101, Train Acc: 0.844872 | Val Loss: 0.122648, Val Acc: 0.762887\n",
      "Epoch 14020 - Train Loss: 0.101096, Train Acc: 0.844872 | Val Loss: 0.122644, Val Acc: 0.762887\n",
      "Epoch 14021 - Train Loss: 0.101091, Train Acc: 0.844872 | Val Loss: 0.122641, Val Acc: 0.762887\n",
      "Epoch 14022 - Train Loss: 0.101086, Train Acc: 0.844872 | Val Loss: 0.122638, Val Acc: 0.762887\n",
      "Epoch 14023 - Train Loss: 0.101082, Train Acc: 0.844872 | Val Loss: 0.122634, Val Acc: 0.762887\n",
      "Epoch 14024 - Train Loss: 0.101077, Train Acc: 0.844872 | Val Loss: 0.122631, Val Acc: 0.762887\n",
      "Epoch 14025 - Train Loss: 0.101072, Train Acc: 0.844872 | Val Loss: 0.122628, Val Acc: 0.762887\n",
      "Epoch 14026 - Train Loss: 0.101068, Train Acc: 0.844872 | Val Loss: 0.122624, Val Acc: 0.762887\n",
      "Epoch 14027 - Train Loss: 0.101063, Train Acc: 0.844872 | Val Loss: 0.122621, Val Acc: 0.762887\n",
      "Epoch 14028 - Train Loss: 0.101058, Train Acc: 0.844872 | Val Loss: 0.122618, Val Acc: 0.762887\n",
      "Epoch 14029 - Train Loss: 0.101054, Train Acc: 0.844872 | Val Loss: 0.122615, Val Acc: 0.762887\n",
      "Epoch 14030 - Train Loss: 0.101049, Train Acc: 0.844872 | Val Loss: 0.122611, Val Acc: 0.762887\n",
      "Epoch 14031 - Train Loss: 0.101044, Train Acc: 0.844872 | Val Loss: 0.122608, Val Acc: 0.762887\n",
      "Epoch 14032 - Train Loss: 0.101040, Train Acc: 0.844872 | Val Loss: 0.122605, Val Acc: 0.762887\n",
      "Epoch 14033 - Train Loss: 0.101035, Train Acc: 0.844872 | Val Loss: 0.122601, Val Acc: 0.762887\n",
      "Epoch 14034 - Train Loss: 0.101030, Train Acc: 0.844872 | Val Loss: 0.122598, Val Acc: 0.762887\n",
      "Epoch 14035 - Train Loss: 0.101026, Train Acc: 0.844872 | Val Loss: 0.122595, Val Acc: 0.762887\n",
      "Epoch 14036 - Train Loss: 0.101021, Train Acc: 0.844872 | Val Loss: 0.122591, Val Acc: 0.762887\n",
      "Epoch 14037 - Train Loss: 0.101016, Train Acc: 0.844872 | Val Loss: 0.122588, Val Acc: 0.762887\n",
      "Epoch 14038 - Train Loss: 0.101012, Train Acc: 0.844872 | Val Loss: 0.122585, Val Acc: 0.762887\n",
      "Epoch 14039 - Train Loss: 0.101007, Train Acc: 0.844872 | Val Loss: 0.122581, Val Acc: 0.762887\n",
      "Epoch 14040 - Train Loss: 0.101002, Train Acc: 0.844872 | Val Loss: 0.122578, Val Acc: 0.762887\n",
      "Epoch 14041 - Train Loss: 0.100998, Train Acc: 0.844872 | Val Loss: 0.122575, Val Acc: 0.762887\n",
      "Epoch 14042 - Train Loss: 0.100993, Train Acc: 0.844872 | Val Loss: 0.122572, Val Acc: 0.762887\n",
      "Epoch 14043 - Train Loss: 0.100988, Train Acc: 0.844872 | Val Loss: 0.122568, Val Acc: 0.762887\n",
      "Epoch 14044 - Train Loss: 0.100983, Train Acc: 0.844872 | Val Loss: 0.122565, Val Acc: 0.762887\n",
      "Epoch 14045 - Train Loss: 0.100979, Train Acc: 0.844872 | Val Loss: 0.122562, Val Acc: 0.762887\n",
      "Epoch 14046 - Train Loss: 0.100974, Train Acc: 0.844872 | Val Loss: 0.122558, Val Acc: 0.762887\n",
      "Epoch 14047 - Train Loss: 0.100969, Train Acc: 0.844872 | Val Loss: 0.122555, Val Acc: 0.762887\n",
      "Epoch 14048 - Train Loss: 0.100965, Train Acc: 0.844872 | Val Loss: 0.122552, Val Acc: 0.762887\n",
      "Epoch 14049 - Train Loss: 0.100960, Train Acc: 0.844872 | Val Loss: 0.122548, Val Acc: 0.762887\n",
      "Epoch 14050 - Train Loss: 0.100955, Train Acc: 0.844872 | Val Loss: 0.122545, Val Acc: 0.762887\n",
      "Epoch 14051 - Train Loss: 0.100951, Train Acc: 0.844872 | Val Loss: 0.122542, Val Acc: 0.762887\n",
      "Epoch 14052 - Train Loss: 0.100946, Train Acc: 0.844872 | Val Loss: 0.122539, Val Acc: 0.762887\n",
      "Epoch 14053 - Train Loss: 0.100941, Train Acc: 0.844872 | Val Loss: 0.122535, Val Acc: 0.762887\n",
      "Epoch 14054 - Train Loss: 0.100937, Train Acc: 0.844872 | Val Loss: 0.122532, Val Acc: 0.762887\n",
      "Epoch 14055 - Train Loss: 0.100932, Train Acc: 0.844872 | Val Loss: 0.122529, Val Acc: 0.762887\n",
      "Epoch 14056 - Train Loss: 0.100927, Train Acc: 0.844872 | Val Loss: 0.122525, Val Acc: 0.762887\n",
      "Epoch 14057 - Train Loss: 0.100923, Train Acc: 0.844872 | Val Loss: 0.122522, Val Acc: 0.762887\n",
      "Epoch 14058 - Train Loss: 0.100918, Train Acc: 0.844872 | Val Loss: 0.122519, Val Acc: 0.762887\n",
      "Epoch 14059 - Train Loss: 0.100913, Train Acc: 0.844872 | Val Loss: 0.122515, Val Acc: 0.762887\n",
      "Epoch 14060 - Train Loss: 0.100909, Train Acc: 0.844872 | Val Loss: 0.122512, Val Acc: 0.762887\n",
      "Epoch 14061 - Train Loss: 0.100904, Train Acc: 0.844872 | Val Loss: 0.122509, Val Acc: 0.762887\n",
      "Epoch 14062 - Train Loss: 0.100899, Train Acc: 0.844872 | Val Loss: 0.122506, Val Acc: 0.762887\n",
      "Epoch 14063 - Train Loss: 0.100895, Train Acc: 0.844872 | Val Loss: 0.122502, Val Acc: 0.762887\n",
      "Epoch 14064 - Train Loss: 0.100890, Train Acc: 0.844872 | Val Loss: 0.122499, Val Acc: 0.762887\n",
      "Epoch 14065 - Train Loss: 0.100886, Train Acc: 0.844872 | Val Loss: 0.122496, Val Acc: 0.762887\n",
      "Epoch 14066 - Train Loss: 0.100881, Train Acc: 0.844872 | Val Loss: 0.122492, Val Acc: 0.762887\n",
      "Epoch 14067 - Train Loss: 0.100876, Train Acc: 0.844872 | Val Loss: 0.122489, Val Acc: 0.762887\n",
      "Epoch 14068 - Train Loss: 0.100872, Train Acc: 0.844872 | Val Loss: 0.122486, Val Acc: 0.762887\n",
      "Epoch 14069 - Train Loss: 0.100867, Train Acc: 0.844872 | Val Loss: 0.122483, Val Acc: 0.762887\n",
      "Epoch 14070 - Train Loss: 0.100862, Train Acc: 0.844872 | Val Loss: 0.122479, Val Acc: 0.762887\n",
      "Epoch 14071 - Train Loss: 0.100858, Train Acc: 0.844872 | Val Loss: 0.122476, Val Acc: 0.762887\n",
      "Epoch 14072 - Train Loss: 0.100853, Train Acc: 0.844872 | Val Loss: 0.122473, Val Acc: 0.762887\n",
      "Epoch 14073 - Train Loss: 0.100848, Train Acc: 0.844872 | Val Loss: 0.122469, Val Acc: 0.762887\n",
      "Epoch 14074 - Train Loss: 0.100844, Train Acc: 0.844872 | Val Loss: 0.122466, Val Acc: 0.762887\n",
      "Epoch 14075 - Train Loss: 0.100839, Train Acc: 0.844872 | Val Loss: 0.122463, Val Acc: 0.762887\n",
      "Epoch 14076 - Train Loss: 0.100834, Train Acc: 0.844872 | Val Loss: 0.122460, Val Acc: 0.762887\n",
      "Epoch 14077 - Train Loss: 0.100830, Train Acc: 0.844872 | Val Loss: 0.122456, Val Acc: 0.762887\n",
      "Epoch 14078 - Train Loss: 0.100825, Train Acc: 0.844872 | Val Loss: 0.122453, Val Acc: 0.762887\n",
      "Epoch 14079 - Train Loss: 0.100820, Train Acc: 0.844872 | Val Loss: 0.122450, Val Acc: 0.762887\n",
      "Epoch 14080 - Train Loss: 0.100816, Train Acc: 0.844872 | Val Loss: 0.122447, Val Acc: 0.762887\n",
      "Epoch 14081 - Train Loss: 0.100811, Train Acc: 0.844872 | Val Loss: 0.122443, Val Acc: 0.762887\n",
      "Epoch 14082 - Train Loss: 0.100806, Train Acc: 0.844872 | Val Loss: 0.122440, Val Acc: 0.762887\n",
      "Epoch 14083 - Train Loss: 0.100802, Train Acc: 0.844872 | Val Loss: 0.122437, Val Acc: 0.762887\n",
      "Epoch 14084 - Train Loss: 0.100797, Train Acc: 0.844872 | Val Loss: 0.122433, Val Acc: 0.762887\n",
      "Epoch 14085 - Train Loss: 0.100792, Train Acc: 0.844872 | Val Loss: 0.122430, Val Acc: 0.762887\n",
      "Epoch 14086 - Train Loss: 0.100788, Train Acc: 0.844872 | Val Loss: 0.122427, Val Acc: 0.762887\n",
      "Epoch 14087 - Train Loss: 0.100783, Train Acc: 0.844872 | Val Loss: 0.122424, Val Acc: 0.762887\n",
      "Epoch 14088 - Train Loss: 0.100779, Train Acc: 0.844872 | Val Loss: 0.122420, Val Acc: 0.762887\n",
      "Epoch 14089 - Train Loss: 0.100774, Train Acc: 0.844872 | Val Loss: 0.122417, Val Acc: 0.762887\n",
      "Epoch 14090 - Train Loss: 0.100769, Train Acc: 0.844872 | Val Loss: 0.122414, Val Acc: 0.762887\n",
      "Epoch 14091 - Train Loss: 0.100765, Train Acc: 0.844872 | Val Loss: 0.122411, Val Acc: 0.762887\n",
      "Epoch 14092 - Train Loss: 0.100760, Train Acc: 0.844872 | Val Loss: 0.122407, Val Acc: 0.762887\n",
      "Epoch 14093 - Train Loss: 0.100755, Train Acc: 0.844872 | Val Loss: 0.122404, Val Acc: 0.762887\n",
      "Epoch 14094 - Train Loss: 0.100751, Train Acc: 0.844872 | Val Loss: 0.122401, Val Acc: 0.762887\n",
      "Epoch 14095 - Train Loss: 0.100746, Train Acc: 0.844872 | Val Loss: 0.122397, Val Acc: 0.762887\n",
      "Epoch 14096 - Train Loss: 0.100741, Train Acc: 0.844872 | Val Loss: 0.122394, Val Acc: 0.762887\n",
      "Epoch 14097 - Train Loss: 0.100737, Train Acc: 0.844872 | Val Loss: 0.122391, Val Acc: 0.762887\n",
      "Epoch 14098 - Train Loss: 0.100732, Train Acc: 0.844872 | Val Loss: 0.122388, Val Acc: 0.762887\n",
      "Epoch 14099 - Train Loss: 0.100727, Train Acc: 0.844872 | Val Loss: 0.122384, Val Acc: 0.762887\n",
      "Epoch 14100 - Train Loss: 0.100723, Train Acc: 0.844872 | Val Loss: 0.122381, Val Acc: 0.762887\n",
      "Epoch 14101 - Train Loss: 0.100718, Train Acc: 0.844872 | Val Loss: 0.122378, Val Acc: 0.762887\n",
      "Epoch 14102 - Train Loss: 0.100714, Train Acc: 0.844872 | Val Loss: 0.122375, Val Acc: 0.762887\n",
      "Epoch 14103 - Train Loss: 0.100709, Train Acc: 0.844872 | Val Loss: 0.122371, Val Acc: 0.762887\n",
      "Epoch 14104 - Train Loss: 0.100704, Train Acc: 0.844872 | Val Loss: 0.122368, Val Acc: 0.762887\n",
      "Epoch 14105 - Train Loss: 0.100700, Train Acc: 0.844872 | Val Loss: 0.122365, Val Acc: 0.762887\n",
      "Epoch 14106 - Train Loss: 0.100695, Train Acc: 0.844872 | Val Loss: 0.122362, Val Acc: 0.762887\n",
      "Epoch 14107 - Train Loss: 0.100690, Train Acc: 0.844872 | Val Loss: 0.122358, Val Acc: 0.762887\n",
      "Epoch 14108 - Train Loss: 0.100686, Train Acc: 0.844872 | Val Loss: 0.122355, Val Acc: 0.762887\n",
      "Epoch 14109 - Train Loss: 0.100681, Train Acc: 0.844872 | Val Loss: 0.122352, Val Acc: 0.762887\n",
      "Epoch 14110 - Train Loss: 0.100676, Train Acc: 0.844872 | Val Loss: 0.122348, Val Acc: 0.762887\n",
      "Epoch 14111 - Train Loss: 0.100672, Train Acc: 0.844872 | Val Loss: 0.122345, Val Acc: 0.762887\n",
      "Epoch 14112 - Train Loss: 0.100667, Train Acc: 0.844872 | Val Loss: 0.122342, Val Acc: 0.762887\n",
      "Epoch 14113 - Train Loss: 0.100663, Train Acc: 0.844872 | Val Loss: 0.122339, Val Acc: 0.762887\n",
      "Epoch 14114 - Train Loss: 0.100658, Train Acc: 0.844872 | Val Loss: 0.122335, Val Acc: 0.762887\n",
      "Epoch 14115 - Train Loss: 0.100653, Train Acc: 0.844872 | Val Loss: 0.122332, Val Acc: 0.762887\n",
      "Epoch 14116 - Train Loss: 0.100649, Train Acc: 0.844872 | Val Loss: 0.122329, Val Acc: 0.762887\n",
      "Epoch 14117 - Train Loss: 0.100644, Train Acc: 0.844872 | Val Loss: 0.122326, Val Acc: 0.762887\n",
      "Epoch 14118 - Train Loss: 0.100639, Train Acc: 0.844872 | Val Loss: 0.122322, Val Acc: 0.762887\n",
      "Epoch 14119 - Train Loss: 0.100635, Train Acc: 0.844872 | Val Loss: 0.122319, Val Acc: 0.762887\n",
      "Epoch 14120 - Train Loss: 0.100630, Train Acc: 0.844872 | Val Loss: 0.122316, Val Acc: 0.762887\n",
      "Epoch 14121 - Train Loss: 0.100626, Train Acc: 0.844872 | Val Loss: 0.122313, Val Acc: 0.762887\n",
      "Epoch 14122 - Train Loss: 0.100621, Train Acc: 0.844872 | Val Loss: 0.122309, Val Acc: 0.762887\n",
      "Epoch 14123 - Train Loss: 0.100616, Train Acc: 0.844872 | Val Loss: 0.122306, Val Acc: 0.762887\n",
      "Epoch 14124 - Train Loss: 0.100612, Train Acc: 0.844872 | Val Loss: 0.122303, Val Acc: 0.762887\n",
      "Epoch 14125 - Train Loss: 0.100607, Train Acc: 0.844872 | Val Loss: 0.122300, Val Acc: 0.762887\n",
      "Epoch 14126 - Train Loss: 0.100602, Train Acc: 0.844872 | Val Loss: 0.122296, Val Acc: 0.762887\n",
      "Epoch 14127 - Train Loss: 0.100598, Train Acc: 0.844872 | Val Loss: 0.122293, Val Acc: 0.762887\n",
      "Epoch 14128 - Train Loss: 0.100593, Train Acc: 0.844872 | Val Loss: 0.122290, Val Acc: 0.762887\n",
      "Epoch 14129 - Train Loss: 0.100589, Train Acc: 0.844872 | Val Loss: 0.122287, Val Acc: 0.762887\n",
      "Epoch 14130 - Train Loss: 0.100584, Train Acc: 0.844872 | Val Loss: 0.122283, Val Acc: 0.762887\n",
      "Epoch 14131 - Train Loss: 0.100579, Train Acc: 0.844872 | Val Loss: 0.122280, Val Acc: 0.762887\n",
      "Epoch 14132 - Train Loss: 0.100575, Train Acc: 0.844872 | Val Loss: 0.122277, Val Acc: 0.762887\n",
      "Epoch 14133 - Train Loss: 0.100570, Train Acc: 0.844872 | Val Loss: 0.122274, Val Acc: 0.762887\n",
      "Epoch 14134 - Train Loss: 0.100566, Train Acc: 0.844872 | Val Loss: 0.122270, Val Acc: 0.762887\n",
      "Epoch 14135 - Train Loss: 0.100561, Train Acc: 0.844872 | Val Loss: 0.122267, Val Acc: 0.762887\n",
      "Epoch 14136 - Train Loss: 0.100556, Train Acc: 0.844872 | Val Loss: 0.122264, Val Acc: 0.762887\n",
      "Epoch 14137 - Train Loss: 0.100552, Train Acc: 0.844872 | Val Loss: 0.122261, Val Acc: 0.762887\n",
      "Epoch 14138 - Train Loss: 0.100547, Train Acc: 0.844872 | Val Loss: 0.122257, Val Acc: 0.762887\n",
      "Epoch 14139 - Train Loss: 0.100542, Train Acc: 0.844872 | Val Loss: 0.122254, Val Acc: 0.762887\n",
      "Epoch 14140 - Train Loss: 0.100538, Train Acc: 0.844872 | Val Loss: 0.122251, Val Acc: 0.762887\n",
      "Epoch 14141 - Train Loss: 0.100533, Train Acc: 0.844872 | Val Loss: 0.122248, Val Acc: 0.762887\n",
      "Epoch 14142 - Train Loss: 0.100529, Train Acc: 0.844872 | Val Loss: 0.122245, Val Acc: 0.762887\n",
      "Epoch 14143 - Train Loss: 0.100524, Train Acc: 0.844872 | Val Loss: 0.122241, Val Acc: 0.762887\n",
      "Epoch 14144 - Train Loss: 0.100519, Train Acc: 0.844872 | Val Loss: 0.122238, Val Acc: 0.762887\n",
      "Epoch 14145 - Train Loss: 0.100515, Train Acc: 0.844872 | Val Loss: 0.122235, Val Acc: 0.762887\n",
      "Epoch 14146 - Train Loss: 0.100510, Train Acc: 0.844872 | Val Loss: 0.122232, Val Acc: 0.762887\n",
      "Epoch 14147 - Train Loss: 0.100506, Train Acc: 0.844872 | Val Loss: 0.122228, Val Acc: 0.762887\n",
      "Epoch 14148 - Train Loss: 0.100501, Train Acc: 0.844872 | Val Loss: 0.122225, Val Acc: 0.762887\n",
      "Epoch 14149 - Train Loss: 0.100496, Train Acc: 0.844872 | Val Loss: 0.122222, Val Acc: 0.762887\n",
      "Epoch 14150 - Train Loss: 0.100492, Train Acc: 0.844872 | Val Loss: 0.122219, Val Acc: 0.762887\n",
      "Epoch 14151 - Train Loss: 0.100487, Train Acc: 0.844872 | Val Loss: 0.122215, Val Acc: 0.762887\n",
      "Epoch 14152 - Train Loss: 0.100483, Train Acc: 0.844872 | Val Loss: 0.122212, Val Acc: 0.762887\n",
      "Epoch 14153 - Train Loss: 0.100478, Train Acc: 0.844872 | Val Loss: 0.122209, Val Acc: 0.762887\n",
      "Epoch 14154 - Train Loss: 0.100473, Train Acc: 0.844872 | Val Loss: 0.122206, Val Acc: 0.762887\n",
      "Epoch 14155 - Train Loss: 0.100469, Train Acc: 0.844872 | Val Loss: 0.122202, Val Acc: 0.762887\n",
      "Epoch 14156 - Train Loss: 0.100464, Train Acc: 0.844872 | Val Loss: 0.122199, Val Acc: 0.762887\n",
      "Epoch 14157 - Train Loss: 0.100460, Train Acc: 0.844872 | Val Loss: 0.122196, Val Acc: 0.762887\n",
      "Epoch 14158 - Train Loss: 0.100455, Train Acc: 0.844872 | Val Loss: 0.122193, Val Acc: 0.762887\n",
      "Epoch 14159 - Train Loss: 0.100450, Train Acc: 0.844872 | Val Loss: 0.122190, Val Acc: 0.762887\n",
      "Epoch 14160 - Train Loss: 0.100446, Train Acc: 0.844872 | Val Loss: 0.122186, Val Acc: 0.762887\n",
      "Epoch 14161 - Train Loss: 0.100441, Train Acc: 0.844872 | Val Loss: 0.122183, Val Acc: 0.762887\n",
      "Epoch 14162 - Train Loss: 0.100437, Train Acc: 0.844872 | Val Loss: 0.122180, Val Acc: 0.762887\n",
      "Epoch 14163 - Train Loss: 0.100432, Train Acc: 0.844872 | Val Loss: 0.122177, Val Acc: 0.762887\n",
      "Epoch 14164 - Train Loss: 0.100427, Train Acc: 0.844872 | Val Loss: 0.122173, Val Acc: 0.762887\n",
      "Epoch 14165 - Train Loss: 0.100423, Train Acc: 0.844872 | Val Loss: 0.122170, Val Acc: 0.762887\n",
      "Epoch 14166 - Train Loss: 0.100418, Train Acc: 0.844872 | Val Loss: 0.122167, Val Acc: 0.762887\n",
      "Epoch 14167 - Train Loss: 0.100414, Train Acc: 0.844872 | Val Loss: 0.122164, Val Acc: 0.762887\n",
      "Epoch 14168 - Train Loss: 0.100409, Train Acc: 0.844872 | Val Loss: 0.122161, Val Acc: 0.762887\n",
      "Epoch 14169 - Train Loss: 0.100404, Train Acc: 0.844872 | Val Loss: 0.122157, Val Acc: 0.762887\n",
      "Epoch 14170 - Train Loss: 0.100400, Train Acc: 0.844872 | Val Loss: 0.122154, Val Acc: 0.762887\n",
      "Epoch 14171 - Train Loss: 0.100395, Train Acc: 0.844872 | Val Loss: 0.122151, Val Acc: 0.762887\n",
      "Epoch 14172 - Train Loss: 0.100391, Train Acc: 0.844872 | Val Loss: 0.122148, Val Acc: 0.762887\n",
      "Epoch 14173 - Train Loss: 0.100386, Train Acc: 0.844872 | Val Loss: 0.122144, Val Acc: 0.762887\n",
      "Epoch 14174 - Train Loss: 0.100381, Train Acc: 0.844872 | Val Loss: 0.122141, Val Acc: 0.762887\n",
      "Epoch 14175 - Train Loss: 0.100377, Train Acc: 0.844872 | Val Loss: 0.122138, Val Acc: 0.762887\n",
      "Epoch 14176 - Train Loss: 0.100372, Train Acc: 0.844872 | Val Loss: 0.122135, Val Acc: 0.762887\n",
      "Epoch 14177 - Train Loss: 0.100368, Train Acc: 0.844872 | Val Loss: 0.122132, Val Acc: 0.762887\n",
      "Epoch 14178 - Train Loss: 0.100363, Train Acc: 0.844872 | Val Loss: 0.122128, Val Acc: 0.762887\n",
      "Epoch 14179 - Train Loss: 0.100358, Train Acc: 0.844872 | Val Loss: 0.122125, Val Acc: 0.762887\n",
      "Epoch 14180 - Train Loss: 0.100354, Train Acc: 0.844872 | Val Loss: 0.122122, Val Acc: 0.762887\n",
      "Epoch 14181 - Train Loss: 0.100349, Train Acc: 0.844872 | Val Loss: 0.122119, Val Acc: 0.762887\n",
      "Epoch 14182 - Train Loss: 0.100345, Train Acc: 0.844872 | Val Loss: 0.122115, Val Acc: 0.762887\n",
      "Epoch 14183 - Train Loss: 0.100340, Train Acc: 0.844872 | Val Loss: 0.122112, Val Acc: 0.762887\n",
      "Epoch 14184 - Train Loss: 0.100335, Train Acc: 0.844872 | Val Loss: 0.122109, Val Acc: 0.762887\n",
      "Epoch 14185 - Train Loss: 0.100331, Train Acc: 0.846154 | Val Loss: 0.122106, Val Acc: 0.762887\n",
      "Epoch 14186 - Train Loss: 0.100326, Train Acc: 0.846154 | Val Loss: 0.122103, Val Acc: 0.762887\n",
      "Epoch 14187 - Train Loss: 0.100322, Train Acc: 0.846154 | Val Loss: 0.122099, Val Acc: 0.762887\n",
      "Epoch 14188 - Train Loss: 0.100317, Train Acc: 0.846154 | Val Loss: 0.122096, Val Acc: 0.762887\n",
      "Epoch 14189 - Train Loss: 0.100313, Train Acc: 0.846154 | Val Loss: 0.122093, Val Acc: 0.762887\n",
      "Epoch 14190 - Train Loss: 0.100308, Train Acc: 0.846154 | Val Loss: 0.122090, Val Acc: 0.762887\n",
      "Epoch 14191 - Train Loss: 0.100303, Train Acc: 0.846154 | Val Loss: 0.122087, Val Acc: 0.762887\n",
      "Epoch 14192 - Train Loss: 0.100299, Train Acc: 0.846154 | Val Loss: 0.122083, Val Acc: 0.762887\n",
      "Epoch 14193 - Train Loss: 0.100294, Train Acc: 0.846154 | Val Loss: 0.122080, Val Acc: 0.762887\n",
      "Epoch 14194 - Train Loss: 0.100290, Train Acc: 0.846154 | Val Loss: 0.122077, Val Acc: 0.762887\n",
      "Epoch 14195 - Train Loss: 0.100285, Train Acc: 0.846154 | Val Loss: 0.122074, Val Acc: 0.762887\n",
      "Epoch 14196 - Train Loss: 0.100281, Train Acc: 0.846154 | Val Loss: 0.122071, Val Acc: 0.762887\n",
      "Epoch 14197 - Train Loss: 0.100276, Train Acc: 0.846154 | Val Loss: 0.122067, Val Acc: 0.762887\n",
      "Epoch 14198 - Train Loss: 0.100271, Train Acc: 0.846154 | Val Loss: 0.122064, Val Acc: 0.762887\n",
      "Epoch 14199 - Train Loss: 0.100267, Train Acc: 0.846154 | Val Loss: 0.122061, Val Acc: 0.762887\n",
      "Epoch 14200 - Train Loss: 0.100262, Train Acc: 0.846154 | Val Loss: 0.122058, Val Acc: 0.762887\n",
      "Epoch 14201 - Train Loss: 0.100258, Train Acc: 0.846154 | Val Loss: 0.122055, Val Acc: 0.762887\n",
      "Epoch 14202 - Train Loss: 0.100253, Train Acc: 0.846154 | Val Loss: 0.122051, Val Acc: 0.762887\n",
      "Epoch 14203 - Train Loss: 0.100248, Train Acc: 0.846154 | Val Loss: 0.122048, Val Acc: 0.762887\n",
      "Epoch 14204 - Train Loss: 0.100244, Train Acc: 0.846154 | Val Loss: 0.122045, Val Acc: 0.762887\n",
      "Epoch 14205 - Train Loss: 0.100239, Train Acc: 0.846154 | Val Loss: 0.122042, Val Acc: 0.762887\n",
      "Epoch 14206 - Train Loss: 0.100235, Train Acc: 0.846154 | Val Loss: 0.122039, Val Acc: 0.762887\n",
      "Epoch 14207 - Train Loss: 0.100230, Train Acc: 0.846154 | Val Loss: 0.122035, Val Acc: 0.762887\n",
      "Epoch 14208 - Train Loss: 0.100226, Train Acc: 0.846154 | Val Loss: 0.122032, Val Acc: 0.762887\n",
      "Epoch 14209 - Train Loss: 0.100221, Train Acc: 0.846154 | Val Loss: 0.122029, Val Acc: 0.762887\n",
      "Epoch 14210 - Train Loss: 0.100216, Train Acc: 0.846154 | Val Loss: 0.122026, Val Acc: 0.762887\n",
      "Epoch 14211 - Train Loss: 0.100212, Train Acc: 0.846154 | Val Loss: 0.122023, Val Acc: 0.762887\n",
      "Epoch 14212 - Train Loss: 0.100207, Train Acc: 0.846154 | Val Loss: 0.122019, Val Acc: 0.762887\n",
      "Epoch 14213 - Train Loss: 0.100203, Train Acc: 0.846154 | Val Loss: 0.122016, Val Acc: 0.762887\n",
      "Epoch 14214 - Train Loss: 0.100198, Train Acc: 0.846154 | Val Loss: 0.122013, Val Acc: 0.762887\n",
      "Epoch 14215 - Train Loss: 0.100194, Train Acc: 0.846154 | Val Loss: 0.122010, Val Acc: 0.762887\n",
      "Epoch 14216 - Train Loss: 0.100189, Train Acc: 0.846154 | Val Loss: 0.122007, Val Acc: 0.762887\n",
      "Epoch 14217 - Train Loss: 0.100185, Train Acc: 0.846154 | Val Loss: 0.122003, Val Acc: 0.762887\n",
      "Epoch 14218 - Train Loss: 0.100180, Train Acc: 0.846154 | Val Loss: 0.122000, Val Acc: 0.762887\n",
      "Epoch 14219 - Train Loss: 0.100175, Train Acc: 0.846154 | Val Loss: 0.121997, Val Acc: 0.762887\n",
      "Epoch 14220 - Train Loss: 0.100171, Train Acc: 0.846154 | Val Loss: 0.121994, Val Acc: 0.762887\n",
      "Epoch 14221 - Train Loss: 0.100166, Train Acc: 0.846154 | Val Loss: 0.121991, Val Acc: 0.762887\n",
      "Epoch 14222 - Train Loss: 0.100162, Train Acc: 0.846154 | Val Loss: 0.121987, Val Acc: 0.762887\n",
      "Epoch 14223 - Train Loss: 0.100157, Train Acc: 0.846154 | Val Loss: 0.121984, Val Acc: 0.762887\n",
      "Epoch 14224 - Train Loss: 0.100153, Train Acc: 0.846154 | Val Loss: 0.121981, Val Acc: 0.762887\n",
      "Epoch 14225 - Train Loss: 0.100148, Train Acc: 0.846154 | Val Loss: 0.121978, Val Acc: 0.762887\n",
      "Epoch 14226 - Train Loss: 0.100143, Train Acc: 0.846154 | Val Loss: 0.121975, Val Acc: 0.762887\n",
      "Epoch 14227 - Train Loss: 0.100139, Train Acc: 0.846154 | Val Loss: 0.121971, Val Acc: 0.762887\n",
      "Epoch 14228 - Train Loss: 0.100134, Train Acc: 0.846154 | Val Loss: 0.121968, Val Acc: 0.762887\n",
      "Epoch 14229 - Train Loss: 0.100130, Train Acc: 0.846154 | Val Loss: 0.121965, Val Acc: 0.762887\n",
      "Epoch 14230 - Train Loss: 0.100125, Train Acc: 0.846154 | Val Loss: 0.121962, Val Acc: 0.762887\n",
      "Epoch 14231 - Train Loss: 0.100121, Train Acc: 0.846154 | Val Loss: 0.121959, Val Acc: 0.762887\n",
      "Epoch 14232 - Train Loss: 0.100116, Train Acc: 0.846154 | Val Loss: 0.121956, Val Acc: 0.762887\n",
      "Epoch 14233 - Train Loss: 0.100112, Train Acc: 0.846154 | Val Loss: 0.121952, Val Acc: 0.762887\n",
      "Epoch 14234 - Train Loss: 0.100107, Train Acc: 0.846154 | Val Loss: 0.121949, Val Acc: 0.762887\n",
      "Epoch 14235 - Train Loss: 0.100102, Train Acc: 0.846154 | Val Loss: 0.121946, Val Acc: 0.762887\n",
      "Epoch 14236 - Train Loss: 0.100098, Train Acc: 0.846154 | Val Loss: 0.121943, Val Acc: 0.762887\n",
      "Epoch 14237 - Train Loss: 0.100093, Train Acc: 0.846154 | Val Loss: 0.121940, Val Acc: 0.762887\n",
      "Epoch 14238 - Train Loss: 0.100089, Train Acc: 0.846154 | Val Loss: 0.121936, Val Acc: 0.762887\n",
      "Epoch 14239 - Train Loss: 0.100084, Train Acc: 0.846154 | Val Loss: 0.121933, Val Acc: 0.762887\n",
      "Epoch 14240 - Train Loss: 0.100080, Train Acc: 0.846154 | Val Loss: 0.121930, Val Acc: 0.762887\n",
      "Epoch 14241 - Train Loss: 0.100075, Train Acc: 0.846154 | Val Loss: 0.121927, Val Acc: 0.762887\n",
      "Epoch 14242 - Train Loss: 0.100071, Train Acc: 0.846154 | Val Loss: 0.121924, Val Acc: 0.762887\n",
      "Epoch 14243 - Train Loss: 0.100066, Train Acc: 0.846154 | Val Loss: 0.121921, Val Acc: 0.762887\n",
      "Epoch 14244 - Train Loss: 0.100061, Train Acc: 0.846154 | Val Loss: 0.121917, Val Acc: 0.762887\n",
      "Epoch 14245 - Train Loss: 0.100057, Train Acc: 0.846154 | Val Loss: 0.121914, Val Acc: 0.762887\n",
      "Epoch 14246 - Train Loss: 0.100052, Train Acc: 0.846154 | Val Loss: 0.121911, Val Acc: 0.762887\n",
      "Epoch 14247 - Train Loss: 0.100048, Train Acc: 0.846154 | Val Loss: 0.121908, Val Acc: 0.762887\n",
      "Epoch 14248 - Train Loss: 0.100043, Train Acc: 0.846154 | Val Loss: 0.121905, Val Acc: 0.762887\n",
      "Epoch 14249 - Train Loss: 0.100039, Train Acc: 0.846154 | Val Loss: 0.121902, Val Acc: 0.762887\n",
      "Epoch 14250 - Train Loss: 0.100034, Train Acc: 0.846154 | Val Loss: 0.121898, Val Acc: 0.762887\n",
      "Epoch 14251 - Train Loss: 0.100030, Train Acc: 0.846154 | Val Loss: 0.121895, Val Acc: 0.762887\n",
      "Epoch 14252 - Train Loss: 0.100025, Train Acc: 0.846154 | Val Loss: 0.121892, Val Acc: 0.762887\n",
      "Epoch 14253 - Train Loss: 0.100021, Train Acc: 0.846154 | Val Loss: 0.121889, Val Acc: 0.762887\n",
      "Epoch 14254 - Train Loss: 0.100016, Train Acc: 0.846154 | Val Loss: 0.121886, Val Acc: 0.762887\n",
      "Epoch 14255 - Train Loss: 0.100012, Train Acc: 0.846154 | Val Loss: 0.121883, Val Acc: 0.762887\n",
      "Epoch 14256 - Train Loss: 0.100007, Train Acc: 0.846154 | Val Loss: 0.121879, Val Acc: 0.762887\n",
      "Epoch 14257 - Train Loss: 0.100002, Train Acc: 0.846154 | Val Loss: 0.121876, Val Acc: 0.762887\n",
      "Epoch 14258 - Train Loss: 0.099998, Train Acc: 0.846154 | Val Loss: 0.121873, Val Acc: 0.762887\n",
      "Epoch 14259 - Train Loss: 0.099993, Train Acc: 0.846154 | Val Loss: 0.121870, Val Acc: 0.762887\n",
      "Epoch 14260 - Train Loss: 0.099989, Train Acc: 0.846154 | Val Loss: 0.121867, Val Acc: 0.762887\n",
      "Epoch 14261 - Train Loss: 0.099984, Train Acc: 0.846154 | Val Loss: 0.121864, Val Acc: 0.762887\n",
      "Epoch 14262 - Train Loss: 0.099980, Train Acc: 0.846154 | Val Loss: 0.121860, Val Acc: 0.762887\n",
      "Epoch 14263 - Train Loss: 0.099975, Train Acc: 0.846154 | Val Loss: 0.121857, Val Acc: 0.762887\n",
      "Epoch 14264 - Train Loss: 0.099971, Train Acc: 0.846154 | Val Loss: 0.121854, Val Acc: 0.762887\n",
      "Epoch 14265 - Train Loss: 0.099966, Train Acc: 0.846154 | Val Loss: 0.121851, Val Acc: 0.762887\n",
      "Epoch 14266 - Train Loss: 0.099962, Train Acc: 0.846154 | Val Loss: 0.121848, Val Acc: 0.762887\n",
      "Epoch 14267 - Train Loss: 0.099957, Train Acc: 0.846154 | Val Loss: 0.121845, Val Acc: 0.762887\n",
      "Epoch 14268 - Train Loss: 0.099953, Train Acc: 0.846154 | Val Loss: 0.121841, Val Acc: 0.762887\n",
      "Epoch 14269 - Train Loss: 0.099948, Train Acc: 0.846154 | Val Loss: 0.121838, Val Acc: 0.762887\n",
      "Epoch 14270 - Train Loss: 0.099943, Train Acc: 0.846154 | Val Loss: 0.121835, Val Acc: 0.762887\n",
      "Epoch 14271 - Train Loss: 0.099939, Train Acc: 0.846154 | Val Loss: 0.121832, Val Acc: 0.762887\n",
      "Epoch 14272 - Train Loss: 0.099934, Train Acc: 0.846154 | Val Loss: 0.121829, Val Acc: 0.762887\n",
      "Epoch 14273 - Train Loss: 0.099930, Train Acc: 0.846154 | Val Loss: 0.121826, Val Acc: 0.762887\n",
      "Epoch 14274 - Train Loss: 0.099925, Train Acc: 0.846154 | Val Loss: 0.121823, Val Acc: 0.762887\n",
      "Epoch 14275 - Train Loss: 0.099921, Train Acc: 0.846154 | Val Loss: 0.121819, Val Acc: 0.762887\n",
      "Epoch 14276 - Train Loss: 0.099916, Train Acc: 0.846154 | Val Loss: 0.121816, Val Acc: 0.762887\n",
      "Epoch 14277 - Train Loss: 0.099912, Train Acc: 0.846154 | Val Loss: 0.121813, Val Acc: 0.762887\n",
      "Epoch 14278 - Train Loss: 0.099907, Train Acc: 0.846154 | Val Loss: 0.121810, Val Acc: 0.762887\n",
      "Epoch 14279 - Train Loss: 0.099903, Train Acc: 0.846154 | Val Loss: 0.121807, Val Acc: 0.762887\n",
      "Epoch 14280 - Train Loss: 0.099898, Train Acc: 0.847436 | Val Loss: 0.121804, Val Acc: 0.762887\n",
      "Epoch 14281 - Train Loss: 0.099894, Train Acc: 0.847436 | Val Loss: 0.121800, Val Acc: 0.762887\n",
      "Epoch 14282 - Train Loss: 0.099889, Train Acc: 0.847436 | Val Loss: 0.121797, Val Acc: 0.762887\n",
      "Epoch 14283 - Train Loss: 0.099885, Train Acc: 0.847436 | Val Loss: 0.121794, Val Acc: 0.762887\n",
      "Epoch 14284 - Train Loss: 0.099880, Train Acc: 0.847436 | Val Loss: 0.121791, Val Acc: 0.762887\n",
      "Epoch 14285 - Train Loss: 0.099876, Train Acc: 0.847436 | Val Loss: 0.121788, Val Acc: 0.762887\n",
      "Epoch 14286 - Train Loss: 0.099871, Train Acc: 0.847436 | Val Loss: 0.121785, Val Acc: 0.762887\n",
      "Epoch 14287 - Train Loss: 0.099866, Train Acc: 0.847436 | Val Loss: 0.121782, Val Acc: 0.762887\n",
      "Epoch 14288 - Train Loss: 0.099862, Train Acc: 0.847436 | Val Loss: 0.121778, Val Acc: 0.762887\n",
      "Epoch 14289 - Train Loss: 0.099857, Train Acc: 0.847436 | Val Loss: 0.121775, Val Acc: 0.762887\n",
      "Epoch 14290 - Train Loss: 0.099853, Train Acc: 0.847436 | Val Loss: 0.121772, Val Acc: 0.762887\n",
      "Epoch 14291 - Train Loss: 0.099848, Train Acc: 0.847436 | Val Loss: 0.121769, Val Acc: 0.762887\n",
      "Epoch 14292 - Train Loss: 0.099844, Train Acc: 0.847436 | Val Loss: 0.121766, Val Acc: 0.762887\n",
      "Epoch 14293 - Train Loss: 0.099839, Train Acc: 0.847436 | Val Loss: 0.121763, Val Acc: 0.762887\n",
      "Epoch 14294 - Train Loss: 0.099835, Train Acc: 0.847436 | Val Loss: 0.121760, Val Acc: 0.762887\n",
      "Epoch 14295 - Train Loss: 0.099830, Train Acc: 0.847436 | Val Loss: 0.121756, Val Acc: 0.762887\n",
      "Epoch 14296 - Train Loss: 0.099826, Train Acc: 0.847436 | Val Loss: 0.121753, Val Acc: 0.762887\n",
      "Epoch 14297 - Train Loss: 0.099821, Train Acc: 0.847436 | Val Loss: 0.121750, Val Acc: 0.762887\n",
      "Epoch 14298 - Train Loss: 0.099817, Train Acc: 0.847436 | Val Loss: 0.121747, Val Acc: 0.762887\n",
      "Epoch 14299 - Train Loss: 0.099812, Train Acc: 0.847436 | Val Loss: 0.121744, Val Acc: 0.762887\n",
      "Epoch 14300 - Train Loss: 0.099808, Train Acc: 0.847436 | Val Loss: 0.121741, Val Acc: 0.762887\n",
      "Epoch 14301 - Train Loss: 0.099803, Train Acc: 0.847436 | Val Loss: 0.121738, Val Acc: 0.762887\n",
      "Epoch 14302 - Train Loss: 0.099799, Train Acc: 0.847436 | Val Loss: 0.121734, Val Acc: 0.762887\n",
      "Epoch 14303 - Train Loss: 0.099794, Train Acc: 0.847436 | Val Loss: 0.121731, Val Acc: 0.762887\n",
      "Epoch 14304 - Train Loss: 0.099790, Train Acc: 0.847436 | Val Loss: 0.121728, Val Acc: 0.762887\n",
      "Epoch 14305 - Train Loss: 0.099785, Train Acc: 0.847436 | Val Loss: 0.121725, Val Acc: 0.762887\n",
      "Epoch 14306 - Train Loss: 0.099781, Train Acc: 0.847436 | Val Loss: 0.121722, Val Acc: 0.762887\n",
      "Epoch 14307 - Train Loss: 0.099776, Train Acc: 0.847436 | Val Loss: 0.121719, Val Acc: 0.762887\n",
      "Epoch 14308 - Train Loss: 0.099772, Train Acc: 0.847436 | Val Loss: 0.121716, Val Acc: 0.762887\n",
      "Epoch 14309 - Train Loss: 0.099767, Train Acc: 0.847436 | Val Loss: 0.121713, Val Acc: 0.762887\n",
      "Epoch 14310 - Train Loss: 0.099763, Train Acc: 0.847436 | Val Loss: 0.121709, Val Acc: 0.762887\n",
      "Epoch 14311 - Train Loss: 0.099758, Train Acc: 0.847436 | Val Loss: 0.121706, Val Acc: 0.762887\n",
      "Epoch 14312 - Train Loss: 0.099754, Train Acc: 0.847436 | Val Loss: 0.121703, Val Acc: 0.762887\n",
      "Epoch 14313 - Train Loss: 0.099749, Train Acc: 0.847436 | Val Loss: 0.121700, Val Acc: 0.762887\n",
      "Epoch 14314 - Train Loss: 0.099745, Train Acc: 0.847436 | Val Loss: 0.121697, Val Acc: 0.762887\n",
      "Epoch 14315 - Train Loss: 0.099740, Train Acc: 0.847436 | Val Loss: 0.121694, Val Acc: 0.762887\n",
      "Epoch 14316 - Train Loss: 0.099736, Train Acc: 0.847436 | Val Loss: 0.121691, Val Acc: 0.762887\n",
      "Epoch 14317 - Train Loss: 0.099731, Train Acc: 0.847436 | Val Loss: 0.121688, Val Acc: 0.762887\n",
      "Epoch 14318 - Train Loss: 0.099727, Train Acc: 0.847436 | Val Loss: 0.121684, Val Acc: 0.762887\n",
      "Epoch 14319 - Train Loss: 0.099722, Train Acc: 0.847436 | Val Loss: 0.121681, Val Acc: 0.762887\n",
      "Epoch 14320 - Train Loss: 0.099718, Train Acc: 0.847436 | Val Loss: 0.121678, Val Acc: 0.762887\n",
      "Epoch 14321 - Train Loss: 0.099713, Train Acc: 0.847436 | Val Loss: 0.121675, Val Acc: 0.762887\n",
      "Epoch 14322 - Train Loss: 0.099709, Train Acc: 0.847436 | Val Loss: 0.121672, Val Acc: 0.762887\n",
      "Epoch 14323 - Train Loss: 0.099704, Train Acc: 0.847436 | Val Loss: 0.121669, Val Acc: 0.762887\n",
      "Epoch 14324 - Train Loss: 0.099700, Train Acc: 0.847436 | Val Loss: 0.121666, Val Acc: 0.762887\n",
      "Epoch 14325 - Train Loss: 0.099695, Train Acc: 0.847436 | Val Loss: 0.121663, Val Acc: 0.762887\n",
      "Epoch 14326 - Train Loss: 0.099691, Train Acc: 0.847436 | Val Loss: 0.121660, Val Acc: 0.762887\n",
      "Epoch 14327 - Train Loss: 0.099686, Train Acc: 0.847436 | Val Loss: 0.121656, Val Acc: 0.762887\n",
      "Epoch 14328 - Train Loss: 0.099682, Train Acc: 0.847436 | Val Loss: 0.121653, Val Acc: 0.762887\n",
      "Epoch 14329 - Train Loss: 0.099677, Train Acc: 0.847436 | Val Loss: 0.121650, Val Acc: 0.762887\n",
      "Epoch 14330 - Train Loss: 0.099673, Train Acc: 0.847436 | Val Loss: 0.121647, Val Acc: 0.762887\n",
      "Epoch 14331 - Train Loss: 0.099668, Train Acc: 0.847436 | Val Loss: 0.121644, Val Acc: 0.762887\n",
      "Epoch 14332 - Train Loss: 0.099664, Train Acc: 0.847436 | Val Loss: 0.121641, Val Acc: 0.762887\n",
      "Epoch 14333 - Train Loss: 0.099659, Train Acc: 0.847436 | Val Loss: 0.121638, Val Acc: 0.762887\n",
      "Epoch 14334 - Train Loss: 0.099655, Train Acc: 0.847436 | Val Loss: 0.121635, Val Acc: 0.762887\n",
      "Epoch 14335 - Train Loss: 0.099650, Train Acc: 0.847436 | Val Loss: 0.121631, Val Acc: 0.762887\n",
      "Epoch 14336 - Train Loss: 0.099646, Train Acc: 0.847436 | Val Loss: 0.121628, Val Acc: 0.762887\n",
      "Epoch 14337 - Train Loss: 0.099641, Train Acc: 0.847436 | Val Loss: 0.121625, Val Acc: 0.762887\n",
      "Epoch 14338 - Train Loss: 0.099637, Train Acc: 0.847436 | Val Loss: 0.121622, Val Acc: 0.762887\n",
      "Epoch 14339 - Train Loss: 0.099632, Train Acc: 0.847436 | Val Loss: 0.121619, Val Acc: 0.762887\n",
      "Epoch 14340 - Train Loss: 0.099628, Train Acc: 0.847436 | Val Loss: 0.121616, Val Acc: 0.762887\n",
      "Epoch 14341 - Train Loss: 0.099623, Train Acc: 0.847436 | Val Loss: 0.121613, Val Acc: 0.762887\n",
      "Epoch 14342 - Train Loss: 0.099619, Train Acc: 0.847436 | Val Loss: 0.121610, Val Acc: 0.762887\n",
      "Epoch 14343 - Train Loss: 0.099614, Train Acc: 0.847436 | Val Loss: 0.121607, Val Acc: 0.762887\n",
      "Epoch 14344 - Train Loss: 0.099610, Train Acc: 0.847436 | Val Loss: 0.121603, Val Acc: 0.762887\n",
      "Epoch 14345 - Train Loss: 0.099605, Train Acc: 0.847436 | Val Loss: 0.121600, Val Acc: 0.762887\n",
      "Epoch 14346 - Train Loss: 0.099601, Train Acc: 0.847436 | Val Loss: 0.121597, Val Acc: 0.762887\n",
      "Epoch 14347 - Train Loss: 0.099596, Train Acc: 0.847436 | Val Loss: 0.121594, Val Acc: 0.762887\n",
      "Epoch 14348 - Train Loss: 0.099592, Train Acc: 0.847436 | Val Loss: 0.121591, Val Acc: 0.762887\n",
      "Epoch 14349 - Train Loss: 0.099587, Train Acc: 0.847436 | Val Loss: 0.121588, Val Acc: 0.762887\n",
      "Epoch 14350 - Train Loss: 0.099583, Train Acc: 0.847436 | Val Loss: 0.121585, Val Acc: 0.762887\n",
      "Epoch 14351 - Train Loss: 0.099578, Train Acc: 0.847436 | Val Loss: 0.121582, Val Acc: 0.762887\n",
      "Epoch 14352 - Train Loss: 0.099574, Train Acc: 0.847436 | Val Loss: 0.121579, Val Acc: 0.762887\n",
      "Epoch 14353 - Train Loss: 0.099569, Train Acc: 0.847436 | Val Loss: 0.121576, Val Acc: 0.762887\n",
      "Epoch 14354 - Train Loss: 0.099565, Train Acc: 0.847436 | Val Loss: 0.121572, Val Acc: 0.762887\n",
      "Epoch 14355 - Train Loss: 0.099560, Train Acc: 0.847436 | Val Loss: 0.121569, Val Acc: 0.762887\n",
      "Epoch 14356 - Train Loss: 0.099556, Train Acc: 0.847436 | Val Loss: 0.121566, Val Acc: 0.762887\n",
      "Epoch 14357 - Train Loss: 0.099551, Train Acc: 0.847436 | Val Loss: 0.121563, Val Acc: 0.762887\n",
      "Epoch 14358 - Train Loss: 0.099547, Train Acc: 0.847436 | Val Loss: 0.121560, Val Acc: 0.762887\n",
      "Epoch 14359 - Train Loss: 0.099542, Train Acc: 0.847436 | Val Loss: 0.121557, Val Acc: 0.762887\n",
      "Epoch 14360 - Train Loss: 0.099538, Train Acc: 0.847436 | Val Loss: 0.121554, Val Acc: 0.762887\n",
      "Epoch 14361 - Train Loss: 0.099534, Train Acc: 0.847436 | Val Loss: 0.121551, Val Acc: 0.762887\n",
      "Epoch 14362 - Train Loss: 0.099529, Train Acc: 0.847436 | Val Loss: 0.121548, Val Acc: 0.762887\n",
      "Epoch 14363 - Train Loss: 0.099525, Train Acc: 0.847436 | Val Loss: 0.121545, Val Acc: 0.762887\n",
      "Epoch 14364 - Train Loss: 0.099520, Train Acc: 0.847436 | Val Loss: 0.121542, Val Acc: 0.762887\n",
      "Epoch 14365 - Train Loss: 0.099516, Train Acc: 0.847436 | Val Loss: 0.121538, Val Acc: 0.762887\n",
      "Epoch 14366 - Train Loss: 0.099511, Train Acc: 0.847436 | Val Loss: 0.121535, Val Acc: 0.762887\n",
      "Epoch 14367 - Train Loss: 0.099507, Train Acc: 0.847436 | Val Loss: 0.121532, Val Acc: 0.762887\n",
      "Epoch 14368 - Train Loss: 0.099502, Train Acc: 0.847436 | Val Loss: 0.121529, Val Acc: 0.762887\n",
      "Epoch 14369 - Train Loss: 0.099498, Train Acc: 0.847436 | Val Loss: 0.121526, Val Acc: 0.762887\n",
      "Epoch 14370 - Train Loss: 0.099493, Train Acc: 0.847436 | Val Loss: 0.121523, Val Acc: 0.762887\n",
      "Epoch 14371 - Train Loss: 0.099489, Train Acc: 0.847436 | Val Loss: 0.121520, Val Acc: 0.762887\n",
      "Epoch 14372 - Train Loss: 0.099484, Train Acc: 0.847436 | Val Loss: 0.121517, Val Acc: 0.762887\n",
      "Epoch 14373 - Train Loss: 0.099480, Train Acc: 0.847436 | Val Loss: 0.121514, Val Acc: 0.762887\n",
      "Epoch 14374 - Train Loss: 0.099475, Train Acc: 0.847436 | Val Loss: 0.121511, Val Acc: 0.762887\n",
      "Epoch 14375 - Train Loss: 0.099471, Train Acc: 0.847436 | Val Loss: 0.121508, Val Acc: 0.762887\n",
      "Epoch 14376 - Train Loss: 0.099466, Train Acc: 0.847436 | Val Loss: 0.121504, Val Acc: 0.762887\n",
      "Epoch 14377 - Train Loss: 0.099462, Train Acc: 0.847436 | Val Loss: 0.121501, Val Acc: 0.762887\n",
      "Epoch 14378 - Train Loss: 0.099457, Train Acc: 0.847436 | Val Loss: 0.121498, Val Acc: 0.762887\n",
      "Epoch 14379 - Train Loss: 0.099453, Train Acc: 0.847436 | Val Loss: 0.121495, Val Acc: 0.762887\n",
      "Epoch 14380 - Train Loss: 0.099449, Train Acc: 0.847436 | Val Loss: 0.121492, Val Acc: 0.762887\n",
      "Epoch 14381 - Train Loss: 0.099444, Train Acc: 0.847436 | Val Loss: 0.121489, Val Acc: 0.762887\n",
      "Epoch 14382 - Train Loss: 0.099440, Train Acc: 0.847436 | Val Loss: 0.121486, Val Acc: 0.762887\n",
      "Epoch 14383 - Train Loss: 0.099435, Train Acc: 0.848718 | Val Loss: 0.121483, Val Acc: 0.762887\n",
      "Epoch 14384 - Train Loss: 0.099431, Train Acc: 0.848718 | Val Loss: 0.121480, Val Acc: 0.762887\n",
      "Epoch 14385 - Train Loss: 0.099426, Train Acc: 0.848718 | Val Loss: 0.121477, Val Acc: 0.762887\n",
      "Epoch 14386 - Train Loss: 0.099422, Train Acc: 0.848718 | Val Loss: 0.121474, Val Acc: 0.762887\n",
      "Epoch 14387 - Train Loss: 0.099417, Train Acc: 0.848718 | Val Loss: 0.121471, Val Acc: 0.762887\n",
      "Epoch 14388 - Train Loss: 0.099413, Train Acc: 0.848718 | Val Loss: 0.121467, Val Acc: 0.762887\n",
      "Epoch 14389 - Train Loss: 0.099408, Train Acc: 0.848718 | Val Loss: 0.121464, Val Acc: 0.762887\n",
      "Epoch 14390 - Train Loss: 0.099404, Train Acc: 0.848718 | Val Loss: 0.121461, Val Acc: 0.762887\n",
      "Epoch 14391 - Train Loss: 0.099399, Train Acc: 0.848718 | Val Loss: 0.121458, Val Acc: 0.762887\n",
      "Epoch 14392 - Train Loss: 0.099395, Train Acc: 0.848718 | Val Loss: 0.121455, Val Acc: 0.762887\n",
      "Epoch 14393 - Train Loss: 0.099391, Train Acc: 0.848718 | Val Loss: 0.121452, Val Acc: 0.762887\n",
      "Epoch 14394 - Train Loss: 0.099386, Train Acc: 0.848718 | Val Loss: 0.121449, Val Acc: 0.762887\n",
      "Epoch 14395 - Train Loss: 0.099382, Train Acc: 0.848718 | Val Loss: 0.121446, Val Acc: 0.762887\n",
      "Epoch 14396 - Train Loss: 0.099377, Train Acc: 0.848718 | Val Loss: 0.121443, Val Acc: 0.762887\n",
      "Epoch 14397 - Train Loss: 0.099373, Train Acc: 0.848718 | Val Loss: 0.121440, Val Acc: 0.762887\n",
      "Epoch 14398 - Train Loss: 0.099368, Train Acc: 0.848718 | Val Loss: 0.121437, Val Acc: 0.762887\n",
      "Epoch 14399 - Train Loss: 0.099364, Train Acc: 0.848718 | Val Loss: 0.121434, Val Acc: 0.762887\n",
      "Epoch 14400 - Train Loss: 0.099359, Train Acc: 0.848718 | Val Loss: 0.121431, Val Acc: 0.762887\n",
      "Epoch 14401 - Train Loss: 0.099355, Train Acc: 0.848718 | Val Loss: 0.121427, Val Acc: 0.762887\n",
      "Epoch 14402 - Train Loss: 0.099350, Train Acc: 0.848718 | Val Loss: 0.121424, Val Acc: 0.762887\n",
      "Epoch 14403 - Train Loss: 0.099346, Train Acc: 0.848718 | Val Loss: 0.121421, Val Acc: 0.762887\n",
      "Epoch 14404 - Train Loss: 0.099342, Train Acc: 0.848718 | Val Loss: 0.121418, Val Acc: 0.762887\n",
      "Epoch 14405 - Train Loss: 0.099337, Train Acc: 0.848718 | Val Loss: 0.121415, Val Acc: 0.762887\n",
      "Epoch 14406 - Train Loss: 0.099333, Train Acc: 0.848718 | Val Loss: 0.121412, Val Acc: 0.762887\n",
      "Epoch 14407 - Train Loss: 0.099328, Train Acc: 0.848718 | Val Loss: 0.121409, Val Acc: 0.762887\n",
      "Epoch 14408 - Train Loss: 0.099324, Train Acc: 0.848718 | Val Loss: 0.121406, Val Acc: 0.762887\n",
      "Epoch 14409 - Train Loss: 0.099319, Train Acc: 0.848718 | Val Loss: 0.121403, Val Acc: 0.762887\n",
      "Epoch 14410 - Train Loss: 0.099315, Train Acc: 0.848718 | Val Loss: 0.121400, Val Acc: 0.762887\n",
      "Epoch 14411 - Train Loss: 0.099310, Train Acc: 0.848718 | Val Loss: 0.121397, Val Acc: 0.762887\n",
      "Epoch 14412 - Train Loss: 0.099306, Train Acc: 0.848718 | Val Loss: 0.121394, Val Acc: 0.762887\n",
      "Epoch 14413 - Train Loss: 0.099302, Train Acc: 0.848718 | Val Loss: 0.121391, Val Acc: 0.762887\n",
      "Epoch 14414 - Train Loss: 0.099297, Train Acc: 0.848718 | Val Loss: 0.121388, Val Acc: 0.762887\n",
      "Epoch 14415 - Train Loss: 0.099293, Train Acc: 0.848718 | Val Loss: 0.121385, Val Acc: 0.762887\n",
      "Epoch 14416 - Train Loss: 0.099288, Train Acc: 0.848718 | Val Loss: 0.121382, Val Acc: 0.762887\n",
      "Epoch 14417 - Train Loss: 0.099284, Train Acc: 0.848718 | Val Loss: 0.121378, Val Acc: 0.762887\n",
      "Epoch 14418 - Train Loss: 0.099279, Train Acc: 0.848718 | Val Loss: 0.121375, Val Acc: 0.762887\n",
      "Epoch 14419 - Train Loss: 0.099275, Train Acc: 0.848718 | Val Loss: 0.121372, Val Acc: 0.762887\n",
      "Epoch 14420 - Train Loss: 0.099270, Train Acc: 0.848718 | Val Loss: 0.121369, Val Acc: 0.762887\n",
      "Epoch 14421 - Train Loss: 0.099266, Train Acc: 0.848718 | Val Loss: 0.121366, Val Acc: 0.762887\n",
      "Epoch 14422 - Train Loss: 0.099262, Train Acc: 0.848718 | Val Loss: 0.121363, Val Acc: 0.762887\n",
      "Epoch 14423 - Train Loss: 0.099257, Train Acc: 0.848718 | Val Loss: 0.121360, Val Acc: 0.762887\n",
      "Epoch 14424 - Train Loss: 0.099253, Train Acc: 0.848718 | Val Loss: 0.121357, Val Acc: 0.762887\n",
      "Epoch 14425 - Train Loss: 0.099248, Train Acc: 0.848718 | Val Loss: 0.121354, Val Acc: 0.762887\n",
      "Epoch 14426 - Train Loss: 0.099244, Train Acc: 0.848718 | Val Loss: 0.121351, Val Acc: 0.762887\n",
      "Epoch 14427 - Train Loss: 0.099239, Train Acc: 0.848718 | Val Loss: 0.121348, Val Acc: 0.762887\n",
      "Epoch 14428 - Train Loss: 0.099235, Train Acc: 0.848718 | Val Loss: 0.121345, Val Acc: 0.762887\n",
      "Epoch 14429 - Train Loss: 0.099230, Train Acc: 0.848718 | Val Loss: 0.121342, Val Acc: 0.762887\n",
      "Epoch 14430 - Train Loss: 0.099226, Train Acc: 0.848718 | Val Loss: 0.121339, Val Acc: 0.762887\n",
      "Epoch 14431 - Train Loss: 0.099222, Train Acc: 0.848718 | Val Loss: 0.121336, Val Acc: 0.762887\n",
      "Epoch 14432 - Train Loss: 0.099217, Train Acc: 0.848718 | Val Loss: 0.121333, Val Acc: 0.762887\n",
      "Epoch 14433 - Train Loss: 0.099213, Train Acc: 0.848718 | Val Loss: 0.121330, Val Acc: 0.762887\n",
      "Epoch 14434 - Train Loss: 0.099208, Train Acc: 0.848718 | Val Loss: 0.121327, Val Acc: 0.762887\n",
      "Epoch 14435 - Train Loss: 0.099204, Train Acc: 0.848718 | Val Loss: 0.121323, Val Acc: 0.762887\n",
      "Epoch 14436 - Train Loss: 0.099199, Train Acc: 0.848718 | Val Loss: 0.121320, Val Acc: 0.762887\n",
      "Epoch 14437 - Train Loss: 0.099195, Train Acc: 0.848718 | Val Loss: 0.121317, Val Acc: 0.762887\n",
      "Epoch 14438 - Train Loss: 0.099191, Train Acc: 0.848718 | Val Loss: 0.121314, Val Acc: 0.762887\n",
      "Epoch 14439 - Train Loss: 0.099186, Train Acc: 0.848718 | Val Loss: 0.121311, Val Acc: 0.762887\n",
      "Epoch 14440 - Train Loss: 0.099182, Train Acc: 0.848718 | Val Loss: 0.121308, Val Acc: 0.762887\n",
      "Epoch 14441 - Train Loss: 0.099177, Train Acc: 0.848718 | Val Loss: 0.121305, Val Acc: 0.762887\n",
      "Epoch 14442 - Train Loss: 0.099173, Train Acc: 0.848718 | Val Loss: 0.121302, Val Acc: 0.762887\n",
      "Epoch 14443 - Train Loss: 0.099168, Train Acc: 0.848718 | Val Loss: 0.121299, Val Acc: 0.762887\n",
      "Epoch 14444 - Train Loss: 0.099164, Train Acc: 0.848718 | Val Loss: 0.121296, Val Acc: 0.762887\n",
      "Epoch 14445 - Train Loss: 0.099160, Train Acc: 0.848718 | Val Loss: 0.121293, Val Acc: 0.762887\n",
      "Epoch 14446 - Train Loss: 0.099155, Train Acc: 0.848718 | Val Loss: 0.121290, Val Acc: 0.762887\n",
      "Epoch 14447 - Train Loss: 0.099151, Train Acc: 0.848718 | Val Loss: 0.121287, Val Acc: 0.762887\n",
      "Epoch 14448 - Train Loss: 0.099146, Train Acc: 0.848718 | Val Loss: 0.121284, Val Acc: 0.762887\n",
      "Epoch 14449 - Train Loss: 0.099142, Train Acc: 0.848718 | Val Loss: 0.121281, Val Acc: 0.762887\n",
      "Epoch 14450 - Train Loss: 0.099137, Train Acc: 0.850000 | Val Loss: 0.121278, Val Acc: 0.762887\n",
      "Epoch 14451 - Train Loss: 0.099133, Train Acc: 0.850000 | Val Loss: 0.121275, Val Acc: 0.762887\n",
      "Epoch 14452 - Train Loss: 0.099129, Train Acc: 0.850000 | Val Loss: 0.121272, Val Acc: 0.762887\n",
      "Epoch 14453 - Train Loss: 0.099124, Train Acc: 0.850000 | Val Loss: 0.121269, Val Acc: 0.762887\n",
      "Epoch 14454 - Train Loss: 0.099120, Train Acc: 0.850000 | Val Loss: 0.121266, Val Acc: 0.762887\n",
      "Epoch 14455 - Train Loss: 0.099115, Train Acc: 0.850000 | Val Loss: 0.121263, Val Acc: 0.762887\n",
      "Epoch 14456 - Train Loss: 0.099111, Train Acc: 0.850000 | Val Loss: 0.121260, Val Acc: 0.762887\n",
      "Epoch 14457 - Train Loss: 0.099106, Train Acc: 0.850000 | Val Loss: 0.121257, Val Acc: 0.762887\n",
      "Epoch 14458 - Train Loss: 0.099102, Train Acc: 0.850000 | Val Loss: 0.121253, Val Acc: 0.762887\n",
      "Epoch 14459 - Train Loss: 0.099098, Train Acc: 0.850000 | Val Loss: 0.121250, Val Acc: 0.762887\n",
      "Epoch 14460 - Train Loss: 0.099093, Train Acc: 0.850000 | Val Loss: 0.121247, Val Acc: 0.762887\n",
      "Epoch 14461 - Train Loss: 0.099089, Train Acc: 0.850000 | Val Loss: 0.121244, Val Acc: 0.762887\n",
      "Epoch 14462 - Train Loss: 0.099084, Train Acc: 0.850000 | Val Loss: 0.121241, Val Acc: 0.762887\n",
      "Epoch 14463 - Train Loss: 0.099080, Train Acc: 0.850000 | Val Loss: 0.121238, Val Acc: 0.762887\n",
      "Epoch 14464 - Train Loss: 0.099076, Train Acc: 0.850000 | Val Loss: 0.121235, Val Acc: 0.762887\n",
      "Epoch 14465 - Train Loss: 0.099071, Train Acc: 0.850000 | Val Loss: 0.121232, Val Acc: 0.762887\n",
      "Epoch 14466 - Train Loss: 0.099067, Train Acc: 0.850000 | Val Loss: 0.121229, Val Acc: 0.762887\n",
      "Epoch 14467 - Train Loss: 0.099062, Train Acc: 0.850000 | Val Loss: 0.121226, Val Acc: 0.762887\n",
      "Epoch 14468 - Train Loss: 0.099058, Train Acc: 0.850000 | Val Loss: 0.121223, Val Acc: 0.762887\n",
      "Epoch 14469 - Train Loss: 0.099053, Train Acc: 0.850000 | Val Loss: 0.121220, Val Acc: 0.762887\n",
      "Epoch 14470 - Train Loss: 0.099049, Train Acc: 0.850000 | Val Loss: 0.121217, Val Acc: 0.762887\n",
      "Epoch 14471 - Train Loss: 0.099045, Train Acc: 0.850000 | Val Loss: 0.121214, Val Acc: 0.762887\n",
      "Epoch 14472 - Train Loss: 0.099040, Train Acc: 0.850000 | Val Loss: 0.121211, Val Acc: 0.762887\n",
      "Epoch 14473 - Train Loss: 0.099036, Train Acc: 0.850000 | Val Loss: 0.121208, Val Acc: 0.762887\n",
      "Epoch 14474 - Train Loss: 0.099031, Train Acc: 0.850000 | Val Loss: 0.121205, Val Acc: 0.762887\n",
      "Epoch 14475 - Train Loss: 0.099027, Train Acc: 0.850000 | Val Loss: 0.121202, Val Acc: 0.762887\n",
      "Epoch 14476 - Train Loss: 0.099023, Train Acc: 0.850000 | Val Loss: 0.121199, Val Acc: 0.762887\n",
      "Epoch 14477 - Train Loss: 0.099018, Train Acc: 0.850000 | Val Loss: 0.121196, Val Acc: 0.762887\n",
      "Epoch 14478 - Train Loss: 0.099014, Train Acc: 0.850000 | Val Loss: 0.121193, Val Acc: 0.762887\n",
      "Epoch 14479 - Train Loss: 0.099009, Train Acc: 0.850000 | Val Loss: 0.121190, Val Acc: 0.762887\n",
      "Epoch 14480 - Train Loss: 0.099005, Train Acc: 0.850000 | Val Loss: 0.121187, Val Acc: 0.762887\n",
      "Epoch 14481 - Train Loss: 0.099001, Train Acc: 0.850000 | Val Loss: 0.121184, Val Acc: 0.762887\n",
      "Epoch 14482 - Train Loss: 0.098996, Train Acc: 0.850000 | Val Loss: 0.121181, Val Acc: 0.762887\n",
      "Epoch 14483 - Train Loss: 0.098992, Train Acc: 0.850000 | Val Loss: 0.121178, Val Acc: 0.762887\n",
      "Epoch 14484 - Train Loss: 0.098987, Train Acc: 0.850000 | Val Loss: 0.121175, Val Acc: 0.762887\n",
      "Epoch 14485 - Train Loss: 0.098983, Train Acc: 0.850000 | Val Loss: 0.121172, Val Acc: 0.762887\n",
      "Epoch 14486 - Train Loss: 0.098978, Train Acc: 0.850000 | Val Loss: 0.121169, Val Acc: 0.762887\n",
      "Epoch 14487 - Train Loss: 0.098974, Train Acc: 0.850000 | Val Loss: 0.121166, Val Acc: 0.762887\n",
      "Epoch 14488 - Train Loss: 0.098970, Train Acc: 0.850000 | Val Loss: 0.121163, Val Acc: 0.762887\n",
      "Epoch 14489 - Train Loss: 0.098965, Train Acc: 0.850000 | Val Loss: 0.121160, Val Acc: 0.762887\n",
      "Epoch 14490 - Train Loss: 0.098961, Train Acc: 0.850000 | Val Loss: 0.121157, Val Acc: 0.762887\n",
      "Epoch 14491 - Train Loss: 0.098956, Train Acc: 0.850000 | Val Loss: 0.121154, Val Acc: 0.762887\n",
      "Epoch 14492 - Train Loss: 0.098952, Train Acc: 0.850000 | Val Loss: 0.121151, Val Acc: 0.762887\n",
      "Epoch 14493 - Train Loss: 0.098948, Train Acc: 0.850000 | Val Loss: 0.121148, Val Acc: 0.762887\n",
      "Epoch 14494 - Train Loss: 0.098943, Train Acc: 0.850000 | Val Loss: 0.121145, Val Acc: 0.762887\n",
      "Epoch 14495 - Train Loss: 0.098939, Train Acc: 0.850000 | Val Loss: 0.121142, Val Acc: 0.762887\n",
      "Epoch 14496 - Train Loss: 0.098934, Train Acc: 0.850000 | Val Loss: 0.121139, Val Acc: 0.762887\n",
      "Epoch 14497 - Train Loss: 0.098930, Train Acc: 0.850000 | Val Loss: 0.121136, Val Acc: 0.762887\n",
      "Epoch 14498 - Train Loss: 0.098926, Train Acc: 0.850000 | Val Loss: 0.121133, Val Acc: 0.762887\n",
      "Epoch 14499 - Train Loss: 0.098921, Train Acc: 0.850000 | Val Loss: 0.121130, Val Acc: 0.762887\n",
      "Epoch 14500 - Train Loss: 0.098917, Train Acc: 0.850000 | Val Loss: 0.121127, Val Acc: 0.762887\n",
      "Epoch 14501 - Train Loss: 0.098913, Train Acc: 0.850000 | Val Loss: 0.121124, Val Acc: 0.762887\n",
      "Epoch 14502 - Train Loss: 0.098908, Train Acc: 0.850000 | Val Loss: 0.121121, Val Acc: 0.762887\n",
      "Epoch 14503 - Train Loss: 0.098904, Train Acc: 0.850000 | Val Loss: 0.121118, Val Acc: 0.762887\n",
      "Epoch 14504 - Train Loss: 0.098899, Train Acc: 0.850000 | Val Loss: 0.121115, Val Acc: 0.762887\n",
      "Epoch 14505 - Train Loss: 0.098895, Train Acc: 0.850000 | Val Loss: 0.121111, Val Acc: 0.762887\n",
      "Epoch 14506 - Train Loss: 0.098891, Train Acc: 0.850000 | Val Loss: 0.121108, Val Acc: 0.762887\n",
      "Epoch 14507 - Train Loss: 0.098886, Train Acc: 0.850000 | Val Loss: 0.121105, Val Acc: 0.762887\n",
      "Epoch 14508 - Train Loss: 0.098882, Train Acc: 0.850000 | Val Loss: 0.121102, Val Acc: 0.762887\n",
      "Epoch 14509 - Train Loss: 0.098877, Train Acc: 0.850000 | Val Loss: 0.121099, Val Acc: 0.762887\n",
      "Epoch 14510 - Train Loss: 0.098873, Train Acc: 0.850000 | Val Loss: 0.121096, Val Acc: 0.762887\n",
      "Epoch 14511 - Train Loss: 0.098869, Train Acc: 0.850000 | Val Loss: 0.121093, Val Acc: 0.762887\n",
      "Epoch 14512 - Train Loss: 0.098864, Train Acc: 0.850000 | Val Loss: 0.121090, Val Acc: 0.762887\n",
      "Epoch 14513 - Train Loss: 0.098860, Train Acc: 0.850000 | Val Loss: 0.121087, Val Acc: 0.762887\n",
      "Epoch 14514 - Train Loss: 0.098855, Train Acc: 0.850000 | Val Loss: 0.121084, Val Acc: 0.762887\n",
      "Epoch 14515 - Train Loss: 0.098851, Train Acc: 0.850000 | Val Loss: 0.121081, Val Acc: 0.762887\n",
      "Epoch 14516 - Train Loss: 0.098847, Train Acc: 0.850000 | Val Loss: 0.121078, Val Acc: 0.762887\n",
      "Epoch 14517 - Train Loss: 0.098842, Train Acc: 0.850000 | Val Loss: 0.121075, Val Acc: 0.762887\n",
      "Epoch 14518 - Train Loss: 0.098838, Train Acc: 0.850000 | Val Loss: 0.121072, Val Acc: 0.762887\n",
      "Epoch 14519 - Train Loss: 0.098834, Train Acc: 0.850000 | Val Loss: 0.121069, Val Acc: 0.762887\n",
      "Epoch 14520 - Train Loss: 0.098829, Train Acc: 0.850000 | Val Loss: 0.121066, Val Acc: 0.762887\n",
      "Epoch 14521 - Train Loss: 0.098825, Train Acc: 0.850000 | Val Loss: 0.121063, Val Acc: 0.762887\n",
      "Epoch 14522 - Train Loss: 0.098820, Train Acc: 0.850000 | Val Loss: 0.121060, Val Acc: 0.762887\n",
      "Epoch 14523 - Train Loss: 0.098816, Train Acc: 0.850000 | Val Loss: 0.121057, Val Acc: 0.762887\n",
      "Epoch 14524 - Train Loss: 0.098812, Train Acc: 0.850000 | Val Loss: 0.121054, Val Acc: 0.762887\n",
      "Epoch 14525 - Train Loss: 0.098807, Train Acc: 0.850000 | Val Loss: 0.121051, Val Acc: 0.762887\n",
      "Epoch 14526 - Train Loss: 0.098803, Train Acc: 0.850000 | Val Loss: 0.121048, Val Acc: 0.762887\n",
      "Epoch 14527 - Train Loss: 0.098798, Train Acc: 0.850000 | Val Loss: 0.121045, Val Acc: 0.762887\n",
      "Epoch 14528 - Train Loss: 0.098794, Train Acc: 0.850000 | Val Loss: 0.121042, Val Acc: 0.762887\n",
      "Epoch 14529 - Train Loss: 0.098790, Train Acc: 0.850000 | Val Loss: 0.121039, Val Acc: 0.762887\n",
      "Epoch 14530 - Train Loss: 0.098785, Train Acc: 0.850000 | Val Loss: 0.121036, Val Acc: 0.762887\n",
      "Epoch 14531 - Train Loss: 0.098781, Train Acc: 0.850000 | Val Loss: 0.121033, Val Acc: 0.762887\n",
      "Epoch 14532 - Train Loss: 0.098777, Train Acc: 0.850000 | Val Loss: 0.121030, Val Acc: 0.762887\n",
      "Epoch 14533 - Train Loss: 0.098772, Train Acc: 0.850000 | Val Loss: 0.121027, Val Acc: 0.762887\n",
      "Epoch 14534 - Train Loss: 0.098768, Train Acc: 0.850000 | Val Loss: 0.121024, Val Acc: 0.762887\n",
      "Epoch 14535 - Train Loss: 0.098763, Train Acc: 0.850000 | Val Loss: 0.121021, Val Acc: 0.762887\n",
      "Epoch 14536 - Train Loss: 0.098759, Train Acc: 0.850000 | Val Loss: 0.121018, Val Acc: 0.762887\n",
      "Epoch 14537 - Train Loss: 0.098755, Train Acc: 0.850000 | Val Loss: 0.121015, Val Acc: 0.762887\n",
      "Epoch 14538 - Train Loss: 0.098750, Train Acc: 0.850000 | Val Loss: 0.121012, Val Acc: 0.762887\n",
      "Epoch 14539 - Train Loss: 0.098746, Train Acc: 0.850000 | Val Loss: 0.121009, Val Acc: 0.762887\n",
      "Epoch 14540 - Train Loss: 0.098742, Train Acc: 0.850000 | Val Loss: 0.121006, Val Acc: 0.762887\n",
      "Epoch 14541 - Train Loss: 0.098737, Train Acc: 0.850000 | Val Loss: 0.121003, Val Acc: 0.762887\n",
      "Epoch 14542 - Train Loss: 0.098733, Train Acc: 0.850000 | Val Loss: 0.121000, Val Acc: 0.762887\n",
      "Epoch 14543 - Train Loss: 0.098728, Train Acc: 0.850000 | Val Loss: 0.120997, Val Acc: 0.762887\n",
      "Epoch 14544 - Train Loss: 0.098724, Train Acc: 0.850000 | Val Loss: 0.120995, Val Acc: 0.762887\n",
      "Epoch 14545 - Train Loss: 0.098720, Train Acc: 0.850000 | Val Loss: 0.120992, Val Acc: 0.762887\n",
      "Epoch 14546 - Train Loss: 0.098715, Train Acc: 0.850000 | Val Loss: 0.120989, Val Acc: 0.762887\n",
      "Epoch 14547 - Train Loss: 0.098711, Train Acc: 0.850000 | Val Loss: 0.120986, Val Acc: 0.762887\n",
      "Epoch 14548 - Train Loss: 0.098707, Train Acc: 0.850000 | Val Loss: 0.120983, Val Acc: 0.762887\n",
      "Epoch 14549 - Train Loss: 0.098702, Train Acc: 0.850000 | Val Loss: 0.120980, Val Acc: 0.762887\n",
      "Epoch 14550 - Train Loss: 0.098698, Train Acc: 0.850000 | Val Loss: 0.120977, Val Acc: 0.762887\n",
      "Epoch 14551 - Train Loss: 0.098694, Train Acc: 0.850000 | Val Loss: 0.120974, Val Acc: 0.762887\n",
      "Epoch 14552 - Train Loss: 0.098689, Train Acc: 0.850000 | Val Loss: 0.120971, Val Acc: 0.762887\n",
      "Epoch 14553 - Train Loss: 0.098685, Train Acc: 0.850000 | Val Loss: 0.120968, Val Acc: 0.762887\n",
      "Epoch 14554 - Train Loss: 0.098680, Train Acc: 0.850000 | Val Loss: 0.120965, Val Acc: 0.762887\n",
      "Epoch 14555 - Train Loss: 0.098676, Train Acc: 0.850000 | Val Loss: 0.120962, Val Acc: 0.762887\n",
      "Epoch 14556 - Train Loss: 0.098672, Train Acc: 0.850000 | Val Loss: 0.120959, Val Acc: 0.762887\n",
      "Epoch 14557 - Train Loss: 0.098667, Train Acc: 0.850000 | Val Loss: 0.120956, Val Acc: 0.762887\n",
      "Epoch 14558 - Train Loss: 0.098663, Train Acc: 0.850000 | Val Loss: 0.120953, Val Acc: 0.762887\n",
      "Epoch 14559 - Train Loss: 0.098659, Train Acc: 0.850000 | Val Loss: 0.120950, Val Acc: 0.762887\n",
      "Epoch 14560 - Train Loss: 0.098654, Train Acc: 0.850000 | Val Loss: 0.120947, Val Acc: 0.762887\n",
      "Epoch 14561 - Train Loss: 0.098650, Train Acc: 0.850000 | Val Loss: 0.120944, Val Acc: 0.762887\n",
      "Epoch 14562 - Train Loss: 0.098646, Train Acc: 0.851282 | Val Loss: 0.120941, Val Acc: 0.762887\n",
      "Epoch 14563 - Train Loss: 0.098641, Train Acc: 0.851282 | Val Loss: 0.120938, Val Acc: 0.762887\n",
      "Epoch 14564 - Train Loss: 0.098637, Train Acc: 0.851282 | Val Loss: 0.120935, Val Acc: 0.762887\n",
      "Epoch 14565 - Train Loss: 0.098632, Train Acc: 0.851282 | Val Loss: 0.120932, Val Acc: 0.762887\n",
      "Epoch 14566 - Train Loss: 0.098628, Train Acc: 0.851282 | Val Loss: 0.120929, Val Acc: 0.762887\n",
      "Epoch 14567 - Train Loss: 0.098624, Train Acc: 0.851282 | Val Loss: 0.120926, Val Acc: 0.762887\n",
      "Epoch 14568 - Train Loss: 0.098619, Train Acc: 0.851282 | Val Loss: 0.120923, Val Acc: 0.762887\n",
      "Epoch 14569 - Train Loss: 0.098615, Train Acc: 0.851282 | Val Loss: 0.120920, Val Acc: 0.762887\n",
      "Epoch 14570 - Train Loss: 0.098611, Train Acc: 0.851282 | Val Loss: 0.120917, Val Acc: 0.762887\n",
      "Epoch 14571 - Train Loss: 0.098606, Train Acc: 0.851282 | Val Loss: 0.120914, Val Acc: 0.762887\n",
      "Epoch 14572 - Train Loss: 0.098602, Train Acc: 0.851282 | Val Loss: 0.120911, Val Acc: 0.762887\n",
      "Epoch 14573 - Train Loss: 0.098598, Train Acc: 0.851282 | Val Loss: 0.120908, Val Acc: 0.762887\n",
      "Epoch 14574 - Train Loss: 0.098593, Train Acc: 0.851282 | Val Loss: 0.120905, Val Acc: 0.762887\n",
      "Epoch 14575 - Train Loss: 0.098589, Train Acc: 0.851282 | Val Loss: 0.120902, Val Acc: 0.762887\n",
      "Epoch 14576 - Train Loss: 0.098585, Train Acc: 0.851282 | Val Loss: 0.120899, Val Acc: 0.762887\n",
      "Epoch 14577 - Train Loss: 0.098580, Train Acc: 0.851282 | Val Loss: 0.120896, Val Acc: 0.762887\n",
      "Epoch 14578 - Train Loss: 0.098576, Train Acc: 0.851282 | Val Loss: 0.120893, Val Acc: 0.762887\n",
      "Epoch 14579 - Train Loss: 0.098572, Train Acc: 0.851282 | Val Loss: 0.120890, Val Acc: 0.762887\n",
      "Epoch 14580 - Train Loss: 0.098567, Train Acc: 0.851282 | Val Loss: 0.120887, Val Acc: 0.762887\n",
      "Epoch 14581 - Train Loss: 0.098563, Train Acc: 0.851282 | Val Loss: 0.120884, Val Acc: 0.762887\n",
      "Epoch 14582 - Train Loss: 0.098558, Train Acc: 0.851282 | Val Loss: 0.120881, Val Acc: 0.762887\n",
      "Epoch 14583 - Train Loss: 0.098554, Train Acc: 0.851282 | Val Loss: 0.120878, Val Acc: 0.762887\n",
      "Epoch 14584 - Train Loss: 0.098550, Train Acc: 0.851282 | Val Loss: 0.120875, Val Acc: 0.762887\n",
      "Epoch 14585 - Train Loss: 0.098545, Train Acc: 0.851282 | Val Loss: 0.120872, Val Acc: 0.762887\n",
      "Epoch 14586 - Train Loss: 0.098541, Train Acc: 0.851282 | Val Loss: 0.120870, Val Acc: 0.762887\n",
      "Epoch 14587 - Train Loss: 0.098537, Train Acc: 0.851282 | Val Loss: 0.120867, Val Acc: 0.762887\n",
      "Epoch 14588 - Train Loss: 0.098532, Train Acc: 0.851282 | Val Loss: 0.120864, Val Acc: 0.762887\n",
      "Epoch 14589 - Train Loss: 0.098528, Train Acc: 0.851282 | Val Loss: 0.120861, Val Acc: 0.762887\n",
      "Epoch 14590 - Train Loss: 0.098524, Train Acc: 0.851282 | Val Loss: 0.120858, Val Acc: 0.762887\n",
      "Epoch 14591 - Train Loss: 0.098519, Train Acc: 0.851282 | Val Loss: 0.120855, Val Acc: 0.762887\n",
      "Epoch 14592 - Train Loss: 0.098515, Train Acc: 0.851282 | Val Loss: 0.120852, Val Acc: 0.762887\n",
      "Epoch 14593 - Train Loss: 0.098511, Train Acc: 0.851282 | Val Loss: 0.120849, Val Acc: 0.762887\n",
      "Epoch 14594 - Train Loss: 0.098506, Train Acc: 0.851282 | Val Loss: 0.120846, Val Acc: 0.762887\n",
      "Epoch 14595 - Train Loss: 0.098502, Train Acc: 0.851282 | Val Loss: 0.120843, Val Acc: 0.762887\n",
      "Epoch 14596 - Train Loss: 0.098498, Train Acc: 0.851282 | Val Loss: 0.120840, Val Acc: 0.762887\n",
      "Epoch 14597 - Train Loss: 0.098493, Train Acc: 0.851282 | Val Loss: 0.120837, Val Acc: 0.762887\n",
      "Epoch 14598 - Train Loss: 0.098489, Train Acc: 0.851282 | Val Loss: 0.120834, Val Acc: 0.762887\n",
      "Epoch 14599 - Train Loss: 0.098485, Train Acc: 0.851282 | Val Loss: 0.120831, Val Acc: 0.762887\n",
      "Epoch 14600 - Train Loss: 0.098480, Train Acc: 0.851282 | Val Loss: 0.120828, Val Acc: 0.762887\n",
      "Epoch 14601 - Train Loss: 0.098476, Train Acc: 0.851282 | Val Loss: 0.120825, Val Acc: 0.762887\n",
      "Epoch 14602 - Train Loss: 0.098472, Train Acc: 0.851282 | Val Loss: 0.120822, Val Acc: 0.762887\n",
      "Epoch 14603 - Train Loss: 0.098467, Train Acc: 0.851282 | Val Loss: 0.120819, Val Acc: 0.762887\n",
      "Epoch 14604 - Train Loss: 0.098463, Train Acc: 0.851282 | Val Loss: 0.120816, Val Acc: 0.762887\n",
      "Epoch 14605 - Train Loss: 0.098459, Train Acc: 0.851282 | Val Loss: 0.120813, Val Acc: 0.762887\n",
      "Epoch 14606 - Train Loss: 0.098454, Train Acc: 0.851282 | Val Loss: 0.120810, Val Acc: 0.762887\n",
      "Epoch 14607 - Train Loss: 0.098450, Train Acc: 0.851282 | Val Loss: 0.120807, Val Acc: 0.762887\n",
      "Epoch 14608 - Train Loss: 0.098446, Train Acc: 0.851282 | Val Loss: 0.120804, Val Acc: 0.762887\n",
      "Epoch 14609 - Train Loss: 0.098441, Train Acc: 0.851282 | Val Loss: 0.120802, Val Acc: 0.762887\n",
      "Epoch 14610 - Train Loss: 0.098437, Train Acc: 0.851282 | Val Loss: 0.120799, Val Acc: 0.762887\n",
      "Epoch 14611 - Train Loss: 0.098433, Train Acc: 0.851282 | Val Loss: 0.120796, Val Acc: 0.762887\n",
      "Epoch 14612 - Train Loss: 0.098428, Train Acc: 0.851282 | Val Loss: 0.120793, Val Acc: 0.762887\n",
      "Epoch 14613 - Train Loss: 0.098424, Train Acc: 0.851282 | Val Loss: 0.120790, Val Acc: 0.762887\n",
      "Epoch 14614 - Train Loss: 0.098420, Train Acc: 0.851282 | Val Loss: 0.120787, Val Acc: 0.762887\n",
      "Epoch 14615 - Train Loss: 0.098415, Train Acc: 0.851282 | Val Loss: 0.120784, Val Acc: 0.762887\n",
      "Epoch 14616 - Train Loss: 0.098411, Train Acc: 0.851282 | Val Loss: 0.120781, Val Acc: 0.762887\n",
      "Epoch 14617 - Train Loss: 0.098407, Train Acc: 0.851282 | Val Loss: 0.120778, Val Acc: 0.762887\n",
      "Epoch 14618 - Train Loss: 0.098402, Train Acc: 0.851282 | Val Loss: 0.120775, Val Acc: 0.762887\n",
      "Epoch 14619 - Train Loss: 0.098398, Train Acc: 0.851282 | Val Loss: 0.120772, Val Acc: 0.762887\n",
      "Epoch 14620 - Train Loss: 0.098394, Train Acc: 0.851282 | Val Loss: 0.120769, Val Acc: 0.762887\n",
      "Epoch 14621 - Train Loss: 0.098389, Train Acc: 0.851282 | Val Loss: 0.120766, Val Acc: 0.762887\n",
      "Epoch 14622 - Train Loss: 0.098385, Train Acc: 0.851282 | Val Loss: 0.120763, Val Acc: 0.762887\n",
      "Epoch 14623 - Train Loss: 0.098381, Train Acc: 0.851282 | Val Loss: 0.120761, Val Acc: 0.762887\n",
      "Epoch 14624 - Train Loss: 0.098376, Train Acc: 0.851282 | Val Loss: 0.120758, Val Acc: 0.762887\n",
      "Epoch 14625 - Train Loss: 0.098372, Train Acc: 0.851282 | Val Loss: 0.120755, Val Acc: 0.762887\n",
      "Epoch 14626 - Train Loss: 0.098368, Train Acc: 0.851282 | Val Loss: 0.120752, Val Acc: 0.762887\n",
      "Epoch 14627 - Train Loss: 0.098363, Train Acc: 0.851282 | Val Loss: 0.120749, Val Acc: 0.762887\n",
      "Epoch 14628 - Train Loss: 0.098359, Train Acc: 0.851282 | Val Loss: 0.120746, Val Acc: 0.762887\n",
      "Epoch 14629 - Train Loss: 0.098355, Train Acc: 0.851282 | Val Loss: 0.120743, Val Acc: 0.762887\n",
      "Epoch 14630 - Train Loss: 0.098350, Train Acc: 0.851282 | Val Loss: 0.120740, Val Acc: 0.762887\n",
      "Epoch 14631 - Train Loss: 0.098346, Train Acc: 0.851282 | Val Loss: 0.120737, Val Acc: 0.762887\n",
      "Epoch 14632 - Train Loss: 0.098342, Train Acc: 0.851282 | Val Loss: 0.120734, Val Acc: 0.762887\n",
      "Epoch 14633 - Train Loss: 0.098338, Train Acc: 0.851282 | Val Loss: 0.120731, Val Acc: 0.762887\n",
      "Epoch 14634 - Train Loss: 0.098333, Train Acc: 0.851282 | Val Loss: 0.120728, Val Acc: 0.762887\n",
      "Epoch 14635 - Train Loss: 0.098329, Train Acc: 0.851282 | Val Loss: 0.120726, Val Acc: 0.762887\n",
      "Epoch 14636 - Train Loss: 0.098325, Train Acc: 0.851282 | Val Loss: 0.120723, Val Acc: 0.762887\n",
      "Epoch 14637 - Train Loss: 0.098320, Train Acc: 0.851282 | Val Loss: 0.120720, Val Acc: 0.762887\n",
      "Epoch 14638 - Train Loss: 0.098316, Train Acc: 0.851282 | Val Loss: 0.120717, Val Acc: 0.762887\n",
      "Epoch 14639 - Train Loss: 0.098312, Train Acc: 0.851282 | Val Loss: 0.120714, Val Acc: 0.762887\n",
      "Epoch 14640 - Train Loss: 0.098307, Train Acc: 0.851282 | Val Loss: 0.120711, Val Acc: 0.762887\n",
      "Epoch 14641 - Train Loss: 0.098303, Train Acc: 0.851282 | Val Loss: 0.120708, Val Acc: 0.762887\n",
      "Epoch 14642 - Train Loss: 0.098299, Train Acc: 0.851282 | Val Loss: 0.120705, Val Acc: 0.762887\n",
      "Epoch 14643 - Train Loss: 0.098294, Train Acc: 0.851282 | Val Loss: 0.120702, Val Acc: 0.762887\n",
      "Epoch 14644 - Train Loss: 0.098290, Train Acc: 0.851282 | Val Loss: 0.120699, Val Acc: 0.762887\n",
      "Epoch 14645 - Train Loss: 0.098286, Train Acc: 0.851282 | Val Loss: 0.120696, Val Acc: 0.762887\n",
      "Epoch 14646 - Train Loss: 0.098281, Train Acc: 0.851282 | Val Loss: 0.120693, Val Acc: 0.762887\n",
      "Epoch 14647 - Train Loss: 0.098277, Train Acc: 0.851282 | Val Loss: 0.120691, Val Acc: 0.762887\n",
      "Epoch 14648 - Train Loss: 0.098273, Train Acc: 0.851282 | Val Loss: 0.120688, Val Acc: 0.762887\n",
      "Epoch 14649 - Train Loss: 0.098269, Train Acc: 0.851282 | Val Loss: 0.120685, Val Acc: 0.762887\n",
      "Epoch 14650 - Train Loss: 0.098264, Train Acc: 0.851282 | Val Loss: 0.120682, Val Acc: 0.762887\n",
      "Epoch 14651 - Train Loss: 0.098260, Train Acc: 0.851282 | Val Loss: 0.120679, Val Acc: 0.762887\n",
      "Epoch 14652 - Train Loss: 0.098256, Train Acc: 0.851282 | Val Loss: 0.120676, Val Acc: 0.762887\n",
      "Epoch 14653 - Train Loss: 0.098251, Train Acc: 0.851282 | Val Loss: 0.120673, Val Acc: 0.762887\n",
      "Epoch 14654 - Train Loss: 0.098247, Train Acc: 0.851282 | Val Loss: 0.120670, Val Acc: 0.762887\n",
      "Epoch 14655 - Train Loss: 0.098243, Train Acc: 0.851282 | Val Loss: 0.120667, Val Acc: 0.762887\n",
      "Epoch 14656 - Train Loss: 0.098238, Train Acc: 0.851282 | Val Loss: 0.120664, Val Acc: 0.762887\n",
      "Epoch 14657 - Train Loss: 0.098234, Train Acc: 0.851282 | Val Loss: 0.120661, Val Acc: 0.762887\n",
      "Epoch 14658 - Train Loss: 0.098230, Train Acc: 0.851282 | Val Loss: 0.120658, Val Acc: 0.762887\n",
      "Epoch 14659 - Train Loss: 0.098225, Train Acc: 0.851282 | Val Loss: 0.120656, Val Acc: 0.762887\n",
      "Epoch 14660 - Train Loss: 0.098221, Train Acc: 0.851282 | Val Loss: 0.120653, Val Acc: 0.762887\n",
      "Epoch 14661 - Train Loss: 0.098217, Train Acc: 0.851282 | Val Loss: 0.120650, Val Acc: 0.762887\n",
      "Epoch 14662 - Train Loss: 0.098213, Train Acc: 0.851282 | Val Loss: 0.120647, Val Acc: 0.762887\n",
      "Epoch 14663 - Train Loss: 0.098208, Train Acc: 0.851282 | Val Loss: 0.120644, Val Acc: 0.762887\n",
      "Epoch 14664 - Train Loss: 0.098204, Train Acc: 0.851282 | Val Loss: 0.120641, Val Acc: 0.762887\n",
      "Epoch 14665 - Train Loss: 0.098200, Train Acc: 0.851282 | Val Loss: 0.120638, Val Acc: 0.762887\n",
      "Epoch 14666 - Train Loss: 0.098195, Train Acc: 0.851282 | Val Loss: 0.120635, Val Acc: 0.762887\n",
      "Epoch 14667 - Train Loss: 0.098191, Train Acc: 0.851282 | Val Loss: 0.120632, Val Acc: 0.762887\n",
      "Epoch 14668 - Train Loss: 0.098187, Train Acc: 0.851282 | Val Loss: 0.120629, Val Acc: 0.762887\n",
      "Epoch 14669 - Train Loss: 0.098182, Train Acc: 0.851282 | Val Loss: 0.120626, Val Acc: 0.762887\n",
      "Epoch 14670 - Train Loss: 0.098178, Train Acc: 0.851282 | Val Loss: 0.120624, Val Acc: 0.762887\n",
      "Epoch 14671 - Train Loss: 0.098174, Train Acc: 0.851282 | Val Loss: 0.120621, Val Acc: 0.762887\n",
      "Epoch 14672 - Train Loss: 0.098170, Train Acc: 0.851282 | Val Loss: 0.120618, Val Acc: 0.762887\n",
      "Epoch 14673 - Train Loss: 0.098165, Train Acc: 0.851282 | Val Loss: 0.120615, Val Acc: 0.762887\n",
      "Epoch 14674 - Train Loss: 0.098161, Train Acc: 0.851282 | Val Loss: 0.120612, Val Acc: 0.762887\n",
      "Epoch 14675 - Train Loss: 0.098157, Train Acc: 0.851282 | Val Loss: 0.120609, Val Acc: 0.762887\n",
      "Epoch 14676 - Train Loss: 0.098152, Train Acc: 0.851282 | Val Loss: 0.120606, Val Acc: 0.762887\n",
      "Epoch 14677 - Train Loss: 0.098148, Train Acc: 0.851282 | Val Loss: 0.120603, Val Acc: 0.762887\n",
      "Epoch 14678 - Train Loss: 0.098144, Train Acc: 0.851282 | Val Loss: 0.120600, Val Acc: 0.762887\n",
      "Epoch 14679 - Train Loss: 0.098139, Train Acc: 0.851282 | Val Loss: 0.120597, Val Acc: 0.762887\n",
      "Epoch 14680 - Train Loss: 0.098135, Train Acc: 0.851282 | Val Loss: 0.120595, Val Acc: 0.762887\n",
      "Epoch 14681 - Train Loss: 0.098131, Train Acc: 0.851282 | Val Loss: 0.120592, Val Acc: 0.762887\n",
      "Epoch 14682 - Train Loss: 0.098127, Train Acc: 0.851282 | Val Loss: 0.120589, Val Acc: 0.762887\n",
      "Epoch 14683 - Train Loss: 0.098122, Train Acc: 0.851282 | Val Loss: 0.120586, Val Acc: 0.762887\n",
      "Epoch 14684 - Train Loss: 0.098118, Train Acc: 0.851282 | Val Loss: 0.120583, Val Acc: 0.762887\n",
      "Epoch 14685 - Train Loss: 0.098114, Train Acc: 0.851282 | Val Loss: 0.120580, Val Acc: 0.762887\n",
      "Epoch 14686 - Train Loss: 0.098109, Train Acc: 0.851282 | Val Loss: 0.120577, Val Acc: 0.762887\n",
      "Epoch 14687 - Train Loss: 0.098105, Train Acc: 0.851282 | Val Loss: 0.120574, Val Acc: 0.762887\n",
      "Epoch 14688 - Train Loss: 0.098101, Train Acc: 0.851282 | Val Loss: 0.120571, Val Acc: 0.762887\n",
      "Epoch 14689 - Train Loss: 0.098097, Train Acc: 0.851282 | Val Loss: 0.120568, Val Acc: 0.762887\n",
      "Epoch 14690 - Train Loss: 0.098092, Train Acc: 0.851282 | Val Loss: 0.120565, Val Acc: 0.762887\n",
      "Epoch 14691 - Train Loss: 0.098088, Train Acc: 0.851282 | Val Loss: 0.120563, Val Acc: 0.762887\n",
      "Epoch 14692 - Train Loss: 0.098084, Train Acc: 0.851282 | Val Loss: 0.120560, Val Acc: 0.762887\n",
      "Epoch 14693 - Train Loss: 0.098079, Train Acc: 0.851282 | Val Loss: 0.120557, Val Acc: 0.762887\n",
      "Epoch 14694 - Train Loss: 0.098075, Train Acc: 0.851282 | Val Loss: 0.120554, Val Acc: 0.762887\n",
      "Epoch 14695 - Train Loss: 0.098071, Train Acc: 0.851282 | Val Loss: 0.120551, Val Acc: 0.762887\n",
      "Epoch 14696 - Train Loss: 0.098067, Train Acc: 0.851282 | Val Loss: 0.120548, Val Acc: 0.762887\n",
      "Epoch 14697 - Train Loss: 0.098062, Train Acc: 0.851282 | Val Loss: 0.120545, Val Acc: 0.762887\n",
      "Epoch 14698 - Train Loss: 0.098058, Train Acc: 0.851282 | Val Loss: 0.120542, Val Acc: 0.762887\n",
      "Epoch 14699 - Train Loss: 0.098054, Train Acc: 0.851282 | Val Loss: 0.120539, Val Acc: 0.762887\n",
      "Epoch 14700 - Train Loss: 0.098049, Train Acc: 0.851282 | Val Loss: 0.120536, Val Acc: 0.762887\n",
      "Epoch 14701 - Train Loss: 0.098045, Train Acc: 0.851282 | Val Loss: 0.120534, Val Acc: 0.762887\n",
      "Epoch 14702 - Train Loss: 0.098041, Train Acc: 0.851282 | Val Loss: 0.120531, Val Acc: 0.762887\n",
      "Epoch 14703 - Train Loss: 0.098037, Train Acc: 0.851282 | Val Loss: 0.120528, Val Acc: 0.762887\n",
      "Epoch 14704 - Train Loss: 0.098032, Train Acc: 0.851282 | Val Loss: 0.120525, Val Acc: 0.762887\n",
      "Epoch 14705 - Train Loss: 0.098028, Train Acc: 0.851282 | Val Loss: 0.120522, Val Acc: 0.762887\n",
      "Epoch 14706 - Train Loss: 0.098024, Train Acc: 0.851282 | Val Loss: 0.120519, Val Acc: 0.762887\n",
      "Epoch 14707 - Train Loss: 0.098019, Train Acc: 0.851282 | Val Loss: 0.120516, Val Acc: 0.762887\n",
      "Epoch 14708 - Train Loss: 0.098015, Train Acc: 0.851282 | Val Loss: 0.120513, Val Acc: 0.762887\n",
      "Epoch 14709 - Train Loss: 0.098011, Train Acc: 0.851282 | Val Loss: 0.120510, Val Acc: 0.762887\n",
      "Epoch 14710 - Train Loss: 0.098007, Train Acc: 0.851282 | Val Loss: 0.120507, Val Acc: 0.762887\n",
      "Epoch 14711 - Train Loss: 0.098002, Train Acc: 0.851282 | Val Loss: 0.120505, Val Acc: 0.762887\n",
      "Epoch 14712 - Train Loss: 0.097998, Train Acc: 0.851282 | Val Loss: 0.120502, Val Acc: 0.762887\n",
      "Epoch 14713 - Train Loss: 0.097994, Train Acc: 0.851282 | Val Loss: 0.120499, Val Acc: 0.762887\n",
      "Epoch 14714 - Train Loss: 0.097990, Train Acc: 0.851282 | Val Loss: 0.120496, Val Acc: 0.752577\n",
      "Epoch 14715 - Train Loss: 0.097985, Train Acc: 0.851282 | Val Loss: 0.120493, Val Acc: 0.752577\n",
      "Epoch 14716 - Train Loss: 0.097981, Train Acc: 0.851282 | Val Loss: 0.120490, Val Acc: 0.752577\n",
      "Epoch 14717 - Train Loss: 0.097977, Train Acc: 0.851282 | Val Loss: 0.120487, Val Acc: 0.752577\n",
      "Epoch 14718 - Train Loss: 0.097972, Train Acc: 0.851282 | Val Loss: 0.120484, Val Acc: 0.752577\n",
      "Epoch 14719 - Train Loss: 0.097968, Train Acc: 0.851282 | Val Loss: 0.120481, Val Acc: 0.752577\n",
      "Epoch 14720 - Train Loss: 0.097964, Train Acc: 0.851282 | Val Loss: 0.120479, Val Acc: 0.752577\n",
      "Epoch 14721 - Train Loss: 0.097960, Train Acc: 0.851282 | Val Loss: 0.120476, Val Acc: 0.752577\n",
      "Epoch 14722 - Train Loss: 0.097955, Train Acc: 0.851282 | Val Loss: 0.120473, Val Acc: 0.752577\n",
      "Epoch 14723 - Train Loss: 0.097951, Train Acc: 0.851282 | Val Loss: 0.120470, Val Acc: 0.752577\n",
      "Epoch 14724 - Train Loss: 0.097947, Train Acc: 0.851282 | Val Loss: 0.120467, Val Acc: 0.752577\n",
      "Epoch 14725 - Train Loss: 0.097943, Train Acc: 0.851282 | Val Loss: 0.120464, Val Acc: 0.752577\n",
      "Epoch 14726 - Train Loss: 0.097938, Train Acc: 0.851282 | Val Loss: 0.120461, Val Acc: 0.752577\n",
      "Epoch 14727 - Train Loss: 0.097934, Train Acc: 0.851282 | Val Loss: 0.120458, Val Acc: 0.752577\n",
      "Epoch 14728 - Train Loss: 0.097930, Train Acc: 0.852564 | Val Loss: 0.120455, Val Acc: 0.752577\n",
      "Epoch 14729 - Train Loss: 0.097926, Train Acc: 0.852564 | Val Loss: 0.120453, Val Acc: 0.752577\n",
      "Epoch 14730 - Train Loss: 0.097921, Train Acc: 0.852564 | Val Loss: 0.120450, Val Acc: 0.752577\n",
      "Epoch 14731 - Train Loss: 0.097917, Train Acc: 0.852564 | Val Loss: 0.120447, Val Acc: 0.752577\n",
      "Epoch 14732 - Train Loss: 0.097913, Train Acc: 0.852564 | Val Loss: 0.120444, Val Acc: 0.752577\n",
      "Epoch 14733 - Train Loss: 0.097908, Train Acc: 0.852564 | Val Loss: 0.120441, Val Acc: 0.752577\n",
      "Epoch 14734 - Train Loss: 0.097904, Train Acc: 0.852564 | Val Loss: 0.120438, Val Acc: 0.752577\n",
      "Epoch 14735 - Train Loss: 0.097900, Train Acc: 0.852564 | Val Loss: 0.120435, Val Acc: 0.752577\n",
      "Epoch 14736 - Train Loss: 0.097896, Train Acc: 0.852564 | Val Loss: 0.120432, Val Acc: 0.752577\n",
      "Epoch 14737 - Train Loss: 0.097891, Train Acc: 0.852564 | Val Loss: 0.120430, Val Acc: 0.752577\n",
      "Epoch 14738 - Train Loss: 0.097887, Train Acc: 0.852564 | Val Loss: 0.120427, Val Acc: 0.752577\n",
      "Epoch 14739 - Train Loss: 0.097883, Train Acc: 0.852564 | Val Loss: 0.120424, Val Acc: 0.752577\n",
      "Epoch 14740 - Train Loss: 0.097879, Train Acc: 0.852564 | Val Loss: 0.120421, Val Acc: 0.752577\n",
      "Epoch 14741 - Train Loss: 0.097874, Train Acc: 0.852564 | Val Loss: 0.120418, Val Acc: 0.752577\n",
      "Epoch 14742 - Train Loss: 0.097870, Train Acc: 0.852564 | Val Loss: 0.120415, Val Acc: 0.752577\n",
      "Epoch 14743 - Train Loss: 0.097866, Train Acc: 0.852564 | Val Loss: 0.120412, Val Acc: 0.752577\n",
      "Epoch 14744 - Train Loss: 0.097862, Train Acc: 0.852564 | Val Loss: 0.120409, Val Acc: 0.752577\n",
      "Epoch 14745 - Train Loss: 0.097857, Train Acc: 0.852564 | Val Loss: 0.120407, Val Acc: 0.752577\n",
      "Epoch 14746 - Train Loss: 0.097853, Train Acc: 0.852564 | Val Loss: 0.120404, Val Acc: 0.752577\n",
      "Epoch 14747 - Train Loss: 0.097849, Train Acc: 0.852564 | Val Loss: 0.120401, Val Acc: 0.752577\n",
      "Epoch 14748 - Train Loss: 0.097845, Train Acc: 0.852564 | Val Loss: 0.120398, Val Acc: 0.752577\n",
      "Epoch 14749 - Train Loss: 0.097840, Train Acc: 0.852564 | Val Loss: 0.120395, Val Acc: 0.752577\n",
      "Epoch 14750 - Train Loss: 0.097836, Train Acc: 0.852564 | Val Loss: 0.120392, Val Acc: 0.752577\n",
      "Epoch 14751 - Train Loss: 0.097832, Train Acc: 0.852564 | Val Loss: 0.120389, Val Acc: 0.752577\n",
      "Epoch 14752 - Train Loss: 0.097828, Train Acc: 0.852564 | Val Loss: 0.120386, Val Acc: 0.752577\n",
      "Epoch 14753 - Train Loss: 0.097823, Train Acc: 0.852564 | Val Loss: 0.120384, Val Acc: 0.752577\n",
      "Epoch 14754 - Train Loss: 0.097819, Train Acc: 0.852564 | Val Loss: 0.120381, Val Acc: 0.752577\n",
      "Epoch 14755 - Train Loss: 0.097815, Train Acc: 0.852564 | Val Loss: 0.120378, Val Acc: 0.752577\n",
      "Epoch 14756 - Train Loss: 0.097811, Train Acc: 0.852564 | Val Loss: 0.120375, Val Acc: 0.752577\n",
      "Epoch 14757 - Train Loss: 0.097806, Train Acc: 0.852564 | Val Loss: 0.120372, Val Acc: 0.752577\n",
      "Epoch 14758 - Train Loss: 0.097802, Train Acc: 0.852564 | Val Loss: 0.120369, Val Acc: 0.752577\n",
      "Epoch 14759 - Train Loss: 0.097798, Train Acc: 0.852564 | Val Loss: 0.120366, Val Acc: 0.762887\n",
      "Epoch 14760 - Train Loss: 0.097794, Train Acc: 0.852564 | Val Loss: 0.120363, Val Acc: 0.762887\n",
      "Epoch 14761 - Train Loss: 0.097789, Train Acc: 0.852564 | Val Loss: 0.120361, Val Acc: 0.762887\n",
      "Epoch 14762 - Train Loss: 0.097785, Train Acc: 0.852564 | Val Loss: 0.120358, Val Acc: 0.762887\n",
      "Epoch 14763 - Train Loss: 0.097781, Train Acc: 0.852564 | Val Loss: 0.120355, Val Acc: 0.762887\n",
      "Epoch 14764 - Train Loss: 0.097777, Train Acc: 0.852564 | Val Loss: 0.120352, Val Acc: 0.762887\n",
      "Epoch 14765 - Train Loss: 0.097772, Train Acc: 0.852564 | Val Loss: 0.120349, Val Acc: 0.762887\n",
      "Epoch 14766 - Train Loss: 0.097768, Train Acc: 0.852564 | Val Loss: 0.120346, Val Acc: 0.762887\n",
      "Epoch 14767 - Train Loss: 0.097764, Train Acc: 0.852564 | Val Loss: 0.120343, Val Acc: 0.762887\n",
      "Epoch 14768 - Train Loss: 0.097760, Train Acc: 0.852564 | Val Loss: 0.120341, Val Acc: 0.762887\n",
      "Epoch 14769 - Train Loss: 0.097755, Train Acc: 0.852564 | Val Loss: 0.120338, Val Acc: 0.762887\n",
      "Epoch 14770 - Train Loss: 0.097751, Train Acc: 0.852564 | Val Loss: 0.120335, Val Acc: 0.762887\n",
      "Epoch 14771 - Train Loss: 0.097747, Train Acc: 0.852564 | Val Loss: 0.120332, Val Acc: 0.762887\n",
      "Epoch 14772 - Train Loss: 0.097743, Train Acc: 0.852564 | Val Loss: 0.120329, Val Acc: 0.762887\n",
      "Epoch 14773 - Train Loss: 0.097738, Train Acc: 0.852564 | Val Loss: 0.120326, Val Acc: 0.762887\n",
      "Epoch 14774 - Train Loss: 0.097734, Train Acc: 0.852564 | Val Loss: 0.120323, Val Acc: 0.762887\n",
      "Epoch 14775 - Train Loss: 0.097730, Train Acc: 0.852564 | Val Loss: 0.120321, Val Acc: 0.762887\n",
      "Epoch 14776 - Train Loss: 0.097726, Train Acc: 0.852564 | Val Loss: 0.120318, Val Acc: 0.762887\n",
      "Epoch 14777 - Train Loss: 0.097722, Train Acc: 0.852564 | Val Loss: 0.120315, Val Acc: 0.762887\n",
      "Epoch 14778 - Train Loss: 0.097717, Train Acc: 0.852564 | Val Loss: 0.120312, Val Acc: 0.762887\n",
      "Epoch 14779 - Train Loss: 0.097713, Train Acc: 0.852564 | Val Loss: 0.120309, Val Acc: 0.762887\n",
      "Epoch 14780 - Train Loss: 0.097709, Train Acc: 0.852564 | Val Loss: 0.120306, Val Acc: 0.762887\n",
      "Epoch 14781 - Train Loss: 0.097705, Train Acc: 0.852564 | Val Loss: 0.120303, Val Acc: 0.762887\n",
      "Epoch 14782 - Train Loss: 0.097700, Train Acc: 0.852564 | Val Loss: 0.120301, Val Acc: 0.762887\n",
      "Epoch 14783 - Train Loss: 0.097696, Train Acc: 0.852564 | Val Loss: 0.120298, Val Acc: 0.762887\n",
      "Epoch 14784 - Train Loss: 0.097692, Train Acc: 0.852564 | Val Loss: 0.120295, Val Acc: 0.762887\n",
      "Epoch 14785 - Train Loss: 0.097688, Train Acc: 0.852564 | Val Loss: 0.120292, Val Acc: 0.762887\n",
      "Epoch 14786 - Train Loss: 0.097683, Train Acc: 0.852564 | Val Loss: 0.120289, Val Acc: 0.762887\n",
      "Epoch 14787 - Train Loss: 0.097679, Train Acc: 0.852564 | Val Loss: 0.120286, Val Acc: 0.762887\n",
      "Epoch 14788 - Train Loss: 0.097675, Train Acc: 0.852564 | Val Loss: 0.120283, Val Acc: 0.762887\n",
      "Epoch 14789 - Train Loss: 0.097671, Train Acc: 0.852564 | Val Loss: 0.120281, Val Acc: 0.762887\n",
      "Epoch 14790 - Train Loss: 0.097666, Train Acc: 0.852564 | Val Loss: 0.120278, Val Acc: 0.762887\n",
      "Epoch 14791 - Train Loss: 0.097662, Train Acc: 0.852564 | Val Loss: 0.120275, Val Acc: 0.762887\n",
      "Epoch 14792 - Train Loss: 0.097658, Train Acc: 0.852564 | Val Loss: 0.120272, Val Acc: 0.762887\n",
      "Epoch 14793 - Train Loss: 0.097654, Train Acc: 0.852564 | Val Loss: 0.120269, Val Acc: 0.762887\n",
      "Epoch 14794 - Train Loss: 0.097650, Train Acc: 0.852564 | Val Loss: 0.120266, Val Acc: 0.762887\n",
      "Epoch 14795 - Train Loss: 0.097645, Train Acc: 0.852564 | Val Loss: 0.120263, Val Acc: 0.762887\n",
      "Epoch 14796 - Train Loss: 0.097641, Train Acc: 0.852564 | Val Loss: 0.120261, Val Acc: 0.762887\n",
      "Epoch 14797 - Train Loss: 0.097637, Train Acc: 0.852564 | Val Loss: 0.120258, Val Acc: 0.762887\n",
      "Epoch 14798 - Train Loss: 0.097633, Train Acc: 0.852564 | Val Loss: 0.120255, Val Acc: 0.762887\n",
      "Epoch 14799 - Train Loss: 0.097628, Train Acc: 0.852564 | Val Loss: 0.120252, Val Acc: 0.762887\n",
      "Epoch 14800 - Train Loss: 0.097624, Train Acc: 0.853846 | Val Loss: 0.120249, Val Acc: 0.762887\n",
      "Epoch 14801 - Train Loss: 0.097620, Train Acc: 0.853846 | Val Loss: 0.120246, Val Acc: 0.762887\n",
      "Epoch 14802 - Train Loss: 0.097616, Train Acc: 0.853846 | Val Loss: 0.120243, Val Acc: 0.762887\n",
      "Epoch 14803 - Train Loss: 0.097612, Train Acc: 0.853846 | Val Loss: 0.120241, Val Acc: 0.762887\n",
      "Epoch 14804 - Train Loss: 0.097607, Train Acc: 0.853846 | Val Loss: 0.120238, Val Acc: 0.762887\n",
      "Epoch 14805 - Train Loss: 0.097603, Train Acc: 0.853846 | Val Loss: 0.120235, Val Acc: 0.762887\n",
      "Epoch 14806 - Train Loss: 0.097599, Train Acc: 0.853846 | Val Loss: 0.120232, Val Acc: 0.762887\n",
      "Epoch 14807 - Train Loss: 0.097595, Train Acc: 0.853846 | Val Loss: 0.120229, Val Acc: 0.762887\n",
      "Epoch 14808 - Train Loss: 0.097590, Train Acc: 0.855128 | Val Loss: 0.120226, Val Acc: 0.762887\n",
      "Epoch 14809 - Train Loss: 0.097586, Train Acc: 0.855128 | Val Loss: 0.120223, Val Acc: 0.762887\n",
      "Epoch 14810 - Train Loss: 0.097582, Train Acc: 0.855128 | Val Loss: 0.120221, Val Acc: 0.762887\n",
      "Epoch 14811 - Train Loss: 0.097578, Train Acc: 0.855128 | Val Loss: 0.120218, Val Acc: 0.762887\n",
      "Epoch 14812 - Train Loss: 0.097574, Train Acc: 0.855128 | Val Loss: 0.120215, Val Acc: 0.762887\n",
      "Epoch 14813 - Train Loss: 0.097569, Train Acc: 0.855128 | Val Loss: 0.120212, Val Acc: 0.762887\n",
      "Epoch 14814 - Train Loss: 0.097565, Train Acc: 0.855128 | Val Loss: 0.120209, Val Acc: 0.762887\n",
      "Epoch 14815 - Train Loss: 0.097561, Train Acc: 0.855128 | Val Loss: 0.120206, Val Acc: 0.762887\n",
      "Epoch 14816 - Train Loss: 0.097557, Train Acc: 0.855128 | Val Loss: 0.120203, Val Acc: 0.762887\n",
      "Epoch 14817 - Train Loss: 0.097553, Train Acc: 0.855128 | Val Loss: 0.120201, Val Acc: 0.762887\n",
      "Epoch 14818 - Train Loss: 0.097548, Train Acc: 0.855128 | Val Loss: 0.120198, Val Acc: 0.762887\n",
      "Epoch 14819 - Train Loss: 0.097544, Train Acc: 0.855128 | Val Loss: 0.120195, Val Acc: 0.762887\n",
      "Epoch 14820 - Train Loss: 0.097540, Train Acc: 0.855128 | Val Loss: 0.120192, Val Acc: 0.762887\n",
      "Epoch 14821 - Train Loss: 0.097536, Train Acc: 0.855128 | Val Loss: 0.120189, Val Acc: 0.762887\n",
      "Epoch 14822 - Train Loss: 0.097531, Train Acc: 0.855128 | Val Loss: 0.120186, Val Acc: 0.762887\n",
      "Epoch 14823 - Train Loss: 0.097527, Train Acc: 0.855128 | Val Loss: 0.120183, Val Acc: 0.762887\n",
      "Epoch 14824 - Train Loss: 0.097523, Train Acc: 0.855128 | Val Loss: 0.120181, Val Acc: 0.762887\n",
      "Epoch 14825 - Train Loss: 0.097519, Train Acc: 0.855128 | Val Loss: 0.120178, Val Acc: 0.762887\n",
      "Epoch 14826 - Train Loss: 0.097515, Train Acc: 0.855128 | Val Loss: 0.120175, Val Acc: 0.762887\n",
      "Epoch 14827 - Train Loss: 0.097510, Train Acc: 0.855128 | Val Loss: 0.120172, Val Acc: 0.762887\n",
      "Epoch 14828 - Train Loss: 0.097506, Train Acc: 0.855128 | Val Loss: 0.120169, Val Acc: 0.762887\n",
      "Epoch 14829 - Train Loss: 0.097502, Train Acc: 0.855128 | Val Loss: 0.120166, Val Acc: 0.762887\n",
      "Epoch 14830 - Train Loss: 0.097498, Train Acc: 0.855128 | Val Loss: 0.120164, Val Acc: 0.762887\n",
      "Epoch 14831 - Train Loss: 0.097494, Train Acc: 0.855128 | Val Loss: 0.120161, Val Acc: 0.762887\n",
      "Epoch 14832 - Train Loss: 0.097489, Train Acc: 0.855128 | Val Loss: 0.120158, Val Acc: 0.762887\n",
      "Epoch 14833 - Train Loss: 0.097485, Train Acc: 0.855128 | Val Loss: 0.120155, Val Acc: 0.762887\n",
      "Epoch 14834 - Train Loss: 0.097481, Train Acc: 0.855128 | Val Loss: 0.120152, Val Acc: 0.762887\n",
      "Epoch 14835 - Train Loss: 0.097477, Train Acc: 0.855128 | Val Loss: 0.120149, Val Acc: 0.762887\n",
      "Epoch 14836 - Train Loss: 0.097473, Train Acc: 0.855128 | Val Loss: 0.120147, Val Acc: 0.762887\n",
      "Epoch 14837 - Train Loss: 0.097468, Train Acc: 0.855128 | Val Loss: 0.120144, Val Acc: 0.762887\n",
      "Epoch 14838 - Train Loss: 0.097464, Train Acc: 0.855128 | Val Loss: 0.120141, Val Acc: 0.762887\n",
      "Epoch 14839 - Train Loss: 0.097460, Train Acc: 0.855128 | Val Loss: 0.120138, Val Acc: 0.762887\n",
      "Epoch 14840 - Train Loss: 0.097456, Train Acc: 0.855128 | Val Loss: 0.120135, Val Acc: 0.762887\n",
      "Epoch 14841 - Train Loss: 0.097452, Train Acc: 0.855128 | Val Loss: 0.120132, Val Acc: 0.762887\n",
      "Epoch 14842 - Train Loss: 0.097447, Train Acc: 0.855128 | Val Loss: 0.120129, Val Acc: 0.762887\n",
      "Epoch 14843 - Train Loss: 0.097443, Train Acc: 0.855128 | Val Loss: 0.120127, Val Acc: 0.762887\n",
      "Epoch 14844 - Train Loss: 0.097439, Train Acc: 0.855128 | Val Loss: 0.120124, Val Acc: 0.762887\n",
      "Epoch 14845 - Train Loss: 0.097435, Train Acc: 0.855128 | Val Loss: 0.120121, Val Acc: 0.762887\n",
      "Epoch 14846 - Train Loss: 0.097431, Train Acc: 0.855128 | Val Loss: 0.120118, Val Acc: 0.762887\n",
      "Epoch 14847 - Train Loss: 0.097426, Train Acc: 0.855128 | Val Loss: 0.120115, Val Acc: 0.762887\n",
      "Epoch 14848 - Train Loss: 0.097422, Train Acc: 0.855128 | Val Loss: 0.120113, Val Acc: 0.762887\n",
      "Epoch 14849 - Train Loss: 0.097418, Train Acc: 0.855128 | Val Loss: 0.120110, Val Acc: 0.762887\n",
      "Epoch 14850 - Train Loss: 0.097414, Train Acc: 0.855128 | Val Loss: 0.120107, Val Acc: 0.762887\n",
      "Epoch 14851 - Train Loss: 0.097410, Train Acc: 0.855128 | Val Loss: 0.120104, Val Acc: 0.762887\n",
      "Epoch 14852 - Train Loss: 0.097405, Train Acc: 0.855128 | Val Loss: 0.120101, Val Acc: 0.762887\n",
      "Epoch 14853 - Train Loss: 0.097401, Train Acc: 0.855128 | Val Loss: 0.120098, Val Acc: 0.762887\n",
      "Epoch 14854 - Train Loss: 0.097397, Train Acc: 0.855128 | Val Loss: 0.120096, Val Acc: 0.762887\n",
      "Epoch 14855 - Train Loss: 0.097393, Train Acc: 0.855128 | Val Loss: 0.120093, Val Acc: 0.762887\n",
      "Epoch 14856 - Train Loss: 0.097389, Train Acc: 0.855128 | Val Loss: 0.120090, Val Acc: 0.762887\n",
      "Epoch 14857 - Train Loss: 0.097384, Train Acc: 0.855128 | Val Loss: 0.120087, Val Acc: 0.762887\n",
      "Epoch 14858 - Train Loss: 0.097380, Train Acc: 0.855128 | Val Loss: 0.120084, Val Acc: 0.762887\n",
      "Epoch 14859 - Train Loss: 0.097376, Train Acc: 0.855128 | Val Loss: 0.120081, Val Acc: 0.762887\n",
      "Epoch 14860 - Train Loss: 0.097372, Train Acc: 0.855128 | Val Loss: 0.120079, Val Acc: 0.762887\n",
      "Epoch 14861 - Train Loss: 0.097368, Train Acc: 0.855128 | Val Loss: 0.120076, Val Acc: 0.762887\n",
      "Epoch 14862 - Train Loss: 0.097363, Train Acc: 0.855128 | Val Loss: 0.120073, Val Acc: 0.762887\n",
      "Epoch 14863 - Train Loss: 0.097359, Train Acc: 0.855128 | Val Loss: 0.120070, Val Acc: 0.762887\n",
      "Epoch 14864 - Train Loss: 0.097355, Train Acc: 0.855128 | Val Loss: 0.120067, Val Acc: 0.762887\n",
      "Epoch 14865 - Train Loss: 0.097351, Train Acc: 0.855128 | Val Loss: 0.120065, Val Acc: 0.762887\n",
      "Epoch 14866 - Train Loss: 0.097347, Train Acc: 0.855128 | Val Loss: 0.120062, Val Acc: 0.762887\n",
      "Epoch 14867 - Train Loss: 0.097343, Train Acc: 0.855128 | Val Loss: 0.120059, Val Acc: 0.762887\n",
      "Epoch 14868 - Train Loss: 0.097338, Train Acc: 0.855128 | Val Loss: 0.120056, Val Acc: 0.762887\n",
      "Epoch 14869 - Train Loss: 0.097334, Train Acc: 0.855128 | Val Loss: 0.120053, Val Acc: 0.762887\n",
      "Epoch 14870 - Train Loss: 0.097330, Train Acc: 0.855128 | Val Loss: 0.120051, Val Acc: 0.762887\n",
      "Epoch 14871 - Train Loss: 0.097326, Train Acc: 0.855128 | Val Loss: 0.120048, Val Acc: 0.762887\n",
      "Epoch 14872 - Train Loss: 0.097322, Train Acc: 0.855128 | Val Loss: 0.120045, Val Acc: 0.762887\n",
      "Epoch 14873 - Train Loss: 0.097317, Train Acc: 0.855128 | Val Loss: 0.120042, Val Acc: 0.762887\n",
      "Epoch 14874 - Train Loss: 0.097313, Train Acc: 0.855128 | Val Loss: 0.120039, Val Acc: 0.762887\n",
      "Epoch 14875 - Train Loss: 0.097309, Train Acc: 0.855128 | Val Loss: 0.120036, Val Acc: 0.762887\n",
      "Epoch 14876 - Train Loss: 0.097305, Train Acc: 0.855128 | Val Loss: 0.120034, Val Acc: 0.762887\n",
      "Epoch 14877 - Train Loss: 0.097301, Train Acc: 0.855128 | Val Loss: 0.120031, Val Acc: 0.762887\n",
      "Epoch 14878 - Train Loss: 0.097297, Train Acc: 0.855128 | Val Loss: 0.120028, Val Acc: 0.762887\n",
      "Epoch 14879 - Train Loss: 0.097292, Train Acc: 0.855128 | Val Loss: 0.120025, Val Acc: 0.762887\n",
      "Epoch 14880 - Train Loss: 0.097288, Train Acc: 0.855128 | Val Loss: 0.120022, Val Acc: 0.762887\n",
      "Epoch 14881 - Train Loss: 0.097284, Train Acc: 0.855128 | Val Loss: 0.120020, Val Acc: 0.762887\n",
      "Epoch 14882 - Train Loss: 0.097280, Train Acc: 0.855128 | Val Loss: 0.120017, Val Acc: 0.762887\n",
      "Epoch 14883 - Train Loss: 0.097276, Train Acc: 0.855128 | Val Loss: 0.120014, Val Acc: 0.762887\n",
      "Epoch 14884 - Train Loss: 0.097271, Train Acc: 0.855128 | Val Loss: 0.120011, Val Acc: 0.762887\n",
      "Epoch 14885 - Train Loss: 0.097267, Train Acc: 0.855128 | Val Loss: 0.120008, Val Acc: 0.762887\n",
      "Epoch 14886 - Train Loss: 0.097263, Train Acc: 0.855128 | Val Loss: 0.120006, Val Acc: 0.762887\n",
      "Epoch 14887 - Train Loss: 0.097259, Train Acc: 0.855128 | Val Loss: 0.120003, Val Acc: 0.762887\n",
      "Epoch 14888 - Train Loss: 0.097255, Train Acc: 0.855128 | Val Loss: 0.120000, Val Acc: 0.762887\n",
      "Epoch 14889 - Train Loss: 0.097251, Train Acc: 0.855128 | Val Loss: 0.119997, Val Acc: 0.762887\n",
      "Epoch 14890 - Train Loss: 0.097246, Train Acc: 0.855128 | Val Loss: 0.119994, Val Acc: 0.762887\n",
      "Epoch 14891 - Train Loss: 0.097242, Train Acc: 0.855128 | Val Loss: 0.119992, Val Acc: 0.762887\n",
      "Epoch 14892 - Train Loss: 0.097238, Train Acc: 0.855128 | Val Loss: 0.119989, Val Acc: 0.762887\n",
      "Epoch 14893 - Train Loss: 0.097234, Train Acc: 0.855128 | Val Loss: 0.119986, Val Acc: 0.762887\n",
      "Epoch 14894 - Train Loss: 0.097230, Train Acc: 0.855128 | Val Loss: 0.119983, Val Acc: 0.762887\n",
      "Epoch 14895 - Train Loss: 0.097226, Train Acc: 0.855128 | Val Loss: 0.119980, Val Acc: 0.762887\n",
      "Epoch 14896 - Train Loss: 0.097221, Train Acc: 0.855128 | Val Loss: 0.119978, Val Acc: 0.762887\n",
      "Epoch 14897 - Train Loss: 0.097217, Train Acc: 0.855128 | Val Loss: 0.119975, Val Acc: 0.762887\n",
      "Epoch 14898 - Train Loss: 0.097213, Train Acc: 0.855128 | Val Loss: 0.119972, Val Acc: 0.762887\n",
      "Epoch 14899 - Train Loss: 0.097209, Train Acc: 0.855128 | Val Loss: 0.119969, Val Acc: 0.762887\n",
      "Epoch 14900 - Train Loss: 0.097205, Train Acc: 0.855128 | Val Loss: 0.119966, Val Acc: 0.762887\n",
      "Epoch 14901 - Train Loss: 0.097201, Train Acc: 0.855128 | Val Loss: 0.119964, Val Acc: 0.762887\n",
      "Epoch 14902 - Train Loss: 0.097196, Train Acc: 0.855128 | Val Loss: 0.119961, Val Acc: 0.762887\n",
      "Epoch 14903 - Train Loss: 0.097192, Train Acc: 0.856410 | Val Loss: 0.119958, Val Acc: 0.762887\n",
      "Epoch 14904 - Train Loss: 0.097188, Train Acc: 0.856410 | Val Loss: 0.119955, Val Acc: 0.762887\n",
      "Epoch 14905 - Train Loss: 0.097184, Train Acc: 0.856410 | Val Loss: 0.119953, Val Acc: 0.762887\n",
      "Epoch 14906 - Train Loss: 0.097180, Train Acc: 0.856410 | Val Loss: 0.119950, Val Acc: 0.762887\n",
      "Epoch 14907 - Train Loss: 0.097176, Train Acc: 0.856410 | Val Loss: 0.119947, Val Acc: 0.762887\n",
      "Epoch 14908 - Train Loss: 0.097171, Train Acc: 0.856410 | Val Loss: 0.119944, Val Acc: 0.762887\n",
      "Epoch 14909 - Train Loss: 0.097167, Train Acc: 0.856410 | Val Loss: 0.119941, Val Acc: 0.762887\n",
      "Epoch 14910 - Train Loss: 0.097163, Train Acc: 0.856410 | Val Loss: 0.119939, Val Acc: 0.762887\n",
      "Epoch 14911 - Train Loss: 0.097159, Train Acc: 0.856410 | Val Loss: 0.119936, Val Acc: 0.762887\n",
      "Epoch 14912 - Train Loss: 0.097155, Train Acc: 0.856410 | Val Loss: 0.119933, Val Acc: 0.762887\n",
      "Epoch 14913 - Train Loss: 0.097151, Train Acc: 0.856410 | Val Loss: 0.119930, Val Acc: 0.762887\n",
      "Epoch 14914 - Train Loss: 0.097146, Train Acc: 0.856410 | Val Loss: 0.119927, Val Acc: 0.762887\n",
      "Epoch 14915 - Train Loss: 0.097142, Train Acc: 0.856410 | Val Loss: 0.119925, Val Acc: 0.762887\n",
      "Epoch 14916 - Train Loss: 0.097138, Train Acc: 0.856410 | Val Loss: 0.119922, Val Acc: 0.762887\n",
      "Epoch 14917 - Train Loss: 0.097134, Train Acc: 0.856410 | Val Loss: 0.119919, Val Acc: 0.762887\n",
      "Epoch 14918 - Train Loss: 0.097130, Train Acc: 0.856410 | Val Loss: 0.119916, Val Acc: 0.762887\n",
      "Epoch 14919 - Train Loss: 0.097126, Train Acc: 0.856410 | Val Loss: 0.119914, Val Acc: 0.762887\n",
      "Epoch 14920 - Train Loss: 0.097121, Train Acc: 0.856410 | Val Loss: 0.119911, Val Acc: 0.762887\n",
      "Epoch 14921 - Train Loss: 0.097117, Train Acc: 0.856410 | Val Loss: 0.119908, Val Acc: 0.762887\n",
      "Epoch 14922 - Train Loss: 0.097113, Train Acc: 0.856410 | Val Loss: 0.119905, Val Acc: 0.762887\n",
      "Epoch 14923 - Train Loss: 0.097109, Train Acc: 0.856410 | Val Loss: 0.119902, Val Acc: 0.762887\n",
      "Epoch 14924 - Train Loss: 0.097105, Train Acc: 0.856410 | Val Loss: 0.119900, Val Acc: 0.762887\n",
      "Epoch 14925 - Train Loss: 0.097101, Train Acc: 0.856410 | Val Loss: 0.119897, Val Acc: 0.762887\n",
      "Epoch 14926 - Train Loss: 0.097097, Train Acc: 0.856410 | Val Loss: 0.119894, Val Acc: 0.762887\n",
      "Epoch 14927 - Train Loss: 0.097092, Train Acc: 0.856410 | Val Loss: 0.119891, Val Acc: 0.762887\n",
      "Epoch 14928 - Train Loss: 0.097088, Train Acc: 0.856410 | Val Loss: 0.119888, Val Acc: 0.762887\n",
      "Epoch 14929 - Train Loss: 0.097084, Train Acc: 0.856410 | Val Loss: 0.119886, Val Acc: 0.762887\n",
      "Epoch 14930 - Train Loss: 0.097080, Train Acc: 0.856410 | Val Loss: 0.119883, Val Acc: 0.762887\n",
      "Epoch 14931 - Train Loss: 0.097076, Train Acc: 0.856410 | Val Loss: 0.119880, Val Acc: 0.762887\n",
      "Epoch 14932 - Train Loss: 0.097072, Train Acc: 0.856410 | Val Loss: 0.119877, Val Acc: 0.762887\n",
      "Epoch 14933 - Train Loss: 0.097067, Train Acc: 0.856410 | Val Loss: 0.119875, Val Acc: 0.762887\n",
      "Epoch 14934 - Train Loss: 0.097063, Train Acc: 0.856410 | Val Loss: 0.119872, Val Acc: 0.762887\n",
      "Epoch 14935 - Train Loss: 0.097059, Train Acc: 0.856410 | Val Loss: 0.119869, Val Acc: 0.762887\n",
      "Epoch 14936 - Train Loss: 0.097055, Train Acc: 0.856410 | Val Loss: 0.119866, Val Acc: 0.762887\n",
      "Epoch 14937 - Train Loss: 0.097051, Train Acc: 0.856410 | Val Loss: 0.119864, Val Acc: 0.762887\n",
      "Epoch 14938 - Train Loss: 0.097047, Train Acc: 0.856410 | Val Loss: 0.119861, Val Acc: 0.762887\n",
      "Epoch 14939 - Train Loss: 0.097043, Train Acc: 0.856410 | Val Loss: 0.119858, Val Acc: 0.762887\n",
      "Epoch 14940 - Train Loss: 0.097038, Train Acc: 0.856410 | Val Loss: 0.119855, Val Acc: 0.762887\n",
      "Epoch 14941 - Train Loss: 0.097034, Train Acc: 0.856410 | Val Loss: 0.119852, Val Acc: 0.762887\n",
      "Epoch 14942 - Train Loss: 0.097030, Train Acc: 0.856410 | Val Loss: 0.119850, Val Acc: 0.762887\n",
      "Epoch 14943 - Train Loss: 0.097026, Train Acc: 0.856410 | Val Loss: 0.119847, Val Acc: 0.762887\n",
      "Epoch 14944 - Train Loss: 0.097022, Train Acc: 0.856410 | Val Loss: 0.119844, Val Acc: 0.762887\n",
      "Epoch 14945 - Train Loss: 0.097018, Train Acc: 0.856410 | Val Loss: 0.119841, Val Acc: 0.762887\n",
      "Epoch 14946 - Train Loss: 0.097014, Train Acc: 0.856410 | Val Loss: 0.119839, Val Acc: 0.762887\n",
      "Epoch 14947 - Train Loss: 0.097009, Train Acc: 0.856410 | Val Loss: 0.119836, Val Acc: 0.762887\n",
      "Epoch 14948 - Train Loss: 0.097005, Train Acc: 0.856410 | Val Loss: 0.119833, Val Acc: 0.762887\n",
      "Epoch 14949 - Train Loss: 0.097001, Train Acc: 0.856410 | Val Loss: 0.119830, Val Acc: 0.762887\n",
      "Epoch 14950 - Train Loss: 0.096997, Train Acc: 0.856410 | Val Loss: 0.119828, Val Acc: 0.762887\n",
      "Epoch 14951 - Train Loss: 0.096993, Train Acc: 0.856410 | Val Loss: 0.119825, Val Acc: 0.762887\n",
      "Epoch 14952 - Train Loss: 0.096989, Train Acc: 0.856410 | Val Loss: 0.119822, Val Acc: 0.762887\n",
      "Epoch 14953 - Train Loss: 0.096985, Train Acc: 0.856410 | Val Loss: 0.119819, Val Acc: 0.762887\n",
      "Epoch 14954 - Train Loss: 0.096980, Train Acc: 0.856410 | Val Loss: 0.119816, Val Acc: 0.762887\n",
      "Epoch 14955 - Train Loss: 0.096976, Train Acc: 0.857692 | Val Loss: 0.119814, Val Acc: 0.762887\n",
      "Epoch 14956 - Train Loss: 0.096972, Train Acc: 0.857692 | Val Loss: 0.119811, Val Acc: 0.762887\n",
      "Epoch 14957 - Train Loss: 0.096968, Train Acc: 0.857692 | Val Loss: 0.119808, Val Acc: 0.762887\n",
      "Epoch 14958 - Train Loss: 0.096964, Train Acc: 0.857692 | Val Loss: 0.119805, Val Acc: 0.762887\n",
      "Epoch 14959 - Train Loss: 0.096960, Train Acc: 0.857692 | Val Loss: 0.119803, Val Acc: 0.762887\n",
      "Epoch 14960 - Train Loss: 0.096956, Train Acc: 0.857692 | Val Loss: 0.119800, Val Acc: 0.762887\n",
      "Epoch 14961 - Train Loss: 0.096951, Train Acc: 0.857692 | Val Loss: 0.119797, Val Acc: 0.762887\n",
      "Epoch 14962 - Train Loss: 0.096947, Train Acc: 0.857692 | Val Loss: 0.119794, Val Acc: 0.762887\n",
      "Epoch 14963 - Train Loss: 0.096943, Train Acc: 0.857692 | Val Loss: 0.119792, Val Acc: 0.762887\n",
      "Epoch 14964 - Train Loss: 0.096939, Train Acc: 0.857692 | Val Loss: 0.119789, Val Acc: 0.762887\n",
      "Epoch 14965 - Train Loss: 0.096935, Train Acc: 0.858974 | Val Loss: 0.119786, Val Acc: 0.762887\n",
      "Epoch 14966 - Train Loss: 0.096931, Train Acc: 0.858974 | Val Loss: 0.119783, Val Acc: 0.762887\n",
      "Epoch 14967 - Train Loss: 0.096927, Train Acc: 0.858974 | Val Loss: 0.119781, Val Acc: 0.762887\n",
      "Epoch 14968 - Train Loss: 0.096923, Train Acc: 0.858974 | Val Loss: 0.119778, Val Acc: 0.762887\n",
      "Epoch 14969 - Train Loss: 0.096918, Train Acc: 0.858974 | Val Loss: 0.119775, Val Acc: 0.762887\n",
      "Epoch 14970 - Train Loss: 0.096914, Train Acc: 0.858974 | Val Loss: 0.119772, Val Acc: 0.762887\n",
      "Epoch 14971 - Train Loss: 0.096910, Train Acc: 0.858974 | Val Loss: 0.119770, Val Acc: 0.762887\n",
      "Epoch 14972 - Train Loss: 0.096906, Train Acc: 0.858974 | Val Loss: 0.119767, Val Acc: 0.762887\n",
      "Epoch 14973 - Train Loss: 0.096902, Train Acc: 0.858974 | Val Loss: 0.119764, Val Acc: 0.762887\n",
      "Epoch 14974 - Train Loss: 0.096898, Train Acc: 0.858974 | Val Loss: 0.119761, Val Acc: 0.762887\n",
      "Epoch 14975 - Train Loss: 0.096894, Train Acc: 0.858974 | Val Loss: 0.119759, Val Acc: 0.762887\n",
      "Epoch 14976 - Train Loss: 0.096890, Train Acc: 0.858974 | Val Loss: 0.119756, Val Acc: 0.762887\n",
      "Epoch 14977 - Train Loss: 0.096885, Train Acc: 0.858974 | Val Loss: 0.119753, Val Acc: 0.762887\n",
      "Epoch 14978 - Train Loss: 0.096881, Train Acc: 0.858974 | Val Loss: 0.119750, Val Acc: 0.762887\n",
      "Epoch 14979 - Train Loss: 0.096877, Train Acc: 0.858974 | Val Loss: 0.119748, Val Acc: 0.762887\n",
      "Epoch 14980 - Train Loss: 0.096873, Train Acc: 0.858974 | Val Loss: 0.119745, Val Acc: 0.762887\n",
      "Epoch 14981 - Train Loss: 0.096869, Train Acc: 0.858974 | Val Loss: 0.119742, Val Acc: 0.762887\n",
      "Epoch 14982 - Train Loss: 0.096865, Train Acc: 0.858974 | Val Loss: 0.119739, Val Acc: 0.762887\n",
      "Epoch 14983 - Train Loss: 0.096861, Train Acc: 0.858974 | Val Loss: 0.119737, Val Acc: 0.762887\n",
      "Epoch 14984 - Train Loss: 0.096857, Train Acc: 0.858974 | Val Loss: 0.119734, Val Acc: 0.762887\n",
      "Epoch 14985 - Train Loss: 0.096852, Train Acc: 0.858974 | Val Loss: 0.119731, Val Acc: 0.762887\n",
      "Epoch 14986 - Train Loss: 0.096848, Train Acc: 0.858974 | Val Loss: 0.119728, Val Acc: 0.762887\n",
      "Epoch 14987 - Train Loss: 0.096844, Train Acc: 0.858974 | Val Loss: 0.119726, Val Acc: 0.762887\n",
      "Epoch 14988 - Train Loss: 0.096840, Train Acc: 0.858974 | Val Loss: 0.119723, Val Acc: 0.762887\n",
      "Epoch 14989 - Train Loss: 0.096836, Train Acc: 0.858974 | Val Loss: 0.119720, Val Acc: 0.762887\n",
      "Epoch 14990 - Train Loss: 0.096832, Train Acc: 0.858974 | Val Loss: 0.119717, Val Acc: 0.762887\n",
      "Epoch 14991 - Train Loss: 0.096828, Train Acc: 0.858974 | Val Loss: 0.119715, Val Acc: 0.762887\n",
      "Epoch 14992 - Train Loss: 0.096824, Train Acc: 0.858974 | Val Loss: 0.119712, Val Acc: 0.762887\n",
      "Epoch 14993 - Train Loss: 0.096819, Train Acc: 0.858974 | Val Loss: 0.119709, Val Acc: 0.762887\n",
      "Epoch 14994 - Train Loss: 0.096815, Train Acc: 0.858974 | Val Loss: 0.119706, Val Acc: 0.762887\n",
      "Epoch 14995 - Train Loss: 0.096811, Train Acc: 0.858974 | Val Loss: 0.119704, Val Acc: 0.762887\n",
      "Epoch 14996 - Train Loss: 0.096807, Train Acc: 0.858974 | Val Loss: 0.119701, Val Acc: 0.762887\n",
      "Epoch 14997 - Train Loss: 0.096803, Train Acc: 0.858974 | Val Loss: 0.119698, Val Acc: 0.762887\n",
      "Epoch 14998 - Train Loss: 0.096799, Train Acc: 0.858974 | Val Loss: 0.119695, Val Acc: 0.762887\n",
      "Epoch 14999 - Train Loss: 0.096795, Train Acc: 0.858974 | Val Loss: 0.119693, Val Acc: 0.762887\n",
      "Epoch 15000 - Train Loss: 0.096791, Train Acc: 0.858974 | Val Loss: 0.119690, Val Acc: 0.762887\n",
      "Epoch 15001 - Train Loss: 0.096787, Train Acc: 0.858974 | Val Loss: 0.119687, Val Acc: 0.762887\n",
      "Epoch 15002 - Train Loss: 0.096782, Train Acc: 0.858974 | Val Loss: 0.119684, Val Acc: 0.762887\n",
      "Epoch 15003 - Train Loss: 0.096778, Train Acc: 0.858974 | Val Loss: 0.119682, Val Acc: 0.762887\n",
      "Epoch 15004 - Train Loss: 0.096774, Train Acc: 0.858974 | Val Loss: 0.119679, Val Acc: 0.762887\n",
      "Epoch 15005 - Train Loss: 0.096770, Train Acc: 0.858974 | Val Loss: 0.119676, Val Acc: 0.762887\n",
      "Epoch 15006 - Train Loss: 0.096766, Train Acc: 0.858974 | Val Loss: 0.119674, Val Acc: 0.762887\n",
      "Epoch 15007 - Train Loss: 0.096762, Train Acc: 0.858974 | Val Loss: 0.119671, Val Acc: 0.762887\n",
      "Epoch 15008 - Train Loss: 0.096758, Train Acc: 0.858974 | Val Loss: 0.119668, Val Acc: 0.762887\n",
      "Epoch 15009 - Train Loss: 0.096754, Train Acc: 0.858974 | Val Loss: 0.119665, Val Acc: 0.762887\n",
      "Epoch 15010 - Train Loss: 0.096750, Train Acc: 0.858974 | Val Loss: 0.119663, Val Acc: 0.762887\n",
      "Epoch 15011 - Train Loss: 0.096745, Train Acc: 0.858974 | Val Loss: 0.119660, Val Acc: 0.762887\n",
      "Epoch 15012 - Train Loss: 0.096741, Train Acc: 0.858974 | Val Loss: 0.119657, Val Acc: 0.762887\n",
      "Epoch 15013 - Train Loss: 0.096737, Train Acc: 0.858974 | Val Loss: 0.119654, Val Acc: 0.762887\n",
      "Epoch 15014 - Train Loss: 0.096733, Train Acc: 0.858974 | Val Loss: 0.119652, Val Acc: 0.762887\n",
      "Epoch 15015 - Train Loss: 0.096729, Train Acc: 0.858974 | Val Loss: 0.119649, Val Acc: 0.762887\n",
      "Epoch 15016 - Train Loss: 0.096725, Train Acc: 0.858974 | Val Loss: 0.119646, Val Acc: 0.762887\n",
      "Epoch 15017 - Train Loss: 0.096721, Train Acc: 0.858974 | Val Loss: 0.119643, Val Acc: 0.762887\n",
      "Epoch 15018 - Train Loss: 0.096717, Train Acc: 0.858974 | Val Loss: 0.119641, Val Acc: 0.762887\n",
      "Epoch 15019 - Train Loss: 0.096713, Train Acc: 0.858974 | Val Loss: 0.119638, Val Acc: 0.762887\n",
      "Epoch 15020 - Train Loss: 0.096708, Train Acc: 0.858974 | Val Loss: 0.119635, Val Acc: 0.762887\n",
      "Epoch 15021 - Train Loss: 0.096704, Train Acc: 0.858974 | Val Loss: 0.119633, Val Acc: 0.762887\n",
      "Epoch 15022 - Train Loss: 0.096700, Train Acc: 0.858974 | Val Loss: 0.119630, Val Acc: 0.762887\n",
      "Epoch 15023 - Train Loss: 0.096696, Train Acc: 0.858974 | Val Loss: 0.119627, Val Acc: 0.762887\n",
      "Epoch 15024 - Train Loss: 0.096692, Train Acc: 0.858974 | Val Loss: 0.119624, Val Acc: 0.762887\n",
      "Epoch 15025 - Train Loss: 0.096688, Train Acc: 0.858974 | Val Loss: 0.119622, Val Acc: 0.762887\n",
      "Epoch 15026 - Train Loss: 0.096684, Train Acc: 0.858974 | Val Loss: 0.119619, Val Acc: 0.762887\n",
      "Epoch 15027 - Train Loss: 0.096680, Train Acc: 0.858974 | Val Loss: 0.119616, Val Acc: 0.762887\n",
      "Epoch 15028 - Train Loss: 0.096676, Train Acc: 0.858974 | Val Loss: 0.119614, Val Acc: 0.762887\n",
      "Epoch 15029 - Train Loss: 0.096672, Train Acc: 0.858974 | Val Loss: 0.119611, Val Acc: 0.762887\n",
      "Epoch 15030 - Train Loss: 0.096667, Train Acc: 0.858974 | Val Loss: 0.119608, Val Acc: 0.762887\n",
      "Epoch 15031 - Train Loss: 0.096663, Train Acc: 0.858974 | Val Loss: 0.119605, Val Acc: 0.762887\n",
      "Epoch 15032 - Train Loss: 0.096659, Train Acc: 0.858974 | Val Loss: 0.119603, Val Acc: 0.762887\n",
      "Epoch 15033 - Train Loss: 0.096655, Train Acc: 0.858974 | Val Loss: 0.119600, Val Acc: 0.762887\n",
      "Epoch 15034 - Train Loss: 0.096651, Train Acc: 0.858974 | Val Loss: 0.119597, Val Acc: 0.762887\n",
      "Epoch 15035 - Train Loss: 0.096647, Train Acc: 0.858974 | Val Loss: 0.119594, Val Acc: 0.762887\n",
      "Epoch 15036 - Train Loss: 0.096643, Train Acc: 0.858974 | Val Loss: 0.119592, Val Acc: 0.762887\n",
      "Epoch 15037 - Train Loss: 0.096639, Train Acc: 0.858974 | Val Loss: 0.119589, Val Acc: 0.762887\n",
      "Epoch 15038 - Train Loss: 0.096635, Train Acc: 0.858974 | Val Loss: 0.119586, Val Acc: 0.762887\n",
      "Epoch 15039 - Train Loss: 0.096631, Train Acc: 0.858974 | Val Loss: 0.119584, Val Acc: 0.762887\n",
      "Epoch 15040 - Train Loss: 0.096627, Train Acc: 0.858974 | Val Loss: 0.119581, Val Acc: 0.762887\n",
      "Epoch 15041 - Train Loss: 0.096622, Train Acc: 0.858974 | Val Loss: 0.119578, Val Acc: 0.762887\n",
      "Epoch 15042 - Train Loss: 0.096618, Train Acc: 0.858974 | Val Loss: 0.119575, Val Acc: 0.762887\n",
      "Epoch 15043 - Train Loss: 0.096614, Train Acc: 0.858974 | Val Loss: 0.119573, Val Acc: 0.762887\n",
      "Epoch 15044 - Train Loss: 0.096610, Train Acc: 0.858974 | Val Loss: 0.119570, Val Acc: 0.762887\n",
      "Epoch 15045 - Train Loss: 0.096606, Train Acc: 0.858974 | Val Loss: 0.119567, Val Acc: 0.762887\n",
      "Epoch 15046 - Train Loss: 0.096602, Train Acc: 0.858974 | Val Loss: 0.119565, Val Acc: 0.762887\n",
      "Epoch 15047 - Train Loss: 0.096598, Train Acc: 0.858974 | Val Loss: 0.119562, Val Acc: 0.762887\n",
      "Epoch 15048 - Train Loss: 0.096594, Train Acc: 0.858974 | Val Loss: 0.119559, Val Acc: 0.762887\n",
      "Epoch 15049 - Train Loss: 0.096590, Train Acc: 0.858974 | Val Loss: 0.119556, Val Acc: 0.762887\n",
      "Epoch 15050 - Train Loss: 0.096586, Train Acc: 0.858974 | Val Loss: 0.119554, Val Acc: 0.762887\n",
      "Epoch 15051 - Train Loss: 0.096582, Train Acc: 0.858974 | Val Loss: 0.119551, Val Acc: 0.762887\n",
      "Epoch 15052 - Train Loss: 0.096577, Train Acc: 0.858974 | Val Loss: 0.119548, Val Acc: 0.762887\n",
      "Epoch 15053 - Train Loss: 0.096573, Train Acc: 0.858974 | Val Loss: 0.119546, Val Acc: 0.762887\n",
      "Epoch 15054 - Train Loss: 0.096569, Train Acc: 0.858974 | Val Loss: 0.119543, Val Acc: 0.762887\n",
      "Epoch 15055 - Train Loss: 0.096565, Train Acc: 0.860256 | Val Loss: 0.119540, Val Acc: 0.762887\n",
      "Epoch 15056 - Train Loss: 0.096561, Train Acc: 0.860256 | Val Loss: 0.119537, Val Acc: 0.762887\n",
      "Epoch 15057 - Train Loss: 0.096557, Train Acc: 0.860256 | Val Loss: 0.119535, Val Acc: 0.762887\n",
      "Epoch 15058 - Train Loss: 0.096553, Train Acc: 0.860256 | Val Loss: 0.119532, Val Acc: 0.762887\n",
      "Epoch 15059 - Train Loss: 0.096549, Train Acc: 0.860256 | Val Loss: 0.119529, Val Acc: 0.762887\n",
      "Epoch 15060 - Train Loss: 0.096545, Train Acc: 0.860256 | Val Loss: 0.119527, Val Acc: 0.762887\n",
      "Epoch 15061 - Train Loss: 0.096541, Train Acc: 0.860256 | Val Loss: 0.119524, Val Acc: 0.762887\n",
      "Epoch 15062 - Train Loss: 0.096537, Train Acc: 0.860256 | Val Loss: 0.119521, Val Acc: 0.762887\n",
      "Epoch 15063 - Train Loss: 0.096533, Train Acc: 0.860256 | Val Loss: 0.119518, Val Acc: 0.762887\n",
      "Epoch 15064 - Train Loss: 0.096528, Train Acc: 0.860256 | Val Loss: 0.119516, Val Acc: 0.762887\n",
      "Epoch 15065 - Train Loss: 0.096524, Train Acc: 0.860256 | Val Loss: 0.119513, Val Acc: 0.762887\n",
      "Epoch 15066 - Train Loss: 0.096520, Train Acc: 0.860256 | Val Loss: 0.119510, Val Acc: 0.762887\n",
      "Epoch 15067 - Train Loss: 0.096516, Train Acc: 0.860256 | Val Loss: 0.119508, Val Acc: 0.762887\n",
      "Epoch 15068 - Train Loss: 0.096512, Train Acc: 0.860256 | Val Loss: 0.119505, Val Acc: 0.762887\n",
      "Epoch 15069 - Train Loss: 0.096508, Train Acc: 0.860256 | Val Loss: 0.119502, Val Acc: 0.762887\n",
      "Epoch 15070 - Train Loss: 0.096504, Train Acc: 0.860256 | Val Loss: 0.119500, Val Acc: 0.762887\n",
      "Epoch 15071 - Train Loss: 0.096500, Train Acc: 0.860256 | Val Loss: 0.119497, Val Acc: 0.762887\n",
      "Epoch 15072 - Train Loss: 0.096496, Train Acc: 0.860256 | Val Loss: 0.119494, Val Acc: 0.762887\n",
      "Epoch 15073 - Train Loss: 0.096492, Train Acc: 0.860256 | Val Loss: 0.119491, Val Acc: 0.762887\n",
      "Epoch 15074 - Train Loss: 0.096488, Train Acc: 0.860256 | Val Loss: 0.119489, Val Acc: 0.762887\n",
      "Epoch 15075 - Train Loss: 0.096484, Train Acc: 0.860256 | Val Loss: 0.119486, Val Acc: 0.762887\n",
      "Epoch 15076 - Train Loss: 0.096480, Train Acc: 0.860256 | Val Loss: 0.119483, Val Acc: 0.762887\n",
      "Epoch 15077 - Train Loss: 0.096475, Train Acc: 0.860256 | Val Loss: 0.119481, Val Acc: 0.762887\n",
      "Epoch 15078 - Train Loss: 0.096471, Train Acc: 0.860256 | Val Loss: 0.119478, Val Acc: 0.762887\n",
      "Epoch 15079 - Train Loss: 0.096467, Train Acc: 0.860256 | Val Loss: 0.119475, Val Acc: 0.762887\n",
      "Epoch 15080 - Train Loss: 0.096463, Train Acc: 0.860256 | Val Loss: 0.119473, Val Acc: 0.762887\n",
      "Epoch 15081 - Train Loss: 0.096459, Train Acc: 0.860256 | Val Loss: 0.119470, Val Acc: 0.762887\n",
      "Epoch 15082 - Train Loss: 0.096455, Train Acc: 0.860256 | Val Loss: 0.119467, Val Acc: 0.762887\n",
      "Epoch 15083 - Train Loss: 0.096451, Train Acc: 0.860256 | Val Loss: 0.119464, Val Acc: 0.762887\n",
      "Epoch 15084 - Train Loss: 0.096447, Train Acc: 0.860256 | Val Loss: 0.119462, Val Acc: 0.762887\n",
      "Epoch 15085 - Train Loss: 0.096443, Train Acc: 0.860256 | Val Loss: 0.119459, Val Acc: 0.762887\n",
      "Epoch 15086 - Train Loss: 0.096439, Train Acc: 0.860256 | Val Loss: 0.119456, Val Acc: 0.762887\n",
      "Epoch 15087 - Train Loss: 0.096435, Train Acc: 0.860256 | Val Loss: 0.119454, Val Acc: 0.762887\n",
      "Epoch 15088 - Train Loss: 0.096431, Train Acc: 0.860256 | Val Loss: 0.119451, Val Acc: 0.762887\n",
      "Epoch 15089 - Train Loss: 0.096427, Train Acc: 0.860256 | Val Loss: 0.119448, Val Acc: 0.762887\n",
      "Epoch 15090 - Train Loss: 0.096423, Train Acc: 0.860256 | Val Loss: 0.119446, Val Acc: 0.762887\n",
      "Epoch 15091 - Train Loss: 0.096419, Train Acc: 0.860256 | Val Loss: 0.119443, Val Acc: 0.762887\n",
      "Epoch 15092 - Train Loss: 0.096414, Train Acc: 0.860256 | Val Loss: 0.119440, Val Acc: 0.762887\n",
      "Epoch 15093 - Train Loss: 0.096410, Train Acc: 0.861538 | Val Loss: 0.119437, Val Acc: 0.762887\n",
      "Epoch 15094 - Train Loss: 0.096406, Train Acc: 0.861538 | Val Loss: 0.119435, Val Acc: 0.762887\n",
      "Epoch 15095 - Train Loss: 0.096402, Train Acc: 0.861538 | Val Loss: 0.119432, Val Acc: 0.762887\n",
      "Epoch 15096 - Train Loss: 0.096398, Train Acc: 0.861538 | Val Loss: 0.119429, Val Acc: 0.762887\n",
      "Epoch 15097 - Train Loss: 0.096394, Train Acc: 0.861538 | Val Loss: 0.119427, Val Acc: 0.762887\n",
      "Epoch 15098 - Train Loss: 0.096390, Train Acc: 0.861538 | Val Loss: 0.119424, Val Acc: 0.762887\n",
      "Epoch 15099 - Train Loss: 0.096386, Train Acc: 0.861538 | Val Loss: 0.119421, Val Acc: 0.762887\n",
      "Epoch 15100 - Train Loss: 0.096382, Train Acc: 0.861538 | Val Loss: 0.119419, Val Acc: 0.762887\n",
      "Epoch 15101 - Train Loss: 0.096378, Train Acc: 0.861538 | Val Loss: 0.119416, Val Acc: 0.762887\n",
      "Epoch 15102 - Train Loss: 0.096374, Train Acc: 0.861538 | Val Loss: 0.119413, Val Acc: 0.762887\n",
      "Epoch 15103 - Train Loss: 0.096370, Train Acc: 0.861538 | Val Loss: 0.119411, Val Acc: 0.762887\n",
      "Epoch 15104 - Train Loss: 0.096366, Train Acc: 0.861538 | Val Loss: 0.119408, Val Acc: 0.762887\n",
      "Epoch 15105 - Train Loss: 0.096362, Train Acc: 0.861538 | Val Loss: 0.119405, Val Acc: 0.762887\n",
      "Epoch 15106 - Train Loss: 0.096358, Train Acc: 0.861538 | Val Loss: 0.119403, Val Acc: 0.762887\n",
      "Epoch 15107 - Train Loss: 0.096354, Train Acc: 0.861538 | Val Loss: 0.119400, Val Acc: 0.762887\n",
      "Epoch 15108 - Train Loss: 0.096350, Train Acc: 0.861538 | Val Loss: 0.119397, Val Acc: 0.762887\n",
      "Epoch 15109 - Train Loss: 0.096345, Train Acc: 0.861538 | Val Loss: 0.119394, Val Acc: 0.762887\n",
      "Epoch 15110 - Train Loss: 0.096341, Train Acc: 0.861538 | Val Loss: 0.119392, Val Acc: 0.762887\n",
      "Epoch 15111 - Train Loss: 0.096337, Train Acc: 0.861538 | Val Loss: 0.119389, Val Acc: 0.762887\n",
      "Epoch 15112 - Train Loss: 0.096333, Train Acc: 0.861538 | Val Loss: 0.119386, Val Acc: 0.762887\n",
      "Epoch 15113 - Train Loss: 0.096329, Train Acc: 0.861538 | Val Loss: 0.119384, Val Acc: 0.762887\n",
      "Epoch 15114 - Train Loss: 0.096325, Train Acc: 0.861538 | Val Loss: 0.119381, Val Acc: 0.762887\n",
      "Epoch 15115 - Train Loss: 0.096321, Train Acc: 0.861538 | Val Loss: 0.119378, Val Acc: 0.762887\n",
      "Epoch 15116 - Train Loss: 0.096317, Train Acc: 0.861538 | Val Loss: 0.119376, Val Acc: 0.762887\n",
      "Epoch 15117 - Train Loss: 0.096313, Train Acc: 0.861538 | Val Loss: 0.119373, Val Acc: 0.762887\n",
      "Epoch 15118 - Train Loss: 0.096309, Train Acc: 0.861538 | Val Loss: 0.119370, Val Acc: 0.762887\n",
      "Epoch 15119 - Train Loss: 0.096305, Train Acc: 0.861538 | Val Loss: 0.119368, Val Acc: 0.762887\n",
      "Epoch 15120 - Train Loss: 0.096301, Train Acc: 0.861538 | Val Loss: 0.119365, Val Acc: 0.762887\n",
      "Epoch 15121 - Train Loss: 0.096297, Train Acc: 0.861538 | Val Loss: 0.119362, Val Acc: 0.762887\n",
      "Epoch 15122 - Train Loss: 0.096293, Train Acc: 0.861538 | Val Loss: 0.119360, Val Acc: 0.762887\n",
      "Epoch 15123 - Train Loss: 0.096289, Train Acc: 0.861538 | Val Loss: 0.119357, Val Acc: 0.762887\n",
      "Epoch 15124 - Train Loss: 0.096285, Train Acc: 0.861538 | Val Loss: 0.119354, Val Acc: 0.762887\n",
      "Epoch 15125 - Train Loss: 0.096281, Train Acc: 0.861538 | Val Loss: 0.119352, Val Acc: 0.762887\n",
      "Epoch 15126 - Train Loss: 0.096277, Train Acc: 0.861538 | Val Loss: 0.119349, Val Acc: 0.762887\n",
      "Epoch 15127 - Train Loss: 0.096273, Train Acc: 0.861538 | Val Loss: 0.119346, Val Acc: 0.762887\n",
      "Epoch 15128 - Train Loss: 0.096269, Train Acc: 0.861538 | Val Loss: 0.119344, Val Acc: 0.762887\n",
      "Epoch 15129 - Train Loss: 0.096264, Train Acc: 0.861538 | Val Loss: 0.119341, Val Acc: 0.762887\n",
      "Epoch 15130 - Train Loss: 0.096260, Train Acc: 0.861538 | Val Loss: 0.119338, Val Acc: 0.762887\n",
      "Epoch 15131 - Train Loss: 0.096256, Train Acc: 0.861538 | Val Loss: 0.119336, Val Acc: 0.762887\n",
      "Epoch 15132 - Train Loss: 0.096252, Train Acc: 0.861538 | Val Loss: 0.119333, Val Acc: 0.762887\n",
      "Epoch 15133 - Train Loss: 0.096248, Train Acc: 0.861538 | Val Loss: 0.119330, Val Acc: 0.762887\n",
      "Epoch 15134 - Train Loss: 0.096244, Train Acc: 0.861538 | Val Loss: 0.119328, Val Acc: 0.762887\n",
      "Epoch 15135 - Train Loss: 0.096240, Train Acc: 0.861538 | Val Loss: 0.119325, Val Acc: 0.762887\n",
      "Epoch 15136 - Train Loss: 0.096236, Train Acc: 0.861538 | Val Loss: 0.119322, Val Acc: 0.762887\n",
      "Epoch 15137 - Train Loss: 0.096232, Train Acc: 0.861538 | Val Loss: 0.119320, Val Acc: 0.762887\n",
      "Epoch 15138 - Train Loss: 0.096228, Train Acc: 0.861538 | Val Loss: 0.119317, Val Acc: 0.762887\n",
      "Epoch 15139 - Train Loss: 0.096224, Train Acc: 0.861538 | Val Loss: 0.119314, Val Acc: 0.762887\n",
      "Epoch 15140 - Train Loss: 0.096220, Train Acc: 0.861538 | Val Loss: 0.119312, Val Acc: 0.762887\n",
      "Epoch 15141 - Train Loss: 0.096216, Train Acc: 0.861538 | Val Loss: 0.119309, Val Acc: 0.762887\n",
      "Epoch 15142 - Train Loss: 0.096212, Train Acc: 0.861538 | Val Loss: 0.119306, Val Acc: 0.762887\n",
      "Epoch 15143 - Train Loss: 0.096208, Train Acc: 0.861538 | Val Loss: 0.119304, Val Acc: 0.762887\n",
      "Epoch 15144 - Train Loss: 0.096204, Train Acc: 0.861538 | Val Loss: 0.119301, Val Acc: 0.762887\n",
      "Epoch 15145 - Train Loss: 0.096200, Train Acc: 0.861538 | Val Loss: 0.119298, Val Acc: 0.762887\n",
      "Epoch 15146 - Train Loss: 0.096196, Train Acc: 0.861538 | Val Loss: 0.119296, Val Acc: 0.762887\n",
      "Epoch 15147 - Train Loss: 0.096192, Train Acc: 0.861538 | Val Loss: 0.119293, Val Acc: 0.762887\n",
      "Epoch 15148 - Train Loss: 0.096188, Train Acc: 0.861538 | Val Loss: 0.119290, Val Acc: 0.762887\n",
      "Epoch 15149 - Train Loss: 0.096184, Train Acc: 0.861538 | Val Loss: 0.119288, Val Acc: 0.762887\n",
      "Epoch 15150 - Train Loss: 0.096180, Train Acc: 0.861538 | Val Loss: 0.119285, Val Acc: 0.762887\n",
      "Epoch 15151 - Train Loss: 0.096176, Train Acc: 0.861538 | Val Loss: 0.119282, Val Acc: 0.762887\n",
      "Epoch 15152 - Train Loss: 0.096172, Train Acc: 0.861538 | Val Loss: 0.119280, Val Acc: 0.762887\n",
      "Epoch 15153 - Train Loss: 0.096168, Train Acc: 0.861538 | Val Loss: 0.119277, Val Acc: 0.762887\n",
      "Epoch 15154 - Train Loss: 0.096164, Train Acc: 0.861538 | Val Loss: 0.119274, Val Acc: 0.762887\n",
      "Epoch 15155 - Train Loss: 0.096159, Train Acc: 0.861538 | Val Loss: 0.119272, Val Acc: 0.762887\n",
      "Epoch 15156 - Train Loss: 0.096155, Train Acc: 0.861538 | Val Loss: 0.119269, Val Acc: 0.762887\n",
      "Epoch 15157 - Train Loss: 0.096151, Train Acc: 0.861538 | Val Loss: 0.119266, Val Acc: 0.762887\n",
      "Epoch 15158 - Train Loss: 0.096147, Train Acc: 0.861538 | Val Loss: 0.119264, Val Acc: 0.762887\n",
      "Epoch 15159 - Train Loss: 0.096143, Train Acc: 0.861538 | Val Loss: 0.119261, Val Acc: 0.762887\n",
      "Epoch 15160 - Train Loss: 0.096139, Train Acc: 0.861538 | Val Loss: 0.119258, Val Acc: 0.762887\n",
      "Epoch 15161 - Train Loss: 0.096135, Train Acc: 0.861538 | Val Loss: 0.119256, Val Acc: 0.762887\n",
      "Epoch 15162 - Train Loss: 0.096131, Train Acc: 0.861538 | Val Loss: 0.119253, Val Acc: 0.762887\n",
      "Epoch 15163 - Train Loss: 0.096127, Train Acc: 0.861538 | Val Loss: 0.119250, Val Acc: 0.762887\n",
      "Epoch 15164 - Train Loss: 0.096123, Train Acc: 0.861538 | Val Loss: 0.119248, Val Acc: 0.762887\n",
      "Epoch 15165 - Train Loss: 0.096119, Train Acc: 0.861538 | Val Loss: 0.119245, Val Acc: 0.762887\n",
      "Epoch 15166 - Train Loss: 0.096115, Train Acc: 0.861538 | Val Loss: 0.119242, Val Acc: 0.762887\n",
      "Epoch 15167 - Train Loss: 0.096111, Train Acc: 0.861538 | Val Loss: 0.119240, Val Acc: 0.762887\n",
      "Epoch 15168 - Train Loss: 0.096107, Train Acc: 0.861538 | Val Loss: 0.119237, Val Acc: 0.762887\n",
      "Epoch 15169 - Train Loss: 0.096103, Train Acc: 0.861538 | Val Loss: 0.119234, Val Acc: 0.762887\n",
      "Epoch 15170 - Train Loss: 0.096099, Train Acc: 0.861538 | Val Loss: 0.119232, Val Acc: 0.762887\n",
      "Epoch 15171 - Train Loss: 0.096095, Train Acc: 0.861538 | Val Loss: 0.119229, Val Acc: 0.762887\n",
      "Epoch 15172 - Train Loss: 0.096091, Train Acc: 0.861538 | Val Loss: 0.119227, Val Acc: 0.762887\n",
      "Epoch 15173 - Train Loss: 0.096087, Train Acc: 0.861538 | Val Loss: 0.119224, Val Acc: 0.762887\n",
      "Epoch 15174 - Train Loss: 0.096083, Train Acc: 0.861538 | Val Loss: 0.119221, Val Acc: 0.762887\n",
      "Epoch 15175 - Train Loss: 0.096079, Train Acc: 0.861538 | Val Loss: 0.119219, Val Acc: 0.762887\n",
      "Epoch 15176 - Train Loss: 0.096075, Train Acc: 0.861538 | Val Loss: 0.119216, Val Acc: 0.762887\n",
      "Epoch 15177 - Train Loss: 0.096071, Train Acc: 0.861538 | Val Loss: 0.119213, Val Acc: 0.762887\n",
      "Epoch 15178 - Train Loss: 0.096067, Train Acc: 0.861538 | Val Loss: 0.119211, Val Acc: 0.762887\n",
      "Epoch 15179 - Train Loss: 0.096063, Train Acc: 0.861538 | Val Loss: 0.119208, Val Acc: 0.762887\n",
      "Epoch 15180 - Train Loss: 0.096059, Train Acc: 0.861538 | Val Loss: 0.119205, Val Acc: 0.762887\n",
      "Epoch 15181 - Train Loss: 0.096055, Train Acc: 0.861538 | Val Loss: 0.119203, Val Acc: 0.762887\n",
      "Epoch 15182 - Train Loss: 0.096051, Train Acc: 0.861538 | Val Loss: 0.119200, Val Acc: 0.762887\n",
      "Epoch 15183 - Train Loss: 0.096047, Train Acc: 0.861538 | Val Loss: 0.119197, Val Acc: 0.762887\n",
      "Epoch 15184 - Train Loss: 0.096043, Train Acc: 0.861538 | Val Loss: 0.119195, Val Acc: 0.762887\n",
      "Epoch 15185 - Train Loss: 0.096039, Train Acc: 0.861538 | Val Loss: 0.119192, Val Acc: 0.762887\n",
      "Epoch 15186 - Train Loss: 0.096035, Train Acc: 0.861538 | Val Loss: 0.119189, Val Acc: 0.762887\n",
      "Epoch 15187 - Train Loss: 0.096031, Train Acc: 0.861538 | Val Loss: 0.119187, Val Acc: 0.762887\n",
      "Epoch 15188 - Train Loss: 0.096027, Train Acc: 0.861538 | Val Loss: 0.119184, Val Acc: 0.762887\n",
      "Epoch 15189 - Train Loss: 0.096023, Train Acc: 0.861538 | Val Loss: 0.119182, Val Acc: 0.762887\n",
      "Epoch 15190 - Train Loss: 0.096019, Train Acc: 0.861538 | Val Loss: 0.119179, Val Acc: 0.762887\n",
      "Epoch 15191 - Train Loss: 0.096015, Train Acc: 0.861538 | Val Loss: 0.119176, Val Acc: 0.762887\n",
      "Epoch 15192 - Train Loss: 0.096011, Train Acc: 0.861538 | Val Loss: 0.119174, Val Acc: 0.762887\n",
      "Epoch 15193 - Train Loss: 0.096007, Train Acc: 0.861538 | Val Loss: 0.119171, Val Acc: 0.762887\n",
      "Epoch 15194 - Train Loss: 0.096003, Train Acc: 0.861538 | Val Loss: 0.119168, Val Acc: 0.762887\n",
      "Epoch 15195 - Train Loss: 0.095999, Train Acc: 0.861538 | Val Loss: 0.119166, Val Acc: 0.762887\n",
      "Epoch 15196 - Train Loss: 0.095995, Train Acc: 0.861538 | Val Loss: 0.119163, Val Acc: 0.762887\n",
      "Epoch 15197 - Train Loss: 0.095991, Train Acc: 0.861538 | Val Loss: 0.119160, Val Acc: 0.762887\n",
      "Epoch 15198 - Train Loss: 0.095987, Train Acc: 0.861538 | Val Loss: 0.119158, Val Acc: 0.762887\n",
      "Epoch 15199 - Train Loss: 0.095983, Train Acc: 0.861538 | Val Loss: 0.119155, Val Acc: 0.762887\n",
      "Epoch 15200 - Train Loss: 0.095979, Train Acc: 0.861538 | Val Loss: 0.119153, Val Acc: 0.762887\n",
      "Epoch 15201 - Train Loss: 0.095975, Train Acc: 0.861538 | Val Loss: 0.119150, Val Acc: 0.762887\n",
      "Epoch 15202 - Train Loss: 0.095971, Train Acc: 0.861538 | Val Loss: 0.119147, Val Acc: 0.762887\n",
      "Epoch 15203 - Train Loss: 0.095967, Train Acc: 0.861538 | Val Loss: 0.119145, Val Acc: 0.762887\n",
      "Epoch 15204 - Train Loss: 0.095963, Train Acc: 0.861538 | Val Loss: 0.119142, Val Acc: 0.762887\n",
      "Epoch 15205 - Train Loss: 0.095959, Train Acc: 0.861538 | Val Loss: 0.119139, Val Acc: 0.762887\n",
      "Epoch 15206 - Train Loss: 0.095955, Train Acc: 0.861538 | Val Loss: 0.119137, Val Acc: 0.762887\n",
      "Epoch 15207 - Train Loss: 0.095951, Train Acc: 0.861538 | Val Loss: 0.119134, Val Acc: 0.762887\n",
      "Epoch 15208 - Train Loss: 0.095947, Train Acc: 0.861538 | Val Loss: 0.119132, Val Acc: 0.762887\n",
      "Epoch 15209 - Train Loss: 0.095943, Train Acc: 0.861538 | Val Loss: 0.119129, Val Acc: 0.762887\n",
      "Epoch 15210 - Train Loss: 0.095939, Train Acc: 0.861538 | Val Loss: 0.119126, Val Acc: 0.762887\n",
      "Epoch 15211 - Train Loss: 0.095935, Train Acc: 0.861538 | Val Loss: 0.119124, Val Acc: 0.762887\n",
      "Epoch 15212 - Train Loss: 0.095931, Train Acc: 0.861538 | Val Loss: 0.119121, Val Acc: 0.762887\n",
      "Epoch 15213 - Train Loss: 0.095927, Train Acc: 0.861538 | Val Loss: 0.119118, Val Acc: 0.762887\n",
      "Epoch 15214 - Train Loss: 0.095923, Train Acc: 0.861538 | Val Loss: 0.119116, Val Acc: 0.762887\n",
      "Epoch 15215 - Train Loss: 0.095919, Train Acc: 0.861538 | Val Loss: 0.119113, Val Acc: 0.762887\n",
      "Epoch 15216 - Train Loss: 0.095915, Train Acc: 0.861538 | Val Loss: 0.119110, Val Acc: 0.762887\n",
      "Epoch 15217 - Train Loss: 0.095911, Train Acc: 0.861538 | Val Loss: 0.119108, Val Acc: 0.762887\n",
      "Epoch 15218 - Train Loss: 0.095907, Train Acc: 0.861538 | Val Loss: 0.119105, Val Acc: 0.762887\n",
      "Epoch 15219 - Train Loss: 0.095903, Train Acc: 0.861538 | Val Loss: 0.119103, Val Acc: 0.762887\n",
      "Epoch 15220 - Train Loss: 0.095899, Train Acc: 0.861538 | Val Loss: 0.119100, Val Acc: 0.762887\n",
      "Epoch 15221 - Train Loss: 0.095895, Train Acc: 0.861538 | Val Loss: 0.119097, Val Acc: 0.762887\n",
      "Epoch 15222 - Train Loss: 0.095891, Train Acc: 0.861538 | Val Loss: 0.119095, Val Acc: 0.762887\n",
      "Epoch 15223 - Train Loss: 0.095887, Train Acc: 0.861538 | Val Loss: 0.119092, Val Acc: 0.762887\n",
      "Epoch 15224 - Train Loss: 0.095883, Train Acc: 0.861538 | Val Loss: 0.119090, Val Acc: 0.762887\n",
      "Epoch 15225 - Train Loss: 0.095879, Train Acc: 0.861538 | Val Loss: 0.119087, Val Acc: 0.762887\n",
      "Epoch 15226 - Train Loss: 0.095875, Train Acc: 0.861538 | Val Loss: 0.119084, Val Acc: 0.762887\n",
      "Epoch 15227 - Train Loss: 0.095871, Train Acc: 0.861538 | Val Loss: 0.119082, Val Acc: 0.762887\n",
      "Epoch 15228 - Train Loss: 0.095867, Train Acc: 0.861538 | Val Loss: 0.119079, Val Acc: 0.762887\n",
      "Epoch 15229 - Train Loss: 0.095863, Train Acc: 0.861538 | Val Loss: 0.119076, Val Acc: 0.762887\n",
      "Epoch 15230 - Train Loss: 0.095859, Train Acc: 0.861538 | Val Loss: 0.119074, Val Acc: 0.762887\n",
      "Epoch 15231 - Train Loss: 0.095855, Train Acc: 0.861538 | Val Loss: 0.119071, Val Acc: 0.762887\n",
      "Epoch 15232 - Train Loss: 0.095851, Train Acc: 0.861538 | Val Loss: 0.119069, Val Acc: 0.762887\n",
      "Epoch 15233 - Train Loss: 0.095847, Train Acc: 0.861538 | Val Loss: 0.119066, Val Acc: 0.762887\n",
      "Epoch 15234 - Train Loss: 0.095843, Train Acc: 0.861538 | Val Loss: 0.119063, Val Acc: 0.762887\n",
      "Epoch 15235 - Train Loss: 0.095839, Train Acc: 0.861538 | Val Loss: 0.119061, Val Acc: 0.762887\n",
      "Epoch 15236 - Train Loss: 0.095835, Train Acc: 0.861538 | Val Loss: 0.119058, Val Acc: 0.762887\n",
      "Epoch 15237 - Train Loss: 0.095831, Train Acc: 0.861538 | Val Loss: 0.119055, Val Acc: 0.762887\n",
      "Epoch 15238 - Train Loss: 0.095827, Train Acc: 0.861538 | Val Loss: 0.119053, Val Acc: 0.762887\n",
      "Epoch 15239 - Train Loss: 0.095823, Train Acc: 0.861538 | Val Loss: 0.119050, Val Acc: 0.762887\n",
      "Epoch 15240 - Train Loss: 0.095819, Train Acc: 0.861538 | Val Loss: 0.119048, Val Acc: 0.762887\n",
      "Epoch 15241 - Train Loss: 0.095815, Train Acc: 0.861538 | Val Loss: 0.119045, Val Acc: 0.762887\n",
      "Epoch 15242 - Train Loss: 0.095811, Train Acc: 0.861538 | Val Loss: 0.119042, Val Acc: 0.762887\n",
      "Epoch 15243 - Train Loss: 0.095807, Train Acc: 0.861538 | Val Loss: 0.119040, Val Acc: 0.762887\n",
      "Epoch 15244 - Train Loss: 0.095803, Train Acc: 0.861538 | Val Loss: 0.119037, Val Acc: 0.762887\n",
      "Epoch 15245 - Train Loss: 0.095799, Train Acc: 0.861538 | Val Loss: 0.119035, Val Acc: 0.762887\n",
      "Epoch 15246 - Train Loss: 0.095795, Train Acc: 0.861538 | Val Loss: 0.119032, Val Acc: 0.762887\n",
      "Epoch 15247 - Train Loss: 0.095791, Train Acc: 0.861538 | Val Loss: 0.119029, Val Acc: 0.762887\n",
      "Epoch 15248 - Train Loss: 0.095787, Train Acc: 0.861538 | Val Loss: 0.119027, Val Acc: 0.762887\n",
      "Epoch 15249 - Train Loss: 0.095783, Train Acc: 0.861538 | Val Loss: 0.119024, Val Acc: 0.762887\n",
      "Epoch 15250 - Train Loss: 0.095779, Train Acc: 0.861538 | Val Loss: 0.119022, Val Acc: 0.762887\n",
      "Epoch 15251 - Train Loss: 0.095775, Train Acc: 0.861538 | Val Loss: 0.119019, Val Acc: 0.762887\n",
      "Epoch 15252 - Train Loss: 0.095771, Train Acc: 0.861538 | Val Loss: 0.119016, Val Acc: 0.762887\n",
      "Epoch 15253 - Train Loss: 0.095767, Train Acc: 0.861538 | Val Loss: 0.119014, Val Acc: 0.762887\n",
      "Epoch 15254 - Train Loss: 0.095763, Train Acc: 0.861538 | Val Loss: 0.119011, Val Acc: 0.762887\n",
      "Epoch 15255 - Train Loss: 0.095759, Train Acc: 0.861538 | Val Loss: 0.119009, Val Acc: 0.762887\n",
      "Epoch 15256 - Train Loss: 0.095755, Train Acc: 0.861538 | Val Loss: 0.119006, Val Acc: 0.762887\n",
      "Epoch 15257 - Train Loss: 0.095751, Train Acc: 0.861538 | Val Loss: 0.119003, Val Acc: 0.762887\n",
      "Epoch 15258 - Train Loss: 0.095747, Train Acc: 0.861538 | Val Loss: 0.119001, Val Acc: 0.762887\n",
      "Epoch 15259 - Train Loss: 0.095743, Train Acc: 0.861538 | Val Loss: 0.118998, Val Acc: 0.762887\n",
      "Epoch 15260 - Train Loss: 0.095739, Train Acc: 0.861538 | Val Loss: 0.118996, Val Acc: 0.762887\n",
      "Epoch 15261 - Train Loss: 0.095735, Train Acc: 0.861538 | Val Loss: 0.118993, Val Acc: 0.762887\n",
      "Epoch 15262 - Train Loss: 0.095731, Train Acc: 0.861538 | Val Loss: 0.118990, Val Acc: 0.762887\n",
      "Epoch 15263 - Train Loss: 0.095727, Train Acc: 0.861538 | Val Loss: 0.118988, Val Acc: 0.762887\n",
      "Epoch 15264 - Train Loss: 0.095723, Train Acc: 0.861538 | Val Loss: 0.118985, Val Acc: 0.762887\n",
      "Epoch 15265 - Train Loss: 0.095719, Train Acc: 0.861538 | Val Loss: 0.118983, Val Acc: 0.762887\n",
      "Epoch 15266 - Train Loss: 0.095715, Train Acc: 0.861538 | Val Loss: 0.118980, Val Acc: 0.762887\n",
      "Epoch 15267 - Train Loss: 0.095711, Train Acc: 0.861538 | Val Loss: 0.118978, Val Acc: 0.762887\n",
      "Epoch 15268 - Train Loss: 0.095707, Train Acc: 0.861538 | Val Loss: 0.118975, Val Acc: 0.762887\n",
      "Epoch 15269 - Train Loss: 0.095703, Train Acc: 0.861538 | Val Loss: 0.118972, Val Acc: 0.762887\n",
      "Epoch 15270 - Train Loss: 0.095699, Train Acc: 0.861538 | Val Loss: 0.118970, Val Acc: 0.762887\n",
      "Epoch 15271 - Train Loss: 0.095695, Train Acc: 0.861538 | Val Loss: 0.118967, Val Acc: 0.762887\n",
      "Epoch 15272 - Train Loss: 0.095691, Train Acc: 0.861538 | Val Loss: 0.118965, Val Acc: 0.762887\n",
      "Epoch 15273 - Train Loss: 0.095687, Train Acc: 0.861538 | Val Loss: 0.118962, Val Acc: 0.762887\n",
      "Epoch 15274 - Train Loss: 0.095683, Train Acc: 0.861538 | Val Loss: 0.118959, Val Acc: 0.762887\n",
      "Epoch 15275 - Train Loss: 0.095680, Train Acc: 0.861538 | Val Loss: 0.118957, Val Acc: 0.762887\n",
      "Epoch 15276 - Train Loss: 0.095676, Train Acc: 0.861538 | Val Loss: 0.118954, Val Acc: 0.762887\n",
      "Epoch 15277 - Train Loss: 0.095672, Train Acc: 0.861538 | Val Loss: 0.118952, Val Acc: 0.762887\n",
      "Epoch 15278 - Train Loss: 0.095668, Train Acc: 0.861538 | Val Loss: 0.118949, Val Acc: 0.762887\n",
      "Epoch 15279 - Train Loss: 0.095664, Train Acc: 0.861538 | Val Loss: 0.118946, Val Acc: 0.762887\n",
      "Epoch 15280 - Train Loss: 0.095660, Train Acc: 0.861538 | Val Loss: 0.118944, Val Acc: 0.762887\n",
      "Epoch 15281 - Train Loss: 0.095656, Train Acc: 0.861538 | Val Loss: 0.118941, Val Acc: 0.762887\n",
      "Epoch 15282 - Train Loss: 0.095652, Train Acc: 0.861538 | Val Loss: 0.118939, Val Acc: 0.762887\n",
      "Epoch 15283 - Train Loss: 0.095648, Train Acc: 0.861538 | Val Loss: 0.118936, Val Acc: 0.762887\n",
      "Epoch 15284 - Train Loss: 0.095644, Train Acc: 0.861538 | Val Loss: 0.118933, Val Acc: 0.762887\n",
      "Epoch 15285 - Train Loss: 0.095640, Train Acc: 0.861538 | Val Loss: 0.118931, Val Acc: 0.762887\n",
      "Epoch 15286 - Train Loss: 0.095636, Train Acc: 0.861538 | Val Loss: 0.118928, Val Acc: 0.762887\n",
      "Epoch 15287 - Train Loss: 0.095632, Train Acc: 0.861538 | Val Loss: 0.118926, Val Acc: 0.762887\n",
      "Epoch 15288 - Train Loss: 0.095628, Train Acc: 0.861538 | Val Loss: 0.118923, Val Acc: 0.762887\n",
      "Epoch 15289 - Train Loss: 0.095624, Train Acc: 0.861538 | Val Loss: 0.118921, Val Acc: 0.762887\n",
      "Epoch 15290 - Train Loss: 0.095620, Train Acc: 0.861538 | Val Loss: 0.118918, Val Acc: 0.762887\n",
      "Epoch 15291 - Train Loss: 0.095616, Train Acc: 0.861538 | Val Loss: 0.118915, Val Acc: 0.762887\n",
      "Epoch 15292 - Train Loss: 0.095612, Train Acc: 0.861538 | Val Loss: 0.118913, Val Acc: 0.762887\n",
      "Epoch 15293 - Train Loss: 0.095608, Train Acc: 0.861538 | Val Loss: 0.118910, Val Acc: 0.762887\n",
      "Epoch 15294 - Train Loss: 0.095604, Train Acc: 0.861538 | Val Loss: 0.118908, Val Acc: 0.762887\n",
      "Epoch 15295 - Train Loss: 0.095600, Train Acc: 0.861538 | Val Loss: 0.118905, Val Acc: 0.762887\n",
      "Epoch 15296 - Train Loss: 0.095596, Train Acc: 0.861538 | Val Loss: 0.118903, Val Acc: 0.762887\n",
      "Epoch 15297 - Train Loss: 0.095592, Train Acc: 0.861538 | Val Loss: 0.118900, Val Acc: 0.762887\n",
      "Epoch 15298 - Train Loss: 0.095588, Train Acc: 0.861538 | Val Loss: 0.118897, Val Acc: 0.762887\n",
      "Epoch 15299 - Train Loss: 0.095584, Train Acc: 0.861538 | Val Loss: 0.118895, Val Acc: 0.762887\n",
      "Epoch 15300 - Train Loss: 0.095580, Train Acc: 0.861538 | Val Loss: 0.118892, Val Acc: 0.762887\n",
      "Epoch 15301 - Train Loss: 0.095577, Train Acc: 0.861538 | Val Loss: 0.118890, Val Acc: 0.762887\n",
      "Epoch 15302 - Train Loss: 0.095573, Train Acc: 0.861538 | Val Loss: 0.118887, Val Acc: 0.762887\n",
      "Epoch 15303 - Train Loss: 0.095569, Train Acc: 0.861538 | Val Loss: 0.118884, Val Acc: 0.762887\n",
      "Epoch 15304 - Train Loss: 0.095565, Train Acc: 0.861538 | Val Loss: 0.118882, Val Acc: 0.762887\n",
      "Epoch 15305 - Train Loss: 0.095561, Train Acc: 0.861538 | Val Loss: 0.118879, Val Acc: 0.762887\n",
      "Epoch 15306 - Train Loss: 0.095557, Train Acc: 0.861538 | Val Loss: 0.118877, Val Acc: 0.762887\n",
      "Epoch 15307 - Train Loss: 0.095553, Train Acc: 0.861538 | Val Loss: 0.118874, Val Acc: 0.762887\n",
      "Epoch 15308 - Train Loss: 0.095549, Train Acc: 0.861538 | Val Loss: 0.118872, Val Acc: 0.762887\n",
      "Epoch 15309 - Train Loss: 0.095545, Train Acc: 0.861538 | Val Loss: 0.118869, Val Acc: 0.762887\n",
      "Epoch 15310 - Train Loss: 0.095541, Train Acc: 0.861538 | Val Loss: 0.118866, Val Acc: 0.762887\n",
      "Epoch 15311 - Train Loss: 0.095537, Train Acc: 0.861538 | Val Loss: 0.118864, Val Acc: 0.762887\n",
      "Epoch 15312 - Train Loss: 0.095533, Train Acc: 0.861538 | Val Loss: 0.118861, Val Acc: 0.762887\n",
      "Epoch 15313 - Train Loss: 0.095529, Train Acc: 0.861538 | Val Loss: 0.118859, Val Acc: 0.762887\n",
      "Epoch 15314 - Train Loss: 0.095525, Train Acc: 0.861538 | Val Loss: 0.118856, Val Acc: 0.762887\n",
      "Epoch 15315 - Train Loss: 0.095521, Train Acc: 0.861538 | Val Loss: 0.118854, Val Acc: 0.762887\n",
      "Epoch 15316 - Train Loss: 0.095517, Train Acc: 0.861538 | Val Loss: 0.118851, Val Acc: 0.762887\n",
      "Epoch 15317 - Train Loss: 0.095513, Train Acc: 0.861538 | Val Loss: 0.118848, Val Acc: 0.762887\n",
      "Epoch 15318 - Train Loss: 0.095509, Train Acc: 0.861538 | Val Loss: 0.118846, Val Acc: 0.762887\n",
      "Epoch 15319 - Train Loss: 0.095505, Train Acc: 0.861538 | Val Loss: 0.118843, Val Acc: 0.762887\n",
      "Epoch 15320 - Train Loss: 0.095501, Train Acc: 0.861538 | Val Loss: 0.118841, Val Acc: 0.762887\n",
      "Epoch 15321 - Train Loss: 0.095498, Train Acc: 0.861538 | Val Loss: 0.118838, Val Acc: 0.762887\n",
      "Epoch 15322 - Train Loss: 0.095494, Train Acc: 0.861538 | Val Loss: 0.118836, Val Acc: 0.762887\n",
      "Epoch 15323 - Train Loss: 0.095490, Train Acc: 0.861538 | Val Loss: 0.118833, Val Acc: 0.762887\n",
      "Epoch 15324 - Train Loss: 0.095486, Train Acc: 0.861538 | Val Loss: 0.118830, Val Acc: 0.762887\n",
      "Epoch 15325 - Train Loss: 0.095482, Train Acc: 0.861538 | Val Loss: 0.118828, Val Acc: 0.762887\n",
      "Epoch 15326 - Train Loss: 0.095478, Train Acc: 0.861538 | Val Loss: 0.118825, Val Acc: 0.762887\n",
      "Epoch 15327 - Train Loss: 0.095474, Train Acc: 0.861538 | Val Loss: 0.118823, Val Acc: 0.762887\n",
      "Epoch 15328 - Train Loss: 0.095470, Train Acc: 0.861538 | Val Loss: 0.118820, Val Acc: 0.762887\n",
      "Epoch 15329 - Train Loss: 0.095466, Train Acc: 0.861538 | Val Loss: 0.118818, Val Acc: 0.762887\n",
      "Epoch 15330 - Train Loss: 0.095462, Train Acc: 0.861538 | Val Loss: 0.118815, Val Acc: 0.762887\n",
      "Epoch 15331 - Train Loss: 0.095458, Train Acc: 0.861538 | Val Loss: 0.118812, Val Acc: 0.762887\n",
      "Epoch 15332 - Train Loss: 0.095454, Train Acc: 0.861538 | Val Loss: 0.118810, Val Acc: 0.762887\n",
      "Epoch 15333 - Train Loss: 0.095450, Train Acc: 0.861538 | Val Loss: 0.118807, Val Acc: 0.762887\n",
      "Epoch 15334 - Train Loss: 0.095446, Train Acc: 0.861538 | Val Loss: 0.118805, Val Acc: 0.762887\n",
      "Epoch 15335 - Train Loss: 0.095442, Train Acc: 0.861538 | Val Loss: 0.118802, Val Acc: 0.762887\n",
      "Epoch 15336 - Train Loss: 0.095438, Train Acc: 0.861538 | Val Loss: 0.118800, Val Acc: 0.762887\n",
      "Epoch 15337 - Train Loss: 0.095434, Train Acc: 0.861538 | Val Loss: 0.118797, Val Acc: 0.762887\n",
      "Epoch 15338 - Train Loss: 0.095431, Train Acc: 0.861538 | Val Loss: 0.118795, Val Acc: 0.762887\n",
      "Epoch 15339 - Train Loss: 0.095427, Train Acc: 0.861538 | Val Loss: 0.118792, Val Acc: 0.762887\n",
      "Epoch 15340 - Train Loss: 0.095423, Train Acc: 0.861538 | Val Loss: 0.118789, Val Acc: 0.762887\n",
      "Epoch 15341 - Train Loss: 0.095419, Train Acc: 0.861538 | Val Loss: 0.118787, Val Acc: 0.762887\n",
      "Epoch 15342 - Train Loss: 0.095415, Train Acc: 0.861538 | Val Loss: 0.118784, Val Acc: 0.762887\n",
      "Epoch 15343 - Train Loss: 0.095411, Train Acc: 0.861538 | Val Loss: 0.118782, Val Acc: 0.762887\n",
      "Epoch 15344 - Train Loss: 0.095407, Train Acc: 0.861538 | Val Loss: 0.118779, Val Acc: 0.762887\n",
      "Epoch 15345 - Train Loss: 0.095403, Train Acc: 0.861538 | Val Loss: 0.118777, Val Acc: 0.762887\n",
      "Epoch 15346 - Train Loss: 0.095399, Train Acc: 0.861538 | Val Loss: 0.118774, Val Acc: 0.762887\n",
      "Epoch 15347 - Train Loss: 0.095395, Train Acc: 0.861538 | Val Loss: 0.118772, Val Acc: 0.762887\n",
      "Epoch 15348 - Train Loss: 0.095391, Train Acc: 0.861538 | Val Loss: 0.118769, Val Acc: 0.762887\n",
      "Epoch 15349 - Train Loss: 0.095387, Train Acc: 0.861538 | Val Loss: 0.118766, Val Acc: 0.762887\n",
      "Epoch 15350 - Train Loss: 0.095383, Train Acc: 0.861538 | Val Loss: 0.118764, Val Acc: 0.762887\n",
      "Epoch 15351 - Train Loss: 0.095379, Train Acc: 0.861538 | Val Loss: 0.118761, Val Acc: 0.762887\n",
      "Epoch 15352 - Train Loss: 0.095375, Train Acc: 0.861538 | Val Loss: 0.118759, Val Acc: 0.762887\n",
      "Epoch 15353 - Train Loss: 0.095372, Train Acc: 0.861538 | Val Loss: 0.118756, Val Acc: 0.762887\n",
      "Epoch 15354 - Train Loss: 0.095368, Train Acc: 0.861538 | Val Loss: 0.118754, Val Acc: 0.762887\n",
      "Epoch 15355 - Train Loss: 0.095364, Train Acc: 0.861538 | Val Loss: 0.118751, Val Acc: 0.762887\n",
      "Epoch 15356 - Train Loss: 0.095360, Train Acc: 0.861538 | Val Loss: 0.118749, Val Acc: 0.762887\n",
      "Epoch 15357 - Train Loss: 0.095356, Train Acc: 0.861538 | Val Loss: 0.118746, Val Acc: 0.762887\n",
      "Epoch 15358 - Train Loss: 0.095352, Train Acc: 0.861538 | Val Loss: 0.118743, Val Acc: 0.762887\n",
      "Epoch 15359 - Train Loss: 0.095348, Train Acc: 0.861538 | Val Loss: 0.118741, Val Acc: 0.762887\n",
      "Epoch 15360 - Train Loss: 0.095344, Train Acc: 0.861538 | Val Loss: 0.118738, Val Acc: 0.762887\n",
      "Epoch 15361 - Train Loss: 0.095340, Train Acc: 0.861538 | Val Loss: 0.118736, Val Acc: 0.762887\n",
      "Epoch 15362 - Train Loss: 0.095336, Train Acc: 0.861538 | Val Loss: 0.118733, Val Acc: 0.762887\n",
      "Epoch 15363 - Train Loss: 0.095332, Train Acc: 0.861538 | Val Loss: 0.118731, Val Acc: 0.762887\n",
      "Epoch 15364 - Train Loss: 0.095328, Train Acc: 0.861538 | Val Loss: 0.118728, Val Acc: 0.762887\n",
      "Epoch 15365 - Train Loss: 0.095324, Train Acc: 0.861538 | Val Loss: 0.118726, Val Acc: 0.762887\n",
      "Epoch 15366 - Train Loss: 0.095321, Train Acc: 0.861538 | Val Loss: 0.118723, Val Acc: 0.762887\n",
      "Epoch 15367 - Train Loss: 0.095317, Train Acc: 0.861538 | Val Loss: 0.118721, Val Acc: 0.762887\n",
      "Epoch 15368 - Train Loss: 0.095313, Train Acc: 0.861538 | Val Loss: 0.118718, Val Acc: 0.762887\n",
      "Epoch 15369 - Train Loss: 0.095309, Train Acc: 0.861538 | Val Loss: 0.118715, Val Acc: 0.762887\n",
      "Epoch 15370 - Train Loss: 0.095305, Train Acc: 0.861538 | Val Loss: 0.118713, Val Acc: 0.762887\n",
      "Epoch 15371 - Train Loss: 0.095301, Train Acc: 0.861538 | Val Loss: 0.118710, Val Acc: 0.762887\n",
      "Epoch 15372 - Train Loss: 0.095297, Train Acc: 0.861538 | Val Loss: 0.118708, Val Acc: 0.762887\n",
      "Epoch 15373 - Train Loss: 0.095293, Train Acc: 0.861538 | Val Loss: 0.118705, Val Acc: 0.762887\n",
      "Epoch 15374 - Train Loss: 0.095289, Train Acc: 0.861538 | Val Loss: 0.118703, Val Acc: 0.762887\n",
      "Epoch 15375 - Train Loss: 0.095285, Train Acc: 0.861538 | Val Loss: 0.118700, Val Acc: 0.762887\n",
      "Epoch 15376 - Train Loss: 0.095281, Train Acc: 0.861538 | Val Loss: 0.118698, Val Acc: 0.762887\n",
      "Epoch 15377 - Train Loss: 0.095277, Train Acc: 0.861538 | Val Loss: 0.118695, Val Acc: 0.762887\n",
      "Epoch 15378 - Train Loss: 0.095273, Train Acc: 0.861538 | Val Loss: 0.118693, Val Acc: 0.762887\n",
      "Epoch 15379 - Train Loss: 0.095270, Train Acc: 0.861538 | Val Loss: 0.118690, Val Acc: 0.762887\n",
      "Epoch 15380 - Train Loss: 0.095266, Train Acc: 0.861538 | Val Loss: 0.118688, Val Acc: 0.762887\n",
      "Epoch 15381 - Train Loss: 0.095262, Train Acc: 0.861538 | Val Loss: 0.118685, Val Acc: 0.762887\n",
      "Epoch 15382 - Train Loss: 0.095258, Train Acc: 0.861538 | Val Loss: 0.118682, Val Acc: 0.762887\n",
      "Epoch 15383 - Train Loss: 0.095254, Train Acc: 0.861538 | Val Loss: 0.118680, Val Acc: 0.762887\n",
      "Epoch 15384 - Train Loss: 0.095250, Train Acc: 0.861538 | Val Loss: 0.118677, Val Acc: 0.762887\n",
      "Epoch 15385 - Train Loss: 0.095246, Train Acc: 0.861538 | Val Loss: 0.118675, Val Acc: 0.762887\n",
      "Epoch 15386 - Train Loss: 0.095242, Train Acc: 0.861538 | Val Loss: 0.118672, Val Acc: 0.762887\n",
      "Epoch 15387 - Train Loss: 0.095238, Train Acc: 0.861538 | Val Loss: 0.118670, Val Acc: 0.762887\n",
      "Epoch 15388 - Train Loss: 0.095234, Train Acc: 0.861538 | Val Loss: 0.118667, Val Acc: 0.762887\n",
      "Epoch 15389 - Train Loss: 0.095230, Train Acc: 0.861538 | Val Loss: 0.118665, Val Acc: 0.762887\n",
      "Epoch 15390 - Train Loss: 0.095227, Train Acc: 0.861538 | Val Loss: 0.118662, Val Acc: 0.762887\n",
      "Epoch 15391 - Train Loss: 0.095223, Train Acc: 0.861538 | Val Loss: 0.118660, Val Acc: 0.762887\n",
      "Epoch 15392 - Train Loss: 0.095219, Train Acc: 0.861538 | Val Loss: 0.118657, Val Acc: 0.762887\n",
      "Epoch 15393 - Train Loss: 0.095215, Train Acc: 0.861538 | Val Loss: 0.118655, Val Acc: 0.762887\n",
      "Epoch 15394 - Train Loss: 0.095211, Train Acc: 0.861538 | Val Loss: 0.118652, Val Acc: 0.762887\n",
      "Epoch 15395 - Train Loss: 0.095207, Train Acc: 0.861538 | Val Loss: 0.118650, Val Acc: 0.762887\n",
      "Epoch 15396 - Train Loss: 0.095203, Train Acc: 0.861538 | Val Loss: 0.118647, Val Acc: 0.762887\n",
      "Epoch 15397 - Train Loss: 0.095199, Train Acc: 0.861538 | Val Loss: 0.118644, Val Acc: 0.762887\n",
      "Epoch 15398 - Train Loss: 0.095195, Train Acc: 0.861538 | Val Loss: 0.118642, Val Acc: 0.762887\n",
      "Epoch 15399 - Train Loss: 0.095191, Train Acc: 0.861538 | Val Loss: 0.118639, Val Acc: 0.762887\n",
      "Epoch 15400 - Train Loss: 0.095187, Train Acc: 0.861538 | Val Loss: 0.118637, Val Acc: 0.762887\n",
      "Epoch 15401 - Train Loss: 0.095184, Train Acc: 0.861538 | Val Loss: 0.118634, Val Acc: 0.762887\n",
      "Epoch 15402 - Train Loss: 0.095180, Train Acc: 0.861538 | Val Loss: 0.118632, Val Acc: 0.762887\n",
      "Epoch 15403 - Train Loss: 0.095176, Train Acc: 0.861538 | Val Loss: 0.118629, Val Acc: 0.762887\n",
      "Epoch 15404 - Train Loss: 0.095172, Train Acc: 0.861538 | Val Loss: 0.118627, Val Acc: 0.762887\n",
      "Epoch 15405 - Train Loss: 0.095168, Train Acc: 0.861538 | Val Loss: 0.118624, Val Acc: 0.762887\n",
      "Epoch 15406 - Train Loss: 0.095164, Train Acc: 0.861538 | Val Loss: 0.118622, Val Acc: 0.762887\n",
      "Epoch 15407 - Train Loss: 0.095160, Train Acc: 0.861538 | Val Loss: 0.118619, Val Acc: 0.762887\n",
      "Epoch 15408 - Train Loss: 0.095156, Train Acc: 0.861538 | Val Loss: 0.118617, Val Acc: 0.762887\n",
      "Epoch 15409 - Train Loss: 0.095152, Train Acc: 0.861538 | Val Loss: 0.118614, Val Acc: 0.762887\n",
      "Epoch 15410 - Train Loss: 0.095148, Train Acc: 0.861538 | Val Loss: 0.118612, Val Acc: 0.762887\n",
      "Epoch 15411 - Train Loss: 0.095145, Train Acc: 0.861538 | Val Loss: 0.118609, Val Acc: 0.762887\n",
      "Epoch 15412 - Train Loss: 0.095141, Train Acc: 0.861538 | Val Loss: 0.118607, Val Acc: 0.762887\n",
      "Epoch 15413 - Train Loss: 0.095137, Train Acc: 0.861538 | Val Loss: 0.118604, Val Acc: 0.762887\n",
      "Epoch 15414 - Train Loss: 0.095133, Train Acc: 0.861538 | Val Loss: 0.118602, Val Acc: 0.762887\n",
      "Epoch 15415 - Train Loss: 0.095129, Train Acc: 0.861538 | Val Loss: 0.118599, Val Acc: 0.762887\n",
      "Epoch 15416 - Train Loss: 0.095125, Train Acc: 0.861538 | Val Loss: 0.118597, Val Acc: 0.762887\n",
      "Epoch 15417 - Train Loss: 0.095121, Train Acc: 0.861538 | Val Loss: 0.118594, Val Acc: 0.762887\n",
      "Epoch 15418 - Train Loss: 0.095117, Train Acc: 0.861538 | Val Loss: 0.118591, Val Acc: 0.762887\n",
      "Epoch 15419 - Train Loss: 0.095113, Train Acc: 0.861538 | Val Loss: 0.118589, Val Acc: 0.762887\n",
      "Epoch 15420 - Train Loss: 0.095109, Train Acc: 0.861538 | Val Loss: 0.118586, Val Acc: 0.762887\n",
      "Epoch 15421 - Train Loss: 0.095106, Train Acc: 0.861538 | Val Loss: 0.118584, Val Acc: 0.762887\n",
      "Epoch 15422 - Train Loss: 0.095102, Train Acc: 0.861538 | Val Loss: 0.118581, Val Acc: 0.762887\n",
      "Epoch 15423 - Train Loss: 0.095098, Train Acc: 0.861538 | Val Loss: 0.118579, Val Acc: 0.762887\n",
      "Epoch 15424 - Train Loss: 0.095094, Train Acc: 0.861538 | Val Loss: 0.118576, Val Acc: 0.762887\n",
      "Epoch 15425 - Train Loss: 0.095090, Train Acc: 0.861538 | Val Loss: 0.118574, Val Acc: 0.762887\n",
      "Epoch 15426 - Train Loss: 0.095086, Train Acc: 0.861538 | Val Loss: 0.118571, Val Acc: 0.762887\n",
      "Epoch 15427 - Train Loss: 0.095082, Train Acc: 0.861538 | Val Loss: 0.118569, Val Acc: 0.762887\n",
      "Epoch 15428 - Train Loss: 0.095078, Train Acc: 0.861538 | Val Loss: 0.118566, Val Acc: 0.762887\n",
      "Epoch 15429 - Train Loss: 0.095074, Train Acc: 0.861538 | Val Loss: 0.118564, Val Acc: 0.762887\n",
      "Epoch 15430 - Train Loss: 0.095071, Train Acc: 0.861538 | Val Loss: 0.118561, Val Acc: 0.762887\n",
      "Epoch 15431 - Train Loss: 0.095067, Train Acc: 0.861538 | Val Loss: 0.118559, Val Acc: 0.762887\n",
      "Epoch 15432 - Train Loss: 0.095063, Train Acc: 0.861538 | Val Loss: 0.118556, Val Acc: 0.762887\n",
      "Epoch 15433 - Train Loss: 0.095059, Train Acc: 0.861538 | Val Loss: 0.118554, Val Acc: 0.762887\n",
      "Epoch 15434 - Train Loss: 0.095055, Train Acc: 0.861538 | Val Loss: 0.118551, Val Acc: 0.762887\n",
      "Epoch 15435 - Train Loss: 0.095051, Train Acc: 0.861538 | Val Loss: 0.118549, Val Acc: 0.762887\n",
      "Epoch 15436 - Train Loss: 0.095047, Train Acc: 0.861538 | Val Loss: 0.118546, Val Acc: 0.762887\n",
      "Epoch 15437 - Train Loss: 0.095043, Train Acc: 0.861538 | Val Loss: 0.118544, Val Acc: 0.762887\n",
      "Epoch 15438 - Train Loss: 0.095039, Train Acc: 0.861538 | Val Loss: 0.118541, Val Acc: 0.762887\n",
      "Epoch 15439 - Train Loss: 0.095036, Train Acc: 0.861538 | Val Loss: 0.118539, Val Acc: 0.762887\n",
      "Epoch 15440 - Train Loss: 0.095032, Train Acc: 0.861538 | Val Loss: 0.118536, Val Acc: 0.762887\n",
      "Epoch 15441 - Train Loss: 0.095028, Train Acc: 0.861538 | Val Loss: 0.118534, Val Acc: 0.762887\n",
      "Epoch 15442 - Train Loss: 0.095024, Train Acc: 0.861538 | Val Loss: 0.118531, Val Acc: 0.762887\n",
      "Epoch 15443 - Train Loss: 0.095020, Train Acc: 0.861538 | Val Loss: 0.118529, Val Acc: 0.762887\n",
      "Epoch 15444 - Train Loss: 0.095016, Train Acc: 0.861538 | Val Loss: 0.118526, Val Acc: 0.762887\n",
      "Epoch 15445 - Train Loss: 0.095012, Train Acc: 0.861538 | Val Loss: 0.118524, Val Acc: 0.762887\n",
      "Epoch 15446 - Train Loss: 0.095008, Train Acc: 0.861538 | Val Loss: 0.118521, Val Acc: 0.762887\n",
      "Epoch 15447 - Train Loss: 0.095004, Train Acc: 0.861538 | Val Loss: 0.118519, Val Acc: 0.762887\n",
      "Epoch 15448 - Train Loss: 0.095001, Train Acc: 0.861538 | Val Loss: 0.118516, Val Acc: 0.762887\n",
      "Epoch 15449 - Train Loss: 0.094997, Train Acc: 0.861538 | Val Loss: 0.118514, Val Acc: 0.762887\n",
      "Epoch 15450 - Train Loss: 0.094993, Train Acc: 0.861538 | Val Loss: 0.118511, Val Acc: 0.762887\n",
      "Epoch 15451 - Train Loss: 0.094989, Train Acc: 0.861538 | Val Loss: 0.118509, Val Acc: 0.762887\n",
      "Epoch 15452 - Train Loss: 0.094985, Train Acc: 0.861538 | Val Loss: 0.118506, Val Acc: 0.762887\n",
      "Epoch 15453 - Train Loss: 0.094981, Train Acc: 0.861538 | Val Loss: 0.118504, Val Acc: 0.762887\n",
      "Epoch 15454 - Train Loss: 0.094977, Train Acc: 0.861538 | Val Loss: 0.118501, Val Acc: 0.762887\n",
      "Epoch 15455 - Train Loss: 0.094973, Train Acc: 0.861538 | Val Loss: 0.118499, Val Acc: 0.762887\n",
      "Epoch 15456 - Train Loss: 0.094970, Train Acc: 0.861538 | Val Loss: 0.118496, Val Acc: 0.762887\n",
      "Epoch 15457 - Train Loss: 0.094966, Train Acc: 0.861538 | Val Loss: 0.118494, Val Acc: 0.762887\n",
      "Epoch 15458 - Train Loss: 0.094962, Train Acc: 0.861538 | Val Loss: 0.118491, Val Acc: 0.762887\n",
      "Epoch 15459 - Train Loss: 0.094958, Train Acc: 0.861538 | Val Loss: 0.118489, Val Acc: 0.762887\n",
      "Epoch 15460 - Train Loss: 0.094954, Train Acc: 0.861538 | Val Loss: 0.118486, Val Acc: 0.762887\n",
      "Epoch 15461 - Train Loss: 0.094950, Train Acc: 0.861538 | Val Loss: 0.118484, Val Acc: 0.762887\n",
      "Epoch 15462 - Train Loss: 0.094946, Train Acc: 0.861538 | Val Loss: 0.118481, Val Acc: 0.762887\n",
      "Epoch 15463 - Train Loss: 0.094942, Train Acc: 0.861538 | Val Loss: 0.118479, Val Acc: 0.762887\n",
      "Epoch 15464 - Train Loss: 0.094939, Train Acc: 0.861538 | Val Loss: 0.118476, Val Acc: 0.762887\n",
      "Epoch 15465 - Train Loss: 0.094935, Train Acc: 0.861538 | Val Loss: 0.118474, Val Acc: 0.762887\n",
      "Epoch 15466 - Train Loss: 0.094931, Train Acc: 0.861538 | Val Loss: 0.118471, Val Acc: 0.762887\n",
      "Epoch 15467 - Train Loss: 0.094927, Train Acc: 0.861538 | Val Loss: 0.118469, Val Acc: 0.762887\n",
      "Epoch 15468 - Train Loss: 0.094923, Train Acc: 0.861538 | Val Loss: 0.118466, Val Acc: 0.762887\n",
      "Epoch 15469 - Train Loss: 0.094919, Train Acc: 0.861538 | Val Loss: 0.118464, Val Acc: 0.762887\n",
      "Epoch 15470 - Train Loss: 0.094915, Train Acc: 0.861538 | Val Loss: 0.118461, Val Acc: 0.762887\n",
      "Epoch 15471 - Train Loss: 0.094911, Train Acc: 0.861538 | Val Loss: 0.118459, Val Acc: 0.762887\n",
      "Epoch 15472 - Train Loss: 0.094908, Train Acc: 0.861538 | Val Loss: 0.118456, Val Acc: 0.762887\n",
      "Epoch 15473 - Train Loss: 0.094904, Train Acc: 0.861538 | Val Loss: 0.118454, Val Acc: 0.762887\n",
      "Epoch 15474 - Train Loss: 0.094900, Train Acc: 0.861538 | Val Loss: 0.118451, Val Acc: 0.762887\n",
      "Epoch 15475 - Train Loss: 0.094896, Train Acc: 0.861538 | Val Loss: 0.118449, Val Acc: 0.762887\n",
      "Epoch 15476 - Train Loss: 0.094892, Train Acc: 0.861538 | Val Loss: 0.118446, Val Acc: 0.762887\n",
      "Epoch 15477 - Train Loss: 0.094888, Train Acc: 0.861538 | Val Loss: 0.118444, Val Acc: 0.762887\n",
      "Epoch 15478 - Train Loss: 0.094884, Train Acc: 0.861538 | Val Loss: 0.118441, Val Acc: 0.762887\n",
      "Epoch 15479 - Train Loss: 0.094881, Train Acc: 0.861538 | Val Loss: 0.118439, Val Acc: 0.773196\n",
      "Epoch 15480 - Train Loss: 0.094877, Train Acc: 0.861538 | Val Loss: 0.118436, Val Acc: 0.773196\n",
      "Epoch 15481 - Train Loss: 0.094873, Train Acc: 0.861538 | Val Loss: 0.118434, Val Acc: 0.773196\n",
      "Epoch 15482 - Train Loss: 0.094869, Train Acc: 0.861538 | Val Loss: 0.118431, Val Acc: 0.773196\n",
      "Epoch 15483 - Train Loss: 0.094865, Train Acc: 0.861538 | Val Loss: 0.118429, Val Acc: 0.773196\n",
      "Epoch 15484 - Train Loss: 0.094861, Train Acc: 0.861538 | Val Loss: 0.118426, Val Acc: 0.773196\n",
      "Epoch 15485 - Train Loss: 0.094857, Train Acc: 0.861538 | Val Loss: 0.118424, Val Acc: 0.773196\n",
      "Epoch 15486 - Train Loss: 0.094853, Train Acc: 0.861538 | Val Loss: 0.118421, Val Acc: 0.773196\n",
      "Epoch 15487 - Train Loss: 0.094850, Train Acc: 0.861538 | Val Loss: 0.118419, Val Acc: 0.773196\n",
      "Epoch 15488 - Train Loss: 0.094846, Train Acc: 0.861538 | Val Loss: 0.118416, Val Acc: 0.773196\n",
      "Epoch 15489 - Train Loss: 0.094842, Train Acc: 0.861538 | Val Loss: 0.118414, Val Acc: 0.773196\n",
      "Epoch 15490 - Train Loss: 0.094838, Train Acc: 0.861538 | Val Loss: 0.118412, Val Acc: 0.773196\n",
      "Epoch 15491 - Train Loss: 0.094834, Train Acc: 0.861538 | Val Loss: 0.118409, Val Acc: 0.773196\n",
      "Epoch 15492 - Train Loss: 0.094830, Train Acc: 0.861538 | Val Loss: 0.118407, Val Acc: 0.773196\n",
      "Epoch 15493 - Train Loss: 0.094826, Train Acc: 0.861538 | Val Loss: 0.118404, Val Acc: 0.773196\n",
      "Epoch 15494 - Train Loss: 0.094823, Train Acc: 0.861538 | Val Loss: 0.118402, Val Acc: 0.773196\n",
      "Epoch 15495 - Train Loss: 0.094819, Train Acc: 0.861538 | Val Loss: 0.118399, Val Acc: 0.773196\n",
      "Epoch 15496 - Train Loss: 0.094815, Train Acc: 0.861538 | Val Loss: 0.118397, Val Acc: 0.773196\n",
      "Epoch 15497 - Train Loss: 0.094811, Train Acc: 0.861538 | Val Loss: 0.118394, Val Acc: 0.773196\n",
      "Epoch 15498 - Train Loss: 0.094807, Train Acc: 0.861538 | Val Loss: 0.118392, Val Acc: 0.773196\n",
      "Epoch 15499 - Train Loss: 0.094803, Train Acc: 0.861538 | Val Loss: 0.118389, Val Acc: 0.773196\n",
      "Epoch 15500 - Train Loss: 0.094799, Train Acc: 0.861538 | Val Loss: 0.118387, Val Acc: 0.773196\n",
      "Epoch 15501 - Train Loss: 0.094796, Train Acc: 0.861538 | Val Loss: 0.118384, Val Acc: 0.773196\n",
      "Epoch 15502 - Train Loss: 0.094792, Train Acc: 0.861538 | Val Loss: 0.118382, Val Acc: 0.773196\n",
      "Epoch 15503 - Train Loss: 0.094788, Train Acc: 0.861538 | Val Loss: 0.118379, Val Acc: 0.773196\n",
      "Epoch 15504 - Train Loss: 0.094784, Train Acc: 0.861538 | Val Loss: 0.118377, Val Acc: 0.773196\n",
      "Epoch 15505 - Train Loss: 0.094780, Train Acc: 0.861538 | Val Loss: 0.118374, Val Acc: 0.773196\n",
      "Epoch 15506 - Train Loss: 0.094776, Train Acc: 0.861538 | Val Loss: 0.118372, Val Acc: 0.773196\n",
      "Epoch 15507 - Train Loss: 0.094772, Train Acc: 0.861538 | Val Loss: 0.118369, Val Acc: 0.773196\n",
      "Epoch 15508 - Train Loss: 0.094769, Train Acc: 0.861538 | Val Loss: 0.118367, Val Acc: 0.773196\n",
      "Epoch 15509 - Train Loss: 0.094765, Train Acc: 0.861538 | Val Loss: 0.118364, Val Acc: 0.773196\n",
      "Epoch 15510 - Train Loss: 0.094761, Train Acc: 0.861538 | Val Loss: 0.118362, Val Acc: 0.773196\n",
      "Epoch 15511 - Train Loss: 0.094757, Train Acc: 0.861538 | Val Loss: 0.118360, Val Acc: 0.773196\n",
      "Epoch 15512 - Train Loss: 0.094753, Train Acc: 0.861538 | Val Loss: 0.118357, Val Acc: 0.773196\n",
      "Epoch 15513 - Train Loss: 0.094749, Train Acc: 0.861538 | Val Loss: 0.118355, Val Acc: 0.773196\n",
      "Epoch 15514 - Train Loss: 0.094746, Train Acc: 0.861538 | Val Loss: 0.118352, Val Acc: 0.773196\n",
      "Epoch 15515 - Train Loss: 0.094742, Train Acc: 0.861538 | Val Loss: 0.118350, Val Acc: 0.773196\n",
      "Epoch 15516 - Train Loss: 0.094738, Train Acc: 0.861538 | Val Loss: 0.118347, Val Acc: 0.773196\n",
      "Epoch 15517 - Train Loss: 0.094734, Train Acc: 0.861538 | Val Loss: 0.118345, Val Acc: 0.773196\n",
      "Epoch 15518 - Train Loss: 0.094730, Train Acc: 0.861538 | Val Loss: 0.118342, Val Acc: 0.773196\n",
      "Epoch 15519 - Train Loss: 0.094726, Train Acc: 0.861538 | Val Loss: 0.118340, Val Acc: 0.773196\n",
      "Epoch 15520 - Train Loss: 0.094722, Train Acc: 0.861538 | Val Loss: 0.118337, Val Acc: 0.773196\n",
      "Epoch 15521 - Train Loss: 0.094719, Train Acc: 0.861538 | Val Loss: 0.118335, Val Acc: 0.773196\n",
      "Epoch 15522 - Train Loss: 0.094715, Train Acc: 0.861538 | Val Loss: 0.118332, Val Acc: 0.773196\n",
      "Epoch 15523 - Train Loss: 0.094711, Train Acc: 0.861538 | Val Loss: 0.118330, Val Acc: 0.773196\n",
      "Epoch 15524 - Train Loss: 0.094707, Train Acc: 0.861538 | Val Loss: 0.118327, Val Acc: 0.773196\n",
      "Epoch 15525 - Train Loss: 0.094703, Train Acc: 0.861538 | Val Loss: 0.118325, Val Acc: 0.773196\n",
      "Epoch 15526 - Train Loss: 0.094699, Train Acc: 0.861538 | Val Loss: 0.118323, Val Acc: 0.773196\n",
      "Epoch 15527 - Train Loss: 0.094696, Train Acc: 0.861538 | Val Loss: 0.118320, Val Acc: 0.773196\n",
      "Epoch 15528 - Train Loss: 0.094692, Train Acc: 0.861538 | Val Loss: 0.118318, Val Acc: 0.773196\n",
      "Epoch 15529 - Train Loss: 0.094688, Train Acc: 0.861538 | Val Loss: 0.118315, Val Acc: 0.773196\n",
      "Epoch 15530 - Train Loss: 0.094684, Train Acc: 0.861538 | Val Loss: 0.118313, Val Acc: 0.773196\n",
      "Epoch 15531 - Train Loss: 0.094680, Train Acc: 0.861538 | Val Loss: 0.118310, Val Acc: 0.773196\n",
      "Epoch 15532 - Train Loss: 0.094676, Train Acc: 0.861538 | Val Loss: 0.118308, Val Acc: 0.773196\n",
      "Epoch 15533 - Train Loss: 0.094673, Train Acc: 0.861538 | Val Loss: 0.118305, Val Acc: 0.773196\n",
      "Epoch 15534 - Train Loss: 0.094669, Train Acc: 0.861538 | Val Loss: 0.118303, Val Acc: 0.773196\n",
      "Epoch 15535 - Train Loss: 0.094665, Train Acc: 0.861538 | Val Loss: 0.118300, Val Acc: 0.773196\n",
      "Epoch 15536 - Train Loss: 0.094661, Train Acc: 0.861538 | Val Loss: 0.118298, Val Acc: 0.773196\n",
      "Epoch 15537 - Train Loss: 0.094657, Train Acc: 0.861538 | Val Loss: 0.118295, Val Acc: 0.773196\n",
      "Epoch 15538 - Train Loss: 0.094653, Train Acc: 0.861538 | Val Loss: 0.118293, Val Acc: 0.773196\n",
      "Epoch 15539 - Train Loss: 0.094649, Train Acc: 0.861538 | Val Loss: 0.118291, Val Acc: 0.773196\n",
      "Epoch 15540 - Train Loss: 0.094646, Train Acc: 0.861538 | Val Loss: 0.118288, Val Acc: 0.773196\n",
      "Epoch 15541 - Train Loss: 0.094642, Train Acc: 0.861538 | Val Loss: 0.118286, Val Acc: 0.773196\n",
      "Epoch 15542 - Train Loss: 0.094638, Train Acc: 0.861538 | Val Loss: 0.118283, Val Acc: 0.773196\n",
      "Epoch 15543 - Train Loss: 0.094634, Train Acc: 0.861538 | Val Loss: 0.118281, Val Acc: 0.773196\n",
      "Epoch 15544 - Train Loss: 0.094630, Train Acc: 0.861538 | Val Loss: 0.118278, Val Acc: 0.773196\n",
      "Epoch 15545 - Train Loss: 0.094626, Train Acc: 0.861538 | Val Loss: 0.118276, Val Acc: 0.773196\n",
      "Epoch 15546 - Train Loss: 0.094623, Train Acc: 0.861538 | Val Loss: 0.118273, Val Acc: 0.773196\n",
      "Epoch 15547 - Train Loss: 0.094619, Train Acc: 0.861538 | Val Loss: 0.118271, Val Acc: 0.773196\n",
      "Epoch 15548 - Train Loss: 0.094615, Train Acc: 0.861538 | Val Loss: 0.118269, Val Acc: 0.773196\n",
      "Epoch 15549 - Train Loss: 0.094611, Train Acc: 0.861538 | Val Loss: 0.118266, Val Acc: 0.773196\n",
      "Epoch 15550 - Train Loss: 0.094607, Train Acc: 0.861538 | Val Loss: 0.118264, Val Acc: 0.773196\n",
      "Epoch 15551 - Train Loss: 0.094603, Train Acc: 0.861538 | Val Loss: 0.118261, Val Acc: 0.773196\n",
      "Epoch 15552 - Train Loss: 0.094600, Train Acc: 0.861538 | Val Loss: 0.118259, Val Acc: 0.773196\n",
      "Epoch 15553 - Train Loss: 0.094596, Train Acc: 0.861538 | Val Loss: 0.118256, Val Acc: 0.773196\n",
      "Epoch 15554 - Train Loss: 0.094592, Train Acc: 0.861538 | Val Loss: 0.118254, Val Acc: 0.773196\n",
      "Epoch 15555 - Train Loss: 0.094588, Train Acc: 0.861538 | Val Loss: 0.118251, Val Acc: 0.773196\n",
      "Epoch 15556 - Train Loss: 0.094584, Train Acc: 0.861538 | Val Loss: 0.118249, Val Acc: 0.773196\n",
      "Epoch 15557 - Train Loss: 0.094581, Train Acc: 0.861538 | Val Loss: 0.118246, Val Acc: 0.773196\n",
      "Epoch 15558 - Train Loss: 0.094577, Train Acc: 0.861538 | Val Loss: 0.118244, Val Acc: 0.773196\n",
      "Epoch 15559 - Train Loss: 0.094573, Train Acc: 0.861538 | Val Loss: 0.118242, Val Acc: 0.773196\n",
      "Epoch 15560 - Train Loss: 0.094569, Train Acc: 0.861538 | Val Loss: 0.118239, Val Acc: 0.773196\n",
      "Epoch 15561 - Train Loss: 0.094565, Train Acc: 0.861538 | Val Loss: 0.118237, Val Acc: 0.773196\n",
      "Epoch 15562 - Train Loss: 0.094561, Train Acc: 0.861538 | Val Loss: 0.118234, Val Acc: 0.773196\n",
      "Epoch 15563 - Train Loss: 0.094558, Train Acc: 0.861538 | Val Loss: 0.118232, Val Acc: 0.773196\n",
      "Epoch 15564 - Train Loss: 0.094554, Train Acc: 0.861538 | Val Loss: 0.118229, Val Acc: 0.773196\n",
      "Epoch 15565 - Train Loss: 0.094550, Train Acc: 0.861538 | Val Loss: 0.118227, Val Acc: 0.773196\n",
      "Epoch 15566 - Train Loss: 0.094546, Train Acc: 0.861538 | Val Loss: 0.118224, Val Acc: 0.773196\n",
      "Epoch 15567 - Train Loss: 0.094542, Train Acc: 0.861538 | Val Loss: 0.118222, Val Acc: 0.773196\n",
      "Epoch 15568 - Train Loss: 0.094538, Train Acc: 0.861538 | Val Loss: 0.118220, Val Acc: 0.773196\n",
      "Epoch 15569 - Train Loss: 0.094535, Train Acc: 0.861538 | Val Loss: 0.118217, Val Acc: 0.773196\n",
      "Epoch 15570 - Train Loss: 0.094531, Train Acc: 0.861538 | Val Loss: 0.118215, Val Acc: 0.773196\n",
      "Epoch 15571 - Train Loss: 0.094527, Train Acc: 0.861538 | Val Loss: 0.118212, Val Acc: 0.773196\n",
      "Epoch 15572 - Train Loss: 0.094523, Train Acc: 0.861538 | Val Loss: 0.118210, Val Acc: 0.773196\n",
      "Epoch 15573 - Train Loss: 0.094519, Train Acc: 0.861538 | Val Loss: 0.118207, Val Acc: 0.773196\n",
      "Epoch 15574 - Train Loss: 0.094516, Train Acc: 0.861538 | Val Loss: 0.118205, Val Acc: 0.773196\n",
      "Epoch 15575 - Train Loss: 0.094512, Train Acc: 0.861538 | Val Loss: 0.118203, Val Acc: 0.773196\n",
      "Epoch 15576 - Train Loss: 0.094508, Train Acc: 0.861538 | Val Loss: 0.118200, Val Acc: 0.773196\n",
      "Epoch 15577 - Train Loss: 0.094504, Train Acc: 0.861538 | Val Loss: 0.118198, Val Acc: 0.773196\n",
      "Epoch 15578 - Train Loss: 0.094500, Train Acc: 0.861538 | Val Loss: 0.118195, Val Acc: 0.773196\n",
      "Epoch 15579 - Train Loss: 0.094496, Train Acc: 0.861538 | Val Loss: 0.118193, Val Acc: 0.773196\n",
      "Epoch 15580 - Train Loss: 0.094493, Train Acc: 0.861538 | Val Loss: 0.118190, Val Acc: 0.773196\n",
      "Epoch 15581 - Train Loss: 0.094489, Train Acc: 0.861538 | Val Loss: 0.118188, Val Acc: 0.773196\n",
      "Epoch 15582 - Train Loss: 0.094485, Train Acc: 0.861538 | Val Loss: 0.118185, Val Acc: 0.773196\n",
      "Epoch 15583 - Train Loss: 0.094481, Train Acc: 0.861538 | Val Loss: 0.118183, Val Acc: 0.773196\n",
      "Epoch 15584 - Train Loss: 0.094477, Train Acc: 0.861538 | Val Loss: 0.118181, Val Acc: 0.773196\n",
      "Epoch 15585 - Train Loss: 0.094474, Train Acc: 0.861538 | Val Loss: 0.118178, Val Acc: 0.773196\n",
      "Epoch 15586 - Train Loss: 0.094470, Train Acc: 0.861538 | Val Loss: 0.118176, Val Acc: 0.773196\n",
      "Epoch 15587 - Train Loss: 0.094466, Train Acc: 0.861538 | Val Loss: 0.118173, Val Acc: 0.773196\n",
      "Epoch 15588 - Train Loss: 0.094462, Train Acc: 0.861538 | Val Loss: 0.118171, Val Acc: 0.773196\n",
      "Epoch 15589 - Train Loss: 0.094458, Train Acc: 0.861538 | Val Loss: 0.118168, Val Acc: 0.773196\n",
      "Epoch 15590 - Train Loss: 0.094454, Train Acc: 0.861538 | Val Loss: 0.118166, Val Acc: 0.773196\n",
      "Epoch 15591 - Train Loss: 0.094451, Train Acc: 0.861538 | Val Loss: 0.118164, Val Acc: 0.773196\n",
      "Epoch 15592 - Train Loss: 0.094447, Train Acc: 0.861538 | Val Loss: 0.118161, Val Acc: 0.773196\n",
      "Epoch 15593 - Train Loss: 0.094443, Train Acc: 0.861538 | Val Loss: 0.118159, Val Acc: 0.773196\n",
      "Epoch 15594 - Train Loss: 0.094439, Train Acc: 0.861538 | Val Loss: 0.118156, Val Acc: 0.773196\n",
      "Epoch 15595 - Train Loss: 0.094435, Train Acc: 0.861538 | Val Loss: 0.118154, Val Acc: 0.773196\n",
      "Epoch 15596 - Train Loss: 0.094432, Train Acc: 0.861538 | Val Loss: 0.118151, Val Acc: 0.773196\n",
      "Epoch 15597 - Train Loss: 0.094428, Train Acc: 0.861538 | Val Loss: 0.118149, Val Acc: 0.773196\n",
      "Epoch 15598 - Train Loss: 0.094424, Train Acc: 0.861538 | Val Loss: 0.118147, Val Acc: 0.773196\n",
      "Epoch 15599 - Train Loss: 0.094420, Train Acc: 0.861538 | Val Loss: 0.118144, Val Acc: 0.773196\n",
      "Epoch 15600 - Train Loss: 0.094416, Train Acc: 0.861538 | Val Loss: 0.118142, Val Acc: 0.773196\n",
      "Epoch 15601 - Train Loss: 0.094413, Train Acc: 0.861538 | Val Loss: 0.118139, Val Acc: 0.773196\n",
      "Epoch 15602 - Train Loss: 0.094409, Train Acc: 0.861538 | Val Loss: 0.118137, Val Acc: 0.773196\n",
      "Epoch 15603 - Train Loss: 0.094405, Train Acc: 0.861538 | Val Loss: 0.118134, Val Acc: 0.773196\n",
      "Epoch 15604 - Train Loss: 0.094401, Train Acc: 0.861538 | Val Loss: 0.118132, Val Acc: 0.773196\n",
      "Epoch 15605 - Train Loss: 0.094397, Train Acc: 0.861538 | Val Loss: 0.118130, Val Acc: 0.773196\n",
      "Epoch 15606 - Train Loss: 0.094394, Train Acc: 0.861538 | Val Loss: 0.118127, Val Acc: 0.773196\n",
      "Epoch 15607 - Train Loss: 0.094390, Train Acc: 0.861538 | Val Loss: 0.118125, Val Acc: 0.773196\n",
      "Epoch 15608 - Train Loss: 0.094386, Train Acc: 0.861538 | Val Loss: 0.118122, Val Acc: 0.773196\n",
      "Epoch 15609 - Train Loss: 0.094382, Train Acc: 0.861538 | Val Loss: 0.118120, Val Acc: 0.773196\n",
      "Epoch 15610 - Train Loss: 0.094378, Train Acc: 0.861538 | Val Loss: 0.118118, Val Acc: 0.773196\n",
      "Epoch 15611 - Train Loss: 0.094375, Train Acc: 0.861538 | Val Loss: 0.118115, Val Acc: 0.773196\n",
      "Epoch 15612 - Train Loss: 0.094371, Train Acc: 0.861538 | Val Loss: 0.118113, Val Acc: 0.773196\n",
      "Epoch 15613 - Train Loss: 0.094367, Train Acc: 0.861538 | Val Loss: 0.118110, Val Acc: 0.773196\n",
      "Epoch 15614 - Train Loss: 0.094363, Train Acc: 0.861538 | Val Loss: 0.118108, Val Acc: 0.773196\n",
      "Epoch 15615 - Train Loss: 0.094359, Train Acc: 0.861538 | Val Loss: 0.118105, Val Acc: 0.773196\n",
      "Epoch 15616 - Train Loss: 0.094356, Train Acc: 0.861538 | Val Loss: 0.118103, Val Acc: 0.773196\n",
      "Epoch 15617 - Train Loss: 0.094352, Train Acc: 0.861538 | Val Loss: 0.118101, Val Acc: 0.773196\n",
      "Epoch 15618 - Train Loss: 0.094348, Train Acc: 0.861538 | Val Loss: 0.118098, Val Acc: 0.773196\n",
      "Epoch 15619 - Train Loss: 0.094344, Train Acc: 0.861538 | Val Loss: 0.118096, Val Acc: 0.773196\n",
      "Epoch 15620 - Train Loss: 0.094340, Train Acc: 0.861538 | Val Loss: 0.118093, Val Acc: 0.773196\n",
      "Epoch 15621 - Train Loss: 0.094337, Train Acc: 0.861538 | Val Loss: 0.118091, Val Acc: 0.773196\n",
      "Epoch 15622 - Train Loss: 0.094333, Train Acc: 0.861538 | Val Loss: 0.118089, Val Acc: 0.773196\n",
      "Epoch 15623 - Train Loss: 0.094329, Train Acc: 0.861538 | Val Loss: 0.118086, Val Acc: 0.773196\n",
      "Epoch 15624 - Train Loss: 0.094325, Train Acc: 0.861538 | Val Loss: 0.118084, Val Acc: 0.773196\n",
      "Epoch 15625 - Train Loss: 0.094321, Train Acc: 0.861538 | Val Loss: 0.118081, Val Acc: 0.773196\n",
      "Epoch 15626 - Train Loss: 0.094318, Train Acc: 0.861538 | Val Loss: 0.118079, Val Acc: 0.773196\n",
      "Epoch 15627 - Train Loss: 0.094314, Train Acc: 0.861538 | Val Loss: 0.118076, Val Acc: 0.773196\n",
      "Epoch 15628 - Train Loss: 0.094310, Train Acc: 0.861538 | Val Loss: 0.118074, Val Acc: 0.773196\n",
      "Epoch 15629 - Train Loss: 0.094306, Train Acc: 0.861538 | Val Loss: 0.118072, Val Acc: 0.773196\n",
      "Epoch 15630 - Train Loss: 0.094302, Train Acc: 0.861538 | Val Loss: 0.118069, Val Acc: 0.773196\n",
      "Epoch 15631 - Train Loss: 0.094299, Train Acc: 0.861538 | Val Loss: 0.118067, Val Acc: 0.773196\n",
      "Epoch 15632 - Train Loss: 0.094295, Train Acc: 0.861538 | Val Loss: 0.118064, Val Acc: 0.773196\n",
      "Epoch 15633 - Train Loss: 0.094291, Train Acc: 0.861538 | Val Loss: 0.118062, Val Acc: 0.773196\n",
      "Epoch 15634 - Train Loss: 0.094287, Train Acc: 0.861538 | Val Loss: 0.118060, Val Acc: 0.773196\n",
      "Epoch 15635 - Train Loss: 0.094283, Train Acc: 0.861538 | Val Loss: 0.118057, Val Acc: 0.773196\n",
      "Epoch 15636 - Train Loss: 0.094280, Train Acc: 0.861538 | Val Loss: 0.118055, Val Acc: 0.773196\n",
      "Epoch 15637 - Train Loss: 0.094276, Train Acc: 0.861538 | Val Loss: 0.118052, Val Acc: 0.773196\n",
      "Epoch 15638 - Train Loss: 0.094272, Train Acc: 0.861538 | Val Loss: 0.118050, Val Acc: 0.773196\n",
      "Epoch 15639 - Train Loss: 0.094268, Train Acc: 0.861538 | Val Loss: 0.118048, Val Acc: 0.773196\n",
      "Epoch 15640 - Train Loss: 0.094265, Train Acc: 0.861538 | Val Loss: 0.118045, Val Acc: 0.773196\n",
      "Epoch 15641 - Train Loss: 0.094261, Train Acc: 0.861538 | Val Loss: 0.118043, Val Acc: 0.773196\n",
      "Epoch 15642 - Train Loss: 0.094257, Train Acc: 0.861538 | Val Loss: 0.118040, Val Acc: 0.773196\n",
      "Epoch 15643 - Train Loss: 0.094253, Train Acc: 0.861538 | Val Loss: 0.118038, Val Acc: 0.773196\n",
      "Epoch 15644 - Train Loss: 0.094249, Train Acc: 0.861538 | Val Loss: 0.118036, Val Acc: 0.773196\n",
      "Epoch 15645 - Train Loss: 0.094246, Train Acc: 0.861538 | Val Loss: 0.118033, Val Acc: 0.773196\n",
      "Epoch 15646 - Train Loss: 0.094242, Train Acc: 0.861538 | Val Loss: 0.118031, Val Acc: 0.773196\n",
      "Epoch 15647 - Train Loss: 0.094238, Train Acc: 0.861538 | Val Loss: 0.118028, Val Acc: 0.773196\n",
      "Epoch 15648 - Train Loss: 0.094234, Train Acc: 0.861538 | Val Loss: 0.118026, Val Acc: 0.773196\n",
      "Epoch 15649 - Train Loss: 0.094230, Train Acc: 0.861538 | Val Loss: 0.118024, Val Acc: 0.773196\n",
      "Epoch 15650 - Train Loss: 0.094227, Train Acc: 0.861538 | Val Loss: 0.118021, Val Acc: 0.773196\n",
      "Epoch 15651 - Train Loss: 0.094223, Train Acc: 0.861538 | Val Loss: 0.118019, Val Acc: 0.773196\n",
      "Epoch 15652 - Train Loss: 0.094219, Train Acc: 0.861538 | Val Loss: 0.118016, Val Acc: 0.773196\n",
      "Epoch 15653 - Train Loss: 0.094215, Train Acc: 0.861538 | Val Loss: 0.118014, Val Acc: 0.773196\n",
      "Epoch 15654 - Train Loss: 0.094212, Train Acc: 0.861538 | Val Loss: 0.118012, Val Acc: 0.773196\n",
      "Epoch 15655 - Train Loss: 0.094208, Train Acc: 0.861538 | Val Loss: 0.118009, Val Acc: 0.773196\n",
      "Epoch 15656 - Train Loss: 0.094204, Train Acc: 0.861538 | Val Loss: 0.118007, Val Acc: 0.773196\n",
      "Epoch 15657 - Train Loss: 0.094200, Train Acc: 0.861538 | Val Loss: 0.118004, Val Acc: 0.773196\n",
      "Epoch 15658 - Train Loss: 0.094196, Train Acc: 0.861538 | Val Loss: 0.118002, Val Acc: 0.773196\n",
      "Epoch 15659 - Train Loss: 0.094193, Train Acc: 0.861538 | Val Loss: 0.118000, Val Acc: 0.773196\n",
      "Epoch 15660 - Train Loss: 0.094189, Train Acc: 0.861538 | Val Loss: 0.117997, Val Acc: 0.773196\n",
      "Epoch 15661 - Train Loss: 0.094185, Train Acc: 0.861538 | Val Loss: 0.117995, Val Acc: 0.773196\n",
      "Epoch 15662 - Train Loss: 0.094181, Train Acc: 0.861538 | Val Loss: 0.117992, Val Acc: 0.773196\n",
      "Epoch 15663 - Train Loss: 0.094178, Train Acc: 0.861538 | Val Loss: 0.117990, Val Acc: 0.773196\n",
      "Epoch 15664 - Train Loss: 0.094174, Train Acc: 0.861538 | Val Loss: 0.117988, Val Acc: 0.773196\n",
      "Epoch 15665 - Train Loss: 0.094170, Train Acc: 0.861538 | Val Loss: 0.117985, Val Acc: 0.773196\n",
      "Epoch 15666 - Train Loss: 0.094166, Train Acc: 0.861538 | Val Loss: 0.117983, Val Acc: 0.773196\n",
      "Epoch 15667 - Train Loss: 0.094162, Train Acc: 0.861538 | Val Loss: 0.117980, Val Acc: 0.773196\n",
      "Epoch 15668 - Train Loss: 0.094159, Train Acc: 0.861538 | Val Loss: 0.117978, Val Acc: 0.773196\n",
      "Epoch 15669 - Train Loss: 0.094155, Train Acc: 0.861538 | Val Loss: 0.117976, Val Acc: 0.773196\n",
      "Epoch 15670 - Train Loss: 0.094151, Train Acc: 0.861538 | Val Loss: 0.117973, Val Acc: 0.773196\n",
      "Epoch 15671 - Train Loss: 0.094147, Train Acc: 0.861538 | Val Loss: 0.117971, Val Acc: 0.773196\n",
      "Epoch 15672 - Train Loss: 0.094144, Train Acc: 0.861538 | Val Loss: 0.117968, Val Acc: 0.773196\n",
      "Epoch 15673 - Train Loss: 0.094140, Train Acc: 0.861538 | Val Loss: 0.117966, Val Acc: 0.773196\n",
      "Epoch 15674 - Train Loss: 0.094136, Train Acc: 0.861538 | Val Loss: 0.117964, Val Acc: 0.773196\n",
      "Epoch 15675 - Train Loss: 0.094132, Train Acc: 0.861538 | Val Loss: 0.117961, Val Acc: 0.773196\n",
      "Epoch 15676 - Train Loss: 0.094128, Train Acc: 0.861538 | Val Loss: 0.117959, Val Acc: 0.773196\n",
      "Epoch 15677 - Train Loss: 0.094125, Train Acc: 0.861538 | Val Loss: 0.117956, Val Acc: 0.773196\n",
      "Epoch 15678 - Train Loss: 0.094121, Train Acc: 0.861538 | Val Loss: 0.117954, Val Acc: 0.773196\n",
      "Epoch 15679 - Train Loss: 0.094117, Train Acc: 0.861538 | Val Loss: 0.117952, Val Acc: 0.773196\n",
      "Epoch 15680 - Train Loss: 0.094113, Train Acc: 0.861538 | Val Loss: 0.117949, Val Acc: 0.773196\n",
      "Epoch 15681 - Train Loss: 0.094110, Train Acc: 0.861538 | Val Loss: 0.117947, Val Acc: 0.773196\n",
      "Epoch 15682 - Train Loss: 0.094106, Train Acc: 0.861538 | Val Loss: 0.117945, Val Acc: 0.773196\n",
      "Epoch 15683 - Train Loss: 0.094102, Train Acc: 0.861538 | Val Loss: 0.117942, Val Acc: 0.773196\n",
      "Epoch 15684 - Train Loss: 0.094098, Train Acc: 0.861538 | Val Loss: 0.117940, Val Acc: 0.773196\n",
      "Epoch 15685 - Train Loss: 0.094095, Train Acc: 0.861538 | Val Loss: 0.117937, Val Acc: 0.773196\n",
      "Epoch 15686 - Train Loss: 0.094091, Train Acc: 0.861538 | Val Loss: 0.117935, Val Acc: 0.773196\n",
      "Epoch 15687 - Train Loss: 0.094087, Train Acc: 0.861538 | Val Loss: 0.117933, Val Acc: 0.773196\n",
      "Epoch 15688 - Train Loss: 0.094083, Train Acc: 0.861538 | Val Loss: 0.117930, Val Acc: 0.773196\n",
      "Epoch 15689 - Train Loss: 0.094080, Train Acc: 0.861538 | Val Loss: 0.117928, Val Acc: 0.773196\n",
      "Epoch 15690 - Train Loss: 0.094076, Train Acc: 0.861538 | Val Loss: 0.117926, Val Acc: 0.773196\n",
      "Epoch 15691 - Train Loss: 0.094072, Train Acc: 0.861538 | Val Loss: 0.117923, Val Acc: 0.773196\n",
      "Epoch 15692 - Train Loss: 0.094068, Train Acc: 0.861538 | Val Loss: 0.117921, Val Acc: 0.773196\n",
      "Epoch 15693 - Train Loss: 0.094064, Train Acc: 0.861538 | Val Loss: 0.117918, Val Acc: 0.773196\n",
      "Epoch 15694 - Train Loss: 0.094061, Train Acc: 0.861538 | Val Loss: 0.117916, Val Acc: 0.773196\n",
      "Epoch 15695 - Train Loss: 0.094057, Train Acc: 0.861538 | Val Loss: 0.117914, Val Acc: 0.773196\n",
      "Epoch 15696 - Train Loss: 0.094053, Train Acc: 0.861538 | Val Loss: 0.117911, Val Acc: 0.773196\n",
      "Epoch 15697 - Train Loss: 0.094049, Train Acc: 0.861538 | Val Loss: 0.117909, Val Acc: 0.773196\n",
      "Epoch 15698 - Train Loss: 0.094046, Train Acc: 0.861538 | Val Loss: 0.117906, Val Acc: 0.773196\n",
      "Epoch 15699 - Train Loss: 0.094042, Train Acc: 0.861538 | Val Loss: 0.117904, Val Acc: 0.773196\n",
      "Epoch 15700 - Train Loss: 0.094038, Train Acc: 0.861538 | Val Loss: 0.117902, Val Acc: 0.773196\n",
      "Epoch 15701 - Train Loss: 0.094034, Train Acc: 0.861538 | Val Loss: 0.117899, Val Acc: 0.773196\n",
      "Epoch 15702 - Train Loss: 0.094031, Train Acc: 0.861538 | Val Loss: 0.117897, Val Acc: 0.773196\n",
      "Epoch 15703 - Train Loss: 0.094027, Train Acc: 0.861538 | Val Loss: 0.117895, Val Acc: 0.773196\n",
      "Epoch 15704 - Train Loss: 0.094023, Train Acc: 0.861538 | Val Loss: 0.117892, Val Acc: 0.773196\n",
      "Epoch 15705 - Train Loss: 0.094019, Train Acc: 0.861538 | Val Loss: 0.117890, Val Acc: 0.773196\n",
      "Epoch 15706 - Train Loss: 0.094016, Train Acc: 0.861538 | Val Loss: 0.117887, Val Acc: 0.773196\n",
      "Epoch 15707 - Train Loss: 0.094012, Train Acc: 0.861538 | Val Loss: 0.117885, Val Acc: 0.773196\n",
      "Epoch 15708 - Train Loss: 0.094008, Train Acc: 0.861538 | Val Loss: 0.117883, Val Acc: 0.773196\n",
      "Epoch 15709 - Train Loss: 0.094004, Train Acc: 0.861538 | Val Loss: 0.117880, Val Acc: 0.773196\n",
      "Epoch 15710 - Train Loss: 0.094001, Train Acc: 0.861538 | Val Loss: 0.117878, Val Acc: 0.773196\n",
      "Epoch 15711 - Train Loss: 0.093997, Train Acc: 0.861538 | Val Loss: 0.117876, Val Acc: 0.773196\n",
      "Epoch 15712 - Train Loss: 0.093993, Train Acc: 0.861538 | Val Loss: 0.117873, Val Acc: 0.773196\n",
      "Epoch 15713 - Train Loss: 0.093989, Train Acc: 0.861538 | Val Loss: 0.117871, Val Acc: 0.773196\n",
      "Epoch 15714 - Train Loss: 0.093986, Train Acc: 0.861538 | Val Loss: 0.117869, Val Acc: 0.773196\n",
      "Epoch 15715 - Train Loss: 0.093982, Train Acc: 0.861538 | Val Loss: 0.117866, Val Acc: 0.773196\n",
      "Epoch 15716 - Train Loss: 0.093978, Train Acc: 0.861538 | Val Loss: 0.117864, Val Acc: 0.773196\n",
      "Epoch 15717 - Train Loss: 0.093974, Train Acc: 0.861538 | Val Loss: 0.117861, Val Acc: 0.773196\n",
      "Epoch 15718 - Train Loss: 0.093971, Train Acc: 0.861538 | Val Loss: 0.117859, Val Acc: 0.773196\n",
      "Epoch 15719 - Train Loss: 0.093967, Train Acc: 0.861538 | Val Loss: 0.117857, Val Acc: 0.773196\n",
      "Epoch 15720 - Train Loss: 0.093963, Train Acc: 0.861538 | Val Loss: 0.117854, Val Acc: 0.773196\n",
      "Epoch 15721 - Train Loss: 0.093959, Train Acc: 0.861538 | Val Loss: 0.117852, Val Acc: 0.773196\n",
      "Epoch 15722 - Train Loss: 0.093956, Train Acc: 0.861538 | Val Loss: 0.117850, Val Acc: 0.773196\n",
      "Epoch 15723 - Train Loss: 0.093952, Train Acc: 0.861538 | Val Loss: 0.117847, Val Acc: 0.773196\n",
      "Epoch 15724 - Train Loss: 0.093948, Train Acc: 0.861538 | Val Loss: 0.117845, Val Acc: 0.773196\n",
      "Epoch 15725 - Train Loss: 0.093944, Train Acc: 0.861538 | Val Loss: 0.117843, Val Acc: 0.773196\n",
      "Epoch 15726 - Train Loss: 0.093941, Train Acc: 0.861538 | Val Loss: 0.117840, Val Acc: 0.773196\n",
      "Epoch 15727 - Train Loss: 0.093937, Train Acc: 0.861538 | Val Loss: 0.117838, Val Acc: 0.773196\n",
      "Epoch 15728 - Train Loss: 0.093933, Train Acc: 0.861538 | Val Loss: 0.117835, Val Acc: 0.773196\n",
      "Epoch 15729 - Train Loss: 0.093929, Train Acc: 0.861538 | Val Loss: 0.117833, Val Acc: 0.773196\n",
      "Epoch 15730 - Train Loss: 0.093926, Train Acc: 0.861538 | Val Loss: 0.117831, Val Acc: 0.773196\n",
      "Epoch 15731 - Train Loss: 0.093922, Train Acc: 0.861538 | Val Loss: 0.117828, Val Acc: 0.773196\n",
      "Epoch 15732 - Train Loss: 0.093918, Train Acc: 0.861538 | Val Loss: 0.117826, Val Acc: 0.773196\n",
      "Epoch 15733 - Train Loss: 0.093914, Train Acc: 0.861538 | Val Loss: 0.117824, Val Acc: 0.773196\n",
      "Epoch 15734 - Train Loss: 0.093911, Train Acc: 0.861538 | Val Loss: 0.117821, Val Acc: 0.773196\n",
      "Epoch 15735 - Train Loss: 0.093907, Train Acc: 0.861538 | Val Loss: 0.117819, Val Acc: 0.773196\n",
      "Epoch 15736 - Train Loss: 0.093903, Train Acc: 0.861538 | Val Loss: 0.117817, Val Acc: 0.773196\n",
      "Epoch 15737 - Train Loss: 0.093899, Train Acc: 0.861538 | Val Loss: 0.117814, Val Acc: 0.773196\n",
      "Epoch 15738 - Train Loss: 0.093896, Train Acc: 0.861538 | Val Loss: 0.117812, Val Acc: 0.773196\n",
      "Epoch 15739 - Train Loss: 0.093892, Train Acc: 0.861538 | Val Loss: 0.117809, Val Acc: 0.773196\n",
      "Epoch 15740 - Train Loss: 0.093888, Train Acc: 0.861538 | Val Loss: 0.117807, Val Acc: 0.773196\n",
      "Epoch 15741 - Train Loss: 0.093884, Train Acc: 0.861538 | Val Loss: 0.117805, Val Acc: 0.773196\n",
      "Epoch 15742 - Train Loss: 0.093881, Train Acc: 0.861538 | Val Loss: 0.117802, Val Acc: 0.773196\n",
      "Epoch 15743 - Train Loss: 0.093877, Train Acc: 0.861538 | Val Loss: 0.117800, Val Acc: 0.773196\n",
      "Epoch 15744 - Train Loss: 0.093873, Train Acc: 0.861538 | Val Loss: 0.117798, Val Acc: 0.773196\n",
      "Epoch 15745 - Train Loss: 0.093869, Train Acc: 0.861538 | Val Loss: 0.117795, Val Acc: 0.773196\n",
      "Epoch 15746 - Train Loss: 0.093866, Train Acc: 0.861538 | Val Loss: 0.117793, Val Acc: 0.773196\n",
      "Epoch 15747 - Train Loss: 0.093862, Train Acc: 0.861538 | Val Loss: 0.117791, Val Acc: 0.773196\n",
      "Epoch 15748 - Train Loss: 0.093858, Train Acc: 0.861538 | Val Loss: 0.117788, Val Acc: 0.773196\n",
      "Epoch 15749 - Train Loss: 0.093855, Train Acc: 0.861538 | Val Loss: 0.117786, Val Acc: 0.773196\n",
      "Epoch 15750 - Train Loss: 0.093851, Train Acc: 0.861538 | Val Loss: 0.117784, Val Acc: 0.773196\n",
      "Epoch 15751 - Train Loss: 0.093847, Train Acc: 0.861538 | Val Loss: 0.117781, Val Acc: 0.773196\n",
      "Epoch 15752 - Train Loss: 0.093843, Train Acc: 0.861538 | Val Loss: 0.117779, Val Acc: 0.773196\n",
      "Epoch 15753 - Train Loss: 0.093840, Train Acc: 0.861538 | Val Loss: 0.117777, Val Acc: 0.773196\n",
      "Epoch 15754 - Train Loss: 0.093836, Train Acc: 0.861538 | Val Loss: 0.117774, Val Acc: 0.773196\n",
      "Epoch 15755 - Train Loss: 0.093832, Train Acc: 0.861538 | Val Loss: 0.117772, Val Acc: 0.773196\n",
      "Epoch 15756 - Train Loss: 0.093828, Train Acc: 0.861538 | Val Loss: 0.117770, Val Acc: 0.773196\n",
      "Epoch 15757 - Train Loss: 0.093825, Train Acc: 0.861538 | Val Loss: 0.117767, Val Acc: 0.773196\n",
      "Epoch 15758 - Train Loss: 0.093821, Train Acc: 0.861538 | Val Loss: 0.117765, Val Acc: 0.773196\n",
      "Epoch 15759 - Train Loss: 0.093817, Train Acc: 0.861538 | Val Loss: 0.117762, Val Acc: 0.773196\n",
      "Epoch 15760 - Train Loss: 0.093813, Train Acc: 0.861538 | Val Loss: 0.117760, Val Acc: 0.773196\n",
      "Epoch 15761 - Train Loss: 0.093810, Train Acc: 0.861538 | Val Loss: 0.117758, Val Acc: 0.773196\n",
      "Epoch 15762 - Train Loss: 0.093806, Train Acc: 0.861538 | Val Loss: 0.117755, Val Acc: 0.773196\n",
      "Epoch 15763 - Train Loss: 0.093802, Train Acc: 0.861538 | Val Loss: 0.117753, Val Acc: 0.773196\n",
      "Epoch 15764 - Train Loss: 0.093799, Train Acc: 0.861538 | Val Loss: 0.117751, Val Acc: 0.773196\n",
      "Epoch 15765 - Train Loss: 0.093795, Train Acc: 0.861538 | Val Loss: 0.117748, Val Acc: 0.773196\n",
      "Epoch 15766 - Train Loss: 0.093791, Train Acc: 0.861538 | Val Loss: 0.117746, Val Acc: 0.773196\n",
      "Epoch 15767 - Train Loss: 0.093787, Train Acc: 0.861538 | Val Loss: 0.117744, Val Acc: 0.773196\n",
      "Epoch 15768 - Train Loss: 0.093784, Train Acc: 0.861538 | Val Loss: 0.117741, Val Acc: 0.773196\n",
      "Epoch 15769 - Train Loss: 0.093780, Train Acc: 0.861538 | Val Loss: 0.117739, Val Acc: 0.773196\n",
      "Epoch 15770 - Train Loss: 0.093776, Train Acc: 0.861538 | Val Loss: 0.117737, Val Acc: 0.773196\n",
      "Epoch 15771 - Train Loss: 0.093772, Train Acc: 0.861538 | Val Loss: 0.117734, Val Acc: 0.773196\n",
      "Epoch 15772 - Train Loss: 0.093769, Train Acc: 0.861538 | Val Loss: 0.117732, Val Acc: 0.773196\n",
      "Epoch 15773 - Train Loss: 0.093765, Train Acc: 0.861538 | Val Loss: 0.117730, Val Acc: 0.773196\n",
      "Epoch 15774 - Train Loss: 0.093761, Train Acc: 0.861538 | Val Loss: 0.117727, Val Acc: 0.773196\n",
      "Epoch 15775 - Train Loss: 0.093758, Train Acc: 0.861538 | Val Loss: 0.117725, Val Acc: 0.773196\n",
      "Epoch 15776 - Train Loss: 0.093754, Train Acc: 0.861538 | Val Loss: 0.117723, Val Acc: 0.773196\n",
      "Epoch 15777 - Train Loss: 0.093750, Train Acc: 0.861538 | Val Loss: 0.117720, Val Acc: 0.773196\n",
      "Epoch 15778 - Train Loss: 0.093746, Train Acc: 0.861538 | Val Loss: 0.117718, Val Acc: 0.773196\n",
      "Epoch 15779 - Train Loss: 0.093743, Train Acc: 0.861538 | Val Loss: 0.117716, Val Acc: 0.773196\n",
      "Epoch 15780 - Train Loss: 0.093739, Train Acc: 0.861538 | Val Loss: 0.117713, Val Acc: 0.773196\n",
      "Epoch 15781 - Train Loss: 0.093735, Train Acc: 0.861538 | Val Loss: 0.117711, Val Acc: 0.773196\n",
      "Epoch 15782 - Train Loss: 0.093732, Train Acc: 0.861538 | Val Loss: 0.117709, Val Acc: 0.773196\n",
      "Epoch 15783 - Train Loss: 0.093728, Train Acc: 0.861538 | Val Loss: 0.117706, Val Acc: 0.773196\n",
      "Epoch 15784 - Train Loss: 0.093724, Train Acc: 0.861538 | Val Loss: 0.117704, Val Acc: 0.773196\n",
      "Epoch 15785 - Train Loss: 0.093720, Train Acc: 0.861538 | Val Loss: 0.117702, Val Acc: 0.773196\n",
      "Epoch 15786 - Train Loss: 0.093717, Train Acc: 0.861538 | Val Loss: 0.117699, Val Acc: 0.773196\n",
      "Epoch 15787 - Train Loss: 0.093713, Train Acc: 0.861538 | Val Loss: 0.117697, Val Acc: 0.773196\n",
      "Epoch 15788 - Train Loss: 0.093709, Train Acc: 0.861538 | Val Loss: 0.117695, Val Acc: 0.773196\n",
      "Epoch 15789 - Train Loss: 0.093705, Train Acc: 0.861538 | Val Loss: 0.117692, Val Acc: 0.773196\n",
      "Epoch 15790 - Train Loss: 0.093702, Train Acc: 0.861538 | Val Loss: 0.117690, Val Acc: 0.773196\n",
      "Epoch 15791 - Train Loss: 0.093698, Train Acc: 0.861538 | Val Loss: 0.117688, Val Acc: 0.773196\n",
      "Epoch 15792 - Train Loss: 0.093694, Train Acc: 0.861538 | Val Loss: 0.117685, Val Acc: 0.773196\n",
      "Epoch 15793 - Train Loss: 0.093691, Train Acc: 0.861538 | Val Loss: 0.117683, Val Acc: 0.773196\n",
      "Epoch 15794 - Train Loss: 0.093687, Train Acc: 0.861538 | Val Loss: 0.117681, Val Acc: 0.773196\n",
      "Epoch 15795 - Train Loss: 0.093683, Train Acc: 0.861538 | Val Loss: 0.117678, Val Acc: 0.773196\n",
      "Epoch 15796 - Train Loss: 0.093679, Train Acc: 0.861538 | Val Loss: 0.117676, Val Acc: 0.773196\n",
      "Epoch 15797 - Train Loss: 0.093676, Train Acc: 0.861538 | Val Loss: 0.117674, Val Acc: 0.773196\n",
      "Epoch 15798 - Train Loss: 0.093672, Train Acc: 0.861538 | Val Loss: 0.117671, Val Acc: 0.773196\n",
      "Epoch 15799 - Train Loss: 0.093668, Train Acc: 0.861538 | Val Loss: 0.117669, Val Acc: 0.773196\n",
      "Epoch 15800 - Train Loss: 0.093665, Train Acc: 0.861538 | Val Loss: 0.117667, Val Acc: 0.773196\n",
      "Epoch 15801 - Train Loss: 0.093661, Train Acc: 0.861538 | Val Loss: 0.117664, Val Acc: 0.773196\n",
      "Epoch 15802 - Train Loss: 0.093657, Train Acc: 0.861538 | Val Loss: 0.117662, Val Acc: 0.773196\n",
      "Epoch 15803 - Train Loss: 0.093653, Train Acc: 0.861538 | Val Loss: 0.117660, Val Acc: 0.773196\n",
      "Epoch 15804 - Train Loss: 0.093650, Train Acc: 0.861538 | Val Loss: 0.117657, Val Acc: 0.773196\n",
      "Epoch 15805 - Train Loss: 0.093646, Train Acc: 0.861538 | Val Loss: 0.117655, Val Acc: 0.773196\n",
      "Epoch 15806 - Train Loss: 0.093642, Train Acc: 0.861538 | Val Loss: 0.117653, Val Acc: 0.773196\n",
      "Epoch 15807 - Train Loss: 0.093639, Train Acc: 0.861538 | Val Loss: 0.117650, Val Acc: 0.773196\n",
      "Epoch 15808 - Train Loss: 0.093635, Train Acc: 0.861538 | Val Loss: 0.117648, Val Acc: 0.773196\n",
      "Epoch 15809 - Train Loss: 0.093631, Train Acc: 0.861538 | Val Loss: 0.117646, Val Acc: 0.773196\n",
      "Epoch 15810 - Train Loss: 0.093628, Train Acc: 0.861538 | Val Loss: 0.117643, Val Acc: 0.773196\n",
      "Epoch 15811 - Train Loss: 0.093624, Train Acc: 0.861538 | Val Loss: 0.117641, Val Acc: 0.773196\n",
      "Epoch 15812 - Train Loss: 0.093620, Train Acc: 0.861538 | Val Loss: 0.117639, Val Acc: 0.773196\n",
      "Epoch 15813 - Train Loss: 0.093616, Train Acc: 0.861538 | Val Loss: 0.117637, Val Acc: 0.773196\n",
      "Epoch 15814 - Train Loss: 0.093613, Train Acc: 0.861538 | Val Loss: 0.117634, Val Acc: 0.773196\n",
      "Epoch 15815 - Train Loss: 0.093609, Train Acc: 0.861538 | Val Loss: 0.117632, Val Acc: 0.773196\n",
      "Epoch 15816 - Train Loss: 0.093605, Train Acc: 0.861538 | Val Loss: 0.117630, Val Acc: 0.773196\n",
      "Epoch 15817 - Train Loss: 0.093602, Train Acc: 0.861538 | Val Loss: 0.117627, Val Acc: 0.773196\n",
      "Epoch 15818 - Train Loss: 0.093598, Train Acc: 0.861538 | Val Loss: 0.117625, Val Acc: 0.773196\n",
      "Epoch 15819 - Train Loss: 0.093594, Train Acc: 0.861538 | Val Loss: 0.117623, Val Acc: 0.773196\n",
      "Epoch 15820 - Train Loss: 0.093590, Train Acc: 0.861538 | Val Loss: 0.117620, Val Acc: 0.773196\n",
      "Epoch 15821 - Train Loss: 0.093587, Train Acc: 0.861538 | Val Loss: 0.117618, Val Acc: 0.773196\n",
      "Epoch 15822 - Train Loss: 0.093583, Train Acc: 0.861538 | Val Loss: 0.117616, Val Acc: 0.773196\n",
      "Epoch 15823 - Train Loss: 0.093579, Train Acc: 0.861538 | Val Loss: 0.117613, Val Acc: 0.773196\n",
      "Epoch 15824 - Train Loss: 0.093576, Train Acc: 0.861538 | Val Loss: 0.117611, Val Acc: 0.773196\n",
      "Epoch 15825 - Train Loss: 0.093572, Train Acc: 0.861538 | Val Loss: 0.117609, Val Acc: 0.773196\n",
      "Epoch 15826 - Train Loss: 0.093568, Train Acc: 0.861538 | Val Loss: 0.117606, Val Acc: 0.773196\n",
      "Epoch 15827 - Train Loss: 0.093565, Train Acc: 0.861538 | Val Loss: 0.117604, Val Acc: 0.773196\n",
      "Epoch 15828 - Train Loss: 0.093561, Train Acc: 0.861538 | Val Loss: 0.117602, Val Acc: 0.773196\n",
      "Epoch 15829 - Train Loss: 0.093557, Train Acc: 0.861538 | Val Loss: 0.117599, Val Acc: 0.773196\n",
      "Epoch 15830 - Train Loss: 0.093553, Train Acc: 0.861538 | Val Loss: 0.117597, Val Acc: 0.773196\n",
      "Epoch 15831 - Train Loss: 0.093550, Train Acc: 0.861538 | Val Loss: 0.117595, Val Acc: 0.773196\n",
      "Epoch 15832 - Train Loss: 0.093546, Train Acc: 0.861538 | Val Loss: 0.117593, Val Acc: 0.773196\n",
      "Epoch 15833 - Train Loss: 0.093542, Train Acc: 0.861538 | Val Loss: 0.117590, Val Acc: 0.773196\n",
      "Epoch 15834 - Train Loss: 0.093539, Train Acc: 0.861538 | Val Loss: 0.117588, Val Acc: 0.773196\n",
      "Epoch 15835 - Train Loss: 0.093535, Train Acc: 0.861538 | Val Loss: 0.117586, Val Acc: 0.773196\n",
      "Epoch 15836 - Train Loss: 0.093531, Train Acc: 0.861538 | Val Loss: 0.117583, Val Acc: 0.773196\n",
      "Epoch 15837 - Train Loss: 0.093528, Train Acc: 0.861538 | Val Loss: 0.117581, Val Acc: 0.773196\n",
      "Epoch 15838 - Train Loss: 0.093524, Train Acc: 0.861538 | Val Loss: 0.117579, Val Acc: 0.773196\n",
      "Epoch 15839 - Train Loss: 0.093520, Train Acc: 0.861538 | Val Loss: 0.117576, Val Acc: 0.773196\n",
      "Epoch 15840 - Train Loss: 0.093517, Train Acc: 0.861538 | Val Loss: 0.117574, Val Acc: 0.773196\n",
      "Epoch 15841 - Train Loss: 0.093513, Train Acc: 0.861538 | Val Loss: 0.117572, Val Acc: 0.773196\n",
      "Epoch 15842 - Train Loss: 0.093509, Train Acc: 0.861538 | Val Loss: 0.117569, Val Acc: 0.773196\n",
      "Epoch 15843 - Train Loss: 0.093505, Train Acc: 0.861538 | Val Loss: 0.117567, Val Acc: 0.773196\n",
      "Epoch 15844 - Train Loss: 0.093502, Train Acc: 0.861538 | Val Loss: 0.117565, Val Acc: 0.773196\n",
      "Epoch 15845 - Train Loss: 0.093498, Train Acc: 0.861538 | Val Loss: 0.117563, Val Acc: 0.773196\n",
      "Epoch 15846 - Train Loss: 0.093494, Train Acc: 0.861538 | Val Loss: 0.117560, Val Acc: 0.773196\n",
      "Epoch 15847 - Train Loss: 0.093491, Train Acc: 0.861538 | Val Loss: 0.117558, Val Acc: 0.773196\n",
      "Epoch 15848 - Train Loss: 0.093487, Train Acc: 0.861538 | Val Loss: 0.117556, Val Acc: 0.773196\n",
      "Epoch 15849 - Train Loss: 0.093483, Train Acc: 0.861538 | Val Loss: 0.117553, Val Acc: 0.773196\n",
      "Epoch 15850 - Train Loss: 0.093480, Train Acc: 0.861538 | Val Loss: 0.117551, Val Acc: 0.773196\n",
      "Epoch 15851 - Train Loss: 0.093476, Train Acc: 0.861538 | Val Loss: 0.117549, Val Acc: 0.773196\n",
      "Epoch 15852 - Train Loss: 0.093472, Train Acc: 0.861538 | Val Loss: 0.117546, Val Acc: 0.773196\n",
      "Epoch 15853 - Train Loss: 0.093469, Train Acc: 0.861538 | Val Loss: 0.117544, Val Acc: 0.773196\n",
      "Epoch 15854 - Train Loss: 0.093465, Train Acc: 0.861538 | Val Loss: 0.117542, Val Acc: 0.773196\n",
      "Epoch 15855 - Train Loss: 0.093461, Train Acc: 0.861538 | Val Loss: 0.117540, Val Acc: 0.773196\n",
      "Epoch 15856 - Train Loss: 0.093458, Train Acc: 0.861538 | Val Loss: 0.117537, Val Acc: 0.773196\n",
      "Epoch 15857 - Train Loss: 0.093454, Train Acc: 0.861538 | Val Loss: 0.117535, Val Acc: 0.773196\n",
      "Epoch 15858 - Train Loss: 0.093450, Train Acc: 0.861538 | Val Loss: 0.117533, Val Acc: 0.773196\n",
      "Epoch 15859 - Train Loss: 0.093446, Train Acc: 0.861538 | Val Loss: 0.117530, Val Acc: 0.773196\n",
      "Epoch 15860 - Train Loss: 0.093443, Train Acc: 0.861538 | Val Loss: 0.117528, Val Acc: 0.773196\n",
      "Epoch 15861 - Train Loss: 0.093439, Train Acc: 0.861538 | Val Loss: 0.117526, Val Acc: 0.773196\n",
      "Epoch 15862 - Train Loss: 0.093435, Train Acc: 0.861538 | Val Loss: 0.117523, Val Acc: 0.773196\n",
      "Epoch 15863 - Train Loss: 0.093432, Train Acc: 0.861538 | Val Loss: 0.117521, Val Acc: 0.773196\n",
      "Epoch 15864 - Train Loss: 0.093428, Train Acc: 0.861538 | Val Loss: 0.117519, Val Acc: 0.773196\n",
      "Epoch 15865 - Train Loss: 0.093424, Train Acc: 0.861538 | Val Loss: 0.117517, Val Acc: 0.773196\n",
      "Epoch 15866 - Train Loss: 0.093421, Train Acc: 0.861538 | Val Loss: 0.117514, Val Acc: 0.773196\n",
      "Epoch 15867 - Train Loss: 0.093417, Train Acc: 0.861538 | Val Loss: 0.117512, Val Acc: 0.773196\n",
      "Epoch 15868 - Train Loss: 0.093413, Train Acc: 0.861538 | Val Loss: 0.117510, Val Acc: 0.773196\n",
      "Epoch 15869 - Train Loss: 0.093410, Train Acc: 0.861538 | Val Loss: 0.117507, Val Acc: 0.773196\n",
      "Epoch 15870 - Train Loss: 0.093406, Train Acc: 0.861538 | Val Loss: 0.117505, Val Acc: 0.773196\n",
      "Epoch 15871 - Train Loss: 0.093402, Train Acc: 0.861538 | Val Loss: 0.117503, Val Acc: 0.773196\n",
      "Epoch 15872 - Train Loss: 0.093399, Train Acc: 0.861538 | Val Loss: 0.117500, Val Acc: 0.773196\n",
      "Epoch 15873 - Train Loss: 0.093395, Train Acc: 0.861538 | Val Loss: 0.117498, Val Acc: 0.773196\n",
      "Epoch 15874 - Train Loss: 0.093391, Train Acc: 0.861538 | Val Loss: 0.117496, Val Acc: 0.773196\n",
      "Epoch 15875 - Train Loss: 0.093388, Train Acc: 0.861538 | Val Loss: 0.117494, Val Acc: 0.773196\n",
      "Epoch 15876 - Train Loss: 0.093384, Train Acc: 0.861538 | Val Loss: 0.117491, Val Acc: 0.773196\n",
      "Epoch 15877 - Train Loss: 0.093380, Train Acc: 0.861538 | Val Loss: 0.117489, Val Acc: 0.773196\n",
      "Epoch 15878 - Train Loss: 0.093377, Train Acc: 0.861538 | Val Loss: 0.117487, Val Acc: 0.773196\n",
      "Epoch 15879 - Train Loss: 0.093373, Train Acc: 0.861538 | Val Loss: 0.117484, Val Acc: 0.773196\n",
      "Epoch 15880 - Train Loss: 0.093369, Train Acc: 0.861538 | Val Loss: 0.117482, Val Acc: 0.773196\n",
      "Epoch 15881 - Train Loss: 0.093366, Train Acc: 0.861538 | Val Loss: 0.117480, Val Acc: 0.773196\n",
      "Epoch 15882 - Train Loss: 0.093362, Train Acc: 0.861538 | Val Loss: 0.117478, Val Acc: 0.773196\n",
      "Epoch 15883 - Train Loss: 0.093358, Train Acc: 0.861538 | Val Loss: 0.117475, Val Acc: 0.773196\n",
      "Epoch 15884 - Train Loss: 0.093354, Train Acc: 0.861538 | Val Loss: 0.117473, Val Acc: 0.773196\n",
      "Epoch 15885 - Train Loss: 0.093351, Train Acc: 0.861538 | Val Loss: 0.117471, Val Acc: 0.773196\n",
      "Epoch 15886 - Train Loss: 0.093347, Train Acc: 0.861538 | Val Loss: 0.117468, Val Acc: 0.773196\n",
      "Epoch 15887 - Train Loss: 0.093343, Train Acc: 0.861538 | Val Loss: 0.117466, Val Acc: 0.773196\n",
      "Epoch 15888 - Train Loss: 0.093340, Train Acc: 0.861538 | Val Loss: 0.117464, Val Acc: 0.773196\n",
      "Epoch 15889 - Train Loss: 0.093336, Train Acc: 0.862821 | Val Loss: 0.117462, Val Acc: 0.773196\n",
      "Epoch 15890 - Train Loss: 0.093332, Train Acc: 0.862821 | Val Loss: 0.117459, Val Acc: 0.773196\n",
      "Epoch 15891 - Train Loss: 0.093329, Train Acc: 0.862821 | Val Loss: 0.117457, Val Acc: 0.773196\n",
      "Epoch 15892 - Train Loss: 0.093325, Train Acc: 0.862821 | Val Loss: 0.117455, Val Acc: 0.773196\n",
      "Epoch 15893 - Train Loss: 0.093321, Train Acc: 0.862821 | Val Loss: 0.117452, Val Acc: 0.773196\n",
      "Epoch 15894 - Train Loss: 0.093318, Train Acc: 0.862821 | Val Loss: 0.117450, Val Acc: 0.773196\n",
      "Epoch 15895 - Train Loss: 0.093314, Train Acc: 0.862821 | Val Loss: 0.117448, Val Acc: 0.773196\n",
      "Epoch 15896 - Train Loss: 0.093310, Train Acc: 0.862821 | Val Loss: 0.117446, Val Acc: 0.773196\n",
      "Epoch 15897 - Train Loss: 0.093307, Train Acc: 0.862821 | Val Loss: 0.117443, Val Acc: 0.773196\n",
      "Epoch 15898 - Train Loss: 0.093303, Train Acc: 0.862821 | Val Loss: 0.117441, Val Acc: 0.773196\n",
      "Epoch 15899 - Train Loss: 0.093299, Train Acc: 0.862821 | Val Loss: 0.117439, Val Acc: 0.773196\n",
      "Epoch 15900 - Train Loss: 0.093296, Train Acc: 0.862821 | Val Loss: 0.117437, Val Acc: 0.773196\n",
      "Epoch 15901 - Train Loss: 0.093292, Train Acc: 0.862821 | Val Loss: 0.117434, Val Acc: 0.773196\n",
      "Epoch 15902 - Train Loss: 0.093288, Train Acc: 0.862821 | Val Loss: 0.117432, Val Acc: 0.773196\n",
      "Epoch 15903 - Train Loss: 0.093285, Train Acc: 0.862821 | Val Loss: 0.117430, Val Acc: 0.773196\n",
      "Epoch 15904 - Train Loss: 0.093281, Train Acc: 0.862821 | Val Loss: 0.117427, Val Acc: 0.773196\n",
      "Epoch 15905 - Train Loss: 0.093277, Train Acc: 0.862821 | Val Loss: 0.117425, Val Acc: 0.773196\n",
      "Epoch 15906 - Train Loss: 0.093274, Train Acc: 0.862821 | Val Loss: 0.117423, Val Acc: 0.773196\n",
      "Epoch 15907 - Train Loss: 0.093270, Train Acc: 0.862821 | Val Loss: 0.117421, Val Acc: 0.773196\n",
      "Epoch 15908 - Train Loss: 0.093266, Train Acc: 0.862821 | Val Loss: 0.117418, Val Acc: 0.773196\n",
      "Epoch 15909 - Train Loss: 0.093263, Train Acc: 0.862821 | Val Loss: 0.117416, Val Acc: 0.773196\n",
      "Epoch 15910 - Train Loss: 0.093259, Train Acc: 0.862821 | Val Loss: 0.117414, Val Acc: 0.773196\n",
      "Epoch 15911 - Train Loss: 0.093255, Train Acc: 0.862821 | Val Loss: 0.117411, Val Acc: 0.773196\n",
      "Epoch 15912 - Train Loss: 0.093252, Train Acc: 0.862821 | Val Loss: 0.117409, Val Acc: 0.773196\n",
      "Epoch 15913 - Train Loss: 0.093248, Train Acc: 0.862821 | Val Loss: 0.117407, Val Acc: 0.773196\n",
      "Epoch 15914 - Train Loss: 0.093245, Train Acc: 0.862821 | Val Loss: 0.117405, Val Acc: 0.773196\n",
      "Epoch 15915 - Train Loss: 0.093241, Train Acc: 0.862821 | Val Loss: 0.117402, Val Acc: 0.773196\n",
      "Epoch 15916 - Train Loss: 0.093237, Train Acc: 0.862821 | Val Loss: 0.117400, Val Acc: 0.773196\n",
      "Epoch 15917 - Train Loss: 0.093234, Train Acc: 0.862821 | Val Loss: 0.117398, Val Acc: 0.773196\n",
      "Epoch 15918 - Train Loss: 0.093230, Train Acc: 0.862821 | Val Loss: 0.117396, Val Acc: 0.773196\n",
      "Epoch 15919 - Train Loss: 0.093226, Train Acc: 0.862821 | Val Loss: 0.117393, Val Acc: 0.773196\n",
      "Epoch 15920 - Train Loss: 0.093223, Train Acc: 0.862821 | Val Loss: 0.117391, Val Acc: 0.773196\n",
      "Epoch 15921 - Train Loss: 0.093219, Train Acc: 0.862821 | Val Loss: 0.117389, Val Acc: 0.773196\n",
      "Epoch 15922 - Train Loss: 0.093215, Train Acc: 0.862821 | Val Loss: 0.117386, Val Acc: 0.773196\n",
      "Epoch 15923 - Train Loss: 0.093212, Train Acc: 0.862821 | Val Loss: 0.117384, Val Acc: 0.773196\n",
      "Epoch 15924 - Train Loss: 0.093208, Train Acc: 0.862821 | Val Loss: 0.117382, Val Acc: 0.773196\n",
      "Epoch 15925 - Train Loss: 0.093204, Train Acc: 0.862821 | Val Loss: 0.117380, Val Acc: 0.773196\n",
      "Epoch 15926 - Train Loss: 0.093201, Train Acc: 0.862821 | Val Loss: 0.117377, Val Acc: 0.773196\n",
      "Epoch 15927 - Train Loss: 0.093197, Train Acc: 0.862821 | Val Loss: 0.117375, Val Acc: 0.773196\n",
      "Epoch 15928 - Train Loss: 0.093193, Train Acc: 0.862821 | Val Loss: 0.117373, Val Acc: 0.773196\n",
      "Epoch 15929 - Train Loss: 0.093190, Train Acc: 0.862821 | Val Loss: 0.117371, Val Acc: 0.773196\n",
      "Epoch 15930 - Train Loss: 0.093186, Train Acc: 0.862821 | Val Loss: 0.117368, Val Acc: 0.773196\n",
      "Epoch 15931 - Train Loss: 0.093182, Train Acc: 0.862821 | Val Loss: 0.117366, Val Acc: 0.773196\n",
      "Epoch 15932 - Train Loss: 0.093179, Train Acc: 0.862821 | Val Loss: 0.117364, Val Acc: 0.773196\n",
      "Epoch 15933 - Train Loss: 0.093175, Train Acc: 0.862821 | Val Loss: 0.117362, Val Acc: 0.773196\n",
      "Epoch 15934 - Train Loss: 0.093171, Train Acc: 0.862821 | Val Loss: 0.117359, Val Acc: 0.773196\n",
      "Epoch 15935 - Train Loss: 0.093168, Train Acc: 0.862821 | Val Loss: 0.117357, Val Acc: 0.773196\n",
      "Epoch 15936 - Train Loss: 0.093164, Train Acc: 0.862821 | Val Loss: 0.117355, Val Acc: 0.773196\n",
      "Epoch 15937 - Train Loss: 0.093160, Train Acc: 0.862821 | Val Loss: 0.117352, Val Acc: 0.773196\n",
      "Epoch 15938 - Train Loss: 0.093157, Train Acc: 0.862821 | Val Loss: 0.117350, Val Acc: 0.773196\n",
      "Epoch 15939 - Train Loss: 0.093153, Train Acc: 0.862821 | Val Loss: 0.117348, Val Acc: 0.773196\n",
      "Epoch 15940 - Train Loss: 0.093150, Train Acc: 0.862821 | Val Loss: 0.117346, Val Acc: 0.773196\n",
      "Epoch 15941 - Train Loss: 0.093146, Train Acc: 0.862821 | Val Loss: 0.117343, Val Acc: 0.773196\n",
      "Epoch 15942 - Train Loss: 0.093142, Train Acc: 0.862821 | Val Loss: 0.117341, Val Acc: 0.773196\n",
      "Epoch 15943 - Train Loss: 0.093139, Train Acc: 0.862821 | Val Loss: 0.117339, Val Acc: 0.773196\n",
      "Epoch 15944 - Train Loss: 0.093135, Train Acc: 0.862821 | Val Loss: 0.117337, Val Acc: 0.773196\n",
      "Epoch 15945 - Train Loss: 0.093131, Train Acc: 0.862821 | Val Loss: 0.117334, Val Acc: 0.773196\n",
      "Epoch 15946 - Train Loss: 0.093128, Train Acc: 0.862821 | Val Loss: 0.117332, Val Acc: 0.773196\n",
      "Epoch 15947 - Train Loss: 0.093124, Train Acc: 0.862821 | Val Loss: 0.117330, Val Acc: 0.773196\n",
      "Epoch 15948 - Train Loss: 0.093120, Train Acc: 0.862821 | Val Loss: 0.117328, Val Acc: 0.773196\n",
      "Epoch 15949 - Train Loss: 0.093117, Train Acc: 0.862821 | Val Loss: 0.117325, Val Acc: 0.773196\n",
      "Epoch 15950 - Train Loss: 0.093113, Train Acc: 0.862821 | Val Loss: 0.117323, Val Acc: 0.773196\n",
      "Epoch 15951 - Train Loss: 0.093109, Train Acc: 0.862821 | Val Loss: 0.117321, Val Acc: 0.773196\n",
      "Epoch 15952 - Train Loss: 0.093106, Train Acc: 0.862821 | Val Loss: 0.117319, Val Acc: 0.773196\n",
      "Epoch 15953 - Train Loss: 0.093102, Train Acc: 0.862821 | Val Loss: 0.117316, Val Acc: 0.773196\n",
      "Epoch 15954 - Train Loss: 0.093099, Train Acc: 0.862821 | Val Loss: 0.117314, Val Acc: 0.773196\n",
      "Epoch 15955 - Train Loss: 0.093095, Train Acc: 0.862821 | Val Loss: 0.117312, Val Acc: 0.773196\n",
      "Epoch 15956 - Train Loss: 0.093091, Train Acc: 0.862821 | Val Loss: 0.117310, Val Acc: 0.773196\n",
      "Epoch 15957 - Train Loss: 0.093088, Train Acc: 0.862821 | Val Loss: 0.117307, Val Acc: 0.773196\n",
      "Epoch 15958 - Train Loss: 0.093084, Train Acc: 0.862821 | Val Loss: 0.117305, Val Acc: 0.773196\n",
      "Epoch 15959 - Train Loss: 0.093080, Train Acc: 0.862821 | Val Loss: 0.117303, Val Acc: 0.773196\n",
      "Epoch 15960 - Train Loss: 0.093077, Train Acc: 0.862821 | Val Loss: 0.117301, Val Acc: 0.773196\n",
      "Epoch 15961 - Train Loss: 0.093073, Train Acc: 0.862821 | Val Loss: 0.117298, Val Acc: 0.773196\n",
      "Epoch 15962 - Train Loss: 0.093069, Train Acc: 0.862821 | Val Loss: 0.117296, Val Acc: 0.773196\n",
      "Epoch 15963 - Train Loss: 0.093066, Train Acc: 0.862821 | Val Loss: 0.117294, Val Acc: 0.773196\n",
      "Epoch 15964 - Train Loss: 0.093062, Train Acc: 0.862821 | Val Loss: 0.117292, Val Acc: 0.773196\n",
      "Epoch 15965 - Train Loss: 0.093059, Train Acc: 0.862821 | Val Loss: 0.117289, Val Acc: 0.773196\n",
      "Epoch 15966 - Train Loss: 0.093055, Train Acc: 0.862821 | Val Loss: 0.117287, Val Acc: 0.773196\n",
      "Epoch 15967 - Train Loss: 0.093051, Train Acc: 0.862821 | Val Loss: 0.117285, Val Acc: 0.773196\n",
      "Epoch 15968 - Train Loss: 0.093048, Train Acc: 0.862821 | Val Loss: 0.117283, Val Acc: 0.773196\n",
      "Epoch 15969 - Train Loss: 0.093044, Train Acc: 0.862821 | Val Loss: 0.117280, Val Acc: 0.773196\n",
      "Epoch 15970 - Train Loss: 0.093040, Train Acc: 0.862821 | Val Loss: 0.117278, Val Acc: 0.773196\n",
      "Epoch 15971 - Train Loss: 0.093037, Train Acc: 0.862821 | Val Loss: 0.117276, Val Acc: 0.773196\n",
      "Epoch 15972 - Train Loss: 0.093033, Train Acc: 0.862821 | Val Loss: 0.117274, Val Acc: 0.773196\n",
      "Epoch 15973 - Train Loss: 0.093029, Train Acc: 0.862821 | Val Loss: 0.117271, Val Acc: 0.773196\n",
      "Epoch 15974 - Train Loss: 0.093026, Train Acc: 0.862821 | Val Loss: 0.117269, Val Acc: 0.773196\n",
      "Epoch 15975 - Train Loss: 0.093022, Train Acc: 0.862821 | Val Loss: 0.117267, Val Acc: 0.773196\n",
      "Epoch 15976 - Train Loss: 0.093019, Train Acc: 0.862821 | Val Loss: 0.117265, Val Acc: 0.773196\n",
      "Epoch 15977 - Train Loss: 0.093015, Train Acc: 0.862821 | Val Loss: 0.117262, Val Acc: 0.773196\n",
      "Epoch 15978 - Train Loss: 0.093011, Train Acc: 0.862821 | Val Loss: 0.117260, Val Acc: 0.773196\n",
      "Epoch 15979 - Train Loss: 0.093008, Train Acc: 0.862821 | Val Loss: 0.117258, Val Acc: 0.773196\n",
      "Epoch 15980 - Train Loss: 0.093004, Train Acc: 0.862821 | Val Loss: 0.117256, Val Acc: 0.773196\n",
      "Epoch 15981 - Train Loss: 0.093000, Train Acc: 0.862821 | Val Loss: 0.117253, Val Acc: 0.773196\n",
      "Epoch 15982 - Train Loss: 0.092997, Train Acc: 0.862821 | Val Loss: 0.117251, Val Acc: 0.773196\n",
      "Epoch 15983 - Train Loss: 0.092993, Train Acc: 0.862821 | Val Loss: 0.117249, Val Acc: 0.773196\n",
      "Epoch 15984 - Train Loss: 0.092990, Train Acc: 0.862821 | Val Loss: 0.117247, Val Acc: 0.773196\n",
      "Epoch 15985 - Train Loss: 0.092986, Train Acc: 0.862821 | Val Loss: 0.117244, Val Acc: 0.773196\n",
      "Epoch 15986 - Train Loss: 0.092982, Train Acc: 0.862821 | Val Loss: 0.117242, Val Acc: 0.773196\n",
      "Epoch 15987 - Train Loss: 0.092979, Train Acc: 0.862821 | Val Loss: 0.117240, Val Acc: 0.773196\n",
      "Epoch 15988 - Train Loss: 0.092975, Train Acc: 0.862821 | Val Loss: 0.117238, Val Acc: 0.773196\n",
      "Epoch 15989 - Train Loss: 0.092971, Train Acc: 0.862821 | Val Loss: 0.117235, Val Acc: 0.773196\n",
      "Epoch 15990 - Train Loss: 0.092968, Train Acc: 0.862821 | Val Loss: 0.117233, Val Acc: 0.773196\n",
      "Epoch 15991 - Train Loss: 0.092964, Train Acc: 0.862821 | Val Loss: 0.117231, Val Acc: 0.773196\n",
      "Epoch 15992 - Train Loss: 0.092961, Train Acc: 0.864103 | Val Loss: 0.117229, Val Acc: 0.773196\n",
      "Epoch 15993 - Train Loss: 0.092957, Train Acc: 0.864103 | Val Loss: 0.117226, Val Acc: 0.773196\n",
      "Epoch 15994 - Train Loss: 0.092953, Train Acc: 0.864103 | Val Loss: 0.117224, Val Acc: 0.773196\n",
      "Epoch 15995 - Train Loss: 0.092950, Train Acc: 0.864103 | Val Loss: 0.117222, Val Acc: 0.773196\n",
      "Epoch 15996 - Train Loss: 0.092946, Train Acc: 0.864103 | Val Loss: 0.117220, Val Acc: 0.773196\n",
      "Epoch 15997 - Train Loss: 0.092942, Train Acc: 0.864103 | Val Loss: 0.117217, Val Acc: 0.773196\n",
      "Epoch 15998 - Train Loss: 0.092939, Train Acc: 0.864103 | Val Loss: 0.117215, Val Acc: 0.773196\n",
      "Epoch 15999 - Train Loss: 0.092935, Train Acc: 0.864103 | Val Loss: 0.117213, Val Acc: 0.773196\n",
      "Epoch 16000 - Train Loss: 0.092932, Train Acc: 0.864103 | Val Loss: 0.117211, Val Acc: 0.773196\n",
      "Epoch 16001 - Train Loss: 0.092928, Train Acc: 0.864103 | Val Loss: 0.117208, Val Acc: 0.773196\n",
      "Epoch 16002 - Train Loss: 0.092924, Train Acc: 0.864103 | Val Loss: 0.117206, Val Acc: 0.773196\n",
      "Epoch 16003 - Train Loss: 0.092921, Train Acc: 0.864103 | Val Loss: 0.117204, Val Acc: 0.773196\n",
      "Epoch 16004 - Train Loss: 0.092917, Train Acc: 0.864103 | Val Loss: 0.117202, Val Acc: 0.773196\n",
      "Epoch 16005 - Train Loss: 0.092913, Train Acc: 0.864103 | Val Loss: 0.117199, Val Acc: 0.773196\n",
      "Epoch 16006 - Train Loss: 0.092910, Train Acc: 0.864103 | Val Loss: 0.117197, Val Acc: 0.773196\n",
      "Epoch 16007 - Train Loss: 0.092906, Train Acc: 0.865385 | Val Loss: 0.117195, Val Acc: 0.773196\n",
      "Epoch 16008 - Train Loss: 0.092903, Train Acc: 0.865385 | Val Loss: 0.117193, Val Acc: 0.773196\n",
      "Epoch 16009 - Train Loss: 0.092899, Train Acc: 0.865385 | Val Loss: 0.117191, Val Acc: 0.773196\n",
      "Epoch 16010 - Train Loss: 0.092895, Train Acc: 0.865385 | Val Loss: 0.117188, Val Acc: 0.773196\n",
      "Epoch 16011 - Train Loss: 0.092892, Train Acc: 0.865385 | Val Loss: 0.117186, Val Acc: 0.773196\n",
      "Epoch 16012 - Train Loss: 0.092888, Train Acc: 0.865385 | Val Loss: 0.117184, Val Acc: 0.773196\n",
      "Epoch 16013 - Train Loss: 0.092885, Train Acc: 0.865385 | Val Loss: 0.117182, Val Acc: 0.773196\n",
      "Epoch 16014 - Train Loss: 0.092881, Train Acc: 0.865385 | Val Loss: 0.117179, Val Acc: 0.773196\n",
      "Epoch 16015 - Train Loss: 0.092877, Train Acc: 0.865385 | Val Loss: 0.117177, Val Acc: 0.773196\n",
      "Epoch 16016 - Train Loss: 0.092874, Train Acc: 0.865385 | Val Loss: 0.117175, Val Acc: 0.773196\n",
      "Epoch 16017 - Train Loss: 0.092870, Train Acc: 0.865385 | Val Loss: 0.117173, Val Acc: 0.773196\n",
      "Epoch 16018 - Train Loss: 0.092866, Train Acc: 0.865385 | Val Loss: 0.117170, Val Acc: 0.773196\n",
      "Epoch 16019 - Train Loss: 0.092863, Train Acc: 0.865385 | Val Loss: 0.117168, Val Acc: 0.773196\n",
      "Epoch 16020 - Train Loss: 0.092859, Train Acc: 0.865385 | Val Loss: 0.117166, Val Acc: 0.773196\n",
      "Epoch 16021 - Train Loss: 0.092856, Train Acc: 0.865385 | Val Loss: 0.117164, Val Acc: 0.773196\n",
      "Epoch 16022 - Train Loss: 0.092852, Train Acc: 0.865385 | Val Loss: 0.117161, Val Acc: 0.773196\n",
      "Epoch 16023 - Train Loss: 0.092848, Train Acc: 0.865385 | Val Loss: 0.117159, Val Acc: 0.773196\n",
      "Epoch 16024 - Train Loss: 0.092845, Train Acc: 0.865385 | Val Loss: 0.117157, Val Acc: 0.773196\n",
      "Epoch 16025 - Train Loss: 0.092841, Train Acc: 0.865385 | Val Loss: 0.117155, Val Acc: 0.773196\n",
      "Epoch 16026 - Train Loss: 0.092838, Train Acc: 0.865385 | Val Loss: 0.117153, Val Acc: 0.773196\n",
      "Epoch 16027 - Train Loss: 0.092834, Train Acc: 0.865385 | Val Loss: 0.117150, Val Acc: 0.773196\n",
      "Epoch 16028 - Train Loss: 0.092830, Train Acc: 0.865385 | Val Loss: 0.117148, Val Acc: 0.773196\n",
      "Epoch 16029 - Train Loss: 0.092827, Train Acc: 0.865385 | Val Loss: 0.117146, Val Acc: 0.773196\n",
      "Epoch 16030 - Train Loss: 0.092823, Train Acc: 0.865385 | Val Loss: 0.117144, Val Acc: 0.773196\n",
      "Epoch 16031 - Train Loss: 0.092820, Train Acc: 0.865385 | Val Loss: 0.117141, Val Acc: 0.773196\n",
      "Epoch 16032 - Train Loss: 0.092816, Train Acc: 0.865385 | Val Loss: 0.117139, Val Acc: 0.773196\n",
      "Epoch 16033 - Train Loss: 0.092812, Train Acc: 0.865385 | Val Loss: 0.117137, Val Acc: 0.773196\n",
      "Epoch 16034 - Train Loss: 0.092809, Train Acc: 0.865385 | Val Loss: 0.117135, Val Acc: 0.773196\n",
      "Epoch 16035 - Train Loss: 0.092805, Train Acc: 0.865385 | Val Loss: 0.117133, Val Acc: 0.773196\n",
      "Epoch 16036 - Train Loss: 0.092802, Train Acc: 0.865385 | Val Loss: 0.117130, Val Acc: 0.773196\n",
      "Epoch 16037 - Train Loss: 0.092798, Train Acc: 0.865385 | Val Loss: 0.117128, Val Acc: 0.773196\n",
      "Epoch 16038 - Train Loss: 0.092794, Train Acc: 0.866667 | Val Loss: 0.117126, Val Acc: 0.773196\n",
      "Epoch 16039 - Train Loss: 0.092791, Train Acc: 0.866667 | Val Loss: 0.117124, Val Acc: 0.773196\n",
      "Epoch 16040 - Train Loss: 0.092787, Train Acc: 0.866667 | Val Loss: 0.117121, Val Acc: 0.773196\n",
      "Epoch 16041 - Train Loss: 0.092784, Train Acc: 0.866667 | Val Loss: 0.117119, Val Acc: 0.773196\n",
      "Epoch 16042 - Train Loss: 0.092780, Train Acc: 0.866667 | Val Loss: 0.117117, Val Acc: 0.773196\n",
      "Epoch 16043 - Train Loss: 0.092776, Train Acc: 0.866667 | Val Loss: 0.117115, Val Acc: 0.773196\n",
      "Epoch 16044 - Train Loss: 0.092773, Train Acc: 0.866667 | Val Loss: 0.117113, Val Acc: 0.773196\n",
      "Epoch 16045 - Train Loss: 0.092769, Train Acc: 0.866667 | Val Loss: 0.117110, Val Acc: 0.773196\n",
      "Epoch 16046 - Train Loss: 0.092766, Train Acc: 0.866667 | Val Loss: 0.117108, Val Acc: 0.773196\n",
      "Epoch 16047 - Train Loss: 0.092762, Train Acc: 0.866667 | Val Loss: 0.117106, Val Acc: 0.773196\n",
      "Epoch 16048 - Train Loss: 0.092758, Train Acc: 0.866667 | Val Loss: 0.117104, Val Acc: 0.773196\n",
      "Epoch 16049 - Train Loss: 0.092755, Train Acc: 0.866667 | Val Loss: 0.117101, Val Acc: 0.773196\n",
      "Epoch 16050 - Train Loss: 0.092751, Train Acc: 0.866667 | Val Loss: 0.117099, Val Acc: 0.773196\n",
      "Epoch 16051 - Train Loss: 0.092748, Train Acc: 0.866667 | Val Loss: 0.117097, Val Acc: 0.773196\n",
      "Epoch 16052 - Train Loss: 0.092744, Train Acc: 0.866667 | Val Loss: 0.117095, Val Acc: 0.773196\n",
      "Epoch 16053 - Train Loss: 0.092740, Train Acc: 0.866667 | Val Loss: 0.117093, Val Acc: 0.773196\n",
      "Epoch 16054 - Train Loss: 0.092737, Train Acc: 0.866667 | Val Loss: 0.117090, Val Acc: 0.773196\n",
      "Epoch 16055 - Train Loss: 0.092733, Train Acc: 0.866667 | Val Loss: 0.117088, Val Acc: 0.773196\n",
      "Epoch 16056 - Train Loss: 0.092730, Train Acc: 0.866667 | Val Loss: 0.117086, Val Acc: 0.773196\n",
      "Epoch 16057 - Train Loss: 0.092726, Train Acc: 0.866667 | Val Loss: 0.117084, Val Acc: 0.773196\n",
      "Epoch 16058 - Train Loss: 0.092722, Train Acc: 0.866667 | Val Loss: 0.117082, Val Acc: 0.773196\n",
      "Epoch 16059 - Train Loss: 0.092719, Train Acc: 0.866667 | Val Loss: 0.117079, Val Acc: 0.773196\n",
      "Epoch 16060 - Train Loss: 0.092715, Train Acc: 0.866667 | Val Loss: 0.117077, Val Acc: 0.773196\n",
      "Epoch 16061 - Train Loss: 0.092712, Train Acc: 0.866667 | Val Loss: 0.117075, Val Acc: 0.773196\n",
      "Epoch 16062 - Train Loss: 0.092708, Train Acc: 0.866667 | Val Loss: 0.117073, Val Acc: 0.773196\n",
      "Epoch 16063 - Train Loss: 0.092704, Train Acc: 0.866667 | Val Loss: 0.117070, Val Acc: 0.773196\n",
      "Epoch 16064 - Train Loss: 0.092701, Train Acc: 0.866667 | Val Loss: 0.117068, Val Acc: 0.773196\n",
      "Epoch 16065 - Train Loss: 0.092697, Train Acc: 0.866667 | Val Loss: 0.117066, Val Acc: 0.773196\n",
      "Epoch 16066 - Train Loss: 0.092694, Train Acc: 0.866667 | Val Loss: 0.117064, Val Acc: 0.773196\n",
      "Epoch 16067 - Train Loss: 0.092690, Train Acc: 0.866667 | Val Loss: 0.117062, Val Acc: 0.773196\n",
      "Epoch 16068 - Train Loss: 0.092686, Train Acc: 0.866667 | Val Loss: 0.117059, Val Acc: 0.773196\n",
      "Epoch 16069 - Train Loss: 0.092683, Train Acc: 0.866667 | Val Loss: 0.117057, Val Acc: 0.773196\n",
      "Epoch 16070 - Train Loss: 0.092679, Train Acc: 0.866667 | Val Loss: 0.117055, Val Acc: 0.773196\n",
      "Epoch 16071 - Train Loss: 0.092676, Train Acc: 0.866667 | Val Loss: 0.117053, Val Acc: 0.773196\n",
      "Epoch 16072 - Train Loss: 0.092672, Train Acc: 0.866667 | Val Loss: 0.117051, Val Acc: 0.773196\n",
      "Epoch 16073 - Train Loss: 0.092669, Train Acc: 0.866667 | Val Loss: 0.117048, Val Acc: 0.773196\n",
      "Epoch 16074 - Train Loss: 0.092665, Train Acc: 0.866667 | Val Loss: 0.117046, Val Acc: 0.773196\n",
      "Epoch 16075 - Train Loss: 0.092661, Train Acc: 0.866667 | Val Loss: 0.117044, Val Acc: 0.773196\n",
      "Epoch 16076 - Train Loss: 0.092658, Train Acc: 0.866667 | Val Loss: 0.117042, Val Acc: 0.773196\n",
      "Epoch 16077 - Train Loss: 0.092654, Train Acc: 0.866667 | Val Loss: 0.117040, Val Acc: 0.773196\n",
      "Epoch 16078 - Train Loss: 0.092651, Train Acc: 0.866667 | Val Loss: 0.117037, Val Acc: 0.773196\n",
      "Epoch 16079 - Train Loss: 0.092647, Train Acc: 0.866667 | Val Loss: 0.117035, Val Acc: 0.773196\n",
      "Epoch 16080 - Train Loss: 0.092643, Train Acc: 0.866667 | Val Loss: 0.117033, Val Acc: 0.773196\n",
      "Epoch 16081 - Train Loss: 0.092640, Train Acc: 0.866667 | Val Loss: 0.117031, Val Acc: 0.773196\n",
      "Epoch 16082 - Train Loss: 0.092636, Train Acc: 0.866667 | Val Loss: 0.117029, Val Acc: 0.773196\n",
      "Epoch 16083 - Train Loss: 0.092633, Train Acc: 0.866667 | Val Loss: 0.117026, Val Acc: 0.773196\n",
      "Epoch 16084 - Train Loss: 0.092629, Train Acc: 0.866667 | Val Loss: 0.117024, Val Acc: 0.773196\n",
      "Epoch 16085 - Train Loss: 0.092626, Train Acc: 0.866667 | Val Loss: 0.117022, Val Acc: 0.773196\n",
      "Epoch 16086 - Train Loss: 0.092622, Train Acc: 0.866667 | Val Loss: 0.117020, Val Acc: 0.773196\n",
      "Epoch 16087 - Train Loss: 0.092618, Train Acc: 0.866667 | Val Loss: 0.117018, Val Acc: 0.773196\n",
      "Epoch 16088 - Train Loss: 0.092615, Train Acc: 0.866667 | Val Loss: 0.117015, Val Acc: 0.773196\n",
      "Epoch 16089 - Train Loss: 0.092611, Train Acc: 0.866667 | Val Loss: 0.117013, Val Acc: 0.773196\n",
      "Epoch 16090 - Train Loss: 0.092608, Train Acc: 0.866667 | Val Loss: 0.117011, Val Acc: 0.773196\n",
      "Epoch 16091 - Train Loss: 0.092604, Train Acc: 0.866667 | Val Loss: 0.117009, Val Acc: 0.773196\n",
      "Epoch 16092 - Train Loss: 0.092600, Train Acc: 0.866667 | Val Loss: 0.117007, Val Acc: 0.773196\n",
      "Epoch 16093 - Train Loss: 0.092597, Train Acc: 0.866667 | Val Loss: 0.117004, Val Acc: 0.773196\n",
      "Epoch 16094 - Train Loss: 0.092593, Train Acc: 0.866667 | Val Loss: 0.117002, Val Acc: 0.773196\n",
      "Epoch 16095 - Train Loss: 0.092590, Train Acc: 0.866667 | Val Loss: 0.117000, Val Acc: 0.773196\n",
      "Epoch 16096 - Train Loss: 0.092586, Train Acc: 0.866667 | Val Loss: 0.116998, Val Acc: 0.773196\n",
      "Epoch 16097 - Train Loss: 0.092583, Train Acc: 0.866667 | Val Loss: 0.116996, Val Acc: 0.773196\n",
      "Epoch 16098 - Train Loss: 0.092579, Train Acc: 0.866667 | Val Loss: 0.116993, Val Acc: 0.773196\n",
      "Epoch 16099 - Train Loss: 0.092575, Train Acc: 0.866667 | Val Loss: 0.116991, Val Acc: 0.773196\n",
      "Epoch 16100 - Train Loss: 0.092572, Train Acc: 0.866667 | Val Loss: 0.116989, Val Acc: 0.773196\n",
      "Epoch 16101 - Train Loss: 0.092568, Train Acc: 0.866667 | Val Loss: 0.116987, Val Acc: 0.773196\n",
      "Epoch 16102 - Train Loss: 0.092565, Train Acc: 0.866667 | Val Loss: 0.116985, Val Acc: 0.773196\n",
      "Epoch 16103 - Train Loss: 0.092561, Train Acc: 0.866667 | Val Loss: 0.116982, Val Acc: 0.773196\n",
      "Epoch 16104 - Train Loss: 0.092558, Train Acc: 0.866667 | Val Loss: 0.116980, Val Acc: 0.773196\n",
      "Epoch 16105 - Train Loss: 0.092554, Train Acc: 0.866667 | Val Loss: 0.116978, Val Acc: 0.773196\n",
      "Epoch 16106 - Train Loss: 0.092550, Train Acc: 0.866667 | Val Loss: 0.116976, Val Acc: 0.773196\n",
      "Epoch 16107 - Train Loss: 0.092547, Train Acc: 0.866667 | Val Loss: 0.116974, Val Acc: 0.773196\n",
      "Epoch 16108 - Train Loss: 0.092543, Train Acc: 0.866667 | Val Loss: 0.116971, Val Acc: 0.773196\n",
      "Epoch 16109 - Train Loss: 0.092540, Train Acc: 0.866667 | Val Loss: 0.116969, Val Acc: 0.773196\n",
      "Epoch 16110 - Train Loss: 0.092536, Train Acc: 0.866667 | Val Loss: 0.116967, Val Acc: 0.773196\n",
      "Epoch 16111 - Train Loss: 0.092533, Train Acc: 0.866667 | Val Loss: 0.116965, Val Acc: 0.773196\n",
      "Epoch 16112 - Train Loss: 0.092529, Train Acc: 0.866667 | Val Loss: 0.116963, Val Acc: 0.773196\n",
      "Epoch 16113 - Train Loss: 0.092525, Train Acc: 0.866667 | Val Loss: 0.116961, Val Acc: 0.773196\n",
      "Epoch 16114 - Train Loss: 0.092522, Train Acc: 0.866667 | Val Loss: 0.116958, Val Acc: 0.773196\n",
      "Epoch 16115 - Train Loss: 0.092518, Train Acc: 0.866667 | Val Loss: 0.116956, Val Acc: 0.773196\n",
      "Epoch 16116 - Train Loss: 0.092515, Train Acc: 0.866667 | Val Loss: 0.116954, Val Acc: 0.773196\n",
      "Epoch 16117 - Train Loss: 0.092511, Train Acc: 0.866667 | Val Loss: 0.116952, Val Acc: 0.773196\n",
      "Epoch 16118 - Train Loss: 0.092508, Train Acc: 0.866667 | Val Loss: 0.116950, Val Acc: 0.773196\n",
      "Epoch 16119 - Train Loss: 0.092504, Train Acc: 0.866667 | Val Loss: 0.116947, Val Acc: 0.773196\n",
      "Epoch 16120 - Train Loss: 0.092500, Train Acc: 0.866667 | Val Loss: 0.116945, Val Acc: 0.773196\n",
      "Epoch 16121 - Train Loss: 0.092497, Train Acc: 0.866667 | Val Loss: 0.116943, Val Acc: 0.773196\n",
      "Epoch 16122 - Train Loss: 0.092493, Train Acc: 0.866667 | Val Loss: 0.116941, Val Acc: 0.773196\n",
      "Epoch 16123 - Train Loss: 0.092490, Train Acc: 0.866667 | Val Loss: 0.116939, Val Acc: 0.773196\n",
      "Epoch 16124 - Train Loss: 0.092486, Train Acc: 0.866667 | Val Loss: 0.116936, Val Acc: 0.773196\n",
      "Epoch 16125 - Train Loss: 0.092483, Train Acc: 0.866667 | Val Loss: 0.116934, Val Acc: 0.773196\n",
      "Epoch 16126 - Train Loss: 0.092479, Train Acc: 0.866667 | Val Loss: 0.116932, Val Acc: 0.773196\n",
      "Epoch 16127 - Train Loss: 0.092476, Train Acc: 0.866667 | Val Loss: 0.116930, Val Acc: 0.773196\n",
      "Epoch 16128 - Train Loss: 0.092472, Train Acc: 0.866667 | Val Loss: 0.116928, Val Acc: 0.773196\n",
      "Epoch 16129 - Train Loss: 0.092468, Train Acc: 0.866667 | Val Loss: 0.116926, Val Acc: 0.773196\n",
      "Epoch 16130 - Train Loss: 0.092465, Train Acc: 0.866667 | Val Loss: 0.116923, Val Acc: 0.773196\n",
      "Epoch 16131 - Train Loss: 0.092461, Train Acc: 0.866667 | Val Loss: 0.116921, Val Acc: 0.773196\n",
      "Epoch 16132 - Train Loss: 0.092458, Train Acc: 0.866667 | Val Loss: 0.116919, Val Acc: 0.773196\n",
      "Epoch 16133 - Train Loss: 0.092454, Train Acc: 0.866667 | Val Loss: 0.116917, Val Acc: 0.773196\n",
      "Epoch 16134 - Train Loss: 0.092451, Train Acc: 0.866667 | Val Loss: 0.116915, Val Acc: 0.773196\n",
      "Epoch 16135 - Train Loss: 0.092447, Train Acc: 0.866667 | Val Loss: 0.116912, Val Acc: 0.773196\n",
      "Epoch 16136 - Train Loss: 0.092443, Train Acc: 0.866667 | Val Loss: 0.116910, Val Acc: 0.773196\n",
      "Epoch 16137 - Train Loss: 0.092440, Train Acc: 0.866667 | Val Loss: 0.116908, Val Acc: 0.773196\n",
      "Epoch 16138 - Train Loss: 0.092436, Train Acc: 0.866667 | Val Loss: 0.116906, Val Acc: 0.773196\n",
      "Epoch 16139 - Train Loss: 0.092433, Train Acc: 0.866667 | Val Loss: 0.116904, Val Acc: 0.773196\n",
      "Epoch 16140 - Train Loss: 0.092429, Train Acc: 0.866667 | Val Loss: 0.116902, Val Acc: 0.773196\n",
      "Epoch 16141 - Train Loss: 0.092426, Train Acc: 0.866667 | Val Loss: 0.116899, Val Acc: 0.773196\n",
      "Epoch 16142 - Train Loss: 0.092422, Train Acc: 0.866667 | Val Loss: 0.116897, Val Acc: 0.773196\n",
      "Epoch 16143 - Train Loss: 0.092419, Train Acc: 0.866667 | Val Loss: 0.116895, Val Acc: 0.773196\n",
      "Epoch 16144 - Train Loss: 0.092415, Train Acc: 0.866667 | Val Loss: 0.116893, Val Acc: 0.773196\n",
      "Epoch 16145 - Train Loss: 0.092411, Train Acc: 0.866667 | Val Loss: 0.116891, Val Acc: 0.773196\n",
      "Epoch 16146 - Train Loss: 0.092408, Train Acc: 0.866667 | Val Loss: 0.116888, Val Acc: 0.773196\n",
      "Epoch 16147 - Train Loss: 0.092404, Train Acc: 0.866667 | Val Loss: 0.116886, Val Acc: 0.773196\n",
      "Epoch 16148 - Train Loss: 0.092401, Train Acc: 0.866667 | Val Loss: 0.116884, Val Acc: 0.773196\n",
      "Epoch 16149 - Train Loss: 0.092397, Train Acc: 0.866667 | Val Loss: 0.116882, Val Acc: 0.773196\n",
      "Epoch 16150 - Train Loss: 0.092394, Train Acc: 0.866667 | Val Loss: 0.116880, Val Acc: 0.773196\n",
      "Epoch 16151 - Train Loss: 0.092390, Train Acc: 0.866667 | Val Loss: 0.116877, Val Acc: 0.773196\n",
      "Epoch 16152 - Train Loss: 0.092387, Train Acc: 0.866667 | Val Loss: 0.116875, Val Acc: 0.773196\n",
      "Epoch 16153 - Train Loss: 0.092383, Train Acc: 0.866667 | Val Loss: 0.116873, Val Acc: 0.773196\n",
      "Epoch 16154 - Train Loss: 0.092380, Train Acc: 0.866667 | Val Loss: 0.116871, Val Acc: 0.773196\n",
      "Epoch 16155 - Train Loss: 0.092376, Train Acc: 0.866667 | Val Loss: 0.116869, Val Acc: 0.773196\n",
      "Epoch 16156 - Train Loss: 0.092372, Train Acc: 0.866667 | Val Loss: 0.116867, Val Acc: 0.773196\n",
      "Epoch 16157 - Train Loss: 0.092369, Train Acc: 0.866667 | Val Loss: 0.116864, Val Acc: 0.773196\n",
      "Epoch 16158 - Train Loss: 0.092365, Train Acc: 0.866667 | Val Loss: 0.116862, Val Acc: 0.773196\n",
      "Epoch 16159 - Train Loss: 0.092362, Train Acc: 0.866667 | Val Loss: 0.116860, Val Acc: 0.773196\n",
      "Epoch 16160 - Train Loss: 0.092358, Train Acc: 0.866667 | Val Loss: 0.116858, Val Acc: 0.773196\n",
      "Epoch 16161 - Train Loss: 0.092355, Train Acc: 0.866667 | Val Loss: 0.116856, Val Acc: 0.773196\n",
      "Epoch 16162 - Train Loss: 0.092351, Train Acc: 0.866667 | Val Loss: 0.116854, Val Acc: 0.773196\n",
      "Epoch 16163 - Train Loss: 0.092348, Train Acc: 0.866667 | Val Loss: 0.116851, Val Acc: 0.773196\n",
      "Epoch 16164 - Train Loss: 0.092344, Train Acc: 0.866667 | Val Loss: 0.116849, Val Acc: 0.773196\n",
      "Epoch 16165 - Train Loss: 0.092340, Train Acc: 0.866667 | Val Loss: 0.116847, Val Acc: 0.773196\n",
      "Epoch 16166 - Train Loss: 0.092337, Train Acc: 0.866667 | Val Loss: 0.116845, Val Acc: 0.773196\n",
      "Epoch 16167 - Train Loss: 0.092333, Train Acc: 0.866667 | Val Loss: 0.116843, Val Acc: 0.773196\n",
      "Epoch 16168 - Train Loss: 0.092330, Train Acc: 0.866667 | Val Loss: 0.116841, Val Acc: 0.773196\n",
      "Epoch 16169 - Train Loss: 0.092326, Train Acc: 0.866667 | Val Loss: 0.116838, Val Acc: 0.773196\n",
      "Epoch 16170 - Train Loss: 0.092323, Train Acc: 0.866667 | Val Loss: 0.116836, Val Acc: 0.773196\n",
      "Epoch 16171 - Train Loss: 0.092319, Train Acc: 0.866667 | Val Loss: 0.116834, Val Acc: 0.773196\n",
      "Epoch 16172 - Train Loss: 0.092316, Train Acc: 0.866667 | Val Loss: 0.116832, Val Acc: 0.773196\n",
      "Epoch 16173 - Train Loss: 0.092312, Train Acc: 0.866667 | Val Loss: 0.116830, Val Acc: 0.773196\n",
      "Epoch 16174 - Train Loss: 0.092309, Train Acc: 0.866667 | Val Loss: 0.116828, Val Acc: 0.773196\n",
      "Epoch 16175 - Train Loss: 0.092305, Train Acc: 0.866667 | Val Loss: 0.116825, Val Acc: 0.773196\n",
      "Epoch 16176 - Train Loss: 0.092302, Train Acc: 0.866667 | Val Loss: 0.116823, Val Acc: 0.773196\n",
      "Epoch 16177 - Train Loss: 0.092298, Train Acc: 0.866667 | Val Loss: 0.116821, Val Acc: 0.773196\n",
      "Epoch 16178 - Train Loss: 0.092294, Train Acc: 0.866667 | Val Loss: 0.116819, Val Acc: 0.773196\n",
      "Epoch 16179 - Train Loss: 0.092291, Train Acc: 0.866667 | Val Loss: 0.116817, Val Acc: 0.773196\n",
      "Epoch 16180 - Train Loss: 0.092287, Train Acc: 0.866667 | Val Loss: 0.116814, Val Acc: 0.773196\n",
      "Epoch 16181 - Train Loss: 0.092284, Train Acc: 0.866667 | Val Loss: 0.116812, Val Acc: 0.773196\n",
      "Epoch 16182 - Train Loss: 0.092280, Train Acc: 0.866667 | Val Loss: 0.116810, Val Acc: 0.773196\n",
      "Epoch 16183 - Train Loss: 0.092277, Train Acc: 0.866667 | Val Loss: 0.116808, Val Acc: 0.773196\n",
      "Epoch 16184 - Train Loss: 0.092273, Train Acc: 0.866667 | Val Loss: 0.116806, Val Acc: 0.773196\n",
      "Epoch 16185 - Train Loss: 0.092270, Train Acc: 0.866667 | Val Loss: 0.116804, Val Acc: 0.773196\n",
      "Epoch 16186 - Train Loss: 0.092266, Train Acc: 0.866667 | Val Loss: 0.116801, Val Acc: 0.773196\n",
      "Epoch 16187 - Train Loss: 0.092263, Train Acc: 0.866667 | Val Loss: 0.116799, Val Acc: 0.773196\n",
      "Epoch 16188 - Train Loss: 0.092259, Train Acc: 0.866667 | Val Loss: 0.116797, Val Acc: 0.773196\n",
      "Epoch 16189 - Train Loss: 0.092256, Train Acc: 0.866667 | Val Loss: 0.116795, Val Acc: 0.773196\n",
      "Epoch 16190 - Train Loss: 0.092252, Train Acc: 0.866667 | Val Loss: 0.116793, Val Acc: 0.773196\n",
      "Epoch 16191 - Train Loss: 0.092248, Train Acc: 0.866667 | Val Loss: 0.116791, Val Acc: 0.773196\n",
      "Epoch 16192 - Train Loss: 0.092245, Train Acc: 0.866667 | Val Loss: 0.116788, Val Acc: 0.773196\n",
      "Epoch 16193 - Train Loss: 0.092241, Train Acc: 0.866667 | Val Loss: 0.116786, Val Acc: 0.773196\n",
      "Epoch 16194 - Train Loss: 0.092238, Train Acc: 0.866667 | Val Loss: 0.116784, Val Acc: 0.773196\n",
      "Epoch 16195 - Train Loss: 0.092234, Train Acc: 0.866667 | Val Loss: 0.116782, Val Acc: 0.773196\n",
      "Epoch 16196 - Train Loss: 0.092231, Train Acc: 0.866667 | Val Loss: 0.116780, Val Acc: 0.773196\n",
      "Epoch 16197 - Train Loss: 0.092227, Train Acc: 0.866667 | Val Loss: 0.116778, Val Acc: 0.773196\n",
      "Epoch 16198 - Train Loss: 0.092224, Train Acc: 0.866667 | Val Loss: 0.116776, Val Acc: 0.773196\n",
      "Epoch 16199 - Train Loss: 0.092220, Train Acc: 0.866667 | Val Loss: 0.116773, Val Acc: 0.773196\n",
      "Epoch 16200 - Train Loss: 0.092217, Train Acc: 0.866667 | Val Loss: 0.116771, Val Acc: 0.773196\n",
      "Epoch 16201 - Train Loss: 0.092213, Train Acc: 0.866667 | Val Loss: 0.116769, Val Acc: 0.773196\n",
      "Epoch 16202 - Train Loss: 0.092210, Train Acc: 0.866667 | Val Loss: 0.116767, Val Acc: 0.773196\n",
      "Epoch 16203 - Train Loss: 0.092206, Train Acc: 0.866667 | Val Loss: 0.116765, Val Acc: 0.773196\n",
      "Epoch 16204 - Train Loss: 0.092203, Train Acc: 0.866667 | Val Loss: 0.116763, Val Acc: 0.773196\n",
      "Epoch 16205 - Train Loss: 0.092199, Train Acc: 0.866667 | Val Loss: 0.116760, Val Acc: 0.773196\n",
      "Epoch 16206 - Train Loss: 0.092196, Train Acc: 0.866667 | Val Loss: 0.116758, Val Acc: 0.773196\n",
      "Epoch 16207 - Train Loss: 0.092192, Train Acc: 0.866667 | Val Loss: 0.116756, Val Acc: 0.773196\n",
      "Epoch 16208 - Train Loss: 0.092188, Train Acc: 0.866667 | Val Loss: 0.116754, Val Acc: 0.773196\n",
      "Epoch 16209 - Train Loss: 0.092185, Train Acc: 0.866667 | Val Loss: 0.116752, Val Acc: 0.773196\n",
      "Epoch 16210 - Train Loss: 0.092181, Train Acc: 0.866667 | Val Loss: 0.116750, Val Acc: 0.773196\n",
      "Epoch 16211 - Train Loss: 0.092178, Train Acc: 0.866667 | Val Loss: 0.116747, Val Acc: 0.773196\n",
      "Epoch 16212 - Train Loss: 0.092174, Train Acc: 0.866667 | Val Loss: 0.116745, Val Acc: 0.773196\n",
      "Epoch 16213 - Train Loss: 0.092171, Train Acc: 0.866667 | Val Loss: 0.116743, Val Acc: 0.773196\n",
      "Epoch 16214 - Train Loss: 0.092167, Train Acc: 0.866667 | Val Loss: 0.116741, Val Acc: 0.773196\n",
      "Epoch 16215 - Train Loss: 0.092164, Train Acc: 0.866667 | Val Loss: 0.116739, Val Acc: 0.773196\n",
      "Epoch 16216 - Train Loss: 0.092160, Train Acc: 0.866667 | Val Loss: 0.116737, Val Acc: 0.773196\n",
      "Epoch 16217 - Train Loss: 0.092157, Train Acc: 0.866667 | Val Loss: 0.116734, Val Acc: 0.773196\n",
      "Epoch 16218 - Train Loss: 0.092153, Train Acc: 0.866667 | Val Loss: 0.116732, Val Acc: 0.773196\n",
      "Epoch 16219 - Train Loss: 0.092150, Train Acc: 0.866667 | Val Loss: 0.116730, Val Acc: 0.773196\n",
      "Epoch 16220 - Train Loss: 0.092146, Train Acc: 0.866667 | Val Loss: 0.116728, Val Acc: 0.773196\n",
      "Epoch 16221 - Train Loss: 0.092143, Train Acc: 0.866667 | Val Loss: 0.116726, Val Acc: 0.773196\n",
      "Epoch 16222 - Train Loss: 0.092139, Train Acc: 0.866667 | Val Loss: 0.116724, Val Acc: 0.773196\n",
      "Epoch 16223 - Train Loss: 0.092136, Train Acc: 0.866667 | Val Loss: 0.116722, Val Acc: 0.773196\n",
      "Epoch 16224 - Train Loss: 0.092132, Train Acc: 0.866667 | Val Loss: 0.116719, Val Acc: 0.773196\n",
      "Epoch 16225 - Train Loss: 0.092129, Train Acc: 0.866667 | Val Loss: 0.116717, Val Acc: 0.773196\n",
      "Epoch 16226 - Train Loss: 0.092125, Train Acc: 0.866667 | Val Loss: 0.116715, Val Acc: 0.773196\n",
      "Epoch 16227 - Train Loss: 0.092122, Train Acc: 0.866667 | Val Loss: 0.116713, Val Acc: 0.773196\n",
      "Epoch 16228 - Train Loss: 0.092118, Train Acc: 0.866667 | Val Loss: 0.116711, Val Acc: 0.773196\n",
      "Epoch 16229 - Train Loss: 0.092115, Train Acc: 0.866667 | Val Loss: 0.116709, Val Acc: 0.773196\n",
      "Epoch 16230 - Train Loss: 0.092111, Train Acc: 0.866667 | Val Loss: 0.116707, Val Acc: 0.773196\n",
      "Epoch 16231 - Train Loss: 0.092107, Train Acc: 0.866667 | Val Loss: 0.116704, Val Acc: 0.773196\n",
      "Epoch 16232 - Train Loss: 0.092104, Train Acc: 0.866667 | Val Loss: 0.116702, Val Acc: 0.773196\n",
      "Epoch 16233 - Train Loss: 0.092100, Train Acc: 0.866667 | Val Loss: 0.116700, Val Acc: 0.773196\n",
      "Epoch 16234 - Train Loss: 0.092097, Train Acc: 0.866667 | Val Loss: 0.116698, Val Acc: 0.773196\n",
      "Epoch 16235 - Train Loss: 0.092093, Train Acc: 0.866667 | Val Loss: 0.116696, Val Acc: 0.773196\n",
      "Epoch 16236 - Train Loss: 0.092090, Train Acc: 0.866667 | Val Loss: 0.116694, Val Acc: 0.773196\n",
      "Epoch 16237 - Train Loss: 0.092086, Train Acc: 0.866667 | Val Loss: 0.116691, Val Acc: 0.773196\n",
      "Epoch 16238 - Train Loss: 0.092083, Train Acc: 0.866667 | Val Loss: 0.116689, Val Acc: 0.773196\n",
      "Epoch 16239 - Train Loss: 0.092079, Train Acc: 0.866667 | Val Loss: 0.116687, Val Acc: 0.773196\n",
      "Epoch 16240 - Train Loss: 0.092076, Train Acc: 0.866667 | Val Loss: 0.116685, Val Acc: 0.773196\n",
      "Epoch 16241 - Train Loss: 0.092072, Train Acc: 0.866667 | Val Loss: 0.116683, Val Acc: 0.773196\n",
      "Epoch 16242 - Train Loss: 0.092069, Train Acc: 0.866667 | Val Loss: 0.116681, Val Acc: 0.773196\n",
      "Epoch 16243 - Train Loss: 0.092065, Train Acc: 0.866667 | Val Loss: 0.116679, Val Acc: 0.773196\n",
      "Epoch 16244 - Train Loss: 0.092062, Train Acc: 0.866667 | Val Loss: 0.116676, Val Acc: 0.773196\n",
      "Epoch 16245 - Train Loss: 0.092058, Train Acc: 0.866667 | Val Loss: 0.116674, Val Acc: 0.773196\n",
      "Epoch 16246 - Train Loss: 0.092055, Train Acc: 0.866667 | Val Loss: 0.116672, Val Acc: 0.773196\n",
      "Epoch 16247 - Train Loss: 0.092051, Train Acc: 0.866667 | Val Loss: 0.116670, Val Acc: 0.773196\n",
      "Epoch 16248 - Train Loss: 0.092048, Train Acc: 0.866667 | Val Loss: 0.116668, Val Acc: 0.773196\n",
      "Epoch 16249 - Train Loss: 0.092044, Train Acc: 0.866667 | Val Loss: 0.116666, Val Acc: 0.773196\n",
      "Epoch 16250 - Train Loss: 0.092041, Train Acc: 0.866667 | Val Loss: 0.116664, Val Acc: 0.773196\n",
      "Epoch 16251 - Train Loss: 0.092037, Train Acc: 0.866667 | Val Loss: 0.116661, Val Acc: 0.773196\n",
      "Epoch 16252 - Train Loss: 0.092034, Train Acc: 0.866667 | Val Loss: 0.116659, Val Acc: 0.773196\n",
      "Epoch 16253 - Train Loss: 0.092030, Train Acc: 0.866667 | Val Loss: 0.116657, Val Acc: 0.773196\n",
      "Epoch 16254 - Train Loss: 0.092027, Train Acc: 0.866667 | Val Loss: 0.116655, Val Acc: 0.773196\n",
      "Epoch 16255 - Train Loss: 0.092023, Train Acc: 0.866667 | Val Loss: 0.116653, Val Acc: 0.773196\n",
      "Epoch 16256 - Train Loss: 0.092020, Train Acc: 0.866667 | Val Loss: 0.116651, Val Acc: 0.773196\n",
      "Epoch 16257 - Train Loss: 0.092016, Train Acc: 0.866667 | Val Loss: 0.116649, Val Acc: 0.773196\n",
      "Epoch 16258 - Train Loss: 0.092013, Train Acc: 0.866667 | Val Loss: 0.116646, Val Acc: 0.773196\n",
      "Epoch 16259 - Train Loss: 0.092009, Train Acc: 0.866667 | Val Loss: 0.116644, Val Acc: 0.773196\n",
      "Epoch 16260 - Train Loss: 0.092006, Train Acc: 0.866667 | Val Loss: 0.116642, Val Acc: 0.773196\n",
      "Epoch 16261 - Train Loss: 0.092002, Train Acc: 0.866667 | Val Loss: 0.116640, Val Acc: 0.773196\n",
      "Epoch 16262 - Train Loss: 0.091999, Train Acc: 0.866667 | Val Loss: 0.116638, Val Acc: 0.773196\n",
      "Epoch 16263 - Train Loss: 0.091995, Train Acc: 0.866667 | Val Loss: 0.116636, Val Acc: 0.773196\n",
      "Epoch 16264 - Train Loss: 0.091992, Train Acc: 0.866667 | Val Loss: 0.116634, Val Acc: 0.773196\n",
      "Epoch 16265 - Train Loss: 0.091988, Train Acc: 0.866667 | Val Loss: 0.116632, Val Acc: 0.773196\n",
      "Epoch 16266 - Train Loss: 0.091985, Train Acc: 0.866667 | Val Loss: 0.116629, Val Acc: 0.773196\n",
      "Epoch 16267 - Train Loss: 0.091981, Train Acc: 0.866667 | Val Loss: 0.116627, Val Acc: 0.773196\n",
      "Epoch 16268 - Train Loss: 0.091978, Train Acc: 0.866667 | Val Loss: 0.116625, Val Acc: 0.773196\n",
      "Epoch 16269 - Train Loss: 0.091974, Train Acc: 0.866667 | Val Loss: 0.116623, Val Acc: 0.773196\n",
      "Epoch 16270 - Train Loss: 0.091971, Train Acc: 0.866667 | Val Loss: 0.116621, Val Acc: 0.773196\n",
      "Epoch 16271 - Train Loss: 0.091967, Train Acc: 0.866667 | Val Loss: 0.116619, Val Acc: 0.773196\n",
      "Epoch 16272 - Train Loss: 0.091964, Train Acc: 0.866667 | Val Loss: 0.116617, Val Acc: 0.773196\n",
      "Epoch 16273 - Train Loss: 0.091960, Train Acc: 0.866667 | Val Loss: 0.116614, Val Acc: 0.773196\n",
      "Epoch 16274 - Train Loss: 0.091957, Train Acc: 0.866667 | Val Loss: 0.116612, Val Acc: 0.773196\n",
      "Epoch 16275 - Train Loss: 0.091953, Train Acc: 0.866667 | Val Loss: 0.116610, Val Acc: 0.773196\n",
      "Epoch 16276 - Train Loss: 0.091950, Train Acc: 0.866667 | Val Loss: 0.116608, Val Acc: 0.773196\n",
      "Epoch 16277 - Train Loss: 0.091946, Train Acc: 0.866667 | Val Loss: 0.116606, Val Acc: 0.773196\n",
      "Epoch 16278 - Train Loss: 0.091943, Train Acc: 0.866667 | Val Loss: 0.116604, Val Acc: 0.773196\n",
      "Epoch 16279 - Train Loss: 0.091939, Train Acc: 0.866667 | Val Loss: 0.116602, Val Acc: 0.773196\n",
      "Epoch 16280 - Train Loss: 0.091936, Train Acc: 0.866667 | Val Loss: 0.116600, Val Acc: 0.773196\n",
      "Epoch 16281 - Train Loss: 0.091932, Train Acc: 0.866667 | Val Loss: 0.116597, Val Acc: 0.773196\n",
      "Epoch 16282 - Train Loss: 0.091929, Train Acc: 0.866667 | Val Loss: 0.116595, Val Acc: 0.773196\n",
      "Epoch 16283 - Train Loss: 0.091925, Train Acc: 0.866667 | Val Loss: 0.116593, Val Acc: 0.773196\n",
      "Epoch 16284 - Train Loss: 0.091922, Train Acc: 0.866667 | Val Loss: 0.116591, Val Acc: 0.773196\n",
      "Epoch 16285 - Train Loss: 0.091918, Train Acc: 0.866667 | Val Loss: 0.116589, Val Acc: 0.773196\n",
      "Epoch 16286 - Train Loss: 0.091915, Train Acc: 0.866667 | Val Loss: 0.116587, Val Acc: 0.773196\n",
      "Epoch 16287 - Train Loss: 0.091911, Train Acc: 0.866667 | Val Loss: 0.116585, Val Acc: 0.773196\n",
      "Epoch 16288 - Train Loss: 0.091908, Train Acc: 0.866667 | Val Loss: 0.116583, Val Acc: 0.773196\n",
      "Epoch 16289 - Train Loss: 0.091904, Train Acc: 0.866667 | Val Loss: 0.116580, Val Acc: 0.773196\n",
      "Epoch 16290 - Train Loss: 0.091901, Train Acc: 0.866667 | Val Loss: 0.116578, Val Acc: 0.773196\n",
      "Epoch 16291 - Train Loss: 0.091897, Train Acc: 0.866667 | Val Loss: 0.116576, Val Acc: 0.773196\n",
      "Epoch 16292 - Train Loss: 0.091894, Train Acc: 0.866667 | Val Loss: 0.116574, Val Acc: 0.773196\n",
      "Epoch 16293 - Train Loss: 0.091890, Train Acc: 0.866667 | Val Loss: 0.116572, Val Acc: 0.773196\n",
      "Epoch 16294 - Train Loss: 0.091887, Train Acc: 0.866667 | Val Loss: 0.116570, Val Acc: 0.773196\n",
      "Epoch 16295 - Train Loss: 0.091883, Train Acc: 0.866667 | Val Loss: 0.116568, Val Acc: 0.773196\n",
      "Epoch 16296 - Train Loss: 0.091880, Train Acc: 0.866667 | Val Loss: 0.116566, Val Acc: 0.773196\n",
      "Epoch 16297 - Train Loss: 0.091876, Train Acc: 0.866667 | Val Loss: 0.116563, Val Acc: 0.773196\n",
      "Epoch 16298 - Train Loss: 0.091873, Train Acc: 0.866667 | Val Loss: 0.116561, Val Acc: 0.773196\n",
      "Epoch 16299 - Train Loss: 0.091869, Train Acc: 0.866667 | Val Loss: 0.116559, Val Acc: 0.773196\n",
      "Epoch 16300 - Train Loss: 0.091866, Train Acc: 0.866667 | Val Loss: 0.116557, Val Acc: 0.773196\n",
      "Epoch 16301 - Train Loss: 0.091862, Train Acc: 0.866667 | Val Loss: 0.116555, Val Acc: 0.773196\n",
      "Epoch 16302 - Train Loss: 0.091859, Train Acc: 0.866667 | Val Loss: 0.116553, Val Acc: 0.773196\n",
      "Epoch 16303 - Train Loss: 0.091855, Train Acc: 0.866667 | Val Loss: 0.116551, Val Acc: 0.773196\n",
      "Epoch 16304 - Train Loss: 0.091852, Train Acc: 0.866667 | Val Loss: 0.116549, Val Acc: 0.773196\n",
      "Epoch 16305 - Train Loss: 0.091848, Train Acc: 0.866667 | Val Loss: 0.116546, Val Acc: 0.773196\n",
      "Epoch 16306 - Train Loss: 0.091845, Train Acc: 0.866667 | Val Loss: 0.116544, Val Acc: 0.773196\n",
      "Epoch 16307 - Train Loss: 0.091842, Train Acc: 0.866667 | Val Loss: 0.116542, Val Acc: 0.773196\n",
      "Epoch 16308 - Train Loss: 0.091838, Train Acc: 0.866667 | Val Loss: 0.116540, Val Acc: 0.773196\n",
      "Epoch 16309 - Train Loss: 0.091835, Train Acc: 0.866667 | Val Loss: 0.116538, Val Acc: 0.773196\n",
      "Epoch 16310 - Train Loss: 0.091831, Train Acc: 0.866667 | Val Loss: 0.116536, Val Acc: 0.773196\n",
      "Epoch 16311 - Train Loss: 0.091828, Train Acc: 0.866667 | Val Loss: 0.116534, Val Acc: 0.773196\n",
      "Epoch 16312 - Train Loss: 0.091824, Train Acc: 0.866667 | Val Loss: 0.116532, Val Acc: 0.773196\n",
      "Epoch 16313 - Train Loss: 0.091821, Train Acc: 0.866667 | Val Loss: 0.116529, Val Acc: 0.773196\n",
      "Epoch 16314 - Train Loss: 0.091817, Train Acc: 0.866667 | Val Loss: 0.116527, Val Acc: 0.773196\n",
      "Epoch 16315 - Train Loss: 0.091814, Train Acc: 0.866667 | Val Loss: 0.116525, Val Acc: 0.773196\n",
      "Epoch 16316 - Train Loss: 0.091810, Train Acc: 0.866667 | Val Loss: 0.116523, Val Acc: 0.773196\n",
      "Epoch 16317 - Train Loss: 0.091807, Train Acc: 0.866667 | Val Loss: 0.116521, Val Acc: 0.773196\n",
      "Epoch 16318 - Train Loss: 0.091803, Train Acc: 0.866667 | Val Loss: 0.116519, Val Acc: 0.773196\n",
      "Epoch 16319 - Train Loss: 0.091800, Train Acc: 0.866667 | Val Loss: 0.116517, Val Acc: 0.773196\n",
      "Epoch 16320 - Train Loss: 0.091796, Train Acc: 0.866667 | Val Loss: 0.116515, Val Acc: 0.773196\n",
      "Epoch 16321 - Train Loss: 0.091793, Train Acc: 0.866667 | Val Loss: 0.116513, Val Acc: 0.773196\n",
      "Epoch 16322 - Train Loss: 0.091789, Train Acc: 0.866667 | Val Loss: 0.116510, Val Acc: 0.773196\n",
      "Epoch 16323 - Train Loss: 0.091786, Train Acc: 0.866667 | Val Loss: 0.116508, Val Acc: 0.773196\n",
      "Epoch 16324 - Train Loss: 0.091782, Train Acc: 0.866667 | Val Loss: 0.116506, Val Acc: 0.773196\n",
      "Epoch 16325 - Train Loss: 0.091779, Train Acc: 0.866667 | Val Loss: 0.116504, Val Acc: 0.773196\n",
      "Epoch 16326 - Train Loss: 0.091775, Train Acc: 0.866667 | Val Loss: 0.116502, Val Acc: 0.773196\n",
      "Epoch 16327 - Train Loss: 0.091772, Train Acc: 0.866667 | Val Loss: 0.116500, Val Acc: 0.773196\n",
      "Epoch 16328 - Train Loss: 0.091768, Train Acc: 0.866667 | Val Loss: 0.116498, Val Acc: 0.773196\n",
      "Epoch 16329 - Train Loss: 0.091765, Train Acc: 0.866667 | Val Loss: 0.116496, Val Acc: 0.773196\n",
      "Epoch 16330 - Train Loss: 0.091762, Train Acc: 0.866667 | Val Loss: 0.116494, Val Acc: 0.773196\n",
      "Epoch 16331 - Train Loss: 0.091758, Train Acc: 0.866667 | Val Loss: 0.116491, Val Acc: 0.773196\n",
      "Epoch 16332 - Train Loss: 0.091755, Train Acc: 0.866667 | Val Loss: 0.116489, Val Acc: 0.773196\n",
      "Epoch 16333 - Train Loss: 0.091751, Train Acc: 0.866667 | Val Loss: 0.116487, Val Acc: 0.773196\n",
      "Epoch 16334 - Train Loss: 0.091748, Train Acc: 0.866667 | Val Loss: 0.116485, Val Acc: 0.773196\n",
      "Epoch 16335 - Train Loss: 0.091744, Train Acc: 0.866667 | Val Loss: 0.116483, Val Acc: 0.773196\n",
      "Epoch 16336 - Train Loss: 0.091741, Train Acc: 0.866667 | Val Loss: 0.116481, Val Acc: 0.773196\n",
      "Epoch 16337 - Train Loss: 0.091737, Train Acc: 0.866667 | Val Loss: 0.116479, Val Acc: 0.773196\n",
      "Epoch 16338 - Train Loss: 0.091734, Train Acc: 0.866667 | Val Loss: 0.116477, Val Acc: 0.773196\n",
      "Epoch 16339 - Train Loss: 0.091730, Train Acc: 0.866667 | Val Loss: 0.116475, Val Acc: 0.773196\n",
      "Epoch 16340 - Train Loss: 0.091727, Train Acc: 0.866667 | Val Loss: 0.116473, Val Acc: 0.773196\n",
      "Epoch 16341 - Train Loss: 0.091723, Train Acc: 0.866667 | Val Loss: 0.116470, Val Acc: 0.773196\n",
      "Epoch 16342 - Train Loss: 0.091720, Train Acc: 0.866667 | Val Loss: 0.116468, Val Acc: 0.773196\n",
      "Epoch 16343 - Train Loss: 0.091716, Train Acc: 0.866667 | Val Loss: 0.116466, Val Acc: 0.773196\n",
      "Epoch 16344 - Train Loss: 0.091713, Train Acc: 0.866667 | Val Loss: 0.116464, Val Acc: 0.773196\n",
      "Epoch 16345 - Train Loss: 0.091709, Train Acc: 0.866667 | Val Loss: 0.116462, Val Acc: 0.773196\n",
      "Epoch 16346 - Train Loss: 0.091706, Train Acc: 0.866667 | Val Loss: 0.116460, Val Acc: 0.773196\n",
      "Epoch 16347 - Train Loss: 0.091703, Train Acc: 0.866667 | Val Loss: 0.116458, Val Acc: 0.773196\n",
      "Epoch 16348 - Train Loss: 0.091699, Train Acc: 0.866667 | Val Loss: 0.116456, Val Acc: 0.773196\n",
      "Epoch 16349 - Train Loss: 0.091696, Train Acc: 0.866667 | Val Loss: 0.116454, Val Acc: 0.773196\n",
      "Epoch 16350 - Train Loss: 0.091692, Train Acc: 0.866667 | Val Loss: 0.116452, Val Acc: 0.773196\n",
      "Epoch 16351 - Train Loss: 0.091689, Train Acc: 0.866667 | Val Loss: 0.116449, Val Acc: 0.773196\n",
      "Epoch 16352 - Train Loss: 0.091685, Train Acc: 0.866667 | Val Loss: 0.116447, Val Acc: 0.773196\n",
      "Epoch 16353 - Train Loss: 0.091682, Train Acc: 0.866667 | Val Loss: 0.116445, Val Acc: 0.773196\n",
      "Epoch 16354 - Train Loss: 0.091678, Train Acc: 0.866667 | Val Loss: 0.116443, Val Acc: 0.773196\n",
      "Epoch 16355 - Train Loss: 0.091675, Train Acc: 0.866667 | Val Loss: 0.116441, Val Acc: 0.773196\n",
      "Epoch 16356 - Train Loss: 0.091671, Train Acc: 0.866667 | Val Loss: 0.116439, Val Acc: 0.773196\n",
      "Epoch 16357 - Train Loss: 0.091668, Train Acc: 0.866667 | Val Loss: 0.116437, Val Acc: 0.773196\n",
      "Epoch 16358 - Train Loss: 0.091664, Train Acc: 0.866667 | Val Loss: 0.116435, Val Acc: 0.773196\n",
      "Epoch 16359 - Train Loss: 0.091661, Train Acc: 0.866667 | Val Loss: 0.116433, Val Acc: 0.773196\n",
      "Epoch 16360 - Train Loss: 0.091658, Train Acc: 0.866667 | Val Loss: 0.116431, Val Acc: 0.773196\n",
      "Epoch 16361 - Train Loss: 0.091654, Train Acc: 0.866667 | Val Loss: 0.116428, Val Acc: 0.773196\n",
      "Epoch 16362 - Train Loss: 0.091651, Train Acc: 0.866667 | Val Loss: 0.116426, Val Acc: 0.773196\n",
      "Epoch 16363 - Train Loss: 0.091647, Train Acc: 0.866667 | Val Loss: 0.116424, Val Acc: 0.773196\n",
      "Epoch 16364 - Train Loss: 0.091644, Train Acc: 0.866667 | Val Loss: 0.116422, Val Acc: 0.773196\n",
      "Epoch 16365 - Train Loss: 0.091640, Train Acc: 0.866667 | Val Loss: 0.116420, Val Acc: 0.773196\n",
      "Epoch 16366 - Train Loss: 0.091637, Train Acc: 0.866667 | Val Loss: 0.116418, Val Acc: 0.773196\n",
      "Epoch 16367 - Train Loss: 0.091633, Train Acc: 0.866667 | Val Loss: 0.116416, Val Acc: 0.773196\n",
      "Epoch 16368 - Train Loss: 0.091630, Train Acc: 0.866667 | Val Loss: 0.116414, Val Acc: 0.773196\n",
      "Epoch 16369 - Train Loss: 0.091626, Train Acc: 0.866667 | Val Loss: 0.116412, Val Acc: 0.773196\n",
      "Epoch 16370 - Train Loss: 0.091623, Train Acc: 0.866667 | Val Loss: 0.116410, Val Acc: 0.773196\n",
      "Epoch 16371 - Train Loss: 0.091619, Train Acc: 0.866667 | Val Loss: 0.116408, Val Acc: 0.773196\n",
      "Epoch 16372 - Train Loss: 0.091616, Train Acc: 0.866667 | Val Loss: 0.116405, Val Acc: 0.773196\n",
      "Epoch 16373 - Train Loss: 0.091613, Train Acc: 0.866667 | Val Loss: 0.116403, Val Acc: 0.773196\n",
      "Epoch 16374 - Train Loss: 0.091609, Train Acc: 0.866667 | Val Loss: 0.116401, Val Acc: 0.773196\n",
      "Epoch 16375 - Train Loss: 0.091606, Train Acc: 0.866667 | Val Loss: 0.116399, Val Acc: 0.773196\n",
      "Epoch 16376 - Train Loss: 0.091602, Train Acc: 0.866667 | Val Loss: 0.116397, Val Acc: 0.773196\n",
      "Epoch 16377 - Train Loss: 0.091599, Train Acc: 0.866667 | Val Loss: 0.116395, Val Acc: 0.773196\n",
      "Epoch 16378 - Train Loss: 0.091595, Train Acc: 0.866667 | Val Loss: 0.116393, Val Acc: 0.773196\n",
      "Epoch 16379 - Train Loss: 0.091592, Train Acc: 0.866667 | Val Loss: 0.116391, Val Acc: 0.773196\n",
      "Epoch 16380 - Train Loss: 0.091588, Train Acc: 0.866667 | Val Loss: 0.116389, Val Acc: 0.773196\n",
      "Epoch 16381 - Train Loss: 0.091585, Train Acc: 0.866667 | Val Loss: 0.116387, Val Acc: 0.773196\n",
      "Epoch 16382 - Train Loss: 0.091581, Train Acc: 0.866667 | Val Loss: 0.116385, Val Acc: 0.773196\n",
      "Epoch 16383 - Train Loss: 0.091578, Train Acc: 0.866667 | Val Loss: 0.116382, Val Acc: 0.773196\n",
      "Epoch 16384 - Train Loss: 0.091575, Train Acc: 0.866667 | Val Loss: 0.116380, Val Acc: 0.773196\n",
      "Epoch 16385 - Train Loss: 0.091571, Train Acc: 0.866667 | Val Loss: 0.116378, Val Acc: 0.773196\n",
      "Epoch 16386 - Train Loss: 0.091568, Train Acc: 0.866667 | Val Loss: 0.116376, Val Acc: 0.773196\n",
      "Epoch 16387 - Train Loss: 0.091564, Train Acc: 0.866667 | Val Loss: 0.116374, Val Acc: 0.773196\n",
      "Epoch 16388 - Train Loss: 0.091561, Train Acc: 0.866667 | Val Loss: 0.116372, Val Acc: 0.773196\n",
      "Epoch 16389 - Train Loss: 0.091557, Train Acc: 0.866667 | Val Loss: 0.116370, Val Acc: 0.773196\n",
      "Epoch 16390 - Train Loss: 0.091554, Train Acc: 0.866667 | Val Loss: 0.116368, Val Acc: 0.773196\n",
      "Epoch 16391 - Train Loss: 0.091550, Train Acc: 0.866667 | Val Loss: 0.116366, Val Acc: 0.773196\n",
      "Epoch 16392 - Train Loss: 0.091547, Train Acc: 0.866667 | Val Loss: 0.116364, Val Acc: 0.773196\n",
      "Epoch 16393 - Train Loss: 0.091544, Train Acc: 0.866667 | Val Loss: 0.116362, Val Acc: 0.773196\n",
      "Epoch 16394 - Train Loss: 0.091540, Train Acc: 0.866667 | Val Loss: 0.116360, Val Acc: 0.773196\n",
      "Epoch 16395 - Train Loss: 0.091537, Train Acc: 0.866667 | Val Loss: 0.116357, Val Acc: 0.773196\n",
      "Epoch 16396 - Train Loss: 0.091533, Train Acc: 0.866667 | Val Loss: 0.116355, Val Acc: 0.773196\n",
      "Epoch 16397 - Train Loss: 0.091530, Train Acc: 0.866667 | Val Loss: 0.116353, Val Acc: 0.773196\n",
      "Epoch 16398 - Train Loss: 0.091526, Train Acc: 0.866667 | Val Loss: 0.116351, Val Acc: 0.773196\n",
      "Epoch 16399 - Train Loss: 0.091523, Train Acc: 0.866667 | Val Loss: 0.116349, Val Acc: 0.773196\n",
      "Epoch 16400 - Train Loss: 0.091519, Train Acc: 0.866667 | Val Loss: 0.116347, Val Acc: 0.773196\n",
      "Epoch 16401 - Train Loss: 0.091516, Train Acc: 0.866667 | Val Loss: 0.116345, Val Acc: 0.773196\n",
      "Epoch 16402 - Train Loss: 0.091513, Train Acc: 0.866667 | Val Loss: 0.116343, Val Acc: 0.773196\n",
      "Epoch 16403 - Train Loss: 0.091509, Train Acc: 0.866667 | Val Loss: 0.116341, Val Acc: 0.773196\n",
      "Epoch 16404 - Train Loss: 0.091506, Train Acc: 0.866667 | Val Loss: 0.116339, Val Acc: 0.773196\n",
      "Epoch 16405 - Train Loss: 0.091502, Train Acc: 0.866667 | Val Loss: 0.116337, Val Acc: 0.773196\n",
      "Epoch 16406 - Train Loss: 0.091499, Train Acc: 0.866667 | Val Loss: 0.116335, Val Acc: 0.773196\n",
      "Epoch 16407 - Train Loss: 0.091495, Train Acc: 0.866667 | Val Loss: 0.116333, Val Acc: 0.773196\n",
      "Epoch 16408 - Train Loss: 0.091492, Train Acc: 0.866667 | Val Loss: 0.116330, Val Acc: 0.773196\n",
      "Epoch 16409 - Train Loss: 0.091488, Train Acc: 0.866667 | Val Loss: 0.116328, Val Acc: 0.773196\n",
      "Epoch 16410 - Train Loss: 0.091485, Train Acc: 0.866667 | Val Loss: 0.116326, Val Acc: 0.773196\n",
      "Epoch 16411 - Train Loss: 0.091482, Train Acc: 0.866667 | Val Loss: 0.116324, Val Acc: 0.773196\n",
      "Epoch 16412 - Train Loss: 0.091478, Train Acc: 0.866667 | Val Loss: 0.116322, Val Acc: 0.773196\n",
      "Epoch 16413 - Train Loss: 0.091475, Train Acc: 0.866667 | Val Loss: 0.116320, Val Acc: 0.773196\n",
      "Epoch 16414 - Train Loss: 0.091471, Train Acc: 0.866667 | Val Loss: 0.116318, Val Acc: 0.773196\n",
      "Epoch 16415 - Train Loss: 0.091468, Train Acc: 0.866667 | Val Loss: 0.116316, Val Acc: 0.773196\n",
      "Epoch 16416 - Train Loss: 0.091464, Train Acc: 0.866667 | Val Loss: 0.116314, Val Acc: 0.773196\n",
      "Epoch 16417 - Train Loss: 0.091461, Train Acc: 0.866667 | Val Loss: 0.116312, Val Acc: 0.773196\n",
      "Epoch 16418 - Train Loss: 0.091458, Train Acc: 0.866667 | Val Loss: 0.116310, Val Acc: 0.773196\n",
      "Epoch 16419 - Train Loss: 0.091454, Train Acc: 0.866667 | Val Loss: 0.116308, Val Acc: 0.773196\n",
      "Epoch 16420 - Train Loss: 0.091451, Train Acc: 0.866667 | Val Loss: 0.116306, Val Acc: 0.773196\n",
      "Epoch 16421 - Train Loss: 0.091447, Train Acc: 0.866667 | Val Loss: 0.116303, Val Acc: 0.773196\n",
      "Epoch 16422 - Train Loss: 0.091444, Train Acc: 0.866667 | Val Loss: 0.116301, Val Acc: 0.773196\n",
      "Epoch 16423 - Train Loss: 0.091440, Train Acc: 0.866667 | Val Loss: 0.116299, Val Acc: 0.773196\n",
      "Epoch 16424 - Train Loss: 0.091437, Train Acc: 0.866667 | Val Loss: 0.116297, Val Acc: 0.773196\n",
      "Epoch 16425 - Train Loss: 0.091433, Train Acc: 0.866667 | Val Loss: 0.116295, Val Acc: 0.773196\n",
      "Epoch 16426 - Train Loss: 0.091430, Train Acc: 0.866667 | Val Loss: 0.116293, Val Acc: 0.773196\n",
      "Epoch 16427 - Train Loss: 0.091427, Train Acc: 0.866667 | Val Loss: 0.116291, Val Acc: 0.773196\n",
      "Epoch 16428 - Train Loss: 0.091423, Train Acc: 0.866667 | Val Loss: 0.116289, Val Acc: 0.773196\n",
      "Epoch 16429 - Train Loss: 0.091420, Train Acc: 0.866667 | Val Loss: 0.116287, Val Acc: 0.773196\n",
      "Epoch 16430 - Train Loss: 0.091416, Train Acc: 0.866667 | Val Loss: 0.116285, Val Acc: 0.773196\n",
      "Epoch 16431 - Train Loss: 0.091413, Train Acc: 0.866667 | Val Loss: 0.116283, Val Acc: 0.773196\n",
      "Epoch 16432 - Train Loss: 0.091409, Train Acc: 0.866667 | Val Loss: 0.116281, Val Acc: 0.773196\n",
      "Epoch 16433 - Train Loss: 0.091406, Train Acc: 0.866667 | Val Loss: 0.116279, Val Acc: 0.773196\n",
      "Epoch 16434 - Train Loss: 0.091403, Train Acc: 0.866667 | Val Loss: 0.116277, Val Acc: 0.773196\n",
      "Epoch 16435 - Train Loss: 0.091399, Train Acc: 0.866667 | Val Loss: 0.116275, Val Acc: 0.773196\n",
      "Epoch 16436 - Train Loss: 0.091396, Train Acc: 0.866667 | Val Loss: 0.116272, Val Acc: 0.773196\n",
      "Epoch 16437 - Train Loss: 0.091392, Train Acc: 0.866667 | Val Loss: 0.116270, Val Acc: 0.773196\n",
      "Epoch 16438 - Train Loss: 0.091389, Train Acc: 0.866667 | Val Loss: 0.116268, Val Acc: 0.773196\n",
      "Epoch 16439 - Train Loss: 0.091385, Train Acc: 0.866667 | Val Loss: 0.116266, Val Acc: 0.773196\n",
      "Epoch 16440 - Train Loss: 0.091382, Train Acc: 0.866667 | Val Loss: 0.116264, Val Acc: 0.773196\n",
      "Epoch 16441 - Train Loss: 0.091379, Train Acc: 0.866667 | Val Loss: 0.116262, Val Acc: 0.773196\n",
      "Epoch 16442 - Train Loss: 0.091375, Train Acc: 0.866667 | Val Loss: 0.116260, Val Acc: 0.773196\n",
      "Epoch 16443 - Train Loss: 0.091372, Train Acc: 0.867949 | Val Loss: 0.116258, Val Acc: 0.773196\n",
      "Epoch 16444 - Train Loss: 0.091368, Train Acc: 0.867949 | Val Loss: 0.116256, Val Acc: 0.773196\n",
      "Epoch 16445 - Train Loss: 0.091365, Train Acc: 0.867949 | Val Loss: 0.116254, Val Acc: 0.773196\n",
      "Epoch 16446 - Train Loss: 0.091361, Train Acc: 0.867949 | Val Loss: 0.116252, Val Acc: 0.773196\n",
      "Epoch 16447 - Train Loss: 0.091358, Train Acc: 0.867949 | Val Loss: 0.116250, Val Acc: 0.773196\n",
      "Epoch 16448 - Train Loss: 0.091355, Train Acc: 0.867949 | Val Loss: 0.116248, Val Acc: 0.773196\n",
      "Epoch 16449 - Train Loss: 0.091351, Train Acc: 0.867949 | Val Loss: 0.116246, Val Acc: 0.773196\n",
      "Epoch 16450 - Train Loss: 0.091348, Train Acc: 0.867949 | Val Loss: 0.116244, Val Acc: 0.773196\n",
      "Epoch 16451 - Train Loss: 0.091344, Train Acc: 0.867949 | Val Loss: 0.116242, Val Acc: 0.773196\n",
      "Epoch 16452 - Train Loss: 0.091341, Train Acc: 0.867949 | Val Loss: 0.116240, Val Acc: 0.773196\n",
      "Epoch 16453 - Train Loss: 0.091338, Train Acc: 0.867949 | Val Loss: 0.116237, Val Acc: 0.773196\n",
      "Epoch 16454 - Train Loss: 0.091334, Train Acc: 0.867949 | Val Loss: 0.116235, Val Acc: 0.773196\n",
      "Epoch 16455 - Train Loss: 0.091331, Train Acc: 0.867949 | Val Loss: 0.116233, Val Acc: 0.773196\n",
      "Epoch 16456 - Train Loss: 0.091327, Train Acc: 0.867949 | Val Loss: 0.116231, Val Acc: 0.773196\n",
      "Epoch 16457 - Train Loss: 0.091324, Train Acc: 0.867949 | Val Loss: 0.116229, Val Acc: 0.773196\n",
      "Epoch 16458 - Train Loss: 0.091320, Train Acc: 0.867949 | Val Loss: 0.116227, Val Acc: 0.773196\n",
      "Epoch 16459 - Train Loss: 0.091317, Train Acc: 0.867949 | Val Loss: 0.116225, Val Acc: 0.773196\n",
      "Epoch 16460 - Train Loss: 0.091314, Train Acc: 0.867949 | Val Loss: 0.116223, Val Acc: 0.773196\n",
      "Epoch 16461 - Train Loss: 0.091310, Train Acc: 0.867949 | Val Loss: 0.116221, Val Acc: 0.773196\n",
      "Epoch 16462 - Train Loss: 0.091307, Train Acc: 0.867949 | Val Loss: 0.116219, Val Acc: 0.773196\n",
      "Epoch 16463 - Train Loss: 0.091303, Train Acc: 0.867949 | Val Loss: 0.116217, Val Acc: 0.773196\n",
      "Epoch 16464 - Train Loss: 0.091300, Train Acc: 0.867949 | Val Loss: 0.116215, Val Acc: 0.773196\n",
      "Epoch 16465 - Train Loss: 0.091296, Train Acc: 0.867949 | Val Loss: 0.116213, Val Acc: 0.773196\n",
      "Epoch 16466 - Train Loss: 0.091293, Train Acc: 0.867949 | Val Loss: 0.116211, Val Acc: 0.773196\n",
      "Epoch 16467 - Train Loss: 0.091290, Train Acc: 0.867949 | Val Loss: 0.116209, Val Acc: 0.773196\n",
      "Epoch 16468 - Train Loss: 0.091286, Train Acc: 0.867949 | Val Loss: 0.116207, Val Acc: 0.773196\n",
      "Epoch 16469 - Train Loss: 0.091283, Train Acc: 0.867949 | Val Loss: 0.116205, Val Acc: 0.773196\n",
      "Epoch 16470 - Train Loss: 0.091279, Train Acc: 0.867949 | Val Loss: 0.116203, Val Acc: 0.773196\n",
      "Epoch 16471 - Train Loss: 0.091276, Train Acc: 0.867949 | Val Loss: 0.116200, Val Acc: 0.773196\n",
      "Epoch 16472 - Train Loss: 0.091273, Train Acc: 0.867949 | Val Loss: 0.116198, Val Acc: 0.773196\n",
      "Epoch 16473 - Train Loss: 0.091269, Train Acc: 0.867949 | Val Loss: 0.116196, Val Acc: 0.773196\n",
      "Epoch 16474 - Train Loss: 0.091266, Train Acc: 0.867949 | Val Loss: 0.116194, Val Acc: 0.773196\n",
      "Epoch 16475 - Train Loss: 0.091262, Train Acc: 0.867949 | Val Loss: 0.116192, Val Acc: 0.773196\n",
      "Epoch 16476 - Train Loss: 0.091259, Train Acc: 0.867949 | Val Loss: 0.116190, Val Acc: 0.773196\n",
      "Epoch 16477 - Train Loss: 0.091256, Train Acc: 0.867949 | Val Loss: 0.116188, Val Acc: 0.773196\n",
      "Epoch 16478 - Train Loss: 0.091252, Train Acc: 0.867949 | Val Loss: 0.116186, Val Acc: 0.773196\n",
      "Epoch 16479 - Train Loss: 0.091249, Train Acc: 0.867949 | Val Loss: 0.116184, Val Acc: 0.773196\n",
      "Epoch 16480 - Train Loss: 0.091245, Train Acc: 0.867949 | Val Loss: 0.116182, Val Acc: 0.773196\n",
      "Epoch 16481 - Train Loss: 0.091242, Train Acc: 0.867949 | Val Loss: 0.116180, Val Acc: 0.773196\n",
      "Epoch 16482 - Train Loss: 0.091238, Train Acc: 0.867949 | Val Loss: 0.116178, Val Acc: 0.773196\n",
      "Epoch 16483 - Train Loss: 0.091235, Train Acc: 0.867949 | Val Loss: 0.116176, Val Acc: 0.773196\n",
      "Epoch 16484 - Train Loss: 0.091232, Train Acc: 0.867949 | Val Loss: 0.116174, Val Acc: 0.773196\n",
      "Epoch 16485 - Train Loss: 0.091228, Train Acc: 0.867949 | Val Loss: 0.116172, Val Acc: 0.773196\n",
      "Epoch 16486 - Train Loss: 0.091225, Train Acc: 0.867949 | Val Loss: 0.116170, Val Acc: 0.773196\n",
      "Epoch 16487 - Train Loss: 0.091221, Train Acc: 0.867949 | Val Loss: 0.116168, Val Acc: 0.773196\n",
      "Epoch 16488 - Train Loss: 0.091218, Train Acc: 0.867949 | Val Loss: 0.116166, Val Acc: 0.773196\n",
      "Epoch 16489 - Train Loss: 0.091215, Train Acc: 0.867949 | Val Loss: 0.116164, Val Acc: 0.773196\n",
      "Epoch 16490 - Train Loss: 0.091211, Train Acc: 0.867949 | Val Loss: 0.116162, Val Acc: 0.773196\n",
      "Epoch 16491 - Train Loss: 0.091208, Train Acc: 0.867949 | Val Loss: 0.116160, Val Acc: 0.773196\n",
      "Epoch 16492 - Train Loss: 0.091204, Train Acc: 0.867949 | Val Loss: 0.116158, Val Acc: 0.773196\n",
      "Epoch 16493 - Train Loss: 0.091201, Train Acc: 0.867949 | Val Loss: 0.116155, Val Acc: 0.773196\n",
      "Epoch 16494 - Train Loss: 0.091198, Train Acc: 0.867949 | Val Loss: 0.116153, Val Acc: 0.773196\n",
      "Epoch 16495 - Train Loss: 0.091194, Train Acc: 0.867949 | Val Loss: 0.116151, Val Acc: 0.773196\n",
      "Epoch 16496 - Train Loss: 0.091191, Train Acc: 0.867949 | Val Loss: 0.116149, Val Acc: 0.773196\n",
      "Epoch 16497 - Train Loss: 0.091187, Train Acc: 0.867949 | Val Loss: 0.116147, Val Acc: 0.773196\n",
      "Epoch 16498 - Train Loss: 0.091184, Train Acc: 0.867949 | Val Loss: 0.116145, Val Acc: 0.773196\n",
      "Epoch 16499 - Train Loss: 0.091181, Train Acc: 0.867949 | Val Loss: 0.116143, Val Acc: 0.773196\n",
      "Epoch 16500 - Train Loss: 0.091177, Train Acc: 0.867949 | Val Loss: 0.116141, Val Acc: 0.773196\n",
      "Epoch 16501 - Train Loss: 0.091174, Train Acc: 0.867949 | Val Loss: 0.116139, Val Acc: 0.773196\n",
      "Epoch 16502 - Train Loss: 0.091170, Train Acc: 0.867949 | Val Loss: 0.116137, Val Acc: 0.773196\n",
      "Epoch 16503 - Train Loss: 0.091167, Train Acc: 0.867949 | Val Loss: 0.116135, Val Acc: 0.773196\n",
      "Epoch 16504 - Train Loss: 0.091164, Train Acc: 0.867949 | Val Loss: 0.116133, Val Acc: 0.773196\n",
      "Epoch 16505 - Train Loss: 0.091160, Train Acc: 0.867949 | Val Loss: 0.116131, Val Acc: 0.773196\n",
      "Epoch 16506 - Train Loss: 0.091157, Train Acc: 0.867949 | Val Loss: 0.116129, Val Acc: 0.773196\n",
      "Epoch 16507 - Train Loss: 0.091153, Train Acc: 0.867949 | Val Loss: 0.116127, Val Acc: 0.773196\n",
      "Epoch 16508 - Train Loss: 0.091150, Train Acc: 0.867949 | Val Loss: 0.116125, Val Acc: 0.773196\n",
      "Epoch 16509 - Train Loss: 0.091147, Train Acc: 0.867949 | Val Loss: 0.116123, Val Acc: 0.773196\n",
      "Epoch 16510 - Train Loss: 0.091143, Train Acc: 0.867949 | Val Loss: 0.116121, Val Acc: 0.773196\n",
      "Epoch 16511 - Train Loss: 0.091140, Train Acc: 0.867949 | Val Loss: 0.116119, Val Acc: 0.773196\n",
      "Epoch 16512 - Train Loss: 0.091136, Train Acc: 0.867949 | Val Loss: 0.116117, Val Acc: 0.773196\n",
      "Epoch 16513 - Train Loss: 0.091133, Train Acc: 0.867949 | Val Loss: 0.116115, Val Acc: 0.773196\n",
      "Epoch 16514 - Train Loss: 0.091130, Train Acc: 0.867949 | Val Loss: 0.116113, Val Acc: 0.773196\n",
      "Epoch 16515 - Train Loss: 0.091126, Train Acc: 0.867949 | Val Loss: 0.116111, Val Acc: 0.773196\n",
      "Epoch 16516 - Train Loss: 0.091123, Train Acc: 0.867949 | Val Loss: 0.116109, Val Acc: 0.773196\n",
      "Epoch 16517 - Train Loss: 0.091119, Train Acc: 0.867949 | Val Loss: 0.116107, Val Acc: 0.773196\n",
      "Epoch 16518 - Train Loss: 0.091116, Train Acc: 0.867949 | Val Loss: 0.116105, Val Acc: 0.773196\n",
      "Epoch 16519 - Train Loss: 0.091113, Train Acc: 0.867949 | Val Loss: 0.116103, Val Acc: 0.773196\n",
      "Epoch 16520 - Train Loss: 0.091109, Train Acc: 0.867949 | Val Loss: 0.116101, Val Acc: 0.773196\n",
      "Epoch 16521 - Train Loss: 0.091106, Train Acc: 0.867949 | Val Loss: 0.116099, Val Acc: 0.773196\n",
      "Epoch 16522 - Train Loss: 0.091102, Train Acc: 0.867949 | Val Loss: 0.116096, Val Acc: 0.773196\n",
      "Epoch 16523 - Train Loss: 0.091099, Train Acc: 0.867949 | Val Loss: 0.116094, Val Acc: 0.773196\n",
      "Epoch 16524 - Train Loss: 0.091096, Train Acc: 0.867949 | Val Loss: 0.116092, Val Acc: 0.773196\n",
      "Epoch 16525 - Train Loss: 0.091092, Train Acc: 0.867949 | Val Loss: 0.116090, Val Acc: 0.773196\n",
      "Epoch 16526 - Train Loss: 0.091089, Train Acc: 0.867949 | Val Loss: 0.116088, Val Acc: 0.773196\n",
      "Epoch 16527 - Train Loss: 0.091086, Train Acc: 0.867949 | Val Loss: 0.116086, Val Acc: 0.773196\n",
      "Epoch 16528 - Train Loss: 0.091082, Train Acc: 0.867949 | Val Loss: 0.116084, Val Acc: 0.773196\n",
      "Epoch 16529 - Train Loss: 0.091079, Train Acc: 0.867949 | Val Loss: 0.116082, Val Acc: 0.773196\n",
      "Epoch 16530 - Train Loss: 0.091075, Train Acc: 0.867949 | Val Loss: 0.116080, Val Acc: 0.773196\n",
      "Epoch 16531 - Train Loss: 0.091072, Train Acc: 0.867949 | Val Loss: 0.116078, Val Acc: 0.773196\n",
      "Epoch 16532 - Train Loss: 0.091069, Train Acc: 0.867949 | Val Loss: 0.116076, Val Acc: 0.773196\n",
      "Epoch 16533 - Train Loss: 0.091065, Train Acc: 0.867949 | Val Loss: 0.116074, Val Acc: 0.773196\n",
      "Epoch 16534 - Train Loss: 0.091062, Train Acc: 0.867949 | Val Loss: 0.116072, Val Acc: 0.773196\n",
      "Epoch 16535 - Train Loss: 0.091058, Train Acc: 0.867949 | Val Loss: 0.116070, Val Acc: 0.773196\n",
      "Epoch 16536 - Train Loss: 0.091055, Train Acc: 0.867949 | Val Loss: 0.116068, Val Acc: 0.773196\n",
      "Epoch 16537 - Train Loss: 0.091052, Train Acc: 0.867949 | Val Loss: 0.116066, Val Acc: 0.773196\n",
      "Epoch 16538 - Train Loss: 0.091048, Train Acc: 0.867949 | Val Loss: 0.116064, Val Acc: 0.773196\n",
      "Epoch 16539 - Train Loss: 0.091045, Train Acc: 0.867949 | Val Loss: 0.116062, Val Acc: 0.773196\n",
      "Epoch 16540 - Train Loss: 0.091041, Train Acc: 0.867949 | Val Loss: 0.116060, Val Acc: 0.773196\n",
      "Epoch 16541 - Train Loss: 0.091038, Train Acc: 0.867949 | Val Loss: 0.116058, Val Acc: 0.773196\n",
      "Epoch 16542 - Train Loss: 0.091035, Train Acc: 0.867949 | Val Loss: 0.116056, Val Acc: 0.773196\n",
      "Epoch 16543 - Train Loss: 0.091031, Train Acc: 0.867949 | Val Loss: 0.116054, Val Acc: 0.773196\n",
      "Epoch 16544 - Train Loss: 0.091028, Train Acc: 0.867949 | Val Loss: 0.116052, Val Acc: 0.773196\n",
      "Epoch 16545 - Train Loss: 0.091025, Train Acc: 0.867949 | Val Loss: 0.116050, Val Acc: 0.773196\n",
      "Epoch 16546 - Train Loss: 0.091021, Train Acc: 0.867949 | Val Loss: 0.116048, Val Acc: 0.773196\n",
      "Epoch 16547 - Train Loss: 0.091018, Train Acc: 0.867949 | Val Loss: 0.116046, Val Acc: 0.773196\n",
      "Epoch 16548 - Train Loss: 0.091014, Train Acc: 0.867949 | Val Loss: 0.116044, Val Acc: 0.773196\n",
      "Epoch 16549 - Train Loss: 0.091011, Train Acc: 0.867949 | Val Loss: 0.116042, Val Acc: 0.773196\n",
      "Epoch 16550 - Train Loss: 0.091008, Train Acc: 0.867949 | Val Loss: 0.116040, Val Acc: 0.773196\n",
      "Epoch 16551 - Train Loss: 0.091004, Train Acc: 0.867949 | Val Loss: 0.116038, Val Acc: 0.773196\n",
      "Epoch 16552 - Train Loss: 0.091001, Train Acc: 0.867949 | Val Loss: 0.116036, Val Acc: 0.773196\n",
      "Epoch 16553 - Train Loss: 0.090998, Train Acc: 0.867949 | Val Loss: 0.116034, Val Acc: 0.773196\n",
      "Epoch 16554 - Train Loss: 0.090994, Train Acc: 0.867949 | Val Loss: 0.116032, Val Acc: 0.773196\n",
      "Epoch 16555 - Train Loss: 0.090991, Train Acc: 0.867949 | Val Loss: 0.116030, Val Acc: 0.773196\n",
      "Epoch 16556 - Train Loss: 0.090987, Train Acc: 0.867949 | Val Loss: 0.116028, Val Acc: 0.773196\n",
      "Epoch 16557 - Train Loss: 0.090984, Train Acc: 0.867949 | Val Loss: 0.116026, Val Acc: 0.773196\n",
      "Epoch 16558 - Train Loss: 0.090981, Train Acc: 0.867949 | Val Loss: 0.116024, Val Acc: 0.773196\n",
      "Epoch 16559 - Train Loss: 0.090977, Train Acc: 0.867949 | Val Loss: 0.116022, Val Acc: 0.773196\n",
      "Epoch 16560 - Train Loss: 0.090974, Train Acc: 0.867949 | Val Loss: 0.116020, Val Acc: 0.773196\n",
      "Epoch 16561 - Train Loss: 0.090971, Train Acc: 0.867949 | Val Loss: 0.116018, Val Acc: 0.773196\n",
      "Epoch 16562 - Train Loss: 0.090967, Train Acc: 0.867949 | Val Loss: 0.116016, Val Acc: 0.773196\n",
      "Epoch 16563 - Train Loss: 0.090964, Train Acc: 0.867949 | Val Loss: 0.116013, Val Acc: 0.773196\n",
      "Epoch 16564 - Train Loss: 0.090960, Train Acc: 0.867949 | Val Loss: 0.116011, Val Acc: 0.773196\n",
      "Epoch 16565 - Train Loss: 0.090957, Train Acc: 0.867949 | Val Loss: 0.116009, Val Acc: 0.773196\n",
      "Epoch 16566 - Train Loss: 0.090954, Train Acc: 0.867949 | Val Loss: 0.116007, Val Acc: 0.773196\n",
      "Epoch 16567 - Train Loss: 0.090950, Train Acc: 0.867949 | Val Loss: 0.116005, Val Acc: 0.773196\n",
      "Epoch 16568 - Train Loss: 0.090947, Train Acc: 0.867949 | Val Loss: 0.116003, Val Acc: 0.773196\n",
      "Epoch 16569 - Train Loss: 0.090944, Train Acc: 0.867949 | Val Loss: 0.116001, Val Acc: 0.773196\n",
      "Epoch 16570 - Train Loss: 0.090940, Train Acc: 0.867949 | Val Loss: 0.115999, Val Acc: 0.773196\n",
      "Epoch 16571 - Train Loss: 0.090937, Train Acc: 0.867949 | Val Loss: 0.115997, Val Acc: 0.773196\n",
      "Epoch 16572 - Train Loss: 0.090933, Train Acc: 0.867949 | Val Loss: 0.115995, Val Acc: 0.773196\n",
      "Epoch 16573 - Train Loss: 0.090930, Train Acc: 0.867949 | Val Loss: 0.115993, Val Acc: 0.773196\n",
      "Epoch 16574 - Train Loss: 0.090927, Train Acc: 0.867949 | Val Loss: 0.115991, Val Acc: 0.773196\n",
      "Epoch 16575 - Train Loss: 0.090923, Train Acc: 0.867949 | Val Loss: 0.115989, Val Acc: 0.773196\n",
      "Epoch 16576 - Train Loss: 0.090920, Train Acc: 0.867949 | Val Loss: 0.115987, Val Acc: 0.773196\n",
      "Epoch 16577 - Train Loss: 0.090917, Train Acc: 0.867949 | Val Loss: 0.115985, Val Acc: 0.773196\n",
      "Epoch 16578 - Train Loss: 0.090913, Train Acc: 0.867949 | Val Loss: 0.115983, Val Acc: 0.773196\n",
      "Epoch 16579 - Train Loss: 0.090910, Train Acc: 0.867949 | Val Loss: 0.115981, Val Acc: 0.773196\n",
      "Epoch 16580 - Train Loss: 0.090906, Train Acc: 0.867949 | Val Loss: 0.115979, Val Acc: 0.773196\n",
      "Epoch 16581 - Train Loss: 0.090903, Train Acc: 0.867949 | Val Loss: 0.115977, Val Acc: 0.773196\n",
      "Epoch 16582 - Train Loss: 0.090900, Train Acc: 0.867949 | Val Loss: 0.115975, Val Acc: 0.773196\n",
      "Epoch 16583 - Train Loss: 0.090896, Train Acc: 0.867949 | Val Loss: 0.115973, Val Acc: 0.773196\n",
      "Epoch 16584 - Train Loss: 0.090893, Train Acc: 0.867949 | Val Loss: 0.115971, Val Acc: 0.773196\n",
      "Epoch 16585 - Train Loss: 0.090890, Train Acc: 0.867949 | Val Loss: 0.115969, Val Acc: 0.773196\n",
      "Epoch 16586 - Train Loss: 0.090886, Train Acc: 0.867949 | Val Loss: 0.115967, Val Acc: 0.773196\n",
      "Epoch 16587 - Train Loss: 0.090883, Train Acc: 0.867949 | Val Loss: 0.115965, Val Acc: 0.773196\n",
      "Epoch 16588 - Train Loss: 0.090880, Train Acc: 0.867949 | Val Loss: 0.115963, Val Acc: 0.773196\n",
      "Epoch 16589 - Train Loss: 0.090876, Train Acc: 0.867949 | Val Loss: 0.115961, Val Acc: 0.773196\n",
      "Epoch 16590 - Train Loss: 0.090873, Train Acc: 0.867949 | Val Loss: 0.115959, Val Acc: 0.773196\n",
      "Epoch 16591 - Train Loss: 0.090869, Train Acc: 0.867949 | Val Loss: 0.115957, Val Acc: 0.773196\n",
      "Epoch 16592 - Train Loss: 0.090866, Train Acc: 0.867949 | Val Loss: 0.115955, Val Acc: 0.773196\n",
      "Epoch 16593 - Train Loss: 0.090863, Train Acc: 0.867949 | Val Loss: 0.115953, Val Acc: 0.773196\n",
      "Epoch 16594 - Train Loss: 0.090859, Train Acc: 0.867949 | Val Loss: 0.115951, Val Acc: 0.773196\n",
      "Epoch 16595 - Train Loss: 0.090856, Train Acc: 0.867949 | Val Loss: 0.115949, Val Acc: 0.773196\n",
      "Epoch 16596 - Train Loss: 0.090853, Train Acc: 0.867949 | Val Loss: 0.115947, Val Acc: 0.773196\n",
      "Epoch 16597 - Train Loss: 0.090849, Train Acc: 0.867949 | Val Loss: 0.115945, Val Acc: 0.773196\n",
      "Epoch 16598 - Train Loss: 0.090846, Train Acc: 0.867949 | Val Loss: 0.115943, Val Acc: 0.773196\n",
      "Epoch 16599 - Train Loss: 0.090843, Train Acc: 0.867949 | Val Loss: 0.115941, Val Acc: 0.773196\n",
      "Epoch 16600 - Train Loss: 0.090839, Train Acc: 0.867949 | Val Loss: 0.115939, Val Acc: 0.783505\n",
      "Epoch 16601 - Train Loss: 0.090836, Train Acc: 0.867949 | Val Loss: 0.115937, Val Acc: 0.783505\n",
      "Epoch 16602 - Train Loss: 0.090833, Train Acc: 0.867949 | Val Loss: 0.115935, Val Acc: 0.783505\n",
      "Epoch 16603 - Train Loss: 0.090829, Train Acc: 0.867949 | Val Loss: 0.115933, Val Acc: 0.783505\n",
      "Epoch 16604 - Train Loss: 0.090826, Train Acc: 0.867949 | Val Loss: 0.115931, Val Acc: 0.783505\n",
      "Epoch 16605 - Train Loss: 0.090822, Train Acc: 0.867949 | Val Loss: 0.115929, Val Acc: 0.783505\n",
      "Epoch 16606 - Train Loss: 0.090819, Train Acc: 0.867949 | Val Loss: 0.115927, Val Acc: 0.783505\n",
      "Epoch 16607 - Train Loss: 0.090816, Train Acc: 0.867949 | Val Loss: 0.115925, Val Acc: 0.783505\n",
      "Epoch 16608 - Train Loss: 0.090812, Train Acc: 0.867949 | Val Loss: 0.115923, Val Acc: 0.783505\n",
      "Epoch 16609 - Train Loss: 0.090809, Train Acc: 0.867949 | Val Loss: 0.115921, Val Acc: 0.783505\n",
      "Epoch 16610 - Train Loss: 0.090806, Train Acc: 0.867949 | Val Loss: 0.115919, Val Acc: 0.783505\n",
      "Epoch 16611 - Train Loss: 0.090802, Train Acc: 0.867949 | Val Loss: 0.115917, Val Acc: 0.783505\n",
      "Epoch 16612 - Train Loss: 0.090799, Train Acc: 0.867949 | Val Loss: 0.115915, Val Acc: 0.783505\n",
      "Epoch 16613 - Train Loss: 0.090796, Train Acc: 0.867949 | Val Loss: 0.115913, Val Acc: 0.783505\n",
      "Epoch 16614 - Train Loss: 0.090792, Train Acc: 0.867949 | Val Loss: 0.115911, Val Acc: 0.783505\n",
      "Epoch 16615 - Train Loss: 0.090789, Train Acc: 0.867949 | Val Loss: 0.115909, Val Acc: 0.783505\n",
      "Epoch 16616 - Train Loss: 0.090786, Train Acc: 0.867949 | Val Loss: 0.115907, Val Acc: 0.783505\n",
      "Epoch 16617 - Train Loss: 0.090782, Train Acc: 0.867949 | Val Loss: 0.115905, Val Acc: 0.783505\n",
      "Epoch 16618 - Train Loss: 0.090779, Train Acc: 0.867949 | Val Loss: 0.115903, Val Acc: 0.783505\n",
      "Epoch 16619 - Train Loss: 0.090775, Train Acc: 0.867949 | Val Loss: 0.115901, Val Acc: 0.783505\n",
      "Epoch 16620 - Train Loss: 0.090772, Train Acc: 0.867949 | Val Loss: 0.115899, Val Acc: 0.783505\n",
      "Epoch 16621 - Train Loss: 0.090769, Train Acc: 0.867949 | Val Loss: 0.115897, Val Acc: 0.783505\n",
      "Epoch 16622 - Train Loss: 0.090765, Train Acc: 0.867949 | Val Loss: 0.115895, Val Acc: 0.783505\n",
      "Epoch 16623 - Train Loss: 0.090762, Train Acc: 0.867949 | Val Loss: 0.115893, Val Acc: 0.783505\n",
      "Epoch 16624 - Train Loss: 0.090759, Train Acc: 0.867949 | Val Loss: 0.115891, Val Acc: 0.783505\n",
      "Epoch 16625 - Train Loss: 0.090755, Train Acc: 0.867949 | Val Loss: 0.115889, Val Acc: 0.783505\n",
      "Epoch 16626 - Train Loss: 0.090752, Train Acc: 0.867949 | Val Loss: 0.115887, Val Acc: 0.783505\n",
      "Epoch 16627 - Train Loss: 0.090749, Train Acc: 0.867949 | Val Loss: 0.115885, Val Acc: 0.783505\n",
      "Epoch 16628 - Train Loss: 0.090745, Train Acc: 0.867949 | Val Loss: 0.115884, Val Acc: 0.783505\n",
      "Epoch 16629 - Train Loss: 0.090742, Train Acc: 0.867949 | Val Loss: 0.115882, Val Acc: 0.783505\n",
      "Epoch 16630 - Train Loss: 0.090739, Train Acc: 0.867949 | Val Loss: 0.115880, Val Acc: 0.783505\n",
      "Epoch 16631 - Train Loss: 0.090735, Train Acc: 0.867949 | Val Loss: 0.115878, Val Acc: 0.783505\n",
      "Epoch 16632 - Train Loss: 0.090732, Train Acc: 0.867949 | Val Loss: 0.115876, Val Acc: 0.783505\n",
      "Epoch 16633 - Train Loss: 0.090729, Train Acc: 0.867949 | Val Loss: 0.115874, Val Acc: 0.783505\n",
      "Epoch 16634 - Train Loss: 0.090725, Train Acc: 0.867949 | Val Loss: 0.115872, Val Acc: 0.783505\n",
      "Epoch 16635 - Train Loss: 0.090722, Train Acc: 0.867949 | Val Loss: 0.115870, Val Acc: 0.783505\n",
      "Epoch 16636 - Train Loss: 0.090719, Train Acc: 0.867949 | Val Loss: 0.115868, Val Acc: 0.783505\n",
      "Epoch 16637 - Train Loss: 0.090715, Train Acc: 0.867949 | Val Loss: 0.115866, Val Acc: 0.783505\n",
      "Epoch 16638 - Train Loss: 0.090712, Train Acc: 0.867949 | Val Loss: 0.115864, Val Acc: 0.783505\n",
      "Epoch 16639 - Train Loss: 0.090709, Train Acc: 0.867949 | Val Loss: 0.115862, Val Acc: 0.783505\n",
      "Epoch 16640 - Train Loss: 0.090705, Train Acc: 0.867949 | Val Loss: 0.115860, Val Acc: 0.783505\n",
      "Epoch 16641 - Train Loss: 0.090702, Train Acc: 0.867949 | Val Loss: 0.115858, Val Acc: 0.783505\n",
      "Epoch 16642 - Train Loss: 0.090699, Train Acc: 0.867949 | Val Loss: 0.115856, Val Acc: 0.783505\n",
      "Epoch 16643 - Train Loss: 0.090695, Train Acc: 0.867949 | Val Loss: 0.115854, Val Acc: 0.783505\n",
      "Epoch 16644 - Train Loss: 0.090692, Train Acc: 0.867949 | Val Loss: 0.115852, Val Acc: 0.783505\n",
      "Epoch 16645 - Train Loss: 0.090689, Train Acc: 0.867949 | Val Loss: 0.115850, Val Acc: 0.783505\n",
      "Epoch 16646 - Train Loss: 0.090685, Train Acc: 0.867949 | Val Loss: 0.115848, Val Acc: 0.783505\n",
      "Epoch 16647 - Train Loss: 0.090682, Train Acc: 0.867949 | Val Loss: 0.115846, Val Acc: 0.783505\n",
      "Epoch 16648 - Train Loss: 0.090678, Train Acc: 0.867949 | Val Loss: 0.115844, Val Acc: 0.783505\n",
      "Epoch 16649 - Train Loss: 0.090675, Train Acc: 0.867949 | Val Loss: 0.115842, Val Acc: 0.783505\n",
      "Epoch 16650 - Train Loss: 0.090672, Train Acc: 0.867949 | Val Loss: 0.115840, Val Acc: 0.783505\n",
      "Epoch 16651 - Train Loss: 0.090668, Train Acc: 0.867949 | Val Loss: 0.115838, Val Acc: 0.783505\n",
      "Epoch 16652 - Train Loss: 0.090665, Train Acc: 0.867949 | Val Loss: 0.115836, Val Acc: 0.783505\n",
      "Epoch 16653 - Train Loss: 0.090662, Train Acc: 0.867949 | Val Loss: 0.115834, Val Acc: 0.783505\n",
      "Epoch 16654 - Train Loss: 0.090658, Train Acc: 0.867949 | Val Loss: 0.115832, Val Acc: 0.783505\n",
      "Epoch 16655 - Train Loss: 0.090655, Train Acc: 0.867949 | Val Loss: 0.115830, Val Acc: 0.783505\n",
      "Epoch 16656 - Train Loss: 0.090652, Train Acc: 0.867949 | Val Loss: 0.115828, Val Acc: 0.783505\n",
      "Epoch 16657 - Train Loss: 0.090648, Train Acc: 0.867949 | Val Loss: 0.115826, Val Acc: 0.783505\n",
      "Epoch 16658 - Train Loss: 0.090645, Train Acc: 0.867949 | Val Loss: 0.115824, Val Acc: 0.783505\n",
      "Epoch 16659 - Train Loss: 0.090642, Train Acc: 0.867949 | Val Loss: 0.115822, Val Acc: 0.783505\n",
      "Epoch 16660 - Train Loss: 0.090638, Train Acc: 0.867949 | Val Loss: 0.115820, Val Acc: 0.783505\n",
      "Epoch 16661 - Train Loss: 0.090635, Train Acc: 0.867949 | Val Loss: 0.115818, Val Acc: 0.783505\n",
      "Epoch 16662 - Train Loss: 0.090632, Train Acc: 0.867949 | Val Loss: 0.115816, Val Acc: 0.783505\n",
      "Epoch 16663 - Train Loss: 0.090628, Train Acc: 0.867949 | Val Loss: 0.115814, Val Acc: 0.783505\n",
      "Epoch 16664 - Train Loss: 0.090625, Train Acc: 0.867949 | Val Loss: 0.115812, Val Acc: 0.783505\n",
      "Epoch 16665 - Train Loss: 0.090622, Train Acc: 0.867949 | Val Loss: 0.115810, Val Acc: 0.783505\n",
      "Epoch 16666 - Train Loss: 0.090618, Train Acc: 0.867949 | Val Loss: 0.115809, Val Acc: 0.783505\n",
      "Epoch 16667 - Train Loss: 0.090615, Train Acc: 0.867949 | Val Loss: 0.115807, Val Acc: 0.783505\n",
      "Epoch 16668 - Train Loss: 0.090612, Train Acc: 0.867949 | Val Loss: 0.115805, Val Acc: 0.783505\n",
      "Epoch 16669 - Train Loss: 0.090608, Train Acc: 0.867949 | Val Loss: 0.115803, Val Acc: 0.783505\n",
      "Epoch 16670 - Train Loss: 0.090605, Train Acc: 0.867949 | Val Loss: 0.115801, Val Acc: 0.783505\n",
      "Epoch 16671 - Train Loss: 0.090602, Train Acc: 0.867949 | Val Loss: 0.115799, Val Acc: 0.783505\n",
      "Epoch 16672 - Train Loss: 0.090598, Train Acc: 0.867949 | Val Loss: 0.115797, Val Acc: 0.783505\n",
      "Epoch 16673 - Train Loss: 0.090595, Train Acc: 0.867949 | Val Loss: 0.115795, Val Acc: 0.783505\n",
      "Epoch 16674 - Train Loss: 0.090592, Train Acc: 0.867949 | Val Loss: 0.115793, Val Acc: 0.783505\n",
      "Epoch 16675 - Train Loss: 0.090589, Train Acc: 0.867949 | Val Loss: 0.115791, Val Acc: 0.783505\n",
      "Epoch 16676 - Train Loss: 0.090585, Train Acc: 0.867949 | Val Loss: 0.115789, Val Acc: 0.783505\n",
      "Epoch 16677 - Train Loss: 0.090582, Train Acc: 0.867949 | Val Loss: 0.115787, Val Acc: 0.783505\n",
      "Epoch 16678 - Train Loss: 0.090579, Train Acc: 0.867949 | Val Loss: 0.115785, Val Acc: 0.783505\n",
      "Epoch 16679 - Train Loss: 0.090575, Train Acc: 0.867949 | Val Loss: 0.115783, Val Acc: 0.783505\n",
      "Epoch 16680 - Train Loss: 0.090572, Train Acc: 0.867949 | Val Loss: 0.115781, Val Acc: 0.783505\n",
      "Epoch 16681 - Train Loss: 0.090569, Train Acc: 0.867949 | Val Loss: 0.115779, Val Acc: 0.783505\n",
      "Epoch 16682 - Train Loss: 0.090565, Train Acc: 0.867949 | Val Loss: 0.115777, Val Acc: 0.783505\n",
      "Epoch 16683 - Train Loss: 0.090562, Train Acc: 0.867949 | Val Loss: 0.115775, Val Acc: 0.783505\n",
      "Epoch 16684 - Train Loss: 0.090559, Train Acc: 0.867949 | Val Loss: 0.115773, Val Acc: 0.783505\n",
      "Epoch 16685 - Train Loss: 0.090555, Train Acc: 0.867949 | Val Loss: 0.115771, Val Acc: 0.783505\n",
      "Epoch 16686 - Train Loss: 0.090552, Train Acc: 0.867949 | Val Loss: 0.115769, Val Acc: 0.783505\n",
      "Epoch 16687 - Train Loss: 0.090549, Train Acc: 0.867949 | Val Loss: 0.115767, Val Acc: 0.783505\n",
      "Epoch 16688 - Train Loss: 0.090545, Train Acc: 0.867949 | Val Loss: 0.115765, Val Acc: 0.783505\n",
      "Epoch 16689 - Train Loss: 0.090542, Train Acc: 0.867949 | Val Loss: 0.115763, Val Acc: 0.783505\n",
      "Epoch 16690 - Train Loss: 0.090539, Train Acc: 0.867949 | Val Loss: 0.115761, Val Acc: 0.783505\n",
      "Epoch 16691 - Train Loss: 0.090535, Train Acc: 0.867949 | Val Loss: 0.115760, Val Acc: 0.783505\n",
      "Epoch 16692 - Train Loss: 0.090532, Train Acc: 0.867949 | Val Loss: 0.115758, Val Acc: 0.783505\n",
      "Epoch 16693 - Train Loss: 0.090529, Train Acc: 0.867949 | Val Loss: 0.115756, Val Acc: 0.783505\n",
      "Epoch 16694 - Train Loss: 0.090525, Train Acc: 0.867949 | Val Loss: 0.115754, Val Acc: 0.783505\n",
      "Epoch 16695 - Train Loss: 0.090522, Train Acc: 0.867949 | Val Loss: 0.115752, Val Acc: 0.783505\n",
      "Epoch 16696 - Train Loss: 0.090519, Train Acc: 0.867949 | Val Loss: 0.115750, Val Acc: 0.783505\n",
      "Epoch 16697 - Train Loss: 0.090515, Train Acc: 0.867949 | Val Loss: 0.115748, Val Acc: 0.783505\n",
      "Epoch 16698 - Train Loss: 0.090512, Train Acc: 0.867949 | Val Loss: 0.115746, Val Acc: 0.783505\n",
      "Epoch 16699 - Train Loss: 0.090509, Train Acc: 0.867949 | Val Loss: 0.115744, Val Acc: 0.783505\n",
      "Epoch 16700 - Train Loss: 0.090505, Train Acc: 0.867949 | Val Loss: 0.115742, Val Acc: 0.783505\n",
      "Epoch 16701 - Train Loss: 0.090502, Train Acc: 0.867949 | Val Loss: 0.115740, Val Acc: 0.783505\n",
      "Epoch 16702 - Train Loss: 0.090499, Train Acc: 0.867949 | Val Loss: 0.115738, Val Acc: 0.783505\n",
      "Epoch 16703 - Train Loss: 0.090495, Train Acc: 0.867949 | Val Loss: 0.115736, Val Acc: 0.783505\n",
      "Epoch 16704 - Train Loss: 0.090492, Train Acc: 0.867949 | Val Loss: 0.115734, Val Acc: 0.783505\n",
      "Epoch 16705 - Train Loss: 0.090489, Train Acc: 0.867949 | Val Loss: 0.115732, Val Acc: 0.783505\n",
      "Epoch 16706 - Train Loss: 0.090486, Train Acc: 0.867949 | Val Loss: 0.115730, Val Acc: 0.783505\n",
      "Epoch 16707 - Train Loss: 0.090482, Train Acc: 0.867949 | Val Loss: 0.115728, Val Acc: 0.783505\n",
      "Epoch 16708 - Train Loss: 0.090479, Train Acc: 0.867949 | Val Loss: 0.115726, Val Acc: 0.783505\n",
      "Epoch 16709 - Train Loss: 0.090476, Train Acc: 0.867949 | Val Loss: 0.115724, Val Acc: 0.783505\n",
      "Epoch 16710 - Train Loss: 0.090472, Train Acc: 0.867949 | Val Loss: 0.115722, Val Acc: 0.783505\n",
      "Epoch 16711 - Train Loss: 0.090469, Train Acc: 0.867949 | Val Loss: 0.115720, Val Acc: 0.783505\n",
      "Epoch 16712 - Train Loss: 0.090466, Train Acc: 0.867949 | Val Loss: 0.115719, Val Acc: 0.783505\n",
      "Epoch 16713 - Train Loss: 0.090462, Train Acc: 0.867949 | Val Loss: 0.115717, Val Acc: 0.783505\n",
      "Epoch 16714 - Train Loss: 0.090459, Train Acc: 0.867949 | Val Loss: 0.115715, Val Acc: 0.783505\n",
      "Epoch 16715 - Train Loss: 0.090456, Train Acc: 0.867949 | Val Loss: 0.115713, Val Acc: 0.783505\n",
      "Epoch 16716 - Train Loss: 0.090452, Train Acc: 0.867949 | Val Loss: 0.115711, Val Acc: 0.783505\n",
      "Epoch 16717 - Train Loss: 0.090449, Train Acc: 0.867949 | Val Loss: 0.115709, Val Acc: 0.783505\n",
      "Epoch 16718 - Train Loss: 0.090446, Train Acc: 0.867949 | Val Loss: 0.115707, Val Acc: 0.783505\n",
      "Epoch 16719 - Train Loss: 0.090442, Train Acc: 0.867949 | Val Loss: 0.115705, Val Acc: 0.783505\n",
      "Epoch 16720 - Train Loss: 0.090439, Train Acc: 0.867949 | Val Loss: 0.115703, Val Acc: 0.783505\n",
      "Epoch 16721 - Train Loss: 0.090436, Train Acc: 0.867949 | Val Loss: 0.115701, Val Acc: 0.783505\n",
      "Epoch 16722 - Train Loss: 0.090433, Train Acc: 0.867949 | Val Loss: 0.115699, Val Acc: 0.783505\n",
      "Epoch 16723 - Train Loss: 0.090429, Train Acc: 0.867949 | Val Loss: 0.115697, Val Acc: 0.783505\n",
      "Epoch 16724 - Train Loss: 0.090426, Train Acc: 0.867949 | Val Loss: 0.115695, Val Acc: 0.783505\n",
      "Epoch 16725 - Train Loss: 0.090423, Train Acc: 0.867949 | Val Loss: 0.115693, Val Acc: 0.783505\n",
      "Epoch 16726 - Train Loss: 0.090419, Train Acc: 0.867949 | Val Loss: 0.115691, Val Acc: 0.783505\n",
      "Epoch 16727 - Train Loss: 0.090416, Train Acc: 0.867949 | Val Loss: 0.115689, Val Acc: 0.783505\n",
      "Epoch 16728 - Train Loss: 0.090413, Train Acc: 0.867949 | Val Loss: 0.115687, Val Acc: 0.783505\n",
      "Epoch 16729 - Train Loss: 0.090409, Train Acc: 0.867949 | Val Loss: 0.115685, Val Acc: 0.783505\n",
      "Epoch 16730 - Train Loss: 0.090406, Train Acc: 0.867949 | Val Loss: 0.115684, Val Acc: 0.783505\n",
      "Epoch 16731 - Train Loss: 0.090403, Train Acc: 0.867949 | Val Loss: 0.115682, Val Acc: 0.783505\n",
      "Epoch 16732 - Train Loss: 0.090399, Train Acc: 0.867949 | Val Loss: 0.115680, Val Acc: 0.783505\n",
      "Epoch 16733 - Train Loss: 0.090396, Train Acc: 0.867949 | Val Loss: 0.115678, Val Acc: 0.783505\n",
      "Epoch 16734 - Train Loss: 0.090393, Train Acc: 0.867949 | Val Loss: 0.115676, Val Acc: 0.783505\n",
      "Epoch 16735 - Train Loss: 0.090390, Train Acc: 0.867949 | Val Loss: 0.115674, Val Acc: 0.783505\n",
      "Epoch 16736 - Train Loss: 0.090386, Train Acc: 0.867949 | Val Loss: 0.115672, Val Acc: 0.783505\n",
      "Epoch 16737 - Train Loss: 0.090383, Train Acc: 0.867949 | Val Loss: 0.115670, Val Acc: 0.783505\n",
      "Epoch 16738 - Train Loss: 0.090380, Train Acc: 0.867949 | Val Loss: 0.115668, Val Acc: 0.783505\n",
      "Epoch 16739 - Train Loss: 0.090376, Train Acc: 0.867949 | Val Loss: 0.115666, Val Acc: 0.783505\n",
      "Epoch 16740 - Train Loss: 0.090373, Train Acc: 0.867949 | Val Loss: 0.115664, Val Acc: 0.783505\n",
      "Epoch 16741 - Train Loss: 0.090370, Train Acc: 0.867949 | Val Loss: 0.115662, Val Acc: 0.783505\n",
      "Epoch 16742 - Train Loss: 0.090366, Train Acc: 0.867949 | Val Loss: 0.115660, Val Acc: 0.783505\n",
      "Epoch 16743 - Train Loss: 0.090363, Train Acc: 0.867949 | Val Loss: 0.115658, Val Acc: 0.783505\n",
      "Epoch 16744 - Train Loss: 0.090360, Train Acc: 0.867949 | Val Loss: 0.115656, Val Acc: 0.783505\n",
      "Epoch 16745 - Train Loss: 0.090357, Train Acc: 0.867949 | Val Loss: 0.115655, Val Acc: 0.783505\n",
      "Epoch 16746 - Train Loss: 0.090353, Train Acc: 0.867949 | Val Loss: 0.115653, Val Acc: 0.783505\n",
      "Epoch 16747 - Train Loss: 0.090350, Train Acc: 0.867949 | Val Loss: 0.115651, Val Acc: 0.783505\n",
      "Epoch 16748 - Train Loss: 0.090347, Train Acc: 0.867949 | Val Loss: 0.115649, Val Acc: 0.783505\n",
      "Epoch 16749 - Train Loss: 0.090343, Train Acc: 0.867949 | Val Loss: 0.115647, Val Acc: 0.783505\n",
      "Epoch 16750 - Train Loss: 0.090340, Train Acc: 0.867949 | Val Loss: 0.115645, Val Acc: 0.783505\n",
      "Epoch 16751 - Train Loss: 0.090337, Train Acc: 0.867949 | Val Loss: 0.115643, Val Acc: 0.783505\n",
      "Epoch 16752 - Train Loss: 0.090333, Train Acc: 0.867949 | Val Loss: 0.115641, Val Acc: 0.783505\n",
      "Epoch 16753 - Train Loss: 0.090330, Train Acc: 0.867949 | Val Loss: 0.115639, Val Acc: 0.783505\n",
      "Epoch 16754 - Train Loss: 0.090327, Train Acc: 0.867949 | Val Loss: 0.115637, Val Acc: 0.783505\n",
      "Epoch 16755 - Train Loss: 0.090324, Train Acc: 0.867949 | Val Loss: 0.115635, Val Acc: 0.783505\n",
      "Epoch 16756 - Train Loss: 0.090320, Train Acc: 0.867949 | Val Loss: 0.115633, Val Acc: 0.783505\n",
      "Epoch 16757 - Train Loss: 0.090317, Train Acc: 0.867949 | Val Loss: 0.115631, Val Acc: 0.783505\n",
      "Epoch 16758 - Train Loss: 0.090314, Train Acc: 0.867949 | Val Loss: 0.115629, Val Acc: 0.783505\n",
      "Epoch 16759 - Train Loss: 0.090310, Train Acc: 0.867949 | Val Loss: 0.115627, Val Acc: 0.783505\n",
      "Epoch 16760 - Train Loss: 0.090307, Train Acc: 0.867949 | Val Loss: 0.115626, Val Acc: 0.783505\n",
      "Epoch 16761 - Train Loss: 0.090304, Train Acc: 0.867949 | Val Loss: 0.115624, Val Acc: 0.783505\n",
      "Epoch 16762 - Train Loss: 0.090301, Train Acc: 0.867949 | Val Loss: 0.115622, Val Acc: 0.783505\n",
      "Epoch 16763 - Train Loss: 0.090297, Train Acc: 0.867949 | Val Loss: 0.115620, Val Acc: 0.783505\n",
      "Epoch 16764 - Train Loss: 0.090294, Train Acc: 0.867949 | Val Loss: 0.115618, Val Acc: 0.783505\n",
      "Epoch 16765 - Train Loss: 0.090291, Train Acc: 0.867949 | Val Loss: 0.115616, Val Acc: 0.783505\n",
      "Epoch 16766 - Train Loss: 0.090287, Train Acc: 0.867949 | Val Loss: 0.115614, Val Acc: 0.783505\n",
      "Epoch 16767 - Train Loss: 0.090284, Train Acc: 0.867949 | Val Loss: 0.115612, Val Acc: 0.783505\n",
      "Epoch 16768 - Train Loss: 0.090281, Train Acc: 0.867949 | Val Loss: 0.115610, Val Acc: 0.783505\n",
      "Epoch 16769 - Train Loss: 0.090277, Train Acc: 0.867949 | Val Loss: 0.115608, Val Acc: 0.783505\n",
      "Epoch 16770 - Train Loss: 0.090274, Train Acc: 0.867949 | Val Loss: 0.115606, Val Acc: 0.783505\n",
      "Epoch 16771 - Train Loss: 0.090271, Train Acc: 0.867949 | Val Loss: 0.115604, Val Acc: 0.783505\n",
      "Epoch 16772 - Train Loss: 0.090268, Train Acc: 0.867949 | Val Loss: 0.115602, Val Acc: 0.783505\n",
      "Epoch 16773 - Train Loss: 0.090264, Train Acc: 0.867949 | Val Loss: 0.115601, Val Acc: 0.783505\n",
      "Epoch 16774 - Train Loss: 0.090261, Train Acc: 0.867949 | Val Loss: 0.115599, Val Acc: 0.783505\n",
      "Epoch 16775 - Train Loss: 0.090258, Train Acc: 0.867949 | Val Loss: 0.115597, Val Acc: 0.783505\n",
      "Epoch 16776 - Train Loss: 0.090254, Train Acc: 0.867949 | Val Loss: 0.115595, Val Acc: 0.783505\n",
      "Epoch 16777 - Train Loss: 0.090251, Train Acc: 0.867949 | Val Loss: 0.115593, Val Acc: 0.783505\n",
      "Epoch 16778 - Train Loss: 0.090248, Train Acc: 0.867949 | Val Loss: 0.115591, Val Acc: 0.783505\n",
      "Epoch 16779 - Train Loss: 0.090245, Train Acc: 0.867949 | Val Loss: 0.115589, Val Acc: 0.783505\n",
      "Epoch 16780 - Train Loss: 0.090241, Train Acc: 0.867949 | Val Loss: 0.115587, Val Acc: 0.783505\n",
      "Epoch 16781 - Train Loss: 0.090238, Train Acc: 0.867949 | Val Loss: 0.115585, Val Acc: 0.783505\n",
      "Epoch 16782 - Train Loss: 0.090235, Train Acc: 0.867949 | Val Loss: 0.115583, Val Acc: 0.783505\n",
      "Epoch 16783 - Train Loss: 0.090231, Train Acc: 0.867949 | Val Loss: 0.115581, Val Acc: 0.783505\n",
      "Epoch 16784 - Train Loss: 0.090228, Train Acc: 0.867949 | Val Loss: 0.115579, Val Acc: 0.783505\n",
      "Epoch 16785 - Train Loss: 0.090225, Train Acc: 0.867949 | Val Loss: 0.115578, Val Acc: 0.783505\n",
      "Epoch 16786 - Train Loss: 0.090222, Train Acc: 0.867949 | Val Loss: 0.115576, Val Acc: 0.783505\n",
      "Epoch 16787 - Train Loss: 0.090218, Train Acc: 0.867949 | Val Loss: 0.115574, Val Acc: 0.783505\n",
      "Epoch 16788 - Train Loss: 0.090215, Train Acc: 0.867949 | Val Loss: 0.115572, Val Acc: 0.783505\n",
      "Epoch 16789 - Train Loss: 0.090212, Train Acc: 0.867949 | Val Loss: 0.115570, Val Acc: 0.783505\n",
      "Epoch 16790 - Train Loss: 0.090208, Train Acc: 0.867949 | Val Loss: 0.115568, Val Acc: 0.783505\n",
      "Epoch 16791 - Train Loss: 0.090205, Train Acc: 0.867949 | Val Loss: 0.115566, Val Acc: 0.783505\n",
      "Epoch 16792 - Train Loss: 0.090202, Train Acc: 0.867949 | Val Loss: 0.115564, Val Acc: 0.783505\n",
      "Epoch 16793 - Train Loss: 0.090199, Train Acc: 0.867949 | Val Loss: 0.115562, Val Acc: 0.783505\n",
      "Epoch 16794 - Train Loss: 0.090195, Train Acc: 0.867949 | Val Loss: 0.115560, Val Acc: 0.783505\n",
      "Epoch 16795 - Train Loss: 0.090192, Train Acc: 0.867949 | Val Loss: 0.115558, Val Acc: 0.783505\n",
      "Epoch 16796 - Train Loss: 0.090189, Train Acc: 0.867949 | Val Loss: 0.115556, Val Acc: 0.783505\n",
      "Epoch 16797 - Train Loss: 0.090186, Train Acc: 0.867949 | Val Loss: 0.115555, Val Acc: 0.783505\n",
      "Epoch 16798 - Train Loss: 0.090182, Train Acc: 0.867949 | Val Loss: 0.115553, Val Acc: 0.783505\n",
      "Epoch 16799 - Train Loss: 0.090179, Train Acc: 0.867949 | Val Loss: 0.115551, Val Acc: 0.783505\n",
      "Epoch 16800 - Train Loss: 0.090176, Train Acc: 0.867949 | Val Loss: 0.115549, Val Acc: 0.783505\n",
      "Epoch 16801 - Train Loss: 0.090172, Train Acc: 0.867949 | Val Loss: 0.115547, Val Acc: 0.783505\n",
      "Epoch 16802 - Train Loss: 0.090169, Train Acc: 0.867949 | Val Loss: 0.115545, Val Acc: 0.783505\n",
      "Epoch 16803 - Train Loss: 0.090166, Train Acc: 0.867949 | Val Loss: 0.115543, Val Acc: 0.783505\n",
      "Epoch 16804 - Train Loss: 0.090163, Train Acc: 0.867949 | Val Loss: 0.115541, Val Acc: 0.783505\n",
      "Epoch 16805 - Train Loss: 0.090159, Train Acc: 0.867949 | Val Loss: 0.115539, Val Acc: 0.783505\n",
      "Epoch 16806 - Train Loss: 0.090156, Train Acc: 0.867949 | Val Loss: 0.115537, Val Acc: 0.783505\n",
      "Epoch 16807 - Train Loss: 0.090153, Train Acc: 0.867949 | Val Loss: 0.115535, Val Acc: 0.783505\n",
      "Epoch 16808 - Train Loss: 0.090149, Train Acc: 0.867949 | Val Loss: 0.115534, Val Acc: 0.783505\n",
      "Epoch 16809 - Train Loss: 0.090146, Train Acc: 0.867949 | Val Loss: 0.115532, Val Acc: 0.783505\n",
      "Epoch 16810 - Train Loss: 0.090143, Train Acc: 0.867949 | Val Loss: 0.115530, Val Acc: 0.783505\n",
      "Epoch 16811 - Train Loss: 0.090140, Train Acc: 0.867949 | Val Loss: 0.115528, Val Acc: 0.783505\n",
      "Epoch 16812 - Train Loss: 0.090136, Train Acc: 0.867949 | Val Loss: 0.115526, Val Acc: 0.783505\n",
      "Epoch 16813 - Train Loss: 0.090133, Train Acc: 0.867949 | Val Loss: 0.115524, Val Acc: 0.783505\n",
      "Epoch 16814 - Train Loss: 0.090130, Train Acc: 0.867949 | Val Loss: 0.115522, Val Acc: 0.783505\n",
      "Epoch 16815 - Train Loss: 0.090127, Train Acc: 0.867949 | Val Loss: 0.115520, Val Acc: 0.783505\n",
      "Epoch 16816 - Train Loss: 0.090123, Train Acc: 0.867949 | Val Loss: 0.115518, Val Acc: 0.783505\n",
      "Epoch 16817 - Train Loss: 0.090120, Train Acc: 0.867949 | Val Loss: 0.115516, Val Acc: 0.783505\n",
      "Epoch 16818 - Train Loss: 0.090117, Train Acc: 0.867949 | Val Loss: 0.115514, Val Acc: 0.783505\n",
      "Epoch 16819 - Train Loss: 0.090113, Train Acc: 0.867949 | Val Loss: 0.115513, Val Acc: 0.783505\n",
      "Epoch 16820 - Train Loss: 0.090110, Train Acc: 0.867949 | Val Loss: 0.115511, Val Acc: 0.783505\n",
      "Epoch 16821 - Train Loss: 0.090107, Train Acc: 0.867949 | Val Loss: 0.115509, Val Acc: 0.783505\n",
      "Epoch 16822 - Train Loss: 0.090104, Train Acc: 0.867949 | Val Loss: 0.115507, Val Acc: 0.783505\n",
      "Epoch 16823 - Train Loss: 0.090100, Train Acc: 0.867949 | Val Loss: 0.115505, Val Acc: 0.783505\n",
      "Epoch 16824 - Train Loss: 0.090097, Train Acc: 0.867949 | Val Loss: 0.115503, Val Acc: 0.783505\n",
      "Epoch 16825 - Train Loss: 0.090094, Train Acc: 0.867949 | Val Loss: 0.115501, Val Acc: 0.783505\n",
      "Epoch 16826 - Train Loss: 0.090091, Train Acc: 0.867949 | Val Loss: 0.115499, Val Acc: 0.783505\n",
      "Epoch 16827 - Train Loss: 0.090087, Train Acc: 0.867949 | Val Loss: 0.115497, Val Acc: 0.783505\n",
      "Epoch 16828 - Train Loss: 0.090084, Train Acc: 0.867949 | Val Loss: 0.115495, Val Acc: 0.783505\n",
      "Epoch 16829 - Train Loss: 0.090081, Train Acc: 0.867949 | Val Loss: 0.115494, Val Acc: 0.783505\n",
      "Epoch 16830 - Train Loss: 0.090078, Train Acc: 0.867949 | Val Loss: 0.115492, Val Acc: 0.783505\n",
      "Epoch 16831 - Train Loss: 0.090074, Train Acc: 0.867949 | Val Loss: 0.115490, Val Acc: 0.783505\n",
      "Epoch 16832 - Train Loss: 0.090071, Train Acc: 0.867949 | Val Loss: 0.115488, Val Acc: 0.783505\n",
      "Epoch 16833 - Train Loss: 0.090068, Train Acc: 0.867949 | Val Loss: 0.115486, Val Acc: 0.783505\n",
      "Epoch 16834 - Train Loss: 0.090064, Train Acc: 0.867949 | Val Loss: 0.115484, Val Acc: 0.783505\n",
      "Epoch 16835 - Train Loss: 0.090061, Train Acc: 0.867949 | Val Loss: 0.115482, Val Acc: 0.783505\n",
      "Epoch 16836 - Train Loss: 0.090058, Train Acc: 0.867949 | Val Loss: 0.115480, Val Acc: 0.783505\n",
      "Epoch 16837 - Train Loss: 0.090055, Train Acc: 0.867949 | Val Loss: 0.115478, Val Acc: 0.783505\n",
      "Epoch 16838 - Train Loss: 0.090051, Train Acc: 0.867949 | Val Loss: 0.115476, Val Acc: 0.783505\n",
      "Epoch 16839 - Train Loss: 0.090048, Train Acc: 0.867949 | Val Loss: 0.115475, Val Acc: 0.783505\n",
      "Epoch 16840 - Train Loss: 0.090045, Train Acc: 0.867949 | Val Loss: 0.115473, Val Acc: 0.783505\n",
      "Epoch 16841 - Train Loss: 0.090042, Train Acc: 0.867949 | Val Loss: 0.115471, Val Acc: 0.783505\n",
      "Epoch 16842 - Train Loss: 0.090038, Train Acc: 0.867949 | Val Loss: 0.115469, Val Acc: 0.783505\n",
      "Epoch 16843 - Train Loss: 0.090035, Train Acc: 0.867949 | Val Loss: 0.115467, Val Acc: 0.783505\n",
      "Epoch 16844 - Train Loss: 0.090032, Train Acc: 0.867949 | Val Loss: 0.115465, Val Acc: 0.783505\n",
      "Epoch 16845 - Train Loss: 0.090029, Train Acc: 0.867949 | Val Loss: 0.115463, Val Acc: 0.783505\n",
      "Epoch 16846 - Train Loss: 0.090025, Train Acc: 0.867949 | Val Loss: 0.115461, Val Acc: 0.783505\n",
      "Epoch 16847 - Train Loss: 0.090022, Train Acc: 0.867949 | Val Loss: 0.115459, Val Acc: 0.783505\n",
      "Epoch 16848 - Train Loss: 0.090019, Train Acc: 0.867949 | Val Loss: 0.115457, Val Acc: 0.783505\n",
      "Epoch 16849 - Train Loss: 0.090016, Train Acc: 0.867949 | Val Loss: 0.115456, Val Acc: 0.783505\n",
      "Epoch 16850 - Train Loss: 0.090012, Train Acc: 0.867949 | Val Loss: 0.115454, Val Acc: 0.783505\n",
      "Epoch 16851 - Train Loss: 0.090009, Train Acc: 0.867949 | Val Loss: 0.115452, Val Acc: 0.783505\n",
      "Epoch 16852 - Train Loss: 0.090006, Train Acc: 0.867949 | Val Loss: 0.115450, Val Acc: 0.783505\n",
      "Epoch 16853 - Train Loss: 0.090003, Train Acc: 0.867949 | Val Loss: 0.115448, Val Acc: 0.783505\n",
      "Epoch 16854 - Train Loss: 0.089999, Train Acc: 0.867949 | Val Loss: 0.115446, Val Acc: 0.783505\n",
      "Epoch 16855 - Train Loss: 0.089996, Train Acc: 0.867949 | Val Loss: 0.115444, Val Acc: 0.783505\n",
      "Epoch 16856 - Train Loss: 0.089993, Train Acc: 0.867949 | Val Loss: 0.115442, Val Acc: 0.783505\n",
      "Epoch 16857 - Train Loss: 0.089990, Train Acc: 0.867949 | Val Loss: 0.115440, Val Acc: 0.783505\n",
      "Epoch 16858 - Train Loss: 0.089986, Train Acc: 0.867949 | Val Loss: 0.115439, Val Acc: 0.783505\n",
      "Epoch 16859 - Train Loss: 0.089983, Train Acc: 0.867949 | Val Loss: 0.115437, Val Acc: 0.783505\n",
      "Epoch 16860 - Train Loss: 0.089980, Train Acc: 0.867949 | Val Loss: 0.115435, Val Acc: 0.783505\n",
      "Epoch 16861 - Train Loss: 0.089976, Train Acc: 0.867949 | Val Loss: 0.115433, Val Acc: 0.783505\n",
      "Epoch 16862 - Train Loss: 0.089973, Train Acc: 0.867949 | Val Loss: 0.115431, Val Acc: 0.783505\n",
      "Epoch 16863 - Train Loss: 0.089970, Train Acc: 0.867949 | Val Loss: 0.115429, Val Acc: 0.783505\n",
      "Epoch 16864 - Train Loss: 0.089967, Train Acc: 0.867949 | Val Loss: 0.115427, Val Acc: 0.783505\n",
      "Epoch 16865 - Train Loss: 0.089963, Train Acc: 0.867949 | Val Loss: 0.115425, Val Acc: 0.783505\n",
      "Epoch 16866 - Train Loss: 0.089960, Train Acc: 0.867949 | Val Loss: 0.115423, Val Acc: 0.783505\n",
      "Epoch 16867 - Train Loss: 0.089957, Train Acc: 0.867949 | Val Loss: 0.115422, Val Acc: 0.783505\n",
      "Epoch 16868 - Train Loss: 0.089954, Train Acc: 0.867949 | Val Loss: 0.115420, Val Acc: 0.783505\n",
      "Epoch 16869 - Train Loss: 0.089950, Train Acc: 0.867949 | Val Loss: 0.115418, Val Acc: 0.783505\n",
      "Epoch 16870 - Train Loss: 0.089947, Train Acc: 0.867949 | Val Loss: 0.115416, Val Acc: 0.783505\n",
      "Epoch 16871 - Train Loss: 0.089944, Train Acc: 0.867949 | Val Loss: 0.115414, Val Acc: 0.783505\n",
      "Epoch 16872 - Train Loss: 0.089941, Train Acc: 0.867949 | Val Loss: 0.115412, Val Acc: 0.783505\n",
      "Epoch 16873 - Train Loss: 0.089937, Train Acc: 0.867949 | Val Loss: 0.115410, Val Acc: 0.783505\n",
      "Epoch 16874 - Train Loss: 0.089934, Train Acc: 0.867949 | Val Loss: 0.115408, Val Acc: 0.783505\n",
      "Epoch 16875 - Train Loss: 0.089931, Train Acc: 0.867949 | Val Loss: 0.115407, Val Acc: 0.783505\n",
      "Epoch 16876 - Train Loss: 0.089928, Train Acc: 0.867949 | Val Loss: 0.115405, Val Acc: 0.783505\n",
      "Epoch 16877 - Train Loss: 0.089924, Train Acc: 0.867949 | Val Loss: 0.115403, Val Acc: 0.783505\n",
      "Epoch 16878 - Train Loss: 0.089921, Train Acc: 0.867949 | Val Loss: 0.115401, Val Acc: 0.783505\n",
      "Epoch 16879 - Train Loss: 0.089918, Train Acc: 0.867949 | Val Loss: 0.115399, Val Acc: 0.783505\n",
      "Epoch 16880 - Train Loss: 0.089915, Train Acc: 0.867949 | Val Loss: 0.115397, Val Acc: 0.783505\n",
      "Epoch 16881 - Train Loss: 0.089912, Train Acc: 0.867949 | Val Loss: 0.115395, Val Acc: 0.783505\n",
      "Epoch 16882 - Train Loss: 0.089908, Train Acc: 0.867949 | Val Loss: 0.115393, Val Acc: 0.783505\n",
      "Epoch 16883 - Train Loss: 0.089905, Train Acc: 0.867949 | Val Loss: 0.115391, Val Acc: 0.783505\n",
      "Epoch 16884 - Train Loss: 0.089902, Train Acc: 0.867949 | Val Loss: 0.115390, Val Acc: 0.783505\n",
      "Epoch 16885 - Train Loss: 0.089899, Train Acc: 0.867949 | Val Loss: 0.115388, Val Acc: 0.783505\n",
      "Epoch 16886 - Train Loss: 0.089895, Train Acc: 0.867949 | Val Loss: 0.115386, Val Acc: 0.783505\n",
      "Epoch 16887 - Train Loss: 0.089892, Train Acc: 0.867949 | Val Loss: 0.115384, Val Acc: 0.783505\n",
      "Epoch 16888 - Train Loss: 0.089889, Train Acc: 0.867949 | Val Loss: 0.115382, Val Acc: 0.783505\n",
      "Epoch 16889 - Train Loss: 0.089886, Train Acc: 0.867949 | Val Loss: 0.115380, Val Acc: 0.783505\n",
      "Epoch 16890 - Train Loss: 0.089882, Train Acc: 0.867949 | Val Loss: 0.115378, Val Acc: 0.783505\n",
      "Epoch 16891 - Train Loss: 0.089879, Train Acc: 0.867949 | Val Loss: 0.115376, Val Acc: 0.783505\n",
      "Epoch 16892 - Train Loss: 0.089876, Train Acc: 0.867949 | Val Loss: 0.115375, Val Acc: 0.783505\n",
      "Epoch 16893 - Train Loss: 0.089873, Train Acc: 0.867949 | Val Loss: 0.115373, Val Acc: 0.783505\n",
      "Epoch 16894 - Train Loss: 0.089869, Train Acc: 0.867949 | Val Loss: 0.115371, Val Acc: 0.783505\n",
      "Epoch 16895 - Train Loss: 0.089866, Train Acc: 0.867949 | Val Loss: 0.115369, Val Acc: 0.783505\n",
      "Epoch 16896 - Train Loss: 0.089863, Train Acc: 0.867949 | Val Loss: 0.115367, Val Acc: 0.783505\n",
      "Epoch 16897 - Train Loss: 0.089860, Train Acc: 0.867949 | Val Loss: 0.115365, Val Acc: 0.783505\n",
      "Epoch 16898 - Train Loss: 0.089856, Train Acc: 0.867949 | Val Loss: 0.115363, Val Acc: 0.783505\n",
      "Epoch 16899 - Train Loss: 0.089853, Train Acc: 0.867949 | Val Loss: 0.115361, Val Acc: 0.783505\n",
      "Epoch 16900 - Train Loss: 0.089850, Train Acc: 0.867949 | Val Loss: 0.115360, Val Acc: 0.783505\n",
      "Epoch 16901 - Train Loss: 0.089847, Train Acc: 0.867949 | Val Loss: 0.115358, Val Acc: 0.783505\n",
      "Epoch 16902 - Train Loss: 0.089843, Train Acc: 0.867949 | Val Loss: 0.115356, Val Acc: 0.783505\n",
      "Epoch 16903 - Train Loss: 0.089840, Train Acc: 0.867949 | Val Loss: 0.115354, Val Acc: 0.783505\n",
      "Epoch 16904 - Train Loss: 0.089837, Train Acc: 0.867949 | Val Loss: 0.115352, Val Acc: 0.783505\n",
      "Epoch 16905 - Train Loss: 0.089834, Train Acc: 0.867949 | Val Loss: 0.115350, Val Acc: 0.783505\n",
      "Epoch 16906 - Train Loss: 0.089830, Train Acc: 0.867949 | Val Loss: 0.115348, Val Acc: 0.783505\n",
      "Epoch 16907 - Train Loss: 0.089827, Train Acc: 0.867949 | Val Loss: 0.115346, Val Acc: 0.783505\n",
      "Epoch 16908 - Train Loss: 0.089824, Train Acc: 0.867949 | Val Loss: 0.115345, Val Acc: 0.783505\n",
      "Epoch 16909 - Train Loss: 0.089821, Train Acc: 0.867949 | Val Loss: 0.115343, Val Acc: 0.783505\n",
      "Epoch 16910 - Train Loss: 0.089818, Train Acc: 0.867949 | Val Loss: 0.115341, Val Acc: 0.783505\n",
      "Epoch 16911 - Train Loss: 0.089814, Train Acc: 0.867949 | Val Loss: 0.115339, Val Acc: 0.783505\n",
      "Epoch 16912 - Train Loss: 0.089811, Train Acc: 0.867949 | Val Loss: 0.115337, Val Acc: 0.783505\n",
      "Epoch 16913 - Train Loss: 0.089808, Train Acc: 0.867949 | Val Loss: 0.115335, Val Acc: 0.783505\n",
      "Epoch 16914 - Train Loss: 0.089805, Train Acc: 0.867949 | Val Loss: 0.115333, Val Acc: 0.783505\n",
      "Epoch 16915 - Train Loss: 0.089801, Train Acc: 0.867949 | Val Loss: 0.115332, Val Acc: 0.783505\n",
      "Epoch 16916 - Train Loss: 0.089798, Train Acc: 0.867949 | Val Loss: 0.115330, Val Acc: 0.783505\n",
      "Epoch 16917 - Train Loss: 0.089795, Train Acc: 0.867949 | Val Loss: 0.115328, Val Acc: 0.783505\n",
      "Epoch 16918 - Train Loss: 0.089792, Train Acc: 0.867949 | Val Loss: 0.115326, Val Acc: 0.783505\n",
      "Epoch 16919 - Train Loss: 0.089788, Train Acc: 0.867949 | Val Loss: 0.115324, Val Acc: 0.783505\n",
      "Epoch 16920 - Train Loss: 0.089785, Train Acc: 0.867949 | Val Loss: 0.115322, Val Acc: 0.783505\n",
      "Epoch 16921 - Train Loss: 0.089782, Train Acc: 0.867949 | Val Loss: 0.115320, Val Acc: 0.783505\n",
      "Epoch 16922 - Train Loss: 0.089779, Train Acc: 0.867949 | Val Loss: 0.115318, Val Acc: 0.783505\n",
      "Epoch 16923 - Train Loss: 0.089776, Train Acc: 0.867949 | Val Loss: 0.115317, Val Acc: 0.783505\n",
      "Epoch 16924 - Train Loss: 0.089772, Train Acc: 0.867949 | Val Loss: 0.115315, Val Acc: 0.783505\n",
      "Epoch 16925 - Train Loss: 0.089769, Train Acc: 0.867949 | Val Loss: 0.115313, Val Acc: 0.783505\n",
      "Epoch 16926 - Train Loss: 0.089766, Train Acc: 0.867949 | Val Loss: 0.115311, Val Acc: 0.783505\n",
      "Epoch 16927 - Train Loss: 0.089763, Train Acc: 0.867949 | Val Loss: 0.115309, Val Acc: 0.783505\n",
      "Epoch 16928 - Train Loss: 0.089759, Train Acc: 0.867949 | Val Loss: 0.115307, Val Acc: 0.783505\n",
      "Epoch 16929 - Train Loss: 0.089756, Train Acc: 0.867949 | Val Loss: 0.115305, Val Acc: 0.783505\n",
      "Epoch 16930 - Train Loss: 0.089753, Train Acc: 0.867949 | Val Loss: 0.115304, Val Acc: 0.783505\n",
      "Epoch 16931 - Train Loss: 0.089750, Train Acc: 0.867949 | Val Loss: 0.115302, Val Acc: 0.783505\n",
      "Epoch 16932 - Train Loss: 0.089746, Train Acc: 0.867949 | Val Loss: 0.115300, Val Acc: 0.783505\n",
      "Epoch 16933 - Train Loss: 0.089743, Train Acc: 0.867949 | Val Loss: 0.115298, Val Acc: 0.783505\n",
      "Epoch 16934 - Train Loss: 0.089740, Train Acc: 0.867949 | Val Loss: 0.115296, Val Acc: 0.783505\n",
      "Epoch 16935 - Train Loss: 0.089737, Train Acc: 0.867949 | Val Loss: 0.115294, Val Acc: 0.783505\n",
      "Epoch 16936 - Train Loss: 0.089734, Train Acc: 0.867949 | Val Loss: 0.115292, Val Acc: 0.783505\n",
      "Epoch 16937 - Train Loss: 0.089730, Train Acc: 0.867949 | Val Loss: 0.115291, Val Acc: 0.783505\n",
      "Epoch 16938 - Train Loss: 0.089727, Train Acc: 0.867949 | Val Loss: 0.115289, Val Acc: 0.783505\n",
      "Epoch 16939 - Train Loss: 0.089724, Train Acc: 0.867949 | Val Loss: 0.115287, Val Acc: 0.783505\n",
      "Epoch 16940 - Train Loss: 0.089721, Train Acc: 0.867949 | Val Loss: 0.115285, Val Acc: 0.783505\n",
      "Epoch 16941 - Train Loss: 0.089717, Train Acc: 0.867949 | Val Loss: 0.115283, Val Acc: 0.783505\n",
      "Epoch 16942 - Train Loss: 0.089714, Train Acc: 0.867949 | Val Loss: 0.115281, Val Acc: 0.783505\n",
      "Epoch 16943 - Train Loss: 0.089711, Train Acc: 0.867949 | Val Loss: 0.115279, Val Acc: 0.783505\n",
      "Epoch 16944 - Train Loss: 0.089708, Train Acc: 0.867949 | Val Loss: 0.115278, Val Acc: 0.783505\n",
      "Epoch 16945 - Train Loss: 0.089705, Train Acc: 0.867949 | Val Loss: 0.115276, Val Acc: 0.783505\n",
      "Epoch 16946 - Train Loss: 0.089701, Train Acc: 0.867949 | Val Loss: 0.115274, Val Acc: 0.783505\n",
      "Epoch 16947 - Train Loss: 0.089698, Train Acc: 0.867949 | Val Loss: 0.115272, Val Acc: 0.783505\n",
      "Epoch 16948 - Train Loss: 0.089695, Train Acc: 0.867949 | Val Loss: 0.115270, Val Acc: 0.783505\n",
      "Epoch 16949 - Train Loss: 0.089692, Train Acc: 0.867949 | Val Loss: 0.115268, Val Acc: 0.783505\n",
      "Epoch 16950 - Train Loss: 0.089688, Train Acc: 0.867949 | Val Loss: 0.115266, Val Acc: 0.783505\n",
      "Epoch 16951 - Train Loss: 0.089685, Train Acc: 0.867949 | Val Loss: 0.115265, Val Acc: 0.783505\n",
      "Epoch 16952 - Train Loss: 0.089682, Train Acc: 0.867949 | Val Loss: 0.115263, Val Acc: 0.783505\n",
      "Epoch 16953 - Train Loss: 0.089679, Train Acc: 0.867949 | Val Loss: 0.115261, Val Acc: 0.783505\n",
      "Epoch 16954 - Train Loss: 0.089676, Train Acc: 0.867949 | Val Loss: 0.115259, Val Acc: 0.783505\n",
      "Epoch 16955 - Train Loss: 0.089672, Train Acc: 0.867949 | Val Loss: 0.115257, Val Acc: 0.783505\n",
      "Epoch 16956 - Train Loss: 0.089669, Train Acc: 0.867949 | Val Loss: 0.115255, Val Acc: 0.783505\n",
      "Epoch 16957 - Train Loss: 0.089666, Train Acc: 0.867949 | Val Loss: 0.115253, Val Acc: 0.783505\n",
      "Epoch 16958 - Train Loss: 0.089663, Train Acc: 0.867949 | Val Loss: 0.115252, Val Acc: 0.783505\n",
      "Epoch 16959 - Train Loss: 0.089660, Train Acc: 0.867949 | Val Loss: 0.115250, Val Acc: 0.783505\n",
      "Epoch 16960 - Train Loss: 0.089656, Train Acc: 0.867949 | Val Loss: 0.115248, Val Acc: 0.783505\n",
      "Epoch 16961 - Train Loss: 0.089653, Train Acc: 0.867949 | Val Loss: 0.115246, Val Acc: 0.783505\n",
      "Epoch 16962 - Train Loss: 0.089650, Train Acc: 0.867949 | Val Loss: 0.115244, Val Acc: 0.783505\n",
      "Epoch 16963 - Train Loss: 0.089647, Train Acc: 0.867949 | Val Loss: 0.115242, Val Acc: 0.783505\n",
      "Epoch 16964 - Train Loss: 0.089643, Train Acc: 0.867949 | Val Loss: 0.115240, Val Acc: 0.783505\n",
      "Epoch 16965 - Train Loss: 0.089640, Train Acc: 0.867949 | Val Loss: 0.115239, Val Acc: 0.783505\n",
      "Epoch 16966 - Train Loss: 0.089637, Train Acc: 0.867949 | Val Loss: 0.115237, Val Acc: 0.783505\n",
      "Epoch 16967 - Train Loss: 0.089634, Train Acc: 0.867949 | Val Loss: 0.115235, Val Acc: 0.783505\n",
      "Epoch 16968 - Train Loss: 0.089631, Train Acc: 0.867949 | Val Loss: 0.115233, Val Acc: 0.783505\n",
      "Epoch 16969 - Train Loss: 0.089627, Train Acc: 0.867949 | Val Loss: 0.115231, Val Acc: 0.783505\n",
      "Epoch 16970 - Train Loss: 0.089624, Train Acc: 0.867949 | Val Loss: 0.115229, Val Acc: 0.783505\n",
      "Epoch 16971 - Train Loss: 0.089621, Train Acc: 0.867949 | Val Loss: 0.115228, Val Acc: 0.783505\n",
      "Epoch 16972 - Train Loss: 0.089618, Train Acc: 0.867949 | Val Loss: 0.115226, Val Acc: 0.783505\n",
      "Epoch 16973 - Train Loss: 0.089615, Train Acc: 0.867949 | Val Loss: 0.115224, Val Acc: 0.783505\n",
      "Epoch 16974 - Train Loss: 0.089611, Train Acc: 0.867949 | Val Loss: 0.115222, Val Acc: 0.783505\n",
      "Epoch 16975 - Train Loss: 0.089608, Train Acc: 0.867949 | Val Loss: 0.115220, Val Acc: 0.783505\n",
      "Epoch 16976 - Train Loss: 0.089605, Train Acc: 0.867949 | Val Loss: 0.115218, Val Acc: 0.783505\n",
      "Epoch 16977 - Train Loss: 0.089602, Train Acc: 0.867949 | Val Loss: 0.115217, Val Acc: 0.783505\n",
      "Epoch 16978 - Train Loss: 0.089598, Train Acc: 0.867949 | Val Loss: 0.115215, Val Acc: 0.783505\n",
      "Epoch 16979 - Train Loss: 0.089595, Train Acc: 0.867949 | Val Loss: 0.115213, Val Acc: 0.783505\n",
      "Epoch 16980 - Train Loss: 0.089592, Train Acc: 0.867949 | Val Loss: 0.115211, Val Acc: 0.783505\n",
      "Epoch 16981 - Train Loss: 0.089589, Train Acc: 0.867949 | Val Loss: 0.115209, Val Acc: 0.783505\n",
      "Epoch 16982 - Train Loss: 0.089586, Train Acc: 0.867949 | Val Loss: 0.115207, Val Acc: 0.783505\n",
      "Epoch 16983 - Train Loss: 0.089582, Train Acc: 0.867949 | Val Loss: 0.115205, Val Acc: 0.783505\n",
      "Epoch 16984 - Train Loss: 0.089579, Train Acc: 0.867949 | Val Loss: 0.115204, Val Acc: 0.783505\n",
      "Epoch 16985 - Train Loss: 0.089576, Train Acc: 0.867949 | Val Loss: 0.115202, Val Acc: 0.783505\n",
      "Epoch 16986 - Train Loss: 0.089573, Train Acc: 0.867949 | Val Loss: 0.115200, Val Acc: 0.783505\n",
      "Epoch 16987 - Train Loss: 0.089570, Train Acc: 0.867949 | Val Loss: 0.115198, Val Acc: 0.783505\n",
      "Epoch 16988 - Train Loss: 0.089566, Train Acc: 0.867949 | Val Loss: 0.115196, Val Acc: 0.783505\n",
      "Epoch 16989 - Train Loss: 0.089563, Train Acc: 0.867949 | Val Loss: 0.115194, Val Acc: 0.783505\n",
      "Epoch 16990 - Train Loss: 0.089560, Train Acc: 0.867949 | Val Loss: 0.115193, Val Acc: 0.783505\n",
      "Epoch 16991 - Train Loss: 0.089557, Train Acc: 0.867949 | Val Loss: 0.115191, Val Acc: 0.783505\n",
      "Epoch 16992 - Train Loss: 0.089554, Train Acc: 0.867949 | Val Loss: 0.115189, Val Acc: 0.783505\n",
      "Epoch 16993 - Train Loss: 0.089550, Train Acc: 0.867949 | Val Loss: 0.115187, Val Acc: 0.783505\n",
      "Epoch 16994 - Train Loss: 0.089547, Train Acc: 0.867949 | Val Loss: 0.115185, Val Acc: 0.783505\n",
      "Epoch 16995 - Train Loss: 0.089544, Train Acc: 0.867949 | Val Loss: 0.115183, Val Acc: 0.783505\n",
      "Epoch 16996 - Train Loss: 0.089541, Train Acc: 0.867949 | Val Loss: 0.115182, Val Acc: 0.783505\n",
      "Epoch 16997 - Train Loss: 0.089538, Train Acc: 0.867949 | Val Loss: 0.115180, Val Acc: 0.783505\n",
      "Epoch 16998 - Train Loss: 0.089534, Train Acc: 0.867949 | Val Loss: 0.115178, Val Acc: 0.783505\n",
      "Epoch 16999 - Train Loss: 0.089531, Train Acc: 0.867949 | Val Loss: 0.115176, Val Acc: 0.783505\n",
      "Epoch 17000 - Train Loss: 0.089528, Train Acc: 0.867949 | Val Loss: 0.115174, Val Acc: 0.783505\n",
      "Epoch 17001 - Train Loss: 0.089525, Train Acc: 0.867949 | Val Loss: 0.115172, Val Acc: 0.783505\n",
      "Epoch 17002 - Train Loss: 0.089522, Train Acc: 0.867949 | Val Loss: 0.115171, Val Acc: 0.783505\n",
      "Epoch 17003 - Train Loss: 0.089518, Train Acc: 0.867949 | Val Loss: 0.115169, Val Acc: 0.783505\n",
      "Epoch 17004 - Train Loss: 0.089515, Train Acc: 0.867949 | Val Loss: 0.115167, Val Acc: 0.783505\n",
      "Epoch 17005 - Train Loss: 0.089512, Train Acc: 0.867949 | Val Loss: 0.115165, Val Acc: 0.783505\n",
      "Epoch 17006 - Train Loss: 0.089509, Train Acc: 0.867949 | Val Loss: 0.115163, Val Acc: 0.783505\n",
      "Epoch 17007 - Train Loss: 0.089506, Train Acc: 0.867949 | Val Loss: 0.115161, Val Acc: 0.783505\n",
      "Epoch 17008 - Train Loss: 0.089502, Train Acc: 0.867949 | Val Loss: 0.115160, Val Acc: 0.783505\n",
      "Epoch 17009 - Train Loss: 0.089499, Train Acc: 0.867949 | Val Loss: 0.115158, Val Acc: 0.783505\n",
      "Epoch 17010 - Train Loss: 0.089496, Train Acc: 0.867949 | Val Loss: 0.115156, Val Acc: 0.783505\n",
      "Epoch 17011 - Train Loss: 0.089493, Train Acc: 0.867949 | Val Loss: 0.115154, Val Acc: 0.783505\n",
      "Epoch 17012 - Train Loss: 0.089490, Train Acc: 0.867949 | Val Loss: 0.115152, Val Acc: 0.783505\n",
      "Epoch 17013 - Train Loss: 0.089486, Train Acc: 0.867949 | Val Loss: 0.115150, Val Acc: 0.783505\n",
      "Epoch 17014 - Train Loss: 0.089483, Train Acc: 0.867949 | Val Loss: 0.115149, Val Acc: 0.783505\n",
      "Epoch 17015 - Train Loss: 0.089480, Train Acc: 0.867949 | Val Loss: 0.115147, Val Acc: 0.783505\n",
      "Epoch 17016 - Train Loss: 0.089477, Train Acc: 0.867949 | Val Loss: 0.115145, Val Acc: 0.783505\n",
      "Epoch 17017 - Train Loss: 0.089474, Train Acc: 0.867949 | Val Loss: 0.115143, Val Acc: 0.783505\n",
      "Epoch 17018 - Train Loss: 0.089470, Train Acc: 0.867949 | Val Loss: 0.115141, Val Acc: 0.783505\n",
      "Epoch 17019 - Train Loss: 0.089467, Train Acc: 0.867949 | Val Loss: 0.115139, Val Acc: 0.783505\n",
      "Epoch 17020 - Train Loss: 0.089464, Train Acc: 0.867949 | Val Loss: 0.115138, Val Acc: 0.783505\n",
      "Epoch 17021 - Train Loss: 0.089461, Train Acc: 0.867949 | Val Loss: 0.115136, Val Acc: 0.783505\n",
      "Epoch 17022 - Train Loss: 0.089458, Train Acc: 0.867949 | Val Loss: 0.115134, Val Acc: 0.783505\n",
      "Epoch 17023 - Train Loss: 0.089455, Train Acc: 0.867949 | Val Loss: 0.115132, Val Acc: 0.783505\n",
      "Epoch 17024 - Train Loss: 0.089451, Train Acc: 0.867949 | Val Loss: 0.115130, Val Acc: 0.783505\n",
      "Epoch 17025 - Train Loss: 0.089448, Train Acc: 0.867949 | Val Loss: 0.115128, Val Acc: 0.783505\n",
      "Epoch 17026 - Train Loss: 0.089445, Train Acc: 0.867949 | Val Loss: 0.115127, Val Acc: 0.783505\n",
      "Epoch 17027 - Train Loss: 0.089442, Train Acc: 0.867949 | Val Loss: 0.115125, Val Acc: 0.783505\n",
      "Epoch 17028 - Train Loss: 0.089439, Train Acc: 0.867949 | Val Loss: 0.115123, Val Acc: 0.783505\n",
      "Epoch 17029 - Train Loss: 0.089435, Train Acc: 0.867949 | Val Loss: 0.115121, Val Acc: 0.783505\n",
      "Epoch 17030 - Train Loss: 0.089432, Train Acc: 0.867949 | Val Loss: 0.115119, Val Acc: 0.783505\n",
      "Epoch 17031 - Train Loss: 0.089429, Train Acc: 0.867949 | Val Loss: 0.115117, Val Acc: 0.783505\n",
      "Epoch 17032 - Train Loss: 0.089426, Train Acc: 0.867949 | Val Loss: 0.115116, Val Acc: 0.783505\n",
      "Epoch 17033 - Train Loss: 0.089423, Train Acc: 0.867949 | Val Loss: 0.115114, Val Acc: 0.783505\n",
      "Epoch 17034 - Train Loss: 0.089419, Train Acc: 0.867949 | Val Loss: 0.115112, Val Acc: 0.783505\n",
      "Epoch 17035 - Train Loss: 0.089416, Train Acc: 0.867949 | Val Loss: 0.115110, Val Acc: 0.783505\n",
      "Epoch 17036 - Train Loss: 0.089413, Train Acc: 0.867949 | Val Loss: 0.115108, Val Acc: 0.783505\n",
      "Epoch 17037 - Train Loss: 0.089410, Train Acc: 0.867949 | Val Loss: 0.115107, Val Acc: 0.783505\n",
      "Epoch 17038 - Train Loss: 0.089407, Train Acc: 0.867949 | Val Loss: 0.115105, Val Acc: 0.783505\n",
      "Epoch 17039 - Train Loss: 0.089403, Train Acc: 0.867949 | Val Loss: 0.115103, Val Acc: 0.783505\n",
      "Epoch 17040 - Train Loss: 0.089400, Train Acc: 0.867949 | Val Loss: 0.115101, Val Acc: 0.783505\n",
      "Epoch 17041 - Train Loss: 0.089397, Train Acc: 0.867949 | Val Loss: 0.115099, Val Acc: 0.783505\n",
      "Epoch 17042 - Train Loss: 0.089394, Train Acc: 0.867949 | Val Loss: 0.115097, Val Acc: 0.783505\n",
      "Epoch 17043 - Train Loss: 0.089391, Train Acc: 0.867949 | Val Loss: 0.115096, Val Acc: 0.783505\n",
      "Epoch 17044 - Train Loss: 0.089388, Train Acc: 0.867949 | Val Loss: 0.115094, Val Acc: 0.783505\n",
      "Epoch 17045 - Train Loss: 0.089384, Train Acc: 0.867949 | Val Loss: 0.115092, Val Acc: 0.783505\n",
      "Epoch 17046 - Train Loss: 0.089381, Train Acc: 0.867949 | Val Loss: 0.115090, Val Acc: 0.783505\n",
      "Epoch 17047 - Train Loss: 0.089378, Train Acc: 0.867949 | Val Loss: 0.115088, Val Acc: 0.783505\n",
      "Epoch 17048 - Train Loss: 0.089375, Train Acc: 0.867949 | Val Loss: 0.115087, Val Acc: 0.783505\n",
      "Epoch 17049 - Train Loss: 0.089372, Train Acc: 0.867949 | Val Loss: 0.115085, Val Acc: 0.783505\n",
      "Epoch 17050 - Train Loss: 0.089368, Train Acc: 0.867949 | Val Loss: 0.115083, Val Acc: 0.783505\n",
      "Epoch 17051 - Train Loss: 0.089365, Train Acc: 0.867949 | Val Loss: 0.115081, Val Acc: 0.783505\n",
      "Epoch 17052 - Train Loss: 0.089362, Train Acc: 0.867949 | Val Loss: 0.115079, Val Acc: 0.783505\n",
      "Epoch 17053 - Train Loss: 0.089359, Train Acc: 0.867949 | Val Loss: 0.115077, Val Acc: 0.783505\n",
      "Epoch 17054 - Train Loss: 0.089356, Train Acc: 0.867949 | Val Loss: 0.115076, Val Acc: 0.783505\n",
      "Epoch 17055 - Train Loss: 0.089353, Train Acc: 0.867949 | Val Loss: 0.115074, Val Acc: 0.783505\n",
      "Epoch 17056 - Train Loss: 0.089349, Train Acc: 0.867949 | Val Loss: 0.115072, Val Acc: 0.783505\n",
      "Epoch 17057 - Train Loss: 0.089346, Train Acc: 0.867949 | Val Loss: 0.115070, Val Acc: 0.783505\n",
      "Epoch 17058 - Train Loss: 0.089343, Train Acc: 0.867949 | Val Loss: 0.115068, Val Acc: 0.783505\n",
      "Epoch 17059 - Train Loss: 0.089340, Train Acc: 0.867949 | Val Loss: 0.115067, Val Acc: 0.783505\n",
      "Epoch 17060 - Train Loss: 0.089337, Train Acc: 0.867949 | Val Loss: 0.115065, Val Acc: 0.783505\n",
      "Epoch 17061 - Train Loss: 0.089334, Train Acc: 0.867949 | Val Loss: 0.115063, Val Acc: 0.783505\n",
      "Epoch 17062 - Train Loss: 0.089330, Train Acc: 0.867949 | Val Loss: 0.115061, Val Acc: 0.783505\n",
      "Epoch 17063 - Train Loss: 0.089327, Train Acc: 0.867949 | Val Loss: 0.115059, Val Acc: 0.783505\n",
      "Epoch 17064 - Train Loss: 0.089324, Train Acc: 0.867949 | Val Loss: 0.115058, Val Acc: 0.783505\n",
      "Epoch 17065 - Train Loss: 0.089321, Train Acc: 0.867949 | Val Loss: 0.115056, Val Acc: 0.783505\n",
      "Epoch 17066 - Train Loss: 0.089318, Train Acc: 0.867949 | Val Loss: 0.115054, Val Acc: 0.783505\n",
      "Epoch 17067 - Train Loss: 0.089314, Train Acc: 0.867949 | Val Loss: 0.115052, Val Acc: 0.783505\n",
      "Epoch 17068 - Train Loss: 0.089311, Train Acc: 0.867949 | Val Loss: 0.115050, Val Acc: 0.783505\n",
      "Epoch 17069 - Train Loss: 0.089308, Train Acc: 0.867949 | Val Loss: 0.115048, Val Acc: 0.783505\n",
      "Epoch 17070 - Train Loss: 0.089305, Train Acc: 0.867949 | Val Loss: 0.115047, Val Acc: 0.783505\n",
      "Epoch 17071 - Train Loss: 0.089302, Train Acc: 0.867949 | Val Loss: 0.115045, Val Acc: 0.783505\n",
      "Epoch 17072 - Train Loss: 0.089299, Train Acc: 0.869231 | Val Loss: 0.115043, Val Acc: 0.783505\n",
      "Epoch 17073 - Train Loss: 0.089295, Train Acc: 0.869231 | Val Loss: 0.115041, Val Acc: 0.783505\n",
      "Epoch 17074 - Train Loss: 0.089292, Train Acc: 0.869231 | Val Loss: 0.115039, Val Acc: 0.783505\n",
      "Epoch 17075 - Train Loss: 0.089289, Train Acc: 0.869231 | Val Loss: 0.115038, Val Acc: 0.783505\n",
      "Epoch 17076 - Train Loss: 0.089286, Train Acc: 0.869231 | Val Loss: 0.115036, Val Acc: 0.783505\n",
      "Epoch 17077 - Train Loss: 0.089283, Train Acc: 0.869231 | Val Loss: 0.115034, Val Acc: 0.783505\n",
      "Epoch 17078 - Train Loss: 0.089280, Train Acc: 0.869231 | Val Loss: 0.115032, Val Acc: 0.783505\n",
      "Epoch 17079 - Train Loss: 0.089276, Train Acc: 0.869231 | Val Loss: 0.115030, Val Acc: 0.783505\n",
      "Epoch 17080 - Train Loss: 0.089273, Train Acc: 0.869231 | Val Loss: 0.115029, Val Acc: 0.783505\n",
      "Epoch 17081 - Train Loss: 0.089270, Train Acc: 0.869231 | Val Loss: 0.115027, Val Acc: 0.783505\n",
      "Epoch 17082 - Train Loss: 0.089267, Train Acc: 0.869231 | Val Loss: 0.115025, Val Acc: 0.783505\n",
      "Epoch 17083 - Train Loss: 0.089264, Train Acc: 0.869231 | Val Loss: 0.115023, Val Acc: 0.783505\n",
      "Epoch 17084 - Train Loss: 0.089261, Train Acc: 0.869231 | Val Loss: 0.115021, Val Acc: 0.783505\n",
      "Epoch 17085 - Train Loss: 0.089257, Train Acc: 0.869231 | Val Loss: 0.115020, Val Acc: 0.783505\n",
      "Epoch 17086 - Train Loss: 0.089254, Train Acc: 0.869231 | Val Loss: 0.115018, Val Acc: 0.783505\n",
      "Epoch 17087 - Train Loss: 0.089251, Train Acc: 0.869231 | Val Loss: 0.115016, Val Acc: 0.783505\n",
      "Epoch 17088 - Train Loss: 0.089248, Train Acc: 0.869231 | Val Loss: 0.115014, Val Acc: 0.783505\n",
      "Epoch 17089 - Train Loss: 0.089245, Train Acc: 0.869231 | Val Loss: 0.115012, Val Acc: 0.783505\n",
      "Epoch 17090 - Train Loss: 0.089242, Train Acc: 0.869231 | Val Loss: 0.115011, Val Acc: 0.783505\n",
      "Epoch 17091 - Train Loss: 0.089238, Train Acc: 0.869231 | Val Loss: 0.115009, Val Acc: 0.783505\n",
      "Epoch 17092 - Train Loss: 0.089235, Train Acc: 0.869231 | Val Loss: 0.115007, Val Acc: 0.783505\n",
      "Epoch 17093 - Train Loss: 0.089232, Train Acc: 0.869231 | Val Loss: 0.115005, Val Acc: 0.783505\n",
      "Epoch 17094 - Train Loss: 0.089229, Train Acc: 0.869231 | Val Loss: 0.115004, Val Acc: 0.783505\n",
      "Epoch 17095 - Train Loss: 0.089226, Train Acc: 0.869231 | Val Loss: 0.115002, Val Acc: 0.783505\n",
      "Epoch 17096 - Train Loss: 0.089223, Train Acc: 0.869231 | Val Loss: 0.115000, Val Acc: 0.783505\n",
      "Epoch 17097 - Train Loss: 0.089219, Train Acc: 0.869231 | Val Loss: 0.114998, Val Acc: 0.783505\n",
      "Epoch 17098 - Train Loss: 0.089216, Train Acc: 0.869231 | Val Loss: 0.114996, Val Acc: 0.783505\n",
      "Epoch 17099 - Train Loss: 0.089213, Train Acc: 0.869231 | Val Loss: 0.114995, Val Acc: 0.783505\n",
      "Epoch 17100 - Train Loss: 0.089210, Train Acc: 0.869231 | Val Loss: 0.114993, Val Acc: 0.783505\n",
      "Epoch 17101 - Train Loss: 0.089207, Train Acc: 0.869231 | Val Loss: 0.114991, Val Acc: 0.783505\n",
      "Epoch 17102 - Train Loss: 0.089204, Train Acc: 0.869231 | Val Loss: 0.114989, Val Acc: 0.783505\n",
      "Epoch 17103 - Train Loss: 0.089200, Train Acc: 0.869231 | Val Loss: 0.114987, Val Acc: 0.783505\n",
      "Epoch 17104 - Train Loss: 0.089197, Train Acc: 0.869231 | Val Loss: 0.114986, Val Acc: 0.783505\n",
      "Epoch 17105 - Train Loss: 0.089194, Train Acc: 0.869231 | Val Loss: 0.114984, Val Acc: 0.783505\n",
      "Epoch 17106 - Train Loss: 0.089191, Train Acc: 0.869231 | Val Loss: 0.114982, Val Acc: 0.783505\n",
      "Epoch 17107 - Train Loss: 0.089188, Train Acc: 0.869231 | Val Loss: 0.114980, Val Acc: 0.783505\n",
      "Epoch 17108 - Train Loss: 0.089185, Train Acc: 0.869231 | Val Loss: 0.114978, Val Acc: 0.783505\n",
      "Epoch 17109 - Train Loss: 0.089181, Train Acc: 0.869231 | Val Loss: 0.114977, Val Acc: 0.783505\n",
      "Epoch 17110 - Train Loss: 0.089178, Train Acc: 0.869231 | Val Loss: 0.114975, Val Acc: 0.783505\n",
      "Epoch 17111 - Train Loss: 0.089175, Train Acc: 0.869231 | Val Loss: 0.114973, Val Acc: 0.783505\n",
      "Epoch 17112 - Train Loss: 0.089172, Train Acc: 0.869231 | Val Loss: 0.114971, Val Acc: 0.783505\n",
      "Epoch 17113 - Train Loss: 0.089169, Train Acc: 0.869231 | Val Loss: 0.114970, Val Acc: 0.783505\n",
      "Epoch 17114 - Train Loss: 0.089166, Train Acc: 0.869231 | Val Loss: 0.114968, Val Acc: 0.783505\n",
      "Epoch 17115 - Train Loss: 0.089162, Train Acc: 0.869231 | Val Loss: 0.114966, Val Acc: 0.783505\n",
      "Epoch 17116 - Train Loss: 0.089159, Train Acc: 0.869231 | Val Loss: 0.114964, Val Acc: 0.783505\n",
      "Epoch 17117 - Train Loss: 0.089156, Train Acc: 0.869231 | Val Loss: 0.114962, Val Acc: 0.783505\n",
      "Epoch 17118 - Train Loss: 0.089153, Train Acc: 0.869231 | Val Loss: 0.114961, Val Acc: 0.783505\n",
      "Epoch 17119 - Train Loss: 0.089150, Train Acc: 0.869231 | Val Loss: 0.114959, Val Acc: 0.783505\n",
      "Epoch 17120 - Train Loss: 0.089147, Train Acc: 0.869231 | Val Loss: 0.114957, Val Acc: 0.783505\n",
      "Epoch 17121 - Train Loss: 0.089144, Train Acc: 0.869231 | Val Loss: 0.114955, Val Acc: 0.783505\n",
      "Epoch 17122 - Train Loss: 0.089140, Train Acc: 0.869231 | Val Loss: 0.114954, Val Acc: 0.783505\n",
      "Epoch 17123 - Train Loss: 0.089137, Train Acc: 0.869231 | Val Loss: 0.114952, Val Acc: 0.783505\n",
      "Epoch 17124 - Train Loss: 0.089134, Train Acc: 0.869231 | Val Loss: 0.114950, Val Acc: 0.783505\n",
      "Epoch 17125 - Train Loss: 0.089131, Train Acc: 0.869231 | Val Loss: 0.114948, Val Acc: 0.783505\n",
      "Epoch 17126 - Train Loss: 0.089128, Train Acc: 0.869231 | Val Loss: 0.114946, Val Acc: 0.783505\n",
      "Epoch 17127 - Train Loss: 0.089125, Train Acc: 0.869231 | Val Loss: 0.114945, Val Acc: 0.783505\n",
      "Epoch 17128 - Train Loss: 0.089121, Train Acc: 0.869231 | Val Loss: 0.114943, Val Acc: 0.783505\n",
      "Epoch 17129 - Train Loss: 0.089118, Train Acc: 0.869231 | Val Loss: 0.114941, Val Acc: 0.783505\n",
      "Epoch 17130 - Train Loss: 0.089115, Train Acc: 0.869231 | Val Loss: 0.114939, Val Acc: 0.783505\n",
      "Epoch 17131 - Train Loss: 0.089112, Train Acc: 0.869231 | Val Loss: 0.114937, Val Acc: 0.783505\n",
      "Epoch 17132 - Train Loss: 0.089109, Train Acc: 0.869231 | Val Loss: 0.114936, Val Acc: 0.783505\n",
      "Epoch 17133 - Train Loss: 0.089106, Train Acc: 0.869231 | Val Loss: 0.114934, Val Acc: 0.783505\n",
      "Epoch 17134 - Train Loss: 0.089103, Train Acc: 0.869231 | Val Loss: 0.114932, Val Acc: 0.783505\n",
      "Epoch 17135 - Train Loss: 0.089099, Train Acc: 0.869231 | Val Loss: 0.114930, Val Acc: 0.783505\n",
      "Epoch 17136 - Train Loss: 0.089096, Train Acc: 0.869231 | Val Loss: 0.114929, Val Acc: 0.783505\n",
      "Epoch 17137 - Train Loss: 0.089093, Train Acc: 0.869231 | Val Loss: 0.114927, Val Acc: 0.783505\n",
      "Epoch 17138 - Train Loss: 0.089090, Train Acc: 0.869231 | Val Loss: 0.114925, Val Acc: 0.783505\n",
      "Epoch 17139 - Train Loss: 0.089087, Train Acc: 0.869231 | Val Loss: 0.114923, Val Acc: 0.783505\n",
      "Epoch 17140 - Train Loss: 0.089084, Train Acc: 0.869231 | Val Loss: 0.114922, Val Acc: 0.783505\n",
      "Epoch 17141 - Train Loss: 0.089081, Train Acc: 0.869231 | Val Loss: 0.114920, Val Acc: 0.783505\n",
      "Epoch 17142 - Train Loss: 0.089077, Train Acc: 0.869231 | Val Loss: 0.114918, Val Acc: 0.783505\n",
      "Epoch 17143 - Train Loss: 0.089074, Train Acc: 0.869231 | Val Loss: 0.114916, Val Acc: 0.783505\n",
      "Epoch 17144 - Train Loss: 0.089071, Train Acc: 0.869231 | Val Loss: 0.114914, Val Acc: 0.783505\n",
      "Epoch 17145 - Train Loss: 0.089068, Train Acc: 0.869231 | Val Loss: 0.114913, Val Acc: 0.783505\n",
      "Epoch 17146 - Train Loss: 0.089065, Train Acc: 0.869231 | Val Loss: 0.114911, Val Acc: 0.783505\n",
      "Epoch 17147 - Train Loss: 0.089062, Train Acc: 0.869231 | Val Loss: 0.114909, Val Acc: 0.783505\n",
      "Epoch 17148 - Train Loss: 0.089058, Train Acc: 0.869231 | Val Loss: 0.114907, Val Acc: 0.783505\n",
      "Epoch 17149 - Train Loss: 0.089055, Train Acc: 0.869231 | Val Loss: 0.114906, Val Acc: 0.783505\n",
      "Epoch 17150 - Train Loss: 0.089052, Train Acc: 0.869231 | Val Loss: 0.114904, Val Acc: 0.783505\n",
      "Epoch 17151 - Train Loss: 0.089049, Train Acc: 0.869231 | Val Loss: 0.114902, Val Acc: 0.783505\n",
      "Epoch 17152 - Train Loss: 0.089046, Train Acc: 0.869231 | Val Loss: 0.114900, Val Acc: 0.783505\n",
      "Epoch 17153 - Train Loss: 0.089043, Train Acc: 0.869231 | Val Loss: 0.114898, Val Acc: 0.783505\n",
      "Epoch 17154 - Train Loss: 0.089040, Train Acc: 0.869231 | Val Loss: 0.114897, Val Acc: 0.783505\n",
      "Epoch 17155 - Train Loss: 0.089036, Train Acc: 0.869231 | Val Loss: 0.114895, Val Acc: 0.783505\n",
      "Epoch 17156 - Train Loss: 0.089033, Train Acc: 0.869231 | Val Loss: 0.114893, Val Acc: 0.783505\n",
      "Epoch 17157 - Train Loss: 0.089030, Train Acc: 0.869231 | Val Loss: 0.114891, Val Acc: 0.783505\n",
      "Epoch 17158 - Train Loss: 0.089027, Train Acc: 0.869231 | Val Loss: 0.114890, Val Acc: 0.783505\n",
      "Epoch 17159 - Train Loss: 0.089024, Train Acc: 0.869231 | Val Loss: 0.114888, Val Acc: 0.783505\n",
      "Epoch 17160 - Train Loss: 0.089021, Train Acc: 0.869231 | Val Loss: 0.114886, Val Acc: 0.783505\n",
      "Epoch 17161 - Train Loss: 0.089018, Train Acc: 0.869231 | Val Loss: 0.114884, Val Acc: 0.783505\n",
      "Epoch 17162 - Train Loss: 0.089014, Train Acc: 0.869231 | Val Loss: 0.114883, Val Acc: 0.783505\n",
      "Epoch 17163 - Train Loss: 0.089011, Train Acc: 0.869231 | Val Loss: 0.114881, Val Acc: 0.783505\n",
      "Epoch 17164 - Train Loss: 0.089008, Train Acc: 0.869231 | Val Loss: 0.114879, Val Acc: 0.783505\n",
      "Epoch 17165 - Train Loss: 0.089005, Train Acc: 0.869231 | Val Loss: 0.114877, Val Acc: 0.783505\n",
      "Epoch 17166 - Train Loss: 0.089002, Train Acc: 0.869231 | Val Loss: 0.114875, Val Acc: 0.783505\n",
      "Epoch 17167 - Train Loss: 0.088999, Train Acc: 0.869231 | Val Loss: 0.114874, Val Acc: 0.783505\n",
      "Epoch 17168 - Train Loss: 0.088996, Train Acc: 0.869231 | Val Loss: 0.114872, Val Acc: 0.783505\n",
      "Epoch 17169 - Train Loss: 0.088993, Train Acc: 0.869231 | Val Loss: 0.114870, Val Acc: 0.783505\n",
      "Epoch 17170 - Train Loss: 0.088989, Train Acc: 0.869231 | Val Loss: 0.114868, Val Acc: 0.783505\n",
      "Epoch 17171 - Train Loss: 0.088986, Train Acc: 0.869231 | Val Loss: 0.114867, Val Acc: 0.783505\n",
      "Epoch 17172 - Train Loss: 0.088983, Train Acc: 0.869231 | Val Loss: 0.114865, Val Acc: 0.783505\n",
      "Epoch 17173 - Train Loss: 0.088980, Train Acc: 0.869231 | Val Loss: 0.114863, Val Acc: 0.783505\n",
      "Epoch 17174 - Train Loss: 0.088977, Train Acc: 0.870513 | Val Loss: 0.114861, Val Acc: 0.783505\n",
      "Epoch 17175 - Train Loss: 0.088974, Train Acc: 0.870513 | Val Loss: 0.114860, Val Acc: 0.783505\n",
      "Epoch 17176 - Train Loss: 0.088971, Train Acc: 0.870513 | Val Loss: 0.114858, Val Acc: 0.783505\n",
      "Epoch 17177 - Train Loss: 0.088967, Train Acc: 0.870513 | Val Loss: 0.114856, Val Acc: 0.783505\n",
      "Epoch 17178 - Train Loss: 0.088964, Train Acc: 0.870513 | Val Loss: 0.114854, Val Acc: 0.783505\n",
      "Epoch 17179 - Train Loss: 0.088961, Train Acc: 0.870513 | Val Loss: 0.114853, Val Acc: 0.783505\n",
      "Epoch 17180 - Train Loss: 0.088958, Train Acc: 0.870513 | Val Loss: 0.114851, Val Acc: 0.783505\n",
      "Epoch 17181 - Train Loss: 0.088955, Train Acc: 0.870513 | Val Loss: 0.114849, Val Acc: 0.783505\n",
      "Epoch 17182 - Train Loss: 0.088952, Train Acc: 0.870513 | Val Loss: 0.114847, Val Acc: 0.783505\n",
      "Epoch 17183 - Train Loss: 0.088949, Train Acc: 0.870513 | Val Loss: 0.114846, Val Acc: 0.783505\n",
      "Epoch 17184 - Train Loss: 0.088946, Train Acc: 0.870513 | Val Loss: 0.114844, Val Acc: 0.783505\n",
      "Epoch 17185 - Train Loss: 0.088942, Train Acc: 0.870513 | Val Loss: 0.114842, Val Acc: 0.783505\n",
      "Epoch 17186 - Train Loss: 0.088939, Train Acc: 0.870513 | Val Loss: 0.114840, Val Acc: 0.783505\n",
      "Epoch 17187 - Train Loss: 0.088936, Train Acc: 0.870513 | Val Loss: 0.114839, Val Acc: 0.783505\n",
      "Epoch 17188 - Train Loss: 0.088933, Train Acc: 0.870513 | Val Loss: 0.114837, Val Acc: 0.783505\n",
      "Epoch 17189 - Train Loss: 0.088930, Train Acc: 0.870513 | Val Loss: 0.114835, Val Acc: 0.783505\n",
      "Epoch 17190 - Train Loss: 0.088927, Train Acc: 0.870513 | Val Loss: 0.114833, Val Acc: 0.783505\n",
      "Epoch 17191 - Train Loss: 0.088924, Train Acc: 0.870513 | Val Loss: 0.114831, Val Acc: 0.783505\n",
      "Epoch 17192 - Train Loss: 0.088920, Train Acc: 0.870513 | Val Loss: 0.114830, Val Acc: 0.783505\n",
      "Epoch 17193 - Train Loss: 0.088917, Train Acc: 0.870513 | Val Loss: 0.114828, Val Acc: 0.783505\n",
      "Epoch 17194 - Train Loss: 0.088914, Train Acc: 0.870513 | Val Loss: 0.114826, Val Acc: 0.783505\n",
      "Epoch 17195 - Train Loss: 0.088911, Train Acc: 0.870513 | Val Loss: 0.114824, Val Acc: 0.783505\n",
      "Epoch 17196 - Train Loss: 0.088908, Train Acc: 0.870513 | Val Loss: 0.114823, Val Acc: 0.783505\n",
      "Epoch 17197 - Train Loss: 0.088905, Train Acc: 0.870513 | Val Loss: 0.114821, Val Acc: 0.783505\n",
      "Epoch 17198 - Train Loss: 0.088902, Train Acc: 0.870513 | Val Loss: 0.114819, Val Acc: 0.783505\n",
      "Epoch 17199 - Train Loss: 0.088899, Train Acc: 0.870513 | Val Loss: 0.114817, Val Acc: 0.783505\n",
      "Epoch 17200 - Train Loss: 0.088895, Train Acc: 0.870513 | Val Loss: 0.114816, Val Acc: 0.783505\n",
      "Epoch 17201 - Train Loss: 0.088892, Train Acc: 0.870513 | Val Loss: 0.114814, Val Acc: 0.783505\n",
      "Epoch 17202 - Train Loss: 0.088889, Train Acc: 0.870513 | Val Loss: 0.114812, Val Acc: 0.783505\n",
      "Epoch 17203 - Train Loss: 0.088886, Train Acc: 0.870513 | Val Loss: 0.114810, Val Acc: 0.783505\n",
      "Epoch 17204 - Train Loss: 0.088883, Train Acc: 0.870513 | Val Loss: 0.114809, Val Acc: 0.783505\n",
      "Epoch 17205 - Train Loss: 0.088880, Train Acc: 0.870513 | Val Loss: 0.114807, Val Acc: 0.783505\n",
      "Epoch 17206 - Train Loss: 0.088877, Train Acc: 0.870513 | Val Loss: 0.114805, Val Acc: 0.783505\n",
      "Epoch 17207 - Train Loss: 0.088874, Train Acc: 0.870513 | Val Loss: 0.114803, Val Acc: 0.783505\n",
      "Epoch 17208 - Train Loss: 0.088870, Train Acc: 0.870513 | Val Loss: 0.114802, Val Acc: 0.783505\n",
      "Epoch 17209 - Train Loss: 0.088867, Train Acc: 0.870513 | Val Loss: 0.114800, Val Acc: 0.783505\n",
      "Epoch 17210 - Train Loss: 0.088864, Train Acc: 0.870513 | Val Loss: 0.114798, Val Acc: 0.783505\n",
      "Epoch 17211 - Train Loss: 0.088861, Train Acc: 0.870513 | Val Loss: 0.114796, Val Acc: 0.783505\n",
      "Epoch 17212 - Train Loss: 0.088858, Train Acc: 0.870513 | Val Loss: 0.114795, Val Acc: 0.783505\n",
      "Epoch 17213 - Train Loss: 0.088855, Train Acc: 0.870513 | Val Loss: 0.114793, Val Acc: 0.783505\n",
      "Epoch 17214 - Train Loss: 0.088852, Train Acc: 0.870513 | Val Loss: 0.114791, Val Acc: 0.783505\n",
      "Epoch 17215 - Train Loss: 0.088849, Train Acc: 0.870513 | Val Loss: 0.114789, Val Acc: 0.783505\n",
      "Epoch 17216 - Train Loss: 0.088845, Train Acc: 0.870513 | Val Loss: 0.114788, Val Acc: 0.783505\n",
      "Epoch 17217 - Train Loss: 0.088842, Train Acc: 0.870513 | Val Loss: 0.114786, Val Acc: 0.783505\n",
      "Epoch 17218 - Train Loss: 0.088839, Train Acc: 0.870513 | Val Loss: 0.114784, Val Acc: 0.783505\n",
      "Epoch 17219 - Train Loss: 0.088836, Train Acc: 0.870513 | Val Loss: 0.114782, Val Acc: 0.783505\n",
      "Epoch 17220 - Train Loss: 0.088833, Train Acc: 0.870513 | Val Loss: 0.114781, Val Acc: 0.783505\n",
      "Epoch 17221 - Train Loss: 0.088830, Train Acc: 0.870513 | Val Loss: 0.114779, Val Acc: 0.783505\n",
      "Epoch 17222 - Train Loss: 0.088827, Train Acc: 0.870513 | Val Loss: 0.114777, Val Acc: 0.783505\n",
      "Epoch 17223 - Train Loss: 0.088824, Train Acc: 0.870513 | Val Loss: 0.114775, Val Acc: 0.783505\n",
      "Epoch 17224 - Train Loss: 0.088821, Train Acc: 0.870513 | Val Loss: 0.114774, Val Acc: 0.783505\n",
      "Epoch 17225 - Train Loss: 0.088817, Train Acc: 0.870513 | Val Loss: 0.114772, Val Acc: 0.783505\n",
      "Epoch 17226 - Train Loss: 0.088814, Train Acc: 0.870513 | Val Loss: 0.114770, Val Acc: 0.783505\n",
      "Epoch 17227 - Train Loss: 0.088811, Train Acc: 0.870513 | Val Loss: 0.114768, Val Acc: 0.783505\n",
      "Epoch 17228 - Train Loss: 0.088808, Train Acc: 0.870513 | Val Loss: 0.114767, Val Acc: 0.783505\n",
      "Epoch 17229 - Train Loss: 0.088805, Train Acc: 0.870513 | Val Loss: 0.114765, Val Acc: 0.783505\n",
      "Epoch 17230 - Train Loss: 0.088802, Train Acc: 0.870513 | Val Loss: 0.114763, Val Acc: 0.783505\n",
      "Epoch 17231 - Train Loss: 0.088799, Train Acc: 0.870513 | Val Loss: 0.114761, Val Acc: 0.783505\n",
      "Epoch 17232 - Train Loss: 0.088796, Train Acc: 0.870513 | Val Loss: 0.114760, Val Acc: 0.783505\n",
      "Epoch 17233 - Train Loss: 0.088793, Train Acc: 0.870513 | Val Loss: 0.114758, Val Acc: 0.783505\n",
      "Epoch 17234 - Train Loss: 0.088789, Train Acc: 0.870513 | Val Loss: 0.114756, Val Acc: 0.783505\n",
      "Epoch 17235 - Train Loss: 0.088786, Train Acc: 0.870513 | Val Loss: 0.114755, Val Acc: 0.783505\n",
      "Epoch 17236 - Train Loss: 0.088783, Train Acc: 0.870513 | Val Loss: 0.114753, Val Acc: 0.783505\n",
      "Epoch 17237 - Train Loss: 0.088780, Train Acc: 0.870513 | Val Loss: 0.114751, Val Acc: 0.783505\n",
      "Epoch 17238 - Train Loss: 0.088777, Train Acc: 0.870513 | Val Loss: 0.114749, Val Acc: 0.783505\n",
      "Epoch 17239 - Train Loss: 0.088774, Train Acc: 0.870513 | Val Loss: 0.114748, Val Acc: 0.783505\n",
      "Epoch 17240 - Train Loss: 0.088771, Train Acc: 0.870513 | Val Loss: 0.114746, Val Acc: 0.783505\n",
      "Epoch 17241 - Train Loss: 0.088768, Train Acc: 0.870513 | Val Loss: 0.114744, Val Acc: 0.783505\n",
      "Epoch 17242 - Train Loss: 0.088765, Train Acc: 0.870513 | Val Loss: 0.114742, Val Acc: 0.783505\n",
      "Epoch 17243 - Train Loss: 0.088761, Train Acc: 0.870513 | Val Loss: 0.114741, Val Acc: 0.783505\n",
      "Epoch 17244 - Train Loss: 0.088758, Train Acc: 0.870513 | Val Loss: 0.114739, Val Acc: 0.783505\n",
      "Epoch 17245 - Train Loss: 0.088755, Train Acc: 0.870513 | Val Loss: 0.114737, Val Acc: 0.783505\n",
      "Epoch 17246 - Train Loss: 0.088752, Train Acc: 0.870513 | Val Loss: 0.114735, Val Acc: 0.783505\n",
      "Epoch 17247 - Train Loss: 0.088749, Train Acc: 0.870513 | Val Loss: 0.114734, Val Acc: 0.783505\n",
      "Epoch 17248 - Train Loss: 0.088746, Train Acc: 0.870513 | Val Loss: 0.114732, Val Acc: 0.783505\n",
      "Epoch 17249 - Train Loss: 0.088743, Train Acc: 0.870513 | Val Loss: 0.114730, Val Acc: 0.783505\n",
      "Epoch 17250 - Train Loss: 0.088740, Train Acc: 0.870513 | Val Loss: 0.114728, Val Acc: 0.783505\n",
      "Epoch 17251 - Train Loss: 0.088737, Train Acc: 0.870513 | Val Loss: 0.114727, Val Acc: 0.783505\n",
      "Epoch 17252 - Train Loss: 0.088733, Train Acc: 0.870513 | Val Loss: 0.114725, Val Acc: 0.783505\n",
      "Epoch 17253 - Train Loss: 0.088730, Train Acc: 0.870513 | Val Loss: 0.114723, Val Acc: 0.783505\n",
      "Epoch 17254 - Train Loss: 0.088727, Train Acc: 0.870513 | Val Loss: 0.114722, Val Acc: 0.783505\n",
      "Epoch 17255 - Train Loss: 0.088724, Train Acc: 0.870513 | Val Loss: 0.114720, Val Acc: 0.783505\n",
      "Epoch 17256 - Train Loss: 0.088721, Train Acc: 0.870513 | Val Loss: 0.114718, Val Acc: 0.783505\n",
      "Epoch 17257 - Train Loss: 0.088718, Train Acc: 0.870513 | Val Loss: 0.114716, Val Acc: 0.783505\n",
      "Epoch 17258 - Train Loss: 0.088715, Train Acc: 0.870513 | Val Loss: 0.114715, Val Acc: 0.783505\n",
      "Epoch 17259 - Train Loss: 0.088712, Train Acc: 0.870513 | Val Loss: 0.114713, Val Acc: 0.783505\n",
      "Epoch 17260 - Train Loss: 0.088709, Train Acc: 0.870513 | Val Loss: 0.114711, Val Acc: 0.783505\n",
      "Epoch 17261 - Train Loss: 0.088705, Train Acc: 0.870513 | Val Loss: 0.114709, Val Acc: 0.783505\n",
      "Epoch 17262 - Train Loss: 0.088702, Train Acc: 0.870513 | Val Loss: 0.114708, Val Acc: 0.783505\n",
      "Epoch 17263 - Train Loss: 0.088699, Train Acc: 0.870513 | Val Loss: 0.114706, Val Acc: 0.783505\n",
      "Epoch 17264 - Train Loss: 0.088696, Train Acc: 0.870513 | Val Loss: 0.114704, Val Acc: 0.783505\n",
      "Epoch 17265 - Train Loss: 0.088693, Train Acc: 0.870513 | Val Loss: 0.114702, Val Acc: 0.783505\n",
      "Epoch 17266 - Train Loss: 0.088690, Train Acc: 0.870513 | Val Loss: 0.114701, Val Acc: 0.783505\n",
      "Epoch 17267 - Train Loss: 0.088687, Train Acc: 0.870513 | Val Loss: 0.114699, Val Acc: 0.783505\n",
      "Epoch 17268 - Train Loss: 0.088684, Train Acc: 0.870513 | Val Loss: 0.114697, Val Acc: 0.783505\n",
      "Epoch 17269 - Train Loss: 0.088681, Train Acc: 0.870513 | Val Loss: 0.114696, Val Acc: 0.783505\n",
      "Epoch 17270 - Train Loss: 0.088678, Train Acc: 0.870513 | Val Loss: 0.114694, Val Acc: 0.783505\n",
      "Epoch 17271 - Train Loss: 0.088674, Train Acc: 0.870513 | Val Loss: 0.114692, Val Acc: 0.783505\n",
      "Epoch 17272 - Train Loss: 0.088671, Train Acc: 0.870513 | Val Loss: 0.114690, Val Acc: 0.783505\n",
      "Epoch 17273 - Train Loss: 0.088668, Train Acc: 0.870513 | Val Loss: 0.114689, Val Acc: 0.783505\n",
      "Epoch 17274 - Train Loss: 0.088665, Train Acc: 0.870513 | Val Loss: 0.114687, Val Acc: 0.783505\n",
      "Epoch 17275 - Train Loss: 0.088662, Train Acc: 0.870513 | Val Loss: 0.114685, Val Acc: 0.783505\n",
      "Epoch 17276 - Train Loss: 0.088659, Train Acc: 0.870513 | Val Loss: 0.114683, Val Acc: 0.783505\n",
      "Epoch 17277 - Train Loss: 0.088656, Train Acc: 0.870513 | Val Loss: 0.114682, Val Acc: 0.783505\n",
      "Epoch 17278 - Train Loss: 0.088653, Train Acc: 0.870513 | Val Loss: 0.114680, Val Acc: 0.783505\n",
      "Epoch 17279 - Train Loss: 0.088650, Train Acc: 0.870513 | Val Loss: 0.114678, Val Acc: 0.783505\n",
      "Epoch 17280 - Train Loss: 0.088647, Train Acc: 0.870513 | Val Loss: 0.114677, Val Acc: 0.783505\n",
      "Epoch 17281 - Train Loss: 0.088644, Train Acc: 0.870513 | Val Loss: 0.114675, Val Acc: 0.783505\n",
      "Epoch 17282 - Train Loss: 0.088640, Train Acc: 0.870513 | Val Loss: 0.114673, Val Acc: 0.783505\n",
      "Epoch 17283 - Train Loss: 0.088637, Train Acc: 0.870513 | Val Loss: 0.114671, Val Acc: 0.783505\n",
      "Epoch 17284 - Train Loss: 0.088634, Train Acc: 0.870513 | Val Loss: 0.114670, Val Acc: 0.783505\n",
      "Epoch 17285 - Train Loss: 0.088631, Train Acc: 0.870513 | Val Loss: 0.114668, Val Acc: 0.783505\n",
      "Epoch 17286 - Train Loss: 0.088628, Train Acc: 0.870513 | Val Loss: 0.114666, Val Acc: 0.783505\n",
      "Epoch 17287 - Train Loss: 0.088625, Train Acc: 0.870513 | Val Loss: 0.114665, Val Acc: 0.783505\n",
      "Epoch 17288 - Train Loss: 0.088622, Train Acc: 0.870513 | Val Loss: 0.114663, Val Acc: 0.783505\n",
      "Epoch 17289 - Train Loss: 0.088619, Train Acc: 0.870513 | Val Loss: 0.114661, Val Acc: 0.783505\n",
      "Epoch 17290 - Train Loss: 0.088616, Train Acc: 0.870513 | Val Loss: 0.114659, Val Acc: 0.783505\n",
      "Epoch 17291 - Train Loss: 0.088613, Train Acc: 0.870513 | Val Loss: 0.114658, Val Acc: 0.783505\n",
      "Epoch 17292 - Train Loss: 0.088609, Train Acc: 0.870513 | Val Loss: 0.114656, Val Acc: 0.783505\n",
      "Epoch 17293 - Train Loss: 0.088606, Train Acc: 0.870513 | Val Loss: 0.114654, Val Acc: 0.783505\n",
      "Epoch 17294 - Train Loss: 0.088603, Train Acc: 0.871795 | Val Loss: 0.114652, Val Acc: 0.783505\n",
      "Epoch 17295 - Train Loss: 0.088600, Train Acc: 0.871795 | Val Loss: 0.114651, Val Acc: 0.783505\n",
      "Epoch 17296 - Train Loss: 0.088597, Train Acc: 0.871795 | Val Loss: 0.114649, Val Acc: 0.783505\n",
      "Epoch 17297 - Train Loss: 0.088594, Train Acc: 0.871795 | Val Loss: 0.114647, Val Acc: 0.783505\n",
      "Epoch 17298 - Train Loss: 0.088591, Train Acc: 0.871795 | Val Loss: 0.114646, Val Acc: 0.783505\n",
      "Epoch 17299 - Train Loss: 0.088588, Train Acc: 0.871795 | Val Loss: 0.114644, Val Acc: 0.783505\n",
      "Epoch 17300 - Train Loss: 0.088585, Train Acc: 0.871795 | Val Loss: 0.114642, Val Acc: 0.783505\n",
      "Epoch 17301 - Train Loss: 0.088582, Train Acc: 0.871795 | Val Loss: 0.114640, Val Acc: 0.783505\n",
      "Epoch 17302 - Train Loss: 0.088579, Train Acc: 0.871795 | Val Loss: 0.114639, Val Acc: 0.783505\n",
      "Epoch 17303 - Train Loss: 0.088575, Train Acc: 0.871795 | Val Loss: 0.114637, Val Acc: 0.783505\n",
      "Epoch 17304 - Train Loss: 0.088572, Train Acc: 0.871795 | Val Loss: 0.114635, Val Acc: 0.783505\n",
      "Epoch 17305 - Train Loss: 0.088569, Train Acc: 0.871795 | Val Loss: 0.114634, Val Acc: 0.783505\n",
      "Epoch 17306 - Train Loss: 0.088566, Train Acc: 0.871795 | Val Loss: 0.114632, Val Acc: 0.783505\n",
      "Epoch 17307 - Train Loss: 0.088563, Train Acc: 0.871795 | Val Loss: 0.114630, Val Acc: 0.783505\n",
      "Epoch 17308 - Train Loss: 0.088560, Train Acc: 0.871795 | Val Loss: 0.114628, Val Acc: 0.783505\n",
      "Epoch 17309 - Train Loss: 0.088557, Train Acc: 0.871795 | Val Loss: 0.114627, Val Acc: 0.783505\n",
      "Epoch 17310 - Train Loss: 0.088554, Train Acc: 0.871795 | Val Loss: 0.114625, Val Acc: 0.783505\n",
      "Epoch 17311 - Train Loss: 0.088551, Train Acc: 0.871795 | Val Loss: 0.114623, Val Acc: 0.783505\n",
      "Epoch 17312 - Train Loss: 0.088548, Train Acc: 0.871795 | Val Loss: 0.114622, Val Acc: 0.783505\n",
      "Epoch 17313 - Train Loss: 0.088545, Train Acc: 0.871795 | Val Loss: 0.114620, Val Acc: 0.783505\n",
      "Epoch 17314 - Train Loss: 0.088542, Train Acc: 0.871795 | Val Loss: 0.114618, Val Acc: 0.783505\n",
      "Epoch 17315 - Train Loss: 0.088538, Train Acc: 0.871795 | Val Loss: 0.114616, Val Acc: 0.783505\n",
      "Epoch 17316 - Train Loss: 0.088535, Train Acc: 0.871795 | Val Loss: 0.114615, Val Acc: 0.783505\n",
      "Epoch 17317 - Train Loss: 0.088532, Train Acc: 0.871795 | Val Loss: 0.114613, Val Acc: 0.783505\n",
      "Epoch 17318 - Train Loss: 0.088529, Train Acc: 0.871795 | Val Loss: 0.114611, Val Acc: 0.783505\n",
      "Epoch 17319 - Train Loss: 0.088526, Train Acc: 0.871795 | Val Loss: 0.114610, Val Acc: 0.783505\n",
      "Epoch 17320 - Train Loss: 0.088523, Train Acc: 0.871795 | Val Loss: 0.114608, Val Acc: 0.783505\n",
      "Epoch 17321 - Train Loss: 0.088520, Train Acc: 0.871795 | Val Loss: 0.114606, Val Acc: 0.783505\n",
      "Epoch 17322 - Train Loss: 0.088517, Train Acc: 0.871795 | Val Loss: 0.114604, Val Acc: 0.783505\n",
      "Epoch 17323 - Train Loss: 0.088514, Train Acc: 0.871795 | Val Loss: 0.114603, Val Acc: 0.783505\n",
      "Epoch 17324 - Train Loss: 0.088511, Train Acc: 0.871795 | Val Loss: 0.114601, Val Acc: 0.783505\n",
      "Epoch 17325 - Train Loss: 0.088508, Train Acc: 0.871795 | Val Loss: 0.114599, Val Acc: 0.783505\n",
      "Epoch 17326 - Train Loss: 0.088505, Train Acc: 0.871795 | Val Loss: 0.114598, Val Acc: 0.783505\n",
      "Epoch 17327 - Train Loss: 0.088501, Train Acc: 0.871795 | Val Loss: 0.114596, Val Acc: 0.783505\n",
      "Epoch 17328 - Train Loss: 0.088498, Train Acc: 0.871795 | Val Loss: 0.114594, Val Acc: 0.783505\n",
      "Epoch 17329 - Train Loss: 0.088495, Train Acc: 0.871795 | Val Loss: 0.114593, Val Acc: 0.783505\n",
      "Epoch 17330 - Train Loss: 0.088492, Train Acc: 0.871795 | Val Loss: 0.114591, Val Acc: 0.783505\n",
      "Epoch 17331 - Train Loss: 0.088489, Train Acc: 0.871795 | Val Loss: 0.114589, Val Acc: 0.783505\n",
      "Epoch 17332 - Train Loss: 0.088486, Train Acc: 0.871795 | Val Loss: 0.114587, Val Acc: 0.783505\n",
      "Epoch 17333 - Train Loss: 0.088483, Train Acc: 0.871795 | Val Loss: 0.114586, Val Acc: 0.783505\n",
      "Epoch 17334 - Train Loss: 0.088480, Train Acc: 0.871795 | Val Loss: 0.114584, Val Acc: 0.783505\n",
      "Epoch 17335 - Train Loss: 0.088477, Train Acc: 0.871795 | Val Loss: 0.114582, Val Acc: 0.783505\n",
      "Epoch 17336 - Train Loss: 0.088474, Train Acc: 0.871795 | Val Loss: 0.114581, Val Acc: 0.783505\n",
      "Epoch 17337 - Train Loss: 0.088471, Train Acc: 0.871795 | Val Loss: 0.114579, Val Acc: 0.783505\n",
      "Epoch 17338 - Train Loss: 0.088468, Train Acc: 0.871795 | Val Loss: 0.114577, Val Acc: 0.783505\n",
      "Epoch 17339 - Train Loss: 0.088465, Train Acc: 0.871795 | Val Loss: 0.114575, Val Acc: 0.783505\n",
      "Epoch 17340 - Train Loss: 0.088461, Train Acc: 0.871795 | Val Loss: 0.114574, Val Acc: 0.783505\n",
      "Epoch 17341 - Train Loss: 0.088458, Train Acc: 0.871795 | Val Loss: 0.114572, Val Acc: 0.783505\n",
      "Epoch 17342 - Train Loss: 0.088455, Train Acc: 0.871795 | Val Loss: 0.114570, Val Acc: 0.783505\n",
      "Epoch 17343 - Train Loss: 0.088452, Train Acc: 0.871795 | Val Loss: 0.114569, Val Acc: 0.783505\n",
      "Epoch 17344 - Train Loss: 0.088449, Train Acc: 0.871795 | Val Loss: 0.114567, Val Acc: 0.783505\n",
      "Epoch 17345 - Train Loss: 0.088446, Train Acc: 0.871795 | Val Loss: 0.114565, Val Acc: 0.783505\n",
      "Epoch 17346 - Train Loss: 0.088443, Train Acc: 0.871795 | Val Loss: 0.114564, Val Acc: 0.783505\n",
      "Epoch 17347 - Train Loss: 0.088440, Train Acc: 0.871795 | Val Loss: 0.114562, Val Acc: 0.783505\n",
      "Epoch 17348 - Train Loss: 0.088437, Train Acc: 0.871795 | Val Loss: 0.114560, Val Acc: 0.783505\n",
      "Epoch 17349 - Train Loss: 0.088434, Train Acc: 0.871795 | Val Loss: 0.114558, Val Acc: 0.783505\n",
      "Epoch 17350 - Train Loss: 0.088431, Train Acc: 0.871795 | Val Loss: 0.114557, Val Acc: 0.783505\n",
      "Epoch 17351 - Train Loss: 0.088428, Train Acc: 0.871795 | Val Loss: 0.114555, Val Acc: 0.783505\n",
      "Epoch 17352 - Train Loss: 0.088425, Train Acc: 0.871795 | Val Loss: 0.114553, Val Acc: 0.783505\n",
      "Epoch 17353 - Train Loss: 0.088422, Train Acc: 0.871795 | Val Loss: 0.114552, Val Acc: 0.783505\n",
      "Epoch 17354 - Train Loss: 0.088418, Train Acc: 0.871795 | Val Loss: 0.114550, Val Acc: 0.783505\n",
      "Epoch 17355 - Train Loss: 0.088415, Train Acc: 0.871795 | Val Loss: 0.114548, Val Acc: 0.783505\n",
      "Epoch 17356 - Train Loss: 0.088412, Train Acc: 0.871795 | Val Loss: 0.114547, Val Acc: 0.783505\n",
      "Epoch 17357 - Train Loss: 0.088409, Train Acc: 0.871795 | Val Loss: 0.114545, Val Acc: 0.783505\n",
      "Epoch 17358 - Train Loss: 0.088406, Train Acc: 0.871795 | Val Loss: 0.114543, Val Acc: 0.783505\n",
      "Epoch 17359 - Train Loss: 0.088403, Train Acc: 0.871795 | Val Loss: 0.114541, Val Acc: 0.783505\n",
      "Epoch 17360 - Train Loss: 0.088400, Train Acc: 0.871795 | Val Loss: 0.114540, Val Acc: 0.783505\n",
      "Epoch 17361 - Train Loss: 0.088397, Train Acc: 0.871795 | Val Loss: 0.114538, Val Acc: 0.783505\n",
      "Epoch 17362 - Train Loss: 0.088394, Train Acc: 0.871795 | Val Loss: 0.114536, Val Acc: 0.783505\n",
      "Epoch 17363 - Train Loss: 0.088391, Train Acc: 0.871795 | Val Loss: 0.114535, Val Acc: 0.783505\n",
      "Epoch 17364 - Train Loss: 0.088388, Train Acc: 0.871795 | Val Loss: 0.114533, Val Acc: 0.783505\n",
      "Epoch 17365 - Train Loss: 0.088385, Train Acc: 0.871795 | Val Loss: 0.114531, Val Acc: 0.783505\n",
      "Epoch 17366 - Train Loss: 0.088382, Train Acc: 0.871795 | Val Loss: 0.114530, Val Acc: 0.783505\n",
      "Epoch 17367 - Train Loss: 0.088379, Train Acc: 0.871795 | Val Loss: 0.114528, Val Acc: 0.783505\n",
      "Epoch 17368 - Train Loss: 0.088376, Train Acc: 0.871795 | Val Loss: 0.114526, Val Acc: 0.783505\n",
      "Epoch 17369 - Train Loss: 0.088372, Train Acc: 0.871795 | Val Loss: 0.114525, Val Acc: 0.783505\n",
      "Epoch 17370 - Train Loss: 0.088369, Train Acc: 0.871795 | Val Loss: 0.114523, Val Acc: 0.783505\n",
      "Epoch 17371 - Train Loss: 0.088366, Train Acc: 0.871795 | Val Loss: 0.114521, Val Acc: 0.783505\n",
      "Epoch 17372 - Train Loss: 0.088363, Train Acc: 0.871795 | Val Loss: 0.114519, Val Acc: 0.783505\n",
      "Epoch 17373 - Train Loss: 0.088360, Train Acc: 0.871795 | Val Loss: 0.114518, Val Acc: 0.783505\n",
      "Epoch 17374 - Train Loss: 0.088357, Train Acc: 0.871795 | Val Loss: 0.114516, Val Acc: 0.783505\n",
      "Epoch 17375 - Train Loss: 0.088354, Train Acc: 0.871795 | Val Loss: 0.114514, Val Acc: 0.783505\n",
      "Epoch 17376 - Train Loss: 0.088351, Train Acc: 0.871795 | Val Loss: 0.114513, Val Acc: 0.783505\n",
      "Epoch 17377 - Train Loss: 0.088348, Train Acc: 0.871795 | Val Loss: 0.114511, Val Acc: 0.783505\n",
      "Epoch 17378 - Train Loss: 0.088345, Train Acc: 0.871795 | Val Loss: 0.114509, Val Acc: 0.783505\n",
      "Epoch 17379 - Train Loss: 0.088342, Train Acc: 0.871795 | Val Loss: 0.114508, Val Acc: 0.783505\n",
      "Epoch 17380 - Train Loss: 0.088339, Train Acc: 0.871795 | Val Loss: 0.114506, Val Acc: 0.783505\n",
      "Epoch 17381 - Train Loss: 0.088336, Train Acc: 0.871795 | Val Loss: 0.114504, Val Acc: 0.783505\n",
      "Epoch 17382 - Train Loss: 0.088333, Train Acc: 0.871795 | Val Loss: 0.114503, Val Acc: 0.783505\n",
      "Epoch 17383 - Train Loss: 0.088330, Train Acc: 0.871795 | Val Loss: 0.114501, Val Acc: 0.783505\n",
      "Epoch 17384 - Train Loss: 0.088327, Train Acc: 0.871795 | Val Loss: 0.114499, Val Acc: 0.783505\n",
      "Epoch 17385 - Train Loss: 0.088324, Train Acc: 0.871795 | Val Loss: 0.114498, Val Acc: 0.783505\n",
      "Epoch 17386 - Train Loss: 0.088320, Train Acc: 0.871795 | Val Loss: 0.114496, Val Acc: 0.783505\n",
      "Epoch 17387 - Train Loss: 0.088317, Train Acc: 0.871795 | Val Loss: 0.114494, Val Acc: 0.783505\n",
      "Epoch 17388 - Train Loss: 0.088314, Train Acc: 0.871795 | Val Loss: 0.114492, Val Acc: 0.783505\n",
      "Epoch 17389 - Train Loss: 0.088311, Train Acc: 0.871795 | Val Loss: 0.114491, Val Acc: 0.783505\n",
      "Epoch 17390 - Train Loss: 0.088308, Train Acc: 0.871795 | Val Loss: 0.114489, Val Acc: 0.783505\n",
      "Epoch 17391 - Train Loss: 0.088305, Train Acc: 0.871795 | Val Loss: 0.114487, Val Acc: 0.783505\n",
      "Epoch 17392 - Train Loss: 0.088302, Train Acc: 0.871795 | Val Loss: 0.114486, Val Acc: 0.783505\n",
      "Epoch 17393 - Train Loss: 0.088299, Train Acc: 0.871795 | Val Loss: 0.114484, Val Acc: 0.783505\n",
      "Epoch 17394 - Train Loss: 0.088296, Train Acc: 0.871795 | Val Loss: 0.114482, Val Acc: 0.783505\n",
      "Epoch 17395 - Train Loss: 0.088293, Train Acc: 0.871795 | Val Loss: 0.114481, Val Acc: 0.783505\n",
      "Epoch 17396 - Train Loss: 0.088290, Train Acc: 0.871795 | Val Loss: 0.114479, Val Acc: 0.783505\n",
      "Epoch 17397 - Train Loss: 0.088287, Train Acc: 0.871795 | Val Loss: 0.114477, Val Acc: 0.783505\n",
      "Epoch 17398 - Train Loss: 0.088284, Train Acc: 0.871795 | Val Loss: 0.114476, Val Acc: 0.783505\n",
      "Epoch 17399 - Train Loss: 0.088281, Train Acc: 0.871795 | Val Loss: 0.114474, Val Acc: 0.783505\n",
      "Epoch 17400 - Train Loss: 0.088278, Train Acc: 0.871795 | Val Loss: 0.114472, Val Acc: 0.783505\n",
      "Epoch 17401 - Train Loss: 0.088275, Train Acc: 0.871795 | Val Loss: 0.114471, Val Acc: 0.783505\n",
      "Epoch 17402 - Train Loss: 0.088272, Train Acc: 0.871795 | Val Loss: 0.114469, Val Acc: 0.783505\n",
      "Epoch 17403 - Train Loss: 0.088269, Train Acc: 0.871795 | Val Loss: 0.114467, Val Acc: 0.783505\n",
      "Epoch 17404 - Train Loss: 0.088265, Train Acc: 0.871795 | Val Loss: 0.114466, Val Acc: 0.783505\n",
      "Epoch 17405 - Train Loss: 0.088262, Train Acc: 0.871795 | Val Loss: 0.114464, Val Acc: 0.783505\n",
      "Epoch 17406 - Train Loss: 0.088259, Train Acc: 0.871795 | Val Loss: 0.114462, Val Acc: 0.783505\n",
      "Epoch 17407 - Train Loss: 0.088256, Train Acc: 0.871795 | Val Loss: 0.114460, Val Acc: 0.783505\n",
      "Epoch 17408 - Train Loss: 0.088253, Train Acc: 0.871795 | Val Loss: 0.114459, Val Acc: 0.783505\n",
      "Epoch 17409 - Train Loss: 0.088250, Train Acc: 0.871795 | Val Loss: 0.114457, Val Acc: 0.783505\n",
      "Epoch 17410 - Train Loss: 0.088247, Train Acc: 0.871795 | Val Loss: 0.114455, Val Acc: 0.783505\n",
      "Epoch 17411 - Train Loss: 0.088244, Train Acc: 0.871795 | Val Loss: 0.114454, Val Acc: 0.783505\n",
      "Epoch 17412 - Train Loss: 0.088241, Train Acc: 0.871795 | Val Loss: 0.114452, Val Acc: 0.783505\n",
      "Epoch 17413 - Train Loss: 0.088238, Train Acc: 0.871795 | Val Loss: 0.114450, Val Acc: 0.783505\n",
      "Epoch 17414 - Train Loss: 0.088235, Train Acc: 0.871795 | Val Loss: 0.114449, Val Acc: 0.783505\n",
      "Epoch 17415 - Train Loss: 0.088232, Train Acc: 0.871795 | Val Loss: 0.114447, Val Acc: 0.783505\n",
      "Epoch 17416 - Train Loss: 0.088229, Train Acc: 0.871795 | Val Loss: 0.114445, Val Acc: 0.783505\n",
      "Epoch 17417 - Train Loss: 0.088226, Train Acc: 0.871795 | Val Loss: 0.114444, Val Acc: 0.783505\n",
      "Epoch 17418 - Train Loss: 0.088223, Train Acc: 0.871795 | Val Loss: 0.114442, Val Acc: 0.783505\n",
      "Epoch 17419 - Train Loss: 0.088220, Train Acc: 0.871795 | Val Loss: 0.114440, Val Acc: 0.783505\n",
      "Epoch 17420 - Train Loss: 0.088217, Train Acc: 0.871795 | Val Loss: 0.114439, Val Acc: 0.783505\n",
      "Epoch 17421 - Train Loss: 0.088214, Train Acc: 0.871795 | Val Loss: 0.114437, Val Acc: 0.783505\n",
      "Epoch 17422 - Train Loss: 0.088211, Train Acc: 0.871795 | Val Loss: 0.114435, Val Acc: 0.783505\n",
      "Epoch 17423 - Train Loss: 0.088208, Train Acc: 0.871795 | Val Loss: 0.114434, Val Acc: 0.783505\n",
      "Epoch 17424 - Train Loss: 0.088205, Train Acc: 0.871795 | Val Loss: 0.114432, Val Acc: 0.783505\n",
      "Epoch 17425 - Train Loss: 0.088201, Train Acc: 0.871795 | Val Loss: 0.114430, Val Acc: 0.783505\n",
      "Epoch 17426 - Train Loss: 0.088198, Train Acc: 0.871795 | Val Loss: 0.114429, Val Acc: 0.783505\n",
      "Epoch 17427 - Train Loss: 0.088195, Train Acc: 0.871795 | Val Loss: 0.114427, Val Acc: 0.783505\n",
      "Epoch 17428 - Train Loss: 0.088192, Train Acc: 0.871795 | Val Loss: 0.114425, Val Acc: 0.783505\n",
      "Epoch 17429 - Train Loss: 0.088189, Train Acc: 0.871795 | Val Loss: 0.114424, Val Acc: 0.783505\n",
      "Epoch 17430 - Train Loss: 0.088186, Train Acc: 0.871795 | Val Loss: 0.114422, Val Acc: 0.783505\n",
      "Epoch 17431 - Train Loss: 0.088183, Train Acc: 0.871795 | Val Loss: 0.114420, Val Acc: 0.783505\n",
      "Epoch 17432 - Train Loss: 0.088180, Train Acc: 0.871795 | Val Loss: 0.114419, Val Acc: 0.783505\n",
      "Epoch 17433 - Train Loss: 0.088177, Train Acc: 0.871795 | Val Loss: 0.114417, Val Acc: 0.783505\n",
      "Epoch 17434 - Train Loss: 0.088174, Train Acc: 0.871795 | Val Loss: 0.114415, Val Acc: 0.783505\n",
      "Epoch 17435 - Train Loss: 0.088171, Train Acc: 0.871795 | Val Loss: 0.114414, Val Acc: 0.783505\n",
      "Epoch 17436 - Train Loss: 0.088168, Train Acc: 0.871795 | Val Loss: 0.114412, Val Acc: 0.783505\n",
      "Epoch 17437 - Train Loss: 0.088165, Train Acc: 0.871795 | Val Loss: 0.114410, Val Acc: 0.783505\n",
      "Epoch 17438 - Train Loss: 0.088162, Train Acc: 0.871795 | Val Loss: 0.114409, Val Acc: 0.783505\n",
      "Epoch 17439 - Train Loss: 0.088159, Train Acc: 0.871795 | Val Loss: 0.114407, Val Acc: 0.783505\n",
      "Epoch 17440 - Train Loss: 0.088156, Train Acc: 0.871795 | Val Loss: 0.114405, Val Acc: 0.783505\n",
      "Epoch 17441 - Train Loss: 0.088153, Train Acc: 0.871795 | Val Loss: 0.114404, Val Acc: 0.783505\n",
      "Epoch 17442 - Train Loss: 0.088150, Train Acc: 0.871795 | Val Loss: 0.114402, Val Acc: 0.783505\n",
      "Epoch 17443 - Train Loss: 0.088147, Train Acc: 0.871795 | Val Loss: 0.114400, Val Acc: 0.783505\n",
      "Epoch 17444 - Train Loss: 0.088144, Train Acc: 0.871795 | Val Loss: 0.114399, Val Acc: 0.783505\n",
      "Epoch 17445 - Train Loss: 0.088141, Train Acc: 0.871795 | Val Loss: 0.114397, Val Acc: 0.783505\n",
      "Epoch 17446 - Train Loss: 0.088138, Train Acc: 0.871795 | Val Loss: 0.114395, Val Acc: 0.783505\n",
      "Epoch 17447 - Train Loss: 0.088135, Train Acc: 0.871795 | Val Loss: 0.114394, Val Acc: 0.783505\n",
      "Epoch 17448 - Train Loss: 0.088132, Train Acc: 0.871795 | Val Loss: 0.114392, Val Acc: 0.783505\n",
      "Epoch 17449 - Train Loss: 0.088129, Train Acc: 0.871795 | Val Loss: 0.114390, Val Acc: 0.783505\n",
      "Epoch 17450 - Train Loss: 0.088125, Train Acc: 0.871795 | Val Loss: 0.114389, Val Acc: 0.783505\n",
      "Epoch 17451 - Train Loss: 0.088122, Train Acc: 0.871795 | Val Loss: 0.114387, Val Acc: 0.783505\n",
      "Epoch 17452 - Train Loss: 0.088119, Train Acc: 0.871795 | Val Loss: 0.114385, Val Acc: 0.783505\n",
      "Epoch 17453 - Train Loss: 0.088116, Train Acc: 0.871795 | Val Loss: 0.114384, Val Acc: 0.783505\n",
      "Epoch 17454 - Train Loss: 0.088113, Train Acc: 0.871795 | Val Loss: 0.114382, Val Acc: 0.783505\n",
      "Epoch 17455 - Train Loss: 0.088110, Train Acc: 0.871795 | Val Loss: 0.114380, Val Acc: 0.783505\n",
      "Epoch 17456 - Train Loss: 0.088107, Train Acc: 0.871795 | Val Loss: 0.114379, Val Acc: 0.783505\n",
      "Epoch 17457 - Train Loss: 0.088104, Train Acc: 0.871795 | Val Loss: 0.114377, Val Acc: 0.783505\n",
      "Epoch 17458 - Train Loss: 0.088101, Train Acc: 0.871795 | Val Loss: 0.114375, Val Acc: 0.783505\n",
      "Epoch 17459 - Train Loss: 0.088098, Train Acc: 0.871795 | Val Loss: 0.114374, Val Acc: 0.783505\n",
      "Epoch 17460 - Train Loss: 0.088095, Train Acc: 0.871795 | Val Loss: 0.114372, Val Acc: 0.783505\n",
      "Epoch 17461 - Train Loss: 0.088092, Train Acc: 0.871795 | Val Loss: 0.114370, Val Acc: 0.783505\n",
      "Epoch 17462 - Train Loss: 0.088089, Train Acc: 0.871795 | Val Loss: 0.114369, Val Acc: 0.783505\n",
      "Epoch 17463 - Train Loss: 0.088086, Train Acc: 0.871795 | Val Loss: 0.114367, Val Acc: 0.783505\n",
      "Epoch 17464 - Train Loss: 0.088083, Train Acc: 0.871795 | Val Loss: 0.114365, Val Acc: 0.783505\n",
      "Epoch 17465 - Train Loss: 0.088080, Train Acc: 0.871795 | Val Loss: 0.114364, Val Acc: 0.783505\n",
      "Epoch 17466 - Train Loss: 0.088077, Train Acc: 0.871795 | Val Loss: 0.114362, Val Acc: 0.783505\n",
      "Epoch 17467 - Train Loss: 0.088074, Train Acc: 0.871795 | Val Loss: 0.114360, Val Acc: 0.783505\n",
      "Epoch 17468 - Train Loss: 0.088071, Train Acc: 0.871795 | Val Loss: 0.114359, Val Acc: 0.783505\n",
      "Epoch 17469 - Train Loss: 0.088068, Train Acc: 0.871795 | Val Loss: 0.114357, Val Acc: 0.783505\n",
      "Epoch 17470 - Train Loss: 0.088065, Train Acc: 0.871795 | Val Loss: 0.114355, Val Acc: 0.783505\n",
      "Epoch 17471 - Train Loss: 0.088062, Train Acc: 0.871795 | Val Loss: 0.114354, Val Acc: 0.783505\n",
      "Epoch 17472 - Train Loss: 0.088059, Train Acc: 0.871795 | Val Loss: 0.114352, Val Acc: 0.783505\n",
      "Epoch 17473 - Train Loss: 0.088056, Train Acc: 0.871795 | Val Loss: 0.114351, Val Acc: 0.783505\n",
      "Epoch 17474 - Train Loss: 0.088053, Train Acc: 0.871795 | Val Loss: 0.114349, Val Acc: 0.783505\n",
      "Epoch 17475 - Train Loss: 0.088050, Train Acc: 0.871795 | Val Loss: 0.114347, Val Acc: 0.783505\n",
      "Epoch 17476 - Train Loss: 0.088047, Train Acc: 0.871795 | Val Loss: 0.114346, Val Acc: 0.783505\n",
      "Epoch 17477 - Train Loss: 0.088044, Train Acc: 0.871795 | Val Loss: 0.114344, Val Acc: 0.783505\n",
      "Epoch 17478 - Train Loss: 0.088041, Train Acc: 0.871795 | Val Loss: 0.114342, Val Acc: 0.783505\n",
      "Epoch 17479 - Train Loss: 0.088038, Train Acc: 0.871795 | Val Loss: 0.114341, Val Acc: 0.783505\n",
      "Epoch 17480 - Train Loss: 0.088035, Train Acc: 0.871795 | Val Loss: 0.114339, Val Acc: 0.783505\n",
      "Epoch 17481 - Train Loss: 0.088032, Train Acc: 0.871795 | Val Loss: 0.114337, Val Acc: 0.783505\n",
      "Epoch 17482 - Train Loss: 0.088029, Train Acc: 0.871795 | Val Loss: 0.114336, Val Acc: 0.783505\n",
      "Epoch 17483 - Train Loss: 0.088026, Train Acc: 0.871795 | Val Loss: 0.114334, Val Acc: 0.783505\n",
      "Epoch 17484 - Train Loss: 0.088022, Train Acc: 0.871795 | Val Loss: 0.114332, Val Acc: 0.783505\n",
      "Epoch 17485 - Train Loss: 0.088019, Train Acc: 0.871795 | Val Loss: 0.114331, Val Acc: 0.783505\n",
      "Epoch 17486 - Train Loss: 0.088016, Train Acc: 0.871795 | Val Loss: 0.114329, Val Acc: 0.783505\n",
      "Epoch 17487 - Train Loss: 0.088013, Train Acc: 0.871795 | Val Loss: 0.114327, Val Acc: 0.783505\n",
      "Epoch 17488 - Train Loss: 0.088010, Train Acc: 0.871795 | Val Loss: 0.114326, Val Acc: 0.783505\n",
      "Epoch 17489 - Train Loss: 0.088007, Train Acc: 0.871795 | Val Loss: 0.114324, Val Acc: 0.783505\n",
      "Epoch 17490 - Train Loss: 0.088004, Train Acc: 0.871795 | Val Loss: 0.114322, Val Acc: 0.783505\n",
      "Epoch 17491 - Train Loss: 0.088001, Train Acc: 0.871795 | Val Loss: 0.114321, Val Acc: 0.783505\n",
      "Epoch 17492 - Train Loss: 0.087998, Train Acc: 0.871795 | Val Loss: 0.114319, Val Acc: 0.783505\n",
      "Epoch 17493 - Train Loss: 0.087995, Train Acc: 0.871795 | Val Loss: 0.114317, Val Acc: 0.783505\n",
      "Epoch 17494 - Train Loss: 0.087992, Train Acc: 0.871795 | Val Loss: 0.114316, Val Acc: 0.783505\n",
      "Epoch 17495 - Train Loss: 0.087989, Train Acc: 0.871795 | Val Loss: 0.114314, Val Acc: 0.783505\n",
      "Epoch 17496 - Train Loss: 0.087986, Train Acc: 0.871795 | Val Loss: 0.114313, Val Acc: 0.783505\n",
      "Epoch 17497 - Train Loss: 0.087983, Train Acc: 0.871795 | Val Loss: 0.114311, Val Acc: 0.783505\n",
      "Epoch 17498 - Train Loss: 0.087980, Train Acc: 0.871795 | Val Loss: 0.114309, Val Acc: 0.783505\n",
      "Epoch 17499 - Train Loss: 0.087977, Train Acc: 0.871795 | Val Loss: 0.114308, Val Acc: 0.783505\n",
      "Epoch 17500 - Train Loss: 0.087974, Train Acc: 0.871795 | Val Loss: 0.114306, Val Acc: 0.783505\n",
      "Epoch 17501 - Train Loss: 0.087971, Train Acc: 0.871795 | Val Loss: 0.114304, Val Acc: 0.783505\n",
      "Epoch 17502 - Train Loss: 0.087968, Train Acc: 0.871795 | Val Loss: 0.114303, Val Acc: 0.783505\n",
      "Epoch 17503 - Train Loss: 0.087965, Train Acc: 0.871795 | Val Loss: 0.114301, Val Acc: 0.783505\n",
      "Epoch 17504 - Train Loss: 0.087962, Train Acc: 0.871795 | Val Loss: 0.114299, Val Acc: 0.783505\n",
      "Epoch 17505 - Train Loss: 0.087959, Train Acc: 0.871795 | Val Loss: 0.114298, Val Acc: 0.783505\n",
      "Epoch 17506 - Train Loss: 0.087956, Train Acc: 0.871795 | Val Loss: 0.114296, Val Acc: 0.783505\n",
      "Epoch 17507 - Train Loss: 0.087953, Train Acc: 0.871795 | Val Loss: 0.114294, Val Acc: 0.783505\n",
      "Epoch 17508 - Train Loss: 0.087950, Train Acc: 0.871795 | Val Loss: 0.114293, Val Acc: 0.783505\n",
      "Epoch 17509 - Train Loss: 0.087947, Train Acc: 0.871795 | Val Loss: 0.114291, Val Acc: 0.783505\n",
      "Epoch 17510 - Train Loss: 0.087944, Train Acc: 0.871795 | Val Loss: 0.114290, Val Acc: 0.783505\n",
      "Epoch 17511 - Train Loss: 0.087941, Train Acc: 0.871795 | Val Loss: 0.114288, Val Acc: 0.783505\n",
      "Epoch 17512 - Train Loss: 0.087938, Train Acc: 0.871795 | Val Loss: 0.114286, Val Acc: 0.783505\n",
      "Epoch 17513 - Train Loss: 0.087935, Train Acc: 0.871795 | Val Loss: 0.114285, Val Acc: 0.783505\n",
      "Epoch 17514 - Train Loss: 0.087932, Train Acc: 0.871795 | Val Loss: 0.114283, Val Acc: 0.783505\n",
      "Epoch 17515 - Train Loss: 0.087929, Train Acc: 0.871795 | Val Loss: 0.114281, Val Acc: 0.783505\n",
      "Epoch 17516 - Train Loss: 0.087926, Train Acc: 0.871795 | Val Loss: 0.114280, Val Acc: 0.783505\n",
      "Epoch 17517 - Train Loss: 0.087923, Train Acc: 0.873077 | Val Loss: 0.114278, Val Acc: 0.783505\n",
      "Epoch 17518 - Train Loss: 0.087920, Train Acc: 0.873077 | Val Loss: 0.114276, Val Acc: 0.783505\n",
      "Epoch 17519 - Train Loss: 0.087917, Train Acc: 0.873077 | Val Loss: 0.114275, Val Acc: 0.783505\n",
      "Epoch 17520 - Train Loss: 0.087914, Train Acc: 0.873077 | Val Loss: 0.114273, Val Acc: 0.783505\n",
      "Epoch 17521 - Train Loss: 0.087911, Train Acc: 0.873077 | Val Loss: 0.114272, Val Acc: 0.783505\n",
      "Epoch 17522 - Train Loss: 0.087908, Train Acc: 0.873077 | Val Loss: 0.114270, Val Acc: 0.783505\n",
      "Epoch 17523 - Train Loss: 0.087905, Train Acc: 0.873077 | Val Loss: 0.114268, Val Acc: 0.783505\n",
      "Epoch 17524 - Train Loss: 0.087902, Train Acc: 0.873077 | Val Loss: 0.114267, Val Acc: 0.783505\n",
      "Epoch 17525 - Train Loss: 0.087899, Train Acc: 0.873077 | Val Loss: 0.114265, Val Acc: 0.783505\n",
      "Epoch 17526 - Train Loss: 0.087896, Train Acc: 0.873077 | Val Loss: 0.114263, Val Acc: 0.783505\n",
      "Epoch 17527 - Train Loss: 0.087893, Train Acc: 0.873077 | Val Loss: 0.114262, Val Acc: 0.783505\n",
      "Epoch 17528 - Train Loss: 0.087890, Train Acc: 0.873077 | Val Loss: 0.114260, Val Acc: 0.783505\n",
      "Epoch 17529 - Train Loss: 0.087887, Train Acc: 0.873077 | Val Loss: 0.114259, Val Acc: 0.783505\n",
      "Epoch 17530 - Train Loss: 0.087884, Train Acc: 0.873077 | Val Loss: 0.114257, Val Acc: 0.783505\n",
      "Epoch 17531 - Train Loss: 0.087881, Train Acc: 0.873077 | Val Loss: 0.114255, Val Acc: 0.783505\n",
      "Epoch 17532 - Train Loss: 0.087878, Train Acc: 0.873077 | Val Loss: 0.114254, Val Acc: 0.783505\n",
      "Epoch 17533 - Train Loss: 0.087875, Train Acc: 0.873077 | Val Loss: 0.114252, Val Acc: 0.783505\n",
      "Epoch 17534 - Train Loss: 0.087872, Train Acc: 0.873077 | Val Loss: 0.114250, Val Acc: 0.783505\n",
      "Epoch 17535 - Train Loss: 0.087869, Train Acc: 0.873077 | Val Loss: 0.114249, Val Acc: 0.783505\n",
      "Epoch 17536 - Train Loss: 0.087866, Train Acc: 0.873077 | Val Loss: 0.114247, Val Acc: 0.783505\n",
      "Epoch 17537 - Train Loss: 0.087863, Train Acc: 0.873077 | Val Loss: 0.114245, Val Acc: 0.783505\n",
      "Epoch 17538 - Train Loss: 0.087860, Train Acc: 0.873077 | Val Loss: 0.114244, Val Acc: 0.783505\n",
      "Epoch 17539 - Train Loss: 0.087857, Train Acc: 0.873077 | Val Loss: 0.114242, Val Acc: 0.783505\n",
      "Epoch 17540 - Train Loss: 0.087854, Train Acc: 0.873077 | Val Loss: 0.114241, Val Acc: 0.783505\n",
      "Epoch 17541 - Train Loss: 0.087851, Train Acc: 0.873077 | Val Loss: 0.114239, Val Acc: 0.783505\n",
      "Epoch 17542 - Train Loss: 0.087848, Train Acc: 0.873077 | Val Loss: 0.114237, Val Acc: 0.783505\n",
      "Epoch 17543 - Train Loss: 0.087845, Train Acc: 0.873077 | Val Loss: 0.114236, Val Acc: 0.783505\n",
      "Epoch 17544 - Train Loss: 0.087842, Train Acc: 0.873077 | Val Loss: 0.114234, Val Acc: 0.783505\n",
      "Epoch 17545 - Train Loss: 0.087839, Train Acc: 0.873077 | Val Loss: 0.114232, Val Acc: 0.783505\n",
      "Epoch 17546 - Train Loss: 0.087836, Train Acc: 0.873077 | Val Loss: 0.114231, Val Acc: 0.783505\n",
      "Epoch 17547 - Train Loss: 0.087833, Train Acc: 0.873077 | Val Loss: 0.114229, Val Acc: 0.783505\n",
      "Epoch 17548 - Train Loss: 0.087830, Train Acc: 0.873077 | Val Loss: 0.114228, Val Acc: 0.783505\n",
      "Epoch 17549 - Train Loss: 0.087827, Train Acc: 0.873077 | Val Loss: 0.114226, Val Acc: 0.783505\n",
      "Epoch 17550 - Train Loss: 0.087824, Train Acc: 0.873077 | Val Loss: 0.114224, Val Acc: 0.783505\n",
      "Epoch 17551 - Train Loss: 0.087821, Train Acc: 0.873077 | Val Loss: 0.114223, Val Acc: 0.783505\n",
      "Epoch 17552 - Train Loss: 0.087818, Train Acc: 0.873077 | Val Loss: 0.114221, Val Acc: 0.783505\n",
      "Epoch 17553 - Train Loss: 0.087815, Train Acc: 0.873077 | Val Loss: 0.114219, Val Acc: 0.783505\n",
      "Epoch 17554 - Train Loss: 0.087812, Train Acc: 0.873077 | Val Loss: 0.114218, Val Acc: 0.783505\n",
      "Epoch 17555 - Train Loss: 0.087809, Train Acc: 0.873077 | Val Loss: 0.114216, Val Acc: 0.783505\n",
      "Epoch 17556 - Train Loss: 0.087806, Train Acc: 0.873077 | Val Loss: 0.114215, Val Acc: 0.783505\n",
      "Epoch 17557 - Train Loss: 0.087803, Train Acc: 0.873077 | Val Loss: 0.114213, Val Acc: 0.783505\n",
      "Epoch 17558 - Train Loss: 0.087800, Train Acc: 0.873077 | Val Loss: 0.114211, Val Acc: 0.783505\n",
      "Epoch 17559 - Train Loss: 0.087797, Train Acc: 0.873077 | Val Loss: 0.114210, Val Acc: 0.783505\n",
      "Epoch 17560 - Train Loss: 0.087794, Train Acc: 0.873077 | Val Loss: 0.114208, Val Acc: 0.783505\n",
      "Epoch 17561 - Train Loss: 0.087791, Train Acc: 0.873077 | Val Loss: 0.114207, Val Acc: 0.783505\n",
      "Epoch 17562 - Train Loss: 0.087788, Train Acc: 0.873077 | Val Loss: 0.114205, Val Acc: 0.783505\n",
      "Epoch 17563 - Train Loss: 0.087785, Train Acc: 0.873077 | Val Loss: 0.114203, Val Acc: 0.783505\n",
      "Epoch 17564 - Train Loss: 0.087782, Train Acc: 0.873077 | Val Loss: 0.114202, Val Acc: 0.783505\n",
      "Epoch 17565 - Train Loss: 0.087779, Train Acc: 0.873077 | Val Loss: 0.114200, Val Acc: 0.783505\n",
      "Epoch 17566 - Train Loss: 0.087776, Train Acc: 0.873077 | Val Loss: 0.114198, Val Acc: 0.783505\n",
      "Epoch 17567 - Train Loss: 0.087773, Train Acc: 0.873077 | Val Loss: 0.114197, Val Acc: 0.783505\n",
      "Epoch 17568 - Train Loss: 0.087770, Train Acc: 0.873077 | Val Loss: 0.114195, Val Acc: 0.783505\n",
      "Epoch 17569 - Train Loss: 0.087767, Train Acc: 0.873077 | Val Loss: 0.114194, Val Acc: 0.783505\n",
      "Epoch 17570 - Train Loss: 0.087764, Train Acc: 0.873077 | Val Loss: 0.114192, Val Acc: 0.783505\n",
      "Epoch 17571 - Train Loss: 0.087761, Train Acc: 0.873077 | Val Loss: 0.114190, Val Acc: 0.783505\n",
      "Epoch 17572 - Train Loss: 0.087758, Train Acc: 0.873077 | Val Loss: 0.114189, Val Acc: 0.783505\n",
      "Epoch 17573 - Train Loss: 0.087755, Train Acc: 0.873077 | Val Loss: 0.114187, Val Acc: 0.783505\n",
      "Epoch 17574 - Train Loss: 0.087752, Train Acc: 0.873077 | Val Loss: 0.114185, Val Acc: 0.783505\n",
      "Epoch 17575 - Train Loss: 0.087749, Train Acc: 0.873077 | Val Loss: 0.114184, Val Acc: 0.783505\n",
      "Epoch 17576 - Train Loss: 0.087746, Train Acc: 0.873077 | Val Loss: 0.114182, Val Acc: 0.783505\n",
      "Epoch 17577 - Train Loss: 0.087743, Train Acc: 0.873077 | Val Loss: 0.114181, Val Acc: 0.783505\n",
      "Epoch 17578 - Train Loss: 0.087740, Train Acc: 0.873077 | Val Loss: 0.114179, Val Acc: 0.783505\n",
      "Epoch 17579 - Train Loss: 0.087737, Train Acc: 0.873077 | Val Loss: 0.114177, Val Acc: 0.783505\n",
      "Epoch 17580 - Train Loss: 0.087734, Train Acc: 0.873077 | Val Loss: 0.114176, Val Acc: 0.783505\n",
      "Epoch 17581 - Train Loss: 0.087731, Train Acc: 0.873077 | Val Loss: 0.114174, Val Acc: 0.783505\n",
      "Epoch 17582 - Train Loss: 0.087728, Train Acc: 0.873077 | Val Loss: 0.114173, Val Acc: 0.783505\n",
      "Epoch 17583 - Train Loss: 0.087725, Train Acc: 0.873077 | Val Loss: 0.114171, Val Acc: 0.783505\n",
      "Epoch 17584 - Train Loss: 0.087722, Train Acc: 0.873077 | Val Loss: 0.114169, Val Acc: 0.783505\n",
      "Epoch 17585 - Train Loss: 0.087719, Train Acc: 0.873077 | Val Loss: 0.114168, Val Acc: 0.783505\n",
      "Epoch 17586 - Train Loss: 0.087716, Train Acc: 0.873077 | Val Loss: 0.114166, Val Acc: 0.783505\n",
      "Epoch 17587 - Train Loss: 0.087713, Train Acc: 0.873077 | Val Loss: 0.114164, Val Acc: 0.783505\n",
      "Epoch 17588 - Train Loss: 0.087710, Train Acc: 0.873077 | Val Loss: 0.114163, Val Acc: 0.783505\n",
      "Epoch 17589 - Train Loss: 0.087707, Train Acc: 0.873077 | Val Loss: 0.114161, Val Acc: 0.783505\n",
      "Epoch 17590 - Train Loss: 0.087704, Train Acc: 0.873077 | Val Loss: 0.114160, Val Acc: 0.783505\n",
      "Epoch 17591 - Train Loss: 0.087701, Train Acc: 0.873077 | Val Loss: 0.114158, Val Acc: 0.783505\n",
      "Epoch 17592 - Train Loss: 0.087698, Train Acc: 0.873077 | Val Loss: 0.114156, Val Acc: 0.783505\n",
      "Epoch 17593 - Train Loss: 0.087695, Train Acc: 0.873077 | Val Loss: 0.114155, Val Acc: 0.783505\n",
      "Epoch 17594 - Train Loss: 0.087692, Train Acc: 0.873077 | Val Loss: 0.114153, Val Acc: 0.783505\n",
      "Epoch 17595 - Train Loss: 0.087689, Train Acc: 0.873077 | Val Loss: 0.114152, Val Acc: 0.783505\n",
      "Epoch 17596 - Train Loss: 0.087686, Train Acc: 0.873077 | Val Loss: 0.114150, Val Acc: 0.783505\n",
      "Epoch 17597 - Train Loss: 0.087683, Train Acc: 0.873077 | Val Loss: 0.114148, Val Acc: 0.783505\n",
      "Epoch 17598 - Train Loss: 0.087680, Train Acc: 0.873077 | Val Loss: 0.114147, Val Acc: 0.783505\n",
      "Epoch 17599 - Train Loss: 0.087677, Train Acc: 0.873077 | Val Loss: 0.114145, Val Acc: 0.783505\n",
      "Epoch 17600 - Train Loss: 0.087674, Train Acc: 0.873077 | Val Loss: 0.114144, Val Acc: 0.783505\n",
      "Epoch 17601 - Train Loss: 0.087671, Train Acc: 0.873077 | Val Loss: 0.114142, Val Acc: 0.783505\n",
      "Epoch 17602 - Train Loss: 0.087668, Train Acc: 0.873077 | Val Loss: 0.114140, Val Acc: 0.783505\n",
      "Epoch 17603 - Train Loss: 0.087665, Train Acc: 0.873077 | Val Loss: 0.114139, Val Acc: 0.783505\n",
      "Epoch 17604 - Train Loss: 0.087662, Train Acc: 0.873077 | Val Loss: 0.114137, Val Acc: 0.783505\n",
      "Epoch 17605 - Train Loss: 0.087659, Train Acc: 0.873077 | Val Loss: 0.114135, Val Acc: 0.783505\n",
      "Epoch 17606 - Train Loss: 0.087656, Train Acc: 0.873077 | Val Loss: 0.114134, Val Acc: 0.783505\n",
      "Epoch 17607 - Train Loss: 0.087653, Train Acc: 0.873077 | Val Loss: 0.114132, Val Acc: 0.783505\n",
      "Epoch 17608 - Train Loss: 0.087650, Train Acc: 0.873077 | Val Loss: 0.114131, Val Acc: 0.783505\n",
      "Epoch 17609 - Train Loss: 0.087647, Train Acc: 0.873077 | Val Loss: 0.114129, Val Acc: 0.783505\n",
      "Epoch 17610 - Train Loss: 0.087644, Train Acc: 0.873077 | Val Loss: 0.114127, Val Acc: 0.783505\n",
      "Epoch 17611 - Train Loss: 0.087641, Train Acc: 0.873077 | Val Loss: 0.114126, Val Acc: 0.783505\n",
      "Epoch 17612 - Train Loss: 0.087638, Train Acc: 0.873077 | Val Loss: 0.114124, Val Acc: 0.783505\n",
      "Epoch 17613 - Train Loss: 0.087636, Train Acc: 0.873077 | Val Loss: 0.114123, Val Acc: 0.783505\n",
      "Epoch 17614 - Train Loss: 0.087633, Train Acc: 0.873077 | Val Loss: 0.114121, Val Acc: 0.783505\n",
      "Epoch 17615 - Train Loss: 0.087630, Train Acc: 0.873077 | Val Loss: 0.114119, Val Acc: 0.783505\n",
      "Epoch 17616 - Train Loss: 0.087627, Train Acc: 0.873077 | Val Loss: 0.114118, Val Acc: 0.783505\n",
      "Epoch 17617 - Train Loss: 0.087624, Train Acc: 0.873077 | Val Loss: 0.114116, Val Acc: 0.783505\n",
      "Epoch 17618 - Train Loss: 0.087621, Train Acc: 0.873077 | Val Loss: 0.114115, Val Acc: 0.783505\n",
      "Epoch 17619 - Train Loss: 0.087618, Train Acc: 0.873077 | Val Loss: 0.114113, Val Acc: 0.783505\n",
      "Epoch 17620 - Train Loss: 0.087615, Train Acc: 0.873077 | Val Loss: 0.114111, Val Acc: 0.783505\n",
      "Epoch 17621 - Train Loss: 0.087612, Train Acc: 0.873077 | Val Loss: 0.114110, Val Acc: 0.783505\n",
      "Epoch 17622 - Train Loss: 0.087609, Train Acc: 0.873077 | Val Loss: 0.114108, Val Acc: 0.783505\n",
      "Epoch 17623 - Train Loss: 0.087606, Train Acc: 0.873077 | Val Loss: 0.114107, Val Acc: 0.783505\n",
      "Epoch 17624 - Train Loss: 0.087603, Train Acc: 0.873077 | Val Loss: 0.114105, Val Acc: 0.783505\n",
      "Epoch 17625 - Train Loss: 0.087600, Train Acc: 0.873077 | Val Loss: 0.114103, Val Acc: 0.783505\n",
      "Epoch 17626 - Train Loss: 0.087597, Train Acc: 0.873077 | Val Loss: 0.114102, Val Acc: 0.783505\n",
      "Epoch 17627 - Train Loss: 0.087594, Train Acc: 0.873077 | Val Loss: 0.114100, Val Acc: 0.783505\n",
      "Epoch 17628 - Train Loss: 0.087591, Train Acc: 0.873077 | Val Loss: 0.114099, Val Acc: 0.783505\n",
      "Epoch 17629 - Train Loss: 0.087588, Train Acc: 0.873077 | Val Loss: 0.114097, Val Acc: 0.783505\n",
      "Epoch 17630 - Train Loss: 0.087585, Train Acc: 0.873077 | Val Loss: 0.114095, Val Acc: 0.783505\n",
      "Epoch 17631 - Train Loss: 0.087582, Train Acc: 0.873077 | Val Loss: 0.114094, Val Acc: 0.783505\n",
      "Epoch 17632 - Train Loss: 0.087579, Train Acc: 0.873077 | Val Loss: 0.114092, Val Acc: 0.783505\n",
      "Epoch 17633 - Train Loss: 0.087576, Train Acc: 0.873077 | Val Loss: 0.114091, Val Acc: 0.783505\n",
      "Epoch 17634 - Train Loss: 0.087573, Train Acc: 0.873077 | Val Loss: 0.114089, Val Acc: 0.783505\n",
      "Epoch 17635 - Train Loss: 0.087570, Train Acc: 0.873077 | Val Loss: 0.114087, Val Acc: 0.783505\n",
      "Epoch 17636 - Train Loss: 0.087567, Train Acc: 0.873077 | Val Loss: 0.114086, Val Acc: 0.783505\n",
      "Epoch 17637 - Train Loss: 0.087564, Train Acc: 0.873077 | Val Loss: 0.114084, Val Acc: 0.783505\n",
      "Epoch 17638 - Train Loss: 0.087561, Train Acc: 0.873077 | Val Loss: 0.114083, Val Acc: 0.783505\n",
      "Epoch 17639 - Train Loss: 0.087558, Train Acc: 0.873077 | Val Loss: 0.114081, Val Acc: 0.783505\n",
      "Epoch 17640 - Train Loss: 0.087555, Train Acc: 0.873077 | Val Loss: 0.114079, Val Acc: 0.783505\n",
      "Epoch 17641 - Train Loss: 0.087552, Train Acc: 0.873077 | Val Loss: 0.114078, Val Acc: 0.783505\n",
      "Epoch 17642 - Train Loss: 0.087549, Train Acc: 0.873077 | Val Loss: 0.114076, Val Acc: 0.783505\n",
      "Epoch 17643 - Train Loss: 0.087546, Train Acc: 0.873077 | Val Loss: 0.114075, Val Acc: 0.783505\n",
      "Epoch 17644 - Train Loss: 0.087543, Train Acc: 0.873077 | Val Loss: 0.114073, Val Acc: 0.783505\n",
      "Epoch 17645 - Train Loss: 0.087540, Train Acc: 0.873077 | Val Loss: 0.114071, Val Acc: 0.783505\n",
      "Epoch 17646 - Train Loss: 0.087537, Train Acc: 0.873077 | Val Loss: 0.114070, Val Acc: 0.783505\n",
      "Epoch 17647 - Train Loss: 0.087534, Train Acc: 0.873077 | Val Loss: 0.114068, Val Acc: 0.783505\n",
      "Epoch 17648 - Train Loss: 0.087532, Train Acc: 0.873077 | Val Loss: 0.114067, Val Acc: 0.783505\n",
      "Epoch 17649 - Train Loss: 0.087529, Train Acc: 0.873077 | Val Loss: 0.114065, Val Acc: 0.783505\n",
      "Epoch 17650 - Train Loss: 0.087526, Train Acc: 0.873077 | Val Loss: 0.114063, Val Acc: 0.783505\n",
      "Epoch 17651 - Train Loss: 0.087523, Train Acc: 0.873077 | Val Loss: 0.114062, Val Acc: 0.783505\n",
      "Epoch 17652 - Train Loss: 0.087520, Train Acc: 0.873077 | Val Loss: 0.114060, Val Acc: 0.783505\n",
      "Epoch 17653 - Train Loss: 0.087517, Train Acc: 0.873077 | Val Loss: 0.114059, Val Acc: 0.783505\n",
      "Epoch 17654 - Train Loss: 0.087514, Train Acc: 0.873077 | Val Loss: 0.114057, Val Acc: 0.783505\n",
      "Epoch 17655 - Train Loss: 0.087511, Train Acc: 0.873077 | Val Loss: 0.114055, Val Acc: 0.783505\n",
      "Epoch 17656 - Train Loss: 0.087508, Train Acc: 0.873077 | Val Loss: 0.114054, Val Acc: 0.783505\n",
      "Epoch 17657 - Train Loss: 0.087505, Train Acc: 0.873077 | Val Loss: 0.114052, Val Acc: 0.783505\n",
      "Epoch 17658 - Train Loss: 0.087502, Train Acc: 0.873077 | Val Loss: 0.114051, Val Acc: 0.783505\n",
      "Epoch 17659 - Train Loss: 0.087499, Train Acc: 0.873077 | Val Loss: 0.114049, Val Acc: 0.783505\n",
      "Epoch 17660 - Train Loss: 0.087496, Train Acc: 0.873077 | Val Loss: 0.114048, Val Acc: 0.783505\n",
      "Epoch 17661 - Train Loss: 0.087493, Train Acc: 0.873077 | Val Loss: 0.114046, Val Acc: 0.783505\n",
      "Epoch 17662 - Train Loss: 0.087490, Train Acc: 0.873077 | Val Loss: 0.114044, Val Acc: 0.783505\n",
      "Epoch 17663 - Train Loss: 0.087487, Train Acc: 0.873077 | Val Loss: 0.114043, Val Acc: 0.783505\n",
      "Epoch 17664 - Train Loss: 0.087484, Train Acc: 0.873077 | Val Loss: 0.114041, Val Acc: 0.783505\n",
      "Epoch 17665 - Train Loss: 0.087481, Train Acc: 0.873077 | Val Loss: 0.114040, Val Acc: 0.783505\n",
      "Epoch 17666 - Train Loss: 0.087478, Train Acc: 0.873077 | Val Loss: 0.114038, Val Acc: 0.783505\n",
      "Epoch 17667 - Train Loss: 0.087475, Train Acc: 0.873077 | Val Loss: 0.114036, Val Acc: 0.783505\n",
      "Epoch 17668 - Train Loss: 0.087472, Train Acc: 0.873077 | Val Loss: 0.114035, Val Acc: 0.783505\n",
      "Epoch 17669 - Train Loss: 0.087469, Train Acc: 0.873077 | Val Loss: 0.114033, Val Acc: 0.783505\n",
      "Epoch 17670 - Train Loss: 0.087466, Train Acc: 0.873077 | Val Loss: 0.114032, Val Acc: 0.783505\n",
      "Epoch 17671 - Train Loss: 0.087463, Train Acc: 0.873077 | Val Loss: 0.114030, Val Acc: 0.783505\n",
      "Epoch 17672 - Train Loss: 0.087460, Train Acc: 0.873077 | Val Loss: 0.114028, Val Acc: 0.783505\n",
      "Epoch 17673 - Train Loss: 0.087457, Train Acc: 0.873077 | Val Loss: 0.114027, Val Acc: 0.783505\n",
      "Epoch 17674 - Train Loss: 0.087455, Train Acc: 0.873077 | Val Loss: 0.114025, Val Acc: 0.783505\n",
      "Epoch 17675 - Train Loss: 0.087452, Train Acc: 0.873077 | Val Loss: 0.114024, Val Acc: 0.783505\n",
      "Epoch 17676 - Train Loss: 0.087449, Train Acc: 0.873077 | Val Loss: 0.114022, Val Acc: 0.783505\n",
      "Epoch 17677 - Train Loss: 0.087446, Train Acc: 0.873077 | Val Loss: 0.114021, Val Acc: 0.783505\n",
      "Epoch 17678 - Train Loss: 0.087443, Train Acc: 0.873077 | Val Loss: 0.114019, Val Acc: 0.783505\n",
      "Epoch 17679 - Train Loss: 0.087440, Train Acc: 0.873077 | Val Loss: 0.114017, Val Acc: 0.783505\n",
      "Epoch 17680 - Train Loss: 0.087437, Train Acc: 0.873077 | Val Loss: 0.114016, Val Acc: 0.783505\n",
      "Epoch 17681 - Train Loss: 0.087434, Train Acc: 0.873077 | Val Loss: 0.114014, Val Acc: 0.783505\n",
      "Epoch 17682 - Train Loss: 0.087431, Train Acc: 0.873077 | Val Loss: 0.114013, Val Acc: 0.783505\n",
      "Epoch 17683 - Train Loss: 0.087428, Train Acc: 0.873077 | Val Loss: 0.114011, Val Acc: 0.783505\n",
      "Epoch 17684 - Train Loss: 0.087425, Train Acc: 0.873077 | Val Loss: 0.114009, Val Acc: 0.783505\n",
      "Epoch 17685 - Train Loss: 0.087422, Train Acc: 0.873077 | Val Loss: 0.114008, Val Acc: 0.783505\n",
      "Epoch 17686 - Train Loss: 0.087419, Train Acc: 0.873077 | Val Loss: 0.114006, Val Acc: 0.783505\n",
      "Epoch 17687 - Train Loss: 0.087416, Train Acc: 0.873077 | Val Loss: 0.114005, Val Acc: 0.783505\n",
      "Epoch 17688 - Train Loss: 0.087413, Train Acc: 0.873077 | Val Loss: 0.114003, Val Acc: 0.783505\n",
      "Epoch 17689 - Train Loss: 0.087410, Train Acc: 0.873077 | Val Loss: 0.114002, Val Acc: 0.783505\n",
      "Epoch 17690 - Train Loss: 0.087407, Train Acc: 0.873077 | Val Loss: 0.114000, Val Acc: 0.783505\n",
      "Epoch 17691 - Train Loss: 0.087404, Train Acc: 0.873077 | Val Loss: 0.113998, Val Acc: 0.783505\n",
      "Epoch 17692 - Train Loss: 0.087401, Train Acc: 0.873077 | Val Loss: 0.113997, Val Acc: 0.783505\n",
      "Epoch 17693 - Train Loss: 0.087398, Train Acc: 0.873077 | Val Loss: 0.113995, Val Acc: 0.783505\n",
      "Epoch 17694 - Train Loss: 0.087395, Train Acc: 0.873077 | Val Loss: 0.113994, Val Acc: 0.783505\n",
      "Epoch 17695 - Train Loss: 0.087393, Train Acc: 0.873077 | Val Loss: 0.113992, Val Acc: 0.783505\n",
      "Epoch 17696 - Train Loss: 0.087390, Train Acc: 0.873077 | Val Loss: 0.113991, Val Acc: 0.783505\n",
      "Epoch 17697 - Train Loss: 0.087387, Train Acc: 0.873077 | Val Loss: 0.113989, Val Acc: 0.783505\n",
      "Epoch 17698 - Train Loss: 0.087384, Train Acc: 0.873077 | Val Loss: 0.113988, Val Acc: 0.783505\n",
      "Epoch 17699 - Train Loss: 0.087381, Train Acc: 0.873077 | Val Loss: 0.113986, Val Acc: 0.783505\n",
      "Epoch 17700 - Train Loss: 0.087378, Train Acc: 0.873077 | Val Loss: 0.113984, Val Acc: 0.783505\n",
      "Epoch 17701 - Train Loss: 0.087375, Train Acc: 0.873077 | Val Loss: 0.113983, Val Acc: 0.783505\n",
      "Epoch 17702 - Train Loss: 0.087372, Train Acc: 0.873077 | Val Loss: 0.113981, Val Acc: 0.783505\n",
      "Epoch 17703 - Train Loss: 0.087369, Train Acc: 0.873077 | Val Loss: 0.113980, Val Acc: 0.783505\n",
      "Epoch 17704 - Train Loss: 0.087366, Train Acc: 0.873077 | Val Loss: 0.113978, Val Acc: 0.783505\n",
      "Epoch 17705 - Train Loss: 0.087363, Train Acc: 0.873077 | Val Loss: 0.113977, Val Acc: 0.783505\n",
      "Epoch 17706 - Train Loss: 0.087360, Train Acc: 0.873077 | Val Loss: 0.113975, Val Acc: 0.783505\n",
      "Epoch 17707 - Train Loss: 0.087357, Train Acc: 0.873077 | Val Loss: 0.113974, Val Acc: 0.783505\n",
      "Epoch 17708 - Train Loss: 0.087354, Train Acc: 0.873077 | Val Loss: 0.113972, Val Acc: 0.783505\n",
      "Epoch 17709 - Train Loss: 0.087351, Train Acc: 0.873077 | Val Loss: 0.113970, Val Acc: 0.783505\n",
      "Epoch 17710 - Train Loss: 0.087348, Train Acc: 0.873077 | Val Loss: 0.113969, Val Acc: 0.783505\n",
      "Epoch 17711 - Train Loss: 0.087345, Train Acc: 0.873077 | Val Loss: 0.113967, Val Acc: 0.783505\n",
      "Epoch 17712 - Train Loss: 0.087342, Train Acc: 0.873077 | Val Loss: 0.113966, Val Acc: 0.783505\n",
      "Epoch 17713 - Train Loss: 0.087339, Train Acc: 0.873077 | Val Loss: 0.113964, Val Acc: 0.783505\n",
      "Epoch 17714 - Train Loss: 0.087337, Train Acc: 0.873077 | Val Loss: 0.113963, Val Acc: 0.783505\n",
      "Epoch 17715 - Train Loss: 0.087334, Train Acc: 0.873077 | Val Loss: 0.113961, Val Acc: 0.783505\n",
      "Epoch 17716 - Train Loss: 0.087331, Train Acc: 0.873077 | Val Loss: 0.113959, Val Acc: 0.783505\n",
      "Epoch 17717 - Train Loss: 0.087328, Train Acc: 0.873077 | Val Loss: 0.113958, Val Acc: 0.783505\n",
      "Epoch 17718 - Train Loss: 0.087325, Train Acc: 0.873077 | Val Loss: 0.113956, Val Acc: 0.783505\n",
      "Epoch 17719 - Train Loss: 0.087322, Train Acc: 0.873077 | Val Loss: 0.113955, Val Acc: 0.783505\n",
      "Epoch 17720 - Train Loss: 0.087319, Train Acc: 0.873077 | Val Loss: 0.113953, Val Acc: 0.783505\n",
      "Epoch 17721 - Train Loss: 0.087316, Train Acc: 0.873077 | Val Loss: 0.113952, Val Acc: 0.783505\n",
      "Epoch 17722 - Train Loss: 0.087313, Train Acc: 0.873077 | Val Loss: 0.113950, Val Acc: 0.783505\n",
      "Epoch 17723 - Train Loss: 0.087310, Train Acc: 0.873077 | Val Loss: 0.113949, Val Acc: 0.783505\n",
      "Epoch 17724 - Train Loss: 0.087307, Train Acc: 0.873077 | Val Loss: 0.113947, Val Acc: 0.783505\n",
      "Epoch 17725 - Train Loss: 0.087304, Train Acc: 0.873077 | Val Loss: 0.113945, Val Acc: 0.783505\n",
      "Epoch 17726 - Train Loss: 0.087301, Train Acc: 0.873077 | Val Loss: 0.113944, Val Acc: 0.783505\n",
      "Epoch 17727 - Train Loss: 0.087298, Train Acc: 0.873077 | Val Loss: 0.113942, Val Acc: 0.783505\n",
      "Epoch 17728 - Train Loss: 0.087295, Train Acc: 0.873077 | Val Loss: 0.113941, Val Acc: 0.783505\n",
      "Epoch 17729 - Train Loss: 0.087292, Train Acc: 0.873077 | Val Loss: 0.113939, Val Acc: 0.783505\n",
      "Epoch 17730 - Train Loss: 0.087289, Train Acc: 0.873077 | Val Loss: 0.113938, Val Acc: 0.783505\n",
      "Epoch 17731 - Train Loss: 0.087287, Train Acc: 0.873077 | Val Loss: 0.113936, Val Acc: 0.783505\n",
      "Epoch 17732 - Train Loss: 0.087284, Train Acc: 0.873077 | Val Loss: 0.113935, Val Acc: 0.783505\n",
      "Epoch 17733 - Train Loss: 0.087281, Train Acc: 0.873077 | Val Loss: 0.113933, Val Acc: 0.783505\n",
      "Epoch 17734 - Train Loss: 0.087278, Train Acc: 0.873077 | Val Loss: 0.113931, Val Acc: 0.783505\n",
      "Epoch 17735 - Train Loss: 0.087275, Train Acc: 0.873077 | Val Loss: 0.113930, Val Acc: 0.783505\n",
      "Epoch 17736 - Train Loss: 0.087272, Train Acc: 0.873077 | Val Loss: 0.113928, Val Acc: 0.783505\n",
      "Epoch 17737 - Train Loss: 0.087269, Train Acc: 0.873077 | Val Loss: 0.113927, Val Acc: 0.783505\n",
      "Epoch 17738 - Train Loss: 0.087266, Train Acc: 0.873077 | Val Loss: 0.113925, Val Acc: 0.783505\n",
      "Epoch 17739 - Train Loss: 0.087263, Train Acc: 0.873077 | Val Loss: 0.113924, Val Acc: 0.783505\n",
      "Epoch 17740 - Train Loss: 0.087260, Train Acc: 0.873077 | Val Loss: 0.113922, Val Acc: 0.783505\n",
      "Epoch 17741 - Train Loss: 0.087257, Train Acc: 0.873077 | Val Loss: 0.113921, Val Acc: 0.783505\n",
      "Epoch 17742 - Train Loss: 0.087254, Train Acc: 0.873077 | Val Loss: 0.113919, Val Acc: 0.783505\n",
      "Epoch 17743 - Train Loss: 0.087251, Train Acc: 0.873077 | Val Loss: 0.113917, Val Acc: 0.783505\n",
      "Epoch 17744 - Train Loss: 0.087248, Train Acc: 0.873077 | Val Loss: 0.113916, Val Acc: 0.783505\n",
      "Epoch 17745 - Train Loss: 0.087245, Train Acc: 0.873077 | Val Loss: 0.113914, Val Acc: 0.783505\n",
      "Epoch 17746 - Train Loss: 0.087242, Train Acc: 0.873077 | Val Loss: 0.113913, Val Acc: 0.783505\n",
      "Epoch 17747 - Train Loss: 0.087240, Train Acc: 0.873077 | Val Loss: 0.113911, Val Acc: 0.783505\n",
      "Epoch 17748 - Train Loss: 0.087237, Train Acc: 0.873077 | Val Loss: 0.113910, Val Acc: 0.783505\n",
      "Epoch 17749 - Train Loss: 0.087234, Train Acc: 0.873077 | Val Loss: 0.113908, Val Acc: 0.783505\n",
      "Epoch 17750 - Train Loss: 0.087231, Train Acc: 0.873077 | Val Loss: 0.113907, Val Acc: 0.783505\n",
      "Epoch 17751 - Train Loss: 0.087228, Train Acc: 0.873077 | Val Loss: 0.113905, Val Acc: 0.783505\n",
      "Epoch 17752 - Train Loss: 0.087225, Train Acc: 0.873077 | Val Loss: 0.113903, Val Acc: 0.783505\n",
      "Epoch 17753 - Train Loss: 0.087222, Train Acc: 0.873077 | Val Loss: 0.113902, Val Acc: 0.783505\n",
      "Epoch 17754 - Train Loss: 0.087219, Train Acc: 0.873077 | Val Loss: 0.113900, Val Acc: 0.783505\n",
      "Epoch 17755 - Train Loss: 0.087216, Train Acc: 0.873077 | Val Loss: 0.113899, Val Acc: 0.783505\n",
      "Epoch 17756 - Train Loss: 0.087213, Train Acc: 0.873077 | Val Loss: 0.113897, Val Acc: 0.783505\n",
      "Epoch 17757 - Train Loss: 0.087210, Train Acc: 0.873077 | Val Loss: 0.113896, Val Acc: 0.783505\n",
      "Epoch 17758 - Train Loss: 0.087207, Train Acc: 0.873077 | Val Loss: 0.113894, Val Acc: 0.783505\n",
      "Epoch 17759 - Train Loss: 0.087204, Train Acc: 0.873077 | Val Loss: 0.113893, Val Acc: 0.783505\n",
      "Epoch 17760 - Train Loss: 0.087201, Train Acc: 0.873077 | Val Loss: 0.113891, Val Acc: 0.783505\n",
      "Epoch 17761 - Train Loss: 0.087199, Train Acc: 0.873077 | Val Loss: 0.113890, Val Acc: 0.783505\n",
      "Epoch 17762 - Train Loss: 0.087196, Train Acc: 0.873077 | Val Loss: 0.113888, Val Acc: 0.783505\n",
      "Epoch 17763 - Train Loss: 0.087193, Train Acc: 0.873077 | Val Loss: 0.113886, Val Acc: 0.783505\n",
      "Epoch 17764 - Train Loss: 0.087190, Train Acc: 0.873077 | Val Loss: 0.113885, Val Acc: 0.783505\n",
      "Epoch 17765 - Train Loss: 0.087187, Train Acc: 0.873077 | Val Loss: 0.113883, Val Acc: 0.783505\n",
      "Epoch 17766 - Train Loss: 0.087184, Train Acc: 0.873077 | Val Loss: 0.113882, Val Acc: 0.783505\n",
      "Epoch 17767 - Train Loss: 0.087181, Train Acc: 0.873077 | Val Loss: 0.113880, Val Acc: 0.783505\n",
      "Epoch 17768 - Train Loss: 0.087178, Train Acc: 0.873077 | Val Loss: 0.113879, Val Acc: 0.783505\n",
      "Epoch 17769 - Train Loss: 0.087175, Train Acc: 0.873077 | Val Loss: 0.113877, Val Acc: 0.783505\n",
      "Epoch 17770 - Train Loss: 0.087172, Train Acc: 0.873077 | Val Loss: 0.113876, Val Acc: 0.783505\n",
      "Epoch 17771 - Train Loss: 0.087169, Train Acc: 0.873077 | Val Loss: 0.113874, Val Acc: 0.783505\n",
      "Epoch 17772 - Train Loss: 0.087166, Train Acc: 0.873077 | Val Loss: 0.113873, Val Acc: 0.783505\n",
      "Epoch 17773 - Train Loss: 0.087163, Train Acc: 0.873077 | Val Loss: 0.113871, Val Acc: 0.783505\n",
      "Epoch 17774 - Train Loss: 0.087161, Train Acc: 0.873077 | Val Loss: 0.113869, Val Acc: 0.783505\n",
      "Epoch 17775 - Train Loss: 0.087158, Train Acc: 0.873077 | Val Loss: 0.113868, Val Acc: 0.783505\n",
      "Epoch 17776 - Train Loss: 0.087155, Train Acc: 0.873077 | Val Loss: 0.113866, Val Acc: 0.783505\n",
      "Epoch 17777 - Train Loss: 0.087152, Train Acc: 0.873077 | Val Loss: 0.113865, Val Acc: 0.783505\n",
      "Epoch 17778 - Train Loss: 0.087149, Train Acc: 0.873077 | Val Loss: 0.113863, Val Acc: 0.783505\n",
      "Epoch 17779 - Train Loss: 0.087146, Train Acc: 0.873077 | Val Loss: 0.113862, Val Acc: 0.783505\n",
      "Epoch 17780 - Train Loss: 0.087143, Train Acc: 0.873077 | Val Loss: 0.113860, Val Acc: 0.783505\n",
      "Epoch 17781 - Train Loss: 0.087140, Train Acc: 0.873077 | Val Loss: 0.113859, Val Acc: 0.783505\n",
      "Epoch 17782 - Train Loss: 0.087137, Train Acc: 0.873077 | Val Loss: 0.113857, Val Acc: 0.783505\n",
      "Epoch 17783 - Train Loss: 0.087134, Train Acc: 0.873077 | Val Loss: 0.113855, Val Acc: 0.783505\n",
      "Epoch 17784 - Train Loss: 0.087131, Train Acc: 0.873077 | Val Loss: 0.113854, Val Acc: 0.783505\n",
      "Epoch 17785 - Train Loss: 0.087128, Train Acc: 0.873077 | Val Loss: 0.113852, Val Acc: 0.783505\n",
      "Epoch 17786 - Train Loss: 0.087125, Train Acc: 0.873077 | Val Loss: 0.113851, Val Acc: 0.783505\n",
      "Epoch 17787 - Train Loss: 0.087123, Train Acc: 0.873077 | Val Loss: 0.113849, Val Acc: 0.783505\n",
      "Epoch 17788 - Train Loss: 0.087120, Train Acc: 0.873077 | Val Loss: 0.113848, Val Acc: 0.783505\n",
      "Epoch 17789 - Train Loss: 0.087117, Train Acc: 0.873077 | Val Loss: 0.113846, Val Acc: 0.783505\n",
      "Epoch 17790 - Train Loss: 0.087114, Train Acc: 0.873077 | Val Loss: 0.113845, Val Acc: 0.783505\n",
      "Epoch 17791 - Train Loss: 0.087111, Train Acc: 0.873077 | Val Loss: 0.113843, Val Acc: 0.783505\n",
      "Epoch 17792 - Train Loss: 0.087108, Train Acc: 0.873077 | Val Loss: 0.113842, Val Acc: 0.783505\n",
      "Epoch 17793 - Train Loss: 0.087105, Train Acc: 0.873077 | Val Loss: 0.113840, Val Acc: 0.783505\n",
      "Epoch 17794 - Train Loss: 0.087102, Train Acc: 0.873077 | Val Loss: 0.113838, Val Acc: 0.783505\n",
      "Epoch 17795 - Train Loss: 0.087099, Train Acc: 0.873077 | Val Loss: 0.113837, Val Acc: 0.783505\n",
      "Epoch 17796 - Train Loss: 0.087096, Train Acc: 0.873077 | Val Loss: 0.113835, Val Acc: 0.783505\n",
      "Epoch 17797 - Train Loss: 0.087093, Train Acc: 0.873077 | Val Loss: 0.113834, Val Acc: 0.783505\n",
      "Epoch 17798 - Train Loss: 0.087090, Train Acc: 0.873077 | Val Loss: 0.113832, Val Acc: 0.783505\n",
      "Epoch 17799 - Train Loss: 0.087088, Train Acc: 0.873077 | Val Loss: 0.113831, Val Acc: 0.783505\n",
      "Epoch 17800 - Train Loss: 0.087085, Train Acc: 0.873077 | Val Loss: 0.113829, Val Acc: 0.783505\n",
      "Epoch 17801 - Train Loss: 0.087082, Train Acc: 0.873077 | Val Loss: 0.113828, Val Acc: 0.783505\n",
      "Epoch 17802 - Train Loss: 0.087079, Train Acc: 0.873077 | Val Loss: 0.113826, Val Acc: 0.783505\n",
      "Epoch 17803 - Train Loss: 0.087076, Train Acc: 0.873077 | Val Loss: 0.113825, Val Acc: 0.783505\n",
      "Epoch 17804 - Train Loss: 0.087073, Train Acc: 0.873077 | Val Loss: 0.113823, Val Acc: 0.783505\n",
      "Epoch 17805 - Train Loss: 0.087070, Train Acc: 0.873077 | Val Loss: 0.113821, Val Acc: 0.783505\n",
      "Epoch 17806 - Train Loss: 0.087067, Train Acc: 0.873077 | Val Loss: 0.113820, Val Acc: 0.783505\n",
      "Epoch 17807 - Train Loss: 0.087064, Train Acc: 0.873077 | Val Loss: 0.113818, Val Acc: 0.783505\n",
      "Epoch 17808 - Train Loss: 0.087061, Train Acc: 0.873077 | Val Loss: 0.113817, Val Acc: 0.783505\n",
      "Epoch 17809 - Train Loss: 0.087058, Train Acc: 0.873077 | Val Loss: 0.113815, Val Acc: 0.783505\n",
      "Epoch 17810 - Train Loss: 0.087056, Train Acc: 0.873077 | Val Loss: 0.113814, Val Acc: 0.783505\n",
      "Epoch 17811 - Train Loss: 0.087053, Train Acc: 0.873077 | Val Loss: 0.113812, Val Acc: 0.783505\n",
      "Epoch 17812 - Train Loss: 0.087050, Train Acc: 0.873077 | Val Loss: 0.113811, Val Acc: 0.783505\n",
      "Epoch 17813 - Train Loss: 0.087047, Train Acc: 0.873077 | Val Loss: 0.113809, Val Acc: 0.783505\n",
      "Epoch 17814 - Train Loss: 0.087044, Train Acc: 0.873077 | Val Loss: 0.113808, Val Acc: 0.783505\n",
      "Epoch 17815 - Train Loss: 0.087041, Train Acc: 0.873077 | Val Loss: 0.113806, Val Acc: 0.783505\n",
      "Epoch 17816 - Train Loss: 0.087038, Train Acc: 0.873077 | Val Loss: 0.113805, Val Acc: 0.783505\n",
      "Epoch 17817 - Train Loss: 0.087035, Train Acc: 0.873077 | Val Loss: 0.113803, Val Acc: 0.783505\n",
      "Epoch 17818 - Train Loss: 0.087032, Train Acc: 0.873077 | Val Loss: 0.113801, Val Acc: 0.783505\n",
      "Epoch 17819 - Train Loss: 0.087029, Train Acc: 0.873077 | Val Loss: 0.113800, Val Acc: 0.783505\n",
      "Epoch 17820 - Train Loss: 0.087026, Train Acc: 0.873077 | Val Loss: 0.113798, Val Acc: 0.783505\n",
      "Epoch 17821 - Train Loss: 0.087024, Train Acc: 0.873077 | Val Loss: 0.113797, Val Acc: 0.783505\n",
      "Epoch 17822 - Train Loss: 0.087021, Train Acc: 0.873077 | Val Loss: 0.113795, Val Acc: 0.783505\n",
      "Epoch 17823 - Train Loss: 0.087018, Train Acc: 0.873077 | Val Loss: 0.113794, Val Acc: 0.783505\n",
      "Epoch 17824 - Train Loss: 0.087015, Train Acc: 0.873077 | Val Loss: 0.113792, Val Acc: 0.783505\n",
      "Epoch 17825 - Train Loss: 0.087012, Train Acc: 0.873077 | Val Loss: 0.113791, Val Acc: 0.783505\n",
      "Epoch 17826 - Train Loss: 0.087009, Train Acc: 0.873077 | Val Loss: 0.113789, Val Acc: 0.783505\n",
      "Epoch 17827 - Train Loss: 0.087006, Train Acc: 0.873077 | Val Loss: 0.113787, Val Acc: 0.783505\n",
      "Epoch 17828 - Train Loss: 0.087003, Train Acc: 0.873077 | Val Loss: 0.113786, Val Acc: 0.783505\n",
      "Epoch 17829 - Train Loss: 0.087000, Train Acc: 0.873077 | Val Loss: 0.113784, Val Acc: 0.783505\n",
      "Epoch 17830 - Train Loss: 0.086997, Train Acc: 0.873077 | Val Loss: 0.113783, Val Acc: 0.783505\n",
      "Epoch 17831 - Train Loss: 0.086994, Train Acc: 0.873077 | Val Loss: 0.113781, Val Acc: 0.783505\n",
      "Epoch 17832 - Train Loss: 0.086992, Train Acc: 0.873077 | Val Loss: 0.113780, Val Acc: 0.783505\n",
      "Epoch 17833 - Train Loss: 0.086989, Train Acc: 0.873077 | Val Loss: 0.113778, Val Acc: 0.783505\n",
      "Epoch 17834 - Train Loss: 0.086986, Train Acc: 0.873077 | Val Loss: 0.113776, Val Acc: 0.783505\n",
      "Epoch 17835 - Train Loss: 0.086983, Train Acc: 0.873077 | Val Loss: 0.113775, Val Acc: 0.783505\n",
      "Epoch 17836 - Train Loss: 0.086980, Train Acc: 0.873077 | Val Loss: 0.113773, Val Acc: 0.783505\n",
      "Epoch 17837 - Train Loss: 0.086977, Train Acc: 0.873077 | Val Loss: 0.113772, Val Acc: 0.783505\n",
      "Epoch 17838 - Train Loss: 0.086974, Train Acc: 0.873077 | Val Loss: 0.113770, Val Acc: 0.783505\n",
      "Epoch 17839 - Train Loss: 0.086971, Train Acc: 0.873077 | Val Loss: 0.113769, Val Acc: 0.783505\n",
      "Epoch 17840 - Train Loss: 0.086968, Train Acc: 0.873077 | Val Loss: 0.113767, Val Acc: 0.783505\n",
      "Epoch 17841 - Train Loss: 0.086965, Train Acc: 0.873077 | Val Loss: 0.113766, Val Acc: 0.783505\n",
      "Epoch 17842 - Train Loss: 0.086963, Train Acc: 0.873077 | Val Loss: 0.113764, Val Acc: 0.783505\n",
      "Epoch 17843 - Train Loss: 0.086960, Train Acc: 0.873077 | Val Loss: 0.113763, Val Acc: 0.783505\n",
      "Epoch 17844 - Train Loss: 0.086957, Train Acc: 0.873077 | Val Loss: 0.113761, Val Acc: 0.783505\n",
      "Epoch 17845 - Train Loss: 0.086954, Train Acc: 0.873077 | Val Loss: 0.113759, Val Acc: 0.783505\n",
      "Epoch 17846 - Train Loss: 0.086951, Train Acc: 0.873077 | Val Loss: 0.113758, Val Acc: 0.783505\n",
      "Epoch 17847 - Train Loss: 0.086948, Train Acc: 0.873077 | Val Loss: 0.113756, Val Acc: 0.783505\n",
      "Epoch 17848 - Train Loss: 0.086945, Train Acc: 0.874359 | Val Loss: 0.113755, Val Acc: 0.783505\n",
      "Epoch 17849 - Train Loss: 0.086942, Train Acc: 0.874359 | Val Loss: 0.113753, Val Acc: 0.783505\n",
      "Epoch 17850 - Train Loss: 0.086939, Train Acc: 0.874359 | Val Loss: 0.113752, Val Acc: 0.783505\n",
      "Epoch 17851 - Train Loss: 0.086936, Train Acc: 0.874359 | Val Loss: 0.113750, Val Acc: 0.783505\n",
      "Epoch 17852 - Train Loss: 0.086934, Train Acc: 0.874359 | Val Loss: 0.113749, Val Acc: 0.783505\n",
      "Epoch 17853 - Train Loss: 0.086931, Train Acc: 0.874359 | Val Loss: 0.113747, Val Acc: 0.783505\n",
      "Epoch 17854 - Train Loss: 0.086928, Train Acc: 0.874359 | Val Loss: 0.113745, Val Acc: 0.783505\n",
      "Epoch 17855 - Train Loss: 0.086925, Train Acc: 0.874359 | Val Loss: 0.113744, Val Acc: 0.783505\n",
      "Epoch 17856 - Train Loss: 0.086922, Train Acc: 0.874359 | Val Loss: 0.113742, Val Acc: 0.783505\n",
      "Epoch 17857 - Train Loss: 0.086919, Train Acc: 0.874359 | Val Loss: 0.113741, Val Acc: 0.783505\n",
      "Epoch 17858 - Train Loss: 0.086916, Train Acc: 0.874359 | Val Loss: 0.113739, Val Acc: 0.783505\n",
      "Epoch 17859 - Train Loss: 0.086913, Train Acc: 0.874359 | Val Loss: 0.113738, Val Acc: 0.783505\n",
      "Epoch 17860 - Train Loss: 0.086910, Train Acc: 0.874359 | Val Loss: 0.113736, Val Acc: 0.783505\n",
      "Epoch 17861 - Train Loss: 0.086908, Train Acc: 0.874359 | Val Loss: 0.113735, Val Acc: 0.783505\n",
      "Epoch 17862 - Train Loss: 0.086905, Train Acc: 0.874359 | Val Loss: 0.113733, Val Acc: 0.783505\n",
      "Epoch 17863 - Train Loss: 0.086902, Train Acc: 0.874359 | Val Loss: 0.113732, Val Acc: 0.783505\n",
      "Epoch 17864 - Train Loss: 0.086899, Train Acc: 0.874359 | Val Loss: 0.113730, Val Acc: 0.783505\n",
      "Epoch 17865 - Train Loss: 0.086896, Train Acc: 0.874359 | Val Loss: 0.113729, Val Acc: 0.783505\n",
      "Epoch 17866 - Train Loss: 0.086893, Train Acc: 0.874359 | Val Loss: 0.113727, Val Acc: 0.783505\n",
      "Epoch 17867 - Train Loss: 0.086890, Train Acc: 0.874359 | Val Loss: 0.113725, Val Acc: 0.783505\n",
      "Epoch 17868 - Train Loss: 0.086887, Train Acc: 0.874359 | Val Loss: 0.113724, Val Acc: 0.783505\n",
      "Epoch 17869 - Train Loss: 0.086884, Train Acc: 0.874359 | Val Loss: 0.113722, Val Acc: 0.783505\n",
      "Epoch 17870 - Train Loss: 0.086882, Train Acc: 0.874359 | Val Loss: 0.113721, Val Acc: 0.783505\n",
      "Epoch 17871 - Train Loss: 0.086879, Train Acc: 0.874359 | Val Loss: 0.113719, Val Acc: 0.783505\n",
      "Epoch 17872 - Train Loss: 0.086876, Train Acc: 0.874359 | Val Loss: 0.113718, Val Acc: 0.783505\n",
      "Epoch 17873 - Train Loss: 0.086873, Train Acc: 0.874359 | Val Loss: 0.113716, Val Acc: 0.783505\n",
      "Epoch 17874 - Train Loss: 0.086870, Train Acc: 0.874359 | Val Loss: 0.113715, Val Acc: 0.783505\n",
      "Epoch 17875 - Train Loss: 0.086867, Train Acc: 0.874359 | Val Loss: 0.113713, Val Acc: 0.783505\n",
      "Epoch 17876 - Train Loss: 0.086864, Train Acc: 0.874359 | Val Loss: 0.113712, Val Acc: 0.783505\n",
      "Epoch 17877 - Train Loss: 0.086861, Train Acc: 0.874359 | Val Loss: 0.113710, Val Acc: 0.783505\n",
      "Epoch 17878 - Train Loss: 0.086858, Train Acc: 0.874359 | Val Loss: 0.113708, Val Acc: 0.783505\n",
      "Epoch 17879 - Train Loss: 0.086856, Train Acc: 0.874359 | Val Loss: 0.113707, Val Acc: 0.783505\n",
      "Epoch 17880 - Train Loss: 0.086853, Train Acc: 0.874359 | Val Loss: 0.113705, Val Acc: 0.783505\n",
      "Epoch 17881 - Train Loss: 0.086850, Train Acc: 0.874359 | Val Loss: 0.113704, Val Acc: 0.783505\n",
      "Epoch 17882 - Train Loss: 0.086847, Train Acc: 0.874359 | Val Loss: 0.113702, Val Acc: 0.783505\n",
      "Epoch 17883 - Train Loss: 0.086844, Train Acc: 0.874359 | Val Loss: 0.113701, Val Acc: 0.783505\n",
      "Epoch 17884 - Train Loss: 0.086841, Train Acc: 0.874359 | Val Loss: 0.113699, Val Acc: 0.783505\n",
      "Epoch 17885 - Train Loss: 0.086838, Train Acc: 0.874359 | Val Loss: 0.113698, Val Acc: 0.783505\n",
      "Epoch 17886 - Train Loss: 0.086835, Train Acc: 0.874359 | Val Loss: 0.113696, Val Acc: 0.783505\n",
      "Epoch 17887 - Train Loss: 0.086832, Train Acc: 0.874359 | Val Loss: 0.113695, Val Acc: 0.783505\n",
      "Epoch 17888 - Train Loss: 0.086830, Train Acc: 0.874359 | Val Loss: 0.113693, Val Acc: 0.783505\n",
      "Epoch 17889 - Train Loss: 0.086827, Train Acc: 0.874359 | Val Loss: 0.113692, Val Acc: 0.783505\n",
      "Epoch 17890 - Train Loss: 0.086824, Train Acc: 0.874359 | Val Loss: 0.113690, Val Acc: 0.783505\n",
      "Epoch 17891 - Train Loss: 0.086821, Train Acc: 0.874359 | Val Loss: 0.113689, Val Acc: 0.783505\n",
      "Epoch 17892 - Train Loss: 0.086818, Train Acc: 0.874359 | Val Loss: 0.113687, Val Acc: 0.783505\n",
      "Epoch 17893 - Train Loss: 0.086815, Train Acc: 0.874359 | Val Loss: 0.113685, Val Acc: 0.783505\n",
      "Epoch 17894 - Train Loss: 0.086812, Train Acc: 0.874359 | Val Loss: 0.113684, Val Acc: 0.783505\n",
      "Epoch 17895 - Train Loss: 0.086809, Train Acc: 0.874359 | Val Loss: 0.113682, Val Acc: 0.783505\n",
      "Epoch 17896 - Train Loss: 0.086806, Train Acc: 0.874359 | Val Loss: 0.113681, Val Acc: 0.783505\n",
      "Epoch 17897 - Train Loss: 0.086804, Train Acc: 0.874359 | Val Loss: 0.113679, Val Acc: 0.783505\n",
      "Epoch 17898 - Train Loss: 0.086801, Train Acc: 0.874359 | Val Loss: 0.113678, Val Acc: 0.783505\n",
      "Epoch 17899 - Train Loss: 0.086798, Train Acc: 0.874359 | Val Loss: 0.113676, Val Acc: 0.783505\n",
      "Epoch 17900 - Train Loss: 0.086795, Train Acc: 0.874359 | Val Loss: 0.113675, Val Acc: 0.783505\n",
      "Epoch 17901 - Train Loss: 0.086792, Train Acc: 0.874359 | Val Loss: 0.113673, Val Acc: 0.783505\n",
      "Epoch 17902 - Train Loss: 0.086789, Train Acc: 0.874359 | Val Loss: 0.113672, Val Acc: 0.783505\n",
      "Epoch 17903 - Train Loss: 0.086786, Train Acc: 0.874359 | Val Loss: 0.113670, Val Acc: 0.783505\n",
      "Epoch 17904 - Train Loss: 0.086783, Train Acc: 0.874359 | Val Loss: 0.113669, Val Acc: 0.783505\n",
      "Epoch 17905 - Train Loss: 0.086781, Train Acc: 0.874359 | Val Loss: 0.113667, Val Acc: 0.783505\n",
      "Epoch 17906 - Train Loss: 0.086778, Train Acc: 0.874359 | Val Loss: 0.113666, Val Acc: 0.783505\n",
      "Epoch 17907 - Train Loss: 0.086775, Train Acc: 0.874359 | Val Loss: 0.113664, Val Acc: 0.783505\n",
      "Epoch 17908 - Train Loss: 0.086772, Train Acc: 0.874359 | Val Loss: 0.113663, Val Acc: 0.783505\n",
      "Epoch 17909 - Train Loss: 0.086769, Train Acc: 0.874359 | Val Loss: 0.113661, Val Acc: 0.783505\n",
      "Epoch 17910 - Train Loss: 0.086766, Train Acc: 0.874359 | Val Loss: 0.113659, Val Acc: 0.783505\n",
      "Epoch 17911 - Train Loss: 0.086763, Train Acc: 0.874359 | Val Loss: 0.113658, Val Acc: 0.783505\n",
      "Epoch 17912 - Train Loss: 0.086760, Train Acc: 0.874359 | Val Loss: 0.113656, Val Acc: 0.783505\n",
      "Epoch 17913 - Train Loss: 0.086758, Train Acc: 0.874359 | Val Loss: 0.113655, Val Acc: 0.783505\n",
      "Epoch 17914 - Train Loss: 0.086755, Train Acc: 0.874359 | Val Loss: 0.113653, Val Acc: 0.783505\n",
      "Epoch 17915 - Train Loss: 0.086752, Train Acc: 0.874359 | Val Loss: 0.113652, Val Acc: 0.783505\n",
      "Epoch 17916 - Train Loss: 0.086749, Train Acc: 0.874359 | Val Loss: 0.113650, Val Acc: 0.783505\n",
      "Epoch 17917 - Train Loss: 0.086746, Train Acc: 0.874359 | Val Loss: 0.113649, Val Acc: 0.783505\n",
      "Epoch 17918 - Train Loss: 0.086743, Train Acc: 0.874359 | Val Loss: 0.113647, Val Acc: 0.783505\n",
      "Epoch 17919 - Train Loss: 0.086740, Train Acc: 0.874359 | Val Loss: 0.113646, Val Acc: 0.783505\n",
      "Epoch 17920 - Train Loss: 0.086737, Train Acc: 0.874359 | Val Loss: 0.113644, Val Acc: 0.783505\n",
      "Epoch 17921 - Train Loss: 0.086735, Train Acc: 0.874359 | Val Loss: 0.113643, Val Acc: 0.783505\n",
      "Epoch 17922 - Train Loss: 0.086732, Train Acc: 0.874359 | Val Loss: 0.113641, Val Acc: 0.783505\n",
      "Epoch 17923 - Train Loss: 0.086729, Train Acc: 0.874359 | Val Loss: 0.113640, Val Acc: 0.783505\n",
      "Epoch 17924 - Train Loss: 0.086726, Train Acc: 0.874359 | Val Loss: 0.113638, Val Acc: 0.783505\n",
      "Epoch 17925 - Train Loss: 0.086723, Train Acc: 0.874359 | Val Loss: 0.113637, Val Acc: 0.783505\n",
      "Epoch 17926 - Train Loss: 0.086720, Train Acc: 0.874359 | Val Loss: 0.113635, Val Acc: 0.783505\n",
      "Epoch 17927 - Train Loss: 0.086717, Train Acc: 0.874359 | Val Loss: 0.113634, Val Acc: 0.783505\n",
      "Epoch 17928 - Train Loss: 0.086714, Train Acc: 0.874359 | Val Loss: 0.113632, Val Acc: 0.783505\n",
      "Epoch 17929 - Train Loss: 0.086712, Train Acc: 0.874359 | Val Loss: 0.113631, Val Acc: 0.783505\n",
      "Epoch 17930 - Train Loss: 0.086709, Train Acc: 0.874359 | Val Loss: 0.113629, Val Acc: 0.783505\n",
      "Epoch 17931 - Train Loss: 0.086706, Train Acc: 0.874359 | Val Loss: 0.113628, Val Acc: 0.783505\n",
      "Epoch 17932 - Train Loss: 0.086703, Train Acc: 0.874359 | Val Loss: 0.113626, Val Acc: 0.783505\n",
      "Epoch 17933 - Train Loss: 0.086700, Train Acc: 0.874359 | Val Loss: 0.113624, Val Acc: 0.783505\n",
      "Epoch 17934 - Train Loss: 0.086697, Train Acc: 0.874359 | Val Loss: 0.113623, Val Acc: 0.783505\n",
      "Epoch 17935 - Train Loss: 0.086694, Train Acc: 0.874359 | Val Loss: 0.113621, Val Acc: 0.783505\n",
      "Epoch 17936 - Train Loss: 0.086692, Train Acc: 0.874359 | Val Loss: 0.113620, Val Acc: 0.783505\n",
      "Epoch 17937 - Train Loss: 0.086689, Train Acc: 0.874359 | Val Loss: 0.113618, Val Acc: 0.783505\n",
      "Epoch 17938 - Train Loss: 0.086686, Train Acc: 0.874359 | Val Loss: 0.113617, Val Acc: 0.783505\n",
      "Epoch 17939 - Train Loss: 0.086683, Train Acc: 0.874359 | Val Loss: 0.113615, Val Acc: 0.783505\n",
      "Epoch 17940 - Train Loss: 0.086680, Train Acc: 0.874359 | Val Loss: 0.113614, Val Acc: 0.783505\n",
      "Epoch 17941 - Train Loss: 0.086677, Train Acc: 0.874359 | Val Loss: 0.113612, Val Acc: 0.783505\n",
      "Epoch 17942 - Train Loss: 0.086674, Train Acc: 0.874359 | Val Loss: 0.113611, Val Acc: 0.783505\n",
      "Epoch 17943 - Train Loss: 0.086671, Train Acc: 0.874359 | Val Loss: 0.113609, Val Acc: 0.783505\n",
      "Epoch 17944 - Train Loss: 0.086669, Train Acc: 0.874359 | Val Loss: 0.113608, Val Acc: 0.783505\n",
      "Epoch 17945 - Train Loss: 0.086666, Train Acc: 0.874359 | Val Loss: 0.113606, Val Acc: 0.783505\n",
      "Epoch 17946 - Train Loss: 0.086663, Train Acc: 0.874359 | Val Loss: 0.113605, Val Acc: 0.783505\n",
      "Epoch 17947 - Train Loss: 0.086660, Train Acc: 0.874359 | Val Loss: 0.113603, Val Acc: 0.783505\n",
      "Epoch 17948 - Train Loss: 0.086657, Train Acc: 0.874359 | Val Loss: 0.113602, Val Acc: 0.783505\n",
      "Epoch 17949 - Train Loss: 0.086654, Train Acc: 0.874359 | Val Loss: 0.113600, Val Acc: 0.783505\n",
      "Epoch 17950 - Train Loss: 0.086651, Train Acc: 0.874359 | Val Loss: 0.113599, Val Acc: 0.783505\n",
      "Epoch 17951 - Train Loss: 0.086649, Train Acc: 0.874359 | Val Loss: 0.113597, Val Acc: 0.783505\n",
      "Epoch 17952 - Train Loss: 0.086646, Train Acc: 0.874359 | Val Loss: 0.113596, Val Acc: 0.783505\n",
      "Epoch 17953 - Train Loss: 0.086643, Train Acc: 0.874359 | Val Loss: 0.113594, Val Acc: 0.783505\n",
      "Epoch 17954 - Train Loss: 0.086640, Train Acc: 0.874359 | Val Loss: 0.113593, Val Acc: 0.783505\n",
      "Epoch 17955 - Train Loss: 0.086637, Train Acc: 0.874359 | Val Loss: 0.113591, Val Acc: 0.783505\n",
      "Epoch 17956 - Train Loss: 0.086634, Train Acc: 0.874359 | Val Loss: 0.113590, Val Acc: 0.783505\n",
      "Epoch 17957 - Train Loss: 0.086631, Train Acc: 0.874359 | Val Loss: 0.113588, Val Acc: 0.783505\n",
      "Epoch 17958 - Train Loss: 0.086628, Train Acc: 0.874359 | Val Loss: 0.113587, Val Acc: 0.783505\n",
      "Epoch 17959 - Train Loss: 0.086626, Train Acc: 0.874359 | Val Loss: 0.113585, Val Acc: 0.783505\n",
      "Epoch 17960 - Train Loss: 0.086623, Train Acc: 0.874359 | Val Loss: 0.113584, Val Acc: 0.783505\n",
      "Epoch 17961 - Train Loss: 0.086620, Train Acc: 0.874359 | Val Loss: 0.113582, Val Acc: 0.783505\n",
      "Epoch 17962 - Train Loss: 0.086617, Train Acc: 0.874359 | Val Loss: 0.113581, Val Acc: 0.783505\n",
      "Epoch 17963 - Train Loss: 0.086614, Train Acc: 0.874359 | Val Loss: 0.113579, Val Acc: 0.783505\n",
      "Epoch 17964 - Train Loss: 0.086611, Train Acc: 0.874359 | Val Loss: 0.113578, Val Acc: 0.783505\n",
      "Epoch 17965 - Train Loss: 0.086608, Train Acc: 0.874359 | Val Loss: 0.113576, Val Acc: 0.783505\n",
      "Epoch 17966 - Train Loss: 0.086606, Train Acc: 0.874359 | Val Loss: 0.113575, Val Acc: 0.783505\n",
      "Epoch 17967 - Train Loss: 0.086603, Train Acc: 0.874359 | Val Loss: 0.113573, Val Acc: 0.783505\n",
      "Epoch 17968 - Train Loss: 0.086600, Train Acc: 0.874359 | Val Loss: 0.113572, Val Acc: 0.783505\n",
      "Epoch 17969 - Train Loss: 0.086597, Train Acc: 0.874359 | Val Loss: 0.113570, Val Acc: 0.783505\n",
      "Epoch 17970 - Train Loss: 0.086594, Train Acc: 0.874359 | Val Loss: 0.113569, Val Acc: 0.783505\n",
      "Epoch 17971 - Train Loss: 0.086591, Train Acc: 0.874359 | Val Loss: 0.113567, Val Acc: 0.783505\n",
      "Epoch 17972 - Train Loss: 0.086588, Train Acc: 0.874359 | Val Loss: 0.113566, Val Acc: 0.783505\n",
      "Epoch 17973 - Train Loss: 0.086586, Train Acc: 0.874359 | Val Loss: 0.113564, Val Acc: 0.783505\n",
      "Epoch 17974 - Train Loss: 0.086583, Train Acc: 0.874359 | Val Loss: 0.113563, Val Acc: 0.783505\n",
      "Epoch 17975 - Train Loss: 0.086580, Train Acc: 0.874359 | Val Loss: 0.113561, Val Acc: 0.783505\n",
      "Epoch 17976 - Train Loss: 0.086577, Train Acc: 0.874359 | Val Loss: 0.113560, Val Acc: 0.783505\n",
      "Epoch 17977 - Train Loss: 0.086574, Train Acc: 0.874359 | Val Loss: 0.113558, Val Acc: 0.783505\n",
      "Epoch 17978 - Train Loss: 0.086571, Train Acc: 0.874359 | Val Loss: 0.113557, Val Acc: 0.783505\n",
      "Epoch 17979 - Train Loss: 0.086568, Train Acc: 0.874359 | Val Loss: 0.113555, Val Acc: 0.783505\n",
      "Epoch 17980 - Train Loss: 0.086566, Train Acc: 0.874359 | Val Loss: 0.113554, Val Acc: 0.783505\n",
      "Epoch 17981 - Train Loss: 0.086563, Train Acc: 0.874359 | Val Loss: 0.113552, Val Acc: 0.783505\n",
      "Epoch 17982 - Train Loss: 0.086560, Train Acc: 0.874359 | Val Loss: 0.113551, Val Acc: 0.783505\n",
      "Epoch 17983 - Train Loss: 0.086557, Train Acc: 0.874359 | Val Loss: 0.113549, Val Acc: 0.783505\n",
      "Epoch 17984 - Train Loss: 0.086554, Train Acc: 0.874359 | Val Loss: 0.113547, Val Acc: 0.783505\n",
      "Epoch 17985 - Train Loss: 0.086551, Train Acc: 0.874359 | Val Loss: 0.113546, Val Acc: 0.783505\n",
      "Epoch 17986 - Train Loss: 0.086549, Train Acc: 0.874359 | Val Loss: 0.113544, Val Acc: 0.783505\n",
      "Epoch 17987 - Train Loss: 0.086546, Train Acc: 0.874359 | Val Loss: 0.113543, Val Acc: 0.783505\n",
      "Epoch 17988 - Train Loss: 0.086543, Train Acc: 0.874359 | Val Loss: 0.113541, Val Acc: 0.783505\n",
      "Epoch 17989 - Train Loss: 0.086540, Train Acc: 0.874359 | Val Loss: 0.113540, Val Acc: 0.783505\n",
      "Epoch 17990 - Train Loss: 0.086537, Train Acc: 0.874359 | Val Loss: 0.113538, Val Acc: 0.783505\n",
      "Epoch 17991 - Train Loss: 0.086534, Train Acc: 0.874359 | Val Loss: 0.113537, Val Acc: 0.783505\n",
      "Epoch 17992 - Train Loss: 0.086531, Train Acc: 0.874359 | Val Loss: 0.113536, Val Acc: 0.783505\n",
      "Epoch 17993 - Train Loss: 0.086529, Train Acc: 0.874359 | Val Loss: 0.113534, Val Acc: 0.783505\n",
      "Epoch 17994 - Train Loss: 0.086526, Train Acc: 0.874359 | Val Loss: 0.113533, Val Acc: 0.783505\n",
      "Epoch 17995 - Train Loss: 0.086523, Train Acc: 0.874359 | Val Loss: 0.113531, Val Acc: 0.783505\n",
      "Epoch 17996 - Train Loss: 0.086520, Train Acc: 0.874359 | Val Loss: 0.113530, Val Acc: 0.783505\n",
      "Epoch 17997 - Train Loss: 0.086517, Train Acc: 0.874359 | Val Loss: 0.113528, Val Acc: 0.783505\n",
      "Epoch 17998 - Train Loss: 0.086514, Train Acc: 0.874359 | Val Loss: 0.113527, Val Acc: 0.783505\n",
      "Epoch 17999 - Train Loss: 0.086511, Train Acc: 0.874359 | Val Loss: 0.113525, Val Acc: 0.783505\n",
      "Epoch 18000 - Train Loss: 0.086509, Train Acc: 0.874359 | Val Loss: 0.113524, Val Acc: 0.783505\n",
      "Epoch 18001 - Train Loss: 0.086506, Train Acc: 0.874359 | Val Loss: 0.113522, Val Acc: 0.783505\n",
      "Epoch 18002 - Train Loss: 0.086503, Train Acc: 0.874359 | Val Loss: 0.113521, Val Acc: 0.783505\n",
      "Epoch 18003 - Train Loss: 0.086500, Train Acc: 0.874359 | Val Loss: 0.113519, Val Acc: 0.783505\n",
      "Epoch 18004 - Train Loss: 0.086497, Train Acc: 0.874359 | Val Loss: 0.113518, Val Acc: 0.783505\n",
      "Epoch 18005 - Train Loss: 0.086494, Train Acc: 0.874359 | Val Loss: 0.113516, Val Acc: 0.783505\n",
      "Epoch 18006 - Train Loss: 0.086492, Train Acc: 0.874359 | Val Loss: 0.113515, Val Acc: 0.783505\n",
      "Epoch 18007 - Train Loss: 0.086489, Train Acc: 0.874359 | Val Loss: 0.113513, Val Acc: 0.783505\n",
      "Epoch 18008 - Train Loss: 0.086486, Train Acc: 0.874359 | Val Loss: 0.113512, Val Acc: 0.783505\n",
      "Epoch 18009 - Train Loss: 0.086483, Train Acc: 0.874359 | Val Loss: 0.113510, Val Acc: 0.783505\n",
      "Epoch 18010 - Train Loss: 0.086480, Train Acc: 0.874359 | Val Loss: 0.113509, Val Acc: 0.783505\n",
      "Epoch 18011 - Train Loss: 0.086477, Train Acc: 0.874359 | Val Loss: 0.113507, Val Acc: 0.783505\n",
      "Epoch 18012 - Train Loss: 0.086474, Train Acc: 0.874359 | Val Loss: 0.113506, Val Acc: 0.783505\n",
      "Epoch 18013 - Train Loss: 0.086472, Train Acc: 0.874359 | Val Loss: 0.113504, Val Acc: 0.783505\n",
      "Epoch 18014 - Train Loss: 0.086469, Train Acc: 0.874359 | Val Loss: 0.113503, Val Acc: 0.783505\n",
      "Epoch 18015 - Train Loss: 0.086466, Train Acc: 0.874359 | Val Loss: 0.113501, Val Acc: 0.783505\n",
      "Epoch 18016 - Train Loss: 0.086463, Train Acc: 0.874359 | Val Loss: 0.113500, Val Acc: 0.783505\n",
      "Epoch 18017 - Train Loss: 0.086460, Train Acc: 0.874359 | Val Loss: 0.113498, Val Acc: 0.783505\n",
      "Epoch 18018 - Train Loss: 0.086457, Train Acc: 0.874359 | Val Loss: 0.113497, Val Acc: 0.783505\n",
      "Epoch 18019 - Train Loss: 0.086455, Train Acc: 0.874359 | Val Loss: 0.113495, Val Acc: 0.783505\n",
      "Epoch 18020 - Train Loss: 0.086452, Train Acc: 0.874359 | Val Loss: 0.113494, Val Acc: 0.783505\n",
      "Epoch 18021 - Train Loss: 0.086449, Train Acc: 0.874359 | Val Loss: 0.113492, Val Acc: 0.783505\n",
      "Epoch 18022 - Train Loss: 0.086446, Train Acc: 0.874359 | Val Loss: 0.113491, Val Acc: 0.783505\n",
      "Epoch 18023 - Train Loss: 0.086443, Train Acc: 0.874359 | Val Loss: 0.113489, Val Acc: 0.783505\n",
      "Epoch 18024 - Train Loss: 0.086440, Train Acc: 0.874359 | Val Loss: 0.113488, Val Acc: 0.783505\n",
      "Epoch 18025 - Train Loss: 0.086438, Train Acc: 0.874359 | Val Loss: 0.113486, Val Acc: 0.783505\n",
      "Epoch 18026 - Train Loss: 0.086435, Train Acc: 0.874359 | Val Loss: 0.113485, Val Acc: 0.783505\n",
      "Epoch 18027 - Train Loss: 0.086432, Train Acc: 0.874359 | Val Loss: 0.113483, Val Acc: 0.783505\n",
      "Epoch 18028 - Train Loss: 0.086429, Train Acc: 0.874359 | Val Loss: 0.113482, Val Acc: 0.783505\n",
      "Epoch 18029 - Train Loss: 0.086426, Train Acc: 0.874359 | Val Loss: 0.113480, Val Acc: 0.783505\n",
      "Epoch 18030 - Train Loss: 0.086423, Train Acc: 0.874359 | Val Loss: 0.113479, Val Acc: 0.783505\n",
      "Epoch 18031 - Train Loss: 0.086421, Train Acc: 0.874359 | Val Loss: 0.113477, Val Acc: 0.783505\n",
      "Epoch 18032 - Train Loss: 0.086418, Train Acc: 0.874359 | Val Loss: 0.113476, Val Acc: 0.783505\n",
      "Epoch 18033 - Train Loss: 0.086415, Train Acc: 0.874359 | Val Loss: 0.113474, Val Acc: 0.783505\n",
      "Epoch 18034 - Train Loss: 0.086412, Train Acc: 0.874359 | Val Loss: 0.113473, Val Acc: 0.783505\n",
      "Epoch 18035 - Train Loss: 0.086409, Train Acc: 0.874359 | Val Loss: 0.113471, Val Acc: 0.783505\n",
      "Epoch 18036 - Train Loss: 0.086406, Train Acc: 0.874359 | Val Loss: 0.113470, Val Acc: 0.783505\n",
      "Epoch 18037 - Train Loss: 0.086403, Train Acc: 0.874359 | Val Loss: 0.113468, Val Acc: 0.783505\n",
      "Epoch 18038 - Train Loss: 0.086401, Train Acc: 0.874359 | Val Loss: 0.113467, Val Acc: 0.783505\n",
      "Epoch 18039 - Train Loss: 0.086398, Train Acc: 0.874359 | Val Loss: 0.113465, Val Acc: 0.783505\n",
      "Epoch 18040 - Train Loss: 0.086395, Train Acc: 0.874359 | Val Loss: 0.113464, Val Acc: 0.783505\n",
      "Epoch 18041 - Train Loss: 0.086392, Train Acc: 0.874359 | Val Loss: 0.113462, Val Acc: 0.783505\n",
      "Epoch 18042 - Train Loss: 0.086389, Train Acc: 0.874359 | Val Loss: 0.113461, Val Acc: 0.783505\n",
      "Epoch 18043 - Train Loss: 0.086386, Train Acc: 0.874359 | Val Loss: 0.113460, Val Acc: 0.783505\n",
      "Epoch 18044 - Train Loss: 0.086384, Train Acc: 0.874359 | Val Loss: 0.113458, Val Acc: 0.783505\n",
      "Epoch 18045 - Train Loss: 0.086381, Train Acc: 0.874359 | Val Loss: 0.113457, Val Acc: 0.783505\n",
      "Epoch 18046 - Train Loss: 0.086378, Train Acc: 0.874359 | Val Loss: 0.113455, Val Acc: 0.783505\n",
      "Epoch 18047 - Train Loss: 0.086375, Train Acc: 0.874359 | Val Loss: 0.113454, Val Acc: 0.783505\n",
      "Epoch 18048 - Train Loss: 0.086372, Train Acc: 0.874359 | Val Loss: 0.113452, Val Acc: 0.783505\n",
      "Epoch 18049 - Train Loss: 0.086369, Train Acc: 0.874359 | Val Loss: 0.113451, Val Acc: 0.783505\n",
      "Epoch 18050 - Train Loss: 0.086367, Train Acc: 0.874359 | Val Loss: 0.113449, Val Acc: 0.783505\n",
      "Epoch 18051 - Train Loss: 0.086364, Train Acc: 0.874359 | Val Loss: 0.113448, Val Acc: 0.783505\n",
      "Epoch 18052 - Train Loss: 0.086361, Train Acc: 0.874359 | Val Loss: 0.113446, Val Acc: 0.783505\n",
      "Epoch 18053 - Train Loss: 0.086358, Train Acc: 0.874359 | Val Loss: 0.113445, Val Acc: 0.783505\n",
      "Epoch 18054 - Train Loss: 0.086355, Train Acc: 0.874359 | Val Loss: 0.113443, Val Acc: 0.783505\n",
      "Epoch 18055 - Train Loss: 0.086353, Train Acc: 0.874359 | Val Loss: 0.113442, Val Acc: 0.783505\n",
      "Epoch 18056 - Train Loss: 0.086350, Train Acc: 0.874359 | Val Loss: 0.113440, Val Acc: 0.783505\n",
      "Epoch 18057 - Train Loss: 0.086347, Train Acc: 0.874359 | Val Loss: 0.113439, Val Acc: 0.783505\n",
      "Epoch 18058 - Train Loss: 0.086344, Train Acc: 0.874359 | Val Loss: 0.113437, Val Acc: 0.783505\n",
      "Epoch 18059 - Train Loss: 0.086341, Train Acc: 0.874359 | Val Loss: 0.113436, Val Acc: 0.783505\n",
      "Epoch 18060 - Train Loss: 0.086338, Train Acc: 0.874359 | Val Loss: 0.113434, Val Acc: 0.783505\n",
      "Epoch 18061 - Train Loss: 0.086336, Train Acc: 0.874359 | Val Loss: 0.113433, Val Acc: 0.783505\n",
      "Epoch 18062 - Train Loss: 0.086333, Train Acc: 0.874359 | Val Loss: 0.113431, Val Acc: 0.783505\n",
      "Epoch 18063 - Train Loss: 0.086330, Train Acc: 0.874359 | Val Loss: 0.113430, Val Acc: 0.783505\n",
      "Epoch 18064 - Train Loss: 0.086327, Train Acc: 0.874359 | Val Loss: 0.113428, Val Acc: 0.783505\n",
      "Epoch 18065 - Train Loss: 0.086324, Train Acc: 0.874359 | Val Loss: 0.113427, Val Acc: 0.783505\n",
      "Epoch 18066 - Train Loss: 0.086321, Train Acc: 0.874359 | Val Loss: 0.113426, Val Acc: 0.783505\n",
      "Epoch 18067 - Train Loss: 0.086319, Train Acc: 0.874359 | Val Loss: 0.113424, Val Acc: 0.783505\n",
      "Epoch 18068 - Train Loss: 0.086316, Train Acc: 0.874359 | Val Loss: 0.113423, Val Acc: 0.783505\n",
      "Epoch 18069 - Train Loss: 0.086313, Train Acc: 0.874359 | Val Loss: 0.113421, Val Acc: 0.783505\n",
      "Epoch 18070 - Train Loss: 0.086310, Train Acc: 0.874359 | Val Loss: 0.113420, Val Acc: 0.783505\n",
      "Epoch 18071 - Train Loss: 0.086307, Train Acc: 0.874359 | Val Loss: 0.113418, Val Acc: 0.783505\n",
      "Epoch 18072 - Train Loss: 0.086304, Train Acc: 0.874359 | Val Loss: 0.113417, Val Acc: 0.783505\n",
      "Epoch 18073 - Train Loss: 0.086302, Train Acc: 0.874359 | Val Loss: 0.113415, Val Acc: 0.783505\n",
      "Epoch 18074 - Train Loss: 0.086299, Train Acc: 0.874359 | Val Loss: 0.113414, Val Acc: 0.783505\n",
      "Epoch 18075 - Train Loss: 0.086296, Train Acc: 0.874359 | Val Loss: 0.113412, Val Acc: 0.783505\n",
      "Epoch 18076 - Train Loss: 0.086293, Train Acc: 0.874359 | Val Loss: 0.113411, Val Acc: 0.783505\n",
      "Epoch 18077 - Train Loss: 0.086290, Train Acc: 0.874359 | Val Loss: 0.113409, Val Acc: 0.783505\n",
      "Epoch 18078 - Train Loss: 0.086288, Train Acc: 0.874359 | Val Loss: 0.113408, Val Acc: 0.783505\n",
      "Epoch 18079 - Train Loss: 0.086285, Train Acc: 0.874359 | Val Loss: 0.113406, Val Acc: 0.783505\n",
      "Epoch 18080 - Train Loss: 0.086282, Train Acc: 0.874359 | Val Loss: 0.113405, Val Acc: 0.783505\n",
      "Epoch 18081 - Train Loss: 0.086279, Train Acc: 0.874359 | Val Loss: 0.113403, Val Acc: 0.783505\n",
      "Epoch 18082 - Train Loss: 0.086276, Train Acc: 0.874359 | Val Loss: 0.113402, Val Acc: 0.783505\n",
      "Epoch 18083 - Train Loss: 0.086273, Train Acc: 0.874359 | Val Loss: 0.113401, Val Acc: 0.783505\n",
      "Epoch 18084 - Train Loss: 0.086271, Train Acc: 0.874359 | Val Loss: 0.113399, Val Acc: 0.783505\n",
      "Epoch 18085 - Train Loss: 0.086268, Train Acc: 0.874359 | Val Loss: 0.113398, Val Acc: 0.783505\n",
      "Epoch 18086 - Train Loss: 0.086265, Train Acc: 0.874359 | Val Loss: 0.113396, Val Acc: 0.783505\n",
      "Epoch 18087 - Train Loss: 0.086262, Train Acc: 0.874359 | Val Loss: 0.113395, Val Acc: 0.783505\n",
      "Epoch 18088 - Train Loss: 0.086259, Train Acc: 0.874359 | Val Loss: 0.113393, Val Acc: 0.783505\n",
      "Epoch 18089 - Train Loss: 0.086256, Train Acc: 0.874359 | Val Loss: 0.113392, Val Acc: 0.783505\n",
      "Epoch 18090 - Train Loss: 0.086254, Train Acc: 0.874359 | Val Loss: 0.113390, Val Acc: 0.783505\n",
      "Epoch 18091 - Train Loss: 0.086251, Train Acc: 0.874359 | Val Loss: 0.113389, Val Acc: 0.783505\n",
      "Epoch 18092 - Train Loss: 0.086248, Train Acc: 0.874359 | Val Loss: 0.113387, Val Acc: 0.783505\n",
      "Epoch 18093 - Train Loss: 0.086245, Train Acc: 0.874359 | Val Loss: 0.113386, Val Acc: 0.783505\n",
      "Epoch 18094 - Train Loss: 0.086242, Train Acc: 0.874359 | Val Loss: 0.113384, Val Acc: 0.783505\n",
      "Epoch 18095 - Train Loss: 0.086240, Train Acc: 0.874359 | Val Loss: 0.113383, Val Acc: 0.783505\n",
      "Epoch 18096 - Train Loss: 0.086237, Train Acc: 0.874359 | Val Loss: 0.113381, Val Acc: 0.783505\n",
      "Epoch 18097 - Train Loss: 0.086234, Train Acc: 0.874359 | Val Loss: 0.113380, Val Acc: 0.783505\n",
      "Epoch 18098 - Train Loss: 0.086231, Train Acc: 0.874359 | Val Loss: 0.113379, Val Acc: 0.783505\n",
      "Epoch 18099 - Train Loss: 0.086228, Train Acc: 0.874359 | Val Loss: 0.113377, Val Acc: 0.783505\n",
      "Epoch 18100 - Train Loss: 0.086226, Train Acc: 0.874359 | Val Loss: 0.113376, Val Acc: 0.783505\n",
      "Epoch 18101 - Train Loss: 0.086223, Train Acc: 0.874359 | Val Loss: 0.113374, Val Acc: 0.783505\n",
      "Epoch 18102 - Train Loss: 0.086220, Train Acc: 0.874359 | Val Loss: 0.113373, Val Acc: 0.783505\n",
      "Epoch 18103 - Train Loss: 0.086217, Train Acc: 0.874359 | Val Loss: 0.113371, Val Acc: 0.783505\n",
      "Epoch 18104 - Train Loss: 0.086214, Train Acc: 0.874359 | Val Loss: 0.113370, Val Acc: 0.783505\n",
      "Epoch 18105 - Train Loss: 0.086211, Train Acc: 0.874359 | Val Loss: 0.113368, Val Acc: 0.783505\n",
      "Epoch 18106 - Train Loss: 0.086209, Train Acc: 0.874359 | Val Loss: 0.113367, Val Acc: 0.783505\n",
      "Epoch 18107 - Train Loss: 0.086206, Train Acc: 0.874359 | Val Loss: 0.113365, Val Acc: 0.783505\n",
      "Epoch 18108 - Train Loss: 0.086203, Train Acc: 0.874359 | Val Loss: 0.113364, Val Acc: 0.783505\n",
      "Epoch 18109 - Train Loss: 0.086200, Train Acc: 0.874359 | Val Loss: 0.113362, Val Acc: 0.783505\n",
      "Epoch 18110 - Train Loss: 0.086197, Train Acc: 0.874359 | Val Loss: 0.113361, Val Acc: 0.783505\n",
      "Epoch 18111 - Train Loss: 0.086195, Train Acc: 0.874359 | Val Loss: 0.113360, Val Acc: 0.783505\n",
      "Epoch 18112 - Train Loss: 0.086192, Train Acc: 0.874359 | Val Loss: 0.113358, Val Acc: 0.783505\n",
      "Epoch 18113 - Train Loss: 0.086189, Train Acc: 0.874359 | Val Loss: 0.113357, Val Acc: 0.783505\n",
      "Epoch 18114 - Train Loss: 0.086186, Train Acc: 0.874359 | Val Loss: 0.113355, Val Acc: 0.783505\n",
      "Epoch 18115 - Train Loss: 0.086183, Train Acc: 0.874359 | Val Loss: 0.113354, Val Acc: 0.783505\n",
      "Epoch 18116 - Train Loss: 0.086180, Train Acc: 0.874359 | Val Loss: 0.113352, Val Acc: 0.783505\n",
      "Epoch 18117 - Train Loss: 0.086178, Train Acc: 0.874359 | Val Loss: 0.113351, Val Acc: 0.783505\n",
      "Epoch 18118 - Train Loss: 0.086175, Train Acc: 0.874359 | Val Loss: 0.113349, Val Acc: 0.783505\n",
      "Epoch 18119 - Train Loss: 0.086172, Train Acc: 0.874359 | Val Loss: 0.113348, Val Acc: 0.783505\n",
      "Epoch 18120 - Train Loss: 0.086169, Train Acc: 0.874359 | Val Loss: 0.113346, Val Acc: 0.783505\n",
      "Epoch 18121 - Train Loss: 0.086166, Train Acc: 0.874359 | Val Loss: 0.113345, Val Acc: 0.783505\n",
      "Epoch 18122 - Train Loss: 0.086164, Train Acc: 0.874359 | Val Loss: 0.113343, Val Acc: 0.783505\n",
      "Epoch 18123 - Train Loss: 0.086161, Train Acc: 0.874359 | Val Loss: 0.113342, Val Acc: 0.783505\n",
      "Epoch 18124 - Train Loss: 0.086158, Train Acc: 0.874359 | Val Loss: 0.113341, Val Acc: 0.783505\n",
      "Epoch 18125 - Train Loss: 0.086155, Train Acc: 0.874359 | Val Loss: 0.113339, Val Acc: 0.783505\n",
      "Epoch 18126 - Train Loss: 0.086152, Train Acc: 0.874359 | Val Loss: 0.113338, Val Acc: 0.783505\n",
      "Epoch 18127 - Train Loss: 0.086150, Train Acc: 0.874359 | Val Loss: 0.113336, Val Acc: 0.783505\n",
      "Epoch 18128 - Train Loss: 0.086147, Train Acc: 0.874359 | Val Loss: 0.113335, Val Acc: 0.783505\n",
      "Epoch 18129 - Train Loss: 0.086144, Train Acc: 0.874359 | Val Loss: 0.113333, Val Acc: 0.783505\n",
      "Epoch 18130 - Train Loss: 0.086141, Train Acc: 0.874359 | Val Loss: 0.113332, Val Acc: 0.783505\n",
      "Epoch 18131 - Train Loss: 0.086138, Train Acc: 0.874359 | Val Loss: 0.113330, Val Acc: 0.783505\n",
      "Epoch 18132 - Train Loss: 0.086136, Train Acc: 0.874359 | Val Loss: 0.113329, Val Acc: 0.783505\n",
      "Epoch 18133 - Train Loss: 0.086133, Train Acc: 0.874359 | Val Loss: 0.113327, Val Acc: 0.783505\n",
      "Epoch 18134 - Train Loss: 0.086130, Train Acc: 0.874359 | Val Loss: 0.113326, Val Acc: 0.783505\n",
      "Epoch 18135 - Train Loss: 0.086127, Train Acc: 0.874359 | Val Loss: 0.113325, Val Acc: 0.783505\n",
      "Epoch 18136 - Train Loss: 0.086124, Train Acc: 0.874359 | Val Loss: 0.113323, Val Acc: 0.783505\n",
      "Epoch 18137 - Train Loss: 0.086122, Train Acc: 0.874359 | Val Loss: 0.113322, Val Acc: 0.783505\n",
      "Epoch 18138 - Train Loss: 0.086119, Train Acc: 0.874359 | Val Loss: 0.113320, Val Acc: 0.783505\n",
      "Epoch 18139 - Train Loss: 0.086116, Train Acc: 0.874359 | Val Loss: 0.113319, Val Acc: 0.783505\n",
      "Epoch 18140 - Train Loss: 0.086113, Train Acc: 0.874359 | Val Loss: 0.113317, Val Acc: 0.783505\n",
      "Epoch 18141 - Train Loss: 0.086110, Train Acc: 0.874359 | Val Loss: 0.113316, Val Acc: 0.783505\n",
      "Epoch 18142 - Train Loss: 0.086108, Train Acc: 0.874359 | Val Loss: 0.113314, Val Acc: 0.783505\n",
      "Epoch 18143 - Train Loss: 0.086105, Train Acc: 0.874359 | Val Loss: 0.113313, Val Acc: 0.783505\n",
      "Epoch 18144 - Train Loss: 0.086102, Train Acc: 0.874359 | Val Loss: 0.113312, Val Acc: 0.783505\n",
      "Epoch 18145 - Train Loss: 0.086099, Train Acc: 0.874359 | Val Loss: 0.113310, Val Acc: 0.783505\n",
      "Epoch 18146 - Train Loss: 0.086096, Train Acc: 0.874359 | Val Loss: 0.113309, Val Acc: 0.783505\n",
      "Epoch 18147 - Train Loss: 0.086094, Train Acc: 0.874359 | Val Loss: 0.113307, Val Acc: 0.783505\n",
      "Epoch 18148 - Train Loss: 0.086091, Train Acc: 0.874359 | Val Loss: 0.113306, Val Acc: 0.783505\n",
      "Epoch 18149 - Train Loss: 0.086088, Train Acc: 0.874359 | Val Loss: 0.113304, Val Acc: 0.783505\n",
      "Epoch 18150 - Train Loss: 0.086085, Train Acc: 0.874359 | Val Loss: 0.113303, Val Acc: 0.783505\n",
      "Epoch 18151 - Train Loss: 0.086082, Train Acc: 0.874359 | Val Loss: 0.113301, Val Acc: 0.783505\n",
      "Epoch 18152 - Train Loss: 0.086080, Train Acc: 0.874359 | Val Loss: 0.113300, Val Acc: 0.783505\n",
      "Epoch 18153 - Train Loss: 0.086077, Train Acc: 0.874359 | Val Loss: 0.113299, Val Acc: 0.783505\n",
      "Epoch 18154 - Train Loss: 0.086074, Train Acc: 0.874359 | Val Loss: 0.113297, Val Acc: 0.783505\n",
      "Epoch 18155 - Train Loss: 0.086071, Train Acc: 0.874359 | Val Loss: 0.113296, Val Acc: 0.783505\n",
      "Epoch 18156 - Train Loss: 0.086068, Train Acc: 0.874359 | Val Loss: 0.113294, Val Acc: 0.783505\n",
      "Epoch 18157 - Train Loss: 0.086066, Train Acc: 0.874359 | Val Loss: 0.113293, Val Acc: 0.783505\n",
      "Epoch 18158 - Train Loss: 0.086063, Train Acc: 0.874359 | Val Loss: 0.113291, Val Acc: 0.783505\n",
      "Epoch 18159 - Train Loss: 0.086060, Train Acc: 0.874359 | Val Loss: 0.113290, Val Acc: 0.783505\n",
      "Epoch 18160 - Train Loss: 0.086057, Train Acc: 0.874359 | Val Loss: 0.113288, Val Acc: 0.783505\n",
      "Epoch 18161 - Train Loss: 0.086054, Train Acc: 0.874359 | Val Loss: 0.113287, Val Acc: 0.783505\n",
      "Epoch 18162 - Train Loss: 0.086052, Train Acc: 0.874359 | Val Loss: 0.113286, Val Acc: 0.783505\n",
      "Epoch 18163 - Train Loss: 0.086049, Train Acc: 0.874359 | Val Loss: 0.113284, Val Acc: 0.783505\n",
      "Epoch 18164 - Train Loss: 0.086046, Train Acc: 0.874359 | Val Loss: 0.113283, Val Acc: 0.783505\n",
      "Epoch 18165 - Train Loss: 0.086043, Train Acc: 0.874359 | Val Loss: 0.113281, Val Acc: 0.783505\n",
      "Epoch 18166 - Train Loss: 0.086040, Train Acc: 0.874359 | Val Loss: 0.113280, Val Acc: 0.783505\n",
      "Epoch 18167 - Train Loss: 0.086038, Train Acc: 0.874359 | Val Loss: 0.113278, Val Acc: 0.783505\n",
      "Epoch 18168 - Train Loss: 0.086035, Train Acc: 0.874359 | Val Loss: 0.113277, Val Acc: 0.783505\n",
      "Epoch 18169 - Train Loss: 0.086032, Train Acc: 0.874359 | Val Loss: 0.113275, Val Acc: 0.783505\n",
      "Epoch 18170 - Train Loss: 0.086029, Train Acc: 0.874359 | Val Loss: 0.113274, Val Acc: 0.783505\n",
      "Epoch 18171 - Train Loss: 0.086026, Train Acc: 0.874359 | Val Loss: 0.113272, Val Acc: 0.783505\n",
      "Epoch 18172 - Train Loss: 0.086024, Train Acc: 0.874359 | Val Loss: 0.113271, Val Acc: 0.783505\n",
      "Epoch 18173 - Train Loss: 0.086021, Train Acc: 0.874359 | Val Loss: 0.113270, Val Acc: 0.783505\n",
      "Epoch 18174 - Train Loss: 0.086018, Train Acc: 0.874359 | Val Loss: 0.113268, Val Acc: 0.783505\n",
      "Epoch 18175 - Train Loss: 0.086015, Train Acc: 0.874359 | Val Loss: 0.113267, Val Acc: 0.783505\n",
      "Epoch 18176 - Train Loss: 0.086012, Train Acc: 0.874359 | Val Loss: 0.113265, Val Acc: 0.783505\n",
      "Epoch 18177 - Train Loss: 0.086010, Train Acc: 0.874359 | Val Loss: 0.113264, Val Acc: 0.783505\n",
      "Epoch 18178 - Train Loss: 0.086007, Train Acc: 0.874359 | Val Loss: 0.113262, Val Acc: 0.783505\n",
      "Epoch 18179 - Train Loss: 0.086004, Train Acc: 0.874359 | Val Loss: 0.113261, Val Acc: 0.783505\n",
      "Epoch 18180 - Train Loss: 0.086001, Train Acc: 0.874359 | Val Loss: 0.113259, Val Acc: 0.783505\n",
      "Epoch 18181 - Train Loss: 0.085999, Train Acc: 0.874359 | Val Loss: 0.113258, Val Acc: 0.783505\n",
      "Epoch 18182 - Train Loss: 0.085996, Train Acc: 0.874359 | Val Loss: 0.113257, Val Acc: 0.783505\n",
      "Epoch 18183 - Train Loss: 0.085993, Train Acc: 0.874359 | Val Loss: 0.113255, Val Acc: 0.783505\n",
      "Epoch 18184 - Train Loss: 0.085990, Train Acc: 0.874359 | Val Loss: 0.113254, Val Acc: 0.783505\n",
      "Epoch 18185 - Train Loss: 0.085987, Train Acc: 0.874359 | Val Loss: 0.113252, Val Acc: 0.783505\n",
      "Epoch 18186 - Train Loss: 0.085985, Train Acc: 0.874359 | Val Loss: 0.113251, Val Acc: 0.783505\n",
      "Epoch 18187 - Train Loss: 0.085982, Train Acc: 0.874359 | Val Loss: 0.113249, Val Acc: 0.783505\n",
      "Epoch 18188 - Train Loss: 0.085979, Train Acc: 0.874359 | Val Loss: 0.113248, Val Acc: 0.783505\n",
      "Epoch 18189 - Train Loss: 0.085976, Train Acc: 0.874359 | Val Loss: 0.113246, Val Acc: 0.783505\n",
      "Epoch 18190 - Train Loss: 0.085973, Train Acc: 0.874359 | Val Loss: 0.113245, Val Acc: 0.783505\n",
      "Epoch 18191 - Train Loss: 0.085971, Train Acc: 0.874359 | Val Loss: 0.113243, Val Acc: 0.783505\n",
      "Epoch 18192 - Train Loss: 0.085968, Train Acc: 0.874359 | Val Loss: 0.113242, Val Acc: 0.783505\n",
      "Epoch 18193 - Train Loss: 0.085965, Train Acc: 0.874359 | Val Loss: 0.113241, Val Acc: 0.783505\n",
      "Epoch 18194 - Train Loss: 0.085962, Train Acc: 0.874359 | Val Loss: 0.113239, Val Acc: 0.783505\n",
      "Epoch 18195 - Train Loss: 0.085959, Train Acc: 0.874359 | Val Loss: 0.113238, Val Acc: 0.783505\n",
      "Epoch 18196 - Train Loss: 0.085957, Train Acc: 0.874359 | Val Loss: 0.113236, Val Acc: 0.783505\n",
      "Epoch 18197 - Train Loss: 0.085954, Train Acc: 0.875641 | Val Loss: 0.113235, Val Acc: 0.783505\n",
      "Epoch 18198 - Train Loss: 0.085951, Train Acc: 0.875641 | Val Loss: 0.113233, Val Acc: 0.783505\n",
      "Epoch 18199 - Train Loss: 0.085948, Train Acc: 0.875641 | Val Loss: 0.113232, Val Acc: 0.783505\n",
      "Epoch 18200 - Train Loss: 0.085946, Train Acc: 0.875641 | Val Loss: 0.113231, Val Acc: 0.783505\n",
      "Epoch 18201 - Train Loss: 0.085943, Train Acc: 0.875641 | Val Loss: 0.113229, Val Acc: 0.783505\n",
      "Epoch 18202 - Train Loss: 0.085940, Train Acc: 0.875641 | Val Loss: 0.113228, Val Acc: 0.783505\n",
      "Epoch 18203 - Train Loss: 0.085937, Train Acc: 0.875641 | Val Loss: 0.113226, Val Acc: 0.783505\n",
      "Epoch 18204 - Train Loss: 0.085934, Train Acc: 0.875641 | Val Loss: 0.113225, Val Acc: 0.783505\n",
      "Epoch 18205 - Train Loss: 0.085932, Train Acc: 0.875641 | Val Loss: 0.113223, Val Acc: 0.783505\n",
      "Epoch 18206 - Train Loss: 0.085929, Train Acc: 0.875641 | Val Loss: 0.113222, Val Acc: 0.783505\n",
      "Epoch 18207 - Train Loss: 0.085926, Train Acc: 0.875641 | Val Loss: 0.113220, Val Acc: 0.783505\n",
      "Epoch 18208 - Train Loss: 0.085923, Train Acc: 0.875641 | Val Loss: 0.113219, Val Acc: 0.783505\n",
      "Epoch 18209 - Train Loss: 0.085921, Train Acc: 0.875641 | Val Loss: 0.113218, Val Acc: 0.783505\n",
      "Epoch 18210 - Train Loss: 0.085918, Train Acc: 0.875641 | Val Loss: 0.113216, Val Acc: 0.783505\n",
      "Epoch 18211 - Train Loss: 0.085915, Train Acc: 0.875641 | Val Loss: 0.113215, Val Acc: 0.783505\n",
      "Epoch 18212 - Train Loss: 0.085912, Train Acc: 0.875641 | Val Loss: 0.113213, Val Acc: 0.783505\n",
      "Epoch 18213 - Train Loss: 0.085909, Train Acc: 0.875641 | Val Loss: 0.113212, Val Acc: 0.783505\n",
      "Epoch 18214 - Train Loss: 0.085907, Train Acc: 0.875641 | Val Loss: 0.113210, Val Acc: 0.783505\n",
      "Epoch 18215 - Train Loss: 0.085904, Train Acc: 0.875641 | Val Loss: 0.113209, Val Acc: 0.783505\n",
      "Epoch 18216 - Train Loss: 0.085901, Train Acc: 0.875641 | Val Loss: 0.113207, Val Acc: 0.783505\n",
      "Epoch 18217 - Train Loss: 0.085898, Train Acc: 0.875641 | Val Loss: 0.113206, Val Acc: 0.783505\n",
      "Epoch 18218 - Train Loss: 0.085896, Train Acc: 0.875641 | Val Loss: 0.113205, Val Acc: 0.783505\n",
      "Epoch 18219 - Train Loss: 0.085893, Train Acc: 0.875641 | Val Loss: 0.113203, Val Acc: 0.783505\n",
      "Epoch 18220 - Train Loss: 0.085890, Train Acc: 0.875641 | Val Loss: 0.113202, Val Acc: 0.783505\n",
      "Epoch 18221 - Train Loss: 0.085887, Train Acc: 0.875641 | Val Loss: 0.113200, Val Acc: 0.783505\n",
      "Epoch 18222 - Train Loss: 0.085884, Train Acc: 0.875641 | Val Loss: 0.113199, Val Acc: 0.783505\n",
      "Epoch 18223 - Train Loss: 0.085882, Train Acc: 0.875641 | Val Loss: 0.113197, Val Acc: 0.783505\n",
      "Epoch 18224 - Train Loss: 0.085879, Train Acc: 0.875641 | Val Loss: 0.113196, Val Acc: 0.783505\n",
      "Epoch 18225 - Train Loss: 0.085876, Train Acc: 0.875641 | Val Loss: 0.113195, Val Acc: 0.783505\n",
      "Epoch 18226 - Train Loss: 0.085873, Train Acc: 0.875641 | Val Loss: 0.113193, Val Acc: 0.783505\n",
      "Epoch 18227 - Train Loss: 0.085871, Train Acc: 0.875641 | Val Loss: 0.113192, Val Acc: 0.783505\n",
      "Epoch 18228 - Train Loss: 0.085868, Train Acc: 0.875641 | Val Loss: 0.113190, Val Acc: 0.783505\n",
      "Epoch 18229 - Train Loss: 0.085865, Train Acc: 0.875641 | Val Loss: 0.113189, Val Acc: 0.783505\n",
      "Epoch 18230 - Train Loss: 0.085862, Train Acc: 0.875641 | Val Loss: 0.113187, Val Acc: 0.783505\n",
      "Epoch 18231 - Train Loss: 0.085859, Train Acc: 0.875641 | Val Loss: 0.113186, Val Acc: 0.783505\n",
      "Epoch 18232 - Train Loss: 0.085857, Train Acc: 0.875641 | Val Loss: 0.113185, Val Acc: 0.783505\n",
      "Epoch 18233 - Train Loss: 0.085854, Train Acc: 0.875641 | Val Loss: 0.113183, Val Acc: 0.783505\n",
      "Epoch 18234 - Train Loss: 0.085851, Train Acc: 0.874359 | Val Loss: 0.113182, Val Acc: 0.783505\n",
      "Epoch 18235 - Train Loss: 0.085848, Train Acc: 0.874359 | Val Loss: 0.113180, Val Acc: 0.783505\n",
      "Epoch 18236 - Train Loss: 0.085846, Train Acc: 0.874359 | Val Loss: 0.113179, Val Acc: 0.783505\n",
      "Epoch 18237 - Train Loss: 0.085843, Train Acc: 0.874359 | Val Loss: 0.113177, Val Acc: 0.783505\n",
      "Epoch 18238 - Train Loss: 0.085840, Train Acc: 0.874359 | Val Loss: 0.113176, Val Acc: 0.783505\n",
      "Epoch 18239 - Train Loss: 0.085837, Train Acc: 0.874359 | Val Loss: 0.113174, Val Acc: 0.783505\n",
      "Epoch 18240 - Train Loss: 0.085834, Train Acc: 0.874359 | Val Loss: 0.113173, Val Acc: 0.783505\n",
      "Epoch 18241 - Train Loss: 0.085832, Train Acc: 0.874359 | Val Loss: 0.113172, Val Acc: 0.783505\n",
      "Epoch 18242 - Train Loss: 0.085829, Train Acc: 0.874359 | Val Loss: 0.113170, Val Acc: 0.783505\n",
      "Epoch 18243 - Train Loss: 0.085826, Train Acc: 0.874359 | Val Loss: 0.113169, Val Acc: 0.783505\n",
      "Epoch 18244 - Train Loss: 0.085823, Train Acc: 0.874359 | Val Loss: 0.113167, Val Acc: 0.783505\n",
      "Epoch 18245 - Train Loss: 0.085821, Train Acc: 0.874359 | Val Loss: 0.113166, Val Acc: 0.783505\n",
      "Epoch 18246 - Train Loss: 0.085818, Train Acc: 0.874359 | Val Loss: 0.113165, Val Acc: 0.783505\n",
      "Epoch 18247 - Train Loss: 0.085815, Train Acc: 0.874359 | Val Loss: 0.113163, Val Acc: 0.783505\n",
      "Epoch 18248 - Train Loss: 0.085812, Train Acc: 0.874359 | Val Loss: 0.113162, Val Acc: 0.783505\n",
      "Epoch 18249 - Train Loss: 0.085810, Train Acc: 0.874359 | Val Loss: 0.113160, Val Acc: 0.783505\n",
      "Epoch 18250 - Train Loss: 0.085807, Train Acc: 0.874359 | Val Loss: 0.113159, Val Acc: 0.783505\n",
      "Epoch 18251 - Train Loss: 0.085804, Train Acc: 0.874359 | Val Loss: 0.113157, Val Acc: 0.783505\n",
      "Epoch 18252 - Train Loss: 0.085801, Train Acc: 0.874359 | Val Loss: 0.113156, Val Acc: 0.783505\n",
      "Epoch 18253 - Train Loss: 0.085798, Train Acc: 0.874359 | Val Loss: 0.113155, Val Acc: 0.783505\n",
      "Epoch 18254 - Train Loss: 0.085796, Train Acc: 0.874359 | Val Loss: 0.113153, Val Acc: 0.783505\n",
      "Epoch 18255 - Train Loss: 0.085793, Train Acc: 0.874359 | Val Loss: 0.113152, Val Acc: 0.783505\n",
      "Epoch 18256 - Train Loss: 0.085790, Train Acc: 0.874359 | Val Loss: 0.113150, Val Acc: 0.783505\n",
      "Epoch 18257 - Train Loss: 0.085787, Train Acc: 0.874359 | Val Loss: 0.113149, Val Acc: 0.783505\n",
      "Epoch 18258 - Train Loss: 0.085785, Train Acc: 0.874359 | Val Loss: 0.113147, Val Acc: 0.783505\n",
      "Epoch 18259 - Train Loss: 0.085782, Train Acc: 0.874359 | Val Loss: 0.113146, Val Acc: 0.783505\n",
      "Epoch 18260 - Train Loss: 0.085779, Train Acc: 0.874359 | Val Loss: 0.113145, Val Acc: 0.783505\n",
      "Epoch 18261 - Train Loss: 0.085776, Train Acc: 0.874359 | Val Loss: 0.113143, Val Acc: 0.783505\n",
      "Epoch 18262 - Train Loss: 0.085774, Train Acc: 0.874359 | Val Loss: 0.113142, Val Acc: 0.783505\n",
      "Epoch 18263 - Train Loss: 0.085771, Train Acc: 0.874359 | Val Loss: 0.113140, Val Acc: 0.783505\n",
      "Epoch 18264 - Train Loss: 0.085768, Train Acc: 0.874359 | Val Loss: 0.113139, Val Acc: 0.783505\n",
      "Epoch 18265 - Train Loss: 0.085765, Train Acc: 0.874359 | Val Loss: 0.113137, Val Acc: 0.783505\n",
      "Epoch 18266 - Train Loss: 0.085763, Train Acc: 0.874359 | Val Loss: 0.113136, Val Acc: 0.783505\n",
      "Epoch 18267 - Train Loss: 0.085760, Train Acc: 0.874359 | Val Loss: 0.113135, Val Acc: 0.783505\n",
      "Epoch 18268 - Train Loss: 0.085757, Train Acc: 0.874359 | Val Loss: 0.113133, Val Acc: 0.783505\n",
      "Epoch 18269 - Train Loss: 0.085754, Train Acc: 0.874359 | Val Loss: 0.113132, Val Acc: 0.783505\n",
      "Epoch 18270 - Train Loss: 0.085751, Train Acc: 0.874359 | Val Loss: 0.113130, Val Acc: 0.783505\n",
      "Epoch 18271 - Train Loss: 0.085749, Train Acc: 0.874359 | Val Loss: 0.113129, Val Acc: 0.783505\n",
      "Epoch 18272 - Train Loss: 0.085746, Train Acc: 0.874359 | Val Loss: 0.113127, Val Acc: 0.783505\n",
      "Epoch 18273 - Train Loss: 0.085743, Train Acc: 0.874359 | Val Loss: 0.113126, Val Acc: 0.783505\n",
      "Epoch 18274 - Train Loss: 0.085740, Train Acc: 0.874359 | Val Loss: 0.113125, Val Acc: 0.783505\n",
      "Epoch 18275 - Train Loss: 0.085738, Train Acc: 0.874359 | Val Loss: 0.113123, Val Acc: 0.783505\n",
      "Epoch 18276 - Train Loss: 0.085735, Train Acc: 0.874359 | Val Loss: 0.113122, Val Acc: 0.783505\n",
      "Epoch 18277 - Train Loss: 0.085732, Train Acc: 0.874359 | Val Loss: 0.113120, Val Acc: 0.783505\n",
      "Epoch 18278 - Train Loss: 0.085729, Train Acc: 0.874359 | Val Loss: 0.113119, Val Acc: 0.783505\n",
      "Epoch 18279 - Train Loss: 0.085727, Train Acc: 0.874359 | Val Loss: 0.113118, Val Acc: 0.783505\n",
      "Epoch 18280 - Train Loss: 0.085724, Train Acc: 0.874359 | Val Loss: 0.113116, Val Acc: 0.783505\n",
      "Epoch 18281 - Train Loss: 0.085721, Train Acc: 0.874359 | Val Loss: 0.113115, Val Acc: 0.783505\n",
      "Epoch 18282 - Train Loss: 0.085718, Train Acc: 0.874359 | Val Loss: 0.113113, Val Acc: 0.783505\n",
      "Epoch 18283 - Train Loss: 0.085716, Train Acc: 0.874359 | Val Loss: 0.113112, Val Acc: 0.783505\n",
      "Epoch 18284 - Train Loss: 0.085713, Train Acc: 0.874359 | Val Loss: 0.113110, Val Acc: 0.783505\n",
      "Epoch 18285 - Train Loss: 0.085710, Train Acc: 0.874359 | Val Loss: 0.113109, Val Acc: 0.783505\n",
      "Epoch 18286 - Train Loss: 0.085707, Train Acc: 0.874359 | Val Loss: 0.113108, Val Acc: 0.783505\n",
      "Epoch 18287 - Train Loss: 0.085705, Train Acc: 0.874359 | Val Loss: 0.113106, Val Acc: 0.783505\n",
      "Epoch 18288 - Train Loss: 0.085702, Train Acc: 0.874359 | Val Loss: 0.113105, Val Acc: 0.783505\n",
      "Epoch 18289 - Train Loss: 0.085699, Train Acc: 0.874359 | Val Loss: 0.113103, Val Acc: 0.783505\n",
      "Epoch 18290 - Train Loss: 0.085696, Train Acc: 0.874359 | Val Loss: 0.113102, Val Acc: 0.783505\n",
      "Epoch 18291 - Train Loss: 0.085694, Train Acc: 0.874359 | Val Loss: 0.113101, Val Acc: 0.783505\n",
      "Epoch 18292 - Train Loss: 0.085691, Train Acc: 0.874359 | Val Loss: 0.113099, Val Acc: 0.783505\n",
      "Epoch 18293 - Train Loss: 0.085688, Train Acc: 0.874359 | Val Loss: 0.113098, Val Acc: 0.783505\n",
      "Epoch 18294 - Train Loss: 0.085685, Train Acc: 0.874359 | Val Loss: 0.113096, Val Acc: 0.783505\n",
      "Epoch 18295 - Train Loss: 0.085683, Train Acc: 0.874359 | Val Loss: 0.113095, Val Acc: 0.783505\n",
      "Epoch 18296 - Train Loss: 0.085680, Train Acc: 0.874359 | Val Loss: 0.113093, Val Acc: 0.783505\n",
      "Epoch 18297 - Train Loss: 0.085677, Train Acc: 0.874359 | Val Loss: 0.113092, Val Acc: 0.783505\n",
      "Epoch 18298 - Train Loss: 0.085674, Train Acc: 0.874359 | Val Loss: 0.113091, Val Acc: 0.783505\n",
      "Epoch 18299 - Train Loss: 0.085672, Train Acc: 0.874359 | Val Loss: 0.113089, Val Acc: 0.783505\n",
      "Epoch 18300 - Train Loss: 0.085669, Train Acc: 0.874359 | Val Loss: 0.113088, Val Acc: 0.783505\n",
      "Epoch 18301 - Train Loss: 0.085666, Train Acc: 0.874359 | Val Loss: 0.113086, Val Acc: 0.783505\n",
      "Epoch 18302 - Train Loss: 0.085663, Train Acc: 0.874359 | Val Loss: 0.113085, Val Acc: 0.783505\n",
      "Epoch 18303 - Train Loss: 0.085661, Train Acc: 0.874359 | Val Loss: 0.113084, Val Acc: 0.783505\n",
      "Epoch 18304 - Train Loss: 0.085658, Train Acc: 0.874359 | Val Loss: 0.113082, Val Acc: 0.783505\n",
      "Epoch 18305 - Train Loss: 0.085655, Train Acc: 0.874359 | Val Loss: 0.113081, Val Acc: 0.783505\n",
      "Epoch 18306 - Train Loss: 0.085652, Train Acc: 0.874359 | Val Loss: 0.113079, Val Acc: 0.783505\n",
      "Epoch 18307 - Train Loss: 0.085650, Train Acc: 0.874359 | Val Loss: 0.113078, Val Acc: 0.783505\n",
      "Epoch 18308 - Train Loss: 0.085647, Train Acc: 0.874359 | Val Loss: 0.113077, Val Acc: 0.783505\n",
      "Epoch 18309 - Train Loss: 0.085644, Train Acc: 0.874359 | Val Loss: 0.113075, Val Acc: 0.783505\n",
      "Epoch 18310 - Train Loss: 0.085641, Train Acc: 0.874359 | Val Loss: 0.113074, Val Acc: 0.783505\n",
      "Epoch 18311 - Train Loss: 0.085639, Train Acc: 0.874359 | Val Loss: 0.113072, Val Acc: 0.783505\n",
      "Epoch 18312 - Train Loss: 0.085636, Train Acc: 0.874359 | Val Loss: 0.113071, Val Acc: 0.783505\n",
      "Epoch 18313 - Train Loss: 0.085633, Train Acc: 0.874359 | Val Loss: 0.113069, Val Acc: 0.783505\n",
      "Epoch 18314 - Train Loss: 0.085630, Train Acc: 0.874359 | Val Loss: 0.113068, Val Acc: 0.783505\n",
      "Epoch 18315 - Train Loss: 0.085628, Train Acc: 0.874359 | Val Loss: 0.113067, Val Acc: 0.783505\n",
      "Epoch 18316 - Train Loss: 0.085625, Train Acc: 0.874359 | Val Loss: 0.113065, Val Acc: 0.783505\n",
      "Epoch 18317 - Train Loss: 0.085622, Train Acc: 0.874359 | Val Loss: 0.113064, Val Acc: 0.783505\n",
      "Epoch 18318 - Train Loss: 0.085619, Train Acc: 0.874359 | Val Loss: 0.113062, Val Acc: 0.783505\n",
      "Epoch 18319 - Train Loss: 0.085617, Train Acc: 0.874359 | Val Loss: 0.113061, Val Acc: 0.783505\n",
      "Epoch 18320 - Train Loss: 0.085614, Train Acc: 0.874359 | Val Loss: 0.113060, Val Acc: 0.783505\n",
      "Epoch 18321 - Train Loss: 0.085611, Train Acc: 0.874359 | Val Loss: 0.113058, Val Acc: 0.783505\n",
      "Epoch 18322 - Train Loss: 0.085608, Train Acc: 0.874359 | Val Loss: 0.113057, Val Acc: 0.783505\n",
      "Epoch 18323 - Train Loss: 0.085606, Train Acc: 0.874359 | Val Loss: 0.113055, Val Acc: 0.783505\n",
      "Epoch 18324 - Train Loss: 0.085603, Train Acc: 0.874359 | Val Loss: 0.113054, Val Acc: 0.783505\n",
      "Epoch 18325 - Train Loss: 0.085600, Train Acc: 0.874359 | Val Loss: 0.113053, Val Acc: 0.783505\n",
      "Epoch 18326 - Train Loss: 0.085597, Train Acc: 0.874359 | Val Loss: 0.113051, Val Acc: 0.783505\n",
      "Epoch 18327 - Train Loss: 0.085595, Train Acc: 0.874359 | Val Loss: 0.113050, Val Acc: 0.783505\n",
      "Epoch 18328 - Train Loss: 0.085592, Train Acc: 0.874359 | Val Loss: 0.113048, Val Acc: 0.783505\n",
      "Epoch 18329 - Train Loss: 0.085589, Train Acc: 0.874359 | Val Loss: 0.113047, Val Acc: 0.783505\n",
      "Epoch 18330 - Train Loss: 0.085586, Train Acc: 0.874359 | Val Loss: 0.113046, Val Acc: 0.783505\n",
      "Epoch 18331 - Train Loss: 0.085584, Train Acc: 0.874359 | Val Loss: 0.113044, Val Acc: 0.783505\n",
      "Epoch 18332 - Train Loss: 0.085581, Train Acc: 0.874359 | Val Loss: 0.113043, Val Acc: 0.783505\n",
      "Epoch 18333 - Train Loss: 0.085578, Train Acc: 0.874359 | Val Loss: 0.113041, Val Acc: 0.783505\n",
      "Epoch 18334 - Train Loss: 0.085575, Train Acc: 0.874359 | Val Loss: 0.113040, Val Acc: 0.783505\n",
      "Epoch 18335 - Train Loss: 0.085573, Train Acc: 0.874359 | Val Loss: 0.113039, Val Acc: 0.783505\n",
      "Epoch 18336 - Train Loss: 0.085570, Train Acc: 0.874359 | Val Loss: 0.113037, Val Acc: 0.783505\n",
      "Epoch 18337 - Train Loss: 0.085567, Train Acc: 0.874359 | Val Loss: 0.113036, Val Acc: 0.783505\n",
      "Epoch 18338 - Train Loss: 0.085564, Train Acc: 0.874359 | Val Loss: 0.113034, Val Acc: 0.783505\n",
      "Epoch 18339 - Train Loss: 0.085562, Train Acc: 0.874359 | Val Loss: 0.113033, Val Acc: 0.783505\n",
      "Epoch 18340 - Train Loss: 0.085559, Train Acc: 0.874359 | Val Loss: 0.113032, Val Acc: 0.783505\n",
      "Epoch 18341 - Train Loss: 0.085556, Train Acc: 0.874359 | Val Loss: 0.113030, Val Acc: 0.783505\n",
      "Epoch 18342 - Train Loss: 0.085553, Train Acc: 0.874359 | Val Loss: 0.113029, Val Acc: 0.783505\n",
      "Epoch 18343 - Train Loss: 0.085551, Train Acc: 0.874359 | Val Loss: 0.113027, Val Acc: 0.783505\n",
      "Epoch 18344 - Train Loss: 0.085548, Train Acc: 0.874359 | Val Loss: 0.113026, Val Acc: 0.783505\n",
      "Epoch 18345 - Train Loss: 0.085545, Train Acc: 0.874359 | Val Loss: 0.113025, Val Acc: 0.783505\n",
      "Epoch 18346 - Train Loss: 0.085543, Train Acc: 0.874359 | Val Loss: 0.113023, Val Acc: 0.783505\n",
      "Epoch 18347 - Train Loss: 0.085540, Train Acc: 0.874359 | Val Loss: 0.113022, Val Acc: 0.783505\n",
      "Epoch 18348 - Train Loss: 0.085537, Train Acc: 0.874359 | Val Loss: 0.113020, Val Acc: 0.783505\n",
      "Epoch 18349 - Train Loss: 0.085534, Train Acc: 0.874359 | Val Loss: 0.113019, Val Acc: 0.783505\n",
      "Epoch 18350 - Train Loss: 0.085532, Train Acc: 0.874359 | Val Loss: 0.113018, Val Acc: 0.783505\n",
      "Epoch 18351 - Train Loss: 0.085529, Train Acc: 0.874359 | Val Loss: 0.113016, Val Acc: 0.783505\n",
      "Epoch 18352 - Train Loss: 0.085526, Train Acc: 0.874359 | Val Loss: 0.113015, Val Acc: 0.783505\n",
      "Epoch 18353 - Train Loss: 0.085523, Train Acc: 0.874359 | Val Loss: 0.113013, Val Acc: 0.783505\n",
      "Epoch 18354 - Train Loss: 0.085521, Train Acc: 0.874359 | Val Loss: 0.113012, Val Acc: 0.783505\n",
      "Epoch 18355 - Train Loss: 0.085518, Train Acc: 0.874359 | Val Loss: 0.113011, Val Acc: 0.783505\n",
      "Epoch 18356 - Train Loss: 0.085515, Train Acc: 0.874359 | Val Loss: 0.113009, Val Acc: 0.783505\n",
      "Epoch 18357 - Train Loss: 0.085512, Train Acc: 0.874359 | Val Loss: 0.113008, Val Acc: 0.783505\n",
      "Epoch 18358 - Train Loss: 0.085510, Train Acc: 0.874359 | Val Loss: 0.113006, Val Acc: 0.783505\n",
      "Epoch 18359 - Train Loss: 0.085507, Train Acc: 0.874359 | Val Loss: 0.113005, Val Acc: 0.783505\n",
      "Epoch 18360 - Train Loss: 0.085504, Train Acc: 0.874359 | Val Loss: 0.113004, Val Acc: 0.783505\n",
      "Epoch 18361 - Train Loss: 0.085501, Train Acc: 0.874359 | Val Loss: 0.113002, Val Acc: 0.783505\n",
      "Epoch 18362 - Train Loss: 0.085499, Train Acc: 0.874359 | Val Loss: 0.113001, Val Acc: 0.783505\n",
      "Epoch 18363 - Train Loss: 0.085496, Train Acc: 0.874359 | Val Loss: 0.112999, Val Acc: 0.783505\n",
      "Epoch 18364 - Train Loss: 0.085493, Train Acc: 0.874359 | Val Loss: 0.112998, Val Acc: 0.783505\n",
      "Epoch 18365 - Train Loss: 0.085491, Train Acc: 0.874359 | Val Loss: 0.112997, Val Acc: 0.783505\n",
      "Epoch 18366 - Train Loss: 0.085488, Train Acc: 0.874359 | Val Loss: 0.112995, Val Acc: 0.783505\n",
      "Epoch 18367 - Train Loss: 0.085485, Train Acc: 0.874359 | Val Loss: 0.112994, Val Acc: 0.783505\n",
      "Epoch 18368 - Train Loss: 0.085482, Train Acc: 0.874359 | Val Loss: 0.112992, Val Acc: 0.783505\n",
      "Epoch 18369 - Train Loss: 0.085480, Train Acc: 0.874359 | Val Loss: 0.112991, Val Acc: 0.783505\n",
      "Epoch 18370 - Train Loss: 0.085477, Train Acc: 0.874359 | Val Loss: 0.112990, Val Acc: 0.783505\n",
      "Epoch 18371 - Train Loss: 0.085474, Train Acc: 0.874359 | Val Loss: 0.112988, Val Acc: 0.783505\n",
      "Epoch 18372 - Train Loss: 0.085471, Train Acc: 0.874359 | Val Loss: 0.112987, Val Acc: 0.783505\n",
      "Epoch 18373 - Train Loss: 0.085469, Train Acc: 0.874359 | Val Loss: 0.112986, Val Acc: 0.783505\n",
      "Epoch 18374 - Train Loss: 0.085466, Train Acc: 0.874359 | Val Loss: 0.112984, Val Acc: 0.783505\n",
      "Epoch 18375 - Train Loss: 0.085463, Train Acc: 0.874359 | Val Loss: 0.112983, Val Acc: 0.783505\n",
      "Epoch 18376 - Train Loss: 0.085461, Train Acc: 0.874359 | Val Loss: 0.112981, Val Acc: 0.783505\n",
      "Epoch 18377 - Train Loss: 0.085458, Train Acc: 0.874359 | Val Loss: 0.112980, Val Acc: 0.783505\n",
      "Epoch 18378 - Train Loss: 0.085455, Train Acc: 0.874359 | Val Loss: 0.112979, Val Acc: 0.783505\n",
      "Epoch 18379 - Train Loss: 0.085452, Train Acc: 0.874359 | Val Loss: 0.112977, Val Acc: 0.783505\n",
      "Epoch 18380 - Train Loss: 0.085450, Train Acc: 0.874359 | Val Loss: 0.112976, Val Acc: 0.783505\n",
      "Epoch 18381 - Train Loss: 0.085447, Train Acc: 0.874359 | Val Loss: 0.112974, Val Acc: 0.783505\n",
      "Epoch 18382 - Train Loss: 0.085444, Train Acc: 0.874359 | Val Loss: 0.112973, Val Acc: 0.783505\n",
      "Epoch 18383 - Train Loss: 0.085441, Train Acc: 0.874359 | Val Loss: 0.112972, Val Acc: 0.783505\n",
      "Epoch 18384 - Train Loss: 0.085439, Train Acc: 0.874359 | Val Loss: 0.112970, Val Acc: 0.783505\n",
      "Epoch 18385 - Train Loss: 0.085436, Train Acc: 0.874359 | Val Loss: 0.112969, Val Acc: 0.783505\n",
      "Epoch 18386 - Train Loss: 0.085433, Train Acc: 0.874359 | Val Loss: 0.112967, Val Acc: 0.783505\n",
      "Epoch 18387 - Train Loss: 0.085431, Train Acc: 0.874359 | Val Loss: 0.112966, Val Acc: 0.783505\n",
      "Epoch 18388 - Train Loss: 0.085428, Train Acc: 0.874359 | Val Loss: 0.112965, Val Acc: 0.783505\n",
      "Epoch 18389 - Train Loss: 0.085425, Train Acc: 0.874359 | Val Loss: 0.112963, Val Acc: 0.783505\n",
      "Epoch 18390 - Train Loss: 0.085422, Train Acc: 0.874359 | Val Loss: 0.112962, Val Acc: 0.783505\n",
      "Epoch 18391 - Train Loss: 0.085420, Train Acc: 0.874359 | Val Loss: 0.112961, Val Acc: 0.783505\n",
      "Epoch 18392 - Train Loss: 0.085417, Train Acc: 0.874359 | Val Loss: 0.112959, Val Acc: 0.783505\n",
      "Epoch 18393 - Train Loss: 0.085414, Train Acc: 0.874359 | Val Loss: 0.112958, Val Acc: 0.783505\n",
      "Epoch 18394 - Train Loss: 0.085411, Train Acc: 0.874359 | Val Loss: 0.112956, Val Acc: 0.783505\n",
      "Epoch 18395 - Train Loss: 0.085409, Train Acc: 0.874359 | Val Loss: 0.112955, Val Acc: 0.783505\n",
      "Epoch 18396 - Train Loss: 0.085406, Train Acc: 0.874359 | Val Loss: 0.112954, Val Acc: 0.783505\n",
      "Epoch 18397 - Train Loss: 0.085403, Train Acc: 0.874359 | Val Loss: 0.112952, Val Acc: 0.783505\n",
      "Epoch 18398 - Train Loss: 0.085401, Train Acc: 0.874359 | Val Loss: 0.112951, Val Acc: 0.783505\n",
      "Epoch 18399 - Train Loss: 0.085398, Train Acc: 0.874359 | Val Loss: 0.112949, Val Acc: 0.783505\n",
      "Epoch 18400 - Train Loss: 0.085395, Train Acc: 0.874359 | Val Loss: 0.112948, Val Acc: 0.783505\n",
      "Epoch 18401 - Train Loss: 0.085392, Train Acc: 0.874359 | Val Loss: 0.112947, Val Acc: 0.783505\n",
      "Epoch 18402 - Train Loss: 0.085390, Train Acc: 0.874359 | Val Loss: 0.112945, Val Acc: 0.783505\n",
      "Epoch 18403 - Train Loss: 0.085387, Train Acc: 0.874359 | Val Loss: 0.112944, Val Acc: 0.783505\n",
      "Epoch 18404 - Train Loss: 0.085384, Train Acc: 0.874359 | Val Loss: 0.112943, Val Acc: 0.783505\n",
      "Epoch 18405 - Train Loss: 0.085382, Train Acc: 0.874359 | Val Loss: 0.112941, Val Acc: 0.783505\n",
      "Epoch 18406 - Train Loss: 0.085379, Train Acc: 0.874359 | Val Loss: 0.112940, Val Acc: 0.783505\n",
      "Epoch 18407 - Train Loss: 0.085376, Train Acc: 0.874359 | Val Loss: 0.112938, Val Acc: 0.783505\n",
      "Epoch 18408 - Train Loss: 0.085373, Train Acc: 0.874359 | Val Loss: 0.112937, Val Acc: 0.783505\n",
      "Epoch 18409 - Train Loss: 0.085371, Train Acc: 0.874359 | Val Loss: 0.112936, Val Acc: 0.783505\n",
      "Epoch 18410 - Train Loss: 0.085368, Train Acc: 0.874359 | Val Loss: 0.112934, Val Acc: 0.783505\n",
      "Epoch 18411 - Train Loss: 0.085365, Train Acc: 0.874359 | Val Loss: 0.112933, Val Acc: 0.783505\n",
      "Epoch 18412 - Train Loss: 0.085362, Train Acc: 0.874359 | Val Loss: 0.112932, Val Acc: 0.783505\n",
      "Epoch 18413 - Train Loss: 0.085360, Train Acc: 0.874359 | Val Loss: 0.112930, Val Acc: 0.783505\n",
      "Epoch 18414 - Train Loss: 0.085357, Train Acc: 0.874359 | Val Loss: 0.112929, Val Acc: 0.783505\n",
      "Epoch 18415 - Train Loss: 0.085354, Train Acc: 0.874359 | Val Loss: 0.112927, Val Acc: 0.783505\n",
      "Epoch 18416 - Train Loss: 0.085352, Train Acc: 0.874359 | Val Loss: 0.112926, Val Acc: 0.783505\n",
      "Epoch 18417 - Train Loss: 0.085349, Train Acc: 0.874359 | Val Loss: 0.112925, Val Acc: 0.783505\n",
      "Epoch 18418 - Train Loss: 0.085346, Train Acc: 0.874359 | Val Loss: 0.112923, Val Acc: 0.783505\n",
      "Epoch 18419 - Train Loss: 0.085343, Train Acc: 0.874359 | Val Loss: 0.112922, Val Acc: 0.783505\n",
      "Epoch 18420 - Train Loss: 0.085341, Train Acc: 0.874359 | Val Loss: 0.112921, Val Acc: 0.783505\n",
      "Epoch 18421 - Train Loss: 0.085338, Train Acc: 0.874359 | Val Loss: 0.112919, Val Acc: 0.783505\n",
      "Epoch 18422 - Train Loss: 0.085335, Train Acc: 0.874359 | Val Loss: 0.112918, Val Acc: 0.783505\n",
      "Epoch 18423 - Train Loss: 0.085333, Train Acc: 0.874359 | Val Loss: 0.112916, Val Acc: 0.783505\n",
      "Epoch 18424 - Train Loss: 0.085330, Train Acc: 0.874359 | Val Loss: 0.112915, Val Acc: 0.783505\n",
      "Epoch 18425 - Train Loss: 0.085327, Train Acc: 0.874359 | Val Loss: 0.112914, Val Acc: 0.783505\n",
      "Epoch 18426 - Train Loss: 0.085324, Train Acc: 0.874359 | Val Loss: 0.112912, Val Acc: 0.783505\n",
      "Epoch 18427 - Train Loss: 0.085322, Train Acc: 0.874359 | Val Loss: 0.112911, Val Acc: 0.783505\n",
      "Epoch 18428 - Train Loss: 0.085319, Train Acc: 0.874359 | Val Loss: 0.112909, Val Acc: 0.783505\n",
      "Epoch 18429 - Train Loss: 0.085316, Train Acc: 0.874359 | Val Loss: 0.112908, Val Acc: 0.783505\n",
      "Epoch 18430 - Train Loss: 0.085314, Train Acc: 0.874359 | Val Loss: 0.112907, Val Acc: 0.783505\n",
      "Epoch 18431 - Train Loss: 0.085311, Train Acc: 0.874359 | Val Loss: 0.112905, Val Acc: 0.783505\n",
      "Epoch 18432 - Train Loss: 0.085308, Train Acc: 0.874359 | Val Loss: 0.112904, Val Acc: 0.783505\n",
      "Epoch 18433 - Train Loss: 0.085305, Train Acc: 0.874359 | Val Loss: 0.112903, Val Acc: 0.783505\n",
      "Epoch 18434 - Train Loss: 0.085303, Train Acc: 0.874359 | Val Loss: 0.112901, Val Acc: 0.783505\n",
      "Epoch 18435 - Train Loss: 0.085300, Train Acc: 0.874359 | Val Loss: 0.112900, Val Acc: 0.783505\n",
      "Epoch 18436 - Train Loss: 0.085297, Train Acc: 0.874359 | Val Loss: 0.112899, Val Acc: 0.783505\n",
      "Epoch 18437 - Train Loss: 0.085295, Train Acc: 0.874359 | Val Loss: 0.112897, Val Acc: 0.783505\n",
      "Epoch 18438 - Train Loss: 0.085292, Train Acc: 0.874359 | Val Loss: 0.112896, Val Acc: 0.783505\n",
      "Epoch 18439 - Train Loss: 0.085289, Train Acc: 0.874359 | Val Loss: 0.112894, Val Acc: 0.783505\n",
      "Epoch 18440 - Train Loss: 0.085287, Train Acc: 0.874359 | Val Loss: 0.112893, Val Acc: 0.783505\n",
      "Epoch 18441 - Train Loss: 0.085284, Train Acc: 0.874359 | Val Loss: 0.112892, Val Acc: 0.783505\n",
      "Epoch 18442 - Train Loss: 0.085281, Train Acc: 0.874359 | Val Loss: 0.112890, Val Acc: 0.783505\n",
      "Epoch 18443 - Train Loss: 0.085278, Train Acc: 0.874359 | Val Loss: 0.112889, Val Acc: 0.783505\n",
      "Epoch 18444 - Train Loss: 0.085276, Train Acc: 0.874359 | Val Loss: 0.112888, Val Acc: 0.783505\n",
      "Epoch 18445 - Train Loss: 0.085273, Train Acc: 0.874359 | Val Loss: 0.112886, Val Acc: 0.783505\n",
      "Epoch 18446 - Train Loss: 0.085270, Train Acc: 0.874359 | Val Loss: 0.112885, Val Acc: 0.783505\n",
      "Epoch 18447 - Train Loss: 0.085268, Train Acc: 0.874359 | Val Loss: 0.112883, Val Acc: 0.783505\n",
      "Epoch 18448 - Train Loss: 0.085265, Train Acc: 0.874359 | Val Loss: 0.112882, Val Acc: 0.783505\n",
      "Epoch 18449 - Train Loss: 0.085262, Train Acc: 0.874359 | Val Loss: 0.112881, Val Acc: 0.783505\n",
      "Epoch 18450 - Train Loss: 0.085259, Train Acc: 0.874359 | Val Loss: 0.112879, Val Acc: 0.783505\n",
      "Epoch 18451 - Train Loss: 0.085257, Train Acc: 0.874359 | Val Loss: 0.112878, Val Acc: 0.783505\n",
      "Epoch 18452 - Train Loss: 0.085254, Train Acc: 0.874359 | Val Loss: 0.112877, Val Acc: 0.783505\n",
      "Epoch 18453 - Train Loss: 0.085251, Train Acc: 0.874359 | Val Loss: 0.112875, Val Acc: 0.783505\n",
      "Epoch 18454 - Train Loss: 0.085249, Train Acc: 0.874359 | Val Loss: 0.112874, Val Acc: 0.783505\n",
      "Epoch 18455 - Train Loss: 0.085246, Train Acc: 0.874359 | Val Loss: 0.112873, Val Acc: 0.783505\n",
      "Epoch 18456 - Train Loss: 0.085243, Train Acc: 0.874359 | Val Loss: 0.112871, Val Acc: 0.783505\n",
      "Epoch 18457 - Train Loss: 0.085240, Train Acc: 0.874359 | Val Loss: 0.112870, Val Acc: 0.783505\n",
      "Epoch 18458 - Train Loss: 0.085238, Train Acc: 0.874359 | Val Loss: 0.112868, Val Acc: 0.783505\n",
      "Epoch 18459 - Train Loss: 0.085235, Train Acc: 0.874359 | Val Loss: 0.112867, Val Acc: 0.783505\n",
      "Epoch 18460 - Train Loss: 0.085232, Train Acc: 0.874359 | Val Loss: 0.112866, Val Acc: 0.783505\n",
      "Epoch 18461 - Train Loss: 0.085230, Train Acc: 0.874359 | Val Loss: 0.112864, Val Acc: 0.783505\n",
      "Epoch 18462 - Train Loss: 0.085227, Train Acc: 0.874359 | Val Loss: 0.112863, Val Acc: 0.783505\n",
      "Epoch 18463 - Train Loss: 0.085224, Train Acc: 0.874359 | Val Loss: 0.112862, Val Acc: 0.783505\n",
      "Epoch 18464 - Train Loss: 0.085222, Train Acc: 0.874359 | Val Loss: 0.112860, Val Acc: 0.783505\n",
      "Epoch 18465 - Train Loss: 0.085219, Train Acc: 0.874359 | Val Loss: 0.112859, Val Acc: 0.783505\n",
      "Epoch 18466 - Train Loss: 0.085216, Train Acc: 0.874359 | Val Loss: 0.112858, Val Acc: 0.783505\n",
      "Epoch 18467 - Train Loss: 0.085213, Train Acc: 0.874359 | Val Loss: 0.112856, Val Acc: 0.783505\n",
      "Epoch 18468 - Train Loss: 0.085211, Train Acc: 0.874359 | Val Loss: 0.112855, Val Acc: 0.783505\n",
      "Epoch 18469 - Train Loss: 0.085208, Train Acc: 0.874359 | Val Loss: 0.112853, Val Acc: 0.783505\n",
      "Epoch 18470 - Train Loss: 0.085205, Train Acc: 0.874359 | Val Loss: 0.112852, Val Acc: 0.783505\n",
      "Epoch 18471 - Train Loss: 0.085203, Train Acc: 0.874359 | Val Loss: 0.112851, Val Acc: 0.783505\n",
      "Epoch 18472 - Train Loss: 0.085200, Train Acc: 0.874359 | Val Loss: 0.112849, Val Acc: 0.783505\n",
      "Epoch 18473 - Train Loss: 0.085197, Train Acc: 0.874359 | Val Loss: 0.112848, Val Acc: 0.783505\n",
      "Epoch 18474 - Train Loss: 0.085195, Train Acc: 0.874359 | Val Loss: 0.112847, Val Acc: 0.783505\n",
      "Epoch 18475 - Train Loss: 0.085192, Train Acc: 0.874359 | Val Loss: 0.112845, Val Acc: 0.783505\n",
      "Epoch 18476 - Train Loss: 0.085189, Train Acc: 0.874359 | Val Loss: 0.112844, Val Acc: 0.783505\n",
      "Epoch 18477 - Train Loss: 0.085186, Train Acc: 0.874359 | Val Loss: 0.112843, Val Acc: 0.783505\n",
      "Epoch 18478 - Train Loss: 0.085184, Train Acc: 0.874359 | Val Loss: 0.112841, Val Acc: 0.783505\n",
      "Epoch 18479 - Train Loss: 0.085181, Train Acc: 0.874359 | Val Loss: 0.112840, Val Acc: 0.783505\n",
      "Epoch 18480 - Train Loss: 0.085178, Train Acc: 0.874359 | Val Loss: 0.112838, Val Acc: 0.783505\n",
      "Epoch 18481 - Train Loss: 0.085176, Train Acc: 0.874359 | Val Loss: 0.112837, Val Acc: 0.783505\n",
      "Epoch 18482 - Train Loss: 0.085173, Train Acc: 0.874359 | Val Loss: 0.112836, Val Acc: 0.783505\n",
      "Epoch 18483 - Train Loss: 0.085170, Train Acc: 0.874359 | Val Loss: 0.112834, Val Acc: 0.783505\n",
      "Epoch 18484 - Train Loss: 0.085168, Train Acc: 0.874359 | Val Loss: 0.112833, Val Acc: 0.783505\n",
      "Epoch 18485 - Train Loss: 0.085165, Train Acc: 0.874359 | Val Loss: 0.112832, Val Acc: 0.783505\n",
      "Epoch 18486 - Train Loss: 0.085162, Train Acc: 0.874359 | Val Loss: 0.112830, Val Acc: 0.783505\n",
      "Epoch 18487 - Train Loss: 0.085159, Train Acc: 0.874359 | Val Loss: 0.112829, Val Acc: 0.783505\n",
      "Epoch 18488 - Train Loss: 0.085157, Train Acc: 0.874359 | Val Loss: 0.112828, Val Acc: 0.783505\n",
      "Epoch 18489 - Train Loss: 0.085154, Train Acc: 0.874359 | Val Loss: 0.112826, Val Acc: 0.783505\n",
      "Epoch 18490 - Train Loss: 0.085151, Train Acc: 0.874359 | Val Loss: 0.112825, Val Acc: 0.783505\n",
      "Epoch 18491 - Train Loss: 0.085149, Train Acc: 0.874359 | Val Loss: 0.112824, Val Acc: 0.783505\n",
      "Epoch 18492 - Train Loss: 0.085146, Train Acc: 0.874359 | Val Loss: 0.112822, Val Acc: 0.783505\n",
      "Epoch 18493 - Train Loss: 0.085143, Train Acc: 0.874359 | Val Loss: 0.112821, Val Acc: 0.783505\n",
      "Epoch 18494 - Train Loss: 0.085141, Train Acc: 0.874359 | Val Loss: 0.112819, Val Acc: 0.783505\n",
      "Epoch 18495 - Train Loss: 0.085138, Train Acc: 0.874359 | Val Loss: 0.112818, Val Acc: 0.783505\n",
      "Epoch 18496 - Train Loss: 0.085135, Train Acc: 0.874359 | Val Loss: 0.112817, Val Acc: 0.783505\n",
      "Epoch 18497 - Train Loss: 0.085133, Train Acc: 0.874359 | Val Loss: 0.112815, Val Acc: 0.783505\n",
      "Epoch 18498 - Train Loss: 0.085130, Train Acc: 0.874359 | Val Loss: 0.112814, Val Acc: 0.783505\n",
      "Epoch 18499 - Train Loss: 0.085127, Train Acc: 0.874359 | Val Loss: 0.112813, Val Acc: 0.783505\n",
      "Epoch 18500 - Train Loss: 0.085124, Train Acc: 0.874359 | Val Loss: 0.112811, Val Acc: 0.783505\n",
      "Epoch 18501 - Train Loss: 0.085122, Train Acc: 0.874359 | Val Loss: 0.112810, Val Acc: 0.783505\n",
      "Epoch 18502 - Train Loss: 0.085119, Train Acc: 0.874359 | Val Loss: 0.112809, Val Acc: 0.783505\n",
      "Epoch 18503 - Train Loss: 0.085116, Train Acc: 0.874359 | Val Loss: 0.112807, Val Acc: 0.783505\n",
      "Epoch 18504 - Train Loss: 0.085114, Train Acc: 0.874359 | Val Loss: 0.112806, Val Acc: 0.783505\n",
      "Epoch 18505 - Train Loss: 0.085111, Train Acc: 0.874359 | Val Loss: 0.112805, Val Acc: 0.783505\n",
      "Epoch 18506 - Train Loss: 0.085108, Train Acc: 0.874359 | Val Loss: 0.112803, Val Acc: 0.783505\n",
      "Epoch 18507 - Train Loss: 0.085106, Train Acc: 0.874359 | Val Loss: 0.112802, Val Acc: 0.783505\n",
      "Epoch 18508 - Train Loss: 0.085103, Train Acc: 0.874359 | Val Loss: 0.112801, Val Acc: 0.783505\n",
      "Epoch 18509 - Train Loss: 0.085100, Train Acc: 0.874359 | Val Loss: 0.112799, Val Acc: 0.783505\n",
      "Epoch 18510 - Train Loss: 0.085098, Train Acc: 0.874359 | Val Loss: 0.112798, Val Acc: 0.783505\n",
      "Epoch 18511 - Train Loss: 0.085095, Train Acc: 0.874359 | Val Loss: 0.112796, Val Acc: 0.783505\n",
      "Epoch 18512 - Train Loss: 0.085092, Train Acc: 0.874359 | Val Loss: 0.112795, Val Acc: 0.783505\n",
      "Epoch 18513 - Train Loss: 0.085090, Train Acc: 0.874359 | Val Loss: 0.112794, Val Acc: 0.783505\n",
      "Epoch 18514 - Train Loss: 0.085087, Train Acc: 0.874359 | Val Loss: 0.112792, Val Acc: 0.783505\n",
      "Epoch 18515 - Train Loss: 0.085084, Train Acc: 0.874359 | Val Loss: 0.112791, Val Acc: 0.783505\n",
      "Epoch 18516 - Train Loss: 0.085081, Train Acc: 0.874359 | Val Loss: 0.112790, Val Acc: 0.783505\n",
      "Epoch 18517 - Train Loss: 0.085079, Train Acc: 0.874359 | Val Loss: 0.112788, Val Acc: 0.783505\n",
      "Epoch 18518 - Train Loss: 0.085076, Train Acc: 0.874359 | Val Loss: 0.112787, Val Acc: 0.783505\n",
      "Epoch 18519 - Train Loss: 0.085073, Train Acc: 0.874359 | Val Loss: 0.112786, Val Acc: 0.783505\n",
      "Epoch 18520 - Train Loss: 0.085071, Train Acc: 0.874359 | Val Loss: 0.112784, Val Acc: 0.783505\n",
      "Epoch 18521 - Train Loss: 0.085068, Train Acc: 0.874359 | Val Loss: 0.112783, Val Acc: 0.783505\n",
      "Epoch 18522 - Train Loss: 0.085065, Train Acc: 0.874359 | Val Loss: 0.112782, Val Acc: 0.783505\n",
      "Epoch 18523 - Train Loss: 0.085063, Train Acc: 0.874359 | Val Loss: 0.112780, Val Acc: 0.783505\n",
      "Epoch 18524 - Train Loss: 0.085060, Train Acc: 0.874359 | Val Loss: 0.112779, Val Acc: 0.783505\n",
      "Epoch 18525 - Train Loss: 0.085057, Train Acc: 0.874359 | Val Loss: 0.112778, Val Acc: 0.783505\n",
      "Epoch 18526 - Train Loss: 0.085055, Train Acc: 0.874359 | Val Loss: 0.112776, Val Acc: 0.783505\n",
      "Epoch 18527 - Train Loss: 0.085052, Train Acc: 0.874359 | Val Loss: 0.112775, Val Acc: 0.783505\n",
      "Epoch 18528 - Train Loss: 0.085049, Train Acc: 0.874359 | Val Loss: 0.112774, Val Acc: 0.783505\n",
      "Epoch 18529 - Train Loss: 0.085047, Train Acc: 0.874359 | Val Loss: 0.112772, Val Acc: 0.783505\n",
      "Epoch 18530 - Train Loss: 0.085044, Train Acc: 0.874359 | Val Loss: 0.112771, Val Acc: 0.783505\n",
      "Epoch 18531 - Train Loss: 0.085041, Train Acc: 0.874359 | Val Loss: 0.112770, Val Acc: 0.783505\n",
      "Epoch 18532 - Train Loss: 0.085039, Train Acc: 0.874359 | Val Loss: 0.112768, Val Acc: 0.783505\n",
      "Epoch 18533 - Train Loss: 0.085036, Train Acc: 0.874359 | Val Loss: 0.112767, Val Acc: 0.783505\n",
      "Epoch 18534 - Train Loss: 0.085033, Train Acc: 0.874359 | Val Loss: 0.112766, Val Acc: 0.783505\n",
      "Epoch 18535 - Train Loss: 0.085030, Train Acc: 0.874359 | Val Loss: 0.112764, Val Acc: 0.783505\n",
      "Epoch 18536 - Train Loss: 0.085028, Train Acc: 0.874359 | Val Loss: 0.112763, Val Acc: 0.783505\n",
      "Epoch 18537 - Train Loss: 0.085025, Train Acc: 0.874359 | Val Loss: 0.112762, Val Acc: 0.783505\n",
      "Epoch 18538 - Train Loss: 0.085022, Train Acc: 0.874359 | Val Loss: 0.112760, Val Acc: 0.783505\n",
      "Epoch 18539 - Train Loss: 0.085020, Train Acc: 0.874359 | Val Loss: 0.112759, Val Acc: 0.783505\n",
      "Epoch 18540 - Train Loss: 0.085017, Train Acc: 0.874359 | Val Loss: 0.112757, Val Acc: 0.783505\n",
      "Epoch 18541 - Train Loss: 0.085014, Train Acc: 0.874359 | Val Loss: 0.112756, Val Acc: 0.783505\n",
      "Epoch 18542 - Train Loss: 0.085012, Train Acc: 0.874359 | Val Loss: 0.112755, Val Acc: 0.783505\n",
      "Epoch 18543 - Train Loss: 0.085009, Train Acc: 0.874359 | Val Loss: 0.112753, Val Acc: 0.783505\n",
      "Epoch 18544 - Train Loss: 0.085006, Train Acc: 0.874359 | Val Loss: 0.112752, Val Acc: 0.783505\n",
      "Epoch 18545 - Train Loss: 0.085004, Train Acc: 0.874359 | Val Loss: 0.112751, Val Acc: 0.783505\n",
      "Epoch 18546 - Train Loss: 0.085001, Train Acc: 0.874359 | Val Loss: 0.112749, Val Acc: 0.783505\n",
      "Epoch 18547 - Train Loss: 0.084998, Train Acc: 0.874359 | Val Loss: 0.112748, Val Acc: 0.783505\n",
      "Epoch 18548 - Train Loss: 0.084996, Train Acc: 0.874359 | Val Loss: 0.112747, Val Acc: 0.783505\n",
      "Epoch 18549 - Train Loss: 0.084993, Train Acc: 0.874359 | Val Loss: 0.112745, Val Acc: 0.783505\n",
      "Epoch 18550 - Train Loss: 0.084990, Train Acc: 0.874359 | Val Loss: 0.112744, Val Acc: 0.783505\n",
      "Epoch 18551 - Train Loss: 0.084988, Train Acc: 0.874359 | Val Loss: 0.112743, Val Acc: 0.783505\n",
      "Epoch 18552 - Train Loss: 0.084985, Train Acc: 0.874359 | Val Loss: 0.112741, Val Acc: 0.783505\n",
      "Epoch 18553 - Train Loss: 0.084982, Train Acc: 0.874359 | Val Loss: 0.112740, Val Acc: 0.783505\n",
      "Epoch 18554 - Train Loss: 0.084980, Train Acc: 0.874359 | Val Loss: 0.112739, Val Acc: 0.783505\n",
      "Epoch 18555 - Train Loss: 0.084977, Train Acc: 0.874359 | Val Loss: 0.112737, Val Acc: 0.783505\n",
      "Epoch 18556 - Train Loss: 0.084974, Train Acc: 0.874359 | Val Loss: 0.112736, Val Acc: 0.783505\n",
      "Epoch 18557 - Train Loss: 0.084972, Train Acc: 0.874359 | Val Loss: 0.112735, Val Acc: 0.783505\n",
      "Epoch 18558 - Train Loss: 0.084969, Train Acc: 0.874359 | Val Loss: 0.112733, Val Acc: 0.783505\n",
      "Epoch 18559 - Train Loss: 0.084966, Train Acc: 0.874359 | Val Loss: 0.112732, Val Acc: 0.783505\n",
      "Epoch 18560 - Train Loss: 0.084964, Train Acc: 0.874359 | Val Loss: 0.112731, Val Acc: 0.783505\n",
      "Epoch 18561 - Train Loss: 0.084961, Train Acc: 0.874359 | Val Loss: 0.112729, Val Acc: 0.783505\n",
      "Epoch 18562 - Train Loss: 0.084958, Train Acc: 0.874359 | Val Loss: 0.112728, Val Acc: 0.783505\n",
      "Epoch 18563 - Train Loss: 0.084956, Train Acc: 0.874359 | Val Loss: 0.112727, Val Acc: 0.783505\n",
      "Epoch 18564 - Train Loss: 0.084953, Train Acc: 0.874359 | Val Loss: 0.112725, Val Acc: 0.783505\n",
      "Epoch 18565 - Train Loss: 0.084950, Train Acc: 0.874359 | Val Loss: 0.112724, Val Acc: 0.783505\n",
      "Epoch 18566 - Train Loss: 0.084948, Train Acc: 0.874359 | Val Loss: 0.112723, Val Acc: 0.783505\n",
      "Epoch 18567 - Train Loss: 0.084945, Train Acc: 0.874359 | Val Loss: 0.112721, Val Acc: 0.783505\n",
      "Epoch 18568 - Train Loss: 0.084942, Train Acc: 0.874359 | Val Loss: 0.112720, Val Acc: 0.783505\n",
      "Epoch 18569 - Train Loss: 0.084939, Train Acc: 0.874359 | Val Loss: 0.112719, Val Acc: 0.783505\n",
      "Epoch 18570 - Train Loss: 0.084937, Train Acc: 0.874359 | Val Loss: 0.112717, Val Acc: 0.783505\n",
      "Epoch 18571 - Train Loss: 0.084934, Train Acc: 0.874359 | Val Loss: 0.112716, Val Acc: 0.783505\n",
      "Epoch 18572 - Train Loss: 0.084931, Train Acc: 0.874359 | Val Loss: 0.112715, Val Acc: 0.783505\n",
      "Epoch 18573 - Train Loss: 0.084929, Train Acc: 0.874359 | Val Loss: 0.112713, Val Acc: 0.783505\n",
      "Epoch 18574 - Train Loss: 0.084926, Train Acc: 0.874359 | Val Loss: 0.112712, Val Acc: 0.783505\n",
      "Epoch 18575 - Train Loss: 0.084923, Train Acc: 0.874359 | Val Loss: 0.112711, Val Acc: 0.783505\n",
      "Epoch 18576 - Train Loss: 0.084921, Train Acc: 0.874359 | Val Loss: 0.112709, Val Acc: 0.783505\n",
      "Epoch 18577 - Train Loss: 0.084918, Train Acc: 0.874359 | Val Loss: 0.112708, Val Acc: 0.783505\n",
      "Epoch 18578 - Train Loss: 0.084915, Train Acc: 0.874359 | Val Loss: 0.112707, Val Acc: 0.783505\n",
      "Epoch 18579 - Train Loss: 0.084913, Train Acc: 0.874359 | Val Loss: 0.112705, Val Acc: 0.783505\n",
      "Epoch 18580 - Train Loss: 0.084910, Train Acc: 0.874359 | Val Loss: 0.112704, Val Acc: 0.783505\n",
      "Epoch 18581 - Train Loss: 0.084907, Train Acc: 0.874359 | Val Loss: 0.112703, Val Acc: 0.783505\n",
      "Epoch 18582 - Train Loss: 0.084905, Train Acc: 0.874359 | Val Loss: 0.112701, Val Acc: 0.783505\n",
      "Epoch 18583 - Train Loss: 0.084902, Train Acc: 0.874359 | Val Loss: 0.112700, Val Acc: 0.783505\n",
      "Epoch 18584 - Train Loss: 0.084899, Train Acc: 0.874359 | Val Loss: 0.112699, Val Acc: 0.783505\n",
      "Epoch 18585 - Train Loss: 0.084897, Train Acc: 0.874359 | Val Loss: 0.112698, Val Acc: 0.783505\n",
      "Epoch 18586 - Train Loss: 0.084894, Train Acc: 0.874359 | Val Loss: 0.112696, Val Acc: 0.783505\n",
      "Epoch 18587 - Train Loss: 0.084891, Train Acc: 0.874359 | Val Loss: 0.112695, Val Acc: 0.783505\n",
      "Epoch 18588 - Train Loss: 0.084889, Train Acc: 0.874359 | Val Loss: 0.112694, Val Acc: 0.783505\n",
      "Epoch 18589 - Train Loss: 0.084886, Train Acc: 0.874359 | Val Loss: 0.112692, Val Acc: 0.783505\n",
      "Epoch 18590 - Train Loss: 0.084883, Train Acc: 0.874359 | Val Loss: 0.112691, Val Acc: 0.783505\n",
      "Epoch 18591 - Train Loss: 0.084881, Train Acc: 0.874359 | Val Loss: 0.112690, Val Acc: 0.783505\n",
      "Epoch 18592 - Train Loss: 0.084878, Train Acc: 0.874359 | Val Loss: 0.112688, Val Acc: 0.783505\n",
      "Epoch 18593 - Train Loss: 0.084875, Train Acc: 0.874359 | Val Loss: 0.112687, Val Acc: 0.783505\n",
      "Epoch 18594 - Train Loss: 0.084873, Train Acc: 0.874359 | Val Loss: 0.112686, Val Acc: 0.783505\n",
      "Epoch 18595 - Train Loss: 0.084870, Train Acc: 0.874359 | Val Loss: 0.112684, Val Acc: 0.783505\n",
      "Epoch 18596 - Train Loss: 0.084867, Train Acc: 0.874359 | Val Loss: 0.112683, Val Acc: 0.783505\n",
      "Epoch 18597 - Train Loss: 0.084865, Train Acc: 0.874359 | Val Loss: 0.112682, Val Acc: 0.783505\n",
      "Epoch 18598 - Train Loss: 0.084862, Train Acc: 0.874359 | Val Loss: 0.112680, Val Acc: 0.783505\n",
      "Epoch 18599 - Train Loss: 0.084860, Train Acc: 0.874359 | Val Loss: 0.112679, Val Acc: 0.783505\n",
      "Epoch 18600 - Train Loss: 0.084857, Train Acc: 0.874359 | Val Loss: 0.112678, Val Acc: 0.783505\n",
      "Epoch 18601 - Train Loss: 0.084854, Train Acc: 0.874359 | Val Loss: 0.112676, Val Acc: 0.783505\n",
      "Epoch 18602 - Train Loss: 0.084852, Train Acc: 0.874359 | Val Loss: 0.112675, Val Acc: 0.783505\n",
      "Epoch 18603 - Train Loss: 0.084849, Train Acc: 0.874359 | Val Loss: 0.112674, Val Acc: 0.783505\n",
      "Epoch 18604 - Train Loss: 0.084846, Train Acc: 0.874359 | Val Loss: 0.112672, Val Acc: 0.783505\n",
      "Epoch 18605 - Train Loss: 0.084844, Train Acc: 0.874359 | Val Loss: 0.112671, Val Acc: 0.783505\n",
      "Epoch 18606 - Train Loss: 0.084841, Train Acc: 0.874359 | Val Loss: 0.112670, Val Acc: 0.783505\n",
      "Epoch 18607 - Train Loss: 0.084838, Train Acc: 0.874359 | Val Loss: 0.112668, Val Acc: 0.783505\n",
      "Epoch 18608 - Train Loss: 0.084836, Train Acc: 0.874359 | Val Loss: 0.112667, Val Acc: 0.783505\n",
      "Epoch 18609 - Train Loss: 0.084833, Train Acc: 0.874359 | Val Loss: 0.112666, Val Acc: 0.783505\n",
      "Epoch 18610 - Train Loss: 0.084830, Train Acc: 0.874359 | Val Loss: 0.112664, Val Acc: 0.783505\n",
      "Epoch 18611 - Train Loss: 0.084828, Train Acc: 0.874359 | Val Loss: 0.112663, Val Acc: 0.783505\n",
      "Epoch 18612 - Train Loss: 0.084825, Train Acc: 0.874359 | Val Loss: 0.112662, Val Acc: 0.783505\n",
      "Epoch 18613 - Train Loss: 0.084822, Train Acc: 0.874359 | Val Loss: 0.112660, Val Acc: 0.783505\n",
      "Epoch 18614 - Train Loss: 0.084820, Train Acc: 0.874359 | Val Loss: 0.112659, Val Acc: 0.783505\n",
      "Epoch 18615 - Train Loss: 0.084817, Train Acc: 0.874359 | Val Loss: 0.112658, Val Acc: 0.783505\n",
      "Epoch 18616 - Train Loss: 0.084814, Train Acc: 0.874359 | Val Loss: 0.112657, Val Acc: 0.783505\n",
      "Epoch 18617 - Train Loss: 0.084812, Train Acc: 0.874359 | Val Loss: 0.112655, Val Acc: 0.783505\n",
      "Epoch 18618 - Train Loss: 0.084809, Train Acc: 0.874359 | Val Loss: 0.112654, Val Acc: 0.783505\n",
      "Epoch 18619 - Train Loss: 0.084806, Train Acc: 0.874359 | Val Loss: 0.112653, Val Acc: 0.783505\n",
      "Epoch 18620 - Train Loss: 0.084804, Train Acc: 0.874359 | Val Loss: 0.112651, Val Acc: 0.783505\n",
      "Epoch 18621 - Train Loss: 0.084801, Train Acc: 0.874359 | Val Loss: 0.112650, Val Acc: 0.783505\n",
      "Epoch 18622 - Train Loss: 0.084798, Train Acc: 0.874359 | Val Loss: 0.112649, Val Acc: 0.783505\n",
      "Epoch 18623 - Train Loss: 0.084796, Train Acc: 0.874359 | Val Loss: 0.112647, Val Acc: 0.783505\n",
      "Epoch 18624 - Train Loss: 0.084793, Train Acc: 0.874359 | Val Loss: 0.112646, Val Acc: 0.783505\n",
      "Epoch 18625 - Train Loss: 0.084790, Train Acc: 0.874359 | Val Loss: 0.112645, Val Acc: 0.783505\n",
      "Epoch 18626 - Train Loss: 0.084788, Train Acc: 0.874359 | Val Loss: 0.112643, Val Acc: 0.783505\n",
      "Epoch 18627 - Train Loss: 0.084785, Train Acc: 0.874359 | Val Loss: 0.112642, Val Acc: 0.783505\n",
      "Epoch 18628 - Train Loss: 0.084782, Train Acc: 0.874359 | Val Loss: 0.112641, Val Acc: 0.783505\n",
      "Epoch 18629 - Train Loss: 0.084780, Train Acc: 0.874359 | Val Loss: 0.112639, Val Acc: 0.783505\n",
      "Epoch 18630 - Train Loss: 0.084777, Train Acc: 0.874359 | Val Loss: 0.112638, Val Acc: 0.783505\n",
      "Epoch 18631 - Train Loss: 0.084774, Train Acc: 0.874359 | Val Loss: 0.112637, Val Acc: 0.783505\n",
      "Epoch 18632 - Train Loss: 0.084772, Train Acc: 0.874359 | Val Loss: 0.112636, Val Acc: 0.783505\n",
      "Epoch 18633 - Train Loss: 0.084769, Train Acc: 0.874359 | Val Loss: 0.112634, Val Acc: 0.783505\n",
      "Epoch 18634 - Train Loss: 0.084767, Train Acc: 0.874359 | Val Loss: 0.112633, Val Acc: 0.783505\n",
      "Epoch 18635 - Train Loss: 0.084764, Train Acc: 0.874359 | Val Loss: 0.112632, Val Acc: 0.783505\n",
      "Epoch 18636 - Train Loss: 0.084761, Train Acc: 0.874359 | Val Loss: 0.112630, Val Acc: 0.783505\n",
      "Epoch 18637 - Train Loss: 0.084759, Train Acc: 0.874359 | Val Loss: 0.112629, Val Acc: 0.783505\n",
      "Epoch 18638 - Train Loss: 0.084756, Train Acc: 0.874359 | Val Loss: 0.112628, Val Acc: 0.783505\n",
      "Epoch 18639 - Train Loss: 0.084753, Train Acc: 0.874359 | Val Loss: 0.112626, Val Acc: 0.783505\n",
      "Epoch 18640 - Train Loss: 0.084751, Train Acc: 0.874359 | Val Loss: 0.112625, Val Acc: 0.783505\n",
      "Epoch 18641 - Train Loss: 0.084748, Train Acc: 0.874359 | Val Loss: 0.112624, Val Acc: 0.783505\n",
      "Epoch 18642 - Train Loss: 0.084745, Train Acc: 0.874359 | Val Loss: 0.112622, Val Acc: 0.783505\n",
      "Epoch 18643 - Train Loss: 0.084743, Train Acc: 0.874359 | Val Loss: 0.112621, Val Acc: 0.783505\n",
      "Epoch 18644 - Train Loss: 0.084740, Train Acc: 0.874359 | Val Loss: 0.112620, Val Acc: 0.783505\n",
      "Epoch 18645 - Train Loss: 0.084737, Train Acc: 0.874359 | Val Loss: 0.112618, Val Acc: 0.783505\n",
      "Epoch 18646 - Train Loss: 0.084735, Train Acc: 0.874359 | Val Loss: 0.112617, Val Acc: 0.783505\n",
      "Epoch 18647 - Train Loss: 0.084732, Train Acc: 0.874359 | Val Loss: 0.112616, Val Acc: 0.783505\n",
      "Epoch 18648 - Train Loss: 0.084729, Train Acc: 0.874359 | Val Loss: 0.112615, Val Acc: 0.783505\n",
      "Epoch 18649 - Train Loss: 0.084727, Train Acc: 0.874359 | Val Loss: 0.112613, Val Acc: 0.783505\n",
      "Epoch 18650 - Train Loss: 0.084724, Train Acc: 0.874359 | Val Loss: 0.112612, Val Acc: 0.783505\n",
      "Epoch 18651 - Train Loss: 0.084721, Train Acc: 0.874359 | Val Loss: 0.112611, Val Acc: 0.783505\n",
      "Epoch 18652 - Train Loss: 0.084719, Train Acc: 0.874359 | Val Loss: 0.112609, Val Acc: 0.783505\n",
      "Epoch 18653 - Train Loss: 0.084716, Train Acc: 0.874359 | Val Loss: 0.112608, Val Acc: 0.783505\n",
      "Epoch 18654 - Train Loss: 0.084714, Train Acc: 0.874359 | Val Loss: 0.112607, Val Acc: 0.783505\n",
      "Epoch 18655 - Train Loss: 0.084711, Train Acc: 0.874359 | Val Loss: 0.112605, Val Acc: 0.783505\n",
      "Epoch 18656 - Train Loss: 0.084708, Train Acc: 0.874359 | Val Loss: 0.112604, Val Acc: 0.783505\n",
      "Epoch 18657 - Train Loss: 0.084706, Train Acc: 0.874359 | Val Loss: 0.112603, Val Acc: 0.783505\n",
      "Epoch 18658 - Train Loss: 0.084703, Train Acc: 0.874359 | Val Loss: 0.112601, Val Acc: 0.783505\n",
      "Epoch 18659 - Train Loss: 0.084700, Train Acc: 0.874359 | Val Loss: 0.112600, Val Acc: 0.783505\n",
      "Epoch 18660 - Train Loss: 0.084698, Train Acc: 0.874359 | Val Loss: 0.112599, Val Acc: 0.783505\n",
      "Epoch 18661 - Train Loss: 0.084695, Train Acc: 0.874359 | Val Loss: 0.112598, Val Acc: 0.783505\n",
      "Epoch 18662 - Train Loss: 0.084692, Train Acc: 0.874359 | Val Loss: 0.112596, Val Acc: 0.783505\n",
      "Epoch 18663 - Train Loss: 0.084690, Train Acc: 0.874359 | Val Loss: 0.112595, Val Acc: 0.783505\n",
      "Epoch 18664 - Train Loss: 0.084687, Train Acc: 0.874359 | Val Loss: 0.112594, Val Acc: 0.783505\n",
      "Epoch 18665 - Train Loss: 0.084684, Train Acc: 0.874359 | Val Loss: 0.112592, Val Acc: 0.783505\n",
      "Epoch 18666 - Train Loss: 0.084682, Train Acc: 0.874359 | Val Loss: 0.112591, Val Acc: 0.783505\n",
      "Epoch 18667 - Train Loss: 0.084679, Train Acc: 0.874359 | Val Loss: 0.112590, Val Acc: 0.783505\n",
      "Epoch 18668 - Train Loss: 0.084677, Train Acc: 0.874359 | Val Loss: 0.112588, Val Acc: 0.783505\n",
      "Epoch 18669 - Train Loss: 0.084674, Train Acc: 0.874359 | Val Loss: 0.112587, Val Acc: 0.783505\n",
      "Epoch 18670 - Train Loss: 0.084671, Train Acc: 0.874359 | Val Loss: 0.112586, Val Acc: 0.783505\n",
      "Epoch 18671 - Train Loss: 0.084669, Train Acc: 0.874359 | Val Loss: 0.112585, Val Acc: 0.783505\n",
      "Epoch 18672 - Train Loss: 0.084666, Train Acc: 0.874359 | Val Loss: 0.112583, Val Acc: 0.783505\n",
      "Epoch 18673 - Train Loss: 0.084663, Train Acc: 0.874359 | Val Loss: 0.112582, Val Acc: 0.783505\n",
      "Epoch 18674 - Train Loss: 0.084661, Train Acc: 0.874359 | Val Loss: 0.112581, Val Acc: 0.783505\n",
      "Epoch 18675 - Train Loss: 0.084658, Train Acc: 0.874359 | Val Loss: 0.112579, Val Acc: 0.783505\n",
      "Epoch 18676 - Train Loss: 0.084655, Train Acc: 0.874359 | Val Loss: 0.112578, Val Acc: 0.783505\n",
      "Epoch 18677 - Train Loss: 0.084653, Train Acc: 0.874359 | Val Loss: 0.112577, Val Acc: 0.783505\n",
      "Epoch 18678 - Train Loss: 0.084650, Train Acc: 0.874359 | Val Loss: 0.112575, Val Acc: 0.783505\n",
      "Epoch 18679 - Train Loss: 0.084647, Train Acc: 0.874359 | Val Loss: 0.112574, Val Acc: 0.783505\n",
      "Epoch 18680 - Train Loss: 0.084645, Train Acc: 0.874359 | Val Loss: 0.112573, Val Acc: 0.783505\n",
      "Epoch 18681 - Train Loss: 0.084642, Train Acc: 0.874359 | Val Loss: 0.112572, Val Acc: 0.783505\n",
      "Epoch 18682 - Train Loss: 0.084640, Train Acc: 0.874359 | Val Loss: 0.112570, Val Acc: 0.783505\n",
      "Epoch 18683 - Train Loss: 0.084637, Train Acc: 0.874359 | Val Loss: 0.112569, Val Acc: 0.783505\n",
      "Epoch 18684 - Train Loss: 0.084634, Train Acc: 0.874359 | Val Loss: 0.112568, Val Acc: 0.783505\n",
      "Epoch 18685 - Train Loss: 0.084632, Train Acc: 0.874359 | Val Loss: 0.112566, Val Acc: 0.783505\n",
      "Epoch 18686 - Train Loss: 0.084629, Train Acc: 0.874359 | Val Loss: 0.112565, Val Acc: 0.783505\n",
      "Epoch 18687 - Train Loss: 0.084626, Train Acc: 0.874359 | Val Loss: 0.112564, Val Acc: 0.783505\n",
      "Epoch 18688 - Train Loss: 0.084624, Train Acc: 0.874359 | Val Loss: 0.112562, Val Acc: 0.783505\n",
      "Epoch 18689 - Train Loss: 0.084621, Train Acc: 0.874359 | Val Loss: 0.112561, Val Acc: 0.783505\n",
      "Epoch 18690 - Train Loss: 0.084618, Train Acc: 0.874359 | Val Loss: 0.112560, Val Acc: 0.783505\n",
      "Epoch 18691 - Train Loss: 0.084616, Train Acc: 0.874359 | Val Loss: 0.112559, Val Acc: 0.783505\n",
      "Epoch 18692 - Train Loss: 0.084613, Train Acc: 0.874359 | Val Loss: 0.112557, Val Acc: 0.783505\n",
      "Epoch 18693 - Train Loss: 0.084611, Train Acc: 0.874359 | Val Loss: 0.112556, Val Acc: 0.783505\n",
      "Epoch 18694 - Train Loss: 0.084608, Train Acc: 0.874359 | Val Loss: 0.112555, Val Acc: 0.783505\n",
      "Epoch 18695 - Train Loss: 0.084605, Train Acc: 0.874359 | Val Loss: 0.112553, Val Acc: 0.783505\n",
      "Epoch 18696 - Train Loss: 0.084603, Train Acc: 0.874359 | Val Loss: 0.112552, Val Acc: 0.783505\n",
      "Epoch 18697 - Train Loss: 0.084600, Train Acc: 0.874359 | Val Loss: 0.112551, Val Acc: 0.783505\n",
      "Epoch 18698 - Train Loss: 0.084597, Train Acc: 0.874359 | Val Loss: 0.112549, Val Acc: 0.783505\n",
      "Epoch 18699 - Train Loss: 0.084595, Train Acc: 0.874359 | Val Loss: 0.112548, Val Acc: 0.783505\n",
      "Epoch 18700 - Train Loss: 0.084592, Train Acc: 0.874359 | Val Loss: 0.112547, Val Acc: 0.783505\n",
      "Epoch 18701 - Train Loss: 0.084589, Train Acc: 0.874359 | Val Loss: 0.112546, Val Acc: 0.783505\n",
      "Epoch 18702 - Train Loss: 0.084587, Train Acc: 0.874359 | Val Loss: 0.112544, Val Acc: 0.783505\n",
      "Epoch 18703 - Train Loss: 0.084584, Train Acc: 0.874359 | Val Loss: 0.112543, Val Acc: 0.783505\n",
      "Epoch 18704 - Train Loss: 0.084582, Train Acc: 0.874359 | Val Loss: 0.112542, Val Acc: 0.783505\n",
      "Epoch 18705 - Train Loss: 0.084579, Train Acc: 0.874359 | Val Loss: 0.112540, Val Acc: 0.783505\n",
      "Epoch 18706 - Train Loss: 0.084576, Train Acc: 0.874359 | Val Loss: 0.112539, Val Acc: 0.783505\n",
      "Epoch 18707 - Train Loss: 0.084574, Train Acc: 0.874359 | Val Loss: 0.112538, Val Acc: 0.783505\n",
      "Epoch 18708 - Train Loss: 0.084571, Train Acc: 0.874359 | Val Loss: 0.112537, Val Acc: 0.783505\n",
      "Epoch 18709 - Train Loss: 0.084568, Train Acc: 0.874359 | Val Loss: 0.112535, Val Acc: 0.783505\n",
      "Epoch 18710 - Train Loss: 0.084566, Train Acc: 0.874359 | Val Loss: 0.112534, Val Acc: 0.783505\n",
      "Epoch 18711 - Train Loss: 0.084563, Train Acc: 0.874359 | Val Loss: 0.112533, Val Acc: 0.783505\n",
      "Epoch 18712 - Train Loss: 0.084561, Train Acc: 0.874359 | Val Loss: 0.112531, Val Acc: 0.783505\n",
      "Epoch 18713 - Train Loss: 0.084558, Train Acc: 0.874359 | Val Loss: 0.112530, Val Acc: 0.783505\n",
      "Epoch 18714 - Train Loss: 0.084555, Train Acc: 0.874359 | Val Loss: 0.112529, Val Acc: 0.783505\n",
      "Epoch 18715 - Train Loss: 0.084553, Train Acc: 0.874359 | Val Loss: 0.112528, Val Acc: 0.783505\n",
      "Epoch 18716 - Train Loss: 0.084550, Train Acc: 0.874359 | Val Loss: 0.112526, Val Acc: 0.783505\n",
      "Epoch 18717 - Train Loss: 0.084547, Train Acc: 0.874359 | Val Loss: 0.112525, Val Acc: 0.783505\n",
      "Epoch 18718 - Train Loss: 0.084545, Train Acc: 0.874359 | Val Loss: 0.112524, Val Acc: 0.783505\n",
      "Epoch 18719 - Train Loss: 0.084542, Train Acc: 0.874359 | Val Loss: 0.112522, Val Acc: 0.783505\n",
      "Epoch 18720 - Train Loss: 0.084540, Train Acc: 0.874359 | Val Loss: 0.112521, Val Acc: 0.783505\n",
      "Epoch 18721 - Train Loss: 0.084537, Train Acc: 0.874359 | Val Loss: 0.112520, Val Acc: 0.783505\n",
      "Epoch 18722 - Train Loss: 0.084534, Train Acc: 0.874359 | Val Loss: 0.112518, Val Acc: 0.783505\n",
      "Epoch 18723 - Train Loss: 0.084532, Train Acc: 0.874359 | Val Loss: 0.112517, Val Acc: 0.783505\n",
      "Epoch 18724 - Train Loss: 0.084529, Train Acc: 0.874359 | Val Loss: 0.112516, Val Acc: 0.783505\n",
      "Epoch 18725 - Train Loss: 0.084526, Train Acc: 0.874359 | Val Loss: 0.112515, Val Acc: 0.783505\n",
      "Epoch 18726 - Train Loss: 0.084524, Train Acc: 0.874359 | Val Loss: 0.112513, Val Acc: 0.783505\n",
      "Epoch 18727 - Train Loss: 0.084521, Train Acc: 0.874359 | Val Loss: 0.112512, Val Acc: 0.783505\n",
      "Epoch 18728 - Train Loss: 0.084518, Train Acc: 0.874359 | Val Loss: 0.112511, Val Acc: 0.783505\n",
      "Epoch 18729 - Train Loss: 0.084516, Train Acc: 0.874359 | Val Loss: 0.112509, Val Acc: 0.783505\n",
      "Epoch 18730 - Train Loss: 0.084513, Train Acc: 0.874359 | Val Loss: 0.112508, Val Acc: 0.783505\n",
      "Epoch 18731 - Train Loss: 0.084511, Train Acc: 0.874359 | Val Loss: 0.112507, Val Acc: 0.783505\n",
      "Epoch 18732 - Train Loss: 0.084508, Train Acc: 0.874359 | Val Loss: 0.112506, Val Acc: 0.783505\n",
      "Epoch 18733 - Train Loss: 0.084505, Train Acc: 0.874359 | Val Loss: 0.112504, Val Acc: 0.783505\n",
      "Epoch 18734 - Train Loss: 0.084503, Train Acc: 0.874359 | Val Loss: 0.112503, Val Acc: 0.783505\n",
      "Epoch 18735 - Train Loss: 0.084500, Train Acc: 0.874359 | Val Loss: 0.112502, Val Acc: 0.783505\n",
      "Epoch 18736 - Train Loss: 0.084498, Train Acc: 0.874359 | Val Loss: 0.112500, Val Acc: 0.783505\n",
      "Epoch 18737 - Train Loss: 0.084495, Train Acc: 0.874359 | Val Loss: 0.112499, Val Acc: 0.783505\n",
      "Epoch 18738 - Train Loss: 0.084492, Train Acc: 0.874359 | Val Loss: 0.112498, Val Acc: 0.783505\n",
      "Epoch 18739 - Train Loss: 0.084490, Train Acc: 0.874359 | Val Loss: 0.112497, Val Acc: 0.783505\n",
      "Epoch 18740 - Train Loss: 0.084487, Train Acc: 0.874359 | Val Loss: 0.112495, Val Acc: 0.783505\n",
      "Epoch 18741 - Train Loss: 0.084484, Train Acc: 0.874359 | Val Loss: 0.112494, Val Acc: 0.783505\n",
      "Epoch 18742 - Train Loss: 0.084482, Train Acc: 0.874359 | Val Loss: 0.112493, Val Acc: 0.783505\n",
      "Epoch 18743 - Train Loss: 0.084479, Train Acc: 0.874359 | Val Loss: 0.112491, Val Acc: 0.783505\n",
      "Epoch 18744 - Train Loss: 0.084477, Train Acc: 0.874359 | Val Loss: 0.112490, Val Acc: 0.783505\n",
      "Epoch 18745 - Train Loss: 0.084474, Train Acc: 0.874359 | Val Loss: 0.112489, Val Acc: 0.783505\n",
      "Epoch 18746 - Train Loss: 0.084471, Train Acc: 0.874359 | Val Loss: 0.112488, Val Acc: 0.783505\n",
      "Epoch 18747 - Train Loss: 0.084469, Train Acc: 0.874359 | Val Loss: 0.112486, Val Acc: 0.783505\n",
      "Epoch 18748 - Train Loss: 0.084466, Train Acc: 0.874359 | Val Loss: 0.112485, Val Acc: 0.783505\n",
      "Epoch 18749 - Train Loss: 0.084463, Train Acc: 0.874359 | Val Loss: 0.112484, Val Acc: 0.783505\n",
      "Epoch 18750 - Train Loss: 0.084461, Train Acc: 0.874359 | Val Loss: 0.112483, Val Acc: 0.783505\n",
      "Epoch 18751 - Train Loss: 0.084458, Train Acc: 0.874359 | Val Loss: 0.112481, Val Acc: 0.783505\n",
      "Epoch 18752 - Train Loss: 0.084456, Train Acc: 0.874359 | Val Loss: 0.112480, Val Acc: 0.783505\n",
      "Epoch 18753 - Train Loss: 0.084453, Train Acc: 0.874359 | Val Loss: 0.112479, Val Acc: 0.783505\n",
      "Epoch 18754 - Train Loss: 0.084450, Train Acc: 0.874359 | Val Loss: 0.112477, Val Acc: 0.783505\n",
      "Epoch 18755 - Train Loss: 0.084448, Train Acc: 0.874359 | Val Loss: 0.112476, Val Acc: 0.783505\n",
      "Epoch 18756 - Train Loss: 0.084445, Train Acc: 0.874359 | Val Loss: 0.112475, Val Acc: 0.783505\n",
      "Epoch 18757 - Train Loss: 0.084442, Train Acc: 0.874359 | Val Loss: 0.112474, Val Acc: 0.783505\n",
      "Epoch 18758 - Train Loss: 0.084440, Train Acc: 0.874359 | Val Loss: 0.112472, Val Acc: 0.783505\n",
      "Epoch 18759 - Train Loss: 0.084437, Train Acc: 0.874359 | Val Loss: 0.112471, Val Acc: 0.783505\n",
      "Epoch 18760 - Train Loss: 0.084435, Train Acc: 0.874359 | Val Loss: 0.112470, Val Acc: 0.783505\n",
      "Epoch 18761 - Train Loss: 0.084432, Train Acc: 0.874359 | Val Loss: 0.112468, Val Acc: 0.783505\n",
      "Epoch 18762 - Train Loss: 0.084429, Train Acc: 0.874359 | Val Loss: 0.112467, Val Acc: 0.783505\n",
      "Epoch 18763 - Train Loss: 0.084427, Train Acc: 0.874359 | Val Loss: 0.112466, Val Acc: 0.783505\n",
      "Epoch 18764 - Train Loss: 0.084424, Train Acc: 0.874359 | Val Loss: 0.112465, Val Acc: 0.783505\n",
      "Epoch 18765 - Train Loss: 0.084422, Train Acc: 0.874359 | Val Loss: 0.112463, Val Acc: 0.783505\n",
      "Epoch 18766 - Train Loss: 0.084419, Train Acc: 0.874359 | Val Loss: 0.112462, Val Acc: 0.783505\n",
      "Epoch 18767 - Train Loss: 0.084416, Train Acc: 0.874359 | Val Loss: 0.112461, Val Acc: 0.783505\n",
      "Epoch 18768 - Train Loss: 0.084414, Train Acc: 0.874359 | Val Loss: 0.112460, Val Acc: 0.783505\n",
      "Epoch 18769 - Train Loss: 0.084411, Train Acc: 0.874359 | Val Loss: 0.112458, Val Acc: 0.783505\n",
      "Epoch 18770 - Train Loss: 0.084408, Train Acc: 0.874359 | Val Loss: 0.112457, Val Acc: 0.783505\n",
      "Epoch 18771 - Train Loss: 0.084406, Train Acc: 0.874359 | Val Loss: 0.112456, Val Acc: 0.783505\n",
      "Epoch 18772 - Train Loss: 0.084403, Train Acc: 0.874359 | Val Loss: 0.112454, Val Acc: 0.783505\n",
      "Epoch 18773 - Train Loss: 0.084401, Train Acc: 0.874359 | Val Loss: 0.112453, Val Acc: 0.783505\n",
      "Epoch 18774 - Train Loss: 0.084398, Train Acc: 0.874359 | Val Loss: 0.112452, Val Acc: 0.783505\n",
      "Epoch 18775 - Train Loss: 0.084395, Train Acc: 0.874359 | Val Loss: 0.112451, Val Acc: 0.783505\n",
      "Epoch 18776 - Train Loss: 0.084393, Train Acc: 0.874359 | Val Loss: 0.112449, Val Acc: 0.783505\n",
      "Epoch 18777 - Train Loss: 0.084390, Train Acc: 0.874359 | Val Loss: 0.112448, Val Acc: 0.783505\n",
      "Epoch 18778 - Train Loss: 0.084388, Train Acc: 0.874359 | Val Loss: 0.112447, Val Acc: 0.783505\n",
      "Epoch 18779 - Train Loss: 0.084385, Train Acc: 0.874359 | Val Loss: 0.112446, Val Acc: 0.783505\n",
      "Epoch 18780 - Train Loss: 0.084382, Train Acc: 0.874359 | Val Loss: 0.112444, Val Acc: 0.783505\n",
      "Epoch 18781 - Train Loss: 0.084380, Train Acc: 0.874359 | Val Loss: 0.112443, Val Acc: 0.783505\n",
      "Epoch 18782 - Train Loss: 0.084377, Train Acc: 0.874359 | Val Loss: 0.112442, Val Acc: 0.783505\n",
      "Epoch 18783 - Train Loss: 0.084375, Train Acc: 0.874359 | Val Loss: 0.112440, Val Acc: 0.783505\n",
      "Epoch 18784 - Train Loss: 0.084372, Train Acc: 0.874359 | Val Loss: 0.112439, Val Acc: 0.783505\n",
      "Epoch 18785 - Train Loss: 0.084369, Train Acc: 0.874359 | Val Loss: 0.112438, Val Acc: 0.783505\n",
      "Epoch 18786 - Train Loss: 0.084367, Train Acc: 0.874359 | Val Loss: 0.112437, Val Acc: 0.783505\n",
      "Epoch 18787 - Train Loss: 0.084364, Train Acc: 0.874359 | Val Loss: 0.112435, Val Acc: 0.783505\n",
      "Epoch 18788 - Train Loss: 0.084362, Train Acc: 0.874359 | Val Loss: 0.112434, Val Acc: 0.783505\n",
      "Epoch 18789 - Train Loss: 0.084359, Train Acc: 0.874359 | Val Loss: 0.112433, Val Acc: 0.783505\n",
      "Epoch 18790 - Train Loss: 0.084356, Train Acc: 0.874359 | Val Loss: 0.112432, Val Acc: 0.783505\n",
      "Epoch 18791 - Train Loss: 0.084354, Train Acc: 0.874359 | Val Loss: 0.112430, Val Acc: 0.783505\n",
      "Epoch 18792 - Train Loss: 0.084351, Train Acc: 0.874359 | Val Loss: 0.112429, Val Acc: 0.783505\n",
      "Epoch 18793 - Train Loss: 0.084348, Train Acc: 0.874359 | Val Loss: 0.112428, Val Acc: 0.783505\n",
      "Epoch 18794 - Train Loss: 0.084346, Train Acc: 0.874359 | Val Loss: 0.112426, Val Acc: 0.783505\n",
      "Epoch 18795 - Train Loss: 0.084343, Train Acc: 0.874359 | Val Loss: 0.112425, Val Acc: 0.783505\n",
      "Epoch 18796 - Train Loss: 0.084341, Train Acc: 0.874359 | Val Loss: 0.112424, Val Acc: 0.783505\n",
      "Epoch 18797 - Train Loss: 0.084338, Train Acc: 0.874359 | Val Loss: 0.112423, Val Acc: 0.783505\n",
      "Epoch 18798 - Train Loss: 0.084335, Train Acc: 0.874359 | Val Loss: 0.112421, Val Acc: 0.783505\n",
      "Epoch 18799 - Train Loss: 0.084333, Train Acc: 0.874359 | Val Loss: 0.112420, Val Acc: 0.783505\n",
      "Epoch 18800 - Train Loss: 0.084330, Train Acc: 0.874359 | Val Loss: 0.112419, Val Acc: 0.783505\n",
      "Epoch 18801 - Train Loss: 0.084328, Train Acc: 0.874359 | Val Loss: 0.112418, Val Acc: 0.783505\n",
      "Epoch 18802 - Train Loss: 0.084325, Train Acc: 0.874359 | Val Loss: 0.112416, Val Acc: 0.783505\n",
      "Epoch 18803 - Train Loss: 0.084322, Train Acc: 0.874359 | Val Loss: 0.112415, Val Acc: 0.783505\n",
      "Epoch 18804 - Train Loss: 0.084320, Train Acc: 0.874359 | Val Loss: 0.112414, Val Acc: 0.783505\n",
      "Epoch 18805 - Train Loss: 0.084317, Train Acc: 0.874359 | Val Loss: 0.112413, Val Acc: 0.783505\n",
      "Epoch 18806 - Train Loss: 0.084315, Train Acc: 0.874359 | Val Loss: 0.112411, Val Acc: 0.783505\n",
      "Epoch 18807 - Train Loss: 0.084312, Train Acc: 0.874359 | Val Loss: 0.112410, Val Acc: 0.783505\n",
      "Epoch 18808 - Train Loss: 0.084309, Train Acc: 0.874359 | Val Loss: 0.112409, Val Acc: 0.783505\n",
      "Epoch 18809 - Train Loss: 0.084307, Train Acc: 0.874359 | Val Loss: 0.112408, Val Acc: 0.783505\n",
      "Epoch 18810 - Train Loss: 0.084304, Train Acc: 0.874359 | Val Loss: 0.112406, Val Acc: 0.783505\n",
      "Epoch 18811 - Train Loss: 0.084302, Train Acc: 0.874359 | Val Loss: 0.112405, Val Acc: 0.783505\n",
      "Epoch 18812 - Train Loss: 0.084299, Train Acc: 0.874359 | Val Loss: 0.112404, Val Acc: 0.783505\n",
      "Epoch 18813 - Train Loss: 0.084296, Train Acc: 0.874359 | Val Loss: 0.112402, Val Acc: 0.783505\n",
      "Epoch 18814 - Train Loss: 0.084294, Train Acc: 0.874359 | Val Loss: 0.112401, Val Acc: 0.783505\n",
      "Epoch 18815 - Train Loss: 0.084291, Train Acc: 0.874359 | Val Loss: 0.112400, Val Acc: 0.783505\n",
      "Epoch 18816 - Train Loss: 0.084289, Train Acc: 0.874359 | Val Loss: 0.112399, Val Acc: 0.783505\n",
      "Epoch 18817 - Train Loss: 0.084286, Train Acc: 0.874359 | Val Loss: 0.112397, Val Acc: 0.783505\n",
      "Epoch 18818 - Train Loss: 0.084283, Train Acc: 0.874359 | Val Loss: 0.112396, Val Acc: 0.783505\n",
      "Epoch 18819 - Train Loss: 0.084281, Train Acc: 0.874359 | Val Loss: 0.112395, Val Acc: 0.783505\n",
      "Epoch 18820 - Train Loss: 0.084278, Train Acc: 0.874359 | Val Loss: 0.112394, Val Acc: 0.783505\n",
      "Epoch 18821 - Train Loss: 0.084276, Train Acc: 0.874359 | Val Loss: 0.112392, Val Acc: 0.783505\n",
      "Epoch 18822 - Train Loss: 0.084273, Train Acc: 0.874359 | Val Loss: 0.112391, Val Acc: 0.783505\n",
      "Epoch 18823 - Train Loss: 0.084270, Train Acc: 0.874359 | Val Loss: 0.112390, Val Acc: 0.783505\n",
      "Epoch 18824 - Train Loss: 0.084268, Train Acc: 0.874359 | Val Loss: 0.112389, Val Acc: 0.783505\n",
      "Epoch 18825 - Train Loss: 0.084265, Train Acc: 0.874359 | Val Loss: 0.112387, Val Acc: 0.783505\n",
      "Epoch 18826 - Train Loss: 0.084263, Train Acc: 0.874359 | Val Loss: 0.112386, Val Acc: 0.783505\n",
      "Epoch 18827 - Train Loss: 0.084260, Train Acc: 0.874359 | Val Loss: 0.112385, Val Acc: 0.783505\n",
      "Epoch 18828 - Train Loss: 0.084257, Train Acc: 0.874359 | Val Loss: 0.112384, Val Acc: 0.783505\n",
      "Epoch 18829 - Train Loss: 0.084255, Train Acc: 0.874359 | Val Loss: 0.112382, Val Acc: 0.783505\n",
      "Epoch 18830 - Train Loss: 0.084252, Train Acc: 0.874359 | Val Loss: 0.112381, Val Acc: 0.783505\n",
      "Epoch 18831 - Train Loss: 0.084250, Train Acc: 0.874359 | Val Loss: 0.112380, Val Acc: 0.783505\n",
      "Epoch 18832 - Train Loss: 0.084247, Train Acc: 0.874359 | Val Loss: 0.112379, Val Acc: 0.783505\n",
      "Epoch 18833 - Train Loss: 0.084244, Train Acc: 0.874359 | Val Loss: 0.112377, Val Acc: 0.783505\n",
      "Epoch 18834 - Train Loss: 0.084242, Train Acc: 0.874359 | Val Loss: 0.112376, Val Acc: 0.783505\n",
      "Epoch 18835 - Train Loss: 0.084239, Train Acc: 0.874359 | Val Loss: 0.112375, Val Acc: 0.783505\n",
      "Epoch 18836 - Train Loss: 0.084237, Train Acc: 0.874359 | Val Loss: 0.112373, Val Acc: 0.783505\n",
      "Epoch 18837 - Train Loss: 0.084234, Train Acc: 0.874359 | Val Loss: 0.112372, Val Acc: 0.783505\n",
      "Epoch 18838 - Train Loss: 0.084231, Train Acc: 0.874359 | Val Loss: 0.112371, Val Acc: 0.783505\n",
      "Epoch 18839 - Train Loss: 0.084229, Train Acc: 0.874359 | Val Loss: 0.112370, Val Acc: 0.783505\n",
      "Epoch 18840 - Train Loss: 0.084226, Train Acc: 0.874359 | Val Loss: 0.112368, Val Acc: 0.783505\n",
      "Epoch 18841 - Train Loss: 0.084224, Train Acc: 0.874359 | Val Loss: 0.112367, Val Acc: 0.783505\n",
      "Epoch 18842 - Train Loss: 0.084221, Train Acc: 0.874359 | Val Loss: 0.112366, Val Acc: 0.783505\n",
      "Epoch 18843 - Train Loss: 0.084218, Train Acc: 0.874359 | Val Loss: 0.112365, Val Acc: 0.783505\n",
      "Epoch 18844 - Train Loss: 0.084216, Train Acc: 0.874359 | Val Loss: 0.112363, Val Acc: 0.783505\n",
      "Epoch 18845 - Train Loss: 0.084213, Train Acc: 0.874359 | Val Loss: 0.112362, Val Acc: 0.783505\n",
      "Epoch 18846 - Train Loss: 0.084211, Train Acc: 0.874359 | Val Loss: 0.112361, Val Acc: 0.783505\n",
      "Epoch 18847 - Train Loss: 0.084208, Train Acc: 0.874359 | Val Loss: 0.112360, Val Acc: 0.783505\n",
      "Epoch 18848 - Train Loss: 0.084206, Train Acc: 0.874359 | Val Loss: 0.112358, Val Acc: 0.783505\n",
      "Epoch 18849 - Train Loss: 0.084203, Train Acc: 0.874359 | Val Loss: 0.112357, Val Acc: 0.783505\n",
      "Epoch 18850 - Train Loss: 0.084200, Train Acc: 0.874359 | Val Loss: 0.112356, Val Acc: 0.783505\n",
      "Epoch 18851 - Train Loss: 0.084198, Train Acc: 0.874359 | Val Loss: 0.112355, Val Acc: 0.783505\n",
      "Epoch 18852 - Train Loss: 0.084195, Train Acc: 0.874359 | Val Loss: 0.112353, Val Acc: 0.783505\n",
      "Epoch 18853 - Train Loss: 0.084193, Train Acc: 0.874359 | Val Loss: 0.112352, Val Acc: 0.783505\n",
      "Epoch 18854 - Train Loss: 0.084190, Train Acc: 0.874359 | Val Loss: 0.112351, Val Acc: 0.783505\n",
      "Epoch 18855 - Train Loss: 0.084187, Train Acc: 0.874359 | Val Loss: 0.112350, Val Acc: 0.783505\n",
      "Epoch 18856 - Train Loss: 0.084185, Train Acc: 0.874359 | Val Loss: 0.112348, Val Acc: 0.783505\n",
      "Epoch 18857 - Train Loss: 0.084182, Train Acc: 0.874359 | Val Loss: 0.112347, Val Acc: 0.783505\n",
      "Epoch 18858 - Train Loss: 0.084180, Train Acc: 0.874359 | Val Loss: 0.112346, Val Acc: 0.783505\n",
      "Epoch 18859 - Train Loss: 0.084177, Train Acc: 0.874359 | Val Loss: 0.112345, Val Acc: 0.783505\n",
      "Epoch 18860 - Train Loss: 0.084174, Train Acc: 0.874359 | Val Loss: 0.112343, Val Acc: 0.783505\n",
      "Epoch 18861 - Train Loss: 0.084172, Train Acc: 0.874359 | Val Loss: 0.112342, Val Acc: 0.783505\n",
      "Epoch 18862 - Train Loss: 0.084169, Train Acc: 0.874359 | Val Loss: 0.112341, Val Acc: 0.783505\n",
      "Epoch 18863 - Train Loss: 0.084167, Train Acc: 0.874359 | Val Loss: 0.112340, Val Acc: 0.783505\n",
      "Epoch 18864 - Train Loss: 0.084164, Train Acc: 0.874359 | Val Loss: 0.112338, Val Acc: 0.783505\n",
      "Epoch 18865 - Train Loss: 0.084162, Train Acc: 0.874359 | Val Loss: 0.112337, Val Acc: 0.783505\n",
      "Epoch 18866 - Train Loss: 0.084159, Train Acc: 0.874359 | Val Loss: 0.112336, Val Acc: 0.783505\n",
      "Epoch 18867 - Train Loss: 0.084156, Train Acc: 0.874359 | Val Loss: 0.112335, Val Acc: 0.783505\n",
      "Epoch 18868 - Train Loss: 0.084154, Train Acc: 0.874359 | Val Loss: 0.112333, Val Acc: 0.783505\n",
      "Epoch 18869 - Train Loss: 0.084151, Train Acc: 0.874359 | Val Loss: 0.112332, Val Acc: 0.783505\n",
      "Epoch 18870 - Train Loss: 0.084149, Train Acc: 0.874359 | Val Loss: 0.112331, Val Acc: 0.783505\n",
      "Epoch 18871 - Train Loss: 0.084146, Train Acc: 0.874359 | Val Loss: 0.112330, Val Acc: 0.783505\n",
      "Epoch 18872 - Train Loss: 0.084143, Train Acc: 0.874359 | Val Loss: 0.112328, Val Acc: 0.783505\n",
      "Epoch 18873 - Train Loss: 0.084141, Train Acc: 0.874359 | Val Loss: 0.112327, Val Acc: 0.783505\n",
      "Epoch 18874 - Train Loss: 0.084138, Train Acc: 0.874359 | Val Loss: 0.112326, Val Acc: 0.783505\n",
      "Epoch 18875 - Train Loss: 0.084136, Train Acc: 0.874359 | Val Loss: 0.112325, Val Acc: 0.783505\n",
      "Epoch 18876 - Train Loss: 0.084133, Train Acc: 0.874359 | Val Loss: 0.112323, Val Acc: 0.783505\n",
      "Epoch 18877 - Train Loss: 0.084131, Train Acc: 0.874359 | Val Loss: 0.112322, Val Acc: 0.783505\n",
      "Epoch 18878 - Train Loss: 0.084128, Train Acc: 0.874359 | Val Loss: 0.112321, Val Acc: 0.783505\n",
      "Epoch 18879 - Train Loss: 0.084125, Train Acc: 0.874359 | Val Loss: 0.112320, Val Acc: 0.783505\n",
      "Epoch 18880 - Train Loss: 0.084123, Train Acc: 0.874359 | Val Loss: 0.112318, Val Acc: 0.783505\n",
      "Epoch 18881 - Train Loss: 0.084120, Train Acc: 0.874359 | Val Loss: 0.112317, Val Acc: 0.783505\n",
      "Epoch 18882 - Train Loss: 0.084118, Train Acc: 0.874359 | Val Loss: 0.112316, Val Acc: 0.783505\n",
      "Epoch 18883 - Train Loss: 0.084115, Train Acc: 0.874359 | Val Loss: 0.112314, Val Acc: 0.783505\n",
      "Epoch 18884 - Train Loss: 0.084112, Train Acc: 0.874359 | Val Loss: 0.112313, Val Acc: 0.783505\n",
      "Epoch 18885 - Train Loss: 0.084110, Train Acc: 0.874359 | Val Loss: 0.112312, Val Acc: 0.783505\n",
      "Epoch 18886 - Train Loss: 0.084107, Train Acc: 0.874359 | Val Loss: 0.112310, Val Acc: 0.783505\n",
      "Epoch 18887 - Train Loss: 0.084105, Train Acc: 0.874359 | Val Loss: 0.112309, Val Acc: 0.783505\n",
      "Epoch 18888 - Train Loss: 0.084102, Train Acc: 0.874359 | Val Loss: 0.112308, Val Acc: 0.783505\n",
      "Epoch 18889 - Train Loss: 0.084099, Train Acc: 0.874359 | Val Loss: 0.112307, Val Acc: 0.783505\n",
      "Epoch 18890 - Train Loss: 0.084097, Train Acc: 0.874359 | Val Loss: 0.112305, Val Acc: 0.783505\n",
      "Epoch 18891 - Train Loss: 0.084094, Train Acc: 0.874359 | Val Loss: 0.112304, Val Acc: 0.783505\n",
      "Epoch 18892 - Train Loss: 0.084092, Train Acc: 0.874359 | Val Loss: 0.112303, Val Acc: 0.783505\n",
      "Epoch 18893 - Train Loss: 0.084089, Train Acc: 0.874359 | Val Loss: 0.112301, Val Acc: 0.783505\n",
      "Epoch 18894 - Train Loss: 0.084087, Train Acc: 0.874359 | Val Loss: 0.112300, Val Acc: 0.783505\n",
      "Epoch 18895 - Train Loss: 0.084084, Train Acc: 0.874359 | Val Loss: 0.112299, Val Acc: 0.783505\n",
      "Epoch 18896 - Train Loss: 0.084081, Train Acc: 0.874359 | Val Loss: 0.112297, Val Acc: 0.783505\n",
      "Epoch 18897 - Train Loss: 0.084079, Train Acc: 0.874359 | Val Loss: 0.112296, Val Acc: 0.783505\n",
      "Epoch 18898 - Train Loss: 0.084076, Train Acc: 0.874359 | Val Loss: 0.112295, Val Acc: 0.783505\n",
      "Epoch 18899 - Train Loss: 0.084074, Train Acc: 0.874359 | Val Loss: 0.112293, Val Acc: 0.783505\n",
      "Epoch 18900 - Train Loss: 0.084071, Train Acc: 0.874359 | Val Loss: 0.112292, Val Acc: 0.783505\n",
      "Epoch 18901 - Train Loss: 0.084068, Train Acc: 0.874359 | Val Loss: 0.112291, Val Acc: 0.783505\n",
      "Epoch 18902 - Train Loss: 0.084066, Train Acc: 0.874359 | Val Loss: 0.112290, Val Acc: 0.783505\n",
      "Epoch 18903 - Train Loss: 0.084063, Train Acc: 0.874359 | Val Loss: 0.112288, Val Acc: 0.783505\n",
      "Epoch 18904 - Train Loss: 0.084061, Train Acc: 0.874359 | Val Loss: 0.112287, Val Acc: 0.783505\n",
      "Epoch 18905 - Train Loss: 0.084058, Train Acc: 0.874359 | Val Loss: 0.112286, Val Acc: 0.783505\n",
      "Epoch 18906 - Train Loss: 0.084056, Train Acc: 0.874359 | Val Loss: 0.112284, Val Acc: 0.783505\n",
      "Epoch 18907 - Train Loss: 0.084053, Train Acc: 0.874359 | Val Loss: 0.112283, Val Acc: 0.783505\n",
      "Epoch 18908 - Train Loss: 0.084050, Train Acc: 0.874359 | Val Loss: 0.112282, Val Acc: 0.783505\n",
      "Epoch 18909 - Train Loss: 0.084048, Train Acc: 0.874359 | Val Loss: 0.112281, Val Acc: 0.783505\n",
      "Epoch 18910 - Train Loss: 0.084045, Train Acc: 0.874359 | Val Loss: 0.112279, Val Acc: 0.783505\n",
      "Epoch 18911 - Train Loss: 0.084043, Train Acc: 0.874359 | Val Loss: 0.112278, Val Acc: 0.783505\n",
      "Epoch 18912 - Train Loss: 0.084040, Train Acc: 0.874359 | Val Loss: 0.112277, Val Acc: 0.783505\n",
      "Epoch 18913 - Train Loss: 0.084037, Train Acc: 0.874359 | Val Loss: 0.112275, Val Acc: 0.783505\n",
      "Epoch 18914 - Train Loss: 0.084035, Train Acc: 0.874359 | Val Loss: 0.112274, Val Acc: 0.783505\n",
      "Epoch 18915 - Train Loss: 0.084032, Train Acc: 0.874359 | Val Loss: 0.112273, Val Acc: 0.783505\n",
      "Epoch 18916 - Train Loss: 0.084030, Train Acc: 0.874359 | Val Loss: 0.112272, Val Acc: 0.783505\n",
      "Epoch 18917 - Train Loss: 0.084027, Train Acc: 0.874359 | Val Loss: 0.112270, Val Acc: 0.783505\n",
      "Epoch 18918 - Train Loss: 0.084025, Train Acc: 0.874359 | Val Loss: 0.112269, Val Acc: 0.783505\n",
      "Epoch 18919 - Train Loss: 0.084022, Train Acc: 0.874359 | Val Loss: 0.112268, Val Acc: 0.783505\n",
      "Epoch 18920 - Train Loss: 0.084019, Train Acc: 0.874359 | Val Loss: 0.112266, Val Acc: 0.783505\n",
      "Epoch 18921 - Train Loss: 0.084017, Train Acc: 0.874359 | Val Loss: 0.112265, Val Acc: 0.783505\n",
      "Epoch 18922 - Train Loss: 0.084014, Train Acc: 0.874359 | Val Loss: 0.112264, Val Acc: 0.783505\n",
      "Epoch 18923 - Train Loss: 0.084012, Train Acc: 0.874359 | Val Loss: 0.112263, Val Acc: 0.783505\n",
      "Epoch 18924 - Train Loss: 0.084009, Train Acc: 0.874359 | Val Loss: 0.112261, Val Acc: 0.783505\n",
      "Epoch 18925 - Train Loss: 0.084007, Train Acc: 0.874359 | Val Loss: 0.112260, Val Acc: 0.783505\n",
      "Epoch 18926 - Train Loss: 0.084004, Train Acc: 0.874359 | Val Loss: 0.112259, Val Acc: 0.783505\n",
      "Epoch 18927 - Train Loss: 0.084001, Train Acc: 0.874359 | Val Loss: 0.112258, Val Acc: 0.783505\n",
      "Epoch 18928 - Train Loss: 0.083999, Train Acc: 0.874359 | Val Loss: 0.112256, Val Acc: 0.783505\n",
      "Epoch 18929 - Train Loss: 0.083996, Train Acc: 0.874359 | Val Loss: 0.112255, Val Acc: 0.783505\n",
      "Epoch 18930 - Train Loss: 0.083994, Train Acc: 0.874359 | Val Loss: 0.112254, Val Acc: 0.783505\n",
      "Epoch 18931 - Train Loss: 0.083991, Train Acc: 0.874359 | Val Loss: 0.112253, Val Acc: 0.783505\n",
      "Epoch 18932 - Train Loss: 0.083989, Train Acc: 0.874359 | Val Loss: 0.112251, Val Acc: 0.783505\n",
      "Epoch 18933 - Train Loss: 0.083986, Train Acc: 0.874359 | Val Loss: 0.112250, Val Acc: 0.783505\n",
      "Epoch 18934 - Train Loss: 0.083983, Train Acc: 0.874359 | Val Loss: 0.112249, Val Acc: 0.783505\n",
      "Epoch 18935 - Train Loss: 0.083981, Train Acc: 0.874359 | Val Loss: 0.112247, Val Acc: 0.783505\n",
      "Epoch 18936 - Train Loss: 0.083978, Train Acc: 0.874359 | Val Loss: 0.112246, Val Acc: 0.783505\n",
      "Epoch 18937 - Train Loss: 0.083976, Train Acc: 0.874359 | Val Loss: 0.112245, Val Acc: 0.783505\n",
      "Epoch 18938 - Train Loss: 0.083973, Train Acc: 0.874359 | Val Loss: 0.112244, Val Acc: 0.783505\n",
      "Epoch 18939 - Train Loss: 0.083971, Train Acc: 0.874359 | Val Loss: 0.112242, Val Acc: 0.783505\n",
      "Epoch 18940 - Train Loss: 0.083968, Train Acc: 0.874359 | Val Loss: 0.112241, Val Acc: 0.783505\n",
      "Epoch 18941 - Train Loss: 0.083965, Train Acc: 0.874359 | Val Loss: 0.112240, Val Acc: 0.783505\n",
      "Epoch 18942 - Train Loss: 0.083963, Train Acc: 0.874359 | Val Loss: 0.112239, Val Acc: 0.783505\n",
      "Epoch 18943 - Train Loss: 0.083960, Train Acc: 0.874359 | Val Loss: 0.112237, Val Acc: 0.783505\n",
      "Epoch 18944 - Train Loss: 0.083958, Train Acc: 0.874359 | Val Loss: 0.112236, Val Acc: 0.783505\n",
      "Epoch 18945 - Train Loss: 0.083955, Train Acc: 0.874359 | Val Loss: 0.112235, Val Acc: 0.783505\n",
      "Epoch 18946 - Train Loss: 0.083953, Train Acc: 0.874359 | Val Loss: 0.112234, Val Acc: 0.783505\n",
      "Epoch 18947 - Train Loss: 0.083950, Train Acc: 0.874359 | Val Loss: 0.112232, Val Acc: 0.783505\n",
      "Epoch 18948 - Train Loss: 0.083947, Train Acc: 0.874359 | Val Loss: 0.112231, Val Acc: 0.783505\n",
      "Epoch 18949 - Train Loss: 0.083945, Train Acc: 0.874359 | Val Loss: 0.112230, Val Acc: 0.783505\n",
      "Epoch 18950 - Train Loss: 0.083942, Train Acc: 0.874359 | Val Loss: 0.112229, Val Acc: 0.783505\n",
      "Epoch 18951 - Train Loss: 0.083940, Train Acc: 0.874359 | Val Loss: 0.112227, Val Acc: 0.783505\n",
      "Epoch 18952 - Train Loss: 0.083937, Train Acc: 0.874359 | Val Loss: 0.112226, Val Acc: 0.783505\n",
      "Epoch 18953 - Train Loss: 0.083935, Train Acc: 0.874359 | Val Loss: 0.112225, Val Acc: 0.783505\n",
      "Epoch 18954 - Train Loss: 0.083932, Train Acc: 0.874359 | Val Loss: 0.112224, Val Acc: 0.783505\n",
      "Epoch 18955 - Train Loss: 0.083929, Train Acc: 0.874359 | Val Loss: 0.112222, Val Acc: 0.783505\n",
      "Epoch 18956 - Train Loss: 0.083927, Train Acc: 0.874359 | Val Loss: 0.112221, Val Acc: 0.783505\n",
      "Epoch 18957 - Train Loss: 0.083924, Train Acc: 0.874359 | Val Loss: 0.112220, Val Acc: 0.783505\n",
      "Epoch 18958 - Train Loss: 0.083922, Train Acc: 0.874359 | Val Loss: 0.112219, Val Acc: 0.783505\n",
      "Epoch 18959 - Train Loss: 0.083919, Train Acc: 0.874359 | Val Loss: 0.112217, Val Acc: 0.783505\n",
      "Epoch 18960 - Train Loss: 0.083917, Train Acc: 0.874359 | Val Loss: 0.112216, Val Acc: 0.783505\n",
      "Epoch 18961 - Train Loss: 0.083914, Train Acc: 0.874359 | Val Loss: 0.112215, Val Acc: 0.783505\n",
      "Epoch 18962 - Train Loss: 0.083911, Train Acc: 0.874359 | Val Loss: 0.112214, Val Acc: 0.783505\n",
      "Epoch 18963 - Train Loss: 0.083909, Train Acc: 0.874359 | Val Loss: 0.112212, Val Acc: 0.783505\n",
      "Epoch 18964 - Train Loss: 0.083906, Train Acc: 0.874359 | Val Loss: 0.112211, Val Acc: 0.783505\n",
      "Epoch 18965 - Train Loss: 0.083904, Train Acc: 0.874359 | Val Loss: 0.112210, Val Acc: 0.783505\n",
      "Epoch 18966 - Train Loss: 0.083901, Train Acc: 0.874359 | Val Loss: 0.112209, Val Acc: 0.783505\n",
      "Epoch 18967 - Train Loss: 0.083899, Train Acc: 0.874359 | Val Loss: 0.112207, Val Acc: 0.783505\n",
      "Epoch 18968 - Train Loss: 0.083896, Train Acc: 0.874359 | Val Loss: 0.112206, Val Acc: 0.783505\n",
      "Epoch 18969 - Train Loss: 0.083893, Train Acc: 0.874359 | Val Loss: 0.112205, Val Acc: 0.783505\n",
      "Epoch 18970 - Train Loss: 0.083891, Train Acc: 0.874359 | Val Loss: 0.112204, Val Acc: 0.783505\n",
      "Epoch 18971 - Train Loss: 0.083888, Train Acc: 0.874359 | Val Loss: 0.112202, Val Acc: 0.783505\n",
      "Epoch 18972 - Train Loss: 0.083886, Train Acc: 0.874359 | Val Loss: 0.112201, Val Acc: 0.783505\n",
      "Epoch 18973 - Train Loss: 0.083883, Train Acc: 0.874359 | Val Loss: 0.112200, Val Acc: 0.783505\n",
      "Epoch 18974 - Train Loss: 0.083881, Train Acc: 0.874359 | Val Loss: 0.112199, Val Acc: 0.783505\n",
      "Epoch 18975 - Train Loss: 0.083878, Train Acc: 0.874359 | Val Loss: 0.112197, Val Acc: 0.783505\n",
      "Epoch 18976 - Train Loss: 0.083876, Train Acc: 0.874359 | Val Loss: 0.112196, Val Acc: 0.783505\n",
      "Epoch 18977 - Train Loss: 0.083873, Train Acc: 0.874359 | Val Loss: 0.112195, Val Acc: 0.783505\n",
      "Epoch 18978 - Train Loss: 0.083870, Train Acc: 0.874359 | Val Loss: 0.112194, Val Acc: 0.783505\n",
      "Epoch 18979 - Train Loss: 0.083868, Train Acc: 0.874359 | Val Loss: 0.112192, Val Acc: 0.783505\n",
      "Epoch 18980 - Train Loss: 0.083865, Train Acc: 0.874359 | Val Loss: 0.112191, Val Acc: 0.783505\n",
      "Epoch 18981 - Train Loss: 0.083863, Train Acc: 0.874359 | Val Loss: 0.112190, Val Acc: 0.783505\n",
      "Epoch 18982 - Train Loss: 0.083860, Train Acc: 0.874359 | Val Loss: 0.112189, Val Acc: 0.783505\n",
      "Epoch 18983 - Train Loss: 0.083858, Train Acc: 0.874359 | Val Loss: 0.112187, Val Acc: 0.783505\n",
      "Epoch 18984 - Train Loss: 0.083855, Train Acc: 0.874359 | Val Loss: 0.112186, Val Acc: 0.783505\n",
      "Epoch 18985 - Train Loss: 0.083852, Train Acc: 0.874359 | Val Loss: 0.112185, Val Acc: 0.783505\n",
      "Epoch 18986 - Train Loss: 0.083850, Train Acc: 0.874359 | Val Loss: 0.112184, Val Acc: 0.783505\n",
      "Epoch 18987 - Train Loss: 0.083847, Train Acc: 0.874359 | Val Loss: 0.112182, Val Acc: 0.783505\n",
      "Epoch 18988 - Train Loss: 0.083845, Train Acc: 0.874359 | Val Loss: 0.112181, Val Acc: 0.783505\n",
      "Epoch 18989 - Train Loss: 0.083842, Train Acc: 0.874359 | Val Loss: 0.112180, Val Acc: 0.783505\n",
      "Epoch 18990 - Train Loss: 0.083840, Train Acc: 0.874359 | Val Loss: 0.112179, Val Acc: 0.783505\n",
      "Epoch 18991 - Train Loss: 0.083837, Train Acc: 0.874359 | Val Loss: 0.112177, Val Acc: 0.783505\n",
      "Epoch 18992 - Train Loss: 0.083835, Train Acc: 0.874359 | Val Loss: 0.112176, Val Acc: 0.783505\n",
      "Epoch 18993 - Train Loss: 0.083832, Train Acc: 0.874359 | Val Loss: 0.112175, Val Acc: 0.783505\n",
      "Epoch 18994 - Train Loss: 0.083829, Train Acc: 0.874359 | Val Loss: 0.112174, Val Acc: 0.783505\n",
      "Epoch 18995 - Train Loss: 0.083827, Train Acc: 0.874359 | Val Loss: 0.112172, Val Acc: 0.783505\n",
      "Epoch 18996 - Train Loss: 0.083824, Train Acc: 0.874359 | Val Loss: 0.112171, Val Acc: 0.783505\n",
      "Epoch 18997 - Train Loss: 0.083822, Train Acc: 0.874359 | Val Loss: 0.112170, Val Acc: 0.783505\n",
      "Epoch 18998 - Train Loss: 0.083819, Train Acc: 0.874359 | Val Loss: 0.112169, Val Acc: 0.783505\n",
      "Epoch 18999 - Train Loss: 0.083817, Train Acc: 0.874359 | Val Loss: 0.112167, Val Acc: 0.783505\n",
      "Epoch 19000 - Train Loss: 0.083814, Train Acc: 0.874359 | Val Loss: 0.112166, Val Acc: 0.783505\n",
      "Epoch 19001 - Train Loss: 0.083812, Train Acc: 0.874359 | Val Loss: 0.112165, Val Acc: 0.783505\n",
      "Epoch 19002 - Train Loss: 0.083809, Train Acc: 0.874359 | Val Loss: 0.112164, Val Acc: 0.783505\n",
      "Epoch 19003 - Train Loss: 0.083806, Train Acc: 0.874359 | Val Loss: 0.112162, Val Acc: 0.783505\n",
      "Epoch 19004 - Train Loss: 0.083804, Train Acc: 0.874359 | Val Loss: 0.112161, Val Acc: 0.783505\n",
      "Epoch 19005 - Train Loss: 0.083801, Train Acc: 0.874359 | Val Loss: 0.112160, Val Acc: 0.783505\n",
      "Epoch 19006 - Train Loss: 0.083799, Train Acc: 0.874359 | Val Loss: 0.112159, Val Acc: 0.783505\n",
      "Epoch 19007 - Train Loss: 0.083796, Train Acc: 0.874359 | Val Loss: 0.112157, Val Acc: 0.783505\n",
      "Epoch 19008 - Train Loss: 0.083794, Train Acc: 0.874359 | Val Loss: 0.112156, Val Acc: 0.783505\n",
      "Epoch 19009 - Train Loss: 0.083791, Train Acc: 0.874359 | Val Loss: 0.112155, Val Acc: 0.783505\n",
      "Epoch 19010 - Train Loss: 0.083789, Train Acc: 0.874359 | Val Loss: 0.112154, Val Acc: 0.783505\n",
      "Epoch 19011 - Train Loss: 0.083786, Train Acc: 0.874359 | Val Loss: 0.112152, Val Acc: 0.783505\n",
      "Epoch 19012 - Train Loss: 0.083783, Train Acc: 0.874359 | Val Loss: 0.112151, Val Acc: 0.783505\n",
      "Epoch 19013 - Train Loss: 0.083781, Train Acc: 0.874359 | Val Loss: 0.112150, Val Acc: 0.783505\n",
      "Epoch 19014 - Train Loss: 0.083778, Train Acc: 0.874359 | Val Loss: 0.112149, Val Acc: 0.783505\n",
      "Epoch 19015 - Train Loss: 0.083776, Train Acc: 0.874359 | Val Loss: 0.112147, Val Acc: 0.783505\n",
      "Epoch 19016 - Train Loss: 0.083773, Train Acc: 0.874359 | Val Loss: 0.112146, Val Acc: 0.783505\n",
      "Epoch 19017 - Train Loss: 0.083771, Train Acc: 0.874359 | Val Loss: 0.112145, Val Acc: 0.783505\n",
      "Epoch 19018 - Train Loss: 0.083768, Train Acc: 0.874359 | Val Loss: 0.112144, Val Acc: 0.783505\n",
      "Epoch 19019 - Train Loss: 0.083766, Train Acc: 0.874359 | Val Loss: 0.112143, Val Acc: 0.783505\n",
      "Epoch 19020 - Train Loss: 0.083763, Train Acc: 0.874359 | Val Loss: 0.112141, Val Acc: 0.783505\n",
      "Epoch 19021 - Train Loss: 0.083761, Train Acc: 0.874359 | Val Loss: 0.112140, Val Acc: 0.783505\n",
      "Epoch 19022 - Train Loss: 0.083758, Train Acc: 0.874359 | Val Loss: 0.112139, Val Acc: 0.783505\n",
      "Epoch 19023 - Train Loss: 0.083755, Train Acc: 0.874359 | Val Loss: 0.112138, Val Acc: 0.783505\n",
      "Epoch 19024 - Train Loss: 0.083753, Train Acc: 0.874359 | Val Loss: 0.112136, Val Acc: 0.783505\n",
      "Epoch 19025 - Train Loss: 0.083750, Train Acc: 0.874359 | Val Loss: 0.112135, Val Acc: 0.783505\n",
      "Epoch 19026 - Train Loss: 0.083748, Train Acc: 0.874359 | Val Loss: 0.112134, Val Acc: 0.783505\n",
      "Epoch 19027 - Train Loss: 0.083745, Train Acc: 0.874359 | Val Loss: 0.112133, Val Acc: 0.783505\n",
      "Epoch 19028 - Train Loss: 0.083743, Train Acc: 0.874359 | Val Loss: 0.112131, Val Acc: 0.783505\n",
      "Epoch 19029 - Train Loss: 0.083740, Train Acc: 0.874359 | Val Loss: 0.112130, Val Acc: 0.783505\n",
      "Epoch 19030 - Train Loss: 0.083738, Train Acc: 0.874359 | Val Loss: 0.112129, Val Acc: 0.783505\n",
      "Epoch 19031 - Train Loss: 0.083735, Train Acc: 0.874359 | Val Loss: 0.112128, Val Acc: 0.783505\n",
      "Epoch 19032 - Train Loss: 0.083732, Train Acc: 0.874359 | Val Loss: 0.112126, Val Acc: 0.783505\n",
      "Epoch 19033 - Train Loss: 0.083730, Train Acc: 0.874359 | Val Loss: 0.112125, Val Acc: 0.783505\n",
      "Epoch 19034 - Train Loss: 0.083727, Train Acc: 0.874359 | Val Loss: 0.112124, Val Acc: 0.783505\n",
      "Epoch 19035 - Train Loss: 0.083725, Train Acc: 0.874359 | Val Loss: 0.112123, Val Acc: 0.783505\n",
      "Epoch 19036 - Train Loss: 0.083722, Train Acc: 0.874359 | Val Loss: 0.112121, Val Acc: 0.783505\n",
      "Epoch 19037 - Train Loss: 0.083720, Train Acc: 0.874359 | Val Loss: 0.112120, Val Acc: 0.783505\n",
      "Epoch 19038 - Train Loss: 0.083717, Train Acc: 0.874359 | Val Loss: 0.112119, Val Acc: 0.783505\n",
      "Epoch 19039 - Train Loss: 0.083715, Train Acc: 0.874359 | Val Loss: 0.112118, Val Acc: 0.783505\n",
      "Epoch 19040 - Train Loss: 0.083712, Train Acc: 0.874359 | Val Loss: 0.112117, Val Acc: 0.783505\n",
      "Epoch 19041 - Train Loss: 0.083710, Train Acc: 0.874359 | Val Loss: 0.112115, Val Acc: 0.783505\n",
      "Epoch 19042 - Train Loss: 0.083707, Train Acc: 0.874359 | Val Loss: 0.112114, Val Acc: 0.783505\n",
      "Epoch 19043 - Train Loss: 0.083704, Train Acc: 0.874359 | Val Loss: 0.112113, Val Acc: 0.783505\n",
      "Epoch 19044 - Train Loss: 0.083702, Train Acc: 0.874359 | Val Loss: 0.112112, Val Acc: 0.783505\n",
      "Epoch 19045 - Train Loss: 0.083699, Train Acc: 0.874359 | Val Loss: 0.112110, Val Acc: 0.783505\n",
      "Epoch 19046 - Train Loss: 0.083697, Train Acc: 0.874359 | Val Loss: 0.112109, Val Acc: 0.783505\n",
      "Epoch 19047 - Train Loss: 0.083694, Train Acc: 0.874359 | Val Loss: 0.112108, Val Acc: 0.783505\n",
      "Epoch 19048 - Train Loss: 0.083692, Train Acc: 0.874359 | Val Loss: 0.112107, Val Acc: 0.783505\n",
      "Epoch 19049 - Train Loss: 0.083689, Train Acc: 0.874359 | Val Loss: 0.112105, Val Acc: 0.783505\n",
      "Epoch 19050 - Train Loss: 0.083687, Train Acc: 0.874359 | Val Loss: 0.112104, Val Acc: 0.783505\n",
      "Epoch 19051 - Train Loss: 0.083684, Train Acc: 0.874359 | Val Loss: 0.112103, Val Acc: 0.783505\n",
      "Epoch 19052 - Train Loss: 0.083682, Train Acc: 0.874359 | Val Loss: 0.112102, Val Acc: 0.783505\n",
      "Epoch 19053 - Train Loss: 0.083679, Train Acc: 0.874359 | Val Loss: 0.112100, Val Acc: 0.783505\n",
      "Epoch 19054 - Train Loss: 0.083676, Train Acc: 0.874359 | Val Loss: 0.112099, Val Acc: 0.783505\n",
      "Epoch 19055 - Train Loss: 0.083674, Train Acc: 0.874359 | Val Loss: 0.112098, Val Acc: 0.783505\n",
      "Epoch 19056 - Train Loss: 0.083671, Train Acc: 0.874359 | Val Loss: 0.112097, Val Acc: 0.783505\n",
      "Epoch 19057 - Train Loss: 0.083669, Train Acc: 0.874359 | Val Loss: 0.112096, Val Acc: 0.783505\n",
      "Epoch 19058 - Train Loss: 0.083666, Train Acc: 0.874359 | Val Loss: 0.112094, Val Acc: 0.783505\n",
      "Epoch 19059 - Train Loss: 0.083664, Train Acc: 0.874359 | Val Loss: 0.112093, Val Acc: 0.783505\n",
      "Epoch 19060 - Train Loss: 0.083661, Train Acc: 0.874359 | Val Loss: 0.112092, Val Acc: 0.783505\n",
      "Epoch 19061 - Train Loss: 0.083659, Train Acc: 0.874359 | Val Loss: 0.112091, Val Acc: 0.783505\n",
      "Epoch 19062 - Train Loss: 0.083656, Train Acc: 0.874359 | Val Loss: 0.112089, Val Acc: 0.783505\n",
      "Epoch 19063 - Train Loss: 0.083654, Train Acc: 0.874359 | Val Loss: 0.112088, Val Acc: 0.783505\n",
      "Epoch 19064 - Train Loss: 0.083651, Train Acc: 0.874359 | Val Loss: 0.112087, Val Acc: 0.783505\n",
      "Epoch 19065 - Train Loss: 0.083649, Train Acc: 0.874359 | Val Loss: 0.112086, Val Acc: 0.783505\n",
      "Epoch 19066 - Train Loss: 0.083646, Train Acc: 0.874359 | Val Loss: 0.112085, Val Acc: 0.783505\n",
      "Epoch 19067 - Train Loss: 0.083643, Train Acc: 0.874359 | Val Loss: 0.112083, Val Acc: 0.783505\n",
      "Epoch 19068 - Train Loss: 0.083641, Train Acc: 0.874359 | Val Loss: 0.112082, Val Acc: 0.783505\n",
      "Epoch 19069 - Train Loss: 0.083638, Train Acc: 0.874359 | Val Loss: 0.112081, Val Acc: 0.783505\n",
      "Epoch 19070 - Train Loss: 0.083636, Train Acc: 0.874359 | Val Loss: 0.112080, Val Acc: 0.783505\n",
      "Epoch 19071 - Train Loss: 0.083633, Train Acc: 0.874359 | Val Loss: 0.112078, Val Acc: 0.783505\n",
      "Epoch 19072 - Train Loss: 0.083631, Train Acc: 0.874359 | Val Loss: 0.112077, Val Acc: 0.783505\n",
      "Epoch 19073 - Train Loss: 0.083628, Train Acc: 0.874359 | Val Loss: 0.112076, Val Acc: 0.783505\n",
      "Epoch 19074 - Train Loss: 0.083626, Train Acc: 0.874359 | Val Loss: 0.112075, Val Acc: 0.783505\n",
      "Epoch 19075 - Train Loss: 0.083623, Train Acc: 0.874359 | Val Loss: 0.112073, Val Acc: 0.783505\n",
      "Epoch 19076 - Train Loss: 0.083621, Train Acc: 0.874359 | Val Loss: 0.112072, Val Acc: 0.783505\n",
      "Epoch 19077 - Train Loss: 0.083618, Train Acc: 0.874359 | Val Loss: 0.112071, Val Acc: 0.783505\n",
      "Epoch 19078 - Train Loss: 0.083616, Train Acc: 0.874359 | Val Loss: 0.112070, Val Acc: 0.783505\n",
      "Epoch 19079 - Train Loss: 0.083613, Train Acc: 0.874359 | Val Loss: 0.112069, Val Acc: 0.783505\n",
      "Epoch 19080 - Train Loss: 0.083611, Train Acc: 0.874359 | Val Loss: 0.112067, Val Acc: 0.783505\n",
      "Epoch 19081 - Train Loss: 0.083608, Train Acc: 0.874359 | Val Loss: 0.112066, Val Acc: 0.783505\n",
      "Epoch 19082 - Train Loss: 0.083605, Train Acc: 0.874359 | Val Loss: 0.112065, Val Acc: 0.783505\n",
      "Epoch 19083 - Train Loss: 0.083603, Train Acc: 0.874359 | Val Loss: 0.112064, Val Acc: 0.783505\n",
      "Epoch 19084 - Train Loss: 0.083600, Train Acc: 0.874359 | Val Loss: 0.112062, Val Acc: 0.783505\n",
      "Epoch 19085 - Train Loss: 0.083598, Train Acc: 0.874359 | Val Loss: 0.112061, Val Acc: 0.783505\n",
      "Epoch 19086 - Train Loss: 0.083595, Train Acc: 0.874359 | Val Loss: 0.112060, Val Acc: 0.783505\n",
      "Epoch 19087 - Train Loss: 0.083593, Train Acc: 0.874359 | Val Loss: 0.112059, Val Acc: 0.783505\n",
      "Epoch 19088 - Train Loss: 0.083590, Train Acc: 0.874359 | Val Loss: 0.112058, Val Acc: 0.783505\n",
      "Epoch 19089 - Train Loss: 0.083588, Train Acc: 0.874359 | Val Loss: 0.112056, Val Acc: 0.783505\n",
      "Epoch 19090 - Train Loss: 0.083585, Train Acc: 0.874359 | Val Loss: 0.112055, Val Acc: 0.783505\n",
      "Epoch 19091 - Train Loss: 0.083583, Train Acc: 0.874359 | Val Loss: 0.112054, Val Acc: 0.783505\n",
      "Epoch 19092 - Train Loss: 0.083580, Train Acc: 0.874359 | Val Loss: 0.112053, Val Acc: 0.783505\n",
      "Epoch 19093 - Train Loss: 0.083578, Train Acc: 0.874359 | Val Loss: 0.112051, Val Acc: 0.783505\n",
      "Epoch 19094 - Train Loss: 0.083575, Train Acc: 0.874359 | Val Loss: 0.112050, Val Acc: 0.783505\n",
      "Epoch 19095 - Train Loss: 0.083573, Train Acc: 0.874359 | Val Loss: 0.112049, Val Acc: 0.783505\n",
      "Epoch 19096 - Train Loss: 0.083570, Train Acc: 0.874359 | Val Loss: 0.112048, Val Acc: 0.783505\n",
      "Epoch 19097 - Train Loss: 0.083567, Train Acc: 0.874359 | Val Loss: 0.112047, Val Acc: 0.783505\n",
      "Epoch 19098 - Train Loss: 0.083565, Train Acc: 0.874359 | Val Loss: 0.112045, Val Acc: 0.783505\n",
      "Epoch 19099 - Train Loss: 0.083562, Train Acc: 0.874359 | Val Loss: 0.112044, Val Acc: 0.783505\n",
      "Epoch 19100 - Train Loss: 0.083560, Train Acc: 0.874359 | Val Loss: 0.112043, Val Acc: 0.783505\n",
      "Epoch 19101 - Train Loss: 0.083557, Train Acc: 0.874359 | Val Loss: 0.112042, Val Acc: 0.783505\n",
      "Epoch 19102 - Train Loss: 0.083555, Train Acc: 0.874359 | Val Loss: 0.112041, Val Acc: 0.783505\n",
      "Epoch 19103 - Train Loss: 0.083552, Train Acc: 0.874359 | Val Loss: 0.112039, Val Acc: 0.783505\n",
      "Epoch 19104 - Train Loss: 0.083550, Train Acc: 0.874359 | Val Loss: 0.112038, Val Acc: 0.783505\n",
      "Epoch 19105 - Train Loss: 0.083547, Train Acc: 0.874359 | Val Loss: 0.112037, Val Acc: 0.783505\n",
      "Epoch 19106 - Train Loss: 0.083545, Train Acc: 0.874359 | Val Loss: 0.112036, Val Acc: 0.783505\n",
      "Epoch 19107 - Train Loss: 0.083542, Train Acc: 0.874359 | Val Loss: 0.112035, Val Acc: 0.783505\n",
      "Epoch 19108 - Train Loss: 0.083540, Train Acc: 0.874359 | Val Loss: 0.112034, Val Acc: 0.783505\n",
      "Epoch 19109 - Train Loss: 0.083537, Train Acc: 0.874359 | Val Loss: 0.112032, Val Acc: 0.783505\n",
      "Epoch 19110 - Train Loss: 0.083535, Train Acc: 0.874359 | Val Loss: 0.112031, Val Acc: 0.783505\n",
      "Epoch 19111 - Train Loss: 0.083532, Train Acc: 0.874359 | Val Loss: 0.112030, Val Acc: 0.783505\n",
      "Epoch 19112 - Train Loss: 0.083530, Train Acc: 0.874359 | Val Loss: 0.112029, Val Acc: 0.783505\n",
      "Epoch 19113 - Train Loss: 0.083527, Train Acc: 0.874359 | Val Loss: 0.112028, Val Acc: 0.783505\n",
      "Epoch 19114 - Train Loss: 0.083525, Train Acc: 0.874359 | Val Loss: 0.112027, Val Acc: 0.783505\n",
      "Epoch 19115 - Train Loss: 0.083522, Train Acc: 0.874359 | Val Loss: 0.112025, Val Acc: 0.783505\n",
      "Epoch 19116 - Train Loss: 0.083519, Train Acc: 0.874359 | Val Loss: 0.112024, Val Acc: 0.783505\n",
      "Epoch 19117 - Train Loss: 0.083517, Train Acc: 0.874359 | Val Loss: 0.112023, Val Acc: 0.783505\n",
      "Epoch 19118 - Train Loss: 0.083514, Train Acc: 0.874359 | Val Loss: 0.112022, Val Acc: 0.783505\n",
      "Epoch 19119 - Train Loss: 0.083512, Train Acc: 0.874359 | Val Loss: 0.112021, Val Acc: 0.783505\n",
      "Epoch 19120 - Train Loss: 0.083509, Train Acc: 0.874359 | Val Loss: 0.112020, Val Acc: 0.783505\n",
      "Epoch 19121 - Train Loss: 0.083507, Train Acc: 0.874359 | Val Loss: 0.112018, Val Acc: 0.783505\n",
      "Epoch 19122 - Train Loss: 0.083504, Train Acc: 0.874359 | Val Loss: 0.112017, Val Acc: 0.783505\n",
      "Epoch 19123 - Train Loss: 0.083502, Train Acc: 0.874359 | Val Loss: 0.112016, Val Acc: 0.783505\n",
      "Epoch 19124 - Train Loss: 0.083499, Train Acc: 0.874359 | Val Loss: 0.112015, Val Acc: 0.783505\n",
      "Epoch 19125 - Train Loss: 0.083497, Train Acc: 0.874359 | Val Loss: 0.112014, Val Acc: 0.783505\n",
      "Epoch 19126 - Train Loss: 0.083494, Train Acc: 0.874359 | Val Loss: 0.112012, Val Acc: 0.783505\n",
      "Epoch 19127 - Train Loss: 0.083492, Train Acc: 0.874359 | Val Loss: 0.112011, Val Acc: 0.783505\n",
      "Epoch 19128 - Train Loss: 0.083489, Train Acc: 0.874359 | Val Loss: 0.112010, Val Acc: 0.783505\n",
      "Epoch 19129 - Train Loss: 0.083487, Train Acc: 0.874359 | Val Loss: 0.112009, Val Acc: 0.783505\n",
      "Epoch 19130 - Train Loss: 0.083484, Train Acc: 0.874359 | Val Loss: 0.112008, Val Acc: 0.783505\n",
      "Epoch 19131 - Train Loss: 0.083482, Train Acc: 0.874359 | Val Loss: 0.112007, Val Acc: 0.783505\n",
      "Epoch 19132 - Train Loss: 0.083479, Train Acc: 0.874359 | Val Loss: 0.112005, Val Acc: 0.783505\n",
      "Epoch 19133 - Train Loss: 0.083477, Train Acc: 0.874359 | Val Loss: 0.112004, Val Acc: 0.783505\n",
      "Epoch 19134 - Train Loss: 0.083474, Train Acc: 0.874359 | Val Loss: 0.112003, Val Acc: 0.783505\n",
      "Epoch 19135 - Train Loss: 0.083472, Train Acc: 0.874359 | Val Loss: 0.112002, Val Acc: 0.783505\n",
      "Epoch 19136 - Train Loss: 0.083469, Train Acc: 0.874359 | Val Loss: 0.112001, Val Acc: 0.783505\n",
      "Epoch 19137 - Train Loss: 0.083466, Train Acc: 0.874359 | Val Loss: 0.112000, Val Acc: 0.783505\n",
      "Epoch 19138 - Train Loss: 0.083464, Train Acc: 0.874359 | Val Loss: 0.111998, Val Acc: 0.783505\n",
      "Epoch 19139 - Train Loss: 0.083461, Train Acc: 0.874359 | Val Loss: 0.111997, Val Acc: 0.783505\n",
      "Epoch 19140 - Train Loss: 0.083459, Train Acc: 0.874359 | Val Loss: 0.111996, Val Acc: 0.783505\n",
      "Epoch 19141 - Train Loss: 0.083456, Train Acc: 0.874359 | Val Loss: 0.111995, Val Acc: 0.783505\n",
      "Epoch 19142 - Train Loss: 0.083454, Train Acc: 0.874359 | Val Loss: 0.111994, Val Acc: 0.783505\n",
      "Epoch 19143 - Train Loss: 0.083451, Train Acc: 0.874359 | Val Loss: 0.111993, Val Acc: 0.783505\n",
      "Epoch 19144 - Train Loss: 0.083449, Train Acc: 0.874359 | Val Loss: 0.111991, Val Acc: 0.783505\n",
      "Epoch 19145 - Train Loss: 0.083446, Train Acc: 0.874359 | Val Loss: 0.111990, Val Acc: 0.783505\n",
      "Epoch 19146 - Train Loss: 0.083444, Train Acc: 0.874359 | Val Loss: 0.111989, Val Acc: 0.783505\n",
      "Epoch 19147 - Train Loss: 0.083441, Train Acc: 0.874359 | Val Loss: 0.111988, Val Acc: 0.783505\n",
      "Epoch 19148 - Train Loss: 0.083439, Train Acc: 0.874359 | Val Loss: 0.111987, Val Acc: 0.783505\n",
      "Epoch 19149 - Train Loss: 0.083436, Train Acc: 0.874359 | Val Loss: 0.111986, Val Acc: 0.783505\n",
      "Epoch 19150 - Train Loss: 0.083434, Train Acc: 0.874359 | Val Loss: 0.111984, Val Acc: 0.783505\n",
      "Epoch 19151 - Train Loss: 0.083431, Train Acc: 0.874359 | Val Loss: 0.111983, Val Acc: 0.783505\n",
      "Epoch 19152 - Train Loss: 0.083429, Train Acc: 0.874359 | Val Loss: 0.111982, Val Acc: 0.783505\n",
      "Epoch 19153 - Train Loss: 0.083426, Train Acc: 0.874359 | Val Loss: 0.111981, Val Acc: 0.783505\n",
      "Epoch 19154 - Train Loss: 0.083424, Train Acc: 0.874359 | Val Loss: 0.111980, Val Acc: 0.783505\n",
      "Epoch 19155 - Train Loss: 0.083421, Train Acc: 0.874359 | Val Loss: 0.111979, Val Acc: 0.783505\n",
      "Epoch 19156 - Train Loss: 0.083419, Train Acc: 0.874359 | Val Loss: 0.111978, Val Acc: 0.783505\n",
      "Epoch 19157 - Train Loss: 0.083416, Train Acc: 0.874359 | Val Loss: 0.111976, Val Acc: 0.783505\n",
      "Epoch 19158 - Train Loss: 0.083414, Train Acc: 0.874359 | Val Loss: 0.111975, Val Acc: 0.783505\n",
      "Epoch 19159 - Train Loss: 0.083411, Train Acc: 0.874359 | Val Loss: 0.111974, Val Acc: 0.783505\n",
      "Epoch 19160 - Train Loss: 0.083409, Train Acc: 0.874359 | Val Loss: 0.111973, Val Acc: 0.783505\n",
      "Epoch 19161 - Train Loss: 0.083406, Train Acc: 0.874359 | Val Loss: 0.111972, Val Acc: 0.783505\n",
      "Epoch 19162 - Train Loss: 0.083404, Train Acc: 0.874359 | Val Loss: 0.111971, Val Acc: 0.783505\n",
      "Epoch 19163 - Train Loss: 0.083401, Train Acc: 0.874359 | Val Loss: 0.111969, Val Acc: 0.783505\n",
      "Epoch 19164 - Train Loss: 0.083399, Train Acc: 0.874359 | Val Loss: 0.111968, Val Acc: 0.783505\n",
      "Epoch 19165 - Train Loss: 0.083396, Train Acc: 0.874359 | Val Loss: 0.111967, Val Acc: 0.783505\n",
      "Epoch 19166 - Train Loss: 0.083394, Train Acc: 0.874359 | Val Loss: 0.111966, Val Acc: 0.783505\n",
      "Epoch 19167 - Train Loss: 0.083391, Train Acc: 0.874359 | Val Loss: 0.111965, Val Acc: 0.783505\n",
      "Epoch 19168 - Train Loss: 0.083389, Train Acc: 0.874359 | Val Loss: 0.111964, Val Acc: 0.783505\n",
      "Epoch 19169 - Train Loss: 0.083386, Train Acc: 0.874359 | Val Loss: 0.111962, Val Acc: 0.783505\n",
      "Epoch 19170 - Train Loss: 0.083384, Train Acc: 0.874359 | Val Loss: 0.111961, Val Acc: 0.783505\n",
      "Epoch 19171 - Train Loss: 0.083381, Train Acc: 0.874359 | Val Loss: 0.111960, Val Acc: 0.783505\n",
      "Epoch 19172 - Train Loss: 0.083378, Train Acc: 0.874359 | Val Loss: 0.111959, Val Acc: 0.783505\n",
      "Epoch 19173 - Train Loss: 0.083376, Train Acc: 0.874359 | Val Loss: 0.111958, Val Acc: 0.783505\n",
      "Epoch 19174 - Train Loss: 0.083373, Train Acc: 0.874359 | Val Loss: 0.111957, Val Acc: 0.783505\n",
      "Epoch 19175 - Train Loss: 0.083371, Train Acc: 0.874359 | Val Loss: 0.111955, Val Acc: 0.783505\n",
      "Epoch 19176 - Train Loss: 0.083368, Train Acc: 0.874359 | Val Loss: 0.111954, Val Acc: 0.783505\n",
      "Epoch 19177 - Train Loss: 0.083366, Train Acc: 0.874359 | Val Loss: 0.111953, Val Acc: 0.783505\n",
      "Epoch 19178 - Train Loss: 0.083363, Train Acc: 0.874359 | Val Loss: 0.111952, Val Acc: 0.783505\n",
      "Epoch 19179 - Train Loss: 0.083361, Train Acc: 0.874359 | Val Loss: 0.111951, Val Acc: 0.783505\n",
      "Epoch 19180 - Train Loss: 0.083358, Train Acc: 0.874359 | Val Loss: 0.111950, Val Acc: 0.783505\n",
      "Epoch 19181 - Train Loss: 0.083356, Train Acc: 0.874359 | Val Loss: 0.111949, Val Acc: 0.783505\n",
      "Epoch 19182 - Train Loss: 0.083353, Train Acc: 0.874359 | Val Loss: 0.111947, Val Acc: 0.783505\n",
      "Epoch 19183 - Train Loss: 0.083351, Train Acc: 0.874359 | Val Loss: 0.111946, Val Acc: 0.783505\n",
      "Epoch 19184 - Train Loss: 0.083348, Train Acc: 0.874359 | Val Loss: 0.111945, Val Acc: 0.783505\n",
      "Epoch 19185 - Train Loss: 0.083346, Train Acc: 0.874359 | Val Loss: 0.111944, Val Acc: 0.783505\n",
      "Epoch 19186 - Train Loss: 0.083343, Train Acc: 0.874359 | Val Loss: 0.111943, Val Acc: 0.783505\n",
      "Epoch 19187 - Train Loss: 0.083341, Train Acc: 0.874359 | Val Loss: 0.111942, Val Acc: 0.783505\n",
      "Epoch 19188 - Train Loss: 0.083338, Train Acc: 0.874359 | Val Loss: 0.111940, Val Acc: 0.783505\n",
      "Epoch 19189 - Train Loss: 0.083336, Train Acc: 0.874359 | Val Loss: 0.111939, Val Acc: 0.783505\n",
      "Epoch 19190 - Train Loss: 0.083333, Train Acc: 0.874359 | Val Loss: 0.111938, Val Acc: 0.783505\n",
      "Epoch 19191 - Train Loss: 0.083331, Train Acc: 0.874359 | Val Loss: 0.111937, Val Acc: 0.783505\n",
      "Epoch 19192 - Train Loss: 0.083328, Train Acc: 0.874359 | Val Loss: 0.111936, Val Acc: 0.783505\n",
      "Epoch 19193 - Train Loss: 0.083326, Train Acc: 0.874359 | Val Loss: 0.111935, Val Acc: 0.783505\n",
      "Epoch 19194 - Train Loss: 0.083323, Train Acc: 0.874359 | Val Loss: 0.111933, Val Acc: 0.783505\n",
      "Epoch 19195 - Train Loss: 0.083321, Train Acc: 0.874359 | Val Loss: 0.111932, Val Acc: 0.783505\n",
      "Epoch 19196 - Train Loss: 0.083318, Train Acc: 0.874359 | Val Loss: 0.111931, Val Acc: 0.783505\n",
      "Epoch 19197 - Train Loss: 0.083316, Train Acc: 0.874359 | Val Loss: 0.111930, Val Acc: 0.783505\n",
      "Epoch 19198 - Train Loss: 0.083313, Train Acc: 0.874359 | Val Loss: 0.111929, Val Acc: 0.783505\n",
      "Epoch 19199 - Train Loss: 0.083311, Train Acc: 0.874359 | Val Loss: 0.111928, Val Acc: 0.783505\n",
      "Epoch 19200 - Train Loss: 0.083308, Train Acc: 0.874359 | Val Loss: 0.111927, Val Acc: 0.783505\n",
      "Epoch 19201 - Train Loss: 0.083306, Train Acc: 0.874359 | Val Loss: 0.111925, Val Acc: 0.783505\n",
      "Epoch 19202 - Train Loss: 0.083303, Train Acc: 0.874359 | Val Loss: 0.111924, Val Acc: 0.783505\n",
      "Epoch 19203 - Train Loss: 0.083301, Train Acc: 0.874359 | Val Loss: 0.111923, Val Acc: 0.783505\n",
      "Epoch 19204 - Train Loss: 0.083298, Train Acc: 0.874359 | Val Loss: 0.111922, Val Acc: 0.783505\n",
      "Epoch 19205 - Train Loss: 0.083296, Train Acc: 0.874359 | Val Loss: 0.111921, Val Acc: 0.783505\n",
      "Epoch 19206 - Train Loss: 0.083293, Train Acc: 0.874359 | Val Loss: 0.111920, Val Acc: 0.783505\n",
      "Epoch 19207 - Train Loss: 0.083291, Train Acc: 0.874359 | Val Loss: 0.111919, Val Acc: 0.783505\n",
      "Epoch 19208 - Train Loss: 0.083288, Train Acc: 0.874359 | Val Loss: 0.111917, Val Acc: 0.783505\n",
      "Epoch 19209 - Train Loss: 0.083286, Train Acc: 0.874359 | Val Loss: 0.111916, Val Acc: 0.783505\n",
      "Epoch 19210 - Train Loss: 0.083283, Train Acc: 0.874359 | Val Loss: 0.111915, Val Acc: 0.783505\n",
      "Epoch 19211 - Train Loss: 0.083281, Train Acc: 0.874359 | Val Loss: 0.111914, Val Acc: 0.783505\n",
      "Epoch 19212 - Train Loss: 0.083278, Train Acc: 0.874359 | Val Loss: 0.111913, Val Acc: 0.783505\n",
      "Epoch 19213 - Train Loss: 0.083276, Train Acc: 0.874359 | Val Loss: 0.111912, Val Acc: 0.783505\n",
      "Epoch 19214 - Train Loss: 0.083273, Train Acc: 0.874359 | Val Loss: 0.111910, Val Acc: 0.783505\n",
      "Epoch 19215 - Train Loss: 0.083271, Train Acc: 0.874359 | Val Loss: 0.111909, Val Acc: 0.783505\n",
      "Epoch 19216 - Train Loss: 0.083268, Train Acc: 0.874359 | Val Loss: 0.111908, Val Acc: 0.783505\n",
      "Epoch 19217 - Train Loss: 0.083266, Train Acc: 0.874359 | Val Loss: 0.111907, Val Acc: 0.783505\n",
      "Epoch 19218 - Train Loss: 0.083263, Train Acc: 0.874359 | Val Loss: 0.111906, Val Acc: 0.783505\n",
      "Epoch 19219 - Train Loss: 0.083261, Train Acc: 0.874359 | Val Loss: 0.111905, Val Acc: 0.783505\n",
      "Epoch 19220 - Train Loss: 0.083258, Train Acc: 0.874359 | Val Loss: 0.111904, Val Acc: 0.783505\n",
      "Epoch 19221 - Train Loss: 0.083256, Train Acc: 0.874359 | Val Loss: 0.111902, Val Acc: 0.783505\n",
      "Epoch 19222 - Train Loss: 0.083253, Train Acc: 0.874359 | Val Loss: 0.111901, Val Acc: 0.783505\n",
      "Epoch 19223 - Train Loss: 0.083251, Train Acc: 0.874359 | Val Loss: 0.111900, Val Acc: 0.783505\n",
      "Epoch 19224 - Train Loss: 0.083248, Train Acc: 0.874359 | Val Loss: 0.111899, Val Acc: 0.783505\n",
      "Epoch 19225 - Train Loss: 0.083246, Train Acc: 0.874359 | Val Loss: 0.111898, Val Acc: 0.783505\n",
      "Epoch 19226 - Train Loss: 0.083243, Train Acc: 0.874359 | Val Loss: 0.111897, Val Acc: 0.783505\n",
      "Epoch 19227 - Train Loss: 0.083241, Train Acc: 0.874359 | Val Loss: 0.111896, Val Acc: 0.783505\n",
      "Epoch 19228 - Train Loss: 0.083238, Train Acc: 0.874359 | Val Loss: 0.111894, Val Acc: 0.783505\n",
      "Epoch 19229 - Train Loss: 0.083236, Train Acc: 0.874359 | Val Loss: 0.111893, Val Acc: 0.783505\n",
      "Epoch 19230 - Train Loss: 0.083233, Train Acc: 0.874359 | Val Loss: 0.111892, Val Acc: 0.783505\n",
      "Epoch 19231 - Train Loss: 0.083231, Train Acc: 0.874359 | Val Loss: 0.111891, Val Acc: 0.783505\n",
      "Epoch 19232 - Train Loss: 0.083228, Train Acc: 0.874359 | Val Loss: 0.111890, Val Acc: 0.783505\n",
      "Epoch 19233 - Train Loss: 0.083226, Train Acc: 0.874359 | Val Loss: 0.111889, Val Acc: 0.783505\n",
      "Epoch 19234 - Train Loss: 0.083223, Train Acc: 0.874359 | Val Loss: 0.111888, Val Acc: 0.783505\n",
      "Epoch 19235 - Train Loss: 0.083221, Train Acc: 0.874359 | Val Loss: 0.111886, Val Acc: 0.783505\n",
      "Epoch 19236 - Train Loss: 0.083218, Train Acc: 0.874359 | Val Loss: 0.111885, Val Acc: 0.783505\n",
      "Epoch 19237 - Train Loss: 0.083216, Train Acc: 0.874359 | Val Loss: 0.111884, Val Acc: 0.783505\n",
      "Epoch 19238 - Train Loss: 0.083213, Train Acc: 0.874359 | Val Loss: 0.111883, Val Acc: 0.783505\n",
      "Epoch 19239 - Train Loss: 0.083211, Train Acc: 0.874359 | Val Loss: 0.111882, Val Acc: 0.783505\n",
      "Epoch 19240 - Train Loss: 0.083208, Train Acc: 0.874359 | Val Loss: 0.111881, Val Acc: 0.783505\n",
      "Epoch 19241 - Train Loss: 0.083206, Train Acc: 0.874359 | Val Loss: 0.111880, Val Acc: 0.783505\n",
      "Epoch 19242 - Train Loss: 0.083203, Train Acc: 0.874359 | Val Loss: 0.111878, Val Acc: 0.783505\n",
      "Epoch 19243 - Train Loss: 0.083201, Train Acc: 0.874359 | Val Loss: 0.111877, Val Acc: 0.783505\n",
      "Epoch 19244 - Train Loss: 0.083198, Train Acc: 0.874359 | Val Loss: 0.111876, Val Acc: 0.783505\n",
      "Epoch 19245 - Train Loss: 0.083196, Train Acc: 0.874359 | Val Loss: 0.111875, Val Acc: 0.783505\n",
      "Epoch 19246 - Train Loss: 0.083194, Train Acc: 0.874359 | Val Loss: 0.111874, Val Acc: 0.783505\n",
      "Epoch 19247 - Train Loss: 0.083191, Train Acc: 0.874359 | Val Loss: 0.111873, Val Acc: 0.783505\n",
      "Epoch 19248 - Train Loss: 0.083189, Train Acc: 0.874359 | Val Loss: 0.111872, Val Acc: 0.783505\n",
      "Epoch 19249 - Train Loss: 0.083186, Train Acc: 0.874359 | Val Loss: 0.111870, Val Acc: 0.783505\n",
      "Epoch 19250 - Train Loss: 0.083184, Train Acc: 0.874359 | Val Loss: 0.111869, Val Acc: 0.783505\n",
      "Epoch 19251 - Train Loss: 0.083181, Train Acc: 0.874359 | Val Loss: 0.111868, Val Acc: 0.783505\n",
      "Epoch 19252 - Train Loss: 0.083179, Train Acc: 0.874359 | Val Loss: 0.111867, Val Acc: 0.783505\n",
      "Epoch 19253 - Train Loss: 0.083176, Train Acc: 0.874359 | Val Loss: 0.111866, Val Acc: 0.783505\n",
      "Epoch 19254 - Train Loss: 0.083174, Train Acc: 0.874359 | Val Loss: 0.111865, Val Acc: 0.783505\n",
      "Epoch 19255 - Train Loss: 0.083171, Train Acc: 0.874359 | Val Loss: 0.111864, Val Acc: 0.783505\n",
      "Epoch 19256 - Train Loss: 0.083169, Train Acc: 0.874359 | Val Loss: 0.111862, Val Acc: 0.783505\n",
      "Epoch 19257 - Train Loss: 0.083166, Train Acc: 0.874359 | Val Loss: 0.111861, Val Acc: 0.783505\n",
      "Epoch 19258 - Train Loss: 0.083164, Train Acc: 0.874359 | Val Loss: 0.111860, Val Acc: 0.783505\n",
      "Epoch 19259 - Train Loss: 0.083161, Train Acc: 0.874359 | Val Loss: 0.111859, Val Acc: 0.783505\n",
      "Epoch 19260 - Train Loss: 0.083159, Train Acc: 0.874359 | Val Loss: 0.111858, Val Acc: 0.783505\n",
      "Epoch 19261 - Train Loss: 0.083156, Train Acc: 0.874359 | Val Loss: 0.111857, Val Acc: 0.783505\n",
      "Epoch 19262 - Train Loss: 0.083154, Train Acc: 0.874359 | Val Loss: 0.111856, Val Acc: 0.783505\n",
      "Epoch 19263 - Train Loss: 0.083151, Train Acc: 0.874359 | Val Loss: 0.111855, Val Acc: 0.783505\n",
      "Epoch 19264 - Train Loss: 0.083149, Train Acc: 0.874359 | Val Loss: 0.111853, Val Acc: 0.783505\n",
      "Epoch 19265 - Train Loss: 0.083146, Train Acc: 0.874359 | Val Loss: 0.111852, Val Acc: 0.783505\n",
      "Epoch 19266 - Train Loss: 0.083144, Train Acc: 0.874359 | Val Loss: 0.111851, Val Acc: 0.783505\n",
      "Epoch 19267 - Train Loss: 0.083141, Train Acc: 0.874359 | Val Loss: 0.111850, Val Acc: 0.783505\n",
      "Epoch 19268 - Train Loss: 0.083139, Train Acc: 0.874359 | Val Loss: 0.111849, Val Acc: 0.783505\n",
      "Epoch 19269 - Train Loss: 0.083136, Train Acc: 0.874359 | Val Loss: 0.111848, Val Acc: 0.783505\n",
      "Epoch 19270 - Train Loss: 0.083134, Train Acc: 0.874359 | Val Loss: 0.111847, Val Acc: 0.783505\n",
      "Epoch 19271 - Train Loss: 0.083131, Train Acc: 0.874359 | Val Loss: 0.111845, Val Acc: 0.783505\n",
      "Epoch 19272 - Train Loss: 0.083129, Train Acc: 0.874359 | Val Loss: 0.111844, Val Acc: 0.783505\n",
      "Epoch 19273 - Train Loss: 0.083126, Train Acc: 0.874359 | Val Loss: 0.111843, Val Acc: 0.783505\n",
      "Epoch 19274 - Train Loss: 0.083124, Train Acc: 0.874359 | Val Loss: 0.111842, Val Acc: 0.783505\n",
      "Epoch 19275 - Train Loss: 0.083121, Train Acc: 0.874359 | Val Loss: 0.111841, Val Acc: 0.783505\n",
      "Epoch 19276 - Train Loss: 0.083119, Train Acc: 0.874359 | Val Loss: 0.111840, Val Acc: 0.783505\n",
      "Epoch 19277 - Train Loss: 0.083116, Train Acc: 0.874359 | Val Loss: 0.111839, Val Acc: 0.783505\n",
      "Epoch 19278 - Train Loss: 0.083114, Train Acc: 0.874359 | Val Loss: 0.111838, Val Acc: 0.783505\n",
      "Epoch 19279 - Train Loss: 0.083111, Train Acc: 0.874359 | Val Loss: 0.111836, Val Acc: 0.783505\n",
      "Epoch 19280 - Train Loss: 0.083109, Train Acc: 0.874359 | Val Loss: 0.111835, Val Acc: 0.783505\n",
      "Epoch 19281 - Train Loss: 0.083107, Train Acc: 0.874359 | Val Loss: 0.111834, Val Acc: 0.783505\n",
      "Epoch 19282 - Train Loss: 0.083104, Train Acc: 0.874359 | Val Loss: 0.111833, Val Acc: 0.783505\n",
      "Epoch 19283 - Train Loss: 0.083102, Train Acc: 0.874359 | Val Loss: 0.111832, Val Acc: 0.783505\n",
      "Epoch 19284 - Train Loss: 0.083099, Train Acc: 0.874359 | Val Loss: 0.111831, Val Acc: 0.783505\n",
      "Epoch 19285 - Train Loss: 0.083097, Train Acc: 0.874359 | Val Loss: 0.111830, Val Acc: 0.783505\n",
      "Epoch 19286 - Train Loss: 0.083094, Train Acc: 0.874359 | Val Loss: 0.111829, Val Acc: 0.783505\n",
      "Epoch 19287 - Train Loss: 0.083092, Train Acc: 0.874359 | Val Loss: 0.111827, Val Acc: 0.783505\n",
      "Epoch 19288 - Train Loss: 0.083089, Train Acc: 0.874359 | Val Loss: 0.111826, Val Acc: 0.783505\n",
      "Epoch 19289 - Train Loss: 0.083087, Train Acc: 0.874359 | Val Loss: 0.111825, Val Acc: 0.783505\n",
      "Epoch 19290 - Train Loss: 0.083084, Train Acc: 0.874359 | Val Loss: 0.111824, Val Acc: 0.783505\n",
      "Epoch 19291 - Train Loss: 0.083082, Train Acc: 0.874359 | Val Loss: 0.111823, Val Acc: 0.783505\n",
      "Epoch 19292 - Train Loss: 0.083079, Train Acc: 0.873077 | Val Loss: 0.111822, Val Acc: 0.783505\n",
      "Epoch 19293 - Train Loss: 0.083077, Train Acc: 0.873077 | Val Loss: 0.111821, Val Acc: 0.783505\n",
      "Epoch 19294 - Train Loss: 0.083074, Train Acc: 0.873077 | Val Loss: 0.111819, Val Acc: 0.783505\n",
      "Epoch 19295 - Train Loss: 0.083072, Train Acc: 0.873077 | Val Loss: 0.111818, Val Acc: 0.783505\n",
      "Epoch 19296 - Train Loss: 0.083069, Train Acc: 0.873077 | Val Loss: 0.111817, Val Acc: 0.783505\n",
      "Epoch 19297 - Train Loss: 0.083067, Train Acc: 0.873077 | Val Loss: 0.111816, Val Acc: 0.783505\n",
      "Epoch 19298 - Train Loss: 0.083064, Train Acc: 0.873077 | Val Loss: 0.111815, Val Acc: 0.783505\n",
      "Epoch 19299 - Train Loss: 0.083062, Train Acc: 0.873077 | Val Loss: 0.111814, Val Acc: 0.783505\n",
      "Epoch 19300 - Train Loss: 0.083059, Train Acc: 0.873077 | Val Loss: 0.111813, Val Acc: 0.783505\n",
      "Epoch 19301 - Train Loss: 0.083057, Train Acc: 0.873077 | Val Loss: 0.111811, Val Acc: 0.783505\n",
      "Epoch 19302 - Train Loss: 0.083054, Train Acc: 0.873077 | Val Loss: 0.111810, Val Acc: 0.783505\n",
      "Epoch 19303 - Train Loss: 0.083052, Train Acc: 0.873077 | Val Loss: 0.111809, Val Acc: 0.783505\n",
      "Epoch 19304 - Train Loss: 0.083049, Train Acc: 0.873077 | Val Loss: 0.111808, Val Acc: 0.783505\n",
      "Epoch 19305 - Train Loss: 0.083047, Train Acc: 0.873077 | Val Loss: 0.111807, Val Acc: 0.783505\n",
      "Epoch 19306 - Train Loss: 0.083044, Train Acc: 0.873077 | Val Loss: 0.111806, Val Acc: 0.783505\n",
      "Epoch 19307 - Train Loss: 0.083042, Train Acc: 0.873077 | Val Loss: 0.111805, Val Acc: 0.783505\n",
      "Epoch 19308 - Train Loss: 0.083039, Train Acc: 0.873077 | Val Loss: 0.111803, Val Acc: 0.783505\n",
      "Epoch 19309 - Train Loss: 0.083037, Train Acc: 0.873077 | Val Loss: 0.111802, Val Acc: 0.783505\n",
      "Epoch 19310 - Train Loss: 0.083034, Train Acc: 0.873077 | Val Loss: 0.111801, Val Acc: 0.783505\n",
      "Epoch 19311 - Train Loss: 0.083032, Train Acc: 0.873077 | Val Loss: 0.111800, Val Acc: 0.783505\n",
      "Epoch 19312 - Train Loss: 0.083030, Train Acc: 0.873077 | Val Loss: 0.111799, Val Acc: 0.783505\n",
      "Epoch 19313 - Train Loss: 0.083027, Train Acc: 0.873077 | Val Loss: 0.111798, Val Acc: 0.783505\n",
      "Epoch 19314 - Train Loss: 0.083025, Train Acc: 0.873077 | Val Loss: 0.111797, Val Acc: 0.783505\n",
      "Epoch 19315 - Train Loss: 0.083022, Train Acc: 0.873077 | Val Loss: 0.111795, Val Acc: 0.783505\n",
      "Epoch 19316 - Train Loss: 0.083020, Train Acc: 0.873077 | Val Loss: 0.111794, Val Acc: 0.783505\n",
      "Epoch 19317 - Train Loss: 0.083017, Train Acc: 0.873077 | Val Loss: 0.111793, Val Acc: 0.783505\n",
      "Epoch 19318 - Train Loss: 0.083015, Train Acc: 0.873077 | Val Loss: 0.111792, Val Acc: 0.783505\n",
      "Epoch 19319 - Train Loss: 0.083012, Train Acc: 0.873077 | Val Loss: 0.111791, Val Acc: 0.783505\n",
      "Epoch 19320 - Train Loss: 0.083010, Train Acc: 0.873077 | Val Loss: 0.111790, Val Acc: 0.783505\n",
      "Epoch 19321 - Train Loss: 0.083007, Train Acc: 0.873077 | Val Loss: 0.111789, Val Acc: 0.783505\n",
      "Epoch 19322 - Train Loss: 0.083005, Train Acc: 0.873077 | Val Loss: 0.111788, Val Acc: 0.783505\n",
      "Epoch 19323 - Train Loss: 0.083002, Train Acc: 0.873077 | Val Loss: 0.111786, Val Acc: 0.783505\n",
      "Epoch 19324 - Train Loss: 0.083000, Train Acc: 0.873077 | Val Loss: 0.111785, Val Acc: 0.783505\n",
      "Epoch 19325 - Train Loss: 0.082997, Train Acc: 0.873077 | Val Loss: 0.111784, Val Acc: 0.783505\n",
      "Epoch 19326 - Train Loss: 0.082995, Train Acc: 0.873077 | Val Loss: 0.111783, Val Acc: 0.783505\n",
      "Epoch 19327 - Train Loss: 0.082992, Train Acc: 0.873077 | Val Loss: 0.111782, Val Acc: 0.783505\n",
      "Epoch 19328 - Train Loss: 0.082990, Train Acc: 0.873077 | Val Loss: 0.111781, Val Acc: 0.783505\n",
      "Epoch 19329 - Train Loss: 0.082987, Train Acc: 0.873077 | Val Loss: 0.111780, Val Acc: 0.783505\n",
      "Epoch 19330 - Train Loss: 0.082985, Train Acc: 0.873077 | Val Loss: 0.111779, Val Acc: 0.783505\n",
      "Epoch 19331 - Train Loss: 0.082982, Train Acc: 0.873077 | Val Loss: 0.111778, Val Acc: 0.783505\n",
      "Epoch 19332 - Train Loss: 0.082980, Train Acc: 0.873077 | Val Loss: 0.111776, Val Acc: 0.783505\n",
      "Epoch 19333 - Train Loss: 0.082977, Train Acc: 0.873077 | Val Loss: 0.111775, Val Acc: 0.783505\n",
      "Epoch 19334 - Train Loss: 0.082975, Train Acc: 0.873077 | Val Loss: 0.111774, Val Acc: 0.783505\n",
      "Epoch 19335 - Train Loss: 0.082973, Train Acc: 0.873077 | Val Loss: 0.111773, Val Acc: 0.783505\n",
      "Epoch 19336 - Train Loss: 0.082970, Train Acc: 0.873077 | Val Loss: 0.111772, Val Acc: 0.783505\n",
      "Epoch 19337 - Train Loss: 0.082968, Train Acc: 0.873077 | Val Loss: 0.111771, Val Acc: 0.783505\n",
      "Epoch 19338 - Train Loss: 0.082965, Train Acc: 0.873077 | Val Loss: 0.111770, Val Acc: 0.783505\n",
      "Epoch 19339 - Train Loss: 0.082963, Train Acc: 0.873077 | Val Loss: 0.111769, Val Acc: 0.783505\n",
      "Epoch 19340 - Train Loss: 0.082960, Train Acc: 0.873077 | Val Loss: 0.111768, Val Acc: 0.783505\n",
      "Epoch 19341 - Train Loss: 0.082958, Train Acc: 0.873077 | Val Loss: 0.111766, Val Acc: 0.783505\n",
      "Epoch 19342 - Train Loss: 0.082955, Train Acc: 0.873077 | Val Loss: 0.111765, Val Acc: 0.783505\n",
      "Epoch 19343 - Train Loss: 0.082953, Train Acc: 0.873077 | Val Loss: 0.111764, Val Acc: 0.783505\n",
      "Epoch 19344 - Train Loss: 0.082950, Train Acc: 0.873077 | Val Loss: 0.111763, Val Acc: 0.783505\n",
      "Epoch 19345 - Train Loss: 0.082948, Train Acc: 0.873077 | Val Loss: 0.111762, Val Acc: 0.783505\n",
      "Epoch 19346 - Train Loss: 0.082945, Train Acc: 0.873077 | Val Loss: 0.111761, Val Acc: 0.783505\n",
      "Epoch 19347 - Train Loss: 0.082943, Train Acc: 0.873077 | Val Loss: 0.111760, Val Acc: 0.783505\n",
      "Epoch 19348 - Train Loss: 0.082940, Train Acc: 0.873077 | Val Loss: 0.111759, Val Acc: 0.783505\n",
      "Epoch 19349 - Train Loss: 0.082938, Train Acc: 0.873077 | Val Loss: 0.111758, Val Acc: 0.783505\n",
      "Epoch 19350 - Train Loss: 0.082935, Train Acc: 0.873077 | Val Loss: 0.111756, Val Acc: 0.783505\n",
      "Epoch 19351 - Train Loss: 0.082933, Train Acc: 0.873077 | Val Loss: 0.111755, Val Acc: 0.783505\n",
      "Epoch 19352 - Train Loss: 0.082931, Train Acc: 0.873077 | Val Loss: 0.111754, Val Acc: 0.783505\n",
      "Epoch 19353 - Train Loss: 0.082928, Train Acc: 0.873077 | Val Loss: 0.111753, Val Acc: 0.783505\n",
      "Epoch 19354 - Train Loss: 0.082926, Train Acc: 0.873077 | Val Loss: 0.111752, Val Acc: 0.783505\n",
      "Epoch 19355 - Train Loss: 0.082923, Train Acc: 0.873077 | Val Loss: 0.111751, Val Acc: 0.783505\n",
      "Epoch 19356 - Train Loss: 0.082921, Train Acc: 0.873077 | Val Loss: 0.111750, Val Acc: 0.783505\n",
      "Epoch 19357 - Train Loss: 0.082918, Train Acc: 0.873077 | Val Loss: 0.111749, Val Acc: 0.783505\n",
      "Epoch 19358 - Train Loss: 0.082916, Train Acc: 0.873077 | Val Loss: 0.111748, Val Acc: 0.783505\n",
      "Epoch 19359 - Train Loss: 0.082913, Train Acc: 0.873077 | Val Loss: 0.111746, Val Acc: 0.783505\n",
      "Epoch 19360 - Train Loss: 0.082911, Train Acc: 0.874359 | Val Loss: 0.111745, Val Acc: 0.783505\n",
      "Epoch 19361 - Train Loss: 0.082908, Train Acc: 0.874359 | Val Loss: 0.111744, Val Acc: 0.783505\n",
      "Epoch 19362 - Train Loss: 0.082906, Train Acc: 0.874359 | Val Loss: 0.111743, Val Acc: 0.783505\n",
      "Epoch 19363 - Train Loss: 0.082903, Train Acc: 0.874359 | Val Loss: 0.111742, Val Acc: 0.783505\n",
      "Epoch 19364 - Train Loss: 0.082901, Train Acc: 0.874359 | Val Loss: 0.111741, Val Acc: 0.783505\n",
      "Epoch 19365 - Train Loss: 0.082898, Train Acc: 0.874359 | Val Loss: 0.111740, Val Acc: 0.783505\n",
      "Epoch 19366 - Train Loss: 0.082896, Train Acc: 0.874359 | Val Loss: 0.111739, Val Acc: 0.783505\n",
      "Epoch 19367 - Train Loss: 0.082894, Train Acc: 0.874359 | Val Loss: 0.111738, Val Acc: 0.783505\n",
      "Epoch 19368 - Train Loss: 0.082891, Train Acc: 0.874359 | Val Loss: 0.111737, Val Acc: 0.783505\n",
      "Epoch 19369 - Train Loss: 0.082889, Train Acc: 0.874359 | Val Loss: 0.111735, Val Acc: 0.783505\n",
      "Epoch 19370 - Train Loss: 0.082886, Train Acc: 0.874359 | Val Loss: 0.111734, Val Acc: 0.783505\n",
      "Epoch 19371 - Train Loss: 0.082884, Train Acc: 0.874359 | Val Loss: 0.111733, Val Acc: 0.783505\n",
      "Epoch 19372 - Train Loss: 0.082881, Train Acc: 0.874359 | Val Loss: 0.111732, Val Acc: 0.783505\n",
      "Epoch 19373 - Train Loss: 0.082879, Train Acc: 0.874359 | Val Loss: 0.111731, Val Acc: 0.783505\n",
      "Epoch 19374 - Train Loss: 0.082876, Train Acc: 0.874359 | Val Loss: 0.111730, Val Acc: 0.783505\n",
      "Epoch 19375 - Train Loss: 0.082874, Train Acc: 0.874359 | Val Loss: 0.111729, Val Acc: 0.783505\n",
      "Epoch 19376 - Train Loss: 0.082871, Train Acc: 0.874359 | Val Loss: 0.111728, Val Acc: 0.783505\n",
      "Epoch 19377 - Train Loss: 0.082869, Train Acc: 0.874359 | Val Loss: 0.111727, Val Acc: 0.783505\n",
      "Epoch 19378 - Train Loss: 0.082866, Train Acc: 0.874359 | Val Loss: 0.111725, Val Acc: 0.783505\n",
      "Epoch 19379 - Train Loss: 0.082864, Train Acc: 0.874359 | Val Loss: 0.111724, Val Acc: 0.783505\n",
      "Epoch 19380 - Train Loss: 0.082862, Train Acc: 0.874359 | Val Loss: 0.111723, Val Acc: 0.783505\n",
      "Epoch 19381 - Train Loss: 0.082859, Train Acc: 0.874359 | Val Loss: 0.111722, Val Acc: 0.783505\n",
      "Epoch 19382 - Train Loss: 0.082857, Train Acc: 0.874359 | Val Loss: 0.111721, Val Acc: 0.783505\n",
      "Epoch 19383 - Train Loss: 0.082854, Train Acc: 0.874359 | Val Loss: 0.111720, Val Acc: 0.783505\n",
      "Epoch 19384 - Train Loss: 0.082852, Train Acc: 0.874359 | Val Loss: 0.111719, Val Acc: 0.783505\n",
      "Epoch 19385 - Train Loss: 0.082849, Train Acc: 0.874359 | Val Loss: 0.111718, Val Acc: 0.783505\n",
      "Epoch 19386 - Train Loss: 0.082847, Train Acc: 0.874359 | Val Loss: 0.111717, Val Acc: 0.783505\n",
      "Epoch 19387 - Train Loss: 0.082844, Train Acc: 0.874359 | Val Loss: 0.111716, Val Acc: 0.783505\n",
      "Epoch 19388 - Train Loss: 0.082842, Train Acc: 0.874359 | Val Loss: 0.111714, Val Acc: 0.783505\n",
      "Epoch 19389 - Train Loss: 0.082839, Train Acc: 0.874359 | Val Loss: 0.111713, Val Acc: 0.783505\n",
      "Epoch 19390 - Train Loss: 0.082837, Train Acc: 0.874359 | Val Loss: 0.111712, Val Acc: 0.783505\n",
      "Epoch 19391 - Train Loss: 0.082834, Train Acc: 0.874359 | Val Loss: 0.111711, Val Acc: 0.783505\n",
      "Epoch 19392 - Train Loss: 0.082832, Train Acc: 0.874359 | Val Loss: 0.111710, Val Acc: 0.783505\n",
      "Epoch 19393 - Train Loss: 0.082830, Train Acc: 0.874359 | Val Loss: 0.111709, Val Acc: 0.783505\n",
      "Epoch 19394 - Train Loss: 0.082827, Train Acc: 0.874359 | Val Loss: 0.111708, Val Acc: 0.783505\n",
      "Epoch 19395 - Train Loss: 0.082825, Train Acc: 0.874359 | Val Loss: 0.111707, Val Acc: 0.783505\n",
      "Epoch 19396 - Train Loss: 0.082822, Train Acc: 0.874359 | Val Loss: 0.111706, Val Acc: 0.783505\n",
      "Epoch 19397 - Train Loss: 0.082820, Train Acc: 0.874359 | Val Loss: 0.111705, Val Acc: 0.783505\n",
      "Epoch 19398 - Train Loss: 0.082817, Train Acc: 0.874359 | Val Loss: 0.111703, Val Acc: 0.783505\n",
      "Epoch 19399 - Train Loss: 0.082815, Train Acc: 0.874359 | Val Loss: 0.111702, Val Acc: 0.783505\n",
      "Epoch 19400 - Train Loss: 0.082812, Train Acc: 0.874359 | Val Loss: 0.111701, Val Acc: 0.783505\n",
      "Epoch 19401 - Train Loss: 0.082810, Train Acc: 0.874359 | Val Loss: 0.111700, Val Acc: 0.783505\n",
      "Epoch 19402 - Train Loss: 0.082807, Train Acc: 0.874359 | Val Loss: 0.111699, Val Acc: 0.783505\n",
      "Epoch 19403 - Train Loss: 0.082805, Train Acc: 0.874359 | Val Loss: 0.111698, Val Acc: 0.783505\n",
      "Epoch 19404 - Train Loss: 0.082803, Train Acc: 0.874359 | Val Loss: 0.111697, Val Acc: 0.783505\n",
      "Epoch 19405 - Train Loss: 0.082800, Train Acc: 0.874359 | Val Loss: 0.111696, Val Acc: 0.783505\n",
      "Epoch 19406 - Train Loss: 0.082798, Train Acc: 0.874359 | Val Loss: 0.111695, Val Acc: 0.783505\n",
      "Epoch 19407 - Train Loss: 0.082795, Train Acc: 0.874359 | Val Loss: 0.111694, Val Acc: 0.783505\n",
      "Epoch 19408 - Train Loss: 0.082793, Train Acc: 0.874359 | Val Loss: 0.111693, Val Acc: 0.783505\n",
      "Epoch 19409 - Train Loss: 0.082790, Train Acc: 0.874359 | Val Loss: 0.111691, Val Acc: 0.783505\n",
      "Epoch 19410 - Train Loss: 0.082788, Train Acc: 0.874359 | Val Loss: 0.111690, Val Acc: 0.783505\n",
      "Epoch 19411 - Train Loss: 0.082785, Train Acc: 0.874359 | Val Loss: 0.111689, Val Acc: 0.783505\n",
      "Epoch 19412 - Train Loss: 0.082783, Train Acc: 0.874359 | Val Loss: 0.111688, Val Acc: 0.783505\n",
      "Epoch 19413 - Train Loss: 0.082780, Train Acc: 0.874359 | Val Loss: 0.111687, Val Acc: 0.783505\n",
      "Epoch 19414 - Train Loss: 0.082778, Train Acc: 0.874359 | Val Loss: 0.111686, Val Acc: 0.783505\n",
      "Epoch 19415 - Train Loss: 0.082776, Train Acc: 0.874359 | Val Loss: 0.111685, Val Acc: 0.783505\n",
      "Epoch 19416 - Train Loss: 0.082773, Train Acc: 0.874359 | Val Loss: 0.111684, Val Acc: 0.783505\n",
      "Epoch 19417 - Train Loss: 0.082771, Train Acc: 0.874359 | Val Loss: 0.111683, Val Acc: 0.783505\n",
      "Epoch 19418 - Train Loss: 0.082768, Train Acc: 0.874359 | Val Loss: 0.111682, Val Acc: 0.783505\n",
      "Epoch 19419 - Train Loss: 0.082766, Train Acc: 0.874359 | Val Loss: 0.111680, Val Acc: 0.783505\n",
      "Epoch 19420 - Train Loss: 0.082763, Train Acc: 0.874359 | Val Loss: 0.111679, Val Acc: 0.783505\n",
      "Epoch 19421 - Train Loss: 0.082761, Train Acc: 0.874359 | Val Loss: 0.111678, Val Acc: 0.783505\n",
      "Epoch 19422 - Train Loss: 0.082758, Train Acc: 0.874359 | Val Loss: 0.111677, Val Acc: 0.783505\n",
      "Epoch 19423 - Train Loss: 0.082756, Train Acc: 0.874359 | Val Loss: 0.111676, Val Acc: 0.783505\n",
      "Epoch 19424 - Train Loss: 0.082753, Train Acc: 0.874359 | Val Loss: 0.111675, Val Acc: 0.783505\n",
      "Epoch 19425 - Train Loss: 0.082751, Train Acc: 0.874359 | Val Loss: 0.111674, Val Acc: 0.783505\n",
      "Epoch 19426 - Train Loss: 0.082749, Train Acc: 0.874359 | Val Loss: 0.111673, Val Acc: 0.783505\n",
      "Epoch 19427 - Train Loss: 0.082746, Train Acc: 0.874359 | Val Loss: 0.111672, Val Acc: 0.783505\n",
      "Epoch 19428 - Train Loss: 0.082744, Train Acc: 0.874359 | Val Loss: 0.111671, Val Acc: 0.783505\n",
      "Epoch 19429 - Train Loss: 0.082741, Train Acc: 0.874359 | Val Loss: 0.111670, Val Acc: 0.783505\n",
      "Epoch 19430 - Train Loss: 0.082739, Train Acc: 0.874359 | Val Loss: 0.111668, Val Acc: 0.783505\n",
      "Epoch 19431 - Train Loss: 0.082736, Train Acc: 0.874359 | Val Loss: 0.111667, Val Acc: 0.783505\n",
      "Epoch 19432 - Train Loss: 0.082734, Train Acc: 0.874359 | Val Loss: 0.111666, Val Acc: 0.783505\n",
      "Epoch 19433 - Train Loss: 0.082731, Train Acc: 0.874359 | Val Loss: 0.111665, Val Acc: 0.783505\n",
      "Epoch 19434 - Train Loss: 0.082729, Train Acc: 0.874359 | Val Loss: 0.111664, Val Acc: 0.783505\n",
      "Epoch 19435 - Train Loss: 0.082727, Train Acc: 0.874359 | Val Loss: 0.111663, Val Acc: 0.783505\n",
      "Epoch 19436 - Train Loss: 0.082724, Train Acc: 0.874359 | Val Loss: 0.111662, Val Acc: 0.783505\n",
      "Epoch 19437 - Train Loss: 0.082722, Train Acc: 0.874359 | Val Loss: 0.111661, Val Acc: 0.783505\n",
      "Epoch 19438 - Train Loss: 0.082719, Train Acc: 0.874359 | Val Loss: 0.111660, Val Acc: 0.783505\n",
      "Epoch 19439 - Train Loss: 0.082717, Train Acc: 0.874359 | Val Loss: 0.111659, Val Acc: 0.783505\n",
      "Epoch 19440 - Train Loss: 0.082714, Train Acc: 0.874359 | Val Loss: 0.111658, Val Acc: 0.783505\n",
      "Epoch 19441 - Train Loss: 0.082712, Train Acc: 0.874359 | Val Loss: 0.111657, Val Acc: 0.783505\n",
      "Epoch 19442 - Train Loss: 0.082709, Train Acc: 0.874359 | Val Loss: 0.111656, Val Acc: 0.783505\n",
      "Epoch 19443 - Train Loss: 0.082707, Train Acc: 0.874359 | Val Loss: 0.111655, Val Acc: 0.783505\n",
      "Epoch 19444 - Train Loss: 0.082705, Train Acc: 0.874359 | Val Loss: 0.111654, Val Acc: 0.783505\n",
      "Epoch 19445 - Train Loss: 0.082702, Train Acc: 0.874359 | Val Loss: 0.111653, Val Acc: 0.783505\n",
      "Epoch 19446 - Train Loss: 0.082700, Train Acc: 0.874359 | Val Loss: 0.111652, Val Acc: 0.783505\n",
      "Epoch 19447 - Train Loss: 0.082697, Train Acc: 0.874359 | Val Loss: 0.111650, Val Acc: 0.783505\n",
      "Epoch 19448 - Train Loss: 0.082695, Train Acc: 0.874359 | Val Loss: 0.111649, Val Acc: 0.783505\n",
      "Epoch 19449 - Train Loss: 0.082692, Train Acc: 0.874359 | Val Loss: 0.111648, Val Acc: 0.783505\n",
      "Epoch 19450 - Train Loss: 0.082690, Train Acc: 0.874359 | Val Loss: 0.111647, Val Acc: 0.783505\n",
      "Epoch 19451 - Train Loss: 0.082688, Train Acc: 0.874359 | Val Loss: 0.111646, Val Acc: 0.783505\n",
      "Epoch 19452 - Train Loss: 0.082685, Train Acc: 0.874359 | Val Loss: 0.111645, Val Acc: 0.783505\n",
      "Epoch 19453 - Train Loss: 0.082683, Train Acc: 0.874359 | Val Loss: 0.111644, Val Acc: 0.783505\n",
      "Epoch 19454 - Train Loss: 0.082680, Train Acc: 0.874359 | Val Loss: 0.111643, Val Acc: 0.783505\n",
      "Epoch 19455 - Train Loss: 0.082678, Train Acc: 0.874359 | Val Loss: 0.111642, Val Acc: 0.783505\n",
      "Epoch 19456 - Train Loss: 0.082675, Train Acc: 0.874359 | Val Loss: 0.111641, Val Acc: 0.783505\n",
      "Epoch 19457 - Train Loss: 0.082673, Train Acc: 0.874359 | Val Loss: 0.111640, Val Acc: 0.783505\n",
      "Epoch 19458 - Train Loss: 0.082671, Train Acc: 0.874359 | Val Loss: 0.111639, Val Acc: 0.783505\n",
      "Epoch 19459 - Train Loss: 0.082668, Train Acc: 0.874359 | Val Loss: 0.111638, Val Acc: 0.783505\n",
      "Epoch 19460 - Train Loss: 0.082666, Train Acc: 0.874359 | Val Loss: 0.111636, Val Acc: 0.783505\n",
      "Epoch 19461 - Train Loss: 0.082663, Train Acc: 0.874359 | Val Loss: 0.111635, Val Acc: 0.783505\n",
      "Epoch 19462 - Train Loss: 0.082661, Train Acc: 0.874359 | Val Loss: 0.111634, Val Acc: 0.783505\n",
      "Epoch 19463 - Train Loss: 0.082658, Train Acc: 0.874359 | Val Loss: 0.111633, Val Acc: 0.783505\n",
      "Epoch 19464 - Train Loss: 0.082656, Train Acc: 0.874359 | Val Loss: 0.111632, Val Acc: 0.783505\n",
      "Epoch 19465 - Train Loss: 0.082654, Train Acc: 0.874359 | Val Loss: 0.111631, Val Acc: 0.783505\n",
      "Epoch 19466 - Train Loss: 0.082651, Train Acc: 0.874359 | Val Loss: 0.111630, Val Acc: 0.783505\n",
      "Epoch 19467 - Train Loss: 0.082649, Train Acc: 0.874359 | Val Loss: 0.111629, Val Acc: 0.783505\n",
      "Epoch 19468 - Train Loss: 0.082646, Train Acc: 0.874359 | Val Loss: 0.111628, Val Acc: 0.783505\n",
      "Epoch 19469 - Train Loss: 0.082644, Train Acc: 0.874359 | Val Loss: 0.111627, Val Acc: 0.783505\n",
      "Epoch 19470 - Train Loss: 0.082641, Train Acc: 0.874359 | Val Loss: 0.111626, Val Acc: 0.783505\n",
      "Epoch 19471 - Train Loss: 0.082639, Train Acc: 0.874359 | Val Loss: 0.111625, Val Acc: 0.783505\n",
      "Epoch 19472 - Train Loss: 0.082636, Train Acc: 0.874359 | Val Loss: 0.111623, Val Acc: 0.783505\n",
      "Epoch 19473 - Train Loss: 0.082634, Train Acc: 0.874359 | Val Loss: 0.111622, Val Acc: 0.783505\n",
      "Epoch 19474 - Train Loss: 0.082632, Train Acc: 0.874359 | Val Loss: 0.111621, Val Acc: 0.783505\n",
      "Epoch 19475 - Train Loss: 0.082629, Train Acc: 0.874359 | Val Loss: 0.111620, Val Acc: 0.783505\n",
      "Epoch 19476 - Train Loss: 0.082627, Train Acc: 0.874359 | Val Loss: 0.111619, Val Acc: 0.783505\n",
      "Epoch 19477 - Train Loss: 0.082624, Train Acc: 0.874359 | Val Loss: 0.111618, Val Acc: 0.783505\n",
      "Epoch 19478 - Train Loss: 0.082622, Train Acc: 0.874359 | Val Loss: 0.111617, Val Acc: 0.783505\n",
      "Epoch 19479 - Train Loss: 0.082620, Train Acc: 0.874359 | Val Loss: 0.111616, Val Acc: 0.783505\n",
      "Epoch 19480 - Train Loss: 0.082617, Train Acc: 0.874359 | Val Loss: 0.111615, Val Acc: 0.783505\n",
      "Epoch 19481 - Train Loss: 0.082615, Train Acc: 0.874359 | Val Loss: 0.111614, Val Acc: 0.783505\n",
      "Epoch 19482 - Train Loss: 0.082612, Train Acc: 0.874359 | Val Loss: 0.111613, Val Acc: 0.783505\n",
      "Epoch 19483 - Train Loss: 0.082610, Train Acc: 0.874359 | Val Loss: 0.111612, Val Acc: 0.783505\n",
      "Epoch 19484 - Train Loss: 0.082607, Train Acc: 0.874359 | Val Loss: 0.111611, Val Acc: 0.783505\n",
      "Epoch 19485 - Train Loss: 0.082605, Train Acc: 0.874359 | Val Loss: 0.111609, Val Acc: 0.783505\n",
      "Epoch 19486 - Train Loss: 0.082603, Train Acc: 0.874359 | Val Loss: 0.111608, Val Acc: 0.783505\n",
      "Epoch 19487 - Train Loss: 0.082600, Train Acc: 0.874359 | Val Loss: 0.111607, Val Acc: 0.783505\n",
      "Epoch 19488 - Train Loss: 0.082598, Train Acc: 0.874359 | Val Loss: 0.111606, Val Acc: 0.783505\n",
      "Epoch 19489 - Train Loss: 0.082595, Train Acc: 0.874359 | Val Loss: 0.111605, Val Acc: 0.783505\n",
      "Epoch 19490 - Train Loss: 0.082593, Train Acc: 0.874359 | Val Loss: 0.111604, Val Acc: 0.783505\n",
      "Epoch 19491 - Train Loss: 0.082590, Train Acc: 0.874359 | Val Loss: 0.111603, Val Acc: 0.783505\n",
      "Epoch 19492 - Train Loss: 0.082588, Train Acc: 0.874359 | Val Loss: 0.111602, Val Acc: 0.783505\n",
      "Epoch 19493 - Train Loss: 0.082586, Train Acc: 0.874359 | Val Loss: 0.111601, Val Acc: 0.783505\n",
      "Epoch 19494 - Train Loss: 0.082583, Train Acc: 0.874359 | Val Loss: 0.111600, Val Acc: 0.783505\n",
      "Epoch 19495 - Train Loss: 0.082581, Train Acc: 0.874359 | Val Loss: 0.111599, Val Acc: 0.783505\n",
      "Epoch 19496 - Train Loss: 0.082578, Train Acc: 0.874359 | Val Loss: 0.111597, Val Acc: 0.783505\n",
      "Epoch 19497 - Train Loss: 0.082576, Train Acc: 0.874359 | Val Loss: 0.111596, Val Acc: 0.783505\n",
      "Epoch 19498 - Train Loss: 0.082573, Train Acc: 0.874359 | Val Loss: 0.111595, Val Acc: 0.783505\n",
      "Epoch 19499 - Train Loss: 0.082571, Train Acc: 0.874359 | Val Loss: 0.111594, Val Acc: 0.783505\n",
      "Epoch 19500 - Train Loss: 0.082569, Train Acc: 0.874359 | Val Loss: 0.111593, Val Acc: 0.783505\n",
      "Epoch 19501 - Train Loss: 0.082566, Train Acc: 0.874359 | Val Loss: 0.111592, Val Acc: 0.783505\n",
      "Epoch 19502 - Train Loss: 0.082564, Train Acc: 0.874359 | Val Loss: 0.111591, Val Acc: 0.783505\n",
      "Epoch 19503 - Train Loss: 0.082561, Train Acc: 0.874359 | Val Loss: 0.111590, Val Acc: 0.783505\n",
      "Epoch 19504 - Train Loss: 0.082559, Train Acc: 0.874359 | Val Loss: 0.111589, Val Acc: 0.783505\n",
      "Epoch 19505 - Train Loss: 0.082556, Train Acc: 0.874359 | Val Loss: 0.111588, Val Acc: 0.783505\n",
      "Epoch 19506 - Train Loss: 0.082554, Train Acc: 0.874359 | Val Loss: 0.111587, Val Acc: 0.783505\n",
      "Epoch 19507 - Train Loss: 0.082552, Train Acc: 0.874359 | Val Loss: 0.111586, Val Acc: 0.783505\n",
      "Epoch 19508 - Train Loss: 0.082549, Train Acc: 0.874359 | Val Loss: 0.111585, Val Acc: 0.783505\n",
      "Epoch 19509 - Train Loss: 0.082547, Train Acc: 0.874359 | Val Loss: 0.111583, Val Acc: 0.783505\n",
      "Epoch 19510 - Train Loss: 0.082544, Train Acc: 0.874359 | Val Loss: 0.111582, Val Acc: 0.783505\n",
      "Epoch 19511 - Train Loss: 0.082542, Train Acc: 0.874359 | Val Loss: 0.111581, Val Acc: 0.783505\n",
      "Epoch 19512 - Train Loss: 0.082540, Train Acc: 0.874359 | Val Loss: 0.111580, Val Acc: 0.783505\n",
      "Epoch 19513 - Train Loss: 0.082537, Train Acc: 0.874359 | Val Loss: 0.111579, Val Acc: 0.783505\n",
      "Epoch 19514 - Train Loss: 0.082535, Train Acc: 0.874359 | Val Loss: 0.111578, Val Acc: 0.783505\n",
      "Epoch 19515 - Train Loss: 0.082532, Train Acc: 0.874359 | Val Loss: 0.111577, Val Acc: 0.783505\n",
      "Epoch 19516 - Train Loss: 0.082530, Train Acc: 0.874359 | Val Loss: 0.111576, Val Acc: 0.783505\n",
      "Epoch 19517 - Train Loss: 0.082527, Train Acc: 0.874359 | Val Loss: 0.111575, Val Acc: 0.783505\n",
      "Epoch 19518 - Train Loss: 0.082525, Train Acc: 0.874359 | Val Loss: 0.111574, Val Acc: 0.783505\n",
      "Epoch 19519 - Train Loss: 0.082523, Train Acc: 0.874359 | Val Loss: 0.111573, Val Acc: 0.783505\n",
      "Epoch 19520 - Train Loss: 0.082520, Train Acc: 0.874359 | Val Loss: 0.111571, Val Acc: 0.783505\n",
      "Epoch 19521 - Train Loss: 0.082518, Train Acc: 0.874359 | Val Loss: 0.111570, Val Acc: 0.783505\n",
      "Epoch 19522 - Train Loss: 0.082515, Train Acc: 0.874359 | Val Loss: 0.111569, Val Acc: 0.783505\n",
      "Epoch 19523 - Train Loss: 0.082513, Train Acc: 0.874359 | Val Loss: 0.111568, Val Acc: 0.783505\n",
      "Epoch 19524 - Train Loss: 0.082511, Train Acc: 0.874359 | Val Loss: 0.111567, Val Acc: 0.783505\n",
      "Epoch 19525 - Train Loss: 0.082508, Train Acc: 0.874359 | Val Loss: 0.111566, Val Acc: 0.783505\n",
      "Epoch 19526 - Train Loss: 0.082506, Train Acc: 0.874359 | Val Loss: 0.111565, Val Acc: 0.783505\n",
      "Epoch 19527 - Train Loss: 0.082503, Train Acc: 0.874359 | Val Loss: 0.111564, Val Acc: 0.783505\n",
      "Epoch 19528 - Train Loss: 0.082501, Train Acc: 0.874359 | Val Loss: 0.111563, Val Acc: 0.783505\n",
      "Epoch 19529 - Train Loss: 0.082498, Train Acc: 0.874359 | Val Loss: 0.111562, Val Acc: 0.783505\n",
      "Epoch 19530 - Train Loss: 0.082496, Train Acc: 0.874359 | Val Loss: 0.111561, Val Acc: 0.783505\n",
      "Epoch 19531 - Train Loss: 0.082494, Train Acc: 0.874359 | Val Loss: 0.111560, Val Acc: 0.783505\n",
      "Epoch 19532 - Train Loss: 0.082491, Train Acc: 0.874359 | Val Loss: 0.111559, Val Acc: 0.783505\n",
      "Epoch 19533 - Train Loss: 0.082489, Train Acc: 0.874359 | Val Loss: 0.111557, Val Acc: 0.783505\n",
      "Epoch 19534 - Train Loss: 0.082486, Train Acc: 0.874359 | Val Loss: 0.111556, Val Acc: 0.783505\n",
      "Epoch 19535 - Train Loss: 0.082484, Train Acc: 0.874359 | Val Loss: 0.111555, Val Acc: 0.783505\n",
      "Epoch 19536 - Train Loss: 0.082482, Train Acc: 0.874359 | Val Loss: 0.111554, Val Acc: 0.783505\n",
      "Epoch 19537 - Train Loss: 0.082479, Train Acc: 0.874359 | Val Loss: 0.111553, Val Acc: 0.783505\n",
      "Epoch 19538 - Train Loss: 0.082477, Train Acc: 0.874359 | Val Loss: 0.111552, Val Acc: 0.783505\n",
      "Epoch 19539 - Train Loss: 0.082474, Train Acc: 0.874359 | Val Loss: 0.111551, Val Acc: 0.783505\n",
      "Epoch 19540 - Train Loss: 0.082472, Train Acc: 0.874359 | Val Loss: 0.111550, Val Acc: 0.783505\n",
      "Epoch 19541 - Train Loss: 0.082470, Train Acc: 0.874359 | Val Loss: 0.111549, Val Acc: 0.783505\n",
      "Epoch 19542 - Train Loss: 0.082467, Train Acc: 0.874359 | Val Loss: 0.111548, Val Acc: 0.783505\n",
      "Epoch 19543 - Train Loss: 0.082465, Train Acc: 0.874359 | Val Loss: 0.111547, Val Acc: 0.783505\n",
      "Epoch 19544 - Train Loss: 0.082462, Train Acc: 0.874359 | Val Loss: 0.111546, Val Acc: 0.783505\n",
      "Epoch 19545 - Train Loss: 0.082460, Train Acc: 0.874359 | Val Loss: 0.111544, Val Acc: 0.783505\n",
      "Epoch 19546 - Train Loss: 0.082457, Train Acc: 0.874359 | Val Loss: 0.111543, Val Acc: 0.783505\n",
      "Epoch 19547 - Train Loss: 0.082455, Train Acc: 0.874359 | Val Loss: 0.111542, Val Acc: 0.783505\n",
      "Epoch 19548 - Train Loss: 0.082453, Train Acc: 0.874359 | Val Loss: 0.111541, Val Acc: 0.783505\n",
      "Epoch 19549 - Train Loss: 0.082450, Train Acc: 0.874359 | Val Loss: 0.111540, Val Acc: 0.783505\n",
      "Epoch 19550 - Train Loss: 0.082448, Train Acc: 0.874359 | Val Loss: 0.111539, Val Acc: 0.783505\n",
      "Epoch 19551 - Train Loss: 0.082445, Train Acc: 0.874359 | Val Loss: 0.111538, Val Acc: 0.783505\n",
      "Epoch 19552 - Train Loss: 0.082443, Train Acc: 0.874359 | Val Loss: 0.111537, Val Acc: 0.783505\n",
      "Epoch 19553 - Train Loss: 0.082441, Train Acc: 0.874359 | Val Loss: 0.111536, Val Acc: 0.783505\n",
      "Epoch 19554 - Train Loss: 0.082438, Train Acc: 0.874359 | Val Loss: 0.111535, Val Acc: 0.783505\n",
      "Epoch 19555 - Train Loss: 0.082436, Train Acc: 0.874359 | Val Loss: 0.111534, Val Acc: 0.783505\n",
      "Epoch 19556 - Train Loss: 0.082433, Train Acc: 0.874359 | Val Loss: 0.111533, Val Acc: 0.783505\n",
      "Epoch 19557 - Train Loss: 0.082431, Train Acc: 0.874359 | Val Loss: 0.111532, Val Acc: 0.783505\n",
      "Epoch 19558 - Train Loss: 0.082429, Train Acc: 0.874359 | Val Loss: 0.111530, Val Acc: 0.783505\n",
      "Epoch 19559 - Train Loss: 0.082426, Train Acc: 0.874359 | Val Loss: 0.111529, Val Acc: 0.783505\n",
      "Epoch 19560 - Train Loss: 0.082424, Train Acc: 0.874359 | Val Loss: 0.111528, Val Acc: 0.783505\n",
      "Epoch 19561 - Train Loss: 0.082421, Train Acc: 0.874359 | Val Loss: 0.111527, Val Acc: 0.783505\n",
      "Epoch 19562 - Train Loss: 0.082419, Train Acc: 0.874359 | Val Loss: 0.111526, Val Acc: 0.783505\n",
      "Epoch 19563 - Train Loss: 0.082417, Train Acc: 0.874359 | Val Loss: 0.111525, Val Acc: 0.783505\n",
      "Epoch 19564 - Train Loss: 0.082414, Train Acc: 0.874359 | Val Loss: 0.111524, Val Acc: 0.783505\n",
      "Epoch 19565 - Train Loss: 0.082412, Train Acc: 0.874359 | Val Loss: 0.111523, Val Acc: 0.783505\n",
      "Epoch 19566 - Train Loss: 0.082409, Train Acc: 0.874359 | Val Loss: 0.111522, Val Acc: 0.783505\n",
      "Epoch 19567 - Train Loss: 0.082407, Train Acc: 0.874359 | Val Loss: 0.111521, Val Acc: 0.783505\n",
      "Epoch 19568 - Train Loss: 0.082405, Train Acc: 0.874359 | Val Loss: 0.111520, Val Acc: 0.783505\n",
      "Epoch 19569 - Train Loss: 0.082402, Train Acc: 0.874359 | Val Loss: 0.111519, Val Acc: 0.783505\n",
      "Epoch 19570 - Train Loss: 0.082400, Train Acc: 0.874359 | Val Loss: 0.111518, Val Acc: 0.783505\n",
      "Epoch 19571 - Train Loss: 0.082397, Train Acc: 0.874359 | Val Loss: 0.111517, Val Acc: 0.783505\n",
      "Epoch 19572 - Train Loss: 0.082395, Train Acc: 0.874359 | Val Loss: 0.111515, Val Acc: 0.783505\n",
      "Epoch 19573 - Train Loss: 0.082392, Train Acc: 0.874359 | Val Loss: 0.111514, Val Acc: 0.783505\n",
      "Epoch 19574 - Train Loss: 0.082390, Train Acc: 0.874359 | Val Loss: 0.111513, Val Acc: 0.783505\n",
      "Epoch 19575 - Train Loss: 0.082388, Train Acc: 0.874359 | Val Loss: 0.111512, Val Acc: 0.783505\n",
      "Epoch 19576 - Train Loss: 0.082385, Train Acc: 0.874359 | Val Loss: 0.111511, Val Acc: 0.783505\n",
      "Epoch 19577 - Train Loss: 0.082383, Train Acc: 0.874359 | Val Loss: 0.111510, Val Acc: 0.783505\n",
      "Epoch 19578 - Train Loss: 0.082380, Train Acc: 0.874359 | Val Loss: 0.111509, Val Acc: 0.783505\n",
      "Epoch 19579 - Train Loss: 0.082378, Train Acc: 0.874359 | Val Loss: 0.111508, Val Acc: 0.783505\n",
      "Epoch 19580 - Train Loss: 0.082376, Train Acc: 0.874359 | Val Loss: 0.111507, Val Acc: 0.783505\n",
      "Epoch 19581 - Train Loss: 0.082373, Train Acc: 0.874359 | Val Loss: 0.111506, Val Acc: 0.783505\n",
      "Epoch 19582 - Train Loss: 0.082371, Train Acc: 0.874359 | Val Loss: 0.111505, Val Acc: 0.783505\n",
      "Epoch 19583 - Train Loss: 0.082368, Train Acc: 0.874359 | Val Loss: 0.111504, Val Acc: 0.783505\n",
      "Epoch 19584 - Train Loss: 0.082366, Train Acc: 0.874359 | Val Loss: 0.111503, Val Acc: 0.783505\n",
      "Epoch 19585 - Train Loss: 0.082364, Train Acc: 0.874359 | Val Loss: 0.111502, Val Acc: 0.783505\n",
      "Epoch 19586 - Train Loss: 0.082361, Train Acc: 0.874359 | Val Loss: 0.111501, Val Acc: 0.783505\n",
      "Epoch 19587 - Train Loss: 0.082359, Train Acc: 0.874359 | Val Loss: 0.111499, Val Acc: 0.783505\n",
      "Epoch 19588 - Train Loss: 0.082356, Train Acc: 0.874359 | Val Loss: 0.111498, Val Acc: 0.783505\n",
      "Epoch 19589 - Train Loss: 0.082354, Train Acc: 0.874359 | Val Loss: 0.111497, Val Acc: 0.783505\n",
      "Epoch 19590 - Train Loss: 0.082352, Train Acc: 0.874359 | Val Loss: 0.111496, Val Acc: 0.783505\n",
      "Epoch 19591 - Train Loss: 0.082349, Train Acc: 0.874359 | Val Loss: 0.111495, Val Acc: 0.783505\n",
      "Epoch 19592 - Train Loss: 0.082347, Train Acc: 0.874359 | Val Loss: 0.111494, Val Acc: 0.783505\n",
      "Epoch 19593 - Train Loss: 0.082344, Train Acc: 0.874359 | Val Loss: 0.111493, Val Acc: 0.783505\n",
      "Epoch 19594 - Train Loss: 0.082342, Train Acc: 0.874359 | Val Loss: 0.111492, Val Acc: 0.783505\n",
      "Epoch 19595 - Train Loss: 0.082340, Train Acc: 0.874359 | Val Loss: 0.111491, Val Acc: 0.783505\n",
      "Epoch 19596 - Train Loss: 0.082337, Train Acc: 0.874359 | Val Loss: 0.111490, Val Acc: 0.783505\n",
      "Epoch 19597 - Train Loss: 0.082335, Train Acc: 0.874359 | Val Loss: 0.111489, Val Acc: 0.783505\n",
      "Epoch 19598 - Train Loss: 0.082332, Train Acc: 0.874359 | Val Loss: 0.111488, Val Acc: 0.783505\n",
      "Epoch 19599 - Train Loss: 0.082330, Train Acc: 0.874359 | Val Loss: 0.111487, Val Acc: 0.783505\n",
      "Epoch 19600 - Train Loss: 0.082328, Train Acc: 0.874359 | Val Loss: 0.111486, Val Acc: 0.783505\n",
      "Epoch 19601 - Train Loss: 0.082325, Train Acc: 0.874359 | Val Loss: 0.111485, Val Acc: 0.783505\n",
      "Epoch 19602 - Train Loss: 0.082323, Train Acc: 0.874359 | Val Loss: 0.111483, Val Acc: 0.783505\n",
      "Epoch 19603 - Train Loss: 0.082320, Train Acc: 0.874359 | Val Loss: 0.111482, Val Acc: 0.783505\n",
      "Epoch 19604 - Train Loss: 0.082318, Train Acc: 0.874359 | Val Loss: 0.111481, Val Acc: 0.783505\n",
      "Epoch 19605 - Train Loss: 0.082316, Train Acc: 0.874359 | Val Loss: 0.111480, Val Acc: 0.783505\n",
      "Epoch 19606 - Train Loss: 0.082313, Train Acc: 0.874359 | Val Loss: 0.111479, Val Acc: 0.783505\n",
      "Epoch 19607 - Train Loss: 0.082311, Train Acc: 0.874359 | Val Loss: 0.111478, Val Acc: 0.783505\n",
      "Epoch 19608 - Train Loss: 0.082309, Train Acc: 0.874359 | Val Loss: 0.111477, Val Acc: 0.783505\n",
      "Epoch 19609 - Train Loss: 0.082306, Train Acc: 0.874359 | Val Loss: 0.111476, Val Acc: 0.783505\n",
      "Epoch 19610 - Train Loss: 0.082304, Train Acc: 0.874359 | Val Loss: 0.111475, Val Acc: 0.783505\n",
      "Epoch 19611 - Train Loss: 0.082301, Train Acc: 0.874359 | Val Loss: 0.111474, Val Acc: 0.783505\n",
      "Epoch 19612 - Train Loss: 0.082299, Train Acc: 0.874359 | Val Loss: 0.111473, Val Acc: 0.783505\n",
      "Epoch 19613 - Train Loss: 0.082297, Train Acc: 0.874359 | Val Loss: 0.111472, Val Acc: 0.783505\n",
      "Epoch 19614 - Train Loss: 0.082294, Train Acc: 0.874359 | Val Loss: 0.111471, Val Acc: 0.783505\n",
      "Epoch 19615 - Train Loss: 0.082292, Train Acc: 0.874359 | Val Loss: 0.111470, Val Acc: 0.783505\n",
      "Epoch 19616 - Train Loss: 0.082289, Train Acc: 0.874359 | Val Loss: 0.111469, Val Acc: 0.783505\n",
      "Epoch 19617 - Train Loss: 0.082287, Train Acc: 0.874359 | Val Loss: 0.111468, Val Acc: 0.783505\n",
      "Epoch 19618 - Train Loss: 0.082285, Train Acc: 0.874359 | Val Loss: 0.111466, Val Acc: 0.783505\n",
      "Epoch 19619 - Train Loss: 0.082282, Train Acc: 0.874359 | Val Loss: 0.111465, Val Acc: 0.783505\n",
      "Epoch 19620 - Train Loss: 0.082280, Train Acc: 0.874359 | Val Loss: 0.111464, Val Acc: 0.783505\n",
      "Epoch 19621 - Train Loss: 0.082277, Train Acc: 0.874359 | Val Loss: 0.111463, Val Acc: 0.783505\n",
      "Epoch 19622 - Train Loss: 0.082275, Train Acc: 0.874359 | Val Loss: 0.111462, Val Acc: 0.783505\n",
      "Epoch 19623 - Train Loss: 0.082273, Train Acc: 0.874359 | Val Loss: 0.111461, Val Acc: 0.783505\n",
      "Epoch 19624 - Train Loss: 0.082270, Train Acc: 0.874359 | Val Loss: 0.111460, Val Acc: 0.783505\n",
      "Epoch 19625 - Train Loss: 0.082268, Train Acc: 0.874359 | Val Loss: 0.111459, Val Acc: 0.783505\n",
      "Epoch 19626 - Train Loss: 0.082265, Train Acc: 0.874359 | Val Loss: 0.111458, Val Acc: 0.783505\n",
      "Epoch 19627 - Train Loss: 0.082263, Train Acc: 0.874359 | Val Loss: 0.111457, Val Acc: 0.783505\n",
      "Epoch 19628 - Train Loss: 0.082261, Train Acc: 0.874359 | Val Loss: 0.111456, Val Acc: 0.783505\n",
      "Epoch 19629 - Train Loss: 0.082258, Train Acc: 0.874359 | Val Loss: 0.111455, Val Acc: 0.783505\n",
      "Epoch 19630 - Train Loss: 0.082256, Train Acc: 0.874359 | Val Loss: 0.111454, Val Acc: 0.783505\n",
      "Epoch 19631 - Train Loss: 0.082254, Train Acc: 0.874359 | Val Loss: 0.111453, Val Acc: 0.783505\n",
      "Epoch 19632 - Train Loss: 0.082251, Train Acc: 0.874359 | Val Loss: 0.111452, Val Acc: 0.783505\n",
      "Epoch 19633 - Train Loss: 0.082249, Train Acc: 0.874359 | Val Loss: 0.111451, Val Acc: 0.783505\n",
      "Epoch 19634 - Train Loss: 0.082246, Train Acc: 0.874359 | Val Loss: 0.111450, Val Acc: 0.783505\n",
      "Epoch 19635 - Train Loss: 0.082244, Train Acc: 0.874359 | Val Loss: 0.111449, Val Acc: 0.783505\n",
      "Epoch 19636 - Train Loss: 0.082242, Train Acc: 0.874359 | Val Loss: 0.111447, Val Acc: 0.783505\n",
      "Epoch 19637 - Train Loss: 0.082239, Train Acc: 0.874359 | Val Loss: 0.111446, Val Acc: 0.783505\n",
      "Epoch 19638 - Train Loss: 0.082237, Train Acc: 0.874359 | Val Loss: 0.111445, Val Acc: 0.783505\n",
      "Epoch 19639 - Train Loss: 0.082234, Train Acc: 0.874359 | Val Loss: 0.111444, Val Acc: 0.783505\n",
      "Epoch 19640 - Train Loss: 0.082232, Train Acc: 0.874359 | Val Loss: 0.111443, Val Acc: 0.783505\n",
      "Epoch 19641 - Train Loss: 0.082230, Train Acc: 0.874359 | Val Loss: 0.111442, Val Acc: 0.783505\n",
      "Epoch 19642 - Train Loss: 0.082227, Train Acc: 0.874359 | Val Loss: 0.111441, Val Acc: 0.783505\n",
      "Epoch 19643 - Train Loss: 0.082225, Train Acc: 0.874359 | Val Loss: 0.111440, Val Acc: 0.783505\n",
      "Epoch 19644 - Train Loss: 0.082222, Train Acc: 0.874359 | Val Loss: 0.111439, Val Acc: 0.783505\n",
      "Epoch 19645 - Train Loss: 0.082220, Train Acc: 0.874359 | Val Loss: 0.111438, Val Acc: 0.783505\n",
      "Epoch 19646 - Train Loss: 0.082218, Train Acc: 0.874359 | Val Loss: 0.111437, Val Acc: 0.783505\n",
      "Epoch 19647 - Train Loss: 0.082215, Train Acc: 0.874359 | Val Loss: 0.111436, Val Acc: 0.783505\n",
      "Epoch 19648 - Train Loss: 0.082213, Train Acc: 0.874359 | Val Loss: 0.111435, Val Acc: 0.783505\n",
      "Epoch 19649 - Train Loss: 0.082211, Train Acc: 0.874359 | Val Loss: 0.111434, Val Acc: 0.783505\n",
      "Epoch 19650 - Train Loss: 0.082208, Train Acc: 0.874359 | Val Loss: 0.111433, Val Acc: 0.783505\n",
      "Epoch 19651 - Train Loss: 0.082206, Train Acc: 0.874359 | Val Loss: 0.111432, Val Acc: 0.783505\n",
      "Epoch 19652 - Train Loss: 0.082203, Train Acc: 0.874359 | Val Loss: 0.111431, Val Acc: 0.783505\n",
      "Epoch 19653 - Train Loss: 0.082201, Train Acc: 0.874359 | Val Loss: 0.111430, Val Acc: 0.783505\n",
      "Epoch 19654 - Train Loss: 0.082199, Train Acc: 0.874359 | Val Loss: 0.111429, Val Acc: 0.783505\n",
      "Epoch 19655 - Train Loss: 0.082196, Train Acc: 0.874359 | Val Loss: 0.111427, Val Acc: 0.783505\n",
      "Epoch 19656 - Train Loss: 0.082194, Train Acc: 0.874359 | Val Loss: 0.111426, Val Acc: 0.783505\n",
      "Epoch 19657 - Train Loss: 0.082191, Train Acc: 0.874359 | Val Loss: 0.111425, Val Acc: 0.783505\n",
      "Epoch 19658 - Train Loss: 0.082189, Train Acc: 0.874359 | Val Loss: 0.111424, Val Acc: 0.783505\n",
      "Epoch 19659 - Train Loss: 0.082187, Train Acc: 0.874359 | Val Loss: 0.111423, Val Acc: 0.783505\n",
      "Epoch 19660 - Train Loss: 0.082184, Train Acc: 0.874359 | Val Loss: 0.111422, Val Acc: 0.783505\n",
      "Epoch 19661 - Train Loss: 0.082182, Train Acc: 0.874359 | Val Loss: 0.111421, Val Acc: 0.783505\n",
      "Epoch 19662 - Train Loss: 0.082180, Train Acc: 0.874359 | Val Loss: 0.111420, Val Acc: 0.783505\n",
      "Epoch 19663 - Train Loss: 0.082177, Train Acc: 0.874359 | Val Loss: 0.111419, Val Acc: 0.783505\n",
      "Epoch 19664 - Train Loss: 0.082175, Train Acc: 0.874359 | Val Loss: 0.111418, Val Acc: 0.783505\n",
      "Epoch 19665 - Train Loss: 0.082172, Train Acc: 0.874359 | Val Loss: 0.111417, Val Acc: 0.783505\n",
      "Epoch 19666 - Train Loss: 0.082170, Train Acc: 0.874359 | Val Loss: 0.111416, Val Acc: 0.783505\n",
      "Epoch 19667 - Train Loss: 0.082168, Train Acc: 0.874359 | Val Loss: 0.111415, Val Acc: 0.783505\n",
      "Epoch 19668 - Train Loss: 0.082165, Train Acc: 0.874359 | Val Loss: 0.111414, Val Acc: 0.783505\n",
      "Epoch 19669 - Train Loss: 0.082163, Train Acc: 0.874359 | Val Loss: 0.111413, Val Acc: 0.783505\n",
      "Epoch 19670 - Train Loss: 0.082161, Train Acc: 0.874359 | Val Loss: 0.111412, Val Acc: 0.783505\n",
      "Epoch 19671 - Train Loss: 0.082158, Train Acc: 0.874359 | Val Loss: 0.111411, Val Acc: 0.783505\n",
      "Epoch 19672 - Train Loss: 0.082156, Train Acc: 0.874359 | Val Loss: 0.111410, Val Acc: 0.783505\n",
      "Epoch 19673 - Train Loss: 0.082153, Train Acc: 0.874359 | Val Loss: 0.111409, Val Acc: 0.783505\n",
      "Epoch 19674 - Train Loss: 0.082151, Train Acc: 0.874359 | Val Loss: 0.111408, Val Acc: 0.783505\n",
      "Epoch 19675 - Train Loss: 0.082149, Train Acc: 0.874359 | Val Loss: 0.111407, Val Acc: 0.783505\n",
      "Epoch 19676 - Train Loss: 0.082146, Train Acc: 0.874359 | Val Loss: 0.111405, Val Acc: 0.783505\n",
      "Epoch 19677 - Train Loss: 0.082144, Train Acc: 0.874359 | Val Loss: 0.111404, Val Acc: 0.783505\n",
      "Epoch 19678 - Train Loss: 0.082142, Train Acc: 0.874359 | Val Loss: 0.111403, Val Acc: 0.783505\n",
      "Epoch 19679 - Train Loss: 0.082139, Train Acc: 0.874359 | Val Loss: 0.111402, Val Acc: 0.783505\n",
      "Epoch 19680 - Train Loss: 0.082137, Train Acc: 0.874359 | Val Loss: 0.111401, Val Acc: 0.783505\n",
      "Epoch 19681 - Train Loss: 0.082134, Train Acc: 0.874359 | Val Loss: 0.111400, Val Acc: 0.783505\n",
      "Epoch 19682 - Train Loss: 0.082132, Train Acc: 0.874359 | Val Loss: 0.111399, Val Acc: 0.783505\n",
      "Epoch 19683 - Train Loss: 0.082130, Train Acc: 0.874359 | Val Loss: 0.111398, Val Acc: 0.783505\n",
      "Epoch 19684 - Train Loss: 0.082127, Train Acc: 0.875641 | Val Loss: 0.111397, Val Acc: 0.783505\n",
      "Epoch 19685 - Train Loss: 0.082125, Train Acc: 0.875641 | Val Loss: 0.111396, Val Acc: 0.783505\n",
      "Epoch 19686 - Train Loss: 0.082123, Train Acc: 0.875641 | Val Loss: 0.111395, Val Acc: 0.783505\n",
      "Epoch 19687 - Train Loss: 0.082120, Train Acc: 0.875641 | Val Loss: 0.111394, Val Acc: 0.783505\n",
      "Epoch 19688 - Train Loss: 0.082118, Train Acc: 0.875641 | Val Loss: 0.111393, Val Acc: 0.783505\n",
      "Epoch 19689 - Train Loss: 0.082115, Train Acc: 0.875641 | Val Loss: 0.111392, Val Acc: 0.783505\n",
      "Epoch 19690 - Train Loss: 0.082113, Train Acc: 0.875641 | Val Loss: 0.111391, Val Acc: 0.783505\n",
      "Epoch 19691 - Train Loss: 0.082111, Train Acc: 0.875641 | Val Loss: 0.111390, Val Acc: 0.783505\n",
      "Epoch 19692 - Train Loss: 0.082108, Train Acc: 0.875641 | Val Loss: 0.111389, Val Acc: 0.783505\n",
      "Epoch 19693 - Train Loss: 0.082106, Train Acc: 0.875641 | Val Loss: 0.111388, Val Acc: 0.783505\n",
      "Epoch 19694 - Train Loss: 0.082104, Train Acc: 0.875641 | Val Loss: 0.111387, Val Acc: 0.783505\n",
      "Epoch 19695 - Train Loss: 0.082101, Train Acc: 0.875641 | Val Loss: 0.111386, Val Acc: 0.783505\n",
      "Epoch 19696 - Train Loss: 0.082099, Train Acc: 0.875641 | Val Loss: 0.111385, Val Acc: 0.783505\n",
      "Epoch 19697 - Train Loss: 0.082096, Train Acc: 0.875641 | Val Loss: 0.111384, Val Acc: 0.783505\n",
      "Epoch 19698 - Train Loss: 0.082094, Train Acc: 0.875641 | Val Loss: 0.111382, Val Acc: 0.783505\n",
      "Epoch 19699 - Train Loss: 0.082092, Train Acc: 0.875641 | Val Loss: 0.111381, Val Acc: 0.783505\n",
      "Epoch 19700 - Train Loss: 0.082089, Train Acc: 0.875641 | Val Loss: 0.111380, Val Acc: 0.783505\n",
      "Epoch 19701 - Train Loss: 0.082087, Train Acc: 0.875641 | Val Loss: 0.111379, Val Acc: 0.783505\n",
      "Epoch 19702 - Train Loss: 0.082085, Train Acc: 0.875641 | Val Loss: 0.111378, Val Acc: 0.783505\n",
      "Epoch 19703 - Train Loss: 0.082082, Train Acc: 0.875641 | Val Loss: 0.111377, Val Acc: 0.783505\n",
      "Epoch 19704 - Train Loss: 0.082080, Train Acc: 0.875641 | Val Loss: 0.111376, Val Acc: 0.783505\n",
      "Epoch 19705 - Train Loss: 0.082077, Train Acc: 0.875641 | Val Loss: 0.111375, Val Acc: 0.783505\n",
      "Epoch 19706 - Train Loss: 0.082075, Train Acc: 0.875641 | Val Loss: 0.111374, Val Acc: 0.783505\n",
      "Epoch 19707 - Train Loss: 0.082073, Train Acc: 0.875641 | Val Loss: 0.111373, Val Acc: 0.783505\n",
      "Epoch 19708 - Train Loss: 0.082070, Train Acc: 0.875641 | Val Loss: 0.111372, Val Acc: 0.783505\n",
      "Epoch 19709 - Train Loss: 0.082068, Train Acc: 0.875641 | Val Loss: 0.111371, Val Acc: 0.783505\n",
      "Epoch 19710 - Train Loss: 0.082066, Train Acc: 0.875641 | Val Loss: 0.111370, Val Acc: 0.783505\n",
      "Epoch 19711 - Train Loss: 0.082063, Train Acc: 0.875641 | Val Loss: 0.111369, Val Acc: 0.783505\n",
      "Epoch 19712 - Train Loss: 0.082061, Train Acc: 0.875641 | Val Loss: 0.111368, Val Acc: 0.783505\n",
      "Epoch 19713 - Train Loss: 0.082058, Train Acc: 0.875641 | Val Loss: 0.111367, Val Acc: 0.783505\n",
      "Epoch 19714 - Train Loss: 0.082056, Train Acc: 0.875641 | Val Loss: 0.111366, Val Acc: 0.783505\n",
      "Epoch 19715 - Train Loss: 0.082054, Train Acc: 0.875641 | Val Loss: 0.111365, Val Acc: 0.783505\n",
      "Epoch 19716 - Train Loss: 0.082051, Train Acc: 0.875641 | Val Loss: 0.111364, Val Acc: 0.783505\n",
      "Epoch 19717 - Train Loss: 0.082049, Train Acc: 0.875641 | Val Loss: 0.111363, Val Acc: 0.783505\n",
      "Epoch 19718 - Train Loss: 0.082047, Train Acc: 0.875641 | Val Loss: 0.111362, Val Acc: 0.783505\n",
      "Epoch 19719 - Train Loss: 0.082044, Train Acc: 0.875641 | Val Loss: 0.111361, Val Acc: 0.783505\n",
      "Epoch 19720 - Train Loss: 0.082042, Train Acc: 0.875641 | Val Loss: 0.111360, Val Acc: 0.783505\n",
      "Epoch 19721 - Train Loss: 0.082040, Train Acc: 0.875641 | Val Loss: 0.111359, Val Acc: 0.783505\n",
      "Epoch 19722 - Train Loss: 0.082037, Train Acc: 0.875641 | Val Loss: 0.111358, Val Acc: 0.783505\n",
      "Epoch 19723 - Train Loss: 0.082035, Train Acc: 0.875641 | Val Loss: 0.111357, Val Acc: 0.783505\n",
      "Epoch 19724 - Train Loss: 0.082032, Train Acc: 0.875641 | Val Loss: 0.111356, Val Acc: 0.783505\n",
      "Epoch 19725 - Train Loss: 0.082030, Train Acc: 0.875641 | Val Loss: 0.111354, Val Acc: 0.783505\n",
      "Epoch 19726 - Train Loss: 0.082028, Train Acc: 0.875641 | Val Loss: 0.111353, Val Acc: 0.783505\n",
      "Epoch 19727 - Train Loss: 0.082025, Train Acc: 0.875641 | Val Loss: 0.111352, Val Acc: 0.783505\n",
      "Epoch 19728 - Train Loss: 0.082023, Train Acc: 0.875641 | Val Loss: 0.111351, Val Acc: 0.783505\n",
      "Epoch 19729 - Train Loss: 0.082021, Train Acc: 0.875641 | Val Loss: 0.111350, Val Acc: 0.783505\n",
      "Epoch 19730 - Train Loss: 0.082018, Train Acc: 0.875641 | Val Loss: 0.111349, Val Acc: 0.783505\n",
      "Epoch 19731 - Train Loss: 0.082016, Train Acc: 0.875641 | Val Loss: 0.111348, Val Acc: 0.783505\n",
      "Epoch 19732 - Train Loss: 0.082013, Train Acc: 0.875641 | Val Loss: 0.111347, Val Acc: 0.783505\n",
      "Epoch 19733 - Train Loss: 0.082011, Train Acc: 0.875641 | Val Loss: 0.111346, Val Acc: 0.783505\n",
      "Epoch 19734 - Train Loss: 0.082009, Train Acc: 0.875641 | Val Loss: 0.111345, Val Acc: 0.783505\n",
      "Epoch 19735 - Train Loss: 0.082006, Train Acc: 0.875641 | Val Loss: 0.111344, Val Acc: 0.783505\n",
      "Epoch 19736 - Train Loss: 0.082004, Train Acc: 0.875641 | Val Loss: 0.111343, Val Acc: 0.783505\n",
      "Epoch 19737 - Train Loss: 0.082002, Train Acc: 0.875641 | Val Loss: 0.111342, Val Acc: 0.783505\n",
      "Epoch 19738 - Train Loss: 0.081999, Train Acc: 0.875641 | Val Loss: 0.111341, Val Acc: 0.783505\n",
      "Epoch 19739 - Train Loss: 0.081997, Train Acc: 0.875641 | Val Loss: 0.111340, Val Acc: 0.783505\n",
      "Epoch 19740 - Train Loss: 0.081995, Train Acc: 0.875641 | Val Loss: 0.111339, Val Acc: 0.783505\n",
      "Epoch 19741 - Train Loss: 0.081992, Train Acc: 0.875641 | Val Loss: 0.111338, Val Acc: 0.783505\n",
      "Epoch 19742 - Train Loss: 0.081990, Train Acc: 0.875641 | Val Loss: 0.111337, Val Acc: 0.783505\n",
      "Epoch 19743 - Train Loss: 0.081988, Train Acc: 0.875641 | Val Loss: 0.111336, Val Acc: 0.783505\n",
      "Epoch 19744 - Train Loss: 0.081985, Train Acc: 0.875641 | Val Loss: 0.111335, Val Acc: 0.783505\n",
      "Epoch 19745 - Train Loss: 0.081983, Train Acc: 0.875641 | Val Loss: 0.111334, Val Acc: 0.783505\n",
      "Epoch 19746 - Train Loss: 0.081980, Train Acc: 0.875641 | Val Loss: 0.111333, Val Acc: 0.783505\n",
      "Epoch 19747 - Train Loss: 0.081978, Train Acc: 0.875641 | Val Loss: 0.111332, Val Acc: 0.783505\n",
      "Epoch 19748 - Train Loss: 0.081976, Train Acc: 0.875641 | Val Loss: 0.111331, Val Acc: 0.783505\n",
      "Epoch 19749 - Train Loss: 0.081973, Train Acc: 0.875641 | Val Loss: 0.111330, Val Acc: 0.783505\n",
      "Epoch 19750 - Train Loss: 0.081971, Train Acc: 0.875641 | Val Loss: 0.111329, Val Acc: 0.783505\n",
      "Epoch 19751 - Train Loss: 0.081969, Train Acc: 0.875641 | Val Loss: 0.111328, Val Acc: 0.783505\n",
      "Epoch 19752 - Train Loss: 0.081966, Train Acc: 0.875641 | Val Loss: 0.111327, Val Acc: 0.783505\n",
      "Epoch 19753 - Train Loss: 0.081964, Train Acc: 0.875641 | Val Loss: 0.111326, Val Acc: 0.783505\n",
      "Epoch 19754 - Train Loss: 0.081962, Train Acc: 0.875641 | Val Loss: 0.111325, Val Acc: 0.783505\n",
      "Epoch 19755 - Train Loss: 0.081959, Train Acc: 0.875641 | Val Loss: 0.111324, Val Acc: 0.783505\n",
      "Epoch 19756 - Train Loss: 0.081957, Train Acc: 0.875641 | Val Loss: 0.111323, Val Acc: 0.783505\n",
      "Epoch 19757 - Train Loss: 0.081954, Train Acc: 0.875641 | Val Loss: 0.111322, Val Acc: 0.783505\n",
      "Epoch 19758 - Train Loss: 0.081952, Train Acc: 0.875641 | Val Loss: 0.111321, Val Acc: 0.783505\n",
      "Epoch 19759 - Train Loss: 0.081950, Train Acc: 0.875641 | Val Loss: 0.111320, Val Acc: 0.783505\n",
      "Epoch 19760 - Train Loss: 0.081947, Train Acc: 0.875641 | Val Loss: 0.111318, Val Acc: 0.783505\n",
      "Epoch 19761 - Train Loss: 0.081945, Train Acc: 0.875641 | Val Loss: 0.111317, Val Acc: 0.783505\n",
      "Epoch 19762 - Train Loss: 0.081943, Train Acc: 0.875641 | Val Loss: 0.111316, Val Acc: 0.783505\n",
      "Epoch 19763 - Train Loss: 0.081940, Train Acc: 0.875641 | Val Loss: 0.111315, Val Acc: 0.783505\n",
      "Epoch 19764 - Train Loss: 0.081938, Train Acc: 0.875641 | Val Loss: 0.111314, Val Acc: 0.783505\n",
      "Epoch 19765 - Train Loss: 0.081936, Train Acc: 0.875641 | Val Loss: 0.111313, Val Acc: 0.783505\n",
      "Epoch 19766 - Train Loss: 0.081933, Train Acc: 0.875641 | Val Loss: 0.111312, Val Acc: 0.783505\n",
      "Epoch 19767 - Train Loss: 0.081931, Train Acc: 0.875641 | Val Loss: 0.111311, Val Acc: 0.783505\n",
      "Epoch 19768 - Train Loss: 0.081929, Train Acc: 0.875641 | Val Loss: 0.111310, Val Acc: 0.783505\n",
      "Epoch 19769 - Train Loss: 0.081926, Train Acc: 0.875641 | Val Loss: 0.111309, Val Acc: 0.783505\n",
      "Epoch 19770 - Train Loss: 0.081924, Train Acc: 0.875641 | Val Loss: 0.111308, Val Acc: 0.783505\n",
      "Epoch 19771 - Train Loss: 0.081921, Train Acc: 0.875641 | Val Loss: 0.111307, Val Acc: 0.783505\n",
      "Epoch 19772 - Train Loss: 0.081919, Train Acc: 0.875641 | Val Loss: 0.111306, Val Acc: 0.783505\n",
      "Epoch 19773 - Train Loss: 0.081917, Train Acc: 0.875641 | Val Loss: 0.111305, Val Acc: 0.783505\n",
      "Epoch 19774 - Train Loss: 0.081914, Train Acc: 0.875641 | Val Loss: 0.111304, Val Acc: 0.783505\n",
      "Epoch 19775 - Train Loss: 0.081912, Train Acc: 0.875641 | Val Loss: 0.111303, Val Acc: 0.783505\n",
      "Epoch 19776 - Train Loss: 0.081910, Train Acc: 0.875641 | Val Loss: 0.111302, Val Acc: 0.783505\n",
      "Epoch 19777 - Train Loss: 0.081907, Train Acc: 0.875641 | Val Loss: 0.111301, Val Acc: 0.783505\n",
      "Epoch 19778 - Train Loss: 0.081905, Train Acc: 0.875641 | Val Loss: 0.111300, Val Acc: 0.783505\n",
      "Epoch 19779 - Train Loss: 0.081903, Train Acc: 0.875641 | Val Loss: 0.111299, Val Acc: 0.783505\n",
      "Epoch 19780 - Train Loss: 0.081900, Train Acc: 0.875641 | Val Loss: 0.111298, Val Acc: 0.783505\n",
      "Epoch 19781 - Train Loss: 0.081898, Train Acc: 0.875641 | Val Loss: 0.111297, Val Acc: 0.783505\n",
      "Epoch 19782 - Train Loss: 0.081896, Train Acc: 0.875641 | Val Loss: 0.111296, Val Acc: 0.783505\n",
      "Epoch 19783 - Train Loss: 0.081893, Train Acc: 0.875641 | Val Loss: 0.111295, Val Acc: 0.783505\n",
      "Epoch 19784 - Train Loss: 0.081891, Train Acc: 0.875641 | Val Loss: 0.111294, Val Acc: 0.783505\n",
      "Epoch 19785 - Train Loss: 0.081888, Train Acc: 0.875641 | Val Loss: 0.111293, Val Acc: 0.783505\n",
      "Epoch 19786 - Train Loss: 0.081886, Train Acc: 0.875641 | Val Loss: 0.111292, Val Acc: 0.783505\n",
      "Epoch 19787 - Train Loss: 0.081884, Train Acc: 0.875641 | Val Loss: 0.111291, Val Acc: 0.783505\n",
      "Epoch 19788 - Train Loss: 0.081881, Train Acc: 0.875641 | Val Loss: 0.111290, Val Acc: 0.783505\n",
      "Epoch 19789 - Train Loss: 0.081879, Train Acc: 0.875641 | Val Loss: 0.111289, Val Acc: 0.783505\n",
      "Epoch 19790 - Train Loss: 0.081877, Train Acc: 0.875641 | Val Loss: 0.111288, Val Acc: 0.783505\n",
      "Epoch 19791 - Train Loss: 0.081874, Train Acc: 0.875641 | Val Loss: 0.111287, Val Acc: 0.783505\n",
      "Epoch 19792 - Train Loss: 0.081872, Train Acc: 0.875641 | Val Loss: 0.111286, Val Acc: 0.783505\n",
      "Epoch 19793 - Train Loss: 0.081870, Train Acc: 0.875641 | Val Loss: 0.111285, Val Acc: 0.783505\n",
      "Epoch 19794 - Train Loss: 0.081867, Train Acc: 0.875641 | Val Loss: 0.111284, Val Acc: 0.783505\n",
      "Epoch 19795 - Train Loss: 0.081865, Train Acc: 0.875641 | Val Loss: 0.111283, Val Acc: 0.783505\n",
      "Epoch 19796 - Train Loss: 0.081863, Train Acc: 0.875641 | Val Loss: 0.111282, Val Acc: 0.783505\n",
      "Epoch 19797 - Train Loss: 0.081860, Train Acc: 0.875641 | Val Loss: 0.111281, Val Acc: 0.783505\n",
      "Epoch 19798 - Train Loss: 0.081858, Train Acc: 0.875641 | Val Loss: 0.111280, Val Acc: 0.783505\n",
      "Epoch 19799 - Train Loss: 0.081856, Train Acc: 0.875641 | Val Loss: 0.111279, Val Acc: 0.783505\n",
      "Epoch 19800 - Train Loss: 0.081853, Train Acc: 0.875641 | Val Loss: 0.111277, Val Acc: 0.783505\n",
      "Epoch 19801 - Train Loss: 0.081851, Train Acc: 0.875641 | Val Loss: 0.111276, Val Acc: 0.783505\n",
      "Epoch 19802 - Train Loss: 0.081849, Train Acc: 0.875641 | Val Loss: 0.111275, Val Acc: 0.783505\n",
      "Epoch 19803 - Train Loss: 0.081846, Train Acc: 0.875641 | Val Loss: 0.111274, Val Acc: 0.783505\n",
      "Epoch 19804 - Train Loss: 0.081844, Train Acc: 0.875641 | Val Loss: 0.111273, Val Acc: 0.783505\n",
      "Epoch 19805 - Train Loss: 0.081841, Train Acc: 0.875641 | Val Loss: 0.111272, Val Acc: 0.783505\n",
      "Epoch 19806 - Train Loss: 0.081839, Train Acc: 0.875641 | Val Loss: 0.111271, Val Acc: 0.783505\n",
      "Epoch 19807 - Train Loss: 0.081837, Train Acc: 0.875641 | Val Loss: 0.111270, Val Acc: 0.783505\n",
      "Epoch 19808 - Train Loss: 0.081834, Train Acc: 0.875641 | Val Loss: 0.111269, Val Acc: 0.783505\n",
      "Epoch 19809 - Train Loss: 0.081832, Train Acc: 0.875641 | Val Loss: 0.111268, Val Acc: 0.783505\n",
      "Epoch 19810 - Train Loss: 0.081830, Train Acc: 0.875641 | Val Loss: 0.111267, Val Acc: 0.783505\n",
      "Epoch 19811 - Train Loss: 0.081827, Train Acc: 0.875641 | Val Loss: 0.111266, Val Acc: 0.783505\n",
      "Epoch 19812 - Train Loss: 0.081825, Train Acc: 0.875641 | Val Loss: 0.111265, Val Acc: 0.783505\n",
      "Epoch 19813 - Train Loss: 0.081823, Train Acc: 0.875641 | Val Loss: 0.111264, Val Acc: 0.783505\n",
      "Epoch 19814 - Train Loss: 0.081820, Train Acc: 0.875641 | Val Loss: 0.111263, Val Acc: 0.783505\n",
      "Epoch 19815 - Train Loss: 0.081818, Train Acc: 0.875641 | Val Loss: 0.111262, Val Acc: 0.783505\n",
      "Epoch 19816 - Train Loss: 0.081816, Train Acc: 0.875641 | Val Loss: 0.111261, Val Acc: 0.783505\n",
      "Epoch 19817 - Train Loss: 0.081813, Train Acc: 0.875641 | Val Loss: 0.111260, Val Acc: 0.783505\n",
      "Epoch 19818 - Train Loss: 0.081811, Train Acc: 0.875641 | Val Loss: 0.111259, Val Acc: 0.783505\n",
      "Epoch 19819 - Train Loss: 0.081809, Train Acc: 0.875641 | Val Loss: 0.111258, Val Acc: 0.783505\n",
      "Epoch 19820 - Train Loss: 0.081806, Train Acc: 0.875641 | Val Loss: 0.111257, Val Acc: 0.783505\n",
      "Epoch 19821 - Train Loss: 0.081804, Train Acc: 0.875641 | Val Loss: 0.111256, Val Acc: 0.783505\n",
      "Epoch 19822 - Train Loss: 0.081802, Train Acc: 0.875641 | Val Loss: 0.111255, Val Acc: 0.783505\n",
      "Epoch 19823 - Train Loss: 0.081799, Train Acc: 0.875641 | Val Loss: 0.111254, Val Acc: 0.783505\n",
      "Epoch 19824 - Train Loss: 0.081797, Train Acc: 0.875641 | Val Loss: 0.111253, Val Acc: 0.783505\n",
      "Epoch 19825 - Train Loss: 0.081795, Train Acc: 0.875641 | Val Loss: 0.111252, Val Acc: 0.783505\n",
      "Epoch 19826 - Train Loss: 0.081792, Train Acc: 0.875641 | Val Loss: 0.111251, Val Acc: 0.783505\n",
      "Epoch 19827 - Train Loss: 0.081790, Train Acc: 0.875641 | Val Loss: 0.111250, Val Acc: 0.783505\n",
      "Epoch 19828 - Train Loss: 0.081787, Train Acc: 0.875641 | Val Loss: 0.111249, Val Acc: 0.783505\n",
      "Epoch 19829 - Train Loss: 0.081785, Train Acc: 0.875641 | Val Loss: 0.111248, Val Acc: 0.783505\n",
      "Epoch 19830 - Train Loss: 0.081783, Train Acc: 0.875641 | Val Loss: 0.111247, Val Acc: 0.783505\n",
      "Epoch 19831 - Train Loss: 0.081780, Train Acc: 0.875641 | Val Loss: 0.111246, Val Acc: 0.783505\n",
      "Epoch 19832 - Train Loss: 0.081778, Train Acc: 0.875641 | Val Loss: 0.111245, Val Acc: 0.783505\n",
      "Epoch 19833 - Train Loss: 0.081776, Train Acc: 0.875641 | Val Loss: 0.111244, Val Acc: 0.783505\n",
      "Epoch 19834 - Train Loss: 0.081773, Train Acc: 0.875641 | Val Loss: 0.111243, Val Acc: 0.783505\n",
      "Epoch 19835 - Train Loss: 0.081771, Train Acc: 0.875641 | Val Loss: 0.111242, Val Acc: 0.783505\n",
      "Epoch 19836 - Train Loss: 0.081769, Train Acc: 0.875641 | Val Loss: 0.111241, Val Acc: 0.783505\n",
      "Epoch 19837 - Train Loss: 0.081766, Train Acc: 0.875641 | Val Loss: 0.111240, Val Acc: 0.783505\n",
      "Epoch 19838 - Train Loss: 0.081764, Train Acc: 0.875641 | Val Loss: 0.111239, Val Acc: 0.783505\n",
      "Epoch 19839 - Train Loss: 0.081762, Train Acc: 0.875641 | Val Loss: 0.111238, Val Acc: 0.783505\n",
      "Epoch 19840 - Train Loss: 0.081759, Train Acc: 0.875641 | Val Loss: 0.111237, Val Acc: 0.783505\n",
      "Epoch 19841 - Train Loss: 0.081757, Train Acc: 0.875641 | Val Loss: 0.111236, Val Acc: 0.783505\n",
      "Epoch 19842 - Train Loss: 0.081755, Train Acc: 0.875641 | Val Loss: 0.111235, Val Acc: 0.783505\n",
      "Epoch 19843 - Train Loss: 0.081752, Train Acc: 0.875641 | Val Loss: 0.111234, Val Acc: 0.783505\n",
      "Epoch 19844 - Train Loss: 0.081750, Train Acc: 0.875641 | Val Loss: 0.111233, Val Acc: 0.783505\n",
      "Epoch 19845 - Train Loss: 0.081748, Train Acc: 0.875641 | Val Loss: 0.111232, Val Acc: 0.783505\n",
      "Epoch 19846 - Train Loss: 0.081745, Train Acc: 0.875641 | Val Loss: 0.111231, Val Acc: 0.783505\n",
      "Epoch 19847 - Train Loss: 0.081743, Train Acc: 0.875641 | Val Loss: 0.111230, Val Acc: 0.783505\n",
      "Epoch 19848 - Train Loss: 0.081741, Train Acc: 0.875641 | Val Loss: 0.111229, Val Acc: 0.783505\n",
      "Epoch 19849 - Train Loss: 0.081738, Train Acc: 0.875641 | Val Loss: 0.111228, Val Acc: 0.783505\n",
      "Epoch 19850 - Train Loss: 0.081736, Train Acc: 0.875641 | Val Loss: 0.111227, Val Acc: 0.783505\n",
      "Epoch 19851 - Train Loss: 0.081734, Train Acc: 0.875641 | Val Loss: 0.111226, Val Acc: 0.783505\n",
      "Epoch 19852 - Train Loss: 0.081731, Train Acc: 0.875641 | Val Loss: 0.111225, Val Acc: 0.783505\n",
      "Epoch 19853 - Train Loss: 0.081729, Train Acc: 0.875641 | Val Loss: 0.111224, Val Acc: 0.783505\n",
      "Epoch 19854 - Train Loss: 0.081727, Train Acc: 0.875641 | Val Loss: 0.111223, Val Acc: 0.783505\n",
      "Epoch 19855 - Train Loss: 0.081724, Train Acc: 0.875641 | Val Loss: 0.111222, Val Acc: 0.783505\n",
      "Epoch 19856 - Train Loss: 0.081722, Train Acc: 0.875641 | Val Loss: 0.111221, Val Acc: 0.783505\n",
      "Epoch 19857 - Train Loss: 0.081720, Train Acc: 0.875641 | Val Loss: 0.111220, Val Acc: 0.783505\n",
      "Epoch 19858 - Train Loss: 0.081717, Train Acc: 0.875641 | Val Loss: 0.111219, Val Acc: 0.783505\n",
      "Epoch 19859 - Train Loss: 0.081715, Train Acc: 0.875641 | Val Loss: 0.111218, Val Acc: 0.783505\n",
      "Epoch 19860 - Train Loss: 0.081713, Train Acc: 0.875641 | Val Loss: 0.111217, Val Acc: 0.783505\n",
      "Epoch 19861 - Train Loss: 0.081710, Train Acc: 0.875641 | Val Loss: 0.111216, Val Acc: 0.783505\n",
      "Epoch 19862 - Train Loss: 0.081708, Train Acc: 0.875641 | Val Loss: 0.111215, Val Acc: 0.783505\n",
      "Epoch 19863 - Train Loss: 0.081706, Train Acc: 0.875641 | Val Loss: 0.111214, Val Acc: 0.783505\n",
      "Epoch 19864 - Train Loss: 0.081703, Train Acc: 0.875641 | Val Loss: 0.111213, Val Acc: 0.783505\n",
      "Epoch 19865 - Train Loss: 0.081701, Train Acc: 0.875641 | Val Loss: 0.111212, Val Acc: 0.783505\n",
      "Epoch 19866 - Train Loss: 0.081699, Train Acc: 0.875641 | Val Loss: 0.111211, Val Acc: 0.783505\n",
      "Epoch 19867 - Train Loss: 0.081696, Train Acc: 0.875641 | Val Loss: 0.111210, Val Acc: 0.783505\n",
      "Epoch 19868 - Train Loss: 0.081694, Train Acc: 0.875641 | Val Loss: 0.111209, Val Acc: 0.783505\n",
      "Epoch 19869 - Train Loss: 0.081692, Train Acc: 0.875641 | Val Loss: 0.111208, Val Acc: 0.783505\n",
      "Epoch 19870 - Train Loss: 0.081689, Train Acc: 0.875641 | Val Loss: 0.111207, Val Acc: 0.783505\n",
      "Epoch 19871 - Train Loss: 0.081687, Train Acc: 0.875641 | Val Loss: 0.111206, Val Acc: 0.783505\n",
      "Epoch 19872 - Train Loss: 0.081685, Train Acc: 0.875641 | Val Loss: 0.111205, Val Acc: 0.783505\n",
      "Epoch 19873 - Train Loss: 0.081682, Train Acc: 0.875641 | Val Loss: 0.111204, Val Acc: 0.783505\n",
      "Epoch 19874 - Train Loss: 0.081680, Train Acc: 0.875641 | Val Loss: 0.111203, Val Acc: 0.783505\n",
      "Epoch 19875 - Train Loss: 0.081678, Train Acc: 0.875641 | Val Loss: 0.111202, Val Acc: 0.783505\n",
      "Epoch 19876 - Train Loss: 0.081675, Train Acc: 0.875641 | Val Loss: 0.111201, Val Acc: 0.783505\n",
      "Epoch 19877 - Train Loss: 0.081673, Train Acc: 0.875641 | Val Loss: 0.111201, Val Acc: 0.783505\n",
      "Epoch 19878 - Train Loss: 0.081671, Train Acc: 0.875641 | Val Loss: 0.111200, Val Acc: 0.783505\n",
      "Epoch 19879 - Train Loss: 0.081668, Train Acc: 0.875641 | Val Loss: 0.111199, Val Acc: 0.783505\n",
      "Epoch 19880 - Train Loss: 0.081666, Train Acc: 0.875641 | Val Loss: 0.111198, Val Acc: 0.783505\n",
      "Epoch 19881 - Train Loss: 0.081664, Train Acc: 0.875641 | Val Loss: 0.111197, Val Acc: 0.783505\n",
      "Epoch 19882 - Train Loss: 0.081661, Train Acc: 0.875641 | Val Loss: 0.111196, Val Acc: 0.783505\n",
      "Epoch 19883 - Train Loss: 0.081659, Train Acc: 0.875641 | Val Loss: 0.111195, Val Acc: 0.783505\n",
      "Epoch 19884 - Train Loss: 0.081657, Train Acc: 0.875641 | Val Loss: 0.111194, Val Acc: 0.783505\n",
      "Epoch 19885 - Train Loss: 0.081654, Train Acc: 0.875641 | Val Loss: 0.111193, Val Acc: 0.783505\n",
      "Epoch 19886 - Train Loss: 0.081652, Train Acc: 0.875641 | Val Loss: 0.111192, Val Acc: 0.783505\n",
      "Epoch 19887 - Train Loss: 0.081650, Train Acc: 0.875641 | Val Loss: 0.111191, Val Acc: 0.783505\n",
      "Epoch 19888 - Train Loss: 0.081647, Train Acc: 0.875641 | Val Loss: 0.111190, Val Acc: 0.783505\n",
      "Epoch 19889 - Train Loss: 0.081645, Train Acc: 0.875641 | Val Loss: 0.111189, Val Acc: 0.783505\n",
      "Epoch 19890 - Train Loss: 0.081643, Train Acc: 0.875641 | Val Loss: 0.111188, Val Acc: 0.783505\n",
      "Epoch 19891 - Train Loss: 0.081640, Train Acc: 0.875641 | Val Loss: 0.111187, Val Acc: 0.783505\n",
      "Epoch 19892 - Train Loss: 0.081638, Train Acc: 0.875641 | Val Loss: 0.111186, Val Acc: 0.783505\n",
      "Epoch 19893 - Train Loss: 0.081636, Train Acc: 0.875641 | Val Loss: 0.111185, Val Acc: 0.783505\n",
      "Epoch 19894 - Train Loss: 0.081633, Train Acc: 0.875641 | Val Loss: 0.111184, Val Acc: 0.783505\n",
      "Epoch 19895 - Train Loss: 0.081631, Train Acc: 0.875641 | Val Loss: 0.111183, Val Acc: 0.783505\n",
      "Epoch 19896 - Train Loss: 0.081629, Train Acc: 0.875641 | Val Loss: 0.111182, Val Acc: 0.783505\n",
      "Epoch 19897 - Train Loss: 0.081626, Train Acc: 0.875641 | Val Loss: 0.111181, Val Acc: 0.783505\n",
      "Epoch 19898 - Train Loss: 0.081624, Train Acc: 0.875641 | Val Loss: 0.111180, Val Acc: 0.783505\n",
      "Epoch 19899 - Train Loss: 0.081622, Train Acc: 0.875641 | Val Loss: 0.111179, Val Acc: 0.783505\n",
      "Epoch 19900 - Train Loss: 0.081620, Train Acc: 0.875641 | Val Loss: 0.111178, Val Acc: 0.783505\n",
      "Epoch 19901 - Train Loss: 0.081617, Train Acc: 0.875641 | Val Loss: 0.111177, Val Acc: 0.783505\n",
      "Epoch 19902 - Train Loss: 0.081615, Train Acc: 0.875641 | Val Loss: 0.111176, Val Acc: 0.783505\n",
      "Epoch 19903 - Train Loss: 0.081613, Train Acc: 0.875641 | Val Loss: 0.111175, Val Acc: 0.783505\n",
      "Epoch 19904 - Train Loss: 0.081610, Train Acc: 0.875641 | Val Loss: 0.111174, Val Acc: 0.783505\n",
      "Epoch 19905 - Train Loss: 0.081608, Train Acc: 0.875641 | Val Loss: 0.111173, Val Acc: 0.783505\n",
      "Epoch 19906 - Train Loss: 0.081606, Train Acc: 0.875641 | Val Loss: 0.111172, Val Acc: 0.783505\n",
      "Epoch 19907 - Train Loss: 0.081603, Train Acc: 0.875641 | Val Loss: 0.111171, Val Acc: 0.783505\n",
      "Epoch 19908 - Train Loss: 0.081601, Train Acc: 0.875641 | Val Loss: 0.111170, Val Acc: 0.783505\n",
      "Epoch 19909 - Train Loss: 0.081599, Train Acc: 0.875641 | Val Loss: 0.111169, Val Acc: 0.783505\n",
      "Epoch 19910 - Train Loss: 0.081596, Train Acc: 0.875641 | Val Loss: 0.111168, Val Acc: 0.783505\n",
      "Epoch 19911 - Train Loss: 0.081594, Train Acc: 0.875641 | Val Loss: 0.111167, Val Acc: 0.783505\n",
      "Epoch 19912 - Train Loss: 0.081592, Train Acc: 0.875641 | Val Loss: 0.111166, Val Acc: 0.783505\n",
      "Epoch 19913 - Train Loss: 0.081589, Train Acc: 0.875641 | Val Loss: 0.111165, Val Acc: 0.783505\n",
      "Epoch 19914 - Train Loss: 0.081587, Train Acc: 0.875641 | Val Loss: 0.111164, Val Acc: 0.783505\n",
      "Epoch 19915 - Train Loss: 0.081585, Train Acc: 0.875641 | Val Loss: 0.111163, Val Acc: 0.783505\n",
      "Epoch 19916 - Train Loss: 0.081582, Train Acc: 0.875641 | Val Loss: 0.111162, Val Acc: 0.783505\n",
      "Epoch 19917 - Train Loss: 0.081580, Train Acc: 0.875641 | Val Loss: 0.111161, Val Acc: 0.783505\n",
      "Epoch 19918 - Train Loss: 0.081578, Train Acc: 0.875641 | Val Loss: 0.111160, Val Acc: 0.783505\n",
      "Epoch 19919 - Train Loss: 0.081575, Train Acc: 0.875641 | Val Loss: 0.111159, Val Acc: 0.783505\n",
      "Epoch 19920 - Train Loss: 0.081573, Train Acc: 0.875641 | Val Loss: 0.111158, Val Acc: 0.783505\n",
      "Epoch 19921 - Train Loss: 0.081571, Train Acc: 0.875641 | Val Loss: 0.111157, Val Acc: 0.783505\n",
      "Epoch 19922 - Train Loss: 0.081568, Train Acc: 0.875641 | Val Loss: 0.111156, Val Acc: 0.783505\n",
      "Epoch 19923 - Train Loss: 0.081566, Train Acc: 0.875641 | Val Loss: 0.111155, Val Acc: 0.783505\n",
      "Epoch 19924 - Train Loss: 0.081564, Train Acc: 0.875641 | Val Loss: 0.111154, Val Acc: 0.783505\n",
      "Epoch 19925 - Train Loss: 0.081562, Train Acc: 0.875641 | Val Loss: 0.111153, Val Acc: 0.783505\n",
      "Epoch 19926 - Train Loss: 0.081559, Train Acc: 0.875641 | Val Loss: 0.111152, Val Acc: 0.783505\n",
      "Epoch 19927 - Train Loss: 0.081557, Train Acc: 0.875641 | Val Loss: 0.111151, Val Acc: 0.783505\n",
      "Epoch 19928 - Train Loss: 0.081555, Train Acc: 0.875641 | Val Loss: 0.111150, Val Acc: 0.783505\n",
      "Epoch 19929 - Train Loss: 0.081552, Train Acc: 0.875641 | Val Loss: 0.111149, Val Acc: 0.783505\n",
      "Epoch 19930 - Train Loss: 0.081550, Train Acc: 0.875641 | Val Loss: 0.111148, Val Acc: 0.783505\n",
      "Epoch 19931 - Train Loss: 0.081548, Train Acc: 0.875641 | Val Loss: 0.111147, Val Acc: 0.783505\n",
      "Epoch 19932 - Train Loss: 0.081545, Train Acc: 0.875641 | Val Loss: 0.111146, Val Acc: 0.783505\n",
      "Epoch 19933 - Train Loss: 0.081543, Train Acc: 0.875641 | Val Loss: 0.111145, Val Acc: 0.783505\n",
      "Epoch 19934 - Train Loss: 0.081541, Train Acc: 0.875641 | Val Loss: 0.111144, Val Acc: 0.783505\n",
      "Epoch 19935 - Train Loss: 0.081538, Train Acc: 0.875641 | Val Loss: 0.111143, Val Acc: 0.783505\n",
      "Epoch 19936 - Train Loss: 0.081536, Train Acc: 0.875641 | Val Loss: 0.111142, Val Acc: 0.783505\n",
      "Epoch 19937 - Train Loss: 0.081534, Train Acc: 0.875641 | Val Loss: 0.111141, Val Acc: 0.783505\n",
      "Epoch 19938 - Train Loss: 0.081531, Train Acc: 0.875641 | Val Loss: 0.111140, Val Acc: 0.783505\n",
      "Epoch 19939 - Train Loss: 0.081529, Train Acc: 0.875641 | Val Loss: 0.111139, Val Acc: 0.783505\n",
      "Epoch 19940 - Train Loss: 0.081527, Train Acc: 0.875641 | Val Loss: 0.111138, Val Acc: 0.783505\n",
      "Epoch 19941 - Train Loss: 0.081524, Train Acc: 0.875641 | Val Loss: 0.111137, Val Acc: 0.783505\n",
      "Epoch 19942 - Train Loss: 0.081522, Train Acc: 0.875641 | Val Loss: 0.111136, Val Acc: 0.783505\n",
      "Epoch 19943 - Train Loss: 0.081520, Train Acc: 0.875641 | Val Loss: 0.111135, Val Acc: 0.783505\n",
      "Epoch 19944 - Train Loss: 0.081518, Train Acc: 0.875641 | Val Loss: 0.111134, Val Acc: 0.783505\n",
      "Epoch 19945 - Train Loss: 0.081515, Train Acc: 0.875641 | Val Loss: 0.111133, Val Acc: 0.783505\n",
      "Epoch 19946 - Train Loss: 0.081513, Train Acc: 0.875641 | Val Loss: 0.111132, Val Acc: 0.783505\n",
      "Epoch 19947 - Train Loss: 0.081511, Train Acc: 0.875641 | Val Loss: 0.111131, Val Acc: 0.783505\n",
      "Epoch 19948 - Train Loss: 0.081508, Train Acc: 0.875641 | Val Loss: 0.111130, Val Acc: 0.783505\n",
      "Epoch 19949 - Train Loss: 0.081506, Train Acc: 0.875641 | Val Loss: 0.111129, Val Acc: 0.783505\n",
      "Epoch 19950 - Train Loss: 0.081504, Train Acc: 0.875641 | Val Loss: 0.111128, Val Acc: 0.783505\n",
      "Epoch 19951 - Train Loss: 0.081501, Train Acc: 0.875641 | Val Loss: 0.111127, Val Acc: 0.783505\n",
      "Epoch 19952 - Train Loss: 0.081499, Train Acc: 0.875641 | Val Loss: 0.111126, Val Acc: 0.783505\n",
      "Epoch 19953 - Train Loss: 0.081497, Train Acc: 0.875641 | Val Loss: 0.111125, Val Acc: 0.783505\n",
      "Epoch 19954 - Train Loss: 0.081494, Train Acc: 0.875641 | Val Loss: 0.111124, Val Acc: 0.783505\n",
      "Epoch 19955 - Train Loss: 0.081492, Train Acc: 0.875641 | Val Loss: 0.111123, Val Acc: 0.783505\n",
      "Epoch 19956 - Train Loss: 0.081490, Train Acc: 0.875641 | Val Loss: 0.111122, Val Acc: 0.783505\n",
      "Epoch 19957 - Train Loss: 0.081487, Train Acc: 0.875641 | Val Loss: 0.111121, Val Acc: 0.783505\n",
      "Epoch 19958 - Train Loss: 0.081485, Train Acc: 0.875641 | Val Loss: 0.111120, Val Acc: 0.783505\n",
      "Epoch 19959 - Train Loss: 0.081483, Train Acc: 0.875641 | Val Loss: 0.111119, Val Acc: 0.783505\n",
      "Epoch 19960 - Train Loss: 0.081481, Train Acc: 0.875641 | Val Loss: 0.111118, Val Acc: 0.783505\n",
      "Epoch 19961 - Train Loss: 0.081478, Train Acc: 0.875641 | Val Loss: 0.111117, Val Acc: 0.783505\n",
      "Epoch 19962 - Train Loss: 0.081476, Train Acc: 0.875641 | Val Loss: 0.111116, Val Acc: 0.783505\n",
      "Epoch 19963 - Train Loss: 0.081474, Train Acc: 0.875641 | Val Loss: 0.111116, Val Acc: 0.783505\n",
      "Epoch 19964 - Train Loss: 0.081471, Train Acc: 0.875641 | Val Loss: 0.111115, Val Acc: 0.783505\n",
      "Epoch 19965 - Train Loss: 0.081469, Train Acc: 0.875641 | Val Loss: 0.111114, Val Acc: 0.783505\n",
      "Epoch 19966 - Train Loss: 0.081467, Train Acc: 0.875641 | Val Loss: 0.111113, Val Acc: 0.783505\n",
      "Epoch 19967 - Train Loss: 0.081464, Train Acc: 0.875641 | Val Loss: 0.111112, Val Acc: 0.783505\n",
      "Epoch 19968 - Train Loss: 0.081462, Train Acc: 0.875641 | Val Loss: 0.111111, Val Acc: 0.783505\n",
      "Epoch 19969 - Train Loss: 0.081460, Train Acc: 0.875641 | Val Loss: 0.111110, Val Acc: 0.783505\n",
      "Epoch 19970 - Train Loss: 0.081457, Train Acc: 0.875641 | Val Loss: 0.111109, Val Acc: 0.783505\n",
      "Epoch 19971 - Train Loss: 0.081455, Train Acc: 0.875641 | Val Loss: 0.111108, Val Acc: 0.783505\n",
      "Epoch 19972 - Train Loss: 0.081453, Train Acc: 0.875641 | Val Loss: 0.111107, Val Acc: 0.783505\n",
      "Epoch 19973 - Train Loss: 0.081451, Train Acc: 0.875641 | Val Loss: 0.111106, Val Acc: 0.783505\n",
      "Epoch 19974 - Train Loss: 0.081448, Train Acc: 0.875641 | Val Loss: 0.111105, Val Acc: 0.783505\n",
      "Epoch 19975 - Train Loss: 0.081446, Train Acc: 0.875641 | Val Loss: 0.111104, Val Acc: 0.783505\n",
      "Epoch 19976 - Train Loss: 0.081444, Train Acc: 0.875641 | Val Loss: 0.111103, Val Acc: 0.783505\n",
      "Epoch 19977 - Train Loss: 0.081441, Train Acc: 0.875641 | Val Loss: 0.111102, Val Acc: 0.783505\n",
      "Epoch 19978 - Train Loss: 0.081439, Train Acc: 0.875641 | Val Loss: 0.111101, Val Acc: 0.783505\n",
      "Epoch 19979 - Train Loss: 0.081437, Train Acc: 0.875641 | Val Loss: 0.111100, Val Acc: 0.783505\n",
      "Epoch 19980 - Train Loss: 0.081434, Train Acc: 0.875641 | Val Loss: 0.111099, Val Acc: 0.783505\n",
      "Epoch 19981 - Train Loss: 0.081432, Train Acc: 0.875641 | Val Loss: 0.111098, Val Acc: 0.783505\n",
      "Epoch 19982 - Train Loss: 0.081430, Train Acc: 0.875641 | Val Loss: 0.111097, Val Acc: 0.783505\n",
      "Epoch 19983 - Train Loss: 0.081428, Train Acc: 0.875641 | Val Loss: 0.111096, Val Acc: 0.783505\n",
      "Epoch 19984 - Train Loss: 0.081425, Train Acc: 0.875641 | Val Loss: 0.111095, Val Acc: 0.783505\n",
      "Epoch 19985 - Train Loss: 0.081423, Train Acc: 0.875641 | Val Loss: 0.111094, Val Acc: 0.783505\n",
      "Epoch 19986 - Train Loss: 0.081421, Train Acc: 0.875641 | Val Loss: 0.111093, Val Acc: 0.783505\n",
      "Epoch 19987 - Train Loss: 0.081418, Train Acc: 0.875641 | Val Loss: 0.111092, Val Acc: 0.783505\n",
      "Epoch 19988 - Train Loss: 0.081416, Train Acc: 0.875641 | Val Loss: 0.111091, Val Acc: 0.783505\n",
      "Epoch 19989 - Train Loss: 0.081414, Train Acc: 0.875641 | Val Loss: 0.111090, Val Acc: 0.783505\n",
      "Epoch 19990 - Train Loss: 0.081411, Train Acc: 0.875641 | Val Loss: 0.111089, Val Acc: 0.783505\n",
      "Epoch 19991 - Train Loss: 0.081409, Train Acc: 0.875641 | Val Loss: 0.111088, Val Acc: 0.783505\n",
      "Epoch 19992 - Train Loss: 0.081407, Train Acc: 0.875641 | Val Loss: 0.111087, Val Acc: 0.783505\n",
      "Epoch 19993 - Train Loss: 0.081405, Train Acc: 0.875641 | Val Loss: 0.111086, Val Acc: 0.783505\n",
      "Epoch 19994 - Train Loss: 0.081402, Train Acc: 0.875641 | Val Loss: 0.111085, Val Acc: 0.783505\n",
      "Epoch 19995 - Train Loss: 0.081400, Train Acc: 0.875641 | Val Loss: 0.111084, Val Acc: 0.783505\n",
      "Epoch 19996 - Train Loss: 0.081398, Train Acc: 0.875641 | Val Loss: 0.111083, Val Acc: 0.783505\n",
      "Epoch 19997 - Train Loss: 0.081395, Train Acc: 0.875641 | Val Loss: 0.111082, Val Acc: 0.783505\n",
      "Epoch 19998 - Train Loss: 0.081393, Train Acc: 0.875641 | Val Loss: 0.111081, Val Acc: 0.783505\n",
      "Epoch 19999 - Train Loss: 0.081391, Train Acc: 0.875641 | Val Loss: 0.111081, Val Acc: 0.783505\n",
      "Epoch 20000 - Train Loss: 0.081388, Train Acc: 0.875641 | Val Loss: 0.111080, Val Acc: 0.783505\n",
      "Epoch 20001 - Train Loss: 0.081386, Train Acc: 0.875641 | Val Loss: 0.111079, Val Acc: 0.783505\n",
      "Epoch 20002 - Train Loss: 0.081384, Train Acc: 0.875641 | Val Loss: 0.111078, Val Acc: 0.783505\n",
      "Epoch 20003 - Train Loss: 0.081382, Train Acc: 0.875641 | Val Loss: 0.111077, Val Acc: 0.783505\n",
      "Epoch 20004 - Train Loss: 0.081379, Train Acc: 0.875641 | Val Loss: 0.111076, Val Acc: 0.783505\n",
      "Epoch 20005 - Train Loss: 0.081377, Train Acc: 0.875641 | Val Loss: 0.111075, Val Acc: 0.783505\n",
      "Epoch 20006 - Train Loss: 0.081375, Train Acc: 0.875641 | Val Loss: 0.111074, Val Acc: 0.783505\n",
      "Epoch 20007 - Train Loss: 0.081372, Train Acc: 0.875641 | Val Loss: 0.111073, Val Acc: 0.783505\n",
      "Epoch 20008 - Train Loss: 0.081370, Train Acc: 0.875641 | Val Loss: 0.111072, Val Acc: 0.783505\n",
      "Epoch 20009 - Train Loss: 0.081368, Train Acc: 0.875641 | Val Loss: 0.111071, Val Acc: 0.783505\n",
      "Epoch 20010 - Train Loss: 0.081365, Train Acc: 0.875641 | Val Loss: 0.111070, Val Acc: 0.783505\n",
      "Epoch 20011 - Train Loss: 0.081363, Train Acc: 0.875641 | Val Loss: 0.111069, Val Acc: 0.783505\n",
      "Epoch 20012 - Train Loss: 0.081361, Train Acc: 0.875641 | Val Loss: 0.111068, Val Acc: 0.783505\n",
      "Epoch 20013 - Train Loss: 0.081359, Train Acc: 0.875641 | Val Loss: 0.111067, Val Acc: 0.783505\n",
      "Epoch 20014 - Train Loss: 0.081356, Train Acc: 0.875641 | Val Loss: 0.111066, Val Acc: 0.783505\n",
      "Epoch 20015 - Train Loss: 0.081354, Train Acc: 0.875641 | Val Loss: 0.111065, Val Acc: 0.783505\n",
      "Epoch 20016 - Train Loss: 0.081352, Train Acc: 0.875641 | Val Loss: 0.111064, Val Acc: 0.783505\n",
      "Epoch 20017 - Train Loss: 0.081349, Train Acc: 0.875641 | Val Loss: 0.111063, Val Acc: 0.783505\n",
      "Epoch 20018 - Train Loss: 0.081347, Train Acc: 0.875641 | Val Loss: 0.111062, Val Acc: 0.783505\n",
      "Epoch 20019 - Train Loss: 0.081345, Train Acc: 0.875641 | Val Loss: 0.111061, Val Acc: 0.783505\n",
      "Epoch 20020 - Train Loss: 0.081343, Train Acc: 0.875641 | Val Loss: 0.111060, Val Acc: 0.783505\n",
      "Epoch 20021 - Train Loss: 0.081340, Train Acc: 0.875641 | Val Loss: 0.111059, Val Acc: 0.783505\n",
      "Epoch 20022 - Train Loss: 0.081338, Train Acc: 0.875641 | Val Loss: 0.111059, Val Acc: 0.783505\n",
      "Epoch 20023 - Train Loss: 0.081336, Train Acc: 0.875641 | Val Loss: 0.111058, Val Acc: 0.783505\n",
      "Epoch 20024 - Train Loss: 0.081333, Train Acc: 0.875641 | Val Loss: 0.111057, Val Acc: 0.783505\n",
      "Epoch 20025 - Train Loss: 0.081331, Train Acc: 0.875641 | Val Loss: 0.111056, Val Acc: 0.783505\n",
      "Epoch 20026 - Train Loss: 0.081329, Train Acc: 0.875641 | Val Loss: 0.111055, Val Acc: 0.783505\n",
      "Epoch 20027 - Train Loss: 0.081327, Train Acc: 0.875641 | Val Loss: 0.111054, Val Acc: 0.783505\n",
      "Epoch 20028 - Train Loss: 0.081324, Train Acc: 0.875641 | Val Loss: 0.111053, Val Acc: 0.783505\n",
      "Epoch 20029 - Train Loss: 0.081322, Train Acc: 0.875641 | Val Loss: 0.111052, Val Acc: 0.783505\n",
      "Epoch 20030 - Train Loss: 0.081320, Train Acc: 0.875641 | Val Loss: 0.111051, Val Acc: 0.783505\n",
      "Epoch 20031 - Train Loss: 0.081317, Train Acc: 0.875641 | Val Loss: 0.111050, Val Acc: 0.783505\n",
      "Epoch 20032 - Train Loss: 0.081315, Train Acc: 0.875641 | Val Loss: 0.111049, Val Acc: 0.783505\n",
      "Epoch 20033 - Train Loss: 0.081313, Train Acc: 0.875641 | Val Loss: 0.111048, Val Acc: 0.783505\n",
      "Epoch 20034 - Train Loss: 0.081311, Train Acc: 0.875641 | Val Loss: 0.111047, Val Acc: 0.783505\n",
      "Epoch 20035 - Train Loss: 0.081308, Train Acc: 0.875641 | Val Loss: 0.111046, Val Acc: 0.783505\n",
      "Epoch 20036 - Train Loss: 0.081306, Train Acc: 0.875641 | Val Loss: 0.111045, Val Acc: 0.783505\n",
      "Epoch 20037 - Train Loss: 0.081304, Train Acc: 0.875641 | Val Loss: 0.111044, Val Acc: 0.783505\n",
      "Epoch 20038 - Train Loss: 0.081301, Train Acc: 0.875641 | Val Loss: 0.111043, Val Acc: 0.783505\n",
      "Epoch 20039 - Train Loss: 0.081299, Train Acc: 0.875641 | Val Loss: 0.111042, Val Acc: 0.783505\n",
      "Epoch 20040 - Train Loss: 0.081297, Train Acc: 0.875641 | Val Loss: 0.111041, Val Acc: 0.783505\n",
      "Epoch 20041 - Train Loss: 0.081295, Train Acc: 0.875641 | Val Loss: 0.111040, Val Acc: 0.783505\n",
      "Epoch 20042 - Train Loss: 0.081292, Train Acc: 0.875641 | Val Loss: 0.111039, Val Acc: 0.783505\n",
      "Epoch 20043 - Train Loss: 0.081290, Train Acc: 0.875641 | Val Loss: 0.111038, Val Acc: 0.783505\n",
      "Epoch 20044 - Train Loss: 0.081288, Train Acc: 0.875641 | Val Loss: 0.111037, Val Acc: 0.783505\n",
      "Epoch 20045 - Train Loss: 0.081285, Train Acc: 0.875641 | Val Loss: 0.111036, Val Acc: 0.783505\n",
      "Epoch 20046 - Train Loss: 0.081283, Train Acc: 0.875641 | Val Loss: 0.111035, Val Acc: 0.783505\n",
      "Epoch 20047 - Train Loss: 0.081281, Train Acc: 0.875641 | Val Loss: 0.111034, Val Acc: 0.783505\n",
      "Epoch 20048 - Train Loss: 0.081279, Train Acc: 0.875641 | Val Loss: 0.111033, Val Acc: 0.783505\n",
      "Epoch 20049 - Train Loss: 0.081276, Train Acc: 0.875641 | Val Loss: 0.111032, Val Acc: 0.783505\n",
      "Epoch 20050 - Train Loss: 0.081274, Train Acc: 0.875641 | Val Loss: 0.111031, Val Acc: 0.783505\n",
      "Epoch 20051 - Train Loss: 0.081272, Train Acc: 0.875641 | Val Loss: 0.111031, Val Acc: 0.783505\n",
      "Epoch 20052 - Train Loss: 0.081269, Train Acc: 0.875641 | Val Loss: 0.111030, Val Acc: 0.783505\n",
      "Epoch 20053 - Train Loss: 0.081267, Train Acc: 0.875641 | Val Loss: 0.111029, Val Acc: 0.783505\n",
      "Epoch 20054 - Train Loss: 0.081265, Train Acc: 0.875641 | Val Loss: 0.111028, Val Acc: 0.783505\n",
      "Epoch 20055 - Train Loss: 0.081263, Train Acc: 0.875641 | Val Loss: 0.111027, Val Acc: 0.783505\n",
      "Epoch 20056 - Train Loss: 0.081260, Train Acc: 0.875641 | Val Loss: 0.111026, Val Acc: 0.783505\n",
      "Epoch 20057 - Train Loss: 0.081258, Train Acc: 0.875641 | Val Loss: 0.111025, Val Acc: 0.783505\n",
      "Epoch 20058 - Train Loss: 0.081256, Train Acc: 0.875641 | Val Loss: 0.111024, Val Acc: 0.783505\n",
      "Epoch 20059 - Train Loss: 0.081253, Train Acc: 0.875641 | Val Loss: 0.111023, Val Acc: 0.783505\n",
      "Epoch 20060 - Train Loss: 0.081251, Train Acc: 0.875641 | Val Loss: 0.111022, Val Acc: 0.783505\n",
      "Epoch 20061 - Train Loss: 0.081249, Train Acc: 0.875641 | Val Loss: 0.111021, Val Acc: 0.783505\n",
      "Epoch 20062 - Train Loss: 0.081247, Train Acc: 0.875641 | Val Loss: 0.111020, Val Acc: 0.783505\n",
      "Epoch 20063 - Train Loss: 0.081244, Train Acc: 0.875641 | Val Loss: 0.111019, Val Acc: 0.783505\n",
      "Epoch 20064 - Train Loss: 0.081242, Train Acc: 0.875641 | Val Loss: 0.111018, Val Acc: 0.783505\n",
      "Epoch 20065 - Train Loss: 0.081240, Train Acc: 0.875641 | Val Loss: 0.111017, Val Acc: 0.783505\n",
      "Epoch 20066 - Train Loss: 0.081237, Train Acc: 0.875641 | Val Loss: 0.111016, Val Acc: 0.783505\n",
      "Epoch 20067 - Train Loss: 0.081235, Train Acc: 0.875641 | Val Loss: 0.111015, Val Acc: 0.783505\n",
      "Epoch 20068 - Train Loss: 0.081233, Train Acc: 0.875641 | Val Loss: 0.111014, Val Acc: 0.783505\n",
      "Epoch 20069 - Train Loss: 0.081231, Train Acc: 0.875641 | Val Loss: 0.111013, Val Acc: 0.783505\n",
      "Epoch 20070 - Train Loss: 0.081228, Train Acc: 0.875641 | Val Loss: 0.111012, Val Acc: 0.783505\n",
      "Epoch 20071 - Train Loss: 0.081226, Train Acc: 0.875641 | Val Loss: 0.111011, Val Acc: 0.783505\n",
      "Epoch 20072 - Train Loss: 0.081224, Train Acc: 0.875641 | Val Loss: 0.111010, Val Acc: 0.783505\n",
      "Epoch 20073 - Train Loss: 0.081221, Train Acc: 0.875641 | Val Loss: 0.111009, Val Acc: 0.783505\n",
      "Epoch 20074 - Train Loss: 0.081219, Train Acc: 0.875641 | Val Loss: 0.111008, Val Acc: 0.783505\n",
      "Epoch 20075 - Train Loss: 0.081217, Train Acc: 0.875641 | Val Loss: 0.111007, Val Acc: 0.783505\n",
      "Epoch 20076 - Train Loss: 0.081215, Train Acc: 0.875641 | Val Loss: 0.111006, Val Acc: 0.783505\n",
      "Epoch 20077 - Train Loss: 0.081212, Train Acc: 0.875641 | Val Loss: 0.111005, Val Acc: 0.783505\n",
      "Epoch 20078 - Train Loss: 0.081210, Train Acc: 0.875641 | Val Loss: 0.111004, Val Acc: 0.783505\n",
      "Epoch 20079 - Train Loss: 0.081208, Train Acc: 0.875641 | Val Loss: 0.111004, Val Acc: 0.783505\n",
      "Epoch 20080 - Train Loss: 0.081206, Train Acc: 0.875641 | Val Loss: 0.111003, Val Acc: 0.783505\n",
      "Epoch 20081 - Train Loss: 0.081203, Train Acc: 0.875641 | Val Loss: 0.111002, Val Acc: 0.783505\n",
      "Epoch 20082 - Train Loss: 0.081201, Train Acc: 0.875641 | Val Loss: 0.111001, Val Acc: 0.783505\n",
      "Epoch 20083 - Train Loss: 0.081199, Train Acc: 0.875641 | Val Loss: 0.111000, Val Acc: 0.783505\n",
      "Epoch 20084 - Train Loss: 0.081196, Train Acc: 0.875641 | Val Loss: 0.110999, Val Acc: 0.783505\n",
      "Epoch 20085 - Train Loss: 0.081194, Train Acc: 0.875641 | Val Loss: 0.110998, Val Acc: 0.783505\n",
      "Epoch 20086 - Train Loss: 0.081192, Train Acc: 0.875641 | Val Loss: 0.110997, Val Acc: 0.783505\n",
      "Epoch 20087 - Train Loss: 0.081190, Train Acc: 0.875641 | Val Loss: 0.110996, Val Acc: 0.783505\n",
      "Epoch 20088 - Train Loss: 0.081187, Train Acc: 0.875641 | Val Loss: 0.110995, Val Acc: 0.783505\n",
      "Epoch 20089 - Train Loss: 0.081185, Train Acc: 0.875641 | Val Loss: 0.110994, Val Acc: 0.783505\n",
      "Epoch 20090 - Train Loss: 0.081183, Train Acc: 0.875641 | Val Loss: 0.110993, Val Acc: 0.783505\n",
      "Epoch 20091 - Train Loss: 0.081181, Train Acc: 0.875641 | Val Loss: 0.110992, Val Acc: 0.783505\n",
      "Epoch 20092 - Train Loss: 0.081178, Train Acc: 0.875641 | Val Loss: 0.110991, Val Acc: 0.783505\n",
      "Epoch 20093 - Train Loss: 0.081176, Train Acc: 0.875641 | Val Loss: 0.110990, Val Acc: 0.783505\n",
      "Epoch 20094 - Train Loss: 0.081174, Train Acc: 0.875641 | Val Loss: 0.110989, Val Acc: 0.783505\n",
      "Epoch 20095 - Train Loss: 0.081171, Train Acc: 0.875641 | Val Loss: 0.110988, Val Acc: 0.783505\n",
      "Epoch 20096 - Train Loss: 0.081169, Train Acc: 0.875641 | Val Loss: 0.110987, Val Acc: 0.783505\n",
      "Epoch 20097 - Train Loss: 0.081167, Train Acc: 0.875641 | Val Loss: 0.110986, Val Acc: 0.783505\n",
      "Epoch 20098 - Train Loss: 0.081165, Train Acc: 0.875641 | Val Loss: 0.110985, Val Acc: 0.783505\n",
      "Epoch 20099 - Train Loss: 0.081162, Train Acc: 0.875641 | Val Loss: 0.110984, Val Acc: 0.783505\n",
      "Epoch 20100 - Train Loss: 0.081160, Train Acc: 0.875641 | Val Loss: 0.110983, Val Acc: 0.783505\n",
      "Epoch 20101 - Train Loss: 0.081158, Train Acc: 0.875641 | Val Loss: 0.110982, Val Acc: 0.783505\n",
      "Epoch 20102 - Train Loss: 0.081155, Train Acc: 0.875641 | Val Loss: 0.110981, Val Acc: 0.783505\n",
      "Epoch 20103 - Train Loss: 0.081153, Train Acc: 0.875641 | Val Loss: 0.110980, Val Acc: 0.783505\n",
      "Epoch 20104 - Train Loss: 0.081151, Train Acc: 0.875641 | Val Loss: 0.110980, Val Acc: 0.783505\n",
      "Epoch 20105 - Train Loss: 0.081149, Train Acc: 0.875641 | Val Loss: 0.110979, Val Acc: 0.783505\n",
      "Epoch 20106 - Train Loss: 0.081146, Train Acc: 0.875641 | Val Loss: 0.110978, Val Acc: 0.783505\n",
      "Epoch 20107 - Train Loss: 0.081144, Train Acc: 0.875641 | Val Loss: 0.110977, Val Acc: 0.783505\n",
      "Epoch 20108 - Train Loss: 0.081142, Train Acc: 0.875641 | Val Loss: 0.110976, Val Acc: 0.783505\n",
      "Epoch 20109 - Train Loss: 0.081140, Train Acc: 0.875641 | Val Loss: 0.110975, Val Acc: 0.783505\n",
      "Epoch 20110 - Train Loss: 0.081137, Train Acc: 0.875641 | Val Loss: 0.110974, Val Acc: 0.783505\n",
      "Epoch 20111 - Train Loss: 0.081135, Train Acc: 0.875641 | Val Loss: 0.110973, Val Acc: 0.783505\n",
      "Epoch 20112 - Train Loss: 0.081133, Train Acc: 0.875641 | Val Loss: 0.110972, Val Acc: 0.783505\n",
      "Epoch 20113 - Train Loss: 0.081131, Train Acc: 0.875641 | Val Loss: 0.110971, Val Acc: 0.783505\n",
      "Epoch 20114 - Train Loss: 0.081128, Train Acc: 0.875641 | Val Loss: 0.110970, Val Acc: 0.783505\n",
      "Epoch 20115 - Train Loss: 0.081126, Train Acc: 0.875641 | Val Loss: 0.110969, Val Acc: 0.783505\n",
      "Epoch 20116 - Train Loss: 0.081124, Train Acc: 0.875641 | Val Loss: 0.110968, Val Acc: 0.783505\n",
      "Epoch 20117 - Train Loss: 0.081121, Train Acc: 0.875641 | Val Loss: 0.110967, Val Acc: 0.783505\n",
      "Epoch 20118 - Train Loss: 0.081119, Train Acc: 0.875641 | Val Loss: 0.110966, Val Acc: 0.783505\n",
      "Epoch 20119 - Train Loss: 0.081117, Train Acc: 0.875641 | Val Loss: 0.110965, Val Acc: 0.783505\n",
      "Epoch 20120 - Train Loss: 0.081115, Train Acc: 0.875641 | Val Loss: 0.110964, Val Acc: 0.783505\n",
      "Epoch 20121 - Train Loss: 0.081112, Train Acc: 0.875641 | Val Loss: 0.110963, Val Acc: 0.783505\n",
      "Epoch 20122 - Train Loss: 0.081110, Train Acc: 0.875641 | Val Loss: 0.110962, Val Acc: 0.783505\n",
      "Epoch 20123 - Train Loss: 0.081108, Train Acc: 0.875641 | Val Loss: 0.110961, Val Acc: 0.783505\n",
      "Epoch 20124 - Train Loss: 0.081106, Train Acc: 0.875641 | Val Loss: 0.110960, Val Acc: 0.783505\n",
      "Epoch 20125 - Train Loss: 0.081103, Train Acc: 0.875641 | Val Loss: 0.110959, Val Acc: 0.783505\n",
      "Epoch 20126 - Train Loss: 0.081101, Train Acc: 0.875641 | Val Loss: 0.110958, Val Acc: 0.783505\n",
      "Epoch 20127 - Train Loss: 0.081099, Train Acc: 0.875641 | Val Loss: 0.110957, Val Acc: 0.783505\n",
      "Epoch 20128 - Train Loss: 0.081097, Train Acc: 0.875641 | Val Loss: 0.110957, Val Acc: 0.783505\n",
      "Epoch 20129 - Train Loss: 0.081094, Train Acc: 0.875641 | Val Loss: 0.110956, Val Acc: 0.783505\n",
      "Epoch 20130 - Train Loss: 0.081092, Train Acc: 0.875641 | Val Loss: 0.110955, Val Acc: 0.783505\n",
      "Epoch 20131 - Train Loss: 0.081090, Train Acc: 0.875641 | Val Loss: 0.110954, Val Acc: 0.783505\n",
      "Epoch 20132 - Train Loss: 0.081087, Train Acc: 0.875641 | Val Loss: 0.110953, Val Acc: 0.783505\n",
      "Epoch 20133 - Train Loss: 0.081085, Train Acc: 0.875641 | Val Loss: 0.110952, Val Acc: 0.783505\n",
      "Epoch 20134 - Train Loss: 0.081083, Train Acc: 0.875641 | Val Loss: 0.110951, Val Acc: 0.783505\n",
      "Epoch 20135 - Train Loss: 0.081081, Train Acc: 0.875641 | Val Loss: 0.110950, Val Acc: 0.783505\n",
      "Epoch 20136 - Train Loss: 0.081078, Train Acc: 0.875641 | Val Loss: 0.110949, Val Acc: 0.783505\n",
      "Epoch 20137 - Train Loss: 0.081076, Train Acc: 0.875641 | Val Loss: 0.110948, Val Acc: 0.783505\n",
      "Epoch 20138 - Train Loss: 0.081074, Train Acc: 0.875641 | Val Loss: 0.110947, Val Acc: 0.783505\n",
      "Epoch 20139 - Train Loss: 0.081072, Train Acc: 0.875641 | Val Loss: 0.110946, Val Acc: 0.783505\n",
      "Epoch 20140 - Train Loss: 0.081069, Train Acc: 0.875641 | Val Loss: 0.110945, Val Acc: 0.783505\n",
      "Epoch 20141 - Train Loss: 0.081067, Train Acc: 0.875641 | Val Loss: 0.110944, Val Acc: 0.783505\n",
      "Epoch 20142 - Train Loss: 0.081065, Train Acc: 0.875641 | Val Loss: 0.110943, Val Acc: 0.783505\n",
      "Epoch 20143 - Train Loss: 0.081063, Train Acc: 0.875641 | Val Loss: 0.110942, Val Acc: 0.783505\n",
      "Epoch 20144 - Train Loss: 0.081060, Train Acc: 0.875641 | Val Loss: 0.110941, Val Acc: 0.783505\n",
      "Epoch 20145 - Train Loss: 0.081058, Train Acc: 0.875641 | Val Loss: 0.110940, Val Acc: 0.783505\n",
      "Epoch 20146 - Train Loss: 0.081056, Train Acc: 0.875641 | Val Loss: 0.110939, Val Acc: 0.783505\n",
      "Epoch 20147 - Train Loss: 0.081053, Train Acc: 0.875641 | Val Loss: 0.110938, Val Acc: 0.783505\n",
      "Epoch 20148 - Train Loss: 0.081051, Train Acc: 0.875641 | Val Loss: 0.110938, Val Acc: 0.783505\n",
      "Epoch 20149 - Train Loss: 0.081049, Train Acc: 0.875641 | Val Loss: 0.110937, Val Acc: 0.783505\n",
      "Epoch 20150 - Train Loss: 0.081047, Train Acc: 0.875641 | Val Loss: 0.110936, Val Acc: 0.783505\n",
      "Epoch 20151 - Train Loss: 0.081044, Train Acc: 0.875641 | Val Loss: 0.110935, Val Acc: 0.783505\n",
      "Epoch 20152 - Train Loss: 0.081042, Train Acc: 0.875641 | Val Loss: 0.110934, Val Acc: 0.783505\n",
      "Epoch 20153 - Train Loss: 0.081040, Train Acc: 0.875641 | Val Loss: 0.110933, Val Acc: 0.783505\n",
      "Epoch 20154 - Train Loss: 0.081038, Train Acc: 0.875641 | Val Loss: 0.110932, Val Acc: 0.783505\n",
      "Epoch 20155 - Train Loss: 0.081035, Train Acc: 0.875641 | Val Loss: 0.110931, Val Acc: 0.783505\n",
      "Epoch 20156 - Train Loss: 0.081033, Train Acc: 0.875641 | Val Loss: 0.110930, Val Acc: 0.783505\n",
      "Epoch 20157 - Train Loss: 0.081031, Train Acc: 0.875641 | Val Loss: 0.110929, Val Acc: 0.783505\n",
      "Epoch 20158 - Train Loss: 0.081029, Train Acc: 0.875641 | Val Loss: 0.110928, Val Acc: 0.783505\n",
      "Epoch 20159 - Train Loss: 0.081026, Train Acc: 0.875641 | Val Loss: 0.110927, Val Acc: 0.783505\n",
      "Epoch 20160 - Train Loss: 0.081024, Train Acc: 0.875641 | Val Loss: 0.110926, Val Acc: 0.783505\n",
      "Epoch 20161 - Train Loss: 0.081022, Train Acc: 0.875641 | Val Loss: 0.110925, Val Acc: 0.783505\n",
      "Epoch 20162 - Train Loss: 0.081020, Train Acc: 0.875641 | Val Loss: 0.110924, Val Acc: 0.783505\n",
      "Epoch 20163 - Train Loss: 0.081017, Train Acc: 0.875641 | Val Loss: 0.110923, Val Acc: 0.783505\n",
      "Epoch 20164 - Train Loss: 0.081015, Train Acc: 0.875641 | Val Loss: 0.110922, Val Acc: 0.783505\n",
      "Epoch 20165 - Train Loss: 0.081013, Train Acc: 0.875641 | Val Loss: 0.110921, Val Acc: 0.783505\n",
      "Epoch 20166 - Train Loss: 0.081011, Train Acc: 0.875641 | Val Loss: 0.110920, Val Acc: 0.783505\n",
      "Epoch 20167 - Train Loss: 0.081008, Train Acc: 0.875641 | Val Loss: 0.110919, Val Acc: 0.783505\n",
      "Epoch 20168 - Train Loss: 0.081006, Train Acc: 0.875641 | Val Loss: 0.110919, Val Acc: 0.783505\n",
      "Epoch 20169 - Train Loss: 0.081004, Train Acc: 0.875641 | Val Loss: 0.110918, Val Acc: 0.783505\n",
      "Epoch 20170 - Train Loss: 0.081002, Train Acc: 0.875641 | Val Loss: 0.110917, Val Acc: 0.783505\n",
      "Epoch 20171 - Train Loss: 0.080999, Train Acc: 0.875641 | Val Loss: 0.110916, Val Acc: 0.783505\n",
      "Epoch 20172 - Train Loss: 0.080997, Train Acc: 0.875641 | Val Loss: 0.110915, Val Acc: 0.783505\n",
      "Epoch 20173 - Train Loss: 0.080995, Train Acc: 0.875641 | Val Loss: 0.110914, Val Acc: 0.783505\n",
      "Epoch 20174 - Train Loss: 0.080993, Train Acc: 0.875641 | Val Loss: 0.110913, Val Acc: 0.783505\n",
      "Epoch 20175 - Train Loss: 0.080990, Train Acc: 0.875641 | Val Loss: 0.110912, Val Acc: 0.783505\n",
      "Epoch 20176 - Train Loss: 0.080988, Train Acc: 0.875641 | Val Loss: 0.110911, Val Acc: 0.783505\n",
      "Epoch 20177 - Train Loss: 0.080986, Train Acc: 0.875641 | Val Loss: 0.110910, Val Acc: 0.783505\n",
      "Epoch 20178 - Train Loss: 0.080983, Train Acc: 0.875641 | Val Loss: 0.110909, Val Acc: 0.783505\n",
      "Epoch 20179 - Train Loss: 0.080981, Train Acc: 0.875641 | Val Loss: 0.110908, Val Acc: 0.783505\n",
      "Epoch 20180 - Train Loss: 0.080979, Train Acc: 0.875641 | Val Loss: 0.110907, Val Acc: 0.783505\n",
      "Epoch 20181 - Train Loss: 0.080977, Train Acc: 0.875641 | Val Loss: 0.110906, Val Acc: 0.783505\n",
      "Epoch 20182 - Train Loss: 0.080974, Train Acc: 0.875641 | Val Loss: 0.110905, Val Acc: 0.783505\n",
      "Epoch 20183 - Train Loss: 0.080972, Train Acc: 0.875641 | Val Loss: 0.110904, Val Acc: 0.783505\n",
      "Epoch 20184 - Train Loss: 0.080970, Train Acc: 0.875641 | Val Loss: 0.110903, Val Acc: 0.783505\n",
      "Epoch 20185 - Train Loss: 0.080968, Train Acc: 0.875641 | Val Loss: 0.110902, Val Acc: 0.783505\n",
      "Epoch 20186 - Train Loss: 0.080965, Train Acc: 0.875641 | Val Loss: 0.110901, Val Acc: 0.783505\n",
      "Epoch 20187 - Train Loss: 0.080963, Train Acc: 0.875641 | Val Loss: 0.110901, Val Acc: 0.783505\n",
      "Epoch 20188 - Train Loss: 0.080961, Train Acc: 0.875641 | Val Loss: 0.110900, Val Acc: 0.783505\n",
      "Epoch 20189 - Train Loss: 0.080959, Train Acc: 0.875641 | Val Loss: 0.110899, Val Acc: 0.783505\n",
      "Epoch 20190 - Train Loss: 0.080956, Train Acc: 0.875641 | Val Loss: 0.110898, Val Acc: 0.783505\n",
      "Epoch 20191 - Train Loss: 0.080954, Train Acc: 0.875641 | Val Loss: 0.110897, Val Acc: 0.783505\n",
      "Epoch 20192 - Train Loss: 0.080952, Train Acc: 0.875641 | Val Loss: 0.110896, Val Acc: 0.783505\n",
      "Epoch 20193 - Train Loss: 0.080950, Train Acc: 0.875641 | Val Loss: 0.110895, Val Acc: 0.783505\n",
      "Epoch 20194 - Train Loss: 0.080947, Train Acc: 0.875641 | Val Loss: 0.110894, Val Acc: 0.783505\n",
      "Epoch 20195 - Train Loss: 0.080945, Train Acc: 0.875641 | Val Loss: 0.110893, Val Acc: 0.783505\n",
      "Epoch 20196 - Train Loss: 0.080943, Train Acc: 0.875641 | Val Loss: 0.110892, Val Acc: 0.783505\n",
      "Epoch 20197 - Train Loss: 0.080941, Train Acc: 0.875641 | Val Loss: 0.110891, Val Acc: 0.783505\n",
      "Epoch 20198 - Train Loss: 0.080938, Train Acc: 0.875641 | Val Loss: 0.110890, Val Acc: 0.783505\n",
      "Epoch 20199 - Train Loss: 0.080936, Train Acc: 0.875641 | Val Loss: 0.110889, Val Acc: 0.783505\n",
      "Epoch 20200 - Train Loss: 0.080934, Train Acc: 0.875641 | Val Loss: 0.110888, Val Acc: 0.783505\n",
      "Epoch 20201 - Train Loss: 0.080932, Train Acc: 0.875641 | Val Loss: 0.110887, Val Acc: 0.783505\n",
      "Epoch 20202 - Train Loss: 0.080929, Train Acc: 0.875641 | Val Loss: 0.110886, Val Acc: 0.783505\n",
      "Epoch 20203 - Train Loss: 0.080927, Train Acc: 0.875641 | Val Loss: 0.110885, Val Acc: 0.783505\n",
      "Epoch 20204 - Train Loss: 0.080925, Train Acc: 0.875641 | Val Loss: 0.110884, Val Acc: 0.783505\n",
      "Epoch 20205 - Train Loss: 0.080923, Train Acc: 0.875641 | Val Loss: 0.110884, Val Acc: 0.783505\n",
      "Epoch 20206 - Train Loss: 0.080920, Train Acc: 0.875641 | Val Loss: 0.110883, Val Acc: 0.783505\n",
      "Epoch 20207 - Train Loss: 0.080918, Train Acc: 0.875641 | Val Loss: 0.110882, Val Acc: 0.783505\n",
      "Epoch 20208 - Train Loss: 0.080916, Train Acc: 0.875641 | Val Loss: 0.110881, Val Acc: 0.783505\n",
      "Epoch 20209 - Train Loss: 0.080914, Train Acc: 0.875641 | Val Loss: 0.110880, Val Acc: 0.783505\n",
      "Epoch 20210 - Train Loss: 0.080911, Train Acc: 0.875641 | Val Loss: 0.110879, Val Acc: 0.783505\n",
      "Epoch 20211 - Train Loss: 0.080909, Train Acc: 0.875641 | Val Loss: 0.110878, Val Acc: 0.783505\n",
      "Epoch 20212 - Train Loss: 0.080907, Train Acc: 0.875641 | Val Loss: 0.110877, Val Acc: 0.783505\n",
      "Epoch 20213 - Train Loss: 0.080905, Train Acc: 0.875641 | Val Loss: 0.110876, Val Acc: 0.783505\n",
      "Epoch 20214 - Train Loss: 0.080902, Train Acc: 0.875641 | Val Loss: 0.110875, Val Acc: 0.783505\n",
      "Epoch 20215 - Train Loss: 0.080900, Train Acc: 0.875641 | Val Loss: 0.110874, Val Acc: 0.783505\n",
      "Epoch 20216 - Train Loss: 0.080898, Train Acc: 0.875641 | Val Loss: 0.110873, Val Acc: 0.783505\n",
      "Epoch 20217 - Train Loss: 0.080896, Train Acc: 0.875641 | Val Loss: 0.110872, Val Acc: 0.783505\n",
      "Epoch 20218 - Train Loss: 0.080893, Train Acc: 0.875641 | Val Loss: 0.110871, Val Acc: 0.783505\n",
      "Epoch 20219 - Train Loss: 0.080891, Train Acc: 0.875641 | Val Loss: 0.110870, Val Acc: 0.783505\n",
      "Epoch 20220 - Train Loss: 0.080889, Train Acc: 0.875641 | Val Loss: 0.110869, Val Acc: 0.783505\n",
      "Epoch 20221 - Train Loss: 0.080887, Train Acc: 0.875641 | Val Loss: 0.110868, Val Acc: 0.783505\n",
      "Epoch 20222 - Train Loss: 0.080885, Train Acc: 0.875641 | Val Loss: 0.110868, Val Acc: 0.783505\n",
      "Epoch 20223 - Train Loss: 0.080882, Train Acc: 0.875641 | Val Loss: 0.110867, Val Acc: 0.783505\n",
      "Epoch 20224 - Train Loss: 0.080880, Train Acc: 0.875641 | Val Loss: 0.110866, Val Acc: 0.783505\n",
      "Epoch 20225 - Train Loss: 0.080878, Train Acc: 0.875641 | Val Loss: 0.110865, Val Acc: 0.783505\n",
      "Epoch 20226 - Train Loss: 0.080876, Train Acc: 0.875641 | Val Loss: 0.110864, Val Acc: 0.783505\n",
      "Epoch 20227 - Train Loss: 0.080873, Train Acc: 0.875641 | Val Loss: 0.110863, Val Acc: 0.783505\n",
      "Epoch 20228 - Train Loss: 0.080871, Train Acc: 0.875641 | Val Loss: 0.110862, Val Acc: 0.783505\n",
      "Epoch 20229 - Train Loss: 0.080869, Train Acc: 0.875641 | Val Loss: 0.110861, Val Acc: 0.783505\n",
      "Epoch 20230 - Train Loss: 0.080867, Train Acc: 0.875641 | Val Loss: 0.110860, Val Acc: 0.783505\n",
      "Epoch 20231 - Train Loss: 0.080864, Train Acc: 0.875641 | Val Loss: 0.110859, Val Acc: 0.783505\n",
      "Epoch 20232 - Train Loss: 0.080862, Train Acc: 0.875641 | Val Loss: 0.110858, Val Acc: 0.783505\n",
      "Epoch 20233 - Train Loss: 0.080860, Train Acc: 0.875641 | Val Loss: 0.110857, Val Acc: 0.783505\n",
      "Epoch 20234 - Train Loss: 0.080858, Train Acc: 0.875641 | Val Loss: 0.110856, Val Acc: 0.783505\n",
      "Epoch 20235 - Train Loss: 0.080855, Train Acc: 0.875641 | Val Loss: 0.110855, Val Acc: 0.783505\n",
      "Epoch 20236 - Train Loss: 0.080853, Train Acc: 0.875641 | Val Loss: 0.110854, Val Acc: 0.783505\n",
      "Epoch 20237 - Train Loss: 0.080851, Train Acc: 0.875641 | Val Loss: 0.110854, Val Acc: 0.783505\n",
      "Epoch 20238 - Train Loss: 0.080849, Train Acc: 0.875641 | Val Loss: 0.110853, Val Acc: 0.783505\n",
      "Epoch 20239 - Train Loss: 0.080846, Train Acc: 0.875641 | Val Loss: 0.110852, Val Acc: 0.783505\n",
      "Epoch 20240 - Train Loss: 0.080844, Train Acc: 0.875641 | Val Loss: 0.110851, Val Acc: 0.783505\n",
      "Epoch 20241 - Train Loss: 0.080842, Train Acc: 0.875641 | Val Loss: 0.110850, Val Acc: 0.783505\n",
      "Epoch 20242 - Train Loss: 0.080840, Train Acc: 0.875641 | Val Loss: 0.110849, Val Acc: 0.783505\n",
      "Epoch 20243 - Train Loss: 0.080837, Train Acc: 0.875641 | Val Loss: 0.110848, Val Acc: 0.783505\n",
      "Epoch 20244 - Train Loss: 0.080835, Train Acc: 0.875641 | Val Loss: 0.110847, Val Acc: 0.783505\n",
      "Epoch 20245 - Train Loss: 0.080833, Train Acc: 0.875641 | Val Loss: 0.110846, Val Acc: 0.783505\n",
      "Epoch 20246 - Train Loss: 0.080831, Train Acc: 0.875641 | Val Loss: 0.110845, Val Acc: 0.783505\n",
      "Epoch 20247 - Train Loss: 0.080828, Train Acc: 0.875641 | Val Loss: 0.110844, Val Acc: 0.783505\n",
      "Epoch 20248 - Train Loss: 0.080826, Train Acc: 0.875641 | Val Loss: 0.110843, Val Acc: 0.783505\n",
      "Epoch 20249 - Train Loss: 0.080824, Train Acc: 0.875641 | Val Loss: 0.110842, Val Acc: 0.783505\n",
      "Epoch 20250 - Train Loss: 0.080822, Train Acc: 0.875641 | Val Loss: 0.110841, Val Acc: 0.783505\n",
      "Epoch 20251 - Train Loss: 0.080820, Train Acc: 0.875641 | Val Loss: 0.110840, Val Acc: 0.783505\n",
      "Epoch 20252 - Train Loss: 0.080817, Train Acc: 0.875641 | Val Loss: 0.110840, Val Acc: 0.783505\n",
      "Epoch 20253 - Train Loss: 0.080815, Train Acc: 0.875641 | Val Loss: 0.110839, Val Acc: 0.783505\n",
      "Epoch 20254 - Train Loss: 0.080813, Train Acc: 0.875641 | Val Loss: 0.110838, Val Acc: 0.783505\n",
      "Epoch 20255 - Train Loss: 0.080811, Train Acc: 0.875641 | Val Loss: 0.110837, Val Acc: 0.783505\n",
      "Epoch 20256 - Train Loss: 0.080808, Train Acc: 0.875641 | Val Loss: 0.110836, Val Acc: 0.783505\n",
      "Epoch 20257 - Train Loss: 0.080806, Train Acc: 0.875641 | Val Loss: 0.110835, Val Acc: 0.783505\n",
      "Epoch 20258 - Train Loss: 0.080804, Train Acc: 0.875641 | Val Loss: 0.110834, Val Acc: 0.783505\n",
      "Epoch 20259 - Train Loss: 0.080802, Train Acc: 0.875641 | Val Loss: 0.110833, Val Acc: 0.783505\n",
      "Epoch 20260 - Train Loss: 0.080799, Train Acc: 0.875641 | Val Loss: 0.110832, Val Acc: 0.783505\n",
      "Epoch 20261 - Train Loss: 0.080797, Train Acc: 0.875641 | Val Loss: 0.110831, Val Acc: 0.783505\n",
      "Epoch 20262 - Train Loss: 0.080795, Train Acc: 0.875641 | Val Loss: 0.110830, Val Acc: 0.783505\n",
      "Epoch 20263 - Train Loss: 0.080793, Train Acc: 0.875641 | Val Loss: 0.110829, Val Acc: 0.783505\n",
      "Epoch 20264 - Train Loss: 0.080790, Train Acc: 0.875641 | Val Loss: 0.110828, Val Acc: 0.783505\n",
      "Epoch 20265 - Train Loss: 0.080788, Train Acc: 0.875641 | Val Loss: 0.110827, Val Acc: 0.783505\n",
      "Epoch 20266 - Train Loss: 0.080786, Train Acc: 0.875641 | Val Loss: 0.110827, Val Acc: 0.783505\n",
      "Epoch 20267 - Train Loss: 0.080784, Train Acc: 0.875641 | Val Loss: 0.110826, Val Acc: 0.783505\n",
      "Epoch 20268 - Train Loss: 0.080782, Train Acc: 0.875641 | Val Loss: 0.110825, Val Acc: 0.783505\n",
      "Epoch 20269 - Train Loss: 0.080779, Train Acc: 0.875641 | Val Loss: 0.110824, Val Acc: 0.783505\n",
      "Epoch 20270 - Train Loss: 0.080777, Train Acc: 0.875641 | Val Loss: 0.110823, Val Acc: 0.783505\n",
      "Epoch 20271 - Train Loss: 0.080775, Train Acc: 0.875641 | Val Loss: 0.110822, Val Acc: 0.783505\n",
      "Epoch 20272 - Train Loss: 0.080773, Train Acc: 0.875641 | Val Loss: 0.110821, Val Acc: 0.783505\n",
      "Epoch 20273 - Train Loss: 0.080770, Train Acc: 0.875641 | Val Loss: 0.110820, Val Acc: 0.783505\n",
      "Epoch 20274 - Train Loss: 0.080768, Train Acc: 0.875641 | Val Loss: 0.110819, Val Acc: 0.783505\n",
      "Epoch 20275 - Train Loss: 0.080766, Train Acc: 0.875641 | Val Loss: 0.110818, Val Acc: 0.783505\n",
      "Epoch 20276 - Train Loss: 0.080764, Train Acc: 0.875641 | Val Loss: 0.110817, Val Acc: 0.783505\n",
      "Epoch 20277 - Train Loss: 0.080761, Train Acc: 0.875641 | Val Loss: 0.110816, Val Acc: 0.783505\n",
      "Epoch 20278 - Train Loss: 0.080759, Train Acc: 0.875641 | Val Loss: 0.110815, Val Acc: 0.783505\n",
      "Epoch 20279 - Train Loss: 0.080757, Train Acc: 0.875641 | Val Loss: 0.110814, Val Acc: 0.783505\n",
      "Epoch 20280 - Train Loss: 0.080755, Train Acc: 0.875641 | Val Loss: 0.110814, Val Acc: 0.783505\n",
      "Epoch 20281 - Train Loss: 0.080752, Train Acc: 0.875641 | Val Loss: 0.110813, Val Acc: 0.783505\n",
      "Epoch 20282 - Train Loss: 0.080750, Train Acc: 0.875641 | Val Loss: 0.110812, Val Acc: 0.783505\n",
      "Epoch 20283 - Train Loss: 0.080748, Train Acc: 0.875641 | Val Loss: 0.110811, Val Acc: 0.783505\n",
      "Epoch 20284 - Train Loss: 0.080746, Train Acc: 0.875641 | Val Loss: 0.110810, Val Acc: 0.783505\n",
      "Epoch 20285 - Train Loss: 0.080744, Train Acc: 0.875641 | Val Loss: 0.110809, Val Acc: 0.783505\n",
      "Epoch 20286 - Train Loss: 0.080741, Train Acc: 0.875641 | Val Loss: 0.110808, Val Acc: 0.783505\n",
      "Epoch 20287 - Train Loss: 0.080739, Train Acc: 0.875641 | Val Loss: 0.110807, Val Acc: 0.783505\n",
      "Epoch 20288 - Train Loss: 0.080737, Train Acc: 0.875641 | Val Loss: 0.110806, Val Acc: 0.783505\n",
      "Epoch 20289 - Train Loss: 0.080735, Train Acc: 0.875641 | Val Loss: 0.110805, Val Acc: 0.783505\n",
      "Epoch 20290 - Train Loss: 0.080732, Train Acc: 0.875641 | Val Loss: 0.110804, Val Acc: 0.783505\n",
      "Epoch 20291 - Train Loss: 0.080730, Train Acc: 0.875641 | Val Loss: 0.110803, Val Acc: 0.783505\n",
      "Epoch 20292 - Train Loss: 0.080728, Train Acc: 0.875641 | Val Loss: 0.110802, Val Acc: 0.783505\n",
      "Epoch 20293 - Train Loss: 0.080726, Train Acc: 0.875641 | Val Loss: 0.110801, Val Acc: 0.783505\n",
      "Epoch 20294 - Train Loss: 0.080723, Train Acc: 0.875641 | Val Loss: 0.110801, Val Acc: 0.783505\n",
      "Epoch 20295 - Train Loss: 0.080721, Train Acc: 0.875641 | Val Loss: 0.110800, Val Acc: 0.783505\n",
      "Epoch 20296 - Train Loss: 0.080719, Train Acc: 0.875641 | Val Loss: 0.110799, Val Acc: 0.783505\n",
      "Epoch 20297 - Train Loss: 0.080717, Train Acc: 0.875641 | Val Loss: 0.110798, Val Acc: 0.783505\n",
      "Epoch 20298 - Train Loss: 0.080715, Train Acc: 0.875641 | Val Loss: 0.110797, Val Acc: 0.783505\n",
      "Epoch 20299 - Train Loss: 0.080712, Train Acc: 0.875641 | Val Loss: 0.110796, Val Acc: 0.783505\n",
      "Epoch 20300 - Train Loss: 0.080710, Train Acc: 0.875641 | Val Loss: 0.110795, Val Acc: 0.783505\n",
      "Epoch 20301 - Train Loss: 0.080708, Train Acc: 0.875641 | Val Loss: 0.110794, Val Acc: 0.783505\n",
      "Epoch 20302 - Train Loss: 0.080706, Train Acc: 0.875641 | Val Loss: 0.110793, Val Acc: 0.783505\n",
      "Epoch 20303 - Train Loss: 0.080703, Train Acc: 0.875641 | Val Loss: 0.110792, Val Acc: 0.783505\n",
      "Epoch 20304 - Train Loss: 0.080701, Train Acc: 0.875641 | Val Loss: 0.110791, Val Acc: 0.783505\n",
      "Epoch 20305 - Train Loss: 0.080699, Train Acc: 0.875641 | Val Loss: 0.110790, Val Acc: 0.783505\n",
      "Epoch 20306 - Train Loss: 0.080697, Train Acc: 0.875641 | Val Loss: 0.110789, Val Acc: 0.783505\n",
      "Epoch 20307 - Train Loss: 0.080695, Train Acc: 0.875641 | Val Loss: 0.110789, Val Acc: 0.783505\n",
      "Epoch 20308 - Train Loss: 0.080692, Train Acc: 0.875641 | Val Loss: 0.110788, Val Acc: 0.783505\n",
      "Epoch 20309 - Train Loss: 0.080690, Train Acc: 0.875641 | Val Loss: 0.110787, Val Acc: 0.783505\n",
      "Epoch 20310 - Train Loss: 0.080688, Train Acc: 0.875641 | Val Loss: 0.110786, Val Acc: 0.783505\n",
      "Epoch 20311 - Train Loss: 0.080686, Train Acc: 0.875641 | Val Loss: 0.110785, Val Acc: 0.783505\n",
      "Epoch 20312 - Train Loss: 0.080683, Train Acc: 0.875641 | Val Loss: 0.110784, Val Acc: 0.783505\n",
      "Epoch 20313 - Train Loss: 0.080681, Train Acc: 0.875641 | Val Loss: 0.110783, Val Acc: 0.783505\n",
      "Epoch 20314 - Train Loss: 0.080679, Train Acc: 0.875641 | Val Loss: 0.110782, Val Acc: 0.783505\n",
      "Epoch 20315 - Train Loss: 0.080677, Train Acc: 0.875641 | Val Loss: 0.110781, Val Acc: 0.783505\n",
      "Epoch 20316 - Train Loss: 0.080675, Train Acc: 0.875641 | Val Loss: 0.110780, Val Acc: 0.783505\n",
      "Epoch 20317 - Train Loss: 0.080672, Train Acc: 0.875641 | Val Loss: 0.110779, Val Acc: 0.783505\n",
      "Epoch 20318 - Train Loss: 0.080670, Train Acc: 0.875641 | Val Loss: 0.110778, Val Acc: 0.783505\n",
      "Epoch 20319 - Train Loss: 0.080668, Train Acc: 0.875641 | Val Loss: 0.110777, Val Acc: 0.783505\n",
      "Epoch 20320 - Train Loss: 0.080666, Train Acc: 0.875641 | Val Loss: 0.110777, Val Acc: 0.783505\n",
      "Epoch 20321 - Train Loss: 0.080663, Train Acc: 0.875641 | Val Loss: 0.110776, Val Acc: 0.783505\n",
      "Epoch 20322 - Train Loss: 0.080661, Train Acc: 0.875641 | Val Loss: 0.110775, Val Acc: 0.783505\n",
      "Epoch 20323 - Train Loss: 0.080659, Train Acc: 0.875641 | Val Loss: 0.110774, Val Acc: 0.783505\n",
      "Epoch 20324 - Train Loss: 0.080657, Train Acc: 0.875641 | Val Loss: 0.110773, Val Acc: 0.783505\n",
      "Epoch 20325 - Train Loss: 0.080655, Train Acc: 0.875641 | Val Loss: 0.110772, Val Acc: 0.783505\n",
      "Epoch 20326 - Train Loss: 0.080652, Train Acc: 0.875641 | Val Loss: 0.110771, Val Acc: 0.783505\n",
      "Epoch 20327 - Train Loss: 0.080650, Train Acc: 0.875641 | Val Loss: 0.110770, Val Acc: 0.783505\n",
      "Epoch 20328 - Train Loss: 0.080648, Train Acc: 0.875641 | Val Loss: 0.110769, Val Acc: 0.783505\n",
      "Epoch 20329 - Train Loss: 0.080646, Train Acc: 0.875641 | Val Loss: 0.110768, Val Acc: 0.783505\n",
      "Epoch 20330 - Train Loss: 0.080643, Train Acc: 0.875641 | Val Loss: 0.110767, Val Acc: 0.783505\n",
      "Epoch 20331 - Train Loss: 0.080641, Train Acc: 0.875641 | Val Loss: 0.110767, Val Acc: 0.783505\n",
      "Epoch 20332 - Train Loss: 0.080639, Train Acc: 0.875641 | Val Loss: 0.110766, Val Acc: 0.783505\n",
      "Epoch 20333 - Train Loss: 0.080637, Train Acc: 0.875641 | Val Loss: 0.110765, Val Acc: 0.783505\n",
      "Epoch 20334 - Train Loss: 0.080635, Train Acc: 0.875641 | Val Loss: 0.110764, Val Acc: 0.783505\n",
      "Epoch 20335 - Train Loss: 0.080632, Train Acc: 0.875641 | Val Loss: 0.110763, Val Acc: 0.783505\n",
      "Epoch 20336 - Train Loss: 0.080630, Train Acc: 0.875641 | Val Loss: 0.110762, Val Acc: 0.783505\n",
      "Epoch 20337 - Train Loss: 0.080628, Train Acc: 0.875641 | Val Loss: 0.110761, Val Acc: 0.783505\n",
      "Epoch 20338 - Train Loss: 0.080626, Train Acc: 0.875641 | Val Loss: 0.110760, Val Acc: 0.783505\n",
      "Epoch 20339 - Train Loss: 0.080623, Train Acc: 0.875641 | Val Loss: 0.110759, Val Acc: 0.783505\n",
      "Epoch 20340 - Train Loss: 0.080621, Train Acc: 0.875641 | Val Loss: 0.110758, Val Acc: 0.783505\n",
      "Epoch 20341 - Train Loss: 0.080619, Train Acc: 0.875641 | Val Loss: 0.110757, Val Acc: 0.783505\n",
      "Epoch 20342 - Train Loss: 0.080617, Train Acc: 0.875641 | Val Loss: 0.110757, Val Acc: 0.783505\n",
      "Epoch 20343 - Train Loss: 0.080615, Train Acc: 0.875641 | Val Loss: 0.110756, Val Acc: 0.783505\n",
      "Epoch 20344 - Train Loss: 0.080612, Train Acc: 0.875641 | Val Loss: 0.110755, Val Acc: 0.783505\n",
      "Epoch 20345 - Train Loss: 0.080610, Train Acc: 0.875641 | Val Loss: 0.110754, Val Acc: 0.783505\n",
      "Epoch 20346 - Train Loss: 0.080608, Train Acc: 0.875641 | Val Loss: 0.110753, Val Acc: 0.783505\n",
      "Epoch 20347 - Train Loss: 0.080606, Train Acc: 0.875641 | Val Loss: 0.110752, Val Acc: 0.783505\n",
      "Epoch 20348 - Train Loss: 0.080604, Train Acc: 0.875641 | Val Loss: 0.110751, Val Acc: 0.783505\n",
      "Epoch 20349 - Train Loss: 0.080601, Train Acc: 0.875641 | Val Loss: 0.110750, Val Acc: 0.783505\n",
      "Epoch 20350 - Train Loss: 0.080599, Train Acc: 0.875641 | Val Loss: 0.110749, Val Acc: 0.783505\n",
      "Epoch 20351 - Train Loss: 0.080597, Train Acc: 0.875641 | Val Loss: 0.110748, Val Acc: 0.783505\n",
      "Epoch 20352 - Train Loss: 0.080595, Train Acc: 0.875641 | Val Loss: 0.110747, Val Acc: 0.783505\n",
      "Epoch 20353 - Train Loss: 0.080592, Train Acc: 0.875641 | Val Loss: 0.110747, Val Acc: 0.783505\n",
      "Epoch 20354 - Train Loss: 0.080590, Train Acc: 0.875641 | Val Loss: 0.110746, Val Acc: 0.783505\n",
      "Epoch 20355 - Train Loss: 0.080588, Train Acc: 0.875641 | Val Loss: 0.110745, Val Acc: 0.783505\n",
      "Epoch 20356 - Train Loss: 0.080586, Train Acc: 0.875641 | Val Loss: 0.110744, Val Acc: 0.783505\n",
      "Epoch 20357 - Train Loss: 0.080584, Train Acc: 0.875641 | Val Loss: 0.110743, Val Acc: 0.783505\n",
      "Epoch 20358 - Train Loss: 0.080581, Train Acc: 0.875641 | Val Loss: 0.110742, Val Acc: 0.783505\n",
      "Epoch 20359 - Train Loss: 0.080579, Train Acc: 0.875641 | Val Loss: 0.110741, Val Acc: 0.783505\n",
      "Epoch 20360 - Train Loss: 0.080577, Train Acc: 0.875641 | Val Loss: 0.110740, Val Acc: 0.783505\n",
      "Epoch 20361 - Train Loss: 0.080575, Train Acc: 0.875641 | Val Loss: 0.110739, Val Acc: 0.783505\n",
      "Epoch 20362 - Train Loss: 0.080572, Train Acc: 0.875641 | Val Loss: 0.110738, Val Acc: 0.783505\n",
      "Epoch 20363 - Train Loss: 0.080570, Train Acc: 0.875641 | Val Loss: 0.110737, Val Acc: 0.783505\n",
      "Epoch 20364 - Train Loss: 0.080568, Train Acc: 0.875641 | Val Loss: 0.110737, Val Acc: 0.783505\n",
      "Epoch 20365 - Train Loss: 0.080566, Train Acc: 0.875641 | Val Loss: 0.110736, Val Acc: 0.783505\n",
      "Epoch 20366 - Train Loss: 0.080564, Train Acc: 0.875641 | Val Loss: 0.110735, Val Acc: 0.783505\n",
      "Epoch 20367 - Train Loss: 0.080561, Train Acc: 0.875641 | Val Loss: 0.110734, Val Acc: 0.783505\n",
      "Epoch 20368 - Train Loss: 0.080559, Train Acc: 0.875641 | Val Loss: 0.110733, Val Acc: 0.783505\n",
      "Epoch 20369 - Train Loss: 0.080557, Train Acc: 0.875641 | Val Loss: 0.110732, Val Acc: 0.783505\n",
      "Epoch 20370 - Train Loss: 0.080555, Train Acc: 0.875641 | Val Loss: 0.110731, Val Acc: 0.783505\n",
      "Epoch 20371 - Train Loss: 0.080553, Train Acc: 0.875641 | Val Loss: 0.110730, Val Acc: 0.783505\n",
      "Epoch 20372 - Train Loss: 0.080550, Train Acc: 0.875641 | Val Loss: 0.110729, Val Acc: 0.783505\n",
      "Epoch 20373 - Train Loss: 0.080548, Train Acc: 0.875641 | Val Loss: 0.110728, Val Acc: 0.783505\n",
      "Epoch 20374 - Train Loss: 0.080546, Train Acc: 0.875641 | Val Loss: 0.110728, Val Acc: 0.783505\n",
      "Epoch 20375 - Train Loss: 0.080544, Train Acc: 0.875641 | Val Loss: 0.110727, Val Acc: 0.783505\n",
      "Epoch 20376 - Train Loss: 0.080542, Train Acc: 0.875641 | Val Loss: 0.110726, Val Acc: 0.783505\n",
      "Epoch 20377 - Train Loss: 0.080539, Train Acc: 0.875641 | Val Loss: 0.110725, Val Acc: 0.783505\n",
      "Epoch 20378 - Train Loss: 0.080537, Train Acc: 0.875641 | Val Loss: 0.110724, Val Acc: 0.783505\n",
      "Epoch 20379 - Train Loss: 0.080535, Train Acc: 0.875641 | Val Loss: 0.110723, Val Acc: 0.783505\n",
      "Epoch 20380 - Train Loss: 0.080533, Train Acc: 0.875641 | Val Loss: 0.110722, Val Acc: 0.783505\n",
      "Epoch 20381 - Train Loss: 0.080530, Train Acc: 0.875641 | Val Loss: 0.110721, Val Acc: 0.783505\n",
      "Epoch 20382 - Train Loss: 0.080528, Train Acc: 0.875641 | Val Loss: 0.110720, Val Acc: 0.783505\n",
      "Epoch 20383 - Train Loss: 0.080526, Train Acc: 0.875641 | Val Loss: 0.110719, Val Acc: 0.783505\n",
      "Epoch 20384 - Train Loss: 0.080524, Train Acc: 0.875641 | Val Loss: 0.110719, Val Acc: 0.783505\n",
      "Epoch 20385 - Train Loss: 0.080522, Train Acc: 0.875641 | Val Loss: 0.110718, Val Acc: 0.783505\n",
      "Epoch 20386 - Train Loss: 0.080519, Train Acc: 0.875641 | Val Loss: 0.110717, Val Acc: 0.783505\n",
      "Epoch 20387 - Train Loss: 0.080517, Train Acc: 0.875641 | Val Loss: 0.110716, Val Acc: 0.783505\n",
      "Epoch 20388 - Train Loss: 0.080515, Train Acc: 0.875641 | Val Loss: 0.110715, Val Acc: 0.783505\n",
      "Epoch 20389 - Train Loss: 0.080513, Train Acc: 0.875641 | Val Loss: 0.110714, Val Acc: 0.783505\n",
      "Epoch 20390 - Train Loss: 0.080511, Train Acc: 0.875641 | Val Loss: 0.110713, Val Acc: 0.783505\n",
      "Epoch 20391 - Train Loss: 0.080508, Train Acc: 0.875641 | Val Loss: 0.110712, Val Acc: 0.783505\n",
      "Epoch 20392 - Train Loss: 0.080506, Train Acc: 0.875641 | Val Loss: 0.110711, Val Acc: 0.783505\n",
      "Epoch 20393 - Train Loss: 0.080504, Train Acc: 0.875641 | Val Loss: 0.110710, Val Acc: 0.783505\n",
      "Epoch 20394 - Train Loss: 0.080502, Train Acc: 0.875641 | Val Loss: 0.110710, Val Acc: 0.783505\n",
      "Epoch 20395 - Train Loss: 0.080500, Train Acc: 0.875641 | Val Loss: 0.110709, Val Acc: 0.783505\n",
      "Epoch 20396 - Train Loss: 0.080497, Train Acc: 0.875641 | Val Loss: 0.110708, Val Acc: 0.783505\n",
      "Epoch 20397 - Train Loss: 0.080495, Train Acc: 0.875641 | Val Loss: 0.110707, Val Acc: 0.783505\n",
      "Epoch 20398 - Train Loss: 0.080493, Train Acc: 0.875641 | Val Loss: 0.110706, Val Acc: 0.783505\n",
      "Epoch 20399 - Train Loss: 0.080491, Train Acc: 0.875641 | Val Loss: 0.110705, Val Acc: 0.783505\n",
      "Epoch 20400 - Train Loss: 0.080489, Train Acc: 0.875641 | Val Loss: 0.110704, Val Acc: 0.783505\n",
      "Epoch 20401 - Train Loss: 0.080486, Train Acc: 0.875641 | Val Loss: 0.110703, Val Acc: 0.783505\n",
      "Epoch 20402 - Train Loss: 0.080484, Train Acc: 0.875641 | Val Loss: 0.110702, Val Acc: 0.783505\n",
      "Epoch 20403 - Train Loss: 0.080482, Train Acc: 0.875641 | Val Loss: 0.110702, Val Acc: 0.783505\n",
      "Epoch 20404 - Train Loss: 0.080480, Train Acc: 0.875641 | Val Loss: 0.110701, Val Acc: 0.783505\n",
      "Epoch 20405 - Train Loss: 0.080478, Train Acc: 0.875641 | Val Loss: 0.110700, Val Acc: 0.783505\n",
      "Epoch 20406 - Train Loss: 0.080475, Train Acc: 0.875641 | Val Loss: 0.110699, Val Acc: 0.783505\n",
      "Epoch 20407 - Train Loss: 0.080473, Train Acc: 0.875641 | Val Loss: 0.110698, Val Acc: 0.783505\n",
      "Epoch 20408 - Train Loss: 0.080471, Train Acc: 0.875641 | Val Loss: 0.110697, Val Acc: 0.783505\n",
      "Epoch 20409 - Train Loss: 0.080469, Train Acc: 0.875641 | Val Loss: 0.110696, Val Acc: 0.783505\n",
      "Epoch 20410 - Train Loss: 0.080467, Train Acc: 0.875641 | Val Loss: 0.110695, Val Acc: 0.783505\n",
      "Epoch 20411 - Train Loss: 0.080464, Train Acc: 0.875641 | Val Loss: 0.110694, Val Acc: 0.783505\n",
      "Epoch 20412 - Train Loss: 0.080462, Train Acc: 0.875641 | Val Loss: 0.110693, Val Acc: 0.783505\n",
      "Epoch 20413 - Train Loss: 0.080460, Train Acc: 0.875641 | Val Loss: 0.110692, Val Acc: 0.783505\n",
      "Epoch 20414 - Train Loss: 0.080458, Train Acc: 0.875641 | Val Loss: 0.110692, Val Acc: 0.783505\n",
      "Epoch 20415 - Train Loss: 0.080456, Train Acc: 0.875641 | Val Loss: 0.110691, Val Acc: 0.783505\n",
      "Epoch 20416 - Train Loss: 0.080453, Train Acc: 0.875641 | Val Loss: 0.110690, Val Acc: 0.783505\n",
      "Epoch 20417 - Train Loss: 0.080451, Train Acc: 0.875641 | Val Loss: 0.110689, Val Acc: 0.783505\n",
      "Epoch 20418 - Train Loss: 0.080449, Train Acc: 0.875641 | Val Loss: 0.110688, Val Acc: 0.783505\n",
      "Epoch 20419 - Train Loss: 0.080447, Train Acc: 0.875641 | Val Loss: 0.110687, Val Acc: 0.783505\n",
      "Epoch 20420 - Train Loss: 0.080445, Train Acc: 0.875641 | Val Loss: 0.110686, Val Acc: 0.783505\n",
      "Epoch 20421 - Train Loss: 0.080442, Train Acc: 0.875641 | Val Loss: 0.110685, Val Acc: 0.783505\n",
      "Epoch 20422 - Train Loss: 0.080440, Train Acc: 0.875641 | Val Loss: 0.110684, Val Acc: 0.783505\n",
      "Epoch 20423 - Train Loss: 0.080438, Train Acc: 0.875641 | Val Loss: 0.110683, Val Acc: 0.783505\n",
      "Epoch 20424 - Train Loss: 0.080436, Train Acc: 0.875641 | Val Loss: 0.110683, Val Acc: 0.783505\n",
      "Epoch 20425 - Train Loss: 0.080434, Train Acc: 0.875641 | Val Loss: 0.110682, Val Acc: 0.783505\n",
      "Epoch 20426 - Train Loss: 0.080431, Train Acc: 0.875641 | Val Loss: 0.110681, Val Acc: 0.783505\n",
      "Epoch 20427 - Train Loss: 0.080429, Train Acc: 0.875641 | Val Loss: 0.110680, Val Acc: 0.783505\n",
      "Epoch 20428 - Train Loss: 0.080427, Train Acc: 0.875641 | Val Loss: 0.110679, Val Acc: 0.783505\n",
      "Epoch 20429 - Train Loss: 0.080425, Train Acc: 0.875641 | Val Loss: 0.110678, Val Acc: 0.783505\n",
      "Epoch 20430 - Train Loss: 0.080423, Train Acc: 0.875641 | Val Loss: 0.110677, Val Acc: 0.783505\n",
      "Epoch 20431 - Train Loss: 0.080420, Train Acc: 0.875641 | Val Loss: 0.110676, Val Acc: 0.783505\n",
      "Epoch 20432 - Train Loss: 0.080418, Train Acc: 0.875641 | Val Loss: 0.110675, Val Acc: 0.783505\n",
      "Epoch 20433 - Train Loss: 0.080416, Train Acc: 0.875641 | Val Loss: 0.110674, Val Acc: 0.783505\n",
      "Epoch 20434 - Train Loss: 0.080414, Train Acc: 0.875641 | Val Loss: 0.110674, Val Acc: 0.783505\n",
      "Epoch 20435 - Train Loss: 0.080412, Train Acc: 0.875641 | Val Loss: 0.110673, Val Acc: 0.783505\n",
      "Epoch 20436 - Train Loss: 0.080409, Train Acc: 0.875641 | Val Loss: 0.110672, Val Acc: 0.783505\n",
      "Epoch 20437 - Train Loss: 0.080407, Train Acc: 0.875641 | Val Loss: 0.110671, Val Acc: 0.783505\n",
      "Epoch 20438 - Train Loss: 0.080405, Train Acc: 0.875641 | Val Loss: 0.110670, Val Acc: 0.783505\n",
      "Epoch 20439 - Train Loss: 0.080403, Train Acc: 0.875641 | Val Loss: 0.110669, Val Acc: 0.783505\n",
      "Epoch 20440 - Train Loss: 0.080401, Train Acc: 0.875641 | Val Loss: 0.110668, Val Acc: 0.783505\n",
      "Epoch 20441 - Train Loss: 0.080398, Train Acc: 0.875641 | Val Loss: 0.110667, Val Acc: 0.783505\n",
      "Epoch 20442 - Train Loss: 0.080396, Train Acc: 0.875641 | Val Loss: 0.110666, Val Acc: 0.783505\n",
      "Epoch 20443 - Train Loss: 0.080394, Train Acc: 0.875641 | Val Loss: 0.110665, Val Acc: 0.783505\n",
      "Epoch 20444 - Train Loss: 0.080392, Train Acc: 0.875641 | Val Loss: 0.110665, Val Acc: 0.783505\n",
      "Epoch 20445 - Train Loss: 0.080390, Train Acc: 0.875641 | Val Loss: 0.110664, Val Acc: 0.783505\n",
      "Epoch 20446 - Train Loss: 0.080387, Train Acc: 0.875641 | Val Loss: 0.110663, Val Acc: 0.783505\n",
      "Epoch 20447 - Train Loss: 0.080385, Train Acc: 0.875641 | Val Loss: 0.110662, Val Acc: 0.783505\n",
      "Epoch 20448 - Train Loss: 0.080383, Train Acc: 0.875641 | Val Loss: 0.110661, Val Acc: 0.783505\n",
      "Epoch 20449 - Train Loss: 0.080381, Train Acc: 0.875641 | Val Loss: 0.110660, Val Acc: 0.783505\n",
      "Epoch 20450 - Train Loss: 0.080379, Train Acc: 0.875641 | Val Loss: 0.110659, Val Acc: 0.783505\n",
      "Epoch 20451 - Train Loss: 0.080376, Train Acc: 0.875641 | Val Loss: 0.110658, Val Acc: 0.783505\n",
      "Epoch 20452 - Train Loss: 0.080374, Train Acc: 0.875641 | Val Loss: 0.110658, Val Acc: 0.783505\n",
      "Epoch 20453 - Train Loss: 0.080372, Train Acc: 0.875641 | Val Loss: 0.110657, Val Acc: 0.783505\n",
      "Epoch 20454 - Train Loss: 0.080370, Train Acc: 0.875641 | Val Loss: 0.110656, Val Acc: 0.783505\n",
      "Epoch 20455 - Train Loss: 0.080368, Train Acc: 0.875641 | Val Loss: 0.110655, Val Acc: 0.783505\n",
      "Epoch 20456 - Train Loss: 0.080365, Train Acc: 0.875641 | Val Loss: 0.110654, Val Acc: 0.783505\n",
      "Epoch 20457 - Train Loss: 0.080363, Train Acc: 0.875641 | Val Loss: 0.110653, Val Acc: 0.783505\n",
      "Epoch 20458 - Train Loss: 0.080361, Train Acc: 0.875641 | Val Loss: 0.110652, Val Acc: 0.783505\n",
      "Epoch 20459 - Train Loss: 0.080359, Train Acc: 0.875641 | Val Loss: 0.110651, Val Acc: 0.783505\n",
      "Epoch 20460 - Train Loss: 0.080357, Train Acc: 0.875641 | Val Loss: 0.110650, Val Acc: 0.783505\n",
      "Epoch 20461 - Train Loss: 0.080355, Train Acc: 0.875641 | Val Loss: 0.110650, Val Acc: 0.783505\n",
      "Epoch 20462 - Train Loss: 0.080352, Train Acc: 0.875641 | Val Loss: 0.110649, Val Acc: 0.783505\n",
      "Epoch 20463 - Train Loss: 0.080350, Train Acc: 0.875641 | Val Loss: 0.110648, Val Acc: 0.783505\n",
      "Epoch 20464 - Train Loss: 0.080348, Train Acc: 0.875641 | Val Loss: 0.110647, Val Acc: 0.783505\n",
      "Epoch 20465 - Train Loss: 0.080346, Train Acc: 0.875641 | Val Loss: 0.110646, Val Acc: 0.783505\n",
      "Epoch 20466 - Train Loss: 0.080344, Train Acc: 0.875641 | Val Loss: 0.110645, Val Acc: 0.783505\n",
      "Epoch 20467 - Train Loss: 0.080341, Train Acc: 0.875641 | Val Loss: 0.110644, Val Acc: 0.783505\n",
      "Epoch 20468 - Train Loss: 0.080339, Train Acc: 0.875641 | Val Loss: 0.110643, Val Acc: 0.783505\n",
      "Epoch 20469 - Train Loss: 0.080337, Train Acc: 0.875641 | Val Loss: 0.110642, Val Acc: 0.783505\n",
      "Epoch 20470 - Train Loss: 0.080335, Train Acc: 0.875641 | Val Loss: 0.110642, Val Acc: 0.783505\n",
      "Epoch 20471 - Train Loss: 0.080333, Train Acc: 0.875641 | Val Loss: 0.110641, Val Acc: 0.783505\n",
      "Epoch 20472 - Train Loss: 0.080330, Train Acc: 0.875641 | Val Loss: 0.110640, Val Acc: 0.783505\n",
      "Epoch 20473 - Train Loss: 0.080328, Train Acc: 0.875641 | Val Loss: 0.110639, Val Acc: 0.783505\n",
      "Epoch 20474 - Train Loss: 0.080326, Train Acc: 0.875641 | Val Loss: 0.110638, Val Acc: 0.783505\n",
      "Epoch 20475 - Train Loss: 0.080324, Train Acc: 0.875641 | Val Loss: 0.110637, Val Acc: 0.783505\n",
      "Epoch 20476 - Train Loss: 0.080322, Train Acc: 0.875641 | Val Loss: 0.110636, Val Acc: 0.783505\n",
      "Epoch 20477 - Train Loss: 0.080319, Train Acc: 0.875641 | Val Loss: 0.110635, Val Acc: 0.783505\n",
      "Epoch 20478 - Train Loss: 0.080317, Train Acc: 0.875641 | Val Loss: 0.110634, Val Acc: 0.783505\n",
      "Epoch 20479 - Train Loss: 0.080315, Train Acc: 0.875641 | Val Loss: 0.110634, Val Acc: 0.783505\n",
      "Epoch 20480 - Train Loss: 0.080313, Train Acc: 0.875641 | Val Loss: 0.110633, Val Acc: 0.783505\n",
      "Epoch 20481 - Train Loss: 0.080311, Train Acc: 0.875641 | Val Loss: 0.110632, Val Acc: 0.783505\n",
      "Epoch 20482 - Train Loss: 0.080309, Train Acc: 0.875641 | Val Loss: 0.110631, Val Acc: 0.783505\n",
      "Epoch 20483 - Train Loss: 0.080306, Train Acc: 0.875641 | Val Loss: 0.110630, Val Acc: 0.783505\n",
      "Epoch 20484 - Train Loss: 0.080304, Train Acc: 0.875641 | Val Loss: 0.110629, Val Acc: 0.783505\n",
      "Epoch 20485 - Train Loss: 0.080302, Train Acc: 0.875641 | Val Loss: 0.110628, Val Acc: 0.783505\n",
      "Epoch 20486 - Train Loss: 0.080300, Train Acc: 0.875641 | Val Loss: 0.110627, Val Acc: 0.783505\n",
      "Epoch 20487 - Train Loss: 0.080298, Train Acc: 0.875641 | Val Loss: 0.110627, Val Acc: 0.783505\n",
      "Epoch 20488 - Train Loss: 0.080295, Train Acc: 0.875641 | Val Loss: 0.110626, Val Acc: 0.783505\n",
      "Epoch 20489 - Train Loss: 0.080293, Train Acc: 0.875641 | Val Loss: 0.110625, Val Acc: 0.783505\n",
      "Epoch 20490 - Train Loss: 0.080291, Train Acc: 0.875641 | Val Loss: 0.110624, Val Acc: 0.783505\n",
      "Epoch 20491 - Train Loss: 0.080289, Train Acc: 0.875641 | Val Loss: 0.110623, Val Acc: 0.783505\n",
      "Epoch 20492 - Train Loss: 0.080287, Train Acc: 0.875641 | Val Loss: 0.110622, Val Acc: 0.783505\n",
      "Epoch 20493 - Train Loss: 0.080285, Train Acc: 0.875641 | Val Loss: 0.110621, Val Acc: 0.783505\n",
      "Epoch 20494 - Train Loss: 0.080282, Train Acc: 0.875641 | Val Loss: 0.110620, Val Acc: 0.783505\n",
      "Epoch 20495 - Train Loss: 0.080280, Train Acc: 0.875641 | Val Loss: 0.110620, Val Acc: 0.783505\n",
      "Epoch 20496 - Train Loss: 0.080278, Train Acc: 0.875641 | Val Loss: 0.110619, Val Acc: 0.783505\n",
      "Epoch 20497 - Train Loss: 0.080276, Train Acc: 0.875641 | Val Loss: 0.110618, Val Acc: 0.783505\n",
      "Epoch 20498 - Train Loss: 0.080274, Train Acc: 0.875641 | Val Loss: 0.110617, Val Acc: 0.783505\n",
      "Epoch 20499 - Train Loss: 0.080271, Train Acc: 0.875641 | Val Loss: 0.110616, Val Acc: 0.783505\n",
      "Epoch 20500 - Train Loss: 0.080269, Train Acc: 0.875641 | Val Loss: 0.110615, Val Acc: 0.783505\n",
      "Epoch 20501 - Train Loss: 0.080267, Train Acc: 0.875641 | Val Loss: 0.110614, Val Acc: 0.783505\n",
      "Epoch 20502 - Train Loss: 0.080265, Train Acc: 0.875641 | Val Loss: 0.110613, Val Acc: 0.783505\n",
      "Epoch 20503 - Train Loss: 0.080263, Train Acc: 0.875641 | Val Loss: 0.110613, Val Acc: 0.783505\n",
      "Epoch 20504 - Train Loss: 0.080260, Train Acc: 0.875641 | Val Loss: 0.110612, Val Acc: 0.783505\n",
      "Epoch 20505 - Train Loss: 0.080258, Train Acc: 0.875641 | Val Loss: 0.110611, Val Acc: 0.783505\n",
      "Epoch 20506 - Train Loss: 0.080256, Train Acc: 0.875641 | Val Loss: 0.110610, Val Acc: 0.783505\n",
      "Epoch 20507 - Train Loss: 0.080254, Train Acc: 0.875641 | Val Loss: 0.110609, Val Acc: 0.783505\n",
      "Epoch 20508 - Train Loss: 0.080252, Train Acc: 0.875641 | Val Loss: 0.110608, Val Acc: 0.783505\n",
      "Epoch 20509 - Train Loss: 0.080250, Train Acc: 0.875641 | Val Loss: 0.110607, Val Acc: 0.783505\n",
      "Epoch 20510 - Train Loss: 0.080247, Train Acc: 0.875641 | Val Loss: 0.110606, Val Acc: 0.783505\n",
      "Epoch 20511 - Train Loss: 0.080245, Train Acc: 0.875641 | Val Loss: 0.110606, Val Acc: 0.783505\n",
      "Epoch 20512 - Train Loss: 0.080243, Train Acc: 0.875641 | Val Loss: 0.110605, Val Acc: 0.783505\n",
      "Epoch 20513 - Train Loss: 0.080241, Train Acc: 0.875641 | Val Loss: 0.110604, Val Acc: 0.783505\n",
      "Epoch 20514 - Train Loss: 0.080239, Train Acc: 0.875641 | Val Loss: 0.110603, Val Acc: 0.783505\n",
      "Epoch 20515 - Train Loss: 0.080237, Train Acc: 0.875641 | Val Loss: 0.110602, Val Acc: 0.783505\n",
      "Epoch 20516 - Train Loss: 0.080234, Train Acc: 0.875641 | Val Loss: 0.110601, Val Acc: 0.783505\n",
      "Epoch 20517 - Train Loss: 0.080232, Train Acc: 0.875641 | Val Loss: 0.110600, Val Acc: 0.783505\n",
      "Epoch 20518 - Train Loss: 0.080230, Train Acc: 0.875641 | Val Loss: 0.110599, Val Acc: 0.783505\n",
      "Epoch 20519 - Train Loss: 0.080228, Train Acc: 0.875641 | Val Loss: 0.110599, Val Acc: 0.783505\n",
      "Epoch 20520 - Train Loss: 0.080226, Train Acc: 0.875641 | Val Loss: 0.110598, Val Acc: 0.783505\n",
      "Epoch 20521 - Train Loss: 0.080223, Train Acc: 0.875641 | Val Loss: 0.110597, Val Acc: 0.783505\n",
      "Epoch 20522 - Train Loss: 0.080221, Train Acc: 0.875641 | Val Loss: 0.110596, Val Acc: 0.783505\n",
      "Epoch 20523 - Train Loss: 0.080219, Train Acc: 0.875641 | Val Loss: 0.110595, Val Acc: 0.783505\n",
      "Epoch 20524 - Train Loss: 0.080217, Train Acc: 0.875641 | Val Loss: 0.110594, Val Acc: 0.783505\n",
      "Epoch 20525 - Train Loss: 0.080215, Train Acc: 0.875641 | Val Loss: 0.110593, Val Acc: 0.783505\n",
      "Epoch 20526 - Train Loss: 0.080213, Train Acc: 0.875641 | Val Loss: 0.110592, Val Acc: 0.783505\n",
      "Epoch 20527 - Train Loss: 0.080210, Train Acc: 0.875641 | Val Loss: 0.110592, Val Acc: 0.783505\n",
      "Epoch 20528 - Train Loss: 0.080208, Train Acc: 0.875641 | Val Loss: 0.110591, Val Acc: 0.783505\n",
      "Epoch 20529 - Train Loss: 0.080206, Train Acc: 0.875641 | Val Loss: 0.110590, Val Acc: 0.783505\n",
      "Epoch 20530 - Train Loss: 0.080204, Train Acc: 0.875641 | Val Loss: 0.110589, Val Acc: 0.783505\n",
      "Epoch 20531 - Train Loss: 0.080202, Train Acc: 0.875641 | Val Loss: 0.110588, Val Acc: 0.783505\n",
      "Epoch 20532 - Train Loss: 0.080199, Train Acc: 0.875641 | Val Loss: 0.110587, Val Acc: 0.783505\n",
      "Epoch 20533 - Train Loss: 0.080197, Train Acc: 0.875641 | Val Loss: 0.110586, Val Acc: 0.783505\n",
      "Epoch 20534 - Train Loss: 0.080195, Train Acc: 0.875641 | Val Loss: 0.110586, Val Acc: 0.783505\n",
      "Epoch 20535 - Train Loss: 0.080193, Train Acc: 0.875641 | Val Loss: 0.110585, Val Acc: 0.783505\n",
      "Epoch 20536 - Train Loss: 0.080191, Train Acc: 0.875641 | Val Loss: 0.110584, Val Acc: 0.783505\n",
      "Epoch 20537 - Train Loss: 0.080189, Train Acc: 0.875641 | Val Loss: 0.110583, Val Acc: 0.783505\n",
      "Epoch 20538 - Train Loss: 0.080186, Train Acc: 0.875641 | Val Loss: 0.110582, Val Acc: 0.783505\n",
      "Epoch 20539 - Train Loss: 0.080184, Train Acc: 0.875641 | Val Loss: 0.110581, Val Acc: 0.783505\n",
      "Epoch 20540 - Train Loss: 0.080182, Train Acc: 0.875641 | Val Loss: 0.110580, Val Acc: 0.783505\n",
      "Epoch 20541 - Train Loss: 0.080180, Train Acc: 0.875641 | Val Loss: 0.110579, Val Acc: 0.783505\n",
      "Epoch 20542 - Train Loss: 0.080178, Train Acc: 0.875641 | Val Loss: 0.110578, Val Acc: 0.783505\n",
      "Epoch 20543 - Train Loss: 0.080176, Train Acc: 0.875641 | Val Loss: 0.110578, Val Acc: 0.783505\n",
      "Epoch 20544 - Train Loss: 0.080173, Train Acc: 0.875641 | Val Loss: 0.110577, Val Acc: 0.783505\n",
      "Epoch 20545 - Train Loss: 0.080171, Train Acc: 0.875641 | Val Loss: 0.110576, Val Acc: 0.783505\n",
      "Epoch 20546 - Train Loss: 0.080169, Train Acc: 0.875641 | Val Loss: 0.110575, Val Acc: 0.783505\n",
      "Epoch 20547 - Train Loss: 0.080167, Train Acc: 0.875641 | Val Loss: 0.110574, Val Acc: 0.783505\n",
      "Epoch 20548 - Train Loss: 0.080165, Train Acc: 0.875641 | Val Loss: 0.110573, Val Acc: 0.783505\n",
      "Epoch 20549 - Train Loss: 0.080163, Train Acc: 0.875641 | Val Loss: 0.110572, Val Acc: 0.783505\n",
      "Epoch 20550 - Train Loss: 0.080160, Train Acc: 0.875641 | Val Loss: 0.110572, Val Acc: 0.783505\n",
      "Epoch 20551 - Train Loss: 0.080158, Train Acc: 0.875641 | Val Loss: 0.110571, Val Acc: 0.783505\n",
      "Epoch 20552 - Train Loss: 0.080156, Train Acc: 0.875641 | Val Loss: 0.110570, Val Acc: 0.783505\n",
      "Epoch 20553 - Train Loss: 0.080154, Train Acc: 0.875641 | Val Loss: 0.110569, Val Acc: 0.783505\n",
      "Epoch 20554 - Train Loss: 0.080152, Train Acc: 0.875641 | Val Loss: 0.110568, Val Acc: 0.783505\n",
      "Epoch 20555 - Train Loss: 0.080149, Train Acc: 0.876923 | Val Loss: 0.110567, Val Acc: 0.783505\n",
      "Epoch 20556 - Train Loss: 0.080147, Train Acc: 0.878205 | Val Loss: 0.110566, Val Acc: 0.783505\n",
      "Epoch 20557 - Train Loss: 0.080145, Train Acc: 0.878205 | Val Loss: 0.110565, Val Acc: 0.783505\n",
      "Epoch 20558 - Train Loss: 0.080143, Train Acc: 0.878205 | Val Loss: 0.110565, Val Acc: 0.783505\n",
      "Epoch 20559 - Train Loss: 0.080141, Train Acc: 0.878205 | Val Loss: 0.110564, Val Acc: 0.783505\n",
      "Epoch 20560 - Train Loss: 0.080139, Train Acc: 0.878205 | Val Loss: 0.110563, Val Acc: 0.783505\n",
      "Epoch 20561 - Train Loss: 0.080136, Train Acc: 0.878205 | Val Loss: 0.110562, Val Acc: 0.783505\n",
      "Epoch 20562 - Train Loss: 0.080134, Train Acc: 0.878205 | Val Loss: 0.110561, Val Acc: 0.783505\n",
      "Epoch 20563 - Train Loss: 0.080132, Train Acc: 0.878205 | Val Loss: 0.110560, Val Acc: 0.783505\n",
      "Epoch 20564 - Train Loss: 0.080130, Train Acc: 0.878205 | Val Loss: 0.110559, Val Acc: 0.783505\n",
      "Epoch 20565 - Train Loss: 0.080128, Train Acc: 0.878205 | Val Loss: 0.110558, Val Acc: 0.783505\n",
      "Epoch 20566 - Train Loss: 0.080126, Train Acc: 0.878205 | Val Loss: 0.110558, Val Acc: 0.783505\n",
      "Epoch 20567 - Train Loss: 0.080123, Train Acc: 0.878205 | Val Loss: 0.110557, Val Acc: 0.783505\n",
      "Epoch 20568 - Train Loss: 0.080121, Train Acc: 0.878205 | Val Loss: 0.110556, Val Acc: 0.783505\n",
      "Epoch 20569 - Train Loss: 0.080119, Train Acc: 0.878205 | Val Loss: 0.110555, Val Acc: 0.783505\n",
      "Epoch 20570 - Train Loss: 0.080117, Train Acc: 0.878205 | Val Loss: 0.110554, Val Acc: 0.783505\n",
      "Epoch 20571 - Train Loss: 0.080115, Train Acc: 0.878205 | Val Loss: 0.110553, Val Acc: 0.783505\n",
      "Epoch 20572 - Train Loss: 0.080113, Train Acc: 0.878205 | Val Loss: 0.110552, Val Acc: 0.783505\n",
      "Epoch 20573 - Train Loss: 0.080110, Train Acc: 0.878205 | Val Loss: 0.110551, Val Acc: 0.783505\n",
      "Epoch 20574 - Train Loss: 0.080108, Train Acc: 0.878205 | Val Loss: 0.110551, Val Acc: 0.783505\n",
      "Epoch 20575 - Train Loss: 0.080106, Train Acc: 0.878205 | Val Loss: 0.110550, Val Acc: 0.783505\n",
      "Epoch 20576 - Train Loss: 0.080104, Train Acc: 0.878205 | Val Loss: 0.110549, Val Acc: 0.783505\n",
      "Epoch 20577 - Train Loss: 0.080102, Train Acc: 0.878205 | Val Loss: 0.110548, Val Acc: 0.783505\n",
      "Epoch 20578 - Train Loss: 0.080100, Train Acc: 0.878205 | Val Loss: 0.110547, Val Acc: 0.783505\n",
      "Epoch 20579 - Train Loss: 0.080097, Train Acc: 0.878205 | Val Loss: 0.110546, Val Acc: 0.783505\n",
      "Epoch 20580 - Train Loss: 0.080095, Train Acc: 0.878205 | Val Loss: 0.110545, Val Acc: 0.783505\n",
      "Epoch 20581 - Train Loss: 0.080093, Train Acc: 0.878205 | Val Loss: 0.110545, Val Acc: 0.783505\n",
      "Epoch 20582 - Train Loss: 0.080091, Train Acc: 0.878205 | Val Loss: 0.110544, Val Acc: 0.783505\n",
      "Epoch 20583 - Train Loss: 0.080089, Train Acc: 0.878205 | Val Loss: 0.110543, Val Acc: 0.783505\n",
      "Epoch 20584 - Train Loss: 0.080087, Train Acc: 0.878205 | Val Loss: 0.110542, Val Acc: 0.783505\n",
      "Epoch 20585 - Train Loss: 0.080084, Train Acc: 0.878205 | Val Loss: 0.110541, Val Acc: 0.783505\n",
      "Epoch 20586 - Train Loss: 0.080082, Train Acc: 0.878205 | Val Loss: 0.110540, Val Acc: 0.783505\n",
      "Epoch 20587 - Train Loss: 0.080080, Train Acc: 0.878205 | Val Loss: 0.110539, Val Acc: 0.783505\n",
      "Epoch 20588 - Train Loss: 0.080078, Train Acc: 0.878205 | Val Loss: 0.110538, Val Acc: 0.783505\n",
      "Epoch 20589 - Train Loss: 0.080076, Train Acc: 0.878205 | Val Loss: 0.110538, Val Acc: 0.783505\n",
      "Epoch 20590 - Train Loss: 0.080074, Train Acc: 0.878205 | Val Loss: 0.110537, Val Acc: 0.783505\n",
      "Epoch 20591 - Train Loss: 0.080071, Train Acc: 0.878205 | Val Loss: 0.110536, Val Acc: 0.783505\n",
      "Epoch 20592 - Train Loss: 0.080069, Train Acc: 0.878205 | Val Loss: 0.110535, Val Acc: 0.783505\n",
      "Epoch 20593 - Train Loss: 0.080067, Train Acc: 0.878205 | Val Loss: 0.110534, Val Acc: 0.783505\n",
      "Epoch 20594 - Train Loss: 0.080065, Train Acc: 0.878205 | Val Loss: 0.110533, Val Acc: 0.783505\n",
      "Epoch 20595 - Train Loss: 0.080063, Train Acc: 0.878205 | Val Loss: 0.110532, Val Acc: 0.783505\n",
      "Epoch 20596 - Train Loss: 0.080061, Train Acc: 0.878205 | Val Loss: 0.110532, Val Acc: 0.783505\n",
      "Epoch 20597 - Train Loss: 0.080059, Train Acc: 0.878205 | Val Loss: 0.110531, Val Acc: 0.783505\n",
      "Epoch 20598 - Train Loss: 0.080056, Train Acc: 0.878205 | Val Loss: 0.110530, Val Acc: 0.783505\n",
      "Epoch 20599 - Train Loss: 0.080054, Train Acc: 0.878205 | Val Loss: 0.110529, Val Acc: 0.783505\n",
      "Epoch 20600 - Train Loss: 0.080052, Train Acc: 0.878205 | Val Loss: 0.110528, Val Acc: 0.783505\n",
      "Epoch 20601 - Train Loss: 0.080050, Train Acc: 0.878205 | Val Loss: 0.110527, Val Acc: 0.783505\n",
      "Epoch 20602 - Train Loss: 0.080048, Train Acc: 0.878205 | Val Loss: 0.110526, Val Acc: 0.783505\n",
      "Epoch 20603 - Train Loss: 0.080046, Train Acc: 0.878205 | Val Loss: 0.110525, Val Acc: 0.783505\n",
      "Epoch 20604 - Train Loss: 0.080043, Train Acc: 0.878205 | Val Loss: 0.110525, Val Acc: 0.783505\n",
      "Epoch 20605 - Train Loss: 0.080041, Train Acc: 0.878205 | Val Loss: 0.110524, Val Acc: 0.783505\n",
      "Epoch 20606 - Train Loss: 0.080039, Train Acc: 0.878205 | Val Loss: 0.110523, Val Acc: 0.783505\n",
      "Epoch 20607 - Train Loss: 0.080037, Train Acc: 0.878205 | Val Loss: 0.110522, Val Acc: 0.783505\n",
      "Epoch 20608 - Train Loss: 0.080035, Train Acc: 0.878205 | Val Loss: 0.110521, Val Acc: 0.783505\n",
      "Epoch 20609 - Train Loss: 0.080033, Train Acc: 0.878205 | Val Loss: 0.110520, Val Acc: 0.783505\n",
      "Epoch 20610 - Train Loss: 0.080030, Train Acc: 0.878205 | Val Loss: 0.110519, Val Acc: 0.783505\n",
      "Epoch 20611 - Train Loss: 0.080028, Train Acc: 0.878205 | Val Loss: 0.110519, Val Acc: 0.783505\n",
      "Epoch 20612 - Train Loss: 0.080026, Train Acc: 0.878205 | Val Loss: 0.110518, Val Acc: 0.783505\n",
      "Epoch 20613 - Train Loss: 0.080024, Train Acc: 0.878205 | Val Loss: 0.110517, Val Acc: 0.783505\n",
      "Epoch 20614 - Train Loss: 0.080022, Train Acc: 0.878205 | Val Loss: 0.110516, Val Acc: 0.783505\n",
      "Epoch 20615 - Train Loss: 0.080020, Train Acc: 0.878205 | Val Loss: 0.110515, Val Acc: 0.783505\n",
      "Epoch 20616 - Train Loss: 0.080017, Train Acc: 0.878205 | Val Loss: 0.110514, Val Acc: 0.783505\n",
      "Epoch 20617 - Train Loss: 0.080015, Train Acc: 0.878205 | Val Loss: 0.110513, Val Acc: 0.783505\n",
      "Epoch 20618 - Train Loss: 0.080013, Train Acc: 0.878205 | Val Loss: 0.110513, Val Acc: 0.783505\n",
      "Epoch 20619 - Train Loss: 0.080011, Train Acc: 0.878205 | Val Loss: 0.110512, Val Acc: 0.783505\n",
      "Epoch 20620 - Train Loss: 0.080009, Train Acc: 0.878205 | Val Loss: 0.110511, Val Acc: 0.783505\n",
      "Epoch 20621 - Train Loss: 0.080007, Train Acc: 0.878205 | Val Loss: 0.110510, Val Acc: 0.783505\n",
      "Epoch 20622 - Train Loss: 0.080005, Train Acc: 0.878205 | Val Loss: 0.110509, Val Acc: 0.783505\n",
      "Epoch 20623 - Train Loss: 0.080002, Train Acc: 0.878205 | Val Loss: 0.110508, Val Acc: 0.783505\n",
      "Epoch 20624 - Train Loss: 0.080000, Train Acc: 0.878205 | Val Loss: 0.110507, Val Acc: 0.783505\n",
      "Epoch 20625 - Train Loss: 0.079998, Train Acc: 0.878205 | Val Loss: 0.110507, Val Acc: 0.783505\n",
      "Epoch 20626 - Train Loss: 0.079996, Train Acc: 0.878205 | Val Loss: 0.110506, Val Acc: 0.783505\n",
      "Epoch 20627 - Train Loss: 0.079994, Train Acc: 0.878205 | Val Loss: 0.110505, Val Acc: 0.783505\n",
      "Epoch 20628 - Train Loss: 0.079992, Train Acc: 0.878205 | Val Loss: 0.110504, Val Acc: 0.783505\n",
      "Epoch 20629 - Train Loss: 0.079989, Train Acc: 0.878205 | Val Loss: 0.110503, Val Acc: 0.783505\n",
      "Epoch 20630 - Train Loss: 0.079987, Train Acc: 0.878205 | Val Loss: 0.110502, Val Acc: 0.783505\n",
      "Epoch 20631 - Train Loss: 0.079985, Train Acc: 0.878205 | Val Loss: 0.110501, Val Acc: 0.783505\n",
      "Epoch 20632 - Train Loss: 0.079983, Train Acc: 0.878205 | Val Loss: 0.110501, Val Acc: 0.783505\n",
      "Epoch 20633 - Train Loss: 0.079981, Train Acc: 0.878205 | Val Loss: 0.110500, Val Acc: 0.783505\n",
      "Epoch 20634 - Train Loss: 0.079979, Train Acc: 0.878205 | Val Loss: 0.110499, Val Acc: 0.783505\n",
      "Epoch 20635 - Train Loss: 0.079977, Train Acc: 0.878205 | Val Loss: 0.110498, Val Acc: 0.783505\n",
      "Epoch 20636 - Train Loss: 0.079974, Train Acc: 0.878205 | Val Loss: 0.110497, Val Acc: 0.783505\n",
      "Epoch 20637 - Train Loss: 0.079972, Train Acc: 0.878205 | Val Loss: 0.110496, Val Acc: 0.783505\n",
      "Epoch 20638 - Train Loss: 0.079970, Train Acc: 0.878205 | Val Loss: 0.110495, Val Acc: 0.783505\n",
      "Epoch 20639 - Train Loss: 0.079968, Train Acc: 0.878205 | Val Loss: 0.110494, Val Acc: 0.783505\n",
      "Epoch 20640 - Train Loss: 0.079966, Train Acc: 0.878205 | Val Loss: 0.110494, Val Acc: 0.783505\n",
      "Epoch 20641 - Train Loss: 0.079964, Train Acc: 0.878205 | Val Loss: 0.110493, Val Acc: 0.783505\n",
      "Epoch 20642 - Train Loss: 0.079961, Train Acc: 0.878205 | Val Loss: 0.110492, Val Acc: 0.783505\n",
      "Epoch 20643 - Train Loss: 0.079959, Train Acc: 0.878205 | Val Loss: 0.110491, Val Acc: 0.783505\n",
      "Epoch 20644 - Train Loss: 0.079957, Train Acc: 0.878205 | Val Loss: 0.110490, Val Acc: 0.783505\n",
      "Epoch 20645 - Train Loss: 0.079955, Train Acc: 0.878205 | Val Loss: 0.110489, Val Acc: 0.783505\n",
      "Epoch 20646 - Train Loss: 0.079953, Train Acc: 0.878205 | Val Loss: 0.110489, Val Acc: 0.783505\n",
      "Epoch 20647 - Train Loss: 0.079951, Train Acc: 0.878205 | Val Loss: 0.110488, Val Acc: 0.783505\n",
      "Epoch 20648 - Train Loss: 0.079949, Train Acc: 0.878205 | Val Loss: 0.110487, Val Acc: 0.783505\n",
      "Epoch 20649 - Train Loss: 0.079946, Train Acc: 0.878205 | Val Loss: 0.110486, Val Acc: 0.783505\n",
      "Epoch 20650 - Train Loss: 0.079944, Train Acc: 0.878205 | Val Loss: 0.110485, Val Acc: 0.783505\n",
      "Epoch 20651 - Train Loss: 0.079942, Train Acc: 0.878205 | Val Loss: 0.110484, Val Acc: 0.783505\n",
      "Epoch 20652 - Train Loss: 0.079940, Train Acc: 0.878205 | Val Loss: 0.110483, Val Acc: 0.783505\n",
      "Epoch 20653 - Train Loss: 0.079938, Train Acc: 0.878205 | Val Loss: 0.110483, Val Acc: 0.783505\n",
      "Epoch 20654 - Train Loss: 0.079936, Train Acc: 0.878205 | Val Loss: 0.110482, Val Acc: 0.783505\n",
      "Epoch 20655 - Train Loss: 0.079933, Train Acc: 0.878205 | Val Loss: 0.110481, Val Acc: 0.783505\n",
      "Epoch 20656 - Train Loss: 0.079931, Train Acc: 0.878205 | Val Loss: 0.110480, Val Acc: 0.783505\n",
      "Epoch 20657 - Train Loss: 0.079929, Train Acc: 0.878205 | Val Loss: 0.110479, Val Acc: 0.783505\n",
      "Epoch 20658 - Train Loss: 0.079927, Train Acc: 0.878205 | Val Loss: 0.110478, Val Acc: 0.783505\n",
      "Epoch 20659 - Train Loss: 0.079925, Train Acc: 0.878205 | Val Loss: 0.110477, Val Acc: 0.783505\n",
      "Epoch 20660 - Train Loss: 0.079923, Train Acc: 0.878205 | Val Loss: 0.110477, Val Acc: 0.783505\n",
      "Epoch 20661 - Train Loss: 0.079921, Train Acc: 0.878205 | Val Loss: 0.110476, Val Acc: 0.783505\n",
      "Epoch 20662 - Train Loss: 0.079918, Train Acc: 0.878205 | Val Loss: 0.110475, Val Acc: 0.783505\n",
      "Epoch 20663 - Train Loss: 0.079916, Train Acc: 0.878205 | Val Loss: 0.110474, Val Acc: 0.783505\n",
      "Epoch 20664 - Train Loss: 0.079914, Train Acc: 0.878205 | Val Loss: 0.110473, Val Acc: 0.783505\n",
      "Epoch 20665 - Train Loss: 0.079912, Train Acc: 0.878205 | Val Loss: 0.110472, Val Acc: 0.783505\n",
      "Epoch 20666 - Train Loss: 0.079910, Train Acc: 0.878205 | Val Loss: 0.110471, Val Acc: 0.783505\n",
      "Epoch 20667 - Train Loss: 0.079908, Train Acc: 0.878205 | Val Loss: 0.110471, Val Acc: 0.783505\n",
      "Epoch 20668 - Train Loss: 0.079906, Train Acc: 0.878205 | Val Loss: 0.110470, Val Acc: 0.783505\n",
      "Epoch 20669 - Train Loss: 0.079903, Train Acc: 0.878205 | Val Loss: 0.110469, Val Acc: 0.783505\n",
      "Epoch 20670 - Train Loss: 0.079901, Train Acc: 0.878205 | Val Loss: 0.110468, Val Acc: 0.783505\n",
      "Epoch 20671 - Train Loss: 0.079899, Train Acc: 0.878205 | Val Loss: 0.110467, Val Acc: 0.783505\n",
      "Epoch 20672 - Train Loss: 0.079897, Train Acc: 0.878205 | Val Loss: 0.110466, Val Acc: 0.783505\n",
      "Epoch 20673 - Train Loss: 0.079895, Train Acc: 0.878205 | Val Loss: 0.110466, Val Acc: 0.783505\n",
      "Epoch 20674 - Train Loss: 0.079893, Train Acc: 0.878205 | Val Loss: 0.110465, Val Acc: 0.783505\n",
      "Epoch 20675 - Train Loss: 0.079891, Train Acc: 0.879487 | Val Loss: 0.110464, Val Acc: 0.783505\n",
      "Epoch 20676 - Train Loss: 0.079888, Train Acc: 0.879487 | Val Loss: 0.110463, Val Acc: 0.783505\n",
      "Epoch 20677 - Train Loss: 0.079886, Train Acc: 0.879487 | Val Loss: 0.110462, Val Acc: 0.783505\n",
      "Epoch 20678 - Train Loss: 0.079884, Train Acc: 0.879487 | Val Loss: 0.110461, Val Acc: 0.783505\n",
      "Epoch 20679 - Train Loss: 0.079882, Train Acc: 0.879487 | Val Loss: 0.110460, Val Acc: 0.783505\n",
      "Epoch 20680 - Train Loss: 0.079880, Train Acc: 0.879487 | Val Loss: 0.110460, Val Acc: 0.783505\n",
      "Epoch 20681 - Train Loss: 0.079878, Train Acc: 0.879487 | Val Loss: 0.110459, Val Acc: 0.783505\n",
      "Epoch 20682 - Train Loss: 0.079876, Train Acc: 0.879487 | Val Loss: 0.110458, Val Acc: 0.783505\n",
      "Epoch 20683 - Train Loss: 0.079873, Train Acc: 0.879487 | Val Loss: 0.110457, Val Acc: 0.783505\n",
      "Epoch 20684 - Train Loss: 0.079871, Train Acc: 0.879487 | Val Loss: 0.110456, Val Acc: 0.783505\n",
      "Epoch 20685 - Train Loss: 0.079869, Train Acc: 0.879487 | Val Loss: 0.110455, Val Acc: 0.783505\n",
      "Epoch 20686 - Train Loss: 0.079867, Train Acc: 0.879487 | Val Loss: 0.110455, Val Acc: 0.783505\n",
      "Epoch 20687 - Train Loss: 0.079865, Train Acc: 0.879487 | Val Loss: 0.110454, Val Acc: 0.783505\n",
      "Epoch 20688 - Train Loss: 0.079863, Train Acc: 0.879487 | Val Loss: 0.110453, Val Acc: 0.783505\n",
      "Epoch 20689 - Train Loss: 0.079860, Train Acc: 0.879487 | Val Loss: 0.110452, Val Acc: 0.783505\n",
      "Epoch 20690 - Train Loss: 0.079858, Train Acc: 0.879487 | Val Loss: 0.110451, Val Acc: 0.783505\n",
      "Epoch 20691 - Train Loss: 0.079856, Train Acc: 0.879487 | Val Loss: 0.110450, Val Acc: 0.783505\n",
      "Epoch 20692 - Train Loss: 0.079854, Train Acc: 0.879487 | Val Loss: 0.110449, Val Acc: 0.783505\n",
      "Epoch 20693 - Train Loss: 0.079852, Train Acc: 0.879487 | Val Loss: 0.110449, Val Acc: 0.783505\n",
      "Epoch 20694 - Train Loss: 0.079850, Train Acc: 0.879487 | Val Loss: 0.110448, Val Acc: 0.783505\n",
      "Epoch 20695 - Train Loss: 0.079848, Train Acc: 0.879487 | Val Loss: 0.110447, Val Acc: 0.783505\n",
      "Epoch 20696 - Train Loss: 0.079846, Train Acc: 0.879487 | Val Loss: 0.110446, Val Acc: 0.783505\n",
      "Epoch 20697 - Train Loss: 0.079843, Train Acc: 0.879487 | Val Loss: 0.110445, Val Acc: 0.783505\n",
      "Epoch 20698 - Train Loss: 0.079841, Train Acc: 0.879487 | Val Loss: 0.110444, Val Acc: 0.783505\n",
      "Epoch 20699 - Train Loss: 0.079839, Train Acc: 0.879487 | Val Loss: 0.110444, Val Acc: 0.783505\n",
      "Epoch 20700 - Train Loss: 0.079837, Train Acc: 0.879487 | Val Loss: 0.110443, Val Acc: 0.783505\n",
      "Epoch 20701 - Train Loss: 0.079835, Train Acc: 0.879487 | Val Loss: 0.110442, Val Acc: 0.783505\n",
      "Epoch 20702 - Train Loss: 0.079833, Train Acc: 0.879487 | Val Loss: 0.110441, Val Acc: 0.783505\n",
      "Epoch 20703 - Train Loss: 0.079831, Train Acc: 0.879487 | Val Loss: 0.110440, Val Acc: 0.783505\n",
      "Epoch 20704 - Train Loss: 0.079828, Train Acc: 0.879487 | Val Loss: 0.110439, Val Acc: 0.783505\n",
      "Epoch 20705 - Train Loss: 0.079826, Train Acc: 0.879487 | Val Loss: 0.110438, Val Acc: 0.783505\n",
      "Epoch 20706 - Train Loss: 0.079824, Train Acc: 0.879487 | Val Loss: 0.110438, Val Acc: 0.783505\n",
      "Epoch 20707 - Train Loss: 0.079822, Train Acc: 0.879487 | Val Loss: 0.110437, Val Acc: 0.783505\n",
      "Epoch 20708 - Train Loss: 0.079820, Train Acc: 0.879487 | Val Loss: 0.110436, Val Acc: 0.783505\n",
      "Epoch 20709 - Train Loss: 0.079818, Train Acc: 0.879487 | Val Loss: 0.110435, Val Acc: 0.783505\n",
      "Epoch 20710 - Train Loss: 0.079816, Train Acc: 0.879487 | Val Loss: 0.110434, Val Acc: 0.783505\n",
      "Epoch 20711 - Train Loss: 0.079813, Train Acc: 0.879487 | Val Loss: 0.110433, Val Acc: 0.783505\n",
      "Epoch 20712 - Train Loss: 0.079811, Train Acc: 0.879487 | Val Loss: 0.110433, Val Acc: 0.783505\n",
      "Epoch 20713 - Train Loss: 0.079809, Train Acc: 0.879487 | Val Loss: 0.110432, Val Acc: 0.783505\n",
      "Epoch 20714 - Train Loss: 0.079807, Train Acc: 0.879487 | Val Loss: 0.110431, Val Acc: 0.783505\n",
      "Epoch 20715 - Train Loss: 0.079805, Train Acc: 0.879487 | Val Loss: 0.110430, Val Acc: 0.783505\n",
      "Epoch 20716 - Train Loss: 0.079803, Train Acc: 0.879487 | Val Loss: 0.110429, Val Acc: 0.783505\n",
      "Epoch 20717 - Train Loss: 0.079801, Train Acc: 0.879487 | Val Loss: 0.110428, Val Acc: 0.783505\n",
      "Epoch 20718 - Train Loss: 0.079798, Train Acc: 0.879487 | Val Loss: 0.110428, Val Acc: 0.783505\n",
      "Epoch 20719 - Train Loss: 0.079796, Train Acc: 0.879487 | Val Loss: 0.110427, Val Acc: 0.783505\n",
      "Epoch 20720 - Train Loss: 0.079794, Train Acc: 0.879487 | Val Loss: 0.110426, Val Acc: 0.783505\n",
      "Epoch 20721 - Train Loss: 0.079792, Train Acc: 0.879487 | Val Loss: 0.110425, Val Acc: 0.783505\n",
      "Epoch 20722 - Train Loss: 0.079790, Train Acc: 0.879487 | Val Loss: 0.110424, Val Acc: 0.783505\n",
      "Epoch 20723 - Train Loss: 0.079788, Train Acc: 0.879487 | Val Loss: 0.110423, Val Acc: 0.783505\n",
      "Epoch 20724 - Train Loss: 0.079786, Train Acc: 0.879487 | Val Loss: 0.110422, Val Acc: 0.783505\n",
      "Epoch 20725 - Train Loss: 0.079783, Train Acc: 0.879487 | Val Loss: 0.110422, Val Acc: 0.783505\n",
      "Epoch 20726 - Train Loss: 0.079781, Train Acc: 0.879487 | Val Loss: 0.110421, Val Acc: 0.783505\n",
      "Epoch 20727 - Train Loss: 0.079779, Train Acc: 0.879487 | Val Loss: 0.110420, Val Acc: 0.783505\n",
      "Epoch 20728 - Train Loss: 0.079777, Train Acc: 0.879487 | Val Loss: 0.110419, Val Acc: 0.783505\n",
      "Epoch 20729 - Train Loss: 0.079775, Train Acc: 0.879487 | Val Loss: 0.110418, Val Acc: 0.783505\n",
      "Epoch 20730 - Train Loss: 0.079773, Train Acc: 0.879487 | Val Loss: 0.110417, Val Acc: 0.783505\n",
      "Epoch 20731 - Train Loss: 0.079771, Train Acc: 0.879487 | Val Loss: 0.110417, Val Acc: 0.783505\n",
      "Epoch 20732 - Train Loss: 0.079769, Train Acc: 0.879487 | Val Loss: 0.110416, Val Acc: 0.783505\n",
      "Epoch 20733 - Train Loss: 0.079766, Train Acc: 0.879487 | Val Loss: 0.110415, Val Acc: 0.783505\n",
      "Epoch 20734 - Train Loss: 0.079764, Train Acc: 0.879487 | Val Loss: 0.110414, Val Acc: 0.783505\n",
      "Epoch 20735 - Train Loss: 0.079762, Train Acc: 0.879487 | Val Loss: 0.110413, Val Acc: 0.783505\n",
      "Epoch 20736 - Train Loss: 0.079760, Train Acc: 0.879487 | Val Loss: 0.110412, Val Acc: 0.783505\n",
      "Epoch 20737 - Train Loss: 0.079758, Train Acc: 0.879487 | Val Loss: 0.110412, Val Acc: 0.783505\n",
      "Epoch 20738 - Train Loss: 0.079756, Train Acc: 0.879487 | Val Loss: 0.110411, Val Acc: 0.783505\n",
      "Epoch 20739 - Train Loss: 0.079754, Train Acc: 0.879487 | Val Loss: 0.110410, Val Acc: 0.783505\n",
      "Epoch 20740 - Train Loss: 0.079751, Train Acc: 0.879487 | Val Loss: 0.110409, Val Acc: 0.783505\n",
      "Epoch 20741 - Train Loss: 0.079749, Train Acc: 0.879487 | Val Loss: 0.110408, Val Acc: 0.783505\n",
      "Epoch 20742 - Train Loss: 0.079747, Train Acc: 0.879487 | Val Loss: 0.110407, Val Acc: 0.783505\n",
      "Epoch 20743 - Train Loss: 0.079745, Train Acc: 0.879487 | Val Loss: 0.110407, Val Acc: 0.783505\n",
      "Epoch 20744 - Train Loss: 0.079743, Train Acc: 0.879487 | Val Loss: 0.110406, Val Acc: 0.783505\n",
      "Epoch 20745 - Train Loss: 0.079741, Train Acc: 0.879487 | Val Loss: 0.110405, Val Acc: 0.783505\n",
      "Epoch 20746 - Train Loss: 0.079739, Train Acc: 0.879487 | Val Loss: 0.110404, Val Acc: 0.783505\n",
      "Epoch 20747 - Train Loss: 0.079737, Train Acc: 0.879487 | Val Loss: 0.110403, Val Acc: 0.783505\n",
      "Epoch 20748 - Train Loss: 0.079734, Train Acc: 0.879487 | Val Loss: 0.110402, Val Acc: 0.783505\n",
      "Epoch 20749 - Train Loss: 0.079732, Train Acc: 0.879487 | Val Loss: 0.110402, Val Acc: 0.783505\n",
      "Epoch 20750 - Train Loss: 0.079730, Train Acc: 0.879487 | Val Loss: 0.110401, Val Acc: 0.783505\n",
      "Epoch 20751 - Train Loss: 0.079728, Train Acc: 0.879487 | Val Loss: 0.110400, Val Acc: 0.783505\n",
      "Epoch 20752 - Train Loss: 0.079726, Train Acc: 0.879487 | Val Loss: 0.110399, Val Acc: 0.783505\n",
      "Epoch 20753 - Train Loss: 0.079724, Train Acc: 0.879487 | Val Loss: 0.110398, Val Acc: 0.783505\n",
      "Epoch 20754 - Train Loss: 0.079722, Train Acc: 0.879487 | Val Loss: 0.110397, Val Acc: 0.783505\n",
      "Epoch 20755 - Train Loss: 0.079720, Train Acc: 0.879487 | Val Loss: 0.110397, Val Acc: 0.783505\n",
      "Epoch 20756 - Train Loss: 0.079717, Train Acc: 0.879487 | Val Loss: 0.110396, Val Acc: 0.783505\n",
      "Epoch 20757 - Train Loss: 0.079715, Train Acc: 0.879487 | Val Loss: 0.110395, Val Acc: 0.783505\n",
      "Epoch 20758 - Train Loss: 0.079713, Train Acc: 0.879487 | Val Loss: 0.110394, Val Acc: 0.783505\n",
      "Epoch 20759 - Train Loss: 0.079711, Train Acc: 0.879487 | Val Loss: 0.110393, Val Acc: 0.783505\n",
      "Epoch 20760 - Train Loss: 0.079709, Train Acc: 0.879487 | Val Loss: 0.110392, Val Acc: 0.783505\n",
      "Epoch 20761 - Train Loss: 0.079707, Train Acc: 0.879487 | Val Loss: 0.110392, Val Acc: 0.783505\n",
      "Epoch 20762 - Train Loss: 0.079705, Train Acc: 0.879487 | Val Loss: 0.110391, Val Acc: 0.783505\n",
      "Epoch 20763 - Train Loss: 0.079703, Train Acc: 0.879487 | Val Loss: 0.110390, Val Acc: 0.783505\n",
      "Epoch 20764 - Train Loss: 0.079700, Train Acc: 0.879487 | Val Loss: 0.110389, Val Acc: 0.783505\n",
      "Epoch 20765 - Train Loss: 0.079698, Train Acc: 0.879487 | Val Loss: 0.110388, Val Acc: 0.783505\n",
      "Epoch 20766 - Train Loss: 0.079696, Train Acc: 0.879487 | Val Loss: 0.110387, Val Acc: 0.783505\n",
      "Epoch 20767 - Train Loss: 0.079694, Train Acc: 0.879487 | Val Loss: 0.110387, Val Acc: 0.783505\n",
      "Epoch 20768 - Train Loss: 0.079692, Train Acc: 0.879487 | Val Loss: 0.110386, Val Acc: 0.783505\n",
      "Epoch 20769 - Train Loss: 0.079690, Train Acc: 0.879487 | Val Loss: 0.110385, Val Acc: 0.783505\n",
      "Epoch 20770 - Train Loss: 0.079688, Train Acc: 0.879487 | Val Loss: 0.110384, Val Acc: 0.783505\n",
      "Epoch 20771 - Train Loss: 0.079685, Train Acc: 0.879487 | Val Loss: 0.110383, Val Acc: 0.783505\n",
      "Epoch 20772 - Train Loss: 0.079683, Train Acc: 0.879487 | Val Loss: 0.110382, Val Acc: 0.783505\n",
      "Epoch 20773 - Train Loss: 0.079681, Train Acc: 0.879487 | Val Loss: 0.110382, Val Acc: 0.783505\n",
      "Epoch 20774 - Train Loss: 0.079679, Train Acc: 0.879487 | Val Loss: 0.110381, Val Acc: 0.783505\n",
      "Epoch 20775 - Train Loss: 0.079677, Train Acc: 0.879487 | Val Loss: 0.110380, Val Acc: 0.783505\n",
      "Epoch 20776 - Train Loss: 0.079675, Train Acc: 0.879487 | Val Loss: 0.110379, Val Acc: 0.783505\n",
      "Epoch 20777 - Train Loss: 0.079673, Train Acc: 0.879487 | Val Loss: 0.110378, Val Acc: 0.783505\n",
      "Epoch 20778 - Train Loss: 0.079671, Train Acc: 0.879487 | Val Loss: 0.110377, Val Acc: 0.783505\n",
      "Epoch 20779 - Train Loss: 0.079668, Train Acc: 0.879487 | Val Loss: 0.110377, Val Acc: 0.783505\n",
      "Epoch 20780 - Train Loss: 0.079666, Train Acc: 0.879487 | Val Loss: 0.110376, Val Acc: 0.783505\n",
      "Epoch 20781 - Train Loss: 0.079664, Train Acc: 0.879487 | Val Loss: 0.110375, Val Acc: 0.783505\n",
      "Epoch 20782 - Train Loss: 0.079662, Train Acc: 0.879487 | Val Loss: 0.110374, Val Acc: 0.783505\n",
      "Epoch 20783 - Train Loss: 0.079660, Train Acc: 0.879487 | Val Loss: 0.110373, Val Acc: 0.783505\n",
      "Epoch 20784 - Train Loss: 0.079658, Train Acc: 0.879487 | Val Loss: 0.110372, Val Acc: 0.783505\n",
      "Epoch 20785 - Train Loss: 0.079656, Train Acc: 0.879487 | Val Loss: 0.110372, Val Acc: 0.783505\n",
      "Epoch 20786 - Train Loss: 0.079654, Train Acc: 0.879487 | Val Loss: 0.110371, Val Acc: 0.783505\n",
      "Epoch 20787 - Train Loss: 0.079652, Train Acc: 0.879487 | Val Loss: 0.110370, Val Acc: 0.783505\n",
      "Epoch 20788 - Train Loss: 0.079649, Train Acc: 0.879487 | Val Loss: 0.110369, Val Acc: 0.783505\n",
      "Epoch 20789 - Train Loss: 0.079647, Train Acc: 0.879487 | Val Loss: 0.110368, Val Acc: 0.783505\n",
      "Epoch 20790 - Train Loss: 0.079645, Train Acc: 0.879487 | Val Loss: 0.110368, Val Acc: 0.783505\n",
      "Epoch 20791 - Train Loss: 0.079643, Train Acc: 0.879487 | Val Loss: 0.110367, Val Acc: 0.783505\n",
      "Epoch 20792 - Train Loss: 0.079641, Train Acc: 0.879487 | Val Loss: 0.110366, Val Acc: 0.783505\n",
      "Epoch 20793 - Train Loss: 0.079639, Train Acc: 0.879487 | Val Loss: 0.110365, Val Acc: 0.783505\n",
      "Epoch 20794 - Train Loss: 0.079637, Train Acc: 0.879487 | Val Loss: 0.110364, Val Acc: 0.783505\n",
      "Epoch 20795 - Train Loss: 0.079635, Train Acc: 0.879487 | Val Loss: 0.110363, Val Acc: 0.783505\n",
      "Epoch 20796 - Train Loss: 0.079632, Train Acc: 0.879487 | Val Loss: 0.110363, Val Acc: 0.783505\n",
      "Epoch 20797 - Train Loss: 0.079630, Train Acc: 0.879487 | Val Loss: 0.110362, Val Acc: 0.783505\n",
      "Epoch 20798 - Train Loss: 0.079628, Train Acc: 0.879487 | Val Loss: 0.110361, Val Acc: 0.783505\n",
      "Epoch 20799 - Train Loss: 0.079626, Train Acc: 0.879487 | Val Loss: 0.110360, Val Acc: 0.783505\n",
      "Epoch 20800 - Train Loss: 0.079624, Train Acc: 0.879487 | Val Loss: 0.110359, Val Acc: 0.783505\n",
      "Epoch 20801 - Train Loss: 0.079622, Train Acc: 0.879487 | Val Loss: 0.110358, Val Acc: 0.783505\n",
      "Epoch 20802 - Train Loss: 0.079620, Train Acc: 0.879487 | Val Loss: 0.110358, Val Acc: 0.783505\n",
      "Epoch 20803 - Train Loss: 0.079618, Train Acc: 0.879487 | Val Loss: 0.110357, Val Acc: 0.783505\n",
      "Epoch 20804 - Train Loss: 0.079615, Train Acc: 0.879487 | Val Loss: 0.110356, Val Acc: 0.783505\n",
      "Epoch 20805 - Train Loss: 0.079613, Train Acc: 0.879487 | Val Loss: 0.110355, Val Acc: 0.783505\n",
      "Epoch 20806 - Train Loss: 0.079611, Train Acc: 0.879487 | Val Loss: 0.110354, Val Acc: 0.783505\n",
      "Epoch 20807 - Train Loss: 0.079609, Train Acc: 0.879487 | Val Loss: 0.110354, Val Acc: 0.783505\n",
      "Epoch 20808 - Train Loss: 0.079607, Train Acc: 0.879487 | Val Loss: 0.110353, Val Acc: 0.783505\n",
      "Epoch 20809 - Train Loss: 0.079605, Train Acc: 0.879487 | Val Loss: 0.110352, Val Acc: 0.783505\n",
      "Epoch 20810 - Train Loss: 0.079603, Train Acc: 0.879487 | Val Loss: 0.110351, Val Acc: 0.783505\n",
      "Epoch 20811 - Train Loss: 0.079601, Train Acc: 0.879487 | Val Loss: 0.110350, Val Acc: 0.783505\n",
      "Epoch 20812 - Train Loss: 0.079599, Train Acc: 0.879487 | Val Loss: 0.110349, Val Acc: 0.783505\n",
      "Epoch 20813 - Train Loss: 0.079596, Train Acc: 0.879487 | Val Loss: 0.110349, Val Acc: 0.783505\n",
      "Epoch 20814 - Train Loss: 0.079594, Train Acc: 0.879487 | Val Loss: 0.110348, Val Acc: 0.783505\n",
      "Epoch 20815 - Train Loss: 0.079592, Train Acc: 0.879487 | Val Loss: 0.110347, Val Acc: 0.783505\n",
      "Epoch 20816 - Train Loss: 0.079590, Train Acc: 0.879487 | Val Loss: 0.110346, Val Acc: 0.783505\n",
      "Epoch 20817 - Train Loss: 0.079588, Train Acc: 0.879487 | Val Loss: 0.110345, Val Acc: 0.783505\n",
      "Epoch 20818 - Train Loss: 0.079586, Train Acc: 0.879487 | Val Loss: 0.110344, Val Acc: 0.783505\n",
      "Epoch 20819 - Train Loss: 0.079584, Train Acc: 0.879487 | Val Loss: 0.110344, Val Acc: 0.783505\n",
      "Epoch 20820 - Train Loss: 0.079582, Train Acc: 0.879487 | Val Loss: 0.110343, Val Acc: 0.783505\n",
      "Epoch 20821 - Train Loss: 0.079579, Train Acc: 0.879487 | Val Loss: 0.110342, Val Acc: 0.783505\n",
      "Epoch 20822 - Train Loss: 0.079577, Train Acc: 0.879487 | Val Loss: 0.110341, Val Acc: 0.783505\n",
      "Epoch 20823 - Train Loss: 0.079575, Train Acc: 0.879487 | Val Loss: 0.110340, Val Acc: 0.783505\n",
      "Epoch 20824 - Train Loss: 0.079573, Train Acc: 0.879487 | Val Loss: 0.110340, Val Acc: 0.783505\n",
      "Epoch 20825 - Train Loss: 0.079571, Train Acc: 0.879487 | Val Loss: 0.110339, Val Acc: 0.783505\n",
      "Epoch 20826 - Train Loss: 0.079569, Train Acc: 0.879487 | Val Loss: 0.110338, Val Acc: 0.783505\n",
      "Epoch 20827 - Train Loss: 0.079567, Train Acc: 0.879487 | Val Loss: 0.110337, Val Acc: 0.783505\n",
      "Epoch 20828 - Train Loss: 0.079565, Train Acc: 0.879487 | Val Loss: 0.110336, Val Acc: 0.783505\n",
      "Epoch 20829 - Train Loss: 0.079563, Train Acc: 0.879487 | Val Loss: 0.110335, Val Acc: 0.783505\n",
      "Epoch 20830 - Train Loss: 0.079560, Train Acc: 0.879487 | Val Loss: 0.110335, Val Acc: 0.783505\n",
      "Epoch 20831 - Train Loss: 0.079558, Train Acc: 0.879487 | Val Loss: 0.110334, Val Acc: 0.783505\n",
      "Epoch 20832 - Train Loss: 0.079556, Train Acc: 0.879487 | Val Loss: 0.110333, Val Acc: 0.783505\n",
      "Epoch 20833 - Train Loss: 0.079554, Train Acc: 0.879487 | Val Loss: 0.110332, Val Acc: 0.783505\n",
      "Epoch 20834 - Train Loss: 0.079552, Train Acc: 0.879487 | Val Loss: 0.110331, Val Acc: 0.783505\n",
      "Epoch 20835 - Train Loss: 0.079550, Train Acc: 0.879487 | Val Loss: 0.110330, Val Acc: 0.783505\n",
      "Epoch 20836 - Train Loss: 0.079548, Train Acc: 0.879487 | Val Loss: 0.110330, Val Acc: 0.783505\n",
      "Epoch 20837 - Train Loss: 0.079546, Train Acc: 0.879487 | Val Loss: 0.110329, Val Acc: 0.783505\n",
      "Epoch 20838 - Train Loss: 0.079544, Train Acc: 0.879487 | Val Loss: 0.110328, Val Acc: 0.783505\n",
      "Epoch 20839 - Train Loss: 0.079541, Train Acc: 0.879487 | Val Loss: 0.110327, Val Acc: 0.783505\n",
      "Epoch 20840 - Train Loss: 0.079539, Train Acc: 0.879487 | Val Loss: 0.110326, Val Acc: 0.783505\n",
      "Epoch 20841 - Train Loss: 0.079537, Train Acc: 0.879487 | Val Loss: 0.110326, Val Acc: 0.783505\n",
      "Epoch 20842 - Train Loss: 0.079535, Train Acc: 0.879487 | Val Loss: 0.110325, Val Acc: 0.783505\n",
      "Epoch 20843 - Train Loss: 0.079533, Train Acc: 0.879487 | Val Loss: 0.110324, Val Acc: 0.783505\n",
      "Epoch 20844 - Train Loss: 0.079531, Train Acc: 0.879487 | Val Loss: 0.110323, Val Acc: 0.783505\n",
      "Epoch 20845 - Train Loss: 0.079529, Train Acc: 0.879487 | Val Loss: 0.110322, Val Acc: 0.783505\n",
      "Epoch 20846 - Train Loss: 0.079527, Train Acc: 0.879487 | Val Loss: 0.110322, Val Acc: 0.783505\n",
      "Epoch 20847 - Train Loss: 0.079525, Train Acc: 0.879487 | Val Loss: 0.110321, Val Acc: 0.783505\n",
      "Epoch 20848 - Train Loss: 0.079522, Train Acc: 0.879487 | Val Loss: 0.110320, Val Acc: 0.783505\n",
      "Epoch 20849 - Train Loss: 0.079520, Train Acc: 0.879487 | Val Loss: 0.110319, Val Acc: 0.783505\n",
      "Epoch 20850 - Train Loss: 0.079518, Train Acc: 0.879487 | Val Loss: 0.110318, Val Acc: 0.783505\n",
      "Epoch 20851 - Train Loss: 0.079516, Train Acc: 0.879487 | Val Loss: 0.110317, Val Acc: 0.783505\n",
      "Epoch 20852 - Train Loss: 0.079514, Train Acc: 0.879487 | Val Loss: 0.110317, Val Acc: 0.783505\n",
      "Epoch 20853 - Train Loss: 0.079512, Train Acc: 0.879487 | Val Loss: 0.110316, Val Acc: 0.783505\n",
      "Epoch 20854 - Train Loss: 0.079510, Train Acc: 0.879487 | Val Loss: 0.110315, Val Acc: 0.783505\n",
      "Epoch 20855 - Train Loss: 0.079508, Train Acc: 0.879487 | Val Loss: 0.110314, Val Acc: 0.783505\n",
      "Epoch 20856 - Train Loss: 0.079506, Train Acc: 0.879487 | Val Loss: 0.110313, Val Acc: 0.783505\n",
      "Epoch 20857 - Train Loss: 0.079503, Train Acc: 0.879487 | Val Loss: 0.110313, Val Acc: 0.783505\n",
      "Epoch 20858 - Train Loss: 0.079501, Train Acc: 0.879487 | Val Loss: 0.110312, Val Acc: 0.783505\n",
      "Epoch 20859 - Train Loss: 0.079499, Train Acc: 0.879487 | Val Loss: 0.110311, Val Acc: 0.783505\n",
      "Epoch 20860 - Train Loss: 0.079497, Train Acc: 0.879487 | Val Loss: 0.110310, Val Acc: 0.783505\n",
      "Epoch 20861 - Train Loss: 0.079495, Train Acc: 0.879487 | Val Loss: 0.110309, Val Acc: 0.783505\n",
      "Epoch 20862 - Train Loss: 0.079493, Train Acc: 0.879487 | Val Loss: 0.110308, Val Acc: 0.783505\n",
      "Epoch 20863 - Train Loss: 0.079491, Train Acc: 0.879487 | Val Loss: 0.110308, Val Acc: 0.783505\n",
      "Epoch 20864 - Train Loss: 0.079489, Train Acc: 0.879487 | Val Loss: 0.110307, Val Acc: 0.783505\n",
      "Epoch 20865 - Train Loss: 0.079487, Train Acc: 0.879487 | Val Loss: 0.110306, Val Acc: 0.783505\n",
      "Epoch 20866 - Train Loss: 0.079484, Train Acc: 0.879487 | Val Loss: 0.110305, Val Acc: 0.783505\n",
      "Epoch 20867 - Train Loss: 0.079482, Train Acc: 0.879487 | Val Loss: 0.110304, Val Acc: 0.783505\n",
      "Epoch 20868 - Train Loss: 0.079480, Train Acc: 0.879487 | Val Loss: 0.110304, Val Acc: 0.783505\n",
      "Epoch 20869 - Train Loss: 0.079478, Train Acc: 0.879487 | Val Loss: 0.110303, Val Acc: 0.783505\n",
      "Epoch 20870 - Train Loss: 0.079476, Train Acc: 0.879487 | Val Loss: 0.110302, Val Acc: 0.783505\n",
      "Epoch 20871 - Train Loss: 0.079474, Train Acc: 0.879487 | Val Loss: 0.110301, Val Acc: 0.783505\n",
      "Epoch 20872 - Train Loss: 0.079472, Train Acc: 0.879487 | Val Loss: 0.110300, Val Acc: 0.783505\n",
      "Epoch 20873 - Train Loss: 0.079470, Train Acc: 0.879487 | Val Loss: 0.110300, Val Acc: 0.783505\n",
      "Epoch 20874 - Train Loss: 0.079468, Train Acc: 0.879487 | Val Loss: 0.110299, Val Acc: 0.783505\n",
      "Epoch 20875 - Train Loss: 0.079466, Train Acc: 0.879487 | Val Loss: 0.110298, Val Acc: 0.783505\n",
      "Epoch 20876 - Train Loss: 0.079463, Train Acc: 0.879487 | Val Loss: 0.110297, Val Acc: 0.783505\n",
      "Epoch 20877 - Train Loss: 0.079461, Train Acc: 0.879487 | Val Loss: 0.110296, Val Acc: 0.783505\n",
      "Epoch 20878 - Train Loss: 0.079459, Train Acc: 0.879487 | Val Loss: 0.110295, Val Acc: 0.783505\n",
      "Epoch 20879 - Train Loss: 0.079457, Train Acc: 0.879487 | Val Loss: 0.110295, Val Acc: 0.783505\n",
      "Epoch 20880 - Train Loss: 0.079455, Train Acc: 0.879487 | Val Loss: 0.110294, Val Acc: 0.783505\n",
      "Epoch 20881 - Train Loss: 0.079453, Train Acc: 0.879487 | Val Loss: 0.110293, Val Acc: 0.783505\n",
      "Epoch 20882 - Train Loss: 0.079451, Train Acc: 0.879487 | Val Loss: 0.110292, Val Acc: 0.783505\n",
      "Epoch 20883 - Train Loss: 0.079449, Train Acc: 0.879487 | Val Loss: 0.110291, Val Acc: 0.783505\n",
      "Epoch 20884 - Train Loss: 0.079447, Train Acc: 0.879487 | Val Loss: 0.110291, Val Acc: 0.783505\n",
      "Epoch 20885 - Train Loss: 0.079444, Train Acc: 0.879487 | Val Loss: 0.110290, Val Acc: 0.783505\n",
      "Epoch 20886 - Train Loss: 0.079442, Train Acc: 0.879487 | Val Loss: 0.110289, Val Acc: 0.783505\n",
      "Epoch 20887 - Train Loss: 0.079440, Train Acc: 0.879487 | Val Loss: 0.110288, Val Acc: 0.783505\n",
      "Epoch 20888 - Train Loss: 0.079438, Train Acc: 0.879487 | Val Loss: 0.110287, Val Acc: 0.783505\n",
      "Epoch 20889 - Train Loss: 0.079436, Train Acc: 0.879487 | Val Loss: 0.110287, Val Acc: 0.783505\n",
      "Epoch 20890 - Train Loss: 0.079434, Train Acc: 0.879487 | Val Loss: 0.110286, Val Acc: 0.783505\n",
      "Epoch 20891 - Train Loss: 0.079432, Train Acc: 0.879487 | Val Loss: 0.110285, Val Acc: 0.783505\n",
      "Epoch 20892 - Train Loss: 0.079430, Train Acc: 0.879487 | Val Loss: 0.110284, Val Acc: 0.783505\n",
      "Epoch 20893 - Train Loss: 0.079428, Train Acc: 0.879487 | Val Loss: 0.110283, Val Acc: 0.783505\n",
      "Epoch 20894 - Train Loss: 0.079426, Train Acc: 0.879487 | Val Loss: 0.110282, Val Acc: 0.783505\n",
      "Epoch 20895 - Train Loss: 0.079423, Train Acc: 0.879487 | Val Loss: 0.110282, Val Acc: 0.783505\n",
      "Epoch 20896 - Train Loss: 0.079421, Train Acc: 0.879487 | Val Loss: 0.110281, Val Acc: 0.783505\n",
      "Epoch 20897 - Train Loss: 0.079419, Train Acc: 0.879487 | Val Loss: 0.110280, Val Acc: 0.783505\n",
      "Epoch 20898 - Train Loss: 0.079417, Train Acc: 0.879487 | Val Loss: 0.110279, Val Acc: 0.783505\n",
      "Epoch 20899 - Train Loss: 0.079415, Train Acc: 0.879487 | Val Loss: 0.110278, Val Acc: 0.783505\n",
      "Epoch 20900 - Train Loss: 0.079413, Train Acc: 0.879487 | Val Loss: 0.110278, Val Acc: 0.783505\n",
      "Epoch 20901 - Train Loss: 0.079411, Train Acc: 0.879487 | Val Loss: 0.110277, Val Acc: 0.783505\n",
      "Epoch 20902 - Train Loss: 0.079409, Train Acc: 0.879487 | Val Loss: 0.110276, Val Acc: 0.783505\n",
      "Epoch 20903 - Train Loss: 0.079407, Train Acc: 0.879487 | Val Loss: 0.110275, Val Acc: 0.783505\n",
      "Epoch 20904 - Train Loss: 0.079405, Train Acc: 0.879487 | Val Loss: 0.110274, Val Acc: 0.783505\n",
      "Epoch 20905 - Train Loss: 0.079402, Train Acc: 0.879487 | Val Loss: 0.110274, Val Acc: 0.783505\n",
      "Epoch 20906 - Train Loss: 0.079400, Train Acc: 0.879487 | Val Loss: 0.110273, Val Acc: 0.783505\n",
      "Epoch 20907 - Train Loss: 0.079398, Train Acc: 0.879487 | Val Loss: 0.110272, Val Acc: 0.783505\n",
      "Epoch 20908 - Train Loss: 0.079396, Train Acc: 0.879487 | Val Loss: 0.110271, Val Acc: 0.783505\n",
      "Epoch 20909 - Train Loss: 0.079394, Train Acc: 0.879487 | Val Loss: 0.110270, Val Acc: 0.783505\n",
      "Epoch 20910 - Train Loss: 0.079392, Train Acc: 0.879487 | Val Loss: 0.110269, Val Acc: 0.783505\n",
      "Epoch 20911 - Train Loss: 0.079390, Train Acc: 0.879487 | Val Loss: 0.110269, Val Acc: 0.783505\n",
      "Epoch 20912 - Train Loss: 0.079388, Train Acc: 0.879487 | Val Loss: 0.110268, Val Acc: 0.783505\n",
      "Epoch 20913 - Train Loss: 0.079386, Train Acc: 0.879487 | Val Loss: 0.110267, Val Acc: 0.783505\n",
      "Epoch 20914 - Train Loss: 0.079384, Train Acc: 0.879487 | Val Loss: 0.110266, Val Acc: 0.783505\n",
      "Epoch 20915 - Train Loss: 0.079381, Train Acc: 0.879487 | Val Loss: 0.110265, Val Acc: 0.783505\n",
      "Epoch 20916 - Train Loss: 0.079379, Train Acc: 0.879487 | Val Loss: 0.110265, Val Acc: 0.783505\n",
      "Epoch 20917 - Train Loss: 0.079377, Train Acc: 0.879487 | Val Loss: 0.110264, Val Acc: 0.783505\n",
      "Epoch 20918 - Train Loss: 0.079375, Train Acc: 0.879487 | Val Loss: 0.110263, Val Acc: 0.783505\n",
      "Epoch 20919 - Train Loss: 0.079373, Train Acc: 0.879487 | Val Loss: 0.110262, Val Acc: 0.783505\n",
      "Epoch 20920 - Train Loss: 0.079371, Train Acc: 0.879487 | Val Loss: 0.110261, Val Acc: 0.783505\n",
      "Epoch 20921 - Train Loss: 0.079369, Train Acc: 0.879487 | Val Loss: 0.110261, Val Acc: 0.783505\n",
      "Epoch 20922 - Train Loss: 0.079367, Train Acc: 0.879487 | Val Loss: 0.110260, Val Acc: 0.783505\n",
      "Epoch 20923 - Train Loss: 0.079365, Train Acc: 0.879487 | Val Loss: 0.110259, Val Acc: 0.783505\n",
      "Epoch 20924 - Train Loss: 0.079363, Train Acc: 0.879487 | Val Loss: 0.110258, Val Acc: 0.783505\n",
      "Epoch 20925 - Train Loss: 0.079361, Train Acc: 0.879487 | Val Loss: 0.110257, Val Acc: 0.783505\n",
      "Epoch 20926 - Train Loss: 0.079358, Train Acc: 0.879487 | Val Loss: 0.110257, Val Acc: 0.783505\n",
      "Epoch 20927 - Train Loss: 0.079356, Train Acc: 0.879487 | Val Loss: 0.110256, Val Acc: 0.783505\n",
      "Epoch 20928 - Train Loss: 0.079354, Train Acc: 0.879487 | Val Loss: 0.110255, Val Acc: 0.783505\n",
      "Epoch 20929 - Train Loss: 0.079352, Train Acc: 0.879487 | Val Loss: 0.110254, Val Acc: 0.783505\n",
      "Epoch 20930 - Train Loss: 0.079350, Train Acc: 0.879487 | Val Loss: 0.110253, Val Acc: 0.783505\n",
      "Epoch 20931 - Train Loss: 0.079348, Train Acc: 0.879487 | Val Loss: 0.110253, Val Acc: 0.783505\n",
      "Epoch 20932 - Train Loss: 0.079346, Train Acc: 0.879487 | Val Loss: 0.110252, Val Acc: 0.783505\n",
      "Epoch 20933 - Train Loss: 0.079344, Train Acc: 0.879487 | Val Loss: 0.110251, Val Acc: 0.783505\n",
      "Epoch 20934 - Train Loss: 0.079342, Train Acc: 0.879487 | Val Loss: 0.110250, Val Acc: 0.783505\n",
      "Epoch 20935 - Train Loss: 0.079340, Train Acc: 0.879487 | Val Loss: 0.110249, Val Acc: 0.783505\n",
      "Epoch 20936 - Train Loss: 0.079337, Train Acc: 0.879487 | Val Loss: 0.110249, Val Acc: 0.783505\n",
      "Epoch 20937 - Train Loss: 0.079335, Train Acc: 0.879487 | Val Loss: 0.110248, Val Acc: 0.783505\n",
      "Epoch 20938 - Train Loss: 0.079333, Train Acc: 0.879487 | Val Loss: 0.110247, Val Acc: 0.783505\n",
      "Epoch 20939 - Train Loss: 0.079331, Train Acc: 0.879487 | Val Loss: 0.110246, Val Acc: 0.783505\n",
      "Epoch 20940 - Train Loss: 0.079329, Train Acc: 0.879487 | Val Loss: 0.110245, Val Acc: 0.783505\n",
      "Epoch 20941 - Train Loss: 0.079327, Train Acc: 0.879487 | Val Loss: 0.110244, Val Acc: 0.783505\n",
      "Epoch 20942 - Train Loss: 0.079325, Train Acc: 0.879487 | Val Loss: 0.110244, Val Acc: 0.783505\n",
      "Epoch 20943 - Train Loss: 0.079323, Train Acc: 0.879487 | Val Loss: 0.110243, Val Acc: 0.783505\n",
      "Epoch 20944 - Train Loss: 0.079321, Train Acc: 0.879487 | Val Loss: 0.110242, Val Acc: 0.783505\n",
      "Epoch 20945 - Train Loss: 0.079319, Train Acc: 0.879487 | Val Loss: 0.110241, Val Acc: 0.783505\n",
      "Epoch 20946 - Train Loss: 0.079317, Train Acc: 0.879487 | Val Loss: 0.110240, Val Acc: 0.783505\n",
      "Epoch 20947 - Train Loss: 0.079314, Train Acc: 0.879487 | Val Loss: 0.110240, Val Acc: 0.783505\n",
      "Epoch 20948 - Train Loss: 0.079312, Train Acc: 0.879487 | Val Loss: 0.110239, Val Acc: 0.783505\n",
      "Epoch 20949 - Train Loss: 0.079310, Train Acc: 0.879487 | Val Loss: 0.110238, Val Acc: 0.783505\n",
      "Epoch 20950 - Train Loss: 0.079308, Train Acc: 0.879487 | Val Loss: 0.110237, Val Acc: 0.783505\n",
      "Epoch 20951 - Train Loss: 0.079306, Train Acc: 0.879487 | Val Loss: 0.110236, Val Acc: 0.783505\n",
      "Epoch 20952 - Train Loss: 0.079304, Train Acc: 0.879487 | Val Loss: 0.110236, Val Acc: 0.783505\n",
      "Epoch 20953 - Train Loss: 0.079302, Train Acc: 0.879487 | Val Loss: 0.110235, Val Acc: 0.783505\n",
      "Epoch 20954 - Train Loss: 0.079300, Train Acc: 0.879487 | Val Loss: 0.110234, Val Acc: 0.783505\n",
      "Epoch 20955 - Train Loss: 0.079298, Train Acc: 0.879487 | Val Loss: 0.110233, Val Acc: 0.783505\n",
      "Epoch 20956 - Train Loss: 0.079296, Train Acc: 0.879487 | Val Loss: 0.110232, Val Acc: 0.783505\n",
      "Epoch 20957 - Train Loss: 0.079294, Train Acc: 0.879487 | Val Loss: 0.110232, Val Acc: 0.783505\n",
      "Epoch 20958 - Train Loss: 0.079291, Train Acc: 0.879487 | Val Loss: 0.110231, Val Acc: 0.783505\n",
      "Epoch 20959 - Train Loss: 0.079289, Train Acc: 0.879487 | Val Loss: 0.110230, Val Acc: 0.783505\n",
      "Epoch 20960 - Train Loss: 0.079287, Train Acc: 0.879487 | Val Loss: 0.110229, Val Acc: 0.783505\n",
      "Epoch 20961 - Train Loss: 0.079285, Train Acc: 0.879487 | Val Loss: 0.110229, Val Acc: 0.783505\n",
      "Epoch 20962 - Train Loss: 0.079283, Train Acc: 0.879487 | Val Loss: 0.110228, Val Acc: 0.783505\n",
      "Epoch 20963 - Train Loss: 0.079281, Train Acc: 0.879487 | Val Loss: 0.110227, Val Acc: 0.783505\n",
      "Epoch 20964 - Train Loss: 0.079279, Train Acc: 0.879487 | Val Loss: 0.110226, Val Acc: 0.783505\n",
      "Epoch 20965 - Train Loss: 0.079277, Train Acc: 0.879487 | Val Loss: 0.110225, Val Acc: 0.783505\n",
      "Epoch 20966 - Train Loss: 0.079275, Train Acc: 0.879487 | Val Loss: 0.110225, Val Acc: 0.783505\n",
      "Epoch 20967 - Train Loss: 0.079273, Train Acc: 0.879487 | Val Loss: 0.110224, Val Acc: 0.783505\n",
      "Epoch 20968 - Train Loss: 0.079271, Train Acc: 0.879487 | Val Loss: 0.110223, Val Acc: 0.783505\n",
      "Epoch 20969 - Train Loss: 0.079268, Train Acc: 0.879487 | Val Loss: 0.110222, Val Acc: 0.783505\n",
      "Epoch 20970 - Train Loss: 0.079266, Train Acc: 0.879487 | Val Loss: 0.110221, Val Acc: 0.783505\n",
      "Epoch 20971 - Train Loss: 0.079264, Train Acc: 0.879487 | Val Loss: 0.110221, Val Acc: 0.783505\n",
      "Epoch 20972 - Train Loss: 0.079262, Train Acc: 0.879487 | Val Loss: 0.110220, Val Acc: 0.783505\n",
      "Epoch 20973 - Train Loss: 0.079260, Train Acc: 0.879487 | Val Loss: 0.110219, Val Acc: 0.783505\n",
      "Epoch 20974 - Train Loss: 0.079258, Train Acc: 0.879487 | Val Loss: 0.110218, Val Acc: 0.783505\n",
      "Epoch 20975 - Train Loss: 0.079256, Train Acc: 0.879487 | Val Loss: 0.110217, Val Acc: 0.783505\n",
      "Epoch 20976 - Train Loss: 0.079254, Train Acc: 0.879487 | Val Loss: 0.110217, Val Acc: 0.783505\n",
      "Epoch 20977 - Train Loss: 0.079252, Train Acc: 0.879487 | Val Loss: 0.110216, Val Acc: 0.783505\n",
      "Epoch 20978 - Train Loss: 0.079250, Train Acc: 0.879487 | Val Loss: 0.110215, Val Acc: 0.783505\n",
      "Epoch 20979 - Train Loss: 0.079248, Train Acc: 0.879487 | Val Loss: 0.110214, Val Acc: 0.783505\n",
      "Epoch 20980 - Train Loss: 0.079246, Train Acc: 0.879487 | Val Loss: 0.110213, Val Acc: 0.783505\n",
      "Epoch 20981 - Train Loss: 0.079243, Train Acc: 0.879487 | Val Loss: 0.110213, Val Acc: 0.783505\n",
      "Epoch 20982 - Train Loss: 0.079241, Train Acc: 0.879487 | Val Loss: 0.110212, Val Acc: 0.783505\n",
      "Epoch 20983 - Train Loss: 0.079239, Train Acc: 0.879487 | Val Loss: 0.110211, Val Acc: 0.783505\n",
      "Epoch 20984 - Train Loss: 0.079237, Train Acc: 0.879487 | Val Loss: 0.110210, Val Acc: 0.783505\n",
      "Epoch 20985 - Train Loss: 0.079235, Train Acc: 0.879487 | Val Loss: 0.110210, Val Acc: 0.783505\n",
      "Epoch 20986 - Train Loss: 0.079233, Train Acc: 0.879487 | Val Loss: 0.110209, Val Acc: 0.783505\n",
      "Epoch 20987 - Train Loss: 0.079231, Train Acc: 0.879487 | Val Loss: 0.110208, Val Acc: 0.783505\n",
      "Epoch 20988 - Train Loss: 0.079229, Train Acc: 0.879487 | Val Loss: 0.110207, Val Acc: 0.783505\n",
      "Epoch 20989 - Train Loss: 0.079227, Train Acc: 0.879487 | Val Loss: 0.110206, Val Acc: 0.783505\n",
      "Epoch 20990 - Train Loss: 0.079225, Train Acc: 0.879487 | Val Loss: 0.110206, Val Acc: 0.783505\n",
      "Epoch 20991 - Train Loss: 0.079223, Train Acc: 0.879487 | Val Loss: 0.110205, Val Acc: 0.783505\n",
      "Epoch 20992 - Train Loss: 0.079221, Train Acc: 0.879487 | Val Loss: 0.110204, Val Acc: 0.783505\n",
      "Epoch 20993 - Train Loss: 0.079218, Train Acc: 0.879487 | Val Loss: 0.110203, Val Acc: 0.783505\n",
      "Epoch 20994 - Train Loss: 0.079216, Train Acc: 0.879487 | Val Loss: 0.110202, Val Acc: 0.783505\n",
      "Epoch 20995 - Train Loss: 0.079214, Train Acc: 0.879487 | Val Loss: 0.110202, Val Acc: 0.783505\n",
      "Epoch 20996 - Train Loss: 0.079212, Train Acc: 0.879487 | Val Loss: 0.110201, Val Acc: 0.783505\n",
      "Epoch 20997 - Train Loss: 0.079210, Train Acc: 0.879487 | Val Loss: 0.110200, Val Acc: 0.783505\n",
      "Epoch 20998 - Train Loss: 0.079208, Train Acc: 0.879487 | Val Loss: 0.110199, Val Acc: 0.783505\n",
      "Epoch 20999 - Train Loss: 0.079206, Train Acc: 0.879487 | Val Loss: 0.110198, Val Acc: 0.783505\n",
      "Epoch 21000 - Train Loss: 0.079204, Train Acc: 0.879487 | Val Loss: 0.110198, Val Acc: 0.783505\n",
      "Epoch 21001 - Train Loss: 0.079202, Train Acc: 0.879487 | Val Loss: 0.110197, Val Acc: 0.783505\n",
      "Epoch 21002 - Train Loss: 0.079200, Train Acc: 0.879487 | Val Loss: 0.110196, Val Acc: 0.783505\n",
      "Epoch 21003 - Train Loss: 0.079198, Train Acc: 0.879487 | Val Loss: 0.110195, Val Acc: 0.783505\n",
      "Epoch 21004 - Train Loss: 0.079196, Train Acc: 0.879487 | Val Loss: 0.110195, Val Acc: 0.783505\n",
      "Epoch 21005 - Train Loss: 0.079193, Train Acc: 0.879487 | Val Loss: 0.110194, Val Acc: 0.783505\n",
      "Epoch 21006 - Train Loss: 0.079191, Train Acc: 0.879487 | Val Loss: 0.110193, Val Acc: 0.783505\n",
      "Epoch 21007 - Train Loss: 0.079189, Train Acc: 0.879487 | Val Loss: 0.110192, Val Acc: 0.783505\n",
      "Epoch 21008 - Train Loss: 0.079187, Train Acc: 0.879487 | Val Loss: 0.110191, Val Acc: 0.783505\n",
      "Epoch 21009 - Train Loss: 0.079185, Train Acc: 0.879487 | Val Loss: 0.110191, Val Acc: 0.783505\n",
      "Epoch 21010 - Train Loss: 0.079183, Train Acc: 0.879487 | Val Loss: 0.110190, Val Acc: 0.783505\n",
      "Epoch 21011 - Train Loss: 0.079181, Train Acc: 0.879487 | Val Loss: 0.110189, Val Acc: 0.783505\n",
      "Epoch 21012 - Train Loss: 0.079179, Train Acc: 0.879487 | Val Loss: 0.110188, Val Acc: 0.783505\n",
      "Epoch 21013 - Train Loss: 0.079177, Train Acc: 0.879487 | Val Loss: 0.110187, Val Acc: 0.783505\n",
      "Epoch 21014 - Train Loss: 0.079175, Train Acc: 0.879487 | Val Loss: 0.110187, Val Acc: 0.783505\n",
      "Epoch 21015 - Train Loss: 0.079173, Train Acc: 0.879487 | Val Loss: 0.110186, Val Acc: 0.783505\n",
      "Epoch 21016 - Train Loss: 0.079171, Train Acc: 0.879487 | Val Loss: 0.110185, Val Acc: 0.783505\n",
      "Epoch 21017 - Train Loss: 0.079169, Train Acc: 0.879487 | Val Loss: 0.110184, Val Acc: 0.783505\n",
      "Epoch 21018 - Train Loss: 0.079166, Train Acc: 0.879487 | Val Loss: 0.110184, Val Acc: 0.783505\n",
      "Epoch 21019 - Train Loss: 0.079164, Train Acc: 0.879487 | Val Loss: 0.110183, Val Acc: 0.783505\n",
      "Epoch 21020 - Train Loss: 0.079162, Train Acc: 0.879487 | Val Loss: 0.110182, Val Acc: 0.783505\n",
      "Epoch 21021 - Train Loss: 0.079160, Train Acc: 0.879487 | Val Loss: 0.110181, Val Acc: 0.783505\n",
      "Epoch 21022 - Train Loss: 0.079158, Train Acc: 0.879487 | Val Loss: 0.110180, Val Acc: 0.783505\n",
      "Epoch 21023 - Train Loss: 0.079156, Train Acc: 0.879487 | Val Loss: 0.110180, Val Acc: 0.783505\n",
      "Epoch 21024 - Train Loss: 0.079154, Train Acc: 0.879487 | Val Loss: 0.110179, Val Acc: 0.783505\n",
      "Epoch 21025 - Train Loss: 0.079152, Train Acc: 0.879487 | Val Loss: 0.110178, Val Acc: 0.783505\n",
      "Epoch 21026 - Train Loss: 0.079150, Train Acc: 0.879487 | Val Loss: 0.110177, Val Acc: 0.783505\n",
      "Epoch 21027 - Train Loss: 0.079148, Train Acc: 0.879487 | Val Loss: 0.110176, Val Acc: 0.783505\n",
      "Epoch 21028 - Train Loss: 0.079146, Train Acc: 0.879487 | Val Loss: 0.110176, Val Acc: 0.783505\n",
      "Epoch 21029 - Train Loss: 0.079144, Train Acc: 0.879487 | Val Loss: 0.110175, Val Acc: 0.783505\n",
      "Epoch 21030 - Train Loss: 0.079142, Train Acc: 0.879487 | Val Loss: 0.110174, Val Acc: 0.783505\n",
      "Epoch 21031 - Train Loss: 0.079139, Train Acc: 0.879487 | Val Loss: 0.110173, Val Acc: 0.783505\n",
      "Epoch 21032 - Train Loss: 0.079137, Train Acc: 0.879487 | Val Loss: 0.110173, Val Acc: 0.783505\n",
      "Epoch 21033 - Train Loss: 0.079135, Train Acc: 0.879487 | Val Loss: 0.110172, Val Acc: 0.783505\n",
      "Epoch 21034 - Train Loss: 0.079133, Train Acc: 0.879487 | Val Loss: 0.110171, Val Acc: 0.783505\n",
      "Epoch 21035 - Train Loss: 0.079131, Train Acc: 0.879487 | Val Loss: 0.110170, Val Acc: 0.783505\n",
      "Epoch 21036 - Train Loss: 0.079129, Train Acc: 0.879487 | Val Loss: 0.110169, Val Acc: 0.783505\n",
      "Epoch 21037 - Train Loss: 0.079127, Train Acc: 0.879487 | Val Loss: 0.110169, Val Acc: 0.783505\n",
      "Epoch 21038 - Train Loss: 0.079125, Train Acc: 0.879487 | Val Loss: 0.110168, Val Acc: 0.783505\n",
      "Epoch 21039 - Train Loss: 0.079123, Train Acc: 0.879487 | Val Loss: 0.110167, Val Acc: 0.783505\n",
      "Epoch 21040 - Train Loss: 0.079121, Train Acc: 0.879487 | Val Loss: 0.110166, Val Acc: 0.783505\n",
      "Epoch 21041 - Train Loss: 0.079119, Train Acc: 0.879487 | Val Loss: 0.110166, Val Acc: 0.783505\n",
      "Epoch 21042 - Train Loss: 0.079117, Train Acc: 0.879487 | Val Loss: 0.110165, Val Acc: 0.783505\n",
      "Epoch 21043 - Train Loss: 0.079115, Train Acc: 0.879487 | Val Loss: 0.110164, Val Acc: 0.783505\n",
      "Epoch 21044 - Train Loss: 0.079113, Train Acc: 0.879487 | Val Loss: 0.110163, Val Acc: 0.783505\n",
      "Epoch 21045 - Train Loss: 0.079110, Train Acc: 0.879487 | Val Loss: 0.110162, Val Acc: 0.783505\n",
      "Epoch 21046 - Train Loss: 0.079108, Train Acc: 0.879487 | Val Loss: 0.110162, Val Acc: 0.783505\n",
      "Epoch 21047 - Train Loss: 0.079106, Train Acc: 0.879487 | Val Loss: 0.110161, Val Acc: 0.783505\n",
      "Epoch 21048 - Train Loss: 0.079104, Train Acc: 0.879487 | Val Loss: 0.110160, Val Acc: 0.783505\n",
      "Epoch 21049 - Train Loss: 0.079102, Train Acc: 0.880769 | Val Loss: 0.110159, Val Acc: 0.783505\n",
      "Epoch 21050 - Train Loss: 0.079100, Train Acc: 0.880769 | Val Loss: 0.110159, Val Acc: 0.783505\n",
      "Epoch 21051 - Train Loss: 0.079098, Train Acc: 0.880769 | Val Loss: 0.110158, Val Acc: 0.783505\n",
      "Epoch 21052 - Train Loss: 0.079096, Train Acc: 0.880769 | Val Loss: 0.110157, Val Acc: 0.783505\n",
      "Epoch 21053 - Train Loss: 0.079094, Train Acc: 0.880769 | Val Loss: 0.110156, Val Acc: 0.783505\n",
      "Epoch 21054 - Train Loss: 0.079092, Train Acc: 0.880769 | Val Loss: 0.110155, Val Acc: 0.783505\n",
      "Epoch 21055 - Train Loss: 0.079090, Train Acc: 0.880769 | Val Loss: 0.110155, Val Acc: 0.783505\n",
      "Epoch 21056 - Train Loss: 0.079088, Train Acc: 0.880769 | Val Loss: 0.110154, Val Acc: 0.783505\n",
      "Epoch 21057 - Train Loss: 0.079086, Train Acc: 0.880769 | Val Loss: 0.110153, Val Acc: 0.783505\n",
      "Epoch 21058 - Train Loss: 0.079084, Train Acc: 0.880769 | Val Loss: 0.110152, Val Acc: 0.783505\n",
      "Epoch 21059 - Train Loss: 0.079081, Train Acc: 0.880769 | Val Loss: 0.110152, Val Acc: 0.783505\n",
      "Epoch 21060 - Train Loss: 0.079079, Train Acc: 0.880769 | Val Loss: 0.110151, Val Acc: 0.783505\n",
      "Epoch 21061 - Train Loss: 0.079077, Train Acc: 0.880769 | Val Loss: 0.110150, Val Acc: 0.783505\n",
      "Epoch 21062 - Train Loss: 0.079075, Train Acc: 0.880769 | Val Loss: 0.110149, Val Acc: 0.783505\n",
      "Epoch 21063 - Train Loss: 0.079073, Train Acc: 0.880769 | Val Loss: 0.110148, Val Acc: 0.783505\n",
      "Epoch 21064 - Train Loss: 0.079071, Train Acc: 0.880769 | Val Loss: 0.110148, Val Acc: 0.783505\n",
      "Epoch 21065 - Train Loss: 0.079069, Train Acc: 0.880769 | Val Loss: 0.110147, Val Acc: 0.783505\n",
      "Epoch 21066 - Train Loss: 0.079067, Train Acc: 0.880769 | Val Loss: 0.110146, Val Acc: 0.783505\n",
      "Epoch 21067 - Train Loss: 0.079065, Train Acc: 0.880769 | Val Loss: 0.110145, Val Acc: 0.783505\n",
      "Epoch 21068 - Train Loss: 0.079063, Train Acc: 0.880769 | Val Loss: 0.110145, Val Acc: 0.783505\n",
      "Epoch 21069 - Train Loss: 0.079061, Train Acc: 0.880769 | Val Loss: 0.110144, Val Acc: 0.783505\n",
      "Epoch 21070 - Train Loss: 0.079059, Train Acc: 0.880769 | Val Loss: 0.110143, Val Acc: 0.783505\n",
      "Epoch 21071 - Train Loss: 0.079057, Train Acc: 0.880769 | Val Loss: 0.110142, Val Acc: 0.783505\n",
      "Epoch 21072 - Train Loss: 0.079055, Train Acc: 0.880769 | Val Loss: 0.110142, Val Acc: 0.783505\n",
      "Epoch 21073 - Train Loss: 0.079053, Train Acc: 0.880769 | Val Loss: 0.110141, Val Acc: 0.783505\n",
      "Epoch 21074 - Train Loss: 0.079050, Train Acc: 0.880769 | Val Loss: 0.110140, Val Acc: 0.783505\n",
      "Epoch 21075 - Train Loss: 0.079048, Train Acc: 0.880769 | Val Loss: 0.110139, Val Acc: 0.783505\n",
      "Epoch 21076 - Train Loss: 0.079046, Train Acc: 0.880769 | Val Loss: 0.110139, Val Acc: 0.783505\n",
      "Epoch 21077 - Train Loss: 0.079044, Train Acc: 0.880769 | Val Loss: 0.110138, Val Acc: 0.783505\n",
      "Epoch 21078 - Train Loss: 0.079042, Train Acc: 0.880769 | Val Loss: 0.110137, Val Acc: 0.783505\n",
      "Epoch 21079 - Train Loss: 0.079040, Train Acc: 0.880769 | Val Loss: 0.110136, Val Acc: 0.783505\n",
      "Epoch 21080 - Train Loss: 0.079038, Train Acc: 0.880769 | Val Loss: 0.110136, Val Acc: 0.783505\n",
      "Epoch 21081 - Train Loss: 0.079036, Train Acc: 0.880769 | Val Loss: 0.110135, Val Acc: 0.783505\n",
      "Epoch 21082 - Train Loss: 0.079034, Train Acc: 0.880769 | Val Loss: 0.110134, Val Acc: 0.783505\n",
      "Epoch 21083 - Train Loss: 0.079032, Train Acc: 0.880769 | Val Loss: 0.110133, Val Acc: 0.783505\n",
      "Epoch 21084 - Train Loss: 0.079030, Train Acc: 0.880769 | Val Loss: 0.110133, Val Acc: 0.783505\n",
      "Epoch 21085 - Train Loss: 0.079028, Train Acc: 0.880769 | Val Loss: 0.110132, Val Acc: 0.783505\n",
      "Epoch 21086 - Train Loss: 0.079026, Train Acc: 0.880769 | Val Loss: 0.110131, Val Acc: 0.783505\n",
      "Epoch 21087 - Train Loss: 0.079024, Train Acc: 0.880769 | Val Loss: 0.110130, Val Acc: 0.783505\n",
      "Epoch 21088 - Train Loss: 0.079022, Train Acc: 0.880769 | Val Loss: 0.110130, Val Acc: 0.783505\n",
      "Epoch 21089 - Train Loss: 0.079019, Train Acc: 0.880769 | Val Loss: 0.110129, Val Acc: 0.783505\n",
      "Epoch 21090 - Train Loss: 0.079017, Train Acc: 0.880769 | Val Loss: 0.110128, Val Acc: 0.783505\n",
      "Epoch 21091 - Train Loss: 0.079015, Train Acc: 0.880769 | Val Loss: 0.110127, Val Acc: 0.783505\n",
      "Epoch 21092 - Train Loss: 0.079013, Train Acc: 0.880769 | Val Loss: 0.110126, Val Acc: 0.783505\n",
      "Epoch 21093 - Train Loss: 0.079011, Train Acc: 0.880769 | Val Loss: 0.110126, Val Acc: 0.783505\n",
      "Epoch 21094 - Train Loss: 0.079009, Train Acc: 0.880769 | Val Loss: 0.110125, Val Acc: 0.783505\n",
      "Epoch 21095 - Train Loss: 0.079007, Train Acc: 0.880769 | Val Loss: 0.110124, Val Acc: 0.783505\n",
      "Epoch 21096 - Train Loss: 0.079005, Train Acc: 0.880769 | Val Loss: 0.110123, Val Acc: 0.783505\n",
      "Epoch 21097 - Train Loss: 0.079003, Train Acc: 0.880769 | Val Loss: 0.110123, Val Acc: 0.783505\n",
      "Epoch 21098 - Train Loss: 0.079001, Train Acc: 0.880769 | Val Loss: 0.110122, Val Acc: 0.783505\n",
      "Epoch 21099 - Train Loss: 0.078999, Train Acc: 0.880769 | Val Loss: 0.110121, Val Acc: 0.783505\n",
      "Epoch 21100 - Train Loss: 0.078997, Train Acc: 0.880769 | Val Loss: 0.110120, Val Acc: 0.783505\n",
      "Epoch 21101 - Train Loss: 0.078995, Train Acc: 0.880769 | Val Loss: 0.110120, Val Acc: 0.783505\n",
      "Epoch 21102 - Train Loss: 0.078993, Train Acc: 0.880769 | Val Loss: 0.110119, Val Acc: 0.783505\n",
      "Epoch 21103 - Train Loss: 0.078991, Train Acc: 0.880769 | Val Loss: 0.110118, Val Acc: 0.783505\n",
      "Epoch 21104 - Train Loss: 0.078989, Train Acc: 0.880769 | Val Loss: 0.110117, Val Acc: 0.783505\n",
      "Epoch 21105 - Train Loss: 0.078987, Train Acc: 0.880769 | Val Loss: 0.110117, Val Acc: 0.783505\n",
      "Epoch 21106 - Train Loss: 0.078984, Train Acc: 0.880769 | Val Loss: 0.110116, Val Acc: 0.783505\n",
      "Epoch 21107 - Train Loss: 0.078982, Train Acc: 0.880769 | Val Loss: 0.110115, Val Acc: 0.783505\n",
      "Epoch 21108 - Train Loss: 0.078980, Train Acc: 0.880769 | Val Loss: 0.110114, Val Acc: 0.783505\n",
      "Epoch 21109 - Train Loss: 0.078978, Train Acc: 0.880769 | Val Loss: 0.110114, Val Acc: 0.783505\n",
      "Epoch 21110 - Train Loss: 0.078976, Train Acc: 0.880769 | Val Loss: 0.110113, Val Acc: 0.783505\n",
      "Epoch 21111 - Train Loss: 0.078974, Train Acc: 0.880769 | Val Loss: 0.110112, Val Acc: 0.783505\n",
      "Epoch 21112 - Train Loss: 0.078972, Train Acc: 0.880769 | Val Loss: 0.110111, Val Acc: 0.783505\n",
      "Epoch 21113 - Train Loss: 0.078970, Train Acc: 0.880769 | Val Loss: 0.110111, Val Acc: 0.783505\n",
      "Epoch 21114 - Train Loss: 0.078968, Train Acc: 0.880769 | Val Loss: 0.110110, Val Acc: 0.783505\n",
      "Epoch 21115 - Train Loss: 0.078966, Train Acc: 0.880769 | Val Loss: 0.110109, Val Acc: 0.783505\n",
      "Epoch 21116 - Train Loss: 0.078964, Train Acc: 0.880769 | Val Loss: 0.110108, Val Acc: 0.783505\n",
      "Epoch 21117 - Train Loss: 0.078962, Train Acc: 0.880769 | Val Loss: 0.110108, Val Acc: 0.783505\n",
      "Epoch 21118 - Train Loss: 0.078960, Train Acc: 0.880769 | Val Loss: 0.110107, Val Acc: 0.783505\n",
      "Epoch 21119 - Train Loss: 0.078958, Train Acc: 0.882051 | Val Loss: 0.110106, Val Acc: 0.783505\n",
      "Epoch 21120 - Train Loss: 0.078956, Train Acc: 0.882051 | Val Loss: 0.110105, Val Acc: 0.783505\n",
      "Epoch 21121 - Train Loss: 0.078954, Train Acc: 0.882051 | Val Loss: 0.110104, Val Acc: 0.783505\n",
      "Epoch 21122 - Train Loss: 0.078952, Train Acc: 0.882051 | Val Loss: 0.110104, Val Acc: 0.783505\n",
      "Epoch 21123 - Train Loss: 0.078949, Train Acc: 0.882051 | Val Loss: 0.110103, Val Acc: 0.783505\n",
      "Epoch 21124 - Train Loss: 0.078947, Train Acc: 0.882051 | Val Loss: 0.110102, Val Acc: 0.783505\n",
      "Epoch 21125 - Train Loss: 0.078945, Train Acc: 0.882051 | Val Loss: 0.110101, Val Acc: 0.783505\n",
      "Epoch 21126 - Train Loss: 0.078943, Train Acc: 0.882051 | Val Loss: 0.110101, Val Acc: 0.783505\n",
      "Epoch 21127 - Train Loss: 0.078941, Train Acc: 0.882051 | Val Loss: 0.110100, Val Acc: 0.783505\n",
      "Epoch 21128 - Train Loss: 0.078939, Train Acc: 0.882051 | Val Loss: 0.110099, Val Acc: 0.783505\n",
      "Epoch 21129 - Train Loss: 0.078937, Train Acc: 0.882051 | Val Loss: 0.110098, Val Acc: 0.783505\n",
      "Epoch 21130 - Train Loss: 0.078935, Train Acc: 0.882051 | Val Loss: 0.110098, Val Acc: 0.783505\n",
      "Epoch 21131 - Train Loss: 0.078933, Train Acc: 0.882051 | Val Loss: 0.110097, Val Acc: 0.783505\n",
      "Epoch 21132 - Train Loss: 0.078931, Train Acc: 0.882051 | Val Loss: 0.110096, Val Acc: 0.783505\n",
      "Epoch 21133 - Train Loss: 0.078929, Train Acc: 0.882051 | Val Loss: 0.110095, Val Acc: 0.783505\n",
      "Epoch 21134 - Train Loss: 0.078927, Train Acc: 0.882051 | Val Loss: 0.110095, Val Acc: 0.783505\n",
      "Epoch 21135 - Train Loss: 0.078925, Train Acc: 0.882051 | Val Loss: 0.110094, Val Acc: 0.783505\n",
      "Epoch 21136 - Train Loss: 0.078923, Train Acc: 0.882051 | Val Loss: 0.110093, Val Acc: 0.783505\n",
      "Epoch 21137 - Train Loss: 0.078921, Train Acc: 0.882051 | Val Loss: 0.110092, Val Acc: 0.783505\n",
      "Epoch 21138 - Train Loss: 0.078919, Train Acc: 0.882051 | Val Loss: 0.110092, Val Acc: 0.783505\n",
      "Epoch 21139 - Train Loss: 0.078917, Train Acc: 0.882051 | Val Loss: 0.110091, Val Acc: 0.783505\n",
      "Epoch 21140 - Train Loss: 0.078915, Train Acc: 0.882051 | Val Loss: 0.110090, Val Acc: 0.783505\n",
      "Epoch 21141 - Train Loss: 0.078913, Train Acc: 0.882051 | Val Loss: 0.110089, Val Acc: 0.783505\n",
      "Epoch 21142 - Train Loss: 0.078910, Train Acc: 0.882051 | Val Loss: 0.110088, Val Acc: 0.783505\n",
      "Epoch 21143 - Train Loss: 0.078908, Train Acc: 0.882051 | Val Loss: 0.110088, Val Acc: 0.783505\n",
      "Epoch 21144 - Train Loss: 0.078906, Train Acc: 0.882051 | Val Loss: 0.110087, Val Acc: 0.783505\n",
      "Epoch 21145 - Train Loss: 0.078904, Train Acc: 0.882051 | Val Loss: 0.110086, Val Acc: 0.783505\n",
      "Epoch 21146 - Train Loss: 0.078902, Train Acc: 0.882051 | Val Loss: 0.110085, Val Acc: 0.783505\n",
      "Epoch 21147 - Train Loss: 0.078900, Train Acc: 0.882051 | Val Loss: 0.110085, Val Acc: 0.783505\n",
      "Epoch 21148 - Train Loss: 0.078898, Train Acc: 0.882051 | Val Loss: 0.110084, Val Acc: 0.783505\n",
      "Epoch 21149 - Train Loss: 0.078896, Train Acc: 0.882051 | Val Loss: 0.110083, Val Acc: 0.783505\n",
      "Epoch 21150 - Train Loss: 0.078894, Train Acc: 0.882051 | Val Loss: 0.110082, Val Acc: 0.783505\n",
      "Epoch 21151 - Train Loss: 0.078892, Train Acc: 0.882051 | Val Loss: 0.110082, Val Acc: 0.783505\n",
      "Epoch 21152 - Train Loss: 0.078890, Train Acc: 0.882051 | Val Loss: 0.110081, Val Acc: 0.783505\n",
      "Epoch 21153 - Train Loss: 0.078888, Train Acc: 0.882051 | Val Loss: 0.110080, Val Acc: 0.783505\n",
      "Epoch 21154 - Train Loss: 0.078886, Train Acc: 0.882051 | Val Loss: 0.110079, Val Acc: 0.783505\n",
      "Epoch 21155 - Train Loss: 0.078884, Train Acc: 0.882051 | Val Loss: 0.110079, Val Acc: 0.783505\n",
      "Epoch 21156 - Train Loss: 0.078882, Train Acc: 0.882051 | Val Loss: 0.110078, Val Acc: 0.783505\n",
      "Epoch 21157 - Train Loss: 0.078880, Train Acc: 0.882051 | Val Loss: 0.110077, Val Acc: 0.783505\n",
      "Epoch 21158 - Train Loss: 0.078878, Train Acc: 0.882051 | Val Loss: 0.110076, Val Acc: 0.783505\n",
      "Epoch 21159 - Train Loss: 0.078876, Train Acc: 0.882051 | Val Loss: 0.110076, Val Acc: 0.783505\n",
      "Epoch 21160 - Train Loss: 0.078874, Train Acc: 0.882051 | Val Loss: 0.110075, Val Acc: 0.783505\n",
      "Epoch 21161 - Train Loss: 0.078872, Train Acc: 0.882051 | Val Loss: 0.110074, Val Acc: 0.783505\n",
      "Epoch 21162 - Train Loss: 0.078869, Train Acc: 0.882051 | Val Loss: 0.110073, Val Acc: 0.783505\n",
      "Epoch 21163 - Train Loss: 0.078867, Train Acc: 0.882051 | Val Loss: 0.110073, Val Acc: 0.783505\n",
      "Epoch 21164 - Train Loss: 0.078865, Train Acc: 0.882051 | Val Loss: 0.110072, Val Acc: 0.783505\n",
      "Epoch 21165 - Train Loss: 0.078863, Train Acc: 0.882051 | Val Loss: 0.110071, Val Acc: 0.783505\n",
      "Epoch 21166 - Train Loss: 0.078861, Train Acc: 0.882051 | Val Loss: 0.110070, Val Acc: 0.783505\n",
      "Epoch 21167 - Train Loss: 0.078859, Train Acc: 0.882051 | Val Loss: 0.110070, Val Acc: 0.783505\n",
      "Epoch 21168 - Train Loss: 0.078857, Train Acc: 0.882051 | Val Loss: 0.110069, Val Acc: 0.783505\n",
      "Epoch 21169 - Train Loss: 0.078855, Train Acc: 0.882051 | Val Loss: 0.110068, Val Acc: 0.783505\n",
      "Epoch 21170 - Train Loss: 0.078853, Train Acc: 0.882051 | Val Loss: 0.110067, Val Acc: 0.783505\n",
      "Epoch 21171 - Train Loss: 0.078851, Train Acc: 0.882051 | Val Loss: 0.110066, Val Acc: 0.783505\n",
      "Epoch 21172 - Train Loss: 0.078849, Train Acc: 0.882051 | Val Loss: 0.110066, Val Acc: 0.783505\n",
      "Epoch 21173 - Train Loss: 0.078847, Train Acc: 0.882051 | Val Loss: 0.110065, Val Acc: 0.783505\n",
      "Epoch 21174 - Train Loss: 0.078845, Train Acc: 0.882051 | Val Loss: 0.110064, Val Acc: 0.783505\n",
      "Epoch 21175 - Train Loss: 0.078843, Train Acc: 0.882051 | Val Loss: 0.110063, Val Acc: 0.783505\n",
      "Epoch 21176 - Train Loss: 0.078841, Train Acc: 0.882051 | Val Loss: 0.110063, Val Acc: 0.783505\n",
      "Epoch 21177 - Train Loss: 0.078839, Train Acc: 0.882051 | Val Loss: 0.110062, Val Acc: 0.783505\n",
      "Epoch 21178 - Train Loss: 0.078837, Train Acc: 0.882051 | Val Loss: 0.110061, Val Acc: 0.783505\n",
      "Epoch 21179 - Train Loss: 0.078835, Train Acc: 0.882051 | Val Loss: 0.110060, Val Acc: 0.783505\n",
      "Epoch 21180 - Train Loss: 0.078833, Train Acc: 0.882051 | Val Loss: 0.110060, Val Acc: 0.783505\n",
      "Epoch 21181 - Train Loss: 0.078831, Train Acc: 0.882051 | Val Loss: 0.110059, Val Acc: 0.783505\n",
      "Epoch 21182 - Train Loss: 0.078829, Train Acc: 0.882051 | Val Loss: 0.110058, Val Acc: 0.783505\n",
      "Epoch 21183 - Train Loss: 0.078826, Train Acc: 0.882051 | Val Loss: 0.110057, Val Acc: 0.783505\n",
      "Epoch 21184 - Train Loss: 0.078824, Train Acc: 0.882051 | Val Loss: 0.110057, Val Acc: 0.783505\n",
      "Epoch 21185 - Train Loss: 0.078822, Train Acc: 0.882051 | Val Loss: 0.110056, Val Acc: 0.783505\n",
      "Epoch 21186 - Train Loss: 0.078820, Train Acc: 0.882051 | Val Loss: 0.110055, Val Acc: 0.783505\n",
      "Epoch 21187 - Train Loss: 0.078818, Train Acc: 0.882051 | Val Loss: 0.110054, Val Acc: 0.783505\n",
      "Epoch 21188 - Train Loss: 0.078816, Train Acc: 0.882051 | Val Loss: 0.110054, Val Acc: 0.783505\n",
      "Epoch 21189 - Train Loss: 0.078814, Train Acc: 0.882051 | Val Loss: 0.110053, Val Acc: 0.783505\n",
      "Epoch 21190 - Train Loss: 0.078812, Train Acc: 0.882051 | Val Loss: 0.110052, Val Acc: 0.783505\n",
      "Epoch 21191 - Train Loss: 0.078810, Train Acc: 0.882051 | Val Loss: 0.110051, Val Acc: 0.783505\n",
      "Epoch 21192 - Train Loss: 0.078808, Train Acc: 0.882051 | Val Loss: 0.110051, Val Acc: 0.783505\n",
      "Epoch 21193 - Train Loss: 0.078806, Train Acc: 0.882051 | Val Loss: 0.110050, Val Acc: 0.783505\n",
      "Epoch 21194 - Train Loss: 0.078804, Train Acc: 0.882051 | Val Loss: 0.110049, Val Acc: 0.783505\n",
      "Epoch 21195 - Train Loss: 0.078802, Train Acc: 0.882051 | Val Loss: 0.110048, Val Acc: 0.783505\n",
      "Epoch 21196 - Train Loss: 0.078800, Train Acc: 0.882051 | Val Loss: 0.110048, Val Acc: 0.783505\n",
      "Epoch 21197 - Train Loss: 0.078798, Train Acc: 0.882051 | Val Loss: 0.110047, Val Acc: 0.783505\n",
      "Epoch 21198 - Train Loss: 0.078796, Train Acc: 0.882051 | Val Loss: 0.110046, Val Acc: 0.783505\n",
      "Epoch 21199 - Train Loss: 0.078794, Train Acc: 0.882051 | Val Loss: 0.110045, Val Acc: 0.783505\n",
      "Epoch 21200 - Train Loss: 0.078792, Train Acc: 0.882051 | Val Loss: 0.110045, Val Acc: 0.783505\n",
      "Epoch 21201 - Train Loss: 0.078790, Train Acc: 0.882051 | Val Loss: 0.110044, Val Acc: 0.783505\n",
      "Epoch 21202 - Train Loss: 0.078788, Train Acc: 0.882051 | Val Loss: 0.110043, Val Acc: 0.783505\n",
      "Epoch 21203 - Train Loss: 0.078786, Train Acc: 0.882051 | Val Loss: 0.110042, Val Acc: 0.783505\n",
      "Epoch 21204 - Train Loss: 0.078784, Train Acc: 0.882051 | Val Loss: 0.110042, Val Acc: 0.783505\n",
      "Epoch 21205 - Train Loss: 0.078782, Train Acc: 0.882051 | Val Loss: 0.110041, Val Acc: 0.783505\n",
      "Epoch 21206 - Train Loss: 0.078780, Train Acc: 0.882051 | Val Loss: 0.110040, Val Acc: 0.783505\n",
      "Epoch 21207 - Train Loss: 0.078777, Train Acc: 0.882051 | Val Loss: 0.110039, Val Acc: 0.783505\n",
      "Epoch 21208 - Train Loss: 0.078775, Train Acc: 0.882051 | Val Loss: 0.110039, Val Acc: 0.783505\n",
      "Epoch 21209 - Train Loss: 0.078773, Train Acc: 0.882051 | Val Loss: 0.110038, Val Acc: 0.783505\n",
      "Epoch 21210 - Train Loss: 0.078771, Train Acc: 0.882051 | Val Loss: 0.110037, Val Acc: 0.783505\n",
      "Epoch 21211 - Train Loss: 0.078769, Train Acc: 0.882051 | Val Loss: 0.110036, Val Acc: 0.783505\n",
      "Epoch 21212 - Train Loss: 0.078767, Train Acc: 0.882051 | Val Loss: 0.110036, Val Acc: 0.783505\n",
      "Epoch 21213 - Train Loss: 0.078765, Train Acc: 0.882051 | Val Loss: 0.110035, Val Acc: 0.783505\n",
      "Epoch 21214 - Train Loss: 0.078763, Train Acc: 0.882051 | Val Loss: 0.110034, Val Acc: 0.783505\n",
      "Epoch 21215 - Train Loss: 0.078761, Train Acc: 0.882051 | Val Loss: 0.110033, Val Acc: 0.783505\n",
      "Epoch 21216 - Train Loss: 0.078759, Train Acc: 0.882051 | Val Loss: 0.110033, Val Acc: 0.783505\n",
      "Epoch 21217 - Train Loss: 0.078757, Train Acc: 0.882051 | Val Loss: 0.110032, Val Acc: 0.783505\n",
      "Epoch 21218 - Train Loss: 0.078755, Train Acc: 0.882051 | Val Loss: 0.110031, Val Acc: 0.783505\n",
      "Epoch 21219 - Train Loss: 0.078753, Train Acc: 0.882051 | Val Loss: 0.110030, Val Acc: 0.783505\n",
      "Epoch 21220 - Train Loss: 0.078751, Train Acc: 0.882051 | Val Loss: 0.110030, Val Acc: 0.783505\n",
      "Epoch 21221 - Train Loss: 0.078749, Train Acc: 0.882051 | Val Loss: 0.110029, Val Acc: 0.783505\n",
      "Epoch 21222 - Train Loss: 0.078747, Train Acc: 0.882051 | Val Loss: 0.110028, Val Acc: 0.783505\n",
      "Epoch 21223 - Train Loss: 0.078745, Train Acc: 0.882051 | Val Loss: 0.110027, Val Acc: 0.783505\n",
      "Epoch 21224 - Train Loss: 0.078743, Train Acc: 0.882051 | Val Loss: 0.110027, Val Acc: 0.783505\n",
      "Epoch 21225 - Train Loss: 0.078741, Train Acc: 0.882051 | Val Loss: 0.110026, Val Acc: 0.783505\n",
      "Epoch 21226 - Train Loss: 0.078739, Train Acc: 0.882051 | Val Loss: 0.110025, Val Acc: 0.783505\n",
      "Epoch 21227 - Train Loss: 0.078737, Train Acc: 0.882051 | Val Loss: 0.110024, Val Acc: 0.783505\n",
      "Epoch 21228 - Train Loss: 0.078735, Train Acc: 0.882051 | Val Loss: 0.110024, Val Acc: 0.783505\n",
      "Epoch 21229 - Train Loss: 0.078733, Train Acc: 0.882051 | Val Loss: 0.110023, Val Acc: 0.783505\n",
      "Epoch 21230 - Train Loss: 0.078731, Train Acc: 0.882051 | Val Loss: 0.110022, Val Acc: 0.783505\n",
      "Epoch 21231 - Train Loss: 0.078729, Train Acc: 0.882051 | Val Loss: 0.110021, Val Acc: 0.783505\n",
      "Epoch 21232 - Train Loss: 0.078727, Train Acc: 0.882051 | Val Loss: 0.110021, Val Acc: 0.783505\n",
      "Epoch 21233 - Train Loss: 0.078725, Train Acc: 0.882051 | Val Loss: 0.110020, Val Acc: 0.783505\n",
      "Epoch 21234 - Train Loss: 0.078723, Train Acc: 0.882051 | Val Loss: 0.110019, Val Acc: 0.783505\n",
      "Epoch 21235 - Train Loss: 0.078720, Train Acc: 0.882051 | Val Loss: 0.110018, Val Acc: 0.783505\n",
      "Epoch 21236 - Train Loss: 0.078718, Train Acc: 0.882051 | Val Loss: 0.110018, Val Acc: 0.783505\n",
      "Epoch 21237 - Train Loss: 0.078716, Train Acc: 0.882051 | Val Loss: 0.110017, Val Acc: 0.783505\n",
      "Epoch 21238 - Train Loss: 0.078714, Train Acc: 0.882051 | Val Loss: 0.110016, Val Acc: 0.783505\n",
      "Epoch 21239 - Train Loss: 0.078712, Train Acc: 0.882051 | Val Loss: 0.110015, Val Acc: 0.783505\n",
      "Epoch 21240 - Train Loss: 0.078710, Train Acc: 0.882051 | Val Loss: 0.110015, Val Acc: 0.783505\n",
      "Epoch 21241 - Train Loss: 0.078708, Train Acc: 0.882051 | Val Loss: 0.110014, Val Acc: 0.783505\n",
      "Epoch 21242 - Train Loss: 0.078706, Train Acc: 0.882051 | Val Loss: 0.110013, Val Acc: 0.783505\n",
      "Epoch 21243 - Train Loss: 0.078704, Train Acc: 0.882051 | Val Loss: 0.110012, Val Acc: 0.783505\n",
      "Epoch 21244 - Train Loss: 0.078702, Train Acc: 0.882051 | Val Loss: 0.110012, Val Acc: 0.783505\n",
      "Epoch 21245 - Train Loss: 0.078700, Train Acc: 0.882051 | Val Loss: 0.110011, Val Acc: 0.783505\n",
      "Epoch 21246 - Train Loss: 0.078698, Train Acc: 0.882051 | Val Loss: 0.110010, Val Acc: 0.783505\n",
      "Epoch 21247 - Train Loss: 0.078696, Train Acc: 0.882051 | Val Loss: 0.110009, Val Acc: 0.783505\n",
      "Epoch 21248 - Train Loss: 0.078694, Train Acc: 0.882051 | Val Loss: 0.110009, Val Acc: 0.783505\n",
      "Epoch 21249 - Train Loss: 0.078692, Train Acc: 0.882051 | Val Loss: 0.110008, Val Acc: 0.783505\n",
      "Epoch 21250 - Train Loss: 0.078690, Train Acc: 0.882051 | Val Loss: 0.110007, Val Acc: 0.783505\n",
      "Epoch 21251 - Train Loss: 0.078688, Train Acc: 0.882051 | Val Loss: 0.110006, Val Acc: 0.783505\n",
      "Epoch 21252 - Train Loss: 0.078686, Train Acc: 0.882051 | Val Loss: 0.110006, Val Acc: 0.783505\n",
      "Epoch 21253 - Train Loss: 0.078684, Train Acc: 0.882051 | Val Loss: 0.110005, Val Acc: 0.783505\n",
      "Epoch 21254 - Train Loss: 0.078682, Train Acc: 0.882051 | Val Loss: 0.110004, Val Acc: 0.783505\n",
      "Epoch 21255 - Train Loss: 0.078680, Train Acc: 0.882051 | Val Loss: 0.110003, Val Acc: 0.783505\n",
      "Epoch 21256 - Train Loss: 0.078678, Train Acc: 0.882051 | Val Loss: 0.110003, Val Acc: 0.783505\n",
      "Epoch 21257 - Train Loss: 0.078676, Train Acc: 0.882051 | Val Loss: 0.110002, Val Acc: 0.783505\n",
      "Epoch 21258 - Train Loss: 0.078674, Train Acc: 0.882051 | Val Loss: 0.110001, Val Acc: 0.783505\n",
      "Epoch 21259 - Train Loss: 0.078672, Train Acc: 0.882051 | Val Loss: 0.110000, Val Acc: 0.783505\n",
      "Epoch 21260 - Train Loss: 0.078670, Train Acc: 0.882051 | Val Loss: 0.110000, Val Acc: 0.783505\n",
      "Epoch 21261 - Train Loss: 0.078668, Train Acc: 0.882051 | Val Loss: 0.109999, Val Acc: 0.783505\n",
      "Epoch 21262 - Train Loss: 0.078666, Train Acc: 0.882051 | Val Loss: 0.109998, Val Acc: 0.783505\n",
      "Epoch 21263 - Train Loss: 0.078664, Train Acc: 0.882051 | Val Loss: 0.109998, Val Acc: 0.783505\n",
      "Epoch 21264 - Train Loss: 0.078662, Train Acc: 0.882051 | Val Loss: 0.109997, Val Acc: 0.783505\n",
      "Epoch 21265 - Train Loss: 0.078660, Train Acc: 0.882051 | Val Loss: 0.109996, Val Acc: 0.783505\n",
      "Epoch 21266 - Train Loss: 0.078658, Train Acc: 0.882051 | Val Loss: 0.109995, Val Acc: 0.783505\n",
      "Epoch 21267 - Train Loss: 0.078655, Train Acc: 0.882051 | Val Loss: 0.109994, Val Acc: 0.783505\n",
      "Epoch 21268 - Train Loss: 0.078653, Train Acc: 0.882051 | Val Loss: 0.109994, Val Acc: 0.783505\n",
      "Epoch 21269 - Train Loss: 0.078651, Train Acc: 0.882051 | Val Loss: 0.109993, Val Acc: 0.783505\n",
      "Epoch 21270 - Train Loss: 0.078649, Train Acc: 0.882051 | Val Loss: 0.109992, Val Acc: 0.783505\n",
      "Epoch 21271 - Train Loss: 0.078647, Train Acc: 0.882051 | Val Loss: 0.109991, Val Acc: 0.783505\n",
      "Epoch 21272 - Train Loss: 0.078645, Train Acc: 0.882051 | Val Loss: 0.109991, Val Acc: 0.783505\n",
      "Epoch 21273 - Train Loss: 0.078643, Train Acc: 0.882051 | Val Loss: 0.109990, Val Acc: 0.783505\n",
      "Epoch 21274 - Train Loss: 0.078641, Train Acc: 0.882051 | Val Loss: 0.109989, Val Acc: 0.783505\n",
      "Epoch 21275 - Train Loss: 0.078639, Train Acc: 0.882051 | Val Loss: 0.109988, Val Acc: 0.783505\n",
      "Epoch 21276 - Train Loss: 0.078637, Train Acc: 0.882051 | Val Loss: 0.109988, Val Acc: 0.783505\n",
      "Epoch 21277 - Train Loss: 0.078635, Train Acc: 0.882051 | Val Loss: 0.109987, Val Acc: 0.783505\n",
      "Epoch 21278 - Train Loss: 0.078633, Train Acc: 0.882051 | Val Loss: 0.109986, Val Acc: 0.783505\n",
      "Epoch 21279 - Train Loss: 0.078631, Train Acc: 0.882051 | Val Loss: 0.109986, Val Acc: 0.783505\n",
      "Epoch 21280 - Train Loss: 0.078629, Train Acc: 0.882051 | Val Loss: 0.109985, Val Acc: 0.783505\n",
      "Epoch 21281 - Train Loss: 0.078627, Train Acc: 0.882051 | Val Loss: 0.109984, Val Acc: 0.783505\n",
      "Epoch 21282 - Train Loss: 0.078625, Train Acc: 0.882051 | Val Loss: 0.109983, Val Acc: 0.783505\n",
      "Epoch 21283 - Train Loss: 0.078623, Train Acc: 0.882051 | Val Loss: 0.109983, Val Acc: 0.783505\n",
      "Epoch 21284 - Train Loss: 0.078621, Train Acc: 0.882051 | Val Loss: 0.109982, Val Acc: 0.783505\n",
      "Epoch 21285 - Train Loss: 0.078619, Train Acc: 0.882051 | Val Loss: 0.109981, Val Acc: 0.783505\n",
      "Epoch 21286 - Train Loss: 0.078617, Train Acc: 0.882051 | Val Loss: 0.109980, Val Acc: 0.783505\n",
      "Epoch 21287 - Train Loss: 0.078615, Train Acc: 0.882051 | Val Loss: 0.109980, Val Acc: 0.783505\n",
      "Epoch 21288 - Train Loss: 0.078613, Train Acc: 0.882051 | Val Loss: 0.109979, Val Acc: 0.783505\n",
      "Epoch 21289 - Train Loss: 0.078611, Train Acc: 0.882051 | Val Loss: 0.109978, Val Acc: 0.783505\n",
      "Epoch 21290 - Train Loss: 0.078609, Train Acc: 0.880769 | Val Loss: 0.109977, Val Acc: 0.783505\n",
      "Epoch 21291 - Train Loss: 0.078607, Train Acc: 0.880769 | Val Loss: 0.109977, Val Acc: 0.783505\n",
      "Epoch 21292 - Train Loss: 0.078605, Train Acc: 0.880769 | Val Loss: 0.109976, Val Acc: 0.783505\n",
      "Epoch 21293 - Train Loss: 0.078603, Train Acc: 0.880769 | Val Loss: 0.109975, Val Acc: 0.783505\n",
      "Epoch 21294 - Train Loss: 0.078601, Train Acc: 0.880769 | Val Loss: 0.109974, Val Acc: 0.783505\n",
      "Epoch 21295 - Train Loss: 0.078599, Train Acc: 0.880769 | Val Loss: 0.109974, Val Acc: 0.783505\n",
      "Epoch 21296 - Train Loss: 0.078597, Train Acc: 0.880769 | Val Loss: 0.109973, Val Acc: 0.783505\n",
      "Epoch 21297 - Train Loss: 0.078595, Train Acc: 0.880769 | Val Loss: 0.109972, Val Acc: 0.783505\n",
      "Epoch 21298 - Train Loss: 0.078593, Train Acc: 0.880769 | Val Loss: 0.109971, Val Acc: 0.783505\n",
      "Epoch 21299 - Train Loss: 0.078591, Train Acc: 0.880769 | Val Loss: 0.109971, Val Acc: 0.783505\n",
      "Epoch 21300 - Train Loss: 0.078589, Train Acc: 0.880769 | Val Loss: 0.109970, Val Acc: 0.783505\n",
      "Epoch 21301 - Train Loss: 0.078587, Train Acc: 0.880769 | Val Loss: 0.109969, Val Acc: 0.783505\n",
      "Epoch 21302 - Train Loss: 0.078585, Train Acc: 0.880769 | Val Loss: 0.109969, Val Acc: 0.783505\n",
      "Epoch 21303 - Train Loss: 0.078583, Train Acc: 0.880769 | Val Loss: 0.109968, Val Acc: 0.783505\n",
      "Epoch 21304 - Train Loss: 0.078581, Train Acc: 0.880769 | Val Loss: 0.109967, Val Acc: 0.783505\n",
      "Epoch 21305 - Train Loss: 0.078579, Train Acc: 0.880769 | Val Loss: 0.109966, Val Acc: 0.783505\n",
      "Epoch 21306 - Train Loss: 0.078576, Train Acc: 0.880769 | Val Loss: 0.109966, Val Acc: 0.783505\n",
      "Epoch 21307 - Train Loss: 0.078574, Train Acc: 0.880769 | Val Loss: 0.109965, Val Acc: 0.783505\n",
      "Epoch 21308 - Train Loss: 0.078572, Train Acc: 0.880769 | Val Loss: 0.109964, Val Acc: 0.783505\n",
      "Epoch 21309 - Train Loss: 0.078570, Train Acc: 0.880769 | Val Loss: 0.109963, Val Acc: 0.783505\n",
      "Epoch 21310 - Train Loss: 0.078568, Train Acc: 0.880769 | Val Loss: 0.109963, Val Acc: 0.783505\n",
      "Epoch 21311 - Train Loss: 0.078566, Train Acc: 0.880769 | Val Loss: 0.109962, Val Acc: 0.783505\n",
      "Epoch 21312 - Train Loss: 0.078564, Train Acc: 0.880769 | Val Loss: 0.109961, Val Acc: 0.783505\n",
      "Epoch 21313 - Train Loss: 0.078562, Train Acc: 0.880769 | Val Loss: 0.109960, Val Acc: 0.783505\n",
      "Epoch 21314 - Train Loss: 0.078560, Train Acc: 0.880769 | Val Loss: 0.109960, Val Acc: 0.783505\n",
      "Epoch 21315 - Train Loss: 0.078558, Train Acc: 0.880769 | Val Loss: 0.109959, Val Acc: 0.783505\n",
      "Epoch 21316 - Train Loss: 0.078556, Train Acc: 0.880769 | Val Loss: 0.109958, Val Acc: 0.783505\n",
      "Epoch 21317 - Train Loss: 0.078554, Train Acc: 0.880769 | Val Loss: 0.109957, Val Acc: 0.783505\n",
      "Epoch 21318 - Train Loss: 0.078552, Train Acc: 0.880769 | Val Loss: 0.109957, Val Acc: 0.783505\n",
      "Epoch 21319 - Train Loss: 0.078550, Train Acc: 0.880769 | Val Loss: 0.109956, Val Acc: 0.783505\n",
      "Epoch 21320 - Train Loss: 0.078548, Train Acc: 0.880769 | Val Loss: 0.109955, Val Acc: 0.783505\n",
      "Epoch 21321 - Train Loss: 0.078546, Train Acc: 0.880769 | Val Loss: 0.109955, Val Acc: 0.783505\n",
      "Epoch 21322 - Train Loss: 0.078544, Train Acc: 0.880769 | Val Loss: 0.109954, Val Acc: 0.783505\n",
      "Epoch 21323 - Train Loss: 0.078542, Train Acc: 0.880769 | Val Loss: 0.109953, Val Acc: 0.783505\n",
      "Epoch 21324 - Train Loss: 0.078540, Train Acc: 0.880769 | Val Loss: 0.109952, Val Acc: 0.783505\n",
      "Epoch 21325 - Train Loss: 0.078538, Train Acc: 0.880769 | Val Loss: 0.109952, Val Acc: 0.783505\n",
      "Epoch 21326 - Train Loss: 0.078536, Train Acc: 0.880769 | Val Loss: 0.109951, Val Acc: 0.783505\n",
      "Epoch 21327 - Train Loss: 0.078534, Train Acc: 0.880769 | Val Loss: 0.109950, Val Acc: 0.783505\n",
      "Epoch 21328 - Train Loss: 0.078532, Train Acc: 0.880769 | Val Loss: 0.109949, Val Acc: 0.783505\n",
      "Epoch 21329 - Train Loss: 0.078530, Train Acc: 0.880769 | Val Loss: 0.109949, Val Acc: 0.783505\n",
      "Epoch 21330 - Train Loss: 0.078528, Train Acc: 0.880769 | Val Loss: 0.109948, Val Acc: 0.783505\n",
      "Epoch 21331 - Train Loss: 0.078526, Train Acc: 0.880769 | Val Loss: 0.109947, Val Acc: 0.783505\n",
      "Epoch 21332 - Train Loss: 0.078524, Train Acc: 0.880769 | Val Loss: 0.109946, Val Acc: 0.783505\n",
      "Epoch 21333 - Train Loss: 0.078522, Train Acc: 0.880769 | Val Loss: 0.109946, Val Acc: 0.783505\n",
      "Epoch 21334 - Train Loss: 0.078520, Train Acc: 0.880769 | Val Loss: 0.109945, Val Acc: 0.783505\n",
      "Epoch 21335 - Train Loss: 0.078518, Train Acc: 0.880769 | Val Loss: 0.109944, Val Acc: 0.783505\n",
      "Epoch 21336 - Train Loss: 0.078516, Train Acc: 0.880769 | Val Loss: 0.109944, Val Acc: 0.783505\n",
      "Epoch 21337 - Train Loss: 0.078514, Train Acc: 0.880769 | Val Loss: 0.109943, Val Acc: 0.783505\n",
      "Epoch 21338 - Train Loss: 0.078512, Train Acc: 0.880769 | Val Loss: 0.109942, Val Acc: 0.783505\n",
      "Epoch 21339 - Train Loss: 0.078510, Train Acc: 0.880769 | Val Loss: 0.109941, Val Acc: 0.783505\n",
      "Epoch 21340 - Train Loss: 0.078508, Train Acc: 0.880769 | Val Loss: 0.109941, Val Acc: 0.783505\n",
      "Epoch 21341 - Train Loss: 0.078506, Train Acc: 0.880769 | Val Loss: 0.109940, Val Acc: 0.783505\n",
      "Epoch 21342 - Train Loss: 0.078504, Train Acc: 0.880769 | Val Loss: 0.109939, Val Acc: 0.783505\n",
      "Epoch 21343 - Train Loss: 0.078502, Train Acc: 0.880769 | Val Loss: 0.109938, Val Acc: 0.783505\n",
      "Epoch 21344 - Train Loss: 0.078500, Train Acc: 0.880769 | Val Loss: 0.109938, Val Acc: 0.783505\n",
      "Epoch 21345 - Train Loss: 0.078498, Train Acc: 0.880769 | Val Loss: 0.109937, Val Acc: 0.783505\n",
      "Epoch 21346 - Train Loss: 0.078496, Train Acc: 0.880769 | Val Loss: 0.109936, Val Acc: 0.783505\n",
      "Epoch 21347 - Train Loss: 0.078494, Train Acc: 0.880769 | Val Loss: 0.109936, Val Acc: 0.783505\n",
      "Epoch 21348 - Train Loss: 0.078492, Train Acc: 0.880769 | Val Loss: 0.109935, Val Acc: 0.783505\n",
      "Epoch 21349 - Train Loss: 0.078490, Train Acc: 0.880769 | Val Loss: 0.109934, Val Acc: 0.783505\n",
      "Epoch 21350 - Train Loss: 0.078488, Train Acc: 0.880769 | Val Loss: 0.109933, Val Acc: 0.783505\n",
      "Epoch 21351 - Train Loss: 0.078486, Train Acc: 0.880769 | Val Loss: 0.109933, Val Acc: 0.783505\n",
      "Epoch 21352 - Train Loss: 0.078484, Train Acc: 0.880769 | Val Loss: 0.109932, Val Acc: 0.783505\n",
      "Epoch 21353 - Train Loss: 0.078482, Train Acc: 0.880769 | Val Loss: 0.109931, Val Acc: 0.783505\n",
      "Epoch 21354 - Train Loss: 0.078480, Train Acc: 0.880769 | Val Loss: 0.109930, Val Acc: 0.783505\n",
      "Epoch 21355 - Train Loss: 0.078478, Train Acc: 0.880769 | Val Loss: 0.109930, Val Acc: 0.783505\n",
      "Epoch 21356 - Train Loss: 0.078476, Train Acc: 0.880769 | Val Loss: 0.109929, Val Acc: 0.783505\n",
      "Epoch 21357 - Train Loss: 0.078474, Train Acc: 0.880769 | Val Loss: 0.109928, Val Acc: 0.783505\n",
      "Epoch 21358 - Train Loss: 0.078472, Train Acc: 0.880769 | Val Loss: 0.109928, Val Acc: 0.783505\n",
      "Epoch 21359 - Train Loss: 0.078470, Train Acc: 0.880769 | Val Loss: 0.109927, Val Acc: 0.783505\n",
      "Epoch 21360 - Train Loss: 0.078468, Train Acc: 0.880769 | Val Loss: 0.109926, Val Acc: 0.783505\n",
      "Epoch 21361 - Train Loss: 0.078466, Train Acc: 0.880769 | Val Loss: 0.109925, Val Acc: 0.783505\n",
      "Epoch 21362 - Train Loss: 0.078464, Train Acc: 0.880769 | Val Loss: 0.109925, Val Acc: 0.783505\n",
      "Epoch 21363 - Train Loss: 0.078462, Train Acc: 0.880769 | Val Loss: 0.109924, Val Acc: 0.783505\n",
      "Epoch 21364 - Train Loss: 0.078460, Train Acc: 0.880769 | Val Loss: 0.109923, Val Acc: 0.783505\n",
      "Epoch 21365 - Train Loss: 0.078458, Train Acc: 0.880769 | Val Loss: 0.109923, Val Acc: 0.783505\n",
      "Epoch 21366 - Train Loss: 0.078455, Train Acc: 0.880769 | Val Loss: 0.109922, Val Acc: 0.783505\n",
      "Epoch 21367 - Train Loss: 0.078453, Train Acc: 0.880769 | Val Loss: 0.109921, Val Acc: 0.783505\n",
      "Epoch 21368 - Train Loss: 0.078451, Train Acc: 0.880769 | Val Loss: 0.109920, Val Acc: 0.783505\n",
      "Epoch 21369 - Train Loss: 0.078449, Train Acc: 0.880769 | Val Loss: 0.109920, Val Acc: 0.783505\n",
      "Epoch 21370 - Train Loss: 0.078447, Train Acc: 0.880769 | Val Loss: 0.109919, Val Acc: 0.783505\n",
      "Epoch 21371 - Train Loss: 0.078445, Train Acc: 0.880769 | Val Loss: 0.109918, Val Acc: 0.783505\n",
      "Epoch 21372 - Train Loss: 0.078443, Train Acc: 0.880769 | Val Loss: 0.109917, Val Acc: 0.783505\n",
      "Epoch 21373 - Train Loss: 0.078441, Train Acc: 0.880769 | Val Loss: 0.109917, Val Acc: 0.783505\n",
      "Epoch 21374 - Train Loss: 0.078439, Train Acc: 0.880769 | Val Loss: 0.109916, Val Acc: 0.783505\n",
      "Epoch 21375 - Train Loss: 0.078437, Train Acc: 0.880769 | Val Loss: 0.109915, Val Acc: 0.783505\n",
      "Epoch 21376 - Train Loss: 0.078435, Train Acc: 0.880769 | Val Loss: 0.109915, Val Acc: 0.783505\n",
      "Epoch 21377 - Train Loss: 0.078433, Train Acc: 0.880769 | Val Loss: 0.109914, Val Acc: 0.783505\n",
      "Epoch 21378 - Train Loss: 0.078431, Train Acc: 0.880769 | Val Loss: 0.109913, Val Acc: 0.783505\n",
      "Epoch 21379 - Train Loss: 0.078429, Train Acc: 0.880769 | Val Loss: 0.109912, Val Acc: 0.783505\n",
      "Epoch 21380 - Train Loss: 0.078427, Train Acc: 0.880769 | Val Loss: 0.109912, Val Acc: 0.783505\n",
      "Epoch 21381 - Train Loss: 0.078425, Train Acc: 0.880769 | Val Loss: 0.109911, Val Acc: 0.783505\n",
      "Epoch 21382 - Train Loss: 0.078423, Train Acc: 0.880769 | Val Loss: 0.109910, Val Acc: 0.783505\n",
      "Epoch 21383 - Train Loss: 0.078421, Train Acc: 0.880769 | Val Loss: 0.109909, Val Acc: 0.783505\n",
      "Epoch 21384 - Train Loss: 0.078419, Train Acc: 0.880769 | Val Loss: 0.109909, Val Acc: 0.783505\n",
      "Epoch 21385 - Train Loss: 0.078417, Train Acc: 0.880769 | Val Loss: 0.109908, Val Acc: 0.783505\n",
      "Epoch 21386 - Train Loss: 0.078415, Train Acc: 0.880769 | Val Loss: 0.109907, Val Acc: 0.783505\n",
      "Epoch 21387 - Train Loss: 0.078413, Train Acc: 0.880769 | Val Loss: 0.109907, Val Acc: 0.783505\n",
      "Epoch 21388 - Train Loss: 0.078411, Train Acc: 0.880769 | Val Loss: 0.109906, Val Acc: 0.783505\n",
      "Epoch 21389 - Train Loss: 0.078409, Train Acc: 0.880769 | Val Loss: 0.109905, Val Acc: 0.783505\n",
      "Epoch 21390 - Train Loss: 0.078407, Train Acc: 0.880769 | Val Loss: 0.109904, Val Acc: 0.783505\n",
      "Epoch 21391 - Train Loss: 0.078405, Train Acc: 0.880769 | Val Loss: 0.109904, Val Acc: 0.783505\n",
      "Epoch 21392 - Train Loss: 0.078403, Train Acc: 0.880769 | Val Loss: 0.109903, Val Acc: 0.783505\n",
      "Epoch 21393 - Train Loss: 0.078401, Train Acc: 0.880769 | Val Loss: 0.109902, Val Acc: 0.783505\n",
      "Epoch 21394 - Train Loss: 0.078399, Train Acc: 0.880769 | Val Loss: 0.109902, Val Acc: 0.783505\n",
      "Epoch 21395 - Train Loss: 0.078397, Train Acc: 0.880769 | Val Loss: 0.109901, Val Acc: 0.783505\n",
      "Epoch 21396 - Train Loss: 0.078395, Train Acc: 0.880769 | Val Loss: 0.109900, Val Acc: 0.783505\n",
      "Epoch 21397 - Train Loss: 0.078393, Train Acc: 0.880769 | Val Loss: 0.109899, Val Acc: 0.783505\n",
      "Epoch 21398 - Train Loss: 0.078391, Train Acc: 0.880769 | Val Loss: 0.109899, Val Acc: 0.783505\n",
      "Epoch 21399 - Train Loss: 0.078389, Train Acc: 0.880769 | Val Loss: 0.109898, Val Acc: 0.783505\n",
      "Epoch 21400 - Train Loss: 0.078387, Train Acc: 0.880769 | Val Loss: 0.109897, Val Acc: 0.783505\n",
      "Epoch 21401 - Train Loss: 0.078385, Train Acc: 0.880769 | Val Loss: 0.109897, Val Acc: 0.783505\n",
      "Epoch 21402 - Train Loss: 0.078383, Train Acc: 0.880769 | Val Loss: 0.109896, Val Acc: 0.783505\n",
      "Epoch 21403 - Train Loss: 0.078381, Train Acc: 0.880769 | Val Loss: 0.109895, Val Acc: 0.783505\n",
      "Epoch 21404 - Train Loss: 0.078379, Train Acc: 0.880769 | Val Loss: 0.109894, Val Acc: 0.783505\n",
      "Epoch 21405 - Train Loss: 0.078377, Train Acc: 0.880769 | Val Loss: 0.109894, Val Acc: 0.783505\n",
      "Epoch 21406 - Train Loss: 0.078375, Train Acc: 0.880769 | Val Loss: 0.109893, Val Acc: 0.783505\n",
      "Epoch 21407 - Train Loss: 0.078373, Train Acc: 0.880769 | Val Loss: 0.109892, Val Acc: 0.783505\n",
      "Epoch 21408 - Train Loss: 0.078371, Train Acc: 0.880769 | Val Loss: 0.109892, Val Acc: 0.783505\n",
      "Epoch 21409 - Train Loss: 0.078369, Train Acc: 0.880769 | Val Loss: 0.109891, Val Acc: 0.783505\n",
      "Epoch 21410 - Train Loss: 0.078367, Train Acc: 0.880769 | Val Loss: 0.109890, Val Acc: 0.783505\n",
      "Epoch 21411 - Train Loss: 0.078365, Train Acc: 0.880769 | Val Loss: 0.109889, Val Acc: 0.783505\n",
      "Epoch 21412 - Train Loss: 0.078363, Train Acc: 0.880769 | Val Loss: 0.109889, Val Acc: 0.783505\n",
      "Epoch 21413 - Train Loss: 0.078361, Train Acc: 0.880769 | Val Loss: 0.109888, Val Acc: 0.783505\n",
      "Epoch 21414 - Train Loss: 0.078359, Train Acc: 0.880769 | Val Loss: 0.109887, Val Acc: 0.783505\n",
      "Epoch 21415 - Train Loss: 0.078357, Train Acc: 0.880769 | Val Loss: 0.109887, Val Acc: 0.783505\n",
      "Epoch 21416 - Train Loss: 0.078355, Train Acc: 0.880769 | Val Loss: 0.109886, Val Acc: 0.783505\n",
      "Epoch 21417 - Train Loss: 0.078353, Train Acc: 0.880769 | Val Loss: 0.109885, Val Acc: 0.783505\n",
      "Epoch 21418 - Train Loss: 0.078351, Train Acc: 0.880769 | Val Loss: 0.109884, Val Acc: 0.783505\n",
      "Epoch 21419 - Train Loss: 0.078349, Train Acc: 0.880769 | Val Loss: 0.109884, Val Acc: 0.783505\n",
      "Epoch 21420 - Train Loss: 0.078347, Train Acc: 0.880769 | Val Loss: 0.109883, Val Acc: 0.783505\n",
      "Epoch 21421 - Train Loss: 0.078345, Train Acc: 0.880769 | Val Loss: 0.109882, Val Acc: 0.783505\n",
      "Epoch 21422 - Train Loss: 0.078343, Train Acc: 0.880769 | Val Loss: 0.109881, Val Acc: 0.783505\n",
      "Epoch 21423 - Train Loss: 0.078341, Train Acc: 0.880769 | Val Loss: 0.109881, Val Acc: 0.783505\n",
      "Epoch 21424 - Train Loss: 0.078339, Train Acc: 0.880769 | Val Loss: 0.109880, Val Acc: 0.783505\n",
      "Epoch 21425 - Train Loss: 0.078337, Train Acc: 0.880769 | Val Loss: 0.109879, Val Acc: 0.783505\n",
      "Epoch 21426 - Train Loss: 0.078335, Train Acc: 0.880769 | Val Loss: 0.109879, Val Acc: 0.783505\n",
      "Epoch 21427 - Train Loss: 0.078333, Train Acc: 0.880769 | Val Loss: 0.109878, Val Acc: 0.783505\n",
      "Epoch 21428 - Train Loss: 0.078331, Train Acc: 0.880769 | Val Loss: 0.109877, Val Acc: 0.783505\n",
      "Epoch 21429 - Train Loss: 0.078329, Train Acc: 0.880769 | Val Loss: 0.109876, Val Acc: 0.783505\n",
      "Epoch 21430 - Train Loss: 0.078327, Train Acc: 0.880769 | Val Loss: 0.109876, Val Acc: 0.783505\n",
      "Epoch 21431 - Train Loss: 0.078325, Train Acc: 0.880769 | Val Loss: 0.109875, Val Acc: 0.783505\n",
      "Epoch 21432 - Train Loss: 0.078323, Train Acc: 0.880769 | Val Loss: 0.109874, Val Acc: 0.783505\n",
      "Epoch 21433 - Train Loss: 0.078321, Train Acc: 0.880769 | Val Loss: 0.109874, Val Acc: 0.783505\n",
      "Epoch 21434 - Train Loss: 0.078319, Train Acc: 0.880769 | Val Loss: 0.109873, Val Acc: 0.783505\n",
      "Epoch 21435 - Train Loss: 0.078317, Train Acc: 0.880769 | Val Loss: 0.109872, Val Acc: 0.783505\n",
      "Epoch 21436 - Train Loss: 0.078315, Train Acc: 0.880769 | Val Loss: 0.109871, Val Acc: 0.783505\n",
      "Epoch 21437 - Train Loss: 0.078313, Train Acc: 0.880769 | Val Loss: 0.109871, Val Acc: 0.783505\n",
      "Epoch 21438 - Train Loss: 0.078311, Train Acc: 0.880769 | Val Loss: 0.109870, Val Acc: 0.783505\n",
      "Epoch 21439 - Train Loss: 0.078309, Train Acc: 0.880769 | Val Loss: 0.109869, Val Acc: 0.783505\n",
      "Epoch 21440 - Train Loss: 0.078307, Train Acc: 0.880769 | Val Loss: 0.109869, Val Acc: 0.783505\n",
      "Epoch 21441 - Train Loss: 0.078305, Train Acc: 0.880769 | Val Loss: 0.109868, Val Acc: 0.783505\n",
      "Epoch 21442 - Train Loss: 0.078303, Train Acc: 0.880769 | Val Loss: 0.109867, Val Acc: 0.783505\n",
      "Epoch 21443 - Train Loss: 0.078301, Train Acc: 0.880769 | Val Loss: 0.109866, Val Acc: 0.783505\n",
      "Epoch 21444 - Train Loss: 0.078299, Train Acc: 0.880769 | Val Loss: 0.109866, Val Acc: 0.783505\n",
      "Epoch 21445 - Train Loss: 0.078297, Train Acc: 0.880769 | Val Loss: 0.109865, Val Acc: 0.783505\n",
      "Epoch 21446 - Train Loss: 0.078295, Train Acc: 0.880769 | Val Loss: 0.109864, Val Acc: 0.783505\n",
      "Epoch 21447 - Train Loss: 0.078293, Train Acc: 0.880769 | Val Loss: 0.109864, Val Acc: 0.783505\n",
      "Epoch 21448 - Train Loss: 0.078291, Train Acc: 0.880769 | Val Loss: 0.109863, Val Acc: 0.783505\n",
      "Epoch 21449 - Train Loss: 0.078289, Train Acc: 0.880769 | Val Loss: 0.109862, Val Acc: 0.783505\n",
      "Epoch 21450 - Train Loss: 0.078287, Train Acc: 0.880769 | Val Loss: 0.109861, Val Acc: 0.783505\n",
      "Epoch 21451 - Train Loss: 0.078285, Train Acc: 0.880769 | Val Loss: 0.109861, Val Acc: 0.783505\n",
      "Epoch 21452 - Train Loss: 0.078283, Train Acc: 0.880769 | Val Loss: 0.109860, Val Acc: 0.783505\n",
      "Epoch 21453 - Train Loss: 0.078281, Train Acc: 0.880769 | Val Loss: 0.109859, Val Acc: 0.783505\n",
      "Epoch 21454 - Train Loss: 0.078279, Train Acc: 0.880769 | Val Loss: 0.109859, Val Acc: 0.783505\n",
      "Epoch 21455 - Train Loss: 0.078277, Train Acc: 0.880769 | Val Loss: 0.109858, Val Acc: 0.783505\n",
      "Epoch 21456 - Train Loss: 0.078275, Train Acc: 0.880769 | Val Loss: 0.109857, Val Acc: 0.783505\n",
      "Epoch 21457 - Train Loss: 0.078273, Train Acc: 0.880769 | Val Loss: 0.109857, Val Acc: 0.783505\n",
      "Epoch 21458 - Train Loss: 0.078271, Train Acc: 0.880769 | Val Loss: 0.109856, Val Acc: 0.783505\n",
      "Epoch 21459 - Train Loss: 0.078269, Train Acc: 0.880769 | Val Loss: 0.109855, Val Acc: 0.783505\n",
      "Epoch 21460 - Train Loss: 0.078267, Train Acc: 0.880769 | Val Loss: 0.109854, Val Acc: 0.783505\n",
      "Epoch 21461 - Train Loss: 0.078265, Train Acc: 0.880769 | Val Loss: 0.109854, Val Acc: 0.783505\n",
      "Epoch 21462 - Train Loss: 0.078263, Train Acc: 0.880769 | Val Loss: 0.109853, Val Acc: 0.783505\n",
      "Epoch 21463 - Train Loss: 0.078261, Train Acc: 0.880769 | Val Loss: 0.109852, Val Acc: 0.783505\n",
      "Epoch 21464 - Train Loss: 0.078259, Train Acc: 0.880769 | Val Loss: 0.109852, Val Acc: 0.783505\n",
      "Epoch 21465 - Train Loss: 0.078257, Train Acc: 0.880769 | Val Loss: 0.109851, Val Acc: 0.783505\n",
      "Epoch 21466 - Train Loss: 0.078255, Train Acc: 0.880769 | Val Loss: 0.109850, Val Acc: 0.783505\n",
      "Epoch 21467 - Train Loss: 0.078253, Train Acc: 0.880769 | Val Loss: 0.109849, Val Acc: 0.783505\n",
      "Epoch 21468 - Train Loss: 0.078251, Train Acc: 0.880769 | Val Loss: 0.109849, Val Acc: 0.783505\n",
      "Epoch 21469 - Train Loss: 0.078249, Train Acc: 0.880769 | Val Loss: 0.109848, Val Acc: 0.783505\n",
      "Epoch 21470 - Train Loss: 0.078247, Train Acc: 0.880769 | Val Loss: 0.109847, Val Acc: 0.783505\n",
      "Epoch 21471 - Train Loss: 0.078245, Train Acc: 0.880769 | Val Loss: 0.109847, Val Acc: 0.783505\n",
      "Epoch 21472 - Train Loss: 0.078243, Train Acc: 0.880769 | Val Loss: 0.109846, Val Acc: 0.783505\n",
      "Epoch 21473 - Train Loss: 0.078241, Train Acc: 0.880769 | Val Loss: 0.109845, Val Acc: 0.783505\n",
      "Epoch 21474 - Train Loss: 0.078239, Train Acc: 0.880769 | Val Loss: 0.109844, Val Acc: 0.783505\n",
      "Epoch 21475 - Train Loss: 0.078237, Train Acc: 0.880769 | Val Loss: 0.109844, Val Acc: 0.783505\n",
      "Epoch 21476 - Train Loss: 0.078235, Train Acc: 0.880769 | Val Loss: 0.109843, Val Acc: 0.783505\n",
      "Epoch 21477 - Train Loss: 0.078233, Train Acc: 0.880769 | Val Loss: 0.109842, Val Acc: 0.783505\n",
      "Epoch 21478 - Train Loss: 0.078231, Train Acc: 0.880769 | Val Loss: 0.109842, Val Acc: 0.783505\n",
      "Epoch 21479 - Train Loss: 0.078229, Train Acc: 0.880769 | Val Loss: 0.109841, Val Acc: 0.783505\n",
      "Epoch 21480 - Train Loss: 0.078227, Train Acc: 0.880769 | Val Loss: 0.109840, Val Acc: 0.783505\n",
      "Epoch 21481 - Train Loss: 0.078225, Train Acc: 0.880769 | Val Loss: 0.109840, Val Acc: 0.783505\n",
      "Epoch 21482 - Train Loss: 0.078224, Train Acc: 0.880769 | Val Loss: 0.109839, Val Acc: 0.783505\n",
      "Epoch 21483 - Train Loss: 0.078222, Train Acc: 0.880769 | Val Loss: 0.109838, Val Acc: 0.783505\n",
      "Epoch 21484 - Train Loss: 0.078220, Train Acc: 0.880769 | Val Loss: 0.109837, Val Acc: 0.783505\n",
      "Epoch 21485 - Train Loss: 0.078218, Train Acc: 0.880769 | Val Loss: 0.109837, Val Acc: 0.783505\n",
      "Epoch 21486 - Train Loss: 0.078216, Train Acc: 0.880769 | Val Loss: 0.109836, Val Acc: 0.783505\n",
      "Epoch 21487 - Train Loss: 0.078214, Train Acc: 0.880769 | Val Loss: 0.109835, Val Acc: 0.783505\n",
      "Epoch 21488 - Train Loss: 0.078212, Train Acc: 0.880769 | Val Loss: 0.109835, Val Acc: 0.783505\n",
      "Epoch 21489 - Train Loss: 0.078210, Train Acc: 0.880769 | Val Loss: 0.109834, Val Acc: 0.783505\n",
      "Epoch 21490 - Train Loss: 0.078208, Train Acc: 0.880769 | Val Loss: 0.109833, Val Acc: 0.783505\n",
      "Epoch 21491 - Train Loss: 0.078206, Train Acc: 0.880769 | Val Loss: 0.109832, Val Acc: 0.783505\n",
      "Epoch 21492 - Train Loss: 0.078204, Train Acc: 0.880769 | Val Loss: 0.109832, Val Acc: 0.783505\n",
      "Epoch 21493 - Train Loss: 0.078202, Train Acc: 0.880769 | Val Loss: 0.109831, Val Acc: 0.783505\n",
      "Epoch 21494 - Train Loss: 0.078200, Train Acc: 0.880769 | Val Loss: 0.109830, Val Acc: 0.783505\n",
      "Epoch 21495 - Train Loss: 0.078198, Train Acc: 0.880769 | Val Loss: 0.109830, Val Acc: 0.783505\n",
      "Epoch 21496 - Train Loss: 0.078196, Train Acc: 0.880769 | Val Loss: 0.109829, Val Acc: 0.783505\n",
      "Epoch 21497 - Train Loss: 0.078194, Train Acc: 0.880769 | Val Loss: 0.109828, Val Acc: 0.783505\n",
      "Epoch 21498 - Train Loss: 0.078192, Train Acc: 0.880769 | Val Loss: 0.109828, Val Acc: 0.783505\n",
      "Epoch 21499 - Train Loss: 0.078190, Train Acc: 0.880769 | Val Loss: 0.109827, Val Acc: 0.783505\n",
      "Epoch 21500 - Train Loss: 0.078188, Train Acc: 0.880769 | Val Loss: 0.109826, Val Acc: 0.783505\n",
      "Epoch 21501 - Train Loss: 0.078186, Train Acc: 0.880769 | Val Loss: 0.109825, Val Acc: 0.783505\n",
      "Epoch 21502 - Train Loss: 0.078184, Train Acc: 0.880769 | Val Loss: 0.109825, Val Acc: 0.783505\n",
      "Epoch 21503 - Train Loss: 0.078182, Train Acc: 0.880769 | Val Loss: 0.109824, Val Acc: 0.783505\n",
      "Epoch 21504 - Train Loss: 0.078180, Train Acc: 0.880769 | Val Loss: 0.109823, Val Acc: 0.783505\n",
      "Epoch 21505 - Train Loss: 0.078178, Train Acc: 0.880769 | Val Loss: 0.109823, Val Acc: 0.783505\n",
      "Epoch 21506 - Train Loss: 0.078176, Train Acc: 0.880769 | Val Loss: 0.109822, Val Acc: 0.783505\n",
      "Epoch 21507 - Train Loss: 0.078174, Train Acc: 0.880769 | Val Loss: 0.109821, Val Acc: 0.783505\n",
      "Epoch 21508 - Train Loss: 0.078172, Train Acc: 0.880769 | Val Loss: 0.109820, Val Acc: 0.783505\n",
      "Epoch 21509 - Train Loss: 0.078170, Train Acc: 0.880769 | Val Loss: 0.109820, Val Acc: 0.783505\n",
      "Epoch 21510 - Train Loss: 0.078168, Train Acc: 0.880769 | Val Loss: 0.109819, Val Acc: 0.783505\n",
      "Epoch 21511 - Train Loss: 0.078166, Train Acc: 0.880769 | Val Loss: 0.109818, Val Acc: 0.783505\n",
      "Epoch 21512 - Train Loss: 0.078164, Train Acc: 0.880769 | Val Loss: 0.109818, Val Acc: 0.783505\n",
      "Epoch 21513 - Train Loss: 0.078162, Train Acc: 0.880769 | Val Loss: 0.109817, Val Acc: 0.783505\n",
      "Epoch 21514 - Train Loss: 0.078160, Train Acc: 0.880769 | Val Loss: 0.109816, Val Acc: 0.783505\n",
      "Epoch 21515 - Train Loss: 0.078158, Train Acc: 0.880769 | Val Loss: 0.109816, Val Acc: 0.783505\n",
      "Epoch 21516 - Train Loss: 0.078156, Train Acc: 0.880769 | Val Loss: 0.109815, Val Acc: 0.783505\n",
      "Epoch 21517 - Train Loss: 0.078154, Train Acc: 0.880769 | Val Loss: 0.109814, Val Acc: 0.783505\n",
      "Epoch 21518 - Train Loss: 0.078152, Train Acc: 0.880769 | Val Loss: 0.109814, Val Acc: 0.783505\n",
      "Epoch 21519 - Train Loss: 0.078150, Train Acc: 0.880769 | Val Loss: 0.109813, Val Acc: 0.783505\n",
      "Epoch 21520 - Train Loss: 0.078148, Train Acc: 0.880769 | Val Loss: 0.109812, Val Acc: 0.783505\n",
      "Epoch 21521 - Train Loss: 0.078146, Train Acc: 0.880769 | Val Loss: 0.109811, Val Acc: 0.783505\n",
      "Epoch 21522 - Train Loss: 0.078144, Train Acc: 0.880769 | Val Loss: 0.109811, Val Acc: 0.783505\n",
      "Epoch 21523 - Train Loss: 0.078142, Train Acc: 0.880769 | Val Loss: 0.109810, Val Acc: 0.783505\n",
      "Epoch 21524 - Train Loss: 0.078140, Train Acc: 0.880769 | Val Loss: 0.109809, Val Acc: 0.783505\n",
      "Epoch 21525 - Train Loss: 0.078138, Train Acc: 0.880769 | Val Loss: 0.109809, Val Acc: 0.783505\n",
      "Epoch 21526 - Train Loss: 0.078136, Train Acc: 0.880769 | Val Loss: 0.109808, Val Acc: 0.783505\n",
      "Epoch 21527 - Train Loss: 0.078134, Train Acc: 0.880769 | Val Loss: 0.109807, Val Acc: 0.783505\n",
      "Epoch 21528 - Train Loss: 0.078132, Train Acc: 0.880769 | Val Loss: 0.109807, Val Acc: 0.783505\n",
      "Epoch 21529 - Train Loss: 0.078130, Train Acc: 0.880769 | Val Loss: 0.109806, Val Acc: 0.783505\n",
      "Epoch 21530 - Train Loss: 0.078128, Train Acc: 0.880769 | Val Loss: 0.109805, Val Acc: 0.783505\n",
      "Epoch 21531 - Train Loss: 0.078126, Train Acc: 0.880769 | Val Loss: 0.109804, Val Acc: 0.783505\n",
      "Epoch 21532 - Train Loss: 0.078124, Train Acc: 0.880769 | Val Loss: 0.109804, Val Acc: 0.783505\n",
      "Epoch 21533 - Train Loss: 0.078122, Train Acc: 0.880769 | Val Loss: 0.109803, Val Acc: 0.783505\n",
      "Epoch 21534 - Train Loss: 0.078120, Train Acc: 0.880769 | Val Loss: 0.109802, Val Acc: 0.783505\n",
      "Epoch 21535 - Train Loss: 0.078118, Train Acc: 0.880769 | Val Loss: 0.109802, Val Acc: 0.783505\n",
      "Epoch 21536 - Train Loss: 0.078116, Train Acc: 0.880769 | Val Loss: 0.109801, Val Acc: 0.783505\n",
      "Epoch 21537 - Train Loss: 0.078114, Train Acc: 0.880769 | Val Loss: 0.109800, Val Acc: 0.783505\n",
      "Epoch 21538 - Train Loss: 0.078112, Train Acc: 0.880769 | Val Loss: 0.109800, Val Acc: 0.783505\n",
      "Epoch 21539 - Train Loss: 0.078110, Train Acc: 0.880769 | Val Loss: 0.109799, Val Acc: 0.783505\n",
      "Epoch 21540 - Train Loss: 0.078108, Train Acc: 0.880769 | Val Loss: 0.109798, Val Acc: 0.783505\n",
      "Epoch 21541 - Train Loss: 0.078106, Train Acc: 0.880769 | Val Loss: 0.109798, Val Acc: 0.783505\n",
      "Epoch 21542 - Train Loss: 0.078104, Train Acc: 0.880769 | Val Loss: 0.109797, Val Acc: 0.783505\n",
      "Epoch 21543 - Train Loss: 0.078103, Train Acc: 0.880769 | Val Loss: 0.109796, Val Acc: 0.783505\n",
      "Epoch 21544 - Train Loss: 0.078101, Train Acc: 0.880769 | Val Loss: 0.109795, Val Acc: 0.783505\n",
      "Epoch 21545 - Train Loss: 0.078099, Train Acc: 0.880769 | Val Loss: 0.109795, Val Acc: 0.783505\n",
      "Epoch 21546 - Train Loss: 0.078097, Train Acc: 0.880769 | Val Loss: 0.109794, Val Acc: 0.783505\n",
      "Epoch 21547 - Train Loss: 0.078095, Train Acc: 0.880769 | Val Loss: 0.109793, Val Acc: 0.783505\n",
      "Epoch 21548 - Train Loss: 0.078093, Train Acc: 0.880769 | Val Loss: 0.109793, Val Acc: 0.783505\n",
      "Epoch 21549 - Train Loss: 0.078091, Train Acc: 0.880769 | Val Loss: 0.109792, Val Acc: 0.783505\n",
      "Epoch 21550 - Train Loss: 0.078089, Train Acc: 0.880769 | Val Loss: 0.109791, Val Acc: 0.783505\n",
      "Epoch 21551 - Train Loss: 0.078087, Train Acc: 0.880769 | Val Loss: 0.109791, Val Acc: 0.783505\n",
      "Epoch 21552 - Train Loss: 0.078085, Train Acc: 0.880769 | Val Loss: 0.109790, Val Acc: 0.783505\n",
      "Epoch 21553 - Train Loss: 0.078083, Train Acc: 0.880769 | Val Loss: 0.109789, Val Acc: 0.783505\n",
      "Epoch 21554 - Train Loss: 0.078081, Train Acc: 0.880769 | Val Loss: 0.109788, Val Acc: 0.783505\n",
      "Epoch 21555 - Train Loss: 0.078079, Train Acc: 0.880769 | Val Loss: 0.109788, Val Acc: 0.783505\n",
      "Epoch 21556 - Train Loss: 0.078077, Train Acc: 0.880769 | Val Loss: 0.109787, Val Acc: 0.783505\n",
      "Epoch 21557 - Train Loss: 0.078075, Train Acc: 0.880769 | Val Loss: 0.109786, Val Acc: 0.783505\n",
      "Epoch 21558 - Train Loss: 0.078073, Train Acc: 0.880769 | Val Loss: 0.109786, Val Acc: 0.783505\n",
      "Epoch 21559 - Train Loss: 0.078071, Train Acc: 0.880769 | Val Loss: 0.109785, Val Acc: 0.783505\n",
      "Epoch 21560 - Train Loss: 0.078069, Train Acc: 0.880769 | Val Loss: 0.109784, Val Acc: 0.783505\n",
      "Epoch 21561 - Train Loss: 0.078067, Train Acc: 0.880769 | Val Loss: 0.109784, Val Acc: 0.783505\n",
      "Epoch 21562 - Train Loss: 0.078065, Train Acc: 0.880769 | Val Loss: 0.109783, Val Acc: 0.783505\n",
      "Epoch 21563 - Train Loss: 0.078063, Train Acc: 0.880769 | Val Loss: 0.109782, Val Acc: 0.783505\n",
      "Epoch 21564 - Train Loss: 0.078061, Train Acc: 0.880769 | Val Loss: 0.109782, Val Acc: 0.783505\n",
      "Epoch 21565 - Train Loss: 0.078059, Train Acc: 0.880769 | Val Loss: 0.109781, Val Acc: 0.783505\n",
      "Epoch 21566 - Train Loss: 0.078057, Train Acc: 0.880769 | Val Loss: 0.109780, Val Acc: 0.783505\n",
      "Epoch 21567 - Train Loss: 0.078055, Train Acc: 0.880769 | Val Loss: 0.109779, Val Acc: 0.783505\n",
      "Epoch 21568 - Train Loss: 0.078053, Train Acc: 0.880769 | Val Loss: 0.109779, Val Acc: 0.783505\n",
      "Epoch 21569 - Train Loss: 0.078051, Train Acc: 0.880769 | Val Loss: 0.109778, Val Acc: 0.783505\n",
      "Epoch 21570 - Train Loss: 0.078049, Train Acc: 0.880769 | Val Loss: 0.109777, Val Acc: 0.783505\n",
      "Epoch 21571 - Train Loss: 0.078047, Train Acc: 0.880769 | Val Loss: 0.109777, Val Acc: 0.783505\n",
      "Epoch 21572 - Train Loss: 0.078045, Train Acc: 0.880769 | Val Loss: 0.109776, Val Acc: 0.783505\n",
      "Epoch 21573 - Train Loss: 0.078043, Train Acc: 0.880769 | Val Loss: 0.109775, Val Acc: 0.783505\n",
      "Epoch 21574 - Train Loss: 0.078041, Train Acc: 0.880769 | Val Loss: 0.109775, Val Acc: 0.783505\n",
      "Epoch 21575 - Train Loss: 0.078039, Train Acc: 0.880769 | Val Loss: 0.109774, Val Acc: 0.783505\n",
      "Epoch 21576 - Train Loss: 0.078037, Train Acc: 0.880769 | Val Loss: 0.109773, Val Acc: 0.783505\n",
      "Epoch 21577 - Train Loss: 0.078035, Train Acc: 0.880769 | Val Loss: 0.109773, Val Acc: 0.783505\n",
      "Epoch 21578 - Train Loss: 0.078033, Train Acc: 0.880769 | Val Loss: 0.109772, Val Acc: 0.783505\n",
      "Epoch 21579 - Train Loss: 0.078031, Train Acc: 0.880769 | Val Loss: 0.109771, Val Acc: 0.783505\n",
      "Epoch 21580 - Train Loss: 0.078029, Train Acc: 0.880769 | Val Loss: 0.109771, Val Acc: 0.783505\n",
      "Epoch 21581 - Train Loss: 0.078027, Train Acc: 0.880769 | Val Loss: 0.109770, Val Acc: 0.783505\n",
      "Epoch 21582 - Train Loss: 0.078026, Train Acc: 0.880769 | Val Loss: 0.109769, Val Acc: 0.783505\n",
      "Epoch 21583 - Train Loss: 0.078024, Train Acc: 0.880769 | Val Loss: 0.109768, Val Acc: 0.783505\n",
      "Epoch 21584 - Train Loss: 0.078022, Train Acc: 0.880769 | Val Loss: 0.109768, Val Acc: 0.783505\n",
      "Epoch 21585 - Train Loss: 0.078020, Train Acc: 0.880769 | Val Loss: 0.109767, Val Acc: 0.783505\n",
      "Epoch 21586 - Train Loss: 0.078018, Train Acc: 0.880769 | Val Loss: 0.109766, Val Acc: 0.783505\n",
      "Epoch 21587 - Train Loss: 0.078016, Train Acc: 0.880769 | Val Loss: 0.109766, Val Acc: 0.783505\n",
      "Epoch 21588 - Train Loss: 0.078014, Train Acc: 0.880769 | Val Loss: 0.109765, Val Acc: 0.783505\n",
      "Epoch 21589 - Train Loss: 0.078012, Train Acc: 0.880769 | Val Loss: 0.109764, Val Acc: 0.783505\n",
      "Epoch 21590 - Train Loss: 0.078010, Train Acc: 0.880769 | Val Loss: 0.109764, Val Acc: 0.783505\n",
      "Epoch 21591 - Train Loss: 0.078008, Train Acc: 0.880769 | Val Loss: 0.109763, Val Acc: 0.783505\n",
      "Epoch 21592 - Train Loss: 0.078006, Train Acc: 0.880769 | Val Loss: 0.109762, Val Acc: 0.783505\n",
      "Epoch 21593 - Train Loss: 0.078004, Train Acc: 0.880769 | Val Loss: 0.109762, Val Acc: 0.783505\n",
      "Epoch 21594 - Train Loss: 0.078002, Train Acc: 0.880769 | Val Loss: 0.109761, Val Acc: 0.783505\n",
      "Epoch 21595 - Train Loss: 0.078000, Train Acc: 0.880769 | Val Loss: 0.109760, Val Acc: 0.783505\n",
      "Epoch 21596 - Train Loss: 0.077998, Train Acc: 0.880769 | Val Loss: 0.109760, Val Acc: 0.783505\n",
      "Epoch 21597 - Train Loss: 0.077996, Train Acc: 0.880769 | Val Loss: 0.109759, Val Acc: 0.783505\n",
      "Epoch 21598 - Train Loss: 0.077994, Train Acc: 0.880769 | Val Loss: 0.109758, Val Acc: 0.783505\n",
      "Epoch 21599 - Train Loss: 0.077992, Train Acc: 0.880769 | Val Loss: 0.109757, Val Acc: 0.783505\n",
      "Epoch 21600 - Train Loss: 0.077990, Train Acc: 0.880769 | Val Loss: 0.109757, Val Acc: 0.783505\n",
      "Epoch 21601 - Train Loss: 0.077988, Train Acc: 0.880769 | Val Loss: 0.109756, Val Acc: 0.783505\n",
      "Epoch 21602 - Train Loss: 0.077986, Train Acc: 0.880769 | Val Loss: 0.109755, Val Acc: 0.783505\n",
      "Epoch 21603 - Train Loss: 0.077984, Train Acc: 0.880769 | Val Loss: 0.109755, Val Acc: 0.783505\n",
      "Epoch 21604 - Train Loss: 0.077982, Train Acc: 0.880769 | Val Loss: 0.109754, Val Acc: 0.783505\n",
      "Epoch 21605 - Train Loss: 0.077980, Train Acc: 0.880769 | Val Loss: 0.109753, Val Acc: 0.783505\n",
      "Epoch 21606 - Train Loss: 0.077978, Train Acc: 0.880769 | Val Loss: 0.109753, Val Acc: 0.783505\n",
      "Epoch 21607 - Train Loss: 0.077976, Train Acc: 0.880769 | Val Loss: 0.109752, Val Acc: 0.783505\n",
      "Epoch 21608 - Train Loss: 0.077974, Train Acc: 0.880769 | Val Loss: 0.109751, Val Acc: 0.783505\n",
      "Epoch 21609 - Train Loss: 0.077972, Train Acc: 0.880769 | Val Loss: 0.109751, Val Acc: 0.783505\n",
      "Epoch 21610 - Train Loss: 0.077970, Train Acc: 0.880769 | Val Loss: 0.109750, Val Acc: 0.783505\n",
      "Epoch 21611 - Train Loss: 0.077968, Train Acc: 0.880769 | Val Loss: 0.109749, Val Acc: 0.783505\n",
      "Epoch 21612 - Train Loss: 0.077966, Train Acc: 0.880769 | Val Loss: 0.109749, Val Acc: 0.783505\n",
      "Epoch 21613 - Train Loss: 0.077964, Train Acc: 0.880769 | Val Loss: 0.109748, Val Acc: 0.783505\n",
      "Epoch 21614 - Train Loss: 0.077963, Train Acc: 0.880769 | Val Loss: 0.109747, Val Acc: 0.783505\n",
      "Epoch 21615 - Train Loss: 0.077961, Train Acc: 0.880769 | Val Loss: 0.109747, Val Acc: 0.783505\n",
      "Epoch 21616 - Train Loss: 0.077959, Train Acc: 0.880769 | Val Loss: 0.109746, Val Acc: 0.783505\n",
      "Epoch 21617 - Train Loss: 0.077957, Train Acc: 0.880769 | Val Loss: 0.109745, Val Acc: 0.783505\n",
      "Epoch 21618 - Train Loss: 0.077955, Train Acc: 0.880769 | Val Loss: 0.109744, Val Acc: 0.783505\n",
      "Epoch 21619 - Train Loss: 0.077953, Train Acc: 0.880769 | Val Loss: 0.109744, Val Acc: 0.783505\n",
      "Epoch 21620 - Train Loss: 0.077951, Train Acc: 0.880769 | Val Loss: 0.109743, Val Acc: 0.783505\n",
      "Epoch 21621 - Train Loss: 0.077949, Train Acc: 0.880769 | Val Loss: 0.109742, Val Acc: 0.783505\n",
      "Epoch 21622 - Train Loss: 0.077947, Train Acc: 0.880769 | Val Loss: 0.109742, Val Acc: 0.783505\n",
      "Epoch 21623 - Train Loss: 0.077945, Train Acc: 0.880769 | Val Loss: 0.109741, Val Acc: 0.783505\n",
      "Epoch 21624 - Train Loss: 0.077943, Train Acc: 0.880769 | Val Loss: 0.109740, Val Acc: 0.783505\n",
      "Epoch 21625 - Train Loss: 0.077941, Train Acc: 0.880769 | Val Loss: 0.109740, Val Acc: 0.783505\n",
      "Epoch 21626 - Train Loss: 0.077939, Train Acc: 0.880769 | Val Loss: 0.109739, Val Acc: 0.783505\n",
      "Epoch 21627 - Train Loss: 0.077937, Train Acc: 0.880769 | Val Loss: 0.109738, Val Acc: 0.783505\n",
      "Epoch 21628 - Train Loss: 0.077935, Train Acc: 0.880769 | Val Loss: 0.109738, Val Acc: 0.783505\n",
      "Epoch 21629 - Train Loss: 0.077933, Train Acc: 0.880769 | Val Loss: 0.109737, Val Acc: 0.783505\n",
      "Epoch 21630 - Train Loss: 0.077931, Train Acc: 0.880769 | Val Loss: 0.109736, Val Acc: 0.783505\n",
      "Epoch 21631 - Train Loss: 0.077929, Train Acc: 0.880769 | Val Loss: 0.109736, Val Acc: 0.783505\n",
      "Epoch 21632 - Train Loss: 0.077927, Train Acc: 0.880769 | Val Loss: 0.109735, Val Acc: 0.783505\n",
      "Epoch 21633 - Train Loss: 0.077925, Train Acc: 0.880769 | Val Loss: 0.109734, Val Acc: 0.783505\n",
      "Epoch 21634 - Train Loss: 0.077923, Train Acc: 0.880769 | Val Loss: 0.109734, Val Acc: 0.783505\n",
      "Epoch 21635 - Train Loss: 0.077921, Train Acc: 0.880769 | Val Loss: 0.109733, Val Acc: 0.783505\n",
      "Epoch 21636 - Train Loss: 0.077919, Train Acc: 0.880769 | Val Loss: 0.109732, Val Acc: 0.783505\n",
      "Epoch 21637 - Train Loss: 0.077917, Train Acc: 0.880769 | Val Loss: 0.109732, Val Acc: 0.783505\n",
      "Epoch 21638 - Train Loss: 0.077915, Train Acc: 0.880769 | Val Loss: 0.109731, Val Acc: 0.783505\n",
      "Epoch 21639 - Train Loss: 0.077913, Train Acc: 0.880769 | Val Loss: 0.109730, Val Acc: 0.783505\n",
      "Epoch 21640 - Train Loss: 0.077912, Train Acc: 0.880769 | Val Loss: 0.109730, Val Acc: 0.783505\n",
      "Epoch 21641 - Train Loss: 0.077910, Train Acc: 0.880769 | Val Loss: 0.109729, Val Acc: 0.783505\n",
      "Epoch 21642 - Train Loss: 0.077908, Train Acc: 0.880769 | Val Loss: 0.109728, Val Acc: 0.783505\n",
      "Epoch 21643 - Train Loss: 0.077906, Train Acc: 0.880769 | Val Loss: 0.109728, Val Acc: 0.783505\n",
      "Epoch 21644 - Train Loss: 0.077904, Train Acc: 0.880769 | Val Loss: 0.109727, Val Acc: 0.783505\n",
      "Epoch 21645 - Train Loss: 0.077902, Train Acc: 0.880769 | Val Loss: 0.109726, Val Acc: 0.783505\n",
      "Epoch 21646 - Train Loss: 0.077900, Train Acc: 0.880769 | Val Loss: 0.109725, Val Acc: 0.783505\n",
      "Epoch 21647 - Train Loss: 0.077898, Train Acc: 0.880769 | Val Loss: 0.109725, Val Acc: 0.783505\n",
      "Epoch 21648 - Train Loss: 0.077896, Train Acc: 0.880769 | Val Loss: 0.109724, Val Acc: 0.783505\n",
      "Epoch 21649 - Train Loss: 0.077894, Train Acc: 0.880769 | Val Loss: 0.109723, Val Acc: 0.783505\n",
      "Epoch 21650 - Train Loss: 0.077892, Train Acc: 0.880769 | Val Loss: 0.109723, Val Acc: 0.783505\n",
      "Epoch 21651 - Train Loss: 0.077890, Train Acc: 0.880769 | Val Loss: 0.109722, Val Acc: 0.783505\n",
      "Epoch 21652 - Train Loss: 0.077888, Train Acc: 0.880769 | Val Loss: 0.109721, Val Acc: 0.783505\n",
      "Epoch 21653 - Train Loss: 0.077886, Train Acc: 0.880769 | Val Loss: 0.109721, Val Acc: 0.783505\n",
      "Epoch 21654 - Train Loss: 0.077884, Train Acc: 0.880769 | Val Loss: 0.109720, Val Acc: 0.783505\n",
      "Epoch 21655 - Train Loss: 0.077882, Train Acc: 0.880769 | Val Loss: 0.109719, Val Acc: 0.783505\n",
      "Epoch 21656 - Train Loss: 0.077880, Train Acc: 0.880769 | Val Loss: 0.109719, Val Acc: 0.783505\n",
      "Epoch 21657 - Train Loss: 0.077878, Train Acc: 0.880769 | Val Loss: 0.109718, Val Acc: 0.783505\n",
      "Epoch 21658 - Train Loss: 0.077876, Train Acc: 0.880769 | Val Loss: 0.109717, Val Acc: 0.783505\n",
      "Epoch 21659 - Train Loss: 0.077874, Train Acc: 0.880769 | Val Loss: 0.109717, Val Acc: 0.783505\n",
      "Epoch 21660 - Train Loss: 0.077872, Train Acc: 0.880769 | Val Loss: 0.109716, Val Acc: 0.783505\n",
      "Epoch 21661 - Train Loss: 0.077870, Train Acc: 0.880769 | Val Loss: 0.109715, Val Acc: 0.783505\n",
      "Epoch 21662 - Train Loss: 0.077868, Train Acc: 0.880769 | Val Loss: 0.109715, Val Acc: 0.783505\n",
      "Epoch 21663 - Train Loss: 0.077866, Train Acc: 0.880769 | Val Loss: 0.109714, Val Acc: 0.783505\n",
      "Epoch 21664 - Train Loss: 0.077865, Train Acc: 0.880769 | Val Loss: 0.109713, Val Acc: 0.783505\n",
      "Epoch 21665 - Train Loss: 0.077863, Train Acc: 0.880769 | Val Loss: 0.109713, Val Acc: 0.783505\n",
      "Epoch 21666 - Train Loss: 0.077861, Train Acc: 0.880769 | Val Loss: 0.109712, Val Acc: 0.783505\n",
      "Epoch 21667 - Train Loss: 0.077859, Train Acc: 0.880769 | Val Loss: 0.109711, Val Acc: 0.783505\n",
      "Epoch 21668 - Train Loss: 0.077857, Train Acc: 0.880769 | Val Loss: 0.109711, Val Acc: 0.783505\n",
      "Epoch 21669 - Train Loss: 0.077855, Train Acc: 0.880769 | Val Loss: 0.109710, Val Acc: 0.783505\n",
      "Epoch 21670 - Train Loss: 0.077853, Train Acc: 0.880769 | Val Loss: 0.109709, Val Acc: 0.783505\n",
      "Epoch 21671 - Train Loss: 0.077851, Train Acc: 0.880769 | Val Loss: 0.109709, Val Acc: 0.783505\n",
      "Epoch 21672 - Train Loss: 0.077849, Train Acc: 0.880769 | Val Loss: 0.109708, Val Acc: 0.783505\n",
      "Epoch 21673 - Train Loss: 0.077847, Train Acc: 0.880769 | Val Loss: 0.109707, Val Acc: 0.783505\n",
      "Epoch 21674 - Train Loss: 0.077845, Train Acc: 0.880769 | Val Loss: 0.109707, Val Acc: 0.783505\n",
      "Epoch 21675 - Train Loss: 0.077843, Train Acc: 0.880769 | Val Loss: 0.109706, Val Acc: 0.783505\n",
      "Epoch 21676 - Train Loss: 0.077841, Train Acc: 0.880769 | Val Loss: 0.109705, Val Acc: 0.783505\n",
      "Epoch 21677 - Train Loss: 0.077839, Train Acc: 0.880769 | Val Loss: 0.109705, Val Acc: 0.783505\n",
      "Epoch 21678 - Train Loss: 0.077837, Train Acc: 0.880769 | Val Loss: 0.109704, Val Acc: 0.783505\n",
      "Epoch 21679 - Train Loss: 0.077835, Train Acc: 0.880769 | Val Loss: 0.109703, Val Acc: 0.783505\n",
      "Epoch 21680 - Train Loss: 0.077833, Train Acc: 0.880769 | Val Loss: 0.109703, Val Acc: 0.783505\n",
      "Epoch 21681 - Train Loss: 0.077831, Train Acc: 0.880769 | Val Loss: 0.109702, Val Acc: 0.783505\n",
      "Epoch 21682 - Train Loss: 0.077829, Train Acc: 0.880769 | Val Loss: 0.109701, Val Acc: 0.783505\n",
      "Epoch 21683 - Train Loss: 0.077827, Train Acc: 0.880769 | Val Loss: 0.109701, Val Acc: 0.783505\n",
      "Epoch 21684 - Train Loss: 0.077825, Train Acc: 0.880769 | Val Loss: 0.109700, Val Acc: 0.783505\n",
      "Epoch 21685 - Train Loss: 0.077823, Train Acc: 0.880769 | Val Loss: 0.109699, Val Acc: 0.783505\n",
      "Epoch 21686 - Train Loss: 0.077822, Train Acc: 0.880769 | Val Loss: 0.109699, Val Acc: 0.783505\n",
      "Epoch 21687 - Train Loss: 0.077820, Train Acc: 0.880769 | Val Loss: 0.109698, Val Acc: 0.783505\n",
      "Epoch 21688 - Train Loss: 0.077818, Train Acc: 0.880769 | Val Loss: 0.109697, Val Acc: 0.783505\n",
      "Epoch 21689 - Train Loss: 0.077816, Train Acc: 0.880769 | Val Loss: 0.109697, Val Acc: 0.783505\n",
      "Epoch 21690 - Train Loss: 0.077814, Train Acc: 0.880769 | Val Loss: 0.109696, Val Acc: 0.783505\n",
      "Epoch 21691 - Train Loss: 0.077812, Train Acc: 0.880769 | Val Loss: 0.109695, Val Acc: 0.783505\n",
      "Epoch 21692 - Train Loss: 0.077810, Train Acc: 0.880769 | Val Loss: 0.109695, Val Acc: 0.783505\n",
      "Epoch 21693 - Train Loss: 0.077808, Train Acc: 0.880769 | Val Loss: 0.109694, Val Acc: 0.783505\n",
      "Epoch 21694 - Train Loss: 0.077806, Train Acc: 0.880769 | Val Loss: 0.109693, Val Acc: 0.783505\n",
      "Epoch 21695 - Train Loss: 0.077804, Train Acc: 0.880769 | Val Loss: 0.109693, Val Acc: 0.783505\n",
      "Epoch 21696 - Train Loss: 0.077802, Train Acc: 0.880769 | Val Loss: 0.109692, Val Acc: 0.783505\n",
      "Epoch 21697 - Train Loss: 0.077800, Train Acc: 0.880769 | Val Loss: 0.109691, Val Acc: 0.783505\n",
      "Epoch 21698 - Train Loss: 0.077798, Train Acc: 0.880769 | Val Loss: 0.109691, Val Acc: 0.783505\n",
      "Epoch 21699 - Train Loss: 0.077796, Train Acc: 0.880769 | Val Loss: 0.109690, Val Acc: 0.783505\n",
      "Epoch 21700 - Train Loss: 0.077794, Train Acc: 0.880769 | Val Loss: 0.109689, Val Acc: 0.783505\n",
      "Epoch 21701 - Train Loss: 0.077792, Train Acc: 0.880769 | Val Loss: 0.109689, Val Acc: 0.783505\n",
      "Epoch 21702 - Train Loss: 0.077790, Train Acc: 0.880769 | Val Loss: 0.109688, Val Acc: 0.783505\n",
      "Epoch 21703 - Train Loss: 0.077788, Train Acc: 0.880769 | Val Loss: 0.109687, Val Acc: 0.783505\n",
      "Epoch 21704 - Train Loss: 0.077786, Train Acc: 0.880769 | Val Loss: 0.109687, Val Acc: 0.783505\n",
      "Epoch 21705 - Train Loss: 0.077784, Train Acc: 0.880769 | Val Loss: 0.109686, Val Acc: 0.783505\n",
      "Epoch 21706 - Train Loss: 0.077783, Train Acc: 0.880769 | Val Loss: 0.109685, Val Acc: 0.783505\n",
      "Epoch 21707 - Train Loss: 0.077781, Train Acc: 0.880769 | Val Loss: 0.109685, Val Acc: 0.783505\n",
      "Epoch 21708 - Train Loss: 0.077779, Train Acc: 0.880769 | Val Loss: 0.109684, Val Acc: 0.783505\n",
      "Epoch 21709 - Train Loss: 0.077777, Train Acc: 0.880769 | Val Loss: 0.109683, Val Acc: 0.783505\n",
      "Epoch 21710 - Train Loss: 0.077775, Train Acc: 0.880769 | Val Loss: 0.109683, Val Acc: 0.783505\n",
      "Epoch 21711 - Train Loss: 0.077773, Train Acc: 0.880769 | Val Loss: 0.109682, Val Acc: 0.783505\n",
      "Epoch 21712 - Train Loss: 0.077771, Train Acc: 0.880769 | Val Loss: 0.109681, Val Acc: 0.783505\n",
      "Epoch 21713 - Train Loss: 0.077769, Train Acc: 0.880769 | Val Loss: 0.109681, Val Acc: 0.783505\n",
      "Epoch 21714 - Train Loss: 0.077767, Train Acc: 0.880769 | Val Loss: 0.109680, Val Acc: 0.783505\n",
      "Epoch 21715 - Train Loss: 0.077765, Train Acc: 0.880769 | Val Loss: 0.109679, Val Acc: 0.783505\n",
      "Epoch 21716 - Train Loss: 0.077763, Train Acc: 0.880769 | Val Loss: 0.109679, Val Acc: 0.783505\n",
      "Epoch 21717 - Train Loss: 0.077761, Train Acc: 0.880769 | Val Loss: 0.109678, Val Acc: 0.783505\n",
      "Epoch 21718 - Train Loss: 0.077759, Train Acc: 0.880769 | Val Loss: 0.109677, Val Acc: 0.783505\n",
      "Epoch 21719 - Train Loss: 0.077757, Train Acc: 0.880769 | Val Loss: 0.109677, Val Acc: 0.783505\n",
      "Epoch 21720 - Train Loss: 0.077755, Train Acc: 0.880769 | Val Loss: 0.109676, Val Acc: 0.783505\n",
      "Epoch 21721 - Train Loss: 0.077753, Train Acc: 0.880769 | Val Loss: 0.109675, Val Acc: 0.783505\n",
      "Epoch 21722 - Train Loss: 0.077751, Train Acc: 0.880769 | Val Loss: 0.109675, Val Acc: 0.783505\n",
      "Epoch 21723 - Train Loss: 0.077749, Train Acc: 0.880769 | Val Loss: 0.109674, Val Acc: 0.783505\n",
      "Epoch 21724 - Train Loss: 0.077747, Train Acc: 0.880769 | Val Loss: 0.109673, Val Acc: 0.783505\n",
      "Epoch 21725 - Train Loss: 0.077746, Train Acc: 0.880769 | Val Loss: 0.109673, Val Acc: 0.783505\n",
      "Epoch 21726 - Train Loss: 0.077744, Train Acc: 0.880769 | Val Loss: 0.109672, Val Acc: 0.783505\n",
      "Epoch 21727 - Train Loss: 0.077742, Train Acc: 0.880769 | Val Loss: 0.109671, Val Acc: 0.783505\n",
      "Epoch 21728 - Train Loss: 0.077740, Train Acc: 0.880769 | Val Loss: 0.109671, Val Acc: 0.783505\n",
      "Epoch 21729 - Train Loss: 0.077738, Train Acc: 0.880769 | Val Loss: 0.109670, Val Acc: 0.783505\n",
      "Epoch 21730 - Train Loss: 0.077736, Train Acc: 0.880769 | Val Loss: 0.109669, Val Acc: 0.783505\n",
      "Epoch 21731 - Train Loss: 0.077734, Train Acc: 0.880769 | Val Loss: 0.109669, Val Acc: 0.783505\n",
      "Epoch 21732 - Train Loss: 0.077732, Train Acc: 0.880769 | Val Loss: 0.109668, Val Acc: 0.783505\n",
      "Epoch 21733 - Train Loss: 0.077730, Train Acc: 0.880769 | Val Loss: 0.109667, Val Acc: 0.783505\n",
      "Epoch 21734 - Train Loss: 0.077728, Train Acc: 0.880769 | Val Loss: 0.109667, Val Acc: 0.783505\n",
      "Epoch 21735 - Train Loss: 0.077726, Train Acc: 0.880769 | Val Loss: 0.109666, Val Acc: 0.783505\n",
      "Epoch 21736 - Train Loss: 0.077724, Train Acc: 0.880769 | Val Loss: 0.109665, Val Acc: 0.783505\n",
      "Epoch 21737 - Train Loss: 0.077722, Train Acc: 0.880769 | Val Loss: 0.109665, Val Acc: 0.783505\n",
      "Epoch 21738 - Train Loss: 0.077720, Train Acc: 0.880769 | Val Loss: 0.109664, Val Acc: 0.783505\n",
      "Epoch 21739 - Train Loss: 0.077718, Train Acc: 0.880769 | Val Loss: 0.109663, Val Acc: 0.783505\n",
      "Epoch 21740 - Train Loss: 0.077716, Train Acc: 0.880769 | Val Loss: 0.109663, Val Acc: 0.783505\n",
      "Epoch 21741 - Train Loss: 0.077714, Train Acc: 0.880769 | Val Loss: 0.109662, Val Acc: 0.783505\n",
      "Epoch 21742 - Train Loss: 0.077712, Train Acc: 0.880769 | Val Loss: 0.109661, Val Acc: 0.783505\n",
      "Epoch 21743 - Train Loss: 0.077711, Train Acc: 0.880769 | Val Loss: 0.109661, Val Acc: 0.783505\n",
      "Epoch 21744 - Train Loss: 0.077709, Train Acc: 0.880769 | Val Loss: 0.109660, Val Acc: 0.783505\n",
      "Epoch 21745 - Train Loss: 0.077707, Train Acc: 0.880769 | Val Loss: 0.109659, Val Acc: 0.783505\n",
      "Epoch 21746 - Train Loss: 0.077705, Train Acc: 0.880769 | Val Loss: 0.109659, Val Acc: 0.783505\n",
      "Epoch 21747 - Train Loss: 0.077703, Train Acc: 0.880769 | Val Loss: 0.109658, Val Acc: 0.783505\n",
      "Epoch 21748 - Train Loss: 0.077701, Train Acc: 0.880769 | Val Loss: 0.109657, Val Acc: 0.783505\n",
      "Epoch 21749 - Train Loss: 0.077699, Train Acc: 0.880769 | Val Loss: 0.109657, Val Acc: 0.783505\n",
      "Epoch 21750 - Train Loss: 0.077697, Train Acc: 0.880769 | Val Loss: 0.109656, Val Acc: 0.783505\n",
      "Epoch 21751 - Train Loss: 0.077695, Train Acc: 0.880769 | Val Loss: 0.109655, Val Acc: 0.783505\n",
      "Epoch 21752 - Train Loss: 0.077693, Train Acc: 0.880769 | Val Loss: 0.109655, Val Acc: 0.783505\n",
      "Epoch 21753 - Train Loss: 0.077691, Train Acc: 0.880769 | Val Loss: 0.109654, Val Acc: 0.783505\n",
      "Epoch 21754 - Train Loss: 0.077689, Train Acc: 0.880769 | Val Loss: 0.109653, Val Acc: 0.783505\n",
      "Epoch 21755 - Train Loss: 0.077687, Train Acc: 0.880769 | Val Loss: 0.109653, Val Acc: 0.783505\n",
      "Epoch 21756 - Train Loss: 0.077685, Train Acc: 0.880769 | Val Loss: 0.109652, Val Acc: 0.783505\n",
      "Epoch 21757 - Train Loss: 0.077683, Train Acc: 0.880769 | Val Loss: 0.109651, Val Acc: 0.783505\n",
      "Epoch 21758 - Train Loss: 0.077681, Train Acc: 0.880769 | Val Loss: 0.109651, Val Acc: 0.783505\n",
      "Epoch 21759 - Train Loss: 0.077679, Train Acc: 0.880769 | Val Loss: 0.109650, Val Acc: 0.783505\n",
      "Epoch 21760 - Train Loss: 0.077678, Train Acc: 0.880769 | Val Loss: 0.109649, Val Acc: 0.783505\n",
      "Epoch 21761 - Train Loss: 0.077676, Train Acc: 0.880769 | Val Loss: 0.109649, Val Acc: 0.783505\n",
      "Epoch 21762 - Train Loss: 0.077674, Train Acc: 0.880769 | Val Loss: 0.109648, Val Acc: 0.783505\n",
      "Epoch 21763 - Train Loss: 0.077672, Train Acc: 0.880769 | Val Loss: 0.109647, Val Acc: 0.783505\n",
      "Epoch 21764 - Train Loss: 0.077670, Train Acc: 0.880769 | Val Loss: 0.109647, Val Acc: 0.783505\n",
      "Epoch 21765 - Train Loss: 0.077668, Train Acc: 0.880769 | Val Loss: 0.109646, Val Acc: 0.783505\n",
      "Epoch 21766 - Train Loss: 0.077666, Train Acc: 0.880769 | Val Loss: 0.109646, Val Acc: 0.783505\n",
      "Epoch 21767 - Train Loss: 0.077664, Train Acc: 0.880769 | Val Loss: 0.109645, Val Acc: 0.783505\n",
      "Epoch 21768 - Train Loss: 0.077662, Train Acc: 0.880769 | Val Loss: 0.109644, Val Acc: 0.783505\n",
      "Epoch 21769 - Train Loss: 0.077660, Train Acc: 0.880769 | Val Loss: 0.109644, Val Acc: 0.783505\n",
      "Epoch 21770 - Train Loss: 0.077658, Train Acc: 0.880769 | Val Loss: 0.109643, Val Acc: 0.783505\n",
      "Epoch 21771 - Train Loss: 0.077656, Train Acc: 0.880769 | Val Loss: 0.109642, Val Acc: 0.783505\n",
      "Epoch 21772 - Train Loss: 0.077654, Train Acc: 0.880769 | Val Loss: 0.109642, Val Acc: 0.783505\n",
      "Epoch 21773 - Train Loss: 0.077652, Train Acc: 0.880769 | Val Loss: 0.109641, Val Acc: 0.783505\n",
      "Epoch 21774 - Train Loss: 0.077650, Train Acc: 0.880769 | Val Loss: 0.109640, Val Acc: 0.783505\n",
      "Epoch 21775 - Train Loss: 0.077648, Train Acc: 0.880769 | Val Loss: 0.109640, Val Acc: 0.783505\n",
      "Epoch 21776 - Train Loss: 0.077647, Train Acc: 0.880769 | Val Loss: 0.109639, Val Acc: 0.783505\n",
      "Epoch 21777 - Train Loss: 0.077645, Train Acc: 0.880769 | Val Loss: 0.109638, Val Acc: 0.783505\n",
      "Epoch 21778 - Train Loss: 0.077643, Train Acc: 0.880769 | Val Loss: 0.109638, Val Acc: 0.783505\n",
      "Epoch 21779 - Train Loss: 0.077641, Train Acc: 0.880769 | Val Loss: 0.109637, Val Acc: 0.783505\n",
      "Epoch 21780 - Train Loss: 0.077639, Train Acc: 0.880769 | Val Loss: 0.109636, Val Acc: 0.783505\n",
      "Epoch 21781 - Train Loss: 0.077637, Train Acc: 0.880769 | Val Loss: 0.109636, Val Acc: 0.783505\n",
      "Epoch 21782 - Train Loss: 0.077635, Train Acc: 0.880769 | Val Loss: 0.109635, Val Acc: 0.783505\n",
      "Epoch 21783 - Train Loss: 0.077633, Train Acc: 0.880769 | Val Loss: 0.109634, Val Acc: 0.783505\n",
      "Epoch 21784 - Train Loss: 0.077631, Train Acc: 0.880769 | Val Loss: 0.109634, Val Acc: 0.783505\n",
      "Epoch 21785 - Train Loss: 0.077629, Train Acc: 0.880769 | Val Loss: 0.109633, Val Acc: 0.783505\n",
      "Epoch 21786 - Train Loss: 0.077627, Train Acc: 0.880769 | Val Loss: 0.109632, Val Acc: 0.783505\n",
      "Epoch 21787 - Train Loss: 0.077625, Train Acc: 0.880769 | Val Loss: 0.109632, Val Acc: 0.783505\n",
      "Epoch 21788 - Train Loss: 0.077623, Train Acc: 0.880769 | Val Loss: 0.109631, Val Acc: 0.783505\n",
      "Epoch 21789 - Train Loss: 0.077621, Train Acc: 0.880769 | Val Loss: 0.109630, Val Acc: 0.783505\n",
      "Epoch 21790 - Train Loss: 0.077619, Train Acc: 0.880769 | Val Loss: 0.109630, Val Acc: 0.783505\n",
      "Epoch 21791 - Train Loss: 0.077618, Train Acc: 0.880769 | Val Loss: 0.109629, Val Acc: 0.783505\n",
      "Epoch 21792 - Train Loss: 0.077616, Train Acc: 0.880769 | Val Loss: 0.109629, Val Acc: 0.783505\n",
      "Epoch 21793 - Train Loss: 0.077614, Train Acc: 0.880769 | Val Loss: 0.109628, Val Acc: 0.783505\n",
      "Epoch 21794 - Train Loss: 0.077612, Train Acc: 0.880769 | Val Loss: 0.109627, Val Acc: 0.783505\n",
      "Epoch 21795 - Train Loss: 0.077610, Train Acc: 0.880769 | Val Loss: 0.109627, Val Acc: 0.783505\n",
      "Epoch 21796 - Train Loss: 0.077608, Train Acc: 0.880769 | Val Loss: 0.109626, Val Acc: 0.783505\n",
      "Epoch 21797 - Train Loss: 0.077606, Train Acc: 0.880769 | Val Loss: 0.109625, Val Acc: 0.783505\n",
      "Epoch 21798 - Train Loss: 0.077604, Train Acc: 0.880769 | Val Loss: 0.109625, Val Acc: 0.783505\n",
      "Epoch 21799 - Train Loss: 0.077602, Train Acc: 0.880769 | Val Loss: 0.109624, Val Acc: 0.783505\n",
      "Epoch 21800 - Train Loss: 0.077600, Train Acc: 0.880769 | Val Loss: 0.109623, Val Acc: 0.783505\n",
      "Epoch 21801 - Train Loss: 0.077598, Train Acc: 0.880769 | Val Loss: 0.109623, Val Acc: 0.783505\n",
      "Epoch 21802 - Train Loss: 0.077596, Train Acc: 0.880769 | Val Loss: 0.109622, Val Acc: 0.783505\n",
      "Epoch 21803 - Train Loss: 0.077594, Train Acc: 0.880769 | Val Loss: 0.109621, Val Acc: 0.783505\n",
      "Epoch 21804 - Train Loss: 0.077592, Train Acc: 0.880769 | Val Loss: 0.109621, Val Acc: 0.783505\n",
      "Epoch 21805 - Train Loss: 0.077590, Train Acc: 0.880769 | Val Loss: 0.109620, Val Acc: 0.783505\n",
      "Epoch 21806 - Train Loss: 0.077589, Train Acc: 0.880769 | Val Loss: 0.109619, Val Acc: 0.783505\n",
      "Epoch 21807 - Train Loss: 0.077587, Train Acc: 0.880769 | Val Loss: 0.109619, Val Acc: 0.783505\n",
      "Epoch 21808 - Train Loss: 0.077585, Train Acc: 0.880769 | Val Loss: 0.109618, Val Acc: 0.783505\n",
      "Epoch 21809 - Train Loss: 0.077583, Train Acc: 0.880769 | Val Loss: 0.109617, Val Acc: 0.783505\n",
      "Epoch 21810 - Train Loss: 0.077581, Train Acc: 0.880769 | Val Loss: 0.109617, Val Acc: 0.783505\n",
      "Epoch 21811 - Train Loss: 0.077579, Train Acc: 0.880769 | Val Loss: 0.109616, Val Acc: 0.783505\n",
      "Epoch 21812 - Train Loss: 0.077577, Train Acc: 0.880769 | Val Loss: 0.109616, Val Acc: 0.783505\n",
      "Epoch 21813 - Train Loss: 0.077575, Train Acc: 0.880769 | Val Loss: 0.109615, Val Acc: 0.783505\n",
      "Epoch 21814 - Train Loss: 0.077573, Train Acc: 0.880769 | Val Loss: 0.109614, Val Acc: 0.783505\n",
      "Epoch 21815 - Train Loss: 0.077571, Train Acc: 0.880769 | Val Loss: 0.109614, Val Acc: 0.783505\n",
      "Epoch 21816 - Train Loss: 0.077569, Train Acc: 0.880769 | Val Loss: 0.109613, Val Acc: 0.783505\n",
      "Epoch 21817 - Train Loss: 0.077567, Train Acc: 0.880769 | Val Loss: 0.109612, Val Acc: 0.783505\n",
      "Epoch 21818 - Train Loss: 0.077565, Train Acc: 0.880769 | Val Loss: 0.109612, Val Acc: 0.783505\n",
      "Epoch 21819 - Train Loss: 0.077563, Train Acc: 0.880769 | Val Loss: 0.109611, Val Acc: 0.783505\n",
      "Epoch 21820 - Train Loss: 0.077561, Train Acc: 0.880769 | Val Loss: 0.109610, Val Acc: 0.783505\n",
      "Epoch 21821 - Train Loss: 0.077560, Train Acc: 0.880769 | Val Loss: 0.109610, Val Acc: 0.783505\n",
      "Epoch 21822 - Train Loss: 0.077558, Train Acc: 0.880769 | Val Loss: 0.109609, Val Acc: 0.783505\n",
      "Epoch 21823 - Train Loss: 0.077556, Train Acc: 0.880769 | Val Loss: 0.109608, Val Acc: 0.783505\n",
      "Epoch 21824 - Train Loss: 0.077554, Train Acc: 0.880769 | Val Loss: 0.109608, Val Acc: 0.783505\n",
      "Epoch 21825 - Train Loss: 0.077552, Train Acc: 0.880769 | Val Loss: 0.109607, Val Acc: 0.783505\n",
      "Epoch 21826 - Train Loss: 0.077550, Train Acc: 0.880769 | Val Loss: 0.109606, Val Acc: 0.783505\n",
      "Epoch 21827 - Train Loss: 0.077548, Train Acc: 0.880769 | Val Loss: 0.109606, Val Acc: 0.783505\n",
      "Epoch 21828 - Train Loss: 0.077546, Train Acc: 0.880769 | Val Loss: 0.109605, Val Acc: 0.783505\n",
      "Epoch 21829 - Train Loss: 0.077544, Train Acc: 0.880769 | Val Loss: 0.109604, Val Acc: 0.783505\n",
      "Epoch 21830 - Train Loss: 0.077542, Train Acc: 0.880769 | Val Loss: 0.109604, Val Acc: 0.783505\n",
      "Epoch 21831 - Train Loss: 0.077540, Train Acc: 0.880769 | Val Loss: 0.109603, Val Acc: 0.783505\n",
      "Epoch 21832 - Train Loss: 0.077538, Train Acc: 0.880769 | Val Loss: 0.109603, Val Acc: 0.783505\n",
      "Epoch 21833 - Train Loss: 0.077536, Train Acc: 0.880769 | Val Loss: 0.109602, Val Acc: 0.783505\n",
      "Epoch 21834 - Train Loss: 0.077535, Train Acc: 0.880769 | Val Loss: 0.109601, Val Acc: 0.783505\n",
      "Epoch 21835 - Train Loss: 0.077533, Train Acc: 0.880769 | Val Loss: 0.109601, Val Acc: 0.783505\n",
      "Epoch 21836 - Train Loss: 0.077531, Train Acc: 0.880769 | Val Loss: 0.109600, Val Acc: 0.783505\n",
      "Epoch 21837 - Train Loss: 0.077529, Train Acc: 0.880769 | Val Loss: 0.109599, Val Acc: 0.783505\n",
      "Epoch 21838 - Train Loss: 0.077527, Train Acc: 0.880769 | Val Loss: 0.109599, Val Acc: 0.783505\n",
      "Epoch 21839 - Train Loss: 0.077525, Train Acc: 0.880769 | Val Loss: 0.109598, Val Acc: 0.783505\n",
      "Epoch 21840 - Train Loss: 0.077523, Train Acc: 0.880769 | Val Loss: 0.109597, Val Acc: 0.783505\n",
      "Epoch 21841 - Train Loss: 0.077521, Train Acc: 0.880769 | Val Loss: 0.109597, Val Acc: 0.783505\n",
      "Epoch 21842 - Train Loss: 0.077519, Train Acc: 0.880769 | Val Loss: 0.109596, Val Acc: 0.783505\n",
      "Epoch 21843 - Train Loss: 0.077517, Train Acc: 0.880769 | Val Loss: 0.109595, Val Acc: 0.783505\n",
      "Epoch 21844 - Train Loss: 0.077515, Train Acc: 0.880769 | Val Loss: 0.109595, Val Acc: 0.783505\n",
      "Epoch 21845 - Train Loss: 0.077513, Train Acc: 0.880769 | Val Loss: 0.109594, Val Acc: 0.783505\n",
      "Epoch 21846 - Train Loss: 0.077511, Train Acc: 0.880769 | Val Loss: 0.109594, Val Acc: 0.783505\n",
      "Epoch 21847 - Train Loss: 0.077509, Train Acc: 0.880769 | Val Loss: 0.109593, Val Acc: 0.783505\n",
      "Epoch 21848 - Train Loss: 0.077508, Train Acc: 0.880769 | Val Loss: 0.109592, Val Acc: 0.783505\n",
      "Epoch 21849 - Train Loss: 0.077506, Train Acc: 0.880769 | Val Loss: 0.109592, Val Acc: 0.783505\n",
      "Epoch 21850 - Train Loss: 0.077504, Train Acc: 0.880769 | Val Loss: 0.109591, Val Acc: 0.783505\n",
      "Epoch 21851 - Train Loss: 0.077502, Train Acc: 0.880769 | Val Loss: 0.109590, Val Acc: 0.783505\n",
      "Epoch 21852 - Train Loss: 0.077500, Train Acc: 0.880769 | Val Loss: 0.109590, Val Acc: 0.783505\n",
      "Epoch 21853 - Train Loss: 0.077498, Train Acc: 0.880769 | Val Loss: 0.109589, Val Acc: 0.783505\n",
      "Epoch 21854 - Train Loss: 0.077496, Train Acc: 0.880769 | Val Loss: 0.109588, Val Acc: 0.783505\n",
      "Epoch 21855 - Train Loss: 0.077494, Train Acc: 0.880769 | Val Loss: 0.109588, Val Acc: 0.783505\n",
      "Epoch 21856 - Train Loss: 0.077492, Train Acc: 0.880769 | Val Loss: 0.109587, Val Acc: 0.783505\n",
      "Epoch 21857 - Train Loss: 0.077490, Train Acc: 0.880769 | Val Loss: 0.109586, Val Acc: 0.783505\n",
      "Epoch 21858 - Train Loss: 0.077488, Train Acc: 0.880769 | Val Loss: 0.109586, Val Acc: 0.783505\n",
      "Epoch 21859 - Train Loss: 0.077486, Train Acc: 0.880769 | Val Loss: 0.109585, Val Acc: 0.783505\n",
      "Epoch 21860 - Train Loss: 0.077484, Train Acc: 0.880769 | Val Loss: 0.109585, Val Acc: 0.783505\n",
      "Epoch 21861 - Train Loss: 0.077483, Train Acc: 0.880769 | Val Loss: 0.109584, Val Acc: 0.783505\n",
      "Epoch 21862 - Train Loss: 0.077481, Train Acc: 0.880769 | Val Loss: 0.109583, Val Acc: 0.783505\n",
      "Epoch 21863 - Train Loss: 0.077479, Train Acc: 0.880769 | Val Loss: 0.109583, Val Acc: 0.783505\n",
      "Epoch 21864 - Train Loss: 0.077477, Train Acc: 0.880769 | Val Loss: 0.109582, Val Acc: 0.783505\n",
      "Epoch 21865 - Train Loss: 0.077475, Train Acc: 0.880769 | Val Loss: 0.109581, Val Acc: 0.783505\n",
      "Epoch 21866 - Train Loss: 0.077473, Train Acc: 0.880769 | Val Loss: 0.109581, Val Acc: 0.783505\n",
      "Epoch 21867 - Train Loss: 0.077471, Train Acc: 0.880769 | Val Loss: 0.109580, Val Acc: 0.783505\n",
      "Epoch 21868 - Train Loss: 0.077469, Train Acc: 0.880769 | Val Loss: 0.109579, Val Acc: 0.783505\n",
      "Epoch 21869 - Train Loss: 0.077467, Train Acc: 0.880769 | Val Loss: 0.109579, Val Acc: 0.783505\n",
      "Epoch 21870 - Train Loss: 0.077465, Train Acc: 0.880769 | Val Loss: 0.109578, Val Acc: 0.783505\n",
      "Epoch 21871 - Train Loss: 0.077463, Train Acc: 0.882051 | Val Loss: 0.109577, Val Acc: 0.783505\n",
      "Epoch 21872 - Train Loss: 0.077461, Train Acc: 0.882051 | Val Loss: 0.109577, Val Acc: 0.783505\n",
      "Epoch 21873 - Train Loss: 0.077460, Train Acc: 0.882051 | Val Loss: 0.109576, Val Acc: 0.783505\n",
      "Epoch 21874 - Train Loss: 0.077458, Train Acc: 0.882051 | Val Loss: 0.109576, Val Acc: 0.783505\n",
      "Epoch 21875 - Train Loss: 0.077456, Train Acc: 0.882051 | Val Loss: 0.109575, Val Acc: 0.783505\n",
      "Epoch 21876 - Train Loss: 0.077454, Train Acc: 0.882051 | Val Loss: 0.109574, Val Acc: 0.783505\n",
      "Epoch 21877 - Train Loss: 0.077452, Train Acc: 0.882051 | Val Loss: 0.109574, Val Acc: 0.783505\n",
      "Epoch 21878 - Train Loss: 0.077450, Train Acc: 0.882051 | Val Loss: 0.109573, Val Acc: 0.783505\n",
      "Epoch 21879 - Train Loss: 0.077448, Train Acc: 0.882051 | Val Loss: 0.109572, Val Acc: 0.783505\n",
      "Epoch 21880 - Train Loss: 0.077446, Train Acc: 0.882051 | Val Loss: 0.109572, Val Acc: 0.783505\n",
      "Epoch 21881 - Train Loss: 0.077444, Train Acc: 0.883333 | Val Loss: 0.109571, Val Acc: 0.783505\n",
      "Epoch 21882 - Train Loss: 0.077442, Train Acc: 0.883333 | Val Loss: 0.109570, Val Acc: 0.783505\n",
      "Epoch 21883 - Train Loss: 0.077440, Train Acc: 0.883333 | Val Loss: 0.109570, Val Acc: 0.783505\n",
      "Epoch 21884 - Train Loss: 0.077438, Train Acc: 0.883333 | Val Loss: 0.109569, Val Acc: 0.783505\n",
      "Epoch 21885 - Train Loss: 0.077436, Train Acc: 0.883333 | Val Loss: 0.109569, Val Acc: 0.783505\n",
      "Epoch 21886 - Train Loss: 0.077435, Train Acc: 0.883333 | Val Loss: 0.109568, Val Acc: 0.783505\n",
      "Epoch 21887 - Train Loss: 0.077433, Train Acc: 0.883333 | Val Loss: 0.109567, Val Acc: 0.783505\n",
      "Epoch 21888 - Train Loss: 0.077431, Train Acc: 0.883333 | Val Loss: 0.109567, Val Acc: 0.783505\n",
      "Epoch 21889 - Train Loss: 0.077429, Train Acc: 0.883333 | Val Loss: 0.109566, Val Acc: 0.783505\n",
      "Epoch 21890 - Train Loss: 0.077427, Train Acc: 0.883333 | Val Loss: 0.109565, Val Acc: 0.783505\n",
      "Epoch 21891 - Train Loss: 0.077425, Train Acc: 0.883333 | Val Loss: 0.109565, Val Acc: 0.783505\n",
      "Epoch 21892 - Train Loss: 0.077423, Train Acc: 0.883333 | Val Loss: 0.109564, Val Acc: 0.783505\n",
      "Epoch 21893 - Train Loss: 0.077421, Train Acc: 0.883333 | Val Loss: 0.109563, Val Acc: 0.783505\n",
      "Epoch 21894 - Train Loss: 0.077419, Train Acc: 0.883333 | Val Loss: 0.109563, Val Acc: 0.783505\n",
      "Epoch 21895 - Train Loss: 0.077417, Train Acc: 0.883333 | Val Loss: 0.109562, Val Acc: 0.783505\n",
      "Epoch 21896 - Train Loss: 0.077415, Train Acc: 0.883333 | Val Loss: 0.109562, Val Acc: 0.783505\n",
      "Epoch 21897 - Train Loss: 0.077414, Train Acc: 0.883333 | Val Loss: 0.109561, Val Acc: 0.783505\n",
      "Epoch 21898 - Train Loss: 0.077412, Train Acc: 0.883333 | Val Loss: 0.109560, Val Acc: 0.783505\n",
      "Epoch 21899 - Train Loss: 0.077410, Train Acc: 0.883333 | Val Loss: 0.109560, Val Acc: 0.783505\n",
      "Epoch 21900 - Train Loss: 0.077408, Train Acc: 0.883333 | Val Loss: 0.109559, Val Acc: 0.783505\n",
      "Epoch 21901 - Train Loss: 0.077406, Train Acc: 0.883333 | Val Loss: 0.109558, Val Acc: 0.783505\n",
      "Epoch 21902 - Train Loss: 0.077404, Train Acc: 0.883333 | Val Loss: 0.109558, Val Acc: 0.783505\n",
      "Epoch 21903 - Train Loss: 0.077402, Train Acc: 0.883333 | Val Loss: 0.109557, Val Acc: 0.783505\n",
      "Epoch 21904 - Train Loss: 0.077400, Train Acc: 0.884615 | Val Loss: 0.109556, Val Acc: 0.783505\n",
      "Epoch 21905 - Train Loss: 0.077398, Train Acc: 0.884615 | Val Loss: 0.109556, Val Acc: 0.783505\n",
      "Epoch 21906 - Train Loss: 0.077396, Train Acc: 0.884615 | Val Loss: 0.109555, Val Acc: 0.783505\n",
      "Epoch 21907 - Train Loss: 0.077394, Train Acc: 0.884615 | Val Loss: 0.109555, Val Acc: 0.783505\n",
      "Epoch 21908 - Train Loss: 0.077392, Train Acc: 0.884615 | Val Loss: 0.109554, Val Acc: 0.783505\n",
      "Epoch 21909 - Train Loss: 0.077391, Train Acc: 0.884615 | Val Loss: 0.109553, Val Acc: 0.783505\n",
      "Epoch 21910 - Train Loss: 0.077389, Train Acc: 0.884615 | Val Loss: 0.109553, Val Acc: 0.783505\n",
      "Epoch 21911 - Train Loss: 0.077387, Train Acc: 0.884615 | Val Loss: 0.109552, Val Acc: 0.783505\n",
      "Epoch 21912 - Train Loss: 0.077385, Train Acc: 0.884615 | Val Loss: 0.109551, Val Acc: 0.783505\n",
      "Epoch 21913 - Train Loss: 0.077383, Train Acc: 0.883333 | Val Loss: 0.109551, Val Acc: 0.783505\n",
      "Epoch 21914 - Train Loss: 0.077381, Train Acc: 0.883333 | Val Loss: 0.109550, Val Acc: 0.783505\n",
      "Epoch 21915 - Train Loss: 0.077379, Train Acc: 0.883333 | Val Loss: 0.109550, Val Acc: 0.783505\n",
      "Epoch 21916 - Train Loss: 0.077377, Train Acc: 0.883333 | Val Loss: 0.109549, Val Acc: 0.783505\n",
      "Epoch 21917 - Train Loss: 0.077375, Train Acc: 0.883333 | Val Loss: 0.109548, Val Acc: 0.783505\n",
      "Epoch 21918 - Train Loss: 0.077373, Train Acc: 0.883333 | Val Loss: 0.109548, Val Acc: 0.783505\n",
      "Epoch 21919 - Train Loss: 0.077371, Train Acc: 0.883333 | Val Loss: 0.109547, Val Acc: 0.783505\n",
      "Epoch 21920 - Train Loss: 0.077369, Train Acc: 0.883333 | Val Loss: 0.109546, Val Acc: 0.783505\n",
      "Epoch 21921 - Train Loss: 0.077368, Train Acc: 0.883333 | Val Loss: 0.109546, Val Acc: 0.783505\n",
      "Epoch 21922 - Train Loss: 0.077366, Train Acc: 0.883333 | Val Loss: 0.109545, Val Acc: 0.783505\n",
      "Epoch 21923 - Train Loss: 0.077364, Train Acc: 0.883333 | Val Loss: 0.109544, Val Acc: 0.783505\n",
      "Epoch 21924 - Train Loss: 0.077362, Train Acc: 0.883333 | Val Loss: 0.109544, Val Acc: 0.783505\n",
      "Epoch 21925 - Train Loss: 0.077360, Train Acc: 0.883333 | Val Loss: 0.109543, Val Acc: 0.783505\n",
      "Epoch 21926 - Train Loss: 0.077358, Train Acc: 0.883333 | Val Loss: 0.109543, Val Acc: 0.783505\n",
      "Epoch 21927 - Train Loss: 0.077356, Train Acc: 0.883333 | Val Loss: 0.109542, Val Acc: 0.783505\n",
      "Epoch 21928 - Train Loss: 0.077354, Train Acc: 0.883333 | Val Loss: 0.109541, Val Acc: 0.783505\n",
      "Epoch 21929 - Train Loss: 0.077352, Train Acc: 0.883333 | Val Loss: 0.109541, Val Acc: 0.783505\n",
      "Epoch 21930 - Train Loss: 0.077350, Train Acc: 0.883333 | Val Loss: 0.109540, Val Acc: 0.783505\n",
      "Epoch 21931 - Train Loss: 0.077348, Train Acc: 0.883333 | Val Loss: 0.109539, Val Acc: 0.783505\n",
      "Epoch 21932 - Train Loss: 0.077347, Train Acc: 0.883333 | Val Loss: 0.109539, Val Acc: 0.783505\n",
      "Epoch 21933 - Train Loss: 0.077345, Train Acc: 0.883333 | Val Loss: 0.109538, Val Acc: 0.783505\n",
      "Epoch 21934 - Train Loss: 0.077343, Train Acc: 0.883333 | Val Loss: 0.109538, Val Acc: 0.783505\n",
      "Epoch 21935 - Train Loss: 0.077341, Train Acc: 0.883333 | Val Loss: 0.109537, Val Acc: 0.783505\n",
      "Epoch 21936 - Train Loss: 0.077339, Train Acc: 0.883333 | Val Loss: 0.109536, Val Acc: 0.783505\n",
      "Epoch 21937 - Train Loss: 0.077337, Train Acc: 0.883333 | Val Loss: 0.109536, Val Acc: 0.783505\n",
      "Epoch 21938 - Train Loss: 0.077335, Train Acc: 0.883333 | Val Loss: 0.109535, Val Acc: 0.783505\n",
      "Epoch 21939 - Train Loss: 0.077333, Train Acc: 0.883333 | Val Loss: 0.109534, Val Acc: 0.783505\n",
      "Epoch 21940 - Train Loss: 0.077331, Train Acc: 0.883333 | Val Loss: 0.109534, Val Acc: 0.783505\n",
      "Epoch 21941 - Train Loss: 0.077329, Train Acc: 0.883333 | Val Loss: 0.109533, Val Acc: 0.783505\n",
      "Epoch 21942 - Train Loss: 0.077327, Train Acc: 0.883333 | Val Loss: 0.109532, Val Acc: 0.783505\n",
      "Epoch 21943 - Train Loss: 0.077326, Train Acc: 0.883333 | Val Loss: 0.109532, Val Acc: 0.783505\n",
      "Epoch 21944 - Train Loss: 0.077324, Train Acc: 0.883333 | Val Loss: 0.109531, Val Acc: 0.783505\n",
      "Epoch 21945 - Train Loss: 0.077322, Train Acc: 0.883333 | Val Loss: 0.109531, Val Acc: 0.783505\n",
      "Epoch 21946 - Train Loss: 0.077320, Train Acc: 0.883333 | Val Loss: 0.109530, Val Acc: 0.783505\n",
      "Epoch 21947 - Train Loss: 0.077318, Train Acc: 0.883333 | Val Loss: 0.109529, Val Acc: 0.783505\n",
      "Epoch 21948 - Train Loss: 0.077316, Train Acc: 0.883333 | Val Loss: 0.109529, Val Acc: 0.783505\n",
      "Epoch 21949 - Train Loss: 0.077314, Train Acc: 0.883333 | Val Loss: 0.109528, Val Acc: 0.783505\n",
      "Epoch 21950 - Train Loss: 0.077312, Train Acc: 0.883333 | Val Loss: 0.109527, Val Acc: 0.783505\n",
      "Epoch 21951 - Train Loss: 0.077310, Train Acc: 0.883333 | Val Loss: 0.109527, Val Acc: 0.783505\n",
      "Epoch 21952 - Train Loss: 0.077308, Train Acc: 0.883333 | Val Loss: 0.109526, Val Acc: 0.783505\n",
      "Epoch 21953 - Train Loss: 0.077307, Train Acc: 0.883333 | Val Loss: 0.109526, Val Acc: 0.783505\n",
      "Epoch 21954 - Train Loss: 0.077305, Train Acc: 0.883333 | Val Loss: 0.109525, Val Acc: 0.783505\n",
      "Epoch 21955 - Train Loss: 0.077303, Train Acc: 0.883333 | Val Loss: 0.109524, Val Acc: 0.783505\n",
      "Epoch 21956 - Train Loss: 0.077301, Train Acc: 0.883333 | Val Loss: 0.109524, Val Acc: 0.783505\n",
      "Epoch 21957 - Train Loss: 0.077299, Train Acc: 0.883333 | Val Loss: 0.109523, Val Acc: 0.783505\n",
      "Epoch 21958 - Train Loss: 0.077297, Train Acc: 0.883333 | Val Loss: 0.109522, Val Acc: 0.783505\n",
      "Epoch 21959 - Train Loss: 0.077295, Train Acc: 0.883333 | Val Loss: 0.109522, Val Acc: 0.783505\n",
      "Epoch 21960 - Train Loss: 0.077293, Train Acc: 0.883333 | Val Loss: 0.109521, Val Acc: 0.783505\n",
      "Epoch 21961 - Train Loss: 0.077291, Train Acc: 0.883333 | Val Loss: 0.109521, Val Acc: 0.783505\n",
      "Epoch 21962 - Train Loss: 0.077289, Train Acc: 0.883333 | Val Loss: 0.109520, Val Acc: 0.783505\n",
      "Epoch 21963 - Train Loss: 0.077287, Train Acc: 0.883333 | Val Loss: 0.109519, Val Acc: 0.783505\n",
      "Epoch 21964 - Train Loss: 0.077286, Train Acc: 0.883333 | Val Loss: 0.109519, Val Acc: 0.783505\n",
      "Epoch 21965 - Train Loss: 0.077284, Train Acc: 0.883333 | Val Loss: 0.109518, Val Acc: 0.783505\n",
      "Epoch 21966 - Train Loss: 0.077282, Train Acc: 0.883333 | Val Loss: 0.109517, Val Acc: 0.783505\n",
      "Epoch 21967 - Train Loss: 0.077280, Train Acc: 0.883333 | Val Loss: 0.109517, Val Acc: 0.783505\n",
      "Epoch 21968 - Train Loss: 0.077278, Train Acc: 0.883333 | Val Loss: 0.109516, Val Acc: 0.783505\n",
      "Epoch 21969 - Train Loss: 0.077276, Train Acc: 0.883333 | Val Loss: 0.109516, Val Acc: 0.783505\n",
      "Epoch 21970 - Train Loss: 0.077274, Train Acc: 0.883333 | Val Loss: 0.109515, Val Acc: 0.783505\n",
      "Epoch 21971 - Train Loss: 0.077272, Train Acc: 0.883333 | Val Loss: 0.109514, Val Acc: 0.783505\n",
      "Epoch 21972 - Train Loss: 0.077270, Train Acc: 0.883333 | Val Loss: 0.109514, Val Acc: 0.783505\n",
      "Epoch 21973 - Train Loss: 0.077268, Train Acc: 0.883333 | Val Loss: 0.109513, Val Acc: 0.783505\n",
      "Epoch 21974 - Train Loss: 0.077267, Train Acc: 0.883333 | Val Loss: 0.109512, Val Acc: 0.783505\n",
      "Epoch 21975 - Train Loss: 0.077265, Train Acc: 0.883333 | Val Loss: 0.109512, Val Acc: 0.783505\n",
      "Epoch 21976 - Train Loss: 0.077263, Train Acc: 0.883333 | Val Loss: 0.109511, Val Acc: 0.783505\n",
      "Epoch 21977 - Train Loss: 0.077261, Train Acc: 0.883333 | Val Loss: 0.109511, Val Acc: 0.783505\n",
      "Epoch 21978 - Train Loss: 0.077259, Train Acc: 0.883333 | Val Loss: 0.109510, Val Acc: 0.783505\n",
      "Epoch 21979 - Train Loss: 0.077257, Train Acc: 0.883333 | Val Loss: 0.109509, Val Acc: 0.783505\n",
      "Epoch 21980 - Train Loss: 0.077255, Train Acc: 0.883333 | Val Loss: 0.109509, Val Acc: 0.783505\n",
      "Epoch 21981 - Train Loss: 0.077253, Train Acc: 0.883333 | Val Loss: 0.109508, Val Acc: 0.783505\n",
      "Epoch 21982 - Train Loss: 0.077251, Train Acc: 0.883333 | Val Loss: 0.109508, Val Acc: 0.783505\n",
      "Epoch 21983 - Train Loss: 0.077249, Train Acc: 0.883333 | Val Loss: 0.109507, Val Acc: 0.783505\n",
      "Epoch 21984 - Train Loss: 0.077248, Train Acc: 0.883333 | Val Loss: 0.109506, Val Acc: 0.783505\n",
      "Epoch 21985 - Train Loss: 0.077246, Train Acc: 0.883333 | Val Loss: 0.109506, Val Acc: 0.783505\n",
      "Epoch 21986 - Train Loss: 0.077244, Train Acc: 0.883333 | Val Loss: 0.109505, Val Acc: 0.783505\n",
      "Epoch 21987 - Train Loss: 0.077242, Train Acc: 0.883333 | Val Loss: 0.109504, Val Acc: 0.783505\n",
      "Epoch 21988 - Train Loss: 0.077240, Train Acc: 0.883333 | Val Loss: 0.109504, Val Acc: 0.783505\n",
      "Epoch 21989 - Train Loss: 0.077238, Train Acc: 0.883333 | Val Loss: 0.109503, Val Acc: 0.783505\n",
      "Epoch 21990 - Train Loss: 0.077236, Train Acc: 0.883333 | Val Loss: 0.109503, Val Acc: 0.783505\n",
      "Epoch 21991 - Train Loss: 0.077234, Train Acc: 0.883333 | Val Loss: 0.109502, Val Acc: 0.783505\n",
      "Epoch 21992 - Train Loss: 0.077232, Train Acc: 0.883333 | Val Loss: 0.109501, Val Acc: 0.783505\n",
      "Epoch 21993 - Train Loss: 0.077230, Train Acc: 0.883333 | Val Loss: 0.109501, Val Acc: 0.783505\n",
      "Epoch 21994 - Train Loss: 0.077229, Train Acc: 0.883333 | Val Loss: 0.109500, Val Acc: 0.783505\n",
      "Epoch 21995 - Train Loss: 0.077227, Train Acc: 0.883333 | Val Loss: 0.109499, Val Acc: 0.783505\n",
      "Epoch 21996 - Train Loss: 0.077225, Train Acc: 0.883333 | Val Loss: 0.109499, Val Acc: 0.783505\n",
      "Epoch 21997 - Train Loss: 0.077223, Train Acc: 0.883333 | Val Loss: 0.109498, Val Acc: 0.783505\n",
      "Epoch 21998 - Train Loss: 0.077221, Train Acc: 0.883333 | Val Loss: 0.109498, Val Acc: 0.783505\n",
      "Epoch 21999 - Train Loss: 0.077219, Train Acc: 0.883333 | Val Loss: 0.109497, Val Acc: 0.783505\n",
      "Epoch 22000 - Train Loss: 0.077217, Train Acc: 0.883333 | Val Loss: 0.109496, Val Acc: 0.783505\n",
      "Epoch 22001 - Train Loss: 0.077215, Train Acc: 0.883333 | Val Loss: 0.109496, Val Acc: 0.783505\n",
      "Epoch 22002 - Train Loss: 0.077213, Train Acc: 0.883333 | Val Loss: 0.109495, Val Acc: 0.783505\n",
      "Epoch 22003 - Train Loss: 0.077211, Train Acc: 0.883333 | Val Loss: 0.109494, Val Acc: 0.783505\n",
      "Epoch 22004 - Train Loss: 0.077210, Train Acc: 0.883333 | Val Loss: 0.109494, Val Acc: 0.783505\n",
      "Epoch 22005 - Train Loss: 0.077208, Train Acc: 0.883333 | Val Loss: 0.109493, Val Acc: 0.783505\n",
      "Epoch 22006 - Train Loss: 0.077206, Train Acc: 0.883333 | Val Loss: 0.109493, Val Acc: 0.783505\n",
      "Epoch 22007 - Train Loss: 0.077204, Train Acc: 0.883333 | Val Loss: 0.109492, Val Acc: 0.783505\n",
      "Epoch 22008 - Train Loss: 0.077202, Train Acc: 0.883333 | Val Loss: 0.109491, Val Acc: 0.783505\n",
      "Epoch 22009 - Train Loss: 0.077200, Train Acc: 0.883333 | Val Loss: 0.109491, Val Acc: 0.783505\n",
      "Epoch 22010 - Train Loss: 0.077198, Train Acc: 0.883333 | Val Loss: 0.109490, Val Acc: 0.783505\n",
      "Epoch 22011 - Train Loss: 0.077196, Train Acc: 0.883333 | Val Loss: 0.109490, Val Acc: 0.783505\n",
      "Epoch 22012 - Train Loss: 0.077194, Train Acc: 0.883333 | Val Loss: 0.109489, Val Acc: 0.783505\n",
      "Epoch 22013 - Train Loss: 0.077192, Train Acc: 0.883333 | Val Loss: 0.109488, Val Acc: 0.783505\n",
      "Epoch 22014 - Train Loss: 0.077191, Train Acc: 0.883333 | Val Loss: 0.109488, Val Acc: 0.783505\n",
      "Epoch 22015 - Train Loss: 0.077189, Train Acc: 0.883333 | Val Loss: 0.109487, Val Acc: 0.783505\n",
      "Epoch 22016 - Train Loss: 0.077187, Train Acc: 0.883333 | Val Loss: 0.109486, Val Acc: 0.783505\n",
      "Epoch 22017 - Train Loss: 0.077185, Train Acc: 0.883333 | Val Loss: 0.109486, Val Acc: 0.783505\n",
      "Epoch 22018 - Train Loss: 0.077183, Train Acc: 0.883333 | Val Loss: 0.109485, Val Acc: 0.783505\n",
      "Epoch 22019 - Train Loss: 0.077181, Train Acc: 0.883333 | Val Loss: 0.109485, Val Acc: 0.783505\n",
      "Epoch 22020 - Train Loss: 0.077179, Train Acc: 0.883333 | Val Loss: 0.109484, Val Acc: 0.783505\n",
      "Epoch 22021 - Train Loss: 0.077177, Train Acc: 0.883333 | Val Loss: 0.109483, Val Acc: 0.783505\n",
      "Epoch 22022 - Train Loss: 0.077175, Train Acc: 0.883333 | Val Loss: 0.109483, Val Acc: 0.783505\n",
      "Epoch 22023 - Train Loss: 0.077174, Train Acc: 0.883333 | Val Loss: 0.109482, Val Acc: 0.783505\n",
      "Epoch 22024 - Train Loss: 0.077172, Train Acc: 0.883333 | Val Loss: 0.109481, Val Acc: 0.783505\n",
      "Epoch 22025 - Train Loss: 0.077170, Train Acc: 0.883333 | Val Loss: 0.109481, Val Acc: 0.783505\n",
      "Epoch 22026 - Train Loss: 0.077168, Train Acc: 0.883333 | Val Loss: 0.109480, Val Acc: 0.783505\n",
      "Epoch 22027 - Train Loss: 0.077166, Train Acc: 0.883333 | Val Loss: 0.109480, Val Acc: 0.783505\n",
      "Epoch 22028 - Train Loss: 0.077164, Train Acc: 0.883333 | Val Loss: 0.109479, Val Acc: 0.783505\n",
      "Epoch 22029 - Train Loss: 0.077162, Train Acc: 0.883333 | Val Loss: 0.109478, Val Acc: 0.783505\n",
      "Epoch 22030 - Train Loss: 0.077160, Train Acc: 0.883333 | Val Loss: 0.109478, Val Acc: 0.783505\n",
      "Epoch 22031 - Train Loss: 0.077158, Train Acc: 0.883333 | Val Loss: 0.109477, Val Acc: 0.783505\n",
      "Epoch 22032 - Train Loss: 0.077156, Train Acc: 0.883333 | Val Loss: 0.109477, Val Acc: 0.783505\n",
      "Epoch 22033 - Train Loss: 0.077155, Train Acc: 0.883333 | Val Loss: 0.109476, Val Acc: 0.783505\n",
      "Epoch 22034 - Train Loss: 0.077153, Train Acc: 0.883333 | Val Loss: 0.109475, Val Acc: 0.783505\n",
      "Epoch 22035 - Train Loss: 0.077151, Train Acc: 0.883333 | Val Loss: 0.109475, Val Acc: 0.783505\n",
      "Epoch 22036 - Train Loss: 0.077149, Train Acc: 0.883333 | Val Loss: 0.109474, Val Acc: 0.783505\n",
      "Epoch 22037 - Train Loss: 0.077147, Train Acc: 0.883333 | Val Loss: 0.109474, Val Acc: 0.783505\n",
      "Epoch 22038 - Train Loss: 0.077145, Train Acc: 0.883333 | Val Loss: 0.109473, Val Acc: 0.783505\n",
      "Epoch 22039 - Train Loss: 0.077143, Train Acc: 0.883333 | Val Loss: 0.109472, Val Acc: 0.783505\n",
      "Epoch 22040 - Train Loss: 0.077141, Train Acc: 0.883333 | Val Loss: 0.109472, Val Acc: 0.783505\n",
      "Epoch 22041 - Train Loss: 0.077139, Train Acc: 0.883333 | Val Loss: 0.109471, Val Acc: 0.783505\n",
      "Epoch 22042 - Train Loss: 0.077138, Train Acc: 0.883333 | Val Loss: 0.109470, Val Acc: 0.783505\n",
      "Epoch 22043 - Train Loss: 0.077136, Train Acc: 0.883333 | Val Loss: 0.109470, Val Acc: 0.783505\n",
      "Epoch 22044 - Train Loss: 0.077134, Train Acc: 0.883333 | Val Loss: 0.109469, Val Acc: 0.783505\n",
      "Epoch 22045 - Train Loss: 0.077132, Train Acc: 0.883333 | Val Loss: 0.109469, Val Acc: 0.783505\n",
      "Epoch 22046 - Train Loss: 0.077130, Train Acc: 0.883333 | Val Loss: 0.109468, Val Acc: 0.783505\n",
      "Epoch 22047 - Train Loss: 0.077128, Train Acc: 0.883333 | Val Loss: 0.109467, Val Acc: 0.783505\n",
      "Epoch 22048 - Train Loss: 0.077126, Train Acc: 0.883333 | Val Loss: 0.109467, Val Acc: 0.783505\n",
      "Epoch 22049 - Train Loss: 0.077124, Train Acc: 0.883333 | Val Loss: 0.109466, Val Acc: 0.783505\n",
      "Epoch 22050 - Train Loss: 0.077122, Train Acc: 0.883333 | Val Loss: 0.109466, Val Acc: 0.783505\n",
      "Epoch 22051 - Train Loss: 0.077121, Train Acc: 0.883333 | Val Loss: 0.109465, Val Acc: 0.783505\n",
      "Epoch 22052 - Train Loss: 0.077119, Train Acc: 0.883333 | Val Loss: 0.109464, Val Acc: 0.783505\n",
      "Epoch 22053 - Train Loss: 0.077117, Train Acc: 0.883333 | Val Loss: 0.109464, Val Acc: 0.783505\n",
      "Epoch 22054 - Train Loss: 0.077115, Train Acc: 0.883333 | Val Loss: 0.109463, Val Acc: 0.783505\n",
      "Epoch 22055 - Train Loss: 0.077113, Train Acc: 0.883333 | Val Loss: 0.109462, Val Acc: 0.783505\n",
      "Epoch 22056 - Train Loss: 0.077111, Train Acc: 0.883333 | Val Loss: 0.109462, Val Acc: 0.783505\n",
      "Epoch 22057 - Train Loss: 0.077109, Train Acc: 0.883333 | Val Loss: 0.109461, Val Acc: 0.783505\n",
      "Epoch 22058 - Train Loss: 0.077107, Train Acc: 0.883333 | Val Loss: 0.109461, Val Acc: 0.783505\n",
      "Epoch 22059 - Train Loss: 0.077105, Train Acc: 0.883333 | Val Loss: 0.109460, Val Acc: 0.783505\n",
      "Epoch 22060 - Train Loss: 0.077104, Train Acc: 0.883333 | Val Loss: 0.109459, Val Acc: 0.783505\n",
      "Epoch 22061 - Train Loss: 0.077102, Train Acc: 0.883333 | Val Loss: 0.109459, Val Acc: 0.783505\n",
      "Epoch 22062 - Train Loss: 0.077100, Train Acc: 0.883333 | Val Loss: 0.109458, Val Acc: 0.783505\n",
      "Epoch 22063 - Train Loss: 0.077098, Train Acc: 0.883333 | Val Loss: 0.109458, Val Acc: 0.783505\n",
      "Epoch 22064 - Train Loss: 0.077096, Train Acc: 0.883333 | Val Loss: 0.109457, Val Acc: 0.783505\n",
      "Epoch 22065 - Train Loss: 0.077094, Train Acc: 0.883333 | Val Loss: 0.109456, Val Acc: 0.783505\n",
      "Epoch 22066 - Train Loss: 0.077092, Train Acc: 0.883333 | Val Loss: 0.109456, Val Acc: 0.783505\n",
      "Epoch 22067 - Train Loss: 0.077090, Train Acc: 0.883333 | Val Loss: 0.109455, Val Acc: 0.783505\n",
      "Epoch 22068 - Train Loss: 0.077088, Train Acc: 0.883333 | Val Loss: 0.109455, Val Acc: 0.783505\n",
      "Epoch 22069 - Train Loss: 0.077087, Train Acc: 0.883333 | Val Loss: 0.109454, Val Acc: 0.783505\n",
      "Epoch 22070 - Train Loss: 0.077085, Train Acc: 0.883333 | Val Loss: 0.109453, Val Acc: 0.783505\n",
      "Epoch 22071 - Train Loss: 0.077083, Train Acc: 0.883333 | Val Loss: 0.109453, Val Acc: 0.783505\n",
      "Epoch 22072 - Train Loss: 0.077081, Train Acc: 0.883333 | Val Loss: 0.109452, Val Acc: 0.783505\n",
      "Epoch 22073 - Train Loss: 0.077079, Train Acc: 0.883333 | Val Loss: 0.109451, Val Acc: 0.783505\n",
      "Epoch 22074 - Train Loss: 0.077077, Train Acc: 0.883333 | Val Loss: 0.109451, Val Acc: 0.783505\n",
      "Epoch 22075 - Train Loss: 0.077075, Train Acc: 0.883333 | Val Loss: 0.109450, Val Acc: 0.783505\n",
      "Epoch 22076 - Train Loss: 0.077073, Train Acc: 0.883333 | Val Loss: 0.109450, Val Acc: 0.783505\n",
      "Epoch 22077 - Train Loss: 0.077071, Train Acc: 0.883333 | Val Loss: 0.109449, Val Acc: 0.783505\n",
      "Epoch 22078 - Train Loss: 0.077070, Train Acc: 0.883333 | Val Loss: 0.109448, Val Acc: 0.783505\n",
      "Epoch 22079 - Train Loss: 0.077068, Train Acc: 0.883333 | Val Loss: 0.109448, Val Acc: 0.783505\n",
      "Epoch 22080 - Train Loss: 0.077066, Train Acc: 0.883333 | Val Loss: 0.109447, Val Acc: 0.783505\n",
      "Epoch 22081 - Train Loss: 0.077064, Train Acc: 0.883333 | Val Loss: 0.109447, Val Acc: 0.783505\n",
      "Epoch 22082 - Train Loss: 0.077062, Train Acc: 0.883333 | Val Loss: 0.109446, Val Acc: 0.783505\n",
      "Epoch 22083 - Train Loss: 0.077060, Train Acc: 0.883333 | Val Loss: 0.109445, Val Acc: 0.783505\n",
      "Epoch 22084 - Train Loss: 0.077058, Train Acc: 0.883333 | Val Loss: 0.109445, Val Acc: 0.783505\n",
      "Epoch 22085 - Train Loss: 0.077056, Train Acc: 0.883333 | Val Loss: 0.109444, Val Acc: 0.783505\n",
      "Epoch 22086 - Train Loss: 0.077055, Train Acc: 0.883333 | Val Loss: 0.109443, Val Acc: 0.783505\n",
      "Epoch 22087 - Train Loss: 0.077053, Train Acc: 0.883333 | Val Loss: 0.109443, Val Acc: 0.783505\n",
      "Epoch 22088 - Train Loss: 0.077051, Train Acc: 0.883333 | Val Loss: 0.109442, Val Acc: 0.783505\n",
      "Epoch 22089 - Train Loss: 0.077049, Train Acc: 0.883333 | Val Loss: 0.109442, Val Acc: 0.783505\n",
      "Epoch 22090 - Train Loss: 0.077047, Train Acc: 0.883333 | Val Loss: 0.109441, Val Acc: 0.783505\n",
      "Epoch 22091 - Train Loss: 0.077045, Train Acc: 0.883333 | Val Loss: 0.109440, Val Acc: 0.783505\n",
      "Epoch 22092 - Train Loss: 0.077043, Train Acc: 0.883333 | Val Loss: 0.109440, Val Acc: 0.783505\n",
      "Epoch 22093 - Train Loss: 0.077041, Train Acc: 0.883333 | Val Loss: 0.109439, Val Acc: 0.783505\n",
      "Epoch 22094 - Train Loss: 0.077039, Train Acc: 0.883333 | Val Loss: 0.109439, Val Acc: 0.783505\n",
      "Epoch 22095 - Train Loss: 0.077038, Train Acc: 0.883333 | Val Loss: 0.109438, Val Acc: 0.783505\n",
      "Epoch 22096 - Train Loss: 0.077036, Train Acc: 0.883333 | Val Loss: 0.109437, Val Acc: 0.783505\n",
      "Epoch 22097 - Train Loss: 0.077034, Train Acc: 0.883333 | Val Loss: 0.109437, Val Acc: 0.783505\n",
      "Epoch 22098 - Train Loss: 0.077032, Train Acc: 0.883333 | Val Loss: 0.109436, Val Acc: 0.783505\n",
      "Epoch 22099 - Train Loss: 0.077030, Train Acc: 0.883333 | Val Loss: 0.109436, Val Acc: 0.783505\n",
      "Epoch 22100 - Train Loss: 0.077028, Train Acc: 0.883333 | Val Loss: 0.109435, Val Acc: 0.783505\n",
      "Epoch 22101 - Train Loss: 0.077026, Train Acc: 0.883333 | Val Loss: 0.109434, Val Acc: 0.783505\n",
      "Epoch 22102 - Train Loss: 0.077024, Train Acc: 0.883333 | Val Loss: 0.109434, Val Acc: 0.783505\n",
      "Epoch 22103 - Train Loss: 0.077023, Train Acc: 0.883333 | Val Loss: 0.109433, Val Acc: 0.783505\n",
      "Epoch 22104 - Train Loss: 0.077021, Train Acc: 0.883333 | Val Loss: 0.109433, Val Acc: 0.783505\n",
      "Epoch 22105 - Train Loss: 0.077019, Train Acc: 0.883333 | Val Loss: 0.109432, Val Acc: 0.783505\n",
      "Epoch 22106 - Train Loss: 0.077017, Train Acc: 0.883333 | Val Loss: 0.109431, Val Acc: 0.783505\n",
      "Epoch 22107 - Train Loss: 0.077015, Train Acc: 0.883333 | Val Loss: 0.109431, Val Acc: 0.783505\n",
      "Epoch 22108 - Train Loss: 0.077013, Train Acc: 0.883333 | Val Loss: 0.109430, Val Acc: 0.783505\n",
      "Epoch 22109 - Train Loss: 0.077011, Train Acc: 0.883333 | Val Loss: 0.109430, Val Acc: 0.783505\n",
      "Epoch 22110 - Train Loss: 0.077009, Train Acc: 0.883333 | Val Loss: 0.109429, Val Acc: 0.783505\n",
      "Epoch 22111 - Train Loss: 0.077007, Train Acc: 0.883333 | Val Loss: 0.109428, Val Acc: 0.783505\n",
      "Epoch 22112 - Train Loss: 0.077006, Train Acc: 0.883333 | Val Loss: 0.109428, Val Acc: 0.783505\n",
      "Epoch 22113 - Train Loss: 0.077004, Train Acc: 0.883333 | Val Loss: 0.109427, Val Acc: 0.783505\n",
      "Epoch 22114 - Train Loss: 0.077002, Train Acc: 0.883333 | Val Loss: 0.109427, Val Acc: 0.783505\n",
      "Epoch 22115 - Train Loss: 0.077000, Train Acc: 0.883333 | Val Loss: 0.109426, Val Acc: 0.783505\n",
      "Epoch 22116 - Train Loss: 0.076998, Train Acc: 0.883333 | Val Loss: 0.109425, Val Acc: 0.783505\n",
      "Epoch 22117 - Train Loss: 0.076996, Train Acc: 0.883333 | Val Loss: 0.109425, Val Acc: 0.783505\n",
      "Epoch 22118 - Train Loss: 0.076994, Train Acc: 0.883333 | Val Loss: 0.109424, Val Acc: 0.783505\n",
      "Epoch 22119 - Train Loss: 0.076992, Train Acc: 0.883333 | Val Loss: 0.109423, Val Acc: 0.783505\n",
      "Epoch 22120 - Train Loss: 0.076991, Train Acc: 0.883333 | Val Loss: 0.109423, Val Acc: 0.783505\n",
      "Epoch 22121 - Train Loss: 0.076989, Train Acc: 0.883333 | Val Loss: 0.109422, Val Acc: 0.783505\n",
      "Epoch 22122 - Train Loss: 0.076987, Train Acc: 0.883333 | Val Loss: 0.109422, Val Acc: 0.783505\n",
      "Epoch 22123 - Train Loss: 0.076985, Train Acc: 0.883333 | Val Loss: 0.109421, Val Acc: 0.783505\n",
      "Epoch 22124 - Train Loss: 0.076983, Train Acc: 0.883333 | Val Loss: 0.109420, Val Acc: 0.783505\n",
      "Epoch 22125 - Train Loss: 0.076981, Train Acc: 0.883333 | Val Loss: 0.109420, Val Acc: 0.783505\n",
      "Epoch 22126 - Train Loss: 0.076979, Train Acc: 0.883333 | Val Loss: 0.109419, Val Acc: 0.783505\n",
      "Epoch 22127 - Train Loss: 0.076977, Train Acc: 0.883333 | Val Loss: 0.109419, Val Acc: 0.783505\n",
      "Epoch 22128 - Train Loss: 0.076976, Train Acc: 0.883333 | Val Loss: 0.109418, Val Acc: 0.783505\n",
      "Epoch 22129 - Train Loss: 0.076974, Train Acc: 0.883333 | Val Loss: 0.109417, Val Acc: 0.783505\n",
      "Epoch 22130 - Train Loss: 0.076972, Train Acc: 0.883333 | Val Loss: 0.109417, Val Acc: 0.783505\n",
      "Epoch 22131 - Train Loss: 0.076970, Train Acc: 0.883333 | Val Loss: 0.109416, Val Acc: 0.783505\n",
      "Epoch 22132 - Train Loss: 0.076968, Train Acc: 0.883333 | Val Loss: 0.109416, Val Acc: 0.783505\n",
      "Epoch 22133 - Train Loss: 0.076966, Train Acc: 0.883333 | Val Loss: 0.109415, Val Acc: 0.783505\n",
      "Epoch 22134 - Train Loss: 0.076964, Train Acc: 0.883333 | Val Loss: 0.109414, Val Acc: 0.783505\n",
      "Epoch 22135 - Train Loss: 0.076962, Train Acc: 0.883333 | Val Loss: 0.109414, Val Acc: 0.783505\n",
      "Epoch 22136 - Train Loss: 0.076961, Train Acc: 0.883333 | Val Loss: 0.109413, Val Acc: 0.783505\n",
      "Epoch 22137 - Train Loss: 0.076959, Train Acc: 0.883333 | Val Loss: 0.109413, Val Acc: 0.783505\n",
      "Epoch 22138 - Train Loss: 0.076957, Train Acc: 0.883333 | Val Loss: 0.109412, Val Acc: 0.783505\n",
      "Epoch 22139 - Train Loss: 0.076955, Train Acc: 0.883333 | Val Loss: 0.109411, Val Acc: 0.783505\n",
      "Epoch 22140 - Train Loss: 0.076953, Train Acc: 0.883333 | Val Loss: 0.109411, Val Acc: 0.783505\n",
      "Epoch 22141 - Train Loss: 0.076951, Train Acc: 0.883333 | Val Loss: 0.109410, Val Acc: 0.783505\n",
      "Epoch 22142 - Train Loss: 0.076949, Train Acc: 0.883333 | Val Loss: 0.109410, Val Acc: 0.783505\n",
      "Epoch 22143 - Train Loss: 0.076947, Train Acc: 0.883333 | Val Loss: 0.109409, Val Acc: 0.783505\n",
      "Epoch 22144 - Train Loss: 0.076946, Train Acc: 0.883333 | Val Loss: 0.109408, Val Acc: 0.783505\n",
      "Epoch 22145 - Train Loss: 0.076944, Train Acc: 0.883333 | Val Loss: 0.109408, Val Acc: 0.783505\n",
      "Epoch 22146 - Train Loss: 0.076942, Train Acc: 0.883333 | Val Loss: 0.109407, Val Acc: 0.783505\n",
      "Epoch 22147 - Train Loss: 0.076940, Train Acc: 0.883333 | Val Loss: 0.109407, Val Acc: 0.783505\n",
      "Epoch 22148 - Train Loss: 0.076938, Train Acc: 0.883333 | Val Loss: 0.109406, Val Acc: 0.783505\n",
      "Epoch 22149 - Train Loss: 0.076936, Train Acc: 0.883333 | Val Loss: 0.109405, Val Acc: 0.783505\n",
      "Epoch 22150 - Train Loss: 0.076934, Train Acc: 0.883333 | Val Loss: 0.109405, Val Acc: 0.783505\n",
      "Epoch 22151 - Train Loss: 0.076932, Train Acc: 0.883333 | Val Loss: 0.109404, Val Acc: 0.783505\n",
      "Epoch 22152 - Train Loss: 0.076931, Train Acc: 0.883333 | Val Loss: 0.109404, Val Acc: 0.783505\n",
      "Epoch 22153 - Train Loss: 0.076929, Train Acc: 0.883333 | Val Loss: 0.109403, Val Acc: 0.783505\n",
      "Epoch 22154 - Train Loss: 0.076927, Train Acc: 0.883333 | Val Loss: 0.109402, Val Acc: 0.783505\n",
      "Epoch 22155 - Train Loss: 0.076925, Train Acc: 0.883333 | Val Loss: 0.109402, Val Acc: 0.783505\n",
      "Epoch 22156 - Train Loss: 0.076923, Train Acc: 0.883333 | Val Loss: 0.109401, Val Acc: 0.783505\n",
      "Epoch 22157 - Train Loss: 0.076921, Train Acc: 0.883333 | Val Loss: 0.109401, Val Acc: 0.783505\n",
      "Epoch 22158 - Train Loss: 0.076919, Train Acc: 0.883333 | Val Loss: 0.109400, Val Acc: 0.783505\n",
      "Epoch 22159 - Train Loss: 0.076917, Train Acc: 0.883333 | Val Loss: 0.109399, Val Acc: 0.783505\n",
      "Epoch 22160 - Train Loss: 0.076916, Train Acc: 0.883333 | Val Loss: 0.109399, Val Acc: 0.783505\n",
      "Epoch 22161 - Train Loss: 0.076914, Train Acc: 0.883333 | Val Loss: 0.109398, Val Acc: 0.783505\n",
      "Epoch 22162 - Train Loss: 0.076912, Train Acc: 0.883333 | Val Loss: 0.109398, Val Acc: 0.783505\n",
      "Epoch 22163 - Train Loss: 0.076910, Train Acc: 0.883333 | Val Loss: 0.109397, Val Acc: 0.783505\n",
      "Epoch 22164 - Train Loss: 0.076908, Train Acc: 0.883333 | Val Loss: 0.109396, Val Acc: 0.783505\n",
      "Epoch 22165 - Train Loss: 0.076906, Train Acc: 0.883333 | Val Loss: 0.109396, Val Acc: 0.783505\n",
      "Epoch 22166 - Train Loss: 0.076904, Train Acc: 0.883333 | Val Loss: 0.109395, Val Acc: 0.783505\n",
      "Epoch 22167 - Train Loss: 0.076902, Train Acc: 0.883333 | Val Loss: 0.109395, Val Acc: 0.783505\n",
      "Epoch 22168 - Train Loss: 0.076901, Train Acc: 0.883333 | Val Loss: 0.109394, Val Acc: 0.783505\n",
      "Epoch 22169 - Train Loss: 0.076899, Train Acc: 0.883333 | Val Loss: 0.109393, Val Acc: 0.783505\n",
      "Epoch 22170 - Train Loss: 0.076897, Train Acc: 0.883333 | Val Loss: 0.109393, Val Acc: 0.783505\n",
      "Epoch 22171 - Train Loss: 0.076895, Train Acc: 0.883333 | Val Loss: 0.109392, Val Acc: 0.783505\n",
      "Epoch 22172 - Train Loss: 0.076893, Train Acc: 0.883333 | Val Loss: 0.109392, Val Acc: 0.783505\n",
      "Epoch 22173 - Train Loss: 0.076891, Train Acc: 0.883333 | Val Loss: 0.109391, Val Acc: 0.783505\n",
      "Epoch 22174 - Train Loss: 0.076889, Train Acc: 0.883333 | Val Loss: 0.109390, Val Acc: 0.783505\n",
      "Epoch 22175 - Train Loss: 0.076888, Train Acc: 0.883333 | Val Loss: 0.109390, Val Acc: 0.783505\n",
      "Epoch 22176 - Train Loss: 0.076886, Train Acc: 0.883333 | Val Loss: 0.109389, Val Acc: 0.783505\n",
      "Epoch 22177 - Train Loss: 0.076884, Train Acc: 0.883333 | Val Loss: 0.109389, Val Acc: 0.783505\n",
      "Epoch 22178 - Train Loss: 0.076882, Train Acc: 0.883333 | Val Loss: 0.109388, Val Acc: 0.783505\n",
      "Epoch 22179 - Train Loss: 0.076880, Train Acc: 0.883333 | Val Loss: 0.109388, Val Acc: 0.783505\n",
      "Epoch 22180 - Train Loss: 0.076878, Train Acc: 0.883333 | Val Loss: 0.109387, Val Acc: 0.783505\n",
      "Epoch 22181 - Train Loss: 0.076876, Train Acc: 0.883333 | Val Loss: 0.109386, Val Acc: 0.783505\n",
      "Epoch 22182 - Train Loss: 0.076874, Train Acc: 0.883333 | Val Loss: 0.109386, Val Acc: 0.783505\n",
      "Epoch 22183 - Train Loss: 0.076873, Train Acc: 0.883333 | Val Loss: 0.109385, Val Acc: 0.783505\n",
      "Epoch 22184 - Train Loss: 0.076871, Train Acc: 0.883333 | Val Loss: 0.109385, Val Acc: 0.783505\n",
      "Epoch 22185 - Train Loss: 0.076869, Train Acc: 0.883333 | Val Loss: 0.109384, Val Acc: 0.783505\n",
      "Epoch 22186 - Train Loss: 0.076867, Train Acc: 0.883333 | Val Loss: 0.109383, Val Acc: 0.783505\n",
      "Epoch 22187 - Train Loss: 0.076865, Train Acc: 0.883333 | Val Loss: 0.109383, Val Acc: 0.783505\n",
      "Epoch 22188 - Train Loss: 0.076863, Train Acc: 0.883333 | Val Loss: 0.109382, Val Acc: 0.783505\n",
      "Epoch 22189 - Train Loss: 0.076861, Train Acc: 0.883333 | Val Loss: 0.109382, Val Acc: 0.783505\n",
      "Epoch 22190 - Train Loss: 0.076860, Train Acc: 0.883333 | Val Loss: 0.109381, Val Acc: 0.783505\n",
      "Epoch 22191 - Train Loss: 0.076858, Train Acc: 0.883333 | Val Loss: 0.109380, Val Acc: 0.783505\n",
      "Epoch 22192 - Train Loss: 0.076856, Train Acc: 0.883333 | Val Loss: 0.109380, Val Acc: 0.783505\n",
      "Epoch 22193 - Train Loss: 0.076854, Train Acc: 0.883333 | Val Loss: 0.109379, Val Acc: 0.783505\n",
      "Epoch 22194 - Train Loss: 0.076852, Train Acc: 0.883333 | Val Loss: 0.109379, Val Acc: 0.783505\n",
      "Epoch 22195 - Train Loss: 0.076850, Train Acc: 0.883333 | Val Loss: 0.109378, Val Acc: 0.783505\n",
      "Epoch 22196 - Train Loss: 0.076848, Train Acc: 0.883333 | Val Loss: 0.109377, Val Acc: 0.783505\n",
      "Epoch 22197 - Train Loss: 0.076846, Train Acc: 0.883333 | Val Loss: 0.109377, Val Acc: 0.783505\n",
      "Epoch 22198 - Train Loss: 0.076845, Train Acc: 0.883333 | Val Loss: 0.109376, Val Acc: 0.783505\n",
      "Epoch 22199 - Train Loss: 0.076843, Train Acc: 0.883333 | Val Loss: 0.109376, Val Acc: 0.783505\n",
      "Epoch 22200 - Train Loss: 0.076841, Train Acc: 0.883333 | Val Loss: 0.109375, Val Acc: 0.783505\n",
      "Epoch 22201 - Train Loss: 0.076839, Train Acc: 0.883333 | Val Loss: 0.109374, Val Acc: 0.783505\n",
      "Epoch 22202 - Train Loss: 0.076837, Train Acc: 0.883333 | Val Loss: 0.109374, Val Acc: 0.783505\n",
      "Epoch 22203 - Train Loss: 0.076835, Train Acc: 0.883333 | Val Loss: 0.109373, Val Acc: 0.783505\n",
      "Epoch 22204 - Train Loss: 0.076833, Train Acc: 0.883333 | Val Loss: 0.109373, Val Acc: 0.783505\n",
      "Epoch 22205 - Train Loss: 0.076832, Train Acc: 0.883333 | Val Loss: 0.109372, Val Acc: 0.783505\n",
      "Epoch 22206 - Train Loss: 0.076830, Train Acc: 0.883333 | Val Loss: 0.109371, Val Acc: 0.783505\n",
      "Epoch 22207 - Train Loss: 0.076828, Train Acc: 0.883333 | Val Loss: 0.109371, Val Acc: 0.783505\n",
      "Epoch 22208 - Train Loss: 0.076826, Train Acc: 0.883333 | Val Loss: 0.109370, Val Acc: 0.783505\n",
      "Epoch 22209 - Train Loss: 0.076824, Train Acc: 0.883333 | Val Loss: 0.109370, Val Acc: 0.783505\n",
      "Epoch 22210 - Train Loss: 0.076822, Train Acc: 0.883333 | Val Loss: 0.109369, Val Acc: 0.783505\n",
      "Epoch 22211 - Train Loss: 0.076820, Train Acc: 0.883333 | Val Loss: 0.109369, Val Acc: 0.783505\n",
      "Epoch 22212 - Train Loss: 0.076819, Train Acc: 0.883333 | Val Loss: 0.109368, Val Acc: 0.783505\n",
      "Epoch 22213 - Train Loss: 0.076817, Train Acc: 0.883333 | Val Loss: 0.109367, Val Acc: 0.783505\n",
      "Epoch 22214 - Train Loss: 0.076815, Train Acc: 0.883333 | Val Loss: 0.109367, Val Acc: 0.783505\n",
      "Epoch 22215 - Train Loss: 0.076813, Train Acc: 0.883333 | Val Loss: 0.109366, Val Acc: 0.783505\n",
      "Epoch 22216 - Train Loss: 0.076811, Train Acc: 0.883333 | Val Loss: 0.109366, Val Acc: 0.783505\n",
      "Epoch 22217 - Train Loss: 0.076809, Train Acc: 0.883333 | Val Loss: 0.109365, Val Acc: 0.783505\n",
      "Epoch 22218 - Train Loss: 0.076807, Train Acc: 0.883333 | Val Loss: 0.109364, Val Acc: 0.783505\n",
      "Epoch 22219 - Train Loss: 0.076805, Train Acc: 0.883333 | Val Loss: 0.109364, Val Acc: 0.783505\n",
      "Epoch 22220 - Train Loss: 0.076804, Train Acc: 0.883333 | Val Loss: 0.109363, Val Acc: 0.783505\n",
      "Epoch 22221 - Train Loss: 0.076802, Train Acc: 0.883333 | Val Loss: 0.109363, Val Acc: 0.783505\n",
      "Epoch 22222 - Train Loss: 0.076800, Train Acc: 0.883333 | Val Loss: 0.109362, Val Acc: 0.783505\n",
      "Epoch 22223 - Train Loss: 0.076798, Train Acc: 0.883333 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 22224 - Train Loss: 0.076796, Train Acc: 0.883333 | Val Loss: 0.109361, Val Acc: 0.783505\n",
      "Epoch 22225 - Train Loss: 0.076794, Train Acc: 0.883333 | Val Loss: 0.109360, Val Acc: 0.783505\n",
      "Epoch 22226 - Train Loss: 0.076792, Train Acc: 0.883333 | Val Loss: 0.109360, Val Acc: 0.783505\n",
      "Epoch 22227 - Train Loss: 0.076791, Train Acc: 0.883333 | Val Loss: 0.109359, Val Acc: 0.783505\n",
      "Epoch 22228 - Train Loss: 0.076789, Train Acc: 0.883333 | Val Loss: 0.109358, Val Acc: 0.783505\n",
      "Epoch 22229 - Train Loss: 0.076787, Train Acc: 0.883333 | Val Loss: 0.109358, Val Acc: 0.783505\n",
      "Epoch 22230 - Train Loss: 0.076785, Train Acc: 0.883333 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 22231 - Train Loss: 0.076783, Train Acc: 0.883333 | Val Loss: 0.109357, Val Acc: 0.783505\n",
      "Epoch 22232 - Train Loss: 0.076781, Train Acc: 0.883333 | Val Loss: 0.109356, Val Acc: 0.783505\n",
      "Epoch 22233 - Train Loss: 0.076779, Train Acc: 0.883333 | Val Loss: 0.109356, Val Acc: 0.783505\n",
      "Epoch 22234 - Train Loss: 0.076778, Train Acc: 0.883333 | Val Loss: 0.109355, Val Acc: 0.783505\n",
      "Epoch 22235 - Train Loss: 0.076776, Train Acc: 0.883333 | Val Loss: 0.109354, Val Acc: 0.783505\n",
      "Epoch 22236 - Train Loss: 0.076774, Train Acc: 0.883333 | Val Loss: 0.109354, Val Acc: 0.783505\n",
      "Epoch 22237 - Train Loss: 0.076772, Train Acc: 0.883333 | Val Loss: 0.109353, Val Acc: 0.783505\n",
      "Epoch 22238 - Train Loss: 0.076770, Train Acc: 0.883333 | Val Loss: 0.109353, Val Acc: 0.783505\n",
      "Epoch 22239 - Train Loss: 0.076768, Train Acc: 0.883333 | Val Loss: 0.109352, Val Acc: 0.783505\n",
      "Epoch 22240 - Train Loss: 0.076766, Train Acc: 0.883333 | Val Loss: 0.109351, Val Acc: 0.783505\n",
      "Epoch 22241 - Train Loss: 0.076765, Train Acc: 0.883333 | Val Loss: 0.109351, Val Acc: 0.783505\n",
      "Epoch 22242 - Train Loss: 0.076763, Train Acc: 0.883333 | Val Loss: 0.109350, Val Acc: 0.783505\n",
      "Epoch 22243 - Train Loss: 0.076761, Train Acc: 0.883333 | Val Loss: 0.109350, Val Acc: 0.783505\n",
      "Epoch 22244 - Train Loss: 0.076759, Train Acc: 0.883333 | Val Loss: 0.109349, Val Acc: 0.783505\n",
      "Epoch 22245 - Train Loss: 0.076757, Train Acc: 0.883333 | Val Loss: 0.109349, Val Acc: 0.783505\n",
      "Epoch 22246 - Train Loss: 0.076755, Train Acc: 0.883333 | Val Loss: 0.109348, Val Acc: 0.783505\n",
      "Epoch 22247 - Train Loss: 0.076753, Train Acc: 0.883333 | Val Loss: 0.109347, Val Acc: 0.783505\n",
      "Epoch 22248 - Train Loss: 0.076752, Train Acc: 0.883333 | Val Loss: 0.109347, Val Acc: 0.783505\n",
      "Epoch 22249 - Train Loss: 0.076750, Train Acc: 0.883333 | Val Loss: 0.109346, Val Acc: 0.783505\n",
      "Epoch 22250 - Train Loss: 0.076748, Train Acc: 0.883333 | Val Loss: 0.109346, Val Acc: 0.783505\n",
      "Epoch 22251 - Train Loss: 0.076746, Train Acc: 0.883333 | Val Loss: 0.109345, Val Acc: 0.783505\n",
      "Epoch 22252 - Train Loss: 0.076744, Train Acc: 0.883333 | Val Loss: 0.109344, Val Acc: 0.783505\n",
      "Epoch 22253 - Train Loss: 0.076742, Train Acc: 0.883333 | Val Loss: 0.109344, Val Acc: 0.783505\n",
      "Epoch 22254 - Train Loss: 0.076740, Train Acc: 0.883333 | Val Loss: 0.109343, Val Acc: 0.783505\n",
      "Epoch 22255 - Train Loss: 0.076739, Train Acc: 0.883333 | Val Loss: 0.109343, Val Acc: 0.783505\n",
      "Epoch 22256 - Train Loss: 0.076737, Train Acc: 0.883333 | Val Loss: 0.109342, Val Acc: 0.783505\n",
      "Epoch 22257 - Train Loss: 0.076735, Train Acc: 0.883333 | Val Loss: 0.109341, Val Acc: 0.783505\n",
      "Epoch 22258 - Train Loss: 0.076733, Train Acc: 0.883333 | Val Loss: 0.109341, Val Acc: 0.783505\n",
      "Epoch 22259 - Train Loss: 0.076731, Train Acc: 0.883333 | Val Loss: 0.109340, Val Acc: 0.783505\n",
      "Epoch 22260 - Train Loss: 0.076729, Train Acc: 0.883333 | Val Loss: 0.109340, Val Acc: 0.783505\n",
      "Epoch 22261 - Train Loss: 0.076727, Train Acc: 0.883333 | Val Loss: 0.109339, Val Acc: 0.783505\n",
      "Epoch 22262 - Train Loss: 0.076726, Train Acc: 0.883333 | Val Loss: 0.109339, Val Acc: 0.783505\n",
      "Epoch 22263 - Train Loss: 0.076724, Train Acc: 0.883333 | Val Loss: 0.109338, Val Acc: 0.783505\n",
      "Epoch 22264 - Train Loss: 0.076722, Train Acc: 0.883333 | Val Loss: 0.109337, Val Acc: 0.783505\n",
      "Epoch 22265 - Train Loss: 0.076720, Train Acc: 0.883333 | Val Loss: 0.109337, Val Acc: 0.783505\n",
      "Epoch 22266 - Train Loss: 0.076718, Train Acc: 0.883333 | Val Loss: 0.109336, Val Acc: 0.783505\n",
      "Epoch 22267 - Train Loss: 0.076716, Train Acc: 0.883333 | Val Loss: 0.109336, Val Acc: 0.783505\n",
      "Epoch 22268 - Train Loss: 0.076714, Train Acc: 0.883333 | Val Loss: 0.109335, Val Acc: 0.783505\n",
      "Epoch 22269 - Train Loss: 0.076713, Train Acc: 0.883333 | Val Loss: 0.109334, Val Acc: 0.783505\n",
      "Epoch 22270 - Train Loss: 0.076711, Train Acc: 0.883333 | Val Loss: 0.109334, Val Acc: 0.783505\n",
      "Epoch 22271 - Train Loss: 0.076709, Train Acc: 0.883333 | Val Loss: 0.109333, Val Acc: 0.783505\n",
      "Epoch 22272 - Train Loss: 0.076707, Train Acc: 0.883333 | Val Loss: 0.109333, Val Acc: 0.783505\n",
      "Epoch 22273 - Train Loss: 0.076705, Train Acc: 0.883333 | Val Loss: 0.109332, Val Acc: 0.783505\n",
      "Epoch 22274 - Train Loss: 0.076703, Train Acc: 0.883333 | Val Loss: 0.109332, Val Acc: 0.783505\n",
      "Epoch 22275 - Train Loss: 0.076701, Train Acc: 0.883333 | Val Loss: 0.109331, Val Acc: 0.783505\n",
      "Epoch 22276 - Train Loss: 0.076700, Train Acc: 0.883333 | Val Loss: 0.109330, Val Acc: 0.783505\n",
      "Epoch 22277 - Train Loss: 0.076698, Train Acc: 0.883333 | Val Loss: 0.109330, Val Acc: 0.783505\n",
      "Epoch 22278 - Train Loss: 0.076696, Train Acc: 0.883333 | Val Loss: 0.109329, Val Acc: 0.783505\n",
      "Epoch 22279 - Train Loss: 0.076694, Train Acc: 0.883333 | Val Loss: 0.109329, Val Acc: 0.783505\n",
      "Epoch 22280 - Train Loss: 0.076692, Train Acc: 0.883333 | Val Loss: 0.109328, Val Acc: 0.783505\n",
      "Epoch 22281 - Train Loss: 0.076690, Train Acc: 0.883333 | Val Loss: 0.109327, Val Acc: 0.783505\n",
      "Epoch 22282 - Train Loss: 0.076689, Train Acc: 0.883333 | Val Loss: 0.109327, Val Acc: 0.783505\n",
      "Epoch 22283 - Train Loss: 0.076687, Train Acc: 0.883333 | Val Loss: 0.109326, Val Acc: 0.783505\n",
      "Epoch 22284 - Train Loss: 0.076685, Train Acc: 0.883333 | Val Loss: 0.109326, Val Acc: 0.783505\n",
      "Epoch 22285 - Train Loss: 0.076683, Train Acc: 0.883333 | Val Loss: 0.109325, Val Acc: 0.783505\n",
      "Epoch 22286 - Train Loss: 0.076681, Train Acc: 0.883333 | Val Loss: 0.109325, Val Acc: 0.783505\n",
      "Epoch 22287 - Train Loss: 0.076679, Train Acc: 0.883333 | Val Loss: 0.109324, Val Acc: 0.783505\n",
      "Epoch 22288 - Train Loss: 0.076677, Train Acc: 0.883333 | Val Loss: 0.109323, Val Acc: 0.783505\n",
      "Epoch 22289 - Train Loss: 0.076676, Train Acc: 0.883333 | Val Loss: 0.109323, Val Acc: 0.783505\n",
      "Epoch 22290 - Train Loss: 0.076674, Train Acc: 0.883333 | Val Loss: 0.109322, Val Acc: 0.783505\n",
      "Epoch 22291 - Train Loss: 0.076672, Train Acc: 0.883333 | Val Loss: 0.109322, Val Acc: 0.783505\n",
      "Epoch 22292 - Train Loss: 0.076670, Train Acc: 0.883333 | Val Loss: 0.109321, Val Acc: 0.783505\n",
      "Epoch 22293 - Train Loss: 0.076668, Train Acc: 0.883333 | Val Loss: 0.109321, Val Acc: 0.783505\n",
      "Epoch 22294 - Train Loss: 0.076666, Train Acc: 0.883333 | Val Loss: 0.109320, Val Acc: 0.783505\n",
      "Epoch 22295 - Train Loss: 0.076664, Train Acc: 0.883333 | Val Loss: 0.109319, Val Acc: 0.783505\n",
      "Epoch 22296 - Train Loss: 0.076663, Train Acc: 0.883333 | Val Loss: 0.109319, Val Acc: 0.783505\n",
      "Epoch 22297 - Train Loss: 0.076661, Train Acc: 0.883333 | Val Loss: 0.109318, Val Acc: 0.783505\n",
      "Epoch 22298 - Train Loss: 0.076659, Train Acc: 0.883333 | Val Loss: 0.109318, Val Acc: 0.783505\n",
      "Epoch 22299 - Train Loss: 0.076657, Train Acc: 0.883333 | Val Loss: 0.109317, Val Acc: 0.783505\n",
      "Epoch 22300 - Train Loss: 0.076655, Train Acc: 0.883333 | Val Loss: 0.109316, Val Acc: 0.783505\n",
      "Epoch 22301 - Train Loss: 0.076653, Train Acc: 0.883333 | Val Loss: 0.109316, Val Acc: 0.783505\n",
      "Epoch 22302 - Train Loss: 0.076652, Train Acc: 0.883333 | Val Loss: 0.109315, Val Acc: 0.783505\n",
      "Epoch 22303 - Train Loss: 0.076650, Train Acc: 0.883333 | Val Loss: 0.109315, Val Acc: 0.783505\n",
      "Epoch 22304 - Train Loss: 0.076648, Train Acc: 0.883333 | Val Loss: 0.109314, Val Acc: 0.783505\n",
      "Epoch 22305 - Train Loss: 0.076646, Train Acc: 0.883333 | Val Loss: 0.109314, Val Acc: 0.783505\n",
      "Epoch 22306 - Train Loss: 0.076644, Train Acc: 0.883333 | Val Loss: 0.109313, Val Acc: 0.783505\n",
      "Epoch 22307 - Train Loss: 0.076642, Train Acc: 0.883333 | Val Loss: 0.109312, Val Acc: 0.783505\n",
      "Epoch 22308 - Train Loss: 0.076640, Train Acc: 0.883333 | Val Loss: 0.109312, Val Acc: 0.783505\n",
      "Epoch 22309 - Train Loss: 0.076639, Train Acc: 0.883333 | Val Loss: 0.109311, Val Acc: 0.783505\n",
      "Epoch 22310 - Train Loss: 0.076637, Train Acc: 0.883333 | Val Loss: 0.109311, Val Acc: 0.783505\n",
      "Epoch 22311 - Train Loss: 0.076635, Train Acc: 0.883333 | Val Loss: 0.109310, Val Acc: 0.783505\n",
      "Epoch 22312 - Train Loss: 0.076633, Train Acc: 0.883333 | Val Loss: 0.109310, Val Acc: 0.783505\n",
      "Epoch 22313 - Train Loss: 0.076631, Train Acc: 0.883333 | Val Loss: 0.109309, Val Acc: 0.783505\n",
      "Epoch 22314 - Train Loss: 0.076629, Train Acc: 0.883333 | Val Loss: 0.109308, Val Acc: 0.783505\n",
      "Epoch 22315 - Train Loss: 0.076628, Train Acc: 0.883333 | Val Loss: 0.109308, Val Acc: 0.783505\n",
      "Epoch 22316 - Train Loss: 0.076626, Train Acc: 0.883333 | Val Loss: 0.109307, Val Acc: 0.783505\n",
      "Epoch 22317 - Train Loss: 0.076624, Train Acc: 0.883333 | Val Loss: 0.109307, Val Acc: 0.783505\n",
      "Epoch 22318 - Train Loss: 0.076622, Train Acc: 0.883333 | Val Loss: 0.109306, Val Acc: 0.783505\n",
      "Epoch 22319 - Train Loss: 0.076620, Train Acc: 0.883333 | Val Loss: 0.109306, Val Acc: 0.783505\n",
      "Epoch 22320 - Train Loss: 0.076618, Train Acc: 0.883333 | Val Loss: 0.109305, Val Acc: 0.783505\n",
      "Epoch 22321 - Train Loss: 0.076616, Train Acc: 0.883333 | Val Loss: 0.109304, Val Acc: 0.783505\n",
      "Epoch 22322 - Train Loss: 0.076615, Train Acc: 0.883333 | Val Loss: 0.109304, Val Acc: 0.783505\n",
      "Epoch 22323 - Train Loss: 0.076613, Train Acc: 0.883333 | Val Loss: 0.109303, Val Acc: 0.783505\n",
      "Epoch 22324 - Train Loss: 0.076611, Train Acc: 0.883333 | Val Loss: 0.109303, Val Acc: 0.783505\n",
      "Epoch 22325 - Train Loss: 0.076609, Train Acc: 0.883333 | Val Loss: 0.109302, Val Acc: 0.783505\n",
      "Epoch 22326 - Train Loss: 0.076607, Train Acc: 0.883333 | Val Loss: 0.109302, Val Acc: 0.783505\n",
      "Epoch 22327 - Train Loss: 0.076605, Train Acc: 0.883333 | Val Loss: 0.109301, Val Acc: 0.783505\n",
      "Epoch 22328 - Train Loss: 0.076604, Train Acc: 0.883333 | Val Loss: 0.109300, Val Acc: 0.783505\n",
      "Epoch 22329 - Train Loss: 0.076602, Train Acc: 0.883333 | Val Loss: 0.109300, Val Acc: 0.783505\n",
      "Epoch 22330 - Train Loss: 0.076600, Train Acc: 0.883333 | Val Loss: 0.109299, Val Acc: 0.783505\n",
      "Epoch 22331 - Train Loss: 0.076598, Train Acc: 0.883333 | Val Loss: 0.109299, Val Acc: 0.783505\n",
      "Epoch 22332 - Train Loss: 0.076596, Train Acc: 0.883333 | Val Loss: 0.109298, Val Acc: 0.783505\n",
      "Epoch 22333 - Train Loss: 0.076594, Train Acc: 0.883333 | Val Loss: 0.109297, Val Acc: 0.783505\n",
      "Epoch 22334 - Train Loss: 0.076592, Train Acc: 0.883333 | Val Loss: 0.109297, Val Acc: 0.783505\n",
      "Epoch 22335 - Train Loss: 0.076591, Train Acc: 0.883333 | Val Loss: 0.109296, Val Acc: 0.783505\n",
      "Epoch 22336 - Train Loss: 0.076589, Train Acc: 0.883333 | Val Loss: 0.109296, Val Acc: 0.783505\n",
      "Epoch 22337 - Train Loss: 0.076587, Train Acc: 0.883333 | Val Loss: 0.109295, Val Acc: 0.783505\n",
      "Epoch 22338 - Train Loss: 0.076585, Train Acc: 0.883333 | Val Loss: 0.109295, Val Acc: 0.783505\n",
      "Epoch 22339 - Train Loss: 0.076583, Train Acc: 0.883333 | Val Loss: 0.109294, Val Acc: 0.783505\n",
      "Epoch 22340 - Train Loss: 0.076581, Train Acc: 0.883333 | Val Loss: 0.109294, Val Acc: 0.783505\n",
      "Epoch 22341 - Train Loss: 0.076580, Train Acc: 0.883333 | Val Loss: 0.109293, Val Acc: 0.783505\n",
      "Epoch 22342 - Train Loss: 0.076578, Train Acc: 0.883333 | Val Loss: 0.109292, Val Acc: 0.783505\n",
      "Epoch 22343 - Train Loss: 0.076576, Train Acc: 0.883333 | Val Loss: 0.109292, Val Acc: 0.783505\n",
      "Epoch 22344 - Train Loss: 0.076574, Train Acc: 0.883333 | Val Loss: 0.109291, Val Acc: 0.783505\n",
      "Epoch 22345 - Train Loss: 0.076572, Train Acc: 0.883333 | Val Loss: 0.109291, Val Acc: 0.783505\n",
      "Epoch 22346 - Train Loss: 0.076570, Train Acc: 0.883333 | Val Loss: 0.109290, Val Acc: 0.783505\n",
      "Epoch 22347 - Train Loss: 0.076569, Train Acc: 0.883333 | Val Loss: 0.109290, Val Acc: 0.783505\n",
      "Epoch 22348 - Train Loss: 0.076567, Train Acc: 0.883333 | Val Loss: 0.109289, Val Acc: 0.783505\n",
      "Epoch 22349 - Train Loss: 0.076565, Train Acc: 0.883333 | Val Loss: 0.109288, Val Acc: 0.783505\n",
      "Epoch 22350 - Train Loss: 0.076563, Train Acc: 0.883333 | Val Loss: 0.109288, Val Acc: 0.783505\n",
      "Epoch 22351 - Train Loss: 0.076561, Train Acc: 0.883333 | Val Loss: 0.109287, Val Acc: 0.783505\n",
      "Epoch 22352 - Train Loss: 0.076559, Train Acc: 0.883333 | Val Loss: 0.109287, Val Acc: 0.783505\n",
      "Epoch 22353 - Train Loss: 0.076558, Train Acc: 0.883333 | Val Loss: 0.109286, Val Acc: 0.783505\n",
      "Epoch 22354 - Train Loss: 0.076556, Train Acc: 0.883333 | Val Loss: 0.109285, Val Acc: 0.783505\n",
      "Epoch 22355 - Train Loss: 0.076554, Train Acc: 0.883333 | Val Loss: 0.109285, Val Acc: 0.783505\n",
      "Epoch 22356 - Train Loss: 0.076552, Train Acc: 0.883333 | Val Loss: 0.109284, Val Acc: 0.783505\n",
      "Epoch 22357 - Train Loss: 0.076550, Train Acc: 0.883333 | Val Loss: 0.109284, Val Acc: 0.783505\n",
      "Epoch 22358 - Train Loss: 0.076548, Train Acc: 0.883333 | Val Loss: 0.109283, Val Acc: 0.783505\n",
      "Epoch 22359 - Train Loss: 0.076546, Train Acc: 0.883333 | Val Loss: 0.109283, Val Acc: 0.783505\n",
      "Epoch 22360 - Train Loss: 0.076545, Train Acc: 0.883333 | Val Loss: 0.109282, Val Acc: 0.783505\n",
      "Epoch 22361 - Train Loss: 0.076543, Train Acc: 0.883333 | Val Loss: 0.109281, Val Acc: 0.783505\n",
      "Epoch 22362 - Train Loss: 0.076541, Train Acc: 0.883333 | Val Loss: 0.109281, Val Acc: 0.783505\n",
      "Epoch 22363 - Train Loss: 0.076539, Train Acc: 0.883333 | Val Loss: 0.109280, Val Acc: 0.783505\n",
      "Epoch 22364 - Train Loss: 0.076537, Train Acc: 0.883333 | Val Loss: 0.109280, Val Acc: 0.783505\n",
      "Epoch 22365 - Train Loss: 0.076535, Train Acc: 0.883333 | Val Loss: 0.109279, Val Acc: 0.783505\n",
      "Epoch 22366 - Train Loss: 0.076534, Train Acc: 0.883333 | Val Loss: 0.109279, Val Acc: 0.783505\n",
      "Epoch 22367 - Train Loss: 0.076532, Train Acc: 0.883333 | Val Loss: 0.109278, Val Acc: 0.783505\n",
      "Epoch 22368 - Train Loss: 0.076530, Train Acc: 0.883333 | Val Loss: 0.109278, Val Acc: 0.783505\n",
      "Epoch 22369 - Train Loss: 0.076528, Train Acc: 0.883333 | Val Loss: 0.109277, Val Acc: 0.783505\n",
      "Epoch 22370 - Train Loss: 0.076526, Train Acc: 0.883333 | Val Loss: 0.109276, Val Acc: 0.783505\n",
      "Epoch 22371 - Train Loss: 0.076524, Train Acc: 0.883333 | Val Loss: 0.109276, Val Acc: 0.783505\n",
      "Epoch 22372 - Train Loss: 0.076523, Train Acc: 0.883333 | Val Loss: 0.109275, Val Acc: 0.783505\n",
      "Epoch 22373 - Train Loss: 0.076521, Train Acc: 0.883333 | Val Loss: 0.109275, Val Acc: 0.783505\n",
      "Epoch 22374 - Train Loss: 0.076519, Train Acc: 0.883333 | Val Loss: 0.109274, Val Acc: 0.783505\n",
      "Epoch 22375 - Train Loss: 0.076517, Train Acc: 0.883333 | Val Loss: 0.109274, Val Acc: 0.783505\n",
      "Epoch 22376 - Train Loss: 0.076515, Train Acc: 0.883333 | Val Loss: 0.109273, Val Acc: 0.783505\n",
      "Epoch 22377 - Train Loss: 0.076513, Train Acc: 0.883333 | Val Loss: 0.109272, Val Acc: 0.783505\n",
      "Epoch 22378 - Train Loss: 0.076512, Train Acc: 0.883333 | Val Loss: 0.109272, Val Acc: 0.783505\n",
      "Epoch 22379 - Train Loss: 0.076510, Train Acc: 0.883333 | Val Loss: 0.109271, Val Acc: 0.783505\n",
      "Epoch 22380 - Train Loss: 0.076508, Train Acc: 0.883333 | Val Loss: 0.109271, Val Acc: 0.783505\n",
      "Epoch 22381 - Train Loss: 0.076506, Train Acc: 0.883333 | Val Loss: 0.109270, Val Acc: 0.783505\n",
      "Epoch 22382 - Train Loss: 0.076504, Train Acc: 0.883333 | Val Loss: 0.109270, Val Acc: 0.783505\n",
      "Epoch 22383 - Train Loss: 0.076502, Train Acc: 0.883333 | Val Loss: 0.109269, Val Acc: 0.783505\n",
      "Epoch 22384 - Train Loss: 0.076501, Train Acc: 0.883333 | Val Loss: 0.109268, Val Acc: 0.783505\n",
      "Epoch 22385 - Train Loss: 0.076499, Train Acc: 0.883333 | Val Loss: 0.109268, Val Acc: 0.783505\n",
      "Epoch 22386 - Train Loss: 0.076497, Train Acc: 0.883333 | Val Loss: 0.109267, Val Acc: 0.783505\n",
      "Epoch 22387 - Train Loss: 0.076495, Train Acc: 0.883333 | Val Loss: 0.109267, Val Acc: 0.783505\n",
      "Epoch 22388 - Train Loss: 0.076493, Train Acc: 0.883333 | Val Loss: 0.109266, Val Acc: 0.783505\n",
      "Epoch 22389 - Train Loss: 0.076491, Train Acc: 0.883333 | Val Loss: 0.109266, Val Acc: 0.783505\n",
      "Epoch 22390 - Train Loss: 0.076490, Train Acc: 0.883333 | Val Loss: 0.109265, Val Acc: 0.783505\n",
      "Epoch 22391 - Train Loss: 0.076488, Train Acc: 0.883333 | Val Loss: 0.109265, Val Acc: 0.783505\n",
      "Epoch 22392 - Train Loss: 0.076486, Train Acc: 0.883333 | Val Loss: 0.109264, Val Acc: 0.783505\n",
      "Epoch 22393 - Train Loss: 0.076484, Train Acc: 0.883333 | Val Loss: 0.109263, Val Acc: 0.783505\n",
      "Epoch 22394 - Train Loss: 0.076482, Train Acc: 0.883333 | Val Loss: 0.109263, Val Acc: 0.783505\n",
      "Epoch 22395 - Train Loss: 0.076480, Train Acc: 0.883333 | Val Loss: 0.109262, Val Acc: 0.783505\n",
      "Epoch 22396 - Train Loss: 0.076479, Train Acc: 0.883333 | Val Loss: 0.109262, Val Acc: 0.783505\n",
      "Epoch 22397 - Train Loss: 0.076477, Train Acc: 0.883333 | Val Loss: 0.109261, Val Acc: 0.783505\n",
      "Epoch 22398 - Train Loss: 0.076475, Train Acc: 0.883333 | Val Loss: 0.109261, Val Acc: 0.783505\n",
      "Epoch 22399 - Train Loss: 0.076473, Train Acc: 0.883333 | Val Loss: 0.109260, Val Acc: 0.783505\n",
      "Epoch 22400 - Train Loss: 0.076471, Train Acc: 0.883333 | Val Loss: 0.109259, Val Acc: 0.783505\n",
      "Epoch 22401 - Train Loss: 0.076469, Train Acc: 0.883333 | Val Loss: 0.109259, Val Acc: 0.783505\n",
      "Epoch 22402 - Train Loss: 0.076468, Train Acc: 0.883333 | Val Loss: 0.109258, Val Acc: 0.783505\n",
      "Epoch 22403 - Train Loss: 0.076466, Train Acc: 0.883333 | Val Loss: 0.109258, Val Acc: 0.783505\n",
      "Epoch 22404 - Train Loss: 0.076464, Train Acc: 0.883333 | Val Loss: 0.109257, Val Acc: 0.783505\n",
      "Epoch 22405 - Train Loss: 0.076462, Train Acc: 0.883333 | Val Loss: 0.109257, Val Acc: 0.783505\n",
      "Epoch 22406 - Train Loss: 0.076460, Train Acc: 0.883333 | Val Loss: 0.109256, Val Acc: 0.783505\n",
      "Epoch 22407 - Train Loss: 0.076458, Train Acc: 0.883333 | Val Loss: 0.109256, Val Acc: 0.783505\n",
      "Epoch 22408 - Train Loss: 0.076457, Train Acc: 0.883333 | Val Loss: 0.109255, Val Acc: 0.783505\n",
      "Epoch 22409 - Train Loss: 0.076455, Train Acc: 0.883333 | Val Loss: 0.109254, Val Acc: 0.783505\n",
      "Epoch 22410 - Train Loss: 0.076453, Train Acc: 0.883333 | Val Loss: 0.109254, Val Acc: 0.783505\n",
      "Epoch 22411 - Train Loss: 0.076451, Train Acc: 0.883333 | Val Loss: 0.109253, Val Acc: 0.783505\n",
      "Epoch 22412 - Train Loss: 0.076449, Train Acc: 0.883333 | Val Loss: 0.109253, Val Acc: 0.783505\n",
      "Epoch 22413 - Train Loss: 0.076447, Train Acc: 0.883333 | Val Loss: 0.109252, Val Acc: 0.783505\n",
      "Epoch 22414 - Train Loss: 0.076446, Train Acc: 0.883333 | Val Loss: 0.109252, Val Acc: 0.783505\n",
      "Epoch 22415 - Train Loss: 0.076444, Train Acc: 0.883333 | Val Loss: 0.109251, Val Acc: 0.783505\n",
      "Epoch 22416 - Train Loss: 0.076442, Train Acc: 0.883333 | Val Loss: 0.109250, Val Acc: 0.783505\n",
      "Epoch 22417 - Train Loss: 0.076440, Train Acc: 0.883333 | Val Loss: 0.109250, Val Acc: 0.783505\n",
      "Epoch 22418 - Train Loss: 0.076438, Train Acc: 0.883333 | Val Loss: 0.109249, Val Acc: 0.783505\n",
      "Epoch 22419 - Train Loss: 0.076436, Train Acc: 0.883333 | Val Loss: 0.109249, Val Acc: 0.783505\n",
      "Epoch 22420 - Train Loss: 0.076435, Train Acc: 0.883333 | Val Loss: 0.109248, Val Acc: 0.783505\n",
      "Epoch 22421 - Train Loss: 0.076433, Train Acc: 0.883333 | Val Loss: 0.109248, Val Acc: 0.783505\n",
      "Epoch 22422 - Train Loss: 0.076431, Train Acc: 0.883333 | Val Loss: 0.109247, Val Acc: 0.783505\n",
      "Epoch 22423 - Train Loss: 0.076429, Train Acc: 0.883333 | Val Loss: 0.109247, Val Acc: 0.783505\n",
      "Epoch 22424 - Train Loss: 0.076427, Train Acc: 0.883333 | Val Loss: 0.109246, Val Acc: 0.783505\n",
      "Epoch 22425 - Train Loss: 0.076425, Train Acc: 0.883333 | Val Loss: 0.109245, Val Acc: 0.783505\n",
      "Epoch 22426 - Train Loss: 0.076424, Train Acc: 0.883333 | Val Loss: 0.109245, Val Acc: 0.783505\n",
      "Epoch 22427 - Train Loss: 0.076422, Train Acc: 0.883333 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 22428 - Train Loss: 0.076420, Train Acc: 0.883333 | Val Loss: 0.109244, Val Acc: 0.783505\n",
      "Epoch 22429 - Train Loss: 0.076418, Train Acc: 0.883333 | Val Loss: 0.109243, Val Acc: 0.783505\n",
      "Epoch 22430 - Train Loss: 0.076416, Train Acc: 0.883333 | Val Loss: 0.109243, Val Acc: 0.783505\n",
      "Epoch 22431 - Train Loss: 0.076414, Train Acc: 0.883333 | Val Loss: 0.109242, Val Acc: 0.783505\n",
      "Epoch 22432 - Train Loss: 0.076413, Train Acc: 0.883333 | Val Loss: 0.109242, Val Acc: 0.783505\n",
      "Epoch 22433 - Train Loss: 0.076411, Train Acc: 0.883333 | Val Loss: 0.109241, Val Acc: 0.783505\n",
      "Epoch 22434 - Train Loss: 0.076409, Train Acc: 0.883333 | Val Loss: 0.109240, Val Acc: 0.783505\n",
      "Epoch 22435 - Train Loss: 0.076407, Train Acc: 0.883333 | Val Loss: 0.109240, Val Acc: 0.783505\n",
      "Epoch 22436 - Train Loss: 0.076405, Train Acc: 0.883333 | Val Loss: 0.109239, Val Acc: 0.783505\n",
      "Epoch 22437 - Train Loss: 0.076404, Train Acc: 0.883333 | Val Loss: 0.109239, Val Acc: 0.783505\n",
      "Epoch 22438 - Train Loss: 0.076402, Train Acc: 0.883333 | Val Loss: 0.109238, Val Acc: 0.783505\n",
      "Epoch 22439 - Train Loss: 0.076400, Train Acc: 0.883333 | Val Loss: 0.109238, Val Acc: 0.783505\n",
      "Epoch 22440 - Train Loss: 0.076398, Train Acc: 0.883333 | Val Loss: 0.109237, Val Acc: 0.783505\n",
      "Epoch 22441 - Train Loss: 0.076396, Train Acc: 0.883333 | Val Loss: 0.109236, Val Acc: 0.783505\n",
      "Epoch 22442 - Train Loss: 0.076394, Train Acc: 0.883333 | Val Loss: 0.109236, Val Acc: 0.783505\n",
      "Epoch 22443 - Train Loss: 0.076393, Train Acc: 0.883333 | Val Loss: 0.109235, Val Acc: 0.783505\n",
      "Epoch 22444 - Train Loss: 0.076391, Train Acc: 0.884615 | Val Loss: 0.109235, Val Acc: 0.783505\n",
      "Epoch 22445 - Train Loss: 0.076389, Train Acc: 0.883333 | Val Loss: 0.109234, Val Acc: 0.783505\n",
      "Epoch 22446 - Train Loss: 0.076387, Train Acc: 0.883333 | Val Loss: 0.109234, Val Acc: 0.783505\n",
      "Epoch 22447 - Train Loss: 0.076385, Train Acc: 0.884615 | Val Loss: 0.109233, Val Acc: 0.783505\n",
      "Epoch 22448 - Train Loss: 0.076383, Train Acc: 0.884615 | Val Loss: 0.109233, Val Acc: 0.783505\n",
      "Epoch 22449 - Train Loss: 0.076382, Train Acc: 0.884615 | Val Loss: 0.109232, Val Acc: 0.783505\n",
      "Epoch 22450 - Train Loss: 0.076380, Train Acc: 0.884615 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 22451 - Train Loss: 0.076378, Train Acc: 0.884615 | Val Loss: 0.109231, Val Acc: 0.783505\n",
      "Epoch 22452 - Train Loss: 0.076376, Train Acc: 0.884615 | Val Loss: 0.109230, Val Acc: 0.783505\n",
      "Epoch 22453 - Train Loss: 0.076374, Train Acc: 0.884615 | Val Loss: 0.109230, Val Acc: 0.783505\n",
      "Epoch 22454 - Train Loss: 0.076373, Train Acc: 0.884615 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 22455 - Train Loss: 0.076371, Train Acc: 0.884615 | Val Loss: 0.109229, Val Acc: 0.783505\n",
      "Epoch 22456 - Train Loss: 0.076369, Train Acc: 0.884615 | Val Loss: 0.109228, Val Acc: 0.783505\n",
      "Epoch 22457 - Train Loss: 0.076367, Train Acc: 0.884615 | Val Loss: 0.109228, Val Acc: 0.783505\n",
      "Epoch 22458 - Train Loss: 0.076365, Train Acc: 0.884615 | Val Loss: 0.109227, Val Acc: 0.783505\n",
      "Epoch 22459 - Train Loss: 0.076363, Train Acc: 0.884615 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 22460 - Train Loss: 0.076362, Train Acc: 0.884615 | Val Loss: 0.109226, Val Acc: 0.783505\n",
      "Epoch 22461 - Train Loss: 0.076360, Train Acc: 0.884615 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 22462 - Train Loss: 0.076358, Train Acc: 0.884615 | Val Loss: 0.109225, Val Acc: 0.783505\n",
      "Epoch 22463 - Train Loss: 0.076356, Train Acc: 0.884615 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 22464 - Train Loss: 0.076354, Train Acc: 0.884615 | Val Loss: 0.109224, Val Acc: 0.783505\n",
      "Epoch 22465 - Train Loss: 0.076352, Train Acc: 0.884615 | Val Loss: 0.109223, Val Acc: 0.783505\n",
      "Epoch 22466 - Train Loss: 0.076351, Train Acc: 0.884615 | Val Loss: 0.109223, Val Acc: 0.783505\n",
      "Epoch 22467 - Train Loss: 0.076349, Train Acc: 0.884615 | Val Loss: 0.109222, Val Acc: 0.783505\n",
      "Epoch 22468 - Train Loss: 0.076347, Train Acc: 0.884615 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 22469 - Train Loss: 0.076345, Train Acc: 0.884615 | Val Loss: 0.109221, Val Acc: 0.783505\n",
      "Epoch 22470 - Train Loss: 0.076343, Train Acc: 0.884615 | Val Loss: 0.109220, Val Acc: 0.783505\n",
      "Epoch 22471 - Train Loss: 0.076342, Train Acc: 0.884615 | Val Loss: 0.109220, Val Acc: 0.783505\n",
      "Epoch 22472 - Train Loss: 0.076340, Train Acc: 0.884615 | Val Loss: 0.109219, Val Acc: 0.783505\n",
      "Epoch 22473 - Train Loss: 0.076338, Train Acc: 0.884615 | Val Loss: 0.109219, Val Acc: 0.783505\n",
      "Epoch 22474 - Train Loss: 0.076336, Train Acc: 0.884615 | Val Loss: 0.109218, Val Acc: 0.783505\n",
      "Epoch 22475 - Train Loss: 0.076334, Train Acc: 0.884615 | Val Loss: 0.109218, Val Acc: 0.783505\n",
      "Epoch 22476 - Train Loss: 0.076332, Train Acc: 0.884615 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 22477 - Train Loss: 0.076331, Train Acc: 0.884615 | Val Loss: 0.109217, Val Acc: 0.783505\n",
      "Epoch 22478 - Train Loss: 0.076329, Train Acc: 0.884615 | Val Loss: 0.109216, Val Acc: 0.783505\n",
      "Epoch 22479 - Train Loss: 0.076327, Train Acc: 0.884615 | Val Loss: 0.109215, Val Acc: 0.783505\n",
      "Epoch 22480 - Train Loss: 0.076325, Train Acc: 0.884615 | Val Loss: 0.109215, Val Acc: 0.783505\n",
      "Epoch 22481 - Train Loss: 0.076323, Train Acc: 0.884615 | Val Loss: 0.109214, Val Acc: 0.783505\n",
      "Epoch 22482 - Train Loss: 0.076321, Train Acc: 0.884615 | Val Loss: 0.109214, Val Acc: 0.783505\n",
      "Epoch 22483 - Train Loss: 0.076320, Train Acc: 0.884615 | Val Loss: 0.109213, Val Acc: 0.783505\n",
      "Epoch 22484 - Train Loss: 0.076318, Train Acc: 0.884615 | Val Loss: 0.109213, Val Acc: 0.783505\n",
      "Epoch 22485 - Train Loss: 0.076316, Train Acc: 0.884615 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 22486 - Train Loss: 0.076314, Train Acc: 0.884615 | Val Loss: 0.109212, Val Acc: 0.783505\n",
      "Epoch 22487 - Train Loss: 0.076312, Train Acc: 0.884615 | Val Loss: 0.109211, Val Acc: 0.783505\n",
      "Epoch 22488 - Train Loss: 0.076311, Train Acc: 0.884615 | Val Loss: 0.109211, Val Acc: 0.783505\n",
      "Epoch 22489 - Train Loss: 0.076309, Train Acc: 0.884615 | Val Loss: 0.109210, Val Acc: 0.783505\n",
      "Epoch 22490 - Train Loss: 0.076307, Train Acc: 0.884615 | Val Loss: 0.109209, Val Acc: 0.783505\n",
      "Epoch 22491 - Train Loss: 0.076305, Train Acc: 0.884615 | Val Loss: 0.109209, Val Acc: 0.783505\n",
      "Epoch 22492 - Train Loss: 0.076303, Train Acc: 0.884615 | Val Loss: 0.109208, Val Acc: 0.783505\n",
      "Epoch 22493 - Train Loss: 0.076301, Train Acc: 0.884615 | Val Loss: 0.109208, Val Acc: 0.783505\n",
      "Epoch 22494 - Train Loss: 0.076300, Train Acc: 0.884615 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 22495 - Train Loss: 0.076298, Train Acc: 0.884615 | Val Loss: 0.109207, Val Acc: 0.783505\n",
      "Epoch 22496 - Train Loss: 0.076296, Train Acc: 0.884615 | Val Loss: 0.109206, Val Acc: 0.783505\n",
      "Epoch 22497 - Train Loss: 0.076294, Train Acc: 0.884615 | Val Loss: 0.109206, Val Acc: 0.783505\n",
      "Epoch 22498 - Train Loss: 0.076292, Train Acc: 0.884615 | Val Loss: 0.109205, Val Acc: 0.783505\n",
      "Epoch 22499 - Train Loss: 0.076291, Train Acc: 0.884615 | Val Loss: 0.109204, Val Acc: 0.783505\n",
      "Epoch 22500 - Train Loss: 0.076289, Train Acc: 0.884615 | Val Loss: 0.109204, Val Acc: 0.783505\n",
      "Epoch 22501 - Train Loss: 0.076287, Train Acc: 0.884615 | Val Loss: 0.109203, Val Acc: 0.783505\n",
      "Epoch 22502 - Train Loss: 0.076285, Train Acc: 0.884615 | Val Loss: 0.109203, Val Acc: 0.783505\n",
      "Epoch 22503 - Train Loss: 0.076283, Train Acc: 0.884615 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 22504 - Train Loss: 0.076282, Train Acc: 0.884615 | Val Loss: 0.109202, Val Acc: 0.783505\n",
      "Epoch 22505 - Train Loss: 0.076280, Train Acc: 0.884615 | Val Loss: 0.109201, Val Acc: 0.783505\n",
      "Epoch 22506 - Train Loss: 0.076278, Train Acc: 0.884615 | Val Loss: 0.109201, Val Acc: 0.783505\n",
      "Epoch 22507 - Train Loss: 0.076276, Train Acc: 0.884615 | Val Loss: 0.109200, Val Acc: 0.783505\n",
      "Epoch 22508 - Train Loss: 0.076274, Train Acc: 0.884615 | Val Loss: 0.109199, Val Acc: 0.783505\n",
      "Epoch 22509 - Train Loss: 0.076272, Train Acc: 0.884615 | Val Loss: 0.109199, Val Acc: 0.783505\n",
      "Epoch 22510 - Train Loss: 0.076271, Train Acc: 0.884615 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 22511 - Train Loss: 0.076269, Train Acc: 0.884615 | Val Loss: 0.109198, Val Acc: 0.783505\n",
      "Epoch 22512 - Train Loss: 0.076267, Train Acc: 0.884615 | Val Loss: 0.109197, Val Acc: 0.783505\n",
      "Epoch 22513 - Train Loss: 0.076265, Train Acc: 0.884615 | Val Loss: 0.109197, Val Acc: 0.783505\n",
      "Epoch 22514 - Train Loss: 0.076263, Train Acc: 0.884615 | Val Loss: 0.109196, Val Acc: 0.783505\n",
      "Epoch 22515 - Train Loss: 0.076262, Train Acc: 0.884615 | Val Loss: 0.109196, Val Acc: 0.783505\n",
      "Epoch 22516 - Train Loss: 0.076260, Train Acc: 0.884615 | Val Loss: 0.109195, Val Acc: 0.783505\n",
      "Epoch 22517 - Train Loss: 0.076258, Train Acc: 0.884615 | Val Loss: 0.109195, Val Acc: 0.783505\n",
      "Epoch 22518 - Train Loss: 0.076256, Train Acc: 0.884615 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 22519 - Train Loss: 0.076254, Train Acc: 0.884615 | Val Loss: 0.109194, Val Acc: 0.783505\n",
      "Epoch 22520 - Train Loss: 0.076252, Train Acc: 0.884615 | Val Loss: 0.109193, Val Acc: 0.783505\n",
      "Epoch 22521 - Train Loss: 0.076251, Train Acc: 0.884615 | Val Loss: 0.109192, Val Acc: 0.783505\n",
      "Epoch 22522 - Train Loss: 0.076249, Train Acc: 0.884615 | Val Loss: 0.109192, Val Acc: 0.783505\n",
      "Epoch 22523 - Train Loss: 0.076247, Train Acc: 0.884615 | Val Loss: 0.109191, Val Acc: 0.783505\n",
      "Epoch 22524 - Train Loss: 0.076245, Train Acc: 0.884615 | Val Loss: 0.109191, Val Acc: 0.783505\n",
      "Epoch 22525 - Train Loss: 0.076243, Train Acc: 0.884615 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 22526 - Train Loss: 0.076242, Train Acc: 0.884615 | Val Loss: 0.109190, Val Acc: 0.783505\n",
      "Epoch 22527 - Train Loss: 0.076240, Train Acc: 0.884615 | Val Loss: 0.109189, Val Acc: 0.783505\n",
      "Epoch 22528 - Train Loss: 0.076238, Train Acc: 0.884615 | Val Loss: 0.109189, Val Acc: 0.783505\n",
      "Epoch 22529 - Train Loss: 0.076236, Train Acc: 0.884615 | Val Loss: 0.109188, Val Acc: 0.783505\n",
      "Epoch 22530 - Train Loss: 0.076234, Train Acc: 0.884615 | Val Loss: 0.109187, Val Acc: 0.783505\n",
      "Epoch 22531 - Train Loss: 0.076233, Train Acc: 0.884615 | Val Loss: 0.109187, Val Acc: 0.783505\n",
      "Epoch 22532 - Train Loss: 0.076231, Train Acc: 0.884615 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 22533 - Train Loss: 0.076229, Train Acc: 0.884615 | Val Loss: 0.109186, Val Acc: 0.783505\n",
      "Epoch 22534 - Train Loss: 0.076227, Train Acc: 0.884615 | Val Loss: 0.109185, Val Acc: 0.783505\n",
      "Epoch 22535 - Train Loss: 0.076225, Train Acc: 0.884615 | Val Loss: 0.109185, Val Acc: 0.783505\n",
      "Epoch 22536 - Train Loss: 0.076223, Train Acc: 0.884615 | Val Loss: 0.109184, Val Acc: 0.783505\n",
      "Epoch 22537 - Train Loss: 0.076222, Train Acc: 0.884615 | Val Loss: 0.109184, Val Acc: 0.783505\n",
      "Epoch 22538 - Train Loss: 0.076220, Train Acc: 0.884615 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 22539 - Train Loss: 0.076218, Train Acc: 0.884615 | Val Loss: 0.109183, Val Acc: 0.783505\n",
      "Epoch 22540 - Train Loss: 0.076216, Train Acc: 0.884615 | Val Loss: 0.109182, Val Acc: 0.783505\n",
      "Epoch 22541 - Train Loss: 0.076214, Train Acc: 0.884615 | Val Loss: 0.109182, Val Acc: 0.783505\n",
      "Epoch 22542 - Train Loss: 0.076213, Train Acc: 0.884615 | Val Loss: 0.109181, Val Acc: 0.783505\n",
      "Epoch 22543 - Train Loss: 0.076211, Train Acc: 0.884615 | Val Loss: 0.109180, Val Acc: 0.783505\n",
      "Epoch 22544 - Train Loss: 0.076209, Train Acc: 0.884615 | Val Loss: 0.109180, Val Acc: 0.783505\n",
      "Epoch 22545 - Train Loss: 0.076207, Train Acc: 0.884615 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 22546 - Train Loss: 0.076205, Train Acc: 0.884615 | Val Loss: 0.109179, Val Acc: 0.783505\n",
      "Epoch 22547 - Train Loss: 0.076204, Train Acc: 0.884615 | Val Loss: 0.109178, Val Acc: 0.783505\n",
      "Epoch 22548 - Train Loss: 0.076202, Train Acc: 0.884615 | Val Loss: 0.109178, Val Acc: 0.783505\n",
      "Epoch 22549 - Train Loss: 0.076200, Train Acc: 0.884615 | Val Loss: 0.109177, Val Acc: 0.783505\n",
      "Epoch 22550 - Train Loss: 0.076198, Train Acc: 0.884615 | Val Loss: 0.109177, Val Acc: 0.783505\n",
      "Epoch 22551 - Train Loss: 0.076196, Train Acc: 0.884615 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 22552 - Train Loss: 0.076195, Train Acc: 0.884615 | Val Loss: 0.109176, Val Acc: 0.783505\n",
      "Epoch 22553 - Train Loss: 0.076193, Train Acc: 0.884615 | Val Loss: 0.109175, Val Acc: 0.783505\n",
      "Epoch 22554 - Train Loss: 0.076191, Train Acc: 0.884615 | Val Loss: 0.109174, Val Acc: 0.783505\n",
      "Epoch 22555 - Train Loss: 0.076189, Train Acc: 0.884615 | Val Loss: 0.109174, Val Acc: 0.783505\n",
      "Epoch 22556 - Train Loss: 0.076187, Train Acc: 0.884615 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 22557 - Train Loss: 0.076185, Train Acc: 0.884615 | Val Loss: 0.109173, Val Acc: 0.783505\n",
      "Epoch 22558 - Train Loss: 0.076184, Train Acc: 0.884615 | Val Loss: 0.109172, Val Acc: 0.783505\n",
      "Epoch 22559 - Train Loss: 0.076182, Train Acc: 0.884615 | Val Loss: 0.109172, Val Acc: 0.783505\n",
      "Epoch 22560 - Train Loss: 0.076180, Train Acc: 0.884615 | Val Loss: 0.109171, Val Acc: 0.783505\n",
      "Epoch 22561 - Train Loss: 0.076178, Train Acc: 0.884615 | Val Loss: 0.109171, Val Acc: 0.783505\n",
      "Epoch 22562 - Train Loss: 0.076176, Train Acc: 0.884615 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 22563 - Train Loss: 0.076175, Train Acc: 0.884615 | Val Loss: 0.109170, Val Acc: 0.783505\n",
      "Epoch 22564 - Train Loss: 0.076173, Train Acc: 0.884615 | Val Loss: 0.109169, Val Acc: 0.783505\n",
      "Epoch 22565 - Train Loss: 0.076171, Train Acc: 0.884615 | Val Loss: 0.109169, Val Acc: 0.783505\n",
      "Epoch 22566 - Train Loss: 0.076169, Train Acc: 0.884615 | Val Loss: 0.109168, Val Acc: 0.783505\n",
      "Epoch 22567 - Train Loss: 0.076167, Train Acc: 0.884615 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 22568 - Train Loss: 0.076166, Train Acc: 0.884615 | Val Loss: 0.109167, Val Acc: 0.783505\n",
      "Epoch 22569 - Train Loss: 0.076164, Train Acc: 0.884615 | Val Loss: 0.109166, Val Acc: 0.783505\n",
      "Epoch 22570 - Train Loss: 0.076162, Train Acc: 0.884615 | Val Loss: 0.109166, Val Acc: 0.783505\n",
      "Epoch 22571 - Train Loss: 0.076160, Train Acc: 0.884615 | Val Loss: 0.109165, Val Acc: 0.783505\n",
      "Epoch 22572 - Train Loss: 0.076158, Train Acc: 0.884615 | Val Loss: 0.109165, Val Acc: 0.783505\n",
      "Epoch 22573 - Train Loss: 0.076157, Train Acc: 0.885897 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 22574 - Train Loss: 0.076155, Train Acc: 0.885897 | Val Loss: 0.109164, Val Acc: 0.783505\n",
      "Epoch 22575 - Train Loss: 0.076153, Train Acc: 0.885897 | Val Loss: 0.109163, Val Acc: 0.783505\n",
      "Epoch 22576 - Train Loss: 0.076151, Train Acc: 0.885897 | Val Loss: 0.109163, Val Acc: 0.783505\n",
      "Epoch 22577 - Train Loss: 0.076149, Train Acc: 0.885897 | Val Loss: 0.109162, Val Acc: 0.783505\n",
      "Epoch 22578 - Train Loss: 0.076148, Train Acc: 0.885897 | Val Loss: 0.109162, Val Acc: 0.783505\n",
      "Epoch 22579 - Train Loss: 0.076146, Train Acc: 0.885897 | Val Loss: 0.109161, Val Acc: 0.783505\n",
      "Epoch 22580 - Train Loss: 0.076144, Train Acc: 0.885897 | Val Loss: 0.109160, Val Acc: 0.783505\n",
      "Epoch 22581 - Train Loss: 0.076142, Train Acc: 0.885897 | Val Loss: 0.109160, Val Acc: 0.783505\n",
      "Epoch 22582 - Train Loss: 0.076140, Train Acc: 0.885897 | Val Loss: 0.109159, Val Acc: 0.783505\n",
      "Epoch 22583 - Train Loss: 0.076139, Train Acc: 0.885897 | Val Loss: 0.109159, Val Acc: 0.783505\n",
      "Epoch 22584 - Train Loss: 0.076137, Train Acc: 0.885897 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 22585 - Train Loss: 0.076135, Train Acc: 0.885897 | Val Loss: 0.109158, Val Acc: 0.783505\n",
      "Epoch 22586 - Train Loss: 0.076133, Train Acc: 0.885897 | Val Loss: 0.109157, Val Acc: 0.783505\n",
      "Epoch 22587 - Train Loss: 0.076131, Train Acc: 0.887179 | Val Loss: 0.109157, Val Acc: 0.783505\n",
      "Epoch 22588 - Train Loss: 0.076130, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 22589 - Train Loss: 0.076128, Train Acc: 0.887179 | Val Loss: 0.109156, Val Acc: 0.783505\n",
      "Epoch 22590 - Train Loss: 0.076126, Train Acc: 0.887179 | Val Loss: 0.109155, Val Acc: 0.783505\n",
      "Epoch 22591 - Train Loss: 0.076124, Train Acc: 0.887179 | Val Loss: 0.109155, Val Acc: 0.783505\n",
      "Epoch 22592 - Train Loss: 0.076122, Train Acc: 0.887179 | Val Loss: 0.109154, Val Acc: 0.783505\n",
      "Epoch 22593 - Train Loss: 0.076121, Train Acc: 0.887179 | Val Loss: 0.109154, Val Acc: 0.783505\n",
      "Epoch 22594 - Train Loss: 0.076119, Train Acc: 0.887179 | Val Loss: 0.109153, Val Acc: 0.783505\n",
      "Epoch 22595 - Train Loss: 0.076117, Train Acc: 0.887179 | Val Loss: 0.109152, Val Acc: 0.783505\n",
      "Epoch 22596 - Train Loss: 0.076115, Train Acc: 0.887179 | Val Loss: 0.109152, Val Acc: 0.783505\n",
      "Epoch 22597 - Train Loss: 0.076113, Train Acc: 0.887179 | Val Loss: 0.109151, Val Acc: 0.783505\n",
      "Epoch 22598 - Train Loss: 0.076112, Train Acc: 0.887179 | Val Loss: 0.109151, Val Acc: 0.783505\n",
      "Epoch 22599 - Train Loss: 0.076110, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 22600 - Train Loss: 0.076108, Train Acc: 0.887179 | Val Loss: 0.109150, Val Acc: 0.783505\n",
      "Epoch 22601 - Train Loss: 0.076106, Train Acc: 0.887179 | Val Loss: 0.109149, Val Acc: 0.783505\n",
      "Epoch 22602 - Train Loss: 0.076104, Train Acc: 0.887179 | Val Loss: 0.109149, Val Acc: 0.783505\n",
      "Epoch 22603 - Train Loss: 0.076102, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 22604 - Train Loss: 0.076101, Train Acc: 0.887179 | Val Loss: 0.109148, Val Acc: 0.783505\n",
      "Epoch 22605 - Train Loss: 0.076099, Train Acc: 0.887179 | Val Loss: 0.109147, Val Acc: 0.783505\n",
      "Epoch 22606 - Train Loss: 0.076097, Train Acc: 0.887179 | Val Loss: 0.109147, Val Acc: 0.783505\n",
      "Epoch 22607 - Train Loss: 0.076095, Train Acc: 0.887179 | Val Loss: 0.109146, Val Acc: 0.783505\n",
      "Epoch 22608 - Train Loss: 0.076093, Train Acc: 0.887179 | Val Loss: 0.109145, Val Acc: 0.783505\n",
      "Epoch 22609 - Train Loss: 0.076092, Train Acc: 0.887179 | Val Loss: 0.109145, Val Acc: 0.783505\n",
      "Epoch 22610 - Train Loss: 0.076090, Train Acc: 0.887179 | Val Loss: 0.109144, Val Acc: 0.783505\n",
      "Epoch 22611 - Train Loss: 0.076088, Train Acc: 0.887179 | Val Loss: 0.109144, Val Acc: 0.783505\n",
      "Epoch 22612 - Train Loss: 0.076086, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 22613 - Train Loss: 0.076085, Train Acc: 0.887179 | Val Loss: 0.109143, Val Acc: 0.783505\n",
      "Epoch 22614 - Train Loss: 0.076083, Train Acc: 0.887179 | Val Loss: 0.109142, Val Acc: 0.783505\n",
      "Epoch 22615 - Train Loss: 0.076081, Train Acc: 0.887179 | Val Loss: 0.109142, Val Acc: 0.783505\n",
      "Epoch 22616 - Train Loss: 0.076079, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 22617 - Train Loss: 0.076077, Train Acc: 0.887179 | Val Loss: 0.109141, Val Acc: 0.783505\n",
      "Epoch 22618 - Train Loss: 0.076076, Train Acc: 0.887179 | Val Loss: 0.109140, Val Acc: 0.783505\n",
      "Epoch 22619 - Train Loss: 0.076074, Train Acc: 0.887179 | Val Loss: 0.109140, Val Acc: 0.783505\n",
      "Epoch 22620 - Train Loss: 0.076072, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 22621 - Train Loss: 0.076070, Train Acc: 0.887179 | Val Loss: 0.109139, Val Acc: 0.783505\n",
      "Epoch 22622 - Train Loss: 0.076068, Train Acc: 0.887179 | Val Loss: 0.109138, Val Acc: 0.783505\n",
      "Epoch 22623 - Train Loss: 0.076067, Train Acc: 0.887179 | Val Loss: 0.109137, Val Acc: 0.783505\n",
      "Epoch 22624 - Train Loss: 0.076065, Train Acc: 0.887179 | Val Loss: 0.109137, Val Acc: 0.783505\n",
      "Epoch 22625 - Train Loss: 0.076063, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 22626 - Train Loss: 0.076061, Train Acc: 0.887179 | Val Loss: 0.109136, Val Acc: 0.783505\n",
      "Epoch 22627 - Train Loss: 0.076059, Train Acc: 0.887179 | Val Loss: 0.109135, Val Acc: 0.783505\n",
      "Epoch 22628 - Train Loss: 0.076058, Train Acc: 0.887179 | Val Loss: 0.109135, Val Acc: 0.783505\n",
      "Epoch 22629 - Train Loss: 0.076056, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 22630 - Train Loss: 0.076054, Train Acc: 0.887179 | Val Loss: 0.109134, Val Acc: 0.783505\n",
      "Epoch 22631 - Train Loss: 0.076052, Train Acc: 0.887179 | Val Loss: 0.109133, Val Acc: 0.783505\n",
      "Epoch 22632 - Train Loss: 0.076050, Train Acc: 0.887179 | Val Loss: 0.109133, Val Acc: 0.783505\n",
      "Epoch 22633 - Train Loss: 0.076049, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 22634 - Train Loss: 0.076047, Train Acc: 0.887179 | Val Loss: 0.109132, Val Acc: 0.783505\n",
      "Epoch 22635 - Train Loss: 0.076045, Train Acc: 0.887179 | Val Loss: 0.109131, Val Acc: 0.783505\n",
      "Epoch 22636 - Train Loss: 0.076043, Train Acc: 0.887179 | Val Loss: 0.109131, Val Acc: 0.783505\n",
      "Epoch 22637 - Train Loss: 0.076041, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 22638 - Train Loss: 0.076040, Train Acc: 0.887179 | Val Loss: 0.109130, Val Acc: 0.783505\n",
      "Epoch 22639 - Train Loss: 0.076038, Train Acc: 0.887179 | Val Loss: 0.109129, Val Acc: 0.783505\n",
      "Epoch 22640 - Train Loss: 0.076036, Train Acc: 0.887179 | Val Loss: 0.109129, Val Acc: 0.783505\n",
      "Epoch 22641 - Train Loss: 0.076034, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 22642 - Train Loss: 0.076032, Train Acc: 0.887179 | Val Loss: 0.109128, Val Acc: 0.783505\n",
      "Epoch 22643 - Train Loss: 0.076031, Train Acc: 0.887179 | Val Loss: 0.109127, Val Acc: 0.783505\n",
      "Epoch 22644 - Train Loss: 0.076029, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 22645 - Train Loss: 0.076027, Train Acc: 0.887179 | Val Loss: 0.109126, Val Acc: 0.783505\n",
      "Epoch 22646 - Train Loss: 0.076025, Train Acc: 0.887179 | Val Loss: 0.109125, Val Acc: 0.783505\n",
      "Epoch 22647 - Train Loss: 0.076023, Train Acc: 0.887179 | Val Loss: 0.109125, Val Acc: 0.783505\n",
      "Epoch 22648 - Train Loss: 0.076022, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 22649 - Train Loss: 0.076020, Train Acc: 0.887179 | Val Loss: 0.109124, Val Acc: 0.783505\n",
      "Epoch 22650 - Train Loss: 0.076018, Train Acc: 0.887179 | Val Loss: 0.109123, Val Acc: 0.783505\n",
      "Epoch 22651 - Train Loss: 0.076016, Train Acc: 0.887179 | Val Loss: 0.109123, Val Acc: 0.783505\n",
      "Epoch 22652 - Train Loss: 0.076014, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 22653 - Train Loss: 0.076013, Train Acc: 0.887179 | Val Loss: 0.109122, Val Acc: 0.783505\n",
      "Epoch 22654 - Train Loss: 0.076011, Train Acc: 0.887179 | Val Loss: 0.109121, Val Acc: 0.783505\n",
      "Epoch 22655 - Train Loss: 0.076009, Train Acc: 0.887179 | Val Loss: 0.109121, Val Acc: 0.783505\n",
      "Epoch 22656 - Train Loss: 0.076007, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 22657 - Train Loss: 0.076006, Train Acc: 0.887179 | Val Loss: 0.109120, Val Acc: 0.783505\n",
      "Epoch 22658 - Train Loss: 0.076004, Train Acc: 0.887179 | Val Loss: 0.109119, Val Acc: 0.783505\n",
      "Epoch 22659 - Train Loss: 0.076002, Train Acc: 0.887179 | Val Loss: 0.109119, Val Acc: 0.783505\n",
      "Epoch 22660 - Train Loss: 0.076000, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 22661 - Train Loss: 0.075998, Train Acc: 0.887179 | Val Loss: 0.109118, Val Acc: 0.783505\n",
      "Epoch 22662 - Train Loss: 0.075997, Train Acc: 0.887179 | Val Loss: 0.109117, Val Acc: 0.783505\n",
      "Epoch 22663 - Train Loss: 0.075995, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 22664 - Train Loss: 0.075993, Train Acc: 0.887179 | Val Loss: 0.109116, Val Acc: 0.783505\n",
      "Epoch 22665 - Train Loss: 0.075991, Train Acc: 0.887179 | Val Loss: 0.109115, Val Acc: 0.783505\n",
      "Epoch 22666 - Train Loss: 0.075989, Train Acc: 0.887179 | Val Loss: 0.109115, Val Acc: 0.783505\n",
      "Epoch 22667 - Train Loss: 0.075988, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 22668 - Train Loss: 0.075986, Train Acc: 0.887179 | Val Loss: 0.109114, Val Acc: 0.783505\n",
      "Epoch 22669 - Train Loss: 0.075984, Train Acc: 0.887179 | Val Loss: 0.109113, Val Acc: 0.783505\n",
      "Epoch 22670 - Train Loss: 0.075982, Train Acc: 0.887179 | Val Loss: 0.109113, Val Acc: 0.783505\n",
      "Epoch 22671 - Train Loss: 0.075980, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 22672 - Train Loss: 0.075979, Train Acc: 0.887179 | Val Loss: 0.109112, Val Acc: 0.783505\n",
      "Epoch 22673 - Train Loss: 0.075977, Train Acc: 0.887179 | Val Loss: 0.109111, Val Acc: 0.783505\n",
      "Epoch 22674 - Train Loss: 0.075975, Train Acc: 0.887179 | Val Loss: 0.109111, Val Acc: 0.783505\n",
      "Epoch 22675 - Train Loss: 0.075973, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 22676 - Train Loss: 0.075972, Train Acc: 0.887179 | Val Loss: 0.109110, Val Acc: 0.783505\n",
      "Epoch 22677 - Train Loss: 0.075970, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 22678 - Train Loss: 0.075968, Train Acc: 0.887179 | Val Loss: 0.109109, Val Acc: 0.783505\n",
      "Epoch 22679 - Train Loss: 0.075966, Train Acc: 0.887179 | Val Loss: 0.109108, Val Acc: 0.783505\n",
      "Epoch 22680 - Train Loss: 0.075964, Train Acc: 0.887179 | Val Loss: 0.109108, Val Acc: 0.783505\n",
      "Epoch 22681 - Train Loss: 0.075963, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 22682 - Train Loss: 0.075961, Train Acc: 0.887179 | Val Loss: 0.109107, Val Acc: 0.783505\n",
      "Epoch 22683 - Train Loss: 0.075959, Train Acc: 0.887179 | Val Loss: 0.109106, Val Acc: 0.783505\n",
      "Epoch 22684 - Train Loss: 0.075957, Train Acc: 0.887179 | Val Loss: 0.109106, Val Acc: 0.783505\n",
      "Epoch 22685 - Train Loss: 0.075955, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 22686 - Train Loss: 0.075954, Train Acc: 0.887179 | Val Loss: 0.109105, Val Acc: 0.783505\n",
      "Epoch 22687 - Train Loss: 0.075952, Train Acc: 0.887179 | Val Loss: 0.109104, Val Acc: 0.783505\n",
      "Epoch 22688 - Train Loss: 0.075950, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 22689 - Train Loss: 0.075948, Train Acc: 0.887179 | Val Loss: 0.109103, Val Acc: 0.783505\n",
      "Epoch 22690 - Train Loss: 0.075946, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 22691 - Train Loss: 0.075945, Train Acc: 0.887179 | Val Loss: 0.109102, Val Acc: 0.783505\n",
      "Epoch 22692 - Train Loss: 0.075943, Train Acc: 0.887179 | Val Loss: 0.109101, Val Acc: 0.783505\n",
      "Epoch 22693 - Train Loss: 0.075941, Train Acc: 0.887179 | Val Loss: 0.109101, Val Acc: 0.783505\n",
      "Epoch 22694 - Train Loss: 0.075939, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 22695 - Train Loss: 0.075938, Train Acc: 0.887179 | Val Loss: 0.109100, Val Acc: 0.783505\n",
      "Epoch 22696 - Train Loss: 0.075936, Train Acc: 0.887179 | Val Loss: 0.109099, Val Acc: 0.783505\n",
      "Epoch 22697 - Train Loss: 0.075934, Train Acc: 0.887179 | Val Loss: 0.109099, Val Acc: 0.783505\n",
      "Epoch 22698 - Train Loss: 0.075932, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 22699 - Train Loss: 0.075930, Train Acc: 0.887179 | Val Loss: 0.109098, Val Acc: 0.783505\n",
      "Epoch 22700 - Train Loss: 0.075929, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 22701 - Train Loss: 0.075927, Train Acc: 0.887179 | Val Loss: 0.109097, Val Acc: 0.783505\n",
      "Epoch 22702 - Train Loss: 0.075925, Train Acc: 0.887179 | Val Loss: 0.109096, Val Acc: 0.783505\n",
      "Epoch 22703 - Train Loss: 0.075923, Train Acc: 0.887179 | Val Loss: 0.109096, Val Acc: 0.783505\n",
      "Epoch 22704 - Train Loss: 0.075921, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 22705 - Train Loss: 0.075920, Train Acc: 0.887179 | Val Loss: 0.109095, Val Acc: 0.783505\n",
      "Epoch 22706 - Train Loss: 0.075918, Train Acc: 0.887179 | Val Loss: 0.109094, Val Acc: 0.783505\n",
      "Epoch 22707 - Train Loss: 0.075916, Train Acc: 0.887179 | Val Loss: 0.109094, Val Acc: 0.783505\n",
      "Epoch 22708 - Train Loss: 0.075914, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 22709 - Train Loss: 0.075913, Train Acc: 0.887179 | Val Loss: 0.109093, Val Acc: 0.783505\n",
      "Epoch 22710 - Train Loss: 0.075911, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 22711 - Train Loss: 0.075909, Train Acc: 0.887179 | Val Loss: 0.109092, Val Acc: 0.783505\n",
      "Epoch 22712 - Train Loss: 0.075907, Train Acc: 0.887179 | Val Loss: 0.109091, Val Acc: 0.783505\n",
      "Epoch 22713 - Train Loss: 0.075905, Train Acc: 0.887179 | Val Loss: 0.109091, Val Acc: 0.783505\n",
      "Epoch 22714 - Train Loss: 0.075904, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 22715 - Train Loss: 0.075902, Train Acc: 0.887179 | Val Loss: 0.109090, Val Acc: 0.783505\n",
      "Epoch 22716 - Train Loss: 0.075900, Train Acc: 0.887179 | Val Loss: 0.109089, Val Acc: 0.783505\n",
      "Epoch 22717 - Train Loss: 0.075898, Train Acc: 0.887179 | Val Loss: 0.109088, Val Acc: 0.783505\n",
      "Epoch 22718 - Train Loss: 0.075897, Train Acc: 0.887179 | Val Loss: 0.109088, Val Acc: 0.783505\n",
      "Epoch 22719 - Train Loss: 0.075895, Train Acc: 0.887179 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 22720 - Train Loss: 0.075893, Train Acc: 0.887179 | Val Loss: 0.109087, Val Acc: 0.783505\n",
      "Epoch 22721 - Train Loss: 0.075891, Train Acc: 0.887179 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 22722 - Train Loss: 0.075889, Train Acc: 0.887179 | Val Loss: 0.109086, Val Acc: 0.783505\n",
      "Epoch 22723 - Train Loss: 0.075888, Train Acc: 0.887179 | Val Loss: 0.109085, Val Acc: 0.783505\n",
      "Epoch 22724 - Train Loss: 0.075886, Train Acc: 0.887179 | Val Loss: 0.109085, Val Acc: 0.783505\n",
      "Epoch 22725 - Train Loss: 0.075884, Train Acc: 0.887179 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 22726 - Train Loss: 0.075882, Train Acc: 0.887179 | Val Loss: 0.109084, Val Acc: 0.783505\n",
      "Epoch 22727 - Train Loss: 0.075880, Train Acc: 0.887179 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 22728 - Train Loss: 0.075879, Train Acc: 0.887179 | Val Loss: 0.109083, Val Acc: 0.783505\n",
      "Epoch 22729 - Train Loss: 0.075877, Train Acc: 0.887179 | Val Loss: 0.109082, Val Acc: 0.783505\n",
      "Epoch 22730 - Train Loss: 0.075875, Train Acc: 0.887179 | Val Loss: 0.109082, Val Acc: 0.783505\n",
      "Epoch 22731 - Train Loss: 0.075873, Train Acc: 0.887179 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 22732 - Train Loss: 0.075872, Train Acc: 0.887179 | Val Loss: 0.109081, Val Acc: 0.783505\n",
      "Epoch 22733 - Train Loss: 0.075870, Train Acc: 0.887179 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 22734 - Train Loss: 0.075868, Train Acc: 0.887179 | Val Loss: 0.109080, Val Acc: 0.783505\n",
      "Epoch 22735 - Train Loss: 0.075866, Train Acc: 0.887179 | Val Loss: 0.109079, Val Acc: 0.783505\n",
      "Epoch 22736 - Train Loss: 0.075864, Train Acc: 0.887179 | Val Loss: 0.109079, Val Acc: 0.783505\n",
      "Epoch 22737 - Train Loss: 0.075863, Train Acc: 0.887179 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 22738 - Train Loss: 0.075861, Train Acc: 0.887179 | Val Loss: 0.109078, Val Acc: 0.783505\n",
      "Epoch 22739 - Train Loss: 0.075859, Train Acc: 0.887179 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 22740 - Train Loss: 0.075857, Train Acc: 0.887179 | Val Loss: 0.109077, Val Acc: 0.783505\n",
      "Epoch 22741 - Train Loss: 0.075856, Train Acc: 0.887179 | Val Loss: 0.109076, Val Acc: 0.783505\n",
      "Epoch 22742 - Train Loss: 0.075854, Train Acc: 0.887179 | Val Loss: 0.109076, Val Acc: 0.783505\n",
      "Epoch 22743 - Train Loss: 0.075852, Train Acc: 0.887179 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 22744 - Train Loss: 0.075850, Train Acc: 0.887179 | Val Loss: 0.109075, Val Acc: 0.783505\n",
      "Epoch 22745 - Train Loss: 0.075848, Train Acc: 0.887179 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 22746 - Train Loss: 0.075847, Train Acc: 0.887179 | Val Loss: 0.109074, Val Acc: 0.783505\n",
      "Epoch 22747 - Train Loss: 0.075845, Train Acc: 0.887179 | Val Loss: 0.109073, Val Acc: 0.783505\n",
      "Epoch 22748 - Train Loss: 0.075843, Train Acc: 0.887179 | Val Loss: 0.109073, Val Acc: 0.783505\n",
      "Epoch 22749 - Train Loss: 0.075841, Train Acc: 0.887179 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 22750 - Train Loss: 0.075840, Train Acc: 0.887179 | Val Loss: 0.109072, Val Acc: 0.783505\n",
      "Epoch 22751 - Train Loss: 0.075838, Train Acc: 0.887179 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 22752 - Train Loss: 0.075836, Train Acc: 0.887179 | Val Loss: 0.109071, Val Acc: 0.783505\n",
      "Epoch 22753 - Train Loss: 0.075834, Train Acc: 0.887179 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 22754 - Train Loss: 0.075832, Train Acc: 0.887179 | Val Loss: 0.109070, Val Acc: 0.783505\n",
      "Epoch 22755 - Train Loss: 0.075831, Train Acc: 0.887179 | Val Loss: 0.109069, Val Acc: 0.783505\n",
      "Epoch 22756 - Train Loss: 0.075829, Train Acc: 0.887179 | Val Loss: 0.109069, Val Acc: 0.783505\n",
      "Epoch 22757 - Train Loss: 0.075827, Train Acc: 0.887179 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 22758 - Train Loss: 0.075825, Train Acc: 0.887179 | Val Loss: 0.109068, Val Acc: 0.783505\n",
      "Epoch 22759 - Train Loss: 0.075824, Train Acc: 0.887179 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 22760 - Train Loss: 0.075822, Train Acc: 0.887179 | Val Loss: 0.109067, Val Acc: 0.783505\n",
      "Epoch 22761 - Train Loss: 0.075820, Train Acc: 0.887179 | Val Loss: 0.109066, Val Acc: 0.783505\n",
      "Epoch 22762 - Train Loss: 0.075818, Train Acc: 0.887179 | Val Loss: 0.109066, Val Acc: 0.783505\n",
      "Epoch 22763 - Train Loss: 0.075816, Train Acc: 0.887179 | Val Loss: 0.109065, Val Acc: 0.783505\n",
      "Epoch 22764 - Train Loss: 0.075815, Train Acc: 0.887179 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 22765 - Train Loss: 0.075813, Train Acc: 0.887179 | Val Loss: 0.109064, Val Acc: 0.783505\n",
      "Epoch 22766 - Train Loss: 0.075811, Train Acc: 0.887179 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 22767 - Train Loss: 0.075809, Train Acc: 0.887179 | Val Loss: 0.109063, Val Acc: 0.783505\n",
      "Epoch 22768 - Train Loss: 0.075808, Train Acc: 0.887179 | Val Loss: 0.109062, Val Acc: 0.783505\n",
      "Epoch 22769 - Train Loss: 0.075806, Train Acc: 0.887179 | Val Loss: 0.109062, Val Acc: 0.783505\n",
      "Epoch 22770 - Train Loss: 0.075804, Train Acc: 0.887179 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 22771 - Train Loss: 0.075802, Train Acc: 0.887179 | Val Loss: 0.109061, Val Acc: 0.783505\n",
      "Epoch 22772 - Train Loss: 0.075800, Train Acc: 0.887179 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 22773 - Train Loss: 0.075799, Train Acc: 0.887179 | Val Loss: 0.109060, Val Acc: 0.783505\n",
      "Epoch 22774 - Train Loss: 0.075797, Train Acc: 0.887179 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 22775 - Train Loss: 0.075795, Train Acc: 0.887179 | Val Loss: 0.109059, Val Acc: 0.783505\n",
      "Epoch 22776 - Train Loss: 0.075793, Train Acc: 0.887179 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 22777 - Train Loss: 0.075792, Train Acc: 0.887179 | Val Loss: 0.109058, Val Acc: 0.783505\n",
      "Epoch 22778 - Train Loss: 0.075790, Train Acc: 0.887179 | Val Loss: 0.109057, Val Acc: 0.783505\n",
      "Epoch 22779 - Train Loss: 0.075788, Train Acc: 0.887179 | Val Loss: 0.109057, Val Acc: 0.783505\n",
      "Epoch 22780 - Train Loss: 0.075786, Train Acc: 0.887179 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 22781 - Train Loss: 0.075785, Train Acc: 0.887179 | Val Loss: 0.109056, Val Acc: 0.783505\n",
      "Epoch 22782 - Train Loss: 0.075783, Train Acc: 0.887179 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 22783 - Train Loss: 0.075781, Train Acc: 0.887179 | Val Loss: 0.109055, Val Acc: 0.783505\n",
      "Epoch 22784 - Train Loss: 0.075779, Train Acc: 0.887179 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 22785 - Train Loss: 0.075777, Train Acc: 0.887179 | Val Loss: 0.109054, Val Acc: 0.783505\n",
      "Epoch 22786 - Train Loss: 0.075776, Train Acc: 0.887179 | Val Loss: 0.109053, Val Acc: 0.783505\n",
      "Epoch 22787 - Train Loss: 0.075774, Train Acc: 0.887179 | Val Loss: 0.109053, Val Acc: 0.783505\n",
      "Epoch 22788 - Train Loss: 0.075772, Train Acc: 0.887179 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 22789 - Train Loss: 0.075770, Train Acc: 0.887179 | Val Loss: 0.109052, Val Acc: 0.783505\n",
      "Epoch 22790 - Train Loss: 0.075769, Train Acc: 0.887179 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 22791 - Train Loss: 0.075767, Train Acc: 0.887179 | Val Loss: 0.109051, Val Acc: 0.783505\n",
      "Epoch 22792 - Train Loss: 0.075765, Train Acc: 0.887179 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 22793 - Train Loss: 0.075763, Train Acc: 0.887179 | Val Loss: 0.109050, Val Acc: 0.783505\n",
      "Epoch 22794 - Train Loss: 0.075761, Train Acc: 0.887179 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 22795 - Train Loss: 0.075760, Train Acc: 0.887179 | Val Loss: 0.109049, Val Acc: 0.783505\n",
      "Epoch 22796 - Train Loss: 0.075758, Train Acc: 0.887179 | Val Loss: 0.109048, Val Acc: 0.783505\n",
      "Epoch 22797 - Train Loss: 0.075756, Train Acc: 0.887179 | Val Loss: 0.109048, Val Acc: 0.783505\n",
      "Epoch 22798 - Train Loss: 0.075754, Train Acc: 0.887179 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 22799 - Train Loss: 0.075753, Train Acc: 0.887179 | Val Loss: 0.109047, Val Acc: 0.783505\n",
      "Epoch 22800 - Train Loss: 0.075751, Train Acc: 0.887179 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 22801 - Train Loss: 0.075749, Train Acc: 0.887179 | Val Loss: 0.109046, Val Acc: 0.783505\n",
      "Epoch 22802 - Train Loss: 0.075747, Train Acc: 0.887179 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 22803 - Train Loss: 0.075746, Train Acc: 0.887179 | Val Loss: 0.109045, Val Acc: 0.783505\n",
      "Epoch 22804 - Train Loss: 0.075744, Train Acc: 0.887179 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 22805 - Train Loss: 0.075742, Train Acc: 0.887179 | Val Loss: 0.109044, Val Acc: 0.783505\n",
      "Epoch 22806 - Train Loss: 0.075740, Train Acc: 0.887179 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 22807 - Train Loss: 0.075738, Train Acc: 0.887179 | Val Loss: 0.109043, Val Acc: 0.783505\n",
      "Epoch 22808 - Train Loss: 0.075737, Train Acc: 0.887179 | Val Loss: 0.109042, Val Acc: 0.783505\n",
      "Epoch 22809 - Train Loss: 0.075735, Train Acc: 0.887179 | Val Loss: 0.109042, Val Acc: 0.783505\n",
      "Epoch 22810 - Train Loss: 0.075733, Train Acc: 0.887179 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 22811 - Train Loss: 0.075731, Train Acc: 0.887179 | Val Loss: 0.109041, Val Acc: 0.783505\n",
      "Epoch 22812 - Train Loss: 0.075730, Train Acc: 0.887179 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 22813 - Train Loss: 0.075728, Train Acc: 0.887179 | Val Loss: 0.109040, Val Acc: 0.783505\n",
      "Epoch 22814 - Train Loss: 0.075726, Train Acc: 0.887179 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 22815 - Train Loss: 0.075724, Train Acc: 0.887179 | Val Loss: 0.109039, Val Acc: 0.783505\n",
      "Epoch 22816 - Train Loss: 0.075723, Train Acc: 0.887179 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 22817 - Train Loss: 0.075721, Train Acc: 0.887179 | Val Loss: 0.109038, Val Acc: 0.783505\n",
      "Epoch 22818 - Train Loss: 0.075719, Train Acc: 0.887179 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 22819 - Train Loss: 0.075717, Train Acc: 0.887179 | Val Loss: 0.109037, Val Acc: 0.783505\n",
      "Epoch 22820 - Train Loss: 0.075715, Train Acc: 0.887179 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 22821 - Train Loss: 0.075714, Train Acc: 0.887179 | Val Loss: 0.109036, Val Acc: 0.783505\n",
      "Epoch 22822 - Train Loss: 0.075712, Train Acc: 0.887179 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 22823 - Train Loss: 0.075710, Train Acc: 0.887179 | Val Loss: 0.109035, Val Acc: 0.783505\n",
      "Epoch 22824 - Train Loss: 0.075708, Train Acc: 0.887179 | Val Loss: 0.109034, Val Acc: 0.783505\n",
      "Epoch 22825 - Train Loss: 0.075707, Train Acc: 0.887179 | Val Loss: 0.109034, Val Acc: 0.783505\n",
      "Epoch 22826 - Train Loss: 0.075705, Train Acc: 0.887179 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 22827 - Train Loss: 0.075703, Train Acc: 0.887179 | Val Loss: 0.109033, Val Acc: 0.783505\n",
      "Epoch 22828 - Train Loss: 0.075701, Train Acc: 0.887179 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 22829 - Train Loss: 0.075700, Train Acc: 0.887179 | Val Loss: 0.109032, Val Acc: 0.783505\n",
      "Epoch 22830 - Train Loss: 0.075698, Train Acc: 0.887179 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 22831 - Train Loss: 0.075696, Train Acc: 0.887179 | Val Loss: 0.109031, Val Acc: 0.783505\n",
      "Epoch 22832 - Train Loss: 0.075694, Train Acc: 0.887179 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 22833 - Train Loss: 0.075693, Train Acc: 0.887179 | Val Loss: 0.109030, Val Acc: 0.783505\n",
      "Epoch 22834 - Train Loss: 0.075691, Train Acc: 0.887179 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 22835 - Train Loss: 0.075689, Train Acc: 0.887179 | Val Loss: 0.109029, Val Acc: 0.783505\n",
      "Epoch 22836 - Train Loss: 0.075687, Train Acc: 0.887179 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 22837 - Train Loss: 0.075685, Train Acc: 0.887179 | Val Loss: 0.109028, Val Acc: 0.783505\n",
      "Epoch 22838 - Train Loss: 0.075684, Train Acc: 0.887179 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 22839 - Train Loss: 0.075682, Train Acc: 0.887179 | Val Loss: 0.109027, Val Acc: 0.783505\n",
      "Epoch 22840 - Train Loss: 0.075680, Train Acc: 0.887179 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 22841 - Train Loss: 0.075678, Train Acc: 0.887179 | Val Loss: 0.109026, Val Acc: 0.783505\n",
      "Epoch 22842 - Train Loss: 0.075677, Train Acc: 0.887179 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 22843 - Train Loss: 0.075675, Train Acc: 0.887179 | Val Loss: 0.109025, Val Acc: 0.783505\n",
      "Epoch 22844 - Train Loss: 0.075673, Train Acc: 0.887179 | Val Loss: 0.109024, Val Acc: 0.783505\n",
      "Epoch 22845 - Train Loss: 0.075671, Train Acc: 0.887179 | Val Loss: 0.109024, Val Acc: 0.783505\n",
      "Epoch 22846 - Train Loss: 0.075670, Train Acc: 0.887179 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 22847 - Train Loss: 0.075668, Train Acc: 0.887179 | Val Loss: 0.109023, Val Acc: 0.783505\n",
      "Epoch 22848 - Train Loss: 0.075666, Train Acc: 0.887179 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 22849 - Train Loss: 0.075664, Train Acc: 0.887179 | Val Loss: 0.109022, Val Acc: 0.783505\n",
      "Epoch 22850 - Train Loss: 0.075663, Train Acc: 0.887179 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 22851 - Train Loss: 0.075661, Train Acc: 0.887179 | Val Loss: 0.109021, Val Acc: 0.783505\n",
      "Epoch 22852 - Train Loss: 0.075659, Train Acc: 0.887179 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 22853 - Train Loss: 0.075657, Train Acc: 0.887179 | Val Loss: 0.109020, Val Acc: 0.783505\n",
      "Epoch 22854 - Train Loss: 0.075655, Train Acc: 0.887179 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 22855 - Train Loss: 0.075654, Train Acc: 0.887179 | Val Loss: 0.109019, Val Acc: 0.783505\n",
      "Epoch 22856 - Train Loss: 0.075652, Train Acc: 0.887179 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 22857 - Train Loss: 0.075650, Train Acc: 0.887179 | Val Loss: 0.109018, Val Acc: 0.783505\n",
      "Epoch 22858 - Train Loss: 0.075648, Train Acc: 0.887179 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 22859 - Train Loss: 0.075647, Train Acc: 0.887179 | Val Loss: 0.109017, Val Acc: 0.783505\n",
      "Epoch 22860 - Train Loss: 0.075645, Train Acc: 0.887179 | Val Loss: 0.109016, Val Acc: 0.793814\n",
      "Epoch 22861 - Train Loss: 0.075643, Train Acc: 0.887179 | Val Loss: 0.109016, Val Acc: 0.793814\n",
      "Epoch 22862 - Train Loss: 0.075641, Train Acc: 0.887179 | Val Loss: 0.109015, Val Acc: 0.793814\n",
      "Epoch 22863 - Train Loss: 0.075640, Train Acc: 0.887179 | Val Loss: 0.109015, Val Acc: 0.793814\n",
      "Epoch 22864 - Train Loss: 0.075638, Train Acc: 0.887179 | Val Loss: 0.109014, Val Acc: 0.793814\n",
      "Epoch 22865 - Train Loss: 0.075636, Train Acc: 0.887179 | Val Loss: 0.109014, Val Acc: 0.793814\n",
      "Epoch 22866 - Train Loss: 0.075634, Train Acc: 0.887179 | Val Loss: 0.109013, Val Acc: 0.793814\n",
      "Epoch 22867 - Train Loss: 0.075633, Train Acc: 0.887179 | Val Loss: 0.109013, Val Acc: 0.793814\n",
      "Epoch 22868 - Train Loss: 0.075631, Train Acc: 0.887179 | Val Loss: 0.109012, Val Acc: 0.793814\n",
      "Epoch 22869 - Train Loss: 0.075629, Train Acc: 0.887179 | Val Loss: 0.109012, Val Acc: 0.793814\n",
      "Epoch 22870 - Train Loss: 0.075627, Train Acc: 0.887179 | Val Loss: 0.109011, Val Acc: 0.793814\n",
      "Epoch 22871 - Train Loss: 0.075626, Train Acc: 0.887179 | Val Loss: 0.109011, Val Acc: 0.793814\n",
      "Epoch 22872 - Train Loss: 0.075624, Train Acc: 0.887179 | Val Loss: 0.109010, Val Acc: 0.793814\n",
      "Epoch 22873 - Train Loss: 0.075622, Train Acc: 0.887179 | Val Loss: 0.109010, Val Acc: 0.793814\n",
      "Epoch 22874 - Train Loss: 0.075620, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.793814\n",
      "Epoch 22875 - Train Loss: 0.075619, Train Acc: 0.887179 | Val Loss: 0.109009, Val Acc: 0.793814\n",
      "Epoch 22876 - Train Loss: 0.075617, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.793814\n",
      "Epoch 22877 - Train Loss: 0.075615, Train Acc: 0.887179 | Val Loss: 0.109008, Val Acc: 0.793814\n",
      "Epoch 22878 - Train Loss: 0.075613, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.793814\n",
      "Epoch 22879 - Train Loss: 0.075611, Train Acc: 0.887179 | Val Loss: 0.109007, Val Acc: 0.793814\n",
      "Epoch 22880 - Train Loss: 0.075610, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.793814\n",
      "Epoch 22881 - Train Loss: 0.075608, Train Acc: 0.887179 | Val Loss: 0.109006, Val Acc: 0.793814\n",
      "Epoch 22882 - Train Loss: 0.075606, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.793814\n",
      "Epoch 22883 - Train Loss: 0.075604, Train Acc: 0.887179 | Val Loss: 0.109005, Val Acc: 0.793814\n",
      "Epoch 22884 - Train Loss: 0.075603, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.793814\n",
      "Epoch 22885 - Train Loss: 0.075601, Train Acc: 0.887179 | Val Loss: 0.109004, Val Acc: 0.793814\n",
      "Epoch 22886 - Train Loss: 0.075599, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.793814\n",
      "Epoch 22887 - Train Loss: 0.075597, Train Acc: 0.887179 | Val Loss: 0.109003, Val Acc: 0.793814\n",
      "Epoch 22888 - Train Loss: 0.075596, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.793814\n",
      "Epoch 22889 - Train Loss: 0.075594, Train Acc: 0.887179 | Val Loss: 0.109002, Val Acc: 0.793814\n",
      "Epoch 22890 - Train Loss: 0.075592, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.793814\n",
      "Epoch 22891 - Train Loss: 0.075590, Train Acc: 0.887179 | Val Loss: 0.109001, Val Acc: 0.793814\n",
      "Epoch 22892 - Train Loss: 0.075589, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.793814\n",
      "Epoch 22893 - Train Loss: 0.075587, Train Acc: 0.887179 | Val Loss: 0.109000, Val Acc: 0.793814\n",
      "Epoch 22894 - Train Loss: 0.075585, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.793814\n",
      "Epoch 22895 - Train Loss: 0.075583, Train Acc: 0.887179 | Val Loss: 0.108999, Val Acc: 0.793814\n",
      "Epoch 22896 - Train Loss: 0.075582, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.793814\n",
      "Epoch 22897 - Train Loss: 0.075580, Train Acc: 0.887179 | Val Loss: 0.108998, Val Acc: 0.793814\n",
      "Epoch 22898 - Train Loss: 0.075578, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.793814\n",
      "Epoch 22899 - Train Loss: 0.075576, Train Acc: 0.887179 | Val Loss: 0.108997, Val Acc: 0.793814\n",
      "Epoch 22900 - Train Loss: 0.075575, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.793814\n",
      "Epoch 22901 - Train Loss: 0.075573, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.793814\n",
      "Epoch 22902 - Train Loss: 0.075571, Train Acc: 0.887179 | Val Loss: 0.108996, Val Acc: 0.793814\n",
      "Epoch 22903 - Train Loss: 0.075569, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.793814\n",
      "Epoch 22904 - Train Loss: 0.075568, Train Acc: 0.887179 | Val Loss: 0.108995, Val Acc: 0.793814\n",
      "Epoch 22905 - Train Loss: 0.075566, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.793814\n",
      "Epoch 22906 - Train Loss: 0.075564, Train Acc: 0.887179 | Val Loss: 0.108994, Val Acc: 0.793814\n",
      "Epoch 22907 - Train Loss: 0.075562, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.793814\n",
      "Epoch 22908 - Train Loss: 0.075561, Train Acc: 0.887179 | Val Loss: 0.108993, Val Acc: 0.793814\n",
      "Epoch 22909 - Train Loss: 0.075559, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.793814\n",
      "Epoch 22910 - Train Loss: 0.075557, Train Acc: 0.887179 | Val Loss: 0.108992, Val Acc: 0.793814\n",
      "Epoch 22911 - Train Loss: 0.075555, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.793814\n",
      "Epoch 22912 - Train Loss: 0.075554, Train Acc: 0.887179 | Val Loss: 0.108991, Val Acc: 0.793814\n",
      "Epoch 22913 - Train Loss: 0.075552, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.793814\n",
      "Epoch 22914 - Train Loss: 0.075550, Train Acc: 0.887179 | Val Loss: 0.108990, Val Acc: 0.793814\n",
      "Epoch 22915 - Train Loss: 0.075548, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.793814\n",
      "Epoch 22916 - Train Loss: 0.075547, Train Acc: 0.887179 | Val Loss: 0.108989, Val Acc: 0.793814\n",
      "Epoch 22917 - Train Loss: 0.075545, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.793814\n",
      "Epoch 22918 - Train Loss: 0.075543, Train Acc: 0.887179 | Val Loss: 0.108988, Val Acc: 0.793814\n",
      "Epoch 22919 - Train Loss: 0.075541, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.793814\n",
      "Epoch 22920 - Train Loss: 0.075540, Train Acc: 0.887179 | Val Loss: 0.108987, Val Acc: 0.793814\n",
      "Epoch 22921 - Train Loss: 0.075538, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.793814\n",
      "Epoch 22922 - Train Loss: 0.075536, Train Acc: 0.887179 | Val Loss: 0.108986, Val Acc: 0.793814\n",
      "Epoch 22923 - Train Loss: 0.075534, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.793814\n",
      "Epoch 22924 - Train Loss: 0.075532, Train Acc: 0.887179 | Val Loss: 0.108985, Val Acc: 0.793814\n",
      "Epoch 22925 - Train Loss: 0.075531, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.793814\n",
      "Epoch 22926 - Train Loss: 0.075529, Train Acc: 0.887179 | Val Loss: 0.108984, Val Acc: 0.793814\n",
      "Epoch 22927 - Train Loss: 0.075527, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.793814\n",
      "Epoch 22928 - Train Loss: 0.075525, Train Acc: 0.887179 | Val Loss: 0.108983, Val Acc: 0.793814\n",
      "Epoch 22929 - Train Loss: 0.075524, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.793814\n",
      "Epoch 22930 - Train Loss: 0.075522, Train Acc: 0.887179 | Val Loss: 0.108982, Val Acc: 0.793814\n",
      "Epoch 22931 - Train Loss: 0.075520, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.793814\n",
      "Epoch 22932 - Train Loss: 0.075518, Train Acc: 0.887179 | Val Loss: 0.108981, Val Acc: 0.793814\n",
      "Epoch 22933 - Train Loss: 0.075517, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.793814\n",
      "Epoch 22934 - Train Loss: 0.075515, Train Acc: 0.887179 | Val Loss: 0.108980, Val Acc: 0.793814\n",
      "Epoch 22935 - Train Loss: 0.075513, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.793814\n",
      "Epoch 22936 - Train Loss: 0.075511, Train Acc: 0.887179 | Val Loss: 0.108979, Val Acc: 0.793814\n",
      "Epoch 22937 - Train Loss: 0.075510, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.793814\n",
      "Epoch 22938 - Train Loss: 0.075508, Train Acc: 0.887179 | Val Loss: 0.108978, Val Acc: 0.793814\n",
      "Epoch 22939 - Train Loss: 0.075506, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.793814\n",
      "Epoch 22940 - Train Loss: 0.075504, Train Acc: 0.887179 | Val Loss: 0.108977, Val Acc: 0.793814\n",
      "Epoch 22941 - Train Loss: 0.075503, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.793814\n",
      "Epoch 22942 - Train Loss: 0.075501, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.793814\n",
      "Epoch 22943 - Train Loss: 0.075499, Train Acc: 0.887179 | Val Loss: 0.108976, Val Acc: 0.793814\n",
      "Epoch 22944 - Train Loss: 0.075497, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.793814\n",
      "Epoch 22945 - Train Loss: 0.075496, Train Acc: 0.887179 | Val Loss: 0.108975, Val Acc: 0.793814\n",
      "Epoch 22946 - Train Loss: 0.075494, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.793814\n",
      "Epoch 22947 - Train Loss: 0.075492, Train Acc: 0.887179 | Val Loss: 0.108974, Val Acc: 0.793814\n",
      "Epoch 22948 - Train Loss: 0.075490, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.793814\n",
      "Epoch 22949 - Train Loss: 0.075489, Train Acc: 0.887179 | Val Loss: 0.108973, Val Acc: 0.793814\n",
      "Epoch 22950 - Train Loss: 0.075487, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.793814\n",
      "Epoch 22951 - Train Loss: 0.075485, Train Acc: 0.887179 | Val Loss: 0.108972, Val Acc: 0.793814\n",
      "Epoch 22952 - Train Loss: 0.075484, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.793814\n",
      "Epoch 22953 - Train Loss: 0.075482, Train Acc: 0.887179 | Val Loss: 0.108971, Val Acc: 0.793814\n",
      "Epoch 22954 - Train Loss: 0.075480, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.793814\n",
      "Epoch 22955 - Train Loss: 0.075478, Train Acc: 0.887179 | Val Loss: 0.108970, Val Acc: 0.793814\n",
      "Epoch 22956 - Train Loss: 0.075477, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.793814\n",
      "Epoch 22957 - Train Loss: 0.075475, Train Acc: 0.887179 | Val Loss: 0.108969, Val Acc: 0.793814\n",
      "Epoch 22958 - Train Loss: 0.075473, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.793814\n",
      "Epoch 22959 - Train Loss: 0.075471, Train Acc: 0.887179 | Val Loss: 0.108968, Val Acc: 0.793814\n",
      "Epoch 22960 - Train Loss: 0.075470, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.793814\n",
      "Epoch 22961 - Train Loss: 0.075468, Train Acc: 0.887179 | Val Loss: 0.108967, Val Acc: 0.793814\n",
      "Epoch 22962 - Train Loss: 0.075466, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.793814\n",
      "Epoch 22963 - Train Loss: 0.075464, Train Acc: 0.887179 | Val Loss: 0.108966, Val Acc: 0.793814\n",
      "Epoch 22964 - Train Loss: 0.075463, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.793814\n",
      "Epoch 22965 - Train Loss: 0.075461, Train Acc: 0.887179 | Val Loss: 0.108965, Val Acc: 0.793814\n",
      "Epoch 22966 - Train Loss: 0.075459, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.793814\n",
      "Epoch 22967 - Train Loss: 0.075457, Train Acc: 0.887179 | Val Loss: 0.108964, Val Acc: 0.793814\n",
      "Epoch 22968 - Train Loss: 0.075456, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.793814\n",
      "Epoch 22969 - Train Loss: 0.075454, Train Acc: 0.887179 | Val Loss: 0.108963, Val Acc: 0.793814\n",
      "Epoch 22970 - Train Loss: 0.075452, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.793814\n",
      "Epoch 22971 - Train Loss: 0.075450, Train Acc: 0.887179 | Val Loss: 0.108962, Val Acc: 0.793814\n",
      "Epoch 22972 - Train Loss: 0.075449, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.793814\n",
      "Epoch 22973 - Train Loss: 0.075447, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.793814\n",
      "Epoch 22974 - Train Loss: 0.075445, Train Acc: 0.887179 | Val Loss: 0.108961, Val Acc: 0.793814\n",
      "Epoch 22975 - Train Loss: 0.075443, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.793814\n",
      "Epoch 22976 - Train Loss: 0.075442, Train Acc: 0.887179 | Val Loss: 0.108960, Val Acc: 0.793814\n",
      "Epoch 22977 - Train Loss: 0.075440, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.793814\n",
      "Epoch 22978 - Train Loss: 0.075438, Train Acc: 0.887179 | Val Loss: 0.108959, Val Acc: 0.793814\n",
      "Epoch 22979 - Train Loss: 0.075436, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.793814\n",
      "Epoch 22980 - Train Loss: 0.075435, Train Acc: 0.887179 | Val Loss: 0.108958, Val Acc: 0.793814\n",
      "Epoch 22981 - Train Loss: 0.075433, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.793814\n",
      "Epoch 22982 - Train Loss: 0.075431, Train Acc: 0.887179 | Val Loss: 0.108957, Val Acc: 0.793814\n",
      "Epoch 22983 - Train Loss: 0.075429, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.793814\n",
      "Epoch 22984 - Train Loss: 0.075428, Train Acc: 0.887179 | Val Loss: 0.108956, Val Acc: 0.793814\n",
      "Epoch 22985 - Train Loss: 0.075426, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.793814\n",
      "Epoch 22986 - Train Loss: 0.075424, Train Acc: 0.887179 | Val Loss: 0.108955, Val Acc: 0.793814\n",
      "Epoch 22987 - Train Loss: 0.075422, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.793814\n",
      "Epoch 22988 - Train Loss: 0.075421, Train Acc: 0.887179 | Val Loss: 0.108954, Val Acc: 0.793814\n",
      "Epoch 22989 - Train Loss: 0.075419, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.793814\n",
      "Epoch 22990 - Train Loss: 0.075417, Train Acc: 0.887179 | Val Loss: 0.108953, Val Acc: 0.793814\n",
      "Epoch 22991 - Train Loss: 0.075415, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.793814\n",
      "Epoch 22992 - Train Loss: 0.075414, Train Acc: 0.887179 | Val Loss: 0.108952, Val Acc: 0.793814\n",
      "Epoch 22993 - Train Loss: 0.075412, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.793814\n",
      "Epoch 22994 - Train Loss: 0.075410, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.793814\n",
      "Epoch 22995 - Train Loss: 0.075408, Train Acc: 0.887179 | Val Loss: 0.108951, Val Acc: 0.793814\n",
      "Epoch 22996 - Train Loss: 0.075407, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.793814\n",
      "Epoch 22997 - Train Loss: 0.075405, Train Acc: 0.887179 | Val Loss: 0.108950, Val Acc: 0.793814\n",
      "Epoch 22998 - Train Loss: 0.075403, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.793814\n",
      "Epoch 22999 - Train Loss: 0.075402, Train Acc: 0.887179 | Val Loss: 0.108949, Val Acc: 0.793814\n",
      "Epoch 23000 - Train Loss: 0.075400, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.793814\n",
      "Epoch 23001 - Train Loss: 0.075398, Train Acc: 0.887179 | Val Loss: 0.108948, Val Acc: 0.793814\n",
      "Epoch 23002 - Train Loss: 0.075396, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.793814\n",
      "Epoch 23003 - Train Loss: 0.075395, Train Acc: 0.887179 | Val Loss: 0.108947, Val Acc: 0.793814\n",
      "Epoch 23004 - Train Loss: 0.075393, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.793814\n",
      "Epoch 23005 - Train Loss: 0.075391, Train Acc: 0.887179 | Val Loss: 0.108946, Val Acc: 0.793814\n",
      "Epoch 23006 - Train Loss: 0.075389, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.793814\n",
      "Epoch 23007 - Train Loss: 0.075388, Train Acc: 0.887179 | Val Loss: 0.108945, Val Acc: 0.793814\n",
      "Epoch 23008 - Train Loss: 0.075386, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.793814\n",
      "Epoch 23009 - Train Loss: 0.075384, Train Acc: 0.887179 | Val Loss: 0.108944, Val Acc: 0.793814\n",
      "Epoch 23010 - Train Loss: 0.075382, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.793814\n",
      "Epoch 23011 - Train Loss: 0.075381, Train Acc: 0.887179 | Val Loss: 0.108943, Val Acc: 0.793814\n",
      "Epoch 23012 - Train Loss: 0.075379, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.793814\n",
      "Epoch 23013 - Train Loss: 0.075377, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.793814\n",
      "Epoch 23014 - Train Loss: 0.075375, Train Acc: 0.887179 | Val Loss: 0.108942, Val Acc: 0.793814\n",
      "Epoch 23015 - Train Loss: 0.075374, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.793814\n",
      "Epoch 23016 - Train Loss: 0.075372, Train Acc: 0.887179 | Val Loss: 0.108941, Val Acc: 0.793814\n",
      "Epoch 23017 - Train Loss: 0.075370, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.793814\n",
      "Epoch 23018 - Train Loss: 0.075368, Train Acc: 0.887179 | Val Loss: 0.108940, Val Acc: 0.793814\n",
      "Epoch 23019 - Train Loss: 0.075367, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.793814\n",
      "Epoch 23020 - Train Loss: 0.075365, Train Acc: 0.887179 | Val Loss: 0.108939, Val Acc: 0.793814\n",
      "Epoch 23021 - Train Loss: 0.075363, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.793814\n",
      "Epoch 23022 - Train Loss: 0.075362, Train Acc: 0.887179 | Val Loss: 0.108938, Val Acc: 0.793814\n",
      "Epoch 23023 - Train Loss: 0.075360, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.793814\n",
      "Epoch 23024 - Train Loss: 0.075358, Train Acc: 0.887179 | Val Loss: 0.108937, Val Acc: 0.793814\n",
      "Epoch 23025 - Train Loss: 0.075356, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.793814\n",
      "Epoch 23026 - Train Loss: 0.075355, Train Acc: 0.887179 | Val Loss: 0.108936, Val Acc: 0.793814\n",
      "Epoch 23027 - Train Loss: 0.075353, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.793814\n",
      "Epoch 23028 - Train Loss: 0.075351, Train Acc: 0.887179 | Val Loss: 0.108935, Val Acc: 0.793814\n",
      "Epoch 23029 - Train Loss: 0.075349, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.793814\n",
      "Epoch 23030 - Train Loss: 0.075348, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.793814\n",
      "Epoch 23031 - Train Loss: 0.075346, Train Acc: 0.887179 | Val Loss: 0.108934, Val Acc: 0.793814\n",
      "Epoch 23032 - Train Loss: 0.075344, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.793814\n",
      "Epoch 23033 - Train Loss: 0.075342, Train Acc: 0.887179 | Val Loss: 0.108933, Val Acc: 0.793814\n",
      "Epoch 23034 - Train Loss: 0.075341, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.793814\n",
      "Epoch 23035 - Train Loss: 0.075339, Train Acc: 0.887179 | Val Loss: 0.108932, Val Acc: 0.793814\n",
      "Epoch 23036 - Train Loss: 0.075337, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.793814\n",
      "Epoch 23037 - Train Loss: 0.075335, Train Acc: 0.887179 | Val Loss: 0.108931, Val Acc: 0.793814\n",
      "Epoch 23038 - Train Loss: 0.075334, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.793814\n",
      "Epoch 23039 - Train Loss: 0.075332, Train Acc: 0.887179 | Val Loss: 0.108930, Val Acc: 0.793814\n",
      "Epoch 23040 - Train Loss: 0.075330, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.793814\n",
      "Epoch 23041 - Train Loss: 0.075329, Train Acc: 0.887179 | Val Loss: 0.108929, Val Acc: 0.793814\n",
      "Epoch 23042 - Train Loss: 0.075327, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.793814\n",
      "Epoch 23043 - Train Loss: 0.075325, Train Acc: 0.887179 | Val Loss: 0.108928, Val Acc: 0.793814\n",
      "Epoch 23044 - Train Loss: 0.075323, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.793814\n",
      "Epoch 23045 - Train Loss: 0.075322, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.793814\n",
      "Epoch 23046 - Train Loss: 0.075320, Train Acc: 0.887179 | Val Loss: 0.108927, Val Acc: 0.793814\n",
      "Epoch 23047 - Train Loss: 0.075318, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.793814\n",
      "Epoch 23048 - Train Loss: 0.075316, Train Acc: 0.887179 | Val Loss: 0.108926, Val Acc: 0.793814\n",
      "Epoch 23049 - Train Loss: 0.075315, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.793814\n",
      "Epoch 23050 - Train Loss: 0.075313, Train Acc: 0.887179 | Val Loss: 0.108925, Val Acc: 0.793814\n",
      "Epoch 23051 - Train Loss: 0.075311, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.793814\n",
      "Epoch 23052 - Train Loss: 0.075309, Train Acc: 0.887179 | Val Loss: 0.108924, Val Acc: 0.793814\n",
      "Epoch 23053 - Train Loss: 0.075308, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.793814\n",
      "Epoch 23054 - Train Loss: 0.075306, Train Acc: 0.887179 | Val Loss: 0.108923, Val Acc: 0.793814\n",
      "Epoch 23055 - Train Loss: 0.075304, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.793814\n",
      "Epoch 23056 - Train Loss: 0.075303, Train Acc: 0.887179 | Val Loss: 0.108922, Val Acc: 0.793814\n",
      "Epoch 23057 - Train Loss: 0.075301, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.793814\n",
      "Epoch 23058 - Train Loss: 0.075299, Train Acc: 0.887179 | Val Loss: 0.108921, Val Acc: 0.793814\n",
      "Epoch 23059 - Train Loss: 0.075297, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.793814\n",
      "Epoch 23060 - Train Loss: 0.075296, Train Acc: 0.887179 | Val Loss: 0.108920, Val Acc: 0.793814\n",
      "Epoch 23061 - Train Loss: 0.075294, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.793814\n",
      "Epoch 23062 - Train Loss: 0.075292, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.793814\n",
      "Epoch 23063 - Train Loss: 0.075290, Train Acc: 0.887179 | Val Loss: 0.108919, Val Acc: 0.793814\n",
      "Epoch 23064 - Train Loss: 0.075289, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.793814\n",
      "Epoch 23065 - Train Loss: 0.075287, Train Acc: 0.887179 | Val Loss: 0.108918, Val Acc: 0.793814\n",
      "Epoch 23066 - Train Loss: 0.075285, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.793814\n",
      "Epoch 23067 - Train Loss: 0.075283, Train Acc: 0.887179 | Val Loss: 0.108917, Val Acc: 0.793814\n",
      "Epoch 23068 - Train Loss: 0.075282, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.793814\n",
      "Epoch 23069 - Train Loss: 0.075280, Train Acc: 0.887179 | Val Loss: 0.108916, Val Acc: 0.793814\n",
      "Epoch 23070 - Train Loss: 0.075278, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.793814\n",
      "Epoch 23071 - Train Loss: 0.075277, Train Acc: 0.887179 | Val Loss: 0.108915, Val Acc: 0.793814\n",
      "Epoch 23072 - Train Loss: 0.075275, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.793814\n",
      "Epoch 23073 - Train Loss: 0.075273, Train Acc: 0.887179 | Val Loss: 0.108914, Val Acc: 0.793814\n",
      "Epoch 23074 - Train Loss: 0.075271, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.793814\n",
      "Epoch 23075 - Train Loss: 0.075270, Train Acc: 0.887179 | Val Loss: 0.108913, Val Acc: 0.793814\n",
      "Epoch 23076 - Train Loss: 0.075268, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.793814\n",
      "Epoch 23077 - Train Loss: 0.075266, Train Acc: 0.887179 | Val Loss: 0.108912, Val Acc: 0.793814\n",
      "Epoch 23078 - Train Loss: 0.075264, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.793814\n",
      "Epoch 23079 - Train Loss: 0.075263, Train Acc: 0.887179 | Val Loss: 0.108911, Val Acc: 0.793814\n",
      "Epoch 23080 - Train Loss: 0.075261, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.793814\n",
      "Epoch 23081 - Train Loss: 0.075259, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.793814\n",
      "Epoch 23082 - Train Loss: 0.075258, Train Acc: 0.887179 | Val Loss: 0.108910, Val Acc: 0.793814\n",
      "Epoch 23083 - Train Loss: 0.075256, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.793814\n",
      "Epoch 23084 - Train Loss: 0.075254, Train Acc: 0.887179 | Val Loss: 0.108909, Val Acc: 0.793814\n",
      "Epoch 23085 - Train Loss: 0.075252, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.793814\n",
      "Epoch 23086 - Train Loss: 0.075251, Train Acc: 0.887179 | Val Loss: 0.108908, Val Acc: 0.793814\n",
      "Epoch 23087 - Train Loss: 0.075249, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.793814\n",
      "Epoch 23088 - Train Loss: 0.075247, Train Acc: 0.887179 | Val Loss: 0.108907, Val Acc: 0.793814\n",
      "Epoch 23089 - Train Loss: 0.075245, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.793814\n",
      "Epoch 23090 - Train Loss: 0.075244, Train Acc: 0.887179 | Val Loss: 0.108906, Val Acc: 0.793814\n",
      "Epoch 23091 - Train Loss: 0.075242, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.793814\n",
      "Epoch 23092 - Train Loss: 0.075240, Train Acc: 0.887179 | Val Loss: 0.108905, Val Acc: 0.793814\n",
      "Epoch 23093 - Train Loss: 0.075239, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.793814\n",
      "Epoch 23094 - Train Loss: 0.075237, Train Acc: 0.887179 | Val Loss: 0.108904, Val Acc: 0.793814\n",
      "Epoch 23095 - Train Loss: 0.075235, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.793814\n",
      "Epoch 23096 - Train Loss: 0.075233, Train Acc: 0.887179 | Val Loss: 0.108903, Val Acc: 0.793814\n",
      "Epoch 23097 - Train Loss: 0.075232, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.793814\n",
      "Epoch 23098 - Train Loss: 0.075230, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.793814\n",
      "Epoch 23099 - Train Loss: 0.075228, Train Acc: 0.887179 | Val Loss: 0.108902, Val Acc: 0.793814\n",
      "Epoch 23100 - Train Loss: 0.075226, Train Acc: 0.887179 | Val Loss: 0.108901, Val Acc: 0.793814\n",
      "Epoch 23101 - Train Loss: 0.075225, Train Acc: 0.887179 | Val Loss: 0.108901, Val Acc: 0.793814\n",
      "Epoch 23102 - Train Loss: 0.075223, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.793814\n",
      "Epoch 23103 - Train Loss: 0.075221, Train Acc: 0.887179 | Val Loss: 0.108900, Val Acc: 0.793814\n",
      "Epoch 23104 - Train Loss: 0.075220, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.793814\n",
      "Epoch 23105 - Train Loss: 0.075218, Train Acc: 0.887179 | Val Loss: 0.108899, Val Acc: 0.793814\n",
      "Epoch 23106 - Train Loss: 0.075216, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.793814\n",
      "Epoch 23107 - Train Loss: 0.075214, Train Acc: 0.887179 | Val Loss: 0.108898, Val Acc: 0.793814\n",
      "Epoch 23108 - Train Loss: 0.075213, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.793814\n",
      "Epoch 23109 - Train Loss: 0.075211, Train Acc: 0.887179 | Val Loss: 0.108897, Val Acc: 0.793814\n",
      "Epoch 23110 - Train Loss: 0.075209, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.793814\n",
      "Epoch 23111 - Train Loss: 0.075207, Train Acc: 0.887179 | Val Loss: 0.108896, Val Acc: 0.793814\n",
      "Epoch 23112 - Train Loss: 0.075206, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.793814\n",
      "Epoch 23113 - Train Loss: 0.075204, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.793814\n",
      "Epoch 23114 - Train Loss: 0.075202, Train Acc: 0.887179 | Val Loss: 0.108895, Val Acc: 0.793814\n",
      "Epoch 23115 - Train Loss: 0.075201, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.793814\n",
      "Epoch 23116 - Train Loss: 0.075199, Train Acc: 0.887179 | Val Loss: 0.108894, Val Acc: 0.793814\n",
      "Epoch 23117 - Train Loss: 0.075197, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.793814\n",
      "Epoch 23118 - Train Loss: 0.075195, Train Acc: 0.887179 | Val Loss: 0.108893, Val Acc: 0.793814\n",
      "Epoch 23119 - Train Loss: 0.075194, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.793814\n",
      "Epoch 23120 - Train Loss: 0.075192, Train Acc: 0.887179 | Val Loss: 0.108892, Val Acc: 0.793814\n",
      "Epoch 23121 - Train Loss: 0.075190, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.793814\n",
      "Epoch 23122 - Train Loss: 0.075188, Train Acc: 0.887179 | Val Loss: 0.108891, Val Acc: 0.793814\n",
      "Epoch 23123 - Train Loss: 0.075187, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.793814\n",
      "Epoch 23124 - Train Loss: 0.075185, Train Acc: 0.887179 | Val Loss: 0.108890, Val Acc: 0.793814\n",
      "Epoch 23125 - Train Loss: 0.075183, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.793814\n",
      "Epoch 23126 - Train Loss: 0.075182, Train Acc: 0.887179 | Val Loss: 0.108889, Val Acc: 0.793814\n",
      "Epoch 23127 - Train Loss: 0.075180, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.793814\n",
      "Epoch 23128 - Train Loss: 0.075178, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.793814\n",
      "Epoch 23129 - Train Loss: 0.075176, Train Acc: 0.887179 | Val Loss: 0.108888, Val Acc: 0.793814\n",
      "Epoch 23130 - Train Loss: 0.075175, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.793814\n",
      "Epoch 23131 - Train Loss: 0.075173, Train Acc: 0.887179 | Val Loss: 0.108887, Val Acc: 0.793814\n",
      "Epoch 23132 - Train Loss: 0.075171, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.793814\n",
      "Epoch 23133 - Train Loss: 0.075170, Train Acc: 0.887179 | Val Loss: 0.108886, Val Acc: 0.793814\n",
      "Epoch 23134 - Train Loss: 0.075168, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.793814\n",
      "Epoch 23135 - Train Loss: 0.075166, Train Acc: 0.887179 | Val Loss: 0.108885, Val Acc: 0.793814\n",
      "Epoch 23136 - Train Loss: 0.075164, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.793814\n",
      "Epoch 23137 - Train Loss: 0.075163, Train Acc: 0.887179 | Val Loss: 0.108884, Val Acc: 0.793814\n",
      "Epoch 23138 - Train Loss: 0.075161, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.793814\n",
      "Epoch 23139 - Train Loss: 0.075159, Train Acc: 0.887179 | Val Loss: 0.108883, Val Acc: 0.793814\n",
      "Epoch 23140 - Train Loss: 0.075157, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.793814\n",
      "Epoch 23141 - Train Loss: 0.075156, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.793814\n",
      "Epoch 23142 - Train Loss: 0.075154, Train Acc: 0.887179 | Val Loss: 0.108882, Val Acc: 0.793814\n",
      "Epoch 23143 - Train Loss: 0.075152, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.793814\n",
      "Epoch 23144 - Train Loss: 0.075151, Train Acc: 0.887179 | Val Loss: 0.108881, Val Acc: 0.793814\n",
      "Epoch 23145 - Train Loss: 0.075149, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.793814\n",
      "Epoch 23146 - Train Loss: 0.075147, Train Acc: 0.887179 | Val Loss: 0.108880, Val Acc: 0.793814\n",
      "Epoch 23147 - Train Loss: 0.075145, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.793814\n",
      "Epoch 23148 - Train Loss: 0.075144, Train Acc: 0.887179 | Val Loss: 0.108879, Val Acc: 0.793814\n",
      "Epoch 23149 - Train Loss: 0.075142, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.793814\n",
      "Epoch 23150 - Train Loss: 0.075140, Train Acc: 0.887179 | Val Loss: 0.108878, Val Acc: 0.793814\n",
      "Epoch 23151 - Train Loss: 0.075139, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.793814\n",
      "Epoch 23152 - Train Loss: 0.075137, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.793814\n",
      "Epoch 23153 - Train Loss: 0.075135, Train Acc: 0.887179 | Val Loss: 0.108877, Val Acc: 0.793814\n",
      "Epoch 23154 - Train Loss: 0.075133, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.793814\n",
      "Epoch 23155 - Train Loss: 0.075132, Train Acc: 0.887179 | Val Loss: 0.108876, Val Acc: 0.793814\n",
      "Epoch 23156 - Train Loss: 0.075130, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.793814\n",
      "Epoch 23157 - Train Loss: 0.075128, Train Acc: 0.887179 | Val Loss: 0.108875, Val Acc: 0.793814\n",
      "Epoch 23158 - Train Loss: 0.075127, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.793814\n",
      "Epoch 23159 - Train Loss: 0.075125, Train Acc: 0.887179 | Val Loss: 0.108874, Val Acc: 0.793814\n",
      "Epoch 23160 - Train Loss: 0.075123, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.793814\n",
      "Epoch 23161 - Train Loss: 0.075121, Train Acc: 0.887179 | Val Loss: 0.108873, Val Acc: 0.793814\n",
      "Epoch 23162 - Train Loss: 0.075120, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.793814\n",
      "Epoch 23163 - Train Loss: 0.075118, Train Acc: 0.887179 | Val Loss: 0.108872, Val Acc: 0.793814\n",
      "Epoch 23164 - Train Loss: 0.075116, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.793814\n",
      "Epoch 23165 - Train Loss: 0.075115, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.793814\n",
      "Epoch 23166 - Train Loss: 0.075113, Train Acc: 0.887179 | Val Loss: 0.108871, Val Acc: 0.793814\n",
      "Epoch 23167 - Train Loss: 0.075111, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.793814\n",
      "Epoch 23168 - Train Loss: 0.075109, Train Acc: 0.887179 | Val Loss: 0.108870, Val Acc: 0.793814\n",
      "Epoch 23169 - Train Loss: 0.075108, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.793814\n",
      "Epoch 23170 - Train Loss: 0.075106, Train Acc: 0.887179 | Val Loss: 0.108869, Val Acc: 0.793814\n",
      "Epoch 23171 - Train Loss: 0.075104, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.793814\n",
      "Epoch 23172 - Train Loss: 0.075103, Train Acc: 0.887179 | Val Loss: 0.108868, Val Acc: 0.793814\n",
      "Epoch 23173 - Train Loss: 0.075101, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.793814\n",
      "Epoch 23174 - Train Loss: 0.075099, Train Acc: 0.887179 | Val Loss: 0.108867, Val Acc: 0.793814\n",
      "Epoch 23175 - Train Loss: 0.075097, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.793814\n",
      "Epoch 23176 - Train Loss: 0.075096, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.793814\n",
      "Epoch 23177 - Train Loss: 0.075094, Train Acc: 0.887179 | Val Loss: 0.108866, Val Acc: 0.793814\n",
      "Epoch 23178 - Train Loss: 0.075092, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.793814\n",
      "Epoch 23179 - Train Loss: 0.075090, Train Acc: 0.887179 | Val Loss: 0.108865, Val Acc: 0.793814\n",
      "Epoch 23180 - Train Loss: 0.075089, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.793814\n",
      "Epoch 23181 - Train Loss: 0.075087, Train Acc: 0.887179 | Val Loss: 0.108864, Val Acc: 0.793814\n",
      "Epoch 23182 - Train Loss: 0.075085, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.793814\n",
      "Epoch 23183 - Train Loss: 0.075084, Train Acc: 0.887179 | Val Loss: 0.108863, Val Acc: 0.793814\n",
      "Epoch 23184 - Train Loss: 0.075082, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.793814\n",
      "Epoch 23185 - Train Loss: 0.075080, Train Acc: 0.887179 | Val Loss: 0.108862, Val Acc: 0.793814\n",
      "Epoch 23186 - Train Loss: 0.075078, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.793814\n",
      "Epoch 23187 - Train Loss: 0.075077, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.793814\n",
      "Epoch 23188 - Train Loss: 0.075075, Train Acc: 0.887179 | Val Loss: 0.108861, Val Acc: 0.793814\n",
      "Epoch 23189 - Train Loss: 0.075073, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.793814\n",
      "Epoch 23190 - Train Loss: 0.075072, Train Acc: 0.887179 | Val Loss: 0.108860, Val Acc: 0.793814\n",
      "Epoch 23191 - Train Loss: 0.075070, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.793814\n",
      "Epoch 23192 - Train Loss: 0.075068, Train Acc: 0.887179 | Val Loss: 0.108859, Val Acc: 0.793814\n",
      "Epoch 23193 - Train Loss: 0.075067, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.793814\n",
      "Epoch 23194 - Train Loss: 0.075065, Train Acc: 0.887179 | Val Loss: 0.108858, Val Acc: 0.793814\n",
      "Epoch 23195 - Train Loss: 0.075063, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.793814\n",
      "Epoch 23196 - Train Loss: 0.075061, Train Acc: 0.887179 | Val Loss: 0.108857, Val Acc: 0.793814\n",
      "Epoch 23197 - Train Loss: 0.075060, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.793814\n",
      "Epoch 23198 - Train Loss: 0.075058, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.793814\n",
      "Epoch 23199 - Train Loss: 0.075056, Train Acc: 0.887179 | Val Loss: 0.108856, Val Acc: 0.793814\n",
      "Epoch 23200 - Train Loss: 0.075055, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.793814\n",
      "Epoch 23201 - Train Loss: 0.075053, Train Acc: 0.887179 | Val Loss: 0.108855, Val Acc: 0.793814\n",
      "Epoch 23202 - Train Loss: 0.075051, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.793814\n",
      "Epoch 23203 - Train Loss: 0.075049, Train Acc: 0.887179 | Val Loss: 0.108854, Val Acc: 0.793814\n",
      "Epoch 23204 - Train Loss: 0.075048, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.793814\n",
      "Epoch 23205 - Train Loss: 0.075046, Train Acc: 0.887179 | Val Loss: 0.108853, Val Acc: 0.793814\n",
      "Epoch 23206 - Train Loss: 0.075044, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.793814\n",
      "Epoch 23207 - Train Loss: 0.075043, Train Acc: 0.887179 | Val Loss: 0.108852, Val Acc: 0.793814\n",
      "Epoch 23208 - Train Loss: 0.075041, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.793814\n",
      "Epoch 23209 - Train Loss: 0.075039, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.793814\n",
      "Epoch 23210 - Train Loss: 0.075037, Train Acc: 0.887179 | Val Loss: 0.108851, Val Acc: 0.793814\n",
      "Epoch 23211 - Train Loss: 0.075036, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.793814\n",
      "Epoch 23212 - Train Loss: 0.075034, Train Acc: 0.887179 | Val Loss: 0.108850, Val Acc: 0.793814\n",
      "Epoch 23213 - Train Loss: 0.075032, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.793814\n",
      "Epoch 23214 - Train Loss: 0.075031, Train Acc: 0.887179 | Val Loss: 0.108849, Val Acc: 0.793814\n",
      "Epoch 23215 - Train Loss: 0.075029, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.793814\n",
      "Epoch 23216 - Train Loss: 0.075027, Train Acc: 0.887179 | Val Loss: 0.108848, Val Acc: 0.793814\n",
      "Epoch 23217 - Train Loss: 0.075025, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.793814\n",
      "Epoch 23218 - Train Loss: 0.075024, Train Acc: 0.887179 | Val Loss: 0.108847, Val Acc: 0.793814\n",
      "Epoch 23219 - Train Loss: 0.075022, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.793814\n",
      "Epoch 23220 - Train Loss: 0.075020, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.793814\n",
      "Epoch 23221 - Train Loss: 0.075019, Train Acc: 0.887179 | Val Loss: 0.108846, Val Acc: 0.793814\n",
      "Epoch 23222 - Train Loss: 0.075017, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.793814\n",
      "Epoch 23223 - Train Loss: 0.075015, Train Acc: 0.887179 | Val Loss: 0.108845, Val Acc: 0.793814\n",
      "Epoch 23224 - Train Loss: 0.075013, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.793814\n",
      "Epoch 23225 - Train Loss: 0.075012, Train Acc: 0.887179 | Val Loss: 0.108844, Val Acc: 0.793814\n",
      "Epoch 23226 - Train Loss: 0.075010, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.793814\n",
      "Epoch 23227 - Train Loss: 0.075008, Train Acc: 0.887179 | Val Loss: 0.108843, Val Acc: 0.793814\n",
      "Epoch 23228 - Train Loss: 0.075007, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.793814\n",
      "Epoch 23229 - Train Loss: 0.075005, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.793814\n",
      "Epoch 23230 - Train Loss: 0.075003, Train Acc: 0.887179 | Val Loss: 0.108842, Val Acc: 0.793814\n",
      "Epoch 23231 - Train Loss: 0.075002, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.793814\n",
      "Epoch 23232 - Train Loss: 0.075000, Train Acc: 0.887179 | Val Loss: 0.108841, Val Acc: 0.793814\n",
      "Epoch 23233 - Train Loss: 0.074998, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.793814\n",
      "Epoch 23234 - Train Loss: 0.074996, Train Acc: 0.887179 | Val Loss: 0.108840, Val Acc: 0.793814\n",
      "Epoch 23235 - Train Loss: 0.074995, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.793814\n",
      "Epoch 23236 - Train Loss: 0.074993, Train Acc: 0.887179 | Val Loss: 0.108839, Val Acc: 0.793814\n",
      "Epoch 23237 - Train Loss: 0.074991, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.793814\n",
      "Epoch 23238 - Train Loss: 0.074990, Train Acc: 0.887179 | Val Loss: 0.108838, Val Acc: 0.793814\n",
      "Epoch 23239 - Train Loss: 0.074988, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.793814\n",
      "Epoch 23240 - Train Loss: 0.074986, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.793814\n",
      "Epoch 23241 - Train Loss: 0.074984, Train Acc: 0.887179 | Val Loss: 0.108837, Val Acc: 0.793814\n",
      "Epoch 23242 - Train Loss: 0.074983, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.793814\n",
      "Epoch 23243 - Train Loss: 0.074981, Train Acc: 0.887179 | Val Loss: 0.108836, Val Acc: 0.793814\n",
      "Epoch 23244 - Train Loss: 0.074979, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.793814\n",
      "Epoch 23245 - Train Loss: 0.074978, Train Acc: 0.887179 | Val Loss: 0.108835, Val Acc: 0.793814\n",
      "Epoch 23246 - Train Loss: 0.074976, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.793814\n",
      "Epoch 23247 - Train Loss: 0.074974, Train Acc: 0.887179 | Val Loss: 0.108834, Val Acc: 0.793814\n",
      "Epoch 23248 - Train Loss: 0.074973, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.793814\n",
      "Epoch 23249 - Train Loss: 0.074971, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.793814\n",
      "Epoch 23250 - Train Loss: 0.074969, Train Acc: 0.887179 | Val Loss: 0.108833, Val Acc: 0.793814\n",
      "Epoch 23251 - Train Loss: 0.074967, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.793814\n",
      "Epoch 23252 - Train Loss: 0.074966, Train Acc: 0.887179 | Val Loss: 0.108832, Val Acc: 0.793814\n",
      "Epoch 23253 - Train Loss: 0.074964, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.793814\n",
      "Epoch 23254 - Train Loss: 0.074962, Train Acc: 0.887179 | Val Loss: 0.108831, Val Acc: 0.793814\n",
      "Epoch 23255 - Train Loss: 0.074961, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.793814\n",
      "Epoch 23256 - Train Loss: 0.074959, Train Acc: 0.887179 | Val Loss: 0.108830, Val Acc: 0.793814\n",
      "Epoch 23257 - Train Loss: 0.074957, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.793814\n",
      "Epoch 23258 - Train Loss: 0.074955, Train Acc: 0.887179 | Val Loss: 0.108829, Val Acc: 0.793814\n",
      "Epoch 23259 - Train Loss: 0.074954, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.793814\n",
      "Epoch 23260 - Train Loss: 0.074952, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.793814\n",
      "Epoch 23261 - Train Loss: 0.074950, Train Acc: 0.887179 | Val Loss: 0.108828, Val Acc: 0.793814\n",
      "Epoch 23262 - Train Loss: 0.074949, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.793814\n",
      "Epoch 23263 - Train Loss: 0.074947, Train Acc: 0.887179 | Val Loss: 0.108827, Val Acc: 0.793814\n",
      "Epoch 23264 - Train Loss: 0.074945, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.793814\n",
      "Epoch 23265 - Train Loss: 0.074944, Train Acc: 0.887179 | Val Loss: 0.108826, Val Acc: 0.793814\n",
      "Epoch 23266 - Train Loss: 0.074942, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.793814\n",
      "Epoch 23267 - Train Loss: 0.074940, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.793814\n",
      "Epoch 23268 - Train Loss: 0.074938, Train Acc: 0.887179 | Val Loss: 0.108825, Val Acc: 0.793814\n",
      "Epoch 23269 - Train Loss: 0.074937, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.793814\n",
      "Epoch 23270 - Train Loss: 0.074935, Train Acc: 0.887179 | Val Loss: 0.108824, Val Acc: 0.793814\n",
      "Epoch 23271 - Train Loss: 0.074933, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.793814\n",
      "Epoch 23272 - Train Loss: 0.074932, Train Acc: 0.887179 | Val Loss: 0.108823, Val Acc: 0.793814\n",
      "Epoch 23273 - Train Loss: 0.074930, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.793814\n",
      "Epoch 23274 - Train Loss: 0.074928, Train Acc: 0.887179 | Val Loss: 0.108822, Val Acc: 0.793814\n",
      "Epoch 23275 - Train Loss: 0.074927, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.793814\n",
      "Epoch 23276 - Train Loss: 0.074925, Train Acc: 0.887179 | Val Loss: 0.108821, Val Acc: 0.793814\n",
      "Epoch 23277 - Train Loss: 0.074923, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.793814\n",
      "Epoch 23278 - Train Loss: 0.074921, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.793814\n",
      "Epoch 23279 - Train Loss: 0.074920, Train Acc: 0.887179 | Val Loss: 0.108820, Val Acc: 0.793814\n",
      "Epoch 23280 - Train Loss: 0.074918, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.793814\n",
      "Epoch 23281 - Train Loss: 0.074916, Train Acc: 0.887179 | Val Loss: 0.108819, Val Acc: 0.793814\n",
      "Epoch 23282 - Train Loss: 0.074915, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.793814\n",
      "Epoch 23283 - Train Loss: 0.074913, Train Acc: 0.887179 | Val Loss: 0.108818, Val Acc: 0.793814\n",
      "Epoch 23284 - Train Loss: 0.074911, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.793814\n",
      "Epoch 23285 - Train Loss: 0.074910, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.793814\n",
      "Epoch 23286 - Train Loss: 0.074908, Train Acc: 0.887179 | Val Loss: 0.108817, Val Acc: 0.793814\n",
      "Epoch 23287 - Train Loss: 0.074906, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.793814\n",
      "Epoch 23288 - Train Loss: 0.074904, Train Acc: 0.887179 | Val Loss: 0.108816, Val Acc: 0.793814\n",
      "Epoch 23289 - Train Loss: 0.074903, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.793814\n",
      "Epoch 23290 - Train Loss: 0.074901, Train Acc: 0.887179 | Val Loss: 0.108815, Val Acc: 0.793814\n",
      "Epoch 23291 - Train Loss: 0.074899, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.793814\n",
      "Epoch 23292 - Train Loss: 0.074898, Train Acc: 0.887179 | Val Loss: 0.108814, Val Acc: 0.793814\n",
      "Epoch 23293 - Train Loss: 0.074896, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.793814\n",
      "Epoch 23294 - Train Loss: 0.074894, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.793814\n",
      "Epoch 23295 - Train Loss: 0.074893, Train Acc: 0.887179 | Val Loss: 0.108813, Val Acc: 0.793814\n",
      "Epoch 23296 - Train Loss: 0.074891, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.793814\n",
      "Epoch 23297 - Train Loss: 0.074889, Train Acc: 0.887179 | Val Loss: 0.108812, Val Acc: 0.793814\n",
      "Epoch 23298 - Train Loss: 0.074887, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.793814\n",
      "Epoch 23299 - Train Loss: 0.074886, Train Acc: 0.887179 | Val Loss: 0.108811, Val Acc: 0.793814\n",
      "Epoch 23300 - Train Loss: 0.074884, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.793814\n",
      "Epoch 23301 - Train Loss: 0.074882, Train Acc: 0.887179 | Val Loss: 0.108810, Val Acc: 0.793814\n",
      "Epoch 23302 - Train Loss: 0.074881, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.793814\n",
      "Epoch 23303 - Train Loss: 0.074879, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.793814\n",
      "Epoch 23304 - Train Loss: 0.074877, Train Acc: 0.887179 | Val Loss: 0.108809, Val Acc: 0.793814\n",
      "Epoch 23305 - Train Loss: 0.074876, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.793814\n",
      "Epoch 23306 - Train Loss: 0.074874, Train Acc: 0.887179 | Val Loss: 0.108808, Val Acc: 0.793814\n",
      "Epoch 23307 - Train Loss: 0.074872, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.793814\n",
      "Epoch 23308 - Train Loss: 0.074870, Train Acc: 0.887179 | Val Loss: 0.108807, Val Acc: 0.793814\n",
      "Epoch 23309 - Train Loss: 0.074869, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.793814\n",
      "Epoch 23310 - Train Loss: 0.074867, Train Acc: 0.887179 | Val Loss: 0.108806, Val Acc: 0.793814\n",
      "Epoch 23311 - Train Loss: 0.074865, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.793814\n",
      "Epoch 23312 - Train Loss: 0.074864, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.793814\n",
      "Epoch 23313 - Train Loss: 0.074862, Train Acc: 0.887179 | Val Loss: 0.108805, Val Acc: 0.793814\n",
      "Epoch 23314 - Train Loss: 0.074860, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.793814\n",
      "Epoch 23315 - Train Loss: 0.074859, Train Acc: 0.887179 | Val Loss: 0.108804, Val Acc: 0.793814\n",
      "Epoch 23316 - Train Loss: 0.074857, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.793814\n",
      "Epoch 23317 - Train Loss: 0.074855, Train Acc: 0.887179 | Val Loss: 0.108803, Val Acc: 0.793814\n",
      "Epoch 23318 - Train Loss: 0.074853, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.793814\n",
      "Epoch 23319 - Train Loss: 0.074852, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.793814\n",
      "Epoch 23320 - Train Loss: 0.074850, Train Acc: 0.887179 | Val Loss: 0.108802, Val Acc: 0.793814\n",
      "Epoch 23321 - Train Loss: 0.074848, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.793814\n",
      "Epoch 23322 - Train Loss: 0.074847, Train Acc: 0.887179 | Val Loss: 0.108801, Val Acc: 0.793814\n",
      "Epoch 23323 - Train Loss: 0.074845, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.793814\n",
      "Epoch 23324 - Train Loss: 0.074843, Train Acc: 0.887179 | Val Loss: 0.108800, Val Acc: 0.793814\n",
      "Epoch 23325 - Train Loss: 0.074842, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.793814\n",
      "Epoch 23326 - Train Loss: 0.074840, Train Acc: 0.887179 | Val Loss: 0.108799, Val Acc: 0.793814\n",
      "Epoch 23327 - Train Loss: 0.074838, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.793814\n",
      "Epoch 23328 - Train Loss: 0.074837, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.793814\n",
      "Epoch 23329 - Train Loss: 0.074835, Train Acc: 0.887179 | Val Loss: 0.108798, Val Acc: 0.793814\n",
      "Epoch 23330 - Train Loss: 0.074833, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.793814\n",
      "Epoch 23331 - Train Loss: 0.074831, Train Acc: 0.887179 | Val Loss: 0.108797, Val Acc: 0.793814\n",
      "Epoch 23332 - Train Loss: 0.074830, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.793814\n",
      "Epoch 23333 - Train Loss: 0.074828, Train Acc: 0.887179 | Val Loss: 0.108796, Val Acc: 0.793814\n",
      "Epoch 23334 - Train Loss: 0.074826, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.793814\n",
      "Epoch 23335 - Train Loss: 0.074825, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.793814\n",
      "Epoch 23336 - Train Loss: 0.074823, Train Acc: 0.887179 | Val Loss: 0.108795, Val Acc: 0.793814\n",
      "Epoch 23337 - Train Loss: 0.074821, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.793814\n",
      "Epoch 23338 - Train Loss: 0.074820, Train Acc: 0.887179 | Val Loss: 0.108794, Val Acc: 0.793814\n",
      "Epoch 23339 - Train Loss: 0.074818, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.793814\n",
      "Epoch 23340 - Train Loss: 0.074816, Train Acc: 0.887179 | Val Loss: 0.108793, Val Acc: 0.793814\n",
      "Epoch 23341 - Train Loss: 0.074815, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.793814\n",
      "Epoch 23342 - Train Loss: 0.074813, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.793814\n",
      "Epoch 23343 - Train Loss: 0.074811, Train Acc: 0.887179 | Val Loss: 0.108792, Val Acc: 0.793814\n",
      "Epoch 23344 - Train Loss: 0.074809, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.793814\n",
      "Epoch 23345 - Train Loss: 0.074808, Train Acc: 0.887179 | Val Loss: 0.108791, Val Acc: 0.793814\n",
      "Epoch 23346 - Train Loss: 0.074806, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.793814\n",
      "Epoch 23347 - Train Loss: 0.074804, Train Acc: 0.887179 | Val Loss: 0.108790, Val Acc: 0.793814\n",
      "Epoch 23348 - Train Loss: 0.074803, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.793814\n",
      "Epoch 23349 - Train Loss: 0.074801, Train Acc: 0.887179 | Val Loss: 0.108789, Val Acc: 0.793814\n",
      "Epoch 23350 - Train Loss: 0.074799, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.793814\n",
      "Epoch 23351 - Train Loss: 0.074798, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.793814\n",
      "Epoch 23352 - Train Loss: 0.074796, Train Acc: 0.887179 | Val Loss: 0.108788, Val Acc: 0.793814\n",
      "Epoch 23353 - Train Loss: 0.074794, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.793814\n",
      "Epoch 23354 - Train Loss: 0.074793, Train Acc: 0.887179 | Val Loss: 0.108787, Val Acc: 0.793814\n",
      "Epoch 23355 - Train Loss: 0.074791, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.793814\n",
      "Epoch 23356 - Train Loss: 0.074789, Train Acc: 0.887179 | Val Loss: 0.108786, Val Acc: 0.793814\n",
      "Epoch 23357 - Train Loss: 0.074787, Train Acc: 0.887179 | Val Loss: 0.108785, Val Acc: 0.793814\n",
      "Epoch 23358 - Train Loss: 0.074786, Train Acc: 0.887179 | Val Loss: 0.108785, Val Acc: 0.793814\n",
      "Epoch 23359 - Train Loss: 0.074784, Train Acc: 0.887179 | Val Loss: 0.108785, Val Acc: 0.793814\n",
      "Epoch 23360 - Train Loss: 0.074782, Train Acc: 0.887179 | Val Loss: 0.108784, Val Acc: 0.793814\n",
      "Epoch 23361 - Train Loss: 0.074781, Train Acc: 0.887179 | Val Loss: 0.108784, Val Acc: 0.793814\n",
      "Epoch 23362 - Train Loss: 0.074779, Train Acc: 0.887179 | Val Loss: 0.108783, Val Acc: 0.793814\n",
      "Epoch 23363 - Train Loss: 0.074777, Train Acc: 0.887179 | Val Loss: 0.108783, Val Acc: 0.793814\n",
      "Epoch 23364 - Train Loss: 0.074776, Train Acc: 0.887179 | Val Loss: 0.108782, Val Acc: 0.793814\n",
      "Epoch 23365 - Train Loss: 0.074774, Train Acc: 0.887179 | Val Loss: 0.108782, Val Acc: 0.793814\n",
      "Epoch 23366 - Train Loss: 0.074772, Train Acc: 0.887179 | Val Loss: 0.108782, Val Acc: 0.793814\n",
      "Epoch 23367 - Train Loss: 0.074771, Train Acc: 0.887179 | Val Loss: 0.108781, Val Acc: 0.793814\n",
      "Epoch 23368 - Train Loss: 0.074769, Train Acc: 0.887179 | Val Loss: 0.108781, Val Acc: 0.793814\n",
      "Epoch 23369 - Train Loss: 0.074767, Train Acc: 0.887179 | Val Loss: 0.108780, Val Acc: 0.793814\n",
      "Epoch 23370 - Train Loss: 0.074766, Train Acc: 0.887179 | Val Loss: 0.108780, Val Acc: 0.793814\n",
      "Epoch 23371 - Train Loss: 0.074764, Train Acc: 0.887179 | Val Loss: 0.108779, Val Acc: 0.793814\n",
      "Epoch 23372 - Train Loss: 0.074762, Train Acc: 0.887179 | Val Loss: 0.108779, Val Acc: 0.793814\n",
      "Epoch 23373 - Train Loss: 0.074760, Train Acc: 0.887179 | Val Loss: 0.108779, Val Acc: 0.793814\n",
      "Epoch 23374 - Train Loss: 0.074759, Train Acc: 0.887179 | Val Loss: 0.108778, Val Acc: 0.793814\n",
      "Epoch 23375 - Train Loss: 0.074757, Train Acc: 0.887179 | Val Loss: 0.108778, Val Acc: 0.793814\n",
      "Epoch 23376 - Train Loss: 0.074755, Train Acc: 0.887179 | Val Loss: 0.108777, Val Acc: 0.793814\n",
      "Epoch 23377 - Train Loss: 0.074754, Train Acc: 0.887179 | Val Loss: 0.108777, Val Acc: 0.793814\n",
      "Epoch 23378 - Train Loss: 0.074752, Train Acc: 0.887179 | Val Loss: 0.108776, Val Acc: 0.793814\n",
      "Epoch 23379 - Train Loss: 0.074750, Train Acc: 0.887179 | Val Loss: 0.108776, Val Acc: 0.793814\n",
      "Epoch 23380 - Train Loss: 0.074749, Train Acc: 0.887179 | Val Loss: 0.108776, Val Acc: 0.793814\n",
      "Epoch 23381 - Train Loss: 0.074747, Train Acc: 0.887179 | Val Loss: 0.108775, Val Acc: 0.793814\n",
      "Epoch 23382 - Train Loss: 0.074745, Train Acc: 0.887179 | Val Loss: 0.108775, Val Acc: 0.793814\n",
      "Epoch 23383 - Train Loss: 0.074744, Train Acc: 0.887179 | Val Loss: 0.108774, Val Acc: 0.793814\n",
      "Epoch 23384 - Train Loss: 0.074742, Train Acc: 0.887179 | Val Loss: 0.108774, Val Acc: 0.793814\n",
      "Epoch 23385 - Train Loss: 0.074740, Train Acc: 0.887179 | Val Loss: 0.108773, Val Acc: 0.793814\n",
      "Epoch 23386 - Train Loss: 0.074739, Train Acc: 0.887179 | Val Loss: 0.108773, Val Acc: 0.793814\n",
      "Epoch 23387 - Train Loss: 0.074737, Train Acc: 0.887179 | Val Loss: 0.108773, Val Acc: 0.793814\n",
      "Epoch 23388 - Train Loss: 0.074735, Train Acc: 0.887179 | Val Loss: 0.108772, Val Acc: 0.793814\n",
      "Epoch 23389 - Train Loss: 0.074733, Train Acc: 0.887179 | Val Loss: 0.108772, Val Acc: 0.793814\n",
      "Epoch 23390 - Train Loss: 0.074732, Train Acc: 0.887179 | Val Loss: 0.108771, Val Acc: 0.793814\n",
      "Epoch 23391 - Train Loss: 0.074730, Train Acc: 0.887179 | Val Loss: 0.108771, Val Acc: 0.793814\n",
      "Epoch 23392 - Train Loss: 0.074728, Train Acc: 0.887179 | Val Loss: 0.108770, Val Acc: 0.793814\n",
      "Epoch 23393 - Train Loss: 0.074727, Train Acc: 0.887179 | Val Loss: 0.108770, Val Acc: 0.793814\n",
      "Epoch 23394 - Train Loss: 0.074725, Train Acc: 0.887179 | Val Loss: 0.108770, Val Acc: 0.793814\n",
      "Epoch 23395 - Train Loss: 0.074723, Train Acc: 0.887179 | Val Loss: 0.108769, Val Acc: 0.793814\n",
      "Epoch 23396 - Train Loss: 0.074722, Train Acc: 0.887179 | Val Loss: 0.108769, Val Acc: 0.793814\n",
      "Epoch 23397 - Train Loss: 0.074720, Train Acc: 0.887179 | Val Loss: 0.108768, Val Acc: 0.793814\n",
      "Epoch 23398 - Train Loss: 0.074718, Train Acc: 0.887179 | Val Loss: 0.108768, Val Acc: 0.793814\n",
      "Epoch 23399 - Train Loss: 0.074717, Train Acc: 0.887179 | Val Loss: 0.108767, Val Acc: 0.793814\n",
      "Epoch 23400 - Train Loss: 0.074715, Train Acc: 0.887179 | Val Loss: 0.108767, Val Acc: 0.793814\n",
      "Epoch 23401 - Train Loss: 0.074713, Train Acc: 0.887179 | Val Loss: 0.108767, Val Acc: 0.793814\n",
      "Epoch 23402 - Train Loss: 0.074712, Train Acc: 0.887179 | Val Loss: 0.108766, Val Acc: 0.793814\n",
      "Epoch 23403 - Train Loss: 0.074710, Train Acc: 0.887179 | Val Loss: 0.108766, Val Acc: 0.793814\n",
      "Epoch 23404 - Train Loss: 0.074708, Train Acc: 0.887179 | Val Loss: 0.108765, Val Acc: 0.793814\n",
      "Epoch 23405 - Train Loss: 0.074707, Train Acc: 0.887179 | Val Loss: 0.108765, Val Acc: 0.793814\n",
      "Epoch 23406 - Train Loss: 0.074705, Train Acc: 0.887179 | Val Loss: 0.108764, Val Acc: 0.793814\n",
      "Epoch 23407 - Train Loss: 0.074703, Train Acc: 0.887179 | Val Loss: 0.108764, Val Acc: 0.793814\n",
      "Epoch 23408 - Train Loss: 0.074701, Train Acc: 0.887179 | Val Loss: 0.108764, Val Acc: 0.793814\n",
      "Epoch 23409 - Train Loss: 0.074700, Train Acc: 0.887179 | Val Loss: 0.108763, Val Acc: 0.793814\n",
      "Epoch 23410 - Train Loss: 0.074698, Train Acc: 0.887179 | Val Loss: 0.108763, Val Acc: 0.793814\n",
      "Epoch 23411 - Train Loss: 0.074696, Train Acc: 0.887179 | Val Loss: 0.108762, Val Acc: 0.793814\n",
      "Epoch 23412 - Train Loss: 0.074695, Train Acc: 0.887179 | Val Loss: 0.108762, Val Acc: 0.793814\n",
      "Epoch 23413 - Train Loss: 0.074693, Train Acc: 0.887179 | Val Loss: 0.108761, Val Acc: 0.793814\n",
      "Epoch 23414 - Train Loss: 0.074691, Train Acc: 0.887179 | Val Loss: 0.108761, Val Acc: 0.793814\n",
      "Epoch 23415 - Train Loss: 0.074690, Train Acc: 0.887179 | Val Loss: 0.108761, Val Acc: 0.793814\n",
      "Epoch 23416 - Train Loss: 0.074688, Train Acc: 0.887179 | Val Loss: 0.108760, Val Acc: 0.793814\n",
      "Epoch 23417 - Train Loss: 0.074686, Train Acc: 0.887179 | Val Loss: 0.108760, Val Acc: 0.793814\n",
      "Epoch 23418 - Train Loss: 0.074685, Train Acc: 0.887179 | Val Loss: 0.108759, Val Acc: 0.793814\n",
      "Epoch 23419 - Train Loss: 0.074683, Train Acc: 0.887179 | Val Loss: 0.108759, Val Acc: 0.793814\n",
      "Epoch 23420 - Train Loss: 0.074681, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.793814\n",
      "Epoch 23421 - Train Loss: 0.074680, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.793814\n",
      "Epoch 23422 - Train Loss: 0.074678, Train Acc: 0.888462 | Val Loss: 0.108758, Val Acc: 0.793814\n",
      "Epoch 23423 - Train Loss: 0.074676, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.793814\n",
      "Epoch 23424 - Train Loss: 0.074675, Train Acc: 0.888462 | Val Loss: 0.108757, Val Acc: 0.793814\n",
      "Epoch 23425 - Train Loss: 0.074673, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.793814\n",
      "Epoch 23426 - Train Loss: 0.074671, Train Acc: 0.888462 | Val Loss: 0.108756, Val Acc: 0.793814\n",
      "Epoch 23427 - Train Loss: 0.074670, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.793814\n",
      "Epoch 23428 - Train Loss: 0.074668, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.793814\n",
      "Epoch 23429 - Train Loss: 0.074666, Train Acc: 0.888462 | Val Loss: 0.108755, Val Acc: 0.793814\n",
      "Epoch 23430 - Train Loss: 0.074664, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.793814\n",
      "Epoch 23431 - Train Loss: 0.074663, Train Acc: 0.888462 | Val Loss: 0.108754, Val Acc: 0.793814\n",
      "Epoch 23432 - Train Loss: 0.074661, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.793814\n",
      "Epoch 23433 - Train Loss: 0.074659, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.793814\n",
      "Epoch 23434 - Train Loss: 0.074658, Train Acc: 0.888462 | Val Loss: 0.108753, Val Acc: 0.793814\n",
      "Epoch 23435 - Train Loss: 0.074656, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.793814\n",
      "Epoch 23436 - Train Loss: 0.074654, Train Acc: 0.888462 | Val Loss: 0.108752, Val Acc: 0.793814\n",
      "Epoch 23437 - Train Loss: 0.074653, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.793814\n",
      "Epoch 23438 - Train Loss: 0.074651, Train Acc: 0.888462 | Val Loss: 0.108751, Val Acc: 0.793814\n",
      "Epoch 23439 - Train Loss: 0.074649, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.793814\n",
      "Epoch 23440 - Train Loss: 0.074648, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.793814\n",
      "Epoch 23441 - Train Loss: 0.074646, Train Acc: 0.888462 | Val Loss: 0.108750, Val Acc: 0.793814\n",
      "Epoch 23442 - Train Loss: 0.074644, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.793814\n",
      "Epoch 23443 - Train Loss: 0.074643, Train Acc: 0.888462 | Val Loss: 0.108749, Val Acc: 0.793814\n",
      "Epoch 23444 - Train Loss: 0.074641, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.793814\n",
      "Epoch 23445 - Train Loss: 0.074639, Train Acc: 0.888462 | Val Loss: 0.108748, Val Acc: 0.793814\n",
      "Epoch 23446 - Train Loss: 0.074638, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.793814\n",
      "Epoch 23447 - Train Loss: 0.074636, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.793814\n",
      "Epoch 23448 - Train Loss: 0.074634, Train Acc: 0.888462 | Val Loss: 0.108747, Val Acc: 0.793814\n",
      "Epoch 23449 - Train Loss: 0.074633, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.793814\n",
      "Epoch 23450 - Train Loss: 0.074631, Train Acc: 0.888462 | Val Loss: 0.108746, Val Acc: 0.793814\n",
      "Epoch 23451 - Train Loss: 0.074629, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.793814\n",
      "Epoch 23452 - Train Loss: 0.074628, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.793814\n",
      "Epoch 23453 - Train Loss: 0.074626, Train Acc: 0.888462 | Val Loss: 0.108745, Val Acc: 0.793814\n",
      "Epoch 23454 - Train Loss: 0.074624, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.793814\n",
      "Epoch 23455 - Train Loss: 0.074623, Train Acc: 0.888462 | Val Loss: 0.108744, Val Acc: 0.793814\n",
      "Epoch 23456 - Train Loss: 0.074621, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.793814\n",
      "Epoch 23457 - Train Loss: 0.074619, Train Acc: 0.888462 | Val Loss: 0.108743, Val Acc: 0.793814\n",
      "Epoch 23458 - Train Loss: 0.074617, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.793814\n",
      "Epoch 23459 - Train Loss: 0.074616, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.793814\n",
      "Epoch 23460 - Train Loss: 0.074614, Train Acc: 0.888462 | Val Loss: 0.108742, Val Acc: 0.793814\n",
      "Epoch 23461 - Train Loss: 0.074612, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.793814\n",
      "Epoch 23462 - Train Loss: 0.074611, Train Acc: 0.888462 | Val Loss: 0.108741, Val Acc: 0.793814\n",
      "Epoch 23463 - Train Loss: 0.074609, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.793814\n",
      "Epoch 23464 - Train Loss: 0.074607, Train Acc: 0.888462 | Val Loss: 0.108740, Val Acc: 0.793814\n",
      "Epoch 23465 - Train Loss: 0.074606, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.793814\n",
      "Epoch 23466 - Train Loss: 0.074604, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.793814\n",
      "Epoch 23467 - Train Loss: 0.074602, Train Acc: 0.888462 | Val Loss: 0.108739, Val Acc: 0.793814\n",
      "Epoch 23468 - Train Loss: 0.074601, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.793814\n",
      "Epoch 23469 - Train Loss: 0.074599, Train Acc: 0.888462 | Val Loss: 0.108738, Val Acc: 0.793814\n",
      "Epoch 23470 - Train Loss: 0.074597, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.793814\n",
      "Epoch 23471 - Train Loss: 0.074596, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.793814\n",
      "Epoch 23472 - Train Loss: 0.074594, Train Acc: 0.888462 | Val Loss: 0.108737, Val Acc: 0.793814\n",
      "Epoch 23473 - Train Loss: 0.074592, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.793814\n",
      "Epoch 23474 - Train Loss: 0.074591, Train Acc: 0.888462 | Val Loss: 0.108736, Val Acc: 0.793814\n",
      "Epoch 23475 - Train Loss: 0.074589, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.793814\n",
      "Epoch 23476 - Train Loss: 0.074587, Train Acc: 0.888462 | Val Loss: 0.108735, Val Acc: 0.793814\n",
      "Epoch 23477 - Train Loss: 0.074586, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.793814\n",
      "Epoch 23478 - Train Loss: 0.074584, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.793814\n",
      "Epoch 23479 - Train Loss: 0.074582, Train Acc: 0.888462 | Val Loss: 0.108734, Val Acc: 0.793814\n",
      "Epoch 23480 - Train Loss: 0.074581, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.793814\n",
      "Epoch 23481 - Train Loss: 0.074579, Train Acc: 0.888462 | Val Loss: 0.108733, Val Acc: 0.793814\n",
      "Epoch 23482 - Train Loss: 0.074577, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.793814\n",
      "Epoch 23483 - Train Loss: 0.074576, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.793814\n",
      "Epoch 23484 - Train Loss: 0.074574, Train Acc: 0.888462 | Val Loss: 0.108732, Val Acc: 0.793814\n",
      "Epoch 23485 - Train Loss: 0.074572, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.793814\n",
      "Epoch 23486 - Train Loss: 0.074571, Train Acc: 0.888462 | Val Loss: 0.108731, Val Acc: 0.793814\n",
      "Epoch 23487 - Train Loss: 0.074569, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.793814\n",
      "Epoch 23488 - Train Loss: 0.074567, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.793814\n",
      "Epoch 23489 - Train Loss: 0.074566, Train Acc: 0.888462 | Val Loss: 0.108730, Val Acc: 0.793814\n",
      "Epoch 23490 - Train Loss: 0.074564, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.793814\n",
      "Epoch 23491 - Train Loss: 0.074562, Train Acc: 0.888462 | Val Loss: 0.108729, Val Acc: 0.793814\n",
      "Epoch 23492 - Train Loss: 0.074561, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.793814\n",
      "Epoch 23493 - Train Loss: 0.074559, Train Acc: 0.888462 | Val Loss: 0.108728, Val Acc: 0.793814\n",
      "Epoch 23494 - Train Loss: 0.074557, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.793814\n",
      "Epoch 23495 - Train Loss: 0.074556, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.804124\n",
      "Epoch 23496 - Train Loss: 0.074554, Train Acc: 0.888462 | Val Loss: 0.108727, Val Acc: 0.804124\n",
      "Epoch 23497 - Train Loss: 0.074552, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.804124\n",
      "Epoch 23498 - Train Loss: 0.074551, Train Acc: 0.888462 | Val Loss: 0.108726, Val Acc: 0.804124\n",
      "Epoch 23499 - Train Loss: 0.074549, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.804124\n",
      "Epoch 23500 - Train Loss: 0.074547, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.804124\n",
      "Epoch 23501 - Train Loss: 0.074546, Train Acc: 0.888462 | Val Loss: 0.108725, Val Acc: 0.804124\n",
      "Epoch 23502 - Train Loss: 0.074544, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.804124\n",
      "Epoch 23503 - Train Loss: 0.074542, Train Acc: 0.888462 | Val Loss: 0.108724, Val Acc: 0.804124\n",
      "Epoch 23504 - Train Loss: 0.074541, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.804124\n",
      "Epoch 23505 - Train Loss: 0.074539, Train Acc: 0.888462 | Val Loss: 0.108723, Val Acc: 0.804124\n",
      "Epoch 23506 - Train Loss: 0.074537, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.804124\n",
      "Epoch 23507 - Train Loss: 0.074536, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.804124\n",
      "Epoch 23508 - Train Loss: 0.074534, Train Acc: 0.888462 | Val Loss: 0.108722, Val Acc: 0.804124\n",
      "Epoch 23509 - Train Loss: 0.074532, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.804124\n",
      "Epoch 23510 - Train Loss: 0.074530, Train Acc: 0.888462 | Val Loss: 0.108721, Val Acc: 0.804124\n",
      "Epoch 23511 - Train Loss: 0.074529, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.804124\n",
      "Epoch 23512 - Train Loss: 0.074527, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.804124\n",
      "Epoch 23513 - Train Loss: 0.074525, Train Acc: 0.888462 | Val Loss: 0.108720, Val Acc: 0.804124\n",
      "Epoch 23514 - Train Loss: 0.074524, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.804124\n",
      "Epoch 23515 - Train Loss: 0.074522, Train Acc: 0.888462 | Val Loss: 0.108719, Val Acc: 0.804124\n",
      "Epoch 23516 - Train Loss: 0.074520, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.804124\n",
      "Epoch 23517 - Train Loss: 0.074519, Train Acc: 0.888462 | Val Loss: 0.108718, Val Acc: 0.804124\n",
      "Epoch 23518 - Train Loss: 0.074517, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.804124\n",
      "Epoch 23519 - Train Loss: 0.074515, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.804124\n",
      "Epoch 23520 - Train Loss: 0.074514, Train Acc: 0.888462 | Val Loss: 0.108717, Val Acc: 0.804124\n",
      "Epoch 23521 - Train Loss: 0.074512, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.804124\n",
      "Epoch 23522 - Train Loss: 0.074510, Train Acc: 0.888462 | Val Loss: 0.108716, Val Acc: 0.804124\n",
      "Epoch 23523 - Train Loss: 0.074509, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.804124\n",
      "Epoch 23524 - Train Loss: 0.074507, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.804124\n",
      "Epoch 23525 - Train Loss: 0.074505, Train Acc: 0.888462 | Val Loss: 0.108715, Val Acc: 0.804124\n",
      "Epoch 23526 - Train Loss: 0.074504, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.804124\n",
      "Epoch 23527 - Train Loss: 0.074502, Train Acc: 0.888462 | Val Loss: 0.108714, Val Acc: 0.804124\n",
      "Epoch 23528 - Train Loss: 0.074500, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.804124\n",
      "Epoch 23529 - Train Loss: 0.074499, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.804124\n",
      "Epoch 23530 - Train Loss: 0.074497, Train Acc: 0.888462 | Val Loss: 0.108713, Val Acc: 0.804124\n",
      "Epoch 23531 - Train Loss: 0.074495, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.804124\n",
      "Epoch 23532 - Train Loss: 0.074494, Train Acc: 0.888462 | Val Loss: 0.108712, Val Acc: 0.804124\n",
      "Epoch 23533 - Train Loss: 0.074492, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.804124\n",
      "Epoch 23534 - Train Loss: 0.074490, Train Acc: 0.888462 | Val Loss: 0.108711, Val Acc: 0.804124\n",
      "Epoch 23535 - Train Loss: 0.074489, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.804124\n",
      "Epoch 23536 - Train Loss: 0.074487, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.804124\n",
      "Epoch 23537 - Train Loss: 0.074485, Train Acc: 0.888462 | Val Loss: 0.108710, Val Acc: 0.804124\n",
      "Epoch 23538 - Train Loss: 0.074484, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.804124\n",
      "Epoch 23539 - Train Loss: 0.074482, Train Acc: 0.888462 | Val Loss: 0.108709, Val Acc: 0.804124\n",
      "Epoch 23540 - Train Loss: 0.074480, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.804124\n",
      "Epoch 23541 - Train Loss: 0.074479, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.804124\n",
      "Epoch 23542 - Train Loss: 0.074477, Train Acc: 0.888462 | Val Loss: 0.108708, Val Acc: 0.804124\n",
      "Epoch 23543 - Train Loss: 0.074475, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.804124\n",
      "Epoch 23544 - Train Loss: 0.074474, Train Acc: 0.888462 | Val Loss: 0.108707, Val Acc: 0.804124\n",
      "Epoch 23545 - Train Loss: 0.074472, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.804124\n",
      "Epoch 23546 - Train Loss: 0.074470, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.804124\n",
      "Epoch 23547 - Train Loss: 0.074469, Train Acc: 0.888462 | Val Loss: 0.108706, Val Acc: 0.804124\n",
      "Epoch 23548 - Train Loss: 0.074467, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.804124\n",
      "Epoch 23549 - Train Loss: 0.074465, Train Acc: 0.888462 | Val Loss: 0.108705, Val Acc: 0.804124\n",
      "Epoch 23550 - Train Loss: 0.074464, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.804124\n",
      "Epoch 23551 - Train Loss: 0.074462, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.804124\n",
      "Epoch 23552 - Train Loss: 0.074461, Train Acc: 0.888462 | Val Loss: 0.108704, Val Acc: 0.804124\n",
      "Epoch 23553 - Train Loss: 0.074459, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.804124\n",
      "Epoch 23554 - Train Loss: 0.074457, Train Acc: 0.888462 | Val Loss: 0.108703, Val Acc: 0.804124\n",
      "Epoch 23555 - Train Loss: 0.074456, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.804124\n",
      "Epoch 23556 - Train Loss: 0.074454, Train Acc: 0.888462 | Val Loss: 0.108702, Val Acc: 0.804124\n",
      "Epoch 23557 - Train Loss: 0.074452, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.804124\n",
      "Epoch 23558 - Train Loss: 0.074451, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.804124\n",
      "Epoch 23559 - Train Loss: 0.074449, Train Acc: 0.888462 | Val Loss: 0.108701, Val Acc: 0.804124\n",
      "Epoch 23560 - Train Loss: 0.074447, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.804124\n",
      "Epoch 23561 - Train Loss: 0.074446, Train Acc: 0.888462 | Val Loss: 0.108700, Val Acc: 0.804124\n",
      "Epoch 23562 - Train Loss: 0.074444, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.804124\n",
      "Epoch 23563 - Train Loss: 0.074442, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.804124\n",
      "Epoch 23564 - Train Loss: 0.074441, Train Acc: 0.888462 | Val Loss: 0.108699, Val Acc: 0.804124\n",
      "Epoch 23565 - Train Loss: 0.074439, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.804124\n",
      "Epoch 23566 - Train Loss: 0.074437, Train Acc: 0.888462 | Val Loss: 0.108698, Val Acc: 0.804124\n",
      "Epoch 23567 - Train Loss: 0.074436, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.804124\n",
      "Epoch 23568 - Train Loss: 0.074434, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.804124\n",
      "Epoch 23569 - Train Loss: 0.074432, Train Acc: 0.888462 | Val Loss: 0.108697, Val Acc: 0.804124\n",
      "Epoch 23570 - Train Loss: 0.074431, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.804124\n",
      "Epoch 23571 - Train Loss: 0.074429, Train Acc: 0.888462 | Val Loss: 0.108696, Val Acc: 0.804124\n",
      "Epoch 23572 - Train Loss: 0.074427, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.804124\n",
      "Epoch 23573 - Train Loss: 0.074426, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.804124\n",
      "Epoch 23574 - Train Loss: 0.074424, Train Acc: 0.888462 | Val Loss: 0.108695, Val Acc: 0.804124\n",
      "Epoch 23575 - Train Loss: 0.074422, Train Acc: 0.888462 | Val Loss: 0.108694, Val Acc: 0.804124\n",
      "Epoch 23576 - Train Loss: 0.074421, Train Acc: 0.888462 | Val Loss: 0.108694, Val Acc: 0.804124\n",
      "Epoch 23577 - Train Loss: 0.074419, Train Acc: 0.888462 | Val Loss: 0.108693, Val Acc: 0.804124\n",
      "Epoch 23578 - Train Loss: 0.074417, Train Acc: 0.888462 | Val Loss: 0.108693, Val Acc: 0.804124\n",
      "Epoch 23579 - Train Loss: 0.074416, Train Acc: 0.888462 | Val Loss: 0.108693, Val Acc: 0.804124\n",
      "Epoch 23580 - Train Loss: 0.074414, Train Acc: 0.888462 | Val Loss: 0.108692, Val Acc: 0.804124\n",
      "Epoch 23581 - Train Loss: 0.074412, Train Acc: 0.888462 | Val Loss: 0.108692, Val Acc: 0.804124\n",
      "Epoch 23582 - Train Loss: 0.074411, Train Acc: 0.888462 | Val Loss: 0.108691, Val Acc: 0.804124\n",
      "Epoch 23583 - Train Loss: 0.074409, Train Acc: 0.888462 | Val Loss: 0.108691, Val Acc: 0.804124\n",
      "Epoch 23584 - Train Loss: 0.074407, Train Acc: 0.888462 | Val Loss: 0.108691, Val Acc: 0.804124\n",
      "Epoch 23585 - Train Loss: 0.074406, Train Acc: 0.888462 | Val Loss: 0.108690, Val Acc: 0.804124\n",
      "Epoch 23586 - Train Loss: 0.074404, Train Acc: 0.888462 | Val Loss: 0.108690, Val Acc: 0.804124\n",
      "Epoch 23587 - Train Loss: 0.074402, Train Acc: 0.888462 | Val Loss: 0.108689, Val Acc: 0.804124\n",
      "Epoch 23588 - Train Loss: 0.074401, Train Acc: 0.888462 | Val Loss: 0.108689, Val Acc: 0.804124\n",
      "Epoch 23589 - Train Loss: 0.074399, Train Acc: 0.888462 | Val Loss: 0.108689, Val Acc: 0.804124\n",
      "Epoch 23590 - Train Loss: 0.074397, Train Acc: 0.888462 | Val Loss: 0.108688, Val Acc: 0.804124\n",
      "Epoch 23591 - Train Loss: 0.074396, Train Acc: 0.888462 | Val Loss: 0.108688, Val Acc: 0.804124\n",
      "Epoch 23592 - Train Loss: 0.074394, Train Acc: 0.888462 | Val Loss: 0.108687, Val Acc: 0.804124\n",
      "Epoch 23593 - Train Loss: 0.074392, Train Acc: 0.888462 | Val Loss: 0.108687, Val Acc: 0.804124\n",
      "Epoch 23594 - Train Loss: 0.074391, Train Acc: 0.888462 | Val Loss: 0.108686, Val Acc: 0.804124\n",
      "Epoch 23595 - Train Loss: 0.074389, Train Acc: 0.888462 | Val Loss: 0.108686, Val Acc: 0.804124\n",
      "Epoch 23596 - Train Loss: 0.074387, Train Acc: 0.888462 | Val Loss: 0.108686, Val Acc: 0.804124\n",
      "Epoch 23597 - Train Loss: 0.074386, Train Acc: 0.888462 | Val Loss: 0.108685, Val Acc: 0.804124\n",
      "Epoch 23598 - Train Loss: 0.074384, Train Acc: 0.888462 | Val Loss: 0.108685, Val Acc: 0.804124\n",
      "Epoch 23599 - Train Loss: 0.074382, Train Acc: 0.888462 | Val Loss: 0.108685, Val Acc: 0.804124\n",
      "Epoch 23600 - Train Loss: 0.074381, Train Acc: 0.888462 | Val Loss: 0.108684, Val Acc: 0.804124\n",
      "Epoch 23601 - Train Loss: 0.074379, Train Acc: 0.888462 | Val Loss: 0.108684, Val Acc: 0.804124\n",
      "Epoch 23602 - Train Loss: 0.074377, Train Acc: 0.888462 | Val Loss: 0.108683, Val Acc: 0.804124\n",
      "Epoch 23603 - Train Loss: 0.074376, Train Acc: 0.888462 | Val Loss: 0.108683, Val Acc: 0.804124\n",
      "Epoch 23604 - Train Loss: 0.074374, Train Acc: 0.888462 | Val Loss: 0.108682, Val Acc: 0.804124\n",
      "Epoch 23605 - Train Loss: 0.074373, Train Acc: 0.888462 | Val Loss: 0.108682, Val Acc: 0.804124\n",
      "Epoch 23606 - Train Loss: 0.074371, Train Acc: 0.888462 | Val Loss: 0.108682, Val Acc: 0.804124\n",
      "Epoch 23607 - Train Loss: 0.074369, Train Acc: 0.888462 | Val Loss: 0.108681, Val Acc: 0.804124\n",
      "Epoch 23608 - Train Loss: 0.074368, Train Acc: 0.888462 | Val Loss: 0.108681, Val Acc: 0.804124\n",
      "Epoch 23609 - Train Loss: 0.074366, Train Acc: 0.888462 | Val Loss: 0.108681, Val Acc: 0.804124\n",
      "Epoch 23610 - Train Loss: 0.074364, Train Acc: 0.888462 | Val Loss: 0.108680, Val Acc: 0.804124\n",
      "Epoch 23611 - Train Loss: 0.074363, Train Acc: 0.888462 | Val Loss: 0.108680, Val Acc: 0.804124\n",
      "Epoch 23612 - Train Loss: 0.074361, Train Acc: 0.888462 | Val Loss: 0.108679, Val Acc: 0.804124\n",
      "Epoch 23613 - Train Loss: 0.074359, Train Acc: 0.888462 | Val Loss: 0.108679, Val Acc: 0.804124\n",
      "Epoch 23614 - Train Loss: 0.074358, Train Acc: 0.888462 | Val Loss: 0.108678, Val Acc: 0.804124\n",
      "Epoch 23615 - Train Loss: 0.074356, Train Acc: 0.888462 | Val Loss: 0.108678, Val Acc: 0.804124\n",
      "Epoch 23616 - Train Loss: 0.074354, Train Acc: 0.888462 | Val Loss: 0.108678, Val Acc: 0.804124\n",
      "Epoch 23617 - Train Loss: 0.074353, Train Acc: 0.888462 | Val Loss: 0.108677, Val Acc: 0.804124\n",
      "Epoch 23618 - Train Loss: 0.074351, Train Acc: 0.888462 | Val Loss: 0.108677, Val Acc: 0.804124\n",
      "Epoch 23619 - Train Loss: 0.074349, Train Acc: 0.888462 | Val Loss: 0.108676, Val Acc: 0.804124\n",
      "Epoch 23620 - Train Loss: 0.074348, Train Acc: 0.888462 | Val Loss: 0.108676, Val Acc: 0.804124\n",
      "Epoch 23621 - Train Loss: 0.074346, Train Acc: 0.888462 | Val Loss: 0.108676, Val Acc: 0.804124\n",
      "Epoch 23622 - Train Loss: 0.074344, Train Acc: 0.888462 | Val Loss: 0.108675, Val Acc: 0.804124\n",
      "Epoch 23623 - Train Loss: 0.074343, Train Acc: 0.888462 | Val Loss: 0.108675, Val Acc: 0.804124\n",
      "Epoch 23624 - Train Loss: 0.074341, Train Acc: 0.888462 | Val Loss: 0.108674, Val Acc: 0.804124\n",
      "Epoch 23625 - Train Loss: 0.074339, Train Acc: 0.888462 | Val Loss: 0.108674, Val Acc: 0.804124\n",
      "Epoch 23626 - Train Loss: 0.074338, Train Acc: 0.888462 | Val Loss: 0.108674, Val Acc: 0.804124\n",
      "Epoch 23627 - Train Loss: 0.074336, Train Acc: 0.888462 | Val Loss: 0.108673, Val Acc: 0.804124\n",
      "Epoch 23628 - Train Loss: 0.074334, Train Acc: 0.888462 | Val Loss: 0.108673, Val Acc: 0.804124\n",
      "Epoch 23629 - Train Loss: 0.074333, Train Acc: 0.888462 | Val Loss: 0.108672, Val Acc: 0.804124\n",
      "Epoch 23630 - Train Loss: 0.074331, Train Acc: 0.888462 | Val Loss: 0.108672, Val Acc: 0.804124\n",
      "Epoch 23631 - Train Loss: 0.074329, Train Acc: 0.888462 | Val Loss: 0.108672, Val Acc: 0.804124\n",
      "Epoch 23632 - Train Loss: 0.074328, Train Acc: 0.888462 | Val Loss: 0.108671, Val Acc: 0.804124\n",
      "Epoch 23633 - Train Loss: 0.074326, Train Acc: 0.888462 | Val Loss: 0.108671, Val Acc: 0.804124\n",
      "Epoch 23634 - Train Loss: 0.074325, Train Acc: 0.888462 | Val Loss: 0.108671, Val Acc: 0.804124\n",
      "Epoch 23635 - Train Loss: 0.074323, Train Acc: 0.888462 | Val Loss: 0.108670, Val Acc: 0.804124\n",
      "Epoch 23636 - Train Loss: 0.074321, Train Acc: 0.888462 | Val Loss: 0.108670, Val Acc: 0.804124\n",
      "Epoch 23637 - Train Loss: 0.074320, Train Acc: 0.888462 | Val Loss: 0.108669, Val Acc: 0.804124\n",
      "Epoch 23638 - Train Loss: 0.074318, Train Acc: 0.888462 | Val Loss: 0.108669, Val Acc: 0.804124\n",
      "Epoch 23639 - Train Loss: 0.074316, Train Acc: 0.888462 | Val Loss: 0.108669, Val Acc: 0.804124\n",
      "Epoch 23640 - Train Loss: 0.074315, Train Acc: 0.888462 | Val Loss: 0.108668, Val Acc: 0.804124\n",
      "Epoch 23641 - Train Loss: 0.074313, Train Acc: 0.888462 | Val Loss: 0.108668, Val Acc: 0.804124\n",
      "Epoch 23642 - Train Loss: 0.074311, Train Acc: 0.888462 | Val Loss: 0.108667, Val Acc: 0.804124\n",
      "Epoch 23643 - Train Loss: 0.074310, Train Acc: 0.888462 | Val Loss: 0.108667, Val Acc: 0.804124\n",
      "Epoch 23644 - Train Loss: 0.074308, Train Acc: 0.888462 | Val Loss: 0.108667, Val Acc: 0.804124\n",
      "Epoch 23645 - Train Loss: 0.074306, Train Acc: 0.888462 | Val Loss: 0.108666, Val Acc: 0.804124\n",
      "Epoch 23646 - Train Loss: 0.074305, Train Acc: 0.888462 | Val Loss: 0.108666, Val Acc: 0.804124\n",
      "Epoch 23647 - Train Loss: 0.074303, Train Acc: 0.888462 | Val Loss: 0.108665, Val Acc: 0.804124\n",
      "Epoch 23648 - Train Loss: 0.074301, Train Acc: 0.888462 | Val Loss: 0.108665, Val Acc: 0.804124\n",
      "Epoch 23649 - Train Loss: 0.074300, Train Acc: 0.888462 | Val Loss: 0.108664, Val Acc: 0.804124\n",
      "Epoch 23650 - Train Loss: 0.074298, Train Acc: 0.888462 | Val Loss: 0.108664, Val Acc: 0.804124\n",
      "Epoch 23651 - Train Loss: 0.074296, Train Acc: 0.888462 | Val Loss: 0.108664, Val Acc: 0.804124\n",
      "Epoch 23652 - Train Loss: 0.074295, Train Acc: 0.888462 | Val Loss: 0.108663, Val Acc: 0.804124\n",
      "Epoch 23653 - Train Loss: 0.074293, Train Acc: 0.888462 | Val Loss: 0.108663, Val Acc: 0.804124\n",
      "Epoch 23654 - Train Loss: 0.074292, Train Acc: 0.888462 | Val Loss: 0.108663, Val Acc: 0.804124\n",
      "Epoch 23655 - Train Loss: 0.074290, Train Acc: 0.888462 | Val Loss: 0.108662, Val Acc: 0.804124\n",
      "Epoch 23656 - Train Loss: 0.074288, Train Acc: 0.888462 | Val Loss: 0.108662, Val Acc: 0.804124\n",
      "Epoch 23657 - Train Loss: 0.074287, Train Acc: 0.888462 | Val Loss: 0.108661, Val Acc: 0.804124\n",
      "Epoch 23658 - Train Loss: 0.074285, Train Acc: 0.888462 | Val Loss: 0.108661, Val Acc: 0.804124\n",
      "Epoch 23659 - Train Loss: 0.074283, Train Acc: 0.888462 | Val Loss: 0.108661, Val Acc: 0.804124\n",
      "Epoch 23660 - Train Loss: 0.074282, Train Acc: 0.888462 | Val Loss: 0.108660, Val Acc: 0.804124\n",
      "Epoch 23661 - Train Loss: 0.074280, Train Acc: 0.888462 | Val Loss: 0.108660, Val Acc: 0.804124\n",
      "Epoch 23662 - Train Loss: 0.074278, Train Acc: 0.888462 | Val Loss: 0.108659, Val Acc: 0.804124\n",
      "Epoch 23663 - Train Loss: 0.074277, Train Acc: 0.888462 | Val Loss: 0.108659, Val Acc: 0.804124\n",
      "Epoch 23664 - Train Loss: 0.074275, Train Acc: 0.888462 | Val Loss: 0.108659, Val Acc: 0.804124\n",
      "Epoch 23665 - Train Loss: 0.074273, Train Acc: 0.888462 | Val Loss: 0.108658, Val Acc: 0.804124\n",
      "Epoch 23666 - Train Loss: 0.074272, Train Acc: 0.888462 | Val Loss: 0.108658, Val Acc: 0.804124\n",
      "Epoch 23667 - Train Loss: 0.074270, Train Acc: 0.888462 | Val Loss: 0.108657, Val Acc: 0.804124\n",
      "Epoch 23668 - Train Loss: 0.074268, Train Acc: 0.888462 | Val Loss: 0.108657, Val Acc: 0.804124\n",
      "Epoch 23669 - Train Loss: 0.074267, Train Acc: 0.888462 | Val Loss: 0.108657, Val Acc: 0.804124\n",
      "Epoch 23670 - Train Loss: 0.074265, Train Acc: 0.888462 | Val Loss: 0.108656, Val Acc: 0.804124\n",
      "Epoch 23671 - Train Loss: 0.074263, Train Acc: 0.888462 | Val Loss: 0.108656, Val Acc: 0.804124\n",
      "Epoch 23672 - Train Loss: 0.074262, Train Acc: 0.888462 | Val Loss: 0.108655, Val Acc: 0.804124\n",
      "Epoch 23673 - Train Loss: 0.074260, Train Acc: 0.888462 | Val Loss: 0.108655, Val Acc: 0.804124\n",
      "Epoch 23674 - Train Loss: 0.074259, Train Acc: 0.888462 | Val Loss: 0.108655, Val Acc: 0.804124\n",
      "Epoch 23675 - Train Loss: 0.074257, Train Acc: 0.888462 | Val Loss: 0.108654, Val Acc: 0.804124\n",
      "Epoch 23676 - Train Loss: 0.074255, Train Acc: 0.888462 | Val Loss: 0.108654, Val Acc: 0.804124\n",
      "Epoch 23677 - Train Loss: 0.074254, Train Acc: 0.888462 | Val Loss: 0.108654, Val Acc: 0.804124\n",
      "Epoch 23678 - Train Loss: 0.074252, Train Acc: 0.888462 | Val Loss: 0.108653, Val Acc: 0.804124\n",
      "Epoch 23679 - Train Loss: 0.074250, Train Acc: 0.888462 | Val Loss: 0.108653, Val Acc: 0.804124\n",
      "Epoch 23680 - Train Loss: 0.074249, Train Acc: 0.888462 | Val Loss: 0.108652, Val Acc: 0.804124\n",
      "Epoch 23681 - Train Loss: 0.074247, Train Acc: 0.888462 | Val Loss: 0.108652, Val Acc: 0.804124\n",
      "Epoch 23682 - Train Loss: 0.074245, Train Acc: 0.888462 | Val Loss: 0.108651, Val Acc: 0.804124\n",
      "Epoch 23683 - Train Loss: 0.074244, Train Acc: 0.888462 | Val Loss: 0.108651, Val Acc: 0.804124\n",
      "Epoch 23684 - Train Loss: 0.074242, Train Acc: 0.888462 | Val Loss: 0.108651, Val Acc: 0.804124\n",
      "Epoch 23685 - Train Loss: 0.074240, Train Acc: 0.888462 | Val Loss: 0.108650, Val Acc: 0.804124\n",
      "Epoch 23686 - Train Loss: 0.074239, Train Acc: 0.888462 | Val Loss: 0.108650, Val Acc: 0.804124\n",
      "Epoch 23687 - Train Loss: 0.074237, Train Acc: 0.888462 | Val Loss: 0.108650, Val Acc: 0.804124\n",
      "Epoch 23688 - Train Loss: 0.074235, Train Acc: 0.888462 | Val Loss: 0.108649, Val Acc: 0.804124\n",
      "Epoch 23689 - Train Loss: 0.074234, Train Acc: 0.888462 | Val Loss: 0.108649, Val Acc: 0.804124\n",
      "Epoch 23690 - Train Loss: 0.074232, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.804124\n",
      "Epoch 23691 - Train Loss: 0.074231, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.804124\n",
      "Epoch 23692 - Train Loss: 0.074229, Train Acc: 0.889744 | Val Loss: 0.108648, Val Acc: 0.804124\n",
      "Epoch 23693 - Train Loss: 0.074227, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.804124\n",
      "Epoch 23694 - Train Loss: 0.074226, Train Acc: 0.889744 | Val Loss: 0.108647, Val Acc: 0.804124\n",
      "Epoch 23695 - Train Loss: 0.074224, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.804124\n",
      "Epoch 23696 - Train Loss: 0.074222, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.804124\n",
      "Epoch 23697 - Train Loss: 0.074221, Train Acc: 0.889744 | Val Loss: 0.108646, Val Acc: 0.804124\n",
      "Epoch 23698 - Train Loss: 0.074219, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.804124\n",
      "Epoch 23699 - Train Loss: 0.074217, Train Acc: 0.889744 | Val Loss: 0.108645, Val Acc: 0.804124\n",
      "Epoch 23700 - Train Loss: 0.074216, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.804124\n",
      "Epoch 23701 - Train Loss: 0.074214, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.804124\n",
      "Epoch 23702 - Train Loss: 0.074212, Train Acc: 0.889744 | Val Loss: 0.108644, Val Acc: 0.804124\n",
      "Epoch 23703 - Train Loss: 0.074211, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.804124\n",
      "Epoch 23704 - Train Loss: 0.074209, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.804124\n",
      "Epoch 23705 - Train Loss: 0.074208, Train Acc: 0.889744 | Val Loss: 0.108643, Val Acc: 0.804124\n",
      "Epoch 23706 - Train Loss: 0.074206, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.804124\n",
      "Epoch 23707 - Train Loss: 0.074204, Train Acc: 0.889744 | Val Loss: 0.108642, Val Acc: 0.804124\n",
      "Epoch 23708 - Train Loss: 0.074203, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.804124\n",
      "Epoch 23709 - Train Loss: 0.074201, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.804124\n",
      "Epoch 23710 - Train Loss: 0.074199, Train Acc: 0.889744 | Val Loss: 0.108641, Val Acc: 0.804124\n",
      "Epoch 23711 - Train Loss: 0.074198, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.804124\n",
      "Epoch 23712 - Train Loss: 0.074196, Train Acc: 0.889744 | Val Loss: 0.108640, Val Acc: 0.804124\n",
      "Epoch 23713 - Train Loss: 0.074194, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.804124\n",
      "Epoch 23714 - Train Loss: 0.074193, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.804124\n",
      "Epoch 23715 - Train Loss: 0.074191, Train Acc: 0.889744 | Val Loss: 0.108639, Val Acc: 0.804124\n",
      "Epoch 23716 - Train Loss: 0.074189, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.804124\n",
      "Epoch 23717 - Train Loss: 0.074188, Train Acc: 0.889744 | Val Loss: 0.108638, Val Acc: 0.804124\n",
      "Epoch 23718 - Train Loss: 0.074186, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.804124\n",
      "Epoch 23719 - Train Loss: 0.074185, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.804124\n",
      "Epoch 23720 - Train Loss: 0.074183, Train Acc: 0.889744 | Val Loss: 0.108637, Val Acc: 0.804124\n",
      "Epoch 23721 - Train Loss: 0.074181, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.804124\n",
      "Epoch 23722 - Train Loss: 0.074180, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.804124\n",
      "Epoch 23723 - Train Loss: 0.074178, Train Acc: 0.889744 | Val Loss: 0.108636, Val Acc: 0.804124\n",
      "Epoch 23724 - Train Loss: 0.074176, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.804124\n",
      "Epoch 23725 - Train Loss: 0.074175, Train Acc: 0.889744 | Val Loss: 0.108635, Val Acc: 0.804124\n",
      "Epoch 23726 - Train Loss: 0.074173, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.804124\n",
      "Epoch 23727 - Train Loss: 0.074171, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.804124\n",
      "Epoch 23728 - Train Loss: 0.074170, Train Acc: 0.889744 | Val Loss: 0.108634, Val Acc: 0.804124\n",
      "Epoch 23729 - Train Loss: 0.074168, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.804124\n",
      "Epoch 23730 - Train Loss: 0.074166, Train Acc: 0.889744 | Val Loss: 0.108633, Val Acc: 0.804124\n",
      "Epoch 23731 - Train Loss: 0.074165, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.804124\n",
      "Epoch 23732 - Train Loss: 0.074163, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.804124\n",
      "Epoch 23733 - Train Loss: 0.074162, Train Acc: 0.889744 | Val Loss: 0.108632, Val Acc: 0.804124\n",
      "Epoch 23734 - Train Loss: 0.074160, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.804124\n",
      "Epoch 23735 - Train Loss: 0.074158, Train Acc: 0.889744 | Val Loss: 0.108631, Val Acc: 0.804124\n",
      "Epoch 23736 - Train Loss: 0.074157, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.804124\n",
      "Epoch 23737 - Train Loss: 0.074155, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.804124\n",
      "Epoch 23738 - Train Loss: 0.074153, Train Acc: 0.889744 | Val Loss: 0.108630, Val Acc: 0.804124\n",
      "Epoch 23739 - Train Loss: 0.074152, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.804124\n",
      "Epoch 23740 - Train Loss: 0.074150, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.804124\n",
      "Epoch 23741 - Train Loss: 0.074148, Train Acc: 0.889744 | Val Loss: 0.108629, Val Acc: 0.804124\n",
      "Epoch 23742 - Train Loss: 0.074147, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.804124\n",
      "Epoch 23743 - Train Loss: 0.074145, Train Acc: 0.889744 | Val Loss: 0.108628, Val Acc: 0.804124\n",
      "Epoch 23744 - Train Loss: 0.074144, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.804124\n",
      "Epoch 23745 - Train Loss: 0.074142, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.804124\n",
      "Epoch 23746 - Train Loss: 0.074140, Train Acc: 0.889744 | Val Loss: 0.108627, Val Acc: 0.804124\n",
      "Epoch 23747 - Train Loss: 0.074139, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.804124\n",
      "Epoch 23748 - Train Loss: 0.074137, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.804124\n",
      "Epoch 23749 - Train Loss: 0.074135, Train Acc: 0.889744 | Val Loss: 0.108626, Val Acc: 0.804124\n",
      "Epoch 23750 - Train Loss: 0.074134, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.804124\n",
      "Epoch 23751 - Train Loss: 0.074132, Train Acc: 0.889744 | Val Loss: 0.108625, Val Acc: 0.804124\n",
      "Epoch 23752 - Train Loss: 0.074130, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.804124\n",
      "Epoch 23753 - Train Loss: 0.074129, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.804124\n",
      "Epoch 23754 - Train Loss: 0.074127, Train Acc: 0.889744 | Val Loss: 0.108624, Val Acc: 0.804124\n",
      "Epoch 23755 - Train Loss: 0.074126, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.804124\n",
      "Epoch 23756 - Train Loss: 0.074124, Train Acc: 0.889744 | Val Loss: 0.108623, Val Acc: 0.804124\n",
      "Epoch 23757 - Train Loss: 0.074122, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.804124\n",
      "Epoch 23758 - Train Loss: 0.074121, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.804124\n",
      "Epoch 23759 - Train Loss: 0.074119, Train Acc: 0.889744 | Val Loss: 0.108622, Val Acc: 0.804124\n",
      "Epoch 23760 - Train Loss: 0.074117, Train Acc: 0.889744 | Val Loss: 0.108621, Val Acc: 0.804124\n",
      "Epoch 23761 - Train Loss: 0.074116, Train Acc: 0.889744 | Val Loss: 0.108621, Val Acc: 0.804124\n",
      "Epoch 23762 - Train Loss: 0.074114, Train Acc: 0.889744 | Val Loss: 0.108621, Val Acc: 0.804124\n",
      "Epoch 23763 - Train Loss: 0.074112, Train Acc: 0.889744 | Val Loss: 0.108620, Val Acc: 0.804124\n",
      "Epoch 23764 - Train Loss: 0.074111, Train Acc: 0.889744 | Val Loss: 0.108620, Val Acc: 0.804124\n",
      "Epoch 23765 - Train Loss: 0.074109, Train Acc: 0.889744 | Val Loss: 0.108619, Val Acc: 0.804124\n",
      "Epoch 23766 - Train Loss: 0.074108, Train Acc: 0.889744 | Val Loss: 0.108619, Val Acc: 0.804124\n",
      "Epoch 23767 - Train Loss: 0.074106, Train Acc: 0.889744 | Val Loss: 0.108619, Val Acc: 0.804124\n",
      "Epoch 23768 - Train Loss: 0.074104, Train Acc: 0.889744 | Val Loss: 0.108618, Val Acc: 0.804124\n",
      "Epoch 23769 - Train Loss: 0.074103, Train Acc: 0.889744 | Val Loss: 0.108618, Val Acc: 0.804124\n",
      "Epoch 23770 - Train Loss: 0.074101, Train Acc: 0.889744 | Val Loss: 0.108617, Val Acc: 0.804124\n",
      "Epoch 23771 - Train Loss: 0.074099, Train Acc: 0.889744 | Val Loss: 0.108617, Val Acc: 0.804124\n",
      "Epoch 23772 - Train Loss: 0.074098, Train Acc: 0.889744 | Val Loss: 0.108617, Val Acc: 0.804124\n",
      "Epoch 23773 - Train Loss: 0.074096, Train Acc: 0.889744 | Val Loss: 0.108616, Val Acc: 0.804124\n",
      "Epoch 23774 - Train Loss: 0.074094, Train Acc: 0.889744 | Val Loss: 0.108616, Val Acc: 0.804124\n",
      "Epoch 23775 - Train Loss: 0.074093, Train Acc: 0.889744 | Val Loss: 0.108616, Val Acc: 0.804124\n",
      "Epoch 23776 - Train Loss: 0.074091, Train Acc: 0.889744 | Val Loss: 0.108615, Val Acc: 0.804124\n",
      "Epoch 23777 - Train Loss: 0.074090, Train Acc: 0.889744 | Val Loss: 0.108615, Val Acc: 0.804124\n",
      "Epoch 23778 - Train Loss: 0.074088, Train Acc: 0.889744 | Val Loss: 0.108614, Val Acc: 0.804124\n",
      "Epoch 23779 - Train Loss: 0.074086, Train Acc: 0.889744 | Val Loss: 0.108614, Val Acc: 0.804124\n",
      "Epoch 23780 - Train Loss: 0.074085, Train Acc: 0.889744 | Val Loss: 0.108614, Val Acc: 0.804124\n",
      "Epoch 23781 - Train Loss: 0.074083, Train Acc: 0.889744 | Val Loss: 0.108613, Val Acc: 0.804124\n",
      "Epoch 23782 - Train Loss: 0.074081, Train Acc: 0.889744 | Val Loss: 0.108613, Val Acc: 0.804124\n",
      "Epoch 23783 - Train Loss: 0.074080, Train Acc: 0.889744 | Val Loss: 0.108612, Val Acc: 0.804124\n",
      "Epoch 23784 - Train Loss: 0.074078, Train Acc: 0.889744 | Val Loss: 0.108612, Val Acc: 0.804124\n",
      "Epoch 23785 - Train Loss: 0.074076, Train Acc: 0.889744 | Val Loss: 0.108612, Val Acc: 0.804124\n",
      "Epoch 23786 - Train Loss: 0.074075, Train Acc: 0.889744 | Val Loss: 0.108611, Val Acc: 0.804124\n",
      "Epoch 23787 - Train Loss: 0.074073, Train Acc: 0.889744 | Val Loss: 0.108611, Val Acc: 0.804124\n",
      "Epoch 23788 - Train Loss: 0.074072, Train Acc: 0.889744 | Val Loss: 0.108611, Val Acc: 0.804124\n",
      "Epoch 23789 - Train Loss: 0.074070, Train Acc: 0.889744 | Val Loss: 0.108610, Val Acc: 0.804124\n",
      "Epoch 23790 - Train Loss: 0.074068, Train Acc: 0.889744 | Val Loss: 0.108610, Val Acc: 0.804124\n",
      "Epoch 23791 - Train Loss: 0.074067, Train Acc: 0.889744 | Val Loss: 0.108609, Val Acc: 0.804124\n",
      "Epoch 23792 - Train Loss: 0.074065, Train Acc: 0.889744 | Val Loss: 0.108609, Val Acc: 0.804124\n",
      "Epoch 23793 - Train Loss: 0.074063, Train Acc: 0.889744 | Val Loss: 0.108609, Val Acc: 0.804124\n",
      "Epoch 23794 - Train Loss: 0.074062, Train Acc: 0.889744 | Val Loss: 0.108608, Val Acc: 0.804124\n",
      "Epoch 23795 - Train Loss: 0.074060, Train Acc: 0.889744 | Val Loss: 0.108608, Val Acc: 0.804124\n",
      "Epoch 23796 - Train Loss: 0.074059, Train Acc: 0.889744 | Val Loss: 0.108608, Val Acc: 0.804124\n",
      "Epoch 23797 - Train Loss: 0.074057, Train Acc: 0.889744 | Val Loss: 0.108607, Val Acc: 0.804124\n",
      "Epoch 23798 - Train Loss: 0.074055, Train Acc: 0.889744 | Val Loss: 0.108607, Val Acc: 0.804124\n",
      "Epoch 23799 - Train Loss: 0.074054, Train Acc: 0.889744 | Val Loss: 0.108606, Val Acc: 0.804124\n",
      "Epoch 23800 - Train Loss: 0.074052, Train Acc: 0.889744 | Val Loss: 0.108606, Val Acc: 0.804124\n",
      "Epoch 23801 - Train Loss: 0.074050, Train Acc: 0.889744 | Val Loss: 0.108606, Val Acc: 0.804124\n",
      "Epoch 23802 - Train Loss: 0.074049, Train Acc: 0.889744 | Val Loss: 0.108605, Val Acc: 0.804124\n",
      "Epoch 23803 - Train Loss: 0.074047, Train Acc: 0.889744 | Val Loss: 0.108605, Val Acc: 0.804124\n",
      "Epoch 23804 - Train Loss: 0.074045, Train Acc: 0.889744 | Val Loss: 0.108605, Val Acc: 0.804124\n",
      "Epoch 23805 - Train Loss: 0.074044, Train Acc: 0.889744 | Val Loss: 0.108604, Val Acc: 0.804124\n",
      "Epoch 23806 - Train Loss: 0.074042, Train Acc: 0.889744 | Val Loss: 0.108604, Val Acc: 0.804124\n",
      "Epoch 23807 - Train Loss: 0.074041, Train Acc: 0.889744 | Val Loss: 0.108603, Val Acc: 0.804124\n",
      "Epoch 23808 - Train Loss: 0.074039, Train Acc: 0.889744 | Val Loss: 0.108603, Val Acc: 0.804124\n",
      "Epoch 23809 - Train Loss: 0.074037, Train Acc: 0.889744 | Val Loss: 0.108603, Val Acc: 0.804124\n",
      "Epoch 23810 - Train Loss: 0.074036, Train Acc: 0.889744 | Val Loss: 0.108602, Val Acc: 0.804124\n",
      "Epoch 23811 - Train Loss: 0.074034, Train Acc: 0.889744 | Val Loss: 0.108602, Val Acc: 0.804124\n",
      "Epoch 23812 - Train Loss: 0.074032, Train Acc: 0.889744 | Val Loss: 0.108602, Val Acc: 0.804124\n",
      "Epoch 23813 - Train Loss: 0.074031, Train Acc: 0.889744 | Val Loss: 0.108601, Val Acc: 0.804124\n",
      "Epoch 23814 - Train Loss: 0.074029, Train Acc: 0.889744 | Val Loss: 0.108601, Val Acc: 0.804124\n",
      "Epoch 23815 - Train Loss: 0.074028, Train Acc: 0.889744 | Val Loss: 0.108600, Val Acc: 0.804124\n",
      "Epoch 23816 - Train Loss: 0.074026, Train Acc: 0.889744 | Val Loss: 0.108600, Val Acc: 0.804124\n",
      "Epoch 23817 - Train Loss: 0.074024, Train Acc: 0.889744 | Val Loss: 0.108600, Val Acc: 0.804124\n",
      "Epoch 23818 - Train Loss: 0.074023, Train Acc: 0.889744 | Val Loss: 0.108599, Val Acc: 0.804124\n",
      "Epoch 23819 - Train Loss: 0.074021, Train Acc: 0.889744 | Val Loss: 0.108599, Val Acc: 0.804124\n",
      "Epoch 23820 - Train Loss: 0.074019, Train Acc: 0.889744 | Val Loss: 0.108599, Val Acc: 0.804124\n",
      "Epoch 23821 - Train Loss: 0.074018, Train Acc: 0.889744 | Val Loss: 0.108598, Val Acc: 0.804124\n",
      "Epoch 23822 - Train Loss: 0.074016, Train Acc: 0.889744 | Val Loss: 0.108598, Val Acc: 0.804124\n",
      "Epoch 23823 - Train Loss: 0.074014, Train Acc: 0.889744 | Val Loss: 0.108597, Val Acc: 0.804124\n",
      "Epoch 23824 - Train Loss: 0.074013, Train Acc: 0.889744 | Val Loss: 0.108597, Val Acc: 0.804124\n",
      "Epoch 23825 - Train Loss: 0.074011, Train Acc: 0.889744 | Val Loss: 0.108597, Val Acc: 0.804124\n",
      "Epoch 23826 - Train Loss: 0.074010, Train Acc: 0.889744 | Val Loss: 0.108596, Val Acc: 0.804124\n",
      "Epoch 23827 - Train Loss: 0.074008, Train Acc: 0.889744 | Val Loss: 0.108596, Val Acc: 0.804124\n",
      "Epoch 23828 - Train Loss: 0.074006, Train Acc: 0.889744 | Val Loss: 0.108595, Val Acc: 0.804124\n",
      "Epoch 23829 - Train Loss: 0.074005, Train Acc: 0.889744 | Val Loss: 0.108595, Val Acc: 0.804124\n",
      "Epoch 23830 - Train Loss: 0.074003, Train Acc: 0.889744 | Val Loss: 0.108595, Val Acc: 0.804124\n",
      "Epoch 23831 - Train Loss: 0.074001, Train Acc: 0.889744 | Val Loss: 0.108594, Val Acc: 0.804124\n",
      "Epoch 23832 - Train Loss: 0.074000, Train Acc: 0.889744 | Val Loss: 0.108594, Val Acc: 0.804124\n",
      "Epoch 23833 - Train Loss: 0.073998, Train Acc: 0.889744 | Val Loss: 0.108594, Val Acc: 0.804124\n",
      "Epoch 23834 - Train Loss: 0.073997, Train Acc: 0.889744 | Val Loss: 0.108593, Val Acc: 0.804124\n",
      "Epoch 23835 - Train Loss: 0.073995, Train Acc: 0.889744 | Val Loss: 0.108593, Val Acc: 0.804124\n",
      "Epoch 23836 - Train Loss: 0.073993, Train Acc: 0.889744 | Val Loss: 0.108592, Val Acc: 0.804124\n",
      "Epoch 23837 - Train Loss: 0.073992, Train Acc: 0.889744 | Val Loss: 0.108592, Val Acc: 0.804124\n",
      "Epoch 23838 - Train Loss: 0.073990, Train Acc: 0.889744 | Val Loss: 0.108592, Val Acc: 0.804124\n",
      "Epoch 23839 - Train Loss: 0.073988, Train Acc: 0.889744 | Val Loss: 0.108591, Val Acc: 0.804124\n",
      "Epoch 23840 - Train Loss: 0.073987, Train Acc: 0.889744 | Val Loss: 0.108591, Val Acc: 0.804124\n",
      "Epoch 23841 - Train Loss: 0.073985, Train Acc: 0.889744 | Val Loss: 0.108591, Val Acc: 0.804124\n",
      "Epoch 23842 - Train Loss: 0.073984, Train Acc: 0.889744 | Val Loss: 0.108590, Val Acc: 0.804124\n",
      "Epoch 23843 - Train Loss: 0.073982, Train Acc: 0.889744 | Val Loss: 0.108590, Val Acc: 0.804124\n",
      "Epoch 23844 - Train Loss: 0.073980, Train Acc: 0.889744 | Val Loss: 0.108590, Val Acc: 0.804124\n",
      "Epoch 23845 - Train Loss: 0.073979, Train Acc: 0.889744 | Val Loss: 0.108589, Val Acc: 0.804124\n",
      "Epoch 23846 - Train Loss: 0.073977, Train Acc: 0.889744 | Val Loss: 0.108589, Val Acc: 0.804124\n",
      "Epoch 23847 - Train Loss: 0.073975, Train Acc: 0.889744 | Val Loss: 0.108588, Val Acc: 0.804124\n",
      "Epoch 23848 - Train Loss: 0.073974, Train Acc: 0.889744 | Val Loss: 0.108588, Val Acc: 0.804124\n",
      "Epoch 23849 - Train Loss: 0.073972, Train Acc: 0.889744 | Val Loss: 0.108588, Val Acc: 0.804124\n",
      "Epoch 23850 - Train Loss: 0.073971, Train Acc: 0.889744 | Val Loss: 0.108587, Val Acc: 0.804124\n",
      "Epoch 23851 - Train Loss: 0.073969, Train Acc: 0.889744 | Val Loss: 0.108587, Val Acc: 0.804124\n",
      "Epoch 23852 - Train Loss: 0.073967, Train Acc: 0.889744 | Val Loss: 0.108587, Val Acc: 0.804124\n",
      "Epoch 23853 - Train Loss: 0.073966, Train Acc: 0.889744 | Val Loss: 0.108586, Val Acc: 0.804124\n",
      "Epoch 23854 - Train Loss: 0.073964, Train Acc: 0.889744 | Val Loss: 0.108586, Val Acc: 0.804124\n",
      "Epoch 23855 - Train Loss: 0.073962, Train Acc: 0.889744 | Val Loss: 0.108585, Val Acc: 0.804124\n",
      "Epoch 23856 - Train Loss: 0.073961, Train Acc: 0.889744 | Val Loss: 0.108585, Val Acc: 0.804124\n",
      "Epoch 23857 - Train Loss: 0.073959, Train Acc: 0.889744 | Val Loss: 0.108585, Val Acc: 0.804124\n",
      "Epoch 23858 - Train Loss: 0.073958, Train Acc: 0.889744 | Val Loss: 0.108584, Val Acc: 0.804124\n",
      "Epoch 23859 - Train Loss: 0.073956, Train Acc: 0.889744 | Val Loss: 0.108584, Val Acc: 0.804124\n",
      "Epoch 23860 - Train Loss: 0.073954, Train Acc: 0.889744 | Val Loss: 0.108584, Val Acc: 0.804124\n",
      "Epoch 23861 - Train Loss: 0.073953, Train Acc: 0.889744 | Val Loss: 0.108583, Val Acc: 0.804124\n",
      "Epoch 23862 - Train Loss: 0.073951, Train Acc: 0.889744 | Val Loss: 0.108583, Val Acc: 0.804124\n",
      "Epoch 23863 - Train Loss: 0.073949, Train Acc: 0.889744 | Val Loss: 0.108582, Val Acc: 0.804124\n",
      "Epoch 23864 - Train Loss: 0.073948, Train Acc: 0.889744 | Val Loss: 0.108582, Val Acc: 0.804124\n",
      "Epoch 23865 - Train Loss: 0.073946, Train Acc: 0.889744 | Val Loss: 0.108582, Val Acc: 0.804124\n",
      "Epoch 23866 - Train Loss: 0.073945, Train Acc: 0.889744 | Val Loss: 0.108581, Val Acc: 0.804124\n",
      "Epoch 23867 - Train Loss: 0.073943, Train Acc: 0.889744 | Val Loss: 0.108581, Val Acc: 0.804124\n",
      "Epoch 23868 - Train Loss: 0.073941, Train Acc: 0.889744 | Val Loss: 0.108581, Val Acc: 0.804124\n",
      "Epoch 23869 - Train Loss: 0.073940, Train Acc: 0.889744 | Val Loss: 0.108580, Val Acc: 0.804124\n",
      "Epoch 23870 - Train Loss: 0.073938, Train Acc: 0.889744 | Val Loss: 0.108580, Val Acc: 0.804124\n",
      "Epoch 23871 - Train Loss: 0.073936, Train Acc: 0.889744 | Val Loss: 0.108579, Val Acc: 0.804124\n",
      "Epoch 23872 - Train Loss: 0.073935, Train Acc: 0.889744 | Val Loss: 0.108579, Val Acc: 0.804124\n",
      "Epoch 23873 - Train Loss: 0.073933, Train Acc: 0.889744 | Val Loss: 0.108579, Val Acc: 0.804124\n",
      "Epoch 23874 - Train Loss: 0.073932, Train Acc: 0.889744 | Val Loss: 0.108578, Val Acc: 0.804124\n",
      "Epoch 23875 - Train Loss: 0.073930, Train Acc: 0.889744 | Val Loss: 0.108578, Val Acc: 0.804124\n",
      "Epoch 23876 - Train Loss: 0.073928, Train Acc: 0.889744 | Val Loss: 0.108578, Val Acc: 0.804124\n",
      "Epoch 23877 - Train Loss: 0.073927, Train Acc: 0.889744 | Val Loss: 0.108577, Val Acc: 0.804124\n",
      "Epoch 23878 - Train Loss: 0.073925, Train Acc: 0.889744 | Val Loss: 0.108577, Val Acc: 0.804124\n",
      "Epoch 23879 - Train Loss: 0.073924, Train Acc: 0.889744 | Val Loss: 0.108577, Val Acc: 0.804124\n",
      "Epoch 23880 - Train Loss: 0.073922, Train Acc: 0.889744 | Val Loss: 0.108576, Val Acc: 0.804124\n",
      "Epoch 23881 - Train Loss: 0.073920, Train Acc: 0.889744 | Val Loss: 0.108576, Val Acc: 0.804124\n",
      "Epoch 23882 - Train Loss: 0.073919, Train Acc: 0.889744 | Val Loss: 0.108575, Val Acc: 0.804124\n",
      "Epoch 23883 - Train Loss: 0.073917, Train Acc: 0.889744 | Val Loss: 0.108575, Val Acc: 0.804124\n",
      "Epoch 23884 - Train Loss: 0.073915, Train Acc: 0.889744 | Val Loss: 0.108575, Val Acc: 0.804124\n",
      "Epoch 23885 - Train Loss: 0.073914, Train Acc: 0.889744 | Val Loss: 0.108574, Val Acc: 0.804124\n",
      "Epoch 23886 - Train Loss: 0.073912, Train Acc: 0.889744 | Val Loss: 0.108574, Val Acc: 0.804124\n",
      "Epoch 23887 - Train Loss: 0.073911, Train Acc: 0.889744 | Val Loss: 0.108574, Val Acc: 0.804124\n",
      "Epoch 23888 - Train Loss: 0.073909, Train Acc: 0.889744 | Val Loss: 0.108573, Val Acc: 0.804124\n",
      "Epoch 23889 - Train Loss: 0.073907, Train Acc: 0.889744 | Val Loss: 0.108573, Val Acc: 0.804124\n",
      "Epoch 23890 - Train Loss: 0.073906, Train Acc: 0.889744 | Val Loss: 0.108572, Val Acc: 0.804124\n",
      "Epoch 23891 - Train Loss: 0.073904, Train Acc: 0.889744 | Val Loss: 0.108572, Val Acc: 0.804124\n",
      "Epoch 23892 - Train Loss: 0.073902, Train Acc: 0.889744 | Val Loss: 0.108572, Val Acc: 0.804124\n",
      "Epoch 23893 - Train Loss: 0.073901, Train Acc: 0.889744 | Val Loss: 0.108571, Val Acc: 0.804124\n",
      "Epoch 23894 - Train Loss: 0.073899, Train Acc: 0.889744 | Val Loss: 0.108571, Val Acc: 0.804124\n",
      "Epoch 23895 - Train Loss: 0.073898, Train Acc: 0.889744 | Val Loss: 0.108571, Val Acc: 0.804124\n",
      "Epoch 23896 - Train Loss: 0.073896, Train Acc: 0.889744 | Val Loss: 0.108570, Val Acc: 0.804124\n",
      "Epoch 23897 - Train Loss: 0.073894, Train Acc: 0.889744 | Val Loss: 0.108570, Val Acc: 0.804124\n",
      "Epoch 23898 - Train Loss: 0.073893, Train Acc: 0.889744 | Val Loss: 0.108570, Val Acc: 0.804124\n",
      "Epoch 23899 - Train Loss: 0.073891, Train Acc: 0.889744 | Val Loss: 0.108569, Val Acc: 0.804124\n",
      "Epoch 23900 - Train Loss: 0.073890, Train Acc: 0.889744 | Val Loss: 0.108569, Val Acc: 0.804124\n",
      "Epoch 23901 - Train Loss: 0.073888, Train Acc: 0.889744 | Val Loss: 0.108568, Val Acc: 0.804124\n",
      "Epoch 23902 - Train Loss: 0.073886, Train Acc: 0.889744 | Val Loss: 0.108568, Val Acc: 0.804124\n",
      "Epoch 23903 - Train Loss: 0.073885, Train Acc: 0.889744 | Val Loss: 0.108568, Val Acc: 0.804124\n",
      "Epoch 23904 - Train Loss: 0.073883, Train Acc: 0.889744 | Val Loss: 0.108567, Val Acc: 0.804124\n",
      "Epoch 23905 - Train Loss: 0.073881, Train Acc: 0.889744 | Val Loss: 0.108567, Val Acc: 0.804124\n",
      "Epoch 23906 - Train Loss: 0.073880, Train Acc: 0.889744 | Val Loss: 0.108567, Val Acc: 0.804124\n",
      "Epoch 23907 - Train Loss: 0.073878, Train Acc: 0.889744 | Val Loss: 0.108566, Val Acc: 0.804124\n",
      "Epoch 23908 - Train Loss: 0.073877, Train Acc: 0.889744 | Val Loss: 0.108566, Val Acc: 0.804124\n",
      "Epoch 23909 - Train Loss: 0.073875, Train Acc: 0.889744 | Val Loss: 0.108565, Val Acc: 0.804124\n",
      "Epoch 23910 - Train Loss: 0.073873, Train Acc: 0.889744 | Val Loss: 0.108565, Val Acc: 0.804124\n",
      "Epoch 23911 - Train Loss: 0.073872, Train Acc: 0.889744 | Val Loss: 0.108565, Val Acc: 0.804124\n",
      "Epoch 23912 - Train Loss: 0.073870, Train Acc: 0.889744 | Val Loss: 0.108564, Val Acc: 0.804124\n",
      "Epoch 23913 - Train Loss: 0.073868, Train Acc: 0.889744 | Val Loss: 0.108564, Val Acc: 0.804124\n",
      "Epoch 23914 - Train Loss: 0.073867, Train Acc: 0.889744 | Val Loss: 0.108564, Val Acc: 0.804124\n",
      "Epoch 23915 - Train Loss: 0.073865, Train Acc: 0.889744 | Val Loss: 0.108563, Val Acc: 0.804124\n",
      "Epoch 23916 - Train Loss: 0.073864, Train Acc: 0.889744 | Val Loss: 0.108563, Val Acc: 0.804124\n",
      "Epoch 23917 - Train Loss: 0.073862, Train Acc: 0.889744 | Val Loss: 0.108563, Val Acc: 0.804124\n",
      "Epoch 23918 - Train Loss: 0.073860, Train Acc: 0.889744 | Val Loss: 0.108562, Val Acc: 0.804124\n",
      "Epoch 23919 - Train Loss: 0.073859, Train Acc: 0.889744 | Val Loss: 0.108562, Val Acc: 0.804124\n",
      "Epoch 23920 - Train Loss: 0.073857, Train Acc: 0.889744 | Val Loss: 0.108561, Val Acc: 0.804124\n",
      "Epoch 23921 - Train Loss: 0.073856, Train Acc: 0.889744 | Val Loss: 0.108561, Val Acc: 0.804124\n",
      "Epoch 23922 - Train Loss: 0.073854, Train Acc: 0.889744 | Val Loss: 0.108561, Val Acc: 0.804124\n",
      "Epoch 23923 - Train Loss: 0.073852, Train Acc: 0.889744 | Val Loss: 0.108560, Val Acc: 0.804124\n",
      "Epoch 23924 - Train Loss: 0.073851, Train Acc: 0.889744 | Val Loss: 0.108560, Val Acc: 0.804124\n",
      "Epoch 23925 - Train Loss: 0.073849, Train Acc: 0.889744 | Val Loss: 0.108560, Val Acc: 0.804124\n",
      "Epoch 23926 - Train Loss: 0.073847, Train Acc: 0.889744 | Val Loss: 0.108559, Val Acc: 0.804124\n",
      "Epoch 23927 - Train Loss: 0.073846, Train Acc: 0.889744 | Val Loss: 0.108559, Val Acc: 0.804124\n",
      "Epoch 23928 - Train Loss: 0.073844, Train Acc: 0.889744 | Val Loss: 0.108559, Val Acc: 0.804124\n",
      "Epoch 23929 - Train Loss: 0.073843, Train Acc: 0.889744 | Val Loss: 0.108558, Val Acc: 0.804124\n",
      "Epoch 23930 - Train Loss: 0.073841, Train Acc: 0.889744 | Val Loss: 0.108558, Val Acc: 0.804124\n",
      "Epoch 23931 - Train Loss: 0.073839, Train Acc: 0.889744 | Val Loss: 0.108557, Val Acc: 0.804124\n",
      "Epoch 23932 - Train Loss: 0.073838, Train Acc: 0.889744 | Val Loss: 0.108557, Val Acc: 0.804124\n",
      "Epoch 23933 - Train Loss: 0.073836, Train Acc: 0.889744 | Val Loss: 0.108557, Val Acc: 0.804124\n",
      "Epoch 23934 - Train Loss: 0.073835, Train Acc: 0.889744 | Val Loss: 0.108556, Val Acc: 0.804124\n",
      "Epoch 23935 - Train Loss: 0.073833, Train Acc: 0.889744 | Val Loss: 0.108556, Val Acc: 0.804124\n",
      "Epoch 23936 - Train Loss: 0.073831, Train Acc: 0.889744 | Val Loss: 0.108556, Val Acc: 0.804124\n",
      "Epoch 23937 - Train Loss: 0.073830, Train Acc: 0.889744 | Val Loss: 0.108555, Val Acc: 0.804124\n",
      "Epoch 23938 - Train Loss: 0.073828, Train Acc: 0.889744 | Val Loss: 0.108555, Val Acc: 0.804124\n",
      "Epoch 23939 - Train Loss: 0.073826, Train Acc: 0.889744 | Val Loss: 0.108555, Val Acc: 0.804124\n",
      "Epoch 23940 - Train Loss: 0.073825, Train Acc: 0.889744 | Val Loss: 0.108554, Val Acc: 0.804124\n",
      "Epoch 23941 - Train Loss: 0.073823, Train Acc: 0.889744 | Val Loss: 0.108554, Val Acc: 0.804124\n",
      "Epoch 23942 - Train Loss: 0.073822, Train Acc: 0.889744 | Val Loss: 0.108553, Val Acc: 0.804124\n",
      "Epoch 23943 - Train Loss: 0.073820, Train Acc: 0.889744 | Val Loss: 0.108553, Val Acc: 0.804124\n",
      "Epoch 23944 - Train Loss: 0.073818, Train Acc: 0.889744 | Val Loss: 0.108553, Val Acc: 0.804124\n",
      "Epoch 23945 - Train Loss: 0.073817, Train Acc: 0.889744 | Val Loss: 0.108552, Val Acc: 0.804124\n",
      "Epoch 23946 - Train Loss: 0.073815, Train Acc: 0.889744 | Val Loss: 0.108552, Val Acc: 0.804124\n",
      "Epoch 23947 - Train Loss: 0.073814, Train Acc: 0.889744 | Val Loss: 0.108552, Val Acc: 0.804124\n",
      "Epoch 23948 - Train Loss: 0.073812, Train Acc: 0.889744 | Val Loss: 0.108551, Val Acc: 0.804124\n",
      "Epoch 23949 - Train Loss: 0.073810, Train Acc: 0.889744 | Val Loss: 0.108551, Val Acc: 0.804124\n",
      "Epoch 23950 - Train Loss: 0.073809, Train Acc: 0.889744 | Val Loss: 0.108551, Val Acc: 0.804124\n",
      "Epoch 23951 - Train Loss: 0.073807, Train Acc: 0.889744 | Val Loss: 0.108550, Val Acc: 0.804124\n",
      "Epoch 23952 - Train Loss: 0.073806, Train Acc: 0.889744 | Val Loss: 0.108550, Val Acc: 0.804124\n",
      "Epoch 23953 - Train Loss: 0.073804, Train Acc: 0.889744 | Val Loss: 0.108549, Val Acc: 0.804124\n",
      "Epoch 23954 - Train Loss: 0.073802, Train Acc: 0.889744 | Val Loss: 0.108549, Val Acc: 0.804124\n",
      "Epoch 23955 - Train Loss: 0.073801, Train Acc: 0.889744 | Val Loss: 0.108549, Val Acc: 0.804124\n",
      "Epoch 23956 - Train Loss: 0.073799, Train Acc: 0.889744 | Val Loss: 0.108548, Val Acc: 0.804124\n",
      "Epoch 23957 - Train Loss: 0.073797, Train Acc: 0.889744 | Val Loss: 0.108548, Val Acc: 0.804124\n",
      "Epoch 23958 - Train Loss: 0.073796, Train Acc: 0.889744 | Val Loss: 0.108548, Val Acc: 0.804124\n",
      "Epoch 23959 - Train Loss: 0.073794, Train Acc: 0.889744 | Val Loss: 0.108547, Val Acc: 0.804124\n",
      "Epoch 23960 - Train Loss: 0.073793, Train Acc: 0.889744 | Val Loss: 0.108547, Val Acc: 0.804124\n",
      "Epoch 23961 - Train Loss: 0.073791, Train Acc: 0.889744 | Val Loss: 0.108546, Val Acc: 0.804124\n",
      "Epoch 23962 - Train Loss: 0.073789, Train Acc: 0.889744 | Val Loss: 0.108546, Val Acc: 0.804124\n",
      "Epoch 23963 - Train Loss: 0.073788, Train Acc: 0.889744 | Val Loss: 0.108546, Val Acc: 0.804124\n",
      "Epoch 23964 - Train Loss: 0.073786, Train Acc: 0.889744 | Val Loss: 0.108545, Val Acc: 0.804124\n",
      "Epoch 23965 - Train Loss: 0.073785, Train Acc: 0.889744 | Val Loss: 0.108545, Val Acc: 0.804124\n",
      "Epoch 23966 - Train Loss: 0.073783, Train Acc: 0.889744 | Val Loss: 0.108545, Val Acc: 0.804124\n",
      "Epoch 23967 - Train Loss: 0.073781, Train Acc: 0.889744 | Val Loss: 0.108544, Val Acc: 0.804124\n",
      "Epoch 23968 - Train Loss: 0.073780, Train Acc: 0.889744 | Val Loss: 0.108544, Val Acc: 0.804124\n",
      "Epoch 23969 - Train Loss: 0.073778, Train Acc: 0.889744 | Val Loss: 0.108544, Val Acc: 0.804124\n",
      "Epoch 23970 - Train Loss: 0.073776, Train Acc: 0.889744 | Val Loss: 0.108543, Val Acc: 0.804124\n",
      "Epoch 23971 - Train Loss: 0.073775, Train Acc: 0.889744 | Val Loss: 0.108543, Val Acc: 0.804124\n",
      "Epoch 23972 - Train Loss: 0.073773, Train Acc: 0.889744 | Val Loss: 0.108542, Val Acc: 0.804124\n",
      "Epoch 23973 - Train Loss: 0.073772, Train Acc: 0.889744 | Val Loss: 0.108542, Val Acc: 0.804124\n",
      "Epoch 23974 - Train Loss: 0.073770, Train Acc: 0.889744 | Val Loss: 0.108542, Val Acc: 0.804124\n",
      "Epoch 23975 - Train Loss: 0.073768, Train Acc: 0.889744 | Val Loss: 0.108541, Val Acc: 0.804124\n",
      "Epoch 23976 - Train Loss: 0.073767, Train Acc: 0.889744 | Val Loss: 0.108541, Val Acc: 0.804124\n",
      "Epoch 23977 - Train Loss: 0.073765, Train Acc: 0.889744 | Val Loss: 0.108541, Val Acc: 0.804124\n",
      "Epoch 23978 - Train Loss: 0.073764, Train Acc: 0.889744 | Val Loss: 0.108540, Val Acc: 0.804124\n",
      "Epoch 23979 - Train Loss: 0.073762, Train Acc: 0.889744 | Val Loss: 0.108540, Val Acc: 0.804124\n",
      "Epoch 23980 - Train Loss: 0.073760, Train Acc: 0.889744 | Val Loss: 0.108539, Val Acc: 0.804124\n",
      "Epoch 23981 - Train Loss: 0.073759, Train Acc: 0.889744 | Val Loss: 0.108539, Val Acc: 0.804124\n",
      "Epoch 23982 - Train Loss: 0.073757, Train Acc: 0.889744 | Val Loss: 0.108539, Val Acc: 0.804124\n",
      "Epoch 23983 - Train Loss: 0.073756, Train Acc: 0.889744 | Val Loss: 0.108538, Val Acc: 0.804124\n",
      "Epoch 23984 - Train Loss: 0.073754, Train Acc: 0.889744 | Val Loss: 0.108538, Val Acc: 0.804124\n",
      "Epoch 23985 - Train Loss: 0.073752, Train Acc: 0.889744 | Val Loss: 0.108538, Val Acc: 0.804124\n",
      "Epoch 23986 - Train Loss: 0.073751, Train Acc: 0.889744 | Val Loss: 0.108537, Val Acc: 0.804124\n",
      "Epoch 23987 - Train Loss: 0.073749, Train Acc: 0.889744 | Val Loss: 0.108537, Val Acc: 0.804124\n",
      "Epoch 23988 - Train Loss: 0.073747, Train Acc: 0.889744 | Val Loss: 0.108537, Val Acc: 0.804124\n",
      "Epoch 23989 - Train Loss: 0.073746, Train Acc: 0.889744 | Val Loss: 0.108536, Val Acc: 0.804124\n",
      "Epoch 23990 - Train Loss: 0.073744, Train Acc: 0.889744 | Val Loss: 0.108536, Val Acc: 0.804124\n",
      "Epoch 23991 - Train Loss: 0.073743, Train Acc: 0.889744 | Val Loss: 0.108535, Val Acc: 0.804124\n",
      "Epoch 23992 - Train Loss: 0.073741, Train Acc: 0.889744 | Val Loss: 0.108535, Val Acc: 0.804124\n",
      "Epoch 23993 - Train Loss: 0.073739, Train Acc: 0.889744 | Val Loss: 0.108535, Val Acc: 0.804124\n",
      "Epoch 23994 - Train Loss: 0.073738, Train Acc: 0.889744 | Val Loss: 0.108534, Val Acc: 0.804124\n",
      "Epoch 23995 - Train Loss: 0.073736, Train Acc: 0.889744 | Val Loss: 0.108534, Val Acc: 0.804124\n",
      "Epoch 23996 - Train Loss: 0.073735, Train Acc: 0.889744 | Val Loss: 0.108534, Val Acc: 0.804124\n",
      "Epoch 23997 - Train Loss: 0.073733, Train Acc: 0.889744 | Val Loss: 0.108533, Val Acc: 0.804124\n",
      "Epoch 23998 - Train Loss: 0.073731, Train Acc: 0.889744 | Val Loss: 0.108533, Val Acc: 0.804124\n",
      "Epoch 23999 - Train Loss: 0.073730, Train Acc: 0.889744 | Val Loss: 0.108533, Val Acc: 0.804124\n",
      "Epoch 24000 - Train Loss: 0.073728, Train Acc: 0.889744 | Val Loss: 0.108532, Val Acc: 0.804124\n",
      "Epoch 24001 - Train Loss: 0.073727, Train Acc: 0.889744 | Val Loss: 0.108532, Val Acc: 0.804124\n",
      "Epoch 24002 - Train Loss: 0.073725, Train Acc: 0.889744 | Val Loss: 0.108532, Val Acc: 0.804124\n",
      "Epoch 24003 - Train Loss: 0.073723, Train Acc: 0.889744 | Val Loss: 0.108531, Val Acc: 0.804124\n",
      "Epoch 24004 - Train Loss: 0.073722, Train Acc: 0.889744 | Val Loss: 0.108531, Val Acc: 0.804124\n",
      "Epoch 24005 - Train Loss: 0.073720, Train Acc: 0.889744 | Val Loss: 0.108530, Val Acc: 0.804124\n",
      "Epoch 24006 - Train Loss: 0.073719, Train Acc: 0.889744 | Val Loss: 0.108530, Val Acc: 0.804124\n",
      "Epoch 24007 - Train Loss: 0.073717, Train Acc: 0.889744 | Val Loss: 0.108530, Val Acc: 0.804124\n",
      "Epoch 24008 - Train Loss: 0.073715, Train Acc: 0.889744 | Val Loss: 0.108529, Val Acc: 0.804124\n",
      "Epoch 24009 - Train Loss: 0.073714, Train Acc: 0.889744 | Val Loss: 0.108529, Val Acc: 0.804124\n",
      "Epoch 24010 - Train Loss: 0.073712, Train Acc: 0.889744 | Val Loss: 0.108529, Val Acc: 0.804124\n",
      "Epoch 24011 - Train Loss: 0.073710, Train Acc: 0.889744 | Val Loss: 0.108528, Val Acc: 0.804124\n",
      "Epoch 24012 - Train Loss: 0.073709, Train Acc: 0.889744 | Val Loss: 0.108528, Val Acc: 0.804124\n",
      "Epoch 24013 - Train Loss: 0.073707, Train Acc: 0.889744 | Val Loss: 0.108528, Val Acc: 0.804124\n",
      "Epoch 24014 - Train Loss: 0.073706, Train Acc: 0.889744 | Val Loss: 0.108527, Val Acc: 0.804124\n",
      "Epoch 24015 - Train Loss: 0.073704, Train Acc: 0.889744 | Val Loss: 0.108527, Val Acc: 0.804124\n",
      "Epoch 24016 - Train Loss: 0.073702, Train Acc: 0.889744 | Val Loss: 0.108527, Val Acc: 0.804124\n",
      "Epoch 24017 - Train Loss: 0.073701, Train Acc: 0.889744 | Val Loss: 0.108526, Val Acc: 0.804124\n",
      "Epoch 24018 - Train Loss: 0.073699, Train Acc: 0.889744 | Val Loss: 0.108526, Val Acc: 0.804124\n",
      "Epoch 24019 - Train Loss: 0.073698, Train Acc: 0.889744 | Val Loss: 0.108526, Val Acc: 0.804124\n",
      "Epoch 24020 - Train Loss: 0.073696, Train Acc: 0.889744 | Val Loss: 0.108525, Val Acc: 0.804124\n",
      "Epoch 24021 - Train Loss: 0.073694, Train Acc: 0.889744 | Val Loss: 0.108525, Val Acc: 0.804124\n",
      "Epoch 24022 - Train Loss: 0.073693, Train Acc: 0.889744 | Val Loss: 0.108525, Val Acc: 0.804124\n",
      "Epoch 24023 - Train Loss: 0.073691, Train Acc: 0.889744 | Val Loss: 0.108524, Val Acc: 0.804124\n",
      "Epoch 24024 - Train Loss: 0.073690, Train Acc: 0.889744 | Val Loss: 0.108524, Val Acc: 0.804124\n",
      "Epoch 24025 - Train Loss: 0.073688, Train Acc: 0.889744 | Val Loss: 0.108524, Val Acc: 0.804124\n",
      "Epoch 24026 - Train Loss: 0.073686, Train Acc: 0.889744 | Val Loss: 0.108523, Val Acc: 0.804124\n",
      "Epoch 24027 - Train Loss: 0.073685, Train Acc: 0.889744 | Val Loss: 0.108523, Val Acc: 0.804124\n",
      "Epoch 24028 - Train Loss: 0.073683, Train Acc: 0.889744 | Val Loss: 0.108522, Val Acc: 0.804124\n",
      "Epoch 24029 - Train Loss: 0.073682, Train Acc: 0.889744 | Val Loss: 0.108522, Val Acc: 0.804124\n",
      "Epoch 24030 - Train Loss: 0.073680, Train Acc: 0.889744 | Val Loss: 0.108522, Val Acc: 0.804124\n",
      "Epoch 24031 - Train Loss: 0.073678, Train Acc: 0.889744 | Val Loss: 0.108521, Val Acc: 0.804124\n",
      "Epoch 24032 - Train Loss: 0.073677, Train Acc: 0.889744 | Val Loss: 0.108521, Val Acc: 0.804124\n",
      "Epoch 24033 - Train Loss: 0.073675, Train Acc: 0.889744 | Val Loss: 0.108521, Val Acc: 0.804124\n",
      "Epoch 24034 - Train Loss: 0.073674, Train Acc: 0.889744 | Val Loss: 0.108520, Val Acc: 0.804124\n",
      "Epoch 24035 - Train Loss: 0.073672, Train Acc: 0.889744 | Val Loss: 0.108520, Val Acc: 0.804124\n",
      "Epoch 24036 - Train Loss: 0.073670, Train Acc: 0.889744 | Val Loss: 0.108520, Val Acc: 0.804124\n",
      "Epoch 24037 - Train Loss: 0.073669, Train Acc: 0.889744 | Val Loss: 0.108519, Val Acc: 0.804124\n",
      "Epoch 24038 - Train Loss: 0.073667, Train Acc: 0.889744 | Val Loss: 0.108519, Val Acc: 0.804124\n",
      "Epoch 24039 - Train Loss: 0.073666, Train Acc: 0.889744 | Val Loss: 0.108519, Val Acc: 0.804124\n",
      "Epoch 24040 - Train Loss: 0.073664, Train Acc: 0.889744 | Val Loss: 0.108518, Val Acc: 0.804124\n",
      "Epoch 24041 - Train Loss: 0.073662, Train Acc: 0.889744 | Val Loss: 0.108518, Val Acc: 0.804124\n",
      "Epoch 24042 - Train Loss: 0.073661, Train Acc: 0.889744 | Val Loss: 0.108518, Val Acc: 0.804124\n",
      "Epoch 24043 - Train Loss: 0.073659, Train Acc: 0.889744 | Val Loss: 0.108517, Val Acc: 0.804124\n",
      "Epoch 24044 - Train Loss: 0.073658, Train Acc: 0.889744 | Val Loss: 0.108517, Val Acc: 0.804124\n",
      "Epoch 24045 - Train Loss: 0.073656, Train Acc: 0.889744 | Val Loss: 0.108517, Val Acc: 0.804124\n",
      "Epoch 24046 - Train Loss: 0.073654, Train Acc: 0.889744 | Val Loss: 0.108516, Val Acc: 0.804124\n",
      "Epoch 24047 - Train Loss: 0.073653, Train Acc: 0.889744 | Val Loss: 0.108516, Val Acc: 0.804124\n",
      "Epoch 24048 - Train Loss: 0.073651, Train Acc: 0.889744 | Val Loss: 0.108516, Val Acc: 0.804124\n",
      "Epoch 24049 - Train Loss: 0.073650, Train Acc: 0.889744 | Val Loss: 0.108515, Val Acc: 0.804124\n",
      "Epoch 24050 - Train Loss: 0.073648, Train Acc: 0.889744 | Val Loss: 0.108515, Val Acc: 0.804124\n",
      "Epoch 24051 - Train Loss: 0.073646, Train Acc: 0.889744 | Val Loss: 0.108515, Val Acc: 0.804124\n",
      "Epoch 24052 - Train Loss: 0.073645, Train Acc: 0.889744 | Val Loss: 0.108514, Val Acc: 0.804124\n",
      "Epoch 24053 - Train Loss: 0.073643, Train Acc: 0.889744 | Val Loss: 0.108514, Val Acc: 0.804124\n",
      "Epoch 24054 - Train Loss: 0.073642, Train Acc: 0.889744 | Val Loss: 0.108514, Val Acc: 0.804124\n",
      "Epoch 24055 - Train Loss: 0.073640, Train Acc: 0.889744 | Val Loss: 0.108513, Val Acc: 0.804124\n",
      "Epoch 24056 - Train Loss: 0.073638, Train Acc: 0.889744 | Val Loss: 0.108513, Val Acc: 0.804124\n",
      "Epoch 24057 - Train Loss: 0.073637, Train Acc: 0.889744 | Val Loss: 0.108513, Val Acc: 0.804124\n",
      "Epoch 24058 - Train Loss: 0.073635, Train Acc: 0.889744 | Val Loss: 0.108512, Val Acc: 0.804124\n",
      "Epoch 24059 - Train Loss: 0.073634, Train Acc: 0.889744 | Val Loss: 0.108512, Val Acc: 0.804124\n",
      "Epoch 24060 - Train Loss: 0.073632, Train Acc: 0.889744 | Val Loss: 0.108512, Val Acc: 0.804124\n",
      "Epoch 24061 - Train Loss: 0.073630, Train Acc: 0.889744 | Val Loss: 0.108511, Val Acc: 0.804124\n",
      "Epoch 24062 - Train Loss: 0.073629, Train Acc: 0.889744 | Val Loss: 0.108511, Val Acc: 0.804124\n",
      "Epoch 24063 - Train Loss: 0.073627, Train Acc: 0.889744 | Val Loss: 0.108511, Val Acc: 0.804124\n",
      "Epoch 24064 - Train Loss: 0.073626, Train Acc: 0.889744 | Val Loss: 0.108510, Val Acc: 0.804124\n",
      "Epoch 24065 - Train Loss: 0.073624, Train Acc: 0.889744 | Val Loss: 0.108510, Val Acc: 0.804124\n",
      "Epoch 24066 - Train Loss: 0.073622, Train Acc: 0.889744 | Val Loss: 0.108510, Val Acc: 0.804124\n",
      "Epoch 24067 - Train Loss: 0.073621, Train Acc: 0.889744 | Val Loss: 0.108509, Val Acc: 0.804124\n",
      "Epoch 24068 - Train Loss: 0.073619, Train Acc: 0.889744 | Val Loss: 0.108509, Val Acc: 0.804124\n",
      "Epoch 24069 - Train Loss: 0.073618, Train Acc: 0.889744 | Val Loss: 0.108509, Val Acc: 0.804124\n",
      "Epoch 24070 - Train Loss: 0.073616, Train Acc: 0.889744 | Val Loss: 0.108508, Val Acc: 0.804124\n",
      "Epoch 24071 - Train Loss: 0.073614, Train Acc: 0.889744 | Val Loss: 0.108508, Val Acc: 0.804124\n",
      "Epoch 24072 - Train Loss: 0.073613, Train Acc: 0.889744 | Val Loss: 0.108508, Val Acc: 0.804124\n",
      "Epoch 24073 - Train Loss: 0.073611, Train Acc: 0.889744 | Val Loss: 0.108507, Val Acc: 0.804124\n",
      "Epoch 24074 - Train Loss: 0.073610, Train Acc: 0.889744 | Val Loss: 0.108507, Val Acc: 0.804124\n",
      "Epoch 24075 - Train Loss: 0.073608, Train Acc: 0.889744 | Val Loss: 0.108507, Val Acc: 0.804124\n",
      "Epoch 24076 - Train Loss: 0.073606, Train Acc: 0.889744 | Val Loss: 0.108506, Val Acc: 0.804124\n",
      "Epoch 24077 - Train Loss: 0.073605, Train Acc: 0.889744 | Val Loss: 0.108506, Val Acc: 0.804124\n",
      "Epoch 24078 - Train Loss: 0.073603, Train Acc: 0.889744 | Val Loss: 0.108506, Val Acc: 0.804124\n",
      "Epoch 24079 - Train Loss: 0.073602, Train Acc: 0.889744 | Val Loss: 0.108505, Val Acc: 0.804124\n",
      "Epoch 24080 - Train Loss: 0.073600, Train Acc: 0.889744 | Val Loss: 0.108505, Val Acc: 0.804124\n",
      "Epoch 24081 - Train Loss: 0.073598, Train Acc: 0.889744 | Val Loss: 0.108505, Val Acc: 0.804124\n",
      "Epoch 24082 - Train Loss: 0.073597, Train Acc: 0.889744 | Val Loss: 0.108504, Val Acc: 0.804124\n",
      "Epoch 24083 - Train Loss: 0.073595, Train Acc: 0.889744 | Val Loss: 0.108504, Val Acc: 0.804124\n",
      "Epoch 24084 - Train Loss: 0.073594, Train Acc: 0.889744 | Val Loss: 0.108504, Val Acc: 0.804124\n",
      "Epoch 24085 - Train Loss: 0.073592, Train Acc: 0.889744 | Val Loss: 0.108503, Val Acc: 0.804124\n",
      "Epoch 24086 - Train Loss: 0.073590, Train Acc: 0.889744 | Val Loss: 0.108503, Val Acc: 0.804124\n",
      "Epoch 24087 - Train Loss: 0.073589, Train Acc: 0.889744 | Val Loss: 0.108503, Val Acc: 0.804124\n",
      "Epoch 24088 - Train Loss: 0.073587, Train Acc: 0.889744 | Val Loss: 0.108502, Val Acc: 0.804124\n",
      "Epoch 24089 - Train Loss: 0.073586, Train Acc: 0.889744 | Val Loss: 0.108502, Val Acc: 0.804124\n",
      "Epoch 24090 - Train Loss: 0.073584, Train Acc: 0.889744 | Val Loss: 0.108502, Val Acc: 0.804124\n",
      "Epoch 24091 - Train Loss: 0.073582, Train Acc: 0.889744 | Val Loss: 0.108501, Val Acc: 0.804124\n",
      "Epoch 24092 - Train Loss: 0.073581, Train Acc: 0.889744 | Val Loss: 0.108501, Val Acc: 0.804124\n",
      "Epoch 24093 - Train Loss: 0.073579, Train Acc: 0.889744 | Val Loss: 0.108501, Val Acc: 0.804124\n",
      "Epoch 24094 - Train Loss: 0.073578, Train Acc: 0.889744 | Val Loss: 0.108500, Val Acc: 0.804124\n",
      "Epoch 24095 - Train Loss: 0.073576, Train Acc: 0.889744 | Val Loss: 0.108500, Val Acc: 0.804124\n",
      "Epoch 24096 - Train Loss: 0.073574, Train Acc: 0.889744 | Val Loss: 0.108500, Val Acc: 0.804124\n",
      "Epoch 24097 - Train Loss: 0.073573, Train Acc: 0.889744 | Val Loss: 0.108499, Val Acc: 0.804124\n",
      "Epoch 24098 - Train Loss: 0.073571, Train Acc: 0.889744 | Val Loss: 0.108499, Val Acc: 0.804124\n",
      "Epoch 24099 - Train Loss: 0.073570, Train Acc: 0.889744 | Val Loss: 0.108499, Val Acc: 0.804124\n",
      "Epoch 24100 - Train Loss: 0.073568, Train Acc: 0.889744 | Val Loss: 0.108498, Val Acc: 0.804124\n",
      "Epoch 24101 - Train Loss: 0.073567, Train Acc: 0.889744 | Val Loss: 0.108498, Val Acc: 0.804124\n",
      "Epoch 24102 - Train Loss: 0.073565, Train Acc: 0.889744 | Val Loss: 0.108498, Val Acc: 0.804124\n",
      "Epoch 24103 - Train Loss: 0.073563, Train Acc: 0.889744 | Val Loss: 0.108497, Val Acc: 0.804124\n",
      "Epoch 24104 - Train Loss: 0.073562, Train Acc: 0.889744 | Val Loss: 0.108497, Val Acc: 0.804124\n",
      "Epoch 24105 - Train Loss: 0.073560, Train Acc: 0.889744 | Val Loss: 0.108497, Val Acc: 0.804124\n",
      "Epoch 24106 - Train Loss: 0.073559, Train Acc: 0.889744 | Val Loss: 0.108496, Val Acc: 0.804124\n",
      "Epoch 24107 - Train Loss: 0.073557, Train Acc: 0.889744 | Val Loss: 0.108496, Val Acc: 0.804124\n",
      "Epoch 24108 - Train Loss: 0.073555, Train Acc: 0.889744 | Val Loss: 0.108496, Val Acc: 0.804124\n",
      "Epoch 24109 - Train Loss: 0.073554, Train Acc: 0.889744 | Val Loss: 0.108495, Val Acc: 0.804124\n",
      "Epoch 24110 - Train Loss: 0.073552, Train Acc: 0.889744 | Val Loss: 0.108495, Val Acc: 0.804124\n",
      "Epoch 24111 - Train Loss: 0.073551, Train Acc: 0.889744 | Val Loss: 0.108495, Val Acc: 0.804124\n",
      "Epoch 24112 - Train Loss: 0.073549, Train Acc: 0.889744 | Val Loss: 0.108494, Val Acc: 0.804124\n",
      "Epoch 24113 - Train Loss: 0.073547, Train Acc: 0.889744 | Val Loss: 0.108494, Val Acc: 0.804124\n",
      "Epoch 24114 - Train Loss: 0.073546, Train Acc: 0.889744 | Val Loss: 0.108494, Val Acc: 0.804124\n",
      "Epoch 24115 - Train Loss: 0.073544, Train Acc: 0.889744 | Val Loss: 0.108493, Val Acc: 0.804124\n",
      "Epoch 24116 - Train Loss: 0.073543, Train Acc: 0.889744 | Val Loss: 0.108493, Val Acc: 0.804124\n",
      "Epoch 24117 - Train Loss: 0.073541, Train Acc: 0.889744 | Val Loss: 0.108493, Val Acc: 0.804124\n",
      "Epoch 24118 - Train Loss: 0.073539, Train Acc: 0.889744 | Val Loss: 0.108492, Val Acc: 0.804124\n",
      "Epoch 24119 - Train Loss: 0.073538, Train Acc: 0.889744 | Val Loss: 0.108492, Val Acc: 0.804124\n",
      "Epoch 24120 - Train Loss: 0.073536, Train Acc: 0.889744 | Val Loss: 0.108492, Val Acc: 0.804124\n",
      "Epoch 24121 - Train Loss: 0.073535, Train Acc: 0.889744 | Val Loss: 0.108491, Val Acc: 0.804124\n",
      "Epoch 24122 - Train Loss: 0.073533, Train Acc: 0.889744 | Val Loss: 0.108491, Val Acc: 0.804124\n",
      "Epoch 24123 - Train Loss: 0.073531, Train Acc: 0.889744 | Val Loss: 0.108491, Val Acc: 0.804124\n",
      "Epoch 24124 - Train Loss: 0.073530, Train Acc: 0.889744 | Val Loss: 0.108490, Val Acc: 0.804124\n",
      "Epoch 24125 - Train Loss: 0.073528, Train Acc: 0.889744 | Val Loss: 0.108490, Val Acc: 0.804124\n",
      "Epoch 24126 - Train Loss: 0.073527, Train Acc: 0.889744 | Val Loss: 0.108490, Val Acc: 0.804124\n",
      "Epoch 24127 - Train Loss: 0.073525, Train Acc: 0.889744 | Val Loss: 0.108489, Val Acc: 0.804124\n",
      "Epoch 24128 - Train Loss: 0.073524, Train Acc: 0.889744 | Val Loss: 0.108489, Val Acc: 0.804124\n",
      "Epoch 24129 - Train Loss: 0.073522, Train Acc: 0.889744 | Val Loss: 0.108489, Val Acc: 0.804124\n",
      "Epoch 24130 - Train Loss: 0.073520, Train Acc: 0.889744 | Val Loss: 0.108488, Val Acc: 0.804124\n",
      "Epoch 24131 - Train Loss: 0.073519, Train Acc: 0.889744 | Val Loss: 0.108488, Val Acc: 0.804124\n",
      "Epoch 24132 - Train Loss: 0.073517, Train Acc: 0.889744 | Val Loss: 0.108488, Val Acc: 0.804124\n",
      "Epoch 24133 - Train Loss: 0.073516, Train Acc: 0.889744 | Val Loss: 0.108487, Val Acc: 0.804124\n",
      "Epoch 24134 - Train Loss: 0.073514, Train Acc: 0.889744 | Val Loss: 0.108487, Val Acc: 0.804124\n",
      "Epoch 24135 - Train Loss: 0.073512, Train Acc: 0.889744 | Val Loss: 0.108487, Val Acc: 0.804124\n",
      "Epoch 24136 - Train Loss: 0.073511, Train Acc: 0.889744 | Val Loss: 0.108486, Val Acc: 0.804124\n",
      "Epoch 24137 - Train Loss: 0.073509, Train Acc: 0.889744 | Val Loss: 0.108486, Val Acc: 0.804124\n",
      "Epoch 24138 - Train Loss: 0.073508, Train Acc: 0.889744 | Val Loss: 0.108486, Val Acc: 0.804124\n",
      "Epoch 24139 - Train Loss: 0.073506, Train Acc: 0.889744 | Val Loss: 0.108485, Val Acc: 0.804124\n",
      "Epoch 24140 - Train Loss: 0.073504, Train Acc: 0.889744 | Val Loss: 0.108485, Val Acc: 0.804124\n",
      "Epoch 24141 - Train Loss: 0.073503, Train Acc: 0.889744 | Val Loss: 0.108485, Val Acc: 0.804124\n",
      "Epoch 24142 - Train Loss: 0.073501, Train Acc: 0.889744 | Val Loss: 0.108484, Val Acc: 0.804124\n",
      "Epoch 24143 - Train Loss: 0.073500, Train Acc: 0.889744 | Val Loss: 0.108484, Val Acc: 0.804124\n",
      "Epoch 24144 - Train Loss: 0.073498, Train Acc: 0.889744 | Val Loss: 0.108484, Val Acc: 0.804124\n",
      "Epoch 24145 - Train Loss: 0.073496, Train Acc: 0.889744 | Val Loss: 0.108483, Val Acc: 0.804124\n",
      "Epoch 24146 - Train Loss: 0.073495, Train Acc: 0.889744 | Val Loss: 0.108483, Val Acc: 0.804124\n",
      "Epoch 24147 - Train Loss: 0.073493, Train Acc: 0.889744 | Val Loss: 0.108483, Val Acc: 0.804124\n",
      "Epoch 24148 - Train Loss: 0.073492, Train Acc: 0.889744 | Val Loss: 0.108483, Val Acc: 0.804124\n",
      "Epoch 24149 - Train Loss: 0.073490, Train Acc: 0.889744 | Val Loss: 0.108482, Val Acc: 0.804124\n",
      "Epoch 24150 - Train Loss: 0.073489, Train Acc: 0.889744 | Val Loss: 0.108482, Val Acc: 0.804124\n",
      "Epoch 24151 - Train Loss: 0.073487, Train Acc: 0.889744 | Val Loss: 0.108482, Val Acc: 0.804124\n",
      "Epoch 24152 - Train Loss: 0.073485, Train Acc: 0.889744 | Val Loss: 0.108481, Val Acc: 0.804124\n",
      "Epoch 24153 - Train Loss: 0.073484, Train Acc: 0.889744 | Val Loss: 0.108481, Val Acc: 0.804124\n",
      "Epoch 24154 - Train Loss: 0.073482, Train Acc: 0.889744 | Val Loss: 0.108481, Val Acc: 0.804124\n",
      "Epoch 24155 - Train Loss: 0.073481, Train Acc: 0.889744 | Val Loss: 0.108480, Val Acc: 0.804124\n",
      "Epoch 24156 - Train Loss: 0.073479, Train Acc: 0.889744 | Val Loss: 0.108480, Val Acc: 0.804124\n",
      "Epoch 24157 - Train Loss: 0.073477, Train Acc: 0.889744 | Val Loss: 0.108480, Val Acc: 0.804124\n",
      "Epoch 24158 - Train Loss: 0.073476, Train Acc: 0.889744 | Val Loss: 0.108479, Val Acc: 0.804124\n",
      "Epoch 24159 - Train Loss: 0.073474, Train Acc: 0.889744 | Val Loss: 0.108479, Val Acc: 0.804124\n",
      "Epoch 24160 - Train Loss: 0.073473, Train Acc: 0.889744 | Val Loss: 0.108479, Val Acc: 0.804124\n",
      "Epoch 24161 - Train Loss: 0.073471, Train Acc: 0.889744 | Val Loss: 0.108478, Val Acc: 0.804124\n",
      "Epoch 24162 - Train Loss: 0.073470, Train Acc: 0.889744 | Val Loss: 0.108478, Val Acc: 0.804124\n",
      "Epoch 24163 - Train Loss: 0.073468, Train Acc: 0.889744 | Val Loss: 0.108478, Val Acc: 0.804124\n",
      "Epoch 24164 - Train Loss: 0.073466, Train Acc: 0.889744 | Val Loss: 0.108477, Val Acc: 0.804124\n",
      "Epoch 24165 - Train Loss: 0.073465, Train Acc: 0.891026 | Val Loss: 0.108477, Val Acc: 0.804124\n",
      "Epoch 24166 - Train Loss: 0.073463, Train Acc: 0.891026 | Val Loss: 0.108477, Val Acc: 0.804124\n",
      "Epoch 24167 - Train Loss: 0.073462, Train Acc: 0.891026 | Val Loss: 0.108476, Val Acc: 0.804124\n",
      "Epoch 24168 - Train Loss: 0.073460, Train Acc: 0.891026 | Val Loss: 0.108476, Val Acc: 0.804124\n",
      "Epoch 24169 - Train Loss: 0.073458, Train Acc: 0.891026 | Val Loss: 0.108476, Val Acc: 0.804124\n",
      "Epoch 24170 - Train Loss: 0.073457, Train Acc: 0.891026 | Val Loss: 0.108475, Val Acc: 0.804124\n",
      "Epoch 24171 - Train Loss: 0.073455, Train Acc: 0.891026 | Val Loss: 0.108475, Val Acc: 0.804124\n",
      "Epoch 24172 - Train Loss: 0.073454, Train Acc: 0.891026 | Val Loss: 0.108475, Val Acc: 0.804124\n",
      "Epoch 24173 - Train Loss: 0.073452, Train Acc: 0.891026 | Val Loss: 0.108474, Val Acc: 0.804124\n",
      "Epoch 24174 - Train Loss: 0.073450, Train Acc: 0.891026 | Val Loss: 0.108474, Val Acc: 0.804124\n",
      "Epoch 24175 - Train Loss: 0.073449, Train Acc: 0.891026 | Val Loss: 0.108474, Val Acc: 0.804124\n",
      "Epoch 24176 - Train Loss: 0.073447, Train Acc: 0.891026 | Val Loss: 0.108473, Val Acc: 0.804124\n",
      "Epoch 24177 - Train Loss: 0.073446, Train Acc: 0.891026 | Val Loss: 0.108473, Val Acc: 0.804124\n",
      "Epoch 24178 - Train Loss: 0.073444, Train Acc: 0.891026 | Val Loss: 0.108473, Val Acc: 0.804124\n",
      "Epoch 24179 - Train Loss: 0.073443, Train Acc: 0.891026 | Val Loss: 0.108472, Val Acc: 0.804124\n",
      "Epoch 24180 - Train Loss: 0.073441, Train Acc: 0.891026 | Val Loss: 0.108472, Val Acc: 0.804124\n",
      "Epoch 24181 - Train Loss: 0.073439, Train Acc: 0.891026 | Val Loss: 0.108472, Val Acc: 0.804124\n",
      "Epoch 24182 - Train Loss: 0.073438, Train Acc: 0.891026 | Val Loss: 0.108471, Val Acc: 0.804124\n",
      "Epoch 24183 - Train Loss: 0.073436, Train Acc: 0.891026 | Val Loss: 0.108471, Val Acc: 0.804124\n",
      "Epoch 24184 - Train Loss: 0.073435, Train Acc: 0.891026 | Val Loss: 0.108471, Val Acc: 0.804124\n",
      "Epoch 24185 - Train Loss: 0.073433, Train Acc: 0.891026 | Val Loss: 0.108471, Val Acc: 0.804124\n",
      "Epoch 24186 - Train Loss: 0.073431, Train Acc: 0.891026 | Val Loss: 0.108470, Val Acc: 0.804124\n",
      "Epoch 24187 - Train Loss: 0.073430, Train Acc: 0.891026 | Val Loss: 0.108470, Val Acc: 0.804124\n",
      "Epoch 24188 - Train Loss: 0.073428, Train Acc: 0.891026 | Val Loss: 0.108470, Val Acc: 0.804124\n",
      "Epoch 24189 - Train Loss: 0.073427, Train Acc: 0.891026 | Val Loss: 0.108469, Val Acc: 0.804124\n",
      "Epoch 24190 - Train Loss: 0.073425, Train Acc: 0.891026 | Val Loss: 0.108469, Val Acc: 0.804124\n",
      "Epoch 24191 - Train Loss: 0.073424, Train Acc: 0.891026 | Val Loss: 0.108469, Val Acc: 0.804124\n",
      "Epoch 24192 - Train Loss: 0.073422, Train Acc: 0.891026 | Val Loss: 0.108468, Val Acc: 0.804124\n",
      "Epoch 24193 - Train Loss: 0.073420, Train Acc: 0.891026 | Val Loss: 0.108468, Val Acc: 0.804124\n",
      "Epoch 24194 - Train Loss: 0.073419, Train Acc: 0.891026 | Val Loss: 0.108468, Val Acc: 0.804124\n",
      "Epoch 24195 - Train Loss: 0.073417, Train Acc: 0.891026 | Val Loss: 0.108467, Val Acc: 0.804124\n",
      "Epoch 24196 - Train Loss: 0.073416, Train Acc: 0.891026 | Val Loss: 0.108467, Val Acc: 0.804124\n",
      "Epoch 24197 - Train Loss: 0.073414, Train Acc: 0.891026 | Val Loss: 0.108467, Val Acc: 0.804124\n",
      "Epoch 24198 - Train Loss: 0.073412, Train Acc: 0.891026 | Val Loss: 0.108466, Val Acc: 0.804124\n",
      "Epoch 24199 - Train Loss: 0.073411, Train Acc: 0.891026 | Val Loss: 0.108466, Val Acc: 0.804124\n",
      "Epoch 24200 - Train Loss: 0.073409, Train Acc: 0.891026 | Val Loss: 0.108466, Val Acc: 0.804124\n",
      "Epoch 24201 - Train Loss: 0.073408, Train Acc: 0.891026 | Val Loss: 0.108465, Val Acc: 0.804124\n",
      "Epoch 24202 - Train Loss: 0.073406, Train Acc: 0.891026 | Val Loss: 0.108465, Val Acc: 0.804124\n",
      "Epoch 24203 - Train Loss: 0.073405, Train Acc: 0.891026 | Val Loss: 0.108465, Val Acc: 0.804124\n",
      "Epoch 24204 - Train Loss: 0.073403, Train Acc: 0.891026 | Val Loss: 0.108464, Val Acc: 0.804124\n",
      "Epoch 24205 - Train Loss: 0.073401, Train Acc: 0.891026 | Val Loss: 0.108464, Val Acc: 0.804124\n",
      "Epoch 24206 - Train Loss: 0.073400, Train Acc: 0.891026 | Val Loss: 0.108464, Val Acc: 0.804124\n",
      "Epoch 24207 - Train Loss: 0.073398, Train Acc: 0.891026 | Val Loss: 0.108463, Val Acc: 0.804124\n",
      "Epoch 24208 - Train Loss: 0.073397, Train Acc: 0.891026 | Val Loss: 0.108463, Val Acc: 0.804124\n",
      "Epoch 24209 - Train Loss: 0.073395, Train Acc: 0.891026 | Val Loss: 0.108463, Val Acc: 0.804124\n",
      "Epoch 24210 - Train Loss: 0.073394, Train Acc: 0.891026 | Val Loss: 0.108462, Val Acc: 0.804124\n",
      "Epoch 24211 - Train Loss: 0.073392, Train Acc: 0.891026 | Val Loss: 0.108462, Val Acc: 0.804124\n",
      "Epoch 24212 - Train Loss: 0.073390, Train Acc: 0.891026 | Val Loss: 0.108462, Val Acc: 0.804124\n",
      "Epoch 24213 - Train Loss: 0.073389, Train Acc: 0.891026 | Val Loss: 0.108462, Val Acc: 0.804124\n",
      "Epoch 24214 - Train Loss: 0.073387, Train Acc: 0.891026 | Val Loss: 0.108461, Val Acc: 0.804124\n",
      "Epoch 24215 - Train Loss: 0.073386, Train Acc: 0.891026 | Val Loss: 0.108461, Val Acc: 0.804124\n",
      "Epoch 24216 - Train Loss: 0.073384, Train Acc: 0.891026 | Val Loss: 0.108461, Val Acc: 0.804124\n",
      "Epoch 24217 - Train Loss: 0.073382, Train Acc: 0.891026 | Val Loss: 0.108460, Val Acc: 0.804124\n",
      "Epoch 24218 - Train Loss: 0.073381, Train Acc: 0.891026 | Val Loss: 0.108460, Val Acc: 0.804124\n",
      "Epoch 24219 - Train Loss: 0.073379, Train Acc: 0.891026 | Val Loss: 0.108460, Val Acc: 0.804124\n",
      "Epoch 24220 - Train Loss: 0.073378, Train Acc: 0.891026 | Val Loss: 0.108459, Val Acc: 0.804124\n",
      "Epoch 24221 - Train Loss: 0.073376, Train Acc: 0.891026 | Val Loss: 0.108459, Val Acc: 0.804124\n",
      "Epoch 24222 - Train Loss: 0.073375, Train Acc: 0.891026 | Val Loss: 0.108459, Val Acc: 0.804124\n",
      "Epoch 24223 - Train Loss: 0.073373, Train Acc: 0.891026 | Val Loss: 0.108458, Val Acc: 0.804124\n",
      "Epoch 24224 - Train Loss: 0.073371, Train Acc: 0.891026 | Val Loss: 0.108458, Val Acc: 0.804124\n",
      "Epoch 24225 - Train Loss: 0.073370, Train Acc: 0.891026 | Val Loss: 0.108458, Val Acc: 0.804124\n",
      "Epoch 24226 - Train Loss: 0.073368, Train Acc: 0.891026 | Val Loss: 0.108458, Val Acc: 0.804124\n",
      "Epoch 24227 - Train Loss: 0.073367, Train Acc: 0.891026 | Val Loss: 0.108457, Val Acc: 0.804124\n",
      "Epoch 24228 - Train Loss: 0.073365, Train Acc: 0.891026 | Val Loss: 0.108457, Val Acc: 0.804124\n",
      "Epoch 24229 - Train Loss: 0.073364, Train Acc: 0.891026 | Val Loss: 0.108457, Val Acc: 0.804124\n",
      "Epoch 24230 - Train Loss: 0.073362, Train Acc: 0.891026 | Val Loss: 0.108456, Val Acc: 0.804124\n",
      "Epoch 24231 - Train Loss: 0.073360, Train Acc: 0.891026 | Val Loss: 0.108456, Val Acc: 0.804124\n",
      "Epoch 24232 - Train Loss: 0.073359, Train Acc: 0.891026 | Val Loss: 0.108456, Val Acc: 0.804124\n",
      "Epoch 24233 - Train Loss: 0.073357, Train Acc: 0.891026 | Val Loss: 0.108455, Val Acc: 0.804124\n",
      "Epoch 24234 - Train Loss: 0.073356, Train Acc: 0.891026 | Val Loss: 0.108455, Val Acc: 0.804124\n",
      "Epoch 24235 - Train Loss: 0.073354, Train Acc: 0.891026 | Val Loss: 0.108455, Val Acc: 0.804124\n",
      "Epoch 24236 - Train Loss: 0.073352, Train Acc: 0.891026 | Val Loss: 0.108454, Val Acc: 0.804124\n",
      "Epoch 24237 - Train Loss: 0.073351, Train Acc: 0.891026 | Val Loss: 0.108454, Val Acc: 0.804124\n",
      "Epoch 24238 - Train Loss: 0.073349, Train Acc: 0.891026 | Val Loss: 0.108454, Val Acc: 0.804124\n",
      "Epoch 24239 - Train Loss: 0.073348, Train Acc: 0.891026 | Val Loss: 0.108453, Val Acc: 0.804124\n",
      "Epoch 24240 - Train Loss: 0.073346, Train Acc: 0.891026 | Val Loss: 0.108453, Val Acc: 0.804124\n",
      "Epoch 24241 - Train Loss: 0.073345, Train Acc: 0.891026 | Val Loss: 0.108453, Val Acc: 0.804124\n",
      "Epoch 24242 - Train Loss: 0.073343, Train Acc: 0.891026 | Val Loss: 0.108453, Val Acc: 0.804124\n",
      "Epoch 24243 - Train Loss: 0.073341, Train Acc: 0.891026 | Val Loss: 0.108452, Val Acc: 0.804124\n",
      "Epoch 24244 - Train Loss: 0.073340, Train Acc: 0.891026 | Val Loss: 0.108452, Val Acc: 0.804124\n",
      "Epoch 24245 - Train Loss: 0.073338, Train Acc: 0.891026 | Val Loss: 0.108452, Val Acc: 0.804124\n",
      "Epoch 24246 - Train Loss: 0.073337, Train Acc: 0.891026 | Val Loss: 0.108451, Val Acc: 0.804124\n",
      "Epoch 24247 - Train Loss: 0.073335, Train Acc: 0.891026 | Val Loss: 0.108451, Val Acc: 0.804124\n",
      "Epoch 24248 - Train Loss: 0.073334, Train Acc: 0.891026 | Val Loss: 0.108451, Val Acc: 0.804124\n",
      "Epoch 24249 - Train Loss: 0.073332, Train Acc: 0.891026 | Val Loss: 0.108450, Val Acc: 0.804124\n",
      "Epoch 24250 - Train Loss: 0.073330, Train Acc: 0.891026 | Val Loss: 0.108450, Val Acc: 0.804124\n",
      "Epoch 24251 - Train Loss: 0.073329, Train Acc: 0.891026 | Val Loss: 0.108450, Val Acc: 0.804124\n",
      "Epoch 24252 - Train Loss: 0.073327, Train Acc: 0.891026 | Val Loss: 0.108449, Val Acc: 0.804124\n",
      "Epoch 24253 - Train Loss: 0.073326, Train Acc: 0.891026 | Val Loss: 0.108449, Val Acc: 0.804124\n",
      "Epoch 24254 - Train Loss: 0.073324, Train Acc: 0.891026 | Val Loss: 0.108449, Val Acc: 0.804124\n",
      "Epoch 24255 - Train Loss: 0.073323, Train Acc: 0.891026 | Val Loss: 0.108448, Val Acc: 0.804124\n",
      "Epoch 24256 - Train Loss: 0.073321, Train Acc: 0.891026 | Val Loss: 0.108448, Val Acc: 0.804124\n",
      "Epoch 24257 - Train Loss: 0.073319, Train Acc: 0.891026 | Val Loss: 0.108448, Val Acc: 0.804124\n",
      "Epoch 24258 - Train Loss: 0.073318, Train Acc: 0.891026 | Val Loss: 0.108448, Val Acc: 0.804124\n",
      "Epoch 24259 - Train Loss: 0.073316, Train Acc: 0.891026 | Val Loss: 0.108447, Val Acc: 0.804124\n",
      "Epoch 24260 - Train Loss: 0.073315, Train Acc: 0.891026 | Val Loss: 0.108447, Val Acc: 0.804124\n",
      "Epoch 24261 - Train Loss: 0.073313, Train Acc: 0.891026 | Val Loss: 0.108447, Val Acc: 0.804124\n",
      "Epoch 24262 - Train Loss: 0.073312, Train Acc: 0.891026 | Val Loss: 0.108446, Val Acc: 0.804124\n",
      "Epoch 24263 - Train Loss: 0.073310, Train Acc: 0.891026 | Val Loss: 0.108446, Val Acc: 0.804124\n",
      "Epoch 24264 - Train Loss: 0.073308, Train Acc: 0.891026 | Val Loss: 0.108446, Val Acc: 0.804124\n",
      "Epoch 24265 - Train Loss: 0.073307, Train Acc: 0.891026 | Val Loss: 0.108446, Val Acc: 0.804124\n",
      "Epoch 24266 - Train Loss: 0.073305, Train Acc: 0.891026 | Val Loss: 0.108445, Val Acc: 0.804124\n",
      "Epoch 24267 - Train Loss: 0.073304, Train Acc: 0.891026 | Val Loss: 0.108445, Val Acc: 0.804124\n",
      "Epoch 24268 - Train Loss: 0.073302, Train Acc: 0.891026 | Val Loss: 0.108445, Val Acc: 0.804124\n",
      "Epoch 24269 - Train Loss: 0.073301, Train Acc: 0.891026 | Val Loss: 0.108444, Val Acc: 0.804124\n",
      "Epoch 24270 - Train Loss: 0.073299, Train Acc: 0.891026 | Val Loss: 0.108444, Val Acc: 0.804124\n",
      "Epoch 24271 - Train Loss: 0.073297, Train Acc: 0.891026 | Val Loss: 0.108444, Val Acc: 0.804124\n",
      "Epoch 24272 - Train Loss: 0.073296, Train Acc: 0.891026 | Val Loss: 0.108443, Val Acc: 0.804124\n",
      "Epoch 24273 - Train Loss: 0.073294, Train Acc: 0.891026 | Val Loss: 0.108443, Val Acc: 0.804124\n",
      "Epoch 24274 - Train Loss: 0.073293, Train Acc: 0.891026 | Val Loss: 0.108443, Val Acc: 0.804124\n",
      "Epoch 24275 - Train Loss: 0.073291, Train Acc: 0.891026 | Val Loss: 0.108442, Val Acc: 0.804124\n",
      "Epoch 24276 - Train Loss: 0.073290, Train Acc: 0.891026 | Val Loss: 0.108442, Val Acc: 0.804124\n",
      "Epoch 24277 - Train Loss: 0.073288, Train Acc: 0.891026 | Val Loss: 0.108442, Val Acc: 0.804124\n",
      "Epoch 24278 - Train Loss: 0.073286, Train Acc: 0.891026 | Val Loss: 0.108441, Val Acc: 0.804124\n",
      "Epoch 24279 - Train Loss: 0.073285, Train Acc: 0.891026 | Val Loss: 0.108441, Val Acc: 0.804124\n",
      "Epoch 24280 - Train Loss: 0.073283, Train Acc: 0.891026 | Val Loss: 0.108441, Val Acc: 0.804124\n",
      "Epoch 24281 - Train Loss: 0.073282, Train Acc: 0.891026 | Val Loss: 0.108440, Val Acc: 0.804124\n",
      "Epoch 24282 - Train Loss: 0.073280, Train Acc: 0.891026 | Val Loss: 0.108440, Val Acc: 0.804124\n",
      "Epoch 24283 - Train Loss: 0.073279, Train Acc: 0.891026 | Val Loss: 0.108440, Val Acc: 0.804124\n",
      "Epoch 24284 - Train Loss: 0.073277, Train Acc: 0.891026 | Val Loss: 0.108440, Val Acc: 0.804124\n",
      "Epoch 24285 - Train Loss: 0.073275, Train Acc: 0.891026 | Val Loss: 0.108439, Val Acc: 0.804124\n",
      "Epoch 24286 - Train Loss: 0.073274, Train Acc: 0.891026 | Val Loss: 0.108439, Val Acc: 0.804124\n",
      "Epoch 24287 - Train Loss: 0.073272, Train Acc: 0.891026 | Val Loss: 0.108439, Val Acc: 0.804124\n",
      "Epoch 24288 - Train Loss: 0.073271, Train Acc: 0.891026 | Val Loss: 0.108438, Val Acc: 0.804124\n",
      "Epoch 24289 - Train Loss: 0.073269, Train Acc: 0.891026 | Val Loss: 0.108438, Val Acc: 0.804124\n",
      "Epoch 24290 - Train Loss: 0.073268, Train Acc: 0.891026 | Val Loss: 0.108438, Val Acc: 0.804124\n",
      "Epoch 24291 - Train Loss: 0.073266, Train Acc: 0.891026 | Val Loss: 0.108437, Val Acc: 0.804124\n",
      "Epoch 24292 - Train Loss: 0.073264, Train Acc: 0.891026 | Val Loss: 0.108437, Val Acc: 0.804124\n",
      "Epoch 24293 - Train Loss: 0.073263, Train Acc: 0.891026 | Val Loss: 0.108437, Val Acc: 0.804124\n",
      "Epoch 24294 - Train Loss: 0.073261, Train Acc: 0.891026 | Val Loss: 0.108436, Val Acc: 0.804124\n",
      "Epoch 24295 - Train Loss: 0.073260, Train Acc: 0.891026 | Val Loss: 0.108436, Val Acc: 0.804124\n",
      "Epoch 24296 - Train Loss: 0.073258, Train Acc: 0.891026 | Val Loss: 0.108436, Val Acc: 0.804124\n",
      "Epoch 24297 - Train Loss: 0.073257, Train Acc: 0.891026 | Val Loss: 0.108436, Val Acc: 0.804124\n",
      "Epoch 24298 - Train Loss: 0.073255, Train Acc: 0.891026 | Val Loss: 0.108435, Val Acc: 0.804124\n",
      "Epoch 24299 - Train Loss: 0.073253, Train Acc: 0.891026 | Val Loss: 0.108435, Val Acc: 0.804124\n",
      "Epoch 24300 - Train Loss: 0.073252, Train Acc: 0.891026 | Val Loss: 0.108435, Val Acc: 0.804124\n",
      "Epoch 24301 - Train Loss: 0.073250, Train Acc: 0.891026 | Val Loss: 0.108434, Val Acc: 0.804124\n",
      "Epoch 24302 - Train Loss: 0.073249, Train Acc: 0.891026 | Val Loss: 0.108434, Val Acc: 0.804124\n",
      "Epoch 24303 - Train Loss: 0.073247, Train Acc: 0.891026 | Val Loss: 0.108434, Val Acc: 0.804124\n",
      "Epoch 24304 - Train Loss: 0.073246, Train Acc: 0.891026 | Val Loss: 0.108433, Val Acc: 0.804124\n",
      "Epoch 24305 - Train Loss: 0.073244, Train Acc: 0.891026 | Val Loss: 0.108433, Val Acc: 0.804124\n",
      "Epoch 24306 - Train Loss: 0.073242, Train Acc: 0.891026 | Val Loss: 0.108433, Val Acc: 0.804124\n",
      "Epoch 24307 - Train Loss: 0.073241, Train Acc: 0.891026 | Val Loss: 0.108432, Val Acc: 0.804124\n",
      "Epoch 24308 - Train Loss: 0.073239, Train Acc: 0.891026 | Val Loss: 0.108432, Val Acc: 0.804124\n",
      "Epoch 24309 - Train Loss: 0.073238, Train Acc: 0.891026 | Val Loss: 0.108432, Val Acc: 0.804124\n",
      "Epoch 24310 - Train Loss: 0.073236, Train Acc: 0.891026 | Val Loss: 0.108432, Val Acc: 0.804124\n",
      "Epoch 24311 - Train Loss: 0.073235, Train Acc: 0.891026 | Val Loss: 0.108431, Val Acc: 0.804124\n",
      "Epoch 24312 - Train Loss: 0.073233, Train Acc: 0.891026 | Val Loss: 0.108431, Val Acc: 0.804124\n",
      "Epoch 24313 - Train Loss: 0.073231, Train Acc: 0.891026 | Val Loss: 0.108431, Val Acc: 0.804124\n",
      "Epoch 24314 - Train Loss: 0.073230, Train Acc: 0.891026 | Val Loss: 0.108430, Val Acc: 0.804124\n",
      "Epoch 24315 - Train Loss: 0.073228, Train Acc: 0.891026 | Val Loss: 0.108430, Val Acc: 0.804124\n",
      "Epoch 24316 - Train Loss: 0.073227, Train Acc: 0.891026 | Val Loss: 0.108430, Val Acc: 0.804124\n",
      "Epoch 24317 - Train Loss: 0.073225, Train Acc: 0.891026 | Val Loss: 0.108429, Val Acc: 0.804124\n",
      "Epoch 24318 - Train Loss: 0.073224, Train Acc: 0.891026 | Val Loss: 0.108429, Val Acc: 0.804124\n",
      "Epoch 24319 - Train Loss: 0.073222, Train Acc: 0.891026 | Val Loss: 0.108429, Val Acc: 0.804124\n",
      "Epoch 24320 - Train Loss: 0.073221, Train Acc: 0.891026 | Val Loss: 0.108429, Val Acc: 0.804124\n",
      "Epoch 24321 - Train Loss: 0.073219, Train Acc: 0.891026 | Val Loss: 0.108428, Val Acc: 0.804124\n",
      "Epoch 24322 - Train Loss: 0.073217, Train Acc: 0.891026 | Val Loss: 0.108428, Val Acc: 0.804124\n",
      "Epoch 24323 - Train Loss: 0.073216, Train Acc: 0.891026 | Val Loss: 0.108428, Val Acc: 0.804124\n",
      "Epoch 24324 - Train Loss: 0.073214, Train Acc: 0.891026 | Val Loss: 0.108427, Val Acc: 0.804124\n",
      "Epoch 24325 - Train Loss: 0.073213, Train Acc: 0.891026 | Val Loss: 0.108427, Val Acc: 0.804124\n",
      "Epoch 24326 - Train Loss: 0.073211, Train Acc: 0.891026 | Val Loss: 0.108427, Val Acc: 0.804124\n",
      "Epoch 24327 - Train Loss: 0.073210, Train Acc: 0.891026 | Val Loss: 0.108426, Val Acc: 0.804124\n",
      "Epoch 24328 - Train Loss: 0.073208, Train Acc: 0.891026 | Val Loss: 0.108426, Val Acc: 0.804124\n",
      "Epoch 24329 - Train Loss: 0.073206, Train Acc: 0.891026 | Val Loss: 0.108426, Val Acc: 0.804124\n",
      "Epoch 24330 - Train Loss: 0.073205, Train Acc: 0.891026 | Val Loss: 0.108425, Val Acc: 0.804124\n",
      "Epoch 24331 - Train Loss: 0.073203, Train Acc: 0.891026 | Val Loss: 0.108425, Val Acc: 0.804124\n",
      "Epoch 24332 - Train Loss: 0.073202, Train Acc: 0.891026 | Val Loss: 0.108425, Val Acc: 0.804124\n",
      "Epoch 24333 - Train Loss: 0.073200, Train Acc: 0.891026 | Val Loss: 0.108425, Val Acc: 0.804124\n",
      "Epoch 24334 - Train Loss: 0.073199, Train Acc: 0.891026 | Val Loss: 0.108424, Val Acc: 0.804124\n",
      "Epoch 24335 - Train Loss: 0.073197, Train Acc: 0.891026 | Val Loss: 0.108424, Val Acc: 0.804124\n",
      "Epoch 24336 - Train Loss: 0.073195, Train Acc: 0.891026 | Val Loss: 0.108424, Val Acc: 0.804124\n",
      "Epoch 24337 - Train Loss: 0.073194, Train Acc: 0.891026 | Val Loss: 0.108423, Val Acc: 0.804124\n",
      "Epoch 24338 - Train Loss: 0.073192, Train Acc: 0.891026 | Val Loss: 0.108423, Val Acc: 0.804124\n",
      "Epoch 24339 - Train Loss: 0.073191, Train Acc: 0.891026 | Val Loss: 0.108423, Val Acc: 0.804124\n",
      "Epoch 24340 - Train Loss: 0.073189, Train Acc: 0.891026 | Val Loss: 0.108423, Val Acc: 0.804124\n",
      "Epoch 24341 - Train Loss: 0.073188, Train Acc: 0.891026 | Val Loss: 0.108422, Val Acc: 0.804124\n",
      "Epoch 24342 - Train Loss: 0.073186, Train Acc: 0.891026 | Val Loss: 0.108422, Val Acc: 0.804124\n",
      "Epoch 24343 - Train Loss: 0.073185, Train Acc: 0.891026 | Val Loss: 0.108422, Val Acc: 0.804124\n",
      "Epoch 24344 - Train Loss: 0.073183, Train Acc: 0.891026 | Val Loss: 0.108421, Val Acc: 0.804124\n",
      "Epoch 24345 - Train Loss: 0.073181, Train Acc: 0.891026 | Val Loss: 0.108421, Val Acc: 0.804124\n",
      "Epoch 24346 - Train Loss: 0.073180, Train Acc: 0.891026 | Val Loss: 0.108421, Val Acc: 0.804124\n",
      "Epoch 24347 - Train Loss: 0.073178, Train Acc: 0.891026 | Val Loss: 0.108420, Val Acc: 0.804124\n",
      "Epoch 24348 - Train Loss: 0.073177, Train Acc: 0.891026 | Val Loss: 0.108420, Val Acc: 0.804124\n",
      "Epoch 24349 - Train Loss: 0.073175, Train Acc: 0.891026 | Val Loss: 0.108420, Val Acc: 0.804124\n",
      "Epoch 24350 - Train Loss: 0.073174, Train Acc: 0.891026 | Val Loss: 0.108419, Val Acc: 0.804124\n",
      "Epoch 24351 - Train Loss: 0.073172, Train Acc: 0.891026 | Val Loss: 0.108419, Val Acc: 0.804124\n",
      "Epoch 24352 - Train Loss: 0.073170, Train Acc: 0.891026 | Val Loss: 0.108419, Val Acc: 0.804124\n",
      "Epoch 24353 - Train Loss: 0.073169, Train Acc: 0.891026 | Val Loss: 0.108419, Val Acc: 0.804124\n",
      "Epoch 24354 - Train Loss: 0.073167, Train Acc: 0.891026 | Val Loss: 0.108418, Val Acc: 0.804124\n",
      "Epoch 24355 - Train Loss: 0.073166, Train Acc: 0.891026 | Val Loss: 0.108418, Val Acc: 0.804124\n",
      "Epoch 24356 - Train Loss: 0.073164, Train Acc: 0.891026 | Val Loss: 0.108418, Val Acc: 0.804124\n",
      "Epoch 24357 - Train Loss: 0.073163, Train Acc: 0.891026 | Val Loss: 0.108417, Val Acc: 0.804124\n",
      "Epoch 24358 - Train Loss: 0.073161, Train Acc: 0.891026 | Val Loss: 0.108417, Val Acc: 0.804124\n",
      "Epoch 24359 - Train Loss: 0.073160, Train Acc: 0.891026 | Val Loss: 0.108417, Val Acc: 0.804124\n",
      "Epoch 24360 - Train Loss: 0.073158, Train Acc: 0.891026 | Val Loss: 0.108416, Val Acc: 0.804124\n",
      "Epoch 24361 - Train Loss: 0.073156, Train Acc: 0.891026 | Val Loss: 0.108416, Val Acc: 0.804124\n",
      "Epoch 24362 - Train Loss: 0.073155, Train Acc: 0.891026 | Val Loss: 0.108416, Val Acc: 0.804124\n",
      "Epoch 24363 - Train Loss: 0.073153, Train Acc: 0.891026 | Val Loss: 0.108415, Val Acc: 0.804124\n",
      "Epoch 24364 - Train Loss: 0.073152, Train Acc: 0.891026 | Val Loss: 0.108415, Val Acc: 0.804124\n",
      "Epoch 24365 - Train Loss: 0.073150, Train Acc: 0.891026 | Val Loss: 0.108415, Val Acc: 0.804124\n",
      "Epoch 24366 - Train Loss: 0.073149, Train Acc: 0.891026 | Val Loss: 0.108415, Val Acc: 0.804124\n",
      "Epoch 24367 - Train Loss: 0.073147, Train Acc: 0.891026 | Val Loss: 0.108414, Val Acc: 0.814433\n",
      "Epoch 24368 - Train Loss: 0.073146, Train Acc: 0.891026 | Val Loss: 0.108414, Val Acc: 0.804124\n",
      "Epoch 24369 - Train Loss: 0.073144, Train Acc: 0.891026 | Val Loss: 0.108414, Val Acc: 0.804124\n",
      "Epoch 24370 - Train Loss: 0.073142, Train Acc: 0.891026 | Val Loss: 0.108413, Val Acc: 0.804124\n",
      "Epoch 24371 - Train Loss: 0.073141, Train Acc: 0.891026 | Val Loss: 0.108413, Val Acc: 0.814433\n",
      "Epoch 24372 - Train Loss: 0.073139, Train Acc: 0.891026 | Val Loss: 0.108413, Val Acc: 0.814433\n",
      "Epoch 24373 - Train Loss: 0.073138, Train Acc: 0.891026 | Val Loss: 0.108412, Val Acc: 0.804124\n",
      "Epoch 24374 - Train Loss: 0.073136, Train Acc: 0.891026 | Val Loss: 0.108412, Val Acc: 0.804124\n",
      "Epoch 24375 - Train Loss: 0.073135, Train Acc: 0.891026 | Val Loss: 0.108412, Val Acc: 0.804124\n",
      "Epoch 24376 - Train Loss: 0.073133, Train Acc: 0.891026 | Val Loss: 0.108411, Val Acc: 0.804124\n",
      "Epoch 24377 - Train Loss: 0.073131, Train Acc: 0.891026 | Val Loss: 0.108411, Val Acc: 0.804124\n",
      "Epoch 24378 - Train Loss: 0.073130, Train Acc: 0.891026 | Val Loss: 0.108411, Val Acc: 0.804124\n",
      "Epoch 24379 - Train Loss: 0.073128, Train Acc: 0.891026 | Val Loss: 0.108410, Val Acc: 0.804124\n",
      "Epoch 24380 - Train Loss: 0.073127, Train Acc: 0.891026 | Val Loss: 0.108410, Val Acc: 0.814433\n",
      "Epoch 24381 - Train Loss: 0.073125, Train Acc: 0.891026 | Val Loss: 0.108410, Val Acc: 0.804124\n",
      "Epoch 24382 - Train Loss: 0.073124, Train Acc: 0.891026 | Val Loss: 0.108410, Val Acc: 0.804124\n",
      "Epoch 24383 - Train Loss: 0.073122, Train Acc: 0.891026 | Val Loss: 0.108409, Val Acc: 0.804124\n",
      "Epoch 24384 - Train Loss: 0.073121, Train Acc: 0.891026 | Val Loss: 0.108409, Val Acc: 0.804124\n",
      "Epoch 24385 - Train Loss: 0.073119, Train Acc: 0.891026 | Val Loss: 0.108409, Val Acc: 0.804124\n",
      "Epoch 24386 - Train Loss: 0.073117, Train Acc: 0.891026 | Val Loss: 0.108408, Val Acc: 0.804124\n",
      "Epoch 24387 - Train Loss: 0.073116, Train Acc: 0.891026 | Val Loss: 0.108408, Val Acc: 0.804124\n",
      "Epoch 24388 - Train Loss: 0.073114, Train Acc: 0.891026 | Val Loss: 0.108408, Val Acc: 0.804124\n",
      "Epoch 24389 - Train Loss: 0.073113, Train Acc: 0.891026 | Val Loss: 0.108407, Val Acc: 0.804124\n",
      "Epoch 24390 - Train Loss: 0.073111, Train Acc: 0.891026 | Val Loss: 0.108407, Val Acc: 0.814433\n",
      "Epoch 24391 - Train Loss: 0.073110, Train Acc: 0.891026 | Val Loss: 0.108407, Val Acc: 0.804124\n",
      "Epoch 24392 - Train Loss: 0.073108, Train Acc: 0.891026 | Val Loss: 0.108406, Val Acc: 0.814433\n",
      "Epoch 24393 - Train Loss: 0.073106, Train Acc: 0.891026 | Val Loss: 0.108406, Val Acc: 0.804124\n",
      "Epoch 24394 - Train Loss: 0.073105, Train Acc: 0.891026 | Val Loss: 0.108406, Val Acc: 0.814433\n",
      "Epoch 24395 - Train Loss: 0.073103, Train Acc: 0.891026 | Val Loss: 0.108405, Val Acc: 0.814433\n",
      "Epoch 24396 - Train Loss: 0.073102, Train Acc: 0.891026 | Val Loss: 0.108405, Val Acc: 0.814433\n",
      "Epoch 24397 - Train Loss: 0.073100, Train Acc: 0.891026 | Val Loss: 0.108405, Val Acc: 0.814433\n",
      "Epoch 24398 - Train Loss: 0.073099, Train Acc: 0.891026 | Val Loss: 0.108405, Val Acc: 0.814433\n",
      "Epoch 24399 - Train Loss: 0.073097, Train Acc: 0.891026 | Val Loss: 0.108404, Val Acc: 0.814433\n",
      "Epoch 24400 - Train Loss: 0.073096, Train Acc: 0.891026 | Val Loss: 0.108404, Val Acc: 0.814433\n",
      "Epoch 24401 - Train Loss: 0.073094, Train Acc: 0.891026 | Val Loss: 0.108404, Val Acc: 0.814433\n",
      "Epoch 24402 - Train Loss: 0.073092, Train Acc: 0.891026 | Val Loss: 0.108404, Val Acc: 0.814433\n",
      "Epoch 24403 - Train Loss: 0.073091, Train Acc: 0.892308 | Val Loss: 0.108403, Val Acc: 0.814433\n",
      "Epoch 24404 - Train Loss: 0.073089, Train Acc: 0.892308 | Val Loss: 0.108403, Val Acc: 0.814433\n",
      "Epoch 24405 - Train Loss: 0.073088, Train Acc: 0.892308 | Val Loss: 0.108403, Val Acc: 0.814433\n",
      "Epoch 24406 - Train Loss: 0.073086, Train Acc: 0.892308 | Val Loss: 0.108403, Val Acc: 0.814433\n",
      "Epoch 24407 - Train Loss: 0.073085, Train Acc: 0.892308 | Val Loss: 0.108402, Val Acc: 0.814433\n",
      "Epoch 24408 - Train Loss: 0.073083, Train Acc: 0.892308 | Val Loss: 0.108402, Val Acc: 0.814433\n",
      "Epoch 24409 - Train Loss: 0.073082, Train Acc: 0.892308 | Val Loss: 0.108402, Val Acc: 0.814433\n",
      "Epoch 24410 - Train Loss: 0.073080, Train Acc: 0.892308 | Val Loss: 0.108402, Val Acc: 0.814433\n",
      "Epoch 24411 - Train Loss: 0.073078, Train Acc: 0.892308 | Val Loss: 0.108401, Val Acc: 0.814433\n",
      "Epoch 24412 - Train Loss: 0.073077, Train Acc: 0.892308 | Val Loss: 0.108401, Val Acc: 0.814433\n",
      "Epoch 24413 - Train Loss: 0.073075, Train Acc: 0.892308 | Val Loss: 0.108401, Val Acc: 0.814433\n",
      "Epoch 24414 - Train Loss: 0.073074, Train Acc: 0.892308 | Val Loss: 0.108400, Val Acc: 0.814433\n",
      "Epoch 24415 - Train Loss: 0.073072, Train Acc: 0.892308 | Val Loss: 0.108400, Val Acc: 0.814433\n",
      "Epoch 24416 - Train Loss: 0.073071, Train Acc: 0.892308 | Val Loss: 0.108400, Val Acc: 0.814433\n",
      "Epoch 24417 - Train Loss: 0.073069, Train Acc: 0.892308 | Val Loss: 0.108400, Val Acc: 0.814433\n",
      "Epoch 24418 - Train Loss: 0.073068, Train Acc: 0.892308 | Val Loss: 0.108399, Val Acc: 0.814433\n",
      "Epoch 24419 - Train Loss: 0.073066, Train Acc: 0.892308 | Val Loss: 0.108399, Val Acc: 0.814433\n",
      "Epoch 24420 - Train Loss: 0.073064, Train Acc: 0.892308 | Val Loss: 0.108399, Val Acc: 0.814433\n",
      "Epoch 24421 - Train Loss: 0.073063, Train Acc: 0.892308 | Val Loss: 0.108398, Val Acc: 0.814433\n",
      "Epoch 24422 - Train Loss: 0.073061, Train Acc: 0.892308 | Val Loss: 0.108398, Val Acc: 0.814433\n",
      "Epoch 24423 - Train Loss: 0.073060, Train Acc: 0.892308 | Val Loss: 0.108398, Val Acc: 0.814433\n",
      "Epoch 24424 - Train Loss: 0.073058, Train Acc: 0.892308 | Val Loss: 0.108398, Val Acc: 0.814433\n",
      "Epoch 24425 - Train Loss: 0.073057, Train Acc: 0.892308 | Val Loss: 0.108397, Val Acc: 0.814433\n",
      "Epoch 24426 - Train Loss: 0.073055, Train Acc: 0.892308 | Val Loss: 0.108397, Val Acc: 0.814433\n",
      "Epoch 24427 - Train Loss: 0.073054, Train Acc: 0.892308 | Val Loss: 0.108397, Val Acc: 0.814433\n",
      "Epoch 24428 - Train Loss: 0.073052, Train Acc: 0.892308 | Val Loss: 0.108397, Val Acc: 0.814433\n",
      "Epoch 24429 - Train Loss: 0.073050, Train Acc: 0.892308 | Val Loss: 0.108396, Val Acc: 0.814433\n",
      "Epoch 24430 - Train Loss: 0.073049, Train Acc: 0.892308 | Val Loss: 0.108396, Val Acc: 0.814433\n",
      "Epoch 24431 - Train Loss: 0.073047, Train Acc: 0.892308 | Val Loss: 0.108396, Val Acc: 0.814433\n",
      "Epoch 24432 - Train Loss: 0.073046, Train Acc: 0.892308 | Val Loss: 0.108395, Val Acc: 0.814433\n",
      "Epoch 24433 - Train Loss: 0.073044, Train Acc: 0.892308 | Val Loss: 0.108395, Val Acc: 0.814433\n",
      "Epoch 24434 - Train Loss: 0.073043, Train Acc: 0.892308 | Val Loss: 0.108395, Val Acc: 0.814433\n",
      "Epoch 24435 - Train Loss: 0.073041, Train Acc: 0.892308 | Val Loss: 0.108395, Val Acc: 0.814433\n",
      "Epoch 24436 - Train Loss: 0.073040, Train Acc: 0.892308 | Val Loss: 0.108394, Val Acc: 0.814433\n",
      "Epoch 24437 - Train Loss: 0.073038, Train Acc: 0.892308 | Val Loss: 0.108394, Val Acc: 0.814433\n",
      "Epoch 24438 - Train Loss: 0.073036, Train Acc: 0.892308 | Val Loss: 0.108394, Val Acc: 0.814433\n",
      "Epoch 24439 - Train Loss: 0.073035, Train Acc: 0.892308 | Val Loss: 0.108393, Val Acc: 0.814433\n",
      "Epoch 24440 - Train Loss: 0.073033, Train Acc: 0.892308 | Val Loss: 0.108393, Val Acc: 0.814433\n",
      "Epoch 24441 - Train Loss: 0.073032, Train Acc: 0.892308 | Val Loss: 0.108393, Val Acc: 0.814433\n",
      "Epoch 24442 - Train Loss: 0.073030, Train Acc: 0.892308 | Val Loss: 0.108393, Val Acc: 0.814433\n",
      "Epoch 24443 - Train Loss: 0.073029, Train Acc: 0.892308 | Val Loss: 0.108392, Val Acc: 0.814433\n",
      "Epoch 24444 - Train Loss: 0.073027, Train Acc: 0.892308 | Val Loss: 0.108392, Val Acc: 0.814433\n",
      "Epoch 24445 - Train Loss: 0.073026, Train Acc: 0.892308 | Val Loss: 0.108392, Val Acc: 0.814433\n",
      "Epoch 24446 - Train Loss: 0.073024, Train Acc: 0.892308 | Val Loss: 0.108392, Val Acc: 0.814433\n",
      "Epoch 24447 - Train Loss: 0.073022, Train Acc: 0.892308 | Val Loss: 0.108391, Val Acc: 0.814433\n",
      "Epoch 24448 - Train Loss: 0.073021, Train Acc: 0.892308 | Val Loss: 0.108391, Val Acc: 0.814433\n",
      "Epoch 24449 - Train Loss: 0.073019, Train Acc: 0.892308 | Val Loss: 0.108391, Val Acc: 0.814433\n",
      "Epoch 24450 - Train Loss: 0.073018, Train Acc: 0.892308 | Val Loss: 0.108390, Val Acc: 0.814433\n",
      "Epoch 24451 - Train Loss: 0.073016, Train Acc: 0.892308 | Val Loss: 0.108390, Val Acc: 0.814433\n",
      "Epoch 24452 - Train Loss: 0.073015, Train Acc: 0.892308 | Val Loss: 0.108390, Val Acc: 0.814433\n",
      "Epoch 24453 - Train Loss: 0.073013, Train Acc: 0.892308 | Val Loss: 0.108390, Val Acc: 0.814433\n",
      "Epoch 24454 - Train Loss: 0.073012, Train Acc: 0.892308 | Val Loss: 0.108389, Val Acc: 0.814433\n",
      "Epoch 24455 - Train Loss: 0.073010, Train Acc: 0.892308 | Val Loss: 0.108389, Val Acc: 0.814433\n",
      "Epoch 24456 - Train Loss: 0.073009, Train Acc: 0.892308 | Val Loss: 0.108389, Val Acc: 0.814433\n",
      "Epoch 24457 - Train Loss: 0.073007, Train Acc: 0.892308 | Val Loss: 0.108388, Val Acc: 0.814433\n",
      "Epoch 24458 - Train Loss: 0.073005, Train Acc: 0.892308 | Val Loss: 0.108388, Val Acc: 0.814433\n",
      "Epoch 24459 - Train Loss: 0.073004, Train Acc: 0.892308 | Val Loss: 0.108388, Val Acc: 0.814433\n",
      "Epoch 24460 - Train Loss: 0.073002, Train Acc: 0.892308 | Val Loss: 0.108388, Val Acc: 0.814433\n",
      "Epoch 24461 - Train Loss: 0.073001, Train Acc: 0.892308 | Val Loss: 0.108387, Val Acc: 0.814433\n",
      "Epoch 24462 - Train Loss: 0.072999, Train Acc: 0.892308 | Val Loss: 0.108387, Val Acc: 0.814433\n",
      "Epoch 24463 - Train Loss: 0.072998, Train Acc: 0.892308 | Val Loss: 0.108387, Val Acc: 0.814433\n",
      "Epoch 24464 - Train Loss: 0.072996, Train Acc: 0.892308 | Val Loss: 0.108386, Val Acc: 0.814433\n",
      "Epoch 24465 - Train Loss: 0.072995, Train Acc: 0.892308 | Val Loss: 0.108386, Val Acc: 0.814433\n",
      "Epoch 24466 - Train Loss: 0.072993, Train Acc: 0.892308 | Val Loss: 0.108386, Val Acc: 0.814433\n",
      "Epoch 24467 - Train Loss: 0.072991, Train Acc: 0.892308 | Val Loss: 0.108386, Val Acc: 0.814433\n",
      "Epoch 24468 - Train Loss: 0.072990, Train Acc: 0.892308 | Val Loss: 0.108385, Val Acc: 0.814433\n",
      "Epoch 24469 - Train Loss: 0.072988, Train Acc: 0.892308 | Val Loss: 0.108385, Val Acc: 0.814433\n",
      "Epoch 24470 - Train Loss: 0.072987, Train Acc: 0.892308 | Val Loss: 0.108385, Val Acc: 0.814433\n",
      "Epoch 24471 - Train Loss: 0.072985, Train Acc: 0.892308 | Val Loss: 0.108384, Val Acc: 0.814433\n",
      "Epoch 24472 - Train Loss: 0.072984, Train Acc: 0.892308 | Val Loss: 0.108384, Val Acc: 0.814433\n",
      "Epoch 24473 - Train Loss: 0.072982, Train Acc: 0.892308 | Val Loss: 0.108384, Val Acc: 0.814433\n",
      "Epoch 24474 - Train Loss: 0.072981, Train Acc: 0.892308 | Val Loss: 0.108384, Val Acc: 0.814433\n",
      "Epoch 24475 - Train Loss: 0.072979, Train Acc: 0.892308 | Val Loss: 0.108383, Val Acc: 0.814433\n",
      "Epoch 24476 - Train Loss: 0.072978, Train Acc: 0.892308 | Val Loss: 0.108383, Val Acc: 0.814433\n",
      "Epoch 24477 - Train Loss: 0.072976, Train Acc: 0.892308 | Val Loss: 0.108383, Val Acc: 0.814433\n",
      "Epoch 24478 - Train Loss: 0.072974, Train Acc: 0.892308 | Val Loss: 0.108382, Val Acc: 0.814433\n",
      "Epoch 24479 - Train Loss: 0.072973, Train Acc: 0.892308 | Val Loss: 0.108382, Val Acc: 0.814433\n",
      "Epoch 24480 - Train Loss: 0.072971, Train Acc: 0.892308 | Val Loss: 0.108382, Val Acc: 0.814433\n",
      "Epoch 24481 - Train Loss: 0.072970, Train Acc: 0.892308 | Val Loss: 0.108382, Val Acc: 0.814433\n",
      "Epoch 24482 - Train Loss: 0.072968, Train Acc: 0.892308 | Val Loss: 0.108381, Val Acc: 0.814433\n",
      "Epoch 24483 - Train Loss: 0.072967, Train Acc: 0.892308 | Val Loss: 0.108381, Val Acc: 0.814433\n",
      "Epoch 24484 - Train Loss: 0.072965, Train Acc: 0.892308 | Val Loss: 0.108381, Val Acc: 0.814433\n",
      "Epoch 24485 - Train Loss: 0.072964, Train Acc: 0.892308 | Val Loss: 0.108381, Val Acc: 0.814433\n",
      "Epoch 24486 - Train Loss: 0.072962, Train Acc: 0.892308 | Val Loss: 0.108380, Val Acc: 0.814433\n",
      "Epoch 24487 - Train Loss: 0.072961, Train Acc: 0.892308 | Val Loss: 0.108380, Val Acc: 0.814433\n",
      "Epoch 24488 - Train Loss: 0.072959, Train Acc: 0.892308 | Val Loss: 0.108380, Val Acc: 0.814433\n",
      "Epoch 24489 - Train Loss: 0.072957, Train Acc: 0.892308 | Val Loss: 0.108379, Val Acc: 0.814433\n",
      "Epoch 24490 - Train Loss: 0.072956, Train Acc: 0.892308 | Val Loss: 0.108379, Val Acc: 0.814433\n",
      "Epoch 24491 - Train Loss: 0.072954, Train Acc: 0.892308 | Val Loss: 0.108379, Val Acc: 0.814433\n",
      "Epoch 24492 - Train Loss: 0.072953, Train Acc: 0.892308 | Val Loss: 0.108379, Val Acc: 0.814433\n",
      "Epoch 24493 - Train Loss: 0.072951, Train Acc: 0.892308 | Val Loss: 0.108378, Val Acc: 0.814433\n",
      "Epoch 24494 - Train Loss: 0.072950, Train Acc: 0.892308 | Val Loss: 0.108378, Val Acc: 0.814433\n",
      "Epoch 24495 - Train Loss: 0.072948, Train Acc: 0.892308 | Val Loss: 0.108378, Val Acc: 0.814433\n",
      "Epoch 24496 - Train Loss: 0.072947, Train Acc: 0.892308 | Val Loss: 0.108377, Val Acc: 0.814433\n",
      "Epoch 24497 - Train Loss: 0.072945, Train Acc: 0.892308 | Val Loss: 0.108377, Val Acc: 0.814433\n",
      "Epoch 24498 - Train Loss: 0.072943, Train Acc: 0.892308 | Val Loss: 0.108377, Val Acc: 0.814433\n",
      "Epoch 24499 - Train Loss: 0.072942, Train Acc: 0.892308 | Val Loss: 0.108377, Val Acc: 0.814433\n",
      "Epoch 24500 - Train Loss: 0.072940, Train Acc: 0.892308 | Val Loss: 0.108376, Val Acc: 0.814433\n",
      "Epoch 24501 - Train Loss: 0.072939, Train Acc: 0.892308 | Val Loss: 0.108376, Val Acc: 0.814433\n",
      "Epoch 24502 - Train Loss: 0.072937, Train Acc: 0.892308 | Val Loss: 0.108376, Val Acc: 0.814433\n",
      "Epoch 24503 - Train Loss: 0.072936, Train Acc: 0.892308 | Val Loss: 0.108375, Val Acc: 0.814433\n",
      "Epoch 24504 - Train Loss: 0.072934, Train Acc: 0.892308 | Val Loss: 0.108375, Val Acc: 0.814433\n",
      "Epoch 24505 - Train Loss: 0.072933, Train Acc: 0.892308 | Val Loss: 0.108375, Val Acc: 0.814433\n",
      "Epoch 24506 - Train Loss: 0.072931, Train Acc: 0.892308 | Val Loss: 0.108375, Val Acc: 0.814433\n",
      "Epoch 24507 - Train Loss: 0.072930, Train Acc: 0.892308 | Val Loss: 0.108374, Val Acc: 0.814433\n",
      "Epoch 24508 - Train Loss: 0.072928, Train Acc: 0.892308 | Val Loss: 0.108374, Val Acc: 0.814433\n",
      "Epoch 24509 - Train Loss: 0.072927, Train Acc: 0.892308 | Val Loss: 0.108374, Val Acc: 0.814433\n",
      "Epoch 24510 - Train Loss: 0.072925, Train Acc: 0.892308 | Val Loss: 0.108373, Val Acc: 0.814433\n",
      "Epoch 24511 - Train Loss: 0.072923, Train Acc: 0.892308 | Val Loss: 0.108373, Val Acc: 0.814433\n",
      "Epoch 24512 - Train Loss: 0.072922, Train Acc: 0.892308 | Val Loss: 0.108373, Val Acc: 0.814433\n",
      "Epoch 24513 - Train Loss: 0.072920, Train Acc: 0.892308 | Val Loss: 0.108373, Val Acc: 0.814433\n",
      "Epoch 24514 - Train Loss: 0.072919, Train Acc: 0.892308 | Val Loss: 0.108372, Val Acc: 0.814433\n",
      "Epoch 24515 - Train Loss: 0.072917, Train Acc: 0.892308 | Val Loss: 0.108372, Val Acc: 0.814433\n",
      "Epoch 24516 - Train Loss: 0.072916, Train Acc: 0.892308 | Val Loss: 0.108372, Val Acc: 0.814433\n",
      "Epoch 24517 - Train Loss: 0.072914, Train Acc: 0.892308 | Val Loss: 0.108372, Val Acc: 0.814433\n",
      "Epoch 24518 - Train Loss: 0.072913, Train Acc: 0.892308 | Val Loss: 0.108371, Val Acc: 0.814433\n",
      "Epoch 24519 - Train Loss: 0.072911, Train Acc: 0.892308 | Val Loss: 0.108371, Val Acc: 0.814433\n",
      "Epoch 24520 - Train Loss: 0.072910, Train Acc: 0.892308 | Val Loss: 0.108371, Val Acc: 0.814433\n",
      "Epoch 24521 - Train Loss: 0.072908, Train Acc: 0.892308 | Val Loss: 0.108370, Val Acc: 0.814433\n",
      "Epoch 24522 - Train Loss: 0.072906, Train Acc: 0.892308 | Val Loss: 0.108370, Val Acc: 0.814433\n",
      "Epoch 24523 - Train Loss: 0.072905, Train Acc: 0.892308 | Val Loss: 0.108370, Val Acc: 0.814433\n",
      "Epoch 24524 - Train Loss: 0.072903, Train Acc: 0.892308 | Val Loss: 0.108370, Val Acc: 0.814433\n",
      "Epoch 24525 - Train Loss: 0.072902, Train Acc: 0.892308 | Val Loss: 0.108369, Val Acc: 0.814433\n",
      "Epoch 24526 - Train Loss: 0.072900, Train Acc: 0.892308 | Val Loss: 0.108369, Val Acc: 0.814433\n",
      "Epoch 24527 - Train Loss: 0.072899, Train Acc: 0.892308 | Val Loss: 0.108369, Val Acc: 0.814433\n",
      "Epoch 24528 - Train Loss: 0.072897, Train Acc: 0.892308 | Val Loss: 0.108368, Val Acc: 0.814433\n",
      "Epoch 24529 - Train Loss: 0.072896, Train Acc: 0.892308 | Val Loss: 0.108368, Val Acc: 0.814433\n",
      "Epoch 24530 - Train Loss: 0.072894, Train Acc: 0.892308 | Val Loss: 0.108368, Val Acc: 0.814433\n",
      "Epoch 24531 - Train Loss: 0.072893, Train Acc: 0.892308 | Val Loss: 0.108368, Val Acc: 0.814433\n",
      "Epoch 24532 - Train Loss: 0.072891, Train Acc: 0.892308 | Val Loss: 0.108367, Val Acc: 0.814433\n",
      "Epoch 24533 - Train Loss: 0.072889, Train Acc: 0.892308 | Val Loss: 0.108367, Val Acc: 0.814433\n",
      "Epoch 24534 - Train Loss: 0.072888, Train Acc: 0.892308 | Val Loss: 0.108367, Val Acc: 0.814433\n",
      "Epoch 24535 - Train Loss: 0.072886, Train Acc: 0.892308 | Val Loss: 0.108366, Val Acc: 0.814433\n",
      "Epoch 24536 - Train Loss: 0.072885, Train Acc: 0.892308 | Val Loss: 0.108366, Val Acc: 0.814433\n",
      "Epoch 24537 - Train Loss: 0.072883, Train Acc: 0.892308 | Val Loss: 0.108366, Val Acc: 0.814433\n",
      "Epoch 24538 - Train Loss: 0.072882, Train Acc: 0.892308 | Val Loss: 0.108366, Val Acc: 0.814433\n",
      "Epoch 24539 - Train Loss: 0.072880, Train Acc: 0.892308 | Val Loss: 0.108365, Val Acc: 0.814433\n",
      "Epoch 24540 - Train Loss: 0.072879, Train Acc: 0.892308 | Val Loss: 0.108365, Val Acc: 0.814433\n",
      "Epoch 24541 - Train Loss: 0.072877, Train Acc: 0.892308 | Val Loss: 0.108365, Val Acc: 0.814433\n",
      "Epoch 24542 - Train Loss: 0.072876, Train Acc: 0.892308 | Val Loss: 0.108365, Val Acc: 0.814433\n",
      "Epoch 24543 - Train Loss: 0.072874, Train Acc: 0.892308 | Val Loss: 0.108364, Val Acc: 0.814433\n",
      "Epoch 24544 - Train Loss: 0.072873, Train Acc: 0.892308 | Val Loss: 0.108364, Val Acc: 0.814433\n",
      "Epoch 24545 - Train Loss: 0.072871, Train Acc: 0.892308 | Val Loss: 0.108364, Val Acc: 0.814433\n",
      "Epoch 24546 - Train Loss: 0.072869, Train Acc: 0.892308 | Val Loss: 0.108363, Val Acc: 0.814433\n",
      "Epoch 24547 - Train Loss: 0.072868, Train Acc: 0.892308 | Val Loss: 0.108363, Val Acc: 0.814433\n",
      "Epoch 24548 - Train Loss: 0.072866, Train Acc: 0.892308 | Val Loss: 0.108363, Val Acc: 0.814433\n",
      "Epoch 24549 - Train Loss: 0.072865, Train Acc: 0.892308 | Val Loss: 0.108363, Val Acc: 0.814433\n",
      "Epoch 24550 - Train Loss: 0.072863, Train Acc: 0.892308 | Val Loss: 0.108362, Val Acc: 0.814433\n",
      "Epoch 24551 - Train Loss: 0.072862, Train Acc: 0.892308 | Val Loss: 0.108362, Val Acc: 0.814433\n",
      "Epoch 24552 - Train Loss: 0.072860, Train Acc: 0.892308 | Val Loss: 0.108362, Val Acc: 0.814433\n",
      "Epoch 24553 - Train Loss: 0.072859, Train Acc: 0.892308 | Val Loss: 0.108361, Val Acc: 0.814433\n",
      "Epoch 24554 - Train Loss: 0.072857, Train Acc: 0.892308 | Val Loss: 0.108361, Val Acc: 0.814433\n",
      "Epoch 24555 - Train Loss: 0.072856, Train Acc: 0.892308 | Val Loss: 0.108361, Val Acc: 0.814433\n",
      "Epoch 24556 - Train Loss: 0.072854, Train Acc: 0.892308 | Val Loss: 0.108361, Val Acc: 0.814433\n",
      "Epoch 24557 - Train Loss: 0.072853, Train Acc: 0.892308 | Val Loss: 0.108360, Val Acc: 0.814433\n",
      "Epoch 24558 - Train Loss: 0.072851, Train Acc: 0.892308 | Val Loss: 0.108360, Val Acc: 0.814433\n",
      "Epoch 24559 - Train Loss: 0.072849, Train Acc: 0.892308 | Val Loss: 0.108360, Val Acc: 0.814433\n",
      "Epoch 24560 - Train Loss: 0.072848, Train Acc: 0.892308 | Val Loss: 0.108360, Val Acc: 0.814433\n",
      "Epoch 24561 - Train Loss: 0.072846, Train Acc: 0.892308 | Val Loss: 0.108359, Val Acc: 0.814433\n",
      "Epoch 24562 - Train Loss: 0.072845, Train Acc: 0.892308 | Val Loss: 0.108359, Val Acc: 0.814433\n",
      "Epoch 24563 - Train Loss: 0.072843, Train Acc: 0.892308 | Val Loss: 0.108359, Val Acc: 0.814433\n",
      "Epoch 24564 - Train Loss: 0.072842, Train Acc: 0.892308 | Val Loss: 0.108358, Val Acc: 0.814433\n",
      "Epoch 24565 - Train Loss: 0.072840, Train Acc: 0.892308 | Val Loss: 0.108358, Val Acc: 0.814433\n",
      "Epoch 24566 - Train Loss: 0.072839, Train Acc: 0.892308 | Val Loss: 0.108358, Val Acc: 0.814433\n",
      "Epoch 24567 - Train Loss: 0.072837, Train Acc: 0.892308 | Val Loss: 0.108358, Val Acc: 0.814433\n",
      "Epoch 24568 - Train Loss: 0.072836, Train Acc: 0.892308 | Val Loss: 0.108357, Val Acc: 0.814433\n",
      "Epoch 24569 - Train Loss: 0.072834, Train Acc: 0.892308 | Val Loss: 0.108357, Val Acc: 0.814433\n",
      "Epoch 24570 - Train Loss: 0.072833, Train Acc: 0.892308 | Val Loss: 0.108357, Val Acc: 0.814433\n",
      "Epoch 24571 - Train Loss: 0.072831, Train Acc: 0.892308 | Val Loss: 0.108357, Val Acc: 0.814433\n",
      "Epoch 24572 - Train Loss: 0.072829, Train Acc: 0.892308 | Val Loss: 0.108356, Val Acc: 0.814433\n",
      "Epoch 24573 - Train Loss: 0.072828, Train Acc: 0.892308 | Val Loss: 0.108356, Val Acc: 0.814433\n",
      "Epoch 24574 - Train Loss: 0.072826, Train Acc: 0.892308 | Val Loss: 0.108356, Val Acc: 0.814433\n",
      "Epoch 24575 - Train Loss: 0.072825, Train Acc: 0.892308 | Val Loss: 0.108355, Val Acc: 0.814433\n",
      "Epoch 24576 - Train Loss: 0.072823, Train Acc: 0.892308 | Val Loss: 0.108355, Val Acc: 0.814433\n",
      "Epoch 24577 - Train Loss: 0.072822, Train Acc: 0.892308 | Val Loss: 0.108355, Val Acc: 0.814433\n",
      "Epoch 24578 - Train Loss: 0.072820, Train Acc: 0.892308 | Val Loss: 0.108355, Val Acc: 0.814433\n",
      "Epoch 24579 - Train Loss: 0.072819, Train Acc: 0.892308 | Val Loss: 0.108354, Val Acc: 0.814433\n",
      "Epoch 24580 - Train Loss: 0.072817, Train Acc: 0.892308 | Val Loss: 0.108354, Val Acc: 0.814433\n",
      "Epoch 24581 - Train Loss: 0.072816, Train Acc: 0.892308 | Val Loss: 0.108354, Val Acc: 0.814433\n",
      "Epoch 24582 - Train Loss: 0.072814, Train Acc: 0.892308 | Val Loss: 0.108353, Val Acc: 0.814433\n",
      "Epoch 24583 - Train Loss: 0.072813, Train Acc: 0.892308 | Val Loss: 0.108353, Val Acc: 0.814433\n",
      "Epoch 24584 - Train Loss: 0.072811, Train Acc: 0.892308 | Val Loss: 0.108353, Val Acc: 0.814433\n",
      "Epoch 24585 - Train Loss: 0.072809, Train Acc: 0.892308 | Val Loss: 0.108353, Val Acc: 0.814433\n",
      "Epoch 24586 - Train Loss: 0.072808, Train Acc: 0.892308 | Val Loss: 0.108352, Val Acc: 0.814433\n",
      "Epoch 24587 - Train Loss: 0.072806, Train Acc: 0.892308 | Val Loss: 0.108352, Val Acc: 0.814433\n",
      "Epoch 24588 - Train Loss: 0.072805, Train Acc: 0.892308 | Val Loss: 0.108352, Val Acc: 0.814433\n",
      "Epoch 24589 - Train Loss: 0.072803, Train Acc: 0.892308 | Val Loss: 0.108351, Val Acc: 0.814433\n",
      "Epoch 24590 - Train Loss: 0.072802, Train Acc: 0.892308 | Val Loss: 0.108351, Val Acc: 0.814433\n",
      "Epoch 24591 - Train Loss: 0.072800, Train Acc: 0.892308 | Val Loss: 0.108351, Val Acc: 0.814433\n",
      "Epoch 24592 - Train Loss: 0.072799, Train Acc: 0.892308 | Val Loss: 0.108351, Val Acc: 0.814433\n",
      "Epoch 24593 - Train Loss: 0.072797, Train Acc: 0.892308 | Val Loss: 0.108350, Val Acc: 0.814433\n",
      "Epoch 24594 - Train Loss: 0.072796, Train Acc: 0.892308 | Val Loss: 0.108350, Val Acc: 0.814433\n",
      "Epoch 24595 - Train Loss: 0.072794, Train Acc: 0.892308 | Val Loss: 0.108350, Val Acc: 0.814433\n",
      "Epoch 24596 - Train Loss: 0.072793, Train Acc: 0.892308 | Val Loss: 0.108350, Val Acc: 0.814433\n",
      "Epoch 24597 - Train Loss: 0.072791, Train Acc: 0.892308 | Val Loss: 0.108349, Val Acc: 0.814433\n",
      "Epoch 24598 - Train Loss: 0.072790, Train Acc: 0.892308 | Val Loss: 0.108349, Val Acc: 0.814433\n",
      "Epoch 24599 - Train Loss: 0.072788, Train Acc: 0.892308 | Val Loss: 0.108349, Val Acc: 0.814433\n",
      "Epoch 24600 - Train Loss: 0.072786, Train Acc: 0.892308 | Val Loss: 0.108348, Val Acc: 0.814433\n",
      "Epoch 24601 - Train Loss: 0.072785, Train Acc: 0.892308 | Val Loss: 0.108348, Val Acc: 0.814433\n",
      "Epoch 24602 - Train Loss: 0.072783, Train Acc: 0.892308 | Val Loss: 0.108348, Val Acc: 0.814433\n",
      "Epoch 24603 - Train Loss: 0.072782, Train Acc: 0.892308 | Val Loss: 0.108348, Val Acc: 0.814433\n",
      "Epoch 24604 - Train Loss: 0.072780, Train Acc: 0.892308 | Val Loss: 0.108347, Val Acc: 0.814433\n",
      "Epoch 24605 - Train Loss: 0.072779, Train Acc: 0.892308 | Val Loss: 0.108347, Val Acc: 0.814433\n",
      "Epoch 24606 - Train Loss: 0.072777, Train Acc: 0.892308 | Val Loss: 0.108347, Val Acc: 0.814433\n",
      "Epoch 24607 - Train Loss: 0.072776, Train Acc: 0.892308 | Val Loss: 0.108347, Val Acc: 0.814433\n",
      "Epoch 24608 - Train Loss: 0.072774, Train Acc: 0.892308 | Val Loss: 0.108346, Val Acc: 0.814433\n",
      "Epoch 24609 - Train Loss: 0.072773, Train Acc: 0.892308 | Val Loss: 0.108346, Val Acc: 0.814433\n",
      "Epoch 24610 - Train Loss: 0.072771, Train Acc: 0.892308 | Val Loss: 0.108346, Val Acc: 0.814433\n",
      "Epoch 24611 - Train Loss: 0.072770, Train Acc: 0.892308 | Val Loss: 0.108346, Val Acc: 0.814433\n",
      "Epoch 24612 - Train Loss: 0.072768, Train Acc: 0.892308 | Val Loss: 0.108345, Val Acc: 0.814433\n",
      "Epoch 24613 - Train Loss: 0.072767, Train Acc: 0.892308 | Val Loss: 0.108345, Val Acc: 0.814433\n",
      "Epoch 24614 - Train Loss: 0.072765, Train Acc: 0.892308 | Val Loss: 0.108345, Val Acc: 0.814433\n",
      "Epoch 24615 - Train Loss: 0.072763, Train Acc: 0.892308 | Val Loss: 0.108344, Val Acc: 0.814433\n",
      "Epoch 24616 - Train Loss: 0.072762, Train Acc: 0.892308 | Val Loss: 0.108344, Val Acc: 0.814433\n",
      "Epoch 24617 - Train Loss: 0.072760, Train Acc: 0.892308 | Val Loss: 0.108344, Val Acc: 0.814433\n",
      "Epoch 24618 - Train Loss: 0.072759, Train Acc: 0.892308 | Val Loss: 0.108344, Val Acc: 0.814433\n",
      "Epoch 24619 - Train Loss: 0.072757, Train Acc: 0.892308 | Val Loss: 0.108343, Val Acc: 0.814433\n",
      "Epoch 24620 - Train Loss: 0.072756, Train Acc: 0.892308 | Val Loss: 0.108343, Val Acc: 0.814433\n",
      "Epoch 24621 - Train Loss: 0.072754, Train Acc: 0.892308 | Val Loss: 0.108343, Val Acc: 0.814433\n",
      "Epoch 24622 - Train Loss: 0.072753, Train Acc: 0.892308 | Val Loss: 0.108342, Val Acc: 0.814433\n",
      "Epoch 24623 - Train Loss: 0.072751, Train Acc: 0.892308 | Val Loss: 0.108342, Val Acc: 0.814433\n",
      "Epoch 24624 - Train Loss: 0.072750, Train Acc: 0.892308 | Val Loss: 0.108342, Val Acc: 0.814433\n",
      "Epoch 24625 - Train Loss: 0.072748, Train Acc: 0.892308 | Val Loss: 0.108342, Val Acc: 0.814433\n",
      "Epoch 24626 - Train Loss: 0.072747, Train Acc: 0.892308 | Val Loss: 0.108341, Val Acc: 0.814433\n",
      "Epoch 24627 - Train Loss: 0.072745, Train Acc: 0.892308 | Val Loss: 0.108341, Val Acc: 0.814433\n",
      "Epoch 24628 - Train Loss: 0.072744, Train Acc: 0.892308 | Val Loss: 0.108341, Val Acc: 0.814433\n",
      "Epoch 24629 - Train Loss: 0.072742, Train Acc: 0.892308 | Val Loss: 0.108341, Val Acc: 0.814433\n",
      "Epoch 24630 - Train Loss: 0.072740, Train Acc: 0.892308 | Val Loss: 0.108340, Val Acc: 0.814433\n",
      "Epoch 24631 - Train Loss: 0.072739, Train Acc: 0.892308 | Val Loss: 0.108340, Val Acc: 0.814433\n",
      "Epoch 24632 - Train Loss: 0.072737, Train Acc: 0.892308 | Val Loss: 0.108340, Val Acc: 0.814433\n",
      "Epoch 24633 - Train Loss: 0.072736, Train Acc: 0.892308 | Val Loss: 0.108339, Val Acc: 0.814433\n",
      "Epoch 24634 - Train Loss: 0.072734, Train Acc: 0.892308 | Val Loss: 0.108339, Val Acc: 0.814433\n",
      "Epoch 24635 - Train Loss: 0.072733, Train Acc: 0.892308 | Val Loss: 0.108339, Val Acc: 0.814433\n",
      "Epoch 24636 - Train Loss: 0.072731, Train Acc: 0.892308 | Val Loss: 0.108339, Val Acc: 0.814433\n",
      "Epoch 24637 - Train Loss: 0.072730, Train Acc: 0.892308 | Val Loss: 0.108338, Val Acc: 0.814433\n",
      "Epoch 24638 - Train Loss: 0.072728, Train Acc: 0.892308 | Val Loss: 0.108338, Val Acc: 0.814433\n",
      "Epoch 24639 - Train Loss: 0.072727, Train Acc: 0.892308 | Val Loss: 0.108338, Val Acc: 0.814433\n",
      "Epoch 24640 - Train Loss: 0.072725, Train Acc: 0.892308 | Val Loss: 0.108338, Val Acc: 0.814433\n",
      "Epoch 24641 - Train Loss: 0.072724, Train Acc: 0.892308 | Val Loss: 0.108337, Val Acc: 0.814433\n",
      "Epoch 24642 - Train Loss: 0.072722, Train Acc: 0.892308 | Val Loss: 0.108337, Val Acc: 0.814433\n",
      "Epoch 24643 - Train Loss: 0.072721, Train Acc: 0.892308 | Val Loss: 0.108337, Val Acc: 0.814433\n",
      "Epoch 24644 - Train Loss: 0.072719, Train Acc: 0.892308 | Val Loss: 0.108336, Val Acc: 0.814433\n",
      "Epoch 24645 - Train Loss: 0.072718, Train Acc: 0.892308 | Val Loss: 0.108336, Val Acc: 0.814433\n",
      "Epoch 24646 - Train Loss: 0.072716, Train Acc: 0.892308 | Val Loss: 0.108336, Val Acc: 0.814433\n",
      "Epoch 24647 - Train Loss: 0.072714, Train Acc: 0.892308 | Val Loss: 0.108336, Val Acc: 0.814433\n",
      "Epoch 24648 - Train Loss: 0.072713, Train Acc: 0.892308 | Val Loss: 0.108335, Val Acc: 0.814433\n",
      "Epoch 24649 - Train Loss: 0.072711, Train Acc: 0.892308 | Val Loss: 0.108335, Val Acc: 0.814433\n",
      "Epoch 24650 - Train Loss: 0.072710, Train Acc: 0.892308 | Val Loss: 0.108335, Val Acc: 0.814433\n",
      "Epoch 24651 - Train Loss: 0.072708, Train Acc: 0.892308 | Val Loss: 0.108335, Val Acc: 0.814433\n",
      "Epoch 24652 - Train Loss: 0.072707, Train Acc: 0.892308 | Val Loss: 0.108334, Val Acc: 0.814433\n",
      "Epoch 24653 - Train Loss: 0.072705, Train Acc: 0.892308 | Val Loss: 0.108334, Val Acc: 0.814433\n",
      "Epoch 24654 - Train Loss: 0.072704, Train Acc: 0.892308 | Val Loss: 0.108334, Val Acc: 0.814433\n",
      "Epoch 24655 - Train Loss: 0.072702, Train Acc: 0.892308 | Val Loss: 0.108334, Val Acc: 0.814433\n",
      "Epoch 24656 - Train Loss: 0.072701, Train Acc: 0.892308 | Val Loss: 0.108333, Val Acc: 0.814433\n",
      "Epoch 24657 - Train Loss: 0.072699, Train Acc: 0.892308 | Val Loss: 0.108333, Val Acc: 0.814433\n",
      "Epoch 24658 - Train Loss: 0.072698, Train Acc: 0.892308 | Val Loss: 0.108333, Val Acc: 0.814433\n",
      "Epoch 24659 - Train Loss: 0.072696, Train Acc: 0.892308 | Val Loss: 0.108332, Val Acc: 0.814433\n",
      "Epoch 24660 - Train Loss: 0.072695, Train Acc: 0.892308 | Val Loss: 0.108332, Val Acc: 0.814433\n",
      "Epoch 24661 - Train Loss: 0.072693, Train Acc: 0.892308 | Val Loss: 0.108332, Val Acc: 0.814433\n",
      "Epoch 24662 - Train Loss: 0.072692, Train Acc: 0.892308 | Val Loss: 0.108332, Val Acc: 0.814433\n",
      "Epoch 24663 - Train Loss: 0.072690, Train Acc: 0.892308 | Val Loss: 0.108331, Val Acc: 0.814433\n",
      "Epoch 24664 - Train Loss: 0.072689, Train Acc: 0.892308 | Val Loss: 0.108331, Val Acc: 0.814433\n",
      "Epoch 24665 - Train Loss: 0.072687, Train Acc: 0.892308 | Val Loss: 0.108331, Val Acc: 0.814433\n",
      "Epoch 24666 - Train Loss: 0.072685, Train Acc: 0.892308 | Val Loss: 0.108331, Val Acc: 0.814433\n",
      "Epoch 24667 - Train Loss: 0.072684, Train Acc: 0.892308 | Val Loss: 0.108330, Val Acc: 0.814433\n",
      "Epoch 24668 - Train Loss: 0.072682, Train Acc: 0.892308 | Val Loss: 0.108330, Val Acc: 0.814433\n",
      "Epoch 24669 - Train Loss: 0.072681, Train Acc: 0.892308 | Val Loss: 0.108330, Val Acc: 0.814433\n",
      "Epoch 24670 - Train Loss: 0.072679, Train Acc: 0.892308 | Val Loss: 0.108330, Val Acc: 0.814433\n",
      "Epoch 24671 - Train Loss: 0.072678, Train Acc: 0.892308 | Val Loss: 0.108329, Val Acc: 0.814433\n",
      "Epoch 24672 - Train Loss: 0.072676, Train Acc: 0.892308 | Val Loss: 0.108329, Val Acc: 0.814433\n",
      "Epoch 24673 - Train Loss: 0.072675, Train Acc: 0.892308 | Val Loss: 0.108329, Val Acc: 0.814433\n",
      "Epoch 24674 - Train Loss: 0.072673, Train Acc: 0.892308 | Val Loss: 0.108328, Val Acc: 0.814433\n",
      "Epoch 24675 - Train Loss: 0.072672, Train Acc: 0.892308 | Val Loss: 0.108328, Val Acc: 0.814433\n",
      "Epoch 24676 - Train Loss: 0.072670, Train Acc: 0.892308 | Val Loss: 0.108328, Val Acc: 0.814433\n",
      "Epoch 24677 - Train Loss: 0.072669, Train Acc: 0.892308 | Val Loss: 0.108328, Val Acc: 0.814433\n",
      "Epoch 24678 - Train Loss: 0.072667, Train Acc: 0.892308 | Val Loss: 0.108327, Val Acc: 0.814433\n",
      "Epoch 24679 - Train Loss: 0.072666, Train Acc: 0.892308 | Val Loss: 0.108327, Val Acc: 0.814433\n",
      "Epoch 24680 - Train Loss: 0.072664, Train Acc: 0.892308 | Val Loss: 0.108327, Val Acc: 0.814433\n",
      "Epoch 24681 - Train Loss: 0.072663, Train Acc: 0.892308 | Val Loss: 0.108327, Val Acc: 0.814433\n",
      "Epoch 24682 - Train Loss: 0.072661, Train Acc: 0.892308 | Val Loss: 0.108326, Val Acc: 0.814433\n",
      "Epoch 24683 - Train Loss: 0.072660, Train Acc: 0.892308 | Val Loss: 0.108326, Val Acc: 0.814433\n",
      "Epoch 24684 - Train Loss: 0.072658, Train Acc: 0.892308 | Val Loss: 0.108326, Val Acc: 0.814433\n",
      "Epoch 24685 - Train Loss: 0.072656, Train Acc: 0.892308 | Val Loss: 0.108326, Val Acc: 0.814433\n",
      "Epoch 24686 - Train Loss: 0.072655, Train Acc: 0.892308 | Val Loss: 0.108325, Val Acc: 0.814433\n",
      "Epoch 24687 - Train Loss: 0.072653, Train Acc: 0.892308 | Val Loss: 0.108325, Val Acc: 0.814433\n",
      "Epoch 24688 - Train Loss: 0.072652, Train Acc: 0.892308 | Val Loss: 0.108325, Val Acc: 0.814433\n",
      "Epoch 24689 - Train Loss: 0.072650, Train Acc: 0.892308 | Val Loss: 0.108324, Val Acc: 0.814433\n",
      "Epoch 24690 - Train Loss: 0.072649, Train Acc: 0.892308 | Val Loss: 0.108324, Val Acc: 0.814433\n",
      "Epoch 24691 - Train Loss: 0.072647, Train Acc: 0.892308 | Val Loss: 0.108324, Val Acc: 0.814433\n",
      "Epoch 24692 - Train Loss: 0.072646, Train Acc: 0.892308 | Val Loss: 0.108324, Val Acc: 0.814433\n",
      "Epoch 24693 - Train Loss: 0.072644, Train Acc: 0.892308 | Val Loss: 0.108323, Val Acc: 0.814433\n",
      "Epoch 24694 - Train Loss: 0.072643, Train Acc: 0.892308 | Val Loss: 0.108323, Val Acc: 0.814433\n",
      "Epoch 24695 - Train Loss: 0.072641, Train Acc: 0.892308 | Val Loss: 0.108323, Val Acc: 0.814433\n",
      "Epoch 24696 - Train Loss: 0.072640, Train Acc: 0.892308 | Val Loss: 0.108323, Val Acc: 0.814433\n",
      "Epoch 24697 - Train Loss: 0.072638, Train Acc: 0.892308 | Val Loss: 0.108322, Val Acc: 0.814433\n",
      "Epoch 24698 - Train Loss: 0.072637, Train Acc: 0.892308 | Val Loss: 0.108322, Val Acc: 0.814433\n",
      "Epoch 24699 - Train Loss: 0.072635, Train Acc: 0.892308 | Val Loss: 0.108322, Val Acc: 0.814433\n",
      "Epoch 24700 - Train Loss: 0.072634, Train Acc: 0.892308 | Val Loss: 0.108322, Val Acc: 0.814433\n",
      "Epoch 24701 - Train Loss: 0.072632, Train Acc: 0.892308 | Val Loss: 0.108321, Val Acc: 0.814433\n",
      "Epoch 24702 - Train Loss: 0.072631, Train Acc: 0.892308 | Val Loss: 0.108321, Val Acc: 0.814433\n",
      "Epoch 24703 - Train Loss: 0.072629, Train Acc: 0.892308 | Val Loss: 0.108321, Val Acc: 0.814433\n",
      "Epoch 24704 - Train Loss: 0.072628, Train Acc: 0.892308 | Val Loss: 0.108320, Val Acc: 0.814433\n",
      "Epoch 24705 - Train Loss: 0.072626, Train Acc: 0.892308 | Val Loss: 0.108320, Val Acc: 0.814433\n",
      "Epoch 24706 - Train Loss: 0.072624, Train Acc: 0.892308 | Val Loss: 0.108320, Val Acc: 0.814433\n",
      "Epoch 24707 - Train Loss: 0.072623, Train Acc: 0.892308 | Val Loss: 0.108320, Val Acc: 0.814433\n",
      "Epoch 24708 - Train Loss: 0.072621, Train Acc: 0.892308 | Val Loss: 0.108319, Val Acc: 0.814433\n",
      "Epoch 24709 - Train Loss: 0.072620, Train Acc: 0.892308 | Val Loss: 0.108319, Val Acc: 0.814433\n",
      "Epoch 24710 - Train Loss: 0.072618, Train Acc: 0.892308 | Val Loss: 0.108319, Val Acc: 0.814433\n",
      "Epoch 24711 - Train Loss: 0.072617, Train Acc: 0.892308 | Val Loss: 0.108319, Val Acc: 0.814433\n",
      "Epoch 24712 - Train Loss: 0.072615, Train Acc: 0.892308 | Val Loss: 0.108318, Val Acc: 0.814433\n",
      "Epoch 24713 - Train Loss: 0.072614, Train Acc: 0.892308 | Val Loss: 0.108318, Val Acc: 0.814433\n",
      "Epoch 24714 - Train Loss: 0.072612, Train Acc: 0.892308 | Val Loss: 0.108318, Val Acc: 0.814433\n",
      "Epoch 24715 - Train Loss: 0.072611, Train Acc: 0.892308 | Val Loss: 0.108318, Val Acc: 0.814433\n",
      "Epoch 24716 - Train Loss: 0.072609, Train Acc: 0.892308 | Val Loss: 0.108317, Val Acc: 0.814433\n",
      "Epoch 24717 - Train Loss: 0.072608, Train Acc: 0.892308 | Val Loss: 0.108317, Val Acc: 0.814433\n",
      "Epoch 24718 - Train Loss: 0.072606, Train Acc: 0.892308 | Val Loss: 0.108317, Val Acc: 0.814433\n",
      "Epoch 24719 - Train Loss: 0.072605, Train Acc: 0.892308 | Val Loss: 0.108316, Val Acc: 0.814433\n",
      "Epoch 24720 - Train Loss: 0.072603, Train Acc: 0.892308 | Val Loss: 0.108316, Val Acc: 0.814433\n",
      "Epoch 24721 - Train Loss: 0.072602, Train Acc: 0.892308 | Val Loss: 0.108316, Val Acc: 0.814433\n",
      "Epoch 24722 - Train Loss: 0.072600, Train Acc: 0.892308 | Val Loss: 0.108316, Val Acc: 0.814433\n",
      "Epoch 24723 - Train Loss: 0.072599, Train Acc: 0.892308 | Val Loss: 0.108315, Val Acc: 0.814433\n",
      "Epoch 24724 - Train Loss: 0.072597, Train Acc: 0.892308 | Val Loss: 0.108315, Val Acc: 0.814433\n",
      "Epoch 24725 - Train Loss: 0.072596, Train Acc: 0.892308 | Val Loss: 0.108315, Val Acc: 0.814433\n",
      "Epoch 24726 - Train Loss: 0.072594, Train Acc: 0.892308 | Val Loss: 0.108315, Val Acc: 0.814433\n",
      "Epoch 24727 - Train Loss: 0.072593, Train Acc: 0.892308 | Val Loss: 0.108314, Val Acc: 0.814433\n",
      "Epoch 24728 - Train Loss: 0.072591, Train Acc: 0.892308 | Val Loss: 0.108314, Val Acc: 0.814433\n",
      "Epoch 24729 - Train Loss: 0.072590, Train Acc: 0.892308 | Val Loss: 0.108314, Val Acc: 0.814433\n",
      "Epoch 24730 - Train Loss: 0.072588, Train Acc: 0.892308 | Val Loss: 0.108314, Val Acc: 0.814433\n",
      "Epoch 24731 - Train Loss: 0.072586, Train Acc: 0.892308 | Val Loss: 0.108313, Val Acc: 0.814433\n",
      "Epoch 24732 - Train Loss: 0.072585, Train Acc: 0.892308 | Val Loss: 0.108313, Val Acc: 0.814433\n",
      "Epoch 24733 - Train Loss: 0.072583, Train Acc: 0.892308 | Val Loss: 0.108313, Val Acc: 0.814433\n",
      "Epoch 24734 - Train Loss: 0.072582, Train Acc: 0.892308 | Val Loss: 0.108313, Val Acc: 0.814433\n",
      "Epoch 24735 - Train Loss: 0.072580, Train Acc: 0.892308 | Val Loss: 0.108312, Val Acc: 0.814433\n",
      "Epoch 24736 - Train Loss: 0.072579, Train Acc: 0.892308 | Val Loss: 0.108312, Val Acc: 0.814433\n",
      "Epoch 24737 - Train Loss: 0.072577, Train Acc: 0.892308 | Val Loss: 0.108312, Val Acc: 0.814433\n",
      "Epoch 24738 - Train Loss: 0.072576, Train Acc: 0.892308 | Val Loss: 0.108312, Val Acc: 0.814433\n",
      "Epoch 24739 - Train Loss: 0.072574, Train Acc: 0.892308 | Val Loss: 0.108311, Val Acc: 0.814433\n",
      "Epoch 24740 - Train Loss: 0.072573, Train Acc: 0.892308 | Val Loss: 0.108311, Val Acc: 0.814433\n",
      "Epoch 24741 - Train Loss: 0.072571, Train Acc: 0.892308 | Val Loss: 0.108311, Val Acc: 0.814433\n",
      "Epoch 24742 - Train Loss: 0.072570, Train Acc: 0.892308 | Val Loss: 0.108310, Val Acc: 0.814433\n",
      "Epoch 24743 - Train Loss: 0.072568, Train Acc: 0.892308 | Val Loss: 0.108310, Val Acc: 0.814433\n",
      "Epoch 24744 - Train Loss: 0.072567, Train Acc: 0.892308 | Val Loss: 0.108310, Val Acc: 0.814433\n",
      "Epoch 24745 - Train Loss: 0.072565, Train Acc: 0.892308 | Val Loss: 0.108310, Val Acc: 0.814433\n",
      "Epoch 24746 - Train Loss: 0.072564, Train Acc: 0.892308 | Val Loss: 0.108309, Val Acc: 0.814433\n",
      "Epoch 24747 - Train Loss: 0.072562, Train Acc: 0.892308 | Val Loss: 0.108309, Val Acc: 0.814433\n",
      "Epoch 24748 - Train Loss: 0.072561, Train Acc: 0.892308 | Val Loss: 0.108309, Val Acc: 0.814433\n",
      "Epoch 24749 - Train Loss: 0.072559, Train Acc: 0.892308 | Val Loss: 0.108309, Val Acc: 0.814433\n",
      "Epoch 24750 - Train Loss: 0.072558, Train Acc: 0.892308 | Val Loss: 0.108308, Val Acc: 0.814433\n",
      "Epoch 24751 - Train Loss: 0.072556, Train Acc: 0.892308 | Val Loss: 0.108308, Val Acc: 0.814433\n",
      "Epoch 24752 - Train Loss: 0.072555, Train Acc: 0.892308 | Val Loss: 0.108308, Val Acc: 0.814433\n",
      "Epoch 24753 - Train Loss: 0.072553, Train Acc: 0.892308 | Val Loss: 0.108308, Val Acc: 0.814433\n",
      "Epoch 24754 - Train Loss: 0.072552, Train Acc: 0.892308 | Val Loss: 0.108307, Val Acc: 0.814433\n",
      "Epoch 24755 - Train Loss: 0.072550, Train Acc: 0.892308 | Val Loss: 0.108307, Val Acc: 0.814433\n",
      "Epoch 24756 - Train Loss: 0.072549, Train Acc: 0.892308 | Val Loss: 0.108307, Val Acc: 0.814433\n",
      "Epoch 24757 - Train Loss: 0.072547, Train Acc: 0.892308 | Val Loss: 0.108307, Val Acc: 0.814433\n",
      "Epoch 24758 - Train Loss: 0.072546, Train Acc: 0.892308 | Val Loss: 0.108306, Val Acc: 0.814433\n",
      "Epoch 24759 - Train Loss: 0.072544, Train Acc: 0.892308 | Val Loss: 0.108306, Val Acc: 0.814433\n",
      "Epoch 24760 - Train Loss: 0.072542, Train Acc: 0.892308 | Val Loss: 0.108306, Val Acc: 0.814433\n",
      "Epoch 24761 - Train Loss: 0.072541, Train Acc: 0.892308 | Val Loss: 0.108306, Val Acc: 0.814433\n",
      "Epoch 24762 - Train Loss: 0.072539, Train Acc: 0.892308 | Val Loss: 0.108305, Val Acc: 0.814433\n",
      "Epoch 24763 - Train Loss: 0.072538, Train Acc: 0.892308 | Val Loss: 0.108305, Val Acc: 0.814433\n",
      "Epoch 24764 - Train Loss: 0.072536, Train Acc: 0.892308 | Val Loss: 0.108305, Val Acc: 0.814433\n",
      "Epoch 24765 - Train Loss: 0.072535, Train Acc: 0.892308 | Val Loss: 0.108305, Val Acc: 0.814433\n",
      "Epoch 24766 - Train Loss: 0.072533, Train Acc: 0.892308 | Val Loss: 0.108304, Val Acc: 0.814433\n",
      "Epoch 24767 - Train Loss: 0.072532, Train Acc: 0.892308 | Val Loss: 0.108304, Val Acc: 0.814433\n",
      "Epoch 24768 - Train Loss: 0.072530, Train Acc: 0.892308 | Val Loss: 0.108304, Val Acc: 0.814433\n",
      "Epoch 24769 - Train Loss: 0.072529, Train Acc: 0.892308 | Val Loss: 0.108304, Val Acc: 0.814433\n",
      "Epoch 24770 - Train Loss: 0.072527, Train Acc: 0.892308 | Val Loss: 0.108303, Val Acc: 0.814433\n",
      "Epoch 24771 - Train Loss: 0.072526, Train Acc: 0.892308 | Val Loss: 0.108303, Val Acc: 0.814433\n",
      "Epoch 24772 - Train Loss: 0.072524, Train Acc: 0.892308 | Val Loss: 0.108303, Val Acc: 0.814433\n",
      "Epoch 24773 - Train Loss: 0.072523, Train Acc: 0.892308 | Val Loss: 0.108302, Val Acc: 0.814433\n",
      "Epoch 24774 - Train Loss: 0.072521, Train Acc: 0.892308 | Val Loss: 0.108302, Val Acc: 0.814433\n",
      "Epoch 24775 - Train Loss: 0.072520, Train Acc: 0.892308 | Val Loss: 0.108302, Val Acc: 0.814433\n",
      "Epoch 24776 - Train Loss: 0.072518, Train Acc: 0.892308 | Val Loss: 0.108302, Val Acc: 0.814433\n",
      "Epoch 24777 - Train Loss: 0.072517, Train Acc: 0.892308 | Val Loss: 0.108301, Val Acc: 0.814433\n",
      "Epoch 24778 - Train Loss: 0.072515, Train Acc: 0.892308 | Val Loss: 0.108301, Val Acc: 0.814433\n",
      "Epoch 24779 - Train Loss: 0.072514, Train Acc: 0.892308 | Val Loss: 0.108301, Val Acc: 0.814433\n",
      "Epoch 24780 - Train Loss: 0.072512, Train Acc: 0.892308 | Val Loss: 0.108301, Val Acc: 0.814433\n",
      "Epoch 24781 - Train Loss: 0.072511, Train Acc: 0.892308 | Val Loss: 0.108300, Val Acc: 0.814433\n",
      "Epoch 24782 - Train Loss: 0.072509, Train Acc: 0.892308 | Val Loss: 0.108300, Val Acc: 0.814433\n",
      "Epoch 24783 - Train Loss: 0.072508, Train Acc: 0.892308 | Val Loss: 0.108300, Val Acc: 0.814433\n",
      "Epoch 24784 - Train Loss: 0.072506, Train Acc: 0.892308 | Val Loss: 0.108300, Val Acc: 0.814433\n",
      "Epoch 24785 - Train Loss: 0.072505, Train Acc: 0.892308 | Val Loss: 0.108299, Val Acc: 0.814433\n",
      "Epoch 24786 - Train Loss: 0.072503, Train Acc: 0.892308 | Val Loss: 0.108299, Val Acc: 0.814433\n",
      "Epoch 24787 - Train Loss: 0.072502, Train Acc: 0.892308 | Val Loss: 0.108299, Val Acc: 0.814433\n",
      "Epoch 24788 - Train Loss: 0.072500, Train Acc: 0.892308 | Val Loss: 0.108299, Val Acc: 0.814433\n",
      "Epoch 24789 - Train Loss: 0.072499, Train Acc: 0.892308 | Val Loss: 0.108298, Val Acc: 0.814433\n",
      "Epoch 24790 - Train Loss: 0.072497, Train Acc: 0.892308 | Val Loss: 0.108298, Val Acc: 0.814433\n",
      "Epoch 24791 - Train Loss: 0.072496, Train Acc: 0.892308 | Val Loss: 0.108298, Val Acc: 0.814433\n",
      "Epoch 24792 - Train Loss: 0.072494, Train Acc: 0.892308 | Val Loss: 0.108298, Val Acc: 0.814433\n",
      "Epoch 24793 - Train Loss: 0.072493, Train Acc: 0.892308 | Val Loss: 0.108297, Val Acc: 0.814433\n",
      "Epoch 24794 - Train Loss: 0.072491, Train Acc: 0.892308 | Val Loss: 0.108297, Val Acc: 0.814433\n",
      "Epoch 24795 - Train Loss: 0.072490, Train Acc: 0.892308 | Val Loss: 0.108297, Val Acc: 0.814433\n",
      "Epoch 24796 - Train Loss: 0.072488, Train Acc: 0.892308 | Val Loss: 0.108297, Val Acc: 0.814433\n",
      "Epoch 24797 - Train Loss: 0.072486, Train Acc: 0.892308 | Val Loss: 0.108296, Val Acc: 0.814433\n",
      "Epoch 24798 - Train Loss: 0.072485, Train Acc: 0.892308 | Val Loss: 0.108296, Val Acc: 0.814433\n",
      "Epoch 24799 - Train Loss: 0.072483, Train Acc: 0.892308 | Val Loss: 0.108296, Val Acc: 0.814433\n",
      "Epoch 24800 - Train Loss: 0.072482, Train Acc: 0.892308 | Val Loss: 0.108296, Val Acc: 0.814433\n",
      "Epoch 24801 - Train Loss: 0.072480, Train Acc: 0.892308 | Val Loss: 0.108295, Val Acc: 0.814433\n",
      "Epoch 24802 - Train Loss: 0.072479, Train Acc: 0.892308 | Val Loss: 0.108295, Val Acc: 0.814433\n",
      "Epoch 24803 - Train Loss: 0.072477, Train Acc: 0.892308 | Val Loss: 0.108295, Val Acc: 0.814433\n",
      "Epoch 24804 - Train Loss: 0.072476, Train Acc: 0.892308 | Val Loss: 0.108295, Val Acc: 0.814433\n",
      "Epoch 24805 - Train Loss: 0.072474, Train Acc: 0.892308 | Val Loss: 0.108294, Val Acc: 0.814433\n",
      "Epoch 24806 - Train Loss: 0.072473, Train Acc: 0.892308 | Val Loss: 0.108294, Val Acc: 0.814433\n",
      "Epoch 24807 - Train Loss: 0.072471, Train Acc: 0.892308 | Val Loss: 0.108294, Val Acc: 0.814433\n",
      "Epoch 24808 - Train Loss: 0.072470, Train Acc: 0.892308 | Val Loss: 0.108293, Val Acc: 0.814433\n",
      "Epoch 24809 - Train Loss: 0.072468, Train Acc: 0.892308 | Val Loss: 0.108293, Val Acc: 0.814433\n",
      "Epoch 24810 - Train Loss: 0.072467, Train Acc: 0.892308 | Val Loss: 0.108293, Val Acc: 0.814433\n",
      "Epoch 24811 - Train Loss: 0.072465, Train Acc: 0.892308 | Val Loss: 0.108293, Val Acc: 0.814433\n",
      "Epoch 24812 - Train Loss: 0.072464, Train Acc: 0.892308 | Val Loss: 0.108292, Val Acc: 0.814433\n",
      "Epoch 24813 - Train Loss: 0.072462, Train Acc: 0.892308 | Val Loss: 0.108292, Val Acc: 0.814433\n",
      "Epoch 24814 - Train Loss: 0.072461, Train Acc: 0.892308 | Val Loss: 0.108292, Val Acc: 0.814433\n",
      "Epoch 24815 - Train Loss: 0.072459, Train Acc: 0.892308 | Val Loss: 0.108292, Val Acc: 0.814433\n",
      "Epoch 24816 - Train Loss: 0.072458, Train Acc: 0.892308 | Val Loss: 0.108292, Val Acc: 0.814433\n",
      "Epoch 24817 - Train Loss: 0.072456, Train Acc: 0.892308 | Val Loss: 0.108291, Val Acc: 0.814433\n",
      "Epoch 24818 - Train Loss: 0.072455, Train Acc: 0.892308 | Val Loss: 0.108291, Val Acc: 0.814433\n",
      "Epoch 24819 - Train Loss: 0.072453, Train Acc: 0.892308 | Val Loss: 0.108291, Val Acc: 0.814433\n",
      "Epoch 24820 - Train Loss: 0.072452, Train Acc: 0.892308 | Val Loss: 0.108290, Val Acc: 0.814433\n",
      "Epoch 24821 - Train Loss: 0.072450, Train Acc: 0.892308 | Val Loss: 0.108290, Val Acc: 0.814433\n",
      "Epoch 24822 - Train Loss: 0.072449, Train Acc: 0.892308 | Val Loss: 0.108290, Val Acc: 0.814433\n",
      "Epoch 24823 - Train Loss: 0.072447, Train Acc: 0.892308 | Val Loss: 0.108290, Val Acc: 0.814433\n",
      "Epoch 24824 - Train Loss: 0.072446, Train Acc: 0.892308 | Val Loss: 0.108289, Val Acc: 0.814433\n",
      "Epoch 24825 - Train Loss: 0.072444, Train Acc: 0.892308 | Val Loss: 0.108289, Val Acc: 0.814433\n",
      "Epoch 24826 - Train Loss: 0.072443, Train Acc: 0.892308 | Val Loss: 0.108289, Val Acc: 0.814433\n",
      "Epoch 24827 - Train Loss: 0.072441, Train Acc: 0.892308 | Val Loss: 0.108289, Val Acc: 0.814433\n",
      "Epoch 24828 - Train Loss: 0.072440, Train Acc: 0.892308 | Val Loss: 0.108288, Val Acc: 0.814433\n",
      "Epoch 24829 - Train Loss: 0.072438, Train Acc: 0.892308 | Val Loss: 0.108288, Val Acc: 0.814433\n",
      "Epoch 24830 - Train Loss: 0.072437, Train Acc: 0.892308 | Val Loss: 0.108288, Val Acc: 0.814433\n",
      "Epoch 24831 - Train Loss: 0.072435, Train Acc: 0.892308 | Val Loss: 0.108288, Val Acc: 0.814433\n",
      "Epoch 24832 - Train Loss: 0.072434, Train Acc: 0.892308 | Val Loss: 0.108287, Val Acc: 0.814433\n",
      "Epoch 24833 - Train Loss: 0.072432, Train Acc: 0.892308 | Val Loss: 0.108287, Val Acc: 0.814433\n",
      "Epoch 24834 - Train Loss: 0.072431, Train Acc: 0.892308 | Val Loss: 0.108287, Val Acc: 0.814433\n",
      "Epoch 24835 - Train Loss: 0.072429, Train Acc: 0.892308 | Val Loss: 0.108287, Val Acc: 0.814433\n",
      "Epoch 24836 - Train Loss: 0.072428, Train Acc: 0.892308 | Val Loss: 0.108286, Val Acc: 0.814433\n",
      "Epoch 24837 - Train Loss: 0.072426, Train Acc: 0.892308 | Val Loss: 0.108286, Val Acc: 0.814433\n",
      "Epoch 24838 - Train Loss: 0.072425, Train Acc: 0.892308 | Val Loss: 0.108286, Val Acc: 0.814433\n",
      "Epoch 24839 - Train Loss: 0.072423, Train Acc: 0.892308 | Val Loss: 0.108286, Val Acc: 0.814433\n",
      "Epoch 24840 - Train Loss: 0.072422, Train Acc: 0.892308 | Val Loss: 0.108285, Val Acc: 0.814433\n",
      "Epoch 24841 - Train Loss: 0.072420, Train Acc: 0.892308 | Val Loss: 0.108285, Val Acc: 0.814433\n",
      "Epoch 24842 - Train Loss: 0.072419, Train Acc: 0.892308 | Val Loss: 0.108285, Val Acc: 0.814433\n",
      "Epoch 24843 - Train Loss: 0.072417, Train Acc: 0.892308 | Val Loss: 0.108285, Val Acc: 0.814433\n",
      "Epoch 24844 - Train Loss: 0.072416, Train Acc: 0.892308 | Val Loss: 0.108284, Val Acc: 0.814433\n",
      "Epoch 24845 - Train Loss: 0.072414, Train Acc: 0.892308 | Val Loss: 0.108284, Val Acc: 0.814433\n",
      "Epoch 24846 - Train Loss: 0.072413, Train Acc: 0.892308 | Val Loss: 0.108284, Val Acc: 0.814433\n",
      "Epoch 24847 - Train Loss: 0.072411, Train Acc: 0.892308 | Val Loss: 0.108284, Val Acc: 0.814433\n",
      "Epoch 24848 - Train Loss: 0.072410, Train Acc: 0.892308 | Val Loss: 0.108283, Val Acc: 0.814433\n",
      "Epoch 24849 - Train Loss: 0.072408, Train Acc: 0.892308 | Val Loss: 0.108283, Val Acc: 0.814433\n",
      "Epoch 24850 - Train Loss: 0.072407, Train Acc: 0.892308 | Val Loss: 0.108283, Val Acc: 0.814433\n",
      "Epoch 24851 - Train Loss: 0.072405, Train Acc: 0.892308 | Val Loss: 0.108283, Val Acc: 0.814433\n",
      "Epoch 24852 - Train Loss: 0.072404, Train Acc: 0.892308 | Val Loss: 0.108282, Val Acc: 0.814433\n",
      "Epoch 24853 - Train Loss: 0.072402, Train Acc: 0.892308 | Val Loss: 0.108282, Val Acc: 0.814433\n",
      "Epoch 24854 - Train Loss: 0.072401, Train Acc: 0.892308 | Val Loss: 0.108282, Val Acc: 0.814433\n",
      "Epoch 24855 - Train Loss: 0.072399, Train Acc: 0.892308 | Val Loss: 0.108282, Val Acc: 0.814433\n",
      "Epoch 24856 - Train Loss: 0.072397, Train Acc: 0.892308 | Val Loss: 0.108281, Val Acc: 0.814433\n",
      "Epoch 24857 - Train Loss: 0.072396, Train Acc: 0.892308 | Val Loss: 0.108281, Val Acc: 0.814433\n",
      "Epoch 24858 - Train Loss: 0.072394, Train Acc: 0.892308 | Val Loss: 0.108281, Val Acc: 0.814433\n",
      "Epoch 24859 - Train Loss: 0.072393, Train Acc: 0.892308 | Val Loss: 0.108281, Val Acc: 0.814433\n",
      "Epoch 24860 - Train Loss: 0.072391, Train Acc: 0.892308 | Val Loss: 0.108280, Val Acc: 0.814433\n",
      "Epoch 24861 - Train Loss: 0.072390, Train Acc: 0.892308 | Val Loss: 0.108280, Val Acc: 0.814433\n",
      "Epoch 24862 - Train Loss: 0.072388, Train Acc: 0.892308 | Val Loss: 0.108280, Val Acc: 0.814433\n",
      "Epoch 24863 - Train Loss: 0.072387, Train Acc: 0.892308 | Val Loss: 0.108280, Val Acc: 0.814433\n",
      "Epoch 24864 - Train Loss: 0.072385, Train Acc: 0.892308 | Val Loss: 0.108279, Val Acc: 0.814433\n",
      "Epoch 24865 - Train Loss: 0.072384, Train Acc: 0.892308 | Val Loss: 0.108279, Val Acc: 0.814433\n",
      "Epoch 24866 - Train Loss: 0.072382, Train Acc: 0.892308 | Val Loss: 0.108279, Val Acc: 0.814433\n",
      "Epoch 24867 - Train Loss: 0.072381, Train Acc: 0.892308 | Val Loss: 0.108279, Val Acc: 0.814433\n",
      "Epoch 24868 - Train Loss: 0.072379, Train Acc: 0.892308 | Val Loss: 0.108278, Val Acc: 0.814433\n",
      "Epoch 24869 - Train Loss: 0.072378, Train Acc: 0.892308 | Val Loss: 0.108278, Val Acc: 0.814433\n",
      "Epoch 24870 - Train Loss: 0.072376, Train Acc: 0.892308 | Val Loss: 0.108278, Val Acc: 0.814433\n",
      "Epoch 24871 - Train Loss: 0.072375, Train Acc: 0.892308 | Val Loss: 0.108278, Val Acc: 0.814433\n",
      "Epoch 24872 - Train Loss: 0.072373, Train Acc: 0.892308 | Val Loss: 0.108277, Val Acc: 0.814433\n",
      "Epoch 24873 - Train Loss: 0.072372, Train Acc: 0.892308 | Val Loss: 0.108277, Val Acc: 0.814433\n",
      "Epoch 24874 - Train Loss: 0.072370, Train Acc: 0.892308 | Val Loss: 0.108277, Val Acc: 0.814433\n",
      "Epoch 24875 - Train Loss: 0.072369, Train Acc: 0.892308 | Val Loss: 0.108277, Val Acc: 0.814433\n",
      "Epoch 24876 - Train Loss: 0.072367, Train Acc: 0.892308 | Val Loss: 0.108276, Val Acc: 0.814433\n",
      "Epoch 24877 - Train Loss: 0.072366, Train Acc: 0.892308 | Val Loss: 0.108276, Val Acc: 0.814433\n",
      "Epoch 24878 - Train Loss: 0.072364, Train Acc: 0.892308 | Val Loss: 0.108276, Val Acc: 0.814433\n",
      "Epoch 24879 - Train Loss: 0.072363, Train Acc: 0.892308 | Val Loss: 0.108276, Val Acc: 0.814433\n",
      "Epoch 24880 - Train Loss: 0.072361, Train Acc: 0.892308 | Val Loss: 0.108275, Val Acc: 0.814433\n",
      "Epoch 24881 - Train Loss: 0.072360, Train Acc: 0.892308 | Val Loss: 0.108275, Val Acc: 0.814433\n",
      "Epoch 24882 - Train Loss: 0.072358, Train Acc: 0.892308 | Val Loss: 0.108275, Val Acc: 0.814433\n",
      "Epoch 24883 - Train Loss: 0.072357, Train Acc: 0.892308 | Val Loss: 0.108275, Val Acc: 0.814433\n",
      "Epoch 24884 - Train Loss: 0.072355, Train Acc: 0.892308 | Val Loss: 0.108274, Val Acc: 0.814433\n",
      "Epoch 24885 - Train Loss: 0.072354, Train Acc: 0.892308 | Val Loss: 0.108274, Val Acc: 0.814433\n",
      "Epoch 24886 - Train Loss: 0.072352, Train Acc: 0.892308 | Val Loss: 0.108274, Val Acc: 0.814433\n",
      "Epoch 24887 - Train Loss: 0.072351, Train Acc: 0.892308 | Val Loss: 0.108274, Val Acc: 0.814433\n",
      "Epoch 24888 - Train Loss: 0.072349, Train Acc: 0.892308 | Val Loss: 0.108273, Val Acc: 0.814433\n",
      "Epoch 24889 - Train Loss: 0.072348, Train Acc: 0.892308 | Val Loss: 0.108273, Val Acc: 0.814433\n",
      "Epoch 24890 - Train Loss: 0.072346, Train Acc: 0.892308 | Val Loss: 0.108273, Val Acc: 0.814433\n",
      "Epoch 24891 - Train Loss: 0.072345, Train Acc: 0.892308 | Val Loss: 0.108273, Val Acc: 0.814433\n",
      "Epoch 24892 - Train Loss: 0.072343, Train Acc: 0.892308 | Val Loss: 0.108272, Val Acc: 0.814433\n",
      "Epoch 24893 - Train Loss: 0.072342, Train Acc: 0.892308 | Val Loss: 0.108272, Val Acc: 0.814433\n",
      "Epoch 24894 - Train Loss: 0.072340, Train Acc: 0.892308 | Val Loss: 0.108272, Val Acc: 0.814433\n",
      "Epoch 24895 - Train Loss: 0.072339, Train Acc: 0.892308 | Val Loss: 0.108272, Val Acc: 0.814433\n",
      "Epoch 24896 - Train Loss: 0.072337, Train Acc: 0.892308 | Val Loss: 0.108271, Val Acc: 0.814433\n",
      "Epoch 24897 - Train Loss: 0.072336, Train Acc: 0.892308 | Val Loss: 0.108271, Val Acc: 0.814433\n",
      "Epoch 24898 - Train Loss: 0.072334, Train Acc: 0.892308 | Val Loss: 0.108271, Val Acc: 0.814433\n",
      "Epoch 24899 - Train Loss: 0.072333, Train Acc: 0.892308 | Val Loss: 0.108271, Val Acc: 0.814433\n",
      "Epoch 24900 - Train Loss: 0.072331, Train Acc: 0.892308 | Val Loss: 0.108270, Val Acc: 0.814433\n",
      "Epoch 24901 - Train Loss: 0.072330, Train Acc: 0.892308 | Val Loss: 0.108270, Val Acc: 0.814433\n",
      "Epoch 24902 - Train Loss: 0.072328, Train Acc: 0.892308 | Val Loss: 0.108270, Val Acc: 0.814433\n",
      "Epoch 24903 - Train Loss: 0.072327, Train Acc: 0.892308 | Val Loss: 0.108270, Val Acc: 0.814433\n",
      "Epoch 24904 - Train Loss: 0.072325, Train Acc: 0.892308 | Val Loss: 0.108269, Val Acc: 0.814433\n",
      "Epoch 24905 - Train Loss: 0.072324, Train Acc: 0.892308 | Val Loss: 0.108269, Val Acc: 0.814433\n",
      "Epoch 24906 - Train Loss: 0.072322, Train Acc: 0.892308 | Val Loss: 0.108269, Val Acc: 0.814433\n",
      "Epoch 24907 - Train Loss: 0.072321, Train Acc: 0.892308 | Val Loss: 0.108269, Val Acc: 0.814433\n",
      "Epoch 24908 - Train Loss: 0.072319, Train Acc: 0.892308 | Val Loss: 0.108269, Val Acc: 0.814433\n",
      "Epoch 24909 - Train Loss: 0.072318, Train Acc: 0.892308 | Val Loss: 0.108268, Val Acc: 0.814433\n",
      "Epoch 24910 - Train Loss: 0.072316, Train Acc: 0.892308 | Val Loss: 0.108268, Val Acc: 0.814433\n",
      "Epoch 24911 - Train Loss: 0.072315, Train Acc: 0.892308 | Val Loss: 0.108268, Val Acc: 0.814433\n",
      "Epoch 24912 - Train Loss: 0.072313, Train Acc: 0.892308 | Val Loss: 0.108268, Val Acc: 0.814433\n",
      "Epoch 24913 - Train Loss: 0.072312, Train Acc: 0.892308 | Val Loss: 0.108267, Val Acc: 0.814433\n",
      "Epoch 24914 - Train Loss: 0.072310, Train Acc: 0.892308 | Val Loss: 0.108267, Val Acc: 0.814433\n",
      "Epoch 24915 - Train Loss: 0.072309, Train Acc: 0.892308 | Val Loss: 0.108267, Val Acc: 0.814433\n",
      "Epoch 24916 - Train Loss: 0.072307, Train Acc: 0.892308 | Val Loss: 0.108267, Val Acc: 0.814433\n",
      "Epoch 24917 - Train Loss: 0.072306, Train Acc: 0.892308 | Val Loss: 0.108266, Val Acc: 0.814433\n",
      "Epoch 24918 - Train Loss: 0.072304, Train Acc: 0.892308 | Val Loss: 0.108266, Val Acc: 0.814433\n",
      "Epoch 24919 - Train Loss: 0.072303, Train Acc: 0.892308 | Val Loss: 0.108266, Val Acc: 0.814433\n",
      "Epoch 24920 - Train Loss: 0.072301, Train Acc: 0.892308 | Val Loss: 0.108266, Val Acc: 0.814433\n",
      "Epoch 24921 - Train Loss: 0.072300, Train Acc: 0.892308 | Val Loss: 0.108265, Val Acc: 0.814433\n",
      "Epoch 24922 - Train Loss: 0.072298, Train Acc: 0.892308 | Val Loss: 0.108265, Val Acc: 0.814433\n",
      "Epoch 24923 - Train Loss: 0.072297, Train Acc: 0.892308 | Val Loss: 0.108265, Val Acc: 0.814433\n",
      "Epoch 24924 - Train Loss: 0.072295, Train Acc: 0.892308 | Val Loss: 0.108265, Val Acc: 0.814433\n",
      "Epoch 24925 - Train Loss: 0.072294, Train Acc: 0.892308 | Val Loss: 0.108264, Val Acc: 0.814433\n",
      "Epoch 24926 - Train Loss: 0.072292, Train Acc: 0.892308 | Val Loss: 0.108264, Val Acc: 0.814433\n",
      "Epoch 24927 - Train Loss: 0.072291, Train Acc: 0.892308 | Val Loss: 0.108264, Val Acc: 0.814433\n",
      "Epoch 24928 - Train Loss: 0.072289, Train Acc: 0.892308 | Val Loss: 0.108264, Val Acc: 0.814433\n",
      "Epoch 24929 - Train Loss: 0.072288, Train Acc: 0.892308 | Val Loss: 0.108263, Val Acc: 0.814433\n",
      "Epoch 24930 - Train Loss: 0.072286, Train Acc: 0.892308 | Val Loss: 0.108263, Val Acc: 0.814433\n",
      "Epoch 24931 - Train Loss: 0.072285, Train Acc: 0.892308 | Val Loss: 0.108263, Val Acc: 0.814433\n",
      "Epoch 24932 - Train Loss: 0.072283, Train Acc: 0.892308 | Val Loss: 0.108263, Val Acc: 0.814433\n",
      "Epoch 24933 - Train Loss: 0.072282, Train Acc: 0.892308 | Val Loss: 0.108262, Val Acc: 0.814433\n",
      "Epoch 24934 - Train Loss: 0.072280, Train Acc: 0.892308 | Val Loss: 0.108262, Val Acc: 0.814433\n",
      "Epoch 24935 - Train Loss: 0.072279, Train Acc: 0.892308 | Val Loss: 0.108262, Val Acc: 0.814433\n",
      "Epoch 24936 - Train Loss: 0.072277, Train Acc: 0.892308 | Val Loss: 0.108262, Val Acc: 0.814433\n",
      "Epoch 24937 - Train Loss: 0.072276, Train Acc: 0.892308 | Val Loss: 0.108261, Val Acc: 0.814433\n",
      "Epoch 24938 - Train Loss: 0.072274, Train Acc: 0.892308 | Val Loss: 0.108261, Val Acc: 0.814433\n",
      "Epoch 24939 - Train Loss: 0.072273, Train Acc: 0.892308 | Val Loss: 0.108261, Val Acc: 0.814433\n",
      "Epoch 24940 - Train Loss: 0.072271, Train Acc: 0.892308 | Val Loss: 0.108261, Val Acc: 0.814433\n",
      "Epoch 24941 - Train Loss: 0.072270, Train Acc: 0.892308 | Val Loss: 0.108260, Val Acc: 0.814433\n",
      "Epoch 24942 - Train Loss: 0.072268, Train Acc: 0.892308 | Val Loss: 0.108260, Val Acc: 0.814433\n",
      "Epoch 24943 - Train Loss: 0.072267, Train Acc: 0.892308 | Val Loss: 0.108260, Val Acc: 0.814433\n",
      "Epoch 24944 - Train Loss: 0.072265, Train Acc: 0.892308 | Val Loss: 0.108260, Val Acc: 0.814433\n",
      "Epoch 24945 - Train Loss: 0.072264, Train Acc: 0.892308 | Val Loss: 0.108260, Val Acc: 0.814433\n",
      "Epoch 24946 - Train Loss: 0.072262, Train Acc: 0.892308 | Val Loss: 0.108259, Val Acc: 0.814433\n",
      "Epoch 24947 - Train Loss: 0.072261, Train Acc: 0.892308 | Val Loss: 0.108259, Val Acc: 0.814433\n",
      "Epoch 24948 - Train Loss: 0.072259, Train Acc: 0.892308 | Val Loss: 0.108259, Val Acc: 0.814433\n",
      "Epoch 24949 - Train Loss: 0.072258, Train Acc: 0.892308 | Val Loss: 0.108258, Val Acc: 0.814433\n",
      "Epoch 24950 - Train Loss: 0.072257, Train Acc: 0.892308 | Val Loss: 0.108258, Val Acc: 0.814433\n",
      "Epoch 24951 - Train Loss: 0.072255, Train Acc: 0.892308 | Val Loss: 0.108258, Val Acc: 0.814433\n",
      "Epoch 24952 - Train Loss: 0.072254, Train Acc: 0.892308 | Val Loss: 0.108258, Val Acc: 0.814433\n",
      "Epoch 24953 - Train Loss: 0.072252, Train Acc: 0.892308 | Val Loss: 0.108258, Val Acc: 0.814433\n",
      "Epoch 24954 - Train Loss: 0.072251, Train Acc: 0.892308 | Val Loss: 0.108257, Val Acc: 0.814433\n",
      "Epoch 24955 - Train Loss: 0.072249, Train Acc: 0.892308 | Val Loss: 0.108257, Val Acc: 0.814433\n",
      "Epoch 24956 - Train Loss: 0.072248, Train Acc: 0.892308 | Val Loss: 0.108257, Val Acc: 0.814433\n",
      "Epoch 24957 - Train Loss: 0.072246, Train Acc: 0.892308 | Val Loss: 0.108257, Val Acc: 0.814433\n",
      "Epoch 24958 - Train Loss: 0.072245, Train Acc: 0.892308 | Val Loss: 0.108256, Val Acc: 0.814433\n",
      "Epoch 24959 - Train Loss: 0.072243, Train Acc: 0.892308 | Val Loss: 0.108256, Val Acc: 0.814433\n",
      "Epoch 24960 - Train Loss: 0.072242, Train Acc: 0.892308 | Val Loss: 0.108256, Val Acc: 0.814433\n",
      "Epoch 24961 - Train Loss: 0.072240, Train Acc: 0.892308 | Val Loss: 0.108256, Val Acc: 0.814433\n",
      "Epoch 24962 - Train Loss: 0.072239, Train Acc: 0.892308 | Val Loss: 0.108255, Val Acc: 0.814433\n",
      "Epoch 24963 - Train Loss: 0.072237, Train Acc: 0.892308 | Val Loss: 0.108255, Val Acc: 0.814433\n",
      "Epoch 24964 - Train Loss: 0.072236, Train Acc: 0.892308 | Val Loss: 0.108255, Val Acc: 0.814433\n",
      "Epoch 24965 - Train Loss: 0.072234, Train Acc: 0.892308 | Val Loss: 0.108255, Val Acc: 0.814433\n",
      "Epoch 24966 - Train Loss: 0.072233, Train Acc: 0.892308 | Val Loss: 0.108254, Val Acc: 0.814433\n",
      "Epoch 24967 - Train Loss: 0.072231, Train Acc: 0.892308 | Val Loss: 0.108254, Val Acc: 0.814433\n",
      "Epoch 24968 - Train Loss: 0.072230, Train Acc: 0.892308 | Val Loss: 0.108254, Val Acc: 0.814433\n",
      "Epoch 24969 - Train Loss: 0.072228, Train Acc: 0.892308 | Val Loss: 0.108254, Val Acc: 0.814433\n",
      "Epoch 24970 - Train Loss: 0.072227, Train Acc: 0.892308 | Val Loss: 0.108254, Val Acc: 0.814433\n",
      "Epoch 24971 - Train Loss: 0.072225, Train Acc: 0.892308 | Val Loss: 0.108253, Val Acc: 0.814433\n",
      "Epoch 24972 - Train Loss: 0.072224, Train Acc: 0.892308 | Val Loss: 0.108253, Val Acc: 0.814433\n",
      "Epoch 24973 - Train Loss: 0.072222, Train Acc: 0.892308 | Val Loss: 0.108253, Val Acc: 0.814433\n",
      "Epoch 24974 - Train Loss: 0.072221, Train Acc: 0.892308 | Val Loss: 0.108253, Val Acc: 0.814433\n",
      "Epoch 24975 - Train Loss: 0.072219, Train Acc: 0.892308 | Val Loss: 0.108252, Val Acc: 0.814433\n",
      "Epoch 24976 - Train Loss: 0.072218, Train Acc: 0.892308 | Val Loss: 0.108252, Val Acc: 0.814433\n",
      "Epoch 24977 - Train Loss: 0.072216, Train Acc: 0.892308 | Val Loss: 0.108252, Val Acc: 0.814433\n",
      "Epoch 24978 - Train Loss: 0.072215, Train Acc: 0.892308 | Val Loss: 0.108252, Val Acc: 0.814433\n",
      "Epoch 24979 - Train Loss: 0.072213, Train Acc: 0.892308 | Val Loss: 0.108251, Val Acc: 0.814433\n",
      "Epoch 24980 - Train Loss: 0.072212, Train Acc: 0.892308 | Val Loss: 0.108251, Val Acc: 0.814433\n",
      "Epoch 24981 - Train Loss: 0.072210, Train Acc: 0.892308 | Val Loss: 0.108251, Val Acc: 0.814433\n",
      "Epoch 24982 - Train Loss: 0.072209, Train Acc: 0.892308 | Val Loss: 0.108251, Val Acc: 0.814433\n",
      "Epoch 24983 - Train Loss: 0.072207, Train Acc: 0.892308 | Val Loss: 0.108250, Val Acc: 0.814433\n",
      "Epoch 24984 - Train Loss: 0.072206, Train Acc: 0.892308 | Val Loss: 0.108250, Val Acc: 0.814433\n",
      "Epoch 24985 - Train Loss: 0.072204, Train Acc: 0.892308 | Val Loss: 0.108250, Val Acc: 0.814433\n",
      "Epoch 24986 - Train Loss: 0.072203, Train Acc: 0.892308 | Val Loss: 0.108250, Val Acc: 0.814433\n",
      "Epoch 24987 - Train Loss: 0.072201, Train Acc: 0.892308 | Val Loss: 0.108250, Val Acc: 0.814433\n",
      "Epoch 24988 - Train Loss: 0.072200, Train Acc: 0.892308 | Val Loss: 0.108249, Val Acc: 0.814433\n",
      "Epoch 24989 - Train Loss: 0.072198, Train Acc: 0.892308 | Val Loss: 0.108249, Val Acc: 0.814433\n",
      "Epoch 24990 - Train Loss: 0.072197, Train Acc: 0.892308 | Val Loss: 0.108249, Val Acc: 0.814433\n",
      "Epoch 24991 - Train Loss: 0.072195, Train Acc: 0.892308 | Val Loss: 0.108249, Val Acc: 0.814433\n",
      "Epoch 24992 - Train Loss: 0.072194, Train Acc: 0.892308 | Val Loss: 0.108248, Val Acc: 0.814433\n",
      "Epoch 24993 - Train Loss: 0.072192, Train Acc: 0.892308 | Val Loss: 0.108248, Val Acc: 0.814433\n",
      "Epoch 24994 - Train Loss: 0.072191, Train Acc: 0.892308 | Val Loss: 0.108248, Val Acc: 0.814433\n",
      "Epoch 24995 - Train Loss: 0.072189, Train Acc: 0.892308 | Val Loss: 0.108248, Val Acc: 0.814433\n",
      "Epoch 24996 - Train Loss: 0.072188, Train Acc: 0.892308 | Val Loss: 0.108247, Val Acc: 0.814433\n",
      "Epoch 24997 - Train Loss: 0.072186, Train Acc: 0.892308 | Val Loss: 0.108247, Val Acc: 0.814433\n",
      "Epoch 24998 - Train Loss: 0.072185, Train Acc: 0.892308 | Val Loss: 0.108247, Val Acc: 0.814433\n",
      "Epoch 24999 - Train Loss: 0.072183, Train Acc: 0.892308 | Val Loss: 0.108247, Val Acc: 0.814433\n",
      "Epoch 25000 - Train Loss: 0.072182, Train Acc: 0.892308 | Val Loss: 0.108246, Val Acc: 0.814433\n",
      "Epoch 25001 - Train Loss: 0.072180, Train Acc: 0.892308 | Val Loss: 0.108246, Val Acc: 0.814433\n",
      "Epoch 25002 - Train Loss: 0.072179, Train Acc: 0.892308 | Val Loss: 0.108246, Val Acc: 0.814433\n",
      "Epoch 25003 - Train Loss: 0.072177, Train Acc: 0.892308 | Val Loss: 0.108246, Val Acc: 0.814433\n",
      "Epoch 25004 - Train Loss: 0.072176, Train Acc: 0.892308 | Val Loss: 0.108245, Val Acc: 0.814433\n",
      "Epoch 25005 - Train Loss: 0.072174, Train Acc: 0.892308 | Val Loss: 0.108245, Val Acc: 0.814433\n",
      "Epoch 25006 - Train Loss: 0.072173, Train Acc: 0.892308 | Val Loss: 0.108245, Val Acc: 0.814433\n",
      "Epoch 25007 - Train Loss: 0.072171, Train Acc: 0.892308 | Val Loss: 0.108245, Val Acc: 0.814433\n",
      "Epoch 25008 - Train Loss: 0.072170, Train Acc: 0.892308 | Val Loss: 0.108245, Val Acc: 0.814433\n",
      "Epoch 25009 - Train Loss: 0.072169, Train Acc: 0.892308 | Val Loss: 0.108244, Val Acc: 0.814433\n",
      "Epoch 25010 - Train Loss: 0.072167, Train Acc: 0.892308 | Val Loss: 0.108244, Val Acc: 0.814433\n",
      "Epoch 25011 - Train Loss: 0.072166, Train Acc: 0.892308 | Val Loss: 0.108244, Val Acc: 0.814433\n",
      "Epoch 25012 - Train Loss: 0.072164, Train Acc: 0.892308 | Val Loss: 0.108244, Val Acc: 0.814433\n",
      "Epoch 25013 - Train Loss: 0.072163, Train Acc: 0.892308 | Val Loss: 0.108243, Val Acc: 0.814433\n",
      "Epoch 25014 - Train Loss: 0.072161, Train Acc: 0.892308 | Val Loss: 0.108243, Val Acc: 0.814433\n",
      "Epoch 25015 - Train Loss: 0.072160, Train Acc: 0.892308 | Val Loss: 0.108243, Val Acc: 0.814433\n",
      "Epoch 25016 - Train Loss: 0.072158, Train Acc: 0.892308 | Val Loss: 0.108243, Val Acc: 0.814433\n",
      "Epoch 25017 - Train Loss: 0.072157, Train Acc: 0.892308 | Val Loss: 0.108242, Val Acc: 0.814433\n",
      "Epoch 25018 - Train Loss: 0.072155, Train Acc: 0.892308 | Val Loss: 0.108242, Val Acc: 0.814433\n",
      "Epoch 25019 - Train Loss: 0.072154, Train Acc: 0.892308 | Val Loss: 0.108242, Val Acc: 0.814433\n",
      "Epoch 25020 - Train Loss: 0.072152, Train Acc: 0.892308 | Val Loss: 0.108242, Val Acc: 0.814433\n",
      "Epoch 25021 - Train Loss: 0.072151, Train Acc: 0.892308 | Val Loss: 0.108241, Val Acc: 0.814433\n",
      "Epoch 25022 - Train Loss: 0.072149, Train Acc: 0.892308 | Val Loss: 0.108241, Val Acc: 0.814433\n",
      "Epoch 25023 - Train Loss: 0.072148, Train Acc: 0.892308 | Val Loss: 0.108241, Val Acc: 0.814433\n",
      "Epoch 25024 - Train Loss: 0.072146, Train Acc: 0.892308 | Val Loss: 0.108241, Val Acc: 0.814433\n",
      "Epoch 25025 - Train Loss: 0.072145, Train Acc: 0.892308 | Val Loss: 0.108241, Val Acc: 0.814433\n",
      "Epoch 25026 - Train Loss: 0.072143, Train Acc: 0.892308 | Val Loss: 0.108240, Val Acc: 0.814433\n",
      "Epoch 25027 - Train Loss: 0.072142, Train Acc: 0.892308 | Val Loss: 0.108240, Val Acc: 0.814433\n",
      "Epoch 25028 - Train Loss: 0.072140, Train Acc: 0.892308 | Val Loss: 0.108240, Val Acc: 0.814433\n",
      "Epoch 25029 - Train Loss: 0.072139, Train Acc: 0.892308 | Val Loss: 0.108240, Val Acc: 0.814433\n",
      "Epoch 25030 - Train Loss: 0.072137, Train Acc: 0.892308 | Val Loss: 0.108239, Val Acc: 0.814433\n",
      "Epoch 25031 - Train Loss: 0.072136, Train Acc: 0.892308 | Val Loss: 0.108239, Val Acc: 0.814433\n",
      "Epoch 25032 - Train Loss: 0.072134, Train Acc: 0.892308 | Val Loss: 0.108239, Val Acc: 0.814433\n",
      "Epoch 25033 - Train Loss: 0.072133, Train Acc: 0.892308 | Val Loss: 0.108239, Val Acc: 0.814433\n",
      "Epoch 25034 - Train Loss: 0.072131, Train Acc: 0.892308 | Val Loss: 0.108238, Val Acc: 0.814433\n",
      "Epoch 25035 - Train Loss: 0.072130, Train Acc: 0.892308 | Val Loss: 0.108238, Val Acc: 0.814433\n",
      "Epoch 25036 - Train Loss: 0.072128, Train Acc: 0.892308 | Val Loss: 0.108238, Val Acc: 0.814433\n",
      "Epoch 25037 - Train Loss: 0.072127, Train Acc: 0.892308 | Val Loss: 0.108238, Val Acc: 0.814433\n",
      "Epoch 25038 - Train Loss: 0.072125, Train Acc: 0.892308 | Val Loss: 0.108237, Val Acc: 0.814433\n",
      "Epoch 25039 - Train Loss: 0.072124, Train Acc: 0.892308 | Val Loss: 0.108237, Val Acc: 0.814433\n",
      "Epoch 25040 - Train Loss: 0.072122, Train Acc: 0.892308 | Val Loss: 0.108237, Val Acc: 0.814433\n",
      "Epoch 25041 - Train Loss: 0.072121, Train Acc: 0.892308 | Val Loss: 0.108237, Val Acc: 0.814433\n",
      "Epoch 25042 - Train Loss: 0.072119, Train Acc: 0.892308 | Val Loss: 0.108237, Val Acc: 0.814433\n",
      "Epoch 25043 - Train Loss: 0.072118, Train Acc: 0.892308 | Val Loss: 0.108236, Val Acc: 0.814433\n",
      "Epoch 25044 - Train Loss: 0.072116, Train Acc: 0.892308 | Val Loss: 0.108236, Val Acc: 0.814433\n",
      "Epoch 25045 - Train Loss: 0.072115, Train Acc: 0.892308 | Val Loss: 0.108236, Val Acc: 0.814433\n",
      "Epoch 25046 - Train Loss: 0.072114, Train Acc: 0.892308 | Val Loss: 0.108236, Val Acc: 0.814433\n",
      "Epoch 25047 - Train Loss: 0.072112, Train Acc: 0.892308 | Val Loss: 0.108235, Val Acc: 0.814433\n",
      "Epoch 25048 - Train Loss: 0.072111, Train Acc: 0.892308 | Val Loss: 0.108235, Val Acc: 0.814433\n",
      "Epoch 25049 - Train Loss: 0.072109, Train Acc: 0.892308 | Val Loss: 0.108235, Val Acc: 0.814433\n",
      "Epoch 25050 - Train Loss: 0.072108, Train Acc: 0.892308 | Val Loss: 0.108235, Val Acc: 0.814433\n",
      "Epoch 25051 - Train Loss: 0.072106, Train Acc: 0.892308 | Val Loss: 0.108234, Val Acc: 0.814433\n",
      "Epoch 25052 - Train Loss: 0.072105, Train Acc: 0.892308 | Val Loss: 0.108234, Val Acc: 0.814433\n",
      "Epoch 25053 - Train Loss: 0.072103, Train Acc: 0.892308 | Val Loss: 0.108234, Val Acc: 0.814433\n",
      "Epoch 25054 - Train Loss: 0.072102, Train Acc: 0.892308 | Val Loss: 0.108234, Val Acc: 0.814433\n",
      "Epoch 25055 - Train Loss: 0.072100, Train Acc: 0.892308 | Val Loss: 0.108234, Val Acc: 0.814433\n",
      "Epoch 25056 - Train Loss: 0.072099, Train Acc: 0.892308 | Val Loss: 0.108233, Val Acc: 0.814433\n",
      "Epoch 25057 - Train Loss: 0.072097, Train Acc: 0.892308 | Val Loss: 0.108233, Val Acc: 0.814433\n",
      "Epoch 25058 - Train Loss: 0.072096, Train Acc: 0.892308 | Val Loss: 0.108233, Val Acc: 0.814433\n",
      "Epoch 25059 - Train Loss: 0.072094, Train Acc: 0.892308 | Val Loss: 0.108233, Val Acc: 0.814433\n",
      "Epoch 25060 - Train Loss: 0.072093, Train Acc: 0.892308 | Val Loss: 0.108232, Val Acc: 0.814433\n",
      "Epoch 25061 - Train Loss: 0.072091, Train Acc: 0.892308 | Val Loss: 0.108232, Val Acc: 0.814433\n",
      "Epoch 25062 - Train Loss: 0.072090, Train Acc: 0.892308 | Val Loss: 0.108232, Val Acc: 0.814433\n",
      "Epoch 25063 - Train Loss: 0.072088, Train Acc: 0.892308 | Val Loss: 0.108232, Val Acc: 0.814433\n",
      "Epoch 25064 - Train Loss: 0.072087, Train Acc: 0.892308 | Val Loss: 0.108231, Val Acc: 0.814433\n",
      "Epoch 25065 - Train Loss: 0.072085, Train Acc: 0.892308 | Val Loss: 0.108231, Val Acc: 0.814433\n",
      "Epoch 25066 - Train Loss: 0.072084, Train Acc: 0.892308 | Val Loss: 0.108231, Val Acc: 0.814433\n",
      "Epoch 25067 - Train Loss: 0.072082, Train Acc: 0.892308 | Val Loss: 0.108231, Val Acc: 0.814433\n",
      "Epoch 25068 - Train Loss: 0.072081, Train Acc: 0.892308 | Val Loss: 0.108231, Val Acc: 0.814433\n",
      "Epoch 25069 - Train Loss: 0.072079, Train Acc: 0.892308 | Val Loss: 0.108230, Val Acc: 0.814433\n",
      "Epoch 25070 - Train Loss: 0.072078, Train Acc: 0.892308 | Val Loss: 0.108230, Val Acc: 0.814433\n",
      "Epoch 25071 - Train Loss: 0.072076, Train Acc: 0.892308 | Val Loss: 0.108230, Val Acc: 0.814433\n",
      "Epoch 25072 - Train Loss: 0.072075, Train Acc: 0.892308 | Val Loss: 0.108230, Val Acc: 0.814433\n",
      "Epoch 25073 - Train Loss: 0.072073, Train Acc: 0.892308 | Val Loss: 0.108229, Val Acc: 0.814433\n",
      "Epoch 25074 - Train Loss: 0.072072, Train Acc: 0.892308 | Val Loss: 0.108229, Val Acc: 0.814433\n",
      "Epoch 25075 - Train Loss: 0.072071, Train Acc: 0.892308 | Val Loss: 0.108229, Val Acc: 0.814433\n",
      "Epoch 25076 - Train Loss: 0.072069, Train Acc: 0.892308 | Val Loss: 0.108229, Val Acc: 0.814433\n",
      "Epoch 25077 - Train Loss: 0.072068, Train Acc: 0.892308 | Val Loss: 0.108228, Val Acc: 0.814433\n",
      "Epoch 25078 - Train Loss: 0.072066, Train Acc: 0.892308 | Val Loss: 0.108228, Val Acc: 0.814433\n",
      "Epoch 25079 - Train Loss: 0.072065, Train Acc: 0.892308 | Val Loss: 0.108228, Val Acc: 0.814433\n",
      "Epoch 25080 - Train Loss: 0.072063, Train Acc: 0.892308 | Val Loss: 0.108228, Val Acc: 0.814433\n",
      "Epoch 25081 - Train Loss: 0.072062, Train Acc: 0.892308 | Val Loss: 0.108228, Val Acc: 0.814433\n",
      "Epoch 25082 - Train Loss: 0.072060, Train Acc: 0.892308 | Val Loss: 0.108227, Val Acc: 0.814433\n",
      "Epoch 25083 - Train Loss: 0.072059, Train Acc: 0.892308 | Val Loss: 0.108227, Val Acc: 0.814433\n",
      "Epoch 25084 - Train Loss: 0.072057, Train Acc: 0.892308 | Val Loss: 0.108227, Val Acc: 0.814433\n",
      "Epoch 25085 - Train Loss: 0.072056, Train Acc: 0.892308 | Val Loss: 0.108227, Val Acc: 0.814433\n",
      "Epoch 25086 - Train Loss: 0.072054, Train Acc: 0.892308 | Val Loss: 0.108226, Val Acc: 0.814433\n",
      "Epoch 25087 - Train Loss: 0.072053, Train Acc: 0.892308 | Val Loss: 0.108226, Val Acc: 0.814433\n",
      "Epoch 25088 - Train Loss: 0.072051, Train Acc: 0.892308 | Val Loss: 0.108226, Val Acc: 0.814433\n",
      "Epoch 25089 - Train Loss: 0.072050, Train Acc: 0.892308 | Val Loss: 0.108226, Val Acc: 0.814433\n",
      "Epoch 25090 - Train Loss: 0.072048, Train Acc: 0.892308 | Val Loss: 0.108226, Val Acc: 0.814433\n",
      "Epoch 25091 - Train Loss: 0.072047, Train Acc: 0.892308 | Val Loss: 0.108225, Val Acc: 0.814433\n",
      "Epoch 25092 - Train Loss: 0.072045, Train Acc: 0.892308 | Val Loss: 0.108225, Val Acc: 0.814433\n",
      "Epoch 25093 - Train Loss: 0.072044, Train Acc: 0.892308 | Val Loss: 0.108225, Val Acc: 0.814433\n",
      "Epoch 25094 - Train Loss: 0.072042, Train Acc: 0.892308 | Val Loss: 0.108225, Val Acc: 0.814433\n",
      "Epoch 25095 - Train Loss: 0.072041, Train Acc: 0.892308 | Val Loss: 0.108224, Val Acc: 0.814433\n",
      "Epoch 25096 - Train Loss: 0.072039, Train Acc: 0.892308 | Val Loss: 0.108224, Val Acc: 0.814433\n",
      "Epoch 25097 - Train Loss: 0.072038, Train Acc: 0.892308 | Val Loss: 0.108224, Val Acc: 0.814433\n",
      "Epoch 25098 - Train Loss: 0.072036, Train Acc: 0.892308 | Val Loss: 0.108224, Val Acc: 0.814433\n",
      "Epoch 25099 - Train Loss: 0.072035, Train Acc: 0.892308 | Val Loss: 0.108223, Val Acc: 0.814433\n",
      "Epoch 25100 - Train Loss: 0.072034, Train Acc: 0.892308 | Val Loss: 0.108223, Val Acc: 0.814433\n",
      "Epoch 25101 - Train Loss: 0.072032, Train Acc: 0.892308 | Val Loss: 0.108223, Val Acc: 0.814433\n",
      "Epoch 25102 - Train Loss: 0.072031, Train Acc: 0.892308 | Val Loss: 0.108223, Val Acc: 0.814433\n",
      "Epoch 25103 - Train Loss: 0.072029, Train Acc: 0.892308 | Val Loss: 0.108223, Val Acc: 0.814433\n",
      "Epoch 25104 - Train Loss: 0.072028, Train Acc: 0.892308 | Val Loss: 0.108222, Val Acc: 0.814433\n",
      "Epoch 25105 - Train Loss: 0.072026, Train Acc: 0.892308 | Val Loss: 0.108222, Val Acc: 0.814433\n",
      "Epoch 25106 - Train Loss: 0.072025, Train Acc: 0.892308 | Val Loss: 0.108222, Val Acc: 0.814433\n",
      "Epoch 25107 - Train Loss: 0.072023, Train Acc: 0.892308 | Val Loss: 0.108222, Val Acc: 0.814433\n",
      "Epoch 25108 - Train Loss: 0.072022, Train Acc: 0.892308 | Val Loss: 0.108221, Val Acc: 0.814433\n",
      "Epoch 25109 - Train Loss: 0.072020, Train Acc: 0.892308 | Val Loss: 0.108221, Val Acc: 0.814433\n",
      "Epoch 25110 - Train Loss: 0.072019, Train Acc: 0.892308 | Val Loss: 0.108221, Val Acc: 0.814433\n",
      "Epoch 25111 - Train Loss: 0.072017, Train Acc: 0.892308 | Val Loss: 0.108221, Val Acc: 0.814433\n",
      "Epoch 25112 - Train Loss: 0.072016, Train Acc: 0.892308 | Val Loss: 0.108220, Val Acc: 0.814433\n",
      "Epoch 25113 - Train Loss: 0.072014, Train Acc: 0.892308 | Val Loss: 0.108220, Val Acc: 0.814433\n",
      "Epoch 25114 - Train Loss: 0.072013, Train Acc: 0.892308 | Val Loss: 0.108220, Val Acc: 0.814433\n",
      "Epoch 25115 - Train Loss: 0.072011, Train Acc: 0.892308 | Val Loss: 0.108220, Val Acc: 0.814433\n",
      "Epoch 25116 - Train Loss: 0.072010, Train Acc: 0.892308 | Val Loss: 0.108220, Val Acc: 0.814433\n",
      "Epoch 25117 - Train Loss: 0.072008, Train Acc: 0.892308 | Val Loss: 0.108219, Val Acc: 0.814433\n",
      "Epoch 25118 - Train Loss: 0.072007, Train Acc: 0.892308 | Val Loss: 0.108219, Val Acc: 0.814433\n",
      "Epoch 25119 - Train Loss: 0.072005, Train Acc: 0.892308 | Val Loss: 0.108219, Val Acc: 0.814433\n",
      "Epoch 25120 - Train Loss: 0.072004, Train Acc: 0.892308 | Val Loss: 0.108219, Val Acc: 0.814433\n",
      "Epoch 25121 - Train Loss: 0.072002, Train Acc: 0.892308 | Val Loss: 0.108218, Val Acc: 0.814433\n",
      "Epoch 25122 - Train Loss: 0.072001, Train Acc: 0.892308 | Val Loss: 0.108218, Val Acc: 0.814433\n",
      "Epoch 25123 - Train Loss: 0.072000, Train Acc: 0.892308 | Val Loss: 0.108218, Val Acc: 0.814433\n",
      "Epoch 25124 - Train Loss: 0.071998, Train Acc: 0.892308 | Val Loss: 0.108218, Val Acc: 0.814433\n",
      "Epoch 25125 - Train Loss: 0.071997, Train Acc: 0.892308 | Val Loss: 0.108218, Val Acc: 0.814433\n",
      "Epoch 25126 - Train Loss: 0.071995, Train Acc: 0.892308 | Val Loss: 0.108217, Val Acc: 0.814433\n",
      "Epoch 25127 - Train Loss: 0.071994, Train Acc: 0.892308 | Val Loss: 0.108217, Val Acc: 0.814433\n",
      "Epoch 25128 - Train Loss: 0.071992, Train Acc: 0.892308 | Val Loss: 0.108217, Val Acc: 0.814433\n",
      "Epoch 25129 - Train Loss: 0.071991, Train Acc: 0.892308 | Val Loss: 0.108217, Val Acc: 0.814433\n",
      "Epoch 25130 - Train Loss: 0.071989, Train Acc: 0.892308 | Val Loss: 0.108216, Val Acc: 0.814433\n",
      "Epoch 25131 - Train Loss: 0.071988, Train Acc: 0.892308 | Val Loss: 0.108216, Val Acc: 0.814433\n",
      "Epoch 25132 - Train Loss: 0.071986, Train Acc: 0.892308 | Val Loss: 0.108216, Val Acc: 0.814433\n",
      "Epoch 25133 - Train Loss: 0.071985, Train Acc: 0.892308 | Val Loss: 0.108216, Val Acc: 0.814433\n",
      "Epoch 25134 - Train Loss: 0.071983, Train Acc: 0.892308 | Val Loss: 0.108216, Val Acc: 0.814433\n",
      "Epoch 25135 - Train Loss: 0.071982, Train Acc: 0.892308 | Val Loss: 0.108215, Val Acc: 0.814433\n",
      "Epoch 25136 - Train Loss: 0.071980, Train Acc: 0.892308 | Val Loss: 0.108215, Val Acc: 0.814433\n",
      "Epoch 25137 - Train Loss: 0.071979, Train Acc: 0.892308 | Val Loss: 0.108215, Val Acc: 0.814433\n",
      "Epoch 25138 - Train Loss: 0.071977, Train Acc: 0.892308 | Val Loss: 0.108215, Val Acc: 0.814433\n",
      "Epoch 25139 - Train Loss: 0.071976, Train Acc: 0.892308 | Val Loss: 0.108214, Val Acc: 0.814433\n",
      "Epoch 25140 - Train Loss: 0.071974, Train Acc: 0.892308 | Val Loss: 0.108214, Val Acc: 0.814433\n",
      "Epoch 25141 - Train Loss: 0.071973, Train Acc: 0.892308 | Val Loss: 0.108214, Val Acc: 0.814433\n",
      "Epoch 25142 - Train Loss: 0.071972, Train Acc: 0.892308 | Val Loss: 0.108214, Val Acc: 0.814433\n",
      "Epoch 25143 - Train Loss: 0.071970, Train Acc: 0.892308 | Val Loss: 0.108214, Val Acc: 0.814433\n",
      "Epoch 25144 - Train Loss: 0.071969, Train Acc: 0.892308 | Val Loss: 0.108213, Val Acc: 0.814433\n",
      "Epoch 25145 - Train Loss: 0.071967, Train Acc: 0.892308 | Val Loss: 0.108213, Val Acc: 0.814433\n",
      "Epoch 25146 - Train Loss: 0.071966, Train Acc: 0.892308 | Val Loss: 0.108213, Val Acc: 0.814433\n",
      "Epoch 25147 - Train Loss: 0.071964, Train Acc: 0.892308 | Val Loss: 0.108213, Val Acc: 0.814433\n",
      "Epoch 25148 - Train Loss: 0.071963, Train Acc: 0.892308 | Val Loss: 0.108212, Val Acc: 0.814433\n",
      "Epoch 25149 - Train Loss: 0.071961, Train Acc: 0.892308 | Val Loss: 0.108212, Val Acc: 0.814433\n",
      "Epoch 25150 - Train Loss: 0.071960, Train Acc: 0.892308 | Val Loss: 0.108212, Val Acc: 0.814433\n",
      "Epoch 25151 - Train Loss: 0.071958, Train Acc: 0.892308 | Val Loss: 0.108212, Val Acc: 0.814433\n",
      "Epoch 25152 - Train Loss: 0.071957, Train Acc: 0.892308 | Val Loss: 0.108212, Val Acc: 0.814433\n",
      "Epoch 25153 - Train Loss: 0.071955, Train Acc: 0.892308 | Val Loss: 0.108211, Val Acc: 0.814433\n",
      "Epoch 25154 - Train Loss: 0.071954, Train Acc: 0.892308 | Val Loss: 0.108211, Val Acc: 0.814433\n",
      "Epoch 25155 - Train Loss: 0.071952, Train Acc: 0.892308 | Val Loss: 0.108211, Val Acc: 0.814433\n",
      "Epoch 25156 - Train Loss: 0.071951, Train Acc: 0.892308 | Val Loss: 0.108211, Val Acc: 0.814433\n",
      "Epoch 25157 - Train Loss: 0.071949, Train Acc: 0.892308 | Val Loss: 0.108210, Val Acc: 0.814433\n",
      "Epoch 25158 - Train Loss: 0.071948, Train Acc: 0.892308 | Val Loss: 0.108210, Val Acc: 0.814433\n",
      "Epoch 25159 - Train Loss: 0.071946, Train Acc: 0.892308 | Val Loss: 0.108210, Val Acc: 0.814433\n",
      "Epoch 25160 - Train Loss: 0.071945, Train Acc: 0.892308 | Val Loss: 0.108210, Val Acc: 0.814433\n",
      "Epoch 25161 - Train Loss: 0.071944, Train Acc: 0.892308 | Val Loss: 0.108210, Val Acc: 0.814433\n",
      "Epoch 25162 - Train Loss: 0.071942, Train Acc: 0.892308 | Val Loss: 0.108209, Val Acc: 0.814433\n",
      "Epoch 25163 - Train Loss: 0.071941, Train Acc: 0.892308 | Val Loss: 0.108209, Val Acc: 0.814433\n",
      "Epoch 25164 - Train Loss: 0.071939, Train Acc: 0.892308 | Val Loss: 0.108209, Val Acc: 0.814433\n",
      "Epoch 25165 - Train Loss: 0.071938, Train Acc: 0.892308 | Val Loss: 0.108209, Val Acc: 0.814433\n",
      "Epoch 25166 - Train Loss: 0.071936, Train Acc: 0.892308 | Val Loss: 0.108208, Val Acc: 0.814433\n",
      "Epoch 25167 - Train Loss: 0.071935, Train Acc: 0.892308 | Val Loss: 0.108208, Val Acc: 0.814433\n",
      "Epoch 25168 - Train Loss: 0.071933, Train Acc: 0.892308 | Val Loss: 0.108208, Val Acc: 0.814433\n",
      "Epoch 25169 - Train Loss: 0.071932, Train Acc: 0.892308 | Val Loss: 0.108208, Val Acc: 0.814433\n",
      "Epoch 25170 - Train Loss: 0.071930, Train Acc: 0.892308 | Val Loss: 0.108208, Val Acc: 0.814433\n",
      "Epoch 25171 - Train Loss: 0.071929, Train Acc: 0.892308 | Val Loss: 0.108207, Val Acc: 0.814433\n",
      "Epoch 25172 - Train Loss: 0.071927, Train Acc: 0.892308 | Val Loss: 0.108207, Val Acc: 0.814433\n",
      "Epoch 25173 - Train Loss: 0.071926, Train Acc: 0.892308 | Val Loss: 0.108207, Val Acc: 0.814433\n",
      "Epoch 25174 - Train Loss: 0.071924, Train Acc: 0.892308 | Val Loss: 0.108207, Val Acc: 0.814433\n",
      "Epoch 25175 - Train Loss: 0.071923, Train Acc: 0.892308 | Val Loss: 0.108206, Val Acc: 0.814433\n",
      "Epoch 25176 - Train Loss: 0.071921, Train Acc: 0.892308 | Val Loss: 0.108206, Val Acc: 0.814433\n",
      "Epoch 25177 - Train Loss: 0.071920, Train Acc: 0.892308 | Val Loss: 0.108206, Val Acc: 0.814433\n",
      "Epoch 25178 - Train Loss: 0.071919, Train Acc: 0.892308 | Val Loss: 0.108206, Val Acc: 0.814433\n",
      "Epoch 25179 - Train Loss: 0.071917, Train Acc: 0.892308 | Val Loss: 0.108206, Val Acc: 0.814433\n",
      "Epoch 25180 - Train Loss: 0.071916, Train Acc: 0.892308 | Val Loss: 0.108205, Val Acc: 0.814433\n",
      "Epoch 25181 - Train Loss: 0.071914, Train Acc: 0.892308 | Val Loss: 0.108205, Val Acc: 0.814433\n",
      "Epoch 25182 - Train Loss: 0.071913, Train Acc: 0.892308 | Val Loss: 0.108205, Val Acc: 0.814433\n",
      "Epoch 25183 - Train Loss: 0.071911, Train Acc: 0.892308 | Val Loss: 0.108205, Val Acc: 0.814433\n",
      "Epoch 25184 - Train Loss: 0.071910, Train Acc: 0.892308 | Val Loss: 0.108204, Val Acc: 0.814433\n",
      "Epoch 25185 - Train Loss: 0.071908, Train Acc: 0.892308 | Val Loss: 0.108204, Val Acc: 0.814433\n",
      "Epoch 25186 - Train Loss: 0.071907, Train Acc: 0.892308 | Val Loss: 0.108204, Val Acc: 0.814433\n",
      "Epoch 25187 - Train Loss: 0.071905, Train Acc: 0.892308 | Val Loss: 0.108204, Val Acc: 0.814433\n",
      "Epoch 25188 - Train Loss: 0.071904, Train Acc: 0.892308 | Val Loss: 0.108204, Val Acc: 0.814433\n",
      "Epoch 25189 - Train Loss: 0.071902, Train Acc: 0.892308 | Val Loss: 0.108203, Val Acc: 0.814433\n",
      "Epoch 25190 - Train Loss: 0.071901, Train Acc: 0.892308 | Val Loss: 0.108203, Val Acc: 0.814433\n",
      "Epoch 25191 - Train Loss: 0.071899, Train Acc: 0.892308 | Val Loss: 0.108203, Val Acc: 0.814433\n",
      "Epoch 25192 - Train Loss: 0.071898, Train Acc: 0.892308 | Val Loss: 0.108203, Val Acc: 0.814433\n",
      "Epoch 25193 - Train Loss: 0.071896, Train Acc: 0.892308 | Val Loss: 0.108203, Val Acc: 0.814433\n",
      "Epoch 25194 - Train Loss: 0.071895, Train Acc: 0.892308 | Val Loss: 0.108202, Val Acc: 0.814433\n",
      "Epoch 25195 - Train Loss: 0.071894, Train Acc: 0.892308 | Val Loss: 0.108202, Val Acc: 0.814433\n",
      "Epoch 25196 - Train Loss: 0.071892, Train Acc: 0.892308 | Val Loss: 0.108202, Val Acc: 0.814433\n",
      "Epoch 25197 - Train Loss: 0.071891, Train Acc: 0.892308 | Val Loss: 0.108202, Val Acc: 0.814433\n",
      "Epoch 25198 - Train Loss: 0.071889, Train Acc: 0.892308 | Val Loss: 0.108201, Val Acc: 0.814433\n",
      "Epoch 25199 - Train Loss: 0.071888, Train Acc: 0.892308 | Val Loss: 0.108201, Val Acc: 0.814433\n",
      "Epoch 25200 - Train Loss: 0.071886, Train Acc: 0.892308 | Val Loss: 0.108201, Val Acc: 0.814433\n",
      "Epoch 25201 - Train Loss: 0.071885, Train Acc: 0.892308 | Val Loss: 0.108201, Val Acc: 0.814433\n",
      "Epoch 25202 - Train Loss: 0.071883, Train Acc: 0.892308 | Val Loss: 0.108201, Val Acc: 0.814433\n",
      "Epoch 25203 - Train Loss: 0.071882, Train Acc: 0.892308 | Val Loss: 0.108200, Val Acc: 0.814433\n",
      "Epoch 25204 - Train Loss: 0.071880, Train Acc: 0.892308 | Val Loss: 0.108200, Val Acc: 0.814433\n",
      "Epoch 25205 - Train Loss: 0.071879, Train Acc: 0.892308 | Val Loss: 0.108200, Val Acc: 0.814433\n",
      "Epoch 25206 - Train Loss: 0.071877, Train Acc: 0.892308 | Val Loss: 0.108200, Val Acc: 0.814433\n",
      "Epoch 25207 - Train Loss: 0.071876, Train Acc: 0.892308 | Val Loss: 0.108200, Val Acc: 0.814433\n",
      "Epoch 25208 - Train Loss: 0.071874, Train Acc: 0.892308 | Val Loss: 0.108199, Val Acc: 0.814433\n",
      "Epoch 25209 - Train Loss: 0.071873, Train Acc: 0.892308 | Val Loss: 0.108199, Val Acc: 0.814433\n",
      "Epoch 25210 - Train Loss: 0.071872, Train Acc: 0.892308 | Val Loss: 0.108199, Val Acc: 0.814433\n",
      "Epoch 25211 - Train Loss: 0.071870, Train Acc: 0.892308 | Val Loss: 0.108199, Val Acc: 0.814433\n",
      "Epoch 25212 - Train Loss: 0.071869, Train Acc: 0.892308 | Val Loss: 0.108198, Val Acc: 0.814433\n",
      "Epoch 25213 - Train Loss: 0.071867, Train Acc: 0.892308 | Val Loss: 0.108198, Val Acc: 0.814433\n",
      "Epoch 25214 - Train Loss: 0.071866, Train Acc: 0.892308 | Val Loss: 0.108198, Val Acc: 0.814433\n",
      "Epoch 25215 - Train Loss: 0.071864, Train Acc: 0.892308 | Val Loss: 0.108198, Val Acc: 0.814433\n",
      "Epoch 25216 - Train Loss: 0.071863, Train Acc: 0.892308 | Val Loss: 0.108198, Val Acc: 0.814433\n",
      "Epoch 25217 - Train Loss: 0.071861, Train Acc: 0.892308 | Val Loss: 0.108197, Val Acc: 0.814433\n",
      "Epoch 25218 - Train Loss: 0.071860, Train Acc: 0.892308 | Val Loss: 0.108197, Val Acc: 0.814433\n",
      "Epoch 25219 - Train Loss: 0.071858, Train Acc: 0.892308 | Val Loss: 0.108197, Val Acc: 0.814433\n",
      "Epoch 25220 - Train Loss: 0.071857, Train Acc: 0.892308 | Val Loss: 0.108197, Val Acc: 0.814433\n",
      "Epoch 25221 - Train Loss: 0.071855, Train Acc: 0.892308 | Val Loss: 0.108196, Val Acc: 0.814433\n",
      "Epoch 25222 - Train Loss: 0.071854, Train Acc: 0.892308 | Val Loss: 0.108196, Val Acc: 0.814433\n",
      "Epoch 25223 - Train Loss: 0.071852, Train Acc: 0.892308 | Val Loss: 0.108196, Val Acc: 0.814433\n",
      "Epoch 25224 - Train Loss: 0.071851, Train Acc: 0.892308 | Val Loss: 0.108196, Val Acc: 0.814433\n",
      "Epoch 25225 - Train Loss: 0.071850, Train Acc: 0.892308 | Val Loss: 0.108196, Val Acc: 0.814433\n",
      "Epoch 25226 - Train Loss: 0.071848, Train Acc: 0.892308 | Val Loss: 0.108195, Val Acc: 0.814433\n",
      "Epoch 25227 - Train Loss: 0.071847, Train Acc: 0.892308 | Val Loss: 0.108195, Val Acc: 0.814433\n",
      "Epoch 25228 - Train Loss: 0.071845, Train Acc: 0.892308 | Val Loss: 0.108195, Val Acc: 0.814433\n",
      "Epoch 25229 - Train Loss: 0.071844, Train Acc: 0.892308 | Val Loss: 0.108195, Val Acc: 0.814433\n",
      "Epoch 25230 - Train Loss: 0.071842, Train Acc: 0.892308 | Val Loss: 0.108194, Val Acc: 0.814433\n",
      "Epoch 25231 - Train Loss: 0.071841, Train Acc: 0.892308 | Val Loss: 0.108194, Val Acc: 0.814433\n",
      "Epoch 25232 - Train Loss: 0.071839, Train Acc: 0.892308 | Val Loss: 0.108194, Val Acc: 0.814433\n",
      "Epoch 25233 - Train Loss: 0.071838, Train Acc: 0.892308 | Val Loss: 0.108194, Val Acc: 0.814433\n",
      "Epoch 25234 - Train Loss: 0.071836, Train Acc: 0.892308 | Val Loss: 0.108194, Val Acc: 0.814433\n",
      "Epoch 25235 - Train Loss: 0.071835, Train Acc: 0.892308 | Val Loss: 0.108193, Val Acc: 0.814433\n",
      "Epoch 25236 - Train Loss: 0.071833, Train Acc: 0.892308 | Val Loss: 0.108193, Val Acc: 0.814433\n",
      "Epoch 25237 - Train Loss: 0.071832, Train Acc: 0.892308 | Val Loss: 0.108193, Val Acc: 0.814433\n",
      "Epoch 25238 - Train Loss: 0.071830, Train Acc: 0.892308 | Val Loss: 0.108193, Val Acc: 0.814433\n",
      "Epoch 25239 - Train Loss: 0.071829, Train Acc: 0.892308 | Val Loss: 0.108193, Val Acc: 0.814433\n",
      "Epoch 25240 - Train Loss: 0.071828, Train Acc: 0.892308 | Val Loss: 0.108192, Val Acc: 0.814433\n",
      "Epoch 25241 - Train Loss: 0.071826, Train Acc: 0.892308 | Val Loss: 0.108192, Val Acc: 0.814433\n",
      "Epoch 25242 - Train Loss: 0.071825, Train Acc: 0.892308 | Val Loss: 0.108192, Val Acc: 0.814433\n",
      "Epoch 25243 - Train Loss: 0.071823, Train Acc: 0.892308 | Val Loss: 0.108192, Val Acc: 0.814433\n",
      "Epoch 25244 - Train Loss: 0.071822, Train Acc: 0.892308 | Val Loss: 0.108191, Val Acc: 0.814433\n",
      "Epoch 25245 - Train Loss: 0.071820, Train Acc: 0.892308 | Val Loss: 0.108191, Val Acc: 0.814433\n",
      "Epoch 25246 - Train Loss: 0.071819, Train Acc: 0.892308 | Val Loss: 0.108191, Val Acc: 0.814433\n",
      "Epoch 25247 - Train Loss: 0.071817, Train Acc: 0.892308 | Val Loss: 0.108191, Val Acc: 0.814433\n",
      "Epoch 25248 - Train Loss: 0.071816, Train Acc: 0.892308 | Val Loss: 0.108191, Val Acc: 0.814433\n",
      "Epoch 25249 - Train Loss: 0.071814, Train Acc: 0.892308 | Val Loss: 0.108190, Val Acc: 0.814433\n",
      "Epoch 25250 - Train Loss: 0.071813, Train Acc: 0.892308 | Val Loss: 0.108190, Val Acc: 0.814433\n",
      "Epoch 25251 - Train Loss: 0.071811, Train Acc: 0.892308 | Val Loss: 0.108190, Val Acc: 0.814433\n",
      "Epoch 25252 - Train Loss: 0.071810, Train Acc: 0.892308 | Val Loss: 0.108190, Val Acc: 0.814433\n",
      "Epoch 25253 - Train Loss: 0.071809, Train Acc: 0.892308 | Val Loss: 0.108190, Val Acc: 0.814433\n",
      "Epoch 25254 - Train Loss: 0.071807, Train Acc: 0.892308 | Val Loss: 0.108189, Val Acc: 0.814433\n",
      "Epoch 25255 - Train Loss: 0.071806, Train Acc: 0.892308 | Val Loss: 0.108189, Val Acc: 0.814433\n",
      "Epoch 25256 - Train Loss: 0.071804, Train Acc: 0.892308 | Val Loss: 0.108189, Val Acc: 0.814433\n",
      "Epoch 25257 - Train Loss: 0.071803, Train Acc: 0.892308 | Val Loss: 0.108189, Val Acc: 0.814433\n",
      "Epoch 25258 - Train Loss: 0.071801, Train Acc: 0.892308 | Val Loss: 0.108189, Val Acc: 0.814433\n",
      "Epoch 25259 - Train Loss: 0.071800, Train Acc: 0.892308 | Val Loss: 0.108188, Val Acc: 0.814433\n",
      "Epoch 25260 - Train Loss: 0.071798, Train Acc: 0.892308 | Val Loss: 0.108188, Val Acc: 0.814433\n",
      "Epoch 25261 - Train Loss: 0.071797, Train Acc: 0.892308 | Val Loss: 0.108188, Val Acc: 0.814433\n",
      "Epoch 25262 - Train Loss: 0.071795, Train Acc: 0.892308 | Val Loss: 0.108188, Val Acc: 0.814433\n",
      "Epoch 25263 - Train Loss: 0.071794, Train Acc: 0.892308 | Val Loss: 0.108187, Val Acc: 0.814433\n",
      "Epoch 25264 - Train Loss: 0.071792, Train Acc: 0.892308 | Val Loss: 0.108187, Val Acc: 0.814433\n",
      "Epoch 25265 - Train Loss: 0.071791, Train Acc: 0.892308 | Val Loss: 0.108187, Val Acc: 0.814433\n",
      "Epoch 25266 - Train Loss: 0.071790, Train Acc: 0.892308 | Val Loss: 0.108187, Val Acc: 0.814433\n",
      "Epoch 25267 - Train Loss: 0.071788, Train Acc: 0.892308 | Val Loss: 0.108187, Val Acc: 0.814433\n",
      "Epoch 25268 - Train Loss: 0.071787, Train Acc: 0.892308 | Val Loss: 0.108186, Val Acc: 0.814433\n",
      "Epoch 25269 - Train Loss: 0.071785, Train Acc: 0.892308 | Val Loss: 0.108186, Val Acc: 0.814433\n",
      "Epoch 25270 - Train Loss: 0.071784, Train Acc: 0.892308 | Val Loss: 0.108186, Val Acc: 0.814433\n",
      "Epoch 25271 - Train Loss: 0.071782, Train Acc: 0.892308 | Val Loss: 0.108186, Val Acc: 0.814433\n",
      "Epoch 25272 - Train Loss: 0.071781, Train Acc: 0.892308 | Val Loss: 0.108186, Val Acc: 0.814433\n",
      "Epoch 25273 - Train Loss: 0.071779, Train Acc: 0.892308 | Val Loss: 0.108185, Val Acc: 0.814433\n",
      "Epoch 25274 - Train Loss: 0.071778, Train Acc: 0.892308 | Val Loss: 0.108185, Val Acc: 0.814433\n",
      "Epoch 25275 - Train Loss: 0.071776, Train Acc: 0.892308 | Val Loss: 0.108185, Val Acc: 0.814433\n",
      "Epoch 25276 - Train Loss: 0.071775, Train Acc: 0.892308 | Val Loss: 0.108185, Val Acc: 0.814433\n",
      "Epoch 25277 - Train Loss: 0.071773, Train Acc: 0.892308 | Val Loss: 0.108184, Val Acc: 0.814433\n",
      "Epoch 25278 - Train Loss: 0.071772, Train Acc: 0.892308 | Val Loss: 0.108184, Val Acc: 0.814433\n",
      "Epoch 25279 - Train Loss: 0.071771, Train Acc: 0.892308 | Val Loss: 0.108184, Val Acc: 0.814433\n",
      "Epoch 25280 - Train Loss: 0.071769, Train Acc: 0.892308 | Val Loss: 0.108184, Val Acc: 0.814433\n",
      "Epoch 25281 - Train Loss: 0.071768, Train Acc: 0.892308 | Val Loss: 0.108184, Val Acc: 0.814433\n",
      "Epoch 25282 - Train Loss: 0.071766, Train Acc: 0.892308 | Val Loss: 0.108183, Val Acc: 0.814433\n",
      "Epoch 25283 - Train Loss: 0.071765, Train Acc: 0.892308 | Val Loss: 0.108183, Val Acc: 0.814433\n",
      "Epoch 25284 - Train Loss: 0.071763, Train Acc: 0.892308 | Val Loss: 0.108183, Val Acc: 0.814433\n",
      "Epoch 25285 - Train Loss: 0.071762, Train Acc: 0.892308 | Val Loss: 0.108183, Val Acc: 0.814433\n",
      "Epoch 25286 - Train Loss: 0.071760, Train Acc: 0.892308 | Val Loss: 0.108183, Val Acc: 0.814433\n",
      "Epoch 25287 - Train Loss: 0.071759, Train Acc: 0.892308 | Val Loss: 0.108182, Val Acc: 0.814433\n",
      "Epoch 25288 - Train Loss: 0.071757, Train Acc: 0.892308 | Val Loss: 0.108182, Val Acc: 0.814433\n",
      "Epoch 25289 - Train Loss: 0.071756, Train Acc: 0.892308 | Val Loss: 0.108182, Val Acc: 0.814433\n",
      "Epoch 25290 - Train Loss: 0.071754, Train Acc: 0.892308 | Val Loss: 0.108182, Val Acc: 0.814433\n",
      "Epoch 25291 - Train Loss: 0.071753, Train Acc: 0.892308 | Val Loss: 0.108182, Val Acc: 0.814433\n",
      "Epoch 25292 - Train Loss: 0.071752, Train Acc: 0.892308 | Val Loss: 0.108181, Val Acc: 0.814433\n",
      "Epoch 25293 - Train Loss: 0.071750, Train Acc: 0.892308 | Val Loss: 0.108181, Val Acc: 0.814433\n",
      "Epoch 25294 - Train Loss: 0.071749, Train Acc: 0.892308 | Val Loss: 0.108181, Val Acc: 0.814433\n",
      "Epoch 25295 - Train Loss: 0.071747, Train Acc: 0.892308 | Val Loss: 0.108181, Val Acc: 0.814433\n",
      "Epoch 25296 - Train Loss: 0.071746, Train Acc: 0.892308 | Val Loss: 0.108180, Val Acc: 0.814433\n",
      "Epoch 25297 - Train Loss: 0.071744, Train Acc: 0.892308 | Val Loss: 0.108180, Val Acc: 0.814433\n",
      "Epoch 25298 - Train Loss: 0.071743, Train Acc: 0.892308 | Val Loss: 0.108180, Val Acc: 0.814433\n",
      "Epoch 25299 - Train Loss: 0.071741, Train Acc: 0.892308 | Val Loss: 0.108180, Val Acc: 0.814433\n",
      "Epoch 25300 - Train Loss: 0.071740, Train Acc: 0.892308 | Val Loss: 0.108180, Val Acc: 0.814433\n",
      "Epoch 25301 - Train Loss: 0.071738, Train Acc: 0.892308 | Val Loss: 0.108179, Val Acc: 0.814433\n",
      "Epoch 25302 - Train Loss: 0.071737, Train Acc: 0.892308 | Val Loss: 0.108179, Val Acc: 0.814433\n",
      "Epoch 25303 - Train Loss: 0.071736, Train Acc: 0.892308 | Val Loss: 0.108179, Val Acc: 0.814433\n",
      "Epoch 25304 - Train Loss: 0.071734, Train Acc: 0.892308 | Val Loss: 0.108179, Val Acc: 0.814433\n",
      "Epoch 25305 - Train Loss: 0.071733, Train Acc: 0.892308 | Val Loss: 0.108179, Val Acc: 0.814433\n",
      "Epoch 25306 - Train Loss: 0.071731, Train Acc: 0.892308 | Val Loss: 0.108178, Val Acc: 0.814433\n",
      "Epoch 25307 - Train Loss: 0.071730, Train Acc: 0.892308 | Val Loss: 0.108178, Val Acc: 0.814433\n",
      "Epoch 25308 - Train Loss: 0.071728, Train Acc: 0.892308 | Val Loss: 0.108178, Val Acc: 0.814433\n",
      "Epoch 25309 - Train Loss: 0.071727, Train Acc: 0.892308 | Val Loss: 0.108178, Val Acc: 0.814433\n",
      "Epoch 25310 - Train Loss: 0.071725, Train Acc: 0.892308 | Val Loss: 0.108178, Val Acc: 0.814433\n",
      "Epoch 25311 - Train Loss: 0.071724, Train Acc: 0.892308 | Val Loss: 0.108177, Val Acc: 0.814433\n",
      "Epoch 25312 - Train Loss: 0.071722, Train Acc: 0.892308 | Val Loss: 0.108177, Val Acc: 0.814433\n",
      "Epoch 25313 - Train Loss: 0.071721, Train Acc: 0.892308 | Val Loss: 0.108177, Val Acc: 0.814433\n",
      "Epoch 25314 - Train Loss: 0.071720, Train Acc: 0.892308 | Val Loss: 0.108177, Val Acc: 0.814433\n",
      "Epoch 25315 - Train Loss: 0.071718, Train Acc: 0.892308 | Val Loss: 0.108177, Val Acc: 0.814433\n",
      "Epoch 25316 - Train Loss: 0.071717, Train Acc: 0.892308 | Val Loss: 0.108176, Val Acc: 0.814433\n",
      "Epoch 25317 - Train Loss: 0.071715, Train Acc: 0.892308 | Val Loss: 0.108176, Val Acc: 0.814433\n",
      "Epoch 25318 - Train Loss: 0.071714, Train Acc: 0.892308 | Val Loss: 0.108176, Val Acc: 0.814433\n",
      "Epoch 25319 - Train Loss: 0.071712, Train Acc: 0.892308 | Val Loss: 0.108176, Val Acc: 0.814433\n",
      "Epoch 25320 - Train Loss: 0.071711, Train Acc: 0.892308 | Val Loss: 0.108176, Val Acc: 0.814433\n",
      "Epoch 25321 - Train Loss: 0.071709, Train Acc: 0.892308 | Val Loss: 0.108175, Val Acc: 0.814433\n",
      "Epoch 25322 - Train Loss: 0.071708, Train Acc: 0.892308 | Val Loss: 0.108175, Val Acc: 0.814433\n",
      "Epoch 25323 - Train Loss: 0.071706, Train Acc: 0.892308 | Val Loss: 0.108175, Val Acc: 0.814433\n",
      "Epoch 25324 - Train Loss: 0.071705, Train Acc: 0.892308 | Val Loss: 0.108175, Val Acc: 0.814433\n",
      "Epoch 25325 - Train Loss: 0.071703, Train Acc: 0.892308 | Val Loss: 0.108175, Val Acc: 0.814433\n",
      "Epoch 25326 - Train Loss: 0.071702, Train Acc: 0.892308 | Val Loss: 0.108174, Val Acc: 0.814433\n",
      "Epoch 25327 - Train Loss: 0.071701, Train Acc: 0.892308 | Val Loss: 0.108174, Val Acc: 0.814433\n",
      "Epoch 25328 - Train Loss: 0.071699, Train Acc: 0.892308 | Val Loss: 0.108174, Val Acc: 0.814433\n",
      "Epoch 25329 - Train Loss: 0.071698, Train Acc: 0.892308 | Val Loss: 0.108174, Val Acc: 0.814433\n",
      "Epoch 25330 - Train Loss: 0.071696, Train Acc: 0.892308 | Val Loss: 0.108173, Val Acc: 0.814433\n",
      "Epoch 25331 - Train Loss: 0.071695, Train Acc: 0.892308 | Val Loss: 0.108173, Val Acc: 0.814433\n",
      "Epoch 25332 - Train Loss: 0.071693, Train Acc: 0.892308 | Val Loss: 0.108173, Val Acc: 0.814433\n",
      "Epoch 25333 - Train Loss: 0.071692, Train Acc: 0.892308 | Val Loss: 0.108173, Val Acc: 0.814433\n",
      "Epoch 25334 - Train Loss: 0.071690, Train Acc: 0.892308 | Val Loss: 0.108173, Val Acc: 0.814433\n",
      "Epoch 25335 - Train Loss: 0.071689, Train Acc: 0.892308 | Val Loss: 0.108172, Val Acc: 0.814433\n",
      "Epoch 25336 - Train Loss: 0.071687, Train Acc: 0.892308 | Val Loss: 0.108172, Val Acc: 0.814433\n",
      "Epoch 25337 - Train Loss: 0.071686, Train Acc: 0.892308 | Val Loss: 0.108172, Val Acc: 0.814433\n",
      "Epoch 25338 - Train Loss: 0.071685, Train Acc: 0.892308 | Val Loss: 0.108172, Val Acc: 0.814433\n",
      "Epoch 25339 - Train Loss: 0.071683, Train Acc: 0.892308 | Val Loss: 0.108172, Val Acc: 0.814433\n",
      "Epoch 25340 - Train Loss: 0.071682, Train Acc: 0.892308 | Val Loss: 0.108171, Val Acc: 0.814433\n",
      "Epoch 25341 - Train Loss: 0.071680, Train Acc: 0.892308 | Val Loss: 0.108171, Val Acc: 0.814433\n",
      "Epoch 25342 - Train Loss: 0.071679, Train Acc: 0.892308 | Val Loss: 0.108171, Val Acc: 0.814433\n",
      "Epoch 25343 - Train Loss: 0.071677, Train Acc: 0.892308 | Val Loss: 0.108171, Val Acc: 0.814433\n",
      "Epoch 25344 - Train Loss: 0.071676, Train Acc: 0.892308 | Val Loss: 0.108171, Val Acc: 0.814433\n",
      "Epoch 25345 - Train Loss: 0.071674, Train Acc: 0.892308 | Val Loss: 0.108170, Val Acc: 0.814433\n",
      "Epoch 25346 - Train Loss: 0.071673, Train Acc: 0.892308 | Val Loss: 0.108170, Val Acc: 0.814433\n",
      "Epoch 25347 - Train Loss: 0.071671, Train Acc: 0.892308 | Val Loss: 0.108170, Val Acc: 0.814433\n",
      "Epoch 25348 - Train Loss: 0.071670, Train Acc: 0.892308 | Val Loss: 0.108170, Val Acc: 0.814433\n",
      "Epoch 25349 - Train Loss: 0.071669, Train Acc: 0.892308 | Val Loss: 0.108170, Val Acc: 0.814433\n",
      "Epoch 25350 - Train Loss: 0.071667, Train Acc: 0.892308 | Val Loss: 0.108169, Val Acc: 0.814433\n",
      "Epoch 25351 - Train Loss: 0.071666, Train Acc: 0.892308 | Val Loss: 0.108169, Val Acc: 0.814433\n",
      "Epoch 25352 - Train Loss: 0.071664, Train Acc: 0.892308 | Val Loss: 0.108169, Val Acc: 0.814433\n",
      "Epoch 25353 - Train Loss: 0.071663, Train Acc: 0.892308 | Val Loss: 0.108169, Val Acc: 0.814433\n",
      "Epoch 25354 - Train Loss: 0.071661, Train Acc: 0.892308 | Val Loss: 0.108169, Val Acc: 0.814433\n",
      "Epoch 25355 - Train Loss: 0.071660, Train Acc: 0.892308 | Val Loss: 0.108168, Val Acc: 0.814433\n",
      "Epoch 25356 - Train Loss: 0.071658, Train Acc: 0.892308 | Val Loss: 0.108168, Val Acc: 0.814433\n",
      "Epoch 25357 - Train Loss: 0.071657, Train Acc: 0.892308 | Val Loss: 0.108168, Val Acc: 0.814433\n",
      "Epoch 25358 - Train Loss: 0.071655, Train Acc: 0.892308 | Val Loss: 0.108168, Val Acc: 0.814433\n",
      "Epoch 25359 - Train Loss: 0.071654, Train Acc: 0.892308 | Val Loss: 0.108168, Val Acc: 0.814433\n",
      "Epoch 25360 - Train Loss: 0.071653, Train Acc: 0.892308 | Val Loss: 0.108168, Val Acc: 0.814433\n",
      "Epoch 25361 - Train Loss: 0.071651, Train Acc: 0.892308 | Val Loss: 0.108167, Val Acc: 0.814433\n",
      "Epoch 25362 - Train Loss: 0.071650, Train Acc: 0.892308 | Val Loss: 0.108167, Val Acc: 0.814433\n",
      "Epoch 25363 - Train Loss: 0.071648, Train Acc: 0.892308 | Val Loss: 0.108167, Val Acc: 0.814433\n",
      "Epoch 25364 - Train Loss: 0.071647, Train Acc: 0.892308 | Val Loss: 0.108167, Val Acc: 0.814433\n",
      "Epoch 25365 - Train Loss: 0.071645, Train Acc: 0.892308 | Val Loss: 0.108167, Val Acc: 0.814433\n",
      "Epoch 25366 - Train Loss: 0.071644, Train Acc: 0.892308 | Val Loss: 0.108166, Val Acc: 0.814433\n",
      "Epoch 25367 - Train Loss: 0.071642, Train Acc: 0.892308 | Val Loss: 0.108166, Val Acc: 0.814433\n",
      "Epoch 25368 - Train Loss: 0.071641, Train Acc: 0.892308 | Val Loss: 0.108166, Val Acc: 0.814433\n",
      "Epoch 25369 - Train Loss: 0.071640, Train Acc: 0.892308 | Val Loss: 0.108166, Val Acc: 0.814433\n",
      "Epoch 25370 - Train Loss: 0.071638, Train Acc: 0.892308 | Val Loss: 0.108166, Val Acc: 0.814433\n",
      "Epoch 25371 - Train Loss: 0.071637, Train Acc: 0.892308 | Val Loss: 0.108165, Val Acc: 0.814433\n",
      "Epoch 25372 - Train Loss: 0.071635, Train Acc: 0.892308 | Val Loss: 0.108165, Val Acc: 0.814433\n",
      "Epoch 25373 - Train Loss: 0.071634, Train Acc: 0.892308 | Val Loss: 0.108165, Val Acc: 0.814433\n",
      "Epoch 25374 - Train Loss: 0.071632, Train Acc: 0.892308 | Val Loss: 0.108165, Val Acc: 0.814433\n",
      "Epoch 25375 - Train Loss: 0.071631, Train Acc: 0.892308 | Val Loss: 0.108165, Val Acc: 0.814433\n",
      "Epoch 25376 - Train Loss: 0.071629, Train Acc: 0.892308 | Val Loss: 0.108164, Val Acc: 0.814433\n",
      "Epoch 25377 - Train Loss: 0.071628, Train Acc: 0.892308 | Val Loss: 0.108164, Val Acc: 0.814433\n",
      "Epoch 25378 - Train Loss: 0.071626, Train Acc: 0.892308 | Val Loss: 0.108164, Val Acc: 0.814433\n",
      "Epoch 25379 - Train Loss: 0.071625, Train Acc: 0.892308 | Val Loss: 0.108164, Val Acc: 0.814433\n",
      "Epoch 25380 - Train Loss: 0.071624, Train Acc: 0.892308 | Val Loss: 0.108164, Val Acc: 0.814433\n",
      "Epoch 25381 - Train Loss: 0.071622, Train Acc: 0.892308 | Val Loss: 0.108163, Val Acc: 0.814433\n",
      "Epoch 25382 - Train Loss: 0.071621, Train Acc: 0.892308 | Val Loss: 0.108163, Val Acc: 0.814433\n",
      "Epoch 25383 - Train Loss: 0.071619, Train Acc: 0.892308 | Val Loss: 0.108163, Val Acc: 0.814433\n",
      "Epoch 25384 - Train Loss: 0.071618, Train Acc: 0.892308 | Val Loss: 0.108163, Val Acc: 0.814433\n",
      "Epoch 25385 - Train Loss: 0.071616, Train Acc: 0.892308 | Val Loss: 0.108163, Val Acc: 0.814433\n",
      "Epoch 25386 - Train Loss: 0.071615, Train Acc: 0.892308 | Val Loss: 0.108162, Val Acc: 0.814433\n",
      "Epoch 25387 - Train Loss: 0.071613, Train Acc: 0.892308 | Val Loss: 0.108162, Val Acc: 0.814433\n",
      "Epoch 25388 - Train Loss: 0.071612, Train Acc: 0.892308 | Val Loss: 0.108162, Val Acc: 0.814433\n",
      "Epoch 25389 - Train Loss: 0.071611, Train Acc: 0.892308 | Val Loss: 0.108162, Val Acc: 0.814433\n",
      "Epoch 25390 - Train Loss: 0.071609, Train Acc: 0.892308 | Val Loss: 0.108162, Val Acc: 0.814433\n",
      "Epoch 25391 - Train Loss: 0.071608, Train Acc: 0.892308 | Val Loss: 0.108161, Val Acc: 0.814433\n",
      "Epoch 25392 - Train Loss: 0.071606, Train Acc: 0.892308 | Val Loss: 0.108161, Val Acc: 0.814433\n",
      "Epoch 25393 - Train Loss: 0.071605, Train Acc: 0.892308 | Val Loss: 0.108161, Val Acc: 0.814433\n",
      "Epoch 25394 - Train Loss: 0.071603, Train Acc: 0.892308 | Val Loss: 0.108161, Val Acc: 0.814433\n",
      "Epoch 25395 - Train Loss: 0.071602, Train Acc: 0.892308 | Val Loss: 0.108161, Val Acc: 0.814433\n",
      "Epoch 25396 - Train Loss: 0.071600, Train Acc: 0.892308 | Val Loss: 0.108161, Val Acc: 0.814433\n",
      "Epoch 25397 - Train Loss: 0.071599, Train Acc: 0.892308 | Val Loss: 0.108160, Val Acc: 0.814433\n",
      "Epoch 25398 - Train Loss: 0.071597, Train Acc: 0.892308 | Val Loss: 0.108160, Val Acc: 0.814433\n",
      "Epoch 25399 - Train Loss: 0.071596, Train Acc: 0.892308 | Val Loss: 0.108160, Val Acc: 0.814433\n",
      "Epoch 25400 - Train Loss: 0.071595, Train Acc: 0.892308 | Val Loss: 0.108160, Val Acc: 0.814433\n",
      "Epoch 25401 - Train Loss: 0.071593, Train Acc: 0.892308 | Val Loss: 0.108160, Val Acc: 0.814433\n",
      "Epoch 25402 - Train Loss: 0.071592, Train Acc: 0.892308 | Val Loss: 0.108159, Val Acc: 0.814433\n",
      "Epoch 25403 - Train Loss: 0.071590, Train Acc: 0.892308 | Val Loss: 0.108159, Val Acc: 0.814433\n",
      "Epoch 25404 - Train Loss: 0.071589, Train Acc: 0.892308 | Val Loss: 0.108159, Val Acc: 0.814433\n",
      "Epoch 25405 - Train Loss: 0.071587, Train Acc: 0.892308 | Val Loss: 0.108159, Val Acc: 0.814433\n",
      "Epoch 25406 - Train Loss: 0.071586, Train Acc: 0.892308 | Val Loss: 0.108159, Val Acc: 0.814433\n",
      "Epoch 25407 - Train Loss: 0.071584, Train Acc: 0.892308 | Val Loss: 0.108158, Val Acc: 0.814433\n",
      "Epoch 25408 - Train Loss: 0.071583, Train Acc: 0.892308 | Val Loss: 0.108158, Val Acc: 0.814433\n",
      "Epoch 25409 - Train Loss: 0.071582, Train Acc: 0.892308 | Val Loss: 0.108158, Val Acc: 0.814433\n",
      "Epoch 25410 - Train Loss: 0.071580, Train Acc: 0.892308 | Val Loss: 0.108158, Val Acc: 0.814433\n",
      "Epoch 25411 - Train Loss: 0.071579, Train Acc: 0.892308 | Val Loss: 0.108158, Val Acc: 0.814433\n",
      "Epoch 25412 - Train Loss: 0.071577, Train Acc: 0.892308 | Val Loss: 0.108157, Val Acc: 0.814433\n",
      "Epoch 25413 - Train Loss: 0.071576, Train Acc: 0.892308 | Val Loss: 0.108157, Val Acc: 0.814433\n",
      "Epoch 25414 - Train Loss: 0.071574, Train Acc: 0.892308 | Val Loss: 0.108157, Val Acc: 0.814433\n",
      "Epoch 25415 - Train Loss: 0.071573, Train Acc: 0.892308 | Val Loss: 0.108157, Val Acc: 0.814433\n",
      "Epoch 25416 - Train Loss: 0.071571, Train Acc: 0.892308 | Val Loss: 0.108157, Val Acc: 0.814433\n",
      "Epoch 25417 - Train Loss: 0.071570, Train Acc: 0.892308 | Val Loss: 0.108156, Val Acc: 0.814433\n",
      "Epoch 25418 - Train Loss: 0.071569, Train Acc: 0.892308 | Val Loss: 0.108156, Val Acc: 0.814433\n",
      "Epoch 25419 - Train Loss: 0.071567, Train Acc: 0.892308 | Val Loss: 0.108156, Val Acc: 0.814433\n",
      "Epoch 25420 - Train Loss: 0.071566, Train Acc: 0.892308 | Val Loss: 0.108156, Val Acc: 0.814433\n",
      "Epoch 25421 - Train Loss: 0.071564, Train Acc: 0.892308 | Val Loss: 0.108156, Val Acc: 0.814433\n",
      "Epoch 25422 - Train Loss: 0.071563, Train Acc: 0.892308 | Val Loss: 0.108155, Val Acc: 0.814433\n",
      "Epoch 25423 - Train Loss: 0.071561, Train Acc: 0.892308 | Val Loss: 0.108155, Val Acc: 0.814433\n",
      "Epoch 25424 - Train Loss: 0.071560, Train Acc: 0.892308 | Val Loss: 0.108155, Val Acc: 0.814433\n",
      "Epoch 25425 - Train Loss: 0.071558, Train Acc: 0.892308 | Val Loss: 0.108155, Val Acc: 0.814433\n",
      "Epoch 25426 - Train Loss: 0.071557, Train Acc: 0.892308 | Val Loss: 0.108155, Val Acc: 0.814433\n",
      "Epoch 25427 - Train Loss: 0.071556, Train Acc: 0.892308 | Val Loss: 0.108154, Val Acc: 0.814433\n",
      "Epoch 25428 - Train Loss: 0.071554, Train Acc: 0.892308 | Val Loss: 0.108154, Val Acc: 0.814433\n",
      "Epoch 25429 - Train Loss: 0.071553, Train Acc: 0.892308 | Val Loss: 0.108154, Val Acc: 0.814433\n",
      "Epoch 25430 - Train Loss: 0.071551, Train Acc: 0.892308 | Val Loss: 0.108154, Val Acc: 0.814433\n",
      "Epoch 25431 - Train Loss: 0.071550, Train Acc: 0.892308 | Val Loss: 0.108154, Val Acc: 0.814433\n",
      "Epoch 25432 - Train Loss: 0.071548, Train Acc: 0.892308 | Val Loss: 0.108153, Val Acc: 0.814433\n",
      "Epoch 25433 - Train Loss: 0.071547, Train Acc: 0.892308 | Val Loss: 0.108153, Val Acc: 0.814433\n",
      "Epoch 25434 - Train Loss: 0.071545, Train Acc: 0.892308 | Val Loss: 0.108153, Val Acc: 0.814433\n",
      "Epoch 25435 - Train Loss: 0.071544, Train Acc: 0.892308 | Val Loss: 0.108153, Val Acc: 0.814433\n",
      "Epoch 25436 - Train Loss: 0.071543, Train Acc: 0.892308 | Val Loss: 0.108153, Val Acc: 0.814433\n",
      "Epoch 25437 - Train Loss: 0.071541, Train Acc: 0.892308 | Val Loss: 0.108152, Val Acc: 0.814433\n",
      "Epoch 25438 - Train Loss: 0.071540, Train Acc: 0.892308 | Val Loss: 0.108152, Val Acc: 0.814433\n",
      "Epoch 25439 - Train Loss: 0.071538, Train Acc: 0.892308 | Val Loss: 0.108152, Val Acc: 0.814433\n",
      "Epoch 25440 - Train Loss: 0.071537, Train Acc: 0.892308 | Val Loss: 0.108152, Val Acc: 0.814433\n",
      "Epoch 25441 - Train Loss: 0.071535, Train Acc: 0.892308 | Val Loss: 0.108152, Val Acc: 0.814433\n",
      "Epoch 25442 - Train Loss: 0.071534, Train Acc: 0.892308 | Val Loss: 0.108151, Val Acc: 0.814433\n",
      "Epoch 25443 - Train Loss: 0.071532, Train Acc: 0.892308 | Val Loss: 0.108151, Val Acc: 0.814433\n",
      "Epoch 25444 - Train Loss: 0.071531, Train Acc: 0.892308 | Val Loss: 0.108151, Val Acc: 0.814433\n",
      "Epoch 25445 - Train Loss: 0.071530, Train Acc: 0.892308 | Val Loss: 0.108151, Val Acc: 0.814433\n",
      "Epoch 25446 - Train Loss: 0.071528, Train Acc: 0.892308 | Val Loss: 0.108151, Val Acc: 0.814433\n",
      "Epoch 25447 - Train Loss: 0.071527, Train Acc: 0.892308 | Val Loss: 0.108150, Val Acc: 0.814433\n",
      "Epoch 25448 - Train Loss: 0.071525, Train Acc: 0.892308 | Val Loss: 0.108150, Val Acc: 0.814433\n",
      "Epoch 25449 - Train Loss: 0.071524, Train Acc: 0.892308 | Val Loss: 0.108150, Val Acc: 0.814433\n",
      "Epoch 25450 - Train Loss: 0.071522, Train Acc: 0.892308 | Val Loss: 0.108150, Val Acc: 0.814433\n",
      "Epoch 25451 - Train Loss: 0.071521, Train Acc: 0.892308 | Val Loss: 0.108150, Val Acc: 0.814433\n",
      "Epoch 25452 - Train Loss: 0.071519, Train Acc: 0.892308 | Val Loss: 0.108149, Val Acc: 0.814433\n",
      "Epoch 25453 - Train Loss: 0.071518, Train Acc: 0.892308 | Val Loss: 0.108149, Val Acc: 0.814433\n",
      "Epoch 25454 - Train Loss: 0.071517, Train Acc: 0.892308 | Val Loss: 0.108149, Val Acc: 0.814433\n",
      "Epoch 25455 - Train Loss: 0.071515, Train Acc: 0.892308 | Val Loss: 0.108149, Val Acc: 0.814433\n",
      "Epoch 25456 - Train Loss: 0.071514, Train Acc: 0.892308 | Val Loss: 0.108149, Val Acc: 0.814433\n",
      "Epoch 25457 - Train Loss: 0.071512, Train Acc: 0.892308 | Val Loss: 0.108148, Val Acc: 0.814433\n",
      "Epoch 25458 - Train Loss: 0.071511, Train Acc: 0.892308 | Val Loss: 0.108148, Val Acc: 0.814433\n",
      "Epoch 25459 - Train Loss: 0.071509, Train Acc: 0.892308 | Val Loss: 0.108148, Val Acc: 0.814433\n",
      "Epoch 25460 - Train Loss: 0.071508, Train Acc: 0.892308 | Val Loss: 0.108148, Val Acc: 0.814433\n",
      "Epoch 25461 - Train Loss: 0.071506, Train Acc: 0.892308 | Val Loss: 0.108148, Val Acc: 0.814433\n",
      "Epoch 25462 - Train Loss: 0.071505, Train Acc: 0.892308 | Val Loss: 0.108147, Val Acc: 0.814433\n",
      "Epoch 25463 - Train Loss: 0.071504, Train Acc: 0.892308 | Val Loss: 0.108147, Val Acc: 0.814433\n",
      "Epoch 25464 - Train Loss: 0.071502, Train Acc: 0.892308 | Val Loss: 0.108147, Val Acc: 0.814433\n",
      "Epoch 25465 - Train Loss: 0.071501, Train Acc: 0.892308 | Val Loss: 0.108147, Val Acc: 0.814433\n",
      "Epoch 25466 - Train Loss: 0.071499, Train Acc: 0.892308 | Val Loss: 0.108147, Val Acc: 0.814433\n",
      "Epoch 25467 - Train Loss: 0.071498, Train Acc: 0.892308 | Val Loss: 0.108146, Val Acc: 0.814433\n",
      "Epoch 25468 - Train Loss: 0.071496, Train Acc: 0.892308 | Val Loss: 0.108146, Val Acc: 0.814433\n",
      "Epoch 25469 - Train Loss: 0.071495, Train Acc: 0.892308 | Val Loss: 0.108146, Val Acc: 0.814433\n",
      "Epoch 25470 - Train Loss: 0.071493, Train Acc: 0.892308 | Val Loss: 0.108146, Val Acc: 0.814433\n",
      "Epoch 25471 - Train Loss: 0.071492, Train Acc: 0.892308 | Val Loss: 0.108146, Val Acc: 0.814433\n",
      "Epoch 25472 - Train Loss: 0.071491, Train Acc: 0.892308 | Val Loss: 0.108145, Val Acc: 0.814433\n",
      "Epoch 25473 - Train Loss: 0.071489, Train Acc: 0.892308 | Val Loss: 0.108145, Val Acc: 0.814433\n",
      "Epoch 25474 - Train Loss: 0.071488, Train Acc: 0.892308 | Val Loss: 0.108145, Val Acc: 0.814433\n",
      "Epoch 25475 - Train Loss: 0.071486, Train Acc: 0.892308 | Val Loss: 0.108145, Val Acc: 0.814433\n",
      "Epoch 25476 - Train Loss: 0.071485, Train Acc: 0.892308 | Val Loss: 0.108145, Val Acc: 0.814433\n",
      "Epoch 25477 - Train Loss: 0.071483, Train Acc: 0.892308 | Val Loss: 0.108144, Val Acc: 0.814433\n",
      "Epoch 25478 - Train Loss: 0.071482, Train Acc: 0.892308 | Val Loss: 0.108144, Val Acc: 0.814433\n",
      "Epoch 25479 - Train Loss: 0.071481, Train Acc: 0.892308 | Val Loss: 0.108144, Val Acc: 0.814433\n",
      "Epoch 25480 - Train Loss: 0.071479, Train Acc: 0.892308 | Val Loss: 0.108144, Val Acc: 0.814433\n",
      "Epoch 25481 - Train Loss: 0.071478, Train Acc: 0.892308 | Val Loss: 0.108144, Val Acc: 0.814433\n",
      "Epoch 25482 - Train Loss: 0.071476, Train Acc: 0.892308 | Val Loss: 0.108143, Val Acc: 0.814433\n",
      "Epoch 25483 - Train Loss: 0.071475, Train Acc: 0.892308 | Val Loss: 0.108143, Val Acc: 0.814433\n",
      "Epoch 25484 - Train Loss: 0.071473, Train Acc: 0.892308 | Val Loss: 0.108143, Val Acc: 0.814433\n",
      "Epoch 25485 - Train Loss: 0.071472, Train Acc: 0.892308 | Val Loss: 0.108143, Val Acc: 0.814433\n",
      "Epoch 25486 - Train Loss: 0.071470, Train Acc: 0.892308 | Val Loss: 0.108143, Val Acc: 0.814433\n",
      "Epoch 25487 - Train Loss: 0.071469, Train Acc: 0.892308 | Val Loss: 0.108142, Val Acc: 0.814433\n",
      "Epoch 25488 - Train Loss: 0.071468, Train Acc: 0.892308 | Val Loss: 0.108142, Val Acc: 0.814433\n",
      "Epoch 25489 - Train Loss: 0.071466, Train Acc: 0.892308 | Val Loss: 0.108142, Val Acc: 0.814433\n",
      "Epoch 25490 - Train Loss: 0.071465, Train Acc: 0.892308 | Val Loss: 0.108142, Val Acc: 0.814433\n",
      "Epoch 25491 - Train Loss: 0.071463, Train Acc: 0.892308 | Val Loss: 0.108142, Val Acc: 0.814433\n",
      "Epoch 25492 - Train Loss: 0.071462, Train Acc: 0.892308 | Val Loss: 0.108141, Val Acc: 0.814433\n",
      "Epoch 25493 - Train Loss: 0.071460, Train Acc: 0.892308 | Val Loss: 0.108141, Val Acc: 0.814433\n",
      "Epoch 25494 - Train Loss: 0.071459, Train Acc: 0.892308 | Val Loss: 0.108141, Val Acc: 0.814433\n",
      "Epoch 25495 - Train Loss: 0.071458, Train Acc: 0.892308 | Val Loss: 0.108141, Val Acc: 0.814433\n",
      "Epoch 25496 - Train Loss: 0.071456, Train Acc: 0.892308 | Val Loss: 0.108141, Val Acc: 0.814433\n",
      "Epoch 25497 - Train Loss: 0.071455, Train Acc: 0.892308 | Val Loss: 0.108140, Val Acc: 0.814433\n",
      "Epoch 25498 - Train Loss: 0.071453, Train Acc: 0.892308 | Val Loss: 0.108140, Val Acc: 0.814433\n",
      "Epoch 25499 - Train Loss: 0.071452, Train Acc: 0.892308 | Val Loss: 0.108140, Val Acc: 0.814433\n",
      "Epoch 25500 - Train Loss: 0.071450, Train Acc: 0.892308 | Val Loss: 0.108140, Val Acc: 0.814433\n",
      "Epoch 25501 - Train Loss: 0.071449, Train Acc: 0.892308 | Val Loss: 0.108140, Val Acc: 0.814433\n",
      "Epoch 25502 - Train Loss: 0.071447, Train Acc: 0.892308 | Val Loss: 0.108139, Val Acc: 0.814433\n",
      "Epoch 25503 - Train Loss: 0.071446, Train Acc: 0.892308 | Val Loss: 0.108139, Val Acc: 0.814433\n",
      "Epoch 25504 - Train Loss: 0.071445, Train Acc: 0.892308 | Val Loss: 0.108139, Val Acc: 0.814433\n",
      "Epoch 25505 - Train Loss: 0.071443, Train Acc: 0.892308 | Val Loss: 0.108139, Val Acc: 0.814433\n",
      "Epoch 25506 - Train Loss: 0.071442, Train Acc: 0.892308 | Val Loss: 0.108139, Val Acc: 0.814433\n",
      "Epoch 25507 - Train Loss: 0.071440, Train Acc: 0.892308 | Val Loss: 0.108138, Val Acc: 0.814433\n",
      "Epoch 25508 - Train Loss: 0.071439, Train Acc: 0.892308 | Val Loss: 0.108138, Val Acc: 0.814433\n",
      "Epoch 25509 - Train Loss: 0.071437, Train Acc: 0.892308 | Val Loss: 0.108138, Val Acc: 0.814433\n",
      "Epoch 25510 - Train Loss: 0.071436, Train Acc: 0.892308 | Val Loss: 0.108138, Val Acc: 0.814433\n",
      "Epoch 25511 - Train Loss: 0.071435, Train Acc: 0.892308 | Val Loss: 0.108138, Val Acc: 0.814433\n",
      "Epoch 25512 - Train Loss: 0.071433, Train Acc: 0.892308 | Val Loss: 0.108137, Val Acc: 0.814433\n",
      "Epoch 25513 - Train Loss: 0.071432, Train Acc: 0.892308 | Val Loss: 0.108137, Val Acc: 0.814433\n",
      "Epoch 25514 - Train Loss: 0.071430, Train Acc: 0.892308 | Val Loss: 0.108137, Val Acc: 0.814433\n",
      "Epoch 25515 - Train Loss: 0.071429, Train Acc: 0.892308 | Val Loss: 0.108137, Val Acc: 0.814433\n",
      "Epoch 25516 - Train Loss: 0.071427, Train Acc: 0.892308 | Val Loss: 0.108137, Val Acc: 0.814433\n",
      "Epoch 25517 - Train Loss: 0.071426, Train Acc: 0.892308 | Val Loss: 0.108136, Val Acc: 0.814433\n",
      "Epoch 25518 - Train Loss: 0.071424, Train Acc: 0.892308 | Val Loss: 0.108136, Val Acc: 0.814433\n",
      "Epoch 25519 - Train Loss: 0.071423, Train Acc: 0.892308 | Val Loss: 0.108136, Val Acc: 0.814433\n",
      "Epoch 25520 - Train Loss: 0.071422, Train Acc: 0.892308 | Val Loss: 0.108136, Val Acc: 0.814433\n",
      "Epoch 25521 - Train Loss: 0.071420, Train Acc: 0.892308 | Val Loss: 0.108136, Val Acc: 0.814433\n",
      "Epoch 25522 - Train Loss: 0.071419, Train Acc: 0.892308 | Val Loss: 0.108135, Val Acc: 0.814433\n",
      "Epoch 25523 - Train Loss: 0.071417, Train Acc: 0.892308 | Val Loss: 0.108135, Val Acc: 0.814433\n",
      "Epoch 25524 - Train Loss: 0.071416, Train Acc: 0.892308 | Val Loss: 0.108135, Val Acc: 0.814433\n",
      "Epoch 25525 - Train Loss: 0.071414, Train Acc: 0.892308 | Val Loss: 0.108135, Val Acc: 0.814433\n",
      "Epoch 25526 - Train Loss: 0.071413, Train Acc: 0.892308 | Val Loss: 0.108135, Val Acc: 0.814433\n",
      "Epoch 25527 - Train Loss: 0.071412, Train Acc: 0.892308 | Val Loss: 0.108134, Val Acc: 0.814433\n",
      "Epoch 25528 - Train Loss: 0.071410, Train Acc: 0.892308 | Val Loss: 0.108134, Val Acc: 0.814433\n",
      "Epoch 25529 - Train Loss: 0.071409, Train Acc: 0.892308 | Val Loss: 0.108134, Val Acc: 0.814433\n",
      "Epoch 25530 - Train Loss: 0.071407, Train Acc: 0.892308 | Val Loss: 0.108134, Val Acc: 0.814433\n",
      "Epoch 25531 - Train Loss: 0.071406, Train Acc: 0.892308 | Val Loss: 0.108134, Val Acc: 0.814433\n",
      "Epoch 25532 - Train Loss: 0.071404, Train Acc: 0.892308 | Val Loss: 0.108134, Val Acc: 0.814433\n",
      "Epoch 25533 - Train Loss: 0.071403, Train Acc: 0.892308 | Val Loss: 0.108133, Val Acc: 0.814433\n",
      "Epoch 25534 - Train Loss: 0.071402, Train Acc: 0.892308 | Val Loss: 0.108133, Val Acc: 0.814433\n",
      "Epoch 25535 - Train Loss: 0.071400, Train Acc: 0.892308 | Val Loss: 0.108133, Val Acc: 0.814433\n",
      "Epoch 25536 - Train Loss: 0.071399, Train Acc: 0.892308 | Val Loss: 0.108133, Val Acc: 0.814433\n",
      "Epoch 25537 - Train Loss: 0.071397, Train Acc: 0.892308 | Val Loss: 0.108132, Val Acc: 0.814433\n",
      "Epoch 25538 - Train Loss: 0.071396, Train Acc: 0.892308 | Val Loss: 0.108132, Val Acc: 0.814433\n",
      "Epoch 25539 - Train Loss: 0.071394, Train Acc: 0.892308 | Val Loss: 0.108132, Val Acc: 0.814433\n",
      "Epoch 25540 - Train Loss: 0.071393, Train Acc: 0.892308 | Val Loss: 0.108132, Val Acc: 0.814433\n",
      "Epoch 25541 - Train Loss: 0.071391, Train Acc: 0.892308 | Val Loss: 0.108132, Val Acc: 0.814433\n",
      "Epoch 25542 - Train Loss: 0.071390, Train Acc: 0.892308 | Val Loss: 0.108132, Val Acc: 0.814433\n",
      "Epoch 25543 - Train Loss: 0.071389, Train Acc: 0.892308 | Val Loss: 0.108131, Val Acc: 0.814433\n",
      "Epoch 25544 - Train Loss: 0.071387, Train Acc: 0.892308 | Val Loss: 0.108131, Val Acc: 0.814433\n",
      "Epoch 25545 - Train Loss: 0.071386, Train Acc: 0.892308 | Val Loss: 0.108131, Val Acc: 0.814433\n",
      "Epoch 25546 - Train Loss: 0.071384, Train Acc: 0.892308 | Val Loss: 0.108131, Val Acc: 0.814433\n",
      "Epoch 25547 - Train Loss: 0.071383, Train Acc: 0.892308 | Val Loss: 0.108131, Val Acc: 0.814433\n",
      "Epoch 25548 - Train Loss: 0.071381, Train Acc: 0.892308 | Val Loss: 0.108130, Val Acc: 0.814433\n",
      "Epoch 25549 - Train Loss: 0.071380, Train Acc: 0.892308 | Val Loss: 0.108130, Val Acc: 0.814433\n",
      "Epoch 25550 - Train Loss: 0.071379, Train Acc: 0.892308 | Val Loss: 0.108130, Val Acc: 0.814433\n",
      "Epoch 25551 - Train Loss: 0.071377, Train Acc: 0.892308 | Val Loss: 0.108130, Val Acc: 0.814433\n",
      "Epoch 25552 - Train Loss: 0.071376, Train Acc: 0.892308 | Val Loss: 0.108130, Val Acc: 0.814433\n",
      "Epoch 25553 - Train Loss: 0.071374, Train Acc: 0.892308 | Val Loss: 0.108129, Val Acc: 0.814433\n",
      "Epoch 25554 - Train Loss: 0.071373, Train Acc: 0.892308 | Val Loss: 0.108129, Val Acc: 0.814433\n",
      "Epoch 25555 - Train Loss: 0.071371, Train Acc: 0.892308 | Val Loss: 0.108129, Val Acc: 0.814433\n",
      "Epoch 25556 - Train Loss: 0.071370, Train Acc: 0.892308 | Val Loss: 0.108129, Val Acc: 0.814433\n",
      "Epoch 25557 - Train Loss: 0.071369, Train Acc: 0.892308 | Val Loss: 0.108129, Val Acc: 0.814433\n",
      "Epoch 25558 - Train Loss: 0.071367, Train Acc: 0.892308 | Val Loss: 0.108128, Val Acc: 0.814433\n",
      "Epoch 25559 - Train Loss: 0.071366, Train Acc: 0.892308 | Val Loss: 0.108128, Val Acc: 0.814433\n",
      "Epoch 25560 - Train Loss: 0.071364, Train Acc: 0.892308 | Val Loss: 0.108128, Val Acc: 0.814433\n",
      "Epoch 25561 - Train Loss: 0.071363, Train Acc: 0.892308 | Val Loss: 0.108128, Val Acc: 0.814433\n",
      "Epoch 25562 - Train Loss: 0.071361, Train Acc: 0.892308 | Val Loss: 0.108128, Val Acc: 0.814433\n",
      "Epoch 25563 - Train Loss: 0.071360, Train Acc: 0.892308 | Val Loss: 0.108127, Val Acc: 0.814433\n",
      "Epoch 25564 - Train Loss: 0.071359, Train Acc: 0.892308 | Val Loss: 0.108127, Val Acc: 0.814433\n",
      "Epoch 25565 - Train Loss: 0.071357, Train Acc: 0.892308 | Val Loss: 0.108127, Val Acc: 0.814433\n",
      "Epoch 25566 - Train Loss: 0.071356, Train Acc: 0.892308 | Val Loss: 0.108127, Val Acc: 0.814433\n",
      "Epoch 25567 - Train Loss: 0.071354, Train Acc: 0.892308 | Val Loss: 0.108127, Val Acc: 0.814433\n",
      "Epoch 25568 - Train Loss: 0.071353, Train Acc: 0.892308 | Val Loss: 0.108127, Val Acc: 0.814433\n",
      "Epoch 25569 - Train Loss: 0.071351, Train Acc: 0.892308 | Val Loss: 0.108126, Val Acc: 0.814433\n",
      "Epoch 25570 - Train Loss: 0.071350, Train Acc: 0.892308 | Val Loss: 0.108126, Val Acc: 0.814433\n",
      "Epoch 25571 - Train Loss: 0.071349, Train Acc: 0.892308 | Val Loss: 0.108126, Val Acc: 0.814433\n",
      "Epoch 25572 - Train Loss: 0.071347, Train Acc: 0.892308 | Val Loss: 0.108126, Val Acc: 0.814433\n",
      "Epoch 25573 - Train Loss: 0.071346, Train Acc: 0.892308 | Val Loss: 0.108126, Val Acc: 0.814433\n",
      "Epoch 25574 - Train Loss: 0.071344, Train Acc: 0.892308 | Val Loss: 0.108125, Val Acc: 0.814433\n",
      "Epoch 25575 - Train Loss: 0.071343, Train Acc: 0.892308 | Val Loss: 0.108125, Val Acc: 0.814433\n",
      "Epoch 25576 - Train Loss: 0.071341, Train Acc: 0.892308 | Val Loss: 0.108125, Val Acc: 0.814433\n",
      "Epoch 25577 - Train Loss: 0.071340, Train Acc: 0.892308 | Val Loss: 0.108125, Val Acc: 0.814433\n",
      "Epoch 25578 - Train Loss: 0.071339, Train Acc: 0.892308 | Val Loss: 0.108125, Val Acc: 0.814433\n",
      "Epoch 25579 - Train Loss: 0.071337, Train Acc: 0.892308 | Val Loss: 0.108124, Val Acc: 0.814433\n",
      "Epoch 25580 - Train Loss: 0.071336, Train Acc: 0.892308 | Val Loss: 0.108124, Val Acc: 0.814433\n",
      "Epoch 25581 - Train Loss: 0.071334, Train Acc: 0.892308 | Val Loss: 0.108124, Val Acc: 0.814433\n",
      "Epoch 25582 - Train Loss: 0.071333, Train Acc: 0.892308 | Val Loss: 0.108124, Val Acc: 0.814433\n",
      "Epoch 25583 - Train Loss: 0.071331, Train Acc: 0.892308 | Val Loss: 0.108124, Val Acc: 0.814433\n",
      "Epoch 25584 - Train Loss: 0.071330, Train Acc: 0.892308 | Val Loss: 0.108124, Val Acc: 0.814433\n",
      "Epoch 25585 - Train Loss: 0.071329, Train Acc: 0.892308 | Val Loss: 0.108123, Val Acc: 0.814433\n",
      "Epoch 25586 - Train Loss: 0.071327, Train Acc: 0.892308 | Val Loss: 0.108123, Val Acc: 0.814433\n",
      "Epoch 25587 - Train Loss: 0.071326, Train Acc: 0.892308 | Val Loss: 0.108123, Val Acc: 0.814433\n",
      "Epoch 25588 - Train Loss: 0.071324, Train Acc: 0.892308 | Val Loss: 0.108123, Val Acc: 0.814433\n",
      "Epoch 25589 - Train Loss: 0.071323, Train Acc: 0.892308 | Val Loss: 0.108123, Val Acc: 0.814433\n",
      "Epoch 25590 - Train Loss: 0.071321, Train Acc: 0.892308 | Val Loss: 0.108122, Val Acc: 0.814433\n",
      "Epoch 25591 - Train Loss: 0.071320, Train Acc: 0.892308 | Val Loss: 0.108122, Val Acc: 0.814433\n",
      "Epoch 25592 - Train Loss: 0.071319, Train Acc: 0.892308 | Val Loss: 0.108122, Val Acc: 0.814433\n",
      "Epoch 25593 - Train Loss: 0.071317, Train Acc: 0.892308 | Val Loss: 0.108122, Val Acc: 0.814433\n",
      "Epoch 25594 - Train Loss: 0.071316, Train Acc: 0.892308 | Val Loss: 0.108122, Val Acc: 0.814433\n",
      "Epoch 25595 - Train Loss: 0.071314, Train Acc: 0.892308 | Val Loss: 0.108121, Val Acc: 0.814433\n",
      "Epoch 25596 - Train Loss: 0.071313, Train Acc: 0.892308 | Val Loss: 0.108121, Val Acc: 0.814433\n",
      "Epoch 25597 - Train Loss: 0.071311, Train Acc: 0.892308 | Val Loss: 0.108121, Val Acc: 0.814433\n",
      "Epoch 25598 - Train Loss: 0.071310, Train Acc: 0.892308 | Val Loss: 0.108121, Val Acc: 0.814433\n",
      "Epoch 25599 - Train Loss: 0.071309, Train Acc: 0.892308 | Val Loss: 0.108121, Val Acc: 0.814433\n",
      "Epoch 25600 - Train Loss: 0.071307, Train Acc: 0.892308 | Val Loss: 0.108120, Val Acc: 0.814433\n",
      "Epoch 25601 - Train Loss: 0.071306, Train Acc: 0.892308 | Val Loss: 0.108120, Val Acc: 0.814433\n",
      "Epoch 25602 - Train Loss: 0.071304, Train Acc: 0.892308 | Val Loss: 0.108120, Val Acc: 0.814433\n",
      "Epoch 25603 - Train Loss: 0.071303, Train Acc: 0.892308 | Val Loss: 0.108120, Val Acc: 0.814433\n",
      "Epoch 25604 - Train Loss: 0.071301, Train Acc: 0.892308 | Val Loss: 0.108120, Val Acc: 0.814433\n",
      "Epoch 25605 - Train Loss: 0.071300, Train Acc: 0.892308 | Val Loss: 0.108120, Val Acc: 0.814433\n",
      "Epoch 25606 - Train Loss: 0.071299, Train Acc: 0.892308 | Val Loss: 0.108119, Val Acc: 0.814433\n",
      "Epoch 25607 - Train Loss: 0.071297, Train Acc: 0.892308 | Val Loss: 0.108119, Val Acc: 0.814433\n",
      "Epoch 25608 - Train Loss: 0.071296, Train Acc: 0.892308 | Val Loss: 0.108119, Val Acc: 0.814433\n",
      "Epoch 25609 - Train Loss: 0.071294, Train Acc: 0.892308 | Val Loss: 0.108119, Val Acc: 0.814433\n",
      "Epoch 25610 - Train Loss: 0.071293, Train Acc: 0.892308 | Val Loss: 0.108119, Val Acc: 0.814433\n",
      "Epoch 25611 - Train Loss: 0.071291, Train Acc: 0.892308 | Val Loss: 0.108118, Val Acc: 0.814433\n",
      "Epoch 25612 - Train Loss: 0.071290, Train Acc: 0.892308 | Val Loss: 0.108118, Val Acc: 0.814433\n",
      "Epoch 25613 - Train Loss: 0.071289, Train Acc: 0.892308 | Val Loss: 0.108118, Val Acc: 0.814433\n",
      "Epoch 25614 - Train Loss: 0.071287, Train Acc: 0.892308 | Val Loss: 0.108118, Val Acc: 0.814433\n",
      "Epoch 25615 - Train Loss: 0.071286, Train Acc: 0.892308 | Val Loss: 0.108118, Val Acc: 0.814433\n",
      "Epoch 25616 - Train Loss: 0.071284, Train Acc: 0.892308 | Val Loss: 0.108117, Val Acc: 0.814433\n",
      "Epoch 25617 - Train Loss: 0.071283, Train Acc: 0.892308 | Val Loss: 0.108117, Val Acc: 0.814433\n",
      "Epoch 25618 - Train Loss: 0.071281, Train Acc: 0.892308 | Val Loss: 0.108117, Val Acc: 0.814433\n",
      "Epoch 25619 - Train Loss: 0.071280, Train Acc: 0.892308 | Val Loss: 0.108117, Val Acc: 0.814433\n",
      "Epoch 25620 - Train Loss: 0.071279, Train Acc: 0.892308 | Val Loss: 0.108117, Val Acc: 0.814433\n",
      "Epoch 25621 - Train Loss: 0.071277, Train Acc: 0.892308 | Val Loss: 0.108117, Val Acc: 0.814433\n",
      "Epoch 25622 - Train Loss: 0.071276, Train Acc: 0.892308 | Val Loss: 0.108116, Val Acc: 0.814433\n",
      "Epoch 25623 - Train Loss: 0.071274, Train Acc: 0.892308 | Val Loss: 0.108116, Val Acc: 0.814433\n",
      "Epoch 25624 - Train Loss: 0.071273, Train Acc: 0.892308 | Val Loss: 0.108116, Val Acc: 0.814433\n",
      "Epoch 25625 - Train Loss: 0.071271, Train Acc: 0.892308 | Val Loss: 0.108116, Val Acc: 0.814433\n",
      "Epoch 25626 - Train Loss: 0.071270, Train Acc: 0.892308 | Val Loss: 0.108116, Val Acc: 0.814433\n",
      "Epoch 25627 - Train Loss: 0.071269, Train Acc: 0.892308 | Val Loss: 0.108115, Val Acc: 0.814433\n",
      "Epoch 25628 - Train Loss: 0.071267, Train Acc: 0.892308 | Val Loss: 0.108115, Val Acc: 0.814433\n",
      "Epoch 25629 - Train Loss: 0.071266, Train Acc: 0.892308 | Val Loss: 0.108115, Val Acc: 0.814433\n",
      "Epoch 25630 - Train Loss: 0.071264, Train Acc: 0.892308 | Val Loss: 0.108115, Val Acc: 0.814433\n",
      "Epoch 25631 - Train Loss: 0.071263, Train Acc: 0.892308 | Val Loss: 0.108115, Val Acc: 0.814433\n",
      "Epoch 25632 - Train Loss: 0.071261, Train Acc: 0.892308 | Val Loss: 0.108115, Val Acc: 0.814433\n",
      "Epoch 25633 - Train Loss: 0.071260, Train Acc: 0.892308 | Val Loss: 0.108114, Val Acc: 0.814433\n",
      "Epoch 25634 - Train Loss: 0.071259, Train Acc: 0.892308 | Val Loss: 0.108114, Val Acc: 0.814433\n",
      "Epoch 25635 - Train Loss: 0.071257, Train Acc: 0.892308 | Val Loss: 0.108114, Val Acc: 0.814433\n",
      "Epoch 25636 - Train Loss: 0.071256, Train Acc: 0.892308 | Val Loss: 0.108114, Val Acc: 0.814433\n",
      "Epoch 25637 - Train Loss: 0.071254, Train Acc: 0.892308 | Val Loss: 0.108114, Val Acc: 0.814433\n",
      "Epoch 25638 - Train Loss: 0.071253, Train Acc: 0.892308 | Val Loss: 0.108113, Val Acc: 0.814433\n",
      "Epoch 25639 - Train Loss: 0.071252, Train Acc: 0.892308 | Val Loss: 0.108113, Val Acc: 0.814433\n",
      "Epoch 25640 - Train Loss: 0.071250, Train Acc: 0.892308 | Val Loss: 0.108113, Val Acc: 0.814433\n",
      "Epoch 25641 - Train Loss: 0.071249, Train Acc: 0.892308 | Val Loss: 0.108113, Val Acc: 0.814433\n",
      "Epoch 25642 - Train Loss: 0.071247, Train Acc: 0.892308 | Val Loss: 0.108113, Val Acc: 0.814433\n",
      "Epoch 25643 - Train Loss: 0.071246, Train Acc: 0.892308 | Val Loss: 0.108112, Val Acc: 0.814433\n",
      "Epoch 25644 - Train Loss: 0.071244, Train Acc: 0.892308 | Val Loss: 0.108112, Val Acc: 0.814433\n",
      "Epoch 25645 - Train Loss: 0.071243, Train Acc: 0.892308 | Val Loss: 0.108112, Val Acc: 0.814433\n",
      "Epoch 25646 - Train Loss: 0.071242, Train Acc: 0.892308 | Val Loss: 0.108112, Val Acc: 0.814433\n",
      "Epoch 25647 - Train Loss: 0.071240, Train Acc: 0.892308 | Val Loss: 0.108112, Val Acc: 0.814433\n",
      "Epoch 25648 - Train Loss: 0.071239, Train Acc: 0.892308 | Val Loss: 0.108112, Val Acc: 0.814433\n",
      "Epoch 25649 - Train Loss: 0.071237, Train Acc: 0.892308 | Val Loss: 0.108111, Val Acc: 0.814433\n",
      "Epoch 25650 - Train Loss: 0.071236, Train Acc: 0.892308 | Val Loss: 0.108111, Val Acc: 0.814433\n",
      "Epoch 25651 - Train Loss: 0.071234, Train Acc: 0.892308 | Val Loss: 0.108111, Val Acc: 0.814433\n",
      "Epoch 25652 - Train Loss: 0.071233, Train Acc: 0.892308 | Val Loss: 0.108111, Val Acc: 0.814433\n",
      "Epoch 25653 - Train Loss: 0.071232, Train Acc: 0.892308 | Val Loss: 0.108111, Val Acc: 0.814433\n",
      "Epoch 25654 - Train Loss: 0.071230, Train Acc: 0.892308 | Val Loss: 0.108110, Val Acc: 0.814433\n",
      "Epoch 25655 - Train Loss: 0.071229, Train Acc: 0.892308 | Val Loss: 0.108110, Val Acc: 0.814433\n",
      "Epoch 25656 - Train Loss: 0.071227, Train Acc: 0.892308 | Val Loss: 0.108110, Val Acc: 0.814433\n",
      "Epoch 25657 - Train Loss: 0.071226, Train Acc: 0.892308 | Val Loss: 0.108110, Val Acc: 0.814433\n",
      "Epoch 25658 - Train Loss: 0.071224, Train Acc: 0.892308 | Val Loss: 0.108110, Val Acc: 0.814433\n",
      "Epoch 25659 - Train Loss: 0.071223, Train Acc: 0.892308 | Val Loss: 0.108110, Val Acc: 0.814433\n",
      "Epoch 25660 - Train Loss: 0.071222, Train Acc: 0.892308 | Val Loss: 0.108109, Val Acc: 0.814433\n",
      "Epoch 25661 - Train Loss: 0.071220, Train Acc: 0.892308 | Val Loss: 0.108109, Val Acc: 0.814433\n",
      "Epoch 25662 - Train Loss: 0.071219, Train Acc: 0.892308 | Val Loss: 0.108109, Val Acc: 0.814433\n",
      "Epoch 25663 - Train Loss: 0.071217, Train Acc: 0.892308 | Val Loss: 0.108109, Val Acc: 0.814433\n",
      "Epoch 25664 - Train Loss: 0.071216, Train Acc: 0.892308 | Val Loss: 0.108109, Val Acc: 0.814433\n",
      "Epoch 25665 - Train Loss: 0.071215, Train Acc: 0.892308 | Val Loss: 0.108108, Val Acc: 0.814433\n",
      "Epoch 25666 - Train Loss: 0.071213, Train Acc: 0.892308 | Val Loss: 0.108108, Val Acc: 0.814433\n",
      "Epoch 25667 - Train Loss: 0.071212, Train Acc: 0.892308 | Val Loss: 0.108108, Val Acc: 0.814433\n",
      "Epoch 25668 - Train Loss: 0.071210, Train Acc: 0.892308 | Val Loss: 0.108108, Val Acc: 0.814433\n",
      "Epoch 25669 - Train Loss: 0.071209, Train Acc: 0.892308 | Val Loss: 0.108108, Val Acc: 0.814433\n",
      "Epoch 25670 - Train Loss: 0.071207, Train Acc: 0.892308 | Val Loss: 0.108108, Val Acc: 0.814433\n",
      "Epoch 25671 - Train Loss: 0.071206, Train Acc: 0.892308 | Val Loss: 0.108107, Val Acc: 0.814433\n",
      "Epoch 25672 - Train Loss: 0.071205, Train Acc: 0.892308 | Val Loss: 0.108107, Val Acc: 0.814433\n",
      "Epoch 25673 - Train Loss: 0.071203, Train Acc: 0.892308 | Val Loss: 0.108107, Val Acc: 0.814433\n",
      "Epoch 25674 - Train Loss: 0.071202, Train Acc: 0.892308 | Val Loss: 0.108107, Val Acc: 0.814433\n",
      "Epoch 25675 - Train Loss: 0.071200, Train Acc: 0.892308 | Val Loss: 0.108107, Val Acc: 0.814433\n",
      "Epoch 25676 - Train Loss: 0.071199, Train Acc: 0.892308 | Val Loss: 0.108106, Val Acc: 0.814433\n",
      "Epoch 25677 - Train Loss: 0.071198, Train Acc: 0.892308 | Val Loss: 0.108106, Val Acc: 0.814433\n",
      "Epoch 25678 - Train Loss: 0.071196, Train Acc: 0.892308 | Val Loss: 0.108106, Val Acc: 0.814433\n",
      "Epoch 25679 - Train Loss: 0.071195, Train Acc: 0.892308 | Val Loss: 0.108106, Val Acc: 0.814433\n",
      "Epoch 25680 - Train Loss: 0.071193, Train Acc: 0.892308 | Val Loss: 0.108106, Val Acc: 0.814433\n",
      "Epoch 25681 - Train Loss: 0.071192, Train Acc: 0.892308 | Val Loss: 0.108106, Val Acc: 0.814433\n",
      "Epoch 25682 - Train Loss: 0.071190, Train Acc: 0.892308 | Val Loss: 0.108105, Val Acc: 0.814433\n",
      "Epoch 25683 - Train Loss: 0.071189, Train Acc: 0.892308 | Val Loss: 0.108105, Val Acc: 0.814433\n",
      "Epoch 25684 - Train Loss: 0.071188, Train Acc: 0.892308 | Val Loss: 0.108105, Val Acc: 0.814433\n",
      "Epoch 25685 - Train Loss: 0.071186, Train Acc: 0.892308 | Val Loss: 0.108105, Val Acc: 0.814433\n",
      "Epoch 25686 - Train Loss: 0.071185, Train Acc: 0.892308 | Val Loss: 0.108105, Val Acc: 0.814433\n",
      "Epoch 25687 - Train Loss: 0.071183, Train Acc: 0.892308 | Val Loss: 0.108104, Val Acc: 0.814433\n",
      "Epoch 25688 - Train Loss: 0.071182, Train Acc: 0.892308 | Val Loss: 0.108104, Val Acc: 0.814433\n",
      "Epoch 25689 - Train Loss: 0.071180, Train Acc: 0.892308 | Val Loss: 0.108104, Val Acc: 0.814433\n",
      "Epoch 25690 - Train Loss: 0.071179, Train Acc: 0.892308 | Val Loss: 0.108104, Val Acc: 0.814433\n",
      "Epoch 25691 - Train Loss: 0.071178, Train Acc: 0.892308 | Val Loss: 0.108104, Val Acc: 0.814433\n",
      "Epoch 25692 - Train Loss: 0.071176, Train Acc: 0.892308 | Val Loss: 0.108104, Val Acc: 0.814433\n",
      "Epoch 25693 - Train Loss: 0.071175, Train Acc: 0.892308 | Val Loss: 0.108103, Val Acc: 0.814433\n",
      "Epoch 25694 - Train Loss: 0.071173, Train Acc: 0.892308 | Val Loss: 0.108103, Val Acc: 0.814433\n",
      "Epoch 25695 - Train Loss: 0.071172, Train Acc: 0.892308 | Val Loss: 0.108103, Val Acc: 0.814433\n",
      "Epoch 25696 - Train Loss: 0.071171, Train Acc: 0.892308 | Val Loss: 0.108103, Val Acc: 0.814433\n",
      "Epoch 25697 - Train Loss: 0.071169, Train Acc: 0.892308 | Val Loss: 0.108103, Val Acc: 0.814433\n",
      "Epoch 25698 - Train Loss: 0.071168, Train Acc: 0.892308 | Val Loss: 0.108102, Val Acc: 0.814433\n",
      "Epoch 25699 - Train Loss: 0.071166, Train Acc: 0.892308 | Val Loss: 0.108102, Val Acc: 0.814433\n",
      "Epoch 25700 - Train Loss: 0.071165, Train Acc: 0.892308 | Val Loss: 0.108102, Val Acc: 0.814433\n",
      "Epoch 25701 - Train Loss: 0.071163, Train Acc: 0.892308 | Val Loss: 0.108102, Val Acc: 0.814433\n",
      "Epoch 25702 - Train Loss: 0.071162, Train Acc: 0.892308 | Val Loss: 0.108102, Val Acc: 0.814433\n",
      "Epoch 25703 - Train Loss: 0.071161, Train Acc: 0.892308 | Val Loss: 0.108102, Val Acc: 0.814433\n",
      "Epoch 25704 - Train Loss: 0.071159, Train Acc: 0.892308 | Val Loss: 0.108101, Val Acc: 0.814433\n",
      "Epoch 25705 - Train Loss: 0.071158, Train Acc: 0.892308 | Val Loss: 0.108101, Val Acc: 0.814433\n",
      "Epoch 25706 - Train Loss: 0.071156, Train Acc: 0.892308 | Val Loss: 0.108101, Val Acc: 0.814433\n",
      "Epoch 25707 - Train Loss: 0.071155, Train Acc: 0.892308 | Val Loss: 0.108101, Val Acc: 0.814433\n",
      "Epoch 25708 - Train Loss: 0.071154, Train Acc: 0.892308 | Val Loss: 0.108101, Val Acc: 0.814433\n",
      "Epoch 25709 - Train Loss: 0.071152, Train Acc: 0.892308 | Val Loss: 0.108101, Val Acc: 0.814433\n",
      "Epoch 25710 - Train Loss: 0.071151, Train Acc: 0.892308 | Val Loss: 0.108100, Val Acc: 0.814433\n",
      "Epoch 25711 - Train Loss: 0.071149, Train Acc: 0.892308 | Val Loss: 0.108100, Val Acc: 0.814433\n",
      "Epoch 25712 - Train Loss: 0.071148, Train Acc: 0.892308 | Val Loss: 0.108100, Val Acc: 0.814433\n",
      "Epoch 25713 - Train Loss: 0.071146, Train Acc: 0.892308 | Val Loss: 0.108100, Val Acc: 0.814433\n",
      "Epoch 25714 - Train Loss: 0.071145, Train Acc: 0.892308 | Val Loss: 0.108100, Val Acc: 0.814433\n",
      "Epoch 25715 - Train Loss: 0.071144, Train Acc: 0.892308 | Val Loss: 0.108099, Val Acc: 0.814433\n",
      "Epoch 25716 - Train Loss: 0.071142, Train Acc: 0.892308 | Val Loss: 0.108099, Val Acc: 0.814433\n",
      "Epoch 25717 - Train Loss: 0.071141, Train Acc: 0.892308 | Val Loss: 0.108099, Val Acc: 0.814433\n",
      "Epoch 25718 - Train Loss: 0.071139, Train Acc: 0.892308 | Val Loss: 0.108099, Val Acc: 0.814433\n",
      "Epoch 25719 - Train Loss: 0.071138, Train Acc: 0.892308 | Val Loss: 0.108099, Val Acc: 0.814433\n",
      "Epoch 25720 - Train Loss: 0.071137, Train Acc: 0.892308 | Val Loss: 0.108099, Val Acc: 0.814433\n",
      "Epoch 25721 - Train Loss: 0.071135, Train Acc: 0.892308 | Val Loss: 0.108098, Val Acc: 0.814433\n",
      "Epoch 25722 - Train Loss: 0.071134, Train Acc: 0.892308 | Val Loss: 0.108098, Val Acc: 0.814433\n",
      "Epoch 25723 - Train Loss: 0.071132, Train Acc: 0.892308 | Val Loss: 0.108098, Val Acc: 0.814433\n",
      "Epoch 25724 - Train Loss: 0.071131, Train Acc: 0.892308 | Val Loss: 0.108098, Val Acc: 0.814433\n",
      "Epoch 25725 - Train Loss: 0.071129, Train Acc: 0.892308 | Val Loss: 0.108098, Val Acc: 0.814433\n",
      "Epoch 25726 - Train Loss: 0.071128, Train Acc: 0.892308 | Val Loss: 0.108097, Val Acc: 0.814433\n",
      "Epoch 25727 - Train Loss: 0.071127, Train Acc: 0.892308 | Val Loss: 0.108097, Val Acc: 0.814433\n",
      "Epoch 25728 - Train Loss: 0.071125, Train Acc: 0.892308 | Val Loss: 0.108097, Val Acc: 0.814433\n",
      "Epoch 25729 - Train Loss: 0.071124, Train Acc: 0.892308 | Val Loss: 0.108097, Val Acc: 0.814433\n",
      "Epoch 25730 - Train Loss: 0.071122, Train Acc: 0.892308 | Val Loss: 0.108097, Val Acc: 0.814433\n",
      "Epoch 25731 - Train Loss: 0.071121, Train Acc: 0.892308 | Val Loss: 0.108097, Val Acc: 0.814433\n",
      "Epoch 25732 - Train Loss: 0.071120, Train Acc: 0.892308 | Val Loss: 0.108096, Val Acc: 0.814433\n",
      "Epoch 25733 - Train Loss: 0.071118, Train Acc: 0.892308 | Val Loss: 0.108096, Val Acc: 0.814433\n",
      "Epoch 25734 - Train Loss: 0.071117, Train Acc: 0.892308 | Val Loss: 0.108096, Val Acc: 0.814433\n",
      "Epoch 25735 - Train Loss: 0.071115, Train Acc: 0.892308 | Val Loss: 0.108096, Val Acc: 0.814433\n",
      "Epoch 25736 - Train Loss: 0.071114, Train Acc: 0.892308 | Val Loss: 0.108096, Val Acc: 0.814433\n",
      "Epoch 25737 - Train Loss: 0.071113, Train Acc: 0.892308 | Val Loss: 0.108096, Val Acc: 0.814433\n",
      "Epoch 25738 - Train Loss: 0.071111, Train Acc: 0.892308 | Val Loss: 0.108095, Val Acc: 0.814433\n",
      "Epoch 25739 - Train Loss: 0.071110, Train Acc: 0.892308 | Val Loss: 0.108095, Val Acc: 0.814433\n",
      "Epoch 25740 - Train Loss: 0.071108, Train Acc: 0.892308 | Val Loss: 0.108095, Val Acc: 0.814433\n",
      "Epoch 25741 - Train Loss: 0.071107, Train Acc: 0.892308 | Val Loss: 0.108095, Val Acc: 0.814433\n",
      "Epoch 25742 - Train Loss: 0.071105, Train Acc: 0.892308 | Val Loss: 0.108095, Val Acc: 0.814433\n",
      "Epoch 25743 - Train Loss: 0.071104, Train Acc: 0.892308 | Val Loss: 0.108095, Val Acc: 0.814433\n",
      "Epoch 25744 - Train Loss: 0.071103, Train Acc: 0.892308 | Val Loss: 0.108094, Val Acc: 0.814433\n",
      "Epoch 25745 - Train Loss: 0.071101, Train Acc: 0.892308 | Val Loss: 0.108094, Val Acc: 0.814433\n",
      "Epoch 25746 - Train Loss: 0.071100, Train Acc: 0.892308 | Val Loss: 0.108094, Val Acc: 0.814433\n",
      "Epoch 25747 - Train Loss: 0.071098, Train Acc: 0.892308 | Val Loss: 0.108094, Val Acc: 0.814433\n",
      "Epoch 25748 - Train Loss: 0.071097, Train Acc: 0.892308 | Val Loss: 0.108094, Val Acc: 0.814433\n",
      "Epoch 25749 - Train Loss: 0.071096, Train Acc: 0.892308 | Val Loss: 0.108093, Val Acc: 0.814433\n",
      "Epoch 25750 - Train Loss: 0.071094, Train Acc: 0.892308 | Val Loss: 0.108093, Val Acc: 0.814433\n",
      "Epoch 25751 - Train Loss: 0.071093, Train Acc: 0.892308 | Val Loss: 0.108093, Val Acc: 0.814433\n",
      "Epoch 25752 - Train Loss: 0.071091, Train Acc: 0.892308 | Val Loss: 0.108093, Val Acc: 0.814433\n",
      "Epoch 25753 - Train Loss: 0.071090, Train Acc: 0.892308 | Val Loss: 0.108093, Val Acc: 0.814433\n",
      "Epoch 25754 - Train Loss: 0.071088, Train Acc: 0.892308 | Val Loss: 0.108093, Val Acc: 0.814433\n",
      "Epoch 25755 - Train Loss: 0.071087, Train Acc: 0.892308 | Val Loss: 0.108092, Val Acc: 0.814433\n",
      "Epoch 25756 - Train Loss: 0.071086, Train Acc: 0.892308 | Val Loss: 0.108092, Val Acc: 0.814433\n",
      "Epoch 25757 - Train Loss: 0.071084, Train Acc: 0.892308 | Val Loss: 0.108092, Val Acc: 0.814433\n",
      "Epoch 25758 - Train Loss: 0.071083, Train Acc: 0.892308 | Val Loss: 0.108092, Val Acc: 0.814433\n",
      "Epoch 25759 - Train Loss: 0.071081, Train Acc: 0.892308 | Val Loss: 0.108092, Val Acc: 0.814433\n",
      "Epoch 25760 - Train Loss: 0.071080, Train Acc: 0.892308 | Val Loss: 0.108092, Val Acc: 0.814433\n",
      "Epoch 25761 - Train Loss: 0.071079, Train Acc: 0.892308 | Val Loss: 0.108091, Val Acc: 0.814433\n",
      "Epoch 25762 - Train Loss: 0.071077, Train Acc: 0.892308 | Val Loss: 0.108091, Val Acc: 0.814433\n",
      "Epoch 25763 - Train Loss: 0.071076, Train Acc: 0.892308 | Val Loss: 0.108091, Val Acc: 0.814433\n",
      "Epoch 25764 - Train Loss: 0.071074, Train Acc: 0.892308 | Val Loss: 0.108091, Val Acc: 0.814433\n",
      "Epoch 25765 - Train Loss: 0.071073, Train Acc: 0.892308 | Val Loss: 0.108091, Val Acc: 0.814433\n",
      "Epoch 25766 - Train Loss: 0.071072, Train Acc: 0.892308 | Val Loss: 0.108090, Val Acc: 0.814433\n",
      "Epoch 25767 - Train Loss: 0.071070, Train Acc: 0.892308 | Val Loss: 0.108090, Val Acc: 0.814433\n",
      "Epoch 25768 - Train Loss: 0.071069, Train Acc: 0.892308 | Val Loss: 0.108090, Val Acc: 0.814433\n",
      "Epoch 25769 - Train Loss: 0.071067, Train Acc: 0.892308 | Val Loss: 0.108090, Val Acc: 0.814433\n",
      "Epoch 25770 - Train Loss: 0.071066, Train Acc: 0.892308 | Val Loss: 0.108090, Val Acc: 0.814433\n",
      "Epoch 25771 - Train Loss: 0.071065, Train Acc: 0.892308 | Val Loss: 0.108090, Val Acc: 0.814433\n",
      "Epoch 25772 - Train Loss: 0.071063, Train Acc: 0.892308 | Val Loss: 0.108089, Val Acc: 0.814433\n",
      "Epoch 25773 - Train Loss: 0.071062, Train Acc: 0.892308 | Val Loss: 0.108089, Val Acc: 0.814433\n",
      "Epoch 25774 - Train Loss: 0.071060, Train Acc: 0.892308 | Val Loss: 0.108089, Val Acc: 0.814433\n",
      "Epoch 25775 - Train Loss: 0.071059, Train Acc: 0.892308 | Val Loss: 0.108089, Val Acc: 0.814433\n",
      "Epoch 25776 - Train Loss: 0.071057, Train Acc: 0.892308 | Val Loss: 0.108089, Val Acc: 0.814433\n",
      "Epoch 25777 - Train Loss: 0.071056, Train Acc: 0.892308 | Val Loss: 0.108089, Val Acc: 0.814433\n",
      "Epoch 25778 - Train Loss: 0.071055, Train Acc: 0.892308 | Val Loss: 0.108088, Val Acc: 0.814433\n",
      "Epoch 25779 - Train Loss: 0.071053, Train Acc: 0.892308 | Val Loss: 0.108088, Val Acc: 0.814433\n",
      "Epoch 25780 - Train Loss: 0.071052, Train Acc: 0.892308 | Val Loss: 0.108088, Val Acc: 0.814433\n",
      "Epoch 25781 - Train Loss: 0.071050, Train Acc: 0.892308 | Val Loss: 0.108088, Val Acc: 0.814433\n",
      "Epoch 25782 - Train Loss: 0.071049, Train Acc: 0.892308 | Val Loss: 0.108088, Val Acc: 0.814433\n",
      "Epoch 25783 - Train Loss: 0.071048, Train Acc: 0.892308 | Val Loss: 0.108088, Val Acc: 0.814433\n",
      "Epoch 25784 - Train Loss: 0.071046, Train Acc: 0.892308 | Val Loss: 0.108087, Val Acc: 0.814433\n",
      "Epoch 25785 - Train Loss: 0.071045, Train Acc: 0.892308 | Val Loss: 0.108087, Val Acc: 0.814433\n",
      "Epoch 25786 - Train Loss: 0.071043, Train Acc: 0.892308 | Val Loss: 0.108087, Val Acc: 0.814433\n",
      "Epoch 25787 - Train Loss: 0.071042, Train Acc: 0.892308 | Val Loss: 0.108087, Val Acc: 0.814433\n",
      "Epoch 25788 - Train Loss: 0.071041, Train Acc: 0.892308 | Val Loss: 0.108087, Val Acc: 0.814433\n",
      "Epoch 25789 - Train Loss: 0.071039, Train Acc: 0.892308 | Val Loss: 0.108087, Val Acc: 0.814433\n",
      "Epoch 25790 - Train Loss: 0.071038, Train Acc: 0.892308 | Val Loss: 0.108086, Val Acc: 0.814433\n",
      "Epoch 25791 - Train Loss: 0.071036, Train Acc: 0.892308 | Val Loss: 0.108086, Val Acc: 0.814433\n",
      "Epoch 25792 - Train Loss: 0.071035, Train Acc: 0.892308 | Val Loss: 0.108086, Val Acc: 0.814433\n",
      "Epoch 25793 - Train Loss: 0.071034, Train Acc: 0.892308 | Val Loss: 0.108086, Val Acc: 0.814433\n",
      "Epoch 25794 - Train Loss: 0.071032, Train Acc: 0.892308 | Val Loss: 0.108086, Val Acc: 0.814433\n",
      "Epoch 25795 - Train Loss: 0.071031, Train Acc: 0.892308 | Val Loss: 0.108086, Val Acc: 0.814433\n",
      "Epoch 25796 - Train Loss: 0.071029, Train Acc: 0.892308 | Val Loss: 0.108085, Val Acc: 0.814433\n",
      "Epoch 25797 - Train Loss: 0.071028, Train Acc: 0.892308 | Val Loss: 0.108085, Val Acc: 0.814433\n",
      "Epoch 25798 - Train Loss: 0.071026, Train Acc: 0.892308 | Val Loss: 0.108085, Val Acc: 0.814433\n",
      "Epoch 25799 - Train Loss: 0.071025, Train Acc: 0.892308 | Val Loss: 0.108085, Val Acc: 0.814433\n",
      "Epoch 25800 - Train Loss: 0.071024, Train Acc: 0.892308 | Val Loss: 0.108085, Val Acc: 0.814433\n",
      "Epoch 25801 - Train Loss: 0.071022, Train Acc: 0.892308 | Val Loss: 0.108085, Val Acc: 0.814433\n",
      "Epoch 25802 - Train Loss: 0.071021, Train Acc: 0.892308 | Val Loss: 0.108084, Val Acc: 0.814433\n",
      "Epoch 25803 - Train Loss: 0.071019, Train Acc: 0.892308 | Val Loss: 0.108084, Val Acc: 0.814433\n",
      "Epoch 25804 - Train Loss: 0.071018, Train Acc: 0.892308 | Val Loss: 0.108084, Val Acc: 0.814433\n",
      "Epoch 25805 - Train Loss: 0.071017, Train Acc: 0.892308 | Val Loss: 0.108084, Val Acc: 0.814433\n",
      "Epoch 25806 - Train Loss: 0.071015, Train Acc: 0.892308 | Val Loss: 0.108084, Val Acc: 0.814433\n",
      "Epoch 25807 - Train Loss: 0.071014, Train Acc: 0.892308 | Val Loss: 0.108084, Val Acc: 0.814433\n",
      "Epoch 25808 - Train Loss: 0.071012, Train Acc: 0.892308 | Val Loss: 0.108083, Val Acc: 0.814433\n",
      "Epoch 25809 - Train Loss: 0.071011, Train Acc: 0.892308 | Val Loss: 0.108083, Val Acc: 0.814433\n",
      "Epoch 25810 - Train Loss: 0.071010, Train Acc: 0.892308 | Val Loss: 0.108083, Val Acc: 0.814433\n",
      "Epoch 25811 - Train Loss: 0.071008, Train Acc: 0.892308 | Val Loss: 0.108083, Val Acc: 0.814433\n",
      "Epoch 25812 - Train Loss: 0.071007, Train Acc: 0.892308 | Val Loss: 0.108083, Val Acc: 0.814433\n",
      "Epoch 25813 - Train Loss: 0.071005, Train Acc: 0.892308 | Val Loss: 0.108082, Val Acc: 0.814433\n",
      "Epoch 25814 - Train Loss: 0.071004, Train Acc: 0.892308 | Val Loss: 0.108082, Val Acc: 0.814433\n",
      "Epoch 25815 - Train Loss: 0.071003, Train Acc: 0.892308 | Val Loss: 0.108082, Val Acc: 0.814433\n",
      "Epoch 25816 - Train Loss: 0.071001, Train Acc: 0.892308 | Val Loss: 0.108082, Val Acc: 0.814433\n",
      "Epoch 25817 - Train Loss: 0.071000, Train Acc: 0.892308 | Val Loss: 0.108082, Val Acc: 0.814433\n",
      "Epoch 25818 - Train Loss: 0.070998, Train Acc: 0.892308 | Val Loss: 0.108082, Val Acc: 0.814433\n",
      "Epoch 25819 - Train Loss: 0.070997, Train Acc: 0.892308 | Val Loss: 0.108081, Val Acc: 0.814433\n",
      "Epoch 25820 - Train Loss: 0.070996, Train Acc: 0.892308 | Val Loss: 0.108081, Val Acc: 0.814433\n",
      "Epoch 25821 - Train Loss: 0.070994, Train Acc: 0.892308 | Val Loss: 0.108081, Val Acc: 0.814433\n",
      "Epoch 25822 - Train Loss: 0.070993, Train Acc: 0.892308 | Val Loss: 0.108081, Val Acc: 0.814433\n",
      "Epoch 25823 - Train Loss: 0.070991, Train Acc: 0.892308 | Val Loss: 0.108081, Val Acc: 0.814433\n",
      "Epoch 25824 - Train Loss: 0.070990, Train Acc: 0.892308 | Val Loss: 0.108081, Val Acc: 0.814433\n",
      "Epoch 25825 - Train Loss: 0.070988, Train Acc: 0.892308 | Val Loss: 0.108080, Val Acc: 0.814433\n",
      "Epoch 25826 - Train Loss: 0.070987, Train Acc: 0.892308 | Val Loss: 0.108080, Val Acc: 0.814433\n",
      "Epoch 25827 - Train Loss: 0.070986, Train Acc: 0.892308 | Val Loss: 0.108080, Val Acc: 0.814433\n",
      "Epoch 25828 - Train Loss: 0.070984, Train Acc: 0.892308 | Val Loss: 0.108080, Val Acc: 0.814433\n",
      "Epoch 25829 - Train Loss: 0.070983, Train Acc: 0.892308 | Val Loss: 0.108080, Val Acc: 0.814433\n",
      "Epoch 25830 - Train Loss: 0.070981, Train Acc: 0.892308 | Val Loss: 0.108080, Val Acc: 0.814433\n",
      "Epoch 25831 - Train Loss: 0.070980, Train Acc: 0.892308 | Val Loss: 0.108079, Val Acc: 0.814433\n",
      "Epoch 25832 - Train Loss: 0.070979, Train Acc: 0.892308 | Val Loss: 0.108079, Val Acc: 0.814433\n",
      "Epoch 25833 - Train Loss: 0.070977, Train Acc: 0.892308 | Val Loss: 0.108079, Val Acc: 0.814433\n",
      "Epoch 25834 - Train Loss: 0.070976, Train Acc: 0.892308 | Val Loss: 0.108079, Val Acc: 0.814433\n",
      "Epoch 25835 - Train Loss: 0.070974, Train Acc: 0.892308 | Val Loss: 0.108079, Val Acc: 0.814433\n",
      "Epoch 25836 - Train Loss: 0.070973, Train Acc: 0.892308 | Val Loss: 0.108079, Val Acc: 0.814433\n",
      "Epoch 25837 - Train Loss: 0.070972, Train Acc: 0.892308 | Val Loss: 0.108078, Val Acc: 0.814433\n",
      "Epoch 25838 - Train Loss: 0.070970, Train Acc: 0.892308 | Val Loss: 0.108078, Val Acc: 0.814433\n",
      "Epoch 25839 - Train Loss: 0.070969, Train Acc: 0.892308 | Val Loss: 0.108078, Val Acc: 0.814433\n",
      "Epoch 25840 - Train Loss: 0.070967, Train Acc: 0.892308 | Val Loss: 0.108078, Val Acc: 0.814433\n",
      "Epoch 25841 - Train Loss: 0.070966, Train Acc: 0.892308 | Val Loss: 0.108078, Val Acc: 0.814433\n",
      "Epoch 25842 - Train Loss: 0.070965, Train Acc: 0.892308 | Val Loss: 0.108078, Val Acc: 0.814433\n",
      "Epoch 25843 - Train Loss: 0.070963, Train Acc: 0.892308 | Val Loss: 0.108077, Val Acc: 0.814433\n",
      "Epoch 25844 - Train Loss: 0.070962, Train Acc: 0.892308 | Val Loss: 0.108077, Val Acc: 0.814433\n",
      "Epoch 25845 - Train Loss: 0.070960, Train Acc: 0.892308 | Val Loss: 0.108077, Val Acc: 0.814433\n",
      "Epoch 25846 - Train Loss: 0.070959, Train Acc: 0.892308 | Val Loss: 0.108077, Val Acc: 0.814433\n",
      "Epoch 25847 - Train Loss: 0.070958, Train Acc: 0.892308 | Val Loss: 0.108077, Val Acc: 0.814433\n",
      "Epoch 25848 - Train Loss: 0.070956, Train Acc: 0.892308 | Val Loss: 0.108077, Val Acc: 0.814433\n",
      "Epoch 25849 - Train Loss: 0.070955, Train Acc: 0.892308 | Val Loss: 0.108076, Val Acc: 0.814433\n",
      "Epoch 25850 - Train Loss: 0.070953, Train Acc: 0.892308 | Val Loss: 0.108076, Val Acc: 0.814433\n",
      "Epoch 25851 - Train Loss: 0.070952, Train Acc: 0.892308 | Val Loss: 0.108076, Val Acc: 0.814433\n",
      "Epoch 25852 - Train Loss: 0.070951, Train Acc: 0.892308 | Val Loss: 0.108076, Val Acc: 0.814433\n",
      "Epoch 25853 - Train Loss: 0.070949, Train Acc: 0.892308 | Val Loss: 0.108076, Val Acc: 0.814433\n",
      "Epoch 25854 - Train Loss: 0.070948, Train Acc: 0.892308 | Val Loss: 0.108076, Val Acc: 0.814433\n",
      "Epoch 25855 - Train Loss: 0.070946, Train Acc: 0.892308 | Val Loss: 0.108075, Val Acc: 0.814433\n",
      "Epoch 25856 - Train Loss: 0.070945, Train Acc: 0.892308 | Val Loss: 0.108075, Val Acc: 0.814433\n",
      "Epoch 25857 - Train Loss: 0.070944, Train Acc: 0.892308 | Val Loss: 0.108075, Val Acc: 0.814433\n",
      "Epoch 25858 - Train Loss: 0.070942, Train Acc: 0.892308 | Val Loss: 0.108075, Val Acc: 0.814433\n",
      "Epoch 25859 - Train Loss: 0.070941, Train Acc: 0.892308 | Val Loss: 0.108075, Val Acc: 0.814433\n",
      "Epoch 25860 - Train Loss: 0.070939, Train Acc: 0.892308 | Val Loss: 0.108075, Val Acc: 0.814433\n",
      "Epoch 25861 - Train Loss: 0.070938, Train Acc: 0.892308 | Val Loss: 0.108074, Val Acc: 0.814433\n",
      "Epoch 25862 - Train Loss: 0.070937, Train Acc: 0.892308 | Val Loss: 0.108074, Val Acc: 0.814433\n",
      "Epoch 25863 - Train Loss: 0.070935, Train Acc: 0.892308 | Val Loss: 0.108074, Val Acc: 0.814433\n",
      "Epoch 25864 - Train Loss: 0.070934, Train Acc: 0.892308 | Val Loss: 0.108074, Val Acc: 0.814433\n",
      "Epoch 25865 - Train Loss: 0.070932, Train Acc: 0.892308 | Val Loss: 0.108074, Val Acc: 0.814433\n",
      "Epoch 25866 - Train Loss: 0.070931, Train Acc: 0.892308 | Val Loss: 0.108074, Val Acc: 0.814433\n",
      "Epoch 25867 - Train Loss: 0.070930, Train Acc: 0.892308 | Val Loss: 0.108073, Val Acc: 0.814433\n",
      "Epoch 25868 - Train Loss: 0.070928, Train Acc: 0.892308 | Val Loss: 0.108073, Val Acc: 0.814433\n",
      "Epoch 25869 - Train Loss: 0.070927, Train Acc: 0.892308 | Val Loss: 0.108073, Val Acc: 0.814433\n",
      "Epoch 25870 - Train Loss: 0.070925, Train Acc: 0.892308 | Val Loss: 0.108073, Val Acc: 0.814433\n",
      "Epoch 25871 - Train Loss: 0.070924, Train Acc: 0.892308 | Val Loss: 0.108073, Val Acc: 0.814433\n",
      "Epoch 25872 - Train Loss: 0.070923, Train Acc: 0.892308 | Val Loss: 0.108073, Val Acc: 0.814433\n",
      "Epoch 25873 - Train Loss: 0.070921, Train Acc: 0.892308 | Val Loss: 0.108072, Val Acc: 0.814433\n",
      "Epoch 25874 - Train Loss: 0.070920, Train Acc: 0.892308 | Val Loss: 0.108072, Val Acc: 0.814433\n",
      "Epoch 25875 - Train Loss: 0.070918, Train Acc: 0.892308 | Val Loss: 0.108072, Val Acc: 0.814433\n",
      "Epoch 25876 - Train Loss: 0.070917, Train Acc: 0.892308 | Val Loss: 0.108072, Val Acc: 0.814433\n",
      "Epoch 25877 - Train Loss: 0.070916, Train Acc: 0.892308 | Val Loss: 0.108072, Val Acc: 0.814433\n",
      "Epoch 25878 - Train Loss: 0.070914, Train Acc: 0.892308 | Val Loss: 0.108072, Val Acc: 0.814433\n",
      "Epoch 25879 - Train Loss: 0.070913, Train Acc: 0.892308 | Val Loss: 0.108071, Val Acc: 0.814433\n",
      "Epoch 25880 - Train Loss: 0.070911, Train Acc: 0.892308 | Val Loss: 0.108071, Val Acc: 0.814433\n",
      "Epoch 25881 - Train Loss: 0.070910, Train Acc: 0.892308 | Val Loss: 0.108071, Val Acc: 0.814433\n",
      "Epoch 25882 - Train Loss: 0.070909, Train Acc: 0.892308 | Val Loss: 0.108071, Val Acc: 0.814433\n",
      "Epoch 25883 - Train Loss: 0.070907, Train Acc: 0.892308 | Val Loss: 0.108071, Val Acc: 0.814433\n",
      "Epoch 25884 - Train Loss: 0.070906, Train Acc: 0.892308 | Val Loss: 0.108071, Val Acc: 0.814433\n",
      "Epoch 25885 - Train Loss: 0.070904, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25886 - Train Loss: 0.070903, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25887 - Train Loss: 0.070902, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25888 - Train Loss: 0.070900, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25889 - Train Loss: 0.070899, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25890 - Train Loss: 0.070897, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25891 - Train Loss: 0.070896, Train Acc: 0.892308 | Val Loss: 0.108070, Val Acc: 0.814433\n",
      "Epoch 25892 - Train Loss: 0.070895, Train Acc: 0.892308 | Val Loss: 0.108069, Val Acc: 0.814433\n",
      "Epoch 25893 - Train Loss: 0.070893, Train Acc: 0.892308 | Val Loss: 0.108069, Val Acc: 0.814433\n",
      "Epoch 25894 - Train Loss: 0.070892, Train Acc: 0.892308 | Val Loss: 0.108069, Val Acc: 0.814433\n",
      "Epoch 25895 - Train Loss: 0.070890, Train Acc: 0.892308 | Val Loss: 0.108069, Val Acc: 0.814433\n",
      "Epoch 25896 - Train Loss: 0.070889, Train Acc: 0.892308 | Val Loss: 0.108069, Val Acc: 0.814433\n",
      "Epoch 25897 - Train Loss: 0.070888, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25898 - Train Loss: 0.070886, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25899 - Train Loss: 0.070885, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25900 - Train Loss: 0.070883, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25901 - Train Loss: 0.070882, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25902 - Train Loss: 0.070881, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25903 - Train Loss: 0.070879, Train Acc: 0.892308 | Val Loss: 0.108068, Val Acc: 0.814433\n",
      "Epoch 25904 - Train Loss: 0.070878, Train Acc: 0.892308 | Val Loss: 0.108067, Val Acc: 0.814433\n",
      "Epoch 25905 - Train Loss: 0.070876, Train Acc: 0.892308 | Val Loss: 0.108067, Val Acc: 0.814433\n",
      "Epoch 25906 - Train Loss: 0.070875, Train Acc: 0.892308 | Val Loss: 0.108067, Val Acc: 0.814433\n",
      "Epoch 25907 - Train Loss: 0.070874, Train Acc: 0.892308 | Val Loss: 0.108067, Val Acc: 0.814433\n",
      "Epoch 25908 - Train Loss: 0.070872, Train Acc: 0.892308 | Val Loss: 0.108067, Val Acc: 0.814433\n",
      "Epoch 25909 - Train Loss: 0.070871, Train Acc: 0.892308 | Val Loss: 0.108067, Val Acc: 0.814433\n",
      "Epoch 25910 - Train Loss: 0.070869, Train Acc: 0.892308 | Val Loss: 0.108066, Val Acc: 0.814433\n",
      "Epoch 25911 - Train Loss: 0.070868, Train Acc: 0.892308 | Val Loss: 0.108066, Val Acc: 0.814433\n",
      "Epoch 25912 - Train Loss: 0.070867, Train Acc: 0.892308 | Val Loss: 0.108066, Val Acc: 0.814433\n",
      "Epoch 25913 - Train Loss: 0.070865, Train Acc: 0.892308 | Val Loss: 0.108066, Val Acc: 0.814433\n",
      "Epoch 25914 - Train Loss: 0.070864, Train Acc: 0.892308 | Val Loss: 0.108066, Val Acc: 0.814433\n",
      "Epoch 25915 - Train Loss: 0.070862, Train Acc: 0.892308 | Val Loss: 0.108066, Val Acc: 0.814433\n",
      "Epoch 25916 - Train Loss: 0.070861, Train Acc: 0.892308 | Val Loss: 0.108065, Val Acc: 0.814433\n",
      "Epoch 25917 - Train Loss: 0.070860, Train Acc: 0.892308 | Val Loss: 0.108065, Val Acc: 0.814433\n",
      "Epoch 25918 - Train Loss: 0.070858, Train Acc: 0.892308 | Val Loss: 0.108065, Val Acc: 0.814433\n",
      "Epoch 25919 - Train Loss: 0.070857, Train Acc: 0.892308 | Val Loss: 0.108065, Val Acc: 0.814433\n",
      "Epoch 25920 - Train Loss: 0.070855, Train Acc: 0.892308 | Val Loss: 0.108065, Val Acc: 0.814433\n",
      "Epoch 25921 - Train Loss: 0.070854, Train Acc: 0.892308 | Val Loss: 0.108065, Val Acc: 0.814433\n",
      "Epoch 25922 - Train Loss: 0.070853, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25923 - Train Loss: 0.070851, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25924 - Train Loss: 0.070850, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25925 - Train Loss: 0.070848, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25926 - Train Loss: 0.070847, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25927 - Train Loss: 0.070846, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25928 - Train Loss: 0.070844, Train Acc: 0.892308 | Val Loss: 0.108064, Val Acc: 0.814433\n",
      "Epoch 25929 - Train Loss: 0.070843, Train Acc: 0.892308 | Val Loss: 0.108063, Val Acc: 0.814433\n",
      "Epoch 25930 - Train Loss: 0.070841, Train Acc: 0.892308 | Val Loss: 0.108063, Val Acc: 0.814433\n",
      "Epoch 25931 - Train Loss: 0.070840, Train Acc: 0.892308 | Val Loss: 0.108063, Val Acc: 0.814433\n",
      "Epoch 25932 - Train Loss: 0.070839, Train Acc: 0.892308 | Val Loss: 0.108063, Val Acc: 0.814433\n",
      "Epoch 25933 - Train Loss: 0.070837, Train Acc: 0.892308 | Val Loss: 0.108063, Val Acc: 0.814433\n",
      "Epoch 25934 - Train Loss: 0.070836, Train Acc: 0.892308 | Val Loss: 0.108063, Val Acc: 0.814433\n",
      "Epoch 25935 - Train Loss: 0.070835, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25936 - Train Loss: 0.070833, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25937 - Train Loss: 0.070832, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25938 - Train Loss: 0.070830, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25939 - Train Loss: 0.070829, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25940 - Train Loss: 0.070828, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25941 - Train Loss: 0.070826, Train Acc: 0.892308 | Val Loss: 0.108062, Val Acc: 0.814433\n",
      "Epoch 25942 - Train Loss: 0.070825, Train Acc: 0.892308 | Val Loss: 0.108061, Val Acc: 0.814433\n",
      "Epoch 25943 - Train Loss: 0.070823, Train Acc: 0.892308 | Val Loss: 0.108061, Val Acc: 0.814433\n",
      "Epoch 25944 - Train Loss: 0.070822, Train Acc: 0.892308 | Val Loss: 0.108061, Val Acc: 0.814433\n",
      "Epoch 25945 - Train Loss: 0.070821, Train Acc: 0.892308 | Val Loss: 0.108061, Val Acc: 0.814433\n",
      "Epoch 25946 - Train Loss: 0.070819, Train Acc: 0.892308 | Val Loss: 0.108061, Val Acc: 0.814433\n",
      "Epoch 25947 - Train Loss: 0.070818, Train Acc: 0.892308 | Val Loss: 0.108061, Val Acc: 0.814433\n",
      "Epoch 25948 - Train Loss: 0.070816, Train Acc: 0.892308 | Val Loss: 0.108060, Val Acc: 0.814433\n",
      "Epoch 25949 - Train Loss: 0.070815, Train Acc: 0.892308 | Val Loss: 0.108060, Val Acc: 0.814433\n",
      "Epoch 25950 - Train Loss: 0.070814, Train Acc: 0.892308 | Val Loss: 0.108060, Val Acc: 0.814433\n",
      "Epoch 25951 - Train Loss: 0.070812, Train Acc: 0.892308 | Val Loss: 0.108060, Val Acc: 0.814433\n",
      "Epoch 25952 - Train Loss: 0.070811, Train Acc: 0.892308 | Val Loss: 0.108060, Val Acc: 0.814433\n",
      "Epoch 25953 - Train Loss: 0.070809, Train Acc: 0.892308 | Val Loss: 0.108060, Val Acc: 0.814433\n",
      "Epoch 25954 - Train Loss: 0.070808, Train Acc: 0.892308 | Val Loss: 0.108059, Val Acc: 0.814433\n",
      "Epoch 25955 - Train Loss: 0.070807, Train Acc: 0.892308 | Val Loss: 0.108059, Val Acc: 0.814433\n",
      "Epoch 25956 - Train Loss: 0.070805, Train Acc: 0.892308 | Val Loss: 0.108059, Val Acc: 0.814433\n",
      "Epoch 25957 - Train Loss: 0.070804, Train Acc: 0.892308 | Val Loss: 0.108059, Val Acc: 0.814433\n",
      "Epoch 25958 - Train Loss: 0.070802, Train Acc: 0.892308 | Val Loss: 0.108059, Val Acc: 0.814433\n",
      "Epoch 25959 - Train Loss: 0.070801, Train Acc: 0.892308 | Val Loss: 0.108059, Val Acc: 0.814433\n",
      "Epoch 25960 - Train Loss: 0.070800, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25961 - Train Loss: 0.070798, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25962 - Train Loss: 0.070797, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25963 - Train Loss: 0.070796, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25964 - Train Loss: 0.070794, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25965 - Train Loss: 0.070793, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25966 - Train Loss: 0.070791, Train Acc: 0.892308 | Val Loss: 0.108058, Val Acc: 0.814433\n",
      "Epoch 25967 - Train Loss: 0.070790, Train Acc: 0.892308 | Val Loss: 0.108057, Val Acc: 0.814433\n",
      "Epoch 25968 - Train Loss: 0.070789, Train Acc: 0.892308 | Val Loss: 0.108057, Val Acc: 0.814433\n",
      "Epoch 25969 - Train Loss: 0.070787, Train Acc: 0.892308 | Val Loss: 0.108057, Val Acc: 0.814433\n",
      "Epoch 25970 - Train Loss: 0.070786, Train Acc: 0.892308 | Val Loss: 0.108057, Val Acc: 0.814433\n",
      "Epoch 25971 - Train Loss: 0.070784, Train Acc: 0.892308 | Val Loss: 0.108057, Val Acc: 0.814433\n",
      "Epoch 25972 - Train Loss: 0.070783, Train Acc: 0.892308 | Val Loss: 0.108057, Val Acc: 0.814433\n",
      "Epoch 25973 - Train Loss: 0.070782, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25974 - Train Loss: 0.070780, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25975 - Train Loss: 0.070779, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25976 - Train Loss: 0.070777, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25977 - Train Loss: 0.070776, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25978 - Train Loss: 0.070775, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25979 - Train Loss: 0.070773, Train Acc: 0.892308 | Val Loss: 0.108056, Val Acc: 0.814433\n",
      "Epoch 25980 - Train Loss: 0.070772, Train Acc: 0.892308 | Val Loss: 0.108055, Val Acc: 0.814433\n",
      "Epoch 25981 - Train Loss: 0.070770, Train Acc: 0.892308 | Val Loss: 0.108055, Val Acc: 0.814433\n",
      "Epoch 25982 - Train Loss: 0.070769, Train Acc: 0.892308 | Val Loss: 0.108055, Val Acc: 0.814433\n",
      "Epoch 25983 - Train Loss: 0.070768, Train Acc: 0.892308 | Val Loss: 0.108055, Val Acc: 0.814433\n",
      "Epoch 25984 - Train Loss: 0.070766, Train Acc: 0.892308 | Val Loss: 0.108055, Val Acc: 0.814433\n",
      "Epoch 25985 - Train Loss: 0.070765, Train Acc: 0.892308 | Val Loss: 0.108055, Val Acc: 0.814433\n",
      "Epoch 25986 - Train Loss: 0.070764, Train Acc: 0.892308 | Val Loss: 0.108054, Val Acc: 0.814433\n",
      "Epoch 25987 - Train Loss: 0.070762, Train Acc: 0.892308 | Val Loss: 0.108054, Val Acc: 0.814433\n",
      "Epoch 25988 - Train Loss: 0.070761, Train Acc: 0.892308 | Val Loss: 0.108054, Val Acc: 0.814433\n",
      "Epoch 25989 - Train Loss: 0.070759, Train Acc: 0.892308 | Val Loss: 0.108054, Val Acc: 0.814433\n",
      "Epoch 25990 - Train Loss: 0.070758, Train Acc: 0.892308 | Val Loss: 0.108054, Val Acc: 0.814433\n",
      "Epoch 25991 - Train Loss: 0.070757, Train Acc: 0.892308 | Val Loss: 0.108054, Val Acc: 0.814433\n",
      "Epoch 25992 - Train Loss: 0.070755, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25993 - Train Loss: 0.070754, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25994 - Train Loss: 0.070752, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25995 - Train Loss: 0.070751, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25996 - Train Loss: 0.070750, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25997 - Train Loss: 0.070748, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25998 - Train Loss: 0.070747, Train Acc: 0.892308 | Val Loss: 0.108053, Val Acc: 0.814433\n",
      "Epoch 25999 - Train Loss: 0.070745, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26000 - Train Loss: 0.070744, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26001 - Train Loss: 0.070743, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26002 - Train Loss: 0.070741, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26003 - Train Loss: 0.070740, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26004 - Train Loss: 0.070739, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26005 - Train Loss: 0.070737, Train Acc: 0.892308 | Val Loss: 0.108052, Val Acc: 0.814433\n",
      "Epoch 26006 - Train Loss: 0.070736, Train Acc: 0.892308 | Val Loss: 0.108051, Val Acc: 0.814433\n",
      "Epoch 26007 - Train Loss: 0.070734, Train Acc: 0.892308 | Val Loss: 0.108051, Val Acc: 0.814433\n",
      "Epoch 26008 - Train Loss: 0.070733, Train Acc: 0.892308 | Val Loss: 0.108051, Val Acc: 0.814433\n",
      "Epoch 26009 - Train Loss: 0.070732, Train Acc: 0.892308 | Val Loss: 0.108051, Val Acc: 0.814433\n",
      "Epoch 26010 - Train Loss: 0.070730, Train Acc: 0.892308 | Val Loss: 0.108051, Val Acc: 0.814433\n",
      "Epoch 26011 - Train Loss: 0.070729, Train Acc: 0.892308 | Val Loss: 0.108051, Val Acc: 0.814433\n",
      "Epoch 26012 - Train Loss: 0.070727, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26013 - Train Loss: 0.070726, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26014 - Train Loss: 0.070725, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26015 - Train Loss: 0.070723, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26016 - Train Loss: 0.070722, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26017 - Train Loss: 0.070720, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26018 - Train Loss: 0.070719, Train Acc: 0.892308 | Val Loss: 0.108050, Val Acc: 0.814433\n",
      "Epoch 26019 - Train Loss: 0.070718, Train Acc: 0.892308 | Val Loss: 0.108049, Val Acc: 0.814433\n",
      "Epoch 26020 - Train Loss: 0.070716, Train Acc: 0.892308 | Val Loss: 0.108049, Val Acc: 0.814433\n",
      "Epoch 26021 - Train Loss: 0.070715, Train Acc: 0.892308 | Val Loss: 0.108049, Val Acc: 0.814433\n",
      "Epoch 26022 - Train Loss: 0.070714, Train Acc: 0.892308 | Val Loss: 0.108049, Val Acc: 0.814433\n",
      "Epoch 26023 - Train Loss: 0.070712, Train Acc: 0.892308 | Val Loss: 0.108049, Val Acc: 0.814433\n",
      "Epoch 26024 - Train Loss: 0.070711, Train Acc: 0.892308 | Val Loss: 0.108049, Val Acc: 0.814433\n",
      "Epoch 26025 - Train Loss: 0.070709, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26026 - Train Loss: 0.070708, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26027 - Train Loss: 0.070707, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26028 - Train Loss: 0.070705, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26029 - Train Loss: 0.070704, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26030 - Train Loss: 0.070702, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26031 - Train Loss: 0.070701, Train Acc: 0.892308 | Val Loss: 0.108048, Val Acc: 0.814433\n",
      "Epoch 26032 - Train Loss: 0.070700, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26033 - Train Loss: 0.070698, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26034 - Train Loss: 0.070697, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26035 - Train Loss: 0.070696, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26036 - Train Loss: 0.070694, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26037 - Train Loss: 0.070693, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26038 - Train Loss: 0.070691, Train Acc: 0.892308 | Val Loss: 0.108047, Val Acc: 0.814433\n",
      "Epoch 26039 - Train Loss: 0.070690, Train Acc: 0.892308 | Val Loss: 0.108046, Val Acc: 0.814433\n",
      "Epoch 26040 - Train Loss: 0.070689, Train Acc: 0.892308 | Val Loss: 0.108046, Val Acc: 0.814433\n",
      "Epoch 26041 - Train Loss: 0.070687, Train Acc: 0.892308 | Val Loss: 0.108046, Val Acc: 0.814433\n",
      "Epoch 26042 - Train Loss: 0.070686, Train Acc: 0.892308 | Val Loss: 0.108046, Val Acc: 0.814433\n",
      "Epoch 26043 - Train Loss: 0.070684, Train Acc: 0.892308 | Val Loss: 0.108046, Val Acc: 0.814433\n",
      "Epoch 26044 - Train Loss: 0.070683, Train Acc: 0.892308 | Val Loss: 0.108046, Val Acc: 0.814433\n",
      "Epoch 26045 - Train Loss: 0.070682, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26046 - Train Loss: 0.070680, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26047 - Train Loss: 0.070679, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26048 - Train Loss: 0.070678, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26049 - Train Loss: 0.070676, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26050 - Train Loss: 0.070675, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26051 - Train Loss: 0.070673, Train Acc: 0.892308 | Val Loss: 0.108045, Val Acc: 0.814433\n",
      "Epoch 26052 - Train Loss: 0.070672, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26053 - Train Loss: 0.070671, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26054 - Train Loss: 0.070669, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26055 - Train Loss: 0.070668, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26056 - Train Loss: 0.070666, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26057 - Train Loss: 0.070665, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26058 - Train Loss: 0.070664, Train Acc: 0.892308 | Val Loss: 0.108044, Val Acc: 0.814433\n",
      "Epoch 26059 - Train Loss: 0.070662, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26060 - Train Loss: 0.070661, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26061 - Train Loss: 0.070660, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26062 - Train Loss: 0.070658, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26063 - Train Loss: 0.070657, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26064 - Train Loss: 0.070655, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26065 - Train Loss: 0.070654, Train Acc: 0.892308 | Val Loss: 0.108043, Val Acc: 0.814433\n",
      "Epoch 26066 - Train Loss: 0.070653, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26067 - Train Loss: 0.070651, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26068 - Train Loss: 0.070650, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26069 - Train Loss: 0.070648, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26070 - Train Loss: 0.070647, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26071 - Train Loss: 0.070646, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26072 - Train Loss: 0.070644, Train Acc: 0.892308 | Val Loss: 0.108042, Val Acc: 0.814433\n",
      "Epoch 26073 - Train Loss: 0.070643, Train Acc: 0.892308 | Val Loss: 0.108041, Val Acc: 0.814433\n",
      "Epoch 26074 - Train Loss: 0.070642, Train Acc: 0.892308 | Val Loss: 0.108041, Val Acc: 0.814433\n",
      "Epoch 26075 - Train Loss: 0.070640, Train Acc: 0.892308 | Val Loss: 0.108041, Val Acc: 0.814433\n",
      "Epoch 26076 - Train Loss: 0.070639, Train Acc: 0.892308 | Val Loss: 0.108041, Val Acc: 0.814433\n",
      "Epoch 26077 - Train Loss: 0.070637, Train Acc: 0.892308 | Val Loss: 0.108041, Val Acc: 0.814433\n",
      "Epoch 26078 - Train Loss: 0.070636, Train Acc: 0.892308 | Val Loss: 0.108041, Val Acc: 0.814433\n",
      "Epoch 26079 - Train Loss: 0.070635, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26080 - Train Loss: 0.070633, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26081 - Train Loss: 0.070632, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26082 - Train Loss: 0.070631, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26083 - Train Loss: 0.070629, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26084 - Train Loss: 0.070628, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26085 - Train Loss: 0.070626, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26086 - Train Loss: 0.070625, Train Acc: 0.892308 | Val Loss: 0.108040, Val Acc: 0.814433\n",
      "Epoch 26087 - Train Loss: 0.070624, Train Acc: 0.892308 | Val Loss: 0.108039, Val Acc: 0.814433\n",
      "Epoch 26088 - Train Loss: 0.070622, Train Acc: 0.892308 | Val Loss: 0.108039, Val Acc: 0.814433\n",
      "Epoch 26089 - Train Loss: 0.070621, Train Acc: 0.892308 | Val Loss: 0.108039, Val Acc: 0.814433\n",
      "Epoch 26090 - Train Loss: 0.070619, Train Acc: 0.892308 | Val Loss: 0.108039, Val Acc: 0.814433\n",
      "Epoch 26091 - Train Loss: 0.070618, Train Acc: 0.892308 | Val Loss: 0.108039, Val Acc: 0.814433\n",
      "Epoch 26092 - Train Loss: 0.070617, Train Acc: 0.892308 | Val Loss: 0.108039, Val Acc: 0.814433\n",
      "Epoch 26093 - Train Loss: 0.070615, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26094 - Train Loss: 0.070614, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26095 - Train Loss: 0.070613, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26096 - Train Loss: 0.070611, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26097 - Train Loss: 0.070610, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26098 - Train Loss: 0.070608, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26099 - Train Loss: 0.070607, Train Acc: 0.892308 | Val Loss: 0.108038, Val Acc: 0.814433\n",
      "Epoch 26100 - Train Loss: 0.070606, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26101 - Train Loss: 0.070604, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26102 - Train Loss: 0.070603, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26103 - Train Loss: 0.070602, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26104 - Train Loss: 0.070600, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26105 - Train Loss: 0.070599, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26106 - Train Loss: 0.070597, Train Acc: 0.892308 | Val Loss: 0.108037, Val Acc: 0.814433\n",
      "Epoch 26107 - Train Loss: 0.070596, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26108 - Train Loss: 0.070595, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26109 - Train Loss: 0.070593, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26110 - Train Loss: 0.070592, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26111 - Train Loss: 0.070591, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26112 - Train Loss: 0.070589, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26113 - Train Loss: 0.070588, Train Acc: 0.892308 | Val Loss: 0.108036, Val Acc: 0.814433\n",
      "Epoch 26114 - Train Loss: 0.070586, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26115 - Train Loss: 0.070585, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26116 - Train Loss: 0.070584, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26117 - Train Loss: 0.070582, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26118 - Train Loss: 0.070581, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26119 - Train Loss: 0.070580, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26120 - Train Loss: 0.070578, Train Acc: 0.892308 | Val Loss: 0.108035, Val Acc: 0.814433\n",
      "Epoch 26121 - Train Loss: 0.070577, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26122 - Train Loss: 0.070575, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26123 - Train Loss: 0.070574, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26124 - Train Loss: 0.070573, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26125 - Train Loss: 0.070571, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26126 - Train Loss: 0.070570, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26127 - Train Loss: 0.070568, Train Acc: 0.892308 | Val Loss: 0.108034, Val Acc: 0.814433\n",
      "Epoch 26128 - Train Loss: 0.070567, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26129 - Train Loss: 0.070566, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26130 - Train Loss: 0.070564, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26131 - Train Loss: 0.070563, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26132 - Train Loss: 0.070562, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26133 - Train Loss: 0.070560, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26134 - Train Loss: 0.070559, Train Acc: 0.892308 | Val Loss: 0.108033, Val Acc: 0.814433\n",
      "Epoch 26135 - Train Loss: 0.070557, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26136 - Train Loss: 0.070556, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26137 - Train Loss: 0.070555, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26138 - Train Loss: 0.070553, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26139 - Train Loss: 0.070552, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26140 - Train Loss: 0.070551, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26141 - Train Loss: 0.070549, Train Acc: 0.892308 | Val Loss: 0.108032, Val Acc: 0.814433\n",
      "Epoch 26142 - Train Loss: 0.070548, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26143 - Train Loss: 0.070546, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26144 - Train Loss: 0.070545, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26145 - Train Loss: 0.070544, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26146 - Train Loss: 0.070542, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26147 - Train Loss: 0.070541, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26148 - Train Loss: 0.070540, Train Acc: 0.892308 | Val Loss: 0.108031, Val Acc: 0.814433\n",
      "Epoch 26149 - Train Loss: 0.070538, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26150 - Train Loss: 0.070537, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26151 - Train Loss: 0.070535, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26152 - Train Loss: 0.070534, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26153 - Train Loss: 0.070533, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26154 - Train Loss: 0.070531, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26155 - Train Loss: 0.070530, Train Acc: 0.892308 | Val Loss: 0.108030, Val Acc: 0.814433\n",
      "Epoch 26156 - Train Loss: 0.070529, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26157 - Train Loss: 0.070527, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26158 - Train Loss: 0.070526, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26159 - Train Loss: 0.070524, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26160 - Train Loss: 0.070523, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26161 - Train Loss: 0.070522, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26162 - Train Loss: 0.070520, Train Acc: 0.892308 | Val Loss: 0.108029, Val Acc: 0.814433\n",
      "Epoch 26163 - Train Loss: 0.070519, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26164 - Train Loss: 0.070518, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26165 - Train Loss: 0.070516, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26166 - Train Loss: 0.070515, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26167 - Train Loss: 0.070514, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26168 - Train Loss: 0.070512, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26169 - Train Loss: 0.070511, Train Acc: 0.892308 | Val Loss: 0.108028, Val Acc: 0.814433\n",
      "Epoch 26170 - Train Loss: 0.070509, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26171 - Train Loss: 0.070508, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26172 - Train Loss: 0.070507, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26173 - Train Loss: 0.070505, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26174 - Train Loss: 0.070504, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26175 - Train Loss: 0.070503, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26176 - Train Loss: 0.070501, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26177 - Train Loss: 0.070500, Train Acc: 0.892308 | Val Loss: 0.108027, Val Acc: 0.814433\n",
      "Epoch 26178 - Train Loss: 0.070498, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26179 - Train Loss: 0.070497, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26180 - Train Loss: 0.070496, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26181 - Train Loss: 0.070494, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26182 - Train Loss: 0.070493, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26183 - Train Loss: 0.070492, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26184 - Train Loss: 0.070490, Train Acc: 0.892308 | Val Loss: 0.108026, Val Acc: 0.814433\n",
      "Epoch 26185 - Train Loss: 0.070489, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26186 - Train Loss: 0.070487, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26187 - Train Loss: 0.070486, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26188 - Train Loss: 0.070485, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26189 - Train Loss: 0.070483, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26190 - Train Loss: 0.070482, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26191 - Train Loss: 0.070481, Train Acc: 0.892308 | Val Loss: 0.108025, Val Acc: 0.814433\n",
      "Epoch 26192 - Train Loss: 0.070479, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26193 - Train Loss: 0.070478, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26194 - Train Loss: 0.070476, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26195 - Train Loss: 0.070475, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26196 - Train Loss: 0.070474, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26197 - Train Loss: 0.070472, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26198 - Train Loss: 0.070471, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26199 - Train Loss: 0.070470, Train Acc: 0.892308 | Val Loss: 0.108024, Val Acc: 0.814433\n",
      "Epoch 26200 - Train Loss: 0.070468, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26201 - Train Loss: 0.070467, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26202 - Train Loss: 0.070466, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26203 - Train Loss: 0.070464, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26204 - Train Loss: 0.070463, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26205 - Train Loss: 0.070461, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26206 - Train Loss: 0.070460, Train Acc: 0.892308 | Val Loss: 0.108023, Val Acc: 0.814433\n",
      "Epoch 26207 - Train Loss: 0.070459, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26208 - Train Loss: 0.070457, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26209 - Train Loss: 0.070456, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26210 - Train Loss: 0.070455, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26211 - Train Loss: 0.070453, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26212 - Train Loss: 0.070452, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26213 - Train Loss: 0.070450, Train Acc: 0.892308 | Val Loss: 0.108022, Val Acc: 0.814433\n",
      "Epoch 26214 - Train Loss: 0.070449, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26215 - Train Loss: 0.070448, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26216 - Train Loss: 0.070446, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26217 - Train Loss: 0.070445, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26218 - Train Loss: 0.070444, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26219 - Train Loss: 0.070442, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26220 - Train Loss: 0.070441, Train Acc: 0.892308 | Val Loss: 0.108021, Val Acc: 0.814433\n",
      "Epoch 26221 - Train Loss: 0.070440, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26222 - Train Loss: 0.070438, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26223 - Train Loss: 0.070437, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26224 - Train Loss: 0.070435, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26225 - Train Loss: 0.070434, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26226 - Train Loss: 0.070433, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26227 - Train Loss: 0.070431, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26228 - Train Loss: 0.070430, Train Acc: 0.892308 | Val Loss: 0.108020, Val Acc: 0.814433\n",
      "Epoch 26229 - Train Loss: 0.070429, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26230 - Train Loss: 0.070427, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26231 - Train Loss: 0.070426, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26232 - Train Loss: 0.070424, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26233 - Train Loss: 0.070423, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26234 - Train Loss: 0.070422, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26235 - Train Loss: 0.070420, Train Acc: 0.892308 | Val Loss: 0.108019, Val Acc: 0.814433\n",
      "Epoch 26236 - Train Loss: 0.070419, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26237 - Train Loss: 0.070418, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26238 - Train Loss: 0.070416, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26239 - Train Loss: 0.070415, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26240 - Train Loss: 0.070414, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26241 - Train Loss: 0.070412, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26242 - Train Loss: 0.070411, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26243 - Train Loss: 0.070409, Train Acc: 0.892308 | Val Loss: 0.108018, Val Acc: 0.814433\n",
      "Epoch 26244 - Train Loss: 0.070408, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26245 - Train Loss: 0.070407, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26246 - Train Loss: 0.070405, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26247 - Train Loss: 0.070404, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26248 - Train Loss: 0.070403, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26249 - Train Loss: 0.070401, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26250 - Train Loss: 0.070400, Train Acc: 0.892308 | Val Loss: 0.108017, Val Acc: 0.814433\n",
      "Epoch 26251 - Train Loss: 0.070399, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26252 - Train Loss: 0.070397, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26253 - Train Loss: 0.070396, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26254 - Train Loss: 0.070394, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26255 - Train Loss: 0.070393, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26256 - Train Loss: 0.070392, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26257 - Train Loss: 0.070390, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26258 - Train Loss: 0.070389, Train Acc: 0.892308 | Val Loss: 0.108016, Val Acc: 0.814433\n",
      "Epoch 26259 - Train Loss: 0.070388, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26260 - Train Loss: 0.070386, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26261 - Train Loss: 0.070385, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26262 - Train Loss: 0.070383, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26263 - Train Loss: 0.070382, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26264 - Train Loss: 0.070381, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26265 - Train Loss: 0.070379, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26266 - Train Loss: 0.070378, Train Acc: 0.892308 | Val Loss: 0.108015, Val Acc: 0.814433\n",
      "Epoch 26267 - Train Loss: 0.070377, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26268 - Train Loss: 0.070375, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26269 - Train Loss: 0.070374, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26270 - Train Loss: 0.070373, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26271 - Train Loss: 0.070371, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26272 - Train Loss: 0.070370, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26273 - Train Loss: 0.070368, Train Acc: 0.892308 | Val Loss: 0.108014, Val Acc: 0.814433\n",
      "Epoch 26274 - Train Loss: 0.070367, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26275 - Train Loss: 0.070366, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26276 - Train Loss: 0.070364, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26277 - Train Loss: 0.070363, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26278 - Train Loss: 0.070362, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26279 - Train Loss: 0.070360, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26280 - Train Loss: 0.070359, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26281 - Train Loss: 0.070358, Train Acc: 0.892308 | Val Loss: 0.108013, Val Acc: 0.814433\n",
      "Epoch 26282 - Train Loss: 0.070356, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26283 - Train Loss: 0.070355, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26284 - Train Loss: 0.070354, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26285 - Train Loss: 0.070352, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26286 - Train Loss: 0.070351, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26287 - Train Loss: 0.070349, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26288 - Train Loss: 0.070348, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26289 - Train Loss: 0.070347, Train Acc: 0.892308 | Val Loss: 0.108012, Val Acc: 0.814433\n",
      "Epoch 26290 - Train Loss: 0.070345, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26291 - Train Loss: 0.070344, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26292 - Train Loss: 0.070343, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26293 - Train Loss: 0.070341, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26294 - Train Loss: 0.070340, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26295 - Train Loss: 0.070339, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26296 - Train Loss: 0.070337, Train Acc: 0.892308 | Val Loss: 0.108011, Val Acc: 0.814433\n",
      "Epoch 26297 - Train Loss: 0.070336, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26298 - Train Loss: 0.070334, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26299 - Train Loss: 0.070333, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26300 - Train Loss: 0.070332, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26301 - Train Loss: 0.070330, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26302 - Train Loss: 0.070329, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26303 - Train Loss: 0.070328, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26304 - Train Loss: 0.070326, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26305 - Train Loss: 0.070325, Train Acc: 0.892308 | Val Loss: 0.108010, Val Acc: 0.814433\n",
      "Epoch 26306 - Train Loss: 0.070324, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26307 - Train Loss: 0.070322, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26308 - Train Loss: 0.070321, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26309 - Train Loss: 0.070319, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26310 - Train Loss: 0.070318, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26311 - Train Loss: 0.070317, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26312 - Train Loss: 0.070315, Train Acc: 0.892308 | Val Loss: 0.108009, Val Acc: 0.814433\n",
      "Epoch 26313 - Train Loss: 0.070314, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26314 - Train Loss: 0.070313, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26315 - Train Loss: 0.070311, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26316 - Train Loss: 0.070310, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26317 - Train Loss: 0.070309, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26318 - Train Loss: 0.070307, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26319 - Train Loss: 0.070306, Train Acc: 0.892308 | Val Loss: 0.108008, Val Acc: 0.814433\n",
      "Epoch 26320 - Train Loss: 0.070305, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26321 - Train Loss: 0.070303, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26322 - Train Loss: 0.070302, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26323 - Train Loss: 0.070300, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26324 - Train Loss: 0.070299, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26325 - Train Loss: 0.070298, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26326 - Train Loss: 0.070296, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26327 - Train Loss: 0.070295, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26328 - Train Loss: 0.070294, Train Acc: 0.892308 | Val Loss: 0.108007, Val Acc: 0.814433\n",
      "Epoch 26329 - Train Loss: 0.070292, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26330 - Train Loss: 0.070291, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26331 - Train Loss: 0.070290, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26332 - Train Loss: 0.070288, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26333 - Train Loss: 0.070287, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26334 - Train Loss: 0.070286, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26335 - Train Loss: 0.070284, Train Acc: 0.892308 | Val Loss: 0.108006, Val Acc: 0.814433\n",
      "Epoch 26336 - Train Loss: 0.070283, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26337 - Train Loss: 0.070281, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26338 - Train Loss: 0.070280, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26339 - Train Loss: 0.070279, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26340 - Train Loss: 0.070277, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26341 - Train Loss: 0.070276, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26342 - Train Loss: 0.070275, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26343 - Train Loss: 0.070273, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26344 - Train Loss: 0.070272, Train Acc: 0.892308 | Val Loss: 0.108005, Val Acc: 0.814433\n",
      "Epoch 26345 - Train Loss: 0.070271, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26346 - Train Loss: 0.070269, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26347 - Train Loss: 0.070268, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26348 - Train Loss: 0.070267, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26349 - Train Loss: 0.070265, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26350 - Train Loss: 0.070264, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26351 - Train Loss: 0.070262, Train Acc: 0.892308 | Val Loss: 0.108004, Val Acc: 0.814433\n",
      "Epoch 26352 - Train Loss: 0.070261, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26353 - Train Loss: 0.070260, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26354 - Train Loss: 0.070258, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26355 - Train Loss: 0.070257, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26356 - Train Loss: 0.070256, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26357 - Train Loss: 0.070254, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26358 - Train Loss: 0.070253, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26359 - Train Loss: 0.070252, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26360 - Train Loss: 0.070250, Train Acc: 0.892308 | Val Loss: 0.108003, Val Acc: 0.814433\n",
      "Epoch 26361 - Train Loss: 0.070249, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26362 - Train Loss: 0.070248, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26363 - Train Loss: 0.070246, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26364 - Train Loss: 0.070245, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26365 - Train Loss: 0.070243, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26366 - Train Loss: 0.070242, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26367 - Train Loss: 0.070241, Train Acc: 0.892308 | Val Loss: 0.108002, Val Acc: 0.814433\n",
      "Epoch 26368 - Train Loss: 0.070239, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26369 - Train Loss: 0.070238, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26370 - Train Loss: 0.070237, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26371 - Train Loss: 0.070235, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26372 - Train Loss: 0.070234, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26373 - Train Loss: 0.070233, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26374 - Train Loss: 0.070231, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26375 - Train Loss: 0.070230, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26376 - Train Loss: 0.070229, Train Acc: 0.892308 | Val Loss: 0.108001, Val Acc: 0.814433\n",
      "Epoch 26377 - Train Loss: 0.070227, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26378 - Train Loss: 0.070226, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26379 - Train Loss: 0.070225, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26380 - Train Loss: 0.070223, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26381 - Train Loss: 0.070222, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26382 - Train Loss: 0.070220, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26383 - Train Loss: 0.070219, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26384 - Train Loss: 0.070218, Train Acc: 0.892308 | Val Loss: 0.108000, Val Acc: 0.814433\n",
      "Epoch 26385 - Train Loss: 0.070216, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26386 - Train Loss: 0.070215, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26387 - Train Loss: 0.070214, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26388 - Train Loss: 0.070212, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26389 - Train Loss: 0.070211, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26390 - Train Loss: 0.070210, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26391 - Train Loss: 0.070208, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26392 - Train Loss: 0.070207, Train Acc: 0.892308 | Val Loss: 0.107999, Val Acc: 0.814433\n",
      "Epoch 26393 - Train Loss: 0.070206, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26394 - Train Loss: 0.070204, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26395 - Train Loss: 0.070203, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26396 - Train Loss: 0.070202, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26397 - Train Loss: 0.070200, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26398 - Train Loss: 0.070199, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26399 - Train Loss: 0.070197, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26400 - Train Loss: 0.070196, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26401 - Train Loss: 0.070195, Train Acc: 0.892308 | Val Loss: 0.107998, Val Acc: 0.814433\n",
      "Epoch 26402 - Train Loss: 0.070193, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26403 - Train Loss: 0.070192, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26404 - Train Loss: 0.070191, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26405 - Train Loss: 0.070189, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26406 - Train Loss: 0.070188, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26407 - Train Loss: 0.070187, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26408 - Train Loss: 0.070185, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26409 - Train Loss: 0.070184, Train Acc: 0.892308 | Val Loss: 0.107997, Val Acc: 0.814433\n",
      "Epoch 26410 - Train Loss: 0.070183, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26411 - Train Loss: 0.070181, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26412 - Train Loss: 0.070180, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26413 - Train Loss: 0.070179, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26414 - Train Loss: 0.070177, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26415 - Train Loss: 0.070176, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26416 - Train Loss: 0.070174, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26417 - Train Loss: 0.070173, Train Acc: 0.892308 | Val Loss: 0.107996, Val Acc: 0.814433\n",
      "Epoch 26418 - Train Loss: 0.070172, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26419 - Train Loss: 0.070170, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26420 - Train Loss: 0.070169, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26421 - Train Loss: 0.070168, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26422 - Train Loss: 0.070166, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26423 - Train Loss: 0.070165, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26424 - Train Loss: 0.070164, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26425 - Train Loss: 0.070162, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26426 - Train Loss: 0.070161, Train Acc: 0.892308 | Val Loss: 0.107995, Val Acc: 0.814433\n",
      "Epoch 26427 - Train Loss: 0.070160, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26428 - Train Loss: 0.070158, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26429 - Train Loss: 0.070157, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26430 - Train Loss: 0.070156, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26431 - Train Loss: 0.070154, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26432 - Train Loss: 0.070153, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26433 - Train Loss: 0.070152, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26434 - Train Loss: 0.070150, Train Acc: 0.892308 | Val Loss: 0.107994, Val Acc: 0.814433\n",
      "Epoch 26435 - Train Loss: 0.070149, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26436 - Train Loss: 0.070147, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26437 - Train Loss: 0.070146, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26438 - Train Loss: 0.070145, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26439 - Train Loss: 0.070143, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26440 - Train Loss: 0.070142, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26441 - Train Loss: 0.070141, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26442 - Train Loss: 0.070139, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26443 - Train Loss: 0.070138, Train Acc: 0.892308 | Val Loss: 0.107993, Val Acc: 0.814433\n",
      "Epoch 26444 - Train Loss: 0.070137, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26445 - Train Loss: 0.070135, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26446 - Train Loss: 0.070134, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26447 - Train Loss: 0.070133, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26448 - Train Loss: 0.070131, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26449 - Train Loss: 0.070130, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26450 - Train Loss: 0.070129, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26451 - Train Loss: 0.070127, Train Acc: 0.892308 | Val Loss: 0.107992, Val Acc: 0.814433\n",
      "Epoch 26452 - Train Loss: 0.070126, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26453 - Train Loss: 0.070125, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26454 - Train Loss: 0.070123, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26455 - Train Loss: 0.070122, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26456 - Train Loss: 0.070121, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26457 - Train Loss: 0.070119, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26458 - Train Loss: 0.070118, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26459 - Train Loss: 0.070116, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26460 - Train Loss: 0.070115, Train Acc: 0.892308 | Val Loss: 0.107991, Val Acc: 0.814433\n",
      "Epoch 26461 - Train Loss: 0.070114, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26462 - Train Loss: 0.070112, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26463 - Train Loss: 0.070111, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26464 - Train Loss: 0.070110, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26465 - Train Loss: 0.070108, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26466 - Train Loss: 0.070107, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26467 - Train Loss: 0.070106, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26468 - Train Loss: 0.070104, Train Acc: 0.892308 | Val Loss: 0.107990, Val Acc: 0.814433\n",
      "Epoch 26469 - Train Loss: 0.070103, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26470 - Train Loss: 0.070102, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26471 - Train Loss: 0.070100, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26472 - Train Loss: 0.070099, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26473 - Train Loss: 0.070098, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26474 - Train Loss: 0.070096, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26475 - Train Loss: 0.070095, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26476 - Train Loss: 0.070094, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26477 - Train Loss: 0.070092, Train Acc: 0.892308 | Val Loss: 0.107989, Val Acc: 0.814433\n",
      "Epoch 26478 - Train Loss: 0.070091, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26479 - Train Loss: 0.070090, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26480 - Train Loss: 0.070088, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26481 - Train Loss: 0.070087, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26482 - Train Loss: 0.070086, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26483 - Train Loss: 0.070084, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26484 - Train Loss: 0.070083, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26485 - Train Loss: 0.070082, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26486 - Train Loss: 0.070080, Train Acc: 0.892308 | Val Loss: 0.107988, Val Acc: 0.814433\n",
      "Epoch 26487 - Train Loss: 0.070079, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26488 - Train Loss: 0.070077, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26489 - Train Loss: 0.070076, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26490 - Train Loss: 0.070075, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26491 - Train Loss: 0.070073, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26492 - Train Loss: 0.070072, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26493 - Train Loss: 0.070071, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26494 - Train Loss: 0.070069, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26495 - Train Loss: 0.070068, Train Acc: 0.892308 | Val Loss: 0.107987, Val Acc: 0.814433\n",
      "Epoch 26496 - Train Loss: 0.070067, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26497 - Train Loss: 0.070065, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26498 - Train Loss: 0.070064, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26499 - Train Loss: 0.070063, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26500 - Train Loss: 0.070061, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26501 - Train Loss: 0.070060, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26502 - Train Loss: 0.070059, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26503 - Train Loss: 0.070057, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26504 - Train Loss: 0.070056, Train Acc: 0.892308 | Val Loss: 0.107986, Val Acc: 0.814433\n",
      "Epoch 26505 - Train Loss: 0.070055, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26506 - Train Loss: 0.070053, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26507 - Train Loss: 0.070052, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26508 - Train Loss: 0.070051, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26509 - Train Loss: 0.070049, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26510 - Train Loss: 0.070048, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26511 - Train Loss: 0.070047, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26512 - Train Loss: 0.070045, Train Acc: 0.892308 | Val Loss: 0.107985, Val Acc: 0.814433\n",
      "Epoch 26513 - Train Loss: 0.070044, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26514 - Train Loss: 0.070043, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26515 - Train Loss: 0.070041, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26516 - Train Loss: 0.070040, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26517 - Train Loss: 0.070039, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26518 - Train Loss: 0.070037, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26519 - Train Loss: 0.070036, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26520 - Train Loss: 0.070035, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26521 - Train Loss: 0.070033, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26522 - Train Loss: 0.070032, Train Acc: 0.892308 | Val Loss: 0.107984, Val Acc: 0.814433\n",
      "Epoch 26523 - Train Loss: 0.070031, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26524 - Train Loss: 0.070029, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26525 - Train Loss: 0.070028, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26526 - Train Loss: 0.070026, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26527 - Train Loss: 0.070025, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26528 - Train Loss: 0.070024, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26529 - Train Loss: 0.070022, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26530 - Train Loss: 0.070021, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26531 - Train Loss: 0.070020, Train Acc: 0.892308 | Val Loss: 0.107983, Val Acc: 0.814433\n",
      "Epoch 26532 - Train Loss: 0.070018, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26533 - Train Loss: 0.070017, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26534 - Train Loss: 0.070016, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26535 - Train Loss: 0.070014, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26536 - Train Loss: 0.070013, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26537 - Train Loss: 0.070012, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26538 - Train Loss: 0.070010, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26539 - Train Loss: 0.070009, Train Acc: 0.892308 | Val Loss: 0.107982, Val Acc: 0.814433\n",
      "Epoch 26540 - Train Loss: 0.070008, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26541 - Train Loss: 0.070006, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26542 - Train Loss: 0.070005, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26543 - Train Loss: 0.070004, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26544 - Train Loss: 0.070002, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26545 - Train Loss: 0.070001, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26546 - Train Loss: 0.070000, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26547 - Train Loss: 0.069998, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26548 - Train Loss: 0.069997, Train Acc: 0.892308 | Val Loss: 0.107981, Val Acc: 0.814433\n",
      "Epoch 26549 - Train Loss: 0.069996, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26550 - Train Loss: 0.069994, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26551 - Train Loss: 0.069993, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26552 - Train Loss: 0.069992, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26553 - Train Loss: 0.069990, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26554 - Train Loss: 0.069989, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26555 - Train Loss: 0.069988, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26556 - Train Loss: 0.069986, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26557 - Train Loss: 0.069985, Train Acc: 0.892308 | Val Loss: 0.107980, Val Acc: 0.814433\n",
      "Epoch 26558 - Train Loss: 0.069984, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26559 - Train Loss: 0.069982, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26560 - Train Loss: 0.069981, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26561 - Train Loss: 0.069980, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26562 - Train Loss: 0.069978, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26563 - Train Loss: 0.069977, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26564 - Train Loss: 0.069976, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26565 - Train Loss: 0.069974, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26566 - Train Loss: 0.069973, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26567 - Train Loss: 0.069972, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26568 - Train Loss: 0.069970, Train Acc: 0.892308 | Val Loss: 0.107979, Val Acc: 0.814433\n",
      "Epoch 26569 - Train Loss: 0.069969, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26570 - Train Loss: 0.069968, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26571 - Train Loss: 0.069966, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26572 - Train Loss: 0.069965, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26573 - Train Loss: 0.069964, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26574 - Train Loss: 0.069962, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26575 - Train Loss: 0.069961, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26576 - Train Loss: 0.069960, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26577 - Train Loss: 0.069958, Train Acc: 0.892308 | Val Loss: 0.107978, Val Acc: 0.814433\n",
      "Epoch 26578 - Train Loss: 0.069957, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26579 - Train Loss: 0.069956, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26580 - Train Loss: 0.069954, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26581 - Train Loss: 0.069953, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26582 - Train Loss: 0.069952, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26583 - Train Loss: 0.069950, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26584 - Train Loss: 0.069949, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26585 - Train Loss: 0.069948, Train Acc: 0.892308 | Val Loss: 0.107977, Val Acc: 0.814433\n",
      "Epoch 26586 - Train Loss: 0.069946, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26587 - Train Loss: 0.069945, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26588 - Train Loss: 0.069944, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26589 - Train Loss: 0.069942, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26590 - Train Loss: 0.069941, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26591 - Train Loss: 0.069940, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26592 - Train Loss: 0.069938, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26593 - Train Loss: 0.069937, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26594 - Train Loss: 0.069936, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26595 - Train Loss: 0.069934, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26596 - Train Loss: 0.069933, Train Acc: 0.892308 | Val Loss: 0.107976, Val Acc: 0.814433\n",
      "Epoch 26597 - Train Loss: 0.069932, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26598 - Train Loss: 0.069930, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26599 - Train Loss: 0.069929, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26600 - Train Loss: 0.069928, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26601 - Train Loss: 0.069926, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26602 - Train Loss: 0.069925, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26603 - Train Loss: 0.069924, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26604 - Train Loss: 0.069922, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26605 - Train Loss: 0.069921, Train Acc: 0.892308 | Val Loss: 0.107975, Val Acc: 0.814433\n",
      "Epoch 26606 - Train Loss: 0.069920, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26607 - Train Loss: 0.069918, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26608 - Train Loss: 0.069917, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26609 - Train Loss: 0.069916, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26610 - Train Loss: 0.069914, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26611 - Train Loss: 0.069913, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26612 - Train Loss: 0.069912, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26613 - Train Loss: 0.069910, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26614 - Train Loss: 0.069909, Train Acc: 0.892308 | Val Loss: 0.107974, Val Acc: 0.814433\n",
      "Epoch 26615 - Train Loss: 0.069908, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26616 - Train Loss: 0.069906, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26617 - Train Loss: 0.069905, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26618 - Train Loss: 0.069904, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26619 - Train Loss: 0.069902, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26620 - Train Loss: 0.069901, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26621 - Train Loss: 0.069900, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26622 - Train Loss: 0.069898, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26623 - Train Loss: 0.069897, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26624 - Train Loss: 0.069896, Train Acc: 0.892308 | Val Loss: 0.107973, Val Acc: 0.814433\n",
      "Epoch 26625 - Train Loss: 0.069894, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26626 - Train Loss: 0.069893, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26627 - Train Loss: 0.069892, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26628 - Train Loss: 0.069890, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26629 - Train Loss: 0.069889, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26630 - Train Loss: 0.069888, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26631 - Train Loss: 0.069886, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26632 - Train Loss: 0.069885, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26633 - Train Loss: 0.069884, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26634 - Train Loss: 0.069882, Train Acc: 0.892308 | Val Loss: 0.107972, Val Acc: 0.814433\n",
      "Epoch 26635 - Train Loss: 0.069881, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26636 - Train Loss: 0.069880, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26637 - Train Loss: 0.069878, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26638 - Train Loss: 0.069877, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26639 - Train Loss: 0.069876, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26640 - Train Loss: 0.069874, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26641 - Train Loss: 0.069873, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26642 - Train Loss: 0.069872, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26643 - Train Loss: 0.069870, Train Acc: 0.892308 | Val Loss: 0.107971, Val Acc: 0.814433\n",
      "Epoch 26644 - Train Loss: 0.069869, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26645 - Train Loss: 0.069868, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26646 - Train Loss: 0.069866, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26647 - Train Loss: 0.069865, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26648 - Train Loss: 0.069864, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26649 - Train Loss: 0.069862, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26650 - Train Loss: 0.069861, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26651 - Train Loss: 0.069860, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26652 - Train Loss: 0.069858, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26653 - Train Loss: 0.069857, Train Acc: 0.892308 | Val Loss: 0.107970, Val Acc: 0.814433\n",
      "Epoch 26654 - Train Loss: 0.069856, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26655 - Train Loss: 0.069854, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26656 - Train Loss: 0.069853, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26657 - Train Loss: 0.069852, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26658 - Train Loss: 0.069850, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26659 - Train Loss: 0.069849, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26660 - Train Loss: 0.069848, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26661 - Train Loss: 0.069846, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26662 - Train Loss: 0.069845, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26663 - Train Loss: 0.069844, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26664 - Train Loss: 0.069842, Train Acc: 0.892308 | Val Loss: 0.107969, Val Acc: 0.814433\n",
      "Epoch 26665 - Train Loss: 0.069841, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26666 - Train Loss: 0.069840, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26667 - Train Loss: 0.069838, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26668 - Train Loss: 0.069837, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26669 - Train Loss: 0.069836, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26670 - Train Loss: 0.069834, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26671 - Train Loss: 0.069833, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26672 - Train Loss: 0.069832, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26673 - Train Loss: 0.069830, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26674 - Train Loss: 0.069829, Train Acc: 0.892308 | Val Loss: 0.107968, Val Acc: 0.814433\n",
      "Epoch 26675 - Train Loss: 0.069828, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26676 - Train Loss: 0.069826, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26677 - Train Loss: 0.069825, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26678 - Train Loss: 0.069824, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26679 - Train Loss: 0.069822, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26680 - Train Loss: 0.069821, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26681 - Train Loss: 0.069820, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26682 - Train Loss: 0.069818, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26683 - Train Loss: 0.069817, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26684 - Train Loss: 0.069816, Train Acc: 0.892308 | Val Loss: 0.107967, Val Acc: 0.814433\n",
      "Epoch 26685 - Train Loss: 0.069814, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26686 - Train Loss: 0.069813, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26687 - Train Loss: 0.069812, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26688 - Train Loss: 0.069810, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26689 - Train Loss: 0.069809, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26690 - Train Loss: 0.069808, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26691 - Train Loss: 0.069806, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26692 - Train Loss: 0.069805, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26693 - Train Loss: 0.069804, Train Acc: 0.892308 | Val Loss: 0.107966, Val Acc: 0.814433\n",
      "Epoch 26694 - Train Loss: 0.069802, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26695 - Train Loss: 0.069801, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26696 - Train Loss: 0.069800, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26697 - Train Loss: 0.069798, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26698 - Train Loss: 0.069797, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26699 - Train Loss: 0.069796, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26700 - Train Loss: 0.069795, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26701 - Train Loss: 0.069793, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26702 - Train Loss: 0.069792, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26703 - Train Loss: 0.069791, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26704 - Train Loss: 0.069789, Train Acc: 0.892308 | Val Loss: 0.107965, Val Acc: 0.814433\n",
      "Epoch 26705 - Train Loss: 0.069788, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26706 - Train Loss: 0.069787, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26707 - Train Loss: 0.069785, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26708 - Train Loss: 0.069784, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26709 - Train Loss: 0.069783, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26710 - Train Loss: 0.069781, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26711 - Train Loss: 0.069780, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26712 - Train Loss: 0.069779, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26713 - Train Loss: 0.069777, Train Acc: 0.892308 | Val Loss: 0.107964, Val Acc: 0.814433\n",
      "Epoch 26714 - Train Loss: 0.069776, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26715 - Train Loss: 0.069775, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26716 - Train Loss: 0.069773, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26717 - Train Loss: 0.069772, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26718 - Train Loss: 0.069771, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26719 - Train Loss: 0.069769, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26720 - Train Loss: 0.069768, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26721 - Train Loss: 0.069767, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26722 - Train Loss: 0.069765, Train Acc: 0.892308 | Val Loss: 0.107963, Val Acc: 0.814433\n",
      "Epoch 26723 - Train Loss: 0.069764, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26724 - Train Loss: 0.069763, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26725 - Train Loss: 0.069761, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26726 - Train Loss: 0.069760, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26727 - Train Loss: 0.069759, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26728 - Train Loss: 0.069757, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26729 - Train Loss: 0.069756, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26730 - Train Loss: 0.069755, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26731 - Train Loss: 0.069753, Train Acc: 0.892308 | Val Loss: 0.107962, Val Acc: 0.814433\n",
      "Epoch 26732 - Train Loss: 0.069752, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26733 - Train Loss: 0.069751, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26734 - Train Loss: 0.069749, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26735 - Train Loss: 0.069748, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26736 - Train Loss: 0.069747, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26737 - Train Loss: 0.069746, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26738 - Train Loss: 0.069744, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26739 - Train Loss: 0.069743, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26740 - Train Loss: 0.069742, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26741 - Train Loss: 0.069740, Train Acc: 0.892308 | Val Loss: 0.107961, Val Acc: 0.814433\n",
      "Epoch 26742 - Train Loss: 0.069739, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26743 - Train Loss: 0.069738, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26744 - Train Loss: 0.069736, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26745 - Train Loss: 0.069735, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26746 - Train Loss: 0.069734, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26747 - Train Loss: 0.069732, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26748 - Train Loss: 0.069731, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26749 - Train Loss: 0.069730, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26750 - Train Loss: 0.069728, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26751 - Train Loss: 0.069727, Train Acc: 0.892308 | Val Loss: 0.107960, Val Acc: 0.814433\n",
      "Epoch 26752 - Train Loss: 0.069726, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26753 - Train Loss: 0.069724, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26754 - Train Loss: 0.069723, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26755 - Train Loss: 0.069722, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26756 - Train Loss: 0.069720, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26757 - Train Loss: 0.069719, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26758 - Train Loss: 0.069718, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26759 - Train Loss: 0.069716, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26760 - Train Loss: 0.069715, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26761 - Train Loss: 0.069714, Train Acc: 0.892308 | Val Loss: 0.107959, Val Acc: 0.814433\n",
      "Epoch 26762 - Train Loss: 0.069713, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26763 - Train Loss: 0.069711, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26764 - Train Loss: 0.069710, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26765 - Train Loss: 0.069709, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26766 - Train Loss: 0.069707, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26767 - Train Loss: 0.069706, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26768 - Train Loss: 0.069705, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26769 - Train Loss: 0.069703, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26770 - Train Loss: 0.069702, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26771 - Train Loss: 0.069701, Train Acc: 0.892308 | Val Loss: 0.107958, Val Acc: 0.814433\n",
      "Epoch 26772 - Train Loss: 0.069699, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26773 - Train Loss: 0.069698, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26774 - Train Loss: 0.069697, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26775 - Train Loss: 0.069695, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26776 - Train Loss: 0.069694, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26777 - Train Loss: 0.069693, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26778 - Train Loss: 0.069691, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26779 - Train Loss: 0.069690, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26780 - Train Loss: 0.069689, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26781 - Train Loss: 0.069687, Train Acc: 0.892308 | Val Loss: 0.107957, Val Acc: 0.814433\n",
      "Epoch 26782 - Train Loss: 0.069686, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26783 - Train Loss: 0.069685, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26784 - Train Loss: 0.069683, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26785 - Train Loss: 0.069682, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26786 - Train Loss: 0.069681, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26787 - Train Loss: 0.069680, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26788 - Train Loss: 0.069678, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26789 - Train Loss: 0.069677, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26790 - Train Loss: 0.069676, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26791 - Train Loss: 0.069674, Train Acc: 0.892308 | Val Loss: 0.107956, Val Acc: 0.814433\n",
      "Epoch 26792 - Train Loss: 0.069673, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26793 - Train Loss: 0.069672, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26794 - Train Loss: 0.069670, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26795 - Train Loss: 0.069669, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26796 - Train Loss: 0.069668, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26797 - Train Loss: 0.069666, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26798 - Train Loss: 0.069665, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26799 - Train Loss: 0.069664, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26800 - Train Loss: 0.069662, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26801 - Train Loss: 0.069661, Train Acc: 0.892308 | Val Loss: 0.107955, Val Acc: 0.814433\n",
      "Epoch 26802 - Train Loss: 0.069660, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26803 - Train Loss: 0.069658, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26804 - Train Loss: 0.069657, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26805 - Train Loss: 0.069656, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26806 - Train Loss: 0.069655, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26807 - Train Loss: 0.069653, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26808 - Train Loss: 0.069652, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26809 - Train Loss: 0.069651, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26810 - Train Loss: 0.069649, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26811 - Train Loss: 0.069648, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26812 - Train Loss: 0.069647, Train Acc: 0.892308 | Val Loss: 0.107954, Val Acc: 0.814433\n",
      "Epoch 26813 - Train Loss: 0.069645, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26814 - Train Loss: 0.069644, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26815 - Train Loss: 0.069643, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26816 - Train Loss: 0.069641, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26817 - Train Loss: 0.069640, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26818 - Train Loss: 0.069639, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26819 - Train Loss: 0.069637, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26820 - Train Loss: 0.069636, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26821 - Train Loss: 0.069635, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26822 - Train Loss: 0.069633, Train Acc: 0.892308 | Val Loss: 0.107953, Val Acc: 0.814433\n",
      "Epoch 26823 - Train Loss: 0.069632, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26824 - Train Loss: 0.069631, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26825 - Train Loss: 0.069630, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26826 - Train Loss: 0.069628, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26827 - Train Loss: 0.069627, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26828 - Train Loss: 0.069626, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26829 - Train Loss: 0.069624, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26830 - Train Loss: 0.069623, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26831 - Train Loss: 0.069622, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26832 - Train Loss: 0.069620, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26833 - Train Loss: 0.069619, Train Acc: 0.892308 | Val Loss: 0.107952, Val Acc: 0.814433\n",
      "Epoch 26834 - Train Loss: 0.069618, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26835 - Train Loss: 0.069616, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26836 - Train Loss: 0.069615, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26837 - Train Loss: 0.069614, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26838 - Train Loss: 0.069612, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26839 - Train Loss: 0.069611, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26840 - Train Loss: 0.069610, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26841 - Train Loss: 0.069608, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26842 - Train Loss: 0.069607, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26843 - Train Loss: 0.069606, Train Acc: 0.892308 | Val Loss: 0.107951, Val Acc: 0.814433\n",
      "Epoch 26844 - Train Loss: 0.069605, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26845 - Train Loss: 0.069603, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26846 - Train Loss: 0.069602, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26847 - Train Loss: 0.069601, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26848 - Train Loss: 0.069599, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26849 - Train Loss: 0.069598, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26850 - Train Loss: 0.069597, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26851 - Train Loss: 0.069595, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26852 - Train Loss: 0.069594, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26853 - Train Loss: 0.069593, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26854 - Train Loss: 0.069591, Train Acc: 0.892308 | Val Loss: 0.107950, Val Acc: 0.814433\n",
      "Epoch 26855 - Train Loss: 0.069590, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26856 - Train Loss: 0.069589, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26857 - Train Loss: 0.069587, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26858 - Train Loss: 0.069586, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26859 - Train Loss: 0.069585, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26860 - Train Loss: 0.069584, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26861 - Train Loss: 0.069582, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26862 - Train Loss: 0.069581, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26863 - Train Loss: 0.069580, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26864 - Train Loss: 0.069578, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26865 - Train Loss: 0.069577, Train Acc: 0.892308 | Val Loss: 0.107949, Val Acc: 0.814433\n",
      "Epoch 26866 - Train Loss: 0.069576, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26867 - Train Loss: 0.069574, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26868 - Train Loss: 0.069573, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26869 - Train Loss: 0.069572, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26870 - Train Loss: 0.069570, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26871 - Train Loss: 0.069569, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26872 - Train Loss: 0.069568, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26873 - Train Loss: 0.069567, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26874 - Train Loss: 0.069565, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26875 - Train Loss: 0.069564, Train Acc: 0.892308 | Val Loss: 0.107948, Val Acc: 0.814433\n",
      "Epoch 26876 - Train Loss: 0.069563, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26877 - Train Loss: 0.069561, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26878 - Train Loss: 0.069560, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26879 - Train Loss: 0.069559, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26880 - Train Loss: 0.069557, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26881 - Train Loss: 0.069556, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26882 - Train Loss: 0.069555, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26883 - Train Loss: 0.069553, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26884 - Train Loss: 0.069552, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26885 - Train Loss: 0.069551, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26886 - Train Loss: 0.069549, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26887 - Train Loss: 0.069548, Train Acc: 0.892308 | Val Loss: 0.107947, Val Acc: 0.814433\n",
      "Epoch 26888 - Train Loss: 0.069547, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26889 - Train Loss: 0.069546, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26890 - Train Loss: 0.069544, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26891 - Train Loss: 0.069543, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26892 - Train Loss: 0.069542, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26893 - Train Loss: 0.069540, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26894 - Train Loss: 0.069539, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26895 - Train Loss: 0.069538, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26896 - Train Loss: 0.069536, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26897 - Train Loss: 0.069535, Train Acc: 0.892308 | Val Loss: 0.107946, Val Acc: 0.814433\n",
      "Epoch 26898 - Train Loss: 0.069534, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26899 - Train Loss: 0.069532, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26900 - Train Loss: 0.069531, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26901 - Train Loss: 0.069530, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26902 - Train Loss: 0.069529, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26903 - Train Loss: 0.069527, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26904 - Train Loss: 0.069526, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26905 - Train Loss: 0.069525, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26906 - Train Loss: 0.069523, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26907 - Train Loss: 0.069522, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26908 - Train Loss: 0.069521, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26909 - Train Loss: 0.069519, Train Acc: 0.892308 | Val Loss: 0.107945, Val Acc: 0.814433\n",
      "Epoch 26910 - Train Loss: 0.069518, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26911 - Train Loss: 0.069517, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26912 - Train Loss: 0.069515, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26913 - Train Loss: 0.069514, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26914 - Train Loss: 0.069513, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26915 - Train Loss: 0.069512, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26916 - Train Loss: 0.069510, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26917 - Train Loss: 0.069509, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26918 - Train Loss: 0.069508, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26919 - Train Loss: 0.069506, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26920 - Train Loss: 0.069505, Train Acc: 0.892308 | Val Loss: 0.107944, Val Acc: 0.814433\n",
      "Epoch 26921 - Train Loss: 0.069504, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26922 - Train Loss: 0.069502, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26923 - Train Loss: 0.069501, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26924 - Train Loss: 0.069500, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26925 - Train Loss: 0.069498, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26926 - Train Loss: 0.069497, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26927 - Train Loss: 0.069496, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26928 - Train Loss: 0.069495, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26929 - Train Loss: 0.069493, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26930 - Train Loss: 0.069492, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26931 - Train Loss: 0.069491, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26932 - Train Loss: 0.069489, Train Acc: 0.892308 | Val Loss: 0.107943, Val Acc: 0.814433\n",
      "Epoch 26933 - Train Loss: 0.069488, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26934 - Train Loss: 0.069487, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26935 - Train Loss: 0.069485, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26936 - Train Loss: 0.069484, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26937 - Train Loss: 0.069483, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26938 - Train Loss: 0.069481, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26939 - Train Loss: 0.069480, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26940 - Train Loss: 0.069479, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26941 - Train Loss: 0.069478, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26942 - Train Loss: 0.069476, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26943 - Train Loss: 0.069475, Train Acc: 0.892308 | Val Loss: 0.107942, Val Acc: 0.814433\n",
      "Epoch 26944 - Train Loss: 0.069474, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26945 - Train Loss: 0.069472, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26946 - Train Loss: 0.069471, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26947 - Train Loss: 0.069470, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26948 - Train Loss: 0.069468, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26949 - Train Loss: 0.069467, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26950 - Train Loss: 0.069466, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26951 - Train Loss: 0.069465, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26952 - Train Loss: 0.069463, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26953 - Train Loss: 0.069462, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26954 - Train Loss: 0.069461, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26955 - Train Loss: 0.069459, Train Acc: 0.892308 | Val Loss: 0.107941, Val Acc: 0.814433\n",
      "Epoch 26956 - Train Loss: 0.069458, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26957 - Train Loss: 0.069457, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26958 - Train Loss: 0.069455, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26959 - Train Loss: 0.069454, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26960 - Train Loss: 0.069453, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26961 - Train Loss: 0.069451, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26962 - Train Loss: 0.069450, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26963 - Train Loss: 0.069449, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26964 - Train Loss: 0.069448, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26965 - Train Loss: 0.069446, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26966 - Train Loss: 0.069445, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26967 - Train Loss: 0.069444, Train Acc: 0.892308 | Val Loss: 0.107940, Val Acc: 0.814433\n",
      "Epoch 26968 - Train Loss: 0.069442, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26969 - Train Loss: 0.069441, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26970 - Train Loss: 0.069440, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26971 - Train Loss: 0.069438, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26972 - Train Loss: 0.069437, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26973 - Train Loss: 0.069436, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26974 - Train Loss: 0.069435, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26975 - Train Loss: 0.069433, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26976 - Train Loss: 0.069432, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26977 - Train Loss: 0.069431, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26978 - Train Loss: 0.069429, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26979 - Train Loss: 0.069428, Train Acc: 0.892308 | Val Loss: 0.107939, Val Acc: 0.814433\n",
      "Epoch 26980 - Train Loss: 0.069427, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26981 - Train Loss: 0.069425, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26982 - Train Loss: 0.069424, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26983 - Train Loss: 0.069423, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26984 - Train Loss: 0.069422, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26985 - Train Loss: 0.069420, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26986 - Train Loss: 0.069419, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26987 - Train Loss: 0.069418, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26988 - Train Loss: 0.069416, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26989 - Train Loss: 0.069415, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26990 - Train Loss: 0.069414, Train Acc: 0.892308 | Val Loss: 0.107938, Val Acc: 0.814433\n",
      "Epoch 26991 - Train Loss: 0.069412, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26992 - Train Loss: 0.069411, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26993 - Train Loss: 0.069410, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26994 - Train Loss: 0.069409, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26995 - Train Loss: 0.069407, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26996 - Train Loss: 0.069406, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26997 - Train Loss: 0.069405, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26998 - Train Loss: 0.069403, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 26999 - Train Loss: 0.069402, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 27000 - Train Loss: 0.069401, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 27001 - Train Loss: 0.069399, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 27002 - Train Loss: 0.069398, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 27003 - Train Loss: 0.069397, Train Acc: 0.892308 | Val Loss: 0.107937, Val Acc: 0.814433\n",
      "Epoch 27004 - Train Loss: 0.069396, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27005 - Train Loss: 0.069394, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27006 - Train Loss: 0.069393, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27007 - Train Loss: 0.069392, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27008 - Train Loss: 0.069390, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27009 - Train Loss: 0.069389, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27010 - Train Loss: 0.069388, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27011 - Train Loss: 0.069386, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27012 - Train Loss: 0.069385, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27013 - Train Loss: 0.069384, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27014 - Train Loss: 0.069383, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27015 - Train Loss: 0.069381, Train Acc: 0.892308 | Val Loss: 0.107936, Val Acc: 0.814433\n",
      "Epoch 27016 - Train Loss: 0.069380, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27017 - Train Loss: 0.069379, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27018 - Train Loss: 0.069377, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27019 - Train Loss: 0.069376, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27020 - Train Loss: 0.069375, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27021 - Train Loss: 0.069373, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27022 - Train Loss: 0.069372, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27023 - Train Loss: 0.069371, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27024 - Train Loss: 0.069370, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27025 - Train Loss: 0.069368, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27026 - Train Loss: 0.069367, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27027 - Train Loss: 0.069366, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27028 - Train Loss: 0.069364, Train Acc: 0.892308 | Val Loss: 0.107935, Val Acc: 0.814433\n",
      "Epoch 27029 - Train Loss: 0.069363, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27030 - Train Loss: 0.069362, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27031 - Train Loss: 0.069360, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27032 - Train Loss: 0.069359, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27033 - Train Loss: 0.069358, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27034 - Train Loss: 0.069357, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27035 - Train Loss: 0.069355, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27036 - Train Loss: 0.069354, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27037 - Train Loss: 0.069353, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27038 - Train Loss: 0.069351, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27039 - Train Loss: 0.069350, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27040 - Train Loss: 0.069349, Train Acc: 0.892308 | Val Loss: 0.107934, Val Acc: 0.814433\n",
      "Epoch 27041 - Train Loss: 0.069347, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27042 - Train Loss: 0.069346, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27043 - Train Loss: 0.069345, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27044 - Train Loss: 0.069344, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27045 - Train Loss: 0.069342, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27046 - Train Loss: 0.069341, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27047 - Train Loss: 0.069340, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27048 - Train Loss: 0.069338, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27049 - Train Loss: 0.069337, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27050 - Train Loss: 0.069336, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27051 - Train Loss: 0.069335, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27052 - Train Loss: 0.069333, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27053 - Train Loss: 0.069332, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27054 - Train Loss: 0.069331, Train Acc: 0.892308 | Val Loss: 0.107933, Val Acc: 0.814433\n",
      "Epoch 27055 - Train Loss: 0.069329, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27056 - Train Loss: 0.069328, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27057 - Train Loss: 0.069327, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27058 - Train Loss: 0.069325, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27059 - Train Loss: 0.069324, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27060 - Train Loss: 0.069323, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27061 - Train Loss: 0.069322, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27062 - Train Loss: 0.069320, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27063 - Train Loss: 0.069319, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27064 - Train Loss: 0.069318, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27065 - Train Loss: 0.069316, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27066 - Train Loss: 0.069315, Train Acc: 0.892308 | Val Loss: 0.107932, Val Acc: 0.814433\n",
      "Epoch 27067 - Train Loss: 0.069314, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27068 - Train Loss: 0.069313, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27069 - Train Loss: 0.069311, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27070 - Train Loss: 0.069310, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27071 - Train Loss: 0.069309, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27072 - Train Loss: 0.069307, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27073 - Train Loss: 0.069306, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27074 - Train Loss: 0.069305, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27075 - Train Loss: 0.069303, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27076 - Train Loss: 0.069302, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27077 - Train Loss: 0.069301, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27078 - Train Loss: 0.069300, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27079 - Train Loss: 0.069298, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27080 - Train Loss: 0.069297, Train Acc: 0.892308 | Val Loss: 0.107931, Val Acc: 0.814433\n",
      "Epoch 27081 - Train Loss: 0.069296, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27082 - Train Loss: 0.069294, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27083 - Train Loss: 0.069293, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27084 - Train Loss: 0.069292, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27085 - Train Loss: 0.069291, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27086 - Train Loss: 0.069289, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27087 - Train Loss: 0.069288, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27088 - Train Loss: 0.069287, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27089 - Train Loss: 0.069285, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27090 - Train Loss: 0.069284, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27091 - Train Loss: 0.069283, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27092 - Train Loss: 0.069281, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27093 - Train Loss: 0.069280, Train Acc: 0.892308 | Val Loss: 0.107930, Val Acc: 0.814433\n",
      "Epoch 27094 - Train Loss: 0.069279, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27095 - Train Loss: 0.069278, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27096 - Train Loss: 0.069276, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27097 - Train Loss: 0.069275, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27098 - Train Loss: 0.069274, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27099 - Train Loss: 0.069272, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27100 - Train Loss: 0.069271, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27101 - Train Loss: 0.069270, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27102 - Train Loss: 0.069269, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27103 - Train Loss: 0.069267, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27104 - Train Loss: 0.069266, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27105 - Train Loss: 0.069265, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27106 - Train Loss: 0.069263, Train Acc: 0.892308 | Val Loss: 0.107929, Val Acc: 0.814433\n",
      "Epoch 27107 - Train Loss: 0.069262, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27108 - Train Loss: 0.069261, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27109 - Train Loss: 0.069260, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27110 - Train Loss: 0.069258, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27111 - Train Loss: 0.069257, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27112 - Train Loss: 0.069256, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27113 - Train Loss: 0.069254, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27114 - Train Loss: 0.069253, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27115 - Train Loss: 0.069252, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27116 - Train Loss: 0.069250, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27117 - Train Loss: 0.069249, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27118 - Train Loss: 0.069248, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27119 - Train Loss: 0.069247, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27120 - Train Loss: 0.069245, Train Acc: 0.892308 | Val Loss: 0.107928, Val Acc: 0.814433\n",
      "Epoch 27121 - Train Loss: 0.069244, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27122 - Train Loss: 0.069243, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27123 - Train Loss: 0.069241, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27124 - Train Loss: 0.069240, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27125 - Train Loss: 0.069239, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27126 - Train Loss: 0.069238, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27127 - Train Loss: 0.069236, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27128 - Train Loss: 0.069235, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27129 - Train Loss: 0.069234, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27130 - Train Loss: 0.069232, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27131 - Train Loss: 0.069231, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27132 - Train Loss: 0.069230, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27133 - Train Loss: 0.069229, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27134 - Train Loss: 0.069227, Train Acc: 0.892308 | Val Loss: 0.107927, Val Acc: 0.814433\n",
      "Epoch 27135 - Train Loss: 0.069226, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27136 - Train Loss: 0.069225, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27137 - Train Loss: 0.069223, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27138 - Train Loss: 0.069222, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27139 - Train Loss: 0.069221, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27140 - Train Loss: 0.069220, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27141 - Train Loss: 0.069218, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27142 - Train Loss: 0.069217, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27143 - Train Loss: 0.069216, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27144 - Train Loss: 0.069214, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27145 - Train Loss: 0.069213, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27146 - Train Loss: 0.069212, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27147 - Train Loss: 0.069211, Train Acc: 0.892308 | Val Loss: 0.107926, Val Acc: 0.814433\n",
      "Epoch 27148 - Train Loss: 0.069209, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27149 - Train Loss: 0.069208, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27150 - Train Loss: 0.069207, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27151 - Train Loss: 0.069205, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27152 - Train Loss: 0.069204, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27153 - Train Loss: 0.069203, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27154 - Train Loss: 0.069202, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27155 - Train Loss: 0.069200, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27156 - Train Loss: 0.069199, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27157 - Train Loss: 0.069198, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27158 - Train Loss: 0.069196, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27159 - Train Loss: 0.069195, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.814433\n",
      "Epoch 27160 - Train Loss: 0.069194, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 27161 - Train Loss: 0.069192, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 27162 - Train Loss: 0.069191, Train Acc: 0.892308 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 27163 - Train Loss: 0.069190, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27164 - Train Loss: 0.069189, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.814433\n",
      "Epoch 27165 - Train Loss: 0.069187, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.814433\n",
      "Epoch 27166 - Train Loss: 0.069186, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.814433\n",
      "Epoch 27167 - Train Loss: 0.069185, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27168 - Train Loss: 0.069183, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27169 - Train Loss: 0.069182, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27170 - Train Loss: 0.069181, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27171 - Train Loss: 0.069180, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27172 - Train Loss: 0.069178, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27173 - Train Loss: 0.069177, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27174 - Train Loss: 0.069176, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27175 - Train Loss: 0.069174, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27176 - Train Loss: 0.069173, Train Acc: 0.892308 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 27177 - Train Loss: 0.069172, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27178 - Train Loss: 0.069171, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27179 - Train Loss: 0.069169, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27180 - Train Loss: 0.069168, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27181 - Train Loss: 0.069167, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27182 - Train Loss: 0.069165, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27183 - Train Loss: 0.069164, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27184 - Train Loss: 0.069163, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27185 - Train Loss: 0.069162, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27186 - Train Loss: 0.069160, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27187 - Train Loss: 0.069159, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27188 - Train Loss: 0.069158, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27189 - Train Loss: 0.069156, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27190 - Train Loss: 0.069155, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27191 - Train Loss: 0.069154, Train Acc: 0.892308 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 27192 - Train Loss: 0.069153, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27193 - Train Loss: 0.069151, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27194 - Train Loss: 0.069150, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27195 - Train Loss: 0.069149, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27196 - Train Loss: 0.069148, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27197 - Train Loss: 0.069146, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27198 - Train Loss: 0.069145, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27199 - Train Loss: 0.069144, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27200 - Train Loss: 0.069142, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27201 - Train Loss: 0.069141, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27202 - Train Loss: 0.069140, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27203 - Train Loss: 0.069139, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27204 - Train Loss: 0.069137, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27205 - Train Loss: 0.069136, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27206 - Train Loss: 0.069135, Train Acc: 0.892308 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 27207 - Train Loss: 0.069133, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27208 - Train Loss: 0.069132, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27209 - Train Loss: 0.069131, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27210 - Train Loss: 0.069130, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27211 - Train Loss: 0.069128, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27212 - Train Loss: 0.069127, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27213 - Train Loss: 0.069126, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27214 - Train Loss: 0.069124, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27215 - Train Loss: 0.069123, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27216 - Train Loss: 0.069122, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27217 - Train Loss: 0.069121, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27218 - Train Loss: 0.069119, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27219 - Train Loss: 0.069118, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27220 - Train Loss: 0.069117, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27221 - Train Loss: 0.069115, Train Acc: 0.892308 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 27222 - Train Loss: 0.069114, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27223 - Train Loss: 0.069113, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27224 - Train Loss: 0.069112, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27225 - Train Loss: 0.069110, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27226 - Train Loss: 0.069109, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27227 - Train Loss: 0.069108, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27228 - Train Loss: 0.069106, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27229 - Train Loss: 0.069105, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27230 - Train Loss: 0.069104, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27231 - Train Loss: 0.069103, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27232 - Train Loss: 0.069101, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27233 - Train Loss: 0.069100, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27234 - Train Loss: 0.069099, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27235 - Train Loss: 0.069098, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27236 - Train Loss: 0.069096, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27237 - Train Loss: 0.069095, Train Acc: 0.892308 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 27238 - Train Loss: 0.069094, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27239 - Train Loss: 0.069092, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27240 - Train Loss: 0.069091, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27241 - Train Loss: 0.069090, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27242 - Train Loss: 0.069089, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27243 - Train Loss: 0.069087, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27244 - Train Loss: 0.069086, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27245 - Train Loss: 0.069085, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27246 - Train Loss: 0.069083, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27247 - Train Loss: 0.069082, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27248 - Train Loss: 0.069081, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27249 - Train Loss: 0.069080, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27250 - Train Loss: 0.069078, Train Acc: 0.892308 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 27251 - Train Loss: 0.069077, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27252 - Train Loss: 0.069076, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27253 - Train Loss: 0.069074, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27254 - Train Loss: 0.069073, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27255 - Train Loss: 0.069072, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27256 - Train Loss: 0.069071, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27257 - Train Loss: 0.069069, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27258 - Train Loss: 0.069068, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27259 - Train Loss: 0.069067, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27260 - Train Loss: 0.069066, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27261 - Train Loss: 0.069064, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27262 - Train Loss: 0.069063, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27263 - Train Loss: 0.069062, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27264 - Train Loss: 0.069060, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27265 - Train Loss: 0.069059, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27266 - Train Loss: 0.069058, Train Acc: 0.892308 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 27267 - Train Loss: 0.069057, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27268 - Train Loss: 0.069055, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27269 - Train Loss: 0.069054, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27270 - Train Loss: 0.069053, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27271 - Train Loss: 0.069051, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27272 - Train Loss: 0.069050, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27273 - Train Loss: 0.069049, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27274 - Train Loss: 0.069048, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27275 - Train Loss: 0.069046, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27276 - Train Loss: 0.069045, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27277 - Train Loss: 0.069044, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27278 - Train Loss: 0.069043, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27279 - Train Loss: 0.069041, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27280 - Train Loss: 0.069040, Train Acc: 0.892308 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 27281 - Train Loss: 0.069039, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27282 - Train Loss: 0.069037, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27283 - Train Loss: 0.069036, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27284 - Train Loss: 0.069035, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27285 - Train Loss: 0.069034, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27286 - Train Loss: 0.069032, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27287 - Train Loss: 0.069031, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27288 - Train Loss: 0.069030, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27289 - Train Loss: 0.069029, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27290 - Train Loss: 0.069027, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27291 - Train Loss: 0.069026, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27292 - Train Loss: 0.069025, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27293 - Train Loss: 0.069023, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27294 - Train Loss: 0.069022, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27295 - Train Loss: 0.069021, Train Acc: 0.892308 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 27296 - Train Loss: 0.069020, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27297 - Train Loss: 0.069018, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27298 - Train Loss: 0.069017, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27299 - Train Loss: 0.069016, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27300 - Train Loss: 0.069014, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27301 - Train Loss: 0.069013, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27302 - Train Loss: 0.069012, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27303 - Train Loss: 0.069011, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27304 - Train Loss: 0.069009, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27305 - Train Loss: 0.069008, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27306 - Train Loss: 0.069007, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27307 - Train Loss: 0.069006, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27308 - Train Loss: 0.069004, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27309 - Train Loss: 0.069003, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27310 - Train Loss: 0.069002, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27311 - Train Loss: 0.069000, Train Acc: 0.892308 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 27312 - Train Loss: 0.068999, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27313 - Train Loss: 0.068998, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27314 - Train Loss: 0.068997, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27315 - Train Loss: 0.068995, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27316 - Train Loss: 0.068994, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27317 - Train Loss: 0.068993, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27318 - Train Loss: 0.068992, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27319 - Train Loss: 0.068990, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27320 - Train Loss: 0.068989, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27321 - Train Loss: 0.068988, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27322 - Train Loss: 0.068986, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27323 - Train Loss: 0.068985, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27324 - Train Loss: 0.068984, Train Acc: 0.892308 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 27325 - Train Loss: 0.068983, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27326 - Train Loss: 0.068981, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27327 - Train Loss: 0.068980, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27328 - Train Loss: 0.068979, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27329 - Train Loss: 0.068978, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27330 - Train Loss: 0.068976, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27331 - Train Loss: 0.068975, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27332 - Train Loss: 0.068974, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27333 - Train Loss: 0.068972, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27334 - Train Loss: 0.068971, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27335 - Train Loss: 0.068970, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27336 - Train Loss: 0.068969, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27337 - Train Loss: 0.068967, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27338 - Train Loss: 0.068966, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27339 - Train Loss: 0.068965, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27340 - Train Loss: 0.068964, Train Acc: 0.892308 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 27341 - Train Loss: 0.068962, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27342 - Train Loss: 0.068961, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27343 - Train Loss: 0.068960, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27344 - Train Loss: 0.068958, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27345 - Train Loss: 0.068957, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27346 - Train Loss: 0.068956, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27347 - Train Loss: 0.068955, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27348 - Train Loss: 0.068953, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27349 - Train Loss: 0.068952, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27350 - Train Loss: 0.068951, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27351 - Train Loss: 0.068950, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27352 - Train Loss: 0.068948, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27353 - Train Loss: 0.068947, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27354 - Train Loss: 0.068946, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27355 - Train Loss: 0.068945, Train Acc: 0.892308 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 27356 - Train Loss: 0.068943, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27357 - Train Loss: 0.068942, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27358 - Train Loss: 0.068941, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27359 - Train Loss: 0.068939, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27360 - Train Loss: 0.068938, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27361 - Train Loss: 0.068937, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27362 - Train Loss: 0.068936, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27363 - Train Loss: 0.068934, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27364 - Train Loss: 0.068933, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27365 - Train Loss: 0.068932, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27366 - Train Loss: 0.068931, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27367 - Train Loss: 0.068929, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27368 - Train Loss: 0.068928, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27369 - Train Loss: 0.068927, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27370 - Train Loss: 0.068925, Train Acc: 0.892308 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 27371 - Train Loss: 0.068924, Train Acc: 0.892308 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27372 - Train Loss: 0.068923, Train Acc: 0.892308 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27373 - Train Loss: 0.068922, Train Acc: 0.892308 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27374 - Train Loss: 0.068920, Train Acc: 0.892308 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27375 - Train Loss: 0.068919, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27376 - Train Loss: 0.068918, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27377 - Train Loss: 0.068917, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27378 - Train Loss: 0.068915, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27379 - Train Loss: 0.068914, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27380 - Train Loss: 0.068913, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27381 - Train Loss: 0.068912, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27382 - Train Loss: 0.068910, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27383 - Train Loss: 0.068909, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27384 - Train Loss: 0.068908, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27385 - Train Loss: 0.068906, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27386 - Train Loss: 0.068905, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27387 - Train Loss: 0.068904, Train Acc: 0.893590 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 27388 - Train Loss: 0.068903, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27389 - Train Loss: 0.068901, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27390 - Train Loss: 0.068900, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27391 - Train Loss: 0.068899, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27392 - Train Loss: 0.068898, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27393 - Train Loss: 0.068896, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27394 - Train Loss: 0.068895, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27395 - Train Loss: 0.068894, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27396 - Train Loss: 0.068892, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27397 - Train Loss: 0.068891, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27398 - Train Loss: 0.068890, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27399 - Train Loss: 0.068889, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27400 - Train Loss: 0.068887, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27401 - Train Loss: 0.068886, Train Acc: 0.893590 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 27402 - Train Loss: 0.068885, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27403 - Train Loss: 0.068884, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27404 - Train Loss: 0.068882, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27405 - Train Loss: 0.068881, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27406 - Train Loss: 0.068880, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27407 - Train Loss: 0.068879, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27408 - Train Loss: 0.068877, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27409 - Train Loss: 0.068876, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27410 - Train Loss: 0.068875, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27411 - Train Loss: 0.068873, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27412 - Train Loss: 0.068872, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27413 - Train Loss: 0.068871, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27414 - Train Loss: 0.068870, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27415 - Train Loss: 0.068868, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27416 - Train Loss: 0.068867, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27417 - Train Loss: 0.068866, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27418 - Train Loss: 0.068865, Train Acc: 0.893590 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 27419 - Train Loss: 0.068863, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27420 - Train Loss: 0.068862, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27421 - Train Loss: 0.068861, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27422 - Train Loss: 0.068860, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27423 - Train Loss: 0.068858, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27424 - Train Loss: 0.068857, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27425 - Train Loss: 0.068856, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27426 - Train Loss: 0.068855, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27427 - Train Loss: 0.068853, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27428 - Train Loss: 0.068852, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27429 - Train Loss: 0.068851, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27430 - Train Loss: 0.068849, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27431 - Train Loss: 0.068848, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27432 - Train Loss: 0.068847, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27433 - Train Loss: 0.068846, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27434 - Train Loss: 0.068844, Train Acc: 0.893590 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 27435 - Train Loss: 0.068843, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27436 - Train Loss: 0.068842, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27437 - Train Loss: 0.068841, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27438 - Train Loss: 0.068839, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27439 - Train Loss: 0.068838, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27440 - Train Loss: 0.068837, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27441 - Train Loss: 0.068836, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27442 - Train Loss: 0.068834, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27443 - Train Loss: 0.068833, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27444 - Train Loss: 0.068832, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27445 - Train Loss: 0.068831, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27446 - Train Loss: 0.068829, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27447 - Train Loss: 0.068828, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27448 - Train Loss: 0.068827, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27449 - Train Loss: 0.068825, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27450 - Train Loss: 0.068824, Train Acc: 0.893590 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 27451 - Train Loss: 0.068823, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27452 - Train Loss: 0.068822, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27453 - Train Loss: 0.068820, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27454 - Train Loss: 0.068819, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27455 - Train Loss: 0.068818, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27456 - Train Loss: 0.068817, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27457 - Train Loss: 0.068815, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27458 - Train Loss: 0.068814, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27459 - Train Loss: 0.068813, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27460 - Train Loss: 0.068812, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27461 - Train Loss: 0.068810, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27462 - Train Loss: 0.068809, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27463 - Train Loss: 0.068808, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27464 - Train Loss: 0.068807, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27465 - Train Loss: 0.068805, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27466 - Train Loss: 0.068804, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27467 - Train Loss: 0.068803, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27468 - Train Loss: 0.068801, Train Acc: 0.893590 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 27469 - Train Loss: 0.068800, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27470 - Train Loss: 0.068799, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27471 - Train Loss: 0.068798, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27472 - Train Loss: 0.068796, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27473 - Train Loss: 0.068795, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27474 - Train Loss: 0.068794, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27475 - Train Loss: 0.068793, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27476 - Train Loss: 0.068791, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27477 - Train Loss: 0.068790, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27478 - Train Loss: 0.068789, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27479 - Train Loss: 0.068788, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27480 - Train Loss: 0.068786, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27481 - Train Loss: 0.068785, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27482 - Train Loss: 0.068784, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27483 - Train Loss: 0.068783, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27484 - Train Loss: 0.068781, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27485 - Train Loss: 0.068780, Train Acc: 0.893590 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 27486 - Train Loss: 0.068779, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27487 - Train Loss: 0.068778, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27488 - Train Loss: 0.068776, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27489 - Train Loss: 0.068775, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27490 - Train Loss: 0.068774, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27491 - Train Loss: 0.068772, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27492 - Train Loss: 0.068771, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27493 - Train Loss: 0.068770, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27494 - Train Loss: 0.068769, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27495 - Train Loss: 0.068767, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27496 - Train Loss: 0.068766, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27497 - Train Loss: 0.068765, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27498 - Train Loss: 0.068764, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27499 - Train Loss: 0.068762, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27500 - Train Loss: 0.068761, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27501 - Train Loss: 0.068760, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27502 - Train Loss: 0.068759, Train Acc: 0.893590 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 27503 - Train Loss: 0.068757, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27504 - Train Loss: 0.068756, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27505 - Train Loss: 0.068755, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27506 - Train Loss: 0.068754, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27507 - Train Loss: 0.068752, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27508 - Train Loss: 0.068751, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27509 - Train Loss: 0.068750, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27510 - Train Loss: 0.068749, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27511 - Train Loss: 0.068747, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27512 - Train Loss: 0.068746, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27513 - Train Loss: 0.068745, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27514 - Train Loss: 0.068744, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27515 - Train Loss: 0.068742, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27516 - Train Loss: 0.068741, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27517 - Train Loss: 0.068740, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27518 - Train Loss: 0.068738, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27519 - Train Loss: 0.068737, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27520 - Train Loss: 0.068736, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27521 - Train Loss: 0.068735, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27522 - Train Loss: 0.068733, Train Acc: 0.893590 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 27523 - Train Loss: 0.068732, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27524 - Train Loss: 0.068731, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27525 - Train Loss: 0.068730, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27526 - Train Loss: 0.068728, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27527 - Train Loss: 0.068727, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27528 - Train Loss: 0.068726, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27529 - Train Loss: 0.068725, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27530 - Train Loss: 0.068723, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27531 - Train Loss: 0.068722, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27532 - Train Loss: 0.068721, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27533 - Train Loss: 0.068720, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27534 - Train Loss: 0.068718, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27535 - Train Loss: 0.068717, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27536 - Train Loss: 0.068716, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27537 - Train Loss: 0.068715, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27538 - Train Loss: 0.068713, Train Acc: 0.893590 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 27539 - Train Loss: 0.068712, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27540 - Train Loss: 0.068711, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27541 - Train Loss: 0.068710, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27542 - Train Loss: 0.068708, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27543 - Train Loss: 0.068707, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27544 - Train Loss: 0.068706, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27545 - Train Loss: 0.068705, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27546 - Train Loss: 0.068703, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27547 - Train Loss: 0.068702, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27548 - Train Loss: 0.068701, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27549 - Train Loss: 0.068700, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27550 - Train Loss: 0.068698, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27551 - Train Loss: 0.068697, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27552 - Train Loss: 0.068696, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27553 - Train Loss: 0.068695, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27554 - Train Loss: 0.068693, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27555 - Train Loss: 0.068692, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27556 - Train Loss: 0.068691, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27557 - Train Loss: 0.068690, Train Acc: 0.893590 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 27558 - Train Loss: 0.068688, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27559 - Train Loss: 0.068687, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27560 - Train Loss: 0.068686, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27561 - Train Loss: 0.068684, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27562 - Train Loss: 0.068683, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27563 - Train Loss: 0.068682, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27564 - Train Loss: 0.068681, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27565 - Train Loss: 0.068679, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27566 - Train Loss: 0.068678, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27567 - Train Loss: 0.068677, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27568 - Train Loss: 0.068676, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27569 - Train Loss: 0.068674, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27570 - Train Loss: 0.068673, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27571 - Train Loss: 0.068672, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27572 - Train Loss: 0.068671, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27573 - Train Loss: 0.068669, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27574 - Train Loss: 0.068668, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27575 - Train Loss: 0.068667, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27576 - Train Loss: 0.068666, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27577 - Train Loss: 0.068664, Train Acc: 0.893590 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 27578 - Train Loss: 0.068663, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27579 - Train Loss: 0.068662, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27580 - Train Loss: 0.068661, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27581 - Train Loss: 0.068659, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27582 - Train Loss: 0.068658, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27583 - Train Loss: 0.068657, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27584 - Train Loss: 0.068656, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27585 - Train Loss: 0.068654, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27586 - Train Loss: 0.068653, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27587 - Train Loss: 0.068652, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27588 - Train Loss: 0.068651, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27589 - Train Loss: 0.068649, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27590 - Train Loss: 0.068648, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27591 - Train Loss: 0.068647, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27592 - Train Loss: 0.068646, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27593 - Train Loss: 0.068644, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27594 - Train Loss: 0.068643, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27595 - Train Loss: 0.068642, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27596 - Train Loss: 0.068641, Train Acc: 0.893590 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 27597 - Train Loss: 0.068639, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27598 - Train Loss: 0.068638, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27599 - Train Loss: 0.068637, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27600 - Train Loss: 0.068636, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27601 - Train Loss: 0.068634, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27602 - Train Loss: 0.068633, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27603 - Train Loss: 0.068632, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27604 - Train Loss: 0.068631, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27605 - Train Loss: 0.068629, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27606 - Train Loss: 0.068628, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27607 - Train Loss: 0.068627, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27608 - Train Loss: 0.068626, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27609 - Train Loss: 0.068624, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27610 - Train Loss: 0.068623, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27611 - Train Loss: 0.068622, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27612 - Train Loss: 0.068621, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27613 - Train Loss: 0.068619, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27614 - Train Loss: 0.068618, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27615 - Train Loss: 0.068617, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27616 - Train Loss: 0.068616, Train Acc: 0.893590 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 27617 - Train Loss: 0.068614, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27618 - Train Loss: 0.068613, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27619 - Train Loss: 0.068612, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27620 - Train Loss: 0.068611, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27621 - Train Loss: 0.068609, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27622 - Train Loss: 0.068608, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27623 - Train Loss: 0.068607, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27624 - Train Loss: 0.068606, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27625 - Train Loss: 0.068604, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27626 - Train Loss: 0.068603, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27627 - Train Loss: 0.068602, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27628 - Train Loss: 0.068601, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27629 - Train Loss: 0.068599, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27630 - Train Loss: 0.068598, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27631 - Train Loss: 0.068597, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27632 - Train Loss: 0.068596, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27633 - Train Loss: 0.068594, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27634 - Train Loss: 0.068593, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27635 - Train Loss: 0.068592, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27636 - Train Loss: 0.068591, Train Acc: 0.893590 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 27637 - Train Loss: 0.068589, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27638 - Train Loss: 0.068588, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27639 - Train Loss: 0.068587, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27640 - Train Loss: 0.068586, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27641 - Train Loss: 0.068584, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27642 - Train Loss: 0.068583, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27643 - Train Loss: 0.068582, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27644 - Train Loss: 0.068581, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27645 - Train Loss: 0.068579, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27646 - Train Loss: 0.068578, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27647 - Train Loss: 0.068577, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27648 - Train Loss: 0.068576, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27649 - Train Loss: 0.068574, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27650 - Train Loss: 0.068573, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27651 - Train Loss: 0.068572, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27652 - Train Loss: 0.068571, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27653 - Train Loss: 0.068569, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27654 - Train Loss: 0.068568, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27655 - Train Loss: 0.068567, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27656 - Train Loss: 0.068566, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27657 - Train Loss: 0.068564, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27658 - Train Loss: 0.068563, Train Acc: 0.893590 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 27659 - Train Loss: 0.068562, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27660 - Train Loss: 0.068561, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27661 - Train Loss: 0.068559, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27662 - Train Loss: 0.068558, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27663 - Train Loss: 0.068557, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27664 - Train Loss: 0.068556, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27665 - Train Loss: 0.068554, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27666 - Train Loss: 0.068553, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27667 - Train Loss: 0.068552, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27668 - Train Loss: 0.068551, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27669 - Train Loss: 0.068549, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27670 - Train Loss: 0.068548, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27671 - Train Loss: 0.068547, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27672 - Train Loss: 0.068546, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27673 - Train Loss: 0.068545, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27674 - Train Loss: 0.068543, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27675 - Train Loss: 0.068542, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27676 - Train Loss: 0.068541, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27677 - Train Loss: 0.068540, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27678 - Train Loss: 0.068538, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27679 - Train Loss: 0.068537, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27680 - Train Loss: 0.068536, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27681 - Train Loss: 0.068535, Train Acc: 0.893590 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 27682 - Train Loss: 0.068533, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27683 - Train Loss: 0.068532, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27684 - Train Loss: 0.068531, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27685 - Train Loss: 0.068530, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27686 - Train Loss: 0.068528, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27687 - Train Loss: 0.068527, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27688 - Train Loss: 0.068526, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27689 - Train Loss: 0.068525, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27690 - Train Loss: 0.068523, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27691 - Train Loss: 0.068522, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27692 - Train Loss: 0.068521, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27693 - Train Loss: 0.068520, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27694 - Train Loss: 0.068518, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27695 - Train Loss: 0.068517, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27696 - Train Loss: 0.068516, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27697 - Train Loss: 0.068515, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27698 - Train Loss: 0.068513, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27699 - Train Loss: 0.068512, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27700 - Train Loss: 0.068511, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27701 - Train Loss: 0.068510, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27702 - Train Loss: 0.068508, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27703 - Train Loss: 0.068507, Train Acc: 0.893590 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 27704 - Train Loss: 0.068506, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27705 - Train Loss: 0.068505, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27706 - Train Loss: 0.068503, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27707 - Train Loss: 0.068502, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27708 - Train Loss: 0.068501, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27709 - Train Loss: 0.068500, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27710 - Train Loss: 0.068498, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27711 - Train Loss: 0.068497, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27712 - Train Loss: 0.068496, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27713 - Train Loss: 0.068495, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27714 - Train Loss: 0.068494, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27715 - Train Loss: 0.068492, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27716 - Train Loss: 0.068491, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27717 - Train Loss: 0.068490, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27718 - Train Loss: 0.068489, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27719 - Train Loss: 0.068487, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27720 - Train Loss: 0.068486, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27721 - Train Loss: 0.068485, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27722 - Train Loss: 0.068484, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27723 - Train Loss: 0.068482, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27724 - Train Loss: 0.068481, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27725 - Train Loss: 0.068480, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27726 - Train Loss: 0.068479, Train Acc: 0.893590 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 27727 - Train Loss: 0.068477, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27728 - Train Loss: 0.068476, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27729 - Train Loss: 0.068475, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27730 - Train Loss: 0.068474, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27731 - Train Loss: 0.068472, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27732 - Train Loss: 0.068471, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27733 - Train Loss: 0.068470, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27734 - Train Loss: 0.068469, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27735 - Train Loss: 0.068467, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27736 - Train Loss: 0.068466, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27737 - Train Loss: 0.068465, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27738 - Train Loss: 0.068464, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27739 - Train Loss: 0.068462, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27740 - Train Loss: 0.068461, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27741 - Train Loss: 0.068460, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27742 - Train Loss: 0.068459, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27743 - Train Loss: 0.068458, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27744 - Train Loss: 0.068456, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27745 - Train Loss: 0.068455, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27746 - Train Loss: 0.068454, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27747 - Train Loss: 0.068453, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27748 - Train Loss: 0.068451, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27749 - Train Loss: 0.068450, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27750 - Train Loss: 0.068449, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27751 - Train Loss: 0.068448, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27752 - Train Loss: 0.068446, Train Acc: 0.893590 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 27753 - Train Loss: 0.068445, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27754 - Train Loss: 0.068444, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27755 - Train Loss: 0.068443, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27756 - Train Loss: 0.068441, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27757 - Train Loss: 0.068440, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27758 - Train Loss: 0.068439, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27759 - Train Loss: 0.068438, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27760 - Train Loss: 0.068436, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27761 - Train Loss: 0.068435, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27762 - Train Loss: 0.068434, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27763 - Train Loss: 0.068433, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27764 - Train Loss: 0.068431, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27765 - Train Loss: 0.068430, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27766 - Train Loss: 0.068429, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27767 - Train Loss: 0.068428, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27768 - Train Loss: 0.068427, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27769 - Train Loss: 0.068425, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27770 - Train Loss: 0.068424, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27771 - Train Loss: 0.068423, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27772 - Train Loss: 0.068422, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27773 - Train Loss: 0.068420, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27774 - Train Loss: 0.068419, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27775 - Train Loss: 0.068418, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27776 - Train Loss: 0.068417, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27777 - Train Loss: 0.068415, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27778 - Train Loss: 0.068414, Train Acc: 0.893590 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 27779 - Train Loss: 0.068413, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27780 - Train Loss: 0.068412, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27781 - Train Loss: 0.068410, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27782 - Train Loss: 0.068409, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27783 - Train Loss: 0.068408, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27784 - Train Loss: 0.068407, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27785 - Train Loss: 0.068405, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27786 - Train Loss: 0.068404, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27787 - Train Loss: 0.068403, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27788 - Train Loss: 0.068402, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27789 - Train Loss: 0.068401, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27790 - Train Loss: 0.068399, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27791 - Train Loss: 0.068398, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27792 - Train Loss: 0.068397, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27793 - Train Loss: 0.068396, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27794 - Train Loss: 0.068394, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27795 - Train Loss: 0.068393, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27796 - Train Loss: 0.068392, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27797 - Train Loss: 0.068391, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27798 - Train Loss: 0.068389, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27799 - Train Loss: 0.068388, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27800 - Train Loss: 0.068387, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27801 - Train Loss: 0.068386, Train Acc: 0.893590 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 27802 - Train Loss: 0.068384, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27803 - Train Loss: 0.068383, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27804 - Train Loss: 0.068382, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27805 - Train Loss: 0.068381, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27806 - Train Loss: 0.068380, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27807 - Train Loss: 0.068378, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27808 - Train Loss: 0.068377, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27809 - Train Loss: 0.068376, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27810 - Train Loss: 0.068375, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27811 - Train Loss: 0.068373, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27812 - Train Loss: 0.068372, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27813 - Train Loss: 0.068371, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27814 - Train Loss: 0.068370, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27815 - Train Loss: 0.068368, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27816 - Train Loss: 0.068367, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27817 - Train Loss: 0.068366, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27818 - Train Loss: 0.068365, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27819 - Train Loss: 0.068363, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27820 - Train Loss: 0.068362, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27821 - Train Loss: 0.068361, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27822 - Train Loss: 0.068360, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27823 - Train Loss: 0.068359, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27824 - Train Loss: 0.068357, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27825 - Train Loss: 0.068356, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27826 - Train Loss: 0.068355, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27827 - Train Loss: 0.068354, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27828 - Train Loss: 0.068352, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27829 - Train Loss: 0.068351, Train Acc: 0.893590 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 27830 - Train Loss: 0.068350, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27831 - Train Loss: 0.068349, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27832 - Train Loss: 0.068347, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27833 - Train Loss: 0.068346, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27834 - Train Loss: 0.068345, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27835 - Train Loss: 0.068344, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27836 - Train Loss: 0.068343, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27837 - Train Loss: 0.068341, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27838 - Train Loss: 0.068340, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27839 - Train Loss: 0.068339, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27840 - Train Loss: 0.068338, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27841 - Train Loss: 0.068336, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27842 - Train Loss: 0.068335, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27843 - Train Loss: 0.068334, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27844 - Train Loss: 0.068333, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27845 - Train Loss: 0.068331, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27846 - Train Loss: 0.068330, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27847 - Train Loss: 0.068329, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27848 - Train Loss: 0.068328, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27849 - Train Loss: 0.068326, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27850 - Train Loss: 0.068325, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27851 - Train Loss: 0.068324, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27852 - Train Loss: 0.068323, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27853 - Train Loss: 0.068322, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27854 - Train Loss: 0.068320, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27855 - Train Loss: 0.068319, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27856 - Train Loss: 0.068318, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27857 - Train Loss: 0.068317, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27858 - Train Loss: 0.068315, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27859 - Train Loss: 0.068314, Train Acc: 0.893590 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 27860 - Train Loss: 0.068313, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27861 - Train Loss: 0.068312, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27862 - Train Loss: 0.068310, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27863 - Train Loss: 0.068309, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27864 - Train Loss: 0.068308, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27865 - Train Loss: 0.068307, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27866 - Train Loss: 0.068306, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27867 - Train Loss: 0.068304, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27868 - Train Loss: 0.068303, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27869 - Train Loss: 0.068302, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27870 - Train Loss: 0.068301, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27871 - Train Loss: 0.068299, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27872 - Train Loss: 0.068298, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27873 - Train Loss: 0.068297, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27874 - Train Loss: 0.068296, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27875 - Train Loss: 0.068294, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27876 - Train Loss: 0.068293, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27877 - Train Loss: 0.068292, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27878 - Train Loss: 0.068291, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27879 - Train Loss: 0.068290, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27880 - Train Loss: 0.068288, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27881 - Train Loss: 0.068287, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27882 - Train Loss: 0.068286, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27883 - Train Loss: 0.068285, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27884 - Train Loss: 0.068283, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27885 - Train Loss: 0.068282, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27886 - Train Loss: 0.068281, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27887 - Train Loss: 0.068280, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27888 - Train Loss: 0.068278, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27889 - Train Loss: 0.068277, Train Acc: 0.893590 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 27890 - Train Loss: 0.068276, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27891 - Train Loss: 0.068275, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27892 - Train Loss: 0.068274, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27893 - Train Loss: 0.068272, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27894 - Train Loss: 0.068271, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27895 - Train Loss: 0.068270, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27896 - Train Loss: 0.068269, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27897 - Train Loss: 0.068267, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27898 - Train Loss: 0.068266, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27899 - Train Loss: 0.068265, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27900 - Train Loss: 0.068264, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27901 - Train Loss: 0.068263, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27902 - Train Loss: 0.068261, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27903 - Train Loss: 0.068260, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27904 - Train Loss: 0.068259, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27905 - Train Loss: 0.068258, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27906 - Train Loss: 0.068256, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27907 - Train Loss: 0.068255, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27908 - Train Loss: 0.068254, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27909 - Train Loss: 0.068253, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27910 - Train Loss: 0.068251, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27911 - Train Loss: 0.068250, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27912 - Train Loss: 0.068249, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27913 - Train Loss: 0.068248, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27914 - Train Loss: 0.068247, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27915 - Train Loss: 0.068245, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27916 - Train Loss: 0.068244, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27917 - Train Loss: 0.068243, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27918 - Train Loss: 0.068242, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27919 - Train Loss: 0.068240, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27920 - Train Loss: 0.068239, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27921 - Train Loss: 0.068238, Train Acc: 0.893590 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 27922 - Train Loss: 0.068237, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27923 - Train Loss: 0.068235, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27924 - Train Loss: 0.068234, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27925 - Train Loss: 0.068233, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27926 - Train Loss: 0.068232, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27927 - Train Loss: 0.068231, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27928 - Train Loss: 0.068229, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27929 - Train Loss: 0.068228, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27930 - Train Loss: 0.068227, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27931 - Train Loss: 0.068226, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27932 - Train Loss: 0.068224, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27933 - Train Loss: 0.068223, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27934 - Train Loss: 0.068222, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27935 - Train Loss: 0.068221, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27936 - Train Loss: 0.068220, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27937 - Train Loss: 0.068218, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27938 - Train Loss: 0.068217, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27939 - Train Loss: 0.068216, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27940 - Train Loss: 0.068215, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27941 - Train Loss: 0.068213, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27942 - Train Loss: 0.068212, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27943 - Train Loss: 0.068211, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27944 - Train Loss: 0.068210, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27945 - Train Loss: 0.068209, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27946 - Train Loss: 0.068207, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27947 - Train Loss: 0.068206, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27948 - Train Loss: 0.068205, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27949 - Train Loss: 0.068204, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27950 - Train Loss: 0.068202, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27951 - Train Loss: 0.068201, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27952 - Train Loss: 0.068200, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27953 - Train Loss: 0.068199, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27954 - Train Loss: 0.068197, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27955 - Train Loss: 0.068196, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27956 - Train Loss: 0.068195, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27957 - Train Loss: 0.068194, Train Acc: 0.893590 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 27958 - Train Loss: 0.068193, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27959 - Train Loss: 0.068191, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27960 - Train Loss: 0.068190, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27961 - Train Loss: 0.068189, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27962 - Train Loss: 0.068188, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27963 - Train Loss: 0.068186, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27964 - Train Loss: 0.068185, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27965 - Train Loss: 0.068184, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27966 - Train Loss: 0.068183, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27967 - Train Loss: 0.068182, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27968 - Train Loss: 0.068180, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27969 - Train Loss: 0.068179, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27970 - Train Loss: 0.068178, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27971 - Train Loss: 0.068177, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27972 - Train Loss: 0.068175, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27973 - Train Loss: 0.068174, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27974 - Train Loss: 0.068173, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27975 - Train Loss: 0.068172, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27976 - Train Loss: 0.068171, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27977 - Train Loss: 0.068169, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27978 - Train Loss: 0.068168, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27979 - Train Loss: 0.068167, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27980 - Train Loss: 0.068166, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27981 - Train Loss: 0.068164, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27982 - Train Loss: 0.068163, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27983 - Train Loss: 0.068162, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27984 - Train Loss: 0.068161, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27985 - Train Loss: 0.068160, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27986 - Train Loss: 0.068158, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27987 - Train Loss: 0.068157, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27988 - Train Loss: 0.068156, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27989 - Train Loss: 0.068155, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27990 - Train Loss: 0.068153, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27991 - Train Loss: 0.068152, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27992 - Train Loss: 0.068151, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 27993 - Train Loss: 0.068150, Train Acc: 0.893590 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 27994 - Train Loss: 0.068149, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 27995 - Train Loss: 0.068147, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 27996 - Train Loss: 0.068146, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 27997 - Train Loss: 0.068145, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 27998 - Train Loss: 0.068144, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 27999 - Train Loss: 0.068142, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28000 - Train Loss: 0.068141, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28001 - Train Loss: 0.068140, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28002 - Train Loss: 0.068139, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28003 - Train Loss: 0.068138, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28004 - Train Loss: 0.068136, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28005 - Train Loss: 0.068135, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28006 - Train Loss: 0.068134, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28007 - Train Loss: 0.068133, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28008 - Train Loss: 0.068131, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28009 - Train Loss: 0.068130, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28010 - Train Loss: 0.068129, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28011 - Train Loss: 0.068128, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28012 - Train Loss: 0.068127, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28013 - Train Loss: 0.068125, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28014 - Train Loss: 0.068124, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28015 - Train Loss: 0.068123, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28016 - Train Loss: 0.068122, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28017 - Train Loss: 0.068121, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28018 - Train Loss: 0.068119, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28019 - Train Loss: 0.068118, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28020 - Train Loss: 0.068117, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28021 - Train Loss: 0.068116, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28022 - Train Loss: 0.068114, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28023 - Train Loss: 0.068113, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28024 - Train Loss: 0.068112, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28025 - Train Loss: 0.068111, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28026 - Train Loss: 0.068110, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28027 - Train Loss: 0.068108, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28028 - Train Loss: 0.068107, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28029 - Train Loss: 0.068106, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28030 - Train Loss: 0.068105, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28031 - Train Loss: 0.068103, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28032 - Train Loss: 0.068102, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28033 - Train Loss: 0.068101, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28034 - Train Loss: 0.068100, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28035 - Train Loss: 0.068099, Train Acc: 0.893590 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28036 - Train Loss: 0.068097, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28037 - Train Loss: 0.068096, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28038 - Train Loss: 0.068095, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28039 - Train Loss: 0.068094, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28040 - Train Loss: 0.068092, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28041 - Train Loss: 0.068091, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28042 - Train Loss: 0.068090, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28043 - Train Loss: 0.068089, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28044 - Train Loss: 0.068088, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28045 - Train Loss: 0.068086, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28046 - Train Loss: 0.068085, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28047 - Train Loss: 0.068084, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28048 - Train Loss: 0.068083, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28049 - Train Loss: 0.068082, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28050 - Train Loss: 0.068080, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28051 - Train Loss: 0.068079, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28052 - Train Loss: 0.068078, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28053 - Train Loss: 0.068077, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28054 - Train Loss: 0.068075, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28055 - Train Loss: 0.068074, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28056 - Train Loss: 0.068073, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28057 - Train Loss: 0.068072, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28058 - Train Loss: 0.068071, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28059 - Train Loss: 0.068069, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28060 - Train Loss: 0.068068, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28061 - Train Loss: 0.068067, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28062 - Train Loss: 0.068066, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28063 - Train Loss: 0.068064, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28064 - Train Loss: 0.068063, Train Acc: 0.893590 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28065 - Train Loss: 0.068062, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28066 - Train Loss: 0.068061, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28067 - Train Loss: 0.068060, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28068 - Train Loss: 0.068058, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28069 - Train Loss: 0.068057, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28070 - Train Loss: 0.068056, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28071 - Train Loss: 0.068055, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28072 - Train Loss: 0.068054, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28073 - Train Loss: 0.068052, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28074 - Train Loss: 0.068051, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28075 - Train Loss: 0.068050, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28076 - Train Loss: 0.068049, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28077 - Train Loss: 0.068047, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28078 - Train Loss: 0.068046, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28079 - Train Loss: 0.068045, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28080 - Train Loss: 0.068044, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28081 - Train Loss: 0.068043, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28082 - Train Loss: 0.068041, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28083 - Train Loss: 0.068040, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28084 - Train Loss: 0.068039, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28085 - Train Loss: 0.068038, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28086 - Train Loss: 0.068037, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28087 - Train Loss: 0.068035, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28088 - Train Loss: 0.068034, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28089 - Train Loss: 0.068033, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28090 - Train Loss: 0.068032, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28091 - Train Loss: 0.068030, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28092 - Train Loss: 0.068029, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28093 - Train Loss: 0.068028, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28094 - Train Loss: 0.068027, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28095 - Train Loss: 0.068026, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28096 - Train Loss: 0.068024, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28097 - Train Loss: 0.068023, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28098 - Train Loss: 0.068022, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28099 - Train Loss: 0.068021, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28100 - Train Loss: 0.068020, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28101 - Train Loss: 0.068018, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28102 - Train Loss: 0.068017, Train Acc: 0.893590 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28103 - Train Loss: 0.068016, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28104 - Train Loss: 0.068015, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28105 - Train Loss: 0.068014, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28106 - Train Loss: 0.068012, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28107 - Train Loss: 0.068011, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28108 - Train Loss: 0.068010, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28109 - Train Loss: 0.068009, Train Acc: 0.893590 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28110 - Train Loss: 0.068007, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28111 - Train Loss: 0.068006, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28112 - Train Loss: 0.068005, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28113 - Train Loss: 0.068004, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28114 - Train Loss: 0.068003, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28115 - Train Loss: 0.068001, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28116 - Train Loss: 0.068000, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28117 - Train Loss: 0.067999, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28118 - Train Loss: 0.067998, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28119 - Train Loss: 0.067997, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28120 - Train Loss: 0.067995, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28121 - Train Loss: 0.067994, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28122 - Train Loss: 0.067993, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28123 - Train Loss: 0.067992, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28124 - Train Loss: 0.067990, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28125 - Train Loss: 0.067989, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28126 - Train Loss: 0.067988, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28127 - Train Loss: 0.067987, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28128 - Train Loss: 0.067986, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28129 - Train Loss: 0.067984, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28130 - Train Loss: 0.067983, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28131 - Train Loss: 0.067982, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28132 - Train Loss: 0.067981, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28133 - Train Loss: 0.067980, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28134 - Train Loss: 0.067978, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28135 - Train Loss: 0.067977, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28136 - Train Loss: 0.067976, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28137 - Train Loss: 0.067975, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28138 - Train Loss: 0.067974, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28139 - Train Loss: 0.067972, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28140 - Train Loss: 0.067971, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28141 - Train Loss: 0.067970, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28142 - Train Loss: 0.067969, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28143 - Train Loss: 0.067967, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28144 - Train Loss: 0.067966, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28145 - Train Loss: 0.067965, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28146 - Train Loss: 0.067964, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28147 - Train Loss: 0.067963, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28148 - Train Loss: 0.067961, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28149 - Train Loss: 0.067960, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28150 - Train Loss: 0.067959, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28151 - Train Loss: 0.067958, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28152 - Train Loss: 0.067957, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28153 - Train Loss: 0.067955, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28154 - Train Loss: 0.067954, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28155 - Train Loss: 0.067953, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28156 - Train Loss: 0.067952, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28157 - Train Loss: 0.067951, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28158 - Train Loss: 0.067949, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28159 - Train Loss: 0.067948, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28160 - Train Loss: 0.067947, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28161 - Train Loss: 0.067946, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28162 - Train Loss: 0.067945, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28163 - Train Loss: 0.067943, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28164 - Train Loss: 0.067942, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28165 - Train Loss: 0.067941, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28166 - Train Loss: 0.067940, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28167 - Train Loss: 0.067938, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28168 - Train Loss: 0.067937, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28169 - Train Loss: 0.067936, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28170 - Train Loss: 0.067935, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28171 - Train Loss: 0.067934, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28172 - Train Loss: 0.067932, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28173 - Train Loss: 0.067931, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28174 - Train Loss: 0.067930, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28175 - Train Loss: 0.067929, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28176 - Train Loss: 0.067928, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28177 - Train Loss: 0.067926, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28178 - Train Loss: 0.067925, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28179 - Train Loss: 0.067924, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28180 - Train Loss: 0.067923, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28181 - Train Loss: 0.067922, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28182 - Train Loss: 0.067920, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28183 - Train Loss: 0.067919, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28184 - Train Loss: 0.067918, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28185 - Train Loss: 0.067917, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28186 - Train Loss: 0.067916, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28187 - Train Loss: 0.067914, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28188 - Train Loss: 0.067913, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28189 - Train Loss: 0.067912, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28190 - Train Loss: 0.067911, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28191 - Train Loss: 0.067909, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28192 - Train Loss: 0.067908, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28193 - Train Loss: 0.067907, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28194 - Train Loss: 0.067906, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28195 - Train Loss: 0.067905, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28196 - Train Loss: 0.067903, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28197 - Train Loss: 0.067902, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28198 - Train Loss: 0.067901, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28199 - Train Loss: 0.067900, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28200 - Train Loss: 0.067899, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28201 - Train Loss: 0.067897, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28202 - Train Loss: 0.067896, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28203 - Train Loss: 0.067895, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28204 - Train Loss: 0.067894, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28205 - Train Loss: 0.067893, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28206 - Train Loss: 0.067891, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28207 - Train Loss: 0.067890, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28208 - Train Loss: 0.067889, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28209 - Train Loss: 0.067888, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28210 - Train Loss: 0.067887, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28211 - Train Loss: 0.067885, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28212 - Train Loss: 0.067884, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28213 - Train Loss: 0.067883, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28214 - Train Loss: 0.067882, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28215 - Train Loss: 0.067881, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28216 - Train Loss: 0.067879, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28217 - Train Loss: 0.067878, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28218 - Train Loss: 0.067877, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28219 - Train Loss: 0.067876, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28220 - Train Loss: 0.067875, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28221 - Train Loss: 0.067873, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28222 - Train Loss: 0.067872, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28223 - Train Loss: 0.067871, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28224 - Train Loss: 0.067870, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28225 - Train Loss: 0.067869, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28226 - Train Loss: 0.067867, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28227 - Train Loss: 0.067866, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28228 - Train Loss: 0.067865, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28229 - Train Loss: 0.067864, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28230 - Train Loss: 0.067863, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28231 - Train Loss: 0.067861, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28232 - Train Loss: 0.067860, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28233 - Train Loss: 0.067859, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28234 - Train Loss: 0.067858, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28235 - Train Loss: 0.067856, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28236 - Train Loss: 0.067855, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28237 - Train Loss: 0.067854, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28238 - Train Loss: 0.067853, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28239 - Train Loss: 0.067852, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28240 - Train Loss: 0.067850, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28241 - Train Loss: 0.067849, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28242 - Train Loss: 0.067848, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28243 - Train Loss: 0.067847, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28244 - Train Loss: 0.067846, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28245 - Train Loss: 0.067844, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28246 - Train Loss: 0.067843, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28247 - Train Loss: 0.067842, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28248 - Train Loss: 0.067841, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28249 - Train Loss: 0.067840, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28250 - Train Loss: 0.067838, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28251 - Train Loss: 0.067837, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28252 - Train Loss: 0.067836, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28253 - Train Loss: 0.067835, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28254 - Train Loss: 0.067834, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28255 - Train Loss: 0.067832, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28256 - Train Loss: 0.067831, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28257 - Train Loss: 0.067830, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28258 - Train Loss: 0.067829, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28259 - Train Loss: 0.067828, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28260 - Train Loss: 0.067826, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28261 - Train Loss: 0.067825, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28262 - Train Loss: 0.067824, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28263 - Train Loss: 0.067823, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28264 - Train Loss: 0.067822, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28265 - Train Loss: 0.067820, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28266 - Train Loss: 0.067819, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28267 - Train Loss: 0.067818, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28268 - Train Loss: 0.067817, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28269 - Train Loss: 0.067816, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28270 - Train Loss: 0.067814, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28271 - Train Loss: 0.067813, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28272 - Train Loss: 0.067812, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28273 - Train Loss: 0.067811, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28274 - Train Loss: 0.067810, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28275 - Train Loss: 0.067808, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28276 - Train Loss: 0.067807, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28277 - Train Loss: 0.067806, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28278 - Train Loss: 0.067805, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28279 - Train Loss: 0.067804, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28280 - Train Loss: 0.067802, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28281 - Train Loss: 0.067801, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28282 - Train Loss: 0.067800, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28283 - Train Loss: 0.067799, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28284 - Train Loss: 0.067798, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28285 - Train Loss: 0.067796, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28286 - Train Loss: 0.067795, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28287 - Train Loss: 0.067794, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28288 - Train Loss: 0.067793, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28289 - Train Loss: 0.067792, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28290 - Train Loss: 0.067790, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28291 - Train Loss: 0.067789, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28292 - Train Loss: 0.067788, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28293 - Train Loss: 0.067787, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28294 - Train Loss: 0.067786, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28295 - Train Loss: 0.067784, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28296 - Train Loss: 0.067783, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28297 - Train Loss: 0.067782, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28298 - Train Loss: 0.067781, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28299 - Train Loss: 0.067780, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28300 - Train Loss: 0.067778, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28301 - Train Loss: 0.067777, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28302 - Train Loss: 0.067776, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28303 - Train Loss: 0.067775, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28304 - Train Loss: 0.067774, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28305 - Train Loss: 0.067772, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28306 - Train Loss: 0.067771, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28307 - Train Loss: 0.067770, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28308 - Train Loss: 0.067769, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28309 - Train Loss: 0.067768, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28310 - Train Loss: 0.067766, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28311 - Train Loss: 0.067765, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28312 - Train Loss: 0.067764, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28313 - Train Loss: 0.067763, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28314 - Train Loss: 0.067762, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28315 - Train Loss: 0.067760, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28316 - Train Loss: 0.067759, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28317 - Train Loss: 0.067758, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28318 - Train Loss: 0.067757, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28319 - Train Loss: 0.067756, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28320 - Train Loss: 0.067754, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28321 - Train Loss: 0.067753, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28322 - Train Loss: 0.067752, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28323 - Train Loss: 0.067751, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28324 - Train Loss: 0.067750, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28325 - Train Loss: 0.067748, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28326 - Train Loss: 0.067747, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28327 - Train Loss: 0.067746, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28328 - Train Loss: 0.067745, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28329 - Train Loss: 0.067744, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28330 - Train Loss: 0.067743, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28331 - Train Loss: 0.067741, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28332 - Train Loss: 0.067740, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28333 - Train Loss: 0.067739, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28334 - Train Loss: 0.067738, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28335 - Train Loss: 0.067737, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28336 - Train Loss: 0.067735, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28337 - Train Loss: 0.067734, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28338 - Train Loss: 0.067733, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28339 - Train Loss: 0.067732, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28340 - Train Loss: 0.067731, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28341 - Train Loss: 0.067729, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28342 - Train Loss: 0.067728, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28343 - Train Loss: 0.067727, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28344 - Train Loss: 0.067726, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28345 - Train Loss: 0.067725, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28346 - Train Loss: 0.067723, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28347 - Train Loss: 0.067722, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28348 - Train Loss: 0.067721, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28349 - Train Loss: 0.067720, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28350 - Train Loss: 0.067719, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28351 - Train Loss: 0.067717, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28352 - Train Loss: 0.067716, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28353 - Train Loss: 0.067715, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28354 - Train Loss: 0.067714, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28355 - Train Loss: 0.067713, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28356 - Train Loss: 0.067711, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28357 - Train Loss: 0.067710, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28358 - Train Loss: 0.067709, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28359 - Train Loss: 0.067708, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28360 - Train Loss: 0.067707, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28361 - Train Loss: 0.067705, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28362 - Train Loss: 0.067704, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28363 - Train Loss: 0.067703, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28364 - Train Loss: 0.067702, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28365 - Train Loss: 0.067701, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28366 - Train Loss: 0.067699, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28367 - Train Loss: 0.067698, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28368 - Train Loss: 0.067697, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28369 - Train Loss: 0.067696, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28370 - Train Loss: 0.067695, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28371 - Train Loss: 0.067693, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28372 - Train Loss: 0.067692, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28373 - Train Loss: 0.067691, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28374 - Train Loss: 0.067690, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28375 - Train Loss: 0.067689, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28376 - Train Loss: 0.067688, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28377 - Train Loss: 0.067686, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28378 - Train Loss: 0.067685, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28379 - Train Loss: 0.067684, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28380 - Train Loss: 0.067683, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28381 - Train Loss: 0.067682, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28382 - Train Loss: 0.067680, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28383 - Train Loss: 0.067679, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28384 - Train Loss: 0.067678, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28385 - Train Loss: 0.067677, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28386 - Train Loss: 0.067676, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28387 - Train Loss: 0.067674, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28388 - Train Loss: 0.067673, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28389 - Train Loss: 0.067672, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28390 - Train Loss: 0.067671, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28391 - Train Loss: 0.067670, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28392 - Train Loss: 0.067668, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28393 - Train Loss: 0.067667, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28394 - Train Loss: 0.067666, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28395 - Train Loss: 0.067665, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28396 - Train Loss: 0.067664, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28397 - Train Loss: 0.067662, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28398 - Train Loss: 0.067661, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28399 - Train Loss: 0.067660, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28400 - Train Loss: 0.067659, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28401 - Train Loss: 0.067658, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28402 - Train Loss: 0.067657, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28403 - Train Loss: 0.067655, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28404 - Train Loss: 0.067654, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28405 - Train Loss: 0.067653, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28406 - Train Loss: 0.067652, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28407 - Train Loss: 0.067651, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28408 - Train Loss: 0.067649, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28409 - Train Loss: 0.067648, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28410 - Train Loss: 0.067647, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28411 - Train Loss: 0.067646, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28412 - Train Loss: 0.067645, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28413 - Train Loss: 0.067643, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28414 - Train Loss: 0.067642, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28415 - Train Loss: 0.067641, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28416 - Train Loss: 0.067640, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28417 - Train Loss: 0.067639, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28418 - Train Loss: 0.067637, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28419 - Train Loss: 0.067636, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28420 - Train Loss: 0.067635, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28421 - Train Loss: 0.067634, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28422 - Train Loss: 0.067633, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28423 - Train Loss: 0.067632, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28424 - Train Loss: 0.067630, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28425 - Train Loss: 0.067629, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28426 - Train Loss: 0.067628, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28427 - Train Loss: 0.067627, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28428 - Train Loss: 0.067626, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28429 - Train Loss: 0.067624, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28430 - Train Loss: 0.067623, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28431 - Train Loss: 0.067622, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28432 - Train Loss: 0.067621, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28433 - Train Loss: 0.067620, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28434 - Train Loss: 0.067618, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28435 - Train Loss: 0.067617, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28436 - Train Loss: 0.067616, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28437 - Train Loss: 0.067615, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28438 - Train Loss: 0.067614, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28439 - Train Loss: 0.067612, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28440 - Train Loss: 0.067611, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28441 - Train Loss: 0.067610, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28442 - Train Loss: 0.067609, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28443 - Train Loss: 0.067608, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28444 - Train Loss: 0.067607, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28445 - Train Loss: 0.067605, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28446 - Train Loss: 0.067604, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28447 - Train Loss: 0.067603, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28448 - Train Loss: 0.067602, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28449 - Train Loss: 0.067601, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28450 - Train Loss: 0.067599, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28451 - Train Loss: 0.067598, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28452 - Train Loss: 0.067597, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28453 - Train Loss: 0.067596, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28454 - Train Loss: 0.067595, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28455 - Train Loss: 0.067593, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28456 - Train Loss: 0.067592, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28457 - Train Loss: 0.067591, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28458 - Train Loss: 0.067590, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28459 - Train Loss: 0.067589, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28460 - Train Loss: 0.067588, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28461 - Train Loss: 0.067586, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28462 - Train Loss: 0.067585, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28463 - Train Loss: 0.067584, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28464 - Train Loss: 0.067583, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28465 - Train Loss: 0.067582, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28466 - Train Loss: 0.067580, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28467 - Train Loss: 0.067579, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28468 - Train Loss: 0.067578, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28469 - Train Loss: 0.067577, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28470 - Train Loss: 0.067576, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28471 - Train Loss: 0.067574, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28472 - Train Loss: 0.067573, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28473 - Train Loss: 0.067572, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28474 - Train Loss: 0.067571, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28475 - Train Loss: 0.067570, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28476 - Train Loss: 0.067569, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28477 - Train Loss: 0.067567, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28478 - Train Loss: 0.067566, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28479 - Train Loss: 0.067565, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28480 - Train Loss: 0.067564, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28481 - Train Loss: 0.067563, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28482 - Train Loss: 0.067561, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28483 - Train Loss: 0.067560, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28484 - Train Loss: 0.067559, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28485 - Train Loss: 0.067558, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28486 - Train Loss: 0.067557, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28487 - Train Loss: 0.067556, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28488 - Train Loss: 0.067554, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28489 - Train Loss: 0.067553, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28490 - Train Loss: 0.067552, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28491 - Train Loss: 0.067551, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28492 - Train Loss: 0.067550, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28493 - Train Loss: 0.067548, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28494 - Train Loss: 0.067547, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28495 - Train Loss: 0.067546, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28496 - Train Loss: 0.067545, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28497 - Train Loss: 0.067544, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28498 - Train Loss: 0.067542, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28499 - Train Loss: 0.067541, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28500 - Train Loss: 0.067540, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28501 - Train Loss: 0.067539, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28502 - Train Loss: 0.067538, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28503 - Train Loss: 0.067537, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28504 - Train Loss: 0.067535, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28505 - Train Loss: 0.067534, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28506 - Train Loss: 0.067533, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28507 - Train Loss: 0.067532, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28508 - Train Loss: 0.067531, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28509 - Train Loss: 0.067529, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28510 - Train Loss: 0.067528, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28511 - Train Loss: 0.067527, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28512 - Train Loss: 0.067526, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28513 - Train Loss: 0.067525, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28514 - Train Loss: 0.067524, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28515 - Train Loss: 0.067522, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28516 - Train Loss: 0.067521, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28517 - Train Loss: 0.067520, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28518 - Train Loss: 0.067519, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28519 - Train Loss: 0.067518, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28520 - Train Loss: 0.067516, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28521 - Train Loss: 0.067515, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28522 - Train Loss: 0.067514, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28523 - Train Loss: 0.067513, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28524 - Train Loss: 0.067512, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28525 - Train Loss: 0.067510, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28526 - Train Loss: 0.067509, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28527 - Train Loss: 0.067508, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28528 - Train Loss: 0.067507, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28529 - Train Loss: 0.067506, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28530 - Train Loss: 0.067505, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28531 - Train Loss: 0.067503, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28532 - Train Loss: 0.067502, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28533 - Train Loss: 0.067501, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28534 - Train Loss: 0.067500, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28535 - Train Loss: 0.067499, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28536 - Train Loss: 0.067497, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28537 - Train Loss: 0.067496, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28538 - Train Loss: 0.067495, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28539 - Train Loss: 0.067494, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28540 - Train Loss: 0.067493, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28541 - Train Loss: 0.067492, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28542 - Train Loss: 0.067490, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28543 - Train Loss: 0.067489, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28544 - Train Loss: 0.067488, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28545 - Train Loss: 0.067487, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28546 - Train Loss: 0.067486, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28547 - Train Loss: 0.067484, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28548 - Train Loss: 0.067483, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28549 - Train Loss: 0.067482, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28550 - Train Loss: 0.067481, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28551 - Train Loss: 0.067480, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28552 - Train Loss: 0.067479, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28553 - Train Loss: 0.067477, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28554 - Train Loss: 0.067476, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28555 - Train Loss: 0.067475, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28556 - Train Loss: 0.067474, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28557 - Train Loss: 0.067473, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28558 - Train Loss: 0.067471, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28559 - Train Loss: 0.067470, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28560 - Train Loss: 0.067469, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28561 - Train Loss: 0.067468, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28562 - Train Loss: 0.067467, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28563 - Train Loss: 0.067466, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28564 - Train Loss: 0.067464, Train Acc: 0.894872 | Val Loss: 0.107875, Val Acc: 0.804124\n",
      "Epoch 28565 - Train Loss: 0.067463, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28566 - Train Loss: 0.067462, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28567 - Train Loss: 0.067461, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28568 - Train Loss: 0.067460, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28569 - Train Loss: 0.067459, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28570 - Train Loss: 0.067457, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28571 - Train Loss: 0.067456, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28572 - Train Loss: 0.067455, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28573 - Train Loss: 0.067454, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28574 - Train Loss: 0.067453, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28575 - Train Loss: 0.067451, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28576 - Train Loss: 0.067450, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28577 - Train Loss: 0.067449, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28578 - Train Loss: 0.067448, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28579 - Train Loss: 0.067447, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28580 - Train Loss: 0.067446, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28581 - Train Loss: 0.067444, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28582 - Train Loss: 0.067443, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28583 - Train Loss: 0.067442, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28584 - Train Loss: 0.067441, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28585 - Train Loss: 0.067440, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28586 - Train Loss: 0.067438, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28587 - Train Loss: 0.067437, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28588 - Train Loss: 0.067436, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28589 - Train Loss: 0.067435, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28590 - Train Loss: 0.067434, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28591 - Train Loss: 0.067433, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28592 - Train Loss: 0.067431, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28593 - Train Loss: 0.067430, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28594 - Train Loss: 0.067429, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28595 - Train Loss: 0.067428, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28596 - Train Loss: 0.067427, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28597 - Train Loss: 0.067425, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28598 - Train Loss: 0.067424, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28599 - Train Loss: 0.067423, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28600 - Train Loss: 0.067422, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28601 - Train Loss: 0.067421, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28602 - Train Loss: 0.067420, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28603 - Train Loss: 0.067418, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28604 - Train Loss: 0.067417, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28605 - Train Loss: 0.067416, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28606 - Train Loss: 0.067415, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28607 - Train Loss: 0.067414, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28608 - Train Loss: 0.067413, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28609 - Train Loss: 0.067411, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28610 - Train Loss: 0.067410, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28611 - Train Loss: 0.067409, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28612 - Train Loss: 0.067408, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28613 - Train Loss: 0.067407, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28614 - Train Loss: 0.067405, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28615 - Train Loss: 0.067404, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28616 - Train Loss: 0.067403, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28617 - Train Loss: 0.067402, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28618 - Train Loss: 0.067401, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28619 - Train Loss: 0.067400, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28620 - Train Loss: 0.067398, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28621 - Train Loss: 0.067397, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28622 - Train Loss: 0.067396, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28623 - Train Loss: 0.067395, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28624 - Train Loss: 0.067394, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28625 - Train Loss: 0.067393, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28626 - Train Loss: 0.067391, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28627 - Train Loss: 0.067390, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28628 - Train Loss: 0.067389, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28629 - Train Loss: 0.067388, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28630 - Train Loss: 0.067387, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28631 - Train Loss: 0.067385, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28632 - Train Loss: 0.067384, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28633 - Train Loss: 0.067383, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28634 - Train Loss: 0.067382, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28635 - Train Loss: 0.067381, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28636 - Train Loss: 0.067380, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28637 - Train Loss: 0.067378, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28638 - Train Loss: 0.067377, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28639 - Train Loss: 0.067376, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28640 - Train Loss: 0.067375, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28641 - Train Loss: 0.067374, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28642 - Train Loss: 0.067373, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28643 - Train Loss: 0.067371, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28644 - Train Loss: 0.067370, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28645 - Train Loss: 0.067369, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28646 - Train Loss: 0.067368, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28647 - Train Loss: 0.067367, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28648 - Train Loss: 0.067365, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28649 - Train Loss: 0.067364, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28650 - Train Loss: 0.067363, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28651 - Train Loss: 0.067362, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28652 - Train Loss: 0.067361, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28653 - Train Loss: 0.067360, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28654 - Train Loss: 0.067358, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28655 - Train Loss: 0.067357, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28656 - Train Loss: 0.067356, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28657 - Train Loss: 0.067355, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28658 - Train Loss: 0.067354, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28659 - Train Loss: 0.067353, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28660 - Train Loss: 0.067351, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28661 - Train Loss: 0.067350, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28662 - Train Loss: 0.067349, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28663 - Train Loss: 0.067348, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28664 - Train Loss: 0.067347, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28665 - Train Loss: 0.067346, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28666 - Train Loss: 0.067344, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28667 - Train Loss: 0.067343, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28668 - Train Loss: 0.067342, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28669 - Train Loss: 0.067341, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28670 - Train Loss: 0.067340, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28671 - Train Loss: 0.067338, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28672 - Train Loss: 0.067337, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28673 - Train Loss: 0.067336, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28674 - Train Loss: 0.067335, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28675 - Train Loss: 0.067334, Train Acc: 0.894872 | Val Loss: 0.107876, Val Acc: 0.804124\n",
      "Epoch 28676 - Train Loss: 0.067333, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28677 - Train Loss: 0.067331, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28678 - Train Loss: 0.067330, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28679 - Train Loss: 0.067329, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28680 - Train Loss: 0.067328, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28681 - Train Loss: 0.067327, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28682 - Train Loss: 0.067326, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28683 - Train Loss: 0.067324, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28684 - Train Loss: 0.067323, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28685 - Train Loss: 0.067322, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28686 - Train Loss: 0.067321, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28687 - Train Loss: 0.067320, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28688 - Train Loss: 0.067319, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28689 - Train Loss: 0.067317, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28690 - Train Loss: 0.067316, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28691 - Train Loss: 0.067315, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28692 - Train Loss: 0.067314, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28693 - Train Loss: 0.067313, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28694 - Train Loss: 0.067312, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28695 - Train Loss: 0.067310, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28696 - Train Loss: 0.067309, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28697 - Train Loss: 0.067308, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28698 - Train Loss: 0.067307, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28699 - Train Loss: 0.067306, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28700 - Train Loss: 0.067305, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28701 - Train Loss: 0.067303, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28702 - Train Loss: 0.067302, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28703 - Train Loss: 0.067301, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28704 - Train Loss: 0.067300, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28705 - Train Loss: 0.067299, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28706 - Train Loss: 0.067297, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28707 - Train Loss: 0.067296, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28708 - Train Loss: 0.067295, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28709 - Train Loss: 0.067294, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28710 - Train Loss: 0.067293, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28711 - Train Loss: 0.067292, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28712 - Train Loss: 0.067290, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28713 - Train Loss: 0.067289, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28714 - Train Loss: 0.067288, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28715 - Train Loss: 0.067287, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28716 - Train Loss: 0.067286, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28717 - Train Loss: 0.067285, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28718 - Train Loss: 0.067283, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28719 - Train Loss: 0.067282, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28720 - Train Loss: 0.067281, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28721 - Train Loss: 0.067280, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28722 - Train Loss: 0.067279, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28723 - Train Loss: 0.067278, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28724 - Train Loss: 0.067276, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28725 - Train Loss: 0.067275, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28726 - Train Loss: 0.067274, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28727 - Train Loss: 0.067273, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28728 - Train Loss: 0.067272, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28729 - Train Loss: 0.067271, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28730 - Train Loss: 0.067269, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28731 - Train Loss: 0.067268, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28732 - Train Loss: 0.067267, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28733 - Train Loss: 0.067266, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28734 - Train Loss: 0.067265, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28735 - Train Loss: 0.067264, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28736 - Train Loss: 0.067262, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28737 - Train Loss: 0.067261, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28738 - Train Loss: 0.067260, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28739 - Train Loss: 0.067259, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28740 - Train Loss: 0.067258, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28741 - Train Loss: 0.067257, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28742 - Train Loss: 0.067255, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28743 - Train Loss: 0.067254, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28744 - Train Loss: 0.067253, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28745 - Train Loss: 0.067252, Train Acc: 0.894872 | Val Loss: 0.107877, Val Acc: 0.804124\n",
      "Epoch 28746 - Train Loss: 0.067251, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28747 - Train Loss: 0.067250, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28748 - Train Loss: 0.067248, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28749 - Train Loss: 0.067247, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28750 - Train Loss: 0.067246, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28751 - Train Loss: 0.067245, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28752 - Train Loss: 0.067244, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28753 - Train Loss: 0.067243, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28754 - Train Loss: 0.067241, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28755 - Train Loss: 0.067240, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28756 - Train Loss: 0.067239, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28757 - Train Loss: 0.067238, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28758 - Train Loss: 0.067237, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28759 - Train Loss: 0.067236, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28760 - Train Loss: 0.067234, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28761 - Train Loss: 0.067233, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28762 - Train Loss: 0.067232, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28763 - Train Loss: 0.067231, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28764 - Train Loss: 0.067230, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28765 - Train Loss: 0.067229, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28766 - Train Loss: 0.067227, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28767 - Train Loss: 0.067226, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28768 - Train Loss: 0.067225, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28769 - Train Loss: 0.067224, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28770 - Train Loss: 0.067223, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28771 - Train Loss: 0.067222, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28772 - Train Loss: 0.067220, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28773 - Train Loss: 0.067219, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28774 - Train Loss: 0.067218, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28775 - Train Loss: 0.067217, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28776 - Train Loss: 0.067216, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28777 - Train Loss: 0.067215, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28778 - Train Loss: 0.067213, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28779 - Train Loss: 0.067212, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28780 - Train Loss: 0.067211, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28781 - Train Loss: 0.067210, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28782 - Train Loss: 0.067209, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28783 - Train Loss: 0.067208, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28784 - Train Loss: 0.067206, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28785 - Train Loss: 0.067205, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28786 - Train Loss: 0.067204, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28787 - Train Loss: 0.067203, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28788 - Train Loss: 0.067202, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28789 - Train Loss: 0.067201, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28790 - Train Loss: 0.067199, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28791 - Train Loss: 0.067198, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28792 - Train Loss: 0.067197, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28793 - Train Loss: 0.067196, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28794 - Train Loss: 0.067195, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28795 - Train Loss: 0.067194, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28796 - Train Loss: 0.067192, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28797 - Train Loss: 0.067191, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28798 - Train Loss: 0.067190, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28799 - Train Loss: 0.067189, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28800 - Train Loss: 0.067188, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28801 - Train Loss: 0.067187, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28802 - Train Loss: 0.067185, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28803 - Train Loss: 0.067184, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28804 - Train Loss: 0.067183, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28805 - Train Loss: 0.067182, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28806 - Train Loss: 0.067181, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28807 - Train Loss: 0.067180, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28808 - Train Loss: 0.067178, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28809 - Train Loss: 0.067177, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28810 - Train Loss: 0.067176, Train Acc: 0.894872 | Val Loss: 0.107878, Val Acc: 0.804124\n",
      "Epoch 28811 - Train Loss: 0.067175, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28812 - Train Loss: 0.067174, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28813 - Train Loss: 0.067173, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28814 - Train Loss: 0.067171, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28815 - Train Loss: 0.067170, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28816 - Train Loss: 0.067169, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28817 - Train Loss: 0.067168, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28818 - Train Loss: 0.067167, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28819 - Train Loss: 0.067166, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28820 - Train Loss: 0.067164, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28821 - Train Loss: 0.067163, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28822 - Train Loss: 0.067162, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28823 - Train Loss: 0.067161, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28824 - Train Loss: 0.067160, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28825 - Train Loss: 0.067159, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28826 - Train Loss: 0.067157, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28827 - Train Loss: 0.067156, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28828 - Train Loss: 0.067155, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28829 - Train Loss: 0.067154, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28830 - Train Loss: 0.067153, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28831 - Train Loss: 0.067152, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28832 - Train Loss: 0.067151, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28833 - Train Loss: 0.067149, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28834 - Train Loss: 0.067148, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28835 - Train Loss: 0.067147, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28836 - Train Loss: 0.067146, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28837 - Train Loss: 0.067145, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28838 - Train Loss: 0.067144, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28839 - Train Loss: 0.067142, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28840 - Train Loss: 0.067141, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28841 - Train Loss: 0.067140, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28842 - Train Loss: 0.067139, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28843 - Train Loss: 0.067138, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28844 - Train Loss: 0.067137, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28845 - Train Loss: 0.067135, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28846 - Train Loss: 0.067134, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28847 - Train Loss: 0.067133, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28848 - Train Loss: 0.067132, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28849 - Train Loss: 0.067131, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28850 - Train Loss: 0.067130, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28851 - Train Loss: 0.067128, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28852 - Train Loss: 0.067127, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28853 - Train Loss: 0.067126, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28854 - Train Loss: 0.067125, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28855 - Train Loss: 0.067124, Train Acc: 0.894872 | Val Loss: 0.107879, Val Acc: 0.804124\n",
      "Epoch 28856 - Train Loss: 0.067123, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28857 - Train Loss: 0.067122, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28858 - Train Loss: 0.067120, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28859 - Train Loss: 0.067119, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28860 - Train Loss: 0.067118, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28861 - Train Loss: 0.067117, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28862 - Train Loss: 0.067116, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28863 - Train Loss: 0.067115, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28864 - Train Loss: 0.067113, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28865 - Train Loss: 0.067112, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28866 - Train Loss: 0.067111, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28867 - Train Loss: 0.067110, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28868 - Train Loss: 0.067109, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28869 - Train Loss: 0.067108, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28870 - Train Loss: 0.067106, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28871 - Train Loss: 0.067105, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28872 - Train Loss: 0.067104, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28873 - Train Loss: 0.067103, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28874 - Train Loss: 0.067102, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28875 - Train Loss: 0.067101, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28876 - Train Loss: 0.067099, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28877 - Train Loss: 0.067098, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28878 - Train Loss: 0.067097, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28879 - Train Loss: 0.067096, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28880 - Train Loss: 0.067095, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28881 - Train Loss: 0.067094, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28882 - Train Loss: 0.067093, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28883 - Train Loss: 0.067091, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28884 - Train Loss: 0.067090, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28885 - Train Loss: 0.067089, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28886 - Train Loss: 0.067088, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28887 - Train Loss: 0.067087, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28888 - Train Loss: 0.067086, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28889 - Train Loss: 0.067084, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28890 - Train Loss: 0.067083, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28891 - Train Loss: 0.067082, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28892 - Train Loss: 0.067081, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28893 - Train Loss: 0.067080, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28894 - Train Loss: 0.067079, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28895 - Train Loss: 0.067077, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28896 - Train Loss: 0.067076, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28897 - Train Loss: 0.067075, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28898 - Train Loss: 0.067074, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28899 - Train Loss: 0.067073, Train Acc: 0.894872 | Val Loss: 0.107880, Val Acc: 0.804124\n",
      "Epoch 28900 - Train Loss: 0.067072, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28901 - Train Loss: 0.067071, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28902 - Train Loss: 0.067069, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28903 - Train Loss: 0.067068, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28904 - Train Loss: 0.067067, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28905 - Train Loss: 0.067066, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28906 - Train Loss: 0.067065, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28907 - Train Loss: 0.067064, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28908 - Train Loss: 0.067062, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28909 - Train Loss: 0.067061, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28910 - Train Loss: 0.067060, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28911 - Train Loss: 0.067059, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28912 - Train Loss: 0.067058, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28913 - Train Loss: 0.067057, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28914 - Train Loss: 0.067056, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28915 - Train Loss: 0.067054, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28916 - Train Loss: 0.067053, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28917 - Train Loss: 0.067052, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28918 - Train Loss: 0.067051, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28919 - Train Loss: 0.067050, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28920 - Train Loss: 0.067049, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28921 - Train Loss: 0.067047, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28922 - Train Loss: 0.067046, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28923 - Train Loss: 0.067045, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28924 - Train Loss: 0.067044, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28925 - Train Loss: 0.067043, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28926 - Train Loss: 0.067042, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28927 - Train Loss: 0.067040, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28928 - Train Loss: 0.067039, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28929 - Train Loss: 0.067038, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28930 - Train Loss: 0.067037, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28931 - Train Loss: 0.067036, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28932 - Train Loss: 0.067035, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28933 - Train Loss: 0.067034, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28934 - Train Loss: 0.067032, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28935 - Train Loss: 0.067031, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28936 - Train Loss: 0.067030, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28937 - Train Loss: 0.067029, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28938 - Train Loss: 0.067028, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28939 - Train Loss: 0.067027, Train Acc: 0.894872 | Val Loss: 0.107881, Val Acc: 0.804124\n",
      "Epoch 28940 - Train Loss: 0.067025, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28941 - Train Loss: 0.067024, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28942 - Train Loss: 0.067023, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28943 - Train Loss: 0.067022, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28944 - Train Loss: 0.067021, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28945 - Train Loss: 0.067020, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28946 - Train Loss: 0.067019, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28947 - Train Loss: 0.067017, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28948 - Train Loss: 0.067016, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28949 - Train Loss: 0.067015, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28950 - Train Loss: 0.067014, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28951 - Train Loss: 0.067013, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28952 - Train Loss: 0.067012, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28953 - Train Loss: 0.067010, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28954 - Train Loss: 0.067009, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28955 - Train Loss: 0.067008, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28956 - Train Loss: 0.067007, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28957 - Train Loss: 0.067006, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28958 - Train Loss: 0.067005, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28959 - Train Loss: 0.067004, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28960 - Train Loss: 0.067002, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28961 - Train Loss: 0.067001, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28962 - Train Loss: 0.067000, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28963 - Train Loss: 0.066999, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28964 - Train Loss: 0.066998, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28965 - Train Loss: 0.066997, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28966 - Train Loss: 0.066995, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28967 - Train Loss: 0.066994, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28968 - Train Loss: 0.066993, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28969 - Train Loss: 0.066992, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28970 - Train Loss: 0.066991, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28971 - Train Loss: 0.066990, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28972 - Train Loss: 0.066989, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28973 - Train Loss: 0.066987, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28974 - Train Loss: 0.066986, Train Acc: 0.894872 | Val Loss: 0.107882, Val Acc: 0.804124\n",
      "Epoch 28975 - Train Loss: 0.066985, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28976 - Train Loss: 0.066984, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28977 - Train Loss: 0.066983, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28978 - Train Loss: 0.066982, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28979 - Train Loss: 0.066980, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28980 - Train Loss: 0.066979, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28981 - Train Loss: 0.066978, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28982 - Train Loss: 0.066977, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28983 - Train Loss: 0.066976, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28984 - Train Loss: 0.066975, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28985 - Train Loss: 0.066974, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28986 - Train Loss: 0.066972, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28987 - Train Loss: 0.066971, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28988 - Train Loss: 0.066970, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28989 - Train Loss: 0.066969, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28990 - Train Loss: 0.066968, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28991 - Train Loss: 0.066967, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28992 - Train Loss: 0.066966, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28993 - Train Loss: 0.066964, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28994 - Train Loss: 0.066963, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28995 - Train Loss: 0.066962, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28996 - Train Loss: 0.066961, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28997 - Train Loss: 0.066960, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28998 - Train Loss: 0.066959, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 28999 - Train Loss: 0.066957, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29000 - Train Loss: 0.066956, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29001 - Train Loss: 0.066955, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29002 - Train Loss: 0.066954, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29003 - Train Loss: 0.066953, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29004 - Train Loss: 0.066952, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29005 - Train Loss: 0.066951, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29006 - Train Loss: 0.066949, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29007 - Train Loss: 0.066948, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29008 - Train Loss: 0.066947, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29009 - Train Loss: 0.066946, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29010 - Train Loss: 0.066945, Train Acc: 0.894872 | Val Loss: 0.107883, Val Acc: 0.804124\n",
      "Epoch 29011 - Train Loss: 0.066944, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29012 - Train Loss: 0.066943, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29013 - Train Loss: 0.066941, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29014 - Train Loss: 0.066940, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29015 - Train Loss: 0.066939, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29016 - Train Loss: 0.066938, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29017 - Train Loss: 0.066937, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29018 - Train Loss: 0.066936, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29019 - Train Loss: 0.066934, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29020 - Train Loss: 0.066933, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29021 - Train Loss: 0.066932, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29022 - Train Loss: 0.066931, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29023 - Train Loss: 0.066930, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29024 - Train Loss: 0.066929, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29025 - Train Loss: 0.066928, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29026 - Train Loss: 0.066926, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29027 - Train Loss: 0.066925, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29028 - Train Loss: 0.066924, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29029 - Train Loss: 0.066923, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29030 - Train Loss: 0.066922, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29031 - Train Loss: 0.066921, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29032 - Train Loss: 0.066920, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29033 - Train Loss: 0.066918, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29034 - Train Loss: 0.066917, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29035 - Train Loss: 0.066916, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29036 - Train Loss: 0.066915, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29037 - Train Loss: 0.066914, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29038 - Train Loss: 0.066913, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29039 - Train Loss: 0.066912, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29040 - Train Loss: 0.066910, Train Acc: 0.894872 | Val Loss: 0.107884, Val Acc: 0.804124\n",
      "Epoch 29041 - Train Loss: 0.066909, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29042 - Train Loss: 0.066908, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29043 - Train Loss: 0.066907, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29044 - Train Loss: 0.066906, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29045 - Train Loss: 0.066905, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29046 - Train Loss: 0.066903, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29047 - Train Loss: 0.066902, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29048 - Train Loss: 0.066901, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29049 - Train Loss: 0.066900, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29050 - Train Loss: 0.066899, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29051 - Train Loss: 0.066898, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29052 - Train Loss: 0.066897, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29053 - Train Loss: 0.066895, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29054 - Train Loss: 0.066894, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29055 - Train Loss: 0.066893, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29056 - Train Loss: 0.066892, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29057 - Train Loss: 0.066891, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29058 - Train Loss: 0.066890, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29059 - Train Loss: 0.066889, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29060 - Train Loss: 0.066887, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29061 - Train Loss: 0.066886, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29062 - Train Loss: 0.066885, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29063 - Train Loss: 0.066884, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29064 - Train Loss: 0.066883, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29065 - Train Loss: 0.066882, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29066 - Train Loss: 0.066881, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29067 - Train Loss: 0.066879, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29068 - Train Loss: 0.066878, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29069 - Train Loss: 0.066877, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29070 - Train Loss: 0.066876, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29071 - Train Loss: 0.066875, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29072 - Train Loss: 0.066874, Train Acc: 0.894872 | Val Loss: 0.107885, Val Acc: 0.804124\n",
      "Epoch 29073 - Train Loss: 0.066873, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29074 - Train Loss: 0.066871, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29075 - Train Loss: 0.066870, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29076 - Train Loss: 0.066869, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29077 - Train Loss: 0.066868, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29078 - Train Loss: 0.066867, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29079 - Train Loss: 0.066866, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29080 - Train Loss: 0.066864, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29081 - Train Loss: 0.066863, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29082 - Train Loss: 0.066862, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29083 - Train Loss: 0.066861, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29084 - Train Loss: 0.066860, Train Acc: 0.894872 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29085 - Train Loss: 0.066859, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29086 - Train Loss: 0.066858, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29087 - Train Loss: 0.066856, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29088 - Train Loss: 0.066855, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29089 - Train Loss: 0.066854, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29090 - Train Loss: 0.066853, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29091 - Train Loss: 0.066852, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29092 - Train Loss: 0.066851, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29093 - Train Loss: 0.066850, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29094 - Train Loss: 0.066848, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29095 - Train Loss: 0.066847, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29096 - Train Loss: 0.066846, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29097 - Train Loss: 0.066845, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29098 - Train Loss: 0.066844, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29099 - Train Loss: 0.066843, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29100 - Train Loss: 0.066842, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29101 - Train Loss: 0.066840, Train Acc: 0.896154 | Val Loss: 0.107886, Val Acc: 0.804124\n",
      "Epoch 29102 - Train Loss: 0.066839, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29103 - Train Loss: 0.066838, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29104 - Train Loss: 0.066837, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29105 - Train Loss: 0.066836, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29106 - Train Loss: 0.066835, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29107 - Train Loss: 0.066834, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29108 - Train Loss: 0.066832, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29109 - Train Loss: 0.066831, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29110 - Train Loss: 0.066830, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29111 - Train Loss: 0.066829, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29112 - Train Loss: 0.066828, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29113 - Train Loss: 0.066827, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29114 - Train Loss: 0.066826, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29115 - Train Loss: 0.066824, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29116 - Train Loss: 0.066823, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29117 - Train Loss: 0.066822, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29118 - Train Loss: 0.066821, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29119 - Train Loss: 0.066820, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29120 - Train Loss: 0.066819, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29121 - Train Loss: 0.066818, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29122 - Train Loss: 0.066816, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29123 - Train Loss: 0.066815, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29124 - Train Loss: 0.066814, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29125 - Train Loss: 0.066813, Train Acc: 0.896154 | Val Loss: 0.107887, Val Acc: 0.804124\n",
      "Epoch 29126 - Train Loss: 0.066812, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29127 - Train Loss: 0.066811, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29128 - Train Loss: 0.066810, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29129 - Train Loss: 0.066808, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29130 - Train Loss: 0.066807, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29131 - Train Loss: 0.066806, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29132 - Train Loss: 0.066805, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29133 - Train Loss: 0.066804, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29134 - Train Loss: 0.066803, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29135 - Train Loss: 0.066802, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29136 - Train Loss: 0.066800, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29137 - Train Loss: 0.066799, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29138 - Train Loss: 0.066798, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29139 - Train Loss: 0.066797, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29140 - Train Loss: 0.066796, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29141 - Train Loss: 0.066795, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29142 - Train Loss: 0.066794, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29143 - Train Loss: 0.066792, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29144 - Train Loss: 0.066791, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29145 - Train Loss: 0.066790, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29146 - Train Loss: 0.066789, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29147 - Train Loss: 0.066788, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29148 - Train Loss: 0.066787, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29149 - Train Loss: 0.066786, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29150 - Train Loss: 0.066784, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29151 - Train Loss: 0.066783, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29152 - Train Loss: 0.066782, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29153 - Train Loss: 0.066781, Train Acc: 0.896154 | Val Loss: 0.107888, Val Acc: 0.804124\n",
      "Epoch 29154 - Train Loss: 0.066780, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29155 - Train Loss: 0.066779, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29156 - Train Loss: 0.066778, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29157 - Train Loss: 0.066776, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29158 - Train Loss: 0.066775, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29159 - Train Loss: 0.066774, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29160 - Train Loss: 0.066773, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29161 - Train Loss: 0.066772, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29162 - Train Loss: 0.066771, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29163 - Train Loss: 0.066770, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29164 - Train Loss: 0.066768, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29165 - Train Loss: 0.066767, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29166 - Train Loss: 0.066766, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29167 - Train Loss: 0.066765, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29168 - Train Loss: 0.066764, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29169 - Train Loss: 0.066763, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29170 - Train Loss: 0.066762, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29171 - Train Loss: 0.066761, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29172 - Train Loss: 0.066759, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29173 - Train Loss: 0.066758, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29174 - Train Loss: 0.066757, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29175 - Train Loss: 0.066756, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29176 - Train Loss: 0.066755, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29177 - Train Loss: 0.066754, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29178 - Train Loss: 0.066753, Train Acc: 0.896154 | Val Loss: 0.107889, Val Acc: 0.804124\n",
      "Epoch 29179 - Train Loss: 0.066751, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29180 - Train Loss: 0.066750, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29181 - Train Loss: 0.066749, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29182 - Train Loss: 0.066748, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29183 - Train Loss: 0.066747, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29184 - Train Loss: 0.066746, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29185 - Train Loss: 0.066745, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29186 - Train Loss: 0.066743, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29187 - Train Loss: 0.066742, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29188 - Train Loss: 0.066741, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29189 - Train Loss: 0.066740, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29190 - Train Loss: 0.066739, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29191 - Train Loss: 0.066738, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29192 - Train Loss: 0.066737, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29193 - Train Loss: 0.066735, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29194 - Train Loss: 0.066734, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29195 - Train Loss: 0.066733, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29196 - Train Loss: 0.066732, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29197 - Train Loss: 0.066731, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29198 - Train Loss: 0.066730, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29199 - Train Loss: 0.066729, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29200 - Train Loss: 0.066727, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29201 - Train Loss: 0.066726, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29202 - Train Loss: 0.066725, Train Acc: 0.896154 | Val Loss: 0.107890, Val Acc: 0.804124\n",
      "Epoch 29203 - Train Loss: 0.066724, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29204 - Train Loss: 0.066723, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29205 - Train Loss: 0.066722, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29206 - Train Loss: 0.066721, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29207 - Train Loss: 0.066720, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29208 - Train Loss: 0.066718, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29209 - Train Loss: 0.066717, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29210 - Train Loss: 0.066716, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29211 - Train Loss: 0.066715, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29212 - Train Loss: 0.066714, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29213 - Train Loss: 0.066713, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29214 - Train Loss: 0.066712, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29215 - Train Loss: 0.066710, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29216 - Train Loss: 0.066709, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29217 - Train Loss: 0.066708, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29218 - Train Loss: 0.066707, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29219 - Train Loss: 0.066706, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29220 - Train Loss: 0.066705, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29221 - Train Loss: 0.066704, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29222 - Train Loss: 0.066702, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29223 - Train Loss: 0.066701, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29224 - Train Loss: 0.066700, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29225 - Train Loss: 0.066699, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29226 - Train Loss: 0.066698, Train Acc: 0.896154 | Val Loss: 0.107891, Val Acc: 0.804124\n",
      "Epoch 29227 - Train Loss: 0.066697, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29228 - Train Loss: 0.066696, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29229 - Train Loss: 0.066695, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29230 - Train Loss: 0.066693, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29231 - Train Loss: 0.066692, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29232 - Train Loss: 0.066691, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29233 - Train Loss: 0.066690, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29234 - Train Loss: 0.066689, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29235 - Train Loss: 0.066688, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29236 - Train Loss: 0.066687, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29237 - Train Loss: 0.066685, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29238 - Train Loss: 0.066684, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29239 - Train Loss: 0.066683, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29240 - Train Loss: 0.066682, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29241 - Train Loss: 0.066681, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29242 - Train Loss: 0.066680, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29243 - Train Loss: 0.066679, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29244 - Train Loss: 0.066677, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29245 - Train Loss: 0.066676, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29246 - Train Loss: 0.066675, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29247 - Train Loss: 0.066674, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29248 - Train Loss: 0.066673, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29249 - Train Loss: 0.066672, Train Acc: 0.896154 | Val Loss: 0.107892, Val Acc: 0.804124\n",
      "Epoch 29250 - Train Loss: 0.066671, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29251 - Train Loss: 0.066670, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29252 - Train Loss: 0.066668, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29253 - Train Loss: 0.066667, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29254 - Train Loss: 0.066666, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29255 - Train Loss: 0.066665, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29256 - Train Loss: 0.066664, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29257 - Train Loss: 0.066663, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29258 - Train Loss: 0.066662, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29259 - Train Loss: 0.066660, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29260 - Train Loss: 0.066659, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29261 - Train Loss: 0.066658, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29262 - Train Loss: 0.066657, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29263 - Train Loss: 0.066656, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29264 - Train Loss: 0.066655, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29265 - Train Loss: 0.066654, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29266 - Train Loss: 0.066653, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29267 - Train Loss: 0.066651, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29268 - Train Loss: 0.066650, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29269 - Train Loss: 0.066649, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29270 - Train Loss: 0.066648, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29271 - Train Loss: 0.066647, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29272 - Train Loss: 0.066646, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29273 - Train Loss: 0.066645, Train Acc: 0.896154 | Val Loss: 0.107893, Val Acc: 0.804124\n",
      "Epoch 29274 - Train Loss: 0.066643, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29275 - Train Loss: 0.066642, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29276 - Train Loss: 0.066641, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29277 - Train Loss: 0.066640, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29278 - Train Loss: 0.066639, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29279 - Train Loss: 0.066638, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29280 - Train Loss: 0.066637, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29281 - Train Loss: 0.066636, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29282 - Train Loss: 0.066634, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29283 - Train Loss: 0.066633, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29284 - Train Loss: 0.066632, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29285 - Train Loss: 0.066631, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29286 - Train Loss: 0.066630, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29287 - Train Loss: 0.066629, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29288 - Train Loss: 0.066628, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29289 - Train Loss: 0.066626, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29290 - Train Loss: 0.066625, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29291 - Train Loss: 0.066624, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29292 - Train Loss: 0.066623, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29293 - Train Loss: 0.066622, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29294 - Train Loss: 0.066621, Train Acc: 0.896154 | Val Loss: 0.107894, Val Acc: 0.804124\n",
      "Epoch 29295 - Train Loss: 0.066620, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29296 - Train Loss: 0.066619, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29297 - Train Loss: 0.066617, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29298 - Train Loss: 0.066616, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29299 - Train Loss: 0.066615, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29300 - Train Loss: 0.066614, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29301 - Train Loss: 0.066613, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29302 - Train Loss: 0.066612, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29303 - Train Loss: 0.066611, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29304 - Train Loss: 0.066610, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29305 - Train Loss: 0.066608, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29306 - Train Loss: 0.066607, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29307 - Train Loss: 0.066606, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29308 - Train Loss: 0.066605, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29309 - Train Loss: 0.066604, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29310 - Train Loss: 0.066603, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29311 - Train Loss: 0.066602, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29312 - Train Loss: 0.066600, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29313 - Train Loss: 0.066599, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29314 - Train Loss: 0.066598, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29315 - Train Loss: 0.066597, Train Acc: 0.896154 | Val Loss: 0.107895, Val Acc: 0.804124\n",
      "Epoch 29316 - Train Loss: 0.066596, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29317 - Train Loss: 0.066595, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29318 - Train Loss: 0.066594, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29319 - Train Loss: 0.066593, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29320 - Train Loss: 0.066591, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29321 - Train Loss: 0.066590, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29322 - Train Loss: 0.066589, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29323 - Train Loss: 0.066588, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29324 - Train Loss: 0.066587, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29325 - Train Loss: 0.066586, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29326 - Train Loss: 0.066585, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29327 - Train Loss: 0.066583, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29328 - Train Loss: 0.066582, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29329 - Train Loss: 0.066581, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29330 - Train Loss: 0.066580, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29331 - Train Loss: 0.066579, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29332 - Train Loss: 0.066578, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29333 - Train Loss: 0.066577, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29334 - Train Loss: 0.066576, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29335 - Train Loss: 0.066574, Train Acc: 0.896154 | Val Loss: 0.107896, Val Acc: 0.804124\n",
      "Epoch 29336 - Train Loss: 0.066573, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29337 - Train Loss: 0.066572, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29338 - Train Loss: 0.066571, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29339 - Train Loss: 0.066570, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29340 - Train Loss: 0.066569, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29341 - Train Loss: 0.066568, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29342 - Train Loss: 0.066567, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29343 - Train Loss: 0.066565, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29344 - Train Loss: 0.066564, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29345 - Train Loss: 0.066563, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29346 - Train Loss: 0.066562, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29347 - Train Loss: 0.066561, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29348 - Train Loss: 0.066560, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29349 - Train Loss: 0.066559, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29350 - Train Loss: 0.066558, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29351 - Train Loss: 0.066556, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29352 - Train Loss: 0.066555, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29353 - Train Loss: 0.066554, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29354 - Train Loss: 0.066553, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29355 - Train Loss: 0.066552, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29356 - Train Loss: 0.066551, Train Acc: 0.896154 | Val Loss: 0.107897, Val Acc: 0.804124\n",
      "Epoch 29357 - Train Loss: 0.066550, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29358 - Train Loss: 0.066548, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29359 - Train Loss: 0.066547, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29360 - Train Loss: 0.066546, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29361 - Train Loss: 0.066545, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29362 - Train Loss: 0.066544, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29363 - Train Loss: 0.066543, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29364 - Train Loss: 0.066542, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29365 - Train Loss: 0.066541, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29366 - Train Loss: 0.066539, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29367 - Train Loss: 0.066538, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29368 - Train Loss: 0.066537, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29369 - Train Loss: 0.066536, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29370 - Train Loss: 0.066535, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29371 - Train Loss: 0.066534, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29372 - Train Loss: 0.066533, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29373 - Train Loss: 0.066532, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29374 - Train Loss: 0.066530, Train Acc: 0.896154 | Val Loss: 0.107898, Val Acc: 0.804124\n",
      "Epoch 29375 - Train Loss: 0.066529, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29376 - Train Loss: 0.066528, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29377 - Train Loss: 0.066527, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29378 - Train Loss: 0.066526, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29379 - Train Loss: 0.066525, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29380 - Train Loss: 0.066524, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29381 - Train Loss: 0.066523, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29382 - Train Loss: 0.066521, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29383 - Train Loss: 0.066520, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29384 - Train Loss: 0.066519, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29385 - Train Loss: 0.066518, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29386 - Train Loss: 0.066517, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29387 - Train Loss: 0.066516, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29388 - Train Loss: 0.066515, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29389 - Train Loss: 0.066514, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29390 - Train Loss: 0.066512, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29391 - Train Loss: 0.066511, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29392 - Train Loss: 0.066510, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29393 - Train Loss: 0.066509, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29394 - Train Loss: 0.066508, Train Acc: 0.896154 | Val Loss: 0.107899, Val Acc: 0.804124\n",
      "Epoch 29395 - Train Loss: 0.066507, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29396 - Train Loss: 0.066506, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29397 - Train Loss: 0.066505, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29398 - Train Loss: 0.066503, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29399 - Train Loss: 0.066502, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29400 - Train Loss: 0.066501, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29401 - Train Loss: 0.066500, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29402 - Train Loss: 0.066499, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29403 - Train Loss: 0.066498, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29404 - Train Loss: 0.066497, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29405 - Train Loss: 0.066496, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29406 - Train Loss: 0.066494, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29407 - Train Loss: 0.066493, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29408 - Train Loss: 0.066492, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29409 - Train Loss: 0.066491, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29410 - Train Loss: 0.066490, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29411 - Train Loss: 0.066489, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29412 - Train Loss: 0.066488, Train Acc: 0.896154 | Val Loss: 0.107900, Val Acc: 0.804124\n",
      "Epoch 29413 - Train Loss: 0.066487, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29414 - Train Loss: 0.066485, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29415 - Train Loss: 0.066484, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29416 - Train Loss: 0.066483, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29417 - Train Loss: 0.066482, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29418 - Train Loss: 0.066481, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29419 - Train Loss: 0.066480, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29420 - Train Loss: 0.066479, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29421 - Train Loss: 0.066478, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29422 - Train Loss: 0.066476, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29423 - Train Loss: 0.066475, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29424 - Train Loss: 0.066474, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29425 - Train Loss: 0.066473, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29426 - Train Loss: 0.066472, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29427 - Train Loss: 0.066471, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29428 - Train Loss: 0.066470, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29429 - Train Loss: 0.066469, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29430 - Train Loss: 0.066467, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29431 - Train Loss: 0.066466, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29432 - Train Loss: 0.066465, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29433 - Train Loss: 0.066464, Train Acc: 0.896154 | Val Loss: 0.107901, Val Acc: 0.804124\n",
      "Epoch 29434 - Train Loss: 0.066463, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29435 - Train Loss: 0.066462, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29436 - Train Loss: 0.066461, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29437 - Train Loss: 0.066460, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29438 - Train Loss: 0.066458, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29439 - Train Loss: 0.066457, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29440 - Train Loss: 0.066456, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29441 - Train Loss: 0.066455, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29442 - Train Loss: 0.066454, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29443 - Train Loss: 0.066453, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29444 - Train Loss: 0.066452, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29445 - Train Loss: 0.066451, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29446 - Train Loss: 0.066449, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29447 - Train Loss: 0.066448, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29448 - Train Loss: 0.066447, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29449 - Train Loss: 0.066446, Train Acc: 0.896154 | Val Loss: 0.107902, Val Acc: 0.804124\n",
      "Epoch 29450 - Train Loss: 0.066445, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29451 - Train Loss: 0.066444, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29452 - Train Loss: 0.066443, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29453 - Train Loss: 0.066442, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29454 - Train Loss: 0.066440, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29455 - Train Loss: 0.066439, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29456 - Train Loss: 0.066438, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29457 - Train Loss: 0.066437, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29458 - Train Loss: 0.066436, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29459 - Train Loss: 0.066435, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29460 - Train Loss: 0.066434, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29461 - Train Loss: 0.066433, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29462 - Train Loss: 0.066432, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29463 - Train Loss: 0.066430, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29464 - Train Loss: 0.066429, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29465 - Train Loss: 0.066428, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29466 - Train Loss: 0.066427, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29467 - Train Loss: 0.066426, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29468 - Train Loss: 0.066425, Train Acc: 0.896154 | Val Loss: 0.107903, Val Acc: 0.804124\n",
      "Epoch 29469 - Train Loss: 0.066424, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29470 - Train Loss: 0.066423, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29471 - Train Loss: 0.066421, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29472 - Train Loss: 0.066420, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29473 - Train Loss: 0.066419, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29474 - Train Loss: 0.066418, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29475 - Train Loss: 0.066417, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29476 - Train Loss: 0.066416, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29477 - Train Loss: 0.066415, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29478 - Train Loss: 0.066414, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29479 - Train Loss: 0.066412, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29480 - Train Loss: 0.066411, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29481 - Train Loss: 0.066410, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29482 - Train Loss: 0.066409, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29483 - Train Loss: 0.066408, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29484 - Train Loss: 0.066407, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29485 - Train Loss: 0.066406, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29486 - Train Loss: 0.066405, Train Acc: 0.896154 | Val Loss: 0.107904, Val Acc: 0.804124\n",
      "Epoch 29487 - Train Loss: 0.066403, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29488 - Train Loss: 0.066402, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29489 - Train Loss: 0.066401, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29490 - Train Loss: 0.066400, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29491 - Train Loss: 0.066399, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29492 - Train Loss: 0.066398, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29493 - Train Loss: 0.066397, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29494 - Train Loss: 0.066396, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29495 - Train Loss: 0.066395, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29496 - Train Loss: 0.066393, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29497 - Train Loss: 0.066392, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29498 - Train Loss: 0.066391, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29499 - Train Loss: 0.066390, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29500 - Train Loss: 0.066389, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29501 - Train Loss: 0.066388, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29502 - Train Loss: 0.066387, Train Acc: 0.896154 | Val Loss: 0.107905, Val Acc: 0.804124\n",
      "Epoch 29503 - Train Loss: 0.066386, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29504 - Train Loss: 0.066384, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29505 - Train Loss: 0.066383, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29506 - Train Loss: 0.066382, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29507 - Train Loss: 0.066381, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29508 - Train Loss: 0.066380, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29509 - Train Loss: 0.066379, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29510 - Train Loss: 0.066378, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29511 - Train Loss: 0.066377, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29512 - Train Loss: 0.066376, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29513 - Train Loss: 0.066374, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29514 - Train Loss: 0.066373, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29515 - Train Loss: 0.066372, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29516 - Train Loss: 0.066371, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29517 - Train Loss: 0.066370, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29518 - Train Loss: 0.066369, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29519 - Train Loss: 0.066368, Train Acc: 0.896154 | Val Loss: 0.107906, Val Acc: 0.804124\n",
      "Epoch 29520 - Train Loss: 0.066367, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29521 - Train Loss: 0.066365, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29522 - Train Loss: 0.066364, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29523 - Train Loss: 0.066363, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29524 - Train Loss: 0.066362, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29525 - Train Loss: 0.066361, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29526 - Train Loss: 0.066360, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29527 - Train Loss: 0.066359, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29528 - Train Loss: 0.066358, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29529 - Train Loss: 0.066357, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29530 - Train Loss: 0.066355, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29531 - Train Loss: 0.066354, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29532 - Train Loss: 0.066353, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29533 - Train Loss: 0.066352, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29534 - Train Loss: 0.066351, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29535 - Train Loss: 0.066350, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29536 - Train Loss: 0.066349, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29537 - Train Loss: 0.066348, Train Acc: 0.896154 | Val Loss: 0.107907, Val Acc: 0.804124\n",
      "Epoch 29538 - Train Loss: 0.066346, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29539 - Train Loss: 0.066345, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29540 - Train Loss: 0.066344, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29541 - Train Loss: 0.066343, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29542 - Train Loss: 0.066342, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29543 - Train Loss: 0.066341, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29544 - Train Loss: 0.066340, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29545 - Train Loss: 0.066339, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29546 - Train Loss: 0.066338, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29547 - Train Loss: 0.066336, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29548 - Train Loss: 0.066335, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29549 - Train Loss: 0.066334, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29550 - Train Loss: 0.066333, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29551 - Train Loss: 0.066332, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29552 - Train Loss: 0.066331, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29553 - Train Loss: 0.066330, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29554 - Train Loss: 0.066329, Train Acc: 0.896154 | Val Loss: 0.107908, Val Acc: 0.804124\n",
      "Epoch 29555 - Train Loss: 0.066327, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29556 - Train Loss: 0.066326, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29557 - Train Loss: 0.066325, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29558 - Train Loss: 0.066324, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29559 - Train Loss: 0.066323, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29560 - Train Loss: 0.066322, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29561 - Train Loss: 0.066321, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29562 - Train Loss: 0.066320, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29563 - Train Loss: 0.066319, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29564 - Train Loss: 0.066317, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29565 - Train Loss: 0.066316, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29566 - Train Loss: 0.066315, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29567 - Train Loss: 0.066314, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29568 - Train Loss: 0.066313, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29569 - Train Loss: 0.066312, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29570 - Train Loss: 0.066311, Train Acc: 0.896154 | Val Loss: 0.107909, Val Acc: 0.804124\n",
      "Epoch 29571 - Train Loss: 0.066310, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29572 - Train Loss: 0.066309, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29573 - Train Loss: 0.066307, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29574 - Train Loss: 0.066306, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29575 - Train Loss: 0.066305, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29576 - Train Loss: 0.066304, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29577 - Train Loss: 0.066303, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29578 - Train Loss: 0.066302, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29579 - Train Loss: 0.066301, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29580 - Train Loss: 0.066300, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29581 - Train Loss: 0.066298, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29582 - Train Loss: 0.066297, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29583 - Train Loss: 0.066296, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29584 - Train Loss: 0.066295, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29585 - Train Loss: 0.066294, Train Acc: 0.896154 | Val Loss: 0.107910, Val Acc: 0.804124\n",
      "Epoch 29586 - Train Loss: 0.066293, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29587 - Train Loss: 0.066292, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29588 - Train Loss: 0.066291, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29589 - Train Loss: 0.066290, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29590 - Train Loss: 0.066288, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29591 - Train Loss: 0.066287, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29592 - Train Loss: 0.066286, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29593 - Train Loss: 0.066285, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29594 - Train Loss: 0.066284, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29595 - Train Loss: 0.066283, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29596 - Train Loss: 0.066282, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29597 - Train Loss: 0.066281, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29598 - Train Loss: 0.066280, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29599 - Train Loss: 0.066278, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29600 - Train Loss: 0.066277, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29601 - Train Loss: 0.066276, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29602 - Train Loss: 0.066275, Train Acc: 0.896154 | Val Loss: 0.107911, Val Acc: 0.804124\n",
      "Epoch 29603 - Train Loss: 0.066274, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29604 - Train Loss: 0.066273, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29605 - Train Loss: 0.066272, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29606 - Train Loss: 0.066271, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29607 - Train Loss: 0.066270, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29608 - Train Loss: 0.066268, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29609 - Train Loss: 0.066267, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29610 - Train Loss: 0.066266, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29611 - Train Loss: 0.066265, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29612 - Train Loss: 0.066264, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29613 - Train Loss: 0.066263, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29614 - Train Loss: 0.066262, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29615 - Train Loss: 0.066261, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29616 - Train Loss: 0.066260, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29617 - Train Loss: 0.066258, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29618 - Train Loss: 0.066257, Train Acc: 0.896154 | Val Loss: 0.107912, Val Acc: 0.804124\n",
      "Epoch 29619 - Train Loss: 0.066256, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29620 - Train Loss: 0.066255, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29621 - Train Loss: 0.066254, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29622 - Train Loss: 0.066253, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29623 - Train Loss: 0.066252, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29624 - Train Loss: 0.066251, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29625 - Train Loss: 0.066249, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29626 - Train Loss: 0.066248, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29627 - Train Loss: 0.066247, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29628 - Train Loss: 0.066246, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29629 - Train Loss: 0.066245, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29630 - Train Loss: 0.066244, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29631 - Train Loss: 0.066243, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29632 - Train Loss: 0.066242, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29633 - Train Loss: 0.066241, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29634 - Train Loss: 0.066239, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29635 - Train Loss: 0.066238, Train Acc: 0.896154 | Val Loss: 0.107913, Val Acc: 0.804124\n",
      "Epoch 29636 - Train Loss: 0.066237, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29637 - Train Loss: 0.066236, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29638 - Train Loss: 0.066235, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29639 - Train Loss: 0.066234, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29640 - Train Loss: 0.066233, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29641 - Train Loss: 0.066232, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29642 - Train Loss: 0.066231, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29643 - Train Loss: 0.066229, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29644 - Train Loss: 0.066228, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29645 - Train Loss: 0.066227, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29646 - Train Loss: 0.066226, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29647 - Train Loss: 0.066225, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29648 - Train Loss: 0.066224, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29649 - Train Loss: 0.066223, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29650 - Train Loss: 0.066222, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29651 - Train Loss: 0.066221, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29652 - Train Loss: 0.066220, Train Acc: 0.896154 | Val Loss: 0.107914, Val Acc: 0.804124\n",
      "Epoch 29653 - Train Loss: 0.066218, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29654 - Train Loss: 0.066217, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29655 - Train Loss: 0.066216, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29656 - Train Loss: 0.066215, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29657 - Train Loss: 0.066214, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29658 - Train Loss: 0.066213, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29659 - Train Loss: 0.066212, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29660 - Train Loss: 0.066211, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29661 - Train Loss: 0.066210, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29662 - Train Loss: 0.066208, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29663 - Train Loss: 0.066207, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29664 - Train Loss: 0.066206, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29665 - Train Loss: 0.066205, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29666 - Train Loss: 0.066204, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29667 - Train Loss: 0.066203, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29668 - Train Loss: 0.066202, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29669 - Train Loss: 0.066201, Train Acc: 0.896154 | Val Loss: 0.107915, Val Acc: 0.804124\n",
      "Epoch 29670 - Train Loss: 0.066200, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29671 - Train Loss: 0.066198, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29672 - Train Loss: 0.066197, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29673 - Train Loss: 0.066196, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29674 - Train Loss: 0.066195, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29675 - Train Loss: 0.066194, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29676 - Train Loss: 0.066193, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29677 - Train Loss: 0.066192, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29678 - Train Loss: 0.066191, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29679 - Train Loss: 0.066190, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29680 - Train Loss: 0.066188, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29681 - Train Loss: 0.066187, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29682 - Train Loss: 0.066186, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29683 - Train Loss: 0.066185, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29684 - Train Loss: 0.066184, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29685 - Train Loss: 0.066183, Train Acc: 0.896154 | Val Loss: 0.107916, Val Acc: 0.804124\n",
      "Epoch 29686 - Train Loss: 0.066182, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29687 - Train Loss: 0.066181, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29688 - Train Loss: 0.066180, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29689 - Train Loss: 0.066178, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29690 - Train Loss: 0.066177, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29691 - Train Loss: 0.066176, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29692 - Train Loss: 0.066175, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29693 - Train Loss: 0.066174, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29694 - Train Loss: 0.066173, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29695 - Train Loss: 0.066172, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29696 - Train Loss: 0.066171, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29697 - Train Loss: 0.066170, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29698 - Train Loss: 0.066169, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29699 - Train Loss: 0.066167, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29700 - Train Loss: 0.066166, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29701 - Train Loss: 0.066165, Train Acc: 0.896154 | Val Loss: 0.107917, Val Acc: 0.804124\n",
      "Epoch 29702 - Train Loss: 0.066164, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29703 - Train Loss: 0.066163, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29704 - Train Loss: 0.066162, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29705 - Train Loss: 0.066161, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29706 - Train Loss: 0.066160, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29707 - Train Loss: 0.066159, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29708 - Train Loss: 0.066157, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29709 - Train Loss: 0.066156, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29710 - Train Loss: 0.066155, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29711 - Train Loss: 0.066154, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29712 - Train Loss: 0.066153, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29713 - Train Loss: 0.066152, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29714 - Train Loss: 0.066151, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29715 - Train Loss: 0.066150, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29716 - Train Loss: 0.066149, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29717 - Train Loss: 0.066147, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29718 - Train Loss: 0.066146, Train Acc: 0.896154 | Val Loss: 0.107918, Val Acc: 0.804124\n",
      "Epoch 29719 - Train Loss: 0.066145, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29720 - Train Loss: 0.066144, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29721 - Train Loss: 0.066143, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29722 - Train Loss: 0.066142, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29723 - Train Loss: 0.066141, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29724 - Train Loss: 0.066140, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29725 - Train Loss: 0.066139, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29726 - Train Loss: 0.066138, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29727 - Train Loss: 0.066136, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29728 - Train Loss: 0.066135, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29729 - Train Loss: 0.066134, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29730 - Train Loss: 0.066133, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29731 - Train Loss: 0.066132, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29732 - Train Loss: 0.066131, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29733 - Train Loss: 0.066130, Train Acc: 0.896154 | Val Loss: 0.107919, Val Acc: 0.804124\n",
      "Epoch 29734 - Train Loss: 0.066129, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29735 - Train Loss: 0.066128, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29736 - Train Loss: 0.066126, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29737 - Train Loss: 0.066125, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29738 - Train Loss: 0.066124, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29739 - Train Loss: 0.066123, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29740 - Train Loss: 0.066122, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29741 - Train Loss: 0.066121, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29742 - Train Loss: 0.066120, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29743 - Train Loss: 0.066119, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29744 - Train Loss: 0.066118, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29745 - Train Loss: 0.066117, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29746 - Train Loss: 0.066115, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29747 - Train Loss: 0.066114, Train Acc: 0.896154 | Val Loss: 0.107920, Val Acc: 0.804124\n",
      "Epoch 29748 - Train Loss: 0.066113, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29749 - Train Loss: 0.066112, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29750 - Train Loss: 0.066111, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29751 - Train Loss: 0.066110, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29752 - Train Loss: 0.066109, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29753 - Train Loss: 0.066108, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29754 - Train Loss: 0.066107, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29755 - Train Loss: 0.066105, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29756 - Train Loss: 0.066104, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29757 - Train Loss: 0.066103, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29758 - Train Loss: 0.066102, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29759 - Train Loss: 0.066101, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29760 - Train Loss: 0.066100, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29761 - Train Loss: 0.066099, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29762 - Train Loss: 0.066098, Train Acc: 0.896154 | Val Loss: 0.107921, Val Acc: 0.804124\n",
      "Epoch 29763 - Train Loss: 0.066097, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29764 - Train Loss: 0.066096, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29765 - Train Loss: 0.066094, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29766 - Train Loss: 0.066093, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29767 - Train Loss: 0.066092, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29768 - Train Loss: 0.066091, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29769 - Train Loss: 0.066090, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29770 - Train Loss: 0.066089, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29771 - Train Loss: 0.066088, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29772 - Train Loss: 0.066087, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29773 - Train Loss: 0.066086, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29774 - Train Loss: 0.066085, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29775 - Train Loss: 0.066083, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29776 - Train Loss: 0.066082, Train Acc: 0.896154 | Val Loss: 0.107922, Val Acc: 0.804124\n",
      "Epoch 29777 - Train Loss: 0.066081, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29778 - Train Loss: 0.066080, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29779 - Train Loss: 0.066079, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29780 - Train Loss: 0.066078, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29781 - Train Loss: 0.066077, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29782 - Train Loss: 0.066076, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29783 - Train Loss: 0.066075, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29784 - Train Loss: 0.066074, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29785 - Train Loss: 0.066072, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29786 - Train Loss: 0.066071, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29787 - Train Loss: 0.066070, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29788 - Train Loss: 0.066069, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29789 - Train Loss: 0.066068, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29790 - Train Loss: 0.066067, Train Acc: 0.896154 | Val Loss: 0.107923, Val Acc: 0.804124\n",
      "Epoch 29791 - Train Loss: 0.066066, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29792 - Train Loss: 0.066065, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29793 - Train Loss: 0.066064, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29794 - Train Loss: 0.066062, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29795 - Train Loss: 0.066061, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29796 - Train Loss: 0.066060, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29797 - Train Loss: 0.066059, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29798 - Train Loss: 0.066058, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29799 - Train Loss: 0.066057, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29800 - Train Loss: 0.066056, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29801 - Train Loss: 0.066055, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29802 - Train Loss: 0.066054, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29803 - Train Loss: 0.066053, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29804 - Train Loss: 0.066051, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29805 - Train Loss: 0.066050, Train Acc: 0.896154 | Val Loss: 0.107924, Val Acc: 0.804124\n",
      "Epoch 29806 - Train Loss: 0.066049, Train Acc: 0.896154 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29807 - Train Loss: 0.066048, Train Acc: 0.896154 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29808 - Train Loss: 0.066047, Train Acc: 0.896154 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29809 - Train Loss: 0.066046, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29810 - Train Loss: 0.066045, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29811 - Train Loss: 0.066044, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29812 - Train Loss: 0.066043, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29813 - Train Loss: 0.066042, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29814 - Train Loss: 0.066040, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29815 - Train Loss: 0.066039, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29816 - Train Loss: 0.066038, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29817 - Train Loss: 0.066037, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29818 - Train Loss: 0.066036, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29819 - Train Loss: 0.066035, Train Acc: 0.897436 | Val Loss: 0.107925, Val Acc: 0.804124\n",
      "Epoch 29820 - Train Loss: 0.066034, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29821 - Train Loss: 0.066033, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29822 - Train Loss: 0.066032, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29823 - Train Loss: 0.066031, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29824 - Train Loss: 0.066029, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29825 - Train Loss: 0.066028, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29826 - Train Loss: 0.066027, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29827 - Train Loss: 0.066026, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29828 - Train Loss: 0.066025, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29829 - Train Loss: 0.066024, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29830 - Train Loss: 0.066023, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29831 - Train Loss: 0.066022, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29832 - Train Loss: 0.066021, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29833 - Train Loss: 0.066020, Train Acc: 0.897436 | Val Loss: 0.107926, Val Acc: 0.804124\n",
      "Epoch 29834 - Train Loss: 0.066018, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29835 - Train Loss: 0.066017, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29836 - Train Loss: 0.066016, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29837 - Train Loss: 0.066015, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29838 - Train Loss: 0.066014, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29839 - Train Loss: 0.066013, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29840 - Train Loss: 0.066012, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29841 - Train Loss: 0.066011, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29842 - Train Loss: 0.066010, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29843 - Train Loss: 0.066009, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29844 - Train Loss: 0.066007, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29845 - Train Loss: 0.066006, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29846 - Train Loss: 0.066005, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29847 - Train Loss: 0.066004, Train Acc: 0.897436 | Val Loss: 0.107927, Val Acc: 0.804124\n",
      "Epoch 29848 - Train Loss: 0.066003, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29849 - Train Loss: 0.066002, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29850 - Train Loss: 0.066001, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29851 - Train Loss: 0.066000, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29852 - Train Loss: 0.065999, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29853 - Train Loss: 0.065998, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29854 - Train Loss: 0.065996, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29855 - Train Loss: 0.065995, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29856 - Train Loss: 0.065994, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29857 - Train Loss: 0.065993, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29858 - Train Loss: 0.065992, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29859 - Train Loss: 0.065991, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29860 - Train Loss: 0.065990, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29861 - Train Loss: 0.065989, Train Acc: 0.897436 | Val Loss: 0.107928, Val Acc: 0.804124\n",
      "Epoch 29862 - Train Loss: 0.065988, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29863 - Train Loss: 0.065987, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29864 - Train Loss: 0.065986, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29865 - Train Loss: 0.065984, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29866 - Train Loss: 0.065983, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29867 - Train Loss: 0.065982, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29868 - Train Loss: 0.065981, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29869 - Train Loss: 0.065980, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29870 - Train Loss: 0.065979, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29871 - Train Loss: 0.065978, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29872 - Train Loss: 0.065977, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29873 - Train Loss: 0.065976, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29874 - Train Loss: 0.065975, Train Acc: 0.897436 | Val Loss: 0.107929, Val Acc: 0.804124\n",
      "Epoch 29875 - Train Loss: 0.065973, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29876 - Train Loss: 0.065972, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29877 - Train Loss: 0.065971, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29878 - Train Loss: 0.065970, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29879 - Train Loss: 0.065969, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29880 - Train Loss: 0.065968, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29881 - Train Loss: 0.065967, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29882 - Train Loss: 0.065966, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29883 - Train Loss: 0.065965, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29884 - Train Loss: 0.065964, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29885 - Train Loss: 0.065962, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29886 - Train Loss: 0.065961, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29887 - Train Loss: 0.065960, Train Acc: 0.897436 | Val Loss: 0.107930, Val Acc: 0.804124\n",
      "Epoch 29888 - Train Loss: 0.065959, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29889 - Train Loss: 0.065958, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29890 - Train Loss: 0.065957, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29891 - Train Loss: 0.065956, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29892 - Train Loss: 0.065955, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29893 - Train Loss: 0.065954, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29894 - Train Loss: 0.065953, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29895 - Train Loss: 0.065952, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29896 - Train Loss: 0.065950, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29897 - Train Loss: 0.065949, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29898 - Train Loss: 0.065948, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29899 - Train Loss: 0.065947, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29900 - Train Loss: 0.065946, Train Acc: 0.897436 | Val Loss: 0.107931, Val Acc: 0.804124\n",
      "Epoch 29901 - Train Loss: 0.065945, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29902 - Train Loss: 0.065944, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29903 - Train Loss: 0.065943, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29904 - Train Loss: 0.065942, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29905 - Train Loss: 0.065941, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29906 - Train Loss: 0.065939, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29907 - Train Loss: 0.065938, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29908 - Train Loss: 0.065937, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29909 - Train Loss: 0.065936, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29910 - Train Loss: 0.065935, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29911 - Train Loss: 0.065934, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29912 - Train Loss: 0.065933, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29913 - Train Loss: 0.065932, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29914 - Train Loss: 0.065931, Train Acc: 0.897436 | Val Loss: 0.107932, Val Acc: 0.804124\n",
      "Epoch 29915 - Train Loss: 0.065930, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29916 - Train Loss: 0.065929, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29917 - Train Loss: 0.065927, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29918 - Train Loss: 0.065926, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29919 - Train Loss: 0.065925, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29920 - Train Loss: 0.065924, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29921 - Train Loss: 0.065923, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29922 - Train Loss: 0.065922, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29923 - Train Loss: 0.065921, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29924 - Train Loss: 0.065920, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29925 - Train Loss: 0.065919, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29926 - Train Loss: 0.065918, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29927 - Train Loss: 0.065916, Train Acc: 0.897436 | Val Loss: 0.107933, Val Acc: 0.804124\n",
      "Epoch 29928 - Train Loss: 0.065915, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29929 - Train Loss: 0.065914, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29930 - Train Loss: 0.065913, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29931 - Train Loss: 0.065912, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29932 - Train Loss: 0.065911, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29933 - Train Loss: 0.065910, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29934 - Train Loss: 0.065909, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29935 - Train Loss: 0.065908, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29936 - Train Loss: 0.065907, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29937 - Train Loss: 0.065906, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29938 - Train Loss: 0.065904, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29939 - Train Loss: 0.065903, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29940 - Train Loss: 0.065902, Train Acc: 0.897436 | Val Loss: 0.107934, Val Acc: 0.804124\n",
      "Epoch 29941 - Train Loss: 0.065901, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29942 - Train Loss: 0.065900, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29943 - Train Loss: 0.065899, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29944 - Train Loss: 0.065898, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29945 - Train Loss: 0.065897, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29946 - Train Loss: 0.065896, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29947 - Train Loss: 0.065895, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29948 - Train Loss: 0.065894, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29949 - Train Loss: 0.065892, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29950 - Train Loss: 0.065891, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29951 - Train Loss: 0.065890, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29952 - Train Loss: 0.065889, Train Acc: 0.897436 | Val Loss: 0.107935, Val Acc: 0.804124\n",
      "Epoch 29953 - Train Loss: 0.065888, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29954 - Train Loss: 0.065887, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29955 - Train Loss: 0.065886, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29956 - Train Loss: 0.065885, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29957 - Train Loss: 0.065884, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29958 - Train Loss: 0.065883, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29959 - Train Loss: 0.065882, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29960 - Train Loss: 0.065880, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29961 - Train Loss: 0.065879, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29962 - Train Loss: 0.065878, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29963 - Train Loss: 0.065877, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29964 - Train Loss: 0.065876, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29965 - Train Loss: 0.065875, Train Acc: 0.897436 | Val Loss: 0.107936, Val Acc: 0.804124\n",
      "Epoch 29966 - Train Loss: 0.065874, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29967 - Train Loss: 0.065873, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29968 - Train Loss: 0.065872, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29969 - Train Loss: 0.065871, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29970 - Train Loss: 0.065870, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29971 - Train Loss: 0.065868, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29972 - Train Loss: 0.065867, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29973 - Train Loss: 0.065866, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29974 - Train Loss: 0.065865, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29975 - Train Loss: 0.065864, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29976 - Train Loss: 0.065863, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29977 - Train Loss: 0.065862, Train Acc: 0.897436 | Val Loss: 0.107937, Val Acc: 0.804124\n",
      "Epoch 29978 - Train Loss: 0.065861, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29979 - Train Loss: 0.065860, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29980 - Train Loss: 0.065859, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29981 - Train Loss: 0.065858, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29982 - Train Loss: 0.065856, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29983 - Train Loss: 0.065855, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29984 - Train Loss: 0.065854, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29985 - Train Loss: 0.065853, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29986 - Train Loss: 0.065852, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29987 - Train Loss: 0.065851, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29988 - Train Loss: 0.065850, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29989 - Train Loss: 0.065849, Train Acc: 0.897436 | Val Loss: 0.107938, Val Acc: 0.804124\n",
      "Epoch 29990 - Train Loss: 0.065848, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29991 - Train Loss: 0.065847, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29992 - Train Loss: 0.065846, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29993 - Train Loss: 0.065844, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29994 - Train Loss: 0.065843, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29995 - Train Loss: 0.065842, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29996 - Train Loss: 0.065841, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29997 - Train Loss: 0.065840, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29998 - Train Loss: 0.065839, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 29999 - Train Loss: 0.065838, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 30000 - Train Loss: 0.065837, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 30001 - Train Loss: 0.065836, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 30002 - Train Loss: 0.065835, Train Acc: 0.897436 | Val Loss: 0.107939, Val Acc: 0.804124\n",
      "Epoch 30003 - Train Loss: 0.065834, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30004 - Train Loss: 0.065832, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30005 - Train Loss: 0.065831, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30006 - Train Loss: 0.065830, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30007 - Train Loss: 0.065829, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30008 - Train Loss: 0.065828, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30009 - Train Loss: 0.065827, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30010 - Train Loss: 0.065826, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30011 - Train Loss: 0.065825, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30012 - Train Loss: 0.065824, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30013 - Train Loss: 0.065823, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30014 - Train Loss: 0.065822, Train Acc: 0.897436 | Val Loss: 0.107940, Val Acc: 0.804124\n",
      "Epoch 30015 - Train Loss: 0.065820, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30016 - Train Loss: 0.065819, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30017 - Train Loss: 0.065818, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30018 - Train Loss: 0.065817, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30019 - Train Loss: 0.065816, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30020 - Train Loss: 0.065815, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30021 - Train Loss: 0.065814, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30022 - Train Loss: 0.065813, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30023 - Train Loss: 0.065812, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30024 - Train Loss: 0.065811, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30025 - Train Loss: 0.065810, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30026 - Train Loss: 0.065808, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30027 - Train Loss: 0.065807, Train Acc: 0.897436 | Val Loss: 0.107941, Val Acc: 0.804124\n",
      "Epoch 30028 - Train Loss: 0.065806, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30029 - Train Loss: 0.065805, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30030 - Train Loss: 0.065804, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30031 - Train Loss: 0.065803, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30032 - Train Loss: 0.065802, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30033 - Train Loss: 0.065801, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30034 - Train Loss: 0.065800, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30035 - Train Loss: 0.065799, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30036 - Train Loss: 0.065798, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30037 - Train Loss: 0.065797, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30038 - Train Loss: 0.065795, Train Acc: 0.897436 | Val Loss: 0.107942, Val Acc: 0.804124\n",
      "Epoch 30039 - Train Loss: 0.065794, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30040 - Train Loss: 0.065793, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30041 - Train Loss: 0.065792, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30042 - Train Loss: 0.065791, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30043 - Train Loss: 0.065790, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30044 - Train Loss: 0.065789, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30045 - Train Loss: 0.065788, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30046 - Train Loss: 0.065787, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30047 - Train Loss: 0.065786, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30048 - Train Loss: 0.065785, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30049 - Train Loss: 0.065783, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30050 - Train Loss: 0.065782, Train Acc: 0.897436 | Val Loss: 0.107943, Val Acc: 0.804124\n",
      "Epoch 30051 - Train Loss: 0.065781, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30052 - Train Loss: 0.065780, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30053 - Train Loss: 0.065779, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30054 - Train Loss: 0.065778, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30055 - Train Loss: 0.065777, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30056 - Train Loss: 0.065776, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30057 - Train Loss: 0.065775, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30058 - Train Loss: 0.065774, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30059 - Train Loss: 0.065773, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30060 - Train Loss: 0.065772, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30061 - Train Loss: 0.065770, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30062 - Train Loss: 0.065769, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30063 - Train Loss: 0.065768, Train Acc: 0.897436 | Val Loss: 0.107944, Val Acc: 0.804124\n",
      "Epoch 30064 - Train Loss: 0.065767, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30065 - Train Loss: 0.065766, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30066 - Train Loss: 0.065765, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30067 - Train Loss: 0.065764, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30068 - Train Loss: 0.065763, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30069 - Train Loss: 0.065762, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30070 - Train Loss: 0.065761, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30071 - Train Loss: 0.065760, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30072 - Train Loss: 0.065758, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30073 - Train Loss: 0.065757, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30074 - Train Loss: 0.065756, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30075 - Train Loss: 0.065755, Train Acc: 0.897436 | Val Loss: 0.107945, Val Acc: 0.804124\n",
      "Epoch 30076 - Train Loss: 0.065754, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30077 - Train Loss: 0.065753, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30078 - Train Loss: 0.065752, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30079 - Train Loss: 0.065751, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30080 - Train Loss: 0.065750, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30081 - Train Loss: 0.065749, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30082 - Train Loss: 0.065748, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30083 - Train Loss: 0.065747, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30084 - Train Loss: 0.065745, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30085 - Train Loss: 0.065744, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30086 - Train Loss: 0.065743, Train Acc: 0.897436 | Val Loss: 0.107946, Val Acc: 0.804124\n",
      "Epoch 30087 - Train Loss: 0.065742, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30088 - Train Loss: 0.065741, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30089 - Train Loss: 0.065740, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30090 - Train Loss: 0.065739, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30091 - Train Loss: 0.065738, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30092 - Train Loss: 0.065737, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30093 - Train Loss: 0.065736, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30094 - Train Loss: 0.065735, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30095 - Train Loss: 0.065734, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30096 - Train Loss: 0.065732, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30097 - Train Loss: 0.065731, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30098 - Train Loss: 0.065730, Train Acc: 0.897436 | Val Loss: 0.107947, Val Acc: 0.804124\n",
      "Epoch 30099 - Train Loss: 0.065729, Train Acc: 0.897436 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30100 - Train Loss: 0.065728, Train Acc: 0.897436 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30101 - Train Loss: 0.065727, Train Acc: 0.897436 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30102 - Train Loss: 0.065726, Train Acc: 0.897436 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30103 - Train Loss: 0.065725, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30104 - Train Loss: 0.065724, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30105 - Train Loss: 0.065723, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30106 - Train Loss: 0.065722, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30107 - Train Loss: 0.065721, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30108 - Train Loss: 0.065719, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30109 - Train Loss: 0.065718, Train Acc: 0.898718 | Val Loss: 0.107948, Val Acc: 0.804124\n",
      "Epoch 30110 - Train Loss: 0.065717, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30111 - Train Loss: 0.065716, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30112 - Train Loss: 0.065715, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30113 - Train Loss: 0.065714, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30114 - Train Loss: 0.065713, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30115 - Train Loss: 0.065712, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30116 - Train Loss: 0.065711, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30117 - Train Loss: 0.065710, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30118 - Train Loss: 0.065709, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30119 - Train Loss: 0.065708, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30120 - Train Loss: 0.065706, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30121 - Train Loss: 0.065705, Train Acc: 0.898718 | Val Loss: 0.107949, Val Acc: 0.804124\n",
      "Epoch 30122 - Train Loss: 0.065704, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30123 - Train Loss: 0.065703, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30124 - Train Loss: 0.065702, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30125 - Train Loss: 0.065701, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30126 - Train Loss: 0.065700, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30127 - Train Loss: 0.065699, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30128 - Train Loss: 0.065698, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30129 - Train Loss: 0.065697, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30130 - Train Loss: 0.065696, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30131 - Train Loss: 0.065695, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30132 - Train Loss: 0.065693, Train Acc: 0.898718 | Val Loss: 0.107950, Val Acc: 0.804124\n",
      "Epoch 30133 - Train Loss: 0.065692, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30134 - Train Loss: 0.065691, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30135 - Train Loss: 0.065690, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30136 - Train Loss: 0.065689, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30137 - Train Loss: 0.065688, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30138 - Train Loss: 0.065687, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30139 - Train Loss: 0.065686, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30140 - Train Loss: 0.065685, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30141 - Train Loss: 0.065684, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30142 - Train Loss: 0.065683, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30143 - Train Loss: 0.065682, Train Acc: 0.898718 | Val Loss: 0.107951, Val Acc: 0.804124\n",
      "Epoch 30144 - Train Loss: 0.065680, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30145 - Train Loss: 0.065679, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30146 - Train Loss: 0.065678, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30147 - Train Loss: 0.065677, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30148 - Train Loss: 0.065676, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30149 - Train Loss: 0.065675, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30150 - Train Loss: 0.065674, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30151 - Train Loss: 0.065673, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30152 - Train Loss: 0.065672, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30153 - Train Loss: 0.065671, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30154 - Train Loss: 0.065670, Train Acc: 0.898718 | Val Loss: 0.107952, Val Acc: 0.804124\n",
      "Epoch 30155 - Train Loss: 0.065669, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30156 - Train Loss: 0.065668, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30157 - Train Loss: 0.065666, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30158 - Train Loss: 0.065665, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30159 - Train Loss: 0.065664, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30160 - Train Loss: 0.065663, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30161 - Train Loss: 0.065662, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30162 - Train Loss: 0.065661, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30163 - Train Loss: 0.065660, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30164 - Train Loss: 0.065659, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30165 - Train Loss: 0.065658, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30166 - Train Loss: 0.065657, Train Acc: 0.898718 | Val Loss: 0.107953, Val Acc: 0.804124\n",
      "Epoch 30167 - Train Loss: 0.065656, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30168 - Train Loss: 0.065655, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30169 - Train Loss: 0.065653, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30170 - Train Loss: 0.065652, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30171 - Train Loss: 0.065651, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30172 - Train Loss: 0.065650, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30173 - Train Loss: 0.065649, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30174 - Train Loss: 0.065648, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30175 - Train Loss: 0.065647, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30176 - Train Loss: 0.065646, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30177 - Train Loss: 0.065645, Train Acc: 0.898718 | Val Loss: 0.107954, Val Acc: 0.804124\n",
      "Epoch 30178 - Train Loss: 0.065644, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30179 - Train Loss: 0.065643, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30180 - Train Loss: 0.065642, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30181 - Train Loss: 0.065641, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30182 - Train Loss: 0.065639, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30183 - Train Loss: 0.065638, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30184 - Train Loss: 0.065637, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30185 - Train Loss: 0.065636, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30186 - Train Loss: 0.065635, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30187 - Train Loss: 0.065634, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30188 - Train Loss: 0.065633, Train Acc: 0.898718 | Val Loss: 0.107955, Val Acc: 0.804124\n",
      "Epoch 30189 - Train Loss: 0.065632, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30190 - Train Loss: 0.065631, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30191 - Train Loss: 0.065630, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30192 - Train Loss: 0.065629, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30193 - Train Loss: 0.065628, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30194 - Train Loss: 0.065626, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30195 - Train Loss: 0.065625, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30196 - Train Loss: 0.065624, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30197 - Train Loss: 0.065623, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30198 - Train Loss: 0.065622, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30199 - Train Loss: 0.065621, Train Acc: 0.898718 | Val Loss: 0.107956, Val Acc: 0.804124\n",
      "Epoch 30200 - Train Loss: 0.065620, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30201 - Train Loss: 0.065619, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30202 - Train Loss: 0.065618, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30203 - Train Loss: 0.065617, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30204 - Train Loss: 0.065616, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30205 - Train Loss: 0.065615, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30206 - Train Loss: 0.065614, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30207 - Train Loss: 0.065612, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30208 - Train Loss: 0.065611, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30209 - Train Loss: 0.065610, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30210 - Train Loss: 0.065609, Train Acc: 0.898718 | Val Loss: 0.107957, Val Acc: 0.804124\n",
      "Epoch 30211 - Train Loss: 0.065608, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30212 - Train Loss: 0.065607, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30213 - Train Loss: 0.065606, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30214 - Train Loss: 0.065605, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30215 - Train Loss: 0.065604, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30216 - Train Loss: 0.065603, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30217 - Train Loss: 0.065602, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30218 - Train Loss: 0.065601, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30219 - Train Loss: 0.065600, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30220 - Train Loss: 0.065598, Train Acc: 0.898718 | Val Loss: 0.107958, Val Acc: 0.804124\n",
      "Epoch 30221 - Train Loss: 0.065597, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30222 - Train Loss: 0.065596, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30223 - Train Loss: 0.065595, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30224 - Train Loss: 0.065594, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30225 - Train Loss: 0.065593, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30226 - Train Loss: 0.065592, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30227 - Train Loss: 0.065591, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30228 - Train Loss: 0.065590, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30229 - Train Loss: 0.065589, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30230 - Train Loss: 0.065588, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30231 - Train Loss: 0.065587, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30232 - Train Loss: 0.065586, Train Acc: 0.898718 | Val Loss: 0.107959, Val Acc: 0.804124\n",
      "Epoch 30233 - Train Loss: 0.065584, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30234 - Train Loss: 0.065583, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30235 - Train Loss: 0.065582, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30236 - Train Loss: 0.065581, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30237 - Train Loss: 0.065580, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30238 - Train Loss: 0.065579, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30239 - Train Loss: 0.065578, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30240 - Train Loss: 0.065577, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30241 - Train Loss: 0.065576, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30242 - Train Loss: 0.065575, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30243 - Train Loss: 0.065574, Train Acc: 0.898718 | Val Loss: 0.107960, Val Acc: 0.804124\n",
      "Epoch 30244 - Train Loss: 0.065573, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30245 - Train Loss: 0.065572, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30246 - Train Loss: 0.065570, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30247 - Train Loss: 0.065569, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30248 - Train Loss: 0.065568, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30249 - Train Loss: 0.065567, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30250 - Train Loss: 0.065566, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30251 - Train Loss: 0.065565, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30252 - Train Loss: 0.065564, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30253 - Train Loss: 0.065563, Train Acc: 0.898718 | Val Loss: 0.107961, Val Acc: 0.804124\n",
      "Epoch 30254 - Train Loss: 0.065562, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30255 - Train Loss: 0.065561, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30256 - Train Loss: 0.065560, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30257 - Train Loss: 0.065559, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30258 - Train Loss: 0.065558, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30259 - Train Loss: 0.065556, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30260 - Train Loss: 0.065555, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30261 - Train Loss: 0.065554, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30262 - Train Loss: 0.065553, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30263 - Train Loss: 0.065552, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30264 - Train Loss: 0.065551, Train Acc: 0.898718 | Val Loss: 0.107962, Val Acc: 0.804124\n",
      "Epoch 30265 - Train Loss: 0.065550, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30266 - Train Loss: 0.065549, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30267 - Train Loss: 0.065548, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30268 - Train Loss: 0.065547, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30269 - Train Loss: 0.065546, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30270 - Train Loss: 0.065545, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30271 - Train Loss: 0.065544, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30272 - Train Loss: 0.065543, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30273 - Train Loss: 0.065541, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30274 - Train Loss: 0.065540, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30275 - Train Loss: 0.065539, Train Acc: 0.898718 | Val Loss: 0.107963, Val Acc: 0.804124\n",
      "Epoch 30276 - Train Loss: 0.065538, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30277 - Train Loss: 0.065537, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30278 - Train Loss: 0.065536, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30279 - Train Loss: 0.065535, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30280 - Train Loss: 0.065534, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30281 - Train Loss: 0.065533, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30282 - Train Loss: 0.065532, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30283 - Train Loss: 0.065531, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30284 - Train Loss: 0.065530, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30285 - Train Loss: 0.065529, Train Acc: 0.898718 | Val Loss: 0.107964, Val Acc: 0.804124\n",
      "Epoch 30286 - Train Loss: 0.065527, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30287 - Train Loss: 0.065526, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30288 - Train Loss: 0.065525, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30289 - Train Loss: 0.065524, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30290 - Train Loss: 0.065523, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30291 - Train Loss: 0.065522, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30292 - Train Loss: 0.065521, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30293 - Train Loss: 0.065520, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30294 - Train Loss: 0.065519, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30295 - Train Loss: 0.065518, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30296 - Train Loss: 0.065517, Train Acc: 0.898718 | Val Loss: 0.107965, Val Acc: 0.804124\n",
      "Epoch 30297 - Train Loss: 0.065516, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30298 - Train Loss: 0.065515, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30299 - Train Loss: 0.065514, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30300 - Train Loss: 0.065512, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30301 - Train Loss: 0.065511, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30302 - Train Loss: 0.065510, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30303 - Train Loss: 0.065509, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30304 - Train Loss: 0.065508, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30305 - Train Loss: 0.065507, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30306 - Train Loss: 0.065506, Train Acc: 0.898718 | Val Loss: 0.107966, Val Acc: 0.804124\n",
      "Epoch 30307 - Train Loss: 0.065505, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30308 - Train Loss: 0.065504, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30309 - Train Loss: 0.065503, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30310 - Train Loss: 0.065502, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30311 - Train Loss: 0.065501, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30312 - Train Loss: 0.065500, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30313 - Train Loss: 0.065499, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30314 - Train Loss: 0.065497, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30315 - Train Loss: 0.065496, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30316 - Train Loss: 0.065495, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30317 - Train Loss: 0.065494, Train Acc: 0.898718 | Val Loss: 0.107967, Val Acc: 0.804124\n",
      "Epoch 30318 - Train Loss: 0.065493, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30319 - Train Loss: 0.065492, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30320 - Train Loss: 0.065491, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30321 - Train Loss: 0.065490, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30322 - Train Loss: 0.065489, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30323 - Train Loss: 0.065488, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30324 - Train Loss: 0.065487, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30325 - Train Loss: 0.065486, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30326 - Train Loss: 0.065485, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30327 - Train Loss: 0.065484, Train Acc: 0.898718 | Val Loss: 0.107968, Val Acc: 0.804124\n",
      "Epoch 30328 - Train Loss: 0.065482, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30329 - Train Loss: 0.065481, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30330 - Train Loss: 0.065480, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30331 - Train Loss: 0.065479, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30332 - Train Loss: 0.065478, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30333 - Train Loss: 0.065477, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30334 - Train Loss: 0.065476, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30335 - Train Loss: 0.065475, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30336 - Train Loss: 0.065474, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30337 - Train Loss: 0.065473, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30338 - Train Loss: 0.065472, Train Acc: 0.898718 | Val Loss: 0.107969, Val Acc: 0.804124\n",
      "Epoch 30339 - Train Loss: 0.065471, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30340 - Train Loss: 0.065470, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30341 - Train Loss: 0.065469, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30342 - Train Loss: 0.065467, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30343 - Train Loss: 0.065466, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30344 - Train Loss: 0.065465, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30345 - Train Loss: 0.065464, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30346 - Train Loss: 0.065463, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30347 - Train Loss: 0.065462, Train Acc: 0.898718 | Val Loss: 0.107970, Val Acc: 0.804124\n",
      "Epoch 30348 - Train Loss: 0.065461, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30349 - Train Loss: 0.065460, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30350 - Train Loss: 0.065459, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30351 - Train Loss: 0.065458, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30352 - Train Loss: 0.065457, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30353 - Train Loss: 0.065456, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30354 - Train Loss: 0.065455, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30355 - Train Loss: 0.065454, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30356 - Train Loss: 0.065452, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30357 - Train Loss: 0.065451, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30358 - Train Loss: 0.065450, Train Acc: 0.898718 | Val Loss: 0.107971, Val Acc: 0.804124\n",
      "Epoch 30359 - Train Loss: 0.065449, Train Acc: 0.898718 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30360 - Train Loss: 0.065448, Train Acc: 0.898718 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30361 - Train Loss: 0.065447, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30362 - Train Loss: 0.065446, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30363 - Train Loss: 0.065445, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30364 - Train Loss: 0.065444, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30365 - Train Loss: 0.065443, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30366 - Train Loss: 0.065442, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30367 - Train Loss: 0.065441, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30368 - Train Loss: 0.065440, Train Acc: 0.900000 | Val Loss: 0.107972, Val Acc: 0.804124\n",
      "Epoch 30369 - Train Loss: 0.065439, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30370 - Train Loss: 0.065438, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30371 - Train Loss: 0.065436, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30372 - Train Loss: 0.065435, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30373 - Train Loss: 0.065434, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30374 - Train Loss: 0.065433, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30375 - Train Loss: 0.065432, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30376 - Train Loss: 0.065431, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30377 - Train Loss: 0.065430, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30378 - Train Loss: 0.065429, Train Acc: 0.900000 | Val Loss: 0.107973, Val Acc: 0.804124\n",
      "Epoch 30379 - Train Loss: 0.065428, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30380 - Train Loss: 0.065427, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30381 - Train Loss: 0.065426, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30382 - Train Loss: 0.065425, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30383 - Train Loss: 0.065424, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30384 - Train Loss: 0.065423, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30385 - Train Loss: 0.065421, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30386 - Train Loss: 0.065420, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30387 - Train Loss: 0.065419, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30388 - Train Loss: 0.065418, Train Acc: 0.900000 | Val Loss: 0.107974, Val Acc: 0.804124\n",
      "Epoch 30389 - Train Loss: 0.065417, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30390 - Train Loss: 0.065416, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30391 - Train Loss: 0.065415, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30392 - Train Loss: 0.065414, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30393 - Train Loss: 0.065413, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30394 - Train Loss: 0.065412, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30395 - Train Loss: 0.065411, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30396 - Train Loss: 0.065410, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30397 - Train Loss: 0.065409, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30398 - Train Loss: 0.065408, Train Acc: 0.900000 | Val Loss: 0.107975, Val Acc: 0.804124\n",
      "Epoch 30399 - Train Loss: 0.065407, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30400 - Train Loss: 0.065405, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30401 - Train Loss: 0.065404, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30402 - Train Loss: 0.065403, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30403 - Train Loss: 0.065402, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30404 - Train Loss: 0.065401, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30405 - Train Loss: 0.065400, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30406 - Train Loss: 0.065399, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30407 - Train Loss: 0.065398, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30408 - Train Loss: 0.065397, Train Acc: 0.900000 | Val Loss: 0.107976, Val Acc: 0.804124\n",
      "Epoch 30409 - Train Loss: 0.065396, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30410 - Train Loss: 0.065395, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30411 - Train Loss: 0.065394, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30412 - Train Loss: 0.065393, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30413 - Train Loss: 0.065392, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30414 - Train Loss: 0.065391, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30415 - Train Loss: 0.065389, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30416 - Train Loss: 0.065388, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30417 - Train Loss: 0.065387, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30418 - Train Loss: 0.065386, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30419 - Train Loss: 0.065385, Train Acc: 0.900000 | Val Loss: 0.107977, Val Acc: 0.804124\n",
      "Epoch 30420 - Train Loss: 0.065384, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30421 - Train Loss: 0.065383, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30422 - Train Loss: 0.065382, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30423 - Train Loss: 0.065381, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30424 - Train Loss: 0.065380, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30425 - Train Loss: 0.065379, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30426 - Train Loss: 0.065378, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30427 - Train Loss: 0.065377, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30428 - Train Loss: 0.065376, Train Acc: 0.900000 | Val Loss: 0.107978, Val Acc: 0.804124\n",
      "Epoch 30429 - Train Loss: 0.065375, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30430 - Train Loss: 0.065373, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30431 - Train Loss: 0.065372, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30432 - Train Loss: 0.065371, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30433 - Train Loss: 0.065370, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30434 - Train Loss: 0.065369, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30435 - Train Loss: 0.065368, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30436 - Train Loss: 0.065367, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30437 - Train Loss: 0.065366, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30438 - Train Loss: 0.065365, Train Acc: 0.900000 | Val Loss: 0.107979, Val Acc: 0.804124\n",
      "Epoch 30439 - Train Loss: 0.065364, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30440 - Train Loss: 0.065363, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30441 - Train Loss: 0.065362, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30442 - Train Loss: 0.065361, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30443 - Train Loss: 0.065360, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30444 - Train Loss: 0.065359, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30445 - Train Loss: 0.065358, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30446 - Train Loss: 0.065356, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30447 - Train Loss: 0.065355, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30448 - Train Loss: 0.065354, Train Acc: 0.900000 | Val Loss: 0.107980, Val Acc: 0.804124\n",
      "Epoch 30449 - Train Loss: 0.065353, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30450 - Train Loss: 0.065352, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30451 - Train Loss: 0.065351, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30452 - Train Loss: 0.065350, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30453 - Train Loss: 0.065349, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30454 - Train Loss: 0.065348, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30455 - Train Loss: 0.065347, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30456 - Train Loss: 0.065346, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30457 - Train Loss: 0.065345, Train Acc: 0.900000 | Val Loss: 0.107981, Val Acc: 0.804124\n",
      "Epoch 30458 - Train Loss: 0.065344, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30459 - Train Loss: 0.065343, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30460 - Train Loss: 0.065342, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30461 - Train Loss: 0.065340, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30462 - Train Loss: 0.065339, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30463 - Train Loss: 0.065338, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30464 - Train Loss: 0.065337, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30465 - Train Loss: 0.065336, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30466 - Train Loss: 0.065335, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30467 - Train Loss: 0.065334, Train Acc: 0.900000 | Val Loss: 0.107982, Val Acc: 0.804124\n",
      "Epoch 30468 - Train Loss: 0.065333, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30469 - Train Loss: 0.065332, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30470 - Train Loss: 0.065331, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30471 - Train Loss: 0.065330, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30472 - Train Loss: 0.065329, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30473 - Train Loss: 0.065328, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30474 - Train Loss: 0.065327, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30475 - Train Loss: 0.065326, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30476 - Train Loss: 0.065325, Train Acc: 0.900000 | Val Loss: 0.107983, Val Acc: 0.804124\n",
      "Epoch 30477 - Train Loss: 0.065323, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30478 - Train Loss: 0.065322, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30479 - Train Loss: 0.065321, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30480 - Train Loss: 0.065320, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30481 - Train Loss: 0.065319, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30482 - Train Loss: 0.065318, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30483 - Train Loss: 0.065317, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30484 - Train Loss: 0.065316, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30485 - Train Loss: 0.065315, Train Acc: 0.900000 | Val Loss: 0.107984, Val Acc: 0.804124\n",
      "Epoch 30486 - Train Loss: 0.065314, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30487 - Train Loss: 0.065313, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30488 - Train Loss: 0.065312, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30489 - Train Loss: 0.065311, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30490 - Train Loss: 0.065310, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30491 - Train Loss: 0.065309, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30492 - Train Loss: 0.065308, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30493 - Train Loss: 0.065306, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30494 - Train Loss: 0.065305, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30495 - Train Loss: 0.065304, Train Acc: 0.900000 | Val Loss: 0.107985, Val Acc: 0.804124\n",
      "Epoch 30496 - Train Loss: 0.065303, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30497 - Train Loss: 0.065302, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30498 - Train Loss: 0.065301, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30499 - Train Loss: 0.065300, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30500 - Train Loss: 0.065299, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30501 - Train Loss: 0.065298, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30502 - Train Loss: 0.065297, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30503 - Train Loss: 0.065296, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30504 - Train Loss: 0.065295, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30505 - Train Loss: 0.065294, Train Acc: 0.900000 | Val Loss: 0.107986, Val Acc: 0.804124\n",
      "Epoch 30506 - Train Loss: 0.065293, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30507 - Train Loss: 0.065292, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30508 - Train Loss: 0.065291, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30509 - Train Loss: 0.065289, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30510 - Train Loss: 0.065288, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30511 - Train Loss: 0.065287, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30512 - Train Loss: 0.065286, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30513 - Train Loss: 0.065285, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30514 - Train Loss: 0.065284, Train Acc: 0.900000 | Val Loss: 0.107987, Val Acc: 0.804124\n",
      "Epoch 30515 - Train Loss: 0.065283, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30516 - Train Loss: 0.065282, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30517 - Train Loss: 0.065281, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30518 - Train Loss: 0.065280, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30519 - Train Loss: 0.065279, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30520 - Train Loss: 0.065278, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30521 - Train Loss: 0.065277, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30522 - Train Loss: 0.065276, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30523 - Train Loss: 0.065275, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30524 - Train Loss: 0.065274, Train Acc: 0.900000 | Val Loss: 0.107988, Val Acc: 0.804124\n",
      "Epoch 30525 - Train Loss: 0.065273, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30526 - Train Loss: 0.065271, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30527 - Train Loss: 0.065270, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30528 - Train Loss: 0.065269, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30529 - Train Loss: 0.065268, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30530 - Train Loss: 0.065267, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30531 - Train Loss: 0.065266, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30532 - Train Loss: 0.065265, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30533 - Train Loss: 0.065264, Train Acc: 0.900000 | Val Loss: 0.107989, Val Acc: 0.804124\n",
      "Epoch 30534 - Train Loss: 0.065263, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30535 - Train Loss: 0.065262, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30536 - Train Loss: 0.065261, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30537 - Train Loss: 0.065260, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30538 - Train Loss: 0.065259, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30539 - Train Loss: 0.065258, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30540 - Train Loss: 0.065257, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30541 - Train Loss: 0.065256, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30542 - Train Loss: 0.065255, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30543 - Train Loss: 0.065253, Train Acc: 0.900000 | Val Loss: 0.107990, Val Acc: 0.804124\n",
      "Epoch 30544 - Train Loss: 0.065252, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30545 - Train Loss: 0.065251, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30546 - Train Loss: 0.065250, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30547 - Train Loss: 0.065249, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30548 - Train Loss: 0.065248, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30549 - Train Loss: 0.065247, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30550 - Train Loss: 0.065246, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30551 - Train Loss: 0.065245, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30552 - Train Loss: 0.065244, Train Acc: 0.900000 | Val Loss: 0.107991, Val Acc: 0.804124\n",
      "Epoch 30553 - Train Loss: 0.065243, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30554 - Train Loss: 0.065242, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30555 - Train Loss: 0.065241, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30556 - Train Loss: 0.065240, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30557 - Train Loss: 0.065239, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30558 - Train Loss: 0.065238, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30559 - Train Loss: 0.065237, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30560 - Train Loss: 0.065235, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30561 - Train Loss: 0.065234, Train Acc: 0.900000 | Val Loss: 0.107992, Val Acc: 0.804124\n",
      "Epoch 30562 - Train Loss: 0.065233, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30563 - Train Loss: 0.065232, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30564 - Train Loss: 0.065231, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30565 - Train Loss: 0.065230, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30566 - Train Loss: 0.065229, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30567 - Train Loss: 0.065228, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30568 - Train Loss: 0.065227, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30569 - Train Loss: 0.065226, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30570 - Train Loss: 0.065225, Train Acc: 0.900000 | Val Loss: 0.107993, Val Acc: 0.804124\n",
      "Epoch 30571 - Train Loss: 0.065224, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30572 - Train Loss: 0.065223, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30573 - Train Loss: 0.065222, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30574 - Train Loss: 0.065221, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30575 - Train Loss: 0.065220, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30576 - Train Loss: 0.065219, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30577 - Train Loss: 0.065217, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30578 - Train Loss: 0.065216, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30579 - Train Loss: 0.065215, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30580 - Train Loss: 0.065214, Train Acc: 0.900000 | Val Loss: 0.107994, Val Acc: 0.804124\n",
      "Epoch 30581 - Train Loss: 0.065213, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30582 - Train Loss: 0.065212, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30583 - Train Loss: 0.065211, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30584 - Train Loss: 0.065210, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30585 - Train Loss: 0.065209, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30586 - Train Loss: 0.065208, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30587 - Train Loss: 0.065207, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30588 - Train Loss: 0.065206, Train Acc: 0.900000 | Val Loss: 0.107995, Val Acc: 0.804124\n",
      "Epoch 30589 - Train Loss: 0.065205, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30590 - Train Loss: 0.065204, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30591 - Train Loss: 0.065203, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30592 - Train Loss: 0.065202, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30593 - Train Loss: 0.065201, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30594 - Train Loss: 0.065199, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30595 - Train Loss: 0.065198, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30596 - Train Loss: 0.065197, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30597 - Train Loss: 0.065196, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30598 - Train Loss: 0.065195, Train Acc: 0.900000 | Val Loss: 0.107996, Val Acc: 0.804124\n",
      "Epoch 30599 - Train Loss: 0.065194, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30600 - Train Loss: 0.065193, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30601 - Train Loss: 0.065192, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30602 - Train Loss: 0.065191, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30603 - Train Loss: 0.065190, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30604 - Train Loss: 0.065189, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30605 - Train Loss: 0.065188, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30606 - Train Loss: 0.065187, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30607 - Train Loss: 0.065186, Train Acc: 0.900000 | Val Loss: 0.107997, Val Acc: 0.804124\n",
      "Epoch 30608 - Train Loss: 0.065185, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30609 - Train Loss: 0.065184, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30610 - Train Loss: 0.065183, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30611 - Train Loss: 0.065182, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30612 - Train Loss: 0.065180, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30613 - Train Loss: 0.065179, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30614 - Train Loss: 0.065178, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30615 - Train Loss: 0.065177, Train Acc: 0.900000 | Val Loss: 0.107998, Val Acc: 0.804124\n",
      "Epoch 30616 - Train Loss: 0.065176, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30617 - Train Loss: 0.065175, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30618 - Train Loss: 0.065174, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30619 - Train Loss: 0.065173, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30620 - Train Loss: 0.065172, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30621 - Train Loss: 0.065171, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30622 - Train Loss: 0.065170, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30623 - Train Loss: 0.065169, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30624 - Train Loss: 0.065168, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30625 - Train Loss: 0.065167, Train Acc: 0.900000 | Val Loss: 0.107999, Val Acc: 0.804124\n",
      "Epoch 30626 - Train Loss: 0.065166, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30627 - Train Loss: 0.065165, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30628 - Train Loss: 0.065164, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30629 - Train Loss: 0.065163, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30630 - Train Loss: 0.065161, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30631 - Train Loss: 0.065160, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30632 - Train Loss: 0.065159, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30633 - Train Loss: 0.065158, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30634 - Train Loss: 0.065157, Train Acc: 0.900000 | Val Loss: 0.108000, Val Acc: 0.804124\n",
      "Epoch 30635 - Train Loss: 0.065156, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30636 - Train Loss: 0.065155, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30637 - Train Loss: 0.065154, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30638 - Train Loss: 0.065153, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30639 - Train Loss: 0.065152, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30640 - Train Loss: 0.065151, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30641 - Train Loss: 0.065150, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30642 - Train Loss: 0.065149, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30643 - Train Loss: 0.065148, Train Acc: 0.900000 | Val Loss: 0.108001, Val Acc: 0.804124\n",
      "Epoch 30644 - Train Loss: 0.065147, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30645 - Train Loss: 0.065146, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30646 - Train Loss: 0.065145, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30647 - Train Loss: 0.065144, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30648 - Train Loss: 0.065143, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30649 - Train Loss: 0.065141, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30650 - Train Loss: 0.065140, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30651 - Train Loss: 0.065139, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30652 - Train Loss: 0.065138, Train Acc: 0.900000 | Val Loss: 0.108002, Val Acc: 0.804124\n",
      "Epoch 30653 - Train Loss: 0.065137, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30654 - Train Loss: 0.065136, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30655 - Train Loss: 0.065135, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30656 - Train Loss: 0.065134, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30657 - Train Loss: 0.065133, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30658 - Train Loss: 0.065132, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30659 - Train Loss: 0.065131, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30660 - Train Loss: 0.065130, Train Acc: 0.900000 | Val Loss: 0.108003, Val Acc: 0.804124\n",
      "Epoch 30661 - Train Loss: 0.065129, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30662 - Train Loss: 0.065128, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30663 - Train Loss: 0.065127, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30664 - Train Loss: 0.065126, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30665 - Train Loss: 0.065125, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30666 - Train Loss: 0.065124, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30667 - Train Loss: 0.065123, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30668 - Train Loss: 0.065121, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30669 - Train Loss: 0.065120, Train Acc: 0.900000 | Val Loss: 0.108004, Val Acc: 0.804124\n",
      "Epoch 30670 - Train Loss: 0.065119, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30671 - Train Loss: 0.065118, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30672 - Train Loss: 0.065117, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30673 - Train Loss: 0.065116, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30674 - Train Loss: 0.065115, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30675 - Train Loss: 0.065114, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30676 - Train Loss: 0.065113, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30677 - Train Loss: 0.065112, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30678 - Train Loss: 0.065111, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30679 - Train Loss: 0.065110, Train Acc: 0.900000 | Val Loss: 0.108005, Val Acc: 0.804124\n",
      "Epoch 30680 - Train Loss: 0.065109, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30681 - Train Loss: 0.065108, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30682 - Train Loss: 0.065107, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30683 - Train Loss: 0.065106, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30684 - Train Loss: 0.065105, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30685 - Train Loss: 0.065104, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30686 - Train Loss: 0.065103, Train Acc: 0.900000 | Val Loss: 0.108006, Val Acc: 0.804124\n",
      "Epoch 30687 - Train Loss: 0.065101, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30688 - Train Loss: 0.065100, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30689 - Train Loss: 0.065099, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30690 - Train Loss: 0.065098, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30691 - Train Loss: 0.065097, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30692 - Train Loss: 0.065096, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30693 - Train Loss: 0.065095, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30694 - Train Loss: 0.065094, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30695 - Train Loss: 0.065093, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30696 - Train Loss: 0.065092, Train Acc: 0.900000 | Val Loss: 0.108007, Val Acc: 0.804124\n",
      "Epoch 30697 - Train Loss: 0.065091, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30698 - Train Loss: 0.065090, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30699 - Train Loss: 0.065089, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30700 - Train Loss: 0.065088, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30701 - Train Loss: 0.065087, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30702 - Train Loss: 0.065086, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30703 - Train Loss: 0.065085, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30704 - Train Loss: 0.065084, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30705 - Train Loss: 0.065083, Train Acc: 0.900000 | Val Loss: 0.108008, Val Acc: 0.804124\n",
      "Epoch 30706 - Train Loss: 0.065081, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30707 - Train Loss: 0.065080, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30708 - Train Loss: 0.065079, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30709 - Train Loss: 0.065078, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30710 - Train Loss: 0.065077, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30711 - Train Loss: 0.065076, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30712 - Train Loss: 0.065075, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30713 - Train Loss: 0.065074, Train Acc: 0.900000 | Val Loss: 0.108009, Val Acc: 0.804124\n",
      "Epoch 30714 - Train Loss: 0.065073, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30715 - Train Loss: 0.065072, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30716 - Train Loss: 0.065071, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30717 - Train Loss: 0.065070, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30718 - Train Loss: 0.065069, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30719 - Train Loss: 0.065068, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30720 - Train Loss: 0.065067, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30721 - Train Loss: 0.065066, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30722 - Train Loss: 0.065065, Train Acc: 0.900000 | Val Loss: 0.108010, Val Acc: 0.804124\n",
      "Epoch 30723 - Train Loss: 0.065064, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30724 - Train Loss: 0.065063, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30725 - Train Loss: 0.065062, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30726 - Train Loss: 0.065060, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30727 - Train Loss: 0.065059, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30728 - Train Loss: 0.065058, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30729 - Train Loss: 0.065057, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30730 - Train Loss: 0.065056, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30731 - Train Loss: 0.065055, Train Acc: 0.900000 | Val Loss: 0.108011, Val Acc: 0.804124\n",
      "Epoch 30732 - Train Loss: 0.065054, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30733 - Train Loss: 0.065053, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30734 - Train Loss: 0.065052, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30735 - Train Loss: 0.065051, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30736 - Train Loss: 0.065050, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30737 - Train Loss: 0.065049, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30738 - Train Loss: 0.065048, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30739 - Train Loss: 0.065047, Train Acc: 0.900000 | Val Loss: 0.108012, Val Acc: 0.804124\n",
      "Epoch 30740 - Train Loss: 0.065046, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30741 - Train Loss: 0.065045, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30742 - Train Loss: 0.065044, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30743 - Train Loss: 0.065043, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30744 - Train Loss: 0.065042, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30745 - Train Loss: 0.065041, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30746 - Train Loss: 0.065040, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30747 - Train Loss: 0.065038, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30748 - Train Loss: 0.065037, Train Acc: 0.900000 | Val Loss: 0.108013, Val Acc: 0.804124\n",
      "Epoch 30749 - Train Loss: 0.065036, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30750 - Train Loss: 0.065035, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30751 - Train Loss: 0.065034, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30752 - Train Loss: 0.065033, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30753 - Train Loss: 0.065032, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30754 - Train Loss: 0.065031, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30755 - Train Loss: 0.065030, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30756 - Train Loss: 0.065029, Train Acc: 0.900000 | Val Loss: 0.108014, Val Acc: 0.804124\n",
      "Epoch 30757 - Train Loss: 0.065028, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30758 - Train Loss: 0.065027, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30759 - Train Loss: 0.065026, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30760 - Train Loss: 0.065025, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30761 - Train Loss: 0.065024, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30762 - Train Loss: 0.065023, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30763 - Train Loss: 0.065022, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30764 - Train Loss: 0.065021, Train Acc: 0.900000 | Val Loss: 0.108015, Val Acc: 0.804124\n",
      "Epoch 30765 - Train Loss: 0.065020, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30766 - Train Loss: 0.065019, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30767 - Train Loss: 0.065018, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30768 - Train Loss: 0.065016, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30769 - Train Loss: 0.065015, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30770 - Train Loss: 0.065014, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30771 - Train Loss: 0.065013, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30772 - Train Loss: 0.065012, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30773 - Train Loss: 0.065011, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30774 - Train Loss: 0.065010, Train Acc: 0.900000 | Val Loss: 0.108016, Val Acc: 0.804124\n",
      "Epoch 30775 - Train Loss: 0.065009, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30776 - Train Loss: 0.065008, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30777 - Train Loss: 0.065007, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30778 - Train Loss: 0.065006, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30779 - Train Loss: 0.065005, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30780 - Train Loss: 0.065004, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30781 - Train Loss: 0.065003, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30782 - Train Loss: 0.065002, Train Acc: 0.900000 | Val Loss: 0.108017, Val Acc: 0.804124\n",
      "Epoch 30783 - Train Loss: 0.065001, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30784 - Train Loss: 0.065000, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30785 - Train Loss: 0.064999, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30786 - Train Loss: 0.064998, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30787 - Train Loss: 0.064997, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30788 - Train Loss: 0.064996, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30789 - Train Loss: 0.064994, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30790 - Train Loss: 0.064993, Train Acc: 0.900000 | Val Loss: 0.108018, Val Acc: 0.804124\n",
      "Epoch 30791 - Train Loss: 0.064992, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30792 - Train Loss: 0.064991, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30793 - Train Loss: 0.064990, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30794 - Train Loss: 0.064989, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30795 - Train Loss: 0.064988, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30796 - Train Loss: 0.064987, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30797 - Train Loss: 0.064986, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30798 - Train Loss: 0.064985, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30799 - Train Loss: 0.064984, Train Acc: 0.900000 | Val Loss: 0.108019, Val Acc: 0.804124\n",
      "Epoch 30800 - Train Loss: 0.064983, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30801 - Train Loss: 0.064982, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30802 - Train Loss: 0.064981, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30803 - Train Loss: 0.064980, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30804 - Train Loss: 0.064979, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30805 - Train Loss: 0.064978, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30806 - Train Loss: 0.064977, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30807 - Train Loss: 0.064976, Train Acc: 0.900000 | Val Loss: 0.108020, Val Acc: 0.804124\n",
      "Epoch 30808 - Train Loss: 0.064975, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30809 - Train Loss: 0.064974, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30810 - Train Loss: 0.064973, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30811 - Train Loss: 0.064971, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30812 - Train Loss: 0.064970, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30813 - Train Loss: 0.064969, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30814 - Train Loss: 0.064968, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30815 - Train Loss: 0.064967, Train Acc: 0.900000 | Val Loss: 0.108021, Val Acc: 0.804124\n",
      "Epoch 30816 - Train Loss: 0.064966, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30817 - Train Loss: 0.064965, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30818 - Train Loss: 0.064964, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30819 - Train Loss: 0.064963, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30820 - Train Loss: 0.064962, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30821 - Train Loss: 0.064961, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30822 - Train Loss: 0.064960, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30823 - Train Loss: 0.064959, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30824 - Train Loss: 0.064958, Train Acc: 0.900000 | Val Loss: 0.108022, Val Acc: 0.804124\n",
      "Epoch 30825 - Train Loss: 0.064957, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30826 - Train Loss: 0.064956, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30827 - Train Loss: 0.064955, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30828 - Train Loss: 0.064954, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30829 - Train Loss: 0.064953, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30830 - Train Loss: 0.064952, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30831 - Train Loss: 0.064951, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30832 - Train Loss: 0.064950, Train Acc: 0.900000 | Val Loss: 0.108023, Val Acc: 0.804124\n",
      "Epoch 30833 - Train Loss: 0.064948, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30834 - Train Loss: 0.064947, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30835 - Train Loss: 0.064946, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30836 - Train Loss: 0.064945, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30837 - Train Loss: 0.064944, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30838 - Train Loss: 0.064943, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30839 - Train Loss: 0.064942, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30840 - Train Loss: 0.064941, Train Acc: 0.900000 | Val Loss: 0.108024, Val Acc: 0.804124\n",
      "Epoch 30841 - Train Loss: 0.064940, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30842 - Train Loss: 0.064939, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30843 - Train Loss: 0.064938, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30844 - Train Loss: 0.064937, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30845 - Train Loss: 0.064936, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30846 - Train Loss: 0.064935, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30847 - Train Loss: 0.064934, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30848 - Train Loss: 0.064933, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30849 - Train Loss: 0.064932, Train Acc: 0.900000 | Val Loss: 0.108025, Val Acc: 0.804124\n",
      "Epoch 30850 - Train Loss: 0.064931, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30851 - Train Loss: 0.064930, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30852 - Train Loss: 0.064929, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30853 - Train Loss: 0.064928, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30854 - Train Loss: 0.064927, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30855 - Train Loss: 0.064926, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30856 - Train Loss: 0.064924, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30857 - Train Loss: 0.064923, Train Acc: 0.900000 | Val Loss: 0.108026, Val Acc: 0.804124\n",
      "Epoch 30858 - Train Loss: 0.064922, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30859 - Train Loss: 0.064921, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30860 - Train Loss: 0.064920, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30861 - Train Loss: 0.064919, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30862 - Train Loss: 0.064918, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30863 - Train Loss: 0.064917, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30864 - Train Loss: 0.064916, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30865 - Train Loss: 0.064915, Train Acc: 0.900000 | Val Loss: 0.108027, Val Acc: 0.804124\n",
      "Epoch 30866 - Train Loss: 0.064914, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30867 - Train Loss: 0.064913, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30868 - Train Loss: 0.064912, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30869 - Train Loss: 0.064911, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30870 - Train Loss: 0.064910, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30871 - Train Loss: 0.064909, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30872 - Train Loss: 0.064908, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30873 - Train Loss: 0.064907, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30874 - Train Loss: 0.064906, Train Acc: 0.900000 | Val Loss: 0.108028, Val Acc: 0.804124\n",
      "Epoch 30875 - Train Loss: 0.064905, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30876 - Train Loss: 0.064904, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30877 - Train Loss: 0.064903, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30878 - Train Loss: 0.064902, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30879 - Train Loss: 0.064901, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30880 - Train Loss: 0.064899, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30881 - Train Loss: 0.064898, Train Acc: 0.900000 | Val Loss: 0.108029, Val Acc: 0.804124\n",
      "Epoch 30882 - Train Loss: 0.064897, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30883 - Train Loss: 0.064896, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30884 - Train Loss: 0.064895, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30885 - Train Loss: 0.064894, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30886 - Train Loss: 0.064893, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30887 - Train Loss: 0.064892, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30888 - Train Loss: 0.064891, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30889 - Train Loss: 0.064890, Train Acc: 0.900000 | Val Loss: 0.108030, Val Acc: 0.804124\n",
      "Epoch 30890 - Train Loss: 0.064889, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30891 - Train Loss: 0.064888, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30892 - Train Loss: 0.064887, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30893 - Train Loss: 0.064886, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30894 - Train Loss: 0.064885, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30895 - Train Loss: 0.064884, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30896 - Train Loss: 0.064883, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30897 - Train Loss: 0.064882, Train Acc: 0.900000 | Val Loss: 0.108031, Val Acc: 0.804124\n",
      "Epoch 30898 - Train Loss: 0.064881, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30899 - Train Loss: 0.064880, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30900 - Train Loss: 0.064879, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30901 - Train Loss: 0.064878, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30902 - Train Loss: 0.064877, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30903 - Train Loss: 0.064876, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30904 - Train Loss: 0.064875, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30905 - Train Loss: 0.064873, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30906 - Train Loss: 0.064872, Train Acc: 0.900000 | Val Loss: 0.108032, Val Acc: 0.804124\n",
      "Epoch 30907 - Train Loss: 0.064871, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30908 - Train Loss: 0.064870, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30909 - Train Loss: 0.064869, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30910 - Train Loss: 0.064868, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30911 - Train Loss: 0.064867, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30912 - Train Loss: 0.064866, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30913 - Train Loss: 0.064865, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30914 - Train Loss: 0.064864, Train Acc: 0.900000 | Val Loss: 0.108033, Val Acc: 0.804124\n",
      "Epoch 30915 - Train Loss: 0.064863, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30916 - Train Loss: 0.064862, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30917 - Train Loss: 0.064861, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30918 - Train Loss: 0.064860, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30919 - Train Loss: 0.064859, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30920 - Train Loss: 0.064858, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30921 - Train Loss: 0.064857, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30922 - Train Loss: 0.064856, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30923 - Train Loss: 0.064855, Train Acc: 0.900000 | Val Loss: 0.108034, Val Acc: 0.804124\n",
      "Epoch 30924 - Train Loss: 0.064854, Train Acc: 0.900000 | Val Loss: 0.108035, Val Acc: 0.804124\n",
      "Epoch 30925 - Train Loss: 0.064853, Train Acc: 0.900000 | Val Loss: 0.108035, Val Acc: 0.804124\n",
      "Epoch 30926 - Train Loss: 0.064852, Train Acc: 0.900000 | Val Loss: 0.108035, Val Acc: 0.804124\n",
      "Epoch 30927 - Train Loss: 0.064851, Train Acc: 0.900000 | Val Loss: 0.108035, Val Acc: 0.804124\n",
      "Epoch 30928 - Train Loss: 0.064850, Train Acc: 0.900000 | Val Loss: 0.108035, Val Acc: 0.804124\n",
      "Epoch 30929 - Train Loss: 0.064849, Train Acc: 0.900000 | Val Loss: 0.108035, Val Acc: 0.804124\n",
      "Epoch 30930 - Train Loss: 0.064847, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30931 - Train Loss: 0.064846, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30932 - Train Loss: 0.064845, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30933 - Train Loss: 0.064844, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30934 - Train Loss: 0.064843, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30935 - Train Loss: 0.064842, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30936 - Train Loss: 0.064841, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30937 - Train Loss: 0.064840, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30938 - Train Loss: 0.064839, Train Acc: 0.900000 | Val Loss: 0.108036, Val Acc: 0.804124\n",
      "Epoch 30939 - Train Loss: 0.064838, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30940 - Train Loss: 0.064837, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30941 - Train Loss: 0.064836, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30942 - Train Loss: 0.064835, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30943 - Train Loss: 0.064834, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30944 - Train Loss: 0.064833, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30945 - Train Loss: 0.064832, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30946 - Train Loss: 0.064831, Train Acc: 0.900000 | Val Loss: 0.108037, Val Acc: 0.804124\n",
      "Epoch 30947 - Train Loss: 0.064830, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30948 - Train Loss: 0.064829, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30949 - Train Loss: 0.064828, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30950 - Train Loss: 0.064827, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30951 - Train Loss: 0.064826, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30952 - Train Loss: 0.064825, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30953 - Train Loss: 0.064824, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30954 - Train Loss: 0.064823, Train Acc: 0.900000 | Val Loss: 0.108038, Val Acc: 0.804124\n",
      "Epoch 30955 - Train Loss: 0.064822, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30956 - Train Loss: 0.064820, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30957 - Train Loss: 0.064819, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30958 - Train Loss: 0.064818, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30959 - Train Loss: 0.064817, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30960 - Train Loss: 0.064816, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30961 - Train Loss: 0.064815, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30962 - Train Loss: 0.064814, Train Acc: 0.900000 | Val Loss: 0.108039, Val Acc: 0.804124\n",
      "Epoch 30963 - Train Loss: 0.064813, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30964 - Train Loss: 0.064812, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30965 - Train Loss: 0.064811, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30966 - Train Loss: 0.064810, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30967 - Train Loss: 0.064809, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30968 - Train Loss: 0.064808, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30969 - Train Loss: 0.064807, Train Acc: 0.900000 | Val Loss: 0.108040, Val Acc: 0.804124\n",
      "Epoch 30970 - Train Loss: 0.064806, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30971 - Train Loss: 0.064805, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30972 - Train Loss: 0.064804, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30973 - Train Loss: 0.064803, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30974 - Train Loss: 0.064802, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30975 - Train Loss: 0.064801, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30976 - Train Loss: 0.064800, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30977 - Train Loss: 0.064799, Train Acc: 0.900000 | Val Loss: 0.108041, Val Acc: 0.804124\n",
      "Epoch 30978 - Train Loss: 0.064798, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30979 - Train Loss: 0.064797, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30980 - Train Loss: 0.064796, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30981 - Train Loss: 0.064795, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30982 - Train Loss: 0.064794, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30983 - Train Loss: 0.064792, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30984 - Train Loss: 0.064791, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30985 - Train Loss: 0.064790, Train Acc: 0.900000 | Val Loss: 0.108042, Val Acc: 0.804124\n",
      "Epoch 30986 - Train Loss: 0.064789, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30987 - Train Loss: 0.064788, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30988 - Train Loss: 0.064787, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30989 - Train Loss: 0.064786, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30990 - Train Loss: 0.064785, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30991 - Train Loss: 0.064784, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30992 - Train Loss: 0.064783, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30993 - Train Loss: 0.064782, Train Acc: 0.900000 | Val Loss: 0.108043, Val Acc: 0.804124\n",
      "Epoch 30994 - Train Loss: 0.064781, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 30995 - Train Loss: 0.064780, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 30996 - Train Loss: 0.064779, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 30997 - Train Loss: 0.064778, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 30998 - Train Loss: 0.064777, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 30999 - Train Loss: 0.064776, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 31000 - Train Loss: 0.064775, Train Acc: 0.900000 | Val Loss: 0.108044, Val Acc: 0.804124\n",
      "Epoch 31001 - Train Loss: 0.064774, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31002 - Train Loss: 0.064773, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31003 - Train Loss: 0.064772, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31004 - Train Loss: 0.064771, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31005 - Train Loss: 0.064770, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31006 - Train Loss: 0.064769, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31007 - Train Loss: 0.064768, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31008 - Train Loss: 0.064767, Train Acc: 0.900000 | Val Loss: 0.108045, Val Acc: 0.804124\n",
      "Epoch 31009 - Train Loss: 0.064766, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31010 - Train Loss: 0.064765, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31011 - Train Loss: 0.064763, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31012 - Train Loss: 0.064762, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31013 - Train Loss: 0.064761, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31014 - Train Loss: 0.064760, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31015 - Train Loss: 0.064759, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31016 - Train Loss: 0.064758, Train Acc: 0.900000 | Val Loss: 0.108046, Val Acc: 0.804124\n",
      "Epoch 31017 - Train Loss: 0.064757, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31018 - Train Loss: 0.064756, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31019 - Train Loss: 0.064755, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31020 - Train Loss: 0.064754, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31021 - Train Loss: 0.064753, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31022 - Train Loss: 0.064752, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31023 - Train Loss: 0.064751, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31024 - Train Loss: 0.064750, Train Acc: 0.900000 | Val Loss: 0.108047, Val Acc: 0.804124\n",
      "Epoch 31025 - Train Loss: 0.064749, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31026 - Train Loss: 0.064748, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31027 - Train Loss: 0.064747, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31028 - Train Loss: 0.064746, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31029 - Train Loss: 0.064745, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31030 - Train Loss: 0.064744, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31031 - Train Loss: 0.064743, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31032 - Train Loss: 0.064742, Train Acc: 0.900000 | Val Loss: 0.108048, Val Acc: 0.804124\n",
      "Epoch 31033 - Train Loss: 0.064741, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31034 - Train Loss: 0.064740, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31035 - Train Loss: 0.064739, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31036 - Train Loss: 0.064738, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31037 - Train Loss: 0.064737, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31038 - Train Loss: 0.064736, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31039 - Train Loss: 0.064735, Train Acc: 0.900000 | Val Loss: 0.108049, Val Acc: 0.804124\n",
      "Epoch 31040 - Train Loss: 0.064733, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31041 - Train Loss: 0.064732, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31042 - Train Loss: 0.064731, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31043 - Train Loss: 0.064730, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31044 - Train Loss: 0.064729, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31045 - Train Loss: 0.064728, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31046 - Train Loss: 0.064727, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31047 - Train Loss: 0.064726, Train Acc: 0.900000 | Val Loss: 0.108050, Val Acc: 0.804124\n",
      "Epoch 31048 - Train Loss: 0.064725, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31049 - Train Loss: 0.064724, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31050 - Train Loss: 0.064723, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31051 - Train Loss: 0.064722, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31052 - Train Loss: 0.064721, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31053 - Train Loss: 0.064720, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31054 - Train Loss: 0.064719, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31055 - Train Loss: 0.064718, Train Acc: 0.900000 | Val Loss: 0.108051, Val Acc: 0.804124\n",
      "Epoch 31056 - Train Loss: 0.064717, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31057 - Train Loss: 0.064716, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31058 - Train Loss: 0.064715, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31059 - Train Loss: 0.064714, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31060 - Train Loss: 0.064713, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31061 - Train Loss: 0.064712, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31062 - Train Loss: 0.064711, Train Acc: 0.900000 | Val Loss: 0.108052, Val Acc: 0.804124\n",
      "Epoch 31063 - Train Loss: 0.064710, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31064 - Train Loss: 0.064709, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31065 - Train Loss: 0.064708, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31066 - Train Loss: 0.064707, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31067 - Train Loss: 0.064706, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31068 - Train Loss: 0.064705, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31069 - Train Loss: 0.064704, Train Acc: 0.900000 | Val Loss: 0.108053, Val Acc: 0.804124\n",
      "Epoch 31070 - Train Loss: 0.064702, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31071 - Train Loss: 0.064701, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31072 - Train Loss: 0.064700, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31073 - Train Loss: 0.064699, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31074 - Train Loss: 0.064698, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31075 - Train Loss: 0.064697, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31076 - Train Loss: 0.064696, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31077 - Train Loss: 0.064695, Train Acc: 0.900000 | Val Loss: 0.108054, Val Acc: 0.804124\n",
      "Epoch 31078 - Train Loss: 0.064694, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31079 - Train Loss: 0.064693, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31080 - Train Loss: 0.064692, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31081 - Train Loss: 0.064691, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31082 - Train Loss: 0.064690, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31083 - Train Loss: 0.064689, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31084 - Train Loss: 0.064688, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31085 - Train Loss: 0.064687, Train Acc: 0.900000 | Val Loss: 0.108055, Val Acc: 0.804124\n",
      "Epoch 31086 - Train Loss: 0.064686, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31087 - Train Loss: 0.064685, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31088 - Train Loss: 0.064684, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31089 - Train Loss: 0.064683, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31090 - Train Loss: 0.064682, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31091 - Train Loss: 0.064681, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31092 - Train Loss: 0.064680, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31093 - Train Loss: 0.064679, Train Acc: 0.900000 | Val Loss: 0.108056, Val Acc: 0.804124\n",
      "Epoch 31094 - Train Loss: 0.064678, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31095 - Train Loss: 0.064677, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31096 - Train Loss: 0.064676, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31097 - Train Loss: 0.064675, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31098 - Train Loss: 0.064674, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31099 - Train Loss: 0.064673, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31100 - Train Loss: 0.064672, Train Acc: 0.900000 | Val Loss: 0.108057, Val Acc: 0.804124\n",
      "Epoch 31101 - Train Loss: 0.064671, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31102 - Train Loss: 0.064669, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31103 - Train Loss: 0.064668, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31104 - Train Loss: 0.064667, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31105 - Train Loss: 0.064666, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31106 - Train Loss: 0.064665, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31107 - Train Loss: 0.064664, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31108 - Train Loss: 0.064663, Train Acc: 0.900000 | Val Loss: 0.108058, Val Acc: 0.804124\n",
      "Epoch 31109 - Train Loss: 0.064662, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31110 - Train Loss: 0.064661, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31111 - Train Loss: 0.064660, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31112 - Train Loss: 0.064659, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31113 - Train Loss: 0.064658, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31114 - Train Loss: 0.064657, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31115 - Train Loss: 0.064656, Train Acc: 0.900000 | Val Loss: 0.108059, Val Acc: 0.804124\n",
      "Epoch 31116 - Train Loss: 0.064655, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31117 - Train Loss: 0.064654, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31118 - Train Loss: 0.064653, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31119 - Train Loss: 0.064652, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31120 - Train Loss: 0.064651, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31121 - Train Loss: 0.064650, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31122 - Train Loss: 0.064649, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31123 - Train Loss: 0.064648, Train Acc: 0.900000 | Val Loss: 0.108060, Val Acc: 0.804124\n",
      "Epoch 31124 - Train Loss: 0.064647, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31125 - Train Loss: 0.064646, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31126 - Train Loss: 0.064645, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31127 - Train Loss: 0.064644, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31128 - Train Loss: 0.064643, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31129 - Train Loss: 0.064642, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31130 - Train Loss: 0.064641, Train Acc: 0.900000 | Val Loss: 0.108061, Val Acc: 0.804124\n",
      "Epoch 31131 - Train Loss: 0.064640, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31132 - Train Loss: 0.064639, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31133 - Train Loss: 0.064638, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31134 - Train Loss: 0.064637, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31135 - Train Loss: 0.064636, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31136 - Train Loss: 0.064634, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31137 - Train Loss: 0.064633, Train Acc: 0.900000 | Val Loss: 0.108062, Val Acc: 0.804124\n",
      "Epoch 31138 - Train Loss: 0.064632, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31139 - Train Loss: 0.064631, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31140 - Train Loss: 0.064630, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31141 - Train Loss: 0.064629, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31142 - Train Loss: 0.064628, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31143 - Train Loss: 0.064627, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31144 - Train Loss: 0.064626, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31145 - Train Loss: 0.064625, Train Acc: 0.900000 | Val Loss: 0.108063, Val Acc: 0.804124\n",
      "Epoch 31146 - Train Loss: 0.064624, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31147 - Train Loss: 0.064623, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31148 - Train Loss: 0.064622, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31149 - Train Loss: 0.064621, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31150 - Train Loss: 0.064620, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31151 - Train Loss: 0.064619, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31152 - Train Loss: 0.064618, Train Acc: 0.900000 | Val Loss: 0.108064, Val Acc: 0.804124\n",
      "Epoch 31153 - Train Loss: 0.064617, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31154 - Train Loss: 0.064616, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31155 - Train Loss: 0.064615, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31156 - Train Loss: 0.064614, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31157 - Train Loss: 0.064613, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31158 - Train Loss: 0.064612, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31159 - Train Loss: 0.064611, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31160 - Train Loss: 0.064610, Train Acc: 0.900000 | Val Loss: 0.108065, Val Acc: 0.804124\n",
      "Epoch 31161 - Train Loss: 0.064609, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31162 - Train Loss: 0.064608, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31163 - Train Loss: 0.064607, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31164 - Train Loss: 0.064606, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31165 - Train Loss: 0.064605, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31166 - Train Loss: 0.064604, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31167 - Train Loss: 0.064603, Train Acc: 0.900000 | Val Loss: 0.108066, Val Acc: 0.804124\n",
      "Epoch 31168 - Train Loss: 0.064602, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31169 - Train Loss: 0.064601, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31170 - Train Loss: 0.064600, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31171 - Train Loss: 0.064599, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31172 - Train Loss: 0.064597, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31173 - Train Loss: 0.064596, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31174 - Train Loss: 0.064595, Train Acc: 0.900000 | Val Loss: 0.108067, Val Acc: 0.804124\n",
      "Epoch 31175 - Train Loss: 0.064594, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31176 - Train Loss: 0.064593, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31177 - Train Loss: 0.064592, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31178 - Train Loss: 0.064591, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31179 - Train Loss: 0.064590, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31180 - Train Loss: 0.064589, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31181 - Train Loss: 0.064588, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31182 - Train Loss: 0.064587, Train Acc: 0.900000 | Val Loss: 0.108068, Val Acc: 0.804124\n",
      "Epoch 31183 - Train Loss: 0.064586, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31184 - Train Loss: 0.064585, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31185 - Train Loss: 0.064584, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31186 - Train Loss: 0.064583, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31187 - Train Loss: 0.064582, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31188 - Train Loss: 0.064581, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31189 - Train Loss: 0.064580, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31190 - Train Loss: 0.064579, Train Acc: 0.900000 | Val Loss: 0.108069, Val Acc: 0.804124\n",
      "Epoch 31191 - Train Loss: 0.064578, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31192 - Train Loss: 0.064577, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31193 - Train Loss: 0.064576, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31194 - Train Loss: 0.064575, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31195 - Train Loss: 0.064574, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31196 - Train Loss: 0.064573, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31197 - Train Loss: 0.064572, Train Acc: 0.900000 | Val Loss: 0.108070, Val Acc: 0.804124\n",
      "Epoch 31198 - Train Loss: 0.064571, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31199 - Train Loss: 0.064570, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31200 - Train Loss: 0.064569, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31201 - Train Loss: 0.064568, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31202 - Train Loss: 0.064567, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31203 - Train Loss: 0.064566, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31204 - Train Loss: 0.064565, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31205 - Train Loss: 0.064564, Train Acc: 0.900000 | Val Loss: 0.108071, Val Acc: 0.804124\n",
      "Epoch 31206 - Train Loss: 0.064563, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31207 - Train Loss: 0.064562, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31208 - Train Loss: 0.064561, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31209 - Train Loss: 0.064560, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31210 - Train Loss: 0.064559, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31211 - Train Loss: 0.064557, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31212 - Train Loss: 0.064556, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31213 - Train Loss: 0.064555, Train Acc: 0.900000 | Val Loss: 0.108072, Val Acc: 0.804124\n",
      "Epoch 31214 - Train Loss: 0.064554, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31215 - Train Loss: 0.064553, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31216 - Train Loss: 0.064552, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31217 - Train Loss: 0.064551, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31218 - Train Loss: 0.064550, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31219 - Train Loss: 0.064549, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31220 - Train Loss: 0.064548, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31221 - Train Loss: 0.064547, Train Acc: 0.900000 | Val Loss: 0.108073, Val Acc: 0.804124\n",
      "Epoch 31222 - Train Loss: 0.064546, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31223 - Train Loss: 0.064545, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31224 - Train Loss: 0.064544, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31225 - Train Loss: 0.064543, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31226 - Train Loss: 0.064542, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31227 - Train Loss: 0.064541, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31228 - Train Loss: 0.064540, Train Acc: 0.900000 | Val Loss: 0.108074, Val Acc: 0.804124\n",
      "Epoch 31229 - Train Loss: 0.064539, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31230 - Train Loss: 0.064538, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31231 - Train Loss: 0.064537, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31232 - Train Loss: 0.064536, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31233 - Train Loss: 0.064535, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31234 - Train Loss: 0.064534, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31235 - Train Loss: 0.064533, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31236 - Train Loss: 0.064532, Train Acc: 0.900000 | Val Loss: 0.108075, Val Acc: 0.804124\n",
      "Epoch 31237 - Train Loss: 0.064531, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31238 - Train Loss: 0.064530, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31239 - Train Loss: 0.064529, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31240 - Train Loss: 0.064528, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31241 - Train Loss: 0.064527, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31242 - Train Loss: 0.064526, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31243 - Train Loss: 0.064525, Train Acc: 0.900000 | Val Loss: 0.108076, Val Acc: 0.804124\n",
      "Epoch 31244 - Train Loss: 0.064524, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31245 - Train Loss: 0.064523, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31246 - Train Loss: 0.064522, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31247 - Train Loss: 0.064521, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31248 - Train Loss: 0.064520, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31249 - Train Loss: 0.064519, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31250 - Train Loss: 0.064518, Train Acc: 0.900000 | Val Loss: 0.108077, Val Acc: 0.804124\n",
      "Epoch 31251 - Train Loss: 0.064517, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31252 - Train Loss: 0.064516, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31253 - Train Loss: 0.064514, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31254 - Train Loss: 0.064513, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31255 - Train Loss: 0.064512, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31256 - Train Loss: 0.064511, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31257 - Train Loss: 0.064510, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31258 - Train Loss: 0.064509, Train Acc: 0.900000 | Val Loss: 0.108078, Val Acc: 0.804124\n",
      "Epoch 31259 - Train Loss: 0.064508, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31260 - Train Loss: 0.064507, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31261 - Train Loss: 0.064506, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31262 - Train Loss: 0.064505, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31263 - Train Loss: 0.064504, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31264 - Train Loss: 0.064503, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31265 - Train Loss: 0.064502, Train Acc: 0.900000 | Val Loss: 0.108079, Val Acc: 0.804124\n",
      "Epoch 31266 - Train Loss: 0.064501, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31267 - Train Loss: 0.064500, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31268 - Train Loss: 0.064499, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31269 - Train Loss: 0.064498, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31270 - Train Loss: 0.064497, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31271 - Train Loss: 0.064496, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31272 - Train Loss: 0.064495, Train Acc: 0.900000 | Val Loss: 0.108080, Val Acc: 0.804124\n",
      "Epoch 31273 - Train Loss: 0.064494, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31274 - Train Loss: 0.064493, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31275 - Train Loss: 0.064492, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31276 - Train Loss: 0.064491, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31277 - Train Loss: 0.064490, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31278 - Train Loss: 0.064489, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31279 - Train Loss: 0.064488, Train Acc: 0.900000 | Val Loss: 0.108081, Val Acc: 0.804124\n",
      "Epoch 31280 - Train Loss: 0.064487, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31281 - Train Loss: 0.064486, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31282 - Train Loss: 0.064485, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31283 - Train Loss: 0.064484, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31284 - Train Loss: 0.064483, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31285 - Train Loss: 0.064482, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31286 - Train Loss: 0.064481, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31287 - Train Loss: 0.064480, Train Acc: 0.900000 | Val Loss: 0.108082, Val Acc: 0.804124\n",
      "Epoch 31288 - Train Loss: 0.064479, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31289 - Train Loss: 0.064478, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31290 - Train Loss: 0.064477, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31291 - Train Loss: 0.064476, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31292 - Train Loss: 0.064475, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31293 - Train Loss: 0.064474, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31294 - Train Loss: 0.064473, Train Acc: 0.900000 | Val Loss: 0.108083, Val Acc: 0.804124\n",
      "Epoch 31295 - Train Loss: 0.064472, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31296 - Train Loss: 0.064471, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31297 - Train Loss: 0.064470, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31298 - Train Loss: 0.064469, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31299 - Train Loss: 0.064468, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31300 - Train Loss: 0.064466, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31301 - Train Loss: 0.064465, Train Acc: 0.900000 | Val Loss: 0.108084, Val Acc: 0.804124\n",
      "Epoch 31302 - Train Loss: 0.064464, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31303 - Train Loss: 0.064463, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31304 - Train Loss: 0.064462, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31305 - Train Loss: 0.064461, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31306 - Train Loss: 0.064460, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31307 - Train Loss: 0.064459, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31308 - Train Loss: 0.064458, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31309 - Train Loss: 0.064457, Train Acc: 0.900000 | Val Loss: 0.108085, Val Acc: 0.804124\n",
      "Epoch 31310 - Train Loss: 0.064456, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31311 - Train Loss: 0.064455, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31312 - Train Loss: 0.064454, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31313 - Train Loss: 0.064453, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31314 - Train Loss: 0.064452, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31315 - Train Loss: 0.064451, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31316 - Train Loss: 0.064450, Train Acc: 0.900000 | Val Loss: 0.108086, Val Acc: 0.804124\n",
      "Epoch 31317 - Train Loss: 0.064449, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31318 - Train Loss: 0.064448, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31319 - Train Loss: 0.064447, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31320 - Train Loss: 0.064446, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31321 - Train Loss: 0.064445, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31322 - Train Loss: 0.064444, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31323 - Train Loss: 0.064443, Train Acc: 0.900000 | Val Loss: 0.108087, Val Acc: 0.804124\n",
      "Epoch 31324 - Train Loss: 0.064442, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31325 - Train Loss: 0.064441, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31326 - Train Loss: 0.064440, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31327 - Train Loss: 0.064439, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31328 - Train Loss: 0.064438, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31329 - Train Loss: 0.064437, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31330 - Train Loss: 0.064436, Train Acc: 0.900000 | Val Loss: 0.108088, Val Acc: 0.804124\n",
      "Epoch 31331 - Train Loss: 0.064435, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31332 - Train Loss: 0.064434, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31333 - Train Loss: 0.064433, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31334 - Train Loss: 0.064432, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31335 - Train Loss: 0.064431, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31336 - Train Loss: 0.064430, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31337 - Train Loss: 0.064429, Train Acc: 0.900000 | Val Loss: 0.108089, Val Acc: 0.804124\n",
      "Epoch 31338 - Train Loss: 0.064428, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31339 - Train Loss: 0.064427, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31340 - Train Loss: 0.064426, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31341 - Train Loss: 0.064425, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31342 - Train Loss: 0.064424, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31343 - Train Loss: 0.064423, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31344 - Train Loss: 0.064422, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31345 - Train Loss: 0.064421, Train Acc: 0.900000 | Val Loss: 0.108090, Val Acc: 0.804124\n",
      "Epoch 31346 - Train Loss: 0.064420, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31347 - Train Loss: 0.064419, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31348 - Train Loss: 0.064418, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31349 - Train Loss: 0.064417, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31350 - Train Loss: 0.064416, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31351 - Train Loss: 0.064415, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31352 - Train Loss: 0.064413, Train Acc: 0.900000 | Val Loss: 0.108091, Val Acc: 0.804124\n",
      "Epoch 31353 - Train Loss: 0.064412, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31354 - Train Loss: 0.064411, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31355 - Train Loss: 0.064410, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31356 - Train Loss: 0.064409, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31357 - Train Loss: 0.064408, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31358 - Train Loss: 0.064407, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31359 - Train Loss: 0.064406, Train Acc: 0.900000 | Val Loss: 0.108092, Val Acc: 0.804124\n",
      "Epoch 31360 - Train Loss: 0.064405, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31361 - Train Loss: 0.064404, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31362 - Train Loss: 0.064403, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31363 - Train Loss: 0.064402, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31364 - Train Loss: 0.064401, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31365 - Train Loss: 0.064400, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31366 - Train Loss: 0.064399, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31367 - Train Loss: 0.064398, Train Acc: 0.900000 | Val Loss: 0.108093, Val Acc: 0.804124\n",
      "Epoch 31368 - Train Loss: 0.064397, Train Acc: 0.900000 | Val Loss: 0.108094, Val Acc: 0.804124\n",
      "Epoch 31369 - Train Loss: 0.064396, Train Acc: 0.900000 | Val Loss: 0.108094, Val Acc: 0.804124\n",
      "Epoch 31370 - Train Loss: 0.064395, Train Acc: 0.900000 | Val Loss: 0.108094, Val Acc: 0.804124\n",
      "Epoch 31371 - Train Loss: 0.064394, Train Acc: 0.900000 | Val Loss: 0.108094, Val Acc: 0.804124\n",
      "Epoch 31372 - Train Loss: 0.064393, Train Acc: 0.900000 | Val Loss: 0.108094, Val Acc: 0.804124\n",
      "Epoch 31373 - Train Loss: 0.064392, Train Acc: 0.900000 | Val Loss: 0.108094, Val Acc: 0.804124\n",
      "Epoch 31374 - Train Loss: 0.064391, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31375 - Train Loss: 0.064390, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31376 - Train Loss: 0.064389, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31377 - Train Loss: 0.064388, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31378 - Train Loss: 0.064387, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31379 - Train Loss: 0.064386, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31380 - Train Loss: 0.064385, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31381 - Train Loss: 0.064384, Train Acc: 0.900000 | Val Loss: 0.108095, Val Acc: 0.804124\n",
      "Epoch 31382 - Train Loss: 0.064383, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31383 - Train Loss: 0.064382, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31384 - Train Loss: 0.064381, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31385 - Train Loss: 0.064380, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31386 - Train Loss: 0.064379, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31387 - Train Loss: 0.064378, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31388 - Train Loss: 0.064377, Train Acc: 0.900000 | Val Loss: 0.108096, Val Acc: 0.804124\n",
      "Epoch 31389 - Train Loss: 0.064376, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31390 - Train Loss: 0.064375, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31391 - Train Loss: 0.064374, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31392 - Train Loss: 0.064373, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31393 - Train Loss: 0.064372, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31394 - Train Loss: 0.064371, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31395 - Train Loss: 0.064370, Train Acc: 0.900000 | Val Loss: 0.108097, Val Acc: 0.804124\n",
      "Epoch 31396 - Train Loss: 0.064369, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31397 - Train Loss: 0.064368, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31398 - Train Loss: 0.064367, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31399 - Train Loss: 0.064366, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31400 - Train Loss: 0.064365, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31401 - Train Loss: 0.064364, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31402 - Train Loss: 0.064363, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31403 - Train Loss: 0.064362, Train Acc: 0.900000 | Val Loss: 0.108098, Val Acc: 0.804124\n",
      "Epoch 31404 - Train Loss: 0.064361, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31405 - Train Loss: 0.064360, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31406 - Train Loss: 0.064359, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31407 - Train Loss: 0.064358, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31408 - Train Loss: 0.064357, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31409 - Train Loss: 0.064356, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31410 - Train Loss: 0.064355, Train Acc: 0.900000 | Val Loss: 0.108099, Val Acc: 0.804124\n",
      "Epoch 31411 - Train Loss: 0.064354, Train Acc: 0.900000 | Val Loss: 0.108100, Val Acc: 0.804124\n",
      "Epoch 31412 - Train Loss: 0.064353, Train Acc: 0.900000 | Val Loss: 0.108100, Val Acc: 0.804124\n",
      "Epoch 31413 - Train Loss: 0.064352, Train Acc: 0.900000 | Val Loss: 0.108100, Val Acc: 0.804124\n",
      "Epoch 31414 - Train Loss: 0.064351, Train Acc: 0.900000 | Val Loss: 0.108100, Val Acc: 0.804124\n",
      "Epoch 31415 - Train Loss: 0.064349, Train Acc: 0.900000 | Val Loss: 0.108100, Val Acc: 0.804124\n",
      "Epoch 31416 - Train Loss: 0.064348, Train Acc: 0.900000 | Val Loss: 0.108100, Val Acc: 0.804124\n",
      "Epoch 31417 - Train Loss: 0.064347, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31418 - Train Loss: 0.064346, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31419 - Train Loss: 0.064345, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31420 - Train Loss: 0.064344, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31421 - Train Loss: 0.064343, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31422 - Train Loss: 0.064342, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31423 - Train Loss: 0.064341, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31424 - Train Loss: 0.064340, Train Acc: 0.900000 | Val Loss: 0.108101, Val Acc: 0.804124\n",
      "Epoch 31425 - Train Loss: 0.064339, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31426 - Train Loss: 0.064338, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31427 - Train Loss: 0.064337, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31428 - Train Loss: 0.064336, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31429 - Train Loss: 0.064335, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31430 - Train Loss: 0.064334, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31431 - Train Loss: 0.064333, Train Acc: 0.900000 | Val Loss: 0.108102, Val Acc: 0.804124\n",
      "Epoch 31432 - Train Loss: 0.064332, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31433 - Train Loss: 0.064331, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31434 - Train Loss: 0.064330, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31435 - Train Loss: 0.064329, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31436 - Train Loss: 0.064328, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31437 - Train Loss: 0.064327, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31438 - Train Loss: 0.064326, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31439 - Train Loss: 0.064325, Train Acc: 0.900000 | Val Loss: 0.108103, Val Acc: 0.804124\n",
      "Epoch 31440 - Train Loss: 0.064324, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31441 - Train Loss: 0.064323, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31442 - Train Loss: 0.064322, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31443 - Train Loss: 0.064321, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31444 - Train Loss: 0.064320, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31445 - Train Loss: 0.064319, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31446 - Train Loss: 0.064318, Train Acc: 0.900000 | Val Loss: 0.108104, Val Acc: 0.804124\n",
      "Epoch 31447 - Train Loss: 0.064317, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31448 - Train Loss: 0.064316, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31449 - Train Loss: 0.064315, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31450 - Train Loss: 0.064314, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31451 - Train Loss: 0.064313, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31452 - Train Loss: 0.064312, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31453 - Train Loss: 0.064311, Train Acc: 0.900000 | Val Loss: 0.108105, Val Acc: 0.804124\n",
      "Epoch 31454 - Train Loss: 0.064310, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31455 - Train Loss: 0.064309, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31456 - Train Loss: 0.064308, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31457 - Train Loss: 0.064307, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31458 - Train Loss: 0.064306, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31459 - Train Loss: 0.064305, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31460 - Train Loss: 0.064304, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31461 - Train Loss: 0.064303, Train Acc: 0.900000 | Val Loss: 0.108106, Val Acc: 0.804124\n",
      "Epoch 31462 - Train Loss: 0.064302, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31463 - Train Loss: 0.064301, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31464 - Train Loss: 0.064300, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31465 - Train Loss: 0.064299, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31466 - Train Loss: 0.064298, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31467 - Train Loss: 0.064297, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31468 - Train Loss: 0.064296, Train Acc: 0.900000 | Val Loss: 0.108107, Val Acc: 0.804124\n",
      "Epoch 31469 - Train Loss: 0.064295, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31470 - Train Loss: 0.064294, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31471 - Train Loss: 0.064293, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31472 - Train Loss: 0.064292, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31473 - Train Loss: 0.064291, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31474 - Train Loss: 0.064290, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31475 - Train Loss: 0.064289, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31476 - Train Loss: 0.064288, Train Acc: 0.900000 | Val Loss: 0.108108, Val Acc: 0.804124\n",
      "Epoch 31477 - Train Loss: 0.064287, Train Acc: 0.900000 | Val Loss: 0.108109, Val Acc: 0.804124\n",
      "Epoch 31478 - Train Loss: 0.064286, Train Acc: 0.900000 | Val Loss: 0.108109, Val Acc: 0.804124\n",
      "Epoch 31479 - Train Loss: 0.064285, Train Acc: 0.900000 | Val Loss: 0.108109, Val Acc: 0.804124\n",
      "Epoch 31480 - Train Loss: 0.064284, Train Acc: 0.900000 | Val Loss: 0.108109, Val Acc: 0.804124\n",
      "Epoch 31481 - Train Loss: 0.064283, Train Acc: 0.900000 | Val Loss: 0.108109, Val Acc: 0.804124\n",
      "Epoch 31482 - Train Loss: 0.064282, Train Acc: 0.900000 | Val Loss: 0.108109, Val Acc: 0.804124\n",
      "Epoch 31483 - Train Loss: 0.064281, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31484 - Train Loss: 0.064280, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31485 - Train Loss: 0.064279, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31486 - Train Loss: 0.064278, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31487 - Train Loss: 0.064277, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31488 - Train Loss: 0.064276, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31489 - Train Loss: 0.064275, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31490 - Train Loss: 0.064274, Train Acc: 0.900000 | Val Loss: 0.108110, Val Acc: 0.804124\n",
      "Epoch 31491 - Train Loss: 0.064273, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31492 - Train Loss: 0.064272, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31493 - Train Loss: 0.064271, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31494 - Train Loss: 0.064270, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31495 - Train Loss: 0.064269, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31496 - Train Loss: 0.064268, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31497 - Train Loss: 0.064267, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31498 - Train Loss: 0.064265, Train Acc: 0.900000 | Val Loss: 0.108111, Val Acc: 0.804124\n",
      "Epoch 31499 - Train Loss: 0.064264, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31500 - Train Loss: 0.064263, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31501 - Train Loss: 0.064262, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31502 - Train Loss: 0.064261, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31503 - Train Loss: 0.064260, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31504 - Train Loss: 0.064259, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31505 - Train Loss: 0.064258, Train Acc: 0.900000 | Val Loss: 0.108112, Val Acc: 0.804124\n",
      "Epoch 31506 - Train Loss: 0.064257, Train Acc: 0.900000 | Val Loss: 0.108113, Val Acc: 0.804124\n",
      "Epoch 31507 - Train Loss: 0.064256, Train Acc: 0.900000 | Val Loss: 0.108113, Val Acc: 0.804124\n",
      "Epoch 31508 - Train Loss: 0.064255, Train Acc: 0.900000 | Val Loss: 0.108113, Val Acc: 0.804124\n",
      "Epoch 31509 - Train Loss: 0.064254, Train Acc: 0.900000 | Val Loss: 0.108113, Val Acc: 0.804124\n",
      "Epoch 31510 - Train Loss: 0.064253, Train Acc: 0.900000 | Val Loss: 0.108113, Val Acc: 0.804124\n",
      "Epoch 31511 - Train Loss: 0.064252, Train Acc: 0.900000 | Val Loss: 0.108113, Val Acc: 0.804124\n",
      "Epoch 31512 - Train Loss: 0.064251, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31513 - Train Loss: 0.064250, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31514 - Train Loss: 0.064249, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31515 - Train Loss: 0.064248, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31516 - Train Loss: 0.064247, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31517 - Train Loss: 0.064246, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31518 - Train Loss: 0.064245, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31519 - Train Loss: 0.064244, Train Acc: 0.900000 | Val Loss: 0.108114, Val Acc: 0.804124\n",
      "Epoch 31520 - Train Loss: 0.064243, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31521 - Train Loss: 0.064242, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31522 - Train Loss: 0.064241, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31523 - Train Loss: 0.064240, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31524 - Train Loss: 0.064239, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31525 - Train Loss: 0.064238, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31526 - Train Loss: 0.064237, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31527 - Train Loss: 0.064236, Train Acc: 0.900000 | Val Loss: 0.108115, Val Acc: 0.804124\n",
      "Epoch 31528 - Train Loss: 0.064235, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31529 - Train Loss: 0.064234, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31530 - Train Loss: 0.064233, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31531 - Train Loss: 0.064232, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31532 - Train Loss: 0.064231, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31533 - Train Loss: 0.064230, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31534 - Train Loss: 0.064229, Train Acc: 0.900000 | Val Loss: 0.108116, Val Acc: 0.804124\n",
      "Epoch 31535 - Train Loss: 0.064228, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31536 - Train Loss: 0.064227, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31537 - Train Loss: 0.064226, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31538 - Train Loss: 0.064225, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31539 - Train Loss: 0.064224, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31540 - Train Loss: 0.064223, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31541 - Train Loss: 0.064222, Train Acc: 0.900000 | Val Loss: 0.108117, Val Acc: 0.804124\n",
      "Epoch 31542 - Train Loss: 0.064221, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31543 - Train Loss: 0.064220, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31544 - Train Loss: 0.064219, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31545 - Train Loss: 0.064218, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31546 - Train Loss: 0.064217, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31547 - Train Loss: 0.064216, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31548 - Train Loss: 0.064215, Train Acc: 0.900000 | Val Loss: 0.108118, Val Acc: 0.804124\n",
      "Epoch 31549 - Train Loss: 0.064214, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31550 - Train Loss: 0.064213, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31551 - Train Loss: 0.064212, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31552 - Train Loss: 0.064211, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31553 - Train Loss: 0.064210, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31554 - Train Loss: 0.064209, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31555 - Train Loss: 0.064208, Train Acc: 0.900000 | Val Loss: 0.108119, Val Acc: 0.804124\n",
      "Epoch 31556 - Train Loss: 0.064207, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31557 - Train Loss: 0.064206, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31558 - Train Loss: 0.064205, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31559 - Train Loss: 0.064204, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31560 - Train Loss: 0.064203, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31561 - Train Loss: 0.064202, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31562 - Train Loss: 0.064201, Train Acc: 0.900000 | Val Loss: 0.108120, Val Acc: 0.804124\n",
      "Epoch 31563 - Train Loss: 0.064200, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31564 - Train Loss: 0.064199, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31565 - Train Loss: 0.064198, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31566 - Train Loss: 0.064197, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31567 - Train Loss: 0.064196, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31568 - Train Loss: 0.064195, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31569 - Train Loss: 0.064194, Train Acc: 0.900000 | Val Loss: 0.108121, Val Acc: 0.804124\n",
      "Epoch 31570 - Train Loss: 0.064193, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31571 - Train Loss: 0.064192, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31572 - Train Loss: 0.064191, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31573 - Train Loss: 0.064190, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31574 - Train Loss: 0.064189, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31575 - Train Loss: 0.064188, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31576 - Train Loss: 0.064187, Train Acc: 0.900000 | Val Loss: 0.108122, Val Acc: 0.804124\n",
      "Epoch 31577 - Train Loss: 0.064186, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31578 - Train Loss: 0.064185, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31579 - Train Loss: 0.064184, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31580 - Train Loss: 0.064183, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31581 - Train Loss: 0.064182, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31582 - Train Loss: 0.064181, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31583 - Train Loss: 0.064180, Train Acc: 0.900000 | Val Loss: 0.108123, Val Acc: 0.804124\n",
      "Epoch 31584 - Train Loss: 0.064179, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31585 - Train Loss: 0.064178, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31586 - Train Loss: 0.064177, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31587 - Train Loss: 0.064176, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31588 - Train Loss: 0.064175, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31589 - Train Loss: 0.064174, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31590 - Train Loss: 0.064173, Train Acc: 0.900000 | Val Loss: 0.108124, Val Acc: 0.804124\n",
      "Epoch 31591 - Train Loss: 0.064172, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31592 - Train Loss: 0.064171, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31593 - Train Loss: 0.064170, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31594 - Train Loss: 0.064169, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31595 - Train Loss: 0.064168, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31596 - Train Loss: 0.064167, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31597 - Train Loss: 0.064166, Train Acc: 0.900000 | Val Loss: 0.108125, Val Acc: 0.804124\n",
      "Epoch 31598 - Train Loss: 0.064165, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31599 - Train Loss: 0.064164, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31600 - Train Loss: 0.064163, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31601 - Train Loss: 0.064162, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31602 - Train Loss: 0.064161, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31603 - Train Loss: 0.064160, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31604 - Train Loss: 0.064159, Train Acc: 0.900000 | Val Loss: 0.108126, Val Acc: 0.804124\n",
      "Epoch 31605 - Train Loss: 0.064158, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31606 - Train Loss: 0.064157, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31607 - Train Loss: 0.064156, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31608 - Train Loss: 0.064155, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31609 - Train Loss: 0.064154, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31610 - Train Loss: 0.064153, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31611 - Train Loss: 0.064152, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31612 - Train Loss: 0.064151, Train Acc: 0.900000 | Val Loss: 0.108127, Val Acc: 0.804124\n",
      "Epoch 31613 - Train Loss: 0.064150, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31614 - Train Loss: 0.064149, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31615 - Train Loss: 0.064148, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31616 - Train Loss: 0.064147, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31617 - Train Loss: 0.064146, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31618 - Train Loss: 0.064145, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31619 - Train Loss: 0.064144, Train Acc: 0.900000 | Val Loss: 0.108128, Val Acc: 0.804124\n",
      "Epoch 31620 - Train Loss: 0.064143, Train Acc: 0.900000 | Val Loss: 0.108129, Val Acc: 0.804124\n",
      "Epoch 31621 - Train Loss: 0.064142, Train Acc: 0.900000 | Val Loss: 0.108129, Val Acc: 0.804124\n",
      "Epoch 31622 - Train Loss: 0.064141, Train Acc: 0.900000 | Val Loss: 0.108129, Val Acc: 0.804124\n",
      "Epoch 31623 - Train Loss: 0.064140, Train Acc: 0.900000 | Val Loss: 0.108129, Val Acc: 0.804124\n",
      "Epoch 31624 - Train Loss: 0.064139, Train Acc: 0.900000 | Val Loss: 0.108129, Val Acc: 0.804124\n",
      "Epoch 31625 - Train Loss: 0.064138, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31626 - Train Loss: 0.064137, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31627 - Train Loss: 0.064136, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31628 - Train Loss: 0.064135, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31629 - Train Loss: 0.064134, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31630 - Train Loss: 0.064133, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31631 - Train Loss: 0.064132, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31632 - Train Loss: 0.064131, Train Acc: 0.900000 | Val Loss: 0.108130, Val Acc: 0.804124\n",
      "Epoch 31633 - Train Loss: 0.064130, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31634 - Train Loss: 0.064129, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31635 - Train Loss: 0.064128, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31636 - Train Loss: 0.064127, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31637 - Train Loss: 0.064126, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31638 - Train Loss: 0.064125, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31639 - Train Loss: 0.064124, Train Acc: 0.900000 | Val Loss: 0.108131, Val Acc: 0.804124\n",
      "Epoch 31640 - Train Loss: 0.064123, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31641 - Train Loss: 0.064122, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31642 - Train Loss: 0.064121, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31643 - Train Loss: 0.064120, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31644 - Train Loss: 0.064119, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31645 - Train Loss: 0.064118, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31646 - Train Loss: 0.064117, Train Acc: 0.900000 | Val Loss: 0.108132, Val Acc: 0.804124\n",
      "Epoch 31647 - Train Loss: 0.064116, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31648 - Train Loss: 0.064115, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31649 - Train Loss: 0.064114, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31650 - Train Loss: 0.064113, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31651 - Train Loss: 0.064112, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31652 - Train Loss: 0.064111, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31653 - Train Loss: 0.064110, Train Acc: 0.900000 | Val Loss: 0.108133, Val Acc: 0.804124\n",
      "Epoch 31654 - Train Loss: 0.064109, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31655 - Train Loss: 0.064108, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31656 - Train Loss: 0.064107, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31657 - Train Loss: 0.064106, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31658 - Train Loss: 0.064105, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31659 - Train Loss: 0.064104, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31660 - Train Loss: 0.064103, Train Acc: 0.900000 | Val Loss: 0.108134, Val Acc: 0.804124\n",
      "Epoch 31661 - Train Loss: 0.064102, Train Acc: 0.900000 | Val Loss: 0.108135, Val Acc: 0.804124\n",
      "Epoch 31662 - Train Loss: 0.064101, Train Acc: 0.900000 | Val Loss: 0.108135, Val Acc: 0.804124\n",
      "Epoch 31663 - Train Loss: 0.064100, Train Acc: 0.900000 | Val Loss: 0.108135, Val Acc: 0.804124\n",
      "Epoch 31664 - Train Loss: 0.064099, Train Acc: 0.900000 | Val Loss: 0.108135, Val Acc: 0.804124\n",
      "Epoch 31665 - Train Loss: 0.064098, Train Acc: 0.900000 | Val Loss: 0.108135, Val Acc: 0.804124\n",
      "Epoch 31666 - Train Loss: 0.064097, Train Acc: 0.900000 | Val Loss: 0.108135, Val Acc: 0.804124\n",
      "Epoch 31667 - Train Loss: 0.064096, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31668 - Train Loss: 0.064095, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31669 - Train Loss: 0.064094, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31670 - Train Loss: 0.064093, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31671 - Train Loss: 0.064092, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31672 - Train Loss: 0.064091, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31673 - Train Loss: 0.064090, Train Acc: 0.900000 | Val Loss: 0.108136, Val Acc: 0.804124\n",
      "Epoch 31674 - Train Loss: 0.064089, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31675 - Train Loss: 0.064088, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31676 - Train Loss: 0.064087, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31677 - Train Loss: 0.064086, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31678 - Train Loss: 0.064085, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31679 - Train Loss: 0.064084, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31680 - Train Loss: 0.064083, Train Acc: 0.900000 | Val Loss: 0.108137, Val Acc: 0.804124\n",
      "Epoch 31681 - Train Loss: 0.064082, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31682 - Train Loss: 0.064081, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31683 - Train Loss: 0.064080, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31684 - Train Loss: 0.064079, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31685 - Train Loss: 0.064078, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31686 - Train Loss: 0.064077, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31687 - Train Loss: 0.064076, Train Acc: 0.900000 | Val Loss: 0.108138, Val Acc: 0.804124\n",
      "Epoch 31688 - Train Loss: 0.064075, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31689 - Train Loss: 0.064074, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31690 - Train Loss: 0.064073, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31691 - Train Loss: 0.064072, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31692 - Train Loss: 0.064071, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31693 - Train Loss: 0.064070, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31694 - Train Loss: 0.064069, Train Acc: 0.900000 | Val Loss: 0.108139, Val Acc: 0.804124\n",
      "Epoch 31695 - Train Loss: 0.064068, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31696 - Train Loss: 0.064067, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31697 - Train Loss: 0.064066, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31698 - Train Loss: 0.064065, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31699 - Train Loss: 0.064064, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31700 - Train Loss: 0.064063, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31701 - Train Loss: 0.064062, Train Acc: 0.900000 | Val Loss: 0.108140, Val Acc: 0.804124\n",
      "Epoch 31702 - Train Loss: 0.064061, Train Acc: 0.900000 | Val Loss: 0.108141, Val Acc: 0.804124\n",
      "Epoch 31703 - Train Loss: 0.064060, Train Acc: 0.900000 | Val Loss: 0.108141, Val Acc: 0.804124\n",
      "Epoch 31704 - Train Loss: 0.064059, Train Acc: 0.900000 | Val Loss: 0.108141, Val Acc: 0.804124\n",
      "Epoch 31705 - Train Loss: 0.064058, Train Acc: 0.900000 | Val Loss: 0.108141, Val Acc: 0.804124\n",
      "Epoch 31706 - Train Loss: 0.064057, Train Acc: 0.900000 | Val Loss: 0.108141, Val Acc: 0.804124\n",
      "Epoch 31707 - Train Loss: 0.064056, Train Acc: 0.900000 | Val Loss: 0.108141, Val Acc: 0.804124\n",
      "Epoch 31708 - Train Loss: 0.064055, Train Acc: 0.900000 | Val Loss: 0.108142, Val Acc: 0.804124\n",
      "Epoch 31709 - Train Loss: 0.064054, Train Acc: 0.900000 | Val Loss: 0.108142, Val Acc: 0.804124\n",
      "Epoch 31710 - Train Loss: 0.064053, Train Acc: 0.900000 | Val Loss: 0.108142, Val Acc: 0.804124\n",
      "Epoch 31711 - Train Loss: 0.064052, Train Acc: 0.900000 | Val Loss: 0.108142, Val Acc: 0.804124\n",
      "Cost has not changed for 10 epochs, stopping training.\n",
      "--- 117.44771814346313 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X_train.shape[0], 30, 5)\n",
    "\n",
    "# init time for training\n",
    "import time\n",
    "start_time = time.time()\n",
    "history_cost, history_acc, val_cost, val_acc = model.train_until_cost_doesnt_change(\n",
    "    X_train, y_train, 0.005, X_val, y_val\n",
    ")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19d67360520>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAHHCAYAAAC1G/yyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACb60lEQVR4nOzdd3hUxdfA8e9uek9IQgqEJEDoEJQmIEVBQ+8d6YK+AkpTQaqAAoIYKcpPpdjoTQQBqUqT3nsJEEpCEkjvu/f9Y8mSJT0kWQLn8zz7ZO/cuXPPbjbs4c7cGZWiKApCCCGEEAIAtbEDEEIIIYR4nkhyJIQQQgiRjiRHQgghhBDpSHIkhBBCCJGOJEdCCCGEEOlIciSEEEIIkY4kR0IIIYQQ6UhyJIQQQgiRjiRHQgghhBDpSHIkiq3+/fvj4+Nj7DCM5ubNm6hUKpYtW6YvmzJlCiqVKlfHq1QqpkyZUqAxNW3alKZNmxZom8XZ3r17UalU7N27t8jOuW3bNmrWrImlpSUqlYrIyMgiO3dRKozPrxBpJDkSBU6lUuXqUZRfGMbWrl07rK2tiYmJybJO7969MTc3JyIioggjy7sLFy4wZcoUbt68aexQ9NKSEJVKxW+//ZZpnYYNG6JSqahWrVq+zrF8+XICAwOfIcrCFxERQbdu3bCysmLhwoX8+uuv2NjYFNr5li1bpn/f9+/fn2G/oih4eXmhUqlo06ZNocXxLA4dOoRarWbcuHGZ7p81axYqlYotW7ag1WpZtmwZ7dq1w8vLCxsbG6pVq8b06dNJTEws4shFoVKEKGC//vqrweOtt95SgAzlISEhz3Se5ORkJTExsYCiLlwrV65UAOXnn3/OdH9cXJxiY2OjtG3bNtdtBgUFKYCydOlSfVlKSoqSkJCQq+MBZfLkybk+X5o1a9YogLJnz54M+5KSkpSkpKQ8t/ms9uzZowCKpaWl0rJlywz7094rS0tLpWrVqvk6R+vWrRVvb+88HaPRaJSEhARFo9Hk65x5tXXrVgVQduzYUSTnW7p0qf59/b//+78M+9N+LxYWFkrr1q0L9Nz5/fxm5v3331fMzMyUc+fOGZTfvHlTsba2Vrp27aooiqLExMQogPLaa68p06dPV3744QdlwIABilqtVpo2bapotdoCiUcYn6lxUjLxInvnnXcMtv/77z927NiRofxp8fHxWFtb5/o8ZmZm+YrPGNq1a4ednR3Lly+nb9++Gfb/8ccfxMXF0bt372c6j6mpKaamxvuzNjc3N9q5AVq1asWmTZsIDw/HxcVFX758+XLc3Nzw8/Pj0aNHhR5HYmIi5ubmqNVqLC0tC/18aR48eACAo6NjgbUZFxeX49WnVq1asWbNGubNm2fw+Vu+fDm1atUiPDy8wOIpDDNnzuSPP/7gvffeY9++ffqu6eHDh2NmZsa3334L6D7fBw4coEGDBvpjBw8ejI+PD5MnT2bXrl00b97cKK9BFCzpVhNG0bRpU6pVq8bx48dp3Lgx1tbWfPbZZ4AuUWjdujWenp5YWFhQrlw5pk2bhkajMWjj6TFHaWNw5syZww8//EC5cuWwsLCgTp06HD16NNt4jh07hkql4ueff86wb/v27ahUKjZv3gxATEwMI0aMwMfHBwsLC0qWLMlbb73FiRMnsmzfysqKTp06sWvXLv0XWHrLly/Hzs6Odu3a8fDhQ8aMGUP16tWxtbXF3t6eli1bcvr06WxfA2Q+5igpKYmRI0fi6uqqP8edO3cyHHvr1i0++OADKlasiJWVFc7OznTt2tWg+2zZsmV07doVgDfeeCNDF2lmY44ePHjAoEGDcHNzw9LSEn9//wzv87P87tJr3749FhYWrFmzxqB8+fLldOvWDRMTk0yP++2336hVqxZWVlaUKFGCHj16EBwcrN/ftGlTtmzZwq1bt/SvOe2zl9alt3LlSiZMmECpUqWwtrYmOjo6yzFHhw8fplWrVjg5OWFjY0ONGjX0X8AAISEhDBgwgNKlS2NhYYGHhwft27fPtiuzadOm9OvXD4A6deqgUqno37+/fv+aNWv0r9HFxYV33nmHu3fvGrTRv39/bG1tuX79Oq1atcLOzi5XCXvPnj2JiIhgx44d+rLk5GTWrl1Lr169Mj0mLi6O0aNH4+XlhYWFBRUrVmTOnDkoimJQL7efX4C7d+8ycOBA3NzcsLCwoGrVqixZsiTH+B0cHPj22285cOAAP/30EwAbNmzgzz//ZObMmXh4eAC65Ch9YpSmY8eOAFy8eDHHc4niQa4cCaOJiIigZcuW9OjRg3feeQc3NzdA9wVsa2vLqFGjsLW1Zffu3UyaNIno6Ghmz56dY7vLly8nJiaG9957D5VKxVdffUWnTp24ceNGllebateuTdmyZVm9erX+CybNqlWrcHJyIiAgAID333+ftWvXMmzYMKpUqUJERAT79+/n4sWLvPrqq1nG1bt3b37++WdWr17NsGHD9OUPHz5k+/bt9OzZEysrK86fP8/GjRvp2rUrvr6+hIaG8r///Y8mTZpw4cIFPD09c3wP0nv33Xf57bff6NWrFw0aNGD37t20bt06Q72jR49y8OBBevToQenSpbl58ybff/89TZs25cKFC1hbW9O4cWM+/PBD5s2bx2effUblypUB9D+flpCQQNOmTbl27RrDhg3D19eXNWvW0L9/fyIjI/noo48M6ufnd5eetbU17du3Z8WKFfzf//0fAKdPn+b8+fP89NNPnDlzJsMxX3zxBRMnTqRbt268++67hIWFMX/+fBo3bszJkydxdHRk/PjxREVFcefOHb755hsAbG1tDdqZNm0a5ubmjBkzhqSkpCyvou3YsYM2bdrg4eHBRx99hLu7OxcvXmTz5s3696Nz586cP3+e4cOH4+Pjw4MHD9ixYwe3b9/O8iaE8ePHU7FiRX744QemTp2Kr68v5cqVA3R/UwMGDKBOnTrMmDGD0NBQfTKQ9hrTpKamEhAQwOuvv86cOXNydTXXx8eH+vXrs2LFClq2bAnA1q1biYqKokePHsybN8+gvqIotGvXjj179jBo0CBq1qzJ9u3b+fjjj7l7967+PYbcf35DQ0N57bXXUKlUDBs2DFdXV7Zu3cqgQYOIjo5mxIgR2b6Grl270rp1az799FOaNWvGRx99RIMGDXjvvfdyfP0hISEABlcrRTFn7H498eIbOnSo8vRHrUmTJgqgLFq0KEP9+Pj4DGXvvfeeYm1tbTDGqF+/fgZjQNLGlTg7OysPHz7Ul//xxx8KoPz555/Zxjlu3DjFzMzM4NikpCTF0dFRGThwoL7MwcFBGTp0aLZtZSY1NVXx8PBQ6tevb1C+aNEiBVC2b9+uKIqiJCYmZhijEhQUpFhYWChTp07N8HrTjzmaPHmywXt96tQpBVA++OADg/Z69eqVYcxGZu/7oUOHFED55Zdf9GXZjTlq0qSJ0qRJE/12YGCgAii//fabviw5OVmpX7++Ymtrq0RHRxu8lvz+7tLGtqxZs0bZvHmzolKplNu3byuKoigff/yxUrZsWX186ccc3bx5UzExMVG++OILg/bOnj2rmJqaGpRnNeYo7dxly5bN8B6m7Ut7r1JTUxVfX1/F29tbefTokUHdtPEqjx49UgBl9uzZ2b7mzKSNATp69Ki+LDk5WSlZsqRSrVo1g/FomzdvVgBl0qRJ+rJ+/fopgDJ27Ng8n2/BggWKnZ2d/j3o2rWr8sYbbyiKoije3t4GY442btyoAMr06dMN2uvSpYuiUqmUa9euKYqSt8/voEGDFA8PDyU8PNygbo8ePRQHB4dMP99Pu3nzpmJjY6OUKFFCMTMzU86ePZur96F58+aKvb19ht+pKL6kW00YjYWFBQMGDMhQbmVlpX8eExNDeHg4jRo1Ij4+nkuXLuXYbvfu3XFyctJvN2rUCIAbN27keFxKSgrr16/Xl/39999ERkbSvXt3fZmjoyOHDx/m3r17OcaSnomJCT169ODQoUMG3SNp42GaNWsG6N4XtVr3p6nRaIiIiMDW1paKFStm23WXmb/++guADz/80KA8s/9Fp3/fU1JSiIiIoHz58jg6Oub5vOnP7+7uTs+ePfVlZmZmfPjhh8TGxvLPP/8Y1M/v7y69t99+mxIlSrBy5UoURWHlypUG509v/fr1aLVaunXrRnh4uP7h7u6On58fe/bsyfV5+/XrZ/AeZubkyZMEBQUxYsSIDOOC0rpDraysMDc3Z+/evQUyPurYsWM8ePCADz74wGD8U+vWralUqRJbtmzJcEzaVbe86NatGwkJCWzevJmYmBg2b96cZZfaX3/9hYmJSYbP5ejRo1EUha1bt+rrQc6fX0VRWLduHW3btkVRFIPfZUBAAFFRUbn6DHt7ezN58mQePnzIqFGjcnVn45dffsnOnTuZOXNmgY71EsYlyZEwmlKlSmXa9XD+/Hk6duyIg4MD9vb2uLq66gdzR0VF5dhumTJlDLbTvmxz+qLx9/enUqVKrFq1Sl+2atUqXFxcePPNN/VlX331FefOncPLy4u6desyZcqUXH95p43fWL58OQB37txh37599OjRQz8eRqvV8s033+Dn54eFhQUuLi64urpy5syZXL3+9G7duoVardZ3r6SpWLFihroJCQlMmjRJPwYk7byRkZF5Pm/68/v5+emTvTRp3XC3bt0yKM/v7y49MzMzunbtyvLly/n3338JDg7O8kv66tWrKIqCn58frq6uBo+LFy9mOj4sK76+vjnWuX79OkC2X7oWFhbMmjWLrVu34ubmRuPGjfnqq6/0XTd5lfYeZ/Y7r1SpUobfgampKaVLl87zeVxdXWnevDnLly9n/fr1aDQaunTpkmVMnp6e2NnZGZQ//bnI7ec3LCyMyMhIfvjhhwy/x7T/gOX2d1mnTh1A19Wek1WrVjFhwgQGDRqUr4RSPL9kzJEwmsz+lx0ZGUmTJk2wt7dn6tSplCtXDktLS06cOMGnn36KVqvNsd2sBt0qTw30zEz37t354osvCA8Px87Ojk2bNtGzZ0+DO3C6detGo0aN2LBhA3///TezZ89m1qxZrF+/Xj/eIiu1atWiUqVKrFixgs8++4wVK1agKIrBoNcvv/ySiRMnMnDgQKZNm0aJEiVQq9WMGDEiV68/v4YPH87SpUsZMWIE9evXx8HBAZVKRY8ePQr1vOk9y+8uvV69erFo0SKmTJmCv78/VapUybSeVqtFpVKxdevWTM/99Lii7OR01SgvRowYQdu2bdm4cSPbt29n4sSJzJgxg927d/PKK68U2Hkyk/7KZV716tWLwYMHExISQsuWLYvsSkra5/Odd97JMGYwTY0aNQr0nDt27KBv3760bt2aRYsWFWjbwvgkORLPlb179xIREcH69etp3LixvjwoKKhIzt+9e3c+//xz1q1bh5ubG9HR0fTo0SNDPQ8PDz744AM++OADHjx4wKuvvsoXX3yRY3IEuqtHEydO5MyZMyxfvhw/Pz/9/1YB1q5dyxtvvMHixYsNjouMjMzzgE9vb2+0Wi3Xr183+N/25cuXM9Rdu3Yt/fr14+uvv9aXJSYmZphhObczcKed/8yZM2i1WoMv3LTuUW9v71y3lRevv/46ZcqUYe/evcyaNSvLeuXKlUNRFHx9falQoUK2bebldWd3PoBz587leMt3uXLlGD16NKNHj+bq1avUrFmTr7/+OstJLrOS9h5fvnzZ4ApoWllB/g46duzIe++9x3///WdwBTazmHbu3ElMTIzB1aOnPxe5/fym3cmm0WiK5Fb6w4cP07FjR2rXrs3q1auNOn2GKBzSrSaeK2n/e09/pSA5OZnvvvuuSM5fuXJlqlevzqpVq1i1ahUeHh4GSZpGo8nQxVSyZEk8PT1JSkrK1TnSrhJNmjSJU6dOZbhV2sTEJMOVkjVr1mS47To30pK1p+8Wymym58zOO3/+/AxTKKTNeZObZSlatWpFSEiIwRdlamoq8+fPx9bWliZNmuTmZeSZSqVi3rx5TJ48mT59+mRZr1OnTpiYmPD5559neO2KohjMVm5jY5Pv7sU0r776Kr6+vgQGBmZ4/9LOHx8fn2G25XLlymFnZ5frz1h6tWvXpmTJkixatMjg+K1bt3Lx4sVM7/zKL1tbW77//numTJlC27Zts6zXqlUrNBoNCxYsMCj/5ptvUKlU+s9tbj+/JiYmdO7cmXXr1nHu3LkM5wsLC8vPy8lU2nvm4+PD5s2bC/SKoXh+SLornisNGjTAycmJfv368eGHH6JSqfj111/z3K3yLLp3786kSZOwtLRk0KBBBlc8YmJiKF26NF26dMHf3x9bW1t27tzJ0aNHDa64ZMfX15cGDRrwxx9/AGRIjtq0acPUqVMZMGAADRo04OzZs/z++++ULVs2z6+lZs2a9OzZk++++46oqCgaNGjArl27uHbtWoa6bdq04ddff8XBwYEqVapw6NAhdu7cibOzc4Y2TUxMmDVrFlFRUVhYWPDmm29SsmTJDG0OGTKE//3vf/Tv35/jx4/j4+PD2rVrOXDgAIGBgRnGnBSk9u3b0759+2zrlCtXjunTpzNu3Dhu3rxJhw4dsLOzIygoiA0bNjBkyBDGjBkD6LpEV61axahRo6hTpw62trbZJgCZUavVfP/997Rt25aaNWsyYMAAPDw8uHTpEufPn2f79u1cuXKFZs2a0a1bN6pUqYKpqSkbNmwgNDQ006uYOTEzM2PWrFkMGDCAJk2a0LNnT/2t/D4+PowcOTLPbWYnq26t9Nq2bcsbb7zB+PHjuXnzJv7+/vz999/88ccfjBgxQn+FLS+f35kzZ7Jnzx7q1avH4MGDqVKlCg8fPuTEiRPs3LmThw8fPvNri4mJISAggEePHvHxxx9nGMxerlw56tev/8znEc+Bor9BTrxssrqVP6tlHA4cOKC89tpripWVleLp6al88sknyvbt2zPcPp7VrfyZ3QJNHpYauHr1qgIogLJ//36DfUlJScrHH3+s+Pv7K3Z2doqNjY3i7++vfPfdd7lqO83ChQsVQKlbt26GfYmJicro0aMVDw8PxcrKSmnYsKFy6NChDLfJ5+ZWfkVRlISEBOXDDz9UnJ2d9UuUBAcHZ3hPHj16pAwYMEBxcXFRbG1tlYCAAOXSpUuKt7e30q9fP4M2f/zxR6Vs2bKKiYmJwe/l6RgVRVFCQ0P17ZqbmyvVq1c3iDn9a8nv7y79rfzZyepzt27dOuX1119XbGxsFBsbG6VSpUrK0KFDlcuXL+vrxMbGKr169VIcHR0VQP/Zy+7cT9/Kn2b//v3KW2+9pf8M1ahRQ5k/f76iKIoSHh6uDB06VKlUqZJiY2OjODg4KPXq1VNWr16d7WtTlMxv5U+zatUq5ZVXXlEsLCyUEiVKKL1791bu3LljUKdfv36KjY1NjufJzfnSe/pWfkXRLcUxcuRIxdPTUzEzM1P8/PyU2bNnZ1iCI7efX0XRfdaGDh2qeHl5KWZmZoq7u7vSrFkz5Ycffsj1a8ru95n2Oc3q8fTfiSi+VIpShP8lF0IIIYR4zsmYIyGEEEKIdCQ5EkIIIYRIR5IjIYQQQoh0JDkSQgghhEhHkiMhhBBCiHQkORJCCCGESOelmwRSq9Vy79497OzsCmQ5ACGEEEIUPkVRiImJwdPTM9/r/+XWS5cc3bt3Dy8vL2OHIYQQQoh8CA4OpnTp0oV6jpcuOUpbriA4OBh7e3sjRyOEEEKI3IiOjsbLy6tQlx1K89IlR2ldafb29pIcCSGEEMVMUQyJkQHZQgghhBDpSHIkhBBCCJGOJEdCCCGEEOlIciSEEEIIkY4kR0IIIYQQ6UhyJIQQQgiRjiRHQgghhBDpSHIkhBBCCJGOJEdCCCGEEOlIciSEEEIIkY4kR0IIIYQQ6UhyJIQQQgiRzku38KwQQgghDEUlRRGXEldg7ZmbmONi5VJg7RU1SY6EEEKIF1ySJomY5Bj99p/X/+RW9C0AToed5lrktQI9n7+rP7+1+q1A2yxKkhwJIYQQRpasSSZJk5SnY8ISwlh7ZS2p2tRs692Pu8/e4L25atPCxCJPMWTFTG1WIO0YiyRHQgghihVFUUjRphg7jBydDjvNvjv7UFCyrXcm7AwnHpwooqiesDCxYEiNIQBYmljSvnx7HCwcijyO55EkR0IIIZ5r0cnRrLm8hvjUeJJSk/j5ws/GDum50tCzIVVdqmZbx1RlSpuybfCy9yqiqHQWLlzI7NmzCQkJwd/fn/nz51O3bt1M66akpDBjxgx+/vln7t69S8WKFZk1axYtWrQo0phBkiMhhBBG8u+df7n08BIAYfFhrLy80sgRFY5elXrl2F1lbmJOlwpdcLZ0zlPbapUaE7XJs4RXaFatWsWoUaNYtGgR9erVIzAwkICAAC5fvkzJkiUz1J8wYQK//fYbP/74I5UqVWL79u107NiRgwcP8sorrxRp7CpFUbK/3veCiY6OxsHBgaioKOzt7Y0djhBCvDB6benFlUdXclU3r+NrAPyc/KjjVgeVSsXrpV6npmvNPLdR1KzNrFGrXs5Zc+rVq0edOnVYsGABAFqtFi8vL4YPH87YsWMz1Pf09GT8+PEMHTpUX9a5c2esrKz47bffivT7W64cCSGEyNa3J75l2flltCvXjopOFTPs/+70d0QlReW7/c5+nQFQqVS87f02FZwqZKhjZWqFtZl1vs8hilZycjLHjx9n3Lhx+jK1Wk3z5s05dOhQpsckJSVhaWlpUGZlZcX+/fsLNdbMSHIkhBAvmZC4EEbsGUFofCiKoqBVtNTzqMdrHq9lqJuoSeSnsz8BsP7q+hzbtja1ZmP7jbmKQ6VS4WbthkqlylP84vkXHh6ORqPBzc3NoNzNzY1Lly5lekxAQABz586lcePGlCtXjl27drF+/Xo0Gk1RhGxAkiMhhHgBhSeEc+DuAb498W2G26rvxd3LUH/bzW1su7kt2zablm6KuYl5pvt8HXxpV64dpe1Kv7TdSOLZfPvttwwePJhKlSqhUqkoV64cAwYMYMmSJUUeiyRHQghRgBRF4WjIUUpYlqC8U/kCa/dc+DnuxWZMarIy+p/ROdZ5vdTrDKg6gF8u/IKKbK7eqKC1b2ta+Bb9XUOieHJxccHExITQ0FCD8tDQUNzd3TM9xtXVlY0bN5KYmEhERASenp6MHTuWsmXLFkXIBiQ5EkKIXLobe5drj57MJPww8SFLzi0xuBPp8qPL+ufuNu44mOd93pjLjy5T3rE8JioT/XljU2LzFbOnjSctfVvS3Lu5QbmHjQfOVro7o+p6ZH5rtRD5ZW5uTq1atdi1axcdOnQAdAOyd+3axbBhw7I91tLSklKlSpGSksK6devo1q1bEURsSJIjIYTIRGRiJGfCz/Ddqe8wUZmQqEnM9Z1YaULiQgiJC8nX+bNazqGWW61ct1G5RGU+qfOJjOkRRjFq1Cj69etH7dq1qVu3LoGBgcTFxTFgwAAA+vbtS6lSpZgxYwYAhw8f5u7du9SsWZO7d+8yZcoUtFotn3zySZHHLsmREOKlcjPqJhGJEVnuj0yMZOn5pZwOO51lnWrO1fQJh1bR0rBUQ4OkJVWbilqlztfYm+03t3Pt0TXUKjXv+7+vP4+pypQarjWwNLXMoQUhng/du3cnLCyMSZMmERISQs2aNdm2bZt+kPbt27dRq5/8jSQmJjJhwgRu3LiBra0trVq14tdff8XR0bHIY5d5joQQLxxFUfj80Ofcj7tvUH7l0RXCE8Lz1Ja3vTf+rv685f0WANVcqhXr1caFKK5kniMhhMinyMRIhu4eypmwM9nW87H3yXKfRtHQwLMB71R+Bx+HrOsJIV5MkhwJIZ5rN6NusuDUglzVDYsPy7CA55evf2mwbWZixuuer2NrbltgMQohXiySHAkhnktJmiTmHJ2T7/W2SlqVZG27tThZOhVwZEKIF50kR0KI505UUhRvr32b+NR4fVn7cu2p4lwlx2NNVCY08WqCu03mc6kIIUROJDkSQjxXvj/9Pd+d+s6gbG3btVQskXFNLyGEKAySHAkhjCpVm8rOWzu5EHGBtVfWEpMSo9/n6+DLitYrsDGzMWKEQoiXjSRHQgijCIsPY9DfgwiKCsp0/44uO6RrTAhhFJIcCSGKTJImibVX1jLzyMxM9/er0g8XKxfeqfIOpmr550kIYRzyr48QolC9t+M9ToTqbq9P1CRm2N+kdBOmN5yOg4WDLHMhhHguSHIkhCgU4QnhDNo+iBtRNzLsc7Rw5OM6H9O8THOszayNEJ0QQmRNkiMhRIHTaDW8sfoNg7JtnbehQoWlqSUlLEsYKTIhhMiZJEdCiAIRHB3MqH9GcenhJYPyyiUq82urX7EwsTBSZEIIkTeSHAkhnklMcgyj9o7iv/v/ZdjnY+/D6rarjRCVEELknyRHQog8e5T4iPd2vIeCkuFKEUCfKn3oUL4Dfo5+RohOCCGejSRHQog8CYkL4a21b2Uor1yiMpMbTKZyicqoVWojRCaEEAVDkiMhRAbBMcGEJ4RnKD/94DRfH/9av924dGN6V+qNmYkZNV1rYmZiVpRhCiFEoZDkSAihl6JJYdXlVcw6OivHup39OjOlwZTCD0oIIYqYJEdCCFK0Kfx05ie+O2244Ku3vXeGugkpCQx/dTitfVsXVXhCCFGkJDkS4iWmKArzTs7jp7M/GZRbmFgwu/Fs3ijzRhZHCiHEi0uSIyFeYnuD9xokRmqVmp/e/ok67nWMF5QQQhiZJEdCvISOhhxlW9A2rkVe05ctDVhKbffaRoxKiJw9XL6c0KnTUFlZYf3KK8YOJ1PWr72Gy5DBxg5DPANJjoR4QaVqU0nWJAOgUqmwMrXiQfwDhvw9hOtR1w3qDqw2UBIjUSyETp0GgJKQQNzBg0aOJnNxBw9S4p3eqK1l3cDiSpIjIV4AiqKgUTSYqExQqVSsv7qeyQcn53hc/6r9cbFyoX259kUQpRAFy3P2V8YOwZCicO+TTwHQJiZKclSMGT05WrhwIbNnzyYkJAR/f3/mz59P3bp1s6wfGBjI999/z+3bt3FxcaFLly7MmDEDS0vLIoxaiOdHeEK4wSKvJa1K8iDhQY7H/dryV2qWrFmIkQlRuBzatjV2CBnc+2w8pKaiJCcbOxTxDIyaHK1atYpRo0axaNEi6tWrR2BgIAEBAVy+fJmSJUtmqL98+XLGjh3LkiVLaNCgAVeuXKF///6oVCrmzp1rhFcghPEoikKXP7tw5dEVg/L0idHqNqvxcfBh3ZV13I+7jwoVzbybUcOlBiZqk6IOWYgMorduJf7oUWOHUWBU5uYoqak8mDsXE1tbY4djNGalSuM8aKCxw8g3laIoirFOXq9ePerUqcOCBQsA0Gq1eHl5MXz4cMaOHZuh/rBhw7h48SK7du3Sl40ePZrDhw+zf//+XJ0zOjoaBwcHoqKisLe3L5gXIkQRufzwMvvu7uPbE99m2FfGrgz1PesDYG9uzwc1P8BUbfSLw0JkSZuUxOXadSAlJV/HV750sYAjenbXmjUn5e5dY4dhdFY1a+KzckWBtlmU399G+5czOTmZ48ePM27cOH2ZWq2mefPmHDp0KNNjGjRowG+//caRI0eoW7cuN27c4K+//qJPnz5ZnicpKYmkpCT9dnR0dMG9CCGKQHxKPDtu7eBB/APmnZyXYb+zpTN/dvwTO3M7I0QnRP5p4+P1iZHLBx+ASpXjMck3bxK9ZQu+m/4o7PDypdQ3c4n9519jh2F0Zh7uxg7hmRgtOQoPD0ej0eDm5mZQ7ubmxqVLGVf5BujVqxfh4eG8/vrrKIpCamoq77//Pp999lmW55kxYwaff/55gcYuRFG5+ugqnTZ1ylDewqcFdT3q0qhUI9ys3VDl4ktFiOeNkvz4ipFajeuHw3N9XKmv5xRSRM/OqkYNrGrUMHYY4hkVq6Wz9+7dy5dffsl3333HiRMnWL9+PVu2bGHatGlZHjNu3DiioqL0j+Dg4CKMWIj8G757uEFiZGliyVveb/G/t/7H7Caz6VqhK+427pIYiedW/IkTPPz55ywfkatWArpxOuLFtHDhQnx8fLC0tKRevXocOXIk2/qBgYFUrFgRKysrvLy8GDlyJImJiQZ1fvzxx1y1qSgKLVu2RKVSsXHjxjzFbbQrRy4uLpiYmBAaGmpQHhoairt75pfjJk6cSJ8+fXj33XcBqF69OnFxcQwZMoTx48ejVmfM9SwsLLCwsCj4FyBEIbkTc4e2G9uSqk3Vl/Wt0peP63xsxKiEyBttQgK3BwxESTesISvql3jg8oussG66+uyzz3LVZmBgYL7/82i05Mjc3JxatWqxa9cuOnToAOgGZO/atYthw4Zlekx8fHyGBMjERHfHjRHHlQtRIKKSojgddpqhu4YalP/X6z9szGyMFJUQ+aOJidEnRvZt2mRb1y7g7aIISRSxuXPnMnjwYAYMGADAokWL2LJlC0uWLMn0pquDBw/SsGFDevXqBYCPjw89e/bk8OHDBvX69euXY5unTp3i66+/5tixY3h4eOQ5dqPeyjJq1Cj69etH7dq1qVu3LoGBgcTFxelfdN++fSlVqhQzZswAoG3btsydO5dXXnmFevXqce3aNSZOnEjbtm31SZIQxVGqNpXXV75uUFbPox4Lmy3EwkSufIriJ22eH5WlJaXmzDZyNKKoFcZNV8mPP1NNmzbNts34+Hh69erFwoULs+yJyolRk6Pu3bsTFhbGpEmTCAkJoWbNmmzbtk0/SPv27dsGV4omTJiASqViwoQJ3L17F1dXV9q2bcsXX3xhrJcgRIGYe9xwni4XKxdJjApZyt27JF65knNFkS+pobr5tmQ80cupMG66ioiIAMjQffZ0myNHjqRBgwa0b5//mf+NPgnKsGHDsuxG27t3r8G2qakpkydPZvLknJdFEKI4iEqKYty+cey7u09ftqzFMl4t+aoMtC5E2sREbrTvgDY21tihvPDUsnqByKX0N12l9Q599NFHTJs2jYkTJ+aqjU2bNrF7925Onjz5TLEYPTkS4mX2dFeaLOlRNDSRkfrEyLJ6dSNH8wJTqXDs2MHYUQgjKIybrpydnQF48MBweaT0be7evZvr16/j6OhoUKdz5840atQow0WXrEhyJISR/HvnyURxr3m8xvv+70tiVETSBgqrra3xXbPayNEI8eIpjJuuzB930f7zzz/6QdtPtzl27Fh9cpWmevXqfPPNN7TNw1p8khwJYQShcaEGd6X9+PaPRoymeNImJ5NyJ3/LNCTfvgXIeBghClNh3XT1888/06BBg0zbdHd3z/TKVJkyZfD19c117JIcCVGEElITOHTvEB/t+UhfNqX+FOMFVEwpWi1BHTqSfOPGM7UjyZEQhaewbrqaPn16lm0WFKMuPGsMsvCsKGr/BP/Df/f/43jocS4+NFwos0+VPnxS5xMjRVZ8aePjufxqLQDU9va5WpPraSrAsWcPSo4YUbDBCSEKxUux8KwQL4N3t7/L4ZDDme6b23Qub3m/VcQRvRi06WZdrnDwACpT+adMCFFw5F8UIQrJufBzBonRgGoDsDWzpUuFLjhaOKJWFaulDbOlKAoU1EVolSrHttImGEStlsRICFHg5F8VIQrY3di7fLT7Iy4/uqwvO9P3zAs7b5GSmsrNnr1IPHu2yM8tY4aEEIVBkiMhCsCD+AesuryKH878kGHfB/4fvLCJEUBqaKhREiMAm3r1jHJeIcSLTZIjIZ7Rj2d+ZN7JeZnuG11rNP2r9S/agIqY9nEXl9rWlnI7/n6mtq7WbwCAiasLZTdtyrG+yVMTvQkhREGQ5EiIfLgfe58jIUcADBKjGi416F+tPw08G2BjZmOs8IqUfoFRCwtMnZwKpE2VqVmBtSWEEHklyZEQeRSdHM3b697OUL6101ZK25U2QkQZxZ84SciUKWgTEvRliiYVE1s7g7KCoE+OZPyPEOIFIcmREHkw7dA0Vl/JuNzE1AZTn5vECCD6r79IymTF+VTuF9o5LcqWfeY2rGrWJOHUKezefLMAIhJCiPyR5EiIXFp7ZW2GxKieRz38Xf3p6NfRSFFlLm3tMMdu3XDs1JE7wz8kNSwMAPs2bSjxTu+CPaFKhUXlys/cTJllS0m+cQOLSpUKICghhMgfSY6EyIWnB12vbL2Sys6Vn9u5itK6usy9y2BVsyZqGxt4nByZlSqFVc2aRowua2pLSyyrVDF2GEKIl5wkR0Jk41b0Lb4+9jV7gvfoy35r9RtVXaoaMarsPfz9d6L++AMAlZluHFD68UAqczOjxCWEEMWFJEdCpPPjmR85+eAkAOcjzvMw8aHB/r86/YWXnZcxQssVRVF4MHOWftvUw13/M20Mkpm7h1FiE0KI4kKSIyEeO3L/SJbzFXnZefF7q99xsnzOby9PTUVJSQHAc84c/cBmzxkziDtwELWtDbaNGhkzQiGEeO5JciReeoqiEBofyqC/B+nLpjaYCoCFiQVNvJoUmzmL9GuOAXbN3kRlYgKAaYkSOLRtY6ywhBCiWJHkSLz0Ptz9IXvv7NVvf/n6l7Qt19Z4AT2D6G3b9c9l3iEhhMif5/NWGyGKyJ/X/zRIjIBimxgpisL9CRMAXWKUdtVICCFE3siVI/HS2nJjC5/t/0y/Pb7eeNqULb5dT0pKCigKAKUCvzFyNEIIUXxJciReSr9e+JWvjn6l317RegXVXKoZMaJnl368kU3DhkaMRAghijdJjsRLKX1i9H3z758pMUq8fJn4w4ezrWNasiR2b7+NSp11T3ZqRAQxf/+tv9ssr7Tx8frnKjOZy0gIIfJLkiPx0niU+Ih3/nqH2zG39WW/tvyVmiVrPlO7wUPeIzU0NMd6ZZYtxea117Lc/2DO10Rt2PBMsQCora2zTcKEEEJkT5Ij8cK7G3uXf4L/Ycm5JYTGGyYxz5oYAfo1y+zeao7K3CLD/rjDh9GEh5MaFp59O+G6/Vb+/piVzv8itrZNm+b7WCGEEJIciRfcrehbtNmQcZB11wpdGV179DO3r6SmglYLgMe0aZg4Omaoc/u994j751+DMUGZtvV4v1PfPji0bv3MsQkhhMgfSY7ECylJk0TXP7sSFBWkL6vnXg83GzeGvzIcV60NCYeOE/v47q6cWFSqjJlbSYMyRVGIP3pUv53VvELqx+WJ58+TXOtVzH18MtRJCQ3Vj1uS+YmEEMK4JDkSL6Q2G9oQEhei3x5bdyy9K/fWb9/q24/4I0dy3Z6JszN+//5jMHdQzPa/uTtihG5DpcoyqVFZWgHwaPlyHq1ejd8/ezF1dtbvV1JTCerYSb+ttrTMdVxCCCEKniRH4oUzeu9ofWJkZWrF353/xtHS0aBOcnAwAOblyqG2ssq6Ma2WxAsX0EREoE1IxMT2yTIiycFPBna7fPABKtPM/5ycunUl5d49Es6cgZQUUkJCDJIjbXw8moe6BW5tmzbFunbtPL1eIYQQBUuSI/HCSNYkU+u3WgZlB3ocwMwk423taeN7Ss2di2XFClm2qWi1XKpSVfc8JRl4khylteHYvTuuw4dl2YZ1nTr4/P4b1956m5Tg4Axjj9Jvl/7+O1QqVZZtCSGEKHySHIkXgkaroe0Gw2U/jr1zLNPECEATEQGAyjz7+YBUajWYmkJqKsk3bqBNd8Un7e6y3I4RSquXEhxMspPTk3Ye3+2mMjeXxEgIIZ4DkhyJF0K7je24F3dPv72jyw4sTDLeVg/w8Jdf9c/VuUhs1ObmaFNTudX7nUz355Rg6etZ6M5175NPs2hHBmILIcTzQJIjUexdfXTVYGLHAz0PYG9un2X9xPPn9M9NPTxybN+hUyei/vgj031qGxvs3ngjV3E6tG1HxN17KI9v/c+wv2OHXLUjhBCicKkUJZf3Mr8goqOjcXBwICoqCnv7rL9ARfGgKAo1fqmh3z7d9zRqVfazQ98ZOZKYrdtwGz+eEn0yvxokhBDi+VKU39+yxoAo1vYG79U/b1O2TY6JkaIoKMm6tcukG0sIIURmpFtNFFvBMcF8uOdD/faY2mOyrR+zaxd3R49BSUwEJDkSQgiROblyJIodRVFYdm4Zrda30pd19uuMs5VzNkdB7L59TxIja2usqlUt1DiFEEIUT3LlSBQriqLQf1t/Tjw4oS9rWKohE16bkPOxj7vTnP/vfVzee09mohZCCJEpSY5EsZHZJI/j642nS4UumKpz/iinTbZo4uAgiZEQQogsSXIkio1D9w7pn5uqTdnXfR+25rYZ6sXs3cuDOXP0V4rS5HXSRiGEEC8nSY5EsaAoCssvLQfA2tSaw70PZ1k3asNGkq9dz3K/RdmyBR6fEEKIF4ckR+K5dzrsNO/89WQ+oha+LbKtryQlAeA8ZAi2TZsa7DMt4YS5j09BhyiEEOIFIsmReG6lalPZfXs3o/8ZbVA+oOqAbI9LG1tkUb4c1q++UmjxCSGEeDFJciSeW58f+pyN1zbqtz+u/TF9qvTJcnHW2H37ePTb7yScPw/I2CIhhBD5I8mReO5ciLjAx/98bLBe2kevfkTfqn2zPS78u+9JOHlSv23m7l5oMQohhHhxSXIknhubb2xmxuEZRCdHG5T/2eFPfBx8cjxeGx8PgPO7g7Bp2BBLf//CCFMIIcQLTpIjYXSnHpyiz9Y+Gcp7VOzBoOqDcLfJ3RWgtLFGtk2aYF2nToHGKIQQ4uUhyZEwiui//iL+xEkURcvuSytIP8S6jntdfBx8MAsGdi4mJJdtpoaFATLWSAghxLOR5EgUOW1cHHc//gQ0GgBaZqhxmFiynscoJyZOTvk+VgghhJDkSBQ5TVwcaDRogQ0NdHeeOVmWoGvFrs/ctkXZspiXKfPM7QghhHh5SXIkilRUUhQ37p3EEkgxhVVNTFjYbCENPRtiojYxdnhCCCGEJEeiaIQnhHP10VWG7BhCkzNahqJLjpa1WEYtt1o5Hi+EEEIUFUmORKFQFIVfLvzCknNLeJj4UF9ukawwdIsWgERzaFhSZrAWQgjxfJHkSBS4+JR4+m7ty+VHlzPsc9XaALp5jGrOWIBapS7i6IQQQojsyTeTKFBLzi2h3vJ6GRKjyfUnc6rPKf5ovQ4AlZUVds2aGSNEIYQQIlty5UgUmC/++4KVl1cCYJai0C7Oj9E1R+jWQguBhJADpIToZi2SuYiEEEI8ryQ5Es8sJjmGz/Z9xt47e/Vlqy43J/XP7dzh/UyPUVtYFFF0QgghRN5IciSeyd3Yu7RY18Kg7J/u/xCz4yNSAbPSpTGxtzc8SKXCoVPHogtSCCGEyANJjkS+aLQa/gr6i8/2f6YvK+dQjv+99T9KWJYgKkW3zpnbZ+Owe/NNY4UphBBC5JkkRyLPjoYcZeD2gQZlQ2sO5X1/XReaNiGB5KvXAFCZydgiIYQQxYvcrSby5EH8gwyJEfAkMUpM5Nrbb6ONjwdk4LUQQojiR64ciVxL1abSbM2T2+8nvjaRyiUqU7FExSd1QkLQhIUDYFG5MpZVqxZ5nEIIIcSzkORI5GjlpZWsu7qOSw8v6cv6VelHt4rdMtTVJuvGGpmUKEHZDeuLLEYhhBCioEhyJDKVok1hxcUVbAnawoWICwb7StmWYkydMZkepySnANKdJoQQoviS5EigKApXI6/iaeOJrbktAG3Wt+Fe3D2DenObzsXJwgl/V/8MbWhi47jZuTPJt24BkhwJIYQoviQ5EvwV9Bdj940FwMvOi+CYYIP9E+pNoFHpRnjaembZRtKVy/rECMC6du3CCVYIIYQoZJIcCf535n/6508nRqf6nMJEbZJjG8rjsUbmvr54L/8dE0fHAo1RCCGEKCpyK/9LLjE1kaCoIP22rZmuW62sQ1mWtViWq8QIniRHaisrTJ2cdOupCSGEEMVQnpOjPXv2FGgACxcuxMfHB0tLS+rVq8eRI0eyrR8ZGcnQoUPx8PDAwsKCChUq8NdffxVoTC+LxNRE6vxeR7+9o8sODvU6xNl+Z/mjwx/UcquV67YiFi8BZKyREEKI4i/PyVGLFi0oV64c06dPJzg4OOcDsrFq1SpGjRrF5MmTOXHiBP7+/gQEBPDgwYNM6ycnJ/PWW29x8+ZN1q5dy+XLl/nxxx8pVarUM8Xxsuq0qZPBtruNe77b0g/ENpWeWiGEEMVbnpOju3fvMmzYMNauXUvZsmUJCAhg9erVJD/uVsmLuXPnMnjwYAYMGECVKlVYtGgR1tbWLFmyJNP6S5Ys4eHDh2zcuJGGDRvi4+NDkyZN8PfPePeUyN6he4cMxheta7fumdpTUlMBKDlu7DO1I4QQQhhbnpMjFxcXRo4cyalTpzh8+DAVKlTggw8+wNPTkw8//JDTp0/nqp3k5GSOHz9O8+bNnwSjVtO8eXMOHTqU6TGbNm2ifv36DB06FDc3N6pVq8aXX36JRqPJ68t4qa24tIIhO4bot0/3PU0FpwrP1OaTMUfWz9SOEEIIYWzP1Afy6quv4u7ujrOzMzNnzmTJkiV899131K9fn0WLFlE1m6UjwsPD0Wg0uLm5GZS7ublx6dKlTI+5ceMGu3fvpnfv3vz1119cu3aNDz74gJSUFCZPnpzpMUlJSSQlJem3o6Oj8/FKXxy/X/ydmUdm6rdnNpqJWpW/cfnJt2/z4Jtv0MbFoY2NBWTMkRBCiOIvX9+KKSkprF27llatWuHt7c327dtZsGABoaGhXLt2DW9vb7p27VrQsaLVailZsiQ//PADtWrVonv37owfP55FixZlecyMGTNwcHDQP7y8vAo8ruIiPCHcIDEqYVmC1mVb57u9yPXridm6jbh/94FWi8rCQm7hF0IIUezl+crR8OHDWbFiBYqi0KdPH7766iuqVaum329jY8OcOXPw9Mx6wkDQdc+ZmJgQGhpqUB4aGoq7e+YDgz08PDAzM8PE5Mnt5ZUrVyYkJITk5GTMM7lqMW7cOEaNGqXfjo6OfikTpHH7xrH5xmb99nfNvqNR6UbP1KY2Ph4A26ZNsXv7bSwrVcTE1uaZ2hRCCCGMLc/J0YULF5g/fz6dOnXCwsIi0zouLi453vJvbm5OrVq12LVrFx06dAB0V4Z27drFsGHDMj2mYcOGLF++HK1Wi1qtu+h15coVPDw8Mk2MACwsLLKM82Ww+OxiAk8EGpQ5WDg8c2IET8YZWVarhmOnjs/cnhAiZ1qtNl83wAhRHJibm+u/340pz8nRrl27cm7U1JQmTZrkWG/UqFH069eP2rVrU7duXQIDA4mLi2PAgAEA9O3bl1KlSjFjxgwA/u///o8FCxbw0UcfMXz4cK5evcqXX37Jhx9+mNeX8VL4986/GRKjrZ22ZrsMSFa0yck8XLqM1PBwfVn8sWOAjDMSoqgkJycTFBSEVqs1dihCFAq1Wo2vr2+WFzyKSr4HZF+4cIHbt29n+B9Mu3btct1G9+7dCQsLY9KkSYSEhFCzZk22bdumH6R9+/ZtgwzSy8uL7du3M3LkSGrUqEGpUqX46KOP+PTTT/P7Ml5Yqy+vZtp/0/Tb1ZyrMaPRDErblc5Xe3H79hH2zTeZ7jNxcsxXm0KI3FMUhfv372NiYoKXl9dz8b9rIQqSVqvl3r173L9/nzJlyhh1pQWVoihKXg64ceMGHTt25OzZs6hUKtIOT3sRz/tt9dHR0Tg4OBAVFYW9vb2xwykUSZokav/2ZOHXzxt8Tie/TtkckbPIdeu5P348ZmXKYN+ypb7cxMEBpx7dUVvLLfxCFKaUlBSuXbuGp6cnDg4Oxg5HiEIRFRXFvXv3KF++PGZmZgb7ivL7O89Xjj766CN8fX3ZtWsXvr6+HDlyhIiICEaPHs2cOXMKI0aRR/vv7Nc/XxKwhNputbOpnTtKyuPxRRUrUHLkiGduTwiRN2n/8TR2d4MQhSnt863RaDIkR0Upz8nRoUOH2L17Ny4uLqjVatRqNa+//jozZszgww8/5OTJk4URp8iDtHFGduZ21HGvk33lp6Q+ekTs7t1YvfoqCSdPYeLoiDYulriDuok5VWbyD7MQxiSLOosX2fPy+c5zcqTRaLCzswN0d6Xdu3ePihUr4u3tzeXLlws8QJF3N6NvAtDKt1Wejw2dNp3obBbyVdvIrfpCCCFebHke0VetWjX9EiH16tXjq6++4sCBA0ydOpWyZcsWeIAib6KSovTPB1QbkOfjY3bsyLTcrEwZHDp0oET/fvmOTQghCoKPjw+BgYHGDkO8wPKcHE2YMEF/G+nUqVMJCgqiUaNG/PXXX8ybN6/AAxR503Ldk8HSpWxLFVi7tk2b4DlzBhblyhVYm0KIF5tKpcr2MWXKlHy1e/ToUYYMGZJzxWw0bdqUESNGPFMb4sWV5261gIAA/fPy5ctz6dIlHj58iJOT03PTV/iyuvboGjEpMQC08GmRY31FUUg8cwZNdMyTspSUTOuqZRCoECKP7t+/r3++atUqJk2aZDD8wtbWVv9cURQ0Gg2mpjl/Lbm6uhZsoEI8Jc9XjqKionj48KFBWYkSJXj06NFLv6irsX2678l8T7Maz8qxfvTmLdzs3oPgwYP1j6yoLCwLJEYhxMvD3d1d/3BwcEClUum3L126hJ2dHVu3bqVWrVpYWFiwf/9+rl+/Tvv27XFzc8PW1pY6deqwc+dOg3af7lZTqVT89NNPdOzYEWtra/z8/Ni0adMzxb5u3TqqVq2KhYUFPj4+fP311wb7v/vuO/z8/LC0tMTNzY0uXbro961du5bq1atjZWWFs7MzzZs3Jy4u7pniEUUrz8lRjx49WLlyZYby1atX06NHjwIJSuTdrehbXHl0BYBOfp1Qq3L+1SbfvgWAiaMjFlUq6x4VKwK6MUYAJi4uWNeti32rllm2I4QoeoqiEJ+capRHHqfHy9bYsWOZOXMmFy9epEaNGsTGxtKqVSt27drFyZMnadGiBW3btuX27dvZtvP555/TrVs3zpw5Q6tWrejdu3eG/8jn1vHjx+nWrRs9evTg7NmzTJkyhYkTJ7Js2TIAjh07xocffsjUqVO5fPky27Zto3HjxoDualnPnj0ZOHAgFy9eZO/evXTq1KlA3zNR+PLcrXb48GHmzp2bobxp06aMHz++QIISebfw5EL980/r5G7GcCVZ14Vm37Yt7uM/K5S4hBCFIyFFQ5VJ241y7gtTA7A2z/cCCwamTp3KW2+9pd8uUaIE/v7++u1p06axYcMGNm3alOW6mwD9+/enZ8+eAHz55ZfMmzePI0eO0KJFzkMMnjZ37lyaNWvGxIkTAahQoQIXLlxg9uzZ9O/fn9u3b2NjY0ObNm2ws7PD29ubV155BdAlR6mpqXTq1Alvb28AqlevnucYhHHl+cpRUlISqampGcpTUlJISEgokKBE3m29uRWAJqWbYG1mOFu1Jjqa5OBg/UMTE4M2KQnNwwgAVObGm2hLCPFyq13bcJLa2NhYxowZQ+XKlXF0dMTW1paLFy/meOWoRo0a+uc2NjbY29vz4MGDfMV08eJFGjZsaFDWsGFDrl69ikaj4a233sLb25uyZcvSp08ffv/9d+Lj4wHw9/enWbNmVK9ena5du/Ljjz/y6NGjfMUhjCfPqX/dunX54YcfmD9/vkH5okWLqFWrVoEFJnLv3zv/6p+Prj3aYF/S9esEdehoONBapYJ0l3hl4Vghih8rMxMuTA3IuWIhnbug2Dw1d9qYMWPYsWMHc+bMoXz58lhZWdGlS5cM63g+7enZlFUqVaEt0GtnZ8eJEyfYu3cvf//9N5MmTWLKlCkcPXoUR0dHduzYwcGDB/n777+ZP38+48eP5/Dhw/j6+hZKPKLg5Tk5mj59Os2bN+f06dM0a9YMgF27dnH06FH+/vvvAg9Q5OzQvUP6574Ohn98iZcu6RIjtRq1pSXaxERI9w+GqZsbto/7yoUQxYdKpSqwrq3nyYEDB+jfvz8dO3YEdFeSbt68WaQxVK5cmQMHDmSIq0KFCpiY6BJDU1NTmjdvTvPmzZk8eTKOjo7s3r2bTp06oVKpaNiwIQ0bNmTSpEl4e3uzYcMGRo0aVaSvQ+Rfnv+yGjZsyH///cdXX33F6tWrsbKyokaNGixevBg/P7/CiFFkIzQulN8u/gZA94rdM+xPG1dk07AhZX78gVv9+hN/+DAAant7/P7ZW2SxCiFETvz8/Fi/fj1t27ZFpVIxceLEQrsCFBYWxqlTpwzKPDw8GD16NHXq1GHatGl0796dQ4cOsWDBAr777jsANm/ezI0bN2jcuDFOTk789ddfaLVaKlasyOHDh9m1axdvv/02JUuW5PDhw4SFhVG5cuVCeQ2icOQpOUpJSeG9995j4sSJ/P7774UVk8iDd/9+V/+8qVfTDPuVx5ei07rO0nehSXeaEOJ5M3fuXAYOHEiDBg1wcXHh008/LbRpYpYvX87y5csNyqZNm8aECRNYvXo1kyZNYtq0aXh4eDB16lT69+8PgKOjI+vXr2fKlCkkJibi5+fHihUrqFq1KhcvXuTff/8lMDCQ6OhovL29+frrr2nZUu74LU5USh7vL3RwcODUqVPFtu80OjoaBwcHoqKisLe3N3Y4z+Re7D0C1j0Zc3C231n988h16wiZOg0lKQkAu5YtKP3NNwQPHUbsrl0AmHp64Ld7d9EGLYTIl8TERIKCgvD19cXSUuYdEy+m7D7nRfn9nee71Tp06MDGjRsLIRSRGw8TH9JyXUuq/1zdIDHa132fQb2YPXv0iRGA9au6wfLW6e4MsX7qLhEhhBBC5GPMkZ+fH1OnTuXAgQPUqlUrw50GH374YYEFJzJqsqpJhrJRtUbhaOloUJbWneb22Tgc2rXDxFG333lAfxw7dkBJTcXE2bmwwxVCCCGKnTwnR4sXL8bR0ZHjx49z/Phxg30qlUqSo0J0IvSEwXZtt9p8UucTKjtnHOiXNhDbpISzPjFK8/S2EEIIIZ7Ic3IUFBRUGHGIHCiKwrT/pum3z/Q9Y7DQ74M5c4jZuUu/nfJ4wUeZ4FEIIYTImxdvkowX1OYbm7kWeQ3QrZ2WPjFStFoiFi8xmNgxjbmPT1GFKIQQQrwQ8pwcDRw4MNv9S5YsyXcwImtTDk7RP//wFcOuSyUlRZ8Yef34I2or3Qh/Uzc3zL28iixGIYQQ4kWQ5+To6TViUlJSOHfuHJGRkbz55psFFph44s/rf5Ks1Q2wntFoBs5WhgOplXTT6lvXq4ta5i8SQggh8i3PydGGDRsylGm1Wv7v//6PcuXKFUhQ4glFUQyuGgX4GK6llBQURMiUz/XbKjMZYySEEEI8izzPc5RpI2o1o0aN4ptvvimI5kQ6h+4d0l81+rXlr5ipDZOfyDVr9cuBmLq5GYxFEkIIIUTeFUhyBHD9+nVSU1MLqjnx2Hs739M/r1myZob92vg4AMw8PSmzbGlRhSWEEEWmadOmjBgxQr/t4+NDYGBgtseoVKoCmbC4oNoRxUueu9WeXlVYURTu37/Pli1b6NevX4EFJmDdlXX657Mazcq0Ttp8Ro49emBRTJd0EUK8mNq2bUtKSgrbtm3LsG/fvn00btyY06dPU6NGjTy1e/To0QwTED+rKVOmsHHjxgwL0d6/fx8nJ6cCPdfTli1bxogRI4iMjCzU84jcy3NydPLkSYNttVqNq6srX3/9dY53soncm3diHj+e/VG/3apsK4P9UX9uJvHcWRIe/yHLfEZCiOfNoEGD6Ny5M3fu3KF06dIG+5YuXUrt2rXznBgBuLq6FlSIOXJ3dy+yc4nnR5671fbs2WPw2LVrFytXrmTIkCGYmsq0SQUhKCrIIDH66e2fDPanPnrEvU8+4eHPv5B84wYgs14LIZ4/bdq0wdXVlWXLlhmUx8bGsmbNGgYNGkRERAQ9e/akVKlSWFtbU716dVasWJFtu093q129epXGjRtjaWlJlSpV2LFjR4ZjPv30UypUqIC1tTVly5Zl4sSJpKTorrwvW7aMzz//nNOnT6NSqVCpVPqYn+5WO3v2LG+++SZWVlY4OzszZMgQYmNj9fv79+9Phw4dmDNnDh4eHjg7OzN06FD9ufLj9u3btG/fHltbW+zt7enWrRuhoaH6/adPn+aNN97Azs4Oe3t7atWqxbFjxwC4desWbdu2xcnJCRsbG6pWrcpff/2V71heFvmaITs1NRU/Pz+D8qtXr2JmZoaPTDqYb1FJUay5soZvT3yrL9veeTuetp4G9bSxsbp5jczMcB4wABMnJ+wDAp5uTgjxIlMUSIk3zrnNrCEXN3+YmprSt29fli1bxvjx4/U3jKxZswaNRkPPnj2JjY2lVq1afPrpp9jb27Nlyxb69OlDuXLlqFu3bo7n0Gq1dOrUCTc3Nw4fPkxUVJTB+KQ0dnZ2LFu2DE9PT86ePcvgwYOxs7Pjk08+oXv37pw7d45t27axc+dOABwcHDK0ERcXR0BAAPXr1+fo0aM8ePCAd999l2HDhhkkgHv27MHDw4M9e/Zw7do1unfvTs2aNRk8eHCOryez15eWGP3zzz+kpqYydOhQunfvzt69ewHo3bs3r7zyCt9//z0mJiacOnUKs8d3Lg8dOpTk5GT+/fdfbGxsuHDhAra2tnmO42WT5+Sof//+DBw4MENydPjwYX766Sf9L0vkzbGQYwzYPsCgbHD1wRkSI3gyr5GJtTUlR40skviEEM+ZlHj4MuO/D0Xis3tgnrsxPwMHDmT27Nn8888/NG3aFNB1qXXu3BkHBwccHBwYM2aMvv7w4cPZvn07q1evzlVytHPnTi5dusT27dvx9NS9H19++SUtW7Y0qDdhwgT9cx8fH8aMGcPKlSv55JNPsLKywtbWFlNT02y70ZYvX05iYiK//PKLfszTggULaNu2LbNmzcLNzQ0AJycnFixYgImJCZUqVaJ169bs2rUrX8nRrl27OHv2LEFBQXg9ntT3l19+oWrVqhw9epQ6depw+/ZtPv74YypVqgRg8P18+/ZtOnfuTPXq1QEoW7ZsnmN4GeW5W+3kyZM0bNgwQ/lrr72WYSCbyF58SjzNVjej1q+1DBIjXwdf5r0xjw9fzbiIb2pEBNF/bQVAJZM9CiGec5UqVaJBgwb61ROuXbvGvn37GDRoEAAajYZp06ZRvXp1SpQoga2tLdu3b+f27du5av/ixYt4eXnpEyOA+vXrZ6i3atUqGjZsiLu7O7a2tkyYMCHX50h/Ln9/f4PB4A0bNkSr1XL58mV9WdWqVTExMdFve3h48ODBgzydK/05vby89IkRQJUqVXB0dOTixYuA7kapd999l+bNmzNz5kyuX7+ur/vhhx8yffp0GjZsyOTJkzlz5ky+4njZ5PnKkUqlIiYmJkN5VFQUGo2mQIIqji5EXGD47uF5OuZBfMY/lomvTaRbxW5ZHhP65Qyit2wBQF3Ad2sIIYoRM2vdFRxjnTsPBg0axPDhw1m4cCFLly6lXLlyNGnSBIDZs2fz7bffEhgYSPXq1bGxsWHEiBEkp5v5/1kdOnSI3r178/nnnxMQEICDgwMrV67k66+/LrBzpGf21GS8KpUKrVZbKOcC3Z12vXr1YsuWLWzdupXJkyezcuVKOnbsyLvvvktAQABbtmzh77//ZsaMGXz99dcMH56376uXTZ6To8aNGzNjxgxWrFihz4w1Gg0zZszg9ddfL/AAi4sUbUqmyU5uvFLyFabUn4KXvVeGSR6flvr4fx9WNWviPGRIvs4nhHgBqFS57toytm7duvHRRx+xfPlyfvnlF/7v//5PP/7owIEDtG/fnnfeeQfQjbG5cuUKVapUyVXblStXJjg4mPv37+Ph4QHAf//9Z1Dn4MGDeHt7M378eH3ZrVu3DOqYm5vn+B/8ypUrs2zZMuLi4vRXjw4cOIBaraZixYq5ijev0l5fcHCw/urRhQsXiIyMNHiPKlSoQIUKFRg5ciQ9e/Zk6dKldOzYEQAvLy/ef/993n//fcaNG8ePP/4oyVEO8pwczZo1i8aNG1OxYkUaNWoE6OariI6OZvfu3QUeYHHh5+jHqjar8nycjZkN3vbeua6fNt7IefC72L35Rp7PJ4QQRc3W1pbu3bszbtw4oqOj6d+/v36fn58fa9eu5eDBgzg5OTF37lxCQ0NznRw1b96cChUq0K9fP2bPnk10dLRBEpR2jtu3b7Ny5Urq1KnDli1bMiyF5ePjQ1BQEKdOnaJ06dLY2dlhYWFhUKd3795MnjyZfv36MWXKFMLCwhg+fDh9+vTRjzfKL41Gk2FoioWFBc2bN6d69er07t2bwMBAUlNT+eCDD2jSpAm1a9cmISGBjz/+mC5duuDr68udO3c4evQonTt3BmDEiBG0bNmSChUq8OjRI/bs2UPlypWfKdaXQZ6ToypVqnDmzBkWLFjA6dOnsbKyom/fvgwbNowSJUoURozFgrWZNVWcc/fHnFeKRkPC6dNo4xNIjdQt/CvjjYQQxcmgQYNYvHgxrVq1MhgfNGHCBG7cuEFAQADW1tYMGTKEDh06EBUVlat21Wo1GzZsYNCgQdStWxcfHx/mzZtHixYt9HXatWvHyJEjGTZsGElJSbRu3ZqJEycyZcoUfZ3OnTuzfv163njjDSIjI1m6dKlBEgdgbW3N9u3b+eijj6hTpw7W1tZ07tyZuXPnPtN7A7rpDV555RWDsnLlynHt2jX++OMPhg8fTuPGjVGr1bRo0YL58+cDYGJiQkREBH379iU0NBQXFxc6derE55/r1tzUaDQMHTqUO3fuYG9vT4sWLWSpr1xQKYqiGDuIohQdHY2DgwNRUVHY29sbO5xcCf/xR8K+NvzjK/PLz9jk4k4OIcSLITExkaCgIHx9fbG0tDR2OEIUiuw+50X5/Z3nK0dLly7F1taWrl27GpSvWbOG+Ph4WUKkEKQ8vqPCxNUFU2cXzEqXwsrf38hRCSGEEC+mPN/KP2PGDFxcXDKUlyxZki+//LJAghKG9OOM+g+g7MYNeC1YgPqpvnAhhBBCFIw8Xzm6ffs2vpkscOrt7Z3nOSNE1hRFITUkBEWjQROp63uXcUZCCCFE4ctzclSyZEnOnDmTYZmQ06dP4+zsXFBxvfQezJnDw8VLDMokORJCCCEKX56To549e/Lhhx9iZ2dH48aNAfjnn3/46KOP6NGjR4EH+LJKOH0aeJwQmZpiWqIENvVkALYQQghR2PKcHE2bNo2bN2/SrFkzTE11h2u1Wvr27csXX3xR4AG+rJRk3QrOpQIDZT4jIYQQogjlOTkyNzdn1apVTJ8+nVOnTmFlZUX16tXx9s79RIYiZ2mDsKUrTQghhChaeU6O0vj5+elX/o2Ojub7779n8eLFHDt2rMCCK04STp3iZu93Cq7Bx9PYq8yzX05ECCGEEAUr38kRwJ49e1iyZAnr16/HwcFBv47LS6uAF95VOzhgUb58gbYphBBCiOzlOTm6e/cuy5YtY+nSpURGRvLo0SOWL19Ot27d9AsJvowsq1Sh/L//FGibJg4OMp+REEI8xcfHhxEjRjBixAhjhyJeULmeBHLdunW0atWKihUrcurUKb7++mvu3buHWq2mevXqL3ViBLqxQWYlSxboQxIjIURxplKpsn2kX9ssL44ePcqQIUMKJMYVK1ZgYmLC0KFDC6Q98WLIdXLUvXt3XnnlFe7fv8+aNWto37495jJYWAghRBbu37+vfwQGBmJvb29QNmbMGH1dRVFITU3NVbuurq5YW1sXSIyLFy/mk08+YcWKFSQmJhZIm/mV/PhGHGF8uU6OBg0axMKFC2nRogWLFi3i0aNHhRmXEEKIYs7d3V3/cHBwQKVS6bcvXbqEnZ0dW7dupVatWlhYWLB//36uX79O+/btcXNzw9bWljp16rBz506Ddn18fAgMDNRvq1QqfvrpJzp27Ii1tTV+fn5s2rQpx/iCgoI4ePAgY8eOpUKFCqxfvz5DnSVLllC1alUsLCzw8PBg2LBh+n2RkZG89957uLm5YWlpSbVq1di8eTMAU6ZMoWbNmgZtBQYGGkyg3L9/fzp06MAXX3yBp6cnFStWBODXX3+ldu3a2NnZ4e7uTq9evXjw4IFBW+fPn6dNmzbY29tjZ2dHo0aNuH79Ov/++y9mZmaEhIQY1B8xYgSNGjXK8T0ROrlOjv73v/9x//59hgwZwooVK/Dw8KB9+/YoioJWqy3MGIUQQjxFURTiU+KN8lAUpcBex9ixY5k5cyYXL16kRo0axMbG0qpVK3bt2sXJkydp0aIFbdu2zXF5qs8//5xu3bpx5swZWrVqRe/evXn48GG2xyxdupTWrVvj4ODAO++8w+LFiw32f//99wwdOpQhQ4Zw9uxZNm3aRPnHN8lotVpatmzJgQMH+O2337hw4QIzZ87ExMQkT69/165dXL58mR07dugTq5SUFKZNm8bp06fZuHEjN2/epH///vpj7t69S+PGjbGwsGD37t0cP36cgQMHkpqaSuPGjSlbtiy//vqrvn5KSgq///47AwcOzFNsL7M8Dci2srKiX79+9OvXj6tXr7J06VKOHTtGw4YNad26NV26dKFTp06FFasQQojHElITqLe8nlHOfbjXYazNCqZba+rUqbz11lv67RIlSuDv76/fnjZtGhs2bGDTpk0GV22e1r9/f3r27AnAl19+ybx58zhy5AgtWrTItL5Wq2XZsmXMnz8fgB49ejB69GiCgoL064dOnz6d0aNH89FHH+mPq1OnDgA7d+7kyJEjXLx4kQoVKgBQtmzZPL9+GxsbfvrpJ4NhKumTmLJlyzJv3jzq1KlDbGwstra2LFy4EAcHB1auXImZmW66l7QYQNfTs3TpUj7++GMA/vzzTxITE+nWrVue43tZ5frK0dP8/Pz48ssvCQ4O5rfffiM+Pl7/wRRCCCFyo3bt2gbbsbGxjBkzhsqVK+Po6IitrS0XL17M8cpRjRo19M9tbGywt7fP0BWV3o4dO4iLi6NVq1YAuLi48NZbb7FkiW5NywcPHnDv3j2aNWuW6fGnTp2idOnSBklJflSvXj3D+N3jx4/Ttm1bypQpg52dHU2aNAHQvwenTp2iUaNG+sToaf379+fatWv8999/ACxbtoxu3bphY2PzTLG+TJ5pniMAtVpN27Ztadu2bbYfRCGEEAXHytSKw70OG+3cBeXpL+wxY8awY8cO5syZQ/ny5bGysqJLly45DlZ+OlFQqVTZDvlYvHgxDx8+xMrqyWvRarWcOXOGzz//3KA8MzntV6vVGbofU1JSMtR7+vXHxcUREBBAQEAAv//+O66urty+fZuAgAD9e5DTuUuWLEnbtm1ZunQpvr6+bN26lb1792Z7jDD0zMlReiVLlizI5oQQQmRBpVIVWNfW8+TAgQP0799fP6lwbGwsN2/eLNBzRERE8Mcff7By5UqqVq2qL9doNLz++uv8/ffftGjRAh8fH3bt2sUbb2Rc37JGjRrcuXOHK1euZHr1yNXVlZCQEBRF0U91c+rUqRxju3TpEhEREcycORMvLy+ADCtP1KhRg59//pmUlJQsrx69++679OzZk9KlS1OuXDkaNmyY47nFE/nuVhNCCCEKmp+fH+vXr+fUqVOcPn2aXr16FfhNP7/++ivOzs5069aNatWq6R/+/v60atVKPzB7ypQpfP3118ybN4+rV69y4sQJ/RilJk2a0LhxYzp37syOHTsICgpi69atbNu2DYCmTZsSFhbGV199xfXr11m4cCFbt27NMbYyZcpgbm7O/PnzuXHjBps2bWLatGkGdYYNG0Z0dDQ9evTg2LFjXL16lV9//ZXLly/r6wQEBGBvb8/06dMZMGBAQb11Lw1JjoQQQjw35s6di5OTEw0aNKBt27YEBATw6quvFug5lixZQseOHTOdvLhz585s2rSJ8PBw+vXrR2BgIN999x1Vq1alTZs2XL16VV933bp11KlTh549e1KlShU++eQTNI+XkapcuTLfffcdCxcuxN/fnyNHjhjM65QVV1dXli1bxpo1a6hSpQozZ85kzpw5BnWcnZ3ZvXs3sbGxNGnShFq1avHjjz8aXEVSq9X0798fjUZD37598/tWvbRUSi7vybxx40a+RuI/b6Kjo3FwcCAqKgp7e3tjhyOEELmSmJiov5PK0tLS2OGIYmDQoEGEhYXlas6n50V2n/Oi/P7O9ZijGjVq4OPjQ7t27Wjfvj316hnnFlIhhBBCZC0qKoqzZ8+yfPnyYpUYPU9y3a0WHh7OjBkzePDgAe3bt8fDw4PBgwfr508QQgghhPG1b9+et99+m/fff99gDimRe7nuVktPURQOHTrEpk2b2LRpE7dv36Z58+a0a9eOtm3b4urqWhixFgjpVhNCFEfSrSZeBs9Lt1q+BmSrVCoaNGjAzJkzuXDhAidPnqRRo0YsW7aM0qVLs3DhwoKOUwghhBCiSBTIPEd+fn6MHj2a0aNHExERkeN6NkIIIYQQz6sCnQQSdLcYOjs7F3SzQgghhBBFQuY5EkIIIYRIR5IjIYQQQoh0JDkSQgghhEgnz8lRcHAwd+7c0W8fOXKEESNG8MMPPxRoYEIIIQTo1ikbMWKEftvHx4fAwMBsj1GpVGzcuPGZz11Q7YjiJc/JUa9evdizZw8AISEhvPXWWxw5coTx48czderUAg9QCCFE8dS2bVtatGiR6b59+/ahUqk4c+ZMnts9evQoQ4YMedbwDEyZMoWaNWtmKL9//z4tW7Ys0HNlJSEhgRIlSuDi4kJSUlKRnFNkLs/J0blz56hbty4Aq1evplq1ahw8eJDff/+dZcuWFXR8QgghiqlBgwaxY8cOg96GNEuXLqV27drUqFEjz+26urpibW1dECHmyN3dHQsLiyI517p166hatSqVKlUy+tUqRVFITU01agzGlOfkKCUlRf9B2blzJ+3atQOgUqVK3L9/v2CjE0IIkSlFUdDGxxvlkduFFdq0aaNfZT692NhY1qxZw6BBg4iIiKBnz56UKlUKa2trqlevzooVK7Jt9+lutatXr9K4cWMsLS2pUqUKO3bsyHDMp59+SoUKFbC2tqZs2bJMnDiRlJQUAJYtW8bnn3/O6dOnUalUqFQqfcxPd6udPXuWN998EysrK5ydnRkyZAixsbH6/f3796dDhw7MmTMHDw8PnJ2dGTp0qP5c2Vm8eDHvvPMO77zzDosXL86w//z587Rp0wZ7e3vs7Oxo1KgR169f1+9fsmQJVatWxcLCAg8PD4YNGwbAzZs3UalUnDp1Sl83MjISlUrF3r17Adi7dy8qlYqtW7dSq1YtLCws2L9/P9evX6d9+/a4ublha2tLnTp12Llzp0FcSUlJfPrpp3h5eWFhYUH58uVZvHgxiqJQvnx55syZY1D/1KlTqFQqrl27luN7Yix5nueoatWqLFq0iNatW7Njxw6mTZsGwL179/I9v9HChQuZPXs2ISEh+Pv7M3/+fP3VqeysXLmSnj170r59e6Nn2UIIUZSUhAQuv1rLKOeueOI4qlxcuTE1NaVv374sW7aM8ePHo1KpAFizZg0ajYaePXsSGxtLrVq1+PTTT7G3t2fLli306dOHcuXK5ep7QKvV0qlTJ9zc3Dh8+DBRUVEG45PS2NnZsWzZMjw9PTl79iyDBw/Gzs6OTz75hO7du3Pu3Dm2bdum/+J3cHDI0EZcXBwBAQHUr1+fo0eP8uDBA959912GDRtmkADu2bMHDw8P9uzZw7Vr1+jevTs1a9Zk8ODBWb6O69evc+jQIdavX4+iKIwcOZJbt27h7e0NwN27d2ncuDFNmzZl9+7d2Nvbc+DAAf3Vne+//55Ro0Yxc+ZMWrZsSVRUFAcOHMjx/Xva2LFjmTNnDmXLlsXJyYng4GBatWrFF198gYWFBb/88gtt27bl8uXLlClTBoC+ffty6NAh5s2bh7+/P0FBQYSHh6NSqRg4cCBLly5lzJgx+nMsXbqUxo0bU758+TzHV2SUPNqzZ4/i6OioqNVqZcCAAfrycePGKR07dsxrc8rKlSsVc3NzZcmSJcr58+eVwYMHK46OjkpoaGi2xwUFBSmlSpVSGjVqpLRv3z7X54uKilIAJSoqKs+xCiGEsSQkJCgXLlxQEhISFEVRFE1cnHKhYiWjPDRxcbmO++LFiwqg7NmzR1/WqFEj5Z133snymNatWyujR4/Wbzdp0kT56KOP9Nve3t7KN998oyiKomzfvl0xNTVV7t69q9+/detWBVA2bNiQ5Tlmz56t1KpVS789efJkxd/fP0O99O388MMPipOTkxIbG6vfv2XLFkWtVishISGKoihKv379FG9vbyU1NVVfp2vXrkr37t2zjEVRFOWzzz5TOnTooN9u3769MnnyZP32uHHjFF9fXyU5OTnT4z09PZXx48dnui8oKEgBlJMnT+rLHj16ZPB72bNnjwIoGzduzDZORVGUqlWrKvPnz1cURVEuX76sAMqOHTsyrXv37l3FxMREOXz4sKIoipKcnKy4uLgoy5Yty7T+05/z9Iry+zvPV46aNm1KeHg40dHRODk56cuHDBmSrz7guXPnMnjwYAYMGADAokWL2LJlC0uWLGHs2LGZHqPRaOjduzeff/45+/btIzIyMs/nFUKI4kxlZUXFE8eNdu7cqlSpEg0aNGDJkiU0bdqUa9eusW/fPv0NPBqNhi+//JLVq1dz9+5dkpOTSUpKyvX3ycWLF/Hy8sLT01NfVr9+/Qz1Vq1axbx587h+/TqxsbGkpqbmefHSixcv4u/vj42Njb6sYcOGaLVaLl++jJubG6DrYTExMdHX8fDw4OzZs1m2q9Fo+Pnnn/n222/1Ze+88w5jxoxh0qRJqNVqTp06RaNGjTAzM8tw/IMHD7h37x7NmjXL0+vJTO3atQ22Y2NjmTJlClu2bOH+/fukpqaSkJDA7du3AV0XmYmJCU2aNMm0PU9PT1q3bs2SJUuoW7cuf/75J0lJSXTt2vWZYy1MeR5zlJCQQFJSkj4xunXrFoGBgVy+fJmSJUvmqa3k5GSOHz9O8+bNnwSkVtO8eXMOHTqU5XFTp06lZMmSDBo0KMdzJCUlER0dbfAQQojiTqVSoba2NsojrXsstwYNGsS6deuIiYlh6dKllCtXTv9lOnv2bL799ls+/fRT9uzZw6lTpwgICCA5ObnA3qtDhw7Ru3dvWrVqxebNmzl58iTjx48v0HOk93QCo1Kp0Gq1Wdbfvn07d+/epXv37piammJqakqPHj24desWu3btAsAqm4Q0u32g+14FDMaKZTUGKn3iBzBmzBg2bNjAl19+yb59+zh16hTVq1fXv3c5nRvg3XffZeXKlSQkJLB06VK6d+9eZAPq8yvPyVH79u355ZdfAN2Arnr16vH111/ToUMHvv/++zy1FR4ejkaj0Wfbadzc3AgJCcn0mP3797N48WJ+/PHHXJ1jxowZODg46B9eXl55ilEIIcSz6datG2q1muXLl/PLL78wcOBAfYJ14MAB2rdvzzvvvIO/vz9ly5blypUruW67cuXKBAcHG9wQ9N9//xnUOXjwIN7e3owfP57atWvj5+fHrVu3DOqYm5uj0WhyPNfp06eJi4vTlx04cAC1Wk3FihVzHfPTFi9eTI8ePTh16pTBo0ePHvqB2TVq1GDfvn2ZJjV2dnb4+PjoE6mnubq6Ahi8R+kHZ2fnwIED9O/fn44dO1K9enXc3d25efOmfn/16tXRarX8888/WbbRqlUrbGxs+P7779m2bRsDBw7M1bmNKc/J0YkTJ2jUqBEAa9euxc3NjVu3bvHLL78wb968Ag8wvZiYGPr06cOPP/6Ii4tLro4ZN24cUVFR+kdwcHChxiiEEMKQra0t3bt3Z9y4cdy/f5/+/fvr9/n5+bFjxw4OHjzIxYsXee+99wgNDc11282bN6dChQr069eP06dPs2/fPsaPH29Qx8/Pj9u3b7Ny5UquX7/OvHnz2LBhg0EdHx8fgoKCOHXqFOHh4ZnOM9S7d28sLS3p168f586dY8+ePQwfPpw+ffpk+E9+boWFhfHnn3/Sr18/qlWrZvDo27cvGzdu5OHDhwwbNozo6Gh69OjBsWPHuHr1Kr/++iuXL18GdPM0ff3118ybN4+rV69y4sQJ5s+fD+iu7rz22mvMnDmTixcv8s8//zBhwoRcxefn58f69es5deoUp0+fplevXgZXwXx8fOjXrx8DBw5k48aNBAUFsXfvXlavXq2vY2JiQv/+/Rk3bhx+fn6Zdns+b/KcHMXHx2NnZwfA33//TadOnVCr1bz22msZMvGcuLi4YGJikuEPITQ0FHd39wz1r1+/zs2bN2nbtq3+0uMvv/zCpk2bMDU1NbilMY2FhQX29vYGDyGEEEVr0KBBPHr0iICAAIPxQRMmTODVV18lICCApk2b4u7uTocOHXLdrlqtZsOGDSQkJFC3bl3effddvvjiC4M67dq1Y+TIkQwbNoyaNWty8OBBJk6caFCnc+fOtGjRgjfeeANXV9dMpxOwtrZm+/btPHz4kDp16tClSxeaNWvGggUL8vZmpPPLL79gY2OT6XihZs2aYWVlxW+//YazszO7d+8mNjaWJk2aUKtWLX788Ud9F16/fv0IDAzku+++o2rVqrRp04arV6/q21qyZAmpqanUqlWLESNGMH369FzFN3fuXJycnGjQoAFt27YlICCAV1991aDO999/T5cuXfjggw+oVKkSgwcPNri6Brrff3Jysn588fNOpSi5nLDisRo1avDuu+/SsWNHqlWrxrZt26hfvz7Hjx+ndevWWXaHZaVevXrUrVtXn+FqtVrKlCnDsGHDMgzITkxMzDAvwoQJE4iJieHbb7+lQoUKmJubZ3u+6OhoHBwciIqKkkRJCFFsJCYmEhQUhK+vL5aWlsYOR4g82bdvH82aNSM4ODjbq2zZfc6L8vs7z3erTZo0iV69ejFy5EjefPNN/eWxv//+m1deeSXPAYwaNYp+/fpRu3Zt6tatS2BgIHFxcfrssm/fvpQqVYoZM2ZgaWlJtWrVDI53dHQEyFAuhBBCCONKSkoiLCyMKVOm0LVr13x3Pxa1PCdHXbp04fXXX+f+/fv4+/vry5s1a0bHjh3zHED37t0JCwtj0qRJhISEULNmTbZt26Z/A2/fvq0faS+EEEKI4mPFihUMGjSImjVr6m/mKg7y3K2WXtp6OaVLly6wgAqbdKsJIYoj6VYTL4PnpVstz5dktFotU6dOxcHBAW9vb7y9vXF0dGTatGnZzuMghBBCCFEc5Llbbfz48SxevJiZM2fSsGFDQDf30JQpU0hMTMxwl4AQQoiC8wwX+4V47j0vn+88J0c///wzP/30E+3atdOX1ahRg1KlSvHBBx9IciSEEIUgbTmK5OTkXM1KLERxlDbzdvrlV4whz8nRw4cPqVSpUobySpUq8fDhwwIJSgghhCFTU1Osra0JCwvDzMxMblQRLxytVktYWBjW1taYmuY5PSlQeT67v78/CxYsyDAb9oIFCwzuXhNCCFFwVCoVHh4eBAUF5XnCXSGKC7VaTZkyZfK8fl9By3Ny9NVXX9G6dWt27typn+Po0KFDBAcH89dffxV4gEIIIXTMzc3x8/MrtAVThTA2c3Pz5+KqaL5u5b937x4LFy7k0qVLgG4xvg8++MBgSvjnldzKL4QQQhQ/Rfn9/UzzHKV3584dpk6dyg8//FAQzRUaSY6EEEKI4ue5nucoKxERESxevLigmhNCCCGEMArjd+wJIYQQQjxHJDkSQgghhEhHkiMhhBBCiHRyfSt/p06dst0fGRn5rLEIIYQQQhhdrpMjBweHHPf37dv3mQMSQgghhDCmXCdHS5cuLcw4hBBCCCGeCzLmSAghhBAiHUmOhBBCCCHSkeRICCGEECIdSY6EEEIIIdKR5EgIIYQQIh1JjoQQQggh0pHkSAghhBAiHUmOhBBCCCHSkeRICCGEECIdSY6EEEIIIdKR5EgIIYQQIh1JjoQQQggh0pHkqKDcPwNLW8PqfsaORAghhBDPwNTYAbwwtClwaz/YlzZ2JEIIIYR4BnLlqKBYOel+JjwybhxCCCGEeCaSHBWUtOQoJQ5Sk4wbixBCCCHyTZKjgmLhAKrHb2dCpFFDEUIIIUT+SXJUUNRqsHTUPZeuNSGEEKLYkuSoIKV1rcVHGDcOIYQQQuSbJEcF5OydKM7E2Oo2ou4YNxghhBBC5JskRwVEQeFCwuMrR49uGjUWIYQQQuSfJEcFxNnWgttKSQCURzeMHI0QQggh8kuSowLibGPOdaUUANp7Z40cjRBCCCHyS5KjAmJpZsJls0oAqMMuQGK0kSMSQgghRH5IclSAVHbuBGndUKHAtR3GDkcIIYQQ+SDJUQHydbFhi/Y13caxpaAoxg1ICCGEEHkmyVEB8nOzZaXmTVJU5nBzHxxbbOyQhBBCCJFHkhwVoBqlHLmjuPKLWTddwZbR8NfHEP/QuIEJIYQQItckOSpAr/u5YKpWMS26JeE13tcVHvkB5tWEvTMhTmbOFkIIIZ53khwVIAcrMwKquQMqRjzshKbXOihZFRKjYO8MCKwGf30Cj24ZO1QhhBBCZEGSowI2snkFLM3U7L8WTs89NlxotwW6LAUPf0iJhyP/g3mvwLp34cElY4crhBBCiKeoFOXluqUqOjoaBwcHoqKisLe3L5Rz7LoYyvAVJ4lP1gDwZqWSDGzgQ0OT86gOfgvXdz+uqYKqHaDxx+BWtVBiEUIIIV4ERfH9nUaSo0JyKyKOr7Zf5q+z9/V39Fd0s2PQ67508AjH/MDXcPHPJwdU6wzNJoOTd6HFJIQQQhRXkhwVoqJ8cwGCwuNYdiCINcfv6K8kudpZ0L+BD33KxmJ/JBDObwQUMLGA1/4PGo0CS4dCj00IIYQoLiQ5KkRFnRyliUpIYdXR2yw9cJP7UYkAWJub0K22F+9XjMP9v2kQ9K+usrULvDEOXu0PJqZFFqMQQgjxvJLkqBAZKzlKk6LRsvnMPX74N4iL93Xrr5mqVfSs48Vonxs47p8GEVd1lV0qwtvTwe8tUKmKPFYhhBDieSHJUSEydnKURlEUDlyLYNE/19l/LRwASzM1g+p7Mcx+P1YHZkHC48kjyzbVJUnu1Y0WrxBCCGFMkhwVouclOUrvvxsRfLXtEiduRwK6+ZI+aeJGj6Q1mBz5H2iSARW80hvenAh27kaNVwghhChqkhwVoucxOQLdlaSdFx8we/slroTGAlDW1YbpTWypH7QQ1fn1uopmNtDwI2gwHMytjRixEEIIUXQkOSpEz2tylEajVVh1NJiv/75MRFwyAI38XJheKwHvY9PhzlFdRTtPaD4ZqncDtczlKYQQ4sUmyVEhet6TozTRiSks3HONpftvkqzRolZBr7pefOp1Ebt90yHqtq6i5ysQ8CV4NzBuwEIIIUQhkuSoEBWX5CjNrYg4Zvx1iW3nQwCwszRlZJMy9DXZiun+uZAco6tYuR28NRVK+BoxWiGEEKJwSHJUiIpbcpTmvxsRTNt8gfP3dLf/eztbM+VNV5re+wnViZ9B0YKJOdR7DxqNAStH4wYshBBCFCBJjgpRcU2OQDcead3xO8z++zJhMUkAvFa2BNMbqCl/Ygbc2KOraO0MTcdBrQEyiaQQQogXgiRHhag4J0dpYpNS+X7vNX7cF0RyqhaVCrrXKs1Yv2Ac930O4Vd0FV0qQsAXUL65TCIphBCiWJPkqBC9CMlRmuCH8czadonNZ+4DYGNuwvCm3gyy2ofZvzOeTCJZ7k14+wtwq2LEaIUQQoj8k+SoEL1IyVGaYzcfMm3zBU7fiQKgtJMVE5uV4u2IX1EdXgTaFFCp4dV+8MZnYFvSyBELIYQQeSPJUSF6EZMjAK1WYeOpu3y17TIh0bqFbev4ODGtsQ2Vzs6Bi5t0Fc3toNEoeO0DMLM0YsRCCCFE7klyVIhe1OQoTXxyKv/75wb/+/c6iSlaADq9WorxVSNxPjAF7p3UVXQoA29OgOpdQG1ivICFEEKIXJDkqBC96MlRmvtRCXy17TIbTt4FwMrMhP9r4sv7Tscx3zsNYu7pKrpW1nW1VW4rg7aFEEI8tyQ5KkQvS3KU5lRwJFP/PK9f1NbDwZJP3ixD+6RNqA9+C4m6cUp41IQ3xoPfW5IkCSGEeO5IclSIXrbkCHSL2v555j6ztl7ibmQCAJU97JnY3JMGoSvgv+8hWbfYLe41oNFo3YzbsmabEEKI54QkR4XoZUyO0iSmaFh28CYL91wjJjEV0C1qO/GNklS4+hMcWwopcbrKLhXg9ZFQvSuYmBkxaiGEEEKSo0L1MidHaR7GJTN/91V+++8WKRoFlQo6v1qaMY1ccL/4Mxxe9KS7zaEMNPwQ/HuCha1xAxdCCPHSKsrv7+ei32ThwoX4+PhgaWlJvXr1OHLkSJZ1f/zxRxo1aoSTkxNOTk40b9482/oioxI25kxuW5Wdo5rQuoYHigJrj9+hyYIzTIlpz4NBx6H552DjClG34a8x8E0V+HsiRAYbO3whhBCiUBk9OVq1ahWjRo1i8uTJnDhxAn9/fwICAnjw4EGm9ffu3UvPnj3Zs2cPhw4dwsvLi7fffpu7d+8WceTFn7ezDQt7vcqGDxpQ16cESalalh28yevfHmNyRHPuDzwCreZAibK6K0kH58G3/rC6H9w+DC/XRUchhBAvCaN3q9WrV486deqwYMECALRaLV5eXgwfPpyxY8fmeLxGo8HJyYkFCxbQt2/fHOtLt1rmFEVh/7Vwvt15lWO3HgFgbqKmex0v/q+JL54P/oX/voOgf58c5Pkq1B4I1TqBuY2RIhdCCPEyeGm61ZKTkzl+/DjNmzfXl6nVapo3b86hQ4dy1UZ8fDwpKSmUKFEi0/1JSUlER0cbPERGKpWKRn6urHm/Pr+/W4+6PiVI1mj59b9bNJnzD2POeHKlxXJ4/wC88g6YWMC9E7BpGHxdGf76GEIvGPtlCCGEEM/MqMlReHg4Go0GNzc3g3I3NzdCQkJy1cann36Kp6enQYKV3owZM3BwcNA/vLy8njnuF5lKpaJheRdWv1+fFYNf47WyJUjRKKw9foe3v/mXAVvjOVRtKsrIc9B8Cjj5QFIUHPkBvq8Pi9+GUysgJcHYL0UIIYTIF6OPOXoWM2fOZOXKlWzYsAFLy8zXCRs3bhxRUVH6R3CwDCjOrfrlnFk5pD7rP2hAi6ruqFSw53IYPX/8jw7LrrDZvjupQ49Dnw2P50UyheDDsPF9+LoibB4JwUdlbJIQQohixdSYJ3dxccHExITQ0FCD8tDQUNzd3bM9ds6cOcycOZOdO3dSo0aNLOtZWFhgYWFRIPG+rF4t48SiPrUICo/jp303WHv8DqfvRDFs+UlKO1nR5zVvurddjGOrh3DyNzjxM0TehmNLdA/n8rqpAPx7gENpY78cIYQQIlvPxYDsunXrMn/+fEA3ILtMmTIMGzYsywHZX331FV988QXbt2/ntddey9P5ZED2swuPTeKXQ7f49dBNHsWnAGBhqqZDzVL0beBNVXc7uPmvrnvt4iZIiX98pAp8G+sSpcptZd4kIYQQufZSTQK5atUq+vXrx//+9z/q1q1LYGAgq1ev5tKlS7i5udG3b19KlSrFjBkzAJg1axaTJk1i+fLlNGzYUN+Ora0ttrY5f9lKclRwEpI1bDp9l2UHb3Hx/pOB7nV8nOhb34cW1dwxS42DC5vg9Aq4ue/JwaZWULEFVO2kW8/NzMoIr0AIIURx8VIlRwALFixg9uzZhISEULNmTebNm0e9evUAaNq0KT4+PixbtgwAHx8fbt26laGNyZMnM2XKlBzPJclRwVMUheO3HrHs4E22nQshVav7SJW0s6BbbS+61/HCq4Q1PLoFZ1bpEqWHN540YG4HlVpBtc5Q9g0wNTfSKxFCCPG8eumSo6IkyVHhCo1OZPnh2yw/cpuwmCQAVCp4vbwLPeqU4a0qbpibqOD+KTi3Ds5tgOg7TxqwdNR1uVXrBD6NZF03IYQQgCRHhUqSo6KRnKrl7wshrDwSzP5r4fpyZxtzOtcqTfc6XpRztQWtFu4chfPr4fwGiE03ON/SESq2gsptoNyb0vUmhBAvMUmOCpEkR0Uv+GE8q44Gs/pYMA8eX00CqOtbgu61vWhRzR0bC1PQauDWATi3XjeQOz7iSSNm1lC+GVRqCxUCwMqx6F+IEEIIo5HkqBBJcmQ8qRotey6HsfLIbfZcfsDjoUlYm5vQopo7XV4tzWtlnVGrVaBJheD/4OJmuLQZotLNT6U21d31VqkNVGoNdtlP+yCEEKL4k+SoEEly9Hy4H5XA2mN3WHfiDjcj4vXlng6WdHilFJ1rldZ1u4FuEsn7p54kSmGXDBvzqKm7muQXAJ6vgLpYz20qhBAiE5IcFSJJjp4viqJw4vYj1p24y+bT94hOTNXv8/dypMurpWhTwxMnm3R3sIVfg0t/6pKlu8cMG7RxBb+3dY9yb4Kl/I6FEOJFIMlRIZLk6PmVmKJh18UHrDtxh3+uhKF53O9mZqKiSYWStPX34K0qblibp5vYPfYBXN0BV7fDtd2QHPNkn9oUvBvorihVCNDN1K1SFfGrEkIIURAkOSpEkhwVD2ExSfxx6i7rT9zlQroJJq3MTGhexY12/p40ruCChanJk4NSk+H2Ibj6N1zZBhHXDBt1LKO7mlT2Dd2YJesSRfRqhBBCPCtJjgqRJEfFz+WQGDadvsufp+9z++GT8Un2lqa0qOZOO/9SvFa2BKYmT401irj+JFG6eQC0KU/2qdS68UlpyVLpOjL5pBBCPMckOSpEkhwVX4qicPpOFH+evsfmM/cIjX4yLYCLrTmtq3vQ1t+TV8s46e54Sy8pFm4dhOu74caejIO6zW11k06WewPKNgWXCtIFJ4QQzxFJjgqRJEcvBo1W4UjQQ/48c4+tZ+/rF8AF3bIlAVXdaVnNnbq+mVxRAoi6Czf2PkmW0s+pBLqB3d4Nwed1XdLkWlGSJSGEMCJJjgqRJEcvnhSNlv3Xwvnz1D12XAglJunJHW8lbMx5q7IbLaq707CcC+ammSRKWi2EntUlStf3QPBhSE00rGPt8jhRevxwrSTJkhBCFCFJjgqRJEcvtqRUDQevRbD13H12XAg1uKJkZ2lK88putKjmTpMKrliamWTeSGoS3D0BN/fDzX0QfARSEwzrWLuAd33wqqd7ePiDqUUhvjIhhHi5SXJUiCQ5enmkarQcDnrI1nP32X4+VL8QLuhm5W5a0ZVmldx4o1JJSthkMxg7LVm6tV+XMN0+nDFZMjHXTUbpVfdxwlRXZu4WQogCJMlRIZLk6OWk1Socv/2IrWdD2H4+hLuRT5IbtQpqeTvRrLIbzSuXpJyrLarsusxSk+Hucd3yJsFHdd1w8eEZ6zmW0SVKpetCqVfBraosniuEEPkkyVEhkuRIKIrC2btR7LwQyo6LD7iYbh4lAB9na5pVdqNZ5ZLU8SmBWWYDug0bhIc34M7jRCn4CDy4AIrWsJ7aFFwrg2dN3TQCnq/oEibpjhNCiBxJclSIJDkST7sbmcDui7pE6b/rESRrniQ19pamNK7gSpPHj5L2lrlrNDFad3XpzlHd495JiAvLWE9tpkuQ0hIm9xq6wd7m1gXz4oQQ4gUhyVEhkuRIZCc2KZX9V8PYceEBey4/4GFcssH+Su52+kSplo+T4Qzd2VEUiL6nS5LSPxIeZqyrUkOJcrqkya0auFXRPXf0ljvkhBDFysKFC5k9ezYhISH4+/szf/586tatm2nd8+fPM2nSJI4fP86tW7f45ptvGDFihH5/2vf3nDlzmD9/fpZthoSE8PHHH7Njxw5iYmKoWLEi48ePp3PnzrmOW5IjIbKg0SqcCn7E3sth/HsljDN3o0j/12JlZkL9cs40qeBK4wqu+DhbZz9W6WmKAlHBhslSyLnMxy8BmNs9SZRKVtFNVOlaEWzdJGkSQjx3Vq1aRd++fVm0aBH16tUjMDCQNWvWcPnyZUqWLJmh/tGjR1m9ejW1atVi5MiRfPrpp5kmR+bm5tm2+fbbbxMZGcmCBQtwcXFh+fLlTJ48mWPHjvHKK6/kKnZJjoTIpYdxyey7GsY/V8L490o44bFJBvtLO1lRv6wzDco7U7+sC+4OueyCe1rsAwg9B6HnHz/OQdhl0CRnXt/CAVz8HidLFcClou65kw+YmGZ+jBBCFLJ69epRp04dFixYAIBWq8XLy4vhw4czduzYbI/18fFhxIgRmSZHgwcP5ocffsiyTVtbW77//nv69OmjP9bZ2ZlZs2bx7rvv5ip2+ZdTiFwqYWNO+5qlaF+zFFqtwsWQaP69Es6/V8I4dushdx4lsOb4HdYcvwNAWRcb6pdzpn45Z14r64yLbS4HXtuWBNs3deu+pdGk6BbSDT0PIWd1yVL4ZXh0E5Ki4O4x3SM9tRk4lwPn8lDCF5x8n/x08JLESQhRaJKTkzl+/Djjxo3Tl6nVapo3b86hQ4fy3SZA06ZNs22zQYMGrFq1itatW+Po6Mjq1atJTEw0OC4n8q+jEPmgVquo6ulAVU8H/q9pOeKSUjl68yGHrkdw6EYEZ+9GcSM8jhvhcfx++DagG6/0WlldolTHxwnn3CZLACZmULKy7lG9y5Py1CTdArvhV548wi7rEqmUeN0ack+vIwe6O+ccyxgmTCV8dVebHLzAUq6qCiHyLzw8HI1Gg5ubm0G5m5sbly5l8m9SLkRE6JZ5erpL7uk2V69eTffu3XF2dsbU1BRra2s2bNhA+fLlc30uSY6EKAA2FqY0rViSphV1f7RR8SkcDtIlSoeuR3ApJEb/WHbwJqC7slTbx4na3iWo7eOEr4tN3sYsgW4aALcqukd6Wi1E34GwK7ppBh7egEdB8DBId7VJk/Sk/Hom7Vo66JIkh9KPH15Pfjp66cY5qXM5GF0IIYrQxIkTiYyMZOfOnbi4uLBx40a6devGvn37qF69eq7akORIiELgYG3G21XdebuqbpbsiNgk/rvxkIPXwzl68yFXQmP1V5ZWH9N1wznbmFPL24k6PrpkqaqnQ+ZrweWGWq27MuRYJuM+rRZi7j+VMKVLnBIjITFK9wg9l0X7pmDvCfaldDOB23k8+Wnr9mTbwk4GiwvxEnJxccHExITQ0FCD8tDQUNzd87d6gLOzMwAPHjzIss3r16+zYMECzp07R9WqVQHw9/dn3759LFy4kEWLFuXqXJIcCVEEnG0taF3Dg9Y1PACIjE/mxO1HHL35iOM3H3HqTiQRccn8fSGUvy/o/jGxMFVT1dOeml5O+Hs5UNPLkTIl8nhHXGbUanAopXv4Nsq4PykGou5C1B3d3XRRwY+f34HIYIi+C9pUiLyte2THzOZx0vT4YesONi6PH666NerSts1tJZES4gVhbm5OrVq12LVrFx06dAB0g6d37drFsGHD8t0mwD///EOvXr0ybTM+Ph7QjUVKz8TEBK32qYl5syHJkRBG4GhtzpuV3Hizkq4/PilVw7m7URy9+YhjNx9x7NZDIuNTOHE7khO3I9MdZ4Z/aUf8vRyp6eWAf2nHvI1dyg0LOyhZSffIjFYDMSG6pCnmvu65wc9Q3fOkKEiJg4fXdY+cmFoaJks2rmDtrHtu7QxWTmDpqPuZ9jCzkoRKiOfUqFGj6NevH7Vr16Zu3boEBgYSFxfHgAEDAOjbty+lSpVixowZgG7A9YULF/TP7969y6lTp7C1tTUYL/Tzzz/ToEGDTNusVKkS5cuX57333mPOnDk4OzuzceNGduzYwebNm3Mdu9zKL8RzSKtVCIqI48ydSE4HR3EqOJIL96INZu9OU9rJimqeDlT1tKdqKXuqeDjgZm/x7FeYnlVy3OOE6XHSFPs4aYqP0M0WHhf++BGWcSHf3DIxf5IoGSROjk/KLO3Bwl6X9KU9LB10P2XpFiEK1YIFC/STQNasWZN58+ZRr149QHfXmY+PD8uWLQPg5s2b+Pr6ZmijSZMm7N27V//9PXv2bP0kkE+3CXD16lXGjh3L/v37iY2NpXz58owZM8bg1v6cSHIkRDGRnKrlUkg0p4MjORUcxek7kVx7EJtpXWcbc6p42lPF056qng5U8bDH18UGE/VzepUlOe5JshQfni55evwz4dGTR2Kk7qc29dnPa2L+OGGyN/xpmS6ZMrcFcxsws07301rXZWhubVhuZq3rthRCFDhZPqQQSXIkXiTRiSmcuxPF+XvRXLgfzfl7UVwPi0OjzfhnbWVmQiUPOyq62VEh7eFui6vtc3CVKa8UBZJjHydMkZknT2n7kmIgKfrxz8eP5MyTygKRliRlmkBZ6boPTS3A1Orxz8fbZk9tG+y3BDPLdPvSPVebSteieClIclSIJDkSL7rEFA2XQ2IeJ0y6xOnS/RgSUjSZ1ne0NnucLNlS0c0OPzddAuVkY17EkRchrcYwWdInT49/JqZLppJjIDleN29Uctzjn/G68VRp5SnxRnwxKt0VMBNz3XxYBs/NMinL5XO1mW6iUHX6h0nW2yqTnOtkOEat21apHz9Uunb025nsFy8tSY4KkSRH4mWk0SoEhcdx4X40V0NjuBIaw5XQWG5GxJHVvwAuthaUL2lDWVdbyrrYUNbVhrIutpR2ssLURLqODGi1unFTTydN+mTq8c+UBEhN1E3emZoIKYmG26mJuduf1VIyL4MskyfV45+Z7X+8D9XjBCvdT8hDGfk49qljMpQ9Rf8HqRhpmzzWz2LbvTp0XZrh5T2Lovz+lrvVhHgJmKhVlC9pS/mStgbliSkarj2I1SdLVx4nTnceJRAem0T44/mZ0jMzUVGmhLUuaXK1eZw46RKoEjbmxa+LriCo1bpuM3MbwLXwz6fV6ibyTEnQjb3SJD9+pOTw/OmyrMqTde1rtbr2DR6aAtpOAUWre+SFotE9xPPNysnYETwTSY6EeIlZmplQrZQD1Uo5GJTHJaVy9UEs1x/EEhQex43wWG6ExREUHkdSqpbrYXFcD4vL0J6dpSllSlg/eTg/ee7paIWZXHEqGGo1qK1045ReBIqiS5K0micJk6J9nAhpC25/2nMUwyseuS4jb8emvbZsy9JJf1WpwLZzW5cc9mezndk+c8P/iBU30q0mhMg1rVbhXlSCPlG6EfZ4pu+wOO5FJWTZRQegVoGnoxXejxMmr8dJk5eTLnFysX1JrzoJIXJFxhwVIkmOhCgciSkagh/Gc/thPLcidD/Ttm8/jCcpNfvuE3NTNZ4Olng6WukfpRzTbTtYYWUu67kJ8bKSMUdCiGLH0swEv8d3uz1Nq1UIi03SJUrpEqdbD+O5+yiB0JhEklO13IyI52ZE1nd+OduYP06WLPFwsMLN3hI3ewvc7S0p+fi5naVZYb5MIUQeLFy4UD8JpL+/P/Pnz6du3bpZ1l+zZg0TJ07k5s2b+Pn5MWvWLFq1amVQ5/Lly0ybNo1//vmH1NRUqlSpwrp16yhTxnAtSUVRaNWqFdu2bWPDhg36ZUxyQ5IjIUShU6tVjxMZS+r4lMiwP0WjJSQqkXuRCdyLSuBeZCJ3IxN025EJ3H2UQFyyhoi4ZCLikjl7NyrLc9mYm+Bmb0nJx0mT2+PEyf1x8pS2z8JUrkIJUZhWrVrFqFGjWLRoEfXq1SMwMJCAgAAuX75MyZIlM9Q/ePAgPXv2ZMaMGbRp04bly5fToUMHTpw4QbVq1fT1AgICePfdd/n888+xt7fn/PnzWFpaZmgvMDAw31310q0mhHjuKYpCdGKqPlm6F5nA3chEHsQkEhqdSGh0EqHRicQk5n7WbHtLU1zsLHCxtcDV1gJnW3NcbC0eP8xxsdOVu9haSHeeEPlQr1496tSpw4IFCwDdIrFeXl4MHz6csWPHZqjfvXt34uLiDNZAe+2116hZsyaLFi3Sf393796dlStXZnvuU6dO0aZNG44dO4aHh4dcORJCvHhUKhUOVmY4WJlR2SPr/9TEJaXyICbpccL0JHEKiU7kQXQiIY+3k1O1RCemEp2Yyo1M7rp7mo25Cc5pSZOthT6pKmFthpONOSVszHGy1v0sYWOOpZkkU+LllpyczPHjxxk3bpy+TK1W07x5cw4dOpTpMYcOHWLUqFEGZQEBAWzcuBHQJVcA5cuXJyAggJMnT+Lr68u4ceMMEp/4+Hh69erFwoULcXd3z1f8khwJIV4YNham+FqY4utik2UdRVGIjE8hIi6JsJhk/XxO4bFJhBtsJxMWq0uk4pI1xD0eWJ4blmZqSlibGyROTpkkUo7WZvptSajEiyQ8PByNRoObm5tBuZubG5cuXcr0mJCQkEzrh4SEABAWFgbAN998w/Tp05k1axbbtm2jU6dO7NmzhyZNmgAwcuRIGjRoQPv27fMdvyRHQoiXikqlwslGl7iUzzjswYCiKMQmpRIe+zhpitElTmGPtyPjk3kYl8yjuBQexSfzKD6ZFI1CYoqWe1GJ3ItKzHVcFqZq/dWx9A/7dM8drTPfL4mVeBmkXTn6//buPSiq8wwD+LN3drkrcjNAIBi8oTYa6cZbU5gAOmmS2olJmZSkrVajqWkSG2NMMJ3pmLFt0k4mpU3b6D+pTEy9tSqtATHVookOCERC1NLSNgJGBJbbwu6+/WPZ4x5hjcaF5fL8ZnY4e75vz37fO2eXZ86es7t06VL86Ec/AgDMmTMH//jHP/Cb3/wGS5Yswf79+1FaWoqKiopbei6GIyIiHzQaDUKDDAgNMlz3aJSHJ0xd6exDS39YutLZH6C6etHS2Xc1UPXfv9LVC6dLYHe40Gyzo9lmv+lx+gpWoUF6hATp++egR4hJj7AgQ/869/oQk3u9TsvvmCL/iYqKgk6nQ1NTk2p9U1OTz4+6YmNjr9t/4sSJAICpU6eq+kybNg3Hjh0DAJSWluLChQuIiIhQ9Vm+fDkWLVqEsrKyGxo/wxERkZ94h6nEiZYbeoyIwGZ3oK2rD23dfWjvdv/13Fq9lq9ta+/ug0twS8HKI9iouxqiPIHKpFdClXdbWJAeISYDLCYdQkx6WIyev3oY9fwWdAKMRiPmzp2LkpIS5Xwgl8uFkpISrFu3btDHWK1WlJSU4Omnn1bWHT58GFarVdkmAJw7d071uE8//RRJSUkAgI0bN+L73/++qj09PR2vv/467r///hseP8MREVEAaTQahAUZEBZkQMJNPtblEnT0qoNVq1dw6rA7YOtxoL2nDx097mX3uj7Yehyw2R3o7f9yzs5eJzp7nWhsv7X5GHVaWEw6BBv1CDbpEGzSX1026hFs0rtDlVEPi0mPEJMOFqNeCVnBJn3/zd3fYtTxm9NHqWeeeQb5+fmYN28e5s+fj1/+8pfo7OzEE088AQD4zne+g8mTJ2Pr1q0AgPXr12PJkiX4xS9+gWXLlqGoqAinTp3CW2+9pdru7t278bvf/Q733nsviouL8ec//1k5IhQbGzvokanExEQkJyff8NgZjoiIRimt9ssHKw+7w+kOTf3hyWbvD049DnT0h6gOu/vKPlvP1cDV0eNAZ68DnXYHOnudSsjqdbrQ2+VCa1efX+ao0QAWgw5mox5moxYWgx5mow5mgw4Wo+6aZf2g64OMOlgM7hBmNmphNur7t6mDSa9l+BoiK1aswKVLl/Dyyy+jsbERc+bMQXFxsXLSdUNDA7Taq0ca77nnHvzxj3/E5s2bsWnTJkyZMgV79+5VfccR4D4he9u2bfjhD3+ItLQ0/OlPf8LChQv9OnZ+zxEREd2yPqcLXXYnOnod6LK7A1VXr7P/rwMddie6+oNU5zXrPH3dQcuBTrsTnb2O6/5Wn79oNYC5Pyh5ApV3ePKsCzJo+/+6bya9VlkOMmgRpPda7v9rumYdf3j51vDnQ4iIaFQx6LQIt2gRbvHPz7eICLr7nO6gZHegu8+Jrl4nunud/csOr2Wnarmnv/3qsnNA316n+0iXS65+pDjUdFoNgrxClUkVuK4GLJMnYOnVYcuzztNu0rsDmMmghVGnVQKZSa+Fsb/NqNfyZPsvgeGIiIhGHI1GA4vRfZL3pFCT37fvcLrQ3ecOTN29/aFpwLJDWe7pc8He5w5bPX0u9Di8lq+z3vsHl50uGbYg5s2g0yhByaTcvO73hyqjzrM8MGR51hu92gZr9zzW0v/FqaMVwxEREY07ep0WoTrtkP9QsYj7axpUQcoxMFTZB4QtXwHsaluvwwW7w9X/1x3E7P3bcnl9JNnnFPQ5HcCXv5jxps1OiMC+tQuG7wn9jOGIiIhoiGg0GuVjtOHkcLqDk70/OHmClCc89Xq1Xe3nPjp2NXCpQ1ev82q7ehsDn8NsGN3nVzEcERERjTF6nRZ6nRbBo/eTrYAa3dGOiIiIyM8YjoiIiIi8MBwREREReWE4IiIiIvLCcERERETkheGIiIiIyAvDEREREZEXhiMiIiIiLwxHRERERF4YjoiIiIi8MBwREREReWE4IiIiIvLCcERERETkheGIiIiIyIs+0AMYbiICAGhvbw/wSIiIiOhGef5ve/6PD6VxF45sNhsAICEhIcAjISIioptls9kQHh4+pM+hkeGIYCOIy+XCZ599htDQUGg0Gr9uu729HQkJCfjPf/6DsLAwv257tGNtfGNtfGNtfGNtfGNtfBvNtRER2Gw2xMfHQ6sd2rOCxt2RI61Wi9tuu21InyMsLGzU7XTDhbXxjbXxjbXxjbXxjbXxbbTWZqiPGHnwhGwiIiIiLwxHRERERF4YjvzIZDKhoKAAJpMp0EMZcVgb31gb31gb31gb31gb31ibGzPuTsgmIiIiuh4eOSIiIiLywnBERERE5IXhiIiIiMgLwxERERGRF4YjP3nzzTdx++23IygoCBkZGfjwww8DPSS/2rJlCzQajeo2depUpb2npwdr167FxIkTERISguXLl6OpqUm1jYaGBixbtgwWiwXR0dHYsGEDHA6Hqk9ZWRnuuusumEwmpKamYseOHcMxvZv2wQcf4P7770d8fDw0Gg327t2rahcRvPzyy4iLi4PZbEZWVhbOnTun6tPS0oK8vDyEhYUhIiIC3/ve99DR0aHqU1VVhUWLFiEoKAgJCQnYtm3bgLHs2rULU6dORVBQENLT03Hw4EG/z/dmfFFtHn/88QH7Uk5OjqrPWKzN1q1bcffddyM0NBTR0dF48MEHUVdXp+oznK+jkfSedSO1+drXvjZgv1m9erWqz1isDQAUFhZi1qxZyhc3Wq1WHDp0SGkfr/vNkBK6ZUVFRWI0GuXtt9+Wjz/+WFauXCkRERHS1NQU6KH5TUFBgcyYMUMuXryo3C5duqS0r169WhISEqSkpEROnTolX/3qV+Wee+5R2h0Oh8ycOVOysrKkoqJCDh48KFFRUfLCCy8off75z3+KxWKRZ555Rs6ePStvvPGG6HQ6KS4uHta53oiDBw/Kiy++KLt37xYAsmfPHlX7q6++KuHh4bJ37145c+aMfOMb35Dk5GTp7u5W+uTk5Mjs2bPlxIkT8ve//11SU1Pl0UcfVdrb2tokJiZG8vLypKamRnbu3Clms1l++9vfKn2OHz8uOp1Otm3bJmfPnpXNmzeLwWCQ6urqIa+BL19Um/z8fMnJyVHtSy0tLao+Y7E22dnZsn37dqmpqZHKykpZunSpJCYmSkdHh9JnuF5HI+0960Zqs2TJElm5cqVqv2lra1Pax2ptRET2798vBw4ckE8//VTq6upk06ZNYjAYpKamRkTG734zlBiO/GD+/Pmydu1a5b7T6ZT4+HjZunVrAEflXwUFBTJ79uxB21pbW8VgMMiuXbuUdbW1tQJAysvLRcT9D1Or1UpjY6PSp7CwUMLCwsRut4uIyI9//GOZMWOGatsrVqyQ7OxsP8/Gv64NAC6XS2JjY+VnP/uZsq61tVVMJpPs3LlTRETOnj0rAOSjjz5S+hw6dEg0Go3873//ExGRX//61xIZGanUR0Tk+eefl7S0NOX+ww8/LMuWLVONJyMjQ37wgx/4dY5flq9w9MADD/h8zHipTXNzswCQo0ePisjwvo5G+nvWtbURcYej9evX+3zMeKmNR2RkpPz+97/nfjNE+LHaLert7cXp06eRlZWlrNNqtcjKykJ5eXkAR+Z/586dQ3x8PFJSUpCXl4eGhgYAwOnTp9HX16eqwdSpU5GYmKjUoLy8HOnp6YiJiVH6ZGdno729HR9//LHSx3sbnj6jrY719fVobGxUzSU8PBwZGRmqekRERGDevHlKn6ysLGi1Wpw8eVLps3jxYhiNRqVPdnY26urqcOXKFaXPaKxZWVkZoqOjkZaWhjVr1uDy5ctK23ipTVtbGwBgwoQJAIbvdTQa3rOurY3HO++8g6ioKMycORMvvPACurq6lLbxUhun04mioiJ0dnbCarVyvxki4+6HZ/3t888/h9PpVO10ABATE4NPPvkkQKPyv4yMDOzYsQNpaWm4ePEiXnnlFSxatAg1NTVobGyE0WhERESE6jExMTFobGwEADQ2Ng5aI0/b9fq0t7eju7sbZrN5iGbnX575DDYX77lGR0er2vV6PSZMmKDqk5ycPGAbnrbIyEifNfNsYyTKycnBN7/5TSQnJ+PChQvYtGkTcnNzUV5eDp1ONy5q43K58PTTT2PBggWYOXMmAAzb6+jKlSsj+j1rsNoAwLe//W0kJSUhPj4eVVVVeP7551FXV4fdu3cDGPu1qa6uhtVqRU9PD0JCQrBnzx5Mnz4dlZWV3G+GAMMR3ZDc3FxledasWcjIyEBSUhLefffdURNaaGR45JFHlOX09HTMmjULd9xxB8rKypCZmRnAkQ2ftWvXoqamBseOHQv0UEYcX7VZtWqVspyeno64uDhkZmbiwoULuOOOO4Z7mMMuLS0NlZWVaGtrw3vvvYf8/HwcPXo00MMas/ix2i2KioqCTqcbcGVAU1MTYmNjAzSqoRcREYE777wT58+fR2xsLHp7e9Ha2qrq412D2NjYQWvkabten7CwsFEVwDzzud4+ERsbi+bmZlW7w+FAS0uLX2o2mva9lJQUREVF4fz58wDGfm3WrVuHv/zlLzhy5Ahuu+02Zf1wvY5G8nuWr9oMJiMjAwBU+81Yro3RaERqairmzp2LrVu3Yvbs2fjVr37F/WaIMBzdIqPRiLlz56KkpERZ53K5UFJSAqvVGsCRDa2Ojg5cuHABcXFxmDt3LgwGg6oGdXV1aGhoUGpgtVpRXV2t+qd3+PBhhIWFYfr06Uof7214+oy2OiYnJyM2NlY1l/b2dpw8eVJVj9bWVpw+fVrpU1paCpfLpbzpW61WfPDBB+jr61P6HD58GGlpaYiMjFT6jPaa/fe//8Xly5cRFxcHYOzWRkSwbt067NmzB6WlpQM+Fhyu19FIfM/6otoMprKyEgBU+81YrI0vLpcLdrt9XO83QyrQZ4SPBUVFRWIymWTHjh1y9uxZWbVqlURERKiuDBjtnn32WSkrK5P6+no5fvy4ZGVlSVRUlDQ3N4uI+1LSxMREKS0tlVOnTonVahWr1ao83nMp6X333SeVlZVSXFwskyZNGvRS0g0bNkhtba28+eabI/ZSfpvNJhUVFVJRUSEA5LXXXpOKigr597//LSLuS/kjIiJk3759UlVVJQ888MCgl/J/5StfkZMnT8qxY8dkypQpqsvVW1tbJSYmRh577DGpqamRoqIisVgsAy5X1+v18vOf/1xqa2uloKAg4JfyX682NptNnnvuOSkvL5f6+np5//335a677pIpU6ZIT0+Pso2xWJs1a9ZIeHi4lJWVqS5H7+rqUvoM1+topL1nfVFtzp8/Lz/5yU/k1KlTUl9fL/v27ZOUlBRZvHixso2xWhsRkY0bN8rRo0elvr5eqqqqZOPGjaLRaORvf/ubiIzf/WYoMRz5yRtvvCGJiYliNBpl/vz5cuLEiUAPya9WrFghcXFxYjQaZfLkybJixQo5f/680t7d3S1PPvmkREZGisVikYceekguXryo2sa//vUvyc3NFbPZLFFRUfLss89KX1+fqs+RI0dkzpw5YjQaJSUlRbZv3z4c07tpR44cEQADbvn5+SLivpz/pZdekpiYGDGZTJKZmSl1dXWqbVy+fFkeffRRCQkJkbCwMHniiSfEZrOp+pw5c0YWLlwoJpNJJk+eLK+++uqAsbz77rty5513itFolBkzZsiBAweGbN434nq16erqkvvuu08mTZokBoNBkpKSZOXKlQPeXMdibQarCQDVPj6cr6OR9J71RbVpaGiQxYsXy4QJE8RkMklqaqps2LBB9T1HImOzNiIi3/3udyUpKUmMRqNMmjRJMjMzlWAkMn73m6GkEREZvuNURERERCMbzzkiIiIi8sJwREREROSF4YiIiIjIC8MRERERkReGIyIiIiIvDEdEREREXhiOiIiIiLwwHBHRuKfRaLB3795AD4OIRgiGIyIKqMcffxwajWbALScnJ9BDI6JxSh/oARAR5eTkYPv27ap1JpMpQKMhovGOR46IKOBMJhNiY2NVt8jISADuj7wKCwuRm5sLs9mMlJQUvPfee6rHV1dX4+tf/zrMZjMmTpyIVatWoaOjQ9Xn7bffxowZM2AymRAXF4d169ap2j///HM89NBDsFgsmDJlCvbv3z+0kyaiEYvhiIhGvJdeegnLly/HmTNnkJeXh0ceeQS1tbUAgM7OTmRnZyMyMhIfffQRdu3ahffff18VfgoLC7F27VqsWrUK1dXV2L9/P1JTU1XP8corr+Dhhx9GVVUVli5diry8PLS0tAzrPIlohAj0L98S0fiWn58vOp1OgoODVbef/vSnIuL+xfbVq1erHpORkSFr1qwREZG33npLIiMjpaOjQ2k/cOCAaLVaaWxsFBGR+Ph4efHFF32OAYBs3rxZud/R0SEA5NChQ36bJxGNHjzniIgC7t5770VhYaFq3YQJE5Rlq9WqarNaraisrAQA1NbWYvbs2QgODlbaFyxYAJfLhbq6Omg0Gnz22WfIzMy87hhmzZqlLAcHByMsLAzNzc1fdkpENIoxHBFRwAUHBw/4mMtfzGbzDfUzGAyq+xqNBi6XayiGREQjHM85IqIR78SJEwPuT5s2DQAwbdo0nDlzBp2dnUr78ePHodVqkZaWhtDQUNx+++0oKSkZ1jET0ejFI0dEFHB2ux2NjY2qdXq9HlFRUQCAXbt2Yd68eVi4cCHeeecdfPjhh/jDH/4AAMjLy0NBQQHy8/OxZcsWXLp0CU899RQee+wxxMTEAAC2bNmC1atXIzo6Grm5ubDZbDh+/Dieeuqp4Z0oEY0KDEdEFHDFxcWIi4tTrUtLS8Mnn3wCwH0lWVFREZ588knExcVh586dmD59OgDAYrHgr3/9K9avX4+7774bFosFy5cvx2uvvaZsKz8/Hz09PXj99dfx3HPPISoqCt/61reGb4JENKpoREQCPQgiIl80Gg327NmDBx98MNBDIaJxguccEREREXlhOCIiIiLywnOOiGhE4yf/RDTceOSIiIiIyAvDEREREZEXhiMiIiIiLwxHRERERF4YjoiIiIi8MBwREREReWE4IiIiIvLCcERERETkheGIiIiIyMv/AS8oVrv8A8rfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cost and accuracy in one graph\n",
    "plt.plot(history_cost, label='Train Loss')\n",
    "plt.plot(val_cost, label='Validation Loss')\n",
    "plt.plot(history_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.text(len(history_cost) - 50, history_cost[-1] + 0.01, str(round(history_cost[-1], 3)))\n",
    "plt.text(len(history_acc) - 50, history_acc[-1] - 0.03, str(round(history_acc[-1], 3)))\n",
    "plt.text(len(val_cost) - 50, val_cost[-1] + 0.01, str(round(val_cost[-1], 3)))\n",
    "plt.text(len(val_acc) - 50, val_acc[-1] - 0.03, str(round(val_acc[-1], 3)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss / Accurcay')\n",
    "plt.title('Train vs Validation Metrics for Mode ' + model_name)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and the cost and accuracy\n",
    "file_name = 'NeuralNetwork_Model_' + model_name + '.pkl'\n",
    "file_name_cost_acc = 'Cost_Accuracy_Model_' + model_name + '.csv'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save cost & accuracy\n",
    "cost_acc = pd.DataFrame({\n",
    "    'train_cost': history_cost,\n",
    "    'train_acc': history_acc,\n",
    "    'val_cost': val_cost,\n",
    "    'val_acc': val_acc\n",
    "})\n",
    "cost_acc.to_csv(file_name_cost_acc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 4, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 0, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 4, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 0, 0, 1, 0, 0, 4, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 4, 0, 0, 0, 0, 1, 4, 4,\n",
      "       0, 3, 0, 4, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 0, 4, 3, 0, 2, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 4, 2, 0, 0, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 4, 0, 3, 0, 0, 4, 4, 0, 2, 0, 2, 3, 0, 0, 4, 4, 4, 1, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 4, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       0, 4, 0, 1, 0, 0, 4, 4, 0, 0, 4, 0, 4, 0, 3, 0, 0, 4, 0, 0, 4, 1,\n",
      "       3, 0, 0, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 3, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 3, 0, 4, 0, 3, 0, 2, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 2, 0, 4, 1, 0, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 4, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 0, 0,\n",
      "       0, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 3, 2, 4, 4, 0, 0, 0, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 3, 0, 0, 2, 3, 3, 0, 0,\n",
      "       3, 0, 4, 0, 0, 0, 2, 0, 0, 0, 4, 4, 0, 4, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 3, 4, 0, 4, 2, 0, 0, 0, 4, 0, 0, 0, 0, 1, 4, 0, 0, 4, 4, 0,\n",
      "       3, 2, 0, 3, 2, 3, 3, 0, 0, 0, 1, 0, 0, 0, 4, 0, 2, 4, 0, 3, 0, 2,\n",
      "       0, 0, 3, 2, 1, 2, 0, 0, 4, 4, 0, 1, 0, 1, 0, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 4, 3, 0, 0, 0, 4, 1, 0, 4, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 4, 0, 4, 3, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 4, 0, 1, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 0,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 2, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 4, 0,\n",
      "       0, 0, 0, 0, 0, 0, 2, 2, 0, 3], dtype=int64), array([0, 4, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 3, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 2, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 3, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 4, 0, 1, 0, 0, 3, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 2, 0, 0, 0, 0, 1, 4, 3,\n",
      "       0, 3, 2, 0, 1, 0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 1, 4, 3, 0, 2, 4, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 4, 3, 1, 1, 0, 0, 3, 2, 0, 4, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 1, 0, 3, 0, 0, 4, 4, 0, 4, 0, 2, 3, 4, 0, 4, 4, 2, 0, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       1, 4, 0, 1, 0, 0, 4, 4, 0, 0, 2, 0, 0, 0, 3, 0, 0, 4, 0, 0, 3, 1,\n",
      "       3, 0, 2, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 1, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 2, 0, 4, 0, 3, 0, 1, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 2, 0, 4, 1, 4, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 2, 0, 0,\n",
      "       4, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 4, 2, 4, 4, 0, 0, 4, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 4, 0, 0, 2, 3, 3, 4, 0,\n",
      "       0, 0, 4, 4, 0, 0, 2, 0, 1, 0, 4, 4, 4, 0, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 2, 4, 0, 4, 2, 0, 0, 0, 3, 0, 0, 4, 0, 1, 4, 0, 0, 0, 4, 4,\n",
      "       4, 2, 0, 3, 2, 3, 4, 0, 1, 0, 1, 0, 0, 0, 4, 0, 2, 0, 0, 3, 0, 2,\n",
      "       0, 0, 4, 2, 1, 1, 0, 0, 4, 0, 0, 1, 0, 1, 2, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 3, 3, 0, 0, 0, 4, 1, 0, 3, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 3, 0, 3, 4, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 3, 0, 1, 3, 3, 3, 3, 0, 3, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 3,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 0, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 4, 0, 0, 3, 0, 4, 4,\n",
      "       0, 0, 0, 4, 0, 0, 2, 2, 0, 3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train, y_train)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 4, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 0, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 4, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 0, 0, 1, 0, 0, 4, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 4, 0, 0, 0, 0, 1, 4, 4,\n",
      "       0, 3, 0, 4, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 0, 4, 3, 0, 2, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 4, 2, 0, 0, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 4, 0, 3, 0, 0, 4, 4, 0, 2, 0, 2, 3, 0, 0, 4, 4, 4, 1, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 4, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       0, 4, 0, 1, 0, 0, 4, 4, 0, 0, 4, 0, 4, 0, 3, 0, 0, 4, 0, 0, 4, 1,\n",
      "       3, 0, 0, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 3, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 3, 0, 4, 0, 3, 0, 2, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 2, 0, 4, 1, 0, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 4, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 0, 0,\n",
      "       0, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 3, 2, 4, 4, 0, 0, 0, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 3, 0, 0, 2, 3, 3, 0, 0,\n",
      "       3, 0, 4, 0, 0, 0, 2, 0, 0, 0, 4, 4, 0, 4, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 3, 4, 0, 4, 2, 0, 0, 0, 4, 0, 0, 0, 0, 1, 4, 0, 0, 4, 4, 0,\n",
      "       3, 2, 0, 3, 2, 3, 3, 0, 0, 0, 1, 0, 0, 0, 4, 0, 2, 4, 0, 3, 0, 2,\n",
      "       0, 0, 3, 2, 1, 2, 0, 0, 4, 4, 0, 1, 0, 1, 0, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 4, 3, 0, 0, 0, 4, 1, 0, 4, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 4, 0, 4, 3, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 4, 0, 1, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 0,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 2, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 4, 0,\n",
      "       0, 0, 0, 0, 0, 0, 2, 2, 0, 3], dtype=int64), array([0, 4, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 3, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 2, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 3, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 4, 0, 1, 0, 0, 3, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 2, 0, 0, 0, 0, 1, 4, 3,\n",
      "       0, 3, 2, 0, 1, 0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 1, 4, 3, 0, 2, 4, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 4, 3, 1, 1, 0, 0, 3, 2, 0, 4, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 1, 0, 3, 0, 0, 4, 4, 0, 4, 0, 2, 3, 4, 0, 4, 4, 2, 0, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       1, 4, 0, 1, 0, 0, 4, 4, 0, 0, 2, 0, 0, 0, 3, 0, 0, 4, 0, 0, 3, 1,\n",
      "       3, 0, 2, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 1, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 2, 0, 4, 0, 3, 0, 1, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 2, 0, 4, 1, 4, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 2, 0, 0,\n",
      "       4, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 4, 2, 4, 4, 0, 0, 4, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 4, 0, 0, 2, 3, 3, 4, 0,\n",
      "       0, 0, 4, 4, 0, 0, 2, 0, 1, 0, 4, 4, 4, 0, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 2, 4, 0, 4, 2, 0, 0, 0, 3, 0, 0, 4, 0, 1, 4, 0, 0, 0, 4, 4,\n",
      "       4, 2, 0, 3, 2, 3, 4, 0, 1, 0, 1, 0, 0, 0, 4, 0, 2, 0, 0, 3, 0, 2,\n",
      "       0, 0, 4, 2, 1, 1, 0, 0, 4, 0, 0, 1, 0, 1, 2, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 3, 3, 0, 0, 0, 4, 1, 0, 3, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 3, 0, 3, 4, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 3, 0, 1, 3, 3, 3, 3, 0, 3, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 3,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 0, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 4, 0, 0, 3, 0, 4, 4,\n",
      "       0, 0, 0, 4, 0, 0, 2, 2, 0, 3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train, y_train)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
